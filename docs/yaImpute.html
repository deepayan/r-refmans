<!DOCTYPE html><html><head><title>Help for package yaImpute</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {yaImpute}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ann'><p>Approximate nearest neighbor search routines</p></a></li>
<li><a href='#applyMask'><p>Removes neighbors that share (or not) group membership with targets.</p></a></li>
<li><a href='#AsciiGridImpute'><p>Imputes/Predicts data for Ascii Grid maps</p></a></li>
<li><a href='#bestVars'><p>Computes the number of <em>best</em> X-variables</p></a></li>
<li><a href='#buildConsensus'><p>Finds the consensus imputations among a list of yai objects</p></a></li>
<li><a href='#compare.yai'><p>Compares different k-NN solutions</p></a></li>
<li><a href='#cor.yai'><p>Correlation between observed and imputed</p></a></li>
<li><a href='#correctBias'><p>Correct bias by selecting different near neighbors</p></a></li>
<li><a href='#ensembleImpute'><p>Computes the mean, median, or mode among a list of impute.yai objects</p></a></li>
<li><a href='#errorStats'><p>Compute error components of k-NN imputations</p></a></li>
<li><a href='#foruse'><p>Report a complete imputation</p></a></li>
<li><a href='#grmsd'><p>Generalized Root Mean Square Distance Between Observed and Imputed Values</p></a></li>
<li><a href='#impute.yai'><p>Impute variables from references to targets</p></a></li>
<li><a href='#MoscowMtStJoe'><p>Moscow Mountain and St. Joe Woodlands (Idaho, USA) Tree and LiDAR Data</p></a></li>
<li><a href='#mostused'><p>Tabulate references most often used in imputation</p></a></li>
<li><a href='#newtargets'><p>Finds K nearest neighbors for new target observations</p></a></li>
<li><a href='#notablyDifferent'><p>Finds observations with large differences between observed and imputed values</p></a></li>
<li><a href='#notablyDistant'><p>Find notably distant targets</p></a></li>
<li><a href='#plot.compare.yai'><p>Plots a compare.yai object</p></a></li>
<li><a href='#plot.notablyDifferent'><p>Plots the scaled root mean square differences between observed and predicted</p></a></li>
<li><a href='#plot.varSel'><p>Boxplot of mean Mahalanobis distances from varSelection()</p></a></li>
<li><a href='#plot.yai'><p>Plot observed verses imputed data</p></a></li>
<li><a href='#predict.yai'><p>Generic predict function for class yai</p></a></li>
<li><a href='#print.yai'><p>Print a summary of a yai object</p></a></li>
<li><a href='#rmsd.yai'><p>Root Mean Square Difference between observed and imputed</p></a></li>
<li><a href='#TallyLake'><p>Tally Lake, Flathead National Forest, Montana, USA</p></a></li>
<li><a href='#unionDataJoin'><p>Combines data from several sources</p></a></li>
<li><a href='#vars'><p>List variables in a yai object</p></a></li>
<li><a href='#varSelection'><p>Select variables for imputation models</p></a></li>
<li><a href='#whatsMax'><p>Find maximum column for each row</p></a></li>
<li><a href='#yai'><p>Find K nearest neighbors</p></a></li>
<li><a href='#yaiRFsummary'><p>Build Summary Data For Method RandomForest</p></a></li>
<li><a href='#yaiVarImp'><p>Reports or plots importance scores for yai method randomForest</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Nearest Neighbor Observation Imputation and Evaluation Tools</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-34</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-12</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs nearest neighbor-based imputation using one or more alternative 
    approaches to processing multivariate data. These include methods based on canonical 
    correlation: analysis, canonical correspondence analysis, and a multivariate adaptation 
    of the random forest classification and regression techniques of Leo Breiman and Adele 
    Cutler. Additional methods are also offered. The package includes functions for 
    comparing the results from running alternative techniques, detecting imputation targets 
    that are notably distant from reference observations, detecting and correcting 
    for bias, bootstrapping and building ensemble imputations, and mapping results.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, graphics, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>vegan, ccaPP, randomForest, gam, fastICA, parallel, gower</td>
</tr>
<tr>
<td>Copyright:</td>
<td>ANN library is copyright University of Maryland and Sunil
Arya and David Mount. See file COPYRIGHTS for details.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jeffrey S. Evans &lt;jeffrey_evans@tnc.org&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/jeffreyevans/yaImpute">https://github.com/jeffreyevans/yaImpute</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jeffreyevans/yaImpute/issues">https://github.com/jeffreyevans/yaImpute/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-12 23:14:22 UTC; jeffrey_evans</td>
</tr>
<tr>
<td>Author:</td>
<td>Jeffrey S. Evans <a href="https://orcid.org/0000-0002-5533-7044"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Nicholas L. Crookston [aut],
  Andrew O. Finley [aut],
  John Coulston (Sunil Arya and David Mount for ANN) [ctb, com]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-12 23:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ann'>Approximate nearest neighbor search routines</h2><span id='topic+ann'></span>

<h3>Description</h3>

<p>Given a set of reference data points <code class="reqn">S</code>, <code>ann</code> constructs a
kd-tree or box-decomposition tree (bd-tree) for efficient <code class="reqn">k</code>-nearest
neighbor searches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ann(ref, target, k=1, eps=0.0, tree.type="kd",
    search.type="standard", bucket.size=1, split.rule="sl_midpt",
    shrink.rule="simple", verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ann_+3A_ref">ref</code></td>
<td>
<p>an <code class="reqn">n \times d</code> matrix containing the reference point set
<code class="reqn">S</code>. Each row in <code>ref</code> corresponds to a point in <code class="reqn">d</code>-dimensional space. </p>
</td></tr>
<tr><td><code id="ann_+3A_target">target</code></td>
<td>
<p>an <code class="reqn">m \times d</code> matrix containing the points
for which <code class="reqn">k</code> nearest neighbor reference points are sought. </p>
</td></tr>
<tr><td><code id="ann_+3A_k">k</code></td>
<td>
<p>defines the number of nearest neighbors to find. The default
is <code class="reqn">k</code>=1. </p>
</td></tr>
<tr><td><code id="ann_+3A_eps">eps</code></td>
<td>
<p>the <code class="reqn">i^{th}</code> nearest neighbor is at most
(1+<code>eps</code>) from true <code class="reqn">i^{th}</code> nearest neighbor, where <code>eps</code><code class="reqn">\ge 0</code> . Specifically, the true (not
squared) difference between the true <code class="reqn">i^{th}</code> and the
approximation of the <code class="reqn">i^{th}</code> point is a factor of
(1+<code>eps</code>). The default value of <code>eps</code>=0 is an exact
search. </p>
</td></tr>
<tr><td><code id="ann_+3A_tree.type">tree.type</code></td>
<td>
<p>the data structures kd-tree or bd-tree as
quoted key words <em>kd</em> and <em>bd</em>, respectively.  A brute force
search can be specified with the quoted key word <em>brute</em>. If
<em>brute</em> is specified, then all subsequent arguments are
ignored.  The default is the kd-tree. </p>
</td></tr>
<tr><td><code id="ann_+3A_search.type">search.type</code></td>
<td>
<p>either standard or priority search in the kd-tree
or bd-tree, specified by quoted key words <em>standard</em> and <em>priority</em>,
respectively. The default is the standard search. </p>
</td></tr>
<tr><td><code id="ann_+3A_bucket.size">bucket.size</code></td>
<td>
<p>the maximum number of reference points in the leaf
nodes. The default is 1. </p>
</td></tr>
<tr><td><code id="ann_+3A_split.rule">split.rule</code></td>
<td>
<p>is the strategy for the recursive splitting of those
nodes with more points than the bucket size.  The splitting
rule applies to both the kd-tree and bd-tree.  Splitting rule
options are the quoted key words:
</p>

<ol>
<li><p> standard - standard kd-tree
</p>
</li>
<li><p> midpt - midpoint
</p>
</li>
<li><p> fair - fair-split
</p>
</li>
<li><p> midpt - sliding-midpoint (default)
</p>
</li>
<li><p> fair - fair-split rule
</p>
</li></ol>

<p>See supporting documentation, reference below, for a thorough
description and discussion of these splitting rules. </p>
</td></tr>
<tr><td><code id="ann_+3A_shrink.rule">shrink.rule</code></td>
<td>
<p>applies only to the bd-tree and is an additional
strategy (beyond the splitting rule) for the recursive partitioning
of nodes.  This argument is ignored if <code>tree.type</code> is specified
as <em>kd</em>. Shrinking rule options are quoted key words:
</p>

<ol>
<li><p> none - equivalent to the kd-tree
</p>
</li>
<li><p> simple - simple shrink (default)
</p>
</li>
<li><p> centroid - centroid shrink
</p>
</li></ol>

<p>See supporting documentation, reference below, for a thorough description and
discussion of these shrinking rules. </p>
</td></tr>
<tr><td><code id="ann_+3A_verbose">verbose</code></td>
<td>
<p>if true, search progress is printed to the screen. </p>
</td></tr>
<tr><td><code id="ann_+3A_...">...</code></td>
<td>
<p>currently no additional arguments. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>ann</code> function calls portions of the Approximate Nearest
Neighbor Library, written by David M. Mount.  All of the <code>ann</code>
function arguments are detailed in the ANN Programming Manual
found at <a href="https://www.cs.umd.edu/~mount/ANN/">https://www.cs.umd.edu/~mount/ANN/</a>.
</p>


<h3>Value</h3>

<p>An object of class <code>ann</code>, which is a list with some or all of
the following tags:
</p>
<table>
<tr><td><code>knnIndexDist</code></td>
<td>
<p>an <code class="reqn">m \times 2k</code> matrix.
Each row corresponds to a target point in <code>target</code> and columns
1:<code class="reqn">k</code> hold the <code>ref</code> matrix row indices of the nearest
neighbors, such that column 1 index holds the <code>ref</code> matrix row
index for the first nearest
neighbor and column <code class="reqn">k</code> is the <code class="reqn">k^{th}</code> nearest
neighbor index.  Columns <code class="reqn">k+1</code>:2k hold the Euclidean distance from the
target to each of the <code class="reqn">k</code> nearest neighbors indexed in columns 1:<code class="reqn">k</code>. </p>
</td></tr>
<tr><td><code>searchTime</code></td>
<td>
<p>total search time, not including data structure
construction, etc. </p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>as defined in the <code>ann</code> function call. </p>
</td></tr>
<tr><td><code>eps</code></td>
<td>
<p>as defined in the <code>ann</code> function call. </p>
</td></tr>
<tr><td><code>tree.type</code></td>
<td>
<p>as defined in the <code>ann</code> function call. </p>
</td></tr>
<tr><td><code>search.type</code></td>
<td>
<p>as defined in the <code>ann</code> function call. </p>
</td></tr>
<tr><td><code>bucket.size</code></td>
<td>
<p>as defined in the <code>ann</code> function call. </p>
</td></tr>
<tr><td><code>split.rule</code></td>
<td>
<p>as defined in the <code>ann</code> function call. </p>
</td></tr>
<tr><td><code>shrink.rule</code></td>
<td>
<p>as defined in the <code>ann</code> function call. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Make a couple of bivariate normal classes
rmvn &lt;- function(n, mu=0, V = matrix(1))
{
  p &lt;- length(mu)
  if(any(is.na(match(dim(V),p))))
    stop("Dimension problem!")
  D &lt;- chol(V)
  matrix(rnorm(n*p), ncol=p) %*% D + rep(mu,rep(n,p))
}

m &lt;- 10000

## Class 1.
mu.1 &lt;- c(20, 40)
V.1 &lt;- matrix(c(-5,1,0,5),2,2); V.1 &lt;- V.1%*%t(V.1)
c.1 &lt;- cbind(rmvn(m, mu.1, V.1), rep(1, m))

## Class 2.
mu.2 &lt;- c(30, 60)
V.2 &lt;- matrix(c(4,2,0,2),2,2); V.2 &lt;- V.2%*%t(V.2)
c.2 &lt;- cbind(rmvn(m, mu.2, V.2), rep(2, m))

## Class 3.
mu.3 &lt;- c(15, 60)
V.3 &lt;- matrix(c(5,5,0,5),2,2); V.3 &lt;- V.3%*%t(V.3)
c.3 &lt;- cbind(rmvn(m, mu.3, V.3), rep(3, m))

c.all &lt;- rbind(c.1, c.2, c.3)
max.x &lt;- max(c.all[,1]); min.x &lt;- min(c.all[,1])
max.y &lt;- max(c.all[,2]); min.y &lt;- min(c.all[,2])

## Check them out.
plot(c.1[,1], c.1[,2], xlim=c(min.x, max.x), ylim=c(min.y, max.y),
     pch=19, cex=0.5,
     col="blue", xlab="Variable 1", ylab="Variable 2")
points(c.2[,1], c.2[,2], pch=19, cex=0.5, col="green")
points(c.3[,1], c.3[,2], pch=19, cex=0.5, col="red")


## Take a reference sample.
n &lt;- 2000
ref &lt;- c.all[sample(1:nrow(c.all), n),]

## Compare search times
k &lt;- 10
## Do a simple brute force search.
brute &lt;- ann(ref=ref[,1:2], target=c.all[,1:2],
             tree.type="brute", k=k, verbose=FALSE)
print(brute$searchTime)

## Do an exact kd-tree search.
kd.exact &lt;- ann(ref=ref[,1:2], target=c.all[,1:2],
                tree.type="kd", k=k, verbose=FALSE)
print(kd.exact$searchTime)

## Do an approximate kd-tree search.
kd.approx &lt;- ann(ref=ref[,1:2], target=c.all[,1:2],
                 tree.type="kd", k=k, eps=100, verbose=FALSE)
print(kd.approx$searchTime)

## Takes too long to calculate for this many targets.
## Compare overall accuracy of the exact vs. approximate search
##knn.mode &lt;- function(knn.indx, ref){
##  x &lt;- ref[knn.indx,]
##  as.numeric(names(sort(as.matrix(table(x))[,1],
##                        decreasing=TRUE))[1])
##}

</code></pre>

<hr>
<h2 id='applyMask'>Removes neighbors that share (or not) group membership with targets.</h2><span id='topic+applyMask'></span>

<h3>Description</h3>

<p>Some of the nearest neighbors found using <code><a href="#topic+yai">yai</a></code> or
<code><a href="#topic+newtargets">newtargets</a></code> are removed using this function. This is possible when there 
are several reference observations for each target as is the case with <em>k&gt;1</em>. 
The function removes neighbor reference observations for a given target if the reference
and target are in (a) the same group or (b) from different
groups, depending on the <code>method</code> used. Group membership is identified for 
reference and target observations using two vectors, <code>refGroups</code> for references 
and <code>trgGroups</code> for targets. If the group membership code is the same for a 
refernece and a target, then they are in the same group while different codes mean  
a lack of common group membership. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>applyMask(object,refGroups=NULL, trgGroups=NULL, method="removeWhenCommon", k=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="applyMask_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="applyMask_+3A_refgroups">refGroups</code></td>
<td>
<p>a vector, with length equal to the number of <em>reference</em> observations, 
of codes that indicate group membership.</p>
</td></tr>
<tr><td><code id="applyMask_+3A_trggroups">trgGroups</code></td>
<td>
<p>a vector, with length equal to the number of <em>target</em> observations, 
of codes that indicate group membership. The data type and coding scheme of <code>refGroups</code> 
and <code>trgGroups</code> must be the same.</p>
</td></tr>
<tr><td><code id="applyMask_+3A_method">method</code></td>
<td>
<p>is the strategy used for removing neighbors from the <code>object</code>, as follows:
</p>

<ol>
<li><p> removeWhenCommon - remove neighbors where the group membership of a
target is the same as the group membership of the near neighbor reference (that is, keep 
near neighbors if they are not in the same group).
</p>
</li>
<li><p> keepWhenCommon - keep near neighbors only when the reference is in the same
group as the target (that is, remove near neighbors if they are not in the same group).
</p>
</li></ol>
</td></tr>
<tr><td><code id="applyMask_+3A_k">k</code></td>
<td>
<p>the number of nearest neighbors to keep.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>yai</code>, that is a copy of the first argument with the
following elements replaced:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call.</p>
</td></tr>
<tr><td><code>neiDstTrgs</code></td>
<td>
<p>a matrix of distances between a target
(identified by its row name) and the k references. There are k columns.</p>
</td></tr>
<tr><td><code>neiIdsTrgs</code></td>
<td>
<p>a matrix of reference identifications
that correspond to neiDstTrgs.</p>
</td></tr>
<tr><td><code>neiDstRefs</code></td>
<td>
<p>set NULL as if <code>noRefs=TRUE</code> in the original call to <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code>neiIdsRefs</code></td>
<td>
<p>set NULL as if <code>noRefs=TRUE</code> in the original call to <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code>noRefs</code></td>
<td>
<p>set TRUE regardless of original value.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the value of k.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Acknowledgment: This function was inspired by correspondence with Clara Anton Fernandez.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code> <code><a href="#topic+newtargets">newtargets</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
require (yaImpute)

data(iris)

# build a base case, there are no targets, 
#    turn off getting references neighbors.
mal &lt;- yai(x=iris[,-5],method="mahalanobis", noRefs = TRUE)

# create a new data, just a copy of the old with new row names.
iris2 &lt;- iris
rownames(iris2) &lt;- paste0("new.",rownames(iris))

# do an imputation with k=55
m55 &lt;- newtargets(mal,newdata=iris2,k=55)

# get the 2 closest where the species codes don't match by
#  removing neighbors when the ref group membership is 
#  in common with the target group membership (same species),
#  thereby forcing neighbors to be from different species. 

#  in this case, the groups are species codes. 

applyMask(m55,refGroups=iris$Species,trgGroups=iris2$Species,
          method="removeWhenCommon",k=2)

# get the 2 closest where the species codes do match by
#  removing neighbors when the ref group membership is 
#  different than the target group membership (different species),
#  thereby forcing neighbors to be from the same species (this
#  is generally true anyway using the iris data). 

applyMask(m55,iris$Species,trgGroups=iris2$Species,
          method="keepWhenCommon",k=2)

</code></pre>

<hr>
<h2 id='AsciiGridImpute'>Imputes/Predicts data for Ascii Grid maps</h2><span id='topic+AsciiGridImpute'></span><span id='topic+AsciiGridPredict'></span>

<h3>Description</h3>

<p><code>AsciiGridImpute</code> finds nearest neighbor <em>reference</em>
observations for each point in the input grid maps and outputs maps
of selected Y-variables in a corresponding set of output grid maps.
</p>
<p><code>AsciiGridPredict</code> applies a predict function to each point in the
input grid maps and outputs maps of the prediction(s) in corresponding 
output grid maps (see Details).
</p>
<p>One row of each grid map is read and processed at a time thereby
avoiding the need to build huge objects in R that would be necessary if all
the rows of all the maps were processed together.</p>


<h3>Usage</h3>

<pre><code class='language-R'>AsciiGridImpute(object,xfiles,outfiles,xtypes=NULL,ancillaryData=NULL,
                ann=NULL,lon=NULL,lat=NULL,rows=NULL,cols=NULL,
                nodata=NULL,myPredFunc=NULL,...)

AsciiGridPredict(object,xfiles,outfiles,xtypes=NULL,lon=NULL,lat=NULL,
                 rows=NULL,cols=NULL,nodata=NULL,myPredFunc=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AsciiGridImpute_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+yai">yai</a></code>, any object for which
a <code><a href="stats.html#topic+predict">predict</a></code> function is defined, or an object that is passed
to a predict function you define using argument <code>myPredFunc</code>. See Details.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_xfiles">xfiles</code></td>
<td>
<p>A <code><a href="base.html#topic+list">list</a></code> of input file names where there is one
grid file for each X-variable. List elements must be given the same names
as the X-variables they correspond with and there must be one file for
each X-variable used when <code>object</code> was built.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_outfiles">outfiles</code></td>
<td>
<p>One of these two forms:
</p>

<ol>
<li><p> A file name that is understood to correspond to the single prediction
returned by the generic <code><a href="stats.html#topic+predict">predict</a></code> function
related to <code>object</code> or returned by <code>myPredFunc</code>. This form only
applies to <code>AsciiGridPredict</code>, when the object is not class <code>yai</code>.
</p>
</li>
<li><p> A <code><a href="base.html#topic+list">list</a></code> of output file names where there is
one grid file for each <em>desired</em> output variable. While there may be
many variables predicted for <code>object</code>, only those for which an
output grid is desire need to be specified. Note that some predict functions return
data frames, some return a single vector, and often what is returned depends on the
value of arguments passed to predict. In addition to names of the
predicted variables, the following two special names can be coded when
the object class is <code>yai</code>: For <code>distance=</code><em>&ldquo;filename&rdquo;</em>
a map of the distances is output and if
<code>useid=</code><em>&ldquo;filename&rdquo;</em> a map of integer indices to row numbers of the
reference observations is output.
When the predict function returns a vector,
an additional special name of <code>predict=</code><em>&ldquo;filename&rdquo;</em> can be
used.</p>
</li></ol>
 </td></tr>
<tr><td><code id="AsciiGridImpute_+3A_xtypes">xtypes</code></td>
<td>
<p>A list of data type names that corresponds exactly to data type of the
maps listed in <code>xfiles</code>. Each value can be one of:
<code>"logical", "integer", "numeric", "character"</code>. If NULL,
or if a type is missing for a member of <code>xfiles</code>, type <code>"numeric"</code> is used.
See Details if you used factors as predictors.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_ancillarydata">ancillaryData</code></td>
<td>
<p>A data frame of Y-variables that may not have been used in
the original call to <code><a href="#topic+yai">yai</a></code>. There must be one row for
each reference observation, no missing data, and row names must match those used
in the original reference observations.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_ann">ann</code></td>
<td>
<p>if NULL, the value is taken from <code>object</code>. When TRUE, <code><a href="#topic+ann">ann</a></code> is
used to find neighbors, and when FALSE a slow exact search is used (ignored for when
method randomForest is used when the original <code><a href="#topic+yai">yai</a></code> object was created).</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_lon">lon</code></td>
<td>
<p>if NULL, the value of <code>cols</code> is used. Otherwise, a 2-element
vector given the range of longitudes (horizontal distance) desired for the output.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_lat">lat</code></td>
<td>
<p>if NULL, the value of <code>rows</code> is used. Otherwise, a 2-element
vector given the range of latitudes (vertical distance) desired for the output.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_rows">rows</code></td>
<td>
<p>if NULL, all rows from the input grids are used. Otherwise, rows is a 2-element
vector given the rows desired for the output. If the second element is greater than
the number of rows, the header value <code>YLLCORNER</code> in the output is adjusted accordingly. 
Ignored if <code>lon</code> is specified.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_cols">cols</code></td>
<td>
<p>if NULL, all columns from the input grids are used. Otherwise, cols is a 2-element
vector given the columns desired for the output. If the first element is greater than
one, the header value <code>XLLCORNER</code> in the output is adjusted accordingly. Ignored
if <code>lat</code> is specified.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_nodata">nodata</code></td>
<td>
<p>the <code>NODATA_VALUE</code> for the output. If NULL, the value is taken from the
input grids.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_mypredfunc">myPredFunc</code></td>
<td>
<p>called by <code>AsciiGridPredict</code> to predict output using the <code>object</code> 
and newdata from the <code>xfiles</code>. Two arguments are passed by <code>AsciiGridPredict</code> to this 
function, the first is the value of <code>object</code> and the
second is a data frame of the new predictor variables created for each row
of data from your input maps. If NULL, the generic
<code>predict</code> function is called for <code>object</code>.</p>
</td></tr>
<tr><td><code id="AsciiGridImpute_+3A_...">...</code></td>
<td>
<p>passed to <code>myPredFunc</code>, <code>predict</code>, or <code>impute</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input maps are assumed to be Asciigrid maps with 6-line headers
containing the following tags: <code>NCOLS, NROWS, XLLCORNER, YLLCORNER,
  CELLSIZE</code> and <code>NODATA_VALUE</code> (case insensitive). The headers should be
identical for all input maps, a warning is issued if they are not. 
It is critical that <code>NODATA_VALUE</code> is the same on all input maps.
</p>
<p>The function builds data frames from the input maps one row at a time and
builds predictions using those data frames as <em>newdata</em>. Each row of the
input maps is processed in sequence so that the entire maps are not stored in
memory. The function works by opening all the input and reads one line (row)
at a time from each. The output file(s) are created one line at time as the
input maps are processed.
</p>
<p>Use <code>AsciiGridImpute</code> for objects builds with <code><a href="#topic+yai">yai</a></code>,
otherwise use <code>AsciiGridPredict</code>. When <code>AsciiGridPredict</code> is
used, the following rules apply. First, when <code>myPredFunc</code> is not
null it is called with the arguments <code>object, newdata, ...</code> where the
new data is the data frame built from the input maps, otherwise the
generic <code><a href="stats.html#topic+predict">predict</a></code> function is called with these same arguments.
When <code>object</code> and <code>myPredFunc</code> are both NULL a copy
<code>newdata</code> used as the prediction. This is useful when <code>lat, lon, rows,</code>
or <code>cols</code> are used in to subset the maps.
</p>
<p>The <code>NODATA_VALUE</code> is output for every <code>NODATA_VALUE</code> found on any
grid cell on any one of the input maps (the predict function is not called for
these grid cells). <code>NODATA_VALUE</code> is also output for any grid cell where
the predict function returns an <code>NA</code>. 
</p>
<p>If factors are used as X-variables in
<code>object</code>, the levels found the map data are checked against those used in
building the <code>object</code>. If new levels are found, the corresponding output
map grid point is set to <code>NODATA_VALUE</code>; the predict function is not called
for these cells as most predict functions will fail in these circumstances.
Checking on factors depends on <code>object</code> containing a meaningful member
named <code>xlevels</code>, as done for objects produced by <code><a href="stats.html#topic+lm">lm</a></code>.
</p>
<p>Asciigrid maps do not contain character data, only numbers. The numbers in the
maps are matched the <code>xlevels</code> by subscript (the first entry in a level corresponds
to the numeric value 1 in the Asciigrid maps, the second to the number 2 and so
on). Care must be taken by the user to insure that the coding scheme used in
building the maps is identical to that used in building the <code>object</code>. See Value for
information on how you can check the matching of these codes.
</p>


<h3>Value</h3>

<p>An <code><a href="base.html#topic+invisible">invisible</a></code> list containing the following named elements:
</p>
<table>
<tr><td><code>unexpectedNAs</code></td>
<td>
<p>A data frame listing the map row numbers and the number
of <code>NA</code> values generated by the predict function for each row. If none
are generated for a row the row is not reported, if none are generated for any rows,
the data frame is NULL.</p>
</td></tr>
<tr><td><code>illegalLevels</code></td>
<td>
<p>A data frame listing levels found in the maps that
were not found in the <code>xlevels</code> for the <code>object</code>. The row names
are the illegal levels, the column names are the variable names, and the
values are the number of grid cells where the illegal levels were found.</p>
</td></tr>
<tr><td><code>outputLegend</code></td>
<td>
<p>A data frame showing the relationship between levels in
the output maps and those found in <code>object</code>. The row names are
level index values, the column names are variable names, and the values
are the levels. NULL if no factors are output.</p>
</td></tr>
<tr><td><code>inputLegend</code></td>
<td>
<p>A data frame showing the relationship between levels found in
the input maps and those found in <code>object</code>. The row names are
level index values (this function assumes they correspond to numeric values
on the maps), the column names are variable names, and the values
are the levels. NULL if no factors are input. This information is consistent with
that in <code>xlevels</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+impute">impute</a></code>, and <code><a href="#topic+newtargets">newtargets</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## These commands write new files to your working directory

# Use the iris data
data(iris)

# Section 1: Imagine that the iris are planted in a planting bed.
# The following set of commands create Asciigrid map
# files for four attributes to illustrate the planting layout.

# Change species from a character factor to numeric (the sp classes
# can not handle character data).

sLen &lt;- matrix(iris[,1],10,15)
sWid &lt;- matrix(iris[,2],10,15)
pLen &lt;- matrix(iris[,3],10,15)
pWid &lt;- matrix(iris[,4],10,15)
spcd &lt;- matrix(as.numeric(iris[,5]),10,15)

# Create and change to a temp directory. You can delete these steps
# if you wish to keep the files in your working directory.
curdir &lt;- getwd()
setwd(tempdir())
cat ("Using working dir",getwd(),"\n")

# Make maps of each variable.
header = c("NCOLS 15","NROWS 10","XLLCORNER 1","YLLCORNER 1",
           "CELLSIZE 1","NODATA_VALUE -9999")
cat(file="slen.txt",header,sep="\n")
cat(file="swid.txt",header,sep="\n")
cat(file="plen.txt",header,sep="\n")
cat(file="pwid.txt",header,sep="\n")
cat(file="spcd.txt",header,sep="\n")


write.table(sLen,file="slen.txt",append=TRUE,col.names=FALSE,
            row.names=FALSE)
write.table(sWid,file="swid.txt",append=TRUE,col.names=FALSE,
            row.names=FALSE)
write.table(pLen,file="plen.txt",append=TRUE,col.names=FALSE,
            row.names=FALSE)
write.table(pWid,file="pwid.txt",append=TRUE,col.names=FALSE,
            row.names=FALSE)
write.table(spcd,file="spcd.txt",append=TRUE,col.names=FALSE,
            row.names=FALSE)

# Section 2: Create functions to predict species

# set the random number seed so that example results are consistant
# normally, leave out this command
set.seed(12345)

# sample the data
refs &lt;- sample(rownames(iris),50)
y &lt;- data.frame(Species=iris[refs,5],row.names=rownames(iris[refs,]))

# build a yai imputation for the reference data.
rfNN &lt;- yai(x=iris[refs,1:4],y=y,method="randomForest")

# make lists of input and output map files.

xfiles &lt;- list(Sepal.Length="slen.txt",Sepal.Width="swid.txt",
               Petal.Length="plen.txt",Petal.Width="pwid.txt")
outfiles1 &lt;- list(distance="dist.txt",Species="spOutrfNN.txt",
                  useid="useindx.txt")

# map the imputation-based predictions for the input maps
AsciiGridImpute(rfNN,xfiles,outfiles1,ancillaryData=iris)
# read the asciigrids and get them ready to plot
spOrig &lt;- t(as.matrix(read.table("spcd.txt",skip=6)))
sprfNN &lt;- t(as.matrix(read.table("spOutrfNN.txt",skip=6)))
dist &lt;- t(as.matrix(read.table("dist.txt",skip=6)))

# demonstrate the use of useid:
spViaUse &lt;- read.table("useindx.txt",skip=6)
for (col in colnames(spViaUse)) spViaUse[,col]=as.character(y$Species[spViaUse[,col]])

# demonstrate how to use factors:
spViaLevels  &lt;- read.table("spOutrfNN.txt",skip=6)
for (col in colnames(spViaLevels)) spViaLevels[,col]=levels(y$Species)[spViaLevels[,col]]

identical(spViaLevels,spViaUse)

if (require(randomForest))
{
  # build a randomForest predictor
  rf &lt;- randomForest(x=iris[refs,1:4],y=iris[refs,5])
  AsciiGridPredict(rf,xfiles,list(predict="spOutrf.txt"))
  sprf &lt;- t(as.matrix(read.table("spOutrf.txt",skip=6)))
} else sprf &lt;- NULL

# reset the directory to that where the example was started.
setwd(curdir)

par(mfcol=c(2,2),mar=c(1,1,2,1))
image(spOrig,main="Original",col=c("red","green","blue"),
      axes=FALSE,useRaster=TRUE)
image(sprfNN,main="Using Impute",col=c("red","green","blue"),
      axes=FALSE,useRaster=TRUE)
if (!is.null(sprf))
  image(sprf,main="Using Predict",col=c("red","green","blue"),
      axes=FALSE,useRaster=TRUE)
image(dist,main="Neighbor Distances",col=terrain.colors(15),
      axes=FALSE,useRaster=TRUE)

</code></pre>

<hr>
<h2 id='bestVars'>Computes the number of <em>best</em> X-variables</h2><span id='topic+bestVars'></span>

<h3>Description</h3>

<p>The number of <em>best</em> variables is estimated by finding an 
apparent inflection point in the relationship between the 
generalized root mean square distance (see <code><a href="#topic+grmsd">grmsd</a></code> and the number
of <em>X</em>-variables. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bestVars(obj,nbest=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bestVars_+3A_obj">obj</code></td>
<td>
<p>an object create by <code><a href="#topic+varSelection">varSelection</a></code></p>
</td></tr>
<tr><td><code id="bestVars_+3A_nbest">nbest</code></td>
<td>
<p>number of variables designated as the best;
if null the number is estimated</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An character vector of variable names in decreasing order of importance.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varSelection">varSelection</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)
set.seed(12345)

x &lt;- iris[,1:2]  # Sepal.Length Sepal.Width 
y &lt;- iris[,3:4]  # Petal.Length Petal.Width 

vsel &lt;- varSelection(x=x,y=y,nboot=5,useParallel=FALSE)

bestVars(vsel)

</code></pre>

<hr>
<h2 id='buildConsensus'>Finds the consensus imputations among a list of yai objects</h2><span id='topic+buildConsensus'></span>

<h3>Description</h3>

<p>Several objects of class <code><a href="#topic+yai">yai</a></code> are combined into a new
object forming a consensus among the many. The intention is that the many would
be formed by running yai several times with <code>bootstrap=TRUE</code> or by varying
other options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>buildConsensus(reps, noTrgs=FALSE, noRefs=FALSE, k=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="buildConsensus_+3A_reps">reps</code></td>
<td>
<p>a list of objects class <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="buildConsensus_+3A_notrgs">noTrgs</code></td>
<td>
<p>If <code>TRUE</code> neighbor relationships for target observations are not merged.</p>
</td></tr>
<tr><td><code id="buildConsensus_+3A_norefs">noRefs</code></td>
<td>
<p>If <code>TRUE</code> neighbor relationships for reference observations are not merged.</p>
</td></tr>
<tr><td><code id="buildConsensus_+3A_k">k</code></td>
<td>
<p>If not specified, the minimum value of <code>k</code> among the objects is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+yai">yai</a></code>
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
John Coulston <a href="mailto:jcoulston@fs.fed.us">jcoulston@fs.fed.us</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require (yaImpute)
data(iris)

set.seed(123) 

# form some test data, y's are defined only for reference
# observations.
refs=sample(rownames(iris),50)
x &lt;- iris[,1:2]      # Sepal.Length Sepal.Width
y &lt;- iris[refs,3:4]  # Petal.Length Petal.Width

reps &lt;- replicate(20, yai(x=x,y=y,method="msn",bootstrap=TRUE,k=2),
                  simplify=FALSE)

buildConsensus(reps)

</code></pre>

<hr>
<h2 id='compare.yai'>Compares different k-NN solutions</h2><span id='topic+compare.yai'></span>

<h3>Description</h3>

<p>Provides a convenient display of the root mean square differences
(see <code><a href="#topic+rmsd.yai">rmsd.yai</a></code>) or correlations (see <code><a href="#topic+cor.yai">cor.yai</a></code>) between observed and
imputed values for each of several imputations. Each column of the returned
data frame corresponds to an imputation result and each row corresponds to a
variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare.yai(...,ancillaryData=NULL,vars=NULL,method="rmsd",scale=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare.yai_+3A_...">...</code></td>
<td>
<p>a list of objects created by <code><a href="#topic+yai">yai</a></code> or <code><a href="#topic+impute.yai">impute.yai</a></code>
that you wish to compare.</p>
</td></tr>
<tr><td><code id="compare.yai_+3A_ancillarydata">ancillaryData</code></td>
<td>
<p>a data frame that defines new variables, passed to <code><a href="#topic+impute.yai">impute.yai</a></code>.</p>
</td></tr>
<tr><td><code id="compare.yai_+3A_vars">vars</code></td>
<td>
<p>a list of variable names you want to include; if NULL all available
variables are included.</p>
</td></tr>
<tr><td><code id="compare.yai_+3A_method">method</code></td>
<td>
<p>when <em>rmsd</em> is specified, the comparison is based on root mean
square differences between observed an imputed, and <br />
when <em>cor</em> is specified, the comparison is based on correlations between
observed and imputed.</p>
</td></tr>
<tr><td><code id="compare.yai_+3A_scale">scale</code></td>
<td>
<p>passed to <code><a href="#topic+rmsd.yai">rmsd.yai</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame of class <code>c("compare.yai","data.frame")</code>, where the columns
are the names of the ...-arguments and the rows are a union of
variable names. NA's are returned when the variables are factors. The scale values (if used)
are returned as an attribute (all if some are different than others, a warning is issued).
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+plot.compare.yai">plot.compare.yai</a></code>,
<code><a href="#topic+impute.yai">impute.yai</a></code>, <code><a href="#topic+rmsd.yai">rmsd.yai</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:2]      # Sepal.Length Sepal.Width
y &lt;- iris[refs,3:4]  # Petal.Length Petal.Width

# build yai objects using 2 methods
msn &lt;- yai(x=x,y=y)
mal &lt;- yai(x=x,y=y,method="mahalanobis")

# compare the y variables
compare.yai(msn,mal)

# compare the all variables in iris
compare.yai(msn,mal,ancillaryData=iris)  # Species is a factor, no comparison is made
</code></pre>

<hr>
<h2 id='cor.yai'>Correlation between observed and imputed</h2><span id='topic+cor.yai'></span>

<h3>Description</h3>

<p>Computes the correlation between observed and imputed values
for each observation that has both.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.yai (object,vars=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor.yai_+3A_object">object</code></td>
<td>
<p>an object created by <code><a href="#topic+yai">yai</a></code> or <code><a href="#topic+impute.yai">impute.yai</a></code>.</p>
</td></tr>
<tr><td><code id="cor.yai_+3A_vars">vars</code></td>
<td>
<p>a list of variables names you want to include, if NULL all available
variables are included.</p>
</td></tr>
<tr><td><code id="cor.yai_+3A_...">...</code></td>
<td>
<p>passed to called methods (not currently used)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The correlations are computed using <code><a href="#topic+cor.yai">cor.yai</a></code>. For data imputation, such
correlations are likely not appropriate (Stage and Crookston 2007).
</p>


<h3>Value</h3>

<p>A data frame with the row names as vars and the column as <code>cor</code>.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>References</h3>

<p>Stage, A.R.; Crookston, N.L. (2007). Partitioning error components
for accuracy-assessment of near neighbor methods of imputation.
<em>For. Sci.</em> 53(1):62-72.
<a href="https://academic.oup.com/forestscience/article/53/1/62/4604364">https://academic.oup.com/forestscience/article/53/1/62/4604364</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+impute.yai">impute.yai</a></code>, <code><a href="#topic+rmsd.yai">rmsd.yai</a></code></p>

<hr>
<h2 id='correctBias'>Correct bias by selecting different near neighbors</h2><span id='topic+correctBias'></span>

<h3>Description</h3>

<p>Change the neighbor selections in a <code><a href="#topic+yai">yai</a></code> object such that 
bias (if any) in the average value of an <em>expression</em> 
of one or more variables is reduced to be within a defined 
confidence interval. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correctBias(object,trgVal,trgValCI=NULL,nStdev=1.5,excludeRefIds=NULL,trace=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correctBias_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code> with <code>k &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="correctBias_+3A_trgval">trgVal</code></td>
<td>
<p>an <code><a href="base.html#topic+expression">expression</a></code> defining a variable or combination of
variables that is applied to each member of the population (see details). If 
passed as a character string it is coerced into an expression. The expression can 
refer to one or more X- and Y-variables defined for the reference observations.</p>
</td></tr> 
<tr><td><code id="correctBias_+3A_trgvalci">trgValCI</code></td>
<td>
<p>The confidence interval that should contain the <code>mean(trgVal)</code>.
If the mean falls within this interval, the problem is solved. If <code>NULL</code>, the
interval is based on <code>nStdev</code>.</p>
</td></tr>
<tr><td><code id="correctBias_+3A_nstdev">nStdev</code></td>
<td>
<p>the number of standard deviations in the vector of values used to 
compute the confidence interval when one is computed, ignored if <code>trgValCI</code> 
is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="correctBias_+3A_excluderefids">excludeRefIds</code></td>
<td>
<p>identities of reference observations to exclude from the 
population, if coded as &quot;all&quot; then all references are excluded (see details).</p>
</td></tr>
<tr><td><code id="correctBias_+3A_trace">trace</code></td>
<td>
<p>if <code>TRUE</code>, detailed output is produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Imputation as it is defined in <code>yaImpute</code> can yield biased
results. Lets say that you have a collection of reference
observations that happen to be selected in a non-biased way among a
population. In this discussion, <em>population</em> is a finite set of all
individual sample units of interest; the reference plus target observations
often represent this population (but this need not be true, see below). 
If the average of a measured attribute is computed from
this random sample, it is an unbiased estimate of the true mean. 
<br /><br />  
Using <code><a href="#topic+yai">yai</a></code>, while setting <em>k=1</em>, values for each of several
attributes are imputed from a single reference observation to a target
observation. Once the imputation is done over all the target observations, an
average of any one measured attribute can be computed over all the observations 
in the population. There is no guarantee that this average will be within a 
pre-specified confidence interval.
<br /><br />
Experience shows that despite any lack of guarantee, the results are accurate 
(not biased). This tends to hold true when the reference data contains
samples that cover the variation of the targets, even when they are not a
random sample, and even if some of the reference observations are from sample
units that are outside the target population. 
<br /><br />
Because there is no guarantee, and because the reference observations might
profitably come from sample units beyond those in the population 
(so as to insure all kinds of targets have a matching reference), it is necessary 
to test the imputation results for bias. If bias is found, it would be helpful to 
do something to correct it.
<br /><br />
The <code>correctBias()</code> function is designed to check for, and correct
discovered bias by selecting alternative nearby reference observations 
to be imputed to targets that contribute to the bias. The idea is that even if
one reference is closest to a target, its attribute(s) of interest might 
be greater (or less) than the mean. An alternative neighbor, one that may be
almost as close, might reduce the overall bias if it were used instead. If this is
the case, <code>correctBias()</code> switches the neighbor selections. 
It makes as many switches as it can until the mean among the population 
targets falls within the specified confidence interval. 
There is no guarantee that the goal will be met.
<br /><br />
The details of the method are: 
<br /><br />
1. An attribute of interest is established by naming one in the call with
argument <code>tarVal</code>. Note that this can be a simple variable name enclosed
in quotations marks or it can be an <code><a href="base.html#topic+expression">expression</a></code> of one or more variables. 
If the former, it is converted into an expression that is executed in the 
environment of the <code>reference</code> observations (both the X- and Y-variables). 
A confidence interval is computed for this value under the assumption that the 
reference observations are an unbiased sample of the target population. This may 
not be the case. Regardless, a confidence interval is <em>necessary</em> and it can
alternatively be supplied using <code>trgValCI</code>. 
<br /><br />
2. One of several possible passes through the data are taken to find neighbor switches
that will result in the bias being corrected. A pass includes computing the
attribute of interest by applying the <code>expression</code> to values imputed to all 
the targets, under the assumption that the next neighbor is used 
in place of the currently used neighbor. This computation results in a 
vector with one element for each target observation that 
measures the contribution toward reducing the bias that would be made if 
a switch were made. The target observations are then ordered 
into increasing order of how much the distance from the currently selected 
reference would increase if the switch were to take place. Enough switches are 
made in this order to correct the bias. 
If the bias is not corrected by the first pass, another pass is done 
using the next neighbor(s).
The number of possible passes is equal to <em>k-1</em> where <em>k</em> is
set in the original call to <code><a href="#topic+yai">yai</a></code>. Note that switches are made
among targets only, and never among reference observations that may make up the
population. That is, reference observations are always left 
to represent themselves with <code>k=1</code>.   
<br /><br />
3. Here are details of the argument <code>excludeRefIds</code>. When computing the mean
of the attribute of interest (using the <code>expression</code>), 
<code>correctBias()</code> must know which observations represent the
population. Normally, all the target observations would be in this set, but perhaps
not all of the reference observations. When <code>excludeRefIds</code> 
is left NULL, the population is made of all reference and all
target observations. Reference observations that should be left out
of the calculations because they are not part of the population can be specified
using the <code>excludeRefIds</code> argument as a vector of character strings identifying 
the rownames to leave out, or a vector of row numbers that identify the row numbers to 
leave out. If <code>excludeRefIds="all"</code>, all reference observations are excluded.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+yai">yai</a></code> where <code>k = 1</code> and the neighbor selections
have been changed as described above. In addition, the <code>call</code> element is changed
to show both the original call to <code><a href="#topic+yai">yai</a></code> and the call to this function. 
A new list called <code>biasParameters</code> is added to the <code><a href="#topic+yai">yai</a></code> object  
with these tags:
</p>
<table>
<tr><td><code>trgValCI</code></td>
<td>
<p>the target CI.</p>
</td></tr>
<tr><td><code>curVal</code></td>
<td>
<p>the value of the bias that was achieved.</p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>the number of passes through the data taken to achieve the result.</p>
</td></tr>
<tr><td><code>oldk</code></td>
<td>
<p>the old value of <code>k</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

set.seed(12345)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

# build an msn run, first build dummy variables for species.

sp1 &lt;- as.integer(iris$Species=="setosa")
sp2 &lt;- as.integer(iris$Species=="versicolor")
y2 &lt;- data.frame(cbind(iris[,4],sp1,sp2),row.names=rownames(iris))
y2 &lt;- y2[refs,]

names(y2) &lt;- c("Petal.Width","Sp1","Sp2")

# find 5 refernece neighbors for each target
msn &lt;- yai(x=x,y=y2,method="msn",k=5)

# check for and correct for bias in mean "Petal.Width". Neighbor  
# selections will be changed as needed to bring the imputed values 
# into line with the CI. In this case, no changes are made (npasses 
# returns as zero).

msnCorr = correctBias(msn,trgVal="Petal.Width")
msnCorr$biasParameters

</code></pre>

<hr>
<h2 id='ensembleImpute'>Computes the mean, median, or mode among a list of impute.yai objects</h2><span id='topic+ensembleImpute'></span>

<h3>Description</h3>

<p>Several objects of class <code><a href="#topic+impute.yai">impute.yai</a></code> or <code><a href="#topic+yai">yai</a></code> 
are combined by computing the mean, median, or mode of separate, individual imputations.
The intention is that the members of the first argument would be formed by running 
yai several times with <code>bootstrap=TRUE</code> or by varying other options. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ensembleImpute(imputes, method="mean",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ensembleImpute_+3A_imputes">imputes</code></td>
<td>
<p>a list of objects class <code><a href="#topic+impute.yai">impute.yai</a></code> or <code><a href="#topic+yai">yai</a></code>. 
Function <code><a href="#topic+impute.yai">impute.yai</a></code> is called for list members where the class is yai.</p>
</td></tr>
<tr><td><code id="ensembleImpute_+3A_method">method</code></td>
<td>
<p>when &quot;mean&quot;, the continuous variables are averaged using <code>mean</code>,
otherwise the <code>median</code> is used. Mode is always used for character data 
(generally the case for factors).</p>
</td></tr>
<tr><td><code id="ensembleImpute_+3A_...">...</code></td>
<td>
<p>passed to <code><a href="#topic+impute.yai">impute.yai</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>c("impute.yai","data.frame")</code>, see <code><a href="#topic+impute.yai">impute.yai</a></code>.
The attributes of the data.frame include the following:
</p>

<ol>
<li><p> sd - A data.frame of standard deviations for continuous variables
if there are any. The columns are not reported if the standard deviation is
zero for all observations which is typically true of &quot;observed&quot; values. 
</p>
</li>
<li><p> N - the number of replications used to compute the corresponding data; 
reported only if the number differs from the total number of replications. This 
will be the case when <code>bootstrap</code>, <code>sampleVar</code>, or both are used in 
<code><a href="#topic+yai">yai</a></code>.
</p>
</li>
<li><p> methods - the method used for each variable.
</p>
</li></ol>
   


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
John Coulston <a href="mailto:jcoulston@fs.fed.us">jcoulston@fs.fed.us</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code> <code><a href="#topic+buildConsensus">buildConsensus</a></code> <code><a href="#topic+impute.yai">impute.yai</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require (yaImpute)
data(iris)

set.seed(123) 

# form some test data, y's are defined only for reference
# observations.
refs=sample(rownames(iris),50)
x &lt;- iris[,1:2]      # Sepal.Length Sepal.Width
y &lt;- iris[refs,3:4]  # Petal.Length Petal.Width

reps &lt;- replicate(10, yai(x=x,y=y,method="msn",bootstrap=TRUE,k=2),
                  simplify=FALSE)

ensembleImpute(reps,ancillaryData=iris)

</code></pre>

<hr>
<h2 id='errorStats'>Compute error components of k-NN imputations</h2><span id='topic+errorStats'></span>

<h3>Description</h3>

<p>Error properties of estimates derived from imputation differ from those of regression-based
estimates because the two methods include a different mix of error components. This function
computes a partitioning of error statistics as proposed by Stage and Crookston (2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorStats(mahal,...,scale=FALSE,pzero=0.1,plg=0.5,seeMethod="lm")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="errorStats_+3A_mahal">mahal</code></td>
<td>
<p>An object of class <code><a href="#topic+yai">yai</a></code> computed with <code>method="mahalanobis"</code>.</p>
</td></tr>
<tr><td><code id="errorStats_+3A_...">...</code></td>
<td>
<p>Other objects of class <code><a href="#topic+yai">yai</a></code> for which statistics are desired. All
objects should be for the same data and variables used for the first argument.</p>
</td></tr>
<tr><td><code id="errorStats_+3A_scale">scale</code></td>
<td>
<p>When <code>TRUE</code>, the errors are scaled by their respective standard deviations.</p>
</td></tr>
<tr><td><code id="errorStats_+3A_pzero">pzero</code></td>
<td>
<p>The lower tail p-value used to pick <em>reference</em> observations that are zero
distance from each other (used to compute <code>rmmsd0</code>).</p>
</td></tr>
<tr><td><code id="errorStats_+3A_plg">plg</code></td>
<td>
<p>The upper tail p-value used to pick <em>reference</em> observations that are
substantially distant from each other (used to compute <code>rmsdlg</code>).</p>
</td></tr>
<tr><td><code id="errorStats_+3A_seemethod">seeMethod</code></td>
<td>
<p>Method used to compute <code>SEE</code>: <code>seeMethod="lm"</code> uses <code><a href="stats.html#topic+lm">lm</a></code>
and <code>seeMethod="gam"</code> uses <code><a href="gam.html#topic+gam">gam</a></code>. In both cases, the model formula is
a simple linear combination of the X-variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://academic.oup.com/forestscience/article/53/1/62/4604364">https://academic.oup.com/forestscience/article/53/1/62/4604364</a>
</p>


<h3>Value</h3>

<p>A list that contains several data frames. The column names of each are a combination
of the name of the object used to compute the statistics and the name of the statistic. The
rownames correspond the the Y-variables from the first argument. The data frame names are as follows:
</p>
<table>
<tr><td><code>common</code></td>
<td>
<p>statistics used to compute other statistics.</p>
</td></tr>
<tr><td><code>name of first argument</code></td>
<td>
<p>error statistics for the first <code><a href="#topic+yai">yai</a></code> object.</p>
</td></tr>
<tr><td><code>names of ... arguments</code></td>
<td>
<p>error statistics for each of the remaining <code><a href="#topic+yai">yai</a></code> objects,
if any.</p>
</td></tr>
<tr><td><code>see</code></td>
<td>
<p>standard error of estimate for individual regressions fit for
corresponding Y-variables.</p>
</td></tr>
<tr><td><code>rmmsd0</code></td>
<td>
<p>root mean square difference for imputations based on <code>method="mahalanobis"</code>
(always based on the first argument to the function).</p>
</td></tr>
<tr><td><code>mlf</code></td>
<td>
<p>square root of the model lack of fit: <code class="reqn">sqrt(see^2 - (rmmsd0^2/2))</code>.</p>
</td></tr>
<tr><td><code>rmsd</code></td>
<td>
<p>root mean square error.</p>
</td></tr>
<tr><td><code>rmsdlg</code></td>
<td>
<p>root mean square error of the observations with larger distances.</p>
</td></tr>
<tr><td><code>sei</code></td>
<td>
<p>standard error of imputation <code class="reqn">sqrt(rmsd^2 - (rmmsd0^2/2))</code>.</p>
</td></tr>
<tr><td><code>dstc</code></td>
<td>
<p>distance component: <code class="reqn">sqrt(rmsd^2 - rmmsd0^2)</code>.</p>
</td></tr>
</table>
<p>Note that unlike Stage and Crookston (2007), all statistics reported here are in the natural
units, not squared units.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Albert R. Stage
</p>


<h3>References</h3>

<p>Stage, A.R.; Crookston, N.L. (2007). Partitioning error components
for accuracy-assessment of near neighbor methods of imputation.
<em>For. Sci.</em> 53(1):62-72.
<a href="https://academic.oup.com/forestscience/article/53/1/62/4604364">https://academic.oup.com/forestscience/article/53/1/62/4604364</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+TallyLake">TallyLake</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require (yaImpute)

data(TallyLake)

diag(cov(TallyLake[,1:8])) # see col A in Table 3 in Stage and Crookston

mal=yai(x=TallyLake[,9:29],y=TallyLake[,1:8],
        noTrgs=TRUE,method="mahalanobis")


msn=yai(x=TallyLake[,9:29],y=TallyLake[,1:8],
        noTrgs=TRUE,method="msn")


# variable "see" for "mal" matches col B (when squared and scaled)
# other columns don't match exactly as Stage and Crookston used different
# software to compute values

errorStats(mal,msn)

</code></pre>

<hr>
<h2 id='foruse'>Report a complete imputation</h2><span id='topic+foruse'></span>

<h3>Description</h3>

<p>Provides a matrix of all observations with the reference observation
identification best used to represent it, followed by the distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>foruse(object,kth=NULL,method="kth",targetsOnly=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="foruse_+3A_object">object</code></td>
<td>
<p>an object created by <code><a href="#topic+yai">yai</a></code></p>
</td></tr>
<tr><td><code id="foruse_+3A_kth">kth</code></td>
<td>
<p>when <code>NULL</code> (and <code>method="kth"</code>),
the best pick is reported (a reference observation represents itself),
otherwise the kth neighbor is picked.</p>
</td></tr>
<tr><td><code id="foruse_+3A_method">method</code></td>
<td>
<p>the method used to select references to represent observations,
as follows: <br />
<code>kth</code>: the <em>kth</em> nearest neighbor is picked; <br />
<code>random</code>: for each observation, the value of <em>kth</em> is selected at
random from the 1 to <code>k</code> neighbors (1 to <code>kth</code> if is <code>kth</code>
specified); <br />
<code>randomWeighted</code>: <code>1/(1+d)</code> is used as a probability weight factor
in selecting the value of <em>kth</em>, where d is the distance..</p>
</td></tr>
<tr><td><code id="foruse_+3A_targetsonly">targetsOnly</code></td>
<td>
<p>when is TRUE, reporting of references is not done.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)

# form some test data
set.seed(1234)
refs=sample(rownames(iris),50)
x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

# build a yai object using mahalanobis
mal &lt;- yai(x=x,y=y,method="mahalanobis",k=3)

foruse(mal)  # for references, use is equal to the rowname
foruse(mal,kth=1) # for references, use is an row to the kth reference.

# get all the choices:
cbind(foruse(mal),foruse(mal,kth=1),foruse(mal,kth=2),foruse(mal,kth=3))

</code></pre>

<hr>
<h2 id='grmsd'>Generalized Root Mean Square Distance Between Observed and Imputed Values</h2><span id='topic+grmsd'></span>

<h3>Description</h3>

<p>Computes the root mean square distance between predicted and corresponding
observed values in an orthogonal multivariate space. This value is the mean
Mahalanobis distance between observed and imputed values in a space defined by
observations and variables were observed and predicted values are defined. 
The statistic provides a way to compare imputation (or prediction) results. 
While it is designed to work with imputation, the function can be used with objects 
that inherit from <code><a href="stats.html#topic+lm">lm</a></code> or with matrices and data frames that 
follow the column naming convention described in the details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grmsd(...,ancillaryData=NULL,vars=NULL,wts=NULL,rtnVectors=FALSE,imputeMethod="closest")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grmsd_+3A_...">...</code></td>
<td>
<p>objects created by any combination of
<code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+impute.yai">impute.yai</a></code>, <code><a href="#topic+ensembleImpute">ensembleImpute</a></code>,
<code><a href="#topic+buildConsensus">buildConsensus</a></code>, <code><a href="stats.html#topic+lm">lm</a></code> and data frames or matrices
that follow the column naming convention described in the details below. 
If an object is of class <code><a href="#topic+yai">yai</a></code>, a call to 
<code><a href="#topic+impute.yai">impute.yai</a></code> is generated internally.</p>
</td></tr>
<tr><td><code id="grmsd_+3A_ancillarydata">ancillaryData</code></td>
<td>
<p>a data frame that defines variables, passed to 
<code><a href="#topic+impute.yai">impute.yai</a></code>.</p>
</td></tr>
<tr><td><code id="grmsd_+3A_vars">vars</code></td>
<td>
<p>a list of variable names you want to include; if NULL all available
variables are included (note that if impute.yai the 
<em>Y</em>-variables are returned when <code>vars=NULL</code>).</p>
</td></tr>
<tr><td><code id="grmsd_+3A_wts">wts</code></td>
<td>
<p>A vector of weights used to compute the mean distances, see 
details below.</p>
</td></tr>
<tr><td><code id="grmsd_+3A_rtnvectors">rtnVectors</code></td>
<td>
<p>The vectors of individual distances are returned (see Value) 
rather than the mean Mahalanobis distance.</p>
</td></tr> 
<tr><td><code id="grmsd_+3A_imputemethod">imputeMethod</code></td>
<td>
<p>passed as <code>method</code> to <code><a href="#topic+impute.yai">impute.yai</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>This function is designed to compute the root mean square distance between observed
and predicted observations over several variables at once. It is the Mahalanobis 
distance between observed and predicted but the name emphasizes the similarities 
to root mean square difference (or error, see <code><a href="#topic+rmsd">rmsd</a></code>). 
Here are some notable characteristics.
</p>

<ol>
<li><p>In the univariate case this function returns the same value as 
<code><a href="#topic+rmsd">rmsd</a></code> with <code>scale=TRUE</code>. In that case
the root mean square difference is computed after <code><a href="base.html#topic+scale">scale</a></code>
has been called on the variable.
</p>
</li>
<li><p>Like <code><a href="#topic+rmsd">rmsd</a></code>, <code>grmsd</code> is zero if the imputed values are
exactly the same as the observed values over all variables.
</p>
</li>
<li><p>Like <code><a href="#topic+rmsd">rmsd</a></code>, <code>grmsd</code> is ~1.0 when the mean of each 
variable is imputed in place of a near neighbor (it would be exactly 1.0 if 
the maximum likelihood estimate of the covariance were used rather than
the unbiased estimate &ndash; it approaches 1 as <em>n</em> gets large.) 
This situation corresponds to regression where the slope is zero. 
It indicates that the imputation error is, over all, the same as it 
would be if the means of the variables were imputed rather than near 
neighbors (it does not signal that the means were imputed). 
</p>
</li>
<li><p>Like <code><a href="#topic+rmsd">rmsd</a></code>, values of grmsd &gt; 1.0 indicate that, on average,
the errors in the imputation are greater than they would be if the mean
of the corresponding variables were imputed for each observation. 
</p>
</li>
<li><p>Note that individual <code><a href="#topic+rmsd">rmsd</a></code> values can be computed even when 
the variance of the variable is zero. In contrast, <code>grmsd</code> can 
only be computed in the situation where the observed data matrix is full rank.
Rank is determined using <code><a href="Matrix.html#topic+qr">qr</a></code> and columns are removed from the 
analysis to create this condition if necessary (with a warning). 
</p>
</li></ol>

<p>Observed and predicted are matched using the column names. Column names
that have &quot;<code>.o</code>&quot; are matched to those that do not. Columns that do not
have matching observed and imputed (predicted) values are ignored. 
</p>
<p>Several objects may be passed as &quot;...&quot;. Function <code><a href="#topic+impute.yai">impute.yai</a></code> is
called for any objects that were created by <code><a href="#topic+yai">yai</a></code>;
<code>ancillaryData</code> and <code>vars</code> are passed to <code><a href="#topic+impute.yai">impute.yai</a></code>
when it is used.
</p>
<p>When objects inherit from <code><a href="stats.html#topic+lm">lm</a></code>, a suitable matrix is formed using
by calling the <code><a href="stats.html#topic+predict">predict</a></code> and <code><a href="stats.html#topic+resid">resid</a></code> functions.
</p>
<p>Factors, if found, are removed (with a warning).
</p>
<p>When argument <code>wts</code> is defined there must be one value for each pair of
observed and predicted variables. If the values are named (preferred), then
the names are matched to the names of predicted variables (no <code>.o</code> suffix).
The matched values effectively scale the axes in which distances are computed. 
When this is done, the resulting distances are not Mahalanobis distances.
</p>


<h3>Value</h3>

<p>When <code>rtnVectors=FALSE</code>, a sorted named vector of mean distances 
is returned; the names are taken from the arguments.
</p>
<p>When <code>rtnVectors=TRUE</code> the function returns vectors of distances, sorted and
named as done wnen this argument is FALSE.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+impute.yai">impute.yai</a></code>, <code><a href="#topic+rmsd.yai">rmsd.yai</a></code>, 
<code><a href="#topic+notablyDifferent">notablyDifferent</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)
set.seed(12345)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:2]      # Sepal.Length Sepal.Width
y &lt;- iris[refs,3:4]  # Petal.Length Petal.Width

# build yai objects using 2 methods
msn &lt;- yai(x=x,y=y)
mal &lt;- yai(x=x,y=y,method="mahalanobis")

# compute the average distances between observed and imputed (predicted)
grmsd(msn,mal,lmFit=lm(as.matrix(y) ~ ., data=x[refs,]))

# use the all variables and observations in iris
# Species is a factor and is automatically deleted with a warning
grmsd(msn,mal,ancillaryData=iris)

# here is an example using lm, and another using column
# means as predictions.

impMean &lt;- y 
colnames(impMean) &lt;- paste0(colnames(impMean),".o")
impMean &lt;- cbind(impMean,y)
# set the predictions to the mean's of the variables
impMean[,"Petal.Length"] &lt;- mean(impMean[,"Petal.Length"])
impMean[,"Petal.Width"]  &lt;- mean(impMean[,"Petal.Width"])

grmsd(msn, mal, lmFit=lm(as.matrix(y) ~ ., data=x[refs,]), impMean )

# compare to using function rmsd (values match):
msnimp &lt;- na.omit(impute(msn))
grmsd(msnimp[,c("Petal.Length","Petal.Length.o")])   
rmsd(msnimp[,c("Petal.Length","Petal.Length.o")],scale=TRUE)

# these are multivariate cases and they don't match
# because the covariance of the two variables is &gt; 0.
grmsd(msnimp)
colSums(rmsd(msnimp,scale=TRUE))/2

# get the vectors and make a boxplot, identify outliers
stats &lt;- boxplot(grmsd(msn,mal,ancillaryData=iris[,-5],rtnVectors=TRUE),
                 ylab="Mahalanobis distance")
stats$out
#     118      132 
#2.231373 1.990961 
</code></pre>

<hr>
<h2 id='impute.yai'>Impute variables from references to targets</h2><span id='topic+impute.yai'></span><span id='topic+impute'></span>

<h3>Description</h3>

<p>Imputes the observation for variables from a <em>reference</em> observation to a
<em>target</em> observation. Also, imputes a value for a <em>reference</em> from other
<em>references</em>. This practice is useful for validation (see <code><a href="#topic+yai">yai</a></code>). Variables
not available in the original data may be imputed using argument <code>ancillaryData</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'yai'
impute(object,ancillaryData=NULL,method="closest",
       method.factor=method,k=NULL,vars=NULL,
       observed=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute.yai_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="impute.yai_+3A_ancillarydata">ancillaryData</code></td>
<td>
<p>a data frame of variables that may not have been used in
the original call to <code><a href="#topic+yai">yai</a></code>. There must be one row for
each reference observation, no missing data, and row names must match those used
in the reference observations.</p>
</td></tr>
<tr><td><code id="impute.yai_+3A_method">method</code></td>
<td>
<p>the method used to compute the imputed values for continuous variables,
as follows: <br />
<code>closest</code>: use the single neighbor that is closest (this is the default and is
always used when <em>k</em>=1); <br />
<code>mean</code>: the mean of the <em>k</em> neighbors is taken;<br />
<code>median</code>: the median of the <em>k</em> neighbors is taken;<br />
<code>dstWeighted</code>: a weighted mean is taken over the <em>k</em> neighbors where the
weights are 1/(1+d).</p>
</td></tr>
<tr><td><code id="impute.yai_+3A_method.factor">method.factor</code></td>
<td>
<p>the method used to compute the imputed values for factors, as follows: <br />
<code>closest</code>: use the single neighbor that is closest (this is the default and is
always used when <em>k</em>=1); <br />
<code>mean or median</code>: actually is the <em>mode</em>\-\-it is the factor level that occurs
the most often among the <em>k</em> neighbors;<br />
<code>dstWeighted</code>: a <em>mode</em> where the count is the sum of the weights (1/(1+d)) rather than
each having a weight of 1.</p>
</td></tr>
<tr><td><code id="impute.yai_+3A_k">k</code></td>
<td>
<p>the number neighbors to use in averages, when NULL all present are used.</p>
</td></tr>
<tr><td><code id="impute.yai_+3A_vars">vars</code></td>
<td>
<p>a character vector of variables to impute, when NULL, the behavior depends
on the value of <code>ancillaryData</code>: when it is NULL, the Y-variables are imputed and 
otherwise all present in <code>ancillaryData</code> are imputed.</p>
</td></tr>
<tr><td><code id="impute.yai_+3A_observed">observed</code></td>
<td>
<p>when TRUE, columns are created for <em>observed</em> values (those from the
<em>target</em> observations) as well as imputed values (those from the
<em>reference</em> observations.</p>
</td></tr>
<tr><td><code id="impute.yai_+3A_...">...</code></td>
<td>
<p>passed to other methods, currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>c("impute.yai","data.frame")</code>, with rownames
identifying observations and column names identifying variables. When
<em>observed=TRUE</em> additional columns are created with a suffix of
<em>.o</em>. <br /><br /> NA's fill columns of observed values when no
corresponding value is known, as in the case for <em>Y</em>-variables from
<em>target</em> observations.<br /><br /> Scale factors for each variable are
returned as an attribute (see <code><a href="base.html#topic+attributes">attributes</a></code>).
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a> <br />
Emilie Henderson <a href="mailto:emilie.henderson@oregonstate.edu">emilie.henderson@oregonstate.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

# build a yai object using mahalanobis
mal &lt;- yai(x=x,y=y,method="mahalanobis")

# output a data frame of observed and imputed values
# of all variables and observations.

impute(mal)
malImp=impute(mal,ancillaryData=iris)
plot(malImp)

</code></pre>

<hr>
<h2 id='MoscowMtStJoe'>Moscow Mountain and St. Joe Woodlands (Idaho, USA) Tree and LiDAR Data</h2><span id='topic+MoscowMtStJoe'></span>

<h3>Description</h3>

<p>Data used to compare the utility of discrete-return light detection
and ranging (LiDAR) data and multispectral satellite imagery, and their
integration, for modeling and mapping basal area and tree density across
two diverse coniferous forest landscapes in north-central Idaho, USA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MoscowMtStJoe)
</code></pre>


<h3>Format</h3>

<p>A data frame with 165 rows and 64 columns: <br /><br />
Ground based measurements of trees:
</p>

<ul>
<li><p> ABGR_BA - Basal area <code class="reqn">(m^2/ha)</code> of ABGR
</p>
</li>
<li><p> ABLA_BA - Basal area <code class="reqn">(m^2/ha)</code> of ABLA
</p>
</li>
<li><p> ACGL_BA - Basal area <code class="reqn">(m^2/ha)</code> of ACGL
</p>
</li>
<li><p> BEOC_BA - Basal area <code class="reqn">(m^2/ha)</code> of BEOC
</p>
</li>
<li><p> LAOC_BA - Basal area <code class="reqn">(m^2/ha)</code> of LAOC
</p>
</li>
<li><p> PICO_BA - Basal area <code class="reqn">(m^2/ha)</code> of PICO
</p>
</li>
<li><p> PIEN_BA - Basal area <code class="reqn">(m^2/ha)</code> of PIEN
</p>
</li>
<li><p> PIMO_BA - Basal area <code class="reqn">(m^2/ha)</code> of PIMO
</p>
</li>
<li><p> PIPO_BA - Basal area <code class="reqn">(m^2/ha)</code> of PIPO
</p>
</li>
<li><p> POBA_BA - Basal area <code class="reqn">(m^2/ha)</code> of POBA
</p>
</li>
<li><p> POTR_BA - Basal area <code class="reqn">(m^2/ha)</code> of POTR
</p>
</li>
<li><p> PSME_BA - Basal area <code class="reqn">(m^2/ha)</code> of PSME
</p>
</li>
<li><p> SAEX_BA - Basal area <code class="reqn">(m^2/ha)</code> of SAEX
</p>
</li>
<li><p> THPL_BA - Basal area <code class="reqn">(m^2/ha)</code> of THPL
</p>
</li>
<li><p> TSHE_BA - Basal area <code class="reqn">(m^2/ha)</code> of TSHE
</p>
</li>
<li><p> TSME_BA - Basal area <code class="reqn">(m^2/ha)</code> of TSME
</p>
</li>
<li><p> UNKN_BA - Basal area <code class="reqn">(m^2/ha)</code> of unknown species
</p>
</li>
<li><p> Total_B - Basal area <code class="reqn">(m^2/ha)</code> total over all species
</p>
</li>
<li><p> ABGR_TD - Trees per ha of ABGR
</p>
</li>
<li><p> ABLA_TD - Trees per ha of ABLA
</p>
</li>
<li><p> ACGL_TD - Trees per ha of ACGL
</p>
</li>
<li><p> BEOC_TD - Trees per ha of BEOC
</p>
</li>
<li><p> LAOC_TD - Trees per ha of LAOC
</p>
</li>
<li><p> PICO_TD - Trees per ha of PICO
</p>
</li>
<li><p> PIEN_TD - Trees per ha of PIEN
</p>
</li>
<li><p> PIMO_TD - Trees per ha of PIMO
</p>
</li>
<li><p> PIPO_TD - Trees per ha of PIPO
</p>
</li>
<li><p> POBA_TD - Trees per ha of POBA
</p>
</li>
<li><p> POTR_TD - Trees per ha of POTR
</p>
</li>
<li><p> PSME_TD - Trees per ha of PSME
</p>
</li>
<li><p> SAEX_TD - Trees per ha of SAEX
</p>
</li>
<li><p> THPL_TD - Trees per ha of THPL
</p>
</li>
<li><p> TSHE_TD - Trees per ha of TSHE
</p>
</li>
<li><p> TSME_TD - Trees per ha of TSME
</p>
</li>
<li><p> UNKN_TD - Trees per ha of unknown species
</p>
</li>
<li><p> Total_T - Trees per ha total over all species
</p>
</li></ul>
    
<p>Geographic Location, Slope and Aspect:
</p>

<ol>
<li><p> EASTING   - UTM (Zone 11) easting at plot center
</p>
</li>
<li><p> NORTHING  - UTM (Zone 11) northing at plot center
</p>
</li>
<li><p> ELEVATION - Mean elevation (m) above sea level over plot
</p>
</li>
<li><p> SLPMEAN   - Mean slope (percent) over plot
</p>
</li>
<li><p> ASPMEAN   - Mean aspect (degrees) over plot
</p>
</li></ol>

<p>Advanced Land Imager (ALI):
</p>

<ol>
<li><p> B1MEAN - Mean of 30 m ALI band 1 pixels intersecting plot
</p>
</li>
<li><p> B2MEAN - Mean of 30 m ALI band 2 pixels intersecting plot
</p>
</li>
<li><p> B3MEAN - Mean of 30 m ALI band 3 pixels intersecting plot
</p>
</li>
<li><p> B4MEAN - Mean of 30 m ALI band 4 pixels intersecting plot
</p>
</li>
<li><p> B5MEAN - Mean of 30 m ALI band 5 pixels intersecting plot
</p>
</li>
<li><p> B6MEAN - Mean of 30 m ALI band 6 pixels intersecting plot
</p>
</li>
<li><p> B7MEAN - Mean of 30 m ALI band 7 pixels intersecting plot
</p>
</li>
<li><p> B8MEAN - Mean of 30 m ALI band 8 pixels intersecting plot
</p>
</li>
<li><p> B9MEAN - Mean of 30 m ALI band 9 pixels intersecting plot
</p>
</li>
<li><p> PANMEA - Mean of 10 m PAN band pixels intersecting plot
</p>
</li>
<li><p> PANSTD - Standard deviation of 10 m PAN band pixels intersecting plot
</p>
</li></ol>

<p>LiDAR Intensity:
</p>

<ol>
<li><p> INTMEAN - Mean of 2 m intensity pixels intersecting plot
</p>
</li>
<li><p> INTSTD  - Standard deviation of 2 m intensity pixels intersecting plot
</p>
</li>
<li><p> INTMIN  - Minimum of 2 m intensity pixels intersecting plot
</p>
</li>
<li><p> INTMAX  - Maximum of 2 m intensity pixels intersecting plot
</p>
</li></ol>

<p>LiDAR Height:
</p>

<ol>
<li><p> HTMEAN - Mean of 6 m height pixels intersecting plot
</p>
</li>
<li><p> HTSTD  - Standard deviation of 6 m height pixels intersecting plot
</p>
</li>
<li><p> HTMIN  - Minimum of 6 m height pixels intersecting plot
</p>
</li>
<li><p> HTMAX  - Maximum of 6 m height pixels intersecting plot
</p>
</li></ol>

<p>LiDAR Canopy Cover:
</p>

<ol>
<li><p> CCMEAN - Mean of 6 m canopy cover pixels intersecting plot
</p>
</li>
<li><p> CCSTD  - Standard deviation of 6 m canopy cover pixels intersecting plot
</p>
</li>
<li><p> CCMIN  - Minimum of 6 m canopy cover pixels intersecting plot
</p>
</li>
<li><p> CCMAX  - Maximum of 6 m canopy cover pixels intersecting plot
</p>
</li></ol>



<h3>Source</h3>

<p>Dr. Andrew T. Hudak  <br />
USDA Forest Service <br />
Rocky Mountain Research Station <br />
1221 South Main <br />
Moscow, Idaho, USA 83843
</p>


<h3>References</h3>

<p>Hudak, A.T.; Crookston, N.L.; Evans, J.S.; Falkowski, M.J.; Smith,
A.M.S.; Gessler, P.E.; Morgan, P. (2006). Regression modeling and mapping
of coniferous forest basal area and tree density from discrete-return
lidar and multispectral satellite data. Can. J. Remote Sensing.
32(2):126-138. <a href="https://www.tandfonline.com/doi/abs/10.5589/m06-007">https://www.tandfonline.com/doi/abs/10.5589/m06-007</a>
</p>

<hr>
<h2 id='mostused'>Tabulate references most often used in imputation</h2><span id='topic+mostused'></span>

<h3>Description</h3>

<p>Provides a matrix of reference observations that are used most often
as sources of imputation and a column of the counts. The observations
are listed in sorted order, most often used first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mostused(object,n=20,kth=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mostused_+3A_object">object</code></td>
<td>
<p>(1) a data frame created by <code><a href="#topic+foruse">foruse</a></code>, or (2) an object
created by <code><a href="#topic+yai">yai</a></code> in which case <code><a href="#topic+foruse">foruse</a></code> is called automatically.</p>
</td></tr>
<tr><td><code id="mostused_+3A_n">n</code></td>
<td>
<p>the number of mostused in sorted order.</p>
</td></tr>
<tr><td><code id="mostused_+3A_kth">kth</code></td>
<td>
<p>passed to <code><a href="#topic+foruse">foruse</a></code>, if called.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

# build a yai object using mahalanobis
mal &lt;- yai(x=x,y=y,method="mahalanobis")

mostused(mal,kth=1)

</code></pre>

<hr>
<h2 id='newtargets'>Finds K nearest neighbors for new target observations</h2><span id='topic+newtargets'></span>

<h3>Description</h3>

<p>Finds nearest neighbor <em>reference</em> observations for a given set of <em>target</em>
observations using an established (see <code><a href="#topic+yai">yai</a></code>) object. Intended use is to
facilitate breaking up large imputation problems (see <code><a href="#topic+AsciiGridImpute">AsciiGridImpute</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newtargets(object,newdata,k=NULL,ann=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newtargets_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="newtargets_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or matrix of new <em>targets</em> for which neighbors are
are found. Must include at least the <em>X</em>-variables used in the original call to
<code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="newtargets_+3A_k">k</code></td>
<td>
<p>if NULL, the value is taken from <code>object</code>, otherwise the number of nearest 
neighbors to find.</p>
</td></tr>
<tr><td><code id="newtargets_+3A_ann">ann</code></td>
<td>
<p>if NULL, the value is taken from <code>object</code>. When TRUE <code><a href="#topic+ann">ann</a></code> is
used to find neighbors, and when FALSE a slow exact search is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>yai</code>, that is a copy of the first argument with the
following elements replaced:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call.</p>
</td></tr>
<tr><td><code>obsDropped</code></td>
<td>
<p>a list of the row names for observations
dropped for various reasons (missing data).</p>
</td></tr>
<tr><td><code>trgRows</code></td>
<td>
<p>a list of the row names for target observations
as a subset of all observations.</p>
</td></tr>
<tr><td><code>xall</code></td>
<td>
<p>the <em>X</em>-variables for all observations.</p>
</td></tr>
<tr><td><code>neiDstTrgs</code></td>
<td>
<p>a matrix of distances between a target
(identified by its row name) and the k references. There are k columns.</p>
</td></tr>
<tr><td><code>neiIdsTrgs</code></td>
<td>
<p>a matrix of reference identifications
that correspond to neiDstTrgs.</p>
</td></tr>
<tr><td><code>neiDstRefs</code></td>
<td>
<p>set NULL as if <code>noRefs=TRUE</code> in the original call to <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code>neiIdsRefs</code></td>
<td>
<p>set NULL as if <code>noRefs=TRUE</code> in the original call to <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the value of k, replaced if changed.</p>
</td></tr>
<tr><td><code>ann</code></td>
<td>
<p>the value of the ann argument.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
require (yaImpute)

data(iris)

# set the random number seed so that example results are consistant
# normally, leave out this command
set.seed(12345)

# form some test data
refs=sample(rownames(iris),50) # just the reference observations
x &lt;- iris[refs,1:3]  # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

# build a yai object using mahalanobis
mal &lt;- yai(x=x,y=y,method="mahalanobis")

# get imputations for the target observations (not references)
malNew &lt;- newtargets(mal,iris[!(rownames(iris) %in% rownames(x)),])

# output a data frame of observed and imputed values for
# the observations that are not in the original yai object

impute(malNew,vars=yvars(malNew))

# in this example, Y is not specified (not required for mahalanobis).
mal2 &lt;- yai(x=x,method="mahalanobis")
identical(foruse(mal),foruse(mal2))

if (require(randomForest))
{
  # here, method randomForest's unsupervised classification is used (no Y).
  rf &lt;- yai(x=x,method="randomForest")
  # now get imputations for the targets in the iris data (those that are
  # not references).
  rfNew &lt;- newtargets(rf,iris[!(rownames(iris) %in% rownames(x)),])
}

</code></pre>

<hr>
<h2 id='notablyDifferent'>Finds observations with large differences between observed and imputed values</h2><span id='topic+notablyDifferent'></span>

<h3>Description</h3>

<p>This routine identifies observations with large errors as measured by scaled 
root mean square error (see <code><a href="#topic+rmsd.yai">rmsd.yai</a></code>). A <em>threshold</em> 
is used to detect observations with large differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>notablyDifferent(object,vars=NULL,threshold=NULL,p=.05,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="notablyDifferent_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="notablyDifferent_+3A_vars">vars</code></td>
<td>
<p>a vector of character strings naming the variables to use, if 
null the X-variables form <code>object</code> are used.</p>
</td></tr>
<tr><td><code id="notablyDifferent_+3A_threshold">threshold</code></td>
<td>
<p>a threshold that if exceeded the observations are listed as 
<em>notably</em> different.</p>
</td></tr>
<tr><td><code id="notablyDifferent_+3A_p">p</code></td>
<td>
<p><code>(1-p)*100</code> is the percentile point in the distribution 
of differences used to compute the threshold (used when 
<code>threshold</code> is NULL).</p>
</td></tr>
<tr><td><code id="notablyDifferent_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="#topic+impute.yai">impute.yai</a></code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The scaled differences are computed a follows:
</p>

<ol>
<li><p> A matrix of differences between observed and imputed values is 
computed for each observation (rows) and each variable (columns).
</p>
</li>
<li><p> These differences are scaled by dividing by the standard deviation
of the observed values among the <em>reference</em> observations.
</p>
</li>
<li><p> The scaled differences are squared.
</p>
</li>
<li><p> Row means are computed resulting in one value for each observation. 
</p>
</li>
<li><p> The square root of each of these values is taken.
</p>
</li></ol>

<p>These values are Euclidean distances between the target 
observations and their nearest references as measured using specified variables. All
the variables that are used must have observed and imputed values. Generally, this
will be the <em>X</em>-variables and not the <em>Y</em>-variables. 
</p>
<p>When <code>threshold</code> is NULL, the function computes one using the 
<code><a href="stats.html#topic+quantile">quantile</a></code> function with its default arguments and <code>probs=1-p</code>.
</p>


<h3>Value</h3>

<p>A named list of several items. In all cases vectors are named using the observation
ids which are the row names of the data used to build the <code><a href="#topic+yai">yai</a></code>object.
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The call.</p>
</td></tr>
<tr><td><code>vars</code></td>
<td>
<p>The variables used (may be fewer than requested).</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>The threshold value.</p>
</td></tr> 
<tr><td><code>notablyDifferent.refs</code></td>
<td>
<p>A sorted named vector of <em>references</em> that exceed 
the threshold.</p>
</td></tr>
<tr><td><code>notablyDifferent.trgs</code></td>
<td>
<p>A sorted named vector of <em>targets</em> that exceed 
the threshold.</p>
</td></tr>
<tr><td><code>rmsdS.refs</code></td>
<td>
<p>A sorted named vector of scaled RMSD <em>references</em>.</p>
</td></tr>
<tr><td><code>rmsdS.trgs</code></td>
<td>
<p>A sorted named vector of scaled RMSD <em>targets</em>.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+notablyDistant">notablyDistant</a></code>, <code><a href="#topic+plot.notablyDifferent">plot.notablyDifferent</a></code>, 
<code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+grmsd">grmsd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

set.seed(12345)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

# build an msn run, first build dummy variables for species.

sp1 &lt;- as.integer(iris$Species=="setosa")
sp2 &lt;- as.integer(iris$Species=="versicolor")
y2 &lt;- data.frame(cbind(iris[,4],sp1,sp2),row.names=rownames(iris))
y2 &lt;- y2[refs,]

names(y2) &lt;- c("Petal.Width","Sp1","Sp2")

msn &lt;- yai(x=x,y=y2,method="msn")

notablyDifferent(msn)

</code></pre>

<hr>
<h2 id='notablyDistant'>Find notably distant targets</h2><span id='topic+notablyDistant'></span>

<h3>Description</h3>

<p>Notably distant <em>targets</em> are those with relatively large distances from the
closest <em>reference</em> observation. A suitable <em>threshold</em> is used to
detect large distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>notablyDistant(object,kth=1,threshold=NULL,p=0.01,method="distribution")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="notablyDistant_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="notablyDistant_+3A_kth">kth</code></td>
<td>
<p>the kth neighbor is used.</p>
</td></tr>
<tr><td><code id="notablyDistant_+3A_threshold">threshold</code></td>
<td>
<p>the thereshold distance that identifies
<em>notably</em> large distances between observations.</p>
</td></tr>
<tr><td><code id="notablyDistant_+3A_p">p</code></td>
<td>
<p><code>(1-p)*100</code> is the percentile point in the distribution 
of distances used to compute the threshold (only used when 
<em>threshold</em> is NULL).</p>
</td></tr>
<tr><td><code id="notablyDistant_+3A_method">method</code></td>
<td>
<p>the method used to compute the <em>threshold</em>, see details.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>When <code>threshold</code> is NULL, the function computes one using one of
two methods. When <code>method</code> is &quot;distribution&quot;, assumption is made that 
distances follow the lognormal distribution, unless the method used
to find neighbors is <code>randomForest</code>, in which case the distances
are assumed to follow the beta distribution. A specified <code>p</code> value
is used to compute the <code>threshold</code>, which is the point in the distribution
where a fraction, <code>p</code>, of the neighbors are larger than the <code>threshold</code>.
</p>
<p>When <code>method</code> is &quot;quantile&quot;, the function uses the <code><a href="stats.html#topic+quantile">quantile</a></code> 
function with <code>probs=1-p</code>.
</p>


<h3>Value</h3>

<p>List of two data frames that contain 1) the <em>references</em> that are notably
distant from other <em>references</em>, 2) the <em>targets</em> that are notably distant
from the <em>references</em>, 3) the <em>threshold</em> used, and 4) the <em>method</em> used.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+notablyDifferent">notablyDifferent</a></code> <code><a href="#topic+yai">yai</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

set.seed(12345)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

# build an msn run, first build dummy variables for species.

sp1 &lt;- as.integer(iris$Species=="setosa")
sp2 &lt;- as.integer(iris$Species=="versicolor")
y2 &lt;- data.frame(cbind(iris[,4],sp1,sp2),row.names=rownames(iris))
y2 &lt;- y2[refs,]

names(y2) &lt;- c("Petal.Width","Sp1","Sp2")

msn &lt;- yai(x=x,y=y2,method="msn")

notablyDistant(msn)

</code></pre>

<hr>
<h2 id='plot.compare.yai'>Plots a compare.yai object</h2><span id='topic+plot.compare.yai'></span>

<h3>Description</h3>

<p>Provides a matrix of plots for objects created by <code><a href="#topic+compare.yai">compare.yai</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'compare.yai'
plot(x,pointColor=1,lineColor=2,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.compare.yai_+3A_x">x</code></td>
<td>
<p>a data frame created by <code><a href="#topic+compare.yai">compare.yai</a></code>.</p>
</td></tr>
<tr><td><code id="plot.compare.yai_+3A_pointcolor">pointColor</code></td>
<td>
<p>the color used for the points.</p>
</td></tr>
<tr><td><code id="plot.compare.yai_+3A_linecolor">lineColor</code></td>
<td>
<p>the color of the 1:1 line.</p>
</td></tr>
<tr><td><code id="plot.compare.yai_+3A_...">...</code></td>
<td>
<p>passed to plot functions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+compare.yai">compare.yai</a></code>,
<code><a href="#topic+impute.yai">impute.yai</a></code>, <code><a href="#topic+rmsd.yai">rmsd.yai</a></code>
</p>

<hr>
<h2 id='plot.notablyDifferent'>Plots the scaled root mean square differences between observed and predicted</h2><span id='topic+plot.notablyDifferent'></span>

<h3>Description</h3>

<p>Provides a descriptive plot of the <em>Imputation Error Profile</em> for object(s) 
created by <code><a href="#topic+notablyDifferent">notablyDifferent</a></code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'notablyDifferent'
plot(x,add=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.notablyDifferent_+3A_x">x</code></td>
<td>

<ol>
<li><p> an object create by <code><a href="#topic+notablyDifferent">notablyDifferent</a></code>, or 
</p>
</li>
<li><p> a (named) list of such objects.</p>
</li></ol>
</td></tr>
<tr><td><code id="plot.notablyDifferent_+3A_add">add</code></td>
<td>
<p>set <code>TRUE</code> if you want to add this plot to an existing plot.</p>
</td></tr>
<tr><td><code id="plot.notablyDifferent_+3A_...">...</code></td>
<td>
<p>passed to plot functions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+notablyDistant">notablyDistant</a></code> and <code><a href="#topic+yai">yai</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)

set.seed(12345)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

mal &lt;- notablyDifferent(yai(x=x,y=y,method="mahalanobis"),vars=colnames(x))
if (require(randomForest))
{
  rf  &lt;- notablyDifferent(yai(x=x,y=y,method="randomForest"),vars=colnames(x))
  plot.notablyDifferent(list(Mahalanobis=mal,randomForest=rf))
}

</code></pre>

<hr>
<h2 id='plot.varSel'>Boxplot of mean Mahalanobis distances from varSelection()</h2><span id='topic+plot.varSel'></span>

<h3>Description</h3>

<p>Provides a descriptive plot of now the mean Mahalanobis distances change
as variables are added or deleted using <code><a href="#topic+varSelection">varSelection</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varSel'
plot(x,main=NULL,nbest=NULL,arrows=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.varSel_+3A_x">x</code></td>
<td>
<p>an object create by <code><a href="#topic+varSelection">varSelection</a></code></p>
</td></tr>
<tr><td><code id="plot.varSel_+3A_main">main</code></td>
<td>
<p>becomes the plot title, if NULL one is generated</p>
</td></tr>
<tr><td><code id="plot.varSel_+3A_nbest">nbest</code></td>
<td>
<p>number of variables designated in the plot as the best;
if null the number is computed by <code><a href="#topic+bestVars">bestVars</a></code></p>
</td></tr>
<tr><td><code id="plot.varSel_+3A_arrows">arrows</code></td>
<td>
<p>if true, an arrow is added to the plot designating 
the best variables.</p>
</td></tr>
<tr><td><code id="plot.varSel_+3A_...">...</code></td>
<td>
<p>passed to boxplot functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varSelection">varSelection</a></code> and <code><a href="#topic+yai">yai</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)
set.seed(12345)

x &lt;- iris[,1:2]  # Sepal.Length Sepal.Width 
y &lt;- iris[,3:4]  # Petal.Length Petal.Width 

vsel &lt;- varSelection(x=x,y=y,nboot=5,useParallel=FALSE)

plot(vsel)

</code></pre>

<hr>
<h2 id='plot.yai'>Plot observed verses imputed data</h2><span id='topic+plot.yai'></span><span id='topic+plot.impute.yai'></span>

<h3>Description</h3>

<p>Provides a matrix of plots of observed verses imputed values for variables in an
object created by <code><a href="#topic+impute.yai">impute.yai</a></code>, which are of class
<code>c("impute.yai","data.frame")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'yai'
plot(x,vars=NULL,pointColor=1,lineColor=2,spineColor=NULL,residual=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.yai_+3A_x">x</code></td>
<td>

<ol>
<li><p> a data frame created by <code><a href="#topic+impute.yai">impute.yai</a></code>, or 
</p>
</li>
<li><p> an object created by <code><a href="#topic+yai">yai</a></code>.</p>
</li></ol>
</td></tr>
<tr><td><code id="plot.yai_+3A_vars">vars</code></td>
<td>
<p>a list of variable names you want to include, if NULL all available
Y-variables are included.</p>
</td></tr>
<tr><td><code id="plot.yai_+3A_pointcolor">pointColor</code></td>
<td>
<p>a color vector for the xy plots (continuous variables).</p>
</td></tr>
<tr><td><code id="plot.yai_+3A_linecolor">lineColor</code></td>
<td>
<p>a color 1:1 lines in xy plots.</p>
</td></tr>
<tr><td><code id="plot.yai_+3A_spinecolor">spineColor</code></td>
<td>
<p>a color vector for the spine plots (factors), one value per level.</p>
</td></tr>
<tr><td><code id="plot.yai_+3A_residual">residual</code></td>
<td>
<p>plots in a residual format (observed-imputed over imputed).</p>
</td></tr>
<tr><td><code id="plot.yai_+3A_...">...</code></td>
<td>
<p>passed to called functions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

data(iris)

# form some test data
refs=sample(rownames(iris),50)
x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length
y &lt;- iris[refs,4:5]  # Petal.Width Species

mal &lt;- yai(x=x,y=y,method="mahalanobis")
malImp=impute(mal,newdata=iris)
plot(malImp)

</code></pre>

<hr>
<h2 id='predict.yai'>Generic predict function for class yai</h2><span id='topic+predict.yai'></span>

<h3>Description</h3>

<p>Provides a generic interface for getting predicted values for <code><a href="#topic+yai">yai</a></code> objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'yai'
predict(object,newdata,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.yai_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code> which is passed as argument to 
<code><a href="#topic+newtargets">newtargets</a></code>, <code><a href="#topic+impute.yai">impute.yai</a></code>, or both of these functions, see details.</p>
</td></tr>
<tr><td><code id="predict.yai_+3A_newdata">newdata</code></td>
<td>
<p>a data frame that at a minimum contains the <em>X</em>-variables for 
new observations.</p>
</td></tr>
<tr><td><code id="predict.yai_+3A_...">...</code></td>
<td>
<p>passed to <code><a href="#topic+newtargets">newtargets</a></code> and <code><a href="#topic+impute.yai">impute.yai</a></code>, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When argument <code>newdata</code> is present function <code><a href="#topic+newtargets">newtargets</a></code> is called followed by a
call to <code><a href="#topic+impute.yai">impute.yai</a></code>. If include in the ..., the arguments <code>k</code> and <code>ann</code> 
are passed to <code><a href="#topic+newtargets">newtargets</a></code>. 
</p>
<p>When argument <code>newdata</code> is absent, <code><a href="#topic+impute.yai">impute.yai</a></code> is called without first calling
<code><a href="#topic+newtargets">newtargets</a></code>.
</p>
<p>All of the ... arguments are passed to <code><a href="#topic+impute.yai">impute.yai</a></code>.
</p>
<p>Another form of prediction in imputation is to get the identity of the imputed observations.
Use function <code><a href="#topic+foruse">foruse</a></code> for this purpose.
</p>


<h3>Value</h3>

<p>An object of class <code>impute.yai</code>.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+foruse">foruse</a></code>, <code><a href="#topic+newtargets">newtargets</a></code> <code><a href="#topic+impute.yai">impute.yai</a></code></p>

<hr>
<h2 id='print.yai'>Print a summary of a yai object</h2><span id='topic+print.yai'></span><span id='topic+summary.yai'></span>

<h3>Description</h3>

<p>Provides a summary of a <code><a href="#topic+yai">yai</a></code> object, showing the
call and essential data customized for each method used.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'yai'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.yai_+3A_x">x</code></td>
<td>
<p>an object of class <code>yai</code>.</p>
</td></tr>
<tr><td><code id="print.yai_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>

<hr>
<h2 id='rmsd.yai'>Root Mean Square Difference between observed and imputed</h2><span id='topic+rmsd.yai'></span><span id='topic+rmsd'></span>

<h3>Description</h3>

<p>Computes the root mean square difference (RMSD) between
observed and imputed values for each observation that has both. RMSD
is computationally like RMSE, but they differ in interpretation. The RMSD
values can be scaled to afford comparisons among variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmsd.yai (object,vars=NULL,scale=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmsd.yai_+3A_object">object</code></td>
<td>
<p>an object created by <code><a href="#topic+yai">yai</a></code> or <code><a href="#topic+impute.yai">impute.yai</a></code></p>
</td></tr>
<tr><td><code id="rmsd.yai_+3A_vars">vars</code></td>
<td>
<p>a list of variable names you want to include, if NULL all available
variables are included</p>
</td></tr>
<tr><td><code id="rmsd.yai_+3A_scale">scale</code></td>
<td>
<p>when <code>TRUE</code>, the values are scaled (see details), if a named vector,
the values are scaled by the corresponding values.</p>
</td></tr>
<tr><td><code id="rmsd.yai_+3A_...">...</code></td>
<td>
<p>passed to called methods, very useful for passing argument
<code>ancillaryData</code> to function <code><a href="#topic+impute.yai">impute.yai</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, RMSD is computed using standard formula for its related statistic,
RMSE. When <code>scale=TRUE</code>, or set of values is supplied, RMSD is divided by the 
scaling factor. The scaling factor is the standard deviation of the
<em>reference</em> observations under the assumption that they are representative
of the population.
</p>


<h3>Value</h3>

<p>A data frame with the row names as vars and the column as <code>rmsd</code>. When
<code>scale=TRUE</code>, the column name is <code>rmsdS</code>. The scaling factors used, if any,
are returned as an attribute.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+impute.yai">impute.yai</a></code> and <a href="https://doi.org/10.18637/jss.v023.i10">doi:10.18637/jss.v023.i10</a>.
</p>

<hr>
<h2 id='TallyLake'>Tally Lake, Flathead National Forest, Montana, USA</h2><span id='topic+TallyLake'></span>

<h3>Description</h3>

<p>Polygon-based reference data used by Stage and Crookston (2007)
to demonstrate partitioning of error components and related statistics.
Observations are summaries of data collected on forest stands (ploygons).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(TallyLake)
</code></pre>


<h3>Format</h3>

<p>A data frame with 847 rows and 29 columns: <br /><br />
Ground based measurements of trees (Y-variables):
</p>

<ol>
<li><p> TopHt   - Height of tallest trees (ft)
</p>
</li>
<li><p> LnVolL  - Log of the volume <code class="reqn">(ft^3/acre)</code> of western larch
</p>
</li>
<li><p> LnVolDF - Log of the volume <code class="reqn">(ft^3/acre)</code> of Douglas-fir
</p>
</li>
<li><p> LnVolLP - Log of the volume <code class="reqn">(ft^3/acre)</code> of lodgepole pine
</p>
</li>
<li><p> LnVolES - Log of the volume <code class="reqn">(ft^3/acre)</code> of Engelmann spruce
</p>
</li>
<li><p> LnVolAF - Log of the volume <code class="reqn">(ft^3/acre)</code> of alpine fir
</p>
</li>
<li><p> LnVolPP - Log of the volume <code class="reqn">(ft^3/acre)</code> of ponderosa pine
</p>
</li>
<li><p> CCover  - Canopy cover (percent)
</p>
</li></ol>

<p>Geographic Location, Slope, and Aspect (X-variables):
</p>

<ol>
<li><p> utmx - UTM easting at plot center
</p>
</li>
<li><p> utmy - UTM northing at plot center
</p>
</li>
<li><p> elevm - Mean elevation (ft) above sea level over plot
</p>
</li>
<li><p> eevsqrd - <code class="reqn">(elevm-1600)^2</code>
</p>
</li>
<li><p> slopem - Mean slope (percent) over plot
</p>
</li>
<li><p> slpcosaspm - Mean of slope (proportion) times the cosine of aspect (see
Stage (1976) for description of this transformation
</p>
</li>
<li><p> slpsinaspm - Mean of slope (proportion) times the sine of aspect
</p>
</li></ol>

<p>Additional X-variables:
</p>

<ol>
<li><p> ctim     - Mean of slope curviture over pixels in stand
</p>
</li>
<li><p> tmb1m    - Mean of LandSat band 1 over pixels in stand
</p>
</li>
<li><p> tmb2m    - Mean of LandSat band 2 over pixels in stand
</p>
</li>
<li><p> tmb3m    - Mean of LandSat band 3 over pixels in stand
</p>
</li>
<li><p> tmb4m    - Mean of LandSat band 4 over pixels in stand
</p>
</li>
<li><p> tmb5m    - Mean of LandSat band 5 over pixels in stand
</p>
</li>
<li><p> tmb6m    - Mean of LandSat band 6 over pixels in stand
</p>
</li>
<li><p> durm     - Mean of light duration over pixels in stand
</p>
</li>
<li><p> insom    - Mean of solar insolation over pixels in stand
</p>
</li>
<li><p> msavim   - Mean of AVI for pixels in stand
</p>
</li>
<li><p> ndvim    - Mean of NDVI for pixels in stand
</p>
</li>
<li><p> crvm     - Mean of slope curviture for pixels in stand
</p>
</li>
<li><p> tancrvm  - Mean of tangent curvature for pixels in stand
</p>
</li>
<li><p> tancrvsd - Standard deviation of tangent curvature for pixels in stand
</p>
</li></ol>



<h3>Source</h3>

<p>USDA Forest Service
</p>


<h3>References</h3>

<p>Stage, A.R.; Crookston, N.L. 2007. Partitioning error components
for accuracy-assessment of near neighbor methods of imputation.
<em>For. Sci.</em> 53(1):62-72 <a href="https://academic.oup.com/forestscience/article/53/1/62/4604364">https://academic.oup.com/forestscience/article/53/1/62/4604364</a>
</p>
<p>Stage, A.R. (1976). An expression for the effect of aspect, slope, and
habitat type on tree growth. <em>For. Sci.</em> 22(4):457-460.  
<a href="https://academic.oup.com/forestscience/article-abstract/22/4/457/4675852">https://academic.oup.com/forestscience/article-abstract/22/4/457/4675852</a>
</p>

<hr>
<h2 id='unionDataJoin'>Combines data from several sources</h2><span id='topic+unionDataJoin'></span>

<h3>Description</h3>

<p>Takes any combination of several data frames or matrices and creates a new data
frame. The rows are defined by a union of all row names in the arguments,
and the columns are defined by a union of all column names in the arguments. The data
are loaded into this new frame where column and row names match the individual
inputs. Duplicates are tolerated with the last one specified being the one
kept. NAs are returned for combinations of rows and columns where no data
exist. Factors are processed as necessary.</p>


<h3>Usage</h3>

<pre><code class='language-R'>unionDataJoin(...,warn=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unionDataJoin_+3A_...">...</code></td>
<td>
<p>a list of data frames, matrices, or any combination.</p>
</td></tr>
<tr><td><code id="unionDataJoin_+3A_warn">warn</code></td>
<td>
<p>when TRUE, warn when a column name is found in more than one data source.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(yaImpute)

d1=data.frame(x1=c("a","b","c","d","e","f"))
d2=data.frame(x1=as.character(seq(1,4)),row.names=seq(5,8))
d3=data.frame(x2=seq(1:10))

# note the levels
levels(d1$x1)
# [1] "a" "b" "c" "d" "e" "f"

levels(d2$x1)
# [1] "1" "2" "3" "4"

all=unionDataJoin(d1,d2,d3,warn=FALSE)
all
#      x1 x2
# 1     a  1
# 2     b  2
# 3     c  3
# 4     d  4
# 5     1  5
# 6     2  6
# 7     3  7
# 8     4  8
# 9  &lt;NA&gt;  9
# 10 &lt;NA&gt; 10

levels(all$x1)
# [1] "1" "2" "3" "4" "a" "b" "c" "d"

</code></pre>

<hr>
<h2 id='vars'>List variables in a yai object</h2><span id='topic+vars'></span><span id='topic+xvars'></span><span id='topic+yvars'></span>

<h3>Description</h3>

<p>Provides a character vector, or a list of character vectors
of all the variables in a <code><a href="#topic+yai">yai</a></code> object,
just the X-variables (<code>xvars</code>), or just the Y-variables (<code>yvars</code>).</p>


<h3>Usage</h3>

<pre><code class='language-R'>vars(object)
xvars(object)
yvars(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vars_+3A_object">object</code></td>
<td>
<p>an object created by <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>yvars</code></td>
<td>
<p>A character vector of <em>Y</em>-variables.</p>
</td></tr>
<tr><td><code>xvars</code></td>
<td>
<p>A character vector of <em>X</em>-variables.</p>
</td></tr>
<tr><td><code>vars</code></td>
<td>
<p>A list of both vectors.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code></p>

<hr>
<h2 id='varSelection'>Select variables for imputation models</h2><span id='topic+varSelection'></span>

<h3>Description</h3>

<p>Computes <code><a href="#topic+grmsd">grmsd</a></code> (generalized root mean square distance)   
as variables are added to (<code>method="addVars"</code>) or removed from 
(<code>method="delVars"</code>) an k-NN imputation model. When adding variables
the function keeps variables that strengthen imputation and
deletes that weaken the imputation the least.
The measure of model strength is grmsd between
imputed and observed <em>Y</em>-variables among the reference observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varSelection(x,y,method="addVars",yaiMethod="msn",imputeMethod="closest",
  wts=NULL,nboot=20,trace=FALSE,
  useParallel=if (.Platform$OS.type == "windows") FALSE else TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varSelection_+3A_x">x</code></td>
<td>
<p>a set of <em>X</em>-Variables as used in <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="varSelection_+3A_y">y</code></td>
<td>
<p>a set of <em>Y</em>-Variables as used in <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="varSelection_+3A_method">method</code></td>
<td>
<p>if <code>addVars</code>, the X-Variables are added and  
if <code>delVars</code> they are deleted (see details).</p>
</td></tr>
<tr><td><code id="varSelection_+3A_yaimethod">yaiMethod</code></td>
<td>
<p>passed as <code>method</code> to <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="varSelection_+3A_imputemethod">imputeMethod</code></td>
<td>
<p>passed as <code>method</code> to <code><a href="#topic+impute.yai">impute.yai</a></code>.</p>
</td></tr>
<tr><td><code id="varSelection_+3A_wts">wts</code></td>
<td>
<p>passed as argument <code>wts</code> to <code><a href="#topic+grmsd">grmsd</a></code> 
which is used to score the alternative varialbe sets.</p>
</td></tr>
<tr><td><code id="varSelection_+3A_nboot">nboot</code></td>
<td>
<p>the number of bootstrap samples used at each variable selection 
step (see Details). When nboot is zero, NO bootstraping is done.</p>
</td></tr> 
<tr><td><code id="varSelection_+3A_trace">trace</code></td>
<td>
<p>if <code>TRUE</code> information at each step is output.</p>
</td></tr>
<tr><td><code id="varSelection_+3A_useparallel">useParallel</code></td>
<td>
<p>function <code>link{parallel:mclapply}</code> from <span class="pkg">parallel</span> 
will be used if it is available for running the bootstraps. It it is
not available, <code>link{lapply}</code> is used (which is the only option
on windows).</p>
</td></tr> 
<tr><td><code id="varSelection_+3A_...">...</code></td>
<td>
<p>passed to <code>link{yai}</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function tracks the effect on generalized root mean square distance 
(see <code><a href="#topic+grmsd">grmsd</a></code>) when variables are added or deleted one at a time. 
When adding variables, the function starts with none, and keeps the single 
variable that provides the smallest <code>grmsd</code>. When deleting variables, 
the functions starts with all <em>X</em>-Variables and deletes them one at a 
time such that those that remain provide the smallest
<code>grmsd</code>. The function uses the following steps:
</p>

<ol>
<li><p> Function <code><a href="#topic+yai">yai</a></code> is run for all the Y-variables and candidate
X-variable(s). The result is passed to <code><a href="#topic+impute.yai">impute.yai</a></code> to get imputed
values of Y-variables. That result is passed to <code><a href="#topic+grmsd">grmsd</a></code> to compute a
mean Mahalanobis distance for the case where the candidate variable is included
(or deleted depending on <code>method</code>). However, these steps are done once
for each bootstrap replication and the resulting values are averaged to provide
an average mean Mahalanobis distance over the bootstraps. 
</p>
</li>
<li><p> Step one is done for each candidate X-variable forming a vector of 
<code><a href="#topic+grmsd">grmsd</a></code> values, one corresponding to the case where each candidate
is added or deleted. 
</p>
</li>
<li><p> When variables are being added (<code>method="addVars"</code>), the variable that
is related to the smallest <code>grmsd</code> is kept. When variables are being 
deleted (<code>method="delVars"</code>), the variable that
is related to the largest <code>grmsd</code> is deleted.
</p>
</li>
<li><p> Once a variable has been added or deleted, the function proceeds to select
another variable for selection or deletion by considering all remaining variables.
</p>
</li></ol>



<h3>Value</h3>

<p>An list of class <code>varSel</code> with these tags:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call</p>
</td></tr>
<tr><td><code>grmsd</code></td>
<td>
<p>a 2-column matrix of the mean and std dev of the mean Mahalanobis 
distances associated with adding or removing the variables stored as 
the rownames. When nboot&lt;2, the std dev are NA</p>
</td></tr>
<tr><td><code>allgrmsd</code></td>
<td>
<p>a list of the grmsd values that correspond to each bootstrap
replication. The data in grmsd are based on these vectors of information.</p>
</td></tr>  
<tr><td><code>method</code></td>
<td>
<p>the value of argument <code>method</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+impute.yai">impute.yai</a></code>, <code><a href="#topic+bestVars">bestVars</a></code> and 
<code><a href="#topic+grmsd">grmsd</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

set.seed(12345)

x &lt;- iris[,1:2]  # Sepal.Length Sepal.Width 
y &lt;- iris[,3:4]  # Petal.Length Petal.Width 

vsel &lt;- varSelection(x=x,y=y,nboot=5,useParallel=FALSE)
vsel

bestVars(vsel)

plot(vsel)

</code></pre>

<hr>
<h2 id='whatsMax'>Find maximum column for each row</h2><span id='topic+whatsMax'></span>

<h3>Description</h3>

<p>For each row, the function identifies the column that has the maximum
value. The function returns a data frame with two columns: the first is
the column name corresponding to the column of maximum value and the
second is the correspond maximum. The first column is converted to a
factor.
</p>
<p>If the maximum is zero, the maximum column is identified as &quot;zero&quot;.
</p>
<p>If there are over <code>nbig</code> factors in column 1, the maximum values
that are less than the largest are combined and identified as &quot;other&quot;.
</p>
<p>Intended use is to transform community ecology data for use in <code><a href="#topic+yai">yai</a></code>
where method is <em>randomForest</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>whatsMax(x,nbig=30)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="whatsMax_+3A_x">x</code></td>
<td>
<p>a data frame or matrix of numeric values.</p>
</td></tr>
<tr><td><code id="whatsMax_+3A_nbig">nbig</code></td>
<td>
<p>see description&ndash;the maximum number of factors, the remainder called 'other'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MoscowMtStJoe)

# get the basal area by species columns
yba  &lt;- MoscowMtStJoe[,1:17]

# for each row, pick the species that has the max basal area
# create "other" for those not in the top 7.

ybaB &lt;- whatsMax(yba,nbig=7)
levels(ybaB[,1])
</code></pre>

<hr>
<h2 id='yai'>Find K nearest neighbors</h2><span id='topic+yai'></span><span id='topic+yaImpute'></span>

<h3>Description</h3>

<p>Given a set of observations, <code>yai</code> </p>

<ol>
<li><p> separates the observations into <em>reference</em> and <em>target</em> observations,
</p>
</li>
<li><p> applies the specified method to project X-variables into a Euclidean space (not
always, see argument <code>method</code>), and 
</p>
</li>
<li><p> finds the <em>k</em>-nearest neighbors within the referenece observations 
and between the reference and target observations.
</p>
</li></ol>
 
<p>An alternative method using <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>
classification and regression trees is provided for steps 2 and 3.
<em>Target</em> observations are those with values for X-variables and
not for Y-variables, while <em>reference</em> observations are those
with no missing values for X-and Y-variables (see Details for the
exception).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yai(x=NULL,y=NULL,data=NULL,k=1,noTrgs=FALSE,noRefs=FALSE,
    nVec=NULL,pVal=.05,method="msn",ann=TRUE,mtry=NULL,ntree=500,
    rfMode="buildClasses",bootstrap=FALSE,ppControl=NULL,sampleVars=NULL,
    rfXsubsets=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yai_+3A_x">x</code></td>
<td>
<p>1) a matrix or data frame containing the X-variables for all
observations with row names are the identification for the observations, or 2) a
one-sided formula defining the X-variables as a linear formula. If
a formula is coded for <code>x</code>, one must be used for <code>y</code> as well, if
needed.</p>
</td></tr>
<tr><td><code id="yai_+3A_y">y</code></td>
<td>
<p>1) a matrix or data frame containing the Y-variables for the
reference observations, or 2) a one-sided formula defining the
Y-variables as a linear formula.</p>
</td></tr>
<tr><td><code id="yai_+3A_data">data</code></td>
<td>
<p>when <code>x</code> and <code>y</code> are formulas, then data is a data frame or
matrix that contains all the variables with row names are the identification for the observations.
The observations are split by <code>yai</code> into two sets.</p>
</td></tr>
<tr><td><code id="yai_+3A_k">k</code></td>
<td>
<p>the number of nearest neighbors; default is 1.</p>
</td></tr>
<tr><td><code id="yai_+3A_notrgs">noTrgs</code></td>
<td>
<p>when TRUE, skip finding neighbors for target observations.</p>
</td></tr>
<tr><td><code id="yai_+3A_norefs">noRefs</code></td>
<td>
<p>when TRUE, skip finding neighbors for reference observations.</p>
</td></tr>
<tr><td><code id="yai_+3A_nvec">nVec</code></td>
<td>
<p>number of canonical vectors to use (methods <code>msn</code> and <code>msn2</code>),
or number of independent of X-variables reference data when method
<code>mahalanobis</code>. When NULL, the number is set by the function.</p>
</td></tr>
<tr><td><code id="yai_+3A_pval">pVal</code></td>
<td>
<p>significant level for canonical vectors, used when <code>method</code> is
<code>msn</code> or <code>msn2</code>.</p>
</td></tr>
<tr><td><code id="yai_+3A_method">method</code></td>
<td>
<p>is the strategy used for computing distance and therefore for finding neighbors; the
options are quoted key words (see details):
</p>

<ol>
<li><p> euclidean - distance is computed in a normalized X space.
</p>
</li>
<li><p> raw - like euclidean, except no normalization is done.
</p>
</li>
<li><p> mahalanobis - distance is computed in its namesakes space.
</p>
</li>
<li><p> ica - like mahalanobis, but based on <em>Independent Component Analysis</em> using
package <code><a href="fastICA.html#topic+fastICA">fastICA</a></code>.
</p>
</li>
<li><p> msn - distance is computed in a projected canonical space.
</p>
</li>
<li><p> msn2 - like msn, but with variance weighting (canonical regression
rather than correlation).
</p>
</li>
<li><p> msnPP - like msn, except that the canonical correlation is computed using
projection pursuit from <span class="pkg">ccaPP</span> (see argument <code>ppControl</code>).
</p>
</li>
<li><p> gnn - distance is computed using a projected ordination of
Xs found using canonical correspondence analysis
(<code><a href="vegan.html#topic+cca">cca</a></code> from package <span class="pkg">vegan</span>). 
If <code><a href="vegan.html#topic+cca">cca</a></code> fails, <code><a href="vegan.html#topic+rda">rda</a></code> is used
and a warning is issued.
</p>
</li>
<li><p> randomForest - distance is one minus the proportion of 
<span class="pkg">randomForest</span> trees where a target observation is in the same terminal node 
as a reference observation (see <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>).
</p>
</li>
<li><p> random - like raw except that the X space is a single vector of uniform random [0,1]
numbers generated using <code><a href="stats.html#topic+runif">runif</a></code>, results in random assignment of neighbors,
and forces <code>ann</code> to be FALSE.
</p>
</li>
<li><p> gower - distance is computed in its namesakes space using function 
<code><a href="gower.html#topic+gower_topn">gower_topn</a></code> from package <span class="pkg">gower</span>; forces <code>ann</code> to be FALSE.
</p>
</li></ol>
   
</td></tr>
<tr><td><code id="yai_+3A_ann">ann</code></td>
<td>
<p>TRUE if <code><a href="#topic+ann">ann</a></code> is used to find neighbors, FALSE if a slow search is used.</p>
</td></tr>
<tr><td><code id="yai_+3A_mtry">mtry</code></td>
<td>
<p>the number of X-variables picked at random when method is <code>randomForest</code>,
see <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, default is sqrt(number of X-variables).</p>
</td></tr>
<tr><td><code id="yai_+3A_ntree">ntree</code></td>
<td>
<p>the number of classification and regression trees when method is <code>randomForest</code>.
When more than one Y-variable is used, the trees are divided among the variables.
Alternatively, ntree can be a vector of values corresponding to each Y-variable.</p>
</td></tr>
<tr><td><code id="yai_+3A_rfmode">rfMode</code></td>
<td>
<p>when <code>buildClasses</code> and method is <code>randomForest</code>, continuous variables
are internally converted to classes forcing randomForest to build classification trees for
the variable. Otherwise, regression trees are built if your version of
<span class="pkg">randomForest</span> is newer than <code>4.5-18</code>.</p>
</td></tr>
<tr><td><code id="yai_+3A_bootstrap">bootstrap</code></td>
<td>
<p>if <code>TRUE</code>, the reference observations are sampled with replacement.</p>
</td></tr>
<tr><td><code id="yai_+3A_ppcontrol">ppControl</code></td>
<td>
<p>used to control how canoncial correlation analysis via 
projection pursuit is done, see Details.</p>
</td></tr>
<tr><td><code id="yai_+3A_samplevars">sampleVars</code></td>
<td>
<p>the X- and/or Y-variables will be sampled (without replacement) 
if this is not NULL and greater than zero. If specified as a single unnamed value, 
that value is used to control the sample size of both X and Y variables. If two unnamed values, 
then the first is taken for X-variables and the second for Y-variables. 
If zero, no sampling is done. Otherwise, values are less than 1.0 they are taken as 
the proportion of the number of variables. Values greater or equal to 1 are number of 
variables to be included in the sample. Specification of a large number will cause the 
sequence of variables to be randomized.</p>
</td></tr>
<tr><td><code id="yai_+3A_rfxsubsets">rfXsubsets</code></td>
<td>
<p>a named list of character vectors where there is one vector for each
Y-variable, see details, only applies when <code>method="randomForest"</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the paper at <a href="https://doi.org/10.18637/jss.v023.i10">doi:10.18637/jss.v023.i10</a> (it includes examples).
</p>
<p>The following information is in addition to the content in the papers.
</p>
<p>You need not have any Y-variables to run yai for the following methods:
<code>euclidean</code>, <code>raw</code>, <code>mahalanobis</code>, <code>ica</code>, <code>random</code>, and
<code>randomForest</code> (in which case unsupervised classification is
performed). However, normally <code>yai</code> classifies <em>reference</em>
observations as those with no missing values for X- and Y- variables and
<em>target</em> observations are those with values for X- variables and
missing data for Y-variables. When Y is NULL (there are no Y-variables),
all the observations are considered <em>references</em>. See
<code><a href="#topic+newtargets">newtargets</a></code> for an example of how to use yai in this
situation.
</p>
<p>When <code>bootstrap=TRUE</code> the reference observations are sampled with replacement. The
sample size is set to the number of reference observations. Normally, about a third of
the reference observations are left out of the sample; they are often called out-of-bag 
samples. The out-of-bag observations are then treated as targets.
</p>
<p>When <code>method="msnPP"</code> projection pursuit from <span class="pkg">ccaPP</span> is used. The method is
further controlled using argument <code>ppControl</code> to specify a character vector that has 
has two named components.
</p>

<ol>
<li><p> method - One of the following 
<code>"spearman", "kendall", "quadrant", "M", "pearson"</code>, default is &quot;spearman&quot;
</p>
</li>
<li><p> searc - If <code>"data"</code> or <code>"proj"</code>, then <code><a href="ccaPP.html#topic+ccaProj">ccaProj</a></code> 
is used, otherwise the default <code><a href="ccaPP.html#topic+ccaGrid">ccaGrid</a></code> is used.
</p>
</li></ol>

<p>Here are some details on argument <code>rfXsubsets</code>. When <code>method="randomForest"</code> 
one call to <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> is generated for for each Y-variable. When
argument <code>rfXsubsets</code> is left <code>NULL</code>, all the X-variables are used for each of 
the Y-variables. However, sometimes better results can be achieved by using specific subsets
of X-variables for each Y-variable. This is done by setting <code>rfXsubsets</code> equal
to a named list of character vectors. The names correspond to the Y-variable names and the
character vectors hold the list of X-variables for the corresponding Y-variable. 
</p>


<h3>Value</h3>

<p>An object of class <code>yai</code>, which is a list with
the following tags:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call.</p>
</td></tr>
<tr><td><code>yRefs</code>, <code>xRefs</code></td>
<td>
<p>matrices of the X- and Y-variables for just
the reference observations (unscaled). The scale factors
are attached as attributes.</p>
</td></tr>
<tr><td><code>obsDropped</code></td>
<td>
<p>a list of the row names for observations
dropped for various reasons (missing data).</p>
</td></tr>
<tr><td><code>trgRows</code></td>
<td>
<p>a list of the row names for target observations
as a subset of all observations.</p>
</td></tr>
<tr><td><code>xall</code></td>
<td>
<p>the X-variables for all observations.</p>
</td></tr>
<tr><td><code>cancor</code></td>
<td>
<p>returned from cancor function when method <code>msn</code> or
<code>msn2</code> is used (NULL otherwise).</p>
</td></tr>
<tr><td><code>ccaVegan</code></td>
<td>
<p>an object of class cca (from package <span class="pkg">vegan</span>) when
method <em>gnn</em> is used.</p>
</td></tr>
<tr><td><code>ftest</code></td>
<td>
<p>a list containing partial F statistics and a vector of
Pr&gt;F (pgf) corresponding to the canonical correlation coefficients
when method msn or msn2 is used (NULL otherwise).</p>
</td></tr>
<tr><td><code>yScale</code>, <code>xScale</code></td>
<td>
<p>scale data used on yRefs and xRefs as needed.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the value of <em>k</em>.</p>
</td></tr>
<tr><td><code>pVal</code></td>
<td>
<p>as input; only used when method <code>msn</code>, <code>msn2</code> or <code>msnPP</code> is used.</p>
</td></tr>
<tr><td><code>projector</code></td>
<td>
<p>NULL when not used. For methods <code>msn</code>, <code>msn2</code>, <code>msnPP</code>, <code>gnn</code>
and <code>mahalanobis</code>, this is a matrix that projects normalized X-variables
into a space suitable for doing Eculidian distances.</p>
</td></tr>
<tr><td><code>nVec</code></td>
<td>
<p>number of canonical vectors used (methods <code>msn</code> and <code>msn2</code>),
or number of independent X-variables in the reference data when method
<code>mahalanobis</code> is used.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>as input, the method used.</p>
</td></tr>
<tr><td><code>ranForest</code></td>
<td>
<p>a list of the forests if method <code>randomForest</code> is used. There is
one forest for each Y-variable, or just one forest when there are no
Y-variables.</p>
</td></tr>
<tr><td><code>ICA</code></td>
<td>
<p>a list of information from <code><a href="fastICA.html#topic+fastICA">fastICA</a></code>
when method <code>ica</code> is used.</p>
</td></tr>
<tr><td><code>ann</code></td>
<td>
<p>the value of ann, TRUE when <code><a href="#topic+ann">ann</a></code> is used, FALSE otherwise.</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>NULL if no factors are used as predictors; otherwise a list
of predictors that have factors and their levels (see <code><a href="stats.html#topic+lm">lm</a></code>).</p>
</td></tr>
<tr><td><code>neiDstTrgs</code></td>
<td>
<p>a matrix of distances between a target
(identified by its row name) and the <em>k</em> references. There are <em>k</em> columns.</p>
</td></tr>
<tr><td><code>neiIdsTrgs</code></td>
<td>
<p>a matrix of reference identifications
that correspond to neiDstTrgs.</p>
</td></tr>
<tr><td><code>neiDstRefs</code>, <code>neiIdsRefs</code></td>
<td>
<p>counterparts for references.</p>
</td></tr>
<tr><td><code>bootstrap</code></td>
<td>
<p>a vector of reference rownames that constitute the bootstrap sample; 
or the value <code>FALSE</code> when bootstrap is not used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
John Coulston <a href="mailto:jcoulston@fs.usda.gov">jcoulston@fs.usda.gov</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grmsd">grmsd</a></code> <code><a href="#topic+ensembleImpute">ensembleImpute</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require (yaImpute)

data(iris)

# set the random number seed so that example results are consistent
# normally, leave out this command
set.seed(12345)

# form some test data, y's are defined only for reference
# observations.
refs=sample(rownames(iris),50)
x &lt;- iris[,1:2]      # Sepal.Length Sepal.Width
y &lt;- iris[refs,3:4]  # Petal.Length Petal.Width

# build yai objects using 2 methods
msn &lt;- yai(x=x,y=y)
mal &lt;- yai(x=x,y=y,method="mahalanobis")
# compare these results using the generalized mean distances. mal wins!
grmsd(mal,msn)

# use projection pursuit and specify ppControl (loads package ccaPP)
if (require(ccaPP)) 
{
  msnPP &lt;- yai(x=x,y=y,method="msnPP",ppControl=c(method="kendall",search="proj"))
  grmsd(mal,msnPP,msn)
}

#############

data(MoscowMtStJoe)

# convert polar slope and aspect measurements to cartesian
# (which is the same as Stage's (1976) transformation).

polar &lt;- MoscowMtStJoe[,40:41]
polar[,1] &lt;- polar[,1]*.01      # slope proportion
polar[,2] &lt;- polar[,2]*(pi/180) # aspect radians
cartesian &lt;- t(apply(polar,1,function (x)
               {return (c(x[1]*cos(x[2]),x[1]*sin(x[2]))) }))
colnames(cartesian) &lt;- c("xSlAsp","ySlAsp")
x &lt;- cbind(MoscowMtStJoe[,37:39],cartesian,MoscowMtStJoe[,42:64])
y &lt;- MoscowMtStJoe[,1:35]

msn &lt;- yai(x=x, y=y, method="msn", k=1)
mal &lt;- yai(x=x, y=y, method="mahalanobis", k=1)
# the results can be plotted.
plot(mal,vars=yvars(mal)[1:16])

# compare these results using the generalized mean distances..
grmsd(mal,msn)

# try method="gower"
if (require(gower))
{
  gow &lt;- yai(x=x, y=y, method="gower", k=1)
  # compare these results using the generalized mean distances..
  grmsd(mal,msn,gow)
}

# try method="randomForest"
if (require(randomForest))
{
  # reduce the plant community data for randomForest.
  yba  &lt;- MoscowMtStJoe[,1:17]
  ybaB &lt;- whatsMax(yba,nbig=7)  # see help on whatsMax
  
  rf &lt;- yai(x=x, y=ybaB, method="randomForest", k=1)
  
  # build the imputations for the original y's
  rforig &lt;- impute(rf,ancillaryData=y)
  
  # compare the results using individual rmsd's
  compare.yai(mal,msn,rforig)
  plot(compare.yai(mal,msn,rforig))
  
  # build another randomForest case forcing regression
  # to be used for continuous variables. The answers differ
  # but one is not clearly better than the other.
  
  rf2 &lt;- yai(x=x, y=ybaB, method="randomForest", rfMode="regression")
  rforig2 &lt;- impute(rf2,ancillaryData=y)
  compare.yai(rforig2,rforig)
}
  
</code></pre>

<hr>
<h2 id='yaiRFsummary'>Build Summary Data For Method RandomForest </h2><span id='topic+yaiRFsummary'></span>

<h3>Description</h3>

<p>When method <code>randomforest</code> is used to build a <code><a href="#topic+yai">yai</a></code>
object, the <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> package computes
several statistics. This function summarizes some of them, including
the variable importance scores computed by function <code><a href="#topic+yaiVarImp">yaiVarImp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yaiRFsummary(object, nTop=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yaiRFsummary_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code>.</p>
</td></tr>
<tr><td><code id="yaiRFsummary_+3A_ntop">nTop</code></td>
<td>
<p>the <code>nTop</code> most important variables are plotted (returned).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr><td><code>forestAttributes</code></td>
<td>
<p>a data frame reporting the error rates and other data
from the randomForest(s).</p>
</td></tr>
<tr><td><code>scaledImportance</code></td>
<td>
<p>the data frame computed by <code><a href="#topic+yaiVarImp">yaiVarImp</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
Andrew O. Finley <a href="mailto:finleya@msu.edu">finleya@msu.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+yaiVarImp">yaiVarImp</a></code>
</p>

<hr>
<h2 id='yaiVarImp'>Reports or plots importance scores for yai method randomForest</h2><span id='topic+yaiVarImp'></span>

<h3>Description</h3>

<p>When method <code>randomforest</code> is used to build a <code><a href="#topic+yai">yai</a></code>
object, the <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> package computes
variable importance scores. This function computes a composite of the
scores and scales them using <code><a href="base.html#topic+scale">scale</a></code>. By default the 
scores are plotted and scores themselves are invisibly returned. For 
classification, the scores are derived from &quot;MeanDecreaseAccuracy&quot; 
and for regression they are based in &quot;
using <code><a href="randomForest.html#topic+importance">importance</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yaiVarImp(object, nTop=20, plot=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yaiVarImp_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+yai">yai</a></code></p>
</td></tr>
<tr><td><code id="yaiVarImp_+3A_ntop">nTop</code></td>
<td>
<p>the <code>nTop</code> most important variables are plotted (returned); 
if NA or zero, all are returned</p>
</td></tr>
<tr><td><code id="yaiVarImp_+3A_plot">plot</code></td>
<td>
<p>if FALSE, no plotting is done, but the scores are returned.</p>
</td></tr>
<tr><td><code id="yaiVarImp_+3A_...">...</code></td>
<td>
<p>passed to the <code><a href="graphics.html#topic+boxplot">boxplot</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the rows corresponding to the randomForest
built for each <em>Y</em>-variable and the columns corresponding to the
<code>nTop</code> most important Y-variables in sorted order.
</p>


<h3>Author(s)</h3>

<p>Nicholas L. Crookston <a href="mailto:ncrookston.fs@gmail.com">ncrookston.fs@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yai">yai</a></code>, <code><a href="#topic+yaiRFsummary">yaiRFsummary</a></code>, <code><a href="#topic+compare.yai">compare.yai</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (require(randomForest))
{
  data(MoscowMtStJoe)

  # get the basal area by species columns
  yba  &lt;- MoscowMtStJoe[,1:17]
  ybaB &lt;- whatsMax(yba,nbig=7)  # see help on whatsMax
  
  ba &lt;- cbind(ybaB,TotalBA=MoscowMtStJoe[,18])
  x &lt;- MoscowMtStJoe[,37:64]
  x &lt;- x[,-(4:5)]
  rf &lt;- yai(x=x,y=ba,method="randomForest")
  
  yaiVarImp(rf)
  
  keep=colnames(yaiVarImp(rf,plot=FALSE,nTop=9))
  
  newx &lt;- x[,keep]
  rf2 &lt;- yai(x=newx,y=ba,method="randomForest")
  
  yaiVarImp(rf2,col="gray")
  
  compare.yai(rf,rf2)
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
