<!DOCTYPE html><html><head><title>Help for package surveillance</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {surveillance}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abattoir'><p>Abattoir Data</p></a></li>
<li><a href='#addFormattedXAxis'>
<p>Formatted Time Axis for <code>"sts"</code> Objects</p></a></li>
<li><a href='#addSeason2formula'>
<p>Add Harmonics to an Existing Formula</p></a></li>
<li><a href='#aggregate-methods'><p>Aggregate an <code>"sts"</code> Object Over Time or Across Units</p></a></li>
<li><a href='#aggregate.disProg'><p>Aggregate a <code>disProg</code> Object</p></a></li>
<li><a href='#algo.bayes'><p>The Bayes System</p></a></li>
<li><a href='#algo.call'><p>Query Transmission to Specified Surveillance Algorithm</p></a></li>
<li><a href='#algo.cdc'><p>The CDC Algorithm</p></a></li>
<li><a href='#algo.compare'><p>Comparison of Specified Surveillance Systems using Quality Values</p></a></li>
<li><a href='#algo.cusum'><p>CUSUM method</p></a></li>
<li><a href='#algo.farrington'><p>Surveillance for Count Time Series Using the Classic Farrington Method</p></a></li>
<li><a href='#algo.farrington.assign.weights'><p>Assign weights to base counts</p></a></li>
<li><a href='#algo.farrington.fitGLM'><p>Fit Poisson GLM of the Farrington procedure for a single time point</p></a></li>
<li><a href='#algo.farrington.threshold'><p>Compute prediction interval for a new observation</p></a></li>
<li><a href='#algo.glrnb'><p>Count Data Regression Charts</p></a></li>
<li><a href='#algo.hmm'><p>Hidden Markov Model (HMM) method</p></a></li>
<li><a href='#algo.outbreakP'><p>Semiparametric surveillance of outbreaks</p></a></li>
<li><a href='#algo.quality'><p>Computation of Quality Values for a Surveillance System Result</p></a></li>
<li><a href='#algo.rki'><p>The system used at the RKI</p></a></li>
<li><a href='#algo.rogerson'><p>Modified CUSUM method as proposed by Rogerson and Yamada (2004)</p></a></li>
<li><a href='#algo.summary'><p>Summary Table Generation for Several Disease Chains</p></a></li>
<li><a href='#algo.twins'><p>Fit a Two-Component Epidemic Model using MCMC</p></a></li>
<li><a href='#all.equal'>
<p>Test if Two Model Fits are (Nearly) Equal</p></a></li>
<li><a href='#animate'>
<p>Generic animation of spatio-temporal objects</p></a></li>
<li><a href='#anscombe.residuals'><p>Compute Anscombe Residuals</p></a></li>
<li><a href='#arlCusum'><p>Calculation of Average Run Length for discrete CUSUM schemes</p></a></li>
<li><a href='#backprojNP'>
<p>Non-parametric back-projection of incidence cases to exposure cases</p>
using a known incubation time as in Becker et al (1991)</a></li>
<li><a href='#bestCombination'><p>Partition of a number into two factors</p></a></li>
<li><a href='#boda'><p>Bayesian Outbreak Detection Algorithm (BODA)</p></a></li>
<li><a href='#bodaDelay'><p>Bayesian Outbreak Detection in the Presence of Reporting Delays</p></a></li>
<li><a href='#calibrationTest'>
<p>Calibration Tests for Poisson or Negative Binomial Predictions</p></a></li>
<li><a href='#campyDE'><p>Campylobacteriosis and Absolute Humidity in Germany 2002-2011</p></a></li>
<li><a href='#categoricalCUSUM'><p>CUSUM detector for time-varying categorical time series</p></a></li>
<li><a href='#checkResidualProcess'>
<p>Check the residual process of a fitted <code>twinSIR</code> or <code>twinstim</code></p></a></li>
<li><a href='#clapply'>
<p>Conditional <code>lapply</code></p></a></li>
<li><a href='#coeflist'>
<p>List Coefficients by Model Component</p></a></li>
<li><a href='#create.disProg'><p>Creating an object of class <code>disProg</code> (DEPRECATED)</p></a></li>
<li><a href='#deleval'><p>Surgical Failures Data</p></a></li>
<li><a href='#discpoly'><p>Polygonal Approximation of a Disc/Circle</p></a></li>
<li><a href='#disProg2sts'><p>Convert disProg object to sts and vice versa</p></a></li>
<li><a href='#earsC'><p>Surveillance for a count data time series using the EARS C1, C2</p>
or C3 method and its extensions</a></li>
<li><a href='#epidata'>
<p>Continuous-Time SIR Event History of a Fixed Population</p></a></li>
<li><a href='#epidata_animate'>
<p>Spatio-Temporal Animation of an Epidemic</p></a></li>
<li><a href='#epidata_intersperse'>
<p>Impute Blocks for Extra Stops in <code>"epidata"</code> Objects</p></a></li>
<li><a href='#epidata_plot'>
<p>Plotting the Evolution of an Epidemic</p></a></li>
<li><a href='#epidata_summary'>
<p>Summarizing an Epidemic</p></a></li>
<li><a href='#epidataCS'>
<p>Continuous Space-Time Marked Point Patterns with Grid-Based Covariates</p></a></li>
<li><a href='#epidataCS_aggregate'><p>Conversion (aggregation) of <code>"epidataCS"</code> to <code>"epidata"</code> or <code>"sts"</code></p></a></li>
<li><a href='#epidataCS_animate'>
<p>Spatio-Temporal Animation of a Continuous-Time Continuous-Space Epidemic</p></a></li>
<li><a href='#epidataCS_permute'>
<p>Randomly Permute Time Points or Locations of <code>"epidataCS"</code></p></a></li>
<li><a href='#epidataCS_plot'>
<p>Plotting the Events of an Epidemic over Time and Space</p></a></li>
<li><a href='#epidataCS_update'>
<p>Update method for <code>"epidataCS"</code></p></a></li>
<li><a href='#estimateGLRNbHook'><p>Hook function for in-control mean estimation</p></a></li>
<li><a href='#fanplot'><p>Fan Plot of Forecast Distributions</p></a></li>
<li><a href='#farringtonFlexible'><p>Surveillance for Univariate Count Time Series Using an Improved Farrington Method</p></a></li>
<li><a href='#find.kh'><p>Determine the k and h values in a standard normal setting</p></a></li>
<li><a href='#findH'><p>Find decision interval for given in-control ARL and reference value</p></a></li>
<li><a href='#findK'><p>Find Reference Value</p></a></li>
<li><a href='#fluBYBW'><p>Influenza in Southern Germany</p></a></li>
<li><a href='#formatDate'>
<p>Convert Dates to Character (Including Quarter Strings)</p></a></li>
<li><a href='#formatPval'>
<p>Pretty p-Value Formatting</p></a></li>
<li><a href='#glm_epidataCS'>
<p>Fit an Endemic-Only <code>twinstim</code> as a Poisson-<code>glm</code></p></a></li>
<li><a href='#ha'><p>Hepatitis A in Berlin</p></a></li>
<li><a href='#hagelloch'><p>1861 Measles Epidemic in the City of Hagelloch, Germany</p></a></li>
<li><a href='#hcl.colors'>
<p>HCL-based Heat Colors from the <span class="pkg">colorspace</span> Package</p></a></li>
<li><a href='#hepatitisA'><p>Hepatitis A in Germany</p></a></li>
<li><a href='#hhh4'><p>Fitting HHH Models with Random Effects and Neighbourhood Structure</p></a></li>
<li><a href='#hhh4_formula'>
<p>Specify Formulae in a Random Effects HHH Model</p></a></li>
<li><a href='#hhh4_internals'>
<p>Internal Functions Dealing with <code>hhh4</code> Models</p></a></li>
<li><a href='#hhh4_methods'>
<p>Print, Summary and other Standard Methods for <code>"hhh4"</code> Objects</p></a></li>
<li><a href='#hhh4_plot'><p>Plots for Fitted <code>hhh4</code>-models</p></a></li>
<li><a href='#hhh4_predict'><p>Predictions from a <code>hhh4</code> Model</p></a></li>
<li><a href='#hhh4_simulate'><p>Simulate <code>"hhh4"</code> Count Time Series</p></a></li>
<li><a href='#hhh4_simulate_plot'>
<p>Plot Simulations from <code>"hhh4"</code> Models</p></a></li>
<li><a href='#hhh4_simulate_scores'>
<p>Proper Scoring Rules for Simulations from <code>hhh4</code> Models</p></a></li>
<li><a href='#hhh4_update'>
<p><code>update</code> a fitted <code>"hhh4"</code> model</p></a></li>
<li><a href='#hhh4_validation'><p>Predictive Model Assessment for <code>hhh4</code> Models</p></a></li>
<li><a href='#hhh4_W'>
<p>Power-Law and Nonparametric Neighbourhood Weights for <code>hhh4</code>-Models</p></a></li>
<li><a href='#hhh4_W_utils'>
<p>Extract Neighbourhood Weights from a Fitted <code>hhh4</code> Model</p></a></li>
<li><a href='#husO104Hosp'><p>Hospitalization date for HUS cases of the STEC outbreak in Germany, 2011</p></a></li>
<li><a href='#imdepi'>
<p>Occurrence of Invasive Meningococcal Disease in Germany</p></a></li>
<li><a href='#imdepifit'>
<p>Example <code>twinstim</code> Fit for the <code>imdepi</code> Data</p></a></li>
<li><a href='#influMen'><p>Influenza and meningococcal infections in Germany, 2001-2006</p></a></li>
<li><a href='#intensityplot'>
<p>Plot Paths of Point Process Intensities</p></a></li>
<li><a href='#intersectPolyCircle'>
<p>Intersection of a Polygonal and a Circular Domain</p></a></li>
<li><a href='#isoWeekYear'><p>Find ISO Week and Year of Date Objects</p></a></li>
<li><a href='#isScalar'>
<p>Checks if the Argument is Scalar</p></a></li>
<li><a href='#knox'>
<p>Knox Test for Space-Time Interaction</p></a></li>
<li><a href='#ks.plot.unif'>
<p>Plot the ECDF of a uniform sample with Kolmogorov-Smirnov bounds</p></a></li>
<li><a href='#layout.labels'>
<p>Layout Items for <code>spplot</code></p></a></li>
<li><a href='#linelist2sts'>
<p>Convert Dates of Individual Case Reports into a</p>
Time Series of Counts</a></li>
<li><a href='#LRCUSUM.runlength'><p>Run length computation of a CUSUM detector</p></a></li>
<li><a href='#m1'><p>RKI SurvStat Data</p></a></li>
<li><a href='#magic.dim'><p>Compute Suitable k1 x k2 Layout for Plotting</p></a></li>
<li><a href='#makeControl'><p>Generate <code>control</code> Settings for an <code>hhh4</code> Model</p></a></li>
<li><a href='#marks'><p>Import from package <span class="pkg">spatstat.geom</span></p></a></li>
<li><a href='#measles.weser'><p>Measles in the Weser-Ems region of Lower Saxony, Germany, 2001-2002</p></a></li>
<li><a href='#measlesDE'><p>Measles in the 16 states of Germany</p></a></li>
<li><a href='#meningo.age'><p>Meningococcal infections in France 1985-1997</p></a></li>
<li><a href='#MMRcoverageDE'><p>MMR coverage levels in the 16 states of Germany</p></a></li>
<li><a href='#momo'><p>Danish 1994-2008 all-cause mortality data for eight age groups</p></a></li>
<li><a href='#multiplicity'><p>Import from package <span class="pkg">spatstat.geom</span></p></a></li>
<li><a href='#multiplicity.Spatial'>
<p>Count Number of Instances of Points</p></a></li>
<li><a href='#nbOrder'>
<p>Determine Neighbourhood Order Matrix from Binary Adjacency Matrix</p></a></li>
<li><a href='#nowcast'>
<p>Adjust a univariate time series of counts for observed</p>
but-not-yet-reported events</a></li>
<li><a href='#pairedbinCUSUM'><p>Paired binary CUSUM and its run-length computation</p></a></li>
<li><a href='#permutationTest'><p>Monte Carlo Permutation Test for Paired Individual Scores</p></a></li>
<li><a href='#pit'>
<p>Non-Randomized Version of the PIT Histogram (for Count Data)</p></a></li>
<li><a href='#plapply'><p>Verbose and Parallel <code>lapply</code></p></a></li>
<li><a href='#plot.atwins'><p>Plots for Fitted <code>algo.twins</code> Models</p></a></li>
<li><a href='#plot.disProg'><p>Plot Observed Counts and Defined Outbreak States of a</p>
(Multivariate) Time Series</a></li>
<li><a href='#plot.survRes'><p>Plot a <code>survRes</code> object</p></a></li>
<li><a href='#poly2adjmat'>
<p>Derive Adjacency Structure of <code>"SpatialPolygons"</code></p></a></li>
<li><a href='#polyAtBorder'><p>Indicate Polygons at the Border</p></a></li>
<li><a href='#primeFactors'><p>Prime Number Factorization</p></a></li>
<li><a href='#print.algoQV'><p>Print Quality Value Object</p></a></li>
<li><a href='#R0'><p>Computes reproduction numbers from fitted models</p></a></li>
<li><a href='#ranef'><p>Import from package <span class="pkg">nlme</span></p></a></li>
<li><a href='#refvalIdxByDate'><p>Compute indices of reference value using Date class</p></a></li>
<li><a href='#residualsCT'>
<p>Extract Cox-Snell-like Residuals of a Fitted Point Process</p></a></li>
<li><a href='#rotaBB'><p>Rotavirus cases in Brandenburg, Germany, during 2002-2013 stratified by 5 age categories</p></a></li>
<li><a href='#runifdisc'>
<p>Sample Points Uniformly on a Disc</p></a></li>
<li><a href='#salmAllOnset'><p>Salmonella cases in Germany 2001-2014 by data of symptoms onset</p></a></li>
<li><a href='#salmHospitalized'><p>Hospitalized Salmonella cases in Germany 2004-2014</p></a></li>
<li><a href='#salmNewport'><p>Salmonella Newport cases in Germany 2004-2013</p></a></li>
<li><a href='#salmonella.agona'><p>Salmonella Agona cases in the UK 1990-1995</p></a></li>
<li><a href='#scores'>
<p>Proper Scoring Rules for Poisson or Negative Binomial Predictions</p></a></li>
<li><a href='#shadar'><p>Salmonella Hadar cases in Germany 2001-2006</p></a></li>
<li><a href='#siaf.simulatePC'>
<p>Simulation from an Isotropic Spatial Kernel via Polar Coordinates</p></a></li>
<li><a href='#sim.pointSource'><p>Simulate Point-Source Epidemics</p></a></li>
<li><a href='#sim.seasonalNoise'><p>Generation of Background Noise for Simulated Timeseries</p></a></li>
<li><a href='#stcd'><p>Spatio-temporal cluster detection</p></a></li>
<li><a href='#stK'>
<p>Diggle et al (1995) K-function test for space-time clustering</p></a></li>
<li><a href='#sts_animate'>
<p>Animated Maps and Time Series of Disease Counts or Incidence</p></a></li>
<li><a href='#sts_creation'><p>Simulate Count Time Series with Outbreaks</p></a></li>
<li><a href='#sts_ggplot'>
<p>Time-Series Plots for <code>"sts"</code> Objects Using <span class="pkg">ggplot2</span></p></a></li>
<li><a href='#sts_observation'><p>Create an <code>sts</code> object with a given observation date</p></a></li>
<li><a href='#sts-class'><p>Class <code>"sts"</code> &ndash; surveillance time series</p></a></li>
<li><a href='#stsBP-class'><p>Class &quot;stsBP&quot; &ndash; a class inheriting from class <code>sts</code> which</p>
allows the user to store the results of back-projecting or nowcasting
surveillance time series</a></li>
<li><a href='#stsNC-class'><p>Class &quot;stsNC&quot; &ndash; a class inheriting from class <code>sts</code> which</p>
allows the user to store the results of back-projecting
surveillance time series</a></li>
<li><a href='#stsNClist_animate'><p>Animate a Sequence of Nowcasts</p></a></li>
<li><a href='#stsNewport'><p>Salmonella Newport cases in Germany 2001-2015</p></a></li>
<li><a href='#stsplot'><p>Plot Methods for Surveillance Time-Series Objects</p></a></li>
<li><a href='#stsplot_space'>
<p>Map of Disease Counts/Incidence accumulated over a Given Period</p></a></li>
<li><a href='#stsplot_spacetime'>
<p>Animated Map of Disease Incidence (DEPRECATED)</p></a></li>
<li><a href='#stsplot_time'>
<p>Time-Series Plots for <code>"sts"</code> Objects</p></a></li>
<li><a href='#stsSlot-generics'><p>Generic Functions to Access <code>"sts"</code> Slots</p></a></li>
<li><a href='#stsXtrct'><p>Subsetting <code>"sts"</code> Objects</p></a></li>
<li><a href='#surveillance-defunct'><p>Defunct Functions in Package <span class="pkg">surveillance</span></p></a></li>
<li><a href='#surveillance-package'><p><span class="pkg">surveillance</span>: Temporal and Spatio-Temporal Modeling and Monitoring of Epidemic Phenomena</p></a></li>
<li><a href='#surveillance.options'><p>Options of the <span class="pkg">surveillance</span> Package</p></a></li>
<li><a href='#tidy.sts'>
<p>Convert an <code>"sts"</code> Object to a Data Frame in Long (Tidy) Format</p></a></li>
<li><a href='#toLatex.sts'><p><code>toLatex</code>-Method for <code>"sts"</code> Objects</p></a></li>
<li><a href='#twinSIR'>
<p>Fit an Additive-Multiplicative Intensity Model for SIR Data</p></a></li>
<li><a href='#twinSIR_cox'>
<p>Identify Endemic Components in an Intensity Model</p></a></li>
<li><a href='#twinSIR_exData'>
<p>Toy Data for <code>twinSIR</code></p></a></li>
<li><a href='#twinSIR_intensityplot'>
<p>Plotting Paths of Infection Intensities for <code>twinSIR</code> Models</p></a></li>
<li><a href='#twinSIR_methods'>
<p>Print, Summary and Extraction Methods for <code>"twinSIR"</code> Objects</p></a></li>
<li><a href='#twinSIR_profile'>
<p>Profile Likelihood Computation and Confidence Intervals</p></a></li>
<li><a href='#twinSIR_simulation'>
<p>Simulation of Epidemic Data</p></a></li>
<li><a href='#twinstim'>
<p>Fit a Two-Component Spatio-Temporal Point Process Model</p></a></li>
<li><a href='#twinstim_epitest'><p>Permutation Test for Space-Time Interaction in <code>"twinstim"</code></p></a></li>
<li><a href='#twinstim_iaf'>
<p>Temporal and Spatial Interaction Functions for <code>twinstim</code></p></a></li>
<li><a href='#twinstim_iafplot'>
<p>Plot the Spatial or Temporal Interaction Function of a <code>twimstim</code></p></a></li>
<li><a href='#twinstim_intensity'>
<p>Plotting Intensities of Infection over Time or Space</p></a></li>
<li><a href='#twinstim_methods'>
<p>Print, Summary and Extraction Methods for <code>"twinstim"</code> Objects</p></a></li>
<li><a href='#twinstim_plot'>
<p>Plot methods for fitted <code>twinstim</code>'s</p></a></li>
<li><a href='#twinstim_profile'>
<p>Profile Likelihood Computation and Confidence Intervals for</p>
<code>twinstim</code> objects</a></li>
<li><a href='#twinstim_siaf'>
<p>Spatial Interaction Function Objects</p></a></li>
<li><a href='#twinstim_simEndemicEvents'>
<p>Quick Simulation from an Endemic-Only <code>twinstim</code></p></a></li>
<li><a href='#twinstim_simulation'>
<p>Simulation of a Self-Exciting Spatio-Temporal Point Process</p></a></li>
<li><a href='#twinstim_step'>
<p>Stepwise Model Selection by AIC</p></a></li>
<li><a href='#twinstim_tiaf'>
<p>Temporal Interaction Function Objects</p></a></li>
<li><a href='#twinstim_update'>
<p><code>update</code>-method for <code>"twinstim"</code></p></a></li>
<li><a href='#unionSpatialPolygons'>
<p>Compute the Unary Union of <code>"SpatialPolygons"</code></p></a></li>
<li><a href='#untie'>
<p>Randomly Break Ties in Data</p></a></li>
<li><a href='#wrap.algo'><p>Multivariate Surveillance through independent univariate algorithms</p></a></li>
<li><a href='#zetaweights'>
<p>Power-Law Weights According to Neighbourhood Order</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Temporal and Spatio-Temporal Modeling and Monitoring of Epidemic
Phenomena</td>
</tr>
<tr>
<td>Version:</td>
<td>1.22.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-27</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0), methods, grDevices, graphics, stats, utils, sp
(&ge; 1.0-15), xtable (&ge; 1.7-0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.1), polyCub (&ge; 0.8.0), MASS, Matrix, nlme,
spatstat.geom</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, polyCub</td>
</tr>
<tr>
<td>Suggests:</td>
<td>parallel, grid, gridExtra (&ge; 2.0.0), lattice (&ge; 0.20-44),
colorspace, scales, animation, msm, spc, coda, runjags, INLA,
spdep, numDeriv, maxLik, gsl, fanplot, hhh4contacts, quadprog,
memoise, polyclip, intervals, splancs, gamlss, MGLM (&ge; 0.1.0),
sf, tinytest (&ge; 1.2.4), knitr</td>
</tr>
<tr>
<td>Enhances:</td>
<td>xts, ggplot2</td>
</tr>
<tr>
<td>Description:</td>
<td>Statistical methods for the modeling and monitoring of time series
    of counts, proportions and categorical data, as well as for the modeling
    of continuous-time point processes of epidemic phenomena.
    The monitoring methods focus on aberration detection in count data time
    series from public health surveillance of communicable diseases, but
    applications could just as well originate from environmetrics,
    reliability engineering, econometrics, or social sciences. The package
    implements many typical outbreak detection procedures such as the
    (improved) Farrington algorithm, or the negative binomial GLR-CUSUM
    method of Hoehle and Paul (2008) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2008.02.015">doi:10.1016/j.csda.2008.02.015</a>&gt;.
    A novel CUSUM approach combining logistic and multinomial logistic
    modeling is also included. The package contains several real-world data
    sets, the ability to simulate outbreak data, and to visualize the
    results of the monitoring in a temporal, spatial or spatio-temporal
    fashion. A recent overview of the available monitoring procedures is
    given by Salmon et al. (2016) &lt;<a href="https://doi.org/10.18637%2Fjss.v070.i10">doi:10.18637/jss.v070.i10</a>&gt;.
    For the retrospective analysis of epidemic spread, the package provides
    three endemic-epidemic modeling frameworks with tools for visualization,
    likelihood inference, and simulation. hhh4() estimates models for
    (multivariate) count time series following Paul and Held (2011)
    &lt;<a href="https://doi.org/10.1002%2Fsim.4177">doi:10.1002/sim.4177</a>&gt; and Meyer and Held (2014) &lt;<a href="https://doi.org/10.1214%2F14-AOAS743">doi:10.1214/14-AOAS743</a>&gt;.
    twinSIR() models the susceptible-infectious-recovered (SIR) event
    history of a fixed population, e.g, epidemics across farms or networks,
    as a multivariate point process as proposed by Hoehle (2009)
    &lt;<a href="https://doi.org/10.1002%2Fbimj.200900050">doi:10.1002/bimj.200900050</a>&gt;. twinstim() estimates self-exciting point
    process models for a spatio-temporal point pattern of infective events,
    e.g., time-stamped geo-referenced surveillance data, as proposed by
    Meyer et al. (2012) &lt;<a href="https://doi.org/10.1111%2Fj.1541-0420.2011.01684.x">doi:10.1111/j.1541-0420.2011.01684.x</a>&gt;.
    A recent overview of the implemented space-time modeling frameworks
    for epidemic phenomena is given by Meyer et al. (2017)
    &lt;<a href="https://doi.org/10.18637%2Fjss.v077.i11">doi:10.18637/jss.v077.i11</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://surveillance.R-Forge.R-project.org/">https://surveillance.R-Forge.R-project.org/</a></td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="https://inla.r-inla-download.org/R/stable/">https://inla.r-inla-download.org/R/stable/</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>utils, knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-28 09:02:24 UTC; smeyer</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael Hoehle <a href="https://orcid.org/0000-0002-0423-6702"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ths],
  Sebastian Meyer <a href="https://orcid.org/0000-0002-1791-9449"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Michaela Paul [aut],
  Leonhard Held [ctb, ths],
  Howard Burkom [ctb],
  Thais Correa [ctb],
  Mathias Hofmann [ctb],
  Christian Lang [ctb],
  Juliane Manitz [ctb],
  Andrea Riebler [ctb],
  Daniel Sabanes Bove [ctb],
  Maelle Salmon [ctb],
  Dirk Schumacher [ctb],
  Stefan Steiner [ctb],
  Mikko Virtanen [ctb],
  Wei Wei [ctb],
  Valentin Wimmer [ctb],
  R Core Team [ctb] (A few code segments are modified versions of code
    from base R)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sebastian Meyer &lt;seb.meyer@fau.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-28 10:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='abattoir'>Abattoir Data</h2><span id='topic+abattoir'></span>

<h3>Description</h3>

<p>A synthetic dataset from the Danish meat inspection &ndash; useful
for illustrating the beta-binomial CUSUM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(abattoir)
</code></pre>


<h3>Details</h3>

<p>The object of class <code>"sts"</code> contains an artificial data set
inspired by meat inspection data used by Danish Pig Production,
Denmark. For each week the number of pigs with positive audit reports
is recorded together with the total number of audits made that week.
</p>


<h3>References</h3>

<p>Höhle, M. (2010):
Online change-point detection in categorical time series.
In: T. Kneib and G. Tutz (Eds.), Statistical
Modelling and Regression Structures, Physica-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+categoricalCUSUM">categoricalCUSUM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("abattoir")
plot(abattoir)
population(abattoir) 
</code></pre>

<hr>
<h2 id='addFormattedXAxis'>
Formatted Time Axis for <code>"sts"</code> Objects
</h2><span id='topic+addFormattedXAxis'></span><span id='topic+atChange'></span><span id='topic+at2ndChange'></span><span id='topic+atMedian'></span>

<h3>Description</h3>

<p>Add a nicely formatted x-axis to time series plots related to the
<code>"<a href="#topic+sts-class">sts</a>"</code> class. This utility function is, e.g., used
by <code><a href="#topic+stsplot_time1">stsplot_time1</a></code> and <code><a href="#topic+plotHHH4_fitted1">plotHHH4_fitted1</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addFormattedXAxis(x, epochsAsDate = FALSE,
                  xaxis.tickFreq = list("%Q"=atChange),
                  xaxis.labelFreq = xaxis.tickFreq,
                  xaxis.labelFormat = "%G\n\n%OQ",
                  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addFormattedXAxis_+3A_x">x</code></td>
<td>

<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.
</p>
</td></tr>
<tr><td><code id="addFormattedXAxis_+3A_epochsasdate">epochsAsDate</code></td>
<td>

<p>a logical indicating if the old (<code>FALSE</code>) or the new
(<code>TRUE</code>) and more flexible implementation should be used.
The <code>xaxis.*</code> arguments are only relevant for the new
implementation <code>epochsAsDate = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="addFormattedXAxis_+3A_xaxis.labelformat">xaxis.labelFormat</code>, <code id="addFormattedXAxis_+3A_xaxis.tickfreq">xaxis.tickFreq</code>, <code id="addFormattedXAxis_+3A_xaxis.labelfreq">xaxis.labelFreq</code></td>
<td>

<p>see the details below.
</p>
</td></tr>
<tr><td><code id="addFormattedXAxis_+3A_...">...</code></td>
<td>

<p>further arguments passed to <code><a href="graphics.html#topic+axis">axis</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The setting <code>epochsAsDate = TRUE</code>
enables very flexible formatting of the x-axis and its
annotations using the <code>xaxis.tickFreq</code>, <code>xaxis.labelFreq</code>
and <code>xaxis.labelFormat</code> arguments. The first two are named lists containing
pairs with the <em>name</em> being a <code><a href="base.html#topic+strftime">strftime</a></code> single
conversion specification and the second part is a function which based
on this conversion returns a subset of the rows in the <code>sts</code>
objects. The subsetting function has the following header:
<code>function(x,xm1)</code>, where <code>x</code> is a vector containing
the result of applying the conversion in <code>name</code> to the epochs of
the <code>sts</code> object and <code>xm1</code> is the scalar result when
applying the conversion to the natural element just before the first
epoch. Please note that the input to the subsetting function is converted
using <code>as.numeric</code> before calling the function. Hence, the
conversion specification needs to result in a string convertible to integer.
</p>
<p>Three predefined subsetting functions exist:
<code>atChange</code>, <code>at2ndChange</code>  and <code>atMedian</code>, which
are used to make a tick at each (each 2nd for <code>at2ndChange</code>)
change and at the median index computed on all having the same value,
respectively:
</p>
<pre>
    atChange &lt;- function(x,xm1) which(diff(c(xm1,x)) != 0)
    at2ndChange &lt;- function(x,xm1) which(diff(c(xm1,x) %/% 2) != 0)
    atMedian &lt;- function(x,xm1) tapply(seq_along(x), INDEX=x, quantile, prob=0.5, type=3)
  </pre>
<p>By defining own functions here, one can obtain an arbitrary degree of
flexibility.
</p>
<p>Finally, <code>xaxis.labelFormat</code> is a <code><a href="base.html#topic+strftime">strftime</a></code>
compatible formatting string., e.g. the default value is
<code>"%G\n\n%OQ"</code>, which means ISO year and quarter (in roman
letters) stacked on top of each other.
</p>


<h3>Value</h3>

<p><code>NULL</code> (invisibly). The function is called for its side effects.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle with contributions by Sebastian Meyer
</p>


<h3>See Also</h3>

<p>the examples in <code><a href="#topic+stsplot_time1">stsplot_time1</a></code> and <code><a href="#topic+plotHHH4_fitted1">plotHHH4_fitted1</a></code>
</p>

<hr>
<h2 id='addSeason2formula'>
Add Harmonics to an Existing Formula
</h2><span id='topic+addSeason2formula'></span>

<h3>Description</h3>

<p>This function helps to construct a <code><a href="stats.html#topic+formula">formula</a></code> object that
can be used in a call to <code><a href="#topic+hhh4">hhh4</a></code> to model 
seasonal variation via a sum of sine and cosine terms. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addSeason2formula(f = ~1, S = 1, period = 52, timevar = "t")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addSeason2formula_+3A_f">f</code></td>
<td>

<p>formula that the seasonal terms should be added to, 
defaults to an intercept <code>~1</code>.
</p>
</td></tr>
<tr><td><code id="addSeason2formula_+3A_s">S</code></td>
<td>

<p>number of sine and cosine terms. If <code>S</code> is a vector, 
unit-specific seasonal terms are created.
</p>
</td></tr>
<tr><td><code id="addSeason2formula_+3A_period">period</code></td>
<td>

<p>period of the season, defaults to 52 for weekly data.
</p>
</td></tr>
<tr><td><code id="addSeason2formula_+3A_timevar">timevar</code></td>
<td>

<p>the time variable in the model. Defaults to <code>"t"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function adds the seasonal terms
</p>
<p style="text-align: center;"><code class="reqn">
    \sin( s \cdot 2\pi \cdot \code{timevar}/\code{period} ),\;
    \cos( s \cdot 2\pi \cdot \code{timevar}/\code{period} ),
  </code>
</p>

<p>for <code class="reqn">s = 1,\dots,\code{S}</code> to an existing formula <code>f</code>.
</p>
<p>Note the following equivalence when interpreting the coefficients of
the seasonal terms:
</p>
<p style="text-align: center;"><code class="reqn">
    \gamma \sin(\omega t) + \delta \cos(\omega t) = 
    A \sin(\omega t + \epsilon)
  </code>
</p>

<p>with amplitude <code class="reqn">A = \sqrt{\gamma^2 + \delta^2}</code>
and phase shift <code class="reqn">\epsilon = \arctan(\delta / \gamma)</code>. 
The amplitude and phase shift can be obtained from a fitted
<code><a href="#topic+hhh4">hhh4</a></code> model via <code>coef(..., amplitudeShift = TRUE)</code>,
see <code><a href="#topic+coef.hhh4">coef.hhh4</a></code>.
</p>


<h3>Value</h3>

<p>Returns a <code><a href="stats.html#topic+formula">formula</a></code> with the seasonal terms added and 
its environment set to <code><a href="base.html#topic+.GlobalEnv">.GlobalEnv</a></code>.
Note that to use the resulting formula in <code><a href="#topic+hhh4">hhh4</a></code>, 
a time variable named as specified by the argument <code>timevar</code> must
be available.
</p>


<h3>Author(s)</h3>

<p>M. Paul, with contributions by S. Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hhh4">hhh4</a></code>, <code><a href="#topic+fe">fe</a></code>, <code><a href="#topic+ri">ri</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># add 2 sine/cosine terms to a model with intercept and linear trend
addSeason2formula(f = ~ 1 + t, S = 2)

# the same for monthly data
addSeason2formula(f = ~ 1 + t, S = 2, period = 12)

# different number of seasons for a bivariate time series
addSeason2formula(f = ~ 1, S = c(3, 1), period = 52)
</code></pre>

<hr>
<h2 id='aggregate-methods'>Aggregate an <code>"sts"</code> Object Over Time or Across Units</h2><span id='topic+aggregate.sts'></span><span id='topic+aggregate+2Csts-method'></span>

<h3>Description</h3>

<p>Aggregate the matrix slots of an <code>"<a href="#topic+sts-class">sts</a>"</code> object.
Either the time series is aggregated so a new sampling frequency of
<code>nfreq</code> observations per year is obtained (i.e., as in
<code><a href="stats.html#topic+aggregate.ts">aggregate.ts</a></code>), or the aggregation is over all
columns (units).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'sts'
aggregate(x, by = "time", nfreq = "all", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate-methods_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.</p>
</td></tr>
<tr><td><code id="aggregate-methods_+3A_by">by</code></td>
<td>
<p>a string being either <code>"time"</code> or <code>"unit"</code>.</p>
</td></tr>
<tr><td><code id="aggregate-methods_+3A_nfreq">nfreq</code></td>
<td>
<p>new sampling frequency for <code>by="time"</code>. If
<code>nfreq="all"</code> then all time points are summed.</p>
</td></tr>
<tr><td><code id="aggregate-methods_+3A_...">...</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"sts"</code>.
</p>


<h3>Warning</h3>

<p>Aggregation over units fills the upperbound slot with
<code>NA</code>s and the <code>map</code> slot is left as-is, but the object 
cannot be plotted by unit any longer.
</p>
<p>The <code>populationFrac</code> slot is aggregated just like <code>observed</code>.
Population fractions are recomputed if and only if <code>x</code> is no
<code>multinomialTS</code> and already contains population fractions.
This might not be intended, especially for aggregation over time.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ha.sts")
dim(ha.sts)
dim(aggregate(ha.sts, by = "unit"))
dim(aggregate(ha.sts, nfreq = 13))

</code></pre>

<hr>
<h2 id='aggregate.disProg'>Aggregate a <code>disProg</code> Object</h2><span id='topic+aggregate.disProg'></span>

<h3>Description</h3>

<p>Aggregates the observed counts of a multivariate
<code>disProg</code> object over the units.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'disProg'
aggregate(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate.disProg_+3A_x">x</code></td>
<td>
<p>Object of class <code>disProg</code></p>
</td></tr>
<tr><td><code id="aggregate.disProg_+3A_...">...</code></td>
<td>
<p>not used at the moment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>univariate <code>disProg</code> object with aggregated 
counts and respective states for each time point.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ha)
dim(ha$observed)
dim(aggregate(ha)$observed)
</code></pre>

<hr>
<h2 id='algo.bayes'>The Bayes System</h2><span id='topic+algo.bayes'></span><span id='topic+algo.bayesLatestTimepoint'></span><span id='topic+algo.bayes1'></span><span id='topic+algo.bayes2'></span><span id='topic+algo.bayes3'></span>

<h3>Description</h3>

<p>Evaluation of timepoints with the Bayes subsystem
1, 2, 3 or a self defined Bayes subsystem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  algo.bayesLatestTimepoint(disProgObj, timePoint = NULL,
       control = list(b = 0, w = 6, actY = TRUE,alpha=0.05))
  algo.bayes(disProgObj, control = list(range = range,
       b = 0, w = 6, actY = TRUE,alpha=0.05))
  algo.bayes1(disProgObj, control = list(range = range))
  algo.bayes2(disProgObj, control = list(range = range))
  algo.bayes3(disProgObj, control = list(range = range))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.bayes_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class disProg (including the observed and the state chain)</p>
</td></tr>
<tr><td><code id="algo.bayes_+3A_timepoint">timePoint</code></td>
<td>
<p>time point which should be evaluated in
<code>algo.bayes LatestTimepoint</code>. The
default is to use the latest timepoint</p>
</td></tr>
<tr><td><code id="algo.bayes_+3A_control">control</code></td>
<td>
<p>control object: <code>range</code> determines the desired
timepoints which should be evaluated, <code>b</code> describes the number of years to go
back for the reference values, <code>w</code> is the half window width for the reference
values around the appropriate timepoint and <code>actY</code> is a boolean to decide if
the year of <code>timePoint</code> also contributes <code>w</code> reference values. The parameter <code>alpha</code> is the <code class="reqn">(1-\alpha)</code>-quantile to use in order to calculate the upper threshold.
As default <code>b</code>, <code>w</code>, <code>actY</code> are set for the Bayes 1 system with <code>alpha</code>=0.05.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using the reference values the <code class="reqn">(1-\alpha)\cdot
    100\%</code> quantile of the
predictive posterior distribution is calculated as a threshold.
An alarm is given if the actual value is bigger or equal than this threshold.
It is possible to show using analytical computations that the predictive
posterior in this case is the negative
binomial distribution. Note: <code>algo.rki</code> or <code>algo.farrington</code>
use two-sided prediction intervals &ndash; if one wants to compare with
these procedures it is necessary to use an alpha, which is half the
one used for these procedures.
</p>
<p>Note also that <code>algo.bayes</code> calls
<code>algo.bayesLatestTimepoint</code> for the values specified in
<code>range</code> and for the system specified in <code>control</code>.
<code>algo.bayes1</code>, <code>algo.bayes2</code>, <code>algo.bayes3</code> call
<code>algo.bayesLatestTimepoint</code> for the values specified in
<code>range</code> for the Bayes 1 system, Bayes 2 system or Bayes 3 system.
</p>

<ul>
<li> <p><code>"Bayes 1"</code> reference values from 6 weeks. Alpha is fixed a
t 0.05.
</p>
</li>
<li> <p><code>"Bayes 2"</code> reference values from 6 weeks ago and
13 weeks of the previous year (symmetrical around the
same week as the current one in the previous year). Alpha is fixed at 0.05.
</p>
</li>
<li> <p><code>"Bayes 3"</code>  18 reference values. 9 from the year ago
and 9 from two years ago (also symmetrical around the
comparable week). Alpha is fixed at 0.05.
</p>
</li></ul>

<p>The procedure is now able to handle <code>NA</code>'s in the reference
values. In the summation and when counting the number of observed
reference values these are simply not counted.
</p>


<h3>Value</h3>

<table>
<tr><td><code>survRes</code></td>
<td>

<p><code>algo.bayesLatestTimepoint</code> returns a list of class <code>survRes</code> (surveillance result), which
includes the alarm value for recognizing an
outbreak (1 for alarm, 0 for no alarm), the threshold value for recognizing the alarm and
the input object of class disProg.
<code>algo.bayes</code> gives a list of class <code>survRes</code> which includes the vector
of alarm values for every timepoint in <code>range</code> and the vector of threshold values
for every timepoint in <code>range</code> for the system specified by <code>b</code>, <code>w</code> and
<code>actY</code>, the range and the input object of class disProg.
<code>algo.bayes1</code> returns the same for the Bayes 1 system, <code>algo.bayes2</code>
for the Bayes 2 system and <code>algo.bayes3</code> for the Bayes 3 system.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>M. Höhle, A. Riebler, C. Lang</p>


<h3>Source</h3>

<p>Riebler, A. (2004), Empirischer Vergleich von statistischen Methoden zur
Ausbruchserkennung bei Surveillance Daten, Bachelor's thesis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.call">algo.call</a></code>, <code><a href="#topic+algo.rkiLatestTimepoint">algo.rkiLatestTimepoint</a></code> and <code><a href="#topic+algo.rki">algo.rki</a></code> for
the RKI system.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    disProg &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 208, A = 1,
                                    alpha = 1, beta = 0, phi = 0,
                                    frequency = 1, state = NULL, K = 1.7)

    # Test for bayes 1 the latest timepoint
    algo.bayesLatestTimepoint(disProg)

    # Test week 200 to 208 for outbreaks with a selfdefined bayes
    algo.bayes(disProg, control = list(range = 200:208, b = 1,
                                                w = 5, actY = TRUE,alpha=0.05))
    # The same for bayes 1 to bayes 3
    algo.bayes1(disProg, control = list(range = 200:208,alpha=0.05))
    algo.bayes2(disProg, control = list(range = 200:208,alpha=0.05))
    algo.bayes3(disProg, control = list(range = 200:208,alpha=0.05))
</code></pre>

<hr>
<h2 id='algo.call'>Query Transmission to Specified Surveillance Algorithm</h2><span id='topic+algo.call'></span>

<h3>Description</h3>

<p>Transmission of a object of class disProg to the specified surveillance algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    algo.call(disProgObj, control = list(
                     list(funcName = "rki1", range = range),
                     list(funcName = "rki", range = range,
                          b = 2, w = 4, actY = TRUE),
                     list(funcName = "rki", range = range,
                          b = 2, w = 5, actY = TRUE)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.call_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class disProg, which includes the state chain and the observed</p>
</td></tr>
<tr><td><code id="algo.call_+3A_control">control</code></td>
<td>
<p>specifies which surveillance algorithm should be used with their parameters.
The parameter <code>funcName</code> and <code>range</code> must be
specified. Here, <code>funcName</code> is the appropriate
method function (without '<code>algo.</code>') and <code>range</code> defines
the timepoints to be evaluated by the actual system.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of survRes objects generated by the specified surveillance algorithm
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.rki">algo.rki</a></code>, <code><a href="#topic+algo.bayes">algo.bayes</a></code>, <code><a href="#topic+algo.farrington">algo.farrington</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a test object
disProg &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 400, A = 1,
                           alpha = 1, beta = 0, phi = 0,
                           frequency = 1, state = NULL, K = 1.7)

# Let this object be tested from any methods in range = 200:400
range &lt;- 200:400
survRes &lt;- algo.call(disProg,
                     control = list(
                         list(funcName = "rki1", range = range),
                         list(funcName = "rki2", range = range),
                         list(funcName = "rki3", range = range),
                         list(funcName = "rki", range = range,
                              b = 3, w = 2, actY = FALSE),
                         list(funcName = "rki", range = range,
                              b = 2, w = 9, actY = TRUE),
                         list(funcName = "bayes1", range = range),
                         list(funcName = "bayes2", range = range),
                         list(funcName = "bayes3", range = range),
                         list(funcName = "bayes",
                              range = range, b = 1, w = 5, actY = TRUE,alpha=0.05)
                     ))
# show selected survRes objects
names(survRes)
plot(survRes[["rki(6,6,0)"]])
survRes[["bayes(5,5,1)"]]
</code></pre>

<hr>
<h2 id='algo.cdc'>The CDC Algorithm</h2><span id='topic+algo.cdcLatestTimepoint'></span><span id='topic+algo.cdc'></span>

<h3>Description</h3>

<p>Surveillance using the CDC Algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.cdcLatestTimepoint(disProgObj, timePoint = NULL,
                        control = list(b = 5, m = 1, alpha=0.025))
algo.cdc(disProgObj, control = list(range = range, b= 5, m=1, 
         alpha = 0.025))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.cdc_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class disProg (including the observed and the state chain).</p>
</td></tr>
<tr><td><code id="algo.cdc_+3A_timepoint">timePoint</code></td>
<td>
<p>time point which should be evaluated in <code>algo.cdcLatestTimepoint</code>. The
default is to use the latest timepoint.</p>
</td></tr>
<tr><td><code id="algo.cdc_+3A_control">control</code></td>
<td>
<p>control object: <code>range</code> determines the desired
timepoints which should be evaluated, <code>b</code> describes the number of years to go
back for the reference values, <code>m</code> is the half window width for the reference
values around the appropriate timepoint (see details).
The standard definition is <code>b</code>=5 and <code>m</code>=1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using the reference values for calculating an upper limit, alarm is
given if the actual value is bigger than a computed threshold.
<code>algo.cdc</code> calls <code>algo.cdcLatestTimepoint</code> for the values
specified in <code>range</code> and for the system specified in
<code>control</code>.  The threshold is calculated from the predictive
distribution, i.e.  </p>
<p style="text-align: center;"><code class="reqn">mean(x) + z_{\alpha/2} * sd(x) * \sqrt{1+1/k},</code>
</p>

<p>which corresponds to Equation 8-1 in Farrington and Andrews (2003).
Note that an aggregation into 4-week blocks occurs in
<code>algo.cdcLatestTimepoint</code> and <code>m</code> denotes number of 4-week
blocks (months) to use as reference values. This function currently
does the same for monthly data (not correct!)
</p>


<h3>Value</h3>

<p><code>algo.cdcLatestTimepoint</code> returns a list of class <code>survRes</code> (surveillance result), which
includes the alarm value (alarm = 1, no alarm = 0) for recognizing an
outbreak, the threshold value for recognizing the alarm and
the input object of class disProg.
</p>
<p><code>algo.cdc</code> gives a list of class <code>survRes</code> which
includes the vector of alarm values for every timepoint in
<code>range</code>, the vector of threshold values for every timepoint
in <code>range</code> for the system specified by <code>b</code>, <code>w</code>,
the range and the input object of class disProg.
</p>


<h3>Author(s)</h3>

<p>M. Höhle</p>


<h3>References</h3>

<p>Stroup, D., G. Williamson, J. Herndon, and J. Karon (1989). Detection
of aberrations in the occurence of notifiable diseases surveillance data.
Statistics in Medicine 8, 323-329. 
</p>
<p>Farrington, C. and N. Andrews (2003). Monitoring the Health of
Populations, Chapter Outbreak Detection: Application to Infectious
Disease Surveillance, pp. 203-231. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.rkiLatestTimepoint">algo.rkiLatestTimepoint</a></code>,<code><a href="#topic+algo.bayesLatestTimepoint">algo.bayesLatestTimepoint</a></code>
and <code><a href="#topic+algo.bayes">algo.bayes</a></code> for the Bayes system.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a test object
disProgObj &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 500, 
                              A = 1,alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 1.7)

# Test week 200 to 208 for outbreaks with a selfdefined cdc
algo.cdc(disProgObj, control = list(range = 400:500,alpha=0.025))
</code></pre>

<hr>
<h2 id='algo.compare'>Comparison of Specified Surveillance Systems using Quality Values</h2><span id='topic+algo.compare'></span>

<h3>Description</h3>

<p>Comparison of specified surveillance algorithms using quality values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.compare(survResList)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.compare_+3A_survreslist">survResList</code></td>
<td>
<p>a list of survRes objects to compare via quality values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with values from <code><a href="#topic+algo.quality">algo.quality</a></code>, i.e. quality
values for every surveillance algorithm found in <code>survResults</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.quality">algo.quality</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a test object
disProgObj &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 400,
                              A = 1, alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 1.7)

# Let this object be tested from any methods in range = 200:400
range &lt;- 200:400
survRes &lt;- algo.call(disProgObj,
                     control = list(
                         list(funcName = "rki1", range = range),
                         list(funcName = "rki2", range = range),
                         list(funcName = "rki3", range = range),
                         list(funcName = "rki", range = range,
                              b = 3, w = 2, actY = FALSE),
                         list(funcName = "rki", range = range,
                              b = 2, w = 9, actY = TRUE),
                         list(funcName = "bayes1", range = range),
                         list(funcName = "bayes2", range = range),
                         list(funcName = "bayes3", range = range),
                         list(funcName = "bayes",
                              range = range, b = 1, w = 5, actY = TRUE,alpha=0.05)
                     ))
algo.compare(survRes)
</code></pre>

<hr>
<h2 id='algo.cusum'>CUSUM method</h2><span id='topic+algo.cusum'></span>

<h3>Description</h3>

 
<p>Approximate one-side CUSUM method for a Poisson variate based on the 
cumulative sum of the deviation between a reference value k and the 
transformed observed values.
An alarm is raised if the cumulative sum equals or exceeds a prespecified
decision boundary h. The function can handle time varying expectations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.cusum(disProgObj, control = list(range = range, k = 1.04, h = 2.26, 
           m = NULL, trans = "standard", alpha = NULL))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.cusum_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class disProg (including the observed and the state chain)</p>
</td></tr>
<tr><td><code id="algo.cusum_+3A_control">control</code></td>
<td>
<p>control object: 
</p>

<dl>
<dt><code>range</code></dt><dd><p>determines the desired time points which should be evaluated</p>
</dd>
<dt><code>k</code></dt><dd><p>is the reference value</p>
</dd>
<dt><code>h</code></dt><dd><p>the decision boundary</p>
</dd>
<dt><code>m</code></dt><dd><p>how to determine the expected number of cases &ndash; 
the following arguments are possible
</p>

<dl>
<dt><code>numeric</code></dt><dd><p>a vector of values having the
same length as <code>range</code>. If a single numeric
value is specified then this value is replicated
<code>length(range)</code> times.</p>
</dd>
<dt><code>NULL</code></dt><dd><p>A single value is estimated by
taking the mean of all observations previous to
the first <code>range</code> value.</p>
</dd>
<dt><code>"glm"</code></dt><dd><p> A GLM of the form </p>
<p style="text-align: center;"><code class="reqn">\log(m_t)
                      = \alpha + \beta t + \sum_{s=1}^S (\gamma_s
                      \sin(\omega_s t) + \delta_s \cos(\omega_s t)),</code>
</p>

<p>where <code class="reqn">\omega_s = \frac{2\pi}{52}s</code> are the
Fourier frequencies is fitted. Then this model is
used to predict the <code>range</code> values.</p>
</dd>
</dl>
</dd>
<dt><code>trans</code></dt><dd><p>one of the following transformations (warning: Anscombe and NegBin transformations are experimental)
</p>

<dl>
<dt><code>rossi</code></dt><dd><p>standardized variables z3 as proposed by Rossi</p>
</dd>
<dt><code>standard</code></dt><dd><p>standardized variables z1 (based
on asymptotic normality) - This is the default.</p>
</dd>
<dt><code>anscombe</code></dt><dd><p>anscombe residuals &ndash; experimental</p>
</dd>
<dt><code>anscombe2nd</code></dt><dd><p> anscombe residuals as in Pierce and Schafer (1986) based on 2nd order approximation of E(X)  &ndash; experimental</p>
</dd>
<dt><code>pearsonNegBin</code></dt><dd><p>compute Pearson residuals for NegBin &ndash; experimental</p>
</dd>
<dt><code>anscombeNegBin</code></dt><dd><p>anscombe residuals for NegBin &ndash; experimental</p>
</dd>
<dt><code>none</code></dt><dd><p> no transformation</p>
</dd>
</dl>

</dd>
<dt><code>alpha</code></dt><dd><p>parameter of the negative binomial distribution, s.t. the variance is <code class="reqn">m+\alpha *m^2</code> </p>
</dd>
</dl>

</td></tr>
</table>


<h3>Value</h3>

<p><code>algo.cusum</code> gives a list of class <code>"survRes"</code> which includes the 
vector of alarm values for every timepoint in <code>range</code> and the vector 
of cumulative sums for every timepoint in <code>range</code> for the system 
specified by <code>k</code> and <code>h</code>, the range and the input object of 
class <code>"disProg"</code>.
</p>
<p>The <code>upperbound</code> entry shows for each time instance the number of diseased individuals
it would have taken the cusum to signal. Once the CUSUM signals no resetting is applied, i.e.
signals occurs until the CUSUM statistic again returns below the threshold.
</p>
<p>In case <code>control$m="glm"</code> was used, the returned
<code>control$m.glm</code> entry contains the fitted <code>"glm"</code> object.
</p>


<h3>Note</h3>

<p>This implementation is experimental, but will not be developed further.</p>


<h3>Author(s)</h3>

<p>M. Paul and M. Höhle</p>


<h3>References</h3>

<p>G. Rossi, L. Lampugnani and M. Marchi (1999), An approximate CUSUM procedure for surveillance of health events, Statistics in Medicine, 18, 2111&ndash;2122
</p>
<p>D. A. Pierce and D. W. Schafer (1986), Residuals in Generalized Linear Models, Journal of the American Statistical Association, 81, 977&ndash;986
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Xi ~ Po(5), i=1,...,500
set.seed(321)
stsObj &lt;- sts(observed = rpois(500,lambda=5))
# there should be no alarms as mean doesn't change
res &lt;- cusum(stsObj, control = list(range = 100:500, trans = "anscombe"))
plot(res, xaxis.labelFormat = NULL)

# simulated data
disProgObj &lt;- sim.pointSource(p = 1, r = 1, length = 250,
                              A = 0, alpha = log(5), beta = 0, phi = 10,
                              frequency = 10, state = NULL, K = 0)
plot(disProgObj)

# Test weeks 200 to 250 for outbreaks
surv0 &lt;- algo.cusum(disProgObj, control = list(range = 200:250))
plot(surv0, xaxis.years = FALSE)

# alternatively, using the newer "sts" interface
stsObj &lt;- disProg2sts(disProgObj)
surv &lt;- cusum(stsObj, control = list(range = 200:250))
plot(surv)
stopifnot(upperbound(surv) == surv0$upperbound)
</code></pre>

<hr>
<h2 id='algo.farrington'>Surveillance for Count Time Series Using the Classic Farrington Method</h2><span id='topic+algo.farrington'></span><span id='topic+farrington'></span>

<h3>Description</h3>

<p>Implements the procedure of Farrington et al. (1996).
At each time point of the specified <code>range</code>, a GLM is fitted to
predict the counts. This is then compared to the observed
counts. If the observation is above a specific quantile of
the prediction interval, then an alarm is raised.
</p>


<h3>Usage</h3>

<pre><code class='language-R'># original interface for a single "disProg" time series
algo.farrington(disProgObj, control=list(
    range=NULL, b=5, w=3, reweight=TRUE, verbose=FALSE, plot=FALSE,
    alpha=0.05, trend=TRUE, limit54=c(5,4), powertrans="2/3",
    fitFun="algo.farrington.fitGLM.fast"))

# wrapper for "sts" data, possibly multivariate
farrington(sts, control=list(
    range=NULL, b=5, w=3, reweight=TRUE, verbose=FALSE,
    alpha=0.05), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.farrington_+3A_disprogobj">disProgObj</code></td>
<td>

<p>an object of class <code>"disProg"</code> (a list including <code>observed</code> and
<code>state</code> time series).
</p>
</td></tr>
<tr><td><code id="algo.farrington_+3A_control">control</code></td>
<td>
<p>list of control parameters
</p>

<dl>
<dt><code>range</code></dt><dd><p>Specifies the index of all timepoints which
should be tested. If range is <code>NULL</code> the maximum number
of possible weeks is used (i.e. as many weeks as possible while
still having enough reference values).</p>
</dd>
<dt><code>b</code></dt><dd><p>how many years back in time to include when
forming the base counts.</p>
</dd>
<dt><code>w</code></dt><dd><p>windows size, i.e. number of weeks to include
before and after the current week</p>
</dd>
<dt><code>reweight</code></dt><dd><p>Boolean specifying whether to perform reweight step</p>
</dd>
<dt><code>trend</code></dt><dd><p>If <code>TRUE</code> a trend is included and kept in
case the conditions documented in Farrington et al. (1996) are met
(see the results). If <code>FALSE</code> then NO trend is fit.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Boolean indicating whether to show extra debugging information.</p>
</dd>
<dt><code>plot</code></dt><dd><p>Boolean specifying whether to show the final GLM model fit graphically (use
History|Recording to see all pictures).</p>
</dd>
<dt><code>powertrans</code></dt><dd><p>Power transformation to apply to the
data. Use either &quot;2/3&quot; for skewness correction (Default),
&quot;1/2&quot; for variance stabilizing transformation or &quot;none&quot; for no
transformation.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>An approximate (two-sided) <code class="reqn">(1-\alpha)</code>
prediction interval is calculated.</p>
</dd>
<dt><code>limit54</code></dt><dd><p>To avoid alarms in cases where the time series only
has about 0-2 cases the algorithm uses the following heuristic
criterion (see Section 3.8 of the Farrington paper) to protect
against low counts: no alarm is sounded if fewer than
<code class="reqn">cases=5</code> reports were received in the past <code class="reqn">period=4</code>
weeks. <code>limit54=c(cases,period)</code> is a vector allowing the
user to change these numbers. Note: As of version 0.9-7 the
term &quot;last&quot; period of weeks includes the current week -
otherwise no alarm is sounded for horrible large numbers if
the four weeks before that are too low.</p>
</dd>
<dt><code>fitFun</code></dt><dd><p>String containing the name of the fit
function to be used for fitting the GLM. The options are
<code>algo.farrington.fitGLM.fast</code> (default) and
<code>algo.farrington.fitGLM</code> or 
<code>algo.farrington.fitGLM.populationOffset</code>. See details of
<code><a href="#topic+algo.farrington.fitGLM">algo.farrington.fitGLM</a></code> for more information.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="algo.farrington_+3A_sts">sts</code></td>
<td>
<p>an object of class <code>"<a href="#topic+sts">sts</a>"</code>.</p>
</td></tr>
<tr><td><code id="algo.farrington_+3A_...">...</code></td>
<td>
<p>arguments for <code><a href="#topic+wrap.algo">wrap.algo</a></code>,
e.g., <code>verbose=FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following steps are performed according to the Farrington
et al. (1996) paper.
</p>

<ol>
<li><p> fit of the initial model and initial estimation of mean and
overdispersion.
</p>
</li>
<li><p> calculation of the weights omega (correction for past outbreaks)
</p>
</li>
<li><p> refitting of the model
</p>
</li>
<li><p> revised estimation of overdispersion
</p>
</li>
<li><p> rescaled model
</p>
</li>
<li><p> omission of the trend, if it is not significant
</p>
</li>
<li><p> repetition of the whole procedure
</p>
</li>
<li><p> calculation of the threshold value
</p>
</li>
<li><p> computation of exceedance score
</p>
</li></ol>



<h3>Value</h3>

<p>For <code>algo.farrington</code>, a list object of class <code>"survRes"</code>
with elements <code>alarm</code>, <code>upperbound</code>, <code>trend</code>,
<code>disProgObj</code>, and <code>control</code>.
</p>
<p>For <code>farrington</code>, the input <code>"<a href="#topic+sts">sts</a>"</code> object with updated
<code>alarm</code>, <code>upperbound</code> and <code>control</code> slots, and subsetted
to <code>control$range</code>.
</p>


<h3>Author(s)</h3>

<p>M. Höhle</p>


<h3>References</h3>

<p>A statistical algorithm for the early detection of outbreaks of
infectious disease, Farrington, C.P., Andrews, N.J, Beale A.D. and
Catchpole, M.A. (1996), J. R. Statist. Soc. A, 159, 547-563.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.farrington.fitGLM">algo.farrington.fitGLM</a></code>,
<code><a href="#topic+algo.farrington.threshold">algo.farrington.threshold</a></code>
</p>
<p>An improved Farrington algorithm is available as function
<code><a href="#topic+farringtonFlexible">farringtonFlexible</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#load "disProg" data
data("salmonella.agona")

#Do surveillance for the last 42 weeks
n &lt;- length(salmonella.agona$observed)
control &lt;- list(b=4,w=3,range=(n-42):n,reweight=TRUE, verbose=FALSE,alpha=0.01)
res &lt;- algo.farrington(salmonella.agona,control=control)
plot(res)

#Generate Poisson counts and create an "sts" object
set.seed(123)
x &lt;- rpois(520,lambda=1)
stsObj &lt;- sts(observed=x, frequency=52)


#Compare timing of the two possible fitters for algo.farrington
range &lt;- 312:520
system.time( sts1 &lt;- farrington(stsObj, control=list(range=range,
                       fitFun="algo.farrington.fitGLM.fast"), verbose=FALSE))
system.time( sts2 &lt;- farrington(stsObj, control=list(range=range,
                       fitFun="algo.farrington.fitGLM"), verbose=FALSE))
#Check if results are the same
stopifnot(upperbound(sts1) == upperbound(sts2))

</code></pre>

<hr>
<h2 id='algo.farrington.assign.weights'>Assign weights to base counts</h2><span id='topic+algo.farrington.assign.weights'></span>

<h3>Description</h3>

<p>Weights are assigned according to the Anscombe residuals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.farrington.assign.weights(s, weightsThreshold=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.farrington.assign.weights_+3A_s">s</code></td>
<td>
<p>Vector of standardized Anscombe residuals</p>
</td></tr>
<tr><td><code id="algo.farrington.assign.weights_+3A_weightsthreshold">weightsThreshold</code></td>
<td>
<p>A scalar indicating when observations are seen
as outlier. In the original Farrington proposal the value was 1
(default value), in the improved version this value is suggested to be 2.58.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Weights according to the residuals</p>


<h3>See Also</h3>

<p><code><a href="#topic+anscombe.residuals">anscombe.residuals</a></code></p>

<hr>
<h2 id='algo.farrington.fitGLM'>Fit Poisson GLM of the Farrington procedure for a single time point</h2><span id='topic+algo.farrington.fitGLM'></span><span id='topic+algo.farrington.fitGLM.fast'></span><span id='topic+algo.farrington.fitGLM.populationOffset'></span>

<h3>Description</h3>

<p>The function fits a Poisson regression model (GLM) with mean predictor
</p>
<p style="text-align: center;"><code class="reqn">\log \mu_t = \alpha + \beta t</code>
</p>

<p>as specified by the Farrington procedure. If 
requested, Anscombe residuals are computed based on an initial fit
and a 2nd fit is made using weights, where base counts suspected to
be caused by earlier outbreaks are downweighted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.farrington.fitGLM(response, wtime, timeTrend = TRUE,
                       reweight = TRUE, ...)
algo.farrington.fitGLM.fast(response, wtime, timeTrend = TRUE,
                            reweight = TRUE, ...)
algo.farrington.fitGLM.populationOffset(response, wtime, population,
                                        timeTrend=TRUE,reweight=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.farrington.fitGLM_+3A_response">response</code></td>
<td>
<p>The vector of observed base counts</p>
</td></tr>
<tr><td><code id="algo.farrington.fitGLM_+3A_wtime">wtime</code></td>
<td>
<p>Vector of week numbers corresponding to <code>response</code></p>
</td></tr>
<tr><td><code id="algo.farrington.fitGLM_+3A_timetrend">timeTrend</code></td>
<td>
<p>Boolean whether to fit the <code class="reqn">\beta t</code> or not</p>
</td></tr>
<tr><td><code id="algo.farrington.fitGLM_+3A_reweight">reweight</code></td>
<td>
<p>Fit twice &ndash; 2nd time with Anscombe residuals</p>
</td></tr>
<tr><td><code id="algo.farrington.fitGLM_+3A_population">population</code></td>
<td>
<p>Population size. Possibly used as offset, i.e. in
<code>algo.farrington.fitGLM.populationOffset</code> the value 
<code>log(population)</code> is used as offset in the linear
predictor of the GLM:   
</p>
<p style="text-align: center;"><code class="reqn">\log \mu_t = \log(\texttt{population}) + \alpha + \beta t</code>
</p>

<p>This provides a way to adjust the Farrington procedure to the case
of greatly varying populations. Note: This is an experimental implementation with methodology not covered by the original paper.
</p>
</td></tr>
<tr><td><code id="algo.farrington.fitGLM_+3A_...">...</code></td>
<td>
<p>Used to catch additional arguments, currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute weights from an initial fit and rescale using
Anscombe based residuals as described in the
<code><a href="#topic+anscombe.residuals">anscombe.residuals</a></code> function.
</p>
<p>Note that <code>algo.farrington.fitGLM</code> uses the <code>glm</code> routine
for fitting. A faster alternative is provided by
<code>algo.farrington.fitGLM.fast</code> which uses the <code>glm.fit</code>
function directly (thanks to Mikko Virtanen). This saves
computational overhead and increases speed for 500 monitored time
points by a factor of approximately two. However, some of the
routine <code>glm</code> functions might not work on the output of this
function. Which function is used for <code>algo.farrington</code> can be
controlled by the <code>control$fitFun</code> argument.
</p>


<h3>Value</h3>

<p>an object of class GLM with additional fields <code>wtime</code>,
<code>response</code> and <code>phi</code>. If the <code>glm</code> returns without
convergence <code>NULL</code> is returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anscombe.residuals">anscombe.residuals</a></code>,<code><a href="#topic+algo.farrington">algo.farrington</a></code></p>

<hr>
<h2 id='algo.farrington.threshold'>Compute prediction interval for a new observation</h2><span id='topic+algo.farrington.threshold'></span>

<h3>Description</h3>

<p>Depending on the current transformation <code class="reqn">h(y)= \{y, \sqrt{y}, y^{2/3}\}</code>,
</p>
<p style="text-align: center;"><code class="reqn">V(h(y_0)-h(\mu_0))=V(h(y_0))+V(h(\mu_0))</code>
</p>

<p>is used to compute a prediction interval. The prediction variance
consists of a component due to the variance of having a single
observation and a prediction variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.farrington.threshold(pred,phi,alpha=0.01,skewness.transform="none",y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.farrington.threshold_+3A_pred">pred</code></td>
<td>
<p>A GLM prediction object</p>
</td></tr>
<tr><td><code id="algo.farrington.threshold_+3A_phi">phi</code></td>
<td>
<p>Current overdispersion parameter (superflous?)</p>
</td></tr>
<tr><td><code id="algo.farrington.threshold_+3A_alpha">alpha</code></td>
<td>
<p>Quantile level in Gaussian based CI, i.e. an <code class="reqn">(1-\alpha)\cdot 100\%</code>
confidence interval is computed. </p>
</td></tr>
<tr><td><code id="algo.farrington.threshold_+3A_skewness.transform">skewness.transform</code></td>
<td>
<p>Skewness correction, i.e. one of
<code>"none"</code>, <code>"1/2"</code>, or <code>"2/3"</code>.</p>
</td></tr>
<tr><td><code id="algo.farrington.threshold_+3A_y">y</code></td>
<td>
<p>Observed number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of length four with lower and upper bounds of an
<code class="reqn">(1-\alpha)\cdot 100\%</code> confidence interval (first two
arguments) and corresponding quantile of observation <code>y</code>
together with the median of the predictive distribution.
</p>

<hr>
<h2 id='algo.glrnb'>Count Data Regression Charts</h2><span id='topic+algo.glrnb'></span><span id='topic+algo.glrpois'></span>

<h3>Description</h3>

<p>Count data regression charts for the monitoring of surveillance time
series as proposed by Höhle and Paul (2008).
The implementation is described in Salmon et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.glrnb(disProgObj, control = list(range=range, c.ARL=5,
           mu0=NULL, alpha=0, Mtilde=1, M=-1, change="intercept",
           theta=NULL, dir=c("inc","dec"),
           ret=c("cases","value"), xMax=1e4))

algo.glrpois(disProgObj, control = list(range=range, c.ARL=5,
             mu0=NULL, Mtilde=1, M=-1, change="intercept",
             theta=NULL, dir=c("inc","dec"),
             ret=c("cases","value"), xMax=1e4))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.glrnb_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class <code>disProg</code> to do surveillance for.
For new <code><a href="#topic+sts">sts</a></code>-class data, use the <code><a href="#topic+glrnb">glrnb</a></code>
wrapper, or the <code><a href="#topic+sts2disProg">sts2disProg</a></code> converter.</p>
</td></tr>
<tr><td><code id="algo.glrnb_+3A_control">control</code></td>
<td>
<p>A list controlling the behaviour of the algorithm
</p>

<dl>
<dt><code>range</code></dt><dd><p>vector of indices in the observed vector
to monitor (should be consecutive)</p>
</dd>
<dt><code>mu0</code></dt><dd><p>A vector of in-control values of the mean of the
Poisson / negative binomial
distribution with the same length as <code>range</code>. If
<code>NULL</code> the observed values in <code>1:(min(range)-1)</code> are
used to estimate the beta vector through a generalized linear
model. To
fine-tune the model one can instead specify <code>mu0</code> as a
list with two components:
</p>

<dl>
<dt><code>S</code></dt><dd><p>integer number of harmonics to include
(typically 1 or 2)</p>
</dd>
<dt><code>trend</code></dt><dd><p>A Boolean indicating whether to include a term <code>t</code> in the GLM model</p>
</dd>
</dl>

<p>The fitting is controlled by the <code>estimateGLRNbHook</code>
function. The in-control mean model is re-fitted after every
alarm. The fitted models can be found as a list <code>mod</code> in
the <code>control</code> slot after the call.
</p>
<p>Note: If a value for <code>alpha</code> is given, then the inverse of
this value is used as fixed <code>theta</code> in a
<code><a href="MASS.html#topic+negative.binomial">negative.binomial</a></code> <code>glm</code>.
If <code>is.null(alpha)</code> then the parameter is
estimated as well (using <code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>) &ndash;
see the description of this parameter for details.
</p>
</dd>
<dt><code>alpha</code></dt><dd><p>The (known) dispersion parameter of the negative
binomial distribution, i.e. the parametrization of the negative
binomial is such that the variance is <code class="reqn">mean +
        alpha*mean^2</code>. Note: This parametrization
is the inverse of the shape parametrization used in R &ndash; for
example in <code>dnbinom</code> and <code>glr.nb</code>. Hence, if
<code>alpha=0</code> then the negative binomial distribution boils
down to the Poisson distribution and a call of <code>algo.glrnb</code>
is equivalent to a call to <code>algo.glrpois</code>. If
<code>alpha=NULL</code> the parameter is calculated as part of the
in-control estimation. However, the parameter is estimated only
once from the first fit. Subsequent fittings are only for the
parameters of the linear predictor with <code>alpha</code> fixed.</p>
</dd>
<dt><code>c.ARL</code></dt><dd><p>threshold in the GLR test,
i.e. <code class="reqn">c_{\gamma}</code></p>
</dd>
<dt><code>Mtilde</code></dt><dd><p>number of observations needed before we
have a full rank the typical setup for the
&quot;<code>intercept</code>&quot; and &quot;<code>epi</code>&quot; charts is <code>Mtilde=1</code></p>
</dd>
<dt><code>M</code></dt><dd><p>number of time instances back in time in the
window-limited approach, i.e. the last value
considered is <code class="reqn">\max{1,n-M}</code>. To always look back
until the first observation use <code>M=-1</code>.</p>
</dd>
<dt><code>change</code></dt><dd><p>a string specifying the type of the
alternative. Currently the two choices are
<code>intercept</code> and <code>epi</code>. See the SFB
Discussion Paper 500 for details.</p>
</dd>
<dt><code>theta</code></dt><dd><p>if <code>NULL</code> then the GLR scheme is
used. If not <code>NULL</code> the prespecified value for
<code class="reqn">\kappa</code> or <code class="reqn">\lambda</code> is used in a recursive
LR scheme, which is faster.  </p>
</dd>
<dt><code>dir</code></dt><dd><p>a string specifying the direction of testing in
GLR scheme. With <code>"inc"</code> only increases in <code class="reqn">x</code> are
considered in the GLR-statistic, with <code>"dec"</code> decreases
are regarded. </p>
</dd>
<dt><code>ret</code></dt><dd><p>a string specifying the type of
<code>upperbound</code>-statistic that is returned. With
<code>"cases"</code> the number of cases that would have been
necessary to produce an alarm or with <code>"value"</code> the
GLR-statistic is computed (see below).</p>
</dd>
<dt><code>xMax</code></dt><dd><p>Maximum value to try for x to see if this is
the upperbound number of cases before sounding an alarm
(Default: 1e4). This only applies for the GLR using the NegBin
when <code>ret="cases"</code> &ndash; see details.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the seasonal count data chart based on
generalized likelihood ratio (GLR) as described in the Höhle and Paul
(2008) paper. A moving-window generalized likelihood ratio
detector is used, i.e. the detector has the form

</p>
<p style="text-align: center;"><code class="reqn">N = \inf\left\{ n : \max_{1\leq k \leq
      n} \left[ \sum_{t=k}^n \log \left\{
        \frac{f_{\theta_1}(x_t|z_t)}{f_{\theta_0}(x_t|z_t)} \right\}
    \right] \geq c_\gamma \right\} </code>
</p>


<p>where instead of <code class="reqn">1\leq k \leq n</code> the GLR statistic is
computed for all <code class="reqn">k \in \{n-M, \ldots, n-\tilde{M}+1\}</code>. To
achieve the typical behaviour from <code class="reqn">1\leq k\leq n</code> use
<code>Mtilde=1</code> and <code>M=-1</code>.
</p>
<p>So <code class="reqn">N</code> is the time point where the GLR statistic is above the
threshold the first time: An alarm is given and the surveillance is
reset starting from time <code class="reqn">N+1</code>. Note that the same
<code>c.ARL</code> as before is used, but if <code>mu0</code> is different at
<code class="reqn">N+1,N+2,\ldots</code> compared to time <code class="reqn">1,2,\ldots</code> the run length
properties differ. Because <code>c.ARL</code> to obtain a specific ARL can
only be obtained my Monte Carlo simulation there is no good way to
update <code>c.ARL</code> automatically at the moment. Also, FIR GLR-detectors
might be worth considering.
</p>
<p>In case <code>is.null(theta)</code> and <code>alpha&gt;0</code> as well as
<code>ret="cases"</code> then a brute-force search is conducted for each time
point in range in order to determine the number of cases necessary
before an alarm is sounded. In case no alarm was sounded so far by time
<code class="reqn">t</code>, the function increases <code class="reqn">x[t]</code> until an alarm is sounded any
time before time point <code class="reqn">t</code>. If no alarm is sounded by <code>xMax</code>, a return value
of 1e99 is given. Similarly, if an alarm was sounded by time <code class="reqn">t</code> the
function counts down instead. Note: This is slow experimental code!
</p>
<p>At the moment, window limited &ldquo;<code>intercept</code>&rdquo; charts have not been
extensively tested and are at the moment not supported. As speed is
not an issue here this doesn't bother too much. Therefore, a value of
<code>M=-1</code> is always used in the intercept charts.
</p>


<h3>Value</h3>

<p><code>algo.glrpois</code> simply calls <code>algo.glrnb</code> with
<code>control$alpha</code> set to 0.
</p>
<p><code>algo.glrnb</code> returns a list of class
<code>survRes</code> (surveillance result), which includes the alarm
value for recognizing an outbreak (1 for alarm, 0 for no alarm),
the threshold value for recognizing the alarm and the input object
of class disProg. The <code>upperbound</code> slot of the object are
filled with the current <code class="reqn">GLR(n)</code> value or with the number of
cases that are necessary to produce an alarm at any time point
<code class="reqn">\leq n</code>. Both lead to the same alarm timepoints, but
<code>"cases"</code> has an obvious interpretation.
</p>


<h3>Author(s)</h3>

<p>M. Höhle with contributions by V. Wimmer</p>


<h3>References</h3>

<p>Höhle, M. and Paul, M. (2008):
Count data regression charts for the monitoring of surveillance time
series. Computational Statistics and Data Analysis, 52 (9), 4357-4368.
</p>
<p>Salmon, M., Schumacher, D. and Höhle, M. (2016):
Monitoring count time series in <span class="rlang"><b>R</b></span>: Aberration detection in public
health surveillance. <em>Journal of Statistical Software</em>,
<b>70</b> (10), 1-35. <a href="https://doi.org/10.18637/jss.v070.i10">doi:10.18637/jss.v070.i10</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Simulate data and apply the algorithm
S &lt;- 1 ; t &lt;- 1:120 ; m &lt;- length(t)
beta &lt;- c(1.5,0.6,0.6)
omega &lt;- 2*pi/52
#log mu_{0,t}
base &lt;- beta[1] + beta[2] * cos(omega*t) + beta[3] * sin(omega*t)
#Generate example data with changepoint and tau=tau
tau &lt;- 100
kappa &lt;- 0.4
mu0 &lt;- exp(base)
mu1 &lt;- exp(base  + kappa)


## Poisson example
#Generate data
set.seed(42)
x &lt;- rpois(length(t),mu0*(exp(kappa)^(t&gt;=tau)))
s.ts &lt;- sts(observed=x, state=(t&gt;=tau))
#Plot the data
plot(s.ts, xaxis.labelFormat=NULL)
#Run
cntrl = list(range=t,c.ARL=5, Mtilde=1, mu0=mu0,
             change="intercept",ret="value",dir="inc")
glr.ts &lt;- glrpois(s.ts,control=cntrl)
plot(glr.ts, xaxis.labelFormat=NULL, dx.upperbound=0.5)
lr.ts  &lt;- glrpois(s.ts,control=c(cntrl,theta=0.4))
plot(lr.ts, xaxis.labelFormat=NULL, dx.upperbound=0.5)

#using the legacy interface for "disProg" data
lr.ts0  &lt;- algo.glrpois(sts2disProg(s.ts), control=c(cntrl,theta=0.4))
stopifnot(upperbound(lr.ts) == lr.ts0$upperbound)


## NegBin example
#Generate data
set.seed(42)
alpha &lt;- 0.2
x &lt;- rnbinom(length(t),mu=mu0*(exp(kappa)^(t&gt;=tau)),size=1/alpha)
s.ts &lt;- sts(observed=x, state=(t&gt;=tau))

#Plot the data
plot(s.ts, xaxis.labelFormat=NULL)

#Run GLR based detection
cntrl = list(range=t,c.ARL=5, Mtilde=1, mu0=mu0, alpha=alpha,
             change="intercept",ret="value",dir="inc")
glr.ts &lt;- glrnb(s.ts, control=cntrl)
plot(glr.ts, xaxis.labelFormat=NULL, dx.upperbound=0.5)

#CUSUM LR detection with backcalculated number of cases
cntrl2 = list(range=t,c.ARL=5, Mtilde=1, mu0=mu0, alpha=alpha,
              change="intercept",ret="cases",dir="inc",theta=1.2)
glr.ts2 &lt;- glrnb(s.ts, control=cntrl2)
plot(glr.ts2, xaxis.labelFormat=NULL)
</code></pre>

<hr>
<h2 id='algo.hmm'>Hidden Markov Model (HMM) method</h2><span id='topic+algo.hmm'></span>

<h3>Description</h3>

 
<p>This function implements on-line HMM detection of outbreaks based on
the retrospective procedure described in Le Strat and Carret (1999).
Using the function <code><a href="msm.html#topic+msm">msm</a></code> (from package <span class="pkg">msm</span>) a specified HMM
is estimated, the decoding problem, i.e. the most probable state
configuration, is found by the Viterbi algorithm and the most
probable state of the last observation is recorded. On-line
detection is performed by sequentially repeating this procedure.
</p>
<p>Warning: This function can be very slow - a more efficient implementation would be nice!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  algo.hmm(disProgObj, control = list(range=range, Mtilde=-1, 
           noStates=2, trend=TRUE, noHarmonics=1,
           covEffectEqual=FALSE, saveHMMs = FALSE, extraMSMargs=list()))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.hmm_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class disProg (including the observed and the state chain)</p>
</td></tr>
<tr><td><code id="algo.hmm_+3A_control">control</code></td>
<td>
<p>control object: 
</p>

<dl>
<dt><code>range</code></dt><dd><p>determines the desired time points
which should be evaluated. Note that opposite to other
surveillance methods an initial parameter estimation
occurs in the HMM. Note that range should be high
enough to allow for enough reference values for
estimating the HMM</p>
</dd>
<dt><code>Mtilde</code></dt><dd><p>number of observations back in time
to use for fitting the HMM (including
the current observation). Reasonable values are a multiple of
<code>disProgObj$freq</code>, the default is
<code>Mtilde=-1</code>, which means to use all possible
values - for long series this might take very long time!</p>
</dd>
<dt><code>noStates</code></dt><dd><p>number of hidden states in the HMM
&ndash; the typical choice is 2. The initial rates are set
such that the <code>noStates</code>th state is the one
having the highest rate. In other words: this state is considered
the outbreak state.</p>
</dd>
<dt><code>trend</code></dt><dd><p>Boolean stating whether a linear time trend exists, i.e. if <code>TRUE</code> (default) then <code class="reqn">\beta_j \neq 0</code></p>
</dd>
<dt><code>noHarmonics</code></dt><dd><p>number of harmonic waves to include in the linear predictor. Default is 1.</p>
</dd>
<dt><code>covEffectEqual</code></dt><dd><p>see details</p>
</dd>
<dt><code>saveHMMs</code></dt><dd><p>Boolean, if <code>TRUE</code> then the fitted HMMs are saved. With this option the function can also be used to analyse data retrospectively. Default option is <code>FALSE</code></p>
</dd>
<dt><code>extraMSMArgs</code></dt><dd><p>A named list with additional arguments to send to the <code><a href="msm.html#topic+msm">msm</a></code> HMM fitting function. Note that the <code>msm</code> arguments <code>formula</code>, <code>data</code>, <code>qmatrix</code>, <code>hmodel</code>, <code>hcovariates</code> and <code>hconstraint</code> are automatically filled by <code>algo.hmm</code>, thus these should NOT be modified.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>For each time point t the reference values values are extracted. If
the number of requested values is larger than the number of possible
values the latter is used. Now the following happens on these reference values:
</p>
<p>A <code>noStates</code>-State Hidden Markov Model (HMM) is used based on
the Poisson distribution with linear predictor on the log-link
scale. I.e.  </p>
<p style="text-align: center;"><code class="reqn">Y_t | X_t = j \sim Po(\mu_t^j),</code>
</p>
<p> where </p>
<p style="text-align: center;"><code class="reqn">\log(\mu_t^j) = \alpha_j + \beta_j\cdot
    t + \sum_{i=1}^{nH} \gamma_j^i \cos(2i\pi/freq\cdot (t-1)) +
    \delta_j^i \sin(2i\pi/freq\cdot (t-1))</code>
</p>

<p>and <code class="reqn">nH=</code><code>noHarmonics</code> and <code class="reqn">freq=12,52</code> depending on the
sampling frequency of the surveillance data. In the above <code class="reqn">t-1</code> is
used, because the first week is always saved as <code>t=1</code>, i.e. we
want to ensure that the first observation corresponds to cos(0) and
sin(0).
</p>
<p>If <code>covEffectEqual</code> then all covariate effects parameters are
equal for the states, i.e. <code class="reqn">\beta_j=\beta, \gamma_j^i=\gamma^i,
    \delta_j^i=\delta^i</code> for all <code class="reqn">j=1,...,\code{noStates}</code>.
</p>
<p>In case more complicated HMM models are to be fitted it is possible to
modify the <code>msm</code> code used in this function. Using
e.g. <code>AIC</code> one can select between different models (see the
<span class="pkg">msm</span> package for further details). 
</p>
<p>Using the Viterbi algorithms the most probable state configuration
is obtained for the reference values and if the most probable
configuration for the last reference value (i.e. time t) equals
<code>control$noOfStates</code> then an alarm is given.
</p>
<p>Note: The HMM is re-fitted from scratch every time, sequential
updating schemes of the HMM would increase speed considerably!  A
major advantage of the approach is that outbreaks in the reference
values are handled automatically.
</p>


<h3>Value</h3>

<p><code>algo.hmm</code> gives a list of class <code>survRes</code> which includes the 
vector of alarm values for every timepoint in <code>range</code>. No
<code>upperbound</code> can be specified and is put equal to zero.
</p>
<p>The resulting object contains a list <code>control$hmms</code>, which
contains the <code>"msm"</code> objects with the fitted HMMs
(if <code>saveHMMs=TRUE</code>).
</p>


<h3>Author(s)</h3>

<p>M. Höhle</p>


<h3>References</h3>

<p>Y. Le Strat and F. Carrat, Monitoring Epidemiologic Surveillance Data using Hidden Markov Models (1999), Statistics in Medicine, 18, 3463&ndash;3478
</p>
<p>I.L. MacDonald and W. Zucchini, Hidden Markov and Other Models for Discrete-valued Time Series,  (1997), Chapman &amp; Hall, Monographs on Statistics and applied Probability 70
</p>


<h3>See Also</h3>

<p><code><a href="msm.html#topic+msm">msm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate outbreak data from HMM
set.seed(123)
counts &lt;- sim.pointSource(p = 0.98, r = 0.8, length = 3*52,
                              A = 1, alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 1.5)

## Not run: 
#Do surveillance using a two state HMM without trend component and
#the effect of the harmonics being the same in both states. A sliding
#window of two years is used to fit the HMM
surv &lt;- algo.hmm(counts, control=list(range=(2*52):length(counts$observed),
                                   Mtilde=2*52,noStates=2,trend=FALSE,
                                   covEffectsEqual=TRUE,extraMSMargs=list()))
plot(surv,legend.opts=list(x="topright"))

## End(Not run)

if (require("msm")) {
#Retrospective use of the function, i.e. monitor only the last time point
#but use option saveHMMs to store the output of the HMM fitting
surv &lt;- algo.hmm(counts,control=list(range=length(counts$observed),Mtilde=-1,noStates=2,
                          trend=FALSE,covEffectsEqual=TRUE, saveHMMs=TRUE))

#Compute most probable state using the viterbi algorithm - 1 is "normal", 2 is "outbreak".
viterbi.msm(surv$control$hmms[[1]])$fitted

#How often correct?
tab &lt;- cbind(truth=counts$state + 1 ,
             hmm=viterbi.msm(surv$control$hmm[[1]])$fitted)
table(tab[,1],tab[,2])
}
</code></pre>

<hr>
<h2 id='algo.outbreakP'>Semiparametric surveillance of outbreaks</h2><span id='topic+algo.outbreakP'></span><span id='topic+calc.outbreakP.statistic'></span>

<h3>Description</h3>

<p>Frisen and Andersson (2009) method for semiparametric surveillance of outbreaks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.outbreakP(disProgObj, control = list(range = range, k=100,
               ret=c("cases","value"),maxUpperboundCases=1e5))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.outbreakP_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class disProg (including the observed and the state chain).</p>
</td></tr>
<tr><td><code id="algo.outbreakP_+3A_control">control</code></td>
<td>
<p>A list controlling the behaviour of the algorithm
</p>

<dl>
<dt><code>range</code></dt><dd><p>determines the desired
time-points which should be monitored. Note that it is
automatically assumed that ALL other values in <code>disProgObj</code>
can be used for the estimation, i.e. for a specific value <code>i</code>
in <code>range</code> all values from 1 to <code>i</code> are used for estimation.</p>
</dd>
<dt><code>k</code></dt><dd><p>The threshold value. Once the outbreak statistic
is above this threshold <code>k</code> an alarm is sounded.</p>
</dd>
<dt><code>ret</code></dt><dd><p>a string specifying the type of
<code>upperbound</code>-statistic that is returned. With
<code>"cases"</code> the number of cases that would have been
necessary to produce an alarm (NNBA) or with <code>"value"</code> the
outbreakP-statistic is computed (see below).</p>
</dd>
<dt><code>maxUpperboundCases</code></dt><dd><p>Upperbound when numerically searching
for NNBA. Default is 1e5.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>A generalized likelihood ratio test based on the Poisson
distribution is implemented where the means of the in-control and
out-of-control states are computed by isotonic regression.
</p>
<p style="text-align: center;"><code class="reqn">OutbreakP(s) = \prod_{t=1}^s \left( \frac{\hat{\mu}^{C1}(t)}{\hat{\mu}^D(t)} \right)^{x(t)}</code>
</p>

<p>where <code class="reqn">\hat{\mu}^{C1}(t)</code> is the estimated mean obtained by
uni-modal regression under the assumption of one change-point and
<code class="reqn">\hat{\mu}^D(t)</code> is the estimated result when there is no
change-point (i.e. this is just the mean of all observations). Note
that the contrasted hypothesis assume all means are equal until the
change-point, i.e. this detection method is especially suited for
detecting a shift from a relative constant mean. Hence, this is less
suited for detection in diseases with strong seasonal endemic
component. Onset of influenza detection is an example where this
method works particular well.
</p>
<p>In case <code>control$ret == "cases"</code> then a brute force numerical
search for the number needed before alarm (NNBA) is performed. That
is, given the past observations, whats the minimum number which would
have caused an alarm? Note: Computing this might take a while because
the search is done by sequentially increasing/decreasing the last
observation by one for each time point in <code>control$range</code> and
then calling the workhorse function of the algorithm again. The argument
<code>control$maxUpperboundCases</code> controls the upper limit of this
search (default is 1e5).
Currently, even though the statistic has passed the threshold, the NNBA
is still computed. After a few time instances what typically happens is
that no matter the observed value we would have an alarm at this time point. In this case the value of NNBA is set to <code>NA</code>. Furthermore, the first time
point is always <code>NA</code>, unless <code>k&lt;1</code>.
</p>


<h3>Value</h3>

<p><code>algo.outbreakP</code> gives a list of class <code>survRes</code> which
includes the vector of alarm values for every time-point in
<code>range</code>, the vector of threshold values for every time-point
in <code>range</code>.
</p>


<h3>Author(s)</h3>

<p>M. Höhle &ndash; based on Java code by M. Frisen and
L. Schiöler</p>


<h3>Source</h3>

<p>The code is an extended R port of the Java code by Marianne
Frisén and Linus Schiöler from the
Computer Assisted Search For Epidemics (CASE) project,
formerly available from <code style="white-space: pre;">&#8288;https://case.folkhalsomyndigheten.se/&#8288;</code>
under the GNU GPL License v3.


</p>
<p>An additional feature of the R code is that it contains a search for
NNBA (see details).
</p>


<h3>References</h3>

<p>Frisén, M., Andersson and Schiöler, L., (2009), Robust
outbreak surveillance of epidemics in Sweden, Statistics in
Medicine, 28(3):476-493.
</p>
<p>Frisén, M. and Andersson, E., (2009) Semiparametric
Surveillance of Monotonic Changes, Sequential Analysis 28(4):434-454.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Use data from outbreakP manual (http://www.hgu.gu.se/item.aspx?id=16857)
y &lt;- matrix(c(1,0,3,1,2,3,5,4,7,3,5,8,16,23,33,34,48),ncol=1)

#Generate sts object with these observations
mysts &lt;- sts(y, alarm=y*0)

#Run the algorithm and present results
#Only the value of outbreakP statistic
upperbound(outbreakP(mysts, control=list(range=1:length(y),k=100,
           ret="value")))

#Graphical illustration with number-needed-before-alarm (NNBA) upperbound.
res &lt;- outbreakP(mysts, control=list(range=1:length(y),k=100,
           ret="cases"))
plot(res,dx.upperbound=0,lwd=c(1,1,3),legend.opts=list(legend=c("Infected",
      "NNBA","Outbreak","Alarm"),horiz=TRUE))
</code></pre>

<hr>
<h2 id='algo.quality'>Computation of Quality Values for a Surveillance System Result</h2><span id='topic+algo.quality'></span><span id='topic+xtable.algoQV'></span>

<h3>Description</h3>

<p>Computation of the quality values for a surveillance system output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.quality(sts, penalty = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.quality_+3A_sts">sts</code></td>
<td>
<p>object of class <code>survRes</code> or <code>sts</code>, which includes the state chain and
the computed alarm chain</p>
</td></tr>
<tr><td><code id="algo.quality_+3A_penalty">penalty</code></td>
<td>
<p>the maximal penalty for the lag</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The lag is defined as follows:
In the state chain just the beginnings of an outbreak chain (outbreaks directly
following each other) are considered. In the alarm chain, the range from the beginning
of an outbreak until <code>min(<var>next outbreak beginning</var>, penalty)</code>
timepoints is considered. The <code>penalty</code> timepoints were
chosen, to provide an upper bound on the penalty for not discovering
an outbreak. Now the difference between the first alarm by the system
and the defined beginning is denoted &ldquo;the lag&rdquo;.
Additionally outbreaks found by the system are not
punished. At the end, the mean of the lags for every outbreak chain is returned
as summary lag.
</p>


<h3>Value</h3>

<p>an object of class <code>"algoQV"</code>, which is
a list of quality values:
</p>
<table>
<tr><td><code>TP</code></td>
<td>
<p>Number of correct found outbreaks.</p>
</td></tr>
<tr><td><code>FP</code></td>
<td>
<p>Number of false found outbreaks.</p>
</td></tr>
<tr><td><code>TN</code></td>
<td>
<p>Number of correct found non outbreaks.</p>
</td></tr>
<tr><td><code>FN</code></td>
<td>
<p>Number of false found non outbreaks.</p>
</td></tr>
<tr><td><code>sens</code></td>
<td>
<p>True positive rate, meaning TP/(FN + TP).</p>
</td></tr>
<tr><td><code>spec</code></td>
<td>
<p>True negative rate, meaning TN/(TN + FP).</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>Euclidean distance between (1-spec, sens) to (0,1).</p>
</td></tr>
<tr><td><code>lag</code></td>
<td>
<p>Lag of the outbreak recognizing by the system.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+algo.compare">algo.compare</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a test object
disProgObj &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 200, A = 1,
                              alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 1.7)

# Let this object be tested from rki1
survResObj &lt;- algo.rki1(disProgObj, control = list(range = 50:200))

# Compute the list of quality values
quality &lt;- algo.quality(survResObj)
quality # the list is printed in matrix form


# Format as an "xtable", which is printed with LaTeX markup (by default)
library("xtable")
xtable(quality)

</code></pre>

<hr>
<h2 id='algo.rki'>The system used at the RKI</h2><span id='topic+algo.rkiLatestTimepoint'></span><span id='topic+algo.rki'></span><span id='topic+algo.rki1'></span><span id='topic+algo.rki2'></span><span id='topic+algo.rki3'></span>

<h3>Description</h3>

<p>Evaluation of timepoints with the detection algorithms used by the RKI
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.rkiLatestTimepoint(disProgObj, timePoint = NULL,
                        control = list(b = 2, w = 4, actY = FALSE))
algo.rki(disProgObj, control = list(range = range,
         b = 2, w = 4, actY = FALSE))
algo.rki1(disProgObj, control = list(range = range))
algo.rki2(disProgObj, control = list(range = range))
algo.rki3(disProgObj, control = list(range = range))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.rki_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class disProg (including the observed and the state chain).</p>
</td></tr>
<tr><td><code id="algo.rki_+3A_timepoint">timePoint</code></td>
<td>
<p>time point which should be evaluated in <code>algo.rkiLatestTimepoint</code>. The
default is to use the latest timepoint.</p>
</td></tr>
<tr><td><code id="algo.rki_+3A_control">control</code></td>
<td>
<p>control object: <code>range</code> determines the desired
timepoints which should be evaluated, <code>b</code> describes the number of years to go
back for the reference values, <code>w</code> is the half window width for the reference
values around the appropriate timepoint and <code>actY</code> is a boolean to decide if
the year of <code>timePoint</code> also spend <code>w</code> reference values of the past.
As default <code>b</code>, <code>w</code>, <code>actY</code> are set for the RKI 3 system.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using the reference values for calculating an upper limit (threshold),
alarm is given if the actual value is bigger than a computed threshold.
<code>algo.rki</code> calls <code>algo.rkiLatestTimepoint</code> for the values specified
in <code>range</code> and for the system specified in <code>control</code>.
<code>algo.rki1</code> calls <code>algo.rkiLatestTimepoint</code> for the values specified
in <code>range</code> for the RKI 1 system.
<code>algo.rki2</code> calls <code>algo.rkiLatestTimepoint</code> for the values specified
in <code>range</code> for the RKI 2 system.
<code>algo.rki3</code> calls <code>algo.rkiLatestTimepoint</code> for the values specified
in <code>range</code> for the RKI 3 system.
</p>

<ul>
<li> <p><code>"RKI 1"</code> reference values from 6 weeks ago
</p>
</li>
<li> <p><code>"RKI 2"</code> reference values from 6 weeks ago and
13 weeks of the year ago (symmetrical around the
comparable week).
</p>
</li>
<li> <p><code>"RKI 3"</code>  18 reference values. 9 from the year ago
and 9 from two years ago (also symmetrical around the
comparable week).
</p>
</li></ul>



<h3>Value</h3>

<p><code>algo.rkiLatestTimepoint</code> returns a list of class <code>survRes</code> (surveillance result), which
includes the alarm value (alarm = 1, no alarm = 0) for recognizing an
outbreak, the threshold value for recognizing the alarm and
the input object of class disProg.
</p>
<p><code>algo.rki</code> gives a list of class <code>survRes</code> which includes the vector
of alarm values for every timepoint in <code>range</code>, the vector of threshold values
for every timepoint in <code>range</code> for the system specified by <code>b</code>, <code>w</code> and
<code>actY</code>, the range and the input object of class disProg.
<code>algo.rki1</code> returns the same for the RKI 1 system, <code>algo.rki2</code>
for the RKI 2 system and <code>algo.rki3</code> for the RKI 3 system.
</p>


<h3>Author(s)</h3>

<p>M. Höhle, A. Riebler, Christian Lang</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.bayesLatestTimepoint">algo.bayesLatestTimepoint</a></code> and <code><a href="#topic+algo.bayes">algo.bayes</a></code> for
the Bayes system.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a test object
disProgObj &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 208, A = 1,
                              alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 1.7)

# Test week 200 to 208 for outbreaks with a selfdefined rki
algo.rki(disProgObj, control = list(range = 200:208, b = 1,
                                    w = 5, actY = TRUE))
# The same for rki 1 to rki 3
algo.rki1(disProgObj, control = list(range = 200:208))
algo.rki2(disProgObj, control = list(range = 200:208))
algo.rki3(disProgObj, control = list(range = 200:208))

# Test for rki 1 the latest timepoint
algo.rkiLatestTimepoint(disProgObj)
</code></pre>

<hr>
<h2 id='algo.rogerson'>Modified CUSUM method as proposed by Rogerson and Yamada (2004)</h2><span id='topic+algo.rogerson'></span>

<h3>Description</h3>

<p>Modified Poisson CUSUM method that allows for a time-varying in-control parameter
<code class="reqn">\theta_{0,t}</code> as proposed by Rogerson and Yamada (2004). The
same approach can be applied to binomial data if <code>distribution="binomial"</code>
is specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.rogerson(disProgObj, control = list(range = range,
   theta0t = NULL, ARL0 = NULL, s = NULL, hValues = NULL,
   distribution = c("poisson","binomial"), nt = NULL, FIR=FALSE, 
   limit = NULL, digits = 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.rogerson_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class <code>disProg</code> that includes a matrix with
the observed number of counts</p>
</td></tr>
<tr><td><code id="algo.rogerson_+3A_control">control</code></td>
<td>
<p> list with elements
</p>

<dl>
<dt>range</dt><dd><p>vector of indices in the observed matrix of <code>disProgObj</code> to monitor</p>
</dd>
<dt>theta0t</dt><dd><p>matrix with in-control parameter, must be specified</p>
</dd>
<dt>ARL0 </dt><dd><p> desired average run length <code class="reqn">\gamma</code> </p>
</dd>
<dt>s</dt><dd><p>change to detect, see <code><a href="#topic+findH">findH</a></code> for further details</p>
</dd>
<dt>hValues</dt><dd><p>matrix with decision intervals <code>h</code> for a sequence of
values <code class="reqn">\theta_{0,t}</code>
(in the range of <code>theta0t</code>) </p>
</dd>
<dt>distribution</dt><dd><p><code>"poisson"</code> or <code>"binomial"</code> </p>
</dd>
<dt>nt</dt><dd><p>optional matrix with varying sample sizes for the binomial CUSUM</p>
</dd>
<dt>FIR</dt><dd><p>a FIR CUSUM with head start <code class="reqn">h/2</code>
is applied to the data if <code>TRUE</code>, otherwise no head start is used;
see details </p>
</dd>
<dt>limit</dt><dd><p>numeric that determines the procedure after an alarm is given, see details</p>
</dd>
<dt>digits</dt><dd><p>the reference value and decision interval are rounded to
<code>digits</code> decimal places. Defaults to 1 and should correspond
to the number of digits used to compute <code>hValues</code> </p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>The CUSUM for a sequence of Poisson or binomial
variates <code class="reqn">x_t</code> is computed as
</p>
<p style="text-align: center;"><code class="reqn">S_t = \max \{0, S_{t-1} + c_t (x_t- k_t)\} , \, t=1,2,\ldots ,</code>
</p>

<p>where <code class="reqn">S_0=0</code> and <code class="reqn">c_t=h/h_t</code>; <code class="reqn">k_t</code> and <code class="reqn">h_t</code> are time-varying
reference values and decision intervals.
An alarm is given at time <code class="reqn">t</code> if <code class="reqn">S_t \geq h</code>.
</p>
<p>If <code>FIR=TRUE</code>, the CUSUM starts
with a head start value <code class="reqn">S_0=h/2</code> at time <code class="reqn">t=0</code>.
After an alarm is given, the FIR CUSUM starts again at this head start value.
</p>
<p>The procedure after the CUSUM gives an alarm can be determined by <code>limit</code>.
Suppose that the CUSUM signals at time <code class="reqn">t</code>, i.e. <code class="reqn">S_t \geq h</code>.
For numeric values of <code>limit</code>, the CUSUM is bounded
above after an alarm is given, 
i.e. <code class="reqn">S_t</code> is set to
<code class="reqn"> \min\{\code{limit} \cdot h, S_t\} </code>.

Using <code>limit</code>=0 corresponds to
resetting <code class="reqn">S_t</code> to zero after an alarm as proposed in the original
formulation of the CUSUM. If <code>FIR=TRUE</code>,
<code class="reqn">S_t</code> is reset to <code class="reqn"> h/2 </code>
(i.e. <code>limit</code>=<code class="reqn">h/2</code> ).
If <code>limit=NULL</code>, no resetting occurs after an alarm is given.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>survRes</code> with elements
</p>
<table>
<tr><td><code>alarm</code></td>
<td>
<p>indicates whether the CUSUM signaled at time <code class="reqn">t</code> or not
(1 = alarm, 0 = no alarm) </p>
</td></tr>
<tr><td><code>upperbound</code></td>
<td>
<p>CUSUM values <code class="reqn">S_t</code> </p>
</td></tr>
<tr><td><code>disProgObj</code></td>
<td>
<p><code>disProg</code> object </p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>list with the alarm threshold <code class="reqn">h</code> and the specified
control object</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>algo.rogerson</code> is a univariate CUSUM method. If the data are
available in several regions (i.e. <code>observed</code> is a matrix),
multiple univariate CUSUMs are applied to each region.
</p>


<h3>References</h3>

<p>Rogerson, P. A. and Yamada, I. Approaches to Syndromic Surveillance When Data
Consist of Small Regional Counts. Morbidity and Mortality Weekly Report, 2004,
53/Supplement, 79-85
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hValues">hValues</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data (seasonal Poisson)
set.seed(123)
t &lt;- 1:300
lambda &lt;- exp(-0.5 + 0.4 * sin(2*pi*t/52) + 0.6 * cos(2*pi*t/52))
data &lt;- sts(observed = rpois(length(lambda), lambda))

# determine a matrix with h values
hVals &lt;- hValues(theta0 = 10:150/100, ARL0=500, s = 1, distr = "poisson")

# convert to legacy "disProg" class and apply modified Poisson CUSUM
disProgObj &lt;- sts2disProg(data)
res &lt;- algo.rogerson(disProgObj, control=c(hVals, list(theta0t=lambda, range=1:300)))
plot(res, xaxis.years = FALSE)
</code></pre>

<hr>
<h2 id='algo.summary'>Summary Table Generation for Several Disease Chains</h2><span id='topic+algo.summary'></span>

<h3>Description</h3>

<p>Summary table generation for several disease chains.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.summary(compMatrices)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.summary_+3A_compmatrices">compMatrices</code></td>
<td>
<p>list of matrices constructed by algo.compare.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As lag the mean of all single lags is returned. TP values, FN values,
TN values and FP values are summed up. <code>dist</code>, <code>sens</code> and
<code>spec</code> are new computed on the basis of the new TP value, FN value,
TN value and FP value.
</p>


<h3>Value</h3>

<p>a matrix summing up the singular input matrices
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.compare">algo.compare</a></code>, <code><a href="#topic+algo.quality">algo.quality</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a test object
disProgObj1 &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 400,
                               A = 1, alpha = 1, beta = 0, phi = 0,
                               frequency = 1, state = NULL, K = 1.7)
disProgObj2 &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 400,
                               A = 1, alpha = 1, beta = 0, phi = 0,
                               frequency = 1, state = NULL, K = 5)
disProgObj3 &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 400,
                               A = 1, alpha = 1, beta = 0, phi = 0,
                               frequency = 1, state = NULL, K = 17)

# Let this object be tested from any methods in range = 200:400
range &lt;- 200:400
control &lt;- list(list(funcName = "rki1", range = range),
                list(funcName = "rki2", range = range),
                list(funcName = "rki3", range = range))

compMatrix1 &lt;- algo.compare(algo.call(disProgObj1, control=control))
compMatrix2 &lt;- algo.compare(algo.call(disProgObj2, control=control))
compMatrix3 &lt;- algo.compare(algo.call(disProgObj3, control=control))

algo.summary( list(a=compMatrix1, b=compMatrix2, c=compMatrix3) )
</code></pre>

<hr>
<h2 id='algo.twins'>Fit a Two-Component Epidemic Model using MCMC</h2><span id='topic+algo.twins'></span>

<h3>Description</h3>

<p>Fits a negative binomial model as described in Held et al. (2006)
to an univariate time series of counts.
</p>
<p>This is an experimental implementation that may be removed
in future versions of the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algo.twins(disProgObj, control=list(burnin=1000, filter=10,
   sampleSize=2500, noOfHarmonics=1, alpha_xi=10, beta_xi=10,
   psiRWSigma=0.25,alpha_psi=1, beta_psi=0.1, nu_trend=FALSE,
   logFile="twins.log"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="algo.twins_+3A_disprogobj">disProgObj</code></td>
<td>
<p>object of class <code>disProg</code></p>
</td></tr>
<tr><td><code id="algo.twins_+3A_control">control</code></td>
<td>
<p>control object:
</p>

<dl>
<dt><code>burnin</code></dt><dd><p>Number of burn in samples.</p>
</dd>
<dt><code>filter</code></dt><dd><p>Thinning parameter. If <code>filter = 10</code> every 10th sample is after the burn in is returned.</p>
</dd>
<dt><code>sampleSize</code></dt><dd><p>Number of returned samples. Total
number of samples = <code>burnin</code>+<code>filter</code>*<code>sampleSize</code></p>
</dd>
<dt><code>noOfHarmonics</code></dt><dd><p>Number of harmonics to use in the
modelling, i.e. <code class="reqn">L</code> in (2.2) of Held et al (2006).</p>
</dd>
<dt><code>alpha_xi</code></dt><dd><p>Parameter <code class="reqn">\alpha_{\xi}</code> of the hyperprior of the epidemic parameter <code class="reqn">\lambda</code></p>
</dd>
<dt><code>beta_xi</code></dt><dd><p>Parameter <code class="reqn">\beta_{\xi}</code> of the hyperprior of the epidemic parameter <code class="reqn">\lambda</code></p>
</dd>
<dt><code>psiRWSigma</code></dt><dd><p>Starting value for the tuning of the variance of the random walk proposal for the overdispersion parameter <code class="reqn">\psi</code>.</p>
</dd>
<dt><code>alpha_psi</code></dt><dd><p>Parameter <code class="reqn">\alpha_{\psi}</code> of the prior of the overdispersion parameter <code class="reqn">\psi</code></p>
</dd>
<dt><code>beta_psi</code></dt><dd><p>Parameter <code class="reqn">\beta_{\psi}</code>
of the prior of the overdispersion parameter <code class="reqn">\psi</code></p>
</dd>
<dt><code>nu_trend</code></dt><dd><p>Adjust for a linear trend in the endemic
part? (default: <code>FALSE</code>)</p>
</dd>
<dt><code>logFile</code></dt><dd><p>Base file name for the output files. The function writes three output files in the current working directory <code>getwd()</code>. If <code>logfile = "twins.log"</code> the results are stored in the three files &lsquo;<span class="file">twins.log</span>&rsquo;, &lsquo;<span class="file">twins.log2</span>&rsquo; and &lsquo;<span class="file">twins.log.acc</span>&rsquo;.<br />
&lsquo;<span class="file">twins.log</span>&rsquo; contains the returned samples of the parameters <code class="reqn">\psi</code>, <code class="reqn">\gamma_{0}</code>, <code class="reqn">\gamma_{1}</code>, <code class="reqn">\gamma_{2}</code>, K, <code class="reqn">\xi_{\lambda}</code> <code class="reqn">\lambda_{1},...,\lambda{n}</code>, the predictive distribution of the number of cases at time <code class="reqn">n+1</code> and the deviance.<br />
&lsquo;<span class="file">twins.log2</span>&rsquo; contains the sample means of the variables <code class="reqn">X_{t}, Y_{t}, \omega_{t}</code> and the relative frequency of a changepoint at time t for t=1,...,n and the relative frequency of a predicted changepoint at time n+1.<br />
&lsquo;<span class="file">twins.log.acc</span>&rsquo; contains the acceptance rates of <code class="reqn">\psi</code>, the changepoints and the endemic parameters <code class="reqn">\gamma_{0}</code>, <code class="reqn">\gamma_{1}</code>, <code class="reqn">\gamma_{2}</code> in the third column and the variance of the random walk proposal for the update of the parameter <code class="reqn">\psi</code> in the second column.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>atwins</code> with elements 
</p>
<table>
<tr><td><code>control</code></td>
<td>
<p>specified control object</p>
</td></tr>
<tr><td><code>disProgObj</code></td>
<td>
<p>specified <code>disProg</code>-object</p>
</td></tr>
<tr><td><code>logFile</code></td>
<td>
<p>contains the returned samples of the parameters <code class="reqn">\psi</code>, <code class="reqn">\gamma_{0}</code>, <code class="reqn">\gamma_{1}</code>, <code class="reqn">\gamma_{2}</code>, K, <code class="reqn">\xi_{\lambda}</code> <code class="reqn">\lambda_{1},...,\lambda{n}</code>, the predictive distribution and the deviance.</p>
</td></tr>
<tr><td><code>logFile2</code></td>
<td>
<p>contains the sample means of the variables <code class="reqn">X_{t}, Y_{t}, \omega_{t}</code> and the relative frequency of a changepoint at time t for t=1,...,n and the relative frequency of a predicted changepoint at time n+1.</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>This function is not a
surveillance algorithm, but only a modelling approach as described in
the Held et. al (2006) paper.
</p>
<p>Note also that the function writes three logfiles in the current
working directory <code>getwd()</code>: &lsquo;<span class="file">twins.log</span>&rsquo;,
&lsquo;<span class="file">twins.log.acc</span>&rsquo; and &lsquo;<span class="file">twins.log2</span>&rsquo;.
Thus you need to have write permissions in the current working
directory.
</p>


<h3>Author(s)</h3>

<p>M. Hofmann and M. Höhle and
D. Sabanés Bové
</p>


<h3>References</h3>

<p>Held, L., Hofmann, M., Höhle, M. and Schmid V. (2006):
A two-component model for counts of infectious diseases.
<em>Biostatistics</em>, <b>7</b>, pp. 422&ndash;437.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the data used in the Held et al. (2006) paper
data("hepatitisA")

# Fix seed - this is used for the MCMC samplers in twins
set.seed(123)

# Call algorithm and save result (use short chain without filtering for speed)
oldwd &lt;- setwd(tempdir())  # where logfiles will be written
otwins &lt;- algo.twins(hepatitisA,
                     control=list(burnin=500, filter=1, sampleSize=1000))
setwd(oldwd)

# This shows the entire output (use ask=TRUE for pause between plots)
plot(otwins, ask=FALSE)

# Direct access to MCMC output
hist(otwins$logFile$psi,xlab=expression(psi),main="")
if (require("coda")) {
    print(summary(mcmc(otwins$logFile[,c("psi","xipsi","K")])))
}
</code></pre>

<hr>
<h2 id='all.equal'>
Test if Two Model Fits are (Nearly) Equal
</h2><span id='topic+all.equal.twinstim'></span><span id='topic+all.equal.hhh4'></span>

<h3>Description</h3>

<p>Two model fits are compared using standard <code><a href="Matrix.html#topic+all.equal">all.equal</a></code>-methods
after discarding certain elements considered irrelevant for the equality
of the fits, e.g., the runtime and the call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinstim'
all.equal(target, current, ..., ignore = NULL)

## S3 method for class 'hhh4'
all.equal(target, current, ..., ignore = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="all.equal_+3A_target">target</code>, <code id="all.equal_+3A_current">current</code></td>
<td>
<p>the model fits to be compared.</p>
</td></tr>
<tr><td><code id="all.equal_+3A_...">...</code></td>
<td>
<p>further arguments for standard
<code><a href="Matrix.html#topic+all.equal">all.equal</a></code>-methods, e.g., the numerical
<code>tolerance</code>.</p>
</td></tr>
<tr><td><code id="all.equal_+3A_ignore">ignore</code></td>
<td>
<p>an optional character vector of elements to ignore when
comparing the two fitted objects. The following elements are always
ignored: <code>"runtime"</code> and <code>"call"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either <code>TRUE</code> or a character vector describing differences between
the <code>target</code> and the <code>current</code> model fit.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>

<hr>
<h2 id='animate'>
Generic animation of spatio-temporal objects
</h2><span id='topic+animate'></span>

<h3>Description</h3>

<p>Generic function for animation of <span class="rlang"><b>R</b></span> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>animate(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="animate_+3A_object">object</code></td>
<td>
<p>The object to animate.</p>
</td></tr>
<tr><td><code id="animate_+3A_...">...</code></td>
<td>

<p>Arguments to be passed to methods, such as graphical parameters or
time interval options for the snapshots.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>The methods <code><a href="#topic+animate.epidata">animate.epidata</a></code>, <code><a href="#topic+animate.epidataCS">animate.epidataCS</a></code>,
and <code><a href="#topic+animate.sts">animate.sts</a></code> for the animation of surveillance data.
</p>

<hr>
<h2 id='anscombe.residuals'>Compute Anscombe Residuals</h2><span id='topic+anscombe.residuals'></span>

<h3>Description</h3>

<p>Compute Anscombe residuals from a fitted <code><a href="stats.html#topic+glm">glm</a></code>,
which makes them approximately standard normal distributed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anscombe.residuals(m, phi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anscombe.residuals_+3A_m">m</code></td>
<td>
<p>a fitted <code>"glm"</code></p>
</td></tr>
<tr><td><code id="anscombe.residuals_+3A_phi">phi</code></td>
<td>
<p>the current estimated overdispersion</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The standardized Anscombe residuals of <code>m</code></p>


<h3>References</h3>

<p>McCullagh &amp; Nelder, Generalized Linear Models, 1989</p>

<hr>
<h2 id='arlCusum'>Calculation of Average Run Length for discrete CUSUM schemes</h2><span id='topic+arlCusum'></span>

<h3>Description</h3>

<p>Calculates the average run length (ARL) for an upward CUSUM scheme for discrete
distributions (i.e. Poisson and binomial) using the Markov chain approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arlCusum(h=10, k=3, theta=2.4, distr=c("poisson","binomial"),
         W=NULL, digits=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="arlCusum_+3A_h">h</code></td>
<td>
<p> decision interval</p>
</td></tr>
<tr><td><code id="arlCusum_+3A_k">k</code></td>
<td>
<p> reference value</p>
</td></tr>
<tr><td><code id="arlCusum_+3A_theta">theta</code></td>
<td>
<p>distribution parameter for the cumulative distribution function
(cdf) <code class="reqn">F</code>, i.e. rate
<code class="reqn">\lambda</code> for Poisson variates or probability <code class="reqn">p</code>
for binomial variates</p>
</td></tr>
<tr><td><code id="arlCusum_+3A_distr">distr</code></td>
<td>
 <p><code>"poisson"</code> or <code>"binomial"</code>
</p>
</td></tr>      
<tr><td><code id="arlCusum_+3A_w">W</code></td>
<td>
<p>Winsorizing value <code>W</code> for a robust CUSUM,
to get a nonrobust CUSUM set 
<code>W</code> &gt; <code>k</code>+<code>h</code>. If <code>NULL</code>, a nonrobust CUSUM is used.</p>
</td></tr>
<tr><td><code id="arlCusum_+3A_digits">digits</code></td>
<td>
 <p><code>k</code> and <code>h</code> are rounded to <code>digits</code> decimal places </p>
</td></tr>
<tr><td><code id="arlCusum_+3A_...">...</code></td>
<td>
<p> further arguments for the distribution function, i.e. number of trials <code>n</code>
for binomial cdf </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with the ARL of the regular (zero-start)
and the fast initial response (FIR)
CUSUM scheme with reference value <code>k</code>, decision interval <code>h</code> for
<code class="reqn">X \sim F(\theta)</code>, where F is the Poisson or binomial CDF.
</p>
<table>
<tr><td><code>ARL</code></td>
<td>
<p>one-sided ARL of the regular (zero-start) CUSUM scheme</p>
</td></tr>
<tr><td><code>FIR.ARL</code></td>
<td>
<p>one-sided ARL of the FIR CUSUM scheme with head start
<code class="reqn">\frac{\code{h}}{2}</code> </p>
</td></tr>
</table>


<h3>Source</h3>

<p>Based on the FORTRAN code of
</p>
<p>Hawkins, D. M. (1992). Evaluation of Average Run Lengths of Cumulative
Sum Charts for an Arbitrary Data Distribution. Communications in
Statistics - Simulation and Computation, 21(4), p. 1001-1020.
</p>

<hr>
<h2 id='backprojNP'>
Non-parametric back-projection of incidence cases to exposure cases
using a known incubation time as in Becker et al (1991)
</h2><span id='topic+backprojNP'></span>

<h3>Description</h3>

<p>The function is an implementation of the non-parametric
back-projection of incidence cases to exposure cases described in
Becker et al. (1991). The method back-projects exposure times
from a univariate time series containing the number of symptom onsets per time
unit. Here, the delay between exposure and symptom onset for an
individual is seen as a realization of a random variable governed by a
known probability mass function.
The back-projection function calculates the expected number of exposures
<code class="reqn">\lambda_t</code> for each time unit under the assumption of a
Poisson distribution, but without any parametric assumption on how the
<code class="reqn">\lambda_t</code> evolve in time.
</p>
<p>Furthermore, the function contains a bootstrap based procedure, as
given in Yip et al (2011), which allows an indication of uncertainty
in the estimated <code class="reqn">\lambda_t</code>. The procedure is
equivalent to the suggestion in Becker and Marschner (1993). However,
the present implementation in <code>backprojNP</code> allows only a
univariate time series, i.e. simultaneous age groups as in Becker and
Marschner (1993) are not possible.
</p>
<p>The method in Becker et al. (1991) was originally developed for the
back-projection of AIDS incidence, but it is equally useful for
analysing the epidemic curve in outbreak situations of a disease
with long incubation time, e.g. in order to qualitatively investigate
the effect of intervention measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backprojNP(sts, incu.pmf, 
   control = list(k = 2, 
                  eps = rep(0.005,2), 
                  iter.max=rep(250,2), 
                  Tmark = nrow(sts), 
                  B = -1, 
                  alpha = 0.05, 
                  verbose = FALSE, 
                  lambda0 = NULL,
                  eq3a.method = c("R","C"),
                  hookFun = function(stsbp) {}),
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backprojNP_+3A_sts">sts</code></td>
<td>

<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code> (or one that can be
coerced to that class): contains the observed number of symptom
onsets as a time series. 
</p>
</td></tr>
<tr><td><code id="backprojNP_+3A_incu.pmf">incu.pmf</code></td>
<td>
<p>Probability mass function (PMF) of the incubation
time. The PMF is specified as a vector or matrix with the value of
the PMF evaluated at <code class="reqn">0,...,d_max</code>, i.e. note that the
support includes zero. The value of <code class="reqn">d_max</code> is
automatically calculated as <code>length(incu.pmf)-1</code> or
<code>nrow(incu.pmf)-1</code>. Note that if the sts object has more
than one column, then for the backprojection the incubation time is
either recycled for all components or, if it is a matrix with
the same number of columns as the sts object, the <code class="reqn">k</code>'th
column of <code>incu.pmf</code> is used for the backprojection of the
<code class="reqn">k</code>'th series.
</p>
</td></tr>
<tr><td><code id="backprojNP_+3A_control">control</code></td>
<td>
<p>A list with named arguments controlling the
functionality of the non-parametric back-projection.
</p>

<dl>
<dt><code>k</code></dt><dd><p>An integer representing the smoothing parameter to use in the smoothing step
of the EMS algorithm. Needs to be an even number.
</p>
</dd>
<dt><code>eps</code></dt><dd><p>A vector of length two representing the
convergence threshold <code class="reqn">\epsilon</code> of the EMS algorithm, see Details for further
information. The first value is the threshold to use in the
<code class="reqn">k=0</code> loop, which forms the values for the parametric
bootstrap. The second value is the threshold to use in the actual fit
and bootstrap fitting using the specified <code>k</code>. If <code>k</code> is
only of length one, then this number is replicated twice.
</p>
</dd>
<dt><code>Tmark</code></dt><dd><p>Numeric with <code class="reqn">T'\leq T</code>. Upper time limit
on which to base convergence, i.e. only the values
<code class="reqn">\lambda_1,\ldots,\lambda_{T'}</code> are monitored for convergence. See
details. 
</p>
</dd>
<dt><code>iter.max</code></dt><dd>
<p>The maximum number of EM iterations to do before stopping. 
</p>
</dd>
<dt><code>B</code></dt><dd>
<p>Number of parametric bootstrap samples to perform from an
initial k=0 fit. For each sample a back projection is performed.
See Becker and Marschner (1993) for details.
</p>
</dd>
<dt><code>alpha</code></dt><dd><p>(1-<code class="reqn">\alpha</code>)*100% confidence
intervals are computed based on the percentile method.
</p>
</dd>
<dt><code>verbose</code></dt><dd><p>(boolean). If true show extra progress and
debug information.
</p>
</dd>
<dt><code>lambda0</code></dt><dd><p>Start values for lambda. Vector needs to be
of the length <code>nrow(sts)</code>.
</p>
</dd>
<dt><code>eq3a.method</code></dt><dd><p>A single character being either
<code>"R"</code> or <code>"C"</code> depending on whether the three nested loops
of equation 3a in Becker et al. (1991) are to be executed as safe R
code (can be extremely slow, however the implementation is not
optimized for speed) or a C code (can be more than 200 times
faster!). However, the C implementation is experimental and can
hang R if, e.g., the time series does not go far enough back.
</p>
</dd>
<dt><code>hookFun</code></dt><dd>
<p>Hook function called for each iteration of the EM algorithm. The
function should take a single argument <code>stsbp</code> of class
<code>"<a href="#topic+stsBP-class">stsBP</a>"</code> class. It will be have the
lambda set to the current value of lambda. If no action desired
just leave the function body empty (default). Additional
arguments are possible.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="backprojNP_+3A_...">...</code></td>
<td>
<p>Additional arguments are sent to the hook function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Becker et al. (1991) specify a non-parametric back-projection
algorithm based on the Expectation-Maximization-Smoothing (EMS)
algorithm.
</p>
<p>In the present implementation the algorithm iterates until
</p>
<p style="text-align: center;"><code class="reqn">\frac{||\lambda^{(k+1)} - \lambda^{(k)}||}{||\lambda^{(k)}||} &lt;
  \epsilon</code>
</p>
<p> This is a slight adaptation of the proposals in Becker et
al. (1991). If <code class="reqn">T</code> is the length of <code class="reqn">\lambda</code> then one can
avoid instability of the algorithm near the end by considering only
the <code class="reqn">\lambda</code>'s with index <code class="reqn">1,\ldots,T'</code>.
</p>
<p>See the references for further information.
</p>


<h3>Value</h3>

<p><code>backprojNP</code> returns an object of <code>"<a href="#topic+stsBP-class">stsBP</a>"</code>.
</p>


<h3>Note</h3>

<p>The method is still experimental. A proper plot routine for
<code>stsBP</code> objects is currently missing.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle with help by
Daniel Sabanés Bové for the <span class="pkg">Rcpp</span> interface
</p>


<h3>References</h3>

<p>Becker NG, Watson LF and Carlin JB (1991), A method for
non-parametric back-projection and its application to AIDS data,
Statistics in Medicine, 10:1527-1542.
</p>
<p>Becker NG and Marschner IC (1993), A method for estimating the
age-specific relative risk of HIV infection from AIDS incidence data,
Biometrika, 80(1):165-178.
</p>
<p>Yip PSF, Lam KF, Xu Y, Chau PH, Xu J, Chang W, Peng Y, Liu Z, Xie X and
Lau HY (2011), Reconstruction of the Infection Curve for SARS Epidemic
in Beijing, China Using a Back-Projection Method, Communications in
Statistics - Simulation and Computation, 37(2):425-433.
</p>
<p>Associations of Age and Sex on Clinical Outcome and Incubation Period
of Shiga toxin-producing Escherichia coli O104:H4 Infections, 2011
(2013), Werber D, King LA, Müller L, Follin P, Buchholz U, Bernard H,
Rosner BM, Ethelberg S, de Valk H, Höhle M, American Journal of
Epidemiology, 178(6):984-992.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate an artificial outbreak of size n starting at time t0 and being of length
n &lt;- 1e3 ; t0 &lt;- 23 ; l &lt;- 10

#PMF of the incubation time is an interval censored gamma distribution
#with mean 15 truncated at 25.
dmax &lt;- 25
inc.pmf &lt;- c(0,(pgamma(1:dmax,15,1.4) - pgamma(0:(dmax-1),15,1.4))/pgamma(dmax,15,1.4))
#Function to sample from the incubation time
rincu &lt;- function(n) {
  sample(0:dmax, size=n, replace=TRUE, prob=inc.pmf)
}
#Sample time of exposure and length of incubation time
set.seed(123)
exposureTimes &lt;- t0 + sample(x=0:(l-1),size=n,replace=TRUE)
symptomTimes &lt;- exposureTimes + rincu(n)

#Time series of exposure (truth) and symptom onset (observed)
X &lt;- table( factor(exposureTimes,levels=1:(max(symptomTimes)+dmax)))
Y &lt;- table( factor(symptomTimes,levels=1:(max(symptomTimes)+dmax)))
#Convert Y to an sts object
Ysts &lt;- sts(Y)

#Plot the outbreak
plot(Ysts, xaxis.labelFormat=NULL, legend=NULL)
#Add true number of exposures to the plot
lines(1:length(Y)+0.2,X,col="red",type="h",lty=2)


#Helper function to show the EM step
plotIt &lt;- function(cur.sts) {
  plot(cur.sts,xaxis.labelFormat=NULL, legend.opts=NULL,ylim=c(0,140))
}

#Call non-parametric back-projection function with hook function but
#without bootstrapped confidence intervals
bpnp.control &lt;- list(k=0,eps=rep(0.005,2),iter.max=rep(250,2),B=-1,hookFun=plotIt,verbose=TRUE)

#Fast C version (use argument: eq3a.method="C")! 
sts.bp &lt;- backprojNP(Ysts, incu.pmf=inc.pmf,
    control=modifyList(bpnp.control,list(eq3a.method="C")), ylim=c(0,max(X,Y)))

#Show result
plot(sts.bp,xaxis.labelFormat=NULL,legend=NULL,lwd=c(1,1,2),lty=c(1,1,1),main="")
lines(1:length(Y)+0.2,X,col="red",type="h",lty=2)

#Do the convolution for the expectation
mu &lt;- matrix(0,ncol=ncol(sts.bp),nrow=nrow(sts.bp))
#Loop over all series
for (j in 1:ncol(sts.bp)) { 
  #Loop over all time points
  for (t in 1:nrow(sts.bp)) {
    #Convolution, note support of inc.pmf starts at zero (move idx by 1)
    i &lt;- seq_len(t)
    mu[t,j] &lt;- sum(inc.pmf[t-i+1] * upperbound(sts.bp)[i,j],na.rm=TRUE)
  }
}
#Show the fit
lines(1:nrow(sts.bp)-0.5,mu[,1],col="green",type="s",lwd=3)

#Non-parametric back-projection including boostrap CIs
bpnp.control2 &lt;- modifyList(bpnp.control, list(hookFun=NULL, k=2,
  B=10, # in practice, use B &gt;= 1000 !
  eq3a.method="C"))
sts.bp2 &lt;- backprojNP(Ysts, incu.pmf=inc.pmf, control=bpnp.control2)

######################################################################
# Plot the result. This is currently a manual routine.
# ToDo: Need to specify a plot method for stsBP objects which also
#       shows the CI.
#
# Parameters:
#  stsBP - object of class stsBP which is to be plotted.
######################################################################

plot.stsBP &lt;- function(stsBP) {
  maxy &lt;- max(observed(stsBP),upperbound(stsBP),stsBP@ci,na.rm=TRUE)
  plot(upperbound(stsBP),type="n",ylim=c(0,maxy), ylab="Cases",xlab="time")
  if (!all(is.na(stsBP@ci))) {
    polygon( c(1:nrow(stsBP),rev(1:nrow(stsBP))),
             c(stsBP@ci[2,,1],rev(stsBP@ci[1,,1])),col="lightgray")
  }
  lines(upperbound(stsBP),type="l",lwd=2)
  legend(x="topright",c(expression(lambda[t])),lty=c(1),col=c(1),fill=c(NA),border=c(NA),lwd=c(2))

  invisible()
}

#Plot the result of k=0 and add truth for comparison. No CIs available
plot.stsBP(sts.bp)
lines(1:length(Y),X,col=2,type="h")
#Same for k=2
plot.stsBP(sts.bp2)
lines(1:length(Y),X,col=2,type="h")

</code></pre>

<hr>
<h2 id='bestCombination'>Partition of a number into two factors</h2><span id='topic+bestCombination'></span>

<h3>Description</h3>

<p>Given a prime number factorization <code>x</code>, <code>bestCombination</code>
partitions <code>x</code> into two groups, such that the product of the numbers
in group one is as similar as possible to the product
of the numbers of group two. This is useful in <code><a href="#topic+magic.dim">magic.dim</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bestCombination(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bestCombination_+3A_x">x</code></td>
<td>
<p>prime number factorization</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector <code>c(prod(set1),prod(set2))</code></p>

<hr>
<h2 id='boda'>Bayesian Outbreak Detection Algorithm (BODA)</h2><span id='topic+boda'></span>

<h3>Description</h3>

<p>The function takes <code>range</code> values of a univariate surveillance time
series <code>sts</code> and for each time point uses a negative binomial
regression model to compute the predictive posterior distribution for
the current observation. The
<code class="reqn">(1-\alpha)\cdot 100\%</code>
quantile of this predictive distribution is then
used as bound: If the actual observation is above the bound an alarm
is raised. 
The Bayesian Outbreak Detection Algorithm (<code>boda</code>) is due to
Manitz and Höhle (2013) and its implementation is
illustrated in Salmon et al. (2016).
However, <code>boda</code> should be considered as an experiment, see the
Warning section below!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boda(sts, control = list(
    range=NULL, X=NULL, trend=FALSE, season=FALSE,
    prior=c('iid','rw1','rw2'), alpha=0.05, mc.munu=100, 
    mc.y=10, verbose=FALSE,
    samplingMethod=c('joint','marginals'),
    quantileMethod=c("MC","MM")
))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boda_+3A_sts">sts</code></td>
<td>
<p>object of class sts (including the <code>observed</code> and the
<code>state</code> time series)</p>
</td></tr>
<tr><td><code id="boda_+3A_control">control</code></td>
<td>
<p>Control object given as a <code>list</code> containing the following components:
</p>

<dl>
<dt><code>range</code></dt><dd><p>Specifies the index of all timepoints which
should be tested. If range is <code>NULL</code> all possible
timepoints are used.</p>
</dd> 
<dt><code>X</code></dt><dd></dd>
<dt><code>trend</code></dt><dd><p>Boolean indicating whether a linear trend term should be
included in the model for the expectation the log-scale</p>
</dd>
<dt><code>season</code></dt><dd><p>Boolean to indicate whether a cyclic spline
should be included.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>The threshold for declaring an observed count as
an aberration is the <code class="reqn">(1-\alpha)\cdot 100\%</code>
quantile of the predictive posterior.</p>
</dd>
<dt><code>mc.munu</code></dt><dd></dd>
<dt><code>mc.y</code></dt><dd><p>Number of samples of <code class="reqn">y</code> to generate for
each par of the mean and size parameter. A total of <code class="reqn">mc.munu
	  \times mc.y</code> samples are generated.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Argument sent to the inla call. When using ESS
it might be necessary to force verbose mode for INLA to work.</p>
</dd>
<dt><code>samplingMethod</code></dt><dd><p>Should one sample from the parameters joint distribution (joint) or from their respective marginal posterior distribution (marginals)?</p>
</dd>
<dt>quantileMethod</dt><dd><p>Character, either <code>MC</code> or <code>MM</code>. Indicates how to compute the quantile based on the posterior distribution (no matter the inference method): either by sampling <code>mc.munu</code> values from the posterior distribution of the parameters and then for each sampled parameters vector sampling <code>mc.y</code> response values so that one gets a vector of response values based on which one computes an empirical quantile (MC method, as explained in Manitz and Höhle 2013); or by sampling <code>mc.munu</code> from the posterior distribution of the parameters and then compute the quantile of the mixture distribution using bisectioning, which is faster.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Warning</h3>

<p>This function is currently experimental!! It also heavily
depends on the <span class="pkg">INLA</span> package so changes there might affect the
operational ability of this function. Since the computations
for the Bayesian GAM are quite involved do not expect this function
to be particularly fast.
</p>
<p>Results are not reproducible if <span class="pkg">INLA</span> uses parallelization (as by default);
set <code>INLA::inla.setOption(num.threads = "1:1")</code> to avoid that,
then do <code><a href="base.html#topic+set.seed">set.seed</a></code> as usual.
</p>


<h3>Note</h3>

<p>This function requires the <span class="rlang"><b>R</b></span> package <span class="pkg">INLA</span>, which is currently
<em>not</em> available from CRAN. It can be obtained from INLA's own
repository via
<code>install.packages("INLA", repos="https://inla.r-inla-download.org/R/stable")</code>.
</p>


<h3>Author(s)</h3>

<p>J. Manitz, M. Höhle, M. Salmon</p>


<h3>References</h3>

<p>Manitz, J. and Höhle, M. (2013):
Bayesian outbreak detection algorithm for monitoring reported cases of
campylobacteriosis in Germany.
Biometrical Journal, 55(4), 509-526.
</p>
<p>Salmon, M., Schumacher, D. and Höhle, M. (2016):
Monitoring count time series in <span class="rlang"><b>R</b></span>: Aberration detection in public
health surveillance. <em>Journal of Statistical Software</em>,
<b>70</b> (10), 1-35. <a href="https://doi.org/10.18637/jss.v070.i10">doi:10.18637/jss.v070.i10</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  ## running this example takes a couple of minutes

  #Load the campylobacteriosis data for Germany
  data("campyDE")
  #Make an sts object from the data.frame
  cam.sts &lt;-  sts(epoch=campyDE$date,
                  observed=campyDE$case, state=campyDE$state)

  #Define monitoring period
#  range &lt;- which(epoch(cam.sts)&gt;=as.Date("2007-01-01"))
#  range &lt;- which(epoch(cam.sts)&gt;=as.Date("2011-12-10"))
  range &lt;- tail(1:nrow(cam.sts),n=2)

  control &lt;- list(range=range, X=NULL, trend=TRUE, season=TRUE,
                  prior='iid', alpha=0.025, mc.munu=100, mc.y=10,
                  samplingMethod = "joint")

  #Apply the boda algorithm in its simples form, i.e. spline is
  #described by iid random effects and no extra covariates
  library("INLA")  # needs to be attached
  cam.boda1 &lt;- boda(cam.sts, control=control)

  plot(cam.boda1, xlab='time [weeks]', ylab='No. reported', dx.upperbound=0)

## End(Not run)
</code></pre>

<hr>
<h2 id='bodaDelay'>Bayesian Outbreak Detection in the Presence of Reporting Delays</h2><span id='topic+bodaDelay'></span>

<h3>Description</h3>

<p>The function takes <code>range</code> values of the surveillance time
series <code>sts</code> and for each time point uses a Bayesian model of the negative binomial family with
log link inspired by the work of Noufaily et al. (2012) and of Manitz and Höhle (2014). It allows delay-corrected aberration detection as explained in Salmon et al. (2015). A <code>reportingTriangle</code> has to be provided in the <code>control</code> slot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bodaDelay(sts, control = list(
  range = NULL, b = 5, w = 3, mc.munu = 100, mc.y = 10,
  pastAberrations = TRUE, verbose = FALSE,
  alpha = 0.05, trend = TRUE, limit54 = c(5,4), 
  inferenceMethod = c("asym","INLA"), quantileMethod = c("MC","MM"),
  noPeriods = 1, pastWeeksNotIncluded = NULL, delay = FALSE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bodaDelay_+3A_sts">sts</code></td>
<td>
<p>sts-object to be analysed. Needs to have a reporting triangle.</p>
</td></tr>
<tr><td><code id="bodaDelay_+3A_control">control</code></td>
<td>
<p>list of control arguments:
</p>

<dl>
<dt><code>b</code></dt><dd><p>How many years back in time to include when forming the base counts.</p>
</dd>
<dt><code>w</code></dt><dd><p>Window's half-size, i.e. number of weeks to include before and after the current week in each year.</p>
</dd>
<dt><code>range</code></dt><dd><p>Specifies the index of all timepoints which should be tested. If range is <code>NULL</code> all possible timepoints are used.</p>
</dd>
<dt><code>pastAberrations</code></dt><dd><p>Boolean indicating whether to include an effect for past outbreaks
in a second fit of the model. This option only makes sense if <code>inferenceMethod</code> is <code>INLA</code>, as it is not supported by the other inference method.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Boolean specifying whether to show extra debugging information.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>An approximate (one-sided) <code class="reqn">(1-\alpha)\cdot 100\%</code>
prediction interval is calculated unlike the original method where it was a two-sided interval. The upper limit of this interval
i.e. the <code class="reqn">(1-\alpha)\cdot 100\%</code> quantile serves as an upperbound.</p>
</dd>
<dt><code>trend</code></dt><dd><p>Boolean indicating whether a trend should be included</p>
</dd>
<dt><code>noPeriods</code></dt><dd><p>Number of levels in the factor allowing to use more baseline. If
equal to 1 no factor variable is created, the set of reference values is defined as in
Farrington et al (1996).</p>
</dd>
<dt><code>inferenceMethod</code></dt><dd><p>Which inference method used, as defined in Salmon et al. (2015). If one chooses <code>"INLA"</code> then inference is performed with INLA. If one chooses <code>"asym"</code> (default) then the asymptotic normal approximation of the posteriori is used.</p>
</dd>
<dt><code>pastWeeksNotIncluded</code></dt><dd><p>Number of past weeks to ignore in the calculation.
The default (<code>NULL</code>) means to use the value of <code>control$w</code>.</p>
</dd>
<dt><code>delay</code></dt><dd><p>Boolean indicating whether to take reporting delays into account.</p>
</dd>
<dt><code>mc.munu</code></dt><dd><p>Number of samples for the parameters of the negative binomial distribution for calculating a threshold</p>
</dd>
<dt><code>mc.y</code></dt><dd><p>Number of samples for observations
when performing Monte Carlo to calculate a threshold</p>
</dd>
<dt><code>limit54</code></dt><dd><p>c(cases,period) is a vector allowing the
user to change these numbers.</p>
</dd>
<dt><code>quantileMethod</code></dt><dd><p>Character, either <code>"MC"</code> (default) or <code>"MM"</code>. Indicates how to compute the quantile based on the posterior distribution (no matter the inference method): either by sampling <code>mc.munu</code> values from the posterior distribution of the parameters and then for each sampled parameters vector sampling <code>mc.y</code> response values so that one gets a vector of response values based on which one computes an empirical quantile (MC method, as explained in Salmon et al. 2015); or by sampling <code>mc.munu</code> from the posterior distribution of the parameters and then compute the quantile of the mixture distribution using bisectioning, which is faster.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>References</h3>

<p>Farrington, C.P., Andrews, N.J, Beale A.D. and Catchpole, M.A. (1996):
A statistical algorithm for the early detection of outbreaks of
infectious disease. J. R. Statist. Soc. A, 159, 547-563.
</p>
<p>Noufaily, A., Enki, D.G., Farrington, C.P., Garthwaite, P.,
Andrews, N.J., Charlett, A. (2012): An improved algorithm for outbreak
detection in multiple surveillance systems. Statistics in Medicine,
32 (7), 1206-1222.
</p>
<p>Salmon, M., Schumacher, D., Stark, K., Höhle, M. (2015):
Bayesian outbreak detection in the presence of reporting delays.
Biometrical Journal, 57 (6), 1051-1067.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("stsNewport")
salm.Normal &lt;- list()
salmDelayAsym &lt;- list()
for (week in 43:45){
  listWeeks &lt;- as.Date(row.names(stsNewport@control$reportingTriangle$n))
  dateObs &lt;- listWeeks[isoWeekYear(listWeeks)$ISOYear==2011 &amp;
                       isoWeekYear(listWeeks)$ISOWeek==week]
  stsC &lt;- sts_observation(stsNewport,
                          dateObservation=dateObs,
                          cut=TRUE)
  inWeeks &lt;- with(isoWeekYear(epoch(stsC)),
                  ISOYear == 2011 &amp; ISOWeek &gt;= 40 &amp; ISOWeek &lt;= 48)
  
  rangeTest &lt;- which(inWeeks)
  alpha &lt;- 0.07

  # Control slot for Noufaily method          
  controlNoufaily &lt;- list(range=rangeTest,noPeriods=10,
                          b=4,w=3,weightsThreshold=2.58,pastWeeksNotIncluded=26,
                          pThresholdTrend=1,thresholdMethod="nbPlugin",alpha=alpha*2,
                          limit54=c(0,50))
  
  # Control slot for the Proposed algorithm with D=0 correction
  controlNormal &lt;- list(range = rangeTest, b = 4, w = 3,
                        reweight = TRUE, mc.munu=10000, mc.y=100,
                        verbose = FALSE,
                        alpha = alpha, trend = TRUE,
                        limit54=c(0,50), 
                        noPeriods = 10, pastWeeksNotIncluded = 26,
                        delay=FALSE)
  
  # Control slot for the Proposed algorithm with D=10 correction
  controlDelayNorm &lt;-  list(range = rangeTest, b = 4, w = 3,
                            reweight = FALSE, mc.munu=10000, mc.y=100,
                            verbose = FALSE,
                            alpha = alpha, trend = TRUE,
                            limit54=c(0,50), 
                            noPeriods = 10, pastWeeksNotIncluded = 26,
                            delay=TRUE,inferenceMethod="asym")
  
  set.seed(1)
  salm.Normal[[week]] &lt;- farringtonFlexible(stsC, controlNoufaily)
  salmDelayAsym[[week]] &lt;- bodaDelay(stsC, controlDelayNorm)
}

opar &lt;- par(mfrow=c(2,3))
lapply(salmDelayAsym[c(43,44,45)],plot, legend=NULL, main="", ylim=c(0,35))
lapply(salm.Normal[c(43,44,45)],plot, legend=NULL, main="", ylim=c(0,35))
par(opar)

## End(Not run)
</code></pre>

<hr>
<h2 id='calibrationTest'>
Calibration Tests for Poisson or Negative Binomial Predictions
</h2><span id='topic+calibrationTest'></span><span id='topic+calibrationTest.default'></span>

<h3>Description</h3>

<p>The implemented calibration tests for Poisson or negative binomial
predictions of count data are based on proper scoring rules and
described in detail in Wei and Held (2014).
The following proper scoring rules are available:
Dawid-Sebastiani score (<code>"dss"</code>),
logarithmic score (<code>"logs"</code>),
ranked probability score (<code>"rps"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrationTest(x, ...)

## Default S3 method:
calibrationTest(x, mu, size = NULL,
                which = c("dss", "logs", "rps"),
                tolerance = 1e-4, method = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrationTest_+3A_x">x</code></td>
<td>

<p>the observed counts.
All involved functions are vectorized and also accept matrices or arrays.
</p>
</td></tr>
<tr><td><code id="calibrationTest_+3A_mu">mu</code></td>
<td>

<p>the means of the predictive distributions for the
observations <code>x</code>.
</p>
</td></tr>
<tr><td><code id="calibrationTest_+3A_size">size</code></td>
<td>

<p>either <code>NULL</code> (default), indicating Poisson predictions with mean
<code>mu</code>, or dispersion parameters of
negative binomial forecasts for the observations <code>x</code>,
parametrized as in <code><a href="stats.html#topic+dnbinom">dnbinom</a></code> with variance
<code>mu*(1+mu/size)</code>.
</p>
</td></tr>
<tr><td><code id="calibrationTest_+3A_which">which</code></td>
<td>

<p>a character string indicating which proper scoring rule to apply.
</p>
</td></tr>
<tr><td><code id="calibrationTest_+3A_tolerance">tolerance</code></td>
<td>

<p>absolute tolerance for the null expectation and variance of
<code>"logs"</code> and <code>"rps"</code>. For the latter, see the note below.
Unused for <code>which = "dss"</code> (closed form).
</p>
</td></tr>
<tr><td><code id="calibrationTest_+3A_method">method</code></td>
<td>

<p>selection of the <code class="reqn">z</code>-statistic: <code>method = 2</code> refers to
the alternative test statistic <code class="reqn">Z_s^*</code> of Wei and Held (2014,
Discussion), which has been recommended for low counts.
<code>method = 1</code> corresponds to Equation 5 in Wei and Held (2014).
</p>
</td></tr>
<tr><td><code id="calibrationTest_+3A_...">...</code></td>
<td>

<p>unused (argument of the generic).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"htest"</code>,
which is a list with the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the type of test
performed (including <code>which</code> scoring rule).</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string naming the supplied <code>x</code> argument.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>the <code class="reqn">z</code>-statistic of the test.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the number of predictions underlying the test, i.e., <code>length(x)</code>.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the <a href="https://CRAN.R-project.org/package=gsl"><span class="pkg">gsl</span></a> package is installed, its implementations of the
Bessel and hypergeometric functions are used when calculating the null
expectation and variance of the <code>rps</code>.
These functions are faster and yield more accurate results (especially
for larger <code>mu</code>).
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer and Wei Wei
</p>


<h3>References</h3>

<p>Wei, W. and Held, L. (2014):
Calibration tests for count data.
<em>Test</em>, <b>23</b>, 787-805.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu &lt;- c(0.1, 1, 3, 6, pi, 100)
size &lt;- 0.1
set.seed(1)
y &lt;- rnbinom(length(mu), mu = mu, size = size)
calibrationTest(y, mu = mu, size = size) # p = 0.99
calibrationTest(y, mu = mu, size = 1) # p = 4.3e-05
calibrationTest(y, mu = 1, size = size) # p = 0.6959
calibrationTest(y, mu = 1, size = size, which = "rps") # p = 0.1286
</code></pre>

<hr>
<h2 id='campyDE'>Campylobacteriosis and Absolute Humidity in Germany 2002-2011</h2><span id='topic+campyDE'></span>

<h3>Description</h3>

<p>Weekly number of reported campylobacteriosis cases in Germany,
2002-2011, together with the corresponding absolute humidity (in g/m^3)
that week. The absolute humidity was computed according to the
procedure by Dengler (1997) using the means of representative weather
station data from the German Climate service.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(campyDE)
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> containing the following columns
</p>

<dl>
<dt><code>date</code></dt><dd><p><code>Date</code> instance containing the Monday of the
reporting week.</p>
</dd>
<dt><code>case</code></dt><dd><p>Number of reported cases that week.</p>
</dd>
<dt><code>state</code></dt><dd><p>Boolean indicating whether there is external knowledge
about an outbreak that week</p>
</dd>
<dt><code>hum</code></dt><dd><p>Mean absolute humidity (in g/m^3) of that week as
measured by a single representative weather station.</p>
</dd>
<dt><code>l1.hum</code>-<code>l5.hum</code></dt><dd><p>Lagged version (lagged by 1-5) of
the <code>hum</code> covariate.</p>
</dd>
<dt>newyears</dt><dd><p>Boolean indicating whether the reporting week
corresponds to the first two weeks of the year (TRUE) or not
(FALSE). Note: The first week of a year is here defined as the first
reporting week, which has its corresponding Monday within new year.</p>
</dd>
<dt>christmas</dt><dd><p>Boolean indicating whether the reporting week
corresponds to the last two weeks of the year (TRUE) or not
(FALSE). Note: This are the first two weeks before the
<code>newyears</code> weeks.</p>
</dd> 
<dt>O104period</dt><dd><p>Boolean indicating whether the reporting week
corresponds to the W21-W30 period of increased gastroenteritis
awareness during the O104:H4 STEC outbreak.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data on campylobacteriosis cases have been queried from the
Survstat@RKI database of the German Robert Koch Institute
(<a href="https://survstat.rki.de/">https://survstat.rki.de/</a>).
</p>
<p>Data for the computation of absolute humidity were obtained from the
German Climate Service (Deutscher Wetterdienst), Climate data of
Germany, available at <a href="https://www.dwd.de">https://www.dwd.de</a>.
</p>
<p>A complete data description and an analysis of the data can be found
in Manitz and Höhle (2013).
</p>


<h3>References</h3>

<p>Manitz, J. and Höhle, M. (2013):
Bayesian outbreak detection algorithm for monitoring reported cases of
campylobacteriosis in Germany.
Biometrical Journal, 55(4), 509-526.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the data
data("campyDE")

# O104 period is W21-W30 in 2011
stopifnot(all(campyDE$O104period == (
  (campyDE$date &gt;= as.Date("2011-05-23")) &amp;
  (campyDE$date &lt; as.Date("2011-07-31"))
)))

# Make an sts object from the data.frame
cam.sts &lt;- sts(epoch=campyDE$date, observed=campyDE$case, state=campyDE$state)

# Plot the result
plot(cam.sts)
</code></pre>

<hr>
<h2 id='categoricalCUSUM'>CUSUM detector for time-varying categorical time series</h2><span id='topic+categoricalCUSUM'></span><span id='topic+catcusum.LLRcompute'></span>

<h3>Description</h3>

<p>Function to process <code>sts</code> object by binomial, beta-binomial
or multinomial CUSUM as described by Höhle (2010).
Logistic, multinomial logistic, proportional
odds or Bradley-Terry regression models are used to specify in-control
and out-of-control parameters.
The implementation is illustrated in Salmon et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categoricalCUSUM(stsObj,control = list(range=NULL,h=5,pi0=NULL,
                 pi1=NULL, dfun=NULL, ret=c("cases","value")),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="categoricalCUSUM_+3A_stsobj">stsObj</code></td>
<td>
<p>Object of class <code>sts</code> containing the number of
counts in each of the <code class="reqn">k</code> categories of the response
variable. Time varying number of counts <code class="reqn">n_t</code> is found in slot
<code>populationFrac</code>. </p>
</td></tr>
<tr><td><code id="categoricalCUSUM_+3A_control">control</code></td>
<td>
<p>Control object containing several items
</p>

<dl>
<dt><code>range</code></dt><dd><p>Vector of length <code class="reqn">t_{max}</code> with indices of the
<code>observed</code> slot to monitor.</p>
</dd>
<dt><code>h</code></dt><dd><p>Threshold to use for the monitoring. Once the
CUSUM statistics is larger or equal to <code>h</code> we have an alarm.</p>
</dd>
<dt><code>pi0</code></dt><dd><p><code class="reqn">(k-1) \times t_{max}</code> in-control probability
vector for all categories except the reference category.</p>
</dd>
<dt><code>mu1</code></dt><dd><p><code class="reqn">(k-1) \times t_{max}</code> out-of-control probability
vector for all categories except the reference category.</p>
</dd>
<dt><code>dfun</code></dt><dd><p>The probability mass function (PMF) or density used
to compute the likelihood ratios of the CUSUM. In a negative
binomial CUSUM this is <code>dnbinom</code>, in a binomial CUSUM
<code>dbinom</code> and in a multinomial CUSUM <code>dmultinom</code>. The
function must be able to handle the arguments <code>y</code>,
<code>size</code>, <code>mu</code> and <code>log</code>. As a consequence, one in
the case of, e.g, the beta-binomial distribution has to write a small
wrapper function.</p>
</dd>
<dt><code>ret</code></dt><dd><p>Return the necessary proportion to sound an alarm in the
slot <code>upperbound</code> or just the value of the CUSUM
statistic. Thus, <code>ret</code> is one of the values in
<code>c("cases","value")</code>. Note: For the binomial PMF it is
possible to compute this value explicitly, which is much faster
than the numeric search otherwise conducted. In case <code>dfun</code>
just corresponds to <code>dbinom</code> just set the attribute
<code>isBinomialPMF</code> for the <code>dfun</code> object.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="categoricalCUSUM_+3A_...">...</code></td>
<td>
<p>Additional arguments to send to <code>dfun</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function allows the monitoring of categorical time series as
described by regression models for binomial, beta-binomial or
multinomial data. The later includes e.g. multinomial logistic
regression models, proportional odds models or Bradley-Terry models
for paired comparisons. See the Höhle (2010) reference
for further details about the methodology.
</p>
<p>Once an alarm is found the CUSUM scheme is reset (to zero) and
monitoring continues from there.
</p>


<h3>Value</h3>

<p>An <code>sts</code> object with <code>observed</code>, <code>alarm</code>,
etc. slots trimmed to the <code>control$range</code> indices.
</p>


<h3>Author(s)</h3>

<p>M. Höhle</p>


<h3>References</h3>

<p>Höhle, M. (2010):
Online Change-Point Detection in Categorical Time Series.
In: T. Kneib and G. Tutz (Eds.), Statistical
Modelling and Regression Structures, Physica-Verlag.
</p>
<p>Salmon, M., Schumacher, D. and Höhle, M. (2016):
Monitoring count time series in <span class="rlang"><b>R</b></span>: Aberration detection in public
health surveillance. <em>Journal of Statistical Software</em>,
<b>70</b> (10), 1-35. <a href="https://doi.org/10.18637/jss.v070.i10">doi:10.18637/jss.v070.i10</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LRCUSUM.runlength">LRCUSUM.runlength</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("gamlss")) {
  ###########################################################################
  #Beta-binomial CUSUM for a small example containing the time-varying
  #number of positive test out of a time-varying number of total
  #test.
  #######################################

  #Load meat inspection data
  data("abattoir")

  #Use GAMLSS to fit beta-bin regression model
  phase1 &lt;- 1:(2*52)
  phase2  &lt;- (max(phase1)+1) : nrow(abattoir)

  #Fit beta-binomial model using GAMLSS
  abattoir.df &lt;- as.data.frame(abattoir)

  #Replace the observed and epoch column names to something more convenient
  dict &lt;- c("observed"="y", "epoch"="t", "population"="n")
  replace &lt;- dict[colnames(abattoir.df)]
  colnames(abattoir.df)[!is.na(replace)] &lt;- replace[!is.na(replace)]

  m.bbin &lt;- gamlss( cbind(y,n-y) ~ 1 + t +
                      + sin(2*pi/52*t) + cos(2*pi/52*t) +
                      + sin(4*pi/52*t) + cos(4*pi/52*t), sigma.formula=~1,
                   family=BB(sigma.link="log"),
                   data=abattoir.df[phase1,c("n","y","t")])

  #CUSUM parameters
  R &lt;- 2 #detect a doubling of the odds for a test being positive
  h &lt;- 4 #threshold of the cusum

  #Compute in-control and out of control mean
  pi0 &lt;- predict(m.bbin,newdata=abattoir.df[phase2,c("n","y","t")],type="response")
  pi1 &lt;- plogis(qlogis(pi0)+log(R))
  #Create matrix with in control and out of control proportions.
  #Categories are D=1 and D=0, where the latter is the reference category
  pi0m &lt;- rbind(pi0, 1-pi0)
  pi1m &lt;- rbind(pi1, 1-pi1)


  ######################################################################
  # Use the multinomial surveillance function. To this end it is necessary
  # to create a new abattoir object containing counts and proportion for
  # each of the k=2 categories. For binomial data this appears a bit
  # redundant, but generalizes easier to k&gt;2 categories.
  ######################################################################

  abattoir2 &lt;- sts(epoch=1:nrow(abattoir), start=c(2006,1), freq=52,
    observed=cbind(abattoir@observed, abattoir@populationFrac-abattoir@observed),
    populationFrac=cbind(abattoir@populationFrac,abattoir@populationFrac),
    state=matrix(0,nrow=nrow(abattoir),ncol=2),
    multinomialTS=TRUE)

  ######################################################################
  #Function to use as dfun in the categoricalCUSUM
  #(just a wrapper to the dBB function). Note that from v 3.0-1 the
  #first argument of dBB changed its name from "y" to "x"!
  ######################################################################
  mydBB.cusum &lt;- function(y, mu, sigma, size, log = FALSE) {
    return(dBB(y[1,], mu = mu[1,], sigma = sigma, bd = size, log = log))
  }


  #Create control object for multinom cusum and use the categoricalCUSUM
  #method
  control &lt;- list(range=phase2,h=h,pi0=pi0m, pi1=pi1m, ret="cases",
		   dfun=mydBB.cusum)
  surv &lt;- categoricalCUSUM(abattoir2, control=control,
			   sigma=exp(m.bbin$sigma.coef))

  #Show results
  plot(surv[,1],dx.upperbound=0)
  lines(pi0,col="green")
  lines(pi1,col="red")

  #Index of the alarm
  which.max(alarms(surv[,1]))
}
</code></pre>

<hr>
<h2 id='checkResidualProcess'>
Check the residual process of a fitted <code>twinSIR</code> or <code>twinstim</code>
</h2><span id='topic+checkResidualProcess'></span>

<h3>Description</h3>

<p>Transform the residual process (cf. the
<code><a href="#topic+residuals.twinstim">residuals</a></code> methods for classes
<code>"twinSIR"</code> and <code>"twinstim"</code>) such that the transformed
residuals should be uniformly distributed if the fitted model
well describes the true conditional intensity function. Graphically
check this using <code><a href="#topic+ks.plot.unif">ks.plot.unif</a></code>.
The transformation for the residuals <code>tau</code> is
<code>1 - exp(-diff(c(0,tau)))</code> (cf. Ogata, 1988).
Another plot inspects the serial correlation between the transformed
residuals (scatterplot between <code class="reqn">u_i</code> and <code class="reqn">u_{i+1}</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkResidualProcess(object, plot = 1:2, mfrow = c(1,length(plot)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkResidualProcess_+3A_object">object</code></td>
<td>

<p>an object of class <code>"<a href="#topic+twinSIR">twinSIR</a>"</code> or <code>"<a href="#topic+twinstim">twinstim</a>"</code>.
</p>
</td></tr>
<tr><td><code id="checkResidualProcess_+3A_plot">plot</code></td>
<td>

<p>logical (or integer index) vector indicating if (which) plots of the
transformed residuals should be produced. The <code>plot</code> index 1
corresponds to a <code><a href="#topic+ks.plot.unif">ks.plot.unif</a></code> to check for deviations
of the transformed residuals from the uniform distribution. The
<code>plot</code> index 2 corresponds to a scatterplot of <code class="reqn">u_i</code> vs.
<code class="reqn">u_{i+1}</code>. By default (<code>plot = 1:2</code>), both plots are produced.
</p>
</td></tr>
<tr><td><code id="checkResidualProcess_+3A_mfrow">mfrow</code></td>
<td>

<p>see <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="checkResidualProcess_+3A_...">...</code></td>
<td>

<p>further arguments passed to <code><a href="#topic+ks.plot.unif">ks.plot.unif</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (returned invisibly, if <code>plot = TRUE</code>) with the following
components:
</p>

<dl>
<dt>tau</dt><dd><p>the residual process obtained by
<code>residuals(object)</code>.</p>
</dd>
<dt>U</dt><dd><p>the transformed residuals which should be distributed as
U(0,1).</p>
</dd>
<dt>ks</dt><dd><p>the result of the <code>ks.test</code> for the uniform
distribution of <code>U</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Ogata, Y. (1988)
Statistical models for earthquake occurrences and residual analysis
for point processes.
<em>Journal of the American Statistical Association</em>, 83, 9-27
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ks.plot.unif">ks.plot.unif</a></code> and the
<code><a href="#topic+residuals.twinstim">residuals</a></code>-method for classes
<code>"twinSIR"</code> and <code>"twinstim"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
fit &lt;- twinSIR(~ household, data = hagelloch)  # a simplistic model
## extract the "residual process", i.e., the fitted cumulative intensities
residuals(fit)
## assess goodness of fit based on these residuals
checkResidualProcess(fit)  # could be better
</code></pre>

<hr>
<h2 id='clapply'>
Conditional <code>lapply</code>
</h2><span id='topic+clapply'></span>

<h3>Description</h3>

<p>Use <code><a href="base.html#topic+lapply">lapply</a></code> if the input is a list and otherwise apply the
function directly to the input <em>and</em> wrap the result in a list.
The function is implemented as
</p>
<pre>
    if (is.list(X)) lapply(X, FUN, ...) else list(FUN(X, ...))
</pre>


<h3>Usage</h3>

<pre><code class='language-R'>clapply(X, FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clapply_+3A_x">X</code></td>
<td>
<p>a list or a single <code>R</code> object on which to apply <code>FUN</code>.</p>
</td></tr>
<tr><td><code id="clapply_+3A_fun">FUN</code></td>
<td>
<p>the function to be applied to (each element of) <code>X</code>.</p>
</td></tr>
<tr><td><code id="clapply_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list (of length 1 if <code>X</code> is not a list).
</p>

<hr>
<h2 id='coeflist'>
List Coefficients by Model Component
</h2><span id='topic+coeflist'></span><span id='topic+coeflist.default'></span>

<h3>Description</h3>

<p>S3-generic function to use with models which contain several groups of
coefficients in their coefficient vector. The <code>coeflist</code> methods
are intended to list the coefficients by group. The default method
simply <code><a href="base.html#topic+split">split</a></code>s the coefficient vector given the number of
coefficients by group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coeflist(x, ...)

## Default S3 method:
coeflist(x, npars, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coeflist_+3A_x">x</code></td>
<td>

<p>a model with groups of coefficients or, for the default method, a
vector of coefficients.
</p>
</td></tr>
<tr><td><code id="coeflist_+3A_npars">npars</code></td>
<td>

<p>a named vector specifying the number of coefficients per group.
</p>
</td></tr>
<tr><td><code id="coeflist_+3A_...">...</code></td>
<td>

<p>potential further arguments (currently ignored).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of coefficients
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## the default method just 'split's the coefficient vector
coefs &lt;- c(a = 1, b = 3, dispersion = 0.5)
npars &lt;- c(regression = 2, variance = 1)
coeflist(coefs, npars)
</code></pre>

<hr>
<h2 id='create.disProg'>Creating an object of class <code>disProg</code> (DEPRECATED)</h2><span id='topic+create.disProg'></span>

<h3>Description</h3>

<p>Creating objects of the legacy class <code>disProg</code> is deprecated;
use <code><a href="#topic+sts">sts</a></code> instead.
</p>
<p>An object of class <code>disProg</code> takes a vector with the weeknumber
(week) and matrices with the observed number of counts (observed) and the
respective state chains (state), where each column represents an individual
time series. The matrices neighbourhood and populationFrac provide 
information about neighbouring units and population proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.disProg(week, observed, state, start=c(2001,1), freq=52, 
               neighbourhood=NULL, populationFrac=NULL, epochAsDate=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.disProg_+3A_week">week</code></td>
<td>
<p>index in the matrix of observations, typically weeks</p>
</td></tr>
<tr><td><code id="create.disProg_+3A_observed">observed</code></td>
<td>
<p>matrix with parallel time series of counts where rows are 
time points and columns are the individual time series for unit/area
<code class="reqn">i, i=1,\ldots,m</code></p>
</td></tr>
<tr><td><code id="create.disProg_+3A_state">state</code></td>
<td>
<p>matrix with corresponding states</p>
</td></tr>
<tr><td><code id="create.disProg_+3A_start">start</code></td>
<td>
<p>vector of length two denoting the year and the sample number (week, month, etc.) of the first observation</p>
</td></tr>
<tr><td><code id="create.disProg_+3A_freq">freq</code></td>
<td>
<p>sampling frequency per year, i.e. 52 for weekly data, 12 for monthly data, 13 if 52 weeks are aggregated into 4 week blocks.</p>
</td></tr>
<tr><td><code id="create.disProg_+3A_neighbourhood">neighbourhood</code></td>
<td>
<p>neighbourhood matrix <code class="reqn">N</code> of dimension 
<code class="reqn">m \times m</code> with elements <code class="reqn">n_{ij}=1</code> if units <code class="reqn">i</code>
and <code class="reqn">j</code> are adjacent and 0 otherwise </p>
</td></tr> 
<tr><td><code id="create.disProg_+3A_populationfrac">populationFrac</code></td>
<td>
<p>matrix with corresponding population proportions</p>
</td></tr> 
<tr><td><code id="create.disProg_+3A_epochasdate">epochAsDate</code></td>
<td>
<p>interpret the integers in <code>week</code> as Dates. Default is <code>FALSE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code>disProg</code></p>


<h3>Author(s)</h3>

<p>M. Paul</p>

<hr>
<h2 id='deleval'>Surgical Failures Data</h2><span id='topic+deleval'></span>

<h3>Description</h3>

<p>The dataset from Steiner et al. (1999) on A synthetic dataset from the Danish meat inspection &ndash; useful
for illustrating the beta-binomial CUSUM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(deleval)</code></pre>


<h3>Details</h3>

<p>Steiner et al. (1999) use data from de Leval et al. (1994) to
illustrate monitoring of failure rates of a surgical procedure
for a bivariate outcome. 
</p>
<p>Over a period of six years an arterial switch operation was performed
on 104 newborn babies. Since the death rate from this surgery was
relatively low the idea of surgical &quot;near miss&quot; was introduced. It is
defined as the need to reinstitute cardiopulmonary bypass after a trial
period of weaning. The object of class <code><a href="#topic+sts-class">sts</a></code> contains the
recordings of near misses and deaths from the surgery for the 104
newborn babies of the study.
</p>
<p>The data could also be handled by a multinomial CUSUM model.
</p>


<h3>References</h3>

<p>Steiner, S. H., Cook, R. J., and Farewell, V. T. (1999), Monitoring
paired binary surgical outcomes using cumulative sum charts,
Statistics in Medicine, 18, pp. 69&ndash;86.
</p>
<p>De Leval, Marc R., Franiois, K., Bull, C., Brawn, W. B. and
Spiegelhalter, D. (1994),  Analysis of a cluster of
surgical failures, Journal of Thoracic and Cardiovascular Surgery,
March, pp. 914&ndash;924.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pairedbinCUSUM">pairedbinCUSUM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("deleval")
plot(deleval, xaxis.labelFormat=NULL,ylab="Response",xlab="Patient number")
</code></pre>

<hr>
<h2 id='discpoly'>Polygonal Approximation of a Disc/Circle</h2><span id='topic+discpoly'></span>

<h3>Description</h3>

<p>Generates a polygon representing a disc/circle (in planar
coordinates) as an object of one of three possible
classes: <code>"<a href="sp.html#topic+Polygon-class">Polygon</a>"</code> from package <a href="https://CRAN.R-project.org/package=sp"><span class="pkg">sp</span></a>,
<code>"<a href="spatstat.geom.html#topic+owin">owin</a>"</code> from package <a href="https://CRAN.R-project.org/package=spatstat.geom"><span class="pkg">spatstat.geom</span></a>, or
<code>"gpc.poly"</code> from <span class="pkg">gpclib</span> (if available).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discpoly(center, radius, npoly = 64,
         class = c("Polygon", "owin", "gpc.poly"),
         hole = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discpoly_+3A_center">center</code></td>
<td>
<p>numeric vector of length 2 (center coordinates of the circle).</p>
</td></tr>
<tr><td><code id="discpoly_+3A_radius">radius</code></td>
<td>
<p>single numeric value (radius of the circle).</p>
</td></tr>
<tr><td><code id="discpoly_+3A_npoly">npoly</code></td>
<td>
<p>single integer. Number of edges of the polygonal approximation.</p>
</td></tr>
<tr><td><code id="discpoly_+3A_class">class</code></td>
<td>
<p>class of the resulting polygon (partial name
matching applies). For <code>"owin"</code>, this is just a
wrapper around <span class="pkg">spatstat.geom</span>'s own <code><a href="spatstat.geom.html#topic+disc">disc</a></code> function.</p>
</td></tr>
<tr><td><code id="discpoly_+3A_hole">hole</code></td>
<td>
<p>logical. Does the resulting polygon represent a hole?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A polygon of class <code>class</code> representing a
circle/disc with <code>npoly</code> edges accuracy.
</p>
<p>If <code>class="gpc.poly"</code> and this S4 class is not yet registered
in the current <span class="rlang"><b>R</b></span> session (by loading <span class="pkg">gpclib</span> beforehand), only the
<code>pts</code> slot of a <code>"gpc.poly"</code> is returned with a warning.
</p>


<h3>See Also</h3>

<p><code><a href="spatstat.geom.html#topic+disc">disc</a></code> in package <span class="pkg">spatstat.geom</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Construct circles with increasing accuracy and of different spatial classes
disc1 &lt;- discpoly(c(0,0), 5, npoly=4, class = "owin")
disc2 &lt;- discpoly(c(0,0), 5, npoly=16, class = "Polygon")
disc3 &lt;- discpoly(c(0,0), 5, npoly=64, class = "gpc.poly")  # may warn

## Look at the results
print(disc1)
plot(disc1, axes=TRUE, main="", border=2)

print(disc2)
lines(disc2, col=3)

print(disc3)  # a list or a formal "gpc.poly" (if gpclib is available)
if (is(disc3, "gpc.poly")) {
  plot(disc3, add=TRUE, poly.args=list(border=4))
} else {
  lines(disc3[[1]], col=4)
}

## to only _draw_ a circle
symbols(0, 0, circles=5, inches=FALSE, add=TRUE, fg=5)
</code></pre>

<hr>
<h2 id='disProg2sts'>Convert disProg object to sts and vice versa</h2><span id='topic+disProg2sts'></span><span id='topic+sts2disProg'></span>

<h3>Description</h3>

<p>A small helper function to convert a <code>disProg</code> object to become
an object of the S4 class <code>sts</code> and vice versa. In the future the
<code>sts</code> should replace the <code>disProg</code> class, but for now this
function allows for conversion between the two formats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   disProg2sts(disProgObj, map=NULL)
   sts2disProg(sts)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disProg2sts_+3A_disprogobj">disProgObj</code></td>
<td>
<p>an object of class <code>"disProg"</code></p>
</td></tr>
<tr><td><code id="disProg2sts_+3A_map">map</code></td>
<td>
<p>an optional <code>"SpatialPolygons"</code> object</p>
</td></tr>
<tr><td><code id="disProg2sts_+3A_sts">sts</code></td>
<td>
<p>an object of class <code>"sts"</code> to convert</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"sts"</code> or <code>"disProg"</code>, respectively.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sts-class">sts-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(ha)
  print(disProg2sts(ha))
  class(sts2disProg(disProg2sts(ha)))
</code></pre>

<hr>
<h2 id='earsC'>Surveillance for a count data time series using the EARS C1, C2
or C3 method and its extensions</h2><span id='topic+earsC'></span>

<h3>Description</h3>


<p>The function takes <code>range</code> values of the surveillance time
series <code>sts</code> and for each time point computes a threshold for the number of counts
based on values from the recent past.
This is then compared to the observed
number of counts. If the observation is above a specific quantile of
the prediction interval, then an alarm is raised.  This method is especially useful
for data without many historic values, since it only needs counts from the recent past.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>earsC(sts, control = list(range = NULL, method = "C1",
                          baseline = 7, minSigma = 0,
                          alpha = 0.001))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="earsC_+3A_sts">sts</code></td>
<td>
<p>object of class sts (including the <code>observed</code> and the <code>state</code> time series) , which is to be monitored.</p>
</td></tr>
<tr><td><code id="earsC_+3A_control">control</code></td>
<td>
<p>Control object
</p>

<dl>
<dt><code>range</code></dt><dd><p>Specifies the index in the <code>sts</code> object of
all the timepoints which
should be monitored. If <code>range</code> is <code>NULL</code> the maximum number
of possible timepoints is used (this number depends on the method chosen):
</p>

<dl>
<dt>C1</dt><dd><p>all timepoints from the observation with index <code>baseline + 1</code>
can be monitored,</p>
</dd>
<dt>C2</dt><dd><p>timepoints from index <code>baseline + 3</code> can be
monitored,</p>
</dd>
<dt>C3</dt><dd><p>timepoints starting from the index <code>baseline + 5</code> can be monitored.</p>
</dd>
</dl>

</dd>
<dt><code>method</code></dt><dd><p>String indicating which method to use: <br />
</p>

<dl>
<dt><code>"C1"</code></dt><dd><p>for EARS C1-MILD method (Default),</p>
</dd>
<dt><code>"C2"</code></dt><dd><p>for EARS C2-MEDIUM method,</p>
</dd>
<dt><code>"C3"</code></dt><dd><p>for EARS C3-HIGH method.</p>
</dd>
</dl>

<p>See Details for further information about the methods.
</p>
</dd>
<dt><code>baseline</code></dt><dd><p>how many time points to use for calculating the baseline, see details</p>
</dd>
<dt><code>minSigma</code></dt><dd><p>By default 0. If <code>minSigma</code> is higher than 0, for C1 and
C2, the quantity zAlpha * minSigma is then the alerting threshold if the
baseline is zero. Howard Burkom suggests using a value of 0.5 or 1 for sparse data.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>An approximate (two-sided) <code class="reqn">(1-\alpha)\cdot 100\%</code> prediction
interval is calculated. By default if <code>alpha</code> is <code>NULL</code>
the value 0.001 is assumed
for C1 and C2 whereas 0.025 is assumed for C3. These different choices are the one made at the CDC.</p>
</dd>

</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>The three methods are different in terms of baseline used for calculation of
the expected value and in terms of method for calculating the expected value:
</p>

<ul>
<li><p> in C1 and C2 the expected value is the moving average of counts over
the sliding window of the baseline and the prediction interval depends on the
standard derivation of the observed counts in this window. They can be considered as
Shewhart control charts with a small sample used for calculations.
</p>
</li>
<li><p> in C3 the expected value is based on the sum over 3 timepoints
(assessed timepoints and the two previous timepoints) of the discrepancy
between observations and predictions, predictions being calculated with
the C2 method.
This method has similarities with a CUSUM method due to it
adding discrepancies between predictions and observations over several timepoints,
but is not a CUSUM  (sum over 3 timepoints, not accumulation over a whole range),
even if it sometimes is presented as such.
</p>
</li></ul>

<p>Here is what the function does for each method, see the literature
sources for further details:
</p>

<ol>
<li><p> For C1 the baseline are the <code>baseline</code> (default 7) timepoints before the assessed timepoint t,
t-<code>baseline</code> to t-1. The expected value is the mean of the baseline. An approximate
(two-sided) <code class="reqn">(1-\alpha)\cdot 100\%</code> prediction interval is calculated based on the
assumption that  the difference between the expected value and the observed
value divided by the standard derivation of counts over the sliding window,
called <code class="reqn">C_1(t)</code>, follows a standard normal distribution in the absence
of outbreaks:
</p>
<p style="text-align: center;"><code class="reqn">C_1(t)= \frac{Y(t)-\bar{Y}_1(t)}{S_1(t)},</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\bar{Y}_1(t)= \frac{1}{\code{baseline}} \sum_{i=t-1}^{t-\code{baseline}} Y(i)</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn"> S^2_1(t)= \frac{1}{6} \sum_{i=t-1}^{t-\code{baseline}} [Y(i) - \bar{Y}_1(i)]^2.</code>
</p>

<p>Then under the null hypothesis of no outbreak,
</p>
<p style="text-align: center;"><code class="reqn">C_1(t) \mathcal \&gt; \sim \&gt; {N}(0,1)</code>
</p>

<p>An alarm is raised if </p>
<p style="text-align: center;"><code class="reqn">C_1(t)\ge z_{1-\alpha}</code>
</p>

<p>with <code class="reqn">z_{1-\alpha}</code> the <code class="reqn">(1-\alpha)^{th}</code> quantile of the standard normal distribution. <br />
</p>
<p>The upperbound <code class="reqn">U_1(t)</code> is then defined by:
</p>
<p style="text-align: center;"><code class="reqn">U_1(t)= \bar{Y}_1(t) + z_{1-\alpha}S_1(t).</code>
</p>

</li>
<li><p> C2 is very similar to C1 apart from a 2-day lag in the baseline definition.
In other words the baseline for C2 is <code>baseline</code> (Default: 7) timepoints with a 2-day lag before the monitored
timepoint t, i.e. <code class="reqn">(t-\code{baseline}-2)</code> to <code class="reqn">t-3</code>. The expected value is the mean of the baseline. An approximate
(two-sided) <code class="reqn">(1-\alpha)\cdot 100\%</code> prediction interval is calculated based on the
assumption that  the difference between the expected value and the observed
value divided by the standard derivation of counts over the sliding window,
called <code class="reqn">C_2(t)</code>, follows a standard normal distribution in the absence
of outbreaks:
</p>
<p style="text-align: center;"><code class="reqn">C_2(t)= \frac{Y(t)-\bar{Y}_2(t)}{S_2(t)},</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\bar{Y}_2(t)= \frac{1}{\code{baseline}} \sum_{i=t-3}^{t-\code{baseline}-2} Y(i)</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn"> S^2_2(t)= \frac{1}{\code{baseline}-1} \sum_{i=t-3}^{t-\code{baseline}-2} [Y(i) - \bar{Y}_2(i)]^2.</code>
</p>

<p>Then under the null hypothesis of no outbreak,
</p>
<p style="text-align: center;"><code class="reqn">C_2(t) \mathcal \sim {N}(0,1)</code>
</p>

<p>An alarm is raised if </p>
<p style="text-align: center;"><code class="reqn">C_2(t)\ge z_{1-\alpha},</code>
</p>

<p>with <code class="reqn">z_{1-\alpha}</code> the <code class="reqn">(1-\alpha)^{th}</code> quantile of the standard normal distribution. <br />
</p>
<p>The upperbound <code class="reqn">U_{2}(t)</code> is then defined by:
</p>
<p style="text-align: center;"><code class="reqn">U_{2}(t)= \bar{Y}_{2}(t) + z_{1-\alpha}S_{2}(t).</code>
</p>

</li>
<li><p> C3 is quite different from the two other methods, but it is based on C2.
Indeed it uses <code class="reqn">C_2(t)</code> from timepoint t and the two previous timepoints.
This means the baseline consists of the timepoints <code class="reqn">t-(\code{baseline}+4)</code> to <code class="reqn">t-3</code>.
The statistic <code class="reqn">C_3(t)</code> is the sum of discrepancies between observations and
predictions.
</p>
<p style="text-align: center;"><code class="reqn">C_3(t)= \sum_{i=t}^{t-2} \max(0,C_2(i)-1)</code>
</p>

<p>Then under the null hypothesis of no outbreak,
</p>
<p style="text-align: center;"><code class="reqn">C_3(t) \mathcal \sim {N}(0,1)</code>
</p>

<p>An alarm is raised if </p>
<p style="text-align: center;"><code class="reqn">C_3(t)\ge z_{1-\alpha},</code>
</p>

<p>with <code class="reqn">z_{1-\alpha}</code> the <code class="reqn">(1-\alpha)^{th}</code> quantile of the standard normal distribution. <br />
</p>
<p>The upperbound <code class="reqn">U_3(t)</code> is then defined by:
</p>
<p style="text-align: center;"><code class="reqn">U_3(t)= \bar{Y}_2(t) + S_2(t)\left(z_{1-\alpha}-\sum_{i=t-1}^{t-2} \max(0,C_2(i)-1)\right).</code>
</p>

</li></ol>



<h3>Value</h3>

<p>An object of class <code>sts</code> with the slots <code>upperbound</code> and <code>alarm</code> filled
by the chosen method.
</p>


<h3>Author(s)</h3>

<p>M. Salmon, H. Burkom</p>


<h3>Source</h3>

<p>Fricker, R.D., Hegler, B.L, and Dunfee, D.A. (2008). Comparing syndromic surveillance detection methods: EARS versus a CUSUM-based methodology,
27:3407-3429, Statistics in medicine.
</p>
<p>Salmon, M., Schumacher, D. and Höhle, M. (2016):
Monitoring count time series in <span class="rlang"><b>R</b></span>: Aberration detection in public
health surveillance. <em>Journal of Statistical Software</em>,
<b>70</b> (10), 1-35. <a href="https://doi.org/10.18637/jss.v070.i10">doi:10.18637/jss.v070.i10</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Sim data and convert to sts object
disProgObj &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 208, A = 1,
                              alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 1.7)
stsObj &lt;- disProg2sts( disProgObj)


# Call earsC function and show result
res1 &lt;- earsC(stsObj, control = list(range = 20:208, method="C1"))
plot(res1, legend.opts=list(horiz=TRUE, x="topright"))


# Compare C3 upperbounds depending on alpha
res3 &lt;- earsC(stsObj, control = list(range = 20:208,method="C3",alpha = 0.001))
plot(upperbound(res3), type='l')
res3 &lt;- earsC(stsObj, control = list(range = 20:208,method="C3"))
lines(upperbound(res3), col='red')

</code></pre>

<hr>
<h2 id='epidata'>
Continuous-Time SIR Event History of a Fixed Population
</h2><span id='topic+as.epidata'></span><span id='topic+as.epidata.data.frame'></span><span id='topic+as.epidata.default'></span><span id='topic+print.epidata'></span><span id='topic++5B.epidata'></span><span id='topic+update.epidata'></span><span id='topic+epidata'></span>

<h3>Description</h3>

<p>The function <code>as.epidata</code> is used to generate objects
of class <code>"epidata"</code>.  Objects of this class are
specific data frames containing the event history of an epidemic together
with some additional attributes.  These objects are the basis for fitting
spatio-temporal epidemic intensity models with the function
<code><a href="#topic+twinSIR">twinSIR</a></code>.  Their implementation is illustrated in Meyer
et al. (2017, Section 4), see <code>vignette("twinSIR")</code>.
Note that the spatial information itself, i.e.
the positions of the individuals, is assumed to be constant over time.  
Besides epidemics following the SIR compartmental model, also data from SI,
SIRS and SIS epidemics may be supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.epidata(data, ...)

## S3 method for class 'data.frame'
as.epidata(data, t0,
           tE.col, tI.col, tR.col, id.col, coords.cols,
           f = list(), w = list(), D = dist,
           max.time = NULL, keep.cols = TRUE, ...)
## Default S3 method:
as.epidata(data, id.col, start.col, stop.col,
           atRiskY.col, event.col, Revent.col, coords.cols,
           f = list(), w = list(), D = dist, .latent = FALSE, ...)

## S3 method for class 'epidata'
print(x, ...)
## S3 method for class 'epidata'
x[i, j, drop]
## S3 method for class 'epidata'
update(object, f = list(), w = list(), D = dist, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidata_+3A_data">data</code></td>
<td>

<p>For the <code>data.frame</code>-method, a data frame with as many rows as
there are individuals in the population and time columns indicating
when each individual became exposed (optional), infectious
(mandatory, but can be <code>NA</code> for non-affected individuals) and
removed (optional). Note that this data format does not allow for
re-infection (SIRS) and time-varying covariates.
The <code>data.frame</code>-method converts the individual-indexed data
frame to the long event history start/stop format and then feeds it
into the default method. If calling the generic function
<code>as.epidata</code> on a <code>data.frame</code> and the <code>t0</code> argument
is missing, the default method is called directly.<br />
For the default method, <code>data</code> can be a <code><a href="base.html#topic+matrix">matrix</a></code> or
a <code><a href="base.html#topic+data.frame">data.frame</a></code>.
It must contain the observed event history in a form similar to 
<code>Surv(, type="counting")</code> in package <span class="pkg">survival</span>,
with additional information (variables) along 
the process.  Rows will be sorted automatically during conversion.
The observation period is split up into <em>consecutive</em>
intervals of constant state - thus constant infection intensities.
The data frame consists of a block of <code class="reqn">N</code> (number of individuals) 
rows for each of those time intervals (all rows in a block have the same start 
and stop values... therefore the name &ldquo;block&rdquo;), where there is one 
row per individual in the block.  Each row describes the (fixed) state of 
the individual during the interval given by the start and stop columns 
<code>start.col</code> and <code>stop.col</code>.<br />
Note that there may not be more than one event (infection or removal) in a
single block.  Thus, in a single block, only one entry in the 
<code>event.col</code> and <code>Revent.col</code> may be 1, all others are 0.  This
rule follows the point process characteristic that there are no
concurrent events (infections or removals).
</p>
</td></tr>
<tr><td><code id="epidata_+3A_t0">t0</code>, <code id="epidata_+3A_max.time">max.time</code></td>
<td>

<p>observation period. In the resulting <code>"epidata"</code>, the time
scale will be relative to the start time <code>t0</code>.
Individuals that have already been removed prior to <code>t0</code>, i.e.,
rows with <code>tR &lt;= t0</code>, will be dropped.
The end of the observation period (<code>max.time</code>) will by default
(<code>NULL</code>, or if <code>NA</code>) coincide with the last observed event.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_te.col">tE.col</code>, <code id="epidata_+3A_ti.col">tI.col</code>, <code id="epidata_+3A_tr.col">tR.col</code></td>
<td>

<p>single numeric or character indexes of the time columns in
<code>data</code>, which specify when the individuals became exposed,
infectious and removed, respectively.
<code>tE.col</code> and <code>tR.col</code> can be missing, corresponding to
SIR, SEI, or SI data. <code>NA</code> entries mean that the respective
event has not (yet) occurred. Note that <code>is.na(tE)</code> implies
<code>is.na(tI)</code> and <code>is.na(tR)</code>, and <code>is.na(tI)</code> implies
<code>is.na(tR)</code> (and this is checked for the provided data).<br />
CAVE: Support for latent periods (<code>tE.col</code>) is experimental!
<code><a href="#topic+twinSIR">twinSIR</a></code> cannot handle them anyway.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_id.col">id.col</code></td>
<td>

<p>single numeric or character index of the <code>id</code> column in <code>data</code>.
The <code>id</code> column identifies the individuals in the data frame.
It is converted to a factor by calling <code><a href="base.html#topic+factor">factor</a></code>, i.e.,
unused levels are dropped if it already was a factor.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_start.col">start.col</code></td>
<td>

<p>single index of the <code>start</code> column in <code>data</code>.  Can be numeric
(by column number) or character (by column name).
The <code>start</code> column contains the (numeric) time points of the beginnings
of the consecutive time intervals of the event history.  The minimum value
in this column, i.e. the start of the observation period should be 0.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_stop.col">stop.col</code></td>
<td>

<p>single index of the <code>stop</code> column in <code>data</code>.  Can be numeric
(by column number) or character (by column name).
The <code>stop</code> column contains the (numeric) time points of the ends
of the consecutive time intervals of the event history.  The stop value must
always be greater than the start value of a row.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_atrisky.col">atRiskY.col</code></td>
<td>

<p>single index of the <code>atRiskY</code> column in <code>data</code>.  Can be numeric
(by column number) or character (by column name).
The <code>atRiskY</code> column indicates if the individual was &ldquo;at-risk&rdquo;
of becoming infected during the time interval (start; stop].  This variable 
must be logical or in 0/1-coding.
Individuals with <code>atRiskY == 0</code> in the first time interval (normally 
the rows with <code>start == 0</code>) are taken as <em>initially infectious</em>.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_event.col">event.col</code></td>
<td>

<p>single index of the <code>event</code> column in <code>data</code>.  Can be numeric
(by column number) or character (by column name).
The <code>event</code> column indicates if the individual became <em>infected</em>
at the <code>stop</code> time of the interval.  This variable must be logical or
in 0/1-coding.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_revent.col">Revent.col</code></td>
<td>

<p>single index of the <code>Revent</code> column in <code>data</code>.  Can be numeric
(by column number) or character (by column name).
The <code>Revent</code> column indicates if the individual was <em>recovered</em> 
at the <code>stop</code> time of the interval.  This variable must be logical or
in 0/1-coding.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_coords.cols">coords.cols</code></td>
<td>

<p>index<em>es</em> of the <code>coords</code> column<em>s</em> in <code>data</code>. Can be
numeric (by column number), character (by column name), or <code>NULL</code>
(no coordinates, e.g., if <code>D</code> is a pre-specified distance matrix).
These columns contain the individuals' coordinates, which determine
the distance matrix for the distance-based components of the force
of infection (see argument <code>f</code>). By default, Euclidean distance
is used (see argument <code>D</code>).<br />
Note that the functions related to <code><a href="#topic+twinSIR">twinSIR</a></code> currently assume
<em>fixed positions</em> of the individuals during the whole epidemic.  Thus, an
individual has the same coordinates in every block.  For simplicity, the
coordinates are derived from the first time block only (normally the rows 
with <code>start == 0</code>).<br />
The <code><a href="#topic+animate.epidata">animate</a></code>-method requires coordinates.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_f">f</code></td>
<td>

<p>a <em>named</em> list of <em>vectorized</em> functions for a
distance-based force of infection.
The functions must interact elementwise on a (distance) matrix <code>D</code> so that
<code>f[[m]](D)</code> results in a matrix.  A simple example is
<code>function(u) {u &lt;= 1}</code>, which indicates if the Euclidean distance
between the individuals is smaller than or equal to 1.
The names of the functions determine the names of the epidemic variables
in the resulting data frame.  So, the names should not coincide with
names of other covariates.
The distance-based weights are computed as follows:
Let <code class="reqn">I(t)</code> denote the set of infectious
individuals just before time <code class="reqn">t</code>.
Then, for individual <code class="reqn">i</code> at time <code class="reqn">t</code>, the
<code class="reqn">m</code>'th covariate has the value
<code class="reqn">\sum_{j \in I(t)} f_m(d_{ij})</code>,
where <code class="reqn">d_{ij}</code> denotes entries of the distance matrix
(by default this is the Euclidean distance <code class="reqn">||s_i - s_j||</code>
between the individuals' coordinates, but see argument <code>D</code>).
</p>
</td></tr>
<tr><td><code id="epidata_+3A_w">w</code></td>
<td>

<p>a <em>named</em> list of <em>vectorized</em> functions for extra 
covariate-based weights <code class="reqn">w_{ij}</code> in the epidemic component.
Each function operates on a single time-constant covariate in
<code>data</code>, which is determined by the name of the first argument:
The two function arguments should be named <code>varname.i</code> and
<code>varname.j</code>, where <code>varname</code> is one of <code>names(data)</code>.
Similar to the components in <code>f</code>, <code>length(w)</code> epidemic
covariates will be generated in the resulting <code>"epidata"</code> named
according to <code>names(w)</code>.  So, the names should not coincide with
names of other covariates.  For individual <code class="reqn">i</code> at time
<code class="reqn">t</code>, the <code class="reqn">m</code>'th such covariate has the value
<code class="reqn">\sum_{j \in I(t)} w_m(z^{(m)}_i, z^{(m)}_j)</code>,
where <code class="reqn">z^{(m)}</code> denotes the variable in <code>data</code> associated
with <code>w[[m]]</code>.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_d">D</code></td>
<td>

<p>either a function to calculate the distances between the individuals
with locations taken from <code>coord.cols</code> (the default is
Euclidean distance via the function <code><a href="stats.html#topic+dist">dist</a></code>) and
the result converted to a matrix via <code><a href="base.html#topic+as.matrix">as.matrix</a></code>,
or a pre-computed distance matrix with <code>dimnames</code> containing
the individual ids (a classed <code>"<a href="Matrix.html#topic+Matrix-class">Matrix</a>"</code> is supported).
</p>
</td></tr>
<tr><td><code id="epidata_+3A_keep.cols">keep.cols</code></td>
<td>

<p>logical indicating if all columns in <code>data</code>
should be retained (and not only the obligatory <code>"epidata"</code>
columns), in particular any additional columns with 
time-constant individual-specific covariates.
Alternatively, <code>keep.cols</code> can be a numeric or character vector
indexing columns of <code>data</code> to keep.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_.latent">.latent</code></td>
<td>

<p>(internal) logical indicating whether to allow for latent periods
(EXPERIMENTAL). Otherwise (default), the function verifies that an
event (i.e., switching to the I state) only happens when the
respective individual is at risk (i.e., in the S state).
</p>
</td></tr>
<tr><td><code id="epidata_+3A_x">x</code>, <code id="epidata_+3A_object">object</code></td>
<td>

<p>an object of class <code>"epidata"</code>.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_...">...</code></td>
<td>

<p>arguments passed to <code><a href="base.html#topic+print.data.frame">print.data.frame</a></code>. Currently unused
in the <code>as.epidata</code>-methods.
</p>
</td></tr>
<tr><td><code id="epidata_+3A_i">i</code>, <code id="epidata_+3A_j">j</code>, <code id="epidata_+3A_drop">drop</code></td>
<td>

<p>arguments passed to <code><a href="base.html#topic++5B.data.frame">[.data.frame</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> method for objects of class <code>"epidata"</code> simply prints
the data frame with a small header containing the time range of the observed
epidemic and the number of infected individuals.  Usually, the data frames
are quite long, so the summary method <code><a href="#topic+summary.epidata">summary.epidata</a></code> might be
useful.  Also, indexing/subsetting <code>"epidata"</code> works exactly as for
<code><a href="base.html#topic++5B.data.frame">data.frame</a></code>s, but there is an own method, which
assures consistency of the resulting <code>"epidata"</code> or drops this class, if
necessary.
The <code>update</code>-method can be used to add or replace distance-based
(<code>f</code>) or covariate-based (<code>w</code>) epidemic variables in an
existing <code>"epidata"</code> object.
</p>
<p>SIS epidemics are implemented as SIRS epidemics where the length of the
removal period equals 0.  This means that an individual, which has an R-event
will be at risk immediately afterwards, i.e. in the following time block.
Therefore, data of SIS epidemics have to be provided in that form containing
&ldquo;pseudo-R-events&rdquo;.  
</p>


<h3>Value</h3>

<p>a <code>data.frame</code> with the columns <code>"BLOCK"</code>, <code>"id"</code>,
<code>"start"</code>, <code>"stop"</code>, <code>"atRiskY"</code>, <code>"event"</code>,
<code>"Revent"</code> and the coordinate columns (with the original names from
<code>data</code>), which are all obligatory.  These columns are followed by any 
remaining columns of the input <code>data</code>.  Last but not least, the newly
generated columns with epidemic variables corresponding to the functions
in the list <code>f</code> are appended, if <code>length(f)</code> &gt; 0.
</p>
<p>The <code>data.frame</code> is given the additional <em>attributes</em>
</p>
<table>
<tr><td><code>"eventTimes"</code></td>
<td>

<p>numeric vector of infection time points (sorted chronologically).
</p>
</td></tr>
<tr><td><code>"timeRange"</code></td>
<td>

<p>numeric vector of length 2: <code>c(min(start), max(stop))</code>.
</p>
</td></tr>
<tr><td><code>"coords.cols"</code></td>
<td>

<p>numeric vector containing the column indices of the coordinate columns in
the resulting data frame.
</p>
</td></tr>
<tr><td><code>"f"</code></td>
<td>

<p>this equals the argument <code>f</code>.
</p>
</td></tr>
<tr><td><code>"w"</code></td>
<td>

<p>this equals the argument <code>w</code>.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The column name <code>"BLOCK"</code> is a reserved name.  This column will be 
added automatically at conversion and the resulting data frame will be 
sorted by this column and by id.  Also the names <code>"id"</code>, <code>"start"</code>,
<code>"stop"</code>, <code>"atRiskY"</code>, <code>"event"</code> and <code>"Revent"</code> are
reserved for the respective columns only.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+hagelloch">hagelloch</a></code> data as an example.
</p>
<p>The <code><a href="#topic+plot.epidata">plot</a></code> and the
<code><a href="#topic+summary.epidata">summary</a></code> method for class <code>"epidata"</code>.
Furthermore, the function <code><a href="#topic+animate.epidata">animate.epidata</a></code> for the animation of
epidemics.
</p>
<p>Function <code><a href="#topic+twinSIR">twinSIR</a></code> for fitting spatio-temporal epidemic intensity
models to epidemic data.
</p>
<p>Function <code><a href="#topic+simEpidata">simEpidata</a></code> for the simulation of epidemic data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")   # see help("hagelloch") for a description
head(hagelloch.df)

## convert the original data frame to an "epidata" event history
myEpi &lt;- as.epidata(hagelloch.df, t0 = 0,
                    tI.col = "tI", tR.col = "tR", id.col = "PN",
                    coords.cols = c("x.loc", "y.loc"),
                    keep.cols = c("SEX", "AGE", "CL"))


str(myEpi)
head(as.data.frame(myEpi))  # "epidata" has event history format
summary(myEpi)              # see 'summary.epidata'
plot(myEpi)                 # see 'plot.epidata' and also 'animate.epidata'


## add distance- and covariate-based weights for the force of infection
## in a twinSIR model, see vignette("twinSIR") for a description
myEpi &lt;- update(myEpi,
    f = list(
        household    = function(u) u == 0,
        nothousehold = function(u) u &gt; 0
    ),
    w = list(
        c1 = function (CL.i, CL.j) CL.i == "1st class" &amp; CL.j == CL.i,
        c2 = function (CL.i, CL.j) CL.i == "2nd class" &amp; CL.j == CL.i
    )
)
## this is now identical to the prepared hagelloch "epidata"
stopifnot(all.equal(myEpi, hagelloch))



</code></pre>

<hr>
<h2 id='epidata_animate'>
Spatio-Temporal Animation of an Epidemic
</h2><span id='topic+animate.epidata'></span><span id='topic+animate.summary.epidata'></span>

<h3>Description</h3>

<p>Function for the animation of epidemic data, i.e. objects inheriting from 
class <code>"epidata"</code>.  This only works with 1- or 2-dimensional coordinates 
and is not useful if some individuals share the same coordinates 
(overlapping).  There are two types of animation, see argument 
<code>time.spacing</code>.  Besides the direct plotting in the <span class="rlang"><b>R</b></span> session, it is 
also possible to generate a sequence of graphics files to create animations 
outside <span class="rlang"><b>R</b></span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.epidata'
animate(object, main = "An animation of the epidemic",
        pch = 19, col = c(3, 2, gray(0.6)), time.spacing = NULL,
        sleep = quote(5/.nTimes), legend.opts = list(), timer.opts = list(),
        end = NULL, generate.snapshots = NULL, ...)

## S3 method for class 'epidata'
animate(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidata_animate_+3A_object">object</code></td>
<td>

<p>an object inheriting from class <code>"epidata"</code> or
<code>"summary.epidata"</code>.  In the former case, its summary is calculated
and the function continues as in the latter case, passing all <code>...</code>
arguments to the <code>summary.epidata</code> method.
</p>
</td></tr>
<tr><td><code id="epidata_animate_+3A_main">main</code></td>
<td>

<p>a main title for the plot, see also <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="epidata_animate_+3A_pch">pch</code>, <code id="epidata_animate_+3A_col">col</code></td>
<td>

<p>vectors of length 3 specifying the point symbols and colors for
susceptible, infectious and removed individuals (in this order).
The vectors are recycled if necessary.
By default, susceptible individuals are marked as filled green circles,
infectious individuals as filled red circles and removed individuals as
filled gray circles.  Note that the symbols are iteratively drawn
(overlayed) in the same plotting region as time proceeds.
For information about the possible values of <code>pch</code> and <code>col</code>, see
the help pages of <code><a href="graphics.html#topic+points">points</a></code> and <code><a href="graphics.html#topic+par">par</a></code>, respectively.
</p>
</td></tr>
<tr><td><code id="epidata_animate_+3A_time.spacing">time.spacing</code></td>
<td>

<p>time interval for the animation steps.  If <code>NULL</code> (the default), the
events are plotted one by one with pauses of <code>sleep</code> seconds.  Thus, 
it is just the <em>ordering</em> of the events, which is shown.  To plot
the appearance of events proportionally to the exact time line,
<code>time.spacing</code> can be set to a numeric value indicating the period of
time between consecutive plots.  Then, for each time point in
<code>seq(0, end, by = time.spacing)</code> the current state of the epidemic can
be seen and an additional timer indicates the current time
(see <code>timer.opts</code> below).  The argument <code>sleep</code> will be the
artificial pause in seconds between two of those time points.
</p>
</td></tr>
<tr><td><code id="epidata_animate_+3A_sleep">sleep</code></td>
<td>

<p>time in seconds to <code><a href="base.html#topic+Sys.sleep">Sys.sleep</a></code> before the next plotting
event.  By default, each artificial pause is of length <code>5/.nTimes</code>
seconds, where <code>.nTimes</code> is the number of events (infections and
removals) of the epidemic, which is evaluated in the function body.
Thus, for <code>time.spacing = NULL</code> the animation has a duration of
approximately 5 seconds. In the other case, <code>sleep</code> is the duration of
the artificial pause between two time points.
Note that <code>sleep</code> is ignored on non-interactive devices
(see <code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>)
</p>
</td></tr>
<tr><td><code id="epidata_animate_+3A_legend.opts">legend.opts</code></td>
<td>

<p>either a list of arguments passed to the <code><a href="graphics.html#topic+legend">legend</a></code> function or
<code>NULL</code> (or <code>NA</code>), in which case no legend will be plotted.  All 
necessary arguments have sensible defaults and need not be specified, i.e.
</p>

<dl>
<dt><code>x</code>:</dt><dd><p><code>"topright"</code></p>
</dd>
<dt><code>legend</code>:</dt><dd><p><code>c("susceptible", "infectious", "removed")</code></p>
</dd>
<dt><code>pch</code>:</dt><dd><p>same as argument <code>pch</code> of the main function</p>
</dd>
<dt><code>col</code>:</dt><dd><p>same as argument <code>col</code> of the main function</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="epidata_animate_+3A_timer.opts">timer.opts</code></td>
<td>

<p>either a list of arguments passed to the <code><a href="graphics.html#topic+legend">legend</a></code> function or
<code>NULL</code> (or <code>NA</code>), in which case no timer will be plotted.  All 
necessary arguments have sensible defaults and need not be specified, i.e.
</p>

<dl>
<dt><code>x</code>:</dt><dd><p><code>"bottomright"</code></p>
</dd>
<dt><code>title</code>:</dt><dd><p><code>"time"</code></p>
</dd>
<dt><code>box.lty</code>:</dt><dd><p><code>0</code></p>
</dd>
<dt><code>adj</code>:</dt><dd><p><code>c(0.5,0.5)</code></p>
</dd>
<dt><code>inset</code>:</dt><dd><p><code>0.01</code></p>
</dd>
<dt><code>bg</code>:</dt><dd><p><code>"white"</code></p>
</dd>
</dl>

<p>Note that the argument <code>legend</code>, which is the current time of the
animation, can not be modified.
</p>
</td></tr>
<tr><td><code id="epidata_animate_+3A_end">end</code></td>
<td>

<p>ending time of the animation in case of <code>time.spacing</code> not being
<code>NULL</code>.  By default (<code>NULL</code>), time stops after the last event.
</p>
</td></tr>
<tr><td><code id="epidata_animate_+3A_generate.snapshots">generate.snapshots</code></td>
<td>

<p>By default (<code>NULL</code>), the animation is not saved to image files
but only shown on the on-screen device. In order to print to files,
<code>time.spacing</code> must not be <code>NULL</code>, a screen device must be
available, and there are two options:<br />
If the framework of the <span class="pkg">animation</span> package
should be used, i.e. the <code>animate</code>-call is passed as the
<code>expr</code> argument to one of the <code>save*</code> functions of the
<span class="pkg">animation</span> package, then set
<code>generate.snapshots = img.name</code>, where <code>img.name</code> is the
base name for the generated images (the same as passed to the
<code>save*</code> function). The path and format (type, width, height)
for the generated images is derived from
<code><a href="animation.html#topic+ani.options">ani.options</a></code>. See the last example below.<br />
Alternatively, <code>generate.snapshots</code> may be a list of arguments
passed to the function <code><a href="grDevices.html#topic+dev.print">dev.print</a></code>, which then is
executed at each time point of the grid defined by
<code>time.spacing</code>.  Essentially, this is used for 
saving the produced snapshots to files, e.g.
</p>
<p><code>generate.snapshots = 
    list(device=pdf, file=quote(paste("epidemic_",sprintf(form,tp),".pdf",
    sep="")))</code>
</p>
<p>will store the animation steps in pdf-files in the current
working directory, where the file names each end with the time point
represented by the corresponding plot.  Because the variables <code>tp</code>
and <code>form</code> should only be evaluated inside the function the
<code>file</code> argument is <code>quote</code>d. Alternatively, the file name
could also make use of the internal plot index <code>i</code>, e.g., use
<code>file=quote(paste("epidemic",i,".pdf",sep=""))</code>.
</p>
</td></tr>
<tr><td><code id="epidata_animate_+3A_...">...</code></td>
<td>

<p>further graphical parameters passed to the basic call of <code>plot</code>, e.g.
<code>las</code>, <code>cex.axis</code> (etc.) and <code>mgp</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.epidata">summary.epidata</a></code> for the data, on which the plot is based.
<code><a href="#topic+plot.epidata">plot.epidata</a></code> for plotting the evolution of an epidemic by
the numbers of susceptible, infectious and removed individuals.
</p>
<p>The contributed <span class="rlang"><b>R</b></span> package <span class="pkg">animation</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
(s &lt;- summary(hagelloch))

# plot the ordering of the events only
animate(s)   # or: animate(hagelloch)

# with timer (animate only up to t=10)
animate(s, time.spacing=0.1, end=10, sleep=0.01,
        legend.opts=list(x="topleft"))

# Such an animation can be saved in various ways using tools of
# the animation package, e.g., saveHTML()
if (interactive() &amp;&amp; require("animation")) {
  oldwd &lt;- setwd(tempdir())  # to not clutter up the current working dir
  saveHTML({
    par(bg="white")  # default "transparent" is grey in some browsers
    animate(s, time.spacing=1, sleep=0, legend.opts=list(x="topleft"),
            generate.snapshots="epiani")
  }, use.dev=FALSE, img.name="epiani", ani.width=600, interval=0.5)
  setwd(oldwd)
}
</code></pre>

<hr>
<h2 id='epidata_intersperse'>
Impute Blocks for Extra Stops in <code>"epidata"</code> Objects
</h2><span id='topic+intersperse'></span>

<h3>Description</h3>

<p>This function modifies an object inheriting from class <code>"epidata"</code> such 
that it features the specified stop time points.  For this purpose, the time 
interval in the event history into which the new stop falls will be split 
up into two parts, one block for the time period until the new stop &ndash; where 
no infection or removal occurs &ndash; and the other block for the time period 
from the new stop to the end of the original interval.<br />
Main application is to enable the use of <code>knots</code> in <code>twinSIR</code>, which
are not existing stop time points in the <code>"epidata"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intersperse(epidata, stoptimes, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidata_intersperse_+3A_epidata">epidata</code></td>
<td>

<p>an object inheriting from class <code>"epidata"</code>.
</p>
</td></tr>
<tr><td><code id="epidata_intersperse_+3A_stoptimes">stoptimes</code></td>
<td>

<p>a numeric vector of time points inside the observation period of the
<code>epidata</code>.
</p>
</td></tr>
<tr><td><code id="epidata_intersperse_+3A_verbose">verbose</code></td>
<td>

<p>logical indicating if a <code><a href="utils.html#topic+txtProgressBar">txtProgressBar</a></code> should be shown
while inserting blocks for extra <code>stoptimes</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of the same class as <code>epidata</code> with additional time blocks
for any new <code>stoptimes</code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.epidata.epidataCS">as.epidata.epidataCS</a></code> where this function is used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
subset(hagelloch, start &lt; 25 &amp; stop &gt; 25 &amp; id %in% 9:13, select = 1:7)
# there is no "stop" time at 25, but we can add this extra stop
nrow(hagelloch)
moreStopsEpi &lt;- intersperse(hagelloch, stoptimes = 25)
nrow(moreStopsEpi)
subset(moreStopsEpi, (stop == 25 | start == 25) &amp; id %in% 9:13, select = 1:7)
</code></pre>

<hr>
<h2 id='epidata_plot'>
Plotting the Evolution of an Epidemic
</h2><span id='topic+plot.epidata'></span><span id='topic+plot.summary.epidata'></span><span id='topic+stateplot'></span>

<h3>Description</h3>

<p>Functions for plotting the evolution of epidemics. The <code><a href="graphics.html#topic+plot">plot</a></code>
methods for <code><a href="base.html#topic+class">class</a></code>es <code>"<a href="#topic+epidata">epidata</a>"</code> and
<code>"summary.epidata"</code> plots the numbers of susceptible, infectious and
recovered (= removed) individuals by step functions along the time axis.  The
function <code>stateplot</code> shows individual state changes along the time axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.epidata'
plot(x,
     lty = c(2, 1, 3), lwd = 2,
     col = c("#1B9E77", "#D95F02", "#7570B3"), col.hor = col, col.vert = col,
     xlab = "Time", ylab = "Number of individuals",
     xlim = NULL, ylim = NULL, legend.opts = list(), do.axis4 = NULL,
     panel.first = grid(), rug.opts = list(),
     which.rug = c("infections", "removals", "susceptibility", "all"), ...)
## S3 method for class 'epidata'
plot(x, ...)

stateplot(x, id, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidata_plot_+3A_x">x</code></td>
<td>

<p>an object inheriting from class <code>"epidata"</code> or
<code>"summary.epidata"</code>.  In the former case, its summary is calculated
and the function continues as in the latter case.  The <code>plot</code> method
for class <code>"epidata"</code> is a simple wrapper for
<code>plot.summary.epidata</code> implemented as <code>plot(summary(x, ...))</code>.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_lty">lty</code>, <code id="epidata_plot_+3A_lwd">lwd</code></td>
<td>

<p>vectors of length 3 containing the line types and widths, respectively, for
the numbers of susceptible, infectious and removed individuals (in this 
order).  By default, all lines have width 1 and the line types are dashed
(susceptible), solid (infectious) and dotted (removed), respectively.  To 
omit the drawing of a specific line, just set the corresponding entry in 
<code>lty</code> to 0.  The vectors are recycled if necessary.  For information 
about the different <code>lty</code> and <code>lwd</code> codes, see the help pages 
of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_col">col</code>, <code id="epidata_plot_+3A_col.hor">col.hor</code>, <code id="epidata_plot_+3A_col.vert">col.vert</code></td>
<td>

<p>vectors of length 3 containing the line colors for the numbers of
susceptible, infectious and removed individuals (in this order). 
<code>col.hor</code> defines the color for the horizontal parts of the step
function, whilst <code>col.vert</code> defines the color for its vertical parts.
The argument <code>col</code> is just short for <code>col.hor = col</code> and
<code>col.vert = col</code>.  The default <code>col</code> vector corresponds to
<code>brewer.pal("Dark2",n=3)</code> from the <a href="https://CRAN.R-project.org/package=RColorBrewer"><span class="pkg">RColorBrewer</span></a> package.
The vectors are recycled if necessary.  For information about the possible
values of <code>col</code>, see the help pages of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_xlab">xlab</code>, <code id="epidata_plot_+3A_ylab">ylab</code></td>
<td>

<p>axis labels, default to &quot;Time&quot; and &quot;Number of individuals&quot;, respectively.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_xlim">xlim</code>, <code id="epidata_plot_+3A_ylim">ylim</code></td>
<td>

<p>the x and y limits of the plot in the form <code>c(xmin, xmax)</code> and
<code>c(ymin, ymax)</code>, respectively.  By default, these are chosen adequately
to fit the time range of the epidemic and the number of individuals.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_legend.opts">legend.opts</code></td>
<td>

<p>if this is a list (of arguments for the <code><a href="graphics.html#topic+legend">legend</a></code> function),
a legend will be plotted.  The defaults are as follows:
</p>

<dl>
<dt><code>x</code>:</dt><dd><p><code>"topright"</code></p>
</dd>
<dt><code>inset</code>:</dt><dd><p><code>c(0,0.02)</code></p>
</dd>
<dt><code>legend</code>:</dt><dd><p><code>c("susceptible", "infectious", "removed")</code></p>
</dd>
<dt><code>lty</code>,<code>lwd</code>,<code>col</code>:</dt><dd><p>same as the arguments
<code>lty</code>, <code>lwd</code>, and <code>col.hor</code> of the main function</p>
</dd>
<dt><code>bty</code>:</dt><dd><p><code>"n"</code></p>
</dd>
</dl>

</td></tr>
<tr><td><code id="epidata_plot_+3A_do.axis4">do.axis4</code></td>
<td>

<p>logical indicating if the final numbers of susceptible and removed
individuals should be indicated on the right axis.  The default <code>NULL</code>
means <code>TRUE</code>, if <code>x</code> represents a SIR epidemic and <code>FALSE</code>
otherwise, i.e. if the epidemic is SI, SIS or SIRS.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_panel.first">panel.first</code></td>
<td>

<p>an expression to be evaluated after the plot axes are set up but before
any plotting takes place.  By default, a standard grid is drawn.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_rug.opts">rug.opts</code></td>
<td>

<p>either a list of arguments passed to the function <code><a href="graphics.html#topic+rug">rug</a></code> or
<code>NULL</code> (or <code>NA</code>), in which case no <code>rug</code> will be plotted.
By default, the argument <code>ticksize</code> is set to 0.02, <code>col</code>
is set to the color according to <code>which.rug</code> (black if this is
<code>"all"</code>), and <code>quiet</code> is set to <code>TRUE</code>.
Note that the argument <code>x</code>, which contains the
locations for the <code>rug</code> is fixed internally and can not be modified.
The argument <code>which.rug</code> (see below) determines the locations to mark.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_which.rug">which.rug</code></td>
<td>

<p>By default, tick marks are drawn at the time points of infections.  
Alternatively, one can choose to mark only <code>"removals"</code>,
<code>"susceptibilities"</code> (i.e. state change from R to S) or
<code>"all"</code> events.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_id">id</code></td>
<td>

<p>single character string or factor of length 1 specifying the individual for
which the <code>stateplot</code> should be established.
</p>
</td></tr>
<tr><td><code id="epidata_plot_+3A_...">...</code></td>
<td>

<p>For <code>plot.summary.epidata</code>: further graphical parameters passed to 
<code>plot</code>, <code>lines</code> and <code>axis</code>, e.g. <code>main</code>, <code>las</code>, 
<code>cex.axis</code> (etc.) and <code>mgp</code>.<br />
For <code>plot.epidata</code>: arguments passed to <code>plot.summary.epidata</code>.<br />
For <code>stateplot</code>: arguments passed to <code><a href="stats.html#topic+plot.stepfun">plot.stepfun</a></code> or
<code><a href="graphics.html#topic+plot.function">plot.function</a></code> (if <code>id</code> had no events during the
observation period).  By default, <code>xlab="time"</code>, <code>ylab="state"</code>,
<code>xlim=attr(x,"timeRange")</code>, <code>xaxs="i"</code> and <code>do.points=FALSE</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plot.summary.epidata</code> (and <code>plot.epidata</code>) invisibly returns the
matrix used for plotting, which contains the evolution of the three
counters.<br />
<code>stateplot</code> invisibly returns the function, which was plotted,
typically of class <code>"stepfun"</code>, but maybe of class <code>"function"</code>,
if no events have been observed for the individual in question (then the
function always returns the initial state).  The vertical axis of
<code>stateplot</code> can range from 1 to 3, where 1 corresponds to
<em>S</em>usceptible, 2 to <em>I</em>nfectious and 3 to <em>R</em>emoved.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.epidata">summary.epidata</a></code> for the data, on which the plots are based.
<code><a href="#topic+animate.epidata">animate.epidata</a></code> for the animation of epidemics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
(s &lt;- summary(hagelloch))

# rudimentary stateplot
stateplot(s, id = "187")

# evolution of the epidemic
plot(s)
</code></pre>

<hr>
<h2 id='epidata_summary'>
Summarizing an Epidemic
</h2><span id='topic+summary.epidata'></span><span id='topic+print.summary.epidata'></span>

<h3>Description</h3>

<p>The <code><a href="base.html#topic+summary">summary</a></code> method for <code><a href="base.html#topic+class">class</a></code>
<code>"<a href="#topic+epidata">epidata</a>"</code> gives an overview of the epidemic.  Its
<code><a href="base.html#topic+print">print</a></code> method shows the type of the epidemic, the time range, the
total number of individuals, the initially and never infected individuals and
the size of the epidemic.  An excerpt of the returned <code>counters</code> data
frame is also printed (see the Value section below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'epidata'
summary(object, ...)

## S3 method for class 'summary.epidata'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidata_summary_+3A_object">object</code></td>
<td>
<p>an object inheriting from class <code>"epidata"</code>.</p>
</td></tr>
<tr><td><code id="epidata_summary_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"summary.epidata"</code>, i.e. an
object returned by the function <code>summary.epidata</code>.</p>
</td></tr>
<tr><td><code id="epidata_summary_+3A_...">...</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>type</code></td>
<td>

<p>character string.  Compartmental type of the epidemic, i.e. one of &quot;SIR&quot;,
&quot;SI&quot;, &quot;SIS&quot; or &quot;SIRS&quot;.
</p>
</td></tr>
<tr><td><code>size</code></td>
<td>

<p>integer.  Size of the epidemic, i.e. the number of initially susceptible
individuals, which became infected during the course of the epidemic.
</p>
</td></tr>
<tr><td><code>initiallyInfected</code></td>
<td>

<p>factor (with the same levels as the <code>id</code> column in the <code>"epidata"</code>
object).  Set of initially infected individuals.
</p>
</td></tr>
<tr><td><code>neverInfected</code></td>
<td>

<p>factor (with the same levels as the <code>id</code> column in the <code>"epidata"</code>
object).  Set of never infected individuals, i.e. individuals, which were 
neither initially infected nor infected during the course of the epidemic.
</p>
</td></tr>
<tr><td><code>coordinates</code></td>
<td>

<p>numeric matrix of individual coordinates with as many rows as there are
individuals and one column for each spatial dimension.  The row names of
the matrix are the <code>id</code>s of the individuals.
</p>
</td></tr>
<tr><td><code>byID</code></td>
<td>

<p>data frame with time points of infection and optionally removal and
re-susceptibility (depending on the <code>type</code> of the epidemic) ordered
by <code>id</code>.  If an event was not observed, the corresponding
entry is missing.
</p>
</td></tr>
<tr><td><code>counters</code></td>
<td>

<p>data frame containing all events (S, I and R) ordered by time.  The columns
are <code>time</code>, <code>type</code> (of event), corresponding <code>id</code> and the
three counters <code>nSusceptible</code>, <code>nInfectious</code> and <code>nRemoved</code>.
The first row additionally shows the counters at the beginning of the
epidemic, where the <code>type</code> and <code>id</code> column contain missing values.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.epidata">as.epidata</a></code> for generating objects of class <code>"epidata"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
s &lt;- summary(hagelloch)
s          # uses the print method for summary.epidata
names(s)   # components of the list 's'

# positions of the individuals
plot(s$coordinates)

# events by id
head(s$byID)
</code></pre>

<hr>
<h2 id='epidataCS'>
Continuous Space-Time Marked Point Patterns with Grid-Based Covariates
</h2><span id='topic+epidataCS'></span><span id='topic+as.epidataCS'></span><span id='topic+print.epidataCS'></span><span id='topic+nobs.epidataCS'></span><span id='topic+head.epidataCS'></span><span id='topic+tail.epidataCS'></span><span id='topic++5B.epidataCS'></span><span id='topic+subset.epidataCS'></span><span id='topic+marks.epidataCS'></span><span id='topic+summary.epidataCS'></span><span id='topic+print.summary.epidataCS'></span><span id='topic+as.stepfun.epidataCS'></span><span id='topic+getSourceDists'></span><span id='topic+coerce+2CepidataCS+2CSpatialPointsDataFrame-method'></span>

<h3>Description</h3>

<p>Data structure for <strong>c</strong>ontinuous <strong>s</strong>patio-temporal event
data, e.g. individual case reports of an infectious disease.
Apart from the actual <code>events</code>, the class simultaneously
holds a spatio-temporal grid of endemic covariates (similar to
disease mapping) and a representation of the observation region.
</p>
<p>The <code>"epidataCS"</code> class is the basis for fitting 
spatio-temporal endemic-epidemic intensity models with the function
<code><a href="#topic+twinstim">twinstim</a></code> (Meyer et al., 2012).
The implementation is described in Meyer et al. (2017, Section 3),
see <code>vignette("twinstim")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.epidataCS(events, stgrid, W, qmatrix = diag(nTypes),
             nCircle2Poly = 32L, T = NULL,
             clipper = "polyclip", verbose = interactive())

## S3 method for class 'epidataCS'
print(x, n = 6L, digits = getOption("digits"), ...)

## S3 method for class 'epidataCS'
nobs(object, ...)
## S3 method for class 'epidataCS'
head(x, n = 6L, ...)
## S3 method for class 'epidataCS'
tail(x, n = 6L, ...)
## S3 method for class 'epidataCS'
x[i, j, ..., drop = TRUE]
## S3 method for class 'epidataCS'
subset(x, subset, select, drop = TRUE, ...)

## S3 method for class 'epidataCS'
marks(x, coords = TRUE, ...)

## S3 method for class 'epidataCS'
summary(object, ...)
## S3 method for class 'summary.epidataCS'
print(x, ...)

## S3 method for class 'epidataCS'
as.stepfun(x, ...)

getSourceDists(object, dimension = c("space", "time"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidataCS_+3A_events">events</code></td>
<td>

<p>a <code>"<a href="sp.html#topic+SpatialPointsDataFrame-class">SpatialPointsDataFrame</a>"</code> of cases with the
following obligatory columns (in the <code>events@data</code>
<code>data.frame</code>): 
</p>

<dl>
<dt>time</dt><dd><p>time point of event. Will be converted to a numeric
variable by <code>as.numeric</code>. There should be no concurrent
events (but see <code><a href="#topic+untie">untie</a></code> for an ex post adjustment)
and there cannot be events beyond <code>stgrid</code>
(i.e., <code>time&lt;=T</code> is required). Events at or before time
<code class="reqn">t_0</code> = <code>min(stgrid$start)</code> are allowed and form the
prehistory of the process.</p>
</dd>
<dt>tile</dt><dd><p>the spatial region (tile) where the event is located.
This links to the tiles of <code>stgrid</code>.</p>
</dd>
<dt>type</dt><dd><p>optional type of event in a marked <code>twinstim</code>
model. Will be converted to a factor variable dropping unused
levels. If missing, all events will be attribute the single type
<code>"1"</code>.</p>
</dd>
<dt>eps.t</dt><dd><p>maximum <em>temporal</em> influence radius (e.g. length of
infectious period, time to culling, etc.); must be positive and
may be <code>Inf</code>.</p>
</dd> 
<dt>eps.s</dt><dd><p>maximum <em>spatial</em> influence radius (e.g. 100 [km]);
must be positive and may be <code>Inf</code>. A compact influence
region mainly has computational advantages, but might also be
plausible for specific applications.</p>
</dd>
</dl>

<p>The <code>data.frame</code> may contain columns with further marks of
the events, e.g. sex, age of infected individuals, which may
be used as epidemic covariates influencing infectiousness.
Note that some auxiliary columns will be added at conversion
whose names are reserved: <code>".obsInfLength"</code>,
<code>".bdist"</code>, <code>".influenceRegion"</code>, and <code>".sources"</code>,
as well as <code>"start"</code>, <code>"BLOCK"</code>, and all endemic
covariates' names from <code>stgrid</code>.
</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_stgrid">stgrid</code></td>
<td>

<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> describing endemic covariates on a full
spatio-temporal region x interval grid (e.g., district x week),
which is a decomposition of the observation region <code>W</code> and
period <code class="reqn">t_0,T</code>. This means that for every combination of spatial
region and time interval there must be exactly one row in this
<code>data.frame</code>, that the union of the spatial tiles equals
<code>W</code>, the union of the time intervals equals <code class="reqn">t_0,T</code>, and
that regions (and intervals) are non-overlapping.
There are the following obligatory columns: 
</p>

<dl>
<dt>tile</dt><dd><p>ID of the spatial region (e.g., district ID). It will
be converted to a factor variable (dropping unused levels if it
already was one).</p>
</dd>
<dt>start, stop</dt><dd><p>columns describing the consecutive temporal
intervals (converted to numeric variables by <code>as.numeric</code>).
The <code>start</code> time of an interval must be equal to the
<code>stop</code> time of the previous interval. The <code>stop</code> column may
be missing, in which case it will be auto-generated from the set
of <code>start</code> values and <code>T</code>.</p>
</dd>
<dt>area</dt><dd><p>area of the spatial region (<code>tile</code>).
Be aware that the unit of this area (e.g., square km) must be consistent
with the units of <code>W</code> and <code>events</code> (as specified in
their <code><a href="sp.html#topic+proj4string">proj4string</a></code>s).</p>
</dd>
</dl>

<p>The remaining columns are endemic covariates.
Note that the column name <code>"BLOCK"</code> is reserved
(a column which will be added automatically for indexing the time
intervals of <code>stgrid</code>).
</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_w">W</code></td>
<td>

<p>an object of class <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>
representing the observation region.
It must have the same <code>proj4string</code> as <code>events</code>
and all events must be within <code>W</code>.
Prior simplification of <code>W</code> may considerably reduce the
computational burden of likelihood evaluations in
<code><a href="#topic+twinstim">twinstim</a></code> models with non-trivial spatial
interaction functions (see the &ldquo;Note&rdquo; section below).
</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_qmatrix">qmatrix</code></td>
<td>

<p>a square indicator matrix (0/1 or <code>FALSE</code>/<code>TRUE</code>) for possible
transmission between the event types. The matrix will be internally
converted to <code>logical</code>. Defaults to an independent spread of the event
types, i.e. the identity matrix. 
</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_ncircle2poly">nCircle2Poly</code></td>
<td>

<p>accuracy (number of edges) of the polygonal approximation of a circle,
see <code><a href="#topic+discpoly">discpoly</a></code>.
</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_t">T</code></td>
<td>

<p>end of observation period (i.e. last <code>stop</code> time of
<code>stgrid</code>). Must be specified if the start but not the stop
times are supplied in <code>stgrid</code> (=&gt; auto-generation of
<code>stop</code> times).
</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_clipper">clipper</code></td>
<td>
<p>polygon clipping engine to use for calculating the
<code>.influenceRegion</code>s of events (see the Value section below).
Default is the <a href="https://CRAN.R-project.org/package=polyclip"><span class="pkg">polyclip</span></a> package (called via
<code>intersect.owin</code> from package <a href="https://CRAN.R-project.org/package=spatstat.geom"><span class="pkg">spatstat.geom</span></a>).
In <span class="pkg">surveillance</span> &lt;= 1.6-0, package <span class="pkg">gpclib</span> was used;
this is no longer supported, neither is <span class="pkg">rgeos</span>.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if status messages should be printed
during input checking and <code>"epidataCS"</code> generation. The default
is to do so in interactive <span class="rlang"><b>R</b></span> sessions.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_x">x</code></td>
<td>
<p>an object of class <code>"epidataCS"</code> or
<code>"summary.epidataCS"</code>, respectively.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_n">n</code></td>
<td>
<p>a single integer. If positive, the first (<code>head</code>, <code>print</code>)
/ last (<code>tail</code>) <code>n</code> events are extracted. If negative,
all but the <code>n</code> first/last events are extracted.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_digits">digits</code></td>
<td>
<p>minimum number of significant digits to be printed in
values.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_i">i</code>, <code id="epidataCS_+3A_j">j</code>, <code id="epidataCS_+3A_drop">drop</code></td>
<td>

<p>arguments passed to the
<code><a href="sp.html#topic++5B+2CSpatialPointsDataFrame-method">[-method</a></code> for
<code>SpatialPointDataFrame</code>s for subsetting the <code>events</code> while
retaining <code>stgrid</code> and <code>W</code>.<br />
If <code>drop=TRUE</code> (the default), event types that completely
disappear due to <code>i</code>-subsetting will be dropped, which reduces
<code>qmatrix</code> and the factor levels of the <code>type</code> column.<br />
By the <code>j</code> index, epidemic covariates can be removed from
<code>events</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_...">...</code></td>
<td>
<p>unused (arguments of the generics) with a few exceptions:
The <code>print</code> method for <code>"epidataCS"</code> passes
<code>...</code> to the <code><a href="base.html#topic+print.data.frame">print.data.frame</a></code> method, and the
<code>print</code> method for <code>"summary.epidataCS"</code> passes additional
arguments to <code><a href="base.html#topic+print.table">print.table</a></code>.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_subset">subset</code>, <code id="epidataCS_+3A_select">select</code></td>
<td>
<p>arguments used to subset the <code>events</code> from
an <code>"epidataCS"</code> object like in <code><a href="base.html#topic+subset.data.frame">subset.data.frame</a></code>.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_coords">coords</code></td>
<td>
<p>logical indicating if the data frame of event marks
returned by <code>marks(x)</code> should have the event
coordinates appended as last columns. This defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_object">object</code></td>
<td>
<p>an object of class <code>"epidataCS"</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_+3A_dimension">dimension</code></td>
<td>
<p>the distances of all events to their potential source
events can be computed in either the <code>"space"</code> or <code>"time"</code>
dimension.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>as.epidataCS</code> is used to generate objects of class
<code>"epidataCS"</code>, which is the data structure required for
<code><a href="#topic+twinstim">twinstim</a></code> models.
</p>
<p>The <code>[</code>-method for class <code>"epidataCS"</code>
ensures that the subsetted object will be valid, for instance, it
updates the auxiliary list of potential transmission paths stored
in the object. The <code>[</code>-method is used in
<code>subset.epidataCS</code>, which is implemented similar to
<code><a href="base.html#topic+subset.data.frame">subset.data.frame</a></code>.
</p>
<p>The <code>print</code> method for <code>"epidataCS"</code> prints some metadata
of the epidemic, e.g., the observation period, the dimensions of the
spatio-temporal grid, the types of events, and the total number of
events. By default, it also prints the first <code>n = 6</code> rows of the
<code>events</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"epidataCS"</code> is a list containing the
following components: 
</p>
<table>
<tr><td><code>events</code></td>
<td>
<p>a <code>"<a href="sp.html#topic+SpatialPointsDataFrame-class">SpatialPointsDataFrame</a>"</code> (see the
description of the argument). 
The input <code>events</code> are checked for requirements and sorted
chronologically. The columns are in the following
order: obligatory event columns, event marks, the columns <code>BLOCK</code>,
<code>start</code> and endemic covariates copied from <code>stgrid</code>,
and finally, hidden auxiliary columns. 
The added auxiliary columns are:
</p>

<dl>
<dt><code>.obsInfLength</code></dt><dd><p>observed length of the infectious period
(possibly truncated at <code>T</code>), i.e., <code>pmin(T-time, eps.t)</code>.</p>
</dd>
<dt><code>.sources</code></dt><dd><p>a list of numeric vectors of potential sources of
infection (wrt the interaction ranges eps.s and eps.t) for each
event. Row numbers are used as index.</p>
</dd>
<dt><code>.bdist</code></dt><dd><p>minimal distance of the event locations to the
polygonal boundary <code>W</code>.</p>
</dd>
<dt><code>.influenceRegion</code></dt><dd><p>a list of influence regions represented by
objects of the <span class="pkg">spatstat.geom</span> class <code>"owin"</code>. For each
event, this is the intersection of <code>W</code> with a (polygonal)
circle of radius <code>eps.s</code> centered at the event's location,
shifted such that the event location becomes the origin.
The list has <code>nCircle2Poly</code> set as an attribute.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>stgrid</code></td>
<td>
<p>a <code>data.frame</code> (see description of the argument).
The spatio-temporal grid of endemic covariates is sorted by time
interval (indexed by the added variable <code>BLOCK</code>) and region
(<code>tile</code>). It is a full <code>BLOCK</code> x <code>tile</code> grid.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>a <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code> object representing
the observation region.</p>
</td></tr>
<tr><td><code>qmatrix</code></td>
<td>
<p>see the above description of the argument. The
<code><a href="base.html#topic+storage.mode">storage.mode</a></code> of the indicator matrix is set to logical
and the <code>dimnames</code> are set to the levels of the event types.</p>
</td></tr>
</table>
<p>The <code>nobs</code>-method returns the number of events.
</p>
<p>The <code>head</code> and <code>tail</code> methods subset the epidemic data using
the extraction method (<code>[</code>), i.e. they return an object of class
<code>"epidataCS"</code>, which only contains (all but) the first/last
<code>n</code> events.
</p>
<p>For the <code>"epidataCS"</code> class, the method of the generic function
<code><a href="spatstat.geom.html#topic+marks">marks</a></code> defined by the <span class="pkg">spatstat.geom</span> package
returns a <code>data.frame</code> of the event marks (actually also
including time and location of the events), disregarding endemic
covariates and the auxiliary columns from the <code>events</code> component
of the <code>"epidataCS"</code> object.
</p>
<p>The <code>summary</code> method (which has again a <code>print</code> method)
returns a list of metadata, event data, the tables of tiles and types,
a step function of the number of infectious individuals over time
(<code>$counter</code>), i.e., the result of the
<code><a href="stats.html#topic+as.stepfun">as.stepfun</a></code>-method for <code>"epidataCS"</code>, and the number
of potential sources of transmission for each event (<code>$nSources</code>)
which is based on the given maximum interaction ranges <code>eps.t</code>
and <code>eps.s</code>.
</p>


<h3>Note</h3>

<p>Since the observation region <code>W</code> defines the integration domain
in the point process likelihood,
the more detailed the polygons of <code>W</code> are the longer it will
take to fit a <code><a href="#topic+twinstim">twinstim</a></code>. You are advised to
sacrifice some shape details for speed by reducing the polygon
complexity, for example via the <code>mapshaper</code> JavaScript library
wrapped by the R package <a href="https://CRAN.R-project.org/package=rmapshaper"><span class="pkg">rmapshaper</span></a>, or via
<code><a href="spatstat.geom.html#topic+simplify.owin">simplify.owin</a></code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>
<p>Contributions to this documentation by Michael
Höhle and Mayeul Kauffmann.
</p>


<h3>References</h3>

<p>Meyer, S., Elias, J. and Höhle, M. (2012):
A space-time conditional intensity model for invasive meningococcal
disease occurrence. <em>Biometrics</em>, <b>68</b>, 607-616.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01684.x">doi:10.1111/j.1541-0420.2011.01684.x</a>
</p>
<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p><code>vignette("twinstim")</code>.
</p>
<p><code><a href="#topic+plot.epidataCS">plot.epidataCS</a></code> for plotting, and
<code><a href="#topic+animate.epidataCS">animate.epidataCS</a></code> for the animation of such an epidemic.
There is also an <code><a href="#topic+update.epidataCS">update</a></code> method for the
<code>"epidataCS"</code> class.
</p>
<p>To re-extract the <code>events</code> point pattern from <code>"epidataCS"</code>,
use <code>as(object, "SpatialPointsDataFrame")</code>.
</p>
<p>It is possible to convert an <code>"epidataCS"</code> point pattern to
an <code>"<a href="#topic+epidata">epidata</a>"</code> object (<code><a href="#topic+as.epidata.epidataCS">as.epidata.epidataCS</a></code>),
or to aggregate the events into an <code>"<a href="#topic+sts-class">sts</a>"</code> object
(<code><a href="#topic+epidataCS2sts">epidataCS2sts</a></code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load "imdepi" example data (which is an object of class "epidataCS")
data("imdepi")

## print and summary
print(imdepi, n=5, digits=2)
print(s &lt;- summary(imdepi))
plot(s$counter,  # same as 'as.stepfun(imdepi)'
     xlab = "Time [days]", ylab="Number of infectious individuals",
     main=paste("Time course of the number of infectious individuals",
                "assuming an infectious period of 30 days", sep="\n"))
plot(table(s$nSources), xlab="Number of \"close\" infective individuals",
     ylab="Number of events",
     main=paste("Distribution of the number of potential sources",
                "assuming an interaction range of 200 km and 30 days",
                sep="\n"))
## the summary object contains further information
str(s)

## a histogram of the spatial distances to potential source events
## (i.e., to events of the previous eps.t=30 days within eps.s=200 km)
sourceDists_space &lt;- getSourceDists(imdepi, "space")
hist(sourceDists_space); rug(sourceDists_space)

## internal structure of an "epidataCS"-object
str(imdepi, max.level=4)
## see help("imdepi") for more info on the data set

## extraction methods subset the 'events' component
imdepi[101:200,]
head(imdepi, n=1)           # only first event
tail(imdepi, n=4)           # only last 4 events
subset(imdepi, type=="B")   # only events of type B

## see help("plot.epidataCS") for convenient plot-methods for "epidataCS"


###
### reconstruct the "imdepi" object
###

## observation region
load(system.file("shapes", "districtsD.RData", package="surveillance"),
     verbose = TRUE)

## extract point pattern of events from the "imdepi" data
## a) as a data frame with coordinate columns via marks()
eventsData &lt;- marks(imdepi)
## b) as a Spatial object via the coerce-method
events &lt;- as(imdepi, "SpatialPointsDataFrame")

## plot observation region with events (may require package 'sf')
if (requireNamespace("sf")) {
  plot(stateD, axes=TRUE); title(xlab="x [km]", ylab="y [km]")
  points(events, pch=unclass(events$type), cex=0.5, col=unclass(events$type))
  legend("topright", legend=levels(events$type), title="Type", pch=1:2, col=1:2)

  summary(events)
}

## space-time grid with endemic covariates
head(stgrid &lt;- imdepi$stgrid[,-1])

## reconstruct the "imdepi" object from its components
myimdepi &lt;- as.epidataCS(events = events, stgrid = stgrid,
                         W = stateD, qmatrix = diag(2), nCircle2Poly = 16)

## This reconstructed object is equal to 'imdepi' as long as the internal
## structures of the embedded classes ("owin", "SpatialPolygons", ...), and
## the calculation of the influence regions by "polyclip" have not changed:
stopifnot(all.equal(imdepi, myimdepi))
</code></pre>

<hr>
<h2 id='epidataCS_aggregate'>Conversion (aggregation) of <code>"epidataCS"</code> to <code>"epidata"</code> or <code>"sts"</code></h2><span id='topic+epidataCS2sts'></span><span id='topic+as.epidata.epidataCS'></span>

<h3>Description</h3>

<p>Continuous-time continuous-space epidemic data stored in an object of
class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code> can be aggregated in space or in space
and time yielding an object of class <code>"<a href="#topic+epidata">epidata</a>"</code> or
<code>"<a href="#topic+sts-class">sts</a>"</code> for use of <code><a href="#topic+twinSIR">twinSIR</a></code> or
<code><a href="#topic+hhh4">hhh4</a></code> modelling, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## aggregation in space and time over 'stgrid' for use of 'hhh4' models
epidataCS2sts(object, freq, start, neighbourhood,
              tiles = NULL, popcol.stgrid = NULL, popdensity = TRUE)

## aggregation in space for use of 'twinSIR' models
## S3 method for class 'epidataCS'
as.epidata(data, tileCentroids, eps = 0.001, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidataCS_aggregate_+3A_object">object</code>, <code id="epidataCS_aggregate_+3A_data">data</code></td>
<td>
<p>an object of class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_aggregate_+3A_freq">freq</code>, <code id="epidataCS_aggregate_+3A_start">start</code></td>
<td>

<p>see the description of the <code>"<a href="#topic+sts-class">sts</a>"</code> class.
The <code>start</code> specification should reflect the beginning of
<code>object$stgrid</code>, i.e., the start of the first time interval.
</p>
</td></tr>
<tr><td><code id="epidataCS_aggregate_+3A_neighbourhood">neighbourhood</code></td>
<td>

<p>binary adjacency or neighbourhood-order matrix of the regions
(<code>tiles</code>). If missing but <code>tiles</code> is given, a binary
adjacency matrix will be auto-generated from <code>tiles</code> using
functionality of the <span class="pkg">spdep</span> package (see
<code><a href="#topic+poly2adjmat">poly2adjmat</a></code>).
Since the <code>"neighbourhood"</code> slot in <code>"<a href="#topic+sts-class">sts</a>"</code>
is actually optional, <code>neighbourhood=NULL</code> also works.
</p>
</td></tr>  
<tr><td><code id="epidataCS_aggregate_+3A_tiles">tiles</code></td>
<td>

<p>object inheriting from <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>
representing the regions in <code>object$stgrid</code> (column
<code>"tile"</code>). It will become the <code>"map"</code> slot of the
resulting <code>"sts"</code> object.
Its <code>row.names</code> must match <code>levels(object$stgrid$tile)</code>.
If <code>neighbourhood</code> is provided, <code>tiles</code> is optional (not
required for <code>hhh4</code>, but for plots of the resulting
<code>"sts"</code> object). 
</p>
</td></tr>
<tr><td><code id="epidataCS_aggregate_+3A_popcol.stgrid">popcol.stgrid</code></td>
<td>

<p>single character or numeric value indexing the
column in <code>object$stgrid</code> which contains the population data
(counts or densities, depending on the <code>popdensity</code> argument).
This will become the <code>"populationFrac"</code> slot (optional).</p>
</td></tr>
<tr><td><code id="epidataCS_aggregate_+3A_popdensity">popdensity</code></td>
<td>

<p>logical indicating if the column referenced by
<code>popcol.stgrid</code> contains population densities or absolute counts.
</p>
</td></tr>
<tr><td><code id="epidataCS_aggregate_+3A_tilecentroids">tileCentroids</code></td>
<td>

<p>a coordinate matrix of the region centroids (i.e., the result of
<code>coordinates(tiles)</code>). Its row names must match
<code>levels(data$stgrid$tile)</code>.
This will be the coordinates used for the &ldquo;population&rdquo; (i.e.,
the <code>tiles</code> from <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>) in the
discrete-space <code><a href="#topic+twinSIR">twinSIR</a></code> modelling.
</p>
</td></tr>
<tr><td><code id="epidataCS_aggregate_+3A_eps">eps</code></td>
<td>

<p>numeric scalar for breaking tied removal and infection times between different
individuals (tiles), which might occur during conversion from
<code>"epidataCS"</code> to <code>"epidata"</code>. Rather dumb, this is simply done
by subtracting <code>eps</code> from each tied removal time.
One should consider other ways of breaking the tied event times.
</p>
</td></tr>
<tr><td><code id="epidataCS_aggregate_+3A_...">...</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conversion to <code>"<a href="#topic+sts-class">sts</a>"</code> only makes sense if the time
intervals (<code>BLOCK</code>s) of the <code>stgrid</code> are regularly spaced
(to give <code>freq</code> intervals per year). Note that events of the
prehistory (not covered by <code>stgrid</code>) are not included in the
resulting <code>sts</code> object.
</p>
<p>Some comments on the conversion to <code>"epidata"</code>:
the conversion results into SIS epidemics only,
i.e. the at-risk indicator is set to 1 immediately after
recovery. A tile is considered infective if at least one individual
within the tile is infective, otherwise it is susceptible.
The lengths of the infectious periods are taken from
<code>data$events$eps.t</code>. There will be no <code>f</code> columns in the resulting
<code>"epidata"</code>. These must be generated by a subsequent call to
<code><a href="#topic+as.epidata">as.epidata</a></code> with desired <code>f</code>.
</p>


<h3>Value</h3>

<p><code>epidataCS2sts</code>: an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>
representing the multivariate time-series of the number of
cases aggregated over <code>stgrid</code>.
</p>
<p><code>as.epidata.epidataCS</code>: an object of class
<code>"<a href="#topic+epidata">epidata</a>"</code> representing an SIS epidemic in form of a
multivariate point process (one for each region/<code>tile</code>).
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+epidata">epidata</a></code> and <code><a href="#topic+twinSIR">twinSIR</a></code>
</p>
<p><code>linkS4class{sts}</code> and <code><a href="#topic+hhh4">hhh4</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi")
load(system.file("shapes", "districtsD.RData", package="surveillance"))

## convert imdepi point pattern into multivariate time series
imdsts &lt;- epidataCS2sts(imdepi, freq = 12, start = c(2002, 1),
                        neighbourhood = NULL, # not needed here
                        tiles = districtsD)

## check the overall number of events by district
stopifnot(all.equal(colSums(observed(imdsts)),
                    c(table(imdepi$events$tile))))

## compare plots of monthly number of cases
opar &lt;- par(mfrow = c(2, 1))
plot(imdepi, "time")
plot(imdsts, type = observed ~ time)
par(opar)


## plot number of cases by district
plot(imdsts, type = observed ~ unit)

## also test conversion to an SIS event history ("epidata") of the "tiles"
if (requireNamespace("intervals")) {
    imdepi_short &lt;- subset(imdepi, time &lt; 50)  # to reduce the runtime
    imdepi_short$stgrid &lt;- subset(imdepi_short$stgrid, start &lt; 50)
    imdepidata &lt;- as.epidata(imdepi_short,
                             tileCentroids = coordinates(districtsD))
    summary(imdepidata)
}
</code></pre>

<hr>
<h2 id='epidataCS_animate'>
Spatio-Temporal Animation of a Continuous-Time Continuous-Space Epidemic
</h2><span id='topic+animate.epidataCS'></span>

<h3>Description</h3>

<p>Function for the animation of continuous-time continuous-space
epidemic data, i.e. objects inheriting from class <code>"epidataCS"</code>.
There are three types of animation, see argument <code>time.spacing</code>.
Besides the on-screen plotting in the interactive <span class="rlang"><b>R</b></span> session, it is possible
and recommended to redirect the animation to an off-screen graphics
device using the contributed <span class="rlang"><b>R</b></span> package <span class="pkg">animation</span>. For instance,
the animation can be watched and navigated in a web browser via
<code><a href="animation.html#topic+saveHTML">saveHTML</a></code> (see Examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'epidataCS'
animate(object, interval = c(0,Inf), time.spacing = NULL,
        nmax = NULL, sleep = NULL, legend.opts = list(), timer.opts = list(),
        pch = 15:18, col.current = "red", col.I = "#C16E41",
        col.R = "#B3B3B3", col.influence = NULL,
        main = NULL, verbose = interactive(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidataCS_animate_+3A_object">object</code></td>
<td>

<p>an object inheriting from class <code>"epidataCS"</code>.
</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_interval">interval</code></td>
<td>
<p>time range of the animation.</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_time.spacing">time.spacing</code></td>
<td>

<p>time interval for the animation steps.<br />
If <code>NULL</code> (the default), the events are plotted sequentially by
producing a snapshot at every time point where an event occurred.
Thus, it is just the <em>ordering</em> of the events, which is shown.<br />
To plot the appearance of events proportionally to the exact time line,
<code>time.spacing</code> can be set to a numeric value indicating the period of
time between consecutive snapshots.  Then, for each time point in
<code>seq(0, end, by = time.spacing)</code> the current state of the epidemic can
be seen and an additional timer indicates the current time
(see <code>timer.opts</code> below).<br />
If <code>time.spacing = NA</code>, then the time spacing is automatically
determined in such a way that <code>nmax</code> snapshots result. In this
case, <code>nmax</code> must be given a finite value.
</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_nmax">nmax</code></td>
<td>

<p>maximum number of snapshots to generate. The default <code>NULL</code>
means to take the value from <code>ani.options("nmax")</code> if the
<span class="pkg">animation</span> package is available, and no limitation (<code>Inf</code>)
otherwise.
</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_sleep">sleep</code></td>
<td>

<p>numeric scalar specifying the artificial pause in seconds between two
time points (using <code><a href="base.html#topic+Sys.sleep">Sys.sleep</a></code>), or <code>NULL</code>
(default), when this is taken from <code>ani.options("interval")</code> if
the <span class="pkg">animation</span> package is available, and set to 0.1 otherwise.
Note that <code>sleep</code> is ignored on non-interactive devices
(see <code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>), e.g., if generating an
animation inside <span class="pkg">animation</span>'s <code><a href="animation.html#topic+saveHTML">saveHTML</a></code>.
</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_pch">pch</code>, <code id="epidataCS_animate_+3A_col">col</code></td>
<td>

<p>vectors of length equal to the number of event types specifying the
point symbols and colors for events to plot (in this order).
The vectors are recycled if necessary.
</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_legend.opts">legend.opts</code></td>
<td>

<p>either a list of arguments passed to the <code><a href="graphics.html#topic+legend">legend</a></code> function or
<code>NULL</code> (or <code>NA</code>), in which case no legend will be plotted.  All 
necessary arguments have sensible defaults and need not be
specified.
</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_timer.opts">timer.opts</code></td>
<td>

<p>either a list of arguments passed to the <code><a href="graphics.html#topic+legend">legend</a></code> function or
<code>NULL</code> (or <code>NA</code>), in which case no timer will be plotted.  All 
necessary arguments have sensible defaults and need not be specified, i.e.
</p>

<dl>
<dt><code>x</code>:</dt><dd><p><code>"bottomright"</code></p>
</dd>
<dt><code>title</code>:</dt><dd><p><code>"time"</code></p>
</dd>
<dt><code>box.lty</code>:</dt><dd><p><code>0</code></p>
</dd>
<dt><code>adj</code>:</dt><dd><p><code>c(0.5,0.5)</code></p>
</dd>
<dt><code>inset</code>:</dt><dd><p><code>0.01</code></p>
</dd>
<dt><code>bg</code>:</dt><dd><p><code>"white"</code></p>
</dd>
</dl>

<p>Note that the argument <code>legend</code>, which is the current time of the
animation, can not be modified.
</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_col.current">col.current</code></td>
<td>
<p>color of events when occurring (new).</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_col.i">col.I</code></td>
<td>
<p>color once infectious.</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_col.r">col.R</code></td>
<td>
<p>color event has once &ldquo;recovered&rdquo;. If <code>NA</code>,
then recovered events will not be shown.</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_col.influence">col.influence</code></td>
<td>
<p>color with which the influence region is drawn. Use
<code>NULL</code> (default) if no influence regions should be drawn.</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_main">main</code></td>
<td>
<p>optional main title placed above the map.</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_verbose">verbose</code></td>
<td>
<p>logical specifying if a (textual) progress bar should
be shown during snapshot generation. This is especially useful if
the animation is produced within <code><a href="animation.html#topic+saveHTML">saveHTML</a></code>
or similar.</p>
</td></tr>
<tr><td><code id="epidataCS_animate_+3A_...">...</code></td>
<td>

<p>further graphical parameters passed to the plot-method of the
<code><a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons-class</a></code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sebastian Meyer with documentation contributions by Michael Höhle
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.epidataCS">plot.epidataCS</a></code> for plotting the numbers of events by time
(aggregated over space) or the locations of the events in the
observation region <code>W</code> (aggregated over time).
</p>
<p>The contributed <span class="rlang"><b>R</b></span> package <span class="pkg">animation</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi")
imdepiB &lt;- subset(imdepi, type == "B")

## Not run: 
# Animate the first year of type B with a step size of 7 days
animate(imdepiB, interval=c(0,365), time.spacing=7, nmax=Inf, sleep=0.1)

# Sequential animation of type B events during the first year
animate(imdepiB, interval=c(0,365), time.spacing=NULL, sleep=0.1)

# Animate the whole time range but with nmax=20 snapshots only
animate(imdepiB, time.spacing=NA, nmax=20, sleep=0.1)

## End(Not run)

# Such an animation can be saved in various ways using the tools of
# the animation package, e.g., saveHTML()
if (interactive() &amp;&amp; require("animation")) {
  oldwd &lt;- setwd(tempdir())  # to not clutter up the current working dir
  saveHTML(animate(imdepiB, interval = c(0,365), time.spacing = 7),
           nmax = Inf, interval = 0.2, loop = FALSE,
           title = "Animation of the first year of type B events")
  setwd(oldwd)
}
</code></pre>

<hr>
<h2 id='epidataCS_permute'>
Randomly Permute Time Points or Locations of <code>"epidataCS"</code>
</h2><span id='topic+permute.epidataCS'></span>

<h3>Description</h3>

<p>Monte Carlo tests for space-time interaction (<code><a href="#topic+epitest">epitest</a></code>)
use the distribution of some test statistic under the null hypothesis
of no space-time interaction. For this purpose, the function
<code>permute.epidataCS</code> randomly permutes the time or space labels of
the events.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permute.epidataCS(x, what = c("time", "space"), keep)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidataCS_permute_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_permute_+3A_what">what</code></td>
<td>
<p>character string determining what to permute: time points
(default) or locations.</p>
</td></tr>
<tr><td><code id="epidataCS_permute_+3A_keep">keep</code></td>
<td>
<p>optional logical expression to be evaluated in the context
of <code>x$events@data</code>, determining for which events the time and
location should be kept as is. For instance, to keep some
&ldquo;prehistory&rdquo; before time point 30 unchanged, use
<code>keep = time &lt;= 30</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the permuted <code>"<a href="#topic+epidataCS">epidataCS</a>"</code> object.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+epitest">epitest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi")

set.seed(3)
permepi &lt;- permute.epidataCS(imdepi, what = "time", keep = time &lt;= 30)

print(imdepi, n = 8)
print(permepi, n = 8)
## the first 6 events are kept (as are all row.names),
## the time labels of the remaining events are shuffled
## (and events then again sorted by time),
## the marginal temporal distribution is unchanged
</code></pre>

<hr>
<h2 id='epidataCS_plot'>
Plotting the Events of an Epidemic over Time and Space
</h2><span id='topic+plot.epidataCS'></span><span id='topic+epidataCSplot_time'></span><span id='topic+epidataCSplot_space'></span>

<h3>Description</h3>

<p>The <code>plot</code> method for class <code>"epidataCS"</code> either plots the
number of events along the time axis (<code>epidataCSplot_time</code>) as a
<code>hist()</code>, or the locations of the events in the observation region
<code>W</code> (<code>epidataCSplot_space</code>).
The spatial plot can be enriched with tile-specific color levels to
indicate attributes such as the population (using <code><a href="sp.html#topic+spplot">spplot</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'epidataCS'
plot(x, aggregate = c("time", "space"), subset, by = type, ...)

epidataCSplot_time(x, subset, by = type,
                   t0.Date = NULL, breaks = "stgrid", freq = TRUE,
                   col = rainbow(nTypes), cumulative = list(),
                   add = FALSE, mar = NULL, xlim = NULL, ylim = NULL,
                   xlab = "Time", ylab = NULL, main = NULL,
                   panel.first = abline(h=axTicks(2), lty=2, col="grey"),
                   legend.types = list(), ...)

epidataCSplot_space(x, subset, by = type, tiles = x$W, pop = NULL,
                    cex.fun = sqrt, points.args = list(), add = FALSE,
                    legend.types = list(), legend.counts = list(),
                    sp.layout = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidataCS_plot_+3A_x">x</code></td>
<td>

<p>an object of class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>.
</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_aggregate">aggregate</code></td>
<td>

<p>character, one of <code>"time"</code> and <code>"space"</code>, referring to the
specific plot functions <code>epidataCSplot_time</code> and
<code>epidataCSplot_time</code>, respectively.
For <code>"time"</code>, the number of events over time is plotted as
<code><a href="graphics.html#topic+hist">hist</a></code> (or <code><a href="graphics.html#topic+hist.Date">hist.Date</a></code>).
For <code>"space"</code>, the observation region <code>x$W</code> (or the
<code>tiles</code>) and the locations of the events therein are plotted.
</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_subset">subset</code></td>
<td>

<p>logical expression indicating a subset of events to consider for
plotting: missing values are taken as false. Note that the
expression is evaluated in the data frame of event marks
(<code>marks(x)</code>), which means that column names can be referred to
by name (like in <code><a href="base.html#topic+subset.data.frame">subset.data.frame</a></code>).
</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_...">...</code></td>
<td>

<p>in the basic <code>plot</code>-method further arguments are passed to the
<code>aggregate</code>-specific plot function.
In <code>epidataCSplot_time</code>, further graphical parameters are
passed to <code><a href="graphics.html#topic+hist">hist</a></code> or <code><a href="graphics.html#topic+hist.Date">hist.Date</a></code>,
respectively. In <code>epidataCSplot_space</code>, further arguments are
passed to the <code>plot</code>-method for
<code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>, which draws <code>tiles</code>.
</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_by">by</code></td>
<td>
<p>an expression evaluated in <code>marks(x)</code>, defining how
events should be stratified in the plot (the result is converted to
a factor), or <code>NULL</code> to disregard event types.
By default (<code>by = type</code>) the plot distinguishes between event
types, i.e., the bars of the temporal plot are stacked by type, and
the point colors in the spatial plot differ by type, respectively.<br />
Note: to select specific event types for plotting use the
<code>subset</code> argument, e.g., <code>subset=(type=="B")</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_t0.date">t0.Date</code></td>
<td>
<p>the beginning of the observation period
<code>t0 = x$stgrid$start[1]</code> as a <code>"<a href="base.html#topic+Date">Date</a>"</code> (or
anything coercible by <code>as.Date</code> without further arguments),
enabling a nice x-axis using <code><a href="graphics.html#topic+hist.Date">hist.Date</a></code> and sensible
<code>breaks</code> of the histogram, e.g., <code>breaks="months"</code>.
The event times then equal
<code>t0.Date + as.integer(x$events$time - t0)</code>, i.e. possible
fractional parts of the event times are removed (which ensures that
using <code>breaks = "months"</code> or other automatic types always
works).</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_breaks">breaks</code></td>
<td>

<p>a specification of the histogram break points, see
<code><a href="graphics.html#topic+hist">hist</a></code> (or <code><a href="graphics.html#topic+hist.Date">hist.Date</a></code> if <code>t0.Date</code> is
used). The default value <code>"stgrid"</code> is special and means to use
the temporal grid points
<code>with(x$stgrid, c(start[1L], unique.default(stop)))</code>
as breaks (or their <code>"Date"</code> equivalents).
</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_freq">freq</code></td>
<td>
<p>see <code><a href="graphics.html#topic+hist">hist</a></code>, defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_col">col</code></td>
<td>
<p>fill colour for the bars of the histogram, defaults to
the vector of <code><a href="grDevices.html#topic+rainbow">rainbow</a></code> colours.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_cumulative">cumulative</code></td>
<td>
<p>if a list (of style options),
lines for the cumulative number of events (per type) will be
added to the plot. Possible options are <code>axis</code> (logical),
<code>lab</code> (axis label), <code>maxat</code> (single integer affecting
the axis range), <code>lwd</code>, <code>col</code>, and <code>offset</code> (a
numeric vector of length the number of types).</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_add">add</code></td>
<td>
<p>logical (default: <code>FALSE</code>) indicating if the plot
should be added to an existing window.
Ignored if an <code><a href="sp.html#topic+spplot">spplot</a></code> is created (if <code>pop</code> is
non-<code>NULL</code>).</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_mar">mar</code></td>
<td>
<p>see <code><a href="graphics.html#topic+par">par</a></code>. The default (<code>NULL</code>) is
<code>mar &lt;- par("mar")</code>, with <code>mar[4] &lt;- mar[2]</code> if an
axis is requested for the <code>cumulative</code> numbers.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_xlim">xlim</code>, <code id="epidataCS_plot_+3A_ylim">ylim</code></td>
<td>
<p><code>NULL</code> provides automatic axis limits.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_xlab">xlab</code>, <code id="epidataCS_plot_+3A_ylab">ylab</code></td>
<td>
<p>axis labels (with sensible defaults).</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_main">main</code></td>
<td>
<p>main title of the plot (defaults to no title).</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_panel.first">panel.first</code></td>
<td>
<p>expression that should be evaluated after the
plotting window has been set up but before the histogram is plotted.
Defaults to adding horizontal grid lines.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_legend.types">legend.types</code></td>
<td>
<p>if a list (of arguments for <code><a href="graphics.html#topic+legend">legend</a></code>),
a legend for the event types is added to the plot in case there is
more than one type.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_tiles">tiles</code></td>
<td>
<p>the observation region <code>x$W</code> (default) or,
alternatively, a <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>
representation of the tiles of <code>x$stgrid</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_pop">pop</code></td>
<td>
<p>if <code>tiles</code> is a
<code>"<a href="sp.html#topic+SpatialPolygonsDataFrame-class">SpatialPolygonsDataFrame</a>"</code>, <code>pop</code> can
specify an attribute to be displayed in a <code>levelplot</code> behind the
point pattern, see <code><a href="sp.html#topic+spplot">spplot</a></code>. By default (<code>NULL</code>),
the conventional graphics system is used to display the <code>tiles</code>
and event locations, otherwise the result is a
<code><a href="lattice.html#topic+trellis.object">trellis.object</a></code>.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_cex.fun">cex.fun</code></td>
<td>
<p>function which takes a vector of counts of events
at each unique location and returns a (vector of) <code>cex</code>
value(s) for the sizes of the corresponding <code>points</code>.
Defaults to the <code>sqrt()</code> function, which for the default
circular <code>pch=1</code> means that the area of each point is
proportional to the number of events at its location.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_points.args">points.args</code></td>
<td>
<p>a list of (type-specific) graphical parameters
for <code><a href="graphics.html#topic+points">points</a></code>, specifically <code>pch</code>, <code>lwd</code>,
and <code>col</code>, which are all recycled to give the length
<code>nlevels(x$events$type)</code>. In contrast, a possible
<code>cex</code> element should be scalar (default: 0.5) and 
multiplies the sizes obtained from <code>cex.fun</code>.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_legend.counts">legend.counts</code></td>
<td>
<p>if a list (of arguments for
<code><a href="graphics.html#topic+legend">legend</a></code>), a legend illustrating the effect of 
<code>cex.fun</code> is added to the plot. This list may contain a
special element <code>counts</code>, which is an integer vector
specifying the counts to illustrate.</p>
</td></tr>
<tr><td><code id="epidataCS_plot_+3A_sp.layout">sp.layout</code></td>
<td>
<p>optional list of additional layout items in case
<code>pop</code> is non-<code>NULL</code>, see <code><a href="sp.html#topic+spplot">spplot</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>aggregate="time"</code> (i.e., <code>epidataCSplot_time</code>) the data
of the histogram (as returned by <code><a href="graphics.html#topic+hist">hist</a></code>),
and for <code>aggregate="space"</code> (i.e., <code>epidataCSplot_space</code>)
<code>NULL</code>, invisibly, or the <code><a href="lattice.html#topic+trellis.object">trellis.object</a></code> generated by
<code><a href="sp.html#topic+spplot">spplot</a></code> (if <code>pop</code> is non-<code>NULL</code>).
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+animate.epidataCS">animate.epidataCS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi")

## show the occurrence of events along time
plot(imdepi, "time", main = "Histogram of event time points")
plot(imdepi, "time", by = NULL, main = "Aggregated over both event types")

## show the distribution in space
plot(imdepi, "space", lwd = 2, col = "lavender")


## with the district-specific population density in the background,
## a scale bar, and customized point style
load(system.file("shapes", "districtsD.RData", package = "surveillance"))
districtsD$log10popdens &lt;- log10(districtsD$POPULATION/districtsD$AREA)
keylabels &lt;- (c(1,2,5) * rep(10^(1:3), each=3))[-1]
plot(imdepi, "space", tiles = districtsD, pop = "log10popdens",
     ## modify point style for better visibility on gray background
     points.args = list(pch=c(1,3), col=c("orangered","blue"), lwd=2),
     ## metric scale bar, see proj4string(imdepi$W)
     sp.layout = layout.scalebar(imdepi$W, scale=100, labels=c("0","100 km")),
     ## gray scale for the population density and white borders
     col.regions = gray.colors(100, start=0.9, end=0.1), col = "white",
     ## color key is equidistant on log10(popdens) scale
     at = seq(1.3, 3.7, by=0.05),
     colorkey = list(labels=list(at=log10(keylabels), labels=keylabels),
                     title=expression("Population density per " * km^2)))

</code></pre>

<hr>
<h2 id='epidataCS_update'>
Update method for <code>"epidataCS"</code>
</h2><span id='topic+update.epidataCS'></span>

<h3>Description</h3>

<p>The <code><a href="stats.html#topic+update">update</a></code> method for the <code>"<a href="#topic+epidataCS">epidataCS</a>"</code> class
may be used to modify the hyperparameters <code class="reqn">\epsilon</code> (<code>eps.t</code>)
and <code class="reqn">\delta</code> (<code>eps.s</code>), the indicator matrix <code>qmatrix</code> of
possible ways of transmission between the event types, and the numerical
accuracy <code>nCircle2Poly</code> of the polygonal representation of a
circle.
The update method will also update the auxiliary information contained
in an <code>"epidataCS"</code> object accordingly, e.g., the vector of potential
sources of each event, or the polygonal representation of the influence
region.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'epidataCS'
update(object, eps.t, eps.s, qmatrix, nCircle2Poly, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epidataCS_update_+3A_object">object</code></td>
<td>

<p>an object of class <code>"epidataCS"</code>.
</p>
</td></tr>
<tr><td><code id="epidataCS_update_+3A_eps.t">eps.t</code></td>
<td>

<p>numeric vector of length the number of events in
<code>object$events</code>.  The event data column <code>eps.t</code> specifies
the maximum temporal influence radius (e.g., length of infectious
period, time to culling, etc.) of the events. 
</p>
</td></tr>
<tr><td><code id="epidataCS_update_+3A_eps.s">eps.s</code></td>
<td>

<p>numeric vector of length the number of events in
<code>object$events</code>.  The event data column <code>eps.s</code> specifies
the maximum spatial influence radius of the events.
</p>
</td></tr>
<tr><td><code id="epidataCS_update_+3A_qmatrix">qmatrix</code></td>
<td>

<p>square indicator matrix (0/1 or TRUE/FALSE) for possible
transmission between the event types.
</p>
</td></tr>
<tr><td><code id="epidataCS_update_+3A_ncircle2poly">nCircle2Poly</code></td>
<td>

<p>accuracy (number of edges) of the polygonal approximation of a circle.
</p>
</td></tr>
<tr><td><code id="epidataCS_update_+3A_...">...</code></td>
<td>

<p>unused (argument of the generic).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated <code>"epidataCS"</code> object.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p>class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi")

## assume different interaction ranges and simplify polygons
imdepi2 &lt;- update(imdepi, eps.t = 20, eps.s = Inf, nCircle2Poly = 16)
    
(s &lt;- summary(imdepi))
(s2 &lt;- summary(imdepi2))
## The update reduced the number of infectives (along time)
## because the length of the infectious periods is reduced. It also 
## changed the set of potential sources of transmission for each
## event, since the interaction is shorter in time but wider in space
## (eps.s=Inf means interaction over the whole observation region).
</code></pre>

<hr>
<h2 id='estimateGLRNbHook'>Hook function for in-control mean estimation</h2><span id='topic+estimateGLRNbHook'></span>

<h3>Description</h3>

<p>Estimation routine for the in-control mean of <code><a href="#topic+algo.glrpois">algo.glrpois</a></code>.
</p>
<p>In <span class="rlang"><b>R</b></span> &lt; 2.14.0 and <span class="pkg">surveillance</span> &lt; 1.4 (i.e., without a package
namespace) users could customize this function simply by
defining a modified version in their workspace.
This is no longer supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimateGLRNbHook()
</code></pre>


<h3>Value</h3>

<p>A list with elements
</p>
<table>
<tr><td><code>mod</code></td>
<td>
<p>resulting model of a call of <code>glm.nb</code></p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>vector of length as <code>range</code> containing the predicted values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>M. Hoehle</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.glrnb">algo.glrnb</a></code>
</p>

<hr>
<h2 id='fanplot'>Fan Plot of Forecast Distributions</h2><span id='topic+fanplot'></span>

<h3>Description</h3>

<p>The <code>fanplot()</code> function in <span class="pkg">surveillance</span> wraps functionality of
the dedicated <a href="https://CRAN.R-project.org/package=fanplot"><span class="pkg">fanplot</span></a> package, employing a different default style
and optionally adding point predictions and observed values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fanplot(quantiles, probs, means = NULL, observed = NULL, start = 1,
        fan.args = list(), means.args = list(), observed.args = list(),
        key.args = NULL, xlim = NULL, ylim = NULL, log = "",
        xlab = "Time", ylab = "No. infected", add = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fanplot_+3A_quantiles">quantiles</code></td>
<td>

<p>a time x <code>probs</code> matrix of forecast quantiles at each time point.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_probs">probs</code></td>
<td>

<p>numeric vector of probabilities with values between 0 and 1.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_means">means</code></td>
<td>

<p>(optional) numeric vector of point forecasts.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_observed">observed</code></td>
<td>

<p>(optional) numeric vector of observed values.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_start">start</code></td>
<td>

<p>time index (x-coordinate) of the first prediction.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_fan.args">fan.args</code></td>
<td>

<p>a list of graphical parameters for the <code><a href="fanplot.html#topic+fan">fan</a></code>,
e.g., to employ a different <code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code> as
<code>fan.col</code>, or to enable contour lines via <code>ln</code>.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_means.args">means.args</code></td>
<td>

<p>a list of graphical parameters for <code><a href="graphics.html#topic+lines">lines</a></code>
to modify the plotting style of the <code>means</code>.
The default is a white line within the fan.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_observed.args">observed.args</code></td>
<td>

<p>a list of graphical parameters for <code><a href="graphics.html#topic+lines">lines</a></code>
to modify the plotting style of the <code>observed</code> values.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_key.args">key.args</code></td>
<td>

<p>if a list, a color key (in <code><a href="fanplot.html#topic+fan">fan</a>()</code>'s
<code>"boxfan"</code>-style) is added to the fan chart. The list may
include positioning parameters <code>start</code> (the x-position) and
<code>ylim</code> (the y-range of the color key), <code>space</code> to modify
the width of the boxfan, and <code>rlab</code> to modify the labels.
An alternative way of labeling the quantiles is
via the argument <code>ln</code> in <code>fan.args</code>.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_xlim">xlim</code>, <code id="fanplot_+3A_ylim">ylim</code></td>
<td>

<p>axis ranges.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_log">log</code></td>
<td>

<p>a character string specifying which axes are to be logarithmic,
e.g., <code>log="y"</code> (see <code><a href="graphics.html#topic+plot.default">plot.default</a></code>).
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_xlab">xlab</code>, <code id="fanplot_+3A_ylab">ylab</code></td>
<td>

<p>axis labels.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_add">add</code></td>
<td>

<p>logical indicating if the fan plot should be added to an existing plot.
</p>
</td></tr>
<tr><td><code id="fanplot_+3A_...">...</code></td>
<td>

<p>further arguments are passed to <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
For instance, <code>panel.first</code> could be used to initialize the
plot with <code><a href="graphics.html#topic+grid">grid</a>(nx=NA, ny=NULL)</code> lines.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code> (invisibly), with the side effect of drawing a fan chart.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p>the underlying <code><a href="fanplot.html#topic+fan">fan</a></code> function in package
<a href="https://CRAN.R-project.org/package=fanplot"><span class="pkg">fanplot</span></a>.
The function is used in <code><a href="#topic+plot.oneStepAhead">plot.oneStepAhead</a></code> and
<code><a href="#topic+plot.hhh4sims">plot.hhh4sims</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## artificial data example to illustrate the graphical options
if (requireNamespace("fanplot")) {
    means &lt;- c(18, 19, 20, 25, 26, 35, 34, 25, 19)
    y &lt;- rlnorm(length(means), log(means), 0.5)
    quantiles &lt;- sapply(1:99/100, qlnorm, log(means), seq(.5,.8,length.out=length(means)))
    
    ## default style with point predictions, color key and log-scale
    fanplot(quantiles = quantiles, probs = 1:99/100, means = means,
            observed = y, key.args = list(start = 1, space = .3), log = "y")
    
    ## with contour lines instead of a key, and different colors
    pal &lt;- colorRampPalette(c("darkgreen", "gray93"))
    fanplot(quantiles = quantiles, probs = 1:99/100, observed = y,
            fan.args = list(fan.col = pal, ln = c(5,10,25,50,75,90,95)/100),
            observed.args = list(type = "b", pch = 19))
}
</code></pre>

<hr>
<h2 id='farringtonFlexible'>Surveillance for Univariate Count Time Series Using an Improved Farrington Method</h2><span id='topic+farringtonFlexible'></span>

<h3>Description</h3>


<p>The function takes <code>range</code> values of the surveillance time
series <code>sts</code> and for each time point uses a Poisson GLM with overdispersion to
predict an upper bound on the number of counts according to the procedure by
Farrington et al. (1996) and by Noufaily et al. (2012). This bound is then compared to the observed
number of counts. If the observation is above the bound, then an alarm is raised.
The implementation is illustrated in Salmon et al. (2016).

</p>


<h3>Usage</h3>

<pre><code class='language-R'>farringtonFlexible(sts, control = list(
    range = NULL, b = 5, w = 3,
    reweight = TRUE, weightsThreshold = 2.58,
    verbose = FALSE, glmWarnings = TRUE,
    alpha = 0.05, trend = TRUE, pThresholdTrend = 0.05,
    limit54 = c(5,4), powertrans = "2/3",
    fitFun = "algo.farrington.fitGLM.flexible",
    populationOffset = FALSE,
    noPeriods = 1, pastWeeksNotIncluded = NULL,
    thresholdMethod = "delta"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="farringtonFlexible_+3A_sts">sts</code></td>
<td>
<p>object of class <code><a href="#topic+sts-class">sts</a></code> (including the <code>observed</code> and the <code>state</code> time series)</p>
</td></tr>
<tr><td><code id="farringtonFlexible_+3A_control">control</code></td>
<td>
<p>Control object given as a <code>list</code> containing the following components:
</p>

<dl>
<dt><code>range</code></dt><dd><p>Specifies the index of all timepoints which
should be tested. If range is <code>NULL</code> all possible timepoints are used.</p>
</dd>
<dt><code>b</code></dt><dd><p>How many years back in time to include when
forming the base counts.</p>
</dd>
<dt><code>w</code></dt><dd><p>Window's half-size, i.e. number of weeks to include
before and after the current week in each year.</p>
</dd>
<dt><code>reweight</code></dt><dd><p>Boolean specifying whether to perform reweighting step.</p>
</dd>
<dt><code>weightsThreshold</code></dt><dd><p>Defines the threshold for reweighting past outbreaks  using the Anscombe residuals
(1 in the original method, 2.58 advised in the improved method).</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Boolean specifying whether to show extra debugging information.</p>
</dd>
<dt><code>glmWarnings</code></dt><dd><p>Boolean specifying whether to print warnings from the call to <code>glm</code>.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>An approximate (one-sided) <code class="reqn">(1-\alpha)\cdot 100\%</code>
prediction interval is calculated unlike the original method where it was a two-sided interval. The upper limit of this interval
i.e. the <code class="reqn">(1-\alpha)\cdot 100\%</code> quantile serves as an upperbound.</p>
</dd>
<dt><code>trend</code></dt><dd><p>Boolean indicating whether a trend should be included and kept in
case the conditions in the Farrington et. al. paper are met
(see the results). If <code>false</code> then NO trend is fit.</p>
</dd>
<dt><code>pThresholdTrend</code></dt><dd><p>Threshold for deciding whether to keep trend in the model
(0.05 in the original method, 1 advised in the improved method).</p>
</dd>
<dt><code>limit54</code></dt><dd><p>Vector containing two numbers: <code>cases</code> and <code>period</code>. To avoid alarms in cases where the time series only
has about almost no cases in the specific week the algorithm uses the following heuristic
criterion (see Section 3.8 of the Farrington paper) to protect
against low counts: no alarm is sounded if fewer than
<code class="reqn">\code{cases}=5</code> reports were received in the past <code class="reqn">\code{period}=4</code>
weeks. <code>limit54=c(cases,period)</code> is a vector allowing the
user to change these numbers. Note: As of version 0.9-7 of the package the
term &quot;last&quot; period of weeks includes the current week -
otherwise no alarm is sounded for horrible large numbers if
the four weeks before that are too low.</p>
</dd>
<dt><code>powertrans</code></dt><dd><p>Power transformation to apply to the
data if the threshold is to be computed with  the method described
in Farrington et al. (1996. Use either &quot;2/3&quot; for skewness correction (Default),
&quot;1/2&quot; for variance stabilizing transformation or &quot;none&quot; for no
transformation.</p>
</dd>
<dt><code>fitFun</code></dt><dd><p>String containing the name of the fit
function to be used for fitting the GLM. The only current option is 
&quot;algo.farrington.fitGLM.flexible&quot;.</p>
</dd>
<dt><code>populationOffset</code></dt><dd><p>Boolean specifying whether to include 
a population offset in the GLM. 
The slot <code>sts@population</code> gives the population vector.</p>
</dd>
<dt><code>noPeriods</code></dt><dd><p>Number of levels in the factor allowing to use more baseline. If
equal to 1 no factor variable is created, the set of reference values is defined as in
Farrington et al (1996).</p>
</dd>
<dt><code>pastWeeksNotIncluded</code></dt><dd><p>Number of past weeks to ignore in the calculation.
The default (<code>NULL</code>) means to use the value of <code>control$w</code>.
Setting <code>pastWeeksNotIncluded=26</code> might be preferable
(Noufaily et al., 2012).</p>
</dd>
<dt><code>thresholdMethod</code></dt><dd><p>Method to be used to derive the upperbound.
Options are <code>"delta"</code> for the method described in Farrington et al. (1996),
<code>"nbPlugin"</code> for the method described in Noufaily et al. (2012),
and <code>"muan"</code> for the method extended from Noufaily et al. (2012).</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>The following steps are performed according to the Farrington
et al. (1996) paper.
</p>

<ol>
<li><p> Fit of the initial model with intercept, time trend if <code>trend</code> is <code>TRUE</code>,
seasonal factor variable if <code>noPeriod</code> is bigger than 1, and population offset if
<code>populationOffset</code> is <code>TRUE</code>. Initial estimation of mean and
overdispersion.
</p>
</li>
<li><p> Calculation of the weights omega (correction for past outbreaks) if <code>reweighting</code> is <code>TRUE</code>.
The threshold for reweighting is defined in <code>control</code>.
</p>
</li>
<li><p> Refitting of the model
</p>
</li>
<li><p> Revised estimation of overdispersion
</p>
</li>
<li><p> Omission of the trend, if it is not significant
</p>
</li>
<li><p> Repetition of the whole procedure
</p>
</li>
<li><p> Calculation of the threshold value using the model to compute a quantile of the predictive distribution.
The method used depends on <code>thresholdMethod</code>, this can either be:  
</p>

<dl>
<dt>&quot;delta&quot;</dt><dd><p>One assumes that the prediction error (or a transformation of the prediction
error, depending on <code>powertrans</code>), is normally distributed. The threshold is deduced from a quantile of
this normal distribution using the variance and estimate of the expected
count given by GLM, and the delta rule. The procedure takes into account both the estimation error (variance of the estimator
of the expected count in the GLM) and the prediction error (variance of the prediction error). This is the suggestion
in Farrington et al. (1996).</p>
</dd>
<dt>&quot;nbPlugin&quot;</dt><dd><p>One assumes that the new count follows
a negative binomial distribution parameterized by the expected count and the overdispersion
estimated in the GLM. The threshold is deduced from a quantile of this discrete distribution.
This process disregards the estimation error, though. This method was used in Noufaily, et al. (2012).</p>
</dd>
<dt>&quot;muan&quot;</dt><dd><p>One also uses the assumption of the negative
binomial sampling distribution but does not plug in the estimate of the expected count from the GLM,
instead one uses a quantile from the asymptotic normal distribution of the expected count estimated
in the GLM; in order to take into account both the estimation error and the prediction error.   </p>
</dd>        </dl>

</li>
<li><p> Computation of exceedance score
</p>
</li></ol>

<p>Warning: monthly data containing the last day of each month as date should be analysed with <code>epochAsDate=FALSE</code> in the <code>sts</code> object. Otherwise February makes it impossible to find some reference time points. 
</p>


<h3>Value</h3>

<p>An object of class <code>sts</code> with the slots <code>upperbound</code> and <code>alarm</code> filled by appropriate output of the algorithm.
The <code>control</code> slot of the input <code>sts</code> is amended with the
following matrix elements, all with <code>length(range)</code> rows:
</p>

<dl>
<dt>trend</dt><dd><p>Booleans indicating whether a time trend was fitted for this time point.</p>
</dd>
<dt>trendVector</dt><dd><p>coefficient of the time trend in the GLM for this time point. If no trend was fitted it is equal to NA.</p>
</dd>
<dt>pvalue</dt><dd><p>probability of observing a value at least equal to the observation under the null hypothesis .</p>
</dd>
<dt>expected</dt><dd><p>expectation of the predictive distribution for each timepoint. 
It is only reported if the conditions for raising an alarm are met (enough cases).</p>
</dd>
<dt>mu0Vector</dt><dd><p>input for the negative binomial distribution to get the upperbound as a quantile 
(either a plug-in from the GLM or a quantile from the asymptotic normal distribution of the estimator)</p>
</dd>
<dt>phiVector</dt><dd><p>overdispersion of the GLM at each timepoint.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>M. Salmon, M. Höhle</p>


<h3>References</h3>

<p>Farrington, C.P., Andrews, N.J, Beale A.D. and Catchpole, M.A. (1996):
A statistical algorithm for the early detection of outbreaks of
infectious disease. J. R. Statist. Soc. A, 159, 547-563.
</p>
<p>Noufaily, A., Enki, D.G., Farrington, C.P., Garthwaite, P., Andrews,
N.J., Charlett, A. (2012): An improved algorithm for outbreak
detection in multiple surveillance systems. Statistics in Medicine,
32 (7), 1206-1222.
</p>
<p>Salmon, M., Schumacher, D. and Höhle, M. (2016):
Monitoring count time series in <span class="rlang"><b>R</b></span>: Aberration detection in public
health surveillance. <em>Journal of Statistical Software</em>,
<b>70</b> (10), 1-35. <a href="https://doi.org/10.18637/jss.v070.i10">doi:10.18637/jss.v070.i10</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.farrington.fitGLM">algo.farrington.fitGLM</a></code>,<code><a href="#topic+algo.farrington.threshold">algo.farrington.threshold</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("salmonella.agona")
# Create the corresponding sts object from the old disProg object
salm &lt;- disProg2sts(salmonella.agona)

### RUN THE ALGORITHMS WITH TWO DIFFERENT SETS OF OPTIONS
control1 &lt;-  list(range=282:312,
                  noPeriods=1,
                  b=4, w=3, weightsThreshold=1,
                  pastWeeksNotIncluded=3,
                  pThresholdTrend=0.05,
                  alpha=0.1)
control2 &lt;- list(range=282:312,
                 noPeriods=10,
                 b=4, w=3, weightsThreshold=2.58,
                 pastWeeksNotIncluded=26,
                 pThresholdTrend=1,
                 alpha=0.1)
salm1 &lt;- farringtonFlexible(salm,control=control1)
salm2 &lt;- farringtonFlexible(salm,control=control2)

### PLOT THE RESULTS
y.max &lt;- max(upperbound(salm1),observed(salm1),upperbound(salm2),na.rm=TRUE)
plot(salm1, ylim=c(0,y.max), main='S. Newport in Germany', legend.opts=NULL)
lines(1:(nrow(salm1)+1)-0.5,
      c(upperbound(salm1),upperbound(salm1)[nrow(salm1)]),
      type="s",col='tomato4',lwd=2)
lines(1:(nrow(salm2)+1)-0.5,
      c(upperbound(salm2),upperbound(salm2)[nrow(salm2)]),
      type="s",col="blueviolet",lwd=2)
legend("topleft",
       legend=c('Alarm','Upperbound with old options',
                'Upperbound with new options'),
       pch=c(24,NA,NA),lty=c(NA,1,1),
       bg="white",lwd=c(2,2,2),col=c('red','tomato4',"blueviolet"))
</code></pre>

<hr>
<h2 id='find.kh'>Determine the k and h values in a standard normal setting</h2><span id='topic+find.kh'></span>

<h3>Description</h3>

<p>Given a specification of the average run length in the (a)cceptance
and (r)ejected setting determine the k and h values in a standard
normal setting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  find.kh(ARLa = 500, ARLr = 7, sided = "one", method = "BFGS", verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find.kh_+3A_arla">ARLa</code></td>
<td>
<p>average run length in acceptance setting, aka. in control state. Specifies the number of observations before false alarm.</p>
</td></tr>
<tr><td><code id="find.kh_+3A_arlr">ARLr</code></td>
<td>
<p>average run length in rejection state, aka. out of control state. Specifies the number of observations before an increase is detected (i.e. detection delay)</p>
</td></tr>
<tr><td><code id="find.kh_+3A_sided">sided</code></td>
<td>
<p>one-sided cusum scheme</p>
</td></tr>
<tr><td><code id="find.kh_+3A_method">method</code></td>
<td>
<p>Which method to use in the function <code><a href="stats.html#topic+optim">optim</a></code>. Standard choice is BFGS, but in some situation Nelder-Mead can be advantageous.</p>
</td></tr> 
<tr><td><code id="find.kh_+3A_verbose">verbose</code></td>
<td>
<p>gives extra information about the root finding process</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functions from the <span class="pkg">spc</span> package are used in a simple univariate
root finding problem.
</p>


<h3>Value</h3>

<p>Returns a list with reference value k and decision interval h.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("spc")) {
    find.kh(ARLa=500,ARLr=7,sided="one")
    find.kh(ARLa=500,ARLr=3,sided="one")
}
</code></pre>

<hr>
<h2 id='findH'>Find decision interval for given in-control ARL and reference value</h2><span id='topic+findH'></span><span id='topic+hValues'></span>

<h3>Description</h3>

<p>Function to find a decision interval <code>h</code>* for given reference value <code>k</code>
and desired ARL <code class="reqn">\gamma</code> so that the
average run length for a Poisson or Binomial CUSUM with in-control
parameter <code class="reqn">\theta_0</code>, reference value <code>k</code> and is approximately <code class="reqn">\gamma</code>,
i.e. <code class="reqn">\Big| \frac{ARL(h^*) -\gamma}{\gamma} \Big| &lt; \epsilon</code>,
or larger, i.e.
<code class="reqn">ARL(h^*) &gt; \gamma </code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findH(ARL0, theta0, s = 1, rel.tol = 0.03, roundK = TRUE,
      distr = c("poisson", "binomial"), digits = 1, FIR = FALSE, ...)

hValues(theta0, ARL0, rel.tol=0.02, s = 1, roundK = TRUE, digits = 1,
        distr = c("poisson", "binomial"), FIR = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findH_+3A_arl0">ARL0</code></td>
<td>
<p> desired in-control ARL <code class="reqn">\gamma</code> </p>
</td></tr>
<tr><td><code id="findH_+3A_theta0">theta0</code></td>
<td>
<p>in-control parameter <code class="reqn">\theta_0</code></p>
</td></tr>
<tr><td><code id="findH_+3A_s">s</code></td>
<td>
<p>change to detect, see details</p>
</td></tr>
<tr><td><code id="findH_+3A_distr">distr</code></td>
<td>
 <p><code>"poisson"</code> or <code>"binomial"</code> </p>
</td></tr>
<tr><td><code id="findH_+3A_rel.tol">rel.tol</code></td>
<td>
<p>relative tolerance, i.e. the search for <code>h</code>* is
stopped if <code class="reqn">\Big| \frac{ARL(h^*) -\gamma}{\gamma} \Big| &lt; </code> <code>rel.tol</code> </p>
</td></tr>
<tr><td><code id="findH_+3A_digits">digits</code></td>
<td>
<p>the reference value <code>k</code> and the decision  interval <code>h</code>
are rounded to <code>digits</code> decimal places</p>
</td></tr>
<tr><td><code id="findH_+3A_roundk">roundK</code></td>
<td>
<p> passed to <code>findK</code> </p>
</td></tr>
<tr><td><code id="findH_+3A_fir">FIR</code></td>
<td>
<p>if <code>TRUE</code>, the decision interval that leads to the desired ARL
for a FIR CUSUM with head start
<code class="reqn">\frac{\code{h}}{2}</code> is returned </p>
</td></tr>
<tr><td><code id="findH_+3A_...">...</code></td>
<td>
<p> further arguments for the distribution function, i.e. number
of trials <code>n</code> for binomial cdf </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The out-of-control parameter used to determine the reference value <code>k</code>
is specified as:
</p>
<p style="text-align: center;"><code class="reqn">\theta_1 = \lambda_0 + s \sqrt{\lambda_0} </code>
</p>

<p>for a Poisson variate <code class="reqn">X \sim Po(\lambda)</code>
</p>
<p style="text-align: center;"><code class="reqn">\theta_1 = \frac{s \pi_0}{1+(s-1) \pi_0} </code>
</p>

<p>for a Binomial variate <code class="reqn">X \sim Bin(n, \pi) </code>
</p>


<h3>Value</h3>

<p><code>findH</code> returns a vector and <code>hValues</code> returns a matrix with elements
</p>
<table>
<tr><td><code>theta0</code></td>
<td>
<p>in-control parameter</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>decision interval</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>reference value</p>
</td></tr>
<tr><td><code>ARL</code></td>
<td>
<p>ARL for a CUSUM with parameters <code>k</code> and <code>h</code> </p>
</td></tr>
<tr><td><code>rel.tol</code></td>
<td>
<p>corresponds to <code class="reqn">\Big| \frac{ARL(h) -\gamma}{\gamma} \Big|</code> </p>
</td></tr>
</table>

<hr>
<h2 id='findK'>Find Reference Value</h2><span id='topic+findK'></span>

<h3>Description</h3>

<p>Calculates the reference value <code>k</code> for a Poisson or binomial CUSUM
designed to detect a shift from <code class="reqn">\theta_0</code> to <code class="reqn">\theta_1</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findK(theta0, theta1, distr = c("poisson", "binomial"),
      roundK = FALSE, digits = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findK_+3A_theta0">theta0</code></td>
<td>
<p> in-control parameter </p>
</td></tr>
<tr><td><code id="findK_+3A_theta1">theta1</code></td>
<td>
<p> out-of-control parameter </p>
</td></tr>
<tr><td><code id="findK_+3A_distr">distr</code></td>
<td>
 <p><code>"poisson"</code> or <code>"binomial"</code> </p>
</td></tr>
<tr><td><code id="findK_+3A_digits">digits</code></td>
<td>
<p> the reference value <code>k</code> is rounded to <code>digits</code> decimal places</p>
</td></tr>
<tr><td><code id="findK_+3A_roundk">roundK</code></td>
<td>

<p>For discrete data and rational reference value there is only
a limited set of possible values that the CUSUM can take (and
therefore there is also only a limited set of ARLs).
If <code>roundK=TRUE</code>, integer multiples of 0.5 are avoided when
rounding the reference value <code>k</code>, 
i.e. the CUSUM can take more values.</p>
</td></tr>
<tr><td><code id="findK_+3A_...">...</code></td>
<td>

<p>further arguments for the distribution function, i.e. number of
trials <code>n</code> for the binomial CDF.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns reference value <code>k</code>.
</p>

<hr>
<h2 id='fluBYBW'>Influenza in Southern Germany</h2><span id='topic+fluBYBW'></span>

<h3>Description</h3>

<p>Weekly number of influenza A &amp; B cases in the 140 districts
of the two Southern German states Bavaria and Baden-Wuerttemberg,
for the years 2001 to 2008. These surveillance data have been
analyzed originally by Paul and Held (2011) and more recently by
Meyer and Held (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fluBYBW)</code></pre>


<h3>Format</h3>

<p>An <code><a href="#topic+sts-class">sts</a></code> object containing <code class="reqn">416\times 140</code>
observations starting from week 1 in 2001.
</p>
<p>The <code>population</code> slot contains the population fractions
of each district at 31.12.2001, obtained from the Federal Statistical
Office of Germany.
</p>
<p>The <code>map</code> slot contains an object of class
<code>"<a href="sp.html#topic+SpatialPolygonsDataFrame-class">SpatialPolygonsDataFrame</a>"</code>.
</p>


<h3>Note</h3>

<p>Prior to <span class="pkg">surveillance</span> version 1.6-0, <code>data(fluBYBW)</code>
contained a redundant last row (417) filled with zeroes only.
</p>


<h3>Source</h3>

<p>Robert Koch-Institut: SurvStat: <a href="https://survstat.rki.de/">https://survstat.rki.de/</a>;
Queried on 6 March 2009.
</p>


<h3>References</h3>

<p>Paul, M. and Held, L. (2011) Predictive assessment of a non-linear
random  effects model for multivariate time series of infectious
disease counts. Statistics in Medicine, <b>30</b>, 1118-1136.
</p>
<p>Meyer, S. and Held, L. (2014):
Power-law models for infectious disease spread.
<em>The Annals of Applied Statistics</em>, <b>8</b> (3), 1612-1639.
<a href="https://doi.org/10.1214/14-AOAS743">doi:10.1214/14-AOAS743</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("fluBYBW")

# Count time series plot
plot(fluBYBW, type = observed ~ time)

# Map of disease incidence (per 100000 inhabitants) for the year 2001
plot(fluBYBW, type = observed ~ unit, tps = 1:52, total.args = list(),
     population = fluBYBW@map$X31_12_01 / 100000)
# the overall rate for 2001 shown in the bottom right corner is
sum(observed(fluBYBW[1:52,])) / sum(fluBYBW@map$X31_12_01) * 100000

## Not run: 
# Generating an animation takes a while.
# Here we take the first 20 weeks of 2001 (runtime: ~3 minutes).
# The full animation is available in Supplement A of Meyer and Held (2014)
if (require("animation")) {
    oldwd &lt;- setwd(tempdir())  # to not clutter up the current working dir
    saveHTML(animate(fluBYBW, tps = 1:20),
             title="Evolution of influenza in Bayern and Baden-Wuerttemberg",
             ani.width=500, ani.height=600)
    setwd(oldwd)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='formatDate'>
Convert Dates to Character (Including Quarter Strings)
</h2><span id='topic+formatDate'></span>

<h3>Description</h3>

<p>An extension of <code><a href="base.html#topic+format.Date">format.Date</a></code> with additional formatting
strings for quarters. Used by <code><a href="#topic+linelist2sts">linelist2sts</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatDate(x, format)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formatDate_+3A_x">x</code></td>
<td>
<p>a <code>"<a href="base.html#topic+Date">Date</a>"</code> object.</p>
</td></tr>
<tr><td><code id="formatDate_+3A_format">format</code></td>
<td>

<p>a character string, see <code><a href="base.html#topic+strftime">strftime</a></code> for possible
specifications. Further to these base formats, <code>formatDate</code>
implements:
</p>

<dl>
<dt><code>"%Q"</code></dt><dd><p>the quarter as a numeric</p>
</dd>
<dt><code>"%OQ"</code></dt><dd><p>the quarter as a roman numeral</p>
</dd>
<dt><code>"%q"</code></dt><dd><p>the day within the quarter</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Value</h3>

<p>a character vector representing the input date(s) <code>x</code>
following the <code>format</code> specification.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strftime">strftime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>formatDate(as.Date("2021-10-13"), "%G/%OQ/%q")
</code></pre>

<hr>
<h2 id='formatPval'>
Pretty p-Value Formatting
</h2><span id='topic+formatPval'></span>

<h3>Description</h3>

<p>Just <abbr><span class="acronym">yapf</span></abbr> &ndash; yet another p-value formatter...
</p>
<p>It is a wrapper around <code><a href="base.html#topic+format.pval">format.pval</a></code>,
such that by default <code>eps = 1e-4</code>, <code>scientific = FALSE</code>,
<code>digits = if (p&lt;10*eps) 1 else 2</code>, and <code>nsmall = 2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatPval(pv, eps = 1e-4, scientific = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formatPval_+3A_pv">pv</code></td>
<td>
<p>a numeric vector (of p-values).</p>
</td></tr>
<tr><td><code id="formatPval_+3A_eps">eps</code></td>
<td>
<p>a numerical tolerance, see <code><a href="base.html#topic+format.pval">format.pval</a></code>.</p>
</td></tr>
<tr><td><code id="formatPval_+3A_scientific">scientific</code></td>
<td>
<p>see <code><a href="base.html#topic+format">format</a></code>.</p>
</td></tr>
<tr><td><code id="formatPval_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="base.html#topic+format.pval">format.pval</a></code>
(but <code>digits</code> and <code>nsmall</code> are hard-coded internally).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The character vector of formatted p-values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>formatPval(c(0.9, 0.13567, 0.0432, 0.000546, 1e-8))
</code></pre>

<hr>
<h2 id='glm_epidataCS'>
Fit an Endemic-Only <code>twinstim</code> as a Poisson-<code>glm</code>
</h2><span id='topic+glm_epidataCS'></span>

<h3>Description</h3>

<p>An endemic-only <code><a href="#topic+twinstim">twinstim</a></code> is equivalent to a Poisson
regression model for the aggregated number of events,
<code class="reqn">Y_{[t][\bm{s}],k}</code>, by time-space-type cell. The rate of the
corresponding Poisson distribution is
<code class="reqn">e_{[t][\bm{s}]} \cdot \lambda([t],[\bm{s}],k)</code>,
where <code class="reqn">e_{[t][\bm{s}]} = |[t]| |[\bm{s}]|</code> is a multiplicative
offset. Thus, the <code><a href="stats.html#topic+glm">glm</a></code> function can be used to fit
an endemic-only <code>twinstim</code>. However, wrapping in <code>glm</code> is
usually slower. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm_epidataCS(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glm_epidataCS_+3A_formula">formula</code></td>
<td>

<p>an endemic model formula without response, comprising variables of
<code>data$stgrid</code> and possibly the variable <code>type</code> for a
type-specific model.
</p>
</td></tr>
<tr><td><code id="glm_epidataCS_+3A_data">data</code></td>
<td>

<p>an object of class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>.
</p>
</td></tr>
<tr><td><code id="glm_epidataCS_+3A_...">...</code></td>
<td>

<p>arguments passed to <code><a href="stats.html#topic+glm">glm</a></code>. Note that <code>family</code> and
<code>offset</code> are fixed internally.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi", "imdepifit")

## Fit an endemic-only twinstim() and an equivalent model wrapped in glm()
fit_twinstim &lt;- update(imdepifit, epidemic = ~0, siaf = NULL, subset = NULL,
                       optim.args=list(control=list(trace=0)), verbose=FALSE)
fit_glm &lt;- glm_epidataCS(formula(fit_twinstim)$endemic, data = imdepi)

## Compare the coefficients
cbind(twinstim = coef(fit_twinstim), glm = coef(fit_glm))


### also compare to an equivalent endemic-only hhh4() fit

## first need to aggregate imdepi into an "sts" object
load(system.file("shapes", "districtsD.RData", package="surveillance"))
imdsts &lt;- epidataCS2sts(imdepi, freq = 12, start = c(2002, 1),
                        neighbourhood = NULL, tiles = districtsD,
                        popcol.stgrid = "popdensity")

## determine the correct offset to get an equivalent model
offset &lt;- 2 * rep(with(subset(imdepi$stgrid, !duplicated(BLOCK)),
                  stop - start), ncol(imdsts)) *
          sum(districtsD$POPULATION) * population(imdsts)

## fit the model using hhh4()
fit_hhh4 &lt;- hhh4(imdsts, control = list(
    end = list(
        f = addSeason2formula(~I(start/365-3.5), period=365, timevar="start"),
        offset = offset
    ), family = "Poisson", subset = 1:nrow(imdsts),
    data = list(start=with(subset(imdepi$stgrid, !duplicated(BLOCK)), start))))

summary(fit_hhh4)
stopifnot(all.equal(coef(fit_hhh4), coef(fit_glm), check.attributes=FALSE))
</code></pre>

<hr>
<h2 id='ha'>Hepatitis A in Berlin</h2><span id='topic+ha'></span><span id='topic+ha.sts'></span>

<h3>Description</h3>

<p>Number of Hepatitis A cases among adult (age&gt;18) males in
Berlin, 2001-2006. An increase is seen during 2006.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ha")
data("ha.sts")
</code></pre>


<h3>Format</h3>

<p><code>ha</code> is a <code>disProg</code> object containing <code class="reqn">290\times 12</code>
observations starting from week 1 in 2001 to week 30 in 2006.
<code>ha.sts</code> was generated from <code>ha</code> via the converter function
<code><a href="#topic+disProg2sts">disProg2sts</a></code> and includes a map of Berlin's districts.
</p>


<h3>Source</h3>

<p>Robert Koch-Institut: SurvStat: <a href="https://survstat.rki.de/">https://survstat.rki.de/</a>;
Queried on 25 August 2006.
</p>
<p>Robert Koch Institut, Epidemiologisches Bulletin 33/2006, p.290.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## deprecated "disProg" object
data("ha")
ha
plot(aggregate(ha))

## new-style "sts" object
data("ha.sts")
ha.sts
plot(ha.sts, type = observed ~ time)  # = plot(aggregate(ha.sts, by = "unit"))
plot(ha.sts, type = observed ~ unit, labels = TRUE)
</code></pre>

<hr>
<h2 id='hagelloch'>1861 Measles Epidemic in the City of Hagelloch, Germany</h2><span id='topic+hagelloch'></span><span id='topic+hagelloch.df'></span>

<h3>Description</h3>

<p>Data on the 188 cases in the measles outbreak among children in the
German city of Hagelloch (near Tübingen) 1861. The data were
originally collected by Dr. Albert Pfeilsticker (1863) and augmented and
re-analysed by Dr. Heike Oesterle (1992).
This dataset is used to illustrate the <code>twinSIR</code> model class in
<code>vignette("twinSIR")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("hagelloch")
</code></pre>


<h3>Format</h3>

<p>Loading <code>data("hagelloch")</code> gives two objects:
<code>hagelloch</code> and <code>hagelloch.df</code>.
The latter is the original <code>data.frame</code> of 188 rows
with individual information for each infected child.
<code>hagelloch</code> has been generated from <code>hagelloch.df</code>
via <code><a href="#topic+as.epidata">as.epidata</a></code> (see the Examples below) to obtain an
<code>"epidata"</code> object for use with <code><a href="#topic+twinSIR">twinSIR</a></code>.
It contains the entire SIR event history of the outbreak
(but not all of the covariates).
</p>
<p>The covariate information in <code>hagelloch.df</code> is as follows:
</p>

<dl>
<dt>PN:</dt><dd><p>patient number</p>
</dd>
<dt>NAME:</dt><dd><p>patient name (as a factor)</p>
</dd>
<dt>FN:</dt><dd><p>family index</p>
</dd>
<dt>HN:</dt><dd><p>house number</p>
</dd>
<dt>AGE:</dt><dd><p>age in years</p>
</dd>
<dt>SEX:</dt><dd><p>gender of the individual (factor: male, female)</p>
</dd>
<dt>PRO:</dt><dd><p><code>Date</code> of prodromes</p>
</dd>
<dt>ERU:</dt><dd><p><code>Date</code> of rash</p>
</dd>
<dt>CL:</dt><dd><p>class (factor: preschool, 1st class, 2nd class)</p>
</dd>
<dt>DEAD:</dt><dd><p><code>Date</code> of death (with missings)</p>
</dd>
<dt>IFTO:</dt><dd><p>number of patient who is the putative source of infection (0 = unknown)</p>
</dd>
<dt>SI:</dt><dd><p>serial interval = number of days between dates of prodromes of infection source and infected person</p>
</dd>
<dt>C:</dt><dd><p>complications (factor: no complications, bronchopneumonia, severe bronchitis, lobar pneumonia, pseudocroup, cerebral edema)</p>
</dd>
<dt>PR:</dt><dd><p>duration of prodromes in days</p>
</dd>
<dt>CA:</dt><dd><p>number of cases in family</p>
</dd>
<dt>NI:</dt><dd><p>number of initial cases</p>
</dd>
<dt>GE:</dt><dd><p>generation number of the case</p>
</dd>
<dt>TD:</dt><dd><p>day of max. fever (days after rush)</p>
</dd>
<dt>TM:</dt><dd><p>max. fever (degree Celsius)</p>
</dd>
<dt>x.loc:</dt><dd><p>x coordinate of house (in meters). Scaling in metres
is obtained by multiplying the original coordinates by 2.5 (see details
in Neal and Roberts (2004))</p>
</dd>
<dt>y.loc:</dt><dd><p>y coordinate of house (in meters). See also the above
description of <code>x.loc</code>.</p>
</dd>
<dt>tPRO:</dt><dd><p>Time of prodromes (first symptoms) in days after the start of the
epidemic (30 Oct 1861).</p>
</dd>
<dt>tERU:</dt><dd><p>Time upon which the rash first appears.</p>
</dd>
<dt>tDEAD:</dt><dd><p>Time of death, if available.</p>
</dd>
<dt>tR:</dt><dd><p>Time at which the infectious period of the individual is
assumed to end. This unknown time is calculated as
</p>
<p style="text-align: center;"><code class="reqn">tR_i = \min(tDEAD_i, tERU_i+d_0),</code>
</p>

<p>where &ndash; as in Section 3.1 of Neal and Roberts (2004) &ndash; we use
<code class="reqn">d_0=3</code>.</p>
</dd>
<dt>tI:</dt><dd><p>Time at which the individual is assumed to become
infectious. Actually this time is unknown, but we use
</p>
<p style="text-align: center;"><code class="reqn">tI_i = tPRO_i - d_1,</code>
</p>
 
<p>where <code class="reqn">d_1=1</code> as in Neal and Roberts (2004).</p>
</dd>
</dl>

<p>The time variables describe the transitions of the individual in an
Susceptible-Infectious-Recovered (SIR) model.  Note that in
order to avoid ties in the event times resulting from daily
interval censoring, the times have been jittered uniformly within the
respective day. The time point 0.5 would correspond to noon of 30 Oct 1861.
</p>
<p>The <code>hagelloch</code> <code>"epidata"</code> object only retains some of
the above covariates to save space. Apart from the usual
<code>"epidata"</code> event columns, <code>hagelloch</code> contains a number of
extra variables representing distance- and covariate-based weights for
the force of infection:
</p>

<dl>
<dt>household:</dt><dd><p>the number of currently infectious children in the same
household (including the child itself if it is currently infectious).</p>
</dd>
<dt>nothousehold:</dt><dd><p>the number of currently infectious children
outside the household.</p>
</dd>
<dt>c1, c2:</dt><dd><p>the number of children infectious during the respective
time block and being members of class 1 and 2, respectively; but
the value is 0 if the individual of the row is not herself a
member of the respective class.</p>
</dd>
</dl>

<p>Such epidemic covariates can been computed by specifying suitable
<code>f</code> and <code>w</code> arguments in <code><a href="#topic+as.epidata">as.epidata</a></code> at
conversion (see the code below), or at a later step via the
<code><a href="#topic+update.epidata">update</a></code>-method for <code>"epidata"</code>.
</p>


<h3>Source</h3>

<p>Thanks to Peter J. Neal, University of Manchester, for providing us
with these data, which he again became from Niels Becker, Australian
National University. To cite the data, the main references are Pfeilsticker
(1863) and Oesterle (1992). 
</p>


<h3>References</h3>

<p>Pfeilsticker, A. (1863). Beiträge zur Pathologie der Masern mit
besonderer Berücksichtigung der statistischen Verhältnisse,
M.D. Thesis, Eberhard-Karls-Universität Tübingen.
Available as <a href="https://archive.org/details/beitrgezurpatho00pfeigoog">https://archive.org/details/beitrgezurpatho00pfeigoog</a>.
</p>
<p>Oesterle, H. (1992). Statistische Reanalyse einer Masernepidemie 1861
in Hagelloch, M.D. Thesis, Eberhard-Karls-Universitäat
Tübingen.
</p>
<p>Neal, P. J. and Roberts, G. O (2004). Statistical inference and model
selection for the 1861 Hagelloch measles epidemic, Biostatistics
5(2):249-261
</p>


<h3>See Also</h3>

<p>data class: <code><a href="#topic+epidata">epidata</a></code>
</p>
<p>point process model: <code><a href="#topic+twinSIR">twinSIR</a></code>
</p>
<p>illustration with <code>hagelloch</code>: <code>vignette("twinSIR")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
head(hagelloch.df)   # original data documented in Oesterle (1992)
head(as.data.frame(hagelloch))   # "epidata" event history format

## How the "epidata" 'hagelloch' was created from 'hagelloch.df'
stopifnot(all.equal(hagelloch,
  as.epidata(
    hagelloch.df, t0 = 0, tI.col = "tI", tR.col = "tR",
    id.col = "PN", coords.cols = c("x.loc", "y.loc"),
    f = list(
        household    = function(u) u == 0,
        nothousehold = function(u) u &gt; 0
    ),
    w = list(
        c1 = function (CL.i, CL.j) CL.i == "1st class" &amp; CL.j == CL.i,
        c2 = function (CL.i, CL.j) CL.i == "2nd class" &amp; CL.j == CL.i
    ),
    keep.cols = c("SEX", "AGE", "CL"))
))


### Basic plots produced from hagelloch.df

# Show case locations as in Neal &amp; Roberts (different scaling) using
# the data.frame (promoted to a SpatialPointsDataFrame)
coordinates(hagelloch.df) &lt;- c("x.loc","y.loc")
plot(hagelloch.df, xlab="x [m]", ylab="x [m]", pch=15, axes=TRUE,
     cex=sqrt(multiplicity(hagelloch.df)))

# Epicurve
hist(as.numeric(hagelloch.df$tI), xlab="Time (days)", ylab="Cases", main="")


### "epidata" summary and plot methods

(s &lt;- summary(hagelloch))
head(s$byID)
plot(s)

## Not run: 
  # Show a dynamic illustration of the spread of the infection
  animate(hagelloch, time.spacing=0.1, sleep=1/100,
          legend.opts=list(x="topleft"))

## End(Not run)
</code></pre>

<hr>
<h2 id='hcl.colors'>
HCL-based Heat Colors from the <span class="pkg">colorspace</span> Package
</h2><span id='topic+.hcl.colors'></span>

<h3>Description</h3>

<p>If package <span class="pkg">colorspace</span> is available, its
<a href="colorspace.html#topic+heat_hcl">heat_hcl</a> function is used to generate a color
palette. Otherwise, the similar Heat 2 palette from R's own
<code>hcl.colors</code> are used.
</p>
<p>This function was exported as <code>hcl.colors</code> in <span class="pkg">surveillance</span>
1.14.0 - 1.17.0 but is now internal to avoid a name clash with R 3.6.0
(or later), which introduced a function of that name in the base
package <span class="pkg">grDevices</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.hcl.colors(ncolors = 100, use.color = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hcl.colors_+3A_ncolors">ncolors</code></td>
<td>
<p>the number of colors (&gt;= 1) to be in the palette.</p>
</td></tr>
<tr><td><code id="hcl.colors_+3A_use.color">use.color</code></td>
<td>
<p>logical. Should the palette use colors?
Otherwise grey levels are returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of <code>ncolors</code> colors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>barplot(rep(1,10), col = surveillance:::.hcl.colors(10), axes = FALSE)
</code></pre>

<hr>
<h2 id='hepatitisA'>Hepatitis A in Germany</h2><span id='topic+hepatitisA'></span>

<h3>Description</h3>

<p>Weekly number of reported hepatitis A infections in Germany 2001-2004. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hepatitisA)</code></pre>


<h3>Format</h3>

<p>A <code>disProg</code> object containing <code class="reqn">208\times 1</code>
observations starting from week 1 in 2001 to week 52 in 2004. 
</p>


<h3>Source</h3>

<p>Robert Koch-Institut: SurvStat: <a href="https://survstat.rki.de/">https://survstat.rki.de/</a>;
Queried on 11-01-2005.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hepatitisA)
plot(hepatitisA)
</code></pre>

<hr>
<h2 id='hhh4'>Fitting HHH Models with Random Effects and Neighbourhood Structure</h2><span id='topic+hhh4'></span>

<h3>Description</h3>

<p>Fits an autoregressive Poisson or negative binomial model
to a univariate or multivariate time series of counts.
The characteristic feature of <code>hhh4</code> models is the additive
decomposition of the conditional mean into <em>epidemic</em> and
<em>endemic</em> components (Held et al, 2005).
Log-linear predictors of covariates and random intercepts are allowed
in all components; see the Details below.
A general introduction to the <code>hhh4</code> modelling approach and its
implementation is given in the <code>vignette("hhh4")</code>. Meyer et al
(2017, Section 5, available as <code>vignette("hhh4_spacetime")</code>)
describe <code>hhh4</code> models for areal time series of infectious
disease counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hhh4(stsObj,
     control = list(
         ar = list(f = ~ -1, offset = 1, lag = 1),
         ne = list(f = ~ -1, offset = 1, lag = 1,
                   weights = neighbourhood(stsObj) == 1,
                   scale = NULL, normalize = FALSE),
         end = list(f = ~ 1, offset = 1),
         family = c("Poisson", "NegBin1", "NegBinM"),
         subset = 2:nrow(stsObj),
         optimizer = list(stop = list(tol=1e-5, niter=100),
                          regression = list(method="nlminb"),
                          variance = list(method="nlminb")),
         verbose = FALSE,
         start = list(fixed=NULL, random=NULL, sd.corr=NULL),
         data = list(t = stsObj@epoch - min(stsObj@epoch)),
         keep.terms = FALSE
     ),
     check.analyticals = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_+3A_stsobj">stsObj</code></td>
<td>
<p>object of class <code>"<a href="#topic+sts-class">sts</a>"</code> containing the (multivariate)
count data time series.</p>
</td></tr>
<tr><td><code id="hhh4_+3A_control">control</code></td>
<td>
<p>a list containing the model specification and control arguments:
</p>

<dl>
<dt><code>ar</code></dt><dd><p>Model for the autoregressive component given as
list with the following components: 
</p>

<dl>
<dt>f = ~ -1</dt><dd><p>a formula specifying <code class="reqn">\log(\lambda_{it})</code></p>
</dd>
<dt>offset = 1</dt><dd><p>optional multiplicative offset, either 1 or
a matrix of the same dimension as <code>observed(stsObj)</code></p>
</dd>
<dt>lag = 1</dt><dd><p>a positive integer meaning autoregression on
<code class="reqn">y_{i,t-lag}</code></p>
</dd>
</dl>

</dd>
<dt><code>ne</code></dt><dd><p>Model for the neighbour-driven component given as
list with the following components:
</p>

<dl>
<dt>f = ~ -1</dt><dd><p>a formula specifying <code class="reqn">\log(\phi_{it})</code></p>
</dd>
<dt>offset = 1</dt><dd><p>optional multiplicative offset, either 1 or
a matrix of the same dimension as <code>observed(stsObj)</code></p>
</dd>
<dt>lag = 1</dt><dd><p>a non-negative integer meaning dependency on
<code class="reqn">y_{j,t-lag}</code></p>
</dd>
<dt>weights = neighbourhood(stsObj) == 1</dt><dd>
<p>neighbourhood weights <code class="reqn">w_{ji}</code>. The default
corresponds to the original formulation by Held et al
(2005), i.e., the spatio-temporal component incorporates an
unweighted sum over the lagged cases of the first-order
neighbours. See Paul et al (2008) and Meyer and Held (2014)
for alternative specifications, e.g.,
<code><a href="#topic+W_powerlaw">W_powerlaw</a></code>.
Time-varying weights are possible by specifying an
array of <code>dim()</code> <code>c(nUnits, nUnits, nTime)</code>, where
<code>nUnits=ncol(stsObj)</code> and <code>nTime=nrow(stsObj)</code>.</p>
</dd>
<dt>scale = NULL</dt><dd>
<p>optional matrix of the same dimensions as <code>weights</code> (or
a vector of length <code>ncol(stsObj)</code>) to scale the
<code>weights</code> to <code>scale * weights</code>.
</p>
</dd>
<dt>normalize = FALSE</dt><dd>
<p>logical indicating if the (scaled) <code>weights</code> should be
normalized such that each row sums to 1.
</p>
</dd>
</dl>

</dd>
<dt><code>end</code></dt><dd><p>Model for the endemic component given as list
with the following components
</p>

<dl>
<dt>f = ~ 1</dt><dd><p>a formula specifying <code class="reqn">\log(\nu_{it})</code></p>
</dd>
<dt>offset = 1</dt><dd><p>optional multiplicative offset <code class="reqn">e_{it}</code>,
either 1 or a matrix of the same dimension as <code>observed(stsObj)</code></p>
</dd>
</dl>

</dd>
<dt><code>family</code></dt><dd><p>Distributional family &ndash; either <code>"Poisson"</code>,
or the Negative Binomial distribution. For the latter, the
overdispersion parameter can be assumed to be the same for all
units (<code>"NegBin1"</code>), to vary freely over all units
(<code>"NegBinM"</code>), or to be shared by some units (specified by
a factor of length <code>ncol(stsObj)</code> such that its number of
levels determines the number of overdispersion parameters).
Note that <code>"NegBinM"</code> is equivalent to
<code>factor(colnames(stsObj), levels = colnames(stsObj))</code>.
</p>
</dd>
<dt><code>subset</code></dt><dd><p>Typically <code>2:nrow(obs)</code> if model contains
autoregression</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>a list of three lists of control arguments.
</p>
<p>The <code>"stop"</code> list specifies two criteria for the outer
optimization of regression and variance parameters: the relative
<code>tol</code>erance for parameter change using the criterion 
<code>max(abs(x[i+1]-x[i])) / max(abs(x[i]))</code>,
and the maximum number <code>niter</code> of outer iterations.
</p>
<p>Control arguments for the single optimizers are specified in the
lists named <code>"regression"</code> and <code>"variance"</code>.
<code>method="nlminb"</code> is the default optimizer for both (taking
advantage of the analytical Fisher information matrices), however,
the <code>method</code>s from <code><a href="stats.html#topic+optim">optim</a></code> may also be specified
(as well as <code>"<a href="stats.html#topic+nlm">nlm</a>"</code> but that one is not recommended here).
Especially for the variance updates, Nelder-Mead optimization
(<code>method="Nelder-Mead"</code>) is an attractive alternative.
All other elements of these two lists are passed as
<code>control</code> arguments to the chosen <code>method</code>, e.g., if
<code>method="nlminb"</code>, adding <code>iter.max=50</code> increases the 
maximum number of inner iterations from 20 (default) to 50.
For <code>method="Nelder-Mead"</code>, the respective argument is
called <code>maxit</code> and defaults to 500.
</p>
</dd>
<dt><code>verbose</code></dt><dd><p>non-negative integer (usually in the range
<code>0:3</code>) specifying the amount of tracing information to be
output during optimization.</p>
</dd>
<dt><code>start</code></dt><dd><p>a list of initial parameter values replacing
initial values set via <code><a href="#topic+fe">fe</a></code> and <code><a href="#topic+ri">ri</a></code>.
Since <span class="pkg">surveillance</span> 1.8-2, named vectors are matched
against the coefficient names in the model (where unmatched
start values are silently ignored), and need not be complete,
e.g., <code>start = list(fixed = c("-log(overdisp)" = 0.5))</code>
(default: 2) for a <code>family = "NegBin1"</code> model.
In contrast, an unnamed start vector must specify the full set
of parameters as used by the model.</p>
</dd>
<dt><code>data</code></dt><dd><p>a named list of covariates that are to be
included as fixed effects (see <code><a href="#topic+fe">fe</a></code>) in any of the 3
component formulae.
By default, the time variable <code>t</code> is available and used for
seasonal effects created by <code><a href="#topic+addSeason2formula">addSeason2formula</a></code>.
In general, covariates in this list can be either vectors of
length <code>nrow(stsObj)</code> interpreted as time-varying but
common across all units, or matrices of the same dimension as
the disease counts <code>observed(stsObj)</code>.</p>
</dd>
<dt><code>keep.terms</code></dt><dd><p>logical indicating if the terms object
used in the fit is to be kept as part of the returned object.
This is usually not necessary, since the terms object is
reconstructed by the <code><a href="stats.html#topic+terms">terms</a></code>-method for class
<code>"hhh4"</code> if necessary (based on <code>stsObj</code> and
<code>control</code>, which are both part of the returned
<code>"hhh4"</code> object).</p>
</dd>
</dl>

<p>The auxiliary function <code><a href="#topic+makeControl">makeControl</a></code> might be useful to
create such a list of control parameters.
</p>
</td></tr>
<tr><td><code id="hhh4_+3A_check.analyticals">check.analyticals</code></td>
<td>
<p>logical (or a subset of
<code>c("numDeriv", "maxLik")</code>), indicating if (how) the implemented
analytical score vector and Fisher information matrix should be
checked against numerical derivatives at the parameter starting values,
using the packages <span class="pkg">numDeriv</span> and/or <span class="pkg">maxLik</span>. If activated,
<code>hhh4</code> will return a list containing the analytical and numerical
derivatives for comparison (no ML estimation will be performed). 
This is mainly intended for internal use by the package developers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An endemic-epidemic multivariate time-series model for infectious
disease counts <code class="reqn">Y_{it}</code> from units <code class="reqn">i=1,\dots,I</code> during
periods <code class="reqn">t=1,\dots,T</code> was proposed by Held et al (2005) and was
later extended in a series of papers (Paul et al, 2008; Paul and Held,
2011; Held and Paul, 2012; Meyer and Held, 2014).
In its most general formulation, this so-called <code>hhh4</code> (or HHH or
<code class="reqn">H^3</code> or triple-H) model assumes that, conditional on past
observations, <code class="reqn">Y_{it}</code> has a Poisson or negative binomial
distribution with mean
</p>
<p style="text-align: center;"><code class="reqn">\mu_{it} = \lambda_{it} y_{i,t-1} + 
                   \phi_{it} \sum_{j\neq i} w_{ji} y_{j,t-1} +
                   e_{it} \nu_{it}  </code>
</p>

<p>In the case of a negative binomial model, the conditional 
variance is <code class="reqn">\mu_{it}(1+\psi_i\mu_{it})</code> 
with overdispersion parameters <code class="reqn">\psi_i &gt; 0</code> (possibly shared
across different units, e.g., <code class="reqn">\psi_i\equiv\psi</code>).
Univariate time series of counts <code class="reqn">Y_t</code> are supported as well, in
which case <code>hhh4</code> can be regarded as an extension of
<code><a href="MASS.html#topic+glm.nb">glm.nb</a></code> to account for autoregression.
See the Examples below for a comparison of an endemic-only
<code>hhh4</code> model with a corresponding <code>glm.nb</code>.
</p>
<p>The three unknown quantities of the mean <code class="reqn">\mu_{it}</code>,
</p>

<ul>
<li> <p><code class="reqn">\lambda_{it}</code> in the autoregressive (<code>ar</code>) component, 
</p>
</li>
<li> <p><code class="reqn">\phi_{it}</code> in the neighbour-driven (<code>ne</code>) component, and
</p>
</li>
<li> <p><code class="reqn">\nu_{it}</code> in the endemic (<code>end</code>) component,
</p>
</li></ul>

<p>are log-linear predictors incorporating time-/unit-specific
covariates. They may also contain unit-specific random intercepts
as proposed by Paul and Held (2011). The endemic mean is usually
modelled proportional to a unit-specific offset <code class="reqn">e_{it}</code>
(e.g., population numbers or fractions); it is possible to include
such multiplicative offsets in the epidemic components as well.
The <code class="reqn">w_{ji}</code> are transmission weights reflecting the flow of
infections from unit <code class="reqn">j</code> to unit <code class="reqn">i</code>. If weights vary over time
(prespecified as a 3-dimensional array <code class="reqn">(w_{jit})</code>), the
<code>ne</code> sum in the mean uses <code class="reqn">w_{jit} y_{j,t-1}</code>.
In spatial <code>hhh4</code> applications, the &ldquo;units&rdquo; refer to
geographical regions and the weights could be derived from movement
network data. Alternatively, the weights <code class="reqn">w_{ji}</code> can be
estimated parametrically as a function of adjacency order (Meyer and
Held, 2014), see <code><a href="#topic+W_powerlaw">W_powerlaw</a></code>.
</p>
<p>(Penalized) Likelihood inference for such <code>hhh4</code> models has been
established by Paul and Held (2011) with extensions for parametric
neighbourhood weights by Meyer and Held (2014).
Supplied with the analytical score function and Fisher information,
the function <code>hhh4</code> by default uses the quasi-Newton algorithm
available through <code><a href="stats.html#topic+nlminb">nlminb</a></code> to maximize the log-likelihood.
Convergence is usually fast even for a large number of parameters.
If the model contains random effects, the penalized and marginal
log-likelihoods are maximized alternately until convergence.
</p>


<h3>Value</h3>

<p><code>hhh4</code> returns an object of class <code>"hhh4"</code>,
which is a list containing the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>named vector with estimated (regression) parameters of the model</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>estimated standard errors (for regression parameters)</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>covariance matrix (for regression parameters)</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>estimated variance-covariance matrix of random effects</p>
</td></tr>
<tr><td><code>Sigma.orig</code></td>
<td>
<p>estimated variance parameters on internal scale used
for optimization</p>
</td></tr>
<tr><td><code>Sigma.cov</code></td>
<td>
<p>inverse of marginal Fisher information (on internal
scale), i.e., the asymptotic covariance matrix of <code>Sigma.orig</code></p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p> the matched call </p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p> vector with number of fixed and random effects in the model </p>
</td></tr>
<tr><td><code>loglikelihood</code></td>
<td>
<p>(penalized) loglikelihood evaluated at the MLE</p>
</td></tr>
<tr><td><code>margll</code></td>
<td>
<p> (approximate) log marginal likelihood should the model contain random effects  </p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>logical. Did optimizer converge?</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>fitted mean values <code class="reqn">\mu_{i,t}</code></p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>control object of the fit</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the terms object used in the fit if <code>keep.terms = TRUE</code>
and <code>NULL</code> otherwise</p>
</td></tr>
<tr><td><code>stsObj</code></td>
<td>
<p> the supplied <code>stsObj</code> </p>
</td></tr>
<tr><td><code>lags</code></td>
<td>
<p>named integer vector of length two containing the lags
used for the epidemic components <code>"ar"</code> and <code>"ne"</code>,
respectively. The corresponding lag is <code>NA</code> if the component
was not included in the model.</p>
</td></tr>
<tr><td><code>nObs</code></td>
<td>
<p>number of observations used for fitting the model</p>
</td></tr>
<tr><td><code>nTime</code></td>
<td>
<p> number of time points used for fitting the model </p>
</td></tr>
<tr><td><code>nUnit</code></td>
<td>
<p> number of units (e.g. areas) used for fitting the model</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>
<p>the <code><a href="base.html#topic+proc.time">proc.time</a></code>-queried time taken
to fit the model, i.e., a named numeric vector of length 5 of class
<code>"proc_time"</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michaela Paul, Sebastian Meyer, Leonhard Held</p>


<h3>References</h3>

<p>Held, L., Höhle, M. and Hofmann, M. (2005):
A statistical framework for the analysis of multivariate infectious
disease surveillance counts.
<em>Statistical Modelling</em>, <b>5</b> (3), 187-199.
<a href="https://doi.org/10.1191/1471082X05st098oa">doi:10.1191/1471082X05st098oa</a>
</p>
<p>Paul, M., Held, L. and Toschke, A. M. (2008):
Multivariate modelling of infectious disease surveillance data.
<em>Statistics in Medicine</em>, <b>27</b> (29), 6250-6267.
<a href="https://doi.org/10.1002/sim.4177">doi:10.1002/sim.4177</a>
</p>
<p>Paul, M. and Held, L. (2011):
Predictive assessment of a non-linear random effects model for
multivariate time series of infectious disease counts.
<em>Statistics in Medicine</em>, <b>30</b> (10), 1118-1136.
<a href="https://doi.org/10.1002/sim.4177">doi:10.1002/sim.4177</a>
</p>
<p>Held, L. and Paul, M. (2012):
Modeling seasonality in space-time infectious disease surveillance data.
<em>Biometrical Journal</em>, <b>54</b> (6), 824-843.
<a href="https://doi.org/10.1002/bimj.201200037">doi:10.1002/bimj.201200037</a>
</p>
<p>Meyer, S. and Held, L. (2014):
Power-law models for infectious disease spread.
<em>The Annals of Applied Statistics</em>, <b>8</b> (3), 1612-1639.
<a href="https://doi.org/10.1214/14-AOAS743">doi:10.1214/14-AOAS743</a>
</p>
<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p>See the special functions <code><a href="#topic+fe">fe</a></code>, <code><a href="#topic+ri">ri</a></code> and the
examples below for how to specify unit-specific effects.
</p>
<p>Further details on the modelling approach and illustrations of its
implementation can be found in <code>vignette("hhh4")</code> and
<code>vignette("hhh4_spacetime")</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######################
## Univariate examples
######################

### weekly counts of salmonella agona cases, UK, 1990-1995

data("salmonella.agona")
## convert old "disProg" to new "sts" data class
salmonella &lt;- disProg2sts(salmonella.agona)
salmonella
plot(salmonella)

## generate formula for an (endemic) time trend and seasonality
f.end &lt;- addSeason2formula(f = ~1 + t, S = 1, period = 52)
f.end
## specify a simple autoregressive negative binomial model
model1 &lt;- list(ar = list(f = ~1), end = list(f = f.end), family = "NegBin1")
## fit this model to the data
res &lt;- hhh4(salmonella, model1)
## summarize the model fit
summary(res, idx2Exp=1, amplitudeShift=TRUE, maxEV=TRUE)
plot(res)
plot(res, type = "season", components = "end")


### weekly counts of meningococcal infections, Germany, 2001-2006

data("influMen")
fluMen &lt;- disProg2sts(influMen)
meningo &lt;- fluMen[, "meningococcus"]
meningo
plot(meningo)

## again a simple autoregressive NegBin model with endemic seasonality
meningoFit &lt;- hhh4(stsObj = meningo, control = list(
    ar = list(f = ~1),
    end = list(f = addSeason2formula(f = ~1, S = 1, period = 52)),
    family = "NegBin1"
))

summary(meningoFit, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)
plot(meningoFit)
plot(meningoFit, type = "season", components = "end")


########################
## Multivariate examples
########################

### bivariate analysis of influenza and meningococcal infections
### (see Paul et al, 2008)

plot(fluMen, same.scale = FALSE)
     
## Fit a negative binomial model with
## - autoregressive component: disease-specific intercepts
## - neighbour-driven component: only transmission from flu to men
## - endemic component: S=3 and S=1 sine/cosine pairs for flu and men, respectively
## - disease-specific overdispersion

WfluMen &lt;- neighbourhood(fluMen)
WfluMen["meningococcus","influenza"] &lt;- 0
WfluMen
f.end_fluMen &lt;- addSeason2formula(f = ~ -1 + fe(1, which = c(TRUE, TRUE)),
                                  S = c(3, 1), period = 52)
f.end_fluMen
fluMenFit &lt;- hhh4(fluMen, control = list(
    ar = list(f = ~ -1 + fe(1, unitSpecific = TRUE)),
    ne = list(f = ~ 1, weights = WfluMen),
    end = list(f = f.end_fluMen),
    family = "NegBinM"))
summary(fluMenFit, idx2Exp=1:3)
plot(fluMenFit, type = "season", components = "end", unit = 1)
plot(fluMenFit, type = "season", components = "end", unit = 2)



### weekly counts of measles, Weser-Ems region of Lower Saxony, Germany

data("measlesWeserEms")
measlesWeserEms
plot(measlesWeserEms)  # note the two districts with zero cases

## we could fit the same simple model as for the salmonella cases above
model1 &lt;- list(
    ar = list(f = ~1),
    end = list(f = addSeason2formula(~1 + t, period = 52)),
    family = "NegBin1"
)
measlesFit &lt;- hhh4(measlesWeserEms, model1)
summary(measlesFit, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)

## but we should probably at least use a population offset in the endemic
## component to reflect heterogeneous incidence levels of the districts,
## and account for spatial dependence (here just using first-order adjacency)
measlesFit2 &lt;- update(measlesFit,
    end = list(offset = population(measlesWeserEms)),
    ne = list(f = ~1, weights = neighbourhood(measlesWeserEms) == 1))
summary(measlesFit2, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)
plot(measlesFit2, units = NULL, hide0s = TRUE)

## 'measlesFit2' corresponds to the 'measlesFit_basic' model in
## vignette("hhh4_spacetime"). See there for further analyses,
## including vaccination coverage as a covariate,
## spatial power-law weights, and random intercepts.


## Not run: 
### last but not least, a more sophisticated (and time-consuming)
### analysis of weekly counts of influenza from 140 districts in
### Southern Germany (originally analysed by Paul and Held, 2011,
### and revisited by Held and Paul, 2012, and Meyer and Held, 2014)

data("fluBYBW")
plot(fluBYBW, type = observed ~ time)
plot(fluBYBW, type = observed ~ unit,
     ## mean yearly incidence per 100.000 inhabitants (8 years)
     population = fluBYBW@map$X31_12_01 / 100000 * 8)

## For the full set of models for data("fluBYBW") as analysed by
## Paul and Held (2011), including predictive model assessement
## using proper scoring rules, see the (computer-intensive)
## demo("fluBYBW") script:
demoscript &lt;- system.file("demo", "fluBYBW.R", package = "surveillance")
demoscript
#file.show(demoscript)

## Here we fit the improved power-law model of Meyer and Held (2014)
## - autoregressive component: random intercepts + S = 1 sine/cosine pair
## - neighbour-driven component: random intercepts + S = 1 sine/cosine pair
##   + population gravity with normalized power-law weights
## - endemic component: random intercepts + trend + S = 3 sine/cosine pairs
## - random intercepts are iid but correlated between components
f.S1 &lt;- addSeason2formula(
    ~-1 + ri(type="iid", corr="all"),
    S = 1, period = 52)
f.end.S3 &lt;- addSeason2formula(
    ~-1 + ri(type="iid", corr="all") + I((t-208)/100),
    S = 3, period = 52)

## for power-law weights, we need adjaceny orders, which can be
## computed from the binary adjacency indicator matrix
nbOrder1 &lt;- neighbourhood(fluBYBW)
neighbourhood(fluBYBW) &lt;- nbOrder(nbOrder1)

## full model specification
fluModel &lt;- list(
    ar = list(f = f.S1),
    ne = list(f = update.formula(f.S1, ~ . + log(pop)),
              weights = W_powerlaw(maxlag=max(neighbourhood(fluBYBW)),
                                   normalize = TRUE, log = TRUE)),
    end = list(f = f.end.S3, offset = population(fluBYBW)),
    family = "NegBin1", data = list(pop = population(fluBYBW)),
    optimizer = list(variance = list(method = "Nelder-Mead")),
    verbose = TRUE)

## CAVE: random effects considerably increase the runtime of model estimation
## (It is usually advantageous to first fit a model with simple intercepts
## to obtain reasonable start values for the other parameters.)
set.seed(1)  # because random intercepts are initialized randomly
fluFit &lt;- hhh4(fluBYBW, fluModel)

summary(fluFit, idx2Exp = TRUE, amplitudeShift = TRUE)

plot(fluFit, type = "fitted", total = TRUE)

plot(fluFit, type = "season")
range(plot(fluFit, type = "maxEV"))

plot(fluFit, type = "maps", prop = TRUE)

gridExtra::grid.arrange(
    grobs = lapply(c("ar", "ne", "end"), function (comp)
        plot(fluFit, type = "ri", component = comp, main = comp,
             exp = TRUE, sub = "multiplicative effect")),
    nrow = 1, ncol = 3)

plot(fluFit, type = "neweights", xlab = "adjacency order")

## End(Not run)


########################################################################
## An endemic-only "hhh4" model can also be estimated using MASS::glm.nb
########################################################################

## weekly counts of measles, Weser-Ems region of Lower Saxony, Germany
data("measlesWeserEms")

## fit an endemic-only "hhh4" model
## with time covariates and a district-specific offset
hhh4fit &lt;- hhh4(measlesWeserEms, control = list(
    end = list(f = addSeason2formula(~1 + t, period = measlesWeserEms@freq),
               offset = population(measlesWeserEms)),
    ar = list(f = ~-1), ne = list(f = ~-1), family = "NegBin1",
    subset = 1:nrow(measlesWeserEms)
))
summary(hhh4fit)

## fit the same model using MASS::glm.nb
measlesWeserEmsData &lt;- as.data.frame(measlesWeserEms, tidy = TRUE)
measlesWeserEmsData$t &lt;- c(hhh4fit$control$data$t)
glmnbfit &lt;- MASS::glm.nb(
    update(formula(hhh4fit)$end, observed ~ . + offset(log(population))),
    data = measlesWeserEmsData
)
summary(glmnbfit)

## Note that the overdispersion parameter is parametrized inversely.
## The likelihood and point estimates are all the same.
## However, the variance estimates are different: in glm.nb, the parameters
## are estimated conditional on the overdispersion theta.


</code></pre>

<hr>
<h2 id='hhh4_formula'>
Specify Formulae in a Random Effects HHH Model
</h2><span id='topic+fe'></span><span id='topic+ri'></span>

<h3>Description</h3>

<p>The special functions <code>fe</code> and <code>ri</code> are used to specify 
unit-specific effects of covariates and random intercept terms, 
respectively, in the component formulae of <code><a href="#topic+hhh4">hhh4</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fe(x, unitSpecific = FALSE, which = NULL, initial = NULL)

ri(type = c("iid","car"), corr = c("none", "all"),
   initial.fe = 0, initial.var = -.5, initial.re = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_formula_+3A_x">x</code></td>
<td>
<p>an expression like <code>sin(2*pi*t/52)</code> involving the time
variable <code>t</code>, or just <code>1</code> for an intercept.
In general this covariate expression might use any variables
contained in the <code>control$data</code> argument of the parent
<code><a href="#topic+hhh4">hhh4</a></code> call.</p>
</td></tr>
<tr><td><code id="hhh4_formula_+3A_unitspecific">unitSpecific</code></td>
<td>
<p>logical indicating if the effect of <code>x</code>
should be unit-specific. This is a convenient shortcut for
<code>which = rep(TRUE, nUnits)</code>, where <code>nUnits</code> is the number
of units (i.e., columns of the <code>"sts"</code> object).</p>
</td></tr>
<tr><td><code id="hhh4_formula_+3A_which">which</code></td>
<td>
<p>vector of logicals indicating which unit(s)
should get an unit-specific parameter.
For units with a <code>FALSE</code>
value, the effect term for <code>x</code> will be zero in the log-linear
predictor. Note especially that setting a <code>FALSE</code> value for the
intercept term of a unit, e.g.,
<code>ar = list(f = ~-1 + fe(1, which=c(TRUE, FALSE)))</code>
in a bivariate <code>hhh4</code> model, does <em>not</em> mean that the
(autoregressive) model component is omitted for this unit, but that
<code class="reqn">\log(\lambda_1) = \alpha_1</code> and <code class="reqn">\log(\lambda_2) = 0</code>, which
is usually not of interest. ATM, omitting an autoregressive effect for
a specific unit is not possible.<br />
If <code>which=NULL</code>, the parameter is assumed to be the same
for all units.</p>
</td></tr>
<tr><td><code id="hhh4_formula_+3A_initial">initial</code></td>
<td>
<p>initial values (on internal scale!) 
for the fixed effects used for optimization. The default
(<code>NULL</code>) means to use zeroes.</p>
</td></tr>
<tr><td><code id="hhh4_formula_+3A_type">type</code></td>
<td>
<p>random intercepts either follow an IID or a CAR model.</p>
</td></tr>
<tr><td><code id="hhh4_formula_+3A_corr">corr</code></td>
<td>
<p>whether random effects
in different components (such as <code>ar</code> and <code>end</code>)
should be correlated or not.</p>
</td></tr>
<tr><td><code id="hhh4_formula_+3A_initial.fe">initial.fe</code></td>
<td>
<p>initial value for the random intercept mean.</p>
</td></tr>
<tr><td><code id="hhh4_formula_+3A_initial.var">initial.var</code></td>
<td>
<p>initial values (on internal scale!) 
for the variance components used for optimization.</p>
</td></tr>
<tr><td><code id="hhh4_formula_+3A_initial.re">initial.re</code></td>
<td>
<p>initial values (on internal scale!) for the random effects 
used for optimization. The default <code>NULL</code> are random numbers
from a normal distribution with zero mean and variance 0.001.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>These special functions are intended for use in component formulae of
<code>hhh4</code> models and are not exported from the package namespace.
</p>
<p>If unit-specific fixed or random intercepts are specified, an overall
intercept must be excluded (by <code>-1</code>) in the component formula.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+addSeason2formula">addSeason2formula</a></code>
</p>
<p><code>hhh4</code> model specifications in <code>vignette("hhh4")</code>,
<code>vignette("hhh4_spacetime")</code> or on the help page of
<code><a href="#topic+hhh4">hhh4</a></code>.
</p>

<hr>
<h2 id='hhh4_internals'>
Internal Functions Dealing with <code>hhh4</code> Models
</h2><span id='topic+meanHHH'></span><span id='topic+sizeHHH'></span><span id='topic+decompose.hhh4'></span>

<h3>Description</h3>

<p>The functions documented here are considered <em>internal</em>,
i.e., not intended to be called by the user. They are used by
add-on packages dealing with <code><a href="#topic+hhh4">hhh4</a></code> models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanHHH(theta, model, subset = model$subset, total.only = FALSE)
sizeHHH(theta, model, subset = model$subset)

decompose.hhh4(x, coefs = x$coefficients, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_internals_+3A_theta">theta</code>, <code id="hhh4_internals_+3A_coefs">coefs</code></td>
<td>
<p>numeric vector of <em>untransformed</em> model parameters,
i.e., the <code>coefficients</code> element of the <code>"hhh4"</code> object.</p>
</td></tr>
<tr><td><code id="hhh4_internals_+3A_model">model</code></td>
<td>
<p>the model terms as returned by the
<code><a href="stats.html#topic+terms">terms</a></code>-method for <code>"hhh4"</code> objects.</p>
</td></tr>
<tr><td><code id="hhh4_internals_+3A_subset">subset</code></td>
<td>
<p>vector of time points for which to compute the component
means. Defaults to the fitted time range. For <code>sizeHHH</code>,
<code>subset=NULL</code> means to return the vector of dispersion
parameters.</p>
</td></tr>
<tr><td><code id="hhh4_internals_+3A_total.only">total.only</code></td>
<td>
<p>logical. Should only the total mean (epidemic +
endemic) be returned in a <code>length(subset)</code> x nUnit matrix?
Otherwise, a list of such matrices is returned, giving the values of
the various model components separately (as well as the total).</p>
</td></tr>
<tr><td><code id="hhh4_internals_+3A_x">x</code></td>
<td>
<p>a fitted <code>hhh4</code> model.</p>
</td></tr>
<tr><td><code id="hhh4_internals_+3A_...">...</code></td>
<td>
<p>unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>meanHHH</code> computes the components of the mean returned in
<code>length(subset)</code> x nUnit matrices.
<code>sizeHHH</code> computes the model dispersion in <code><a href="stats.html#topic+dnbinom">dnbinom</a></code>
(<code>mu</code>, <code>size</code>) parametrization (it returns <code>NULL</code> in
the Poisson case).
<code>decompose.hhh4</code> decomposes the fitted mean (extracted via
<code>meanHHH</code>) in an array with dimensions <code class="reqn">(t, i, j)</code>, where the
first <code class="reqn">j</code> index is <code>"endemic"</code>.
</p>


<h3>Author(s)</h3>

<p>Michaela Paul and Sebastian Meyer
</p>

<hr>
<h2 id='hhh4_methods'>
Print, Summary and other Standard Methods for <code>"hhh4"</code> Objects
</h2><span id='topic+print.hhh4'></span><span id='topic+summary.hhh4'></span><span id='topic+nobs.hhh4'></span><span id='topic+formula.hhh4'></span><span id='topic+logLik.hhh4'></span><span id='topic+coef.hhh4'></span><span id='topic+vcov.hhh4'></span><span id='topic+fixef.hhh4'></span><span id='topic+ranef.hhh4'></span><span id='topic+coeflist.hhh4'></span><span id='topic+confint.hhh4'></span><span id='topic+residuals.hhh4'></span>

<h3>Description</h3>

<p>Besides <code>print</code> and <code>summary</code> methods there are also some standard
extraction methods defined for objects of class <code>"hhh4"</code> resulting
from a call to <code><a href="#topic+hhh4">hhh4</a></code>.
The implementation is illustrated in Meyer et al. (2017, Section 5),
see <code>vignette("hhh4_spacetime")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hhh4'
print(x, digits = max(3, getOption("digits") - 3), ...)
## S3 method for class 'hhh4'
summary(object, maxEV = FALSE, ...)

## S3 method for class 'hhh4'
coef(object, se = FALSE, reparamPsi = TRUE, 
     idx2Exp = NULL, amplitudeShift = FALSE, ...)
## S3 method for class 'hhh4'
fixef(object, ...)
## S3 method for class 'hhh4'
ranef(object, tomatrix = FALSE, intercept = FALSE, ...)
## S3 method for class 'hhh4'
coeflist(x, ...)

## S3 method for class 'hhh4'
formula(x, ...)
## S3 method for class 'hhh4'
nobs(object, ...)
## S3 method for class 'hhh4'
logLik(object, ...)

## S3 method for class 'hhh4'
vcov(object, reparamPsi = TRUE, 
     idx2Exp = NULL, amplitudeShift = FALSE, ...)
## S3 method for class 'hhh4'
confint(object, parm, level = 0.95, 
        reparamPsi = TRUE, idx2Exp = NULL, amplitudeShift = FALSE, ...)

## S3 method for class 'hhh4'
residuals(object, type = c("deviance", "response"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_methods_+3A_x">x</code>, <code id="hhh4_methods_+3A_object">object</code></td>
<td>
<p>an object of class <code>"hhh4"</code>.</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing
parameter estimates.</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_maxev">maxEV</code></td>
<td>
<p>logical indicating if the summary should contain the
(range of the) dominant eigenvalue as a measure of the importance of
the epidemic components. By default, the value is not calculated as
this may take some seconds depending on the number of time points
and units in <code>object$stsObj</code>.</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_...">...</code></td>
<td>

<p>For the <code>print</code>, <code>summary</code>, <code>fixef</code>, <code>ranef</code>,
and <code>coeflist</code> methods: arguments passed to <code>coef</code>.<br />
For the remaining methods: unused (argument of the generic).
</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_reparampsi">reparamPsi</code></td>
<td>

<p>logical. If <code>TRUE</code> (default), the overdispersion parameter from the 
negative binomial distribution is transformed from internal scale (-log)
to standard scale, where zero corresponds to a Poisson distribution. 
</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_se">se</code></td>
<td>
<p>logical switch indicating if standard errors are required</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_idx2exp">idx2Exp</code></td>
<td>
<p>integer vector selecting the parameters
which should be returned on exp-scale.
Alternatively, <code>idx2Exp = TRUE</code> will exp-transform all
parameters except for those associated with <code>log()</code> covariates
or already affected by <code>reparamPsi</code> or <code>amplitudeShift</code>.</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_amplitudeshift">amplitudeShift</code></td>
<td>
<p>logical switch indicating whether the parameters
for sine/cosine terms modelling seasonal patterns 
(see <code><a href="#topic+addSeason2formula">addSeason2formula</a></code>) should be transformed
to an amplitude/shift formulation.</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_tomatrix">tomatrix</code></td>
<td>
<p>logical. If <code>FALSE</code> (default), the vector of
all random effects is returned (as used internally). However, for
random intercepts of <code>type="car"</code>, the number of parameters is
one less than the number of regions and the individual parameters are
not obviously linked to specific regions. Setting <code>tomatrix</code> to
<code>TRUE</code> returns a more useful representation of random effects
in a matrix with as many rows as there are regions and as many
columns as there are random effects. Here, any CAR-effects are
transformed to region-specific effects.</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_intercept">intercept</code></td>
<td>
<p>logical. If <code>FALSE</code> (default), the returned
random effects represent zero-mean deviations around the
corresponding global intercepts of the <em>log</em>-linear predictors.
Setting <code>intercept=TRUE</code> adds these global intercepts to the
result (and implies <code>tomatrix=TRUE</code>).</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_parm">parm</code></td>
<td>
<p>a vector of numbers or names, specifying which parameters 
are to be given confidence intervals. If missing, all parameters
are considered.</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_level">level</code></td>
<td>
<p>the confidence level required.</p>
</td></tr>
<tr><td><code id="hhh4_methods_+3A_type">type</code></td>
<td>
<p>the type of residuals which should be returned. The
alternatives are <code>"deviance"</code> (default) and <code>"response"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code><a href="stats.html#topic+coef">coef</a></code>-method returns all estimated (regression)
parameters from a <code><a href="#topic+hhh4">hhh4</a></code> model.
If the model includes random effects, those can be extracted with
<code>ranef</code>, whereas <code>fixef</code> returns the fixed parameters.
The <code>coeflist</code>-method extracts the model coefficients in a list
(by parameter group).
</p>
<p>The <code><a href="stats.html#topic+formula">formula</a></code>-method returns the formulae used for the
three log-linear predictors in a list with elements <code>"ar"</code>,
<code>"ne"</code>, and <code>"end"</code>.
The <code><a href="stats.html#topic+nobs">nobs</a></code>-method returns the number of observations used
for model fitting.
The <code><a href="stats.html#topic+logLik">logLik</a></code>-method returns an object of class
<code>"logLik"</code> with <code>"df"</code> and <code>"nobs"</code> attributes.
For a random effects model, the value of the <em>penalized</em>
log-likelihood at the MLE is returned, but degrees of freedom are
not available (<code>NA_real_</code>).
As a consequence, <code><a href="stats.html#topic+AIC">AIC</a></code> and <code><a href="stats.html#topic+BIC">BIC</a></code> are only
well defined for models without random effects;
otherwise these functions return <code>NA_real_</code>.
</p>
<p>The <code><a href="stats.html#topic+vcov">vcov</a></code>-method returns the estimated
variance-covariance matrix of the <em>regression</em> parameters.
The estimated variance-covariance matrix of random effects is
available as <code>object$Sigma</code>.
The <code><a href="stats.html#topic+confint">confint</a></code>-method returns Wald-type confidence
intervals (assuming asymptotic normality).
</p>
<p>The <code><a href="stats.html#topic+residuals">residuals</a></code>-method extracts raw (<code>"response"</code>) or
scaled (<code>"deviance"</code>) residuals from the model fit similar to
<code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code> for Poisson or NegBin GLM's.
</p>


<h3>Author(s)</h3>

<p>Michaela Paul and Sebastian Meyer
</p>


<h3>References</h3>

<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p>the <code><a href="#topic+plot.hhh4">plot</a></code>
and <code><a href="#topic+update.hhh4">update</a></code> methods
for fitted <code>"hhh4"</code> models.
</p>

<hr>
<h2 id='hhh4_plot'>Plots for Fitted <code>hhh4</code>-models</h2><span id='topic+plot.hhh4'></span><span id='topic+plotHHH4_fitted'></span><span id='topic+plotHHH4_fitted1'></span><span id='topic+plotHHH4_season'></span><span id='topic+getMaxEV_season'></span><span id='topic+plotHHH4_maxEV'></span><span id='topic+getMaxEV'></span><span id='topic+plotHHH4_maps'></span><span id='topic+plotHHH4_ri'></span><span id='topic+plotHHH4_neweights'></span>

<h3>Description</h3>

<p>There are six <code>type</code>s of plots for fitted <code><a href="#topic+hhh4">hhh4</a></code> models:
</p>

<ul>
<li><p> Plot the <code>"fitted"</code> component means (of selected units)
along time along with the observed counts.
</p>
</li>
<li><p> Plot the estimated <code>"season"</code>ality of the three components.
</p>
</li>
<li><p> Plot the time-course of the dominant eigenvalue <code>"maxEV"</code>.
</p>
</li>
<li><p> If the units of the corresponding multivariate
<code>"<a href="#topic+sts-class">sts</a>"</code> object represent different regions,
maps of the fitted mean components averaged over time (<code>"maps"</code>),
or a map of estimated region-specific intercepts (<code>"ri"</code>) of a
selected model component can be produced.
</p>
</li>
<li><p> Plot the (estimated) neighbourhood weights
(<code>"neweights"</code>) as a function of neighbourhood order
(shortest-path distance between regions), i.e., <code>w_ji ~ o_ji</code>.
</p>
</li></ul>

<p>Spatio-temporal <code>"hhh4"</code> models and these plots are illustrated in
Meyer et al. (2017, Section 5), see <code>vignette("hhh4_spacetime")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hhh4'
plot(x, type=c("fitted", "season", "maxEV", "maps", "ri", "neweights"), ...)

plotHHH4_fitted(x, units = 1, names = NULL,
                col = c("grey85", "blue", "orange"),
                pch = 19, pt.cex = 0.6, pt.col = 1,
                par.settings = list(),
                legend = TRUE, legend.args = list(),
                legend.observed = FALSE,
                decompose = NULL, total = FALSE, meanHHH = NULL, ...)

plotHHH4_fitted1(x, unit = 1, main = NULL,
                 col = c("grey85", "blue", "orange"),
                 pch = 19, pt.cex = 0.6, pt.col = 1, border = col, 
                 start = x$stsObj@start, end = NULL, xaxis = NULL,
                 xlim = NULL, ylim = NULL, xlab = "", ylab = "No. infected",
                 hide0s = FALSE, decompose = NULL, total = FALSE, meanHHH = NULL)

plotHHH4_season(..., components = NULL, intercept = FALSE,
                xlim = NULL, ylim = NULL,
                xlab = NULL, ylab = "", main = NULL,
                par.settings = list(), matplot.args = list(),
                legend = NULL, legend.args = list(),
                refline.args = list(), unit = 1, period = NULL)
getMaxEV_season(x, period = x$stsObj@freq)

plotHHH4_maxEV(...,
               matplot.args = list(), refline.args = list(),
               legend.args = list())
getMaxEV(x)

plotHHH4_maps(x, which = c("mean", "endemic", "epi.own", "epi.neighbours"),
              prop = FALSE, main = which, zmax = NULL, col.regions = NULL,
              labels = FALSE, sp.layout = NULL, ...,
              map = x$stsObj@map, meanHHH = NULL)

plotHHH4_ri(x, component, exp = FALSE,
            at = list(n = 10), col.regions = cm.colors(100),
            colorkey = TRUE, labels = FALSE, sp.layout = NULL,
            gpar.missing = list(col = "darkgrey", lty = 2, lwd = 2),
            ...)

plotHHH4_neweights(x, plotter = boxplot, ...,
                   exclude = 0, maxlag = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_plot_+3A_x">x</code></td>
<td>
<p>a fitted <code><a href="#topic+hhh4">hhh4</a></code> object.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_type">type</code></td>
<td>
<p>type of plot: either <code>"fitted"</code> component means of
selected <code>units</code> along time along with the observed counts, or
<code>"season"</code>ality plots of the model components and the epidemic
dominant eigenvalue (which may also be plotted along overall time by
<code>type="maxEV"</code>, especially if the model contains time-varying
neighbourhood weights or unit-specific epidemic effects),
or <code>"maps"</code> of the fitted mean components averaged over time,
or a map of estimated region-specific random
intercepts (<code>"ri"</code>) of a specific model <code>component</code>.
The latter two require <code>x$stsObj</code> to contain a map.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_...">...</code></td>
<td>
<p>For <code>plotHHH4_season</code> and <code>plotHHH4_maxEV</code>,
one or more <code><a href="#topic+hhh4">hhh4</a></code>-fits, or a single list of these.
Otherwise further arguments passed on to other functions.<br />
For the <code>plot</code>-method these go to the specific plot
<code>type</code> function.<br />
<code>plotHHH4_fitted</code> passes them to <code>plotHHH4_fitted1</code>, which is called
sequentially for every unit in <code>units</code>.<br />
<code>plotHHH4_maps</code> and <code>plotHHH4_ri</code> pass additional arguments to
<code><a href="sp.html#topic+spplot">spplot</a></code>, and <code>plotHHH4_neweights</code> to the
<code>plotter</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_units">units</code>, <code id="hhh4_plot_+3A_unit">unit</code></td>
<td>
<p>integer or character vector specifying a single
<code>unit</code> or possibly multiple <code>units</code> to plot.
It indexes <code>colnames(x$stsObj)</code>.<br />
In <code>plotHHH4_fitted</code>, <code>units=NULL</code> plots all units.<br />
In the seasonality plot,
selection of a unit is only relevant if the model contains
unit-specific intercepts or seasonality terms.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_names">names</code>, <code id="hhh4_plot_+3A_main">main</code></td>
<td>
<p>main title(s) for the selected
<code>unit</code>(<code>s</code>) / <code>components</code>. If <code>NULL</code> (default),
<code>plotHHH4_fitted1</code> will use the appropriate element of
<code>colnames(x$stsObj)</code>, whereas <code>plotHHH4_season</code> uses
default titles.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_col">col</code>, <code id="hhh4_plot_+3A_border">border</code></td>
<td>
<p>length 3 vectors specifying the fill and border colors for the
endemic, autoregressive, and spatio-temporal component polygons (in
this order).</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_pch">pch</code>, <code id="hhh4_plot_+3A_pt.cex">pt.cex</code>, <code id="hhh4_plot_+3A_pt.col">pt.col</code></td>
<td>
<p>style specifications for the dots drawn to represent
the observed counts. <code>pch=NA</code> can be used to disable these dots.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_par.settings">par.settings</code></td>
<td>
<p>list of graphical parameters for
<code><a href="graphics.html#topic+par">par</a></code>. Sensible defaults for <code>mfrow</code>, <code>mar</code> and
<code>las</code> will be applied unless overridden or
<code>!is.list(par.settings)</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_legend">legend</code></td>
<td>
<p>Integer vector specifying in which of the
<code>length(units)</code> frames the legend should be drawn. If a logical
vector is supplied, <code>which(legend)</code> determines the frame
selection, i.e., the default is to drawn the legend in the first
(upper left) frame only, and <code>legend=FALSE</code> results in no
legend being drawn.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_legend.args">legend.args</code></td>
<td>
<p>list of arguments for <code><a href="graphics.html#topic+legend">legend</a></code>, e.g.,
to modify the default positioning
<code>list(x="topright", inset=0.02)</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_legend.observed">legend.observed</code></td>
<td>
<p>logical indicating if the legend should contain
a line for the dots corresponding to observed counts.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_decompose">decompose</code></td>
<td>
<p>if <code>TRUE</code> or (a permutation of)
<code>colnames(x$stsObj)</code>, the fitted mean will be decomposed
into the contributions from each single unit and the endemic part
instead of the default endemic + AR + neighbours decomposition.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_total">total</code></td>
<td>
<p>logical indicating if the fitted components should be
summed over all units to be compared with the total observed
counts at each time point. If <code>total=TRUE</code>, the
<code>units</code>/<code>unit</code> argument is ignored.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_start">start</code>, <code id="hhh4_plot_+3A_end">end</code></td>
<td>
<p>time range to plot specified by vectors of length two
in the form <code>c(year,number)</code>, see <code>"<a href="#topic+sts-class">sts</a>"</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_xaxis">xaxis</code></td>
<td>
<p>if this is a list (of arguments for
<code><a href="#topic+addFormattedXAxis">addFormattedXAxis</a></code>), the time axis is nicely labelled
similar to <code><a href="#topic+stsplot_time">stsplot_time</a></code>.
Note that in this case or if <code>xaxis = NA</code>,
the basic time indexes <code>1:nrow(x$stsObj)</code>
will be used as x coordinates, which is different from the
long-standing default (<code>xaxis = NULL</code>) with a real time scale.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_xlim">xlim</code></td>
<td>
<p>numeric vector of length 2 specifying the x-axis range.
The default (<code>NULL</code>) is to plot the complete time range
(<code>type="fitted"</code>) or period (<code>type="season"</code>), respectively.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_ylim">ylim</code></td>
<td>
<p>y-axis range.
For <code>type="fitted"</code>, this defaults to 
<code>c(0,max(observed(x$stsObj)[,unit]))</code>.
For <code>type="season"</code>, <code>ylim</code> must be a list of length
<code>length(components)</code> specifying the range for every component
plot, or a named list to customize only a subset of these. If only
one <code>ylim</code> is specified, it will be recycled for all
<code>components</code> plots.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_xlab">xlab</code>, <code id="hhh4_plot_+3A_ylab">ylab</code></td>
<td>
<p>axis labels. For <code>plotHHH4_season</code>, <code>ylab</code>
specifies the y-axis labels for all <code>components</code> in a
list (similar to <code>ylim</code>). If <code>NULL</code> or incomplete, 
default mathematical expressions are used.
If a single name is supplied such as the default <code>ylab=""</code> (to
omit y-axis labels), it is used for all <code>components</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_hide0s">hide0s</code></td>
<td>
<p>logical indicating if dots for zero observed counts
should be omitted. Especially useful if there are too many.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_meanhhh">meanHHH</code></td>
<td>
<p>(internal) use different component means than those
estimated and available from <code>x</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_components">components</code></td>
<td>
<p>character vector of component names, i.e., a subset
of <code>c("ar", "ne", "end")</code>, for which to plot the estimated
seasonality. If <code>NULL</code> (the default), only components which
appear in any of the models in <code>...</code> are plotted.<br />
A seasonality plot of the epidemic dominant eigenvalue
is also available by including <code>"maxEV"</code> in <code>components</code>,
but it only supports models without epidemic covariates/offsets.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_intercept">intercept</code></td>
<td>
<p>logical indicating whether to include the global
intercept. For <code>plotHHH4_season</code>, the default (<code>FALSE</code>)
means to plot seasonality as a multiplicative effect on the
respective component. Multiplication by the intercept only
makes sense if there are no further (non-centered)
covariates/offsets in the component.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_exp">exp</code></td>
<td>
<p>logical indicating whether to <code>exp</code>-transform the
color-key axis labels to show the multiplicative effect of
the region-specific random intercept on the respective component.
Axis labels are then computed using <code><a href="scales.html#topic+log_breaks">log_breaks</a></code>
from package <span class="pkg">scales</span> (if that is available) or
<code><a href="grDevices.html#topic+axisTicks">axisTicks</a></code> (as a fallback) respecting the
<code>colorkey$tick.number</code> setting (default: 7).
The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_at">at</code></td>
<td>
<p>a numeric vector of breaks for the color levels (see
<code><a href="lattice.html#topic+levelplot">levelplot</a></code>), or a list specifying the number
of breaks <code>n</code> (default: 10) and their <code>range</code> (default:
range of the random effects, extended to be symmetric around 0).
In the latter case, breaks are equally spaced (on the original,
non-<code>exp</code> scale of the random intercepts). If <code>exp=TRUE</code>,
custom breaks (or <code>range</code>) need to be given on the exp-scale.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_matplot.args">matplot.args</code></td>
<td>
<p>list of line style specifications passed to
<code><a href="graphics.html#topic+matplot">matplot</a></code>, e.g., <code>lty</code>, <code>lwd</code>, <code>col</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_refline.args">refline.args</code></td>
<td>
<p>list of line style specifications (e.g.,
<code>lty</code> or <code>col</code>) passed to <code><a href="graphics.html#topic+abline">abline</a></code> when
drawing the reference line (<code>h=1</code>) in plots of seasonal effects
(if <code>intercept=FALSE</code>) and of the dominant eigenvalue.
The reference line is omitted if <code>refline.args</code> is not a list.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_period">period</code></td>
<td>
<p>a numeric value giving the (longest) period of the
harmonic terms in the model. This usually coincides with the
<code>freq</code> of the data (the default), but needs to be adjusted if
the model contains harmonics with a longer periodicity.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_which">which</code></td>
<td>
<p>a character vector specifying the components of the mean
for which to produce maps. By default, the overall mean and all
three components are shown.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_prop">prop</code></td>
<td>
<p>a logical indicating whether the component maps should
display proportions of the total mean instead of absolute numbers.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_zmax">zmax</code></td>
<td>
<p>a numeric vector of length <code>length(which)</code> (recycled
as necessary) specifying upper limits for the color keys of the
maps, using a lower limit of 0.
A missing element (<code>NA</code>) means to use a map-specific color key
only covering the range of the values in that map
(can be useful for <code>prop = TRUE</code>).
The default <code>zmax = NULL</code> means to use the same scale for the component maps
and a separate scale for the map showing the overall mean.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_col.regions">col.regions</code></td>
<td>
<p>a vector of colors used to encode the fitted
component means (see <code><a href="lattice.html#topic+levelplot">levelplot</a></code>).
For <code>plotHHH4_maps</code>, the length of this color vector also
determines the number of levels, using 10 heat colors by default.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_colorkey">colorkey</code></td>
<td>
<p>a Boolean indicating whether to draw the color key.
Alternatively, a list specifying how to draw it, see
<code><a href="lattice.html#topic+levelplot">levelplot</a></code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_map">map</code></td>
<td>
<p>an object inheriting from <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>
with <code>row.names</code> covering <code>colnames(x)</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_component">component</code></td>
<td>
<p>component for which to plot the estimated
region-specific random intercepts. Must partially match one of
<code>colnames(ranef(x, tomatrix=TRUE))</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_labels">labels</code></td>
<td>
<p>determines if and how regions are labeled, see
<code><a href="#topic+layout.labels">layout.labels</a></code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_sp.layout">sp.layout</code></td>
<td>
<p>optional list of additional layout items, see
<code><a href="sp.html#topic+spplot">spplot</a></code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_gpar.missing">gpar.missing</code></td>
<td>
<p>list of graphical parameters for
<code><a href="sp.html#topic+sp.polygons">sp.polygons</a></code>, applied to regions
with missing random intercepts, i.e., not included in the model.
Such extra regions won't be plotted if
<code>!is.list(gpar.missing)</code>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_plotter">plotter</code></td>
<td>
<p>the (name of a) function used to produce the plot of
weights (a numeric vector) as a function of neighbourhood order (a
factor variable). It is called as
<code>plotter(Weight ~ Distance, ...)</code> and defaults to
<code><a href="graphics.html#topic+boxplot">boxplot</a></code>. A useful alternative is, e.g.,
<code><a href="lattice.html#topic+stripplot">stripplot</a></code> from package <span class="pkg">lattice</span>.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_exclude">exclude</code></td>
<td>
<p>vector of neighbourhood orders to be excluded from
plotting (passed to <code><a href="base.html#topic+factor">factor</a></code>).
By default, the neighbourhood weight for order 0 is not
shown, which is usually zero anyway.</p>
</td></tr>
<tr><td><code id="hhh4_plot_+3A_maxlag">maxlag</code></td>
<td>
<p>maximum order of neighbourhood to be assumed when
computing the <code><a href="#topic+nbOrder">nbOrder</a></code> matrix. This additional step is
necessary iff <code>neighbourhood(x$stsObj)</code> only specifies a binary
adjacency matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plotHHH4_fitted1</code> invisibly returns a matrix of the fitted
component means for the selected <code>unit</code>, and <code>plotHHH4_fitted</code>
returns these in a list for all <code>units</code>.<br />
<code>plotHHH4_season</code> invisibly returns the plotted y-values, i.e. the
multiplicative seasonality effect within each of <code>components</code>.
Note that this will include the intercept, i.e. the point estimate of
<code class="reqn">exp(intercept + seasonality)</code> is plotted and returned.<br />
<code>getMaxEV_season</code> returns a list with elements
<code>"maxEV.season"</code> (as plotted by
<code>plotHHH4_season(..., components="maxEV")</code>,
<code>"maxEV.const"</code> and <code>"Lambda.const"</code> (the Lambda matrix and
its dominant eigenvalue if time effects are ignored).<br />
<code>plotHHH4_maxEV</code> (invisibly) and <code>getMaxEV</code> return the
dominant eigenvalue of the <code class="reqn">\Lambda_t</code> matrix for all time points
<code class="reqn">t</code> of <code>x$stsObj</code>.<br />
<code>plotHHH4_maps</code> returns a <code><a href="lattice.html#topic+trellis.object">trellis.object</a></code> if
<code>length(which) == 1</code> (a single <code><a href="sp.html#topic+spplot">spplot</a></code>), and
otherwise uses <code><a href="gridExtra.html#topic+grid.arrange">grid.arrange</a></code> from the
<span class="pkg">gridExtra</span> package to arrange all <code>length(which)</code>
<code><a href="sp.html#topic+spplot">spplot</a></code>s on a single page.
<code>plotHHH4_ri</code> returns the generated <code><a href="sp.html#topic+spplot">spplot</a></code>, i.e.,
a <code><a href="lattice.html#topic+trellis.object">trellis.object</a></code>.<br />
<code>plotHHH4_neweights</code> eventually calls <code>plotter</code> and
thus returns whatever is returned by that function.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Held, L. and Paul, M. (2012): Modeling seasonality in space-time
infectious disease surveillance data.
<em>Biometrical Journal</em>, <b>54</b>, 824-843.
<a href="https://doi.org/10.1002/bimj.201200037">doi:10.1002/bimj.201200037</a>
</p>
<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p>other methods for <code>hhh4</code> fits, e.g., <code><a href="#topic+summary.hhh4">summary.hhh4</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("measlesWeserEms")

## fit a simple hhh4 model
measlesModel &lt;- list(
    ar = list(f = ~ 1),
    end = list(f = addSeason2formula(~0 + ri(type="iid"), S=1, period=52),
               offset = population(measlesWeserEms)),
    family = "NegBin1"
    )
measlesFit &lt;- hhh4(measlesWeserEms, measlesModel)

## fitted values for a single unit
plot(measlesFit, units=2)

## sum fitted components over all units
plot(measlesFit, total=TRUE)

## 'xaxis' option for a nicely formatted time axis
## default tick locations and labels:
plot(measlesFit, total=TRUE, xaxis=list(epochsAsDate=TRUE, line=1))
## an alternative with monthly ticks:
oopts &lt;- surveillance.options(stsTickFactors = c("%m"=0.75, "%Y" = 1.5))
plot(measlesFit, total=TRUE, xaxis=list(epochsAsDate=TRUE,
    xaxis.tickFreq=list("%m"=atChange, "%Y"=atChange),
    xaxis.labelFreq=list("%Y"=atMedian), xaxis.labelFormat="%Y"))
surveillance.options(oopts)

## plot the multiplicative effect of seasonality
plot(measlesFit, type="season")

## alternative fit with biennial pattern, plotted jointly with original fit
measlesFit2 &lt;- update(measlesFit,
    end = list(f = addSeason2formula(~0 + ri(type="iid"), S=2, period=104)))
plotHHH4_season(measlesFit, measlesFit2, components="end", period=104)

## dominant eigenvalue of the Lambda matrix (cf. Held and Paul, 2012)
getMaxEV(measlesFit)  # here simply constant and equal to exp(ar.1)
plot(measlesFit, type="maxEV")  # not very exciting

## fitted mean components/proportions by district, averaged over time
if (requireNamespace("gridExtra")) {
    plot(measlesFit, type="maps", labels=list(cex=0.6),
         which=c("endemic", "epi.own"), prop=TRUE, zmax=NA,
         main=c("endemic proportion", "autoregressive proportion"))
}

## estimated random intercepts of the endemic component
fixef(measlesFit)["end.ri(iid)"]     # global intercept (log-scale)
ranef(measlesFit, tomatrix = TRUE)   # zero-mean deviations
ranef(measlesFit, intercept = TRUE)  # sum of the above
exp(ranef(measlesFit))               # multiplicative effects
plot(measlesFit, type="ri", component="end",
     main="deviations around the endemic intercept (log-scale)")
plot(measlesFit, type="ri", component="end", exp=TRUE,
     main="multiplicative effects",
     labels=list(font=3, labels="GEN"))

## neighbourhood weights as a function of neighbourhood order
plot(measlesFit, type="neweights")  # boring, model has no "ne" component

## fitted values for the 6 regions with most cases and some customization
bigunits &lt;- tail(names(sort(colSums(observed(measlesWeserEms)))), 6)
plot(measlesFit, units=bigunits,
     names=measlesWeserEms@map@data[bigunits,"GEN"],
     legend=5, legend.args=list(x="top"), xlab="Time (weekly)",
     hide0s=TRUE, ylim=c(0,max(observed(measlesWeserEms)[,bigunits])),
     start=c(2002,1), end=c(2002,26), par.settings=list(xaxs="i"))
</code></pre>

<hr>
<h2 id='hhh4_predict'>Predictions from a <code>hhh4</code> Model</h2><span id='topic+predict.hhh4'></span>

<h3>Description</h3>

<p>Get fitted (component) means from a <code><a href="#topic+hhh4">hhh4</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hhh4'
predict(object, newSubset=object$control$subset,
        type="response", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_predict_+3A_object">object</code></td>
<td>
<p>fitted <code><a href="#topic+hhh4">hhh4</a></code> model (class <code>"hhh4"</code>).</p>
</td></tr>
<tr><td><code id="hhh4_predict_+3A_newsubset">newSubset</code></td>
<td>
<p>subset of time points for which to return the
predictions. Defaults to the subset used for fitting the model, and
must be a subset of <code>1:nrow(object$stsObj)</code>.</p>
</td></tr>
<tr><td><code id="hhh4_predict_+3A_type">type</code></td>
<td>
<p>the type of prediction required. The default
(<code>"response"</code> or, equivalently, <code>"mean"</code>) is on the 
scale of the response variable (mean = endemic plus epidemic components).
The alternatives are: <code>"endemic"</code>, <code>"epidemic"</code>,
<code>"epi.own"</code> (i.e. the autoregressive part), and
<code>"epi.neighbours"</code> (i.e. the spatio-temporal part).</p>
</td></tr>
<tr><td><code id="hhh4_predict_+3A_...">...</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of fitted means for each time point (of <code>newSubset</code>) and region.
</p>


<h3>Note</h3>

<p>Predictions for &ldquo;newdata&rdquo;, i.e., with modified covariates or
fixed weights, can be computed manually by adjusting the control list
(in a copy of the original fit), dropping the old <code>terms</code>, and using
the internal function <code><a href="#topic+meanHHH">meanHHH</a></code> directly, see the Example.
</p>


<h3>Author(s)</h3>

<p>Michaela Paul and Sebastian Meyer</p>


<h3>Examples</h3>

<pre><code class='language-R'>## simulate simple seasonal noise with reduced baseline for t &gt;= 60
t &lt;- 0:100
y &lt;- rpois(length(t), exp(3 + sin(2*pi*t/52) - 2*(t &gt;= 60)))
obj &lt;- sts(y)
plot(obj)

## fit true model
fit &lt;- hhh4(obj, list(end = list(f = addSeason2formula(~lock)),
                      data = list(lock = as.integer(t &gt;= 60)),
                      family = "Poisson"))
coef(fit, amplitudeShift = TRUE, se = TRUE)

## compute predictions for a subset of the time points
stopifnot(identical(predict(fit), fitted(fit)))
plot(obj)
lines(40:80, predict(fit, newSubset = 40:80), lwd = 2)


## advanced: compute predictions for "newdata" (here, a modified covariate)
mod &lt;- fit
mod$terms &lt;- NULL  # to be sure
mod$control$data$lock[t &gt;= 60] &lt;- 0.5
pred &lt;- meanHHH(mod$coefficients, terms(mod))$mean
plot(fit, xaxis = NA)
lines(mod$control$subset, pred, lty = 2)
</code></pre>

<hr>
<h2 id='hhh4_simulate'>Simulate <code>"hhh4"</code> Count Time Series</h2><span id='topic+simulate.hhh4'></span>

<h3>Description</h3>

<p>Simulates a multivariate time series of counts based on the
Poisson/Negative Binomial model as described in Paul and Held (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hhh4'
simulate(object, nsim = 1, seed = NULL, y.start = NULL,
         subset = 1:nrow(object$stsObj), coefs = coef(object),
         components = c("ar","ne","end"), simplify = nsim&gt;1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_simulate_+3A_object">object</code></td>
<td>

<p>an object of class <code>"<a href="#topic+hhh4">hhh4</a>"</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_+3A_nsim">nsim</code></td>
<td>

<p>number of time series to simulate. Defaults to <code>1</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_+3A_seed">seed</code></td>
<td>

<p>an object specifying how the random number generator should be
initialized for simulation (via <code><a href="base.html#topic+set.seed">set.seed</a></code>). The
initial state will also be stored as an attribute <code>"seed"</code> of
the result. The original state of the <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>
will be restored at the end of the simulation.
By default (<code>NULL</code>), neither initialization nor recovery will
be done.
This behaviour is copied from the <code><a href="stats.html#topic+simulate">simulate</a>.lm</code> method.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_+3A_y.start">y.start</code></td>
<td>

<p>vector or matrix (with <code>ncol(object$stsObj)</code> columns) with
starting counts for the epidemic components. 
If <code>NULL</code>, the observed means in the respective units of the
data in <code>object</code> during <code>subset</code> are used.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_+3A_subset">subset</code></td>
<td>

<p>time period in which to simulate data. Defaults to (and cannot
exceed) the whole period defined by the underlying <code>"sts"</code>
object.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_+3A_coefs">coefs</code></td>
<td>

<p>coefficients used for simulation from the model in <code>object</code>.
Default is to use the fitted parameters.
Note that the <code>coefs</code>-vector must be in the same order and
scaling as <code>coef(object)</code>, which especially means
<code>reparamPsi = TRUE</code> (as per default when using the
<code>coef</code>-method to extract the parameters).
The overdispersion parameter in <code>coefs</code> is the inverse of the
dispersion parameter <code>size</code> in <code><a href="stats.html#topic+rnbinom">rnbinom</a></code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_+3A_components">components</code></td>
<td>

<p>character vector indicating which components of the fitted model
<code>object</code> should be active during simulation. For instance,
a simulation with <code>components="end"</code> is solely based on the
fitted endemic mean.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_+3A_simplify">simplify</code></td>
<td>

<p>logical indicating if only the simulated counts (<code>TRUE</code>) or the
full <code>"<a href="#topic+sts-class">sts</a>"</code> object (<code>FALSE</code>) should be
returned for every replicate.
By default a full <code>"sts"</code> object is returned iff <code>nsim=1</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_+3A_...">...</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulates data from a Poisson or a Negative Binomial model
with mean
</p>
<p style="text-align: center;"><code class="reqn">\mu_{it} = \lambda_{it} y_{i,t-1} + 
                   \phi_{it} \sum_{j \neq i} w_{ji} y_{j,t-1} + 
                   \nu_{it}</code>
</p>

<p>where
<code class="reqn">\lambda_{it}&gt;0</code>, <code class="reqn">\phi_{it}&gt;0</code>, and <code class="reqn">\nu_{it}&gt;0</code> are 
parameters which are modelled parametrically.
The function uses the model and parameter estimates of the fitted
<code>object</code> to simulate the time series.
</p>
<p>With the argument <code>coefs</code> it is possible to simulate from  
the model as specified in <code>object</code>, but with different 
parameter values.
</p>


<h3>Value</h3>

<p>If <code>simplify=FALSE</code>: an object of class
<code>"<a href="#topic+sts-class">sts</a>"</code> (<code>nsim = 1</code>) or a list of those
(<code>nsim &gt; 1</code>).
</p>
<p>If <code>simplify=TRUE</code>: an object of class
<code>"hhh4sims"</code>, which is an array of dimension
<code>c(length(subset), ncol(object$stsObj), nsim)</code>.
The originally observed counts during the simulation period,
<code>object$stsObj[subset,]</code>, are attached for reference
(used by the <code>plot</code>-methods) as an attribute <code>"stsObserved"</code>,
and the initial condition <code>y.start</code> as attribute <code>"initial"</code>.
The <code>[</code>-method for <code>"hhh4sims"</code> takes care of subsetting
these attributes appropriately.
</p>


<h3>Author(s)</h3>

<p>Michaela Paul and Sebastian Meyer
</p>


<h3>References</h3>

<p>Paul, M. and Held, L. (2011) Predictive assessment of a non-linear
random  effects model for multivariate time series of infectious
disease counts. Statistics in Medicine, <b>30</b>, 1118&ndash;1136
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.hhh4sims">plot.hhh4sims</a></code> and <code><a href="#topic+scores.hhh4sims">scores.hhh4sims</a></code>
and the examples therein for <code>nsim &gt; 1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(influMen)
# convert to sts class and extract meningococcal disease time series
meningo &lt;- disProg2sts(influMen)[,2]

# fit model
fit &lt;- hhh4(meningo, control = list(
              ar = list(f = ~ 1),
              end = list(f = addSeason2formula(~1, period = 52)),
              family = "NegBin1"))
plot(fit)

# simulate from model (generates an "sts" object)
simData &lt;- simulate(fit, seed=1234)

# plot simulated data
plot(simData, main = "simulated data", xaxis.labelFormat=NULL)

# use simplify=TRUE to return an array of simulated counts
simCounts &lt;- simulate(fit, seed=1234, simplify=TRUE)
dim(simCounts)  # nTime x nUnit x nsim

# plot the first year of simulated counts (+ initial + observed)
plot(simCounts[1:52,,], type = "time", xaxis.labelFormat = NULL)
# see help(plot.hhh4sims) for other plots, mainly useful for nsim &gt; 1

# simulate from a Poisson instead of a NegBin model
# keeping all other parameters fixed at their original estimates
coefs &lt;- replace(coef(fit), "overdisp", 0)
simData2 &lt;- simulate(fit, seed=123, coefs = coefs)
plot(simData2, main = "simulated data: Poisson model", xaxis.labelFormat = NULL)

# simulate from a model with higher autoregressive parameter
coefs &lt;- replace(coef(fit), "ar.1", log(0.9))
simData3 &lt;- simulate(fit, seed=321, coefs = coefs)
plot(simData3, main = "simulated data: lambda = 0.5", xaxis.labelFormat = NULL)


## more sophisticated: simulate beyond initially observed time range

# extend data range by one year (non-observed domain), filling with NA values
nextend &lt;- 52
timeslots &lt;- c("observed", "state", "alarm", "upperbound", "populationFrac")
addrows &lt;- function (mat, n) mat[c(seq_len(nrow(mat)), rep(NA, n)),,drop=FALSE]
extended &lt;- Map(function (x) addrows(slot(meningo, x), n = nextend), x = timeslots)
# create new sts object with extended matrices
meningo2 &lt;- do.call("sts", c(list(start = meningo@start, frequency = meningo@freq,
                                  map = meningo@map), extended))

# fit to the observed time range only, via the 'subset' argument
fit2 &lt;- hhh4(meningo2, control = list(
              ar = list(f = ~ 1),
              end = list(f = addSeason2formula(~1, period = 52)),
              family = "NegBin1",
              subset = 2:(nrow(meningo2) - nextend)))
# the result is the same as before
stopifnot(all.equal(fit, fit2, ignore = c("stsObj", "control")))

# long-term probabilistic forecast via simulation for non-observed time points
meningoSim &lt;- simulate(fit2, nsim = 100, seed = 1,
                       subset = seq(nrow(meningo)+1, nrow(meningo2)),
                       y.start = tail(observed(meningo), 1))
apply(meningoSim, 1:2, function (ysim) quantile(ysim, c(0.1, 0.5, 0.9)))
# three plot types are available for "hhh4sims", see also ?plot.hhh4sims
plot(meningoSim, type = "time", average = median)
plot(meningoSim, type = "size", observed = FALSE)
if (requireNamespace("fanplot"))
    plot(meningoSim, type = "fan", means.args = list(),
         fan.args = list(ln = c(.1,.9), ln.col = 8))
</code></pre>

<hr>
<h2 id='hhh4_simulate_plot'>
Plot Simulations from <code>"hhh4"</code> Models
</h2><span id='topic+plot.hhh4sims'></span><span id='topic+aggregate.hhh4sims'></span><span id='topic+as.hhh4simslist'></span><span id='topic+plot.hhh4simslist'></span><span id='topic+aggregate.hhh4simslist'></span><span id='topic+plotHHH4sims_size'></span><span id='topic+plotHHH4sims_time'></span><span id='topic+plotHHH4sims_fan'></span>

<h3>Description</h3>

<p>Arrays of simulated counts from <code><a href="#topic+simulate.hhh4">simulate.hhh4</a></code> can be
visualized as final size boxplots, individual or average time series,
or fan charts (using the <a href="https://CRAN.R-project.org/package=fanplot"><span class="pkg">fanplot</span></a> package).
An <code>aggregate</code>-method is also available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hhh4sims'
plot(x, ...)
## S3 method for class 'hhh4sims'
aggregate(x, units = TRUE, time = FALSE, ..., drop = FALSE)

as.hhh4simslist(x, ...)
## S3 method for class 'hhh4simslist'
plot(x, type = c("size", "time", "fan"), ...,
     groups = NULL, par.settings = list())
## S3 method for class 'hhh4simslist'
aggregate(x, units = TRUE, time = FALSE, ..., drop = FALSE)

plotHHH4sims_size(x, horizontal = TRUE, trafo = NULL, observed = TRUE,
                  names = base::names(x), ...)

plotHHH4sims_time(x, average = mean, individual = length(x) == 1,
    conf.level = if (individual) 0.95 else NULL,
    matplot.args = list(), initial.args = list(), legend = length(x) &gt; 1,
    xlim = NULL, ylim = NULL, add = FALSE, ...)

plotHHH4sims_fan(x, which = 1,
    fan.args = list(), observed.args = list(), initial.args = list(),
    means.args = NULL, key.args = NULL, xlim = NULL, ylim = NULL,
    add = FALSE, xaxis = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_simulate_plot_+3A_x">x</code></td>
<td>

<p>an object of class <code>"hhh4sims"</code> (as resulting from the
<code><a href="#topic+simulate.hhh4">simulate</a></code>-method for
<code>"<a href="#topic+hhh4">hhh4</a>"</code> models if <code>simplify = TRUE</code> was set),
or an <code>"hhh4simslist"</code>, i.e.,
a list of such simulations potentially obtained from different
model fits (using the same simulation period).
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_type">type</code></td>
<td>

<p>a character string indicating the summary plot to produce.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_...">...</code></td>
<td>

<p>further arguments passed to methods.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_groups">groups</code></td>
<td>

<p>an optional factor to produce stratified plots by groups of units.
The special setting <code>groups = TRUE</code> is a convenient shortcut
for one plot by unit.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_par.settings">par.settings</code></td>
<td>

<p>a list of graphical parameters for <code><a href="graphics.html#topic+par">par</a></code>.
Sensible defaults for <code>mfrow</code>, <code>mar</code> and <code>las</code> will
be applied unless overridden or <code>!is.list(par.settings)</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_horizontal">horizontal</code></td>
<td>

<p>a logical indicating if the boxplots of the final size distributions
should be horizontal (the default).
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_trafo">trafo</code></td>
<td>

<p>an optional transformation function from the <span class="pkg">scales</span> package, e.g.,
<code><a href="scales.html#topic+sqrt_trans">sqrt_trans</a></code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_observed">observed</code></td>
<td>

<p>a logical indicating if a line and axis value for the observed size
of the epidemic should be added to the plot.
Alternatively, a list with graphical parameters can be specified to
modify the default values.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_names">names</code></td>
<td>

<p>a character vector of names for <code>x</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_average">average</code></td>
<td>

<p>scalar-valued function to apply to the simulated counts at each time point.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_individual">individual</code></td>
<td>

<p>a logical indicating if the individual simulations should be shown as well.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_conf.level">conf.level</code></td>
<td>

<p>a scalar in (0,1), which determines the level of the pointwise
quantiles obtained from the simulated counts at each time point.
A value of <code>NULL</code> disables the confidence interval.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_matplot.args">matplot.args</code></td>
<td>

<p>a list of graphical parameters for <code><a href="graphics.html#topic+matlines">matlines</a></code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_initial.args">initial.args</code></td>
<td>

<p>if a list (of graphical parameters for <code><a href="graphics.html#topic+lines">lines</a></code>),
a bar for the initial number of cases is added to the plot.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_legend">legend</code></td>
<td>

<p>a logical, a character vector (providing names for <code>x</code>),
or a list of parameters for <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_xlim">xlim</code>, <code id="hhh4_simulate_plot_+3A_ylim">ylim</code></td>
<td>

<p>vectors of length 2 determining the axis limits.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_add">add</code></td>
<td>

<p>a logical indicating if the (mean) simulated time series or the fan
chart, respectively, should be added to an existing plot.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_which">which</code></td>
<td>

<p>a single integer or a character string selecting the model in
<code>x</code> for which to produce the fan chart.
This is only relevant if <code>x</code> is a <code>"hhh4simslist"</code> of
simulations from multiple models.
Defaults to the first model.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_fan.args">fan.args</code></td>
<td>

<p>a list of graphical parameters for the <code><a href="fanplot.html#topic+fan">fan</a></code>,
e.g., to employ a different <code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code> as
<code>fan.col</code>, or to enable contour lines via <code>ln</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_observed.args">observed.args</code></td>
<td>

<p>if a list (of graphical parameters for <code><a href="graphics.html#topic+lines">lines</a></code>),
the originally observed counts are added to the plot.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_means.args">means.args</code></td>
<td>

<p>if a list (of graphical parameters for <code><a href="graphics.html#topic+lines">lines</a></code>),
the point forecasts are added to the plot (by default as
a white line within the fan).
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_key.args">key.args</code></td>
<td>

<p>if a list, a color key (in <code><a href="fanplot.html#topic+fan">fan</a></code>'s
<code>"boxfan"</code>-style) is added to the fan chart. The list may
include positioning parameters <code>start</code> (the x-position) and
<code>ylim</code> (the y-range of the color key), <code>space</code> to modify
the width of the boxfan, and <code>rlab</code> to modify the labels.
The color key is disabled by default.
An alternative way of labeling the quantiles is via the argument
<code>ln</code> in <code>fan.args</code>, see the Examples.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_xaxis">xaxis</code></td>
<td>

<p>if a list of arguments for <code><a href="#topic+addFormattedXAxis">addFormattedXAxis</a></code>, that
function is used to draw the time axis, otherwise a default x-axis
is drawn.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_units">units</code></td>
<td>

<p>a logical indicating aggregation over units. Can also be a factor
(or something convertible to a factor using <code><a href="base.html#topic+as.factor">as.factor</a></code>)
to aggregate groups of units.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_time">time</code></td>
<td>

<p>a logical indicating if the counts should be summed over the whole
simulation period.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_plot_+3A_drop">drop</code></td>
<td>

<p>a logical indicating if the unit dimension and the <code>"hhh4sims"</code>
(or <code>"hhh4simslist"</code>) class should be dropped after aggregating
over (groups of) units.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### univariate example
data("salmAllOnset")

## fit a hhh4 model to the first 13 years
salmModel &lt;- list(end = list(f = addSeason2formula(~1 + t)),
                  ar = list(f = ~1), family = "NegBin1", subset = 2:678)
salmFit &lt;- hhh4(salmAllOnset, salmModel)

## simulate the next 20 weeks ahead
salmSims &lt;- simulate(salmFit, nsim = 300, seed = 3, subset = 678 + seq_len(20),
                     y.start = observed(salmAllOnset)[678,])

## compare final size distribution to observed value
summary(aggregate(salmSims, time = TRUE))  # summary of simulated values
plot(salmSims, type = "size")

## individual and average simulated time series with a confidence interval
plot(salmSims, type = "time", main = "20-weeks-ahead simulation")

## fan chart based on the quantiles of the simulated counts at each time point
## point forecasts are represented by a white line within the fan
if (requireNamespace("fanplot")) {
    plot(salmSims, type = "fan", main = "20-weeks-ahead simulation",
         fan.args = list(ln = 1:9/10), means.args = list())
}


### multivariate example
data("measlesWeserEms")

## fit a hhh4 model to the first year
measlesModel &lt;- list(
    end = list(f = addSeason2formula(~1), offset = population(measlesWeserEms)),
    ar = list(f = ~1),
    ne = list(f = ~1 + log(pop),
        weights = W_powerlaw(maxlag = 5, normalize = TRUE)),
    family = "NegBin1", subset = 2:52,
    data = list(pop = population(measlesWeserEms)))
measlesFit1 &lt;- hhh4(measlesWeserEms, control = measlesModel)

## use a Poisson distribution instead (just for comparison)
measlesFit2 &lt;- update(measlesFit1, family = "Poisson")

## simulate realizations from these models during the second year
measlesSims &lt;- lapply(X = list(NegBin = measlesFit1, Poisson = measlesFit2),
                      FUN = simulate, nsim = 50, seed = 1, subset = 53:104,
                      y.start = observed(measlesWeserEms)[52,])

## final size of the first model
plot(measlesSims[[1]])

## stratified by groups of districts
mygroups &lt;- factor(substr(colnames(measlesWeserEms), 4, 4))
apply(aggregate(measlesSims[[1]], time = TRUE, units = mygroups), 1, summary)
plot(measlesSims[[1]], groups = mygroups)

## a class and plot-method for a list of simulations from different models
measlesSims &lt;- as.hhh4simslist(measlesSims)
plot(measlesSims)

## simulated time series
plot(measlesSims, type = "time", individual = TRUE, ylim = c(0, 80))

## fan charts
if (requireNamespace("fanplot")) {
    opar &lt;- par(mfrow = c(2,1))
    plot(measlesSims, type = "fan", which = 1, ylim = c(0, 80), main = "NegBin",
         key.args = list())
    plot(measlesSims, type = "fan", which = 2, ylim = c(0, 80), main = "Poisson")
    par(opar)
}
</code></pre>

<hr>
<h2 id='hhh4_simulate_scores'>
Proper Scoring Rules for Simulations from <code>hhh4</code> Models
</h2><span id='topic+scores.hhh4sims'></span><span id='topic+scores.hhh4simslist'></span>

<h3>Description</h3>

<p>Calculate proper scoring rules based on simulated predictive distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hhh4sims'
scores(x, which = "rps", units = NULL, ..., drop = TRUE)
## S3 method for class 'hhh4simslist'
scores(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_simulate_scores_+3A_x">x</code></td>
<td>

<p>an object of class <code>"hhh4sims"</code> (as resulting from the
<code><a href="#topic+simulate.hhh4">simulate</a></code>-method for
<code>"<a href="#topic+hhh4">hhh4</a>"</code> models if <code>simplify = TRUE</code> was set),
or an <code>"hhh4simslist"</code>, i.e.,
a list of such simulations potentially obtained from different
model fits (using the same simulation period).
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_scores_+3A_which">which</code></td>
<td>

<p>a character vector indicating which proper scoring rules to compute.
By default, only the ranked probability score (<code>"rps"</code>) is
calculated. Other options include <code>"logs"</code> and <code>"dss"</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_scores_+3A_units">units</code></td>
<td>

<p>if non-<code>NULL</code>, an integer or character vector indexing the
columns of <code>x</code> for which to compute the scores.
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_scores_+3A_drop">drop</code></td>
<td>

<p>a logical indicating if univariate dimensions should be dropped
(the default).
</p>
</td></tr>
<tr><td><code id="hhh4_simulate_scores_+3A_...">...</code></td>
<td>

<p>unused (argument of the generic).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation can only compute <em>univariate scores</em>, i.e.,
independently for each time point.
</p>
<p>The logarithmic score is badly estimated if the domain is large and
there are not enough samples to cover the underlying distribution in
enough detail (the score becomes infinite when an observed value does
not occur in the samples). An alternative is to use kernel density
estimation as implemented in the <span class="rlang"><b>R</b></span> package <a href="https://CRAN.R-project.org/package=scoringRules"><span class="pkg">scoringRules</span></a>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("salmAllOnset")

## fit a hhh4 model to the first 13 years
salmModel &lt;- list(end = list(f = addSeason2formula(~1 + t)),
                  ar = list(f = ~1), family = "NegBin1", subset = 2:678)
salmFit &lt;- hhh4(salmAllOnset, salmModel)

## simulate the next 20 weeks ahead (with very small 'nsim' for speed)
salmSims &lt;- simulate(salmFit, nsim = 500, seed = 3, subset = 678 + seq_len(20),
                     y.start = observed(salmAllOnset)[678,])
if (requireNamespace("fanplot"))
    plot(salmSims, "fan")


### calculate scores at each time point

## using empirical distribution of simulated counts as forecast distribution
scores(salmSims, which = c("rps", "logs", "dss"))
## observed count sometimes not covered by simulations -&gt; infinite log-score
## =&gt; for a more detailed forecast, either considerably increase 'nsim', or:

## 1. use continuous density() of simulated counts as forecast distribution
fi &lt;- apply(salmSims, 1, function (x) approxfun(density(x)))
logs_kde &lt;- mapply(function (f, y) -log(f(y)),
                   f = fi, y = observed(attr(salmSims,"stsObserved")))
cbind("empirical" = scores(salmSims, "logs"), "density" = logs_kde)
## a similar KDE approach is implemented in scoringRules::logs_sample()

## 2. average conditional predictive NegBin's of simulated trajectories,
##    currently only implemented in HIDDA.forecasting::dhhh4sims()


### produce a PIT histogram

## using empirical distribution of simulated counts as forecast distribition
pit(x = observed(attr(salmSims, "stsObserved")),
    pdistr = apply(salmSims, 1:2, ecdf))
## long-term forecast is badly calibrated (lower tail is unused, see fan above)
## we also get a warning for the same reason as infinite log-scores
</code></pre>

<hr>
<h2 id='hhh4_update'>
<code>update</code> a fitted <code>"hhh4"</code> model
</h2><span id='topic+update.hhh4'></span>

<h3>Description</h3>

<p>Re-fit a <code>"<a href="#topic+hhh4">hhh4</a>"</code> model with a modified <code>control</code> list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hhh4'
update(object, ..., S = NULL, subset.upper = NULL,
       use.estimates = object$convergence, evaluate = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_update_+3A_object">object</code></td>
<td>

<p>a fitted <code>"hhh4"</code> model.
Non-convergent fits can be updated as well.
</p>
</td></tr>
<tr><td><code id="hhh4_update_+3A_...">...</code></td>
<td>

<p>components modifying the original control list for
<code><a href="#topic+hhh4">hhh4</a></code>. Modifications are performed by
<code><a href="utils.html#topic+modifyList">modifyList</a>(object$control, list(...))</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_update_+3A_s">S</code></td>
<td>

<p>a named list of numeric vectors serving as argument for
<code><a href="#topic+addSeason2formula">addSeason2formula</a></code>, or <code>NULL</code> (meaning no
modification of seasonal terms). This argument provides a convenient
way of changing the number of harmonics in the <code>f</code>ormulae of
the model components <code>"ar"</code>, <code>"ne"</code> and <code>"end"</code> (to be
used as names of the list). Non-specified components are not touched.
Updating the <code>i</code>'th component's <code>f</code>ormula works by first
dropping all sine and cosine terms and then applying
<code>addSeason2formula</code> with arguments <code>S = S[[i]]</code> and
<code>period = object$stsObj@freq</code>. Note that this step of updating
seasonality is processed after modification of the <code>control</code>
list by the <code>...</code> arguments.
</p>
</td></tr>
<tr><td><code id="hhh4_update_+3A_subset.upper">subset.upper</code></td>
<td>

<p>if a scalar value, refit the model to the data up to the time index
given by <code>subset.upper</code>. The lower time index remains
unchanged, i.e., <code>control$subset[1]:subset.upper</code> is used as
the new <code>subset</code>.
This argument is used by <code><a href="#topic+oneStepAhead">oneStepAhead</a></code>.
</p>
</td></tr>
<tr><td><code id="hhh4_update_+3A_use.estimates">use.estimates</code></td>
<td>

<p>logical specifying if <code>coef(object)</code> should be used as
starting values for the new fit (which is the new default since
<span class="pkg">surveillance</span> 1.8-2, in case the original fit has converged).
This works by matching names
against the coefficients of the new model. Extra coefficients no
longer in the model are silently ignored. Setting
<code>use.estimates = FALSE</code> means to re-use the previous start
specification <code>object$control$start</code>.<br />
Note that coefficients can also receive initial values from an extra
<code>start</code> argument in the update call (as in <code><a href="#topic+hhh4">hhh4</a></code>),
which then takes precedence over <code>coef(object)</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_update_+3A_evaluate">evaluate</code></td>
<td>

<p>logical indicating if the updated model should be fitted directly
(defaults to <code>TRUE</code>). Otherwise, the updated <code>control</code> list
is returned.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>evaluate = TRUE</code> the re-fitted object, otherwise the updated
<code>control</code> list for <code><a href="#topic+hhh4">hhh4</a></code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hhh4">hhh4</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("salmonella.agona")
## convert to sts class
salmonella &lt;- disProg2sts(salmonella.agona)

## fit a basic model
fit0 &lt;- hhh4(salmonella,
            list(ar = list(f = ~1), end = list(f = addSeason2formula(~t))))

## update: Poisson -&gt; NegBin1, component seasonality
fit1 &lt;- update(fit0, family = "NegBin1", S = list(end=2, ar=2))

## compare fits
AIC(fit0, fit1)
opar &lt;- par(mfrow=c(2,2))
plot(fit0, type="fitted", names="fit0", par.settings=NULL)
plot(fit1, type="fitted", names="fit1", par.settings=NULL)
plot(fit0, fit1, type="season", components=c("end", "ar"), par.settings=NULL)
par(opar)
</code></pre>

<hr>
<h2 id='hhh4_validation'>Predictive Model Assessment for <code>hhh4</code> Models</h2><span id='topic+oneStepAhead'></span><span id='topic+quantile.oneStepAhead'></span><span id='topic+confint.oneStepAhead'></span><span id='topic+plot.oneStepAhead'></span><span id='topic+scores.oneStepAhead'></span><span id='topic+scores.hhh4'></span><span id='topic+calibrationTest.oneStepAhead'></span><span id='topic+calibrationTest.hhh4'></span><span id='topic+pit.oneStepAhead'></span><span id='topic+pit.hhh4'></span>

<h3>Description</h3>

<p>The function <code>oneStepAhead</code> computes successive one-step-ahead
predictions for a (random effects) HHH model fitted by <code><a href="#topic+hhh4">hhh4</a></code>.
These can be inspected using the <code>quantile</code>, <code>confint</code> or
<code>plot</code> methods.
The associated <code><a href="#topic+scores">scores</a></code>-method computes a number of (strictly) proper
scoring rules based on such one-step-ahead predictions;
see Paul and Held (2011) for details.
There are also <code><a href="#topic+calibrationTest">calibrationTest</a></code> and <code><a href="#topic+pit">pit</a></code>
methods for <code>oneStepAhead</code> predictions.
</p>
<p>Scores, calibration tests and PIT histograms can also be
computed for the fitted values of an <code>hhh4</code> model
(i.e., in-sample/training data evaluation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oneStepAhead(result, tp, type = c("rolling", "first", "final"),
             which.start = c("current", "final"),
             keep.estimates = FALSE, verbose = type != "final",
             cores = 1)

## S3 method for class 'oneStepAhead'
quantile(x, probs = c(2.5, 10, 50, 90, 97.5)/100, ...)
## S3 method for class 'oneStepAhead'
confint(object, parm, level = 0.95, ...)
## S3 method for class 'oneStepAhead'
plot(x, unit = 1, probs = 1:99/100,
     start = NULL, means.args = NULL, ...)

## assessment of "oneStepAhead" predictions
## S3 method for class 'oneStepAhead'
scores(x, which = c("logs", "rps", "dss", "ses"),
       units = NULL, sign = FALSE, individual = FALSE, reverse = FALSE, ...)
## S3 method for class 'oneStepAhead'
calibrationTest(x, units = NULL, ...)
## S3 method for class 'oneStepAhead'
pit(x, units = NULL, ...)

## assessment of the "hhh4" model fit (in-sample predictions)
## S3 method for class 'hhh4'
scores(x, which = c("logs", "rps", "dss", "ses"),
       subset = x$control$subset, units = seq_len(x$nUnit), sign = FALSE, ...)
## S3 method for class 'hhh4'
calibrationTest(x,
                subset = x$control$subset, units = seq_len(x$nUnit), ...)
## S3 method for class 'hhh4'
pit(x, subset = x$control$subset, units = seq_len(x$nUnit), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_validation_+3A_result">result</code></td>
<td>
<p>fitted <code><a href="#topic+hhh4">hhh4</a></code> model (class <code>"hhh4"</code>).</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_tp">tp</code></td>
<td>

<p>numeric vector of length 2 specifying the time range in
which to compute one-step-ahead predictions (for the time points
<code>tp[1]+1</code>, ..., <code>tp[2]+1</code>).
If a single time index is specified, it is interpreted as
<code>tp[1]</code>, and <code>tp[2]</code> is set to the penultimate time point
of <code>result$control$subset</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_type">type</code></td>
<td>

<p>The default <code>"rolling"</code> procedure sequentially 
refits the model up to each time point in <code>tp</code> and computes
the one-step-ahead predictions for the respective next time point.
The alternative <code>type</code>s are no true one-step-ahead predictions
but much faster:
<code>"first"</code> will refit the model for the first time point
<code>tp[1]</code> only and use this specific fit to calculate all
subsequent predictions, whereas
<code>"final"</code> will just use <code>result</code> to calculate these.
The latter case thus gives nothing else than a subset of
<code>result$fitted.values</code> if the <code>tp</code>'s are part of the
fitted subset <code>result$control$subset</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_which.start">which.start</code></td>
<td>

<p>Which initial parameter values should be used when successively
refitting the model to subsets of the data (up to time point
<code>tp[1]</code>, up to <code>tp[1]+1</code>, ...) if <code>type="rolling"</code>?
Default (<code>"current"</code>) is to use the parameter estimates from the
previous time point, and <code>"final"</code> means to always
use the estimates from <code>result</code> as initial values.
Alternatively, <code>which.start</code> can be a list of <code>start</code>
values as expected by <code><a href="#topic+hhh4">hhh4</a></code>, which then replace
the corresponding estimates from <code>result</code> as initial values.
This argument is ignored for &ldquo;non-rolling&rdquo; <code>type</code>s.
</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_keep.estimates">keep.estimates</code></td>
<td>

<p>logical indicating if parameter estimates and log-likelihoods from
the successive fits should be returned.
</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_verbose">verbose</code></td>
<td>

<p>non-negative integer (usually in the range <code>0:3</code>) specifying
the amount of tracing information to output.
During <code>hhh4</code> model updates, the following verbosity is used:
<code>0</code> if <code>cores &gt; 1</code>, otherwise <code>verbose-1</code> if there
is more than one time point to predict, otherwise <code>verbose</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_cores">cores</code></td>
<td>
<p>the number of cores to use when computing
the predictions for the set of time points <code>tp</code> in parallel
(with <code><a href="parallel.html#topic+mclapply">mclapply</a></code>).
Note that parallelization is not possible in the default setting
<code>type="rolling"</code> and <code>which.start="current"</code> (use
<code>which.start="final"</code> for this to work).</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_object">object</code></td>
<td>
<p>an object of class <code>"oneStepAhead"</code>.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_parm">parm</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_level">level</code></td>
<td>
<p>required confidence level of the prediction interval.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_probs">probs</code></td>
<td>
<p>numeric vector of probabilities with values in [0,1].</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_unit">unit</code></td>
<td>
<p>single integer or character selecting a unit for which to
produce the plot.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_start">start</code></td>
<td>

<p>x-coordinate of the first prediction. If <code>start=NULL</code>
(default), this is derived from <code>x</code>.
</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_means.args">means.args</code></td>
<td>

<p>if a list (of graphical parameters for <code><a href="graphics.html#topic+lines">lines</a></code>),
the point predictions (from <code>x$pred</code>) are added to the plot.
</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_x">x</code></td>
<td>
<p>an object of class <code>"oneStepAhead"</code> or <code>"hhh4"</code>.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_which">which</code></td>
<td>
<p>character vector determining which scores to compute.
The package <span class="pkg">surveillance</span> implements the following proper
scoring rules: logarithmic score (<code>"logs"</code>), ranked probability
score (<code>"rps"</code>), Dawid-Sebastiani score (<code>"dss"</code>), and
squared error score (<code>"ses"</code>). The normalized SES
(<code>"nses"</code>) is also available but it is improper and hence not
computed by default.<br />
It is possible to name own scoring rules in <code>which</code>. These
must be functions of <code>(x, mu, size)</code>, vectorized in all arguments
(time x unit matrices) except that <code>size</code> is <code>NULL</code>
in case of a Poisson model.
See the available scoring rules for guidance, e.g., <code><a href="#topic+dss">dss</a></code>.
</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_subset">subset</code></td>
<td>

<p>subset of time points for which to calculate the scores
(or test calibration, or produce the PIT histogram, respectively).
Defaults to the subset used for fitting the model.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_units">units</code></td>
<td>
<p>integer or character vector indexing the units for which
to compute the scores (or the calibration test or the PIT histogram,
respectively). By default, all units are considered.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_sign">sign</code></td>
<td>
<p>logical indicating if the function should also return
<code>sign(x-mu)</code>, i.e., the sign of the difference between
the observed counts and corresponding predictions.
This does not really make sense when averaging over multiple
<code>units</code> with <code>individual=FALSE</code>.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_individual">individual</code></td>
<td>
<p>logical indicating if the individual scores of the
<code>units</code> should be returned. By default (<code>FALSE</code>), the
individual scores are averaged over all <code>units</code>.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_reverse">reverse</code></td>
<td>
<p>logical indicating if the rows (time points) should be
reversed in the result. The long-standing but awkward default was to
do so for the <code>oneStepAhead</code>-method. This has changed in
version 1.16.0, so time points are no longer reversed by default.</p>
</td></tr>
<tr><td><code id="hhh4_validation_+3A_...">...</code></td>
<td>
<p>Unused by the <code>quantile</code>, <code>confint</code> and
<code>scores</code> methods.<br />
The <code>plot</code>-method passes further arguments to the
<code><a href="#topic+fanplot">fanplot</a></code> function, e.g., <code>fan.args</code>,
<code>observed.args</code>, and <code>key.args</code> can be used to modify the
plotting style.<br />
For the <code>calibrationTest</code>-method, further arguments are passed
to <code><a href="#topic+calibrationTest.default">calibrationTest.default</a></code>, e.g., <code>which</code> to
select a scoring rule.<br />
For the <code>pit</code>-methods, further arguments are passed to
<code><a href="#topic+pit.default">pit.default</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>oneStepAhead</code> returns a list (of class <code>"oneStepAhead"</code>)
with the following components:
</p>
<table>
<tr><td><code>pred</code></td>
<td>
<p>one-step-ahead predictions in a matrix, where each row
corresponds to one of the time points requested via the argument
<code>tp</code>, and which has <code>ncol(result$stsObj)</code>
unit-specific columns. The rownames indicate the predicted time points
and the column names are identical to <code>colnames(result$stsObj)</code>.</p>
</td></tr>
<tr><td><code>observed</code></td>
<td>
<p>matrix with observed counts at the predicted time
points. It has the same dimensions and names as <code>pred</code>.</p>
</td></tr>
<tr><td><code>psi</code></td>
<td>
<p>in case of a negative-binomial model, a matrix of the
estimated overdispersion parameter(s) at each time point on 
the internal -log-scale (1 column if <code>"NegBin1"</code>,
<code>ncol(observed)</code> columns if <code>"NegBinM"</code> or shared overdispersion). 
For a <code>"Poisson"</code> model, this component is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>allConverged</code></td>
<td>
<p>logical indicating if all successive fits
converged.</p>
</td></tr>
</table>
<p>If <code>keep.estimates=TRUE</code>, there are the following additional elements:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>matrix of estimated regression parameters from the successive fits.</p>
</td></tr>
<tr><td><code>Sigma.orig</code></td>
<td>
<p>matrix of estimated variance parameters from the successive fits.</p>
</td></tr>
<tr><td><code>logliks</code></td>
<td>
<p>matrix with columns <code>"loglikelihood"</code> and
<code>"margll"</code> with their obvious meanings.</p>
</td></tr>
</table>
<p>The <code>quantile</code>-method computes quantiles of the one-step-ahead
forecasts. If there is only one unit, it returns a tp x prob matrix,
otherwise a tp x unit x prob array.
The <code>confint</code>-method is a convenient wrapper with <code>probs</code> set
according to the required confidence level.
</p>
<p>The function <code>scores</code> computes the scoring rules specified in the
argument <code>which</code>.
If multiple <code>units</code> are selected and <code>individual=TRUE</code>, the
result is an array of dimensions
<code>c(nrow(pred),length(units),5+sign)</code> (up to <span class="pkg">surveillance</span>
1.8-0, the first two dimensions were collapsed to give a matrix).
Otherwise, the result is a matrix with <code>nrow(pred)</code> rows and
<code>5+sign</code> columns. If there is only one predicted time point, the
first dimension is dropped in both cases.
</p>
<p>The <code><a href="#topic+calibrationTest">calibrationTest</a></code>- and <code><a href="#topic+pit">pit</a></code>-methods are
just convenient wrappers around the respective default methods.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer and Michaela Paul
</p>


<h3>References</h3>

<p>Czado, C., Gneiting, T. and Held, L. (2009):
Predictive model assessment for count data.
<em>Biometrics</em>, <b>65</b> (4), 1254-1261.
<a href="https://doi.org/10.1111/j.1541-0420.2009.01191.x">doi:10.1111/j.1541-0420.2009.01191.x</a>
</p>
<p>Paul, M. and Held, L. (2011):
Predictive assessment of a non-linear random effects model for
multivariate time series of infectious disease counts.
<em>Statistics in Medicine</em>, <b>30</b> (10), 1118-1136.
<a href="https://doi.org/10.1002/sim.4177">doi:10.1002/sim.4177</a>
</p>


<h3>See Also</h3>

<p><code>vignette("hhh4")</code> and <code>vignette("hhh4_spacetime")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### univariate salmonella agona count time series

data("salmonella.agona")
## convert from old "disProg" to new "sts" class
salmonella &lt;- disProg2sts(salmonella.agona)

## generate formula for temporal and seasonal trends
f.end &lt;- addSeason2formula(~1 + t, S=1, period=52)
model &lt;- list(ar = list(f = ~1), end = list(f = f.end), family = "NegBin1")
## fit the model
result &lt;- hhh4(salmonella, model)

## do sequential one-step-ahead predictions for the last 5 weeks
pred &lt;- oneStepAhead(result, nrow(salmonella)-5, type="rolling",
                     which.start="final", verbose=FALSE)
pred
quantile(pred)
confint(pred)

## simple plot of the 80% one-week-ahead prediction interval
## and point forecasts
if (requireNamespace("fanplot"))
    plot(pred, probs = c(.1,.9), means.args = list())



## note: oneStepAhead(..., type="final") just means fitted values
stopifnot(identical(
    unname(oneStepAhead(result, nrow(salmonella)-5, type="final")$pred),
    unname(tail(fitted(result), 5))))


## compute scores of the one-step-ahead predictions
(sc &lt;- scores(pred))

## the above uses the scores-method for "oneStepAhead" predictions,
## which is a simple wrapper around the default method:
scores(x = pred$observed, mu = pred$pred, size = exp(pred$psi))

## scores with respect to the fitted values are similar
(scFitted &lt;- scores(result, subset = nrow(salmonella)-(4:0)))




## test if the one-step-ahead predictions are calibrated
calibrationTest(pred)  # p = 0.8746

## the above uses the calibrationTest-method for "oneStepAhead" predictions,
## which is a simple wrapper around the default method:
calibrationTest(x = pred$observed, mu = pred$pred, size = exp(pred$psi))

## we can also test calibration of the fitted values
## using the calibrationTest-method for "hhh4" fits
calibrationTest(result, subset = nrow(salmonella)-(4:0))


## plot a (non-randomized) PIT histogram for the predictions
pit(pred)

## the above uses the pit-method for "oneStepAhead" predictions,
## which is a simple wrapper around the default method:
pit(x = pred$observed, pdistr = "pnbinom", mu = pred$pred, size = exp(pred$psi))


### multivariate measles count time series
## (omitting oneStepAhead forecasts here to keep runtime low)

data("measlesWeserEms")

## simple hhh4 model with random effects in the endemic component
measlesModel &lt;- list(
    end = list(f = addSeason2formula(~0 + ri(type="iid"))),
    ar = list(f = ~1),
    family = "NegBin1")
measlesFit &lt;- hhh4(measlesWeserEms, control = measlesModel)

## assess overall (in-sample) calibration of the model, i.e.,
## if the observed counts are from the fitted NegBin distribution
calibrationTest(measlesFit) # default is DSS (not suitable for low counts)
calibrationTest(measlesFit, which = "logs") # p = 0.7238

## to assess calibration in the second year for a specific district
calibrationTest(measlesFit, subset = 53:104, units = "03452", which = "rps")
pit(measlesFit, subset = 53:104, units = "03452")


### For a more sophisticated multivariate analysis of
### areal time series of influenza counts - data("fluBYBW") -
### see the (computer-intensive) demo("fluBYBW") script:
demoscript &lt;- system.file("demo", "fluBYBW.R", package = "surveillance")
#file.show(demoscript)
</code></pre>

<hr>
<h2 id='hhh4_W'>
Power-Law and Nonparametric Neighbourhood Weights for <code>hhh4</code>-Models
</h2><span id='topic+W_powerlaw'></span><span id='topic+W_np'></span>

<h3>Description</h3>

<p>Set up power-law or nonparametric weights for the neighbourhood
component of <code><a href="#topic+hhh4">hhh4</a></code>-models as proposed by Meyer and Held (2014).
Without normalization, power-law weights are
<code class="reqn">w_{ji} = o_{ji}^{-d}</code>
(if <code class="reqn">o_{ji} &gt; 0</code>, otherwise <code class="reqn">w_{ji} = 0</code>),
where <code class="reqn">o_{ji}</code> (<code class="reqn">=o_{ij}</code>) is the adjacency order
between regions <code class="reqn">i</code> and <code class="reqn">j</code>,
and the decay parameter <code class="reqn">d</code> is to be estimated.
In the nonparametric formulation, unconstrained log-weights will be
estimated for each of the adjacency orders <code>2:maxlag</code> (the
first-order weight is fixed to 1 for identifiability).
Both weight functions can be modified to include a 0-distance weight,
which enables <code>hhh4</code> models without a separate autoregressive component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>W_powerlaw(maxlag, normalize = TRUE, log = FALSE,
           initial = if (log) 0 else 1, from0 = FALSE)

W_np(maxlag, truncate = TRUE, normalize = TRUE,
     initial = log(zetaweights(2:(maxlag+from0))),
     from0 = FALSE, to0 = truncate)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_W_+3A_maxlag">maxlag</code></td>
<td>
<p>a single integer specifying a limiting order of
adjacency. If spatial dependence is not to be truncated at some
high order, <code>maxlag</code> should be set to the maximum adjacency
order in the network of regions. The smallest possible value for
<code>maxlag</code> is 2 if <code>from0=FALSE</code> and 1 otherwise.</p>
</td></tr>
<tr><td><code id="hhh4_W_+3A_truncate">truncate</code>, <code id="hhh4_W_+3A_to0">to0</code></td>
<td>
<p><code>W_np</code> represents order-specific log-weights up to
order <code>maxlag</code>. Higher orders are by default (<code>truncate=TRUE</code>)
assumed to have zero weight (similar to <code>W_powerlaw</code>).
Alternatively, <code>truncate=FALSE</code> requests that the weight at
order <code>maxlag</code> should be carried forward to higher orders.
<code>truncate</code> has previously been called <code>to0</code> (deprecated).</p>
</td></tr>
<tr><td><code id="hhh4_W_+3A_normalize">normalize</code></td>
<td>
<p>logical indicating if the weights should be normalized
such that the rows of the weight matrix sum to 1 (default).
Note that normalization does not work with islands, i.e., regions
without neighbours.</p>
</td></tr>
<tr><td><code id="hhh4_W_+3A_log">log</code></td>
<td>
<p>logical indicating if the decay parameter <code class="reqn">d</code> should be
estimated on the log-scale to ensure positivity.</p>
</td></tr>
<tr><td><code id="hhh4_W_+3A_initial">initial</code></td>
<td>
<p>initial value of the parameter vector.</p>
</td></tr>
<tr><td><code id="hhh4_W_+3A_from0">from0</code></td>
<td>
<p>logical indicating if these parametric weights should
include the 0-distance (autoregressive) case. In the default setting
(<code>from0 = FALSE</code>), adjacency order 0 has zero weight, which is
suitable for <code>hhh4</code> models with a separate autoregressive
component. With <code>from0 = TRUE</code> (Meyer and Held, 2017), the
power law is based on <code class="reqn">(o_{ji} + 1)</code>, and
nonparametric weights are estimated for adjacency orders
<code>1:maxlag</code>, respectively, where the 0-distance weight is
<code class="reqn">w_{jj} = 1</code> (without normalization). Note that
the corresponding <code>hhh4</code> model should then exclude a separate
autoregressive component (<code>control$ar$f = ~ -1</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hhh4</code> will take adjacency orders from the <code>neighbourhood</code>
slot of the <code>"sts"</code> object, so these must be prepared before
fitting a model with parametric neighbourhood weights. The function
<code><a href="#topic+nbOrder">nbOrder</a></code> can be used to derive adjacency orders from a
binary adjacency matrix.
</p>


<h3>Value</h3>

<p>a list which can be passed as a specification of parametric
neighbourhood weights in the <code>control$ne$weights</code> argument of
<code><a href="#topic+hhh4">hhh4</a></code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Meyer, S. and Held, L. (2014):
Power-law models for infectious disease spread.
<em>The Annals of Applied Statistics</em>, <b>8</b> (3), 1612-1639.
<a href="https://doi.org/10.1214/14-AOAS743">doi:10.1214/14-AOAS743</a>
</p>
<p>Meyer, S. and Held, L. (2017):
Incorporating social contact data in spatio-temporal models for
infectious disease spread.
<em>Biostatistics</em>, <b>18</b> (2), 338-351.
<a href="https://doi.org/10.1093/biostatistics/kxw051">doi:10.1093/biostatistics/kxw051</a>
</p>


<h3>See Also</h3>

  
<p><code><a href="#topic+nbOrder">nbOrder</a></code> to determine adjacency orders from a binary
adjacency matrix.
</p>
<p><code><a href="#topic+getNEweights">getNEweights</a></code> and <code><a href="#topic+coefW">coefW</a></code> to extract the
estimated neighbourhood weight matrix and coefficients from an
<code>hhh4</code> model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("measlesWeserEms")

## data contains adjaceny orders as required for parametric weights
plot(measlesWeserEms, type = observed ~ unit, labels = TRUE)
neighbourhood(measlesWeserEms)[1:6,1:6]
max(neighbourhood(measlesWeserEms))  # max order is 5

## fit a power-law decay of spatial interaction
## in a hhh4 model with seasonality and random intercepts in the endemic part
measlesModel &lt;- list(
    ar = list(f = ~ 1),
    ne = list(f = ~ 1, weights = W_powerlaw(maxlag=5)),
    end = list(f = addSeason2formula(~-1 + ri(), S=1, period=52)),
    family = "NegBin1")

## fit the model
set.seed(1)  # random intercepts are initialized randomly
measlesFit &lt;- hhh4(measlesWeserEms, measlesModel)
summary(measlesFit)  # "neweights.d" is the decay parameter d
coefW(measlesFit)

## plot the spatio-temporal weights o_ji^-d / sum_k o_jk^-d
## as a function of adjacency order
plot(measlesFit, type = "neweights", xlab = "adjacency order")
## normalization =&gt; same distance does not necessarily mean same weight.
## to extract the whole weight matrix W: getNEweights(measlesFit)

## visualize contributions of the three model components
## to the overall number of infections (aggregated over all districts)
plot(measlesFit, total = TRUE)
## little contribution from neighbouring districts


## simpler model with autoregressive effects captured by the ne component
measlesModel2 &lt;- list(
    ne = list(f = ~ 1, weights = W_powerlaw(maxlag=5, from0=TRUE)),
    end = list(f = addSeason2formula(~-1 + ri(), S=1, period=52)),
    family = "NegBin1")
measlesFit2 &lt;- hhh4(measlesWeserEms, measlesModel2)
## omitting the separate AR component simplifies model extensions/selection
## and interpretation of covariate effects (only two predictors left)

plot(measlesFit2, type = "neweights", exclude = NULL, xlab = "adjacency order")
## strong decay, again mostly within-district transmission
## (one could also try a purely autoregressive model)
plot(measlesFit2, total = TRUE,
     legend.args = list(legend = c("epidemic", "endemic")))
## almost the same RMSE as with separate AR and NE effects
c(rmse1 = sqrt(mean(residuals(measlesFit, "response")^2)),
  rmse2 = sqrt(mean(residuals(measlesFit2, "response")^2)))

</code></pre>

<hr>
<h2 id='hhh4_W_utils'>
Extract Neighbourhood Weights from a Fitted <code>hhh4</code> Model
</h2><span id='topic+getNEweights'></span><span id='topic+coefW'></span>

<h3>Description</h3>

<p>The <code>getNEweights</code> function extracts the (fitted) weight
matrix/array from a <code>"hhh4"</code> object, after scaling and
normalization.
The <code>coefW</code> function extracts the coefficients of parametric
neighbourhood weights from a <code>hhh4</code> fit (or directly from a
corresponding coefficient vector), i.e., coefficients whose names
begin with &ldquo;neweights&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNEweights(object, pars = coefW(object),
             scale = ne$scale, normalize = ne$normalize)
coefW(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhh4_W_utils_+3A_object">object</code></td>
<td>
<p>an object of class <code>"hhh4"</code>.
<code>coefW</code> also works with the coefficient vector.</p>
</td></tr>
<tr><td><code id="hhh4_W_utils_+3A_pars">pars</code></td>
<td>
<p>coefficients for parametric neighbourhood weights,
such as for models using <code><a href="#topic+W_powerlaw">W_powerlaw</a></code>.
Defaults to the corresponding point estimates in <code>object</code>.</p>
</td></tr>
<tr><td><code id="hhh4_W_utils_+3A_scale">scale</code>, <code id="hhh4_W_utils_+3A_normalize">normalize</code></td>
<td>
<p>parameters of the <code>ne</code> component of
<code><a href="#topic+hhh4">hhh4</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>

<hr>
<h2 id='husO104Hosp'>Hospitalization date for HUS cases of the STEC outbreak in Germany, 2011</h2><span id='topic+husO104Hosp'></span>

<h3>Description</h3>

<p>Data contain the date of hospitalization for 630 hemolytic-uremic
syndrome (HUS) cases during the large STEC outbreak in Germany,
2011. Note: Only HUS cases which ultimately had a hospitalization
date available/reported are included in the data set. The total number
of HUS cases during the outbreak was 855 &ndash; see Höhle and
an der Heiden (2014) as well as Frank et al. (2011) for details.
</p>
<p>For each HUS case the attribute <code>dHosp</code> contains the date of
hospitalization and the attribute <code>dReport</code> contains the date of
first arrival of this hospitalization date at the Robert Koch
Institute (RKI). As described in Höhle and an der Heiden
(2014) the mechanisms of the delay were complicated and should be
interpreted with care. For example, the case report could have arrived
earlier, but without information about the hospitalization date.
</p>
<p>The resulting reporting triangle corresponds to Fig. 1 of the Web
appendix of Höhle and an der Heiden (2014). This means
that the reports which arrived with a delay longer than 15 days are
set to have have arrived after 15 days. Altogether, this gives small
discrepancies when compared with the results of the paper. However, as
mentioned in the paper, longer delays were not very relevant for the
nowcasting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(husO104Hosp)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> object. 
</p>


<h3>Source</h3>

<p>Data were collected during the outbreak as part of the mandatory
reporting of notifiable diseases in Germany (Faensen et al.,
2006). Here, reports are transmitted from the local health authorities
via the state health authorities to the Robert Koch Institute, Berlin.
The resulting reporting triangle corresponds to Fig. 1 of the Web
appendix of Höhle and an der Heiden (2014).
</p>


<h3>References</h3>

<p>Höhle M and an der Heiden, M (2014). Bayesian Nowcasting
during the STEC O104:H4 Outbreak in Germany, 2011, In revision for
Biometrics.
</p>
<p>Frank C, Werber D, Cramer JP, Askar M, Faber M, an der Heiden M,
Bernard H, Fruth A, Prager R, Spode A, Wadl M, Zoufaly A, Jordan S,
Kemper MJ, Follin P, Müller L, King LA, Rosner B,
Buchholz U, Stark K, Krause G; HUS Investigation Team (2011).
Epidemic Profile of Shiga-Toxin Producing Escherichia coli O104:H4
Outbreak in Germany, N Engl J Med. 2011 Nov 10;365(19):1771-80.
</p>
<p>Faensen D, Claus H, Benzler J, Ammon A, Pfoch T, Breuer T, Krause G (2014).
SurvNet@RKI - a multistate electronic reporting system for communicable
diseases, Euro Surveillance, 2006;11(4):100-103.
</p>

<hr>
<h2 id='imdepi'>
Occurrence of Invasive Meningococcal Disease in Germany
</h2><span id='topic+imdepi'></span>

<h3>Description</h3>

<p><code>imdepi</code> contains data on the spatio-temporal location of 636
cases of invasive meningococcal disease (IMD) caused by the two most
common meningococcal finetypes in Germany, &lsquo;<span class="samp">&#8288;B:P1.7-2,4:F1-5&#8288;</span>&rsquo; (of
serogroup B) and &lsquo;<span class="samp">&#8288;C:P1.5,2:F3-3&#8288;</span>&rsquo; (of serogroup C).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("imdepi")
</code></pre>


<h3>Format</h3>

<p><code>imdepi</code> is an object of class
<code>"<a href="#topic+epidataCS">epidataCS</a>"</code> (a list with components <code>events</code>,
<code>stgrid</code>, <code>W</code> and <code>qmatrix</code>).
</p>


<h3>Details</h3>

<p>The <code>imdepi</code> data is a simplified version of what has been
analyzed by Meyer et al. (2012). Simplification is with respect to the
temporal resolution of the <code>stgrid</code> (see below) to be used in
<code><a href="#topic+twinstim">twinstim</a></code>'s endemic model component.
In what follows, we describe the elements <code>events</code>,
<code>stgrid</code>, <code>W</code>, and <code>qmatrix</code> of <code>imdepi</code> in
greater detail.
</p>
<p><code>imdepi$events</code> is a <code>"<a href="sp.html#topic+SpatialPointsDataFrame-class">SpatialPointsDataFrame</a>"</code>
object (ETRS89 projection, i.e. EPSG code 3035, with unit &lsquo;km&rsquo;)
containing 636 events, each with the following entries:
</p>

<dl>
<dt>time:</dt><dd><p>Time of the case occurrence measured in number of days
since origin. Note that a U(0,1)-distributed random number has
been subtracted from each of the original event times (days) to
break ties (using
<code><a href="#topic+untie">untie</a>(imdepi_tied, amount=list(t=1))</code>).</p>
</dd>
<dt>tile:</dt><dd><p>Tile ID in the spatio-temporal grid (<code>stgrid</code>) of
endemic covariates, where the event is contained in.
This corresponds to one of the 413 districts of Germany.
</p>
</dd>
<dt>type:</dt><dd><p>Event type, a factor with levels <code>"B"</code> and <code>"C"</code>.</p>
</dd>
<dt>eps.t:</dt><dd><p>Maximum temporal interaction range for the event.
Here set to 30 days.</p>
</dd>
<dt>eps.s:</dt><dd><p>Maximum spatial interaction range for the event.
Here set to 200 km.</p>
</dd>
<dt>sex:</dt><dd><p>Sex of the case, i.e. a factor with levels <code>"female"</code>
and <code>"male"</code>. Note: for some cases this
information is not available (<code>NA</code>).</p>
</dd> 
<dt>agegrp:</dt><dd><p>Factor giving the age group of the case,
i.e. 0-2, 3-18 or &gt;=19. Note: for one case this
information is not available (<code>NA</code>).</p>
</dd>
<dt>BLOCK, start:</dt><dd><p>Block ID and start time (in days since origin) of
the cell in the spatio-temporal endemic covariate grid, which the
event belongs to.</p>
</dd> 
<dt>popdensity:</dt><dd><p>Population density (per square km) at the
location of the event (corresponds to population density of the
district where the event is located).</p>
</dd>
</dl>

<p>There are further auxiliary columns attached to the events' data
the names of which begin with a . (dot): These are created during
conversion to the <code>"epidataCS"</code> class and are necessary for
fitting the data with <code>twinstim</code>, see the description of the
<code>"<a href="#topic+epidataCS">epidataCS</a>"</code>-class.
With <code>coordinates(imdepi$events)</code> one obtains the (x,y) locations
of the events.
</p>
<p>The district identifier in <code>tile</code> is indexed according to
the German official municipality key (
&ldquo;Amtlicher Gemeindeschlüssel&rdquo;). See
<a href="https://de.wikipedia.org/wiki/Amtlicher_Gemeindeschl%C3%BCssel">https://de.wikipedia.org/wiki/Amtlicher_Gemeindeschl%C3%BCssel</a>
for details.
</p>
<p>The data component <code>stgrid</code> contains the spatio-temporal grid of 
endemic covariate information. In addition to the usual bookkeeping
variables this includes:
</p>

<dl>
<dt>area:</dt><dd><p>Area of the district <code>tile</code> in square kilometers.</p>
</dd>
<dt>popdensity:</dt><dd><p>Population density (inhabitants per square
kilometer) computed from DESTATIS (Federal Statistical Office)
information (Date: 31.12.2008) on communities level (LAU2)
aggregated to district level (NUTS3).</p>
</dd> 
</dl>

<p>We have actually not included any time-dependent covariates here, we
just established this grid with a (reduced -&gt; fast) temporal
resolution of <em>monthly</em> intervals so that we can model endemic
time trends and seasonality (in this discretized time).
</p>
<p>The entry <code>W</code> contains the observation window as a
<code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code> object, in this case the
boundaries of Germany (<code>stateD</code>). It was obtained as the
&ldquo;UnaryUnion&rdquo; of Germany's districts (<code>districtsD</code>) as at
2009-01-01, simplified by the &ldquo;modified Visvalingam&rdquo; algorithm
(level 6.6%) available at <a href="https://MapShaper.org">https://MapShaper.org</a> (v. 0.1.17).
The objects <code>districtsD</code> and <code>stateD</code> are contained in
<code>system.file("shapes", "districtsD.RData", package="surveillance")</code>.
</p>
<p>The entry <code>qmatrix</code> is a <code class="reqn">2\times 2</code> identity matrix
indicating that no transmission between the two finetypes can occur.
</p>


<h3>Source</h3>

<p>IMD case reports: German Reference Centre for Meningococci
at the Department of Hygiene and Microbiology,
Julius-Maximilians-Universität Würzburg, Germany
(<a href="https://www.hygiene.uni-wuerzburg.de/meningococcus/">https://www.hygiene.uni-wuerzburg.de/meningococcus/</a>).
Thanks to Dr. Johannes Elias and Prof. Dr. Ulrich Vogel for providing
the data.
</p>
<p>Shapefile of Germany's districts as at 2009-01-01:
German Federal Agency for Cartography and Geodesy, Frankfurt
am Main, Germany, <a href="https://gdz.bkg.bund.de/">https://gdz.bkg.bund.de/</a>.


</p>


<h3>References</h3>

<p>Meyer, S., Elias, J. and Höhle, M. (2012):
A space-time conditional intensity model for invasive meningococcal
disease occurrence. <em>Biometrics</em>, <b>68</b>, 607-616.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01684.x">doi:10.1111/j.1541-0420.2011.01684.x</a>
</p>


<h3>See Also</h3>

<p>the data class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>, and function
<code><a href="#topic+twinstim">twinstim</a></code> for model fitting. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi")

# Basic information
print(imdepi, n=5, digits=2)

# What is an epidataCS-object?
str(imdepi, max.level=4)
names(imdepi$events@data)
# =&gt; events data.frame has hidden columns
sapply(imdepi$events@data, class)
# marks and print methods ignore these auxiliary columns

# look at the B type only
imdepiB &lt;- subset(imdepi, type == "B")
#&lt;- subsetting applies to the 'events' component
imdepiB

# select only the last 10 events
tail(imdepi, n=10)   # there is also a corresponding 'head' method

# Access event marks
str(marks(imdepi))

# there is an update-method which assures that the object remains valid
# when changing parameters like eps.s, eps.t or qmatrix
update(imdepi, eps.t = 20)

# Summary
s &lt;- summary(imdepi)
s
str(s)

# Step function of number of infectives
plot(s$counter, xlab = "Time [days]",
     ylab = "Number of infectious individuals",
     main = "Time series of IMD assuming 30 days infectious period")

# distribution of number of potential sources of infection
opar &lt;- par(mfrow=c(1,2), las=1)
for (type in c("B","C")) {
  plot(100*prop.table(table(s$nSources[s$eventTypes==type])),
  xlim=range(s$nSources), xlab = "Number of potential epidemic sources",
  ylab = "Proportion of events [%]")
}
par(opar)

# a histogram of the number of events along time (using the
# plot-method for the epidataCS-class, see ?plot.epidataCS)
opar &lt;- par(mfrow = c(2,1))
plot(imdepi, "time", subset = type == "B", main = "Finetype B")
plot(imdepi, "time", subset = type == "C", main = "Finetype C")
par(opar)

# Plot the spatial distribution of the events in W
plot(imdepi, "space", points.args = list(col=c("indianred", "darkblue")))

# or manually (no legends, no account for tied locations)
plot(imdepi$W, lwd=2, asp=1) 
plot(imdepi$events, pch=c(3,4)[imdepi$events$type], cex=0.8,
     col=c("indianred", "darkblue")[imdepi$events$type], add=TRUE)

## Not run: 
  # Show a dynamic illustration of the spatio-temporal dynamics of the 
  # spread during the first year of type B with a step size of 7 days
  animate(imdepiB, interval=c(0,365), time.spacing=7, sleep=0.1)

## End(Not run)
</code></pre>

<hr>
<h2 id='imdepifit'>
Example <code>twinstim</code> Fit for the <code>imdepi</code> Data
</h2><span id='topic+imdepifit'></span>

<h3>Description</h3>

<p><code>data("imdepifit")</code> is a <code><a href="#topic+twinstim">twinstim</a></code> model
fitted to the <code><a href="#topic+imdepi">imdepi</a></code> data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("imdepifit")</code></pre>


<h3>Format</h3>

<p>an object of class <code>"<a href="#topic+twinstim">twinstim</a>"</code>
obtained from the following call using <code>data(imdepi)</code>:
</p>
<p><code style="white-space: pre;">&#8288;

twinstim(endemic = addSeason2formula(~offset(log(popdensity)) + 
    I(start/365 - 3.5), S = 1, 
    period = 365, timevar = "start"), 
    epidemic = ~type + agegrp, 
    siaf = siaf.gaussian(), 
    data = imdepi, subset = !is.na(agegrp), 
    optim.args = list(control = list(reltol = sqrt(.Machine$double.eps))), 
    model = FALSE, cumCIF = FALSE)
&#8288;</code>
</p>


<h3>See Also</h3>

<p>common methods for <code>"twinstim"</code> fits,
exemplified using <code>imdepifit</code>, e.g.,
<code><a href="#topic+summary.twinstim">summary.twinstim</a></code>, <code><a href="#topic+plot.twinstim">plot.twinstim</a></code>,
and <code><a href="#topic+simulate.twinstim">simulate.twinstim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi", "imdepifit")

## how this fit was obtained
imdepifit$call

## reproduce "imdepifit"
stopifnot(all.equal(imdepifit, eval(imdepifit$call)))
</code></pre>

<hr>
<h2 id='influMen'>Influenza and meningococcal infections in Germany, 2001-2006</h2><span id='topic+influMen'></span>

<h3>Description</h3>

<p>Weekly counts of new influenza and meningococcal infections in Germany 2001-2006. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(influMen)</code></pre>


<h3>Format</h3>

<p>A <code>disProg</code> object containing <code class="reqn">312\times 2</code>
observations starting from week 1 in 2001 to week 52 in 2006. 
</p>


<h3>Source</h3>

<p>Robert Koch-Institut: SurvStat: <a href="https://survstat.rki.de/">https://survstat.rki.de/</a>.
Queried on 25 July 2007.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(influMen)
plot(influMen, as.one=FALSE, same.scale=FALSE) 
</code></pre>

<hr>
<h2 id='intensityplot'>
Plot Paths of Point Process Intensities
</h2><span id='topic+intensityplot'></span>

<h3>Description</h3>

<p>Generic function for plotting paths of point process intensities.
Methods currently defined in package <span class="pkg">surveillance</span> are for
classes <code>"twinSIR"</code> and <code>"simEpidata"</code> (temporal), as well as
<code>"twinstim"</code> and <code>"simEpidataCS"</code> (spatio-temporal). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intensityplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intensityplot_+3A_x">x</code></td>
<td>

<p>An object for which an <code>intensityplot</code> method is defined.
</p>
</td></tr>
<tr><td><code id="intensityplot_+3A_...">...</code></td>
<td>

<p>Arguments passed to the corresponding method.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>The methods <code><a href="#topic+intensityplot.twinSIR">intensityplot.twinSIR</a></code> and
<code><a href="#topic+intensityplot.twinstim">intensityplot.twinstim</a></code>.
</p>

<hr>
<h2 id='intersectPolyCircle'>
Intersection of a Polygonal and a Circular Domain
</h2><span id='topic+intersectPolyCircle'></span><span id='topic+intersectPolyCircle.owin'></span>

<h3>Description</h3>

<p>This is a unifying wrapper around functionality of various packages
dealing with spatial data. It computes the intersection of a circular
domain and a polygonal domain (whose class defines the specific method).
</p>
<p>Currently the only supported class is <code>"<a href="spatstat.geom.html#topic+owin">owin</a>"</code>
from package <a href="https://CRAN.R-project.org/package=spatstat.geom"><span class="pkg">spatstat.geom</span></a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intersectPolyCircle(object, center, radius, ...)

## S3 method for class 'owin'
intersectPolyCircle(object, center, radius, npoly = 32, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intersectPolyCircle_+3A_object">object</code></td>
<td>
<p>a polygonal domain of one of the supported classes.</p>
</td></tr>
<tr><td><code id="intersectPolyCircle_+3A_center">center</code>, <code id="intersectPolyCircle_+3A_radius">radius</code>, <code id="intersectPolyCircle_+3A_npoly">npoly</code></td>
<td>
<p>see <code><a href="#topic+discpoly">discpoly</a></code>.</p>
</td></tr>
<tr><td><code id="intersectPolyCircle_+3A_...">...</code></td>
<td>
<p>potential further arguments (from the generic).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a polygonal domain of the same class as the input <code>object</code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+discpoly">discpoly</a></code> to generate a polygonal approximation to a disc
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("spatstat.geom")
plot(letterR)
plot(intersectPolyCircle(letterR, c(3,2), 1), add=TRUE, col=2, lwd=3)
</code></pre>

<hr>
<h2 id='isoWeekYear'>Find ISO Week and Year of Date Objects</h2><span id='topic+isoWeekYear'></span>

<h3>Description</h3>

<p>The function <code>isoWeekYear</code> extracts the year and week of a
<code><a href="base.html#topic+Date">Date</a></code> according to the ISO 8601 specification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isoWeekYear(Y, M, D)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isoWeekYear_+3A_y">Y</code></td>
<td>
<p>year(s) or a Date/POSIXt object. Can be a vector.</p>
</td></tr>
<tr><td><code id="isoWeekYear_+3A_m">M</code></td>
<td>
<p>month(s), only used if <code>Y</code> is not a Date/POSIXt object.</p>
</td></tr>
<tr><td><code id="isoWeekYear_+3A_d">D</code></td>
<td>
<p>day(s), only used if <code>Y</code> is not a Date/POSIXt object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with entries <code>ISOYear</code> and <code>ISOWeek</code> containing the
corresponding results.
</p>


<h3>Note</h3>

<p>As from <span class="pkg">surveillance</span> 1.17.0, this function simply
calls <code><a href="base.html#topic+strftime">strftime</a></code> with format strings <code>"%G"</code>
and <code>"%V"</code>, respectively, as this is nowadays (<span class="rlang"><b>R</b></span> &gt;= 3.1.0)
also supported on Windows.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dates &lt;- as.Date(c("2002-12-31","2003-01-01","2003-01-06"))
isoWeekYear(dates)

## the same using numeric inputs:
isoWeekYear(Y = c(2002, 2003, 2003), M = c(12, 1, 1), D = c(31, 1, 6))
</code></pre>

<hr>
<h2 id='isScalar'>
Checks if the Argument is Scalar
</h2><span id='topic+isScalar'></span>

<h3>Description</h3>

<p>The simple helper function <code>isScalar</code> just checks if its argument is
a scalar, i.e. a numeric vector of length 1.
It is implemented as <code>length(x) == 1L &amp;&amp; is.vector(x, mode = "numeric")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isScalar(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isScalar_+3A_x">x</code></td>
<td>
<p>an <code>R</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A length-one logical vector.
</p>

<hr>
<h2 id='knox'>
Knox Test for Space-Time Interaction
</h2><span id='topic+knox'></span><span id='topic+plot.knox'></span><span id='topic+toLatex.knox'></span>

<h3>Description</h3>

<p>Given temporal and spatial distances as well as corresponding critical
thresholds defining what &ldquo;close&rdquo; means, the function
<code>knox</code> performs Knox (1963, 1964) test for space-time interaction.
The corresponding p-value can be calculated either by the Poisson
approximation or by a Monte Carlo permutation approach (Mantel, 1967)
with support for parallel computation via <code><a href="#topic+plapply">plapply</a></code>.
There is a simple <code>plot</code>-method showing a <code><a href="MASS.html#topic+truehist">truehist</a></code> of
the simulated null distribution together with the expected and observed
values.
This implementation of the Knox test is due to Meyer et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knox(dt, ds, eps.t, eps.s, simulate.p.value = TRUE, B = 999, ...)

## S3 method for class 'knox'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knox_+3A_dt">dt</code>, <code id="knox_+3A_ds">ds</code></td>
<td>

<p>numeric vectors containing temporal and spatial distances, respectively.
Logical vectors indicating temporal/spatial closeness may also be
supplied, in which case <code>eps.t</code>/<code>eps.s</code> is ignored.
To test for space-time interaction in a single point pattern of <code class="reqn">n</code>
events, these vectors should be of length <code class="reqn">n*(n-1)/2</code> and
contain the pairwise event distances (e.g., the lower triangle of
the distance matrix, such as in <code>"<a href="stats.html#topic+dist">dist</a>"</code> objects).
Note that there is no special handling of matrix input, i.e.,
if <code>dt</code> or <code>ds</code> are matrices, all elements are used
(but a warning is given if a symmetric matrix is detected).
</p>
</td></tr>
<tr><td><code id="knox_+3A_eps.t">eps.t</code>, <code id="knox_+3A_eps.s">eps.s</code></td>
<td>

<p>Critical distances defining closeness in time and space,
respectively. Distances lower than or equal to the critical distance
are considered &ldquo;&quot;close&quot;&rdquo;.
</p>
</td></tr>
<tr><td><code id="knox_+3A_simulate.p.value">simulate.p.value</code></td>
<td>

<p>logical indicating if a Monte Carlo permutation test should be
performed (as per default). Do not forget to set the
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> via an extra <code>.seed</code> argument if
reproducibility is required (see the ... arguments below).
If <code>simulate.p.value = FALSE</code>, the Poisson approximation is
used (but see the note below).
</p>
</td></tr>
<tr><td><code id="knox_+3A_b">B</code></td>
<td>

<p>number of permutations for the Monte Carlo approach.
</p>
</td></tr>
<tr><td><code id="knox_+3A_...">...</code></td>
<td>

<p>arguments configuring <code><a href="#topic+plapply">plapply</a></code>:
<code>.parallel</code>, <code>.seed</code>, and <code>.verbose</code>.
By default, no parallelization is performed (<code>.parallel = 1</code>),
and a progress bar is shown (<code>.verbose = TRUE</code>).<br />
For the <code>plot</code>-method, further arguments passed to
<code><a href="MASS.html#topic+truehist">truehist</a></code>.
</p>
</td></tr>
<tr><td><code id="knox_+3A_x">x</code></td>
<td>

<p>an object of class <code>"knox"</code> as returned by the
<code>knox</code> test.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"knox"</code> (inheriting from <code>"htest"</code>),
which is a list with the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the type of test
performed, and whether the Poisson approximation or Monte Carlo
simulation was used.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the supplied <code>dt</code> and
<code>ds</code> arguments.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>the number of close pairs.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>if <code>simulate.p.value = TRUE</code>, the number
<code>B</code> of permutations, otherwise the <code>lambda</code> parameter of
the Poisson distribution, i.e., the same as <code>null.value</code>.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test. In case
<code>simulate.p.value = TRUE</code>, the p-value from the Poisson
approximation is still attached as an attribute <code>"Poisson"</code>.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>the character string <code>"greater"</code> (this is a
one-sided test).</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>the expected number of close pairs in the absence of
space-time interaction.</p>
</td></tr>
<tr><td><code>table</code></td>
<td>
<p>the contingency table of <code>dt &lt;= eps.t</code> and
<code>ds &lt;= eps.s</code>.</p>
</td></tr>
</table>
<p>The <code>plot</code>-method invisibly returns <code>NULL</code>.
</p>
<p>A <code>toLatex</code>-method exists, which generates LaTeX code for the
contingency table associated with the Knox test.
</p>


<h3>Note</h3>

<p>The Poisson approximation works well if the proportions of close
pairs in both time and space are small (Kulldorff and Hjalmars,
1999), otherwise the Monte Carlo permutation approach is
recommended.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Knox, G. (1963):
Detection of low intensity epidemicity: application to cleft lip and palate.
<em>British Journal of Preventive &amp; Social Medicine</em>, <b>17</b>, 121-127.
</p>
<p>Knox, E. G. (1964):
The detection of space-time interactions.
<em>Journal of the Royal Statistical Society. Series C (Applied
Statistics)</em>, <b>13</b>, 25-30.
</p>
<p>Kulldorff, M. and Hjalmars, U. (1999):
The Knox method and other tests for space-time interaction.
<em>Biometrics</em>, <b>55</b>, 544-552.
</p>
<p>Mantel, N. (1967):
The detection of disease clustering and a generalized regression approach.
<em>Cancer Research</em>, <b>27</b>, 209-220.
</p>
<p>Meyer, S., Warnke, I., Rössler, W. and Held, L. (2016):
Model-based testing for space-time interaction using point processes:
An application to psychiatric hospital admissions in an urban area.
<em>Spatial and Spatio-temporal Epidemiology</em>, <b>17</b>, 15-25.
<a href="https://doi.org/10.1016/j.sste.2016.03.002">doi:10.1016/j.sste.2016.03.002</a>.
Eprint: <a href="https://arxiv.org/abs/1512.09052">https://arxiv.org/abs/1512.09052</a>.
</p>


<h3>See Also</h3>

<p>The function <code>mantel.randtest</code> in package <span class="pkg">ade4</span>
implements Mantel's (1967) space-time interaction test, i.e., using
the Pearson correlation between the spatial and temporal distances of
all event pairs as the test statistic, and assessing statistical
significance using a Monte Carlo permutation approach as with
<code>simulate.p.value</code> here in the <code>knox</code> function.
To combine information from different scales <code>eps.t</code> and
<code>eps.s</code> while also handling edge effects, the space-time
K-function test available via <code><a href="#topic+stKtest">stKtest</a></code> can be used.
Function <code><a href="#topic+epitest">epitest</a></code> tests epidemicity in a
<code>"<a href="#topic+twinstim">twinstim</a>"</code> point process model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi")
imdepiB &lt;- subset(imdepi, type == "B")

## Perfom the Knox test using the Poisson approximation
knoxtest &lt;- knox(
    dt = dist(imdepiB$events$time), eps.t = 30,
    ds = dist(coordinates(imdepiB$events)), eps.s = 50,
    simulate.p.value = FALSE
)
knoxtest
## The Poisson approximation works well for these data since
## the proportion of close pairs is rather small (204/56280).

## contingency table in LaTeX
toLatex(knoxtest)


## Obtain the p-value via a Monte Carlo permutation test,
## where the permutations can be computed in parallel
## (using forking on Unix-alikes and a cluster on Windows, see ?plapply)
knoxtestMC &lt;- knox(
    dt = dist(imdepiB$events$time), eps.t = 30,
    ds = dist(coordinates(imdepiB$events)), eps.s = 50,
    simulate.p.value = TRUE, B = 99,  # limited here for speed
    .parallel = 2, .seed = 1, .verbose = FALSE
)
knoxtestMC
plot(knoxtestMC)
</code></pre>

<hr>
<h2 id='ks.plot.unif'>
Plot the ECDF of a uniform sample with Kolmogorov-Smirnov bounds
</h2><span id='topic+ks.plot.unif'></span>

<h3>Description</h3>

<p>This plot function takes a univariate sample that should be tested for
a U(0,1) distribution, plots its empirical cumulative distribution
function (<code><a href="stats.html#topic+ecdf">ecdf</a></code>), and adds a confidence band by inverting
the corresponding Kolmogorov-Smirnov test (<code><a href="stats.html#topic+ks.test">ks.test</a></code>). The
uniform distribution is rejected if the ECDF is not completely inside
the confidence band.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ks.plot.unif(U, conf.level = 0.95, exact = NULL,
             col.conf = "gray", col.ref = "gray",
             xlab = expression(u[(i)]), ylab = "Cumulative distribution")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ks.plot.unif_+3A_u">U</code></td>
<td>

<p>numeric vector containing the sample.
Missing values are (silently) ignored.
</p>
</td></tr>
<tr><td><code id="ks.plot.unif_+3A_conf.level">conf.level</code></td>
<td>

<p>confidence level for the K-S-test (defaults to 0.95), can also be a
vector of multiple levels.
</p>
</td></tr>
<tr><td><code id="ks.plot.unif_+3A_exact">exact</code></td>
<td>
<p>see <code><a href="stats.html#topic+ks.test">ks.test</a></code>.</p>
</td></tr>
<tr><td><code id="ks.plot.unif_+3A_col.conf">col.conf</code></td>
<td>

<p>colour of the confidence lines.
</p>
</td></tr>
<tr><td><code id="ks.plot.unif_+3A_col.ref">col.ref</code></td>
<td>

<p>colour of the diagonal reference line.
</p>
</td></tr>
<tr><td><code id="ks.plot.unif_+3A_xlab">xlab</code>, <code id="ks.plot.unif_+3A_ylab">ylab</code></td>
<td>

<p>axis labels.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code> (invisibly).
</p>


<h3>Author(s)</h3>

<p>Michael Höhle and Sebastian Meyer.
</p>
<p>The code re-uses fragments from the <a href="stats.html#topic+ks.test">ks.test</a> source file
<a href="https://svn.R-project.org/R/trunk/src/library/stats/R/ks.test.R">https://svn.R-project.org/R/trunk/src/library/stats/R/ks.test.R</a>,
with Copyright (C) 1995-2022 The R Core Team, available under GPL-2
(or later), and C functionality from the source file
<a href="https://svn.R-project.org/R/trunk/src/library/stats/src/ks.c">https://svn.R-project.org/R/trunk/src/library/stats/src/ks.c</a>,
partially based on code published in Marsaglia et al. (2003),
with Copyright (C) 1999-2022 The R Core Team, also available under
GPL-2 (or later).
</p>


<h3>References</h3>

<p>George Marsaglia and Wai Wan Tsang and Jingbo Wang (2003):
Evaluating Kolmogorov's distribution.
<em>Journal of Statistical Software</em>, <b>8</b> (18).
<a href="https://doi.org/10.18637/jss.v008.i18">doi:10.18637/jss.v008.i18</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ks.test">ks.test</a></code> for the Kolmogorov-Smirnov test, as well as
<code><a href="#topic+checkResidualProcess">checkResidualProcess</a></code>, which makes use of this plot
function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>samp &lt;- runif(99)
ks.plot.unif(samp, conf.level=c(0.95, 0.99), exact=TRUE)
ks.plot.unif(samp, conf.level=c(0.95, 0.99), exact=FALSE)
</code></pre>

<hr>
<h2 id='layout.labels'>
Layout Items for <code>spplot</code>
</h2><span id='topic+layout.labels'></span><span id='topic+layout.scalebar'></span>

<h3>Description</h3>

<p>Generate <code>sp.layout</code> items for use by <code><a href="sp.html#topic+spplot">spplot</a></code>
or plot these items directly in the traditional graphics system.
Function <code>layout.labels</code> draws labels at the coordinates of the
spatial object, and <code>layout.scalebar</code> returns a labeled scale bar.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layout.labels(obj, labels = TRUE, plot = FALSE)

layout.scalebar(obj, corner = c(0.05, 0.95), scale = 1,
                labels = c(0, scale), height = 0.05,
                pos = 3, ..., plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layout.labels_+3A_obj">obj</code></td>
<td>

<p>an object inheriting from a <code><a href="sp.html#topic+Spatial-class">Spatial</a></code> class.
</p>
</td></tr>
<tr><td><code id="layout.labels_+3A_labels">labels</code></td>
<td>

<p>specification of the labels. For <code>layout.labels</code>:
</p>

<ul>
<li><p> a <code>FALSE</code> or <code>NULL</code> value omits labels
(<code>NULL</code> is returned),
</p>
</li>
<li> <p><code>labels = TRUE</code> uses <code>row.names(obj)</code>,
</p>
</li>
<li><p> a character or numeric index for a column of <code>obj@data</code>
which contains suitable labels,
</p>
</li>
<li><p> a vector of length <code>length(obj)</code> with labels,
</p>
</li>
<li><p> or a list of arguments for <code><a href="lattice.html#topic+panel.text">panel.text</a></code>,
where the optional <code>labels</code> component follows the same rules
as above.
</p>
</li></ul>

<p>For <code>layout.scalebar</code>, a character vector of length two giving
the labels to be put above the left and right ends of the scale bar.
</p>
</td></tr>
<tr><td><code id="layout.labels_+3A_corner">corner</code></td>
<td>

<p>the location of the scale bar in the unit square, where
<code>c(0,0)</code> refers to the bottom left corner. By default, the
scale bar is placed in the top left corner (with a small buffer).
</p>
</td></tr>
<tr><td><code id="layout.labels_+3A_scale">scale</code></td>
<td>

<p>the width of the scale bar in the units of <code><a href="sp.html#topic+proj4string">proj4string</a>(obj)</code>.
If <code>identical(FALSE, <a href="sp.html#topic+is.projected">is.projected</a>(obj))</code>
(i.e., <code>obj</code> has longlat coordinates), <code>scale</code> is
interpreted in kilometres.
</p>
</td></tr>
<tr><td><code id="layout.labels_+3A_height">height</code></td>
<td>

<p>the height of the scale bar, see <code><a href="sp.html#topic+layout.scale.bar">layout.scale.bar</a></code>.
</p>
</td></tr>
<tr><td><code id="layout.labels_+3A_pos">pos</code></td>
<td>

<p>a position specifier for the labels (see <code><a href="graphics.html#topic+text">text</a></code>).
By default, the labels are plotted above the scale bar.
</p>
</td></tr>
<tr><td><code id="layout.labels_+3A_...">...</code></td>
<td>

<p>further arguments for <code><a href="lattice.html#topic+panel.text">panel.text</a></code> (if
<code>plot = FALSE</code>) or <code><a href="graphics.html#topic+text">text</a></code> (if <code>plot = TRUE</code>)
to change the style of the labels, e.g., <code>cex</code>, <code>col</code>,
and <code>font</code>.
</p>
</td></tr>
<tr><td><code id="layout.labels_+3A_plot">plot</code></td>
<td>

<p>logical indicating if the layout item should be plotted using the
traditional graphics system. By default (<code>FALSE</code>), a list for
subsequent use by <code><a href="sp.html#topic+spplot">spplot</a></code> is returned.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>layout.labels</code>, a single <code>sp.layout</code> item, which is
a list with first element <code>"panel.text"</code> and subsequent elements
being arguments to that function based on the <code>labels</code>
specification.
</p>
<p>For <code>layout.scalebar</code>, a list of <code>sp.layout</code> items
comprising the polygonal scale bar and the labels.
</p>
<p>If these layout functions are called with <code>plot = TRUE</code>,
the item is plotted directly using traditional graphics functions
and <code>NULL</code> is returned.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("sf")) { # required by recent 'sp'

## districts in the Regierungsbezirk Weser-Ems (longlat coordinates)
data("measlesWeserEms")
mapWE &lt;- measlesWeserEms@map
li1 &lt;- layout.labels(mapWE, labels = list(font=2, labels="GEN"))
li2 &lt;- layout.scalebar(mapWE, corner = c(0.05, 0.05), scale = 20,
                       labels = c("0", "20 km"))
spplot(mapWE, zcol = "AREA", sp.layout = c(list(li1), li2),
       col.regions = rev(heat.colors(100)), scales = list(draw = TRUE))

## districts in Bavaria (projected coordinates)
load(system.file("shapes", "districtsD.RData", package = "surveillance"))
bavaria &lt;- districtsD[substr(row.names(districtsD), 1, 2) == "09", ]
sb &lt;- layout.scalebar(bavaria, corner = c(0.75,0.9), scale = 50,
                      labels = c("0", "50 km"), cex = 0.8)
spplot(bavaria, zcol = "POPULATION", sp.layout = sb,
       xlab = "x [km]", ylab = "y [km]", scales = list(draw = TRUE),
       col.regions = rev(heat.colors(100)))

## these layout functions also work in the traditional graphics system
par(mar = c(0,0,0,0))
plot(bavaria, col = "lavender")
layout.scalebar(bavaria, corner = c(0.75, 0.9), scale = 50,
                labels = c("0", "50 km"), plot = TRUE)
layout.labels(bavaria, labels = list(cex = 0.8,
              labels = substr(bavaria$GEN, 1, 3)), plot = TRUE)

}
</code></pre>

<hr>
<h2 id='linelist2sts'>
Convert Dates of Individual Case Reports into a
Time Series of Counts
</h2><span id='topic+linelist2sts'></span>

<h3>Description</h3>

<p>The function is used to convert an individual line list of cases to an
aggregated time series of counts based on event date information of the cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linelist2sts(linelist,dateCol,
              aggregate.by=c("1 day", "1 week", "7 day", "1 week",
"1 month",  "3 month", "1 year"),
              dRange=NULL,
              epochInPeriodStr=switch(aggregate.by, "1 day"="1",
"1 week"="%u", "1 month"="%d","3 month"="%q","1 year"="%j"),
              startYearFormat=switch(aggregate.by,"1 day"="%Y",
"7 day"="%G", "1 week"="%G","1 month"="%Y","3 month"="%Y","1 year"="%Y"),
              startEpochFormat=switch(aggregate.by,"1 day"="%j",
"7 day"="%V", "1 week"="%V", "1 month"="%m", "3 month"="%Q", "1 year"="1")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linelist2sts_+3A_linelist">linelist</code></td>
<td>

<p>A <code>data.frame</code> containing the line list of cases.
</p>
</td></tr>
<tr><td><code id="linelist2sts_+3A_datecol">dateCol</code></td>
<td>
<p>A character string stating the column name in
<code>linelist</code> which contains the event occurrence information (as a
vector of <code>Date</code>s) which are to be temporally aggregated.
</p>
</td></tr>
<tr><td><code id="linelist2sts_+3A_aggregate.by">aggregate.by</code></td>
<td>
<p>Temporal aggregation level given as a string, see
the <code>by</code> variable of the <code><a href="base.html#topic+seq.Date">seq.Date</a></code> function for
further details.  
</p>
</td></tr>
<tr><td><code id="linelist2sts_+3A_drange">dRange</code></td>
<td>
<p>A vector containing the minimum and maximum date
for doing the aggregation. If not specified these dates are
extracted automatically by taking <code>range(D[,dateCol])</code> and
adjust these according to <code>aggregate.by</code> (e.g. always first of
a month).
</p>
</td></tr>
<tr><td><code id="linelist2sts_+3A_epochinperiodstr">epochInPeriodStr</code></td>
<td>
<p><code>strptime</code> compatible format string to use for
determining how a date is placed within the epoch. This is, e.g.,
used to move the <code>dRange</code> epochs to the beginning of the
period. Example: In case of weekly aggregation the &quot;%u&quot; determines
which day within the week (Monday is day 1) we have. See
<code><a href="base.html#topic+strptime">strptime</a></code> for further details.
</p>
</td></tr>
<tr><td><code id="linelist2sts_+3A_startyearformat">startYearFormat</code></td>
<td>
<p><code>strptime</code> compatible format string to use for
determining how the <code>start</code> entry of the <code>sts</code> object is
generated. Usually the provided defaults are sufficient.</p>
</td></tr>
<tr><td><code id="linelist2sts_+3A_startepochformat">startEpochFormat</code></td>
<td>
<p><code>strptime</code> compatible format string to use for
determining how the <code>start</code> entry of the <code>sts</code> object is
generated. Usually the provided defaults are sufficient.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The date range is automatically extended such that the starting and
ending dates are always the first epoch within the period, i.e. for
aggregation by week it is moved to Mondays. This is controlled by the
<code>epochInPeriodStr</code> parameter.
</p>
<p>Please note that the formatting strings are implemented by the
<code><a href="#topic+formatDate">formatDate</a></code> function, which uses <code><a href="base.html#topic+strptime">strptime</a></code>
formatting strings as well as
formatting of quarters via &quot;%Q&quot;, &quot;%OQ&quot; and &quot;%q&quot;.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.
The <code>freq</code> slot might not be appropriate.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+seq.Date">seq.Date</a></code>, <code><a href="base.html#topic+strptime">strptime</a></code>, <code><a href="#topic+formatDate">formatDate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Load O104 outbreak data
data("husO104Hosp")

#Convert line list to an sts object
sts &lt;- linelist2sts(husO104Hosp, dateCol="dHosp", aggregate.by="1 day")

#Check that the number of cases is correct
all.equal(sum(observed(sts)),nrow(husO104Hosp))

#Plot the result
plot(sts,xaxis.tickFreq=list("%d"=atChange,"%m"=atChange),
           xaxis.labelFreq=list("%d"=at2ndChange),
           xaxis.labelFormat="%d %b",
           xlab="",las=2,cex.axis=0.8)
</code></pre>

<hr>
<h2 id='LRCUSUM.runlength'>Run length computation of a CUSUM detector</h2><span id='topic+LRCUSUM.runlength'></span>

<h3>Description</h3>

<p>Compute run length for a count data or categorical CUSUM. The
computations are based on a Markov representation of the
likelihood ratio based CUSUM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRCUSUM.runlength(mu, mu0, mu1, h, dfun, n, g=5, outcomeFun=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRCUSUM.runlength_+3A_mu">mu</code></td>
<td>
<p><code class="reqn">k-1 \times T</code> matrix with true proportions, i.e. equal to mu0 or mu1 if one wants to compute e.g. <code class="reqn">ARL_0</code> or <code class="reqn">ARL_1</code>.</p>
</td></tr>
<tr><td><code id="LRCUSUM.runlength_+3A_mu0">mu0</code></td>
<td>
<p><code class="reqn">k-1 \times T</code> matrix with in-control proportions</p>
</td></tr>
<tr><td><code id="LRCUSUM.runlength_+3A_mu1">mu1</code></td>
<td>
<p><code class="reqn">k-1 \times T</code> matrix with out-of-control proportion</p>
</td></tr>
<tr><td><code id="LRCUSUM.runlength_+3A_h">h</code></td>
<td>
<p>The threshold h which is used for the CUSUM.</p>
</td></tr>
<tr><td><code id="LRCUSUM.runlength_+3A_dfun">dfun</code></td>
<td>
<p>The probability mass function or density used to compute
the likelihood ratios of the CUSUM. In a negative binomial CUSUM
this is <code>dnbinom</code>, in a binomial CUSUM <code>dbinom</code> and in a
multinomial CUSUM <code>dmultinom</code>.</p>
</td></tr>
<tr><td><code id="LRCUSUM.runlength_+3A_n">n</code></td>
<td>
<p>Vector of length <code class="reqn">T</code> containing the total number of
experiments for each time point.</p>
</td></tr>
<tr><td><code id="LRCUSUM.runlength_+3A_g">g</code></td>
<td>
<p>The number of levels to cut the state space into when
performing the Markov chain approximation. Sometimes also denoted
<code class="reqn">M</code>. Note that the quality of the approximation depends very
much on <code>g</code>. If <code class="reqn">T</code> is greater than, say, 50 it's necessary to
increase the value of <code>g</code>.</p>
</td></tr>
<tr><td><code id="LRCUSUM.runlength_+3A_outcomefun">outcomeFun</code></td>
<td>
<p>A hook <code>function (k,n)</code> to compute all possible outcome
states to compute the likelihood ratio for. If <code>NULL</code> then the
internal default function <code>surveillance:::outcomeFunStandard</code> is used. This
function uses the Cartesian product of <code>0:n</code> for <code>k</code> components.</p>
</td></tr>
<tr><td><code id="LRCUSUM.runlength_+3A_...">...</code></td>
<td>
<p>Additional arguments to send to <code>dfun</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Brook and Evans (1972) formulated an approximate approach based
on Markov chains to determine the PMF of the run length of a
time-constant CUSUM detector. They describe the dynamics of the CUSUM
statistic by a Markov chain with a discretized state space of
size <code class="reqn">g+2</code>. This is adopted to the time varying case in
Höhle (2010) and implemented in R using the ... notation
such that it works for a very large class of distributions.
</p>


<h3>Value</h3>

<p>A list with five components
</p>
<table>
<tr><td><code>P</code></td>
<td>
<p>An array of <code class="reqn">g+2 \times g+2</code> transition matrices of the
approximation Markov chain.</p>
</td></tr>
<tr><td><code>pmf</code></td>
<td>
<p>Probability mass function (up to length <code class="reqn">T</code>) of the run
length variable.</p>
</td></tr>
<tr><td><code>cdf</code></td>
<td>
<p>Cumulative density function (up to length <code class="reqn">T</code>) of the run
length variable.</p>
</td></tr>
<tr><td><code>arl</code></td>
<td>
<p>If the model is time homogenous (i.e. if <code class="reqn">T==1</code>) then
the ARL is computed based on the stationary distribution of the
Markov chain. See the eqns in the reference for details. Note: If
the model is not time homogeneous then the function returns
<code>NA</code> and the ARL has to be approximated manually from the
output. One could use <code>sum(1:length(pmf) * pmf)</code>, which is an
approximation because of using a finite support for a sum which
should be from 1 to infinity.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>M. Höhle</p>


<h3>References</h3>

<p>Höhle, M. (2010):
Online change-point detection in categorical time series. 
In: T. Kneib and G. Tutz (Eds.), Statistical
Modelling and Regression Structures - Festschrift in Honour of Ludwig
Fahrmeir, Physica-Verlag, pp. 377-397. Preprint available as
<a href="https://staff.math.su.se/hoehle/pubs/hoehle2010-preprint.pdf">https://staff.math.su.se/hoehle/pubs/hoehle2010-preprint.pdf</a>
</p>
<p>Höhle, M. and Mazick, A. (2010):
Aberration detection in R illustrated
by Danish mortality monitoring. In: T. Kass-Hout
and X. Zhang (Eds.), Biosurveillance: A Health Protection Priority,
CRCPress. Preprint available as
<a href="https://staff.math.su.se/hoehle/pubs/hoehle_mazick2009-preprint.pdf">https://staff.math.su.se/hoehle/pubs/hoehle_mazick2009-preprint.pdf</a>
</p>
<p>Brook, D. and Evans, D. A. (1972):  An approach to the probability
distribution of cusum run length. <em>Biometrika</em> <b>59</b>(3):539-549.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+categoricalCUSUM">categoricalCUSUM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>######################################################
#Run length of a time constant negative binomial CUSUM
######################################################

#In-control and out of control parameters
mu0 &lt;- 10
alpha &lt;- 1/2
kappa &lt;- 2

#Density for comparison in the negative binomial distribution
dY &lt;- function(y,mu,log=FALSE, alpha, ...) {
  dnbinom(y, mu=mu, size=1/alpha, log=log)
}

#In this case "n" is the maximum value to investigate the LLR for
#It is assumed that beyond n the LLR is too unlikely to be worth
#computing.
LRCUSUM.runlength( mu=t(mu0), mu0=t(mu0), mu1=kappa*t(mu0), h=5,
  dfun = dY, n=rep(100,length(mu0)), alpha=alpha)

h.grid &lt;- seq(3,6,by=0.3)
arls &lt;- sapply(h.grid, function(h) {
  LRCUSUM.runlength( mu=t(mu0), mu0=t(mu0), mu1=kappa*t(mu0), h=h,
  dfun = dY, n=rep(100,length(mu0)), alpha=alpha,g=20)$arl
})
plot(h.grid, arls,type="l",xlab="threshold h",ylab=expression(ARL[0]))


######################################################
#Run length of a time varying negative binomial CUSUM
######################################################

mu0 &lt;- matrix(5*sin(2*pi/52 * 1:200) + 10,ncol=1)

rl &lt;- LRCUSUM.runlength( mu=t(mu0), mu0=t(mu0), mu1=kappa*t(mu0), h=2,
  dfun = dY, n=rep(100,length(mu0)), alpha=alpha,g=20)

plot(1:length(mu0),rl$pmf,type="l",xlab="t",ylab="PMF")
plot(1:length(mu0),rl$cdf,type="l",xlab="t",ylab="CDF")


########################################################
# Further examples contain the binomial, beta-binomial
# and multinomial CUSUMs. Hopefully, these will be added
# in the future.
########################################################

#dfun function for the multinomial distribution (Note: Only k-1 categories are specified).
dmult &lt;- function(y, size,mu, log = FALSE) {
    return(dmultinom(c(y,size-sum(y)), size = size, prob=c(mu,1-sum(mu)), log = log))
}

#Example for the time-constant multinomial distribution
#with size 100 and in-control and out-of-control parameters as below.
n &lt;- 100
pi0 &lt;- as.matrix(c(0.5,0.3,0.2))
pi1 &lt;- as.matrix(c(0.38,0.46,0.16))

#ARL_0
LRCUSUM.runlength(mu=pi0[1:2,,drop=FALSE],mu0=pi0[1:2,,drop=FALSE],mu1=pi1[1:2,,drop=FALSE],
                  h=5,dfun=dmult, n=n, g=15)$arl
#ARL_1
LRCUSUM.runlength(mu=pi1[1:2,,drop=FALSE],mu0=pi0[1:2,,drop=FALSE],mu1=pi1[1:2,,drop=FALSE],
                  h=5,dfun=dmult, n=n, g=15)$arl


</code></pre>

<hr>
<h2 id='m1'>RKI SurvStat Data</h2><span id='topic+m1'></span><span id='topic+h1_nrwrp'></span><span id='topic+k1'></span><span id='topic+m2'></span><span id='topic+m3'></span><span id='topic+m4'></span><span id='topic+m5'></span><span id='topic+n1'></span><span id='topic+n2'></span><span id='topic+q1_nrwh'></span><span id='topic+q2'></span><span id='topic+s1'></span><span id='topic+s2'></span><span id='topic+s3'></span>

<h3>Description</h3>

<p>14 datasets for different diseases beginning in
2001 to the 3rd Quarter of 2004 including their defined outbreaks.
</p>

<ul>
<li> <p><code>m1</code> 'Masern' in the 'Landkreis Nordfriesland' (Germany, Schleswig-Holstein)
</p>
</li>
<li> <p><code>m2</code> 'Masern' in the 'Stadt- und Landkreis Coburg' (Germany, Bayern)
</p>
</li>
<li> <p><code>m3</code> 'Masern' in the 'Kreis Leer' (Germany, Niedersachsen)
</p>
</li>
<li> <p><code>m4</code> 'Masern' in the 'Stadt- und Landkreis Aachen' (Germany, Nordrhein-Westfalen)
</p>
</li>
<li> <p><code>m5</code> 'Masern' in the 'Stadt Verden' (Germany, Niedersachsen)
</p>
</li>
<li> <p><code>q1_nrwh</code> 'Q-Fieber' in the 'Hochsauerlandkreis' (Germany, Westfalen)
and in the 'Landkreis Waldeck-Frankenberg' (Germany, Hessen)
</p>
</li>
<li> <p><code>q2</code> 'Q-Fieber' in 'München' (Germany, Bayern)
</p>
</li>
<li> <p><code>s1</code> 'Salmonella Oranienburg' in Germany
</p>
</li>
<li> <p><code>s2</code> 'Salmonella Agona' in 12 'Bundesländern' of Germany
</p>
</li>
<li> <p><code>s3</code> 'Salmonella Anatum' in Germany
</p>
</li>
<li> <p><code>k1</code> 'Kryptosporidiose' in Germany, 'Baden-Württemberg'
</p>
</li>
<li> <p><code>n1</code> 'Norovirus' in 'Stadtkreis Berlin Mitte' (Germany, Berlin)
</p>
</li>
<li> <p><code>n2</code> 'Norovirus' in 'Torgau-Oschatz' (Germany, Sachsen)
</p>
</li>
<li> <p><code>h1_nrwrp</code> 'Hepatitis A' in 'Oberbergischer Kreis, Olpe, Rhein-Sieg-kreis'
(Germany, Nordrhein-Westfalen) and 'Siegenwittgenstein Altenkirchen' (Germany, Rheinland-Pfalz)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(m1)</code></pre>


<h3>Format</h3>

<p><code>disProg</code> objects each containing 209 observations (weekly on 52 weeks)
</p>

<dl>
<dt>observed</dt><dd><p>Number of counts in the corresponding week</p>
</dd>
<dt>state</dt><dd><p>Boolean whether there was an outbreak.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Robert Koch-Institut: SurvStat:
<a href="https://survstat.rki.de/">https://survstat.rki.de/</a>;
m1 and m3 were queried on 10 November 2004. The rest during September 2004.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(k1)
survResObj &lt;- algo.rki1(k1, control=list(range=27:192))
plot(survResObj, "RKI 1", "k1")
</code></pre>

<hr>
<h2 id='magic.dim'>Compute Suitable k1 x k2 Layout for Plotting</h2><span id='topic+magic.dim'></span>

<h3>Description</h3>

<p>For a given number <code>k</code>, <code>magic.dim</code> provides a vector 
containing two elements, the number of rows (k1) and columns (k2),
respectively, which can be used to set the 
dimension of a single graphic device so that k1*k2 plots can be 
drawn by row (or by column) on the device.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>      magic.dim(k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="magic.dim_+3A_k">k</code></td>
<td>
<p>an integer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector with two elements</p>


<h3>See Also</h3>

<p><code><a href="#topic+primeFactors">primeFactors</a></code> and <code><a href="#topic+bestCombination">bestCombination</a></code> which are
internally used to complete the task.
</p>
<p><code><a href="grDevices.html#topic+n2mfrow">n2mfrow</a></code> is a similar function from package <span class="pkg">grDevices</span>.
</p>

<hr>
<h2 id='makeControl'>Generate <code>control</code> Settings for an <code>hhh4</code> Model</h2><span id='topic+makeControl'></span>

<h3>Description</h3>

<p>Generate <code>control</code> Settings for an <code>hhh4</code> Model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeControl(f = list(~1), S = list(0, 0, 1), period = 52, offset = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeControl_+3A_f">f</code>, <code id="makeControl_+3A_s">S</code>, <code id="makeControl_+3A_period">period</code></td>
<td>

<p>arguments for <code><a href="#topic+addSeason2formula">addSeason2formula</a></code> defining
each of the three model formulae in the order (<code>ar</code>, <code>ne</code>,
<code>end</code>). Recycled if necessary within <code><a href="base.html#topic+mapply">mapply</a></code>.
</p>
</td></tr>
<tr><td><code id="makeControl_+3A_offset">offset</code></td>
<td>

<p>multiplicative component offsets in the order (<code>ar</code>,
<code>ne</code>, <code>end</code>).
</p>
</td></tr>
<tr><td><code id="makeControl_+3A_...">...</code></td>
<td>

<p>further elements for the <code><a href="#topic+hhh4">hhh4</a></code> control list. The
<code>family</code> parameter is set to <code>"NegBin1"</code> by default.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list for use as the <code>control</code> argument in <code><a href="#topic+hhh4">hhh4</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>makeControl()

## a simplistic model for the fluBYBW data
## (first-order transmission only, no district-specific intercepts)
data("fluBYBW")
mycontrol &lt;- makeControl(
    f = list(~1, ~1, ~t), S = c(1, 1, 3),
    offset = list(population(fluBYBW)),  # recycled -&gt; in all components
    ne = list(normalize = TRUE),
    verbose = TRUE)
str(mycontrol)

## fit this model
fit &lt;- hhh4(fluBYBW, mycontrol)
</code></pre>

<hr>
<h2 id='marks'>Import from package <span class="pkg">spatstat.geom</span></h2><span id='topic+marks'></span>

<h3>Description</h3>

<p>The generic function <code>marks</code> is imported from package <span class="pkg">spatstat.geom</span>.
See <code><a href="spatstat.geom.html#topic+marks">spatstat.geom::marks</a></code> for <span class="pkg">spatstat.geom</span>'s
own methods, and <code><a href="#topic+marks.epidataCS">marks.epidataCS</a></code> for the
<code>"epidataCS"</code>-specific method.
</p>

<hr>
<h2 id='measles.weser'>Measles in the Weser-Ems region of Lower Saxony, Germany, 2001-2002</h2><span id='topic+measles.weser'></span><span id='topic+measlesWeserEms'></span>

<h3>Description</h3>

<p>Weekly counts of new measles cases for the 17 administrative
districts (NUTS-3 level) of the &ldquo;Weser-Ems&rdquo; region of Lower
Saxony, Germany, during 2001 and 2002, as reported to the Robert Koch
institute according to the Infection Protection Act
(&ldquo;Infektionsschutzgesetz&rdquo;, <abbr><span class="acronym">IfSG</span></abbr>).<br />
<code>data("measlesWeserEms")</code> is a corrected version of
<code>data("measles.weser")</code> (see Format section below).
These data are illustrated and analyzed in Meyer et al. (2017, Section 5),
see <code>vignette("hhh4_spacetime")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("measles.weser")
data("measlesWeserEms")
</code></pre>


<h3>Format</h3>

<p><code>data("measles.weser")</code> is an object of the old <code>"disProg"</code>
class, whereas <code>data("measlesWeserEms")</code> is of the new class
<code>"<a href="#topic+sts-class">sts</a>"</code>.
</p>
<p>Furthermore, the following updates have been applied for
<code>data("measlesWeserEms")</code>:
</p>

<ul>
<li><p> it includes the two districts &ldquo;SK Delmenhorst&rdquo; (03401) and
&ldquo;SK Wilhemshaven&rdquo; (03405) with zero counts, which are ignored in
<code>data("measles.weser")</code>.
</p>
</li>
<li><p> it corrects the time lag error for year 2002 caused by a
redundant pseudo-week &ldquo;0&rdquo; with 0 counts only
(the row <code>measles.weser$observed[53,]</code> is nonsense).
</p>
</li>
<li><p> it has one more case attributed to &ldquo;LK Oldenburg&rdquo;
(03458) during 2001/W17, i.e., 2 cases instead of 1. This reflects
the official data as of &ldquo;Jahrbuch 2005&rdquo;, whereas
<code>data("measles.weser")</code> is as of &ldquo;Jahrbuch 2004&rdquo;.
</p>
</li>
<li><p> it contains a map of the region (as a
<code>"<a href="sp.html#topic+SpatialPolygonsDataFrame-class">SpatialPolygonsDataFrame</a>"</code>) with the following
variables:
</p>

<dl>
<dt><code>GEN</code></dt><dd><p>district label.</p>
</dd>
<dt><code>AREA</code></dt><dd><p>district area in m^2.</p>
</dd>
<dt><code>POPULATION</code></dt><dd><p>number of inhabitants (as of 31/12/2003).</p>
</dd>
<dt><code>vaccdoc.2004</code></dt><dd><p>proportion with a vaccination card
among screened abecedarians (2004).</p>
</dd>
<dt><code>vacc1.2004</code></dt><dd><p>proportion with at least one vaccination
against measles among abecedarians presenting a vaccination card
(2004).</p>
</dd>
<dt><code>vacc2.2004</code></dt><dd><p>proportion of doubly vaccinated
abecedarians among the ones presenting their vaccination card at
school entry in the year 2004.</p>
</dd>
</dl>

</li>
<li><p> it uses the correct format for the official district keys,
i.e., 5 digits (initial 0).
</p>
</li>
<li><p> its attached neighbourhood matrix is more general: a distance matrix
(neighbourhood orders) instead of just an adjacency indicator matrix
(special case <code>nbOrder == 1</code>).
</p>
</li>
<li><p> population fractions represent data as of 31/12/2003 (<abbr><span class="acronym">LSN</span></abbr>,
2004, document &ldquo;A I 2 - hj 2 / 2003&rdquo;). There are only
minor differences to the ones used for <code>data("measles.weser")</code>.
</p>
</li></ul>



<h3>Source</h3>

<p>Measles counts were obtained from the public SurvStat database of the
Robert Koch institute: <a href="https://survstat.rki.de/">https://survstat.rki.de/</a>.
</p>
<p>A shapefile of Germany's districts as of 01/01/2009 was obtained from
the German Federal Agency for Cartography and Geodesy
(<a href="https://gdz.bkg.bund.de/">https://gdz.bkg.bund.de/</a>).
The map of the 17 districts of the &ldquo;Weser-Ems&rdquo; region
(<code>measlesWeserEms@map</code>) is a simplified subset of this
shapefile using a 30% reduction via the Douglas-Peucker reduction method
as implemented at <a href="https://MapShaper.org">https://MapShaper.org</a>.
</p>
<p>Population numbers were obtained from the Federal Statistical Office of
Lower Saxony (<abbr><span class="acronym">LSN</span></abbr>).

</p>
<p>Vaccination coverage was obtained from the public health department of
Lower Saxony (<abbr><span class="acronym">NLGA</span></abbr>, &ldquo;Impfreport&rdquo;).




</p>


<h3>References</h3>

<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## old "disProg" object
data("measles.weser")
measles.weser
plot(measles.weser, as.one=FALSE)

## new "sts" object (with corrections)
data("measlesWeserEms")
measlesWeserEms
plot(measlesWeserEms)
</code></pre>

<hr>
<h2 id='measlesDE'>Measles in the 16 states of Germany</h2><span id='topic+measlesDE'></span>

<h3>Description</h3>

<p>Weekly number of measles cases in the 16 states
(Bundeslaender) of Germany for years 2005 to 2007.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(measlesDE)</code></pre>


<h3>Format</h3>

<p>An <code>"<a href="#topic+sts-class">sts</a>"</code> object containing <code class="reqn">156\times 16</code>
observations starting from week 1 in 2005.
</p>
<p>The <code>population</code> slot contains the population fractions
of each state at 31.12.2006, obtained from the Federal Statistical
Office of Germany.
</p>


<h3>Source</h3>

<p>Robert Koch-Institut: SurvStat:
<a href="https://survstat.rki.de/">https://survstat.rki.de/</a>;
Queried on 14 October 2009. 
</p>


<h3>References</h3>

<p>Herzog, S. A., Paul, M. and Held, L. (2011):
Heterogeneity in vaccination coverage explains the size and
occurrence of measles epidemics in German surveillance data.
<em>Epidemiology and Infection</em>, <b>139</b>, 505-515.
<a href="https://doi.org/10.1017/S0950268810001664">doi:10.1017/S0950268810001664</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MMRcoverageDE">MMRcoverageDE</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(measlesDE)
plot(measlesDE)

## aggregate to bi-weekly intervals
measles2w &lt;- aggregate(measlesDE, nfreq = 26)
plot(measles2w, type = observed ~ time)

## use a date index for nicer x-axis plotting
epoch(measles2w) &lt;- seq(as.Date("2005-01-03"), by = "2 weeks",
                        length.out = nrow(measles2w))
plot(measles2w, type = observed ~ time)
</code></pre>

<hr>
<h2 id='meningo.age'>Meningococcal infections in France 1985-1997</h2><span id='topic+meningo.age'></span>

<h3>Description</h3>

<p>Monthly counts of meningococcal infections in France 1985-1997.
Here, the data is split into 4 age groups (&lt;1, 1-5, 5-20, &gt;20).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(meningo.age)</code></pre>


<h3>Format</h3>

<p>An object of class <code>disProg</code> with 156 observations in each of 4 age groups.
</p>

<dl>
<dt>week</dt><dd><p>Month index</p>
</dd>
<dt>observed</dt><dd><p>Matrix with number of counts in the corresponding month and age group</p>
</dd>
<dt>state</dt><dd><p>Boolean whether there was an outbreak &ndash; dummy not implemented</p>
</dd>
<dt>neighbourhood</dt><dd><p>Neighbourhood matrix, all age groups are adjacent</p>
</dd>
<dt>populationFrac</dt><dd><p>Population fractions</p>
</dd> 
</dl>



<h3>Source</h3>

<p>??
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(meningo.age)
plot(meningo.age, title="Meningococcal infections in France 1985-97")
plot(meningo.age, as.one=FALSE)
</code></pre>

<hr>
<h2 id='MMRcoverageDE'>MMR coverage levels in the 16 states of Germany</h2><span id='topic+MMRcoverageDE'></span>

<h3>Description</h3>

<p>Coverage levels at school entry for the first and second dose
of the combined measles-mumps-rubella (MMR) vaccine in 2006, estimated 
from children presenting vaccination documents at school entry examinations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MMRcoverageDE)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> containing 19 rows and 5 columns with variables
</p>

<dl>
<dt>state</dt><dd><p>Names of states: the 16 federal states are
followed by the total of Germany, as well as the total 
of West and East Germany.</p>
</dd>
<dt>nOfexaminedChildren</dt><dd><p>Number of children examined.</p>
</dd>
<dt>withVaccDocument</dt><dd><p>Percentage of children who presented vaccination documents.</p>
</dd>
<dt>MMR1</dt><dd><p>Percentage of children with vaccination documents, who
received at least 1 dose of MMR vaccine.</p>
</dd>
<dt>MMR2</dt><dd><p>Percentage of children with vaccination documents, who
received at least 2 doses of MMR vaccine.</p>
</dd>
</dl>
 
<p>Coverage levels were derived from vaccination documents presented
at medical examinations, which are conducted by local health authorities
at school entry each year. Records include information about the receipt 
of 1st and 2nd doses of MMR, but no information about dates.
Note that information from children who did not present a vaccination 
document on the day of the medical examination, is not included in
the estimated coverage. 
</p>


<h3>Source</h3>

<p>Robert Koch-Institut (2008) Zu den Impfquoten bei den 
Schuleingangsuntersuchungen in Deutschland 2006. 
Epidemiologisches Bulletin, <b>7</b>, 55-57
</p>


<h3>References</h3>

<p>Herzog, S.A., Paul, M. and Held, L. (2011) Heterogeneity in vaccination
coverage explains the size and occurrence of measles epidemics in
German surveillance data. Epidemiology and Infection, <b>139</b>, 505&ndash;515.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+measlesDE">measlesDE</a></code></p>

<hr>
<h2 id='momo'>Danish 1994-2008 all-cause mortality data for eight age groups</h2><span id='topic+momo'></span>

<h3>Description</h3>

<p>Weekly number of all cause mortality from 1994-2008 in each
of the eight age groups &lt;1, 1-4, 5-14, 15-44, 45-64, 65-74,
75-84 and 85+ years, see Höhle and Mazick (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(momo)</code></pre>


<h3>Format</h3>

<p>An object of class <code>"<a href="#topic+sts-class">sts</a>"</code> containing the weekly
number of all-cause deaths in Denmark, 1994-2008 (782 weeks), for each
of the eight age groups &lt;1, 1-4, 5-14, 15-44, 45-64, 65-74,
75-84 and 85+ years. A special feature of the EuroMOMO data is that
weeks follow the ISO 8601 standard, which can be
handled by the <code>"sts"</code> class.
</p>
<p>The <code>population</code> slot of the <code>momo</code> object contains the
population size in each of the eight age groups.
These are yearly data obtained from the StatBank Denmark.
</p>


<h3>Source</h3>

<p><em>European monitoring of excess mortality for public health action</em>
(EuroMOMO) project. <a href="https://www.euromomo.eu/">https://www.euromomo.eu/</a>.
</p>
<p>Department of Epidemiology, Statens Serum Institute, Copenhagen, Denmark
StatBank Denmark, Statistics Denmark, <a href="https://www.statistikbanken.dk/">https://www.statistikbanken.dk/</a>
</p>


<h3>References</h3>

<p>Höhle, M. and Mazick, A. (2010). Aberration detection in R
illustrated by Danish mortality monitoring. In T. Kass-Hout and X.
Zhang (eds.), <em>Biosurveillance: A Health Protection Priority</em>,
chapter 12. Chapman &amp; Hall/CRC.<br />
Preprint available at
<a href="https://staff.math.su.se/hoehle/pubs/hoehle_mazick2009-preprint.pdf">https://staff.math.su.se/hoehle/pubs/hoehle_mazick2009-preprint.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("momo")
momo

## show the period 2000-2008 with customized x-axis annotation
## (this is Figure 1 in Hoehle and Mazick, 2010)
oopts &lt;- surveillance.options("stsTickFactors" = c("%G" = 1.5, "%Q"=.75))
plot(momo[year(momo) &gt;= 2000,], ylab = "", xlab = "Time (weeks)",
     par.list = list(las = 1), col = c(gray(0.5), NA, NA),
     xaxis.tickFreq = list("%G"=atChange, "%Q"=atChange),
     xaxis.labelFreq = list("%G"=atChange), xaxis.labelFormat = "%G")
surveillance.options(oopts)


## stratified monitoring from 2007-W40 using the Farrington algorithm
phase2 &lt;- which(epoch(momo) &gt;= "2007-10-01")
momo2 &lt;- farrington(momo, control = list(range=phase2, alpha=0.01, b=5, w=4))
colSums(alarms(momo2))
plot(momo2, col = c(8, NA, 4), same.scale = FALSE)

## stripchart of alarms (Figure 5 in Hoehle and Mazick, 2010)
plot(momo2, type = alarm ~ time, xlab = "Time (weeks)", main = "",
     alarm.symbol = list(pch=3, col=1, cex=1.5))

</code></pre>

<hr>
<h2 id='multiplicity'>Import from package <span class="pkg">spatstat.geom</span></h2><span id='topic+multiplicity'></span>

<h3>Description</h3>

<p>The generic function <code>multiplicity</code> is imported from package <span class="pkg">spatstat.geom</span>.
See <code><a href="spatstat.geom.html#topic+multiplicity">spatstat.geom::multiplicity</a></code> for
<span class="pkg">spatstat.geom</span>'s own methods, and <code><a href="#topic+multiplicity.Spatial">multiplicity.Spatial</a></code> for the
added method for <code><a href="sp.html#topic+Spatial-class">Spatial</a></code> objects.
</p>

<hr>
<h2 id='multiplicity.Spatial'>
Count Number of Instances of Points
</h2><span id='topic+multiplicity.Spatial'></span>

<h3>Description</h3>

<p>The generic function <code>multiplicity</code> defined in <span class="pkg">spatstat.geom</span> is
intended to count the number of duplicates of each element of an object.
<span class="pkg">spatstat.geom</span> already offers methods for point patterns, matrices and
data frames, and here we add a method for <code>Spatial</code> objects from
the <span class="pkg">sp</span> package. It is a wrapper for the default method, which
effectively computes the distance matrix of the points,
and then just counts the number of zeroes in each row.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Spatial'
multiplicity(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiplicity.Spatial_+3A_x">x</code></td>
<td>

<p>a <code>"<a href="sp.html#topic+Spatial-class">Spatial</a>"</code> object (we only need a
<code><a href="sp.html#topic+coordinates">coordinates</a></code>-method), e.g. of class
<code>"<a href="sp.html#topic+SpatialPoints-class">SpatialPoints</a>"</code>. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an integer vector containing the number of instances of each
point of the object.
</p>


<h3>See Also</h3>

<p><code><a href="spatstat.geom.html#topic+multiplicity">multiplicity</a></code> in package <span class="pkg">spatstat.geom</span>.
See the Examples of the <code><a href="#topic+hagelloch">hagelloch</a></code> data for a specific
use of <code>multiplicity</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>foo &lt;- SpatialPoints(matrix(c(1,2,
                              2,3,
                              1,2,
                              4,5), 4, 2, byrow=TRUE))
multiplicity(foo)

# the following function determines the multiplicities in a matrix
# or data frame and returns unique rows with appended multiplicity
countunique &lt;- function(x) unique(cbind(x, count=multiplicity(x)))
countunique(coordinates(foo))
</code></pre>

<hr>
<h2 id='nbOrder'>
Determine Neighbourhood Order Matrix from Binary Adjacency Matrix
</h2><span id='topic+nbOrder'></span>

<h3>Description</h3>

<p>Given a square binary adjacency matrix, the function
<code>nbOrder</code> determines the integer matrix of neighbourhood orders
(shortest-path distance).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nbOrder(neighbourhood, maxlag = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nbOrder_+3A_neighbourhood">neighbourhood</code></td>
<td>

<p>a square, numeric or logical, and usually symmetric matrix with
finite entries (and usually zeros on the diagonal) which indicates
vertex adjacencies, i.e., first-order neighbourhood (interpreted as
<code>neighbourhood == 1</code>, <em>not</em> <code>&gt;0</code>).
</p>
</td></tr>
<tr><td><code id="nbOrder_+3A_maxlag">maxlag</code></td>
<td>

<p>positive scalar integer specifying an upper bound for the
neighbourhood order. The default (<code>Inf</code>) means no truncation
(but orders cannot be larger than the number of regions minus 1),
whereas <code>maxlag = 1</code> just returns the input
neighbourhood matrix (converted to binary integer mode).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer matrix of neighbourhood orders, i.e., the shortest-path
distance matrix of the vertices.
The <code>dimnames</code> of the input <code>neighbourhood</code> matrix are preserved.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="spdep.html#topic+nblag">nblag</a></code> from the <span class="pkg">spdep</span> package
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate adjacency matrix
set.seed(1)
n &lt;- 6
adjmat &lt;- matrix(0, n, n)
adjmat[lower.tri(adjmat)] &lt;- sample(0:1, n*(n-1)/2, replace=TRUE)
adjmat &lt;- adjmat + t(adjmat)
adjmat

## determine neighbourhood order matrix
nblags &lt;- nbOrder(adjmat)
nblags
</code></pre>

<hr>
<h2 id='nowcast'>
Adjust a univariate time series of counts for observed
but-not-yet-reported events
</h2><span id='topic+nowcast'></span>

<h3>Description</h3>

<p>Nowcasting can help to obtain up-to-date information on trends during
a situation where reports about events arrive with delay. For example
in public health reporting, reports about important
indicators (such as occurrence of cases) are prone to be delayed due to
for example manual quality checking and reporting system
hierarchies. Altogether, the delays are subject to a delay distribution,
which may, or may not, vary over time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nowcast(now, when, data, dEventCol="dHospital", dReportCol="dReport",
        method=c("bayes.notrunc", "bayes.notrunc.bnb", "lawless",
                 "bayes.trunc", "unif", "bayes.trunc.ddcp"),
        aggregate.by="1 day",
        D=15,
        m=NULL, m.interpretation=c("hoehle_anderheiden2014", "lawless1994"),
        control=list(
            dRange=NULL, alpha=0.05, nSamples=1e3,
            N.tInf.prior=c("poisgamma","pois","unif"),
            N.tInf.max=300, gd.prior.kappa=0.1,
            ddcp=list(ddChangepoint=NULL,
                      cp_order=c("zero","one"),
                      Wextra=NULL,
                      logLambda=c("iidLogGa","tps","rw1","rw2"),
                      responseDistr=c("poisson", "negbin"),
                      mcmc=c(burnin=2500, sample=10000, thin=1, adapt=1000,
                             store.samples=FALSE)),
            score=FALSE, predPMF=FALSE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nowcast_+3A_now">now</code></td>
<td>

<p>an object of class <code>Date</code> denoting the day at which to do the
nowcast. This corresponds to <code class="reqn">T</code> in the notation of
Höhle and an der Heiden (2014).
</p>
</td></tr>
<tr><td><code id="nowcast_+3A_when">when</code></td>
<td>
<p>a vector of <code>Date</code> objects denoting the day(s) for which
the projections are to be done. One needs to ensure that each
element in <code>when</code> is smaller or equal to <code>now</code>.
</p>
</td></tr>
<tr><td><code id="nowcast_+3A_data">data</code></td>
<td>
<p>A data frame with one row per case &ndash; for each case on needs
information on the day of the event (e.g. hospitalization) and the
day of report of this event.
</p>
</td></tr>
<tr><td><code id="nowcast_+3A_deventcol">dEventCol</code></td>
<td>
<p>The name of the column in <code>data</code> which contains the
date of the event, e.g. hospitalization. Default: <code>"dHospital"</code>.
</p>
</td></tr>
<tr><td><code id="nowcast_+3A_dreportcol">dReportCol</code></td>
<td>
<p>Name of the column in <code>data</code> containing the date at
which the report arrives at the respective register. Default:
<code>"dReport"</code>.
</p>
</td></tr>
<tr><td><code id="nowcast_+3A_method">method</code></td>
<td>
<p>A vector of strings denoting the different methods for doing
the nowcasting. Note that results of the first name in this list are
officially
returned by the function. However, it is possible to specify several
methods here, e.g., in order to compare score evaluations. Details of
the methods are described in Höhle and an der Heiden (2014).
</p>

<dl>
<dt><code>"unif"</code></dt><dd></dd>
<dt><code>"bayes.notrunc"</code></dt><dd><p>A Bayesian procedure ignoring
truncation.</p>
</dd>
<dt><code>"bayes.notrunc.bnb"</code></dt><dd><p>A fast Bayesian procedure ignoring
truncation and which calculates the adjustment per-time
(i.e. ignoring other delays) using the negative binomial.</p>
</dd>
<dt><code>"lawless"</code></dt><dd><p>A discretized version of the Gaussian
predictive distribution suggested in Lawless (1994).</p>
</dd>
<dt><code>"bayes.trunc"</code></dt><dd><p>Bayesian method based on the generalized
Dirichlet distribution, which is the conjugate prior-posterior for the
delay distribution PMF under right-truncated sampling as shown in HadH
(2014).</p>
</dd>
<dt><code>"bayes.trunc.ddcp"</code></dt><dd><p>Fully Bayesian method allowing for
change-points in the delay distribution, e.g., due to speed-ups
in the reporting process. A discrete-survival
model is used for the delay distribution. Details of
the methods are described in HadH (2014). Note: This method
requires that the JAGS program is installed on the system.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="nowcast_+3A_aggregate.by">aggregate.by</code></td>
<td>
<p>Time scale used for the temporal aggregation of
the records in the data <code>data</code>. See
<code><a href="#topic+linelist2sts">linelist2sts</a></code> and <code><a href="base.html#topic+seq.Date">seq.Date</a></code> for further
information.</p>
</td></tr>
<tr><td><code id="nowcast_+3A_d">D</code></td>
<td>
<p>Maximum possible or maximum relevant delay (unit:
<code>aggregate.by</code>). Default: 15.</p>
</td></tr>
<tr><td><code id="nowcast_+3A_m">m</code></td>
<td>
<p>Size of the moving window for the estimation of the delay
distribution. Default: <code>NULL</code>, i.e. take all values at all
times. Otherwise: a positive integer equal to or greater than <code>D</code>
such that only values from a sliding window are used. The shape of the
window depends on the value of <code>m.interpretation</code>.</p>
</td></tr>
<tr><td><code id="nowcast_+3A_m.interpretation">m.interpretation</code></td>
<td>
<p>This parameter controls the interpretation of
the sliding window used to estimate the delay distribution. If
<code>m.interpretation="hoehle_anderheiden2014"</code> (Default) then the
sliding window is defined as a horizontal cut in the reporting
triangle, i.e. the values for the delay estimation originate from
reports occuring during <code>(now-m):now</code>. This means that the estimation of long delays is
based on fewer observations than the estimation of the short delays,
hence, the long delay estimates are subject to more variability. If
for example <code class="reqn">m=D</code> then the estimate for a delay of <code class="reqn">d=D</code> is
based on only one observation.
The advantage of this choice is that one explicitly knows which time
period all observations originate from. For details see Section 3 of
Höhle and an der Heiden (2014).    
</p>
<p>Alternatively, when <code>m.interpretation</code>=&quot;lawless1994&quot;, the cut in
the reporting triangle is made such that each delay <code>d</code> is
estimated based on the same number of observations (<code class="reqn">m+1</code>). This
means that in order to estimate the delay for <code class="reqn">d</code> days, a
sliding rectangle of length <code class="reqn">m+1</code> containing the reports which
occured during <code>(now-m-d):now</code>. See Fig. 2 in Lawless (1994) for
details. Note: A warning is given is
<code>method="lawless"</code>, but <code>m.interpretation</code> is not.</p>
</td></tr>
<tr><td><code id="nowcast_+3A_control">control</code></td>
<td>
<p>A list with named arguments controlling the
functionality of the nowcasting.
</p>

<dl>
<dt>dRange</dt><dd><p>Default: <code>NULL</code>. In this case the
<code>dEventCol</code> column is used to extract the first and last
available in <code>data</code>.</p>
</dd>
<dt>alpha</dt><dd><p>Equal tailed (1-<code class="reqn">\alpha</code>)*100% prediction
intervals are calculated. Default: 0.05.</p>
</dd>
<dt>nSamples</dt><dd><p>Number of PMF samples in the <code>bayes.*</code>
procedures. Note: Entire vectors containing the PMF on the grid from 0
to <code>N.tInf.max</code> are drawn and which are then combined. The
argument does not apply to the <code>bayes.trunc.ddcp</code> method.</p>
</dd>
<dt>N.tInf.prior</dt><dd><p>Prior distribution of
<code class="reqn">N(t,\infty)</code>. Applies only to the <code>bayes.*</code> except
<code>bayes.bayes.ddcp</code> methods. See example on how to control the
distribution parameters.</p>
</dd>
<dt>N.tInf.max</dt><dd><p>Limit of the support of <code class="reqn">N(t,\infty)</code>. The
value needs to be high enough such that at this limit only little of
the predictive distribution is right-truncated. Default: 300.</p>
</dd>
<dt>gd.prior.kappa</dt><dd><p>Concentration parameter for the Dirichlet
prior for the delay distribution on <code class="reqn">0,...,D</code>. Default: 0.1. Note:
The procedure is quite sensitive to this parameter in case only few
cases are available.</p>
</dd>
<dt>ddcp</dt><dd><p>A list specifying the change point model for the delay
distribution. This method should only be used if detailed information
about changes in the delay distribution are available as, e.g., in the
case of the STEC O104:H4 outbreak. The components are as
follows:
</p>

<dl>
<dt><code>ddChangepoint</code></dt><dd><p>Vector of Date objects corresponding
to the changepoints</p>
</dd>
<dt><code>cp_order</code></dt><dd><p>Either <code>"zero"</code> (Default) or
<code>"one"</code>. This is the degree of the TPS spline for the baseline
hazard, which is formed by the changepoints. Order zero corresponds to
the dummy variables of the change-points being simply zero or one. In
case a 1st order polynomial is chosen, this allows the delay
distribution to change towards faster or slow reporting as time
progresses (until the next change-point). The later can be helpful in
very dynamic epidemic situations where a lot of cases suddenly appear
overwhelming the surveillance system infrastructure.</p>
</dd>
<dt><code>Wextra</code></dt><dd><p>An additional design matrix part to be joined
onto the part originating from the change-points. Altogether, the
column bind of these two quantities will be <code class="reqn">W_{t,d}</code>. This allows
one to include, e.g., day of the week effects or holidays.</p>
</dd>
<dt><code>logLambda</code></dt><dd><p>Prior on the spline. One of
<code>c("iidLogGa","tps","rw1","rw2")</code>.</p>
</dd>
<dt><code>respDistr</code></dt><dd><p>Reponse distribution of <code class="reqn">n_{t,d}</code>
in the reporting triangle. Default is <code>"poisson"</code>. An
experimental alternative is to use <code>"negbin"</code>.</p>
</dd>
<dt><code>tau.gamma</code></dt><dd></dd>
<dt><code>eta.mu</code></dt><dd><p>Vector of coefficients describing the
mean of the prior normal distribution of the regression effects in the
discrete time survival model.</p>
</dd>
<dt><code>eta.prec</code></dt><dd><p>A precision matrix for the regression
effects in the discrete time survival model.</p>
</dd>
<dt><code>mcmc</code></dt><dd><p>A named vector of length 5 containing
burn-in (default: 2500), number of samples (10000),
thinning (1) and adaptation (1000) for the
three MCMC chains which are ran. The values are passed on to
<code><a href="runjags.html#topic+run.jags">run.jags</a></code>. The fifth argument <code>store.samples</code>
denotes if the output of the JAGS sampling should be included as part of the
returned <code>stsNC</code> object. Warning: If <code>TRUE</code> (Default: <code>FALSE</code>)
the size of the returned object might increase substantially.</p>
</dd>
</dl>

</dd>
<dt>score</dt><dd><p>Compute scoring rules. Default: <code>FALSE</code>. The
computed scores are found in the <code>SR</code> slot of the result.</p>
</dd>
<dt>predPMF</dt><dd><p>Boolean whether to return the probability mass
functions of the individual forecasts (Default: <code>FALSE</code>). The
result can be found in the <code>control</code> slot of the return object.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>The methodological details of the nowcasting procedures are described in
Höhle M and an der Heiden M (2014).
</p>


<h3>Value</h3>

<p><code>nowcast</code> returns an object of <code>"<a href="#topic+stsNC-class">stsNC</a>"</code>. The
<code>upperbound</code> slot contains the median of the method specified at
the first position the argument <code>method</code>. The slot <code>pi</code> (for
prediction interval)
contains the equal tailed (1-<code class="reqn">\alpha</code>)*100% prediction
intervals, which are calculated based on the predictive distributions
in slot <code>predPMF</code>.
Furthermore, slot <code>truth</code> contains an <code>sts</code> object
containing the true number of cases (if possible to compute it is based on
the data in <code>data</code>). Finally, slot <code>SR</code> contains the results
for the proper scoring rules (requires truth to be calculable).
</p>


<h3>Note</h3>

<p>Note: The <code>bayes.trunc.ddcp</code> uses the JAGS software together with
the <span class="rlang"><b>R</b></span> package <span class="pkg">runjags</span> to handle the parallelization of
the MCMC using the <code>"rjparallel"</code> method of
<code><a href="runjags.html#topic+run.jags">run.jags</a></code>, which additionally requires the
<span class="pkg">rjags</span> package. You need to manually install
JAGS on your computer for the package to work &ndash; see
<a href="https://mcmc-jags.sourceforge.io/">https://mcmc-jags.sourceforge.io/</a>
and the documentation of <span class="pkg">runjags</span> for details.
</p>
<p>Note: The function is still under development and might change in the
future. Unfortunately, little emphasis has so far been put on making
the function easy to understand and use.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle
</p>


<h3>References</h3>

<p>Höhle, M. and an der Heiden, M. (2014): Bayesian nowcasting
during the STEC O104:H4 outbreak in Germany, 2011. <em>Biometrics</em>
70(4):993-1002. <a href="https://doi.org/10.1111/biom.12194">doi:10.1111/biom.12194</a>.<br />
A preprint is available as
<a href="https://staff.math.su.se/hoehle/pubs/hoehle_anderheiden2014-preprint.pdf">https://staff.math.su.se/hoehle/pubs/hoehle_anderheiden2014-preprint.pdf</a>.
</p>
<p>Günther, F. and Bender, A. and Katz, K. and
Küchenhoff, H. and Höhle, M. (2020):
Nowcasting the COVID-19 pandemic in Bavaria.
<em>Biometrical Journal</em>. <a href="https://doi.org/10.1002/bimj.202000112">doi:10.1002/bimj.202000112</a><br />
Preprint available at <a href="https://doi.org/10.1101/2020.06.26.20140210">doi:10.1101/2020.06.26.20140210</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("husO104Hosp")

#Extract the reporting triangle at a specific day
t.repTriangle &lt;- as.Date("2011-07-04")

#Use 'void' nowcasting procedure (we just want the reporting triangle)
nc &lt;- nowcast(now=t.repTriangle,when=t.repTriangle,
              dEventCol="dHosp",dReportCol="dReport",data=husO104Hosp,
              D=15,method="unif")

#Show reporting triangle
reportingTriangle(nc)

#Perform Bayesian nowcasting assuming the delay distribution is stable over time
nc.control &lt;- list(N.tInf.prior=structure("poisgamma",
                                mean.lambda=50,var.lambda=3000),
                                nSamples=1e2)

t.repTriangle &lt;- as.Date("2011-06-10")
when &lt;- seq(t.repTriangle-3,length.out=10,by="-1 day")
nc &lt;- nowcast(now=t.repTriangle,when=when,
              dEventCol="dHosp",dReportCol="dReport",data=husO104Hosp,
              D=15,method="bayes.trunc",control=nc.control)

#Show time series and posterior median forecast/nowcast
plot(nc,xaxis.tickFreq=list("%d"=atChange,"%m"=atChange),
     xaxis.labelFreq=list("%d"=at2ndChange),xaxis.labelFormat="%d-%b",
     xlab="Time (days)",lty=c(1,1,1,1),lwd=c(1,1,2))

## Not run: 
### Using runjags to do a Bayesian model with changepoint(s)
### -- this might take a while
nc.control.ddcp &lt;- modifyList(nc.control,
                    list(gd.prior.kappa=0.1,
                         ddcp=list(ddChangepoint=as.Date(c("2011-05-23")),
                             logLambda="tps",
                             tau.gamma=1,
                             mcmc=c(burnin=1000,sample=1000,thin=1,
                                    adapt=1000,store.samples=FALSE))))

nc.ddcp &lt;- nowcast(now=t.repTriangle,when=when,
               dEventCol="dHosp",dReportCol="dReport",
               data=husO104Hosp, aggregate.by="1 day",
               method="bayes.trunc.ddcp", D=15,
                   control=nc.control.ddcp)

plot(nc.ddcp,legend.opts=NULL,
     xaxis.tickFreq=list("%d"=atChange,"%m"=atChange),
     xaxis.labelFreq=list("%d"=at2ndChange),xaxis.labelFormat="%d-%b",
     xlab="Time (days)",lty=c(1,1,1,1),lwd=c(1,1,2))

lambda &lt;- attr(delayCDF(nc.ddcp)[["bayes.trunc.ddcp"]],"model")$lambda
showIdx &lt;- seq(which( max(when) == epoch(nc.ddcp))) #seq(ncol(lambda))
matlines( showIdx,t(lambda)[showIdx,],col="gray",lwd=c(1,2,1),lty=c(2,1,2))
legend(x="topright",c(expression(lambda(t)),"95% CI"),col="gray",lwd=c(2,1),lty=c(1,2))

## End(Not run)
</code></pre>

<hr>
<h2 id='pairedbinCUSUM'>Paired binary CUSUM and its run-length computation</h2><span id='topic+pairedbinCUSUM'></span><span id='topic+pairedbinCUSUM.runlength'></span><span id='topic+pairedbinCUSUM.LLRcompute'></span>

<h3>Description</h3>

<p>CUSUM for paired binary data as described in Steiner et al. (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairedbinCUSUM(stsObj, control = list(range=NULL,theta0,theta1,
                                      h1,h2,h11,h22))
pairedbinCUSUM.runlength(p,w1,w2,h1,h2,h11,h22, sparse=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairedbinCUSUM_+3A_stsobj">stsObj</code></td>
<td>
<p>Object of class <code>sts</code> containing the paired
responses for each of the, say n, patients. The observed slot of
<code>stsObj</code> is thus a <code class="reqn">n \times 2</code> matrix.</p>
</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_control">control</code></td>
<td>
<p>Control object as a list containing several parameters.
</p>

<dl>
<dt><code>range</code></dt><dd><p>Vector of indices in the observed slot to monitor.</p>
</dd>
<dt><code>theta0</code></dt><dd><p>In-control parameters of the paired binary CUSUM.</p>
</dd>
<dt><code>theta1</code></dt><dd><p>Out-of-control parameters of the paired binary CUSUM.</p>
</dd>
<dt><code>h1</code></dt><dd><p>Primary control limit (=threshold) of 1st CUSUM.</p>
</dd>
<dt><code>h2</code></dt><dd><p>Primary control limit (=threshold) of 2nd CUSUM.</p>
</dd>
<dt><code>h11</code></dt><dd><p>Secondary limit for 1st CUSUM.</p>
</dd>
<dt><code>h22</code></dt><dd><p>Secondary limit for 2nd CUSUM.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_p">p</code></td>
<td>
<p>Vector giving the probability of the four different
possible states, i.e. c((death=0,near-miss=0),(death=1,near-miss=0),
(death=0,near-miss=1),(death=1,near-miss=1)).</p>
</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_w1">w1</code></td>
<td>
<p>The parameters <code>w1</code> and <code>w2</code> are the sample
weights vectors for the two CUSUMs, see eqn. (2) in the paper. We
have that <code>w1</code> is equal to deaths </p>
</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_w2">w2</code></td>
<td>
<p>As for <code>w1</code></p>
</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_h1">h1</code></td>
<td>
<p>decision barrier for 1st individual cusums</p>
</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_h2">h2</code></td>
<td>
<p>decision barrier for 2nd cusums</p>
</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_h11">h11</code></td>
<td>
<p>together with <code>h22</code> this makes up the joing decision barriers</p>
</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_h22">h22</code></td>
<td>
<p>together with <code>h11</code> this makes up the joing decision barriers</p>
</td></tr>
<tr><td><code id="pairedbinCUSUM_+3A_sparse">sparse</code></td>
<td>
<p>Boolean indicating whether to use sparse matrix
computations from the <code>Matrix</code> library (usually much faster!). Default:
<code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details about the method see the Steiner et al. (1999) reference
listed below. Basically, two individual CUSUMs are run each based on a
logistic regression model. The combined CUSUM not only signals if one
of its two individual CUSUMs signals, but also if the two CUSUMs
simultaneously cross the secondary limits.
</p>


<h3>Value</h3>

<p>An <code>sts</code> object with <code>observed</code>, <code>alarm</code>,
etc. slots trimmed to the <code>control$range</code> indices.
</p>


<h3>Author(s)</h3>

<p>S. Steiner and M. Höhle</p>


<h3>References</h3>

<p>Steiner, S. H., Cook, R. J., and Farewell, V. T. (1999), Monitoring
paired binary surgical outcomes using cumulative sum charts,
Statistics in Medicine, 18, pp. 69&ndash;86.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+categoricalCUSUM">categoricalCUSUM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Set in-control and out-of-control parameters as in paper
theta0 &lt;- c(-2.3,-4.5,2.5)
theta1 &lt;- c(-1.7,-2.9,2.5)

#Small helper function to compute the paired-binary likelihood
#of the length two vector yz when the true parameters are theta
dPBin &lt;- function(yz,theta) {
    exp(dbinom(yz[1],size=1,prob=plogis(theta[1]),log=TRUE) +
    dbinom(yz[2],size=1,prob=plogis(theta[2]+theta[3]*yz[1]),log=TRUE))
}

#Likelihood ratio for all four possible configurations
p &lt;- c(dPBin(c(0,0), theta=theta0), dPBin(c(0,1), theta=theta0),
       dPBin(c(1,0), theta=theta0), dPBin(c(1,1), theta=theta0))

#Compute ARL using non-sparse matrix operations
pairedbinCUSUM.runlength(p,w1=c(-1,37,-9,29),w2=c(-1,7),h1=70,h2=32,
                         h11=38,h22=17)

#Sparse computations can be considerably (!) faster
pairedbinCUSUM.runlength(p,w1=c(-1,37,-9,29),w2=c(-1,7),h1=70,h2=32,
                         h11=38,h22=17,sparse=TRUE)

#Use paired binary CUSUM on the De Leval et al. (1994) arterial switch
#operation data on 104 newborn babies
data("deleval")

#Switch between death and near misses
observed(deleval) &lt;- observed(deleval)[,c(2,1)]

#Run paired-binary CUSUM without generating alarms.
pb.surv &lt;- pairedbinCUSUM(deleval,control=list(theta0=theta0,
             theta1=theta1,h1=Inf,h2=Inf,h11=Inf,h22=Inf))

plot(pb.surv, xaxis.labelFormat=NULL, ylab="CUSUM Statistic")



######################################################################
#Scale the plots so they become comparable to the plots in Steiner et
#al. (1999). To this end a small helper function is defined.
######################################################################

######################################################################
#Log LR for conditional specification of the paired model
######################################################################
LLR.pairedbin &lt;- function(yz,theta0, theta1) {
    #In control
    alphay0 &lt;- theta0[1] ; alphaz0 &lt;- theta0[2] ; beta0 &lt;- theta0[3]
    #Out of control
    alphay1 &lt;- theta1[1] ; alphaz1 &lt;- theta1[2] ; beta1 &lt;- theta1[3]
    #Likelihood ratios
    llry &lt;- (alphay1-alphay0)*yz[1]+log(1+exp(alphay0))-log(1+exp(alphay1))
    llrz &lt;- (alphaz1-alphaz0)*yz[2]+log(1+exp(alphaz0+beta0*yz[1]))-
                                    log(1+exp(alphaz1+beta1*yz[1]))
    return(c(llry=llry,llrz=llrz))
}


val &lt;- expand.grid(0:1,0:1)
table &lt;- t(apply(val,1, LLR.pairedbin, theta0=theta0, theta1=theta1))
w1 &lt;- min(abs(table[,1]))
w2 &lt;- min(abs(table[,2]))
S &lt;- upperbound(pb.surv) / cbind(rep(w1,nrow(observed(pb.surv))),w2)

#Show results
opar &lt;- par(mfcol=c(2,1))
plot(1:nrow(deleval),S[,1],type="l",main="Near Miss",xlab="Patient No.",
     ylab="CUSUM Statistic")
lines(c(0,1e99), c(32,32),lty=2,col=2)
lines(c(0,1e99), c(17,17),lty=2,col=3)

plot(1:nrow(deleval),S[,2],type="l",main="Death",xlab="Patient No.",
     ylab="CUSUM Statistic")
    lines(c(0,1e99), c(70,70),lty=2,col=2)
    lines(c(0,1e99), c(38,38),lty=2,col=3)
par(opar)

######################################################################
# Run the CUSUM with thresholds as in Steiner et al. (1999).
# After each alarm the CUSUM statistic is set to zero and
# monitoring continues from this point. Triangles indicate alarm
# in the respective CUSUM (nearmiss or death). If in both
# simultaneously then an alarm is caued by the secondary limits.
######################################################################
pb.surv2 &lt;- pairedbinCUSUM(deleval,control=list(theta0=theta0,
             theta1=theta1,h1=70*w1,h2=32*w2,h11=38*w1,h22=17*w2))

plot(pb.surv2, xaxis.labelFormat=NULL)
</code></pre>

<hr>
<h2 id='permutationTest'>Monte Carlo Permutation Test for Paired Individual Scores</h2><span id='topic+permutationTest'></span>

<h3>Description</h3>

<p>The difference between mean <code><a href="#topic+scores">scores</a></code> from model 1 and
mean <code><a href="#topic+scores">scores</a></code> from model 2 is used as the test statistic.
Under the null hypothesis of no difference, the actually observed
difference between mean scores should not be notably different from
the distribution of the test statistic under permutation.
As the computation of all possible permutations is only feasible for
small datasets, a random sample of permutations is used to obtain the
null distribution. The resulting p-value thus depends on the
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permutationTest(score1, score2, nPermutation = 9999,
                plot = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permutationTest_+3A_score1">score1</code>, <code id="permutationTest_+3A_score2">score2</code></td>
<td>

<p>numeric vectors of scores from models 1 and 2, respectively.
</p>
</td></tr>
<tr><td><code id="permutationTest_+3A_npermutation">nPermutation</code></td>
<td>

<p>number of Monte Carlo replicates.
</p>
</td></tr>
<tr><td><code id="permutationTest_+3A_plot">plot</code></td>
<td>

<p>logical indicating if a <code><a href="MASS.html#topic+truehist">truehist</a></code> of the <code>nPermutation</code>
permutation test statistics should be plotted with a vertical line
marking the observed difference of the means.
To customize the histogram, <code>plot</code> can also be a list of
arguments for <code>truehist</code> replacing internal defaults.
</p>
</td></tr>
<tr><td><code id="permutationTest_+3A_verbose">verbose</code></td>
<td>

<p>logical indicating if the results should be printed in one line.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each permutation, we first randomly assign the membership of the n
individual scores to either model 1 or 2 with probability 0.5. We then
compute the respective difference in mean for model 1 and 2 in this
permuted set of scores. The Monte Carlo p-value is then given by
(1 + #{permuted differences larger than observed difference (in
absolute value)}) / (1 + <code>nPermutation</code>).
</p>


<h3>Value</h3>

<p>a list of the following elements:
</p>
<table>
<tr><td><code>diffObs</code></td>
<td>
<p>observed difference in mean scores, i.e.,
<code>mean(score1) - mean(score2)</code></p>
</td></tr>
<tr><td><code>pVal.permut</code></td>
<td>
<p>p-value of the permutation test</p>
</td></tr>
<tr><td><code>pVal.t</code></td>
<td>
<p>p-value of the corresponding
<code><a href="stats.html#topic+t.test">t.test</a>(score1, score2, paired=TRUE)</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michaela Paul with contributions by Sebastian Meyer
</p>


<h3>References</h3>

<p>Paul, M. and Held, L. (2011):
Predictive assessment of a non-linear random effects model for
multivariate time series of infectious disease counts.
<em>Statistics in Medicine</em>, <b>30</b> (10), 1118-1136.
<a href="https://doi.org/10.1002/sim.4177">doi:10.1002/sim.4177</a>
</p>


<h3>See Also</h3>

<p>Package <a href="https://CRAN.R-project.org/package=coin"><span class="pkg">coin</span></a> for a comprehensive permutation test framework.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>permutationTest(rnorm(50, 1.5), rnorm(50, 1), plot = TRUE)
</code></pre>

<hr>
<h2 id='pit'>
Non-Randomized Version of the PIT Histogram (for Count Data)
</h2><span id='topic+pit'></span><span id='topic+pit.default'></span>

<h3>Description</h3>

<p>See Czado et al. (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pit(x, ...)
## Default S3 method:
pit(x, pdistr, J = 10, relative = TRUE, ..., plot = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pit_+3A_x">x</code></td>
<td>

<p>numeric vector representing the observed counts.
</p>
</td></tr>
<tr><td><code id="pit_+3A_pdistr">pdistr</code></td>
<td>

<p>either a list of predictive cumulative distribution functions for
the observations <code>x</code>, or (the name of) a single predictive CDF
used for all <code>x</code> (with potentially varying arguments <code>...</code>).
It is checked that the predictive CDF returns 0 at <code>x=-1</code>.
The name of its first argument can be different from <code>x</code>, e.g.,
<code>pdistr="pnbinom"</code> is possible.<br />
If <code>pdistr</code> is a single function and no additional <code>...</code>
arguments are supplied, <code>pdistr</code> is assumed to be vectorized,
i.e., it is simply called as <code>pdistr(x)</code> and <code>pdistr(x-1)</code>.
Otherwise, the predictive CDF is called sequentially and does not
need to be vectorized.
</p>
</td></tr>
<tr><td><code id="pit_+3A_j">J</code></td>
<td>

<p>the number of bins of the histogram.
</p>
</td></tr>
<tr><td><code id="pit_+3A_relative">relative</code></td>
<td>

<p>logical indicating if relative frequency or the density should be plotted.
Due to a historical bug, <code>relative=TRUE</code> (the default) actually
plots a density histogram while <code>relative=FALSE</code> plots relative
frequencies.
</p>
</td></tr>
<tr><td><code id="pit_+3A_...">...</code></td>
<td>

<p>ignored if <code>pdistr</code> is a list. Otherwise, such additional
arguments are used in sequential calls of <code>pdistr</code> via
<code><a href="base.html#topic+mapply">mapply</a>(pdistr, x, ...)</code>.
</p>
</td></tr>
<tr><td><code id="pit_+3A_plot">plot</code></td>
<td>

<p>a list of arguments for <code><a href="graphics.html#topic+plot.histogram">plot.histogram</a></code>.
Otherwise, no plot will be produced.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"pit"</code>, which inherits from class
<code>"histogram"</code> (see <code><a href="graphics.html#topic+hist">hist</a></code>).
It is returned invisibly if a plot is produced.
</p>


<h3>Author(s)</h3>

<p>Michaela Paul and Sebastian Meyer
</p>


<h3>References</h3>

<p>Czado, C., Gneiting, T. and Held, L. (2009):
Predictive model assessment for count data.
<em>Biometrics</em>, <b>65</b> (4), 1254-1261.
<a href="https://doi.org/10.1111/j.1541-0420.2009.01191.x">doi:10.1111/j.1541-0420.2009.01191.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulation example of Czado et al. (2009, Section 2.4)
set.seed(100)
x &lt;- rnbinom(200, mu = 5, size = 2)
pdistrs &lt;- list("NB(5,0)"   = function (x) ppois(x, lambda=5),
                "NB(5,1/2)" = function (x) pnbinom(x, mu=5, size=2),
                "NB(5,1)"   = function (x) pnbinom(x, mu=5, size=1))
## Reproduce Figure 1
op &lt;- par(mfrow = c(1,3))
for (i in seq_along(pdistrs)) {
    pit(x, pdistr = pdistrs[[i]], J = 10,
        plot = list(ylim = c(0,2.75), main = names(pdistrs)[i]))
    box()
}
par(op)

## Alternative call using ... arguments for pdistr (less efficient)
stopifnot(identical(pit(x, "pnbinom", mu = 5, size = 2, plot = FALSE),
                    pit(x, pdistrs[[2]], plot = FALSE)))
</code></pre>

<hr>
<h2 id='plapply'>Verbose and Parallel <code>lapply</code></h2><span id='topic+plapply'></span>

<h3>Description</h3>

<p>Verbose and parallelized version of <code>lapply</code> wrapping around
<code><a href="parallel.html#topic+mclapply">mclapply</a></code> and <code><a href="parallel.html#topic+parLapply">parLapply</a></code>
in the base package <span class="pkg">parallel</span>.
This wrapper can take care of the <code>.Random.seed</code> and
print progress information (not for cluster-based parallelization).
With the default arguments it equals <code>lapply</code>
enriched by a progress bar.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plapply(X, FUN, ...,
        .parallel = 1, .seed = NULL, .verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plapply_+3A_x">X</code>, <code id="plapply_+3A_fun">FUN</code>, <code id="plapply_+3A_...">...</code></td>
<td>
<p>see <code><a href="base.html#topic+lapply">lapply</a></code>.</p>
</td></tr>
<tr><td><code id="plapply_+3A_.parallel">.parallel</code></td>
<td>

<p>the number of processes to use in parallel operation, or a
<code>"cluster"</code> object (see <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>).
If a number, <code><a href="parallel.html#topic+mclapply">mclapply</a></code> (forking) is used on
Unix-alikes, whereas on Windows <code><a href="parallel.html#topic+parLapply">parLapply</a></code> is
used on a newly created cluster of the specified size, which is
stopped when exiting the function.
By default (<code>.parallel = 1</code>), the basic <code><a href="base.html#topic+lapply">lapply</a></code> is used.
</p>
</td></tr>
<tr><td><code id="plapply_+3A_.seed">.seed</code></td>
<td>

<p>If set (non-<code>NULL</code>), results involving random number generation
become reproducible. If using a cluster (see the <code>.parallel</code>
argument), <code><a href="parallel.html#topic+clusterSetRNGStream">clusterSetRNGStream</a></code> is called
with the specified <code>.seed</code> before running <code>parLapply</code>.
Otherwise, <code><a href="base.html#topic+set.seed">set.seed</a>(.seed)</code> is called and the
<code><a href="base.html#topic+RNGkind">RNGkind</a></code> is changed to <code>"L'Ecuyer-CMRG"</code> if
<code>.parallel &gt; 1</code> (see the section on random numbers in the
documentation of <code>mcparallel</code> in package <span class="pkg">parallel</span>).

If <code>.seed</code> is non-<code>NULL</code>,
the original <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> will be restored
<code>on.exit</code> of the function.
</p>
</td></tr>
<tr><td><code id="plapply_+3A_.verbose">.verbose</code></td>
<td>

<p>if and how progress information should be displayed, i.e., what to
do on each exit of <code>FUN</code>. This is unsupported and ignored for
cluster-based parallelization and primitive <code>FUN</code>ctions.
The default (<code>TRUE</code>) will show a <code><a href="utils.html#topic+txtProgressBar">txtProgressBar</a></code>
(if <code>.parallel = 1</code> in an <code><a href="base.html#topic+interactive">interactive</a></code> <span class="rlang"><b>R</b></span> session)
or <code>cat(".")</code> (otherwise). Other choices for the dot are possible
by specifying the desired symbol directly as the <code>.verbose</code>
argument. Alternatively, <code>.verbose</code> may be any custom call or
expression to be executed <code><a href="base.html#topic+on.exit">on.exit</a></code> of <code>FUN</code> and
may thus involve any objects from the local evaluation environment.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of the results of calling <code>FUN</code> on each value of <code>X</code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="parallel.html#topic+mclapply">mclapply</a></code> and <code><a href="parallel.html#topic+parLapply">parLapply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example inspired by help("lapply")
x &lt;- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE))

## if neither parallel nor verbose then this simply equals lapply()
plapply(x, quantile, probs = 1:3/4, .verbose = FALSE)

## verbose lapply() -- not really useful for such fast computations
res &lt;- plapply(x, quantile, probs = 1:3/4, .verbose = TRUE)
res &lt;- plapply(x, quantile, probs = 1:3/4, .verbose = "|")
res &lt;- plapply(x, quantile, probs = 1:3/4,
               .verbose = quote(cat("length(x) =", length(x), "\n")))

## setting the seed for reproducibility of results involving the RNG
samp &lt;- plapply(as.list(1:3), runif, .seed = 1)

## parallel lapply()
res &lt;- plapply(x, quantile, probs = 1:3/4, .parallel = 2)

## using a predefined cluster
library("parallel")
cl &lt;- makeCluster(getOption("cl.cores", 2))
res &lt;- plapply(x, quantile, probs = 1:3/4, .parallel = cl)
stopCluster(cl)
</code></pre>

<hr>
<h2 id='plot.atwins'>Plots for Fitted <code>algo.twins</code> Models</h2><span id='topic+plot.atwins'></span>

<h3>Description</h3>

<p>Plot results of fitting a twins model using MCMC output. Plots similar
to those in the Held et al. (2006) paper are generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'atwins'
plot(x, which=c(1,4,6,7), ask=TRUE, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.atwins_+3A_x">x</code></td>
<td>
<p>An object of class <code>"atwins"</code> as returned by
<code><a href="#topic+algo.twins">algo.twins</a></code>.</p>
</td></tr>
<tr><td><code id="plot.atwins_+3A_which">which</code></td>
<td>
<p>a vector containing the different plot types to show
</p>

<dl>
<dt>1</dt><dd><p>A plot of the observed time series Z is shown together
with posterior means for the number of endemic cases (X) and number of
epidemic cases (Y).</p>
</dd>
<dt>2</dt><dd><p>This plot shows trace plots of the gamma parameters
over all MCMC samples.</p>
</dd>
<dt>3</dt><dd><p>This shows a trace plot of psi, which controls the
overdispersion in the model.</p>
</dd>
<dt>4</dt><dd><p>Autocorrelation functions for K and psi are shown in
order to judge whether the MCMC sampler has converged.</p>
</dd>
<dt>5</dt><dd><p>Shows a plot of the posterior mean of the seasonal
model nu[t] together with 95% credibility intervals based on the
quantiles of the posterior.</p>
</dd>
<dt>6</dt><dd><p>Histograms illustrating the posterior density for K and
psi. The first one corresponds to Fig. 4(f) in the paper.</p>
</dd>
<dt>7</dt><dd><p>Histograms illustrating the predictive posterior
density for the next observed number of cases Z[n+1]. Compare with Fig.5
in the paper.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="plot.atwins_+3A_ask">ask</code></td>
<td>
<p>Boolean indicating whether to ask for a newline before
showing the next plot (only if multiple are shown).</p>
</td></tr>
<tr><td><code id="plot.atwins_+3A_...">...</code></td>
<td>
<p>Additional arguments for <code><a href="#topic+stsplot_time">stsplot_time</a></code>,
used for plot type 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details see the plots in the paper. Basically MCMC output is
visualized. This function is experimental, as is <code><a href="#topic+algo.twins">algo.twins</a></code>.
</p>


<h3>Author(s)</h3>

<p>M. Hofmann and M. Höhle</p>


<h3>References</h3>

<p>Held, L., Hofmann, M., Höhle, M. and Schmid V. (2006)
A two-component
model for counts of infectious diseases, Biostatistics, <b>7</b>, pp.
422&ndash;437.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.twins">algo.twins</a></code> (with an example)</p>

<hr>
<h2 id='plot.disProg'>Plot Observed Counts and Defined Outbreak States of a 
(Multivariate) Time Series</h2><span id='topic+plot.disProg'></span>

<h3>Description</h3>

<p>Plotting a (multivariate) <code>disProg</code> object (soft-deprecated).
</p>
<p>As of <span class="pkg">surveillance</span> 1.20.0, legacy <code>disProg</code> objects are
plotted via internal <code><a href="#topic+disProg2sts">disProg2sts</a></code> conversion
and <code><a href="#topic+stsplot_time">stsplot_time</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'disProg'
plot(x, title = "", xaxis.years=TRUE, startyear = x$start[1],
    firstweek = x$start[2], as.one=TRUE, same.scale=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.disProg_+3A_x">x</code></td>
<td>
<p>object of class <code>disProg</code></p>
</td></tr>
<tr><td><code id="plot.disProg_+3A_title">title</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id="plot.disProg_+3A_xaxis.years">xaxis.years</code></td>
<td>
<p>if <code>TRUE</code>, the x axis is labeled using years</p>
</td></tr>
<tr><td><code id="plot.disProg_+3A_startyear">startyear</code>, <code id="plot.disProg_+3A_firstweek">firstweek</code></td>
<td>
<p>(legacy arguments, ignored with a warning)</p>
</td></tr>
<tr><td><code id="plot.disProg_+3A_as.one">as.one</code></td>
<td>
<p>if <code>TRUE</code> all individual time series are shown in 
one plot</p>
</td></tr>
<tr><td><code id="plot.disProg_+3A_same.scale">same.scale</code></td>
<td>
<p>if <code>TRUE</code> all plots have same scale</p>
</td></tr>
<tr><td><code id="plot.disProg_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+stsplot_time">stsplot_time</a></code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Plotting of simulated data
disProgObj &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 208,
                              A = 1, alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 5)
plot(disProgObj)
title &lt;- "Infection Counts and Defined Outbreaks for Simulated Data"
plot(disProgObj, title = title)
plot(disProgObj, title = title, xaxis.years = FALSE)

# Plotting of measles data
data(measles.weser)
# one plot
plot(measles.weser, title = "measles cases in the district Weser-Ems")
# plot cases for each "Kreis" 
plot(measles.weser, as.one = FALSE)
plot(measles.weser, as.one = FALSE, same.scale = FALSE)
</code></pre>

<hr>
<h2 id='plot.survRes'>Plot a <code>survRes</code> object</h2><span id='topic+plot.survRes'></span>

<h3>Description</h3>

<p>Plotting a (multivariate) <code>survRes</code> object (soft-deprecated),
including the number of infected, the threshold for recognizing an
outbreak, the alarm status and the outbreak status.
</p>
<p>As of <span class="pkg">surveillance</span> 1.20.0, legacy <code>survRes</code> objects are
plotted via internal <code><a href="#topic+disProg2sts">disProg2sts</a></code> conversion
and <code><a href="#topic+stsplot_time">stsplot_time</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'survRes'
plot(x, method = x$control$name, disease = x$control$data,
     xaxis.years = TRUE, startyear = 2001, firstweek = 1,
     same.scale = TRUE, ...,
     main = paste0("Analysis of ", disease, " using ", method))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.survRes_+3A_x">x</code></td>
<td>
<p>object of class <code>survRes</code></p>
</td></tr>
<tr><td><code id="plot.survRes_+3A_method">method</code></td>
<td>
<p>surveillance method to be used in title</p>
</td></tr>
<tr><td><code id="plot.survRes_+3A_disease">disease</code></td>
<td>
<p>name of disease in title</p>
</td></tr>
<tr><td><code id="plot.survRes_+3A_xaxis.years">xaxis.years</code></td>
<td>
<p>Boolean indicating whether to show a year-based x-axis</p>
</td></tr>
<tr><td><code id="plot.survRes_+3A_startyear">startyear</code>, <code id="plot.survRes_+3A_firstweek">firstweek</code></td>
<td>
<p>(legacy arguments, ignored with a warning)</p>
</td></tr>
<tr><td><code id="plot.survRes_+3A_same.scale">same.scale</code></td>
<td>
<p>if <code>TRUE</code> (default), all plots use the same <code>ylim</code></p>
</td></tr>
<tr><td><code id="plot.survRes_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+stsplot_time">stsplot_time</a></code></p>
</td></tr>
<tr><td><code id="plot.survRes_+3A_main">main</code></td>
<td>
<p>the plot title is generated from the
<code>method</code> and <code>disease</code> arguments if not specified otherwise</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(ha)
ctrl &lt;- list(range = 209:290, b = 2, w = 6, alpha = 0.005)
plot(algo.bayes(aggregate(ha), control = ctrl))
</code></pre>

<hr>
<h2 id='poly2adjmat'>
Derive Adjacency Structure of <code>"SpatialPolygons"</code>
</h2><span id='topic+poly2adjmat'></span>

<h3>Description</h3>

<p>Wrapping around functionality of the <span class="pkg">spdep</span> package, this function
computes the symmetric, binary (0/1), adjacency matrix from a
<code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code> object.
It essentially applies
<code><a href="spdep.html#topic+nb2mat">nb2mat</a>(<a href="spdep.html#topic+poly2nb">poly2nb</a>(SpP, ...), style="B",
  zero.policy=zero.policy)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poly2adjmat(SpP, ..., zero.policy = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poly2adjmat_+3A_spp">SpP</code></td>
<td>
<p>an object inheriting from <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>.</p>
</td></tr>
<tr><td><code id="poly2adjmat_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="spdep.html#topic+poly2nb">poly2nb</a></code>.
Its <code>snap</code> argument might be particularly useful to handle maps
with sliver polygons.</p>
</td></tr>
<tr><td><code id="poly2adjmat_+3A_zero.policy">zero.policy</code></td>
<td>
<p>logical indicating if islands are allowed, see
<code><a href="spdep.html#topic+nb2mat">nb2mat</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a symmetric numeric indicator matrix of size <code>length(SpP)</code>^2
representing polygon adjacencies.
</p>


<h3>Author(s)</h3>

<p>(of this wrapper) Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="spdep.html#topic+poly2nb">poly2nb</a></code> in package <span class="pkg">spdep</span>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("spdep")) {
    ## generate adjacency matrix for districts of Bayern and Baden-Wuerttemberg
    data("fluBYBW")
    adjmat &lt;- poly2adjmat(fluBYBW@map)

    ## same as already stored in the neighbourhood slot (in different order)
    stopifnot(all.equal(adjmat,
                        neighbourhood(fluBYBW)[rownames(adjmat),colnames(adjmat)]))

    ## a visual check of the district-specific number of neighbours
    plot(fluBYBW@map)
    text(coordinates(fluBYBW@map), labels=rowSums(adjmat==1), font=2, col=2)
}
</code></pre>

<hr>
<h2 id='polyAtBorder'>Indicate Polygons at the Border</h2><span id='topic+polyAtBorder'></span>

<h3>Description</h3>

<p>Determines which polygons of a <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>
object are at the border, i.e. have coordinates in common with the
spatial union of all polygons (constructed using
<code><a href="#topic+unionSpatialPolygons">unionSpatialPolygons</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polyAtBorder(SpP, snap = sqrt(.Machine$double.eps),
             method = "sf", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyAtBorder_+3A_spp">SpP</code></td>
<td>

<p>an object of class <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>.
</p>
</td></tr>
<tr><td><code id="polyAtBorder_+3A_snap">snap</code></td>
<td>

<p>tolerance used to consider coordinates as identical.
</p>
</td></tr>
<tr><td><code id="polyAtBorder_+3A_method">method</code></td>
<td>
<p>method to use for <code><a href="#topic+unionSpatialPolygons">unionSpatialPolygons</a></code>.
Defaults to <span class="pkg">sf</span>, since <span class="pkg">polyclip</span> uses integer
arithmetic, which causes rounding errors usually requiring tuning of
(i.e., increasing) the tolerance parameter <code>snap</code> (see example
below).</p>
</td></tr>
<tr><td><code id="polyAtBorder_+3A_...">...</code></td>
<td>
<p>further arguments passed to the chosen <code>method</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical vector of the same length as <code>SpP</code> also inheriting its
<code>row.names</code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load districts of Germany
load(system.file("shapes", "districtsD.RData", package = "surveillance"))

## Determine districts at the border and check the result on the map
if (requireNamespace("sf")) {
    atBorder &lt;- polyAtBorder(districtsD, method = "sf")
    if (interactive()) plot(districtsD, col = atBorder)
    table(atBorder)
}

## For method = "polyclip", a higher snapping tolerance is required
## to obtain the correct result
if (requireNamespace("polyclip")) {
    atBorder &lt;- polyAtBorder(districtsD, snap = 1e-6, method = "polyclip")
    if (interactive()) plot(districtsD, col = atBorder)
    table(atBorder)
}
</code></pre>

<hr>
<h2 id='primeFactors'>Prime Number Factorization</h2><span id='topic+primeFactors'></span>

<h3>Description</h3>

<p>Computes the prime number factorization of an integer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>primeFactors(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="primeFactors_+3A_x">x</code></td>
<td>
<p>an integer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with prime number factorization of <code>x</code></p>

<hr>
<h2 id='print.algoQV'>Print Quality Value Object</h2><span id='topic+print.algoQV'></span>

<h3>Description</h3>

<p>Print a single quality value object in a nicely formatted way</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'algoQV'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.algoQV_+3A_x">x</code></td>
<td>
<p>Quality Values object generated with <code>quality</code></p>
</td></tr>
<tr><td><code id="print.algoQV_+3A_...">...</code></td>
<td>
<p>Further arguments (not really used)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Create a test object
disProgObj &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 200, A = 1,
                              alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 1.7)

# Let this object be tested from rki1
survResObj &lt;- algo.rki1(disProgObj, control = list(range = 50:200))

# Compute the quality values in a nice formatted way
algo.quality(survResObj) 
</code></pre>

<hr>
<h2 id='R0'>Computes reproduction numbers from fitted models</h2><span id='topic+R0'></span><span id='topic+R0.twinstim'></span><span id='topic+R0.simEpidataCS'></span><span id='topic+simpleR0'></span>

<h3>Description</h3>

<p>The S3 generic function <code>R0</code> defined in package <span class="pkg">surveillance</span> is intended to
compute reproduction numbers from fitted epidemic models.
The package currently defines a method for the <code>"<a href="#topic+twinstim">twinstim</a>"</code> class, which
computes expected numbers of infections caused by infected individuals depending on the event type
and marks attached to the individual, which contribute to the infection pressure
in the epidemic predictor of that class.
There is also a method for simulated <code>"epidataCS"</code>
(just a wrapper for the <code>"twinstim"</code>-method).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R0(object, ...)

## S3 method for class 'twinstim'
R0(object, newevents, trimmed = TRUE, newcoef = NULL, ...)
## S3 method for class 'simEpidataCS'
R0(object, trimmed = TRUE, ...)

simpleR0(object, eta = coef(object)[["e.(Intercept)"]],
         eps.s = NULL, eps.t = NULL, newcoef = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R0_+3A_object">object</code></td>
<td>
<p>A fitted epidemic model object for which an <code>R0</code> method exists.</p>
</td></tr>
<tr><td><code id="R0_+3A_newevents">newevents</code></td>
<td>

<p>an optional <code>data.frame</code> of events for which the reproduction
numbers should be calculated.  If omitted, it is calculated for the
original events from the fit.  In this case, if
<code>trimmed = TRUE</code> (the default), the result is just
<code>object$R0</code>; however, if <code>trimmed = FALSE</code>, the model
environment is required, i.e. <code>object</code> must have been fitted
with <code>model = TRUE</code>.
</p>
<p>For the <code>twinstim</code> method, <code>newevents</code> must at least
contain the following columns:
the event <code>time</code> (only for <code>trimmed = TRUE</code>)
and <code>type</code> (only for multi-type epidemics),
the maximum interaction ranges <code>eps.t</code> and <code>eps.s</code>,
as well as columns for the marks and <code>stgrid</code> variables
used in the epidemic component of the fitted <code>"twinstim"</code>
<code>object</code> as stored in <code>formula(object)$epidemic</code>.
For <code>trimmed</code> R0 values, <code>newevents</code> must additionally
contain the components <code>.influenceRegion</code> and, if using the
<code>Fcircle</code> trick in the <code>siaf</code> specification, also
<code>.bdist</code> (cf. the hidden columns in the <code>events</code>
component of class <code>"epidataCS"</code>).
</p>
</td></tr>
<tr><td><code id="R0_+3A_trimmed">trimmed</code></td>
<td>

<p>logical indicating if the individual reproduction numbers should be
calculated by integrating the epidemic intensities over the
observation period and region only (<code>trimmed = TRUE</code>) or over
the whole time-space domain R+ x R^2 (<code>trimmed = FALSE</code>). By
default, if <code>newevents</code> is missing, the trimmed <code>R0</code>
values stored in <code>object</code> are returned. Trimming means that
events near the (spatial or temporal) edges of the observation
domain have lower reproduction numbers (ceteris paribus) because
events outside the observation domain are not observed.
</p>
</td></tr>
<tr><td><code id="R0_+3A_newcoef">newcoef</code></td>
<td>

<p>the model parameters to use when calculating reproduction numbers.
The default (<code>NULL</code>) is to use the MLE <code>coef(object)</code>.
This argument mainly serves the construction of Monte Carlo
confidence intervals by evaluating <code>R0</code> for parameter vectors
sampled from the asymptotic multivariate normal distribution of the MLE,
see Examples.
</p>
</td></tr>
<tr><td><code id="R0_+3A_...">...</code></td>
<td>
<p>additional arguments passed to methods.
Currently unused for the <code>twinstim</code> method.</p>
</td></tr>
<tr><td><code id="R0_+3A_eta">eta</code></td>
<td>
<p>a value for the epidemic linear predictor, see details.</p>
</td></tr>
<tr><td><code id="R0_+3A_eps.s">eps.s</code>, <code id="R0_+3A_eps.t">eps.t</code></td>
<td>
<p>the spatial/temporal radius of interaction.
If <code>NULL</code> (the default), the original value from the data is
used if this is unique and an error is thrown otherwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the <code>"<a href="#topic+twinstim">twinstim</a>"</code> class, the individual-specific expected
number <code class="reqn">\mu_j</code> of infections caused by individual (event) <code class="reqn">j</code>
inside its theoretical (untrimmed) spatio-temporal range of interaction
given by its <code>eps.t</code> (<code class="reqn">\epsilon</code>) and <code>eps.s</code>
(<code class="reqn">\delta</code>) values is defined as follows (cf. Meyer et al, 2012):
</p>
<p style="text-align: center;"><code class="reqn">\mu_j = e^{\eta_j} \cdot
  \int_{b(\bold{0},\delta)} f(\bold{s}) d\bold{s} \cdot
  \int_0^\epsilon g(t) dt .</code>
</p>

<p>Here, <code class="reqn">b(\bold{0},\delta)</code> denotes the disc centred at (0,0)' with
radius <code class="reqn">\delta</code>, <code class="reqn">\eta_j</code> is the epidemic linear predictor,
<code class="reqn">g(t)</code> is the temporal interaction function, and <code class="reqn">f(\bold{s})</code>
is the spatial interaction function. For a type-specific
<code>twinstim</code>, there is an additional factor for the number of event
types which can be infected by the type of event <code class="reqn">j</code> and the
interaction functions may be type-specific as well.
</p>
<p>Alternatively to the equation above,
the <code>trimmed</code> (observed) reproduction numbers
are obtain by integrating over the observed infectious domains of the
individuals, i.e. integrate <code class="reqn">f</code> over the intersection of the
influence region with the observation region <code>W</code>
(i.e. over <code class="reqn">\{ W \cap b(\bold{s}_j,\delta) \} - \bold{s}_j</code>)
and <code class="reqn">g</code> over the intersection of the observed infectious period with
the observation period <code class="reqn">(t_0;T]</code> (i.e. over
<code class="reqn">(0; \min(T-t_j,\epsilon)]</code>).
</p>
<p>The function <code>simpleR0</code> computes
</p>
<p style="text-align: center;"><code class="reqn">\exp(\eta) \cdot
  \int_{b(\bold{0},\delta)} f(\bold{s}) d\bold{s} \cdot 
  \int_0^{\epsilon} g(t) dt ,</code>
</p>

<p>where <code class="reqn">\eta</code> defaults to <code class="reqn">\gamma_0</code> disregarding any epidemic
effects of types and marks. It is thus only
suitable for simple epidemic <code><a href="#topic+twinstim">twinstim</a></code> models with
<code>epidemic = ~1</code>, a diagonal (or secondary diagonal) <code>qmatrix</code>,
and type-invariant interaction functions.
<code>simpleR0</code> mainly exists for use by <code><a href="#topic+epitest">epitest</a></code>.
</p>
<p>(Numerical) Integration is performed exactly as during the fitting of
<code>object</code>, for instance <code>object$control.siaf</code> is queried if
necessary.
</p>


<h3>Value</h3>

<p>For the <code>R0</code> methods,
a numeric vector of estimated reproduction numbers from the fitted
model <code>object</code> corresponding to the rows of <code>newevents</code> (if
supplied) or the original fitted events including events of the prehistory.
</p>
<p>For <code>simpleR0</code>, a single number (see details).
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer</p>


<h3>References</h3>

<p>Meyer, S., Elias, J. and Höhle, M. (2012):
A space-time conditional intensity model for invasive meningococcal
disease occurrence. <em>Biometrics</em>, <b>68</b>, 607-616.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01684.x">doi:10.1111/j.1541-0420.2011.01684.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load the 'imdepi' data and a model fit
data("imdepi", "imdepifit")

## calculate individual and type-specific reproduction numbers
R0s &lt;- R0(imdepifit)
tapply(R0s, imdepi$events@data[names(R0s), "type"], summary)

## untrimmed R0 for specific event settings
refevent &lt;- data.frame(agegrp = "[0,3)", type = "B", eps.s = Inf, eps.t = 30)
setting2 &lt;- data.frame(agegrp = "[3,19)", type = "C", eps.s = Inf, eps.t = 14)
newevents &lt;- rbind("ref" = refevent, "event2" = setting2)
(R0_examples &lt;- R0(imdepifit, newevents = newevents, trimmed = FALSE))
stopifnot(all.equal(R0_examples[["ref"]],
                    simpleR0(imdepifit)))


### compute a Monte Carlo confidence interval

## use a simpler model with constant 'siaf' for speed
simplefit &lt;- update(imdepifit, epidemic=~type, siaf=NULL, subset=NULL)

## we'd like to compute the mean R0's by event type
meanR0ByType &lt;- function (newcoef) {
    R0events &lt;- R0(simplefit, newcoef=newcoef)
    tapply(R0events, imdepi$events@data[names(R0events),"type"], mean)
}
(meansMLE &lt;- meanR0ByType(newcoef=NULL))

## sample B times from asymptotic multivariate normal of the MLE
B &lt;- 5  # CAVE: toy example! In practice this has to be much larger
set.seed(123)
parsamples &lt;- MASS::mvrnorm(B, mu=coef(simplefit), Sigma=vcov(simplefit))

## for each sample compute the 'meanR0ByType'
meansMC &lt;- apply(parsamples, 1, meanR0ByType)

## get the quantiles and print the result
cisMC &lt;- apply(cbind(meansMLE, meansMC), 1, quantile, probs=c(0.025,0.975))
print(rbind(MLE=meansMLE, cisMC))


### R0 for a simple epidemic model
### without epidemic covariates, i.e., all individuals are equally infectious

mepi1 &lt;- update(simplefit, epidemic = ~1, subset = type == "B",
                model = TRUE, verbose = FALSE)
## using the default spatial and temporal ranges of interaction
(R0B &lt;- simpleR0(mepi1))  # eps.s=200, eps.t=30
stopifnot(identical(R0B, R0(mepi1, trimmed = FALSE)[[1]]))
## assuming smaller interaction ranges (but same infection intensity)
simpleR0(mepi1, eps.s = 50, eps.t = 15)
</code></pre>

<hr>
<h2 id='ranef'>Import from package <span class="pkg">nlme</span></h2><span id='topic+ranef'></span><span id='topic+fixef'></span>

<h3>Description</h3>

<p>The generic functions <code>ranef</code> and <code>fixef</code>
are imported from package <span class="pkg">nlme</span>.
See <code><a href="nlme.html#topic+ranef">nlme::ranef</a></code> for <span class="pkg">nlme</span>'s own
description, and <code><a href="#topic+ranef.hhh4">ranef.hhh4</a></code> or <code><a href="#topic+fixef.hhh4">fixef.hhh4</a></code>
for the added methods for <code>"<a href="#topic+hhh4">hhh4</a>"</code> models.
</p>

<hr>
<h2 id='refvalIdxByDate'>Compute indices of reference value using Date class</h2><span id='topic+refvalIdxByDate'></span>

<h3>Description</h3>

 
<p>The reference values are formed based on computations 
of <code>seq</code> for Date class arguments.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>refvalIdxByDate(t0, b, w, epochStr, epochs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="refvalIdxByDate_+3A_t0">t0</code></td>
<td>
<p>A Date object describing the time point</p>
</td></tr>
<tr><td><code id="refvalIdxByDate_+3A_b">b</code></td>
<td>
<p>Number of years to go back in time</p>
</td></tr>
<tr><td><code id="refvalIdxByDate_+3A_w">w</code></td>
<td>
<p>Half width of window to include reference values for</p>
</td></tr>
<tr><td><code id="refvalIdxByDate_+3A_epochstr">epochStr</code></td>
<td>
<p>One of <code>"1 month"</code>, <code>"1 week"</code> or <code>"1 day"</code></p>
</td></tr>
<tr><td><code id="refvalIdxByDate_+3A_epochs">epochs</code></td>
<td>
<p>Vector containing the epoch value of the sts/disProg object</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>Using the Date class the reference values are formed as follows:
Starting from <code>t0</code> go i, i= 1,...,<code>b</code> years back in time.
For each year, go <code>w</code> epochs back and include from here to
<code>w</code> epochs after <code>t0</code>.
</p>
<p>In case of weeks we always go back to the closest Monday of this
date. In case of months we also go back in time to closest 1st of
month. 
</p>


<h3>Value</h3>

<p>a vector of indices in epochs which match
</p>

<hr>
<h2 id='residualsCT'>
Extract Cox-Snell-like Residuals of a Fitted Point Process
</h2><span id='topic+residuals.twinSIR'></span><span id='topic+residuals.twinstim'></span><span id='topic+residuals.simEpidataCS'></span>

<h3>Description</h3>

<p>Extract the &ldquo;residual process&rdquo; (cf. Ogata, 1988) of a fitted
point process model specified through the conditional intensity
function, for instance a model of class <code>"<a href="#topic+twinSIR">twinSIR</a>"</code> or
<code>"<a href="#topic+twinstim">twinstim</a>"</code> (and also <code>"<a href="#topic+simEpidataCS">simEpidataCS</a>"</code>).
The residuals are defined as the fitted cumulative intensities at the
event times, and are generalized residuals similar to those discussed in
Cox and Snell (1968).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinSIR'
residuals(object, ...)
## S3 method for class 'twinstim'
residuals(object, ...)
## S3 method for class 'simEpidataCS'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residualsCT_+3A_object">object</code></td>
<td>

<p>an object of one of the aforementioned model classes.
</p>
</td></tr>
<tr><td><code id="residualsCT_+3A_...">...</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects of class <code>twinstim</code>, the residuals may already be
stored in the object as component <code>object$tau</code> if the model was
fitted with <code>cumCIF = TRUE</code> (and they always are for
<code>"simEpidataCS"</code>). In this case, the <code>residuals</code>
method just extracts these values.  Otherwise, the residuals have to
be calculated, which is only possible with access to the model
environment, i.e. <code>object</code> must have been fitted with
<code>model = TRUE</code>. The calculated residuals are then also appended
to <code>object</code> for future use. However, if <code>cumCIF</code> and
<code>model</code> were both set to true in the <code>object</code> fit, then it
is not possible to calculate the residuals and the method returns an
error.
</p>


<h3>Value</h3>

<p>Numeric vector of length the number of events of the corresponding point
process fitted by <code>object</code>. This is the observed residual process.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Ogata, Y. (1988)
Statistical models for earthquake occurrences and residual analysis
for point processes.
<em>Journal of the American Statistical Association</em>, 83, 9-27
</p>
<p>Cox, D. R. &amp; Snell, E. J. (1968)
A general definition of residuals.
<em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, 30, 248-275
</p>


<h3>See Also</h3>

<p><code><a href="#topic+checkResidualProcess">checkResidualProcess</a></code> to graphically check the
goodness-of-fit of the underlying model.
</p>

<hr>
<h2 id='rotaBB'>Rotavirus cases in Brandenburg, Germany, during 2002-2013 stratified by 5 age categories</h2><span id='topic+rotaBB'></span>

<h3>Description</h3>

<p>Monthly reported number of rotavirus infections in the federal state of
Brandenburg stratified by five age categories (00-04, 05-09, 10-14, 15-69, 70+)
during 2002-2013.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rotaBB)</code></pre>


<h3>Format</h3>

<p>A <code>sts</code> object. 
</p>


<h3>Source</h3>

<p>The data were queried on 19 Feb 2014 from the Survstat@RKI database of the German
Robert Koch Institute (<a href="https://survstat.rki.de/">https://survstat.rki.de/</a>). 
</p>

<hr>
<h2 id='runifdisc'>
Sample Points Uniformly on a Disc
</h2><span id='topic+runifdisc'></span>

<h3>Description</h3>

<p>Sample <code>n</code> points uniformly on a disc of radius <code>r</code> in
two-dimensional euclidean space via transformation to polar coordinates:
the angle is sampled uniformly from <code class="reqn">U(0,2\pi)</code>, the length is
sampled uniformly from <code class="reqn">\sqrt{U(0,r^2)}</code>. The sampled polar
coordinates are then back-transformed to cartesian coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runifdisc(n, r = 1, buffer = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runifdisc_+3A_n">n</code></td>
<td>

<p>integer size of the sample.
</p>
</td></tr>
<tr><td><code id="runifdisc_+3A_r">r</code></td>
<td>

<p>numeric radius of the disc (centered at (0,0)).
</p>
</td></tr>
<tr><td><code id="runifdisc_+3A_buffer">buffer</code></td>
<td>

<p>radius of inner buffer zone without points.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two-column coordinate matrix of the sampled points.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- surveillance:::runifdisc(1000, 3)
plot(x)
</code></pre>

<hr>
<h2 id='salmAllOnset'>Salmonella cases in Germany 2001-2014 by data of symptoms onset</h2><span id='topic+salmAllOnset'></span>

<h3>Description</h3>

<p>A dataset containing the reported number of cases of Salmonella in
Germany 2001-2014 aggregated by data of disease onset. The slot
<code>control</code> contains a matrix <code>reportingTriangle$n</code> with the
reporting triangle as described in Salmon et al. (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(salmAllOnset)
</code></pre>


<h3>Format</h3>

<p>A sts-object</p>


<h3>References</h3>

<p>Salmon, M., Schumacher, D., Stark, K., Höhle, M. (2015):
Bayesian outbreak detection in the presence of reporting delays.
Biometrical Journal, 57 (6), 1051-1067.
</p>

<hr>
<h2 id='salmHospitalized'>Hospitalized Salmonella cases in Germany 2004-2014</h2><span id='topic+salmHospitalized'></span>

<h3>Description</h3>

<p>Reported number of cases of Salmonella in Germany 2004-2014 (early 2014) that were hospitalized. The corresponding 
total number of cases is indicated in the slot <code>populationFrac</code> and <code>multinomialTS</code> is <code>TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(salmHospitalized)</code></pre>


<h3>Format</h3>

<p>An <code>"<a href="#topic+sts-class">sts</a>"</code> object. 
</p>


<h3>Source</h3>

<p>The data are queried from the Survstat@RKI database of the German
Robert Koch Institute (<a href="https://survstat.rki.de/">https://survstat.rki.de/</a>).
</p>

<hr>
<h2 id='salmNewport'>Salmonella Newport cases in Germany 2004-2013</h2><span id='topic+salmNewport'></span>

<h3>Description</h3>

<p>Reported number of cases of the Salmonella Newport serovar in the 16 German
federal states 2004-2013.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(salmNewport)</code></pre>


<h3>Format</h3>

<p>A <code>sts</code> object. 
</p>


<h3>Source</h3>

<p>The data were queried from the SurvStat@RKI database of the German
Robert Koch Institute (<a href="https://survstat.rki.de/">https://survstat.rki.de/</a>). A detailed
description of the 2011 outbreak can be found in the publication
</p>
<p>Bayer, C., Bernard, H., Prager, R., Rabsch, W., Hiller, P., Malorny,
B., Pfefferkorn, B., Frank, C., de Jong, A., Friesema, I., Start, K.,
Rosner, B.M. (2014), An outbreak of Salmonella Newport associated with
mung bean sprouts in Germany and the Netherlands, October to November
2011, Eurosurveillance 19(1):pii=20665.
</p>

<hr>
<h2 id='salmonella.agona'>Salmonella Agona cases in the UK 1990-1995</h2><span id='topic+salmonella.agona'></span>

<h3>Description</h3>

<p>Reported number of cases of the Salmonella Agona serovar in the UK
1990-1995. Note however
that the counts do not correspond exactly to the ones used by
Farrington et. al (1996).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(salmonella.agona)</code></pre>


<h3>Format</h3>

<p>A <code>disProg</code> object with 312 observations starting from week 1 in 1990.
</p>


<h3>Source</h3>

<p>A statistical algorithm for the early detection of outbreaks of
infectious disease, Farrington, C.P., Andrews, N.J, Beale A.D. and
Catchpole, M.A. (1996). , J. R. Statist. Soc. A, 159, 547-563.
</p>

<hr>
<h2 id='scores'>
Proper Scoring Rules for Poisson or Negative Binomial Predictions
</h2><span id='topic+scores'></span><span id='topic+scores.default'></span><span id='topic+logs'></span><span id='topic+rps'></span><span id='topic+dss'></span><span id='topic+ses'></span>

<h3>Description</h3>

<p>Proper scoring rules for Poisson or negative binomial predictions
of count data are described in Czado et al. (2009).
The following scores are implemented:
logarithmic score (<code>logs</code>),
ranked probability score (<code>rps</code>),
Dawid-Sebastiani score (<code>dss</code>),
squared error score (<code>ses</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scores(x, ...)

## Default S3 method:
scores(x, mu, size = NULL,
       which = c("logs", "rps", "dss", "ses"),
       sign = FALSE, ...)

logs(x, mu, size = NULL)
rps(x, mu, size = NULL, k = 40, tolerance = sqrt(.Machine$double.eps))
dss(x, mu, size = NULL)
ses(x, mu, size = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_+3A_x">x</code></td>
<td>

<p>the observed counts.
All functions are vectorized and also accept matrices or arrays.
Dimensions are preserved.
</p>
</td></tr>
<tr><td><code id="scores_+3A_mu">mu</code></td>
<td>

<p>the means of the predictive distributions for the
observations <code>x</code>.
</p>
</td></tr>
<tr><td><code id="scores_+3A_size">size</code></td>
<td>

<p>either <code>NULL</code> (default), indicating Poisson predictions with mean
<code>mu</code>, or dispersion parameters of
negative binomial forecasts for the observations <code>x</code>,
parametrized as in <code><a href="stats.html#topic+dnbinom">dnbinom</a></code> with variance
<code>mu*(1+mu/size)</code>.
</p>
</td></tr>
<tr><td><code id="scores_+3A_which">which</code></td>
<td>

<p>a character vector specifying which scoring rules to apply.
By default, all four proper scores are calculated.
The normalized squared error score (<code>"nses"</code>) is also available
but it is improper and hence not computed by default.
</p>
</td></tr>
<tr><td><code id="scores_+3A_sign">sign</code></td>
<td>

<p>a logical indicating if the function should also return
<code>sign(x-mu)</code>, i.e., the sign of the difference between
the observed counts and corresponding predictions.
</p>
</td></tr>
<tr><td><code id="scores_+3A_...">...</code></td>
<td>

<p>unused (argument of the generic).
</p>
</td></tr>
<tr><td><code id="scores_+3A_k">k</code></td>
<td>

<p>scalar argument controlling the finite sum approximation for the
<code>rps</code> with truncation at <code>max(x, ceiling(mu + k*sd))</code>.
</p>
</td></tr>
<tr><td><code id="scores_+3A_tolerance">tolerance</code></td>
<td>

<p>absolute tolerance for the finite sum approximation employed in the
<code>rps</code> calculation. A warning is produced if the approximation
with <code>k</code> summands is insufficient for the specified
<code>tolerance</code>. In this case, increase <code>k</code> for higher
precision (or use a larger tolerance).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The scoring functions return the individual scores for the predictions
of the observations in <code>x</code> (maintaining their dimension attributes).
</p>
<p>The default <code>scores</code>-method applies the selected (<code>which</code>)
scoring functions (and calculates <code>sign(x-mu)</code>) and returns the
results in an array (via <code><a href="base.html#topic+simplify2array">simplify2array</a></code>), where the last
dimension corresponds to the different scores.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer and Michaela Paul
</p>


<h3>References</h3>

<p>Czado, C., Gneiting, T. and Held, L. (2009):
Predictive model assessment for count data.
<em>Biometrics</em>, <b>65</b> (4), 1254-1261.
<a href="https://doi.org/10.1111/j.1541-0420.2009.01191.x">doi:10.1111/j.1541-0420.2009.01191.x</a>
</p>


<h3>See Also</h3>

<p>The R package <a href="https://CRAN.R-project.org/package=scoringRules"><span class="pkg">scoringRules</span></a> implements the logarithmic
score and the (continuous) ranked probability score for many
distributions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu &lt;- c(0.1, 1, 3, 6, 3*pi, 100)
size &lt;- 0.5
set.seed(1)
y &lt;- rnbinom(length(mu), mu = mu, size = size)
scores(y, mu = mu, size = size)
scores(y, mu = mu, size = 1)  # ses ignores the variance
scores(y, mu = 1, size = size)

## apply a specific scoring rule
scores(y, mu = mu, size = size, which = "rps")
rps(y, mu = mu, size = size)

## rps() gives NA (with a warning) if the NegBin is too wide
rps(1e5, mu = 1e5, size = 1e-5)
</code></pre>

<hr>
<h2 id='shadar'>Salmonella Hadar cases in Germany 2001-2006</h2><span id='topic+shadar'></span>

<h3>Description</h3>

<p>Number of salmonella hadar cases in
Germany 2001-2006. An increase is seen during 2006.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(shadar)</code></pre>


<h3>Format</h3>

<p>A <code>disProg</code> object containing <code class="reqn">295\times 1</code>
observations starting from week 1 in 2001 to week 35 in 2006. 
</p>


<h3>Source</h3>

<p>Robert Koch-Institut: SurvStat: <a href="https://survstat.rki.de/">https://survstat.rki.de/</a>;
Queried on September 2006.
</p>
<p>Robert Koch Institut, Epidemiologisches Bulletin 31/2006.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(shadar)
plot(shadar)
</code></pre>

<hr>
<h2 id='siaf.simulatePC'>
Simulation from an Isotropic Spatial Kernel via Polar Coordinates
</h2><span id='topic+siaf.simulatePC'></span>

<h3>Description</h3>

<p>To sample points from isotropic spatial kernels
<code class="reqn">f_2(s) = f(||s||)</code> such as <code><a href="#topic+siaf.powerlaw">siaf.powerlaw</a></code> on a
bounded domain (i.e., <code class="reqn">||s|| &lt; \code{ub}</code>), it is
convenient to switch to polar coordinates <code class="reqn">(r,\theta)</code>,
which have a density proportional to
<code class="reqn">r f_2((r \cos(\theta), r \sin(\theta))) = r f(r)</code>
(independent of the angle <code class="reqn">\theta</code> due to isotropy).
The angle is thus simply drawn uniformly in <code class="reqn">[0,2\pi)</code>, and
<code class="reqn">r</code> can be sampled by the inversion method, where numeric root
finding is used for the quantiles (since the quantile function is not
available in closed form).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>siaf.simulatePC(intrfr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="siaf.simulatePC_+3A_intrfr">intrfr</code></td>
<td>

<p>a function computing the integral of <code class="reqn">r f(r)</code> from 0 to <code>R</code>
(first argument, not necessarily named <code>R</code>). Parameters of the
function are passed as its second argument and a third argument is
the event type.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a function with arguments <code>(n, siafpars, type, ub)</code>, which
samples <code>n</code> points from the spatial kernel <code class="reqn">f_2(s)</code> within the
disc of radius <code>ub</code>, where <code>siafpars</code> and <code>type</code> are
passed as second and third argument to <code>intrfr</code>.
The environment of the returned function will be the caller's environment.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simfun &lt;- siaf.powerlaw()$simulate
## is internally generated as siaf.simulatePC(intrfr.powerlaw)

set.seed(1)
simfun(n=10, siafpars=log(c(sigma=1, d=2)), ub=5)
</code></pre>

<hr>
<h2 id='sim.pointSource'>Simulate Point-Source Epidemics</h2><span id='topic+sim.pointSource'></span>

<h3>Description</h3>

<p>Simulation of epidemics which were introduced by point sources.
The basis of this programme is a combination of a Hidden Markov Model
(to get random timepoints for outbreaks) and a simple model
(compare <code><a href="#topic+sim.seasonalNoise">sim.seasonalNoise</a></code>) to simulate the baseline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.pointSource(p = 0.99, r = 0.01, length = 400, A = 1, 
                alpha = 1, beta = 0, phi = 0, frequency = 1, state = NULL, K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.pointSource_+3A_p">p</code></td>
<td>
<p>probability to get a new outbreak at time i if there was one at time i-1, default 0.99.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_r">r</code></td>
<td>
<p>probability to get no new outbreak at time i if there was none at time i-1, default 0.01.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_length">length</code></td>
<td>
<p>number of weeks to model, default 400. <code>length</code> is ignored if <code>state</code>
is given. In this case the length of <code>state</code> is used.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_a">A</code></td>
<td>
<p>amplitude (range of sinus), default = 1.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_alpha">alpha</code></td>
<td>
<p>parameter to move along the y-axis (negative values not allowed)
with alpha &gt; = A, default = 1.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_beta">beta</code></td>
<td>
<p>regression coefficient, default = 0.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_phi">phi</code></td>
<td>
<p>factor to create seasonal moves
(moves the curve along the x-axis), default = 0.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_frequency">frequency</code></td>
<td>
<p>factor to determine the oscillation-frequency, default = 1.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_state">state</code></td>
<td>
<p>use a state chain to define the status at this timepoint (outbreak or not).
If not given a Markov chain is generated by the programme, default NULL.</p>
</td></tr>
<tr><td><code id="sim.pointSource_+3A_k">K</code></td>
<td>
<p>additional weigth for an outbreak which influences the distribution
parameter mu, default = 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>disProg</code> (disease progress) object including a list of the
observed, the state chain and nearly all input parameters.
</p>


<h3>Author(s)</h3>

<p>M. Höhle, A. Riebler, C. Lang</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim.seasonalNoise">sim.seasonalNoise</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
disProgObj &lt;- sim.pointSource(p = 0.99, r = 0.5, length = 208,
                              A = 1, alpha = 1, beta = 0, phi = 0,
                              frequency = 1, state = NULL, K = 2)
plot(disProgObj)

## with predefined state chain
state &lt;- rep(c(0,0,0,0,0,0,0,0,1,1), 20)
disProgObj &lt;- sim.pointSource(state = state, K = 1.2)
plot(disProgObj)

## simulate epidemic, send to RKI 1 system, plot, and compute quality values
testSim &lt;- function (..., K = 0, range = 200:400) {
  disProgObj &lt;- sim.pointSource(..., K = K)
  survResults &lt;- algo.call(disProgObj,
    control = list(list(funcName = "rki1", range = range)))
  plot(survResults[[1]], "RKI 1", "Simulation")
  algo.compare(survResults)
}
testSim(K = 2)
testSim(r = 0.5, K = 5)  # larger and more frequent outbreaks
</code></pre>

<hr>
<h2 id='sim.seasonalNoise'>Generation of Background Noise for Simulated Timeseries</h2><span id='topic+sim.seasonalNoise'></span>

<h3>Description</h3>

<p>Generation of a cyclic model of a Poisson distribution
as background data for a simulated timevector.
</p>
<p>The mean of the Poisson distribution is modelled as:
</p>
<p style="text-align: center;"><code class="reqn">\mu = \exp(A \sin( frequency \cdot \omega \cdot (t + \phi)) + \alpha  + \beta * t +  K * state)</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>sim.seasonalNoise(A = 1, alpha = 1, beta = 0, phi = 0,
                  length, frequency = 1, state = NULL, K = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.seasonalNoise_+3A_a">A</code></td>
<td>
<p>amplitude (range of sinus), default = 1.</p>
</td></tr>
<tr><td><code id="sim.seasonalNoise_+3A_alpha">alpha</code></td>
<td>
<p>parameter to move along the y-axis (negative values not allowed)
with alpha &gt; = A, default = 1.</p>
</td></tr>
<tr><td><code id="sim.seasonalNoise_+3A_beta">beta</code></td>
<td>
<p>regression coefficient, default = 0.</p>
</td></tr>
<tr><td><code id="sim.seasonalNoise_+3A_phi">phi</code></td>
<td>
<p>factor to create seasonal moves
(moves the curve along the x-axis), default = 0.</p>
</td></tr>
<tr><td><code id="sim.seasonalNoise_+3A_length">length</code></td>
<td>
<p>number of weeks to model.</p>
</td></tr>
<tr><td><code id="sim.seasonalNoise_+3A_frequency">frequency</code></td>
<td>
<p>factor to determine the oscillation-frequency, default = 1.</p>
</td></tr>
<tr><td><code id="sim.seasonalNoise_+3A_state">state</code></td>
<td>
<p>if a state chain is entered the outbreaks will be additional
weighted by K.</p>
</td></tr>
<tr><td><code id="sim.seasonalNoise_+3A_k">K</code></td>
<td>
<p>additional weigth for an outbreak which influences the distribution
parameter mu, default = 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>seasonNoise</code> which includes the modelled
timevector, the parameter <code>mu</code> and all input parameters.
</p>


<h3>Author(s)</h3>

<p>M. Höhle, A. Riebler, C. Lang</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim.pointSource">sim.pointSource</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>season &lt;- sim.seasonalNoise(length = 300)
plot(season$seasonalBackground,type = "l")

# use a negative timetrend beta
season &lt;- sim.seasonalNoise(beta = -0.003, length = 300)
plot(season$seasonalBackground,type = "l")
</code></pre>

<hr>
<h2 id='stcd'>Spatio-temporal cluster detection</h2><span id='topic+stcd'></span>

<h3>Description</h3>

<p>Shiryaev-Roberts based prospective spatio-temporal cluster detection
as in Assuncao &amp; Correa (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stcd(x, y,t,radius,epsilon,areaA, areaAcapBk, threshold, cusum=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stcd_+3A_x">x</code></td>
<td>
<p>Vector containing spatial x coordinate of the events.</p>
</td></tr>
<tr><td><code id="stcd_+3A_y">y</code></td>
<td>
<p>Vector containing spatial y coordinate of the events.</p>
</td></tr>
<tr><td><code id="stcd_+3A_t">t</code></td>
<td>
<p>Vector containing the time points of the events. It is
assumed that the vector is sorted (early-&gt;last).</p>
</td></tr>
<tr><td><code id="stcd_+3A_radius">radius</code></td>
<td>
<p>Radius of the cluster to detect.</p>
</td></tr>
<tr><td><code id="stcd_+3A_epsilon">epsilon</code></td>
<td>
<p>Relative change of event-intensity within the cluster
to detect. See reference paper for an explicit definition.</p>
</td></tr>
<tr><td><code id="stcd_+3A_areaa">areaA</code></td>
<td>
<p>Area of the observation region A (single number) &ndash; This
argument is currently ignored!</p>
</td></tr>
<tr><td><code id="stcd_+3A_areaacapbk">areaAcapBk</code></td>
<td>
<p>Area of A \ B(s_k,rho) for all k=1,...,n
(vector). This argument is currently ignored!</p>
</td></tr>
<tr><td><code id="stcd_+3A_threshold">threshold</code></td>
<td>
<p>Threshold limit for the alarm and should be equal to
the desired Average-Run-Length (ARL) of the detector.</p>
</td></tr>
<tr><td><code id="stcd_+3A_cusum">cusum</code></td>
<td>
<p>(logical) If <code>FALSE</code> (default) then the
Shiryaev-Roberts detector is used as in the original article by
Assuncao &amp; Correa (2009), i.e. <code class="reqn">R_n = \sum_{k=1}^n
      \Lambda_{k,n}</code>, where <code class="reqn">\Lambda_{k,n}</code> denotes the likelihood
ratio between the in-control and out-of control model. If
<code>TRUE</code>, CUSUM test statistic is 
used instead. Here, </p>
<p style="text-align: center;"><code class="reqn">R_n = \max_{1\leq k \leq n}
      \Lambda_{k,n}</code>
</p>
<p>. Note that this has implications on what threshold
will sound the alarm (CUSUM threshold needs to be smaller).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Shiryaev-Roberts based spatio-temporal cluster detection based
on the work in Assuncao and Correa (2009). The implementation
is based on C++ code originally written by Marcos Oliveira Prates, UFMG,
Brazil and provided by Thais Correa, UFMG, Brazil during her research
stay in Munich. This stay was financially supported by the Munich
Center of Health Sciences.
</p>
<p>Note that the vectors <code>x</code>, <code>y</code> and <code>t</code> need to be of the
same length. Furthermore, the vector <code>t</code> needs to be sorted (to
improve speed, the latter is not verified within the function).
</p>
<p>The current implementation uses a call to a C++ function to perform the
actual computations of the test statistic. The function is currently
experimental &ndash; data type and results may be subject to changes.
</p>


<h3>Value</h3>

<p>A list with three components
</p>
<table>
<tr><td><code>R</code></td>
<td>
<p>A vector of the same length as the input containing the value
of the test statistic for each observation.</p>
</td></tr>
<tr><td><code>idxFA</code></td>
<td>
<p>Index in the x,y,t vector causing a possible alarm. If no
cluster was detected, then a value of <code>-1</code> is returned here.</p>
</td></tr>
<tr><td><code>idxCC</code></td>
<td>
<p>index in the x,y,t vector of the event containing the
cluster. If no cluster was detected, then a value of <code>-1</code> is
returned here.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>M. O. Prates, T. Correa and M. Höhle</p>


<h3>References</h3>

<p>Assuncao, R. and Correa, T. (2009), Surveillance to detect emerging
space-time clusters, Computational Statistics &amp; Data Analysis,
53(8):2817-2830.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("splancs")) {
    # load the data from package "splancs"
    data(burkitt, package="splancs")

    # order the times
    burkitt &lt;- burkitt[order(burkitt$t), ]

    #Parameters for the SR detection
    epsilon &lt;- 0.5 # relative change within the cluster
    radius &lt;- 20 # radius
    threshold &lt;- 161 # threshold limit

    res &lt;- stcd(x=burkitt$x,
                y=burkitt$y,
                t=burkitt$t,
                radius=radius,
                epsilon=epsilon,
                areaA=1,
                areaAcapBk=1,
                threshold=threshold)

    #Index of the event
    which.max(res$R &gt;= threshold)
}
</code></pre>

<hr>
<h2 id='stK'>
Diggle et al (1995) K-function test for space-time clustering
</h2><span id='topic+stKtest'></span><span id='topic+plot.stKtest'></span>

<h3>Description</h3>

<p>The function <code>stKtest</code> wraps functions in package <span class="pkg">splancs</span> to
perform the K-function based Monte Carlo permutation test for space-time
clustering (Diggle et al, 1995) for <code>"epidataCS"</code>.
The implementation is due to Meyer et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stKtest(object, eps.s = NULL, eps.t = NULL, B = 199,
        cores = 1, seed = NULL, poly = object$W)

## S3 method for class 'stKtest'
plot(x, which = c("D", "R", "MC"),
     args.D = list(), args.D0 = args.D, args.R = list(), args.MC = list(),
     mfrow = sort(n2mfrow(length(which))), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stK_+3A_object">object</code></td>
<td>
<p>an object of class <code>"epidataCS"</code>.</p>
</td></tr>
<tr><td><code id="stK_+3A_eps.s">eps.s</code>, <code id="stK_+3A_eps.t">eps.t</code></td>
<td>

<p>numeric vectors defining the spatial and temporal
grids of critical distances over which to evaluate the test.
The default (<code>NULL</code>) uses equidistant values from 0 to the
smallest <code>eps.s</code>/<code>eps.t</code> value in <code>object$events</code>,
but not larger than half the observed spatial/temporal domain.
</p>
</td></tr>
<tr><td><code id="stK_+3A_b">B</code></td>
<td>
<p>the number of permutations.</p>
</td></tr>
<tr><td><code id="stK_+3A_cores">cores</code></td>
<td>

<p>the number of parallel processes over which to distribute the
requested number of permutations.
</p>
</td></tr>
<tr><td><code id="stK_+3A_seed">seed</code></td>
<td>

<p>argument for <code><a href="base.html#topic+set.seed">set.seed</a></code> to initialize the random number
generator such that results become reproducible
(also if <code>cores &gt; 1</code>, see <code><a href="#topic+plapply">plapply</a></code>).
</p>
</td></tr>
<tr><td><code id="stK_+3A_poly">poly</code></td>
<td>

<p>the polygonal observation region of the events (as an object handled
by <code>xylist</code>). The default <code>object$W</code> might not work
since package <span class="pkg">splancs</span> does not support multi-polygons. In this
case, the <code>poly</code> argument can be used to specify a substitute.
</p>
</td></tr>
<tr><td><code id="stK_+3A_x">x</code></td>
<td>
<p>an <code>"stKtest"</code>.</p>
</td></tr>
<tr><td><code id="stK_+3A_which">which</code></td>
<td>

<p>a character vector indicating which diagnostic plots to produce.
The full set is <code>c("D", "D0", "R", "MC")</code>.
The special value <code>which = "stdiagn"</code> means to call the
associated <span class="pkg">splancs</span> function <code><a href="splancs.html#topic+stdiagn">stdiagn</a></code>.
</p>
</td></tr>
<tr><td><code id="stK_+3A_args.d">args.D</code>, <code id="stK_+3A_args.d0">args.D0</code>, <code id="stK_+3A_args.r">args.R</code>, <code id="stK_+3A_args.mc">args.MC</code></td>
<td>

<p>argument lists for the plot functions <code><a href="graphics.html#topic+persp">persp</a></code> (for
<code>"D"</code> and <code>"D0"</code>), <code><a href="graphics.html#topic+plot.default">plot.default</a></code>
(<code>"R"</code>), and <code><a href="MASS.html#topic+truehist">truehist</a></code> (<code>"MC"</code>),
respectively, to modify the default settings.
Ignored if <code>which = "stdiagn"</code>.
</p>
</td></tr>
<tr><td><code id="stK_+3A_mfrow">mfrow</code></td>
<td>

<p><code><a href="graphics.html#topic+par">par</a></code>-setting to layout the plots.
Ignored for <code>which = "stdiagn"</code> and if set to <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="stK_+3A_...">...</code></td>
<td>
<p>ignored (argument of the generic).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"stKtest"</code> (inheriting from <code>"htest"</code>),
which is a list with the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the type of test performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string naming the supplied <code>object</code>.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>the sum <code class="reqn">U</code> of the standardized residuals <code class="reqn">R(s,t)</code>.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the number <code>B</code> of permutations.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>pts</code></td>
<td>
<p>the coordinate matrix of the event locations (for
<code><a href="splancs.html#topic+stdiagn">stdiagn</a></code>.</p>
</td></tr>
<tr><td><code>stK</code></td>
<td>
<p>the estimated K-function as returned by
<code><a href="splancs.html#topic+stkhat">stkhat</a></code>.</p>
</td></tr>
<tr><td><code>seD</code></td>
<td>
<p>the standard error of the estimated <code class="reqn">D(s,t)</code> as
returned by <code><a href="splancs.html#topic+stsecal">stsecal</a></code>.</p>
</td></tr>
<tr><td><code>mctest</code></td>
<td>
<p>the observed and permutation values of the test
statistic as returned by <code><a href="splancs.html#topic+stmctest">stmctest</a></code>.</p>
</td></tr>
</table>
<p>The <code>plot</code>-method invisibly returns <code>NULL</code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Diggle, P. J.; Chetwynd, A. G.; Häggkvist, R. and Morris, S. E. (1995):
Second-order analysis of space-time clustering
<em>Statistical Methods in Medical Research</em>, <b>4</b>, 124-136.
</p>
<p>Meyer, S., Warnke, I., Rössler, W. and Held, L. (2016):
Model-based testing for space-time interaction using point processes:
An application to psychiatric hospital admissions in an urban area.
<em>Spatial and Spatio-temporal Epidemiology</em>, <b>17</b>, 15-25.
<a href="https://doi.org/10.1016/j.sste.2016.03.002">doi:10.1016/j.sste.2016.03.002</a>.
Eprint: <a href="https://arxiv.org/abs/1512.09052">https://arxiv.org/abs/1512.09052</a>.
</p>


<h3>See Also</h3>

<p>the simple <code><a href="#topic+knox">knox</a></code> test and function <code><a href="#topic+epitest">epitest</a></code>
for testing <code>"<a href="#topic+twinstim">twinstim</a>"</code> models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("splancs")) {
    data("imdepi")
    imdepiB &lt;- subset(imdepi, type == "B")
    mainpoly &lt;- coordinates(imdepiB$W@polygons[[1]]@Polygons[[5]])
    SGRID &lt;- c(10, 25, 50, 100, 150)
    TGRID &lt;- c(1, 7, 14, 21)
    B &lt;- 19  # limited here for speed
     
    imdBstKtest &lt;- stKtest(imdepiB, eps.s = SGRID, eps.t = TGRID, B = B,
                           cores = 2, seed = 1, poly = list(mainpoly))
    print(imdBstKtest)
    plot(imdBstKtest)
}
</code></pre>

<hr>
<h2 id='sts_animate'>
Animated Maps and Time Series of Disease Counts or Incidence
</h2><span id='topic+animate.sts'></span>

<h3>Description</h3>

<p>The <code>animate</code>-method for <code><a href="#topic+sts-class">sts</a></code> objects
supersedes the <code><a href="#topic+stsplot">stsplot</a></code> type <code>observed~1|unit*time</code>.
Maps generated by <code><a href="#topic+stsplot_space">stsplot_space</a></code> are
sequentially plotted along time (optionally showing cumulative
counts/incidence), with an optional time series chart below the map
to track the epidemic curve.
It is worth using functionality of the <span class="pkg">animation</span> package
(e.g., <code><a href="animation.html#topic+saveHTML">saveHTML</a></code>) to directly export the
animation into a useful format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sts'
animate(object, tps = NULL, cumulative = FALSE,
        population = NULL, at = 10, ...,
        timeplot = list(pos = 1, size = 0.3, fill = TRUE),
        sleep = 0.5, verbose = interactive(), draw = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sts_animate_+3A_object">object</code></td>
<td>

<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code> or a matrix of counts,
i.e., <code>observed(stsObj)</code>, where especially
<code>colnames(x)</code> have to be contained in <code>row.names(map)</code>.
If a matrix, the <code>map</code> object has to be provided explicitly (as
part of <code>...</code>).
</p>
</td></tr>
<tr><td><code id="sts_animate_+3A_tps">tps</code></td>
<td>

<p>a numeric vector of one or more time points at which to plot the map.
The default <code>tps=NULL</code> means the whole time period <code>1:nrow(object)</code>.
</p>
</td></tr>
<tr><td><code id="sts_animate_+3A_cumulative">cumulative</code></td>
<td>

<p>logical specifying if the cumulative counts/incidence over time
should be plotted. The cumulative incidence is relative to the
population from the first time point <code>tps[1]</code> throughout the
whole animation, while <code>cumulative=FALSE</code> computes the
incidence from the current population numbers.
</p>
</td></tr>
<tr><td><code id="sts_animate_+3A_population">population</code>, <code id="sts_animate_+3A_at">at</code>, <code id="sts_animate_+3A_...">...</code></td>
<td>

<p>arguments for <code><a href="#topic+stsplot_space">stsplot_space</a></code>.
</p>
</td></tr>
<tr><td><code id="sts_animate_+3A_timeplot">timeplot</code></td>
<td>

<p>if a list and package <a href="https://CRAN.R-project.org/package=gridExtra"><span class="pkg">gridExtra</span></a> is available,
a time series chart of the counts along
the selected time points <code>tps</code> will be plotted next to the map.
The list elements determine both the positioning of this plot
(<code>pos</code>, <code>size</code>, and <code>fill</code>) and its appearance.
The default <code>pos=1</code> and <code>size=0.3</code> arguments put the time
series plot below the map, using 30% of the total plot height.
The logical value <code>fill</code> indicates whether to make the panel as
big as possible (default: TRUE). An alternative to <code>fill=FALSE</code>
is to manually specify an <code>aspect</code> (ratio) value in <code>timeplot</code>.
Other list elements are arguments for the internal (and currently
undocumented) function <code>stsplot_timeSimple</code>. For example,
<code>inactive</code> and <code>active</code> are lists of graphical parameters
(e.g., <code>col</code>) determining the appearance of the bars (e.g.,
default color is grey when inactive and black when active),
and the boolean <code>as.Date</code> determines whether dates should be
put on the x-axis (instead of the <code>tps</code> indexes).
</p>
</td></tr>
<tr><td><code id="sts_animate_+3A_sleep">sleep</code></td>
<td>

<p>time to wait (<code>Sys.sleep</code>) between subsequent snapshots (only if
<code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>), in seconds.
</p>
</td></tr>
<tr><td><code id="sts_animate_+3A_verbose">verbose</code></td>
<td>

<p>logical indicating if a <code><a href="utils.html#topic+txtProgressBar">txtProgressBar</a></code> should be shown
during generation of the animation &ndash; which may take a while.
Default is to do so in <code><a href="base.html#topic+interactive">interactive</a></code> sessions.
</p>
</td></tr>
<tr><td><code id="sts_animate_+3A_draw">draw</code></td>
<td>

<p>logical indicating if the produced plots at each time point should
be drawn directly (the default) or not.
The setting <code>draw = FALSE</code> is useful if one would like to
manually arrange the plots, which are always returned invisibly in a
list of length <code>length(tps)</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(invisibly) a list of the <code>length(tps)</code> sequential plot objects.
These are of class <code>"gtable"</code> (from <a href="https://CRAN.R-project.org/package=gtable"><span class="pkg">gtable</span></a>)
if the <code>timeplot</code> is included, otherwise of class
<code>"\code{<a href="lattice.html#topic+trellis.object">trellis</a>"</code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p>the other plot types documented in <code><a href="#topic+stsplot">stsplot</a></code> for static
time series plots and maps.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("measlesWeserEms")

## animate the weekly counts of measles (during weeks 12-16 only, for speed)
if (interactive() &amp;&amp; require("animation")) {
    oldwd &lt;- setwd(tempdir())  # to not clutter up the current working dir
    saveHTML(animate(measlesWeserEms, tps=12:16),
             title="Evolution of the measles epidemic in the Weser-Ems region",
             ani.width=500, ani.height=600)
    setwd(oldwd)
}

## Not run: 
## animate the weekly incidence of measles (per 100'000 inhabitants),
## and label the time series plot with dates in a specified format
animate(measlesWeserEms, tps=12:16,
        population = measlesWeserEms@map$POPULATION / 100000,
        timeplot = list(as.Date = TRUE,
                        scales = list(x = list(format = "%G/%V"))))

## End(Not run)
</code></pre>

<hr>
<h2 id='sts_creation'>Simulate Count Time Series with Outbreaks</h2><span id='topic+sts_creation'></span>

<h3>Description</h3>

<p>Function for simulating a time series and creating an
<code><a href="#topic+sts-class">sts</a></code> object.
As the counts are generated using a negative binomial distribution
one also gets the (1-alpha) quantile for each timepoint (can be interpreted
as an in-control upperbound for in-control values).
The baseline and outbreaks are created as in Noufaily et al. (2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sts_creation(theta, beta, gamma1, gamma2, m, overdispersion, dates,
  sizesOutbreak, datesOutbreak, delayMax, alpha, densityDelay)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sts_creation_+3A_theta">theta</code></td>
<td>
<p>baseline frequency of reports</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_beta">beta</code></td>
<td>
<p>time trend</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_gamma1">gamma1</code></td>
<td>
<p>seasonality</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_gamma2">gamma2</code></td>
<td>
<p>seasonality</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_m">m</code></td>
<td>
<p>seasonality</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_overdispersion">overdispersion</code></td>
<td>
<p><code>size</code> parameter of <code><a href="stats.html#topic+rnbinom">rnbinom</a></code> for
the parameterization with mean and dispersion</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_dates">dates</code></td>
<td>
<p>dates of the time series</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_sizesoutbreak">sizesOutbreak</code></td>
<td>
<p>sizes of all the outbreaks (vector)</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_datesoutbreak">datesOutbreak</code></td>
<td>
<p>dates of all the outbreaks (vector)</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_delaymax">delayMax</code></td>
<td>
<p>maximal delay in time units</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_alpha">alpha</code></td>
<td>
<p>alpha for getting the (1-alpha) quantile of the negative
binomial distribution at each timepoint</p>
</td></tr>
<tr><td><code id="sts_creation_+3A_densitydelay">densityDelay</code></td>
<td>
<p>density distribution for the delay</p>
</td></tr>
</table>


<h3>References</h3>

<p>Noufaily, A., Enki, D.G., Farrington, C.P., Garthwaite, P., Andrews,
N.J., Charlett, A. (2012): An improved algorithm for outbreak
detection in multiple surveillance systems. Statistics in Medicine,
32 (7), 1206-1222.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
# Time series parameters
scenario4 &lt;- c(1.6,0,0.4,0.5,2)
theta &lt;- 1.6
beta &lt;- 0
gamma1 &lt;-0.4
gamma2 &lt;- 0.5
overdispersion &lt;- 1
m &lt;- 1
# Dates
firstDate &lt;- "2006-01-01"
lengthT=350
dates &lt;- as.Date(firstDate) + 7 * 0:(lengthT - 1)
# Maximal delay in weeks
D=10
# Dates and sizes of the outbreaks
datesOutbreak &lt;- as.Date(c("2008-03-30","2011-09-25"))
sizesOutbreak &lt;- c(2,5)
# Delay distribution
data("salmAllOnset")
in2011 &lt;- which(isoWeekYear(epoch(salmAllOnset))$ISOYear == 2011)
rT2011 &lt;- salmAllOnset@control$reportingTriangle$n[in2011,]
densityDelay &lt;- apply(rT2011,2,sum, na.rm=TRUE)/sum(rT2011, na.rm=TRUE)
# alpha for the upperbound
alpha &lt;- 0.05
# Create the sts with the full time series
stsSim &lt;- sts_creation(theta=theta,beta=beta,gamma1=gamma1,gamma2=gamma2,m=m,
                       overdispersion=overdispersion,
                       dates=dates,
                       sizesOutbreak=sizesOutbreak,datesOutbreak=datesOutbreak,
                       delayMax=D,densityDelay=densityDelay,
                       alpha=alpha)
plot(stsSim)
</code></pre>

<hr>
<h2 id='sts_ggplot'>
Time-Series Plots for <code>"sts"</code> Objects Using <span class="pkg">ggplot2</span>
</h2><span id='topic+autoplot.sts'></span>

<h3>Description</h3>

<p>A simple <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a> variant of <code><a href="#topic+stsplot_time">stsplot_time</a></code>,
based on a &ldquo;tidy&rdquo; version of the <code>"sts"</code> object via
<code><a href="#topic+tidy.sts">tidy.sts</a></code>.
It uses a date axis and thus only works for time series indexed by
dates or with a standard frequency (daily, (bi-)weekly, or monthly).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoplot.sts(object, population = FALSE, units = NULL,
             as.one = FALSE, scales = "fixed", width = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sts_ggplot_+3A_object">object</code></td>
<td>
<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.</p>
</td></tr>
<tr><td><code id="sts_ggplot_+3A_population">population</code></td>
<td>
<p>logical indicating whether <code>observed(object)</code>
should be divided by <code>population(object)</code>.
The <code>population</code> argument can also be a scalar,
which is used to scale the denominator <code>population(object)</code>,
i.e., <code>observed(object)</code> is divided by
<code>population(object) / population</code>.
For instance, if <code>population(object)</code> contains raw population
numbers, <code>population = 1000</code> could be used to plot the
incidence per 1000 inhabitants.</p>
</td></tr>
<tr><td><code id="sts_ggplot_+3A_units">units</code></td>
<td>
<p>optional integer or character vector to select the units
(=columns of <code>object</code>) to plot. The default (<code>NULL</code>) is
to plot all time series.</p>
</td></tr>
<tr><td><code id="sts_ggplot_+3A_as.one">as.one</code></td>
<td>
<p>logical indicating if all time series should be plotted
in one panel with <code><a href="ggplot2.html#topic+geom_line">geom_line</a></code>.
By default, the time series are plotted in separate panels (using
<code><a href="ggplot2.html#topic+geom_col">geom_col</a></code>).</p>
</td></tr>
<tr><td><code id="sts_ggplot_+3A_scales">scales</code></td>
<td>
<p>passed to <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>
(for <code>as.one=FALSE</code>). By default, all panels use a common
<code>ylim</code> (and <code>xlim</code>).</p>
</td></tr>
<tr><td><code id="sts_ggplot_+3A_width">width</code></td>
<td>
<p>bar width, passed to <code><a href="ggplot2.html#topic+geom_col">geom_col</a></code>.
Defaults to 7 for weekly time series.</p>
</td></tr>
<tr><td><code id="sts_ggplot_+3A_...">...</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>"ggplot"</code> object.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stsplot_time">stsplot_time</a></code> for the traditional plots.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## compare traditional plot() with ggplot2-based autoplot.sts()
if (requireNamespace("ggplot2")) {
    data("measlesDE")
    plot(measlesDE, units = 1:2)
    autoplot.sts(measlesDE, units = 1:2)
}


## weekly incidence: population(measlesDE) gives population fractions,
## which we need to multiply by the total population
if (require("ggplot2")) {
    autoplot.sts(measlesDE, population = 1000000/82314906) +
        ylab("Weekly incidence [per 1'000'000 inhabitants]")
}
</code></pre>

<hr>
<h2 id='sts_observation'>Create an <code>sts</code> object with a given observation date</h2><span id='topic+sts_observation'></span>

<h3>Description</h3>

<p>Function for creating an <code><a href="#topic+sts-class">sts</a></code> object with a given observation date.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sts_observation(sts, dateObservation, cut = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sts_observation_+3A_sts">sts</code></td>
<td>
<p>sts-object we want to set at a previous state. Needs to include a reporting triangle.</p>
</td></tr>
<tr><td><code id="sts_observation_+3A_dateobservation">dateObservation</code></td>
<td>
<p>Date for which we want the state. Needs to be in the reporting triangle dates.</p>
</td></tr>
<tr><td><code id="sts_observation_+3A_cut">cut</code></td>
<td>
<p>Boolean indicating whether to have 0 counts after the observation date or to simply cut the sts-object</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data("salmAllOnset")
salmAllOnsety2014m01d20 &lt;- sts_observation(salmAllOnset,
  dateObservation="2014-01-20",cut=FALSE)
plot(salmAllOnset)
lines(observed(salmAllOnsety2014m01d20),type="h",col="red")
</code></pre>

<hr>
<h2 id='sts-class'>Class <code>"sts"</code> &ndash; surveillance time series</h2><span id='topic+sts'></span><span id='topic+sts-class'></span><span id='topic+alarms+2Csts-method'></span><span id='topic+alarms+3C-+2Csts-method'></span><span id='topic+upperbound+2Csts-method'></span><span id='topic+upperbound+3C-+2Csts-method'></span><span id='topic+control+2Csts-method'></span><span id='topic+control+3C-+2Csts-method'></span><span id='topic+epoch+2Csts-method'></span><span id='topic+epoch+3C-+2Csts-method'></span><span id='topic+observed+2Csts-method'></span><span id='topic+observed+3C-+2Csts-method'></span><span id='topic+population+2Csts-method'></span><span id='topic+population+3C-+2Csts-method'></span><span id='topic+multinomialTS+2Csts-method'></span><span id='topic+multinomialTS+3C-+2Csts-method'></span><span id='topic+neighbourhood+2Csts-method'></span><span id='topic+neighbourhood+3C-+2Csts-method'></span><span id='topic+dim+2Csts-method'></span><span id='topic+dimnames+2Csts-method'></span><span id='topic+year'></span><span id='topic+year+2Csts-method'></span><span id='topic+epochInYear'></span><span id='topic+epochInYear+2Csts-method'></span><span id='topic+as.data.frame.sts'></span><span id='topic+as.data.frame+2Csts-method'></span><span id='topic+as.ts.sts'></span><span id='topic+coerce+2Csts+2Cts-method'></span><span id='topic+coerce+2Cts+2Csts-method'></span><span id='topic+as.xts.sts'></span>

<h3>Description</h3>

<p>This is a lightweight S4 class to implement (multivariate) time
series of counts, typically from public health surveillance.
The <code>"sts"</code> class supersedes the informal <code>"disProg"</code> class
used in early versions of package <span class="pkg">surveillance</span>. Converters are
available, see <code><a href="#topic+disProg2sts">disProg2sts</a></code>.
</p>
<p>For areal time series, the class can also capture the spatial layout
of the regions, where the data originate from.
The constructor function <code>sts</code> can be used to setup an
<code>"sts"</code> object. Conversion of simple time-series objects
(of class <code>"<a href="stats.html#topic+ts">ts</a>"</code>) is also possible.
The slots of the <code>"sts"</code> class and available methods are
described below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sts(observed, start = c(2000, 1), frequency = 52,
    epoch = NULL, population = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sts-class_+3A_observed">observed</code></td>
<td>
<p>a vector (for a single time series) or matrix (one
time series per column) of counts. A purely numeric data frame will
also do (transformed via <code>as.matrix</code>). This argument sets the
<code>observed</code> slot, which is the core element of the resulting
<code>"sts"</code> object. It determines the dimensions and colnames for
several other slots. The columns (&ldquo;units&rdquo;) typically
correspond to different regions, diseases, or age groups.</p>
</td></tr>
<tr><td><code id="sts-class_+3A_start">start</code>, <code id="sts-class_+3A_frequency">frequency</code></td>
<td>
<p>basic characteristics of the time series data
just like for simple <code>"<a href="stats.html#topic+ts">ts</a>"</code> objects. The (historical)
default values correspond to weekly data starting in the first week
of 2000. The <code>epoch</code> and <code>epochInYear</code> methods use the ISO
8601 specification when converting between week numbers and dates,
see <code><a href="#topic+isoWeekYear">isoWeekYear</a></code>.</p>
</td></tr>
<tr><td><code id="sts-class_+3A_epoch">epoch</code></td>
<td>
<p>observation times, either as an integer sequence (default)
or as a <code>Date</code> vector (in which case <code>epochAsDate</code> is
automatically set to <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sts-class_+3A_population">population</code></td>
<td>
<p>a vector of length the number of columns in
<code>observed</code> or a matrix of the same dimension as
<code>observed</code>. Especially for multivariate time series, the
population numbers (or fractions) underlying the counts in each unit
are relevant for visualization and statistical inference. The
<code>population</code> argument is an alias for the corresponding slot
<code>populationFrac</code>. The default <code>NULL</code> value sets
equal population fractions across all units.</p>
</td></tr>
<tr><td><code id="sts-class_+3A_...">...</code></td>
<td>
<p>further named arguments with names corresponding to slot
names (see the list below). For instance, in the public health surveillance context,
the <code>state</code> slot is used to indicate outbreaks (default:
<code>FALSE</code> for all observations). For areal time series data, the
<code>map</code> and <code>neighbourhood</code> slots are used to store the
spatial structure of the observation region.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>epoch</code>:</dt><dd><p>a numeric vector specifying
the time of observation, typically a week index. Depending on
the <code>freq</code> slot, it could also index days or months.
Furthermore, if <code>epochAsDate=TRUE</code> then <code>epoch</code>
is the integer representation of <code><a href="base.html#topic+Date">Date</a></code>s
giving the exact date of the observation.</p>
</dd>
<dt><code>freq</code>:</dt><dd><p>number of observations per year, e.g.,
52 for weekly data, 12 for monthly data.</p>
</dd>
<dt><code>start</code>:</dt><dd><p>vector of length two denoting the year and the
sample number (week, month, etc.) of the first observation</p>
</dd>
<dt><code>observed</code>:</dt><dd><p>A matrix of size <code>length(epoch)</code> times the
number of regions containing the weekly/monthly number of counts in
each region. The colnames of the matrix should match the ID values of
the shapes in the <code>map</code> slot.</p>
</dd>
<dt><code>state</code>:</dt><dd><p>Matrix with the same dimension as <code>observed</code>
containing Booleans whether at the specific time point there was an
outbreak in the region</p>
</dd>
<dt><code>alarm</code>:</dt><dd><p>Matrix with the same dimension as
<code>observed</code> specifying whether an outbreak detection algorithm
declared a specific time point in the region as having an alarm.</p>
</dd>
<dt><code>upperbound</code>:</dt><dd><p>Matrix with upper bound values </p>
</dd>
<dt><code>neighbourhood</code>:</dt><dd><p>Symmetric matrix of size
<code class="reqn">(number of regions)^2</code> describing the neighbourhood structure. It
may either be a binary adjacency matrix or contain neighbourhood orders
(see the Examples for how to infer the latter from the <code>map</code>).</p>
</dd>
<dt><code>populationFrac</code>:</dt><dd><p>A <code>matrix</code> of population 
fractions or absolute numbers (see <code>multinomialTS</code> below)
with dimensions <code>dim(observed)</code>.</p>
</dd>
<dt><code>map</code>:</dt><dd><p>Object of class <code><a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a></code>
(or <code><a href="sp.html#topic+SpatialPolygonsDataFrame-class">SpatialPolygonsDataFrame</a></code>)
providing a shape of the areas which are monitored. </p>
</dd>
<dt><code>control</code>:</dt><dd><p>Object of class <code>list</code>, this is a
rather free data type to be returned by the surveillance algorithms. </p>
</dd>
<dt><code>epochAsDate</code>:</dt><dd><p>a Boolean indicating
if the <code>epoch</code> slot corresponds to <code>Date</code>s.</p>
</dd>
<dt><code>multinomialTS</code>:</dt><dd><p>a Boolean
stating whether to interpret the object as <code>observed</code> out of
<code>population</code>, i.e. a multinomial interpretation instead of a
count interpretation.</p>
</dd>
</dl>



<h3>Methods</h3>



<h4>Extraction of slots</h4>

<p>There is an extraction (and replacement) method for almost every slot.
The name of the method corresponds to the slot name, with two exceptions:
the <code>populationFrac</code> slot is addressed by a <code>population</code> method,
and the <code>alarm</code> slot is addressed by an <code>alarms</code> method.
</p>

<dl>
<dt>epoch</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code>epoch</code> slot. If the <code>sts</code> object is indexed
by dates (<code>epochAsDate</code> = TRUE), the returned vector is of
class <code>Date</code>, otherwise numeric (usually the integer
sequence <code>1:nrow(x)</code>).<br />
By explicitly requesting <code>epoch(x, as.Date = TRUE)</code>, dates
can also be extracted if the <code>sts</code> object is not internally
indexed by dates but has a standard frequency of 12 (monthly) or
52 (weekly). The transformation is based on <code>start</code> and
<code>freq</code> and will return the first day of each month
(<code>freq=12</code>) and the Monday of each week (<code>freq=52</code>),
respectively.</p>
</dd>
<dt>observed</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code>observed</code> slot.</p>
</dd>
<dt>alarms</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code>alarm</code> slot.</p>
</dd>
<dt>upperbound</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code>upperbound</code> slot.</p>
</dd>
<dt>neighbourhood</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code>neighbourhood</code> slot.</p>
</dd>
<dt>population</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code>populationFrac</code> slot.</p>
</dd>
<dt>control</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code>control</code> slot.</p>
</dd>
<dt>multinomialTS</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code>multinomialTS</code> slot.</p>
</dd>
</dl>




<h4>Other extraction methods</h4>


<dl>
<dt>dim</dt><dd><p><code>signature(x = "sts")</code>:
extract matrix dimensions of <code>observed</code>.
This method also enables <code>nrow(x)</code> and <code>ncol(x)</code>.</p>
</dd>
<dt>dimnames</dt><dd><p><code>signature(x = "sts")</code>:
extract the <code><a href="base.html#topic+dimnames">dimnames</a></code> of the <code>observed</code> matrix.
This method also enables <code>rownames(x)</code> and <code>colnames(x)</code>.</p>
</dd>
<dt>year</dt><dd><p><code>signature(x = "sts")</code>:
extract the corresponding year of each observation.</p>
</dd>
<dt>epochInYear</dt><dd><p><code>signature(x = "sts")</code>:
extract the epoch number within the year.</p>
</dd>
<dt>[</dt><dd><p><code>signature(x = "sts")</code>:
subset rows (time points) and/or columns (units),
see <code>help("<a href="#topic++5B+2Csts-method">[,sts-method</a>")</code>.</p>
</dd>
</dl>




<h4>Transformation methods</h4>


<dl>
<dt>aggregate</dt><dd><p><code>signature(x = "sts")</code>:
see <code><a href="#topic+aggregate.sts">aggregate.sts</a></code>.</p>
</dd>
<dt>as.data.frame</dt><dd><p><code>signature(x = "sts")</code>:
the default <code>as.data.frame</code> call will collect the following
slots into a data frame: <code>observed</code>, <code>epoch</code>,
<code>state</code>, <code>alarm</code>, <code>upperbound</code>, and
<code>populationFrac</code>. Additional columns will be created for
<code>freq</code> (potentially varying by year for weekly or daily data
if <code>x@epochAsDate</code> is <code>TRUE</code>) and
<code>epochInPeriod</code> (the epoch fraction within the current year).<br />
Calling the <code>as.data.frame</code> method with the argument
<code>tidy = TRUE</code> will return <code><a href="#topic+tidy.sts">tidy.sts</a>(x)</code>,
which reshapes multivariate <code>sts</code> objects to the
&ldquo;long&rdquo; format (one row per epoch and observational unit).
The tidy format is particularly useful for standard regression
models and customized plotting.</p>
</dd>
<dt>coerce</dt><dd><p><code>signature(from="sts", to="ts")</code> and
<code>signature(from="ts", to="sts")</code>,
to be called via <code>as(stsObj, "ts")</code> (or <code>as.ts(stsObj)</code>)
and <code>as(tsObj, "sts")</code>, respectively.</p>
</dd>
<dt>as.xts</dt><dd><p>convert to the <a href="https://CRAN.R-project.org/package=xts"><span class="pkg">xts</span></a> package format.</p>
</dd>
</dl>




<h4>Visualization methods</h4>


<dl>
<dt>plot</dt><dd><p><code>signature(x = "sts", y = "missing")</code>:
entry point to a collection of plot variants.
The <code>type</code> of plot is specified using a formula,
see <code><a href="#topic+plot.sts">plot.sts</a></code> for details.</p>
</dd>
<dt>autoplot</dt><dd><p>a <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a> variant of the standard
time-series-type plot, see <code><a href="#topic+autoplot.sts">autoplot.sts</a></code>.</p>
</dd>
<dt>animate</dt><dd><p>see <code><a href="#topic+animate.sts">animate.sts</a></code>.</p>
</dd>
<dt>toLatex</dt><dd><p>see <code><a href="#topic+toLatex.sts">toLatex.sts</a></code>.</p>
</dd>
</dl>




<h3>Author(s)</h3>

<p>Michael Höhle and Sebastian Meyer</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("sts")

## create an sts object from time-series data
salmonellaDF &lt;- read.table(system.file("extdata/salmonella.agona.txt",
                                       package = "surveillance"), header = TRUE)
str(salmonellaDF)
salmonella &lt;- with(salmonellaDF,
                   sts(observed = observed, state = state,
                       start = c(1990, 1), frequency = 52))
salmonella
plot(salmonella)

## these data are also available as a legacy "disProg" object in the package
data(salmonella.agona)
stopifnot(all.equal(salmonella, disProg2sts(salmonella.agona)))


## A typical dataset with weekly counts of measles from several districts
data("measlesWeserEms")
measlesWeserEms

## reconstruct data("measlesWeserEms") from its components
counts &lt;- observed(measlesWeserEms)
map &lt;- measlesWeserEms@map
populationFrac &lt;- population(measlesWeserEms)
weserems_nbOrder &lt;- neighbourhood(measlesWeserEms)
## orders of adjacency can also be determined from the map
if (requireNamespace("spdep")) {
    stopifnot(identical(weserems_nbOrder,
                        nbOrder(poly2adjmat(map))))
}
mymeasles &lt;- sts(counts, start = c(2001, 1), frequency = 52,
                 population = populationFrac,
                 neighbourhood = weserems_nbOrder, map = map)
stopifnot(identical(mymeasles, measlesWeserEms))

## convert ts/mts object to sts
z &lt;- ts(matrix(rpois(300,10), 100, 3), start = c(1961, 1), frequency = 12)
z.sts &lt;- as(z, "sts")
plot(z.sts)

## conversion of "sts" objects to the quasi-standard "xts" class
if (requireNamespace("xts")) {
    z.xts &lt;- as.xts.sts(z.sts)
    plot(z.xts)
}
</code></pre>

<hr>
<h2 id='stsBP-class'>Class &quot;stsBP&quot; &ndash; a class inheriting from class <code>sts</code> which
allows the user to store the results of back-projecting or nowcasting
surveillance time series</h2><span id='topic+stsBP-class'></span><span id='topic+coerce+2Csts+2CstsBP-method'></span>

<h3>Description</h3>

<p>A class inheriting from class <code>sts</code>, but with additional slots
to store the result and associated confidence intervals from back
projection of a <code>sts</code> object.
</p>


<h3>Slots</h3>

<p>The slots are as for <code>"<a href="#topic+sts-class">sts</a>"</code>. However, two
additional slots exists.
</p>

<dl>
<dt><code>ci</code>:</dt><dd><p>An array containing the upper and lower limit
of the confidence interval.</p>
</dd>
<dt><code>lambda</code>:</dt><dd><p>Back projection component</p>
</dd>
</dl>



<h3>Methods</h3>

<p>The methods are the same as for <code>"<a href="#topic+sts-class">sts</a>"</code>.
</p>

<dl>
<dt>coerce</dt><dd><p><code>signature(from = "sts", to = "stsBP")</code>:
convert an object of class <code>sts</code> to class <code>stsBP</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>M. Höhle</p>

<hr>
<h2 id='stsNC-class'>Class &quot;stsNC&quot; &ndash; a class inheriting from class <code>sts</code> which
allows the user to store the results of back-projecting
surveillance time series</h2><span id='topic+stsNC-class'></span><span id='topic+reportingTriangle'></span><span id='topic+reportingTriangle+2CstsNC-method'></span><span id='topic+delayCDF'></span><span id='topic+delayCDF+2CstsNC-method'></span><span id='topic+score'></span><span id='topic+score+2CstsNC-method'></span><span id='topic+predint'></span><span id='topic+predint+2CstsNC-method'></span><span id='topic+coerce+2Csts+2CstsNC-method'></span>

<h3>Description</h3>

<p>A class inheriting from class <code>sts</code>, but with additional slots
to store the results of nowcasting.
</p>


<h3>Slots</h3>

<p>The slots are as for <code>"<a href="#topic+sts-class">sts</a>"</code>. However, a number of
additional slots exists.
</p>

<dl>
<dt><code>reportingTriangle</code>:</dt><dd><p>An array containing the upper and lower limit
of the confidence interval.</p>
</dd>
<dt><code>predPMF</code>:</dt><dd><p>Predictive distribution for each nowcasted
time point.</p>
</dd>
<dt><code>pi</code>:</dt><dd><p>A prediction interval for each nowcasted time
point. This is calculated based on <code>predPMF</code>.</p>
</dd>
<dt><code>truth</code>:</dt><dd><p>An object of type <code>sts</code> containing the
true number of cases.</p>
</dd>
<dt><code>delayCDF</code>:</dt><dd><p>List with the CDF of the estimated delay
distribution for each method.</p>
</dd>
<dt><code>SR</code>:</dt><dd><p>Possible output of proper scoring rules</p>
</dd>
</dl>



<h3>Methods</h3>

<p>The methods are the same as for <code>"<a href="#topic+sts-class">sts</a>"</code>.
</p>

<dl>
<dt>coerce</dt><dd><p><code>signature(from = "sts", to = "stsNC")</code>:
convert an object of class <code>sts</code> to class <code>stsNC</code>.
</p>
</dd>
<dt>reportingTriangle</dt><dd><p><code>signature(x = "stsNC")</code>: extract the
<code>reportingTriangle</code> slot of an <code>stsNC</code> object.
</p>
</dd>
<dt>delayCDF</dt><dd><p><code>signature(x = "stsNC")</code>: extract the
<code>delayCDF</code> slot of an <code>stsNC</code> object.
</p>
</dd>
<dt>score</dt><dd><p><code>signature(x = "stsNC")</code>: extract the
scoring rules result slot of an <code>stsNC</code> object.
</p>
</dd>
<dt>predint</dt><dd><p><code>signature(x = "stsNC")</code>: extract the
prediction interval slot of an <code>stsNC</code> object.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>M. Höhle</p>

<hr>
<h2 id='stsNClist_animate'>Animate a Sequence of Nowcasts</h2><span id='topic+stsNClist_animate'></span><span id='topic+animate_nowcasts'></span>

<h3>Description</h3>

<p>Animate a sequence of nowcasts stored as a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>animate_nowcasts(nowcasts,linelist_truth, method="bayes.trunc.ddcp",
      control=list(dRange=NULL,anim.dRange=NULL, plot.dRange=NULL,
                   consistent=FALSE, sys.sleep = 1, ylim=NULL,cex.names=0.7,
                   col=c("violetred3","#2171B5","orange","blue","black",
                         "greenyellow")),
                   showLambda=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stsNClist_animate_+3A_nowcasts">nowcasts</code></td>
<td>
<p>A list of objects of class <code><a href="#topic+stsNC-class">stsNC</a></code></p>
</td></tr>
<tr><td><code id="stsNClist_animate_+3A_linelist_truth">linelist_truth</code></td>
<td>
<p>True linelist</p>
</td></tr>
<tr><td><code id="stsNClist_animate_+3A_method">method</code></td>
<td>
<p>Which method to show (has to be present in the
nowcasts)</p>
</td></tr>
<tr><td><code id="stsNClist_animate_+3A_control">control</code></td>
<td>
<p>List with control options</p>
</td></tr>
<tr><td><code id="stsNClist_animate_+3A_showlambda">showLambda</code></td>
<td>
<p>Boolean indicating whether to show the estimate for
the epidemic curve (only applied to <code>bayes.trunc.ddcp</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function is experimental and not yet fully documented.
</p>


<h3>Author(s)</h3>

<p>M. Höhle</p>


<h3>See Also</h3>

<p><a href="https://staff.math.su.se/hoehle/blog/2016/07/19/nowCast.html">https://staff.math.su.se/hoehle/blog/2016/07/19/nowCast.html</a>
for a worked through example.
</p>

<hr>
<h2 id='stsNewport'>Salmonella Newport cases in Germany 2001-2015</h2><span id='topic+stsNewport'></span>

<h3>Description</h3>

<p>Reported number of cases of the Salmonella Newport serovar in Germany
2001-2015, by date of disease onset. The slot <code>control</code> contains
a matrix <code>reportingTriangle$n</code> with the reporting triangle as
described in Salmon et al. (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(stsNewport)</code></pre>


<h3>Format</h3>

<p>A <code>sts</code> object. 
</p>


<h3>References</h3>

<p>Salmon, M., Schumacher, D., Stark, K., Höhle, M. (2015):
Bayesian outbreak detection in the presence of reporting delays.
Biometrical Journal, 57 (6), 1051-1067.
</p>

<hr>
<h2 id='stsplot'>Plot Methods for Surveillance Time-Series Objects</h2><span id='topic+plot.sts'></span><span id='topic+plot+2Csts+2Cmissing-method'></span><span id='topic+plot+2CstsNC+2Cmissing-method'></span><span id='topic+stsplot'></span>

<h3>Description</h3>

<p>This page gives an overview of plot types
for objects of class <code>"sts"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S4 method for signature 'sts,missing'
plot(x, type = observed ~ time | unit, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stsplot_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.</p>
</td></tr>
<tr><td><code id="stsplot_+3A_type">type</code></td>
<td>
<p>see Details.</p>
</td></tr>
<tr><td><code id="stsplot_+3A_...">...</code></td>
<td>
<p>arguments passed to the <code>type</code>-specific plot
function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are various types of plots which can be produced from an
<code>"sts"</code> object. The <code>type</code> argument specifies the desired
plot as a formula, which defaults to <code>observed ~ time | unit</code>,
i.e., plot the time series of each unit separately. Arguments to
specific plot functions can be passed as further arguments (...).
The following list describes the plot variants:
</p>

<dl>
<dt><code>observed ~ time | unit</code></dt><dd><p>The default type shows
<code>ncol(x)</code> plots, each containing the time series of one
observational unit. The actual plotting per unit is done by the
function <code><a href="#topic+stsplot_time1">stsplot_time1</a></code>, called sequentially from
<code><a href="#topic+stsplot_time">stsplot_time</a></code>.<br />
A <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a>-based alternative for this type of plot is
provided through an <code><a href="#topic+autoplot.sts">autoplot</a></code>-method
for <code>"sts"</code> objects.
</p>
</dd>
<dt><code>observed ~ time</code></dt><dd><p>The observations in <code>x</code> are
first <code><a href="#topic+aggregate.sts">aggregated</a></code> over units
and the resulting univariate time-series is plotted via the
function <code><a href="#topic+stsplot_time">stsplot_time</a></code>.</p>
</dd>
<dt><code>alarm ~ time</code></dt><dd><p>Generates a so called alarmplot for a
multivariate <code>sts</code> object. For each time point and each
series it is shown whether there is an alarm. In case of
hierarchical surveillance the user can pass
an additional argument <code>lvl</code>, which is a vector of the
same length as rows in <code>x</code> specifying for each time series
its level.
</p>
</dd>
<dt><code>observed ~ unit</code></dt><dd>
<p>produces a map of counts (or incidence) per region aggregated over
time. See <code><a href="#topic+stsplot_space">stsplot_space</a></code> for optional arguments,
details and examples.
</p>
</dd>
<dt><code>observed ~ 1 | unit</code></dt><dd><p>old version of the map plot,
via the deprecated <code><a href="#topic+stsplot_spacetime">stsplot_spacetime</a></code> function.
Use <code>type = observed ~ unit</code> instead.
</p>
</dd>
<dt><code>observed ~ 1 | unit * time</code></dt><dd><p>old version for animated
maps via the deprecated <code><a href="#topic+stsplot_spacetime">stsplot_spacetime</a></code> function.
Use the <code><a href="#topic+animate.sts">animate</a></code> method instead.
</p>
</dd>
</dl>



<h3>Value</h3>

<p><code>NULL</code> (invisibly).
The methods are called for their side-effects.
</p>


<h3>See Also</h3>

<p>the documentation of the individual plot types
<code><a href="#topic+stsplot_time">stsplot_time</a></code>, <code><a href="#topic+stsplot_space">stsplot_space</a></code>,
as well as the <code><a href="#topic+animate.sts">animate</a></code> method.
</p>

<hr>
<h2 id='stsplot_space'>
Map of Disease Counts/Incidence accumulated over a Given Period
</h2><span id='topic+stsplot_space'></span>

<h3>Description</h3>

<p>This is the <code>plot</code> variant of <code>type=observed~unit</code> for
<code>"<a href="#topic+sts-class">sts</a>"</code> objects, i.e.,
<code>plot(stsObj, type=observed~unit, ...)</code> calls the function
documented below. It produces an <code><a href="sp.html#topic+spplot">spplot</a></code>
where regions are color-coded according to disease incidence
(either absolute counts or relative to population) over a given
time period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stsplot_space(x, tps = NULL, map = x@map, population = NULL,
              main = NULL, labels = FALSE, ...,
              at = 10, col.regions = NULL,
              colorkey = list(space = "bottom", labels = list(at=at)),
              total.args = NULL,
              gpar.missing = list(col = "darkgrey", lty = 2, lwd = 2),
              sp.layout = NULL, 
              xlim = bbox(map)[1, ], ylim = bbox(map)[2, ])
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stsplot_space_+3A_x">x</code></td>
<td>

<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code> or a matrix of counts,
i.e., <code>observed(stsObj)</code>, where especially
<code>colnames(x)</code> have to be contained in <code>row.names(map)</code>.
If a matrix, the <code>map</code> object has to be provided explicitly.
The possibility of specifying a matrix is, e.g., useful to plot mean
counts of simulations from <code><a href="#topic+simulate.hhh4">simulate.hhh4</a></code>.
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_tps">tps</code></td>
<td>

<p>a numeric vector of one or more time points.
The unit-specific <em>sum</em> over all time points <code>tps</code> is
plotted. The default <code>tps=NULL</code> means accumulation over the whole
time period <code>1:nrow(x)</code>.
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_map">map</code></td>
<td>

<p>an object inheriting from <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>
representing the <code>ncol(x)</code> regions. By default
the <code>map</code> slot of <code>x</code> is queried (which might be
empty and is not applicable if <code>x</code> is a matrix of counts).
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_population">population</code></td>
<td>

<p>if <code>NULL</code> (default), the map shows the region-specific numbers
of cases accumulated over <code>tps</code>. For a disease incidence map,
<code>population</code> can be specified in three ways:
</p>

<ul>
<li><p> a numeric vector of population numbers in the
<code>ncol(x)</code> regions, used to divide the disease counts.
</p>
</li>
<li><p> a matrix of population counts of dimension <code>dim(x)</code>
(such as <code>population(x)</code> in an <code>"sts"</code> object).
This will produce the cumulative incidence over <code>tps</code>
relative to the population at the first time point, i.e., only
<code>population[tps[1],]</code> is used.
</p>
</li>
<li><p> [if <code>is(x, "sts")</code>]
a scalar specifying how <code>population(x)</code> should be scaled for
use as the population matrix, i.e.,
<code>population(x)/population</code> is used. For instance, if
<code>population(x)</code> contains raw population numbers,
<code>population=1000</code> would produce the incidence per 1000
inhabitants.
</p>
</li></ul>

</td></tr>
<tr><td><code id="stsplot_space_+3A_main">main</code></td>
<td>

<p>a main title for the plot. If <code>NULL</code> and <code>x</code> is of
class <code>"sts"</code>, the time range of <code>tps</code> is put as
the main title.
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_labels">labels</code></td>
<td>

<p>determines if and how the regions of the <code>map</code> are labeled,
see <code><a href="#topic+layout.labels">layout.labels</a></code>.
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_...">...</code></td>
<td>

<p>further arguments for <code><a href="sp.html#topic+spplot">spplot</a></code>,
for example <code>col = "white"</code> for white polygon lines.
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_at">at</code></td>
<td>

<p>either a number of levels (default: 10) for the categorization
(color-coding) of counts/incidence,
or a numeric vector of specific break points,
or a named list of a number of levels (<code>"n"</code>), a transformer
(<code>"trafo"</code>) of class <code>"<a href="scales.html#topic+trans">trans</a>"</code> defined by
package <span class="pkg">scales</span>, and optional further arguments for
<code><a href="base.html#topic+pretty">pretty</a></code>. The default breaks are equally spaced
on the square-root scale (equivalent to
<code><a href="scales.html#topic+sqrt_trans">sqrt_trans</a></code>).
Note that intervals given by <code>at</code> are closed on the left
and open to the right; if manually specified break points do not
cover the data range, further breaks are automatically added at 0
and the maximum (rounded up to 1 significant digit), respectively.
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_col.regions">col.regions</code></td>
<td>

<p>a vector of fill colors, sufficiently long to serve all levels
(determined by <code>at</code>).
&ldquo;Heat&rdquo; colors are used by default (<code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_colorkey">colorkey</code></td>
<td>

<p>a list describing the color key, see
<code><a href="lattice.html#topic+levelplot">levelplot</a></code>. The default list elements will be
updated by the provided list using <code><a href="utils.html#topic+modifyList">modifyList</a></code>.
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_total.args">total.args</code></td>
<td>

<p>an optional list of arguments for <code><a href="grid.html#topic+grid.text">grid.text</a></code> to
have the overall number/incidence of cases printed at an edge of the
map. The default settings are
<code>list(label="Overall: ", x=1, y=0)</code>, and
<code>total.args=list()</code> will use all of them.
</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_gpar.missing">gpar.missing</code></td>
<td>
<p>list of graphical parameters for
<code><a href="sp.html#topic+sp.polygons">sp.polygons</a></code> applied to the regions of <code>map</code>,
which are not part of <code>x</code>. Such extra regions won't be plotted
if <code>!is.list(gpar.missing)</code>.</p>
</td></tr>
<tr><td><code id="stsplot_space_+3A_sp.layout">sp.layout</code></td>
<td>

<p>optional list of additional layout items, see <code><a href="sp.html#topic+spplot">spplot</a></code>.
</p>
</td></tr>



<tr><td><code id="stsplot_space_+3A_xlim">xlim</code>, <code id="stsplot_space_+3A_ylim">ylim</code></td>
<td>
<p>numeric vectors of length 2 specifying the axis limits.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a lattice plot of class
<code>"<a href="lattice.html#topic+trellis.object">trellis</a>"</code>, but see
<code><a href="sp.html#topic+spplot">spplot</a></code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p>the central <code><a href="#topic+stsplot">stsplot</a></code>-documentation for an overview of
plot types, and <code><a href="#topic+animate.sts">animate.sts</a></code> for animations of
<code>"sts"</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("measlesWeserEms")

# default plot: total region-specific counts over all weeks
plot(measlesWeserEms, type = observed ~ unit)
stsplot_space(measlesWeserEms)  # the same

# cumulative incidence (per 100'000 inhabitants),
# with region labels and white borders
plot(measlesWeserEms, observed ~ unit,
     population = measlesWeserEms@map$POPULATION / 100000,
     labels = list(labels = "GEN", cex = 0.7, font = 3),
     col = "white", lwd = 2,
     sub = "cumulative incidence (per 100'000 inhabitants)")

# incidence in a particular week, manual color breaks, display total
plot(measlesWeserEms, observed ~ unit, tps = 62,
     population = measlesWeserEms@map$POPULATION / 100000,
     at = c(0, 1, 5),
     total.args = list(x = 0, label = "Overall incidence: "))

# if we had only observed a subset of the regions
plot(measlesWeserEms[,5:11], observed ~ unit,
     gpar.missing = list(col = "gray", lty = 4))
</code></pre>

<hr>
<h2 id='stsplot_spacetime'>
Animated Map of Disease Incidence (DEPRECATED)
</h2><span id='topic+stsplot_spacetime'></span>

<h3>Description</h3>

<p>For each period (row) or for the overall period of the
<code>observed</code> matrix of the <code>"<a href="#topic+sts-class">sts</a>"</code> object, a map
showing the counts by region is produced.
It is possible to redirect the output into files, e.g., to generate an
animated GIF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stsplot_spacetime(x, type, legend = NULL, opts.col = NULL, labels = TRUE,
                  wait.ms = 250, cex.lab = 0.7, verbose = FALSE,
                  dev.printer = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stsplot_spacetime_+3A_x">x</code></td>
<td>

<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.
</p>
</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_type">type</code></td>
<td>

<p>a formula (see <code><a href="#topic+stsplot">stsplot</a></code>). For a map aggregated over
time (no animation), use <code>observed ~ 1 | unit</code>, otherwise
<code>observed ~ 1 | unit * time</code>.
</p>
</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_legend">legend</code></td>
<td>

<p>a <code>list</code> containing the following items used
for coloring
</p>

<dl>
<dt><code>dx</code></dt><dd><p>position increments in x direction</p>
</dd>
<dt><code>dy</code></dt><dd><p>position increments in y direction</p>
</dd>
<dt><code>x</code></dt><dd><p>position in x</p>
</dd>
<dt><code>y</code></dt><dd><p>position in y</p>
</dd>
<dt><code>once</code></dt><dd><p>a Boolean; if <code>TRUE</code> then only shown once</p>
</dd>
</dl>

<p>If <code>NULL</code> then a default legend is used.
</p>
</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_opts.col">opts.col</code></td>
<td>

<p>a <code>list</code> containing the two elements
</p>

<dl>
<dt><code>ncolors</code></dt><dd><p>number of colors to use for plotting</p>
</dd>
<dt><code>use.color</code></dt><dd><p>a Boolean; if <code>TRUE</code> then colors
will be used in the palette, otherwise grayscale</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_labels">labels</code></td>
<td>
<p>Boolean whether to add labels
</p>
</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_wait.ms">wait.ms</code></td>
<td>
<p>Number of milliseconds to wait between each plot
</p>
</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_cex.lab">cex.lab</code></td>
<td>
<p><code>cex</code> of the labels
</p>
</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_verbose">verbose</code></td>
<td>
<p>Boolean whether to write out extra information
</p>
</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_dev.printer">dev.printer</code></td>
<td>
<p>Either <code>NULL</code> (default), which means that plotting is
only to the screen, or a list with elements <code>device</code>,
<code>extension</code>, <code>width</code>, <code>height</code>, and <code>name</code>
(with defaults <code>png</code>, <code>".png"</code>, <code>640</code>, <code>480</code>,
and <code>"Rplot"</code>, respectively) to <code><a href="grDevices.html#topic+dev.print">dev.print</a></code> the
plots to files (only works in interactive sessions).
This option is more or less obsolete since the <span class="pkg">animation</span>
package provides better features for output to files.
</p>
</td></tr>
<tr><td><code id="stsplot_spacetime_+3A_...">...</code></td>
<td>
<p>Extra arguments sent to the plot function.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code><a href="#topic+animate.sts">animate.sts</a></code> method provides a
re-implementation and supersedes this function!
</p>


<h3>Author(s)</h3>

<p>Michael Höhle
</p>


<h3>See Also</h3>

<p>Other <code><a href="#topic+stsplot">stsplot</a></code> types, and <code><a href="#topic+animate.sts">animate.sts</a></code> for
the new implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ha.sts")
print(ha.sts)


## map of total counts by district (compare old vs. new implementation)
plot(ha.sts, type = observed ~ 1 | unit)
plot(ha.sts, type = observed ~ unit, labels = TRUE)


## Not run: 
# space-time animation
plot(aggregate(ha.sts,nfreq=13), type = observed ~ 1 | unit * time)

#print the frames to a png device
#and do the animation without extra sleeping between frames
imgname &lt;- file.path(tempdir(), "berlin")
plot(aggregate(ha.sts,nfreq=13), type = observed ~ 1 | unit * time,
     wait.ms=0, dev.printer=list(name=imgname))

#Use ImageMagick (you might have to adjust the path to 'convert')
system(paste0("convert -delay 50 ", imgname,
              "*.png ", imgname, "-animated.gif"))

## End(Not run)
</code></pre>

<hr>
<h2 id='stsplot_time'>
Time-Series Plots for <code>"sts"</code> Objects
</h2><span id='topic+stsplot_time'></span><span id='topic+stsplot_time1'></span><span id='topic+stsplot_alarm'></span>

<h3>Description</h3>

<p>These are the <code>plot</code> variants of <code>type=observed~time|unit</code>,
<code>type=observed~time</code>, and <code>type=alarm~time</code>
for <code>"<a href="#topic+sts-class">sts</a>"</code> objects (see the central <code>"sts"</code>
<code><a href="#topic+plot+2Csts+2Cmissing-method">plot</a></code>-method for
an overview of plot types).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stsplot_time(x, units=NULL,
             as.one=FALSE, same.scale=TRUE, par.list=list(), ...)

stsplot_time1(x, k=1, ylim=NULL,
              axes=TRUE, xaxis.tickFreq=list("%Q"=atChange),
              xaxis.labelFreq=xaxis.tickFreq, xaxis.labelFormat="%G\n\n%OQ",
              epochsAsDate=x@epochAsDate,
              xlab="time", ylab="No. infected", main=NULL,
              type="s", lty=c(1,1,2), col=c(NA,1,4), lwd=c(1,1,1),
              outbreak.symbol=list(pch=3, col=3, cex=1, lwd=1),
              alarm.symbol=list(pch=24, col=2, cex=1, lwd=1),
              legend.opts=list(),
              dx.upperbound=0L, hookFunc=function(){},
              .hookFuncInheritance=function() {}, ...)

stsplot_alarm(x, lvl=rep(1,ncol(x)),
              xaxis.tickFreq=list("%Q"=atChange),
              xaxis.labelFreq=xaxis.tickFreq, xaxis.labelFormat="%G\n\n%OQ",
              epochsAsDate=x@epochAsDate,
              xlab="time", ylab="", main=NULL,
              outbreak.symbol=list(pch=3, col=3, cex=1, lwd=1),
              alarm.symbol=list(pch=24, col=2, cex=1, lwd=1),
              cex.yaxis=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stsplot_time_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_units">units</code></td>
<td>
<p>optional integer or character vector to select the units (=columns of
<code>observed(x)</code>) to plot. The default is to plot all time series.
If <code>as.one=FALSE</code>, <code>stsplot_time1</code> is called
<code>for (k in units)</code> with <code>mfrow</code> splitting (see <code>par.list</code>).
Note that if there are too many <code>units</code>, the default <code>mfrow</code>
setting might lead to the error &ldquo;figure margins too large&rdquo;
(meaning that the units do not fit onto a single page).</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_as.one">as.one</code></td>
<td>
<p>logical indicating if all time series should be plotted
in a single frame (using <code><a href="graphics.html#topic+matplot">matplot</a></code>).</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_same.scale">same.scale</code></td>
<td>
<p>logical indicating if all time series should be
plotted with the same <code>ylim</code>. Default is to do so. Only
relevant for multivariate plots (<code>ncol(x) &gt; 1</code>).</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_par.list">par.list</code></td>
<td>
<p>a list of arguments delivered to a call of
<code><a href="graphics.html#topic+par">par</a></code> to set graphical parameters before plotting.
The <code>mfrow</code> splitting is handled per default. Afterwards,
the <code>par</code>ameters are reverted to their original values.
Use <code>par.list=NULL</code> to disable the internal <code>par</code> call.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_k">k</code></td>
<td>
<p>the unit to plot, i.e., an element of <code>1:ncol(x)</code>.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_ylim">ylim</code></td>
<td>
<p>the y limits of the plot(s). Ignored if
<code>same.scale=FALSE</code>.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_axes">axes</code></td>
<td>
<p>a logical value indicating whether both axes should be drawn
on the plot.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_xaxis.tickfreq">xaxis.tickFreq</code>, <code id="stsplot_time_+3A_xaxis.labelfreq">xaxis.labelFreq</code>, <code id="stsplot_time_+3A_xaxis.labelformat">xaxis.labelFormat</code></td>
<td>

<p>arguments for <code><a href="#topic+addFormattedXAxis">addFormattedXAxis</a></code>
if <code>epochsAsDate=TRUE</code>.
Use <code>xaxis.labelFormat=NULL</code> to get a standard x-axis
(without date labels).</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_epochsasdate">epochsAsDate</code></td>
<td>
<p>Boolean indicating whether to treat the epochs as
Date objects (or to transform them to dates such that the new x-axis
formatting is applied).
Default: Value of the <code>epochAsDate</code> slot of <code>x</code>.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_xlab">xlab</code></td>
<td>
<p>a title for the x axis. See <code>plot.default</code>.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_ylab">ylab</code></td>
<td>
<p>a title for the y axis. See <code>plot.default</code>.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_main">main</code></td>
<td>
<p>an overall title for the plot: see 'title'.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_type">type</code></td>
<td>
<p>type of plot to do.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_lty">lty</code></td>
<td>
<p>vector of length 3 specifying the line type for the three
lines in the plot &ndash; see <code>col</code> argument.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_col">col</code></td>
<td>
<p>Vector of length 3 specifying the color to use in the
plot. The first color is the fill color of the polygons for the
counts bars (<code>NA</code> for unfilled), the 2nd element denotes their
border color, the 3rd element is the color of the <code>upperbound</code>
plotting.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_lwd">lwd</code></td>
<td>
<p>Vector of length 3 specifying the line width of the three
elements to plot. See also the <code>col</code> argument.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_alarm.symbol">alarm.symbol</code></td>
<td>
<p>a list with entries <code>pch</code>, <code>col</code>,
<code>cex</code> and <code>lwd</code> specifying the appearance of the outbreak
symbol in the plot.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_outbreak.symbol">outbreak.symbol</code></td>
<td>
<p>a list with entries <code>pch</code>, <code>col</code>,
<code>cex</code> and <code>lwd</code> specifying the appearance of the outbreak
symbol in the plot.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_legend.opts">legend.opts</code></td>
<td>
<p>a list of arguments for the <code><a href="graphics.html#topic+legend">legend</a></code>.
If <code><a href="base.html#topic+missing">missing</a>(legend.opts)</code> (i.e., not explicitly
specified), the default legend will only be added if the <code>"sts"</code> object
contains outbreaks, alarms, or upperbounds.
The default legend options are
</p>

<dl>
<dt><code>x</code></dt><dd><p><code>"top"</code></p>
</dd>
<dt><code>legend</code></dt><dd><p><code>c("Infected","Threshold","Outbreak","Alarm")[included]</code></p>
</dd>
<dt><code>lty,lwd,pch,col</code></dt><dd><p>the corresponding graphical settings
of the included elements</p>
</dd>
</dl>

<p>where individual elements are only <code>included</code> in the legend if
they are plotted (except for alarms, which are also included if
upperbounds exist).
To disable the legend, use <code>legend.opts=NULL</code>.
</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_dx.upperbound">dx.upperbound</code></td>
<td>
<p>horizontal change in the plotting of the
upperbound line. Sometimes it can be convenient to offset this line
a little for better visibility.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_lvl">lvl</code></td>
<td>
<p>A vector of length <code>ncol(x)</code>, which is used to
specify the hierarchy level for each time series in the sts object
for alarm plots.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_cex.yaxis">cex.yaxis</code></td>
<td>
<p>The magnification to be used for y-axis annotation.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_hookfunc">hookFunc</code></td>
<td>
<p>a function that is called after all the basic plotting
has be done, i.e., it is not possible to control formatting with
this function. See Examples.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_.hookfuncinheritance">.hookFuncInheritance</code></td>
<td>
<p>a function which is altered by sub-classes
plot method. Do not alter this function manually.</p>
</td></tr>
<tr><td><code id="stsplot_time_+3A_...">...</code></td>
<td>
<p>further arguments for the function <code>matplot</code>. If
e.g. <code>xlab</code> or <code>main</code> are provided they overwrite the
default values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The time series plot relies on the work-horse <code>stsplot_time1</code>.
Its arguments are (almost) similar to <code><a href="#topic+plot.survRes">plot.survRes</a></code>.
</p>


<h3>Value</h3>

<p><code>NULL</code> (invisibly).
The functions are called for their side-effects.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle and Sebastian Meyer
</p>


<h3>See Also</h3>

<p>There is an <code><a href="#topic+autoplot.sts">autoplot</a></code>-method, which
implements <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a>-based time-series plots of <code>"sts"</code>
objects.
</p>
<p>The <code><a href="#topic+stsplot">stsplot</a></code> help page gives an overview of other
types of plots for <code>"sts"</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ha.sts")
print(ha.sts)

plot(ha.sts, type=observed ~ time | unit)  # default multivariate type
plot(ha.sts, units=c("mitt", "pank"))      # selected units
plot(ha.sts, type=observed ~ time)         # aggregated over all districts

## Hook function example
hookFunc &lt;- function() grid(NA,NULL,lwd=1)
plot(ha.sts, hookFunc=hookFunc)

## another multivariate time series example plotted "as.one"
data("measlesDE")
plot(measlesDE, units=1:2, as.one=TRUE, legend.opts=list(cex=0.8))
## more sophisticated plots are offered by package "xts"
if (requireNamespace("xts"))
    plot(as.xts.sts(measlesDE))

## Use ISO8601 date formatting (see ?strptime) and no legend
data("salmNewport")
plot(aggregate(salmNewport,by="unit"), xlab="Time (weeks)",
     xaxis.tickFreq=list("%m"=atChange,"%G"=atChange),
     xaxis.labelFreq=list("%G"=atMedian),xaxis.labelFormat="%G")

## Formatting now also works for daily data (illustrate by artifical
## outbreak converted to sts object by linelist2sts)
set.seed(123)
exposureTimes &lt;-  as.Date("2014-03-12") + sample(x=0:25,size=99,replace=TRUE)
sts &lt;- linelist2sts(data.frame(exposure=exposureTimes),
                               dateCol="exposure",aggregate.by="1 day")
## Plot it with larger ticks for days than usual
surveillance.options("stsTickFactors"=c("%d"=1, "%W"=0.33,
                "%V"=0.33, "%m"=1.75, "%Q"=1.25, "%Y"=1.5, "%G"=1.5))
plot(sts,xaxis.tickFreq=list("%d"=atChange,"%m"=atChange),
     xaxis.labelFreq=list("%d"=at2ndChange),xaxis.labelFormat="%d-%b",
     xlab="Time (days)")
</code></pre>

<hr>
<h2 id='stsSlot-generics'>Generic Functions to Access <code>"sts"</code> Slots</h2><span id='topic+alarms'></span><span id='topic+alarms+3C-'></span><span id='topic+upperbound'></span><span id='topic+upperbound+3C-'></span><span id='topic+control'></span><span id='topic+control+3C-'></span><span id='topic+epoch'></span><span id='topic+epoch+3C-'></span><span id='topic+observed'></span><span id='topic+observed+3C-'></span><span id='topic+population'></span><span id='topic+population+3C-'></span><span id='topic+multinomialTS'></span><span id='topic+multinomialTS+3C-'></span><span id='topic+neighbourhood'></span><span id='topic+neighbourhood+3C-'></span>

<h3>Description</h3>

<p>For almost every slot of the <code>"sts"</code> class, package <span class="pkg">surveillance</span>
defines a generic function of the same name (and a replacement
version) to extract (or set) the corresponding slot.
See the <code>"<a href="#topic+sts-class">sts</a>"</code> class documentation.
</p>

<hr>
<h2 id='stsXtrct'>Subsetting <code>"sts"</code> Objects</h2><span id='topic++5B+2Csts-method'></span><span id='topic++5B+2Csts+2CANY+2CANY+2CANY-method'></span>

<h3>Description</h3>

<p>The <code>[</code>-method extracts parts of an
<code>"<a href="#topic+sts-class">sts</a>"</code> object
using row (time) and column (unit) indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'sts'
x[i, j, ..., drop]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stsXtrct_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.</p>
</td></tr>
<tr><td><code id="stsXtrct_+3A_i">i</code></td>
<td>
<p>row index (integer or logical vector).</p>
</td></tr>
<tr><td><code id="stsXtrct_+3A_j">j</code></td>
<td>
<p>column index (character, integer, or logical vector).</p>
</td></tr>
<tr><td><code id="stsXtrct_+3A_...">...</code>, <code id="stsXtrct_+3A_drop">drop</code></td>
<td>
<p>unused (arguments of the generic).<br />
Dimensions are never dropped.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Row indices are used to select a subset of the original time period.
The <code>start</code> and <code>epoch</code> slots of the time series are
adjusted accordingly.
A warning is issued if an irregular integer sequence is used to
extract rows, e.g., <code>x[c(1,2,4),]</code>, which could destroy the
structure of the time series (<code>freq</code>).
</p>
<p>Column indices work as usual when indexing matrices,
so may select units by name, position or a vector of booleans.
When subsetting columns, population fractions are recomputed if and
only if <code>x</code> is no <code>multinomialTS</code> and already contains
population fractions.
</p>
<p><code>NA</code> indices are not supported, negative indices are.
</p>
<p>Note that a <code>[&lt;-</code> method (i.e., subassignment) is not implemented.
</p>


<h3>Value</h3>

<p>an object of class <code>"sts"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ha.sts")
haagg &lt;- aggregate(ha.sts, nfreq=13)

plot(haagg[, 3])       # Single series
plot(haagg[1:30, 3])   # Somewhat shorter

#Counts at time 20
plot(haagg[20, ], type = observed ~ unit)
</code></pre>

<hr>
<h2 id='surveillance-defunct'>Defunct Functions in Package <span class="pkg">surveillance</span></h2><span id='topic+surveillance-defunct'></span><span id='topic+compMatrix.writeTable'></span><span id='topic+correct53to52'></span><span id='topic+enlargeData'></span><span id='topic+makePlot'></span><span id='topic+readData'></span><span id='topic+test'></span><span id='topic+testSim'></span><span id='topic+toFileDisProg'></span><span id='topic+algo.hhh'></span><span id='topic+algo.hhh.grid'></span><span id='topic+create.grid'></span><span id='topic+qlomax'></span><span id='topic+inside.gpc.poly'></span><span id='topic+intersectPolyCircle.gpc.poly'></span><span id='topic+scale.gpc.poly'></span>

<h3>Description</h3>

<p>The functions listed here are no longer part of <span class="pkg">surveillance</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Removed in surveillance 1.17.0
compMatrix.writeTable(compMatrix)
correct53to52(disProgObj, firstweek = 1)
enlargeData(disProgObj, range = 1:156, times = 1)
makePlot(outputpath, data = "k1", method = "rki1",
         name, disease, range = 157:339)
readData(abb, week53to52=TRUE, sysPath=TRUE)
test(data = c("k1", "m5"), range = 157:339)
testSim(p = 0.99, r = 0.01, length = 400, A = 1, alpha = 1,
        beta = 0, phi = 0, frequency = 1, state = NULL, K, 
        range = 200:400)
toFileDisProg(disProgObj, toFile)

## Removed in surveillance 1.18.0
algo.hhh(disProgObj, control=list(
             lambda=TRUE, neighbours=FALSE, linear=FALSE, nseason=0,
             negbin=c("none", "single", "multiple"),
             proportion=c("none", "single", "multiple"), lag.range=NULL
         ), thetastart=NULL, verbose=TRUE)
algo.hhh.grid(disProgObj, control=list(
                 lambda=TRUE, neighbours=FALSE, linear=FALSE, nseason=0,
                 negbin=c("none", "single", "multiple"),
                 proportion=c("none", "single", "multiple"), lag.range=NULL
              ), thetastartMatrix, maxTime=1800, verbose=FALSE)
create.grid(disProgObj, control, params=list(
                epidemic=c(0.1, 0.9, 5), endemic=c(-0.5, 0.5, 3),
                negbin=c(0.3, 12, 10)
            ))

## Removed in surveillance 1.20.0
qlomax(p, scale, shape)

## Removed in surveillance 1.22.0
inside.gpc.poly(x, y = NULL, polyregion, mode.checked = FALSE)
## S3 method for class 'gpc.poly'
intersectPolyCircle(object, center, radius, npoly = 32,
                   useGEOS = FALSE, ...)
## S3 method for class 'gpc.poly'
scale(x, center = c(0,0), scale = c(1,1))
</code></pre>


<h3>Details</h3>

<p>The trivial function <code>compMatrix.writeTable</code> is no longer used
(it did nothing more than generating an <code><a href="xtable.html#topic+xtable">xtable</a></code> of its input).
</p>
<p>The ancient test function <code>makePlot</code> is no longer used,
nor are functions <code>readData</code> (the datasets are still available
via <code>data(<a href="#topic+m1">m1</a>)</code> etc) and <code>correct53to52</code> /
<code>enlargeData</code> (which both only worked for old <code>"disProg"</code>
objects with non-matrix elements). <code>enlargeData</code> is still
exemplified in the old <code>vignette("surveillance")</code>.
<code>test</code> calls of outbreak detection algorithms applied to the old
SurvStat datasets can be found in <code>vignette("surveillance")</code>,
and <code>testSim</code> is provided as an example
in <code>help("<a href="#topic+sim.pointSource">sim.pointSource</a>")</code>.
</p>
<p>Functions related to the old <code>"<a href="#topic+create.disProg">disProg</a>"</code>
class are no longer needed. The effect of <code>toFileDisProg</code> could
still be achieved via <code><a href="utils.html#topic+write.table">write.table</a></code> of
<code>as.data.frame(disProg2sts(disProgObj))[c("epoch", "observed", "state")]</code>.
</p>
<p><code>algo.hhh</code> was an early implementation of the HHH regression
framework for multivariate time series of infectious disease counts.
An improved and considerably extended implementation is provided by
the <code><a href="#topic+hhh4">hhh4</a></code> function since 2012.
</p>
<p>A <code>qlomax</code> function is provided in package <span class="pkg">VGAM</span>.
</p>
<p>Long unused methods for <code>"gpc.poly"</code> objects have been removed;
the corresponding package <span class="pkg">gpclib</span> has been unmaintained on CRAN.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Defunct">Defunct</a></code>
</p>

<hr>
<h2 id='surveillance-package'><span class="pkg">surveillance</span>: Temporal and Spatio-Temporal Modeling and Monitoring of Epidemic Phenomena</h2><span id='topic+surveillance-package'></span><span id='topic+surveillance'></span>

<h3>Description</h3>

<p>The <span class="rlang"><b>R</b></span> package <span class="pkg">surveillance</span> implements statistical methods for the
retrospective modeling and prospective monitoring of epidemic phenomena
in temporal and spatio-temporal contexts.
Focus is on (routinely collected) public health surveillance data,
but the methods just as well apply to data from environmetrics,
econometrics or the social sciences. As many of the monitoring methods
rely on statistical process control methodology, the package is
also relevant to quality control and reliability engineering.
</p>


<h3>Details</h3>

<p>The package implements many typical outbreak detection procedures such
as Stroup et al. (1989), Farrington et al. (1996), Rossi et al. (1999),
Rogerson and Yamada (2001), a Bayesian approach (Höhle, 2007),
negative binomial CUSUM methods (Höhle and Mazick, 2009), and a
detector based on generalized likelihood ratios (Höhle
and Paul, 2008), see <code><a href="#topic+wrap.algo">wrap.algo</a></code>.
Also CUSUMs for the prospective change-point detection in binomial,
beta-binomial and multinomial time series are covered based on
generalized linear modeling, see <code><a href="#topic+categoricalCUSUM">categoricalCUSUM</a></code>.
This includes, e.g., paired comparison Bradley-Terry modeling described
in Höhle (2010), or paired binary CUSUM
(<code><a href="#topic+pairedbinCUSUM">pairedbinCUSUM</a></code>) described by Steiner et al. (1999).
The package contains several real-world datasets, the ability
to simulate outbreak data, visualize the results of the monitoring in
temporal, spatial or spatio-temporal fashion. In dealing with time
series data, the fundamental data structure of the package is the S4
class <code><a href="#topic+sts">sts</a></code> wrapping observations, monitoring results and
date handling for multivariate time series.
A recent overview of the available monitoring procedures is
given by Salmon et al. (2016).
</p>
<p>For the retrospective analysis of epidemic spread, the package
provides three endemic-epidemic modeling frameworks with
tools for visualization, likelihood inference, and simulation.
The function <code><a href="#topic+hhh4">hhh4</a></code> offers inference methods for the
(multivariate) count time series models of Held et al. (2005), Paul et
al. (2008), Paul and Held (2011), Held and Paul (2012), and Meyer and
Held (2014). See <code>vignette("hhh4")</code> for a general introduction
and <code>vignette("hhh4_spacetime")</code> for a discussion and
illustration of spatial <code>hhh4</code> models.
Furthermore, the fully Bayesian approach for univariate
time series of counts from Held et al. (2006) is implemented as
function <code><a href="#topic+algo.twins">algo.twins</a></code>.
Self-exciting point processes are modeled through endemic-epidemic
conditional intensity functions.
<code><a href="#topic+twinSIR">twinSIR</a></code> (Höhle, 2009) models the
susceptible-infectious-recovered (SIR) event history of a 
fixed population, e.g, epidemics across farms or networks;
see <code>vignette("twinSIR")</code> for an illustration.
<code><a href="#topic+twinstim">twinstim</a></code> (Meyer et al., 2012) fits spatio-temporal point
process models to point patterns of infective events, e.g.,
time-stamped geo-referenced surveillance data on infectious disease
occurrence; see <code>vignette("twinstim")</code> for an illustration.
A recent overview of the implemented space-time modeling frameworks
for epidemic phenomena is given by Meyer et al. (2017).
</p>


<h3>Acknowledgements</h3>

<p>Substantial contributions of code by:
Leonhard Held, Howard Burkom, Thais Correa, Mathias Hofmann, Christian Lang, Juliane Manitz, Andrea Riebler, Daniel Sabanes Bove, Maelle Salmon, Dirk Schumacher, Stefan Steiner, Mikko Virtanen, Wei Wei, Valentin Wimmer.
</p>
<p>Furthermore, the authors would like to thank the following people
for ideas, discussions, testing and feedback:
Doris Altmann, Johannes Bracher, Caterina De Bacco, Johannes Dreesman, Johannes Elias, Marc Geilhufe, Jim Hester, Kurt Hornik, Mayeul Kauffmann, Junyi Lu, Lore Merdrignac, Tim Pollington, Marcos Prates, André Victor Ribeiro Amaral, Brian D. Ripley, François Rousseu, Barry Rowlingson, Christopher W. Ryan, Klaus Stark, Yann Le Strat, André Michael Toschke, Wei Wei, George Wood, Achim Zeileis, Bing Zhang.
</p>


<h3>Author(s)</h3>

<p>Michael Hoehle, Sebastian Meyer, Michaela Paul
</p>
<p>Maintainer: Sebastian Meyer <a href="mailto:seb.meyer@fau.de">seb.meyer@fau.de</a>

</p>


<h3>References</h3>

<p><code>citation(package="surveillance")</code> gives the two main software
references for the modeling (Meyer et al., 2017) and the monitoring
(Salmon et al., 2016) functionalities:
</p>

<ul>
<li><p> Meyer S, Held L, Höhle M (2017).
&ldquo;Spatio-Temporal Analysis of Epidemic Phenomena Using the R Package surveillance.&rdquo;
<em>Journal of Statistical Software</em>, <b>77</b>(11), 1&ndash;55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>.

</p>
</li>
<li><p> Salmon M, Schumacher D, Höhle M (2016).
&ldquo;Monitoring Count Time Series in R: Aberration Detection in Public Health Surveillance.&rdquo;
<em>Journal of Statistical Software</em>, <b>70</b>(10), 1&ndash;35.
<a href="https://doi.org/10.18637/jss.v070.i10">doi:10.18637/jss.v070.i10</a>.
</p>
</li></ul>

<p>Further references are listed in <code>surveillance:::REFERENCES</code>.
</p>
<p>If you use the <span class="pkg">surveillance</span> package in your own
work, please do cite the corresponding publications.
</p>


<h3>See Also</h3>

<p><a href="https://surveillance.R-forge.R-project.org/">https://surveillance.R-forge.R-project.org/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Additional documentation and illustrations of the methods are
## available in the form of package vignettes and demo scripts:
vignette(package = "surveillance")
demo(package = "surveillance")
</code></pre>

<hr>
<h2 id='surveillance.options'>Options of the <span class="pkg">surveillance</span> Package</h2><span id='topic+surveillance.options'></span><span id='topic+reset.surveillance.options'></span>

<h3>Description</h3>

<p>Query, set or reset options specific to the <span class="pkg">surveillance</span>
package, similar to what <code><a href="base.html#topic+options">options</a></code> does for global settings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>surveillance.options(...)
reset.surveillance.options()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="surveillance.options_+3A_...">...</code></td>
<td>

<p>Either empty, or a sequence of option names (as strings),
or a sequence of <code>name=value</code> pairs, or a named list of
options. Available options are:
</p>

<dl>
<dt>stsTickFactors:</dt><dd>
<p>A named vector containing tick sizes for the <code>"sts"</code> x-axis relative to
<code><a href="graphics.html#topic+par">par</a>("tcl")</code>. Each entry contains the size at <code><a href="base.html#topic+strptime">strptime</a></code>
formatting strings. See the help on <code><a href="#topic+stsplot_time1">stsplot_time1</a></code> for
details.
</p>

<dl>
<dt>&quot;%d&quot;</dt><dd></dd>
<dt>&quot;%W&quot;</dt><dd></dd>
<dt>&quot;%V&quot;</dt><dd></dd>
<dt>&quot;%m&quot;</dt><dd></dd>
<dt>&quot;%Q&quot;</dt><dd></dd>
<dt>&quot;%Y&quot;</dt><dd></dd>
<dt>&quot;%G&quot;</dt><dd></dd>
</dl>

</dd>
<dt>colors:</dt><dd>
<p>A named list containing plotting color defaults.
</p>

<dl>
<dt>nowSymbol</dt><dd><p>Color of the &quot;now&quot; symbol in <code>stsNC</code>
plots. Default: <code>"springgreen4"</code>.</p>
</dd>
<dt>piBars</dt><dd><p>Color of the prediction interval bars in <code>stsNC</code>
plots. Default: <code>"orange"</code>.</p>
</dd>
</dl>

</dd>
<dt>allExamples:</dt><dd>
<p>Logical flag queried before running cumbersome computations in
help file examples. For <code>interactive()</code> sessions,
this option defaults to <code>TRUE</code>. Otherwise, long examples
will only be run if the environment variable
<span class="env">_R_SURVEILLANCE_ALL_EXAMPLES_</span> is set (to any value different
from <code>""</code>) when attaching the <span class="pkg">surveillance</span> package.
This is to avoid long computations during (daily) CRAN checks.
</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Value</h3>

<p><code>reset.surveillance.options</code> reverts all options to their default
values and (invisibly) returns these in a list.
</p>
<p>For <code>surveillance.options</code>, the following holds:
</p>

<ul>
<li><p> If no arguments are given, the current values of all package options are
returned in a list.
</p>
</li>
<li><p> If one option name is given, the current value of this
option is returned (<em>not</em> in a list, just the value).
</p>
</li>
<li><p> If several option names are given, the current values of these options
are returned in a list.
</p>
</li>
<li><p> If <code>name=value</code> pairs are given, the named options
are set to the given values, and the <em>previous</em> values of
these options are returned in a list.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>surveillance.options()
</code></pre>

<hr>
<h2 id='tidy.sts'>
Convert an <code>"sts"</code> Object to a Data Frame in Long (Tidy) Format
</h2><span id='topic+tidy.sts'></span>

<h3>Description</h3>

<p>The resulting data frame will have a row for each time point and
observational unit, and columns corresponding to the slots of the
<code>"<a href="#topic+sts-class">sts</a>"</code> object (except for <code>populationFrac</code>,
which is named <code>population</code>).
Some time variables are added for convenience:
<code>year</code>, <code>epochInYear</code>, <code>epochInPeriod</code>, <code>date</code>
(the latter gives <code>NA</code> dates if <code>epoch(x, as.Date=TRUE)</code>
fails, i.e., for non-standard <code>x@freq</code> if not <code>x@epochAsDate</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tidy.sts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tidy.sts_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+sts-class">sts</a>"</code>.</p>
</td></tr>
<tr><td><code id="tidy.sts_+3A_...">...</code></td>
<td>
<p>unused.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.data.frame.sts">as.data.frame.sts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("momo")
momodat &lt;- tidy.sts(momo)
head(momodat)

## tidy.sts(stsObj) is the same as as.data.frame(stsObj, tidy = TRUE)
stopifnot(identical(as.data.frame(momo, tidy = TRUE), momodat))
</code></pre>

<hr>
<h2 id='toLatex.sts'><code>toLatex</code>-Method for <code>"sts"</code> Objects</h2><span id='topic+toLatex.sts'></span><span id='topic+toLatex+2Csts-method'></span>

<h3>Description</h3>

<p>Convert <code>"<a href="#topic+sts-class">sts</a>"</code> objects to a
character vector with LaTeX markup.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'sts'
toLatex(object, caption = "",label=" ", columnLabels = NULL,
        subset = NULL, 
        alarmPrefix = "\\textbf{\\textcolor{red}{",
        alarmSuffix = "}}", ubColumnLabel = "UB", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="toLatex.sts_+3A_object">object</code></td>
<td>
<p>an <code>"<a href="#topic+sts-class">sts</a>"</code> object.</p>
</td></tr>
<tr><td><code id="toLatex.sts_+3A_caption">caption</code></td>
<td>
<p>A caption for the table. Default is the empty string.</p>
</td></tr>
<tr><td><code id="toLatex.sts_+3A_label">label</code></td>
<td>
<p>A label for the table. Default is the empty string.</p>
</td></tr>
<tr><td><code id="toLatex.sts_+3A_columnlabels">columnLabels</code></td>
<td>
<p>A list of labels for each column of the resulting table. Default is NULL</p>
</td></tr>
<tr><td><code id="toLatex.sts_+3A_subset">subset</code></td>
<td>
<p>A range of values which should be displayed. If Null, then all data in the sts objects will be displayed. Else only a subset of 
data. Therefore range needs to be a numerical vector of indexes from 1 to length(@observed).</p>
</td></tr>
<tr><td><code id="toLatex.sts_+3A_alarmprefix">alarmPrefix</code></td>
<td>
<p>A latex compatible prefix string wrapped around a table cell iff there is an alarm;i.e. alarm = TRUE</p>
</td></tr>
<tr><td><code id="toLatex.sts_+3A_alarmsuffix">alarmSuffix</code></td>
<td>
<p>A latex compatible suffix string wrapped around a table cell iff there is an alarm;i.e. alarm[i,j] = TRUE</p>
</td></tr>
<tr><td><code id="toLatex.sts_+3A_ubcolumnlabel">ubColumnLabel</code></td>
<td>
<p>The label of the upper bound column; default is
\&quot;UB\&quot;.</p>
</td></tr>
<tr><td><code id="toLatex.sts_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="xtable.html#topic+print.xtable">print.xtable</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="utils.html#topic+toLatex">&quot;Latex&quot;</a></code>.
</p>


<h3>Author(s)</h3>

<p>Dirk Schumacher</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a test object
data("salmonella.agona")

# Create the corresponding sts object from the old disProg object
salm &lt;- disProg2sts(salmonella.agona)

control &lt;- list(range=(260:312),
                noPeriods=1,populationOffset=FALSE,
                fitFun="algo.farrington.fitGLM.flexible",
                b=4,w=3,weightsThreshold=1,
                pastWeeksNotIncluded=3,
                pThresholdTrend=0.05,trend=TRUE,
                thresholdMethod="delta",alpha=0.1)
salm &lt;- farringtonFlexible(salm,control=control)

toLatex(salm, sanitize.text.function=identity, comment=FALSE)
</code></pre>

<hr>
<h2 id='twinSIR'>
Fit an Additive-Multiplicative Intensity Model for SIR Data
</h2><span id='topic+twinSIR'></span>

<h3>Description</h3>

<p><code>twinSIR</code> is used to fit additive-multiplicative intensity models for
epidemics as described in Höhle (2009).  Estimation is driven 
by (penalized) maximum likelihood in the point process frame work.  Optimization 
(maximization) of the (penalized) likelihood function is performed by means of 
<code><a href="stats.html#topic+optim">optim</a></code>.
The implementation is illustrated in Meyer et al. (2017, Section 4),
see <code>vignette("twinSIR")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twinSIR(formula, data, weights, subset,
        knots = NULL, nIntervals = 1, lambda.smooth = 0, penalty = 1,
        optim.args = list(), model = TRUE, keep.data = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinSIR_+3A_formula">formula</code></td>
<td>

<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that can be coerced to
that class): a symbolic description of the intensity model to be estimated.  
The details of the model specification are given below.
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_data">data</code></td>
<td>

<p>an object inheriting from class <code>"<a href="#topic+epidata">epidata</a>"</code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_weights">weights</code></td>
<td>

<p>an optional vector of weights to be used in the fitting process.  Should be
<code>NULL</code> (the default, i.e. all observations have unit weight) or a
numeric vector.
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_subset">subset</code></td>
<td>

<p>an optional vector specifying a subset of observations to be used in the
fitting process.  The subset <code>atRiskY == 1</code> is automatically chosen,
because the likelihood only depends on those observations.
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_knots">knots</code></td>
<td>

<p>numeric vector or <code>NULL</code> (the default).  Specification of the knots,
where we suppose a step of the log-baseline.  With the current 
implementation, these must be existing <code>"stop"</code> time points in the
selected <code>subset</code> of the <code>data</code>, which is always
restricted to <code>atRiskY == 1</code> rows.
The intervals of constant log-baseline 
hazard rate then are <code class="reqn">(minTime;knots_1]</code>, <code class="reqn">(knots_1;knots_2]</code>,
..., <code class="reqn">(knots_K;maxTime]</code>.
By default, the <code>knots</code> are automatically chosen at the quantiles of
the infection time points such that <code>nIntervals</code> intervals result.
Non-NULL <code>knots</code> take precedence over <code>nIntervals</code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_nintervals">nIntervals</code></td>
<td>

<p>the number of intervals of constant log-baseline hazard.  Defaults to 1,
which means an overall constant log-baseline hazard will be fitted.
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_lambda.smooth">lambda.smooth</code></td>
<td>

<p>numeric, the smoothing parameter <code class="reqn">\lambda</code>.  By default it is 0 which
leads to unpenalized likelihood inference.
In case <code>lambda.smooth=-1</code>, the automatic smoothing parameter
selection based on a mixed model approach is used (cf.
Höhle, 2009).
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_penalty">penalty</code></td>
<td>

<p>either a single number denoting the order of the difference used to penalize
the log-baseline coefficients (defaults to 1), or a more specific penalty
matrix <code class="reqn">K</code> for the parameter sub-vector <code class="reqn">\beta</code>. In case of
non-equidistant knots &ndash; usually the case when using quantile based
knot locations &ndash; only a 1st order differences penalty matrix as in
Fahrmeir and Lang (2001) is implemented.
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_optim.args">optim.args</code></td>
<td>

<p>a list with arguments passed to the <code><a href="stats.html#topic+optim">optim</a></code> function.
Especially useful are the following ones:
</p>

<dl>
<dt><code>par</code>:</dt><dd>
<p>to specify initial parameter values.  Those must be in the order
<code>c(alpha, h0, beta)</code>, i.e. first the coefficients of the epidemic
covariates in the same order as they appear in the <code>formula</code>, then
the log-baseline levels in chronological order and finally the
coefficients of the endemic covariates in the same order
as they appear in the <code>cox</code> terms of the <code>formula</code>.  The default
is to start with 1's for <code>alpha</code> and 0's for <code>h0</code> and
<code>beta</code>.
</p>
</dd>
<dt><code>control</code>:</dt><dd>
<p>for more detailed <code>trace</code>-ing (default: 1), another <code>REPORT</code>-ing
frequency if <code>trace</code> is positive (default: 10), higher <code>maxit</code>
(maximum number of iterations, default: 300) or another <code>factr</code> value
(default: 1e7, a lower value means higher precision).
</p>
</dd>
<dt><code>method</code>:</dt><dd>
<p>the optimization algorithm defaults to <code>"L-BFGS-B"</code> (for
box-constrained optimization), if there are any epidemic (non-<code>cox</code>)
variables in the model, and to <code>"BFGS"</code> otherwise.
</p>
</dd>
<dt><code>lower</code>:</dt><dd>
<p>if <code>method = "L-BFGS-B"</code> this defines the lower bounds for the
model coefficients.  By default, all effects <code class="reqn">\alpha</code> of epidemic
variables are restricted to be non-negative.  Normally, this is exactly
what one would like to have, but there might be reasons for other lower
bounds, see the Note below.
</p>
</dd>
<dt><code>hessian</code>:</dt><dd>
<p>An estimation of the Expected Fisher Information matrix is always 
part of the return value of the function.  It might be interesting to see 
the Observed Fisher Information (= negative Hessian at the maximum), too. 
This will be additionally returned if <code>hessian = TRUE</code>.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="twinSIR_+3A_model">model</code></td>
<td>

<p>logical indicating if the model frame, the <code>weights</code>,
<code>lambda.smooth</code>, the penalty matrix <code class="reqn">K</code> and the list of used
distance functions <code>f</code> (from <code>attributes(data)</code>) should be
returned for further computation.  This defaults to <code>TRUE</code> as this
information is necessary e.g. in the <code>profile</code> and <code>plot</code> 
methods.
</p>
</td></tr>
<tr><td><code id="twinSIR_+3A_keep.data">keep.data</code></td>
<td>

<p>logical indicating if the <code>"epidata"</code> object (<code>data</code>)
should be part of the return value. This is only necessary for use of the
<code><a href="#topic+simulate.twinSIR">simulate</a></code>-method for <code>"twinSIR"</code>
objects.  The reason is that the <code>twinSIR</code> function only uses and
stores the rows with <code>atRiskY == 1</code> in the <code>model</code> component, but
for the simulation of new epidemic data one needs the whole data set with
all individuals in every time block.  The default value is <code>FALSE</code>, so
if you intent to use <code>simulate.twinSIR</code>, you have to set this to
<code>TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

  
<p>A model is specified through the <code>formula</code>, which has the form
</p>
<p><code>~ epidemicTerm1 + epidemicTerm2 + cox(endemicVar1) *
    cox(endemicVar2)</code>,
</p>
<p>i.e. the right hand side has the usual form as in <code><a href="stats.html#topic+lm">lm</a></code> with
some variables marked as being endemic by the special function
<code><a href="#topic+cox">cox</a></code>.  The left hand side of the formula is empty and will be
set internally to <code>cbind(start, stop, event)</code>, which is similar to
<code>Surv(start, stop, event, type="counting")</code> in package <span class="pkg">survival</span>.
</p>
<p>Basically, the additive-multiplicative model for the infection intensity
<code class="reqn">\lambda_i(t)</code> for individual <code class="reqn">i</code> is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_i(t) = Y_i(t) * (e_i(t) + h_i(t))</code>
</p>

<p>where
</p>

<dl>
<dt>Y_i(t)</dt><dd>
<p>is the at-risk indicator, indicating if individual <code class="reqn">i</code> is
&ldquo;at risk&rdquo; of becoming infected at time point <code class="reqn">t</code>.
This variable is part of the event history <code>data</code>.
</p>
</dd>
<dt>e_i(t)</dt><dd>
<p>is the epidemic component of the infection intensity, defined as
</p>
<p style="text-align: center;"><code class="reqn">e_i(t) = \sum_{j \in I(t)} f(||s_i - s_j||)</code>
</p>

<p>where <code class="reqn">I(t)</code> is the set of infectious individuals just before time
point <code class="reqn">t</code>, <code class="reqn">s_i</code> is the coordinate vector of individual <code class="reqn">i</code>
and the function <code class="reqn">f</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">f(u) = \sum_{m=1}^p \alpha_m B_m(u)</code>
</p>

<p>with unknown transmission parameters <code class="reqn">\alpha</code> and known distance
functions <code class="reqn">B_m</code>. This set of distance functions results in the set of
epidemic variables normally calculated by the converter function
<code><a href="#topic+as.epidata">as.epidata</a></code>, considering the equality
</p>
<p style="text-align: center;"><code class="reqn">e_i(t) = \sum_{m=1}^p \alpha_m x_{im}(t)</code>
</p>

<p>with <code class="reqn">x_{im}(t) = \sum_{j \in I(t)} B_m(||s_i - s_j||)</code> being the
<code class="reqn">m</code>'th epidemic variable for individual <code class="reqn">i</code>.
</p>
</dd>
<dt>h_i(t)</dt><dd>
<p>is the endemic (<code>cox</code>) component of the infection intensity, defined
as
</p>
<p style="text-align: center;"><code class="reqn">h_i(t) = \exp(h_0(t) + z_i(t)' \beta)</code>
</p>

<p>where <code class="reqn">h_0(t)</code> is the log-baseline hazard function, <code class="reqn">z_i(t)</code>
is the vector of endemic covariates of individual <code class="reqn">i</code> and <code class="reqn">\beta</code>
is the vector of unknown coefficients.
To fit the model, the log-baseline hazard function is approximated by a
piecewise constant function with known knots, but unknown levels,
which will be estimated. The approximation is specified by the arguments
<code>knots</code> or <code>nIntervals</code>.
</p>
</dd>
</dl>

<p>If a big number of <code>knots</code> (or <code>nIntervals</code>) is chosen, the
corresponding log-baseline parameters can be rendered identifiable by
the use of penalized likelihood inference.  At present, it is the job
of the user to choose an adequate value of the smoothing parameter
<code>lambda.smooth</code>. Alternatively, a data driven
<code>lambda.smooth</code> smoothing parameter selection based on a mixed
model representation of an equivalent truncated power spline is offered (see
reference for further details). The following two steps are iterated
until convergence:
</p>

<ol>
<li><p> Given fixed smoothing parameter, the penalized
likelihood is optimized for the regression components using a L-BFGS-B
approach
</p>
</li>
<li><p> Given fixed regression parameters, a Laplace approximation of the
marginal likelihood for the smoothing parameter is numerically
optimized.  
</p>
</li></ol>

<p>Depending on the data, convergence might take a couple of iterations.
</p>
<p>Note also that it is unwise to include endemic covariates with huge values,
as they affect the intensities on the exponential scale (after
multiplication by the parameter vector <code class="reqn">\beta</code>).
With large covariate values, the
<code>optim</code> method &quot;L-BFGS-B&quot; will likely terminate due to an infinite 
log-likelihood or score function in some iteration.
</p>


<h3>Value</h3>

<p><code>twinSIR</code> returns an object of class
<code>"twinSIR"</code>, which is a list containing the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>a named vector of coefficients.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>the maximum of the (penalized) log-likelihood function.</p>
</td></tr>
<tr><td><code>counts</code></td>
<td>
<p>the number of log-likelihood and score function evaluations.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>logical indicating convergence of the optimization
algorithm.</p>
</td></tr>
<tr><td><code>fisherinfo.observed</code></td>
<td>
<p>if requested, the negative Hessian from
<code>optim</code>.</p>
</td></tr>
<tr><td><code>fisherinfo</code></td>
<td>
<p>an estimation of the Expected Fisher Information matrix.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the optimization algorithm used.</p>
</td></tr>
<tr><td><code>intervals</code></td>
<td>
<p>a numeric vector (<code>c(minTime, knots, maxTime)</code>)
representing the consecutive intervals of constant log-baseline.</p>
</td></tr>
<tr><td><code>nEvents</code></td>
<td>
<p>a numeric vector containing the number of infections in each of
the above <code>intervals</code>.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>if requested, the model information used. This is a list with
components <code>"survs"</code> (data.frame with the id, start, stop and event
columns), <code>"X"</code> (matrix of the epidemic variables), <code>"Z"</code> (matrix
of the endemic variables), <code>"weights"</code> (the specified <code>weights</code>), 
<code>"lambda.smooth"</code> (the specified <code>lambda.smooth</code>), <code>"K"</code>
(the penalty matrix used), and <code>"f"</code> and <code>"w"</code>
(the functions to generate the used epidemic covariates).
Be aware that the model only contains those rows with <code>atRiskY == 1</code>!</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>if requested, the supplied <code>"epidata"</code> <code>data</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the specified <code>formula</code>.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the <code>terms</code> object used.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>There are some restrictions to modelling the infection intensity
without a baseline hazard rate, i.e. without an intercept in the
<code>formula</code>.  
Reason: At some point, the optimization algorithm L-BFGS-B tries to set all 
transmission parameters <code class="reqn">\alpha</code> to the boundary value 0 and to calculate
the (penalized) score function with this set of parameters (all 0).  The problem
then is that the values of the infection intensities <code class="reqn">lambda_i(t)</code> are 0
for all <code class="reqn">i</code> and <code class="reqn">t</code> and especially at observed event times, which is 
impossible.  Without a baseline, it is not allowed to have all alpha's set to 0, 
because then we would not observe any infections.  Unfortunately, L-BFGS-B can 
not consider this restriction.  Thus, if one wants to fit a model without 
baseline hazard, the control parameter <code>lower</code> must be specified in 
<code>optim.args</code> so that some alpha is strictly positive, e.g.
<code>optim.args = list(lower = c(0,0.001,0.001,0))</code> and the initial parameter
vector <code>par</code> must not be the zero vector.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle and Sebastian Meyer
</p>


<h3>References</h3>

<p>Höhle, M. (2009),
Additive-multiplicative regression models for spatio-temporal
epidemics, <em>Biometrical Journal</em>, <b>51</b> (6), 961-978.
</p>
<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.epidata">as.epidata</a></code> for the necessary data input structure,
<code><a href="#topic+plot.twinSIR">plot.twinSIR</a></code> for plotting the path of the infection intensity,
<code><a href="#topic+profile.twinSIR">profile.twinSIR</a></code> for profile likelihood estimation.
and <code><a href="#topic+simulate.twinSIR">simulate.twinSIR</a></code> for the simulation of epidemics following
the fitted model.
</p>
<p>Furthermore, the standard extraction methods
<code><a href="#topic+vcov.twinSIR">vcov</a></code>, <code><a href="#topic+logLik.twinSIR">logLik</a></code>,
<code><a href="#topic+AIC.twinSIR">AIC</a></code> and
<code><a href="#topic+extractAIC.twinSIR">extractAIC</a></code> are implemented for
objects of class <code>"twinSIR"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
summary(hagelloch)

# simple model with an overall constant baseline hazard rate
fit1 &lt;- twinSIR(~ household + cox(AGE), data = hagelloch)
fit1
summary(fit1)   # see also help("summary.twinSIR")
plot(fit1)      # see also help("plot.twinSIR")
checkResidualProcess(fit1)   # could be better

# fit a piecewise constant baseline hazard rate with 3 intervals using 
# _un_penalized ML and estimated coefs from fit1 as starting values 
fit2 &lt;- twinSIR(~ household, data = hagelloch, nIntervals = 3,
                optim.args = list(par = coef(fit1)[c(1,2,2,2)]))
summary(fit2)

# fit a piecewise constant baseline hazard rate with 7 intervals
# using _penalized_ ML
fit3 &lt;- twinSIR(~ household, data = hagelloch, nIntervals = 7,
                lambda.smooth = 0.1, penalty = 1)
summary(fit3)
checkResidualProcess(fit3)

# plot the estimated log-baseline levels
plot(x=fit2$intervals, y=coef(fit2)[c(2,2:4)], type="S", ylim=c(-6, -1))
lines(x=fit3$intervals, y=coef(fit3)[c(2,2:8)], type="S", col=2)
legend("right", legend=c("unpenalized 3", "penalized 7"), lty=1, col=1:2, bty="n")


## special use case: fit the model to a subset of the events only,
## while preserving epidemic contributions from the remainder
## (maybe some buffer area nodes)
fit_subset &lt;- twinSIR(~ household, data = hagelloch, subset = CL=="preschool")
summary(fit_subset)


</code></pre>

<hr>
<h2 id='twinSIR_cox'>
Identify Endemic Components in an Intensity Model
</h2><span id='topic+cox'></span>

<h3>Description</h3>

<p>The special function <code>cox</code> marks terms in formulae of the functions
<code><a href="#topic+twinSIR">twinSIR</a></code> and <code><a href="#topic+simEpidata">simEpidata</a></code> as endemic components,
i.e. variables acting multiplicatively on the baseline infection intensity.
An illustrative <code>twinSIR</code> call with two epidemic and two endemic
covariates is:
<code>twinSIR(~B1 + B2 + cox(vaccination) + cox(size), data=myEpidata)</code>.
</p>
<p>Technically, this function is implemented as <code>function(x) {x}</code> and
defined as &ldquo;special&rdquo; in <code><a href="stats.html#topic+terms.formula">terms.formula</a></code>.
</p>


<h3>See Also</h3>

<p>Usage in formulae of functions <code><a href="#topic+twinSIR">twinSIR</a></code> and
<code><a href="#topic+simEpidata">simEpidata</a></code>.
</p>

<hr>
<h2 id='twinSIR_exData'>
Toy Data for <code>twinSIR</code>
</h2><span id='topic+fooepidata'></span>

<h3>Description</h3>

<p>Toy <code>"<a href="#topic+epidata">epidata</a>"</code> previously used to exemplify
<code><a href="#topic+twinSIR">twinSIR</a></code> models. We now use the well-known
<code><a href="#topic+hagelloch">hagelloch</a></code> dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fooepidata)
</code></pre>

<hr>
<h2 id='twinSIR_intensityplot'>
Plotting Paths of Infection Intensities for <code>twinSIR</code> Models
</h2><span id='topic+plot.twinSIR'></span><span id='topic+intensityplot.twinSIR'></span><span id='topic+intensityplot.simEpidata'></span>

<h3>Description</h3>

<p><code><a href="#topic+intensityplot">intensityplot</a></code> methods to plot the evolution of the total infection
intensity, its epidemic proportion or its endemic proportion over time.
The default <code>plot</code> method for objects of class <code>"twinSIR"</code>
is just a wrapper for the <code>intensityplot</code> method.
The implementation is illustrated in Meyer et al. (2017, Section 4),
see <code>vignette("twinSIR")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinSIR'
plot(x, which = c("epidemic proportion", "endemic proportion",
     "total intensity"), ...)

## S3 method for class 'twinSIR'
intensityplot(x, which = c("epidemic proportion", "endemic proportion",
              "total intensity"), aggregate = TRUE, theta = NULL,
              plot = TRUE, add = FALSE, rug.opts = list(), ...)

## S3 method for class 'simEpidata'
intensityplot(x, which = c("epidemic proportion", "endemic proportion",
              "total intensity"), aggregate = TRUE, theta = NULL,
              plot = TRUE, add = FALSE, rug.opts = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinSIR_intensityplot_+3A_x">x</code></td>
<td>

<p>an object of class <code>"<a href="#topic+twinSIR">twinSIR</a>"</code> (fitted model) or
<code>"<a href="#topic+simEpidata">simEpidata</a>"</code> (simulated <code>twinSIR</code> epidemic),
respectively. 
</p>
</td></tr>
<tr><td><code id="twinSIR_intensityplot_+3A_which">which</code></td>
<td>

<p><code>"epidemic proportion"</code>, <code>"endemic proportion"</code>,
or <code>"total intensity"</code>.  Partial matching is applied.  Determines
whether to plot the path of the total intensity <code class="reqn">\lambda(t)</code> or its 
epidemic or endemic proportions
<code class="reqn">\frac{e(t)}{\lambda(t)}</code> or
<code class="reqn">\frac{h(t)}{\lambda(t)}</code>. 
</p>
</td></tr>
<tr><td><code id="twinSIR_intensityplot_+3A_aggregate">aggregate</code></td>
<td>

<p>logical. Determines whether lines for all individual infection
intensities should be drawn (<code>FALSE</code>) or their sum only
(<code>TRUE</code>, the default).
</p>
</td></tr>
<tr><td><code id="twinSIR_intensityplot_+3A_theta">theta</code></td>
<td>

<p>numeric vector of model coefficients.  If <code>x</code> is of class
<code>"twinSIR"</code>, then <code>theta = c(alpha, beta)</code>, where <code>beta</code>
consists of the coefficients of the piecewise constant log-baseline function
and the coefficients of the endemic (<code>cox</code>) predictor.  If <code>x</code> is
of class <code>"simEpidata"</code>, then <code>theta = c(alpha, 1, betarest)</code>, 
where 1 refers to the (true) log-baseline used in the simulation and 
<code>betarest</code> is the vector of the remaining coefficients of the endemic 
(<code>cox</code>) predictor.
The default (<code>NULL</code>) means that the fitted or true parameters,
respectively, will be used.
</p>
</td></tr>
<tr><td><code id="twinSIR_intensityplot_+3A_plot">plot</code></td>
<td>

<p>logical indicating if a plot is desired, defaults to <code>TRUE</code>.
Otherwise, only the data of the plot will be returned.  Especially with
<code>aggregate = FALSE</code> and many individuals one might e.g. consider to 
plot a subset of the individual intensity paths only or do some further
calculations/analysis of the infection intensities.
</p>
</td></tr>
<tr><td><code id="twinSIR_intensityplot_+3A_add">add</code></td>
<td>

<p>logical.  If <code>TRUE</code>, paths are added to the current plot, using
<code>lines</code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_intensityplot_+3A_rug.opts">rug.opts</code></td>
<td>

<p>either a list of arguments passed to the function <code><a href="graphics.html#topic+rug">rug</a></code>, or
<code>NULL</code> (or <code>NA</code>), in which case no <code>rug</code> will be plotted.
By default, the argument <code>ticksize</code> is set to 0.02 and <code>quiet</code>
is set to <code>TRUE</code>.  Note that the argument <code>x</code> of the
<code>rug()</code> function, which contains the
locations for the <code>rug</code> is fixed internally and can not be modified.
The locations of the rug are the time points of infections.
</p>
</td></tr>
<tr><td><code id="twinSIR_intensityplot_+3A_...">...</code></td>
<td>

<p>For the <code>plot.twinSIR</code> method, arguments passed to
<code>intensityplot.twinSIR</code>.
For the <code>intensityplot</code> methods, further graphical parameters
passed to the function <code><a href="graphics.html#topic+matplot">matplot</a></code>, 
e.g. <code>lty</code>, <code>lwd</code>, <code>col</code>, <code>xlab</code>, <code>ylab</code> and
<code>main</code>.  Note that the <code>matplot</code> arguments <code>x</code>, <code>y</code>,
<code>type</code> and <code>add</code> are implicit and can not be specified here.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric matrix with the first column <code>"stop"</code> and as many rows as there
are <code>"stop"</code> time points in the event history <code>x</code>.  The other 
columns depend on the argument <code>aggregate</code>: if <code>TRUE</code>, there 
is only one other column named <code>which</code>, which contains the values of 
<code>which</code> at the respective <code>"stop"</code> time points.  Otherwise, if
<code>aggregate = FALSE</code>, there is one column for each individual, each of
them containing the individual <code>which</code> at the respective <code>"stop"</code>
time points.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+twinSIR">twinSIR</a></code> for a description of the intensity model, and
<code><a href="#topic+simulate.twinSIR">simulate.twinSIR</a></code> for the simulation of epidemic data
according to a <code>twinSIR</code> specification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
plot(hagelloch)

# a simplistic twinSIR model
fit &lt;- twinSIR(~ household, data = hagelloch)

# overall total intensity
plot(fit, which = "total")

# overall epidemic proportion
epi &lt;- plot(fit, which = "epidemic", ylim = c(0, 1))
head(epi)
# add overall endemic proportion = 1 - epidemic proportion
ende &lt;- plot(fit, which = "endemic", add = TRUE, col = 2)
legend("topleft", legend = "endemic proportion", lty = 1, col = 2, bty = "n")


# individual intensities
tmp &lt;- plot(fit, which = "total", aggregate = FALSE,
    col = rgb(0, 0, 0, alpha = 0.1),
    main = expression("Individual infection intensities " *
        lambda[i](t) == Y[i](t) %.% (e[i](t) + h[i](t))))
# return value: matrix of individual intensity paths
str(tmp)

# plot intensity path only for individuals 3 and 99
matplot(x = tmp[,1], y = tmp[,1+c(3,99)], type = "S",
        ylab = "Force of infection", xlab = "time",
        main = expression("Paths of the infection intensities " *
                          lambda[3](t) * " and " * lambda[99](t)))
legend("topright", legend = paste("Individual", c(3,99)),
       col = 1:2, lty = 1:2)

</code></pre>

<hr>
<h2 id='twinSIR_methods'>
Print, Summary and Extraction Methods for <code>"twinSIR"</code> Objects
</h2><span id='topic+print.twinSIR'></span><span id='topic+summary.twinSIR'></span><span id='topic+AIC.twinSIR'></span><span id='topic+extractAIC.twinSIR'></span><span id='topic+vcov.twinSIR'></span><span id='topic+logLik.twinSIR'></span><span id='topic+print.summary.twinSIR'></span>

<h3>Description</h3>

<p>Besides <code>print</code> and <code>summary</code> methods there are also some standard
extraction methods defined for objects of class <code>"twinSIR"</code>:
<code>vcov</code>, <code>logLik</code> and especially <code>AIC</code> and
<code>extractAIC</code>, which extract Akaike's Information Criterion.  Note that
special care is needed, when fitting models with parameter constraints such as
the epidemic effects <code class="reqn">\alpha</code> in <code>twinSIR</code> models.  Parameter
constraints reduce the average increase in the maximized loglikelihood - thus
the penalty for constrained parameters should be smaller than the factor 2 used
in the ordinary definition of AIC.  To this end, these two methods offer the
calculation of the so-called one-sided AIC (OSAIC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinSIR'
print(x, digits = max(3, getOption("digits") - 3), ...)
## S3 method for class 'twinSIR'
summary(object,
        correlation = FALSE, symbolic.cor = FALSE, ...)

## S3 method for class 'twinSIR'
AIC(object, ..., k = 2, one.sided = NULL, nsim = 1e3)
## S3 method for class 'twinSIR'
extractAIC(fit, scale = 0, k = 2, one.sided = NULL,
           nsim = 1e3, ...)

## S3 method for class 'twinSIR'
vcov(object, ...)
## S3 method for class 'twinSIR'
logLik(object, ...)

## S3 method for class 'summary.twinSIR'
print(x,
      digits = max(3, getOption("digits") - 3), symbolic.cor = x$symbolic.cor,
      signif.stars = getOption("show.signif.stars"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinSIR_methods_+3A_x">x</code>, <code id="twinSIR_methods_+3A_object">object</code>, <code id="twinSIR_methods_+3A_fit">fit</code></td>
<td>
<p>an object of class <code>"twinSIR"</code>.<br />
For the <code>print</code> method of the <code>summary</code> method, an object of
class <code>"summary.twinSIR"</code>.</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_digits">digits</code></td>
<td>

<p>integer, used for number formatting with <code>signif()</code>.  Minimum number of
significant digits to be printed in values.
</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_correlation">correlation</code></td>
<td>

<p>logical. if <code>TRUE</code>, the correlation matrix of the estimated parameters
is returned and printed.
</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_symbolic.cor">symbolic.cor</code></td>
<td>

<p>logical. If <code>TRUE</code>, print the correlations in a symbolic form (see
<code>symnum</code>) rather than as numbers.
</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_...">...</code></td>
<td>

<p>For the <code>summary</code> method: arguments passed to
<code><a href="#topic+extractAIC.twinSIR">extractAIC.twinSIR</a></code>.<br />
For the <code>AIC</code> method, optionally more fitted model objects.<br />
For the <code>print</code>, <code>extractAIC</code>, <code>vcov</code> and
<code>logLik</code> methods: unused (argument of the generic).
</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_k">k</code></td>
<td>

<p>numeric specifying the &quot;weight&quot; of the <em>penalty</em> to be used;
in an unconstrained fit <code>k = 2</code> is the classical AIC.
</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_one.sided">one.sided</code></td>
<td>

<p>logical or <code>NULL</code> (the default).  Determines if the one-sided AIC
should be calculated instead of using the classical penalty <code>k*edf</code>. 
The default value <code>NULL</code> chooses classical AIC in the case of an
unconstrained fit and one-sided AIC in the case of constraints. The type of
the fit can be seen in <code>object$method</code> (or <code>fit$method</code>
respectively), where <code>"L-BFGS"</code> means constrained optimization.
</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_nsim">nsim</code></td>
<td>

<p>when there are more than two epidemic covariates in the fit, the
weights in the OSAIC formula have to be determined by simulation. 
Default is to use 1000 samples. Note that package <span class="pkg">quadprog</span> is
additionally required in this case.
</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_scale">scale</code></td>
<td>
<p>unused (argument of the generic).</p>
</td></tr>
<tr><td><code id="twinSIR_methods_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical. If <code>TRUE</code>, &ldquo;significance
stars&rdquo; are printed for each coefficient.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> and <code>summary</code> methods allow the compact or comprehensive
representation of the fitting results, respectively.  The former only prints
the original function call, the estimated coefficients and the maximum
log-likelihood value.  The latter prints the whole coefficient matrix with
standard errors, z- and p-values (see <code><a href="stats.html#topic+printCoefmat">printCoefmat</a></code>), and 
additionally the number of infections per log-baseline <code>interval</code>, 
the (one-sided) AIC and the number of log-likelihood evaluations.  They both
append a big &ldquo;WARNING&rdquo;, if the optimization algorithm did not converge.
</p>
<p>The estimated coefficients may be extracted by using the default
<code>coef</code>-method from package <span class="pkg">stats</span>.
</p>
<p>The two AIC functions differ only in that <code>AIC</code> can take more than one
fitted model object and that <code>extractAIC</code> always returns the number of
parameters in the model (<code>AIC</code> only does with more than one fitted model
object).
</p>
<p>Concerning the choice of one-sided AIC: parameter constraints &ndash; such as the
non-negative constraints for the epidemic effects alpha in <code>twinSIR</code>
models &ndash; reduce the average increase in the maximized loglikelihood.  Thus,
the penalty for constrained parameters should be smaller than the factor 2
used in the ordinary definition of AIC.  One-sided AIC (OSAIC) suggested by
Hughes and King (2003) is such a proposal when <code class="reqn">p</code> out of <code class="reqn">k = p + q</code>
parameters have non-negative constraints:
</p>
<p style="text-align: center;"><code class="reqn">OSAIC = -2 l(\theta, \tau) + 2 \sum_{g=0}^p w(p,g) (k-p+g)</code>
</p>

<p>where <code class="reqn">w(p,g)</code> are <code class="reqn">p</code>-specific weights.  For more details see
Section 5.2 in Höhle (2009).
</p>


<h3>Value</h3>

<p>The <code>print</code> methods return their first argument, invisibly, as
they always should. The <code>vcov</code> and <code>logLik</code>
methods return the estimated variance-covariance
matrix of the parameters (here, the inverse of the estimate of the
expected Fisher information matrix), and the maximum log-likelihood
value of the model, respectively.
The <code>summary</code> method returns a list containing some summary
statistics of the fitted model, which is nicely printed by the
corresponding <code>print</code> method.
For the <code><a href="stats.html#topic+AIC">AIC</a></code> and <code><a href="stats.html#topic+extractAIC">extractAIC</a></code> methods, see
the documentation of the corresponding generic functions.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle and Sebastian Meyer
</p>


<h3>References</h3>

<p>Hughes A, King M (2003)
Model selection using AIC in the presence of one-sided information.
<em>Journal of Statistical Planning and Inference</em> <strong>115</strong>,
pp. 397&ndash;411.
</p>
<p>Höhle, M. (2009),
Additive-Multiplicative Regression Models for Spatio-Temporal
Epidemics, Biometrical Journal, 51(6):961-978.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")

# a simplistic twinSIR model
fit &lt;- twinSIR(~ household + cox(AGE), data = hagelloch)

coef(fit)
vcov(fit)
logLik(fit)

summary(fit, correlation = TRUE, symbolic.cor = TRUE)

# AIC or OSAIC
AIC(fit)
AIC(fit, one.sided = FALSE)
extractAIC(fit)
extractAIC(fit, one.sided = FALSE)

# comparing models via AIC
fit2 &lt;- update(fit, nIntervals = 2)
AIC(fit, fit2)   # the 2nd column should be named "OSAIC" here
</code></pre>

<hr>
<h2 id='twinSIR_profile'>
Profile Likelihood Computation and Confidence Intervals
</h2><span id='topic+profile.twinSIR'></span><span id='topic+plot.profile.twinSIR'></span>

<h3>Description</h3>

<p>Function to compute estimated and profile likelihood based confidence
intervals. Computations might be cumbersome!
There is a simple <code>plot</code>-method for the result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinSIR'
profile(fitted, profile, alpha = 0.05,
        control = list(fnscale = -1, factr = 10, maxit = 100), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinSIR_profile_+3A_fitted">fitted</code></td>
<td>

<p>an object of class <code>"twinSIR"</code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_profile_+3A_profile">profile</code></td>
<td>

<p>a list with elements being numeric vectors of length 4.  These vectors must
have the form <code>c(index, lower, upper, gridsize)</code>.
</p>

<dl>
<dt><code>index</code>:</dt><dd>
<p>index of the parameter to be profiled in the vector <code>coef(fitted)</code>.
</p>
</dd>
<dt><code>lower, upper</code>:</dt><dd>
<p>lower/upper limit of the grid on which the profile log-likelihood is
evaluated. Can also be <code>NA</code> in which case <code>lower/upper</code> equals 
the lower/upper bound of the respective 0.3 % Wald confidence interval
(+-3*se).
</p>
</dd>
<dt><code>gridsize</code>:</dt><dd>
<p>grid size of the equally spaced grid between lower and upper.  Can also
be 0 in which case the profile log-likelihood for this parameter is not 
evaluated on a grid.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="twinSIR_profile_+3A_alpha">alpha</code></td>
<td>

<p><code class="reqn">(1-\alpha) 100\%</code> profile likelihood based confidence
intervals are computed.  If <code>alpha &lt;= 0</code>, then no confidence intervals are
computed.
</p>
</td></tr>
<tr><td><code id="twinSIR_profile_+3A_control">control</code></td>
<td>

<p>control object to use in <code><a href="stats.html#topic+optim">optim</a></code> for the profile log-likelihood
computations.
</p>
</td></tr>
<tr><td><code id="twinSIR_profile_+3A_...">...</code></td>
<td>

<p>unused (argument of the generic).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with profile log-likelihood evaluations on the grid and highest likelihood
and Wald confidence intervals.  The argument <code>profile</code> is also returned.
The result has class <code>"profile.twinSIR"</code>, for which a simple (undocumented)
<code>plot</code>-method is available.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle and Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("hagelloch")
fit &lt;- twinSIR(~ household, data = hagelloch)
gridsize &lt;- if (interactive()) 35 else 5  # for fast tests
prof &lt;- profile(fit, list(c(1, NA, NA, gridsize)))
prof$ci.hl
plot(prof)
</code></pre>

<hr>
<h2 id='twinSIR_simulation'>
Simulation of Epidemic Data
</h2><span id='topic+simEpidata'></span><span id='topic+simulate.twinSIR'></span>

<h3>Description</h3>

<p>This function simulates the infection (and removal) times of 
an epidemic.  Besides the classical SIR type of epidemic, also SI, SIRS and
SIS epidemics are supported.  Simulation works via the conditional intensity 
of infection of an individual, given some (time varying) endemic covariates 
and/or some distance functions (epidemic components) as well as the fixed 
positions of the individuals.  The lengths of the infectious and removed 
periods are generated following a pre-specified function (can be
deterministic).
</p>
<p>The <code><a href="stats.html#topic+simulate">simulate</a></code> method for objects of class
<code>"<a href="#topic+twinSIR">twinSIR</a>"</code> simulates new epidemic data using the model and
the parameter estimates of the fitted object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simEpidata(formula, data, id.col, I0.col, coords.cols, subset,
           beta, h0, f = list(), w = list(), alpha, infPeriod,
           remPeriod = function(ids) rep(Inf, length(ids)),
           end = Inf, trace = FALSE, .allocate = NULL)

## S3 method for class 'twinSIR'
simulate(object, nsim = 1, seed = 1,
         infPeriod = NULL, remPeriod = NULL,
         end = diff(range(object$intervals)), trace = FALSE, .allocate = NULL,
         data = object$data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinSIR_simulation_+3A_formula">formula</code></td>
<td>

<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that can be coerced to
that class): a symbolic description of the intensity model to be estimated.  
The details of model specification are given under Details.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_data">data</code></td>
<td>

<p>a data.frame containing the variables in <code>formula</code> and the variables
specified by <code>id.col</code>, <code>I0.col</code> and <code>coords.col</code> (see below).
It represents the &ldquo;history&rdquo; of the endemic covariates to use for the
simulation.  The form is similar to and can be an object of class
<code>"<a href="#topic+epidata">epidata</a>"</code>.  The simulation period is split up into
<em>consecutive</em> intervals of constant endemic covariables.  The 
data frame consists of a block of N (number of individuals) rows for each of
those time intervals (all rows in a block share the same start and stop 
values... therefore the name &ldquo;block&rdquo;), where there is one row per 
individual in the block.  Each row describes the (fixed) state of the 
endemic covariates of the individual during the time interval given by the 
start and stop columns (specified through the lhs of <code>formula</code>).
</p>
<p>For the <code>simulate</code> method of class <code>"twinSIR"</code> this should be 
the object of class <code>"<a href="#topic+epidata">epidata</a>"</code> used for the fit.  This is a
part of the return value of the function <code>twinSIR</code>, if called with 
argument <code>keep.data</code> set to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_id.col">id.col</code></td>
<td>

<p>only if <code>data</code> does not inherit from <code>epidata</code>:
single index of the <code>id</code> column in <code>data</code>.  Can be numeric
(by column number) or character (by column name).<br />
The <code>id</code> column identifies the individuals in the data-frame.  It will
be converted to a factor variable and its levels serve also to identify 
individuals as argument to the <code>infPeriod</code> function.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_i0.col">I0.col</code></td>
<td>

<p>only if <code>data</code> does not inherit from <code>epidata</code>:
single index of the <code>I0</code> column in <code>data</code>.  Can be numeric
(by column number), character (by column name) or <code>NULL</code>.<br />
The <code>I0</code> column indicates if an individual is initially infectious,
i.e. it is already infectious at the beginning of the first time block.
Setting <code>I0.col = NULL</code> is short for &ldquo;there are no initially
infectious individuals&rdquo;. Otherwise, the variable must be logical or in
0/1-coding.  As this variable is constant over time the initially
infectious individuals are derived from the first time block only.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_coords.cols">coords.cols</code></td>
<td>

<p>only if <code>data</code> does not inherit from <code>epidata</code>:
index<em>es</em> of the <code>coords</code> column<em>s</em> in <code>data</code>.  Can be a
numeric (by column number), a character (by column name) vector or
<code>NULL</code>.<br />
These columns contain the coordinates of the individuals.  It must be
emphasized that the functions in this package currently assume <em>fixed
positions</em> of the individuals during the whole epidemic.  Thus, an
individual has the same coordinates in every block.  For simplicity, the
coordinates are derived from the first time block only.  The epidemic
covariates are calculated based on the Euclidian distance between the
individuals, see <code>f</code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_subset">subset</code></td>
<td>

<p>an optional vector specifying a subset of the covariate history to be used 
in the simulation.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_beta">beta</code></td>
<td>

<p>numeric vector of length equal the number of endemic (<code>cox</code>) terms on
the rhs of <code>formula</code>.  It contains the effects of the endemic predictor
(excluding the log-baseline <code>h0</code>, see below) in the same order as in 
the formula.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_h0">h0</code></td>
<td>

<p><em>either</em> a single number to specify a constant baseline hazard
(equal to <code>exp(h0)</code>) <em>or</em> a list of functions named
<code>exact</code> and <code>upper</code>.  In the latter case, <code>h0$exact</code>
is the true log-baseline hazard function and <code>h0$upper</code> is a
<em>piecewise constant upper bound</em> for <code>h0$exact</code>.  The function
<code>h0$upper</code> must inherit from <code><a href="stats.html#topic+stepfun">stepfun</a></code> with
<code>right=FALSE</code>.  Theoretically, the intensity function is
left-continuous, thus <code>right=TRUE</code> would be adequate, but in the
implementation, when we evaluate the intensity at the
<code><a href="stats.html#topic+knots">knots</a></code> (change points) of <code>h0$upper</code> we need its value
for the subsequent interval.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_f">f</code>, <code id="twinSIR_simulation_+3A_w">w</code></td>
<td>

<p>see <code><a href="#topic+as.epidata">as.epidata</a></code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_alpha">alpha</code></td>
<td>

<p>a named numeric vector of coefficients for the epidemic
covariates generated by <code>f</code> and <code>w</code>. The names are matched
against <code>names(f)</code> and <code>names(w)</code>.
Remember that <code>alpha &gt;= 0</code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_infperiod">infPeriod</code></td>
<td>

<p>a function generating lengths of infectious periods.  It should take one
parameter (e.g. <code>ids</code>), which is a character vector of id's of 
individuals, and return appropriate infection periods for those
individuals.  Therefore, the value of the function should be of length
<code>length(ids)</code>.  For example, for independent and identically
distributed infection periods following <code class="reqn">Exp(1)</code>,
the generating function is <code>function(ids) rexp(length(ids), rate=1)</code>.  
For a constant infectious period of length c, it is sufficient to set
<code>function (x) {c}</code>.<br />
For the <code>simulate</code> method of class <code>"twinSIR"</code> only, this can
also be <code>NULL</code> (the default), which means that the observed infectious
periods of infected individuals are re-used when simulating a new epidemic
and individuals with missing infectious periods (i.e. infection and 
recovery was not observed) are attributed to the mean observed
infectious period.
</p>
<p>Note that it is even possible to simulate an SI-epidemic by setting
</p>
<p><code>infPeriod = function (x) {Inf}</code>
</p>
<p>In other words: once an individual became
infected it spreads the disease forever, i.e. it will never be removed.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_remperiod">remPeriod</code></td>
<td>

<p>a function generating lengths of removal periods.  Per default, once an
individual was removed it will stay in this state forever (<code>Inf</code>).
Therefore, it will not become at-risk (S) again and re-infections are not
possible.  Alternatively, always returning 0 as length of the removal 
period corresponds to a SIS epidemic.  Any other values correspond to SIRS.
Note that <code>end</code> should be set to a finite value in these cases.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_end">end</code></td>
<td>

<p>a single positive numeric value specifying the time point at which the
simulation should be forced to end.  By default, this is <code>Inf</code>, i.e.
the simulation continues until there is no susceptible individual left.<br />
For the <code>simulate</code> method of class <code>"twinSIR"</code> the default is
to have equal simulation and observation periods.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_trace">trace</code></td>
<td>

<p>logical (or integer) indicating if (or how often) the sets of susceptible 
and infected individuals as well as the rejection indicator (of the 
rejection sampling step) should be <code>cat</code>ed.  Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_.allocate">.allocate</code></td>
<td>

<p>number of blocks to initially allocate for the event history (i.e.
<code>.allocate*N</code> rows). By default (<code>NULL</code>), this number is set to
<code>max(500, ceiling(nBlocks/100)*100)</code>, i.e. 500 but at least the
number of blocks in <code>data</code> (rounded to the next multiple of 100).
Each time the simulated epidemic exceeds the allocated space, the
event history will be enlarged by <code>.allocate</code> blocks.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_object">object</code></td>
<td>

<p>an object of class <code>"twinSIR"</code>.  This must contain the original
<code>data</code> used for the fit (see <code>data</code>).
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_nsim">nsim</code></td>
<td>

<p>number of epidemics to simulate.  Defaults to 1.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_seed">seed</code></td>
<td>

<p>an integer that will be used in the call to <code><a href="base.html#topic+set.seed">set.seed</a></code> before
simulating the epidemics.
</p>
</td></tr>
<tr><td><code id="twinSIR_simulation_+3A_...">...</code></td>
<td>

<p>unused (argument of the generic).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A model is specified through the <code>formula</code>, which has the form
</p>
<p><code>cbind(start, stop) ~ cox(endemicVar1) * cox(endemicVar2)</code>,
</p>
<p>i.e. the right hand side has the usual form as in <code><a href="stats.html#topic+lm">lm</a></code>, but
all variables are marked as being endemic by the special function
<code><a href="#topic+cox">cox</a></code>.  The effects of those predictor terms are specified by
<code>beta</code>.  The left hand side of the formula denotes the start
and stop columns in <code>data</code>.  This can be omitted, if <code>data</code> inherits
from class <code>"epidata"</code> in which case <code>cbind(start, stop)</code> will be
used.  The epidemic model component is specified by the arguments
<code>f</code> and <code>w</code> (and the associated coefficients <code>alpha</code>).
</p>
<p>If the epidemic model component is empty and <code>infPeriod</code>
always returns <code>Inf</code>, then one actually simulates from a pure Cox model.
</p>
<p>The simulation algorithm used is <em>Ogata's modified thinning</em>.
For details, see Höhle (2009), Section 4.
</p>


<h3>Value</h3>

<p>An object of class <code>"simEpidata"</code>, which is a <code>data.frame</code> with the
columns <code>"id"</code>, <code>"start"</code>, <code>"stop"</code>, <code>"atRiskY"</code>,
<code>"event"</code>, <code>"Revent"</code> and the coordinate columns (with the original
names from <code>data</code>), which are all obligatory.  These columns are followed
by all the variables appearing on the rhs of the <code>formula</code>.  Last but not
least, the generated columns with epidemic covariates corresponding to the
functions in the lists <code>f</code> and <code>w</code> are appended.
</p>
<p>Note that objects of class <code>"simEpidata"</code> also inherit from class
<code>"<a href="#topic+epidata">epidata</a>"</code>, thus all <code>"<a href="#topic+epidata">epidata</a>"</code> methods can be
applied.
</p>
<p>The <code>data.frame</code> is given the additional <em>attributes</em>
</p>
<table>
<tr><td><code>"eventTimes"</code></td>
<td>

<p>numeric vector of infection time points (sorted chronologically).
</p>
</td></tr>
<tr><td><code>"timeRange"</code></td>
<td>

<p>numeric vector of length 2: <code>c(min(start), max(stop))</code>.
</p>
</td></tr>
<tr><td><code>"coords.cols"</code></td>
<td>

<p>numeric vector containing the column indices of the coordinate columns in
the resulting data-frame.
</p>
</td></tr>
<tr><td><code>"f"</code></td>
<td>

<p>this equals the argument <code>f</code>.
</p>
</td></tr>
<tr><td><code>"w"</code></td>
<td>

<p>this equals the argument <code>w</code>.
</p>
</td></tr>
<tr><td><code>"config"</code></td>
<td>

<p>a list with elements <code>h0 = h0$exact</code>, <code>beta</code> and <code>alpha</code>.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the <code>terms</code> object used.</p>
</td></tr>
</table>
<p>If <code>nsim &gt; 1</code> epidemics are simulated by the
<code>simulate</code>-method for fitted <code>"twinSIR"</code> models, these are
returned in a list.
</p>


<h3>Author(s)</h3>

 
<p>Sebastian Meyer and Michael Höhle
</p>


<h3>References</h3>

<p>Höhle, M. (2009),
Additive-Multiplicative Regression Models for Spatio-Temporal
Epidemics, Biometrical Journal, 51(6):961-978.
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+plot.epidata">plot.epidata</a></code> and <code><a href="#topic+animate.epidata">animate.epidata</a></code> methods
for plotting and animating (simulated) epidemic data, respectively.
The <code><a href="#topic+intensityplot.simEpidata">intensityplot.simEpidata</a></code> method for plotting paths of
infection intensities.
</p>
<p>Function <code><a href="#topic+twinSIR">twinSIR</a></code> for fitting spatio-temporal epidemic intensity
models to epidemic data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate a data frame containing a hypothetic population with 100 individuals
set.seed(1234)
n &lt;- 100
pos &lt;- matrix(rnorm(n*2), ncol=2, dimnames=list(NULL, c("x", "y")))
pop &lt;- data.frame(id=1:n, x=pos[,1], y=pos[,2], 
                  gender=sample(0:1, n, replace=TRUE),
                  I0col=c(rep(1,3),rep(0,n-3)), # 3 initially infectious
                  start=rep(0,n), stop=rep(Inf,n))

## Simulate an SIR epidemic in this population
set.seed(123)
infPeriods &lt;- setNames(c(1:3/10, rexp(n-3, rate=1)), 1:n)
epi &lt;- simEpidata(
    cbind(start,stop) ~ cox(gender), data = pop,
    id.col = "id", I0.col = "I0col", coords.cols = c("x","y"),
    beta = c(-2), h0 = -1, alpha = c(B1=0.1), f = list(B1=function(u) u&lt;=1),
    infPeriod = function(ids) infPeriods[ids],
    ##remPeriod = function(ids) rexp(length(ids), rate=0.1), end = 30   # -&gt; SIRS
)

## extract event times by id
head(summary(epi)$byID)

## Plot the numbers of susceptible, infectious and removed individuals
plot(epi)


## load the 1861 Hagelloch measles epidemic
data("hagelloch")
summary(hagelloch)
plot(hagelloch)

## fit a simplistic twinSIR model
fit &lt;- twinSIR(~ household, data = hagelloch)

## simulate a new epidemic from the above model
## with simulation period = observation period, re-using observed infPeriods
sim1 &lt;- simulate(fit, data = hagelloch)
plot(sim1)

## check if we find similar parameters in the simulated epidemic
fitsim1 &lt;- update(fit, data = sim1)
cbind(base = coef(fit), new = coef(fitsim1))


## simulate only 10 days, using random infPeriods ~ Exp(0.1)
sim2 &lt;- simulate(fit, data = hagelloch, seed = 2, end = 10,
    infPeriod = function(ids) rexp(length(ids), rate = 0.1))
plot(sim2)

## simulate from a different model with manually specified parameters
set.seed(321)
simepi &lt;- simEpidata(~ cox(AGE), data = hagelloch,
    beta = c(0.1), h0 = -4, alpha = c(household = 0.05),
    f = list(household = function(u) u == 0),
    infPeriod = function(ids) rexp(length(ids), rate=1/8))
plot(simepi)
intensityplot(simepi)

## see if we correctly estimate the parameters
fitsimepi &lt;- twinSIR(~ cox(AGE) + household, data = simepi)
cbind(true = c(0.05, -4, 0.1), est = coef(fitsimepi), confint(fitsimepi))

</code></pre>

<hr>
<h2 id='twinstim'>
Fit a Two-Component Spatio-Temporal Point Process Model
</h2><span id='topic+twinstim'></span>

<h3>Description</h3>

<p>A <code>twinstim</code> model as described in Meyer et al. (2012) is fitted to
marked spatio-temporal point process data. This constitutes a
regression approach for conditional intensity function modelling.
The implementation is illustrated in Meyer et al. (2017, Section 3),
see <code>vignette("twinstim")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twinstim(endemic, epidemic, siaf, tiaf, qmatrix = data$qmatrix, data,
         subset, t0 = data$stgrid$start[1], T = tail(data$stgrid$stop,1),
         na.action = na.fail, start = NULL, partial = FALSE,
         epilink = "log", control.siaf = list(F = list(), Deriv = list()),
         optim.args = list(), finetune = FALSE,
         model = FALSE, cumCIF = FALSE, cumCIF.pb = interactive(),
         cores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_+3A_endemic">endemic</code></td>
<td>

<p>right-hand side formula for the exponential (Cox-like
multiplicative) endemic component. May contain offsets (to be marked
by the special function <code>offset</code>).  If omitted or <code>~0</code>
there will be no endemic component in the model.  A type-specific
endemic intercept can be requested by including the term
<code>(1|type)</code> in the formula.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_epidemic">epidemic</code></td>
<td>

<p>formula representing the epidemic model for the event-specific
covariates (marks) determining infectivity. Offsets are not
implemented here. If omitted or <code>~0</code> there will be no epidemic
component in the model.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_siaf">siaf</code></td>
<td>

<p>spatial interaction function. Possible specifications are:
</p>

<ul>
<li> <p><code>NULL</code> or missing, corresponding to
<code>siaf.constant()</code>, i.e. spatially homogeneous 
infectivity independent of the distance from the host
</p>
</li>
<li><p> a list as returned by <code><a href="#topic+siaf">siaf</a></code> or, more commonly,
generated by a predefined interaction function such as
<code><a href="#topic+siaf.gaussian">siaf.gaussian</a></code> as in Meyer et al. (2012) or
<code><a href="#topic+siaf.powerlaw">siaf.powerlaw</a></code> as in Meyer and Held (2014).
The latter requires unique event locations, possibly after random
tie-breaking (<code><a href="#topic+untie">untie</a></code>) or imputation of
interval-censored locations.
<code><a href="#topic+siaf.exponential">siaf.exponential</a></code> is a simpler alternative.
</p>
</li>
<li><p> a numeric vector corresponding to the knots of a step
function, i.e. the same as <code><a href="#topic+siaf.step">siaf.step</a>(knots)</code>
</p>
</li></ul>

<p>If you run into &ldquo;false convergence&rdquo; with a non-constant
<code>siaf</code> specification, the numerical accuracy of the cubature
methods is most likely too low (see the <code>control.siaf</code>
argument).
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_tiaf">tiaf</code></td>
<td>

<p>temporal interaction function. Possible specifications are:
</p>

<ul>
<li> <p><code>NULL</code> or missing, corresponding to
<code>tiaf.constant()</code>, i.e. time-constant infectivity
</p>
</li>
<li><p> a list as returned by <code><a href="#topic+tiaf">tiaf</a></code> or by a
predefined interaction function such as
<code><a href="#topic+tiaf.exponential">tiaf.exponential</a></code>
</p>
</li>
<li><p> a numeric vector corresponding to the knots of a step
function, i.e. the same as <code><a href="#topic+tiaf.step">tiaf.step</a>(knots)</code>
</p>
</li></ul>

</td></tr>
<tr><td><code id="twinstim_+3A_qmatrix">qmatrix</code></td>
<td>

<p>square indicator matrix (0/1 or <code>FALSE</code>/<code>TRUE</code>) for
possible transmission between the event types. The matrix will be
internally converted to <code>logical</code>. Defaults to the <code class="reqn">Q</code> matrix
specified in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_data">data</code></td>
<td>

<p>an object of class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_subset">subset</code></td>
<td>

<p>an optional vector evaluating to logical indicating a subset of
<code>data$events</code> to keep. Missing values are
taken as <code>FALSE</code>. The expression is evaluated in the context of the
<code>data$events@data</code> <code>data.frame</code>, i.e. columns of this
<code>data.frame</code> may be referenced directly by name.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_t0">t0</code>, <code id="twinstim_+3A_t">T</code></td>
<td>

<p>events having occurred during (-Inf;t0] are regarded as part of the
prehistory <code class="reqn">H_0</code> of the process. Only events that occurred in the
interval (t0; T] are considered in the likelihood.
The time point <code>t0</code> (<code>T</code>) must
be an element of <code>data$stgrid$start</code> (<code>data$stgrid$stop</code>).
The default time range covers the whole spatio-temporal grid
of endemic covariates.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_na.action">na.action</code></td>
<td>

<p>how to deal with missing values in <code>data$events</code>? Do not use
<code><a href="stats.html#topic+na.pass">na.pass</a></code>. Missing values in the spatio-temporal grid
<code>data$stgrid</code> are not accepted.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_start">start</code></td>
<td>

<p>a named vector of initial values for (a subset of) the parameters.
The names must conform to the conventions of <code>twinstim</code> to be
assigned to the correct model terms. For instance,
<code>"h.(Intercept)"</code> = endemic intercept,
<code>"h.I(start/365)"</code> = coefficient of a linear time
trend in the endemic component, <code>"h.factorB"</code> =
coefficient of the level B of the factor variable <code>factor</code> in
the endemic predictor, <code>"e.(Intercept)"</code> = epidemic intercept,
<code>"e.VAR"</code> = coefficient of the epidemic term <code>VAR</code>,
<code>"e.siaf.2"</code> = second <code>siaf</code> parameter,
<code>"e.tiaf.1"</code> = first <code>tiaf</code> parameter.
Elements which don't match any of the model parameters are ignored.
</p>
<p>Alternatively, <code>start</code> may also be a named list with elements
<code>"endemic"</code> or <code>"h"</code>, <code>"epidemic"</code> or <code>"e"</code>,
<code>"siaf"</code> or <code>"e.siaf"</code>, and <code>"tiaf"</code> or <code>"e.tiaf"</code>,
each of which containing a named numeric vector with the term labels
as names (i.e. without the prefix <code>"h."</code>, <code>"e."</code>, etc).
Thus, <code>start=list(endemic=c("(Intercept)"=-10))</code> is equivalent
to <code>start=c("h.(Intercept)"=-10)</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_partial">partial</code></td>
<td>

<p>logical indicating if a partial likelihood similar to the approach
by Diggle et al. (2010) should be used (default is <code>FALSE</code>).
Note that the partial likelihood implementation is not well tested.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_epilink">epilink</code></td>
<td>

<p>a character string determining the link function to be used for the
<code>epidemic</code> linear predictor of event marks. By default, the
log-link is used. The experimental alternative
<code>epilink = "identity"</code> (for use by <code><a href="#topic+epitest">epitest</a></code>) does
not guarantee the force of infection to be positive. If this leads
to a negative total intensity (endemic + epidemic), the point
process is not well defined (the log-likelihood will be
<code><a href="base.html#topic+NaN">NaN</a></code>).
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_control.siaf">control.siaf</code></td>
<td>

<p>a list with elements <code>"F"</code> and <code>"Deriv"</code>, which are lists
of extra arguments passed to the functions <code>siaf$F</code> and
<code>siaf$Deriv</code>, respectively.<br />
These arguments control the accuracy of the cubature routines from
package <span class="pkg">polyCub</span> involved in non-constant <code>siaf</code>
specifications, e.g., the bandwidth of the midpoint rule
<code>polyCub.midpoint</code>, the number of Gaussian
quadrature points for <code>polyCub.SV</code>, or the relative
tolerance of <code><a href="stats.html#topic+integrate">integrate</a></code> in <code>polyCub.iso</code>.<br />
For instance, <code><a href="#topic+siaf.gaussian">siaf.gaussian</a>(F.adaptive = TRUE)</code> uses the
midpoint-cubature <code>polyCub.midpoint</code> with an
adaptive bandwidth of <code>eps=adapt*sd</code> to numerically integrate the
kernel <code class="reqn">f(\bold{s})</code>, and the default <code>adapt</code> value (0.1)
can be overwritten by setting <code>control.siaf$F$adapt</code>.
However, the default version <code>siaf.gaussian()</code>
as well as <code><a href="#topic+siaf.powerlaw">siaf.powerlaw</a>()</code> and friends use
<code>polyCub.iso</code> and thus accept control arguments for the
standard <code><a href="stats.html#topic+integrate">integrate</a></code> routine (such as <code>rel.tol</code>)
via <code>control.siaf$F</code> and <code>control.siaf$Deriv</code>.<br />
This argument list is ignored in the case
<code>siaf=siaf.constant()</code> (which is the default if <code>siaf</code> is
unspecified).
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_optim.args">optim.args</code></td>
<td>

<p>an argument list passed to <code><a href="stats.html#topic+optim">optim</a></code>, or <code>NULL</code>, in
which case no optimization will be performed
but the necessary functions will be returned in a list (similar to
what is returned if <code>model = TRUE</code>).
</p>
<p>Initial values for the parameters may be given as list element
<code>par</code> in the order <code>(endemic, epidemic, siaf, tiaf)</code>.
If no initial values are provided, crude estimates will be used for
the endemic intercept and the Gaussian kernel, -9 for the epidemic
intercept, and zeroes for the remaining parameters.
Any initial values given in the <code>start</code> argument
take precedence over those in <code>par</code>.
</p>
<p>Note that <code>optim</code> receives the negative log-likelihood for 
minimization (thus, if used, <code>optim.args$control$fnscale</code> should be
positive). The <code>hessian</code> argument defaults to <code>TRUE</code>, and
in the <code>control</code> list, <code>trace</code>ing is enabled with
<code>REPORT=1</code> by default. By setting
<code>optim.args$control$trace = 0</code>, all output from the
optimization routine is suppressed.
</p>
<p>For the <code>partial</code> likelihood, the analytic score function and
the Fisher information are not implemented and the default is to use
robust <code>method="Nelder-Mead"</code> optimization.
</p>
<p>There may be an extra component <code>fixed</code> in the
<code>optim.args</code> list, which determines which parameters should stick
to their initial values. This can be specified by a
logical vector of the same length as the <code>par</code> component, by an
integer vector indexing <code>par</code> or by a character vector following
the <code>twinstim</code> naming conventions. Furthermore, if
<code>isTRUE(fixed)</code>, then all parameters are fixed at their initial
values and no optimization is performed.
</p>
<p>Importantly, the <code>method</code> argument in the <code>optim.args</code>
list may also be <code>"nlminb"</code>, in 
which case the <code><a href="stats.html#topic+nlminb">nlminb</a></code> optimizer is used. This is also the
default for full likelihood inference.
In this case, not only the score function but also the
<em>expected</em> Fisher information can be used during optimization (as
estimated by what Martinussen and Scheike (2006, p. 64) call the
&ldquo;optional variation process&rdquo;, or see Rathbun (1996, equation
(4.7))). In our experience this gives better convergence than
<code>optim</code>'s methods.
For <code>method="nlminb"</code>, the following parameters of the
<code>optim.args$control</code> list may be named like for
<code>optim</code> and are renamed appropriately:
<code>maxit</code> (-&gt; <code>iter.max</code>), <code>REPORT</code> (-&gt; <code>trace</code>,
default: 1), <code>abstol</code> (-&gt; <code>abs.tol</code>), and
<code>reltol</code> (-&gt; <code>rel.tol</code>, default: <code>1e-6</code>).
For <code>nlminb</code>, a logical <code>hessian</code> argument (default:
<code>TRUE</code>) indicates if the negative <em>expected</em> Fisher
information matrix should be used as the Hessian during optimization
(otherwise a numerical approximation is used).
</p>
<p>Similarly, <code>method="nlm"</code> should also work but is not
recommended here.    
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_finetune">finetune</code></td>
<td>

<p>logical indicating if a second maximisation should be performed with
robust Nelder-Mead <code>optim</code> using the resulting
parameters from the first maximisation as starting point. This
argument is only considered if <code>partial = FALSE</code> and the
default is to not conduct a second maximization (in most cases this
does not improve upon the MLE).
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_model">model</code></td>
<td>

<p>logical indicating if the model environment should be kept with the
result, which is required for
<code><a href="#topic+intensityplot.twinstim">intensityplot</a></code>s and
<code><a href="#topic+R0.twinstim">R0</a>(..., trimmed = FALSE)</code>.
Specifically, if <code>model=TRUE</code>, the return value will have the
evaluation environment set as its <code><a href="base.html#topic+environment">environment</a></code>,
and the returned <code>functions</code> element will contain the
log-likelihood function (or partial log-likelihood function, if
<code>partial = TRUE</code>), and optionally the score and the expected
Fisher information functions (not for the partial likelihood, and
only if <code>siaf</code> and <code>tiaf</code> provide the necessary
derivatives).<br />
Note that fitted objects with a model environment might consume
quite a lot of memory since they contain the <code>data</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_cumcif">cumCIF</code></td>
<td>

<p>logical (default: <code>FALSE</code>) indicating whether to
calculate the fitted cumulative ground intensity at event times.
This is the residual process, see <code><a href="#topic+residuals.twinstim">residuals.twinstim</a></code>.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_cumcif.pb">cumCIF.pb</code></td>
<td>

<p>logical indicating if a progress bar should be shown
during the calculation of <code>cumCIF</code>. Defaults to do so in an
interactive <span class="rlang"><b>R</b></span> session, and will be <code>FALSE</code> if <code>cores != 1</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_cores">cores</code></td>
<td>

<p>number of processes to use in parallel operation. By default
<code>twinstim</code> runs in single-CPU mode. Currently, only the
<span class="pkg">multicore</span>-type of parallel computing via forking is
supported, which is not available on Windows, see
<code><a href="parallel.html#topic+mclapply">mclapply</a></code> in package <span class="pkg">parallel</span>.
Note that for a <span class="pkg">memoise</span>d <code><a href="#topic+siaf.step">siaf.step</a></code> kernel,
<code>cores=1</code> is fixed internally since parallelization would slow
down model fitting significantly.
</p>
</td></tr>
<tr><td><code id="twinstim_+3A_verbose">verbose</code></td>
<td>

<p>logical indicating if information should be printed during
execution. Defaults to <code>TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs maximum likelihood inference
for the additive-multiplicative spatio-temporal intensity model
described in Meyer et al. (2012). It uses <code><a href="stats.html#topic+nlminb">nlminb</a></code> as the
default optimizer and returns an object of class <code>"twinstim"</code>.
Such objects have <code>print</code>, <code><a href="#topic+plot.twinstim">plot</a></code> and
<code><a href="#topic+summary.twinstim">summary</a></code> methods.
The <code>summary</code> output can be converted via corresponding
<code><a href="#topic+xtable.summary.twinstim">xtable</a></code> or
<code><a href="#topic+toLatex.summary.twinstim">toLatex</a></code> methods.
Furthermore, the usual accessor methods are implemented, including
<code>coef</code>, <code>vcov</code>, <code>logLik</code>,
<code><a href="#topic+residuals.twinstim">residuals</a></code>, and
<code>update</code>.
Additional functionality is provided by the <code><a href="#topic+R0">R0</a></code> and
<code><a href="#topic+simulate.twinstim">simulate</a></code> methods.
</p>


<h3>Value</h3>

<p>Returns an S3 object of class <code>"twinstim"</code>, which is a list with
the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>vector containing the MLE.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>value of the log-likelihood function at the MLE with a
logical attribute <code>"partial"</code> indicating if the partial
likelihood was used.</p>
</td></tr>
<tr><td><code>counts</code></td>
<td>
<p>number of log-likelihood and score evaluations during
optimization.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>either <code>TRUE</code> (if the optimizer converged) or a
character string containing a failure message.</p>
</td></tr>
<tr><td><code>fisherinfo</code></td>
<td>
<p><em>expected</em> Fisher information evaluated at the
MLE. Only non-<code>NULL</code> for full likelihood inference
(<code>partial = FALSE</code>) and if spatial and temporal interaction
functions are provided with their derivatives.</p>
</td></tr>
<tr><td><code>fisherinfo.observed</code></td>
<td>
<p>observed Fisher information matrix
evaluated at the value of the MLE. Obtained as the negative Hessian.
Only non-<code>NULL</code> if <code>optim.args$method</code> is not
<code>"nlminb"</code> and if it was requested by setting
<code>hessian=TRUE</code> in <code>optim.args</code>.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>fitted values of the conditional intensity function at the events.</p>
</td></tr>
<tr><td><code>fittedComponents</code></td>
<td>
<p>two-column matrix with columns <code>"h"</code> and
<code>"e"</code> containing the fitted values of the endemic and epidemic
components, respectively.<br />
(Note that <code>rowSums(fittedComponents) == fitted</code>.)</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>fitted cumulative ground intensities at the event times.
Only non-<code>NULL</code> if <code>cumCIF = TRUE</code>.
This is the &ldquo;residual process&rdquo; of the model, see
<code><a href="#topic+residuals.twinstim">residuals.twinstim</a></code>.</p>
</td></tr>
<tr><td><code>R0</code></td>
<td>
<p>estimated basic reproduction number for each event. This
equals the spatio-temporal integral of the epidemic intensity over
the observation domain (t0;T] x W for each event.</p>
</td></tr>
<tr><td><code>npars</code></td>
<td>
<p>vector describing the lengths of the 5 parameter
subvectors: endemic intercept(s) <code class="reqn">\beta_0(\kappa)</code>, endemic
coefficients <code class="reqn">\beta</code>, epidemic coefficients <code class="reqn">\gamma</code>,
parameters of the <code>siaf</code> kernel, and parameters of the
<code>tiaf</code> kernel.</p>
</td></tr>
<tr><td><code>qmatrix</code></td>
<td>
<p>the <code>qmatrix</code> associated with the epidemic
<code>data</code> as supplied in the model call.</p>
</td></tr>
<tr><td><code>bbox</code></td>
<td>
<p>the bounding box of <code>data$W</code>.</p>
</td></tr>
<tr><td><code>timeRange</code></td>
<td>
<p>the time range used for fitting: <code>c(t0,T)</code>.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>a list containing the four main parts of the model
specification: <code>endemic</code>, <code>epidemic</code>, <code>siaf</code>, and
<code>tiaf</code>.</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>a record of the levels of the factors used in fitting.</p>
</td></tr>
<tr><td><code>control.siaf</code></td>
<td>
<p>see the &ldquo;Arguments&rdquo; section above.</p>
</td></tr>
<tr><td><code>optim.args</code></td>
<td>
<p>input optimizer arguments used to determine the MLE.</p>
</td></tr>
<tr><td><code>functions</code></td>
<td>
<p>if <code>model=TRUE</code> this is a <code>list</code> with
components <code>ll</code>, <code>sc</code> and <code>fi</code>, which are functions
evaluating the log-likelihood, the score function and the expected
Fisher information for a parameter vector <code class="reqn">\theta</code>. The
<code>environment</code> of these function is the model environment, which
is thus retained in the workspace if <code>model=TRUE</code>. Otherwise,
the <code>functions</code> component is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>
<p>the <code><a href="base.html#topic+proc.time">proc.time</a></code>-queried time taken
to fit the model, i.e., a named numeric vector of length 5 of class
<code>"proc_time"</code>, with the number of <code>cores</code> set as
additional attribute.</p>
</td></tr>
</table>
<p>If <code>model=TRUE</code>, the model evaluation environment is assigned to
this list and can thus be queried by calling <code>environment()</code> on
the result.
</p>


<h3>Note</h3>

<p><code>twinstim</code> makes use of the <span class="pkg">memoise</span> package if it is
available &ndash; and that is highly recommended for non-constant
<code>siaf</code> specifications to speed up calculations. Specifically, the
necessary numerical integrations of the spatial interaction function
will be cached such that they are only calculated once for every
state of the <code>siaf</code> parameters during optimization.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>
<p>Contributions to this documentation by
Michael Höhle and Mayeul Kauffmann.
</p>


<h3>References</h3>

<p>Diggle, P. J., Kaimi, I. &amp; Abellana, R. (2010):
Partial-likelihood analysis of spatio-temporal point-process data.
<em>Biometrics</em>, <b>66</b>, 347-354.
</p>
<p>Martinussen, T. and Scheike, T. H. (2006):
Dynamic Regression Models for Survival Data.
Springer.
</p>
<p>Meyer, S. (2010):
Spatio-Temporal Infectious Disease Epidemiology based on Point Processes.
Master's Thesis, Ludwig-Maximilians-Universität
München.<br />
Available as <a href="https://epub.ub.uni-muenchen.de/11703/">https://epub.ub.uni-muenchen.de/11703/</a>
</p>
<p>Meyer, S., Elias, J. and Höhle, M. (2012):
A space-time conditional intensity model for invasive meningococcal
disease occurrence. <em>Biometrics</em>, <b>68</b>, 607-616.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01684.x">doi:10.1111/j.1541-0420.2011.01684.x</a>
</p>
<p>Meyer, S. and Held, L. (2014):
Power-law models for infectious disease spread.
<em>The Annals of Applied Statistics</em>, <b>8</b> (3), 1612-1639.
<a href="https://doi.org/10.1214/14-AOAS743">doi:10.1214/14-AOAS743</a>
</p>
<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>
<p>Rathbun, S. L. (1996):
Asymptotic properties of the maximum likelihood estimator for
spatio-temporal point processes.
<em>Journal of Statistical Planning and Inference</em>, <b>51</b>, 55-74.
</p>


<h3>See Also</h3>

<p><code>vignette("twinstim")</code>.
</p>
<p>There is a <code><a href="#topic+simulate.twinstim">simulate.twinstim</a></code> method,
which simulates the point process based on the fitted <code>twinstim</code>.
</p>
<p>A discrete-space alternative is offered by the <code><a href="#topic+twinSIR">twinSIR</a></code>
modelling framework.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load invasive meningococcal disease data
data("imdepi")


### first, fit a simple endemic-only model

m_noepi &lt;- twinstim(
    endemic = addSeason2formula(~ offset(log(popdensity)) + I(start/365-3.5),
                                S=1, period=365, timevar="start"),
    data = imdepi, subset = !is.na(agegrp)
)

## look at the model summary
summary(m_noepi)

## there is no evidence for a type-dependent endemic intercept (LR test)
m_noepi_type &lt;- update(m_noepi, endemic = ~(1|type) + .)
pchisq(2*c(logLik(m_noepi_type)-logLik(m_noepi)), df=1, lower.tail=FALSE)


### add an epidemic component with just the intercept, i.e.
### assuming uniform dispersal in time and space up to a distance of
### eps.s = 200 km and eps.t = 30 days (see summary(imdepi))

m0 &lt;- update(m_noepi, epidemic=~1, model=TRUE)

## summarize the model fit
summary(m0, correlation = TRUE, symbolic.cor = TRUE)

## the default confint-method can be used for Wald-CI's
confint(m0, level=0.95)

## same "untrimmed" R0 for every event (simple epidemic intercept model)
summary(R0(m0, trimmed=FALSE))

## plot the path of the fitted total intensity
plot(m0, "total intensity", tgrid=500)


## extract "residual process" integrating over space (takes some seconds)
res &lt;- residuals(m0)
# if the model describes the true CIF well _in the temporal dimension_,
# then this residual process should behave like a stationary Poisson
# process with intensity 1
plot(res, type="l"); abline(h=c(0, length(res)), lty=2)
# easier, with CI and serial correlation -&gt; checkResidualProcess()
checkResidualProcess(m0)


## Not run: 
  ## NB: in contrast to nlminb(), optim's BFGS would miss the
  ##     likelihood maximum wrt the epidemic intercept
  m0_BFGS &lt;- update(m_noepi, epidemic=~1, optim.args = list(method="BFGS"))
  format(cbind(nlminb=coef(m0), BFGS=coef(m0_BFGS)), digits=3, scientific=FALSE)
  m0_BFGS$fisherinfo   # singular Fisher information matrix here
  m0$fisherinfo
  logLik(m0_BFGS)
  logLik(m0)
  ## nlminb is more powerful since we make use of the analytical fisherinfo
  ## as estimated by the model during optimization, which optim cannot

## End(Not run)


### an epidemic-only model?
## for a purely epidemic model, all events must have potential source events
## (otherwise the intensity at the observed event would be 0)

## let's focus on the C-type for this example
imdepiC &lt;- subset(imdepi, type == "C")
table(summary(imdepiC)$nSources)
## 106 events have no prior, close events (in terms of eps.s and eps.t)
try(twinstim(epidemic = ~1, data = imdepiC))  # detects this problem
## let's assume spatially unbounded interaction
imdepiC_infeps &lt;- update(imdepiC, eps.s = Inf)
(s &lt;- summary(imdepiC_infeps))
table(s$nSources)
## for 11 events, there is no prior event within eps.t = 30 days
## (which is certainly true for the first event)
plot(s$counter, main = "Number of infectious individuals over time (eps.t = 30)")
rug(imdepiC_infeps$events$time)
rug(imdepiC_infeps$events$time[s$nSources == 0], col = 2, lwd = 3)
## An endemic component would catch such events (from unobserved sources),
## otherwise a longer infectious period would need to be assumed and
## for the first event to happen, a prehistory is required (e.g., t0 = 31).
## As an example, we fit the data only until T = 638 (all events have ancestors)
m_epi &lt;- twinstim(epidemic = ~1, data = imdepiC_infeps, t0 = 31, T = 638)
summary(m_epi)


### full model with interaction functions (time-consuming)
## estimate an exponential temporal decay of infectivity
m1_tiaf &lt;- update(m0, tiaf=tiaf.exponential())
plot(m1_tiaf, "tiaf", scaled=FALSE)

## estimate a step function for spatial interaction
summary(sourceDists &lt;- getSourceDists(imdepi, "space"))
(knots &lt;- quantile(sourceDists, c(5,10,20,40)/100))
m1_fstep &lt;- update(m0, siaf=knots)
plot(m1_fstep, "siaf", scaled=FALSE)
rug(sourceDists, ticksize=0.02)

## estimate a continuously decreasing spatial interaction function,
## here we use the kernel of an isotropic bivariate Gaussian
m1 &lt;- update(m0, siaf = siaf.gaussian())
AIC(m_noepi, m0, m1_fstep, m1)
summary(m1)  # e.siaf.1 is log(sigma), no test for H0: log(sigma) = 0
exp(confint(m1, "e.siaf.1"))  # a confidence interval for sigma
plot(m1, "siaf", scaled=FALSE)
## alternative: siaf.powerlaw() with eps.s=Inf and untie()d data,
##              see vignette("twinstim")

## add epidemic covariates
m2 &lt;- update(m1, epidemic = ~ 1 + type + agegrp)
AIC(m1, m2)   # further improvement
summary(m2)
  
## look at estimated R0 values by event type
tapply(R0(m2), imdepi$events@data[names(R0(m2)), "type"], summary)

</code></pre>

<hr>
<h2 id='twinstim_epitest'>Permutation Test for Space-Time Interaction in <code>"twinstim"</code></h2><span id='topic+epitest'></span><span id='topic+coef.epitest'></span><span id='topic+plot.epitest'></span>

<h3>Description</h3>

<p>The function <code>epitest</code> takes a <code>"twinstim"</code> model
and tests if the spatio-temporal interaction invoked by the epidemic
model component is statistically significant.
The test only works for simple epidemic models, where <code>epidemic = ~1</code>
(no additional parameters for event-specific infectivity),
and requires the non-canonical <code>epilink="identity"</code> (see
<code><a href="#topic+twinstim">twinstim</a></code>).
A permutation test is performed by default, which is only valid if the
endemic intensity is space-time separable.
The approach is described in detail in Meyer et al. (2016),
where it is also compared to alternative global tests for clustering
such as the <code><a href="#topic+knox">knox</a></code> test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epitest(model, data, tiles, method = "time", B = 199,
        eps.s = NULL, eps.t = NULL, fixed = NULL,
        verbose = TRUE, compress = FALSE, ...)

## S3 method for class 'epitest'
coef(object, which = c("m1", "m0"), ...)
## S3 method for class 'epitest'
plot(x, teststat = c("simpleR0", "D"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_epitest_+3A_model">model</code></td>
<td>

<p>a simple epidemic <code>"<a href="#topic+twinstim">twinstim</a>"</code> with <code>epidemic = ~1</code>,
fitted using the non-canonical <code>epilink="identity"</code>.
Note that the permutation test is only valid for models with
a space-time separable endemic intensity, where covariates vary
either in space or time but not both.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_data">data</code></td>
<td>

<p>an object of class <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>, the <code>data</code> to
which the <code>model</code> was fitted.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_tiles">tiles</code></td>
<td>

<p>(only used by <code>method = "simulate"</code>)
a <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code> representation of the
<code>tile</code>s in <code>data$stgrid</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_method">method</code></td>
<td>

<p>one of the following character strings specifying the test method:
</p>

<dl>
<dt><code>"LRT"</code>:</dt><dd>
<p>a simple likelihood ratio test of the epidemic
<code>model</code> against the corresponding endemic-only model,
</p>
</dd>
<dt><code>"time"</code>/<code>"space"</code>:</dt><dd>
<p>a Monte Carlo permutation test where the null distribution is
obtained by relabeling time points or locations, respectively
(using <code><a href="#topic+permute.epidataCS">permute.epidataCS</a></code>).
</p>
</dd>
<dt><code>"simulate"</code>:</dt><dd>
<p>obtain the null distribution of the test statistic by
simulations from the endemic-only model
(using <code><a href="#topic+simEndemicEvents">simEndemicEvents</a></code>).
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="twinstim_epitest_+3A_b">B</code></td>
<td>

<p>the number of permutations for the Monte Carlo approach.
The default number is rather low; if computationally feasible,
<code>B = 999</code> is more appropriate. Note that this determines the
&ldquo;resolution&rdquo; of the p-value: the smallest attainable p-value
is <code>1/(B+1)</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_eps.s">eps.s</code>, <code id="twinstim_epitest_+3A_eps.t">eps.t</code></td>
<td>
<p>arguments for <code><a href="#topic+simpleR0">simpleR0</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_fixed">fixed</code></td>
<td>

<p>optional character vector naming parameters to fix at their original
value when re-fitting the <code>model</code> on permuted data.
The special value <code>fixed = TRUE</code> means to fix all epidemic
parameters but the intercept.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_verbose">verbose</code></td>
<td>

<p>the amount of tracing in the range <code>0:3</code>.
Set to 0 (or <code>FALSE</code>) for no output,
1 (or <code>TRUE</code>, the default) for a progress bar,
2 for the test statistics resulting from each permutation,
and to 3 for additional tracing of the log-likelihood
maximization in each permutation (not useful if parallelized).
Tracing does not work if permutations are parallelized using clusters.
See <code><a href="#topic+plapply">plapply</a></code> for other choices.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_compress">compress</code></td>
<td>

<p>logical indicating if the <code>nobs</code>-dependent elements <code>"fitted"</code>,
<code>"fittedComponents"</code>, and <code>"R0"</code> should be dropped from
the permutation-based model fits. Not keeping these elements saves a
lot of memory especially with a large number of events.
Note, however, that the returned <code>permfits</code> then no longer are
fully valid <code>"twinstim"</code> objects (but most methods will still work).
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_...">...</code></td>
<td>
<p>further arguments for <code><a href="#topic+plapply">plapply</a></code> to configure
parallel operation, i.e., <code>.parallel</code> as well as
<code>.seed</code> to make the results reproducible.<br />
For the <code>plot</code>-method, further arguments passed to
<code><a href="MASS.html#topic+truehist">truehist</a></code>.<br />
Ignored by the <code>coef</code>-method.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_object">object</code>, <code id="twinstim_epitest_+3A_x">x</code></td>
<td>

<p>an object of class <code>"epitest"</code> as returned by <code>epitest</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_which">which</code></td>
<td>

<p>a character string indicating either the full (<code>"m1"</code>, default)
or the endemic-only (<code>"m0"</code>) model.
</p>
</td></tr>
<tr><td><code id="twinstim_epitest_+3A_teststat">teststat</code></td>
<td>

<p>a character string determining the test statistic to plot, either
<code>"<a href="#topic+simpleR0">simpleR0</a>"</code> or <code>"D"</code> (twice the log-likelihood
difference of the models).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This space-time interaction test is limited to models with
<code>epidemic = ~1</code>, since covariate effects are not identifiable
under the null hypothesis of no space-time interaction.
Estimating a rich epidemic <code>model</code> based on permuted data
will most likely result in singular convergence.
A similar issue might arise when the model employs parametric
interaction functions, in which case <code>fixed=TRUE</code> can be used.
For further details see Meyer et al. (2016).
</p>
<p>The test statistic is the reproduction number <code><a href="#topic+simpleR0">simpleR0</a></code>.
A likelihood ratio test of the supplied epidemic model against
the corresponding endemic-only model is also available.
By default, the null distribution of the test statistic under no
space-time interaction is obtained by a Monte Carlo permutation
approach (via <code><a href="#topic+permute.epidataCS">permute.epidataCS</a></code>) and therefore relies on
a space-time separable endemic model component.
</p>
<p>The <code>plot</code>-method shows a <code><a href="MASS.html#topic+truehist">truehist</a></code> of
the simulated null distribution together with the observed value.
The <code>coef</code>-method extracts the parameter estimates from the <code>B</code>
<code>permfits</code> (by default for the full model <code>which = "m1"</code>).
</p>


<h3>Value</h3>

<p>a list (inheriting from <code>"htest"</code>) with the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the type of test performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the supplied <code>data</code> and
<code>model</code> arguments.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>the observed test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the (effective) number of permutations used to
calculate the p-value (only those with convergent fits are used).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test. For the <code>method</code>s
involving resampling under the null (<code>method != "LRT"</code>),
it is based on the subset of convergent fits only and the p-value
from the simple LRT is attached as an attribute <code>"LRT"</code>.</p>
</td></tr>
</table>
<p>In addition, if <code>method != "LRT"</code>, the result will have the
following elements:
</p>
<table>
<tr><td><code>permfits</code></td>
<td>
<p>the list of model fits (endemic-only and epidemic)
from the <code>B</code> permutations.</p>
</td></tr>
<tr><td><code>permstats</code></td>
<td>
<p>a data frame with <code>B</code> rows and the columns
<code>"l0"</code> (log-likelihood of the endemic-only model <code>m0</code>),
<code>"l1"</code> (log-likelihood of the epidemic model <code>m1</code>),
<code>"D"</code> (twice their difference),
<code>"simpleR0"</code> (the results of <code><a href="#topic+simpleR0">simpleR0</a>(m1, eps.s, eps.t)</code>), 
and <code>"converged"</code> (a boolean indicator if both models converged).</p>
</td></tr>
</table>
<p>The <code>plot</code>-method invisibly returns <code>NULL</code>.
The <code>coef</code>-method returns the <code>B</code> x <code>length(coef(model))</code>
matrix of parameter estimates.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Meyer, S., Warnke, I., Rössler, W. and Held, L. (2016):
Model-based testing for space-time interaction using point processes:
An application to psychiatric hospital admissions in an urban area.
<em>Spatial and Spatio-temporal Epidemiology</em>, <b>17</b>, 15-25.
<a href="https://doi.org/10.1016/j.sste.2016.03.002">doi:10.1016/j.sste.2016.03.002</a>.
Eprint: <a href="https://arxiv.org/abs/1512.09052">https://arxiv.org/abs/1512.09052</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+permute.epidataCS">permute.epidataCS</a></code>, <code><a href="#topic+knox">knox</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi", "imdepifit")

## test for space-time interaction of the B-cases
## assuming spatial interaction to be constant within 50 km
imdepiB50 &lt;- update(subset(imdepi, type == "B"), eps.s = 50)
imdfitB50 &lt;- update(imdepifit, data = imdepiB50, subset = NULL,
                    epidemic = ~1, epilink = "identity", siaf = NULL,
                    start = c("e.(Intercept)" = 0))

## simple likelihood ratio test
epitest(imdfitB50, imdepiB50, method = "LRT")

## permutation test
et &lt;- epitest(imdfitB50, imdepiB50,
              B = 5,        # CAVE: limited here for speed
              verbose = 2,  # (tracing does not work on Windows
              .seed = 1, .parallel = 1)       # if parallelized)
et
plot(et)

## summary of parameter estimates under permutation
summary(coef(et, which = "m1"))
</code></pre>

<hr>
<h2 id='twinstim_iaf'>
Temporal and Spatial Interaction Functions for <code>twinstim</code>
</h2><span id='topic+siaf.constant'></span><span id='topic+siaf.step'></span><span id='topic+siaf.gaussian'></span><span id='topic+siaf.exponential'></span><span id='topic+siaf.powerlaw'></span><span id='topic+siaf.powerlaw1'></span><span id='topic+siaf.powerlawL'></span><span id='topic+siaf.student'></span><span id='topic+tiaf.constant'></span><span id='topic+tiaf.step'></span><span id='topic+tiaf.exponential'></span>

<h3>Description</h3>

<p>A <code>twinstim</code> model as described in Meyer et al. (2012) requires
the specification of the spatial and temporal interaction functions
(<code class="reqn">f</code> and <code class="reqn">g</code>, respectively), 
i.e. how infectivity decays with increasing spatial and temporal
distance from the source of infection.
Own such functions can be specified (see
<code><a href="#topic+siaf">siaf</a></code> and <code><a href="#topic+tiaf">tiaf</a></code>, respectively), but the
package already predefines some common dispersal kernels returned by
the constructor functions documented here.
See Meyer and Held (2014) for various spatial interaction functions,
and Meyer et al. (2017, Section 3, available as <code>vignette("twinstim")</code>)
for an illustration of the implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'># predefined spatial interaction functions
siaf.constant()
siaf.step(knots, maxRange = Inf, nTypes = 1, validpars = NULL)
siaf.gaussian(nTypes = 1, logsd = TRUE, density = FALSE,
              F.adaptive = FALSE, F.method = "iso",
              effRangeMult = 6, validpars = NULL)
siaf.exponential(nTypes = 1, validpars = NULL, engine = "C")
siaf.powerlaw(nTypes = 1, validpars = NULL, engine = "C")
siaf.powerlaw1(nTypes = 1, validpars = NULL, sigma = 1)
siaf.powerlawL(nTypes = 1, validpars = NULL, engine = "C")
siaf.student(nTypes = 1, validpars = NULL, engine = "C")

# predefined temporal interaction functions
tiaf.constant()
tiaf.step(knots, maxRange = Inf, nTypes = 1, validpars = NULL)
tiaf.exponential(nTypes = 1, validpars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_iaf_+3A_knots">knots</code></td>
<td>
<p>numeric vector of distances at which the step function
switches to a new height. The length of this vector determines the
number of parameters to estimate. For identifiability, the step
function has height 1 in the first interval <code class="reqn">[0,knots_1)</code>. Note
that the implementation is right-continuous, i.e., intervals are
<code class="reqn">[a,b)</code>.<br />
An initial choice of knots could be based on quantiles of the
observed distances between events and their potential source events.
For instance, an identifiable spatial step function could be
<code>siaf.step(quantile(<a href="#topic+getSourceDists">getSourceDists</a>(myepi, "space"), c(1,2,4)/10))</code>,
where <code>myepi</code> is the <code>"epidataCS"</code> data to be modelled.</p>
</td></tr>
<tr><td><code id="twinstim_iaf_+3A_maxrange">maxRange</code></td>
<td>
<p>a scalar larger than any of <code>knots</code>.
Per default (<code>maxRange=Inf</code>), the step function
never drops to 0 but keeps the last height for any distance larger
than the last knot. However, this might not work in some cases,
where the last parameter value would become very small and lead to
numerical problems. It is then possible to truncate
interaction at a distance <code>maxRange</code> (just like what the
variables <code>eps.s</code> and <code>eps.t</code> do in the
<code>"<a href="#topic+epidataCS">epidataCS</a>"</code> object).</p>
</td></tr>
<tr><td><code id="twinstim_iaf_+3A_ntypes">nTypes</code></td>
<td>

<p>determines the number of parameters ((log-)scales or (log-)shapes)
of the kernels. In a multitype epidemic, the different types may
share the same spatial interaction function, in which case
<code>nTypes=1</code>. Otherwise <code>nTypes</code> should equal the number of
event types of the epidemic, in which case every type has its own
(log-)scale or (log-)shape, respectively.<br />
Currently, <code>nTypes &gt; 1</code> is only implemented for
<code>siaf.gaussian(F.adaptive = TRUE)</code>,
<code>tiaf.step</code>, and <code>tiaf.exponential</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_iaf_+3A_logsd">logsd</code>, <code id="twinstim_iaf_+3A_density">density</code></td>
<td>

<p>logicals affecting the parametrization of the Gaussian kernel.
Settings different from the defaults are deprecated.
The default is to use only the kernel of the bivariate, isotropic
normal distribution (<code>density=FALSE</code>, see Details below),
parametrized with the log-standard deviation (<code>logsd=TRUE</code>) to
avoid constrained optimisation (L-BFGS-B) or <code>validpars</code>.<br />
The power-law kernels always employ the log-scale for their scale
and shape parameters.
</p>
</td></tr>
<tr><td><code id="twinstim_iaf_+3A_f.adaptive">F.adaptive</code>, <code id="twinstim_iaf_+3A_f.method">F.method</code></td>
<td>

<p>If <code>F.adaptive = TRUE</code>, then an adaptive bandwidth of
<code>adapt*sd</code> will be used in the midpoint-cubature
(<code><a href="polyCub.html#topic+polyCub.midpoint">polyCub.midpoint</a></code> in package <span class="pkg">polyCub</span>)
of the Gaussian interaction
kernel, where <code>adapt</code> is an extra parameter of the returned
<code>siaf$F</code> function and defaults to 0.1. It can be customized
either by the <code>control.siaf$F</code> argument list of
<code>twinstim</code>, or by a numeric specification of <code>F.adaptive</code>
in the constructing call, e.g., <code>F.adaptive = 0.05</code> to achieve
higher accuracy.<br />
Otherwise, if <code>F.adaptive = FALSE</code>, the <code>F.method</code>
argument determines which <code><a href="polyCub.html#topic+polyCub">polyCub</a></code> method to
use in <code>siaf$F</code>. The accuracy (controlled via, e.g.,
<code>nGQ</code>, <code>rel.tol</code>, or <code>eps</code>, depending on the cubature
method) can then be adjusted in <code>twinstim</code>'s
<code>control.siaf$F</code> argument.
</p>
</td></tr>
<tr><td><code id="twinstim_iaf_+3A_effrangemult">effRangeMult</code></td>
<td>

<p>determines the effective range for numerical integration
in terms of multiples of the standard deviation <code class="reqn">\sigma</code> of the
Gaussian kernel, i.e. with <code>effRangeMult=6</code>
the <code class="reqn">6 \sigma</code> region around the event is considered as
the relevant integration domain instead
of the whole observation region <code>W</code>.
Setting <code>effRangeMult=NULL</code> will disable
the integral approximation with an effective integration range.
</p>
</td></tr>
<tr><td><code id="twinstim_iaf_+3A_validpars">validpars</code></td>
<td>

<p>function taking one argument, the parameter vector, indicating if it
is valid (see also <code><a href="#topic+siaf">siaf</a></code>).
If <code>logsd=FALSE</code> and one prefers not to use
<code>method="L-BFGS-B"</code> for fitting the <code>twinstim</code>, then
<code>validpars</code> could be set to <code>function (pars) pars &gt; 0</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_iaf_+3A_engine">engine</code></td>
<td>

<p>character string specifying the implementation to use.
Prior to <span class="pkg">surveillance</span> 0.14.0, the <code>intrfr</code> functions for
<code>polyCub.iso</code> were evaluated in <span class="rlang"><b>R</b></span> (and this
implementation is available via <code>engine = "R"</code>).
The new C-implementation, &lsquo;<span class="samp">&#8288;LinkingTo&#8288;</span>&rsquo; the newly exported
<code>polyCub_iso</code> C-implementation in <span class="pkg">polyCub</span> 0.6.0,
is considerably faster.
</p>
</td></tr>
<tr><td><code id="twinstim_iaf_+3A_sigma">sigma</code></td>
<td>

<p>Fixed value of <code class="reqn">\sigma</code> for the one-parameter power-law kernel.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Evaluation of <code>twinstim</code>'s likelihood involves cubature of the
spatial interaction function over polygonal domains. Various
approaches have been compared by Meyer (2010, Section 3.2) and a new
efficient method, which takes advantage of the assumed isotropy, has
been proposed by Meyer and Held (2014, Supplement B, Section 2) for
evaluation of the power-law kernels.
These cubature methods are available in the dedicated <span class="rlang"><b>R</b></span> package
<span class="pkg">polyCub</span> and used by the kernels implemented in <span class="pkg">surveillance</span>.
</p>
<p>The readily available spatial interaction functions are defined as
follows:
</p>

<dl>
<dt><code>siaf.constant</code>:</dt><dd>
<p><code class="reqn">f(s) = 1</code>
</p>
</dd>
<dt><code>siaf.step</code>:</dt><dd>
<p><code class="reqn">f(s) = \sum_{k=0}^K \exp(\alpha_k) I_k(||s||)</code>,<br />
where <code class="reqn">\alpha_0 = 0</code>, and <code class="reqn">\alpha_1, \dots, \alpha_K</code> are
the parameters (heights) to estimate. <code class="reqn">I_k(||s||)</code> indicates
if distance <code class="reqn">||s||</code> belongs to the <code class="reqn">k</code>th interval
according to <code>c(0,knots,maxRange)</code>, where <code class="reqn">k=0</code> indicates
the interval <code>c(0,knots[1])</code>.<br />
Note that <code>siaf.step</code> makes use of the <span class="pkg">memoise</span> package
if it is available &ndash; and that is highly recommended to speed up
calculations. Specifically, the areas of the intersection of a
polygonal domain (influence region) with the &ldquo;rings&rdquo; of the
two-dimensional step function will be cached such that they are
only calculated once for every <code>polydomain</code> (in the first
iteration of the <code>twinstim</code> optimization). They are used in
the integration components <code>F</code> and <code>Deriv</code>.
See Meyer and Held (2014) for a use case and further details.
</p>
</dd>
<dt><code>siaf.gaussian</code>:</dt><dd>
<p><code class="reqn">f(s|\kappa) = \exp(-||s||/2/\sigma_\kappa^2)</code><br />
If <code>nTypes=1</code> (single-type epidemic or type-invariant
<code>siaf</code> in multi-type epidemic), then
<code class="reqn">\sigma_\kappa = \sigma</code> for all types <code class="reqn">\kappa</code>.
If <code>density=TRUE</code> (deprecated), then the kernel formula above is
additionally divided by <code class="reqn">2 \pi \sigma_\kappa^2</code>, yielding the
density of the bivariate, isotropic Gaussian distribution with
zero mean and covariance matrix <code class="reqn">\sigma_\kappa^2 I_2</code>.
The standard deviation is optimized on the log-scale
(<code>logsd = TRUE</code>, not doing so is deprecated).
</p>
</dd>
<dt><code>siaf.exponential</code>:</dt><dd>
<p><code class="reqn">f(s) = exp(-||s||/sigma)</code><br />
The scale parameter <code class="reqn">sigma</code> is estimated on the log-scale,
i.e., <code class="reqn">\sigma = \exp(\tilde{\sigma})</code>, and <code class="reqn">\tilde{\sigma}</code>
is the actual model parameter.
</p>
</dd>
<dt><code>siaf.powerlaw</code>:</dt><dd>
<p><code class="reqn">f(s) = (||s|| + \sigma)^{-d}</code><br />
The parameters are optimized on the log-scale to ensure positivity, i.e.,
<code class="reqn">\sigma = \exp(\tilde{\sigma})</code> and <code class="reqn">d = \exp(\tilde{d})</code>,
where <code class="reqn">(\tilde{\sigma}, \tilde{d})</code> is the parameter vector.
If a power-law kernel is not identifiable for the dataset at hand,
the exponential kernel or a lagged power law are useful alternatives.
</p>
</dd>
<dt><code>siaf.powerlaw1</code>:</dt><dd>
<p><code class="reqn">f(s) = (||s|| + 1)^{-d}</code>,<br />
i.e., <code>siaf.powerlaw</code> with fixed <code class="reqn">\sigma = 1</code>.
A different fixed value for <code class="reqn">sigma</code> can be specified via the
<code>sigma</code> argument of <code>siaf.powerlaw1</code>.
The decay parameter <code class="reqn">d</code> is estimated on the log-scale.
</p>
</dd>
<dt><code>siaf.powerlawL</code>:</dt><dd>
<p><code class="reqn">f(s) = (||s||/\sigma)^{-d}</code>, for <code class="reqn">||s|| \ge \sigma</code>, and
<code class="reqn">f(s) = 1</code> otherwise,<br />
which is a <em>L</em>agged power-law kernel featuring uniform
short-range dispersal (up to distance <code class="reqn">\sigma</code>) and a
power-law decay (Pareto-style) from distance <code class="reqn">\sigma</code> onwards.
The parameters are optimized on the log-scale to ensure positivity, i.e.
<code class="reqn">\sigma = \exp(\tilde{\sigma})</code> and <code class="reqn">d = \exp(\tilde{d})</code>,
where <code class="reqn">(\tilde{\sigma}, \tilde{d})</code> is the parameter vector.
However, there is a caveat associated with this kernel: Its
derivative wrt <code class="reqn">\tilde{\sigma}</code> is mathematically undefined at
the threshold <code class="reqn">||s||=\sigma</code>. This local non-differentiability
makes <code>twinstim</code>'s likelihood maximization sensitive wrt
parameter start values, and is likely to cause false convergence
warnings by <code><a href="stats.html#topic+nlminb">nlminb</a></code>. Possible workarounds are to use
the slow and robust <code>method="Nelder-Mead"</code>, or to just ignore
the warning and verify the result by sets of different start values.
</p>
</dd>
<dt><code>siaf.student</code>:</dt><dd>
<p><code class="reqn">f(s) = (||s||^2 + \sigma^2)^{-d}</code>,<br />
which is a reparametrized <code class="reqn">t</code>-kernel.
For <code class="reqn">d=1</code>, this is the kernel of the Cauchy density with scale
<code>sigma</code>. In Geostatistics, a correlation function of this
kind is known as the Cauchy model.<br />
The parameters are optimized on the log-scale to ensure
positivity, i.e. <code class="reqn">\sigma = \exp(\tilde{\sigma})</code> and
<code class="reqn">d = \exp(\tilde{d})</code>, where <code class="reqn">(\tilde{\sigma}, \tilde{d})</code>
is the parameter vector.
</p>
</dd>
</dl>

<p>The predefined temporal interaction functions are defined as follows:
</p>

<dl>
<dt><code>tiaf.constant</code>:</dt><dd>
<p><code class="reqn">g(t) = 1</code>
</p>
</dd>
<dt><code>tiaf.step</code>:</dt><dd>
<p><code class="reqn">g(t) = \sum_{k=0}^K \exp(\alpha_k) I_k(t)</code>,<br />
where <code class="reqn">\alpha_0 = 0</code>, and <code class="reqn">\alpha_1, \dots, \alpha_K</code> are
the parameters (heights) to estimate. <code class="reqn">I_k(t)</code> indicates
if <code class="reqn">t</code> belongs to the <code class="reqn">k</code>th interval
according to <code>c(0,knots,maxRange)</code>, where <code class="reqn">k=0</code> indicates
the interval <code>c(0,knots[1])</code>.
</p>
</dd>
<dt><code>tiaf.exponential</code>:</dt><dd>
<p><code class="reqn">g(t|\kappa) = \exp(-\alpha_\kappa t)</code>,<br />
which is the kernel of the exponential distribution.
If <code>nTypes=1</code> (single-type epidemic or type-invariant
<code>tiaf</code> in multi-type epidemic), then
<code class="reqn">\alpha_\kappa = \alpha</code> for all types <code class="reqn">\kappa</code>.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>The specification of an interaction function, which is a list.
See <code><a href="#topic+siaf">siaf</a></code> and <code><a href="#topic+tiaf">tiaf</a></code>, respectively, for a
description of its components.  
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Meyer, S. (2010):
Spatio-Temporal Infectious Disease Epidemiology based on Point Processes.
Master's Thesis, Ludwig-Maximilians-Universität
München.<br />
Available as <a href="https://epub.ub.uni-muenchen.de/11703/">https://epub.ub.uni-muenchen.de/11703/</a>
</p>
<p>Meyer, S., Elias, J. and Höhle, M. (2012):
A space-time conditional intensity model for invasive meningococcal
disease occurrence. <em>Biometrics</em>, <b>68</b>, 607-616.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01684.x">doi:10.1111/j.1541-0420.2011.01684.x</a>
</p>
<p>Meyer, S. and Held, L. (2014):
Power-law models for infectious disease spread.
<em>The Annals of Applied Statistics</em>, <b>8</b> (3), 1612-1639.
<a href="https://doi.org/10.1214/14-AOAS743">doi:10.1214/14-AOAS743</a>
</p>
<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+twinstim">twinstim</a></code>, <code><a href="#topic+siaf">siaf</a></code>, <code><a href="#topic+tiaf">tiaf</a></code>,
and package <span class="pkg">polyCub</span> for the involved cubature methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># constant temporal dispersal
tiaf.constant()
# step function kernel
tiaf.step(c(3,7), maxRange=14, nTypes=2)
# exponential temporal decay
tiaf.exponential()

# Type-dependent Gaussian spatial interaction function using an adaptive
# two-dimensional midpoint-rule to integrate it over polygonal domains
siaf.gaussian(2, F.adaptive=TRUE)

# Single-type Gaussian spatial interaction function (using polyCub.iso)
siaf.gaussian()

# Exponential kernel
siaf.exponential()

# Power-law kernel
siaf.powerlaw()

# Power-law kernel with fixed sigma = 1
siaf.powerlaw1()

# "lagged" power-law
siaf.powerlawL()

# (reparametrized) t-kernel
siaf.student()

# step function kernel
siaf.step(c(10,20,50), maxRange=100)
</code></pre>

<hr>
<h2 id='twinstim_iafplot'>
Plot the Spatial or Temporal Interaction Function of a <code>twimstim</code>
</h2><span id='topic+iafplot'></span>

<h3>Description</h3>

<p>The function plots the fitted temporal or (isotropic) spatial
interaction function of a <code>twinstim</code> object.
The implementation is illustrated in Meyer et al. (2017, Section 3),
see <code>vignette("twinstim")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iafplot(object, which = c("siaf", "tiaf"), types = NULL,
        scaled = c("intercept", "standardized", "no"), truncated = FALSE,
        log = "", conf.type = if (length(pars) &gt; 1) "MC" else "parbounds",
        conf.level = 0.95, conf.B = 999, xgrid = 101,
        col.estimate = rainbow(length(types)), col.conf = col.estimate,
        alpha.B = 0.15, lwd = c(3,1), lty = c(1,2),
        verticals = FALSE, do.points = FALSE,
        add = FALSE, xlim = NULL, ylim = NULL, xlab = NULL, ylab = NULL,
        legend = !add &amp;&amp; (length(types) &gt; 1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_iafplot_+3A_object">object</code></td>
<td>

<p>object of class <code>"twinstim"</code> containing the fitted model.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_which">which</code></td>
<td>

<p>argument indicating which of the two interaction functions to plot.
Possible values are <code>"siaf"</code> (default) for the spatial interaction
<code class="reqn">f(x)</code> as a function of the distance <code class="reqn">x</code>, and <code>"tiaf"</code>
for the temporal interaction function <code class="reqn">g(t)</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_types">types</code></td>
<td>

<p>integer vector indicating for which event <code>types</code> 
the interaction function should be plotted in case of a marked
<code>"twinstim"</code>. The default <code>types=NULL</code> checks if the interaction
function is type-specific: if so, <code>types=1:nrow(object$qmatrix)</code>
is used, otherwise <code>types=1</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_scaled">scaled</code></td>
<td>

<p>character string determining if/how the the interaction function
should be scaled. Possible choices are:
</p>

<dl>
<dt>&quot;intercept&quot;:</dt><dd><p>multiplication by the epidemic intercept.</p>
</dd>
<dt>&quot;standardized&quot;:</dt><dd><p>division by the value at 0 distance such
that the function starts at 1.</p>
</dd>
<dt>&quot;no&quot;:</dt><dd><p>no scaling.</p>
</dd>
</dl>

<p>The first one is the default and required for the comparison of
estimated interaction functions from different models.
For backward compatibility, <code>scaled</code> can also be a boolean,
where <code>TRUE</code> refers to <code>"intercept"</code> scaling and
<code>FALSE</code> to <code>"no"</code> scaling.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_truncated">truncated</code></td>
<td>

<p>logical indicating if the plotted interaction function should
take the maximum range of interaction (<code>eps.t</code>/<code>eps.s</code>)
into account, i.e., drop to zero at that point (if it is finite
after all). If there is no common range of interaction, a
<code><a href="graphics.html#topic+rug">rug</a></code> indicating the various ranges will 
be added to the plot if <code>truncated=TRUE</code>.
If <code>truncated</code> is a scalar, this value is used as the point
<code>eps</code> where the function drops to 0.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_log">log</code></td>
<td>
<p>a character string passed to <code><a href="graphics.html#topic+plot.default">plot.default</a></code>
indicating which axes should be logarithmic.
If <code>add=TRUE</code>, <code>log</code> is set according to
<code>par("xlog")</code> and <code>par("ylog")</code>.</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_conf.type">conf.type</code></td>
<td>

<p>type of confidence interval to produce.<br />
If <code>conf.type="MC"</code> (or <code>"bootstrap"</code>), <code>conf.B</code>
parameter vectors are sampled from the asymptotic
(multivariate) normal distribution of the ML estimate of the
interaction function parameters; the interaction function is then
evaluated on the <code>xgrid</code> (i.e. temporal or spatial distances
from the host) for each parameter realization to obtain a
<code>conf.level</code> confidence interval at each point of the
<code>xgrid</code> (or to plot the interaction functions of all
Monte-Carlo samples if <code>conf.level=NA</code>).
Note that the resulting plot is <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>-dependent
for the Monte-Carlo type of confidence interval.<br />
If <code>conf.type="parbounds"</code>, the <code>conf.level</code> Wald confidence
intervals for the interaction function parameters are calculated and
the interaction function is evaluated on the <code>xgrid</code>
(distances from the host) for all combinations of the bounds
of the parameters and the point-wise extremes of those functions are
plotted. This type of confidence interval is only valid in case of
a single parameter, i.e. <code>scaled + nsiafpars == 1</code>, but could
also be used as a rough indication if the Monte-Carlo approach takes
too long. A warning is thrown if the <code>"parbounds"</code> type is used
for multiple parameters.<br /> 
If <code>conf.type="none"</code> or <code>NA</code> or <code>NULL</code>, no
confidence interval will be calculated.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_conf.level">conf.level</code></td>
<td>

<p>the confidence level required. For <code>conf.type = "MC"</code> it
may also be specified as <code>NA</code>, in which case all <code>conf.B</code>
sampled functions will be plotted with transparency value given
by <code>alpha.B</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_conf.b">conf.B</code></td>
<td>

<p>number of samples for the <code>"MC"</code> (Monte Carlo)
confidence interval.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_xgrid">xgrid</code></td>
<td>

<p>either a numeric vector of x-values (distances from the host) where
to evaluate <code>which</code>, or a scalar representing the desired number of
evaluation points in the interval <code>c(0,xlim[2])</code>.<br />
If the interaction function is a step function
(<code><a href="#topic+siaf.step">siaf.step</a></code> or <code><a href="#topic+tiaf.step">tiaf.step</a></code>), <code>xgrid</code>
is ignored and internally set to <code>c(0, knots)</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_col.estimate">col.estimate</code></td>
<td>

<p>vector of colours to use for the function point estimates of the different <code>types</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_col.conf">col.conf</code></td>
<td>

<p>vector of colours to use for the confidence intervals of the different <code>types</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_alpha.b">alpha.B</code></td>
<td>

<p>alpha transparency value (as relative opacity) used for the <code>conf.B</code>
sampled interaction functions in case <code>conf.level = NA</code>
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_lwd">lwd</code>, <code id="twinstim_iafplot_+3A_lty">lty</code></td>
<td>

<p>numeric vectors of length two specifying the line width and type of point
estimates (first element) and confidence limits (second element),
respectively. 
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_verticals">verticals</code>, <code id="twinstim_iafplot_+3A_do.points">do.points</code></td>
<td>
<p>graphical settings for step function
kernels. These can be logical (as in <code><a href="stats.html#topic+plot.stepfun">plot.stepfun</a></code>) or
lists of graphical parameters.</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_add">add</code></td>
<td>

<p>add to an existing plot?
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_xlim">xlim</code>, <code id="twinstim_iafplot_+3A_ylim">ylim</code></td>
<td>

<p>vectors of length two containing the x- and y-axis limit of the
plot. The default y-axis range (<code>ylim=NULL</code>) is from 0 to the
value of the (scaled) interaction function at <code class="reqn">x = 0</code>.
The default x-axis (<code>xlim=NULL</code>) starts at 0, and the upper
limit is determined as follows (in decreasing order of precedence):
</p>

<ul>
<li><p> If <code>xgrid</code> is a vector of evaluation points, <code>xlim[2]</code> is
set to <code>max(xgrid)</code>.
</p>
</li>
<li> <p><code>eps.t</code>/<code>eps.s</code> if it is unique and finite.
</p>
</li>
<li><p> If the interaction function is a step function with
<code>maxRange&lt;Inf</code>, i.e. it drops to 0 at <code>maxRange</code>,
<code>xlim[2]</code> is set to <code>maxRange</code>.
</p>
</li>
<li><p> Otherwise, it is set to the length of the observation period
(<code>which="tiaf"</code>) or the diagonal length of the bounding box of
the observation region (<code>which="siaf"</code>), respectively.
</p>
</li></ul>

</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_xlab">xlab</code>, <code id="twinstim_iafplot_+3A_ylab">ylab</code></td>
<td>

<p>labels for the axes with <code>NULL</code> providing sensible defaults.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_legend">legend</code></td>
<td>

<p>logical indicating if a legend for the <code>types</code> should be added.
It can also be a list of arguments passed to <code><a href="graphics.html#topic+legend">legend</a></code>
to tweak the default settings.
</p>
</td></tr>
<tr><td><code id="twinstim_iafplot_+3A_...">...</code></td>
<td>

<p>additional arguments passed to the default <code>plot</code> method.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot is created &ndash; see e.g. Figure 3(b) in Meyer et al. (2012).
</p>
<p>The function invisibly returns a matrix of the plotted values of the
interaction function (evaluated on <code>xgrid</code>, by type). The first
column of the matrix contains the distance <code class="reqn">x</code>, and the remaining
<code>length(types)</code> columns contain the (scaled) function values for
each type.
</p>
<p>The pointwise confidence intervals of the interaction functions are
returned in similar matrices as attributes: if
<code>length(types)==1</code>, there is a single attribute <code>"CI"</code>,
whereas for multiple types, the attributes are named
<code>paste0("CI.",typeNames)</code> (where the <code>typeNames</code> are
retrieved from <code>object$qmatrix</code>).
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>References</h3>

<p>Meyer, S., Elias, J. and Höhle, M. (2012):
A space-time conditional intensity model for invasive meningococcal
disease occurrence. <em>Biometrics</em>, <b>68</b>, 607-616.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01684.x">doi:10.1111/j.1541-0420.2011.01684.x</a>
</p>
<p>Meyer, S., Held, L. and Höhle, M. (2017):
Spatio-temporal analysis of epidemic phenomena using the <span class="rlang"><b>R</b></span> package
<span class="pkg">surveillance</span>.
<em>Journal of Statistical Software</em>, <b>77</b> (11), 1-55.
<a href="https://doi.org/10.18637/jss.v077.i11">doi:10.18637/jss.v077.i11</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.twinstim">plot.twinstim</a></code>, which calls this function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepifit")

iafplot(imdepifit, "tiaf", scaled=FALSE)   # tiaf.constant(), not very exciting
iafplot(imdepifit, "siaf", scaled=FALSE)

# scaled version uses a Monte-Carlo-CI
set.seed(1)  # result depends on .Random.seed
iafplot(imdepifit, "siaf", scaled=TRUE, conf.type="MC", conf.B=199,
        col.conf=gray(0.4), conf.level=NA)  # show MC samples
</code></pre>

<hr>
<h2 id='twinstim_intensity'>
Plotting Intensities of Infection over Time or Space
</h2><span id='topic+intensityplot.twinstim'></span><span id='topic+intensity.twinstim'></span><span id='topic+intensityplot.simEpidataCS'></span>

<h3>Description</h3>

<p><code><a href="#topic+intensityplot">intensityplot</a></code> method to plot the evolution of the total infection
intensity, its epidemic proportion or its endemic proportion over time
or space (integrated over the other dimension) of fitted
<code><a href="#topic+twinstim">twinstim</a></code> models (or <code><a href="#topic+simEpidataCS">simEpidataCS</a></code>).
The <code>"simEpidataCS"</code>-method is just a wrapper around
<code>intensityplot.twinstim</code> by making the <code>"simEpidataCS"</code> object
<code>"twinstim"</code>-compatible, i.e. enriching it by the
required model components and environment.
</p>
<p>The <code>intensity.twinstim</code> auxiliary function returns functions which
calculate the endemic or epidemic intensity at a specific time point or
location (integrated over the other dimension).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinstim'
intensityplot(x,
    which = c("epidemic proportion", "endemic proportion", "total intensity"),
    aggregate = c("time", "space"), types = 1:nrow(x$qmatrix),
    tiles, tiles.idcol = NULL, plot = TRUE, add = FALSE,
    tgrid = 101, rug.opts = list(),
    sgrid = 128, polygons.args = list(), points.args = list(),
    cex.fun = sqrt, ...)

## S3 method for class 'simEpidataCS'
intensityplot(x, ...)

intensity.twinstim(x,
    aggregate = c("time", "space"), types = 1:nrow(x$qmatrix), 
    tiles, tiles.idcol = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_intensity_+3A_x">x</code></td>
<td>

<p>an object of class <code>"twinstim"</code> or <code>"simEpidataCS"</code>, respectively.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_which">which</code></td>
<td>

<p><code>"epidemic proportion"</code>, <code>"endemic proportion"</code>,
or <code>"total intensity"</code>.  Partial matching is applied.  Determines
whether to plot the path of the total intensity or its 
epidemic or endemic proportions over time or space (<code>which</code>)
aggregated over the other dimension and <code>types</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_aggregate">aggregate</code></td>
<td>

<p>One of <code>"time"</code> or <code>"space"</code>. The former results in a plot
of the evolution of <code>which</code> as a function of time (integrated
over the observation region <code class="reqn">\bold{W}</code>), whereas the latter
produces a <code>spplot</code> of <code>which</code> over <code class="reqn">\bold{W}</code>
(spanned by <code>tiles</code>). In both cases, <code>which</code> is evaluated
on a grid of values, given by <code>tgrid</code> or <code>sgrid</code>, respectively.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_types">types</code></td>
<td>

<p>event types to aggregate. By default, all types of events are
aggregated, but one could also be interested in only one specific
type or a subset of event types.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_tiles">tiles</code></td>
<td>

<p>object of class <code><a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a></code> representing
the decomposition of <code class="reqn">\bold{W}</code> into different regions (as used
in the corresponding <code>stgrid</code> of the <code>"<a href="#topic+epidataCS">epidataCS</a>"</code>.
This is only needed for <code>aggregate = "space"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_tiles.idcol">tiles.idcol</code></td>
<td>

<p>either a column index for <code>tiles@data</code> (if <code>tiles</code> is a
<code><a href="sp.html#topic+SpatialPolygonsDataFrame-class">SpatialPolygonsDataFrame</a></code>), or <code>NULL</code>
(default), which refers to the <code>"ID"</code> slot of the polygons,
i.e., <code>row.names(tiles)</code>.
The ID's must correspond to the factor levels of
<code>stgrid$tile</code> of the <code>"<a href="#topic+epidataCS">epidataCS</a>"</code> on which
<code>x</code> was fitted.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_plot">plot</code></td>
<td>

<p>logical indicating if a plot is desired, which defaults to <code>TRUE</code>.
Otherwise, a function will be returned, which takes a vector of time
points (if <code>aggregate = "time"</code>) or a matrix of coordinates (if
<code>aggregate = "space"</code>), and returns <code>which</code> on this grid.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_add">add</code></td>
<td>

<p>logical.  If <code>TRUE</code> and <code>aggregate = "time"</code>, paths are
added to the current plot, using <code>lines</code>.  This does not work
for <code>aggregate = "space"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_tgrid">tgrid</code></td>
<td>

<p>either a numeric vector of time points when to evaluate
<code>which</code>, or a scalar representing the desired number of
evaluation points in the observation interval <code class="reqn">[t_0, T]</code>.
This argument is unused for <code>aggregate = "space"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_rug.opts">rug.opts</code></td>
<td>

<p>if a list, its elements are passed as arguments to the function
<code><a href="graphics.html#topic+rug">rug</a></code>, which will mark the time points of the events if
<code>aggregate = "time"</code> (it is unused in the spatial case);
otherwise (e.g., <code>NULL</code>), no <code>rug</code> will be produced.
By default, the <code>rug</code> argument <code>ticksize</code> is set to 0.02
and <code>quiet</code> is set to <code>TRUE</code>.  Note that the argument
<code>x</code> of the <code>rug</code> function, which contains the
locations for the <code>rug</code> is fixed internally and can not be
modified.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_sgrid">sgrid</code></td>
<td>

<p>either an object of class <code>"<a href="sp.html#topic+SpatialPixels-class">SpatialPixels</a>"</code> (or
coercible to that class) representing the locations where to
evaluate <code>which</code>, or a scalar representing the approximate
number of points of a grid constructed on the bounding box of
<code>tiles</code>.
<code>sgrid</code> is internally subsetted to contain only
points inside <code>tiles</code>.
This argument is unused for <code>aggregate = "time"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_polygons.args">polygons.args</code></td>
<td>

<p>if a list, its elements are passed as arguments to
<code><a href="sp.html#topic+sp.polygons">sp.polygons</a></code>, which will add <code>tiles</code> to the plot
if <code>aggregate = "space"</code> (it is unused for the temporal plot).
By default, the fill <code>col</code>our of the tiles is set to
<code>"darkgrey"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_points.args">points.args</code></td>
<td>

<p>if a list, its elements are passed as arguments to
<code><a href="sp.html#topic+sp.points">sp.points</a></code>, which will add the event locations to the plot
if <code>aggregate = "space"</code> (it is unused for the temporal plot).
By default, the plot symbol is set to <code>pch=1</code>. The sizes
of the points are determined as the product of the argument <code>cex</code>
(default: 0.5) of this list and the sizes obtained from
the function <code>cex.fun</code> which accounts for multiple events at the
same location.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_cex.fun">cex.fun</code></td>
<td>

<p>function which takes a vector of counts of events
at each unique location and returns a (vector of) <code>cex</code>
value(s) for the sizes of the points at the event locations used in
<code>points.args</code>.
Defaults to the <code>sqrt()</code> function, which for the default
circular <code>pch=1</code> means that the area of each point is
proportional to the number of events at its location.
</p>
</td></tr>
<tr><td><code id="twinstim_intensity_+3A_...">...</code></td>
<td>

<p>further arguments passed to <code>plot</code> or <code>lines</code> (if
<code>aggregate = "time"</code>), or to <code><a href="sp.html#topic+spplot">spplot</a></code> (if
<code>aggregate = "space"</code>).<br />
For <code>intensityplot.simEpidataCS</code>, arguments passed to
<code>intensityplot.twinstim</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>plot = FALSE</code> or <code>aggregate = "time"</code>,
a function is returned, which takes a vector of
time points (if <code>aggregate = "time"</code>) or a matrix of coordinates
(if <code>aggregate = "space"</code>), and returns <code>which</code> on this grid.
<code>intensity.twinstim</code> returns a list containing such functions for
the endemic and epidemic intensity (but these are not vectorized).
</p>
<p>If <code>plot = TRUE</code> and <code>aggregate = "space"</code>, the
<code><a href="lattice.html#topic+trellis.object">trellis.object</a></code> of the spatial plot is returned.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.twinstim">plot.twinstim</a></code>, which calls <code>intensityplot.twinstim</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi", "imdepifit")

# for the intensityplot we need the model environment, which can be
# easily added by the intelligent update method (no need to refit the model)
imdepifit &lt;- update(imdepifit, model=TRUE)

## path of the total intensity
opar &lt;- par(mfrow=c(2,1))
intensityplot(imdepifit, which="total intensity",
              aggregate="time", tgrid=500)
plot(imdepi, "time", breaks=100)
par(opar)

## time course of the epidemic proportion by event
intensityplot(imdepifit, which="epidemic proportion",
              aggregate="time", tgrid=500, types=1)
intensityplot(imdepifit, which="epidemic proportion",
              aggregate="time", tgrid=500, types=2, add=TRUE, col=2)
legend("topright", legend=levels(imdepi$events$type), lty=1, col=1:2,
       title = "event type")

## endemic and total intensity in one plot
intensity_endprop &lt;- intensityplot(imdepifit, which="endemic proportion",
                                   aggregate="time", plot=FALSE)
intensity_total &lt;- intensityplot(imdepifit, which="total intensity",
                                 aggregate="time", tgrid=501, lwd=2)
curve(intensity_endprop(x) * intensity_total(x), add=TRUE, col=2, lwd=2, n=501)
text(2500, 0.36, labels="total", col=1, pos=2, font=2)
text(2500, 0.08, labels="endemic", col=2, pos=2, font=2)


## spatial shape of the intensity (aggregated over time)

  ## load borders of Germany's districts
  load(system.file("shapes", "districtsD.RData", package="surveillance"))

  # total intensity (using a rather sparse 'sgrid' for speed)
  intensityplot(imdepifit, which="total intensity",
                aggregate="space", tiles=districtsD, sgrid=500,
                col.regions=rev(heat.colors(100))) 

  # epidemic proportion by type
  maps_epiprop &lt;- lapply(1:2, function (type) {
      intensityplot(imdepifit, which="epidemic", aggregate="space",
                    types=type, tiles=districtsD, sgrid=1000,
                    main=rownames(imdepifit$qmatrix)[type],
                    scales=list(draw=FALSE), at=seq(0,1,by=0.1),
                    col.regions=rev(hcl.colors(10,"YlOrRd")),
                    colorkey=list(title=list("Epidemic proportion", cex=1)))
  })
  plot(maps_epiprop[[1]], split=c(1,1,2,1), more=TRUE)
  plot(maps_epiprop[[2]], split=c(2,1,2,1))

</code></pre>

<hr>
<h2 id='twinstim_methods'>
Print, Summary and Extraction Methods for <code>"twinstim"</code> Objects
</h2><span id='topic+print.twinstim'></span><span id='topic+summary.twinstim'></span><span id='topic+coeflist.twinstim'></span><span id='topic+vcov.twinstim'></span><span id='topic+logLik.twinstim'></span><span id='topic+nobs.twinstim'></span><span id='topic+print.summary.twinstim'></span><span id='topic+toLatex.summary.twinstim'></span><span id='topic+xtable.twinstim'></span><span id='topic+xtable.summary.twinstim'></span>

<h3>Description</h3>

<p>Besides <code><a href="base.html#topic+print">print</a></code> and <code><a href="base.html#topic+summary">summary</a></code> methods there
are also some standard extraction methods defined for objects of class
<code>"twinstim"</code>: <code><a href="stats.html#topic+vcov">vcov</a></code>, <code><a href="stats.html#topic+logLik">logLik</a></code>, and
<code><a href="stats.html#topic+nobs">nobs</a></code>. This
also enables the use of, e.g., <code><a href="stats.html#topic+confint">confint</a></code> and
<code><a href="stats.html#topic+AIC">AIC</a></code>. The model <code>summary</code> can be exported to LaTeX
by the corresponding <code><a href="utils.html#topic+toLatex">toLatex</a></code> or <code><a href="xtable.html#topic+xtable">xtable</a></code>
methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinstim'
print(x, digits = max(3, getOption("digits") - 3), ...)
## S3 method for class 'twinstim'
summary(object, test.iaf = FALSE,
        correlation = FALSE, symbolic.cor = FALSE, runtime = FALSE, ...)

## S3 method for class 'twinstim'
coeflist(x, ...)
## S3 method for class 'twinstim'
vcov(object, ...)
## S3 method for class 'twinstim'
logLik(object, ...)
## S3 method for class 'twinstim'
nobs(object, ...)

## S3 method for class 'summary.twinstim'
print(x,
      digits = max(3, getOption("digits") - 3), symbolic.cor = x$symbolic.cor,
      signif.stars = getOption("show.signif.stars"), ...)

## S3 method for class 'summary.twinstim'
toLatex(object,
        digits = max(3, getOption("digits") - 3), eps.Pvalue = 1e-4,
        align = "lrrrr", booktabs = getOption("xtable.booktabs", FALSE),
        withAIC = FALSE, ...)
## S3 method for class 'summary.twinstim'
xtable(x, caption = NULL, label = NULL,
      align = c("l", "r", "r", "r"), digits = 3,
      display = c("s", "f", "s", "s"), ...,
      ci.level = 0.95, ci.fmt = "%4.2f", ci.to = "--",
      eps.Pvalue = 1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_methods_+3A_x">x</code>, <code id="twinstim_methods_+3A_object">object</code></td>
<td>
<p>an object of class <code>"twinstim"</code> or
<code>"summary.twinstim"</code>, respectively.</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_digits">digits</code></td>
<td>

<p>integer, used for number formatting with <code>signif()</code>.  Minimum number of
significant digits to be printed in values.
</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_test.iaf">test.iaf</code></td>
<td>
<p>logical indicating if the simple Wald z- and p-values
should be calculated for parameters of the interaction functions
<code>siaf</code> and <code>tiaf</code>.
Because it is often invalid or meaningless to do so, the default is
<code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_correlation">correlation</code></td>
<td>

<p>logical. If <code>TRUE</code>, the correlation matrix of the estimated parameters
is returned and printed.
</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_symbolic.cor">symbolic.cor</code></td>
<td>

<p>logical. If <code>TRUE</code>, print the correlations in a symbolic form (see
<code>symnum</code>) rather than as numbers.
</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_runtime">runtime</code></td>
<td>

<p>logical. If <code>TRUE</code>, the summary additionally includes the time
elapsed and the number of log-likelihood and score function evaluations
during model fitting.
</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical. If <code>TRUE</code>, &ldquo;significance
stars&rdquo; are printed for each coefficient.</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_eps.pvalue">eps.Pvalue</code></td>
<td>
<p>passed to <code><a href="base.html#topic+format.pval">format.pval</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_booktabs">booktabs</code></td>
<td>
<p>logical indicating if the <code>toprule</code>,
<code>midrule</code> and <code>bottomrule</code> commands from the LaTeX package
<span class="pkg">booktabs</span> should be used for horizontal lines rather than <code>hline</code>.</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_withaic">withAIC</code></td>
<td>
<p>logical indicating if the AIC and the log-likelihood of
the model should be included below the table of coefficients in the
LaTeX tabular.</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_caption">caption</code>, <code id="twinstim_methods_+3A_label">label</code>, <code id="twinstim_methods_+3A_align">align</code>, <code id="twinstim_methods_+3A_display">display</code></td>
<td>
<p>see <code><a href="xtable.html#topic+xtable">xtable</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_ci.level">ci.level</code>, <code id="twinstim_methods_+3A_ci.fmt">ci.fmt</code>, <code id="twinstim_methods_+3A_ci.to">ci.to</code></td>
<td>
<p>the confidence intervals are calculated
at level <code>ci.level</code> and printed using <code><a href="base.html#topic+sprintf">sprintf</a></code>
with format <code>ci.fmt</code> and separator <code>ci.to</code>.</p>
</td></tr>
<tr><td><code id="twinstim_methods_+3A_...">...</code></td>
<td>

<p>For <code>print.summary.twinstim</code>, arguments passed to
<code><a href="stats.html#topic+printCoefmat">printCoefmat</a></code>.<br />
For all other methods: unused (argument of the generic).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimated coefficients and standard Wald-type confidence intervals
can be extracted using the default <code><a href="stats.html#topic+coef">coef</a></code> and
<code><a href="stats.html#topic+confint">confint</a></code> methods from package <span class="pkg">stats</span>.
Note, however, that there is the useful <code><a href="#topic+coeflist">coeflist</a></code> method to
list the coefficients by model component.
</p>
<p>The <code>print</code> and <code>summary</code> methods allow the compact or comprehensive
representation of the fitting results, respectively.  The former only prints
the original function call, the estimated coefficients and the maximum
log-likelihood value.  The latter prints the whole coefficient matrix
with standard errors, z- and p-values (see <code><a href="stats.html#topic+printCoefmat">printCoefmat</a></code>)
&ndash; separately for the endemic and the epidemic component &ndash; and 
additionally the AIC, the achieved log-likelihood, the number of
log-likelihood and score evaluations, and the runtime.
They both append a big &ldquo;WARNING&rdquo;, if the optimization algorithm
did not converge.
</p>
<p>The <code>toLatex</code> method is essentially a
translation of the printed summary table of coefficients to LaTeX
code (using <span class="pkg">xtable</span>). However, the <code>xtable</code> method does a
different job in that it first converts coefficients to rate ratios
(RR, i.e., the <code>exp</code>-transformation) and gives confidence
intervals for those instead of standard errors and z-values.
Intercepts and interaction function parameters are ignored by the
<code>xtable</code> method.
</p>


<h3>Value</h3>

<p>The <code>print</code> methods return their first argument, invisibly, as
they always should.
The <code>vcov</code> method returns the estimated variance-covariance
matrix of the parameters, which is the inverse of
<code>object$fisherinfo</code> (estimate of the <em>expected</em> Fisher
information matrix). This <code>"fisherinfo"</code> is not always available
(see <code><a href="#topic+twinstim">twinstim</a></code>), in which case
<code>object$fisherinfo.observed</code> is used if available or an error is
returned otherwise. 
The <code>logLik</code> and <code>nobs</code> methods return the maximum
log-likelihood value of the model, and the number of events (excluding
events of the prehistory), respectively.
</p>
<p>The <code>summary</code> method returns a list containing some summary
statistics of the model, which is nicely printed by the corresponding
<code>print</code> method.
</p>
<p>The <code>toLatex</code> method returns a character vector of class
<code>"Latex"</code>, each element containing one line of LaTeX code (see
<code><a href="utils.html#topic+print.Latex">print.Latex</a></code>).
The <code>xtable</code> method returns an object of class
<code>"<a href="xtable.html#topic+xtable">xtable</a>"</code>. Note that the column name of the confidence
interval, e.g. &ldquo;95% CI&rdquo;, contains the percent symbol that may
need to be escaped when printing the <code>"xtable"</code> in the output
format (see <code>sanitize.text.function</code> in
<code><a href="xtable.html#topic+print.xtable">print.xtable</a></code>). This may also hold for row names.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load a fit of the 'imdepi' data, see the example in ?twinstim
data("imdepifit")

# print method
imdepifit

# extract point estimates (in a single vector or listed by model component)
coef(imdepifit)
coeflist(imdepifit)

# variance-covariance matrix of endemic parameters
# (inverse of expected Fisher information)
unname(vcov(imdepifit)[1:4,1:4])

# the default confint() method may be used for Wald CI's
confint(imdepifit, parm="e.typeC", level=0.95)

# log-likelihood and AIC of the fitted model
logLik(imdepifit)
AIC(imdepifit)
nobs(imdepifit)

# produce a summary with parameter correlations and runtime information
(s &lt;- summary(imdepifit, correlation=TRUE, symbolic.cor=TRUE, runtime=TRUE))

# create LaTeX code of coefficient table
toLatex(s, digits=2)

# or using the xtable-method (which produces rate ratios)
xtable(s)

</code></pre>

<hr>
<h2 id='twinstim_plot'>
Plot methods for fitted <code>twinstim</code>'s
</h2><span id='topic+plot.twinstim'></span>

<h3>Description</h3>

<p>The fitted conditional intensity function from <code><a href="#topic+twinstim">twinstim</a></code>
may be visualized in at least two ways: <code><a href="#topic+iafplot">iafplot</a></code> plots the fitted
interaction functions (as a function of the distance from the host), and
<code><a href="#topic+intensityplot.twinstim">intensityplot.twinstim</a></code> plots the fitted intensity either
aggregated over space (evolution over time) or aggregated over time
(spatial surface of the cumulated intensity). The <code>plot</code> method for
class <code>"twinstim"</code> is just a wrapper for these two functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinstim'
plot(x, which, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_plot_+3A_x">x</code></td>
<td>

<p>an object of class <code>"twinstim"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_plot_+3A_which">which</code></td>
<td>

<p>character. Which characteristic of the conditional intensity should
be plotted? Possible values are the ones allowed in
the functions <code><a href="#topic+iafplot">iafplot</a></code> and
<code><a href="#topic+intensityplot.twinstim">intensityplot.twinstim</a></code>, e.g. <code>"siaf"</code>, or
<code>"epidemic proportion"</code>. Partial matching is applied.
</p>
</td></tr>
<tr><td><code id="twinstim_plot_+3A_...">...</code></td>
<td>

<p>further arguments passed to <code>iafplot</code> or
<code>intensityplot.twinstim</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See the documentation of the respective plot functions,
<code><a href="#topic+iafplot">iafplot</a></code> or <code><a href="#topic+intensityplot.twinstim">intensityplot.twinstim</a></code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see the examples for iafplot() and intensityplot.twinstim()
</code></pre>

<hr>
<h2 id='twinstim_profile'>
Profile Likelihood Computation and Confidence Intervals for
<code>twinstim</code> objects
</h2><span id='topic+profile.twinstim'></span>

<h3>Description</h3>

<p>Function to compute estimated and profile likelihood based confidence
intervals for <code>twinstim</code> objects. Computations might be cumbersome!
</p>
<p>WARNING: the implementation is not well tested, simply uses
<code>optim</code> (ignoring optimizer settings from the original fit),
and does not return the complete set of coefficients at each grid point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinstim'
profile(fitted, profile, alpha = 0.05,
        control = list(fnscale = -1, maxit = 100, trace = 1),
        do.ltildeprofile=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_profile_+3A_fitted">fitted</code></td>
<td>

<p>an object of class <code>"twinstim"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_profile_+3A_profile">profile</code></td>
<td>

<p>a list with elements being numeric vectors of length 4.  These vectors must
have the form <code>c(index, lower, upper, gridsize)</code>.
</p>

<dl>
<dt><code>index</code>:</dt><dd>
<p>index of the parameter to be profiled in the vector <code>coef(fitted)</code>.
</p>
</dd>
<dt><code>lower, upper</code>:</dt><dd>
<p>lower/upper limit of the grid on which the profile log-likelihood is
evaluated. Can also be <code>NA</code> in which case <code>lower/upper</code> equals 
the lower/upper bound of the respective 0.3 % Wald confidence interval
(+-3*se).
</p>
</dd>
<dt><code>gridsize</code>:</dt><dd>
<p>grid size of the equally spaced grid between lower and upper.  Can also
be 0 in which case the profile log-likelihood for this parameter is not 
evaluated on a grid.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="twinstim_profile_+3A_alpha">alpha</code></td>
<td>

<p><code class="reqn">(1-\alpha)\%</code> profile likelihood based confidence
intervals are computed.  If alpha &lt;= 0, then no confidence intervals are
computed. This is currently not implemented.
</p>
</td></tr>
<tr><td><code id="twinstim_profile_+3A_control">control</code></td>
<td>

<p>control object to use in <code><a href="stats.html#topic+optim">optim</a></code> for the profile log-likelihood
computations. It might be necessary to control <code>maxit</code> or
<code>reltol</code> in order to obtain results in finite time.
</p>
</td></tr>
<tr><td><code id="twinstim_profile_+3A_do.ltildeprofile">do.ltildeprofile</code></td>
<td>
<p>If <code>TRUE</code> calculate profile likelihood as
well. This might take a while, since an optimisation for all other
parameters has to be performed. Useful for likelihood based
confidence intervals. Default: <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_profile_+3A_...">...</code></td>
<td>

<p>unused (argument of the generic).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with profile log-likelihood evaluations on the grid, and
&ndash; not implemented yet &ndash;
highest likelihood and Wald confidence intervals.
The argument <code>profile</code> is also returned.
</p>


<h3>Author(s)</h3>

<p>Michael Höhle
</p>


<h3>Examples</h3>

<pre><code class='language-R'># profiling takes a while
## Not run: 
#Load the twinstim model fitted to the IMD data
data("imdepi", "imdepifit")
# for profiling we need the model environment
imdepifit &lt;- update(imdepifit, model=TRUE)

#Generate profiling object for a list of parameters for the new model
names &lt;- c("h.(Intercept)","e.typeC")
coefList &lt;- lapply(names, function(name) {
  c(pmatch(name,names(coef(imdepifit))),NA,NA,11)
})

#Profile object (necessary to specify a more loose convergence
#criterion). Speed things up by using do.ltildeprofile=FALSE (the default)
prof &lt;- profile(imdepifit, coefList,
  control=list(reltol=0.1, REPORT=1), do.ltildeprofile=TRUE)

#Plot result for one variable
par(mfrow=c(1,2))
for (name in names) {
  with(as.data.frame(prof$lp[[name]]),
       matplot(grid,cbind(profile,estimated,wald),
               type="l",xlab=name,ylab="loglik"))
  legend(x="bottomleft",c("profile","estimated","wald"),lty=1:3,col=1:3)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='twinstim_siaf'>
Spatial Interaction Function Objects
</h2><span id='topic+siaf'></span>

<h3>Description</h3>

<p>A spatial interaction function for use in <code><a href="#topic+twinstim">twinstim</a></code>
can be constructed via the <code>siaf</code> function.
It checks the supplied function elements, assigns defaults for
missing arguments, and returns all checked arguments in a list.
However, for standard applications it is much easier to use one of the
pre-defined spatial interaction functions, e.g.,
<code><a href="#topic+siaf.gaussian">siaf.gaussian</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>siaf(f, F, Fcircle, effRange, deriv, Deriv, simulate, npars,
     validpars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_siaf_+3A_f">f</code></td>
<td>
<p>the spatial interaction function. It must accept
two arguments, the first one being a (2-column) coordinate matrix, the
second one a parameter vector. For marked <code>twinstim</code>, it must
accept the type of the event (integer code) as its third argument
(either a single type for all locations or separate types for each
location).</p>
</td></tr>
<tr><td><code id="twinstim_siaf_+3A_f">F</code></td>
<td>
<p>function computing the integral of <code class="reqn">f(s)</code> (passed as
second argument) over a polygonal <code>"owin"</code> domain (first argument).
The third and fourth argument are
the parameter vector and the (<em>single</em>) type, respectively.
There may be additional arguments, which can then be specified in
the <code>control.siaf$F</code> argument list of <code>twinstim</code>. If the <code>F</code>
function is missing, a general default (<code><a href="polyCub.html#topic+polyCub">polyCub</a></code>) 
will be used, with extra arguments <code>method</code> (default: <code>"SV"</code>) 
and corresponding accuracy parameters.</p>
</td></tr>
<tr><td><code id="twinstim_siaf_+3A_fcircle">Fcircle</code></td>
<td>
<p>optional function for fast calculation of the
(two-dimensional) integral of <code class="reqn">f(s)</code> over a circle with radius
<code>r</code> (first argument). Further arguments are as for <code>f</code>. It
must not be vectorized (will always be called with single radius
and a single type). If this function is specified, integration of
the <code>siaf</code> over the spatial influence region of an event will
be faster if the region is actually circular. This is the case if
the event is located at least a distance <code>eps.s</code> from the border
of the observation region <code>W</code>, or if the distance to the border
is larger than the effective integration range (if specified, see
<code>effRange</code> below).</p>
</td></tr>
<tr><td><code id="twinstim_siaf_+3A_effrange">effRange</code></td>
<td>
<p>optional function returning the &ldquo;effective&rdquo;
range of <code class="reqn">f(s)</code> for the given set of parameters (the first and
only argument) such that the circle with radius <code>effRange</code>
contains the numerically essential proportion of the 
integral mass. For the Gaussian kernel the default is
<code>function (logsd) 6*exp(logsd)</code>. The return value must be a
vector of length <code>nTypes</code> (effective range for each type). This
function is only used if <code>Fcircle</code> is also specified.</p>
</td></tr>
<tr><td><code id="twinstim_siaf_+3A_deriv">deriv</code></td>
<td>
<p>optional derivative of <code class="reqn">f(s)</code> <em>with respect to
the parameters</em>. It takes the same arguments as <code>f</code> but
returns a matrix with as many rows as there were coordinates in the
input and <code>npars</code> columns. This derivative is necessary for the
calculation of the score function in <code>twinstim()</code>, which is
advantageous for the numerical log-likelihood maximization.</p>
</td></tr> 
<tr><td><code id="twinstim_siaf_+3A_deriv">Deriv</code></td>
<td>
<p>function computing the integral of <code>deriv</code> (passed as
second argument) over a polygonal <code>"owin"</code> domain (first
argument). The return value is thus a vector of length <code>npars</code>.
The third argument is the parameter vector and the fourth argument
is a (<em>single</em>) type and must be named <code>type</code>.
There may be additional arguments, which can then be specified in
the <code>control.siaf$Deriv</code> argument list of <code>twinstim</code>. If the
<code>Deriv</code> function is missing, a general default
(<code><a href="polyCub.html#topic+polyCub">polyCub</a></code>) will be used, with extra arguments
<code>method</code> (default: <code>"SV"</code>) and corresponding accuracy parameters.</p>
</td></tr>
<tr><td><code id="twinstim_siaf_+3A_simulate">simulate</code></td>
<td>
<p>optional function returning a sample drawn from the
spatial kernel (only required for the simulation of <code>twinstim</code>
models).  Its first argument is the size of the sample to
generate, next the parameter vector, an optional single event type,
and an optional upper bound for the radius within which to simulate
points. The function must return a two-column <em>matrix</em> of the
sampled locations. 
Note that the simulation method actually samples only one location
at a time, thus it is sufficient to have a working
<code>function(n=1, pars, type, ub)</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_siaf_+3A_npars">npars</code></td>
<td>
<p>the number of parameters of the spatial interaction
function <code>f</code> (i.e. the length of its second argument).</p>
</td></tr>
<tr><td><code id="twinstim_siaf_+3A_validpars">validpars</code></td>
<td>

<p>optional function taking one argument, the parameter vector, indicating if it
is valid. This approach to specify parameter constraints is rarely
needed, because usual box-constrained parameters can be taken into
account by using L-BFGS-B as the optimization method in
<code>twinstim</code> (with arguments <code>lower</code> and <code>upper</code>), and
positivity constraints by using log-parametrizations.
This component is not necessary (and ignored) if <code>npars == 0</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of checked arguments.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+siaf.gaussian">siaf.gaussian</a></code> for a pre-defined spatial interaction
function, and <code><a href="#topic+tiaf">tiaf</a></code> for the temporal interaction function.
</p>

<hr>
<h2 id='twinstim_simEndemicEvents'>
Quick Simulation from an Endemic-Only <code>twinstim</code>
</h2><span id='topic+simEndemicEvents'></span>

<h3>Description</h3>

<p>In <em>endemic-only</em> <code><a href="#topic+twinstim">twinstim</a></code> models, the conditional
intensity is a piecewise constant function independent from the history
of the process. This allows for a much more efficient simulation
algorithm than via Ogata's modified thinning as in the general
<code><a href="#topic+simulate.twinstim">simulate.twinstim</a></code> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simEndemicEvents(object, tiles)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_simEndemicEvents_+3A_object">object</code></td>
<td>

<p>an object of class <code>"<a href="#topic+twinstim">twinstim</a>"</code> (with the <code>model</code>
component retained; otherwise try
<code>object &lt;- <a href="#topic+update.twinstim">update</a>(object, model = TRUE)</code>).
</p>
</td></tr>
<tr><td><code id="twinstim_simEndemicEvents_+3A_tiles">tiles</code></td>
<td>

<p>an object inheriting from <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>,
which represents the tiles of the original data's <code>stgrid</code>
(see, e.g., <code>levels(environment(object)$gridTiles)</code>).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="sp.html#topic+SpatialPointsDataFrame-class">SpatialPointsDataFrame</a></code>
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p>the general simulation method <code><a href="#topic+simulate.twinstim">simulate.twinstim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi", "imdepifit")
load(system.file("shapes", "districtsD.RData", package="surveillance"))

## Fit an endemic-only twinstim()
m_noepi &lt;- update(imdepifit, epidemic = ~0, siaf = NULL, model = TRUE,
                  T = 120)  # using a restricted time range, for speed

## Simulate events from the above endemic model
set.seed(1)
s1 &lt;- simEndemicEvents(m_noepi, tiles = districtsD)
class(s1)  # just a "SpatialPointsDataFrame"
summary(s1@data)
plot(imdepi$W, lwd = 2, asp = 1)  
plot(s1, col = s1$type, cex = 0.5, add = TRUE)


## the general simulation method takes longer
s0 &lt;- simulate(m_noepi, seed = 1, data = imdepi, tiles = districtsD)
class(s0)  # gives a full "simEpidataCS" with several methods applicable
methods(class = "epidataCS")
plot(s0, "time")
plot(s0, "space", points.args = list(pch = 3), lwd = 2)

</code></pre>

<hr>
<h2 id='twinstim_simulation'>
Simulation of a Self-Exciting Spatio-Temporal Point Process
</h2><span id='topic+simEpidataCS'></span><span id='topic+simulate.twinstim'></span>

<h3>Description</h3>

<p>The function <code>simEpidataCS</code> simulates events of a self-exciting
spatio-temporal point process of the <code>"<a href="#topic+twinstim">twinstim</a>"</code> class.
Simulation works via Ogata's modified thinning of the conditional
intensity as described in Meyer et al. (2012). Note that simulation is
limited to the spatial and temporal range of <code>stgrid</code>.
</p>
<p>The <code><a href="stats.html#topic+simulate">simulate</a></code> method for objects of class
<code>"<a href="#topic+twinstim">twinstim</a>"</code> simulates new epidemic data using the model and
the parameter estimates of the fitted object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simEpidataCS(endemic, epidemic, siaf, tiaf, qmatrix, rmarks,
    events, stgrid, tiles, beta0, beta, gamma, siafpars, tiafpars,
    epilink = "log", t0 = stgrid$start[1], T = tail(stgrid$stop,1),
    nEvents = 1e5, control.siaf = list(F=list(), Deriv=list()),
    W = NULL, trace = 5, nCircle2Poly = 32, gmax = NULL, .allocate = 500,
    .skipChecks = FALSE, .onlyEvents = FALSE)

## S3 method for class 'twinstim'
simulate(object, nsim = 1, seed = NULL, data, tiles,
    newcoef = NULL, rmarks = NULL, t0 = NULL, T = NULL, nEvents = 1e5,
    control.siaf = object$control.siaf,
    W = data$W, trace = FALSE, nCircle2Poly = NULL, gmax = NULL,
    .allocate = 500, simplify = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_simulation_+3A_endemic">endemic</code></td>
<td>

<p>see <code><a href="#topic+twinstim">twinstim</a></code>. Note that type-specific endemic
intercepts are specified by <code>beta0</code> here, not by the term
<code>(1|type)</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_epidemic">epidemic</code></td>
<td>

<p>see <code><a href="#topic+twinstim">twinstim</a></code>. Marks appearing in this formula must
be returned by the generating function <code>rmarks</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_siaf">siaf</code></td>
<td>

<p>see <code><a href="#topic+twinstim">twinstim</a></code>.
In addition to what is required for fitting with <code>twinstim</code>,
the <code>siaf</code> specification must also contain the element
<code>simulate</code>, a function which draws random locations following the
spatial kernel <code>siaf$f</code>. The first argument of the function is the
number of points to sample (say <code>n</code>),
the second one is the vector of parameters
<code>siafpars</code>, the third one is the type indicator (a character string
matching a type name as specified by <code>dimnames(qmatrix)</code>). With the
current implementation there will always be simulated only one
location at a time, i.e. <code>n=1</code>.
The <a href="#topic+siaf.constant">predefined siaf's</a> all provide simulation.
</p>
</td></tr> 
<tr><td><code id="twinstim_simulation_+3A_tiaf">tiaf</code></td>
<td>

<p>e.g. what is returned by the generating function
<code><a href="#topic+tiaf.constant">tiaf.constant</a></code> or <code><a href="#topic+tiaf.exponential">tiaf.exponential</a></code>. See also
<code><a href="#topic+twinstim">twinstim</a></code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_qmatrix">qmatrix</code></td>
<td>

<p>see <code><a href="#topic+epidataCS">epidataCS</a></code>. Note that this square
matrix and its <code>dimnames</code> determine the number and names of the
different event types. In the simplest case, there is only a single
type of event, i.e. <code>qmatrix = diag(1)</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_rmarks">rmarks</code></td>
<td>

<p>function of single time (1st argument) and location
(2nd argument) returning a one-row <code>data.frame</code> of marks (named
according to the variables in <code>epidemic</code>) for an event at this
point. This must include the columns <code>eps.s</code> and <code>eps.t</code>, 
i.e. the values of the spatial and temporal interaction ranges at this
point. Only <code>"numeric"</code> and <code>"factor"</code> columns are
allowed. Assure that factor variables are coded equally 
(same levels and level order) for each new sample.
</p>
<p>For the <code>simulate.twinstim</code> method, the default (<code>NULL</code>)
means sampling from the empirical distribution function of the
(non-missing) marks in <code>data</code> restricted to events in the
simulation period (<code>t0</code>;<code>T</code>]. If there are no events in
this period, e.g., if simulating beyond the original observation
period, <code>rmarks</code> will sample marks from all of
<code>data$events</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_events">events</code></td>
<td>

<p><code>NULL</code> or missing (default) in case of an empty prehistory,
or a <code><a href="sp.html#topic+SpatialPointsDataFrame">SpatialPointsDataFrame</a></code> containing events of the
prehistory (-Inf;<code>t0</code>] of the process (required for the
epidemic to start in case of no endemic component in the model).
The <code>SpatialPointsDataFrame</code> must have the same
<code>proj4string</code> as <code>tiles</code> and <code>W</code>). The attached
<code>data.frame</code> (data slot) must contain the typical 
columns as described in <code><a href="#topic+as.epidataCS">as.epidataCS</a></code> (<code>time</code>,
<code>tile</code>, <code>eps.t</code>, <code>eps.s</code>, and, for type-specific
models, <code>type</code>) and all marks appearing in the <code>epidemic</code>
specification. Note that some column names are reserved (see
<code><a href="#topic+as.epidataCS">as.epidataCS</a></code>).  Only events up to
time <code>t0</code> are selected and taken as the prehistory.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_stgrid">stgrid</code></td>
<td>

<p>see <code><a href="#topic+as.epidataCS">as.epidataCS</a></code>. Simulation only works inside the spatial
and temporal range of <code>stgrid</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_tiles">tiles</code></td>
<td>

<p>object inheriting from <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code> with
<code>row.names</code> matching the <code>tile</code> names in <code>stgrid</code> and
having the same <code>proj4string</code> as <code>events</code> and <code>W</code>. This is necessary
to sample the spatial location of events generated by the endemic component.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_beta0">beta0</code>, <code id="twinstim_simulation_+3A_beta">beta</code>, <code id="twinstim_simulation_+3A_gamma">gamma</code>, <code id="twinstim_simulation_+3A_siafpars">siafpars</code>, <code id="twinstim_simulation_+3A_tiafpars">tiafpars</code></td>
<td>

<p>these are the parameter subvectors of the <code>twinstim</code>.
<code>beta</code> and <code>gamma</code> must be given in the 
same order as they appear in <code>endemic</code> and <code>epidemic</code>,
respectively. <code>beta0</code> is either a single endemic intercept or a
vector of type-specific endemic intercepts in the same order as in
<code>qmatrix</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_epilink">epilink</code></td>
<td>

<p>a character string determining the link function to be used for the
<code>epidemic</code> linear predictor of event marks. By default, the
log-link is used. The experimental alternative is
<code>epilink = "identity"</code>. Note that the identity link does not
guarantee the force of infection to be positive. If this leads to a
negative total intensity (endemic + epidemic), the point process is
not well defined and simulation cannot proceed.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_t0">t0</code></td>
<td>

<p><code>events</code> having occurred during (-Inf;<code>t0</code>] are regarded
as part of the prehistory <code class="reqn">H_0</code> of the process.
For <code>simEpidataCS</code>, by default and also if <code>t0=NULL</code>,
the beginning of <code>stgrid</code> is used as <code>t0</code>.
For the <code>simulate.twinstim</code> method, <code>NULL</code> means to use
the fitted time range of the <code>"twinstim"</code> <code>object</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_t">T</code>, <code id="twinstim_simulation_+3A_nevents">nEvents</code></td>
<td>

<p>simulate a maximum of <code>nEvents</code> events up to time <code>T</code>,
then stop. For <code>simEpidataCS</code>, by default, and also if
<code>T=NULL</code>, <code>T</code> equals the last stop time in <code>stgrid</code>
(it cannot be greater) and <code>nEvents</code> is bounded above by 10000.
For the <code>simulate.twinstim</code> method, <code>T=NULL</code> means to use
the same same time range as for the fitting of the <code>"twinstim"</code>
<code>object</code>. 
</p>
</td></tr> 
<tr><td><code id="twinstim_simulation_+3A_w">W</code></td>
<td>

<p>see <code><a href="#topic+as.epidataCS">as.epidataCS</a></code>. When simulating from
<code>twinstim</code>-fits, <code>W</code> is by default taken from the original
<code>data$W</code>. If specified as <code>NULL</code>, <code>W</code> is generated 
automatically via <code><a href="#topic+unionSpatialPolygons">unionSpatialPolygons</a>(tiles)</code>.
However, since the result of such a polygon operation should always
be verified, it is recommended to do that in advance.<br />
It is important that <code>W</code> and <code>tiles</code> cover the same region:
on the one hand direct offspring is sampled
in the spatial influence region of the parent event, i.e., in the
intersection of <code>W</code> and a circle of radius the <code>eps.s</code> of the
parent event, after which the corresponding tile is determined by
overlay with <code>tiles</code>. On the other hand endemic events are
sampled from <code>tiles</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_trace">trace</code></td>
<td>

<p>logical (or integer) indicating if (or how often) the current
simulation status should be <code>cat</code>ed.  For the
<code>simulate.twinstim</code> method, <code>trace</code> currently only applies
to the first of the <code>nsim</code> simulations.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_.allocate">.allocate</code></td>
<td>

<p>number of rows (events) to initially allocate for the event history;
defaults to 500.  Each time the simulated epidemic exceeds the
allocated space, the event <code>data.frame</code> will be enlarged by
<code>.allocate</code> rows.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_.skipchecks">.skipChecks</code>, <code id="twinstim_simulation_+3A_.onlyevents">.onlyEvents</code></td>
<td>

<p>these logical arguments are not meant to be set by the user.
They are used by the <code>simulate</code>-method for <code>"twinstim"</code> objects.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_object">object</code></td>
<td>

<p>an object of class <code>"<a href="#topic+twinstim">twinstim</a>"</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_nsim">nsim</code></td>
<td>

<p>number of epidemics (i.e. spatio-temporal point patterns inheriting
from class <code>"epidataCS"</code>) to simulate.  Defaults to 1 when the
result is a simple object inheriting from class
<code>"simEpidataCS"</code> (as if <code>simEpidataCS</code> would have been
called directly).  If <code>nsim &gt; 1</code>, the result 
will be a list the structure of which depends on the argument
<code>simplify</code>. 
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_seed">seed</code></td>
<td>

<p>an object specifying how the random number generator should be
initialized for simulation (via <code><a href="base.html#topic+set.seed">set.seed</a></code>). The
initial state will also be stored as an attribute <code>"seed"</code> of
the result. The original state of the <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>
will be restored at the end of the simulation.
By default (<code>NULL</code>), neither initialization nor recovery will
be done.
This behaviour is copied from the <code><a href="stats.html#topic+simulate">simulate</a>.lm</code> method.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_data">data</code></td>
<td>

<p>an object of class <code>"epidataCS"</code>, usually the one to which the
<code>"twinstim"</code> <code>object</code> was fitted. It carries
the <code>stgrid</code> of the endemic component, but also
<code>events</code> for use as the prehistory, and defaults for
<code>rmarks</code> and <code>nCircle2Poly</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_newcoef">newcoef</code></td>
<td>

<p>an optional named numeric vector of (a subset of) parameters to
replace the original point estimates in <code>coef(object)</code>.
Elements which do not match any model parameter by name are silently
ignored. The <code>newcoef</code>s may also be supplied in a list
following the same conventions as for the <code>start</code> argument in
<code><a href="#topic+twinstim">twinstim</a></code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_simplify">simplify</code></td>
<td>

<p>logical. It is strongly recommended to set <code>simplify = TRUE</code>
(default) if <code>nsim</code> is large. This saves space and computation time,
because for each simulated epidemic only the <code>events</code> component is
saved. All other components, which do not vary between simulations,
are only stored from the first run. In this case, the runtime of each
simulation is stored as an attribute <code>"runtime"</code> to each simulated
<code>events</code>. See also the &ldquo;Value&rdquo; section below.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_control.siaf">control.siaf</code></td>
<td>
<p>see <code><a href="#topic+twinstim">twinstim</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_ncircle2poly">nCircle2Poly</code></td>
<td>
<p>see <code><a href="#topic+as.epidataCS">as.epidataCS</a></code>. For
<code>simulate.twinstim</code>, <code>NULL</code> means to use the same value as
for <code>data</code>.</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_gmax">gmax</code></td>
<td>

<p>maximum value the temporal interaction function
<code>tiaf$g</code> can attain. If <code>NULL</code>, then it is assumed as the
maximum value of the type-specific values at 0, i.e.
<code>max(tiaf$g(rep.int(0,nTypes), tiafpars, 1:nTypes))</code>.
</p>
</td></tr>
<tr><td><code id="twinstim_simulation_+3A_...">...</code></td>
<td>
<p>unused (arguments of the generic).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>simEpidataCS</code> returns a simulated epidemic of class
<code>"simEpidataCS"</code>, which enhances the class
<code>"epidataCS"</code> by the following additional components known from
objects of class <code>"<a href="#topic+twinstim">twinstim</a>"</code>:
<code>bbox</code>, <code>timeRange</code>, <code>formula</code>, <code>coefficients</code>,
<code>npars</code>, <code>control.siaf</code>, <code>call</code>, <code>runtime</code>.
It has corresponding <code><a href="#topic+coeflist">coeflist</a></code>,
<code><a href="#topic+residuals.simEpidataCS">residuals</a></code>,
<code><a href="#topic+R0.simEpidataCS">R0</a></code>, and
<code><a href="#topic+intensityplot.simEpidataCS">intensityplot</a></code> methods.
</p>
<p>The <code>simulate.twinstim</code> method has some additional
<em>attributes</em> set on its result:
<code>call</code>, <code>seed</code>, and <code>runtime</code>.
If <code>nsim &gt; 1</code>, it returns an object of class
<code>"simEpidataCSlist"</code>, the form of which depends on the value of
<code>simplify</code> (which is stored as an attribute <code>simplified</code>):
if <code>simplify = FALSE</code>, then the return value is
just a list of sequential simulations, each of class
<code>"simEpidataCS"</code>. However, if <code>simplify = TRUE</code>, then the
sequential simulations share all components but the simulated
<code>events</code>, i.e. the result is a list with the same components as
a single object of class <code>"simEpidataCS"</code>, but with <code>events</code>
replaced by an <code>eventsList</code> containing the <code>events</code> returned
by each of the simulations.
</p>
<p>The <code>stgrid</code> component of the returned <code>"simEpidataCS"</code>
will be truncated to the actual end of the simulation, which might
be <code class="reqn">&lt;T</code>, if the upper bound <code>nEvents</code> is reached during
simulation.
</p>
<p>CAVE: Currently, <code>simplify=TRUE</code> in <code>simulate.twinstim</code>
ignores that multiple simulated epidemics
(<code>nsim &gt; 1</code>) may have different <code>stgrid</code> 
time ranges. In a <code>"simEpidataCSlist"</code>, the <code>stgrid</code> shared
by all of the simulated epidemics is just the <code>stgrid</code>
returned by the <em>first</em> simulation.
</p>


<h3>Note</h3>

<p>The more detailed the polygons in <code>tiles</code> are the slower is
the algorithm. You are advised to sacrifice some shape
details for speed by reducing the polygon complexity,
for example via the <code>mapshaper</code> JavaScript library wrapped by
the R package <a href="https://CRAN.R-project.org/package=rmapshaper"><span class="pkg">rmapshaper</span></a>, or via
<code><a href="spatstat.geom.html#topic+simplify.owin">simplify.owin</a></code>.
</p>


<h3>Author(s)</h3>

 
<p>Sebastian Meyer, with contributions by Michael Höhle
</p>


<h3>References</h3>

<p>Douglas, D. H. and Peucker, T. K. (1973):
Algorithms for the reduction of the number of points required to
represent a digitized line or its caricature.
<em>Cartographica: The International Journal for Geographic
Information and Geovisualization</em>, <b>10</b>, 112-122
</p>
<p>Meyer, S., Elias, J. and Höhle, M. (2012):
A space-time conditional intensity model for invasive meningococcal
disease occurrence. <em>Biometrics</em>, <b>68</b>, 607-616.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01684.x">doi:10.1111/j.1541-0420.2011.01684.x</a>
</p>


<h3>See Also</h3>

<p>The function <code><a href="#topic+simEndemicEvents">simEndemicEvents</a></code> is a faster alternative
for endemic-only models, only returning a
<code>"<a href="sp.html#topic+SpatialPointsDataFrame-class">SpatialPointsDataFrame</a>"</code> of simulated events.
</p>
<p>The <code><a href="#topic+plot.epidataCS">plot.epidataCS</a></code> and <code><a href="#topic+animate.epidataCS">animate.epidataCS</a></code>
methods for plotting and animating continuous-space epidemic data,
respectively, also work for simulated epidemics (by inheritance),
and <code><a href="#topic+twinstim">twinstim</a></code> can be used to fit
spatio-temporal conditional intensity models also to simulated data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi", "imdepifit")

## load borders of Germany's districts (originally obtained from
## the German Federal Agency for Cartography and Geodesy,
## https://gdz.bkg.bund.de/), simplified by the "modified Visvalingam"
## algorithm (level=6.6%) using MapShaper.org (v. 0.1.17):
load(system.file("shapes", "districtsD.RData", package="surveillance"))

plot(districtsD)
plot(stateD, add=TRUE, border=2, lwd=2)


## simulate 2 realizations (over a short period, for speed)
## considering events from data(imdepi) before t=31 as prehistory

mysims &lt;- simulate(imdepifit, nsim=2, seed=1, data=imdepi,
                   tiles=districtsD, newcoef=c("e.typeC"=-1),
                   t0=31, T=if (interactive()) 180 else 45, # for CRAN
                   simplify=TRUE)



## plot both simulations using the plot-method for simEpidataCSlist's
mysims
plot(mysims, aggregate="time")

## extract the second realization -&gt; object of class simEpidataCS
mysim2 &lt;- mysims[[2]]
summary(mysim2)
plot(mysim2, aggregate="space")


### compare the observed _cumulative_ number of cases during the
### first 90 days to 20 simulations from the fitted model

sims &lt;- simulate(imdepifit, nsim=20, seed=1, data=imdepi, t0=0, T=90,
                 tiles=districtsD, simplify=TRUE)

## extract cusums
getcsums &lt;- function (events) {
    tapply(events$time, events@data["type"],
           function (t) cumsum(table(t)), simplify=FALSE)
}
csums_observed &lt;- getcsums(imdepi$events)
csums_simulated &lt;- lapply(sims$eventsList, getcsums)

## plot it
plotcsums &lt;- function (csums, ...) {
    mapply(function (csum, ...) lines(as.numeric(names(csum)), csum, ...),
           csums, ...)
    invisible()
}
plot(c(0,90), c(0,35), type="n", xlab="Time [days]",
     ylab="Cumulative number of cases")
plotcsums(csums_observed, col=c(2,4), lwd=3)
legend("topleft", legend=levels(imdepi$events$type), col=c(2,4), lwd=1)
invisible(lapply(csums_simulated, plotcsums,
                 col=adjustcolor(c(2,4), alpha=0.5)))



## Not run: 

### Experimental code to generate 'nsim' simulations of 'nm2add' months
### beyond the observed time period:
nm2add &lt;- 24
nsim &lt;- 5
### The events still infective by the end of imdepi$stgrid will be used
### as the prehistory for the continued process.

origT &lt;- tail(imdepi$stgrid$stop, 1)
## create a time-extended version of imdepi
imdepiext &lt;- local({
    ## first we have to expand stgrid (assuming constant "popdensity")
    g &lt;- imdepi$stgrid
    g$stop &lt;- g$BLOCK &lt;- NULL
    gadd &lt;- data.frame(start=rep(seq(origT, by=30, length.out=nm2add),
                                 each=nlevels(g$tile)),
                       g[rep(seq_len(nlevels(g$tile)), nm2add), -1])
    ## now create an "epidataCS" using this time-extended stgrid
    as.epidataCS(events=imdepi$events,  # the replacement warnings are ok
                 W=imdepi$W, qmatrix=imdepi$qmatrix,
                 stgrid=rbind(g, gadd), T=max(gadd$start) + 30)
})
newT &lt;- tail(imdepiext$stgrid$stop, 1)

## simulate beyond the original period
simsext &lt;- simulate(imdepifit, nsim=nsim, seed=1, t0=origT, T=newT,
                    data=imdepiext, tiles=districtsD, simplify=TRUE)

## Aside to understand the note from checking events and tiles:
# marks(imdepi)["636",]  # tile 09662 is attributed to this event, but:
# plot(districtsD[c("09678","09662"),], border=1:2, lwd=2, axes=TRUE)
# points(imdepi$events["636",])
## this mismatch is due to polygon simplification

## plot the observed and simulated event numbers over time
plot(imdepiext, breaks=c(unique(imdepi$stgrid$start),origT),
     cumulative=list(maxat=330))
for (i in seq_along(simsext$eventsList))
    plot(simsext[[i]], add=TRUE, legend.types=FALSE,
         breaks=c(unique(simsext$stgrid$start),newT),
         subset=!is.na(source),  # have to exclude the events of the prehistory
         cumulative=list(offset=c(table(imdepi$events$type)), maxat=330, axis=FALSE),
         border=NA, density=0)  # no histogram
abline(v=origT, lty=2, lwd=2)


## End(Not run)
</code></pre>

<hr>
<h2 id='twinstim_step'>
Stepwise Model Selection by AIC
</h2><span id='topic+stepComponent'></span><span id='topic+add1.twinstim'></span><span id='topic+drop1.twinstim'></span>

<h3>Description</h3>

<p><code>stepComponent</code> is a wrapper around <code><a href="stats.html#topic+step">step</a></code> to select a
<code>"<a href="#topic+twinstim">twinstim</a>"</code> component's model based on an information
criterion in a stepwise algorithm.
</p>
<p>There are also stand-alone single-step methods of <code><a href="stats.html#topic+add1">add1</a></code> and
<code><a href="stats.html#topic+drop1">drop1</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepComponent(object, component = c("endemic", "epidemic"),
              scope = list(upper = object$formula[[component]]),
              direction = "both", trace = 2, verbose = FALSE, ...)

## S3 method for class 'twinstim'
add1(object, scope, component = c("endemic", "epidemic"), 
    trace = 2, ...)
## S3 method for class 'twinstim'
drop1(object, scope, component = c("endemic", "epidemic"), 
     trace = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_step_+3A_object">object</code></td>
<td>
<p>an object of class <code>"twinstim"</code>.</p>
</td></tr>
<tr><td><code id="twinstim_step_+3A_component">component</code></td>
<td>
<p>one of <code>"endemic"</code> or <code>"epidemic"</code>
(partially matched), determining the model component where the
algorithm should proceed.</p>
</td></tr>
<tr><td><code id="twinstim_step_+3A_scope">scope</code>, <code id="twinstim_step_+3A_direction">direction</code>, <code id="twinstim_step_+3A_trace">trace</code></td>
<td>
<p>see <code><a href="stats.html#topic+step">step</a></code> and
<code><a href="stats.html#topic+add1">add1</a></code>, respectively.</p>
</td></tr>
<tr><td><code id="twinstim_step_+3A_verbose">verbose</code></td>
<td>
<p>see <code><a href="#topic+twinstim">twinstim</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_step_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="stats.html#topic+step">step</a></code>,
<code><a href="stats.html#topic+add1.default">add1.default</a></code>, or <code><a href="stats.html#topic+drop1.default">drop1.default</a></code>,
respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See <code><a href="stats.html#topic+step">step</a></code> and <code><a href="stats.html#topic+add1">add1</a></code>, respectively.
</p>


<h3>Author(s)</h3>

<p>(of this wrapper around <code><a href="stats.html#topic+step">step</a></code>) Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+step">step</a></code>, <code><a href="stats.html#topic+add1">add1</a></code>, <code><a href="stats.html#topic+drop1">drop1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi", "imdepifit")

## simple baseline model
m0 &lt;- update(imdepifit, epidemic=~1, siaf=NULL)

## AIC-based step-wise backward selection of the endemic component
m0_step &lt;- stepComponent(m0, "endemic", scope=list(lower=~I(start/365-3.5)))
## nothing is dropped from the model


</code></pre>

<hr>
<h2 id='twinstim_tiaf'>
Temporal Interaction Function Objects
</h2><span id='topic+tiaf'></span>

<h3>Description</h3>

<p>A temporal interaction function for use in <code><a href="#topic+twinstim">twinstim</a></code>
can be constructed via the <code>tiaf</code> function.
It checks the supplied function elements, assigns defaults for
missing arguments, and returns all checked arguments in a list.
However, for standard applications it is much easier to use one of the
pre-defined temporal interaction functions, e.g.,
<code><a href="#topic+tiaf.exponential">tiaf.exponential</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tiaf(g, G, deriv, Deriv, npars, validpars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_tiaf_+3A_g">g</code></td>
<td>
<p>the temporal interaction function. It must accept
two arguments, the first one being a vector of time points, the
second one a parameter vector. For marked <code>twinstim</code>, it must
accept the type of the event (integer code) as its third argument
(either a single type for all locations or separate types for each
location).</p>
</td></tr>
<tr><td><code id="twinstim_tiaf_+3A_g">G</code></td>
<td>
<p>a primitive of <code class="reqn">g(t)</code> (with respect to time). It must
accept the same arguments as <code>g</code>, for instance a <em>vector</em>
of time points (not just a single one).</p>
</td></tr>
<tr><td><code id="twinstim_tiaf_+3A_deriv">deriv</code></td>
<td>
<p>optional derivative of <code class="reqn">g(t)</code> <em>with respect to
the parameters</em>. It takes the same arguments as <code>g</code> but
returns a matrix with as many rows as there were time points in the
input and <code>npars</code> columns. This derivative is necessary for the
calculation of the score function in <code>twinstim()</code>, which is
advantageous for the numerical log-likelihood maximization.</p>
</td></tr>
<tr><td><code id="twinstim_tiaf_+3A_deriv">Deriv</code></td>
<td>
<p>optional primitive of <code>deriv</code> (with respect to
time). It must accept the same arguments as <code>deriv</code>, <code>g</code> and
<code>G</code> and returns a matrix with as many rows as there were time
points in the input and <code>npars</code> columns. The integrated
derivative is necessary for the score function in <code>twinstim</code>.</p>
</td></tr>
<tr><td><code id="twinstim_tiaf_+3A_npars">npars</code></td>
<td>
<p>the number of parameters of the temporal interaction
function <code>g</code> (i.e. the length of its second argument).</p>
</td></tr>
<tr><td><code id="twinstim_tiaf_+3A_validpars">validpars</code></td>
<td>

<p>optional function taking one argument, the parameter vector, indicating if it
is valid. This approach to specify parameter constraints is rarely
needed, because usual box-constrained parameters can be taken into
account by using L-BFGS-B as the optimization method in
<code>twinstim</code> (with arguments <code>lower</code> and <code>upper</code>), and
positivity constraints by using log-parametrizations.
This component is not necessary (and ignored) if <code>npars == 0</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of checked arguments.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tiaf.exponential">tiaf.exponential</a></code> for a pre-defined temporal interaction
function, and <code><a href="#topic+siaf">siaf</a></code> for the spatial interaction function.
</p>

<hr>
<h2 id='twinstim_update'>
<code>update</code>-method for <code>"twinstim"</code>
</h2><span id='topic+update.twinstim'></span>

<h3>Description</h3>

<p>Update and (by default) re-fit a <code>"twinstim"</code>. This method is
especially useful if one wants to add the <code>model</code> environment
(which is required for some methods) to a fitted model object a posteriori.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twinstim'
update(object, endemic, epidemic,
       control.siaf, optim.args, model,
       ..., use.estimates = TRUE, evaluate = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twinstim_update_+3A_object">object</code></td>
<td>
<p>a previous <code>"twinstim"</code> fit.</p>
</td></tr>
<tr><td><code id="twinstim_update_+3A_endemic">endemic</code>, <code id="twinstim_update_+3A_epidemic">epidemic</code></td>
<td>
<p>changes to the formulae &ndash; see
<code><a href="stats.html#topic+update.formula">update.formula</a></code> and <code><a href="#topic+twinstim">twinstim</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_update_+3A_control.siaf">control.siaf</code></td>
<td>
<p>a list (see <code><a href="#topic+twinstim">twinstim</a></code>) to replace
the given elements in the original <code>control.siaf</code> list.
If <code>NULL</code>, the original list of control arguments is removed
from the call, i.e., the defaults are used in <code>twinstim</code>.</p>
</td></tr>
<tr><td><code id="twinstim_update_+3A_optim.args">optim.args</code></td>
<td>
<p>see <code><a href="#topic+twinstim">twinstim</a></code>. If a list, it will
modify the original <code>optim.args</code> using <code><a href="utils.html#topic+modifyList">modifyList</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_update_+3A_model">model</code></td>
<td>
<p>see <code><a href="#topic+twinstim">twinstim</a></code>. If this is the only argument
to update, re-fitting is cleverly circumvented.
Enriching the fit by the model environment is, e.g., required for
<code><a href="#topic+intensityplot.twinstim">intensityplot.twinstim</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_update_+3A_...">...</code></td>
<td>
<p>Additional arguments to the call, or arguments with changed
values.<br />
If <code>start</code> values are specified, they need to be in the same
format as in the original call <code>object$call$start</code>,
which is either a named list of named numeric vectors or a named
numeric vector; see the argument description in <code><a href="#topic+twinstim">twinstim</a></code>.</p>
</td></tr>
<tr><td><code id="twinstim_update_+3A_use.estimates">use.estimates</code></td>
<td>
<p>logical indicating if the estimates of
<code>object</code> should be used as initial values for the new fit
(in the <code>start</code> argument of <code>twinstim</code>). Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="twinstim_update_+3A_evaluate">evaluate</code></td>
<td>
<p>If <code>TRUE</code> (default), evaluate the new call else
return the call.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>evaluate = TRUE</code> the re-fitted object, otherwise the updated call.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>
<p>Inspiration and some pieces of code originate from
<code><a href="stats.html#topic+update.default">update.default</a></code> by the R Core Team.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+update.default">update.default</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("imdepi", "imdepifit")

## add another epidemic covariate
## (but fix siaf-parameter so that this example runs quickly)
imdepifit2 &lt;- update(imdepifit, epidemic = ~. + log(popdensity),
                     optim.args = list(fixed="e.siaf.1"))

## compare by AIC
AIC(imdepifit, imdepifit2)
</code></pre>

<hr>
<h2 id='unionSpatialPolygons'>
Compute the Unary Union of <code>"SpatialPolygons"</code>
</h2><span id='topic+unionSpatialPolygons'></span>

<h3>Description</h3>

<p>Union all subpolygons of a
<code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code> object.
This is a legacy wrapper for the polygon clipping engines implemented by
packages <span class="pkg">sf</span> and <span class="pkg">polyclip</span>.
Internally, both <code>method</code>s need to convert the input polygons to a
class appropriate for the <code>method</code>, so are rather inefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unionSpatialPolygons(SpP, method = c("sf", "polyclip"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unionSpatialPolygons_+3A_spp">SpP</code></td>
<td>

<p>an object of class
<code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>.
For the <span class="pkg">polyclip</span> <code>method</code> only, all polygon classes for
which an <code>xylist</code>-method exists should work as input.
</p>
</td></tr>
<tr><td><code id="unionSpatialPolygons_+3A_method">method</code></td>
<td>

<p>polygon clipping machinery to use. Default is to call
<code><a href="sf.html#topic+st_union">st_union</a></code> in package <span class="pkg">sf</span>.
For <code>method="polyclip"</code>, function
<code><a href="polyclip.html#topic+polyclip">polyclip</a></code> from package <span class="pkg">polyclip</span> is used.
The old <code>method="gpclib"</code> is no longer available.
</p>
</td></tr>
<tr><td><code id="unionSpatialPolygons_+3A_...">...</code></td>
<td>
<p>further arguments passed to the chosen <code>method</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class
<code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code> representing
the union of all subpolygons.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="sf.html#topic+st_union">st_union</a></code> in package <span class="pkg">sf</span>,
<code><a href="polyclip.html#topic+polyclip">polyclip</a></code> in package <span class="pkg">polyclip</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load districts of Germany
load(system.file("shapes", "districtsD.RData", package = "surveillance"))
plot(districtsD, border = "gray", asp = 1)  

## Union these districts using either "sf" or "polyclip"
if (requireNamespace("sf"))  {
    stateD &lt;- unionSpatialPolygons(districtsD, method = "sf")
    plot(stateD, add = TRUE, border = 2, lwd = 2)
}
if (requireNamespace("polyclip")) {
    stateD_pc &lt;- unionSpatialPolygons(districtsD, method = "polyclip")
    plot(stateD_pc, add = TRUE, border = 1, lwd = 2, lty = 2)
}
</code></pre>

<hr>
<h2 id='untie'>
Randomly Break Ties in Data
</h2><span id='topic+untie'></span><span id='topic+untie.epidataCS'></span><span id='topic+untie.matrix'></span><span id='topic+untie.default'></span>

<h3>Description</h3>

<p>This is a generic function intended to randomly break tied data in a
way similar to what <code><a href="base.html#topic+jitter">jitter</a></code> does: tie-breaking is
performed by shifting <em>all</em> data points by a random amount.
The <span class="pkg">surveillance</span> package defines methods for matrices,
<code>"epidataCS"</code>, and a default method for numeric vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>untie(x, amount, ...)

## S3 method for class 'epidataCS'
untie(x, amount = list(t=NULL, s=NULL),
      minsep = list(t=0, s=0), direction = "left", keep.sources = FALSE,
      ..., verbose = FALSE)
## S3 method for class 'matrix'
untie(x, amount = NULL, minsep = 0,
      constraint = NULL, giveup = 1000, ...)
## Default S3 method:
untie(x, amount = NULL, minsep = 0,
      direction = c("symmetric", "left", "right"), sort = NULL,
      giveup = 1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="untie_+3A_x">x</code></td>
<td>

<p>the data to be untied.
</p>
</td></tr>
<tr><td><code id="untie_+3A_amount">amount</code></td>
<td>

<p>upper bound for the random amount by which data are shifted.
<code>NULL</code> means to use a data-driven default, which equals
the minimum separation of the data points for the non-symmetric
default method and its half for the symmetric default method and the
<code>matrix</code> method. 
</p>
</td></tr>
<tr><td><code id="untie_+3A_minsep">minsep</code></td>
<td>
<p>minimum separation of jittered points. Can only be
obeyed if much smaller than <code>amount</code> (also depending on the
number of points). <code>minsep&gt;0</code> is currently only implemented for
the spatial (matrix) method.</p>
</td></tr>
<tr><td><code id="untie_+3A_keep.sources">keep.sources</code></td>
<td>

<p>logical (<code>FALSE</code>). If <code>TRUE</code>, the original list of
possible event sources in <code>x$events$.sources</code> will be
preserved. For instance, events observed at the same time did by
definition not trigger each other; however, after random
tie-breaking one event will precede the other and considered as a
potential source of infection for the latter, although it could just
as well be the other way round. Enabling <code>keep.sources</code> will
use the <code>.sources</code> list from the original (tied)
<code>"epidataCS"</code> object. Note, however, that an update is forced
within <code>twinstim</code> if a subset of the data is selected
for model fitting or if a different <code>qmatrix</code> is supplied.
</p>
</td></tr>
<tr><td><code id="untie_+3A_constraint">constraint</code></td>
<td>

<p>an object of class <code>"<a href="sp.html#topic+SpatialPolygons-class">SpatialPolygons</a>"</code>
representing the domain which the points of the matrix should belong
to &ndash; before and after jittering.
</p>
</td></tr>
<tr><td><code id="untie_+3A_giveup">giveup</code></td>
<td>
<p>number of attempts after which the
algorithm should stop trying to generate new points.</p>
</td></tr>
<tr><td><code id="untie_+3A_direction">direction</code></td>
<td>

<p>one of <code>"symmetric"</code> (default), <code>"left"</code>, or
<code>"right"</code>, indicating in which direction vector elements should
be shifted.
</p>
</td></tr>
<tr><td><code id="untie_+3A_sort">sort</code></td>
<td>

<p>logical indicating if the jittered vector should be sorted. Defaults
to doing so if the original vector was already sorted.
</p>
</td></tr>
<tr><td><code id="untie_+3A_...">...</code></td>
<td>

<p>For the <code>"epidataCS"</code>-method: arguments passed to the
<code>matrix</code>- or <code>default</code>-method (<code>giveup</code>).
Unused in other methods.
</p>
</td></tr>
<tr><td><code id="untie_+3A_verbose">verbose</code></td>
<td>
<p>logical passed to <code><a href="#topic+as.epidataCS">as.epidataCS</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For numeric vectors (default method), the jittered version is the
same as for <code><a href="base.html#topic+jitter">jitter</a>(x, amount=amount)</code>, if
<code>direction="symmetric"</code> (and <code>amount</code> is non-<code>NULL</code>),
and otherwise uses
<code>x</code> &ldquo;+-&rdquo; <code>runif(length(x), 0, amount)</code>.
</p>
<p>For matrices, a vector uniformly drawn from the disc with radius
<code>amount</code> is added to each point (row).
</p>
<p>For <code>"epidataCS"</code>, <code>amount</code> is a list stating the amounts
for the temporal and/or spatial dimension, respectively. It then
uses the specific methods with arguments <code>constraint=x$W</code>,
<code>direction</code>, and <code>sort=TRUE</code>. Note that this implements a
simplistic approach of tie-breaking where all events are assumed to be
subject to the same amounts of censoring, and the default amounts may
not be sensible choices.
</p>


<h3>Value</h3>

<p>the untied (jittered) data.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+jitter">jitter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># vector example
set.seed(123)
untie(c(rep(1,3), rep(1.2, 4), rep(3,3)), direction="left", sort=FALSE)

# spatial example
data(imdepi)
coords &lt;- coordinates(imdepi$events)
table(duplicated(coords))
plot(coords, cex=sqrt(multiplicity(coords)))
set.seed(1)
coords_untied &lt;- untie(coords)
stopifnot(!anyDuplicated(coords_untied))
points(coords_untied, col=2) # shifted by very small amount in this case
</code></pre>

<hr>
<h2 id='wrap.algo'>Multivariate Surveillance through independent univariate algorithms</h2><span id='topic+wrap.algo'></span><span id='topic+bayes'></span><span id='topic+rki'></span><span id='topic+cusum'></span><span id='topic+glrpois'></span><span id='topic+glrnb'></span><span id='topic+outbreakP'></span>

<h3>Description</h3>

<p>This function takes an <code><a href="#topic+sts">sts</a></code> object and applies an univariate
surveillance algorithm to the time series of each observational unit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
wrap.algo(sts, algo, control,control.hook=function(k, control)
         return(control),verbose=TRUE,...)


bayes(sts, control = list(range = range, b = 0, w = 6,
         actY = TRUE,alpha=0.05),...)
rki(sts, control = list(range = range, b = 2, w = 4,
         actY = FALSE),...)
cusum(sts,  control = list(range=range, k=1.04, h=2.26,
         m=NULL, trans="standard",alpha=NULL),...)
glrpois(sts, control = list(range=range,c.ARL=5, S=1,beta=NULL,
         Mtilde=1, M=-1, change="intercept",theta=NULL),...)
glrnb(sts, control = list(range=range,c.ARL=5, mu0=NULL, alpha=0,
         Mtilde=1, M=-1, change="intercept",
         theta=NULL,dir=c("inc","dec"),
         ret=c("cases","value")),...)
outbreakP(sts, control=list(range = range, k=100,
         ret=c("cases","value"),maxUpperboundCases=1e5),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.algo_+3A_sts">sts</code></td>
<td>
<p>Object of class <code><a href="#topic+sts">sts</a></code></p>
</td></tr>
<tr><td><code id="wrap.algo_+3A_algo">algo</code></td>
<td>
<p>Character string giving the function name of the algorithm
to call, e.g. <code>"algo.farrington"</code>. Calling is done using
<code>do.call</code>.</p>
</td></tr>
<tr><td><code id="wrap.algo_+3A_control">control</code></td>
<td>
<p>Control object as list. Depends on each algorithm.</p>
</td></tr>
<tr><td><code id="wrap.algo_+3A_control.hook">control.hook</code></td>
<td>
<p>This is a function for handling multivariate
objects. This argument is a function function of integer k and the
current control object and which
returns the appropriate control object for region k.</p>
</td></tr>
<tr><td><code id="wrap.algo_+3A_verbose">verbose</code></td>
<td>
<p>Boolean, if <code>TRUE</code> then textual information about the
process is given</p>
</td></tr>
<tr><td><code id="wrap.algo_+3A_...">...</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>sts</code> object with the <code>alarm</code>, <code>upperbound</code>,
etc. slots filled with the results of independent and univariate
surveillance algorithm.
</p>


<h3>Author(s)</h3>

<p>M. Höhle</p>


<h3>See Also</h3>

<p><code><a href="#topic+algo.rki">algo.rki</a></code>, <code><a href="#topic+algo.farrington">algo.farrington</a></code>,
<code><a href="#topic+algo.cusum">algo.cusum</a></code>, <code><a href="#topic+algo.glrpois">algo.glrpois</a></code>,
<code><a href="#topic+algo.glrnb">algo.glrnb</a></code>, <code><a href="#topic+algo.outbreakP">algo.outbreakP</a></code>
for the exact form of the <code>control</code> object.
</p>

<hr>
<h2 id='zetaweights'>
Power-Law Weights According to Neighbourhood Order
</h2><span id='topic+zetaweights'></span>

<h3>Description</h3>

<p>Compute power-law weights with decay parameter <code>d</code>
based on a matrix of neighbourhood orders <code>nbmat</code>
(e.g., as obtained via <code><a href="#topic+nbOrder">nbOrder</a></code>).
Without normalization and truncation,
this is just <code class="reqn">o^{-d}</code> (where <code class="reqn">o</code> is a neighbourhood order).
This function is mainly used internally for <code><a href="#topic+W_powerlaw">W_powerlaw</a></code>
weights in <code><a href="#topic+hhh4">hhh4</a></code> models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zetaweights(nbmat, d = 1, maxlag = max(nbmat), normalize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zetaweights_+3A_nbmat">nbmat</code></td>
<td>
<p>numeric, symmetric matrix of neighbourhood orders.</p>
</td></tr>
<tr><td><code id="zetaweights_+3A_d">d</code></td>
<td>
<p>single numeric decay parameter (default: 1). Should be
positive.</p>
</td></tr>
<tr><td><code id="zetaweights_+3A_maxlag">maxlag</code></td>
<td>
<p>single numeric specifying an upper limit for the power
law. For neighbourhood orders &gt; <code>maxlag</code>, the resulting weight
is 0. Defaults to no truncation.</p>
</td></tr>
<tr><td><code id="zetaweights_+3A_normalize">normalize</code></td>
<td>
<p>Should the resulting weight matrix be normalized such
that rows sum to 1?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric matrix with same dimensions and names as the input matrix.
</p>


<h3>Author(s)</h3>

<p>Sebastian Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+W_powerlaw">W_powerlaw</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>nbmat &lt;- matrix(c(0,1,2,2,
                  1,0,1,1,
                  2,1,0,2,
                  2,1,2,0), 4, 4, byrow=TRUE)
zetaweights(nbmat, d=1, normalize=FALSE) # harmonic: o^-1
zetaweights(nbmat, d=1, normalize=TRUE)  # rowSums=1
zetaweights(nbmat, maxlag=1, normalize=FALSE) # results in adjacency matrix
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
