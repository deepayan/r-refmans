<!DOCTYPE html><html><head><title>Help for package glmnet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {glmnet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#assess.glmnet'><p>assess performance of a 'glmnet' object using test data.</p></a></li>
<li><a href='#beta_CVX'><p>Simulated data for the glmnet vignette</p></a></li>
<li><a href='#bigGlm'><p>fit a glm with all the options in <code>glmnet</code></p></a></li>
<li><a href='#BinomialExample'><p>Synthetic dataset with binary response</p></a></li>
<li><a href='#Cindex'><p>compute C index for a Cox model</p></a></li>
<li><a href='#coef.glmnet'><p>Extract coefficients from a glmnet object</p></a></li>
<li><a href='#cox_obj_function'><p>Elastic net objective function value for Cox regression model</p></a></li>
<li><a href='#cox.fit'><p>Fit a Cox regression model with elastic net regularization for a single</p>
value of lambda</a></li>
<li><a href='#cox.path'><p>Fit a Cox regression model with elastic net regularization for a path of</p>
lambda values</a></li>
<li><a href='#CoxExample'><p>Synthetic dataset with right-censored survival response</p></a></li>
<li><a href='#coxgrad'><p>Compute gradient for Cox model</p></a></li>
<li><a href='#coxnet.deviance'><p>Compute deviance for Cox model</p></a></li>
<li><a href='#cv.glmnet'><p>Cross-validation for glmnet</p></a></li>
<li><a href='#dev_function'><p>Elastic net deviance value</p></a></li>
<li><a href='#deviance.glmnet'><p>Extract the deviance from a glmnet object</p></a></li>
<li><a href='#elnet.fit'><p>Solve weighted least squares (WLS) problem for a single lambda value</p></a></li>
<li><a href='#fid'><p>Helper function for Cox deviance and gradient</p></a></li>
<li><a href='#get_cox_lambda_max'><p>Get lambda max for Cox regression model</p></a></li>
<li><a href='#get_eta'><p>Helper function to get etas (linear predictions)</p></a></li>
<li><a href='#get_start'><p>Get null deviance, starting mu and lambda max</p></a></li>
<li><a href='#glmnet'><p>fit a GLM with lasso or elasticnet regularization</p></a></li>
<li><a href='#glmnet-internal'><p>Internal glmnet functions</p></a></li>
<li><a href='#glmnet-package'><p>Elastic net model paths for some generalized linear models</p></a></li>
<li><a href='#glmnet.control'><p>internal glmnet parameters</p></a></li>
<li><a href='#glmnet.fit'><p>Fit a GLM with elastic net regularization for a single value of lambda</p></a></li>
<li><a href='#glmnet.measures'><p>Display the names of the measures used in CV for different &quot;glmnet&quot; families</p></a></li>
<li><a href='#glmnet.path'><p>Fit a GLM with elastic net regularization for a path of lambda values</p></a></li>
<li><a href='#makeX'><p>convert a data frame to a data matrix with one-hot encoding</p></a></li>
<li><a href='#MultiGaussianExample'><p>Synthetic dataset with multiple Gaussian responses</p></a></li>
<li><a href='#MultinomialExample'><p>Synthetic dataset with multinomial response</p></a></li>
<li><a href='#mycoxph'><p>Helper function to fit coxph model for survfit.coxnet</p></a></li>
<li><a href='#mycoxpred'><p>Helper function to amend ... for new data in survfit.coxnet</p></a></li>
<li><a href='#na.replace'><p>Replace the missing entries in a matrix columnwise with the entries in a</p>
supplied vector</a></li>
<li><a href='#obj_function'><p>Elastic net objective function value</p></a></li>
<li><a href='#pen_function'><p>Elastic net penalty value</p></a></li>
<li><a href='#plot.cv.glmnet'><p>plot the cross-validation curve produced by cv.glmnet</p></a></li>
<li><a href='#plot.glmnet'><p>plot coefficients from a &quot;glmnet&quot; object</p></a></li>
<li><a href='#PoissonExample'><p>Synthetic dataset with count response</p></a></li>
<li><a href='#predict.cv.glmnet'><p>make predictions from a &quot;cv.glmnet&quot; object.</p></a></li>
<li><a href='#predict.glmnetfit'><p>Get predictions from a <code>glmnetfit</code> fit object</p></a></li>
<li><a href='#print.cv.glmnet'><p>print a cross-validated glmnet object</p></a></li>
<li><a href='#print.glmnet'><p>print a glmnet object</p></a></li>
<li><a href='#QuickStartExample'><p>Synthetic dataset with Gaussian response</p></a></li>
<li><a href='#response.coxnet'><p>Make response for coxnet</p></a></li>
<li><a href='#rmult'><p>Generate multinomial samples from a probability matrix</p></a></li>
<li><a href='#SparseExample'><p>Synthetic dataset with sparse design matrix</p></a></li>
<li><a href='#stratifySurv'><p>Add strata to a Surv object</p></a></li>
<li><a href='#survfit.coxnet'><p>Compute a survival curve from a coxnet object</p></a></li>
<li><a href='#survfit.cv.glmnet'><p>Compute a survival curve from a cv.glmnet object</p></a></li>
<li><a href='#use.cox.path'><p>Check if glmnet should call cox.path</p></a></li>
<li><a href='#weighted_mean_sd'><p>Helper function to compute weighted mean and standard deviation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Lasso and Elastic-Net Regularized Generalized Linear Models</td>
</tr>
<tr>
<td>Version:</td>
<td>4.1-8</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-19</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0), Matrix (&ge; 1.0-6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, utils, foreach, shape, survival, Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, lars, testthat, xfun, rmarkdown</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>Description:</td>
<td>Extremely efficient procedures for fitting the entire lasso or elastic-net regularization path for linear regression, logistic and multinomial regression models, Poisson regression, Cox model,  multiple-response Gaussian, and the grouped multinomial regression; see &lt;<a href="https://doi.org/10.18637%2Fjss.v033.i01">doi:10.18637/jss.v033.i01</a>&gt; and &lt;<a href="https://doi.org/10.18637%2Fjss.v039.i05">doi:10.18637/jss.v039.i05</a>&gt;. There are two new and important additions. The family argument can be a GLM family object, which opens the door to any programmed family (&lt;<a href="https://doi.org/10.18637%2Fjss.v106.i01">doi:10.18637/jss.v106.i01</a>&gt;). This comes with a modest computational cost, so when the built-in families suffice, they should be used instead.  The other novelty is the relax option, which refits each of the active sets in the path unpenalized. The algorithm uses cyclical coordinate descent in a path-wise fashion, as described in the papers cited.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://glmnet.stanford.edu">https://glmnet.stanford.edu</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>RcppEigen, Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-20 00:30:42 UTC; hastie</td>
</tr>
<tr>
<td>Author:</td>
<td>Jerome Friedman [aut],
  Trevor Hastie [aut, cre],
  Rob Tibshirani [aut],
  Balasubramanian Narasimhan [aut],
  Kenneth Tay [aut],
  Noah Simon [aut],
  Junyang Qian [ctb],
  James Yang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Trevor Hastie &lt;hastie@stanford.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-22 03:10:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='assess.glmnet'>assess performance of a 'glmnet' object using test data.</h2><span id='topic+assess.glmnet'></span><span id='topic+confusion.glmnet'></span><span id='topic+roc.glmnet'></span>

<h3>Description</h3>

<p>Given a test set, produce summary performance measures for the glmnet
model(s)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assess.glmnet(
  object,
  newx = NULL,
  newy,
  weights = NULL,
  family = c("gaussian", "binomial", "poisson", "multinomial", "cox", "mgaussian"),
  ...
)

confusion.glmnet(
  object,
  newx = NULL,
  newy,
  family = c("binomial", "multinomial"),
  ...
)

roc.glmnet(object, newx = NULL, newy, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assess.glmnet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"glmnet"</code> or <code>"cv.glmnet"</code>, <code>"relaxed"</code>
or <code>"cv.relaxed"</code> object, OR a matrix of predictions (for
<code>roc.glmnet</code> or <code>assess.glmnet</code>). For <code>roc.glmnet</code> the model
must be a 'binomial', and for <code>confusion.glmnet</code> must be either
'binomial' or 'multinomial'</p>
</td></tr>
<tr><td><code id="assess.glmnet_+3A_newx">newx</code></td>
<td>
<p>If predictions are to made, these are the 'x' values. Required
for <code>confusion.glmnet</code></p>
</td></tr>
<tr><td><code id="assess.glmnet_+3A_newy">newy</code></td>
<td>
<p>required argument for all functions; the new response values</p>
</td></tr>
<tr><td><code id="assess.glmnet_+3A_weights">weights</code></td>
<td>
<p>For observation weights for the test observations</p>
</td></tr>
<tr><td><code id="assess.glmnet_+3A_family">family</code></td>
<td>
<p>The family of the model, in case predictions are passed in as
'object'</p>
</td></tr>
<tr><td><code id="assess.glmnet_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>predict.glmnet</code> when &quot;object&quot; is a
&quot;glmnet&quot; fit, and predictions must be made to produce the statistics.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>assess.glmnet</code> produces all the different performance measures
provided by <code>cv.glmnet</code> for each of the families. A single vector, or a
matrix of predictions can be provided, or fitted model objects or CV
objects. In the case when the predictions are still to be made, the
<code>...</code> arguments allow, for example, 'offsets' and other prediction
parameters such as values for 'gamma' for 'relaxed' fits.  <code>roc.glmnet</code>
produces for a single vector a two column matrix with columns TPR and FPR
(true positive rate and false positive rate). This object can be plotted to
produce an ROC curve. If more than one predictions are called for, then a
list of such matrices is produced.  <code>confusion.glmnet</code> produces a
confusion matrix tabulating the classification results. Again, a single
table or a list, with a print method.
</p>


<h3>Value</h3>

<p><code>assess.glmnet</code> produces a list of vectors of measures.
<code>roc.glmnet</code> a list of 'roc' two-column matrices, and
<code>confusion.glmnet</code> a list of tables. If a single prediction is
provided, or predictions are made from a CV object, the latter two drop the
list status and produce a single matrix or table.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and Rob Tibshirani<br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>cv.glmnet</code>, <code>glmnet.measures</code> and <code>vignette("relax",package="glmnet")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(QuickStartExample)
x &lt;- QuickStartExample$x; y &lt;- QuickStartExample$y
set.seed(11)
train = sample(seq(length(y)),70,replace=FALSE)
fit1 = glmnet(x[train,], y[train])
assess.glmnet(fit1, newx = x[-train,], newy = y[-train])
preds = predict(fit1, newx = x[-train, ], s = c(1, 0.25))
assess.glmnet(preds, newy = y[-train], family = "gaussian")
fit1c = cv.glmnet(x, y, keep = TRUE)
fit1a = assess.glmnet(fit1c$fit.preval, newy=y,family="gaussian")
plot(fit1c$lambda, log="x",fit1a$mae,xlab="Log Lambda",ylab="Mean Absolute Error")
abline(v=fit1c$lambda.min, lty=2, col="red")
data(BinomialExample)
x &lt;- BinomialExample$x; y &lt;- BinomialExample$y
fit2 = glmnet(x[train,], y[train], family = "binomial")
assess.glmnet(fit2,newx = x[-train,], newy=y[-train], s=0.1)
plot(roc.glmnet(fit2, newx = x[-train,], newy=y[-train])[[10]])
fit2c = cv.glmnet(x, y, family = "binomial", keep=TRUE)
idmin = match(fit2c$lambda.min, fit2c$lambda)
plot(roc.glmnet(fit2c$fit.preval, newy = y)[[idmin]])
data(MultinomialExample)
x &lt;- MultinomialExample$x; y &lt;- MultinomialExample$y
set.seed(103)
train = sample(seq(length(y)),100,replace=FALSE)
fit3 = glmnet(x[train,], y[train], family = "multinomial")
confusion.glmnet(fit3, newx = x[-train, ], newy = y[-train], s = 0.01)
fit3c = cv.glmnet(x, y, family = "multinomial", type.measure="class", keep=TRUE)
idmin = match(fit3c$lambda.min, fit3c$lambda)
confusion.glmnet(fit3c$fit.preval, newy = y, family="multinomial")[[idmin]]

</code></pre>

<hr>
<h2 id='beta_CVX'>Simulated data for the glmnet vignette</h2><span id='topic+beta_CVX'></span><span id='topic+x'></span><span id='topic+y'></span>

<h3>Description</h3>

<p>Simple simulated data, used to demonstrate the features of glmnet
</p>


<h3>Format</h3>

<p>Data objects used to demonstrate features in the glmnet vignette
</p>


<h3>Details</h3>

<p>These datasets are artificial, and are used to test out some of the
features of glmnet.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(QuickStartExample)
x &lt;- QuickStartExample$x; y &lt;- QuickStartExample$y
glmnet(x, y)

</code></pre>

<hr>
<h2 id='bigGlm'>fit a glm with all the options in <code>glmnet</code></h2><span id='topic+bigGlm'></span>

<h3>Description</h3>

<p>Fit a generalized linear model as in <code>glmnet</code> but unpenalized. This
allows all the features of <code>glmnet</code> such as sparse x, bounds on
coefficients, offsets, and so on.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bigGlm(x, ..., path = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bigGlm_+3A_x">x</code></td>
<td>
<p>input matrix</p>
</td></tr>
<tr><td><code id="bigGlm_+3A_...">...</code></td>
<td>
<p>Most other arguments to glmnet that make sense</p>
</td></tr>
<tr><td><code id="bigGlm_+3A_path">path</code></td>
<td>
<p>Since <code>glmnet</code> does not do stepsize optimization, the Newton
algorithm can get stuck and not converge, especially with unpenalized fits. With <code>path=TRUE</code>,
the  fit computed with pathwise lasso regularization. The current implementation does this twice:
the first time to get the lambda sequence, and the second time with a zero attached to the end).
Default is <code>path=FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is essentially the same as fitting a &quot;glmnet&quot; model with a single value
<code>lambda=0</code>, but it avoids some edge cases. CAVEAT: If the user tries a
problem with N smaller than or close to p for some models, it is likely to
fail (and maybe not gracefully!) If so, use the <code>path=TRUE</code> argument.
</p>


<h3>Value</h3>

<p>It returns an object of class &quot;bigGlm&quot; that inherits from class
&quot;glmnet&quot;. That means it can be predicted from, coefficients extracted via
<code>coef</code>. It has its own print method.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie<br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>print</code>, <code>predict</code>, and <code>coef</code> methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Gaussian
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit1 = bigGlm(x, y)
print(fit1)

fit2=bigGlm(x,y&gt;0,family="binomial")
print(fit2)
fit2p=bigGlm(x,y&gt;0,family="binomial",path=TRUE)
print(fit2p)

</code></pre>

<hr>
<h2 id='BinomialExample'>Synthetic dataset with binary response</h2><span id='topic+BinomialExample'></span>

<h3>Description</h3>

<p>Randomly generated data for binomial regression example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BinomialExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>x</dt><dd><p>100 by 30 matrix of numeric values.</p>
</dd>
<dt>y</dt><dd><p>Numeric vector of length 100 containing 44 zeros and 56 ones.</p>
</dd>
</dl>


<hr>
<h2 id='Cindex'>compute C index for a Cox model</h2><span id='topic+Cindex'></span>

<h3>Description</h3>

<p>Computes Harrel's C index for predictions from a <code>"coxnet"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cindex(pred, y, weights = rep(1, nrow(y)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cindex_+3A_pred">pred</code></td>
<td>
<p>Predictions from a <code>"coxnet"</code> object</p>
</td></tr>
<tr><td><code id="Cindex_+3A_y">y</code></td>
<td>
<p>a survival response object - a matrix with two columns &quot;time&quot; and
&quot;status&quot;; see documentation for &quot;glmnet&quot;</p>
</td></tr>
<tr><td><code id="Cindex_+3A_weights">weights</code></td>
<td>
<p>optional observation weights</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the concordance index, taking into account censoring.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie  <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Harrel Jr, F. E. and Lee, K. L. and Mark, D. B. (1996)
<em>Tutorial in biostatistics: multivariable prognostic models: issues in
developing models, evaluating assumptions and adequacy, and measuring and
reducing error</em>, Statistics in Medicine, 15, pages 361&ndash;387.
</p>


<h3>See Also</h3>

<p><code>cv.glmnet</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(10101)
N = 1000
p = 30
nzc = p/3
x = matrix(rnorm(N * p), N, p)
beta = rnorm(nzc)
fx = x[, seq(nzc)] %*% beta/3
hx = exp(fx)
ty = rexp(N, hx)
tcens = rbinom(n = N, prob = 0.3, size = 1)  # censoring indicator
y = cbind(time = ty, status = 1 - tcens)  # y=Surv(ty,1-tcens) with library(survival)
fit = glmnet(x, y, family = "cox")
pred = predict(fit, newx = x)
apply(pred, 2, Cindex, y=y)
cv.glmnet(x, y, family = "cox", type.measure = "C")

</code></pre>

<hr>
<h2 id='coef.glmnet'>Extract coefficients from a glmnet object</h2><span id='topic+coef.glmnet'></span><span id='topic+predict.glmnet'></span><span id='topic+coef.relaxed'></span><span id='topic+predict.relaxed'></span><span id='topic+predict.elnet'></span><span id='topic+predict.lognet'></span><span id='topic+predict.multnet'></span><span id='topic+predict.mrelnet'></span><span id='topic+predict.fishnet'></span><span id='topic+predict.coxnet'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this functions predicts fitted values,
logits, coefficients and more from a fitted <code>"glmnet"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmnet'
coef(object, s = NULL, exact = FALSE, ...)

## S3 method for class 'glmnet'
predict(
  object,
  newx,
  s = NULL,
  type = c("link", "response", "coefficients", "nonzero", "class"),
  exact = FALSE,
  newoffset,
  ...
)

## S3 method for class 'relaxed'
predict(
  object,
  newx,
  s = NULL,
  gamma = 1,
  type = c("link", "response", "coefficients", "nonzero", "class"),
  exact = FALSE,
  newoffset,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.glmnet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"glmnet"</code> model object or a <code>"relaxed"</code>
model (which inherits from class &quot;glmnet&quot;).</p>
</td></tr>
<tr><td><code id="coef.glmnet_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter <code>lambda</code> at which
predictions are required. Default is the entire sequence used to create the
model.</p>
</td></tr>
<tr><td><code id="coef.glmnet_+3A_exact">exact</code></td>
<td>
<p>This argument is relevant only when predictions are made at
values of <code>s</code> (lambda) <em>different</em> from those used in the fitting
of the original model. Not available for <code>"relaxed"</code> objects. If
<code>exact=FALSE</code> (default), then the predict function uses linear
interpolation to make predictions for values of <code>s</code> (lambda) that do
not coincide with those used in the fitting algorithm. While this is often a
good approximation, it can sometimes be a bit coarse.  With
<code>exact=TRUE</code>, these different values of <code>s</code> are merged (and
sorted) with <code>object$lambda</code>, and the model is refit before predictions
are made. In this case, it is required to supply the original data <code>x=</code>
and <code>y=</code> as additional named arguments to <code>predict()</code> or
<code>coef()</code>.  The workhorse <code>predict.glmnet()</code> needs to <code>update</code>
the model, and so needs the data used to create it. The same is true of
<code>weights</code>, <code>offset</code>, <code>penalty.factor</code>, <code>lower.limits</code>,
<code>upper.limits</code> if these were used in the original call. Failure to do
so will result in an error.</p>
</td></tr>
<tr><td><code id="coef.glmnet_+3A_...">...</code></td>
<td>
<p>This is the mechanism for passing arguments like <code>x=</code> when
<code>exact=TRUE</code>; see<code>exact</code> argument.</p>
</td></tr>
<tr><td><code id="coef.glmnet_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be
made. Must be a matrix; can be sparse as in <code>Matrix</code> package. This
argument is not used for <code>type=c("coefficients","nonzero")</code></p>
</td></tr>
<tr><td><code id="coef.glmnet_+3A_type">type</code></td>
<td>
<p>Type of prediction required. Type <code>"link"</code> gives the linear
predictors for <code>"binomial"</code>, <code>"multinomial"</code>, <code>"poisson"</code> or
<code>"cox"</code> models; for <code>"gaussian"</code> models it gives the fitted
values. Type <code>"response"</code> gives the fitted probabilities for
<code>"binomial"</code> or <code>"multinomial"</code>, fitted mean for <code>"poisson"</code>
and the fitted relative-risk for <code>"cox"</code>; for <code>"gaussian"</code> type
<code>"response"</code> is equivalent to type <code>"link"</code>. Type
<code>"coefficients"</code> computes the coefficients at the requested values for
<code>s</code>.  Note that for <code>"binomial"</code> models, results are returned only
for the class corresponding to the second level of the factor response.
Type <code>"class"</code> applies only to <code>"binomial"</code> or
<code>"multinomial"</code> models, and produces the class label corresponding to
the maximum probability. Type <code>"nonzero"</code> returns a list of the indices
of the nonzero coefficients for each value of <code>s</code>.</p>
</td></tr>
<tr><td><code id="coef.glmnet_+3A_newoffset">newoffset</code></td>
<td>
<p>If an offset is used in the fit, then one must be supplied
for making predictions (except for <code>type="coefficients"</code> or
<code>type="nonzero"</code>)</p>
</td></tr>
<tr><td><code id="coef.glmnet_+3A_gamma">gamma</code></td>
<td>
<p>Single value of <code>gamma</code> at which predictions are required,
for &quot;relaxed&quot; objects.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The shape of the objects returned are different for <code>"multinomial"</code>
objects. This function actually calls <code>NextMethod()</code>, and the
appropriate predict method is invoked for each of the three model types.
<code>coef(...)</code> is equivalent to <code>predict(type="coefficients",...)</code>
</p>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie and Rob Tibshirani<br /> Maintainer:
Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.<br />
Glmnet webpage with four vignettes, <a href="https://glmnet.stanford.edu">https://glmnet.stanford.edu</a>.
</p>


<h3>See Also</h3>

<p><code>glmnet</code>, and <code>print</code>, and <code>coef</code> methods, and
<code>cv.glmnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
g2=sample(1:2,100,replace=TRUE)
g4=sample(1:4,100,replace=TRUE)
fit1=glmnet(x,y)
predict(fit1,newx=x[1:5,],s=c(0.01,0.005))
predict(fit1,type="coef")
fit2=glmnet(x,g2,family="binomial")
predict(fit2,type="response",newx=x[2:5,])
predict(fit2,type="nonzero")
fit3=glmnet(x,g4,family="multinomial")
predict(fit3,newx=x[1:3,],type="response",s=0.01)
</code></pre>

<hr>
<h2 id='cox_obj_function'>Elastic net objective function value for Cox regression model</h2><span id='topic+cox_obj_function'></span>

<h3>Description</h3>

<p>Returns the elastic net objective function value for Cox regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cox_obj_function(y, pred, weights, lambda, alpha, coefficients, vp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cox_obj_function_+3A_y">y</code></td>
<td>
<p>Survival response variable, must be a <code>Surv</code> or
<code>stratifySurv</code> object.</p>
</td></tr>
<tr><td><code id="cox_obj_function_+3A_pred">pred</code></td>
<td>
<p>Model's predictions for <code>y</code>.</p>
</td></tr>
<tr><td><code id="cox_obj_function_+3A_weights">weights</code></td>
<td>
<p>Observation weights.</p>
</td></tr>
<tr><td><code id="cox_obj_function_+3A_lambda">lambda</code></td>
<td>
<p>A single value for the <code>lambda</code> hyperparameter.</p>
</td></tr>
<tr><td><code id="cox_obj_function_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>.</p>
</td></tr>
<tr><td><code id="cox_obj_function_+3A_coefficients">coefficients</code></td>
<td>
<p>The model's coefficients.</p>
</td></tr>
<tr><td><code id="cox_obj_function_+3A_vp">vp</code></td>
<td>
<p>Penalty factors for each of the coefficients.</p>
</td></tr>
</table>

<hr>
<h2 id='cox.fit'>Fit a Cox regression model with elastic net regularization for a single
value of lambda</h2><span id='topic+cox.fit'></span>

<h3>Description</h3>

<p>Fit a Cox regression model via penalized maximum likelihood for a single
value of lambda. Can deal with (start, stop] data and strata, as well as
sparse design matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cox.fit(
  x,
  y,
  weights,
  lambda,
  alpha = 1,
  offset = rep(0, nobs),
  thresh = 1e-10,
  maxit = 1e+05,
  penalty.factor = rep(1, nvars),
  exclude = c(),
  lower.limits = -Inf,
  upper.limits = Inf,
  warm = NULL,
  from.cox.path = FALSE,
  save.fit = FALSE,
  trace.it = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cox.fit_+3A_x">x</code></td>
<td>
<p>Input matrix, of dimension <code>nobs x nvars</code>; each row is an
observation vector. If it is a sparse matrix, it is assumed to be unstandardized.
It should have attributes <code>xm</code> and <code>xs</code>, where <code>xm(j)</code> and
<code>xs(j)</code> are the centering and scaling factors for variable j respsectively.
If it is not a sparse matrix, it is assumed that any standardization needed
has already been done.</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_y">y</code></td>
<td>
<p>Survival response variable, must be a Surv or stratifySurv object.</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_weights">weights</code></td>
<td>
<p>Observation weights. <code>cox.fit</code> does NOT standardize
these weights.</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_lambda">lambda</code></td>
<td>
<p>A single value for the <code>lambda</code> hyperparameter.</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_alpha">alpha</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_offset">offset</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_thresh">thresh</code></td>
<td>
<p>Convergence threshold for coordinate descent. Each inner
coordinate-descent loop continues until the maximum change in the objective
after any coefficient update is less than thresh times the null deviance.
Default value is <code>1e-10</code>.</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of passes over the data; default is <code>10^5</code>.
(If a warm start object is provided, the number of passes the warm start object
performed is included.)</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_exclude">exclude</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_lower.limits">lower.limits</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_upper.limits">upper.limits</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_warm">warm</code></td>
<td>
<p>Either a <code>glmnetfit</code> object or a list (with name <code>beta</code>
containing coefficients) which can be used as a warm start. Default is
<code>NULL</code>, indicating no warm start. For internal use only.</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_from.cox.path">from.cox.path</code></td>
<td>
<p>Was <code>cox.fit()</code> called from <code>cox.path()</code>?
Default is FALSE.This has implications for computation of the penalty factors.</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_save.fit">save.fit</code></td>
<td>
<p>Return the warm start object? Default is FALSE.</p>
</td></tr>
<tr><td><code id="cox.fit_+3A_trace.it">trace.it</code></td>
<td>
<p>Controls how much information is printed to screen. If
<code>trace.it=2</code>, some information about the fitting procedure is printed to
the console as the model is being fitted. Default is <code>trace.it=0</code>
(no information printed). (<code>trace.it=1</code> not used for compatibility with
<code>glmnet.path</code>.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WARNING: Users should not call <code>cox.fit</code> directly. Higher-level
functions in this package call <code>cox.fit</code> as a subroutine. If a
warm start object is provided, some of the other arguments in the function
may be overriden.
</p>
<p><code>cox.fit</code> solves the elastic net problem for a single, user-specified
value of lambda. <code>cox.fit</code> works for Cox regression models, including
(start, stop] data and strata. It solves the problem using iteratively
reweighted least squares (IRLS). For each IRLS iteration, <code>cox.fit</code>
makes a quadratic (Newton) approximation of the log-likelihood, then calls
<code>elnet.fit</code> to minimize the resulting approximation.
</p>
<p>In terms of standardization: <code>cox.fit</code> does not standardize <code>x</code>
and <code>weights</code>. <code>penalty.factor</code> is standardized so that they sum
up to <code>nvars</code>.
</p>


<h3>Value</h3>

<p>An object with class &quot;coxnet&quot;, &quot;glmnetfit&quot; and &quot;glmnet&quot;. The list
returned contains more keys than that of a &quot;glmnet&quot; object.
</p>
<table>
<tr><td><code>a0</code></td>
<td>
<p>Intercept value, <code>NULL</code> for &quot;cox&quot; family.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A <code>nvars x 1</code> matrix of coefficients, stored in sparse matrix
format.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of nonzero coefficients.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Dimension of coefficient matrix.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Lambda value used.</p>
</td></tr>
<tr><td><code>dev.ratio</code></td>
<td>
<p>The fraction of (null) deviance explained. The deviance
calculations incorporate weights if present in the model. The deviance is
defined to be 2*(loglike_sat - loglike), where loglike_sat is the log-likelihood
for the saturated model (a model with a free parameter per observation).
Hence dev.ratio=1-dev/nulldev.</p>
</td></tr>
<tr><td><code>nulldev</code></td>
<td>
<p>Null deviance (per observation). This is defined to be
2*(loglike_sat -loglike(Null)). The null model refers to the 0 model.</p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>Total passes over the data.</p>
</td></tr>
<tr><td><code>jerr</code></td>
<td>
<p>Error flag, for warnings and errors (largely for internal
debugging).</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>A logical variable indicating whether an offset was included
in the model.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code>warm_fit</code></td>
<td>
<p>If <code>save.fit=TRUE</code>, output of C++ routine, used for
warm starts. For internal use only.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>Family used for the model, always &quot;cox&quot;.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>A logical variable: was the algorithm judged to have
converged?</p>
</td></tr>
<tr><td><code>boundary</code></td>
<td>
<p>A logical variable: is the fitted value on the boundary of
the attainable values?</p>
</td></tr>
<tr><td><code>obj_function</code></td>
<td>
<p>Objective function value at the solution.</p>
</td></tr>
</table>

<hr>
<h2 id='cox.path'>Fit a Cox regression model with elastic net regularization for a path of
lambda values</h2><span id='topic+cox.path'></span>

<h3>Description</h3>

<p>Fit a Cox regression model via penalized maximum likelihood for a path of
lambda values. Can deal with (start, stop] data and strata, as well as
sparse design matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cox.path(
  x,
  y,
  weights = NULL,
  offset = NULL,
  alpha = 1,
  nlambda = 100,
  lambda.min.ratio = ifelse(nobs &lt; nvars, 0.01, 1e-04),
  lambda = NULL,
  standardize = TRUE,
  thresh = 1e-10,
  exclude = NULL,
  penalty.factor = rep(1, nvars),
  lower.limits = -Inf,
  upper.limits = Inf,
  maxit = 1e+05,
  trace.it = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cox.path_+3A_x">x</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_y">y</code></td>
<td>
<p>Survival response variable, must be a <code>Surv</code> or
<code>stratifySurv</code> object.</p>
</td></tr>
<tr><td><code id="cox.path_+3A_weights">weights</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_offset">offset</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_alpha">alpha</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_nlambda">nlambda</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_lambda">lambda</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_standardize">standardize</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_thresh">thresh</code></td>
<td>
<p>Convergence threshold for coordinate descent. Each inner
coordinate-descent loop continues until the maximum change in the objective
after any coefficient update is less than thresh times the null deviance.
Default value is <code>1e-10</code>.</p>
</td></tr>
<tr><td><code id="cox.path_+3A_exclude">exclude</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_lower.limits">lower.limits</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_upper.limits">upper.limits</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_maxit">maxit</code></td>
<td>
<p>See glmnet help file</p>
</td></tr>
<tr><td><code id="cox.path_+3A_trace.it">trace.it</code></td>
<td>
<p>Controls how much information is printed to screen. Default is
<code>trace.it=0</code> (no information printed). If <code>trace.it=1</code>, a progress
bar is displayed. If <code>trace.it=2</code>, some information about the fitting
procedure is printed to the console as the model is being fitted.</p>
</td></tr>
<tr><td><code id="cox.path_+3A_...">...</code></td>
<td>
<p>Other arguments passed from glmnet (not used right now).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sometimes the sequence is truncated before <code>nlambda</code> values of lambda
have been used. This happens when <code>cox.path</code> detects that the
decrease in deviance is marginal (i.e. we are near a saturated fit).
</p>


<h3>Value</h3>

<p>An object of class &quot;coxnet&quot; and &quot;glmnet&quot;.
</p>
<table>
<tr><td><code>a0</code></td>
<td>
<p>Intercept value, <code>NULL</code> for &quot;cox&quot; family.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A <code>nvars x length(lambda)</code> matrix of coefficients, stored in
sparse matrix format.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of nonzero coefficients for each value of lambda.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Dimension of coefficient matrix.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The actual sequence of lambda values used. When alpha=0, the
largest lambda reported does not quite give the zero coefficients reported
(lambda=inf would in principle). Instead, the largest lambda for alpha=0.001
is used, and the sequence of lambda values is derived from this.</p>
</td></tr>
<tr><td><code>dev.ratio</code></td>
<td>
<p>The fraction of (null) deviance explained. The deviance
calculations incorporate weights if present in the model. The deviance is
defined to be 2*(loglike_sat - loglike), where loglike_sat is the log-likelihood
for the saturated model (a model with a free parameter per observation).
Hence dev.ratio=1-dev/nulldev.</p>
</td></tr>
<tr><td><code>nulldev</code></td>
<td>
<p>Null deviance (per observation). This is defined to be
2*(loglike_sat -loglike(Null)). The null model refers to the 0 model.</p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>Total passes over the data summed over all lambda values.</p>
</td></tr>
<tr><td><code>jerr</code></td>
<td>
<p>Error flag, for warnings and errors (largely for internal
debugging).</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>A logical variable indicating whether an offset was included
in the model.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2)
nobs &lt;- 100; nvars &lt;- 15
xvec &lt;- rnorm(nobs * nvars)
xvec[sample.int(nobs * nvars, size = 0.4 * nobs * nvars)] &lt;- 0
x &lt;- matrix(xvec, nrow = nobs)
beta &lt;- rnorm(nvars / 3)
fx &lt;- x[, seq(nvars / 3)] %*% beta / 3
ty &lt;- rexp(nobs, exp(fx))
tcens &lt;- rbinom(n = nobs, prob = 0.3, size = 1)
jsurv &lt;- survival::Surv(ty, tcens)
fit1 &lt;- glmnet:::cox.path(x, jsurv)

# works with sparse x matrix
x_sparse &lt;- Matrix::Matrix(x, sparse = TRUE)
fit2 &lt;- glmnet:::cox.path(x_sparse, jsurv)

# example with (start, stop] data
set.seed(2)
start_time &lt;- runif(100, min = 0, max = 5)
stop_time &lt;- start_time + runif(100, min = 0.1, max = 3)
status &lt;- rbinom(n = nobs, prob = 0.3, size = 1)
jsurv_ss &lt;- survival::Surv(start_time, stop_time, status)
fit3 &lt;- glmnet:::cox.path(x, jsurv_ss)

# example with strata
jsurv_ss2 &lt;- stratifySurv(jsurv_ss, rep(1:2, each = 50))
fit4 &lt;- glmnet:::cox.path(x, jsurv_ss2)
</code></pre>

<hr>
<h2 id='CoxExample'>Synthetic dataset with right-censored survival response</h2><span id='topic+CoxExample'></span>

<h3>Description</h3>

<p>Randomly generated data for Cox regression example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(CoxExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>x</dt><dd><p>1,000 by 30 matrix of numeric values.</p>
</dd>
<dt>y</dt><dd><p>1,000 by 2 matrix with column names &quot;time&quot; and &quot;status&quot;. The
first column consists of positive numbers representing time to event,
while the second column represents the status indicator
(0=right-censored, 1=observed).</p>
</dd>
</dl>


<hr>
<h2 id='coxgrad'>Compute gradient for Cox model</h2><span id='topic+coxgrad'></span>

<h3>Description</h3>

<p>Compute the gradient of the log partial likelihood at a particular fit for Cox
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coxgrad(eta, y, w, std.weights = TRUE, diag.hessian = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coxgrad_+3A_eta">eta</code></td>
<td>
<p>Fit vector (usually from glmnet at a particular lambda).</p>
</td></tr>
<tr><td><code id="coxgrad_+3A_y">y</code></td>
<td>
<p>Survival response variable, must be a <code>Surv</code> or
<code>stratifySurv</code> object.</p>
</td></tr>
<tr><td><code id="coxgrad_+3A_w">w</code></td>
<td>
<p>Observation weights (default is all equal to 1).</p>
</td></tr>
<tr><td><code id="coxgrad_+3A_std.weights">std.weights</code></td>
<td>
<p>If TRUE (default), observation weights are standardized
to sum to 1.</p>
</td></tr>
<tr><td><code id="coxgrad_+3A_diag.hessian">diag.hessian</code></td>
<td>
<p>If <code>TRUE</code>, compute the diagonal of the Hessian
of the log partial likelihood as well. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute a gradient vector at the fitted vector for the log partial likelihood.
This is like a residual vector, and useful for manual screening of
predictors for <code>glmnet</code> in applications where <code>p</code> is very large
(as in GWAS). Uses the Breslow approach to ties.
</p>
<p>This function is essentially a wrapper: it checks whether the response
provided is right-censored or (start, stop] survival data, and calls the
appropriate internal routine.
</p>


<h3>Value</h3>

<p>A single gradient vector the same length as <code>eta</code>. If
<code>diag.hessian=TRUE</code>, the diagonal of the Hessian is
included as an attribute &quot;diag_hessian&quot;.
</p>


<h3>See Also</h3>

<p><code>coxnet.deviance</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
eta &lt;- rnorm(10)
time &lt;- runif(10, min = 1, max = 10)
d &lt;- ifelse(rnorm(10) &gt; 0, 1, 0)
y &lt;- survival::Surv(time, d)
coxgrad(eta, y)

# return diagonal of Hessian as well
coxgrad(eta, y, diag.hessian = TRUE)

# example with (start, stop] data
y2 &lt;- survival::Surv(time, time + runif(10), d)
coxgrad(eta, y2)

# example with strata
y2 &lt;- stratifySurv(y, rep(1:2, length.out = 10))
coxgrad(eta, y2)

</code></pre>

<hr>
<h2 id='coxnet.deviance'>Compute deviance for Cox model</h2><span id='topic+coxnet.deviance'></span>

<h3>Description</h3>

<p>Compute the deviance (-2 log partial likelihood) for Cox model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coxnet.deviance(
  pred = NULL,
  y,
  x = NULL,
  offset = NULL,
  weights = NULL,
  std.weights = TRUE,
  beta = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coxnet.deviance_+3A_pred">pred</code></td>
<td>
<p>Fit vector or matrix (usually from glmnet at a particular
lambda or a sequence of lambdas).</p>
</td></tr>
<tr><td><code id="coxnet.deviance_+3A_y">y</code></td>
<td>
<p>Survival response variable, must be a <code>Surv</code> or
<code>stratifySurv</code> object.</p>
</td></tr>
<tr><td><code id="coxnet.deviance_+3A_x">x</code></td>
<td>
<p>Optional <code>x</code> matrix, to be supplied if <code>pred = NULL</code>.</p>
</td></tr>
<tr><td><code id="coxnet.deviance_+3A_offset">offset</code></td>
<td>
<p>Optional offset vector.</p>
</td></tr>
<tr><td><code id="coxnet.deviance_+3A_weights">weights</code></td>
<td>
<p>Observation weights (default is all equal to 1).</p>
</td></tr>
<tr><td><code id="coxnet.deviance_+3A_std.weights">std.weights</code></td>
<td>
<p>If TRUE (default), observation weights are standardized
to sum to 1.</p>
</td></tr>
<tr><td><code id="coxnet.deviance_+3A_beta">beta</code></td>
<td>
<p>Optional coefficient vector/matrix, to be supplied if
<code>pred = NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the deviance for a single set of predictions, or for a matrix
of predictions. The user can either supply the predictions
directly through the <code>pred</code> option, or by supplying the <code>x</code> matrix
and <code>beta</code> coefficients. Uses the Breslow approach to ties.
</p>
<p>The function first checks if <code>pred</code> is passed: if so, it is used as
the predictions. If <code>pred</code> is not passed but <code>x</code> and <code>beta</code>
are passed, then these values are used to compute the predictions. If
neither <code>x</code> nor <code>beta</code> are passed, then the predictions are all
taken to be 0.
</p>
<p><code>coxnet.deviance()</code> is a wrapper: it calls the appropriate internal
routine based on whether the response is right-censored data or
(start, stop] survival data.
</p>


<h3>Value</h3>

<p>A vector of deviances, one for each column of predictions.
</p>


<h3>See Also</h3>

<p><code>coxgrad</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
eta &lt;- rnorm(10)
time &lt;- runif(10, min = 1, max = 10)
d &lt;- ifelse(rnorm(10) &gt; 0, 1, 0)
y &lt;- survival::Surv(time, d)
coxnet.deviance(pred = eta, y = y)

# if pred not provided, it is set to zero vector
coxnet.deviance(y = y)

# example with x and beta
x &lt;- matrix(rnorm(10 * 3), nrow = 10)
beta &lt;- matrix(1:3, ncol = 1)
coxnet.deviance(y = y, x = x, beta = beta)

# example with (start, stop] data
y2 &lt;- survival::Surv(time, time + runif(10), d)
coxnet.deviance(pred = eta, y = y2)

# example with strata
y2 &lt;- stratifySurv(y, rep(1:2, length.out = 10))
coxnet.deviance(pred = eta, y = y2)

</code></pre>

<hr>
<h2 id='cv.glmnet'>Cross-validation for glmnet</h2><span id='topic+cv.glmnet'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for glmnet, produces a plot, and returns a
value for <code>lambda</code> (and <code>gamma</code> if <code>relax=TRUE</code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.glmnet(
  x,
  y,
  weights = NULL,
  offset = NULL,
  lambda = NULL,
  type.measure = c("default", "mse", "deviance", "class", "auc", "mae", "C"),
  nfolds = 10,
  foldid = NULL,
  alignment = c("lambda", "fraction"),
  grouped = TRUE,
  keep = FALSE,
  parallel = FALSE,
  gamma = c(0, 0.25, 0.5, 0.75, 1),
  relax = FALSE,
  trace.it = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.glmnet_+3A_x">x</code></td>
<td>
<p><code>x</code> matrix as in <code>glmnet</code>.</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_y">y</code></td>
<td>
<p>response <code>y</code> as in <code>glmnet</code>.</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_weights">weights</code></td>
<td>
<p>Observation weights; defaults to 1 per observation</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_offset">offset</code></td>
<td>
<p>Offset vector (matrix) as in <code>glmnet</code></p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_lambda">lambda</code></td>
<td>
<p>Optional user-supplied lambda sequence; default is
<code>NULL</code>, and <code>glmnet</code> chooses its own sequence. Note that this is done
for the full model (master sequence), and separately for each fold.
The fits are then alligned using the master sequence (see the <code>allignment</code>
argument for additional details). Adapting <code>lambda</code> for each fold
leads to better convergence. When <code>lambda</code> is supplied, the same sequence
is used everywhere, but in some GLMs can lead to convergence issues.</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_type.measure">type.measure</code></td>
<td>
<p>loss to use for cross-validation. Currently five
options, not all available for all models. The default is
<code>type.measure="deviance"</code>, which uses squared-error for gaussian models
(a.k.a <code>type.measure="mse"</code> there), deviance for logistic and poisson
regression, and partial-likelihood for the Cox model.
<code>type.measure="class"</code> applies to binomial and multinomial logistic
regression only, and gives misclassification error.
<code>type.measure="auc"</code> is for two-class logistic regression only, and
gives area under the ROC curve. <code>type.measure="mse"</code> or
<code>type.measure="mae"</code> (mean absolute error) can be used by all models
except the <code>"cox"</code>; they measure the deviation from the fitted mean to
the response.
<code>type.measure="C"</code> is Harrel's concordance measure, only available for <code>cox</code> models.</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds - default is 10. Although <code>nfolds</code> can be
as large as the sample size (leave-one-out CV), it is not recommended for
large datasets. Smallest value allowable is <code>nfolds=3</code></p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_foldid">foldid</code></td>
<td>
<p>an optional vector of values between 1 and <code>nfolds</code>
identifying what fold each observation is in. If supplied, <code>nfolds</code> can
be missing.</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_alignment">alignment</code></td>
<td>
<p>This is an experimental argument, designed to fix the
problems users were having with CV, with possible values <code>"lambda"</code>
(the default) else <code>"fraction"</code>. With <code>"lambda"</code> the <code>lambda</code>
values from the master fit (on all the data) are used to line up the
predictions from each of the folds. In some cases this can give strange
values, since the effective <code>lambda</code> values in each fold could be quite
different. With <code>"fraction"</code> we line up the predictions in each fold
according to the fraction of progress along the regularization. If in the
call a <code>lambda</code> argument is also provided, <code>alignment="fraction"</code>
is ignored (with a warning).</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_grouped">grouped</code></td>
<td>
<p>This is an experimental argument, with default <code>TRUE</code>,
and can be ignored by most users. For all models except the <code>"cox"</code>,
this refers to computing <code>nfolds</code> separate statistics, and then using
their mean and estimated standard error to describe the CV curve. If
<code>grouped=FALSE</code>, an error matrix is built up at the observation level
from the predictions from the <code>nfolds</code> fits, and then summarized (does
not apply to <code>type.measure="auc"</code>). For the <code>"cox"</code> family,
<code>grouped=TRUE</code> obtains the CV partial likelihood for the Kth fold by
<em>subtraction</em>; by subtracting the log partial likelihood evaluated on
the full dataset from that evaluated on the on the (K-1)/K dataset. This
makes more efficient use of risk sets. With <code>grouped=FALSE</code> the log
partial likelihood is computed only on the Kth fold</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_keep">keep</code></td>
<td>
<p>If <code>keep=TRUE</code>, a <em>prevalidated</em> array is returned
containing fitted values for each observation and each value of
<code>lambda</code>. This means these fits are computed with this observation and
the rest of its fold omitted. The <code>foldid</code> vector is also returned.
Default is keep=FALSE.  If <code>relax=TRUE</code>, then a list of such arrays is
returned, one for each value of 'gamma'. Note: if the value 'gamma=1' is
omitted, this case is included in the list since it corresponds to the
original 'glmnet' fit.</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_parallel">parallel</code></td>
<td>
<p>If <code>TRUE</code>, use parallel <code>foreach</code> to fit each
fold.  Must register parallel before hand, such as <code>doMC</code> or others.
See the example below.</p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_gamma">gamma</code></td>
<td>
<p>The values of the parameter for mixing the relaxed fit with the
regularized fit, between 0 and 1; default is <code>gamma = c(0, 0.25, 0.5,
0.75, 1)</code></p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_relax">relax</code></td>
<td>
<p>If <code>TRUE</code>, then CV is done with respect to the mixing
parameter <code>gamma</code> as well as <code>lambda</code>. Default is
<code>relax=FALSE</code></p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_trace.it">trace.it</code></td>
<td>
<p>If <code>trace.it=1</code>, then progress bars are displayed;
useful for big models that take a long time to fit. Limited tracing if
<code>parallel=TRUE</code></p>
</td></tr>
<tr><td><code id="cv.glmnet_+3A_...">...</code></td>
<td>
<p>Other arguments that can be passed to <code>glmnet</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs <code>glmnet</code> <code>nfolds</code>+1 times; the first to get the
<code>lambda</code> sequence, and then the remainder to compute the fit with each
of the folds omitted. The error is accumulated, and the average error and
standard deviation over the folds is computed.  Note that <code>cv.glmnet</code>
does NOT search for values for <code>alpha</code>. A specific value should be
supplied, else <code>alpha=1</code> is assumed by default. If users would like to
cross-validate <code>alpha</code> as well, they should call <code>cv.glmnet</code> with
a pre-computed vector <code>foldid</code>, and then use this same fold vector in
separate calls to <code>cv.glmnet</code> with different values of <code>alpha</code>.
Note also that the results of <code>cv.glmnet</code> are random, since the folds
are selected at random. Users can reduce this randomness by running
<code>cv.glmnet</code> many times, and averaging the error curves.
</p>
<p>If <code>relax=TRUE</code> then the values of <code>gamma</code> are used to mix the
fits. If <code class="reqn">\eta</code> is the fit for lasso/elastic net, and <code class="reqn">\eta_R</code> is
the relaxed fit (with unpenalized coefficients), then a relaxed fit mixed by
<code class="reqn">\gamma</code> is </p>
<p style="text-align: center;"><code class="reqn">\eta(\gamma)=(1-\gamma)\eta_R+\gamma\eta.</code>
</p>
<p> There is
practically no extra cost for having a lot of values for <code>gamma</code>.
However, 5 seems sufficient for most purposes. CV then selects both
<code>gamma</code> and <code>lambda</code>.
</p>


<h3>Value</h3>

<p>an object of class <code>"cv.glmnet"</code> is returned, which is a list
with the ingredients of the cross-validation fit.  If the object was created
with <code>relax=TRUE</code> then this class has a prefix class of
<code>"cv.relaxed"</code>.  </p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>the values of <code>lambda</code> used in the
fits.</p>
</td></tr> <tr><td><code>cvm</code></td>
<td>
<p>The mean cross-validated error - a vector of length
<code>length(lambda)</code>.</p>
</td></tr> <tr><td><code>cvsd</code></td>
<td>
<p>estimate of standard error of
<code>cvm</code>.</p>
</td></tr> <tr><td><code>cvup</code></td>
<td>
<p>upper curve = <code>cvm+cvsd</code>.</p>
</td></tr> <tr><td><code>cvlo</code></td>
<td>
<p>lower
curve = <code>cvm-cvsd</code>.</p>
</td></tr> <tr><td><code>nzero</code></td>
<td>
<p>number of non-zero coefficients at
each <code>lambda</code>.</p>
</td></tr> <tr><td><code>name</code></td>
<td>
<p>a text string indicating type of measure
(for plotting purposes).</p>
</td></tr> <tr><td><code>glmnet.fit</code></td>
<td>
<p>a fitted glmnet object for the
full data.</p>
</td></tr> <tr><td><code>lambda.min</code></td>
<td>
<p>value of <code>lambda</code> that gives minimum
<code>cvm</code>.</p>
</td></tr> <tr><td><code>lambda.1se</code></td>
<td>
<p>largest value of <code>lambda</code> such that
error is within 1 standard error of the minimum.</p>
</td></tr> <tr><td><code>fit.preval</code></td>
<td>
<p>if
<code>keep=TRUE</code>, this is the array of prevalidated fits. Some entries can
be <code>NA</code>, if that and subsequent values of <code>lambda</code> are not reached
for that fold</p>
</td></tr> <tr><td><code>foldid</code></td>
<td>
<p>if <code>keep=TRUE</code>, the fold assignments used</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>a one column matrix with the indices of <code>lambda.min</code> and <code>lambda.1se</code> in the sequence of coefficients, fits etc.</p>
</td></tr>
<tr><td><code>relaxed</code></td>
<td>
<p>if <code>relax=TRUE</code>, this additional item has the CV info
for each of the mixed fits. In particular it also selects <code>lambda,
gamma</code> pairs corresponding to the 1se rule, as well as the minimum error. It also has a component <code>index</code>, a two-column matrix  which contains the <code>lambda</code> and <code>gamma</code> indices corresponding to the &quot;min&quot; and &quot;1se&quot; solutions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie and Rob Tibshirani<br /> Noah Simon
helped develop the 'coxnet' function.<br /> Jeffrey Wong and B. Narasimhan
helped with the parallel option<br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.
</p>


<h3>See Also</h3>

<p><code>glmnet</code> and <code>plot</code>, <code>predict</code>, and <code>coef</code>
methods for <code>"cv.glmnet"</code> and <code>"cv.relaxed"</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1010)
n = 1000
p = 100
nzc = trunc(p/10)
x = matrix(rnorm(n * p), n, p)
beta = rnorm(nzc)
fx = x[, seq(nzc)] %*% beta
eps = rnorm(n) * 5
y = drop(fx + eps)
px = exp(fx)
px = px/(1 + px)
ly = rbinom(n = length(px), prob = px, size = 1)
set.seed(1011)
cvob1 = cv.glmnet(x, y)
plot(cvob1)
coef(cvob1)
predict(cvob1, newx = x[1:5, ], s = "lambda.min")
title("Gaussian Family", line = 2.5)
set.seed(1011)
cvob1a = cv.glmnet(x, y, type.measure = "mae")
plot(cvob1a)
title("Gaussian Family", line = 2.5)
set.seed(1011)
par(mfrow = c(2, 2), mar = c(4.5, 4.5, 4, 1))
cvob2 = cv.glmnet(x, ly, family = "binomial")
plot(cvob2)
title("Binomial Family", line = 2.5)
frame()
set.seed(1011)
cvob3 = cv.glmnet(x, ly, family = "binomial", type.measure = "class")
plot(cvob3)
title("Binomial Family", line = 2.5)
## Not run: 
cvob1r = cv.glmnet(x, y, relax = TRUE)
plot(cvob1r)
predict(cvob1r, newx = x[, 1:5])
set.seed(1011)
cvob3a = cv.glmnet(x, ly, family = "binomial", type.measure = "auc")
plot(cvob3a)
title("Binomial Family", line = 2.5)
set.seed(1011)
mu = exp(fx/10)
y = rpois(n, mu)
cvob4 = cv.glmnet(x, y, family = "poisson")
plot(cvob4)
title("Poisson Family", line = 2.5)

# Multinomial
n = 500
p = 30
nzc = trunc(p/10)
x = matrix(rnorm(n * p), n, p)
beta3 = matrix(rnorm(30), 10, 3)
beta3 = rbind(beta3, matrix(0, p - 10, 3))
f3 = x %*% beta3
p3 = exp(f3)
p3 = p3/apply(p3, 1, sum)
g3 = glmnet:::rmult(p3)
set.seed(10101)
cvfit = cv.glmnet(x, g3, family = "multinomial")
plot(cvfit)
title("Multinomial Family", line = 2.5)
# Cox
beta = rnorm(nzc)
fx = x[, seq(nzc)] %*% beta/3
hx = exp(fx)
ty = rexp(n, hx)
tcens = rbinom(n = n, prob = 0.3, size = 1)  # censoring indicator
y = cbind(time = ty, status = 1 - tcens)  # y=Surv(ty,1-tcens) with library(survival)
foldid = sample(rep(seq(10), length = n))
fit1_cv = cv.glmnet(x, y, family = "cox", foldid = foldid)
plot(fit1_cv)
title("Cox Family", line = 2.5)
# Parallel
require(doMC)
registerDoMC(cores = 4)
x = matrix(rnorm(1e+05 * 100), 1e+05, 100)
y = rnorm(1e+05)
system.time(cv.glmnet(x, y))
system.time(cv.glmnet(x, y, parallel = TRUE))

## End(Not run)

</code></pre>

<hr>
<h2 id='dev_function'>Elastic net deviance value</h2><span id='topic+dev_function'></span>

<h3>Description</h3>

<p>Returns the elastic net deviance value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dev_function(y, mu, weights, family)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dev_function_+3A_y">y</code></td>
<td>
<p>Quantitative response variable.</p>
</td></tr>
<tr><td><code id="dev_function_+3A_mu">mu</code></td>
<td>
<p>Model's predictions for <code>y</code>.</p>
</td></tr>
<tr><td><code id="dev_function_+3A_weights">weights</code></td>
<td>
<p>Observation weights.</p>
</td></tr>
<tr><td><code id="dev_function_+3A_family">family</code></td>
<td>
<p>A description of the error distribution and link function to be
used in the model. This is the result of a call to a family function.</p>
</td></tr>
</table>

<hr>
<h2 id='deviance.glmnet'>Extract the deviance from a glmnet object</h2><span id='topic+deviance.glmnet'></span>

<h3>Description</h3>

<p>Compute the deviance sequence from the glmnet object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmnet'
deviance(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deviance.glmnet_+3A_object">object</code></td>
<td>
<p>fitted glmnet object</p>
</td></tr>
<tr><td><code id="deviance.glmnet_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A glmnet object has components <code>dev.ratio</code> and <code>nulldev</code>.  The
former is the fraction of (null) deviance explained. The deviance
calculations incorporate weights if present in the model. The deviance is
defined to be 2*(loglike_sat - loglike), where loglike_sat is the
log-likelihood for the saturated model (a model with a free parameter per
observation).  Null deviance is defined to be 2*(loglike_sat
-loglike(Null)); The NULL model refers to the intercept model, except for
the Cox, where it is the 0 model. Hence dev.ratio=1-deviance/nulldev, and
this <code>deviance</code> method returns (1-dev.ratio)*nulldev.
</p>


<h3>Value</h3>

<p>(1-dev.ratio)*nulldev
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie and Rob Tibshirani<br /> Maintainer:
Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent</em>
</p>


<h3>See Also</h3>

<p><code>glmnet</code>, <code>predict</code>, <code>print</code>, and <code>coef</code>
methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit1 = glmnet(x, y)
deviance(fit1)
</code></pre>

<hr>
<h2 id='elnet.fit'>Solve weighted least squares (WLS) problem for a single lambda value</h2><span id='topic+elnet.fit'></span>

<h3>Description</h3>

<p>Solves the weighted least squares (WLS) problem for a single lambda value. Internal
function that users should not call directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elnet.fit(
  x,
  y,
  weights,
  lambda,
  alpha = 1,
  intercept = TRUE,
  thresh = 1e-07,
  maxit = 1e+05,
  penalty.factor = rep(1, nvars),
  exclude = c(),
  lower.limits = -Inf,
  upper.limits = Inf,
  warm = NULL,
  from.glmnet.fit = FALSE,
  save.fit = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="elnet.fit_+3A_x">x</code></td>
<td>
<p>Input matrix, of dimension <code>nobs x nvars</code>; each row is an
observation vector. If it is a sparse matrix, it is assumed to be unstandardized.
It should have attributes <code>xm</code> and <code>xs</code>, where <code>xm(j)</code> and
<code>xs(j)</code> are the centering and scaling factors for variable j respsectively.
If it is not a sparse matrix, it is assumed that any standardization needed
has already been done.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_y">y</code></td>
<td>
<p>Quantitative response variable.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_weights">weights</code></td>
<td>
<p>Observation weights. <code>elnet.fit</code> does NOT standardize
these weights.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_lambda">lambda</code></td>
<td>
<p>A single value for the <code>lambda</code> hyperparameter.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>.
The penalty is defined as </p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.</code>
</p>

<p><code>alpha=1</code> is the lasso penalty, and <code>alpha=0</code> the ridge penalty.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept be fitted (default=TRUE) or set to zero (FALSE)?</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_thresh">thresh</code></td>
<td>
<p>Convergence threshold for coordinate descent. Each inner
coordinate-descent loop continues until the maximum change in the objective
after any coefficient update is less than thresh times the null deviance.
Default value is <code>1e-7</code>.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of passes over the data; default is <code>10^5</code>.
(If a warm start object is provided, the number of passes the warm start object
performed is included.)</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each
coefficient. This is a number that multiplies <code>lambda</code> to allow differential
shrinkage. Can be 0 for some variables, which implies no shrinkage, and that
variable is always included in the model. Default is 1 for all variables (and
implicitly infinity for variables listed in exclude). Note: the penalty
factors are internally rescaled to sum to <code>nvars</code>.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the model. Default is
none. Equivalent to an infinite penalty factor.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_lower.limits">lower.limits</code></td>
<td>
<p>Vector of lower limits for each coefficient; default
<code>-Inf</code>. Each of these must be non-positive. Can be presented as a single
value (which will then be replicated), else a vector of length <code>nvars</code>.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_upper.limits">upper.limits</code></td>
<td>
<p>Vector of upper limits for each coefficient; default
<code>Inf</code>. See <code>lower.limits</code>.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_warm">warm</code></td>
<td>
<p>Either a <code>glmnetfit</code> object or a list (with names <code>beta</code>
and <code>a0</code> containing coefficients and intercept respectively) which can
be used as a warm start. Default is <code>NULL</code>, indicating no warm start.
For internal use only.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_from.glmnet.fit">from.glmnet.fit</code></td>
<td>
<p>Was <code>elnet.fit()</code> called from <code>glmnet.fit()</code>?
Default is FALSE.This has implications for computation of the penalty factors.</p>
</td></tr>
<tr><td><code id="elnet.fit_+3A_save.fit">save.fit</code></td>
<td>
<p>Return the warm start object? Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WARNING: Users should not call <code>elnet.fit</code> directly. Higher-level functions
in this package call <code>elnet.fit</code> as a subroutine. If a warm start object
is provided, some of the other arguments in the function may be overriden.
</p>
<p><code>elnet.fit</code> is essentially a wrapper around a C++ subroutine which
minimizes
</p>
<p style="text-align: center;"><code class="reqn">1/2 \sum w_i (y_i - X_i^T \beta)^2 + \sum \lambda \gamma_j
[(1-\alpha)/2 \beta^2+\alpha|\beta|],</code>
</p>

<p>over <code class="reqn">\beta</code>, where <code class="reqn">\gamma_j</code> is the relative penalty factor on the
jth variable. If <code>intercept = TRUE</code>, then the term in the first sum is
<code class="reqn">w_i (y_i - \beta_0 - X_i^T \beta)^2</code>, and we are minimizing over both
<code class="reqn">\beta_0</code> and <code class="reqn">\beta</code>.
</p>
<p>None of the inputs are standardized except for <code>penalty.factor</code>, which
is standardized so that they sum up to <code>nvars</code>.
</p>


<h3>Value</h3>

<p>An object with class &quot;glmnetfit&quot; and &quot;glmnet&quot;. The list returned has
the same keys as that of a <code>glmnet</code> object, except that it might have an
additional <code>warm_fit</code> key.
</p>
<table>
<tr><td><code>a0</code></td>
<td>
<p>Intercept value.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A <code>nvars x 1</code> matrix of coefficients, stored in sparse matrix
format.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of nonzero coefficients.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Dimension of coefficient matrix.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Lambda value used.</p>
</td></tr>
<tr><td><code>dev.ratio</code></td>
<td>
<p>The fraction of (null) deviance explained. The deviance
calculations incorporate weights if present in the model. The deviance is
defined to be 2*(loglike_sat - loglike), where loglike_sat is the log-likelihood
for the saturated model (a model with a free parameter per observation).
Hence dev.ratio=1-dev/nulldev.</p>
</td></tr>
<tr><td><code>nulldev</code></td>
<td>
<p>Null deviance (per observation). This is defined to be
2*(loglike_sat -loglike(Null)). The null model refers to the intercept model.</p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>Total passes over the data.</p>
</td></tr>
<tr><td><code>jerr</code></td>
<td>
<p>Error flag, for warnings and errors (largely for internal
debugging).</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>Always FALSE, since offsets do not appear in the WLS problem.
Included for compability with glmnet output.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code>warm_fit</code></td>
<td>
<p>If <code>save.fit=TRUE</code>, output of C++ routine, used for
warm starts. For internal use only.</p>
</td></tr>
</table>

<hr>
<h2 id='fid'>Helper function for Cox deviance and gradient</h2><span id='topic+fid'></span>

<h3>Description</h3>

<p>Helps to find ties in death times of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fid(x, index)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fid_+3A_x">x</code></td>
<td>
<p>Sorted vector of death times.</p>
</td></tr>
<tr><td><code id="fid_+3A_index">index</code></td>
<td>
<p>Vector of indices for the death times.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two arguments.
</p>
<table>
<tr><td><code>index_first</code></td>
<td>
<p>A vector of indices for the first observation at each
death time as they appear in the sorted list.</p>
</td></tr>
<tr><td><code>index_ties</code></td>
<td>
<p>If there are no ties at all, this is NULL. If not, this is
a list with length equal to the number of unique times with ties. For each
time with ties, index_ties gives the indices of the observations with a
death at that time.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Example with no ties
glmnet:::fid(c(1, 4, 5, 6), 1:5)

# Example with ties
glmnet:::fid(c(1, 1, 1, 2, 3, 3, 4, 4, 4), 1:9)
</code></pre>

<hr>
<h2 id='get_cox_lambda_max'>Get lambda max for Cox regression model</h2><span id='topic+get_cox_lambda_max'></span>

<h3>Description</h3>

<p>Return the lambda max value for Cox regression model, used for computing
initial lambda values. For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_cox_lambda_max(
  x,
  y,
  alpha,
  weights = rep(1, nrow(x)),
  offset = rep(0, nrow(x)),
  exclude = c(),
  vp = rep(1, ncol(x))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_cox_lambda_max_+3A_x">x</code></td>
<td>
<p>Input matrix, of dimension <code>nobs x nvars</code>; each row is an
observation vector. If it is a sparse matrix, it is assumed to be unstandardized.
It should have attributes <code>xm</code> and <code>xs</code>, where <code>xm(j)</code> and
<code>xs(j)</code> are the centering and scaling factors for variable j respsectively.
If it is not a sparse matrix, it is assumed to be standardized.</p>
</td></tr>
<tr><td><code id="get_cox_lambda_max_+3A_y">y</code></td>
<td>
<p>Survival response variable, must be a <code>Surv</code> or
<code>stratifySurv</code> object.</p>
</td></tr>
<tr><td><code id="get_cox_lambda_max_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>.</p>
</td></tr>
<tr><td><code id="get_cox_lambda_max_+3A_weights">weights</code></td>
<td>
<p>Observation weights.</p>
</td></tr>
<tr><td><code id="get_cox_lambda_max_+3A_offset">offset</code></td>
<td>
<p>Offset for the model. Default is a zero vector of length
<code>nrow(y)</code>.</p>
</td></tr>
<tr><td><code id="get_cox_lambda_max_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the model.</p>
</td></tr>
<tr><td><code id="get_cox_lambda_max_+3A_vp">vp</code></td>
<td>
<p>Separate penalty factors can be applied to each coefficient.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by <code>cox.path</code> for the value of lambda max.
</p>
<p>When <code>x</code> is not sparse, it is expected to already by centered and scaled.
When <code>x</code> is sparse, the function will get its attributes <code>xm</code> and
<code>xs</code> for its centering and scaling factors. The value of
<code>lambda_max</code> changes depending on whether <code>x</code> is centered and
scaled or not, so we need <code>xm</code> and <code>xs</code> to get the correct value.
</p>

<hr>
<h2 id='get_eta'>Helper function to get etas (linear predictions)</h2><span id='topic+get_eta'></span>

<h3>Description</h3>

<p>Given x, coefficients and intercept, return linear predictions. Wrapper that
works with both regular and sparse x. Only works for single set of coefficients
and intercept.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_eta(x, beta, a0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_eta_+3A_x">x</code></td>
<td>
<p>Input matrix, of dimension <code>nobs x nvars</code>; each row is an
observation vector. If it is a sparse matrix, it is assumed to be unstandardized.
It should have attributes <code>xm</code> and <code>xs</code>, where <code>xm(j)</code> and
<code>xs(j)</code> are the centering and scaling factors for variable j respsectively.
If it is not a sparse matrix, it is assumed to be standardized.</p>
</td></tr>
<tr><td><code id="get_eta_+3A_beta">beta</code></td>
<td>
<p>Feature coefficients.</p>
</td></tr>
<tr><td><code id="get_eta_+3A_a0">a0</code></td>
<td>
<p>Intercept.</p>
</td></tr>
</table>

<hr>
<h2 id='get_start'>Get null deviance, starting mu and lambda max</h2><span id='topic+get_start'></span>

<h3>Description</h3>

<p>Return the null deviance, starting mu and lambda max values for
initialization. For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_start(
  x,
  y,
  weights,
  family,
  intercept,
  is.offset,
  offset,
  exclude,
  vp,
  alpha
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_start_+3A_x">x</code></td>
<td>
<p>Input matrix, of dimension <code>nobs x nvars</code>; each row is an
observation vector. If it is a sparse matrix, it is assumed to be unstandardized.
It should have attributes <code>xm</code> and <code>xs</code>, where <code>xm(j)</code> and
<code>xs(j)</code> are the centering and scaling factors for variable j respsectively.
If it is not a sparse matrix, it is assumed to be standardized.</p>
</td></tr>
<tr><td><code id="get_start_+3A_y">y</code></td>
<td>
<p>Quantitative response variable.</p>
</td></tr>
<tr><td><code id="get_start_+3A_weights">weights</code></td>
<td>
<p>Observation weights.</p>
</td></tr>
<tr><td><code id="get_start_+3A_family">family</code></td>
<td>
<p>A description of the error distribution and link function to be
used in the model. This is the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details on family functions.)</p>
</td></tr>
<tr><td><code id="get_start_+3A_intercept">intercept</code></td>
<td>
<p>Does the model we are fitting have an intercept term or not?</p>
</td></tr>
<tr><td><code id="get_start_+3A_is.offset">is.offset</code></td>
<td>
<p>Is the model being fit with an offset or not?</p>
</td></tr>
<tr><td><code id="get_start_+3A_offset">offset</code></td>
<td>
<p>Offset for the model. If <code>is.offset=FALSE</code>, this should be
a zero vector of the same length as <code>y</code>.</p>
</td></tr>
<tr><td><code id="get_start_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the model.</p>
</td></tr>
<tr><td><code id="get_start_+3A_vp">vp</code></td>
<td>
<p>Separate penalty factors can be applied to each coefficient.</p>
</td></tr>
<tr><td><code id="get_start_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by <code>glmnet.path</code> for null deviance, starting mu
and lambda max values. It is also called by <code>glmnet.fit</code> when used
without warmstart, but they only use the null deviance and starting mu values.
</p>
<p>When <code>x</code> is not sparse, it is expected to already by centered and scaled.
When <code>x</code> is sparse, the function will get its attributes <code>xm</code> and
<code>xs</code> for its centering and scaling factors.
</p>
<p>Note that whether <code>x</code> is centered &amp; scaled or not, the values of <code>mu</code>
and <code>nulldev</code> don't change. However, the value of <code>lambda_max</code> does
change, and we need <code>xm</code> and <code>xs</code> to get the correct value.
</p>

<hr>
<h2 id='glmnet'>fit a GLM with lasso or elasticnet regularization</h2><span id='topic+glmnet'></span><span id='topic+relax.glmnet'></span>

<h3>Description</h3>

<p>Fit a generalized linear model via penalized maximum likelihood.  The
regularization path is computed for the lasso or elasticnet penalty at a
grid of values for the regularization parameter lambda. Can deal with all
shapes of data, including very large sparse data matrices. Fits linear,
logistic and multinomial, poisson, and Cox regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet(
  x,
  y,
  family = c("gaussian", "binomial", "poisson", "multinomial", "cox", "mgaussian"),
  weights = NULL,
  offset = NULL,
  alpha = 1,
  nlambda = 100,
  lambda.min.ratio = ifelse(nobs &lt; nvars, 0.01, 1e-04),
  lambda = NULL,
  standardize = TRUE,
  intercept = TRUE,
  thresh = 1e-07,
  dfmax = nvars + 1,
  pmax = min(dfmax * 2 + 20, nvars),
  exclude = NULL,
  penalty.factor = rep(1, nvars),
  lower.limits = -Inf,
  upper.limits = Inf,
  maxit = 1e+05,
  type.gaussian = ifelse(nvars &lt; 500, "covariance", "naive"),
  type.logistic = c("Newton", "modified.Newton"),
  standardize.response = FALSE,
  type.multinomial = c("ungrouped", "grouped"),
  relax = FALSE,
  trace.it = 0,
  ...
)

relax.glmnet(fit, x, ..., maxp = n - 3, path = FALSE, check.args = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmnet_+3A_x">x</code></td>
<td>
<p>input matrix, of dimension nobs x nvars; each row is an observation
vector. Can be in sparse matrix format (inherit from class
<code>"sparseMatrix"</code> as in package <code>Matrix</code>).
Requirement: <code>nvars &gt;1</code>; in other words, <code>x</code> should have 2 or more columns.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_y">y</code></td>
<td>
<p>response variable. Quantitative for <code>family="gaussian"</code>, or
<code>family="poisson"</code> (non-negative counts). For <code>family="binomial"</code>
should be either a factor with two levels, or a two-column matrix of counts
or proportions (the second column is treated as the target class; for a
factor, the last level in alphabetical order is the target class). For
<code>family="multinomial"</code>, can be a <code>nc&gt;=2</code> level factor, or a matrix
with <code>nc</code> columns of counts or proportions. For either
<code>"binomial"</code> or <code>"multinomial"</code>, if <code>y</code> is presented as a
vector, it will be coerced into a factor. For <code>family="cox"</code>, preferably
a <code>Surv</code> object from the survival package: see Details section for
more information. For <code>family="mgaussian"</code>, <code>y</code> is a matrix
of quantitative responses.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_family">family</code></td>
<td>
<p>Either a character string representing
one of the built-in families, or else a <code>glm()</code> family object. For more
information, see Details section below or the documentation for response
type (above).</p>
</td></tr>
<tr><td><code id="glmnet_+3A_weights">weights</code></td>
<td>
<p>observation weights. Can be total counts if responses are
proportion matrices. Default is 1 for each observation</p>
</td></tr>
<tr><td><code id="glmnet_+3A_offset">offset</code></td>
<td>
<p>A vector of length <code>nobs</code> that is included in the linear
predictor (a <code>nobs x nc</code> matrix for the <code>"multinomial"</code> family).
Useful for the <code>"poisson"</code> family (e.g. log of exposure time), or for
refining a model by starting at a current fit. Default is <code>NULL</code>. If
supplied, then values must also be supplied to the <code>predict</code> function.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0\le\alpha\le 1</code>.
The penalty is defined as
</p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.</code>
</p>
 <p><code>alpha=1</code> is the
lasso penalty, and <code>alpha=0</code> the ridge penalty.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values - default is 100.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for <code>lambda</code>, as a fraction of
<code>lambda.max</code>, the (data derived) entry value (i.e. the smallest value
for which all coefficients are zero). The default depends on the sample size
<code>nobs</code> relative to the number of variables <code>nvars</code>. If <code>nobs
&gt; nvars</code>, the default is <code>0.0001</code>, close to zero.  If <code>nobs &lt;
nvars</code>, the default is <code>0.01</code>.  A very small value of
<code>lambda.min.ratio</code> will lead to a saturated fit in the <code>nobs &lt;
nvars</code> case. This is undefined for <code>"binomial"</code> and
<code>"multinomial"</code> models, and <code>glmnet</code> will exit gracefully when the
percentage deviance explained is almost 1.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied <code>lambda</code> sequence. Typical usage is to
have the program compute its own <code>lambda</code> sequence based on
<code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying a value of
<code>lambda</code> overrides this. WARNING: use with care. Avoid supplying a
single value for <code>lambda</code> (for predictions after CV use
<code>predict()</code> instead).  Supply instead a decreasing sequence of
<code>lambda</code> values. <code>glmnet</code> relies on its warms starts for speed,
and its often faster to fit a whole path than compute a single fit.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for x variable standardization, prior to
fitting the model sequence. The coefficients are always returned on the
original scale. Default is <code>standardize=TRUE</code>.  If variables are in the
same units already, you might not wish to standardize. See details below for
y standardization with <code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept(s) be fitted (default=TRUE) or set to zero
(FALSE)</p>
</td></tr>
<tr><td><code id="glmnet_+3A_thresh">thresh</code></td>
<td>
<p>Convergence threshold for coordinate descent. Each inner
coordinate-descent loop continues until the maximum change in the objective
after any coefficient update is less than <code>thresh</code> times the null
deviance. Defaults value is <code>1E-7</code>.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_dfmax">dfmax</code></td>
<td>
<p>Limit the maximum number of variables in the model. Useful for
very large <code>nvars</code>, if a partial path is desired.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_pmax">pmax</code></td>
<td>
<p>Limit the maximum number of variables ever to be nonzero</p>
</td></tr>
<tr><td><code id="glmnet_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the model. Default
is none. Equivalent to an infinite penalty factor for the variables excluded (next item).
Users can supply instead an <code>exclude</code> function that generates the list of indices.
This function is most generally defined as <code>function(x, y, weights, ...)</code>,
and is called inside <code>glmnet</code> to generate the indices for excluded variables.
The <code>...</code> argument is required, the others are optional.
This is useful for filtering wide data, and works correctly with <code>cv.glmnet</code>.
See the vignette 'Introduction' for examples.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each
coefficient. This is a number that multiplies <code>lambda</code> to allow
differential shrinkage. Can be 0 for some variables, which implies no
shrinkage, and that variable is always included in the model. Default is 1
for all variables (and implicitly infinity for variables listed in
<code>exclude</code>). Also, any <code>penalty.factor</code> that is set to <code>inf</code> is
converted to an <code>exclude</code>, and then internally reset to 1.
Note: the penalty factors are internally rescaled to sum to
nvars, and the lambda sequence will reflect this change.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_lower.limits">lower.limits</code></td>
<td>
<p>Vector of lower limits for each coefficient; default
<code>-Inf</code>. Each of these must be non-positive. Can be presented as a
single value (which will then be replicated), else a vector of length
<code>nvars</code></p>
</td></tr>
<tr><td><code id="glmnet_+3A_upper.limits">upper.limits</code></td>
<td>
<p>Vector of upper limits for each coefficient; default
<code>Inf</code>. See <code>lower.limits</code></p>
</td></tr>
<tr><td><code id="glmnet_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of passes over the data for all lambda values;
default is 10^5.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_type.gaussian">type.gaussian</code></td>
<td>
<p>Two algorithm types are supported for (only)
<code>family="gaussian"</code>. The default when <code>nvar&lt;500</code> is
<code>type.gaussian="covariance"</code>, and saves all inner-products ever
computed. This can be much faster than <code>type.gaussian="naive"</code>, which
loops through <code>nobs</code> every time an inner-product is computed. The
latter can be far more efficient for <code>nvar &gt;&gt; nobs</code> situations, or when
<code>nvar &gt; 500</code>.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_type.logistic">type.logistic</code></td>
<td>
<p>If <code>"Newton"</code> then the exact hessian is used
(default), while <code>"modified.Newton"</code> uses an upper-bound on the
hessian, and can be faster.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_standardize.response">standardize.response</code></td>
<td>
<p>This is for the <code>family="mgaussian"</code>
family, and allows the user to standardize the response variables</p>
</td></tr>
<tr><td><code id="glmnet_+3A_type.multinomial">type.multinomial</code></td>
<td>
<p>If <code>"grouped"</code> then a grouped lasso penalty is
used on the multinomial coefficients for a variable. This ensures they are
all in our out together. The default is <code>"ungrouped"</code></p>
</td></tr>
<tr><td><code id="glmnet_+3A_relax">relax</code></td>
<td>
<p>If <code>TRUE</code> then for each <em>active set</em> in the path of
solutions, the model is refit without any regularization. See <code>details</code>
for more information. This argument is new, and users may experience convergence issues
with small datasets, especially with non-gaussian families. Limiting the
value of 'maxp' can alleviate these issues in some cases.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_trace.it">trace.it</code></td>
<td>
<p>If <code>trace.it=1</code>, then a progress bar is displayed;
useful for big models that take a long time to fit.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_...">...</code></td>
<td>
<p>Additional argument used in <code>relax.glmnet</code>. These include
some of the original arguments to 'glmnet', and each must be named if used.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_fit">fit</code></td>
<td>
<p>For <code>relax.glmnet</code> a fitted 'glmnet' object</p>
</td></tr>
<tr><td><code id="glmnet_+3A_maxp">maxp</code></td>
<td>
<p>a limit on how many relaxed coefficients are allowed. Default is
'n-3', where 'n' is the sample size. This may not be sufficient for
non-gaussian familes, in which case users should supply a smaller value.
This argument can be supplied directly to 'glmnet'.</p>
</td></tr>
<tr><td><code id="glmnet_+3A_path">path</code></td>
<td>
<p>Since <code>glmnet</code> does not do stepsize optimization, the Newton
algorithm can get stuck and not converge, especially with relaxed fits. With <code>path=TRUE</code>,
each relaxed fit on a particular set of variables is computed pathwise using the original sequence
of lambda values (with a zero attached to the end). Not needed for Gaussian models, and should not
be used unless needed, since will lead to longer compute times. Default is <code>path=FALSE</code>.
appropriate subset of variables</p>
</td></tr>
<tr><td><code id="glmnet_+3A_check.args">check.args</code></td>
<td>
<p>Should <code>relax.glmnet</code> make sure that all the data
dependent arguments used in creating 'fit' have been resupplied. Default is
'TRUE'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models implied by <code>lambda</code> is fit by coordinate
descent. For <code>family="gaussian"</code> this is the lasso sequence if
<code>alpha=1</code>, else it is the elasticnet sequence.
</p>
<p>The objective function for <code>"gaussian"</code> is </p>
<p style="text-align: center;"><code class="reqn">1/2 RSS/nobs +
\lambda*penalty,</code>
</p>
<p> and for the other models it is </p>
<p style="text-align: center;"><code class="reqn">-loglik/nobs +
\lambda*penalty.</code>
</p>
<p> Note also that for <code>"gaussian"</code>, <code>glmnet</code>
standardizes y to have unit variance (using 1/n rather than 1/(n-1) formula)
before computing its lambda sequence (and then unstandardizes the resulting
coefficients); if you wish to reproduce/compare results with other software,
best to supply a standardized y. The coefficients for any predictor
variables with zero variance are set to zero for all values of lambda.
</p>


<h4>Details on <code>family</code> option</h4>

<p>From version 4.0 onwards, glmnet supports both the original built-in families,
as well as <em>any</em> family object as used by <code>stats:glm()</code>.
This opens the door to a wide variety of additional models. For example
<code>family=binomial(link=cloglog)</code> or <code>family=negative.binomial(theta=1.5)</code> (from the MASS library).
Note that the code runs faster for the built-in families.
</p>
<p>The built in families are specifed via a character string. For all families,
the object produced is a lasso or elasticnet regularization path for fitting the
generalized linear regression paths, by maximizing the appropriate penalized
log-likelihood (partial likelihood for the &quot;cox&quot; model). Sometimes the
sequence is truncated before <code>nlambda</code> values of <code>lambda</code> have
been used, because of instabilities in the inverse link functions near a
saturated fit. <code>glmnet(...,family="binomial")</code> fits a traditional
logistic regression model for the log-odds.
<code>glmnet(...,family="multinomial")</code> fits a symmetric multinomial model,
where each class is represented by a linear model (on the log-scale). The
penalties take care of redundancies. A two-class <code>"multinomial"</code> model
will produce the same fit as the corresponding <code>"binomial"</code> model,
except the pair of coefficient matrices will be equal in magnitude and
opposite in sign, and half the <code>"binomial"</code> values.
Two useful additional families are the <code>family="mgaussian"</code> family and
the <code>type.multinomial="grouped"</code> option for multinomial fitting. The
former allows a multi-response gaussian model to be fit, using a &quot;group
-lasso&quot; penalty on the coefficients for each variable. Tying the responses
together like this is called &quot;multi-task&quot; learning in some domains. The
grouped multinomial allows the same penalty for the
<code>family="multinomial"</code> model, which is also multi-responsed. For both
of these the penalty on the coefficient vector for variable j is
</p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2||\beta_j||_2^2+\alpha||\beta_j||_2.</code>
</p>
<p> When <code>alpha=1</code>
this is a group-lasso penalty, and otherwise it mixes with quadratic just
like elasticnet. A small detail in the Cox model: if death times are tied
with censored times, we assume the censored times occurred just
<em>before</em> the death times in computing the Breslow approximation; if
users prefer the usual convention of <em>after</em>, they can add a small
number to all censoring times to achieve this effect.
</p>



<h4>Details on response for <code>family="cox"</code></h4>

<p>For Cox models, the response should preferably be a <code>Surv</code> object,
created by the <code>Surv()</code> function in <span class="pkg">survival</span> package. For
right-censored data, this object should have type &quot;right&quot;, and for
(start, stop] data, it should have type &quot;counting&quot;. To fit stratified Cox
models, strata should be added to the response via the <code>stratifySurv()</code>
function before passing the response to <code>glmnet()</code>. (For backward
compatibility, right-censored data can also be passed as a
two-column matrix with columns named 'time' and 'status'. The
latter is a binary variable, with '1' indicating death, and '0' indicating
right censored.)
</p>



<h4>Details on <code>relax</code> option</h4>

<p>If <code>relax=TRUE</code>
a duplicate sequence of models is produced, where each active set in the
elastic-net path is refit without regularization. The result of this is a
matching <code>"glmnet"</code> object which is stored on the original object in a
component named <code>"relaxed"</code>, and is part of the glmnet output.
Generally users will not call <code>relax.glmnet</code> directly, unless the
original 'glmnet' object took a long time to fit. But if they do, they must
supply the fit, and all the original arguments used to create that fit. They
can limit the length of the relaxed path via 'maxp'.
</p>



<h3>Value</h3>

<p>An object with S3 class <code>"glmnet","*" </code>, where <code>"*"</code> is
<code>"elnet"</code>, <code>"lognet"</code>, <code>"multnet"</code>, <code>"fishnet"</code>
(poisson), <code>"coxnet"</code> or <code>"mrelnet"</code> for the various types of
models. If the model was created with <code>relax=TRUE</code> then this class has
a prefix class of <code>"relaxed"</code>.  </p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call that produced this
object</p>
</td></tr> <tr><td><code>a0</code></td>
<td>
<p>Intercept sequence of length <code>length(lambda)</code></p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>For <code>"elnet"</code>, <code>"lognet"</code>, <code>"fishnet"</code> and
<code>"coxnet"</code> models, a <code>nvars x length(lambda)</code> matrix of
coefficients, stored in sparse column format (<code>"CsparseMatrix"</code>). For
<code>"multnet"</code> and <code>"mgaussian"</code>, a list of <code>nc</code> such matrices,
one for each class.</p>
</td></tr> <tr><td><code>lambda</code></td>
<td>
<p>The actual sequence of <code>lambda</code>
values used. When <code>alpha=0</code>, the largest lambda reported does not quite
give the zero coefficients reported (<code>lambda=inf</code> would in principle).
Instead, the largest <code>lambda</code> for <code>alpha=0.001</code> is used, and the
sequence of <code>lambda</code> values is derived from this.</p>
</td></tr> <tr><td><code>dev.ratio</code></td>
<td>
<p>The
fraction of (null) deviance explained (for <code>"elnet"</code>, this is the
R-square). The deviance calculations incorporate weights if present in the
model. The deviance is defined to be 2*(loglike_sat - loglike), where
loglike_sat is the log-likelihood for the saturated model (a model with a
free parameter per observation). Hence dev.ratio=1-dev/nulldev.</p>
</td></tr>
<tr><td><code>nulldev</code></td>
<td>
<p>Null deviance (per observation). This is defined to be
2*(loglike_sat -loglike(Null)); The NULL model refers to the intercept
model, except for the Cox, where it is the 0 model.</p>
</td></tr> <tr><td><code>df</code></td>
<td>
<p>The number of
nonzero coefficients for each value of <code>lambda</code>. For <code>"multnet"</code>,
this is the number of variables with a nonzero coefficient for <em>any</em>
class.</p>
</td></tr> <tr><td><code>dfmat</code></td>
<td>
<p>For <code>"multnet"</code> and <code>"mrelnet"</code> only. A
matrix consisting of the number of nonzero coefficients per class</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>dimension of coefficient matrix (ices)</p>
</td></tr> <tr><td><code>nobs</code></td>
<td>
<p>number of
observations</p>
</td></tr> <tr><td><code>npasses</code></td>
<td>
<p>total passes over the data summed over all
lambda values</p>
</td></tr> <tr><td><code>offset</code></td>
<td>
<p>a logical variable indicating whether an offset
was included in the model</p>
</td></tr> <tr><td><code>jerr</code></td>
<td>
<p>error flag, for warnings and errors
(largely for internal debugging).</p>
</td></tr> <tr><td><code>relaxed</code></td>
<td>
<p>If <code>relax=TRUE</code>, this
additional item is another glmnet object with different values for
<code>beta</code> and <code>dev.ratio</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie, Balasubramanian Narasimhan, Noah
Simon, Kenneth Tay and Rob Tibshirani<br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.<br />
Tibshirani,Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and
Tibshirani, Ryan. (2012) <em>Strong Rules for Discarding Predictors in
Lasso-type Problems, JRSSB, Vol. 74(2), 245-266</em>,
<a href="https://arxiv.org/abs/1011.2234">https://arxiv.org/abs/1011.2234</a>.<br />
Hastie, T., Tibshirani, Robert and Tibshirani, Ryan (2020) <em>Best Subset,
Forward Stepwise or Lasso? Analysis and Recommendations Based on Extensive Comparisons,
Statist. Sc. Vol. 35(4), 579-592</em>,
<a href="https://arxiv.org/abs/1707.08692">https://arxiv.org/abs/1707.08692</a>.<br />
Glmnet webpage with four vignettes: <a href="https://glmnet.stanford.edu">https://glmnet.stanford.edu</a>.
</p>


<h3>See Also</h3>

<p><code>print</code>, <code>predict</code>, <code>coef</code> and <code>plot</code> methods,
and the <code>cv.glmnet</code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Gaussian
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit1 = glmnet(x, y)
print(fit1)
coef(fit1, s = 0.01)  # extract coefficients at a single value of lambda
predict(fit1, newx = x[1:10, ], s = c(0.01, 0.005))  # make predictions

# Relaxed
fit1r = glmnet(x, y, relax = TRUE)  # can be used with any model

# multivariate gaussian
y = matrix(rnorm(100 * 3), 100, 3)
fit1m = glmnet(x, y, family = "mgaussian")
plot(fit1m, type.coef = "2norm")

# binomial
g2 = sample(c(0,1), 100, replace = TRUE)
fit2 = glmnet(x, g2, family = "binomial")
fit2n = glmnet(x, g2, family = binomial(link=cloglog))
fit2r = glmnet(x,g2, family = "binomial", relax=TRUE)
fit2rp = glmnet(x,g2, family = "binomial", relax=TRUE, path=TRUE)

# multinomial
g4 = sample(1:4, 100, replace = TRUE)
fit3 = glmnet(x, g4, family = "multinomial")
fit3a = glmnet(x, g4, family = "multinomial", type.multinomial = "grouped")
# poisson
N = 500
p = 20
nzc = 5
x = matrix(rnorm(N * p), N, p)
beta = rnorm(nzc)
f = x[, seq(nzc)] %*% beta
mu = exp(f)
y = rpois(N, mu)
fit = glmnet(x, y, family = "poisson")
plot(fit)
pfit = predict(fit, x, s = 0.001, type = "response")
plot(pfit, y)

# Cox
set.seed(10101)
N = 1000
p = 30
nzc = p/3
x = matrix(rnorm(N * p), N, p)
beta = rnorm(nzc)
fx = x[, seq(nzc)] %*% beta/3
hx = exp(fx)
ty = rexp(N, hx)
tcens = rbinom(n = N, prob = 0.3, size = 1)  # censoring indicator
y = cbind(time = ty, status = 1 - tcens)  # y=Surv(ty,1-tcens) with library(survival)
fit = glmnet(x, y, family = "cox")
plot(fit)

# Cox example with (start, stop] data
set.seed(2)
nobs &lt;- 100; nvars &lt;- 15
xvec &lt;- rnorm(nobs * nvars)
xvec[sample.int(nobs * nvars, size = 0.4 * nobs * nvars)] &lt;- 0
x &lt;- matrix(xvec, nrow = nobs)
start_time &lt;- runif(100, min = 0, max = 5)
stop_time &lt;- start_time + runif(100, min = 0.1, max = 3)
status &lt;- rbinom(n = nobs, prob = 0.3, size = 1)
jsurv_ss &lt;- survival::Surv(start_time, stop_time, status)
fit &lt;- glmnet(x, jsurv_ss, family = "cox")

# Cox example with strata
jsurv_ss2 &lt;- stratifySurv(jsurv_ss, rep(1:2, each = 50))
fit &lt;- glmnet(x, jsurv_ss2, family = "cox")

# Sparse
n = 10000
p = 200
nzc = trunc(p/10)
x = matrix(rnorm(n * p), n, p)
iz = sample(1:(n * p), size = n * p * 0.85, replace = FALSE)
x[iz] = 0
sx = Matrix(x, sparse = TRUE)
inherits(sx, "sparseMatrix")  #confirm that it is sparse
beta = rnorm(nzc)
fx = x[, seq(nzc)] %*% beta
eps = rnorm(n)
y = fx + eps
px = exp(fx)
px = px/(1 + px)
ly = rbinom(n = length(px), prob = px, size = 1)
system.time(fit1 &lt;- glmnet(sx, y))
system.time(fit2n &lt;- glmnet(x, y))

</code></pre>

<hr>
<h2 id='glmnet-internal'>Internal glmnet functions</h2><span id='topic+glmnet-internal'></span><span id='topic+auc'></span><span id='topic+assess.coxnet'></span><span id='topic+auc.mat'></span><span id='topic+cvtype'></span><span id='topic+cvstats'></span><span id='topic+cvcompute'></span><span id='topic+getcoef'></span><span id='topic+getcoef.multinomial'></span><span id='topic+fix.lam'></span><span id='topic+error.bars'></span><span id='topic+getmin'></span><span id='topic+elnet'></span><span id='topic+mrelnet'></span><span id='topic+lognet'></span><span id='topic+fishnet'></span><span id='topic+coefnorm'></span><span id='topic+coxnet'></span><span id='topic+cv.lognet'></span><span id='topic+cv.elnet'></span><span id='topic+cv.multnet'></span><span id='topic+cv.mrelnet'></span><span id='topic+cv.coxnet'></span><span id='topic+cv.fishnet'></span><span id='topic+cv.glmnet.raw'></span><span id='topic+cv.relaxed.raw'></span><span id='topic+blend.relaxed'></span><span id='topic+checkgamma.relax'></span><span id='topic+buildPredmat'></span><span id='topic+buildPredmat.mrelnetlist'></span><span id='topic+buildPredmat.multnetlist'></span><span id='topic+buildPredmat.lognetlist'></span><span id='topic+buildPredmat.array'></span><span id='topic+buildPredmat.coxnetlist'></span><span id='topic+buildPredmat.default'></span><span id='topic+lambda.interp'></span><span id='topic+nonzeroCoef'></span><span id='topic+glmnet_softmax'></span><span id='topic+getOptcv.glmnet'></span><span id='topic+getOptcv.relaxed'></span><span id='topic+jerr'></span><span id='topic+jerr.elnet'></span><span id='topic+jerr.lognet'></span><span id='topic+jerr.fishnet'></span><span id='topic+jerr.coxnet'></span><span id='topic+jerr.mrelnet'></span><span id='topic+plotCoef'></span><span id='topic+zeromat'></span><span id='topic+na.mean'></span><span id='topic+check_dots'></span><span id='topic+na_sparse_fix'></span><span id='topic+prepareX'></span>

<h3>Description</h3>

<p>These are not intended for use by users. <code>lambda.interp</code> does linear
interpolation of the lambdas to obtain a prediction at a new point s.
<code>glmnet_softmax</code> does the classification for multinomial models.
<code>nonzeroCoef</code> determines in an efficient manner which variables are
nonzero in each fit. <code>jerr</code> prints out error messages from the C++ routines.
<code>plotCoef</code> is called by the <code>plot</code> method for <code>glmnet</code>
objects. <code>check_dots</code> is used in <code>coef</code> and <code>predict</code> with
argument <code>exact=TRUE</code>, to make sure user supplies original data used to
fit the <code>"glmnet"</code> object.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie
</p>

<hr>
<h2 id='glmnet-package'>Elastic net model paths for some generalized linear models</h2><span id='topic+glmnet-package'></span>

<h3>Description</h3>

<p>This package fits lasso and elastic-net model paths for regression, logistic
and multinomial regression using coordinate descent. The algorithm is
extremely fast, and exploits sparsity in the input x matrix where it exists.
A variety of predictions can be made from the fitted models.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;"> Package: </td><td style="text-align: left;"> glmnet</td>
</tr>
<tr>
 <td style="text-align: left;"> Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;"> Version: </td><td style="text-align: left;">
1.0</td>
</tr>
<tr>
 <td style="text-align: left;"> Date: </td><td style="text-align: left;"> 2008-05-14</td>
</tr>
<tr>
 <td style="text-align: left;"> License: </td><td style="text-align: left;"> What license is it under?</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>Very simple to use. Accepts <code>x,y</code> data for regression models, and
produces the regularization path over a grid of values for the tuning
parameter <code>lambda</code>. Only 5 functions: <code>glmnet</code><br />
<code>predict.glmnet</code><br /> <code>plot.glmnet</code><br /> <code>print.glmnet</code><br />
<code>coef.glmnet</code>
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie and Rob Tibshirani<br /> Maintainer:
Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.<br />
Tibshirani,Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and
Tibshirani, Ryan. (2012) <em>Strong Rules for Discarding Predictors in
Lasso-type Problems, JRSSB, Vol. 74(2), 245-266</em>,
<a href="https://arxiv.org/abs/1011.2234">https://arxiv.org/abs/1011.2234</a>.<br />
Hastie, T., Tibshirani, Robert and Tibshirani, Ryan (2020) <em>Best Subset,
Forward Stepwise or Lasso? Analysis and Recommendations Based on Extensive Comparisons,
Statist. Sc. Vol. 35(4), 579-592</em>,
<a href="https://arxiv.org/abs/1707.08692">https://arxiv.org/abs/1707.08692</a>.<br />
Glmnet webpage with four vignettes: <a href="https://glmnet.stanford.edu">https://glmnet.stanford.edu</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
g2 = sample(1:2, 100, replace = TRUE)
g4 = sample(1:4, 100, replace = TRUE)
fit1 = glmnet(x, y)
predict(fit1, newx = x[1:5, ], s = c(0.01, 0.005))
predict(fit1, type = "coef")
plot(fit1, xvar = "lambda")
fit2 = glmnet(x, g2, family = "binomial")
predict(fit2, type = "response", newx = x[2:5, ])
predict(fit2, type = "nonzero")
fit3 = glmnet(x, g4, family = "multinomial")
predict(fit3, newx = x[1:3, ], type = "response", s = 0.01)

</code></pre>

<hr>
<h2 id='glmnet.control'>internal glmnet parameters</h2><span id='topic+glmnet.control'></span>

<h3>Description</h3>

<p>View and/or change the factory default parameters in glmnet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet.control(
  fdev = 1e-05,
  devmax = 0.999,
  eps = 1e-06,
  big = 9.9e+35,
  mnlam = 5,
  pmin = 1e-09,
  exmx = 250,
  prec = 1e-10,
  mxit = 100,
  itrace = 0,
  epsnr = 1e-06,
  mxitnr = 25,
  factory = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmnet.control_+3A_fdev">fdev</code></td>
<td>
<p>minimum fractional change in deviance for stopping path; factory
default = 1.0e-5</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_devmax">devmax</code></td>
<td>
<p>maximum fraction of explained deviance for stopping path;
factory default = 0.999</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_eps">eps</code></td>
<td>
<p>minimum value of lambda.min.ratio (see glmnet); factory default=
1.0e-6</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_big">big</code></td>
<td>
<p>large floating point number; factory default = 9.9e35. Inf in
definition of upper.limit is set to big</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_mnlam">mnlam</code></td>
<td>
<p>minimum number of path points (lambda values) allowed; factory
default = 5</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_pmin">pmin</code></td>
<td>
<p>minimum probability for any class. factory default = 1.0e-9.
Note that this implies a pmax of 1-pmin.</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_exmx">exmx</code></td>
<td>
<p>maximum allowed exponent. factory default = 250.0</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_prec">prec</code></td>
<td>
<p>convergence threshold for multi response bounds adjustment
solution. factory default = 1.0e-10</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_mxit">mxit</code></td>
<td>
<p>maximum iterations for multiresponse bounds adjustment solution.
factory default = 100</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_itrace">itrace</code></td>
<td>
<p>If 1 then progress bar is displayed when running <code>glmnet</code>
and <code>cv.glmnet</code>. factory default = 0</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_epsnr">epsnr</code></td>
<td>
<p>convergence threshold for <code>glmnet.fit</code>. factory default =
1.0e-6</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_mxitnr">mxitnr</code></td>
<td>
<p>maximum iterations for the IRLS loop in <code>glmnet.fit</code>. factory
default = 25</p>
</td></tr>
<tr><td><code id="glmnet.control_+3A_factory">factory</code></td>
<td>
<p>If <code>TRUE</code>, reset all the parameters to the factory
default; default is <code>FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If called with no arguments, <code>glmnet.control()</code> returns a list with the
current settings of these parameters. Any arguments included in the call
sets those parameters to the new values, and then silently returns. The
values set are persistent for the duration of the R session.
</p>


<h3>Value</h3>

<p>A list with named elements as in the argument list
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Kenneth Tay, Trevor Hastie<br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>glmnet</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
glmnet.control(fdev = 0)  #continue along path even though not much changes
glmnet.control()  # view current settings
glmnet.control(factory = TRUE)  # reset all the parameters to their default

</code></pre>

<hr>
<h2 id='glmnet.fit'>Fit a GLM with elastic net regularization for a single value of lambda</h2><span id='topic+glmnet.fit'></span>

<h3>Description</h3>

<p>Fit a generalized linear model via penalized maximum likelihood for a single
value of lambda. Can deal with any GLM family.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet.fit(
  x,
  y,
  weights,
  lambda,
  alpha = 1,
  offset = rep(0, nobs),
  family = gaussian(),
  intercept = TRUE,
  thresh = 1e-10,
  maxit = 1e+05,
  penalty.factor = rep(1, nvars),
  exclude = c(),
  lower.limits = -Inf,
  upper.limits = Inf,
  warm = NULL,
  from.glmnet.path = FALSE,
  save.fit = FALSE,
  trace.it = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmnet.fit_+3A_x">x</code></td>
<td>
<p>Input matrix, of dimension <code>nobs x nvars</code>; each row is an
observation vector. If it is a sparse matrix, it is assumed to be unstandardized.
It should have attributes <code>xm</code> and <code>xs</code>, where <code>xm(j)</code> and
<code>xs(j)</code> are the centering and scaling factors for variable j respsectively.
If it is not a sparse matrix, it is assumed that any standardization needed
has already been done.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_y">y</code></td>
<td>
<p>Quantitative response variable.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_weights">weights</code></td>
<td>
<p>Observation weights. <code>glmnet.fit</code> does NOT standardize
these weights.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_lambda">lambda</code></td>
<td>
<p>A single value for the <code>lambda</code> hyperparameter.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>.
The penalty is defined as </p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.</code>
</p>

<p><code>alpha=1</code> is the lasso penalty, and <code>alpha=0</code> the ridge penalty.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_offset">offset</code></td>
<td>
<p>A vector of length <code>nobs</code> that is included in the linear
predictor. Useful for the &quot;poisson&quot; family (e.g. log of exposure time), or
for refining a model by starting at a current fit. Default is NULL. If
supplied, then values must also be supplied to the <code>predict</code> function.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_family">family</code></td>
<td>
<p>A description of the error distribution and link function to be
used in the model. This is the result of a call to a family function. Default
is <code>gaussian()</code>. (See <code><a href="stats.html#topic+family">family</a></code> for details on
family functions.)</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept be fitted (default=TRUE) or set to zero (FALSE)?</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_thresh">thresh</code></td>
<td>
<p>Convergence threshold for coordinate descent. Each inner
coordinate-descent loop continues until the maximum change in the objective
after any coefficient update is less than thresh times the null deviance.
Default value is <code>1e-10</code>.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of passes over the data; default is <code>10^5</code>.
(If a warm start object is provided, the number of passes the warm start object
performed is included.)</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each
coefficient. This is a number that multiplies <code>lambda</code> to allow differential
shrinkage. Can be 0 for some variables, which implies no shrinkage, and that
variable is always included in the model. Default is 1 for all variables (and
implicitly infinity for variables listed in exclude). Note: the penalty
factors are internally rescaled to sum to <code>nvars</code>.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the model. Default is
none. Equivalent to an infinite penalty factor.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_lower.limits">lower.limits</code></td>
<td>
<p>Vector of lower limits for each coefficient; default
<code>-Inf</code>. Each of these must be non-positive. Can be presented as a single
value (which will then be replicated), else a vector of length <code>nvars</code>.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_upper.limits">upper.limits</code></td>
<td>
<p>Vector of upper limits for each coefficient; default
<code>Inf</code>. See <code>lower.limits</code>.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_warm">warm</code></td>
<td>
<p>Either a <code>glmnetfit</code> object or a list (with names <code>beta</code>
and <code>a0</code> containing coefficients and intercept respectively) which can
be used as a warm start. Default is <code>NULL</code>, indicating no warm start.
For internal use only.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_from.glmnet.path">from.glmnet.path</code></td>
<td>
<p>Was <code>glmnet.fit()</code> called from <code>glmnet.path()</code>?
Default is FALSE.This has implications for computation of the penalty factors.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_save.fit">save.fit</code></td>
<td>
<p>Return the warm start object? Default is FALSE.</p>
</td></tr>
<tr><td><code id="glmnet.fit_+3A_trace.it">trace.it</code></td>
<td>
<p>Controls how much information is printed to screen. If
<code>trace.it=2</code>, some information about the fitting procedure is printed to
the console as the model is being fitted. Default is <code>trace.it=0</code>
(no information printed). (<code>trace.it=1</code> not used for compatibility with
<code>glmnet.path</code>.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WARNING: Users should not call <code>glmnet.fit</code> directly. Higher-level functions
in this package call <code>glmnet.fit</code> as a subroutine. If a warm start object
is provided, some of the other arguments in the function may be overriden.
</p>
<p><code>glmnet.fit</code> solves the elastic net problem for a single, user-specified
value of lambda. <code>glmnet.fit</code> works for any GLM family. It solves the
problem using iteratively reweighted least squares (IRLS). For each IRLS
iteration, <code>glmnet.fit</code> makes a quadratic (Newton) approximation of the
log-likelihood, then calls <code>elnet.fit</code> to minimize the resulting
approximation.
</p>
<p>In terms of standardization: <code>glmnet.fit</code> does not standardize <code>x</code>
and <code>weights</code>. <code>penalty.factor</code> is standardized so that they sum up
to <code>nvars</code>.
</p>


<h3>Value</h3>

<p>An object with class &quot;glmnetfit&quot; and &quot;glmnet&quot;. The list
returned contains more keys than that of a &quot;glmnet&quot; object.
</p>
<table>
<tr><td><code>a0</code></td>
<td>
<p>Intercept value.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A <code>nvars x 1</code> matrix of coefficients, stored in sparse matrix
format.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of nonzero coefficients.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Dimension of coefficient matrix.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Lambda value used.</p>
</td></tr>
<tr><td><code>dev.ratio</code></td>
<td>
<p>The fraction of (null) deviance explained. The deviance
calculations incorporate weights if present in the model. The deviance is
defined to be 2*(loglike_sat - loglike), where loglike_sat is the log-likelihood
for the saturated model (a model with a free parameter per observation).
Hence dev.ratio=1-dev/nulldev.</p>
</td></tr>
<tr><td><code>nulldev</code></td>
<td>
<p>Null deviance (per observation). This is defined to be
2*(loglike_sat -loglike(Null)). The null model refers to the intercept model.</p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>Total passes over the data.</p>
</td></tr>
<tr><td><code>jerr</code></td>
<td>
<p>Error flag, for warnings and errors (largely for internal
debugging).</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>A logical variable indicating whether an offset was included
in the model.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code>warm_fit</code></td>
<td>
<p>If <code>save.fit=TRUE</code>, output of C++ routine, used for
warm starts. For internal use only.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>Family used for the model.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>A logical variable: was the algorithm judged to have
converged?</p>
</td></tr>
<tr><td><code>boundary</code></td>
<td>
<p>A logical variable: is the fitted value on the boundary of
the attainable values?</p>
</td></tr>
<tr><td><code>obj_function</code></td>
<td>
<p>Objective function value at the solution.</p>
</td></tr>
</table>

<hr>
<h2 id='glmnet.measures'>Display the names of the measures used in CV for different &quot;glmnet&quot; families</h2><span id='topic+glmnet.measures'></span>

<h3>Description</h3>

<p>Produces a list of names of measures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet.measures(
  family = c("all", "gaussian", "binomial", "poisson", "multinomial", "cox", "mgaussian",
    "GLM")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmnet.measures_+3A_family">family</code></td>
<td>
<p>If a &quot;glmnet&quot; family is supplied, a list of the names of
measures available for that family are produced. Default is &quot;all&quot;, in which
case the names of measures for all families are produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Try it and see. A very simple function to provide information
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie<br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>cv.glmnet</code> and <code>assess.glmnet</code>.
</p>

<hr>
<h2 id='glmnet.path'>Fit a GLM with elastic net regularization for a path of lambda values</h2><span id='topic+glmnet.path'></span>

<h3>Description</h3>

<p>Fit a generalized linear model via penalized maximum likelihood for a path of
lambda values. Can deal with any GLM family.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet.path(
  x,
  y,
  weights = NULL,
  lambda = NULL,
  nlambda = 100,
  lambda.min.ratio = ifelse(nobs &lt; nvars, 0.01, 1e-04),
  alpha = 1,
  offset = NULL,
  family = gaussian(),
  standardize = TRUE,
  intercept = TRUE,
  thresh = 1e-10,
  maxit = 1e+05,
  penalty.factor = rep(1, nvars),
  exclude = integer(0),
  lower.limits = -Inf,
  upper.limits = Inf,
  trace.it = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmnet.path_+3A_x">x</code></td>
<td>
<p>Input matrix, of dimension <code>nobs x nvars</code>; each row is an
observation vector. Can be a sparse matrix.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_y">y</code></td>
<td>
<p>Quantitative response variable.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_weights">weights</code></td>
<td>
<p>Observation weights. Default is 1 for each observation.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda sequence. Typical usage is to have the
program compute its own lambda sequence based on <code>nlambda</code> and
<code>lambda.min.ratio</code>. Supplying a value of lambda overrides this.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values, default is 100.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for lambda as a fraction of lambda.max,
the (data derived) entry value (i.e. the smallest value for which all
coefficients are zero). The default depends on the sample size <code>nobs</code>
relative to the number of variables <code>nvars</code>. If <code>nobs &gt;= nvars</code>, the
default is 0.0001, close to zero. If <code>nobs &lt; nvars</code>, the default is 0.01.
A very small value of <code>lambda.min.ratio</code> will lead to a saturated fit
in the <code>nobs &lt; nvars</code> case. This is undefined for some families of
models, and the function will exit gracefully when the percentage deviance
explained is almost 1.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>.
The penalty is defined as </p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.</code>
</p>

<p><code>alpha=1</code> is the lasso penalty, and <code>alpha=0</code> the ridge penalty.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_offset">offset</code></td>
<td>
<p>A vector of length <code>nobs</code> that is included in the linear
predictor. Useful for the &quot;poisson&quot; family (e.g. log of exposure time), or
for refining a model by starting at a current fit. Default is NULL. If
supplied, then values must also be supplied to the <code>predict</code> function.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_family">family</code></td>
<td>
<p>A description of the error distribution and link function to be
used in the model. This is the result of a call to a family function. Default
is <code>gaussian()</code>. (See <code><a href="stats.html#topic+family">family</a></code> for details on
family functions.)</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for x variable standardization, prior to
fitting the model sequence. The coefficients are always returned on the
original scale. Default is <code>standardize=TRUE</code>. If variables are in the
same units already, you might not wish to standardize.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept be fitted (default=TRUE) or set to zero (FALSE)?</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_thresh">thresh</code></td>
<td>
<p>Convergence threshold for coordinate descent. Each inner
coordinate-descent loop continues until the maximum change in the objective
after any coefficient update is less than thresh times the null deviance.
Default value is <code>1e-10</code>.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of passes over the data; default is <code>10^5</code>.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each
coefficient. This is a number that multiplies <code>lambda</code> to allow differential
shrinkage. Can be 0 for some variables, which implies no shrinkage, and that
variable is always included in the model. Default is 1 for all variables (and
implicitly infinity for variables listed in exclude). Note: the penalty
factors are internally rescaled to sum to <code>nvars</code>.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the model. Default is
none. Equivalent to an infinite penalty factor.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_lower.limits">lower.limits</code></td>
<td>
<p>Vector of lower limits for each coefficient; default
<code>-Inf</code>. Each of these must be non-positive. Can be presented as a single
value (which will then be replicated), else a vector of length <code>nvars</code>.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_upper.limits">upper.limits</code></td>
<td>
<p>Vector of upper limits for each coefficient; default
<code>Inf</code>. See <code>lower.limits</code>.</p>
</td></tr>
<tr><td><code id="glmnet.path_+3A_trace.it">trace.it</code></td>
<td>
<p>Controls how much information is printed to screen. Default is
<code>trace.it=0</code> (no information printed). If <code>trace.it=1</code>, a progress
bar is displayed. If <code>trace.it=2</code>, some information about the fitting
procedure is printed to the console as the model is being fitted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>glmnet.path</code> solves the elastic net problem for a path of lambda values.
It generalizes <code>glmnet::glmnet</code> in that it works for any GLM family.
</p>
<p>Sometimes the sequence is truncated before <code>nlambda</code> values of lambda
have been used. This happens when <code>glmnet.path</code> detects that the decrease
in deviance is marginal (i.e. we are near a saturated fit).
</p>


<h3>Value</h3>

<p>An object with class &quot;glmnetfit&quot; and &quot;glmnet&quot;.
</p>
<table>
<tr><td><code>a0</code></td>
<td>
<p>Intercept sequence of length <code>length(lambda)</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A <code>nvars x length(lambda)</code> matrix of coefficients, stored in
sparse matrix format.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of nonzero coefficients for each value of lambda.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Dimension of coefficient matrix.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The actual sequence of lambda values used. When alpha=0, the
largest lambda reported does not quite give the zero coefficients reported
(lambda=inf would in principle). Instead, the largest lambda for alpha=0.001
is used, and the sequence of lambda values is derived from this.</p>
</td></tr>
<tr><td><code>dev.ratio</code></td>
<td>
<p>The fraction of (null) deviance explained. The deviance
calculations incorporate weights if present in the model. The deviance is
defined to be 2*(loglike_sat - loglike), where loglike_sat is the log-likelihood
for the saturated model (a model with a free parameter per observation).
Hence dev.ratio=1-dev/nulldev.</p>
</td></tr>
<tr><td><code>nulldev</code></td>
<td>
<p>Null deviance (per observation). This is defined to be
2*(loglike_sat -loglike(Null)). The null model refers to the intercept model.</p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>Total passes over the data summed over all lambda values.</p>
</td></tr>
<tr><td><code>jerr</code></td>
<td>
<p>Error flag, for warnings and errors (largely for internal
debugging).</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>A logical variable indicating whether an offset was included
in the model.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>Family used for the model.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(rnorm(100 * 20), nrow = 100)
y &lt;- ifelse(rnorm(100) &gt; 0, 1, 0)

# binomial with probit link
fit1 &lt;- glmnet:::glmnet.path(x, y, family = binomial(link = "probit"))
</code></pre>

<hr>
<h2 id='makeX'>convert a data frame to a data matrix with one-hot encoding</h2><span id='topic+makeX'></span>

<h3>Description</h3>

<p>Converts a data frame to a data matrix suitable for input to <code>glmnet</code>.
Factors are converted to dummy matrices via &quot;one-hot&quot; encoding. Options deal
with missing values and sparsity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeX(train, test = NULL, na.impute = FALSE, sparse = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeX_+3A_train">train</code></td>
<td>
<p>Required argument. A dataframe consisting of vectors, matrices
and factors</p>
</td></tr>
<tr><td><code id="makeX_+3A_test">test</code></td>
<td>
<p>Optional argument. A dataframe matching 'train' for use as
testing data</p>
</td></tr>
<tr><td><code id="makeX_+3A_na.impute">na.impute</code></td>
<td>
<p>Logical, default <code>FALSE</code>. If <code>TRUE</code>, missing
values for any column in the resultant 'x' matrix are replaced by the means
of the nonmissing values derived from 'train'</p>
</td></tr>
<tr><td><code id="makeX_+3A_sparse">sparse</code></td>
<td>
<p>Logical, default <code>FALSE</code>. If <code>TRUE</code> then the
returned matrice(s) are converted to matrices of class &quot;CsparseMatrix&quot;.
Useful if some factors have a large number of levels, resulting in very big
matrices, mostly zero</p>
</td></tr>
<tr><td><code id="makeX_+3A_...">...</code></td>
<td>
<p>additional arguments, currently unused</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main function is to convert factors to dummy matrices via &quot;one-hot&quot;
encoding. Having the 'train' and 'test' data present is useful if some
factor levels are missing in either. Since a factor with k levels leads to a
submatrix with 1/k entries zero, with large k the <code>sparse=TRUE</code> option
can be helpful; a large matrix will be returned, but stored in sparse matrix
format. Finally, the function can deal with missing data. The current
version has the option to replace missing observations with the mean from
the training data. For dummy submatrices, these are the mean proportions at
each level.
</p>


<h3>Value</h3>

<p>If only 'train' was provided, the function returns a matrix 'x'. If
missing values were imputed, this matrix has an attribute containing its
column means (before imputation). If 'test' was provided as well, a list
with two components is returned: 'x' and 'xtest'.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>glmnet</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(101)
### Single data frame
X = matrix(rnorm(20), 10, 2)
X3 = sample(letters[1:3], 10, replace = TRUE)
X4 = sample(LETTERS[1:3], 10, replace = TRUE)
df = data.frame(X, X3, X4)
makeX(df)
makeX(df, sparse = TRUE)

### Single data freame with missing values
Xn = X
Xn[3, 1] = NA
Xn[5, 2] = NA
X3n = X3
X3n[6] = NA
X4n = X4
X4n[9] = NA
dfn = data.frame(Xn, X3n, X4n)

makeX(dfn)
makeX(dfn, sparse = TRUE)
makeX(dfn, na.impute = TRUE)
makeX(dfn, na.impute = TRUE, sparse = TRUE)

### Test data as well
X = matrix(rnorm(10), 5, 2)
X3 = sample(letters[1:3], 5, replace = TRUE)
X4 = sample(LETTERS[1:3], 5, replace = TRUE)
dft = data.frame(X, X3, X4)

makeX(df, dft)
makeX(df, dft, sparse = TRUE)

### Missing data in test as well
Xn = X
Xn[3, 1] = NA
Xn[5, 2] = NA
X3n = X3
X3n[1] = NA
X4n = X4
X4n[2] = NA
dftn = data.frame(Xn, X3n, X4n)

makeX(dfn, dftn)
makeX(dfn, dftn, sparse = TRUE)
makeX(dfn, dftn, na.impute = TRUE)
makeX(dfn, dftn, sparse = TRUE, na.impute = TRUE)

</code></pre>

<hr>
<h2 id='MultiGaussianExample'>Synthetic dataset with multiple Gaussian responses</h2><span id='topic+MultiGaussianExample'></span>

<h3>Description</h3>

<p>Randomly generated data for multi-response Gaussian regression example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MultiGaussianExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>x</dt><dd><p>100 by 20 matrix of numeric values.</p>
</dd>
<dt>y</dt><dd><p>100 by 4 matrix of numeric values, each column representing
one response vector.</p>
</dd>
</dl>


<hr>
<h2 id='MultinomialExample'>Synthetic dataset with multinomial response</h2><span id='topic+MultinomialExample'></span>

<h3>Description</h3>

<p>Randomly generated data for multinomial regression example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MultinomialExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>x</dt><dd><p>500 by 30 matrix of numeric values.</p>
</dd>
<dt>y</dt><dd><p>Numeric vector of length 500 containing 142 ones, 174 twos
and 184 threes.</p>
</dd>
</dl>


<hr>
<h2 id='mycoxph'>Helper function to fit coxph model for survfit.coxnet</h2><span id='topic+mycoxph'></span>

<h3>Description</h3>

<p>This function constructs the coxph call needed to run the &quot;hack&quot; of
coxph with 0 iterations. It's a separate function as we have to deal with
function options like strata, offset and observation weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mycoxph(object, s, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mycoxph_+3A_object">object</code></td>
<td>
<p>A class <code>coxnet</code> object.</p>
</td></tr>
<tr><td><code id="mycoxph_+3A_s">s</code></td>
<td>
<p>The value of the penalty parameter lambda at which the survival
curve is required.</p>
</td></tr>
<tr><td><code id="mycoxph_+3A_...">...</code></td>
<td>
<p>The same ... that was passed to survfit.coxnet.</p>
</td></tr>
</table>

<hr>
<h2 id='mycoxpred'>Helper function to amend ... for new data in survfit.coxnet</h2><span id='topic+mycoxpred'></span>

<h3>Description</h3>

<p>This function amends the function arguments passed to survfit.coxnet
via ... if new data was passed to survfit.coxnet. It's a separate
function as we have to deal with function options like newstrata
and newoffset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mycoxpred(object, s, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mycoxpred_+3A_object">object</code></td>
<td>
<p>A class <code>coxnet</code> object.</p>
</td></tr>
<tr><td><code id="mycoxpred_+3A_s">s</code></td>
<td>
<p>The response for the fitted model.</p>
</td></tr>
<tr><td><code id="mycoxpred_+3A_...">...</code></td>
<td>
<p>The same ... that was passed to survfit.coxnet.</p>
</td></tr>
</table>

<hr>
<h2 id='na.replace'>Replace the missing entries in a matrix columnwise with the entries in a
supplied vector</h2><span id='topic+na.replace'></span>

<h3>Description</h3>

<p>Missing entries in any given column of the matrix are replaced by the column
means or the values in a supplied vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.replace(x, m = rowSums(x, na.rm = TRUE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="na.replace_+3A_x">x</code></td>
<td>
<p>A matrix with potentially missing values, and also potentially in
sparse matrix format (i.e. inherits from &quot;sparseMatrix&quot;)</p>
</td></tr>
<tr><td><code id="na.replace_+3A_m">m</code></td>
<td>
<p>Optional argument. A vector of values used to replace the missing
entries, columnwise. If missing, the column means of 'x' are used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a simple imputation scheme. This function is called by <code>makeX</code>
if the <code>na.impute=TRUE</code> option is used, but of course can be used on
its own. If 'x' is sparse, the result is sparse, and the replacements are
done so as to maintain sparsity.
</p>


<h3>Value</h3>

<p>A version of 'x' is returned with the missing values replaced.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>makeX</code> and <code>glmnet</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(101)
### Single data frame
X = matrix(rnorm(20), 10, 2)
X[3, 1] = NA
X[5, 2] = NA
X3 = sample(letters[1:3], 10, replace = TRUE)
X3[6] = NA
X4 = sample(LETTERS[1:3], 10, replace = TRUE)
X4[9] = NA
dfn = data.frame(X, X3, X4)

x = makeX(dfn)
m = rowSums(x, na.rm = TRUE)
na.replace(x, m)

x = makeX(dfn, sparse = TRUE)
na.replace(x, m)

</code></pre>

<hr>
<h2 id='obj_function'>Elastic net objective function value</h2><span id='topic+obj_function'></span>

<h3>Description</h3>

<p>Returns the elastic net objective function value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obj_function(y, mu, weights, family, lambda, alpha, coefficients, vp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="obj_function_+3A_y">y</code></td>
<td>
<p>Quantitative response variable.</p>
</td></tr>
<tr><td><code id="obj_function_+3A_mu">mu</code></td>
<td>
<p>Model's predictions for <code>y</code>.</p>
</td></tr>
<tr><td><code id="obj_function_+3A_weights">weights</code></td>
<td>
<p>Observation weights.</p>
</td></tr>
<tr><td><code id="obj_function_+3A_family">family</code></td>
<td>
<p>A description of the error distribution and link function to be
used in the model. This is the result of a call to a family function.</p>
</td></tr>
<tr><td><code id="obj_function_+3A_lambda">lambda</code></td>
<td>
<p>A single value for the <code>lambda</code> hyperparameter.</p>
</td></tr>
<tr><td><code id="obj_function_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>.</p>
</td></tr>
<tr><td><code id="obj_function_+3A_coefficients">coefficients</code></td>
<td>
<p>The model's coefficients (excluding intercept).</p>
</td></tr>
<tr><td><code id="obj_function_+3A_vp">vp</code></td>
<td>
<p>Penalty factors for each of the coefficients.</p>
</td></tr>
</table>

<hr>
<h2 id='pen_function'>Elastic net penalty value</h2><span id='topic+pen_function'></span>

<h3>Description</h3>

<p>Returns the elastic net penalty value without the <code>lambda</code> factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pen_function(coefficients, alpha = 1, vp = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pen_function_+3A_coefficients">coefficients</code></td>
<td>
<p>The model's coefficients (excluding intercept).</p>
</td></tr>
<tr><td><code id="pen_function_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>.</p>
</td></tr>
<tr><td><code id="pen_function_+3A_vp">vp</code></td>
<td>
<p>Penalty factors for each of the coefficients.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The penalty is defined as
</p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2 \sum vp_j \beta_j^2 + \alpha \sum vp_j |\beta|.</code>
</p>

<p>Note the omission of the multiplicative <code>lambda</code> factor.
</p>

<hr>
<h2 id='plot.cv.glmnet'>plot the cross-validation curve produced by cv.glmnet</h2><span id='topic+plot.cv.glmnet'></span><span id='topic+plot.cv.relaxed'></span>

<h3>Description</h3>

<p>Plots the cross-validation curve, and upper and lower standard deviation
curves, as a function of the <code>lambda</code> values used. If the object has
class <code>"cv.relaxed"</code> a different plot is produced, showing both
<code>lambda</code> and <code>gamma</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.glmnet'
plot(x, sign.lambda = 1, ...)

## S3 method for class 'cv.relaxed'
plot(x, se.bands = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.glmnet_+3A_x">x</code></td>
<td>
<p>fitted <code>"cv.glmnet"</code> object</p>
</td></tr>
<tr><td><code id="plot.cv.glmnet_+3A_sign.lambda">sign.lambda</code></td>
<td>
<p>Either plot against <code>log(lambda)</code> (default) or its
negative if <code>sign.lambda=-1</code>.</p>
</td></tr>
<tr><td><code id="plot.cv.glmnet_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot</p>
</td></tr>
<tr><td><code id="plot.cv.glmnet_+3A_se.bands">se.bands</code></td>
<td>
<p>Should shading be produced to show standard-error bands;
default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>A plot is produced, and nothing is returned.
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie and Rob Tibshirani<br /> Maintainer:
Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent</em>
</p>


<h3>See Also</h3>

<p><code>glmnet</code> and <code>cv.glmnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1010)
n = 1000
p = 100
nzc = trunc(p/10)
x = matrix(rnorm(n * p), n, p)
beta = rnorm(nzc)
fx = (x[, seq(nzc)] %*% beta)
eps = rnorm(n) * 5
y = drop(fx + eps)
px = exp(fx)
px = px/(1 + px)
ly = rbinom(n = length(px), prob = px, size = 1)
cvob1 = cv.glmnet(x, y)
plot(cvob1)
title("Gaussian Family", line = 2.5)
cvob1r = cv.glmnet(x, y, relax = TRUE)
plot(cvob1r)
frame()
set.seed(1011)
par(mfrow = c(2, 2), mar = c(4.5, 4.5, 4, 1))
cvob2 = cv.glmnet(x, ly, family = "binomial")
plot(cvob2)
title("Binomial Family", line = 2.5)
## set.seed(1011)
## cvob3 = cv.glmnet(x, ly, family = "binomial", type = "class")
## plot(cvob3)
## title("Binomial Family", line = 2.5)

</code></pre>

<hr>
<h2 id='plot.glmnet'>plot coefficients from a &quot;glmnet&quot; object</h2><span id='topic+plot.glmnet'></span><span id='topic+plot.multnet'></span><span id='topic+plot.mrelnet'></span><span id='topic+plot.relaxed'></span>

<h3>Description</h3>

<p>Produces a coefficient profile plot of the coefficient paths for a fitted
<code>"glmnet"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmnet'
plot(x, xvar = c("norm", "lambda", "dev"), label = FALSE, ...)

## S3 method for class 'mrelnet'
plot(
  x,
  xvar = c("norm", "lambda", "dev"),
  label = FALSE,
  type.coef = c("coef", "2norm"),
  ...
)

## S3 method for class 'multnet'
plot(
  x,
  xvar = c("norm", "lambda", "dev"),
  label = FALSE,
  type.coef = c("coef", "2norm"),
  ...
)

## S3 method for class 'relaxed'
plot(x, xvar = c("lambda", "dev"), label = FALSE, gamma = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.glmnet_+3A_x">x</code></td>
<td>
<p>fitted <code>"glmnet"</code> model</p>
</td></tr>
<tr><td><code id="plot.glmnet_+3A_xvar">xvar</code></td>
<td>
<p>What is on the X-axis. <code>"norm"</code> plots against the L1-norm
of the coefficients, <code>"lambda"</code> against the log-lambda sequence, and
<code>"dev"</code> against the percent deviance explained.</p>
</td></tr>
<tr><td><code id="plot.glmnet_+3A_label">label</code></td>
<td>
<p>If <code>TRUE</code>, label the curves with variable sequence
numbers.</p>
</td></tr>
<tr><td><code id="plot.glmnet_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot</p>
</td></tr>
<tr><td><code id="plot.glmnet_+3A_type.coef">type.coef</code></td>
<td>
<p>If <code>type.coef="2norm"</code> then a single curve per
variable, else if <code>type.coef="coef"</code>, a coefficient plot per response</p>
</td></tr>
<tr><td><code id="plot.glmnet_+3A_gamma">gamma</code></td>
<td>
<p>Value of the mixing parameter for a &quot;relaxed&quot; fit</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A coefficient profile plot is produced. If <code>x</code> is a multinomial model,
a coefficient plot is produced for each class.
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie and Rob Tibshirani<br /> Maintainer:
Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent</em>
</p>


<h3>See Also</h3>

<p><code>glmnet</code>, and <code>print</code>, <code>predict</code> and <code>coef</code>
methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
g2=sample(1:2,100,replace=TRUE)
g4=sample(1:4,100,replace=TRUE)
fit1=glmnet(x,y)
plot(fit1)
plot(fit1,xvar="lambda",label=TRUE)
fit3=glmnet(x,g4,family="multinomial")
plot(fit3,pch=19)
</code></pre>

<hr>
<h2 id='PoissonExample'>Synthetic dataset with count response</h2><span id='topic+PoissonExample'></span>

<h3>Description</h3>

<p>Randomly generated data for Poisson regression example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PoissonExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>x</dt><dd><p>500 by 20 matrix of numeric values.</p>
</dd>
<dt>y</dt><dd><p>Numeric vector of length 500 consisting of non-negative
integers.</p>
</dd>
</dl>


<hr>
<h2 id='predict.cv.glmnet'>make predictions from a &quot;cv.glmnet&quot; object.</h2><span id='topic+predict.cv.glmnet'></span><span id='topic+coef.cv.glmnet'></span><span id='topic+coef.cv.relaxed'></span><span id='topic+predict.cv.relaxed'></span>

<h3>Description</h3>

<p>This function makes predictions from a cross-validated glmnet model, using
the stored <code>"glmnet.fit"</code> object, and the optimal value chosen for
<code>lambda</code> (and <code>gamma</code> for a 'relaxed' fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.glmnet'
predict(object, newx, s = c("lambda.1se", "lambda.min"), ...)

## S3 method for class 'cv.relaxed'
predict(
  object,
  newx,
  s = c("lambda.1se", "lambda.min"),
  gamma = c("gamma.1se", "gamma.min"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.glmnet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"cv.glmnet"</code> or <code>"cv.relaxed"</code> object.</p>
</td></tr>
<tr><td><code id="predict.cv.glmnet_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be
made. Must be a matrix; can be sparse as in <code>Matrix</code> package. See
documentation for <code>predict.glmnet</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.glmnet_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter <code>lambda</code> at which
predictions are required. Default is the value <code>s="lambda.1se"</code> stored
on the CV <code>object</code>. Alternatively <code>s="lambda.min"</code> can be used. If
<code>s</code> is numeric, it is taken as the value(s) of <code>lambda</code> to be
used. (For historical reasons we use the symbol 's' rather than 'lambda' to
reference this parameter)</p>
</td></tr>
<tr><td><code id="predict.cv.glmnet_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to predict.</p>
</td></tr>
<tr><td><code id="predict.cv.glmnet_+3A_gamma">gamma</code></td>
<td>
<p>Value (single) of 'gamma' at which predictions are to be made</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes it easier to use the results of cross-validation to make
a prediction.
</p>


<h3>Value</h3>

<p>The object returned depends on the ... argument which is passed
on to the <code>predict</code> method for <code>glmnet</code> objects.
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie and Rob Tibshirani<br /> Maintainer:
Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.<br />
Hastie, T., Tibshirani, Robert and Tibshirani, Ryan (2020) <em>Best Subset,
Forward Stepwise or Lasso? Analysis and Recommendations Based on Extensive Comparisons,
Statist. Sc. Vol. 35(4), 579-592</em>,
<a href="https://arxiv.org/abs/1707.08692">https://arxiv.org/abs/1707.08692</a>.<br />
Glmnet webpage with four vignettes, <a href="https://glmnet.stanford.edu">https://glmnet.stanford.edu</a>.
</p>


<h3>See Also</h3>

<p><code>glmnet</code>, and <code>print</code>, and <code>coef</code> methods, and
<code>cv.glmnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
cv.fit = cv.glmnet(x, y)
predict(cv.fit, newx = x[1:5, ])
coef(cv.fit)
coef(cv.fit, s = "lambda.min")
predict(cv.fit, newx = x[1:5, ], s = c(0.001, 0.002))
cv.fitr = cv.glmnet(x, y, relax = TRUE)
predict(cv.fit, newx = x[1:5, ])
coef(cv.fit)
coef(cv.fit, s = "lambda.min", gamma = "gamma.min")
predict(cv.fit, newx = x[1:5, ], s = c(0.001, 0.002), gamma = "gamma.min")

</code></pre>

<hr>
<h2 id='predict.glmnetfit'>Get predictions from a <code>glmnetfit</code> fit object</h2><span id='topic+predict.glmnetfit'></span>

<h3>Description</h3>

<p>Gives fitted values, linear predictors, coefficients and number of non-zero
coefficients from a fitted <code>glmnetfit</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmnetfit'
predict(
  object,
  newx,
  s = NULL,
  type = c("link", "response", "coefficients", "nonzero"),
  exact = FALSE,
  newoffset,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.glmnetfit_+3A_object">object</code></td>
<td>
<p>Fitted &quot;glmnetfit&quot; object.</p>
</td></tr>
<tr><td><code id="predict.glmnetfit_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be
made. Must be a matrix. This argument is not used for <code>type =
c("coefficients","nonzero")</code>.</p>
</td></tr>
<tr><td><code id="predict.glmnetfit_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter lambda at which predictions are
required. Default is the entire sequence used to create the model.</p>
</td></tr>
<tr><td><code id="predict.glmnetfit_+3A_type">type</code></td>
<td>
<p>Type of prediction required. Type &quot;link&quot; gives the linear
predictors (eta scale); Type &quot;response&quot; gives the fitted values (mu scale).
Type &quot;coefficients&quot; computes the coefficients at the requested values for s.
Type &quot;nonzero&quot; returns a list of the indices of the nonzero coefficients for
each value of s.</p>
</td></tr>
<tr><td><code id="predict.glmnetfit_+3A_exact">exact</code></td>
<td>
<p>This argument is relevant only when predictions are made at values
of <code>s</code> (lambda) <em>different</em> from those used in the fitting of the
original model. If <code>exact=FALSE</code> (default), then the predict function
uses linear interpolation to make predictions for values of <code>s</code> (lambda)
that do not coincide with those used in the fitting algorithm. While this is
often a good approximation, it can sometimes be a bit coarse. With
<code>exact=TRUE</code>, these different values of <code>s</code> are merged (and sorted)
with <code>object$lambda</code>, and the model is refit before predictions are made.
In this case, it is required to supply the original data x= and y= as additional
named arguments to predict() or coef(). The workhorse <code>predict.glmnet()</code>
needs to update the model, and so needs the data used to create it. The same
is true of weights, offset, penalty.factor, lower.limits, upper.limits if
these were used in the original call. Failure to do so will result in an error.</p>
</td></tr>
<tr><td><code id="predict.glmnetfit_+3A_newoffset">newoffset</code></td>
<td>
<p>If an offset is used in the fit, then one must be supplied for
making predictions (except for type=&quot;coefficients&quot; or type=&quot;nonzero&quot;).</p>
</td></tr>
<tr><td><code id="predict.glmnetfit_+3A_...">...</code></td>
<td>
<p>This is the mechanism for passing arguments like <code>x=</code> when
<code>exact=TRUE</code>; see <code>exact</code> argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on type.
</p>

<hr>
<h2 id='print.cv.glmnet'>print a cross-validated glmnet object</h2><span id='topic+print.cv.glmnet'></span><span id='topic+print.cv.relaxed'></span>

<h3>Description</h3>

<p>Print a summary of the results of cross-validation for a glmnet model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.glmnet'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cv.glmnet_+3A_x">x</code></td>
<td>
<p>fitted 'cv.glmnet' object</p>
</td></tr>
<tr><td><code id="print.cv.glmnet_+3A_digits">digits</code></td>
<td>
<p>significant digits in printout</p>
</td></tr>
<tr><td><code id="print.cv.glmnet_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A summary of the cross-validated fit is produced, slightly different for a
'cv.relaxed' object than for a 'cv.glmnet' object.  Note that a 'cv.relaxed'
object inherits from class 'cv.glmnet', so by directly invoking
<code>print.cv.glmnet(object)</code> will print the summary as if
<code>relax=TRUE</code> had not been used.
</p>


<h3>Author(s)</h3>

<p>Jerome Friedman, Trevor Hastie and Rob Tibshirani<br /> Maintainer:
Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent</em><br /> <a href="https://arxiv.org/abs/1707.08692">https://arxiv.org/abs/1707.08692</a><br /> Hastie, T.,
Tibshirani, Robert, Tibshirani, Ryan (2019) <em>Extended Comparisons of
Best Subset Selection, Forward Stepwise Selection, and the Lasso</em>
</p>


<h3>See Also</h3>

<p><code>glmnet</code>, <code>predict</code> and <code>coef</code> methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit1 = cv.glmnet(x, y)
print(fit1)
fit1r = cv.glmnet(x, y, relax = TRUE)
print(fit1r)
## print.cv.glmnet(fit1r)  ## CHECK WITH TREVOR
</code></pre>

<hr>
<h2 id='print.glmnet'>print a glmnet object</h2><span id='topic+print.glmnet'></span><span id='topic+print.relaxed'></span><span id='topic+print.bigGlm'></span>

<h3>Description</h3>

<p>Print a summary of the glmnet path at each step along the path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmnet'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.glmnet_+3A_x">x</code></td>
<td>
<p>fitted glmnet object</p>
</td></tr>
<tr><td><code id="print.glmnet_+3A_digits">digits</code></td>
<td>
<p>significant digits in printout</p>
</td></tr>
<tr><td><code id="print.glmnet_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The call that produced the object <code>x</code> is printed, followed by a
three-column matrix with columns <code>Df</code>, <code style="white-space: pre;">&#8288;%Dev&#8288;</code> and <code>Lambda</code>.
The <code>Df</code> column is the number of nonzero coefficients (Df is a
reasonable name only for lasso fits). <code style="white-space: pre;">&#8288;%Dev&#8288;</code> is the percent deviance
explained (relative to the null deviance).  In the case of a 'relaxed' fit,
an additional column is inserted, <code style="white-space: pre;">&#8288;%Dev R&#8288;</code> which gives the percent
deviance explained by the relaxed model. For a &quot;bigGlm&quot; model, a simpler
summary is printed.
</p>


<h3>Value</h3>

<p>The matrix above is silently returned
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008). Regularization Paths for Generalized Linear Models via Coordinate Descent
</p>


<h3>See Also</h3>

<p><code>glmnet</code>, <code>predict</code> and <code>coef</code> methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit1 = glmnet(x, y)
print(fit1)
</code></pre>

<hr>
<h2 id='QuickStartExample'>Synthetic dataset with Gaussian response</h2><span id='topic+QuickStartExample'></span>

<h3>Description</h3>

<p>Randomly generated data for Gaussian regression example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(QuickStartExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>x</dt><dd><p>100 by 20 matrix of numeric values.</p>
</dd>
<dt>y</dt><dd><p>Numeric vector of length 100.</p>
</dd>
</dl>


<hr>
<h2 id='response.coxnet'>Make response for coxnet</h2><span id='topic+response.coxnet'></span>

<h3>Description</h3>

<p>Internal function to make the response y passed to glmnet suitable
for coxnet (i.e. glmnet with family = &quot;cox&quot;). Sanity checks are performed
here too.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>response.coxnet(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="response.coxnet_+3A_y">y</code></td>
<td>
<p>Response variable. Either a class &quot;Surv&quot; object or a two-column
matrix with columns named 'time' and 'status'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If y is a class &quot;Surv&quot; object, this function returns y with no changes. If
y is a two-column matrix with columns named 'time' and 'status', it is
converted into a &quot;Surv&quot; object.
</p>


<h3>Value</h3>

<p>A class &quot;Surv&quot; object.
</p>

<hr>
<h2 id='rmult'>Generate multinomial samples from a probability matrix</h2><span id='topic+rmult'></span>

<h3>Description</h3>

<p>Generate multinomial samples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmult(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmult_+3A_p">p</code></td>
<td>
<p>matrix of probabilities, with number of columns the number of classes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simple function that calls the <code>rmultinom</code> function. It generates a class label
for each row of its input matrix of class probabilities.
</p>


<h3>Value</h3>

<p>a vector of class memberships
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>

<hr>
<h2 id='SparseExample'>Synthetic dataset with sparse design matrix</h2><span id='topic+SparseExample'></span>

<h3>Description</h3>

<p>Randomly generated data for Gaussian regression example with the
design matrix x being in sparse matrix format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SparseExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>x</dt><dd><p>100 by 20 matrix of numeric values. x is in sparse matrix
format, having class &quot;dgCMatrix&quot;.</p>
</dd>
<dt>y</dt><dd><p>Numeric vector of length 100.</p>
</dd>
</dl>


<hr>
<h2 id='stratifySurv'>Add strata to a Surv object</h2><span id='topic+stratifySurv'></span>

<h3>Description</h3>

<p>Helper function to add strata as an attribute to a Surv object. The
output of this function can be used as the response in <code>glmnet()</code>
for fitting stratified Cox models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stratifySurv(y, strata = rep(1, length(y)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stratifySurv_+3A_y">y</code></td>
<td>
<p>A Surv object.</p>
</td></tr>
<tr><td><code id="stratifySurv_+3A_strata">strata</code></td>
<td>
<p>A vector of length equal to the number of observations in
y, indicating strata membership. Default is all belong to same strata.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When fitting a stratified Cox model with <code>glmnet()</code>, strata should
be added to a <code>Surv</code> response with this helper function. Note that
it is not sufficient to add strata as an attribute to the <code>Surv</code>
response manually: if the result does not have class <code>stratifySurv</code>,
subsetting of the response will not work properly.
</p>


<h3>Value</h3>

<p>An object of class <code>stratifySurv</code> (in addition to all the
classes <code>y</code> belonged to).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- survival::Surv(1:10, rep(0:1, length.out = 10))
strata &lt;- rep(1:3, length.out = 10)
y2 &lt;- stratifySurv(y, strata)  # returns stratifySurv object

</code></pre>

<hr>
<h2 id='survfit.coxnet'>Compute a survival curve from a coxnet object</h2><span id='topic+survfit.coxnet'></span>

<h3>Description</h3>

<p>Computes the predicted survivor function for a Cox proportional hazards
model with elastic net penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coxnet'
survfit(formula, s = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="survfit.coxnet_+3A_formula">formula</code></td>
<td>
<p>A class <code>coxnet</code> object.</p>
</td></tr>
<tr><td><code id="survfit.coxnet_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter lambda at which the survival
curve is required. Default is the entire sequence used to create the model.
However, it is recommended that <code>survfit.coxnet</code> is called for
a single penalty parameter.</p>
</td></tr>
<tr><td><code id="survfit.coxnet_+3A_...">...</code></td>
<td>
<p>This is the mechanism for passing additional arguments like
(i) x= and y= for the x and y used to fit the model,
(ii) weights= and offset= when the model was fit with these options,
(iii) arguments for new data (newx, newoffset, newstrata), and
(iv) arguments to be passed to survfit.coxph().</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To be consistent with other functions in <code>glmnet</code>, if <code>s</code>
is not specified, survival curves are returned for the entire lambda
sequence. This is not recommended usage: it is best to call
<code>survfit.coxnet</code> with a single value of the penalty parameter
for the <code>s</code> option.
</p>


<h3>Value</h3>

<p>If <code>s</code> is a single value, an object of class &quot;survfitcox&quot;
and &quot;survfit&quot; containing one or more survival curves. Otherwise, a list
of such objects, one element for each value in <code>s</code>.
Methods defined for survfit objects are print, summary and plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2)
nobs &lt;- 100; nvars &lt;- 15
xvec &lt;- rnorm(nobs * nvars)
xvec[sample.int(nobs * nvars, size = 0.4 * nobs * nvars)] &lt;- 0
x &lt;- matrix(xvec, nrow = nobs)
beta &lt;- rnorm(nvars / 3)
fx &lt;- x[, seq(nvars / 3)] %*% beta / 3
ty &lt;- rexp(nobs, exp(fx))
tcens &lt;- rbinom(n = nobs, prob = 0.3, size = 1)
y &lt;- survival::Surv(ty, tcens)
fit1 &lt;- glmnet(x, y, family = "cox")

# survfit object for Cox model where lambda = 0.1
sf1 &lt;- survival::survfit(fit1, s = 0.1, x = x, y = y)
plot(sf1)

# example with new data
sf2 &lt;- survival::survfit(fit1, s = 0.1, x = x, y = y, newx = x[1:3, ])
plot(sf2)

# example with strata
y2 &lt;- stratifySurv(y, rep(1:2, length.out = nobs))
fit2 &lt;- glmnet(x, y2, family = "cox")
sf3 &lt;- survival::survfit(fit2, s = 0.1, x = x, y = y2)
sf4 &lt;- survival::survfit(fit2, s = 0.1, x = x, y = y2,
               newx = x[1:3, ], newstrata = c(1, 1, 1))

</code></pre>

<hr>
<h2 id='survfit.cv.glmnet'>Compute a survival curve from a cv.glmnet object</h2><span id='topic+survfit.cv.glmnet'></span>

<h3>Description</h3>

<p>Computes the predicted survivor function for a Cox proportional hazards
model with elastic net penalty from a cross-validated glmnet model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.glmnet'
survfit(formula, s = c("lambda.1se", "lambda.min"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="survfit.cv.glmnet_+3A_formula">formula</code></td>
<td>
<p>A class <code>cv.glmnet</code> object. The object should have
been fit with <code>family = "cox"</code>.</p>
</td></tr>
<tr><td><code id="survfit.cv.glmnet_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter lambda at which predictions
are required. Default is the value s=&quot;lambda.1se&quot; stored on the CV object.
Alternatively s=&quot;lambda.min&quot; can be used. If s is numeric, it is taken
as the value(s) of lambda to be used.</p>
</td></tr>
<tr><td><code id="survfit.cv.glmnet_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>survfit.coxnet</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes it easier to use the results of cross-validation
to compute a survival curve.
</p>


<h3>Value</h3>

<p>If <code>s</code> is a single value, an object of class &quot;survfitcox&quot;
and &quot;survfit&quot; containing one or more survival curves. Otherwise, a list
of such objects, one element for each value in <code>s</code>.
Methods defined for survfit objects are print, summary and plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2)
nobs &lt;- 100; nvars &lt;- 15
xvec &lt;- rnorm(nobs * nvars)
x &lt;- matrix(xvec, nrow = nobs)
beta &lt;- rnorm(nvars / 3)
fx &lt;- x[, seq(nvars / 3)] %*% beta / 3
ty &lt;- rexp(nobs, exp(fx))
tcens &lt;- rbinom(n = nobs, prob = 0.3, size = 1)
y &lt;- survival::Surv(ty, tcens)
cvfit &lt;- cv.glmnet(x, y, family = "cox")
# default: s = "lambda.1se"
survival::survfit(cvfit, x = x, y = y)

# s = "lambda.min"
survival::survfit(cvfit, s = "lambda.min", x = x, y = y)
</code></pre>

<hr>
<h2 id='use.cox.path'>Check if glmnet should call cox.path</h2><span id='topic+use.cox.path'></span>

<h3>Description</h3>

<p>Helper function to check if glmnet() should call cox.path().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>use.cox.path(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="use.cox.path_+3A_x">x</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code id="use.cox.path_+3A_y">y</code></td>
<td>
<p>Response variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>family="cox"</code>, we only call the original coxnet() function if
(i) x is not sparse, (ii) y is right-censored data, and (iii) we are
not fitting a stratified Cox model. This function also throws an error
if y has a &quot;strata&quot; attribute but is not of type &quot;stratifySurv&quot;.
</p>


<h3>Value</h3>

<p>TRUE if cox.path() should be called, FALSE otherwise.
</p>

<hr>
<h2 id='weighted_mean_sd'>Helper function to compute weighted mean and standard deviation</h2><span id='topic+weighted_mean_sd'></span>

<h3>Description</h3>

<p>Helper function to compute weighted mean and standard deviation.
Deals gracefully whether x is sparse matrix or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted_mean_sd(x, weights = rep(1, nrow(x)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted_mean_sd_+3A_x">x</code></td>
<td>
<p>Observation matrix.</p>
</td></tr>
<tr><td><code id="weighted_mean_sd_+3A_weights">weights</code></td>
<td>
<p>Optional weight vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components.
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>vector of weighted means of columns of x</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>vector of weighted standard deviations of columns of x</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
