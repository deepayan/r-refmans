<!DOCTYPE html><html lang="en"><head><title>Help for package discnorm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {discnorm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bootTest'><p>Bootstrap test for discretized normality</p></a></li>
<li><a href='#catLSadj'><p>Adjusted polychoric correlation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Test for Discretized Normality in Ordinal Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Tests whether multivariate ordinal data may stem from discretizing a multivariate normal distribution.
             The test is described by Foldnes and Grønneberg (2019) &lt;<a href="https://doi.org/10.1080%2F10705511.2019.1673168">doi:10.1080/10705511.2019.1673168</a>&gt;. 
             In addition, an adjusted polychoric correlation estimator is provided that takes marginal knowledge into account,
             as described by Grønneberg and Foldnes (2022) &lt;<a href="https://doi.org/10.1037%2Fmet0000495">doi:10.1037/met0000495</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>lavaan (&ge; 0.6.10), arules, sirt, MASS, pbivnorm, cubature,
copula, mnormt, GoFKernel</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-25 10:00:38 UTC; njaalfoldnes</td>
</tr>
<tr>
<td>Author:</td>
<td>Njål Foldnes [aut, cre],
  Steffen Grønneberg [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Njål Foldnes &lt;njal.foldnes@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-25 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bootTest'>Bootstrap test for discretized normality</h2><span id='topic+bootTest'></span>

<h3>Description</h3>

<p><code>bootTest</code> is a bootstrap test for whether an ordinal dataset is consistent with being
a discretization of a multivariate normal dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootTest(my.data, B = 1000, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootTest_+3A_my.data">my.data</code></td>
<td>
<p>A dataset containing ordinal data. Must contain only integer values.</p>
</td></tr>
<tr><td><code id="bootTest_+3A_b">B</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="bootTest_+3A_verbose">verbose</code></td>
<td>
<p>If true, bootstrap progress is printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>p-value associated with the underlying normality hypothesis.
</p>


<h3>References</h3>

<p>Njål Foldnes &amp; Steffen Grønneberg (2019) Pernicious Polychorics: The Impact and Detection of Underlying Non-normality, Structural Equation Modeling: A Multidisciplinary Journal, DOI: 10.1080/10705511.2019.1673168
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
norm.data &lt;- MASS::mvrnorm(300, m=rep(0,3), 
Sigma=cov(MASS::mvrnorm(15, mu=rep(0,3), Sigma=diag(3))))
disc.data &lt;- apply(norm.data,2,  cut, 
breaks = c(-Inf, 0,1, Inf), labels=FALSE)# normal data discretized
pvalue &lt;- bootTest(disc.data, B=500)
#no support for underlying non-normality
</code></pre>

<hr>
<h2 id='catLSadj'>Adjusted polychoric correlation</h2><span id='topic+catLSadj'></span>

<h3>Description</h3>

<p><code>catLSadj</code> estimates the underlying correlations assuming bivariate normal copulas, and marginal underlying distributions as provided by the user. 
The output, i.e., an adjusted correlation matrix and its associated asymptotic covariance matrix, may be used to estimate ordinal factor models and structural equation models with systems such as lavaan.
How to do this is shown in the example/vignette.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catLSadj(data.df, marginslist, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="catLSadj_+3A_data.df">data.df</code></td>
<td>
<p>A dataset containing ordinal data.</p>
</td></tr>
<tr><td><code id="catLSadj_+3A_marginslist">marginslist</code></td>
<td>
<p>A list of length equal to the number of columns in data.df. Each element in the list
specifies a univariate marginal distribution. 
Each element must contain a function F, which is the univariate
CDF of the marginal. It must accept vectorial input.
</p>
<p>F is assumed to be continuous, and have support on a interval, which
may be all numbers.
That is, a random variable X which is F distributed can take
any values in an interval (which could be the set of all real numbers).
In addition, elements &quot;qF&quot;, &quot;sd&quot; and &quot;support&quot; may be included.
&quot;qF&quot; is to be the quantile function of F.
&quot;sd&quot; is to be the standard deviation of F.
&quot;support&quot; is the support of the distribution of F.
If &quot;support&quot; is not included, it is assumed to be all numbers.
If qF or sd is not included, they are numerically approximated.
</p>
<p>For optimal performance, both qF and sd should be passed.
If they are not provided, they will be approximated numerically, sometimes
at great cost of both precision and execution speed. 
For all well-known univariate distributions, both qF and sd are well-known.
Implementations for most quantiles are available in R, and standard deviation
formulas for most distributions are available on Wikipedia.</p>
</td></tr>
<tr><td><code id="catLSadj_+3A_verbose">verbose</code></td>
<td>
<p>If true, additional information is printed to screen.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two elements: The adjusted polychoric correlation matrix and its associated asymptotic covariance matrix.
</p>


<h3>References</h3>

<p>Steffen Grønneberg &amp; Njål Foldnes (2022) Factor Analyzing Ordinal Items Requires Substantive Knowledge of Response Marginals, Psychological Methods, DOI: 10.1037/met0000495
</p>


<h3>Examples</h3>

<pre><code class='language-R'>shape= 2
scale = 1/sqrt(shape)
m1 &lt;- list(F=function(x) pchisq(x, df=1), qF=function(x) qchisq(x, df=1), sd=sqrt(2))
G3 &lt;- function(x) pgamma(x+shape*scale, shape=shape, scale=scale)
G3flip &lt;- function(x) 1- G3(-x)
qG3 &lt;- function(x) qgamma(x, shape=shape, scale=scale)-shape*scale
qG3flip &lt;- function(x) -qG3(1-x)
marginslist &lt;- list(m1, list(F=G3, qF=qG3), list(F=G3flip, qF=qG3flip))
Sigma &lt;- diag(3)
Sigma[Sigma==0] &lt;- 0.5
Sigma
# [,1] [,2] [,3]
# [1,]  1.0  0.5  0.5
# [2,]  0.5  1.0  0.5
# [3,]  0.5  0.5  1.0
set.seed(1)
norm.data &lt;- MASS::mvrnorm(10^5, rep(0,3), Sigma)
colnames(norm.data) &lt;- c("x1", "x2", "x3")
#With normal marginals, the correlation matrix is (approximately)
#Sigma.
#Transform the marginals to follow the elements in marginslist:
nonnorm.data &lt;- data.frame(x1=marginslist[[1]]$qF(pnorm(norm.data[, 1])), 
                          x2=marginslist[[2]]$qF(pnorm(norm.data[, 2])),
                          x3=marginslist[[3]]$qF(pnorm(norm.data[, 3])))
#the transformed data has the following  correlation
cor(nonnorm.data)
#           x1        x2        x3
# x1 1.0000000 0.4389354 0.3549677
# x2 0.4389354 1.0000000 0.4256547
# x3 0.3549677 0.4256547 1.0000000
#The original normal dataset ia fitted perfectly to a factor model with
#the following parameters:
head(lavaan::standardizedsolution(lavaan::cfa("F=~ x1+x2+x3", norm.data)),3)
#Extract from output:
#   lhs op rhs est.std    se       z pvalue ci.lower ci.upper
# 1   F =~  x1   0.710 0.002 286.201      0    0.705    0.715
# 2   F =~  x2   0.707 0.002 284.859      0    0.702    0.712
# 3   F =~  x3   0.710 0.002 286.078      0    0.705    0.715

#With non-normal marginals, the factor loadings (and remaining parameters)
#change:
head(lavaan::standardizedsolution(lavaan::cfa("F=~ x1+x2+x3", nonnorm.data)),3)
#Extract from output:
#   lhs op rhs est.std    se       z pvalue ci.lower ci.upper
# 1   F =~  x1   0.605 0.003 191.004      0    0.599    0.611
# 2   F =~  x2   0.725 0.003 219.829      0    0.719    0.732
# 3   F =~  x3   0.587 0.003 185.940      0    0.581    0.593
#Discretize the non-normal dataset:
disc.data &lt;- data.frame(x1=cut(nonnorm.data[, 1], breaks= c(-Inf, 0.1, 1, Inf), labels=FALSE), 
                       x2= cut(nonnorm.data[, 2], breaks= c(-Inf, -.7, 0,1, Inf), labels=FALSE),
                       x3=cut(nonnorm.data[, 3], breaks= c(-Inf, -1, 0,1, Inf), labels=FALSE))
#The polychoric correlation is not close to the correlation matrix
#of the non-normal data, but is close to the correlation matrix
#of the -normal- dataset:
lavaan::lavCor(disc.data, ordered=colnames(disc.data))
#    x1    x2    x3   
# x1 1.000            
# x2 0.503 1.000      
# x3 0.506 0.503 1.000
#Compute the adjustments:
## Not run: adjusted &lt;- catLSadj(disc.data, marginslist, verbose=T )

#The estimated adjusted polychoric correlation matrix is close to the
#correlation matrix of the non-normal data:
adjusted[[1]]
#       x1    x2    x3   
# x1 1.000            
# x2 0.440 1.000      
# x3 0.357 0.427 1.000
# run cat LS without adjustment
fcat &lt;- lavaan::cfa("F=~ x1+x2+x3", disc.data, ordered=colnames(disc.data))
head(lavaan::standardizedsolution(fcat), 3)
#Extract from output:
#   lhs op rhs est.std    se       z pvalue ci.lower ci.upper
# 1   F =~  x1   0.712 0.003 221.553      0    0.705    0.718
# 2   F =~  x2   0.707 0.003 225.835      0    0.701    0.713
# 3   F =~  x3   0.711 0.003 226.119      0    0.705    0.717
#These parameter estimates are close to the parameters of the continuous model for
#normal data, and not to the model parameters obtained from the discretized non-normal dataset
#To get consistent estimates of these parameters
#we need to use the adjusted polychoric correlation.
#To get lavaan to compute the adjusted factor estimates, we need:
sample.th   &lt;- lavaan::lavInspect(fcat, "sampstat")$th
attr(sample.th, "th.idx") &lt;- lavaan::lavInspect(fcat, "th.idx")
#the asymptotic covariance matrix of the adjusted polychorics: 
gamma.adj &lt;- adjusted[[2]]
WLS.V.new &lt;- diag(1/diag(gamma.adj))
fcat.adj  &lt;- lavaan::cfa("F=~ x1+x2+x3", sample.cov=adjusted[[1]],
                sample.nobs=nrow(disc.data),  sample.th=sample.th,
                NACOV = gamma.adj, WLS.V=WLS.V.new)
head(lavaan::standardizedsolution(fcat.adj), 3)
#Extract from output:
#   lhs op rhs est.std    se       z pvalue ci.lower ci.upper
# 1   F =~  x1   0.607 0.003 224.011      0    0.602    0.612
# 2   F =~  x2   0.725 0.003 224.485      0    0.719    0.731
# 3   F =~  x3   0.589 0.002 237.887      0    0.584    0.593
#Closely matches the model parameters obtained with the non-normal dataset
## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
