<!DOCTYPE html><html><head><title>Help for package likelihoodR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {likelihoodR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#L_1way_ANOVA'><p>Likelihood Supports for One-way Independent Samples ANOVA</p></a></li>
<li><a href='#L_1way_cat'><p>Likelihood Support for One-way Categorical Data</p></a></li>
<li><a href='#L_1way_RM_ANOVA'><p>Likelihood Supports for One-way Repeated Measures ANOVA</p></a></li>
<li><a href='#L_2S_ttest'><p>Likelihood Supports for Independent Samples t Test</p></a></li>
<li><a href='#L_2way_cat'><p>Likelihood Support for Two-way Categorical Data</p></a></li>
<li><a href='#L_2way_Factorial_ANOVA'><p>Likelihood Supports for Two-way Independent Samples Factorial ANOVA</p></a></li>
<li><a href='#L_corr'><p>Likelihood Support for Correlation</p></a></li>
<li><a href='#L_efficacy'><p>Likelihood Support for Efficacy</p></a></li>
<li><a href='#L_logistic_regress'><p>Likelihood Support for Logistic Regression</p></a></li>
<li><a href='#L_OR'><p>Likelihood Support for Odds Ratio (OR)</p></a></li>
<li><a href='#L_regress'><p>Likelihood Support for Regression</p></a></li>
<li><a href='#L_RR'><p>Likelihood Support for Relative Risk (RR)</p></a></li>
<li><a href='#L_t_test_sample_size'><p>Sample size calculation using the evidential approach for t tests</p></a></li>
<li><a href='#L_ttest'><p>Likelihood Supports for the One Sample and Related Samples t Test</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Likelihood Analyses for Common Statistical Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.4</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of functions that calculate the log likelihood 
    (support) for a range of statistical tests. Where possible the likelihood 
    function and likelihood interval for the observed data are displayed. The 
    evidential approach used here is based on the book "Likelihood" by A.W.F. 
    Edwards (1992, ISBN-13 : 978-0801844430), "Statistical Evidence" by R. 
    Royall (1997, ISBN-13 : 978-0412044113), S.N. Goodman &amp; R. Royall 
    (2011) &lt;<a href="https://doi.org/10.2105%2FAJPH.78.12.1568">doi:10.2105/AJPH.78.12.1568</a>&gt;, "Understanding 
    Psychology as a Science" by Z. Dienes (2008, ISBN-13 : 978-0230542310), 
    S. Glover &amp; P. Dixon &lt;<a href="https://doi.org/10.3758%2FBF03196706">doi:10.3758/BF03196706</a>&gt; 
    and others. This package accompanies "Evidence-Based Statistics" by 
    P. Cahusac (2020, ISBN-13 : 978-1119549802) 
    &lt;<a href="https://doi.org/10.1002%2F9781119549833">doi:10.1002/9781119549833</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, lme4</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-14 05:15:46 UTC; pcahusac</td>
</tr>
<tr>
<td>Author:</td>
<td>Peter Cahusac <a href="https://orcid.org/0000-0003-4976-2834"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Peter Cahusac &lt;peteqsac@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-14 05:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='L_1way_ANOVA'>Likelihood Supports for One-way Independent Samples ANOVA</h2><span id='topic+L_1way_ANOVA'></span>

<h3>Description</h3>

<p>This function calculates supports for independent samples ANOVA. One support is
for the model of group means against the null (no grouping), for the first contrast
versus the group means model, and the other for 2 contrasts.
Both contrasts should be either NULL or specified.
If the contrasts use the default of NULL, then it calculates a linear versus a
quadratic contrast. The corrected support is given for groups versus null, using
Akaike's correction (Hurvich &amp; Tsai (1989)). No correction is necessary for the
two contrasts' support since they both involve 1 parameter.
Conventional frequentist F and p value statistics are given for the overall
analysis and for contrast 1. Unequal group sizes are
accommodated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_1way_ANOVA(data, group, contrast1=NULL, contrast2=NULL, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_1way_ANOVA_+3A_data">data</code></td>
<td>
<p>a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="L_1way_ANOVA_+3A_group">group</code></td>
<td>
<p>an integer vector the same length as data, coding for k groups.</p>
</td></tr>
<tr><td><code id="L_1way_ANOVA_+3A_contrast1">contrast1</code></td>
<td>
<p>first contrast, default = NULL.</p>
</td></tr>
<tr><td><code id="L_1way_ANOVA_+3A_contrast2">contrast2</code></td>
<td>
<p>second contrast, default = NULL.</p>
</td></tr>
<tr><td><code id="L_1way_ANOVA_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.12c - corrected support for groups hypothesis versus null.
</p>
<p>$S.12 - uncorrected support for groups hypothesis versus null.
</p>
<p>S.1mc - support for contrast 1 versus the group means model.
</p>
<p>$S.1m = uncorrected support for contrast 1 vs group means.
</p>
<p>$S.cont.12 - support for contrast 1 versus contrast 2.
</p>
<p>$contrast1 - first contrast.
</p>
<p>$contrast2 - second contrast.
</p>
<p>$gp.means - group means.
</p>
<p>$df - degrees of freedom for groups and error.
</p>
<p>$F.val - F value for overall ANOVA analysis.
</p>
<p>$P.val - p value for overall analysis.
</p>
<p>$eta.sq - eta-squared.
</p>
<p>$Fval.c1 - F value for contrast 1.
</p>
<p>$df.1 - degrees of freedom for contrast.
</p>
<p>$P.val1 - p value for contrast 1.
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Hurvich CM, Tsai C-L. Regression and time series model selection in small
samples. Biometrika. 1989; 76(2):297.
</p>
<p>Dixon P. The effective number of parameters in post hoc models. Behavior
Research Methods. 2013; 45(3):604.
</p>
<p>Dixon P. The p-value fallacy and how to avoid it. Canadian Journal of
Experimental Psychology/Revue canadienne de psychologie expérimentale. 2003;
57(3):189.
</p>
<p>Glover S, Dixon P. Likelihood ratios: a simple and flexible statistic for empirical
psychologists. Psychonomic Bulletin and Review. 2004; 11(5):791.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># fitness example, p 81
dat &lt;- c(7,	5,	9,	8,	3,	12,	10,	8,	7,	9,
5,	7,	7,	6,	4,	8,	12,	9,	7,	8,
3,	2,	7,	6,	8,	6,	5,	3,	4,	3,
4,	3,	3,	1,	2,	5,	7,	6,	8,	7)
gp &lt;- as.factor(rep(1:4,each=10))
gp = gl(4,10,40, labels=c("6 hr",	"3 hr",	"Sports club",	"Video games"))
contrast1 &lt;- c(-3, -1, 1, 3)  # linear
contrast2 &lt;- c(1, -1, -1, 1)  # quadratic
contrast3 &lt;- c(1, 1, -1, -1)
L_1way_ANOVA(dat,gp,contrast3, contrast1)

</code></pre>

<hr>
<h2 id='L_1way_cat'>Likelihood Support for One-way Categorical Data</h2><span id='topic+L_1way_cat'></span>

<h3>Description</h3>

<p>This function calculates the support for one-way categorical data (multinomial), also
gives chi-squared and likelihood ratio test (G) statistics. If there are only 2
categories then binomial information
is given too with likelihood interval, including the likelihood-based % confidence
interval. Support for the variance being more different than expected (Edwards p 187,
Cahusac p 158) is also calculated.
It uses the optimize function to locate desired limits for both intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_1way_cat(obs, exp.p=NULL, L.int=2, alpha=0.05, toler=0.0001,
logplot=FALSE, supplot=-10, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_1way_cat_+3A_obs">obs</code></td>
<td>
<p>a vector containing the number of counts in each category.</p>
</td></tr>
<tr><td><code id="L_1way_cat_+3A_exp.p">exp.p</code></td>
<td>
<p>a vector containing expected probabilities. If NULL then this is 1/#cats.</p>
</td></tr>
<tr><td><code id="L_1way_cat_+3A_l.int">L.int</code></td>
<td>
<p>likelihood interval given as support values, e.g. 2 or 3, default = 2.</p>
</td></tr>
<tr><td><code id="L_1way_cat_+3A_alpha">alpha</code></td>
<td>
<p>the significance level used, 1 - alpha interval calculated, default = 0.05.</p>
</td></tr>
<tr><td><code id="L_1way_cat_+3A_toler">toler</code></td>
<td>
<p>the desired accuracy using optimise, default = 0.0001.</p>
</td></tr>
<tr><td><code id="L_1way_cat_+3A_logplot">logplot</code></td>
<td>
<p>plot vertical axis as log likelihood, default = FALSE</p>
</td></tr>
<tr><td><code id="L_1way_cat_+3A_supplot">supplot</code></td>
<td>
<p>set minimum likelihood display value in plot, default = -10</p>
</td></tr>
<tr><td><code id="L_1way_cat_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.val - support for one-way observed versus expected.
</p>
<p>$uncorrected.sup - uncorrected support.
</p>
<p>$df - degrees of freedom for table.
</p>
<p>$observed - observed counts.
</p>
<p>$exp.p - expected probabilities.
</p>
<p>$too.good - support for the variance of counts being more different than expected.
</p>
<p>$chi.sq - chi-squared value.
</p>
<p>$p.value - p value for chi-squared.
</p>
<p>$LR.test = the likelihood ratio test statistic.
</p>
<p>$lrt.p = the p value for the likelihood ratio test statistic
</p>
<p>Additional outputs for binomial:
</p>
<p>$prob.val - MLE probability from data.
</p>
<p>$succ.fail - number of successes and failures.
</p>
<p>$like.int - likelihood interval.
</p>
<p>$like.int.spec - specified likelihood interval in units of support.
</p>
<p>$conf.int - likelihood-based confidence interval.
</p>
<p>$alpha.spec - specified alpha for confidence interval.
</p>
<p>$err.acc - error accuracy for optimize function.
</p>


<h3>References</h3>

<p>Aitkin, M. et al (1989) Statistical Modelling in GLIM, Clarendon Press, ISBN : 978-0198522041
</p>
<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. London: Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example for binomial, p 123
obs &lt;- c(6,4)
L_1way_cat(obs, L.int=2, toler=0.0001, logplot=FALSE, supplot=-10, verb = TRUE)

# example for multinomial, p 134
obs &lt;- c(60,40,100)
exp &lt;- c(0.25,0.25,0.5)
L_1way_cat(obs, exp.p=exp, L.int=2, toler=0.0001, logplot=FALSE, supplot=-10,
verb = TRUE)

</code></pre>

<hr>
<h2 id='L_1way_RM_ANOVA'>Likelihood Supports for One-way Repeated Measures ANOVA</h2><span id='topic+L_1way_RM_ANOVA'></span>

<h3>Description</h3>

<p>This function calculates support for the treatment means versus the null model,
Type of correction for the parameters in the null versus the means model can be selected.
support for the first contrast versus the group means model and the
support for the first versus the second contrast.
Also gives the F, p and partial eta-squared values for the overall analysis,
and F and p for the first contrast. Assumes sphericity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_1way_RM_ANOVA(dat, group, ID, correct=1, contrast1=NULL, contrast2=NULL, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_1way_RM_ANOVA_+3A_dat">dat</code></td>
<td>
<p>a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="L_1way_RM_ANOVA_+3A_group">group</code></td>
<td>
<p>a vector the same length as data, coding for k groups.</p>
</td></tr>
<tr><td><code id="L_1way_RM_ANOVA_+3A_id">ID</code></td>
<td>
<p>is an identifier for each case.</p>
</td></tr>
<tr><td><code id="L_1way_RM_ANOVA_+3A_correct">correct</code></td>
<td>
<p>specifies the correction: 0 = none, 1 = Occam's bonus (default), 2 = AIC</p>
</td></tr>
<tr><td><code id="L_1way_RM_ANOVA_+3A_contrast1">contrast1</code></td>
<td>
<p>first contrast, default = NULL.</p>
</td></tr>
<tr><td><code id="L_1way_RM_ANOVA_+3A_contrast2">contrast2</code></td>
<td>
<p>second contrast, default = NULL.</p>
</td></tr>
<tr><td><code id="L_1way_RM_ANOVA_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.12 - support for groups means hypothesis versus null, uncorrected
</p>
<p>$S.12c - corrected
</p>
<p>$capplied - type of correction
</p>
<p>$S.1m = support for first contrast versus means model.
</p>
<p>$S.cont.12 - support for first versus second contrast.
</p>
<p>$contrast1 - first contrast.
</p>
<p>$contrast2 - second contrast.
</p>
<p>$gp.means - group means.
</p>
<p>$df - degrees of freedom for ANOVA.
</p>
<p>$F.val - F value for overall analysis.
</p>
<p>$P.val - p value for the overall analysis.
</p>
<p>Fval.c1 - F value for the first contrast.
</p>
<p>$df.1 - degrees of freedom for the contrast.
</p>
<p>$P.val1 - p value for the contrast.
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Dixon P. The effective number of parameters in post hoc models. Behavior
Research Methods. 2013; 45(3):604.
</p>
<p>Dixon P. The p-value fallacy and how to avoid it. Canadian Journal of
Experimental Psychology/Revue canadienne de psychologie expérimentale. 2003;
57(3):189.
</p>
<p>Glover S, Dixon P. Likelihood ratios: a simple and flexible statistic for empirical
psychologists. Psychonomic Bulletin and Review. 2004; 11(5):791.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># sleep data example, p 97
dat &lt;- c(0.7,	-1.6,	-0.2,	-1.2,	-0.1,	3.4,	3.7,	0.8,	0,	2,
1.9,	0.8,	1.1,	0.1,	-0.1,	4.4,	5.5,	1.6,	4.6,	3.4,
1.5,	1.4,	0.0,	-0.7,	0.5,	5.1,	5.7,	1.5,	4.7,	3.5)
treat &lt;- gl(3,10,30)
patients &lt;- gl(10,1,30)
contrast1 &lt;- c(-1, 0, 1)  # linear
contrast2 &lt;- c(-2, 1, 1)  # 1st vs treatments 2 &amp; 3

m=L_1way_RM_ANOVA(dat, treat, patients, correct=1, contrast1, contrast2)
m

</code></pre>

<hr>
<h2 id='L_2S_ttest'>Likelihood Supports for Independent Samples t Test</h2><span id='topic+L_2S_ttest'></span>

<h3>Description</h3>

<p>This function calculates several different supports for independent samples. Effect
size (Cohen's d) and a second alternative hypothesis value can be specified.
The maximum support is the support for the observed mean versus the null value.
The support for the specified d versus the null is also calculated. If a second
hypothesis value is specified (in units of the original measurements) then two
further supports are calculated: d versus 2nd alternative hypothesis, and 2nd
alternative hypothesis versus the null. The likelihood curve graphic with MLE and
specified hypothesis values is produced. Finally, the requested likelihood interval
is provided. The t, p and observed d values for the test against the null are given.
If variances are specified as unequal then uses Welch's test where
homogeneity of variance is not required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_2S_ttest(data, group, veq=0, null=0, d=0.5, alt.2=NULL,
L.int=2, toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_2S_ttest_+3A_data">data</code></td>
<td>
<p>a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_group">group</code></td>
<td>
<p>an integer vector the same length as data, coding for 2 groups.</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_veq">veq</code></td>
<td>
<p>whether variances are equal: 1 = Yes, 0 = No, default = 0.</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_null">null</code></td>
<td>
<p>value for the null hypothesis, default = 0.</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_d">d</code></td>
<td>
<p>Cohen's effect size, default = 0.5.</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_alt.2">alt.2</code></td>
<td>
<p>value for an alternative hypothesis, in units used for data, default = NULL.</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_l.int">L.int</code></td>
<td>
<p>likelihood interval given as support values, e.g. 2 or 3, default = 2.</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_toler">toler</code></td>
<td>
<p>the desired accuracy using optimise, default = 0.0001.</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_logplot">logplot</code></td>
<td>
<p>plot vertical axis as log likelihood, default = FALSE</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_supplot">supplot</code></td>
<td>
<p>set minimum likelihood display value in plot, default = -10</p>
</td></tr>
<tr><td><code id="L_2S_ttest_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$obs.diff - the observed difference in means.
</p>
<p>$df - degrees of freedom.
</p>
<p>$var.eq - if not equal (0) then Welch's test used.
</p>
<p>$alt.H1 - mean value according to specified d.
</p>
<p>$alt.H2 - specified second hypothesis value.
</p>
<p>$S_max - maximum support for observed mean difference against the null.
</p>
<p>$S_10 - support for d versus null.
</p>
<p>$S_12 - support for d versus specified second hypothesis.
</p>
<p>$S_20 - support for second hypothesis versus the null.
</p>
<p>$like.int - likelihood interval.
</p>
<p>$L.int.spec - specified likelihood interval in units of support.
</p>
<p>$null.value - null value
</p>
<p>$t.val - t value for test against null.
</p>
<p>$p.val - p value for test against null.
</p>
<p>$d.obs - observed effect size (from null).
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Baguley, T. (2012) Serious Stats, Palgrave Macmillan, ISBN: 978-0230577183
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>
<p>Royall, R. M. (1997) Statistical Evidence: A Likelihood Paradigm, Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Royall, R. M. (2000). On the probability of observing misleading statistical evidence.
Journal of the American Statistical Association, 95, 760.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using a variation on Gosset's original additional hours of sleep data, p 59
mysample &lt;- c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, 0.8, 0.0, 2.0)
treat &lt;- rep(1:0,each=5)
L_2S_ttest(mysample, treat, veq=0, null=0, d=0.5, alt.2=2, L.int=2,
toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)

</code></pre>

<hr>
<h2 id='L_2way_cat'>Likelihood Support for Two-way Categorical Data</h2><span id='topic+L_2way_cat'></span>

<h3>Description</h3>

<p>This function calculates supports for two-way categorical data. This consists of the
support for the interaction and the two main effects. Support for the interaction
being closer or worse (different variance) than expected (Edwards p 187, Cahusac p 158)
is calculated. The support
for trend across the columns is given (assuming the levels for columns are ordered),
and conventional p value for trend.
Finally, Chi-squared and likelihood ratio test (G) statistics are given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_2way_cat(table, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_2way_cat_+3A_table">table</code></td>
<td>
<p>a 2 x 2 matrix or contingency table containing counts.</p>
</td></tr>
<tr><td><code id="L_2way_cat_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.int - support for the interaction.
</p>
<p>$df - the degrees of freedom for the interaction.
</p>
<p>$S.int.unc - the uncorrected support for the interaction.
</p>
<p>$S.Main.rows - support for the rows main effect.
</p>
<p>$S.Main.cols - support for the columns main effect.
</p>
<p>$S.Mr.uncorr - uncorrected support for rows main effect.
</p>
<p>$S.Mc.uncorr - uncorrected support for the columns main effect.
</p>
<p>$df.rows - degrees of freedom for rows.
</p>
<p>$df.cols - degrees of freedom for columns.
</p>
<p>$S.total - support for the whole table.
</p>
<p>$S.trend - support for the trend across columns (if ordered).
</p>
<p>$too.good - support for the variance being different from expected.
</p>
<p>$observed - the observed table frequencies.
</p>
<p>$expected - the expected values for null hypothesis of no interaction.
</p>
<p>$residuals - the Pearson residuals.
</p>
<p>$LR.test = the likelihood ratio test statistic.
</p>
<p>$lrt.p - the p value for likelihood ratio test.
</p>
<p>$chi.sq - chi-squared value.
</p>
<p>$p.value - p value for chi-squared.
</p>
<p>$trend.p - p value for trend (from chi-squared dist.).
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. London: Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>


<h3>Examples</h3>

<pre><code class='language-R'># S. mansoni eggs in stools example, p 151
eggs &lt;- as.table(rbind(c(14, 16, 14, 7, 6), c(87, 33, 66, 34, 11)))
dimnames(eggs) = list("Infested" = c("Positive","Negative"),
                  "Age Group" = c("0-","10-", "20-",
                  "30-", "40-"))
L_2way_cat(eggs)

# or as a matrix
eggs &lt;- as.matrix(c(14, 87, 16, 33, 14, 66, 7, 34, 6, 11))
dim(eggs) &lt;- c(2,5)
L_2way_cat(eggs)


</code></pre>

<hr>
<h2 id='L_2way_Factorial_ANOVA'>Likelihood Supports for Two-way Independent Samples Factorial ANOVA</h2><span id='topic+L_2way_Factorial_ANOVA'></span>

<h3>Description</h3>

<p>This function calculates supports for independent samples ANOVA. One support is
for the full model versus null (no factors), and the second is for full model
versus main effects. Two contrasts can be specified which can be used
to explore interactions. Each should be given
as a vector arranged as means for factor1 changing first (see example). If only the first
contrast is specified then this is compared to the main effects model. If a second
contrast is specified then the first contrast is compared to it.
Corrected support is given where appropriate, using
Akaike's correction (Hurvich &amp; Tsai (1989)). No correction is necessary for the
two contrasts support since they both involve 1 parameter. Unequal group sizes are
accommodated, using type III sums of squares. F, p and partial eta-squared values
are given for the two factors and their interaction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_2way_Factorial_ANOVA(data, factor1, factor2, contrast1=NULL, contrast2=NULL, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_2way_Factorial_ANOVA_+3A_data">data</code></td>
<td>
<p>a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="L_2way_Factorial_ANOVA_+3A_factor1">factor1</code></td>
<td>
<p>a vector the same length as data, coding the first factor.</p>
</td></tr>
<tr><td><code id="L_2way_Factorial_ANOVA_+3A_factor2">factor2</code></td>
<td>
<p>a vector the same length as data, coding the second factor.</p>
</td></tr>
<tr><td><code id="L_2way_Factorial_ANOVA_+3A_contrast1">contrast1</code></td>
<td>
<p>first contrast, with values for factor1 changing first, default = NULL.</p>
</td></tr>
<tr><td><code id="L_2way_Factorial_ANOVA_+3A_contrast2">contrast2</code></td>
<td>
<p>second contrast, default = NULL.</p>
</td></tr>
<tr><td><code id="L_2way_Factorial_ANOVA_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.12c - corrected support for full model versus null.
</p>
<p>$S.12 - uncorrected support for full model versus null.
</p>
<p>$S_FMc - corrected support for full model versus main effects model.
</p>
<p>$S.FM - uncorrected support for full versus main effects.
</p>
<p>$S.c1.Mc - corrected support for first contrast versus main effects model.
</p>
<p>$S.c1.M - uncorrected support for first contrast versus main effects.
</p>
<p>$S.c1.c2 - support for first versus second contrast.
</p>
<p>$Means - 2 way table of means.
</p>
<p>$df - degrees of freedom for the ANOVA.
</p>
<p>$F.f1 - F value for first factor main effect.
</p>
<p>$Pval.f1 - P value for first factor main effect.
</p>
<p>$eta.sq.1 - partial eta-squared for first factor main effect.
</p>
<p>$F.f2 - F value for second factor main effect.
</p>
<p>$Pval.f2 - P value for second factor main effect.
</p>
<p>$eta.sq.2 - partial eta-squared for second factor main effect.
</p>
<p>$F.int - F value for interaction.
</p>
<p>$Pval.int - P value for interaction.
</p>
<p>$eta.sq.12 - partial eta-squared for the interaction.
</p>
<p>$F.val.c1 - F value for first contrast.
</p>
<p>$P.val.c1 - P value for first contrast.
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Hurvich CM, Tsai C-L. Regression and time series model selection in small
samples. Biometrika. 1989; 76(2):297.
</p>
<p>Dixon P. The effective number of parameters in post hoc models. Behavior
Research Methods. 2013; 45(3):604.
</p>
<p>Dixon P. The p-value fallacy and how to avoid it. Canadian Journal of
Experimental Psychology/Revue canadienne de psychologie expérimentale. 2003;
57(3):189.
</p>
<p>Glover S, Dixon P. Likelihood ratios: a simple and flexible statistic for empirical
psychologists. Psychonomic Bulletin and Review. 2004; 11(5):791.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># blood clotting times example, p 91
time &lt;- c(6.4,	4.6,	6.4,	5.6,	5.9, 6.1,	6.3,	4.5,
4.8,	6.6, 7,	9.3,	7.9,	9.4,	8.2, 4.4,	4.2,	5,
6.9,	4.5, 4,	4.3,	6.9,	5.5,	5.8,
4.4,	4.2,	5.1,	6.9,	4.5)
Treatment = gl(3,5,30, labels=c("T1","T2","T3"))
Health = gl(2,15,30, labels=c("Hemophiliac","Normal"))

L_2way_Factorial_ANOVA(time, Treatment, Health)

contrast1 &lt;- c(-1, -1, 5,
               -1, -1, -1) # interaction Hemo T3 higher than others
L_2way_Factorial_ANOVA(time, Treatment, Health, contrast1)

contrast2 &lt;- c(-1, -1, -1,
               1, 1, 1) # main effect of health status (Hemo higher than Normal)

m=L_2way_Factorial_ANOVA(time, Treatment, Health, contrast1, contrast2)
m     #show outputs

</code></pre>

<hr>
<h2 id='L_corr'>Likelihood Support for Correlation</h2><span id='topic+L_corr'></span>

<h3>Description</h3>

<p>This function calculates the support for a correlation from 2 vectors of data.
An expected correlation can be specified and the support calculated for this relative to the observed
and the null (which is assumed to be 0, but can also be specified) values. A likelihood function
is plotted for the obtained correlation with a likelihood interval added and expected correlation,
if specified. Conventional p value is also given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_corr(xv, yv, null=0, exp.r=NULL, L.int=2, alpha=.05,
toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_corr_+3A_xv">xv</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="L_corr_+3A_yv">yv</code></td>
<td>
<p>a numeric vector the same length as xv.</p>
</td></tr>
<tr><td><code id="L_corr_+3A_null">null</code></td>
<td>
<p>the null value, default = 0.</p>
</td></tr>
<tr><td><code id="L_corr_+3A_exp.r">exp.r</code></td>
<td>
<p>a specified correlation (could be expected value for the study), default = NULL.</p>
</td></tr>
<tr><td><code id="L_corr_+3A_l.int">L.int</code></td>
<td>
<p>likelihood interval given as support values, e.g. 2 or 3, default = 2.</p>
</td></tr>
<tr><td><code id="L_corr_+3A_alpha">alpha</code></td>
<td>
<p>the significance level used, 1 - alpha interval calculated, default = 0.05.</p>
</td></tr>
<tr><td><code id="L_corr_+3A_toler">toler</code></td>
<td>
<p>the desired accuracy using optimise, default = 0.0001.</p>
</td></tr>
<tr><td><code id="L_corr_+3A_logplot">logplot</code></td>
<td>
<p>plot vertical axis as log likelihood, default = FALSE</p>
</td></tr>
<tr><td><code id="L_corr_+3A_supplot">supplot</code></td>
<td>
<p>set minimum likelihood display value in plot, default = -10</p>
</td></tr>
<tr><td><code id="L_corr_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$obs.r - observed correlation.
</p>
<p>$S.0 - support for observed correlation versus the null.
</p>
<p>$S.1 - support for the specified correlation versus observed correlation.
</p>
<p>$S.10 - support for the specified correlation versus the null value.
</p>
<p>$exp.r - the specified correlation.
</p>
<p>$N - the sample size.
</p>
<p>$p.value - the p value for significance test versus 0.
</p>
<p>$like.int - the likelihood interval.
</p>
<p>$like.int.spec - the specified likelihood interval in terms of support.
</p>
<p>$conf.int - the % confidence interval for the correlation.
</p>
<p>$alpha.spec - the specified alpha for the % confidence interval.
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. London: Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for heptathlon example, p 104
m200 &lt;- c(22.6,	23.7,	23.1,	23.6,	23.6,	23.6,	25.5,
23.9,	24.5,	23.9,	24.9,	24.8,	24.7,
25.0,	24.6,	24.9,	25.0,	25.6,	24.8,
25.5,	25.7,	24.9,	26.6,	25.2,	26.2)
m800 &lt;- c(128.5,	126.1,	124.2,	132.5,
134.7,	132.5,	138.5,	127.9,	133.7,	132.2,
136.1,	142.8,	125.8, 131.5,	137.1,	134.9,
146.7,	133.9,	146.4,	144.0,	133.4,
138.0,	139.2,	137.3,	163.4)
m=L_corr(m200, m800, null=0, exp.r=.4, L.int=3, alpha=.05,
toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
m
#Note: the support for observed vs 0 is different from book (5.776 vs 5.700)
#due to differences in calculation of r by Excel and R

</code></pre>

<hr>
<h2 id='L_efficacy'>Likelihood Support for Efficacy</h2><span id='topic+L_efficacy'></span>

<h3>Description</h3>

<p>This function calculates the support for the efficacy, the likelihood interval
and the likelihood-based confidence interval.
It uses the optimize function to locate desired limits and their error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_efficacy(a, n, null=0, exp.eff=NULL, L.int=2,
alpha=0.05, toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_efficacy_+3A_a">a</code></td>
<td>
<p>the number of affected in control group.</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_n">n</code></td>
<td>
<p>total number of participants.</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_null">null</code></td>
<td>
<p>the null value for efficacy, if no effect then it would be 0, default = 0.</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_exp.eff">exp.eff</code></td>
<td>
<p>the expected or hypothesized efficacy, default = NULL.</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_l.int">L.int</code></td>
<td>
<p>likelihood interval given as support values, e.g. 2 or 3, default = 2.</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_alpha">alpha</code></td>
<td>
<p>the significance level used, 1 - alpha interval calculated, default = 0.05.</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_toler">toler</code></td>
<td>
<p>the desired accuracy using optimise, default = 0.0001.</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_logplot">logplot</code></td>
<td>
<p>plot vertical axis as log likelihood, default = FALSE</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_supplot">supplot</code></td>
<td>
<p>set minimum likelihood display value in plot, default = -10</p>
</td></tr>
<tr><td><code id="L_efficacy_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.val - support for the observed efficacy versus the null value.
</p>
<p>$obs.eff - the observed efficacy.
</p>
<p>$null - the null efficacy.
</p>
<p>$exp.eff - expected efficacy as specified.
</p>
<p>$S.exp.vsObs - support for expected efficacy versus observed.
</p>
<p>$S.exp.versus.null - support for the expected efficacy versus the null.
</p>
<p>$L.int - the likelihood interval for the observed efficacy.
</p>
<p>$S_int - the specified likelihood interval.
</p>
<p>$observed - observed numbers affected in control and intervention groups.
</p>
<p>$expected - expected numbers according to the null.
</p>
<p>$chi.sq - chi-squared statistic.
</p>
<p>$p.value - p value associated with chi-squared statistic.
</p>
<p>$df - degrees of freedom for chi-squared.
</p>
<p>$residuals - the Pearson residuals.
</p>
<p>$conf.int - likelihood-based confidence interval according to specified alpha.
</p>
<p>$alpha - specified alpha for confidence interval.
</p>
<p>$all.err.acc - error accuracy for each application of the optimize function.
</p>


<h3>References</h3>

<p>Aitkin, M. et al (1989) Statistical Modelling in GLIM, Clarendon Press, ISBN : 978-0198522041
</p>
<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. London: Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>


<h3>Examples</h3>

<pre><code class='language-R'># pfizer covid-19 efficacy 2020
m = L_efficacy(a = 86, n = 94, null=0.8, exp.eff=0.95, L.int=2,
alpha=0.05, toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
m

</code></pre>

<hr>
<h2 id='L_logistic_regress'>Likelihood Support for Logistic Regression</h2><span id='topic+L_logistic_regress'></span>

<h3>Description</h3>

<p>This function calculates the supports for multiple logistic regression.
A binary dependent variable is entered into the function, followed by up to 6 predictor
variables (which need to be dummy coded if nominal and more than 2 levels). Outputs
give the overall support for the full model versus the null (constant) model, supports
for each of the predictor variables. Outputs include the usual chi-squared and p values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_logistic_regress(yv, p1, p2=NULL, p3=NULL, p4=NULL, p5=NULL, p6=NULL, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_logistic_regress_+3A_yv">yv</code></td>
<td>
<p>a binomial numeric vector for dependent variable.</p>
</td></tr>
<tr><td><code id="L_logistic_regress_+3A_p1">p1</code></td>
<td>
<p>vector for predictor variable, same length as yv.</p>
</td></tr>
<tr><td><code id="L_logistic_regress_+3A_p2">p2</code></td>
<td>
<p>vector for predictor variable, same length as yv, default = NULL.</p>
</td></tr>
<tr><td><code id="L_logistic_regress_+3A_p3">p3</code></td>
<td>
<p>vector for predictor variable, same length as yv, default = NULL.</p>
</td></tr>
<tr><td><code id="L_logistic_regress_+3A_p4">p4</code></td>
<td>
<p>vector for predictor variable, same length as yv, default = NULL.</p>
</td></tr>
<tr><td><code id="L_logistic_regress_+3A_p5">p5</code></td>
<td>
<p>vector for predictor variable, same length as yv, default = NULL.</p>
</td></tr>
<tr><td><code id="L_logistic_regress_+3A_p6">p6</code></td>
<td>
<p>vector for predictor variable, same length as yv, default = NULL.</p>
</td></tr>
<tr><td><code id="L_logistic_regress_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.FNc - support for the full versus null (constant value) model.
</p>
<p>$S.each - support for each of the predictors, from first to last.
</p>
<p>$chi.sq.FN - chi-squared for full versus null model.
</p>
<p>$df - degrees of freedom for chi-squared.
</p>
<p>$chi.sq.FN.p - p value for chi-squared.
</p>
<p>$p.vals - p values for each of the predictors
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>1 Akaike H. A new look at the statistical model identification. IEEE Transactions
on Automatic Control. 1974;19(6):716.
</p>
<p>Glover S, Dixon P. Likelihood ratios: a simple and flexible statistic for empirical
psychologists. Psychonomic Bulletin &amp; Review. 2004;11(5):791.
</p>
<p>Tabachnick BG, Fidell LS. Using Multivariate Statistics. Boston: Pearson Education; 2007.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># prescription errors example, p 114
p_error &lt;- c(rep(1,6),rep(0,9))
score &lt;- c(4,	5,	6,	5,	4,	6,	6,	4,
5,	8,	9,	7,	10,	8,	9)
med1 &lt;- c(1,	1,	0,	0,	1,	1,	0,	0,
0,	0,	0,	0,	0,	0,	1)
med2 &lt;- c(0,	0,	1,	0,	0,	0,	1,	0,
0,	1,	1,	0,	1,	1,	0)
m1 = L_logistic_regress(p_error, score, med1, med2)
m1

</code></pre>

<hr>
<h2 id='L_OR'>Likelihood Support for Odds Ratio (OR)</h2><span id='topic+L_OR'></span>

<h3>Description</h3>

<p>This function calculates the support for an OR from a 2 x 2 categorical data table.
An expected OR can be specified and the support calculated for this relative to the observed
and null (which is assumed to be 1, but can also be specified) values. A likelihood function
is plotted for the obtained OR with a specified likelihood interval, and expected OR,
if specified. The log likelihood plot can optionally be given instead.
Chi-squared and likelihood ratio test (G) statistics are also provided and a likelihood-based % confidence interval.
It uses the optimize function to locate desired limits for both intervals and other
support calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_OR(table, null=1, exp.OR=NULL, L.int=2, alpha=0.05,
cc=FALSE, toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_OR_+3A_table">table</code></td>
<td>
<p>a 2 x 2 matrix or contingency table containing counts.</p>
</td></tr>
<tr><td><code id="L_OR_+3A_null">null</code></td>
<td>
<p>the value against which the obtained OR is tested, default = 1.</p>
</td></tr>
<tr><td><code id="L_OR_+3A_exp.or">exp.OR</code></td>
<td>
<p>an expected or hypothetical OR.</p>
</td></tr>
<tr><td><code id="L_OR_+3A_l.int">L.int</code></td>
<td>
<p>likelihood interval given as support values, e.g. 2 or 3, default = 2.</p>
</td></tr>
<tr><td><code id="L_OR_+3A_alpha">alpha</code></td>
<td>
<p>the significance level used, 1 - alpha interval calculated, default = 0.05.</p>
</td></tr>
<tr><td><code id="L_OR_+3A_cc">cc</code></td>
<td>
<p>logical indicating whether to apply continuity correction, default = FALSE.</p>
</td></tr>
<tr><td><code id="L_OR_+3A_toler">toler</code></td>
<td>
<p>the desired accuracy using optimise, default = 0.0001.</p>
</td></tr>
<tr><td><code id="L_OR_+3A_logplot">logplot</code></td>
<td>
<p>plot vertical axis as log likelihood, default = FALSE</p>
</td></tr>
<tr><td><code id="L_OR_+3A_supplot">supplot</code></td>
<td>
<p>set minimum likelihood display value in plot, default = -10</p>
</td></tr>
<tr><td><code id="L_OR_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.val - support for observed OR from expected.
</p>
<p>$df - degrees of freedom.
</p>
<p>$exp.OR - expected OR.
</p>
<p>$S.exp.ORvsObs - support for expected OR versus observed.
</p>
<p>$S.exp.ORvsNull - support for expected OR versus the null.
</p>
<p>$HAc - Haldane-Anscombe correction applied when a count is 0.
</p>
<p>$L.int - likelihood interval of observed OR for specified level of support.
</p>
<p>$S_int - specified likelihood interval in units of support.
</p>
<p>$observed - observed frequencies.
</p>
<p>$expected - the expected values for null hypothesis of no interaction.
</p>
<p>$chi.sq - chi-squared statistic.
</p>
<p>$corrected - whether chi-squared was corrected, default = FALSE.
</p>
<p>$p.value - p value.
</p>
<p>$LR.test = the likelihood ratio test statistic.
</p>
<p>$lrt.p = the p value for the likelihood ratio test statistic
</p>
<p>$residuals - the Pearson residuals.
</p>
<p>$alpha - specified significance level.
</p>
<p>$conf.int - likelihood-based confidence interval for observed RR.
</p>
<p>$all.err.acc - error accuracy for each application of the optimize function.
</p>


<h3>References</h3>

<p>Aitkin, M. et al (1989) Statistical Modelling in GLIM, Clarendon Press, ISBN : 978-0198522041
</p>
<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. London: Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>
<p>Dienes, Z. (2008) Understanding Psychology as a Science: An Introduction to Scientific and Statistical
Inference, Palgrave, MacMillan, ISBN : 978-0230542303
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for folic acid and neural tube defects example, p 146
tab &lt;- as.table(rbind(c(6,587),c(21,581)))
dimnames(tab) &lt;- list(Treatment=c("Folic acid","None"),Defect=c("Yes","No"))
L_OR(tab, exp.OR = 0.5, L.int = 2, alpha=0.05, cc=FALSE,
toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)

</code></pre>

<hr>
<h2 id='L_regress'>Likelihood Support for Regression</h2><span id='topic+L_regress'></span>

<h3>Description</h3>

<p>This function calculates the supports for different regression fits from 2 vectors of data.
Models include linear, quadratic and cubic (given sufficient data). A plot is
included showing linear (black), quadratic (red) and cubic (blue dashed) lines. P values for
the model fits are also given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_regress(y, x, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_regress_+3A_y">y</code></td>
<td>
<p>a numeric vector the same length as x.</p>
</td></tr>
<tr><td><code id="L_regress_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="L_regress_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.LNc - corrected support for linear versus null model.
</p>
<p>$S.LN - uncorrected support for linear versus null model.
</p>
<p>$S.QLc - corrected support for quadratic versus linear model.
</p>
<p>$S.QL - uncorrected support for quadratic versus linear model.
</p>
<p>S.QCc = support for quadratic versus cubic model.
</p>
<p>$N - sample size.
</p>
<p>$p.vals - p values for 3 fits.
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. London: Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for women's world record times for 1500m event example, p 108
years &lt;- c(0.0,	7.1,	8.9,	8.9,	10.1,	12.8,	17.0,	19.1,
25.0, 28.7, 29.7,	29.9,	35.3, 39.8,	40.2,	41.9,	42.1,	44.0,
44.9, 45.0,	45.1, 45.1,	48.9,	52.9,	53.0,	66.1,	87.9)
time &lt;- c(5.30,	5.12,	5.03,	4.79,	4.75,	4.70,	4.63,	4.63,
4.62, 4.59,	4.50,	4.50,	4.32,   4.29,	4.26,	4.21,	4.18,
4.16,	4.12, 4.11,	4.09,	4.02,	3.93,	3.92,	3.87,	3.84,	3.83)

m=L_regress(time, years)
m

</code></pre>

<hr>
<h2 id='L_RR'>Likelihood Support for Relative Risk (RR)</h2><span id='topic+L_RR'></span>

<h3>Description</h3>

<p>This function calculates the support for an RR from a 2 x 2 categorical data table.
An expected RR can be specified and the support calculated for this relative to the observed
and null (which is assumed to be 1, but can also be specified) values. A likelihood function
is plotted for the obtained RR with a likelihood interval, and expected RR,
if specified. The log likelihood plot can optionally be given instead.
Chi-squared statistics are also provided and a likelihood-based % confidence interval.
It uses the optimize function to locate desired limits for both intervals and other
support calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_RR(table, null=1, exp.RR=NULL, L.int=2, alpha=0.05,
cc=FALSE, toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_RR_+3A_table">table</code></td>
<td>
<p>a 2 x 2 matrix or contingency table containing counts.</p>
</td></tr>
<tr><td><code id="L_RR_+3A_null">null</code></td>
<td>
<p>the value against which the obtained RR is tested, default = 1.</p>
</td></tr>
<tr><td><code id="L_RR_+3A_exp.rr">exp.RR</code></td>
<td>
<p>an expected or hypothetical RR.</p>
</td></tr>
<tr><td><code id="L_RR_+3A_l.int">L.int</code></td>
<td>
<p>likelihood interval given as support values, e.g. 2 or 3, default = 2.</p>
</td></tr>
<tr><td><code id="L_RR_+3A_alpha">alpha</code></td>
<td>
<p>the significance level used, 1 - alpha interval calculated, default = 0.05.</p>
</td></tr>
<tr><td><code id="L_RR_+3A_cc">cc</code></td>
<td>
<p>logical indicating whether to apply continuity correction, default = FALSE.</p>
</td></tr>
<tr><td><code id="L_RR_+3A_toler">toler</code></td>
<td>
<p>the desired accuracy using optimise, default = 0.0001.</p>
</td></tr>
<tr><td><code id="L_RR_+3A_logplot">logplot</code></td>
<td>
<p>plot vertical axis as log likelihood, default = FALSE</p>
</td></tr>
<tr><td><code id="L_RR_+3A_supplot">supplot</code></td>
<td>
<p>set minimum likelihood display value in plot, default = -10</p>
</td></tr>
<tr><td><code id="L_RR_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$S.val - support for observed RR from expected.
</p>
<p>$df - degrees of freedom.
</p>
<p>$exp.RR - expected RR.
</p>
<p>$S.exp.RRvsObs - support for expected RR versus observed.
</p>
<p>$S.exp.RRvsNull - support for expected RR versus the null.
</p>
<p>$L.int - likelihood interval of observed RR for specified level of support.
</p>
<p>$S_int - specified likelihood interval in units of support.
</p>
<p>$observed - observed frequencies.
</p>
<p>$expected - the expected values for null hypothesis of no interaction.
</p>
<p>$chi.sq - chi-squared statistic.
</p>
<p>$corrected - whether chi-squared was corrected, default = FALSE.
</p>
<p>$p.value - p value.
</p>
<p>$residuals - the Pearson residuals.
</p>
<p>$alpha - specified significance level.
</p>
<p>$conf.int - likelihood-based confidence interval for observed RR.
</p>
<p>$all.err.acc - error accuracy for each application of the optimize function.
</p>


<h3>References</h3>

<p>Aitkin, M. et al (1989) Statistical Modelling in GLIM, Clarendon Press, ISBN : 978-0198522041
</p>
<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. London: Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>
<p>Dienes, Z. (2008) Understanding Psychology as a Science: An Introduction to Scientific and Statistical
Inference, Palgrave, MacMillan, ISBN : 978-0230542303
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for folic acid and neural tube defects example
tab &lt;- as.table(rbind(c(6,587),c(21,581)))
dimnames(tab) &lt;- list(Treatment=c("Folic acid","None"),Defect=c("Yes","No"))
L_RR(tab, exp.RR = 0.5, L.int = 2, alpha=0.05, cc=FALSE,
toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)

# S. Korea COVID-19 patient mortality
tabcor &lt;- as.table(rbind(c(41,3095),c(34,4992)))
dimnames(tabcor) &lt;- list(Sex=c("Male","Female"),Status=c("Dead","Alive"))
L_RR(tabcor, exp.RR = 0.5, L.int = 2, alpha=0.05, cc=FALSE, toler=0.0001,
logplot=FALSE, supplot=-10, verb=TRUE)

</code></pre>

<hr>
<h2 id='L_t_test_sample_size'>Sample size calculation using the evidential approach for t tests</h2><span id='topic+L_t_test_sample_size'></span>

<h3>Description</h3>

<p>This function calculates
the required sample size for t tests. The standard deviation and effect size are
specified. Calculations given for one sample and independent samples t tests. For a related
samples test calculation use the sd for paired differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_t_test_sample_size(MW = 0.05, sd = 1, d = 1.2, S = 3, paired = FALSE, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_t_test_sample_size_+3A_mw">MW</code></td>
<td>
<p>set M1 + W1 probability, default = .05.</p>
</td></tr>
<tr><td><code id="L_t_test_sample_size_+3A_sd">sd</code></td>
<td>
<p>set standard deviation, default = 1.</p>
</td></tr>
<tr><td><code id="L_t_test_sample_size_+3A_d">d</code></td>
<td>
<p>set desired effect size, default = 1.2.</p>
</td></tr>
<tr><td><code id="L_t_test_sample_size_+3A_s">S</code></td>
<td>
<p>set strength of evidence (support), default = 3.</p>
</td></tr>
<tr><td><code id="L_t_test_sample_size_+3A_paired">paired</code></td>
<td>
<p>set to TRUE for one sample and FALSE for independent samples, default = FALSE.</p>
</td></tr>
<tr><td><code id="L_t_test_sample_size_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$N - required sample size.
</p>
<p>$S - specified strength (support) for evidence from the test.
</p>
<p>$sd - specified standard deviation.
</p>
<p>$d - Cohen's effect size specified.
</p>
<p>$m1.w1 - specified probability for combined misleading and weak evidence.
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Cahusac, P.M.B. &amp; Mansour, S.E. (2022) Estimating sample sizes for evidential t tests, Research in Mathematics, 9(1):1-12
https://doi.org/10.1080/27684830.2022.2089373
</p>
<p>Royall, R. (2000). &quot;On the Probability of Observing Misleading Statistical Evidence.&quot; Journal of the
American Statistical Association 95(451): 760.
</p>
<p>Royall, R. (2004). The Likelihood paradigm for statistical evidence. The Nature of Scientific Evidence.
M. L. Taper and S. R. Lele. Chicago, University of Chicago: 119.
</p>
<p>Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. London: Chapman &amp; Hall, ISBN : 978-0412044113
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for one sample or related samples (differences)
v = L_t_test_sample_size(MW = 0.2, sd = 1, d = 1, S = 3, paired = TRUE)
v
# for 2 independent samples
v = L_t_test_sample_size(MW = 0.05, sd = 1, d = 1.2, S = 3, paired = FALSE)
v

</code></pre>

<hr>
<h2 id='L_ttest'>Likelihood Supports for the One Sample and Related Samples t Test</h2><span id='topic+L_ttest'></span>

<h3>Description</h3>

<p>This function calculates several different supports. Effect size (Cohen's d) and a
second alternative hypothesis value can be specified. The maximum support is the support
for the observed mean versus the null value. The support for the specified d versus
the null is also calculated. If a second hypothesis value is specified (in units of
the original measurements) then two further supports are calculated: d versus 2nd
alternative hypothesis, and 2nd alternative hypothesis versus the null.
The likelihood curve graphic with MLE and specified hypothesis values is produced.
The requested likelihood interval is provided and displayed on likelihood curve.
The t and p values for the test against the null value are given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L_ttest(data1, data2, null=0, d=0.5, alt.2=NULL,
L.int=2, toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L_ttest_+3A_data1">data1</code></td>
<td>
<p>a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_data2">data2</code></td>
<td>
<p>a (non-empty) numeric vector of data values for related sample, default = NULL.</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_null">null</code></td>
<td>
<p>value for the null hypothesis, default = 0.</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_d">d</code></td>
<td>
<p>Cohen's effect size, default = 0.5.</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_alt.2">alt.2</code></td>
<td>
<p>value for an alternative hypothesis, in units used for data, default = NULL.</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_l.int">L.int</code></td>
<td>
<p>likelihood interval given for a given support value, e.g. 2 or 3, default = 2.</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_toler">toler</code></td>
<td>
<p>the desired accuracy using optimise, default = 0.0001.</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_logplot">logplot</code></td>
<td>
<p>plot vertical axis as log likelihood, default = FALSE</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_supplot">supplot</code></td>
<td>
<p>set minimum likelihood display value in plot, default = -10</p>
</td></tr>
<tr><td><code id="L_ttest_+3A_verb">verb</code></td>
<td>
<p>show output, default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>$obs.mean - the observed mean or difference in mean for related samples.
</p>
<p>$df - degrees of freedom.
</p>
<p>$alt.H1 - mean value according to specified d.
</p>
<p>$alt.H2 - specified second hypothesis value.
</p>
<p>$S_max - maximum support for observed mean against the null.
</p>
<p>$S_10 - support for d versus null.
</p>
<p>$S_12 - support for d versus specified second hypothesis.
</p>
<p>$S_20 - support for second hypothesis versus the null.
</p>
<p>$like.int - likelihood interval.
</p>
<p>$L.int.spec - specified likelihood interval in units of support.
</p>
<p>$null.value - null value.
</p>
<p>$t.val - t value for test against null.
</p>
<p>$p.val - p value for test against null.
</p>
<p>$d.obs - observed effect size.
</p>


<h3>References</h3>

<p>Cahusac, P.M.B. (2020) Evidence-Based Statistics, Wiley, ISBN : 978-1119549802
</p>
<p>Baguley, T. (2012) Serious Stats, Palgrave Macmillan, ISBN: 978-0230577183
</p>
<p>Edwards, A.W.F. (1992) Likelihood, Johns Hopkins Press, ISBN : 978-0801844430
</p>
<p>Royall, R. M. (2000). On the probability of observing misleading statistical evidence.
Journal of the American Statistical Association, 95, 760.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># one sample Gosset's original additional hours of sleep data, p 29
mysample &lt;- c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, 0.8, 0.0, 2.0)
L_ttest(mysample, d=.5, alt.2=2, L.int=2)

# related samples, p 56
mysample2 &lt;- c(1.9, 0.8, 1.1, 0.1, -0.1, 4.4, 5.5, 1.6, 4.6, 3.4)
L_ttest(mysample, mysample2, d=1, alt.2=2, L.int=2,
toler=0.0001, logplot=FALSE, supplot=-10, verb=TRUE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
