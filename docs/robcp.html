<!DOCTYPE html><html><head><title>Help for package robcp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {robcp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cor_cusum'><p>A CUSUM-type test to detect changes in the fluctuation.</p></a></li>
<li><a href='#cor_stat'><p>Test statistic to detect Fluctuation Changes</p></a></li>
<li><a href='#CUSUM'>
<p>CUSUM Test Statistic</p></a></li>
<li><a href='#hl_test'><p>Hodges-Lehmann Test for Change Points</p></a></li>
<li><a href='#HodgesLehmann'><p>Hodges Lehmann Test Statistic</p></a></li>
<li><a href='#huber_cusum'>
<p>Huberized CUSUM test</p></a></li>
<li><a href='#kthPair'>
<p>K-th largest element in a sum of sets.</p></a></li>
<li><a href='#lrv'>
<p>Long Run Variance</p></a></li>
<li><a href='#medianDiff'><p>Median of the set X - Y</p></a></li>
<li><a href='#modifChol'>
<p>Revised Modified Cholesky Factorization</p></a></li>
<li><a href='#pKSdist'>
<p>Asymptotic cumulative distribution for the CUSUM Test statistic</p></a></li>
<li><a href='#plot.cpStat'><p>Plot method for change point statistics</p></a></li>
<li><a href='#print.cpStat'><p>Print method for change point statistics</p></a></li>
<li><a href='#psi'>
<p>Transformation of time series</p></a></li>
<li><a href='#psi_cumsum'>
<p>Cumulative sum of transformed vectors</p></a></li>
<li><a href='#Qalpha'><p><code class="reqn">Q^{\alpha}</code></p></a></li>
<li><a href='#scale_cusum'><p>Tests for Scale Changes Based on Pairwise Differences</p></a></li>
<li><a href='#scale_stat'><p>Test statistic to detect Scale Changes</p></a></li>
<li><a href='#weightedMedian'><p>Weighted Median</p></a></li>
<li><a href='#wilcox_stat'><p>Wilcoxon-Mann-Whitney Test Statistic for Change Points</p></a></li>
<li><a href='#wmw_test'><p>Wilocxon-Mann-Whitney Test for Change Points</p></a></li>
<li><a href='#zeros'>
<p>Zero of the Bessel function of first kind</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Robust Change-Point Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.7</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides robust methods to detect change-points in uni- or multivariate time series. They can cope with corrupted data and heavy tails. Focus is on the detection of abrupt changes in location, but changes scale or dependence structure can be detected as well. This package provides tests for change detection in uni- and multivariate time series based on Huberized versions of CUSUM tests proposed in Duerre and Fried (2019) &lt;<a href="https://arxiv.org/abs/1905.06201">arXiv:1905.06201</a>&gt;, and tests for change detection in univariate time series based on 2-sample U-statistics or 2-sample U-quantiles as proposed by Dehling et al. (2015) &lt;<a href="https://doi.org/10.1007%2F978-1-4939-3076-0_12">doi:10.1007/978-1-4939-3076-0_12</a>&gt; and Dehling, Fried and Wendler (2020) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasaa004">doi:10.1093/biomet/asaa004</a>&gt;. Furthermore, the packages provides tests on changes in the scale or the correlation as proposed in Gerstenberger, Vogel and Wendler (2020) &lt;<a href="https://doi.org/10.1080%2F01621459.2019.1629938">doi:10.1080/01621459.2019.1629938</a>&gt;, Dehling et al. (2017) &lt;<a href="https://doi.org/10.1017%2FS026646661600044X">doi:10.1017/S026646661600044X</a>&gt;, and Wied et al. (2014) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2013.03.005">doi:10.1016/j.csda.2013.03.005</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.1)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-09-16 13:14:15 UTC; goerz</td>
</tr>
<tr>
<td>Author:</td>
<td>Sheila Goerz [aut, cre],
  Alexander Duerre [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sheila Goerz &lt;sheila.goerz@tu-dortmund.de&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, Rcpp</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, MASS, pracma, mvtnorm, cumstats</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-09-16 13:36:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='cor_cusum'>A CUSUM-type test to detect changes in the fluctuation.</h2><span id='topic+cor_cusum'></span>

<h3>Description</h3>

<p>Performs a CUSUM-based test on changes in Spearman's rho or Kendall's tau.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_cusum(x, version = c("tau", "rho"), method = "kernel", control = list(), 
          fpc = TRUE, tol = 1e-08, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_cusum_+3A_x">x</code></td>
<td>
<p>time series (matrix or ts object with numeric/integer values).</p>
</td></tr>
<tr><td><code id="cor_cusum_+3A_version">version</code></td>
<td>
<p>version of the test. Either <code>rho</code> or <code>tau</code>.</p>
</td></tr>
<tr><td><code id="cor_cusum_+3A_method">method</code></td>
<td>
<p>method for estimating the long run variance.</p>
</td></tr>
<tr><td><code id="cor_cusum_+3A_control">control</code></td>
<td>
<p>a list of control parameters.</p>
</td></tr>
<tr><td><code id="cor_cusum_+3A_fpc">fpc</code></td>
<td>
<p>finite population correction (boolean).</p>
</td></tr>
<tr><td><code id="cor_cusum_+3A_tol">tol</code></td>
<td>
<p>tolerance of the distribution function (numeric), which is used do compute p-values.</p>
</td></tr>
<tr><td><code id="cor_cusum_+3A_plot">plot</code></td>
<td>
<p>should the test statistic be plotted (cf. <code><a href="#topic+plot.cpStat">plot.cpStat</a></code>)? Boolean.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function perform a CUSUM-type test on changes in the fluctuation of a time series <code class="reqn">x</code>. Formally, the hypothesis pair can be written as
</p>
<p style="text-align: center;"><code class="reqn">H_0: \xi_1, ..., \xi_n</code>
</p>

<p style="text-align: center;"><code class="reqn">vs.</code>
</p>

<p style="text-align: center;"><code class="reqn">H_1: \exists k \in \{1, ..., n-1\}: \xi_k \neq \xi_{k+1}</code>
</p>

<p>where <code class="reqn">\xi_i</code> is a fluctuation measure (either Spearman's rho or Kendall's tau) and <code class="reqn">n</code> is the length of the time series. <code class="reqn">k</code> is called a 'change point'.
</p>
<p>The test statistic is computed using <code><a href="#topic+cor_stat">cor_stat</a></code> and asymptotically follows a Kolmogorov distribution. To derive the p-value, the funtion <code><a href="#topic+pKSdist">pKSdist</a></code> is used.
</p>


<h3>Value</h3>

<p>A list of the class &quot;htest&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>return value of the function <code><a href="#topic+cor_stat">cor_stat</a></code>.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value (numeric).</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis (character string).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>name of the performed test (character string).</p>
</td></tr>
<tr><td><code>cp.location</code></td>
<td>
<p>index of the estimated change point location (integer).</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data (character string).</p>
</td></tr>
<tr><td><code>lrv</code></td>
<td>
<p>list containing the compontents <code>method</code>, <code>param</code> and <code>value</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Wied, D., Dehling, H., Van Kampen, M., and Vogel, D. (2014). A fluctuation test for constant Spearman’s rho with nuisance-free limit distribution. Computational Statistics &amp; Data Analysis, 76, 723-736.
</p>
<p>Dürre, A. (2022+). &quot;Finite sample correction for cusum tests&quot;, <em>unpublished manuscript</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cor_stat">cor_stat</a></code>, <code><a href="#topic+lrv">lrv</a></code>, <code><a href="#topic+pKSdist">pKSdist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### first: gerenate a time series with a burn-in period of m and a change point k
require(mvtnorm)
n &lt;- 500
m &lt;- 100
N &lt;- n + m
k &lt;- m + floor(n * 0.5)
n1 &lt;- N - k

## Spearman's rho:
rho &lt;- c(0.4, -0.9)
  
# serial dependence:
theta1 &lt;- 0.3
theta2 &lt;- 0.2
theta &lt;- cbind(c(theta1, 0), c(0, theta2))
q &lt;- rho * sqrt( (theta1^2 + 1) * (theta2^2 + 1) / (theta1 * theta2 + 1))
# shape matrices of the innovations:
S0 &lt;- cbind(c(1, q[1]), c(q[1], 1))
S1 &lt;- cbind(c(1, q[2]), c(q[2], 1))

e0 &lt;- rmvt(k, S0, 5)
e1 &lt;- rmvt(n1, S1, 5)
e &lt;- rbind(e0, e1)
# generate the data:
x &lt;- matrix(numeric(N * 2), ncol = 2)
x[1, ] &lt;- e[1, ]
invisible(sapply(2:N, function(i) x[i, ] &lt;&lt;- e[i, ] + theta %*% e[i-1, ]))
x &lt;- x[-(1:m), ]

cor_cusum(x, "rho")


## Kendall's tau
S0 &lt;- cbind(c(1, rho[1]), c(rho[1], 1))
S1 &lt;- cbind(c(1, rho[2]), c(rho[2], 1))
e0 &lt;- rmvt(k, S0, 5)
e1 &lt;- rmvt(n1, S1, 5)
e &lt;- rbind(e0, e1)
x &lt;- matrix(numeric(N * 2), ncol = 2)
x[1, ] &lt;- e[1, ]
# AR(1):
invisible(sapply(2:N, function(i) x[i, ] &lt;&lt;- 0.8 * x[i-1, ] + e[i, ]))
x &lt;- x[-(1:m), ]

cor_cusum(x, version = "tau")

</code></pre>

<hr>
<h2 id='cor_stat'>Test statistic to detect Fluctuation Changes</h2><span id='topic+cor_stat'></span>

<h3>Description</h3>

<p>Computes the test statistic for a CUSUM-based tests on changes in Spearman's rho or Kendall's tau.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_stat(x, version = c("tau", "rho"), method = "kernel", control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_stat_+3A_x">x</code></td>
<td>
<p>time series (numeric or ts vector).</p>
</td></tr>
<tr><td><code id="cor_stat_+3A_version">version</code></td>
<td>
<p>version of the test. Either <code>"rho"</code> or <code>"tau"</code>.</p>
</td></tr>
<tr><td><code id="cor_stat_+3A_method">method</code></td>
<td>
<p>methods of long run variance estimation. Options are <code>"kernel"</code> and <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="cor_stat_+3A_control">control</code></td>
<td>
<p>a list of control parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">n</code> be the length of the time series, i.e. the number of rows in <code>x</code>. In general, the (scaled) CUSUM test statistic is defined as
</p>
<p style="text-align: center;"><code class="reqn">\hat{T}_{\xi; n} = \max_{k = 1, ..., n} \frac{k}{2\sqrt{n}\hat{\sigma}} | \hat{\xi}_k - \hat{\xi}_n |,</code>
</p>

<p>where <code class="reqn">\hat{\xi}</code> is an estimator for the property on which to test, and <code class="reqn">\hat{\sigma}</code> is an estimator for the square root of the corresponding long run variance (cf. <code><a href="#topic+lrv">lrv</a></code>).
</p>
<p>If <code>version = "tau"</code>, the function tests if the correlation between <code class="reqn">x_i</code> and <code class="reqn">x_i</code> of the bivariate time series <code class="reqn">(x_i, x_i)_{i = 1, ..., n}</code> stays constant for all <code class="reqn">i = 1, ..., n</code> by considering Kendall's tau. Therefore, <code class="reqn">\hat{\xi} = \hat{\tau}</code> is the the sample version of Kendall's tau:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\tau}_k = \frac{2}{k(k-1)} \sum_{1 \leq i &lt; j \leq k} sign\left((x_j - x_i)(y_j - y_i)\right).</code>
</p>

<p>The default bandwidth for the kernel-based long run variance estimation is <code class="reqn">b_n = \lfloor 2n^{1/3} \rfloor</code> and the default kernel function is the quatratic kernel.
</p>
<p>If <code>version = "rho"</code>, the function tests if the correlation of a time series of an arbitrary dimension <code class="reqn">d</code> (&gt;= 2) stays constant by considering Spearman's rho. Therefore, <code class="reqn">\hat{\xi} = \hat{\rho}</code> is the sample version of Spearman's rho:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\rho}_k = a(d) \left( \frac{2^d}{k} \sum_{j = 1}^k \prod_{i = 1}^d (1 - U_{i, j; n}) - 1 \right)</code>
</p>

<p>where <code class="reqn">U_{i, j; n} = n^{-1}</code> (rank of <code class="reqn">x_{i,j}</code> in <code class="reqn">x_{i,1}, ..., x_{i,n})</code> and <code class="reqn">a(d) = (d+1) / (2^d - d - 1)</code>. Here it is essential to use <code class="reqn">\hat{U}_{i, j; n}</code> instead of <code class="reqn">\hat{U}_{i, j; k}</code>. The default bandwidth for the kernel-based long run variance estimation is <code class="reqn">\sqrt{n}</code> and the default kernel function is the Bartlett kernel.
</p>


<h3>Value</h3>

<p>Test statistic (numeric value) with the following attributes:
</p>
<table>
<tr><td><code>cp-location</code></td>
<td>
<p>indicating at which index a change point is most likely.</p>
</td></tr>
<tr><td><code>teststat</code></td>
<td>
<p>test process (before taking the maximum).</p>
</td></tr>
<tr><td><code>lrv-estimation</code></td>
<td>
<p>long run variance estimation method.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated long run variance.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>parameter used for the lrv estimation.</p>
</td></tr>
<tr><td><code>kFun</code></td>
<td>
<p>kernel function used for the lrv estimation.</p>
</td></tr>
</table>
<p>Is an S3 object of the class &quot;cpStat&quot;.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Wied, D., Dehling, H., Van Kampen, M., and Vogel, D. (2014). A fluctuation test for constant Spearman’s rho with nuisance-free limit distribution. Computational Statistics &amp; Data Analysis, 76, 723-736.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lrv">lrv</a></code>, <code><a href="#topic+cor_cusum">cor_cusum</a></code>
</p>

<hr>
<h2 id='CUSUM'>
CUSUM Test Statistic
</h2><span id='topic+CUSUM'></span>

<h3>Description</h3>

<p>Computes the test statistic for the CUSUM change point test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CUSUM(x, method = "kernel", control = list(), inverse = "Cholesky", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CUSUM_+3A_x">x</code></td>
<td>
<p>vector or matrix with each column representing a time series (numeric).</p>
</td></tr>
<tr><td><code id="CUSUM_+3A_method">method</code></td>
<td>
<p>method of long run variance estimation. Options are <code>"kernel"</code>, <code>"subsampling"</code>, <code>"bootstrap"</code> and <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="CUSUM_+3A_control">control</code></td>
<td>
<p>a list of control parameters for the estimation of the long run variance (cf. <code><a href="#topic+lrv">lrv</a></code>).</p>
</td></tr>
<tr><td><code id="CUSUM_+3A_inverse">inverse</code></td>
<td>
<p>character string specifying the method of inversion. Options are &quot;Cholesky&quot; for inverting over <code><a href="#topic+modifChol">modifChol</a></code> and &quot;generalized&quot; for using <code><a href="MASS.html#topic+ginv">ginv</a></code> from the <code>MASS</code> package.</p>
</td></tr>
<tr><td><code id="CUSUM_+3A_...">...</code></td>
<td>
<p>further arguments passed to the inverse-computing functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let n be the length of the time series <code class="reqn">x = (x_1, ..., x_n)</code>. 
</p>
<p>In case of a univariate time series the test statistic can be written as </p>
<p style="text-align: center;"><code class="reqn">\max_{k = 1, ..., n}\frac{1}{\sqrt{n} \sigma}\left|\sum_{i = 1}^{k} x_i - (k / n) \sum_{i = 1}^n x_i\right|,</code>
</p>
<p> where <code class="reqn">\sigma</code> is the square root of <code><a href="#topic+lrv">lrv</a></code>.
Default method is <code>"kernel"</code> and the default kernel function is <code>"TH"</code>. If no bandwidth value is supplied, first the time series <code class="reqn">x</code> is corrected for the estimated change point and Spearman's autocorrelation to lag 1 (<code class="reqn">\rho</code>) is computed. Then the default bandwidth follows as 
</p>
<p style="text-align: center;"><code class="reqn">b_n = \max\left\{\left\lceil n^{0.45} \left( \frac{2\rho}{1 - \rho^2} \right)^{0.4} \right\rceil, 1 \right\}.</code>
</p>

<p>In case of a multivariate time series the test statistic follows as
</p>
<p style="text-align: center;"><code class="reqn">\max_{k = 1, ..., n}\frac{1}{n}\left(\sum_{i = 1}^{k} X_i - \frac{k}{n} \sum_{i = 1}^{n} X_i\right)^T \Sigma^{-1} \left(\sum_{i = 1}^{k} X_i - \frac{k}{n} \sum_{i = 1}^{n} X_i\right),</code>
</p>
<p> where <code class="reqn">X_i</code> denotes the i-th row of x and <code class="reqn">\Sigma^{-1}</code> is the inverse of <code><a href="#topic+lrv">lrv</a></code>.
</p>


<h3>Value</h3>

<p>Test statistic (numeric value) with the following attributes:
</p>
<table>
<tr><td><code>cp-location</code></td>
<td>
<p>indicating at which index a change point is most likely.</p>
</td></tr>
<tr><td><code>teststat</code></td>
<td>
<p>test process (before taking the maximum).</p>
</td></tr>
<tr><td><code>lrv-estimation</code></td>
<td>
<p>long run variance estimation method.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated long run variance.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>parameter used for the lrv estimation.</p>
</td></tr>
<tr><td><code>kFun</code></td>
<td>
<p>kernel function used for the lrv estimation.</p>
</td></tr>
</table>
<p>Is an S3 object of the class &quot;cpStat&quot;.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psi_cumsum">psi_cumsum</a></code>, 
<code><a href="#topic+psi">psi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># time series with a location change at t = 20
ts &lt;- c(rnorm(20, 0), rnorm(20, 2))

# Huberized CUSUM change point test statistic
CUSUM(psi(ts))
</code></pre>

<hr>
<h2 id='hl_test'>Hodges-Lehmann Test for Change Points</h2><span id='topic+hl_test'></span>

<h3>Description</h3>

<p>Performs the two-sample Hodges-Lehmann change point test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hl_test(x, b_u = "nrd0", method = "kernel", control = list(), tol = 1e-8, 
        plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hl_test_+3A_x">x</code></td>
<td>
<p>time series (numeric or ts vector).</p>
</td></tr>
<tr><td><code id="hl_test_+3A_b_u">b_u</code></td>
<td>
<p>bandwidth for <code><a href="#topic+u_hat">u_hat</a></code>. Either a numeric value or the name
of a bandwidth selection function (c.f. <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code>).</p>
</td></tr>
<tr><td><code id="hl_test_+3A_method">method</code></td>
<td>
<p>method for estimating the long run variance.</p>
</td></tr>
<tr><td><code id="hl_test_+3A_control">control</code></td>
<td>
<p>a list of control parameters (cf. <code><a href="#topic+lrv">lrv</a></code>).</p>
</td></tr>
<tr><td><code id="hl_test_+3A_tol">tol</code></td>
<td>
<p>tolerance of the distribution function (numeric), which is used to compute p-values.</p>
</td></tr>
<tr><td><code id="hl_test_+3A_plot">plot</code></td>
<td>
<p>should the test statistic be plotted (cf. <code><a href="#topic+plot.cpStat">plot.cpStat</a></code>)? Boolean.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the two-sample Hodges-Lehmann change point test. It tests the hypothesis pair
</p>
<p style="text-align: center;"><code class="reqn">H_0: \mu_1 = ... = \mu_n</code>
</p>

<p style="text-align: center;"><code class="reqn">vs.</code>
</p>

<p style="text-align: center;"><code class="reqn">H_1: \exists k \in \{1, ..., n-1\}: \mu_k \neq \mu_{k+1}</code>
</p>

<p>where <code class="reqn">\mu_t = E(X_t)</code> and <code class="reqn">n</code> is the length of the time series. <code class="reqn">k</code> is called a 'change point'. 
</p>
<p>The test statistic is computed using <code><a href="#topic+HodgesLehmann">HodgesLehmann</a></code> and asymptotically follows a Kolmogorov distribution. To derive the p-value, the function <code><a href="#topic+pKSdist">pKSdist</a></code> is used. 
</p>


<h3>Value</h3>

<p>A list of the class &quot;htest&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>value of the test statistic (numeric).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value (numeric).</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis (character string).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>name of the performed test (character string).</p>
</td></tr>
<tr><td><code>cp.location</code></td>
<td>
<p>index of the estimated change point location (integer).</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data (character string).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Dehling, H., Fried, R., and Wendler, M. &quot;A robust method for shift detection in time series.&quot; Biometrika 107.3 (2020): 647-660.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HodgesLehmann">HodgesLehmann</a></code>, <code><a href="#topic+medianDiff">medianDiff</a></code>, <code><a href="#topic+lrv">lrv</a></code>, <code><a href="#topic+pKSdist">pKSdist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#time series with a structural break at t = 20
Z &lt;- c(rnorm(20, 0), rnorm(20, 2))

hl_test(Z, control = list(overlapping = TRUE, b_n = 5, b2 = 0.05))
</code></pre>

<hr>
<h2 id='HodgesLehmann'>Hodges Lehmann Test Statistic</h2><span id='topic+HodgesLehmann'></span><span id='topic+u_hat'></span>

<h3>Description</h3>

<p>Computes the test statistic for the Hodges-Lehmann change point test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HodgesLehmann(x, b_u = "nrd0", method = "kernel", control = list())
u_hat(x, b_u = "nrd0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HodgesLehmann_+3A_x">x</code></td>
<td>
<p>time series (numeric or <code>ts</code> vector).</p>
</td></tr>
<tr><td><code id="HodgesLehmann_+3A_b_u">b_u</code></td>
<td>
<p>bandwidth for <code><a href="#topic+u_hat">u_hat</a></code>. Either a numeric value or the name
of a bandwidth selection function (c.f. <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code>).</p>
</td></tr>
<tr><td><code id="HodgesLehmann_+3A_method">method</code></td>
<td>
<p>method of long run variance estimation. Options are <code>"kernel"</code>, <code>"subsampling"</code>, <code>"bootstrap"</code> and <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="HodgesLehmann_+3A_control">control</code></td>
<td>
<p>a list of control parameters for the estimation of the long run variance (cf. <code><a href="#topic+lrv">lrv</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">n</code> be the length of the time series. The Hodges-Lehmann test statistic is then computed as
</p>
<p style="text-align: center;"><code class="reqn">\frac{\sqrt{n}}{\hat{\sigma}_n} \max_{1 \leq k &lt; n} \hat{u}_{k,n}(0) \frac{k}{n} \left(1 - \frac{k}{n}\right) | med\{(x_j - x_i); 1 \leq i \leq k; k+1 \leq j \leq n\} | ,</code>
</p>

<p>where <code class="reqn">\hat{\sigma}</code> is the estimated long run variance, computed by the square root of <code><a href="#topic+lrv">lrv</a></code>. By default the long run variance is estimated kernel-based with the following bandwidth: first the time series <code class="reqn">x</code> is corrected for the estimated change point and Spearman's autocorrelation to lag 1 (<code class="reqn">\rho</code>) is computed. Then the default block length follows as 
</p>
<p style="text-align: center;"><code class="reqn">l = \max\left\{\left\lceil n^{1/3} \left( \frac{2\rho}{1 - \rho^2}\right)^{0.9} \right\rceil, 1\right\}.</code>
</p>

<p><code class="reqn">\hat{u}_{k,n}(0)</code> is estimated by <code>u_hat</code> on data <code class="reqn">\tilde{x}</code>, where <code class="reqn">med\{(x_j - x_i); 1 \leq i \leq k; k+1 \leq j \leq n\}</code> was subtracted from <code class="reqn">x_{k+1}, ..., x_n</code>. Then <code><a href="stats.html#topic+density">density</a></code> with the arguments <code>na.rm = TRUE</code>, <code>from = 0</code>, <code>to = 0</code>, <code>n = 1</code> and <code>bw =  b_u</code> is applied to <code class="reqn">(\tilde{x}_i - \tilde{x_j})_{1 \leq i &lt; j \leq n}</code>.
</p>


<h3>Value</h3>

<p><code>HodgesLehmann</code> returns a test statistic (numeric value) with the following attributes:
</p>
<table>
<tr><td><code>cp-location</code></td>
<td>
<p>indicating at which index a change point is most likely.</p>
</td></tr>
<tr><td><code>teststat</code></td>
<td>
<p>test process (before taking the maximum).</p>
</td></tr>
<tr><td><code>lrv-estimation</code></td>
<td>
<p>long run variance estimation method.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated long run variance.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>parameter used for the lrv estimation.</p>
</td></tr>
<tr><td><code>kFun</code></td>
<td>
<p>kernel function used for the lrv estimation.</p>
</td></tr>
</table>
<p>Is an S3 object of the class &quot;cpStat&quot;.
</p>
<p><code>u_hat</code> returns a numeric value.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Dehling, H., Fried, R., and Wendler, M. &quot;A robust method for shift detection in time series.&quot; Biometrika 107.3 (2020): 647-660.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+medianDiff">medianDiff</a></code>, <code><a href="#topic+lrv">lrv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># time series with a location change at t = 20
x &lt;- c(rnorm(20, 0), rnorm(20, 2))

# Hodges-Lehmann change point test statistic
HodgesLehmann(x, b_u = 0.01)
</code></pre>

<hr>
<h2 id='huber_cusum'>
Huberized CUSUM test
</h2><span id='topic+huber_cusum'></span>

<h3>Description</h3>

<p>Performs a CUSUM test on data transformed by <code><a href="#topic+psi">psi</a></code>. Depending on the chosen psi-function different types of changes can be detected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber_cusum(x, fun = "HLm", k, constant = 1.4826, method = "kernel",
            control = list(), fpc = TRUE, tol = 1e-8, plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="huber_cusum_+3A_x">x</code></td>
<td>
<p>numeric vector containing a single time series or a numeric matrix containing multiple time series (column-wise).</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_fun">fun</code></td>
<td>
<p>character string specifying the transformation function <code class="reqn">\psi</code>, see details.</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_k">k</code></td>
<td>
<p>numeric bound used in <code><a href="#topic+psi">psi</a></code>.</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_constant">constant</code></td>
<td>
<p>scale factor of the MAD. Default is 1.4826.</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_method">method</code></td>
<td>
<p>method for estimating the long run variance.</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_control">control</code></td>
<td>
<p>a list of control parameters for the estimation of the long run variance (cf. <code><a href="#topic+lrv">lrv</a></code>).</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_fpc">fpc</code></td>
<td>
<p>finite population correction (boolean).</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_tol">tol</code></td>
<td>
<p>tolerance of the distribution function (numeric), which is used to compute p-values.</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_plot">plot</code></td>
<td>
<p>should the test statistic be plotted (cf. <code><a href="#topic+plot.cpStat">plot.cpStat</a></code>). Boolean.</p>
</td></tr>
<tr><td><code id="huber_cusum_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code><a href="#topic+CUSUM">CUSUM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs a Huberized CUSUM test. It tests the null hypothesis <code class="reqn">H_0: \boldsymbol{\theta}</code> does not change for <code class="reqn">x</code> against the alternative of a change, where <code class="reqn">\boldsymbol{\theta}</code> is the parameter vector of interest. <code class="reqn">k</code> is called a 'change point'. First the data is transformed by a suitable psi-function. To detect changes in location one can apply <code>fun = "HLm"</code>, <code>"HLg"</code>, <code>"SLm"</code> or <code>"SLg"</code> and the hypothesis pair is
</p>
<p style="text-align: center;"><code class="reqn">H_0: \mu_1 = ... = \mu_n</code>
</p>

<p style="text-align: center;"><code class="reqn">vs.</code>
</p>

<p style="text-align: center;"><code class="reqn">H_1: \exists k \in \{1, ..., n-1\}: \mu_k \neq \mu_{k+1}</code>
</p>

<p>where <code class="reqn">\mu_t = E(X_t)</code> and <code class="reqn">n</code> is the length of the time series. For changes in scale <code>fun = "HCm"</code> is available and for changes in the dependence respectively covariance structure <code>fun = "HCm"</code>, <code>"HCg"</code>, <code>"SCm"</code> and <code>"SCg"</code> are possible. The hypothesis pair is the same as in the location case, only with <code class="reqn">\mu_i</code> being replaced by <code class="reqn">\Sigma_i</code>, <code class="reqn">\Sigma_i = Cov(X_i)</code>. Exact definitions of the psi-functions can be found on the help page of <code><a href="#topic+psi">psi</a></code>. 
</p>
<p>Denote by <code class="reqn">Y_1,\ldots,Y_n</code> the transformed time series. If <code class="reqn">Y_1</code> is one-dimensional, then the test statistic
</p>
<p style="text-align: center;"><code class="reqn">V_n = \max_{k=1,\ldots,n} \frac{1}{\sqrt{n}\sigma} \left|\sum_{i=1}^k Y_i-\frac{k}{n} \sum_{i=1}^n Y_i\right|
</code>
</p>

<p>is calculated, where <code class="reqn">\sigma^2</code> is an estimator for the long run variance, see the help function of <code><a href="#topic+lrv">lrv</a></code> for details. <code class="reqn">V</code> is asymptotically Kolmogorov-Smirnov distributed. If <code>fpc</code> is <code>TRUE</code> we use a finite population correction <code class="reqn">V+0.58/\sqrt{n}</code> to improve finite sample performance (Dürre, 2021+).  <br />
If <code class="reqn">Y_1</code> is multivariate, then the test statistic
</p>
<p style="text-align: center;"><code class="reqn">W_n=\max_{k=1,\ldots,n} \frac{1}{n}\left(\sum_{i=1}^k Y_i-\frac{k}{n} \sum_{i=1}^n Y_i\right)' \Sigma^{-1}\left(\sum_{i=1}^k Y_i-\frac{k}{n} \sum_{i=1}^n Y_i\right)
</code>
</p>

<p>is computed, where <code class="reqn">\Sigma</code> is the long run covariance, see also <code><a href="#topic+lrv">lrv</a></code> for details. <code class="reqn">W</code> is asymptotically distributed like the maximum of a squared Bessel bridge. We use the identity derived by Kiefer (1959) to derive p-values. Like in the one dimensional case if <code>fpc</code> is <code>TRUE</code> we use a finite sample correction <code class="reqn">(\sqrt{W}+0.58/\sqrt{n})^2</code>.
</p>
<p>The change point location is estimated as the time point <code class="reqn">k</code> for which the CUSUM process takes its maximum. 
</p>


<h3>Value</h3>

<p>A list of the class &quot;htest&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>value of the test statistic (numeric).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value (numeric).</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis (character string).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>name of the performed test (character string).</p>
</td></tr>
<tr><td><code>cp.location</code></td>
<td>
<p>index of the estimated change point location (integer).</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data (character string).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Dürre, A. and Fried, R. (2019). &quot;Robust change point tests by bounded transformations&quot;, <a href="https://arxiv.org/abs/1905.06201">https://arxiv.org/abs/1905.06201</a>
</p>
<p>Dürre, A. (2021+). &quot;Finite sample correction for cusum tests&quot;, <em>unpublished manuscript</em>
</p>
<p>Kiefer, J. (1959). &quot;K-sample analogues of the Kolmogorov-Smirnov and Cramer-V. Mises tests&quot;, <em>The Annals of Mathematical Statistics</em>, 420&ndash;447.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lrv">lrv</a></code>, 
<code><a href="#topic+psi">psi</a></code>, <code><a href="#topic+psi_cumsum">psi_cumsum</a></code>, <code><a href="#topic+CUSUM">CUSUM</a></code>, 
<code><a href="#topic+pKSdist">pKSdist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1895)

#time series with a structural break at t = 20
Z &lt;- c(rnorm(20, 0), rnorm(20, 2))
huber_cusum(Z) 

# two time series with a structural break at t = 20
timeSeries &lt;- matrix(c(rnorm(20, 0), rnorm(20, 2), rnorm(20, 1), rnorm(20, 3), 
                     ncol = 2))
                     
huber_cusum(timeSeries)
</code></pre>

<hr>
<h2 id='kthPair'>
K-th largest element in a sum of sets.
</h2><span id='topic+kthPair'></span>

<h3>Description</h3>

<p>Selects the k-th largest element of X + Y, a sum of sets. X + Y denotes the set <code class="reqn">\{x + y | x \in X, y \in Y\}</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kthPair(X, Y, k, k2 = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kthPair_+3A_x">X</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="kthPair_+3A_y">Y</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="kthPair_+3A_k">k</code></td>
<td>
<p>Index of element to be selected. Must be an integer and between 1 and the product of the lengths of x and y.</p>
</td></tr>
<tr><td><code id="kthPair_+3A_k2">k2</code></td>
<td>
<p>Optional second index. <code>k</code> and <code>k2</code> must be consecutive. Useful, if the number of elements of X + Y is even and the median is to be calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A generalized version of the algorithm of Johnson and Mizoguchi (1978), where <code class="reqn">X</code> and <code class="reqn">Y</code> are allowed to be of different lengths. The optional argument <code>k2</code> allows the computation of the mean of two consecutive value without running the algorithm twice.
</p>


<h3>Value</h3>

<p>K-th largest value (numeric).
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Johnson, D. B., &amp; Mizoguchi, T. (1978). Selecting the K-th Element in X+Y and X_1+X_2+ ... +X_m. SIAM Journal on Computing, 7(2), 147-153.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1895)
x &lt;- rnorm(100)
y &lt;- runif(100)

kthPair(x, y, 5000)
kthPair(x, y, 5000, 5001)
</code></pre>

<hr>
<h2 id='lrv'>
Long Run Variance
</h2><span id='topic+lrv'></span>

<h3>Description</h3>

<p>Estimates the long run variance respectively covariance matrix of the supplied time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrv(x, method = c("kernel", "subsampling", "bootstrap", "none"), control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrv_+3A_x">x</code></td>
<td>
<p>vector or matrix with each column representing a time series (numeric).</p>
</td></tr>
<tr><td><code id="lrv_+3A_method">method</code></td>
<td>
<p>method of estimation. Options are <code>kernel</code>, <code>subsampling</code>, <code>bootstrap</code> and <code>none</code>.</p>
</td></tr>
<tr><td><code id="lrv_+3A_control">control</code></td>
<td>
<p>a list of control parameters. See 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The long run variance equals the limit of <code class="reqn">n</code> times the variance of the arithmetic mean of a short range dependent time series, where <code class="reqn">n</code> is the length of the time series. It is used to standardize tests concering the mean on dependent data.
</p>
<p>If <code>method = "none"</code>, no long run variance estimation is performed and the value 1 is returned (i.e. it does not alterate the test statistic). 
</p>
<p>The <code>control</code> argument is a list that can supply any of the following components:
</p>

<dl>
<dt><code>kFun</code></dt><dd><p>Kernel function (character string). More in 'Notes'.</p>
</dd>
<dt><code>b_n</code></dt><dd><p>Bandwidth (numeric &gt; 0 and smaller than sample size).</p>
</dd>
<dt><code>gamma0</code></dt><dd><p>Only use estimated variance if estimated long run variance is &lt; 0? Boolean.</p>
</dd>
<dt><code>l</code></dt><dd><p>Block length (numeric &gt; 0 and smaller than sample size).</p>
</dd>
<dt><code>overlapping</code></dt><dd><p>Overlapping subsampling estimation? Boolean.</p>
</dd>
<dt><code>distr</code></dt><dd><p>Tranform observations by their empirical distribution function? Boolean. Default is <code>FALSE</code>.</p>
</dd>
<dt><code>B</code></dt><dd><p>Bootstrap repetitions (integer).</p>
</dd>
<dt><code>seed</code></dt><dd><p>RNG seed (numeric).</p>
</dd>
<dt><code>version</code></dt><dd><p>What property does the CUSUM test test for? Character string, details below.</p>
</dd>
<dt><code>loc</code></dt><dd><p>Estimated location corresponding to <code>version</code>. Numeric value, details below.</p>
</dd>
<dt><code>scale</code></dt><dd><p>Estimated scale corresponding to <code>version</code>. Numeric value, details below.</p>
</dd>
</dl>

<p><strong>Kernel-based estimation</strong>
</p>
<p>The kernel-based long run variance estimation is available for various testing scenarios (set by <code>control$version</code>) and both for one- and multi-dimensional data. It uses the bandwidth <code class="reqn">b_n = </code> <code>control$b_n</code> and kernel function <code class="reqn">k(x) = </code> <code>control$kFun</code>. For tests on certain properties also a corresponding location <code>control$loc</code> (<code class="reqn">m_n</code>) and scale <code>control$scale</code> (<code class="reqn">v_n</code>) estimation needs to be supplied. Supported testing scenarios are:
</p>

<ul>
<li> <p><code>"mean"</code>
</p>

<ul>
<li><p> 1-dim. data:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = \frac{1}{n} \sum_{i = 1}^n (x_i - \bar{x})^2 + \frac{2}{n} \sum_{h = 1}^{b_n} \sum_{i = 1}^{n - h} (x_i - \bar{x}) (x_{i + h} - \bar{x}) k(h / b_n).</code>
</p>

<p>If <code>control$distr = TRUE</code>, then the long run variance is estimated on the empirical distribution of <code class="reqn">x</code>. The resulting value is then multiplied with <code class="reqn">\sqrt{\pi} / 2</code>.
</p>
<p>Default values: <code>b_n</code> = <code class="reqn">0.9 n^{1/3}</code>, <code>kFun = "bartlett"</code>.
</p>
</li>
<li><p> multivariate time series:
The <code class="reqn">k,l</code>-element of <code class="reqn">\Sigma</code> is estimated by
</p>
<p style="text-align: center;"><code class="reqn">\hat{\Sigma}^{(k,l)} = \frac{1}{n} \sum_{i,j = 1}^{n}(x_i^{(k)} - \bar{x}^{(k)})  (x_j^{(l)} -        \bar{x}^{(l)})  k((i-j) / b_n),</code>
</p>

<p><code class="reqn">k, l = 1, ..., m</code>.
</p>
<p>Default values: <code>b_n</code> = <code class="reqn">\log_{1.8 + m / 40}(n / 50)</code>, <code>kFun = "bartlett"</code>.
</p>
</li></ul>

</li>
<li> <p><code>"empVar"</code> for tests on changes in the empirical variance.
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = \sum_{h = -(n-1)}^{n-1} W \left( \frac{|h|}{b_n} \right) \frac{1}{n} \sum_{i = 1}^{n - |h|} ((x_i - m_n)^2 - v_n)((x_{i+|h|} - m_n)^2 - v_n).</code>
</p>

<p>Default values: <code class="reqn">m_n =</code> <code>mean(x)</code>, <code class="reqn">v_n = </code> <code>var(x)</code>.
</p>
</li>
<li> <p><code>"MD"</code> for tests on a change in the median deviation.
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = \sum_{h = -(n-1)}^{n-1} W \left( \frac{|h|}{b_n} \right) \frac{1}{n} \sum_{i = 1}^{n - |h|} (|x_i - m_n| - v_n)(|x_{i+|h|} - m_n| - v_n).</code>
</p>

<p>Default values: <code class="reqn">m_n =</code> <code>median(x)</code>, <code class="reqn">v_n = \frac{1}{n-1} \sum_{i = 1}^n |x_i - m_n|</code>.
</p>
</li>
<li> <p><code>"GMD"</code> for tests on changes in Gini's mean difference.
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = 4 \sum_{h = -(n-1)}^{n-1} W \left( \frac{|h|}{b_n} \right) \frac{1}{n} \sum_{i = 1}^{n - |h|} \hat{\phi}_n(x_i)\hat{\phi}_n(x_{i+|h|})</code>
</p>

<p>with <code class="reqn">\hat{\phi}_n(x) = n^{-1} \sum_{i = 1}^n |x - x_i| - v_n</code>.
</p>
<p>Default value: <code class="reqn">v_n =</code> <code class="reqn">\frac{2}{n(n-1)} \sum_{1 \leq i &lt; j \leq n} |x_i - x_j|.</code>
</p>







</li>
<li> <p><code>"Qalpha"</code> for tests on changes in <code><a href="#topic+Qalpha">Qalpha</a></code>.
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = \frac{4}{\hat{u}(v_n)} \sum_{h = -(n-1)}^{n-1} W \left( \frac{|h|}{b_n} \right) \frac{1}{n} \sum_{i = 1}^{n - |h|} \hat{\phi}_n(x_i)\hat{\phi}_n(x_{i+|h|}),</code>
</p>

<p>where <code class="reqn">\hat{\phi}_n(x) = n^{-1} \sum_{i = 1}^n 1_{\{|x - x_i| \leq v_n\}} - m_n</code> and 
</p>
<p style="text-align: center;"><code class="reqn">\hat{u}(t) = \frac{2}{n(n-1)h_n} \sum_{1 \leq i &lt; j \leq n} K\left(\frac{|x_i - x_j| - t}{h_n}\right)</code>
</p>

<p>the kernel density estimation of the densitiy <code class="reqn">u</code> corresponding to the distribution function <code class="reqn">U(t) = P(|X-Y| \leq t)</code>, <code class="reqn">h_n =</code> <code>IQR(x)</code><code class="reqn">n^{-\frac{1}{3}}</code> and <code class="reqn">K</code> is the quatratic kernel function.
</p>
<p>Default values: <code class="reqn">m_n = \alpha = 0.5</code>, <code class="reqn">v_n =</code> <code>Qalpha(x, m_n)[n-1]</code>.
</p>
</li>
<li> <p><code>"tau"</code> for tests in changes in Kendall's tau.
</p>
<p>Only available for bivariate data: assume that the given data <code>x</code> has the format <code class="reqn">(x_i, y_i)_{i = 1, ..., n}</code>.
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = \sum_{h = -(n-1)}^{n-1} W \left( \frac{|h|}{b_n} \right) \frac{1}{n} \sum_{i = 1}^{n - |h|} \hat{\phi}_n((x_i, y_i))\hat{\phi}_n((x_{i+|h|}, y_{i+|h|}),</code>
</p>

<p>where <code class="reqn">\hat{\phi}_n(x) = 4 F_n(x, y) - 2F_{X,n}(x) 2 - F_{Y,n}(y) + 1 - v_n</code> and <code class="reqn">F_n</code>, <code class="reqn">F_{X,n}</code> and <code class="reqn">F_{Y,n}</code> are the empirical distribution functions of <code class="reqn">((X_i, Y_i))_{i = 1, ..., n}</code>, <code class="reqn">(X_i)_{i = 1, ..., n}</code> and <code class="reqn">(Y_i)_{i = 1, ..., n}</code>.
</p>
<p>Default value: <code class="reqn">v_n = \hat{\tau}_n = \frac{2}{n(n-1)} \sum_{1 \leq i &lt; j \leq n} sign\left((x_j - x_i)(y_j - y_i)\right)</code>.
</p>
</li>
<li> <p><code>"rho"</code> for tests on changes in Spearman's rho.
</p>
<p>Only availabe for <code class="reqn">d</code>-variate data with <code class="reqn">d &gt; 1</code>: assume that the given data <code>x</code> has the format <code class="reqn">(x_{i,j} | i = 1, ..., n; j = 1, ..., d)</code>.
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = a(d)^2 2^{2d} \left\{ \sum_{h = -(n-1)}^{n-1} K\left( \frac{|h|}{b_n} \right) \left( \sum_{i = 1}^{n-|h|} n^{-1} \prod_{j = 1}^d \hat{\phi}_n(x_i, x_j) \hat{\phi}_n(x_{i+|h|}, x_j) - M^2 \right) \right\} ,</code>
</p>

<p>where <code class="reqn">a(d) = (d+1) / (2^d - d - 1)</code>,  <code class="reqn">M = n^{-1} \sum_{i = 1}^n \prod_{j = 1}^d \hat{\phi}_n(x_i, x_j)</code> and <code class="reqn">\hat{\phi}_n(x, y) = 1 - \hat{U}_n(x, y)</code>, <code class="reqn">\hat{U}_n(x, y) = n^{-1}</code> (rank of <code class="reqn">x_{i,j}</code> in <code class="reqn">x_{i,1}, ..., x_{i,n})</code>.
</p>
</li></ul>

<p>When <code>control$gamma0 = TRUE</code> (default) then negative estimates of the long run variance are replaced by the autocovariance at lag 0 (= ordinary variance of the data). The function will then throw a warning.
</p>
<p><strong>Subsampling estimation</strong>
</p>
<p>For <code>method = "subsampling"</code> there are an overlapping and a non-overlapping version (parameter <code>control$overlapping</code>). Also it can be specified if the observations x were transformed by their empirical distribution function <code class="reqn">\tilde{F}_n</code> (parameter <code>control$distr</code>). Via <code>control$l</code> the block length <code class="reqn">l</code> can be controlled.
</p>
<p>If <code>control$overlapping = TRUE</code> and <code>control$distr = TRUE</code>:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}_n = \frac{\sqrt{\pi}}{\sqrt{2l}(n - l + 1)} \sum_{i = 0}^{n-l} \left| \sum_{j = i+1}^{i+l} (F_n(x_j) - 0.5) \right|.</code>
</p>

<p>Otherwise, if <code>control$distr = FALSE</code>, the estimator is
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = \frac{1}{l (n - l + 1)} \sum_{i = 0}^{n-l} \left( \sum_{j = i + 1}^{i+l} x_j - \frac{l}{n} \sum_{j = 1}^n x_j \right)^2.</code>
</p>

<p>If <code>control$overlapping = FALSE</code> and <code>control$distr = TRUE</code>:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma} = \frac{1}{n/l} \sqrt{\pi/2} \sum_{i = 1}{n/l} \frac{1}{\sqrt{l}} \left| \sum_{j = (i-1)l + 1}^{il} F_n(x_j) - \frac{l}{n} \sum_{j = 1}^n F_n(x_j) \right|.</code>
</p>

<p>Otherwise, if <code>control$distr = FALSE</code>, the estimator is
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = \frac{1}{n/l} \sum_{i = 1}^{n/l} \frac{1}{l} \left(\sum_{j = (i-1)l + 1}^{il} x_j - \frac{l}{n} \sum_{j = 1}^n x_j\right)^2.</code>
</p>

<p>Default values: overlapping = TRUE, the block length is chosen adaptively: 
</p>
<p style="text-align: center;"><code class="reqn">l_n = \max{\left\{ \left\lceil n^{1/3} \left( \frac{2 \rho}{1 - \rho^2} \right)^{(2/3)} \right\rceil, 1 \right\}}</code>
</p>

<p>where <code class="reqn">\rho</code> is the Spearman autocorrelation at lag 1.
</p>
<p><strong>Bootstrap estimation</strong>
</p>
<p>If <code>method = "bootstrap"</code> a dependent wild bootstrap with the parameters <code class="reqn">B = </code> <code>control$B</code>, <code class="reqn">l = </code> <code>control$l</code> and <code class="reqn">k(x) = </code> <code>control$kFun</code> is performed:
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\sigma}^2 = \sqrt{n} Var(\bar{x^*_k} - \bar{x}), k = 1, ..., B</code>
</p>

<p>A single <code class="reqn">x_{ik}^*</code> is generated by <code class="reqn">x_i^* = \bar{x} + (x_i - \bar{x}) a_i</code> where <code class="reqn">a_i</code> are independent from the data <code>x</code> and are generated from a multivariate normal distribution with <code class="reqn">E(A_i) = 0</code>, <code class="reqn">Var(A_i) = 1</code> and <code class="reqn">Cov(A_i, A_j) = k\left(\frac{i - j}{l}\right), i = 1, ..., n; j \neq i</code>. Via <code>control$seed</code> a seed can optionally be specified (cf. <code><a href="base.html#topic+set.seed">set.seed</a></code>). Only <code>"bartlett"</code>, <code>"parzen"</code> and <code>"QS"</code> are supported as kernel functions. Uses the function <code><a href="pracma.html#topic+sqrtm">sqrtm</a></code> from package <code>pracma</code>.
</p>
<p>Default values: <code>B</code> = 1000, <code>kFun = "bartlett"</code>, <code>l</code> is the same as for subsampling.
</p>


<h3>Value</h3>

<p>long run variance <code class="reqn">\sigma^2</code> (numeric) resp. <code class="reqn">\Sigma</code> (numeric matrix)
</p>


<h3>Note</h3>

<p>Kernel functions
</p>
<p><code>bartlett</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) = (1 - |x|) * 1_{\{|x| &lt; 1\}}</code>
</p>

<p><code>FT</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) = 1 * 1_{\{|x| \leq 0.5\}} + (2 - 2 * |x|) * 1_{\{0.5 &lt; |x| &lt; 1\}}</code>
</p>

<p><code>parzen</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) = (1 - 6x^2 + 6|x|^3) * 1_{\{0 \leq |x| \leq 0.5\}} + 2(1 - |x|)^3 * 1_{\{0.5 &lt; |x| \leq 1\}}</code>
</p>

<p><code>QS</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) = \frac{25}{12 \pi ^2 x^2} \left(\frac{\sin(6\pi x / 5)}{6\pi x / 5} - \cos(6 \pi x / 5)\right)</code>
</p>

<p><code>TH</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) = (1 + \cos(\pi  x)) / 2 * 1_{\{|x| &lt; 1\}}</code>
</p>

<p><code>truncated</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) = 1_{\{|x| &lt; 1\}}</code>
</p>

<p><code>SFT</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) = (1 - 4(|x| - 0.5)^2)^2 * 1_{\{|x| &lt; 1\}}</code>
</p>

<p><code>Epanechnikov</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) =  3 \frac{1 - x^2}{4} * 1_{\{|x| &lt; 1\}}</code>
</p>

<p><code>quatratic</code>:
</p>
<p style="text-align: center;"><code class="reqn">k(x) = (1 - x^2)^2 * 1_{\{|x| &lt; 1\}}</code>
</p>



<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Andrews, D.W. &quot;Heteroskedasticity and autocorrelation consistent covariance matrix estimation.&quot; Econometrica: Journal of the Econometric Society (1991): 817-858.
</p>
<p>Dehling, H., et al. &quot;Change-point detection under dependence based on two-sample U-statistics.&quot; Asymptotic laws and methods in stochastics. Springer, New York, NY, (2015). 195-220.
</p>
<p>Dehling, H., Fried, R., and Wendler, M. &quot;A robust method for shift detection in time series.&quot; Biometrika 107.3 (2020): 647-660.
</p>
<p>Parzen, E. &quot;On consistent estimates of the spectrum of a stationary time series.&quot; The Annals of Mathematical Statistics (1957): 329-348.
</p>
<p>Shao, X. &quot;The dependent wild bootstrap.&quot; Journal of the American Statistical Association 105.489 (2010): 218-235.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CUSUM">CUSUM</a></code>, <code><a href="#topic+HodgesLehmann">HodgesLehmann</a></code>, <code><a href="#topic+wilcox_stat">wilcox_stat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Z &lt;- c(rnorm(20), rnorm(20, 2))

## kernel density estimation
lrv(Z)

## overlapping subsampling
lrv(Z, method = "subsampling", control = list(overlapping = FALSE, distr = TRUE, l = 5))

## dependent wild bootstrap
lrv(Z, method = "bootstrap", control = list(B = 2000, l = 4, kFun = "parzen"))
</code></pre>

<hr>
<h2 id='medianDiff'>Median of the set X - Y</h2><span id='topic+medianDiff'></span>

<h3>Description</h3>

<p>Computes the median of the set X - Y. X - Y denotes the set <code class="reqn">\{x - y | x \in X, y \in Y</code>}.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medianDiff(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="medianDiff_+3A_x">x</code>, <code id="medianDiff_+3A_y">y</code></td>
<td>
<p>Numeric vectors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Special case of the function <code><a href="#topic+kthPair">kthPair</a></code>.
</p>


<h3>Value</h3>

<p>The median element of X - Y
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Johnson, D. B., &amp; Mizoguchi, T. (1978). Selecting the K-th Element in X+Y and X_1+X_2+ ... +X_m. SIAM Journal on Computing, 7(2), 147-153.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
y &lt;- runif(100)
medianDiff(x, y)
</code></pre>

<hr>
<h2 id='modifChol'>
Revised Modified Cholesky Factorization
</h2><span id='topic+modifChol'></span>

<h3>Description</h3>

<p>Computes the revised modified Cholesky factorization described in Schnabel and Eskow (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modifChol(x, tau = .Machine$double.eps^(1 / 3), 
           tau_bar = .Machine$double.eps^(2 / 3), mu = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modifChol_+3A_x">x</code></td>
<td>
<p>a symmetric matrix.</p>
</td></tr>
<tr><td><code id="modifChol_+3A_tau">tau</code></td>
<td>
<p>(machine epsilon)^(1/3).</p>
</td></tr>
<tr><td><code id="modifChol_+3A_tau_bar">tau_bar</code></td>
<td>
<p>(machine epsilon^(2/3)).</p>
</td></tr>
<tr><td><code id="modifChol_+3A_mu">mu</code></td>
<td>
<p>numeric, <code class="reqn">0 &lt; \mu \le 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>modif.chol</code> computes the revised modified Cholesky Factorization of a symmetric, not necessarily positive definite matrix x + E such that <code class="reqn">L'L = x + E</code> for <code class="reqn">E \ge 0</code>.
</p>


<h3>Value</h3>

<p>Upper triangular matrix <code class="reqn">L</code> of the form <code class="reqn">L'L = x + E</code>.
The attribute <code>swaps</code> is a vector of the length of dimension of x. It contains the indices of the rows and columns that were swapped in x in order to compute the modified Cholesky factorization. For example if the <code>i</code>-th element of <code>swaps</code> is the number <code>j</code>, then the <code>i</code>-th and the <code>j</code>-th row and column were swapped. To reconstruct the original matrix swaps has to be read backwards.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Schnabel, R. B., &amp; Eskow, E. (1999). &quot;A revised modified Cholesky factorization algorithm&quot; SIAM Journal on optimization, 9(4), 1135-1148.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- matrix(runif(9), ncol = 3)
x &lt;- psi(y)
modifChol(lrv(x))
</code></pre>

<hr>
<h2 id='pKSdist'>
Asymptotic cumulative distribution for the CUSUM Test statistic
</h2><span id='topic+pKSdist'></span><span id='topic+pBessel'></span>

<h3>Description</h3>

<p>Computes the asymptotic cumulative distribution of the statistic of <code><a href="#topic+CUSUM">CUSUM</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pKSdist(tn, tol = 1e-8)
pBessel(tn, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pKSdist_+3A_tn">tn</code></td>
<td>
<p>vector of test statistics (numeric). For <code>pBessel</code> length of <code>tn</code> has to be 1.</p>
</td></tr>
<tr><td><code id="pKSdist_+3A_p">p</code></td>
<td>
<p>dimension of time series (integer). If <code>p</code> is equal to 1 <code>pBessel</code> uses <code>pKSdist</code> to compute the corresponding probability.</p>
</td></tr>
<tr><td><code id="pKSdist_+3A_tol">tol</code></td>
<td>
<p>tolerance (numeric).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a single time series, the distribution is the same distribution as in the two sample Kolmogorov Smirnov Test, namely the distribution of the maximal value of the absolute values of a Brownian bridge. It is computated as follows (Durbin, 1973 and van Mulbregt, 2018):
</p>
<p>For <code class="reqn">t_n(x) &lt; 1</code>:
</p>
<p style="text-align: center;"><code class="reqn">
P(t_n(X) \le t_n(x)) = 
\frac{\sqrt{2 \pi}}{t_n(x)} t (1 + t^8(1 + t^{16}(1 + t^{24}(1 + ...))))</code>
</p>

<p>up to <code class="reqn">t^{8 k_{max}},
k_{max} = \lfloor \sqrt{2 - \log(tol)}\rfloor</code>, where <code class="reqn">t = \exp(-\pi^2 / (8x^2))</code>
</p>
<p>else:
</p>
<p style="text-align: center;"><code class="reqn">
P(t_n(X) \le t_n(x)) = 2  \sum_{k = 1}^{\infty} (-1)^{k - 1} \exp(-2 k^2 x^2)</code>
</p>

<p>until
<code class="reqn">|2 (-1)^{k - 1} \exp(-2 k^2 x^2) - 2 (-1)^{(k-1) - 1}  \exp(-2 (k-1)^2 x^2)| \le tol.
</code>
</p>
<p>In case of multiple time series, the distribution equals that of the maximum of an <code>p</code> dimensional squared Bessel bridge. It can be computed by (Kiefer, 1959)
</p>
<p style="text-align: center;"><code class="reqn">P(t_n(X) \le t_n(x)) = 
\frac{4}{ \Gamma(p / 2) 2^{p / 2} t_n^p }  \sum_{i = 1}^{\infty}  \frac{(\gamma_{(p - 2)/2, n})^{p - 2} \exp(-(\gamma_{(p - 2)/2, n})^2 / (2t_n^2))}{J_{p/2}(\gamma_{(p - 2)/2, n})^2 },</code>
</p>

<p>where <code class="reqn">J_p</code> is the Bessel function of first kind and p-th order, <code class="reqn">\Gamma</code> is the gamma function and <code class="reqn">\gamma_{p, n}</code> denotes the n-th zero of <code class="reqn">J_p</code>.
</p>


<h3>Value</h3>

<p>vector of <code class="reqn">P(t_n(X) \le tn[i])</code>.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz, Alexander Dürre
</p>


<h3>References</h3>

<p>Durbin, James. (1973) &quot;Distribution theory for tests based on the sample distribution function.&quot; <em>Society for Industrial and Applied Mathematics</em>.
</p>
<p>van Mulbregt, P. (2018) &quot;Computing the Cumulative Distribution Function and Quantiles of the limit of the Two-sided Kolmogorov-Smirnov Statistic.&quot; arXiv preprint arXiv:1803.00426.
</p>
<p>/src/library/stats/src/ks.c rev60573
</p>
<p>Kiefer, J. (1959). &quot;K-sample analogues of the Kolmogorov-Smirnov and Cramer-V. Mises tests&quot;, <em>The Annals of Mathematical Statistics</em>, 420&ndash;447.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psi">psi</a></code>, <code><a href="#topic+CUSUM">CUSUM</a></code>, <code><a href="#topic+psi_cumsum">psi_cumsum</a></code>, <code><a href="#topic+huber_cusum">huber_cusum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># single time series
timeSeries &lt;- c(rnorm(20, 0), rnorm(20, 2))
tn &lt;- CUSUM(timeSeries)

pKSdist(tn)

# two time series
timeSeries &lt;- matrix(c(rnorm(20, 0), rnorm(20, 2), rnorm(20, 1), rnorm(20, 3)), 
                     ncol = 2)
tn &lt;- CUSUM(timeSeries)

pBessel(tn, 2)

</code></pre>

<hr>
<h2 id='plot.cpStat'>Plot method for change point statistics</h2><span id='topic+plot.cpStat'></span>

<h3>Description</h3>

<p>Plots the trajectory of the test statistic process together with a red line indicating 
the critical value (alpha = 0.05) and a blue line indicating the most
probable change point location
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cpStat'
plot(x, ylim, xaxt, crit.val, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cpStat_+3A_x">x</code></td>
<td>
<p>object of the class 'cpStat'.</p>
</td></tr>
<tr><td><code id="plot.cpStat_+3A_ylim">ylim</code></td>
<td>
<p>the y limits of the plot.</p>
</td></tr>
<tr><td><code id="plot.cpStat_+3A_xaxt">xaxt</code></td>
<td>
<p>a character which specifies the x axis type (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="plot.cpStat_+3A_crit.val">crit.val</code></td>
<td>
<p>critical value of the test. Default: 1.358.</p>
</td></tr>
<tr><td><code id="plot.cpStat_+3A_...">...</code></td>
<td>
<p>other graphical parameters (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> Default for <code>ylim</code> is <code>c(min(c(data, 1.358)), max(c(data, 1.358)))</code>.
</p>
</li>
<li><p> Default for <code>xaxt</code> is the simliar to the option <code>"s"</code>, only that there 
is a red labelled tick at the most probable change point location. Ticks too 
close to this will be suppressed.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="graphics.html#topic+par">par</a></code>, <code><a href="#topic+CUSUM">CUSUM</a></code>, <code><a href="#topic+HodgesLehmann">HodgesLehmann</a></code>, 
<code><a href="#topic+wilcox_stat">wilcox_stat</a></code>
</p>

<hr>
<h2 id='print.cpStat'>Print method for change point statistics</h2><span id='topic+print.cpStat'></span>

<h3>Description</h3>

<p>Prints the value of the test statistic and add the most likely change point location.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cpStat'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cpStat_+3A_x">x</code></td>
<td>
<p>object of the class 'cpStat'.</p>
</td></tr>
<tr><td><code id="print.cpStat_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+print">print</a></code>, <code><a href="#topic+wilcox_stat">wilcox_stat</a></code>, <code><a href="#topic+CUSUM">CUSUM</a></code>, <code><a href="#topic+HodgesLehmann">HodgesLehmann</a></code>,
</p>

<hr>
<h2 id='psi'>
Transformation of time series
</h2><span id='topic+psi'></span>

<h3>Description</h3>

<p>Standardizes (multivariate) time series by their median, MAD and transforms the standardized time series by a <code class="reqn">\psi</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psi(y, fun = c("HLm", "HLg", "SLm", "SLg", "HCm", "HCg", "SCm", "SCg"), k, 
    constant = 1.4826)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psi_+3A_y">y</code></td>
<td>
<p>vector or matrix with each column representing a time series (numeric).</p>
</td></tr>
<tr><td><code id="psi_+3A_fun">fun</code></td>
<td>
<p>character string specifying the transformation function <code class="reqn">\psi</code> (more in Details).</p>
</td></tr>
<tr><td><code id="psi_+3A_k">k</code></td>
<td>
<p>numeric bound used for Huber type psi-functions which determines robustness and efficiency of the test. Default for <code>psi = "HLg"</code> or <code>"HCg"</code> is <code>sqrt(qchisq(0.8, df = m)</code> where <code>m</code> are the number of time series, and otherwise it is 1.5.</p>
</td></tr>
<tr><td><code id="psi_+3A_constant">constant</code></td>
<td>
<p>scale factor of the MAD.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">x = \frac{y - med(y)}{MAD(y)}</code> be the standardized values of a univariate time series.
</p>
<p>Available <code class="reqn">\psi</code> functions are: <br />
</p>
<p>marginal Huber for location: <br />
<code>fun = "HLm"</code>. <br />
<code class="reqn">\psi_{HLm}(x) = k * 1_{\{x &gt; k\}} + x * 1_{\{-k \le x \le k\}} - k * 1_{\{x &lt; -k\}}</code>. <br />
</p>
<p>global Huber for location: <br />
<code>fun = "HLg"</code>. <br />
<code class="reqn">\psi_{HLg}(x) = x * 1_{\{0 &lt; |x| \le k\}} + \frac{k x}{|x|} * 1_{\{|x| &gt; k\}}</code>. <br />
</p>
<p>marginal sign for location: <br />
<code>fun = "SLm"</code>. <br />
<code class="reqn">\psi_{SLm}(x_i) = sign(x_i)</code>. <br />
</p>
<p>global sign for location: <br />
<code>fun = "SLg"</code>. <br />
<code class="reqn">\psi_{SLg}(x) = x / |x| * 1_{\{|x| &gt; 0\}}</code>. <br />
</p>
<p>marginal Huber for covariance: <br />
<code>fun = "HCm"</code>. <br />
<code class="reqn">\psi_{HCm}(x) = \psi_{HLm}(x) \psi_{HLm}(x)^T</code>. <br />
</p>
<p>global Huber for covariance: <br />
<code>fun = "HCg"</code>. <br />
<code class="reqn">\psi_{HCg}(x) = \psi_{HLg}(x) \psi_{HLg}(x)^T</code>. <br />
</p>
<p>marginal sign covariance: <br />
<code>fun = "SCm"</code>. <br />
<code class="reqn">\psi_{SCm}(x) = \psi_{SLm}(x) \psi_{SLm}(x)^T</code>. <br />
</p>
<p>gloabl sign covariance: <br />
<code>fun = "SCg"</code>. <br />
<code class="reqn">\psi_{SCg}(x) = \psi_{SCg}(x) \psi_{SCg}(x)^T</code>. <br />
</p>
<p>Note that for all covariances only the upper diagonal is used and turned into a vector. In case of the marginal sign covariance, the main diagonal is also left out. For the global sign covariance matrix the last element of the main diagonal is left out.
</p>


<h3>Value</h3>

<p>Transformed numeric vector or matrix with the same number of rows as <code>y</code>.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psi_cumsum">psi_cumsum</a></code>, 
<code><a href="#topic+CUSUM">CUSUM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>psi(rnorm(100))
</code></pre>

<hr>
<h2 id='psi_cumsum'>
Cumulative sum of transformed vectors
</h2><span id='topic+psi_cumsum'></span>

<h3>Description</h3>

<p>Computes the cumulative sum of a transformed numeric vector or matrix. Transformation function is <code><a href="#topic+psi">psi</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psi_cumsum(y, fun = "HLm", k, constant)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psi_cumsum_+3A_y">y</code></td>
<td>
<p>numeric vector containing a single time series or a numeric matrix containing multiple time series (column-wise).</p>
</td></tr>
<tr><td><code id="psi_cumsum_+3A_fun">fun</code></td>
<td>
<p>character string specifying the transformation function <code class="reqn">\psi</code>.</p>
</td></tr>
<tr><td><code id="psi_cumsum_+3A_k">k</code></td>
<td>
<p>numeric bound used in <code><a href="#topic+psi">psi</a></code>.</p>
</td></tr>
<tr><td><code id="psi_cumsum_+3A_constant">constant</code></td>
<td>
<p>scale factor of the MAD. Default is 1.4826.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prior to computing the sums, y is being transformed by the function <code>fun</code>.
</p>


<h3>Value</h3>

<p>Numeric vector or matrix containing the cumulative sums of the transformed values. In case of a matrix, cumulative sums are being computed for each time series (column) independently.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psi">psi</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>psi_cumsum(rnorm(100))
</code></pre>

<hr>
<h2 id='Qalpha'><code class="reqn">Q^{\alpha}</code></h2><span id='topic+Qalpha'></span>

<h3>Description</h3>

<p>Estimates Q-alpha using the first <code class="reqn">k</code> elements of a time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Qalpha(x, alpha = 0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Qalpha_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="Qalpha_+3A_alpha">alpha</code></td>
<td>
<p>quantile. Numeric value in (0, 1]</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">\hat{Q}^{\alpha}_{1:k} = U_{1:k}^{-1}(\alpha) = \inf\{x | \alpha \leq U_{1:k}(x)\},</code>
</p>

<p>where <code class="reqn">U_{1:k}</code> is the empirical distribtion function of <code class="reqn">|x_i - x_j|, \, 1 \leq i &lt; j \leq k</code>. 
</p>


<h3>Value</h3>

<p>Numeric vector of <code class="reqn">Q^{\alpha}</code>-s estimated using <code>x[1], ..., x[k]</code>, <code class="reqn">k = 1, ..., n</code>, <code class="reqn">n</code> being the length of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(10)
Qalpha(x, 0.5)
</code></pre>

<hr>
<h2 id='scale_cusum'>Tests for Scale Changes Based on Pairwise Differences</h2><span id='topic+scale_cusum'></span>

<h3>Description</h3>

<p>Performs the CUSUM-based test on changes in the scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scale_cusum(x, version =  c("empVar", "MD", "GMD", "Qalpha"), method = "kernel",
            control = list(), alpha = 0.8, fpc = TRUE, tol,
            plot = FALSE, level = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scale_cusum_+3A_x">x</code></td>
<td>
<p>time series (numeric or ts vector).</p>
</td></tr>
<tr><td><code id="scale_cusum_+3A_version">version</code></td>
<td>
<p>variance estimation method (see <code><a href="#topic+scale_stat">scale_stat</a></code>).</p>
</td></tr>
<tr><td><code id="scale_cusum_+3A_method">method</code></td>
<td>
<p>method for estimating the long run variance.</p>
</td></tr>
<tr><td><code id="scale_cusum_+3A_control">control</code></td>
<td>
<p>a list of control parameters.</p>
</td></tr>
<tr><td><code id="scale_cusum_+3A_alpha">alpha</code></td>
<td>
<p>quantile of the distribution function of all absolute pairwise differences used in <code>version = "Qalpha"</code>.</p>
</td></tr>
<tr><td><code id="scale_cusum_+3A_fpc">fpc</code></td>
<td>
<p>finite population correction (boolean).</p>
</td></tr>
<tr><td><code id="scale_cusum_+3A_tol">tol</code></td>
<td>
<p>tolerance for the computation of the p-value (numeric). Default for kernel-based long run variance estimation: 1e-8. Default for bootstrap: 1e-3.</p>
</td></tr>
<tr><td><code id="scale_cusum_+3A_plot">plot</code></td>
<td>
<p>should the test statistic be plotted (cf. <code><a href="#topic+plot.cpStat">plot.cpStat</a></code>)? Boolean.</p>
</td></tr>
<tr><td><code id="scale_cusum_+3A_level">level</code></td>
<td>
<p>significance level of the test (numeric between 0 and 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs a CUSUM-type test on changes in the scale. Formally, the hypothesis pair is
</p>
<p style="text-align: center;"><code class="reqn">H_0: \sigma^2_2 = ... = \sigma_n^2</code>
</p>

<p style="text-align: center;"><code class="reqn">vs.</code>
</p>

<p style="text-align: center;"><code class="reqn">H_1: \exists k \in \{2, ..., n-1\}: \sigma^2_k \neq \sigma^2_{k+1}</code>
</p>

<p>where <code class="reqn">\sigma^2_t = Var(X_t)</code> and <code class="reqn">n</code> is the length of the time series. <code class="reqn">k</code> is called a 'change point'. The hypotheses do not include <code class="reqn">\sigma^2_1</code> since then the variance of one single observation would need to be estimated. 
</p>
<p>The test statistic is computed using <code><a href="#topic+scale_stat">scale_stat</a></code> and in the case of <code>method = "kernel"</code> asymptotically follows a Kolmogorov distribution. To derive the p-value, the function <code><a href="#topic+pKSdist">pKSdist</a></code> is used.
</p>
<p>If <code>method = "bootstrap"</code>, a dependent block bootstrap with parameters <code class="reqn">B = 1/</code><code>tol</code> and <code class="reqn">l =</code> <code>control$l</code> is performed in order to derive the p-value of the test. First, select a boostrap sample <code class="reqn">x_1^*, ..., x_{kl}^*</code>, <code class="reqn">k = \lfloor n/l \rfloor</code>, the following way: Uniformly draw a random iid sample <code class="reqn">J_1, ..., J_k</code> from <code class="reqn">\{1, ..., n-l+1\}</code> and concatenate the blocks <code class="reqn">x_{J_i}, ..., x_{J_i + l-1}</code> for <code class="reqn">i = 1, ..., k</code>. Then apply the test statistic <code class="reqn">\hat{T}_s</code> to the bootstrap sample. Repeat the procedure <code class="reqn">B</code> times. The p-value is can be obtained as the proportion of the bootstrapped test statistics which is larger than the test statistic on the full sample.
</p>


<h3>Value</h3>

<p>A list of the class &quot;htest&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>return value of the function <code><a href="#topic+scale_stat">scale_stat</a></code>.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value (numeric).</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis (character string).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>name of the performed test (character string).</p>
</td></tr>
<tr><td><code>cp.location</code></td>
<td>
<p>index of the estimated change point location (integer).</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data (character string).</p>
</td></tr>
</table>
<p>Plus if <code>method = "kernel"</code>:
</p>
<table>
<tr><td><code>lrv</code></td>
<td>
<p>list containing the compontents <code>method</code>, <code>param</code> and <code>value</code>.</p>
</td></tr>
</table>
<p>else if <code>method = "bootstrap"</code>:
</p>
<table>
<tr><td><code>bootstrap</code></td>
<td>
<p>list containing the compontents <code>param</code> (= block length) and <code>crit.value</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Gerstenberger, C., Vogel, D., and Wendler, M. (2020). Tests for scale changes based on pairwise differences. Journal of the American Statistical Association, 115(531), 1336-1348.
</p>
<p>Dürre, A. (2022+). &quot;Finite sample correction for cusum tests&quot;, <em>unpublished manuscript</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scale_stat">scale_stat</a></code>, <code><a href="#topic+lrv">lrv</a></code>, <code><a href="#topic+pKSdist">pKSdist</a></code>, <code><a href="#topic+Qalpha">Qalpha</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- arima.sim(list(ar = 0.5), 100)

# under H_0:
scale_cusum(x)
scale_cusum(x, "MD")

# under the alternative:
x[51:100] &lt;- x[51:100] * 3
scale_cusum(x)
scale_cusum(x, "MD")
</code></pre>

<hr>
<h2 id='scale_stat'>Test statistic to detect Scale Changes</h2><span id='topic+scale_stat'></span>

<h3>Description</h3>

<p>Computes the test statistic for CUSUM-based tests on scale changes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scale_stat(x, version =  c("empVar", "MD", "GMD", "Qalpha"), method = "kernel",
           control = list(), alpha = 0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scale_stat_+3A_x">x</code></td>
<td>
<p>time series (numeric or ts vector).</p>
</td></tr>
<tr><td><code id="scale_stat_+3A_version">version</code></td>
<td>
<p>variance estimation method.</p>
</td></tr>
<tr><td><code id="scale_stat_+3A_method">method</code></td>
<td>
<p>either <code>"kernel"</code> for performing a kernel-based long run variance estimation, or <code>"bootstrap"</code> for performing a dependent wild bootstrap. See 'Details' below.</p>
</td></tr>
<tr><td><code id="scale_stat_+3A_control">control</code></td>
<td>
<p>a list of control parameters.</p>
</td></tr>
<tr><td><code id="scale_stat_+3A_alpha">alpha</code></td>
<td>
<p>quantile of the distribution function of all absolute pairwise differences used in <code>version = "Qalpha"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">n</code> be the length of the time series. The CUSUM test statistic for testing on a change in the scale is then defined as
</p>
<p style="text-align: center;"><code class="reqn">\hat{T}_{s} = \max_{1 &lt; k \leq n} \frac{k}{\sqrt{n}} |\hat{s}_{1:k} - \hat{s}_{1:n}|,</code>
</p>

<p>where <code class="reqn">\hat{s}_{1:k}</code> is a scale estimator computed using only the first <code class="reqn">k</code> elements of the time series <code class="reqn">x</code>.
</p>
<p>If <code>method = "kernel"</code>, the test statistic <code class="reqn">\hat{T}_s</code> is divided by the estimated long run variance <code class="reqn">\hat{D}_s</code> so that it asymptotically follows a Kolmogorov distribution. <code class="reqn">\hat{D}_s</code> is computed by the function <code><a href="#topic+lrv">lrv</a></code> using kernel-based estimation. 
</p>
<p>For the scale estimator <code class="reqn">\hat{s}_{1:k}</code>, there are five different options which can be set via the <code>version</code> parameter:
</p>
<p><b>Empirical variance</b> (<code>empVar</code>)
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2_{1:k} = \frac{1}{k-1} \sum_{i = 1}^k (x_i - \bar{x}_{1:k})^2; \; \bar{x}_{1:k} = k^{-1} \sum_{i = 1}^k x_i.</code>
</p>

<p><b>Mean deviation</b> (<code>MD</code>)
</p>
<p style="text-align: center;"><code class="reqn">\hat{d}_{1:k}= \frac{1}{k-1} \sum_{i = 1}^k |x_i - med_{1:k}|,</code>
</p>

<p>where <code class="reqn">med_{1:k}</code> is the median of <code class="reqn">x_1, ..., x_k</code>. 
</p>
<p><b>Gini's mean difference</b> (<code>GMD</code>)
</p>
<p style="text-align: center;"><code class="reqn">\hat{g}_{1:k} = \frac{2}{k(k-1)} \sum_{1 \leq i &lt; j \leq k} (x_i - x_j).</code>
</p>



<p><b><code class="reqn">Q^{\alpha}</code></b> (<code>Qalpha</code>)
</p>
<p style="text-align: center;"><code class="reqn">\hat{Q}^{\alpha}_{1:k} = U_{1:k}^{-1}(\alpha) = \inf\{x | \alpha \leq U_{1:k}(x)\},</code>
</p>

<p>where <code class="reqn">U_{1:k}</code> is the empirical distribtion function of <code class="reqn">|x_i - x_j|, \, 1 \leq i &lt; j \leq k</code> (cf. <code><a href="#topic+Qalpha">Qalpha</a></code>). 
</p>
<p>For the kernel-based long run variance estimation, the default bandwidth <code class="reqn">b_n</code> is determined as follows:
</p>
<p>If <code class="reqn">\hat{\rho}_j</code> is the estimated autocorrelation to lag <code class="reqn">j</code>, a maximal lag <code class="reqn">l</code> is selected to be the smallest integer <code class="reqn">k</code> so that 
</p>
<p style="text-align: center;"><code class="reqn">\max \{|\hat{\rho}_k|, ..., |\hat{\rho}_{k + \kappa_n}|\} \leq 2 \sqrt(\log_{10}(n) / n), </code>
</p>

<p><code class="reqn">\kappa_n = \max \{5, \sqrt{\log_{10}(n)}\}</code>. This <code class="reqn">l</code> is determined for both the original data <code class="reqn">x</code> and the squared data <code class="reqn">x^2</code> and the maximum <code class="reqn">l_{max}</code> is taken. Then the bandwidth <code class="reqn">b_n</code> is the minimum of <code class="reqn">l_{max}</code> and <code class="reqn">n^{1/3}</code>.
</p>


<h3>Value</h3>

<p>Test statistic (numeric value) with the following attributes:
</p>
<table>
<tr><td><code>cp-location</code></td>
<td>
<p>indicating at which index a change point is most likely.</p>
</td></tr>
<tr><td><code>teststat</code></td>
<td>
<p>test process (before taking the maximum).</p>
</td></tr>
<tr><td><code>lrv-estimation</code></td>
<td>
<p>long run variance estimation method.</p>
</td></tr>
</table>
<p>If <code>method = "kernel"</code> the following attributes are also included:
</p>
<table>
<tr><td><code>sigma</code></td>
<td>
<p>estimated long run variance.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>parameter used for the lrv estimation.</p>
</td></tr>
<tr><td><code>kFun</code></td>
<td>
<p>kernel function used for the lrv estimation.</p>
</td></tr>
</table>
<p>Is an S3 object of the class &quot;cpStat&quot;.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Gerstenberger, C., Vogel, D., and Wendler, M. (2020). Tests for scale changes based on pairwise differences. Journal of the American Statistical Association, 115(531), 1336-1348.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lrv">lrv</a></code>, <code><a href="#topic+Qalpha">Qalpha</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- arima.sim(list(ar = 0.5), 100)

# under H_0:
scale_stat(x, "GMD")
scale_stat(x, "Qalpha", method = "bootstrap")

# under the alternative:
x[51:100] &lt;- x[51:100] * 3
scale_stat(x)
scale_stat(x, "Qalpha", method = "bootstrap")
</code></pre>

<hr>
<h2 id='weightedMedian'>Weighted Median</h2><span id='topic+weightedMedian'></span>

<h3>Description</h3>

<p>Computes the weighted median of a numeric vector.</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedMedian(x, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedMedian_+3A_x">x</code></td>
<td>
<p>Numeric vector.</p>
</td></tr>
<tr><td><code id="weightedMedian_+3A_w">w</code></td>
<td>
<p>Integer vector of weights.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Here, the median of an even length <code class="reqn">n</code> of <code class="reqn">x</code> is defined as <code class="reqn">x_{(n/2 + 1)}</code> if <code class="reqn">x_{(i)}</code> is the <code class="reqn">i</code>-th largest element in <code class="reqn">x</code>, i.e. the larger value is taken.
</p>


<h3>Value</h3>

<p>Weighted median of x with respect to w.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1, 4, 9)
w &lt;- c(5, 1, 1)
weightedMedian(x, w)
</code></pre>

<hr>
<h2 id='wilcox_stat'>Wilcoxon-Mann-Whitney Test Statistic for Change Points</h2><span id='topic+wilcox_stat'></span>

<h3>Description</h3>

<p>Computes the test statistic for the Wilcoxon-Mann-Whitney change point test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wilcox_stat(x, h = 1L, method = "kernel", control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wilcox_stat_+3A_x">x</code></td>
<td>
<p>Time series (numeric or ts vector).</p>
</td></tr>
<tr><td><code id="wilcox_stat_+3A_h">h</code></td>
<td>
<p>Kernel function of the U statistic (1L or 2L, or a function with two parameters).</p>
</td></tr>
<tr><td><code id="wilcox_stat_+3A_method">method</code></td>
<td>
<p>Method for estimating the long run variance. Options are <code>"kernel"</code>, <code>"subsampling"</code>, <code>"bootstrap"</code> and <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="wilcox_stat_+3A_control">control</code></td>
<td>
<p>A list of control parameters for the estimation of the long run variance (cf. <code><a href="#topic+lrv">lrv</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let n be the length of <code>x</code>, i.e. the number of observations.
</p>
<p><code>h = 1L</code>:
</p>
<p style="text-align: center;"><code class="reqn">T_n = \frac{1}{\hat{\sigma}} \max_{1 \leq k \leq n} \left| \frac{1}{n^{3/2}} \sum_{i = 1}^k \sum_{j = k+1}^n (1_{\{x_i &lt; x_j\}} - 0.5) \right|</code>
</p>

<p><code>h = 2L</code>:
</p>
<p style="text-align: center;"><code class="reqn">T_n = \frac{1}{\hat{\sigma}} \max_{1 \leq k \leq n} \left| \frac{1}{n^{3/2}} \sum_{i = 1}^k \sum_{j = k+1}^n (x_i - x_j) \right|</code>
</p>

<p><code class="reqn">\hat{\sigma}</code> is estimated by the square root of <code><a href="#topic+lrv">lrv</a></code>. The denominator corresponds to that in the ordinary CUSUM change point test. 
</p>
<p>By default, kernel-based estimation is used. 
</p>
<p>If <code>h = 1L</code>, the default for <code>distr</code> is <code>TRUE</code>. If no block length is supplied, first the time series <code class="reqn">x</code> is corrected for the estimated change point and Spearman's autocorrelation to lag 1 (<code class="reqn">\rho</code>) is computed. Then the default bandwidth follows as
</p>
<p style="text-align: center;"><code class="reqn">b_n = \max\left\{\left\lceil n^{0.25} \left( \frac{2\rho}{1 - \rho^2}\right)^{0.8} \right\rceil, 1\right\}.</code>
</p>

<p>Otherwise, the default for <code>distr</code> is <code>FALSE</code> and the default bandwidth is
</p>
<p style="text-align: center;"><code class="reqn">b_n = \max\left\{\left\lceil n^{0.4} \left( \frac{2\rho}{1 - \rho^2}\right)^{1/3} \right\rceil, 1\right\}.</code>
</p>



<h3>Value</h3>

<p>Test statistic (numeric value) with the following attributes:
</p>
<table>
<tr><td><code>cp-location</code></td>
<td>
<p>indicating at which index a change point is most likely.</p>
</td></tr>
<tr><td><code>teststat</code></td>
<td>
<p>test process (before taking the maximum).</p>
</td></tr>
<tr><td><code>lrv-estimation</code></td>
<td>
<p>long run variance estimation method.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated long run variance.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>parameter used for the lrv estimation.</p>
</td></tr>
<tr><td><code>kFun</code></td>
<td>
<p>kernel function used for the lrv estimation.</p>
</td></tr>
</table>
<p>Is an S3 object of the class &quot;cpStat&quot;.
</p>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Dehling, H., et al. &quot;Change-point detection under dependence based on two-sample U-statistics.&quot; Asymptotic laws and methods in stochastics. Springer, New York, NY, 2015. 195-220.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lrv">lrv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># time series with a location change at t = 20
x &lt;- c(rnorm(20, 0), rnorm(20, 2))

# Wilcoxon-Mann-Whitney change point test statistic
wilcox_stat(x, h = 1L, control = list(b_n = length(x)^(1/3)))
</code></pre>

<hr>
<h2 id='wmw_test'>Wilocxon-Mann-Whitney Test for Change Points</h2><span id='topic+wmw_test'></span>

<h3>Description</h3>

<p>Performs the Wilcoxon-Mann-Whitney change point test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wmw_test(x, h = 1L, method = "kernel", control = list(), tol = 1e-8, 
         plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wmw_test_+3A_x">x</code></td>
<td>
<p>time series (numeric or ts vector).</p>
</td></tr>
<tr><td><code id="wmw_test_+3A_h">h</code></td>
<td>
<p>version of the test (integer, 1L or 2L)</p>
</td></tr>
<tr><td><code id="wmw_test_+3A_method">method</code></td>
<td>
<p>method for estimating the long run variance.</p>
</td></tr>
<tr><td><code id="wmw_test_+3A_control">control</code></td>
<td>
<p>a list of control parameters (cf. <code><a href="#topic+lrv">lrv</a></code>).</p>
</td></tr>
<tr><td><code id="wmw_test_+3A_tol">tol</code></td>
<td>
<p>tolerance of the distribution function (numeric), which is used to compute p-values.</p>
</td></tr>
<tr><td><code id="wmw_test_+3A_plot">plot</code></td>
<td>
<p>should the test statistic be plotted (cf. <code><a href="#topic+plot.cpStat">plot.cpStat</a></code>). Boolean.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs a Wilcoxon-Mann-Whitney change point test. It tests the hypothesis pair
</p>
<p style="text-align: center;"><code class="reqn">H_0: \mu_1 = ... = \mu_n</code>
</p>

<p style="text-align: center;"><code class="reqn">vs.</code>
</p>

<p style="text-align: center;"><code class="reqn">H_1: \exists k \in \{1, ..., n-1\}: \mu_k \neq \mu_{k+1}</code>
</p>

<p>where <code class="reqn">\mu_t = E(X_t)</code> and <code class="reqn">n</code> is the length of the time series. <code class="reqn">k</code> is called a 'change point'. 
</p>
<p>The test statistic is computed using <code><a href="#topic+wilcox_stat">wilcox_stat</a></code> and asymptotically follows a Kolmogorov distribution. To derive the p-value, the function <code><a href="#topic+pKSdist">pKSdist</a></code> is used. 
</p>


<h3>Value</h3>

<p>A list of the class &quot;htest&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>value of the test statistic (numeric).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value (numeric).</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis (character string).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>name of the performed test (character string).</p>
</td></tr>
<tr><td><code>cp.location</code></td>
<td>
<p>index of the estimated change point location (integer).</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data (character string).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sheila Görz
</p>


<h3>References</h3>

<p>Dehling, H., et al. &quot;Change-point detection under dependence based on two-sample U-statistics.&quot; Asymptotic laws and methods in stochastics. Springer, New York, NY, 2015. 195-220.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wilcox_stat">wilcox_stat</a></code>, <code><a href="#topic+lrv">lrv</a></code>, <code><a href="#topic+pKSdist">pKSdist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#time series with a structural break at t = 20
Z &lt;- c(rnorm(20, 0), rnorm(20, 2))

wmw_test(Z, h = 1L, control = list(overlapping = TRUE, b_n = 5))
</code></pre>

<hr>
<h2 id='zeros'>
Zero of the Bessel function of first kind
</h2><span id='topic+zeros'></span>

<h3>Description</h3>

<p>Contains the zeros of the Bessel function of first kind.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("zeros")</code></pre>


<h3>Format</h3>

<p>A data frame where the i-th column contains the first 50 zeros of the Bessel 
function of the first kind and ((i - 1) / 2)th order, i = 1, ..., 5001.
</p>


<h3>Source</h3>

<p>The zeros are computed by the mathematical software octave.
</p>


<h3>References</h3>

<p>Eaton, J., Bateman, D., Hauberg, S., Wehbring, R. (2015). &quot;GNU Octave version 4.0.0 manual: a high-level interactive language for numerical computations&quot;.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
