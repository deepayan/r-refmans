<!DOCTYPE html><html><head><title>Help for package dipm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dipm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dipm'><p>Depth Importance in Precision Medicine (DIPM)</p></a></li>
<li><a href='#node_dipm'><p>Panel-Generator for Visualization of A Precision Medicine Tree</p></a></li>
<li><a href='#pmprune'><p>Pruning A Precision Medicine Tree</p></a></li>
<li><a href='#spmtree'><p>Simple Precision Medicine Tree</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Depth Importance in Precision Medicine (DIPM) Method</td>
</tr>
<tr>
<td>Version:</td>
<td>1.9</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-10-27</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Cai Li &lt;cai.li.stats@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation by Chen, Li, and Zhang (2022) &lt;<a href="https://doi.org/10.1093%2Fbioadv%2Fvbac041">doi:10.1093/bioadv/vbac041</a>&gt; of the Depth Importance in Precision Medicine (DIPM) method 
             in Chen and Zhang (2022) &lt;<a href="https://doi.org/10.1093%2Fbiostatistics%2Fkxaa021">doi:10.1093/biostatistics/kxaa021</a>&gt; and Chen and 
             Zhang (2020) &lt;<a href="https://doi.org/10.1007%2F978-3-030-46161-4_16">doi:10.1007/978-3-030-46161-4_16</a>&gt;. The DIPM method is a classification 
             tree that searches for subgroups with especially poor or strong performance in a given treatment group.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, survival, partykit (&ge; 1.2-6), ggplot2, grid</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-27 05:32:15 UTC; cli9</td>
</tr>
<tr>
<td>Author:</td>
<td>Cai Li [aut, cre],
  Victoria Chen [aut],
  Heping Zhang [aut]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-27 15:05:15 UTC</td>
</tr>
</table>
<hr>
<h2 id='dipm'>Depth Importance in Precision Medicine (DIPM)</h2><span id='topic+dipm'></span>

<h3>Description</h3>

<p>This function creates a classification tree
designed to identify subgroups in which subjects
perform especially well or especially poorly in a
given treatment group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dipm(
  formula,
  data,
  types = NULL,
  nmin = 5,
  nmin2 = 5,
  ntree = NULL,
  mtry = Inf,
  maxdepth = Inf,
  maxdepth2 = Inf,
  print = TRUE,
  dataframe = FALSE,
  prune = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dipm_+3A_formula">formula</code></td>
<td>
<p>A description of the model to be fit with format
<code>Y ~ treatment | X1 + X2</code> for data with a
continuous outcome variable Y and 
<code>Surv(Y, delta) ~ treatment | X1 + X2</code> for data with
a right-censored survival outcome variable Y and
a status indicator delta</p>
</td></tr>
<tr><td><code id="dipm_+3A_data">data</code></td>
<td>
<p>A matrix or data frame of the data</p>
</td></tr>
<tr><td><code id="dipm_+3A_types">types</code></td>
<td>
<p>A vector, data frame, or matrix of the types
of each variable in the data; if left blank, the
default is to assume all of the candidate split
variables are ordinal; otherwise, all variables in 
the data must be specified, and the possible variable 
types are: &quot;response&quot;, &quot;treatment&quot;, &quot;status&quot;, &quot;binary&quot;, 
&quot;ordinal&quot;, and &quot;nominal&quot; for outcome variable Y, the 
treatment variable, the status indicator (if 
applicable), binary candidate split variables, ordinal
candidate split variables, and nominal candidate split
variables respectively</p>
</td></tr>
<tr><td><code id="dipm_+3A_nmin">nmin</code></td>
<td>
<p>An integer specifying the minimum node size of
the overall classification tree</p>
</td></tr>
<tr><td><code id="dipm_+3A_nmin2">nmin2</code></td>
<td>
<p>An integer specifying the minimum node size of
embedded trees</p>
</td></tr>
<tr><td><code id="dipm_+3A_ntree">ntree</code></td>
<td>
<p>An integer specifying the number of embedded trees
to construct at each node of the overall 
classification tree; if left blank, the default value
of <code>ceiling(min(max(sqrt(n), sqrt(nc)), 1000))</code>
will be used if <code>mtry = Inf</code> below and 
<code>ceiling(min(max(n, nc), 1000))</code> otherwise; 
<code>n</code> is the total sample size of the data, and
<code>nc</code> is the total number of candidate split
variables</p>
</td></tr>
<tr><td><code id="dipm_+3A_mtry">mtry</code></td>
<td>
<p>An integer specifying the number of candidate split
variables to randomly select at each node of 
embedded trees; if <code>mtry</code> is set equal to the
default value of Inf, then all possible splits of all
candidate split variables are considered at the nodes
of the embedded trees; otherwise, a recommended value
of <code>mtry</code> to use is the square root of the total
number of candidate split variables rounded up to the
nearest integer</p>
</td></tr>
<tr><td><code id="dipm_+3A_maxdepth">maxdepth</code></td>
<td>
<p>An integer specifying the maximum depth of the
overall classification tree; this argument is 
optional but useful for shortening computation 
time; if left blank, the default is to grow the 
full tree until the minimum node size <code>nmin</code> 
is reached</p>
</td></tr>
<tr><td><code id="dipm_+3A_maxdepth2">maxdepth2</code></td>
<td>
<p>An integer specifying the maximum depth of 
embedded trees; this argument is optional but 
useful for shortening computation time; if left 
blank, the default is to grow each full, 
embedded tree until the minimum node size
<code>nmin2</code> is reached</p>
</td></tr>
<tr><td><code id="dipm_+3A_print">print</code></td>
<td>
<p>A boolean (TRUE/FALSE) value, where TRUE prints
a more readable version of the final tree to the
screen</p>
</td></tr>
<tr><td><code id="dipm_+3A_dataframe">dataframe</code></td>
<td>
<p>A boolean (TRUE/FALSE) value, where TRUE returns
the final tree as a dataframe</p>
</td></tr>
<tr><td><code id="dipm_+3A_prune">prune</code></td>
<td>
<p>A boolean (TRUE/FALSE) value, where TRUE prunes
the final tree using <code>pmprune</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates a classification tree to identify
subgroups relevant to the precision medicine setting.
At each node of the classification tree, a random forest
of so-called embedded trees are fit and used to
calculate a depth variable importance score for each
candidate split variable in the data. The candidate
split variable with the largest variable importance score
is identified as the best split variable of the node.
Then, all possible splits of the selected split variable
are considered, and the split with the greatest split
criteria value is finally selected as the best split of
the best variable.
</p>
<p>The depth variable importance score was originally
proposed by Chen et al. (2007), and the score has been
adapted to the precision medicine setting here.
The depth variable importance score is a relatively
simple measure that takes into account two components:
the depth of a split in a tree and the strength of the
split. The strength of the split is captured with a G
test statistic that may be modified depending on the
type of analysis at hand. When the outcome variable is
continuous, G is the test statistic that tests the
significance of the split by treatment interaction term
in a linear regression model. When the outcome variable
is a right-censored survival time, G is the test statistic
that tests the significance of the split by interaction
term in a Cox proportional hazards model.
</p>
<p>When using <code>dipm</code>, note the following
requirements for the supplied data. First, the dataset
must contain an outcome variable Y and a treatment
variable. If Y is a right-censored survival time
outcome, then there must also be a status indicator
delta, where values of 1 denote the occurrence of the 
(harmful) event of interest, and values of 0 denote
censoring. If there are only two treatment groups, then
the two possible values must be 0 or 1. If there are
more than two treatment groups, then the possible values
must be integers starting from 1 to the total number of
treatment assignments. In regard to the candidate split
variables, if a variable is binary, then the variable
must take values of 0 or 1. If a variable is nominal,
then the values must be integers starting from 1 to the
total number of categories. There cannot be any missing
values in the dataset. For candidate split variables
with missing values, the missings together (MT) method
proposed by Zhang et al. (1996) is helpful.
</p>


<h3>Value</h3>

<p><code>dipm</code> returns the final classification tree as a 
<code>party</code> object by default or a data frame. See
Hothorn and Zeileis (2015) for details. The data 
frame contains the following columns of information:
</p>
<table>
<tr><td><code>node</code></td>
<td>
<p>Unique integer values that identify each node
in the tree, where all of the nodes are
indexed starting from 1</p>
</td></tr>
<tr><td><code>splitvar</code></td>
<td>
<p>Integers that represent the candidate split
variable used to split each node, where
all of the variables are indexed starting
from 1; for terminal nodes, i.e., nodes
without child nodes, the value is set 
equal to NA</p>
</td></tr>
<tr><td><code>splitvar_name</code></td>
<td>
<p>The names of the candidate split 
variables used to split each node
obtained from the column names of the
supplied data; for terminal nodes,
the value is set equal to NA</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Characters that denote the type of each 
candidate split variable; &quot;bin&quot; is for binary
variables, &quot;ord&quot; for ordinal, and &quot;nom&quot; for
nominal; for terminal nodes, the value is set
equal to NA</p>
</td></tr>
<tr><td><code>splitval</code></td>
<td>
<p>Values of the left child node of the 
current split/node; for binary variables,
a value of 0 is printed, and subjects with
values of 0 for the current <code>splitvar</code>
are in the left child node, while subjects
with values of 1 are in the right child
node; for ordinal variables,
<code>splitval</code> is numeric and implies
that subjects with values of the current
<code>splitvar</code> less than or equal to
<code>splitval</code> are in the left child 
node, while the remaining subjects with 
values greater than <code>splitval</code> are in 
the right child node; for nominal
variables, the <code>splitval</code> is a set of
integers separated by commas, and subjects
in that set of categories are in the left
child node, while the remaining subjects
are in the right child node; for terminal
nodes, the value is set equal to NA</p>
</td></tr>
<tr><td><code>lchild</code></td>
<td>
<p>Integers that represent the index (i.e.,
<code>node</code> value) of each node's left
child node; for terminal nodes, the value is
set equal to NA</p>
</td></tr>
<tr><td><code>rchild</code></td>
<td>
<p>Integers that represent the index (i.e.,
<code>node</code> value) of each node's right
child node; for terminal nodes, the value is
set equal to NA</p>
</td></tr>
<tr><td><code>depth</code></td>
<td>
<p>Integers that specify the depth of each
node; the root node has depth 1, its 
children have depth 2, etc.</p>
</td></tr>
<tr><td><code>nsubj</code></td>
<td>
<p>Integers that count the total number of
subjects within each node</p>
</td></tr>
<tr><td><code>besttrt</code></td>
<td>
<p>Integers that denote the identified best 
treatment assignment of each node</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chen, V., Li, C., and Zhang, H. (2022). dipm: an 
R package implementing the Depth Importance in 
Precision Medicine (DIPM) tree and Forest-based method.
<em>Bioinformatics Advances</em>, <strong>2</strong>(1), vbac041.
</p>
<p>Chen, V. and Zhang, H. (2022). Depth importance in 
precision medicine (DIPM): A tree-and forest-based 
method for right-censored survival outcomes. 
<em>Biostatistics</em> <strong>23</strong>(1), 157-172.
</p>
<p>Chen, V. and Zhang, H. (2020). Depth importance in 
precision medicine (DIPM): a tree and forest based method. 
In <em>Contemporary Experimental Design, 
Multivariate Analysis and Data Mining</em>, 243-259.
</p>
<p>Chen, X., Liu, C.-T., Zhang, M., and Zhang, H. (2007).
A forest-based approach to identifying gene and
gene-gene interactions. <em>Proceedings of the 
National Academy of Sciences of the United States of 
America</em> <strong>204</strong>, 19199-19203.
</p>
<p>Zhang, H., Holford, T., and Bracken, M.B. (1996).
A tree-based method of analysis for prospective
studies. <em>Statistics in Medicine</em> <strong>15</strong>,
37-49.
</p>
<p>Hothorn, T. and Zeileis, A. (2015). partykit: 
a modular toolkit for recursive partytioning in R. 
<em>The Journal of Machine Learning Research</em> 
<strong>16</strong>(1), 3905-3909.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spmtree">spmtree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#
# ... an example with a continuous outcome variable
#     and two treatment groups
#

N = 100
set.seed(123)

# generate binary treatments
treatment = rbinom(N, 1, 0.5)

# generate candidate split variables
X1 = rnorm(n = N, mean = 0, sd = 1)
X2 = rnorm(n = N, mean = 0, sd = 1)
X3 = rnorm(n = N, mean = 0, sd = 1)
X4 = rnorm(n = N, mean = 0, sd = 1)
X5 = rnorm(n = N, mean = 0, sd = 1)
X = cbind(X1, X2, X3, X4, X5)
colnames(X) = paste0("X", 1:5)

# generate continuous outcome variable
calculateLink = function(X, treatment){

    ((X[, 1] &lt;= 0) &amp; (X[, 2] &lt;= 0)) *
        (25 * (1 - treatment) + 8 * treatment) + 

    ((X[, 1] &lt;= 0) &amp; (X[, 2] &gt; 0)) *
        (18 * (1 - treatment) + 20 * treatment) +

    ((X[, 1] &gt; 0) &amp; (X[, 3] &lt;= 0)) *
        (20 * (1 - treatment) + 18 * treatment) + 

    ((X[, 1] &gt; 0) &amp; (X[, 3] &gt; 0)) *
        (8 * (1 - treatment) + 25 * treatment)
}

Link = calculateLink(X, treatment)
Y = rnorm(N, mean = Link, sd = 1)

# combine variables in a data frame
data = data.frame(X, Y, treatment)

# fit a dipm classification tree 
tree1 = dipm(Y ~ treatment | ., data, mtry = 1, maxdepth = 3)
# predict optimal treatment for new subjects
predict(tree1, newdata = head(data), 
FUN = function(n)  as.numeric(n$info$opt_trt))


#
# ... an example with a continuous outcome variable
#     and three treatment groups
#

N = 600
set.seed(123)

# generate treatments
treatment = sample(1:3, N, replace = TRUE)

# generate candidate split variables
X1 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X2 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X3 = sample(1:4, N, replace = TRUE)
X4 = sample(1:5, N, replace = TRUE)
X5 = rbinom(N, 1, 0.5)
X6 = rbinom(N, 1, 0.5)
X7 = rbinom(N, 1, 0.5)
X = cbind(X1, X2, X3, X4, X5, X6, X7)
colnames(X) = paste0("X", 1:7)

# generate continuous outcome variable
calculateLink = function(X,treatment){

    10.2 - 0.3 * (treatment == 1) - 0.1 * X[, 1] + 
    2.1 * (treatment == 1) * X[, 1] +
    1.2 * X[, 2]
}

Link = calculateLink(X, treatment)
Y = rnorm(N, mean = Link, sd = 1)

# combine variables in a data frame
data = data.frame(X, Y, treatment)

# create vector of variable types
types = c(rep("ordinal", 2), rep("nominal", 2), rep("binary", 3),
        "response", "treatment")

# fit a dipm classification tree 
tree2 = dipm(Y ~ treatment | ., data, types = types, maxdepth = 2)

#
# ... an example with a survival outcome variable
#     and two treatment groups
#

N = 300
set.seed(321)

# generate binary treatments
treatment = rbinom(N, 1, 0.5)

# generate candidate split variables
X1 = rnorm(n = N, mean = 0, sd = 1)
X2 = rnorm(n = N, mean = 0, sd = 1)
X3 = rnorm(n = N, mean = 0, sd = 1)
X4 = rnorm(n = N, mean = 0, sd = 1)
X5 = rnorm(n = N, mean = 0, sd = 1)
X = cbind(X1, X2, X3, X4, X5)
colnames(X) = paste0("X", 1:5)

# generate survival outcome variable
calculateLink = function(X, treatment){

    X[, 1] + 0.5 * X[, 3] + (3 * treatment - 1.5) * (abs(X[, 5]) - 0.67)
}

Link = calculateLink(X, treatment)
T = rexp(N, exp(-Link))
C0 = rexp(N, 0.1 * exp(X[, 5] + X[, 2]))
Y = pmin(T, C0)
delta = (T &lt;= C0)

# combine variables in a data frame
data = data.frame(X, Y, delta, treatment)

# fit a dipm classification tree 
tree3 = dipm(Surv(Y, delta) ~ treatment | .,data, ntree = 1, maxdepth = 2,
           maxdepth2 = 6)

#
# ... an example with a survival outcome variable
#     and four treatment groups
#

N = 800
set.seed(321)

# generate treatments
treatment = sample(1:4, N, replace = TRUE)

# generate candidate split variables
X1 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X2 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X3 = sample(1:4, N, replace = TRUE)
X4 = sample(1:5, N, replace = TRUE)
X5 = rbinom(N, 1, 0.5)
X6 = rbinom(N, 1, 0.5)
X7 = rbinom(N, 1, 0.5)
X = cbind(X1, X2, X3, X4, X5, X6, X7)
colnames(X) = paste0("X", 1:7)

# generate survival outcome variable
calculateLink = function(X, treatment, noise){

    -0.2 * (treatment == 1) +
    -1.1 * X[, 1] + 
    1.2 * (treatment == 1) * X[, 1] +
    1.2 * X[, 2]
}

Link = calculateLink(X, treatment)
T = rweibull(N, shape=2, scale = exp(Link))
Cnoise = runif(n = N) + runif(n = N)
C0 = rexp(N, exp(0.3 * -Cnoise))
Y = pmin(T, C0)
delta = (T &lt;= C0)

# combine variables in a data frame
data = data.frame(X, Y, delta, treatment)

# create vector of variable types
types = c(rep("ordinal", 2), rep("nominal", 2), rep("binary", 3), 
        "response", "status", "treatment")

# fit two dipm classification trees 
tree4 = dipm(Surv(Y, delta) ~ treatment | ., data, types = types, ntree = 1, 
           maxdepth = 2, maxdepth2 = 6)
tree5 = dipm(Surv(Y, delta) ~ treatment | X3 + X4, data, types = types, ntree = 1, 
           maxdepth = 2, maxdepth2 = 6)


</code></pre>

<hr>
<h2 id='node_dipm'>Panel-Generator for Visualization of A Precision Medicine Tree</h2><span id='topic+node_dipm'></span>

<h3>Description</h3>

<p>This function provides a new plot method for <code>dipm</code>
and <code>spmtree</code>. It visualizes stratified treatment groups through 
boxplots for a continuous outcome and survival plots for a survival outcome, 
respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>node_dipm(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="node_dipm_+3A_obj">obj</code></td>
<td>
<p>A <code>party</code> tree object returned from either the 
<code>dipm()</code> or <code>spmtree()</code> function</p>
</td></tr>
<tr><td><code id="node_dipm_+3A_...">...</code></td>
<td>
<p>Arguments passed on to plotfun</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function visualizes the precision medicine trees
proposed in Chen and Zhang (2020a, b).
</p>


<h3>Value</h3>

<p>No return value, called for plot
</p>


<h3>References</h3>

<p>Chen, V., Li, C., and Zhang, H. (2022). dipm: an 
R package implementing the Depth Importance in 
Precision Medicine (DIPM) tree and Forest-based method.
<em>Bioinformatics Advances</em>, <strong>2</strong>(1), vbac041.
</p>
<p>Chen, V. and Zhang, H. (2020). Depth importance in 
precision medicine (DIPM): a tree and forest based method. 
In <em>Contemporary Experimental Design, 
Multivariate Analysis and Data Mining</em>, 243-259.
</p>
<p>Chen, V. and Zhang, H. (2022). Depth importance in 
precision medicine (DIPM): A tree-and forest-based 
method for right-censored survival outcomes. 
<em>Biostatistics</em> <strong>23</strong>(1), 157-172.
</p>
<p>Seibold, H., Zeileis, A., and Hothorn, T. (2019). 
model4you: An R package for personalised treatment 
effect estimation. <em>Journal of Open Research 
Software</em> <strong>7</strong>(1).
</p>
<p>Hothorn, T. and Zeileis, A. (2015). partykit: 
a modular toolkit for recursive partytioning in R. 
<em>The Journal of Machine Learning Research</em> 
<strong>16</strong>(1), 3905-3909.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dipm">dipm</a></code>, <code><a href="#topic+spmtree">spmtree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#' #
# ... an example with a continuous outcome variable
#     and two treatment groups
#

N = 100
set.seed(123)

# generate binary treatments
treatment = rbinom(N, 1, 0.5)

# generate candidate split variables
X1 = rnorm(n = N, mean = 0, sd = 1)
X2 = rnorm(n = N, mean = 0, sd = 1)
X3 = rnorm(n = N, mean = 0, sd = 1)
X4 = rnorm(n = N, mean = 0, sd = 1)
X5 = rnorm(n = N, mean = 0, sd = 1)
X = cbind(X1, X2, X3, X4, X5)
colnames(X) = paste0("X", 1:5)

# generate continuous outcome variable
calculateLink = function(X, treatment){

    ((X[, 1] &lt;= 0) &amp; (X[, 2] &lt;= 0)) *
        (25 * (1 - treatment) + 8 * treatment) + 

    ((X[, 1] &lt;= 0) &amp; (X[, 2] &gt; 0)) *
        (18 * (1 - treatment) + 20 * treatment) +

    ((X[,1 ] &gt; 0) &amp; (X[, 3] &lt;= 0)) *
        (20 * (1 - treatment) + 18 * treatment) + 

    ((X[,1] &gt; 0) &amp; (X[,3] &gt; 0)) *
        (8 * (1 - treatment) + 25 * treatment)
}

Link = calculateLink(X, treatment)
Y = rnorm(N, mean = Link, sd = 1)

# combine variables in a data frame
data = data.frame(X, Y, treatment)

# fit a dipm classification tree
tree = dipm(Y ~ treatment | ., data, mtry = 1, maxdepth = 3) 
plot(tree, terminal_panel = node_dipm)
            

                                    
</code></pre>

<hr>
<h2 id='pmprune'>Pruning A Precision Medicine Tree</h2><span id='topic+pmprune'></span>

<h3>Description</h3>

<p>This function prunes classification trees designed
for the precision medicine setting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmprune(tree)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmprune_+3A_tree">tree</code></td>
<td>
<p>A data frame object returned from either the 
<code>dipm()</code> or <code>spmtree()</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the simple pruning strategy
proposed and used in Tsai et al. (2016). Terminal
sister nodes, i.e., nodes with no child nodes that
share the same parent node, are removed if they have
the same identified optimal treatment assignment.
</p>


<h3>Value</h3>

<p><code>pmprune</code> returns the pruned classification tree as a 
data frame. The data frame contains the following columns 
of information:
</p>
<table>
<tr><td><code>node</code></td>
<td>
<p>Unique integer values that identify each node
in the tree, where all of the nodes are
indexed starting from 1</p>
</td></tr>
<tr><td><code>splitvar</code></td>
<td>
<p>Integers that represent the candidate split
variable used to split each node, where
all of the variables are indexed starting
from 1; for terminal nodes, i.e., nodes
without child nodes, the value is set 
equal to NA</p>
</td></tr>
<tr><td><code>splitvar_name</code></td>
<td>
<p>The names of the candidate split 
variables used to split each node
obtained from the column names of the
supplied data; for terminal nodes,
the value is set equal to NA</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Characters that denote the type of each 
candidate split variable; &quot;bin&quot; is for binary
variables, &quot;ord&quot; for ordinal, and &quot;nom&quot; for
nominal; for terminal nodes, the value is set
equal to NA</p>
</td></tr>
<tr><td><code>splitval</code></td>
<td>
<p>Values of the left child node of the 
current split/node; for binary variables,
a value of 0 is printed, and subjects with
values of 0 for the current <code>splitvar</code>
are in the left child node, while subjects
with values of 1 are in the right child
node; for ordinal variables,
<code>splitval</code> is numeric and implies
that subjects with values of the current
<code>splitvar</code> less than or equal to
<code>splitval</code> are in the left child 
node, while the remaining subjects with 
values greater than <code>splitval</code> are in 
the right child node; for nominal
variables, the <code>splitval</code> is a set of
integers separated by commas, and subjects
in that set of categories are in the left
child node, while the remaining subjects
are in the right child node; for terminal
nodes, the value is set equal to NA</p>
</td></tr>
<tr><td><code>lchild</code></td>
<td>
<p>Integers that represent the index (i.e.,
<code>node</code> value) of each node's left
child node; for terminal nodes, the value is
set equal to NA</p>
</td></tr>
<tr><td><code>rchild</code></td>
<td>
<p>Integers that represent the index (i.e.,
<code>node</code> value) of each node's right
child node; for terminal nodes, the value is
set equal to NA</p>
</td></tr>
<tr><td><code>depth</code></td>
<td>
<p>Integers that specify the depth of each
node; the root node has depth 1, its 
children have depth 2, etc.</p>
</td></tr>
<tr><td><code>nsubj</code></td>
<td>
<p>Integers that count the total number of
subjects within each node</p>
</td></tr>
<tr><td><code>besttrt</code></td>
<td>
<p>Integers that denote the identified best 
treatment assignment of each node</p>
</td></tr>
</table>


<h3>References</h3>

<p>Tsai, W.-M., Zhang, H., Buta, E., O'Malley, S., 
Gueorguieva, R. (2016). A modified classification
tree method for personalized medicine decisions.
<em>Statistics and its Interface</em> <strong>9</strong>, 
239-253.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dipm">dipm</a></code>, <code><a href="#topic+spmtree">spmtree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#
# ... an example with a continuous outcome variable
#     and three treatment groups
#


N = 100
set.seed(123)

# generate treatments
treatment = sample(1:3, N, replace = TRUE)

# generate candidate split variables
X1 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X2 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X3 = sample(1:4, N, replace = TRUE)
X4 = sample(1:5, N, replace = TRUE)
X5 = rbinom(N, 1, 0.5)
X6 = rbinom(N, 1, 0.5)
X7 = rbinom(N, 1, 0.5)
X = cbind(X1, X2, X3, X4, X5, X6, X7)
colnames(X) = paste0("X", 1:7)

# generate continuous outcome variable
calculateLink = function(X, treatment){

    10.2 - 0.3 * (treatment == 1) - 0.1 * X[, 1] + 
    2.1 * (treatment == 1) * X[, 1] +
    1.2 * X[, 2]
}

Link = calculateLink(X, treatment)
Y = rnorm(N, mean = Link, sd = 1)

# combine variables in a data frame
data = data.frame(X, Y, treatment)

# create vector of variable types
types = c(rep("ordinal", 2), rep("nominal", 2), rep("binary", 3),
            "response", "treatment")

# fit a classification tree
tree = spmtree(Y ~ treatment | ., data, types = types, dataframe = TRUE)

# prune the tree
ptree = pmprune(tree)


</code></pre>

<hr>
<h2 id='spmtree'>Simple Precision Medicine Tree</h2><span id='topic+spmtree'></span>

<h3>Description</h3>

<p>This function creates a classification tree
designed to identify subgroups in which subjects
perform especially well or especially poorly in a
given treatment group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spmtree(
  formula,
  data,
  types = NULL,
  nmin = 5,
  maxdepth = Inf,
  print = TRUE,
  dataframe = FALSE,
  prune = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spmtree_+3A_formula">formula</code></td>
<td>
<p>A description of the model to be fit with format
<code>Y ~ treatment | X1 + X2</code> for data with a
continuous outcome variable Y and 
<code>Surv(Y, delta) ~ treatment | X1 + X2</code> for data with
a right-censored survival outcome variable Y and
a status indicator delta</p>
</td></tr>
<tr><td><code id="spmtree_+3A_data">data</code></td>
<td>
<p>A matrix or data frame of the data</p>
</td></tr>
<tr><td><code id="spmtree_+3A_types">types</code></td>
<td>
<p>A vector, data frame, or matrix of the types
of each variable in the data; if left blank, the
default is to assume all of the candidate split
variables are ordinal; otherwise, all variables in 
the data must be specified, and the possible variable 
types are: &quot;response&quot;, &quot;treatment&quot;, &quot;status&quot;, &quot;binary&quot;, 
&quot;ordinal&quot;, and &quot;nominal&quot; for outcome variable Y, the 
treatment variable, the status indicator (if 
applicable), binary candidate split variables, ordinal
candidate split variables, and nominal candidate split
variables respectively</p>
</td></tr>
<tr><td><code id="spmtree_+3A_nmin">nmin</code></td>
<td>
<p>An integer specifying the minimum node size of
the overall classification tree</p>
</td></tr>
<tr><td><code id="spmtree_+3A_maxdepth">maxdepth</code></td>
<td>
<p>An integer specifying the maximum depth of the
overall classification tree; this argument is 
optional but useful for shortening computation 
time; if left blank, the default is to grow the 
full tree until the minimum node size <code>nmin</code> 
is reached</p>
</td></tr>
<tr><td><code id="spmtree_+3A_print">print</code></td>
<td>
<p>A boolean (TRUE/FALSE) value, where TRUE prints
a more readable version of the final tree to the
screen</p>
</td></tr>
<tr><td><code id="spmtree_+3A_dataframe">dataframe</code></td>
<td>
<p>A boolean (TRUE/FALSE) value, where TRUE returns
the final tree as a dataframe</p>
</td></tr>
<tr><td><code id="spmtree_+3A_prune">prune</code></td>
<td>
<p>A boolean (TRUE/FALSE) value, where TRUE prunes
the final tree using <code>pmprune</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To identify the best split at each node of the 
classification tree, all possible splits of all 
candidate split variables are considered. The single
split with the highest split criteria score is
identified as the best split of the node. For data with 
a continuous outcome variable, the split criteria is the 
DIFF value that was first proposed for usage in the 
relative-effectiveness based method (Zhang et al. (2010),
Tsai et al. (2016)). For data with a survival outcome 
variable, the split criteria is the squared test 
statistic that tests the significance of the split by 
treatment interaction term in a Cox proportional hazards 
model.
</p>
<p>When using <code>spmtree</code>, note the following
requirements for the supplied data. First, the dataset
must contain an outcome variable Y and a treatment
variable. If Y is a right-censored survival time
outcome, then there must also be a status indicator
delta, where values of 1 denote the occurrence of the 
(harmful) event of interest, and values of 0 denote
censoring. If there are only two treatment groups, then
the two possible values must be 0 or 1. If there are
more than two treatment groups, then the possible values
must be integers starting from 1 to the total number of
treatment assignments. In regard to the candidate split
variables, if a variable is binary, then the variable
must take values of 0 or 1. If a variable is nominal,
then the values must be integers starting from 1 to the
total number of categories. There cannot be any missing
values in the dataset. For candidate split variables
with missing values, the missings together (MT) method
proposed by Zhang et al. (1996) is helpful.
</p>


<h3>Value</h3>

<p><code>spmtree</code> returns the final classification tree as a 
<code>party</code> object by default or a data frame. See 
Hothorn and Zeileis (2015) for details. The data 
frame contains the following columns of information:
</p>
<table>
<tr><td><code>node</code></td>
<td>
<p>Unique integer values that identify each node
in the tree, where all of the nodes are
indexed starting from 1</p>
</td></tr>
<tr><td><code>splitvar</code></td>
<td>
<p>Integers that represent the candidate split
variable used to split each node, where
all of the variables are indexed starting
from 1; for terminal nodes, i.e., nodes
without child nodes, the value is set 
equal to NA</p>
</td></tr>
<tr><td><code>splitvar_name</code></td>
<td>
<p>The names of the candidate split 
variables used to split each node
obtained from the column names of the
supplied data; for terminal nodes,
the value is set equal to NA</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Characters that denote the type of each 
candidate split variable; &quot;bin&quot; is for binary
variables, &quot;ord&quot; for ordinal, and &quot;nom&quot; for
nominal; for terminal nodes, the value is set
equal to NA</p>
</td></tr>
<tr><td><code>splitval</code></td>
<td>
<p>Values of the left child node of the 
current split/node; for binary variables,
a value of 0 is printed, and subjects with
values of 0 for the current <code>splitvar</code>
are in the left child node, while subjects
with values of 1 are in the right child
node; for ordinal variables,
<code>splitval</code> is numeric and implies
that subjects with values of the current
<code>splitvar</code> less than or equal to
<code>splitval</code> are in the left child 
node, while the remaining subjects with 
values greater than <code>splitval</code> are in 
the right child node; for nominal
variables, the <code>splitval</code> is a set of
integers separated by commas, and subjects
in that set of categories are in the left
child node, while the remaining subjects
are in the right child node; for terminal
nodes, the value is set equal to NA</p>
</td></tr>
<tr><td><code>lchild</code></td>
<td>
<p>Integers that represent the index (i.e.,
<code>node</code> value) of each node's left
child node; for terminal nodes, the value is
set equal to NA</p>
</td></tr>
<tr><td><code>rchild</code></td>
<td>
<p>Integers that represent the index (i.e.,
<code>node</code> value) of each node's right
child node; for terminal nodes, the value is
set equal to NA</p>
</td></tr>
<tr><td><code>depth</code></td>
<td>
<p>Integers that specify the depth of each
node; the root node has depth 1, its 
children have depth 2, etc.</p>
</td></tr>
<tr><td><code>nsubj</code></td>
<td>
<p>Integers that count the total number of
subjects within each node</p>
</td></tr>
<tr><td><code>besttrt</code></td>
<td>
<p>Integers that denote the identified best 
treatment assignment of each node</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chen, V., Li, C., and Zhang, H. (2022). dipm: an 
R package implementing the Depth Importance in 
Precision Medicine (DIPM) tree and Forest-based method.
<em>Bioinformatics Advances</em>, <strong>2</strong>(1), vbac041.
</p>
<p>Chen, V. and Zhang, H. (2022). Depth importance in 
precision medicine (DIPM): A tree-and forest-based 
method for right-censored survival outcomes. 
<em>Biostatistics</em> <strong>23</strong>(1), 157-172.
</p>
<p>Chen, V. and Zhang, H. (2020). Depth importance in 
precision medicine (DIPM): a tree and forest based method. 
In <em>Contemporary Experimental Design, 
Multivariate Analysis and Data Mining</em>, 243-259.
</p>
<p>Tsai, W.-M., Zhang, H., Buta, E., O'Malley, S., 
Gueorguieva, R. (2016). A modified classification
tree method for personalized medicine decisions.
<em>Statistics and its Interface</em> <strong>9</strong>, 
239-253.
</p>
<p>Zhang, H., Holford, T., and Bracken, M.B. (1996).
A tree-based method of analysis for prospective
studies. <em>Statistics in Medicine</em> <strong>15</strong>,
37-49.
</p>
<p>Zhang, H., Legro, R.S., Zhang, J., Zhang, L., Chen,
X., et al. (2010). Decision trees for identifying
predictors of treatment effectiveness in clinical
trials and its application to ovulation in a study of
women with polycystic ovary syndrome. <em>Human
Reproduction</em> <strong>25</strong>, 2612-2621.
</p>
<p>Hothorn, T. and Zeileis, A. (2015). partykit: 
a modular toolkit for recursive partytioning in R. 
<em>The Journal of Machine Learning Research</em> 
<strong>16</strong>(1), 3905-3909.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dipm">dipm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#
# ... an example with a continuous outcome variable
#     and two treatment groups
#

N = 300
set.seed(123)

# generate binary treatments
treatment = rbinom(N, 1, 0.5)

# generate candidate split variables
X1 = rnorm(n = N, mean = 0, sd = 1)
X2 = rnorm(n = N, mean = 0, sd = 1)
X3 = rnorm(n = N, mean = 0, sd = 1)
X4 = rnorm(n = N, mean = 0, sd = 1)
X5 = rnorm(n = N, mean = 0, sd = 1)
X = cbind(X1, X2, X3, X4, X5)
colnames(X) = paste0("X", 1:5)

# generate continuous outcome variable
calculateLink = function(X, treatment){

    ((X[, 1] &lt;= 0) &amp; (X[, 2] &lt;= 0)) *
        (25 * (1 - treatment) + 8 * treatment) + 

    ((X[, 1] &lt;= 0) &amp; (X[, 2] &gt; 0)) *
        (18 * (1 - treatment) + 20 * treatment) +

    ((X[, 1] &gt; 0) &amp; (X[, 3] &lt;= 0)) *
        (20 * (1 - treatment) + 18 * treatment) + 

    ((X[, 1] &gt; 0) &amp; (X[, 3] &gt; 0)) *
        (8 * (1 - treatment) + 25 * treatment)
}

Link = calculateLink(X, treatment)
Y = rnorm(N, mean = Link, sd = 1)

# combine variables in a data frame
data = data.frame(X, Y, treatment)

# fit a classification tree
tree1 = spmtree(Y ~ treatment | ., data, maxdepth = 3)
# predict optimal treatment for new subjects
predict(tree1, newdata = head(data), 
FUN = function(n)  as.numeric(n$info$opt_trt))


#
# ... an example with a continuous outcome variable
#     and three treatment groups
#

N = 600
set.seed(123)

# generate treatments
treatment = sample(1:3, N, replace = TRUE)

# generate candidate split variables
X1 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X2 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X3 = sample(1:4, N, replace = TRUE)
X4 = sample(1:5, N, replace = TRUE)
X5 = rbinom(N, 1, 0.5)
X6 = rbinom(N, 1, 0.5)
X7 = rbinom(N, 1, 0.5)
X = cbind(X1, X2, X3, X4, X5, X6, X7)
colnames(X) = paste0("X", 1:7)

# generate continuous outcome variable
calculateLink = function(X, treatment){

    10.2 - 0.3 * (treatment == 1) - 0.1 * X[, 1] + 
    2.1 * (treatment == 1) * X[, 1] +
    1.2 * X[, 2]
}

Link = calculateLink(X, treatment)
Y = rnorm(N, mean = Link, sd = 1)

# combine variables in a data frame
data = data.frame(X, Y, treatment)

# create vector of variable types
types = c(rep("ordinal", 2), rep("nominal", 2), rep("binary", 3),
        "response", "treatment")

# fit a classification tree
tree2 = spmtree(Y ~ treatment | ., data, types = types)

#
# ... an example with a survival outcome variable
#     and two treatment groups
#

N = 300
set.seed(321)

# generate binary treatments
treatment = rbinom(N, 1, 0.5)

# generate candidate split variables
X1 = rnorm(n = N, mean = 0, sd = 1)
X2 = rnorm(n = N, mean = 0, sd = 1)
X3 = rnorm(n = N, mean = 0, sd = 1)
X4 = rnorm(n = N, mean = 0, sd = 1)
X5 = rnorm(n = N, mean = 0, sd = 1)
X = cbind(X1, X2, X3, X4, X5)
colnames(X) = paste0("X", 1:5)

# generate survival outcome variable
calculateLink = function(X, treatment){

    X[, 1] + 0.5 * X[, 3] + (3 * treatment - 1.5) * (abs(X[, 5]) - 0.67)
}

Link = calculateLink(X, treatment)
T = rexp(N, exp(-Link))
C0 = rexp(N, 0.1 * exp(X[, 5] + X[, 2]))
Y = pmin(T, C0)
delta = (T &lt;= C0)

# combine variables in a data frame
data = data.frame(X, Y, delta, treatment)

# fit a classification tree
tree3 = spmtree(Surv(Y, delta) ~ treatment | ., data, maxdepth = 2)

#
# ... an example with a survival outcome variable
#     and four treatment groups
#

N = 800
set.seed(321)

# generate treatments
treatment = sample(1:4, N, replace = TRUE)

# generate candidate split variables
X1 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X2 = round(rnorm(n = N, mean = 0, sd = 1), 4)
X3 = sample(1:4, N, replace = TRUE)
X4 = sample(1:5, N, replace = TRUE)
X5 = rbinom(N, 1, 0.5)
X6 = rbinom(N, 1, 0.5)
X7 = rbinom(N, 1, 0.5)
X = cbind(X1, X2, X3, X4, X5, X6, X7)
colnames(X) = paste0("X", 1:7)

# generate survival outcome variable
calculateLink = function(X, treatment, noise){

    -0.2 * (treatment == 1) +
    -1.1 * X[, 1] + 
    1.2 * (treatment == 1) * X[, 1] +
    1.2 * X[, 2]
}

Link = calculateLink(X, treatment)
T = rweibull(N, shape = 2, scale = exp(Link))
Cnoise = runif(n = N) + runif(n = N)
C0 = rexp(N, exp(0.3 * -Cnoise))
Y = pmin(T, C0)
delta = (T &lt;= C0)

# combine variables in a data frame
data = data.frame(X, Y, delta, treatment)

# create vector of variable types
types = c(rep("ordinal", 2), rep("nominal", 2), rep("binary", 3),
        "response", "status", "treatment")

# fit two classification trees
tree4 = spmtree(Surv(Y, delta) ~ treatment | ., data, types = types, maxdepth = 2)
tree5 = spmtree(Surv(Y, delta) ~ treatment | X3 + X4, data, types = types,
             maxdepth = 2)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
