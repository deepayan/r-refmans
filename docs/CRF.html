<!DOCTYPE html><html><head><title>Help for package CRF</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CRF}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CRF-package'><p>CRF - Conditional Random Fields</p></a></li>
<li><a href='#Chain'><p>Chain CRF example</p></a></li>
<li><a href='#clamp.crf'><p>Make clamped CRF</p></a></li>
<li><a href='#clamp.reset'><p>Reset clamped CRF</p></a></li>
<li><a href='#Clique'><p>Clique CRF example</p></a></li>
<li><a href='#crf.nll'><p>Calculate CRF negative log likelihood</p></a></li>
<li><a href='#crf.update'><p>Update CRF potentials</p></a></li>
<li><a href='#decode.block'><p>Decoding method using block iterated conditional modes algorithm</p></a></li>
<li><a href='#decode.chain'><p>Decoding method for chain-structured graphs</p></a></li>
<li><a href='#decode.conditional'><p>Conditional decoding method</p></a></li>
<li><a href='#decode.cutset'><p>Decoding method for graphs with a small cutset</p></a></li>
<li><a href='#decode.exact'><p>Decoding method for small graphs</p></a></li>
<li><a href='#decode.greedy'><p>Decoding method using greedy algorithm</p></a></li>
<li><a href='#decode.icm'><p>Decoding method using iterated conditional modes algorithm</p></a></li>
<li><a href='#decode.ilp'><p>Decoding method using integer linear programming</p></a></li>
<li><a href='#decode.junction'><p>Decoding method for low-treewidth graphs</p></a></li>
<li><a href='#decode.lbp'><p>Decoding method using loopy belief propagation</p></a></li>
<li><a href='#decode.marginal'><p>Decoding method using inference</p></a></li>
<li><a href='#decode.rbp'><p>Decoding method using residual belief propagation</p></a></li>
<li><a href='#decode.sample'><p>Decoding method using sampling</p></a></li>
<li><a href='#decode.trbp'><p>Decoding method using tree-reweighted belief propagation</p></a></li>
<li><a href='#decode.tree'><p>Decoding method for tree- and forest-structured graphs</p></a></li>
<li><a href='#duplicate.crf'><p>Duplicate CRF</p></a></li>
<li><a href='#get.logPotential'><p>Calculate the log-potential of CRF</p></a></li>
<li><a href='#get.potential'><p>Calculate the potential of CRF</p></a></li>
<li><a href='#infer.chain'><p>Inference method for chain-structured graphs</p></a></li>
<li><a href='#infer.conditional'><p>Conditional inference method</p></a></li>
<li><a href='#infer.cutset'><p>Inference method for graphs with a small cutset</p></a></li>
<li><a href='#infer.exact'><p>Inference method for small graphs</p></a></li>
<li><a href='#infer.junction'><p>Inference method for low-treewidth graphs</p></a></li>
<li><a href='#infer.lbp'><p>Inference method using loopy belief propagation</p></a></li>
<li><a href='#infer.rbp'><p>Inference method using residual belief propagation</p></a></li>
<li><a href='#infer.sample'><p>Inference method using sampling</p></a></li>
<li><a href='#infer.trbp'><p>Inference method using tree-reweighted belief propagation</p></a></li>
<li><a href='#infer.tree'><p>Inference method for tree- and forest-structured graphs</p></a></li>
<li><a href='#Loop'><p>Loop CRF example</p></a></li>
<li><a href='#make.crf'><p>Make CRF</p></a></li>
<li><a href='#make.features'><p>Make CRF features</p></a></li>
<li><a href='#make.par'><p>Make CRF parameters</p></a></li>
<li><a href='#mrf.nll'><p>Calculate MRF negative log-likelihood</p></a></li>
<li><a href='#mrf.stat'><p>Calculate MRF sufficient statistics</p></a></li>
<li><a href='#mrf.update'><p>Update MRF potentials</p></a></li>
<li><a href='#Rain'><p>Rain data</p></a></li>
<li><a href='#sample.chain'><p>Sampling method for chain-structured graphs</p></a></li>
<li><a href='#sample.conditional'><p>Conditional sampling method</p></a></li>
<li><a href='#sample.cutset'><p>Sampling method for graphs with a small cutset</p></a></li>
<li><a href='#sample.exact'><p>Sampling method for small graphs</p></a></li>
<li><a href='#sample.gibbs'><p>Sampling method using single-site Gibbs sampler</p></a></li>
<li><a href='#sample.junction'><p>Sampling method for low-treewidth graphs</p></a></li>
<li><a href='#sample.tree'><p>Sampling method for tree- and forest-structured graphs</p></a></li>
<li><a href='#Small'><p>Small CRF example</p></a></li>
<li><a href='#sub.crf'><p>Make sub CRF</p></a></li>
<li><a href='#train.crf'><p>Train CRF model</p></a></li>
<li><a href='#train.mrf'><p>Train MRF model</p></a></li>
<li><a href='#Tree'><p>Tree CRF example</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.4-3</td>
</tr>
<tr>
<td>Title:</td>
<td>Conditional Random Fields</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements modeling and computational tools for conditional
    random fields (CRF) model as well as other probabilistic undirected
    graphical models of discrete data with pairwise and unary potentials.</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, Rglpk</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/wulingyun/CRF/issues">https://github.com/wulingyun/CRF/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/wulingyun/CRF">https://github.com/wulingyun/CRF</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Author:</td>
<td>Ling-Yun Wu [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ling-Yun Wu &lt;wulingyun@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Repository/R-Forge/Project:</td>
<td>crf</td>
</tr>
<tr>
<td>Repository/R-Forge/Revision:</td>
<td>51</td>
</tr>
<tr>
<td>Repository/R-Forge/DateTimeStamp:</td>
<td>2019-11-30 02:18:39</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-12-01 20:10:23 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-11-30 02:50:47 UTC; rforge</td>
</tr>
</table>
<hr>
<h2 id='CRF-package'>CRF - Conditional Random Fields</h2><span id='topic+CRF-package'></span><span id='topic+CRF'></span>

<h3>Description</h3>

<p>Library of Conditional Random Fields model
</p>


<h3>Details</h3>

<p>CRF is R package for various computational tasks of conditional random
fields as well as other probabilistic undirected graphical models of
discrete data with pairwise and unary potentials. The
decoding/inference/sampling tasks are implemented for general discrete
undirected graphical models with pairwise potentials. The training task is
less general, focusing on conditional random fields with log-linear
potentials and a fixed structure. The code is written entirely in R and C++.
The initial version is ported from UGM written by Mark Schmidt.
</p>
<p>Decoding: Computing the most likely configuration 
</p>

<ul>
<li> <p><code><a href="#topic+decode.exact">decode.exact</a></code> Exact decoding for small graphs with brute-force search
</p>
</li>
<li> <p><code><a href="#topic+decode.chain">decode.chain</a></code> Exact decoding for chain-structured graphs with the Viterbi algorithm 
</p>
</li>
<li> <p><code><a href="#topic+decode.tree">decode.tree</a></code> Exact decoding for tree- and forest-structured graphs with max-product belief propagation 
</p>
</li>
<li> <p><code><a href="#topic+decode.conditional">decode.conditional</a></code> Conditional decoding (takes another decoding method as input) 
</p>
</li>
<li> <p><code><a href="#topic+decode.cutset">decode.cutset</a></code> Exact decoding for graphs with a small cutset using cutset conditioning
</p>
</li>
<li> <p><code><a href="#topic+decode.junction">decode.junction</a></code> Exact decoding for low-treewidth graphs using junction trees 
</p>
</li>
<li> <p><code><a href="#topic+decode.sample">decode.sample</a></code> Approximate decoding using sampling (takes a sampling method as input) 
</p>
</li>
<li> <p><code><a href="#topic+decode.marginal">decode.marginal</a></code> Approximate decoding using inference (takes an inference method as input) 
</p>
</li>
<li> <p><code><a href="#topic+decode.lbp">decode.lbp</a></code> Approximate decoding using max-product loopy belief propagation 
</p>
</li>
<li> <p><code><a href="#topic+decode.trbp">decode.trbp</a></code> Approximate decoding using max-product tree-reweighted belief propagtion 
</p>
</li>
<li> <p><code><a href="#topic+decode.greedy">decode.greedy</a></code> Approximate decoding with greedy algorithm 
</p>
</li>
<li> <p><code><a href="#topic+decode.icm">decode.icm</a></code> Approximate decoding with the iterated conditional modes algorithm 
</p>
</li>
<li> <p><code><a href="#topic+decode.block">decode.block</a></code> Approximate decoding with the block iterated conditional modes algorithm 
</p>
</li>
<li> <p><code><a href="#topic+decode.ilp">decode.ilp</a></code> Exact decoding with an integer linear programming formulation and approximate using LP relaxation 
</p>
</li></ul>

<p>Inference: Computing the partition function and marginal probabilities
</p>
 
<ul>
<li> <p><code><a href="#topic+infer.exact">infer.exact</a></code> Exact inference for small graphs with brute-force counting 
</p>
</li>
<li> <p><code><a href="#topic+infer.chain">infer.chain</a></code> Exact inference for chain-structured graphs with the forward-backward algorithm 
</p>
</li>
<li> <p><code><a href="#topic+infer.tree">infer.tree</a></code> Exact inference for tree- and forest-structured graphs with sum-product belief propagation 
</p>
</li>
<li> <p><code><a href="#topic+infer.conditional">infer.conditional</a></code> Conditional inference (takes another inference method as input) 
</p>
</li>
<li> <p><code><a href="#topic+infer.cutset">infer.cutset</a></code> Exact inference for graphs with a small cutset using cutset conditioning 
</p>
</li>
<li> <p><code><a href="#topic+infer.junction">infer.junction</a></code> Exact decoding for low-treewidth graphs using junction trees 
</p>
</li>
<li> <p><code><a href="#topic+infer.sample">infer.sample</a></code> Approximate inference using sampling (takes a sampling method as input) 
</p>
</li>
<li> <p><code><a href="#topic+infer.lbp">infer.lbp</a></code> Approximate inference using sum-product loopy belief propagation 
</p>
</li>
<li> <p><code><a href="#topic+infer.trbp">infer.trbp</a></code> Approximate inference using sum-product tree-reweighted belief propagation 
</p>
</li></ul>

<p>Sampling: Generating samples from the distribution 
</p>
 
<ul>
<li> <p><code><a href="#topic+sample.exact">sample.exact</a></code> Exact sampling for small graphs with brute-force inverse cumulative distribution 
</p>
</li>
<li> <p><code><a href="#topic+sample.chain">sample.chain</a></code> Exact sampling for chain-structured graphs with the forward-filter backward-sample algorithm 
</p>
</li>
<li> <p><code><a href="#topic+sample.tree">sample.tree</a></code> Exact sampling for tree- and forest-structured graphs with sum-product belief propagation and backward-sampling 
</p>
</li>
<li> <p><code><a href="#topic+sample.conditional">sample.conditional</a></code> Conditional sampling (takes another sampling method as input) 
</p>
</li>
<li> <p><code><a href="#topic+sample.cutset">sample.cutset</a></code> Exact sampling for graphs with a small cutset using cutset conditioning 
</p>
</li>
<li> <p><code><a href="#topic+sample.junction">sample.junction</a></code> Exact sampling for low-treewidth graphs using junction trees 
</p>
</li>
<li> <p><code><a href="#topic+sample.gibbs">sample.gibbs</a></code> Approximate sampling using a single-site Gibbs sampler 
</p>
</li></ul>

<p>Training: Given data, computing the most likely estimates of the parameters
</p>

<ul>
<li> <p><code><a href="#topic+train.crf">train.crf</a></code> Train CRF model
</p>
</li>
<li> <p><code><a href="#topic+train.mrf">train.mrf</a></code> Train MRF model
</p>
</li></ul>

<p>Tools: Tools for building and manipulating CRF data
</p>

<ul>
<li> <p><code><a href="#topic+make.crf">make.crf</a></code> Generate CRF from the adjacent matrix
</p>
</li>
<li> <p><code><a href="#topic+make.features">make.features</a></code> Make the data structure of CRF features
</p>
</li>
<li> <p><code><a href="#topic+make.par">make.par</a></code> Make the data structure of CRF parameters
</p>
</li>
<li> <p><code><a href="#topic+duplicate.crf">duplicate.crf</a></code> Duplicate an existing CRF
</p>
</li>
<li> <p><code><a href="#topic+clamp.crf">clamp.crf</a></code> Generate clamped CRF by fixing the states of some nodes
</p>
</li>
<li> <p><code><a href="#topic+clamp.reset">clamp.reset</a></code> Reset clamped CRF by changing the states of clamped nodes
</p>
</li>
<li> <p><code><a href="#topic+sub.crf">sub.crf</a></code> Generate sub CRF by selecting some nodes
</p>
</li>
<li> <p><code><a href="#topic+mrf.update">mrf.update</a></code> Update node and edge potentials of MRF model
</p>
</li>
<li> <p><code><a href="#topic+crf.update">crf.update</a></code> Update node and edge potentials of CRF model
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Ling-Yun Wu <a href="mailto:wulingyun@gmail.com">wulingyun@gmail.com</a>
</p>


<h3>References</h3>

<p>J. Lafferty, A. McCallum, and F. Pereira. Conditional random fields:
Probabilistic models for segmenting and labeling sequence data. In <em>the 
proceedings of International Conference on Machine Learning (ICML)</em>, pp. 282-289, 2001.
</p>
<p>Mark Schmidt. UGM: A Matlab toolbox for probabilistic undirected graphical models.
<a href="http://www.cs.ubc.ca/~schmidtm/Software/UGM.html">http://www.cs.ubc.ca/~schmidtm/Software/UGM.html</a>, 2007.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
decode.exact(Small$crf)
infer.exact(Small$crf)
sample.exact(Small$crf, 100)

</code></pre>

<hr>
<h2 id='Chain'>Chain CRF example</h2><span id='topic+Chain'></span>

<h3>Description</h3>

<p>This data set gives a chain CRF example
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Chain)
</code></pre>


<h3>Format</h3>

<p>A list containing two elements:
</p>

<ul>
<li> <p><code>crf</code> The CRF
</p>
</li>
<li> <p><code>answer</code> A list of 4 elements:
</p>

<ul>
<li> <p><code>decode</code> The most likely configuration
</p>
</li>
<li> <p><code>node.bel</code> The node belief
</p>
</li>
<li> <p><code>edge.bel</code> The edge belief
</p>
</li>
<li> <p><code>logZ</code> The logarithmic value of CRF normalization factor Z
</p>
</li></ul>

</li></ul>

<hr>
<h2 id='clamp.crf'>Make clamped CRF</h2><span id='topic+clamp.crf'></span>

<h3>Description</h3>

<p>Generate clamped CRF by fixing the states of some nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clamp.crf(crf, clamped)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clamp.crf_+3A_crf">crf</code></td>
<td>
<p>The CRF generated by <code><a href="#topic+make.crf">make.crf</a></code></p>
</td></tr>
<tr><td><code id="clamp.crf_+3A_clamped">clamped</code></td>
<td>
<p>The vector of fixed states of nodes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will generate a clamped CRF from a given CRF
by fixing the states of some nodes. The vector <code>clamped</code>
contains the desired state for each node while zero means the state is not
fixed. The node and edge potentials are updated to the conditional
potentials based on the clamped vector.
</p>


<h3>Value</h3>

<p>The function will return a new CRF with additional components: 
</p>
<table>
<tr><td><code>original</code></td>
<td>
<p>The original CRF.</p>
</td></tr> 
<tr><td><code>clamped</code></td>
<td>
<p>The vector of fixed states of nodes.</p>
</td></tr> 
<tr><td><code>node.id</code></td>
<td>
<p>The vector of the original node ids for nodes in the new CRF.</p>
</td></tr> 
<tr><td><code>node.map</code></td>
<td>
<p>The vector of the new node ids for nodes in the original CRF.</p>
</td></tr> 
<tr><td><code>edge.id</code></td>
<td>
<p>The vector of the original edge ids for edges in the new CRF.</p>
</td></tr> 
<tr><td><code>edge.map</code></td>
<td>
<p>The vector of the new edge ids for edges in the original CRF.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+make.crf">make.crf</a></code>, <code><a href="#topic+sub.crf">sub.crf</a></code>, <code><a href="#topic+clamp.reset">clamp.reset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
crf &lt;- clamp.crf(Small$crf, c(0, 0, 1, 1))


</code></pre>

<hr>
<h2 id='clamp.reset'>Reset clamped CRF</h2><span id='topic+clamp.reset'></span>

<h3>Description</h3>

<p>Reset clamped CRF by changing the states of clamped nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clamp.reset(crf, clamped)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clamp.reset_+3A_crf">crf</code></td>
<td>
<p>The clamped CRF generated by <code><a href="#topic+clamp.crf">clamp.crf</a></code></p>
</td></tr>
<tr><td><code id="clamp.reset_+3A_clamped">clamped</code></td>
<td>
<p>The vector of fixed states of nodes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will reset a clamped CRF by changing the states of fixed nodes.
The vector <code>clamped</code> contains the desired state for each node 
while zero means the state is not fixed. The node and edge potentials are 
updated to the conditional potentials based on the clamped vector.
</p>


<h3>Value</h3>

<p>The function will return the same clamped CRF.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+make.crf">make.crf</a></code>, <code><a href="#topic+clamp.crf">clamp.crf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
crf &lt;- clamp.crf(Small$crf, c(0, 0, 1, 1))
clamp.reset(crf, c(0,0,2,2))


</code></pre>

<hr>
<h2 id='Clique'>Clique CRF example</h2><span id='topic+Clique'></span>

<h3>Description</h3>

<p>This data set gives a clique CRF example
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Clique)
</code></pre>


<h3>Format</h3>

<p>A list containing two elements:
</p>

<ul>
<li> <p><code>crf</code> The CRF
</p>
</li>
<li> <p><code>answer</code> A list of 4 elements:
</p>

<ul>
<li> <p><code>decode</code> The most likely configuration
</p>
</li>
<li> <p><code>node.bel</code> The node belief
</p>
</li>
<li> <p><code>edge.bel</code> The edge belief
</p>
</li>
<li> <p><code>logZ</code> The logarithmic value of CRF normalization factor Z
</p>
</li></ul>

</li></ul>

<hr>
<h2 id='crf.nll'>Calculate CRF negative log likelihood</h2><span id='topic+crf.nll'></span>

<h3>Description</h3>

<p>Calculate the negative log likelihood of CRF model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf.nll(
  par,
  crf,
  instances,
  node.fea = NULL,
  edge.fea = NULL,
  node.ext = NULL,
  edge.ext = NULL,
  infer.method = infer.chain,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf.nll_+3A_par">par</code></td>
<td>
<p>The parameter vector of CRF</p>
</td></tr>
<tr><td><code id="crf.nll_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="crf.nll_+3A_instances">instances</code></td>
<td>
<p>The training data matrix of CRF model</p>
</td></tr>
<tr><td><code id="crf.nll_+3A_node.fea">node.fea</code></td>
<td>
<p>The list of node features</p>
</td></tr>
<tr><td><code id="crf.nll_+3A_edge.fea">edge.fea</code></td>
<td>
<p>The list of edge features</p>
</td></tr>
<tr><td><code id="crf.nll_+3A_node.ext">node.ext</code></td>
<td>
<p>The list of extended information of node features</p>
</td></tr>
<tr><td><code id="crf.nll_+3A_edge.ext">edge.ext</code></td>
<td>
<p>The list of extended information of edge features</p>
</td></tr>
<tr><td><code id="crf.nll_+3A_infer.method">infer.method</code></td>
<td>
<p>The inference method used to compute the likelihood</p>
</td></tr>
<tr><td><code id="crf.nll_+3A_...">...</code></td>
<td>
<p>Extra parameters need by the inference method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the negative log likelihood of CRF model as well as
the gradient. This function is intended to be called by optimization algorithm
in training process.
</p>
<p>In the training data matrix <code>instances</code>, each row is an instance and 
each column corresponds a node in CRF.
The variables <code>node.fea</code>, <code>edge.fea</code>, <code>node.ext</code>, <code>edge.ext</code>
are lists of length equal to the number of instances, and their elements are
defined as in <code><a href="#topic+crf.update">crf.update</a></code> respectively.
</p>


<h3>Value</h3>

<p>This function will return the value of CRF negative log-likelihood.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crf.update">crf.update</a></code>, <code><a href="#topic+train.crf">train.crf</a></code>
</p>

<hr>
<h2 id='crf.update'>Update CRF potentials</h2><span id='topic+crf.update'></span>

<h3>Description</h3>

<p>Update node and edge potentials of CRF model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf.update(
  crf,
  node.fea = NULL,
  edge.fea = NULL,
  node.ext = NULL,
  edge.ext = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf.update_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="crf.update_+3A_node.fea">node.fea</code></td>
<td>
<p>The node features matrix with dimension <code>(n.nf, n.nodes)</code></p>
</td></tr>
<tr><td><code id="crf.update_+3A_edge.fea">edge.fea</code></td>
<td>
<p>The edge features matrix with dimension <code>(n.ef, n.edges)</code></p>
</td></tr>
<tr><td><code id="crf.update_+3A_node.ext">node.ext</code></td>
<td>
<p>The extended information of node features</p>
</td></tr>
<tr><td><code id="crf.update_+3A_edge.ext">edge.ext</code></td>
<td>
<p>The extended information of edge features</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function updates <code>node.pot</code> and <code>edge.pot</code> of CRF model by using 
the current values of parameters and features.
</p>
<p>There are two ways to model the relationship between parameters and features.
The first one exploits the special structure of features to reduce the memory
usage. However it may not suitable for all circumstances. The other one is more 
straighforward by explicitly specifying the coefficients of each parameter to
calculate the potentials, and may use much more memory. Two approaches can be
used together.
</p>
<p>The first way uses the objects <code>node.par</code> and <code>edge.par</code> to define
the structure of features and provides the feature information in variables
<code>node.fea</code> and <code>edge.fea</code>. The second way directly provides the
feature information in variables <code>node.ext</code> and <code>edge.ext</code> without
any prior assumption on feature structure. <code>node.ext</code> is a list and
each element has the same structure as <code>node.pot</code>. <code>edge.ext</code> is
a list and each element has the same structure as <code>edge.pot</code>.
</p>
<p>In detail, the node potential is updated as follows:
</p>
<p style="text-align: center;"><code class="reqn">
node.pot[n,i] = exp( \sum_{f} par[node.par[n,i,f]] * node.fea[f,n] + \sum_{k} par[k] * node.ext[[k]][n,i] )
</code>
</p>

<p>and the edge potential is updated as follows:
</p>
<p style="text-align: center;"><code class="reqn">
edge.pot[[e]][i,j] = exp( \sum_{f} par[edge.par[[e]][i,j,f]] * edge.fea[f,e] + \sum_{k} par[k] * edge.ext[[k]][[e]][i,j] )
</code>
</p>



<h3>Value</h3>

<p>This function will directly modify the CRF and return the same CRF.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crf.nll">crf.nll</a></code>, <code><a href="#topic+train.crf">train.crf</a></code>
</p>

<hr>
<h2 id='decode.block'>Decoding method using block iterated conditional modes algorithm</h2><span id='topic+decode.block'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.block(
  crf,
  blocks,
  decode.method = decode.tree,
  restart = 0,
  start = apply(crf$node.pot, 1, which.max),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.block_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.block_+3A_blocks">blocks</code></td>
<td>
<p>A list of vectors, each vector containing the nodes in a block</p>
</td></tr>
<tr><td><code id="decode.block_+3A_decode.method">decode.method</code></td>
<td>
<p>The decoding method to solve the clamped CRF</p>
</td></tr>
<tr><td><code id="decode.block_+3A_restart">restart</code></td>
<td>
<p>Non-negative integer to control how many restart iterations are repeated</p>
</td></tr>
<tr><td><code id="decode.block_+3A_start">start</code></td>
<td>
<p>An initial configuration, a good start will significantly reduce the seraching time</p>
</td></tr>
<tr><td><code id="decode.block_+3A_...">...</code></td>
<td>
<p>The parameters for <code>decode.method</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate decoding with the block iterated conditional modes algorithm
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.block(Small$crf, list(c(1,3), c(2,4)))

</code></pre>

<hr>
<h2 id='decode.chain'>Decoding method for chain-structured graphs</h2><span id='topic+decode.chain'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.chain(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.chain_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact decoding for chain-structured graphs with the Viterbi algorithm.
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.chain(Small$crf)

</code></pre>

<hr>
<h2 id='decode.conditional'>Conditional decoding method</h2><span id='topic+decode.conditional'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.conditional(crf, clamped, decode.method, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.conditional_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.conditional_+3A_clamped">clamped</code></td>
<td>
<p>The vector of fixed values for clamped nodes, 0 for unfixed nodes</p>
</td></tr>
<tr><td><code id="decode.conditional_+3A_decode.method">decode.method</code></td>
<td>
<p>The decoding method to solve clamped CRF</p>
</td></tr>
<tr><td><code id="decode.conditional_+3A_...">...</code></td>
<td>
<p>The parameters for <code>decode.method</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conditional decoding (takes another decoding method as input)
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.conditional(Small$crf, c(0,1,0,0), decode.exact)

</code></pre>

<hr>
<h2 id='decode.cutset'>Decoding method for graphs with a small cutset</h2><span id='topic+decode.cutset'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.cutset(
  crf,
  cutset,
  engine = "default",
  start = apply(crf$node.pot, 1, which.max)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.cutset_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.cutset_+3A_cutset">cutset</code></td>
<td>
<p>A vector of nodes in the cutset</p>
</td></tr>
<tr><td><code id="decode.cutset_+3A_engine">engine</code></td>
<td>
<p>The underlying engine for cutset decoding, possible values are &quot;default&quot;, &quot;none&quot;, &quot;exact&quot;, &quot;chain&quot;, and &quot;tree&quot;.</p>
</td></tr>
<tr><td><code id="decode.cutset_+3A_start">start</code></td>
<td>
<p>An initial configuration, a good start will significantly reduce the seraching time</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact decoding for graphs with a small cutset using cutset conditioning
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.cutset(Small$crf, c(2))

</code></pre>

<hr>
<h2 id='decode.exact'>Decoding method for small graphs</h2><span id='topic+decode.exact'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.exact(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.exact_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact decoding for small graphs with brute-force search
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.exact(Small$crf)

</code></pre>

<hr>
<h2 id='decode.greedy'>Decoding method using greedy algorithm</h2><span id='topic+decode.greedy'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.greedy(crf, restart = 0, start = apply(crf$node.pot, 1, which.max))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.greedy_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.greedy_+3A_restart">restart</code></td>
<td>
<p>Non-negative integer to control how many restart iterations are repeated</p>
</td></tr>
<tr><td><code id="decode.greedy_+3A_start">start</code></td>
<td>
<p>An initial configuration, a good start will significantly reduce the seraching time</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate decoding with greedy algorithm
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.greedy(Small$crf)

</code></pre>

<hr>
<h2 id='decode.icm'>Decoding method using iterated conditional modes algorithm</h2><span id='topic+decode.icm'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.icm(crf, restart = 0, start = apply(crf$node.pot, 1, which.max))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.icm_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.icm_+3A_restart">restart</code></td>
<td>
<p>Non-negative integer to control how many restart iterations are repeated</p>
</td></tr>
<tr><td><code id="decode.icm_+3A_start">start</code></td>
<td>
<p>An initial configuration, a good start will significantly reduce the seraching time</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate decoding with the iterated conditional modes algorithm
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.icm(Small$crf)

</code></pre>

<hr>
<h2 id='decode.ilp'>Decoding method using integer linear programming</h2><span id='topic+decode.ilp'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.ilp(crf, lp.rounding = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.ilp_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.ilp_+3A_lp.rounding">lp.rounding</code></td>
<td>
<p>Boolean variable to indicate whether LP rounding is need.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact decoding with an integer linear programming formulation and approximate using LP relaxation
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
library(CRF)
data(Small)
d &lt;- decode.ilp(Small$crf)

## End(Not run)

</code></pre>

<hr>
<h2 id='decode.junction'>Decoding method for low-treewidth graphs</h2><span id='topic+decode.junction'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.junction(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.junction_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact decoding for low-treewidth graphs using junction trees
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.junction(Small$crf)

</code></pre>

<hr>
<h2 id='decode.lbp'>Decoding method using loopy belief propagation</h2><span id='topic+decode.lbp'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.lbp(crf, max.iter = 10000, cutoff = 1e-04, verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.lbp_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.lbp_+3A_max.iter">max.iter</code></td>
<td>
<p>The maximum allowed iterations of termination criteria</p>
</td></tr>
<tr><td><code id="decode.lbp_+3A_cutoff">cutoff</code></td>
<td>
<p>The convergence cutoff of termination criteria</p>
</td></tr>
<tr><td><code id="decode.lbp_+3A_verbose">verbose</code></td>
<td>
<p>Non-negative integer to control the tracing informtion in algorithm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate decoding using max-product loopy belief propagation
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.lbp(Small$crf)

</code></pre>

<hr>
<h2 id='decode.marginal'>Decoding method using inference</h2><span id='topic+decode.marginal'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.marginal(crf, infer.method, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.marginal_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.marginal_+3A_infer.method">infer.method</code></td>
<td>
<p>The inference method</p>
</td></tr>
<tr><td><code id="decode.marginal_+3A_...">...</code></td>
<td>
<p>The parameters for <code>infer.method</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate decoding using inference (takes an inference method as input)
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.marginal(Small$crf, infer.exact)

</code></pre>

<hr>
<h2 id='decode.rbp'>Decoding method using residual belief propagation</h2><span id='topic+decode.rbp'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.rbp(crf, max.iter = 10000, cutoff = 1e-04, verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.rbp_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.rbp_+3A_max.iter">max.iter</code></td>
<td>
<p>The maximum allowed iterations of termination criteria</p>
</td></tr>
<tr><td><code id="decode.rbp_+3A_cutoff">cutoff</code></td>
<td>
<p>The convergence cutoff of termination criteria</p>
</td></tr>
<tr><td><code id="decode.rbp_+3A_verbose">verbose</code></td>
<td>
<p>Non-negative integer to control the tracing informtion in algorithm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate decoding using max-product residual belief propagation
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.rbp(Small$crf)

</code></pre>

<hr>
<h2 id='decode.sample'>Decoding method using sampling</h2><span id='topic+decode.sample'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.sample(crf, sample.method, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.sample_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.sample_+3A_sample.method">sample.method</code></td>
<td>
<p>The sampling method</p>
</td></tr>
<tr><td><code id="decode.sample_+3A_...">...</code></td>
<td>
<p>The parameters for <code>sample.method</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate decoding using sampling (takes a sampling method as input)
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.sample(Small$crf, sample.exact, 10000)

</code></pre>

<hr>
<h2 id='decode.trbp'>Decoding method using tree-reweighted belief propagation</h2><span id='topic+decode.trbp'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.trbp(crf, max.iter = 10000, cutoff = 1e-04, verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.trbp_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="decode.trbp_+3A_max.iter">max.iter</code></td>
<td>
<p>The maximum allowed iterations of termination criteria</p>
</td></tr>
<tr><td><code id="decode.trbp_+3A_cutoff">cutoff</code></td>
<td>
<p>The convergence cutoff of termination criteria</p>
</td></tr>
<tr><td><code id="decode.trbp_+3A_verbose">verbose</code></td>
<td>
<p>Non-negative integer to control the tracing informtion in algorithm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate decoding using max-product tree-reweighted belief propagtion
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.trbp(Small$crf)

</code></pre>

<hr>
<h2 id='decode.tree'>Decoding method for tree- and forest-structured graphs</h2><span id='topic+decode.tree'></span>

<h3>Description</h3>

<p>Computing the most likely configuration for CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode.tree(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode.tree_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact decoding for tree- and forest-structured graphs with max-product belief propagation
</p>


<h3>Value</h3>

<p>This function will return the most likely configuration, which is a vector of length <code>crf$n.nodes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
d &lt;- decode.tree(Small$crf)

</code></pre>

<hr>
<h2 id='duplicate.crf'>Duplicate CRF</h2><span id='topic+duplicate.crf'></span>

<h3>Description</h3>

<p>Duplicate an existing CRF
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplicate.crf(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duplicate.crf_+3A_crf">crf</code></td>
<td>
<p>The existing CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will duplicate an existing CRF. Since CRF is implemented as an
environment, normal assignment will only copy the pointer instead of the 
real data. This function will generate a new CRF and really copy all data.
</p>


<h3>Value</h3>

<p>The function will return a new CRF with copied data
</p>


<h3>See Also</h3>

<p><code><a href="#topic+make.crf">make.crf</a></code>
</p>

<hr>
<h2 id='get.logPotential'>Calculate the log-potential of CRF</h2><span id='topic+get.logPotential'></span>

<h3>Description</h3>

<p>Calculate the logarithmic potential of a CRF with given configuration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.logPotential(crf, configuration)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.logPotential_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="get.logPotential_+3A_configuration">configuration</code></td>
<td>
<p>The vector of states of nodes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will calculate the logarithmic potential of a CRF with given configuration,
i.e., the assigned states of nodes in the CRF.
</p>


<h3>Value</h3>

<p>The function will return the log-potential of CRF with given configuration
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get.potential">get.potential</a></code>
</p>

<hr>
<h2 id='get.potential'>Calculate the potential of CRF</h2><span id='topic+get.potential'></span>

<h3>Description</h3>

<p>Calculate the potential of a CRF with given configuration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.potential(crf, configuration)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.potential_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="get.potential_+3A_configuration">configuration</code></td>
<td>
<p>The vector of states of nodes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will calculate the potential of a CRF with given configuration,
i.e., the assigned states of nodes in the CRF.
</p>


<h3>Value</h3>

<p>The function will return the potential of CRF with given configuration
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get.logPotential">get.logPotential</a></code>
</p>

<hr>
<h2 id='infer.chain'>Inference method for chain-structured graphs</h2><span id='topic+infer.chain'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.chain(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.chain_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact inference for chain-structured graphs with the forward-backward algorithm
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.chain(Small$crf)

</code></pre>

<hr>
<h2 id='infer.conditional'>Conditional inference method</h2><span id='topic+infer.conditional'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.conditional(crf, clamped, infer.method, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.conditional_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="infer.conditional_+3A_clamped">clamped</code></td>
<td>
<p>The vector of fixed values for clamped nodes, 0 for unfixed nodes</p>
</td></tr>
<tr><td><code id="infer.conditional_+3A_infer.method">infer.method</code></td>
<td>
<p>The inference method to solve the clamped CRF</p>
</td></tr>
<tr><td><code id="infer.conditional_+3A_...">...</code></td>
<td>
<p>The parameters for <code>infer.method</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conditional inference (takes another inference method as input)
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.conditional(Small$crf, c(0,1,0,0), infer.exact)

</code></pre>

<hr>
<h2 id='infer.cutset'>Inference method for graphs with a small cutset</h2><span id='topic+infer.cutset'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.cutset(crf, cutset, engine = "default")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.cutset_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="infer.cutset_+3A_cutset">cutset</code></td>
<td>
<p>A vector of nodes in the cutset</p>
</td></tr>
<tr><td><code id="infer.cutset_+3A_engine">engine</code></td>
<td>
<p>The underlying engine for cutset decoding, possible values are &quot;default&quot;, &quot;none&quot;, &quot;exact&quot;, &quot;chain&quot;, and &quot;tree&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact inference for graphs with a small cutset using cutset conditioning
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.cutset(Small$crf, c(2))

</code></pre>

<hr>
<h2 id='infer.exact'>Inference method for small graphs</h2><span id='topic+infer.exact'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.exact(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.exact_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact inference for small graphs with brute-force counting
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.exact(Small$crf)

</code></pre>

<hr>
<h2 id='infer.junction'>Inference method for low-treewidth graphs</h2><span id='topic+infer.junction'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.junction(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.junction_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact decoding for low-treewidth graphs using junction trees
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.junction(Small$crf)

</code></pre>

<hr>
<h2 id='infer.lbp'>Inference method using loopy belief propagation</h2><span id='topic+infer.lbp'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.lbp(crf, max.iter = 10000, cutoff = 1e-04, verbose = 0, maximize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.lbp_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="infer.lbp_+3A_max.iter">max.iter</code></td>
<td>
<p>The maximum allowed iterations of termination criteria</p>
</td></tr>
<tr><td><code id="infer.lbp_+3A_cutoff">cutoff</code></td>
<td>
<p>The convergence cutoff of termination criteria</p>
</td></tr>
<tr><td><code id="infer.lbp_+3A_verbose">verbose</code></td>
<td>
<p>Non-negative integer to control the tracing informtion in algorithm</p>
</td></tr>
<tr><td><code id="infer.lbp_+3A_maximize">maximize</code></td>
<td>
<p>Logical variable to indicate using max-product instead of sum-product</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate inference using sum-product loopy belief propagation
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.lbp(Small$crf)

</code></pre>

<hr>
<h2 id='infer.rbp'>Inference method using residual belief propagation</h2><span id='topic+infer.rbp'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.rbp(crf, max.iter = 10000, cutoff = 1e-04, verbose = 0, maximize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.rbp_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="infer.rbp_+3A_max.iter">max.iter</code></td>
<td>
<p>The maximum allowed iterations of termination criteria</p>
</td></tr>
<tr><td><code id="infer.rbp_+3A_cutoff">cutoff</code></td>
<td>
<p>The convergence cutoff of termination criteria</p>
</td></tr>
<tr><td><code id="infer.rbp_+3A_verbose">verbose</code></td>
<td>
<p>Non-negative integer to control the tracing informtion in algorithm</p>
</td></tr>
<tr><td><code id="infer.rbp_+3A_maximize">maximize</code></td>
<td>
<p>Logical variable to indicate using max-product instead of sum-product</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate inference using sum-product residual belief propagation
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.rbp(Small$crf)

</code></pre>

<hr>
<h2 id='infer.sample'>Inference method using sampling</h2><span id='topic+infer.sample'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.sample(crf, sample.method, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.sample_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="infer.sample_+3A_sample.method">sample.method</code></td>
<td>
<p>The sampling method</p>
</td></tr>
<tr><td><code id="infer.sample_+3A_...">...</code></td>
<td>
<p>The parameters for <code>sample.method</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate inference using sampling (takes a sampling method as input)
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.sample(Small$crf, sample.exact, 10000)

</code></pre>

<hr>
<h2 id='infer.trbp'>Inference method using tree-reweighted belief propagation</h2><span id='topic+infer.trbp'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.trbp(
  crf,
  max.iter = 10000,
  cutoff = 1e-04,
  verbose = 0,
  maximize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.trbp_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="infer.trbp_+3A_max.iter">max.iter</code></td>
<td>
<p>The maximum allowed iterations of termination criteria</p>
</td></tr>
<tr><td><code id="infer.trbp_+3A_cutoff">cutoff</code></td>
<td>
<p>The convergence cutoff of termination criteria</p>
</td></tr>
<tr><td><code id="infer.trbp_+3A_verbose">verbose</code></td>
<td>
<p>Non-negative integer to control the tracing informtion in algorithm</p>
</td></tr>
<tr><td><code id="infer.trbp_+3A_maximize">maximize</code></td>
<td>
<p>Logical variable to indicate using max-product instead of sum-product</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate inference using sum-product tree-reweighted belief propagation
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.trbp(Small$crf)

</code></pre>

<hr>
<h2 id='infer.tree'>Inference method for tree- and forest-structured graphs</h2><span id='topic+infer.tree'></span>

<h3>Description</h3>

<p>Computing the partition function and marginal probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer.tree(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer.tree_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact inference for tree- and forest-structured graphs with sum-product belief propagation
</p>


<h3>Value</h3>

<p>This function will return a list with components:
</p>
<table>
<tr><td><code>node.bel</code></td>
<td>
<p>Node belief. It is a matrix with <code>crf$n.nodes</code> rows and <code>crf$max.state</code> columns.</p>
</td></tr>
<tr><td><code>edge.bel</code></td>
<td>
<p>Edge belief. It is a list of matrices. The size of list is <code>crf$n.edges</code> and 
the matrix <code>i</code> has <code>crf$n.states[crf$edges[i,1]]</code> rows and <code>crf$n.states[crf$edges[i,2]]</code> columns.</p>
</td></tr>
<tr><td><code>logZ</code></td>
<td>
<p>The logarithmic value of CRF normalization factor Z.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
i &lt;- infer.tree(Small$crf)

</code></pre>

<hr>
<h2 id='Loop'>Loop CRF example</h2><span id='topic+Loop'></span>

<h3>Description</h3>

<p>This data set gives a loop CRF example
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Loop)
</code></pre>


<h3>Format</h3>

<p>A list containing two elements:
</p>

<ul>
<li> <p><code>crf</code> The CRF
</p>
</li>
<li> <p><code>answer</code> A list of 4 elements:
</p>

<ul>
<li> <p><code>decode</code> The most likely configuration
</p>
</li>
<li> <p><code>node.bel</code> The node belief
</p>
</li>
<li> <p><code>edge.bel</code> The edge belief
</p>
</li>
<li> <p><code>logZ</code> The logarithmic value of CRF normalization factor Z
</p>
</li></ul>

</li></ul>

<hr>
<h2 id='make.crf'>Make CRF</h2><span id='topic+make.crf'></span>

<h3>Description</h3>

<p>Generate CRF from the adjacent matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.crf(adj.matrix = NULL, n.states = 2, n.nodes = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.crf_+3A_adj.matrix">adj.matrix</code></td>
<td>
<p>The adjacent matrix of CRF network.</p>
</td></tr>
<tr><td><code id="make.crf_+3A_n.states">n.states</code></td>
<td>
<p>The state numbers of nodes.</p>
</td></tr>
<tr><td><code id="make.crf_+3A_n.nodes">n.nodes</code></td>
<td>
<p>The number of nodes, which is only used to generate linear chain CRF when <code>adj.matrix</code> is NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will generate an empty CRF from a given adjacent
matrix. If the length of <code>nstates</code> is less than <code>n.nodes</code>, it will
be used repeatly. All node and edge potentials are initilized as 1.
</p>
<p>Since the CRF data are often very huge, CRF is implemented as an environment.
The assignment of environments will only copy the addresses instead of real data,
therefore the variables using normal assignment will refer to the exactly same CRF.
For complete duplication of the data, please use <code><a href="#topic+duplicate.crf">duplicate.crf</a></code>.
</p>


<h3>Value</h3>

<p>The function will return a new CRF, which is an environment with
components: 
</p>
<table>
<tr><td><code>n.nodes</code></td>
<td>
<p>The number of nodes.</p>
</td></tr> 
<tr><td><code>n.edges</code></td>
<td>
<p>The number of edges.</p>
</td></tr> 
<tr><td><code>n.states</code></td>
<td>
<p>The number of states for each node. It is a vector of length <code>n.nodes</code>.</p>
</td></tr> 
<tr><td><code>max.state</code></td>
<td>
<p>The maximum number of states. It is equal to <code>max(n.states)</code>.</p>
</td></tr> 
<tr><td><code>edges</code></td>
<td>
<p>The node pair of each edge. It is a matrix with 2 columns and <code>n.edges</code> rows. Each row
denotes one edge. The node with smaller id is put in the first column.</p>
</td></tr>
<tr><td><code>n.adj</code></td>
<td>
<p>The number of adjacent nodes for each node. It is a vector of length <code>n.nodes</code>.</p>
</td></tr> 
<tr><td><code>adj.nodes</code></td>
<td>
<p>The list of adjacent nodes for each
node. It is a list of length <code>n.nodes</code> and the i-th element is a vector
of length <code>n.adj[i]</code>.</p>
</td></tr> 
<tr><td><code>adj.edges</code></td>
<td>
<p>The list of adjacent edges for each node. It is similiar to <code>adj.nodes</code>
while contains the edge ids instead of node ids.</p>
</td></tr> 
<tr><td><code>node.pot</code></td>
<td>
<p>The node potentials. It is a matrix with dimmension <code>(n.nodes, max.state)</code>.
Each row <code>node.pot[i,]</code> denotes the node potentials of the i-th node.</p>
</td></tr> 
<tr><td><code>edge.pot</code></td>
<td>
<p>The edge potentials. It is a list of <code>n.edges</code> matrixes. Each matrix
<code>edge.pot[[i]]</code>, with dimension <code>(n.states[edges[i,1]],
    n.states[edges[i,2]])</code>, denotes the edge potentials of the i-th edge.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+duplicate.crf">duplicate.crf</a></code>, <code><a href="#topic+clamp.crf">clamp.crf</a></code>, <code><a href="#topic+sub.crf">sub.crf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)

nNodes &lt;- 4
nStates &lt;- 2

adj &lt;- matrix(0, nrow=nNodes, ncol=nNodes)
for (i in 1:(nNodes-1))
{
	adj[i,i+1] &lt;- 1
	adj[i+1,i] &lt;- 1
}

crf &lt;- make.crf(adj, nStates)

crf$node.pot[1,] &lt;- c(1, 3)
crf$node.pot[2,] &lt;- c(9, 1)
crf$node.pot[3,] &lt;- c(1, 3)
crf$node.pot[4,] &lt;- c(9, 1)

for (i in 1:crf$n.edges)
{
   crf$edge.pot[[i]][1,] &lt;- c(2, 1)
   crf$edge.pot[[i]][2,] &lt;- c(1, 2)
}

</code></pre>

<hr>
<h2 id='make.features'>Make CRF features</h2><span id='topic+make.features'></span>

<h3>Description</h3>

<p>Make the data structure of CRF features
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.features(crf, n.nf = 1, n.ef = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.features_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="make.features_+3A_n.nf">n.nf</code></td>
<td>
<p>The number of node features</p>
</td></tr>
<tr><td><code id="make.features_+3A_n.ef">n.ef</code></td>
<td>
<p>The number of edge features</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes the data structure of features need for modeling and training CRF.
</p>
<p>The parameters <code>n.nf</code> and <code>n.ef</code> specify the number of node and edge features,
respectively.
</p>
<p>The objects <code>node.par</code> and <code>edge.par</code> define the corresponding
parameters used with each feature. <code>node.par</code> is a 3-dimensional arrays, 
and element <code>node.par[n,i,f]</code> is the index of parameter associated with the 
corresponding node potential <code>node.pot[n,i]</code> and node feature <code>f</code>.
<code>edge.par</code> is a list of 3-dimensional arrays, and element 
<code>edge.par[[e]][i,j,f]</code> is the index of parameter associated with the 
corresponding edge potential <code>edge.pot[[e]][i,j]</code> and edge feature <code>f</code>.
The value 0 is used to indicate the corresponding node or edge potential 
does not depend on that feature.
</p>
<p>For detail of calculation of node and edge potentials from features and parameters,
please see <code><a href="#topic+crf.update">crf.update</a></code>.
</p>


<h3>Value</h3>

<p>This function will directly modify the CRF and return the same CRF.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crf.update">crf.update</a></code>, <code><a href="#topic+make.par">make.par</a></code>, <code><a href="#topic+make.crf">make.crf</a></code>
</p>

<hr>
<h2 id='make.par'>Make CRF parameters</h2><span id='topic+make.par'></span>

<h3>Description</h3>

<p>Make the data structure of CRF parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.par(crf, n.par = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.par_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="make.par_+3A_n.par">n.par</code></td>
<td>
<p>The number of parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes the data structure of parameters need for modeling and training CRF.
The parameters are stored in <code>par</code>, which is a numeric vector of length <code>n.par</code>.
</p>


<h3>Value</h3>

<p>This function will directly modify the CRF and return the same CRF.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crf.update">crf.update</a></code>, <code><a href="#topic+make.features">make.features</a></code>, <code><a href="#topic+make.crf">make.crf</a></code>
</p>

<hr>
<h2 id='mrf.nll'>Calculate MRF negative log-likelihood</h2><span id='topic+mrf.nll'></span>

<h3>Description</h3>

<p>Calculate the negative log-likelihood of MRF model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrf.nll(par, crf, instances, infer.method = infer.chain, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mrf.nll_+3A_par">par</code></td>
<td>
<p>The parameter vector of CRF</p>
</td></tr>
<tr><td><code id="mrf.nll_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="mrf.nll_+3A_instances">instances</code></td>
<td>
<p>The training data matrix of MRF model</p>
</td></tr>
<tr><td><code id="mrf.nll_+3A_infer.method">infer.method</code></td>
<td>
<p>The inference method used to compute the likelihood</p>
</td></tr>
<tr><td><code id="mrf.nll_+3A_...">...</code></td>
<td>
<p>Extra parameters need by the inference method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the negative log-likelihood of MRF model as well as 
the gradient. This function is intended to be called by optimization algorithm
in training process. Before calling this function, the MRF sufficient 
statistics must be calculated and stored in object <code>par.stat</code> of CRF.
</p>
<p>In the training data matrix <code>instances</code>, each row is an instance and 
each column corresponds a node in CRF.
</p>


<h3>Value</h3>

<p>This function will return the value of MRF negative log-likilihood.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mrf.stat">mrf.stat</a></code>, <code><a href="#topic+mrf.update">mrf.update</a></code>, <code><a href="#topic+train.mrf">train.mrf</a></code>
</p>

<hr>
<h2 id='mrf.stat'>Calculate MRF sufficient statistics</h2><span id='topic+mrf.stat'></span>

<h3>Description</h3>

<p>Calculate the sufficient statistics of MRF model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrf.stat(crf, instances)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mrf.stat_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="mrf.stat_+3A_instances">instances</code></td>
<td>
<p>The training data matrix of MRF model</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the sufficient statistics of MRF model. This function
much be called before the first calling to <code><a href="#topic+mrf.nll">mrf.nll</a></code>. 
In the training data matrix <code>instances</code>, each row is an instance and 
each column corresponds a node in CRF.
</p>


<h3>Value</h3>

<p>This function will return the value of MRF sufficient statistics.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mrf.nll">mrf.nll</a></code>, <code><a href="#topic+train.mrf">train.mrf</a></code>
</p>

<hr>
<h2 id='mrf.update'>Update MRF potentials</h2><span id='topic+mrf.update'></span>

<h3>Description</h3>

<p>Update node and edge potentials of MRF model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrf.update(crf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mrf.update_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function updates <code>node.pot</code> and <code>edge.pot</code> of MRF model.
</p>


<h3>Value</h3>

<p>This function will directly modify the CRF and return the same CRF.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mrf.nll">mrf.nll</a></code>, <code><a href="#topic+train.mrf">train.mrf</a></code>
</p>

<hr>
<h2 id='Rain'>Rain data</h2><span id='topic+Rain'></span>

<h3>Description</h3>

<p>This data set gives an example of rain data used to train CRF and MRF models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Rain)
</code></pre>


<h3>Format</h3>

<p>A list containing two elements:
</p>

<ul>
<li> <p><code>rain</code> A matrix of 28 columns containing raining data (1: rain, 2: sunny).
Each row is an instance of 28 days for one month.
</p>
</li>
<li> <p><code>months</code> A vector containing the months of each instance.
</p>
</li></ul>


<h3>References</h3>

<p>Mark Schmidt. UGM: A Matlab toolbox for probabilistic undirected graphical models.
<a href="http://www.cs.ubc.ca/~schmidtm/Software/UGM.html">http://www.cs.ubc.ca/~schmidtm/Software/UGM.html</a>, 2007.
</p>

<hr>
<h2 id='sample.chain'>Sampling method for chain-structured graphs</h2><span id='topic+sample.chain'></span>

<h3>Description</h3>

<p>Generating samples from the distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.chain(crf, size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample.chain_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="sample.chain_+3A_size">size</code></td>
<td>
<p>The sample size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact sampling for chain-structured graphs with the forward-filter backward-sample algorithm
</p>


<h3>Value</h3>

<p>This function will return a matrix with <code>size</code> rows and <code>crf$n.nodes</code> columns,
in which each row is a sampled configuration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
s &lt;- sample.chain(Small$crf, 100)

</code></pre>

<hr>
<h2 id='sample.conditional'>Conditional sampling method</h2><span id='topic+sample.conditional'></span>

<h3>Description</h3>

<p>Generating samples from the distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.conditional(crf, size, clamped, sample.method, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample.conditional_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="sample.conditional_+3A_size">size</code></td>
<td>
<p>The sample size</p>
</td></tr>
<tr><td><code id="sample.conditional_+3A_clamped">clamped</code></td>
<td>
<p>The vector of fixed values for clamped nodes, 0 for unfixed nodes</p>
</td></tr>
<tr><td><code id="sample.conditional_+3A_sample.method">sample.method</code></td>
<td>
<p>The sampling method to solve the clamped CRF</p>
</td></tr>
<tr><td><code id="sample.conditional_+3A_...">...</code></td>
<td>
<p>The parameters for <code>sample.method</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conditional sampling (takes another sampling method as input)
</p>


<h3>Value</h3>

<p>This function will return a matrix with <code>size</code> rows and <code>crf$n.nodes</code> columns,
in which each row is a sampled configuration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
s &lt;- sample.conditional(Small$crf, 100, c(0,1,0,0), sample.exact)

</code></pre>

<hr>
<h2 id='sample.cutset'>Sampling method for graphs with a small cutset</h2><span id='topic+sample.cutset'></span>

<h3>Description</h3>

<p>Generating samples from the distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.cutset(crf, size, cutset, engine = "default")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample.cutset_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="sample.cutset_+3A_size">size</code></td>
<td>
<p>The sample size</p>
</td></tr>
<tr><td><code id="sample.cutset_+3A_cutset">cutset</code></td>
<td>
<p>A vector of nodes in the cutset</p>
</td></tr>
<tr><td><code id="sample.cutset_+3A_engine">engine</code></td>
<td>
<p>The underlying engine for cutset sampling, possible values are &quot;default&quot;, &quot;none&quot;, &quot;exact&quot;, &quot;chain&quot;, and &quot;tree&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact sampling for graphs with a small cutset using cutset conditioning
</p>


<h3>Value</h3>

<p>This function will return a matrix with <code>size</code> rows and <code>crf$n.nodes</code> columns,
in which each row is a sampled configuration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
s &lt;- sample.cutset(Small$crf, 100, c(2))

</code></pre>

<hr>
<h2 id='sample.exact'>Sampling method for small graphs</h2><span id='topic+sample.exact'></span>

<h3>Description</h3>

<p>Generating samples from the distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.exact(crf, size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample.exact_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="sample.exact_+3A_size">size</code></td>
<td>
<p>The sample size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact sampling for small graphs with brute-force inverse cumulative distribution
</p>


<h3>Value</h3>

<p>This function will return a matrix with <code>size</code> rows and <code>crf$n.nodes</code> columns,
in which each row is a sampled configuration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
s &lt;- sample.exact(Small$crf, 100)

</code></pre>

<hr>
<h2 id='sample.gibbs'>Sampling method using single-site Gibbs sampler</h2><span id='topic+sample.gibbs'></span>

<h3>Description</h3>

<p>Generating samples from the distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.gibbs(
  crf,
  size,
  burn.in = 1000,
  start = apply(crf$node.pot, 1, which.max)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample.gibbs_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="sample.gibbs_+3A_size">size</code></td>
<td>
<p>The sample size</p>
</td></tr>
<tr><td><code id="sample.gibbs_+3A_burn.in">burn.in</code></td>
<td>
<p>The number of samples at the beginning that will be discarded</p>
</td></tr>
<tr><td><code id="sample.gibbs_+3A_start">start</code></td>
<td>
<p>An initial configuration</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate sampling using a single-site Gibbs sampler
</p>


<h3>Value</h3>

<p>This function will return a matrix with <code>size</code> rows and <code>crf$n.nodes</code> columns,
in which each row is a sampled configuration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
s &lt;- sample.gibbs(Small$crf, 100)

</code></pre>

<hr>
<h2 id='sample.junction'>Sampling method for low-treewidth graphs</h2><span id='topic+sample.junction'></span>

<h3>Description</h3>

<p>Generating samples from the distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.junction(crf, size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample.junction_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="sample.junction_+3A_size">size</code></td>
<td>
<p>The sample size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact sampling for low-treewidth graphs using junction trees
</p>


<h3>Value</h3>

<p>This function will return a matrix with <code>size</code> rows and <code>crf$n.nodes</code> columns,
in which each row is a sampled configuration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
s &lt;- sample.junction(Small$crf, 100)

</code></pre>

<hr>
<h2 id='sample.tree'>Sampling method for tree- and forest-structured graphs</h2><span id='topic+sample.tree'></span>

<h3>Description</h3>

<p>Generating samples from the distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample.tree(crf, size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample.tree_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="sample.tree_+3A_size">size</code></td>
<td>
<p>The sample size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exact sampling for tree- and forest-structured graphs with sum-product belief propagation and backward-sampling
</p>


<h3>Value</h3>

<p>This function will return a matrix with <code>size</code> rows and <code>crf$n.nodes</code> columns,
in which each row is a sampled configuration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
s &lt;- sample.tree(Small$crf, 100)

</code></pre>

<hr>
<h2 id='Small'>Small CRF example</h2><span id='topic+Small'></span>

<h3>Description</h3>

<p>This data set gives a small CRF example
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Small)
</code></pre>


<h3>Format</h3>

<p>A list containing two elements:
</p>

<ul>
<li> <p><code>crf</code> The CRF
</p>
</li>
<li> <p><code>answer</code> A list of 4 elements:
</p>

<ul>
<li> <p><code>decode</code> The most likely configuration
</p>
</li>
<li> <p><code>node.bel</code> The node belief
</p>
</li>
<li> <p><code>edge.bel</code> The edge belief
</p>
</li>
<li> <p><code>logZ</code> The logarithmic value of CRF normalization factor Z
</p>
</li></ul>

</li></ul>

<hr>
<h2 id='sub.crf'>Make sub CRF</h2><span id='topic+sub.crf'></span>

<h3>Description</h3>

<p>Generate sub CRF by selecting some nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sub.crf(crf, subset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sub.crf_+3A_crf">crf</code></td>
<td>
<p>The CRF generated by <code><a href="#topic+make.crf">make.crf</a></code></p>
</td></tr>
<tr><td><code id="sub.crf_+3A_subset">subset</code></td>
<td>
<p>The vector of selected node ids</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will generate a new CRF from a given CRF
by selecting some nodes. The vector <code>subset</code> contains the
node ids selected to generate the new CRF. Unlike
<code><a href="#topic+clamp.crf">clamp.crf</a></code>, the potentials of remainning nodes and edges are
untouched.
</p>


<h3>Value</h3>

<p>The function will return a new CRF with additional components: 
</p>
<table>
<tr><td><code>original</code></td>
<td>
<p>The original CRF data.</p>
</td></tr> 
<tr><td><code>node.id</code></td>
<td>
<p>The vector of the original node ids for nodes in the new CRF.</p>
</td></tr>
<tr><td><code>node.map</code></td>
<td>
<p>The vector of the new node ids for nodes in the original CRF.</p>
</td></tr> 
<tr><td><code>edge.id</code></td>
<td>
<p>The vector of the original edge ids for edges in the new CRF.</p>
</td></tr> 
<tr><td><code>edge.map</code></td>
<td>
<p>The vector of the new edge ids for edges in the original CRF.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+make.crf">make.crf</a></code>, <code><a href="#topic+clamp.crf">clamp.crf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(CRF)
data(Small)
crf &lt;- sub.crf(Small$crf, c(2, 3))


</code></pre>

<hr>
<h2 id='train.crf'>Train CRF model</h2><span id='topic+train.crf'></span>

<h3>Description</h3>

<p>Train the CRF model to estimate the parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.crf(
  crf,
  instances,
  node.fea = NULL,
  edge.fea = NULL,
  node.ext = NULL,
  edge.ext = NULL,
  nll = crf.nll,
  infer.method = infer.chain,
  ...,
  trace = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.crf_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="train.crf_+3A_instances">instances</code></td>
<td>
<p>The training data matrix of CRF model</p>
</td></tr>
<tr><td><code id="train.crf_+3A_node.fea">node.fea</code></td>
<td>
<p>The list of node features</p>
</td></tr>
<tr><td><code id="train.crf_+3A_edge.fea">edge.fea</code></td>
<td>
<p>The list of edge features</p>
</td></tr>
<tr><td><code id="train.crf_+3A_node.ext">node.ext</code></td>
<td>
<p>The list of extended information of node features</p>
</td></tr>
<tr><td><code id="train.crf_+3A_edge.ext">edge.ext</code></td>
<td>
<p>The list of extended information of edge features</p>
</td></tr>
<tr><td><code id="train.crf_+3A_nll">nll</code></td>
<td>
<p>The function to calculate negative log likelihood</p>
</td></tr>
<tr><td><code id="train.crf_+3A_infer.method">infer.method</code></td>
<td>
<p>The inference method used to compute the likelihood</p>
</td></tr>
<tr><td><code id="train.crf_+3A_...">...</code></td>
<td>
<p>Extra parameters need by the inference method</p>
</td></tr>
<tr><td><code id="train.crf_+3A_trace">trace</code></td>
<td>
<p>Non-negative integer to control the tracing informtion of the optimization process</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function train the CRF model.
</p>
<p>In the training data matrix <code>instances</code>, each row is an instance and 
each column corresponds a node in CRF.
The variables <code>node.fea</code>, <code>edge.fea</code>, <code>node.ext</code>, <code>edge.ext</code>
are lists of length equal to the number of instances, and their elements are
defined as in <code><a href="#topic+crf.update">crf.update</a></code> respectively.
</p>


<h3>Value</h3>

<p>This function will directly modify the CRF and return the same CRF.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crf.update">crf.update</a></code>, <code><a href="#topic+crf.nll">crf.nll</a></code>, <code><a href="#topic+make.crf">make.crf</a></code>
</p>

<hr>
<h2 id='train.mrf'>Train MRF model</h2><span id='topic+train.mrf'></span>

<h3>Description</h3>

<p>Train the MRF model to estimate the parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train.mrf(
  crf,
  instances,
  nll = mrf.nll,
  infer.method = infer.chain,
  ...,
  trace = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.mrf_+3A_crf">crf</code></td>
<td>
<p>The CRF</p>
</td></tr>
<tr><td><code id="train.mrf_+3A_instances">instances</code></td>
<td>
<p>The training data matrix of CRF model</p>
</td></tr>
<tr><td><code id="train.mrf_+3A_nll">nll</code></td>
<td>
<p>The function to calculate negative log likelihood</p>
</td></tr>
<tr><td><code id="train.mrf_+3A_infer.method">infer.method</code></td>
<td>
<p>The inference method used to compute the likelihood</p>
</td></tr>
<tr><td><code id="train.mrf_+3A_...">...</code></td>
<td>
<p>Extra parameters need by the inference method</p>
</td></tr>
<tr><td><code id="train.mrf_+3A_trace">trace</code></td>
<td>
<p>Non-negative integer to control the tracing informtion of the optimization process</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function trains the Markov Random Fields (MRF) model, which is a simple variant of CRF model.
</p>
<p>In the training data matrix <code>instances</code>, each row is an instance and 
each column corresponds a node in CRF.
</p>


<h3>Value</h3>

<p>This function will directly modify the CRF and return the same CRF.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mrf.update">mrf.update</a></code>, <code><a href="#topic+mrf.stat">mrf.stat</a></code>, <code><a href="#topic+mrf.nll">mrf.nll</a></code>, <code><a href="#topic+make.crf">make.crf</a></code>
</p>

<hr>
<h2 id='Tree'>Tree CRF example</h2><span id='topic+Tree'></span>

<h3>Description</h3>

<p>This data set gives a tree CRF example
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Tree)
</code></pre>


<h3>Format</h3>

<p>A list containing two elements:
</p>

<ul>
<li> <p><code>crf</code> The CRF
</p>
</li>
<li> <p><code>answer</code> A list of 4 elements:
</p>

<ul>
<li> <p><code>decode</code> The most likely configuration
</p>
</li>
<li> <p><code>node.bel</code> The node belief
</p>
</li>
<li> <p><code>edge.bel</code> The edge belief
</p>
</li>
<li> <p><code>logZ</code> The logarithmic value of CRF normalization factor Z
</p>
</li></ul>

</li></ul>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
