<!DOCTYPE html><html><head><title>Help for package RALSA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RALSA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#RALSA'><p>R Analyzer for Large-Scale Assessments (RALSA)</p></a></li>
<li><a href='#lsa.bench'><p>Compute percentages of respondents reaching or surpassing certain ability cut-off scores</p></a></li>
<li><a href='#lsa.bin.log.reg'><p>Compute binary logistic regression coefficients specified groups</p></a></li>
<li><a href='#lsa.convert.data'><p>Convert Large-Scale Assessments' Datasets to .RData Format</p></a></li>
<li><a href='#lsa.convert.data2'><p>Convert Large-Scale Assessments' Datasets to .RData Format</p></a></li>
<li><a href='#lsa.corr'><p>Compute correlations between variables within specified groups</p></a></li>
<li><a href='#lsa.crosstabs'><p>Compute crosstabulations and design corrected chi-square statistics</p></a></li>
<li><a href='#lsa.data.diag'><p>Produce data diagnostic tables</p></a></li>
<li><a href='#lsa.lin.reg'><p>Compute linear regression coefficients specified groups</p></a></li>
<li><a href='#lsa.merge.data'><p>Merge study data from different countries and/or respondents</p></a></li>
<li><a href='#lsa.pcts.means'><p>Compute percentages of respondents in groups and/or means (arithmetic average, median or mode) on continuous variables within specified groups</p></a></li>
<li><a href='#lsa.prctls'><p>Compute percentiles of continuous variables within groups</p></a></li>
<li><a href='#lsa.recode.vars'><p>Recode variables in large-scale assessments' data sets</p></a></li>
<li><a href='#lsa.vars.dict'><p>Produce dictionary for large-scale assessments data variables</p></a></li>
<li><a href='#ralsaGUI'><p>Start RALSA's Graphical User Interface (GUI)</p></a></li>
<li><a href='#ralsaGUIfailsafe'><p>Start RALSA's Graphical User Interface (GUI) in a failsafe mode</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>R Analyzer for Large-Scale Assessments</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-02 17:00</td>
</tr>
<tr>
<td>Author:</td>
<td>Plamen V. Mirazchiyski [aut, cre],
  INERI [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Plamen V. Mirazchiyski &lt;plamen.mirazchiyski@ineri.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Prepare and analyze data from large-scale assessments and surveys with
    complex sampling and assessment design (see 'Rutkowski', 2010
    &lt;<a href="https://doi.org/10.3102%2F0013189X10363170">doi:10.3102/0013189X10363170</a>&gt;). Such studies are, for example,
    international assessments like 'TIMSS', 'PIRLS' and 'PISA'. A graphical
    interface is available for the non-technical user.The package includes
    functions to covert the original data from 'SPSS' into 'R' data sets
    keeping the user-defined missing values, merge data from different
    respondents and/or countries, generate variable dictionaries, modify
    data, produce descriptive statistics (percentages, means, percentiles,
    benchmarks) and multivariate statistics (correlations, linear
    regression, binary logistic regression). The number of supported
    studies and analysis types will increase in future. For a general
    presentation of the package, see 'Mirazchiyski', 2021a
    (&lt;<a href="https://doi.org/10.1186%2Fs40536-021-00114-4">doi:10.1186/s40536-021-00114-4</a>&gt;). For detailed technical aspects of the
    package, see 'Mirazchiyski', 2021b (&lt;<a href="https://doi.org/10.3390%2Fpsych3020018">doi:10.3390/psych3020018</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>DT, haven, Hmisc, data.table, foreign, ggplot2, import,
methods, openxlsx, rclipboard, readr, rstudioapi, shiny,
shinyFiles, shinydashboard, shinyjs, shinyWidgets, stringi,
stringr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://ralsa.ineri.org/">https://ralsa.ineri.org/</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-02 13:54:46 UTC; plamen</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-02 14:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='RALSA'>R Analyzer for Large-Scale Assessments (RALSA)</h2><span id='topic+RALSA'></span><span id='topic+RALSA-package'></span>

<h3>Description</h3>

<p>The RALSA package provides functionality for analyzing data from large-scale assessments and surveys which use complex sampling and assessment design. Such (international) assessments and surveys are TIMSS, PIRLS and PISA, for example.
</p>
<p>The sampling (complex sampling design) in large-scale assessments and surveys is multistage with probability proportional to the size of the (primary) sampling units (usually schools), i.e. with unequal probabilities of selection. Thus, all weights assigned to the individual respondents reflect these unequal probabilities. This is quite different from the usual simple or systematic random sampling. Different modifications of Jackknife Repeated Replication (JRR, with full or half replication) or Balanced Repeated Replication (BRR) are used in different studies to compute the standard errors of the population estimates. The proficiency test scores (complex assessment design) is applied to cope with practical issues. No respondent takes all test items, but the items are distributed across multiple test item blocks and the blocks are rotated across multiple assessment booklets, each respondent taking one booklet only. As a consequence, no respondent receives a single test score, but five (or even 10) separate test scores (called &quot;plausible values&quot; or PVs) resulting from multiple imputation technique where the missing by design responses are imputed. As a consequence of the complex sampling and assessment designs, each estimate has to be computed with each JRR or BRR weight and each PV (this can take up to 781 computations per estimate per group per country, depending on the study), then summarized to compute the final estimate, its sampling and imputation variance, and the final standard error.
</p>
<p>RALSA provides data preparation and analysis functions which take into account the complex sampling and assessment design of the studies. Each study has its a different implementation of the complex sampling and assessment designs and RALSA handles these and implements the corresponding computational procedure.
</p>


<h3>Studies</h3>

<p>Currently, RALSA works with data from <strong>all cycles</strong> of the the following studies:
</p>

<ul>
<li><p> IEA CivED;
</p>
</li>
<li><p> IEA ICCS;
</p>
</li>
<li><p> IEA ICILS;
</p>
</li>
<li><p> IEA RLII;
</p>
</li>
<li><p> IEA PIRLS (including PIRLS Literacy and ePIRLS);
</p>
</li>
<li><p> IEA TIMSS (including TIMSS Numeracy, eTIMSS);
</p>
</li>
<li><p> IEA TiPi (TIMSS and PIRLS joint study);
</p>
</li>
<li><p> IEA TIMSS Advanced;
</p>
</li>
<li><p> IEA SITES;
</p>
</li>
<li><p> IEA TEDS-M;
</p>
</li>
<li><p> IEA REDS;
</p>
</li>
<li><p> OECD PISA;
</p>
</li>
<li><p> OECD PISA for Development;
</p>
</li>
<li><p> OECD TALIS; and
</p>
</li>
<li><p> OECD TALIS Starting Strong Survey (a.k.a. TALIS 3S).
</p>
</li></ul>

<p>More studies (national international) will be added in future.
</p>


<h3>Functions</h3>

<p>Currently, RALSA provides the following functionality:
</p>

<ul>
<li><p> Data preparation functions - prepare data for analysis
</p>

<ul>
<li> <p><code>lsa.convert.data</code> The studies provide their data in SPSS and SAS format. In addition, PISA cycles prior to 2015 provide the data in <code>.TXT</code> format, along with their SPSS and SAS import syntax files. This function takes the originally provided SPSS data (or <code>.TXT</code>, along with the import syntaxes) files and converts them into native <code>.RData</code> files. It also adds variable labels, user-defined missing codes (if requested) and identifiers of the study, cycle, and respondent types (i.e. student, parent, teacher, school principal).
</p>
</li>
<li> <p><code>lsa.select.countries.PISA</code> Utility function to select countries' data from a converted PISA file and save them as a new file or assign them to an object in memory. This makes it more convenient to work with PISA data files which contain data from all countries per respondent type.
</p>
</li>
<li> <p><code>lsa.merge.data</code> The studies provide data from different respondents (i.e. student, parent, teacher, school principal) which are sampled hierarchically (e.g. students are nested in classes, classes are nested in schools and taught by teachers) and linked between each other. The files in the databases are provided separately per country and respondent type. This function merges data sets from different respondents and/or countries assuring the links between the different types of respondents (i.e. linking students only to principals' data only for their school and to the teachers who teach them). This function merges data for all studies, except for PISA where the structure of the files does not allow (for now) merging data from different respondent types.
</p>
</li>
<li> <p><code>lsa.vars.dict</code> Prints and/or saves variable dictionaries in a file. Convenient when need to know the structure of the variables of interest.
</p>
</li>
<li> <p><code>lsa.data.diag</code> Helper function for quick frequency (for categorical variables) and descriptive (continuous variables) tables (weighted or unweighted). These can serve for initial exploration of the data and elaborating hypotheses. Not intended for actual analysis.
</p>
</li>
<li> <p><code>lsa.recode.vars</code> Recodes variables from large-scale assessments taking care of the user-defined missing values. Convenient for collapsing categories or changing their order.
</p>
</li></ul>

</li>
<li><p> Analysis functions - estimates are on population level, taking into account the complex sampling and assessment design
</p>

<ul>
<li> <p><code>lsa.pcts.means</code> Computes percentages of respondents and means (arithmetic average, median or mode) for continuous variables within groups
</p>
</li>
<li> <p><code>lsa.prctls</code> Computes percentiles of continuous variables within groups
</p>
</li>
<li> <p><code>lsa.bench</code> Computes percentages of respondents reaching or surpassing benchmarks of achievement
</p>
</li>
<li> <p><code>lsa.crosstabs</code> Crosstabulations with Rao-Scott first- and second-order chi-square adjustments
</p>
</li>
<li> <p><code>lsa.corr</code> Computes correlations between variables (Pearson or Spearman)
</p>
</li>
<li> <p><code>lsa.lin.reg</code> Computes linear regression with or without contrast coding of categorical variables
</p>
</li>
<li> <p><code>lsa.bin.log.reg</code> Computes binary logistic regression with or without contrast coding of categorical variables
</p>
</li></ul>

</li></ul>

<p>The <code>lsa.pcts.means</code>, <code>lsa.prctls</code>, <code>lsa.bench</code> and <code>lsa.crosstabs</code> also have the option to produce graphs from the estimates.
</p>
<p>More studies and analysis types will be added in future, and the existing ones will be updated, adding more features.
</p>
<p>RALSA also has a Graphical User Interface (GUI) for the less technical users. The GUI incorporates all aspects of the data preparation and analysis functions.
</p>


<h3>Author(s)</h3>

<p>Plamen V. Mirazchiyski, INERI
</p>


<h3>References</h3>

<p>Here are the two articles presenting the package and it's technical details:
</p>
<p>Mirazchiyski, P.V. (2021). RALSA: The R analyzer for large-scale assessments. <em>Large-scale Assess Educ 9</em>(21), 1-24. https://doi.org/10.1186/s40536-021-00114-4
</p>
<p>Mirazchiyski, P. V. (2021). RALSA: Design and Implementation. <em>Psych, 3</em>(2), 233-248. https://doi.org/10.3390/psych3020018
</p>
<p>Here is a list of selected references related to some of the studies' design, relevant to their latest cycles:
</p>
<p>Foy, P., &amp; LaRoche, S. (2017). Estimating Standard Errors in the PIRLS 2016 Results. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in PIRLS 2016</em> (p. 4.1-4.22). Lynch School of Education, Boston College.
</p>
<p>Foy, P., &amp; Yin, L. (2016). TIMSS 2015 Achievement Scaling Methodology. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (p. 13.1-13.62). TIMSS &amp; PIRLS International Study Center.
</p>
<p>LaRoche, S., Joncas, M., &amp; Foy, P. (2016). Sample Design in TIMSS 2015. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (p. 3.1-3.37). TIMSS &amp; PIRLS International Study Center.
</p>
<p>OECD. (in press). <em>PISA 2018 Technical Report</em>. OECD.
</p>
<p>Rutkowski, L., Gonzalez, E., Joncas, M., &amp; von Davier, M. (2010). International Large-Scale Assessment Data: Issues in Secondary Analysis and Reporting. <em>Educational Researcher, 39</em>(2), 142-151.
</p>
<p>Rutkowski, L., Rutkowski, D., &amp; von Davier, M. (2014). A Brief Introduction to Modern International Large-Scale Assessment. In L. Rutkowski, M. von Davier, &amp; D. Rutkowski (Eds.), <em>Handbook of International Large-Scale Assessments: Background, Technical Issues, and Methods of Data Analysis</em> (pp. 3-10). CRC Press.
</p>

<hr>
<h2 id='lsa.bench'>Compute percentages of respondents reaching or surpassing certain ability cut-off scores</h2><span id='topic+lsa.bench'></span>

<h3>Description</h3>

<p><code>lsa.bench</code> computes percentages of respondents reaching or surpassing certain ability cut-off scores (benchmarks/performance levels). The cut-off scores are points in the distributions of PVs defined differently in different studies and, sometimes, in different study cycles. The percentages can also be computed as cumulative percentages. There is an option to compute an average of continuous contextual/background variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.bench(
  data.file,
  data.object,
  split.vars,
  PV.root.bench,
  bench.vals,
  bench.type,
  pcts.within = FALSE,
  bckg.var,
  weight.var,
  include.missing = FALSE,
  shortcut = FALSE,
  graphs = FALSE,
  perc.x.label = NULL,
  perc.y.label = NULL,
  mean.x.label = NULL,
  mean.y.label = NULL,
  save.output = TRUE,
  output.file,
  open.output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.bench_+3A_data.file">data.file</code></td>
<td>
<p>The file containing <code>lsa.data</code> object. Either this or <code>data.object</code>
shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either this
or <code>data.file</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_split.vars">split.vars</code></td>
<td>
<p>Categorical variable(s) to split the results by. If no split variables are
provided, the results will be for the overall countries' populations. If
one or more variables are provided, the results will be split by all but
the last variable and the percentages of respondents will be computed by
the unique values of the last splitting variable.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_pv.root.bench">PV.root.bench</code></td>
<td>
<p>The root name(s) for the set(s) of plausible values which will be used
to compute the percentages of respondents reaching or surpassing certain
cut-off score. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_bench.vals">bench.vals</code></td>
<td>
<p>A vector of integers representing the cut-off scores. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_bench.type">bench.type</code></td>
<td>
<p>A character string representing how the percentages of respondents shall
be computed. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_pcts.within">pcts.within</code></td>
<td>
<p>Logical value specifying if the percentages shall be computed within the
groups defined by the <code>split.vars</code> (<code>TRUE</code>) or not (<code>FALSE</code>,
default). See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_bckg.var">bckg.var</code></td>
<td>
<p>Name of a continuous background or contextual variable to compute the
mean for. The results will be computed by all groups specified by the
splitting variables and per performance group. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_weight.var">weight.var</code></td>
<td>
<p>The name of the variable containing the weights. If no name of a weight
variable is provide, the function will automatically select the default
weight variable for the provided data, depending on the respondent type.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_include.missing">include.missing</code></td>
<td>
<p>Logical, shall the missing values of the splitting variables be included
as categories to split by and all statistics produced for them? The
default (<code>FALSE</code>) takes all cases on the splitting variables
without missing values before computing any statistics. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_shortcut">shortcut</code></td>
<td>
<p>Logical, shall the &quot;shortcut&quot; method for IEA TIMSS, TIMSS Advanced,
TIMSS Numeracy, eTIMSS PSI, PIRLS, ePIRLS, PIRLS Literacy and RLII be
applied? The default (<code>FALSE</code>) applies the &quot;full&quot; design when
computing the variance components and the standard errors of the
estimates.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_graphs">graphs</code></td>
<td>
<p>Logical, shall graphs be produced? Default is <code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_perc.x.label">perc.x.label</code></td>
<td>
<p>String, custom label for the horizontal axis in percentage graphs.
Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_perc.y.label">perc.y.label</code></td>
<td>
<p>String, custom label for the vertical axis in percentage graphs.
Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_mean.x.label">mean.x.label</code></td>
<td>
<p>List of strings, custom labels for the horizontal axis in means' graphs.
Ignored if <code>bckg.var</code> is omitted and/or <code>graphs = FALSE</code>.
See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_mean.y.label">mean.y.label</code></td>
<td>
<p>List of strings, custom labels for the vertical axis in means' graphs.
Ignored if <code>bckg.var</code> is omitted and/or <code>graphs = FALSE</code>.
See details.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_save.output">save.output</code></td>
<td>
<p>Logical, shall the output be saved in MS Excel file (default) or not
(printed to the console or assigned to an object).</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_output.file">output.file</code></td>
<td>
<p>If <code>save.output = TRUE</code> (default), full path to the output file
including the file name. If omitted, a file with a default file name
&quot;Analysis.xlsx&quot; will be written to the working directory (<code>getwd()</code>).
Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsa.bench_+3A_open.output">open.output</code></td>
<td>
<p>Logical, shall the output be open after it has been written? The default
(<code>TRUE</code>) opens the output in the default spreadsheet program installed
on the computer. Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>The function computes percentages of respondents which reach or surpass certain cut-off scores (benchmarks/performance levels). These percentages are computed using a set of PVs, specified in the <code>PV.root.bench</code>. Only one set of PVs can be added to <code>PV.root.bench</code> at a time. All studies (except CivED, TEDS-M, SITES, TALIS and TALIS Starting Strong Survey) have a set of PVs per content domain (e.g. in TIMSS five for overall mathematics, five for algebra, five for geometry, etc.) and cognitive domain (i.e. knowing, applying and reasoning). In some studies (say TIMSS and PIRLS) the names of the PVs in a set always start with character string and end with sequential number of the PV. For example, the names of the set of PVs for overall mathematics in TIMSS are BSMMAT01, BSMMAT02, BSMMAT03, BSMMAT04 and BSMMAT05. The root of the PVs for this set to be added to <code>PV.root.avg</code> will be &quot;BSMMAT&quot;. The function will automatically find all the variables in this set of PVs and include them in the analysis. In other studies like OECD PISA and IEA ICCS and ICILS the sequential number of each PV is included in the middle of the name. For example, in ICCS the names of the set of PVs are PV1CIV, PV2CIV, PV3CIV, PV4CIV and PV5CIV. The root PV name has to be specified in <code>PV.root.bench</code> as &quot;PV#CIV&quot;.
</p>
<p>Multiple splitting variables can be added to the <code>split.vars</code>, the function will compute the percentages of respondents reaching or surpassing the cut-off scores for all formed groups and their means on the continuous variables. If no splitting variables are added, the results will be only by country.
</p>
<p>If a continuous contextual/background variable is provided to the <code>bckg.var</code>, the average for that variable will be computed for each group formed by the splitting variables and the performance groups. Only one contextual/background variable can be added in the analysis. This argument is ignored when <code>bench.type = "cumulative"</code>.
</p>
<p>The cut-off scores are provided as vector of integers (e.g. <code>c(475, 500)</code>) to the <code>bench.vals</code>. If no cut-off scores are provided, the function will automatically choose all benchmark values for the corresponding study and, in some cases for the data from the specific cycle. The latter applies to ICCS and PISA where the proficiency levels differ from one cycle to another.
</p>
<p>The <code>bench.type</code> argument has two different options: <code>"discrete"</code> (default) and <code>"cumulative"</code>. Using the former will compute the percentages of respondents within the boundaries specified by the cut-off scores in <code>bench.vals</code>. Using the latter, the function will compute the percentages of respondents at or above the cut-off points in the <code>bench.vals</code>.
</p>
<p>If the <code>pcts.within</code> if <code>FALSE</code> (default), the function will compute the percentages of respondents reaching or surpassing each of the cut-off scores defined by <code>bench.vals</code>. In this case the percentages of all respondents across the performance levels will add to 100 in each group defined by the splitting variables. On the contrary, if <code>pcts.within = TRUE</code>, the function will compute the percentages of respondents at each of the performance levels across groups defined by the splitting variables. Then the sum of percentages within a specific performance level will sum up to 100 across the groups defined by the splitting variables. For example, we can compute what is the ratio (i.e. percentages) of female and male students performing between 475 and 550 points in PIRLS &ndash; say 55 of all students performing at this level are female and 45 are male. If no split variables are provided, the percentages will be 100 for each performance level within a country. The argument is ignored if <code>bench.type = "cumulative"</code>.
</p>
<p>If no variables are specified for <code>bckg.var</code>, the output will contain only percentages of cases in groups specified by the splitting variables and the cut-off scores.
</p>
<p>If <code>include.missing = FALSE</code> (default), all cases with missing values on the splitting variables will be removed and only cases with valid values will be retained in the statistics. Note that the data from the studies can be exported in two different ways: (1) setting all user-defined missing values to <code>NA</code>; and (2) importing all user-defined missing values as valid ones and adding their codes in an additional attribute to each variable. If the <code>include.missing</code> is set to <code>FALSE</code> (default) and the data used is exported using option (2), the output will remove all values from the variable matching the values in its <code>missings</code> attribute. Otherwise, it will include them as valid values and compute statistics for them.
</p>
<p>The <code>shortcut</code> argument is valid only for TIMSS, eTIMSS PSI, TIMSS Numeracy, TIMSS Advanced, PIRLS, ePIRLS, PIRLS Literacy and RLII. Previously, in computing the standard errors, these studies were using 75 replicates because one of the schools in the 75 JK zones had its weights doubled and the other one has been taken out. Since TIMSS 2015 and PIRLS 2016 the studies use 150 replicates and in each JK zone once a school has its weights doubled and once taken out, i.e. the computations are done twice for each zone. For more details see Foy &amp; LaRoche (2016) and Foy &amp; LaRoche (2017). If replication of the tables and figures is needed, the <code>shortcut</code> argument has to be changed to <code>TRUE</code>.
</p>
<p>If <code>graphs = TRUE</code>, the function will produce graphs. If <code>split.vars</code> are specified, bar plots of percentages of respondents (population estimates) reaching or surpassing each benchmark level specified in <code>bench.vals</code> per group specified by <code>split.vars</code> will be produced with error bars (95% confidence) for these percentages. If <code>bckg.var</code> is specified, plots with 95% confidence intervals of the average for this variable will be produced. All plots are produced per country. By default the percentage graphs horizontal axis is labeled as &quot;Performance Group&quot;, and the vertical is labeled as &quot;Percentages XXXXX&quot; where XXXXX is the root name of the set of PVs percentages within performance group are computed for. If <code>bckg.var</code> is provide to compute means for, the means plots' horizontal axis is labeled as &quot;Performance Group&quot;, and the vertical axis is labeled as &quot;Mean XXXXX&quot; where XXXXX is the name of the variable for which means are computed for each performance group. These defaults can be overriden by supplying values to <code>perc.x.label</code>, <code>perc.y.label</code>, <code>mean.x.label</code> and <code>mean.y.label</code>. The <code>perc.x.label</code>, <code>perc.y.label</code>, <code>mean.x.label</code> and <code>mean.y.label</code> arguments accept vectors of length 1, and if longer vectors are supplied, error is thrown. See the examples.
</p>


<h3>Value</h3>

<p>If <code>save.output = FALSE</code>, a list containing the estimates and analysis information. If <code>graphs = TRUE</code>, the plots will be added to the list of estimates.
</p>
<p>If <code>save.output = TRUE</code> (default), an MS Excel (<code>.xlsx</code>) file (which can be opened in any spreadsheet program), as specified with the full path in the <code>output.file</code>. If the argument is missing, an Excel file with the generic file name &quot;Analysis.xlsx&quot; will be saved in the working directory (<code>getwd()</code>). The workbook contains three spreadsheets. The first one (&quot;Estimates&quot;) contains a table with the results by country and the final part of the table contains averaged results from all countries' statistics. The following columns can be found in the table, depending on the specification of the analysis:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> n_Cases - the number of cases reaching or surpassing each of the benchmarks using a set of PVs. Please note that these may not be whole numbers because they are computed using each PV and then averaged.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the estimated population number of elements per group after applying the weights. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the the estimated population number of elements per group. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Performance_Group - the labels for the performance groups defined by the <code>bench.vals</code>.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>PVs' root name<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentages of respondents (population estimates) reaching or surpassing each cut-off score (in case of <code>bench.type = "discrete"</code>) or the the percentages of respondents (population estimates) at or above each cut-off value (in case of <code>bench.type = "cumulative"</code>) per groups defined by the splitting variables in <code>split.vars</code>.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>PVs' root name<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the percentages from above.
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the average of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.var</code>.
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the average of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.var</code>.
</p>
</li>
<li><p> Variance_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the variance for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.var</code>.
</p>
</li>
<li><p> Variance_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the error of the variance for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.var</code>.
</p>
</li>
<li><p> SD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the standard deviation for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.var</code>.
</p>
</li>
<li><p> SD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the error of the standard deviation for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.var</code>.
</p>
</li>
<li><p> Percent_Missings_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentage of missing values for the <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.var</code>.
</p>
</li></ul>

<p>The second sheet contains some additional information related to the analysis per country in columns:
</p>

<ul>
<li><p> DATA - used <code>data.file</code> or <code>data.object</code>.
</p>
</li>
<li><p> STUDY - which study the data comes from.
</p>
</li>
<li><p> CYCLE - which cycle of the study the data comes from.
</p>
</li>
<li><p> WEIGHT - which weight variable was used.
</p>
</li>
<li><p> DESIGN - which resampling technique was used (JRR or BRR).
</p>
</li>
<li><p> SHORTCUT - logical, whether the shortcut method was used.
</p>
</li>
<li><p> NREPS - how many replication weights were used.
</p>
</li>
<li><p> ANALYSIS_DATE - on which date the analysis was performed.
</p>
</li>
<li><p> START_TIME - at what time the analysis started.
</p>
</li>
<li><p> END_TIME - at what time the analysis finished.
</p>
</li>
<li><p> DURATION - how long the analysis took in hours, minutes, seconds and milliseconds.
</p>
</li></ul>

<p>The third sheet contains the call to the function with values for all parameters as it was executed. This is useful if the analysis needs to be replicated later.
</p>
<p>If <code>graphs = TRUE</code> there will be an additional &quot;Graphs&quot; sheet containing all plots.
</p>
<p>If any warnings resulting from the computations are issued, these will be included in an additional &quot;Warnings&quot; sheet in the workbook as well.
</p>


<h3>References</h3>

<p>LaRoche, S., Joncas, M., &amp; Foy, P. (2016). Sample Design in TIMSS 2015. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (pp. 3.1-3.37). Chestnut Hill, MA: TIMSS &amp; PIRLS International Study Center.
LaRoche, S., Joncas, M., &amp; Foy, P. (2017). Sample Design in PIRLS 2016. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in PIRLS 2016</em> (pp. 3.1-3.34). Chestnut Hill, MA: Lynch School of Education, Boston College.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute percentages of female and male students reaching or surpassing the "Intermediate"
# and "High" benchamrks in TIMSS 2015 grade 8 mathematics using data file, omit missing from
# the splitting variable (female and male as answered by the students), without shortcut, and
# open the output after the computations are done
## Not run: 
lsa.bench(data.file = "C:/Data/TIMSS_2015_G8_Student_Miss_to_NA.RData", split.vars = "BSBG01",
include.missing = FALSE, PV.root.bench = "BSMMAT", bench.vals = c(475, 550),
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Repeat the analysis from above, using an object loaded in the memory, the student senate
# weight and compute the cumulative percentage, adding student feeling safe at school as a
# second splitting variable, using the shortcut method and including the missing values of
# the splitting variables
## Not run: 
lsa.bench(data.object = T15_G8_student_data, split.vars = c("BSBG01", "BSBG15B"),
PV.root.bench = "BSMMAT", bench.vals = c(475, 550), weight.var = "SENWGT",
include.missing = TRUE, shortcut = TRUE, output.file = "C:/temp/test.xlsx",
open.output = TRUE)

## End(Not run)

# Compute the percentage of students reaching or surpassing the "Level 2" and "Level 3"
# in computer and information lteracy and the average of the complex background scale
# "Use of specialist applications for activities" by student sex and expected further
# level of education using ICILS 2018 data loaded in memory, include the missing values
# in the splitting variables
## Not run: 
lsa.bench(data.object = ICILS_2018_student_data, split.vars = c("S_SEX", "IS2G03"),
PV.root.bench = "PV#CIL", bckg.var = "S_SPECACT", include.missing = TRUE,
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Same as above, this time adding graphs with custom x-axis and y-axis labels
## Not run: 
lsa.bench(data.object = ICILS_2018_student_data, split.vars = c("S_SEX", "IS2G03"),
PV.root.bench = "PV#CIL", bckg.var = "S_SPECACT",
graphs = TRUE, perc.x.label = "Percentages of students", perc.y.label = "Benchmark groups",
mean.x.label = "Performance groups", mean.y.label = "Average of using specialist apps scale",
include.missing = TRUE,
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Compute the cumulative percentage of students at or above each of the (default) benchmarks
# of student overall reading achievement scores using PIRLS 2016 student data file, split the
# output by student sex, use the full design, include the missing values of the splitting
# variable (i.e. student sex), and do not open the output after the computations are finished
## Not run: 
lsa.bench(data.file = "C:/Data/PIRLS_2016_Student_Miss_to_NA.RData", split.vars = "ASBG01",
PV.root.bench = "ASRREA", bench.type = "cumulative", include.missing = TRUE,
output.file = "C:/temp/test.xlsx", open.output = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.bin.log.reg'>Compute binary logistic regression coefficients specified groups</h2><span id='topic+lsa.bin.log.reg'></span>

<h3>Description</h3>

<p><code>lsa.bin.log.reg</code> computes binary logistic regression coefficients within groups defined by one or more variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.bin.log.reg(
  data.file,
  data.object,
  split.vars,
  bin.dep.var,
  bckg.indep.cont.vars,
  bckg.indep.cat.vars,
  bckg.cat.contrasts,
  bckg.ref.cats,
  PV.root.indep,
  interactions,
  standardize = FALSE,
  weight.var,
  norm.weight = FALSE,
  include.missing = FALSE,
  shortcut = FALSE,
  save.output = TRUE,
  output.file,
  open.output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.bin.log.reg_+3A_data.file">data.file</code></td>
<td>
<p>The file containing <code>lsa.data</code> object. Either this or
<code>data.object</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either
this or <code>data.file</code> shall be specified, but not both. See
details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_split.vars">split.vars</code></td>
<td>
<p>Categorical variable(s) to split the results by. If no split
variables are provided, the results will be for the overall
countries' populations. If one or more variables are provided, the
results will be split by all but the last variable and the
percentages of respondents will be computed by the unique values of
the last splitting variable.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_bin.dep.var">bin.dep.var</code></td>
<td>
<p>Name of a binary (i.e. just two distinct values) background or
contextual variable used as a dependent variable in the model. See
details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_bckg.indep.cont.vars">bckg.indep.cont.vars</code></td>
<td>
<p>Names of continuous independent background or contextual variables
used as predictors in the model. See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_bckg.indep.cat.vars">bckg.indep.cat.vars</code></td>
<td>
<p>Names of categorical independent background or contextual variables
used as predictors in the model to compute contrasts for (see
<code>bckg.cat.contrasts</code> and <code>bckg.ref.cats</code>). See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_bckg.cat.contrasts">bckg.cat.contrasts</code></td>
<td>
<p>String vector with the same length as the length of
<code>bckg.indep.cat.vars</code> specifying the type of contrasts to
compute in case <code>bckg.indep.cat.vars</code> are provided. See
details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_bckg.ref.cats">bckg.ref.cats</code></td>
<td>
<p>Vector of integers with the same length as the length of
<code>bckg.indep.cat.vars</code> and <code>bckg.cat.contrasts</code> specifying
the reference categories for the contrasts to compute in case
<code>bckg.indep.cat.vars</code> are provided. See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_pv.root.indep">PV.root.indep</code></td>
<td>
<p>The root names for a set of plausible values used as a independent
variables in the model. See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_interactions">interactions</code></td>
<td>
<p>Interaction terms - a list containing vectors of length of two.
See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_standardize">standardize</code></td>
<td>
<p>Shall the dependent and independent variables be standardized to
produce beta coefficients? The default is <code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_weight.var">weight.var</code></td>
<td>
<p>The name of the variable containing the weights. If no name of a
weight variable is provide, the function will automatically select
the default weight variable for the provided data, depending on the
respondent type.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_norm.weight">norm.weight</code></td>
<td>
<p>Shall the weights be normalized before applying them, default is
<code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_include.missing">include.missing</code></td>
<td>
<p>Logical, shall the missing values of the splitting variables be
included as categories to split by and all statistics produced for
them? The default (<code>FALSE</code>) takes all cases on the splitting
variables without missing values before computing any statistics.
See details.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_shortcut">shortcut</code></td>
<td>
<p>Logical, shall the &quot;shortcut&quot; method for IEA TIMSS, TIMSS Advanced,
TIMSS Numeracy, eTIMSS PSI, PIRLS, ePIRLS, PIRLS Literacy and RLII
be applied? The default (<code>FALSE</code>) applies the &quot;full&quot; design
when computing the variance components and the standard errors of
the estimates.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_save.output">save.output</code></td>
<td>
<p>Logical, shall the output be saved in MS Excel file (default) or
not (printed to the console or assigned to an object).</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_output.file">output.file</code></td>
<td>
<p>If <code>save.output = TRUE</code> (default), full path to the output file
including the file name. If omitted, a file with a default file name
&quot;Analysis.xlsx&quot; will be written to the working directory
(<code>getwd()</code>). Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsa.bin.log.reg_+3A_open.output">open.output</code></td>
<td>
<p>Logical, shall the output be open after it has been written? The
default (<code>TRUE</code>) opens the output in the default spreadsheet
program installed on the computer. Ignored if
<code>save.output = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
The function computes binary logistic regression coefficients by the categories of the splitting variables. The percentages of respondents in each group are computed within the groups specified by the last splitting variable. If no splitting variables are added, the results will be computed only by country.
</p>
<p>If <code>standardize = TRUE</code>, the variables will be standardized before computing any statistics to provide beta regression coefficients.
</p>
<p>A binary (i.e. dichotomous) background/contextual variable must be provided to <code>bin.dep.var</code> (numeric or factor). If more than two categories exist in the variable, the function will exit with an error. The function automatically recodes the two categories of the <code>bin.dep.var</code> to 0 and 1 if they are not as such (e.g. as 1 and 2 as in factors). If the variable of interest has more than two distinct values (can use the <code>lsa.var.dict</code> to see them), they can be collapsed using the <code>lsa.recode.vars</code>.
</p>
<p>Background/contextual variables passed to <code>bckg.indep.cont.vars</code> will be treated as numeric variables in the model. Variables with discrete number of categories (i.e. factors) passed to <code>bckg.indep.cat.vars</code> will be used to compute contrasts. In this case the type of contrast have to be passed to <code>bckg.cat.contrasts</code> and the number of the reference categories for each of the <code>bckg.indep.cat.vars</code>. The number of types of contrasts and the reference categories must be the same as the number of <code>bckg.indep.cat.vars</code>. The currently supported contrast coding schemes are:
</p>

<ul>
<li> <p><code>dummy</code> (also called &quot;indicator&quot; in logistic regression) - the odds ratios show what is the probability for a positive (i.e. 1) outcome in the binary dependent variable compared to the negative outcome (i.e. 0) per category of a variable in the <code>bckg.indep.cat.cats</code> compared to the reference category of that dummy coded variable. The intercept shows the log of the odds for the reference category when all other levels are 0.
</p>
</li>
<li> <p><code>deviation</code> (also called &quot;effect&quot; in logistic regression) - comparing the effect of each category (except for the reference) of the deviation coded variable to the overall effect (which is the intercept).
</p>
</li>
<li> <p><code>simple</code> - the same as for the <code>dummy</code> contrast coding, except for the intercept which in this case is the overall effect.
</p>
</li></ul>

<p>Note that when using <code>standardize = TRUE</code>, the contrast coding of <code>bckg.indep.cat.vars</code> is not standardized. Thus, the regression coefficients may not be comparable to other software solutions for analyzing large-scale assessment data which rely on, for example, SPSS or SAS where the contrast coding of categorical variables (e.g. dummy coding) takes place by default. However, the model statistics will be identical.
</p>
<p>Multiple continuous or categorical background variables and/or sets of plausible values can be provided to compute regression coefficients for. Please note that in this case the results will slightly differ compared to using each pair of the same background continuous variables or PVs in separate analysis. This is because the cases with the missing values are removed in advance and the more variables are provided, the more cases are likely to be removed. That is, the function support only listwisie deletion.
</p>
<p>Computation of regression coefficients involving plausible values requires providing a root of the plausible values names in <code>PV.root.dep</code> and/or <code>PV.root.indep</code>. All studies (except CivED, TEDS-M, SITES, TALIS and TALIS Starting Strong Survey) have a set of PVs per construct (e.g. in TIMSS five for overall mathematics, five for algebra, five for geometry, etc.). In some studies (say TIMSS and PIRLS) the names of the PVs in a set always start with character string and end with sequential number of the PV. For example, the names of the set of PVs for overall mathematics in TIMSS are BSMMAT01, BSMMAT02, BSMMAT03, BSMMAT04 and BSMMAT05. The root of the PVs for this set to be added to <code>PV.root.dep</code> or <code>PV.root.indep</code> will be &quot;BSMMAT&quot;. The function will automatically find all the variables in this set of PVs and include them in the analysis. In other studies like OECD PISA and IEA ICCS and ICILS the sequential number of each PV is included in the middle of the name. For example, in ICCS the names of the set of PVs are PV1CIV, PV2CIV, PV3CIV, PV4CIV and PV5CIV. The root PV name has to be specified in <code>PV.root.dep</code> or <code>PV.root.indep</code> as &quot;PV#CIV&quot;. More than one set of PVs can be added in <code>PV.root.indep</code>.
</p>
<p>The function can also compute two-way interaction effects between independent variables by passing a list to the <code>interactions</code> argument. The list must contain vectors of length two and all variables in these vectors <strong>must also be passed as independent variables</strong> (see the examples). Note the following:
</p>

<ul>
<li><p> When an interaction is between two independent background continuous variables (i.e. both are passed to <code>bckg.indep.cont.vars</code>), the interaction effect will be computed between them as they are.
</p>
</li>
<li><p> When the interaction is between two categorical variables (i.e. both are passed to <code>bckg.indep.cat.vars</code>), the interaction effect will be computed between each possible pair of categories of the two variables, except for the reference categories.
</p>
</li>
<li><p> When the interaction is between one continuous (i.e. passed to <code>bckg.indep.cont.vars</code>) and one categorical (i.e. passed to <code>bckg.indep.cat.vars</code>), the interaction effect will be computed between the continuous variable and each category of the categorical variable, except for the reference category.
</p>
</li>
<li><p> When the interaction is between a continuous variable (i.e. passed to <code>bckg.indep.cont.vars</code>) and a set of PVs (i.e. passed to <code>PV.root.indep</code>), the interaction effect is computed between the continuous variable and each PV in the set and the results are aggregated.
</p>
</li>
<li><p> When the interaction is between a categorical variable  (i.e. passed to <code>bckg.indep.cat.vars</code>) and a set of PVs (i.e. passed to <code>PV.root.indep</code>), the interaction effect is computed between each category of the categorical variable (except the reference category) and each PV in the set. The results are aggregated for each of the categories of the categorical variables and the set of PVs.
</p>
</li>
<li><p> When the interaction is between two sets of PVs (i.e. passed to <code>PV.root.indep</code>), the interaction effect is computed between the first PV in the first set and the first PV in the second set, the second PV in the first set and the second PV in the second set, and so on. The results are then aggregated.
</p>
</li></ul>

<p>If <code>norm.weight = TRUE</code>, the weights will be normalized before used in the model. This may be necessary in some countries in some studies extreme weights for some of the cases may result in inflated estimates due to model perfect separation. The consequence of normalizing weights is that the number of elements in the population will sum to the number of cases in the sample. Use with caution.
</p>
<p>If <code>include.missing = FALSE</code> (default), all cases with missing values on the splitting variables will be removed and only cases with valid values will be retained in the statistics. Note that the data from the studies can be exported in two different ways: (1) setting all user-defined missing values to <code>NA</code>; and (2) importing all user-defined missing values as valid ones and adding their codes in an additional attribute to each variable. If the <code>include.missing</code> is set to <code>FALSE</code> (default) and the data used is exported using option (2), the output will remove all values from the variable matching the values in its <code>missings</code> attribute. Otherwise, it will include them as valid values and compute statistics for them.
</p>
<p>The <code>shortcut</code> argument is valid only for TIMSS, eTIMSS PSI, TIMSS Advanced, TIMSS Numeracy, PIRLS, ePIRLS, PIRLS Literacy and RLII. Previously, in computing the standard errors, these studies were using 75 replicates because one of the schools in the 75 JK zones had its weights doubled and the other one has been taken out. Since TIMSS 2015 and PIRLS 2016 the studies use 150 replicates and in each JK zone once a school has its weights doubled and once taken out, i.e. the computations are done twice for each zone. For more details see Foy &amp; LaRoche (2016) and Foy &amp; LaRoche (2017). If replication of the tables and figures is needed, the <code>shortcut</code> argument has to be changed to <code>TRUE</code>.
The function provides two-tailed <em>t</em>-test and <em>p</em>-values for the regression coefficients.
</p>


<h3>Value</h3>

<p>If <code>save.output = FALSE</code>, a list containing the estimates and analysis information. If <code>save.output = TRUE</code> (default), an MS Excel (<code>.xlsx</code>) file (which can be opened in any spreadsheet program), as specified with the full path in the <code>output.file</code>. If the argument is missing, an Excel file with the generic file name &quot;Analysis.xlsx&quot; will be saved in the working directory (<code>getwd()</code>). The workbook contains four spreadsheets. The first one (&quot;Estimates&quot;) contains a table with the results by country and the final part of the table contains averaged results from all countries' statistics. The following columns can be found in the table, depending on the specification of the analysis:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> n_Cases - the number of cases in the sample used to compute the statistics.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the estimated population number of elements per group after applying the weights. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the the estimated population number of elements per group. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentages of respondents (population estimates) per groups defined by the splitting variables in <code>split.vars</code>. The percentages will be for the last splitting variable which defines the final groups.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the percentages from above.
</p>
</li>
<li><p> Variable - the variable names (background/contextual or PV root names, or contrast coded variable names).
</p>
</li>
<li><p> Coefficients - the logistic regression coefficients (intercept and slopes).
</p>
</li>
<li><p> Coefficients_SE - the standard error of the logistic regression coefficients (intercepts and slopes) for each independent variable (background/contextual or PV root names, or contrast coded variable names) in the model.
</p>
</li>
<li><p> Coefficients_SVR - the sampling variance component for the logistic regression coefficients if root PVs are specified either as dependent or independent variables.
</p>
</li>
<li><p> Coefficients_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>MVR - the measurement variance component for the logistic regression coefficients if root PVs are specified either as dependent or independent variables.
</p>
</li>
<li><p> Wald_Statistic - Wald (<em>z</em>) statistic.
</p>
</li>
<li><p> p_value - the <em>p</em>-value for the regression coefficients.
</p>
</li>
<li><p> Odds_Ratio - the odds ratios of the logistic regression.
</p>
</li>
<li><p> Odds_Ratio_SE - the standard errors for the odds ratios of the logistic regression.
</p>
</li>
<li><p> Wald_L95CI - the lower 95% model-based confidence intervals for the logistic regression coefficients.
</p>
</li>
<li><p> Wald_U95CI - the upper 95% model-based confidence intervals for the logistic regression coefficients.
</p>
</li>
<li><p> Odds_L95CI - the lower 95% model-based confidence intervals for the odds ratios.
</p>
</li>
<li><p> Odds_U95CI - the upper 95% model-based confidence intervals for the odds ratios.
</p>
</li></ul>

<p>When interaction terms are included, the cells with the interactions in the <code>Variables</code> column will contain the names of the two variables in each of the interaction terms, divided by colon, e.g. <code>ASBGSSB:ASBGHRL</code>.
</p>
<p>The second sheet contains the model statistics:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> Statistic - a column containing the Null Deviance (-2LL, no predictors in the model, just constant, also called &quot;baseline&quot;), Deviance (-2LL, after adding predictors, residual deviance, also called &quot;new&quot;), DF Null (degrees of freedom for the null deviance), DF Residual (degrees of freedom for the residual deviance), Akaike Information Criteria (AIC), Bayesian information criterion (BIC), model Chi-Square, different R-Squared statistics (Hosmer &amp; Lemeshow - HS, Cox &amp; Snell - CS, and Nagelkerke - N).
</p>
</li>
<li><p> Estimate - the numerical estimates for each of the above.
</p>
</li>
<li><p> Estimate_SE - the standard errors of the estimates from above.
</p>
</li>
<li><p> Estimate_SVR - the sampling variance component if PVs were included in the model.
</p>
</li>
<li><p> Estimate_MVR - the measurement variance component if PVs were included in the model.
</p>
</li></ul>

<p>The third sheet contains some additional information related to the analysis per country in columns:
</p>

<ul>
<li><p> DATA - used <code>data.file</code> or <code>data.object</code>.
</p>
</li>
<li><p> STUDY - which study the data comes from.
</p>
</li>
<li><p> CYCLE - which cycle of the study the data comes from.
</p>
</li>
<li><p> WEIGHT - which weight variable was used.
</p>
</li>
<li><p> DESIGN - which resampling technique was used (JRR or BRR).
</p>
</li>
<li><p> SHORTCUT - logical, whether the shortcut method was used.
</p>
</li>
<li><p> NREPS - how many replication weights were used.
</p>
</li>
<li><p> ANALYSIS_DATE - on which date the analysis was performed.
</p>
</li>
<li><p> START_TIME - at what time the analysis started.
</p>
</li>
<li><p> END_TIME - at what time the analysis finished.
</p>
</li>
<li><p> DURATION - how long the analysis took in hours, minutes, seconds and milliseconds.
</p>
</li></ul>

<p>The fourth sheet contains the call to the function with values for all parameters as it was executed. This is useful if the analysis needs to be replicated later.
</p>


<h3>References</h3>

<p>LaRoche, S., Joncas, M., &amp; Foy, P. (2016). Sample Design in TIMSS 2015. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (pp. 3.1-3.37). Chestnut Hill, MA: TIMSS &amp; PIRLS International Study Center.
LaRoche, S., Joncas, M., &amp; Foy, P. (2017). Sample Design in PIRLS 2016. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in PIRLS 2016</em> (pp. 3.1-3.34). Chestnut Hill, MA: Lynch School of Education, Boston College.
UCLA: Statistical Consulting Group. 2020. &quot;R LIBRARY CONTRAST CODING SYSTEMS FOR CATEGORICAL VARIABLES.&quot; <em>IDRE Stats - Statistical Consulting Web Resources</em>. Retrieved June 16, 2020 (https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/).
Hilbe, J. M. (2015). <em>Practical Guide to Logistic Regression</em>. CRC Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>, , <code><a href="#topic+lsa.vars.dict">lsa.vars.dict</a></code>, <code><a href="#topic+lsa.recode.vars">lsa.recode.vars</a></code>, <code><a href="#topic+lsa.lin.reg">lsa.lin.reg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute logistic regression predicting the log of the odds the students will respond
# "Agree a lot" when asked if teachers are fair (dependent variable, categorical), as a function
# of their own sense of school belonging (independent variable, continuous) using PIRLS 2016
# student data. Because the dependent variable has four categories, it needs to be recoded first
# into a dichotomous (using the \code{lsa.recode.vars}).
## Not run: 
lsa.recode.vars(data.file = "C:/temp/test.RData", src.variables = "ASBG12D",
old.new = "1=2;2=2;3=1;4=1;5=3", new.variables = "ASBG12Dr",
new.labels = c("Disagree", "Agree", "Omitted or invalid"),
missings.attr = "Omitted or invalid",
variable.labels = "GEN/AGREE/TEACHERS ARE FAIR - RECODED",
out.file = "C:/temp/test.RData")

lsa.bin.log.reg(data.file = "C:/temp/test.RData", split.vars = "ASBG01",
bin.dep.var = "ASBG12Dr", bckg.indep.cont.vars = "ASBGSSB")

## End(Not run)

# Perform the same analysis from above, this time use the overall student reading achievement
# as a predictor.
## Not run: 
lsa.bin.log.reg(data.object = test, split.vars = "ASBG01",
bin.dep.var = "ASBG12Dr", PV.root.indep = "ASRREA")

## End(Not run)

# Compute linear regression with interaction terms using PIRLS 2016 student data.
## Not run: 
lsa.bin.log.reg(data.file = "C:/temp/test.RData", bin.dep.var = "ASBG05B",
bckg.indep.cont.vars = "ASBGSSB", bckg.indep.cat.vars = c("ASBG01", "ASBG12B"),
PV.root.indep = c("ASRREA", "ASRLIT"),
interactions = list(c("ASBG12B", "ASBGSSB"), c("ASBG01", "ASRLIT")))

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.convert.data'>Convert Large-Scale Assessments' Datasets to .RData Format</h2><span id='topic+lsa.convert.data'></span><span id='topic+print.lsa.data'></span><span id='topic+lsa.select.countries.PISA'></span>

<h3>Description</h3>

<p><code>lsa.convert.data</code> converts datasets from large-scale assessments from their original formats (SPSS or ASCII text) into <code>.RData</code> files. <code>print</code> prints the properties of an <code>lsa.data</code> objects on screen. <code>lsa.select.countries.PISA</code> lets selecting PISA data from specific countries for analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.convert.data(
  inp.folder,
  PISApre15 = FALSE,
  ISO,
  missing.to.NA = FALSE,
  out.folder
)

## S3 method for class 'lsa.data'
print(x, col.nums, ...)

lsa.select.countries.PISA(data.file, data.object, cnt.names, output.file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.convert.data_+3A_inp.folder">inp.folder</code></td>
<td>
<p>The folder containing the IEA-like SPSS data files or ASCII text files and
<code>.sps</code> import files for OECD PISA data from cycles prior to 2015.
See details.
If blank, the working directory (<code>getwd()</code>) is used.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_pisapre15">PISApre15</code></td>
<td>
<p>When converting PISA files, set to <code>TRUE</code> if the input files are from
PISA cycles prior 2015 (ASCII text format with <code>.sps</code> control files)
or to <code>FALSE</code> (default) if they are in SPSS <code>.sav</code> format, as in
the case of IEA studies and the like and OECD PISA 2015 or later. Ignored
if the input folder contains IEA-like studies.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_iso">ISO</code></td>
<td>
<p>Vector containing character ISO codes of the countries' data files to
convert (e.g. <code>ISO = c("aus", "svn")</code>). If none of the files contain
the specified ISO codes in their names, the codes are ignored and a warning
is shown. Ignored when converting PISA files (both for cycles prior 2015
and 2015 and later). This argument is case-insensitive, i.e. the ISO codes
can be passed as lower- or upper-case.
(lower or upper) as the original SPSS <code>.sav</code> files.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_missing.to.na">missing.to.NA</code></td>
<td>
<p>Should the user-defined missing values be recoded to <code>NA</code>? If
<code>TRUE</code>, all user-defined missing values from the SPSS files (or
specified in the OECD PISA import syntax files) are all imported as
<code>NA</code>. If <code>FALSE</code> (default), they are converted to valid values
and the missing codes are assigned to an attribute <code>missings</code> for
each variable. See details.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_out.folder">out.folder</code></td>
<td>
<p>Path to the folder where the converted files will be stored. If omitted,
same as the <code>inp.folder</code>, and if the <code>inp.folder</code> is missing as
well, this will be <code>getwd()</code>.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_x">x</code></td>
<td>
<p>(<code>print</code> only) <code>lsa.data</code> object.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_col.nums">col.nums</code></td>
<td>
<p>(<code>print</code> only) Which columns to print, positions by number.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_...">...</code></td>
<td>
<p>(<code>print</code> only) Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_data.file">data.file</code></td>
<td>
<p>(<code>lsa.select.countries.PISA</code> only) Converted PISA data file to select
countries' data from. Either this one or <code>data.object</code> must be
provided, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_data.object">data.object</code></td>
<td>
<p>(<code>lsa.select.countries.PISA</code> only) PISA object in memory to filter.
Either this one or <code>data.file</code> must be provided, but not both.
See details.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_cnt.names">cnt.names</code></td>
<td>
<p>(<code>lsa.select.countries.PISA</code> only) Character vector containing the
names of the countries, as they exist in the data, which should stay in the
PISA exported file or object in memory.</p>
</td></tr>
<tr><td><code id="lsa.convert.data_+3A_output.file">output.file</code></td>
<td>
<p>(<code>lsa.select.countries.PISA</code> only) Full path to the file with the filtered
countries' data to be written on disk. If not provided, the PISA object
will be written to memory.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>lsa.convert.data</code> function converts the originally provided data files into <code>.RData</code> sets. RALSA adds its own method for printing <code>lsa.data</code> objects on screen. The <code>lsa.select.countries.PISA</code> is a utility function that allows the user to select countries of interest from a converted PISA data file (or PISA object residing in memory) and remove the rest of the countries' data. This is useful when the user does not want to analyze all countries data in a PISA file.
</p>

<ul>
<li> <p><strong><code>lsa.convert.data</code></strong>
</p>
<p>IEA studies, as well as OECD TALIS and some conducted by other organizations, provide their data in SPSS <code>.sav</code> format with same or very similar structure: one file per country and type of respondent (e.g. school principal, student, teacher, etc.) per population. For IEA studies and OECD TALIS use the <code>ISO</code> argument to specify the countries' three-letter ISO codes whose data is to be converted. The three-letter ISO codes for each country can be found in the user guide for the study in scope. For example, the ISO codes of the countries participating in PIRLS 2016 can be found in its user guide on pages 52-54. To convert the files from all countries in the downloaded data from IEA studies and OECD TALIS, simply omit the <code>ISO</code> argument. Cycles of OECD PISA prior to 2015, on the other hand, do not provide SPSS <code>.sav</code> or other binary files, but ASCII text files, accompanied with SPSS syntax (<code>.sps</code>) files that are used to import the text files into SPSS. These files are per each type of respondent containing all countries' data. The <code>lsa.convert.data</code> function converts the data from either source assuring that the structure of the output <code>.RData</code> files is the same, although the structure of the input files is different (SPSS binary files vs. ASCII text files plus import <code>.sps</code> files). The data from PISA 2015 and later, on the other hand, is provided in SPSS format (all countries in one file per type of respondent). Thus, the <code>PISApre15</code> argument needs to be specified as <code>TRUE</code> when converting data sets from PISA prior to its 2015 cycle. The default for the <code>PISApre15</code> argument is <code>FALSE</code> which means that the function expects to find IEA-like SPSS binary files per country and type of respondent in the directory in <code>inp.folder</code> or OECD PISA 2015 (or later) SPSS <code>.sav</code> files. If <code>PISApre15 = TRUE</code> and country codes are provided to <code>ISO</code>, they will be ignored because PISA files contain data from all countries together.
</p>
<p>The files to be converted must be in a folder on their own, from a single study, single cycle and single population. In addition, if there are more than one file types per study, cycle and population, these also must be in different folders. For example, in TIMSS 2019 the grade 8 data files are main (end with &quot;m7&quot;, electronic version of the paper administered items), bridge (end with &quot;b7&quot;, paper administration with trend items for countries participating in previous TIMSS cycles) and Problem Solving and Inquiry (PSI) tasks (end with &quot;z7&quot;, electronic administration only, optional for countries). These different types must be in separate folders. In case of OECD PISA prior 2015, the folder must contain both the ASCII text files and the SPSS <code>.sps</code> import syntax files. If the folder contains data sets from more than one study or cycle, the operation will break with error messages.
</p>
<p>If the path for the <code>inp.folder</code> argument is not specified, the function will search for files in the working directory (i.e. as returned by <code>getwd()</code>). If folder path for the the <code>out.folder</code> is not specified, it will take the one from the <code>inp.folder</code> and the files will be stored there. If both the <code>inp.folder</code> and <code>out.folder</code> arguments are missing, the directory from <code>getwd()</code> will be used to search, convert and store files.
</p>
<p>If <code>missing.to.NA</code> is set to <code>TRUE</code>, all user-defined missing values from the SPSS will be imported as <code>NA</code> which is <code>R</code>'s only kind of missing value. This will be the most often case when analyzing these data since the reason why the response is missing will be irrelevant most of the times. However, if it is needed to know why the reasons for missing responses, as when analyzing achievement items (i.e. not administered vs. omitted or not reached), the argument shall be set to <code>FALSE</code> (default for this argument) which will convert all user-defined missing values as valid ones.
</p>
</li>
<li> <p><strong><code>print</code></strong>
</p>
<p>RALSA uses its own method for printing objects of class <code>lsa.data</code> on screen. Passing just the object name to the console will print summarized information about the study's data and the first six columns of the dataset (see the Value section). If <code>col.nums</code> specifies which columns from the dataset shall be included in the output (see examples).
</p>
</li>
<li> <p><strong><code>lsa.select.countries.PISA</code></strong>
</p>
<p><code>lsa.select.countries.PISA</code> lets the user to take a PISA dataset, either a converted file or <code>lsa.data</code> object in the memory and reduce the number of countries in it by passing the names of the countries which need to be kept as a character vector to the <code>cnt.names</code> argument. If full path (including the file name) to the resulting file is specified in the <code>output.file</code> argument, it will be written on disk. If not, the data will be written to an <code>lsa.object</code> in memory with the same name as the input file. See the examples.
</p>
</li></ul>



<h3>Value</h3>


<ul>
<li> <p><strong><code>lsa.convert.data</code></strong>
</p>
<p><code>.RData</code> data files, containing an object with class <code>lsa.data</code>, an extension of the <code>data.table</code> class. The <code>data.table</code> object has the same name as the <code>.RData</code> file it is saved in. The object has additional attributes: study name (<code>study</code>), study cycle (<code>cycle</code>), and respondent file type (<code>file.type</code>). Each variable has its own additional attributes: its own label attached to it, if it existed in the source SPSS file. If the <code>missing.to.NA</code> was set to <code>TRUE</code>, each variable has an attribute <code>missings</code>, containing the user-defined missing values from the SPSS files.
</p>
<p>The object in the <code>.RData</code> file is keyed on the country ID variable.
</p>
</li>
<li> <p><strong><code>print</code></strong>
</p>
<p>Prints the information of an <code>lsa.data</code> object (study, cycle, respondent type, number of countries, key &ndash; country ID, and if the variables have user-defined missing values) and a preview of the data. The default preview (when no <code>col.nums</code>) are specified will include the first six columns.
</p>
</li>
<li> <p><strong><code>lsa.select.countries.PISA</code></strong>
</p>
<p>Writes a file containing an <code>lsa.object</code> with the data for the countries passed to the <code>cnt.names</code> argument, if the <code>output.file</code> argument is used. If the <code>output.file</code> argument is not used, the <code>lsa.object</code> will be written to the memory with the same name as the file name in <code>inp.file</code>.
</p>
</li></ul>



<h3>Note</h3>

<p>When downloading the <code>.sps</code> files (ASCII text and control <code>.sps</code>) for OECD PISA files prior to the 2015 cycle (say http://www.oecd.org/pisa/pisaproducts/pisa2009database-downloadabledata.htm), save them <strong>without changing their names and without modifying the file contents</strong>. The function will look for the files as they were named originally.
</p>
<p>Different studies and cycles define the &quot;I don't know&quot; (or similar) category of discrete variables in different ways - either as a valid or missing value. The <code>lsa.convert.data</code> function sets all such or similar codes to missing value. If this has to be changed, the <code>lsa.recode.vars</code> can be used as well (also see <code>lsa.vars.dict</code>).
</p>


<h3>References</h3>

<p>Foy, P. (Ed.). (2018). <em>PIRLS 2016 User Guide for the International Database</em>. TIMSS &amp; PIRLS International Study Center.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.merge.data">lsa.merge.data</a></code>, <code><a href="#topic+lsa.vars.dict">lsa.vars.dict</a></code>, <code><a href="#topic+lsa.recode.vars">lsa.recode.vars</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Convert all IEA-like SPSS files in the working directory, setting all user-defined missing
# values to \code{NA}
## Not run: 
lsa.convert.data(missing.to.NA = TRUE)

## End(Not run)


# Convert IEA TIMSS 2011 grade 8 data from Australia and Slovenia, keeping all user-defined
# missing values as valid ones specifying custom input and output directories
## Not run: 
lsa.convert.data(inp.folder = "C:/TIMSS_2011_G8", ISO = c("aus", "svn"), missing.to.NA = FALSE,
out.folder = "C:/Data")

## End(Not run)

# Convert OECD PISA 2009 files converting all user-defined missing values to \code{NA}
# using custom input and output directories
## Not run: 
lsa.convert.data(inp.folder = "/media/PISA_2009", PISApre15 = TRUE, missing.to.NA = TRUE,
out.folder = "/tmp")

## End(Not run)

# Print 20th to 25th column in PISA 2018 student questionnaire dataset loaded into memory
## Not run: 
print(x = cy07_msu_stu_qqq, col.nums = 20:25)

## End(Not run)

# Select data from Albania and Slovenia from PISA 2018 student questionnaire dataset
# and save it under the same file name in a different folder
## Not run: 
lsa.select.countries.PISA(data.file = "C:/PISA/cy07_msu_stu_qqq.RData",
cnt.names = c("Albania", "Slovenia"),
output.file = "C:/PISA/Reduced/cy07_msu_stu_qqq.RData")

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.convert.data2'>Convert Large-Scale Assessments' Datasets to .RData Format</h2><span id='topic+lsa.convert.data2'></span>

<h3>Description</h3>

<p><code>lsa.convert.data2</code> is a deprecated version of of the <code>lsa.convert.data</code> function using a different approach. It is an old version of the <code>lsa.convert.data</code> function and will be removed from the package in June of 2025. Use only if you experience issues with <code>lsa.convert.data</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.convert.data2(
  inp.folder,
  PISApre15 = FALSE,
  ISO,
  missing.to.NA = FALSE,
  out.folder
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.convert.data2_+3A_inp.folder">inp.folder</code></td>
<td>
<p>The folder containing the IEA-like SPSS data files or ASCII text files and
<code>.sps</code> import files for OECD PISA data from cycles prior to 2015.
See details.
If blank, the working directory (<code>getwd()</code>) is used.</p>
</td></tr>
<tr><td><code id="lsa.convert.data2_+3A_pisapre15">PISApre15</code></td>
<td>
<p>When converting PISA files, set to <code>TRUE</code> if the input files are from
PISA cycles prior 2015 (ASCII text format with <code>.sps</code> control files)
or to <code>FALSE</code> (default) if they are in SPSS <code>.sav</code> format, as in
the case of IEA studies and the like and OECD PISA 2015 or later. Ignored
if the input folder contains IEA-like studies.</p>
</td></tr>
<tr><td><code id="lsa.convert.data2_+3A_iso">ISO</code></td>
<td>
<p>Vector containing character ISO codes of the countries' data files to
convert (e.g. <code>ISO = c("aus", "svn")</code>). If none of the files contain
the specified ISO codes in their names, the codes are ignored and a warning
is shown. Ignored when converting PISA files (both for cycles prior 2015
and 2015 and later). This argument is case-insensitive, i.e. the ISO codes
can be passed as lower- or upper-case.
(lower or upper) as the original SPSS <code>.sav</code> files.</p>
</td></tr>
<tr><td><code id="lsa.convert.data2_+3A_missing.to.na">missing.to.NA</code></td>
<td>
<p>Should the user-defined missing values be recoded to <code>NA</code>? If
<code>TRUE</code>, all user-defined missing values from the SPSS files (or
specified in the OECD PISA import syntax files) are all imported as
<code>NA</code>. If <code>FALSE</code> (default), they are converted to valid values
and the missing codes are assigned to an attribute <code>missings</code> for
each variable. See details.</p>
</td></tr>
<tr><td><code id="lsa.convert.data2_+3A_out.folder">out.folder</code></td>
<td>
<p>Path to the folder where the converted files will be stored. If omitted,
same as the <code>inp.folder</code>, and if the <code>inp.folder</code> is missing as
well, this will be <code>getwd()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the details of <code>lsa.convert.data</code>.
</p>


<h3>Value</h3>

<p>See the &quot;Value&quot; section of the <code>lsa.convert.data</code>.
</p>


<h3>Note</h3>

<p>See the &quot;Notes&quot; section of <code>lsa.convert.data</code>.
</p>


<h3>References</h3>

<p>Foy, P. (Ed.). (2018). <em>PIRLS 2016 User Guide for the International Database</em>. TIMSS &amp; PIRLS International Study Center.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data2">lsa.convert.data2</a></code>, <code><a href="#topic+lsa.merge.data">lsa.merge.data</a></code>, <code><a href="#topic+lsa.vars.dict">lsa.vars.dict</a></code>, <code><a href="#topic+lsa.recode.vars">lsa.recode.vars</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See the examples of \code{lsa.convert.data}.

</code></pre>

<hr>
<h2 id='lsa.corr'>Compute correlations between variables within specified groups</h2><span id='topic+lsa.corr'></span>

<h3>Description</h3>

<p><code>lsa.corr</code> computes correlation coefficients between variables within groups defined by one or more variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.corr(
  data.file,
  data.object,
  split.vars,
  bckg.corr.vars,
  PV.root.corr,
  corr.type,
  weight.var,
  include.missing = FALSE,
  shortcut = FALSE,
  save.output = TRUE,
  output.file,
  open.output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.corr_+3A_data.file">data.file</code></td>
<td>
<p>The file containing <code>lsa.data</code> object. Either this or <code>data.object</code>
shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either this or
<code>data.file</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_split.vars">split.vars</code></td>
<td>
<p>Categorical variable(s) to split the results by. If no split variables are
provided, the results will be for the overall countries' populations.
If one or more variables are provided, the results will be split by all
but the last variable and the percentages of respondents will be computed
by the unique values of the last splitting variable.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_bckg.corr.vars">bckg.corr.vars</code></td>
<td>
<p>Names of continuous background or contextual variables to compute the
correlation coefficients for. The results will be computed by all groups
specified by the splitting variables. See details.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_pv.root.corr">PV.root.corr</code></td>
<td>
<p>The root names for the sets of plausible values to compute the correlation
coefficients for. See details.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_corr.type">corr.type</code></td>
<td>
<p>String of length one, specifying the type of the correlations to compute,
either <code>"Pearson"</code> (default) or <code>"Spearman"</code>.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_weight.var">weight.var</code></td>
<td>
<p>The name of the variable containing the weights. If no name of a weight
variable is provide, the function will automatically select the default
weight variable for the provided data, depending on the respondent type.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_include.missing">include.missing</code></td>
<td>
<p>Logical, shall the missing values of the splitting variables be included
as categories to split by and all statistics produced for them? The
default (<code>FALSE</code>) takes all cases on the splitting variables without
missing values before computing any statistics. See details.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_shortcut">shortcut</code></td>
<td>
<p>Logical, shall the &quot;shortcut&quot; method for IEA TIMSS, TIMSS Advanced,
TIMSS Numeracy, eTIMSS PSI, PIRLS, ePIRLS, PIRLS Literacy and RLII be
applied? The default (<code>FALSE</code>) applies the &quot;full&quot; design when
computing the variance components and the standard errors of the
estimates.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_save.output">save.output</code></td>
<td>
<p>Logical, shall the output be saved in MS Excel file (default) or not
(printed to the console or assigned to an object).</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_output.file">output.file</code></td>
<td>
<p>If <code>save.output = TRUE</code> (default), full path to the output file
including the file name. If omitted, a file with a default file name
&quot;Analysis.xlsx&quot; will be written to the working directory
(<code>getwd()</code>). Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsa.corr_+3A_open.output">open.output</code></td>
<td>
<p>Logical, shall the output be open after it has been written? The default
(<code>TRUE</code>) opens the output in the default spreadsheet program
installed on the computer. Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>The function computes correlation coefficients by the categories of the splitting variables. The percentages of respondents in each group are computed within the groups specified by the last splitting variable. If no splitting variables are added, the results will be computed only by country.
</p>
<p>Multiple continuous background variables and/or sets of plausible values can be provided to compute correlation coefficients for. Please note that in this case the results will slightly differ compared to using each pair of the same background continuous variables or PVs in separate analysis. This is because the cases with the missing values are removed in advance and the more variables are provided to compute correlations for, the more cases are likely to be removed. That is, the function support only listwisie deletion.
</p>
<p>Computation of correlation coefficients involving plausible values requires providing a root of the plausible values names in <code>PV.root.corr</code>. All studies (except CivED, TEDS-M, SITES, TALIS and TALIS Starting Strong Survey) have a set of PVs per construct (e.g. in TIMSS five for overall mathematics, five for algebra, five for geometry, etc.). In some studies (say TIMSS and PIRLS) the names of the PVs in a set always start with character string and end with sequential number of the PV. For example, the names of the set of PVs for overall mathematics in TIMSS are BSMMAT01, BSMMAT02, BSMMAT03, BSMMAT04 and BSMMAT05. The root of the PVs for this set to be added to <code>PV.root.corr</code> will be &quot;BSMMAT&quot;. The function will automatically find all the variables in this set of PVs and include them in the analysis. In other studies like OECD PISA and IEA ICCS and ICILS the sequential number of each PV is included in the middle of the name. For example, in ICCS the names of the set of PVs are PV1CIV, PV2CIV, PV3CIV, PV4CIV and PV5CIV. The root PV name has to be specified in <code>PV.root.corr</code> as &quot;PV#CIV&quot;. More than one set of PVs can be added. Note, however, that providing multiple continuous variables for the <code>bckg.avg.corr</code> argument and multiple PV roots for the <code>PV.root.corr</code> argument will affect the results for the correlation coefficients for the PVs because the cases with missing on <code>bckg.corr.vars</code> will be removed and this will also affect the results from the PVs (i.e. listwise deletion). On the other hand, using only sets of PVs to correlate should not affect the results on any PV estimates because PVs shall not have any missing values.
</p>
<p>A sufficient number of variable names (background/contextual) or PV roots have to be provided - either two background variables, or two PV roots, or mixture of them with total length of two (i.e. one background/contextual variable and one PV root).
</p>
<p>If <code>include.missing = FALSE</code> (default), all cases with missing values on the splitting variables will be removed and only cases with valid values will be retained in the statistics. Note that the data from the studies can be exported in two different ways: (1) setting all user-defined missing values to <code>NA</code>; and (2) importing all user-defined missing values as valid ones and adding their codes in an additional attribute to each variable. If the <code>include.missing</code> is set to <code>FALSE</code> (default) and the data used is exported using option (2), the output will remove all values from the variable matching the values in its <code>missings</code> attribute. Otherwise, it will include them as valid values and compute statistics for them.
</p>
<p>The <code>shortcut</code> argument is valid only for TIMSS, eTIMSS PSI, TIMSS Advanced, TIMSS Numeracy, PIRLS, ePIRLS, PIRLS Literacy and RLII. Previously, in computing the standard errors, these studies were using 75 replicates because one of the schools in the 75 JK zones had its weights doubled and the other one has been taken out. Since TIMSS 2015 and PIRLS 2016 the studies use 150 replicates and in each JK zone once a school has its weights doubled and once taken out, i.e. the computations are done twice for each zone. For more details see Foy &amp; LaRoche (2016) and Foy &amp; LaRoche (2017). If replication of the tables and figures is needed, the <code>shortcut</code> argument has to be changed to <code>TRUE</code>.
The function provides two-tailed <em>t</em>-test and <em>p</em>-values for the correlation coefficients.
</p>


<h3>Value</h3>

<p>If <code>save.output = FALSE</code>, a list containing the estimates and analysis information. If <code>save.output = TRUE</code> (default), an MS Excel (<code>.xlsx</code>) file (which can be opened in any spreadsheet program), as specified with the full path in the <code>output.file</code>. If the argument is missing, an Excel file with the generic file name &quot;Analysis.xlsx&quot; will be saved in the working directory (<code>getwd()</code>). The workbook contains three spreadsheets. The first one (&quot;Estimates&quot;) contains a table with the results by country and the final part of the table contains averaged results from all countries' statistics. The results are presented as a correlation matrices by the splitting variables. The following columns can be found in the table, depending on the specification of the analysis:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> n_Cases - the number of cases in the sample used to compute the statistics.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the estimated population number of elements per group after applying the weights. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the the estimated population number of elements per group. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentages of respondents (population estimates) per groups defined by the splitting variables in <code>split.vars</code>. The percentages will be for the last splitting variable which defines the final groups.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the percentages from above.
</p>
</li>
<li><p> Variable - the variable names (background/contextual or PV root names) to be matched against the rows of the following columns, forming the correlation matrices together.
</p>
</li>
<li><p> Correlation_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the correlation coefficient of each continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.corr.vars</code> against itself and each of the variables in the column &quot;Variable&quot;. There will be one column with correlation coefficient estimate for each variable specified in <code>bckg.corr.vars</code> and/or set of PVs specified in <code>PV.root.corr</code>.
</p>
</li>
<li><p> Correlation_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the correlation of each continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.corr.vars</code>. There will be one column with the SE of the correlation coefficient estimate for each variable specified in <code>bckg.corr.vars</code> and/or set of PVs specified in <code>PV.root.corr</code>.
</p>
</li>
<li><p> Correlation_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the correlation coefficient of each set of PVs specified as PV root name in <code>PV.root.corr</code> against itself and each of the variables in the column &quot;Variable&quot;. There will be one column with correlation coefficient estimate for each set of PVs specified in <code>PV.root.corr</code> and each other set of PVs specified in <code>PV.root.corr</code> and/or each continuous background variable specified in <code>bckg.corr.vars</code>.
</p>
</li>
<li><p> Correlation_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the correlation of each set of PVs specified as PV root name in <code>PV.root.corr</code>. There will be one column with the SE of the correlation coefficient estimate for each set of root PVs specified in <code>PV.root.corr</code> and another set of PVs specified in <code>PV.root.corr</code> and/or each continuous background variable specified in <code>bckg.corr.vars</code>.
</p>
</li>
<li><p> Correlation_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SVR - the sampling variance component for the correlation of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.corr</code>. There will be one column with the sampling variance component for the correlation coefficient estimate for each set of PVs specified in <code>PV.root.corr</code> with the other variables (other sets of PVs or background/contextual variables).
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>MVR - the measurement variance component for the correlation of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.corr</code>. There will be one column with the measurement variance component for the correlation coefficient estimate for each set of PVs specified in <code>PV.root.corr</code> with the other variables (other sets of PVs or background/contextual variables).
</p>
</li>
<li><p> Correlation_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SVR - the sampling variance component for the correlation of the particular background variable with a set of PVs specified in <code>PV.root.corr</code> it is correlated with. There will be one column with the sampling variance component for the average estimate for each background/contextual variable correlated with a set of PVs specified in <code>PV.root.corr</code>.
</p>
</li>
<li><p> Correlation_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>MVR - the measurement variance component for the correlation of the particular background variable PVs with a set of PVs specified in <code>PV.root.corr</code>. There will be one column with the measurement variance component for the correlation coefficient estimate for each background/contextual variable correlated with a set of PVs specified in <code>PV.root.corr</code>.
</p>
</li>
<li><p> t_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the <em>t</em>-test value for the correlation coefficients of a set of PVs when correlating them with other variables (background/contextual or other sets of PVs).
</p>
</li>
<li><p> t_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the <em>t</em>-test value for the correlation coefficients of background variables when correlating them with other variables (background/contextual or other sets of PVs).
</p>
</li>
<li><p> p_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the <em>p</em>-value for the correlation coefficients of a set of PVs when correlating them with other variables (background/contextual or other sets of PVs).
</p>
</li>
<li><p> p_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the <em>p</em>-value value for the correlation coefficients of background variables when correlating them with other variables (background/contextual or other sets of PVs).
</p>
</li></ul>

<p>The second sheet contains some additional information related to the analysis per country in columns:
</p>

<ul>
<li><p> DATA - used <code>data.file</code> or <code>data.object</code>.
</p>
</li>
<li><p> STUDY - which study the data comes from.
</p>
</li>
<li><p> CYCLE - which cycle of the study the data comes from.
</p>
</li>
<li><p> WEIGHT - which weight variable was used.
</p>
</li>
<li><p> DESIGN - which resampling technique was used (JRR or BRR).
</p>
</li>
<li><p> SHORTCUT - logical, whether the shortcut method was used.
</p>
</li>
<li><p> NREPS - how many replication weights were used.
</p>
</li>
<li><p> ANALYSIS_DATE - on which date the analysis was performed.
</p>
</li>
<li><p> START_TIME - at what time the analysis started.
</p>
</li>
<li><p> END_TIME - at what time the analysis finished.
</p>
</li>
<li><p> DURATION - how long the analysis took in hours, minutes, seconds and milliseconds.
</p>
</li></ul>

<p>The third sheet contains the call to the function with values for all parameters as it was executed. This is useful if the analysis needs to be replicated later.
</p>


<h3>References</h3>

<p>LaRoche, S., Joncas, M., &amp; Foy, P. (2016). Sample Design in TIMSS 2015. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (pp. 3.1-3.37). Chestnut Hill, MA: TIMSS &amp; PIRLS International Study Center.
LaRoche, S., Joncas, M., &amp; Foy, P. (2017). Sample Design in PIRLS 2016. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in PIRLS 2016</em> (pp. 3.1-3.34). Chestnut Hill, MA: Lynch School of Education, Boston College.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute correlations between the complex student background scales
# "Home Educational Resources/SCL", "Students Sense of School Belonging/SCL" and
# "Students Value Mathematics/SCL" by sex of students in TIMSS 2015 grade 8
# using data file, omit missing from the splitting variable (female and male
# as answered by the students), without shortcut, and open the output after the
# computations are done
## Not run: 
lsa.corr(data.file = "C:/Data/TIMSS_2015_G8_Student_Miss_to_NA.RData", split.vars = "BSBG01",
bckg.corr.vars = c("BSBGHER", "BSBGSSB", "BSBGSVM"), include.missing = FALSE,
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Compute correlations between the complex student background scales
# "Home Educational Resources/SCL" and "Students Sense of School Belonging/SCL"
# and the plausible values in overall mathematics and overall science by student
# sex and frequency of using computer or tablet at home using TIMSS 2015 grade 8
# data loaded in memory, using the shortcut, include the missing values in the
# splitting variables, and use the senate weights
## Not run: 
lsa.corr(data.object = T15_G8_student_data, split.vars = c("BSBG01", "BSBG13A"),
bckg.corr.vars = c("BSBGHER", "BSBGSSB"), PV.root.corr = c("BSMMAT", "BSSSCI"),
weight.var = "SENWGT", include.missing = FALSE, shortcut = TRUE,
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Compute the correlations between student overall reading achievement, overall mathematics
# scores (i.e. using a set of PVs) and student family wealth, using PISA 2018 student data
# loaded as object in the memory, by country, and do not open the output after the computations
# are finished
## Not run: 
lsa.corr(data.object = CY07_MSU_STU_QQQ, bckg.corr.vars = "WEALTH",
PV.root.corr = c("PV#MATH", "PV#READ"), include.missing = TRUE,
output.file = "C:/temp/test.xlsx", open.output = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.crosstabs'>Compute crosstabulations and design corrected chi-square statistics</h2><span id='topic+lsa.crosstabs'></span>

<h3>Description</h3>

<p><code>lsa.crosstabs</code> computes two-way tables and estimates the Rao-Scott first- and second-order adjusted chi-square.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.crosstabs(
  data.file,
  data.object,
  split.vars,
  bckg.row.var,
  bckg.col.var,
  expected.cnts = TRUE,
  row.pcts = FALSE,
  column.pcts = FALSE,
  total.pcts = FALSE,
  weight.var,
  include.missing = FALSE,
  shortcut = FALSE,
  graphs = FALSE,
  graph.row.label = NULL,
  graph.col.label = NULL,
  save.output = TRUE,
  output.file,
  open.output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.crosstabs_+3A_data.file">data.file</code></td>
<td>
<p>A file containing <code>lsa.data</code> object. Either this or
<code>data.object</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_data.object">data.object</code></td>
<td>
<p>An object in the memory containing <code>lsa.data</code>. Either this
or <code>data.file</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_split.vars">split.vars</code></td>
<td>
<p>Categorical variable(s) to split the results by. If no split variables
are provided, the results will be for the overall countries'
populations. If one or more variables are provided, the results will be
split by all but the last variable and the percentages of respondents
will be computed by the unique values of the last splitting variable.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_bckg.row.var">bckg.row.var</code></td>
<td>
<p>Name of the categorical background row variable. The results will be
computed by all groups specified by the splitting variables. See details.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_bckg.col.var">bckg.col.var</code></td>
<td>
<p>Name of the categorical background column variable. The results will be
computed by all groups specified by the splitting variables. See details.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_expected.cnts">expected.cnts</code></td>
<td>
<p>Logical, shall the expected counts be computed as well? The default
(<code>TRUE</code>) will compute the expected counts. If <code>FALSE</code>, only
the observed counts will be included in the output.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_row.pcts">row.pcts</code></td>
<td>
<p>Logical, shall row percentages be computed? The default (<code>FALSE</code>)
will skip the computation of the row percentages.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_column.pcts">column.pcts</code></td>
<td>
<p>Logical, shall column percentages be computed? The default (<code>FALSE</code>)
will skip the computation of the column percentages.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_total.pcts">total.pcts</code></td>
<td>
<p>Logical, shall percentages of total be computed? The default
(<code>FALSE</code>) will skip the computation of the total percentages.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_weight.var">weight.var</code></td>
<td>
<p>The name of the variable containing the weights. If no name of a weight
variable is provided, the function will automatically select the default
weight variable for the provided data, depending on the respondent type.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_include.missing">include.missing</code></td>
<td>
<p>Logical, shall the missing values of the splitting variables be included
as categories to split by and all statistics produced for them? The
default (<code>FALSE</code>) takes all cases on the splitting variables
without missing values before computing any statistics. See details.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_shortcut">shortcut</code></td>
<td>
<p>Logical, shall the &quot;shortcut&quot; method for IEA TIMSS, TIMSS Advanced,
TIMSS Numeracy, eTIMSS, PIRLS, ePIRLS, PIRLS Literacy and RLII be
applied? The default (<code>FALSE</code>) applies the &quot;full&quot; design when
computing the variance components and the standard errors of the
estimates.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_graphs">graphs</code></td>
<td>
<p>Logical, shall graphs be produced? Default is <code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_graph.row.label">graph.row.label</code></td>
<td>
<p>String, custom label for the row variable in graphs. Ignored if
<code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_graph.col.label">graph.col.label</code></td>
<td>
<p>String, custom label for the column variable in graphs. Ignored if
<code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_save.output">save.output</code></td>
<td>
<p>Logical, shall the output be saved in MS Excel file (default) or not
(printed to the console or assigned to an object).</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_output.file">output.file</code></td>
<td>
<p>If <code>save.output = TRUE</code> (default), full path to the output file
including the file name. If omitted, a file with a default file name
&quot;Analysis.xlsx&quot; will be written to the working directory
(<code>getwd()</code>). Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsa.crosstabs_+3A_open.output">open.output</code></td>
<td>
<p>Logical, shall the output be open after it has been written? The default
(<code>TRUE</code>) opens the output in the default spreadsheet program
installed on the computer. Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes two-way tables between two categorical variables and estimates the Rao-Scott first- and second-order design correction of the chi-square statistics. All statistics are computed within the groups specified by the last splitting variable. If no splitting variables are added, the results will be computed only by country.
</p>
<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>Only two (row and column) categorical variables can be provided. The function always computes the observed counts. If requested, the expected counts, row percentages, column percentages and total percentages can be computed as well.
</p>
<p>If <code>include.missing = FALSE</code> (default), all cases with missing values on the splitting variables will be removed and only cases with valid values will be retained in the statistics. Note that the data from the studies can be exported in two different ways: (1) setting all user-defined missing values to <code>NA</code>; and (2) importing all user-defined missing values as valid ones and adding their codes in an additional attribute to each variable. If the <code>include.missing</code> is set to <code>FALSE</code> (default) and the data used is exported using option (2), the output will remove all values from the variable matching the values in its <code>missings</code> attribute. Otherwise, it will include them as valid values and compute statistics for them.
</p>
<p>The <code>shortcut</code> argument is valid only for TIMSS, eTIMSS, TIMSS Advanced, TIMSS Numeracy, PIRLS, ePIRLS, PIRLS Literacy and RLII. Previously, in computing the standard errors, these studies were using 75 replicates because one of the schools in the 75 JK zones had its weights doubled and the other one has been taken out. Since TIMSS 2015 and PIRLS 2016 the studies use 150 replicates and in each JK zone once a school has its weights doubled and once taken out, i.e. the computations are done twice for each zone. For more details see Foy &amp; LaRoche (2016) and Foy &amp; LaRoche (2017).
</p>
<p>If <code>graphs = TRUE</code>, the function will produce graphs, heatmaps of counts per combination of <code>bckg.row.var</code> and <code>bckg.col.var</code> category (population estimates) per group defined by the <code>split.vars</code> will be produced. All plots are produced per country. If no <code>split.vars</code> at the end there will be a heatmap for all countries together. By default the row and column variable names are used for labeling the axes of the heatmaps, unless <code>graph.row.label</code> and/or <code>graph.col.label</code> arguments are supplied. These two arguments accept strings of length 1 which will be used to label the axes.
</p>
<p>The function also computes chi-square statistics with Rao-Scott first- and second-order design corrections because of the clustering in complex survey designs. For more details, see Rao &amp; Scott (1984, 1987) and Skinner (2019).
</p>


<h3>Value</h3>

<p>If <code>save.output = FALSE</code>, a list containing the estimates and analysis information. If <code>graphs = TRUE</code>, the plots will be added to the list of estimates.
</p>
<p>If <code>save.output = TRUE</code> (default), an MS Excel (<code>.xlsx</code>) file (which can be opened in any spreadsheet program), as specified with the full path in the <code>output.file</code>. If the argument is missing, an Excel file with the generic file name &quot;Analysis.xlsx&quot; will be saved in the working directory (<code>getwd()</code>). The workbook contains four spreadsheets. The first one (&quot;Estimates&quot;) contains a table with the results by country and the final part of the table contains averaged results from all countries' statistics. The following columns can be found in the table, depending on the specification of the analysis:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> n_Cases - the number of cases in the sample used to compute the statistics for each split combination defined by the <code>split.vars</code>, if any, and the <code>bckg.row.var</code>.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the estimated population number of elements per group after applying the weights. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the the estimated population number of elements per group. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Row variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentages of respondents (population estimates) per groups defined by the splitting variables in <code>split.vars</code>, if any, and the row variable in <code>bckg.row.var</code>. The percentages will be for the combination of categories in the last splitting variable and the row variable which define the final groups.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Row variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the percentages from above.
</p>
</li>
<li><p> Type - the type of computed values depending on the logical values passed to the <code>expected.cnts</code>, <code>row.pcts</code>, <code>column.pcts</code>, and <code>total.pcts</code> arguments: &quot;Observed count&quot;, &quot;Expected count&quot;, &quot;Row percent&quot;, &quot;Column percent&quot;, and &quot;Percent of total&quot;.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Column variable name Category 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Column variable name Category 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>,... - the estimated values for all combinations between the row and column variables passed to <code>bckg.row.var</code> and <code>bckg.col.var</code>. There will be one column for each category of the column variable.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Column variable name Category 1, 2,... n<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the estimated values from the above.
</p>
</li>
<li><p> Total - the grand totals for each of the estimated value types (&quot;Observed count&quot;, &quot;Expected count&quot;, &quot;Row percent&quot;, &quot;Column percent&quot;, and &quot;Percent of total&quot;) depending on the logical values (<code>TRUE</code>, <code>FALSE</code>) passed to the <code>expected.cnts</code>, <code>row.pcts</code>, <code>column.pcts</code>, and <code>total.pcts</code> arguments.
</p>
</li>
<li><p> Total<code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the estimated values from the above.
</p>
</li></ul>

<p>The second sheet contains some additional information related to the analysis per country in the following columns:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> Statistics - contains the names of the different statistics types: chi-squares, degrees of freedom (sample and design), and p-values.
</p>
</li>
<li><p> Value - the estimated values for the statistics from above.
</p>
</li></ul>

<p>The third sheet contains some additional information related to the analysis per country in the following columns:
</p>

<ul>
<li><p> DATA - used <code>data.file</code> or <code>data.object</code>.
</p>
</li>
<li><p> STUDY - which study the data comes from.
</p>
</li>
<li><p> CYCLE - which cycle of the study the data comes from.
</p>
</li>
<li><p> WEIGHT - which weight variable was used.
</p>
</li>
<li><p> DESIGN - which resampling technique was used (JRR or BRR).
</p>
</li>
<li><p> SHORTCUT - logical, whether the shortcut method was used.
</p>
</li>
<li><p> NREPS - how many replication weights were used.
</p>
</li>
<li><p> ANALYSIS_DATE - on which date the analysis was performed.
</p>
</li>
<li><p> START_TIME - at what time the analysis started.
</p>
</li>
<li><p> END_TIME - at what time the analysis finished.
</p>
</li>
<li><p> DURATION - how long the analysis took in hours, minutes, seconds and milliseconds.
</p>
</li></ul>

<p>The fourth sheet contains the call to the function with values for all parameters as it was executed. This is useful if the analysis needs to be replicated later.
</p>
<p>If <code>graphs = TRUE</code> there will be an additional &quot;Graphs&quot; sheet containing all plots.
</p>
<p>If any warnings resulting from the computations are issued, these will be included in an additional &quot;Warnings&quot; sheet in the workbook as well.
</p>


<h3>References</h3>

<p>LaRoche, S., Joncas, M., &amp; Foy, P. (2016). Sample Design in TIMSS 2015. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (pp. 3.1-3.37). Chestnut Hill, MA: TIMSS &amp; PIRLS International Study Center.
LaRoche, S., Joncas, M., &amp; Foy, P. (2017). Sample Design in PIRLS 2016. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in PIRLS 2016</em> (pp. 3.1-3.34). Chestnut Hill, MA: Lynch School of Education, Boston College.
Rao, J. N. K., &amp; Scott, A. J. (1984). On Chi-Squared Tests for Multiway Contingency Tables with Cell Proportions Estimated from Survey Data. <em>The Annals of Statistics</em>, <em>12</em>(1). https://doi.org/10.1214/aos/1176346391
Rao, J. N. K., &amp; Scott, A. J. (1987). On Simple Adjustments to Chi-Square Tests with Sample Survey Data. <em>The Annals of Statistics</em>, <em>15</em>(1), 385-397.
Skinner, C. (2019). Analysis of Categorical Data for Complex Surveys. <em>International Statistical Review</em>, <em>87</em>(S1), S64-S78. https://doi.org/10.1111/insr.12285
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute two-way table between student sex and how much they proud they are proud to go to
# school using PIRLS 2016 student data.
## Not run: 
lsa.crosstabs(data.file = "C:/Data/PIRLS_2016_G8_Student_Miss_to_NA.RData",
bckg.row.var = "ITSEX", bckg.col.var = "ASBG12E")

## End(Not run)

# Same as the above, this time also computing the expected counts, row percentages, column
# percentages, percentages of total.
## Not run: 
lsa.crosstabs(data.file = "C:/Data/PIRLS_2016_G8_Student_Miss_to_NA.RData",
bckg.row.var = "ITSEX", bckg.col.var = "ASBG12E", expected.cnts = TRUE,
row.pcts = TRUE, column.pcts = TRUE, total.pcts = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.data.diag'>Produce data diagnostic tables</h2><span id='topic+lsa.data.diag'></span>

<h3>Description</h3>

<p><code>lsa.data.diag</code> is a utility function which produces diagnostic tables for variables in an <code>lsa.data</code> object available in the memory or saved in an <code>.RData</code> file. The function can be used with regular <code>data.frame</code> or <code>data.table</code>, i.e. it is applicable not only to large-scale assessment data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.data.diag(
  data.file,
  data.object,
  split.vars,
  variables,
  weight.var,
  cont.freq = FALSE,
  include.missing = FALSE,
  output.file,
  open.output = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.data.diag_+3A_data.file">data.file</code></td>
<td>
<p>The file containing <code>lsa.data</code> object. Either this or
<code>data.object</code>
shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either this
or <code>data.file</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_split.vars">split.vars</code></td>
<td>
<p>Variable(s) to split the results by. If no split variables are
provided, the results will be computed on country level.
(if weights are used) or samples (if no weights are used). See details.</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_variables">variables</code></td>
<td>
<p>Names of the variables to compute statistics for. If the variables are
factors or character, frequencies will be computed, and if they are
numeric, descriptives will be computed, unless <code>cont.freq = TRUE</code>.
See details.</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_weight.var">weight.var</code></td>
<td>
<p>The name of the variable containing the weights, if weighted statistics
are needed. If no name of a weight variable is provided, the function
will automatically select the default weight variable for the provided
<code>lsa.data</code>, depending on the respondent type. <code>"none"</code> is
for unweighted statistics. See details.</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_cont.freq">cont.freq</code></td>
<td>
<p>Logical, shall the values of the numeric categories be treated as
categorical to compute frequencies for? See details.</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_include.missing">include.missing</code></td>
<td>
<p>Shall the <code>NA</code> and user-defined missing values (if available) be
included as splitting categories for the variables in <code>split.vars</code>?
The default is <code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_output.file">output.file</code></td>
<td>
<p>Full path to the output file including the file name. If omitted, a file
with a default file name &quot;Analysis.xlsx&quot; will be written to the working
directory (<code>getwd()</code>).</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_open.output">open.output</code></td>
<td>
<p>Logical, shall the output be open after it has been written? The default
(<code>TRUE</code>) opens the output in the default spreadsheet program
installed on the computer.</p>
</td></tr>
<tr><td><code id="lsa.data.diag_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function produces data diagnostic tables for variables in an <code>lsa.data</code> set by the categories of splitting variables. The function is also applicable to data sets which are not of class <code>lsa.data</code>, a regular <code>data.frame</code> or a <code>data.table</code> are accepted as well. If the data is of class <code>lsa.data</code> and no <code>split.vars</code> variables are provided, the results will be automatically split and computed by country. The country ID variable will be added automatically, there is no need to specify it explicitly in <code>split.vars</code>. If the data is not of class <code>lsa.data</code> and no <code>split.vars</code> variables are provided, the results will be computed without any split.
</p>
<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>If variables are provided for the <code>split.vars</code> argument and <code>include.missing = TRUE</code>, the function will automatically add the <code>NA</code> and user-defined missing values from the <code>missings</code> attribute (if available) of the <code>split.vars</code> variables to the categories to split by and will compute statistics for the provided <code>variables</code> for these as well. See the documentation on <code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code> for more details on the conversion of data with and without user-defined missing values.
</p>
<p>If no variable names are provided to <code>variables</code> all variables available in the data set will be added automatically, except the weighting and splitting variables, and statistics for all of them will be computed.
</p>
<p>If the variables provided to the <code>variables</code> argument are factor or character, the function will compute frequencies, percentages, valid percentages, and cumulative percentages. If the variables are numeric, the computed statistics will include the total number of cases, range, minimum, maximum, mean, variance, and standard deviation. If <code>cont.freq = TRUE</code>, then the numeric variables will be treated as factors.
</p>
<p>If the data set is of class <code>lsa.data</code> and no weight variable is provided, the computed statistics will be automatically weighted by the default weight for the respondents' data in the object. If the name of a weight variable is provided, the statistics will be weighted by it. If <code>weight.var = "none"</code>, the computed statistics will be unweighted. If the data is not of class <code>lsa.data</code> and no <code>weight.var</code> is provided, the computed statistics will be unweighted. If a weight variable is provided, the computed statistics will be weighted by it.
</p>


<h3>Value</h3>

<p>A MS Excel (<code>.xlsx</code>) file (which can be opened in any spreadsheet program), as specified with the full path in the <code>output.file</code>. If the argument is missing, an Excel file with the generic file name &quot;Analysis.xlsx&quot; will be saved in the working directory (<code>getwd()</code>). The first sheet in the workbook is an <code>Index</code> sheet. All other sheets contain the computed statistics for the variables, one sheet per variable. The <code>Index</code> sheet contains columns with the names of the variables for which statistics are computed and their labels, if available. The names are clickable links, if clicked, they switch to the corresponding sheet with statistics for the corresponding variable. If the data is of class <code>lsa.data</code>, the <code>Index</code> sheet also contains information with the study name, cycle, respondent type and used weight. If the data is not of class <code>lsa.data</code>, the <code>Index</code> sheet contains information only which weight was used. Each sheet with statistics for a variable contains a clickable link to go back to the <code>Index</code> sheet, the variable name and label (if any), and the table with statistics for that variable.
</p>


<h3>Note</h3>

<p>This function is intended only as utility function for diagnostic purposes, to inspect the variables prior to performing an actual analysis. It is <strong>not</strong> intended for actual analysis of large-scale assessments' data. Reporting statistics from it can and will lead to biased and erroneous conclusions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Merge PIRLS 2016 school principal data for all countries
## Not run: 
lsa.merge.data(inp.folder = "C:/Data", file.types = list(acg = NULL),
out.file = "C:/Merged/Merged.RData")

## End(Not run)

# Produce diagnostic tables for some factor (categorical) and numeric (continuous) variables
# by country
## Not run: 
lsa.data.diag(data.file = "C:/Merged/Merged.RData",
variables = c("ACBG05A", "ACBG04", "ACBGELS", "ACBGRRS"),
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Repeat the above, splitting the results by country and percentage of students at school
# coming from economically affluent homes ("ACBG03B")
## Not run: 
lsa.data.diag(data.file = "C:/Merged/Merged.RData",
split.vars = "ACBG03B", variables = c("ACBG05A", "ACBG04", "ACBGELS", "ACBGRRS"),
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Repeat the above, this time treating the numeric variables ("ACBGELS" and "ACBGRRS")
# as categorical
## Not run: 
lsa.data.diag(data.file = "C:/Merged/Merged.RData",
split.vars = "ACBG03B, include.missing = TRUE,
variables = c("ACBG05A", "ACBG04", "ACBGELS", "ACBGRRS"),
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Produce diag for all variables in the data set by country and percentage of students
# coming from economically affluent homes ("ASBG03B")
## Not run: 
lsa.data.diag(data.file = "C:/Merged/Merged.RData",
split.vars = "ACBG03B, output.file = "C:/temp/test.xlsx",
open.output = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.lin.reg'>Compute linear regression coefficients specified groups</h2><span id='topic+lsa.lin.reg'></span>

<h3>Description</h3>

<p><code>lsa.lin.reg</code> computes linear regression coefficients within groups defined by one or more variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.lin.reg(
  data.file,
  data.object,
  split.vars,
  bckg.dep.var,
  PV.root.dep,
  bckg.indep.cont.vars,
  bckg.indep.cat.vars,
  bckg.cat.contrasts,
  bckg.ref.cats,
  PV.root.indep,
  interactions,
  standardize = FALSE,
  weight.var,
  include.missing = FALSE,
  shortcut = FALSE,
  save.output = TRUE,
  output.file,
  open.output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.lin.reg_+3A_data.file">data.file</code></td>
<td>
<p>The file containing <code>lsa.data</code> object. Either this or
<code>data.object</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either
this or <code>data.file</code> shall be specified, but not both. See
details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_split.vars">split.vars</code></td>
<td>
<p>Categorical variable(s) to split the results by. If no split
variables are provided, the results will be for the overall
countries' populations. If one or more variables are provided, the
results will be split by all but the last variable and the
percentages of respondents will be computed by the unique values
of the last splitting variable.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_bckg.dep.var">bckg.dep.var</code></td>
<td>
<p>Name of a continuous background or contextual variable used as a
dependent variable in the model. See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_pv.root.dep">PV.root.dep</code></td>
<td>
<p>The root name for a set of plausible values used as a dependent
variable in the model. See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_bckg.indep.cont.vars">bckg.indep.cont.vars</code></td>
<td>
<p>Names of continuous independent background or contextual variables
used as predictors in the model. See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_bckg.indep.cat.vars">bckg.indep.cat.vars</code></td>
<td>
<p>Names of categorical independent background or contextual variables
used as predictors in the model to compute contrasts for (see
<code>bckg.cat.contrasts</code> and <code>bckg.ref.cats</code>). See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_bckg.cat.contrasts">bckg.cat.contrasts</code></td>
<td>
<p>String vector with the same length as the length of
<code>bckg.indep.cat.vars</code> specifying the type of contrasts to
compute in case <code>bckg.indep.cat.vars</code> are provided. See
details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_bckg.ref.cats">bckg.ref.cats</code></td>
<td>
<p>Vector of integers with the same length as the length of
<code>bckg.indep.cat.vars</code> and <code>bckg.cat.contrasts</code> specifying
the reference categories for the contrasts to compute in case
<code>bckg.indep.cat.vars</code> are provided. See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_pv.root.indep">PV.root.indep</code></td>
<td>
<p>The root names for a set of plausible values used as a independent
variables in the model. See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_interactions">interactions</code></td>
<td>
<p>Interaction terms - a list containing vectors of length of two. See
details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_standardize">standardize</code></td>
<td>
<p>Shall the dependent and independent variables be standardized to
produce beta coefficients? The default is <code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_weight.var">weight.var</code></td>
<td>
<p>The name of the variable containing the weights. If no name of a
weight variable is provide, the function will automatically select
the default weight variable for the provided data, depending on the
respondent type.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_include.missing">include.missing</code></td>
<td>
<p>Logical, shall the missing values of the splitting variables be
included as categories to split by and all statistics produced for
them? The default (<code>FALSE</code>) takes all cases on the splitting
variables without missing values before computing any statistics.
See details.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_shortcut">shortcut</code></td>
<td>
<p>Logical, shall the &quot;shortcut&quot; method for IEA TIMSS, TIMSS Advanced,
TIMSS Numeracy, eTIMSS PSI, PIRLS, ePIRLS, PIRLS Literacy and RLII
be applied? The default (<code>FALSE</code>) applies the &quot;full&quot; design
when computing the variance components and the standard errors of
the estimates.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_save.output">save.output</code></td>
<td>
<p>Logical, shall the output be saved in MS Excel file (default) or not
(printed to the console or assigned to an object).</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_output.file">output.file</code></td>
<td>
<p>If <code>save.output = TRUE</code> (default), full path to the output file
including the file name. If omitted, a file with a default file name
&quot;Analysis.xlsx&quot; will be written to the working directory
(<code>getwd()</code>). Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsa.lin.reg_+3A_open.output">open.output</code></td>
<td>
<p>Logical, shall the output be open after it has been written? The
default (<code>TRUE</code>) opens the output in the default spreadsheet
program installed on the computer. Ignored if
<code>save.output = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>The function computes linear regression coefficients by the categories of the splitting variables. The percentages of respondents in each group are computed within the groups specified by the last splitting variable. If no splitting variables are added, the results will be computed only by country.
</p>
<p>If <code>standardize = TRUE</code>, the variables will be standardized before computing any statistics to provide beta regression coefficients.
</p>
<p>Either a background/contextual variable (<code>bckg.dep.var</code>) or a root name of a set of plausible values (<code>PV.root.dep</code>) can be provided as dependent variable but not both.
</p>
<p>Background/contextual variables passed to <code>bckg.indep.cont.vars</code> will be treated as numeric variables in the model. Variables with discrete number of categories (i.e. factors) passed to <code>bckg.indep.cat.vars</code> will be used to compute contrasts. In this case the type of contrast has to be passed to <code>bckg.cat.contrasts</code> and the number of the reference categories for each of the <code>bckg.indep.cat.vars</code>. The number of types of contrasts and the reference categories must be the same as the number of <code>bckg.indep.cat.vars</code>. The currently supported contrast coding schemes are:
</p>

<ul>
<li> <p><code>dummy</code> - the intercept is the average on the dependent variable for the respondents choosing the reference category and the slopes are the differences between intercept and the average of respondents on the dependent variable choosing every other category.
</p>
</li>
<li> <p><code>deviation</code> - the intercept is the grand mean on the dependent variable regardless of the group and the slopes are the differences between intercept and the average of respondents on the dependent variable choosing every other category except the reference one.
</p>
</li>
<li> <p><code>simple</code> - the same as for the <code>dummy</code> contrast coding, except for the intercept which in this case is the grand mean.
</p>
</li></ul>

<p>Note that when using <code>standardize = TRUE</code>, the contrast coding of <code>bckg.indep.cat.vars</code> is not standardized. Thus, the regression coefficients may not be comparable to other software solutions for analyzing large-scale assessment data which rely on, for example, SPSS or SAS where the contrast coding of categorical variables (e.g. dummy coding) takes place by default. However, the model statistics will be identical.
</p>
<p>Multiple continuous or categorical background variables and/or sets of plausible values can be provided to compute regression coefficients for. Please note that in this case the results will slightly differ compared to using each pair of the same background continuous variables or PVs in separate analysis. This is because the cases with the missing values are removed in advance and the more variables are provided, the more cases are likely to be removed. That is, the function support only listwisie deletion.
</p>
<p>Computation of regression coefficients involving plausible values requires providing a root of the plausible values names in <code>PV.root.dep</code> and/or <code>PV.root.indep</code>. All studies (except CivED, TEDS-M, SITES, TALIS and TALIS Starting Strong Survey) have a set of PVs per construct (e.g. in TIMSS five for overall mathematics, five for algebra, five for geometry, etc.). In some studies (say TIMSS and PIRLS) the names of the PVs in a set always start with character string and end with sequential number of the PV. For example, the names of the set of PVs for overall mathematics in TIMSS are BSMMAT01, BSMMAT02, BSMMAT03, BSMMAT04 and BSMMAT05. The root of the PVs for this set to be added to <code>PV.root.dep</code> or <code>PV.root.indep</code> will be &quot;BSMMAT&quot;. The function will automatically find all the variables in this set of PVs and include them in the analysis. In other studies like OECD PISA and IEA ICCS and ICILS the sequential number of each PV is included in the middle of the name. For example, in ICCS the names of the set of PVs are PV1CIV, PV2CIV, PV3CIV, PV4CIV and PV5CIV. The root PV name has to be specified in <code>PV.root.dep</code> or <code>PV.root.indep</code> as &quot;PV#CIV&quot;. More than one set of PVs can be added in <code>PV.root.indep</code>.
</p>
<p>The function can also compute two-way interaction effects between independent variables by passing a list to the <code>interactions</code> argument. The list must contain vectors of length two and all variables in these vectors <strong>must also be passed as independent variables</strong> (see the examples). Note the following:
</p>

<ul>
<li><p> When an interaction is between two independent background continuous variables (i.e. both are passed to <code>bckg.indep.cont.vars</code>), the interaction effect will be computed between them as they are.
</p>
</li>
<li><p> When the interaction is between two categorical variables (i.e. both are passed to <code>bckg.indep.cat.vars</code>), the interaction effect will be computed between each possible pair of categories of the two variables, except for the reference categories.
</p>
</li>
<li><p> When the interaction is between one continuous (i.e. passed to <code>bckg.indep.cont.vars</code>) and one categorical (i.e. passed to <code>bckg.indep.cat.vars</code>), the interaction effect will be computed between the continuous variable and each category of the categorical variable, except for the reference category.
</p>
</li>
<li><p> When the interaction is between a continuous variable (i.e. passed to <code>bckg.indep.cont.vars</code>) and a set of PVs (i.e. passed to <code>PV.root.indep</code>), the interaction effect is computed between the continuous variable and each PV in the set and the results are aggregated.
</p>
</li>
<li><p> When the interaction is between a categorical variable  (i.e. passed to <code>bckg.indep.cat.vars</code>) and a set of PVs (i.e. passed to <code>PV.root.indep</code>), the interaction effect is computed between each category of the categorical variable (except the reference category) and each PV in the set. The results are aggregated for each of the categories of the categorical variables and the set of PVs.
</p>
</li>
<li><p> When the interaction is between two sets of PVs (i.e. passed to <code>PV.root.indep</code>), the interaction effect is computed between the first PV in the first set and the first PV in the second set, the second PV in the first set and the second PV in the second set, and so on. The results are then aggregated.
</p>
</li></ul>

<p>If <code>include.missing = FALSE</code> (default), all cases with missing values on the splitting variables will be removed and only cases with valid values will be retained in the statistics. Note that the data from the studies can be exported in two different ways: (1) setting all user-defined missing values to <code>NA</code>; and (2) importing all user-defined missing values as valid ones and adding their codes in an additional attribute to each variable. If the <code>include.missing</code> is set to <code>FALSE</code> (default) and the data used is exported using option (2), the output will remove all values from the variable matching the values in its <code>missings</code> attribute. Otherwise, it will include them as valid values and compute statistics for them.
</p>
<p>The <code>shortcut</code> argument is valid only for TIMSS, eTIMSS, TIMSS Advanced, TIMSS Numeracy, eTIMSS PSI, PIRLS, ePIRLS, PIRLS Literacy and RLII. Previously, in computing the standard errors, these studies were using 75 replicates because one of the schools in the 75 JK zones had its weights doubled and the other one has been taken out. Since TIMSS 2015 and PIRLS 2016 the studies use 150 replicates and in each JK zone once a school has its weights doubled and once taken out, i.e. the computations are done twice for each zone. For more details see Foy &amp; LaRoche (2016) and Foy &amp; LaRoche (2017). If replication of the tables and figures is needed, the <code>shortcut</code> argument has to be changed to <code>TRUE</code>.
The function provides two-tailed <em>t</em>-test and <em>p</em>-values for the regression coefficients.
</p>


<h3>Value</h3>

<p>If <code>save.output = FALSE</code>, a list containing the estimates and analysis information. If <code>save.output = TRUE</code> (default), an MS Excel (<code>.xlsx</code>) file (which can be opened in any spreadsheet program), as specified with the full path in the <code>output.file</code>. If the argument is missing, an Excel file with the generic file name &quot;Analysis.xlsx&quot; will be saved in the working directory (<code>getwd()</code>). The workbook contains four spreadsheets. The first one (&quot;Estimates&quot;) contains a table with the results by country and the final part of the table contains averaged results from all countries' statistics. The following columns can be found in the table, depending on the specification of the analysis:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> n_Cases - the number of cases in the sample used to compute the statistics.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the estimated population number of elements per group after applying the weights. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the the estimated population number of elements per group. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentages of respondents (population estimates) per groups defined by the splitting variables in <code>split.vars</code>. The percentages will be for the last splitting variable which defines the final groups.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the percentages from above.
</p>
</li>
<li><p> Variable - the variable names (background/contextual or PV root names, or contrast coded variable names).
</p>
</li>
<li><p> Coefficients - the regression coefficients (intercept and slopes).
</p>
</li>
<li><p> Coefficients_SE - the standard error of the regression coefficients (intercepts and slopes) for each independent variable (background/contextual or PV root names, or contrast coded variable names) in the model.
</p>
</li>
<li><p> Coefficients_SVR - the sampling variance component for the regression coefficients if root PVs are specified either as dependent or independent variables.
</p>
</li>
<li><p> Coefficients_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>MVR - the measurement variance component for the regression coefficients if root PVs are specified either as dependent or independent variables.
</p>
</li>
<li><p> t_value - the <em>t</em>-test value for the regression coefficients.
</p>
</li>
<li><p> p_value - the <em>p</em>-value for the regression coefficients.
</p>
</li></ul>

<p>When interaction terms are included, the cells with the interactions in the <code>Variables</code> column will contain the names of the two variables in each of the interaction terms, divided by colon, e.g. <code>ASBGSSB:ASBGHRL</code>.
</p>
<p>The second sheet contains the model statistics:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> Statistic - a column containing the R-Squared, adjusted R-Squared, F-Statistic and degrees of freedom estimates.
</p>
</li>
<li><p> Estimate - the numerical estimates for each of the above.
</p>
</li>
<li><p> Estimate_SE - the standard errors of the estimates from above.
</p>
</li>
<li><p> Estimate_SVR - the sampling variance component if PVs were included in the model.
</p>
</li>
<li><p> Estimate_MVR - the measurement variance component if PVs were included in the model.
</p>
</li>
<li><p> t_value - the <em>t</em>-test value for the regression coefficients, value only for the F-Statistic is provided.
</p>
</li>
<li><p> p_value - the <em>p</em>-value for the regression coefficients, value only for the F-Statistic is provided.
</p>
</li></ul>

<p>The third sheet contains some additional information related to the analysis per country in columns:
</p>

<ul>
<li><p> DATA - used <code>data.file</code> or <code>data.object</code>.
</p>
</li>
<li><p> STUDY - which study the data comes from.
</p>
</li>
<li><p> CYCLE - which cycle of the study the data comes from.
</p>
</li>
<li><p> WEIGHT - which weight variable was used.
</p>
</li>
<li><p> DESIGN - which resampling technique was used (JRR or BRR).
</p>
</li>
<li><p> SHORTCUT - logical, whether the shortcut method was used.
</p>
</li>
<li><p> NREPS - how many replication weights were used.
</p>
</li>
<li><p> ANALYSIS_DATE - on which date the analysis was performed.
</p>
</li>
<li><p> START_TIME - at what time the analysis started.
</p>
</li>
<li><p> END_TIME - at what time the analysis finished.
</p>
</li>
<li><p> DURATION - how long the analysis took in hours, minutes, seconds and milliseconds.
</p>
</li></ul>

<p>The fourth sheet contains the call to the function with values for all parameters as it was executed. This is useful if the analysis needs to be replicated later.
</p>


<h3>References</h3>

<p>LaRoche, S., Joncas, M., &amp; Foy, P. (2016). Sample Design in TIMSS 2015. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (pp. 3.1-3.37). Chestnut Hill, MA: TIMSS &amp; PIRLS International Study Center.
LaRoche, S., Joncas, M., &amp; Foy, P. (2017). Sample Design in PIRLS 2016. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in PIRLS 2016</em> (pp. 3.1-3.34). Chestnut Hill, MA: Lynch School of Education, Boston College.
UCLA: Statistical Consulting Group. 2020. &quot;R LIBRARY CONTRAST CODING SYSTEMS FOR CATEGORICAL VARIABLES.&quot; <em>IDRE Stats - Statistical Consulting Web Resources</em>. Retrieved June 16, 2020 (https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute linear regression coefficients with the complex student background scale "Student
# Sense of School Belonging/SCL" as dependent variable, and "Home Educational Resources/SCL"
# and "Students Value Science/SCL" as independent variables, by sex of students in TIMSS 2015
# grade 8 using data file, omit missing from the splitting variable (female and male as answered
# by the students), without shortcut, and open the output after the computations are done
## Not run: 
lsa.lin.reg(data.file = "C:/temp/test.RData", split.vars = "BSBG01", bckg.dep.var = "BSBGSSB",
bckg.indep.cont.vars = c("BSBGHER", "BSBGSVS"))

## End(Not run)

# Compute linear regression coefficients with the set of PVs on overall mathematics achievement
# as dependent variable, and "Home Educational Resources/SCL" and "Students Value Science/SCL"
# independent variables, by sex of students in TIMSS 2015 grade 8 using data file, omit missing
# from the splitting variable (female and male as answered by the students), with shortcut, and
# without opening the output after the computations are done
## Not run: 
lsa.lin.reg(data.file = "C:/temp/test.RData", split.vars = "BSBG01", PV.root.dep = "BSMMAT",
bckg.indep.cont.vars = c("BSBGHER", "BSBGSVS"), shortcut = TRUE, open.output = FALSE)

## End(Not run)

# Same as above, standardizing the coefficients
## Not run: 
lsa.lin.reg(data.file = "C:/temp/test.RData", split.vars = "BSBG01", PV.root.dep = "BSMMAT",
bckg.indep.cont.vars = c("BSBGHER", "BSBGSVS"), standardize = TRUE, shortcut = TRUE,
open.output = FALSE)

## End(Not run)

# Compute linear regression with contrast coded categorical variables, using student sex as
# splitting variable, the set of five PVs on overall mathematics achievement as dependent
# variable, and the frequency of speaking the language of test at home and the number of
# books at home as contrast (dummy and simple) coded variables where the second and the third
# categories, respectively, are the reference, without shortcut, saving the output in the home
# directory and opening it after the computations are done
## Not run: 
lsa.lin.reg(data.object = merged.TIMSS.2015, split.vars = "BSBG01", PV.root.dep = "BSMMAT",
bckg.indep.cat.vars = c("BSBG03", "BSBG04"), bckg.cat.contrasts = c("dummy", "simple"),
bckg.ref.cats = c(2, 3))

## End(Not run)

# Compute linear regression with interaction terms using PIRLS 2016 student data.
## Not run: 
lsa.lin.reg(data.file = "C:/temp/test.RData", bckg.dep.var = "ASBGSB",
bckg.indep.cont.vars = c("ASBGSSB", "ASBGHRL"), bckg.indep.cat.vars = "ASBG01",
interactions = list(c("ASBG01", "ASBGSSB"), c("ASBGHRL", "ASBGSSB")))

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.merge.data'>Merge study data from different countries and/or respondents</h2><span id='topic+lsa.merge.data'></span>

<h3>Description</h3>

<p><code>lsa.merge.data</code> combines data from different countries and/or different respondents (e.g. students and teachers, or students and schools).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.merge.data(inp.folder, file.types, ISO, out.file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.merge.data_+3A_inp.folder">inp.folder</code></td>
<td>
<p>Folder containing the data sets. The data sets must be <code>.RData</code>, produced
by <code>lsa.convert.data</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.merge.data_+3A_file.types">file.types</code></td>
<td>
<p>What file types (i.e. respondents) shall be merged? See details.</p>
</td></tr>
<tr><td><code id="lsa.merge.data_+3A_iso">ISO</code></td>
<td>
<p>Vector containing character ISO codes of the countries' data files to include
in the merged file. See details.</p>
</td></tr>
<tr><td><code id="lsa.merge.data_+3A_out.file">out.file</code></td>
<td>
<p>Full path to the file the data shall be stored in. The object stored in the
file will have the same name. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function merges files from studies where the files are per country and respondent type (e.g. student, school, teacher). That is, all studies except PISA.
</p>
<p>The <code>inp.folder</code> specifies the path to the folder containing the <code>.RData</code> files produced by <code>lsa.convert.data</code>. The folder must contain only files for a single study, single cycle and single population (e.g. TIMSS 2015 grade 4 or TIMSS 2015 grade 8, but not both), or mode of administration (e.g. either PIRLS 2016 or ePIRLS 2016, but not both; or TIMSS 2019 or TIMSS 2019 Bridge, but not both). All files in the input folder must be exported with the same option (<code>TRUE</code> or <code>FALSE</code>) of the <code>missing.to.NA</code> argument of the <code>lsa.convert.data</code> function. If input folder is not provided to the argument, the working folder (<code>getwd()</code>) will be used.
</p>
<p>The <code>file.types</code> is a list of the respondent types as component names and their variables as elements to be merged. The file type names are three-character codes, the first three characters of the corresponding file names. The elements are vectors of upper case variable names, <code>NULL</code> takes all variables in the corresponding file. For example, in TIMSS <code>asg</code> will merge only student-level data from grade 4, <code>c(asg, atg)</code> will merge the student-level and teacher-level data from grade 4, <code>c(bsg, btm)</code> will merge student-level and mathematics teacher-level data from grade 8. If a merge is not possible by the study design, the function will stop with an error. See the examples.
</p>
<p>The <code>ISO</code> is a character vector specifying the countries whose data shall be merged. The elements of the vector are the fourth, fifth and sixth characters in the file names. For example, <code>c("aus", "swe", "svn")</code> will merge the data from Australia, Sweden and Slovenia for the file types specified in <code>file.types</code>. The three-letter ISO codes for each country can be found in the user guide for the study in scope. For example, the ISO codes of the countries participating in PIRLS 2016 can be found in its user guide on pages 52-54. If file for specific country does not exist in the <code>inp.folder</code>, a warning will be issued. If the <code>ISO</code> argument is missing, the files for all countries in the folder will be merged for the specified <code>file.types</code>.
</p>
<p>The <code>out.file</code> must contain full path (including the <code>.RData</code> extension, if missing, it will be added) to the output file (i.e. the file containing merged data). The file contains object with the same name and has a class extension <code>lsa.data</code>. It has additional attribute <code>file.type</code> showing data from which respondents is available after the merging has been done. For example, merging the student-level data with teacher-level data in TIMSS grade 4 will assign &quot;std.bckg.tch.bckg&quot; to this attribute. The object has two additional attributes: study name (<code>study</code>) and study cycle (<code>cycle</code>). The object in the <code>.RData</code> file is keyed on the country ID variable. If output folder is not provided, the merged file will be saved in the working folder (<code>getwd()</code>) as <code>merged_data.RData</code>.
</p>


<h3>Value</h3>

<p><code>.RData</code> data file containing an object with class <code>lsa.data</code>, an extension of the <code>data.table</code> class. The <code>data.table</code> object has the same name as the <code>.RData</code> file it is saved in. The object contains the data from different respondents and/or countries merged and has additional attributes: study name (<code>study</code>), study cycle (<code>cycle</code>), and respondent file type (<code>file.type</code>). Each variable has its own additional attributes: its own label attached to it, if it existed in the source SPSS file. If the <code>missing.to.NA</code> in the source file was set to <code>TRUE</code>, each variable has an attribute <code>missings</code>, containing the user-defined missing values.
</p>


<h3>References</h3>

<p>Foy, P. (Ed.). (2018). <em>PIRLS 2016 User Guide for the International Database</em>. TIMSS &amp; PIRLS International Study Center.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Merge TIMSS 2015 grade 4 student and teacher variables for Australia, Chinese Taipei and
# Slovenia taking all variables in both files
## Not run: 
lsa.merge.data(inp.folder = "C:/Data", file.types = list(asg = NULL, atg = NULL),
ISO = c("aus", "twn", "svnn"), out.file = "C:/Merged/Merged.RData")

## End(Not run)

# Same as the above, taking just few variables from each file
## Not run: 
lsa.merge.data(inp.folder = "C:/Data",
file.types = list(asg = c("ASBG01", "ASBG02A", "ASBG02B"),
atg = c("ATBG01", "ATBG02", "ATBG03")), ISO = c("aus", "twn", "svnn"),
out.file = "C:/Merged/Merged.RData")

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.pcts.means'>Compute percentages of respondents in groups and/or means (arithmetic average, median or mode) on continuous variables within specified groups</h2><span id='topic+lsa.pcts.means'></span>

<h3>Description</h3>

<p><code>lsa.pcts.means</code> computes percentages of respondents within groups defined by one or more variables and the means for one or more variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.pcts.means(
  data.file,
  data.object,
  split.vars,
  bckg.avg.vars,
  PV.root.avg,
  central.tendency,
  weight.var,
  include.missing = FALSE,
  shortcut = FALSE,
  graphs = FALSE,
  perc.x.label = NULL,
  perc.y.label = NULL,
  mean.x.labels = NULL,
  mean.y.labels = NULL,
  save.output = TRUE,
  output.file,
  open.output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.pcts.means_+3A_data.file">data.file</code></td>
<td>
<p>The file containing <code>lsa.data</code> object. Either this or
<code>data.object</code> shall be specified, but not both.
See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either
this or <code>data.file</code> shall be specified, but not both.
See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_split.vars">split.vars</code></td>
<td>
<p>Categorical variable(s) to split the results by. If no split variables
are provided, the results will be for the overall countries'
populations. If one or more variables are provided, the results will
be split by all but the last variable and the percentages of
respondents will be computed by the unique values of the last splitting
variable.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_bckg.avg.vars">bckg.avg.vars</code></td>
<td>
<p>Name(s) of continuous background or contextual variable(s) to compute
the means for. The results will be computed by all groups specified by
the splitting variables. See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_pv.root.avg">PV.root.avg</code></td>
<td>
<p>The root name(s) for the set(s) of plausible values. See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_central.tendency">central.tendency</code></td>
<td>
<p>Which measure of central tendency shall be computed - <code>mean</code>
(default) <code>median</code> or <code>mode</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_weight.var">weight.var</code></td>
<td>
<p>The name of the variable containing the weights. If no name of a weight
variable is provided, the function will automatically select the
default weight variable for the provided data, depending on the
respondent type.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_include.missing">include.missing</code></td>
<td>
<p>Logical, shall the missing values of the splitting variables be
included as categories to split by and all statistics produced for
them? The default (<code>FALSE</code>) takes all cases on the splitting
variables without missing values before computing any statistics.
See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_shortcut">shortcut</code></td>
<td>
<p>Logical, shall the &quot;shortcut&quot; method for IEA TIMSS, TIMSS Advanced,
TIMSS Numeracy, eTIMSS PSI, PIRLS, ePIRLS, PIRLS Literacy and RLII be
applied? The default (<code>FALSE</code>) applies the &quot;full&quot; design when
computing the variance components and the standard errors of the
estimates.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_graphs">graphs</code></td>
<td>
<p>Logical, shall graphs be produced? Default is <code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_perc.x.label">perc.x.label</code></td>
<td>
<p>String, custom label for the horizontal axis in percentage graphs.
Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_perc.y.label">perc.y.label</code></td>
<td>
<p>String, custom label for the vertical axis in percentage graphs.
Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_mean.x.labels">mean.x.labels</code></td>
<td>
<p>List of strings, custom labels for the horizontal axis in means' graphs.
Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_mean.y.labels">mean.y.labels</code></td>
<td>
<p>List of strings, custom labels for the vertical axis in means' graphs.
Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_save.output">save.output</code></td>
<td>
<p>Logical, shall the output be saved in MS Excel file (default) or not
(printed to the console or assigned to an object).</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_output.file">output.file</code></td>
<td>
<p>If <code>save.output = TRUE</code> (default), full path to the output file
including the file name. If omitted, a file with a default file name
&quot;Analysis.xlsx&quot; will be written to the working directory
(<code>getwd()</code>). Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsa.pcts.means_+3A_open.output">open.output</code></td>
<td>
<p>Logical, shall the output be open after it has been written? The default
(<code>TRUE</code>) opens the output in the default spreadsheet program
installed on the computer. Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes percentages of respondents specified by the categories of splitting variables. The percentages are computed within the groups specified by the last splitting variable. If a continuous variable(s) are provided (background or sets of plausible values), their means (as arithmetic means, medians or modes) will be computed by groups defined by one or more splitting variables. If no splitting variables are added, the results will be computed only by country.
</p>
<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>Multiple continuous background variables can be provided to compute their means (as arithmetic means, medians or modes). Please note that in this case the results will slightly differ compared to using each of the same background continuous variables in separate analyses. This is because the cases with the missing values on <code>bckg.avg.vars</code> are removed in advance and the more variables are provided to <code>bckg.avg.vars</code>, the more cases are likely to be removed.
</p>
<p>Computation of means involving plausible values requires providing a root of the plausible values names in <code>PV.root.avg</code>. All studies (except CivED, TEDS-M, SITES, TALIS and TALIS Starting Strong Survey) have a set of PVs per construct (e.g. in TIMSS five for overall mathematics, five for algebra, five for geometry, etc.). In some studies (say TIMSS and PIRLS) the names of the PVs in a set always start with character string and end with sequential number of the PV. For example, the names of the set of PVs for overall mathematics in TIMSS are BSMMAT01, BSMMAT02, BSMMAT03, BSMMAT04 and BSMMAT05. The root of the PVs for this set to be added to <code>PV.root.avg</code> will be &quot;BSMMAT&quot;. The function will automatically find all the variables in this set of PVs and include them in the analysis. In other studies like OECD PISA and IEA ICCS and ICILS the sequential number of each PV is included in the middle of the name. For example, in ICCS the names of the set of PVs are PV1CIV, PV2CIV, PV3CIV, PV4CIV and PV5CIV. The root PV name has to be specified in <code>PV.root.avg</code> as &quot;PV#CIV&quot;. More than one set of PVs can be added. Note, however, that providing continuous variable(s) for the <code>bckg.avg.vars</code> argument and root PV for the <code>PV.root.avg</code> argument will affect the results for the PVs because the cases with missing on <code>bckg.avg.vars</code> will be removed and this will also affect the results from the PVs. On the other hand, using more than one set of PVs at the same time should not affect the results on any PV estimates because PVs shall not have any missing values.
</p>
<p>If no variables are specified for <code>bckg.avg.vars</code>, and no PV root names for <code>PV.root.avg</code>, the output will contain only percentages of cases in groups specified by the splitting variables, if any. If they are, their means will be computed either as arithmetic means, medians or modes. This can be controlled by setting the <code>central.tendency</code> argument to <code>mean</code> (default), <code>median</code> or <code>mode</code>. Note that if <code>central.tendency = "mode"</code> and the variables passed to <code>bckg.avg.vars</code> or the sets of PVs passed to <code>PV.root.avg</code> have more than one mode, the value for the lowest value will be included in the output. As a conseequence, the standard errors may be inflated.
</p>
<p>If <code>include.missing = FALSE</code> (default), all cases with missing values on the splitting variables will be removed and only cases with valid values will be retained in the statistics. Note that the data from the studies can be exported in two different ways: (1) setting all user-defined missing values to <code>NA</code>; and (2) importing all user-defined missing values as valid ones and adding their codes in an additional attribute to each variable. If the <code>include.missing</code> is set to <code>FALSE</code> (default) and the data used is exported using option (2), the output will remove all values from the variable matching the values in its <code>missings</code> attribute. Otherwise, it will include them as valid values and compute statistics for them.
</p>
<p>The <code>shortcut</code> argument is valid only for TIMSS, eTIMSS PSI, TIMSS Advanced, TIMSS Numeracy, PIRLS, ePIRLS, PIRLS Literacy and RLII. Previously, in computing the standard errors, these studies were using 75 replicates because one of the schools in the 75 JK zones had its weights doubled and the other one has been taken out. Since TIMSS 2015 and PIRLS 2016 the studies use 150 replicates and in each JK zone once a school has its weights doubled and once taken out, i.e. the computations are done twice for each zone. For more details see Foy &amp; LaRoche (2016) and Foy &amp; LaRoche (2017). If replication of the tables and figures is needed, the <code>shortcut</code> argument has to be changed to <code>TRUE</code>.
</p>
<p>If <code>graphs = TRUE</code>, the function will produce graphs. If only <code>split.vars</code> are specified, bar plots of percentages of respondents (population estimates) per group will be produced with error bars (95% confidence) for these percentages. If <code>bckg.avg.vars</code> and/or <code>PV.root.avg</code> are specified, plots with 95% confidence intervals of the averages (means, medians or modes) will be produced for each average analysis variable. All plots are produced per country. If <code>bckg.avg.vars</code> and/or <code>PV.root.avg</code> are specified, but no <code>split.vars</code> at the end there will be plots for each of the analysis average variables for all countries together. By default the percentage graphs horizontal axis is labeled with the name of the last splitting variable, and the vertical is labeled as &quot;Percentages XXXXX&quot; where XXXXX is the last splitting variable the percentages are computed for. For the means' plots the horizontal axis is labeled as the name of the last splitting variable for whose categories the means are computed by, and the vertical axis is labeled as &quot;Mean XXXXX&quot; where XXXXX is the name of the variable for which means are computed. These defaults can be overriden by supplying values to <code>perc.x.label</code>, <code>perc.y.label</code>, <code>mean.x.labels</code> and <code>mean.y.labels</code>. The <code>perc.x.label</code> and <code>perc.y.label</code> arguments accept vectors of length 1, and if longer vectors are supplied, error is thrown. The <code>mean.x.labels</code> and <code>mean.y.labels</code> accept lists with number of components equal to the number of variables (background or PVs) for which means are computed, longer or shorter lists throw errors. See the examples.
</p>
<p>row and column variable names are used for labeling the axes of the heatmaps, unless <code>graph.row.label</code> and/or <code>graph.col.label</code> arguments are supplied. These two arguments accept strings which will be used to label the axes.
</p>


<h3>Value</h3>

<p>If <code>save.output = FALSE</code>, a list containing the estimates and analysis information. If <code>graphs = TRUE</code>, the plots will be added to the list of estimates.
</p>
<p>If <code>save.output = TRUE</code> (default), an MS Excel (<code>.xlsx</code>) file (which can be opened in any spreadsheet program), as specified with the full path in the <code>output.file</code>. If the argument is missing, an Excel file with the generic file name &quot;Analysis.xlsx&quot; will be saved in the working directory (<code>getwd()</code>). The workbook contains three spreadsheets. The first one (&quot;Estimates&quot;) contains a table with the results by country and the final part of the table contains averaged results from all countries' statistics. The following columns can be found in the table, depending on the specification of the analysis:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> n_Cases - the number of cases in the sample used to compute the statistics.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the estimated population number of elements per group after applying the weights. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the the estimated population number of elements per group. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentages of respondents (population estimates) per groups defined by the splitting variables in <code>split.vars</code>. The percentages will be for the last splitting variable which defines the final groups.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the percentages from above.
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "mean"</code>, the arithmetic average of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the arithmetic average estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "mean"</code>, the standard error of the arithmetic average of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the SE of the average estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Variance_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "mean"</code>, the variance for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the variance estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Variance_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "mean"</code>, the error of the variance for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the error of the variance estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> SD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "mean"</code>, the standard deviation for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the standard deviation estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> SD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "mean"</code>, the error of the standard deviation for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the error of the standard deviation estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Median_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "median"</code>, the median of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the median estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Median_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "median"</code>, the standard error of the median of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the SE of the median estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> MAD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "median"</code>, the Median Absolute Deviation (MAD) for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the MAD estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> MAD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "median"</code>, the standard error of MAD for the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the MAD SE estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Mode_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "mode"</code>, the mode of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the mode estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Mode_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "mode"</code>, the standard error of the mode of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the SE of the mode estimate for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Percent_Missings_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentage of missing values for the <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.avg.vars</code>. There will be one column with the percentage of missing values for each variable specified in <code>bckg.avg.vars</code>.
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "mean"</code>, the arithmetic average of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the arithmetic average estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "mean"</code>, the standard error of the arithmetic average of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the standard error of arithmetic average estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SVR - returned if <code>central.tendency = "mean"</code>, the sampling variance component for the arithmetic average of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the sampling variance component for the arithmetic average estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Mean_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>MVR - returned if <code>central.tendency = "mean"</code>, the measurement variance component for the arithmetic average of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the measurement variance component for the arithmetic average estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Variance_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "mean"</code>, the total variance of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the total variance of each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Variance_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "mean"</code>, the standard error of the total variance of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the standard error of the total variance of each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Variance_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SVR - returned if <code>central.tendency = "mean"</code>, the sampling component of the variance of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the sampling component of the variance of each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Variance_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>MVR - returned if <code>central.tendency = "mean"</code>, the measurement component of the variance of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the measurement component of the variance of each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> SD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "mean"</code>, the standard deviation of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the standard deviation of each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> SD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "mean"</code>, the standard error of the standard deviation of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the standard error of the standard deviation of each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> SD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SVR - returned if <code>central.tendency = "mean"</code>, the sampling component of the standard deviation of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the sampling component of the standard deviation of each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> SD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>MVR - returned if <code>central.tendency = "mean"</code>, the measurement component of the standard deviation of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the measurement component of the standard deviation of each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Median_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "median"</code>, the median of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the median estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Median_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "median"</code>, the standard error of the median of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the standard error of median estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> MAD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "median"</code>, the Median Absolute Deviation (MAD) for a set of PVs specified in <code>PV.root.avg</code>. There will be one column with the MAD estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> MAD_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "median"</code>, the standard error of MAD for a set of PVs specified in <code>PV.root.avg</code>. There will be one column with the SE estimate of the MAD for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Mode_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - returned if <code>central.tendency = "mode"</code>, the mode of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the mode estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Mode_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - returned if <code>central.tendency = "mode"</code>, the standard error of the mode of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the standard error of mode estimate for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li>
<li><p> Percent_Missings_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentage of missing values for the <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.avg</code>. There will be one column with the percentage of missing values for each set of PVs specified in <code>PV.root.avg</code>.
</p>
</li></ul>

<p>The second sheet contains some additional information related to the analysis per country in the following columns:
</p>

<ul>
<li><p> DATA - used <code>data.file</code> or <code>data.object</code>.
</p>
</li>
<li><p> STUDY - which study the data comes from.
</p>
</li>
<li><p> CYCLE - which cycle of the study the data comes from.
</p>
</li>
<li><p> WEIGHT - which weight variable was used.
</p>
</li>
<li><p> DESIGN - which resampling technique was used (JRR or BRR).
</p>
</li>
<li><p> SHORTCUT - logical, whether the shortcut method was used.
</p>
</li>
<li><p> NREPS - how many replication weights were used.
</p>
</li>
<li><p> ANALYSIS_DATE - on which date the analysis was performed.
</p>
</li>
<li><p> START_TIME - at what time the analysis started.
</p>
</li>
<li><p> END_TIME - at what time the analysis finished.
</p>
</li>
<li><p> DURATION - how long the analysis took in hours, minutes, seconds and milliseconds.
</p>
</li></ul>

<p>The third sheet contains the call to the function with values for all parameters as it was executed. This is useful if the analysis needs to be replicated later.
</p>
<p>If <code>graphs = TRUE</code> there will be an additional &quot;Graphs&quot; sheet containing all plots.
</p>
<p>If any warnings resulting from the computations are issued, these will be included in an additional &quot;Warnings&quot; sheet in the workbook as well.
</p>


<h3>References</h3>

<p>LaRoche, S., Joncas, M., &amp; Foy, P. (2016). Sample Design in TIMSS 2015. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (pp. 3.1-3.37). Chestnut Hill, MA: TIMSS &amp; PIRLS International Study Center.
LaRoche, S., Joncas, M., &amp; Foy, P. (2017). Sample Design in PIRLS 2016. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in PIRLS 2016</em> (pp. 3.1-3.34). Chestnut Hill, MA: Lynch School of Education, Boston College.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute percentages of female and male students in TIMSS 2015 grade 8 using data file, omit
# missing from the splitting variable (female and male as answered by the students), without
# shortcut, and open the output after the computations are done
## Not run: 
lsa.pcts.means(data.file = "C:/Data/TIMSS_2015_G8_Student_Miss_to_NA.RData",
split.vars = "BSBG01", include.missing = FALSE,
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Compute the arithmetic average of the complex background scale "Students like learning
# mathematics" by student sex and frequency of using computer or tablet at home using TIMSS
# 2015 grade 8 data loaded in memory, using the shortcut, include the missing values in
# the splitting variables, and use the senate weights
## Not run: 
lsa.pcts.means(data.object = T15_G8_student_data, split.vars = c("BSBG01", "BSBG13A"),
bckg.avg.vars = "BSBGSLM", weight.var = "SENWGT", include.missing = FALSE, shortcut = TRUE,
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Repeat the analysis from above, adding a second continuous variable to compute the arithmetic
# average for, the "Students Like Learning Science" complex scale
## Not run: 
lsa.pcts.means(data.object = T15_G8_student_data, split.vars = c("BSBG01", "BSBG13A"),
bckg.avg.vars = c("BSBGSLM", "BSBGSLS"), weight.var = "SENWGT", include.missing = FALSE,
shortcut = TRUE, output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)
# Same as above, but add graphs with custom labels for the percentages and means
## Not run: 
lsa.pcts.means(data.object = T15_G8_student_data, split.vars = c("BSBG01", "BSBG13A"),
bckg.avg.vars = c("BSBGSLM", "BSBGSLS"), weight.var = "SENWGT", include.missing = FALSE,
shortcut = TRUE, graphs = TRUE,
perc.x.label = "Using computer or tables for schoolwork at home",
perc.y.label = "Percentage of students",
mean.x.labels = list("Books at home", "Books at home"),
mean.y.labels = list("Average like learning math", "Average like learning science"),
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Compute the arithmetic average of student overall reading achievement scores
# (i.e. using a set of PVs), using PIRLS 2016 student data file, split the output by student
# sex, use the full design, include the missing values od the splitting variable
# (i.e. student sex), and do not open the output after the computations are finished
## Not run: 
lsa.pcts.means(data.file = "C:/Data/PIRLS_2016_Student_Miss_to_NA.RData", split.vars = "ASBG01",
PV.root.avg = "ASRREA", include.missing = TRUE,
output.file = "C:/temp/test.xlsx", open.output = FALSE)

## End(Not run)

# Same as above, this time compute the median instead of the arithmetic average
## Not run: 
lsa.pcts.means(data.file = "C:/Data/PIRLS_2016_Student_Miss_to_NA.RData", split.vars = "ASBG01",
PV.root.avg = "ASRREA", include.missing = TRUE,
central.tendency = "median",
output.file = "C:/temp/test.xlsx", open.output = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.prctls'>Compute percentiles of continuous variables within groups</h2><span id='topic+lsa.prctls'></span>

<h3>Description</h3>

<p><code>lsa.prctls</code> computes percentiles of continuous variables within groups defined by one or more variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.prctls(
  data.file,
  data.object,
  split.vars,
  bckg.prctls.vars,
  PV.root.prctls,
  prctls = c(5, 25, 50, 75, 95),
  weight.var,
  include.missing = FALSE,
  shortcut = FALSE,
  graphs = FALSE,
  perc.x.label = NULL,
  perc.y.label = NULL,
  prctl.x.labels = NULL,
  prctl.y.labels = NULL,
  save.output = TRUE,
  output.file,
  open.output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.prctls_+3A_data.file">data.file</code></td>
<td>
<p>The file containing <code>lsa.data</code> object. Either this or <code>data.object</code>
shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either this or
<code>data.file</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_split.vars">split.vars</code></td>
<td>
<p>Categorical variable(s) to split the results by. If no split variables
are provided, the results will be for the overall countries'
populations. If one or more variables are provided, the results will
be split by all but the last variable and the percentages of respondents
will be computed by the unique values of the last splitting variable.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_bckg.prctls.vars">bckg.prctls.vars</code></td>
<td>
<p>Name(s) of continuous background or contextual variable(s) to compute
the percentiles for. The results will be computed by all groups specified
by the splitting variables. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_pv.root.prctls">PV.root.prctls</code></td>
<td>
<p>The root name(s) for the set(s) of plausible values. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_prctls">prctls</code></td>
<td>
<p>Vector of integers specifying the percentiles to be computed, the default
is <code>c(5, 25, 50, 75, 95)</code>. See examples.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_weight.var">weight.var</code></td>
<td>
<p>The name of the variable containing the weights. If no name of a weight
variable is provide, the function will automatically select the default
weight variable for the provided data, depending on the respondent type.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_include.missing">include.missing</code></td>
<td>
<p>Logical, shall the missing values of the splitting variables be included
as categories to split by and all statistics produced for them? The
default (<code>FALSE</code>) takes all cases on the splitting variables
without missing values before computing any statistics. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_shortcut">shortcut</code></td>
<td>
<p>Logical, shall the &quot;shortcut&quot; method for IEA TIMSS, TIMSS Advanced,
TIMSS Numeracy, eTIMSS PSI, PIRLS, ePIRLS, PIRLS Literacy and RLII be
applied when using PVs? The default (<code>FALSE</code>) applies the &quot;full&quot;
design when computing the variance components and the standard errors of
the PV estimates.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_graphs">graphs</code></td>
<td>
<p>Logical, shall graphs be produced? Default is <code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_perc.x.label">perc.x.label</code></td>
<td>
<p>String, custom label for the horizontal axis in percentage graphs.
Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_perc.y.label">perc.y.label</code></td>
<td>
<p>String, custom label for the vertical axis in percentage graphs.
Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_prctl.x.labels">prctl.x.labels</code></td>
<td>
<p>List of strings, custom labels for the horizontal axis in percentiles'
graphs. Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_prctl.y.labels">prctl.y.labels</code></td>
<td>
<p>List of strings, custom labels for the vertical axis in percentiles'
graphs.  Ignored if <code>graphs = FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_save.output">save.output</code></td>
<td>
<p>Logical, shall the output be saved in MS Excel file (default) or not
(printed to the console or assigned to an object).</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_output.file">output.file</code></td>
<td>
<p>If <code>save.output = TRUE</code> (default), full path to the output file
including the file name. If omitted, a file with a default file name
&quot;Analysis.xlsx&quot; will be written to the working directory
(<code>getwd()</code>). Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsa.prctls_+3A_open.output">open.output</code></td>
<td>
<p>Logical, shall the output be open after it has been written? The default
(<code>TRUE</code>) opens the output in the default spreadsheet program
installed on the computer. Ignored if <code>save.output = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>The function computes percentiles of variables (background/contextual or sets of plausible values) by groups defined by one or more categorical variables (splitting variables). Multiple splitting variables can be added, the function will compute the percentages for all formed groups and their percentiles on the continuous variables. If no splitting variables are added, the results will be computed only by country.
</p>
<p>Multiple continuous background variables can be provided to compute the specified percentiles for them. Please note that in this case the results will slightly differ compared to using each of the same background continuous variables in separate analyses. This is because the cases with the missing values on <code>bckg.prctls.vars</code> are removed in advance and the more variables are provided to <code>bckg.prctls.vars</code>, the more cases are likely to be removed.
</p>
<p>Computation of percentiles involving plausible values requires providing a root of the plausible values names in <code>PV.root.prctls</code>. All studies (except CivED, TEDS-M, SITES, TALIS and TALIS Starting Strong Survey) have a set of PVs per construct (e.g. in TIMSS five for overall mathematics, five for algebra, five for geometry, etc.). In some studies (say TIMSS and PIRLS) the names of the PVs in a set always start with character string and end with sequential number of the PV. For example, the names of the set of PVs for overall mathematics in TIMSS are BSMMAT01, BSMMAT02, BSMMAT03, BSMMAT04 and BSMMAT05. The root of the PVs for this set to be added to <code>PV.root.prctls</code> will be &quot;BSMMAT&quot;. The function will automatically find all the variables in this set of PVs and include them in the analysis. In other studies like OECD PISA and IEA ICCS and ICILS the sequential number of each PV is included in the middle of the name. For example, in ICCS the names of the set of PVs are PV1CIV, PV2CIV, PV3CIV, PV4CIV and PV5CIV. The root PV name has to be specified in <code>PV.root.prctls</code> as &quot;PV#CIV&quot;. More than one set of PVs can be added. Note, however, that providing continuous variable(s) for the <code>bckg.prctls.vars</code> argument and root PV for the <code>PV.root.prctls</code> argument will affect the results for the PVs because the cases with missing on <code>bckg.prctls.vars</code> will be removed and this will also affect the results from the PVs. On the other hand, using more than one set of PVs at the same time should not affect the results on any PV estimates because PVs shall not have any missing values.
</p>
<p>If <code>include.missing = FALSE</code> (default), all cases with missing values on the splitting variables will be removed and only cases with valid values will be retained in the statistics. Note that the data from the studies can be exported in two different ways using the <code>lsa.convert.data</code>: (1) setting all user-defined missing values to <code>NA</code>; and (2) importing all user-defined missing values as valid ones and adding their codes in an additional attribute to each variable. If the <code>include.missing</code> in <code>lsa.prctls</code> is set to <code>FALSE</code> (default) and the data used is exported using option (2), the output will remove all values from the variable matching the values in its <code>missings</code> attribute. Otherwise, it will include them as valid values and compute statistics for them.
</p>
<p>The <code>shortcut</code> argument is valid only for TIMSS, eTIMSS PSI, TIMSS Advanced, TIMSS Numeracy, PIRLS, ePIRLS, PIRLS Literacy and RLII. Previously, in computing the standard errors, these studies were using 75 replicates because one of the schools in the 75 JK zones had its weights doubled and the other one has been taken out. Since TIMSS 2015 and PIRLS 2016 the studies use 150 replicates and in each JK zone once a school has its weights doubled and once taken out, i.e. the computations are done twice for each zone. For more details see Foy &amp; LaRoche (2016) and Foy &amp; LaRoche (2017). If replication of the tables and figures is needed, the <code>shortcut</code> argument has to be changed to <code>TRUE</code>.
</p>
<p>If <code>graphs = TRUE</code>, the function will produce graphs. Bar plots of percentages of respondents (population estimates) per group will be produced with error bars (95% confidence) for these percentages. Line plots for the percentiles per group defined by the <code>split.vars</code> will be created with 95% confidence intervals for the percentile values. All plots are produced per country. If no <code>split.vars</code> are specified, at the end there will be percentile plots for each of the variables specified in <code>bckg.prctls.vars</code> and/or <code>PV.root.prctls</code> for all countries together. By default the percentage graphs horizontal axis is labeled with the name of the last splitting variable, and the vertical is labeled as &quot;Percentages XXXXX&quot; where XXXXX is the last splitting variable the percentages are computed for. For the percentiles' plots the horizontal axis is labeled as &quot;Percentiles&quot;, and the vertical axis is labeled as the name of the variable for which percentiles are computed. These defaults can be overriden by supplying values to <code>perc.x.label</code>, <code>perc.y.label</code>, <code>prctl.x.labels</code> and <code>prctl.y.labels</code>. The <code>perc.x.label</code> and <code>perc.y.label</code> arguments accept vectors of length 1, and if longer vectors are supplied, error is thrown. The <code>prctl.x.labels</code> and <code>prctl.y.labels</code> accept lists with number of components equal to the number of variables (background or PVs) for which percentiles are computed, longer or shorter lists throw errors. See the examples.
</p>


<h3>Value</h3>

<p>If <code>save.output = FALSE</code>, a list containing the estimates and analysis information. If <code>graphs = TRUE</code>, the plots will be added to the list of estimates.
</p>
<p>If <code>save.output = TRUE</code> (default), an MS Excel (<code>.xlsx</code>) file (which can be opened in any spreadsheet program), as specified with the full path in the <code>output.file</code>. If the argument is missing, an Excel file with the generic file name &quot;Analysis.xlsx&quot; will be saved in the working directory (<code>getwd()</code>). The workbook contains three spreadsheets. The first one (&quot;Estimates&quot;) contains a table with the results by country and the final part of the table contains averaged results from all countries' statistics. The following columns can be found in the table, depending on the specification of the analysis:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Country ID<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - a column containing the names of the countries in the file for which statistics are computed. The exact column header will depend on the country identifier used in the particular study.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 1<code style="white-space: pre;">&#8288;&gt;&#8288;</code>, <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Split variable 2<code style="white-space: pre;">&#8288;&gt;&#8288;</code>... - columns containing the categories by which the statistics were split by. The exact names will depend on the variables in <code>split.vars</code>.
</p>
</li>
<li><p> n_Cases - the number of cases in the sample used to compute the statistics.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the estimated population number of elements per group after applying the weights. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Sum_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Weight variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the the estimated population number of elements per group. The actual name of the weight variable will depend on the weight variable used in the analysis.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentages of respondents (population estimates) per groups defined by the splitting variables in <code>split.vars</code>. The percentages will be for the last splitting variable which defines the final groups.
</p>
</li>
<li><p> Percentages_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Last split variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard errors of the percentages from above.
</p>
</li>
<li><p> Prctl_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Percentile value<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentile of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.prctls.vars</code>. There will be one column for each percentile estimate for each variable specified in <code>bckg.prctls.vars</code>.
</p>
</li>
<li><p> Prctl_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Percentile value<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code><code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error of the percentile of the continuous <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.prctls.vars</code>. There will be one column with the SE per percentile estimate for each variable specified in <code>bckg.prctls.vars</code>.
</p>
</li>
<li><p> Percent_Missings_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentage of missing values for the <code style="white-space: pre;">&#8288;&lt;&#8288;</code>Background variable<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>bckg.prctls.vars</code>. There will be one column with the percentage of missing values for each variable specified in <code>bckg.prctls.vars</code>.
</p>
</li>
<li><p> Prctl_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Percentile value<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code><code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentile of the PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.prctls</code>. There will be one column per percentile value estimate for each set of PVs specified in <code>PV.root.prctls</code>.
</p>
</li>
<li><p> Prctl_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Percentile value<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code><code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SE - the standard error per percentile per set of PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.prctls</code>. There will be one column with the standard error of estimate per percentile per set of PVs specified in <code>PV.root.prctls</code>.
</p>
</li>
<li><p> Prctl_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Percentile value<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code><code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>SVR - the sampling variance component per percentile per set of PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.prctls</code>. There will be one column with the sampling variance component percentile estimate for each set of PVs specified in <code>PV.root.prctls</code>.
</p>
</li>
<li><p> Prctl_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>Percentile value<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code><code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code><code style="white-space: pre;">&#8288;_&#8288;</code>MVR - the measurement variance component per percentiles per set of PVs with the same <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.prctls</code>. There will be one column with the measurement variance component per percentile per set of PVs specified in <code>PV.root.prctls</code>.
</p>
</li>
<li><p> Percent_Missings_<code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> - the percentage of missing values for the <code style="white-space: pre;">&#8288;&lt;&#8288;</code>root PV<code style="white-space: pre;">&#8288;&gt;&#8288;</code> specified in <code>PV.root.prctls</code>. There will be one column with the percentage of missing values for each set of PVs specified in <code>PV.root.prctls</code>.
</p>
</li></ul>

<p>The second sheet contains some additional information related to the analysis per country in columns:
</p>

<ul>
<li><p> DATA - used <code>data.file</code> or <code>data.object</code>.
</p>
</li>
<li><p> STUDY - which study the data comes from.
</p>
</li>
<li><p> CYCLE - which cycle of the study the data comes from.
</p>
</li>
<li><p> WEIGHT - which weight variable was used.
</p>
</li>
<li><p> DESIGN - which resampling technique was used (JRR or BRR).
</p>
</li>
<li><p> SHORTCUT - logical, whether the shortcut method was used.
</p>
</li>
<li><p> NREPS - how many replication weights were used.
</p>
</li>
<li><p> ANALYSIS_DATE - on which date the analysis was performed.
</p>
</li>
<li><p> START_TIME - at what time the analysis started.
</p>
</li>
<li><p> END_TIME - at what time the analysis finished.
</p>
</li>
<li><p> DURATION - how long the analysis took in hours, minutes, seconds and milliseconds.
</p>
</li></ul>

<p>The third sheet contains the call to the function with values for all parameters as it was executed. This is useful if the analysis needs to be replicated later.
</p>
<p>If <code>graphs = TRUE</code> there will be an additional &quot;Graphs&quot; sheet containing all plots.
</p>
<p>If any warnings resulting from the computations are issued, these will be included in an additional &quot;Warnings&quot; sheet in the workbook as well.
</p>


<h3>References</h3>

<p>LaRoche, S., Joncas, M., &amp; Foy, P. (2016). Sample Design in TIMSS 2015. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in TIMSS 2015</em> (pp. 3.1-3.37). Chestnut Hill, MA: TIMSS &amp; PIRLS International Study Center.
LaRoche, S., Joncas, M., &amp; Foy, P. (2017). Sample Design in PIRLS 2016. In M. O. Martin, I. V. S. Mullis, &amp; M. Hooper (Eds.), <em>Methods and Procedures in PIRLS 2016</em> (pp. 3.1-3.34). Chestnut Hill, MA: Lynch School of Education, Boston College.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the 5th, 25th and 50th percentiles of the complex background scale "Students like
# learning mathematics" by student sex and frequency of using computer or tablet at home using
# TIMSS 2015 grade 8 data loaded in memory, without shortcut, exclude the cases with missing
# values in the splitting variables, and use the default (TOTWGT) weights
## Not run: 
lsa.pcts.prctls(data.object = T15_G8_student_data, split.vars = c("BSBG01", "BSBG13A"),
bckg.prctls.vars = "BSBGSLM", prctls = c(5, 25, 50),
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Repeat the analysis from above, this time with shortcut, include the cases with missing
# values in the splitting variables, and use the senate weights
## Not run: 
lsa.pcts.prctls(data.object = T15_G8_student_data, split.vars = c("BSBG01", "BSBG13A"),
bckg.prctls.vars = "BSBGSLM", prctls = c(5, 25, 50), weight.var = "SENWGT",
include.missing = TRUE, shortcut = TRUE, output.file = "C:/temp/test.xlsx",
open.output = TRUE)

## End(Not run)

# Repeat the analysis from above, adding a second continuous variable to compute the
# percentiles for, the "Students Like Learning Science" complex scale
## Not run: 
lsa.pcts.prctls(data.object = T15_G8_student_data, split.vars = c("BSBG01", "BSBG13A"),
bckg.prctls.vars = c("BSBGSLM", "BSBGSLS"), prctls = c(5, 25, 50), weight.var = "SENWGT",
include.missing = FALSE, shortcut = TRUE,
output.file = "C:/temp/test.xlsx", open.output = TRUE)

## End(Not run)

# Compute the 5th, 25th and 50th percentiles for the student overall reading achievement
# scores (i.e. using a set of PVs), using PIRLS 2016 student data file, split the output
# by student sex, use the full design, include the missing values od the splitting variable
# (i.e. student sex), and do not open the output after the computations are finished
## Not run: 
lsa.pcts.prctls(data.file = "C:/Data/PIRLS_2016_Student_Miss_to_NA.RData",
split.vars = "ASBG01", PV.root.prctls = "ASRREA", prctls = c(5, 25, 50),
include.missing = TRUE, output.file = "C:/temp/test.xlsx", open.output = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='lsa.recode.vars'>Recode variables in large-scale assessments' data sets</h2><span id='topic+lsa.recode.vars'></span>

<h3>Description</h3>

<p>Utility function to recode variables in objects or data sets containing objects of class <code>lsa.data</code>, taking care of user-defined missing values, if specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.recode.vars(
  data.file,
  data.object,
  src.variables,
  new.variables,
  old.new,
  new.labels,
  missings.attr,
  variable.labels,
  out.file
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.recode.vars_+3A_data.file">data.file</code></td>
<td>
<p>Full path to the <code>.RData</code> file containing <code>lsa.data</code> object.
Either this or <code>data.object</code> shall be specified, but not both.
See details.</p>
</td></tr>
<tr><td><code id="lsa.recode.vars_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either this or
<code>data.file</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.recode.vars_+3A_src.variables">src.variables</code></td>
<td>
<p>Names of the source variables with the same class whose values shall be
recoded. See details.</p>
</td></tr>
<tr><td><code id="lsa.recode.vars_+3A_new.variables">new.variables</code></td>
<td>
<p>Optional, vector of variable names to be created with the recoded values
with the same length as <code>src.variables</code>. If missing, the <code>src.variables</code>
will be overwritten.</p>
</td></tr>
<tr><td><code id="lsa.recode.vars_+3A_old.new">old.new</code></td>
<td>
<p>String with the recoding instructions matching the length of the factor
levels (or unique values in case of numeric or character variables) in
the variables. See details and examples.</p>
</td></tr>
<tr><td><code id="lsa.recode.vars_+3A_new.labels">new.labels</code></td>
<td>
<p>The new labels if the <code>src.variables</code> variables are of class <code>factor</code>
or labels to be assigned to the recoded values (i.e. turning variables of class
<code>numeric</code> or <code>character</code> into factors) with the same length as the
new desired values. See details.</p>
</td></tr>
<tr><td><code id="lsa.recode.vars_+3A_missings.attr">missings.attr</code></td>
<td>
<p>Optional, list of character vectors to assign user-defined missing values
for each recoded variable. See details and examples.</p>
</td></tr>
<tr><td><code id="lsa.recode.vars_+3A_variable.labels">variable.labels</code></td>
<td>
<p>Optional, string vector with the new variable labels to be assigned.
See details.</p>
</td></tr>
<tr><td><code id="lsa.recode.vars_+3A_out.file">out.file</code></td>
<td>
<p>Full path to the <code>.RData</code> file to be written. If missing, the object
will be written to memory. See examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Before recoding variables of interest, it is worth running the <code>lsa.vars.dict</code> to check their properties.
</p>
<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>The variable names passed to <code>src.variables</code> must be with the same class and structure, i.e. same number of levels and same labels in case of <code>factor</code> variables, or the same unique values in case of <code>numeric</code> or <code>character</code> variables. If the classes differ, the function will stop with an error. If the unique values and/or labels differ, the function would execute the recodings, but will drop a warning.
</p>
<p>The <code>new.variables</code> is optional. If provided, the recoded values will be saved under the provided new variable names and the <code>src.variables</code> will remain unchanged. If missing, the variables passed in <code>src.variables</code> will be overwritten. Note that the number of names passed to <code>src.variables</code> and <code>new.variables</code> must be the same.
</p>
<p>The <code>old.new</code> (old values to new values) is the recoding scheme to be evaluated and executed provided as a characters string in the form of <code>"1=1;2=1;3=2;4=3"</code>. In this example it means &quot;recode 1 into 1, 2 into one, 3 into 2, and 4 into 3&quot;. Note that all available values have to be included in the recoding statement, even if they are not to be changed. In this example, if we omit recoding 1 into 1, 1 will be set to NA during the recoding. This recoding definition works with factor and numeric variables. For character variables the individual values have to be defined in full, e.g. <code>"'No time'='30 minutes or less';'30 minutes or less'='30 minutes or less';'More than 30 minutes'='More than 30 minutes';'Omitted or invalid'='Omitted or invalid'"</code> because these cannot be reliably referred to by position (as for factors) or actual number (as for numeric).
</p>
<p>The <code>new.labels</code> assigns new labels to factor variables. Their length must be the same as for the newly recoded values. If the variables passed to <code>src.variabes</code> are character or numeric, and <code>new.labels</code> are provided, the recoded variables will be converted to factors. If, on the other hand, the <code>src.variables</code> are factors and no <code>new.labels</code> are provided, the variables will be converted to numeric.
</p>
<p>Note that the <code>lsa.convert.data</code> has two options: keep the user-defined missing values (<code>missing.to.NA = FALSE</code>) and set the user-defined missing values to NA (<code>missing.to.NA = TRUE</code>). The former option will provide an attribute with user-defined missing values attached to each variable they have been defined for, the latter will not (i.e. will assign all user-defined missing values to NA). In case variables from data converted with the former option are recoded, user-defined missing values have to be supplied to <code>missings.attr</code>, otherwise (if all available values are recoded) the user-defined missing values will appear as valid codes. Not recoding the user-defined missing codes available in the data will automatically set them to <code>NA</code>. In either case, the function will drop a warning. On the other hand, if the data was exported with <code>missing.to.NA = TRUE</code>, there will be no attributes with user-defined missing codes and omitting <code>missings.attr</code> will issue no warning. User-defined missing codes can, however, be added in this case too, if necessary. The <code>missings.attr</code> has to be provided as a list where each component is a vector with the values for the missing codes. See the examples.
</p>
<p>The <code>variable.labels</code> argument provides the variable labels to be assigned to the recoded variables. If omitted and <code>new.variables</code> are provided the newly created variables will have no variable labels. If provided, and <code>new.variables</code> are not provided, they will be ignored.
If full path to <code>.RData</code> file is provided to <code>out.file</code>, the data.set will be written to that file. If no, the data will remain in the memory.
</p>


<h3>Value</h3>

<p>A <code>lsa.data</code> object in memory (if <code>out.file</code> is missing) or <code>.RData</code> file containing <code>lsa.data</code> object with the recoded values for the specified variables.
In addition, the function will print tables for the specified variables before and after recoding them to check if all recodings were done as intended. In addition, it will print warnings if different issues have been encountered.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>, <code><a href="#topic+lsa.vars.dict">lsa.vars.dict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Recode PIRLS 2016 student variables "ASBG10A" (How much time do you spend using a computer or
# tablet to do these activities for your schoolwork on a normal school day? Finding and reading
# information) and "ASBG10B" (How much time do you spend using a computer or tablet to do these
# activities for your schoolwork on a normal school day? Preparing reports and presentations).
# Both variables are factors, the original valid values (1 - "No time",
# 2 - "30 minutes or less", 3 - "More than 30 minutes") are recoded to
# 1 - "No time or 30 minutes" and 2 - "More than 30 minutes", collapsing the first two.
# The missing value "Omitted or invalid" which originally appears as 4th has to be recoded to
# 3rd. The "Omitted or invalid" is assigned as user-defined missing value for both variables.
# The data is saved on disk as a new data set.
## Not run: 
lsa.recode.vars(data.file = "C:/temp/test.RData", src.variables = c("ASBG10A", "ASBG10B"),
new.variables = c("ASBG10A_rec", "ASBG10B_rec"),
variable.labels = c("Recoded ASBG10A", "Recoded ASBG10B"),
old.new = "1=1;2=1;3=2;4=3",
new.labels = c("No time or 30 minutes", "More than 30 minutes", "Omitted or invalid"),
missings.attr = list("Omitted or invalid", "Omitted or invalid"),
out.file = "C:/temp/test_new.RData")

## End(Not run)

# Similar to the above, recode PIRLS 2016 student variables "ASBG10A" and "ASBG10B", this time
# leaving the original categories (1 - "No time", 2 - "30 minutes or less",
# 3 - "More than 30 minutes") as they are, but changing the user-defined missing values
# definition (1 - "No time" becomes user-defined missing).
# The recoded data remains in the memory.
## Not run: 
lsa.recode.vars(data.file = "C:/temp/test.RData", src.variables = c("ASBG10A", "ASBG10B"),
new.variables = c("ASBG10A_rec", "ASBG10B_rec"),
variable.labels = c("Recoded ASBG10A", "Recoded ASBG10B"), old.new = "1=1;2=2;3=3;4=4",
new.labels = c("No time", "30 minutes or less", "More than 30 minutes", "Omitted or invalid"),
missings.attr = list(c("No time", "Omitted or invalid"), c("No time", "Omitted or invalid")))

## End(Not run)

# Similar to the first example, this time overwriting the original variables. The first valid
# value (1 - "No time") is set to NA (note that no new value and factor level is provided for
# it in "new.labels"), the rest of the values are redefined, so the factor starts from 1,
# as it always does in R.
## Not run: 
lsa.recode.vars(data.file = "C:/temp/test.RData", src.variables = c("ASBG10A", "ASBG10B"),
variable.labels = c("Recoded ASBG10A", "Recoded ASBG10B"), old.new = "2=1;3=2;4=3",
new.labels = c("30 minutes or less", "More than 30 minutes", "Omitted or invalid"),
missings.attr = list("Omitted or invalid"),
out.file = "C:/temp/test_new.RData")

## End(Not run)
# The databases rarely contain character variables and the numeric variables have too many
# unique values to be recoded using the function. The following two examples are just for
# demonstration purpose on how to recode character and numeric variables.

# Convert the "ASBG04" (number of books at home) from ePIRLS 2016 to numeric and recode the
# values of the new variable, collapsing the first two and the last two valid values.
# The data remains in the memory.
## Not run: 
load("/tmp/test.RData")
test[ , ASBG04NUM := as.numeric(ASBG04)]
table(test[ , ASBG04NUM])
lsa.recode.vars(data.object = test, src.variables = "ASBG04NUM",
old.new = "1=1;2=1;3=2;4=3;5=3;6=4",
missings.attr = list("Omitted or invalid" = 4))

# Similar to the above, this time converting "ASBG03" to character, collapsing its categories
# of frequency of using the test language at home to two ("Always or almost always" and
# "Sometimes or never").
\dontrun{
load("/tmp/test.RData")
test[ , ASBG03CHAR := as.character(ASBG03)]
table(test[ , ASBG03CHAR])
# Add the lines together to be able to run the following
lsa.recode.vars(data.object = test, src.variables = "ASBG03CHAR",
old.new = "'I always speak &lt;language of test&gt; at home'='Always or almost always';
'I almost always speak &lt;language of test&gt; at home'='Always or almost always';
'I sometimes speak &lt;language of test&gt; and sometimes speak another language at home'=
'Sometimes or never';'I never speak &lt;language of test&gt; at home'='Sometimes or never';
'Omitted or invalid'='Omitted or invalid'",
missings.attr = list("Omitted or invalid"))
}


## End(Not run)
</code></pre>

<hr>
<h2 id='lsa.vars.dict'>Produce dictionary for large-scale assessments data variables</h2><span id='topic+lsa.vars.dict'></span>

<h3>Description</h3>

<p>Utility function to display dictionaries of variables from data sets containing objects of class <code>lsa.data</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsa.vars.dict(
  data.file,
  data.object,
  var.names,
  out.file,
  open.out.file = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsa.vars.dict_+3A_data.file">data.file</code></td>
<td>
<p>Full path to the <code>.RData</code> file containing <code>lsa.data</code> object.
Either this or <code>data.object</code> shall be specified, but not both.
See details.</p>
</td></tr>
<tr><td><code id="lsa.vars.dict_+3A_data.object">data.object</code></td>
<td>
<p>The object in the memory containing <code>lsa.data</code> object. Either this
or <code>data.file</code> shall be specified, but not both. See details.</p>
</td></tr>
<tr><td><code id="lsa.vars.dict_+3A_var.names">var.names</code></td>
<td>
<p>Vector of variable names whose dictionaries shall be produced.
See details.</p>
</td></tr>
<tr><td><code id="lsa.vars.dict_+3A_out.file">out.file</code></td>
<td>
<p>Optional, full path to a <code>.txt</code> file where the dictionaries shall be
saved, if needed. See details.</p>
</td></tr>
<tr><td><code id="lsa.vars.dict_+3A_open.out.file">open.out.file</code></td>
<td>
<p>Optional, if file path is provided to <code>out.file</code> shall the produced
file be open after the file is written?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>data.file</code> or <code>data.object</code> shall be provided as source of data. If both of them are provided, the function will stop with an error message.
</p>
<p>If <code>var.names</code> are not provided, then the function will produce dictionaries for all variables in the file/object.
</p>
<p>The function will print the dictionaries on the screen. If these need to be saved to a file for further reference as well, a full path to the <code>.txt</code> file shall be provided. If the file exists, it will be overwritten. If the file name is provided to <code>out.file</code> and <code>open.out.file = TRUE</code>, it will be automatically open in the default text editor after being written.
</p>


<h3>Value</h3>

<p>The dictionaries for the variables in <code>var.names</code> will be printed as tables on the screen. For each variable the dictionaries contain the variable name, the variable class, the variable label, unique variable values (see below) and the user-defined missing values (if any).
</p>
<p>The unique values' representation will depend on the variable class. If the variable is a factor, the factor levels will be displayed. If the variable is numeric or character, the unique values will be printed up to the sixth one.
</p>
<p>The user-defined missing values for factor variables will be as text strings. For the numeric variables these will be integers, followed by their labels in brackets.
</p>
<p>If a full file path is provided to the <code>out.file</code>, the same output will be written to a <code>.txt</code> file with a text on top which data file/object was used.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsa.convert.data">lsa.convert.data</a></code>, <code><a href="#topic+lsa.recode.vars">lsa.recode.vars</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Display and write to file the dictionaries for multiple factor and numeric variables using
# PIRLS 2016 file with teacher and student data from several countries and open the file after
# it has been written to the disk.
## Not run: 
lsa.vars.dict(data.file = "C:/temp/test.RData", var.names = c("ASBG10A", "ASBG10B", "ASBG05A",
"ASBG05B", "ASBG05C", "ASBG05D", "ASBG05E", "ASBG05F", "ASBG05G", "ASBG05H", "ASBG06",
"ASBG07A", "ASBG07B", "ASBG08", "ATBG05BA", "ATBG05BB", "ATBG05BC", "ATBG05BD"),
out.file = "C:/temp/dict.txt", open.out.file = TRUE)

## End(Not run)

## Not run: 
lsa.vars.dict(data.object = test, var.names = c("ASBG10A", "ASBG10B", "ASBG05A", "ASBG05B",
"ASBG05C", "ASBG05D", "ASBG05E", "ASBG05F", "ASBG05G", "ASBG05H","ASBG06", "ASBG07A",
"ASBG07B", "ASBG08", "ATBG05BA", "ATBG05BB", "ATBG05BC", "ATBG05BD"),
out.file = "C:/temp/dict.txt", open.out.file = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='ralsaGUI'>Start RALSA's Graphical User Interface (GUI)</h2><span id='topic+ralsaGUI'></span>

<h3>Description</h3>

<p>Starts the GUI. The GUI contains elements for each parameter of each function (data preparation or analysis). The GUI starts as a background job without blocking the console which can be used as usual.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ralsaGUI()
</code></pre>

<hr>
<h2 id='ralsaGUIfailsafe'>Start RALSA's Graphical User Interface (GUI) in a failsafe mode</h2><span id='topic+ralsaGUIfailsafe'></span>

<h3>Description</h3>

<p>If, for any reason, the GUI cannot be started using the regular <code>ralsaGUI()</code> command, use this instead. The downside of using this function is that the R console will be blocked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ralsaGUIfailsafe()
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
