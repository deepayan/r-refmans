<!DOCTYPE html><html lang="en"><head><title>Help for package qcluster</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {qcluster}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#banknote'><p>Swiss Banknotes Data</p></a></li>
<li><a href='#bqs'><p>Bootstrapping quadratic scores</p></a></li>
<li><a href='#bqs_rank'><p>Ranking Clusters Quadratic Scores Estimated Via Boostrap</p></a></li>
<li><a href='#bqs_select'><p>Select Ranked Cluster Solutions by Quadratic Score</p></a></li>
<li><a href='#clust2params'><p>Converts Hard Assignment Into Cluster Parameters</p></a></li>
<li><a href='#gmix'><p>Gaussian Mixture Modelling</p></a></li>
<li><a href='#mbind'><p>Combines Methods Settings</p></a></li>
<li><a href='#mset_gmix'><p>Generates Methods Settings for Gaussian Mixture Model-Based Clustering</p></a></li>
<li><a href='#mset_kmeans'><p>Generates Methods Settings for K-Means Clustering</p></a></li>
<li><a href='#mset_pam'><p>Generates Methods Settings for Partitioning Around Medoids (Pam) Clustering</p></a></li>
<li><a href='#mset_user'><p>Generates Clustering Methods Settings for a Prototype Methodology</p>
Provided by the User</a></li>
<li><a href='#plot_clustering'><p>Plot Data With Clustering Information</p></a></li>
<li><a href='#plot.bqs'><p>Plot (Bootstrap) Quadratic Score Results</p></a></li>
<li><a href='#plot.mbcfit'><p>Plot Fitted Mixture Models</p></a></li>
<li><a href='#predict.mbcfit'><p>Predict Hard Clustering Assignments for using Mixture Models</p></a></li>
<li><a href='#print.bqs'><p>Display Information on Bootstrap Quadratic Scores Objects</p></a></li>
<li><a href='#print.mbcfit'><p>Display Information for Mixture Model Objects</p></a></li>
<li><a href='#qscore'><p>Clustering Quadratic Score</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-12-23</td>
</tr>
<tr>
<td>Title:</td>
<td>Clustering via Quadratic Scoring</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs tuning of clustering models, methods and algorithms including the problem of determining an appropriate number of clusters. Validation of cluster analysis results is performed via quadratic scoring using resampling methods, as in Coraggio, L. and Coretto, P. (2023) &lt;<a href="https://doi.org/10.1016%2Fj.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>&gt;.</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>cluster, doParallel, foreach, grDevices, graphics, iterators,
methods, parallel, stats</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-13 18:46:57 UTC; lucac</td>
</tr>
<tr>
<td>Author:</td>
<td>Luca Coraggio [cre, aut] (Homepage: &lt;https://luca-coraggio.com&gt;),
  Pietro Coretto [aut] (Homepage: &lt;https://pietro-coretto.github.io&gt;)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Luca Coraggio &lt;luca.coraggio@unina.it&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-13 19:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='banknote'>Swiss Banknotes Data</h2><span id='topic+banknote'></span>

<h3>Description</h3>

<p>Data from Tables 1.1 and 1.2 (pp. 5-8) of Flury  and Riedwyl
(1988). There are  six measurements made on 200 Swiss
banknotes  (the old-Swiss 1000-franc). The banknotes belong to two
classes of equal size:  <em>genuine</em> and <em>counterfeit</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(banknote)</code></pre>


<h3>Format</h3>

<p>A  <code>data.frame</code> of dimension <code>200x7</code> with the following variables:
</p>

<dl>
<dt>Class</dt><dd><p>a <code>factor</code> with classes: <code>genuine</code>, <code>counterfeit</code></p>
</dd>
<dt>Length</dt><dd><p>Length of bill (mm)</p>
</dd>
<dt>Left</dt><dd><p>Width of left edge (mm)</p>
</dd>
<dt>Right</dt><dd><p>Width of right edge (mm)</p>
</dd>
<dt>Bottom</dt><dd><p>Bottom margin width (mm)</p>
</dd>
<dt>Top</dt><dd><p>Top margin width (mm)</p>
</dd>
<dt>Diagonal</dt><dd><p>Length of diagonal (mm)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Flury, B. and Riedwyl, H. (1988).
<em>Multivariate Statistics: A practical approach.</em>
London: Chapman &amp; Hall.
</p>

<hr>
<h2 id='bqs'>Bootstrapping quadratic scores</h2><span id='topic+bqs'></span><span id='topic+qcluster'></span>

<h3>Description</h3>

<p>Estimates the expected quadratic score for clustering
solutions provided by a list of of candidate model, methods or
algorithmic setting.</p>


<h3>Usage</h3>

<pre><code class='language-R'>   bqs(data,
       methodset,
       B = 10,
       type = "smooth",
       oob = FALSE, 
       ncores = detectCores() - 2,
       alpha = 0.05,
       rankby = ifelse(B == 0, "mean", "lq"),
       boot_na_share = 0.25,
       savescores = FALSE,
       saveparams = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bqs_+3A_data">data</code></td>
<td>

<p>a numeric vector, matrix, or data frame of observations. Rows
correspond to observations and columns correspond to
variables/features.
Categorical variables and <code>NA</code> values are not allowed.
</p>
</td></tr>
<tr><td><code id="bqs_+3A_methodset">methodset</code></td>
<td>

<p>a list of functions. A function in the list  takes <code>data</code> as
input and provide a clustering method to be scored
(see <em>Details</em>).
</p>
</td></tr>
<tr><td><code id="bqs_+3A_b">B</code></td>
<td>

<p>a integer <code>&gt;=0</code>.
If <code>B=0</code>, the funciton fits and scores the clustering methods on
the entire data set without resampling (see <em>Details</em>).
<code>B&gt;=1</code>, sets the number of boostrap replicates (see
<em>Details</em>).
</p>
</td></tr>
<tr><td><code id="bqs_+3A_type">type</code></td>
<td>

<p>character string specifying the type of score,
Possibile values are <code>{"smooth", "hard", "both"}</code>. 
If <code>="smooth"</code> (default), only the smooth score is
estimated.
If <code>="hard"</code>, only the hard score is
estimated. 
<code>="both"</code>,  both the smooth and the hard
scores are estimated.
</p>
</td></tr>
<tr><td><code id="bqs_+3A_oob">oob</code></td>
<td>

<p>logical or character string specifying if out-of-bag bootstrap
is performed.
Possibile values are <code>{FALSE, TRUE, "only"}</code>
If <code>=FALSE</code> (default),  out-of-bag boostrap is not performed. 
If <code>=TRUE</code>, out-of-bag bootstrap is performed along with the
empirical bootstrap sampling.
If <code>="only"</code>, only the out-of-bag bootstrap is performed. 
</p>
</td></tr>
<tr><td><code id="bqs_+3A_ncores">ncores</code></td>
<td>

<p>an integer,   it defines the number of cores used for parallel
computing (see <em>Details</em>).
</p>
</td></tr>
<tr><td><code id="bqs_+3A_alpha">alpha</code></td>
<td>

<p>a number in <code>(0,1)</code>, the confidence-level for empirical
bootstrap quantiles (both-tails). 
</p>
</td></tr>
<tr><td><code id="bqs_+3A_rankby">rankby</code></td>
<td>

<p>character string specifying how the scored solution are ranked.
Possible values are <code>{"lq", "mean", "1se"}</code>.
With <code>="lq"</code> (default), the solutions are ranked by maximizing the estimated
lower limit of the of the <code>1-alpha</code> bootstrap confidence
intervalfor  the expected score.
With <code>="mean"</code>, the solutions are ranked by maximizing the estimated
expected score. 
With <code>="1se"</code>, the solutions are ranked by maximizing the estimated
lower limit of the confidence interval for the expected score
whose semi-length is equal to a <em>standard error</em>.
The expected score's <em>standard error</em> is approximated using the
boostrap distribution.
</p>
</td></tr>
<tr><td><code id="bqs_+3A_boot_na_share">boot_na_share</code></td>
<td>

<p>a numeric value in <code>(0,1)</code>.
During the boostrapping a method's score is set to <code>NA</code> if the
underlying comptutation runs into errors. 
Methods resulting in more than <code>B * boot_na_share</code> errors are
excluded from the comparison
</p>
</td></tr>
<tr><td><code id="bqs_+3A_savescores">savescores</code></td>
<td>

<p>logical, if <code>=TRUE</code> it returns estimated scores for each
boostrap sample. 
</p>
</td></tr>
<tr><td><code id="bqs_+3A_saveparams">saveparams</code></td>
<td>

<p>logical, if <code>=TRUE</code> it returns estimated cluster parameters for
each boostrap sample.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements the estimation and selection of an
appropriate  clustering based on the methodology proposed in Coraggio
and Coretto (2023). In addition, we add the possibility of obtaining
score estimates using out-of-bag-boorstrap sampling alongside the
empirical  bootstrap-based estimates proposed in the aforementioned
paper. Note that the out-of-bag-boorstrap estimates are obtained
using the same samples used for the emprical bootsrap, therefore,
<code>oob=TRUE</code> add a small computational cost.
</p>
<p><strong>Choice of <code>B</code>.</strong> In theory <code>B</code> should be as large as
possible, however, if the list of methods is large and the
computational capacity is modest, a large <code>B</code> may require 
long run times. Coraggio and Coretto (2023) show experiments where
changing from <code>B=1000</code> to <code>B=100</code> introduces a marginal
increase  in variability. <code>B=100</code> should be considered as a
lower  bound. In the case where one has very large method lists,
high-dimensional  datasets and demanding methods, a possible strategy
to reduce the computational cost is as follows:
</p>

<ol>
<li><p> set a small value of <code>B</code>, e.g., <code>B=50</code> or even less.
</p>
</li>
<li><p> Analyze the methods' ranking and identify those methods that
report score values that are small compared to the top performers.
</p>
</li>
<li><p> Narrow down the <code>methodset</code> list and repeat the
bootstrap  estimation with a value of <code>B</code> that is as large as
possible relative to available computational resources.
</p>
</li></ol>

<p><strong>Parallel computing.</strong> Bootstrap sampling is performed using
<code>foreach</code>-based parallel computation via the <code>doParallel</code>
parallel backend.   Note that depending on the system settings, and
how the functions in <code>methodset</code> make use of parallelism and/or
multi-threading computing, increasing <code>ncores</code> may not produce
the desired reduction in computing time. For instance, this happens
when  using linear algebra routines optimized for multi-threaded
computing  (e.g., OpenBLAS, Intel Math Kernel Library (MKL), and so
on).  These optimized shared libraries already implement
multi-threading,  and it is necessary to find the optimal trade-off
between distributing processes over physical cores and
multi-threading  at the logical unit level of the same physical unit.
Unfortunately, there is no universal recipe and much depends on
hardware  architectures, operating system, shared libraries, etc.
We obtained the best results using OpenBLAS (the tagged
<em>serial</em>) and setting <code>ncores=</code> the number of physical
cores. 
</p>
<p><strong><code>methodset</code> argument.</strong> The <code>methodset</code> argument 
allows in input a <code>function</code>, <code>list</code>, or output from mset 
functions: <code>mset_user</code>, <code>mset_gmix</code>, <code>mset_kmeans</code>, 
<code>mset_pam</code>. It is also possible give any combination of these, 
concatenated with the <code>mbind</code> function. When passing a 
<code>function</code>, either as a single element or in a list, this must 
take the data set as its first argument, and must return in output 
at least <code>list</code> named <em>&quot;params&quot;</em>, conforming with the 
return value of <code>clust2params</code>, i.e. a list containing 
<code>proportion</code>, <code>mean</code> and <code>cov</code> elements, representing 
the estimated clusters' parameters.
</p>


<h3>Value</h3>

<p>An S3 object of class <code>bqs</code>. Output components are as follows:
</p>
<table role = "presentation">
<tr><td><code>smooth</code></td>
<td>

<p>data.frame returned if
<code>type="smooth"</code> or <code>type="both"</code>.
It contains a summary of the estimated score. The rows corresponds to
competing methods in <code>methodset</code> sorted by the specified ranking
criterion. 
Columns are as follows:
</p>

<dl>
<dt><code>id:</code></dt><dd>
<p>index of the method in the corresponding <code>methodset</code> list;
</p>
</dd> 
<dt><code>rank:</code></dt><dd>
<p>rank of the clustering solution according to <code>rankby</code>;
</p>
</dd> 
<dt><code>mean:</code></dt><dd>
<p>expected score;</p>
</dd>
<dt> <code>sterr</code></dt><dd>
<p>standard error for the mean score;
</p>
</dd>
<dt><code>lower_qnt:</code></dt><dd>
<p>lower limit of the confidence interval for the mean score;
</p>
</dd>
<dt><code>upper_qnt:</code></dt><dd>
<p>upper limit of the confidence interval for the mean score;
</p>
</dd>
<dt><code>n_obs:</code></dt><dd>
<p>number of valid bootstrap samples after filtering erroneous cases;
</p>
</dd>
<dt><code>n_missing:</code></dt><dd>
<p>number of filtered erroneous cases.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>hard</code></td>
<td>

<p>data.frame returned if 
<code>type="hard"</code> or <code>type="both"</code>.
It reports the results about the hard score in analogy to the previous object
<code>smooth</code>.
</p>
</td></tr>
<tr><td><code>obb_smooth</code></td>
<td>

<p>data.frame returned if 
<code>type="smooth"</code> or <code>type="both"</code> and <code>obb=TRUE</code> or <code>obb="only"</code>.
It reports the results about the smooth score estimated using
out-of-bang-boostrap samples  in analogy to the previous objects
<code>smooth</code> and <code>hard</code>.
</p>
</td></tr>
<tr><td><code>obb_hard</code></td>
<td>

<p>data.frame returned if
<code>type="hard"</code> or <code>type="both"</code> and   <code>obb=TRUE</code> or <code>obb="only"</code>.
It reports the results about the hard score estimated using
out-of-bang-boostrap samples  in analogy to the previous objects
<code>smooth</code> and <code>hard</code>.
</p>
</td></tr>
<tr><td><code>best_smooth</code></td>
<td>

<p>Clustering produced by the <em>best</em> method, according the
specified <code>rankby</code> criterion, applied to the smooth score
estimated using the empirical bootstrap sampling.
</p>
</td></tr>
<tr><td><code>best_hard</code></td>
<td>
  
<p>clustering produced by the <em>best</em> method, according the
specified <code>rankby</code> criterion, applied to the hard score
estimated using the empirical bootstrap sampling.
</p>
</td></tr>
<tr><td><code>best_obb_smooth</code></td>
<td>

<p>clustering produced by the <em>best</em> method, according the
specified <code>rankby</code> criterion, applied to the smooth score
estimated using the out-of-bag-boostrap samples.
</p>
</td></tr>
<tr><td><code>best_obb_hard</code></td>
<td>

<p>clustering produced by the <em>best</em> method, according the
specified <code>rankby</code> criterion, applied to the hard score
estimated using the out-of-bag-boostrap samples.
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>a list containing information about the input <code>data</code> set
necessary for the fruition of the returned object.
</p>
</td></tr>
<tr><td><code>B</code></td>
<td>

<p>number of bootstrap replicates.
</p>
</td></tr>
<tr><td><code>methodset</code></td>
<td>

<p>The elements of <code>methodset</code> for which a solution is
produced.
</p>
</td></tr>
<tr><td><code>rankby</code></td>
<td>

<p>the ranking criterion.
</p>
</td></tr>
<tr><td><code>raw</code></td>
<td>

<p>a list that  allows tracing the bootstrap sampling in almost
every stage.
Let <code>n=</code>sample size, <code>B=</code>bootstrap samples, <code>M=</code> number
of methods in <code>methoset</code>.
It contains the following objects.
</p>

<dl>
<dt><code>boot_id</code>:</dt><dd>
<p>an array of dimension <code>n x B</code> where
the <code>j</code>-th column contains the indexes of the observed data
points belonging to the <code>j</code>-th bootstrap sample. That is,  
<code>data[boot_id[ ,j], ]</code> gives the <code>j</code>-th bootstrap data
set.</p>
</dd>

<dt><code>scores</code>:</dt><dd>
<p>an array of dimension <code>(M x 3 x B)</code> returned if
<code>savescores=TRUE</code>.
It reports both hard and smooth scores estimated in each  bootstrap
replicate.
<code>score[,1,]</code> reports a <code>code=1</code> if the corresponding
bootstrap sample has been excluded because of errors (otherwise
<code>code=0</code>).</p>
</dd>

<dt><code>oob_scores</code>:</dt><dd>
<p>returned if  <code>obb=TRUE</code> or <code>obb="only"</code> and <code>savescores=TRUE</code>.
It is an array is organized as the previous object <code>score</code>
but contains information about out-of-bag-bootstrap estimates.
</p>
</dd>

<dt><code>params</code>:</dt><dd>
<p>a list returned if <code>saveparams=TRUE</code>.  <code>params[[m]]</code>
contains  estimated cluster parameters for <code>methodset[[m]]</code>
where <code>m=1,...,M</code>.  Each member of the list is a list of
length <code>B</code>  where <code>params[[m]][[b]]</code> contains the
cluster  parameters fitted by the <code>m</code>-th method on the
<code>b</code>-th  bootstrap sample.
</p>
</dd>
</dl>

</td></tr>
</table>


<h3>References</h3>

<p>Coraggio, Luca and Pietro Coretto (2023). Selecting the number of
clusters, clustering models, and algorithms. A unifying approach based
on the  quadratic discriminant score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), 1-20.
doi: <a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mset_user">mset_user</a></code>, <code><a href="#topic+mset_gmix">mset_gmix</a></code>, <code><a href="#topic+mset_kmeans">mset_kmeans</a></code>, 
<code><a href="cluster.html#topic+pam">pam</a></code>, <code><a href="#topic+mbind">mbind</a></code>, <code><a href="#topic+clust2params">clust2params</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load data
data("banknote")
dat &lt;- banknote[-1]

## set up methods
## see also help('mset_user')  and related functions 
KM   &lt;- mset_kmeans(K = 3)
GMIX &lt;- mset_gmix(K=3, erc=c(1,100)) 

# combine tuned methods
mlist &lt;- mbind(KM, GMIX)

# perform bootstrap
# change B and ncores to a much larger value in real problems 
res &lt;- bqs(dat, mlist, B = 3, type = "both", rankby="lq",
         ncores = 1, oob = TRUE, savescores = TRUE, saveparams = FALSE)
res


## Not run: 
# The following example is more realistic but may take time
# ----------------------------------------------------------
# load data
data("banknote")
dat &lt;- banknote[-1]

# set up kmeans, see help('mset_kmeans')
KM    &lt;- mset_kmeans(K = 2:5)

# set up Gaussian model-based clustering via gmix() 
GMIX  &lt;- mset_gmix(K=2:5, erc=c(1, 50 , 100)) 

# set up Gaussian model-based clustering via library("mclust")
# see examples in help('mset_user')
require(mclust)
mc_wrapper &lt;- function(data, K, ...){
    y &lt;- Mclust(data, G = K, ...)
    y[["params"]] &lt;- list(proportion = y$parameters$pro,
                          mean = y$parameters$mean,
                          cov = y$parameters$variance$sigma)
    return(y)
    }
MC &lt;- mset_user(fname = "mc_wrapper", K = 2:5, modelNames = c("EEI", "VVV"))


# combine tuned methods
mlist &lt;- mbind(KM, GMIX, MC)

# perform bootstrap
# set 'ncores' to the number of available physical cores
res &lt;- bqs(dat, mlist, B = 100, type = "both", rankby="lq", ncores=1,
           oob = TRUE, savescores = TRUE, saveparams = FALSE)
res

## End(Not run)  
</code></pre>

<hr>
<h2 id='bqs_rank'>Ranking Clusters Quadratic Scores Estimated Via Boostrap</h2><span id='topic+bqs_rank'></span>

<h3>Description</h3>

<p>Ranks the scores of clusters methods estimated via boostrap</p>


<h3>Usage</h3>

<pre><code class='language-R'>   bqs_rank(bqsol, rankby = "lq", boot_na_share = 0.25)
   </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bqs_rank_+3A_bqsol">bqsol</code></td>
<td>

<p>an object of class <code>bqs</code> obtained from <code><a href="#topic+bqs">bqs</a></code>.
</p>
</td></tr>
<tr><td><code id="bqs_rank_+3A_rankby">rankby</code></td>
<td>

<p>character string specifying how the scored solution are ranked.
Possible values are <code>{"lq", "mean", "1se"}</code>.
With <code>="lq"</code> (default), the solutions are ranked by maximizing the estimated
lower limit of the of the <code>1-alpha</code> bootstrap confidence
intervalfor  the expected score.
With <code>="mean"</code>, the solutions are ranked by maximizing the estimated
expected score. 
With <code>="1se"</code>, the solutions are ranked by maximizing the estimated
lower limit of the confidence interval for the expected score
whose semi-length is equal to a <em>standard error</em>.
The expected score's <em>standard error</em> is approximated using the
boostrap distribution.
</p>
</td></tr>
<tr><td><code id="bqs_rank_+3A_boot_na_share">boot_na_share</code></td>
<td>

<p>a numeric value in <code>(0,1)</code>.
During the boostrapping a method's score is set to <code>NA</code> if the
underlying comptutation runs into errors. 
Methods resulting in more than <code>B * boot_na_share</code> errors are
excluded from the comparison
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>bqs</code>. Output components are those of
<code><a href="#topic+bqs">bqs</a></code>. See <em>Value</em> in <code><a href="#topic+bqs">bqs</a></code>.
</p>


<h3>References</h3>

<p>Coraggio, Luca and Pietro Coretto (2023). Selecting the number of
clusters, clustering models, and algorithms. A unifying approach based
on the  quadratic discriminant score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), 1-20.
doi: <a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bqs">bqs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data("banknote")
dat &lt;- banknote[-1]

## set up methods
## see also help('mset_user')  and related functions 
KM   &lt;- mset_kmeans(K = 3)
GMIX &lt;- mset_gmix(K=3, erc=c(1,100)) 

# combine tuned methods
mlist &lt;- mbind(KM, GMIX)

# perform bootstrap
# change B and ncores to a much larger value in real problems 
res &lt;- bqs(dat, mlist, B = 3, rankby="lq", ncores=1)
res

   
# now change ranking criterion
res2 &lt;- bqs_rank(res, rankby="mean")
res2
</code></pre>

<hr>
<h2 id='bqs_select'>Select Ranked Cluster Solutions by Quadratic Score</h2><span id='topic+bqs_select'></span>

<h3>Description</h3>

<p>Select solutions from a <code>bqs</code> object based on specified rank and type of score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   bqs_select(bqs_sol, rank = 1, type = "smooth", rankby = NA, boot_na_share = 0.25)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bqs_select_+3A_bqs_sol">bqs_sol</code></td>
<td>

<p>An object of class <code>bqs</code> containing the clustering solutions to be selected.
</p>
</td></tr>
<tr><td><code id="bqs_select_+3A_rank">rank</code></td>
<td>

<p>An integer <code>&gt;0</code> specifying the rank of the solution to select. Default is <code>1</code>.
</p>
</td></tr>
<tr><td><code id="bqs_select_+3A_type">type</code></td>
<td>

<p>A character string specifying the type of Quadratic Score. Possible values are <code>"hard"</code>, <code>"smooth"</code>, <code>"oob_hard"</code>, <code>"oob_smooth"</code>. Default is <code>"smooth"</code>.
</p>
</td></tr>
<tr><td><code id="bqs_select_+3A_rankby">rankby</code></td>
<td>

<p>A character string specifying the criteria used to rank solutions in <code>bqs</code>. Possible values are <code>"lq"</code>, <code>"mean"</code>, <code>"1se"</code>, or <code>NA</code> (default). See <em>Details</em>.
</p>
</td></tr>
<tr><td><code id="bqs_select_+3A_boot_na_share">boot_na_share</code></td>
<td>

<p>A numeric value between (0, 1). Clustering solutions in <code>bqs_sol</code> with a share of <code>NA</code> bootstrap estimates are excluded from ranking. Default is <code>0.25</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Even if the <code>bqs_sol</code> object is not pre-ranked, the user may specify a ranking criterion to rank clustering solutions dynamically using the <code>rankby</code> argument; this does not influence the <code>bqs_sol</code> ranking. In these instances, the user can also specify <code>boot_na_share</code> as in <code><a href="#topic+bqs_rank">bqs_rank</a></code> to exclude solutions based on the proportion of unsuccessful bootstrap estimations. If <code>rankby=NA</code>, the <code>bqs_sol</code> must be pre-ranked.
</p>


<h3>Value</h3>

<p>A named list of all clustering solutions achieving a <code>type</code> score of rank <code>rank</code> when ranked  according to <code>rankby</code> criterion, or <code>NULL</code> if no such solution is available in the <code>bqs_sol</code> object. List names correspond to methods' names, and each named entry contains the corresponding clustering method in <code>bqs_sol$methodlist</code> fit on <code>bqs_sol$data</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bqs">bqs</a></code>, <code><a href="#topic+bqs_rank">bqs_rank</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load data and set seet
set.seed(123)
data("banknote")
dat &lt;- banknote[-1]

# set up kmeans, see help('mset_kmeans')
KM    &lt;- mset_kmeans(K = 2:5)

# set up Gaussian model-based clustering via gmix()
GMIX  &lt;- mset_gmix(K=2:5, erc=c(1, 50 , 100))

# combine tuned methods
mlist &lt;- mbind(KM, GMIX)

# perform bootstrap
# se 'ncores' to the number of available physical cores
res &lt;- bqs(dat, mlist, B = 20, type = "both", rankby=NA, ncores = 1,
           oob = TRUE, savescores = TRUE, saveparams = FALSE)

# Methods are not ranked; this will raise an error
try(bqs_select(res, rank = 1))

# Rank method dynamically
ranked_res &lt;- bqs_select(res, rank = 2, rankby = "lq", boot_na_share = 0.25)
names(ranked_res)

</code></pre>

<hr>
<h2 id='clust2params'>Converts Hard Assignment Into Cluster Parameters</h2><span id='topic+clust2params'></span>

<h3>Description</h3>

<p>Transforms cluster labels into a list of parameters  describing cluster size, 
mean, and dispersion.</p>


<h3>Usage</h3>

<pre><code class='language-R'>   clust2params(data, cluster)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clust2params_+3A_data">data</code></td>
<td>

<p>a numeric vector, matrix, or data frame of observations. 
Rows correspond to observations and columns correspond to variables/features. 
Categorical variables and <code>NA</code> values are not allowed.
</p>
</td></tr>
<tr><td><code id="clust2params_+3A_cluster">cluster</code></td>
<td>

<p>a vector of integers representing cluster labels.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing  cluster parameters. 
Let <code>P=</code><em>number of variable/features</em> and <code>K=</code><em>number of clusters</em>. 
The elements  of the list are as follows: 
</p>

<ul>
<li> <p><code>prop:</code> a vector of clusters' proportions; 
</p>
</li>
<li> <p><code>mean:</code> a matrix of dimension <code>(P x K)</code> containing the clusters' mean 
parameters;
</p>
</li>
<li> <p><code>cov:</code> an array of size <code>(P x P x K)</code> containing the clusters'
covariance matrices.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># load data
data("banknote")

# compute the k-means partition 
set.seed(2024)
cl &lt;- kmeans(banknote[-1], centers = 2, nstart = 1)$cluster

# convert k-means hard assignment into cluster parameters 
clpars &lt;- clust2params(banknote[-1], cl) 
clpars

</code></pre>

<hr>
<h2 id='gmix'>Gaussian Mixture Modelling</h2><span id='topic+gmix'></span>

<h3>Description</h3>

<p>Fast implementation of the EM algorithm for ML estimation and clustering of Gaussian mixture models with covariance matrix regularization based on eigenvalue 
ratio constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmix(
   data,
   K = NA,
   erc = 50,
   iter.max = 1000,
   tol = 1e-8,
   init = "kmed",
   init.nstart = 25,
   init.iter.max = 30,
   init.tol = tol,
   save_cluster = TRUE,
   save_params = TRUE,
   save_taus = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gmix_+3A_data">data</code></td>
<td>

<p>a numeric vector, matrix, or data frame of observations. Rows
correspond to observations and columns correspond to
variables/features.  Let <code>N=nrows(data)</code> and
<code>P=ncol(data)</code>. Categorical variables and <code>NA</code> values are
not allowed.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_k">K</code></td>
<td>

<p>the number of mixture components or clusters. It can be left
<code>NA</code> for certain specifications of <code>init</code> (see below) where
the number of cluster is retrieved from the initial partition.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_erc">erc</code></td>
<td>

<p>a numeric value <code>&gt;=1</code> specifying the eigenvalue ratio
constraint (See <em>Details</em>).
</p>
</td></tr>
<tr><td><code id="gmix_+3A_iter.max">iter.max</code></td>
<td>

<p>maximum number of iterations for the EM algorithm.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_tol">tol</code></td>
<td>

<p>tolerance for the convergence of the EM algorithm.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_init">init</code></td>
<td>

<p>a character in the set <code>c("kmed", "kmeans", "pam")</code>, a vector, a matrix, 
or a callable giving the initial assignment of data points (see
<em>Details</em>). The default choice is &quot;kmed&quot;.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_init.nstart">init.nstart</code></td>
<td>

<p>number of initial partitions ((see <em>Details</em>)).
</p>
</td></tr>
<tr><td><code id="gmix_+3A_init.iter.max">init.iter.max</code></td>
<td>

<p>maximum number of iterations for each run of the kmedian
initialization.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_init.tol">init.tol</code></td>
<td>

<p>tolerance for the convergence of each ran of the  kmedian
initialization.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_save_cluster">save_cluster</code></td>
<td>

<p>logical, if <code>TRUE</code> the point-to-cluster assignment based on the 
<em>maximum a posteriori probability</em> (MAP) rule is returned.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_save_params">save_params</code></td>
<td>

<p>logical, if <code>TRUE</code> the estimated mixture parameters are
returned.
</p>
</td></tr>
<tr><td><code id="gmix_+3A_save_taus">save_taus</code></td>
<td>

<p>logical, if <code>TRUE</code> the posterior class probabilities are returned
(these are also known as <em>posterior weights</em> or <em>fuzzy
weights</em>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements the constrained ML estimator studied in
Coretto and Hennig  (2023). The convariance matrix constraints are
computed according to the <code>CM1-step</code> of  Algorithm 2 of Coretto
and Hennig (2017). This function uses highly optimized C code for fast
execution. The constrained M-step extensively uses low-level common
linear algebra matrix operations (BLAS/LAPACK routines). Consequently,
to maximize computational efficiency, it is recommended that the best
available shared libraries, such as  OpenBLAS, Intel Math Kernel
Library (MKL),  etc., be set up. 
</p>
<p><strong>Initialization.</strong> 
The default method, set with <code>init="kmed"</code>, uses fast C
implementation  of the  k<code>-</code>medians algorithm with random initial
centers drawn uniformly over the <code>data</code> rows <code>init.iter.max</code>
times. Depending on the computer power available
it is suggested to set <code>init.iter.max</code> as large as  possible
particularly  in cases where the data set dimensionality is large in
terms  of both sample  size and number of  features.
Setting  <code>init="kmeans"</code> one replaces the K<code>-</code>medians with
the  K<code>-</code>means. With <code>init="pam"</code>  initial clusters are
determined  using the PAM algorithm based on  Euclidian distances. The
latter  does not perform multiple starts. 
The user can also set <code>init = x</code> where <code>x</code> is a vector of
integers  of length <code>N=nrow(data)</code> representing an initial hard
assignment  of data points to the mixture components or clusters (see <em>Examples</em>). 
Another possibility is to set <code>init = W</code> where <code>W</code> is a
matrix of  dimension <code>(N x {K})</code> containing the initial posterior
probabilities that the <em>i</em>th observation belongs to the
<em>k</em>th  cluster. The assignment provided via <code>W</code> can be hard
(0<code>-</code>1 weights with the constraint that only a 1 is possible in
each row of <code>W</code>, or smooth (each row of <code>W</code> must sum up to
1).   <code>W</code> can be seen as the initial version of the object
<code>tau</code>  describied in the <em>Value</em> section below.
The last alternative is to set <code>init = f(data)</code>. Here
<code>f(data)</code>  is a function 
that takes <code>data</code> as an input and returns the matrix with an
initial  hard/smooth assignment as the <code>W</code> matrix previously
described (see the example below).	
</p>
<p><strong>Eigenvalue ratio constraint (<code>erc</code>).</strong> 
It is  the maximum allowed ratio between within-cluster covariance
matrix  eigenvalues. 
It defines the so<code>-</code>called <em>eigenratio constraint</em>. 
<code>erc=1</code> enforces spherical clusters with equal covariance matrices. 
A large <code>erc</code> allows for large between-cluster covariance discrepancies. 
It is suggested to never set <code>erc</code> arbitrarily large, its main role is to 
prevent degenerate covariance parameters and the related emergence of spurious 
clusters (see <em>Referenceses</em> below).
Finally, in order to facilitate the setting of <code>erc</code>, it is
suggested to scale the  columns of <code>data</code> whenever measurement
units  of the different variables 
are grossly incompatible. 
</p>


<h3>Value</h3>

<p>An S3 object of class <code>'mbcfit'</code>. Output components are as follows:
</p>
<table role = "presentation">
<tr><td><code>info</code></td>
<td>

<p>information on convergence and errors (see notes).
</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>

<p>number of iterations performed in the underlying  EM-algorithm.
</p>
</td></tr>
<tr><td><code>N</code></td>
<td>

<p>number of data points.
</p>
</td></tr>
<tr><td><code>P</code></td>
<td>

<p>data dimension.
</p>
</td></tr>
<tr><td><code>K</code></td>
<td>

<p>number of clusters.
</p>
</td></tr>
<tr><td><code>eloglik</code></td>
<td>

<p>sample expected log<code>-</code>likelihood.
</p>
</td></tr>
<tr><td><code>size</code></td>
<td>

<p>cluster size (counts).
</p>
</td></tr>
<tr><td><code>cluster</code></td>
<td>

<p>cluster assignment based on the  <em>maximum a posteriori</em> rule  (MAP).
</p>
</td></tr>
<tr><td><code>taus</code></td>
<td>

<p>a matrix of dimension <code>(N x {K})</code> where <code>tau[i, k]</code> is the 
estimated posterior probability that the <em>i</em>th observation belongs to the
<em>k</em>th cluster.
</p>
</td></tr>
<tr><td><code>params</code></td>
<td>

<p>a list containing mixture components parameters.   
The elements  of the list are as follows:  
<code>$prop=</code>vector of proportions;  
<code>$mean=</code>=matrix of dimension <code>(P x K)</code> containing mean parameters; 
<code>$cov=</code>array of size <code>(P x P x K)</code> containing covariance 
matrices. 
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>a list with two components named giving information about underlysing
EM algorithm. The  <code>code</code> obejects can take the following values:
</p>

<ul>
<li> <p><code>code=1</code>: the algorithm converged within <code>iter.max</code>. 
</p>
</li>
<li> <p><code>code=2</code>: the algorithm reached <code>iter.max</code>.
</p>
</li>
<li> <p><code>code=3</code>: the algorithm did not move from initial values.
</p>
</li>
<li> <p><code>code=-1</code>: unexpected memory allocation issues occured.
</p>
</li>
<li> <p><code>code=-2</code>: unexpected LAPACK routines errors  occured.
</p>
</li></ul>

<p>The  <code>flag</code> obejects can take the following values:
</p>

<ul>
<li> <p><code>flag=0</code> no flag.
</p>
</li>
<li> <p><code>flag=1</code> numerically degenerate posterior probabilities.
(<code>taus</code>) could not be prevented.
</p>
</li>
<li> <p><code>flag=2</code> the ERC was enforced at least once.
</p>
</li>
<li>  <p><code>flag=3</code> if condition of <code>flag=1</code> and <code>flag=2</code>
occurred.
</p>
</li></ul>

</td></tr>
</table>


<h3>References</h3>

<p>Coretto, Pietro and Christian Hennig (2017).
Consistency, breakdown robustness, and algorithms for robust improper
maximum  likelihood clustering.
<em>Journal of Machine Learning Research</em>, Vol. 18(142), pp. 1-39.   URL: 
<a href="https://jmlr.org/papers/v18/16-382.html">https://jmlr.org/papers/v18/16-382.html</a>
</p>
<p>Coretto, Pietro and Christian Hennig (2023)
Nonparametric consistency for maximum likelihood estimation and clustering based 
on mixtures of elliptically-symmetric distributions.
<em>arXiv:2311.06108</em>. URL: 
<a href="https://arxiv.org/abs/2311.06108">https://arxiv.org/abs/2311.06108</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># --- load data
data("banknote")
dat &lt;- banknote[-1]
n   &lt;- nrow(dat) #sample size
nc  &lt;- 2         #number of clusters


   
# fit 2 clusters using the default k-median initialization 
# In real applications set 'init.nstart' as large as possibile
set.seed(101)
fit1 &lt;- gmix(dat, K = nc, init.nstart = 1)
print(fit1)

# plot partition (default)
plot(x = fit1, data = dat)


# plot partition onto the first 3 principal component coordinates 
plot(x = fit1, data = prcomp(dat)$x, margins = c(1,2,3),
     pch_cl = c("A", "B"), col_cl = c("#4285F4", "#0F9D58"),
     main = "Principal Components")


 
# user-defined random initialization with hard assignment labels 
set.seed(102)
i2   &lt;- sample(1:nc, size = n, replace = TRUE)
fit2 &lt;- gmix(dat, K = 2, init = i2)
plot(x=fit2, data = dat)



# user-defined smooth "toy" initialization: 
# 50% of the points are assigned to cluster 1 with probability 0.95 and to
# cluster 2 with probability 5%. The remaining data points are assigned to
# cluster 1 with probability 10% and  to cluster 2 with probability 10%
# 
set.seed(103)
idx        &lt;- sample(c(TRUE, FALSE), size = n, replace = TRUE)
i3         &lt;- matrix(0, nrow = n, ncol = nc) 
i3[idx,  ] &lt;- c(0.9, 0.1)
i3[!idx, ] &lt;- c(0.1, 0.9)
# fit
fit3  &lt;- gmix(dat, K = nc, init = i3)
plot(x=fit3, data = dat)



# user-defined function for initialization
# this one produces a 0-1 hard posterior matrix W based on kmeans
#
compute_init &lt;- function(data, K){
  cl  &lt;- kmeans(data, K, nstart=1, iter.max=10)$cluster
  W   &lt;- sapply(seq(K), function(x) as.numeric(cl==x))
  return(W)
} 
fit4 &lt;- gmix(dat, K = nc, init = compute_init)
plot(fit4, data = dat)

</code></pre>

<hr>
<h2 id='mbind'>Combines Methods Settings</h2><span id='topic+mbind'></span>

<h3>Description</h3>

<p>The function combines functions containing clustering methods setups 
built using <code><a href="#topic+mset_user">mset_user</a></code> and related functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  mbind(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mbind_+3A_...">...</code></td>
<td>

<p>one or more object of class <code>qcmethod</code> obtained from <code><a href="#topic+mset_user">mset_user</a></code> and related functions
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>'qcmethod'</code>. Each element of the list
represents a competing method containing the following objects
</p>
<table role = "presentation">
<tr><td><code>fullname</code></td>
<td>

<p>a string identifying the setup.
</p>
</td></tr>
<tr><td><code>callargs</code></td>
<td>

<p>a list with arguments that are passed to the base function.
</p>
</td></tr>
<tr><td><code>fn</code></td>
<td>

<p>the function implementing the specified setting. This <code>fn</code>
function can be executed on the data set.
It has two arguments: <code>data</code> and <code>only_params</code>.
<code>data</code> is a data matrix or data.frame
<code>only_params</code> is logical.
If <code>only_params==FALSE</code> (default), <code>fn</code> will return the
object returned by the <code>fname</code>.
If <code>only_params==TRUE</code> (default) <code>fn</code> will return only cluster 
parameters (proportions, mean, and cov, see <a href="#topic+clust2params">clust2params</a>).
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coraggio, Luca and Pietro Coretto (2023). Selecting the number of
clusters, clustering models, and algorithms. A unifying approach based
on the  quadratic discriminant score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), 1-20.
doi: <a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mset_user">mset_user</a></code>, <code><a href="#topic+mset_gmix">mset_gmix</a></code>,  <code><a href="#topic+mset_kmeans">mset_kmeans</a></code>, <code><a href="#topic+mset_pam">mset_pam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data("banknote")
dat  &lt;- banknote[-1]

# generate  kmeans setups 
A &lt;- mset_kmeans(K=c(2,3))

# generate gmix  setups 
B &lt;- mset_gmix(K=c(2,3))

# combine setups
M &lt;- mbind(A, B)

# get the PAM setting with K=3
m &lt;- M[[4]]
m

# cluster data with M[[3]]
fit &lt;- m$fn(dat)
fit
</code></pre>

<hr>
<h2 id='mset_gmix'>Generates Methods Settings for Gaussian Mixture Model-Based Clustering</h2><span id='topic+mset_gmix'></span>

<h3>Description</h3>

<p>The function generates a software abstraction of a list of clustering
models implemented through a set of tuned methods and algorithms. 
In particular, it  generates a list of<code><a href="#topic+gmix">gmix</a></code> -type functions each
combining model tuning parameters and other algorithmic settings.
The generated functions are ready to be called on the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mset_gmix(
   K = seq(10),
   init = "kmed",
   erc = c(1, 50, 1000),
   iter.max = 1000,
   tol = 1e-8,
   init.nstart = 25, 
   init.iter.max = 30,
   init.tol = tol)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mset_gmix_+3A_k">K</code></td>
<td>

<p>a vector/list, specifies the number of clusters.  
</p>
</td></tr>
<tr><td><code id="mset_gmix_+3A_init">init</code></td>
<td>

<p>a vector, contains the settings of the <code>init</code> parameter of <code><a href="#topic+gmix">gmix</a></code>.
</p>
</td></tr>
<tr><td><code id="mset_gmix_+3A_erc">erc</code></td>
<td>

<p>a vector/list, contains the settings of the <code>erc</code> parameter of <code><a href="#topic+gmix">gmix</a></code>.
</p>
</td></tr>
<tr><td><code id="mset_gmix_+3A_iter.max">iter.max</code></td>
<td>

<p>a integer vector, contains the settings of the <code>iter.max</code> parameter of <code><a href="#topic+gmix">gmix</a></code>. 
</p>
</td></tr>
<tr><td><code id="mset_gmix_+3A_tol">tol</code></td>
<td>

<p>a vector/list, contains the settings of the <code>tol</code> parameter of <code><a href="#topic+gmix">gmix</a></code>. 
</p>
</td></tr>
<tr><td><code id="mset_gmix_+3A_init.nstart">init.nstart</code></td>
<td>

<p>a integer vector, contains the settings of the <code>init.start</code>
parameter of <code><a href="#topic+gmix">gmix</a></code>. 
</p>
</td></tr>
<tr><td><code id="mset_gmix_+3A_init.iter.max">init.iter.max</code></td>
<td>

<p>a integer vector, contains the settings of the <code>init.iter.max</code> parameter of <code><a href="#topic+gmix">gmix</a></code>. 
</p>
</td></tr>   
<tr><td><code id="mset_gmix_+3A_init.tol">init.tol</code></td>
<td>

<p>a vector/list, contains the settings of the <code>init.tol</code> parameter of <code><a href="#topic+gmix">gmix</a></code>. 
</p>
</td></tr>   
</table>


<h3>Details</h3>

<p>The function produces functions implementing competing clustering methods
based on several Gaussian Mixture models specifications.  
The function produces functions for fitting competing Gaussian Mixture
model-based clustering methods settings.
This is a specialized version of the more general function
<code><a href="#topic+mset_user">mset_user</a></code>. 
In particular, it produces a list of <code><a href="#topic+gmix">gmix</a></code> functions each
corresponding to a specific setup in terms of both model
hyper-parameters (<em>e.g.</em> the number of clusters, the eigenvalue ratio
constraint, <em>etc.</em>) and algorithm's control parameters
(<em>e.g.</em>  the type of initialization, maximum number of iteration,
<em> etc.</em>). See <code><a href="#topic+gmix">gmix</a></code> for a detailed description of
the   role of each argument and their data types.
</p>


<h3>Value</h3>

<p>An S3 object of class <code>'qcmethod'</code>. Each element of the list
represents a competing method containing the following objects
</p>
<table role = "presentation">
<tr><td><code>fullname</code></td>
<td>

<p>a string identifying the setup.
</p>
</td></tr>
<tr><td><code>callargs</code></td>
<td>

<p>a list with  <code><a href="#topic+gmix">gmix</a></code> function arguments.
</p>
</td></tr>
<tr><td><code>fn</code></td>
<td>

<p>the function implementing the specified setting. This <code>fn</code>
function can be executed on the data set.
It has two arguments: <code>data</code> and <code>only_params</code>.
<code>data</code> is a data matrix or data.frame
<code>only_params</code> is logical.
If <code>only_params==FALSE</code> (default), <code>fn</code> will return the
object returned by <code><a href="#topic+gmix">gmix</a></code>.
If <code>only_params==TRUE</code> (default) <code>fn</code> will return only
cluster parameters (proportions, mean, and cov, see <a href="#topic+clust2params">clust2params</a>.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coraggio, Luca, and Pietro Coretto (2023).
Selecting the Number of Clusters, Clustering Models, and Algorithms.
A Unifying Approach Based on the Quadratic Discriminant Score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), pp. 1-20,
<a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gmix">gmix</a></code>, <code><a href="#topic+mset_user">mset_user</a></code>, <code><a href="#topic+bqs">bqs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 'gmix' settings combining number of clusters K={3,4} and eigenvalue 
# ratio constraints {1,10} 
A &lt;- mset_gmix(K = c(2,3), erc = c(1,10))
   
# select setup 1: K=2, erc = 1, init =" kmed"
ma1 &lt;- A[[1]]
print(ma1)

# fit M[[1]] on banknote data
data("banknote")
dat  &lt;- banknote[-1]
fit1 &lt;- ma1$fn(dat)   
fit1

# if only cluster parameters are needed
fit1b &lt;- ma1$fn(dat, only_params = TRUE)   
fit1b

   
# include a custom initialization, see also help('gmix')
compute_init &lt;- function(data, K){
  cl  &lt;- kmeans(data, K, nstart=1, iter.max=10)$cluster
  W   &lt;- sapply(seq(K), function(x) as.numeric(cl==x))
  return(W)
}

# generate methods settings 
B &lt;- mset_gmix(K = c(2,3), erc = c(1,10), init=c(compute_init, "kmed"))


# select setup 2: K=2, erc=10, init = compute_init
mb2  &lt;- B[[2]]
fit2 &lt;- mb2$fn(dat)   
fit2
</code></pre>

<hr>
<h2 id='mset_kmeans'>Generates Methods Settings for K-Means Clustering</h2><span id='topic+mset_kmeans'></span>

<h3>Description</h3>

<p>The function generates a software abstraction of a list of clustering
models implemented through a set of tuned methods and algorithms. 
In particular, it  generates a list of
<code><a href="stats.html#topic+kmeans">kmeans</a></code>-type   functions each combining tuning
parameters and other algorithmic settings.
The generated functions are ready to be called on the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mset_kmeans(K = c(1:10),
            iter.max = 50,
            nstart = 30,
            algorithm = "Hartigan-Wong",
            trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mset_kmeans_+3A_k">K</code></td>
<td>

<p>a vector, specifies the number of clusters.  
</p>
</td></tr>
<tr><td><code id="mset_kmeans_+3A_iter.max">iter.max</code></td>
<td>

<p>a vector, contains the settings of the <code>iter.max</code> parameter of <code><a href="stats.html#topic+kmeans">kmeans</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_kmeans_+3A_nstart">nstart</code></td>
<td>

<p>a vector, contains the settings of the <code>nstart</code> parameter of<code><a href="stats.html#topic+kmeans">kmeans</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_kmeans_+3A_algorithm">algorithm</code></td>
<td>

<p>a vector, contains the settings of the <code>algorithm</code> parameter of <code><a href="stats.html#topic+kmeans">kmeans</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_kmeans_+3A_trace">trace</code></td>
<td>

<p>a vector, contains the settings  of the <code>trace</code> parameter of <code><a href="stats.html#topic+kmeans">kmeans</a></code>.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function produces functions implementing competing clustering methods
based on the K-Means methodology  as implemented in
<code><a href="stats.html#topic+kmeans">kmeans</a></code>.
This is a specialized version of the more general function
<code><a href="#topic+mset_user">mset_user</a></code>. 
In particular, it produces a list of <code><a href="stats.html#topic+kmeans">kmeans</a></code> functions each
corresponding to a specific setup in terms of
hyper-parameters (<em>e.g.</em> the number of clusters) and algorithm's
control parameters (<em>e.g.</em>  initialization).
See <code><a href="stats.html#topic+kmeans">kmeans</a></code> for more detail for a detailed description of
the role of each argument and their data types.
</p>


<h3>Value</h3>

<p>An S3 object of class <code>'qcmethod'</code>. Each element of the list
represents a competing method containing the following objects
</p>
<table role = "presentation">
<tr><td><code>fullname</code></td>
<td>

<p>a string identifying the setup.
</p>
</td></tr>
<tr><td><code>callargs</code></td>
<td>

<p>a list with  <code><a href="stats.html#topic+kmeans">kmeans</a></code> function arguments.
</p>
</td></tr>
<tr><td><code>fn</code></td>
<td>

<p>the function implementing the specified setting. This <code>fn</code>
function can be executed on the data set.
It has two arguments: <code>data</code> and <code>only_params</code>.
<code>data</code> is a data matrix or data.frame
<code>only_params</code> is logical.
If <code>only_params==FALSE</code> (default), <code>fn</code> will return the
object returned by <code><a href="stats.html#topic+kmeans">kmeans</a></code>.
If <code>only_params==TRUE</code> (default) <code>fn</code> will return only cluster 
parameters (proportions, mean, and cov, see <a href="#topic+clust2params">clust2params</a>.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coraggio, Luca, and Pietro Coretto (2023).
Selecting the Number of Clusters, Clustering Models, and Algorithms.
A Unifying Approach Based on the Quadratic Discriminant Score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), pp. 1-20,
<a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+kmeans">kmeans</a></code>, <code><a href="#topic+mset_user">mset_user</a></code>, <code><a href="#topic+bqs">bqs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 'pam' settings combining number of clusters K={2,3}, and dissimilarities {euclidean, manhattan}
A &lt;- mset_pam(K = c(2,3), metric = c("euclidean", "manhattan"))
   
# select setup 1: K=2, metric = "euclidean"
m &lt;- A[[1]]
print(m)

# cluster with the method set in 'ma1'
data("banknote")
dat  &lt;- banknote[-1]
fit1 &lt;- m$fn(dat)   
fit1
class(fit1)

# if only cluster parameters are needed
fit2 &lt;- m$fn(dat, only_params = TRUE)   
fit2
</code></pre>

<hr>
<h2 id='mset_pam'>Generates Methods Settings for Partitioning Around Medoids (Pam) Clustering</h2><span id='topic+mset_pam'></span>

<h3>Description</h3>

<p>The function generates a software abstraction of a list of clustering
models implemented through the a set of  tuned methods and algorithms. 
In particular, it generates a list of <code><a href="cluster.html#topic+pam">pam</a></code>-type
functions each combining tuning parameters and other algorithmic settings.  
The generated functions are ready to be called on the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mset_pam(K = seq(10),
         metric = "euclidean",
         medoids = if (is.numeric(nstart)) "random",
         nstart = if (variant == "faster") 1 else NA,
         stand = FALSE,
         do.swap = TRUE,
         variant = "original",
         pamonce = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mset_pam_+3A_k">K</code></td>
<td>

<p>a vector/list, specifies the number of clusters.  
</p>
</td></tr>
<tr><td><code id="mset_pam_+3A_metric">metric</code></td>
<td>
  
<p>a vector, contains the settings of the <code>metric</code> parameter of <code><a href="cluster.html#topic+pam">pam</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_pam_+3A_medoids">medoids</code></td>
<td>

<p>list, contains the settings of the <code>medoids</code> parameter of <code><a href="cluster.html#topic+pam">pam</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_pam_+3A_nstart">nstart</code></td>
<td>

<p>a vector, contains the settings of the <code>nstart</code> parameter of <code><a href="cluster.html#topic+pam">pam</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_pam_+3A_stand">stand</code></td>
<td>

<p>a vector, contains the settings  of the <code>stand</code> parameter of <code><a href="cluster.html#topic+pam">pam</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_pam_+3A_do.swap">do.swap</code></td>
<td>

<p>a vector, contains the settings of the <code>do.swap</code> parameter of <code><a href="cluster.html#topic+pam">pam</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_pam_+3A_variant">variant</code></td>
<td>

<p>a list, contains the settings of the <code>variant</code> parameter of <code><a href="cluster.html#topic+pam">pam</a></code>.  
</p>
</td></tr>
<tr><td><code id="mset_pam_+3A_pamonce">pamonce</code></td>
<td>

<p>a vector, contains the settings of the <code>pamonce</code> parameter of <code><a href="cluster.html#topic+pam">pam</a></code>.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function produces functions implementing competing clustering methods
based on the PAM clustering methodology  as implemented in
<code><a href="cluster.html#topic+pam">pam</a></code>.
This is a specialized version of the more general function
<code><a href="#topic+mset_user">mset_user</a></code>. 
In particular, it produces a list of <code><a href="cluster.html#topic+pam">pam</a></code> functions each
corresponding to a specific setup in terms of
hyper-parameters (<em>e.g.</em> the number of clusters) and algorithm's
control parameters (<em>e.g.</em>  initialization).
See <code><a href="cluster.html#topic+pam">pam</a></code> for more detail for a detailed description of
the role of each argument and their data types. 
</p>


<h3>Value</h3>

<p>An S3 object of class <code>'qcmethod'</code>. Each element of the list
represents a competing method containing the following objects
</p>
<table role = "presentation">
<tr><td><code>fullname</code></td>
<td>

<p>a string identifying the setup.
</p>
</td></tr>
<tr><td><code>callargs</code></td>
<td>

<p>a list with  <code><a href="cluster.html#topic+pam">pam</a></code> function arguments.
</p>
</td></tr>
<tr><td><code>fn</code></td>
<td>

<p>the function implementing the specified setting. This <code>fn</code>
function can be executed on the data set.
It has two arguments: <code>data</code> and <code>only_params</code>.
<code>data</code> is a data matrix or data.frame
<code>only_params</code> is logical.
If <code>only_params==FALSE</code> (default), <code>fn</code> will return the
object returned by <code><a href="cluster.html#topic+pam">pam</a></code>.
If <code>only_params==TRUE</code> (default) <code>fn</code> will return only cluster 
parameters (proportions, mean, and cov, see <a href="#topic+clust2params">clust2params</a>.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coraggio, Luca, and Pietro Coretto (2023).
Selecting the Number of Clusters, Clustering Models, and Algorithms.
A Unifying Approach Based on the Quadratic Discriminant Score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), pp. 1-20,
<a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="cluster.html#topic+pam">pam</a></code>,<code><a href="#topic+mset_user">mset_user</a></code>, <code><a href="#topic+bqs">bqs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 'pam' settings combining number of clusters K={2,3}, and dissimilarities {euclidean, manhattan}
A &lt;- mset_pam(K = c(2,3), metric = c("euclidean", "manhattan"))
   
# select setup 1: K=2, metric = "euclidean"
m &lt;- A[[1]]
print(m)

      
# cluster with the method set in 'm'
data("banknote")
dat  &lt;- banknote[-1]
fit1 &lt;- m$fn(dat)   
fit1
class(fit1)


# if only cluster parameters are needed
fit1b &lt;- m$fn(dat, only_params = TRUE)   
fit1b

</code></pre>

<hr>
<h2 id='mset_user'>Generates Clustering Methods Settings for a Prototype Methodology
Provided by the User</h2><span id='topic+mset_user'></span>

<h3>Description</h3>

<p>The function generates a software abstraction of a list of clustering
models implemented through the a set of  tuned methods and algorithms.
The <em>base</em> clustering methodology is provided via a user-defined
function. The latter prototype is exapanded in a list  of fucntions
each  combining tuning parameters and other algorithmic settings. 
The generated functions are ready to be called on the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mset_user(fname, .packages = NULL, .export = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mset_user_+3A_fname">fname</code></td>
<td>

<p>a function implementing a user-defined clustering method. It clusters
a data set and outputs cluster parameters. <code>fname</code>
must fulfill certain requirements detailed below in the
<em>Details</em>. 
</p>
</td></tr>
<tr><td><code id="mset_user_+3A_.packages">.packages</code></td>
<td>

<p>character vector of packages that the tasks in <code>fname</code> depend
on (see <em>Details</em>).
</p>
</td></tr>
<tr><td><code id="mset_user_+3A_.export">.export</code></td>
<td>

<p>character vector of variables to export that are needed by
<code>fname</code> and that are not defined in the current environment
(see <em>Details</em>).
</p>
</td></tr>
<tr><td><code id="mset_user_+3A_...">...</code></td>
<td>

<p>parameters passed to <code>fname</code>. If a given parameter is included as
a vector/list each of its members is to obtain the final collection
of <code>fname</code> specifications (see <em>Details</em> and <em>Examples</em>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function produces functions implementing competing clustering methods
based on a <em>prototype</em> methodology implemented by the user via
the input argument  <code>fname</code>. 
In particular, it builds a list of <code>fname</code>-type  functions each
corresponding to a specific setup in terms of
hyper-parameters (<em>e.g.</em> the number of clusters) and algorithm's
control parameters (<em>e.g.</em>  initialization).
</p>
<p><strong>Requirements for <code>fname</code>.</strong> 
<code>fname</code> is a function implementing the base clustering method of
interest. It must have the following input argument

</p>

<ul>
<li> <p><code>data:</code>
a numeric vector, matrix, or data frame of observations. Rows
correspond to observations and columns correspond to
variables/features.
Categorical variables and <code>NA</code> values are not allowed.
</p>
</li></ul>


<p>Additionally, <code>fname</code> can have any other input parameter controlling
the underlying clustering model/method/algorithm. All this additional
parameters  are passed to <code>mset_user</code> via <code>...</code>
(see <em>Arguments</em>).
</p>
<p>The output of <code>fname</code> must contain a list named <code>params</code> 
with cluster parameters describing size, centrality and scatter. 
Let <code>P=</code><em>number of variable/features</em> and <code>K=</code><em>number of clusters</em>. 
The elements  of <code>params</code> are as follows:

</p>

<ul>
<li> <p><code>prop:</code> a vector of clusters' proportions; 
</p>
</li>
<li> <p><code>mean:</code> a matrix of dimension <code>(P x K)</code> containing the clusters' mean 
parameters;
</p>
</li>
<li> <p><code>cov:</code> an array of size <code>(P x P x K)</code> containing the clusters'
covariance matrices.
</p>
</li></ul>


<p>Note that <code>params</code> can be easily obtained from a vector of cluster labels
using <code><a href="#topic+clust2params">clust2params</a></code>.
</p>
<p><strong><code>packages</code> and <code>export</code>.</strong> The user does not
normally need to specify <code>packages</code> and <code>export</code>.
These arguments are not needed if the functions generated by <code>mset_user</code>
will  be called from an environment containing all variables and
functions needed to execute <code>fname</code>.
Functions like <code><a href="#topic+bqs">bqs</a></code> will call the functions 
by <code>mset_user</code> within a parallel infrastructure
using <code><a href="foreach.html#topic+foreach">foreach</a></code>. If the user specifies
<code>packages</code> and <code>export</code>, they will be passed to the 
<code>.packages</code> and <code>.export</code> arguments of 
<code><a href="foreach.html#topic+foreach">foreach</a></code>.  
</p>
<p>Finally, note that the package already contains specialized versions of <code>mset_user</code>
generating methods settings for some popular algorithms
(see <code><a href="#topic+mset_gmix">mset_gmix</a></code>,  <code><a href="#topic+mset_kmeans">mset_kmeans</a></code>, <code><a href="#topic+mset_pam">mset_pam</a></code>)
</p>


<h3>Value</h3>

<p>An S3 object of class <code>'qcmethod'</code>. Each element of the list
represents a competing method containing the following objects
</p>
<table role = "presentation">
<tr><td><code>fullname</code></td>
<td>

<p>a string identifying the setup.
</p>
</td></tr>
<tr><td><code>callargs</code></td>
<td>

<p>a list with arguments that are passed to the base function.
</p>
</td></tr>
<tr><td><code>fn</code></td>
<td>

<p>the function implementing the specified setting. This <code>fn</code>
function can be executed on the data set.
It has two arguments: <code>data</code> and <code>only_params</code>.
<code>data</code> is a data matrix or data.frame
<code>only_params</code> is logical.
If <code>only_params==FALSE</code> (default), <code>fn</code> will return the
object returned by the <code>fname</code>.
If <code>only_params==TRUE</code> (default) <code>fn</code> will return only cluster 
parameters (proportions, mean, and cov, see <a href="#topic+clust2params">clust2params</a>).
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coraggio, Luca, and Pietro Coretto (2023).
Selecting the Number of Clusters, Clustering Models, and Algorithms.
A Unifying Approach Based on the Quadratic Discriminant Score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), pp. 1-20,
<a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clust2params">clust2params</a></code>, <code><a href="#topic+mset_gmix">mset_gmix</a></code>,  <code><a href="#topic+mset_kmeans">mset_kmeans</a></code>, <code><a href="#topic+mset_pam">mset_pam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data("banknote")
dat  &lt;- banknote[-1]



# EXAMPLE 1: generate Hierarchical Clustering settings
# ----------------------------------------------------

# wrapper for the popular stats::hclust() for Hierarchical Clustering
# Note the usee:
#   of the optional arguments '...' passed to the underling clustering function
#   the use of 'clust2params' to add cluster parameters to the output 
hc_wrapper &lt;- function(data, K, ...){ 
    dm  &lt;- dist(data, method = "euclidean")
    ## ... = hc parameters 
    hc  &lt;- hclust(dm, ...)
    cl  &lt;- cutree(hc, k = K)
    ## output with params 
    res          &lt;- list()
    res$cluster  &lt;- cl
    res$params   &lt;- clust2params(data, cluster = cl)
    return(res)
}

# generate settings for Hierarchical Clustering with varying
# number of clusters K={3,4},  agglomeration method = {ward.D, median}
# see help('stats::hclust')
A &lt;- mset_user(fname="hc_wrapper", K = c(2,3), method = c("ward.D", "complete"))

# get the setting with K=2 and method = "complete"
ma &lt;- A[[4]]
ma

# cluster data with M[[3]]
fit_a1 &lt;- ma$fn(dat)
fit_a1

## if only cluster parameters are needed 
fit_a2 &lt;- ma$fn(dat, only_params = TRUE)
fit_a2


 
## Not run: 
# EXAMPLE 2: generate 'mclust' model settings 
# -------------------------------------------
# mclust is popular package for performing model based clustering based on
# Gaussian mixture. Please visit
# https://cran.r-project.org/web/packages/mclust/vignettes/mclust.html
require(mclust)

# wrapper for the popular stats::hclust() for Hierarchical Clustering
# Notes:
#  * optional arguments '...' are passed to the underling
#    'mclust' clustering function
#  * 'mclust' fits Gaussian Mixture models so cluster parameters are 
#     contained in the mclust object  
mc_wrapper &lt;- function(data, K, ...){
    y &lt;- Mclust(data, G = K, ...)
    y[["params"]] &lt;- list(proportion = y$parameters$pro,
                          mean = y$parameters$mean,
                          cov = y$parameters$variance$sigma)
    return(y)
    }

# generate 'mclust' model settings by varying the number of clusters and
# covariance matrix models (see help('mclust::mclustModelNames'))
B &lt;- mset_user(fname = "mc_wrapper", K = c(2,3), modelNames = c("EEI", "VVV"))

    
# get the setting with K=3 and covariance model "EEI"
mb &lt;- B[[2]]
mb

# cluster data with M[[3]]
fit_b &lt;- mb$fn(dat)
fit_b ## class(fit_b) = "Mclust"

   
# if needed one can make sure that 'mclust' package is always available
# by setting the argument 'packages'
B &lt;- mset_user(fname = "mc_wrapper", K = c(2,3), modelNames = c("EEI","VVV"),
               packages=c("mclust"))

## End(Not run)


## Not run: 
# EXAMPLE 3: generate 'dbscan' settings 
# -------------------------------------
# DBSCAN is popular nonparametric method for discovering clusters of
# arbitrary shapes with noise. The number of clusters is implicitly
# determined via two crucial tunings usually called 'eps' and 'minPts'
# See https://en.wikipedia.org/wiki/DBSCAN
require(dbscan)

# wrapper for dbscan::dbscan
db_wrap &lt;- function(data, ...) {
  cl &lt;- dbscan(data, borderPoints = TRUE, ...)$cluster
  return(params = clust2params(data, cl))
}

D  &lt;- mset_user(fname = "db_wrap", eps = c(0.5, 1), minPts=c(5,10))
md    &lt;- D[[2]]
fit_d &lt;- md$fn(dat)
fit_d
class(fit_d)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot_clustering'>Plot Data With Clustering Information</h2><span id='topic+plot_clustering'></span>

<h3>Description</h3>

<p>This function plots data and optionally adds clustering information such as clustering assignments, contours, or boundaries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_clustering(data,  subset = NULL,
                cluster = NULL, params = NULL,
                what = c("clustering", "contour", "boundary"),
                col_cl = NULL, pch_cl = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_clustering_+3A_data">data</code></td>
<td>

<p>a numeric vector, matrix, or data frame of observations. Rows correspond to observations and columns correspond to variables/features. Categorical variables and <code>NA</code> values are not allowed.
</p>
</td></tr>
<tr><td><code id="plot_clustering_+3A_subset">subset</code></td>
<td>

<p>A numeric vector indexing columns of <code>data</code> to subset and focus the plot on specific features. Default is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="plot_clustering_+3A_cluster">cluster</code></td>
<td>

<p>A vector of cluster assignments. If provided, the plot can display clustering information as specified in <code>what</code>. Must have the same number of observations as <code>data</code>
</p>
</td></tr>
<tr><td><code id="plot_clustering_+3A_params">params</code></td>
<td>

<p>A list of clustering parameters, including <code>proportion</code>, <code>mean</code>, and <code>cov</code>. If provided, the plot can display contour and boundary information.
</p>
</td></tr>
<tr><td><code id="plot_clustering_+3A_what">what</code></td>
<td>

<p>Character vector specifying which elements to plot. Options are <code>"clustering"</code>, <code>"contour"</code>, and <code>"boundary"</code>. Default is to plot <code>"clustering"</code> whenever <code>cluster</code> is not <code>NULL</code>, and <code>"contour"</code> and <code>"boundary"</code> whenever <code>params</code> is not <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="plot_clustering_+3A_col_cl">col_cl</code></td>
<td>

<p>A vector of colors to use for clusters (one for each cluster). Default is <code>NULL</code>, which uses a default sequence of colors.
</p>
</td></tr>
<tr><td><code id="plot_clustering_+3A_pch_cl">pch_cl</code></td>
<td>

<p>A vector of plotting symbols (one for each cluster) to use for clusters. Default is <code>NULL</code>, which uses a default sequence of symbols.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects</p>


<h3>See Also</h3>

<p><code><a href="#topic+bqs">bqs</a></code>, <code><a href="#topic+clust2params">clust2params</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example data
set.seed(123)
data &lt;- rbind(
            matrix(rnorm(100 * 2), ncol = 2),
            matrix(rnorm(100 * 2) + 2, ncol = 2)
        )
cluster &lt;- c(rep(1, 100), rep(2, 100))
params &lt;- clust2params(data, cluster)

# Plot with clustering information
plot_clustering(data, cluster = cluster, what = "clustering")

# Plot with subset of variables
plot_clustering(data, cluster = cluster, subset = 1, what = c("clustering", "contour"))

# Plot with customized colors and symbols
plot_clustering(data, cluster = cluster, params = params,
                col_cl = c("magenta", "orange"), pch_cl = c("A", "B"))
</code></pre>

<hr>
<h2 id='plot.bqs'>Plot (Bootstrap) Quadratic Score Results</h2><span id='topic+plot.bqs'></span>

<h3>Description</h3>

<p>Produce a plot of bqs (Bootstrap Quadratic Scores). This function creates plots based on the BQS (Bootstrap Quality Scores) data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bqs'
plot(x, score = NULL, perc_scale = FALSE, top = NULL, annotate = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.bqs_+3A_x">x</code></td>
<td>

<p>An S3 object of class <code>bqs</code> as returned by the <code>bqs</code> function. <code>x</code> is expected to have the component <code>rankby</code> set.
</p>
</td></tr>
<tr><td><code id="plot.bqs_+3A_score">score</code></td>
<td>

<p>Character vector specifying the score(s) to be plotted. Valid scores are <code>"hard"</code>, <code>"smooth"</code>, <code>"oob_hard"</code>, and <code>"oob_smooth"</code>. If <code>NULL</code> (default), all valid scores present in <code>x</code> are plotted.
</p>
</td></tr>
<tr><td><code id="plot.bqs_+3A_perc_scale">perc_scale</code></td>
<td>

<p>Logical; if <code>TRUE</code>, scales the plot using percentages, relative to the best score. Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="plot.bqs_+3A_top">top</code></td>
<td>

<p>Numeric; specifies the number of top models to individually highlight. Must be a single number less than or equal to the length of <code>x$methodset</code>. If <code>NULL</code> (default), <code>top</code> is automatically determined based on the <code>score</code> values.
</p>
</td></tr>
<tr><td><code id="plot.bqs_+3A_annotate">annotate</code></td>
<td>

<p>Logical; if <code>TRUE</code>, annotates the top models in the plot. Default is automatically determined (<code>TRUE</code> if the number of methods <code>M &lt;= 30</code>, <code>FALSE</code> otherwise).
</p>
</td></tr>
<tr><td><code id="plot.bqs_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot displaying the Bootstrap Quality Scores.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bqs">bqs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load data
data("banknote")
dat &lt;- banknote[-1]

# set up methods
mlist &lt;- mset_gmix(K=1:3, erc=c(1,100))

# perform bootstrap
# change B and ncores to a much larger value in real problems
res &lt;- bqs(dat, mlist, B = 3, type = "both", rankby="lq",
         ncores = 1, oob = TRUE, savescores = FALSE, saveparams = FALSE)

# Plot with default settings
plot(res)

# Plot in percentage scale relative to first model
plot(res, perc_scale = TRUE)

</code></pre>

<hr>
<h2 id='plot.mbcfit'>Plot Fitted Mixture Models</h2><span id='topic+plot.mbcfit'></span>

<h3>Description</h3>

<p>This function provides a plot method for objects of class <code>mbcfit</code>, returned as output by the <code>gmix</code> function. It serves as a wrapper around <code><a href="#topic+plot_clustering">plot_clustering</a></code>, allowing easy visualization of clustering results, including clustering assignments, contours, and boundaries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mbcfit'
plot(x, data = NULL, subset = NULL,
                      what = c("clustering", "contour"),
                      col_cl = NULL, pch_cl = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.mbcfit_+3A_x">x</code></td>
<td>

<p>An object of class <code>mbcfit</code>, typically a result of the <code>gmix</code> function.
</p>
</td></tr>
<tr><td><code id="plot.mbcfit_+3A_data">data</code></td>
<td>

<p><code>NULL</code> or a data matrix, data frame, or array containing data points to be plotted. See <em>Details</em>.
</p>
</td></tr>
<tr><td><code id="plot.mbcfit_+3A_subset">subset</code></td>
<td>

<p>A numeric vector indexing columns of <code>data</code> to subset and focus the plot on specific features. Default is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="plot.mbcfit_+3A_what">what</code></td>
<td>

<p>Character vector specifying which elements to plot. Options are <code>"clustering"</code>, <code>"contour"</code>, and <code>"boundary"</code>. Default is to plot <code>"clustering"</code> and <code>"boundary"</code>. See <em>Details</em>.
</p>
</td></tr>
<tr><td><code id="plot.mbcfit_+3A_col_cl">col_cl</code></td>
<td>

<p>A vector of colors to use for clusters (one for each cluster). Default is <code>NULL</code>, which uses a default sequence of colors.
</p>
</td></tr>
<tr><td><code id="plot.mbcfit_+3A_pch_cl">pch_cl</code></td>
<td>

<p>A vector of plotting symbols (one for each cluster) to use for clusters. Default is <code>NULL</code>, which uses a default sequence of symbols.
</p>
</td></tr>
<tr><td><code id="plot.mbcfit_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot.mbcfit</code> function provides a plotting method for objects of the class <code>mbcfit</code>. It acts as a wrapper around the <code><a href="#topic+plot_clustering">plot_clustering</a></code> function, allowing users to easily generate various plots to analyze the clustering results. A plot is produced only upon a successful <code>mbcfit</code> estimate, i.e., when <code>mbcfit</code> has <code>code</code> equal to either <code>1</code> or <code>2</code>.
</p>
<p>When <code>data</code> is <code>NULL</code> (the default), the function plots only contour sets (and optionally clustering boundaries) for the estimated mixture density components, using the <code>params</code> information from the <code>mbcfit</code> object. When <code>data</code> is not <code>NULL</code>, the function additionally plots data points and their hard clustering labels, which are obtained using <code>mbcfit</code> to predict the cluster labels (see <code><a href="#topic+predict.mbcfit">predict.mbcfit</a></code>).
</p>


<h3>Value</h3>

<p>A plot displaying the data with clustering information, contours, and/or boundaries, depending on the specified <code>what</code> argument.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gmix">gmix</a></code>, <code><a href="#topic+plot_clustering">plot_clustering</a></code>, <code>link{predict.mbcfit}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data("banknote")
dat &lt;- banknote[-1]

# fit 2 clusters
set.seed(123)
fit &lt;- gmix(dat, K = 2, init.nstart = 1)
print(fit)

# plot partition (default)
plot(x = fit, data = dat)


# plot partition onto the first 3 coordinates
plot(x = fit, data = dat, subset = c(1:3), pch_cl = c("A", "B"),
     col_cl = c("#4285F4", "#0F9D58"), what = "clustering")

# additionally plot clustering boundary and contour sets
plot(x = fit, data = dat, subset = c(1:3), pch_cl = c("A", "B"),
     col_cl = c("#4285F4", "#0F9D58"), what = c("clustering", "boundary", "contour"))

</code></pre>

<hr>
<h2 id='predict.mbcfit'>Predict Hard Clustering Assignments for using Mixture Models</h2><span id='topic+predict.mbcfit'></span>

<h3>Description</h3>

<p>This function predicts cluster assignments for new data based on an existing model of class <code>mbcfit</code>. The prediction leverages information from the fitted model to categorize new observations into clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mbcfit'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.mbcfit_+3A_object">object</code></td>
<td>

<p>An object of class <code>mbcfit</code>, representing the fitted mixture model. This is typically obtained in output from the <code>gmix</code> function. See <em>Details</em>.
</p>
</td></tr>
<tr><td><code id="predict.mbcfit_+3A_newdata">newdata</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Rows correspond to observations and columns correspond to variables/features. Categorical variables and <code>NA</code> values are not allowed. The number of columns must be coherent with that implied by <code>x</code>. See <em>Details</em>.
</p>
</td></tr>
<tr><td><code id="predict.mbcfit_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>predict.mbcfit</code> function utilizes the parameters of a previously fitted <code>mbcfit</code> model to allocate new data points to estimated clusters. The function performs necessary checks to ensure the <code>mbcfit</code> model returns valid estimates and the dimensionality of the new data aligns with the model.
</p>
<p>The <code>mbcfit</code> object must contain a component named <code>params</code>, which is itself a list containing the following necessary elements, for a mixture model with K components:
</p>

<dl>
<dt><code>proportions</code></dt><dd><p>A numeric vector of length K, with elements summing to 1, representing cluster proportions.</p>
</dd>
<dt><code>mean</code></dt><dd><p>A numeric matrix of dimensions <code>c(P, K)</code>, representing cluster centers.</p>
</dd>
<dt><code>cov</code></dt><dd><p>A numeric array of dimensions <code>c(P, P, K)</code>, representing cluster covariance matrices.</p>
</dd>
</dl>

<p>Data dimensionality is <code>P</code>, and new data dimensionality must match (<code>ncol(data)</code> must be equal to <code>P</code>) or otherwise the function terminates with an error message.
</p>
<p>The predicted clustering is obtained as the MAP estimator using posterior weights of a Gaussian mixture model parametrized at <code>params</code>.
Denoting with <code class="reqn">z(x)</code> the predicted cluster label for point <code class="reqn">x</code>, and with <code class="reqn">\phi</code> the (multivariate) Gaussian density:
</p>
<p style="text-align: center;"><code class="reqn">z(x) = \underset{k=\{1,\ldots,K\}}{\arg\,\max} \frac{\pi_k\phi(x, \mu_k, \Sigma_k)}{\sum_{j=1}^K \pi_j\phi(x, \mu_j, \Sigma_j)}</code>
</p>



<h3>Value</h3>

<p>A vector of length <code>nrow(data)</code> containing the estimated cluster labels for each observation in the provided <code>data</code>.
</p>


<h3>References</h3>

<p>Coraggio, Luca and Pietro Coretto (2023). Selecting the number of
clusters, clustering models, and algorithms. A unifying approach based
on the  quadratic discriminant score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), 1-20.
doi: <a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gmix">gmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data(banknote)
dat &lt;- banknote[,-1]

# Estimate 3-components gaussian mixture model
set.seed(123)
res &lt;- gmix(dat, K = 3)

# Cluster in output from gmix
print(res$cluster)

# Predict cluster on a single point
# (keep table dimension)
predict(res, dat[1, , drop=FALSE])

# Predict cluster on a subset
predict(res, dat[1:10, ])

# Predicted cluster on original dataset are equal to the clustering from the gmix model
all(predict(res, dat) == res$cluster)
</code></pre>

<hr>
<h2 id='print.bqs'>Display Information on Bootstrap Quadratic Scores Objects</h2><span id='topic+print.bqs'></span>

<h3>Description</h3>

<p>This function provides a print method for objects of class <code>bqs</code>, which are produced by the <code>bqs</code> function. It prints a summary of the bootstrapped quadratic score results for the clustering solutions considered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bqs'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.bqs_+3A_x">x</code></td>
<td>

<p>An object of class <code>bqs</code>, usually the output of the <code>bqs</code> function.
</p>
</td></tr>
<tr><td><code id="print.bqs_+3A_...">...</code></td>
<td>

<p>Additional arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print.bqs</code> function provides a print method for objects of class <code>bqs</code>.
</p>
<p>If clustering solutions in <code>bqs</code> are not ranked, the printing method displays a message to the user signalling it. Otherwise, the printing method shows a summary of the top-6 ranked solutions, in decreasing order, for any available scoring method (this is determined by the <code>oob</code> argument used in input to the <code>bqs</code> function. See Details in <code><a href="#topic+bqs">bqs</a></code>).
</p>
<p>The summary tables for ranked methods has <code>row.names</code> set to the method's codename, and shows the following information along the columns:
</p>

<dl>
<dt><code>id</code></dt><dd><p>Method's index in the <code>methodset</code> list (see Details in <code><a href="#topic+bqs">bqs</a></code>).</p>
</dd>
<dt><code>rank</code></dt><dd><p>Method's rank according to ranking criterion.</p>
</dd>
<dt><code>mean</code></dt><dd><p>Method's mean (bootstrap) quadratic score.</p>
</dd>
<dt><code>sterr</code></dt><dd><p>Method's standard error for the (bootstrap) quadratic score.</p>
</dd>
<dt><code>lower_qnt</code></dt><dd><p>(Only shown for &quot;mean&quot; and &quot;lq&quot; ranking) Method's lower <code>alpha/2</code>-level quantile of the bootstrap distribution of the quadratic score (<code>alpha</code> is given in input to <code>bqs</code> function).</p>
</dd>
<dt><code>upper_qnt</code></dt><dd><p>(Only shown for &quot;mean&quot; and &quot;lq&quot; ranking) Method's upper <code>alpha/2</code>-level quantile of the bootstrap distribution of the quadratic score (<code>alpha</code> is given in input to <code>bqs</code> function).</p>
</dd>
<dt><code>-1se</code></dt><dd><p>(Only shown for &quot;1se&quot; ranking) Method's mean (bootstrap) quadratic score minus 1 standard error.</p>
</dd>
<dt><code>-1se</code></dt><dd><p>(Only shown for &quot;1se&quot; ranking) Method's mean (bootstrap) quadratic score plus 1 standard error.</p>
</dd>
</dl>



<h3>Value</h3>

<p>No return value, called for side effects</p>


<h3>See Also</h3>

<p><code><a href="#topic+bqs">bqs</a></code>, <code><a href="#topic+bqs_rank">bqs_rank</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load data and set seet
set.seed(123)
data("banknote")
dat &lt;- banknote[-1]

# set up kmeans, see help('mset_kmeans')
KM    &lt;- mset_kmeans(K = 2:5)

# set up Gaussian model-based clustering via gmix()
GMIX  &lt;- mset_gmix(K=2:5, erc=c(1, 50 , 100))

# combine tuned methods
mlist &lt;- mbind(KM, GMIX)

# perform bootstrap
# se 'ncores' to the number of available physical cores
res &lt;- bqs(dat, mlist, B = 100, type = "both", rankby=NA, ncores = 1,
           oob = TRUE, savescores = TRUE, saveparams = FALSE)

# Methods are not ranked; only available components are shown
res

# Rank method and show summaries
ranked_res &lt;- bqs_rank(res, rankby = "lq", boot_na_share = 0.25)

ranked_res

</code></pre>

<hr>
<h2 id='print.mbcfit'>Display Information for Mixture Model Objects</h2><span id='topic+print.mbcfit'></span>

<h3>Description</h3>

<p>This function provides a print method for objects of class <code>mbcfit</code>, returned in output by the <code>gmix</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mbcfit'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.mbcfit_+3A_x">x</code></td>
<td>

<p>An object of class <code>mbcfit</code>, typically a result of the <code>gmix</code> function.
</p>
</td></tr>
<tr><td><code id="print.mbcfit_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print.mbcfit</code> function gives a summary of a model-based clustering fit, estimated using the <code>gmix</code> function.
</p>
<p>The function handles different <code>code</code> values from the object's <code>info</code> field, each representing a specific status or error condition:
</p>

<dl>
<dt><code>-2</code></dt><dd>
<p>'Lapack DSYEV failed'. This error occurs whenever any of the cluster-covariance matrices becomes singular during estimation, using the EM algorithm.
</p>
</dd>
<dt><code>-1</code></dt><dd>
<p>'Memory allocation error'. This error occurs when there is insufficient available memory to allocate the quantities required to execute the EM algorithm.
</p>
</dd>
<dt><code>1</code></dt><dd>
<p>Success.
</p>
</dd>
<dt><code>2</code></dt><dd>
<p>'gmix' did not converge (iterations reached the maximum limit).
</p>
</dd>
<dt><code>3</code></dt><dd>
<p>EM algorithm failed; no better than the initial solution. This error occurs whenever the EM algorithm failed for other reasons (e.g., degenerate posterior-weights could not be prevented), and it was not possible to find a solution.
</p>
</dd>
</dl>

<p>The printed output also lists available components of the <code>mbcfit</code> object and summarizes the number of clusters found and their size, whenever this information is available.
</p>


<h3>Value</h3>

<p>No return value, called for side effects</p>


<h3>See Also</h3>

<p><code><a href="#topic+gmix">gmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)

# Estimate a simple a 3-clusters Gaussian mixture model, using iris data as example
res &lt;- gmix(iris[,-5], K = 3, erc = 10)

# Print the 'gmix' output
print(res)
</code></pre>

<hr>
<h2 id='qscore'>Clustering Quadratic Score</h2><span id='topic+qscore'></span>

<h3>Description</h3>

<p>Computes both the hard and the smooth quadratic score of a clustering.
Handles both 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   qscore(data, params, type = "both")
   </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qscore_+3A_data">data</code></td>
<td>
<p>a numeric vector, matrix, or data frame of observations. 
Rows correspond to observations and columns correspond to variables/features. 
Let <code>N=nrows(data)</code> and <code>P=ncol(data)</code>. 
Categorical variables and <code>NA</code> values are not allowed.
</p>
</td></tr>
<tr><td><code id="qscore_+3A_params">params</code></td>
<td>

<p>a list containing  cluster parameters <em>(size, mean, cov)</em>. Let 
<code>K=</code><em>number of clusters</em>.
The elements  of the list are as follows: 
<code>$prop=</code>vector of clusters' proportions; 
<code>$mean=</code>matrix of dimension <code>(P x K)</code> containing the clusters' mean 
parameters;
<code>$cov=</code>array of size <code>(P x P x K)</code> containing the clusters'
covariance matrices.
</p>
</td></tr>
<tr><td><code id="qscore_+3A_type">type</code></td>
<td>
<p>the type of score, a character in the set 
<code>c("both", "smooth", "hard")</code>. The default value is set to
&quot;booth&quot;. See <em>Details</em>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates quadratic scores as defined in equation (22) in Coraggio
and Coretto (2023). 
</p>


<h3>Value</h3>

<p>A numeric vector with both the hard and the smooth score, or only one of them 
depending on the argument <code>type</code>.
</p>


<h3>References</h3>

<p>Coraggio, Luca and Pietro Coretto (2023). Selecting the number of
clusters, clustering models, and algorithms. A unifying approach based
on the  quadratic discriminant score.
<em>Journal of Multivariate Analysis</em>, Vol. 196(105181), 1-20.
DOI: <a href="https://doi.org/10.1016/j.jmva.2023.105181">doi:10.1016/j.jmva.2023.105181</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clust2params">clust2params</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># --- load and split data
data("banknote")
set.seed(345)
idx   &lt;- sample(1:nrow(banknote), size = 25, replace = FALSE)
dat_f &lt;- banknote[-idx, -1] ## training data set  
dat_v &lt;- banknote[ idx, -1] ## validation data set 


# --- Gaussian model-based clustering, K=3
# fit clusters 
fit1 &lt;- gmix(dat_f, K=3)
## compute quadratic scores using fitted mixture parameters
s1 &lt;- qscore(dat_v , params = fit1$params)
s1


# --- k-means clustering, K=3
# obtain the k-means partition 
cl_km &lt;- kmeans(dat_f, centers = 3, nstart = 1)$cluster
## convert k-means hard assignment into  cluster parameters 
par_km &lt;- clust2params(dat_f, cl_km)
# compute quadratic scores 
s2 &lt;- qscore(dat_v, params = par_km)
s2
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
