<!DOCTYPE html><html><head><title>Help for package bujar</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bujar}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bujar'><p> Buckley-James Regression</p></a></li>
<li><a href='#bujar-internal'><p>Internal bujar objects</p></a></li>
<li><a href='#chop'><p>Survival of CHOP for diffuse large B cell lymphoma</p></a></li>
<li><a href='#rchop'><p>Survival of R-CHOP for diffuse large B cell lymphoma</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Buckley-James Regression for Survival Data with High-Dimensional
Covariates</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2-11</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-06-23</td>
</tr>
<tr>
<td>Author:</td>
<td>Zhu Wang &lt;https://orcid.org/0000-0002-0773-0052&gt; and others (see COPYRIGHTS)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Zhu Wang &lt;zwang145@uthsc.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Buckley-James regression for right-censoring survival data with high-dimensional covariates. Implementations for survival data include boosting with componentwise linear least squares, componentwise smoothing splines, regression trees and MARS. Other high-dimensional tools include penalized regression for survival data. See Wang and Wang (2010) &lt;<a href="https://doi.org/10.2202%2F1544-6115.1550">doi:10.2202/1544-6115.1550</a>&gt;.</td>
</tr>
<tr>
<td>Imports:</td>
<td>mda, mpath, mboost, gbm, earth, elasticnet, rms, methods,
modeltools, bst, parallel, survival</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>TH.data, R.rsp, gridExtra</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-25 01:43:20 UTC; zhu</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-25 02:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bujar'> Buckley-James Regression </h2><span id='topic+bujar'></span><span id='topic+print.bujar'></span><span id='topic+plot.bujar'></span><span id='topic+coef.bujar'></span><span id='topic+predict.bujar'></span><span id='topic+summary.bujar'></span>

<h3>Description</h3>

<p>Buckley-James regression for right-censoring survival data with high-dimensional covariates. Including L_2 boosting with componentwise linear least squares, componentwise P-splines, regression trees. Other Buckley-James methods including elastic net, MCP, SCAD, MARS and ACOSSO (ACOSSO not supported for the current version). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bujar(y, cens, x, valdata = NULL, degree = 1, learner = "linear.regression",
center=TRUE, mimpu = NULL, iter.bj = 20, max.cycle = 5, nu = 0.1, mstop = 50, 
twin = FALSE, mstop2= 100, tuning = TRUE, cv = FALSE, nfold = 5, method = "corrected", 
vimpint = TRUE,gamma = 3, lambda=NULL, whichlambda=NULL, lamb = 0, s = 0.5, nk = 4, 
wt.pow = 1, theta = NULL, rel.inf = FALSE, tol = .Machine$double.eps, n.cores= 2, 
rng=123, trace = FALSE)
## S3 method for class 'bujar'
print(x, ...)
## S3 method for class 'bujar'
predict(object, newx=NULL, ...)
## S3 method for class 'bujar'
plot(x, ...)
## S3 method for class 'bujar'
coef(object, ...)
## S3 method for class 'bujar'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bujar_+3A_y">y</code></td>
<td>
<p> survival time</p>
</td></tr>
<tr><td><code id="bujar_+3A_cens">cens</code></td>
<td>
<p> censoring indicator, must be 0 or 1 with 0=alive, 1=dead</p>
</td></tr>
<tr><td><code id="bujar_+3A_x">x</code></td>
<td>
<p> covariate matrix</p>
</td></tr>
<tr><td><code id="bujar_+3A_object">object</code></td>
<td>
<p> an object of class <code>"bujar"</code></p>
</td></tr>
<tr><td><code id="bujar_+3A_newx">newx</code></td>
<td>
<p> covariate matrix for prediction</p>
</td></tr>
<tr><td><code id="bujar_+3A_valdata">valdata</code></td>
<td>
<p> test data, which must have the first column as survival time, second column as censoring indicator, and the remaining columns similar to same x.</p>
</td></tr>
<tr><td><code id="bujar_+3A_degree">degree</code></td>
<td>
<p> mars/tree/linear regression degree of interaction; if 2, second-order interaction,
if degree=1, additive model;</p>
</td></tr>
<tr><td><code id="bujar_+3A_learner">learner</code></td>
<td>
<p> methods used for BJ regression.</p>
</td></tr> 
<tr><td><code id="bujar_+3A_center">center</code></td>
<td>
<p> center covariates</p>
</td></tr>
<tr><td><code id="bujar_+3A_mimpu">mimpu</code></td>
<td>
<p> initial estimate. If TRUE, mean-imputation;
FALSE, imputed with the marginal best variable linear regression; if NULL, 0.</p>
</td></tr>
<tr><td><code id="bujar_+3A_iter.bj">iter.bj</code></td>
<td>
<p> number of B-J iteration</p>
</td></tr>
<tr><td><code id="bujar_+3A_max.cycle">max.cycle</code></td>
<td>
<p> max cycle allowed </p>
</td></tr>
<tr><td><code id="bujar_+3A_nu">nu</code></td>
<td>
<p> step-size boosting parameter</p>
</td></tr>
<tr><td><code id="bujar_+3A_mstop">mstop</code></td>
<td>
<p> boosting tuning parameters. It can be one number or have the length <code>iter.bj</code>+<code>max.cycle</code>. If <code>cv=TRUE</code>, then <code>mstop</code> is the maximum number of tuning parameter</p>
</td></tr>
<tr><td><code id="bujar_+3A_twin">twin</code></td>
<td>
<p> logical, if TRUE, twin boosting</p>
</td></tr>
<tr><td><code id="bujar_+3A_mstop2">mstop2</code></td>
<td>
<p> twin boosting tuning parameter</p>
</td></tr>
<tr><td><code id="bujar_+3A_tuning">tuning</code></td>
<td>
<p> logical value. if TRUE, the tuning parameter will be selected by cv or AIC/BIC methods. Ignored if <code>twin=TRUE</code> for which no tuning parameter selection is implemented </p>
</td></tr>
<tr><td><code id="bujar_+3A_cv">cv</code></td>
<td>
<p> logical value. if TRUE, cross-validation for tuning parameter, only used if <code>tuning=TRUE</code>. If <code>tuning=FALSE</code> or <code>twin=TRUE</code>, then ignored</p>
</td></tr>
<tr><td><code id="bujar_+3A_nfold">nfold</code></td>
<td>
<p> number of fold of cv</p>
</td></tr>
<tr><td><code id="bujar_+3A_method">method</code></td>
<td>
<p> boosting tuning parameter selection method in AIC</p>
</td></tr>
<tr><td><code id="bujar_+3A_vimpint">vimpint</code></td>
<td>
<p> logical value. If TRUE, compute variable importance and interaction measures for MARS if <code>learner="mars"</code> and <code>degree</code> &gt; 1. </p>
</td></tr>
<tr><td><code id="bujar_+3A_gamma">gamma</code></td>
<td>
<p> MCP, or SCAD gamma tuning parameter</p>
</td></tr>
<tr><td><code id="bujar_+3A_lambda">lambda</code></td>
<td>
<p> MCP, or SCAD lambda tuning parameter</p>
</td></tr>
<tr><td><code id="bujar_+3A_whichlambda">whichlambda</code></td>
<td>
<p> which lambda used for MCP or SCAD lambda tuning parameter </p>
</td></tr>
<tr><td><code id="bujar_+3A_lamb">lamb</code></td>
<td>
<p> elastic net lambda tuning parameter, only used if <code>learner="enet"</code></p>
</td></tr>
<tr><td><code id="bujar_+3A_s">s</code></td>
<td>
<p> the second enet tuning parameter, which is a fraction between (0, 1), only used if <code>learne="enet"</code></p>
</td></tr>
<tr><td><code id="bujar_+3A_nk">nk</code></td>
<td>
<p> number of basis function for <code>learner="mars"</code></p>
</td></tr>
<tr><td><code id="bujar_+3A_wt.pow">wt.pow</code></td>
<td>
<p> not used but kept for historical reasons, only for <code>learner=ACOSSO</code>. This is a parameter (power of weight). It might be chosen by CV from c(0, 1.0, 1.5, 2.0, 2.5, 3.0). If wt.pow=0, then this is COSSO method</p>
</td></tr> 
<tr><td><code id="bujar_+3A_theta">theta</code></td>
<td>
<p> For <code>learner="acosso"</code>, not used now. A numerical vector with 0 or 1. 0 means the variable not included and 1 means included. See Storlie et al. (2009).</p>
</td></tr>
<tr><td><code id="bujar_+3A_rel.inf">rel.inf</code></td>
<td>
<p> logical value. if TRUE, variable importance measure and interaction importance measure computed</p>
</td></tr>
<tr><td><code id="bujar_+3A_tol">tol</code></td>
<td>
<p> convergency criteria </p>
</td></tr>
<tr><td><code id="bujar_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. The cross-validation loop
will attempt to send different CV folds off to different cores. Used for <code>learner="tree"</code></p>
</td></tr> 
<tr><td><code id="bujar_+3A_rng">rng</code></td>
<td>
<p> a number to be used for random number generation in boosting trees </p>
</td></tr>
<tr><td><code id="bujar_+3A_trace">trace</code></td>
<td>
<p> logical value. If TRUE, print out interim computing results</p>
</td></tr>
<tr><td><code id="bujar_+3A_...">...</code></td>
<td>
<p> additional arguments used in estimation methods, for instance, trees. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Buckley-James regression for right-censoring survival data with high-dimensional covariates. Including L_2 boosting with componentwise linear least squares, componentwise P-splines, regression trees. Other Buckley-James methods including elastic net, SCAD and MCP. <code>learner="enet"</code> and <code>learner="enet2"</code> use two different implementations of LASSO. Some of these methods are discussed in Wang and Wang (2010) and the references therein. Also see the references below.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p> original covariates</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p> survival time</p>
</td></tr>
<tr><td><code>cens</code></td>
<td>
<p> censoring indicator</p>
</td></tr>
<tr><td><code>ynew</code></td>
<td>
<p> imputed y</p>
</td></tr>
<tr><td><code>yhat</code></td>
<td>
<p> estimated y from ynew</p>
</td></tr>
<tr><td><code>pred.bj</code></td>
<td>
<p> estimated y from the testing sample</p>
</td></tr>
<tr><td><code>res.fit</code></td>
<td>
<p> model fitted with the learner</p>
</td></tr>
<tr><td><code>learner</code></td>
<td>
<p> original learner used</p>
</td></tr>
<tr><td><code>degree</code></td>
<td>
<p> =1, additive model, degree=2, second-order interaction</p>
</td></tr>
<tr><td><code>mse</code></td>
<td>
<p> MSE at each BJ iteration, only available in simulations, or when valdata provided</p>
</td></tr>
<tr><td><code>mse.bj</code></td>
<td>
<p> MSE from training data at the BJ termination</p>
</td></tr>
<tr><td><code>mse.bj.val</code></td>
<td>
<p>MSE with valdata</p>
</td></tr>
<tr><td><code>mse.all</code></td>
<td>
<p> a vector of MSE for uncensoring data at BJ iteration</p>
</td></tr>
<tr><td><code>nz.bj.iter</code></td>
<td>
<p> number of selected covariates at each BJ iteration</p>
</td></tr>
<tr><td><code>nz.bj</code></td>
<td>
<p> number of selected covariates at the claimed BJ termination</p>
</td></tr>
<tr><td><code>xselect</code></td>
<td>
<p> a vector of dimension of covariates, either 1 (covariate selected) or 0 (not selected)</p>
</td></tr>
<tr><td><code>coef.bj</code></td>
<td>
<p> estimated coefficients with linear model</p>
</td></tr>
<tr><td><code>vim</code></td>
<td>
<p> a vector of length of number of column of x, variable importance, between 0 to 100</p>
</td></tr>
<tr><td><code>interactions</code></td>
<td>
<p> measure of strength of interactions</p>
</td></tr>
<tr><td><code>ybstdiff</code></td>
<td>
<p> largest absolute difference of estimated y. Useful to monitor convergency</p>
</td></tr>
<tr><td><code>ybstcon</code></td>
<td>
<p> a vector with length of BJ iteration each is a convergency measure</p>
</td></tr> 
<tr><td><code>cycleperiod</code></td>
<td>
<p> number of cycle of BJ iteration</p>
</td></tr>
<tr><td><code>cycle.coef.diff</code></td>
<td>
<p> within cycle of BJ, the maximum difference of coefficients for BJ boosting</p>
</td></tr>
<tr><td><code>nonconv</code></td>
<td>
<p> logical value. if TRUE, non-convergency</p>
</td></tr>
<tr><td><code>fnorm2</code></td>
<td>
<p> value of L_2 norm, can be useful to access convergency</p>
</td></tr>
<tr><td><code>mselect</code></td>
<td>
<p> a vector of length of BJ iteration, each element is the tuning parameter mstop</p>
</td></tr>
<tr><td><code>contype</code></td>
<td>
<p> 0 (converged), 1, not converged but cycle found, 2, not converged and max iteration reached.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Zhu Wang </p>


<h3>References</h3>

 
<p>Zhu Wang and C.Y. Wang (2010),
Buckley-James Boosting for Survival Analysis with High-Dimensional
Biomarker Data.
<em>Statistical Applications in Genetics and Molecular Biology</em>,
Vol. 9 : Iss. 1, Article 24.
</p>
<p>Peter Buhlmann and Bin Yu (2003),
Boosting with the L2 loss: regression and classification.
<em>Journal of the American Statistical Association</em>, <b>98</b>,
324&ndash;339.
</p>
<p>Peter Buhlmann (2006), Boosting for high-dimensional linear models.
<em>The Annals of Statistics</em>, <b>34</b>(2), 559&ndash;583.
</p>
<p>Peter Buhlmann and Torsten Hothorn (2007),
Boosting algorithms: regularization, prediction and model fitting.
<em>Statistical Science</em>, <b>22</b>(4), 477&ndash;505.
</p>
<p>J. Friedman (1991), Multivariate Adaptive Regression Splines (with
discussion) .
<em>Annals of Statistics</em>, <b>19</b>/1, 1&ndash;141.
</p>
<p>J.H. Friedman, T. Hastie and R. Tibshirani (2000), Additive Logistic Regression:
a Statistical View of Boosting. <em>Annals of Statistics</em> <b>28</b>(2):337-374.
</p>
<p>C. Storlie, H. Bondell, B. Reich and H. H. Zhang (2009),
Surface Estimation, Variable Selection, and the Nonparametric Oracle
Property.
<em>Statistica Sinica</em>, to appear.
</p>
<p>Sijian Wang, Bin Nan, Ji Zhu, and David G. Beer (2008),
Doubly penalized Buckley-James Method for Survival Data with High-Dimensional
Covariates.
<em>Biometrics</em>,
<b>64</b>:132-140.
</p>
<p>H. Zou and T. Hastie (2005), Regularization and variable selection via the elastic net.
<em>Journal of the Royal Statistical Society</em>, Series B, <b>67</b>, 301-320.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wpbc", package = "TH.data")
wpbc2 &lt;- wpbc[, 1:12]
wpbc2$status &lt;- as.numeric(wpbc2$status) - 1
fit &lt;- bujar(y=log(wpbc2$time),cens=wpbc2$status, x= wpbc2[, -(1:2)])
print(fit)
coef(fit)
pr &lt;- predict(fit)
plot(fit)
fit &lt;- bujar(y=log(wpbc2$time),cens=wpbc2$status, x= wpbc2[, -(1:2)], tuning = TRUE)
## Not run: 
fit &lt;- bujar(y=log(wpbc2$time),cens=wpbc2$status, x=wpbc2[, -(1:2)], learner="pspline")
fit &lt;- bujar(y=log(wpbc2$time),cens=wpbc2$status, x=wpbc2[, -(1:2)], 
 learner="tree", degree=2)
### select tuning parameter for "enet"
tmp &lt;- gcv.enet(y=log(wpbc2$time), cens=wpbc2$status, x=wpbc2[, -(1:2)])
fit &lt;- bujar(y=log(wpbc2$time),cens=wpbc2$status, x=wpbc2[, -(1:2)], learner="enet", 
lamb = tmp$lambda, s=tmp$s)

fit &lt;- bujar(y=log(wpbc2$time),cens=wpbc2$status, x=wpbc2[, -(1:2)], learner="mars", 
degree=2)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='bujar-internal'>Internal bujar objects</h2><span id='topic+bjboost.fit'></span><span id='topic+gcv.enet'></span><span id='topic+import.inter'></span><span id='topic+partialPlot'></span><span id='topic+vimpint'></span><span id='topic+cvmboost'></span><span id='topic+nxselect'></span><span id='topic+vim.interactions'></span><span id='topic+diff.quot'></span><span id='topic+rif'></span><span id='topic+bstfit'></span><span id='topic+predval'></span><span id='topic+convCheck'></span><span id='topic+.required'></span>

<h3>Description</h3>

<p>Internal bujar objects.</p>


<h3>Details</h3>

<p>These are not to be called by the user.</p>

<hr>
<h2 id='chop'>Survival of CHOP for diffuse large B cell lymphoma</h2><span id='topic+chop'></span>

<h3>Description</h3>

<p>Microarray data for DLBCL patients undergoing CHOP treatment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chop)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:181, 1:3835] 
</p>


<h3>Details</h3>

<p>Microarray data of DLBCL of 181 patients treated with a combination chemotherapy with cyclophosphamide, doxorubicin, vincristine
and prednisone (CHOP). The original data have 54675 probe sets or covariates. Due to the nature of high-dimensional data, a preselection procedure was conducted to filter out the genes with lower variations if a sample variance for a gene was smaller than the 10th percentile for that gene.
The first column if the survival times. The second column is an indicator whether an the survival time was observed or right censoring occurred. 0=alive, 1=dead. There are 3833 genes after the filtering process. 
</p>


<h3>Source</h3>

<p>Lenz, et al. (2008). Stromal gene signatures in large-B-cell lymphomas. <em>New England Journal of Medicine</em>,
<b>359(22)</b>, 2313&ndash;2323
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chop)
str(chop)
</code></pre>

<hr>
<h2 id='rchop'>Survival of R-CHOP for diffuse large B cell lymphoma</h2><span id='topic+rchop'></span>

<h3>Description</h3>

<p>Microarray data for DLBCL patients undergoing R-CHOP treatment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rchop)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:233, 1:3835] 
</p>


<h3>Details</h3>

<p>Microarray data of DLBCL of 233 patients treated with the current gold standard R-CHOP including rituxima immunotherapy in addition to the chemotherapy CHOP.  The original data have 54675 probe sets or covariates. Due to the nature of high-dimensional data, a preselection procedure was conducted to filter out the genes to match those in <code>chop</code>.
The first column if the survival times. The second column is an indicator whether an the survival time was observed or right censoring occurred. 0=alive, 1=dead. There are 3833 same genes as in <code>chop</code>. The data set is used to validate the prediction accuracy for models developed using training data <code>chop</code>. 
</p>


<h3>Source</h3>

<p>Lenz, et al. (2008). Stromal gene signatures in large-B-cell lymphomas. <em>New England Journal of Medicine</em>,
<b>359(22)</b>, 2313&ndash;2323
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rchop)
str(rchop)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
