<!DOCTYPE html><html><head><title>Help for package mistral</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mistral}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mistral-package'><p>Methods In Structural Reliability Analysis</p></a></li>
<li><a href='#AKMCS'><p>Active learning reliability method combining Kriging and Monte Carlo</p>
Simulation</a></li>
<li><a href='#BMP'><p>Bayesian Moving Particles</p></a></li>
<li><a href='#cantilever'><p>A function calculating the deviation of a cantilever beam.</p></a></li>
<li><a href='#ComputeDistributionParameter'><p>Compute internal parameters and moments for univariate distribution functions</p></a></li>
<li><a href='#estimateSUR'><p>EstimateSUR</p></a></li>
<li><a href='#FORM'><p>First-order reliability method</p></a></li>
<li><a href='#FORMv0'><p>FORM method (old version)</p></a></li>
<li><a href='#generateK'><p>Generate Standard Gaussian samples with a Gaussian transiiton kernel</p></a></li>
<li><a href='#IRW'><p>Increasing Randow Walk</p></a></li>
<li><a href='#kiureghian'><p>A limit-state-function defined by Der Kiureghian</p></a></li>
<li><a href='#LSVM'><p>Linear Support Vector Machine under monotonicity constraints</p></a></li>
<li><a href='#MetaIS'><p>Metamodel based Impotance Sampling</p></a></li>
<li><a href='#MetropolisHastings'><p>The modified Metropolis-Hastings algorithm</p></a></li>
<li><a href='#modelLSVM'><p>Estimation of the parameters of the LSVM</p></a></li>
<li><a href='#ModifCorrMatrix'><p>Modification of a correlation matrix to use in UtoX</p></a></li>
<li><a href='#MonotonicQuantileEstimation'><p>Quantile estimation under monotonicity constraints</p></a></li>
<li><a href='#MonteCarlo'><p>Crude Monte Carlo method</p></a></li>
<li><a href='#MP'><p>Moving Particles</p></a></li>
<li><a href='#ok'><p>Class of Ordinary Kriging</p></a></li>
<li><a href='#oscillator_d6'><p>A limit-state-function defined with a non-linear oscillator in dimension 6.</p></a></li>
<li><a href='#plotLSVM'><p>plot of LSVM</p></a></li>
<li><a href='#precomputeUpdateData'><p>precomputeUpdateData</p></a></li>
<li><a href='#quantileWilks'><p>Computing quantiles with the Wilks formula</p></a></li>
<li><a href='#rackwitz'><p>A limit-state-function defined by Rackwitz</p></a></li>
<li><a href='#S2MART'><p>Subset by Support vector Margin Algorithm for Reliability esTimation</p></a></li>
<li><a href='#SMART'><p>Support-vector Margin Algoritm for Reliability esTimation</p></a></li>
<li><a href='#SubsetSimulation'><p>Subset Simulation Monte Carlo</p></a></li>
<li><a href='#testConvexity'><p>Test the convexity of set of data</p></a></li>
<li><a href='#twodof'><p>A limit-state-function defined with a two degrees of freedom damped oscillator</p></a></li>
<li><a href='#updateLSVM'><p>Update LSVM classifier</p></a></li>
<li><a href='#updateSd'><p>UpdateSd</p></a></li>
<li><a href='#updateSd.old'><p>UpdateSd.old</p></a></li>
<li><a href='#UtoX'><p>Iso-probabilistic transformation from U space to X space</p></a></li>
<li><a href='#waarts'><p>A limit-state-function defined by Waarts</p></a></li>
<li><a href='#WilksFormula'><p>Sample size by Wilks formula</p></a></li>
<li><a href='#XtoU'><p>From X to standard space</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.2.2</td>
</tr>
<tr>
<td>Title:</td>
<td>Methods in Structural Reliability</td>
</tr>
<tr>
<td>Author:</td>
<td>Clement Walter, Gilles Defaux, Bertrand Iooss, Vincent Moutoussamy with contributions from Nicolas Bousquet, Claire Cannamela and Paul Lemaitre</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Bertrand Iooss &lt;biooss@yahoo.fr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>e1071, Matrix, mvtnorm, ggplot2, doParallel, foreach,
iterators, DiceKriging, quadprog, Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>microbenchmark, deSolve, scatterplot3d, KrigInv, rgenoud,
kernlab, knitr, rmarkdown, markdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Description:</td>
<td>Various reliability analysis methods for rare event inference (computing failure probability and quantile from model/function outputs).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-17 13:05:09 UTC; F80570</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-17 13:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mistral-package'>Methods In Structural Reliability Analysis</h2><span id='topic+mistral-package'></span><span id='topic+mistral'></span>

<h3>Description</h3>

<p>Provide tools for structural reliability analysis (failure probability and quantile of model/function outputs).</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
   Package: </td><td style="text-align: left;"> mistral</td>
</tr>
<tr>
 <td style="text-align: left;">
   Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
   License: </td><td style="text-align: left;"> GPL-2
  </td>
</tr>

</table>

<p>This package provides tools for structural reliability analysis:
</p>

<ul>
<li><p> Calculate failure probability with FORM method and importance sampling.
</p>
</li>
<li><p> Calculate failure probability with crude Monte Carlo method
</p>
</li>
<li><p> Calculate failure probability with Subset Simulation algorithm
</p>
</li>
<li><p> Calculate failure probability with metamodel based algorithms : AKMCS, SMART and MetaIS
</p>
</li>
<li><p> Calculate failure probability with a metamodel based Subset Simulation : S2MART
</p>
</li>
<li><p> Wilks formula: Compute a quantile (or tolerance interval) with a given confidence level from a i.i.d. sample,
</p>
</li>
<li><p> Wilks formula: Compute the minimal sample size to estimate a quantile with a given confidence level,
</p>
</li>
<li><p> Calculate a quantile under monotonicity constraints
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Clement Walter, Gilles Defaux, Bertrand Iooss, Vincent Moutoussamy, with contributions from Nicolas Bousquet, Claire Cannamela and Paul Lemaitre
(maintainer: Bertrand Iooss <a href="mailto:biooss@yahoo.fr">biooss@yahoo.fr</a>)</p>


<h3>References</h3>

<p>S.-K. Au, J. L. Beck. Estimation of small failure probabilities in high dimensions by Subset Simulation. Probabilistic Engineering Mechanics, 2001
</p>
<p>J.-M. Bourinet, F. Deheeger, M. Lemaire. Assessing small failure probabilities by combined Subset Simulation and Support Vector Machines. Structural Safety, 2011
</p>
<p>N. Bousquet. Accelerated monte carlo estimation of exceedance probabilities under monotonicity constraints. Annales de la Faculte des Sciences de Toulouse. XXI(3), 557-592, 2012
</p>
<p>H.A. David and H.N. Nagaraja. Order statistics, Wiley, 2003
</p>
<p>F. Deheeger. Couplage mecano-fiabiliste : 2SMART - methodologie d'apprentissage stochastique en fiabilite. PhD. Thesis, Universite Blaise Pascal - Clermont II, 2008
</p>
<p>A. Der Kiureghian, T. Dakessian. Multiple design points in first and second-order reliability. Structural Safety, vol.20, 1998
</p>
<p>O. Ditlevsen and H.O. Madsen. Structural reliability methods, Wiley, 1996
</p>
<p>V. Dubourg. Meta-modeles adaptatifs pour l'analyse de fiabilite et l'optimisation sous containte fiabiliste. PhD. Thesis, Universite Blaise Pascal - Clermont II, 2011
</p>
<p>B. Echard, N. Gayton, M. Lemaire. AK-MCS : an Active learning reliability method combining Kriging and Monte Carlo Simulation
</p>
<p>M. Lemaire, A. Chateauneuf and J. Mitteau. Structural reliability, Wiley Online Library, 2009
</p>
<p>J. Morio and M. Balesdent. Estimation of rare event probabilities in complex aerospace and other systems. Woodhead Publishing, 2016
</p>
<p>V. Moutoussamy. Contributions to structural reliability analysis: accounting for monotonicity constraints in numerical models, PhD Thesis of Universite de Toulouse, France, 2015
</p>
<p>W.T. Nutt and G.B. Wallis. Evaluation of nuclear safety from the outputs of computer codes in the presence of uncertainties. Reliability Engineering and System Safety, 83:57-77, 2004
</p>
<p>P.-H. Waarts. Structural reliability using finite element methods: an appraisal of DARS, Directional Adaptive Response Surface Sampling. PhD. Thesis, Technical University of Delft, The Netherlands, 2000
</p>
<p>C. Walter. Using Poisson processes for rare event simulation, PhD Thesis of Universite Paris Diderot, France, 2016
</p>
<p>S.S. Wilks. Determination of Sample Sizes for Setting Tolerance Limits. Annals Mathematical Statistics, 12:91-96, 1941
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########## FORM ########### 
# u.dep is a starting point for the research of the Most Probable Failing Point
# N.calls is a total number of calls
form &lt;- mistral::FORM(dimension = 2, mistral::kiureghian, N.calls = 1000,
                    u.dep = c(0,0))
form$p

# use IS=TRUE to use an Importance Sampling scheme with a Gaussian standard
# proposal distribution centred at the MPFP
form.IS &lt;- mistral::FORM(dimension = 2, mistral::kiureghian, N.calls = 1000,
                       u.dep = c(0,0),
                       IS = TRUE)
form.IS$p

########### Wilks ##########

N &lt;- WilksFormula(0.95,0.95,order=1)
print(N)
</code></pre>

<hr>
<h2 id='AKMCS'>Active learning reliability method combining Kriging and Monte Carlo
Simulation</h2><span id='topic+AKMCS'></span>

<h3>Description</h3>

<p>Estimate a failure probability with the AKMCS method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AKMCS(
  dimension,
  lsf,
  N = 5e+05,
  N1 = 10 * dimension,
  Nmax = 200,
  Nmin = 2,
  X = NULL,
  y = NULL,
  failure = 0,
  precision = 0.05,
  bayesian = TRUE,
  compute.PPP = FALSE,
  meta_model = NULL,
  kernel = "matern5_2",
  learn_each_train = TRUE,
  crit_min = 2,
  lower.tail = TRUE,
  limit_fun_MH = NULL,
  failure_MH = 0,
  sampling_strategy = "MH",
  first_DOE = "Gaussian",
  seeds = NULL,
  seeds_eval = limit_fun_MH(seeds),
  burnin = 30,
  plot = FALSE,
  limited_plot = FALSE,
  add = FALSE,
  output_dir = NULL,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AKMCS_+3A_dimension">dimension</code></td>
<td>
<p>dimension of the input space.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_lsf">lsf</code></td>
<td>
<p>the function defining the failure/safety domain.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_n">N</code></td>
<td>
<p>Monte-Carlo population size.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_n1">N1</code></td>
<td>
<p>size of the first DOE.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_nmax">Nmax</code></td>
<td>
<p>maximum number of calls to the LSF.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_nmin">Nmin</code></td>
<td>
<p>minimum number of calls during enrichment step.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_x">X</code></td>
<td>
<p>coordinates of already known points.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_y">y</code></td>
<td>
<p>value of the LSF on these points.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_failure">failure</code></td>
<td>
<p>failure threshold.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_precision">precision</code></td>
<td>
<p>maximum desired cov on the Monte-Carlo estimate.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_bayesian">bayesian</code></td>
<td>
<p>estimate the conditional expectation E_X [ P[meta(X)&lt;failure] ].</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_compute.ppp">compute.PPP</code></td>
<td>
<p>to simulate a Poisson process at each iteration to estimate
the conditional expectation and the SUR criteria based on the conditional
variance: h (average probability of misclassification at level <code>failure</code>)
and I (integral of h over the whole interval [failure, infty))</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_meta_model">meta_model</code></td>
<td>
<p>provide here a kriging metamodel from km if wanted.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_kernel">kernel</code></td>
<td>
<p>specify the kernel to use for km.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_learn_each_train">learn_each_train</code></td>
<td>
<p>specify if kernel parameters are re-estimated at each train.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_crit_min">crit_min</code></td>
<td>
<p>minimum value of the criteria to be used for refinement.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_lower.tail">lower.tail</code></td>
<td>
<p>as for pxxxx functions, TRUE for estimating P(lsf(X) &lt; failure), FALSE
for P(lsf(X) &gt; failure)</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_limit_fun_mh">limit_fun_MH</code></td>
<td>
<p>define an area of exclusion with a limit function.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_failure_mh">failure_MH</code></td>
<td>
<p>the theshold for the limit_fun_MH function.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_sampling_strategy">sampling_strategy</code></td>
<td>
<p>either MH for Metropolis-Hastings of AR for accept-reject.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_first_doe">first_DOE</code></td>
<td>
<p>either Gaussian or Uniform, to specify the population on which
clustering is done. Set to &quot;No&quot; for no initial DoE (use together with a first DoE
given in <code>X</code> for instance).</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_seeds">seeds</code></td>
<td>
<p>if some points are already known to be in the appropriate subdomain.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_seeds_eval">seeds_eval</code></td>
<td>
<p>value of the metamodel on these points.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_burnin">burnin</code></td>
<td>
<p>burnin parameter for MH.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_plot">plot</code></td>
<td>
<p>set to TRUE for a full plot, ie refresh at each iteration.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_limited_plot">limited_plot</code></td>
<td>
<p>set to TRUE for a final plot with final DOE, metamodel and LSF.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_add">add</code></td>
<td>
<p>if plots are to be added to a current device.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_output_dir">output_dir</code></td>
<td>
<p>if plots are to be saved in jpeg in a given directory.</p>
</td></tr>
<tr><td><code id="AKMCS_+3A_verbose">verbose</code></td>
<td>
<p>either 0 for almost no output, 1 for medium size output and 2 for all
outputs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AKMCS strategy is based on a original Monte-Carlo population which
is classified
with a kriging-based metamodel. This means that no sampling is done during
refinements
steps. Indeed, it tries to classify this Monte-Carlo population with a
confidence greater
than a given value, for instance &lsquo;distance&rsquo; to the failure should be
greater than
<code>crit_min</code> standard deviation.
</p>
<p>Thus, while this criterion is not verified, the point minimizing it is added to
the learning database and then evaluated.
</p>
<p>Finally, once all points are classified or when the maximum number of calls
has been reached, crude Monte-Carlo is performed. A final test controlling
the size of this population regarding the targeted coefficient of variation
is done; if it is too small then a new population of sufficient size
(considering ordre of magnitude of found probability) is generated, and
algorithm run again.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the failure probability and some
more outputs as described below:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>the estimated failure probability.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>the coefficient of variation of the Monte-Carlo probability estimate.</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>the total number of calls to the <code>lsf</code>.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the final learning database, ie. all points where <code>lsf</code> has
been calculated.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the value of the <code>lsf</code> on the learning database.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>the sequence of the estimated relative SUR criteria.</p>
</td></tr>
<tr><td><code>I</code></td>
<td>
<p>the sequence of the estimated integrated SUR criteria.</p>
</td></tr>
<tr><td><code>meta_fun</code></td>
<td>
<p>the metamodel approximation of the <code>lsf</code>. A call output is a
list containing the value and the standard deviation.</p>
</td></tr>
<tr><td><code>meta_model</code></td>
<td>
<p>the final metamodel. An S4 object from <span class="pkg">DiceKriging</span>. Note
that the algorithm enforces the problem to be the estimation of P[lsf(X)&lt;failure]
and so using &lsquo;predict&rsquo; with this object will return inverse values if
<code>lower.tail==FALSE</code>; in this scope prefer using directly <code>meta_fun</code> which
handles this possible issue.</p>
</td></tr>
<tr><td><code>points</code></td>
<td>
<p>points in the failure domain according to the metamodel.</p>
</td></tr>
<tr><td><code>meta_eval</code></td>
<td>
<p>evaluation of the metamodel on these points.</p>
</td></tr>
<tr><td><code>z_meta</code></td>
<td>
<p>if <code>plot</code>==TRUE, the evaluation of the metamodel on the plot grid.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Problem is supposed to be defined in the standard space. If not,
use <code><a href="#topic+UtoX">UtoX</a></code> to do so. Furthermore, each time a set of vector
is defined as a matrix, &lsquo;nrow&rsquo; = <code>dimension</code> and
&lsquo;ncol&rsquo; = number of vector to be consistent with <code>as.matrix</code>
transformation of a vector.
</p>
<p>Algorithm calls lsf(X) (where X is a matrix as defined previously) and
expects a vector in return. This allows the user to optimise the computation
of a batch of points, either by vectorial computation, or by the use of
external codes (optimised C or C++ codes for example) and/or parallel
computation; see examples in <a href="#topic+MonteCarlo">MonteCarlo</a>.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>B. Echard, N. Gayton, M. Lemaire:<br />
<em>AK-MCS : an Active learning reliability method combining Kriging and
Monte Carlo Simulation</em><br />
Structural Safety, Elsevier, 2011.<br />
</p>
</li>
<li>
<p>B. Echard, N. Gayton, M. Lemaire and N. Relun:<br />
<em>A combined Importance Sampling and Kriging reliability method for
small failure probabilities with time-demanding numerical models</em><br />
Reliability Engineering and System Safety,2012<br />
</p>
</li>
<li>
<p>B. Echard, N. Gayton and A. Bignonnet:<br />
<em>A reliability analysis method for fatigue design</em><br />
International Journal of Fatigue, 2014<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+SubsetSimulation">SubsetSimulation</a></code>
<code><a href="#topic+MonteCarlo">MonteCarlo</a></code>
<code><a href="#topic+MetaIS">MetaIS</a></code>
<code><a href="DiceKriging.html#topic+km">km</a></code> (in package <span class="pkg">DiceKriging</span>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res = AKMCS(dimension=2,lsf=kiureghian,plot=TRUE)

#Compare with crude Monte-Carlo reference value
N = 500000
dimension = 2
U = matrix(rnorm(dimension*N),dimension,N)
G = kiureghian(U)
P = mean(G&lt;0)
cov = sqrt((1-P)/(N*P))

## End(Not run)

#See impact of kernel choice with serial function from Waarts:
waarts = function(u) {
  u = as.matrix(u)
  b1 = 3+(u[1,]-u[2,])^2/10 - sign(u[1,] + u[2,])*(u[1,]+u[2,])/sqrt(2)
  b2 = sign(u[2,]-u[1,])*(u[1,]-u[2,])+7/sqrt(2)
  val = apply(cbind(b1, b2), 1, min)
}

## Not run: 
res = list()
res$matern5_2 = AKMCS(2, waarts, plot=TRUE)
res$matern3_2 = AKMCS(2, waarts, kernel="matern3_2", plot=TRUE)
res$gaussian  = AKMCS(2, waarts, kernel="gauss", plot=TRUE)
res$exp       = AKMCS(2, waarts, kernel="exp", plot=TRUE)

#Compare with crude Monte-Carlo reference value
N = 500000
dimension = 2
U = matrix(rnorm(dimension*N),dimension,N)
G = waarts(U)
P = mean(G&lt;0)
cov = sqrt((1-P)/(N*P))

## End(Not run)

</code></pre>

<hr>
<h2 id='BMP'>Bayesian Moving Particles</h2><span id='topic+BMP'></span>

<h3>Description</h3>

<p>This function runs the Bayesian Moving Particles algorithm for estimating extreme probability
and quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BMP(
  dimension,
  lsf,
  q,
  N = 1000,
  N.final = N,
  N.iter = 30,
  adaptive = FALSE,
  N.DoE = 5 * dimension,
  firstDoE = "uniform",
  radius = qnorm(1e-10, lower.tail = FALSE),
  X,
  y,
  covariance = NULL,
  learn_each_train = Inf,
  km.param = list(nugget.estim = TRUE, multistart = 1, optim.method = "BFGS", coef.trend
    = q),
  burnin = 20,
  fast = TRUE,
  sur = list(integrated = TRUE, r = 1, approx.pnorm = FALSE),
  lower.tail = TRUE,
  save.dir,
  plot = FALSE,
  plot.lsf = TRUE,
  plot.lab = c("x_1", "x_2"),
  chi2 = FALSE,
  verbose = 1,
  breaks
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BMP_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of the input space.</p>
</td></tr>
<tr><td><code id="BMP_+3A_lsf">lsf</code></td>
<td>
<p>the function defining the RV of interest Y = lsf(X).</p>
</td></tr>
<tr><td><code id="BMP_+3A_q">q</code></td>
<td>
<p>a given quantile to estimate the corresponding probability.</p>
</td></tr>
<tr><td><code id="BMP_+3A_n">N</code></td>
<td>
<p>the total number of Poisson processes during the refinement step.</p>
</td></tr>
<tr><td><code id="BMP_+3A_n.final">N.final</code></td>
<td>
<p>the total number of Poisson processes for the final alpha estimate.</p>
</td></tr>
<tr><td><code id="BMP_+3A_n.iter">N.iter</code></td>
<td>
<p>the total number of iteration of the algorithm, ie that total number of
calls to the <code>lsf</code> will be <code>N.DoE + N.iter*r</code>.</p>
</td></tr>
<tr><td><code id="BMP_+3A_adaptive">adaptive</code></td>
<td>
<p>if the algorithm should stop automatically if the stopping criterion
is verified, precisely the mean probability of misclassification of the particles
being over a given threshold.</p>
</td></tr>
<tr><td><code id="BMP_+3A_n.doe">N.DoE</code></td>
<td>
<p>the number of points for the initial Design of Experiment</p>
</td></tr>
<tr><td><code id="BMP_+3A_firstdoe">firstDoE</code></td>
<td>
<p>default is &quot;uniform&quot; for a random
uniform sampling over a sphere of radius <code>radius</code>. Also available &quot;maximim&quot; for a maximim LHS.</p>
</td></tr>
<tr><td><code id="BMP_+3A_radius">radius</code></td>
<td>
<p>the size of the radius of the sphere for uniform DoE or the semi length
of the interval on each dimension for maximin LHS</p>
</td></tr>
<tr><td><code id="BMP_+3A_x">X</code></td>
<td>
<p>(optional) a first Design of Experiemnt to be used instead of building
a new DoE</p>
</td></tr>
<tr><td><code id="BMP_+3A_y">y</code></td>
<td>
<p>the value of <code>lsf</code> on the <code>X</code></p>
</td></tr>
<tr><td><code id="BMP_+3A_covariance">covariance</code></td>
<td>
<p>(optional) to give a covariance kernel for the <code>km</code> object.</p>
</td></tr>
<tr><td><code id="BMP_+3A_learn_each_train">learn_each_train</code></td>
<td>
<p>a integer: after this limit the covariance parameters are not
learnt any more and model is just updated with the new datapoints.</p>
</td></tr>
<tr><td><code id="BMP_+3A_km.param">km.param</code></td>
<td>
<p>(optional) list of parameters to be passed to <code>DiceKriging::km</code>.</p>
</td></tr>
<tr><td><code id="BMP_+3A_burnin">burnin</code></td>
<td>
<p>a burnin parameter for Markov Chain drawing of the metamodel based
Poisson process (this does not change the number of calls to <code>lsf</code>).</p>
</td></tr>
<tr><td><code id="BMP_+3A_fast">fast</code></td>
<td>
<p>in current implementation it appears that the call to the metamodel is
faster when doing batch computation. This parameter lets do the Markov chain the other way
around: instead of first selecting a starting point and then applying <code>burnin</code> times the
transition kernel, it creates a working population by apply the kernel to all the
particles and then makes some moves with the generated discretised distribution.</p>
</td></tr>
<tr><td><code id="BMP_+3A_sur">sur</code></td>
<td>
<p>a list containing any parameters to be passed to <code>estimateSUR</code>. Default is
<code>sur$integrated=TRUE</code> and <code>sur$r=1</code> for a one step ahead integrated SUR criterion.</p>
</td></tr>
<tr><td><code id="BMP_+3A_lower.tail">lower.tail</code></td>
<td>
<p>as for pxxxx functions, TRUE for estimating P(lsf(X) &lt; q), FALSE
for P(lsf(X) &gt; q).</p>
</td></tr>
<tr><td><code id="BMP_+3A_save.dir">save.dir</code></td>
<td>
<p>(optional) a directory to save the <code>X</code> and <code>y</code> at each iteration.</p>
</td></tr>
<tr><td><code id="BMP_+3A_plot">plot</code></td>
<td>
<p>to plot the DoE and the updated model.</p>
</td></tr>
<tr><td><code id="BMP_+3A_plot.lsf">plot.lsf</code></td>
<td>
<p>to plot the contour of the true <code>lsf</code>. Note that this requires its
evaluation on a grid and should be used only on toy examples.</p>
</td></tr>
<tr><td><code id="BMP_+3A_plot.lab">plot.lab</code></td>
<td>
<p>the labels of the axis for the plot.</p>
</td></tr>
<tr><td><code id="BMP_+3A_chi2">chi2</code></td>
<td>
<p>for a chi2 test on the number of events.</p>
</td></tr>
<tr><td><code id="BMP_+3A_verbose">verbose</code></td>
<td>
<p>controls the level of outputs of the algorithm.</p>
</td></tr>
<tr><td><code id="BMP_+3A_breaks">breaks</code></td>
<td>
<p>optional, for the final histogram if <code>chi2 == TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian Moving Particles algorithm uses the point process framework for rare event to iteratively estimate
the conditional expectation of the (random) limit-state function, to quantify the quality of the learning
and to propose a new point to be added to the model with a SUR criterion.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the outputs described below:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>the estimated conditional expectation of the probability.</p>
</td></tr>
<tr><td><code>alpha.seq</code></td>
<td>
<p>the sequence of estimated alpha during the refinement step.</p>
</td></tr>
<tr><td><code>cv2</code></td>
<td>
<p>an estimate of the squarred coefficient of variation of alpha.</p>
</td></tr>
<tr><td><code>cv.seq</code></td>
<td>
<p>the sequence of the estimated coefficients of variations.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>the sequence of the estimated upper bound of the conditional variance
divided by estimated alpha.</p>
</td></tr>
<tr><td><code>I</code></td>
<td>
<p>the sequence of the estimated integrated h.</p>
</td></tr>
<tr><td><code>sur_min</code></td>
<td>
<p>a list containing the the sequence of corresponding thresholds and
-log probability of the sample minimising the SUR criterion.</p>
</td></tr>
<tr><td><code>sur_stat</code></td>
<td>
<p>a list containing at each iterations number of points tried for the SUR
criterion as well as the computational spent.</p>
</td></tr>
<tr><td><code>q</code></td>
<td>
<p>the reference quantile for the probability estimate.</p>
</td></tr>
<tr><td><code>ecdf</code></td>
<td>
<p>the empirical cdf, i.e. the estimation of the function q -&gt; E(alpha(q)).</p>
</td></tr>
<tr><td><code>L_max</code></td>
<td>
<p>the farthest state reached by the random process. Validity range
for the <code>ecdf</code> is then (-Inf, L_max] or [L_max, Inf).</p>
</td></tr>
<tr><td><code>PPP</code></td>
<td>
<p>the last Poisson process generated with <code>N.final</code> particles.</p>
</td></tr>
<tr><td><code>meta_fun</code></td>
<td>
<p>the metamodel approximation of the <code>lsf</code>. A call output is a
list containing the value and the standard deviation.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the final metamodel. An S4 object from <span class="pkg">DiceKriging</span>. Note
that the algorithm enforces the problem to be the estimation of P[lsf(X)&gt;q]
and so using &lsquo;predict&rsquo; with this object will return inverse values if
<code>lower.tail==TRUE</code>; in this scope prefer using directly <code>meta_fun</code> which
handles this possible issue.</p>
</td></tr>
<tr><td><code>model.first</code></td>
<td>
<p>the first metamodel with the intial DoE.</p>
</td></tr>
<tr><td><code>alpha_int</code></td>
<td>
<p>a 95% confidence intervalle on the estimate of alpha.</p>
</td></tr>
<tr><td><code>moves</code></td>
<td>
<p>a vector containing the number of moves for each one of the <code>N.batch</code> particles.</p>
</td></tr>
<tr><td><code>chi2</code></td>
<td>
<p>the output of the chisq.test function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Probleme should be defined in the standard space. Transformations can be made using <code>UtoX</code> and <code>XtoU</code>
functions.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> A. Guyader, N. Hengartner and E. Matzner-Lober:<br />
<em>Simulation and estimation of extreme quantiles and extreme
probabilities</em><br />
Applied Mathematics and Optimization, 64(2), 171-196.<br />
</p>
</li>
<li><p> C. Walter:<br />
<em>Moving Particles: a parallel optimal Multilevel Splitting
method with application in quantiles estimation and meta-model
based algorithms</em><br />
Structural Safety, 55, 10-25.<br />
</p>
</li>
<li><p> J. Bect, L. Li and E. Vazquez:<br />
<em>Bayesian subset simulation</em><br />
arXiv preprint arXiv:1601.02557
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+SubsetSimulation">SubsetSimulation</a></code>
<code><a href="#topic+MonteCarlo">MonteCarlo</a></code>
<code><a href="#topic+IRW">IRW</a></code>
<code><a href="#topic+MP">MP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Estimate P(g(X)&lt;0)
## Not run: p &lt;- BMP(dimension = 2, lsf = kiureghian, q = 0, N = 100, N.iter = 30, plot = TRUE)

# More extreme event
## Not run: p &lt;- BMP(dimension = 2, lsf = waarts, q = -4, N = 100, N.iter = 50, plot = TRUE)

# One can also estimate probability of the form P(g(X)&gt;q)
## Not run: p &lt;- BMP(dimension = 2, lsf = cantilever, q = 1/325, N = 100, N.iter = 30, plot = TRUE)

</code></pre>

<hr>
<h2 id='cantilever'>A function calculating the deviation of a cantilever beam.</h2><span id='topic+cantilever'></span>

<h3>Description</h3>

<p>The limit-state function is defined in the standard space and isoprobabilistic transformation is used internally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cantilever</code></pre>


<h3>Format</h3>

<p>The function can handle a vector or a matrix with column vectors.</p>


<h3>References</h3>

<p>Gayton, N. and Bourinet, J.-M. and Lemaire, M.:<br />
<em>CD2RS: a new statistical approach to the response surface method for reliability analysis.</em><br />
Structural Safety 25 99-121, 2003.<br />
</p>

<hr>
<h2 id='ComputeDistributionParameter'>Compute internal parameters and moments for univariate distribution functions</h2><span id='topic+ComputeDistributionParameter'></span>

<h3>Description</h3>

<p>Compute the internal parameters needed in the definition of several distribution functions when unknown
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ComputeDistributionParameter(margin)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ComputeDistributionParameter_+3A_margin">margin</code></td>
<td>
<p> A list containing the definition of the marginal distribution function</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>margin</code></td>
<td>
<p>The updated list</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> gilles DEFAUX, <a href="mailto:gilles.defaux@cea.fr">gilles.defaux@cea.fr</a> </p>


<h3>Examples</h3>

<pre><code class='language-R'> 
distX1 &lt;- list(type='Lnorm', MEAN=120.0, STD=12.0, P1=NULL, P2=NULL, NAME='X1')
distX1 &lt;- ComputeDistributionParameter(distX1)
print(distX1)
</code></pre>

<hr>
<h2 id='estimateSUR'>EstimateSUR</h2><span id='topic+estimateSUR'></span>

<h3>Description</h3>

<p>A function for estimating a SUR criterion with a realisation of a PPP
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimateSUR(
  PPP,
  xi_PPP_X,
  integrated = TRUE,
  N_ppp,
  method = "discrete",
  SUR_pop,
  r = N.batch,
  optimcontrol = list(pop.size = 50 * d, max.generations = 10 * d),
  approx.pnorm,
  J = 0,
  N.batch = foreach::getDoParWorkers(),
  verbose = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimateSUR_+3A_ppp">PPP</code></td>
<td>
<p>the Poisson point process generated to get alpha.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_xi_ppp_x">xi_PPP_X</code></td>
<td>
<p>the output of xi(cbind(PPP$X, PPP$final_X)).</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_integrated">integrated</code></td>
<td>
<p>boolean to specify of SUR criterion is standard or
integrated.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_n_ppp">N_ppp</code></td>
<td>
<p>the number of Poisson processes used for the SUR criterion estimation.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_method">method</code></td>
<td>
<p>eiter &quot;genoud&quot; for an optimisation using the package <code>rgenoud</code> or
&quot;discrete&quot; for a discrete search over <code>SUR_pop</code>.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_sur_pop">SUR_pop</code></td>
<td>
<p>if <code>optimcontrol$method=="discrete"</code>, SUR_pop is the population
onto which minimizer is sought. Should
be a matrix d x n.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_r">r</code></td>
<td>
<p>number of points to be added to the DoE.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_optimcontrol">optimcontrol</code></td>
<td>
<p>a list of control parameters for the optimisation
of the SUR criterion using the <code>rgenoud</code> package.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_approx.pnorm">approx.pnorm</code></td>
<td>
<p>(optional) an approximation of base pnorm function running faster.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_j">J</code></td>
<td>
<p>the center of an interval of size 8 for pnorm approximation.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_n.batch">N.batch</code></td>
<td>
<p>Number of batchs for parallel computation.</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_verbose">verbose</code></td>
<td>
<p>to control the print level of the algorithm</p>
</td></tr>
<tr><td><code id="estimateSUR_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to fSUR.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the points minimising the criterion
</p>

<hr>
<h2 id='FORM'>First-order reliability method</h2><span id='topic+FORM'></span>

<h3>Description</h3>

<p>The First-Order Reliability Method computes an estimation of the failure
probability by approximating the limit-state function at the Most Probable Failure Point
with a hyperplane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FORM(
  dimension,
  lsf,
  u.dep = rep(0, dimension),
  N.calls = 100,
  eps = 1e-07,
  Method = "HLRF",
  IS = FALSE,
  IS.ratio = 0.5,
  plot = FALSE,
  plot.lsf = FALSE,
  plot.lab = c("x_1", "x_2")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FORM_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of the input space.</p>
</td></tr>
<tr><td><code id="FORM_+3A_lsf">lsf</code></td>
<td>
<p>the limit-state function.</p>
</td></tr>
<tr><td><code id="FORM_+3A_u.dep">u.dep</code></td>
<td>
<p>the starting point for the MPFP search.</p>
</td></tr>
<tr><td><code id="FORM_+3A_n.calls">N.calls</code></td>
<td>
<p>the total number of calls for the whole algorithm.</p>
</td></tr>
<tr><td><code id="FORM_+3A_eps">eps</code></td>
<td>
<p>stopping criterion: distance of two points between two iterations.</p>
</td></tr>
<tr><td><code id="FORM_+3A_method">Method</code></td>
<td>
<p>choice of the method to search the design point: &quot;AR&quot; for Abdo-Rackwitz
and &quot;HLRF&quot; for Hasofer-Lindt-Rackwitz-Fiessler.</p>
</td></tr>
<tr><td><code id="FORM_+3A_is">IS</code></td>
<td>
<p>&quot;TRUE&quot; for using importance Sampling method with an standard Gaussian importance
density centred at the MPFP.</p>
</td></tr>
<tr><td><code id="FORM_+3A_is.ratio">IS.ratio</code></td>
<td>
<p>ratio of N.calls for the search of the design point by FORM. Default = 0.5.
1-<code>IS.ratio</code> = the remaining ratio to be used for importance sampling.</p>
</td></tr>
<tr><td><code id="FORM_+3A_plot">plot</code></td>
<td>
<p>to plot the generated samples.</p>
</td></tr>
<tr><td><code id="FORM_+3A_plot.lsf">plot.lsf</code></td>
<td>
<p>a boolean indicating if the <code>lsf</code> should be added to the
plot. This requires the evaluation of the <code>lsf</code> over a grid and
consequently should be used only for illustation purposes.</p>
</td></tr>
<tr><td><code id="FORM_+3A_plot.lab">plot.lab</code></td>
<td>
<p>the x and y labels for the plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The FORM method has to be used in the standard Gaussian input space. It is designed
to estimate probability of the form <code class="reqn">P[g(\mathbf{X}) &lt; 0]</code> with g the limit-state function.
This function has to be modified accordingly to fit into this framework
</p>
<p>Furthermore, it should be able to handle matrix input of column vectors. See the mistral vignette
for more info about <code>lsf</code> definition
</p>


<h3>Value</h3>

<p>A list containing the following objects
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>Failure probability</p>
</td></tr>
<tr><td><code>indice.reliab</code></td>
<td>
<p>Reliability index</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>Number of calls to f</p>
</td></tr>
<tr><td><code>Design.Point</code></td>
<td>
<p>Coordinates of the design point</p>
</td></tr>
<tr><td><code>fact.imp</code></td>
<td>
<p>Importance factors</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>Standard error of the probability estimator (if IS = TRUE)</p>
</td></tr>
<tr><td><code>Interval.conf</code></td>
<td>
<p>Confidence interval of the estimator at 0.95 (if IS = TRUE)</p>
</td></tr>
<tr><td><code>DOE</code></td>
<td>
<p>List which contains the design of experiments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vincent MOUTOUSSAMY and Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>O. Ditlevsen and H.O. Madsen. Structural reliability methods, Wiley, 1996<br />
</p>
</li>
<li>
<p>M. Lemaire, A. Chateauneuf and J. Mitteau. Structural reliability, Wiley Online Library, 2009.<br />
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# u.dep is a starting point for the research of the Most Probable Failing Point
# N.calls is a total number of calls
form &lt;- mistral::FORM(dimension = 2, mistral::kiureghian, N.calls = 1000,
                     u.dep = c(0,0))
form$p

# use IS=TRUE to use an Importance Sampling scheme with a Gaussian standard
# proposal distribution centred at the MPFP
form.IS &lt;- mistral::FORM(dimension = 2, mistral::kiureghian, N.calls = 1000,
                        u.dep = c(0,0),
                        IS = TRUE)
form.IS$p

## End(Not run)

</code></pre>

<hr>
<h2 id='FORMv0'>FORM method (old version)</h2><span id='topic+FORMv0'></span>

<h3>Description</h3>

<p>Calculate failure probability by FORM method and important sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FORMv0(f, u.dep, inputDist, N.calls, eps = 1e-7,
     Method = "HLRF", IS = FALSE, q = 0.5, copula = "unif")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FORMv0_+3A_f">f</code></td>
<td>

<p>A failure fonction
</p>
</td></tr>
<tr><td><code id="FORMv0_+3A_u.dep">u.dep</code></td>
<td>

<p>A vector, starting point to the research of the design point  
</p>
</td></tr>
<tr><td><code id="FORMv0_+3A_inputdist">inputDist</code></td>
<td>

<p>A list which contains the name of the input distribution and their parameters.
For the input &quot;i&quot;, inputDistribution[[i]] = list(&quot;name_law&quot;,c(parameters1,..., parametersN))
</p>
</td></tr>
<tr><td><code id="FORMv0_+3A_n.calls">N.calls</code></td>
<td>

<p>Number of calls to f allowed
</p>
</td></tr>
<tr><td><code id="FORMv0_+3A_eps">eps</code></td>
<td>

<p>Stop criterion : distance of two points between two iterations
</p>
</td></tr>
<tr><td><code id="FORMv0_+3A_method">Method</code></td>
<td>

<p>Choice of the method to research the design point: &quot;AR&quot; for Abdo-Rackwitz and &quot;HLRF&quot; for Hasofer-Lindt-Rackwitz-Fiessler
</p>
</td></tr>
<tr><td><code id="FORMv0_+3A_is">IS</code></td>
<td>

<p>&quot;TRUE&quot; for using importance Sampling method (applied after FORM which provides the importance density). Default = &quot;FALSE&quot;.
</p>
</td></tr>
<tr><td><code id="FORMv0_+3A_q">q</code></td>
<td>

<p>Ratio of N.calls for the research of the design point by FORM. Default = 0.5. 1-q = the remaining ratio to use importance sampling. 
</p>
</td></tr>
<tr><td><code id="FORMv0_+3A_copula">copula</code></td>
<td>

<p>Choice of the copula. Default = &quot;unif&quot; (uniform copula)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimate the probability that the output of the failure function is negative using FORM algorithm. The importance sampling procedure estimate a probability using a Gaussian distribution centered in the design point with a covariance matrix equal to the indentity.
</p>


<h3>Value</h3>

<table>
<tr><td><code>pf</code></td>
<td>
<p>Failure probability</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Reliability index (beta)</p>
</td></tr>
<tr><td><code>compt.f</code></td>
<td>
<p>Number of calls to f</p>
</td></tr>
<tr><td><code>design.point</code></td>
<td>
<p>Coordinates of the design point</p>
</td></tr>
<tr><td><code>fact.imp</code></td>
<td>
<p>Importance factors</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>Standard error of the probability estimator (if IS = TRUE)</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>Confidence interval of the estimator at 0.95 (if IS = TRUE)</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>A data frame containing the input design of experiments</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>A vector of model responses (corresponding to x)</p>
</td></tr>
<tr><td><code>dy</code></td>
<td>
<p>A data frame of model response derivatives (wrt each input and corresponding to x); for the IS sample, the derivatives are not computed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vincent Moutoussamy and Bertrand Iooss
</p>


<h3>References</h3>

<p>O. Ditlevsen and H.O. Madsen. Structural reliability methods, Wiley, 1996
</p>
<p>M. Lemaire, A. Chateauneuf and J. Mitteau. Structural reliability, Wiley Online Library, 2009.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Not run: 
 distribution = list()
 distribution[[1]] = list("gamma",c(2,1))
 distribution[[2]] = list("gamma",c(3,1))
 
 f &lt;- function(X){
    X[1]/sum(X) - qbeta((1e-5),2,3)
 }

 res &lt;- mistral:::FORMv0(f, u.dep = c(0,0.1), inputDist = distribution, 
     N.calls = 1000, eps = 1e-7, Method = "HLRF", IS = "TRUE", 
     q = 0.1, copula = "unif")
                  
names(res)
print(res)
print(res$pf)

## End(Not run)
</code></pre>

<hr>
<h2 id='generateK'>Generate Standard Gaussian samples with a Gaussian transiiton kernel</h2><span id='topic+generateK'></span>

<h3>Description</h3>

<p>Generate Standard Gaussian samples with a Gaussian transiiton kernel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateK(X, N = 100, thinning = 4, sigma = 1, lsf, burnin = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateK_+3A_x">X</code></td>
<td>
<p>the seeds for the Markov Chain. There are as many MC drawn as given
seeds</p>
</td></tr>
<tr><td><code id="generateK_+3A_n">N</code></td>
<td>
<p>the number of desired samples&quot;'</p>
</td></tr>
<tr><td><code id="generateK_+3A_thinning">thinning</code></td>
<td>
<p>the proportion of kept samples, ie. 1 each <code>thinning</code> draw.</p>
</td></tr>
<tr><td><code id="generateK_+3A_sigma">sigma</code></td>
<td>
<p>the exploration parameter for the transition kernel</p>
</td></tr>
<tr><td><code id="generateK_+3A_lsf">lsf</code></td>
<td>
<p>a boolean limit-state function for definig a subdomain of the input
space.</p>
</td></tr>
<tr><td><code id="generateK_+3A_burnin">burnin</code></td>
<td>
<p>the <code>burnin</code> parameter, ie. the number of discarded samples
before keeping one.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates standard Gaussian samples with a Markov Chain
using a suitable transition kernel
</p>


<h3>Value</h3>

<p>A matrix <code>X</code> with the number of desired samples
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get a seed in dimension 2
X &lt;- matrix(rnorm(2), nrow = 2)
X &lt;- generateK(X, N = 1000)

library(ggplot2)
ggplot(as.data.frame(t(X)), aes(x_1,x_2)) + geom_point()

# One can also specify a limit-state function
lsf &lt;- function(X){
     sqrt(colSums(X^2)) &gt; 2
}
X &lt;- matrix(c(2, 2), nrow = 2)
X &lt;- generateK(X, N = 1000, lsf = lsf)

ggplot(as.data.frame(t(X)), aes(x_1,x_2)) + geom_point()

</code></pre>

<hr>
<h2 id='IRW'>Increasing Randow Walk</h2><span id='topic+IRW'></span><span id='topic+NestedSampling'></span><span id='topic+TPA'></span>

<h3>Description</h3>

<p>Simulate the increasing random walk associated with a real-valued continuous
random variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRW(
  dimension,
  lsf,
  N = 10,
  q = Inf,
  Nevent = Inf,
  X,
  y = lsf(X),
  K,
  burnin = 20,
  sigma = 0.3,
  last.return = TRUE,
  use.potential = TRUE,
  plot = FALSE,
  plot.lsf = FALSE,
  print_plot = FALSE,
  output_dir = NULL,
  plot.lab = c("x_1", "x_2")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IRW_+3A_dimension">dimension</code></td>
<td>
<p>dimension of the input space.</p>
</td></tr>
<tr><td><code id="IRW_+3A_lsf">lsf</code></td>
<td>
<p>limit state function.</p>
</td></tr>
<tr><td><code id="IRW_+3A_n">N</code></td>
<td>
<p>number of particules.</p>
</td></tr>
<tr><td><code id="IRW_+3A_q">q</code></td>
<td>
<p>level until which the randow walk is to be generated.</p>
</td></tr>
<tr><td><code id="IRW_+3A_nevent">Nevent</code></td>
<td>
<p>the number of desired events.</p>
</td></tr>
<tr><td><code id="IRW_+3A_x">X</code></td>
<td>
<p>to start with some given particles.</p>
</td></tr>
<tr><td><code id="IRW_+3A_y">y</code></td>
<td>
<p>value of the <code>lsf</code> on X.</p>
</td></tr>
<tr><td><code id="IRW_+3A_k">K</code></td>
<td>
<p>kernel transition for conditional generations.</p>
</td></tr>
<tr><td><code id="IRW_+3A_burnin">burnin</code></td>
<td>
<p>burnin parameter.</p>
</td></tr>
<tr><td><code id="IRW_+3A_sigma">sigma</code></td>
<td>
<p>radius parameter for <code>K</code>.</p>
</td></tr>
<tr><td><code id="IRW_+3A_last.return">last.return</code></td>
<td>
<p>if the last event should be returned.</p>
</td></tr>
<tr><td><code id="IRW_+3A_use.potential">use.potential</code></td>
<td>
<p>tu use a &lsquo;potential&rsquo; matrix to select starting point not
directly related to the sample to be moved with the MH algorithm.</p>
</td></tr>
<tr><td><code id="IRW_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, the algorithm plots the evolution of the particles. This
requieres to evaluate the <code>lsf</code> on a grid and is only for visual purpose.</p>
</td></tr>
<tr><td><code id="IRW_+3A_plot.lsf">plot.lsf</code></td>
<td>
<p>a boolean indicating if the <code>lsf</code> should be added to the
plot. This requires the evaluation of the <code>lsf</code> over a grid and
consequently should be used only for illustation purposes.</p>
</td></tr>
<tr><td><code id="IRW_+3A_print_plot">print_plot</code></td>
<td>
<p>if TRUE, print the updated plot after each iteration. This might
be slow; use with a small <code>N</code>. Otherwise it only prints the final plot.</p>
</td></tr>
<tr><td><code id="IRW_+3A_output_dir">output_dir</code></td>
<td>
<p>if plots are to be saved in pdf in a given directory. This will
be pasted with &lsquo;_IRW.pdf&rsquo;. Together with <code>print_plot==TRUE</code> this will
produce a pdf with a plot at each iteration, enabling &lsquo;video&rsquo; reconstitution
of the algorithm.</p>
</td></tr>
<tr><td><code id="IRW_+3A_plot.lab">plot.lab</code></td>
<td>
<p>the x and y labels for the plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function lets generate the increasing random walk associated with a continous
real-valued random variable of the form <code>Y = lsf(X)</code> where <code>X</code> is
vectorial random variable.
</p>
<p>This random walk can be associated with a Poisson process with parameter
<code>N</code> and hence the number of iterations before a given threshold <code>q</code>
is directly related to P[ lsf(X) &gt; q]. It is the core tool of algorithms
such as nested sampling, Last Particle Algorithm or Tootsie Pop Algorithm.
</p>
<p>Bascially for <code>N = 1</code>, it generates a sample <code class="reqn">Y = lsf(X)</code> and iteratively
regenerates greater than the found value: <code class="reqn">Y_{n+1} \sim \mu^Y( \cdot \mid Y &gt; Y_n</code>. This
regeneration step is done with a Metropolis-Hastings algorithm and that is why it is usefull
to consider generating several chains all together (<code>N &gt; 1</code>).
</p>
<p>The algorithm stops when it has simulated the required number of events <code>Nevent</code> or when
it has reached the sought threshold <code>q</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the following data:
</p>
<table>
<tr><td><code>L</code></td>
<td>
<p>the events of the random walk.</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>the total number of iterations.</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>the total number of calls to the <code>lsf</code>.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>a matrix containing the final particles.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the value of <code>lsf</code> on <code>X</code>.</p>
</td></tr>
<tr><td><code>q</code></td>
<td>
<p>the threshold considered when generating the random walk.</p>
</td></tr>
<tr><td><code>Nevent</code></td>
<td>
<p>the target number of events when generating the random walk.</p>
</td></tr>
<tr><td><code>Nwmoves</code></td>
<td>
<p>the number of rejected transitions, ie when the proposed point was not stricly
greater/lower than the current state.</p>
</td></tr>
<tr><td><code>acceptance</code></td>
<td>
<p>a vector containing the acceptance rate for each use of the MH algorithm.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Problem is supposed to be defined in the standard space. If not,
use <code><a href="#topic+UtoX">UtoX</a></code> to do so. Furthermore, each time a set of vector
is defined as a matrix, &lsquo;nrow&rsquo; = <code>dimension</code> and
&lsquo;ncol&rsquo; = number of vector to be consistent with <code>as.matrix</code>
transformation of a vector.
</p>
<p>Algorithm calls lsf(X) (where X is a matrix as defined previously) and
expects a vector in return. This allows the user to optimise the computation
of a batch of points, either by vectorial computation, or by the use of
external codes (optimised C or C++ codes for example) and/or parallel
computation; see examples in <a href="#topic+MonteCarlo">MonteCarlo</a>.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> C. Walter:<br />
<em>Moving Particles: a parallel optimal Multilevel Splitting method
with application in quantiles estimation and meta-model based algorithms</em><br />
Structural Safety, 55, 10-25.<br />
</p>
</li>
<li><p> C. Walter:<br />
<em>Point Process-based Monte Carlo estimation</em><br />
Statistics and Computing, in press, 1-18.<br />
arXiv preprint arXiv:1412.6368.<br />
</p>
</li>
<li><p> J. Skilling:<br />
<em>Nested sampling for general Bayesian computation</em><br />
Bayesian Analysis, 1(4), 833-859.<br />
</p>
</li>
<li><p> M. Huber and S. Schott:<br />
<em>Using TPA for Bayesian inference</em><br />
Bayesian Statistics 9, 9, 257.<br />
</p>
</li>
<li><p> A. Guyader, N. Hengartner and E. Matzner-Lober:<br />
<em>Simulation and estimation of extreme quantiles and extreme
probabilities</em><br />
Applied Mathematics and Optimization, 64(2), 171-196.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+MP">MP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get faililng samples for the kiureghian limit state function
# Failure is defined as lsf(X) &lt; 0 so we have to invert the lsf
lsf &lt;- function(x) -1*kiureghian(x)
## Not run: 
fail.samp &lt;- IRW(2, lsf, q = 0, N = 10, plot = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='kiureghian'>A limit-state-function defined by Der Kiureghian</h2><span id='topic+kiureghian'></span>

<h3>Description</h3>

<p>The limit-state function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
      f(x) = b - x_2 - \kappa*(x_1-e)^2
    </code>
</p>

<p>with <code class="reqn">b = 5</code>, <code class="reqn">\kappa = 0.5</code> and <code class="reqn">e = 0.1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kiureghian</code></pre>


<h3>Format</h3>

<p>The function can handle a vector or matrix with column vectors.</p>


<h3>References</h3>

<p>Der Kiureghian, A and Dakessian, T:<br />
<em>Multiple design points in first and second-order reliability</em><br />
Structural Safety, 20, 1, 37-49, 1998.<br />
</p>

<hr>
<h2 id='LSVM'>Linear Support Vector Machine under monotonicity constraints</h2><span id='topic+LSVM'></span>

<h3>Description</h3>

<p>Produce a globally increasing binary classifier built from linear monotonic SVM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  LSVM(x, A.model.lsvm, convexity)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LSVM_+3A_x">x</code></td>
<td>
<p>a set of points where the class must be estimated.</p>
</td></tr>
<tr><td><code id="LSVM_+3A_a.model.lsvm">A.model.lsvm</code></td>
<td>
<p>a matrix containing the parameters of all hyperplanes.</p>
</td></tr>
<tr><td><code id="LSVM_+3A_convexity">convexity</code></td>
<td>
<p>Either -1 if the set of data associated to the label &quot;-1&quot; is convex or +1 otherwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>LSVM is a monotonic binary classifier built from linear SVM under the constraint that one of the two classes of data is convex.
</p>


<h3>Value</h3>

<p>An object of class <code>integer</code> representing the class of x
</p>
<table>
<tr><td><code>res</code></td>
<td>
<p>A vector of -1 or +1.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vincent Moutoussamy<br />
</p>


<h3>References</h3>


<ul>
<li>
<p>R.T. Rockafellar:<br />
<em>Convex analysis</em><br />
Princeton university press, 2015.<br />
</p>
</li>
<li>
<p>N. Bousquet, T. Klein and V. Moutoussamy :<br />
<em>Approximation of limit state surfaces in monotonic Monte Carlo settings</em><br />
Submitted .<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code> <a href="#topic+modelLSVM">modelLSVM</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A limit state function
f &lt;- function(x){  sqrt(sum(x^2)) - sqrt(2)/2 }

# Creation of the data sets
n &lt;- 200
X &lt;- matrix(runif(2*n), nrow = n)
Y &lt;- apply(X, MARGIN = 1, function(w){sign(f(w))})

#The convexity is known
## Not run: 
  model.A &lt;- modelLSVM(X, Y, convexity = -1)
  m &lt;- 10
  X.test &lt;- matrix(runif(2*m), nrow = m)
  classOf.X.test &lt;- LSVM(X.test, model.A, convexity = -1)

## End(Not run)

</code></pre>

<hr>
<h2 id='MetaIS'>Metamodel based Impotance Sampling</h2><span id='topic+MetaIS'></span>

<h3>Description</h3>

<p>Estimate failure probability by MetaIS method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MetaIS(
  dimension,
  lsf,
  N = 5e+05,
  N_alpha = 100,
  N_DOE = 10 * dimension,
  N1 = N_DOE * 30,
  Ru = 8,
  Nmin = 30,
  Nmax = 200,
  Ncall_max = 1000,
  precision = 0.05,
  N_seeds = 2 * dimension,
  Niter_seed = Inf,
  N_alphaLOO = 5000,
  K_alphaLOO = 1,
  alpha_int = c(0.1, 10),
  k_margin = 1.96,
  lower.tail = TRUE,
  X = NULL,
  y = NULL,
  failure = 0,
  meta_model = NULL,
  kernel = "matern5_2",
  learn_each_train = TRUE,
  limit_fun_MH = NULL,
  failure_MH = 0,
  sampling_strategy = "MH",
  seeds = NULL,
  seeds_eval = limit_fun_MH(seeds),
  burnin = 20,
  compute.PPP = FALSE,
  plot = FALSE,
  limited_plot = FALSE,
  add = FALSE,
  output_dir = NULL,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MetaIS_+3A_dimension">dimension</code></td>
<td>
<p>of the input space</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_lsf">lsf</code></td>
<td>
<p>the failure defining the failure/safety domain</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_n">N</code></td>
<td>
<p>size of the Monte-Carlo population for P_epsilon estimate</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_n_alpha">N_alpha</code></td>
<td>
<p>initial size of the Monte-Carlo population for alpha estimate</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_n_doe">N_DOE</code></td>
<td>
<p>size of the initial DOE got by clustering of the N1 samples</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_n1">N1</code></td>
<td>
<p>size of the initial uniform population sampled in a hypersphere of radius Ru</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_ru">Ru</code></td>
<td>
<p>radius of the hypersphere for the initial sampling</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_nmin">Nmin</code></td>
<td>
<p>minimum number of call for the construction step</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_nmax">Nmax</code></td>
<td>
<p>maximum number of call for the construction step</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_ncall_max">Ncall_max</code></td>
<td>
<p>maximum number of call for the whole algorithm</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_precision">precision</code></td>
<td>
<p>desired maximal value of cov</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_n_seeds">N_seeds</code></td>
<td>
<p>number of seeds for MH algoritm while generating into the margin (
according to MP*gauss)</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_niter_seed">Niter_seed</code></td>
<td>
<p>maximum number of iteration for the research of a seed for alphaLOO
refinement sampling</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_n_alphaloo">N_alphaLOO</code></td>
<td>
<p>number of points to sample at each refinement step</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_k_alphaloo">K_alphaLOO</code></td>
<td>
<p>number of clusters at each refinement step</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_alpha_int">alpha_int</code></td>
<td>
<p>range for alpha to stop construction step</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_k_margin">k_margin</code></td>
<td>
<p>margin width; default value means that points are classified with more
than 97,5%</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_lower.tail">lower.tail</code></td>
<td>
<p>specify if one wants to estimate P[lsf(X)&lt;failure] or P[lsf(X)&gt;failure].</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_x">X</code></td>
<td>
<p>Coordinates of alredy known points</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_y">y</code></td>
<td>
<p>Value of the LSF on these points</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_failure">failure</code></td>
<td>
<p>Failure threshold</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_meta_model">meta_model</code></td>
<td>
<p>Provide here a kriging metamodel from km if wanted</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_kernel">kernel</code></td>
<td>
<p>Specify the kernel to use for km</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_learn_each_train">learn_each_train</code></td>
<td>
<p>Specify if kernel parameters are re-estimated at each train</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_limit_fun_mh">limit_fun_MH</code></td>
<td>
<p>Define an area of exclusion with a limit function</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_failure_mh">failure_MH</code></td>
<td>
<p>Threshold for the limit_MH function</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_sampling_strategy">sampling_strategy</code></td>
<td>
<p>Either MH for Metropolis-Hastings of AR for accept-reject</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_seeds">seeds</code></td>
<td>
<p>If some points are already known to be in the appropriate subdomain</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_seeds_eval">seeds_eval</code></td>
<td>
<p>Value of the metamodel on these points</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_burnin">burnin</code></td>
<td>
<p>Burnin parameter for MH</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_compute.ppp">compute.PPP</code></td>
<td>
<p>to simulate a Poisson process at each iteration to estimate
the conditional expectation and the SUR criteria based on the conditional
variance: h (average probability of misclassification at level <code>failure</code>)
and I (integral of h over the whole interval [failure, infty))</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_plot">plot</code></td>
<td>
<p>Set to TRUE for a full plot, ie refresh at each iteration</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_limited_plot">limited_plot</code></td>
<td>
<p>Set to TRUE for a final plot with final DOE, metamodel and LSF</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_add">add</code></td>
<td>
<p>If plots are to be added to a current device</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_output_dir">output_dir</code></td>
<td>
<p>If plots are to be saved in jpeg in a given directory</p>
</td></tr>
<tr><td><code id="MetaIS_+3A_verbose">verbose</code></td>
<td>
<p>Either 0 for almost no output, or 1 for medium size or 2 for all outputs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MetaIS is an Important Sampling based probability estimator. It makes use of
a kriging surogate to approximate the optimal density function, replacing the
indicatrice by its kriging pendant, the probability of being in the failure
domain. In this context, the normallizing constant of this quasi-optimal PDF
is called the &lsquo;augmented failure probability&rsquo; and the modified
probability &lsquo;alpha&rsquo;.
</p>
<p>After a first uniform Design of Experiments, MetaIS uses an alpha
Leave-One-Out criterion combined with a margin sampling strategy to refine
a kriging-based metamodel. Samples are generated according to the weighted
margin probability with Metropolis-Hastings algorithm and some are selected
by clustering; the <code>N_seeds</code> are got from an accept-reject strategy on
a standard population.
</p>
<p>Once criterion is reached or maximum number of call done, the augmented
failure probability is estimated with a crude Monte-Carlo. Then, a new
population is generated according to the quasi-optimal instrumenal PDF;
<code>burnin</code> and <code>thinning</code> are used here and alpha is evaluated.
While the coefficient of variation of alpha estimate is greater than a
given threshold and some computation spots still available (defined by
<code>Ncall_max</code>) the estimate is refined with extra calculus.
</p>
<p>The final probability is the product of p_epsilon and alpha, and final
squared coefficient of variation is the sum of p_epsilon and alpha one's.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the failure probability
and some more outputs as described below:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>The estimated failure probability.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>The coefficient of variation of the Monte-Carlo probability
estimate.</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>The total number of calls to the <code>lsf</code>.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>The final learning database, ie. all points where <code>lsf</code>
has been calculated.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The value of the <code>lsf</code> on the learning database.</p>
</td></tr>
<tr><td><code>meta_fun</code></td>
<td>
<p>The metamodel approximation of the <code>lsf</code>. A call output
is a list containing the value and the standard deviation.</p>
</td></tr>
<tr><td><code>meta_model</code></td>
<td>
<p>The final metamodel. An S4 object from <span class="pkg">DiceKriging</span>.
Note that the algorithm enforces the problem to be the estimation of
P[lsf(X)&lt;failure] and so using &lsquo;predict&rsquo; with this object will
return inverse values if <code>lower.tail==FALSE</code>; in this scope prefer
using directly <code>meta_fun</code> which handle this possible issue.</p>
</td></tr>
<tr><td><code>points</code></td>
<td>
<p>Points in the failure domain according to the metamodel.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>the sequence of the estimated relative SUR criteria.</p>
</td></tr>
<tr><td><code>I</code></td>
<td>
<p>the sequence of the estimated integrated SUR criteria.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Problem is supposed to be defined in the standard space. If not,
use <code><a href="#topic+UtoX">UtoX</a></code> to do so. Furthermore, each time a set of vector
is defined as a matrix, &lsquo;nrow&rsquo; = <code>dimension</code> and
&lsquo;ncol&rsquo; = number of vector to be consistent with <code>as.matrix</code>
transformation of a vector.
</p>
<p>Algorithm calls lsf(X) (where X is a matrix as defined previously) and
expects a vector in return. This allows the user to optimise the computation
of a batch of points, either by vectorial computation, or by the use of
external codes (optimised C or C++ codes for example) and/or parallel
computation; see examples in <a href="#topic+MonteCarlo">MonteCarlo</a>.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>V. Dubourg:<br />
Meta-modeles adaptatifs pour l'analyse de fiabilite et l'optimisation sous
containte fiabiliste<br />
PhD Thesis, Universite Blaise Pascal - Clermont II,2011<br />
</p>
</li>
<li>
<p>V. Dubourg, B. Sudret, F. Deheeger:<br />
Metamodel-based importance sampling for structural reliability analysis
Original Research Article<br />
Probabilistic Engineering Mechanics, Volume 33, July 2013, Pages 47-57<br />
</p>
</li>
<li>
<p>V. Dubourg, B. Sudret:<br />
Metamodel-based importance sampling for reliability sensitivity analysis.<br />
Accepted for publication in Structural Safety, special issue in the honor
of Prof. Wilson Tang.(2013)<br />
</p>
</li>
<li>
<p>V. Dubourg, B. Sudret and J.-M. Bourinet:<br />
Reliability-based design optimization using kriging surrogates and subset
simulation.<br />
Struct. Multidisc. Optim.(2011)<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+SubsetSimulation">SubsetSimulation</a></code>
<code><a href="#topic+MonteCarlo">MonteCarlo</a></code>
<code><a href="DiceKriging.html#topic+km">km</a></code> (in package <span class="pkg">DiceKriging</span>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>kiureghian = function(x, b=5, kappa=0.5, e=0.1) {
x = as.matrix(x)
b - x[2,] - kappa*(x[1,]-e)^2
}

## Not run: 
res = MetaIS(dimension=2,lsf=kiureghian,plot=TRUE)

#Compare with crude Monte-Carlo reference value
N = 500000
dimension = 2
U = matrix(rnorm(dimension*N),dimension,N)
G = kiureghian(U)
P = mean(G&lt;0)
cov = sqrt((1-P)/(N*P))

## End(Not run)

#See impact of kernel choice with Waarts function :
waarts = function(u) {
  u = as.matrix(u)
  b1 = 3+(u[1,]-u[2,])^2/10 - sign(u[1,] + u[2,])*(u[1,]+u[2,])/sqrt(2)
  b2 = sign(u[2,]-u[1,])*(u[1,]-u[2,])+7/sqrt(2)
  val = apply(cbind(b1, b2), 1, min)
}

## Not run: 
res = list()
res$matern5_2 = MetaIS(2,waarts,plot=TRUE)
res$matern3_2 = MetaIS(2,waarts,kernel="matern3_2",plot=TRUE)
res$gaussian = MetaIS(2,waarts,kernel="gauss",plot=TRUE)
res$exp = MetaIS(2,waarts,kernel="exp",plot=TRUE)

#Compare with crude Monte-Carlo reference value
N = 500000
dimension = 2
U = matrix(rnorm(dimension*N),dimension,N)
G = waarts(U)
P = mean(G&lt;0)
cov = sqrt((1-P)/(N*P))

## End(Not run)

</code></pre>

<hr>
<h2 id='MetropolisHastings'>The modified Metropolis-Hastings algorithm</h2><span id='topic+MetropolisHastings'></span>

<h3>Description</h3>

<p>The function implements the specific modified Metropolis-Hastings algorithm
as described first by Au and Beck and including another scaling parameter for an extended
search in initial steps of the <code>SMART</code> algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MetropolisHastings(
  x0,
  eval_x0 = -1,
  chain_length,
  modified = TRUE,
  sigma = 0.3,
  proposal = "Uniform",
  lambda = 1,
  limit_fun = function(x) {     -1 },
  burnin = 20,
  thinning = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MetropolisHastings_+3A_x0">x0</code></td>
<td>
<p>the starting point of the Markov chain</p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_eval_x0">eval_x0</code></td>
<td>
<p>the value of the limit-state function on <code>x0</code></p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_chain_length">chain_length</code></td>
<td>
<p>the length of the Markov chain. At the end the chain
will be chain_length + 1 long</p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_modified">modified</code></td>
<td>
<p>a boolean to use either the original Metropolis-Hastings
transition kernel or the coordinate-wise one</p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_sigma">sigma</code></td>
<td>
<p>a radius parameter for the Gaussian or Uniform proposal</p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_proposal">proposal</code></td>
<td>
<p>either &quot;Uniform&quot; for a Uniform random variable in an interval
[-sigma, sigma] or &quot;Gaussian&quot; for a centred Gaussian random variable with
standard deviation sigma</p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_lambda">lambda</code></td>
<td>
<p>the coefficient to increase the likelihood ratio</p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_limit_fun">limit_fun</code></td>
<td>
<p>the limite-state function delimiting the domain to sample in</p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_burnin">burnin</code></td>
<td>
<p>a burnin parameter, ie a number of initial discards samples</p>
</td></tr>
<tr><td><code id="MetropolisHastings_+3A_thinning">thinning</code></td>
<td>
<p>a thinning parameter, ie that one sample over <code>thinning</code>
samples is kept along the chain</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The modified Metropolis-Hastings algorithm is supposed to be used in the
Gaussian standard space. Instead of using a proposed point for the multidimensional
Gaussian random variable, it applies a Metropolis step to each coordinate. Then it
generates the multivariate candidate by checking if it lies in the right domain.
</p>
<p>This version proposed by Bourinet et al. includes an scaling parameter <code>lambda</code>.
This parameter is multiplied with the likelihood ratio in order to increase the chance
of accepting the candidate. While it biases the output distribution of the Markov chain,
the authors of <code>SMART</code> suggest its use (<code>lambda &gt; 1</code>) for the exploration phase.
Note such a value disable to possiblity to use the output population for Monte Carlo
estimation.
</p>


<h3>Value</h3>

<p>A list containing the following entries:
</p>
<table>
<tr><td><code>points</code></td>
<td>
<p>the generated Markov chain</p>
</td></tr>
<tr><td><code>eval</code></td>
<td>
<p>the value of the limit-state function on the generated samples</p>
</td></tr>
<tr><td><code>acceptation</code></td>
<td>
<p>the acceptation rate</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>the total number of call to the limit-state function</p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>all the generated samples</p>
</td></tr>
<tr><td><code>eval_samples</code></td>
<td>
<p>the evaluation of the limit-state function on the
<code>samples</code> samples</p>
</td></tr>
</table>

<hr>
<h2 id='modelLSVM'>Estimation of the parameters of the LSVM</h2><span id='topic+modelLSVM'></span>

<h3>Description</h3>

<p>Produce a matrix containing the parameters of a set of hyperplanes separating the two classes of data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  modelLSVM(X, Y, convexity)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelLSVM_+3A_x">X</code></td>
<td>
<p>a matrix containing the data sets</p>
</td></tr>
<tr><td><code id="modelLSVM_+3A_y">Y</code></td>
<td>
<p>a vector containing -1 or +1 that reprensents the class of each elements of X.</p>
</td></tr>
<tr><td><code id="modelLSVM_+3A_convexity">convexity</code></td>
<td>
<p>Either -1 if the set of data associated to the label &quot;-1&quot; is convex or +1 otherwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>modelLSVM evaluate the classifier on a set of points.
</p>


<h3>Value</h3>

<p>An object of class <code>matrix</code> containing the parameters of a set of hyperplanes
</p>
<table>
<tr><td><code>res</code></td>
<td>
<p>A matrix where each lines contains the parameters of a hyperplane.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vincent Moutoussamy<br />
</p>


<h3>References</h3>


<ul>
<li>
<p>R.T. Rockafellar:<br />
<em>Convex analysis</em><br />
Princeton university press, 2015.<br />
</p>
</li>
<li>
<p>N. Bousquet, T. Klein and V. Moutoussamy :<br />
<em>Approximation of limit state surfaces in monotonic Monte Carlo settings</em><br />
Submitted .<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+LSVM">LSVM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# A limit state function
f &lt;- function(x){  sqrt(sum(x^2)) - sqrt(2)/2 }

# Creation of the data sets
n &lt;- 200
X &lt;- matrix(runif(2*n), nrow = n)
Y &lt;- apply(X, MARGIN = 1, function(w){sign(f(w))})

#The convexity is known
## Not run: 
  model.A &lt;- modelLSVM(X, Y, convexity = -1)

## End(Not run)

</code></pre>

<hr>
<h2 id='ModifCorrMatrix'>Modification of a correlation matrix to use in UtoX</h2><span id='topic+ModifCorrMatrix'></span>

<h3>Description</h3>

<p><code>ModifCorrMatrix</code> modifies a correlation matrix originally defined using SPEARMAN correlation coefficients to the correlation matrix to be used in the NATAF transformation performed in <code>UtoX</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ModifCorrMatrix(Rs) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ModifCorrMatrix_+3A_rs">Rs</code></td>
<td>
<p> Original correlation matrix defined using SPEARMAN correlation coefficient : </p>
<p style="text-align: center;"><code class="reqn">R_s=[\rho_{ij}^s]</code>
</p>
 </td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>R0</code></td>
<td>
<p>Modified correlation matrix</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The NATAF distribution is reviewed from the (normal) copula viewpoint as a particular and convenient means to describe a joint probabilistic model assuming that the normal copula fits to the description of the input X.
The normal copula is defined by a symmetric positive definite matrix R0. Even though the off-diagonal terms in this matrix are comprised in ]-1; 1[ and its diagonal terms are equal to 1, it shall not be confused with the more usual correlation matrix.
Lebrun and Dutfoy point out that the SPEARMAN (or rank) correlation coefficient is better suited to parametrize a copula because it leads to a simpler closed-form expression for <code class="reqn">\rho_{ij}</code>.

</p>


<h3>Author(s)</h3>

<p> Gilles DEFAUX, <a href="mailto:gilles.defaux@cea.fr">gilles.defaux@cea.fr</a> </p>


<h3>References</h3>


<ul>
<li><p> M. Lemaire, A. Chateauneuf and J. Mitteau. Structural reliability, Wiley Online Library, 2009
</p>
</li>
<li><p> Lebrun, R. and A. Dutfoy. A generalization of the Nataf transformation to distributions with elliptical copula. Prob. Eng. Mech., 24(2), 172-178.
</p>
</li>
<li>
<p>V. Dubourg, Meta-modeles adaptatifs pour l'analyse de fiabilite et l'optimisation sous containte fiabiliste, PhD Thesis, Universite Blaise Pascal - Clermont II,2011
</p>
</li></ul>



<h3>See Also</h3>

 <p><code><a href="#topic+UtoX">UtoX</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'> 
Dim &lt;- 2
input.Rho    &lt;- matrix( c(1.0, 0.5,
                          0.5, 1.0),nrow=Dim)
input.R0     &lt;- ModifCorrMatrix(input.Rho)
print(input.R0)
</code></pre>

<hr>
<h2 id='MonotonicQuantileEstimation'>Quantile estimation under monotonicity constraints</h2><span id='topic+MonotonicQuantileEstimation'></span>

<h3>Description</h3>

<p>Estimate a quantile with the constraints that the function is monotone
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  MonotonicQuantileEstimation(f, 
                            inputDimension, 
                            inputDistribution,
                            dir.monot,
                            N.calls,
                            p,
                            method,
                            X.input = NULL,
                            Y.input = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MonotonicQuantileEstimation_+3A_f">f</code></td>
<td>

<p>a failure fonction
</p>
</td></tr>
<tr><td><code id="MonotonicQuantileEstimation_+3A_inputdimension">inputDimension</code></td>
<td>

<p>dimension of the inputs
</p>
</td></tr>
<tr><td><code id="MonotonicQuantileEstimation_+3A_inputdistribution">inputDistribution</code></td>
<td>

<p>a list of length &lsquo;inputDimension&rsquo; which contains the name of the input distribution and their parameters. For the input &quot;i&quot;,
inputDistribution[[i]] = list(&quot;name_law&quot;,c(parameters1,..., parametersN))
</p>
</td></tr>
<tr><td><code id="MonotonicQuantileEstimation_+3A_dir.monot">dir.monot</code></td>
<td>

<p>vector of size <code>inputDimension</code> which represents the monotonicity of the failure function. dir.monot[i] = -1 (resp. 1) if the failure function f is decreasing (resp. increasing) according with direction i.
</p>
</td></tr>
<tr><td><code id="MonotonicQuantileEstimation_+3A_n.calls">N.calls</code></td>
<td>

<p>Number of calls to f allowed
</p>
</td></tr>
<tr><td><code id="MonotonicQuantileEstimation_+3A_method">method</code></td>
<td>

<p>there are four methods available. &quot;MonteCarloWB&quot; provides the empirical quantile estimator, &quot;MonteCarloWB&quot; provides the empirical quantile estimator as well as two bounds for the searched quantile, &quot;Bounds&quot; provides two bounds for a quantile from a set of points and &quot;MonteCarloIS&quot; provides an estimate of a quantile based on a sequential framework of simulation.
</p>
</td></tr>
<tr><td><code id="MonotonicQuantileEstimation_+3A_p">p</code></td>
<td>

<p>the probability associated to the quantile
</p>
</td></tr>
<tr><td><code id="MonotonicQuantileEstimation_+3A_x.input">X.input</code></td>
<td>

<p>a set of points
</p>
</td></tr>
<tr><td><code id="MonotonicQuantileEstimation_+3A_y.input">Y.input</code></td>
<td>

<p>value of f on X.input
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MonotonicQuantileEstimation provides many methods to estimate a quantile under monotonicity constraints.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the quantile as well as:
</p>
<table>
<tr><td><code>qm</code></td>
<td>
<p>A lower bound of the quantile.</p>
</td></tr>
<tr><td><code>qM</code></td>
<td>
<p>A upperer bound of the quantile.</p>
</td></tr>
<tr><td><code>q.hat</code></td>
<td>
<p>An estimate of the quantile.</p>
</td></tr>
<tr><td><code>Um</code></td>
<td>
<p>A lower bounds of the probability obtained from the desing of experiments.</p>
</td></tr>
<tr><td><code>UM</code></td>
<td>
<p>An upper bounds of the probability obtained from the desing of experiments.</p>
</td></tr>
<tr><td><code>XX</code></td>
<td>
<p>Design of experiments</p>
</td></tr>
<tr><td><code>YY</code></td>
<td>
<p>Values of on XX</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Inputs X.input and Y.input are useful only for method = &quot;Bounds&quot; 
</p>


<h3>Author(s)</h3>

<p>Vincent Moutoussamy <br />
</p>


<h3>References</h3>

<p>Bousquet, N. (2012) Accelerated monte carlo estimation of exceedance probabilities under monotonicity constraints. Annales de la Faculte des Sciences de Toulouse. XXI(3), 557-592.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 inputDistribution &lt;- list()
 inputDistribution[[1]] &lt;- list("norm",c(4,1))
 inputDistribution[[2]] &lt;- list("norm",c(0,1))

 inputDimension &lt;- length(inputDistribution)
 dir.monot &lt;- c(1, -1)
 N.calls &lt;- 80

 f &lt;- function(x){
   return(x[1] - x[2])
 }

 probability &lt;- 1e-2

 trueQuantile &lt;- qnorm(probability,
                     inputDistribution[[1]][[2]][1] - inputDistribution[[2]][[2]][1],
                     sqrt(inputDistribution[[1]][[2]][2] + inputDistribution[[1]][[2]][2]))

 resQuantile &lt;- MonotonicQuantileEstimation(f, inputDimension, inputDistribution,
                                      dir.monot, N.calls, p = probability, method = "MonteCarloIS")

 quantileEstimate &lt;- resQuantile[[1]][N.calls, 3]


## End(Not run)
</code></pre>

<hr>
<h2 id='MonteCarlo'>Crude Monte Carlo method</h2><span id='topic+MonteCarlo'></span>

<h3>Description</h3>

<p>Estimate a failure probability using a crude Monte Carlo method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MonteCarlo(
  dimension,
  lsf,
  N_max = 5e+05,
  N_batch = foreach::getDoParWorkers(),
  q = 0,
  lower.tail = TRUE,
  precision = 0.05,
  plot = FALSE,
  output_dir = NULL,
  save.X = TRUE,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MonteCarlo_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of the input space.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_lsf">lsf</code></td>
<td>
<p>the function defining safety/failure domain.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_n_max">N_max</code></td>
<td>
<p>maximum number of calls to the <code>lsf</code>.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_n_batch">N_batch</code></td>
<td>
<p>number of points evaluated at each iteration.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_q">q</code></td>
<td>
<p>the quantile.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_lower.tail">lower.tail</code></td>
<td>
<p>as for pxxxx functions, TRUE for estimating P(lsf(X) &lt; q), FALSE
for P(lsf(X) &gt; q).</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_precision">precision</code></td>
<td>
<p>a targeted maximum value for the coefficient of variation.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_plot">plot</code></td>
<td>
<p>to plot the contour of the <code>lsf</code> as well as the generated samples.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_output_dir">output_dir</code></td>
<td>
<p>to save a copy of the plot in a pdf. This name will be
pasted with
&quot;_Monte_Carlo_brut.pdf&quot;.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_save.x">save.X</code></td>
<td>
<p>to save all the samples generated as a matrix. Can be set to FALSE
to reduce output size.</p>
</td></tr>
<tr><td><code id="MonteCarlo_+3A_verbose">verbose</code></td>
<td>
<p>to control the level of outputs in the console; either 0 or 1 or 2 for
almost no outputs to a high level output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation of the crude Monte Carlo method works with evaluating
batchs of points sequentialy until a given precision is reached on the final
estimator
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the failure probability and some
more outputs as described below:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>the estimated probabilty.</p>
</td></tr>
<tr><td><code>ecdf</code></td>
<td>
<p>the empiracal cdf got with the generated samples.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>the coefficient of variation of the Monte Carlo estimator.</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>the total numnber of calls to the <code>lsf</code>, ie the total
number of generated samples.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the generated samples.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the value <code>lsf(X)</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Problem is supposed to be defined in the standard space. If not, use <code><a href="#topic+UtoX">UtoX</a></code>
to do so. Furthermore, each time a set of vector is defined as a matrix, &lsquo;nrow&rsquo;
= <code>dimension</code> and &lsquo;ncol&rsquo; = number of vector to be consistent with
<code>as.matrix</code> transformation of a vector.
</p>
<p>Algorithm calls lsf(X) (where X is a matrix as defined previously) and expects a vector
in return. This allows the user to optimise the computation of a batch of points,
either by vectorial computation, or by the use of external codes (optimised C or
C++ codes for example) and/or parallel computation.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>R. Rubinstein and D. Kroese:<br />
<em>Simulation and the Monte Carlo method</em> <br />
Wiley (2008)<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+SubsetSimulation">SubsetSimulation</a></code>
<code><a href="foreach.html#topic+foreach">foreach</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#First some considerations on the usage of the lsf. 
#Limit state function defined by Kiureghian &amp; Dakessian :
# Remember you have to consider the fact that the input will be a matrix ncol &gt;= 1
lsf_wrong = function(x, b=5, kappa=0.5, e=0.1) {
  b - x[2] - kappa*(x[1]-e)^2 # work only with a vector of lenght 2
}
lsf_correct = function(x){
  apply(x, 2, lsf_wrong)
}
lsf = function(x, b=5, kappa=0.5, e=0.1) {
  x = as.matrix(x)
  b - x[2,] - kappa*(x[1,]-e)^2 # vectorial computation, run fast
}

y = lsf(X &lt;- matrix(rnorm(20), 2, 10))
#Compare running time
## Not run: 
  require(microbenchmark)
  X = matrix(rnorm(2e5), 2)
  microbenchmark(lsf(X), lsf_correct(X))

## End(Not run)

#Example of parallel computation
require(doParallel)
lsf_par = function(x){
 foreach(x=iter(X, by='col'), .combine = 'c') %dopar% lsf(x)
}

#Try Naive Monte Carlo on a given function with different failure level
## Not run: 
  res = list()
  res[[1]] = MonteCarlo(2,lsf,q = 0,plot=TRUE)
  res[[2]] = MonteCarlo(2,lsf,q = 1,plot=TRUE)
  res[[3]] = MonteCarlo(2,lsf,q = -1,plot=TRUE)
  

## End(Not run)


#Try Naive Monte Carlo on a given function and change number of points.
## Not run: 
  res = list()
  res[[1]] = MonteCarlo(2,lsf,N_max = 10000)
  res[[2]] = MonteCarlo(2,lsf,N_max = 100000)
  res[[3]] = MonteCarlo(2,lsf,N_max = 500000)

## End(Not run)

</code></pre>

<hr>
<h2 id='MP'>Moving Particles</h2><span id='topic+MP'></span><span id='topic+LPA'></span>

<h3>Description</h3>

<p>This function runs the Moving Particles algorithm for estimating extreme probability
and quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MP(
  dimension,
  lsf,
  N = 100,
  N.batch = foreach::getDoParWorkers(),
  p,
  q,
  lower.tail = TRUE,
  Niter_1fold,
  alpha = 0.05,
  compute_confidence = FALSE,
  verbose = 0,
  chi2 = FALSE,
  breaks = N.batch/5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MP_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of the input space.</p>
</td></tr>
<tr><td><code id="MP_+3A_lsf">lsf</code></td>
<td>
<p>the function defining the RV of interest Y = lsf(X).</p>
</td></tr>
<tr><td><code id="MP_+3A_n">N</code></td>
<td>
<p>the total number of particles,</p>
</td></tr>
<tr><td><code id="MP_+3A_n.batch">N.batch</code></td>
<td>
<p>the number of parallel batches for the algorithm. Each batch will then
have <code>N/N.batch</code> particles. Typically this could be <code>detectCores()</code> or some
other machine-derived parameters. Note that <code>N/N.batch</code> has to be an integer.</p>
</td></tr>
<tr><td><code id="MP_+3A_p">p</code></td>
<td>
<p>a given probability to estimate the corresponding quantile (as in qxxxx functions).</p>
</td></tr>
<tr><td><code id="MP_+3A_q">q</code></td>
<td>
<p>a given quantile to estimate the corresponding probability (as in pxxxx functions).</p>
</td></tr>
<tr><td><code id="MP_+3A_lower.tail">lower.tail</code></td>
<td>
<p>as for pxxxx functions, TRUE for estimating P(lsf(X) &lt; q), FALSE
for P(lsf(X) &gt; q).</p>
</td></tr>
<tr><td><code id="MP_+3A_niter_1fold">Niter_1fold</code></td>
<td>
<p>a function = fun(N) giving the deterministic number of iterations
for the first pass.</p>
</td></tr>
<tr><td><code id="MP_+3A_alpha">alpha</code></td>
<td>
<p>when using default <code>Niter_1fold</code> function, this is the risk not to have
simulated enough samples to produce a quantile estimator.</p>
</td></tr>
<tr><td><code id="MP_+3A_compute_confidence">compute_confidence</code></td>
<td>
<p>if <code>TRUE</code>, the algorithm runs a little bit longer to produces
a 95% interval on the quantile estimator.</p>
</td></tr>
<tr><td><code id="MP_+3A_verbose">verbose</code></td>
<td>
<p>to control level of print (either 0, or 1, or 2).</p>
</td></tr>
<tr><td><code id="MP_+3A_chi2">chi2</code></td>
<td>
<p>for a chi2 test on the number of events.</p>
</td></tr>
<tr><td><code id="MP_+3A_breaks">breaks</code></td>
<td>
<p>for the final histogram is <code>chi2 == TRUE</code>.</p>
</td></tr>
<tr><td><code id="MP_+3A_...">...</code></td>
<td>
<p>further arguments past to <code><a href="#topic+IRW">IRW</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MP</code> is a wrap up of <code><a href="#topic+IRW">IRW</a></code> for probability and quantile estimation.
By construction, the several calls to <code><a href="#topic+IRW">IRW</a></code> are parallel (<span class="pkg">foreach</span>)
and so is the algorithm. Especially, with <code>N.batch=1</code>, this is the Last Particle
Algorithm, which is a specific version of <code><a href="#topic+SubsetSimulation">SubsetSimulation</a></code> with <code>p_0 = 1-1/N</code>.
However, note that this algorithm not only gives a quantile or a probability estimate
but also an estimate of the whole cdf until the given threshold <code>q</code>.
</p>
<p>The probability estimator only requires to generate several random walks as it is the estimation
of the parameter of a Poisson random variable. The quantile estimator is a little bit more complicated
and requires a 2-passes algorithm. It is thus not exactly fully parallel as cluster/cores have to
communicate after the first pass. During the first pass, particles are moved a given number of
times, during the second pass particles are moved until the farthest event reach during the first
pass. Hence, the random process is completely simulated until this given state.
</p>
<p>For an easy user experiment, all the parameters are defined by default with the optimised values
as described in the reference paper (see References below) and a typical use will only specify
<code>N</code> and <code>N.batch</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the outputs described below:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>the estimated probability or the reference for the quantile estimate.</p>
</td></tr>
<tr><td><code>q</code></td>
<td>
<p>the estimated quantile or the reference for the probability estimate.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>the coefficient of variation of the probability estimator.</p>
</td></tr>
<tr><td><code>ecdf</code></td>
<td>
<p>the empirical cdf.</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>the states of the random walk.</p>
</td></tr>
<tr><td><code>L_max</code></td>
<td>
<p>the farthest state reached by the random process. Validity range
for the <code>ecdf</code> is then (-Inf, L_max] or [L_max, Inf).</p>
</td></tr>
<tr><td><code>times</code></td>
<td>
<p>the <em>times</em> of the random process.</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>the total number of calls to the <code>lsf</code>.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the <code>N</code> particles in their final state.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the value of the <code>lsf(X)</code>.</p>
</td></tr>
<tr><td><code>moves</code></td>
<td>
<p>a vector containing the number of moves for each batch.</p>
</td></tr>
<tr><td><code>p_int</code></td>
<td>
<p>a 95% confidence intervalle on the probability estimate.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>the coefficient of variation of the estimator</p>
</td></tr>
<tr><td><code>q_int</code></td>
<td>
<p>a 95% confidence intervall on the quantile estimate.</p>
</td></tr>
<tr><td><code>chi2</code></td>
<td>
<p>the output of the chisq.test function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>alpha</code> parameter is set to 0.05 by default. Indeed it should not be
set too small as it is defined approximating the Poisson distribution with the Gaussian one.
However if no estimate is produce then the algorithm can be restarted for the few missing events.
In any cases, setting <code>Niter_1fold = -N/N.batch*log(p)</code> gives 100% chances to produces
a quantile estimator.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li><p> A. Guyader, N. Hengartner and E. Matzner-Lober:<br />
<em>Simulation and estimation of extreme quantiles and extreme
probabilities</em><br />
Applied Mathematics and Optimization, 64(2), 171-196.<br />
</p>
</li>
<li><p> C. Walter:<br />
<em>Moving Particles: a parallel optimal Multilevel Splitting
method with application in quantiles estimation and meta-model
based algorithms</em><br />
Structural Safety, 55, 10-25.<br />
</p>
</li>
<li><p> E. Simonnet:<br />
<em>Combinatorial analysis of the adaptive last particle method</em><br />
Statistics and Computing, 1-20.<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+SubsetSimulation">SubsetSimulation</a></code>
<code><a href="#topic+MonteCarlo">MonteCarlo</a></code>
<code><a href="#topic+IRW">IRW</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Estimate some probability and quantile with the parabolic lsf
p.est &lt;- MP(2, kiureghian, N = 100, q = 0) # estimate P(lsf(X) &lt; 0)
p.est &lt;- MP(2, kiureghian, N = 100, q = 7.8, lower.tail = FALSE) # estimate P(lsf(X) &gt; 7.8)

q.est &lt;- MP(2, kiureghian, N = 100, p = 1e-3) # estimate q such that P(lsf(X) &lt; q) = 1e-3
q.est &lt;- MP(2, kiureghian, N = 100, p = 1e-3, lower.tail = FALSE) # estimate q such
# that P(lsf(X) &gt; q) = 1e-3


# plot the empirical cdf
plot(xplot &lt;- seq(-3, p.est$L_max, l = 100), sapply(xplot, p.est$ecdf_MP))

# check validity range
p.est$ecdf_MP(p.est$L_max - 1)
# this example will fail because the quantile is greater than the limit
tryCatch({
   p.est$ecdf_MP(p.est$L_max + 0.1)},
   error = function(cond) message(cond))

# Run in parallel
library(doParallel)
registerDoParallel()
p.est &lt;- MP(2, kiureghian, N = 100, q = 0, N.batch = getDoParWorkers())

## End(Not run)

</code></pre>

<hr>
<h2 id='ok'>Class of Ordinary Kriging</h2><span id='topic+ok'></span>

<h3>Description</h3>

<p>An implementation of Ordinary Kriging based upon a km-class object that should be
faster than usual predict method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ok(model, beta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ok_+3A_model">model</code></td>
<td>
<p>a kriging model object from <code>DiceKriging::km-class</code></p>
</td></tr>
<tr><td><code id="ok_+3A_beta">beta</code></td>
<td>
<p>the trend of the model</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Ordinary Kriging is a special case of kriging where the trend is supposed to be
and unknown constant. Consequently some linear algebra operations can be reduced by knowning
that the vector of parameter <code>beta</code> is indeed a real.
</p>
<p>The ok class defines three functions: <code>xi</code> the kriging predictor, <code>updateSd</code> and
<code>updateSdfast</code> two methods for updating the kriging variance when some poitns are
virtually added to the model. These two last functions differ in their implementation: the
first one allows for the user to specify which are the predicted points and which are the
added points. The second one outputs a matrix where the kriging variances of all the points
is updated when each one is iteratively added the the Design of Experiments.
</p>
<p>The faster between looping <code>updateSd</code> and using <code>updateSdfast</code> is indeed problem
dependent (depending on parallel computer, size of the data, etc.) and should be
benchmark by the user.
</p>


<h3>Value</h3>

<p>An object of S3 class 'ok' containing
</p>
<table>
<tr><td><code>Kinv</code></td>
<td>
<p>the inverse of the covariance matrix of the data</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the estimated coefficient of the trend</p>
</td></tr>
<tr><td><code>y_centred</code></td>
<td>
<p>the data centred according to the estimated trend</p>
</td></tr>
<tr><td><code>sigma_beta</code></td>
<td>
<p>the standard deviation of the estimation of beta</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>
<p>the kriging predictor</p>
</td></tr>
<tr><td><code>updateSd</code></td>
<td>
<p>a function to calculate the updated kriging variance when
<code>Xnew</code> points are added to the Design of Experiments</p>
</td></tr>
<tr><td><code>updateSdfast</code></td>
<td>
<p>a function to calculate the update kriging variance
when the SUR criterion is minimised over a population which is also the one
used to estimate it.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate a dataset
X &lt;- data.frame(x1 = rnorm(10), x2 = rnorm(10))
y &lt;- cos(sqrt(rowSums(X^2)))

# Learn a model
krig &lt;- DiceKriging::km(design=X, response=y)

# Create Ordinary Kriging object
OK &lt;- ok(krig)

# Microbenchmark
# create a dataset
X = data.frame(x1 = rnorm(100), x2 = rnorm(100))
microbenchmark::microbenchmark(OK$xi(t(X)), predict(krig, X, type="UK"))

# Check identical results
X &lt;- rnorm(2)
OK$xi(X)[c('mean', 'sd')]
predict(krig, data.frame(x1=X[1], x2=X[2]), type="UK")[c('mean', 'sd')]

</code></pre>

<hr>
<h2 id='oscillator_d6'>A limit-state-function defined with a non-linear oscillator in dimension 6.</h2><span id='topic+oscillator_d6'></span>

<h3>Description</h3>

<p>The limit-state function is defined in the standard space and isoprobabilistic transformation is used internally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oscillator_d6</code></pre>


<h3>Format</h3>

<p>The function can handle a vector or a matrix with column vectors.</p>


<h3>References</h3>

<p>Echard, B and Gayton, N and Lemaire, M and Relun, N:<br />
<em>A combined Importance Sampling and Kriging reliability method for
small failure probabilities with time-demanding numerical models</em><br />
Reliability Engineering and System Safety 111 232-240, 2013.<br />
</p>

<hr>
<h2 id='plotLSVM'>plot of LSVM</h2><span id='topic+plotLSVM'></span>

<h3>Description</h3>

<p>Make a plot of the data and the LSVM classifier
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotLSVM(X,
          Y,
          A.model.lsvm,
          hyperplanes = FALSE,
          limit.state.estimate = TRUE,
          convexity)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotLSVM_+3A_x">X</code></td>
<td>
<p>a matrix containing the data sets</p>
</td></tr>
<tr><td><code id="plotLSVM_+3A_y">Y</code></td>
<td>
<p>a vector containing -1 or +1 that reprensents the class of each elements of X.</p>
</td></tr>
<tr><td><code id="plotLSVM_+3A_a.model.lsvm">A.model.lsvm</code></td>
<td>
<p>a matrix containing the parameters of all hyperplanes.</p>
</td></tr>
<tr><td><code id="plotLSVM_+3A_hyperplanes">hyperplanes</code></td>
<td>
<p>A boolean. If TRUE, plot the hyperplanes obtained.</p>
</td></tr>
<tr><td><code id="plotLSVM_+3A_limit.state.estimate">limit.state.estimate</code></td>
<td>
<p>A boolean. If TRUE, plot the estimate of the limit state.</p>
</td></tr>
<tr><td><code id="plotLSVM_+3A_convexity">convexity</code></td>
<td>
<p>Either -1 if the set of data associated to the label &quot;-1&quot; is convex or +1 otherwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>plotLSVM makes a plot of the data as well as the estimate limit state and the hyperplanes involved in this construction.
</p>


<h3>Note</h3>

<p>This function is useful only in dimension 2.
</p>


<h3>Author(s)</h3>

<p>Vincent Moutoussamy<br />
</p>


<h3>References</h3>


<ul>
<li>
<p>R.T. Rockafellar:<br />
<em>Convex analysis</em><br />
Princeton university press, 2015.<br />
</p>
</li>
<li>
<p>N. Bousquet, T. Klein and V. Moutoussamy :<br />
<em>Approximation of limit state surfaces in monotonic Monte Carlo settings</em><br />
Submitted .<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+LSVM">LSVM</a></code>
<code><a href="#topic+modelLSVM">modelLSVM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# A limit state function
f &lt;- function(x){  sqrt(sum(x^2)) - sqrt(2)/2 }

# Creation of the data sets

n &lt;- 200
X &lt;- matrix(runif(2*n), nrow = n)
Y &lt;- apply(X, MARGIN = 1, function(w){sign(f(w))})

## Not run: 
  model.A &lt;- modelLSVM(X,Y, convexity = -1)
  plotLSVM(X, Y, model.A, hyperplanes = FALSE, limit.state.estimate = TRUE, convexity = -1)

## End(Not run)

</code></pre>

<hr>
<h2 id='precomputeUpdateData'>precomputeUpdateData</h2><span id='topic+precomputeUpdateData'></span>

<h3>Description</h3>

<p>precomputeUpdateData
</p>


<h3>Usage</h3>

<pre><code class='language-R'>precomputeUpdateData(model, integration.points)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="precomputeUpdateData_+3A_model">model</code></td>
<td>
<p>a object from <code>km</code></p>
</td></tr>
<tr><td><code id="precomputeUpdateData_+3A_integration.points">integration.points</code></td>
<td>
<p>the points onto which the updated variance will be computed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements
</p>
<table>
<tr><td><code>Kinv.c.olddata</code></td>
<td>
<p>kriging weights for the integrations.points over krig@X</p>
</td></tr>
<tr><td><code>Kinv.F</code></td>
<td>
<p>The matrix product of the inverse covariance and F the matrix of
the trend functions at model@X</p>
</td></tr>
<tr><td><code>first.member</code></td>
<td>
</td></tr>
</table>

<hr>
<h2 id='quantileWilks'>Computing quantiles with the Wilks formula</h2><span id='topic+quantileWilks'></span>

<h3>Description</h3>

<p>From the Wilks formula, compute a quantile (or a tolerance interval) with a given confidence level from a i.i.d. sample, or compute the minimal sample size to estimate a quantile (or a tolerance interval) with a given confidence level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantileWilks(alpha=0.95,beta=0.95,data=NULL,bilateral=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quantileWilks_+3A_alpha">alpha</code></td>
<td>

<p>level of the unilateral or bilateral quantile (default = 0.95)
</p>
</td></tr>
<tr><td><code id="quantileWilks_+3A_beta">beta</code></td>
<td>

<p>level of the confidence interval on quantile value(s) (default = 0.95)
</p>
</td></tr>
<tr><td><code id="quantileWilks_+3A_data">data</code></td>
<td>

<p>the data sample (vector format) to compute the quantile(s);
if data=NULL (by default), the function returns the minimal sample size to compute the required quantile 
</p>
</td></tr>
<tr><td><code id="quantileWilks_+3A_bilateral">bilateral</code></td>
<td>

<p>TRUE for bilateral quantile (default = unilateral = FALSE)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>4 output values if 'data' is specified; 1 output value (nmin) if 'data' is not specified
</p>
<table>
<tr><td><code>lower</code></td>
<td>

<p>lower bound of the bilateral tolerance interval; if bilateral=FALSE, no value
</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>

<p>upper bound of the tolerance interval (bilateral case) or quantile value (unilateral case)
</p>
</td></tr>
<tr><td><code>nmin</code></td>
<td>

<p>minimal size of the required i.i.d. sample for given alpha and beta:
- bilateral case: tolerance interval will be composed with the min and max of the sample;
- unilateral case: the quantile will correspond to max of the sample.
</p>
</td></tr>
<tr><td><code>ind</code></td>
<td>

<p>the index (unilateral case) or indices (bilateral case) of the quantiles in the ordered sample (increasing order) 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Claire Cannamela and Bertrand Iooss
</p>


<h3>References</h3>

<p>H.A. David and H.N. Nagaraja. Order statistics, Wiley, 2003.
</p>
<p>W.T. Nutt and G.B. Wallis. Evaluation of nuclear safety from the outputs of computer codes in the presence of uncertainties. Reliability Engineering and System Safety, 83:57-77, 2004.
</p>
<p>S.S. Wilks. Determination of Sample Sizes for Setting Tolerance Limits. Annals Mathematical Statistics, 12:91-96, 1941.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
N &lt;- quantileWilks(alpha=0.95,beta=0.95)
print(N)
</code></pre>

<hr>
<h2 id='rackwitz'>A limit-state-function defined by Rackwitz</h2><span id='topic+rackwitz'></span>

<h3>Description</h3>

<p>The function is defined in the standard space and internal normal-lognormal transformation is done. Its definition with iid lognormal random variables is:
</p>
<p style="text-align: center;"><code class="reqn">d + a\sigma\sqrt{d} - \sum_{i=1}^d x_i</code>
</p>

<p>Default values are: <code class="reqn">a=1</code>, <code>mean=1</code> and <code class="reqn">\sigma=0.2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rackwitz</code></pre>


<h3>Format</h3>

<p>The function can handle a vector or a matrix with column vectors.</p>


<h3>References</h3>

<p>Rackwitz, R:<br />
<em>Reliability analysis: a review and some perspectives</em><br />
Structural Safety, 23, 4, 365-395, 2001.<br />
</p>

<hr>
<h2 id='S2MART'>Subset by Support vector Margin Algorithm for Reliability esTimation</h2><span id='topic+S2MART'></span>

<h3>Description</h3>

<p><code>S2MART</code> introduces a metamodeling step at each subset simulation
threshold, making number of necessary samples lower and the probability estimation
better according to subset simulation by itself.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>S2MART(
  dimension,
  lsf,
  Nn = 100,
  alpha_quantile = 0.1,
  failure = 0,
  lower.tail = TRUE,
  ...,
  plot = FALSE,
  output_dir = NULL,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="S2MART_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of the input space</p>
</td></tr>
<tr><td><code id="S2MART_+3A_lsf">lsf</code></td>
<td>
<p>the function defining the failure domain. Failure is lsf(X) &lt; <code>failure</code></p>
</td></tr>
<tr><td><code id="S2MART_+3A_nn">Nn</code></td>
<td>
<p>number of samples to evaluate the quantiles in the subset step</p>
</td></tr>
<tr><td><code id="S2MART_+3A_alpha_quantile">alpha_quantile</code></td>
<td>
<p>cutoff probability for the subsets</p>
</td></tr>
<tr><td><code id="S2MART_+3A_failure">failure</code></td>
<td>
<p>the failure threshold</p>
</td></tr>
<tr><td><code id="S2MART_+3A_lower.tail">lower.tail</code></td>
<td>
<p>as for pxxxx functions, TRUE for estimating P(lsf(X) &lt; failure), FALSE
for P(lsf(X) &gt; failure)</p>
</td></tr>
<tr><td><code id="S2MART_+3A_...">...</code></td>
<td>
<p>All others parameters of the metamodel based algorithm</p>
</td></tr>
<tr><td><code id="S2MART_+3A_plot">plot</code></td>
<td>
<p>to produce a plot of the failure and safety domain. Note that this requires a lot of
calls to the <code>lsf</code> and is thus only for training purpose</p>
</td></tr>
<tr><td><code id="S2MART_+3A_output_dir">output_dir</code></td>
<td>
<p>to save the plot into the given directory. This will be pasted with &quot;_S2MART.pdf&quot;</p>
</td></tr>
<tr><td><code id="S2MART_+3A_verbose">verbose</code></td>
<td>
<p>either 0 for almost no output, 1 for medium size output and 2 for all outputs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>S2MART algorithm is based on the idea that subset simulations conditional
probabilities are estimated with a relatively poor precision as it
requires calls to the expensive-to-evaluate limit state function and
does not take benefit from its numerous calls to the limit state function
in the Metropolis-Hastings algorithm. In this scope, the key concept is
to reduce the subset simulation population to its minimum and use it only
to estimate crudely the next quantile. Then the use of a metamodel-based
algorithm lets refine the border and calculate an accurate estimation of
the conditional probability by the mean of a crude Monte-Carlo.
</p>
<p>In this scope, a compromise has to be found between the two sources of
calls to the limit state function as total number of calls = (<code>Nn</code> +
number of calls to refine the metamodel) x (number of subsets) :
</p>

<ul>
<li><p><code>Nn</code> calls to find the next threshold value : the bigger <code>Nn</code>,
the more accurate the &lsquo;decreasing speed&rsquo; specified by the
<code>alpha_quantile</code> value and so the smaller the number of subsets
</p>
</li>
<li><p>total number of calls to refine the metamodel at each threshold
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <code>list</code> containing the failure probability
and some more outputs as described below:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>The estimated failure probability.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>The coefficient of variation of the Monte-Carlo probability
estimate.</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>The total number of calls to the <code>lsf</code>.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>The final learning database, ie. all points where <code>lsf</code>
has been calculated.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The value of the <code>lsf</code> on the learning database.</p>
</td></tr>
<tr><td><code>meta_model</code></td>
<td>
<p>The final metamodel. An object from <span class="pkg">e1071</span>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Problem is supposed to be defined in the standard space. If not,
use <code><a href="#topic+UtoX">UtoX</a></code> to do so. Furthermore, each time a set of vector
is defined as a matrix, &lsquo;nrow&rsquo; = <code>dimension</code> and
&lsquo;ncol&rsquo; = number of vector to be consistent with <code>as.matrix</code>
transformation of a vector.
</p>
<p>Algorithm calls lsf(X) (where X is a matrix as defined previously) and
expects a vector in return. This allows the user to optimise the computation
of a batch of points, either by vectorial computation, or by the use of
external codes (optimised C or C++ codes for example) and/or parallel
computation; see examples in <a href="#topic+MonteCarlo">MonteCarlo</a>.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>J.-M. Bourinet, F. Deheeger, M. Lemaire:<br />
<em>Assessing small failure probabilities by combined Subset Simulation and Support Vector Machines</em><br />
Structural Safety (2011)
</p>
</li>
<li>
<p>F. Deheeger:<br />
<em>Couplage m?cano-fiabiliste : 2SMART - m?thodologie d'apprentissage stochastique en fiabilit?</em><br />
PhD. Thesis, Universit? Blaise Pascal - Clermont II, 2008
</p>
</li>
<li>
<p>S.-K. Au, J. L. Beck:<br />
<em>Estimation of small failure probabilities in high dimensions by Subset Simulation</em> <br />
Probabilistic Engineering Mechanics (2001)
</p>
</li>
<li>
<p>A. Der Kiureghian, T. Dakessian:<br />
<em>Multiple design points in first and second-order reliability</em><br />
Structural Safety, vol.20 (1998)
</p>
</li>
<li>
<p>P.-H. Waarts:<br />
<em>Structural reliability using finite element methods: an appraisal of DARS:<br /> Directional Adaptive Response Surface Sampling</em><br />
PhD. Thesis, Technical University of Delft, The Netherlands, 2000
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+SMART">SMART</a></code>
<code><a href="#topic+SubsetSimulation">SubsetSimulation</a></code>
<code><a href="#topic+MonteCarlo">MonteCarlo</a></code>
<code><a href="DiceKriging.html#topic+km">km</a></code> (in package <span class="pkg">DiceKriging</span>)
<code><a href="e1071.html#topic+svm">svm</a></code> (in package <span class="pkg">e1071</span>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  res = S2MART(dimension = 2,
               lsf = kiureghian,
               N1 = 1000, N2 = 5000, N3 = 10000,
               plot = TRUE)
  
  #Compare with crude Monte-Carlo reference value
  reference = MonteCarlo(2, kiureghian, N_max = 500000)

## End(Not run)

#See impact of metamodel-based subset simulation with Waarts function :
## Not run: 
  res = list()
  # SMART stands for the pure metamodel based algorithm targeting directly the
  # failure domain. This is not recommended by its authors which for this purpose
  # designed S2MART : Subset-SMART
  res$SMART = mistral:::SMART(dimension  = 2, lsf = waarts, plot=TRUE)
  res$S2MART = S2MART(dimension = 2,
                      lsf = waarts,
                      N1 = 1000, N2 = 5000, N3 = 10000,
                      plot=TRUE)
  res$SS = SubsetSimulation(dimension = 2, waarts, n_init_samples = 10000)
 res$MC = MonteCarlo(2, waarts, N_max = 500000)

## End(Not run)

</code></pre>

<hr>
<h2 id='SMART'>Support-vector Margin Algoritm for Reliability esTimation</h2><span id='topic+SMART'></span>

<h3>Description</h3>

<p>Calculate a failure probability with SMART method. This
should not be used by itself but only through S2MART.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SMART(
  dimension,
  lsf,
  N1 = 10000,
  N2 = 50000,
  N3 = 2e+05,
  Nu = 50,
  lambda1 = 7,
  lambda2 = 3.5,
  lambda3 = 1,
  tune_cost = c(1, 10, 100, 1000),
  tune_gamma = c(0.5, 0.2, 0.1, 0.05, 0.02, 0.01),
  clusterInMargin = TRUE,
  alpha_margin = 1,
  k1 = round(6 * (dimension/2)^(0.2)),
  k2 = round(12 * (dimension/2)^(0.2)),
  k3 = k2 + 16,
  X = NULL,
  y = NULL,
  failure = 0,
  limit_fun_MH = NULL,
  sampling_strategy = "MH",
  seeds = NULL,
  seeds_eval = NULL,
  burnin = 20,
  thinning = 4,
  plot = FALSE,
  limited_plot = FALSE,
  add = FALSE,
  output_dir = NULL,
  z_MH = NULL,
  z_lsf = NULL,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SMART_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of the input space</p>
</td></tr>
<tr><td><code id="SMART_+3A_lsf">lsf</code></td>
<td>
<p>the limit-state function</p>
</td></tr>
<tr><td><code id="SMART_+3A_n1">N1</code></td>
<td>
<p>Number of samples for the (L)ocalisation step</p>
</td></tr>
<tr><td><code id="SMART_+3A_n2">N2</code></td>
<td>
<p>Number of samples for the (S)tabilisation step</p>
</td></tr>
<tr><td><code id="SMART_+3A_n3">N3</code></td>
<td>
<p>Number of samples for the (C)onvergence step</p>
</td></tr>
<tr><td><code id="SMART_+3A_nu">Nu</code></td>
<td>
<p>Size of the first Design of Experiments</p>
</td></tr>
<tr><td><code id="SMART_+3A_lambda1">lambda1</code></td>
<td>
<p>Relaxing parameter for MH algorithm at step L</p>
</td></tr>
<tr><td><code id="SMART_+3A_lambda2">lambda2</code></td>
<td>
<p>Relaxing parameter for MH algorithm at step S</p>
</td></tr>
<tr><td><code id="SMART_+3A_lambda3">lambda3</code></td>
<td>
<p>Relaxing parameter for MH algorithm at step C</p>
</td></tr>
<tr><td><code id="SMART_+3A_tune_cost">tune_cost</code></td>
<td>
<p>Input for tuning cost paramter of the SVM</p>
</td></tr>
<tr><td><code id="SMART_+3A_tune_gamma">tune_gamma</code></td>
<td>
<p>Input for tuning gamma parameter of the SVM</p>
</td></tr>
<tr><td><code id="SMART_+3A_clusterinmargin">clusterInMargin</code></td>
<td>
<p>Enforce selected clusterised points to be in margin</p>
</td></tr>
<tr><td><code id="SMART_+3A_alpha_margin">alpha_margin</code></td>
<td>
<p>a real value defining the margin. While
1 is the &lsquo;real&rsquo; margin for a SVM, one can decide here to
stretch it a bit.</p>
</td></tr>
<tr><td><code id="SMART_+3A_k1">k1</code></td>
<td>
<p>Rank of the first iteration of step S</p>
</td></tr>
<tr><td><code id="SMART_+3A_k2">k2</code></td>
<td>
<p>Rank of the first iteration of step C</p>
</td></tr>
<tr><td><code id="SMART_+3A_k3">k3</code></td>
<td>
<p>Rank of the last iteration of step C</p>
</td></tr>
<tr><td><code id="SMART_+3A_x">X</code></td>
<td>
<p>Coordinates of alredy known points</p>
</td></tr>
<tr><td><code id="SMART_+3A_y">y</code></td>
<td>
<p>Value of the LSF on these points</p>
</td></tr>
<tr><td><code id="SMART_+3A_failure">failure</code></td>
<td>
<p>Failure threshold</p>
</td></tr>
<tr><td><code id="SMART_+3A_limit_fun_mh">limit_fun_MH</code></td>
<td>
<p>Define an area of exclusion with a limit function</p>
</td></tr>
<tr><td><code id="SMART_+3A_sampling_strategy">sampling_strategy</code></td>
<td>
<p>Either MH for Metropolis-Hastings of AR for accept-reject</p>
</td></tr>
<tr><td><code id="SMART_+3A_seeds">seeds</code></td>
<td>
<p>If some points are already known to be in the subdomain defined
by <code>limit_fun_MH</code></p>
</td></tr>
<tr><td><code id="SMART_+3A_seeds_eval">seeds_eval</code></td>
<td>
<p>Value of the metamodel on these points</p>
</td></tr>
<tr><td><code id="SMART_+3A_burnin">burnin</code></td>
<td>
<p>Burnin parameter for MH</p>
</td></tr>
<tr><td><code id="SMART_+3A_thinning">thinning</code></td>
<td>
<p>Thinning parameter for MH</p>
</td></tr>
<tr><td><code id="SMART_+3A_plot">plot</code></td>
<td>
<p>Set to TRUE for a full plot, ie. refresh at each iteration</p>
</td></tr>
<tr><td><code id="SMART_+3A_limited_plot">limited_plot</code></td>
<td>
<p>Set to TRUE for a final plot with final DOE, metamodel and LSF</p>
</td></tr>
<tr><td><code id="SMART_+3A_add">add</code></td>
<td>
<p>If plots are to be added to the current device</p>
</td></tr>
<tr><td><code id="SMART_+3A_output_dir">output_dir</code></td>
<td>
<p>If plots are to be saved in jpeg in a given directory</p>
</td></tr>
<tr><td><code id="SMART_+3A_z_mh">z_MH</code></td>
<td>
<p>For plots, if the limit_fun_MH has already been evaluated on the grid</p>
</td></tr>
<tr><td><code id="SMART_+3A_z_lsf">z_lsf</code></td>
<td>
<p>For plots, if LSF has already been evaluated on the grid</p>
</td></tr>
<tr><td><code id="SMART_+3A_verbose">verbose</code></td>
<td>
<p>Either 0 for almost no output, 1 for medium size output and 2
for all outputs</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SMART</code> is a reliability method proposed by J.-M. Bourinet et al. It makes
uses of a SVM-based metamodel to approximate the limit state function and calculates
the failure probability with a crude Monte-Carlo method using the metamodel-based
limit state function. As SVM is a classification method, it makes use of limit state
function values to create two classes : greater and lower than the failure threshold.
Then the border is taken as a surogate of the limit state function.
</p>
<p>Concerning the refinement strategy, it distinguishes 3 stages, known as Localisation,
Stalibilsation and Convergence stages. The first one is proposed to reduce the margin
as much as possible, the second one focuses on switching points while the last one works
on the final Monte-Carlo population and is designed to insure a strong margin;
see F. Deheeger PhD thesis for more information.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the failure probability and some more outputs as described below:
</p>
<table>
<tr><td><code>proba</code></td>
<td>
<p>The estimated failure probability.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>The coefficient of variation of the Monte-Carlo probability estimate.</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>The total number of calls to the <code>limit_state_function</code>.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>The final learning database, ie. all points where <code>lsf</code> has been calculated.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The value of the <code>limit_state_function</code> on the learning database.</p>
</td></tr>
<tr><td><code>meta_fun</code></td>
<td>
<p>The metamodel approximation of the <code>limit_state_function</code>.
A call output is a list containing the value and the standard deviation.</p>
</td></tr>
<tr><td><code>meta_model</code></td>
<td>
<p>The final metamodel.</p>
</td></tr>
<tr><td><code>points</code></td>
<td>
<p>Points in the failure domain according to the metamodel.</p>
</td></tr>
<tr><td><code>meta_eval</code></td>
<td>
<p>Evaluation of the metamodel on these points.</p>
</td></tr>
<tr><td><code>z_meta</code></td>
<td>
<p>If <code>plot</code>==TRUE, the evaluation of the metamodel on the plot grid.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Problem is supposed to be defined in the standard space. If not, use <code><a href="#topic+UtoX">UtoX</a></code>
to do so.
</p>
<p>Furthermore, each time a set of vector is defined as a matrix,
&lsquo;nrow&rsquo; = <code>dimension</code> and &lsquo;ncol&rsquo; = number of vector.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>J.-M. Bourinet, F. Deheeger, M. Lemaire:<br />
<em>Assessing small failure probabilities by combined Subset Simulation and Support Vector Machines</em><br />
Structural Safety (2011)
</p>
</li>
<li>
<p>F. Deheeger:<br />
<em>Couplage mecano-fiabiliste : 2SMART - methodologie d'apprentissage stochastique en fiabilite</em><br />
PhD. Thesis, Universite Blaise Pascal - Clermont II, 2008
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+SubsetSimulation">SubsetSimulation</a></code>
<code><a href="#topic+MonteCarlo">MonteCarlo</a></code>
<code><a href="e1071.html#topic+svm">svm</a></code> (in package <span class="pkg">e1071</span>)
<code><a href="#topic+S2MART">S2MART</a></code>
</p>

<hr>
<h2 id='SubsetSimulation'>Subset Simulation Monte Carlo</h2><span id='topic+SubsetSimulation'></span><span id='topic+ss'></span><span id='topic+subset'></span>

<h3>Description</h3>

<p>Estimate a probability of failure with the Subset Simulation algorithm (also known as
Multilevel Splitting or Sequential Monte Carlo for rare events).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SubsetSimulation(
  dimension,
  lsf,
  p_0 = 0.1,
  N = 10000,
  q = 0,
  lower.tail = TRUE,
  K,
  thinning = 20,
  save.all = FALSE,
  plot = FALSE,
  plot.level = 5,
  plot.lsf = TRUE,
  output_dir = NULL,
  plot.lab = c("x", "y"),
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SubsetSimulation_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of the input space.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_lsf">lsf</code></td>
<td>
<p>the function defining failure/safety domain.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_p_0">p_0</code></td>
<td>
<p>a cutoff probability for defining the subsets.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_n">N</code></td>
<td>
<p>the number of samples per subset, ie the population size for the Monte
Carlo estimation of each conditional probability.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_q">q</code></td>
<td>
<p>the quantile defining the failure domain.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_lower.tail">lower.tail</code></td>
<td>
<p>as for pxxxx functions, TRUE for estimating P(lsf(X) &lt; q), FALSE
for P(lsf(X) &gt; q)</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_k">K</code></td>
<td>
<p>a transition Kernel for Markov chain drawing in the regeneration step.
K(X) should propose a matrix of candidate sample (same dimension as X) on which
<code>lsf</code> will be then evaluated and transition accepted of rejected. Default
kernel is the one defined K(X) = (X + sigma*W)/sqrt(1 + sigma^2) with W ~ N(0, 1).</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_thinning">thinning</code></td>
<td>
<p>a thinning parameter for the the regeneration step.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_save.all">save.all</code></td>
<td>
<p>if TRUE, all the samples generated during the algorithms are saved
and return at the end. Otherwise only the working population is kept at each
iteration.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_plot">plot</code></td>
<td>
<p>to plot the generated samples.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_plot.level">plot.level</code></td>
<td>
<p>maximum number of expected levels for color consistency. If number of
levels exceeds this value, the color scale will change according to
<code>ggplot2</code> default policy.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_plot.lsf">plot.lsf</code></td>
<td>
<p>a boolean indicating if the <code>lsf</code> should be added to the
plot. This requires the evaluation of the <code>lsf</code> over a grid and
consequently should be used only for illustation purposes.</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_output_dir">output_dir</code></td>
<td>
<p>to save the plot into a pdf file. This variable will
be paster with
&quot;_Subset_Simulation.pdf&quot;</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_plot.lab">plot.lab</code></td>
<td>
<p>the x and y labels for the plot</p>
</td></tr>
<tr><td><code id="SubsetSimulation_+3A_verbose">verbose</code></td>
<td>
<p>Either 0 for almost no output, 1 for medium size output and 2 for all outputs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm uses the property of conditional probabilities on nested subsets
to calculate a given probability defined by a limit state function.
</p>
<p>It operates iteratively on &lsquo;populations&rsquo; to estimate the quantile
corresponding to a probability of <code>p_0</code>. Then, it generates
samples conditionnaly to this threshold, until found threshold be lower
than 0.
</p>
<p>Finally, the estimate is the product of the conditional probabilities.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the failure probability and
some more outputs as described below:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>the estimated failure probability.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>the estimated coefficient of variation of the estimate.</p>
</td></tr>
<tr><td><code>Ncall</code></td>
<td>
<p>the total number of calls to the <code>lsf</code>.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the working population.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the value lsf(X).</p>
</td></tr>
<tr><td><code>Xtot</code></td>
<td>
<p>if <code>save.list==TRUE</code>, all the <code>Ncall</code> samples generated by
the algorithm.</p>
</td></tr>
<tr><td><code>Ytot</code></td>
<td>
<p>the value lsf(Xtot).</p>
</td></tr>
<tr><td><code>sigma.hist</code></td>
<td>
<p>if default kernel is used, sigma is initialized with 0.3 and
then further adaptively updated to have an average acceptance rate of 0.3</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Problem is supposed to be defined in the standard space. If not, use <code><a href="#topic+UtoX">UtoX</a></code>
to do so. Furthermore, each time a set of vector is defined as a matrix, &lsquo;nrow&rsquo;
= <code>dimension</code> and &lsquo;ncol&rsquo; = number of vector to be consistent with
<code>as.matrix</code> transformation of a vector.
</p>
<p>Algorithm calls lsf(X) (where X is a matrix as defined previously) and expects a vector
in return. This allows the user to optimise the computation of a batch of points,
either by vectorial computation, or by the use of external codes (optimised C or
C++ codes for example) and/or parallel computation; see examples in <a href="#topic+MonteCarlo">MonteCarlo</a>.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>S.-K. Au, J. L. Beck:<br />
<em>Estimation of small failure probabilities in high dimensions by Subset Simulation</em> <br />
Probabilistic Engineering Mechanics (2001)<br />
</p>
</li>
<li><p> A. Guyader, N. Hengartner and E. Matzner-Lober:<br />
<em>Simulation and estimation of extreme quantiles and extreme
probabilities</em><br />
Applied Mathematics and Optimization, 64(2), 171-196.<br />
</p>
</li>
<li><p> F. Cerou, P. Del Moral, T. Furon and A. Guyader:<br />
<em>Sequential Monte Carlo for rare event estimation</em><br />
Statistics and Computing, 22(3), 795-808.<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+IRW">IRW</a></code>
<code><a href="#topic+MP">MP</a></code>
<code><a href="#topic+MonteCarlo">MonteCarlo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Try Subset Simulation Monte Carlo on a given function and change number of points.
 
## Not run: 
 res = list()
 res[[1]] = SubsetSimulation(2,kiureghian,N=10000)
 res[[2]] = SubsetSimulation(2,kiureghian,N=100000)
 res[[3]] = SubsetSimulation(2,kiureghian,N=500000)

## End(Not run)

# Compare SubsetSimulation with MP
## Not run: 
p &lt;- res[[3]]$p # get a reference value for p
p_0 &lt;- 0.1 # the default value recommended by Au and Beck
N_mp &lt;- 100
# to get approxumately the same number of calls to the lsf
N_ss &lt;- ceiling(N_mp*log(p)/log(p_0))
comp &lt;- replicate(50, {
ss &lt;- SubsetSimulation(2, kiureghian, N = N_ss)
mp &lt;- MP(2, kiureghian, N = N_mp, q = 0)
comp &lt;- c(ss$p, mp$p, ss$Ncall, mp$Ncall)
names(comp) = rep(c("SS", "MP"), 2)
comp
})
boxplot(t(comp[1:2,])) # check accuracy
sd.comp &lt;- apply(comp,1,sd)
print(sd.comp[1]/sd.comp[2]) # variance increase in SubsetSimulation compared to MP

colMeans(t(comp[3:4,])) # check similar number of calls

## End(Not run)

</code></pre>

<hr>
<h2 id='testConvexity'>Test the convexity of set of data</h2><span id='topic+testConvexity'></span>

<h3>Description</h3>

<p>Provides the 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  testConvexity(X,Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="testConvexity_+3A_x">X</code></td>
<td>
<p>a matrix containing the data sets</p>
</td></tr>
<tr><td><code id="testConvexity_+3A_y">Y</code></td>
<td>
<p>a vector containing -1 or +1 that reprensents the class of each elements of X.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>testConvexity test if one of the two data set is potentially convex.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the number of the class which is convex and the parameters of a set of hyperplanes separating the two classes
</p>


<h3>Author(s)</h3>

<p>Vincent Moutoussamy<br />
</p>


<h3>References</h3>


<ul>
<li>
<p>R.T. Rockafellar:<br />
<em>Convex analysis</em><br />
Princeton university press, 2015.<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+LSVM">LSVM</a></code>
<code><a href="#topic+modelLSVM">modelLSVM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# A limit state function
f &lt;- function(x){  sqrt(sum(x^2)) - sqrt(2)/2 }

# Creation of the data sets
n &lt;- 200
X &lt;- matrix(runif(2*n), nrow = n)
Y &lt;- apply(X, MARGIN = 1, function(w){sign(f(w))})

## Not run: 
  TEST.Convexity &lt;- testConvexity(X, Y)
  if(length(TEST.Convexity) == 2){
    Convexity &lt;- TEST.Convexity[[1]] 
    model.A   &lt;- TEST.Convexity[[2]]
  }
  if(length(TEST.Convexity) == 1){
    # The problem is not convex
    Convexity &lt;- 0 #the problem is not convex
  }

## End(Not run)

</code></pre>

<hr>
<h2 id='twodof'>A limit-state-function defined with a two degrees of freedom damped oscillator</h2><span id='topic+twodof'></span><span id='topic+oscillator_d8'></span>

<h3>Description</h3>

<p>The limit-state function is defined in the standard space and isoprobabilistic transformation is used internally.
</p>
<p>Parameters <code>mean_Fs</code> and <code>p</code> can be specified and default are 27.5 and 3 respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twodof</code></pre>


<h3>Format</h3>

<p>The function can handle a vector or a matrix with column vectors.</p>


<h3>References</h3>

<p>Dubourg, V and Deheeger, F and Sudret, B:<br />
<em>Metamodel-based importance sampling for the simulation of rare events</em><br />
arXiv preprint arXiv:1104.3476, 2011.<br />
</p>

<hr>
<h2 id='updateLSVM'>Update LSVM classifier</h2><span id='topic+updateLSVM'></span>

<h3>Description</h3>

<p>Update the existing classifier LSVM with a new set of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  updateLSVM(X.new,
             Y.new,
             X,
             Y,
             A.model.lsvm,
             convexity,
             PLOTSVM = FALSE,
             step.plot.LSVM = 1,
             hyperplanes = FALSE,
             limit.state.estimate = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="updateLSVM_+3A_x.new">X.new</code></td>
<td>
<p>a matrix containing a new data sets</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_y.new">Y.new</code></td>
<td>
<p>a vector containing -1 or +1 that reprensents the class of each elements of X.new.</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_x">X</code></td>
<td>
<p>a matrix containing the data sets</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_y">Y</code></td>
<td>
<p>a vector containing -1 or +1 that reprensents the class of each elements of X.</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_a.model.lsvm">A.model.lsvm</code></td>
<td>
<p>a matrix containing the parameters of all hyperplanes.</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_convexity">convexity</code></td>
<td>
<p>Either -1 if the set of data associated to the label &quot;-1&quot; is convex or +1 otherwise.</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_plotsvm">PLOTSVM</code></td>
<td>
<p>A boolean. If TRUE, plot the data.</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_step.plot.lsvm">step.plot.LSVM</code></td>
<td>
<p>A plot is made each <code>step.plot.LSVM</code> steps.</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_hyperplanes">hyperplanes</code></td>
<td>
<p>A boolean. If TRUE, plot the hyperplanes obtained.</p>
</td></tr>
<tr><td><code id="updateLSVM_+3A_limit.state.estimate">limit.state.estimate</code></td>
<td>
<p>A boolean. If TRUE, plot the estimate of the limit state.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>updateLSVM allows to make an update of the classifier LSVM.
</p>


<h3>Value</h3>

<p>An object of class <code>matrix</code> containing the parameters of a set of hyperplanes
</p>


<h3>Note</h3>

<p>The argument PLOTSVM is useful only in dimension 2.
</p>


<h3>Author(s)</h3>

<p>Vincent Moutoussamy<br />
</p>


<h3>References</h3>


<ul>
<li>
<p>R.T. Rockafellar:<br />
<em>Convex analysis</em><br />
Princeton university press, 2015.<br />
</p>
</li>
<li>
<p>N. Bousquet, T. Klein and V. Moutoussamy :<br />
<em>Approximation of limit state surfaces in monotonic Monte Carlo settings</em><br />
Submitted .<br />
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+LSVM">LSVM</a></code>
<code><a href="#topic+modelLSVM">modelLSVM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# A limit state function
f &lt;- function(x){  sqrt(sum(x^2)) - sqrt(2)/2 }

# Creation of the data sets

n &lt;- 200
X &lt;- matrix(runif(2*n), nrow = n)
Y &lt;- apply(X, MARGIN = 1, function(w){sign(f(w))})

## Not run: 
  model.A &lt;- modelLSVM(X,Y, convexity = -1)
  M &lt;- 20
  X.new &lt;- matrix(runif(2*M), nrow = M)
  Y.new &lt;- apply(X.new, MARGIN = 1, function(w){ sign(f(w))})

  X.new.S &lt;- X.new[which(Y.new &gt; 0), ]
  Y.new.S &lt;- Y.new[which(Y.new &gt; 0)]
  model.A.new &lt;- updateLSVM(X.new.S, Y.new.S, X, Y,
                            model.A, convexity = -1, PLOTSVM = TRUE, step.plot.LSVM = 5)

## End(Not run)

</code></pre>

<hr>
<h2 id='updateSd'>UpdateSd</h2><span id='topic+updateSd'></span>

<h3>Description</h3>

<p>Update kriging variance when adding new points to the DoE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updateSd(
  X.new,
  integration.points.oldsd,
  model,
  precalc.data,
  integration.points
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="updateSd_+3A_x.new">X.new</code></td>
<td>
<p>the d x N matrix containing the points added to the model for
the update of the kriging variance.</p>
</td></tr>
<tr><td><code id="updateSd_+3A_integration.points.oldsd">integration.points.oldsd</code></td>
<td>
<p>a vector containing the standard deviation
of the points to be added to the metamodel learning database.</p>
</td></tr>
<tr><td><code id="updateSd_+3A_model">model</code></td>
<td>
<p>the current kriging model (a <code>km</code> object).</p>
</td></tr>
<tr><td><code id="updateSd_+3A_precalc.data">precalc.data</code></td>
<td>
<p>precomputed data from KrigInv::precomputeUpdateData.</p>
</td></tr>
<tr><td><code id="updateSd_+3A_integration.points">integration.points</code></td>
<td>
<p>points where the updated sd is to be calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector containing the kriging sd at points <code>integration.points</code>
</p>

<hr>
<h2 id='updateSd.old'>UpdateSd.old</h2><span id='topic+updateSd.old'></span>

<h3>Description</h3>

<p>UpdateSd.old
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updateSd.old(X.new, newdata.oldsd, model, precalc.data, integration.points)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="updateSd.old_+3A_x.new">X.new</code></td>
<td>
<p>the d x N matrix containing the points added to the model for
the update of the kriging variance.</p>
</td></tr>
<tr><td><code id="updateSd.old_+3A_newdata.oldsd">newdata.oldsd</code></td>
<td>
<p>a vector containing the standard deviation
of the points to be added to the metamodel learning database.</p>
</td></tr>
<tr><td><code id="updateSd.old_+3A_model">model</code></td>
<td>
<p>the current kriging model (a <code>km</code> object).</p>
</td></tr>
<tr><td><code id="updateSd.old_+3A_precalc.data">precalc.data</code></td>
<td>
<p>precomputed data from KrigInv::precomputeUpdateData.</p>
</td></tr>
<tr><td><code id="updateSd.old_+3A_integration.points">integration.points</code></td>
<td>
<p>points where the updated sd is to be calculated.</p>
</td></tr>
</table>

<hr>
<h2 id='UtoX'>Iso-probabilistic transformation from U space to X space</h2><span id='topic+UtoX'></span>

<h3>Description</h3>

<p><code>UtoX</code> performs as iso-probabilistic transformation from standardized space (U) to physical space (X) according to the NATAF transformation, which requires only to know the means, the standard deviations, the correlation matrix <code class="reqn">\rho(Xi,Xj) = \rho_{ij}</code> and the marginal distributions of Xi.
In standard space, all random variables are uncorrelated standard normal distributed variables whereas they are correlated and defined using the following distribution functions: Normal (or Gaussian), Lognormal, Uniform, Gumbel, Weibull and Gamma.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> UtoX(U, input.margin, L0) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UtoX_+3A_u">U</code></td>
<td>
<p>a matrix containing the realisation of all random variables in U-space</p>
</td></tr>
<tr><td><code id="UtoX_+3A_input.margin">input.margin</code></td>
<td>
<p> A list containing one or more list defining the marginal distribution functions of all random variables to be used </p>
</td></tr>
<tr><td><code id="UtoX_+3A_l0">L0</code></td>
<td>
<p>the lower matrix of the Cholesky decomposition of correlation matrix R0 (result of <code><a href="#topic+ModifCorrMatrix">ModifCorrMatrix</a></code>) </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Supported distributions are :
</p>

<ul>
<li><p> NORMAL: distribution, defined by its mean and standard deviation </p>
<p style="text-align: center;"><code class="reqn">distX &lt;- list(type="Norm", MEAN=0.0, STD=1.0, NAME="X1")</code>
</p>

</li>
<li><p> LOGNORMAL: distribution, defined by its internal parameters P1=meanlog and P2=sdlog (<code><a href="stats.html#topic+plnorm">plnorm</a></code>) </p>
<p style="text-align: center;"><code class="reqn">distX &lt;- list(type="Lnorm", P1=10.0, P2=2.0, NAME="X2")</code>
</p>

</li>
<li><p> UNIFORM: distribution, defined by its internal parameters P1=min and P2=max (<code><a href="stats.html#topic+punif">punif</a></code>) </p>
<p style="text-align: center;"><code class="reqn">distX &lt;- list(type="Unif",P1=2.0, P2=6.0, NAME="X3")</code>
</p>

</li>
<li><p> GUMBEL: distribution, defined by its internal parameters P1 and P2 </p>
<p style="text-align: center;"><code class="reqn">distX &lt;- list(type='Gumbel',P1=6.0, P2=2.0, NAME='X4')</code>
</p>

</li>
<li><p> WEIBULL: distribution, defined by its internal parameters P1=shape and P2=scale (<code><a href="stats.html#topic+pweibull">pweibull</a></code>) </p>
<p style="text-align: center;"><code class="reqn">distX &lt;- list(type='Weibull', P1=NULL, P2=NULL, NAME='X5')</code>
</p>

</li>
<li><p> GAMMA: distribution, defined by its internal parameters P1=shape and P2=scale (<code><a href="stats.html#topic+pgamma">pgamma</a></code>) </p>
<p style="text-align: center;"><code class="reqn">distX &lt;- list(type='Gamma', P1=6.0, P2=6.0, NAME='X6')</code>
</p>

</li>
<li><p> BETA: distribution, defined by its internal parameters P1=shape1 and P2=shapze2 (<code><a href="stats.html#topic+pbeta">pbeta</a></code>) </p>
<p style="text-align: center;"><code class="reqn">distX &lt;- list(type='Beta', P1=6.0, P2=6.0, NAME='X7')</code>
</p>

</li></ul>


<h3>Value</h3>

 
<table>
<tr><td><code>X</code></td>
<td>
<p>a matrix containing the realisation of all random variables in X-space</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> gilles DEFAUX, <a href="mailto:gilles.defaux@cea.fr">gilles.defaux@cea.fr</a> </p>


<h3>References</h3>


<ul>
<li><p> M. Lemaire, A. Chateauneuf and J. Mitteau. Structural reliability, Wiley Online Library, 2009
</p>
</li>
<li><p> V. Dubourg, Meta-modeles adaptatifs pour l'analyse de fiabilite et l'optimisation sous containte fiabiliste, PhD Thesis, Universite Blaise Pascal - Clermont II,2011
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ModifCorrMatrix">ModifCorrMatrix</a></code>, <code><a href="#topic+ComputeDistributionParameter">ComputeDistributionParameter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
Dim = 2

distX1 &lt;- list(type='Norm',  MEAN=0.0, STD=1.0, P1=NULL, P2=NULL, NAME='X1')
distX2 &lt;- list(type='Norm',  MEAN=0.0, STD=1.0, P1=NULL, P2=NULL, NAME='X2')

input.margin &lt;- list(distX1,distX2)
input.Rho    &lt;- matrix( c(1.0, 0.5,
                          0.5, 1.0),nrow=Dim)
input.R0     &lt;- ModifCorrMatrix(input.Rho)
L0           &lt;- t(chol(input.R0))

lsf = function(U) {   
    X &lt;- UtoX(U, input.margin, L0)
    G &lt;- 5.0 - 0.2*(X[1,]-X[2,])^2.0 - (X[1,]+X[2,])/sqrt(2.0)
    return(G)
}

u0 &lt;- as.matrix(c(1.0,-0.5))
lsf(u0)
</code></pre>

<hr>
<h2 id='waarts'>A limit-state-function defined by Waarts</h2><span id='topic+waarts'></span>

<h3>Description</h3>

<p>The limit-state function is defined by:
</p>
<p style="text-align: center;"><code class="reqn"> b1 = 3 + (u_1-u_2)^2/10 - sign(u_1 + u_2)*(u_1+u_2)/sqrt(2) </code>
</p>

<p style="text-align: center;"><code class="reqn"> b2 = sign(u_2-u_1)*(u_1-u_2)+7/sqrt(2) </code>
</p>

<p style="text-align: center;"><code class="reqn"> f(u) = min(b1, b2) </code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>waarts</code></pre>


<h3>Format</h3>

<p>The function can handle a vector or matrix with column vectors.</p>


<h3>References</h3>

<p>Waarts, PH:<br />
<em>An appraisal of DARS: directional adaptive response surface sampling</em><br />
Delft University Press, The Netherlands, 2000.<br />
</p>

<hr>
<h2 id='WilksFormula'>Sample size by Wilks formula</h2><span id='topic+WilksFormula'></span>

<h3>Description</h3>

<p>Compute Wilks formula for setting size of a i.i.d. sample for quantile estimation with confidence level or for tolerance intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WilksFormula(alpha=0.95,beta=0.95,bilateral=FALSE,order=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WilksFormula_+3A_alpha">alpha</code></td>
<td>

<p>order of the quantile (default = 0.95)
</p>
</td></tr>
<tr><td><code id="WilksFormula_+3A_beta">beta</code></td>
<td>

<p>level of the confidence interval (default = 0.95)
</p>
</td></tr>
<tr><td><code id="WilksFormula_+3A_bilateral">bilateral</code></td>
<td>

<p>TRUE for bilateral quantile (default = unilateral = FALSE)
</p>
</td></tr>
<tr><td><code id="WilksFormula_+3A_order">order</code></td>
<td>

<p>order of the Wilks formula (default = 1)
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>N</code></td>
<td>
<p>The minimal sample size to apply Wilks formula</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Lemaitre and Bertrand Iooss
</p>


<h3>References</h3>

<p>H.A. David and H.N. Nagaraja. Order statistics, Wiley, 2003.
</p>
<p>W.T. Nutt and G.B. Wallis. Evaluation of nuclear safety from the outputs of computer codes in the presence of uncertainties. Reliability Engineering and System Safety, 83:57-77, 2004.
</p>
<p>S.S. Wilks. Determination of Sample Sizes for Setting Tolerance Limits. Annals Mathematical Statistics, 12:91-96, 1941.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
N &lt;- WilksFormula(0.95,0.95,order=1)
print(N)
</code></pre>

<hr>
<h2 id='XtoU'>From X to standard space</h2><span id='topic+XtoU'></span>

<h3>Description</h3>

<p>XtoU lets transform datapoint in the original space X to the standard Gaussian
space U with isoprobalisitc transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XtoU(X, input.margin, L0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="XtoU_+3A_x">X</code></td>
<td>
<p>the matrix d x n of the input points</p>
</td></tr>
<tr><td><code id="XtoU_+3A_input.margin">input.margin</code></td>
<td>
<p>A list containing one or more list defining the marginal distribution
functions of all random variables to be used</p>
</td></tr>
<tr><td><code id="XtoU_+3A_l0">L0</code></td>
<td>
<p>the lower matrix of the Cholesky decomposition of correlation matrix R0
(result of <code><a href="#topic+ModifCorrMatrix">ModifCorrMatrix</a></code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clement.walter@cea.fr">clement.walter@cea.fr</a>
</p>


<h3>See Also</h3>

<p><code>UtoX</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
