<!DOCTYPE html><html lang="en"><head><title>Help for package nlmrt</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nlmrt}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#nlmrt-package'>
<p>Tools for solving nonlinear least squares problems. UNDER DEVELOPMENT.</p></a></li>
<li><a href='#coef.nlmrt'><p>Output model coefficients for nlmrt object.</p></a></li>
<li><a href='#model2grfun'><p>Generate a gradient function from a nonlinear model expression</p>
and a vector of named parameters.</a></li>
<li><a href='#model2jacfun'><p>Generate a Jacobian matrix function from a nonlinear model expression</p>
and a vector of named parameters.</a></li>
<li><a href='#model2resfun'><p>Generate a residual function from a nonlinear model expression</p>
and a vector of named parameters.</a></li>
<li><a href='#model2ssfun'><p>Generate a sum of squares objective function from a nonlinear model expression</p>
and a vector of named parameters.</a></li>
<li><a href='#modgr'><p>Compute gradient from residuals and Jacobian.</p></a></li>
<li><a href='#modss'><p>Compute gradient from residuals and Jacobian.</p></a></li>
<li><a href='#nlfb'><p>Nash variant of Marquardt nonlinear least squares solution via</p>
qr linear solver.</a></li>
<li><a href='#nlxb'><p>Nash variant of Marquardt nonlinear least squares solution via</p>
qr linear solver.</a></li>
<li><a href='#print.nlmrt'><p>Print method for an object of class nlmrt.</p></a></li>
<li><a href='#summary.nlmrt'><p>Summary output for nlmrt object.</p></a></li>
<li><a href='#wrapnls'><p>Nash variant of Marquardt nonlinear least squares solution via</p>
qr linear solver.</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functions for Nonlinear Least Squares Solutions</td>
</tr>
<tr>
<td>Version:</td>
<td>2016.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-3-2</td>
</tr>
<tr>
<td>Author:</td>
<td>John C. Nash [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>John C. Nash &lt;nashjc@uottawa.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Replacement for nls() tools for working with nonlinear least squares problems.
      The calling structure is similar to, but much simpler than, that of the nls()
      function. Moreover, where nls() specifically does NOT deal with small or zero
      residual problems, nlmrt is quite happy to solve them. It also attempts to be
      more robust in finding solutions, thereby avoiding 'singular gradient' messages
      that arise in the Gauss-Newton method within nls(). The Marquardt-Nash approach
      in nlmrt generally works more reliably to get a solution, though this may be 
      one of a set of possibilities, and may also be statistically unsatisfactory.
      Added print and summary as of August 28, 2012.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>minpack.lm, optimx, Rvmmin, Rcgmin, numDeriv</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-03-04 16:30:35 UTC; john</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-03-04 23:57:39</td>
</tr>
</table>
<hr>
<h2 id='nlmrt-package'>
Tools for solving nonlinear least squares problems. UNDER DEVELOPMENT.
</h2><span id='topic+nlmrt-package'></span><span id='topic+nlmrt'></span>

<h3>Description</h3>

<p>The package provides some tools related to using the Nash variant
of Marquardt's algorithm for nonlinear least squares. 
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> nlmrt</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2012-03-05</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>This package includes methods for solving nonlinear least squares problems
specified by a modeling expression and given a starting vector of named 
paramters. Note: You must provide an expression of the form
lhs ~ rhsexpression
so that the residual expression 
rhsexpression - lhs
can be computed. The expression can be enclosed in quotes, and this seems to give
fewer difficulties with R. Data variables must already be defined, either within 
the parent environment or else in the dot-arguments. Other symbolic elements in
the modeling expression must be standard functions or else parameters that are 
named in the start vector.
</p>
<p>The main functions in <code>nlmrt</code> are:
</p>
<pre>
   nlfb - Nash variant of the Marquardt procedure for nonlinear least squares,
	with bounds constraints, using a residual and optionally Jacobian
	described as \code{R} functions. 
    20120803: Todo: Make masks more consistent between nlfb and nlxb.

   nlxb - Nash variant of the Marquardt procedure for nonlinear least squares,
	with bounds constraints, using an expression to describe the residual via
        an \code{R} modeling expression. The Jacobian is computed via symbolic
	differentiation.
            
   wrapnls - Uses nlxb to solve nonlinear least squares then calls nls() to
            create an object of type nls.

   model2grfun.R - Generate a gradient vector function from a nonlinear 
        model expression and a vector of named parameters.

   model2jacfun.R - Generate a Jacobian matrix function from a nonlinear 
        model expression and a vector of named parameters.

   model2resfun.R - Generate a residual vector function from a nonlinear 
        model expression and a vector of named parameters.

   model2ssfun.R - Generate a sum of squares objective function from a 
        nonlinear model expression and a vector of named parameters.

   modgr.R - compute gradient of the sum of squares function using the 
        Jacobian and residuals for a nonlinear least squares problem
      
   modss.R - computer the sum of squares function from the residuals of
        a nonlinear least squares problem

   myfn.R, mygr.R, myjac.R, myres.R, myss.R - dummy functions that seem to
       be needed so there is an available handle for output of functions that
       generate various functions from expressions.

</pre> 
<p>For testing purposes, there are also some experimental codes using different 
internal computations for the linear algebraic sub-problems in the inst/dev-codes/
sub-folder.
</p>


<h3>Author(s)</h3>

<p> John C Nash 
</p>
<p>Maintainer:  &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>
<p>others!!??
</p>


<h3>See Also</h3>

<p><code>nls</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>rm(list=ls())
# library(nlmrt)

# traceval set TRUE to debug or give full history
traceval  &lt;-  FALSE

## Problem in 1 parameter to ensure methods work in trivial case

cat("Problem in 1 parameter to ensure methods work in trivial case\n")
nobs&lt;-8
tt &lt;- seq(1,nobs)
dd &lt;- 1.23*tt + 4*runif(nobs)

df &lt;- data.frame(tt, dd)

a1par&lt;-nlxb(dd ~ a*tt, start=c(a=1), data=df)
a1par


# Data for Hobbs problem
cat("Hobbs weed problem -- unscaled\n")
ydat  &lt;-  c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 
          38.558, 50.156, 62.948, 75.995, 91.972) # for testing
y  &lt;-  ydat  # for testing
tdat  &lt;-  seq_along(ydat) # for testing

eunsc  &lt;-   y ~ b1/(1+b2*exp(-b3*tt))

cat("Hobbs unscaled with data in data frames\n")

weeddata1  &lt;-  data.frame(y=ydat, tt=tdat)
# scale the data 
weeddata2  &lt;-  data.frame(y=1.5*ydat, tt=tdat)
start1  &lt;-  c(b1=1, b2=1, b3=1)
anlxb1  &lt;-  try(nlxb(eunsc, start=start1, trace=traceval, data=weeddata1))
print(anlxb1)

anlxb2  &lt;-  try(nlxb(eunsc, start=start1, trace=traceval, data=weeddata2))
print(anlxb2)

# Problem 2 - Gabor Grothendieck 2016-3-2

cat("Gabor G problem with zero residuals\n")

DF &lt;- data.frame(x = c(5, 4, 3, 2, 1), y = c(1, 2, 3, 4, 5))
library(nlmrt)
nlxb1 &lt;- nlxb(y ~ A * x + B, data = DF, start = c(A = 1, B = 6), trace=TRUE)
print(nlxb1)

# tmp &lt;- readline("continue with start at the minimum -- failed on 2014 version. ")

nlxb0 &lt;- nlxb(y ~ A * x + B, data = DF, start = c(A = -1, B = 6), trace=TRUE)
print(nlxb0) 

## Not run: 
# WARNING -- using T can get confusion with TRUE
tt  &lt;-  tdat
# A simple starting vector -- must have named parameters for nlxb, nls, wrapnls.

cat("GLOBAL DATA\n")

anls1g  &lt;-  try(nls(eunsc, start=start1, trace=traceval))
print(anls1g)

cat("GLOBAL DATA AND EXPRESSION -- SHOULD FAIL\n")
anlxb1g  &lt;-  try(nlxb(eunsc, start=start1, trace=traceval))
print(anlxb1g)


## End(Not run) # end dontrun

rm(y)
rm(tt)


startf1  &lt;-  c(b1=1, b2=1, b3=.1)


## Not run: 

## With BOUNDS

anlxb1  &lt;-  try(nlxb(eunsc, start=startf1, lower=c(b1=0, b2=0, b3=0), 
      upper=c(b1=500, b2=100, b3=5), trace=traceval, data=weeddata1))
print(anlxb1)


## End(Not run) # end dontrun


# Check nls too
## Not run: 
cat("check nls result\n")
anlsb1  &lt;-  try(nls(eunsc, start=start1, lower=c(b1=0, b2=0, b3=0), 
     upper=c(b1=500, b2=100, b3=5), trace=traceval, data=weeddata1, 
             algorithm='port'))
print(anlsb1)

# tmp  &lt;-  readline("next")


## End(Not run) # end dontrun

## Not run: 

anlxb2  &lt;-  try(nlxb(eunsc, start=start1, lower=c(b1=0, b2=0, b3=0), 
        upper=c(b1=500, b2=100, b3=.25), trace=traceval, data=weeddata1))
print(anlxb2)


anlsb2  &lt;-  try(nls(eunsc, start=start1, lower=c(b1=0, b2=0, b3=0), 
                upper=c(b1=500, b2=100, b3=.25), trace=traceval, 
                data=weeddata1, algorithm='port'))
print(anlsb2)

# tmp  &lt;-  readline("next")

## End(Not run) # end dontrun


## Not run: 
cat("UNCONSTRAINED\n")
an1q  &lt;-  try(nlxb(eunsc, start=start1, trace=traceval, data=weeddata1))
print(an1q)
# tmp  &lt;-  readline("next")

## End(Not run) # end dontrun


## Not run: 
cat("TEST MASKS\n")

anlsmnqm  &lt;-  try(nlxb(eunsc, start=start1, lower=c(b1=0, b2=0, b3=0), 
   upper=c(b1=500, b2=100, b3=5), masked=c("b2"), trace=traceval, data=weeddata1))
print(anlsmnqm)

## End(Not run) # end dontrun


## Not run: 

cat("MASKED\n")

an1qm3  &lt;-  try(nlxb(eunsc, start=start1, trace=traceval, data=weeddata1, 
                masked=c("b3")))
print(an1qm3)
# tmp  &lt;-  readline("next")

# Note that the parameters are put in out of order to test code.
an1qm123  &lt;-  try(nlxb(eunsc, start=start1, trace=traceval, data=weeddata1, 
                  masked=c("b2","b1","b3")))
print(an1qm123)
# tmp  &lt;-  readline("next")


## End(Not run) # end dontrun


cat("BOUNDS test problem for Hobbs")
start2  &lt;-  c(b1=100, b2=10, b3=0.1)
an1qb1  &lt;-  try(nlxb(eunsc, start=start2, trace=traceval, data=weeddata1, 
                     lower=c(0,0,0), upper=c(200, 60, .3)))
print(an1qb1)

## tmp  &lt;-  readline("next")


cat("BOUNDS and MASK")

## Not run: 

an1qbm2  &lt;-  try(nlxb(eunsc, start=start2, trace=traceval, data=weeddata1, 
                      lower=c(0,0,0), upper=c(200, 60, .3), masked=c("b2")))
print(an1qbm2)

# tmp  &lt;-  readline("next")


## End(Not run) # end dontrun


escal  &lt;-   y ~ 100*b1/(1+10*b2*exp(-0.1*b3*tt))
suneasy  &lt;-  c(b1=200, b2=50, b3=0.3)
ssceasy  &lt;-  c(b1=2, b2=5, b3=3)
st1scal  &lt;-  c(b1=100, b2=10, b3=0.1)


cat("EASY start -- unscaled")
anls01  &lt;-  try(nls(eunsc, start=suneasy, trace=traceval, data=weeddata1))
print(anls01)
anlmrt01  &lt;-  try(nlxb(eunsc, start=ssceasy, trace=traceval, data=weeddata1))
print(anlmrt01)

## Not run: 

cat("All 1s start -- unscaled")
anls02  &lt;-  try(nls(eunsc, start=start1, trace=traceval, data=weeddata1))
if (class(anls02) == "try-error") {
   cat("FAILED:")
   print(anls02)
} else {
   print(anls02)
}
anlmrt02  &lt;-  nlxb(eunsc, start=start1, trace=traceval, data=weeddata1)
print(anlmrt02)

cat("ones start -- scaled")
anls03  &lt;-  try(nls(escal, start=start1, trace=traceval, data=weeddata1))
print(anls03)
anlmrt03  &lt;-  nlxb(escal, start=start1, trace=traceval, data=weeddata1)
print(anlmrt03)

cat("HARD start -- scaled")
anls04  &lt;-  try(nls(escal, start=st1scal, trace=traceval, data=weeddata1))
print(anls04)
anlmrt04  &lt;-  nlxb(escal, start=st1scal, trace=traceval, data=weeddata1)
print(anlmrt04)

cat("EASY start -- scaled")
anls05  &lt;-  try(nls(escal, start=ssceasy, trace=traceval, data=weeddata1))
print(anls05)
anlmrt05  &lt;-  nlxb(escal, start=ssceasy, trace=traceval, data=weeddata1)
print(anlmrt03)


## End(Not run) # end dontrun


## Not run: 

shobbs.res  &lt;-  function(x){ # scaled Hobbs weeds problem -- residual
# This variant uses looping
    if(length(x) != 3) stop("hobbs.res -- parameter vector n!=3")
    y  &lt;-  c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 
             38.558, 50.156, 62.948, 75.995, 91.972)
    tt  &lt;-  1:12
    res  &lt;-  100.0*x[1]/(1+x[2]*10.*exp(-0.1*x[3]*tt)) - y
}
 
shobbs.jac  &lt;-  function(x) { # scaled Hobbs weeds problem -- Jacobian
    jj  &lt;-  matrix(0.0, 12, 3)
    tt  &lt;-  1:12
    yy  &lt;-  exp(-0.1*x[3]*tt)
    zz  &lt;-  100.0/(1+10.*x[2]*yy)
    jj[tt,1]   &lt;-   zz
    jj[tt,2]   &lt;-   -0.1*x[1]*zz*zz*yy
    jj[tt,3]   &lt;-   0.01*x[1]*zz*zz*yy*x[2]*tt
    return(jj)
}

cat("try nlfb\n")
st  &lt;-  c(b1=1, b2=1, b3=1)
low  &lt;-  -Inf
up &lt;- Inf

ans1 &lt;- nlfb(st, shobbs.res, shobbs.jac, trace=traceval)
ans1
cat("No jacobian function -- use internal approximation\n")
ans1n &lt;- nlfb(st, shobbs.res, trace=TRUE, control=list(watch=TRUE)) # NO jacfn
ans1n

# tmp &lt;- readline("Try with bounds at 2")
time2 &lt;- system.time(ans2 &lt;- nlfb(st, shobbs.res, shobbs.jac, upper=c(2,2,2), 
                                  trace=traceval))
ans2
time2



## End(Not run) # end dontrun

## Not run: 

cat("BOUNDS")
st2s &lt;- c(b1=1, b2=1, b3=1)

an1qb1 &lt;- try(nlxb(escal, start=st2s, trace=traceval, data=weeddata1, 
  lower=c(0,0,0), upper=c(2, 6, 3), control=list(watch=FALSE)))
print(an1qb1)

# tmp &lt;- readline("next")

ans2 &lt;- nlfb(st2s,shobbs.res, shobbs.jac, lower=c(0,0,0), upper=c(2, 6, 3), 
   trace=traceval, control=list(watch=FALSE))
print(ans2)

cat("BUT ... nls() seems to do better from the TRACE information\n")
anlsb &lt;- nls(escal, start=st2s, trace=traceval, data=weeddata1, lower=c(0,0,0),
     upper=c(2,6,3), algorithm='port')
cat("However, let us check the answer\n")
print(anlsb)
cat("BUT...crossprod(resid(anlsb))=",crossprod(resid(anlsb)),"\n")


## End(Not run) # end dontrun


# tmp &lt;- readline("next")

cat("Try wrapnls\n")
traceval &lt;- FALSE
# Data for Hobbs problem
ydat &lt;- c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 
          38.558, 50.156, 62.948, 75.995, 91.972) # for testing
tdat &lt;- seq_along(ydat) # for testing
start1 &lt;- c(b1=1, b2=1, b3=1)
escal &lt;-  y ~ 100*b1/(1+10*b2*exp(-0.1*b3*tt))
up1 &lt;- c(2,6,3)
up2 &lt;- c(1, 5, 9)

weeddata1 &lt;- data.frame(y=ydat, tt=tdat)

an1w &lt;- try(wrapnls(escal, start=start1, trace=traceval, data=weeddata1))
print(an1w)


## Not run: 

cat("BOUNDED wrapnls\n")

an1wb &lt;- try(wrapnls(escal, start=start1, trace=traceval, data=weeddata1, upper=up1))
print(an1wb)


cat("BOUNDED wrapnls\n")

an2wb &lt;- try(wrapnls(escal, start=start1, trace=traceval, data=weeddata1, upper=up2))
print(an2wb)

cat("TRY MASKS ONLY\n")

an1xm3 &lt;- try(nlxb(escal, start1, trace=traceval, data=weeddata1, 
                   masked=c("b3")))
printsum(an1xm3)
an1fm3 &lt;- try(nlfb(start1, shobbs.res, shobbs.jac, trace=traceval, 
                   data=weeddata1, maskidx=c(3)))
printsum(an1fm3)

an1xm1 &lt;- try(nlxb(escal, start1, trace=traceval, data=weeddata1, 
                   masked=c("b1")))
printsum(an1xm1)
an1fm1 &lt;- try(nlfb(start1, shobbs.res, shobbs.jac, trace=traceval, 
                   data=weeddata1, maskidx=c(1)))
printsum(an1fm1)


## End(Not run) # end dontrun

# Need to check when all parameters masked.??

## Not run: 


cat("\n\n Now check conversion of expression to function\n\n")
cat("K Vandepoel function\n")

x &lt;- c(1,3,5,7) # data
y &lt;- c(37.98,11.68,3.65,3.93)
penetrationks28 &lt;- data.frame(x=x,y=y)

cat("Try nls() -- note the try() function!\n")

fit0  &lt;-  try(nls(y ~ (a+b*exp(1)^(-c * x)), data = penetrationks28, 
    start = c(a=0,b = 1,c=1), trace = TRUE))
print(fit0)

cat("\n\n")

fit1  &lt;-  nlxb(y ~ (a+b*exp(-c*x)), data = penetrationks28, 
   start = c(a=0,b=1,c=1), trace = TRUE) 
printsum(fit1)

mexprn &lt;- "y ~ (a+b*exp(-c*x))"
pvec &lt;- c(a=0,b=1,c=1)
bnew &lt;- c(a=10,b=3,c=4)

k.r &lt;- model2resfun(mexprn , pvec)
k.j &lt;- model2jacfun(mexprn , pvec)
k.f &lt;- model2ssfun(mexprn , pvec)
k.g &lt;- model2grfun(mexprn , pvec)


cat("At pvec:")
print(pvec)
rp &lt;- k.r(pvec, x=x, y=y)
cat(" rp=")
print(rp)
rf &lt;- k.f(pvec, x=x, y=y)
cat(" rf=")
print(rf)
rj &lt;- k.j(pvec, x=x, y=y)
cat(" rj=")
print(rj)
rg &lt;- k.g(pvec, x=x, y=y)
cat(" rg=")
print(rg)
cat("modss at pvec gives ")
print(modss(pvec, k.r, x=x, y=y))
cat("modgr at pvec gives ")
print(modgr(pvec, k.r, k.j, x=x, y=y))
cat("\n\n")

cat("At bnew:")
print(bnew)
rb &lt;- k.r(bnew, x=x, y=y)
cat(" rb=")
print(rb)
rf &lt;- k.f(bnew, x=x, y=y)
cat(" rf=")
print(rf)
rj &lt;- k.j(bnew, x=x, y=y)
cat(" rj=")
print(rj)
rg &lt;- k.g(bnew, x=x, y=y)
cat(" rg=")
print(rg)
cat("modss at bnew gives ")
print(modss(bnew, k.r, x=x, y=y))
cat("modgr at bnew gives ")
print(modgr(bnew, k.r, k.j, x=x, y=y))
cat("\n\n")


## End(Not run)  ## end of dontrun


</code></pre>

<hr>
<h2 id='coef.nlmrt'>Output model coefficients for nlmrt object.
</h2><span id='topic+coef.nlmrt'></span>

<h3>Description</h3>

<p><code>coef.nlmrt</code> extracts and displays the coefficients for a model 
estimated by <code>nlxb</code> or <code>nlfb</code> in the <code>nlmrt</code> structured
<code>object</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    ## S3 method for class 'nlmrt'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.nlmrt_+3A_object">object</code></td>
<td>

<p>An object of class 'nlmrt'
</p>
</td></tr>
<tr><td><code id="coef.nlmrt_+3A_...">...</code></td>
<td>

<p>Any data needed for the function. We do not know of any!
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coef.nlmrt</code> extracts and displays the coefficients for a model 
estimated by <code>nlxb</code> or <code>nlfb</code>. 
</p>


<h3>Value</h3>

<p>returns the coefficients from the nlmrt object.
</p>


<h3>Note</h3>

<p>Special notes, if any, will appear here.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>

<hr>
<h2 id='model2grfun'>Generate a gradient function from a nonlinear model expression
and a vector of named parameters.
</h2><span id='topic+model2grfun'></span>

<h3>Description</h3>

<p>Given a nonlinear model expressed as an expression of the form
lhs ~ formula_for_rhs
and a start vector where parameters used in the model formula are named,
attempts to build the the <code>R</code> function for the gradient of the 
residual sum of squares.
As a side effect, a text file with the program code is generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   model2grfun(modelformula, pvec, funname="mygr", filename=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model2grfun_+3A_modelformula">modelformula</code></td>
<td>

<p>This is a modeling formula of the form (as in <code>nls</code>)
lhsvar ~ rhsexpression
for example,
y ~ b1/(1+b2*exp(-b3*tt))
You may also give this as a string.
</p>
</td></tr>
<tr><td><code id="model2grfun_+3A_pvec">pvec</code></td>
<td>

<p>A named parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
WARNING: the parameters in the output function will be used in the 
order presented in this vector. Names are NOT respected in the 
output function. 
</p>
</td></tr>
<tr><td><code id="model2grfun_+3A_funname">funname</code></td>
<td>

<p>The (optional) name for the function that is generated in the file
named in the next argument. The default name is 'mygr'.
</p>
</td></tr> 
<tr><td><code id="model2grfun_+3A_filename">filename</code></td>
<td>

<p>The (optional) name of a file that is written containing the (text) program code
for the function. If NULL, no file is written.
</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>None.
</p>


<h3>Value</h3>

<p>An <code>R</code> function object that computes the gradient of the sum of 
squared residuals of a nonlinear model at a set of parameters. 
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  cat("See also examples in nlmrt-package.Rd\n")
  require(numDeriv)
  y &lt;- c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 38.558, 
      50.156, 62.948, 75.995, 91.972)  # for testing
  tt &lt;- seq_along(y)  # for testing
  f &lt;- y ~ b1/(1 + b2 * exp(-1 * b3 * tt))
  p &lt;- c(b1 = 1, b2 = 1, b3 = 1)
  mygr &lt;- model2grfun(f, p)
  myss &lt;- model2ssfun(f, p) # for check
  cat("mygr:\n")
  print(mygr)
  
  ans &lt;- mygr(p, tt = tt, y = y)
  print(ans)
  gnum &lt;- grad(myss, p, tt = tt, y = y)
  cat("Max(abs(ans-gnum)) = ",max(abs(ans-gnum)),"\n")

  bnew &lt;- c(b1 = 200, b2 = 50, b3 = 0.3)
  ans &lt;- mygr(prm = bnew, tt = tt, y = y)
  print(ans)
  gnum &lt;- grad(myss, bnew, tt = tt, y = y)
  cat("Max(abs(ans-gnum)) = ",max(abs(ans-gnum)),"\n")
  
  cat("Test with un-named vector\n")  # At 20120424 should fail
  bthree &lt;- c(100, 40, 0.1)
  ans &lt;- mygr(prm = bthree, tt = tt, y = y)
  print(ans)
  gnum &lt;- grad(myss, bthree, tt = tt, y = y)
  cat("Max(abs(ans-gnum)) = ",max(abs(ans-gnum)),"\n")
</code></pre>

<hr>
<h2 id='model2jacfun'>Generate a Jacobian matrix function from a nonlinear model expression
and a vector of named parameters.
</h2><span id='topic+model2jacfun'></span>

<h3>Description</h3>

<p>Given a nonlinear model expressed as an expression of the form
lhs ~ formula_for_rhs
and a start vector where parameters used in the model formula are named,
attempts to build the the <code>R</code> function for the Jacobian of the residuals.
As a side effect, a text file with the program code is generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   model2jacfun(modelformula, pvec, funname="myjac", filename=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model2jacfun_+3A_modelformula">modelformula</code></td>
<td>

<p>This is a modeling formula of the form (as in <code>nls</code>)
lhsvar ~ rhsexpression
for example,
y ~ b1/(1+b2*exp(-b3*tt))
You may also give this as a string.
</p>
</td></tr>
<tr><td><code id="model2jacfun_+3A_pvec">pvec</code></td>
<td>

<p>A named parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
WARNING: the parameters in the output function will be used in the 
order presented in this vector. Names are NOT respected in the 
output function. 
</p>
</td></tr>
<tr><td><code id="model2jacfun_+3A_funname">funname</code></td>
<td>

<p>The (optional) name for the function that is generated in the file
named in the next argument. The default name is 'myjac'.
</p>
</td></tr> 
<tr><td><code id="model2jacfun_+3A_filename">filename</code></td>
<td>

<p>The (optional) name of a file that is written containing the (text) program code
for the function. If NULL, no file is written.
</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>None.
</p>


<h3>Value</h3>

<p>An <code>R</code> function object that computes the Jacobian of the nonlinear
model at a set of parameters.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  cat("See also examples in nlmrt-package.Rd\n")
  require(numDeriv)
  y &lt;- c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 38.558, 
      50.156, 62.948, 75.995, 91.972)  # for testing
  tt &lt;- seq_along(y)  # for testing
  f &lt;- y ~ b1/(1 + b2 * exp(-1 * b3 * tt))
  p &lt;- c(b1 = 1, b2 = 1, b3 = 1)
  myfn &lt;- model2jacfun(f, p)
  myres &lt;- model2resfun(f, p)
  cat("myfn:\n")
  print(myfn)
  
  ans &lt;- myfn(p, tt = tt, y = y)
  print(ans)
  Jnum&lt;-jacobian(myres, p,  tt = tt, y = y)
  cat("max(abs(ans-Jnum)) = ",max(abs(ans-Jnum)),"\n")

  bnew &lt;- c(b1 = 200, b2 = 50, b3 = 0.3)
  ans &lt;- myfn(prm = bnew, tt = tt, y = y)
  print(ans)
  Jnum&lt;-jacobian(myres, bnew,  tt = tt, y = y)
  cat("max(abs(ans-Jnum)) = ",max(abs(ans-Jnum)),"\n")
  
  cat("Test with un-named vector\n")  # At 20120424 should fail
  bthree &lt;- c(100, 40, 0.1)
  ans &lt;- try(myfn(prm = bthree, tt = tt, y = y))
  print(ans)
  Jnum&lt;-jacobian(myres, bthree,  tt = tt, y = y)
  cat("max(abs(ans-Jnum)) = ",max(abs(ans-Jnum)),"\n")
</code></pre>

<hr>
<h2 id='model2resfun'>Generate a residual function from a nonlinear model expression
and a vector of named parameters.
</h2><span id='topic+model2resfun'></span>

<h3>Description</h3>

<p>Given a nonlinear model expressed as an expression of the form
lhs ~ formula_for_rhs
and a start vector where parameters used in the model formula are named,
attempts to build the the <code>R</code> function for the residuals of the model.
As a side effect, a text file with the program code is generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   model2resfun(modelformula, pvec, funname="myres", filename=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model2resfun_+3A_modelformula">modelformula</code></td>
<td>

<p>This is a modeling formula of the form (as in <code>nls</code>)
lhsvar ~ rhsexpression
for example,
y ~ b1/(1+b2*exp(-b3*tt))
You may also give this as a string.
</p>
</td></tr>
<tr><td><code id="model2resfun_+3A_pvec">pvec</code></td>
<td>

<p>A named parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
WARNING: the parameters in the output function will be used in the 
order presented in this vector. Names are NOT respected in the 
output function. 
</p>
</td></tr>
<tr><td><code id="model2resfun_+3A_funname">funname</code></td>
<td>

<p>The (optional) name for the function that is generated in the file
named in the next argument. The default name is 'myres'.
</p>
</td></tr> 
<tr><td><code id="model2resfun_+3A_filename">filename</code></td>
<td>

<p>The (optional) name of a file that is written containing the (text) program code
for the function. If NULL, no file is written.
</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>None.
</p>


<h3>Value</h3>

<p>An <code>R</code> function object that computes the gradient of the sum of 
squared residuals of a nonlinear model at a set of parameters. 
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  cat("See also examples in nlmrt-package.Rd\n")
    # a test
  y &lt;- c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 38.558, 
      50.156, 62.948, 75.995, 91.972)  # for testing
  tt &lt;- seq_along(y)  # for testing
  # NOTE: use of t gives confusion with t() in R CMD check,
  # but not in direct use with source() 120429
  f &lt;- y ~ b1/(1 + b2 * exp(-1 * b3 * tt))
  p &lt;- c(b1 = 1, b2 = 1, b3 = 1)
  myres &lt;- model2resfun(f, p)
  cat("myres:\n")
  print(myres)
  ans &lt;- myres(p, tt = tt, y = y)  
  cat("ans:")  
  print(ans)
  cat("ss ( =? 23520.58):", as.numeric(crossprod(ans)),"\n")
  bnew &lt;- c(b1 = 200, b2 = 50, b3 = 0.3)
  # anew&lt;-myres(prm=bnew, t=t, y=y) # Note issue with t vs
  # t()
  anew &lt;- eval(myres(prm = bnew, tt = tt, y = y))
  cat("anew:")
  print(anew)
  cat("ss ( =? 158.2324):", as.numeric(crossprod(anew)),"\n")
  cat("Test with vector of un-named parameters\n")
  bthree &lt;- c(100, 40, 0.1)
  athree &lt;- try(myres(prm = bthree, tt = tt, y = y))
  print(athree)
  cat("ss ( =? 19536.65):", as.numeric(crossprod(athree)),"\n")
</code></pre>

<hr>
<h2 id='model2ssfun'>Generate a sum of squares objective function from a nonlinear model expression
and a vector of named parameters.
</h2><span id='topic+model2ssfun'></span>

<h3>Description</h3>

<p>Given a nonlinear model expressed as an expression of the form
lhs ~ formula_for_rhs
and a start vector where parameters used in the model formula are named,
attempts to build the the <code>R</code> function for the residual sum of squares.
As a side effect, a text file with the program code is generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   model2ssfun(modelformula, pvec, funname="myss", filename=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model2ssfun_+3A_modelformula">modelformula</code></td>
<td>

<p>This is a modeling formula of the form (as in <code>nls</code>)
lhsvar ~ rhsexpression
for example,
y ~ b1/(1+b2*exp(-b3*tt))
You may also give this as a string.
</p>
</td></tr>
<tr><td><code id="model2ssfun_+3A_pvec">pvec</code></td>
<td>

<p>A named parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
WARNING: the parameters in the output function will be used in the 
order presented in this vector. Names are NOT respected in the 
output function. 
</p>
</td></tr>
<tr><td><code id="model2ssfun_+3A_funname">funname</code></td>
<td>

<p>The (optional) name for the function that is generated in the file
named in the next argument. The default name is 'myss'.
</p>
</td></tr> 
<tr><td><code id="model2ssfun_+3A_filename">filename</code></td>
<td>

<p>The (optional) name of a file that is written containing the (text) program code
for the function. If NULL, no file is written.
</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>None.
</p>


<h3>Value</h3>

<p>An <code>R</code> function object that computes the sum of squares of the 
residuals of the nonlinear model at a set of parameters.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # a test
  y &lt;- c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 38.558, 
      50.156, 62.948, 75.995, 91.972)  # for testing
  tt &lt;- seq_along(y)  # for testing
  f &lt;- y ~ b1/(1 + b2 * exp(-1 * b3 * tt))
  p &lt;- c(b1 = 1, b2 = 1, b3 = 1)
  myfn &lt;- model2ssfun(f, p)
  cat("myfn: \n")
  print(myfn) # list the function
  cat("Compute the function at several points\n")
  ans &lt;- myfn(p, tt = tt, y = y)
  print(ans) # should be  23520.58
  bnew &lt;- c(b1 = 200, b2 = 50, b3 = 0.3)
  anew &lt;- myfn(prm = bnew, tt = tt, y = y)
  print(anew)# should be  158.2324
  
  cat("Test with vector of un-named parameters \n")
  bthree &lt;- c(100, 40, 0.1)
  athree &lt;- try(myfn(prm = bthree, tt = tt, y = y))
  print(athree) # should be 19536.65
</code></pre>

<hr>
<h2 id='modgr'>Compute gradient from residuals and Jacobian.
</h2><span id='topic+modgr'></span>

<h3>Description</h3>

<p>For a nonlinear model originally expressed as an expression of the form
lhs ~ formula_for_rhs
assume we have a resfn and jacfn that compute the residuals and the 
Jacobian at a set of parameters. This routine computes the gradient, 
that is, t(Jacobian) . residuals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   modgr(prm, resfn, jacfn, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modgr_+3A_prm">prm</code></td>
<td>

<p>A parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
However, the names are NOT used, only positions in the vector.
</p>
</td></tr>
<tr><td><code id="modgr_+3A_resfn">resfn</code></td>
<td>

<p>A function to compute the residuals of our model at a parameter vector.
</p>
</td></tr>
<tr><td><code id="modgr_+3A_jacfn">jacfn</code></td>
<td>

<p>A function to compute the Jacobian of the residuals at a paramter vector.
</p>
</td></tr>
<tr><td><code id="modgr_+3A_...">...</code></td>
<td>

<p>Any data needed for computation of the residual vector from the expression
rhsexpression - lhsvar. Note that this is the negative of the usual residual,
but the sum of squares is the same.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>modgr</code> calls resfn to compute residuals and jacfn to compute the
Jacobian at the parameters <code>prm</code> using external data in the dot arguments.
It then computes the gradient using t(Jacobian) . residuals.
</p>
<p>Note that it appears awkward to use this function in calls to optimization
routines. The author would like to learn why. 
</p>


<h3>Value</h3>

<p>The numeric vector with the gradient of the sum of squares at the paramters.
</p>


<h3>Note</h3>

<p>Special notes, if any, will appear here.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  cat("See examples in nlmrt-package.Rd\n")
  y &lt;- c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 38.558, 
      50.156, 62.948, 75.995, 91.972)  # for testing
  tt &lt;- seq_along(y)  # for testing
  f &lt;- y ~ b1/(1 + b2 * exp(-1 * b3 * tt))
  p &lt;- c(b1 = 1, b2 = 1, b3 = 1)
  myres &lt;- model2resfun(f, p)
  myjac &lt;- model2jacfun(f, p)
  mygr  &lt;- model2grfun(f, p)
  gr &lt;- mygr(p, tt = tt, y = y)
  grm &lt;- modgr(p, myres, myjac, tt = tt, y = y)
  cat("max(abs(grm - gr)) =",max(abs(grm-gr)),"\n")
</code></pre>

<hr>
<h2 id='modss'>Compute gradient from residuals and Jacobian.
</h2><span id='topic+modss'></span>

<h3>Description</h3>

<p>For a nonlinear model originally expressed as an expression of the form
lhs ~ formula_for_rhs
assume we have a resfn and jacfn that compute the residuals and the 
Jacobian at a set of parameters. This routine computes the gradient, 
that is, t(Jacobian) 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   modss(prm, resfn, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modss_+3A_prm">prm</code></td>
<td>

<p>A parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
However, the names are NOT used, only positions in the vector.
</p>
</td></tr>
<tr><td><code id="modss_+3A_resfn">resfn</code></td>
<td>

<p>A function to compute the residuals of our model at a parameter vector.
</p>
</td></tr> 
<tr><td><code id="modss_+3A_...">...</code></td>
<td>

<p>Any data needed for computation of the residual vector from the expression
rhsexpression - lhsvar. Note that this is the negative of the usual residual,
but the sum of squares is the same.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>modss</code> calls resfn to compute residuals and then uses <code>crossprod</code>
to compute the sum of squares. 
</p>
<p>At 2012-4-26 there is no checking for errors. 
</p>
<p>Note that it appears awkward to use this function in calls to optimization
routines. The author would like to learn why. 
</p>


<h3>Value</h3>

<p>The numeric value of the sum of squares at the paramters.
</p>


<h3>Note</h3>

<p>Special notes, if any, will appear here.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>
<p>others!!
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  cat("See examples in nlmrt-package.Rd\n")
  y &lt;- c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 38.558, 
      50.156, 62.948, 75.995, 91.972)  # for testing
  tt &lt;- seq_along(y)  # for testing
  f &lt;- y ~ b1/(1 + b2 * exp(-1 * b3 * tt))
  p &lt;- c(b1 = 1, b2 = 1, b3 = 1)
  myres &lt;- model2resfun(f, p)
  myssval &lt;- modss(p, myres, tt = tt, y = y)
  cat("ss at (1,1,1) (should be 23520.58) = ",myssval,"\n")
</code></pre>

<hr>
<h2 id='nlfb'>Nash variant of Marquardt nonlinear least squares solution via
qr linear solver.
</h2><span id='topic+nlfb'></span>

<h3>Description</h3>

<p>Given a nonlinear model expressed as an expression of the form
lhs ~ formula_for_rhs
and a start vector where parameters used in the model formula are named,
attempts to find the minimum of the residual sum of squares using the
Nash variant (Nash, 1979) of the Marquardt algorithm, where the linear 
sub-problem is solved by a qr method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   nlfb(start, resfn, jacfn=NULL, trace=FALSE, lower=-Inf, upper=Inf, 
         maskidx=NULL, control, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nlfb_+3A_resfn">resfn</code></td>
<td>

<p>A function that evaluates the residual vector for computing the elements of
the sum of squares function at the set of parameters <code>start</code>. 
</p>
</td></tr>
<tr><td><code id="nlfb_+3A_jacfn">jacfn</code></td>
<td>

<p>A function that evaluates the Jacobian of the sum of squares function, that
is, the matrix of partial derivatives of the residuals with respect to each
of the parameters. If NULL (default), uses an approximation.
?? put in character form as in optimx??
</p>
</td></tr>
<tr><td><code id="nlfb_+3A_start">start</code></td>
<td>

<p>A named parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
<code>nls()</code> takes a list, and that is permitted here also.
</p>
</td></tr>
<tr><td><code id="nlfb_+3A_trace">trace</code></td>
<td>

<p>Logical TRUE if we want intermediate progress to be reported. Default is FALSE.
</p>
</td></tr> 
<tr><td><code id="nlfb_+3A_lower">lower</code></td>
<td>

<p>Lower bounds on the parameters. If a single number, this will be applied to all
parameters. Default -Inf.
</p>
</td></tr> 
<tr><td><code id="nlfb_+3A_upper">upper</code></td>
<td>

<p>Upper bounds on the parameters. If a single number, this will be applied to all
parameters. Default Inf.
</p>
</td></tr> 
<tr><td><code id="nlfb_+3A_maskidx">maskidx</code></td>
<td>

<p>Vector if indices of the parameters to be masked. These parameters will NOT be altered
by the algorithm. Note that the mechanism here is different from that in <code>nlxb</code>
which uses the names of the parameters.
</p>
</td></tr> 
<tr><td><code id="nlfb_+3A_control">control</code></td>
<td>
 
<p>A list of controls for the algorithm. These are:
</p>

<dl>
<dt><code>watch</code></dt><dd><p>Monitor progress if TRUE. Default is FALSE.</p>
</dd>
<dt><code>phi</code></dt><dd><p>Default is phi=1, which adds phi*Identity to Jacobian inner product.</p>
</dd>
<dt><code>lamda</code></dt><dd><p>Initial Marquardt adjustment (Default 0.0001). Odd spelling is deliberate.</p>
</dd>
<dt><code>offset</code></dt><dd><p>Shift to test for floating-point equality. Default is 100.</p>
</dd>
<dt><code>laminc</code></dt><dd><p>Factor to use to increase lamda. Default is 10.</p>
</dd>
<dt><code>lamdec</code></dt><dd><p>Factor to use to decrease lamda is lamdec/laminc. Default lamdec=4.</p>
</dd>
<dt><code>femax</code></dt><dd><p>Maximum function (sum of squares) evaluations. Default is 10000,
which is extremely aggressive.</p>
</dd>
<dt><code>jemax</code></dt><dd><p>Maximum number of Jacobian evaluations. Default is 5000.</p>
</dd>
<dt><code>ndstep</code></dt><dd><p>Stepsize to use to computer numerical Jacobian approximatin. Default
is 1e-7.</p>
</dd>
<dt><code>rofftest</code></dt><dd><p>Default is TRUE. Use a termination test of the relative offset 
orthogonality type. Useful for nonlinear regression problems.</p>
</dd>
<dt><code>smallsstest</code></dt><dd><p>Default is TRUE. Exit the function if the sum of squares falls
below (100 * .Machine$double.eps)^4 times the initial sumsquares. This is a test
for a &ldquo;small&rdquo; sum of squares, but there are problems which are very extreme 
for which this control needs to be set FALSE.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="nlfb_+3A_...">...</code></td>
<td>

<p>Any data needed for computation of the residual vector from the expression
rhsexpression - lhsvar. Note that this is the negative of the usual residual,
but the sum of squares is the same. It is not clear how the dot variables should
be used, since data should be in 'data'.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nlfb</code> attempts to solve the nonlinear sum of squares problem by using
a variant of Marquardt's approach to stabilizing the Gauss-Newton method using
the Levenberg-Marquardt adjustment. This is explained in Nash (1979 or 1990) in
the sections that discuss Algorithm 23.
</p>
<p>In this code, we solve the (adjusted) Marquardt equations by use of the 
<code>qr.solve()</code>. Rather than forming the J'J + lambda*D matrix, we augment
the J matrix with extra rows and the y vector with null elements. 
</p>


<h3>Value</h3>

<p>A list of the following items
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>A named vector giving the parameter values at the supposed solution.</p>
</td></tr>
<tr><td><code>ssquares</code></td>
<td>
<p>The sum of squared residuals at this set of parameters.</p>
</td></tr>
<tr><td><code>resid</code></td>
<td>
<p>The residual vector at the returned parameters.</p>
</td></tr>
<tr><td><code>jacobian</code></td>
<td>
<p>The jacobian matrix (partial derivatives of residuals w.r.t. the parameters)
at the returned parameters.</p>
</td></tr>
<tr><td><code>feval</code></td>
<td>
<p>The number of residual evaluations (sum of squares computations) used.</p>
</td></tr>
<tr><td><code>jeval</code></td>
<td>
<p>The number of Jacobian evaluations used.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Special notes, if any, will appear here.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>
<p>others!!
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cat("See examples in nlmrt-package.Rd\n")

</code></pre>

<hr>
<h2 id='nlxb'>Nash variant of Marquardt nonlinear least squares solution via
qr linear solver.
</h2><span id='topic+nlxb'></span>

<h3>Description</h3>

<p>Given a nonlinear model expressed as an expression of the form
lhs ~ formula_for_rhs
and a start vector where parameters used in the model formula are named,
attempts to find the minimum of the residual sum of squares using the
Nash variant (Nash, 1979) of the Marquardt algorithm, where the linear 
sub-problem is solved by a qr method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   nlxb(formula, start, trace=FALSE, data, lower=-Inf, upper=Inf, 
        masked=NULL, control, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nlxb_+3A_formula">formula</code></td>
<td>

<p>This is a modeling formula of the form (as in <code>nls</code>)
lhsvar ~ rhsexpression
for example,
y ~ b1/(1+b2*exp(-b3*tt))
You may also give this as a string.
</p>
</td></tr>
<tr><td><code id="nlxb_+3A_start">start</code></td>
<td>

<p>A named parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
</p>
</td></tr>
<tr><td><code id="nlxb_+3A_trace">trace</code></td>
<td>

<p>Logical TRUE if we want intermediate progress to be reported. Default is FALSE.
</p>
</td></tr> 
<tr><td><code id="nlxb_+3A_data">data</code></td>
<td>

<p>A data frame containing the data of the variables in the formula. This data may,
however, be supplied directly in the parent frame. 
</p>
</td></tr> 
<tr><td><code id="nlxb_+3A_lower">lower</code></td>
<td>

<p>Lower bounds on the parameters. If a single number, this will be applied to all
parameters. Default -Inf.
</p>
</td></tr> 
<tr><td><code id="nlxb_+3A_upper">upper</code></td>
<td>

<p>Upper bounds on the parameters. If a single number, this will be applied to all
parameters. Default Inf.
</p>
</td></tr> 
<tr><td><code id="nlxb_+3A_masked">masked</code></td>
<td>

<p>Character vector of quoted parameter names. These parameters will NOT be altered
by the algorithm.
</p>
</td></tr> 
<tr><td><code id="nlxb_+3A_control">control</code></td>
<td>
 
<p>A list of controls for the algorithm. These are:
</p>

<dl>
<dt><code>watch</code></dt><dd><p>Monitor progress if TRUE. Default is FALSE.</p>
</dd>
<dt><code>phi</code></dt><dd><p>Default is phi=1, which adds phi*Identity to 
Jacobian inner product.</p>
</dd>
<dt><code>lamda</code></dt><dd><p>Initial Marquardt adjustment (Default 0.0001). 
Odd spelling is deliberate.</p>
</dd>
<dt><code>offset</code></dt><dd><p>Shift to test for floating-point equality. 
Default is 100.</p>
</dd>
<dt><code>laminc</code></dt><dd><p>Factor to use to increase lamda. Default is 10.</p>
</dd>
<dt><code>lamdec</code></dt><dd><p>Factor to use to decrease lamda is lamdec/laminc. 
Default lamdec=4.</p>
</dd>
<dt><code>femax</code></dt><dd><p>Maximum function (sum of squares) evaluations. 
Default is 10000, which is extremely aggressive.</p>
</dd>
<dt><code>jemax</code></dt><dd><p>Maximum number of Jacobian evaluations. 
Default is 5000.</p>
</dd>
<dt><code>rofftest</code></dt><dd><p>Default is TRUE. Use a termination test of the relative offset 
orthogonality type. Useful for nonlinear regression problems.</p>
</dd>
<dt><code>smallsstest</code></dt><dd><p>Default is TRUE. Exit the function if the sum of squares falls
below (100 * .Machine$double.eps)^4 times the initial sumsquares. This is a test
for a &ldquo;small&rdquo; sum of squares, but there are problems which are very extreme 
for which this control needs to be set FALSE.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="nlxb_+3A_...">...</code></td>
<td>

<p>Any data needed for computation of the residual vector from the 
expression rhsexpression - lhsvar. Note that this is the negative 
of the usual residual, but the sum of squares is the same.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nlxb</code> attempts to solve the nonlinear sum of squares problem by using
a variant of Marquardt's approach to stabilizing the Gauss-Newton method using
the Levenberg-Marquardt adjustment. This is explained in Nash (1979 or 1990) in
the sections that discuss Algorithm 23. (?? do we want a vignette. Yes, because
folk don't have access to book easily, but finding time.)
</p>
<p>In this code, we solve the (adjusted) Marquardt equations by use of the 
<code>qr.solve()</code>. Rather than forming the J'J + lambda*D matrix, we augment
the J matrix with extra rows and the y vector with null elements. 
</p>


<h3>Value</h3>

<p>A list of the following items
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>A named vector giving the parameter values at the supposed solution.</p>
</td></tr>
<tr><td><code>ssquares</code></td>
<td>
<p>The sum of squared residuals at this set of parameters.</p>
</td></tr>
<tr><td><code>resid</code></td>
<td>
<p>The residual vector at the returned parameters.</p>
</td></tr>
<tr><td><code>jacobian</code></td>
<td>
<p>The jacobian matrix (partial derivatives of residuals 
w.r.t. the parameters) at the returned parameters.</p>
</td></tr>
<tr><td><code>feval</code></td>
<td>
<p>The number of residual evaluations (sum of squares computations) used.</p>
</td></tr>
<tr><td><code>jeval</code></td>
<td>
<p>The number of Jacobian evaluations used.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Special notes, if any, will appear here.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>References</h3>

<p>Nash, J. C. (1979, 1990) _Compact Numerical Methods for Computers.
Linear Algebra and Function Minimisation._ Adam Hilger./Institute
of Physics Publications
</p>
<p>others!!
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cat("See examples in nlmrt-package.Rd\n")


</code></pre>

<hr>
<h2 id='print.nlmrt'>Print method for an object of class nlmrt.
</h2><span id='topic+print.nlmrt'></span>

<h3>Description</h3>

<p>Print summary output (but involving some serious computations!) of
an object of class nlmrt from <code>nlxb</code> or <code>nlfb</code> from package
<code>nlmrt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    ## S3 method for class 'nlmrt'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.nlmrt_+3A_x">x</code></td>
<td>

<p>An object of class 'nlmrt'
</p>
</td></tr>
<tr><td><code id="print.nlmrt_+3A_...">...</code></td>
<td>

<p>Any data needed for the function. We do not know of any!
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>printsum.nlmrt</code> performs a print method for an object of class 'nlmrt' that
has been created by a routine such as <code>nlfb</code> or <code>nlxb</code> for nonlinear
least squares problems.
</p>


<h3>Value</h3>

<p>Invisibly returns the input object.
</p>


<h3>Note</h3>

<p>Special notes, if any, will appear here.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>

<hr>
<h2 id='summary.nlmrt'>Summary output for nlmrt object.
</h2><span id='topic+summary.nlmrt'></span>

<h3>Description</h3>

<p>Provide a summary output (but involving some serious computations!) of
an object of class nlmrt from <code>nlxb</code> or <code>nlfb</code> from package
<code>nlmrt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    ## S3 method for class 'nlmrt'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.nlmrt_+3A_object">object</code></td>
<td>

<p>An object of class 'nlmrt'
</p>
</td></tr>
<tr><td><code id="summary.nlmrt_+3A_...">...</code></td>
<td>

<p>Any data needed for the function. We do not know of any!
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>summary.nlmrt</code> performs a summary method for an object of class 'nlmrt' that
has been created by a routine such as <code>nlfb</code> or <code>nlxb</code> for nonlinear
least squares problems.
</p>
<p>Issue: When there are bounded parameters, <code>nls</code> returns a Standard Error for each of
the parameters. However, this summary does NOT have a Jacobian value (it is set to 0)
for columns where a parameter is masked or at (or very close to) a bound. See the 
<code>R</code> code for the determination of whether we are at a bound. In this case, 
users may wish to look in the <code>inst/dev-codes</code> directory of this package, 
where there is a script <code>seboundsnlmrtx.R</code> that computes the <code>nls()</code> 
standard errors for comparison on a simple problem. 
</p>
<p>Issue: The printsum() of this object includes the singular values of the Jacobian. 
These are displayed, one per coefficient row, with the coefficients. However, the 
Jacobian singular values do NOT have a direct correspondence to the coefficients 
on whose display row they appear. It simply happens that there are as many Jacobian 
singular values as coefficients, and this is a convenient place to display them.
The same issue applies to the gradient components.
</p>


<h3>Value</h3>

<p>returns an invisible copy of the nlmrt object.
</p>


<h3>Note</h3>

<p>Special notes, if any, will appear here.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>

<hr>
<h2 id='wrapnls'>Nash variant of Marquardt nonlinear least squares solution via
qr linear solver.
</h2><span id='topic+wrapnls'></span>

<h3>Description</h3>

<p>Given a nonlinear model expressed as an expression of the form
lhs ~ formula_for_rhs
and a start vector where parameters used in the model formula are named,
attempts to find the minimum of the residual sum of squares using the
Nash variant (Nash, 1979) of the Marquardt algorithm, where the linear 
sub-problem is solved by a qr method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   wrapnls(formula, start, trace=FALSE, data, lower=-Inf, upper=Inf, 
           control=list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wrapnls_+3A_formula">formula</code></td>
<td>

<p>This is a modeling formula of the form (as in <code>nls</code>)
lhsvar ~ rhsexpression
for example,
y ~ b1/(1+b2*exp(-b3*tt))
You may also give this as a string.
</p>
</td></tr>
<tr><td><code id="wrapnls_+3A_start">start</code></td>
<td>

<p>A named parameter vector. For our example, we could use
start=c(b1=1, b2=2.345, b3=0.123)
</p>
</td></tr>
<tr><td><code id="wrapnls_+3A_trace">trace</code></td>
<td>

<p>Logical TRUE if we want intermediate progress to be reported. Default is FALSE.
</p>
</td></tr> 
<tr><td><code id="wrapnls_+3A_data">data</code></td>
<td>

<p>A data frame containing the data of the variables in the formula. This data may,
however, be supplied directly in the parent frame. 
</p>
</td></tr> 
<tr><td><code id="wrapnls_+3A_lower">lower</code></td>
<td>

<p>Lower bounds on the parameters. If a single number, this will be applied to all
parameters. Default -Inf.
</p>
</td></tr> 
<tr><td><code id="wrapnls_+3A_upper">upper</code></td>
<td>

<p>Upper bounds on the parameters. If a single number, this will be applied to all
parameters. Default Inf.
</p>
</td></tr> 
<tr><td><code id="wrapnls_+3A_control">control</code></td>
<td>
 
<p>A list of controls for the algorithm. These are as for <code>nlxb()</code>.
</p>
</td></tr>
<tr><td><code id="wrapnls_+3A_...">...</code></td>
<td>

<p>Any data needed for computation of the residual vector from the expression
rhsexpression - lhsvar. Note that this is the negative of the usual residual,
but the sum of squares is the same.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>wrapnls</code> first attempts to solve the nonlinear sum of squares problem by using
<code>nlsmnq</code>, then takes the parameters from that method to call <code>nls</code>.
</p>


<h3>Value</h3>

<p>An object of type nls.</p>


<h3>Note</h3>

<p>Special notes, if any, will appear here.
</p>


<h3>Author(s)</h3>

<p>John C Nash &lt;nashjc@uottawa.ca&gt;
</p>


<h3>See Also</h3>

<p>Function <code>nls()</code>, packages <code><a href="stats.html#topic+optim">optim</a></code> and <code>optimx</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cat("See examples in nlmrt-package.Rd\n")

## Not run: 
cat("kvanderpoel.R test\n")
# require(nlmrt)
x&lt;-c(1,3,5,7)
y&lt;-c(37.98,11.68,3.65,3.93)
pks28&lt;-data.frame(x=x,y=y)
fit0&lt;-try(nls(y~(a+b*exp(1)^(-c*x)), data=pks28, start=c(a=0,b=1,c=1), 
          trace=TRUE))
print(fit0)
cat("\n\n")
fit1&lt;-nlxb(y~(a+b*exp(-c*x)), data=pks28, start=c(a=0,b=1,c=1), trace = TRUE)
print(fit1) 
cat("\n\nor better\n")
fit2&lt;-wrapnls(y~(a+b*exp(-c*x)), data=pks28, start=c(a=0,b=1,c=1), 
              lower=-Inf, upper=Inf, trace = TRUE)


## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
