<!DOCTYPE html><html><head><title>Help for package AzureVision</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {AzureVision}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add_image_regions'><p>Add and remove regions from images</p></a></li>
<li><a href='#add_image_tags'><p>Tag and untag images uploaded to a project</p></a></li>
<li><a href='#add_images'><p>Add, list and remove images for a project</p></a></li>
<li><a href='#add_tags'><p>Add, retrieve and remove tags for a project</p></a></li>
<li><a href='#analyze'><p>Interface to Azure Computer Vision API</p></a></li>
<li><a href='#browse_images'><p>View images uploaded to a Custom Vision project</p></a></li>
<li><a href='#classification_service'><p>Connect to a Custom Vision predictive service</p></a></li>
<li><a href='#computervision_endpoint'><p>Endpoint objects for computer vision services</p></a></li>
<li><a href='#create_classification_project'><p>Create, retrieve, update and delete Azure Custom Vision projects</p></a></li>
<li><a href='#do_training_op'><p>Carry out a Custom Vision operation</p></a></li>
<li><a href='#predict.customvision_model'><p>Get predictions from a Custom Vision model</p></a></li>
<li><a href='#publish_model'><p>Publish, export and unpublish a Custom Vision model iteration</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#show_model'><p>Display model iteration details</p></a></li>
<li><a href='#train_model'><p>Create, retrieve, rename and delete a model iteration</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Interface to Azure Computer Vision Services</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>An interface to 'Azure Computer Vision' <a href="https://docs.microsoft.com/azure/cognitive-services/Computer-vision/Home">https://docs.microsoft.com/azure/cognitive-services/Computer-vision/Home</a> and 'Azure Custom Vision' <a href="https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home">https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home</a>, building on the low-level functionality provided by the 'AzureCognitive' package. These services allow users to leverage the cloud to carry out visual recognition tasks using advanced image processing models, without needing powerful hardware of their own. Part of the 'AzureR' family of packages.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Azure/AzureVision">https://github.com/Azure/AzureVision</a>
<a href="https://github.com/Azure/AzureR">https://github.com/Azure/AzureR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Azure/AzureVision/issues">https://github.com/Azure/AzureVision/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3)</td>
</tr>
<tr>
<td>Imports:</td>
<td>AzureRMR, AzureCognitive, httr, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, AzureAuth, testthat</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-10-17 19:38:31 UTC; hongo</td>
</tr>
<tr>
<td>Author:</td>
<td>Hong Ooi [aut, cre],
  Microsoft [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hong Ooi &lt;hongooi73@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-10-17 22:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='add_image_regions'>Add and remove regions from images</h2><span id='topic+add_image_regions'></span><span id='topic+customvision_regions'></span><span id='topic+remove_image_regions'></span><span id='topic+identify_regions'></span>

<h3>Description</h3>

<p>Add and remove regions from images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_image_regions(project, image_ids, regions)

remove_image_regions(project, image_ids, region_ids = NULL)

identify_regions(project, image)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_image_regions_+3A_project">project</code></td>
<td>
<p>A Custom Vision object detection project.</p>
</td></tr>
<tr><td><code id="add_image_regions_+3A_image_ids">image_ids</code></td>
<td>
<p>For <code>add_image_regions</code> and <code>remove_image_regions</code>, the IDs of the images for which to add or remove regions.</p>
</td></tr>
<tr><td><code id="add_image_regions_+3A_regions">regions</code></td>
<td>
<p>For <code>add_image_regions</code>, the regions to add. See 'Details' below.</p>
</td></tr>
<tr><td><code id="add_image_regions_+3A_region_ids">region_ids</code></td>
<td>
<p>For <code>remove_image_regions</code>, a vector of region IDs. This is an alternative to image ID for specifying the regions to remove; if this is provided, <code>image_ids</code> is not used.</p>
</td></tr>
<tr><td><code id="add_image_regions_+3A_image">image</code></td>
<td>
<p>For <code>identify_regions</code>, an image for which to identify possible regions in which an object exists. This can be the ID of an image that was previously uploaded to the project; if not, the image is uploaded. Otherwise, see <code>add_images</code> for how to specify an image to upload.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>add_image_regions</code> and <code>remove_image_regions</code> let you specify the regions in an image that contain an object. You can use <code>identify_regions</code> to have Custom Vision try to guess the regions for an image.
</p>
<p>The regions to add should be specified as a list of data frames, with one data frame per image. Each data frame should have one row per region, and the following columns:
</p>

<ul>
<li> <p><code>left</code>, <code>top</code>, <code>width</code>, <code>height</code>: the location and dimensions of the region bounding box, normalised to be between 0 and 1.
</p>
</li>
<li> <p><code>tag</code>: the name of the tag to associate with the region.
Any other columns in the data frame will be ignored.
</p>
</li></ul>



<h3>Value</h3>

<p>For <code>add_image_regions</code>, a data frame containing the details on the added regions.
</p>
<p>For <code>remove_image_regions</code>, the value of <code>image_ids</code> invisibly, if this argument was provided; NULL otherwise.
</p>
<p>For <code>identify_regions</code>, a list with the following components: <code>projectId</code>, the ID of the project; <code>imageId</code>, the ID of the image; and <code>proposals</code>, a data frame containing the coordinates of each identified region along with a confidence score.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+add_images">add_images</a></code>, <code><a href="#topic+add_tags">add_tags</a></code>
</p>
<p><code><a href="#topic+add_image_tags">add_image_tags</a></code> for classification projects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

img_ids &lt;- add_images(myproj, c("catanddog.jpg", "cat.jpg", "dog.jpg"))

regions &lt;- list(
    data.frame(
        tag=c("cat", "dog"),
        left=c(0.1, 0.5),
        top=c(0.25, 0.28),
        width=c(0.24, 0.21),
        height=c(0.7, 0.6)
    ),
    data.frame(
        tag="cat", left=0.5, top=0.35, width=0.25, height=0.62
    ),
    data.frame(
        tag="dog", left=0.07, top=0.12, width=0.79, height=0.5
    )
)

add_image_regions(myproj, img_ids, regions)
remove_image_regions(myproj, img_ids[3])
add_image_regions(myproj, img_ids[3],
    list(data.frame(
        tag="dog", left=0.5, top=0.12, width=0.4, height=0.7
    ))
)


## End(Not run)
</code></pre>

<hr>
<h2 id='add_image_tags'>Tag and untag images uploaded to a project</h2><span id='topic+add_image_tags'></span><span id='topic+customvision_image_tags'></span><span id='topic+add_image_tags.classification_project'></span><span id='topic+remove_image_tags'></span>

<h3>Description</h3>

<p>Tag and untag images uploaded to a project
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_image_tags(project, image_ids, tags)

## S3 method for class 'classification_project'
add_image_tags(project, image_ids = list_images(project, "untagged"), tags)

remove_image_tags(project, image_ids = list_images(project, "tagged", as =
  "ids"), tags = list_tags(project, as = "ids"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_image_tags_+3A_project">project</code></td>
<td>
<p>a Custom Vision classification project.</p>
</td></tr>
<tr><td><code id="add_image_tags_+3A_image_ids">image_ids</code></td>
<td>
<p>The IDs of the images to tag or untag.</p>
</td></tr>
<tr><td><code id="add_image_tags_+3A_tags">tags</code></td>
<td>
<p>For <code>add_image_tags</code>, the tag labels to add to the images. For <code>remove_image_tags</code>, the tags (either text labels or IDs) to remove from images. The default for untagging is to remove all assigned tags.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>add_image_tags</code> is for tagging images that were uploaded previously, while <code>remove_image_tags</code> untags them. Adding tags does not remove previously assigned ones. Similarly, removing one tag from an image leaves any other tags intact.
</p>
<p>Tags can be specified in the following ways:
</p>

<ul>
<li><p> For a regular classification project (one tag per image), as a vector of strings. The tags will be applied to the images in order. If the length of the vector is 1, it will be recycled to the length of <code>image_ids</code>.
</p>
</li>
<li><p> For a multilabel classification project (multiple tags per image), as a <em>list</em> of vectors of strings. Each vector in the list contains the tags to be assigned to the corresponding image. If the length of the list is 1, it will be recycled to the length of <code>image_ids</code>.
</p>
</li></ul>

<p>If the length of the vector is 1, it will be recycled to the length of <code>image_ids</code>.
</p>


<h3>Value</h3>

<p>The vector of IDs for the images affected, invisibly.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+add_images">add_images</a></code>, <code><a href="#topic+add_tags">add_tags</a></code>
</p>
<p><code><a href="#topic+add_image_regions">add_image_regions</a></code> for object detection projects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

imgs &lt;- dir("path/to/images", full.names=TRUE)
img_ids &lt;- add_images(myproj, imgs)
add_image_tags(myproj, "mytag")
remove_image_tags(myproj, img_ids[1])
add_image_tags(myproj, img_ids[1], "myothertag")


## End(Not run)
</code></pre>

<hr>
<h2 id='add_images'>Add, list and remove images for a project</h2><span id='topic+add_images'></span><span id='topic+customvision_images'></span><span id='topic+add_images.classification_project'></span><span id='topic+add_images.object_detection_project'></span><span id='topic+list_images'></span><span id='topic+remove_images'></span>

<h3>Description</h3>

<p>Add, list and remove images for a project
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_images(project, ...)

## S3 method for class 'classification_project'
add_images(project, images, tags = NULL, ...)

## S3 method for class 'object_detection_project'
add_images(project, images, regions = NULL, ...)

list_images(project, include = c("all", "tagged", "untagged"),
  as = c("ids", "dataframe", "list"), iteration = NULL)

remove_images(project, image_ids = list_images(project, "untagged", as =
  "ids"), confirm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_images_+3A_project">project</code></td>
<td>
<p>A Custom Vision project.</p>
</td></tr>
<tr><td><code id="add_images_+3A_...">...</code></td>
<td>
<p>Arguments passed to lower-level functions.</p>
</td></tr>
<tr><td><code id="add_images_+3A_images">images</code></td>
<td>
<p>For <code>add_images</code>, the images to add (upload) to the project.</p>
</td></tr>
<tr><td><code id="add_images_+3A_tags">tags</code></td>
<td>
<p>Optional tags to add to the images. Only for classification projects.</p>
</td></tr>
<tr><td><code id="add_images_+3A_regions">regions</code></td>
<td>
<p>Optional list of regions in the images that contain objects. Only for object detection projects.</p>
</td></tr>
<tr><td><code id="add_images_+3A_include">include</code></td>
<td>
<p>For <code>list_images</code>, which images to include in the list: untagged, tagged, or both (the default).</p>
</td></tr>
<tr><td><code id="add_images_+3A_as">as</code></td>
<td>
<p>For <code>list_images</code>, the return value: a vector of image IDs, a data frame of image metadata, or a list of metadata.</p>
</td></tr>
<tr><td><code id="add_images_+3A_iteration">iteration</code></td>
<td>
<p>For <code>list_images</code>, the iteration ID (roughly, which model generation to use). Defaults to the latest iteration.</p>
</td></tr>
<tr><td><code id="add_images_+3A_image_ids">image_ids</code></td>
<td>
<p>For <code>remove_images</code>, the IDs of the images to remove from the project.</p>
</td></tr>
<tr><td><code id="add_images_+3A_confirm">confirm</code></td>
<td>
<p>For <code>remove_images</code>, whether to ask for confirmation first.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The images to be uploaded can be specified as:
</p>

<ul>
<li><p> A vector of local filenames. JPG, PNG and GIF file formats are supported.
</p>
</li>
<li><p> A vector of publicly accessible URLs.
</p>
</li>
<li><p> A raw vector, or a list of raw vectors, holding the binary contents of the image files.
</p>
</li></ul>

<p>Uploaded images can also have <em>tags</em> added (for a classification project) or <em>regions</em> (for an object detection project). Classification tags can be specified in the following ways:
</p>

<ul>
<li><p> For a regular classification project (one tag per image), as a vector of strings. The tags will be applied to the images in order. If the length of the vector is 1, it will be recycled to the length of <code>image_ids</code>.
</p>
</li>
<li><p> For a multilabel classification project (multiple tags per image), as a <em>list</em> of vectors of strings. Each vector in the list contains the tags to be assigned to the corresponding image. If the length of the list is 1, it will be recycled to the length of <code>image_ids</code>.
</p>
</li></ul>

<p>If the length of the vector is 1, it will be recycled to the length of <code>image_ids</code>.
</p>
<p>Object detection projects also have tags, but they are specified as part of the <code>regions</code> argument. The regions to add should be specified as a list of data frames, with one data frame per image. Each data frame should have one row per region, and the following columns:
</p>

<ul>
<li> <p><code>left</code>, <code>top</code>, <code>width</code>, <code>height</code>: the location and dimensions of the region bounding box, normalised to be between 0 and 1.
</p>
</li>
<li> <p><code>tag</code>: the name of the tag to associate with the region.
</p>
</li></ul>

<p>Any other columns in the data frame will be ignored. If the length of the list is 1, it will be recycled to the length of <code>image_ids</code>.
</p>
<p>Note that once uploaded, images are identified only by their ID; there is no general link back to the source filename or URL. If you don't include tags or regions in the <code>add_images</code> call, be sure to save the returned IDs and then call <code><a href="#topic+add_image_tags">add_image_tags</a></code> or <code><a href="#topic+add_image_regions">add_image_regions</a></code> as appropriate.
</p>


<h3>Value</h3>

<p>For <code>add_images</code>, the vector of IDs of the uploaded images.
</p>
<p>For <code>list_images</code>, based on the value of the <code>as</code> argument. The default is a vector of image IDs; <code>as="list"</code> returns a (nested) list of image metadata with one component per image; and <code>as="dataframe"</code> returns the same metadata but reshaped into a data frame.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+add_image_tags">add_image_tags</a></code> and <code><a href="#topic+add_image_regions">add_image_regions</a></code> to add tags and regions to images, if not done at upload time
</p>
<p><code><a href="#topic+add_tags">add_tags</a></code>, <code><a href="#topic+list_tags">list_tags</a></code>, <code><a href="#topic+remove_tags">remove_tags</a></code>
</p>
<p><code><a href="#topic+customvision_project">customvision_project</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- customvision_training_endpoint(url="endpoint_url", key="key")

# classification
proj1 &lt;- create_classification_project(endp, "myproject")
list_images(proj1)
imgs &lt;- dir("path/to/images", full.names=TRUE)

# recycling: apply one tag to all images
add_images(proj1, imgs, tags="mytag")
list_images(proj1, include="tagged", as="dataframe")

# different tags per image
add_images(proj1, c("cat.jpg", "dog.jpg", tags=c("cat", "dog"))

# adding online images
host &lt;- "https://mysite.example.com/"
img_urls &lt;- paste0(host, c("img1.jpg", "img2.jpg", "img3.jpg"))
add_images(proj1, img_urls, tags="mytag")

# multiple label classification
proj2 &lt;- create_classification_project(endp, "mymultilabelproject", multiple_tags=TRUE)

add_images(proj2, imgs, tags=list(c("tag1", "tag2")))
add_images(proj2, c("catanddog.jpg", "cat.jpg", "dog.jpg"),
    tags=list(
        c("cat", "dog"),
        "cat",
        "dog"
    )
)

# object detection
proj3 &lt;- create_object_detection_project(endp, "myobjdetproj")

regions &lt;- list(
    data.frame(
        tag=c("cat", "dog"),
        left=c(0.1, 0.5),
        top=c(0.25, 0.28),
        width=c(0.24, 0.21),
        height=c(0.7, 0.6)
    ),
    data.frame(
        tag="cat", left=0.5, top=0.35, width=0.25, height=0.62
    ),
    data.frame(
        tag="dog", left=0.07, top=0.12, width=0.79, height=0.5
    )
)
add_images(proj3, c("catanddog.jpg", "cat.jpg", "dog.jpg"), regions=regions)


## End(Not run)
</code></pre>

<hr>
<h2 id='add_tags'>Add, retrieve and remove tags for a project</h2><span id='topic+add_tags'></span><span id='topic+customvision_tags'></span><span id='topic+add_negative_tag'></span><span id='topic+list_tags'></span><span id='topic+get_tag'></span><span id='topic+remove_tags'></span>

<h3>Description</h3>

<p>Add, retrieve and remove tags for a project
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_tags(project, tags)

add_negative_tag(project, negative_name = "_negative_")

list_tags(project, as = c("names", "ids", "dataframe", "list"),
  iteration = NULL)

get_tag(project, name = NULL, id = NULL, iteration = NULL)

remove_tags(project, tags, confirm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_tags_+3A_project">project</code></td>
<td>
<p>A Custom Vision project.</p>
</td></tr>
<tr><td><code id="add_tags_+3A_tags">tags</code></td>
<td>
<p>For <code>add_tags</code>, a vector of strings to treat as tags.</p>
</td></tr>
<tr><td><code id="add_tags_+3A_negative_name">negative_name</code></td>
<td>
<p>For <code>add_negative_tag</code>, the label to provide a negative tag. See 'Negative tags' below.</p>
</td></tr>
<tr><td><code id="add_tags_+3A_as">as</code></td>
<td>
<p>For <code>list_tags</code>, the format in which to return results: a vector of tag names, a vector of tag IDs, a data frame of metadata, or a list of metadata.</p>
</td></tr>
<tr><td><code id="add_tags_+3A_iteration">iteration</code></td>
<td>
<p>For <code>list_tags</code> and <code>get_tag</code>, the iteration ID (roughly, which model generation to use). Defaults to the latest iteration.</p>
</td></tr>
<tr><td><code id="add_tags_+3A_name">name</code>, <code id="add_tags_+3A_id">id</code></td>
<td>
<p>For <code>get_tag</code>, the name (text string) for a tag, and its ID. Provide one or the other, but not both.</p>
</td></tr>
<tr><td><code id="add_tags_+3A_confirm">confirm</code></td>
<td>
<p>For <code>remove_tags</code>, whether to ask for confirmation first.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Tags</em> are the labels attached to images for use in classification projects. An image can have one or multiple tags associated with it; however, the latter only makes sense if the project is setup for multi-label classification.
</p>
<p>Tags form part of the metadata for a Custom Vision project, and have to be explicitly defined prior to use. Each tag has a corresponding ID which is used to manage it. In general, you can let AzureVision handle the details of managing tags and tag IDs.
</p>


<h3>Value</h3>

<p><code>add_tags</code> and <code>add_negative_tag</code> return a data frame containing the names and IDs of the tags added.
</p>


<h3>Negative tags</h3>

<p>A <em>negative tag</em> is a special tag that represents the absence of any other tag. For example, if a project is classifying images into cats and dogs, an image that doesn't contain either a cat or dog should be given a negative tag. This can be distinguished from an <em>untagged</em> image, where there is no information at all on what it contains.
</p>
<p>You can add a negative tag to a project with the <code>add_negative_tag</code> method. Once defined, a negative tag is treated like any other tag. A project can only have one negative tag defined.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+add_image_tags">add_image_tags</a></code>, <code><a href="#topic+remove_image_tags">remove_image_tags</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

add_tags(myproj, "newtag")
add_negative_tag(myproj)
remove_tags(myproj, "_negative_")
add_negative_tag(myproj, "nothing")


## End(Not run)
</code></pre>

<hr>
<h2 id='analyze'>Interface to Azure Computer Vision API</h2><span id='topic+analyze'></span><span id='topic+computervision'></span><span id='topic+describe'></span><span id='topic+detect_objects'></span><span id='topic+area_of_interest'></span><span id='topic+tag'></span><span id='topic+categorize'></span><span id='topic+read_text'></span><span id='topic+list_computervision_domains'></span><span id='topic+make_thumbnail'></span>

<h3>Description</h3>

<p>Interface to Azure Computer Vision API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analyze(endpoint, image, domain = NULL, feature_types = NULL,
  language = "en", ...)

describe(endpoint, image, language = "en", ...)

detect_objects(endpoint, image, ...)

area_of_interest(endpoint, image, ...)

tag(endpoint, image, language = "en", ...)

categorize(endpoint, image, ...)

read_text(endpoint, image, detect_orientation = TRUE, language = "en", ...)

list_computervision_domains(endpoint, ...)

make_thumbnail(endpoint, image, outfile, width = 50, height = 50,
  smart_crop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="analyze_+3A_endpoint">endpoint</code></td>
<td>
<p>A computer vision endpoint.</p>
</td></tr>
<tr><td><code id="analyze_+3A_image">image</code></td>
<td>
<p>An image to be sent to the endpoint. This can be either a filename, a publicly accessible URL, or a raw vector holding the file contents.</p>
</td></tr>
<tr><td><code id="analyze_+3A_domain">domain</code></td>
<td>
<p>For <code>analyze</code>, an optional domain-specific model to use to analyze the image. Can be &quot;celebrities&quot; or &quot;landmarks&quot;.</p>
</td></tr>
<tr><td><code id="analyze_+3A_feature_types">feature_types</code></td>
<td>
<p>For <code>analyze</code>, an optional character vector of more detailed features to return. This can be one or more of: &quot;categories&quot;, &quot;tags&quot;, &quot;description&quot;, &quot;faces&quot;, &quot;imagetype&quot;, &quot;color&quot;, &quot;adult&quot;, &quot;brands&quot; and &quot;objects&quot;. If not supplied, defaults to &quot;categories&quot;.</p>
</td></tr>
<tr><td><code id="analyze_+3A_language">language</code></td>
<td>
<p>A 2-character code indicating the language to use for tags, feature labels and descriptions. The default is <code>en</code>, for English.</p>
</td></tr>
<tr><td><code id="analyze_+3A_...">...</code></td>
<td>
<p>Arguments passed to lower-level functions, and ultimately to <code>call_cognitive_endpoint</code>.</p>
</td></tr>
<tr><td><code id="analyze_+3A_detect_orientation">detect_orientation</code></td>
<td>
<p>For <code>read_text</code>, whether to automatically determine the image's orientation.</p>
</td></tr>
<tr><td><code id="analyze_+3A_outfile">outfile</code></td>
<td>
<p>For <code>make_thumbnail</code>, the filename for the generated thumbnail. Alternatively, if this is NULL the thumbnail is returned as a raw vector.</p>
</td></tr>
<tr><td><code id="analyze_+3A_width">width</code>, <code id="analyze_+3A_height">height</code></td>
<td>
<p>For <code>make_thumbnail</code>, the dimensions for the returned thumbnail.</p>
</td></tr>
<tr><td><code id="analyze_+3A_smart_crop">smart_crop</code></td>
<td>
<p>For <code>make_thumbnail</code>, whether to automatically determine the best location to crop for the thumbnail. Useful when the aspect ratios of the original image and the thumbnail don't match.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>analyze</code> extracts visual features from the image. To obtain more detailed features, specify the <code>domain</code> and/or <code>feature_types</code> arguments as appropriate.
</p>
<p><code>describe</code> attempts to provide a text description of the image.
</p>
<p><code>detect_objects</code> detects objects in the image.
</p>
<p><code>area_of_interest</code> attempts to find the &quot;interesting&quot; part of an image, meaning the most likely location of the image's subject.
</p>
<p><code>tag</code> returns a set of words that are relevant to the content of the image. Not to be confused with the <code><a href="#topic+add_tags">add_tags</a></code> or <code><a href="#topic+add_image_tags">add_image_tags</a></code> functions that are part of the Custom Vision API.
</p>
<p><code>categorize</code> attempts to place the image into a list of predefined categories.
</p>
<p><code>read_text</code> performs optical character recognition (OCR) on the image.
</p>
<p><code>list_domains</code> returns the predefined domain-specific models that can be queried by <code>analyze</code> for deeper analysis. Not to be confused with the domains available for training models with the Custom Vision API.
</p>
<p><code>make_thumbnail</code> generates a thumbnail of the image, with the specified dimensions.
</p>


<h3>Value</h3>

<p><code>analyze</code> returns a list containing the results of the analysis. The components will vary depending on the domain and feature types requested.
</p>
<p><code>describe</code> returns a list with two components: <code>tags</code>, a vector of text labels; and <code>captions</code>, a data frame of descriptive sentences.
</p>
<p><code>detect_objects</code>  returns a dataframe giving the locations and types of the detected objects.
</p>
<p><code>area_of_interest</code> returns a length-4 numeric vector, containing the top-left coordinates of the area of interest and its width and height.
</p>
<p><code>tag</code> and <code>categorize</code> return a data frame of tag and category information, respectively.
</p>
<p><code>read_text</code> returns the extracted text as a list with one component per region that contains text. Each component is a vector of character strings.
</p>
<p><code>list_computervision_domains</code> returns a character vector of domain names.
</p>
<p><code>make_thumbnail</code> returns a raw vector holding the contents of the thumbnail, if the <code>outfile</code> argument is NULL. Otherwise, the thumbnail is saved into <code>outfile</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+computervision_endpoint">computervision_endpoint</a></code>, <code><a href="AzureCognitive.html#topic+call_cognitive_endpoint">AzureCognitive::call_cognitive_endpoint</a></code>
</p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/Computer-vision/Home">Computer Vision documentation</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

vis &lt;- computervision_endpoint(
    url="https://accountname.cognitiveservices.azure.com/",
    key="account_key"
)

list_domains(vis)

# analyze a local file
analyze(vis, "image.jpg")
# picture on the Internet
analyze(vis, "https://example.com/image.jpg")
# as a raw vector
analyze(vis, readBin("image.jpg", "raw", file.size("image.jpg")))

# analyze has optional extras
analyze(vis, "image.jpg", feature_types=c("faces", "objects"))

describe(vis, "image.jpg")
detect_objects(vis, "image.jpg")
area_of_interest(vis, "image.jpg")
tag(vis, "image.jpg")  # more reliable than analyze(*, feature_types="tags")
categorize(vis, "image.jpg")
read_text(vis, "scanned_text.jpg")


## End(Not run)
</code></pre>

<hr>
<h2 id='browse_images'>View images uploaded to a Custom Vision project</h2><span id='topic+browse_images'></span>

<h3>Description</h3>

<p>View images uploaded to a Custom Vision project
</p>


<h3>Usage</h3>

<pre><code class='language-R'>browse_images(project, img_ids, which = c("resized", "original",
  "thumbnail"), max_images = 20, iteration = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="browse_images_+3A_project">project</code></td>
<td>
<p>A Custom Vision project.</p>
</td></tr>
<tr><td><code id="browse_images_+3A_img_ids">img_ids</code></td>
<td>
<p>The IDs of the images to view. You can use <code><a href="#topic+list_images">list_images</a></code> to get the image IDs for this project.</p>
</td></tr>
<tr><td><code id="browse_images_+3A_which">which</code></td>
<td>
<p>Which image to view: the resized version used for training (the default), the original uploaded image, or the thumbnail.</p>
</td></tr>
<tr><td><code id="browse_images_+3A_max_images">max_images</code></td>
<td>
<p>The maximum number of images to display.</p>
</td></tr>
<tr><td><code id="browse_images_+3A_iteration">iteration</code></td>
<td>
<p>The iteration ID (roughly, which model generation to use). Defaults to the latest iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Images in a Custom Vision project are stored in Azure Storage. This function gets the URLs for the uploaded images and displays them in your browser.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+list_images">list_images</a></code>
</p>

<hr>
<h2 id='classification_service'>Connect to a Custom Vision predictive service</h2><span id='topic+classification_service'></span><span id='topic+customvision_predictive_service'></span><span id='topic+object_detection_service'></span>

<h3>Description</h3>

<p>Connect to a Custom Vision predictive service
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classification_service(endpoint, project, name)

object_detection_service(endpoint, project, name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classification_service_+3A_endpoint">endpoint</code></td>
<td>
<p>A prediction endpoint object, of class <code>customvision_prediction_endpoint</code>.</p>
</td></tr>
<tr><td><code id="classification_service_+3A_project">project</code></td>
<td>
<p>The project underlying this predictive service. Can be either an object of class <code>customvision_project</code>, or a string giving the ID of the project.</p>
</td></tr>
<tr><td><code id="classification_service_+3A_name">name</code></td>
<td>
<p>The published name of the service.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are handles to a predictive service that was previously published from a trained model. They have <code>predict</code> methods defined for them.
</p>


<h3>Value</h3>

<p>An object of class <code>classification_service</code> or <code>object_detection_service</code>, as appropriate. These are subclasses of <code>customvision_predictive_service</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+customvision_prediction_endpoint">customvision_prediction_endpoint</a></code>, <code><a href="#topic+customvision_project">customvision_project</a></code>
</p>
<p><code><a href="#topic+predict.classification_service">predict.classification_service</a></code>, <code><a href="#topic+predict.object_detection_service">predict.object_detection_service</a></code>, <code><a href="#topic+do_prediction_op">do_prediction_op</a></code>
</p>
<p><code><a href="#topic+train_model">train_model</a></code>, <code><a href="#topic+publish_model">publish_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- customvision_training_endpoint(url="endpoint_url", key="key")
myproj &lt;- get_project(endp, "myproject")

# getting the ID from the project object -- in practice you would store the ID separately
pred_endp &lt;- customvision_prediction_endpoint(url="endpoint_url", key="pred_key")
classification_service(pred_endp, myproj$project$id, "publishedname")


## End(Not run)
</code></pre>

<hr>
<h2 id='computervision_endpoint'>Endpoint objects for computer vision services</h2><span id='topic+computervision_endpoint'></span><span id='topic+customvision_training_endpoint'></span><span id='topic+customvision_prediction_endpoint'></span>

<h3>Description</h3>

<p>Endpoint objects for computer vision services
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computervision_endpoint(url, key = NULL, aad_token = NULL, ...)

customvision_training_endpoint(url, key = NULL, ...)

customvision_prediction_endpoint(url, key = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computervision_endpoint_+3A_url">url</code></td>
<td>
<p>The URL of the endpoint.</p>
</td></tr>
<tr><td><code id="computervision_endpoint_+3A_key">key</code></td>
<td>
<p>A subscription key. Can be single-service or multi-service.</p>
</td></tr>
<tr><td><code id="computervision_endpoint_+3A_aad_token">aad_token</code></td>
<td>
<p>For the Computer Vision endpoint, an OAuth token object, of class <code><a href="AzureAuth.html#topic+AzureToken">AzureAuth::AzureToken</a></code>. You can supply this as an alternative to a subscription key.</p>
</td></tr>
<tr><td><code id="computervision_endpoint_+3A_...">...</code></td>
<td>
<p>Other arguments to pass to <code><a href="AzureCognitive.html#topic+cognitive_endpoint">AzureCognitive::cognitive_endpoint</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are functions to create service-specific endpoint objects. Computer Vision supports authentication via either a subscription key or Azure Active Directory (AAD) token; Custom Vision only supports subscription key. Note that there are <em>two</em> kinds of Custom Vision endpoint, one for training and the other for prediction.
</p>


<h3>Value</h3>

<p>An object inheriting from <code>cognitive_endpoint</code>. The subclass indicates the type of service/endpoint: Computer Vision, Custom Vision training, or Custom Vision prediction.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cognitive_endpoint">cognitive_endpoint</a></code>, <code><a href="#topic+call_cognitive_endpoint">call_cognitive_endpoint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
computervision_endpoint("https://myaccount.cognitiveservices.azure.com", key="key")

customvision_training_endpoint("https://westus.api.cognitive.microsoft.com", key="key")

customvision_prediction_endpoint("https://westus.api.cognitive.microsoft.com", key="key")

</code></pre>

<hr>
<h2 id='create_classification_project'>Create, retrieve, update and delete Azure Custom Vision projects</h2><span id='topic+create_classification_project'></span><span id='topic+customvision_project'></span><span id='topic+create_object_detection_project'></span><span id='topic+list_projects'></span><span id='topic+get_project'></span><span id='topic+update_project'></span><span id='topic+delete_project'></span>

<h3>Description</h3>

<p>Create, retrieve, update and delete Azure Custom Vision projects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_classification_project(endpoint, name, domain = "general",
  export_target = c("none", "standard", "vaidk"), multiple_tags = FALSE,
  description = NULL)

create_object_detection_project(endpoint, name, domain = "general",
  export_target = c("none", "standard", "vaidk"), description = NULL)

list_projects(endpoint)

get_project(endpoint, name = NULL, id = NULL)

update_project(endpoint, name = NULL, id = NULL, domain = "general",
  export_target = c("none", "standard", "vaidk"), multiple_tags = FALSE,
  description = NULL)

delete_project(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_classification_project_+3A_endpoint">endpoint</code></td>
<td>
<p>A custom vision endpoint.</p>
</td></tr>
<tr><td><code id="create_classification_project_+3A_name">name</code>, <code id="create_classification_project_+3A_id">id</code></td>
<td>
<p>The name and ID of the project. At least one of these must be specified for <code>get_project</code>, <code>update_project</code> and <code>delete_project</code>. The name is required for <code>create_project</code> (the ID will be assigned automatically).</p>
</td></tr>
<tr><td><code id="create_classification_project_+3A_domain">domain</code></td>
<td>
<p>What kinds of images the model is meant to apply to. The default &quot;general&quot; means the model is suitable for use in a generic setting. Other, more specialised domains for classification include &quot;food&quot;, &quot;landmarks&quot; and &quot;retail&quot;; for object detection the other possible domain is &quot;logo&quot;.</p>
</td></tr>
<tr><td><code id="create_classification_project_+3A_export_target">export_target</code></td>
<td>
<p>What formats are supported when exporting the model.</p>
</td></tr>
<tr><td><code id="create_classification_project_+3A_multiple_tags">multiple_tags</code></td>
<td>
<p>For classification models, Whether multiple categories (tags/labels) for an image are allowed. The default is <code>FALSE</code>, meaning an image represents one and only one category. Ignored for object detection models.</p>
</td></tr>
<tr><td><code id="create_classification_project_+3A_description">description</code></td>
<td>
<p>An optional text description of the project.</p>
</td></tr>
<tr><td><code id="create_classification_project_+3A_object">object</code></td>
<td>
<p>For <code>delete_customvision_project</code>, either an endpoint, or a project object.</p>
</td></tr>
<tr><td><code id="create_classification_project_+3A_...">...</code></td>
<td>
<p>Further arguments passed to lower-level methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Custom Vision project contains the metadata for a model: its intended purpose (classification vs object detection), the domain, the set of training images, and so on. Once you have created a project, you upload images to it, and train models based on those images. A trained model can then be published as a predictive service, or exported for standalone use.
</p>
<p>By default, a Custom Vision project does not support exporting the model; this allows it to be more complex, and thus potentially more accurate. Setting <code>export_target="standard"</code> enables exporting to the following formats:
</p>

<ul>
<li><p> ONNX 1.2
</p>
</li>
<li><p> CoreML, for iOS 11 devices
</p>
</li>
<li><p> TensorFlow
</p>
</li>
<li><p> TensorFlow Lite, for Android devices
</p>
</li>
<li><p> A Docker image for the Windows, Linux or Raspberry Pi 3 (ARM) platform
</p>
</li></ul>

<p>Setting <code>export_target="vaidk"</code> allows exporting to Vision AI Development Kit format, in addition to the above.
</p>


<h3>Value</h3>

<p><code>delete_project</code> returns NULL invisibly, on a successful deletion. The others return an object of class <code>customvision_project</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+customvision_training_endpoint">customvision_training_endpoint</a></code>, <code><a href="#topic+add_images">add_images</a></code>, <code><a href="#topic+train_model">train_model</a></code>, <code><a href="#topic+publish_model">publish_model</a></code>, <code><a href="#topic+predict.customvision_model">predict.customvision_model</a></code>, <code><a href="#topic+do_training_op">do_training_op</a></code>
</p>

<ul>
<li> <p><a href="https://www.customvision.ai/">CustomVision.ai</a>: An interactive site for building Custom Vision models, provided by Microsoft
</p>
</li>
<li> <p><a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/Custom_Vision_Training_3.0/operations/5c771cdcbf6a2b18a0c3b7fa">Training API reference</a>
</p>
</li>
<li> <p><a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/Custom_Vision_Prediction_3.0/operations/5c82db60bf6a2b11a8247c15">Prediction API reference</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- customvision_training_endpoint(url="endpoint_url", key="key")

create_classification_project(endp, "myproject")
create_classification_project(endp, "mymultilabelproject", multiple_tags=TRUE)
create_object_detection_project(endp, "myobjdetproj")

create_classification_project(endp, "mystdproject", export_target="standard")

list_projects(endp)

get_project(endp, "myproject")

update_project(endp, "myproject", export_target="vaidk")


## End(Not run)
</code></pre>

<hr>
<h2 id='do_training_op'>Carry out a Custom Vision operation</h2><span id='topic+do_training_op'></span><span id='topic+do_training_op.customvision_project'></span><span id='topic+do_prediction_op'></span><span id='topic+do_prediction_op.customvision_predictive_service'></span>

<h3>Description</h3>

<p>Carry out a Custom Vision operation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do_training_op(project, ...)

## S3 method for class 'customvision_project'
do_training_op(project, op, ...)

do_prediction_op(service, ...)

## S3 method for class 'customvision_predictive_service'
do_prediction_op(service, op, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do_training_op_+3A_project">project</code></td>
<td>
<p>For <code>do_training_op</code>, a Custom Vision project.</p>
</td></tr>
<tr><td><code id="do_training_op_+3A_op">op</code>, <code id="do_training_op_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>call_cognitive_endpoint</code>, and ultimately to the REST API.</p>
</td></tr>
<tr><td><code id="do_training_op_+3A_service">service</code></td>
<td>
<p>For <code>do_prediction_op</code>, a Custom Vision predictive service.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions provide low-level access to the Custom Vision REST API. <code>do_training_op</code> is for working with the training endpoint, and <code>do_prediction_op</code> with the prediction endpoint. You can use them if the other tools in this package don't provide what you need.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+customvision_training_endpoint">customvision_training_endpoint</a></code>, <code><a href="#topic+customvision_prediction_endpoint">customvision_prediction_endpoint</a></code>,
<code><a href="#topic+customvision_project">customvision_project</a></code>, <code><a href="#topic+customvision_predictive_service">customvision_predictive_service</a></code>, <code><a href="#topic+call_cognitive_endpoint">call_cognitive_endpoint</a></code>
</p>

<hr>
<h2 id='predict.customvision_model'>Get predictions from a Custom Vision model</h2><span id='topic+predict.customvision_model'></span><span id='topic+predict'></span><span id='topic+predict.classification_service'></span><span id='topic+predict.object_detection_service'></span>

<h3>Description</h3>

<p>Get predictions from a Custom Vision model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'customvision_model'
predict(object, images, type = c("class", "prob", "list"), ...)

## S3 method for class 'classification_service'
predict(object, images, type = c("class",
  "prob", "list"), save_result = FALSE, ...)

## S3 method for class 'object_detection_service'
predict(object, images, type = c("class",
  "prob", "list"), save_result = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.customvision_model_+3A_object">object</code></td>
<td>
<p>A Custom Vision object from which to get predictions. See 'Details' below.</p>
</td></tr>
<tr><td><code id="predict.customvision_model_+3A_images">images</code></td>
<td>
<p>The images for which to get predictions.</p>
</td></tr>
<tr><td><code id="predict.customvision_model_+3A_type">type</code></td>
<td>
<p>The type of prediction: either class membership (the default), the class probabilities, or a list containing all information returned by the prediction endpoint.</p>
</td></tr>
<tr><td><code id="predict.customvision_model_+3A_...">...</code></td>
<td>
<p>Further arguments passed to lower-level functions; not used.</p>
</td></tr>
<tr><td><code id="predict.customvision_model_+3A_save_result">save_result</code></td>
<td>
<p>For the predictive service methods, whether to store the predictions on the server for future use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AzureVision defines prediction methods for both Custom Vision model training objects (of class <code>customvision_model</code>) and prediction services (<code>classification_service</code> and <code>object_detection_service</code>). The method for model training objects calls the &quot;quick test&quot; endpoint, and is meant only for testing purposes.
</p>
<p>The prediction endpoints accept a single image per request, so supplying multiple images to these functions will call the endpoints multiple times, in sequence. The images can be specified as:
</p>

<ul>
<li><p> A vector of local filenames. All common image file formats are supported.
</p>
</li>
<li><p> A vector of publicly accessible URLs.
</p>
</li>
<li><p> A raw vector, or a list of raw vectors, holding the binary contents of the image files.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+train_model">train_model</a></code>, <code><a href="#topic+publish_model">publish_model</a></code>, <code><a href="#topic+classification_service">classification_service</a></code>, <code><a href="#topic+object_detection_service">object_detection_service</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# predicting with the training endpoint
endp &lt;- customvision_training_endpoint(url="endpoint_url", key="key")
myproj &lt;- get_project(endp, "myproject")
mod &lt;- get_model(myproj)

predict(mod, "testimage.jpg")
predict(mod, "https://mysite.example.com/testimage.jpg", type="prob")

imgraw &lt;- readBin("testimage.jpg", "raw", file.size("testimage.jpg"))
predict(mod, imgraw, type="list")

# predicting with the prediction endpoint
# you'll need either the project object or the ID
proj_id &lt;- myproj$project$id
pred_endp &lt;- customvision_prediction_endpoint(url="endpoint_url", key="pred_key")
pred_svc &lt;- classification_service(pred_endp, proj_id, "iteration1")
predict(pred_svc, "testimage.jpg")


## End(Not run)
</code></pre>

<hr>
<h2 id='publish_model'>Publish, export and unpublish a Custom Vision model iteration</h2><span id='topic+publish_model'></span><span id='topic+unpublish_model'></span><span id='topic+export_model'></span><span id='topic+list_model_exports'></span>

<h3>Description</h3>

<p>Publish, export and unpublish a Custom Vision model iteration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>publish_model(model, name, prediction_resource)

unpublish_model(model, confirm = TRUE)

export_model(model, format, destfile = basename(httr::parse_url(dl_link)$path))

list_model_exports(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="publish_model_+3A_model">model</code></td>
<td>
<p>A Custom Vision model iteration object.</p>
</td></tr>
<tr><td><code id="publish_model_+3A_name">name</code></td>
<td>
<p>For <code>publish_model</code>, the name to assign to the published model on the prediction endpoint.</p>
</td></tr>
<tr><td><code id="publish_model_+3A_prediction_resource">prediction_resource</code></td>
<td>
<p>For <code>publish_model</code>, the Custom Vision prediction resource to publish to. This can either be a string containing the Azure resource ID, or an AzureRMR resource object.</p>
</td></tr>
<tr><td><code id="publish_model_+3A_confirm">confirm</code></td>
<td>
<p>For <code>unpublish_model</code>, whether to ask for confirmation first.</p>
</td></tr>
<tr><td><code id="publish_model_+3A_format">format</code></td>
<td>
<p>For <code>export_model</code>, the format to export to. See below for supported formats.</p>
</td></tr>
<tr><td><code id="publish_model_+3A_destfile">destfile</code></td>
<td>
<p>For <code>export_model</code>, the destination file for downloading. Set this to NULL to skip downloading.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Publishing a model makes it available to clients as a predictive service. Exporting a model serialises it to a file of the given format in Azure storage, which can then be downloaded. Each iteration of the model can be published or exported separately.
</p>
<p>The <code>format</code> argument to <code>export_model</code> can be one of the following. Note that exporting a model requires that the project was created with support for it.
</p>

<ul>
<li> <p><code>"onnx"</code>: ONNX 1.2
</p>
</li>
<li> <p><code>"coreml"</code>: CoreML, for iOS 11 devices
</p>
</li>
<li> <p><code>"tensorflow"</code>: TensorFlow
</p>
</li>
<li> <p><code>"tensorflow lite"</code>: TensorFlow Lite for Android devices
</p>
</li>
<li> <p><code>"linux docker"</code>, <code>"windows docker"</code>, <code>"arm docker"</code>: A Docker image for the given platform (Raspberry Pi 3 in the case of ARM)
</p>
</li>
<li> <p><code>"vaidk"</code>: Vision AI Development Kit
</p>
</li></ul>



<h3>Value</h3>

<p><code>export_model</code> returns the URL of the exported file, invisibly if it was downloaded.
</p>
<p><code>list_model_exports</code> returns a data frame detailing the formats the current model has been exported to, along with their download URLs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train_model">train_model</a></code>, <code><a href="#topic+get_model">get_model</a></code>, <code><a href="#topic+customvision_predictive_service">customvision_predictive_service</a></code>, <code><a href="#topic+predict.classification_service">predict.classification_service</a></code>, <code><a href="#topic+predict.object_detection_service">predict.object_detection_service</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- customvision_training_endpoint(url="endpoint_url", key="key")
myproj &lt;- get_project(endp, "myproject")
mod &lt;- get_model(myproj)

export_model(mod, "tensorflow", download=FALSE)
export_model(mod, "onnx", destfile="onnx.zip")

rg &lt;- AzureRMR::get_azure_login("yourtenant")$
    get_subscription("sub_id")$
    get_resource_group("rgname")

pred_res &lt;- rg$get_cognitive_service("mycustvis_prediction")
publish_model(mod, "mypublishedmod", pred_res)

unpublish_model(mod)


## End(Not run)
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+cognitive_endpoint'></span><span id='topic+call_cognitive_endpoint'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>AzureCognitive</dt><dd><p><code><a href="AzureCognitive.html#topic+call_cognitive_endpoint">call_cognitive_endpoint</a></code>, <code><a href="AzureCognitive.html#topic+cognitive_endpoint">cognitive_endpoint</a></code></p>
</dd>
</dl>

<hr>
<h2 id='show_model'>Display model iteration details</h2><span id='topic+show_model'></span><span id='topic+show_training_performance'></span><span id='topic+summary.customvision_model'></span>

<h3>Description</h3>

<p>Display model iteration details
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_model(model)

show_training_performance(model, threshold = 0.5, overlap = NULL)

## S3 method for class 'customvision_model'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_model_+3A_model">model</code>, <code id="show_model_+3A_object">object</code></td>
<td>
<p>A Custom Vision model iteration object.</p>
</td></tr>
<tr><td><code id="show_model_+3A_threshold">threshold</code></td>
<td>
<p>For a classification model, the probability threshold to assign an image to a class.</p>
</td></tr>
<tr><td><code id="show_model_+3A_overlap">overlap</code></td>
<td>
<p>For an object detection model, the overlap threshold for distinguishing between overlapping objects.</p>
</td></tr>
<tr><td><code id="show_model_+3A_...">...</code></td>
<td>
<p>Arguments passed to lower-level functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>show_model</code> displays the metadata for a model iteration: the name (assigned by default), model training status, publishing details, and so on. <code>show_training_performance</code> displays summary statistics for the model's performance on the training data. The <code>summary</code> method for Custom Vision model objects simply calls <code>show_training_performance</code>.
</p>


<h3>Value</h3>

<p>For <code>show_model</code>, a list containing the metadata for the model iteration. For <code>show_training_performance</code> and <code>summary.customvision_model</code>, a list of performance diagnostics.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+train_model">train_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- customvision_training_endpoint(url="endpoint_url", key="key")
myproj &lt;- get_project(endp, "myproject")
mod &lt;- get_model(myproj)

show_model(mod)

show_training_performance(mod)
summary(mod)


## End(Not run)
</code></pre>

<hr>
<h2 id='train_model'>Create, retrieve, rename and delete a model iteration</h2><span id='topic+train_model'></span><span id='topic+list_models'></span><span id='topic+get_model'></span><span id='topic+rename_model'></span><span id='topic+delete_model'></span><span id='topic+delete_model.customvision_project'></span><span id='topic+delete_model.customvision_model'></span>

<h3>Description</h3>

<p>Create, retrieve, rename and delete a model iteration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_model(project, training_method = c("quick", "advanced"),
  max_time = 1, force = FALSE, email = NULL, wait = (training_method ==
  "quick"))

list_models(project, as = c("ids", "list"))

get_model(project, iteration = NULL)

rename_model(model, name, ...)

delete_model(object, ...)

## S3 method for class 'customvision_project'
delete_model(object, iteration = NULL, confirm = TRUE, ...)

## S3 method for class 'customvision_model'
delete_model(object, confirm = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_model_+3A_project">project</code></td>
<td>
<p>A Custom Vision project.</p>
</td></tr>
<tr><td><code id="train_model_+3A_training_method">training_method</code></td>
<td>
<p>The training method to use. The default &quot;quick&quot; is faster but may be less accurate. The &quot;advanced&quot; method is slower but produces better results.</p>
</td></tr>
<tr><td><code id="train_model_+3A_max_time">max_time</code></td>
<td>
<p>For advanced training, the maximum training time in hours.</p>
</td></tr>
<tr><td><code id="train_model_+3A_force">force</code></td>
<td>
<p>For advanced training, whether to refit the model even if the data has not changed since the last iteration.</p>
</td></tr>
<tr><td><code id="train_model_+3A_email">email</code></td>
<td>
<p>For advanced training, an email address to notify when the training is complete.</p>
</td></tr>
<tr><td><code id="train_model_+3A_wait">wait</code></td>
<td>
<p>whether to wait until training is complete (or the maximum training time has elapsed) before returning.</p>
</td></tr>
<tr><td><code id="train_model_+3A_as">as</code></td>
<td>
<p>For <code>list_models</code>, the format in which to return results: as a named vector of model iteration IDs, or a list of model objects.</p>
</td></tr>
<tr><td><code id="train_model_+3A_iteration">iteration</code></td>
<td>
<p>For <code>get_model</code> and <code>delete_model.customvision_project</code>, either the iteration name or ID.</p>
</td></tr>
<tr><td><code id="train_model_+3A_model">model</code></td>
<td>
<p>A Custom Vision model.</p>
</td></tr>
<tr><td><code id="train_model_+3A_name">name</code></td>
<td>
<p>For <code>rename_model</code>, the new name for the model.</p>
</td></tr>
<tr><td><code id="train_model_+3A_...">...</code></td>
<td>
<p>Arguments passed to lower-level functions.</p>
</td></tr>
<tr><td><code id="train_model_+3A_object">object</code></td>
<td>
<p>For the <code>delete_model</code> method, a Custom Vision project or model, as appropriate.</p>
</td></tr>
<tr><td><code id="train_model_+3A_confirm">confirm</code></td>
<td>
<p>For the <code>delete_model</code> methods, whether to ask for confirmation first.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Training a Custom Vision model results in a <em>model iteration</em>. Each iteration is based on the current set of images uploaded to the endpoint. Successive model iterations trained on different image sets do not overwrite previous ones.
</p>
<p>You must have at least 5 images per tag for a classification project, and 15 images per tag for an object detection project, before you can train a model.
</p>
<p>By default, AzureVision will use the latest model iteration for actions such as prediction, showing performance statistics, and so on. You can list the model iterations with <code>list_models</code>, and retrieve a specific iteration by passing the iteration ID to <code>get_model</code>.
</p>


<h3>Value</h3>

<p>For <code>train_model</code>, <code>get_model</code> and <code>rename_model</code>, an object of class <code>customvision_model</code> which is a handle to the iteration.
</p>
<p>For <code>list_models</code>, based on the <code>as</code> argument: <code>as="ids"</code> returns a named vector of model iteration IDs, while <code>as="list"</code> returns a list of model objects.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+show_model">show_model</a></code>, <code><a href="#topic+show_training_performance">show_training_performance</a></code>, <code><a href="#topic+publish_model">publish_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- customvision_training_endpoint(url="endpoint_url", key="key")
myproj &lt;- get_project(endp, "myproject")

train_model(myproj)
train_model(myproj, method="advanced", force=TRUE, email="me@example.com")

list_models(myproj)

mod &lt;- get_model(myproj)
rename(mod, "mymodel")
mod &lt;- get_model(myproj, "mymodel")

delete_model(mod)


## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
