<!DOCTYPE html><html><head><title>Help for package ddecompose</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ddecompose}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggregate_terms'><p>Aggregate decomposition terms</p></a></li>
<li><a href='#bootstrap_estimate_ob_decompose'><p>Bootstrapping the OB decomposition</p></a></li>
<li><a href='#dfl_decompose'><p>DFL reweighting decomposition</p></a></li>
<li><a href='#dfl_decompose_bootstrap'><p>Bootstrapping the DFL reweighting decomposition</p></a></li>
<li><a href='#dfl_decompose_estimate'><p>Estimate the DFL reweighting decomposition</p></a></li>
<li><a href='#estimate_iq_range'><p>Interquantile range</p></a></li>
<li><a href='#estimate_iq_ratio'><p>Interquantile ratio</p></a></li>
<li><a href='#estimate_ob_decompose'><p>Estimate OB decomposition</p></a></li>
<li><a href='#fit_and_predict_probabilities'><p>Predict conditional probabilities</p></a></li>
<li><a href='#get_distributional_statistics'><p>Estimate distributional statistics</p></a></li>
<li><a href='#get_normalized_difference'><p>Get normalized differences</p></a></li>
<li><a href='#GU_normalization'><p>Gardeazabal and Ugidos normalization of factor variables</p></a></li>
<li><a href='#GU_normalization_get_coefficients'><p>Get coefficients for GU normalization</p></a></li>
<li><a href='#GU_normalization_get_vcov'><p>Get covariance matrix for GU normalization</p></a></li>
<li><a href='#GU_normalization_sum_coefficients'><p>Sum coefficients for GU normalization</p></a></li>
<li><a href='#GU_normalization_sum_vcov'><p>Sum covariance matrix for GU normalization</p></a></li>
<li><a href='#men8305'><p>Sample of male wage data from the CPS 1983-1985 and 2003-2005</p></a></li>
<li><a href='#nlys00'><p>Sample of NLSY79 wage data from 2000</p></a></li>
<li><a href='#ob_decompose'><p>Oaxaca-Blinder decomposition</p></a></li>
<li><a href='#ob_decompose_calculate_terms'><p>Calculate OB decomposition terms</p></a></li>
<li><a href='#ob_decompose_calculate_vcov'><p>Calculate covariance matrix for OB decomposition terms</p></a></li>
<li><a href='#plot.dfl_decompose'><p>Plot decomposition terms for quantiles</p></a></li>
<li><a href='#plot.ob_decompose'><p>Plot decomposition terms for quantiles</p></a></li>
<li><a href='#print.dfl_decompose'><p>print method for class &quot;dfl_decompose&quot;</p></a></li>
<li><a href='#print.ob_decompose'><p>print method for class &quot;ob_decompose&quot;</p></a></li>
<li><a href='#select_observations_to_be_trimmed'><p>Select observations with little common support to be trimmed</p></a></li>
<li><a href='#summary.dfl_decompose'><p>summary method for class &quot;dfl_decompose&quot;</p></a></li>
<li><a href='#summary.ob_decompose'><p>summary method for class &quot;ob_decompose&quot;</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Detailed Distributional Decomposition</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Samuel Meier &lt;samuel.meier+ddecompose@immerda.ch&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the Oaxaca-Blinder decomposition method and generalizations of it that decompose differences in distributional statistics beyond the mean.
    The function ob_decompose() decomposes differences in the mean outcome between two groups into one part explained by different covariates (composition effect) and into another part due to differences in the way covariates are linked to the outcome variable (structure effect). The function further divides the two effects into the contribution of each covariate and allows for weighted doubly robust decompositions. For distributional statistics beyond the mean, the function performs the recentered influence function (RIF) decomposition proposed by Firpo, Fortin, and Lemieux (2018).
    The function dfl_decompose() divides differences in distributional statistics into an composition effect and a structure effect using inverse probability weighting as introduced by DiNardo, Fortin, and Lemieux (1996). The function also allows to sequentially decompose the composition effect into the contribution of single covariates.
    References: 
    Firpo, Sergio, Nicole M. Fortin, and Thomas Lemieux. (2018) &lt;<a href="https://doi.org/10.3390%2Feconometrics6020028">doi:10.3390/econometrics6020028</a>&gt;. "Decomposing Wage Distributions Using Recentered Influence Function Regressions."
    Fortin, Nicole M., Thomas Lemieux, and Sergio Firpo. (2011) &lt;<a href="https://doi.org/10.3386%2Fw16045">doi:10.3386/w16045</a>&gt;. "Decomposition Methods in Economics."
    DiNardo, John, Nicole M. Fortin, and Thomas Lemieux. (1996) &lt;<a href="https://doi.org/10.2307%2F2171954">doi:10.2307/2171954</a>&gt;. "Labor Market Institutions and the Distribution of Wages, 1973-1992: A Semiparametric Approach."
    Oaxaca, Ronald. (1973) &lt;<a href="https://doi.org/10.2307%2F2525981">doi:10.2307/2525981</a>&gt;. "Male-Female Wage Differentials in Urban Labor Markets."
    Blinder, Alan S. (1973) &lt;<a href="https://doi.org/10.2307%2F144855">doi:10.2307/144855</a>&gt;. "Wage Discrimination: Reduced Form and Structural Estimates."</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>ggplot2, R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>rifreg, Formula, Hmisc, parallel, pbapply, sandwich, stats,
ranger, fastglm, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), tidyr, dplyr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-07 07:44:54 UTC; daidai</td>
</tr>
<tr>
<td>Author:</td>
<td>David Gallusser [aut],
  Samuel Meier [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-07 15:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggregate_terms'>Aggregate decomposition terms</h2><span id='topic+aggregate_terms'></span>

<h3>Description</h3>

<p>The function aggregates decomposition terms and calculates
their covariance matrix based on detailed decomposition results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_terms(
  x,
  aggregate_factors = TRUE,
  custom_aggregation = NULL,
  reweighting
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate_terms_+3A_x">x</code></td>
<td>
<p>an object of class &quot;ob_decompose&quot;, usually , a result of a call to [ob_decompose()].</p>
</td></tr>
<tr><td><code id="aggregate_terms_+3A_aggregate_factors">aggregate_factors</code></td>
<td>
<p>boolean, if 'TRUE' (default) terms associated with detailed factor
levels are aggregated to a single term for every factor variable.</p>
</td></tr>
<tr><td><code id="aggregate_terms_+3A_custom_aggregation">custom_aggregation</code></td>
<td>
<p>list specifying the aggregation of detailed decomposition
terms. The parameter 'custom_aggregation' overrides the parameter 'aggregate_factors'.
If 'NULL' (default), then either all detailed terms or all terms associated with
a single variable are returned.</p>
</td></tr>
<tr><td><code id="aggregate_terms_+3A_reweighting">reweighting</code></td>
<td>
<p>boolean, if 'TRUE' the decompostion in 'object' contains reweighting
(i.e. specification and reweighting error)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an updated object of class &quot;ob_decompose&quot; containing
the aggregated decomposition terms.
</p>

<hr>
<h2 id='bootstrap_estimate_ob_decompose'>Bootstrapping the OB decomposition</h2><span id='topic+bootstrap_estimate_ob_decompose'></span>

<h3>Description</h3>

<p>The function resamples observations and restimates the OB decomposition
with the new sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap_estimate_ob_decompose(
  formula_decomposition,
  formula_reweighting,
  data_used,
  group,
  reference_0,
  normalize_factors,
  reweighting,
  reweighting_method,
  trimming,
  trimming_threshold,
  rifreg,
  rifreg_statistic,
  rifreg_probs,
  custom_rif_function,
  na.action,
  cluster = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_formula_decomposition">formula_decomposition</code></td>
<td>
<p><code>formula</code> object that contains the formula for the decomposition</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_formula_reweighting">formula_reweighting</code></td>
<td>
<p><code>formula</code> object that contains the formula for
the reweighting in case of a reweighted decompostion</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_data_used">data_used</code></td>
<td>
<p><code>data.frame</code> with data used for estimation (including weight and group variable)</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_group">group</code></td>
<td>
<p>name of the a binary variable (numeric or factor)
identifying the two groups that will be compared. The group identified by the
lower ranked value in 'group' (i.e., 0 in the case of a dummy variable or the
first level of factor variable) is defined as group 0.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_reference_0">reference_0</code></td>
<td>
<p>boolean: indicating if group 0 is the reference group and if its coefficients are used to compute the counterfactual mean.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_normalize_factors">normalize_factors</code></td>
<td>
<p>boolean: If 'TRUE', then factor variables are normalized as proposed by Gardeazabal/Ugidos (2004)</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_reweighting">reweighting</code></td>
<td>
<p>boolean: if 'TRUE', then the decomposition is performed with
with respect to reweighted reference group.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_reweighting_method">reweighting_method</code></td>
<td>
<p>specifies the method fit and predict conditional probabilities
used to derive the reweighting factor. Currently, <code>"logit"</code>, <code>"fastglm"</code>,
and <code>"random_forest"</code> are available.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_trimming">trimming</code></td>
<td>
<p>boolean: If <code>TRUE</code>, observations with dominant reweighting factor
values are trimmend according to rule of Huber, Lechner, and Wunsch (2013). Per
default, trimming is set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_trimming_threshold">trimming_threshold</code></td>
<td>
<p>numeric: threshold defining the maximal accepted
relative weight of the reweighting factor value (i.e., inverse probability weight)
of a single observation. If <code>NULL</code>, the threshold is set to <code class="reqn">sqrt(N)/N</code>,
where <code class="reqn">N</code> is the number of observations in the reference group.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_rifreg">rifreg</code></td>
<td>
<p>boolean: if 'TRUE', then RIF decomposition is performed</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_rifreg_statistic">rifreg_statistic</code></td>
<td>
<p>string containing the distributional statistic for which to compute the RIF.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_rifreg_probs">rifreg_probs</code></td>
<td>
<p>a vector of length 1 or more with probabilities of quantiles.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_custom_rif_function">custom_rif_function</code></td>
<td>
<p>the RIF function to compute the RIF of the custom distributional statistic.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_na.action">na.action</code></td>
<td>
<p>generic function that defines how NAs in the data should be handled.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_cluster">cluster</code></td>
<td>
<p>numeric vector of same length as <code>dep_var</code> indicating the
clustering of observations. If <code>cluster = NULL</code> (default), no clustering
is a assumend and bootstrap procedure resamples individual observations. Otherwise
bootstrap procedure resamples clusters.</p>
</td></tr>
<tr><td><code id="bootstrap_estimate_ob_decompose_+3A_...">...</code></td>
<td>
<p>additional parameters passed to custom_rif_function</p>
</td></tr>
</table>

<hr>
<h2 id='dfl_decompose'>DFL reweighting decomposition</h2><span id='topic+dfl_decompose'></span>

<h3>Description</h3>

<p><code>dfl_decompose</code> divides between-group differences in distributional
statistics of an outcome variable into a structure effect and a composition
effect. Following DiNardo, Fortin, and Lemieux (1996), the procedure reweights
the sample distribution of a reference group such that the group's covariates
distribution matches the covariates distribution of a comparison group.
</p>
<p>The function derives counterfactual distributions with inverse probability
weigthing. Reweighting factors are estimate by modelling the probability of
belonging to the comparison group conditional on covariates.
</p>
<p>The function allows detailed decompositions of the composition effect by
sequentially reweighting (conditional) covariate distributions. Standard
errors can be bootstrapped.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfl_decompose(
  formula,
  data,
  weights,
  group,
  na.action = na.exclude,
  reference_0 = TRUE,
  subtract_1_from_0 = FALSE,
  right_to_left = TRUE,
  method = "logit",
  estimate_statistics = TRUE,
  statistics = c("quantiles", "mean", "variance", "gini", "iq_range_p90_p10",
    "iq_range_p90_p50", "iq_range_p50_p10"),
  probs = c(1:9)/10,
  custom_statistic_function = NULL,
  trimming = FALSE,
  trimming_threshold = NULL,
  return_model = TRUE,
  estimate_normalized_difference = TRUE,
  bootstrap = FALSE,
  bootstrap_iterations = 100,
  bootstrap_robust = FALSE,
  cores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfl_decompose_+3A_formula">formula</code></td>
<td>
<p>a <code>formula</code> object with an outcome variable Y on the left-hand side
and the covariates X on the right-hand side. For sequential decompositions,
the sequence of covariates X are distinguished by the <code>|</code> operator.
Covariates are used to estimate the conditional probabilities for the reweighting factors.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> containing all variables and observations of
both groups.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_weights">weights</code></td>
<td>
<p>name of the observation weights variable or vector of
observation weights.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_group">group</code></td>
<td>
<p>name of a binary variable (numeric or factor) identifying the
two groups for which the differences are to be decomposed. The group
identified by the lower ranked value in <code>group</code> (i.e., 0 in the
case of a dummy variable or the first level of factor variable) is defined
as group 0. Per default, group 0 is the reference group (see <code>reference_0</code>).</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_na.action">na.action</code></td>
<td>
<p>a function to filter missing data (default <code>na.exclude</code>).</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_reference_0">reference_0</code></td>
<td>
<p>boolean: if <code>TRUE</code> (default), then the group 0 &ndash; i.e.,
the group identified by the lower ranked value in <code>group</code> &ndash; will be defined
as reference group. The reference group will be reweighted to match the
covariates distribution of the sample of the comparison group.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_subtract_1_from_0">subtract_1_from_0</code></td>
<td>
<p>boolean: By default ('FALSE'), the distributional statistic
of group 0 is subtracted from the one of group 1 to compute the overall difference.
Setting 'subtract_1_from_0' to 'TRUE' merely changes the sign of the decomposition
results.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_right_to_left">right_to_left</code></td>
<td>
<p>determines the direction of a sequential decomposition.
If <code>TRUE</code> (default), the sequential decomposition starts right and reweights
first the reference group using only the variables entered last into the
<code>formula</code> sequence. Sequentially, the other variables are added. Otherwise,
the decomposition start left and using all variables entered into
<code>formula</code> object from the start, sequentially removing variables.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_method">method</code></td>
<td>
<p>specifies the method to fit and predict conditional probabilities
used to derive the reweighting factor. At the moment, <code>"logit"</code>, <code>"fastglm"</code>,
and <code>"random_forest"</code> are available.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_estimate_statistics">estimate_statistics</code></td>
<td>
<p>boolean: if <code>TRUE</code> (default), then distributional
statistics are estimated and the decomposition is performed. If <code>FALSE</code>,
the function only returns the fitted inverse propensity weights.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_statistics">statistics</code></td>
<td>
<p>a character vector that defines the distributional statistics
for which the decomposition is performed. Per default,
<code>c("quantiles", "mean", "variance", "gini", "iq_range_p90_p10", "iq_range_p90_p50", "iq_range_p50_p10")</code>
are estimated and decomposed. Also implemented are 'c(&quot;iq_ratio_p90_p10&quot;, &quot;iq_ratio_p90_p50&quot;, &quot;iq_ratio_p50_p10&quot;)'.
Note: The function calculates the Gini coefficient for the untransformed variable
(i.e., <code>exp(log(Y))</code>), if the logarithm of a variable Y is set as outcome variable
in <code>formula</code>).</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_probs">probs</code></td>
<td>
<p>a vector of length 1 or more with the probabilities of the quantiles
to be estimated with default <code>c(1:9)/10</code>.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_custom_statistic_function">custom_statistic_function</code></td>
<td>
<p>a function estimating a custom distributional statistic
that will be decomposed (<code>NULL</code> by default). Every custom_statistic_function needs the parameters
<code>dep_var</code> (vector of the outcome variable) and <code>weights</code> (vector with observation weights);
additional arguments are not allowed or need to be 'hardcoded'. See <code>examples</code> for further details.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_trimming">trimming</code></td>
<td>
<p>boolean: If <code>TRUE</code>, observations with dominant reweighting factor
values are trimmed according to rule of Huber, Lechner, and Wunsch (2013). Per
default, trimming is set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_trimming_threshold">trimming_threshold</code></td>
<td>
<p>numeric: threshold defining the maximal accepted
relative weight of the reweighting factor value (i.e., inverse probability weight)
of a single observation. If <code>NULL</code>, the threshold is set to <code class="reqn">sqrt(N)/N</code>,
where <code class="reqn">N</code> is the number of observations in the reference group.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_return_model">return_model</code></td>
<td>
<p>boolean: If <code>TRUE</code> (default), the object(s) of the model
fit(s) used to predict the conditional probabilities for the reweighting factor(s)
are returned.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_estimate_normalized_difference">estimate_normalized_difference</code></td>
<td>
<p>boolean: If <code>TRUE</code> (default), the
normalized differences between the covariate means of the comparison group and the
reweighted reference group are calculated.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_bootstrap">bootstrap</code></td>
<td>
<p>boolean: If <code>FALSE</code> (default), then the estimation is not boostrapped
and no standard errors are calculated.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_bootstrap_iterations">bootstrap_iterations</code></td>
<td>
<p>positive integer with default <code>100</code> indicating the
number of bootstrap iterations to be executed.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_bootstrap_robust">bootstrap_robust</code></td>
<td>
<p>boolean: if <code>FALSE</code> (default), then bootstrapped standard
errores are estimated as the standard deviations of the bootstrapp estimates.
Otherwise, the function uses the bootstrap interquartile range rescaled by the
interquantile range of the standard distribution to estimate standard errors.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_cores">cores</code></td>
<td>
<p>positive integer with default <code>1</code> indicating the number of cores
to use when computing bootstrap standard errors.</p>
</td></tr>
<tr><td><code id="dfl_decompose_+3A_...">...</code></td>
<td>
<p>other parameters passed to the function estimating the conditional probabilities.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The observed difference to be decomposed equals the difference between the values
of the distributional statistic of <code>group</code> 1 and <code>group</code> 0, respectively:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_O = \nu_1 - \nu_0,</code>
</p>

<p>where <code class="reqn">\nu_t = \nu(F_g)</code> denotes the statistics of the outcome distribution
<code class="reqn">F_g</code> of group <code class="reqn">g</code>. Group 0 is identified by the lower ranked value
of the <code>group</code> variable.
</p>
<p>If <code>reference_0=TRUE</code>, then group 0 is the reference group and its observations
are reweighted such that they match the covariates distribution of group 1, the
comparison group. The counterfactual combines the covariates distribution
<code class="reqn">F_1(x)</code> of group 1 with the conditional outcome distribution <code class="reqn">F_0(y|x)</code>
of group 0 and is derived by reweighting group 0
</p>
<p style="text-align: center;"><code class="reqn">F_C(y) = \int F_0(y|x) dF_1(x) = \int F_0(y|x) \Psi(x) dF_0(x),</code>
</p>

<p>where <code class="reqn">\Psi(x)</code> is the reweighting factor, i.e., the inverse probabilities
of belonging to the comparison group conditional on covariates x.
</p>
<p>The distributional statistic of the counterfactual distribution,
<code class="reqn">\nu_C = \nu(F_C)</code>, allows to decompose the observed difference into
a (wage) structure effect (<code class="reqn">\Delta_S = \nu_1 - \nu_C</code>) and a
composition effect (<code class="reqn">\Delta_C = \nu_C - \nu_0</code>).
</p>
<p>If <code>reference_0=FALSE</code>, then the counterfactual is derived by combining
the covariates distribution of group 0 with the conditional outcome
distribution of group 1 and, thus, reweighting group 1
</p>
<p style="text-align: center;"><code class="reqn">F_C(y) = \int F_1(y|x) dF_0(x) = \int F_1(y|x) \Psi(x) dF_1(x).</code>
</p>

<p>The composition effect becomes <code class="reqn">\Delta_C = \nu_1 - \nu_C</code> and the
structure effect <code class="reqn">\Delta_S = \nu_C - \nu_0</code>, respectively.
</p>
<p>The covariates are defined in <code>formula</code>. The reweighting factor is
estimated in the pooled sample with observations from both groups. <code>method = "logit"</code>
uses a logit model to fit the conditional probabilities. <code>method = "fastglm"</code>
also fits a logit model but with a faster algorithm from <strong>fastglm</strong>.
<code>method = "random_forest"</code> uses the <strong>Ranger</strong> implementation of
the random forests classifier.
</p>
<p>The counterfactual statistics are then estimated with the observed data of
the reference group and the fitted reweighting factors.
</p>
<p><code>formula</code> allows to specify interaction terms in the conditional
probability models. If you are interested in an aggregate decomposition,
then all covariates have to be entered at once, e.g., <code>Y ~ X + Z</code>.
</p>
<p>The procedure allows for sequential decomposition of the composition effect.
In this case, more than one reweighting factor based on different sets of
covariates are estimated.
</p>
<p>If you are interested in a sequential decomposition, the decomposition
sequence has to be distinguished by the <code>|</code> operator in the <code>formula</code>
object. For instance, <code>Y ~ X | Z</code> would decompose the aggregate composition
effect into the contribution of covariate(s) X and the one of covariate(s) Z,
respectively.
</p>
<p>In this two-fold sequential decomposition, we have the detailed composition
effects
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{C_X} = \nu_1 - \nu_{CX},</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{C_Z} = \nu_{CX} - \nu_C,</code>
</p>

<p>which sum up to the aggregate composition effect <code class="reqn">\Delta_C</code>.
<code class="reqn">\nu_C</code> is defined as above. It captures the contribution of all
covariates (i.e., X and Z). In contrast, <code class="reqn">\nu_{CX}</code> corresponds
to the statistic of the counterfactual distribution isolating the contribution
of covariate(s) X in contrast to the one of covariate(s) Z.
</p>
<p>If <code>right_to_left=TRUE</code>, then the counterfactual is defined as
</p>
<p style="text-align: center;"><code class="reqn">F_{CX}(y) = \iint F_0(y|x,z) dF_0(x|z) dF_1(z),</code>
</p>

<p>where <code class="reqn">F_1(x|z)</code> is the conditional distribution of X given Z of
group 1 and <code class="reqn">F_0(z)</code> the distribution of Z. If <code>right_to_left=FALSE</code>,
we have
</p>
<p style="text-align: center;"><code class="reqn">F_{CX}(y) = \iint F_0(y|x,z) dF_1(x|z) dF_0(z).</code>
</p>

<p>Note that it is possible to specify the detailed models in every part of <code>formula</code>.
This is useful if you want to estimate in every step a fully saturated model,
e.g., <code>Y ~ X * Z | Z</code>. If not further specified, the variables are
additively included in the model used to derived the aggregate reweighting
factor.
</p>
<p>The detailed decomposition terms are path-dependent. The results depend on the sequence
the covariates enter the decomposition (e.g, <code>Y ~ X | Z</code> yields different
detailed decomposition terms than <code>Y ~ Z | X</code>) . Even for the same sequence,
the results differ depending on the 'direction' of the decomposition. In
the example above using <code>right_to_left=TRUE</code>, the contribution of Z is evaluated
using the conditional distribution of X given Z from group 0. If we use
<code>right_to_left=FALSE</code> instead, the same contribution is evaluated using
the conditional distribution from group 1.
</p>
<p>Per default, the distributional statistics for which the between group differences
are decomposed are quantiles, the mean, the variance, the Gini coefficient
and the interquantile range between the 9th and the 1st decile, the 9th decile
and the median, and the median and the first decile, respectively. The interquantile
ratios between the same quantiles are implemented, as well.
</p>
<p>The quantiles can be specified by <code>probs</code> that sets the corresponding
probabilities of the quantiles of interest. For other distributional statistics,
please use <code>custom_statistic_function</code>
</p>
<p>The function bootstraps standard errors and derives a bootstrapped Kolmogorov-Smirnov
distribution to construct uniform confindence bands. The Kolmogorov-Smirnov distribution
is estimated as in Chen et al. (2017).
</p>


<h3>Value</h3>

<p>an object of class <code>dfl_decompose</code> containing a data.frame with the
decomposition results for the quantiles and for the other distributional
statistics, respectively, a data.frame with the estimated reweighting factor
for every observation, a data.frame with sample quantiles of the reweighting
factors and a list with standard errors for the decomposition terms, the
quantiles of the reweighting factor, the bootstrapped
Kolmogorov-Smirnov distribution to construct uniform confidence bands for
quantiles, as well as a list with the normalized differences between the
covariate means of the comparison group and the reweighted reference group.
</p>


<h3>References</h3>

<p>Chen, Mingli, Victor Chernozhukov, Iván Fernández-Val, and Blaise Melly. 2017.
&quot;Counterfactual: An R Package for Counterfactual Analysis.&quot; *The R Journal* 9(1): 370-384.
</p>
<p>DiNardo, John, Nicole M. Fortin, and Thomas Lemieux. 1996. &quot;Labor Market
Institutions and the Distribution of Wages, 1973-1992: A Semiparametric Approach.&quot;
<em>Econometrica</em>, 64(5), 1001-1044.
</p>
<p>Firpo, Sergio P., Nicole M. Fortin, and Thomas Lemieux. 2018. &quot;Decomposing Wage
Distributions Using Recentered Influence Function Regressions.&quot;
<em>Econometrics</em> 6(2), 28.
</p>
<p>Fortin, Nicole M., Thomas Lemieux, and Sergio Firpo. 2011. &quot;Decomposition methods in economics.&quot;
In Orley Ashenfelter and David Card, eds., <em>Handbook of Labor Economics</em>. Vol. 4. Elsevier, 1-102.
</p>
<p>Firpo, Sergio P., and Cristine Pinto. 2016. &quot;Identification and Estimation of
Distributional Impacts of Interventions Using Changes in Inequality Measures.&quot;
<em>Journal of Applied Econometrics</em>, 31(3), 457-486.
</p>
<p>Huber, Martin, Michael Lechner, and Conny Wunsch. 2013. &quot;The performance of
estimators based on the propensity score.&quot; <em>Journal of Econometrics</em>,
175(1), 1-21.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example from handbook chapter of Fortin, Lemieux, and Firpo (2011: 67)
## with a sample of the original data


data("men8305")

flf_model &lt;- log(wage) ~ union * (education + experience) + education * experience

# Reweighting sample from 1983-85
flf_male_inequality &lt;- dfl_decompose(flf_model,
  data = men8305,
  weights = weights,
  group = year
)

# Summarize results
summary(flf_male_inequality)

# Plot decomposition of quantile differences
plot(flf_male_inequality)

# Use alternative reference group (i.e., reweight sample from 2003-05)
flf_male_inequality_reference_0305 &lt;- dfl_decompose(flf_model,
  data = men8305,
  weights = weights,
  group = year,
  reference_0 = FALSE
)
summary(flf_male_inequality_reference_0305)

# Bootstrap standard errors (using smaller sample for the sake of illustration)

set.seed(123)
flf_male_inequality_boot &lt;- dfl_decompose(flf_model,
  data = men8305[1:1000, ],
  weights = weights,
  group = year,
  bootstrap = TRUE,
  bootstrap_iterations = 100,
  cores = 1
)

# Get standard errors and confidence intervals
summary(flf_male_inequality_boot)

# Plot quantile differences with pointwise confidence intervals
plot(flf_male_inequality_boot)

# Plot quantile differences with uniform confidence intervals
plot(flf_male_inequality_boot, uniform_bands = TRUE)



## Sequential decomposition

# Here we distinguish the contribution of education and experience
# from the contribution of unionization conditional on education and experience.


model_sequential &lt;- log(wage) ~ union * (education + experience) +
  education * experience |
  education * experience

# First variant:
# Contribution of union is evaluated using composition of
# education and experience from 2003-2005 (group 1)

male_inequality_sequential &lt;- dfl_decompose(model_sequential,
  data = men8305,
  weights = weights,
  group = year
)

# Summarize results
summary(male_inequality_sequential)

# Second variant:
# Contribution of union is evaluated using composition of
# education and experience from 1983-1985 (group 0)

male_inequality_sequential_2 &lt;- dfl_decompose(model_sequential,
  data = men8305,
  weights = weights,
  group = year,
  right_to_left = FALSE
)

# Summarize results
summary(male_inequality_sequential_2)

# The domposition effects associated with (conditional) unionization for deciles
cbind(
  male_inequality_sequential$decomposition_quantiles$prob,
  male_inequality_sequential$decomposition_quantiles$`Comp. eff. X1|X2`,
  male_inequality_sequential_2$decomposition_quantiles$`Comp. eff. X1|X2`
)


## Trim observations with weak common support
## (i.e. observations with relative factor weights &gt; \sqrt(N)/N)

set.seed(123)
data_weak_common_support &lt;- data.frame(
  d = factor(c(
    c("A", "A", rep("B", 98)),
    c(rep("A", 90), rep("B", 10))
  )),
  group = rep(c(0, 1), each = 100)
)
data_weak_common_support$y &lt;- ifelse(data_weak_common_support$d == "A", 1, 2) +
  data_weak_common_support$group +
  rnorm(200, 0, 0.5)

decompose_results_trimmed &lt;- dfl_decompose(y ~ d,
  data_weak_common_support,
  group = group,
  trimming = TRUE
)

identical(
  decompose_results_trimmed$trimmed_observations,
  which(data_weak_common_support$d == "A")
)



## Pass a custom statistic function to decompose income share of top 10%

top_share &lt;- function(dep_var,
                      weights,
                      top_percent = 0.1) {
  threshold &lt;- Hmisc::wtd.quantile(dep_var, weights = weights, probs = 1 - top_percent)
  share &lt;- sum(weights[which(dep_var &gt; threshold)] *
    dep_var[which(dep_var &gt; threshold)]) /
    sum(weights * dep_var)
  return(share)
}

flf_male_inequality_custom_stat &lt;- dfl_decompose(flf_model,
  data = men8305,
  weights = weights,
  group = year,
  custom_statistic_function = top_share
)
summary(flf_male_inequality_custom_stat)

</code></pre>

<hr>
<h2 id='dfl_decompose_bootstrap'>Bootstrapping the DFL reweighting decomposition</h2><span id='topic+dfl_decompose_bootstrap'></span>

<h3>Description</h3>

<p>The function resamples observations and restimates the DFL decomposition
with the new sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfl_decompose_bootstrap(
  formula,
  dep_var,
  data_used,
  weights,
  group_variable,
  reference_group,
  estimate_statistics,
  statistics,
  probs,
  custom_statistic_function,
  right_to_left,
  trimming,
  trimming_threshold,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfl_decompose_bootstrap_+3A_formula">formula</code></td>
<td>
<p><code>formula</code> object</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_dep_var">dep_var</code></td>
<td>
<p>dependent variable</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_data_used">data_used</code></td>
<td>
<p><code>data.frame</code> with data used for estimation</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_weights">weights</code></td>
<td>
<p>weights variable</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_group_variable">group_variable</code></td>
<td>
<p>group variable</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_reference_group">reference_group</code></td>
<td>
<p>reference_group to be reweighted</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_estimate_statistics">estimate_statistics</code></td>
<td>
<p>boolean: if <code>TRUE</code> (default), then distributional
statistics are estimated and the decomposition is performed. If <code>FALSE</code>,
the function only returns the fitted inverse propensity weights.</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_statistics">statistics</code></td>
<td>
<p>a character vector that defines the distributional statistics
for which the decomposition is performed.</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_probs">probs</code></td>
<td>
<p>a vector of length 1 or more with the probabilities of the quantiles
to be estimated.</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_custom_statistic_function">custom_statistic_function</code></td>
<td>
<p>a function estimating a custom distributional statistic
that will be decomposed.</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_right_to_left">right_to_left</code></td>
<td>
<p>determines the direction of a sequential decomposition.</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_trimming">trimming</code></td>
<td>
<p>boolean: If <code>TRUE</code>, observations with dominant reweighting factor
values are trimmed according to rule of Huber, Lechner, and Wunsch (2013).</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_trimming_threshold">trimming_threshold</code></td>
<td>
<p>numeric: threshold defining the maximal accepted
relative weight of the reweighting factor value (i.e., inverse probability weight)
of a single observation. If <code>NULL</code>, the threshold is set to <code class="reqn">sqrt(N)/N</code>,
where <code class="reqn">N</code> is the number of observations in the reference group.</p>
</td></tr>
<tr><td><code id="dfl_decompose_bootstrap_+3A_...">...</code></td>
<td>
<p>other parameters passed to the function estimating the conditional probabilities.</p>
</td></tr>
</table>

<hr>
<h2 id='dfl_decompose_estimate'>Estimate the DFL reweighting decomposition</h2><span id='topic+dfl_decompose_estimate'></span>

<h3>Description</h3>

<p>This function performs the DFL decomposition. It derives the
reweighting factors, estimates the distributional statistics and
calculates the decomposition terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfl_decompose_estimate(
  formula,
  dep_var,
  data_used,
  weights,
  group_variable,
  reference_group,
  method,
  estimate_statistics,
  statistics,
  probs,
  custom_statistic_function,
  right_to_left,
  trimming,
  trimming_threshold,
  return_model,
  estimate_normalized_difference,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfl_decompose_estimate_+3A_formula">formula</code></td>
<td>
<p><code>formula</code> object</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_dep_var">dep_var</code></td>
<td>
<p>dependent variable</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_data_used">data_used</code></td>
<td>
<p><code>data.frame</code> with data used for estimation</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_weights">weights</code></td>
<td>
<p>weights variable</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_group_variable">group_variable</code></td>
<td>
<p>group variable</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_reference_group">reference_group</code></td>
<td>
<p>reference_group to be reweighted</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_method">method</code></td>
<td>
<p>method used to estimate conditional probabilities</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_estimate_statistics">estimate_statistics</code></td>
<td>
<p>boolean: if <code>TRUE</code> (default), then distributional
statistics are estimated and the decomposition is performed. If <code>FALSE</code>,
the function only returns the fitted inverse propensity weights.</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_statistics">statistics</code></td>
<td>
<p>a character vector that defines the distributional statistics
for which the decomposition is performed.</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_probs">probs</code></td>
<td>
<p>a vector of length 1 or more with the probabilities of the quantiles
to be estimated.</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_custom_statistic_function">custom_statistic_function</code></td>
<td>
<p>a function estimating a custom distributional statistic
that will be decomposed.</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_right_to_left">right_to_left</code></td>
<td>
<p>determines the direction of a sequential decomposition.</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_trimming">trimming</code></td>
<td>
<p>boolean: If <code>TRUE</code>, observations with dominant reweighting factor
values are trimmed according to rule of Huber, Lechner, and Wunsch (2013).</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_trimming_threshold">trimming_threshold</code></td>
<td>
<p>numeric: threshold defining the maximal accepted
relative weight of the reweighting factor value (i.e., inverse probability weight)
of a single observation. If <code>NULL</code>, the threshold is set to <code class="reqn">sqrt(N)/N</code>,
where <code class="reqn">N</code> is the number of observations in the reference group.</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_return_model">return_model</code></td>
<td>
<p>boolean: If <code>TRUE</code> (default), the object(s) of the model
fit(s) used to predict the conditional probabilities for the reweighting factor(s)
are returned.</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_estimate_normalized_difference">estimate_normalized_difference</code></td>
<td>
<p>boolean: If <code>TRUE</code> (default), the
normalized differences between the covariate means of the comparison group and the
reweighted reference group are calculated.</p>
</td></tr>
<tr><td><code id="dfl_decompose_estimate_+3A_...">...</code></td>
<td>
<p>other parameters passed to the function estimating the conditional probabilities.</p>
</td></tr>
</table>

<hr>
<h2 id='estimate_iq_range'>Interquantile range</h2><span id='topic+estimate_iq_range'></span>

<h3>Description</h3>

<p>Interquantile range
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_iq_range(dep_var, weights, probs = c(0.1, 0.9))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_iq_range_+3A_dep_var">dep_var</code></td>
<td>
<p>numeric vector of outcome variable</p>
</td></tr>
<tr><td><code id="estimate_iq_range_+3A_weights">weights</code></td>
<td>
<p>numeric vector of weights</p>
</td></tr>
<tr><td><code id="estimate_iq_range_+3A_probs">probs</code></td>
<td>
<p>a vector with probabilities whose range defines the interquantile range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value indicating the (weighted) interquantile range
</p>

<hr>
<h2 id='estimate_iq_ratio'>Interquantile ratio</h2><span id='topic+estimate_iq_ratio'></span>

<h3>Description</h3>

<p>Interquantile ratio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_iq_ratio(dep_var, weights, probs = c(0.1, 0.9))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_iq_ratio_+3A_dep_var">dep_var</code></td>
<td>
<p>numeric vector of outcome variable</p>
</td></tr>
<tr><td><code id="estimate_iq_ratio_+3A_weights">weights</code></td>
<td>
<p>numeric vector of weights</p>
</td></tr>
<tr><td><code id="estimate_iq_ratio_+3A_probs">probs</code></td>
<td>
<p>a vector with probabilities whose range defines the interquantile range</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value indicating the (weighted) interquantile ratio
</p>

<hr>
<h2 id='estimate_ob_decompose'>Estimate OB decomposition</h2><span id='topic+estimate_ob_decompose'></span>

<h3>Description</h3>

<p>The function performs the linear Oaxaca-Blinder decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_ob_decompose(
  formula,
  data_used,
  reference_0,
  normalize_factors,
  compute_analytical_se,
  return_model_fit,
  reweighting,
  rifreg,
  rifreg_statistic,
  rifreg_probs,
  custom_rif_function,
  na.action,
  vcov,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_ob_decompose_+3A_formula">formula</code></td>
<td>
<p><code>formula</code> object</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_data_used">data_used</code></td>
<td>
<p><code>data.frame</code> with data used for estimation (including weight and group variable)</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_reference_0">reference_0</code></td>
<td>
<p>boolean: indicating if group 0 is the reference group and if its coefficients are used to compute the counterfactual mean.</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_normalize_factors">normalize_factors</code></td>
<td>
<p>boolean: If 'TRUE', then factor variables are normalized as proposed by Gardeazabal/Ugidos (2004)</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_compute_analytical_se">compute_analytical_se</code></td>
<td>
<p>boolean: If 'TRUE', then analytical standard errors for decomposition terms are calculated (assuming independence between groups).</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_return_model_fit">return_model_fit</code></td>
<td>
<p>boolean: If 'TRUE', then model objects are returned.</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_reweighting">reweighting</code></td>
<td>
<p>boolean: if 'TRUE', then the decomposition is performed with
with respect to reweighted reference group.</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_rifreg">rifreg</code></td>
<td>
<p>boolean: if 'TRUE', then RIF decomposition is performed</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_rifreg_statistic">rifreg_statistic</code></td>
<td>
<p>string containing the distributional statistic for which to compute the RIF.</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_rifreg_probs">rifreg_probs</code></td>
<td>
<p>a vector of length 1 or more with probabilities of quantiles.</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_custom_rif_function">custom_rif_function</code></td>
<td>
<p>the RIF function to compute the RIF of the custom distributional statistic.</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_na.action">na.action</code></td>
<td>
<p>generic function that defines how NAs in the data should be handled.</p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_vcov">vcov</code></td>
<td>
<p>unction estimating covariance matrix of regression coefficients if <code>compute_analytical_se == TRUE</code></p>
</td></tr>
<tr><td><code id="estimate_ob_decompose_+3A_...">...</code></td>
<td>
<p>additional parameters passed to custom_rif_function</p>
</td></tr>
</table>

<hr>
<h2 id='fit_and_predict_probabilities'>Predict conditional probabilities</h2><span id='topic+fit_and_predict_probabilities'></span>

<h3>Description</h3>

<p>This function fits a binary choice model and predicts probabilities for every
observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_and_predict_probabilities(
  formula,
  data_used,
  weights,
  method = "logit",
  return_model = FALSE,
  newdata = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_and_predict_probabilities_+3A_formula">formula</code></td>
<td>
<p><code>formula</code> object specifying the conditional probability model.</p>
</td></tr>
<tr><td><code id="fit_and_predict_probabilities_+3A_data_used">data_used</code></td>
<td>
<p><code>data.frame</code> with data.</p>
</td></tr>
<tr><td><code id="fit_and_predict_probabilities_+3A_weights">weights</code></td>
<td>
<p>weights variable</p>
</td></tr>
<tr><td><code id="fit_and_predict_probabilities_+3A_method">method</code></td>
<td>
<p>method to estimate conditional probabilities</p>
</td></tr>
<tr><td><code id="fit_and_predict_probabilities_+3A_return_model">return_model</code></td>
<td>
<p>boolean: If <code>FALSE</code> (default), the object of the model
fit used to predict the conditional probabilities for the reweighting factor
are not returned.</p>
</td></tr>
<tr><td><code id="fit_and_predict_probabilities_+3A_newdata">newdata</code></td>
<td>
<p><code>data.frame</code> with data to be used for predictions.</p>
</td></tr>
<tr><td><code id="fit_and_predict_probabilities_+3A_...">...</code></td>
<td>
<p>other parameters passed to the estimation function.</p>
</td></tr>
</table>

<hr>
<h2 id='get_distributional_statistics'>Estimate distributional statistics</h2><span id='topic+get_distributional_statistics'></span>

<h3>Description</h3>

<p>Estimate weighted distributional statistics for the reference or
the counterfactual group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_distributional_statistics(
  dep_var,
  weights,
  group_variable,
  group,
  statistics,
  custom_statistic_function = NULL,
  probs = 1:9/10,
  log_transformed
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_distributional_statistics_+3A_dep_var">dep_var</code></td>
<td>
<p>vector of outcome variable</p>
</td></tr>
<tr><td><code id="get_distributional_statistics_+3A_weights">weights</code></td>
<td>
<p>vector of observations weights</p>
</td></tr>
<tr><td><code id="get_distributional_statistics_+3A_group_variable">group_variable</code></td>
<td>
<p>vector of group assignment</p>
</td></tr>
<tr><td><code id="get_distributional_statistics_+3A_group">group</code></td>
<td>
<p>identifier of group for which distributional statistics are calculated</p>
</td></tr>
<tr><td><code id="get_distributional_statistics_+3A_statistics">statistics</code></td>
<td>
<p>vector of statistics to be calculated</p>
</td></tr>
<tr><td><code id="get_distributional_statistics_+3A_custom_statistic_function">custom_statistic_function</code></td>
<td>
<p>a custom statistic function to be evaluated</p>
</td></tr>
<tr><td><code id="get_distributional_statistics_+3A_probs">probs</code></td>
<td>
<p>probabilities of quantiles to be calculated</p>
</td></tr>
<tr><td><code id="get_distributional_statistics_+3A_log_transformed">log_transformed</code></td>
<td>
<p>indicator if outcome variable is log transformed</p>
</td></tr>
</table>

<hr>
<h2 id='get_normalized_difference'>Get normalized differences</h2><span id='topic+get_normalized_difference'></span>

<h3>Description</h3>

<p>The function calculates normalized differences between covariate means of comparison
group and reweighted reference group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_normalized_difference(
  formula,
  data_used,
  weights,
  psi,
  group_variable,
  reference_group
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_normalized_difference_+3A_formula">formula</code></td>
<td>
<p>model formula used to calulate the conditional probabilities of the reweighting factor</p>
</td></tr>
<tr><td><code id="get_normalized_difference_+3A_data_used">data_used</code></td>
<td>
<p><code>data.frame</code> with the observation for the estimation of the reweighting factor</p>
</td></tr>
<tr><td><code id="get_normalized_difference_+3A_weights">weights</code></td>
<td>
<p>vector with observations weights</p>
</td></tr>
<tr><td><code id="get_normalized_difference_+3A_psi">psi</code></td>
<td>
<p>vector with the estimated reweighting factor</p>
</td></tr>
<tr><td><code id="get_normalized_difference_+3A_group_variable">group_variable</code></td>
<td>
<p>variable with group identifier</p>
</td></tr>
<tr><td><code id="get_normalized_difference_+3A_reference_group">reference_group</code></td>
<td>
<p>identifier of (reweighted) reference group</p>
</td></tr>
</table>


<h3>References</h3>

<p>Imbens, Guido W. and Jeffrey M. Wooldridge. 2009. Recent developments in the econometrics of program evaluation. Journal of Economic Literature 47, no. 1: 5-86.
</p>

<hr>
<h2 id='GU_normalization'>Gardeazabal and Ugidos normalization of factor variables</h2><span id='topic+GU_normalization'></span>

<h3>Description</h3>

<p>The function performs the normalization of the factor variables
proposed by Gardeazabal and Ugidos (2004, GU) to estimate detailed decompositions
that do not depend on the chosen reference levels of the factor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GU_normalization(formula, data, weights, group)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GU_normalization_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;formula&quot;. See <a href="stats.html#topic+lm">lm</a> for further details.</p>
</td></tr>
<tr><td><code id="GU_normalization_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="GU_normalization_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative observation weights, hence of same length as <code>dep_var</code>.</p>
</td></tr>
<tr><td><code id="GU_normalization_+3A_group">group</code></td>
<td>
<p>name of the a binary variable (numeric or factor) identifying the two groups that will be compared.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the adjusted formula, adjusted data, adjusted coefficient names,
and the normalized regressors for prediction and the
</p>


<h3>References</h3>

<p>Gardeazabal, Javier, and Arantza Ugidos. 2004. &quot;More on identification in detailed wage decompositions.&quot;
<em>Review of Economics and Statistics</em> 86(4): 1034-1036.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("men8305")
mod1 &lt;- log(wage) ~ union + married + nonwhite + education + experience
normalized_data &lt;- GU_normalization(
  formula = mod1,
  data = men8305,
  weights = weights,
  group = year
)

</code></pre>

<hr>
<h2 id='GU_normalization_get_coefficients'>Get coefficients for GU normalization</h2><span id='topic+GU_normalization_get_coefficients'></span>

<h3>Description</h3>

<p>This function constructs sums the coefficients of each factor variable to
construct a additional coefficients for their originally left-out reference
levels and adds them to the estimated coefficients vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GU_normalization_get_coefficients(coef_names, est_coef)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GU_normalization_get_coefficients_+3A_coef_names">coef_names</code></td>
<td>
<p>list with coefficients of every factor variable that need to be adjusted</p>
</td></tr>
<tr><td><code id="GU_normalization_get_coefficients_+3A_est_coef">est_coef</code></td>
<td>
<p>vector of estimated coefficients</p>
</td></tr>
</table>

<hr>
<h2 id='GU_normalization_get_vcov'>Get covariance matrix for GU normalization</h2><span id='topic+GU_normalization_get_vcov'></span>

<h3>Description</h3>

<p>This function adjusts the covariance matrix for the additional coefficients
of the originally left-out reference levels of all factor variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GU_normalization_get_vcov(coef_names, Cov_beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GU_normalization_get_vcov_+3A_coef_names">coef_names</code></td>
<td>
<p>list with coefficients of every factor variable that need to be adjusted</p>
</td></tr>
<tr><td><code id="GU_normalization_get_vcov_+3A_cov_beta">Cov_beta</code></td>
<td>
<p>estimated covariance matrix of the regression coefficients</p>
</td></tr>
</table>

<hr>
<h2 id='GU_normalization_sum_coefficients'>Sum coefficients for GU normalization</h2><span id='topic+GU_normalization_sum_coefficients'></span>

<h3>Description</h3>

<p>This function sums the coefficients of a single factor variable to construct
an additional coefficient for the left-out reference level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GU_normalization_sum_coefficients(coef_names, est_coef)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GU_normalization_sum_coefficients_+3A_coef_names">coef_names</code></td>
<td>
<p>names of the dummy coefficients of a factor variable</p>
</td></tr>
<tr><td><code id="GU_normalization_sum_coefficients_+3A_est_coef">est_coef</code></td>
<td>
<p>estimated coefficient vector</p>
</td></tr>
</table>

<hr>
<h2 id='GU_normalization_sum_vcov'>Sum covariance matrix for GU normalization</h2><span id='topic+GU_normalization_sum_vcov'></span>

<h3>Description</h3>

<p>This function adjusts the covariance matrix for the additional coefficient
of the originally left-out reference level of a single factor variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GU_normalization_sum_vcov(coef_names, Cov_beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GU_normalization_sum_vcov_+3A_coef_names">coef_names</code></td>
<td>
<p>names of the dummy coefficients of a factor variable</p>
</td></tr>
<tr><td><code id="GU_normalization_sum_vcov_+3A_cov_beta">Cov_beta</code></td>
<td>
<p>estimated covariance matrix of the regression coefficients</p>
</td></tr>
</table>

<hr>
<h2 id='men8305'>Sample of male wage data from the CPS 1983-1985 and 2003-2005</h2><span id='topic+men8305'></span>

<h3>Description</h3>

<p>A sample of the the Merged Outgoing Rotation Group of the
Current Population Survey from 1983 to 1985 and 2003 to 2005, respectively,
used as example by Fortin, Lemieux &amp; Firpo  (2011) in their handbook chapter.
The data set contains a selection of 8 variables and a sample of 40,347 observations
of male workers (i.e., a tenth of the origninal data set).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>men8305
</code></pre>


<h3>Format</h3>

<p>A data frame with 40,347 rows and 8 variables.
</p>

<dl>
<dt>wage</dt><dd><p>Hourly wage in US dollars at constant prices</p>
</dd>
<dt>union</dt><dd><p>Union status indicator</p>
</dd>
<dt>education</dt><dd><p>Factor variable with 6 education levels: high-school graduates (reference), elementary, high-school dropouts , some college, college graduates, post college graduates</p>
</dd>
<dt>experience</dt><dd><p>Factor variable with 9 potential experience levels, each of five years gap, 20 to 24 years as reference level)</p>
</dd>
<dt>married</dt><dd><p>Married indicator</p>
</dd>
<dt>nonwhite</dt><dd><p>Non-white indicator</p>
</dd>
<dt>year</dt><dd><p>Indicator distinguishing pooled observations from the 1983 to 1985 period and those from 2003 to 2005</p>
</dd>
<dt>weights</dt><dd><p>CPS sample weights</p>
</dd>
</dl>



<h3>Source</h3>

<p>Fortin, Nicole M., Thomas Lemieux, and Firpo Segio. 2011.
&quot;Decomposition Methods in Economics.&quot; In Orley Ashenfelter and David Card, eds.,
Handbook of Labor Economics, Volume 4a., Chapter 1, 1-102.
</p>

<hr>
<h2 id='nlys00'>Sample of NLSY79 wage data from 2000</h2><span id='topic+nlys00'></span>

<h3>Description</h3>

<p>Sample of National Longitudinal Survey (NLSY) 79
containig wage data from the year 2000
of workers who were aged 35 to 43 in that year. The data is from O'Neill
and O'Neill (2006) and is used as an illustration of the Oxaca-Blinder mean
decomposition in Firpo, Fortin, and Lemieuex (2011). The data contains 2655
male and 2654 female observations, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlys00
</code></pre>


<h3>Format</h3>

<p>A data frame with 5,396 rows and 15 variables.
</p>

<dl>
<dt>female</dt><dd><p>Female indicator</p>
</dd>
<dt>wage</dt><dd><p>Hourly wage in US dollars</p>
</dd>
<dt>age</dt><dd><p>Age in years</p>
</dd>
<dt>central_city</dt><dd><p>Central city indicator</p>
</dd>
<dt>msa</dt><dd><p>Metropolitan statistical area (MSA) indicator</p>
</dd>
<dt>region</dt><dd><p>Factor variable disinguishing 4 large regions</p>
</dd>
<dt>black</dt><dd><p>Black indicator</p>
</dd>
<dt>hispanic</dt><dd><p>Hispanic indicator</p>
</dd>
<dt>education</dt><dd><p>Factor variable indicating highest attained education</p>
</dd>
<dt>afqt</dt><dd><p>Percentile score of armed force qualification test (AFTQ) devided by 10</p>
</dd>
<dt>family_responsibility</dt><dd><p>Family responsibility indicator</p>
</dd>
<dt>years_worked_civilian</dt><dd><p>Years worked in cilivian labor force</p>
</dd>
<dt>years_worked_military</dt><dd><p>Years worked in military</p>
</dd>
<dt>part_time</dt><dd><p>Share of years worked in part-time</p>
</dd>
<dt>industry</dt><dd><p>Factor variable identifying 4 industries</p>
</dd>
</dl>



<h3>Source</h3>

<p>Fortin, Nicole M., Thomas Lemieux, and Firpo Segio. 2011.
&quot;Decomposition Methods in Economics.&quot; In Orley Ashenfelter and David Card, eds.,
Handbook of Labor Economics, Volume 4a., Chapter 1, 1-102.
</p>

<hr>
<h2 id='ob_decompose'>Oaxaca-Blinder decomposition</h2><span id='topic+ob_decompose'></span>

<h3>Description</h3>

<p><code>ob_decompose</code> implements the Oaxaca-Blinder decomposition that
divides differences in the mean outcome between two groups into one part explained
by different covariate means (composition effect) and into another part due to
differences in linear regression coefficients linking covariates to the outcome
variable (structure effect).
</p>
<p>The function allows for 'doubly robust' decompositions where the sample of one
group is reweighted such that it matches the covariates distribution of the
other group before the regression coefficients are estimated.
</p>
<p>For distributional statistics beyond the mean, the function performs the RIF
regression decomposition proposed by Firpo, Fortin, and Lemieux (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ob_decompose(
  formula,
  data,
  group,
  weights = NULL,
  reweighting = FALSE,
  normalize_factors = FALSE,
  reference_0 = TRUE,
  subtract_1_from_0 = FALSE,
  reweighting_method = "logit",
  trimming = FALSE,
  trimming_threshold = NULL,
  rifreg_statistic = NULL,
  rifreg_probs = c(1:9)/10,
  custom_rif_function = NULL,
  na.action = na.omit,
  bootstrap = FALSE,
  bootstrap_iterations = 100,
  bootstrap_robust = FALSE,
  cluster = NULL,
  cores = 1,
  vcov = stats::vcov,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ob_decompose_+3A_formula">formula</code></td>
<td>
<p>a <code>formula</code> object with an outcome variable Y on the left-hand side
and the covariates X on the right-hand side. If <code>reweighting = TRUE</code>, the same
covariates are used to estimate the conditional probabilities for the reweighting factor.
A different model for estimating the conditional probabilities can be defined
after a <code>|</code> operator on the right-hand side.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_group">group</code></td>
<td>
<p>name of the a binary variable (numeric or factor)
identifying the two groups that will be compared. The group identified by the
lower ranked value in 'group' (i.e., 0 in the case of a dummy variable or the
first level of factor variable) is defined as group 0.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative observation weights, hence of same length as <code>dep_var</code>.
The default (<code>NULL</code>) is equivalent to <code>weights = rep(1, length(dep_var))</code>.
If no weights are used, make sure you do not define this parameter (e.g. with <code>weights = NULL</code>).</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_reweighting">reweighting</code></td>
<td>
<p>boolean: if 'TRUE', then the decomposition is performed with
with respect to reweighted reference group yielding either a 'doubly robust'
Oaxaca-Blinder decomposition or a reweighted RIF decomposition.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_normalize_factors">normalize_factors</code></td>
<td>
<p>boolean: If 'TRUE', then factor variables are normalized as
proposed by Gardeazabal/Ugidos (2004) and results are not dependent on the factor's
reference group. Per default (<code>normalize_factors  = FALSE</code>) and factors are not
normalized.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_reference_0">reference_0</code></td>
<td>
<p>boolean: if 'TRUE' (default), then the group 0 &ndash; i.e.,
the group identified by the lower ranked value in 'group' &ndash; will be defined
as reference group. The reference group will be reweighted to match the
covariates distribution of the counterfactual sample.
By default, the composition effect is computed as <code>(X1 - X0) * b0</code> and
the structure effect as <code>X1 * (b1 - b0)</code>. Putting <code>reference_0 = FALSE</code> changes
the reference structure. Hence, the composition effect is computed as <code>(X1 - X0) * b1</code> and
the structure effect as <code>X0 * (b1 - b0)</code>.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_subtract_1_from_0">subtract_1_from_0</code></td>
<td>
<p>boolean: By default ('FALSE'), X0 is subtracted from X1 and beta0 from beta1 (X1b1 - X0b0)
to compute the overall difference. Setting 'subtract_1_from_0' to 'TRUE' merely changes the sign of the decomposition results.
This means the composition effect is computed as <code>(X0 - X1) * b1</code> and
the structure effect as <code>X0 * (b0 - b1)</code>.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_reweighting_method">reweighting_method</code></td>
<td>
<p>specifies the method fit and predict conditional probabilities
used to derive the reweighting factor. Currently, <code>"logit"</code>, <code>"fastglm"</code>,
and <code>"random_forest"</code> are available.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_trimming">trimming</code></td>
<td>
<p>boolean: If <code>TRUE</code>, observations with dominant reweighting factor
values are trimmend according to rule of Huber, Lechner, and Wunsch (2013). Per
default, trimming is set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_trimming_threshold">trimming_threshold</code></td>
<td>
<p>numeric: threshold defining the maximal accepted
relative weight of the reweighting factor value (i.e., inverse probability weight)
of a single observation. If <code>NULL</code>, the threshold is set to <code class="reqn">sqrt(N)/N</code>,
where <code class="reqn">N</code> is the number of observations in the reference group.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_rifreg_statistic">rifreg_statistic</code></td>
<td>
<p>string containing the distributional statistic for which to compute the RIF.
If 'NULL' (default), no RIF regression decomposition is computed.
If an available statistic is selected, 'ob_decompose' estimates a RIF regression decomposition.
The 'rifreg_statistic' can be one of
&quot;quantiles&quot;, &quot;mean&quot;, &quot;variance&quot;, &quot;gini&quot;, &quot;interquantile_range&quot;, &quot;interquantile_ratio&quot;, or &quot;custom&quot;.
If &quot;custom&quot; is selected, a <code>custom_rif_function</code> needs to be provided.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_rifreg_probs">rifreg_probs</code></td>
<td>
<p>a vector of length 1 or more with probabilities of quantiles. Each quantile is indicated with a value between 0 and 1.
Default is <code>c(1:9)/10</code>. If <code>statistic = "quantiles"</code>, a single RIF regression for every quantile in <code>probs</code>
is estimated. An interquantile ratio (range) is defined by the ratio (difference) between the <code>max(probs)</code>-quantile and
the <code>min(probs)</code>-quantile.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_custom_rif_function">custom_rif_function</code></td>
<td>
<p>the RIF function to compute the RIF of the custom distributional statistic.
Default is NULL. Only needs to be provided if <code>statistic = "custom"</code>.
Every custom_rif_function needs the parameters <code>dep_var</code>, <code>weights</code> and <code>probs</code>.
If they are not needed, they must be set to NULL in the function definition (e.g. <code>probs = NULL</code>).
A custom function must return a data frame containing at least a &quot;rif&quot; and &quot;weights&quot; column.
See <code>examples</code> for further details.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_na.action">na.action</code></td>
<td>
<p>generic function that defines how NAs in the data should be handled.
Default is <code>na.omit</code>, leading to exclusion of observations that contain one or more missings.
See <a href="stats.html#topic+na.action">na.action</a> for further details.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_bootstrap">bootstrap</code></td>
<td>
<p>boolean: If 'FALSE' (default), then no bootstrapped standard
errors are calculated and, in the case of a standard Oaxaca-Blinder decomposition,
analytical standard errors are estimated (assuming independence between groups).</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_bootstrap_iterations">bootstrap_iterations</code></td>
<td>
<p>positive integer indicating the number of bootstrap
iterations to execute. Only required if <code>bootstrap = TRUE</code>.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_bootstrap_robust">bootstrap_robust</code></td>
<td>
<p>boolean: if 'FALSE' (default), then bootstrapped standard
errors are estimated as the standard deviations of the bootstrapp estimates.
Otherwise, the function uses the bootstrap interquartile range rescaled by the
interquantile range of the standard distribution to estimate standard errors.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_cluster">cluster</code></td>
<td>
<p>numeric vector of same length as <code>dep_var</code> indicating the
clustering of observations. If <code>cluster = NULL</code> (default), no clustering
is a assumend and bootstrap procedure resamples individual observations. Otherwise
bootstrap procedure resamples clusters.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_cores">cores</code></td>
<td>
<p>positive integer indicating the number of cores to use when
computing bootstrap standard errors. Only required if <code>bootstrap = TRUE</code>.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_vcov">vcov</code></td>
<td>
<p>function estimating covariance matrix of regression coefficients if
standard errors are not bootstrapped (i.e., <code>bootstrap = FALSE</code>). By default,
<a href="stats.html#topic+vcov">vcov</a> is used assuming homoscedastic errors.</p>
</td></tr>
<tr><td><code id="ob_decompose_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the custom_rif_function.
Apart from dep_var, weights and probs they must have a different name than the the ones in rifreg.
For instance, if you want to pass a parameter statistic to the custom_rif_function, name it custom_statistic.
Additional parameters can also be passed to the <a href="stats.html#topic+density">density</a> function used
to estimate the RIF of quantiles.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ob_decompose()</code> contains for four different decomposition methods of
observed group differences.
</p>
<p>1. The original Oaxaca-Blinder decomposition (default)
2. A 'doubly robust Oaxaca-Blinder decomposition (<code>reweighting=TRUE</code>)
3. A RIF Regression decomposition. (e.g., <code>rifreg_statistic="quantiles"</code>)
4. A reweighted RIF regression decomposition. (<code>reweighting=TRUE</code> and <code>rifreg_statistic="quantiles"</code>)
</p>
<p>The doubly robust OB decomposition is a robust and path independent alternative
for detailed decompositions at the mean. is to combine reweighting with the linear Oaxaca-Blinder method (see
Fortin et al., 2011: 48-51). This approach has the valuable side effect of
accounting for potential errors introduced by an incomplete inverse probability
weighting and the linear model specification, respectively.
</p>
<p>A path independent method that goes beyond the mean is the RIF decomposition
of Firpo, Fortin, and Lemieux (2018). The approach approximates the expected value
of the 'recentered influence function' (RIF) of the distributional statistic
(e.g., quantile, variance, or Gini coefficient) of an outcome variable
conditional on covariates with linear regressions. RIF regression coefficients can
be consistent estimates of the marginal effect
of a small change in the expected value of a covariate to the distributional statistics of
an outcome variable (see documentation of the companion package <code>rifreg</code>).
Thus, they can be used to decompose between-group difference in distributional statistics.
Firpo et al. (2018) combine the RIF regressions again with the reweighting estimator to avoid specification errors.
</p>


<h3>Value</h3>

<p>an object of class <code>ob_decompose</code> containing a data.frame with the
decomposition results for the quantiles and for the other distributional
statistics, respectively, a data.frame with the estimated reweighting factor
for every observation, a data.frame with sample quantiles of the reweighting
factors and a list with standard errors for the decomposition terms, the
quantiles of the reweighting factor, the bootstrapped
Kolmogorov-Smirnov distribution to construct uniform confidence bands for
quantiles, as well as a list with the normalized differences between the
covariate means of the comparison group and the reweighted reference group.
</p>
<p>A list object of class 'ob_decompose' containing the following components:
</p>
<p>- 'ob_decompose': A list containing the decomposition results, covariance matrix, model fits and more detailed result information.
- 'group_variable_name': A string indicating the name of the group variable.
- 'group_variable_levels': A string indicating the levels of the group variable.
- 'reference_group': A string indicating the which level of the group variable was used as reference group.
- 'reweighting_estimates': A list containing the reweighting estimates if <code>reweighting=TRUE</code>, else (<code>NA</code>)
- 'input_parameters': A list of input parameters used for the estimation.
</p>


<h3>References</h3>

<p>Firpo, Sergio, Nicole M. Fortin, and Thomas Lemieux. 2018.
&quot;Decomposing Wage Distributions Using Recentered Influence Function Regressions.&quot; <em>Econometrics</em>, 6(2):28.
</p>
<p>Fortin, Nicole, Thomas Lemieux, and Sergio Firpo. 2011. &quot;Decomposition methods in economics.&quot;
In Orley Ashenfelter and David Card, eds., <em>Handbook of labor economics</em>. Vol. 4. Elsevier, 1-102.
</p>
<p>Gardeazabal, Javier, and Arantza Ugidos. 2004. &quot;More on identification in detailed wage decompositions.&quot;
<em>Review of Economics and Statistics</em>, 86(4): 1034-1036.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Oaxaca-Blinder decomposition of gender wage gap
## with NLYS79 data like in Fortin, Lemieux, &amp; Firpo (2011: 41)

data("nlys00")

mod1 &lt;- log(wage) ~ age + central_city + msa + region + black +
  hispanic + education + afqt + family_responsibility + years_worked_civilian +
  years_worked_military + part_time + industry

# Using female coefficients (reference_0 = TRUE) to estimate counterfactual mean
decompose_female_as_reference &lt;- ob_decompose(
  formula = mod1,
  data = nlys00,
  group = female,
  reference_0 = TRUE
)
decompose_female_as_reference

# Using male coefficients (reference_0 = FALSE)
decompose_male_as_reference &lt;- ob_decompose(
  formula = mod1,
  data = nlys00,
  group = female,
  reference_0 = FALSE
)
decompose_male_as_reference

# Replicate first and third column in Table 3 in Fortin, Lemieux, &amp; Firpo (2011: 41)
# Define aggregation of decomposition terms
custom_aggregation &lt;- list(
  `Age, race, region, etc.` = c(
    "age",
    "blackyes",
    "hispanicyes",
    "regionNorth-central",
    "regionSouth",
    "regionWest",
    "central_cityyes",
    "msayes"
  ),
  `Education` = c(
    "education&lt;10 yrs",
    "educationHS grad (diploma)",
    "educationHS grad (GED)",
    "educationSome college",
    "educationBA or equiv. degree",
    "educationMA or equiv. degree",
    "educationPh.D or prof. degree"
  ),
  `AFTQ` = "afqt",
  `L.T. withdrawal due to family` = "family_responsibility",
  `Life-time work experience` = c(
    "years_worked_civilian",
    "years_worked_military",
    "part_time"
  ),
  `Industrial sectors` = c(
    "industryManufacturing",
    "industryEducation, Health, Public Admin.",
    "industryOther services"
  )
)

# First column
summary(decompose_male_as_reference, custom_aggregation = custom_aggregation)

# Third column
summary(decompose_female_as_reference, custom_aggregation = custom_aggregation)

## Compare bootstrapped standard errors...
decompose_female_as_reference_bs &lt;- ob_decompose(
  formula = mod1,
  data = nlys00,
  group = female,
  bootstrap = TRUE,
  bootstrap_iterations = 100
)
summary(decompose_female_as_reference_bs, custom_aggregation = custom_aggregation)

# ... to analytical standard errors (assuming independence between groups and
# homoscedasticity)
decompose_female_as_reference &lt;- ob_decompose(
  formula = mod1,
  data = nlys00,
  group = female,
  reference_0 = TRUE
)
summary(decompose_female_as_reference, custom_aggregation = custom_aggregation)

# Return standard errors for all detailed terms
summary(decompose_female_as_reference, aggregate_factors = FALSE)


## 'Doubly robust' Oaxaca-Blinder decomposition of gender wage gap
mod2 &lt;- log(wage) ~ age + central_city + msa + region + black +
  hispanic + education + afqt + family_responsibility + years_worked_civilian +
  years_worked_military + part_time + industry | age + (central_city + msa) * region + (black +
  hispanic) * (education + afqt) + family_responsibility * (years_worked_civilian +
  years_worked_military) + part_time * industry
decompose_male_as_reference_robust &lt;- ob_decompose(
  formula = mod2,
  data = nlys00,
  group = female,
  reference_0 = FALSE,
  reweighting = TRUE
)

# ... using random forests instead of logit to estimate weights
decompose_male_as_reference_robust_rf &lt;- ob_decompose(
  formula = mod1,
  data = nlys00,
  group = female,
  reference_0 = FALSE,
  reweighting = TRUE,
  method = "random_forest"
)


# Reweighted RIF Regression Decomposition
data("men8305")

model_rifreg &lt;- log(wage) ~  union + education + experience |
  union * (education + experience) + education * experience

# Variance
variance_decomposition &lt;- ob_decompose(
  formula = model_rifreg,
  data = men8305,
  group = year,
  reweighting = TRUE,
  rifreg_statistic = "variance"
)

# Deciles
deciles_decomposition &lt;- ob_decompose(
  formula = model_rifreg,
  data = men8305,
  group = year,
  reweighting = TRUE,
  rifreg_statistic = "quantiles",
  rifreg_probs = c(1:9) / 10
)

# plot(deciles_decomposition)

# RIF regression decomposition with custom function

# custom function
custom_variance_function &lt;- function(dep_var, weights, probs = NULL) {
  weighted_mean &lt;- weighted.mean(x = dep_var, w = weights)
  rif &lt;- (dep_var - weighted_mean)^2
  rif &lt;- data.frame(rif, weights)
  names(rif) &lt;- c("rif_variance", "weights")
  return(rif)
}

 custom_decomposition &lt;-
   ob_decompose(
    formula = model_rifreg,
    data = men8305,
    group = year,
    reweighting = TRUE,
    rifreg_statistic = "custom",
    custom_rif_function = custom_variance_function
  )

</code></pre>

<hr>
<h2 id='ob_decompose_calculate_terms'>Calculate OB decomposition terms</h2><span id='topic+ob_decompose_calculate_terms'></span>

<h3>Description</h3>

<p>The function calculates the decomposition terms of the linear
Oaxaca-Blinder decomposition based on the estimated OLS
coefficients and the respective <code>model.matrix</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ob_decompose_calculate_terms(
  beta0,
  beta1,
  X0,
  X1,
  weights0,
  weights1,
  reference_0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ob_decompose_calculate_terms_+3A_beta0">beta0</code></td>
<td>
<p>vector of estimated coefficients of group 0</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_terms_+3A_beta1">beta1</code></td>
<td>
<p>vector of estimated coefficients of group 1</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_terms_+3A_x0">X0</code></td>
<td>
<p><code>model.matrix</code> of group 0</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_terms_+3A_x1">X1</code></td>
<td>
<p><code>model.matrix</code> of group 1</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_terms_+3A_weights0">weights0</code></td>
<td>
<p>vector of observation weights of group 0</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_terms_+3A_weights1">weights1</code></td>
<td>
<p>vector of observation weights of group 1</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_terms_+3A_reference_0">reference_0</code></td>
<td>
<p>boolean: indicating if group 0 is the reference group and if its coefficients are used to compute the counterfactual mean.</p>
</td></tr>
</table>

<hr>
<h2 id='ob_decompose_calculate_vcov'>Calculate covariance matrix for OB decomposition terms</h2><span id='topic+ob_decompose_calculate_vcov'></span>

<h3>Description</h3>

<p>The function calculate the covariance matrix for the decomposition terms
of the linear Oaxaca-Blinder decomposition assuming independence between
groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ob_decompose_calculate_vcov(
  beta0,
  beta1,
  X0,
  X1,
  weights0,
  weights1,
  Cov_beta0,
  Cov_beta1,
  reference_0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_beta0">beta0</code></td>
<td>
<p>vector of estimated coefficients of group 0</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_beta1">beta1</code></td>
<td>
<p>vector of estimated coefficients of group 1</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_x0">X0</code></td>
<td>
<p><code>model.matrix</code> of group 0</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_x1">X1</code></td>
<td>
<p><code>model.matrix</code> of group 1</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_weights0">weights0</code></td>
<td>
<p>vector of observation weights of group 0</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_weights1">weights1</code></td>
<td>
<p>vector of observation weights of group 1</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_cov_beta0">Cov_beta0</code></td>
<td>
<p>estimated covariance matrix of coefficients of group 0</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_cov_beta1">Cov_beta1</code></td>
<td>
<p>estimated covariance matrix of coefficients of group 1</p>
</td></tr>
<tr><td><code id="ob_decompose_calculate_vcov_+3A_reference_0">reference_0</code></td>
<td>
<p>boolean: indicating if group 0 is the reference group and if its coefficients are used to compute the counterfactual mean.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Jann, Ben, 2005. &quot;Standard errors for the Blinder-Oaxaca decomposition.&quot; *3rd German Stata Users’ Group Meeting 2005*. Available from [https://boris.unibe.ch/69506/1/oaxaca_se_handout.pdf](https://boris.unibe.ch/69506/1/oaxaca_se_handout.pdf).
</p>

<hr>
<h2 id='plot.dfl_decompose'>Plot decomposition terms for quantiles</h2><span id='topic+plot.dfl_decompose'></span>

<h3>Description</h3>

<p>The function plots decomposition terms for quantiles estimated
with <code>dfl_decompose</code> over the  unit interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dfl_decompose'
plot(
  x,
  ...,
  confidence_bands = TRUE,
  confidence_level = 0.95,
  uniform_bands = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.dfl_decompose_+3A_x">x</code></td>
<td>
<p>an object of class &quot;dfl_decompose&quot;, usually, a result of a call to [dfl_decompose()] with [statistics = &quot;quantiles&quot;].</p>
</td></tr>
<tr><td><code id="plot.dfl_decompose_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plot function.</p>
</td></tr>
<tr><td><code id="plot.dfl_decompose_+3A_confidence_bands">confidence_bands</code></td>
<td>
<p>If 'TRUE' (default) and if standard errors have been bootstrapped, confidence bands are plotted.</p>
</td></tr>
<tr><td><code id="plot.dfl_decompose_+3A_confidence_level">confidence_level</code></td>
<td>
<p>numeric value between 0 and 1 (default = 0.95) that defines the confidence interval
plotted as a ribbon and defined as <code>qnorm((1-confidence_level)/2)</code> * standard error.</p>
</td></tr>
<tr><td><code id="plot.dfl_decompose_+3A_uniform_bands">uniform_bands</code></td>
<td>
<p>If 'FALSE' (default), pointwise confidence bands are computed. Otherwise, uniform bands are constructed
based on the bootstrapped Kolmogrov-Smirnov statistic (see <a href="#topic+summary.dfl_decompose">summary.dfl_decompose</a>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot illustrating the decomposition terms for quantiles.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("men8305")
flf_model &lt;- log(wage) ~ union * (education + experience) + education * experience
flf_male_inequality &lt;- dfl_decompose(flf_model,
  data = men8305,
  weights = weights,
  group = year
)
plot(flf_male_inequality)

</code></pre>

<hr>
<h2 id='plot.ob_decompose'>Plot decomposition terms for quantiles</h2><span id='topic+plot.ob_decompose'></span>

<h3>Description</h3>

<p>The function plots decomposition terms for quantiles estimtated
with <code>ob_decompose</code> over the  unit interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ob_decompose'
plot(
  x,
  ...,
  detailed_effects = TRUE,
  aggregate_factors = TRUE,
  custom_aggregation = NULL,
  confidence_bands = FALSE,
  confidence_level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ob_decompose_+3A_x">x</code></td>
<td>
<p>an object of class &quot;ob_decompose&quot;, usually, a result of a call to [ob_decompose()] with [statistics = &quot;quantiles&quot;].</p>
</td></tr>
<tr><td><code id="plot.ob_decompose_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plot function.</p>
</td></tr>
<tr><td><code id="plot.ob_decompose_+3A_detailed_effects">detailed_effects</code></td>
<td>
<p>If 'TRUE' (default), then the detailed effects are plotted. Otherwise only the total (aggregate) effects are plotted.</p>
</td></tr>
<tr><td><code id="plot.ob_decompose_+3A_aggregate_factors">aggregate_factors</code></td>
<td>
<p>boolean, if 'TRUE' (default) terms associated with detailed factor
levels are aggregated to a single term for every factor variable.</p>
</td></tr>
<tr><td><code id="plot.ob_decompose_+3A_custom_aggregation">custom_aggregation</code></td>
<td>
<p>list specifying the aggregation of detailed decomposition
terms. The parameter 'custom_aggregation' overrides the parameter 'aggregate_factors'.
If 'NULL' (default), then either all detailed terms or all terms associated with
a single variable are returned.</p>
</td></tr>
<tr><td><code id="plot.ob_decompose_+3A_confidence_bands">confidence_bands</code></td>
<td>
<p>If 'TRUE' and if standard errors have been bootstrapped, confidence bands are plotted.</p>
</td></tr>
<tr><td><code id="plot.ob_decompose_+3A_confidence_level">confidence_level</code></td>
<td>
<p>numeric value between 0 and 1 (default = 0.95) that defines the confidence interval
plotted as a ribbon and defined as <code>qnorm((1-confidence_level)/2)</code> * standard error.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot illustrating the decomposition terms for quantiles.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("nlys00")

mod1 &lt;- log(wage) ~ age + central_city + msa + region + black +
  hispanic + education + afqt + family_responsibility + years_worked_civilian +
  years_worked_military + part_time + industry

# plotting RIF regression decomposition of deciles

decompose_rifreg_deciles &lt;- ob_decompose(
  formula = mod1,
  data = nlys00,
  group = female,
  reweighting = TRUE,
  rifreg_statistic = "quantiles",
  bootstrap = TRUE,
  bootstrap_iterations = 50,
  reference_0 = FALSE
)

plot(decompose_rifreg_deciles)

plot(decompose_rifreg_deciles,
  confidence_bands = TRUE
)


# plotting Oaxaca-Blinder decomposition

decompose_ob_mean &lt;- ob_decompose(
  formula = mod1,
  data = nlys00,
  group = female,
  reweighting = TRUE,
  bootstrap = FALSE,
  reference_0 = FALSE
)

plot(decompose_ob_mean)
plot(decompose_ob_mean, detailed_effects = FALSE)


# With custom aggregation

custom_aggregation &lt;- list(
  `Age, race, region, etc.` = c(
    "age",
    "blackyes",
    "hispanicyes",
    "regionNorth-central",
    "regionSouth",
    "regionWest",
    "central_cityyes",
    "msayes"
  ),
  `Education` = c(
    "education&lt;10 yrs",
    "educationHS grad (diploma)",
    "educationHS grad (GED)",
    "educationSome college",
    "educationBA or equiv. degree",
    "educationMA or equiv. degree",
    "educationPh.D or prof. degree"
  ),
  `AFTQ` = "afqt",
  `L.T. withdrawal due to family` = "family_responsibility",
  `Life-time work experience` = c(
    "years_worked_civilian",
    "years_worked_military",
    "part_time"
  ),
  `Industrial sectors` = c(
    "industryManufacturing",
    "industryEducation, Health, Public Admin.",
    "industryOther services"
  )
)

plot(decompose_ob_mean, custom_aggregation = custom_aggregation)

</code></pre>

<hr>
<h2 id='print.dfl_decompose'>print method for class &quot;dfl_decompose&quot;</h2><span id='topic+print.dfl_decompose'></span>

<h3>Description</h3>

<p>print method for class &quot;dfl_decompose&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dfl_decompose'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.dfl_decompose_+3A_x">x</code></td>
<td>
<p>an object of class &quot;dfl_decompose&quot;, usually , a result of a call to [dfl_decompose()].</p>
</td></tr>
<tr><td><code id="print.dfl_decompose_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to printing functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>print.dfl_decompose()</code> displays the decompositions terms saved in <code>x</code>.
</p>

<hr>
<h2 id='print.ob_decompose'>print method for class &quot;ob_decompose&quot;</h2><span id='topic+print.ob_decompose'></span>

<h3>Description</h3>

<p>print method for class &quot;ob_decompose&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ob_decompose'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ob_decompose_+3A_x">x</code></td>
<td>
<p>an object of class &quot;ob_decompose&quot;, usually , a result of a call to [ob_decompose()].</p>
</td></tr>
<tr><td><code id="print.ob_decompose_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to printing functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>print.ob_decompose()</code> displays the decompositions terms saved in <code>x</code>.
</p>

<hr>
<h2 id='select_observations_to_be_trimmed'>Select observations with little common support to be trimmed</h2><span id='topic+select_observations_to_be_trimmed'></span>

<h3>Description</h3>

<p>This function implements the trimming rule proposed by Huber, Lechner,
and Wunsch (2014). Observations above the trimming threshold are trimmed in
the reference group and in the comparison group. Per default, the timming
is set to sqrt(N)/N, where N is the number of observation in the  reweighted
reference group. The function returns vector index of observation to be trimmed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_observations_to_be_trimmed(
  reweighting_factor,
  group_variable,
  group,
  trimming_threshold = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select_observations_to_be_trimmed_+3A_reweighting_factor">reweighting_factor</code></td>
<td>
<p>Estimated reweigting factor</p>
</td></tr>
<tr><td><code id="select_observations_to_be_trimmed_+3A_group_variable">group_variable</code></td>
<td>
<p>Variable identifying the reference and comparison group, respectively.</p>
</td></tr>
<tr><td><code id="select_observations_to_be_trimmed_+3A_group">group</code></td>
<td>
<p>Identifier of reference group</p>
</td></tr>
<tr><td><code id="select_observations_to_be_trimmed_+3A_trimming_threshold">trimming_threshold</code></td>
<td>
<p>threshold defining the maximal accepted relative weight of a reweighting factor/observation. If 'NULL', the threshold is set to 'sqrt(N)/N', where N is the number of observations in the reference group.</p>
</td></tr>
</table>

<hr>
<h2 id='summary.dfl_decompose'>summary method for class &quot;dfl_decompose&quot;</h2><span id='topic+summary.dfl_decompose'></span>

<h3>Description</h3>

<p>summary method for class &quot;dfl_decompose&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dfl_decompose'
summary(object, ..., confidence_level = 0.95, digits = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.dfl_decompose_+3A_object">object</code></td>
<td>
<p>an object of class &quot;dfl_decompose&quot;, a result of a call to [dfl_decompose()].</p>
</td></tr>
<tr><td><code id="summary.dfl_decompose_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to printing functions.</p>
</td></tr>
<tr><td><code id="summary.dfl_decompose_+3A_confidence_level">confidence_level</code></td>
<td>
<p>numeric value between 0 and 1 (default = 0.95) that defines the
confidence level of the printed confidence intervals.</p>
</td></tr>
<tr><td><code id="summary.dfl_decompose_+3A_digits">digits</code></td>
<td>
<p>number of digits to be printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If standard errors were bootstrapped, standard
errors and confidence bands are given. Pointwise confidences bands are defined
as <code>qnorm((1-confidence_level)/2)</code> * standard error. Uniform bands
are constructed by multiplying the standard error with <code>confidence_level</code>-quantile
of the bootstrapped Kolmogorov-Smirnov statistic as in Chen et al. (2017).
</p>


<h3>Value</h3>

<p>The function <code>summary.dfl_decompose()</code> displays the decompositions
terms save in <code>object</code>. The function further returns a list with the displayed
decomposition terms and, if standard errors were bootstrapped, the corresponding
standard errors and confindence bands.
</p>


<h3>References</h3>

<p>Chen, Mingli, Victor Chernozhukov, Iván Fernández-Val, and Blaise Melly. 2017.
&quot;Counterfactual: An R Package for Counterfactual Analysis.&quot; <em>The R Journal</em> 9(1): 370-384.
</p>

<hr>
<h2 id='summary.ob_decompose'>summary method for class &quot;ob_decompose&quot;</h2><span id='topic+summary.ob_decompose'></span>

<h3>Description</h3>

<p>Apart from displaying the (detailed) decomposition results with standard
errors, <code>summary.ob_decompose()</code> allows to customize the aggregation of the
detailed decomposition terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ob_decompose'
summary(
  object,
  ...,
  aggregate_factors = TRUE,
  custom_aggregation = NULL,
  confidence_level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ob_decompose_+3A_object">object</code></td>
<td>
<p>an object of class &quot;ob_decompose&quot;, usually , a result of a call to [ob_decompose()].</p>
</td></tr>
<tr><td><code id="summary.ob_decompose_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to summary function.</p>
</td></tr>
<tr><td><code id="summary.ob_decompose_+3A_aggregate_factors">aggregate_factors</code></td>
<td>
<p>boolean, if 'TRUE' (default) terms associated with detailed factor
levels are aggregated to a single term for every factor variable.</p>
</td></tr>
<tr><td><code id="summary.ob_decompose_+3A_custom_aggregation">custom_aggregation</code></td>
<td>
<p>list specifying the aggregation of detailed decomposition
terms. The parameter 'custom_aggregation' overrides the parameter 'aggregate_factors'.
If 'NULL' (default), then either all detailed terms or all terms associated with
a single variable are returned.</p>
</td></tr>
<tr><td><code id="summary.ob_decompose_+3A_confidence_level">confidence_level</code></td>
<td>
<p>numeric value between 0 and 1 (default = 0.95) that defines the printed confidence interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>summary.ob_decompose()</code> summarizes the decompositions terms saved in <code>object</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("nlys00")
mod1 &lt;- log(wage) ~ age + education + years_worked_civilian +
  years_worked_military + part_time + industry

decompose_results &lt;- ob_decompose(
  formula = mod1,
  data = nlys00,
  group = female,
  reference_0 = TRUE
)

# Print standard errors
summary(decompose_results)

# Aggregate decomposition terms associated with factor levels
summary(decompose_results, aggregate_factors = TRUE)

# custom aggregation of decomposition terms
custom_aggregation &lt;-
  list(
    `Age` = c("age"),
    `Education` = c(
      "education&lt;10 yrs",
      "educationHS grad (diploma)",
      "educationHS grad (GED)",
      "educationSome college",
      "educationBA or equiv. degree",
      "educationMA or equiv. degree",
      "educationPh.D or prof. degree"
    ),
    `Life-time work experience` = c(
      "years_worked_civilian",
      "years_worked_military",
      "part_time"
    ),
    `Industrial sectors` = c(
      "industryManufacturing",
      "industryEducation, Health, Public Admin.",
      "industryOther services"
    )
  )
summary(decompose_results, custom_aggregation = custom_aggregation)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
