<!DOCTYPE html><html><head><title>Help for package mulgar</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mulgar}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aflw'><p>AFLW player statistics</p></a></li>
<li><a href='#box'><p>3D plane in 5D</p></a></li>
<li><a href='#bushfires'><p>Australian bushfires 2019-2020</p></a></li>
<li><a href='#c1'><p>Challenge data sets</p></a></li>
<li><a href='#calc_mv_dist'><p>Compute Mahalanobis distances between all pairs of observations</p></a></li>
<li><a href='#calc_norm'><p>Calculate the norm of a vector</p></a></li>
<li><a href='#clusters'><p>Three clusters in 5D</p></a></li>
<li><a href='#clusters_nonlin'><p>Four unusually shaped clusters in 4D</p></a></li>
<li><a href='#convert_proj_tibble'><p>This function turns a projection sequence into a tibble</p></a></li>
<li><a href='#gen_vc_ellipse'><p>Generate points on the surface of an ellipse</p></a></li>
<li><a href='#gen_xvar_ellipse'><p>Ellipse matching data center and variance</p></a></li>
<li><a href='#ggmcbic'><p>Produces an mclust summary plot with ggplot</p></a></li>
<li><a href='#ggscree'><p>This function produces a simple scree plot</p></a></li>
<li><a href='#ggslice'><p>Generate an axis-parallel slice display</p></a></li>
<li><a href='#ggslice_projection'><p>Generate slice display</p></a></li>
<li><a href='#hierfly'><p>Generate a dendrogram to be added to data</p></a></li>
<li><a href='#mc_ellipse'><p>Computes the ellipses of an mclust model</p></a></li>
<li><a href='#mulgar-package'><p>mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation using Tours</p></a></li>
<li><a href='#multicluster'><p>Multiple clusters of different sizes, shapes and distance from each other</p></a></li>
<li><a href='#norm_vec'><p>Normalise a vector to have length 1</p></a></li>
<li><a href='#pca_model'><p>Create wire frame of PCA model</p></a></li>
<li><a href='#pisa'><p>PISA scores</p></a></li>
<li><a href='#plane'><p>2D plane in 5D</p></a></li>
<li><a href='#plane_nonlin'><p>Non-linear relationship in 5D</p></a></li>
<li><a href='#pooled_vc'><p>Compute pooled variance-covariance matrix</p></a></li>
<li><a href='#rmvn'><p>Generate a sample from a multivariate normal</p></a></li>
<li><a href='#simple_clusters'><p>Two clusters in 2D</p></a></li>
<li><a href='#sketches_test'><p>Images of sketches for testing</p></a></li>
<li><a href='#sketches_train'><p>Images of sketches for training</p></a></li>
<li><a href='#som_model'><p>Process the output from SOM to display the map and data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Functions for Pre-Processing Data for Multivariate Data
Visualisation using Tours</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>This is a companion to the book Cook, D. and Laa, U. (2023) <a href="https://dicook.github.io/mulgar_book/">https://dicook.github.io/mulgar_book/</a>
  "Interactively exploring high-dimensional data and models in R".  
  by Cook and Laa. It contains useful functions for processing data in preparation for 
  visualising with a tour. There are also several sample data sets.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>geozoo, tibble, ggplot2, tidyr, dplyr, purrr, stats, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>tourr, ggdendro, colorspace, mclust, kohonen</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>bzip2</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://dicook.github.io/mulgar/">https://dicook.github.io/mulgar/</a>, <a href="https://github.com/dicook/mulgar">https://github.com/dicook/mulgar</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/dicook/mulgar/issues">https://github.com/dicook/mulgar/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-25 21:45:41 UTC; cookd</td>
</tr>
<tr>
<td>Author:</td>
<td>Dianne Cook <a href="https://orcid.org/0000-0002-3813-7155"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Ursula Laa <a href="https://orcid.org/0000-0002-0249-6439"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dianne Cook &lt;dicook@monash.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-25 22:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aflw'>AFLW player statistics</h2><span id='topic+aflw'></span>

<h3>Description</h3>

<p>This is data from the 2021 Women's Australian Football League.
These are average player statistics across the season, with game statistics
provided by the <a href="https://jimmyday12.github.io/fitzRoy/">fitzRoy</a> package.
If you are new to the game of AFL, there is a nice
explanation on <a href="https://en.wikipedia.org/wiki/Women%27s_Australian_rules_football">Wikipedia</a>.
The primary analysis is to summarise the variation using
principal component analysis, which gives information about
relationships between the statistics or skills sets common in
players. One also might be tempted to cluster the players, but
there are no obvious clusters so it could be frustrating. At
best one could partition the players into groups, while recognising
there are no absolutely distinct and separated groups.
</p>


<h3>Format</h3>

<p>A dataset with 381 rows and 35 columns
</p>


<h3>Details</h3>


<dl>
<dt>id, given_name, surname, number, position, team</dt><dd><p>player identification details</p>
</dd>
<dt>time_pct, ..., clearances</dt><dd><p>player statistics for the match</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
require(dplyr)
data(aflw)
glimpse(aflw)
</code></pre>

<hr>
<h2 id='box'>3D plane in 5D</h2><span id='topic+box'></span>

<h3>Description</h3>

<p>This data is simulated to use for testing.
It has three dimensions of variability and
two of noise. It is created from a 3 factor
model. All variables are linearly associated.
</p>


<h3>Format</h3>

<p>A dataset with 200 rows and 5 columns
</p>


<h3>Details</h3>


<dl>
<dt>x1, x2, x3, x4, x5</dt><dd><p>five numeric variables</p>
</dd>
</dl>



<h3>See Also</h3>

<p>plane
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
box_pca &lt;- prcomp(box)
ggscree(box_pca)
</code></pre>

<hr>
<h2 id='bushfires'>Australian bushfires 2019-2020</h2><span id='topic+bushfires'></span>

<h3>Description</h3>

<p>This data was collated by Weihao (Patrick) Li as part of his
Honours research at Monash University. It contains fire
ignitions as detected from satellite hotspots, and processed
using the <a href="https://tengmcing.github.io/spotoroo/">spotoroo</a> package, augmented with
measurements on weather, vegetation, proximity to human activity. The
cause variable is predicted based on historical fire ignition data
collected by County Fire Authority personnel.
</p>


<h3>Format</h3>

<p>A dataset with 1021 rows and 60 columns
</p>


<h3>Details</h3>


<dl>
<dt>id, lon, lat, time</dt><dd><p>unique id, and spatiotemporal information for each fire ignition</p>
</dd>
<dt>FOR_CODE, FOR_TYPE, COVER, HEIGHT, FOREST</dt><dd><p>vegetation variables</p>
</dd>
<dt>rf, arf7-arf720</dt><dd><p>average rainfall, on that day, and over last 7, ..., 720 days</p>
</dd>
<dt>se, ase7-ase720</dt><dd><p>solar exposure, on that day, and over last 7, ..., 720 days</p>
</dd>
<dt>maxt, amaxt7-amaxt720</dt><dd><p>max temperature, on that day, and over last 7, ..., 720 days</p>
</dd>
<dt>mint, amint7-amint720</dt><dd><p>min temperature, on that day, and over last 7, ..., 720 days</p>
</dd>
<dt>ws, aws_m0-aws_m24</dt><dd><p>average wind speed, on that day, and for last 1-24 months</p>
</dd>
<dt>dist_road, log_dist_road</dt><dd><p>distance to nearest road</p>
</dd>
<dt>dist_cfa, log_dist_cfa</dt><dd><p>distance to nearest county fire authority facility</p>
</dd>
<dt>dist_camp, log_dist_camp</dt><dd><p>distance to nearest camp site</p>
</dd>
<dt>cause</dt><dd><p>predicted ignition cause, accident, arson, burning_off, lightning</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
require(dplyr)
data(bushfires)
glimpse(bushfires)
</code></pre>

<hr>
<h2 id='c1'>Challenge data sets</h2><span id='topic+c1'></span><span id='topic+c2'></span><span id='topic+c3'></span><span id='topic+c4'></span><span id='topic+c5'></span><span id='topic+c6'></span><span id='topic+c7'></span>

<h3>Description</h3>

<p>Simulated data with different structure
</p>


<h3>Format</h3>

<p>A datasets with differing number of rows and columns
</p>


<h3>Details</h3>


<dl>
<dt>x1, x2, ... </dt><dd><p>numeric variables</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>require(ggplot2)
ggplot(c1, aes(x=x1, y=x2)) +
  geom_point() + theme(aspect.ratio=1)
</code></pre>

<hr>
<h2 id='calc_mv_dist'>Compute Mahalanobis distances between all pairs of observations</h2><span id='topic+calc_mv_dist'></span>

<h3>Description</h3>

<p>For a data matrix, compute the sample variance-covariance,
which is used to compute the Mahalanobis distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_mv_dist(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_mv_dist_+3A_x">x</code></td>
<td>
<p>multivariate data set</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is useful for checking distance arise from a
multivariate normal sample.
</p>


<h3>Value</h3>

<p>vector of length n
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(ggplot2)
require(tibble)
data(aflw)
aflw_std &lt;- apply(aflw[,7:35], 2, function(x)
                    (x-mean(x, na.rm=TRUE))/
							       sd(x, na.rm=TRUE))
d &lt;- calc_mv_dist(aflw_std[,c("goals","behinds",
                               "kicks","disposals")])
d &lt;- as_tibble(d, .name_repair="minimal")
ggplot(d, aes(x=value)) + geom_histogram()
</code></pre>

<hr>
<h2 id='calc_norm'>Calculate the norm of a vector</h2><span id='topic+calc_norm'></span>

<h3>Description</h3>

<p>Returns the square root of the sum of squares
of a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_norm(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_norm_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(5)
calc_norm(x)
</code></pre>

<hr>
<h2 id='clusters'>Three clusters in 5D</h2><span id='topic+clusters'></span>

<h3>Description</h3>

<p>This data is simulated to use for testing.
It has three elliptical clusters in mostly
variables 2 and 4. They are not equidistant.
</p>


<h3>Format</h3>

<p>A dataset with 300 rows and 6 columns
</p>


<h3>Details</h3>


<dl>
<dt>x1, x2, x3, x4, x5</dt><dd><p>five numeric variables</p>
</dd>
<dt>cl</dt><dd><p>class variable</p>
</dd>
</dl>



<h3>See Also</h3>

<p>simple_clusters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
clusters_pca &lt;- prcomp(clusters[,1:5])
ggscree(clusters_pca)
</code></pre>

<hr>
<h2 id='clusters_nonlin'>Four unusually shaped clusters in 4D</h2><span id='topic+clusters_nonlin'></span>

<h3>Description</h3>

<p>This data is simulated to use for testing.
It has two small spherical clusters, and
a curve cluster and a sine wave cluster.
</p>


<h3>Format</h3>

<p>A dataset with 300 rows and 6 columns
</p>


<h3>Details</h3>


<dl>
<dt>x1, x2, x3, x4</dt><dd><p>five numeric variables</p>
</dd>
</dl>



<h3>See Also</h3>

<p>clusters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(ggplot2)
ggplot(clusters_nonlin, aes(x=x1, y=x2)) +
  geom_point() +
  theme(aspect.ratio=1)
</code></pre>

<hr>
<h2 id='convert_proj_tibble'>This function turns a projection sequence into a tibble</h2><span id='topic+convert_proj_tibble'></span>

<h3>Description</h3>

<p>Take an array of a projection sequence, and turn into
a tibble with numbered projections
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_proj_tibble(t1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convert_proj_tibble_+3A_t1">t1</code></td>
<td>
<p>tour projection sequence</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tbl1 tibble
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(tourr)
t1 &lt;- interpolate(save_history(flea[, 1:6], grand_tour(4), max = 2))
tbl1 &lt;- convert_proj_tibble(t1)
</code></pre>

<hr>
<h2 id='gen_vc_ellipse'>Generate points on the surface of an ellipse</h2><span id='topic+gen_vc_ellipse'></span>

<h3>Description</h3>

<p>This function generates points by transforming points
on the surface of a sphere.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_vc_ellipse(vc, xm = rep(0, ncol(vc)), n = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen_vc_ellipse_+3A_vc">vc</code></td>
<td>
<p>symmetric square matrix describing the
variance-covariance matrix which defines the shape
of the ellipse.</p>
</td></tr>
<tr><td><code id="gen_vc_ellipse_+3A_xm">xm</code></td>
<td>
<p>center of the ellipse, a vector of length
equal to the dimension of vc</p>
</td></tr>
<tr><td><code id="gen_vc_ellipse_+3A_n">n</code></td>
<td>
<p>number of points to generate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of size n x p
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(ggplot2)
require(tibble)
ell2d &lt;- gen_vc_ellipse(vc = matrix(c(4, 2, 2, 6),
                        ncol=2, byrow=TRUE),
                        xm = c(1,1))
ell2d &lt;- as_tibble(ell2d)
ggplot(ell2d, aes(x = V1, y = V2)) + geom_point() +
  theme(aspect.ratio=1)
</code></pre>

<hr>
<h2 id='gen_xvar_ellipse'>Ellipse matching data center and variance</h2><span id='topic+gen_xvar_ellipse'></span>

<h3>Description</h3>

<p>This function generates points on the surface of an
ellipse with the same center and variance-covariance
of the provided data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_xvar_ellipse(x, n = 100, nstd = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen_xvar_ellipse_+3A_x">x</code></td>
<td>
<p>multivariate data set.</p>
</td></tr>
<tr><td><code id="gen_xvar_ellipse_+3A_n">n</code></td>
<td>
<p>number of points to generate</p>
</td></tr>
<tr><td><code id="gen_xvar_ellipse_+3A_nstd">nstd</code></td>
<td>
<p>scale factor for size of ellipse, in terms
of number of standard deviations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is useful for checking the equal variance-covariance
assumption from linear discriminant analysis.
</p>


<h3>Value</h3>

<p>matrix of size n x p
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(aflw)
aflw_vc &lt;- gen_xvar_ellipse(aflw[,c("goals","behinds",
                               "kicks","disposals")], n=500)
require(ggplot2)
ggplot(aflw_vc, aes(x=goals, y=behinds)) + geom_point() +
  theme(aspect.ratio=1)
if (interactive()) {
  require(tourr)
  animate_slice(aflw_vc, rescale=TRUE, v_rel=0.02)
  aflw_all &lt;- rbind(aflw_vc, aflw[,c("goals","behinds",
                               "kicks","disposals")])
  clrs &lt;- c(rep("orange", 500), rep("black", nrow(aflw)))
  animate_xy(aflw_all, col=clrs)
}
</code></pre>

<hr>
<h2 id='ggmcbic'>Produces an mclust summary plot with ggplot</h2><span id='topic+ggmcbic'></span>

<h3>Description</h3>

<p>Takes data returned by <code>mclustBIC()</code>, converts to a tibble
for plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggmcbic(mc, cl = 1:nrow(mc), top = ncol(mc))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggmcbic_+3A_mc">mc</code></td>
<td>
<p>mclustBIC object</p>
</td></tr>
<tr><td><code id="ggmcbic_+3A_cl">cl</code></td>
<td>
<p>subset of clusters to show</p>
</td></tr>
<tr><td><code id="ggmcbic_+3A_top">top</code></td>
<td>
<p>number to indicate how many models to show, default &quot;all&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>mc_bic a ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(mclust)
data(clusters)
clusters_BIC &lt;- mclustBIC(clusters[,1:5], G=2:6)
ggmcbic(clusters_BIC)
ggmcbic(clusters_BIC, top=4)

data(simple_clusters)
clusters_BIC &lt;- mclustBIC(simple_clusters[,1:2])
ggmcbic(clusters_BIC, cl=2:5, top=3)
</code></pre>

<hr>
<h2 id='ggscree'>This function produces a simple scree plot</h2><span id='topic+ggscree'></span>

<h3>Description</h3>

<p>Takes a PCA object returned by <code>prcomp()</code>, extracts
the standard deviations of the principal components (PC), and
plots these against the PC number. The guidance line assumes that
all of the variables have been standardised prior to PCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggscree(pc, q = 2, guide = TRUE, cumulative = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggscree_+3A_pc">pc</code></td>
<td>
<p>PCA object</p>
</td></tr>
<tr><td><code id="ggscree_+3A_q">q</code></td>
<td>
<p>number of principal components to show, default 2 (you should change)</p>
</td></tr>
<tr><td><code id="ggscree_+3A_guide">guide</code></td>
<td>
<p>logical whether to compute and add
a typical value of the variance, if the data was full-dimensional</p>
</td></tr>
<tr><td><code id="ggscree_+3A_cumulative">cumulative</code></td>
<td>
<p>logical whether to draw cumulative variance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>scree a ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(aflw)
aflw_std &lt;- apply(aflw[,7:35], 2, function(x)
                    (x-mean(x, na.rm=TRUE))/
							       sd(x, na.rm=TRUE))
aflw_pca &lt;- prcomp(aflw_std[,c("goals","behinds",
                               "kicks","disposals")])
ggscree(aflw_pca, q=3)
</code></pre>

<hr>
<h2 id='ggslice'>Generate an axis-parallel slice display</h2><span id='topic+ggslice'></span>

<h3>Description</h3>

<p>Following the slice definition available in <code>tourr</code>
this function returns a <code>ggplot2</code> display of a slice
defined via the projection onto two of the variables.
Note that because the underlying function works with any
projection, the axis labels need to be set by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggslice(data, h, v1 = 1, v2 = 2, center = NULL, col = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggslice_+3A_data">data</code></td>
<td>
<p>data frame containing only variables used for the display</p>
</td></tr>
<tr><td><code id="ggslice_+3A_h">h</code></td>
<td>
<p>slice thickness</p>
</td></tr>
<tr><td><code id="ggslice_+3A_v1">v1</code></td>
<td>
<p>column number of variable mapped to x-axis</p>
</td></tr>
<tr><td><code id="ggslice_+3A_v2">v2</code></td>
<td>
<p>column number of variable mapped to y-axis</p>
</td></tr>
<tr><td><code id="ggslice_+3A_center">center</code></td>
<td>
<p>center point vector used for anchoring the slice,
if NULL the mean of the data is used</p>
</td></tr>
<tr><td><code id="ggslice_+3A_col">col</code></td>
<td>
<p>grouping vector mapped to color in the display</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 object showing the sliced data
</p>


<h3>See Also</h3>

<p>ggslice_projection
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- geozoo::sphere.hollow(4, 1000)$points
ggslice(d, 0.3, 1, 2)
ggslice(d, 0.3, 1, 2, center = c(0, 0, 0.7, 0))
</code></pre>

<hr>
<h2 id='ggslice_projection'>Generate slice display</h2><span id='topic+ggslice_projection'></span>

<h3>Description</h3>

<p>Generate slice display
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggslice_projection(data, h, proj, center = NULL, col = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggslice_projection_+3A_data">data</code></td>
<td>
<p>data frame containing only variables used for the display</p>
</td></tr>
<tr><td><code id="ggslice_projection_+3A_h">h</code></td>
<td>
<p>slice thickness</p>
</td></tr>
<tr><td><code id="ggslice_projection_+3A_proj">proj</code></td>
<td>
<p>projection matrix from p to 2 dimensions</p>
</td></tr>
<tr><td><code id="ggslice_projection_+3A_center">center</code></td>
<td>
<p>center point vector used for anchoring the slice,
if NULL the mean of the data is used</p>
</td></tr>
<tr><td><code id="ggslice_projection_+3A_col">col</code></td>
<td>
<p>grouping vector mapped to color in the display</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 object showing the sliced data
</p>


<h3>See Also</h3>

<p>ggslice
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- geozoo::sphere.hollow(4, 1000)$points
ggslice_projection(d, 0.3, tourr::basis_random(4))
ggslice_projection(d, 0.3, tourr::basis_random(4),
                   center = c(0.4, 0.4, 0.4, 0.4))
</code></pre>

<hr>
<h2 id='hierfly'>Generate a dendrogram to be added to data</h2><span id='topic+hierfly'></span>

<h3>Description</h3>

<p>Supplements a data set with information needed to draw a
dendrogram. Intermediate cluster nodes are added as needed, and
positioned at the centroid of the combined clusters. Note that
categorical variables need to be factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierfly(data, h = NULL, metric = "euclidean", method = "ward.D2", scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hierfly_+3A_data">data</code></td>
<td>
<p>data set</p>
</td></tr>
<tr><td><code id="hierfly_+3A_h">h</code></td>
<td>
<p>an hclust object</p>
</td></tr>
<tr><td><code id="hierfly_+3A_metric">metric</code></td>
<td>
<p>distance metric to use, see <code><a href="stats.html#topic+dist">dist</a></code> for list of
possibilities</p>
</td></tr>
<tr><td><code id="hierfly_+3A_method">method</code></td>
<td>
<p>cluster distance measure to use, see <code><a href="stats.html#topic+hclust">hclust</a></code> for
details</p>
</td></tr>
<tr><td><code id="hierfly_+3A_scale">scale</code></td>
<td>
<p>logical value whether to scale data or not, default TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with data and edges and segments
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clusters)
cl_dist &lt;- dist(clusters[,1:5])
cl_hw &lt;- hclust(cl_dist, method="ward.D2")
require(ggdendro)
ggdendrogram(cl_hw, type = "triangle", labels = FALSE)
clusters$clw &lt;- factor(cutree(cl_hw, 3))
cl_hfly &lt;- hierfly(clusters, cl_hw, scale=FALSE)
if (interactive()) {
  require(tourr)
  glyphs &lt;- c(16, 46)
  pch &lt;- glyphs[cl_hfly$data$node+1]
  require(colorspace)
  clrs &lt;- heat_hcl(length(unique(cl_hfly$data$clw)))
  pcol &lt;- clrs[cl_hfly$data$clw]
  ecol &lt;- clrs[cl_hfly$data$clw[cl_hfly$edges[,1]]]
  animate_xy(cl_hfly$data[,1:5], edges=cl_hfly$edges,
    col=pcol, pch=pch, edges.col=ecol,
    axes="bottomleft")
}
</code></pre>

<hr>
<h2 id='mc_ellipse'>Computes the ellipses of an mclust model</h2><span id='topic+mc_ellipse'></span>

<h3>Description</h3>

<p>Takes data returned by <code>Mclust()</code>, extracts
parameter estimates, and computes points on
ellipses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mc_ellipse(mc, npts = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mc_ellipse_+3A_mc">mc</code></td>
<td>
<p>Mclust object</p>
</td></tr>
<tr><td><code id="mc_ellipse_+3A_npts">npts</code></td>
<td>
<p>Number of points to simulate for each cluster, default 100</p>
</td></tr>
</table>


<h3>Value</h3>

<p>mc_ellipses data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(mclust)
data(simple_clusters)
clusters_mc &lt;- Mclust(simple_clusters[,1:2],
                     G=2,
                     modelname="EEI")
mce &lt;- mc_ellipse(clusters_mc, npts=400)
require(ggplot2)
sc &lt;- simple_clusters
sc$cl &lt;- factor(clusters_mc$classification)
ggplot() +
  geom_point(data=sc, aes(x=x1, y=x2, colour=cl)) +
  geom_point(data=mce$ell, aes(x=x1, y=x2, colour=cl), shape=4) +
  geom_point(data=mce$mn, aes(x=x1, y=x2, colour=cl), shape=3) +
  theme(aspect.ratio=1, legend.position="none")
</code></pre>

<hr>
<h2 id='mulgar-package'>mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation using Tours</h2><span id='topic+mulgar'></span><span id='topic+mulgar-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>This is a companion to the book Cook, D. and Laa, U. (2023) <a href="https://dicook.github.io/mulgar_book/">https://dicook.github.io/mulgar_book/</a> &quot;Interactively exploring high-dimensional data and models in R&quot;. by Cook and Laa. It contains useful functions for processing data in preparation for visualising with a tour. There are also several sample data sets.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Dianne Cook <a href="mailto:dicook@monash.edu">dicook@monash.edu</a> (<a href="https://orcid.org/0000-0002-3813-7155">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Ursula Laa <a href="mailto:ursula.laa@boku.ac.at">ursula.laa@boku.ac.at</a> (<a href="https://orcid.org/0000-0002-0249-6439">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://dicook.github.io/mulgar/">https://dicook.github.io/mulgar/</a>
</p>
</li>
<li> <p><a href="https://github.com/dicook/mulgar">https://github.com/dicook/mulgar</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/dicook/mulgar/issues">https://github.com/dicook/mulgar/issues</a>
</p>
</li></ul>


<hr>
<h2 id='multicluster'>Multiple clusters of different sizes, shapes and distance from each other</h2><span id='topic+multicluster'></span>

<h3>Description</h3>

<p>This data is originally from http://ifs.tuwien.ac.at/dm/download/multiChallenge-matrix.txt,
and provided as a challenge for non-linear dimension reduction.It was used
as an example in Lee, Laa, Cook (2023) https://doi.org/10.52933/jdssv.v2i3.
</p>


<h3>Format</h3>

<p>A dataset with 400 rows and 11 columns
</p>


<h3>Details</h3>


<dl>
<dt>group</dt><dd><p>cluster label</p>
</dd>
<dt>x1, ... x10</dt><dd><p>numeric variables</p>
</dd>
</dl>



<h3>See Also</h3>

<p>clusters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(ggplot2)
ggplot(multicluster, aes(x=x1, y=x2)) +
  geom_point() + theme(aspect.ratio=1)
</code></pre>

<hr>
<h2 id='norm_vec'>Normalise a vector to have length 1</h2><span id='topic+norm_vec'></span>

<h3>Description</h3>

<p>Returns the normalised vector, where the sum of
squares is equal to 1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_vec(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm_vec_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(5)
norm_vec(x)
</code></pre>

<hr>
<h2 id='pca_model'>Create wire frame of PCA model</h2><span id='topic+pca_model'></span>

<h3>Description</h3>

<p>This function takes the PCA and produces a wire frame
of the PCA to examine with the data in a tour. The purpose
is to see how well the variance is explained. The model
will be centered at the mean, and extend 3 SDs towards the edge
of the data, which is assuming that the data is standardised.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pca_model(pc, d = 2, s = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pca_model_+3A_pc">pc</code></td>
<td>
<p>PCA object</p>
</td></tr>
<tr><td><code id="pca_model_+3A_d">d</code></td>
<td>
<p>number of dimensions to use, default=2</p>
</td></tr>
<tr><td><code id="pca_model_+3A_s">s</code></td>
<td>
<p>scale model, default=1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of points and edges
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(plane)
plane_pca &lt;- prcomp(plane)
plane_m &lt;- pca_model(plane_pca)
plane_m_d &lt;- rbind(plane_m$points, plane)
if (interactive()) {
  require(tourr)
  animate_xy(plane_m_d, edges=plane_m$edges, axes="bottomleft")
}
</code></pre>

<hr>
<h2 id='pisa'>PISA scores</h2><span id='topic+pisa'></span>

<h3>Description</h3>

<p>This is data from the 2018 testing, available from
https://webfs.oecd.org/pisa2018/SPSS_STU_QQQ.zip.
A subset of the data containing only
Australia and Indonesia, and the simulated
scores for math, reading and science.
</p>


<h3>Format</h3>

<p>A data set with 26371 rows and 31 columns
</p>


<h3>Details</h3>


<dl>
<dt>CNT</dt><dd><p>Country (Australia, Indonesia)</p>
</dd>
<dt>PV1MATH-PV10SCIE</dt><dd><p>simulated scores for math, reading and science</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
require(dplyr)
data(pisa)
pisa %&gt;% count(CNT)
</code></pre>

<hr>
<h2 id='plane'>2D plane in 5D</h2><span id='topic+plane'></span>

<h3>Description</h3>

<p>This data is simulated to use for testing.
It has two dimensions of variability and
three of noise. It is created from a 2 factor
model, where all variables are related.
</p>


<h3>Format</h3>

<p>A data set with 100 rows and 5 columns
</p>


<h3>Details</h3>


<dl>
<dt>x1, x2, x3, x4, x5</dt><dd><p>five numeric variables</p>
</dd>
</dl>



<h3>See Also</h3>

<p>box
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
plane_pca &lt;- prcomp(plane)
ggscree(plane_pca)
</code></pre>

<hr>
<h2 id='plane_nonlin'>Non-linear relationship in 5D</h2><span id='topic+plane_nonlin'></span>

<h3>Description</h3>

<p>This data is simulated to use for testing.
It has three dimensions of variability and
two of noise. It is created from a 2 factor
non-linear model. All variables are associated.
</p>


<h3>Format</h3>

<p>A dataset with 100 rows and 5 columns
</p>


<h3>Details</h3>


<dl>
<dt>x1, x2, x3, x4, x5</dt><dd><p>five numeric variables</p>
</dd>
</dl>



<h3>See Also</h3>

<p>plane, box
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
plane_nonlin_pca &lt;- prcomp(plane_nonlin)
ggscree(plane_nonlin_pca)
</code></pre>

<hr>
<h2 id='pooled_vc'>Compute pooled variance-covariance matrix</h2><span id='topic+pooled_vc'></span>

<h3>Description</h3>

<p>This function computes the group variance-covariance
matrices, and produces a weighted average. It is useful
for examining the linear discriminant analysis model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pooled_vc(x, cl, prior = rep(1/length(unique(cl)), length(unique(cl))))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pooled_vc_+3A_x">x</code></td>
<td>
<p>multivariate data set, matrix.</p>
</td></tr>
<tr><td><code id="pooled_vc_+3A_cl">cl</code></td>
<td>
<p>class variable</p>
</td></tr>
<tr><td><code id="pooled_vc_+3A_prior">prior</code></td>
<td>
<p>prior probability for each class, must sum to 1, default all equal</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clusters)
pooled_vc(clusters[,1:5], clusters$cl)
</code></pre>

<hr>
<h2 id='rmvn'>Generate a sample from a multivariate normal</h2><span id='topic+rmvn'></span>

<h3>Description</h3>

<p>This function generates a  sample of size n from a
multivariate normal distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvn(n = 100, p = 5, mn = rep(0, p), vc = diag(rep(1, p)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvn_+3A_n">n</code></td>
<td>
<p>number of points to generate</p>
</td></tr>
<tr><td><code id="rmvn_+3A_p">p</code></td>
<td>
<p>dimension</p>
</td></tr>
<tr><td><code id="rmvn_+3A_mn">mn</code></td>
<td>
<p>mean of the distribution, a vector of length
equal to the dimension of vc</p>
</td></tr>
<tr><td><code id="rmvn_+3A_vc">vc</code></td>
<td>
<p>symmetric square matrix describing the
variance-covariance matrix which defines the shape
of the ellipse.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of size n x p
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(ggplot2)
d &lt;- mulgar::rmvn(n=100, p=2, mn = c(1,1),
                  vc = matrix(c(4, 2, 2, 6),
                         ncol=2, byrow=TRUE))
ggplot(data.frame(d), aes(x = x1, y = x2)) +
  geom_point() + theme(aspect.ratio=1)
</code></pre>

<hr>
<h2 id='simple_clusters'>Two clusters in 2D</h2><span id='topic+simple_clusters'></span>

<h3>Description</h3>

<p>This data is simulated to use for testing.
It has two spherical clusters, and two variables.
</p>


<h3>Format</h3>

<p>A dataset with 137 rows and 3 columns
</p>


<h3>Details</h3>


<dl>
<dt>x1, x2</dt><dd><p>two numeric variables</p>
</dd>
<dt>cl</dt><dd><p>class variable</p>
</dd>
</dl>



<h3>See Also</h3>

<p>clusters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(ggplot2)
ggplot(simple_clusters, aes(x=x1, y=x2)) +
  geom_point() + theme(aspect.ratio=1)
</code></pre>

<hr>
<h2 id='sketches_test'>Images of sketches for testing</h2><span id='topic+sketches_test'></span>

<h3>Description</h3>

<p>This data is a subset of images from https://quickdraw.withgoogle.com
The subset was created using the quickdraw R package at
https://huizezhang-sherry.github.io/quickdraw/.
It has 6 different groups: banana, boomerang, cactus, flip flops,
kangaroo. Each image is 28x28 pixels.
</p>


<h3>Format</h3>

<p>A data frame with 1200 rows and 786 columns
</p>


<h3>Details</h3>


<dl>
<dt>V1-V784</dt><dd><p>grey scale 0-255</p>
</dd>
<dt>word</dt><dd><p>all NA, you need to predict this</p>
</dd>
<dt>id</dt><dd><p>unique id for each sketch</p>
</dd>
</dl>



<h3>See Also</h3>

<p>sketches_train
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(ggplot2)
data("sketches_test")
x &lt;- sketches_test[sample(1:nrow(sketches_test), 1), ]
xm &lt;- data.frame(gry=t(as.matrix(x[,1:784])),
        x=rep(1:28, 28),
        y=rep(28:1, rep(28, 28)))
ggplot(xm, aes(x=x, y=y, fill=gry)) +
  geom_tile() +
  scale_fill_gradientn(colors = gray.colors(256, start = 0, end = 1, rev = TRUE )) +
  theme_void() + theme(legend.position="none")
</code></pre>

<hr>
<h2 id='sketches_train'>Images of sketches for training</h2><span id='topic+sketches_train'></span>

<h3>Description</h3>

<p>This data is a subset of images from https://quickdraw.withgoogle.com
The subset was created using the quickdraw R package at
https://huizezhang-sherry.github.io/quickdraw/.
It has 6 different groups: banana, boomerang, cactus, flip flops,
kangaroo. Each image is 28x28 pixels. This data would be
used to train a classification model.
</p>


<h3>Format</h3>

<p>A data frame with 5998 rows and 786 columns
</p>


<h3>Details</h3>


<dl>
<dt>V1-V784</dt><dd><p>grey scale 0-255</p>
</dd>
<dt>word</dt><dd><p>what the person was asked to draw</p>
</dd>
<dt>id</dt><dd><p>unique id for each sketch</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
require(ggplot2)
data("sketches_train")
x &lt;- sketches_train[sample(1:nrow(sketches_train), 1), ]
# print(x$word)
xm &lt;- data.frame(gry=t(as.matrix(x[,1:784])),
        x=rep(1:28, 28),
        y=rep(28:1, rep(28, 28)))
ggplot(xm, aes(x=x, y=y, fill=gry)) +
  geom_tile() +
  scale_fill_gradientn(colors = gray.colors(256, start = 0, end = 1, rev = TRUE )) +
  theme_void() + theme(legend.position="none")
</code></pre>

<hr>
<h2 id='som_model'>Process the output from SOM to display the map and data</h2><span id='topic+som_model'></span>

<h3>Description</h3>

<p>This function generates a grid of points to match the
nodes from the self-organising map (SOM), and jitters points
from the data so they can be seen relative to the grid.
This allows the clustering of points by SOM to be inspected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som_model(x_som, j_val = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som_model_+3A_x_som">x_som</code></td>
<td>
<p>object returned by kohonen::som</p>
</td></tr>
<tr><td><code id="som_model_+3A_j_val">j_val</code></td>
<td>
<p>amount of jitter, should range from 0-1, default 0.3</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li><p> data this object contains
</p>

<ul>
<li><p> original variables from the data
</p>
</li>
<li><p> map1, map2 location of observations in 2D som map, jittered
</p>
</li>
<li><p> distance distances between observations and the closest node
</p>
</li>
<li><p> id row id of data
</p>
</li></ul>

</li>
<li><p> net this object contains
</p>

<ul>
<li><p> values of the nodes in the high-d space
</p>
</li>
<li><p> map1, map2 nodes of the som net
</p>
</li>
<li><p> distance distances between observations and the closest node
</p>
</li>
<li><p> id row id of net
</p>
</li></ul>

</li>
<li><p> edges from, to specifying row ids of net to connect with lines
</p>
</li>
<li><p> edges_s x, xend, y, yend for segments to draw lines to form 2D map
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>require(kohonen)
data(clusters)
c_grid &lt;- kohonen::somgrid(xdim = 5, ydim = 5,
  topo = 'rectangular')
c_som &lt;- kohonen::som(as.matrix(clusters[,1:5]), grid = c_grid)
c_data_net &lt;- som_model(c_som)
require(ggplot2)
ggplot() +
  geom_segment(data=c_data_net$edges_s,
    aes(x=x, xend=xend, y=y, yend=yend)) +
  geom_point(data=c_data_net$data, aes(x=map1, y=map2),
    colour="orange", size=2, alpha=0.5)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
