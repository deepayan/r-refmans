<!DOCTYPE html><html><head><title>Help for package ecpc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ecpc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ecpc-package'>
<p>Flexible Co-Data Learning for High-Dimensional Prediction</p></a></li>
<li><a href='#coef.ecpc'>
<p>Obtain coefficients from 'ecpc' object</p></a></li>
<li><a href='#createCon'>
<p>Create a list of constraints for co-data weight estimation</p></a></li>
<li><a href='#createGroupset'>
<p>Create a group set (groups) of variables</p></a></li>
<li><a href='#createS'>
<p>Create a generalised penalty matrix</p></a></li>
<li><a href='#createZforGroupset'>
<p>Create a co-data matrix Z for a group set</p></a></li>
<li><a href='#createZforSplines'>
<p>Create a co-data matrix Z of splines</p></a></li>
<li><a href='#cv.ecpc'>
<p>Cross-validation for 'ecpc'</p></a></li>
<li><a href='#ecpc'>
<p>Fit adaptive multi-group ridge GLM with hypershrinkage</p></a></li>
<li><a href='#hierarchicalLasso'>
<p>Fit hierarchical lasso using LOG penalty</p></a></li>
<li><a href='#obtainHierarchy'>
<p>Obtain hierarchy</p></a></li>
<li><a href='#plot.ecpc'>
<p>Plot an 'ecpc' object</p></a></li>
<li><a href='#postSelect'>
<p>Perform posterior selection</p></a></li>
<li><a href='#predict.ecpc'>
<p>Predict for new samples for &lsquo;ecpc&rsquo; object</p></a></li>
<li><a href='#print.ecpc'>
<p>Print summary of 'ecpc' object</p></a></li>
<li><a href='#produceFolds'>
<p>Produce folds</p></a></li>
<li><a href='#simDat'>
<p>Simulate data</p></a></li>
<li><a href='#splitMedian'>
<p>Discretise continuous data in multiple granularities</p></a></li>
<li><a href='#visualiseGroupset'>
<p>Visualise a group set</p></a></li>
<li><a href='#visualiseGroupsetweights'>
<p>Visualise estimated group set weights</p></a></li>
<li><a href='#visualiseGroupweights'>
<p>Visualise estimated group weights</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Flexible Co-Data Learning for High-Dimensional Prediction</td>
</tr>
<tr>
<td>Version:</td>
<td>3.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-02-27</td>
</tr>
<tr>
<td>Author:</td>
<td>Mirrelijn M. van Nee [aut, cre],
  Lodewyk F.A. Wessels [aut],
  Mark A. van de Wiel [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mirrelijn M. van Nee &lt;m.vannee@amsterdamumc.nl&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, stats, Matrix, gglasso, mvtnorm, CVXR, multiridge (&ge;
1.5), survival, pROC, mgcv, pracma, JOPS, quadprog, checkmate</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Rsolnp, expm, foreach, doParallel, parallel, ggplot2, ggraph,
igraph, ggpubr, scales, dplyr, magrittr, nnls</td>
</tr>
<tr>
<td>Description:</td>
<td>Fit linear, logistic and Cox survival regression models penalised with adaptive multi-group ridge penalties.
  The multi-group penalties correspond to groups of covariates defined by (multiple) co-data sources.
  Group hyperparameters are estimated with an empirical Bayes method of moments, penalised with an extra level of hyper shrinkage.
  Various types of hyper shrinkage may be used for various co-data.
  Co-data may be continuous or categorical. 
  The method accommodates inclusion of unpenalised covariates, posterior selection of covariates and multiple data types.
  The model fit is used to predict for new samples.
  The name 'ecpc' stands for Empirical Bayes, Co-data learnt, Prediction and Covariate selection.
  See Van Nee et al. (2020) &lt;<a href="https://doi.org/10.48550/arXiv.2005.04010">doi:10.48550/arXiv.2005.04010</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://dx.doi.org/10.1002/sim.9162">http://dx.doi.org/10.1002/sim.9162</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-02-27 19:56:56 UTC; Mirrelijn</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-02-27 21:12:30 UTC</td>
</tr>
</table>
<hr>
<h2 id='ecpc-package'>
Flexible Co-Data Learning for High-Dimensional Prediction
</h2><span id='topic+ecpc-package'></span><span id='topic+ecpc-package'></span>

<h3>Description</h3>

<p>Fit linear, logistic and Cox survival regression models penalised with adaptive multi-group ridge penalties.
  The multi-group penalties correspond to groups of covariates defined by (multiple) co-data sources.
  Group hyperparameters are estimated with an empirical Bayes method of moments, penalised with an extra level of hyper shrinkage.
  Various types of hyper shrinkage may be used for various co-data.
  Co-data may be continuous or categorical. 
  The method accommodates inclusion of unpenalised covariates, posterior selection of covariates and multiple data types.
  The model fit is used to predict for new samples.
  The name 'ecpc' stands for Empirical Bayes, Co-data learnt, Prediction and Covariate selection.
  See Van Nee et al. (2020) &lt;arXiv:2005.04010&gt;.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> ecpc</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Flexible Co-Data Learning for High-Dimensional Prediction</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 3.1.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-02-27</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person(c("Mirrelijn","M."), "van Nee", role = c("aut", "cre"),
                     email = "m.vannee@amsterdamumc.nl"),
              person(c("Lodewyk","F.A."), "Wessels", role = "aut"),
              person(c("Mark","A."), "van de Wiel", role = "aut"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Mirrelijn M. van Nee [aut, cre],
  Lodewyk F.A. Wessels [aut],
  Mark A. van de Wiel [aut]</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Mirrelijn M. van Nee &lt;m.vannee@amsterdamumc.nl&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.5.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> glmnet, stats, Matrix, gglasso, mvtnorm, CVXR, multiridge (&gt;= 1.5),
survival, pROC, mgcv, pracma, JOPS, quadprog, checkmate</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> Rsolnp, expm, foreach, doParallel, parallel,
ggplot2, ggraph, igraph, ggpubr, scales, dplyr, magrittr, nnls</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Fit linear, logistic and Cox survival regression models penalised with adaptive multi-group ridge penalties.
  The multi-group penalties correspond to groups of covariates defined by (multiple) co-data sources.
  Group hyperparameters are estimated with an empirical Bayes method of moments, penalised with an extra level of hyper shrinkage.
  Various types of hyper shrinkage may be used for various co-data.
  Co-data may be continuous or categorical. 
  The method accommodates inclusion of unpenalised covariates, posterior selection of covariates and multiple data types.
  The model fit is used to predict for new samples.
  The name 'ecpc' stands for Empirical Bayes, Co-data learnt, Prediction and Covariate selection.
  See Van Nee et al. (2020) &lt;arXiv:2005.04010&gt;.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 3)</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> http://dx.doi.org/10.1002/sim.9162</td>
</tr>
<tr>
 <td style="text-align: left;">
RoxygenNote: </td><td style="text-align: left;"> 7.2.0</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
coef.ecpc               Obtain coefficients from 'ecpc' object
createCon               Create a list of constraints for co-data weight
                        estimation
createGroupset          Create a group set (groups) of variables
createS                 Create a generalised penalty matrix
createZforGroupset      Create a co-data matrix Z for a group set
createZforSplines       Create a co-data matrix Z of splines
cv.ecpc                 Cross-validation for 'ecpc'
ecpc                    Fit adaptive multi-group ridge GLM with
                        hypershrinkage
ecpc-package            Flexible Co-Data Learning for High-Dimensional
                        Prediction
hierarchicalLasso       Fit hierarchical lasso using LOG penalty
obtainHierarchy         Obtain hierarchy
plot.ecpc               Plot an 'ecpc' object
postSelect              Perform posterior selection
predict.ecpc            Predict for new samples for 'ecpc' object
print.ecpc              Print summary of 'ecpc' object
produceFolds            Produce folds
simDat                  Simulate data
splitMedian             Discretise continuous data in multiple
                        granularities
visualiseGroupset       Visualise a group set
visualiseGroupsetweights
                        Visualise estimated group set weights
visualiseGroupweights   Visualise estimated group weights
</pre>
<p>See <code><a href="#topic+ecpc">ecpc</a></code> for example code.
</p>


<h3>Author(s)</h3>

<p>Mirrelijn M. van Nee [aut, cre],
  Lodewyk F.A. Wessels [aut],
  Mark A. van de Wiel [aut]
</p>
<p>Maintainer: Mirrelijn M. van Nee &lt;m.vannee@amsterdamumc.nl&gt;
</p>

<hr>
<h2 id='coef.ecpc'>
Obtain coefficients from 'ecpc' object
</h2><span id='topic+coef.ecpc'></span><span id='topic+penalties'></span>

<h3>Description</h3>

<p>Obtain regression coefficients or penalties from an existing model fit given in an 'ecpc' object,
re-estimate regression coefficients for a given 'ecpc' object and ridge
penalties, or obtain ridge penalties for given prior parameters and co-data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ecpc'
coef(object, penalties = NULL, 
          X = NULL, Y = NULL, 
          unpen = NULL, intrcpt = TRUE, 
          model = c("linear", "logistic", "cox"), 
          est_beta_method = c("glmnet", "multiridge"), ...)

penalties(object, tauglobal=NULL, sigmahat=NULL, gamma=NULL, gamma0=NULL, w=NULL,
          Z=NULL, groupsets=NULL,
          unpen=NULL, datablocks=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.ecpc_+3A_object">object</code></td>
<td>

<p>An 'ecpc' object returned by <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_penalties">penalties</code></td>
<td>

<p>Ridge penalties; p-dimensional vector. If provided to <code>coef.ecpc</code>, 'X' and 'Y' should be provided too.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_tauglobal">tauglobal</code></td>
<td>

<p>Estimated global prior variance; scalar (or vector with datatype-specific global prior variances when multiple &lsquo;datablocks&rsquo; are given).) If provided to <code>penalties</code>, 'Z' or 'groupsets' should be provided too.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_sigmahat">sigmahat</code></td>
<td>
<p>(linear model) Estimated sigma^2. If provided to <code>penalties</code>, 'Z' or 'groupsets' should be provided too.</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_gamma">gamma</code></td>
<td>
<p>Estimated co-data variable weights; vector of dimension the total number of groups. If provided to <code>penalties</code>, 'Z' or 'groupsets' should be provided too.</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_gamma0">gamma0</code></td>
<td>
<p>Estimated co-data variable intercept; scalar. If provided to <code>penalties</code>, 'Z' or 'groupsets' should be provided too.</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_w">w</code></td>
<td>
<p>Estimated group set weights; m-dimensional vector. If provided to <code>penalties</code>, 'Z' or 'groupsets' should be provided too.</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_x">X</code></td>
<td>

<p>Observed data; (nxp)-dimensional matrix (p: number of covariates) with each row the observed high-dimensional feature vector of a sample.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_y">Y</code></td>
<td>

<p>Response data; n-dimensional vector (n: number of samples) for linear and logistic outcomes, or <code><a href="survival.html#topic+Surv">Surv</a></code> object for Cox survival.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_z">Z</code></td>
<td>

<p>List with m co-data matrices. Each element is a (pxG)-dimensional co-data matrix containing co-data on the p   variables. Co-data should either be provided in &lsquo;Z&rsquo; or &lsquo;groupsets&rsquo;. 
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_groupsets">groupsets</code></td>
<td>

<p>Co-data group sets; list with m (m: number of group sets) group sets. Each group set is a list of all groups in that set. Each group is a vector containing the indices of the covariates in that group.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_unpen">unpen</code></td>
<td>

<p>Unpenalised covariates; vector with indices of covariates that should not be penalised.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_intrcpt">intrcpt</code></td>
<td>

<p>Should an intercept be included? Included by default for linear and logistic, excluded for Cox for which the baseline hazard is estimated.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_model">model</code></td>
<td>

<p>Type of model for the response; linear, logistic or cox.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_est_beta_method">est_beta_method</code></td>
<td>

<p>Package used for estimating regression coefficients, either &quot;glmnet&quot; or &quot;multiridge&quot;.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_datablocks">datablocks</code></td>
<td>

<p>(optional) for multiple data types, the corresponding blocks of data may be given in datablocks; a list of B vectors of the indices of covariates in &lsquo;X&rsquo; that belong to each of the B data blocks. Unpenalised covariates should not be given as seperate block, but can be omitted or included in blocks with penalised covariates. Each datatype obtains a datatype-specific &lsquo;tauglobal&rsquo; as in multiridge.
</p>
</td></tr>
<tr><td><code id="coef.ecpc_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>coef.ecpc</code>, a list with:
</p>
<table>
<tr><td><code>intercept</code></td>
<td>

<p>If included, the estimated intercept; scalar.
</p>
</td></tr> 
<tr><td><code>beta</code></td>
<td>

<p>Estimated regression coefficients; p-dimensional vector.
</p>
</td></tr> 
</table>
<p>For <code>penalties</code>: a p-dimensional vector with ridge penalties.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+penalties">penalties</a></code> for obtaining penalties for given prior parameters and co-data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
#####################
# Simulate toy data #
#####################
p&lt;-300 #number of covariates
n&lt;-100 #sample size training data set
n2&lt;-100 #sample size test data set

#simulate all betas i.i.d. from beta_k~N(mean=0,sd=sqrt(0.1)):
muBeta&lt;-0 #prior mean
varBeta&lt;-0.1 #prior variance
indT1&lt;-rep(1,p) #vector with group numbers all 1 (all simulated from same normal distribution)

#simulate test and training data sets:
Dat&lt;-simDat(n,p,n2,muBeta,varBeta,indT1,sigma=1,model='linear') 
str(Dat) #Dat contains centered observed data, response data and regression coefficients

###################
# Provide co-data #
###################
continuousCodata &lt;- abs(Dat$beta) 
Z1 &lt;- cbind(continuousCodata,sqrt(continuousCodata))

#setting 2: splines for informative continuous
Z2 &lt;- createZforSplines(values=continuousCodata)
S1.Z2 &lt;- createS(orderPen=2, G=dim(Z2)[2]) #create difference penalty matrix
Con2 &lt;- createCon(G=dim(Z2)[2], shape="positive+monotone.i") #create constraints

#setting 3: 5 random groups
G &lt;- 5
categoricalRandom &lt;- as.factor(sample(1:G,p,TRUE))
#make group set, i.e. list with G groups:
groupsetRandom &lt;- createGroupset(categoricalRandom)
Z3 &lt;- createZforGroupset(groupsetRandom,p=p)
S1.Z3 &lt;- createS(G=G, categorical = TRUE) #create difference penalty matrix
Con3 &lt;- createCon(G=dim(Z3)[2], shape="positive") #create constraints

#fit ecpc for the three co-data matrices with following penalty matrices and constraints
#note: can also be fitted without paraPen and/or paraCon
Z.all &lt;- list(Z1=Z1,Z2=Z2,Z3=Z3)
paraPen.all &lt;- list(Z2=list(S1=S1.Z2), Z3=list(S1=S1.Z3))
paraCon &lt;- list(Z2=Con2, Z3=Con3)

############
# Fit ecpc #
############
tic&lt;-proc.time()[[3]]
fit &lt;- ecpc(Y=Dat$Y,X=Dat$Xctd,
           Z = Z.all, paraPen = paraPen.all, paraCon = paraCon,
           model="linear",maxsel=c(5,10,15,20),
           Y2=Dat$Y2,X2=Dat$X2ctd)
toc &lt;- proc.time()[[3]]-tic

#estimate coefficients for twice as large penalties
new_coefficients &lt;- coef(fit, penalties=fit$penalties*2, X=Dat$Xctd, Y=Dat$Y)

#change some prior parameters and find penalties
gamma2 &lt;- fit$gamma; gamma2[1:3] &lt;- 1:3
new_penalties &lt;- penalties(fit, gamma=gamma2, Z=Z.all)
new_coefficients2 &lt;- coef(fit, penalties=new_penalties, X=Dat$Xctd, Y=Dat$Y)


</code></pre>

<hr>
<h2 id='createCon'>
Create a list of constraints for co-data weight estimation
</h2><span id='topic+createCon'></span>

<h3>Description</h3>

<p>Create a list of constraints to be used by <code><a href="#topic+ecpc">ecpc</a></code> in estimating G co-data weights. Combine constraints with p-splines to estimate shape-constrained functions, e.g. positive, monotone increasing and/or convex functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createCon(G, shape = "positive+monotone.i+convex")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createCon_+3A_g">G</code></td>
<td>

<p>Number of co-data weights that should be estimated subject to constraints. 
</p>
</td></tr>
<tr><td><code id="createCon_+3A_shape">shape</code></td>
<td>

<p>Common type of shapes, including &lsquo;positive&rsquo;, 'monotone.i' ('monotone.d') for monotonically increasing (decreasing), 'convex' ('concave'), or any combination thereof by attaching multiple with a '+' sign.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the form <code>list(M.ineq = M.ineq, b.ineq = b.ineq)</code> with the matrix M.ineq and vector b.ineq containing the inequality constraints corresponding to the given shape.
</p>


<h3>See Also</h3>

<p>The relation between the prior variance and co-data may be estimated with a shape-constrained spline, see <code><a href="#topic+createZforSplines">createZforSplines</a></code> and <code><a href="#topic+createS">createS</a></code> for creating a spline basis and difference penalty matrix for a co-data variable. See <code><a href="#topic+ecpc">ecpc</a></code> for an example.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#create constraints for positivity
Con1 &lt;- createCon(G=10, shape="positive") 
#create constraints for positive and monotonically increasing weights
Con2 &lt;- createCon(G=10, shape="positive+monotone.i")  

</code></pre>

<hr>
<h2 id='createGroupset'>
Create a group set (groups) of variables
</h2><span id='topic+createGroupset'></span>

<h3>Description</h3>

<p>Create a group set (groups) of variables for categorical co-data (factor, character or boolean input), or for continuous co-data (numeric). Continuous co-data is discretised in non-overlapping groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createGroupset(values,index=NULL,grsize=NULL,ngroup=10,
                decreasing=TRUE,uniform=FALSE,minGroupSize = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createGroupset_+3A_values">values</code></td>
<td>

<p>Factor, character or boolean vector for categorical co-data, or numeric vector for continuous co-data values.
</p>
</td></tr>
<tr><td><code id="createGroupset_+3A_index">index</code></td>
<td>

<p>Index of the covariates corresponding to the values supplied. Useful if part of the co-data is missing/seperated and only the non-missing/remaining part should be discretised.
</p>
</td></tr>
<tr><td><code id="createGroupset_+3A_grsize">grsize</code></td>
<td>

<p>Numeric. Size of the groups. Only relevant when <code>values</code> is a numeric vector and <code>uniform=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="createGroupset_+3A_ngroup">ngroup</code></td>
<td>

<p>Numeric. Number of the groups to create. Only relevant when <code>values</code> is a numeric vector and 
<code>grsize</code> is NOT specified.
</p>
</td></tr>
<tr><td><code id="createGroupset_+3A_decreasing">decreasing</code></td>
<td>

<p>Boolean. If <code>TRUE</code> then <code>values</code> is sorted in decreasing order.
</p>
</td></tr>
<tr><td><code id="createGroupset_+3A_uniform">uniform</code></td>
<td>

<p>Boolean. If <code>TRUE</code> the group sizes are as equal as possible.
</p>
</td></tr>
<tr><td><code id="createGroupset_+3A_mingroupsize">minGroupSize</code></td>
<td>

<p>Numeric. Minimum group size. Only relevant when <code>values</code> is a numeric vector and <code>uniform=FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is derived from <code>CreatePartition</code> from the <code>GRridge</code>-package, available on Bioconductor. Note that the function name and some variable names have been adapted to match terminology used in other functions in the <code>ecpc</code>-package.
</p>
<p>A convenience function to create group sets of variables from external information that is stored in <code>values</code>. If <code>values</code> is a factor then the levels of the factor define the groups. 
If <code>values</code> is a character vector then the unique names in the character vector define the groups.
If <code>values</code> is a Boolean vector then the group set consists of two groups for True and False.
If <code>values</code> is a numeric vector, then groups contain the variables corresponding to 
<code>grsize</code> consecutive values of <code>values</code>. Alternatively, the group size 
is determined automatically from <code>ngroup</code>. If <code>uniform=FALSE</code>, a group with rank $r$ is  
of approximate size <code>mingr*(r^f)</code>, where <code>f&gt;1</code> is determined such that the total number of groups equals <code>ngroup</code>.
Such unequal group sizes enable the use of fewer groups (and hence faster computations) while still maintaining a 
good &lsquo;resolution&rsquo; for the extreme values in <code>values</code>. About <code>decreasing</code>: if smaller values
mean &lsquo;less relevant&rsquo; (e.g. test statistics, absolute regression coefficients) use <code>decreasing=TRUE</code>, else use <code>decreasing=FALSE</code>, e.g. for p-values. If <code>index</code> is defined, then the group set will use these variable indices corresponding to the values. Useful if the group set should be made for a subset of all variables.
</p>


<h3>Value</h3>

<p>A list with elements that contain the indices of the variables belonging to each of the groups. 
</p>


<h3>Author(s)</h3>

<p>Mark A. van de Wiel
</p>


<h3>See Also</h3>

<p>Instead of discretising continuous co-data in a a fixed number of groups, they may be discretised adaptively to learn a discretisation that fits the data well, see: <code><a href="#topic+splitMedian">splitMedian</a></code>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#SOME EXAMPLES ON SMALL NR OF VARIABLES

#EXAMPLE 1: group set based on known gene signature (boolean vector)
genset &lt;- sapply(1:100,function(x) paste("Gene",x))
signature &lt;- sapply(seq(1,100,by=2),function(x) paste("Gene",x))
SignatureGroupset &lt;- createGroupset(genset%in%signature) #boolean vector

#EXAMPLE 2: group set based on factor variable
Genetype &lt;- factor(sapply(rep(1:4,25),function(x) paste("Type",x)))
TypeGroupset &lt;- createGroupset(Genetype)

#EXAMPLE 3: group set based on continuous variable, e.g. p-value
pvals &lt;- rbeta(100,1,4)

#Creating a group set of 10 equally-sized groups, corresponding to increasing p-values.
PvGroupset &lt;- createGroupset(pvals, decreasing=FALSE,uniform=TRUE,ngroup=10)

#Alternatively, create a group set of 5 unequally-sized groups,
#with minimal size at least 10. Group size
#increases with less relevant p-values.
# Recommended when nr of variables is large.
PvGroupset2 &lt;- createGroupset(pvals, decreasing=FALSE,uniform=FALSE,
                              ngroup=5,minGroupSize=10)

#EXAMPLE 4: group set based on subset of variables,
#e.g. p-values only available for 50 genes. 
genset &lt;- sapply(1:100,function(x) paste("Gene",x))
subsetgenes &lt;- sort(sapply(sample(1:100,50),function(x) paste("Gene",x)))
index &lt;- which(genset%in%subsetgenes)

pvals50 &lt;- rbeta(50,1,6)

#Returns the group set for the subset based on the indices of 
#the variables in entire genset. 

PvGroupsetSubset &lt;- createGroupset(pvals50, index=index,
                                   decreasing=FALSE,uniform=TRUE, ngroup=5)
#append list with group containing the covariate indices for missing p-values
PvGroupsetSubset &lt;- c(PvGroupsetSubset,
                      list("missing"=which(!(genset%in%subsetgenes))))

#EXAMPLE 5: COMBINING GROUP SETS

#Combines group sets into one list with named components. 
#This can be used as input for the ecpc() function.

GroupsetsAll &lt;- list(signature=SignatureGroupset, type = TypeGroupset,
                     pval = PvGroupset, pvalsubset=PvGroupsetSubset)
               
#NOTE: if one aims to use one group set only, then this should also be
# provided in a list as input for the ecpc() function.

GroupsetsOne &lt;- list(signature=SignatureGroupset)

</code></pre>

<hr>
<h2 id='createS'>
Create a generalised penalty matrix
</h2><span id='topic+createS'></span>

<h3>Description</h3>

<p>Create a generalised penalty matrix which can be used as hypershrinkage for 
co-data matrix Z. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createS(orderPen=2, G=10, categorical=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createS_+3A_orderpen">orderPen</code></td>
<td>

<p>The order of the difference penalty. If 0, then a ridge penalty matrix is returned.
</p>
</td></tr>
<tr><td><code id="createS_+3A_g">G</code></td>
<td>

<p>Number of co-data variables to be penalised.
</p>
</td></tr>
<tr><td><code id="createS_+3A_categorical">categorical</code></td>
<td>

<p>If TRUE, a block correlation matrix is returned.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (GxG)-dimensional penalty matrix.
</p>


<h3>References</h3>

<p>See for an introduction on p-splines and difference penalties:
</p>
<p>Eilers, P. H., &amp; Marx, B. D. (2021). Practical Smoothing: The Joys of P-splines. Cambridge University Press.
</p>


<h3>See Also</h3>

<p>A difference penalty may be applied for p-spline basis functions created with <code><a href="#topic+createZforSplines">createZforSplines</a></code> or for categorical co-data created with <code><a href="#topic+createZforGroupset">createZforGroupset</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>S1 &lt;- createS(orderPen=2,G=10) #second difference penalty matrix
S2 &lt;- createS(orderPen=0,G=10) #zeroth order defined as ridge penalty matrix
S3 &lt;- createS(G=10,categorical=TRUE) #difference penalty for unordered categorical groups
</code></pre>

<hr>
<h2 id='createZforGroupset'>
Create a co-data matrix Z for a group set
</h2><span id='topic+createZforGroupset'></span>

<h3>Description</h3>

<p>Create a co-data matrix Z for a group set as obtained for instance with <a href="#topic+createGroupset">createGroupset</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createZforGroupset(groupset,p=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createZforGroupset_+3A_groupset">groupset</code></td>
<td>

<p>A list with G elements that contain the indices of the variables belonging to each of the groups.
</p>
</td></tr>
<tr><td><code id="createZforGroupset_+3A_p">p</code></td>
<td>

<p>Number of covariates in total. If not given, taken as maximum index in &lsquo;groupset&rsquo;. But in cases where some covariates are left unpenalised, the total number of covariates may be larger.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (pxG)-dimensional co-data matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+createGroupset">createGroupset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Group set: G random groups
G &lt;- 5 #number of groups
p &lt;- 300 #number of covariates from which last 10 left unpenalised
#sample random categorical co-data:
categoricalRandom &lt;- as.factor(sample(1:G,(p-10),TRUE))
#make group set, i.e. list with G groups
groupsetRandom &lt;- createGroupset(categoricalRandom)
Zcat &lt;- createZforGroupset(groupsetRandom,p=p)
</code></pre>

<hr>
<h2 id='createZforSplines'>
Create a co-data matrix Z of splines 
</h2><span id='topic+createZforSplines'></span>

<h3>Description</h3>

<p>Create a co-data matrix Z of spline basis functions for a continuous co-data variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createZforSplines(values, G=10, bdeg=3, index=NULL, p=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createZforSplines_+3A_values">values</code></td>
<td>

<p>A vector with continuous co-data values.
</p>
</td></tr>
<tr><td><code id="createZforSplines_+3A_g">G</code></td>
<td>

<p>Number of B-splines.
</p>
</td></tr>
<tr><td><code id="createZforSplines_+3A_bdeg">bdeg</code></td>
<td>

<p>Degree of the B-spline basis functions.
</p>
</td></tr>
<tr><td><code id="createZforSplines_+3A_index">index</code></td>
<td>

<p>Index of the covariates corresponding to the values supplied. Useful when 
part of the co-data is missing/seperated and only the non-missing/remaining 
part should be modelled with splines.
</p>
</td></tr>
<tr><td><code id="createZforSplines_+3A_p">p</code></td>
<td>

<p>Number of covariates in total. If not given, taken as length of &lsquo;values&rsquo;. But in cases where some covariates are left unpenalised, the total number of covariates may be larger.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (pxG)-dimensional co-data matrix.
</p>


<h3>References</h3>

<p>See for an introduction on p-splines:
</p>
<p>Eilers, P. H., &amp; Marx, B. D. (2021). Practical Smoothing: The Joys of P-splines. Cambridge University Press.
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+createS">createS</a></code> to create a difference penalty for p-splines.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#create co-data with random normally distributed values for 100 covariates
values &lt;- rnorm(n=100)
#suppose that there is one additional covariate (the first) that should not be modelled
ind &lt;- 2:101
p&lt;-101
Z &lt;- createZforSplines(values=values,G=10,index=ind,p=p)
</code></pre>

<hr>
<h2 id='cv.ecpc'>
Cross-validation for 'ecpc'
</h2><span id='topic+cv.ecpc'></span>

<h3>Description</h3>

<p>Cross-validates 'ecpc' and returns model fit, summary statistics and cross-validated performance measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.ecpc(Y,X,type.measure=c("MSE","AUC"),outerfolds=10,
        lambdas=NULL,ncores=1,balance=TRUE,silent=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.ecpc_+3A_y">Y</code></td>
<td>

<p>Response data; n-dimensional vector (n: number of samples) for linear and logistic outcomes, or <code><a href="survival.html#topic+Surv">Surv</a></code> object for Cox survival.
</p>
</td></tr>
<tr><td><code id="cv.ecpc_+3A_x">X</code></td>
<td>

<p>Observed data; (nxp)-dimensional matrix (p: number of covariates) with each row the observed high-dimensional feature vector of a sample.
</p>
</td></tr>
<tr><td><code id="cv.ecpc_+3A_type.measure">type.measure</code></td>
<td>

<p>Type of cross-validated performance measure returned.
</p>
</td></tr>
<tr><td><code id="cv.ecpc_+3A_outerfolds">outerfolds</code></td>
<td>

<p>Number of cross-validation folds.
</p>
</td></tr>
<tr><td><code id="cv.ecpc_+3A_lambdas">lambdas</code></td>
<td>

<p>A vector of global ridge penalties for each fold; may be given, else estimated.
</p>
</td></tr>
<tr><td><code id="cv.ecpc_+3A_ncores">ncores</code></td>
<td>

<p>Number of cores; if larger than 1, the outer cross-validation folds are processed in parallel over 'ncores' clusters.
</p>
</td></tr>
<tr><td><code id="cv.ecpc_+3A_balance">balance</code></td>
<td>

<p>(logistic, Cox) Should folds be balanced in response?
</p>
</td></tr>
<tr><td><code id="cv.ecpc_+3A_silent">silent</code></td>
<td>

<p>Should output messages be suppressed (default FALSE)?
</p>
</td></tr>
<tr><td><code id="cv.ecpc_+3A_...">...</code></td>
<td>

<p>Additional arguments used in <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>ecpc.fit</code></td>
<td>
<p>List with the ecpc model fit in each fold.</p>
</td></tr>
<tr><td><code>dfPred</code></td>
<td>
<p>Data frame with information about out-of-bag predictions.</p>
</td></tr>
<tr><td><code>dfGrps</code></td>
<td>
<p>Data frame with information about estimated group and group set weights across folds.</p>
</td></tr>
<tr><td><code>dfCVM</code></td>
<td>
<p>Data frame with cross-validated performance metric.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Visualise cross-validated group set weights with <code><a href="#topic+visualiseGroupsetweights">visualiseGroupsetweights</a></code> or group weights with <code><a href="#topic+visualiseGroupweights">visualiseGroupweights</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#####################
# Simulate toy data #
#####################
p&lt;-300 #number of covariates
n&lt;-100 #sample size training data set
n2&lt;-100 #sample size test data set

#simulate all betas i.i.d. from beta_k~N(mean=0,sd=sqrt(0.1)):
muBeta&lt;-0 #prior mean
varBeta&lt;-0.1 #prior variance
indT1&lt;-rep(1,p) #vector with group numbers all 1 (all simulated from same normal distribution)

#simulate test and training data sets:
Dat&lt;-simDat(n,p,n2,muBeta,varBeta,indT1,sigma=1,model='linear') 
str(Dat) #Dat contains centered observed data, response data and regression coefficients

##########################
# Make co-data group sets #
##########################
#Group set: G random groups
G &lt;- 5 #number of groups
#sample random categorical co-data:
categoricalRandom &lt;- as.factor(sample(1:G,p,TRUE))
#make group set, i.e. list with G groups:
groupsetRandom &lt;- createGroupset(categoricalRandom)

#######################
# Cross-validate ecpc #
#######################
tic&lt;-proc.time()[[3]]
cv.fit &lt;- cv.ecpc(type.measure="MSE",outerfolds=2,
                  Y=Dat$Y,X=Dat$Xctd,
                  groupsets=list(groupsetRandom),
                  groupsets.grouplvl=list(NULL),
                  hypershrinkage=c("none"),
                  model="linear",maxsel=c(5,10,15,20))
toc &lt;- proc.time()[[3]]-tic

str(cv.fit$ecpc.fit) #list containing the model fits on the folds
str(cv.fit$dfPred) #data frame containing information on the predictions
cv.fit$dfCVM #data frame with the cross-validated performance for ecpc
#with/without posterior selection and ordinary ridge



</code></pre>

<hr>
<h2 id='ecpc'>
Fit adaptive multi-group ridge GLM with hypershrinkage
</h2><span id='topic+ecpc'></span>

<h3>Description</h3>

<p>Fits a generalised linear (linear, logistic) or Cox survival model, penalised with adaptive co-data learnt ridge penalties.
The ridge penalties correspond to normal prior variances which are regressed on (multiple) co-data sources, e.g. for categorical co-data, each group of variables obtains a group-specific ridge penalty. 
Co-data weights are estimated with an empirical Bayes method of moments, penalised with an extra level of hypershrinkage and possibly constrained by linear constraints.
Various types of hypershrinkage may be used for various co-data, including overlapping groups, hierarchical groups and continuous co-data.
P-splines may be used to estimate the relation between the prior variance and continuous co-data variables. This may be combined with linear constraints to estimate shape-constrained functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecpc(Y, X,
Z=NULL, paraPen=NULL, paraCon=NULL, intrcpt.bam=TRUE, bam.method="ML",
groupsets=NULL, groupsets.grouplvl = NULL, hypershrinkage=NULL, 
unpen = NULL, intrcpt = TRUE, model=c("linear","logistic","cox"), 
postselection = "elnet,dense", maxsel = 10,
lambda = NULL, fold = 10, sigmasq = NaN, w = NULL,
nsplits = 100, weights = TRUE, profplotRSS = FALSE, Y2 = NULL, X2 = NULL,
compare = TRUE, mu = FALSE, normalise = FALSE, silent = FALSE,
datablocks = NULL, est_beta_method=c("glmnet","multiridge"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecpc_+3A_y">Y</code></td>
<td>

<p>Response data; n-dimensional vector (n: number of samples) for linear and logistic outcomes, or <code><a href="survival.html#topic+Surv">Surv</a></code> object for Cox survival.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_x">X</code></td>
<td>

<p>Observed data; (nxp)-dimensional matrix (p: number of covariates) with each row the observed high-dimensional feature vector of a sample.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_z">Z</code></td>
<td>

<p>List with m co-data matrices. Each element is a (pxG)-dimensional co-data matrix containing co-data on the p   variables. Co-data should either be provided in &lsquo;Z&rsquo; or &lsquo;groupsets&rsquo;. 
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_parapen">paraPen</code></td>
<td>

<p>A list with generalised ridge penalty matrices used as hypershrinkage in estimating co-data weights, e.g. <code>list("Z2" = list("S1" = M1,"S2"= M2))</code> when the second co-data source given in &lsquo;Z&rsquo; should be penalised by a penalty matrix &lsquo;M1&rsquo; and &lsquo;M2&rsquo;. The names of the elements of the list should  be equal to &lsquo;Zi&rsquo; where &lsquo;i&rsquo; matches the index of the co-data matrix. The list elements should again be lists with elements &lsquo;Si&rsquo; for i=1,2,.. different generalised ridge penalty matrices. 
Same as the argument &lsquo;paraPen&rsquo; used in <code>bam</code> of &lsquo;mgcv&rsquo;.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_paracon">paraCon</code></td>
<td>

<p>A list with linear inequality and or equality constraints used in estimating co-data weights, e.g. <code>list("Z2" = list("M.ineq" = M1,"b.ineq"= b.ineq, "M.eq" = M2,"b.eq"= b.eq))</code>.
The names of the elements of the list should  be equal to &lsquo;Zi&rsquo; where &lsquo;i&rsquo; matches the index of the co-data matrix. The list elements should again be lists with elements &lsquo;M.ineq&rsquo;, &lsquo;b.ineq&rsquo; for inequality constraints and &lsquo;M.eq&rsquo;, &lsquo;b.eq&rsquo; for equality constraints, similar to the arguments used in <code>lsqlincon</code> of &lsquo;pracma&rsquo;.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_intrcpt.bam">intrcpt.bam</code></td>
<td>

<p>Should an intercept be included in the co-data model?
Is used only when &lsquo;Z&rsquo; is provided, for which the function <code>bam</code> of &lsquo;mgcv&rsquo; is used to fit a generalised additive model. 
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_bam.method">bam.method</code></td>
<td>

<p>When &lsquo;Z&rsquo; is provided, &lsquo;bam.method&rsquo; indicates the method used in <code>bam</code> of &lsquo;mgcv&rsquo; to estimate the hyperpenalties corresponding to the generalised ridge penalty matrices given in &lsquo;paraPen&rsquo;.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_groupsets">groupsets</code></td>
<td>

<p>Co-data group sets; list with m (m: number of group sets) group sets. Each group set is a list of all groups in that set. Each group is a vector containing the indices of the covariates in that group.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_groupsets.grouplvl">groupsets.grouplvl</code></td>
<td>

<p>(optional) Group sets on group level used in hypershrinkage; list of m elements (corresponding to 'groupsets'), with NULL if there is no structure on group level, or with a list of groups containing the indices of groups of covariates in that group. May be used for hierarchical groups and to adaptively discretise continuous co-data, see <code><a href="#topic+obtainHierarchy">obtainHierarchy</a></code>.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_hypershrinkage">hypershrinkage</code></td>
<td>

<p>Type of shrinkage that is used on the group level; vector of m strings indicating the shrinkage type (or penalty) that is used for each of the m group sets. String may be of the simple form &quot;type1&quot;, or &quot;type1,type2&quot;, in which type1 is used to select groups and type2 to estimate the group weights of the selected groups. Possible hypershrinkage types are:
</p>
<p>c(&quot;none&quot;,&quot;ridge&quot;,&quot;lasso&quot;,&quot;hierLasso&quot;,&quot;lasso,ridge&quot;,&quot;hierLasso,ridge&quot;); 
</p>
<p>&quot;none&quot; for no hypershrinkage, &quot;ridge&quot; (default), &quot;lasso&quot; and &quot;hierLasso&quot; (hierarchical lasso using a latent overlapping group lasso penalty) for group selection possibly be combined with ridge shrinkage.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_unpen">unpen</code></td>
<td>

<p>Unpenalised covariates; vector with indices of covariates that should not be penalised.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_intrcpt">intrcpt</code></td>
<td>

<p>Should an intercept be included? Included by default for linear and logistic, excluded for Cox for which the baseline hazard is estimated.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_model">model</code></td>
<td>

<p>Type of model for the response; linear, logistic or cox.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_postselection">postselection</code></td>
<td>

<p>Type of posterior selection method used to obtain a parsimonious model of maxsel covariates, or FALSE if no parsimonious model is needed. Possible options are &quot;elnet,dense&quot; (default), &quot;elnet,sparse&quot;, &quot;BRmarginal,dense&quot;, &quot;BRmarginal,sparse&quot; or &quot;DSS&quot;.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_maxsel">maxsel</code></td>
<td>

<p>Maximum number of covariates to be selected a posteriori, in addition to all unpenalised covariates. If maxsel is a vector, multiple parsimonious models are returned.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_lambda">lambda</code></td>
<td>

<p>Global ridge penalty; if given, numeric value to fix the global ridge penalty and equivalently, the global prior variance. When not given, for linear, by default &quot;ML&quot; is used for estimation for maximum marginal likelihood estimation and &quot;CV&quot; for other models for cross-validation.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_fold">fold</code></td>
<td>

<p>Number of folds used in inner cross-validation to estimate global ridge penalty lambda.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_sigmasq">sigmasq</code></td>
<td>

<p>(linear model only) If given, noise level is fixed (Y~N(X*beta,sd=sqrt(sigmasq))).
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_w">w</code></td>
<td>

<p>Group set weights: m-dimensional vector. If given, group set weights are fixed.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_nsplits">nsplits</code></td>
<td>

<p>Number of splits used in the Residual Sum of Squares (RSS) criterion to estimate the optimal hyperlambda.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_weights">weights</code></td>
<td>

<p>Should weights be used in hypershrinkage to correct for group size (default TRUE)?
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_profplotrss">profplotRSS</code></td>
<td>

<p>Should a profile plot of the residual sum of squares (RSS) criterium be shown?
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_y2">Y2</code></td>
<td>

<p>(optional) Independent response data to compare with predicted response.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_x2">X2</code></td>
<td>

<p>(optional) Independent observed data for which response is predicted.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_compare">compare</code></td>
<td>

<p>Should an ordinary ridge model be fitted to compare with?
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_mu">mu</code></td>
<td>

<p>Should group prior means be included (default FALSE)?
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_normalise">normalise</code></td>
<td>

<p>Should group variances be normalised to sum to 1 (default FALSE)?
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_silent">silent</code></td>
<td>

<p>Should output messages be suppressed (default FALSE)?
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_datablocks">datablocks</code></td>
<td>

<p>(optional) for multiple data types, the corresponding blocks of data may be given in datablocks; a list of B vectors of the indices of covariates in &lsquo;X&rsquo; that belong to each of the B data blocks. Unpenalised covariates should not be given as seperate block, but can be omitted or included in blocks with penalised covariates. Each datatype obtains a datatype-specific &lsquo;tauglobal&rsquo; as in multiridge.
</p>
</td></tr>
<tr><td><code id="ecpc_+3A_est_beta_method">est_beta_method</code></td>
<td>

<p>Package used for estimating regression coefficients, either &quot;glmnet&quot; or &quot;multiridge&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Model:</strong>
</p>
<p>The response is modeled with a generalised linear model with variance <code class="reqn">Var(Y)=\sigma^2*V(Y)</code>. For the linear model, <code class="reqn">\sigma^2</code> is the error variance parameter. For the logistic and Cox model, <code class="reqn">\sigma^2=1</code>.
The regression coefficients are independently modeled with a normal prior with prior variance <code class="reqn">v</code> regressed on (possibly multiple sources of) co-data
</p>
<p style="text-align: center;"><code class="reqn">\beta~N(0,v),   v = \tau_global^2* sum_d [w_d*Z_d*\gamma_d]</code>
</p>

<p>with <code class="reqn">\tau_global^2</code> the global scaling parameter, the scalar <code class="reqn">w_d</code> the importance weight of co-data set <code class="reqn">d</code>, <code class="reqn">Z_d</code> the co-data matrix for source d and <code class="reqn">\gamma_d</code> the vector of co-data variable weights of source <code class="reqn">d</code>.
</p>
<p><strong>Co-data and hypershrinkage input:</strong>
</p>
<p>Co-data should be provided in a list of co-data matrices given in argument 'Z' or in a list of group sets given in 'groupsets'. The latter may be used only for (overlapping) groups of variables, whereas the first may be used for continuous co-data too. In most cases, providing co-data in 'Z' is faster, so users may want to transform co-data from a group set to a co-data matrix with <code><a href="#topic+createZforGroupset">createZforGroupset</a></code>. 
</p>
<p>The co-data variable weights are estimated with an extra level of hypershrinkage, i.e. with a penalised estimator (see below). The type of hypershrinkage may differ per co-data source. Providing these types depends on whether the co-data is provided in 'Z' or 'groupsets'. 
When co-data is provided in 'Z', the hypershrinkage may be provided in the arguments 'paraPen', 'paraCon', 'intrcpt.bam' and 'bam.method' (second line above in usage).
When co-data is provided in 'groupsets', the hypershrinkage may be provided in the arguments 'groupsets.grouplvl' and 'hypershrinkage' (third line above in usage).
</p>
<p><strong>Estimation:</strong>
</p>
<p>The regression coefficients are estimated by maximising the penalised likelihood (equiv. maximum a posteriori estimate) for estimated prior parameters:
</p>
<p style="text-align: center;"><code class="reqn">\beta' = argmax_\beta[ loglik + sum_k (\beta_k^2 / (2 v_k) ]</code>
</p>

<p>The prior parameters are estimated from the data using an empirical Bayes approach; <code class="reqn">\tau_global^2</code> is estimated by maximising the marginal likelihood (linear, default, jointly optimised with <code class="reqn">\sigma^2</code>) or by cross-validation (linear, logistic, Cox). 
<code class="reqn">\gamma_d</code> is estimated per co-data source by finding the minimum (penalised) least squares solution corresponding to the marginal moment equations:
</p>
<p style="text-align: center;"><code class="reqn">\gamma_d = argmin_\gamma[ ||A\gamma - b||_2^2 + f_pen(\gamma;\lambda_d)]</code>
</p>

<p>with <code class="reqn">f_pen</code> some penalty function ('hypershrinkage', see below) depending on hyperpenalty parameter <code class="reqn">\lambda_d</code>.
Co-data weights <code class="reqn">w</code> are estimated with a similar, unpenalised marginal moment estimator.
</p>
<p>'ecpc' is the first implementation of marginal moment estimation with the additional layer of hypershrinkage. Moment-based estimates without hypershrinkage have been implemented in the R-package 'GRridge'.
</p>
<p><strong>Hypershrinkage:</strong>
</p>
<p>For co-data provided in the argument 'Z', a generalised ridge penalty may be used of the type:
</p>
<p style="text-align: center;"><code class="reqn">\lambda_d*\gamma_d^T * S * \gamma_d</code>
</p>

<p>with the penalty matrix <code class="reqn">S</code> possibly a sum of multiple penalty matrices and given in argument 'paraPen'.
Additionally, linear (in)equality constraints may be added with the argument 'paraCon', i.e. the least squares estimate is subject to <code class="reqn">M_ineq*\gamma_d &lt;= b_ineq</code> and <code class="reqn">M_eq*\gamma_d = b_ineq</code>.
</p>
<p>For co-data provided in the argument 'groupsets', the types of hypershrinkage include the ridge penalty (<code class="reqn">\lambda_d*||\gamma||^2_2</code>), lasso penalty (<code class="reqn">\lambda_d*||\gamma||_1</code>) and hierarchical lasso penalty with hierarchy defined in 'groupsets.grouplvl'.
</p>


<h3>Value</h3>

<p>An object of the class &lsquo;ecpc&rsquo; with the following elements:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>Estimated regression coefficients; p-dimensional vector.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>If included, the estimated intercept; scalar.</p>
</td></tr>
<tr><td><code>tauglobal</code></td>
<td>
<p>Estimated global prior variance; scalar (or vector with datatype-specific global prior variances when multiple &lsquo;datablocks&rsquo; are given).)</p>
</td></tr>
<tr><td><code>gammatilde</code></td>
<td>
<p>Estimated group weights before truncating negative weights to 0; vector of dimension the total number of groups.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>Final estimated group weights; vector of dimension the total number of groups.</p>
</td></tr>
<tr><td><code>gamma0</code></td>
<td>
<p>Estimated co-data variable intercept; scalar.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>Estimated group set weights; m-dimensional vector.</p>
</td></tr>
<tr><td><code>penalties</code></td>
<td>
<p>Estimated multi-group ridge penalties; p-dimensional vector.</p>
</td></tr>
<tr><td><code>hyperlambdas</code></td>
<td>
<p>Estimated hyperpenalty parameters used in hypershrinkage; m-dimensional vector.</p>
</td></tr>
<tr><td><code>Ypred</code></td>
<td>
<p>If independent test set 'X2' is given, predictions for the test set.</p>
</td></tr>
<tr><td><code>MSEecpc</code></td>
<td>
<p>If independent test set 'X2', 'Y2' is given, mean squared error of the predictions.</p>
</td></tr>
<tr><td><code>sigmahat</code></td>
<td>
<p>(linear model) Estimated sigma^2.</p>
</td></tr>
</table>
<p>If 'compare'=TRUE, ordinary ridge estimates and predictions are given. If in addition multiple &lsquo;datablocks&rsquo; are given, the estimates and predictions for multiridge penalty are given;
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>Type of model fitted for the response; linear, logistic or cox.</p>
</td></tr>
<tr><td><code>betaridge</code></td>
<td>
<p>Estimated regression coefficients for ordinary ridge (or multiridge) penalty.</p>
</td></tr>
<tr><td><code>interceptridge</code></td>
<td>
<p>Estimated intercept for ordinary ridge (or multiridge) penalty.</p>
</td></tr>
<tr><td><code>lambdaridge</code></td>
<td>
<p>Estimated (multi)ridge penalty.</p>
</td></tr>
<tr><td><code>Ypredridge</code></td>
<td>
<p>If independent test set 'X2' is given, ordinary ridge (or multiridge) predictions for the test set.</p>
</td></tr>
<tr><td><code>MSEridge</code></td>
<td>
<p>If independent test set 'X2', 'Y2' is given, mean squared error of the ordinary ridge (or multiridge) predictions.</p>
</td></tr>
</table>
<p>If posterior selection is performed;
</p>
<table>
<tr><td><code>betaPost</code></td>
<td>
<p>Estimated regression coefficients for parsimonious models. If 'maxsel' is a vector, 'betaPost' is a matrix with each column the vector estimate corresponding to the maximum number of selected covariates given in 'maxsel'.</p>
</td></tr>
<tr><td><code>interceptPost</code></td>
<td>
<p>Estimated intercept coefficient for parsimonious models.</p>
</td></tr>
<tr><td><code>YpredPost</code></td>
<td>
<p>If independent test set 'X2' is given, posterior selection model predictions for the test set.</p>
</td></tr>
<tr><td><code>MSEPost</code></td>
<td>
<p>If independent test set 'X2', 'Y2' is given, mean squared error of the posterior selection model predictions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mirrelijn van Nee, Lodewyk Wessels, Mark van de Wiel
</p>


<h3>References</h3>

<p>van Nee, Mirrelijn M., Lodewyk FA Wessels, and Mark A. van de Wiel. &quot;Flexible co-data learning for high-dimensional prediction.&quot; Statistics in medicine 40.26 (2021): 5910-5925.
</p>
<p>van de Wiel, Mark A., Mirrelijn M. van Nee, and Armin Rauschenberger. &quot;Fast cross-validation for multi-penalty high-dimensional ridge regression.&quot; Journal of Computational and Graphical Statistics 30.4 (2021): 835-847.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
#####################
# Simulate toy data #
#####################
p&lt;-300 #number of covariates
n&lt;-100 #sample size training data set
n2&lt;-100 #sample size test data set

#simulate all betas i.i.d. from beta_k~N(mean=0,sd=sqrt(0.1)):
muBeta&lt;-0 #prior mean
varBeta&lt;-0.1 #prior variance
indT1&lt;-rep(1,p) #vector with group numbers all 1 (all simulated from same normal distribution)

#simulate test and training data sets:
Dat&lt;-simDat(n,p,n2,muBeta,varBeta,indT1,sigma=1,model='linear') 
str(Dat) #Dat contains centered observed data, response data and regression coefficients

###################################
# Provide co-data in group sets.. #
###################################
#Group set 1: G random groups
G &lt;- 5 #number of groups
#sample random categorical co-data:
categoricalRandom &lt;- as.factor(sample(1:G,p,TRUE))
#make group set, i.e. list with G groups:
groupsetRandom &lt;- createGroupset(categoricalRandom)

#Group set 2: informative hierarchical group set
continuousCodata &lt;- abs(Dat$beta) #use the magnitude of beta as continuous co-data
#Use adaptive discretisation to find a good discretisation of the continuous co-data;
# discretise in groups of covariates of various sizes:
groupsetHierarchical &lt;- splitMedian(values=continuousCodata,index = 1:p,
                        minGroupSize = 50,split="both") 
# and obtain group set on group level that defines the hierarchy:
hierarchy.grouplevel &lt;- obtainHierarchy(groupset = groupsetHierarchical) 
#visualise hierarchical groups:
#visualiseGroupset(Groupset = groupsetHierarchical,groupset.grouplvl = hierarchy.grouplevel) 

############################
# ..or in co-data matrices #
############################
#Setting 1: some transformations of informative, continuous co-data
Z1 &lt;- cbind(continuousCodata,sqrt(continuousCodata))

#setting 2: splines for informative continuous
Z2 &lt;- createZforSplines(values=continuousCodata)
S1.Z2 &lt;- createS(orderPen=2, G=dim(Z2)[2]) #create difference penalty matrix
Con2 &lt;- createCon(G=dim(Z2)[2], shape="positive+monotone.i") #create constraints

#setting 3: 5 random groups
Z3 &lt;- createZforGroupset(groupsetRandom,p=p)
S1.Z3 &lt;- createS(G=G, categorical = TRUE) #create difference penalty matrix
Con3 &lt;- createCon(G=dim(Z3)[2], shape="positive") #create constraints


############################
# Fit ecpc on group sets.. #
############################

#fit ecpc for the two group sets, with ridge hypershrinkage for group set 1, 
# and hierarchical lasso and ridge for group set 2.
tic&lt;-proc.time()[[3]]
fit &lt;- ecpc(Y=Dat$Y,X=Dat$Xctd,groupsets=list(groupsetRandom,groupsetHierarchical),
           groupsets.grouplvl=list(NULL,hierarchy.grouplevel),
           hypershrinkage=c("ridge","hierLasso,ridge"),
           model="linear",maxsel=c(5,10,15,20),
           Y2=Dat$Y2,X2=Dat$X2ctd)
toc &lt;- proc.time()[[3]]-tic

fit$tauglobal #estimated global prior variance
fit$gamma #estimated group weights (concatenated for the group sets)
fit$w #estimated group set weights
summary(fit$beta) #estimated regression coefficients
summary(fit$betaPost) #estimated regression coefficients after posterior selection

c(fit$MSEecpc,fit$MSEridge) #mean squared error on test set for ecpc and ordinary ridge
fit$MSEPost #MSE on the test set of ecpc after posterior selection

############################
# ..or on co-data matrices #
############################

#fit ecpc for the three co-data matrices with following penalty matrices and constraints
#note: can also be fitted without paraPen and/or paraCon
Z.all &lt;- list(Z1=Z1,Z2=Z2,Z3=Z3)
paraPen.all &lt;- list(Z2=list(S1=S1.Z2), Z3=list(S1=S1.Z3))
paraCon &lt;- list(Z2=Con2, Z3=Con3)

tic&lt;-proc.time()[[3]]
fit &lt;- ecpc(Y=Dat$Y,X=Dat$Xctd,
           Z = Z.all, paraPen = paraPen.all, paraCon = paraCon,
           model="linear",maxsel=c(5,10,15,20),
           Y2=Dat$Y2,X2=Dat$X2ctd)
toc &lt;- proc.time()[[3]]-tic

fit$tauglobal #estimated global prior variance
fit$gamma #estimated group weights (concatenated for the co-data sources)
fit$gamma0 #estimated co-data intercept

#plot contribution of one co-data source
i &lt;-1
groupsetNO &lt;- c(unlist(sapply(1:length(Z.all),function(i) rep(i,dim(Z.all[[i]])[2]))))
vk &lt;- as.vector(Z.all[[i]]%*%fit$gamma[groupsetNO==i])*fit$tauglobal
plot(continuousCodata,vk)

summary(fit$beta) #estimated regression coefficients
summary(fit$betaPost) #estimated regression coefficients after posterior selection

c(fit$MSEecpc,fit$MSEridge) #mean squared error on test set for ecpc and ordinary ridge
fit$MSEPost #MSE on the test set of ecpc after posterior selection

###################################
# Fit ecpc for multiple datatypes #
###################################
rankBeta&lt;-order(abs(Dat$beta)) #betas ranked in order of magnitude
 
#with multiple datatypes (given in datablocks) and informative groups
fit2 &lt;- ecpc(Y=Dat$Y,X=Dat$Xctd[,rankBeta],groupsets=list(list(1:75,76:150,151:225,226:300)),
            groupsets.grouplvl=list(NULL),
            hypershrinkage=c("none"),
            model="linear",maxsel=c(5,10,15,20),
            Y2=Dat$Y2,X2=Dat$X2ctd[,rankBeta],
            datablocks = list(1:floor(p/2),(floor(p/2)+1):p))


</code></pre>

<hr>
<h2 id='hierarchicalLasso'>
Fit hierarchical lasso using LOG penalty
</h2><span id='topic+hierarchicalLasso'></span>

<h3>Description</h3>

<p>Fits a linear regression model penalised with a hierarchical lasso penalty, using a latent overlapping group (LOG) lasso penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierarchicalLasso(X, Y, groupset, lambda=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hierarchicalLasso_+3A_x">X</code></td>
<td>

<p>nxp matrix with observed data
</p>
</td></tr>
<tr><td><code id="hierarchicalLasso_+3A_y">Y</code></td>
<td>

<p>nx1 vector with response data
</p>
</td></tr>
<tr><td><code id="hierarchicalLasso_+3A_groupset">groupset</code></td>
<td>

<p>list with hierarchical group indices
</p>
</td></tr>
<tr><td><code id="hierarchicalLasso_+3A_lambda">lambda</code></td>
<td>

<p>Scalar. Penalty parameter for the latent overlapping group penalty.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The LOG penalty can be used to impose hierarchical constraints in the estimation of regression coefficients (Yan, Bien et al. 2007), e.g. a group of covariates (child node in the hierarchical tree) may be selected only if another group is selected (parent node in the hierarchical tree).
This function uses the simple implementation for the LOG penalty described in (Jacob, Obozinski and Vert, 2009). Faster and more scalable algorithms may be available but not yet used in this pacakage.
</p>


<h3>Value</h3>

<p>A list with the following elements;
</p>
<table>
<tr><td><code>betas</code></td>
<td>
<p>Estimated regression coefficients.</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>Estimated intercept.</p>
</td></tr>
<tr><td><code>lambdarange</code></td>
<td>
<p>Range of penalty parameter used for CV (if lambda was not given).</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Estimated penalty parameter.</p>
</td></tr>
<tr><td><code>group.weights</code></td>
<td>
<p>Fixed group weights used in the LOG-penalty.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yan, X., Bien, J. et al. (2017). Hierarchical sparse modeling: A choice of two group lasso formulations. Statistical Science 32 531-560.
</p>
<p>Jacob, L., Obozinski, G. and Vert, J.-P. (2009). Group lasso with overlap and graph lasso. In: Proceedings of the 26th annual international conference on machine learning 433-440. ACM.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate toy data 
p&lt;-60 #number of covariates
n&lt;-30 #sample size training data set
n2&lt;-100 #sample size test data set

#simulate all betas i.i.d. from beta_k~N(mean=0,sd=sqrt(0.1)):
muBeta&lt;-c(0,0) #prior mean
varBeta&lt;-c(0.0001,0.1) #prior variance
#vector with group numbers all 1 (all simulated from same normal distribution)
indT1&lt;-rep(c(1,2),each=p/2)

#simulate test and training data sets:
Dat&lt;-simDat(n,p,n2,muBeta,varBeta,indT1,sigma=1,model='linear')
str(Dat) #Dat contains centered observed data, response data and regression coefficients

#hierarchical grouping: e.g. covariates (p/4+1):(p/2) can only be selected when
#covariates 1:(p/4) are selected
groupset &lt;- list(1:(p/2),(p/2+1):p,1:(p/4),(3*p/4+1):p)

#Fit hierarchical lasso, perform CV to find optimal lambda penalty
res &lt;- hierarchicalLasso(X=Dat$Xctd,Y=Dat$Y,groupset = groupset )
res$lambdarange
plot(res$betas)

#Fit hierarchical lasso for fixed lambda
res2 &lt;- hierarchicalLasso(X=Dat$Xctd,Y=Dat$Y,groupset = groupset,lambda=res$lambdarange[2] )
plot(res2$betas)
</code></pre>

<hr>
<h2 id='obtainHierarchy'>
Obtain hierarchy
</h2><span id='topic+obtainHierarchy'></span>

<h3>Description</h3>

<p>This function obtains the group set on group level that defines the hierarchy;
if a group of covariates g is a subset of group h, then group h is an ancestor of group g (higher up in the hierarchy).
This hierarchy is used in adaptively discretising continuous co-data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obtainHierarchy(groupset, penalty = "LOG")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="obtainHierarchy_+3A_groupset">groupset</code></td>
<td>

<p>Group set of groups of covariates with nested groups.
</p>
</td></tr>
<tr><td><code id="obtainHierarchy_+3A_penalty">penalty</code></td>
<td>

<p>Default: &quot;LOG&quot; for a latent overlapping group approach (currently the only option in ecpc)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We use the latent overlapping group (LOG) lasso penalty to define the hierarchical constraints as described in (Yan, Bien et al. 2007);
for each group g of covariates, we make a group on group level with group number g and the group numbers of its ancestors in the hierarchical tree. 
This way, group g can be selected if and only if all its ancestors are selected.
This function assumes that if group g is a subset of group h, then group h is an ancestor of group g. 
Note that this assumption does not necessarily hold for all hierarchies. The group set on group level should then be coded manually.
</p>


<h3>Value</h3>

<p>A group set on group level defining the hierarchy.
</p>


<h3>References</h3>

<p>Yan, X., Bien, J. et al. (2017). Hierarchical sparse modeling: A choice of two group lasso formulations. Statistical Science 32 531-560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+splitMedian">splitMedian</a></code> to obtain a group set of nested groups for continuous co-data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cont.codata &lt;- seq(0,1,length.out=20) #continuous co-data
#only split at lower continous co-data group
groupset &lt;- splitMedian(values=cont.codata,split="lower",minGroupSize=5) 
#obtain groups on group level defining the hierarchy
groupset.grouplvl &lt;- obtainHierarchy(groupset) 

</code></pre>

<hr>
<h2 id='plot.ecpc'>
Plot an 'ecpc' object
</h2><span id='topic+plot.ecpc'></span>

<h3>Description</h3>

<p>Make a plot of the fitted regression coefficients versus their corresponding fitted
prior variances, or fit the prior variance weight contribution of each co-data source.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ecpc'
plot(x, show = c("coefficients", "priorweights"), 
     Z = NULL, values = NULL, groupsets = NULL,
     codataweights=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ecpc_+3A_x">x</code></td>
<td>

<p>An 'ecpc' object returned by <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.ecpc_+3A_show">show</code></td>
<td>

<p>Either &quot;coefficients&quot; or &quot;priorweights&quot; to show the fitted regression coefficients
or the prior variances. To plot the prior variances, co-data should be provided 
in either 'Z' or 'groupsets'.
</p>
</td></tr>
<tr><td><code id="plot.ecpc_+3A_z">Z</code></td>
<td>

<p>List of m co-data matrices, as in <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.ecpc_+3A_values">values</code></td>
<td>

<p>List of m elements, containing p-dimensinal vectors with continuous co-data values or NULL.
If provided, the prior variances will be plotted versus the provided continuous co-data.
If NULL, the prior variances will be plotted per co-data variable.
</p>
</td></tr>
<tr><td><code id="plot.ecpc_+3A_groupsets">groupsets</code></td>
<td>

<p>Co-data provided as list of group sets, as in <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.ecpc_+3A_codataweights">codataweights</code></td>
<td>

<p>For the option &lsquo;show=&quot;priorweights&quot;&rsquo;, should the prior variances include the co-data source weights?
</p>
</td></tr>
<tr><td><code id="plot.ecpc_+3A_...">...</code></td>
<td>
<p>...</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the packages &lsquo;ggplot2&rsquo; and &lsquo;ggpubr&rsquo; are installed, a &lsquo;ggplot&rsquo; object is shown and returned, else a base plot is shown.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+ecpc">ecpc</a></code> for model fitting.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
#####################
# Simulate toy data #
#####################
p&lt;-300 #number of covariates
n&lt;-100 #sample size training data set
n2&lt;-100 #sample size test data set

#simulate all betas i.i.d. from beta_k~N(mean=0,sd=sqrt(0.1)):
muBeta&lt;-0 #prior mean
varBeta&lt;-0.1 #prior variance
indT1&lt;-rep(1,p) #vector with group numbers all 1 (all simulated from same normal distribution)

#simulate test and training data sets:
Dat&lt;-simDat(n,p,n2,muBeta,varBeta,indT1,sigma=1,model='linear') 
str(Dat) #Dat contains centered observed data, response data and regression coefficients

###################
# Provide co-data #
###################
continuousCodata &lt;- abs(Dat$beta) 
Z1 &lt;- cbind(continuousCodata,sqrt(continuousCodata))

#setting 2: splines for informative continuous
Z2 &lt;- createZforSplines(values=continuousCodata)
S1.Z2 &lt;- createS(orderPen=2, G=dim(Z2)[2]) #create difference penalty matrix
Con2 &lt;- createCon(G=dim(Z2)[2], shape="positive+monotone.i") #create constraints

#setting 3: 5 random groups
G &lt;- 5
categoricalRandom &lt;- as.factor(sample(1:G,p,TRUE))
#make group set, i.e. list with G groups:
groupsetRandom &lt;- createGroupset(categoricalRandom)
Z3 &lt;- createZforGroupset(groupsetRandom,p=p)
S1.Z3 &lt;- createS(G=G, categorical = TRUE) #create difference penalty matrix
Con3 &lt;- createCon(G=dim(Z3)[2], shape="positive") #create constraints

#fit ecpc for the three co-data matrices with following penalty matrices and constraints
#note: can also be fitted without paraPen and/or paraCon
Z.all &lt;- list(Z1=Z1,Z2=Z2,Z3=Z3)
paraPen.all &lt;- list(Z2=list(S1=S1.Z2), Z3=list(S1=S1.Z3))
paraCon &lt;- list(Z2=Con2, Z3=Con3)

############
# Fit ecpc #
############
tic&lt;-proc.time()[[3]]
fit &lt;- ecpc(Y=Dat$Y,X=Dat$Xctd,
           Z = Z.all, paraPen = paraPen.all, paraCon = paraCon,
           model="linear",maxsel=c(5,10,15,20),
           Y2=Dat$Y2,X2=Dat$X2ctd)
toc &lt;- proc.time()[[3]]-tic

values &lt;- list(NULL, continuousCodata, NULL)

plot(fit, show="coefficients")
plot(fit, show="priorweights", Z=Z.all, values=values)


</code></pre>

<hr>
<h2 id='postSelect'>
Perform posterior selection
</h2><span id='topic+postSelect'></span>

<h3>Description</h3>

<p>Given data and estimated parameters from a previously fit multi-group ridge penalised model, perform posterior selection to find a parsimonious model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postSelect(object, X, Y, beta=NULL, intrcpt = 0, penfctr=NULL, 
           postselection = c("elnet,dense","elnet,sparse","BRmarginal,dense",
           "BRmarginal,sparse","DSS"), maxsel = 30, penalties=NULL, 
           model=c("linear","logistic","cox"), tauglobal=NULL, sigmahat = NULL, 
           muhatp = 0, X2 = NULL, Y2 = NULL, silent=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="postSelect_+3A_object">object</code></td>
<td>

<p>An 'ecpc' object returned by <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_x">X</code></td>
<td>

<p>Observed data: data of p penalised and unpenalised covariates on n samples; (nxp)-dimensional matrix.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_y">Y</code></td>
<td>

<p>Response data; n-dimensional vector (linear, logistic) or <code><a href="survival.html#topic+Surv">Surv</a></code> object (Cox survival).
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_beta">beta</code></td>
<td>

<p>Estimated regression coefficients from the previously fit model.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_intrcpt">intrcpt</code></td>
<td>

<p>Estimated intercept from the previously fit model.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_penfctr">penfctr</code></td>
<td>

<p>As in glmnet penalty.factor; p-dimensional vector with a 0 if covariate is not penalised, 1 if covariate is penalised.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_postselection">postselection</code></td>
<td>

<p>Posterior selection method to be used.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_maxsel">maxsel</code></td>
<td>

<p>Maximum number of covariates to be selected a posteriori, in addition to all unpenalised covariates. If maxsel is a vector, multiple parsimonious models are returned.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_penalties">penalties</code></td>
<td>

<p>Estimated multi-group ridge penalties for all penalised covariates from the previously fit model; vector of length the number of penalised covariates.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_model">model</code></td>
<td>

<p>Type of model for the response.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_tauglobal">tauglobal</code></td>
<td>

<p>Estimated global prior variance from the previously fit model.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_sigmahat">sigmahat</code></td>
<td>

<p>(linear model only) estimated variance parameter from the previously fit model.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_muhatp">muhatp</code></td>
<td>

<p>(optional) Estimated multi-group prior means for the penalised covariates from the previously fit model.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_x2">X2</code></td>
<td>

<p>(optional) Independent observed data.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_y2">Y2</code></td>
<td>

<p>(optional) Independent response data.
</p>
</td></tr>
<tr><td><code id="postSelect_+3A_silent">silent</code></td>
<td>

<p>Should output messages be suppressed (default FALSE)?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>betaPost</code></td>
<td>
<p>Estimated regression coefficients for parsimonious models. If 'maxsel' is a vector,
'betaPost' is a matrix with each column the vector estimate corresponding to the maximum number of 
selected covariates given in 'maxsel'.</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>Estimated intercept coefficient for parsimonious models.</p>
</td></tr>
<tr><td><code>YpredPost</code></td>
<td>
<p>If independent test set 'X2' is given, posterior selection model predictions for the test set.</p>
</td></tr>
<tr><td><code>MSEPost</code></td>
<td>
<p>If independent test set 'X2', 'Y2' is given, mean squared error of the posterior selection model predictions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
#####################
# Simulate toy data #
#####################
p&lt;-300 #number of covariates
n&lt;-100 #sample size training data set
n2&lt;-100 #sample size test data set

#simulate all betas i.i.d. from beta_k~N(mean=0,sd=sqrt(0.1)):
muBeta&lt;-0 #prior mean
varBeta&lt;-0.1 #prior variance
indT1&lt;-rep(1,p) #vector with group numbers all 1 (all simulated from same normal distribution)

#simulate test and training data sets:
Dat&lt;-simDat(n,p,n2,muBeta,varBeta,indT1,sigma=1,model='linear') 
str(Dat) #Dat contains centered observed data, response data and regression coefficients

####################################### 
# Fit ecpc and perform post-selection #
#######################################
fit &lt;- ecpc(Y=Dat$Y,X=Dat$Xctd,groupsets=list(list(1:p)),
            groupsets.grouplvl=list(NULL),
            hypershrinkage=c("none"),
            model="linear",maxsel=c(5,10,15,20),
            Y2=Dat$Y2,X2=Dat$X2ctd)

fitPost &lt;- postSelect(fit, Y=Dat$Y, X=Dat$Xctd, maxsel = c(5,10,15,20))
summary(fit$betaPost[,1]); summary(fitPost$betaPost[,1])

</code></pre>

<hr>
<h2 id='predict.ecpc'>
Predict for new samples for &lsquo;ecpc&rsquo; object
</h2><span id='topic+predict.ecpc'></span>

<h3>Description</h3>

<p>Predict the response for new samples based on an &lsquo;ecpc&rsquo; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ecpc'
predict(object, X2, X=NULL, Y=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ecpc_+3A_object">object</code></td>
<td>

<p>An 'ecpc' object returned by <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.ecpc_+3A_x2">X2</code></td>
<td>

<p>Independent observed data for which response is predicted.
</p>
</td></tr>
<tr><td><code id="predict.ecpc_+3A_x">X</code></td>
<td>

<p>Observed data used in fitting the &lsquo;object&rsquo;; (nxp)-dimensional matrix (p: number of covariates) with each row the observed high-dimensional feature vector of a sample.
</p>
</td></tr>
<tr><td><code id="predict.ecpc_+3A_y">Y</code></td>
<td>

<p>Response data used in fitting the &lsquo;object&rsquo;; n-dimensional vector (n: number of samples) for linear and logistic outcomes, or <code><a href="survival.html#topic+Surv">Surv</a></code> object for Cox survival.
</p>
</td></tr>
<tr><td><code id="predict.ecpc_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with predicted values. Note that for Cox response, the relative risks are provided, unless training data X and Y is provided to compute the Breslow estimator.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
#####################
# Simulate toy data #
#####################
p&lt;-300 #number of covariates
n&lt;-100 #sample size training data set
n2&lt;-100 #sample size test data set

#simulate all betas i.i.d. from beta_k~N(mean=0,sd=sqrt(0.1)):
muBeta&lt;-0 #prior mean
varBeta&lt;-0.1 #prior variance
indT1&lt;-rep(1,p) #vector with group numbers all 1 (all simulated from same normal distribution)

#simulate test and training data sets:
Dat&lt;-simDat(n,p,n2,muBeta,varBeta,indT1,sigma=1,model='linear') 
str(Dat) #Dat contains centered observed data, response data and regression coefficients

###################
# Provide co-data #
###################
continuousCodata &lt;- abs(Dat$beta) 
Z1 &lt;- cbind(continuousCodata,sqrt(continuousCodata))

#setting 2: splines for informative continuous
Z2 &lt;- createZforSplines(values=continuousCodata)
S1.Z2 &lt;- createS(orderPen=2, G=dim(Z2)[2]) #create difference penalty matrix
Con2 &lt;- createCon(G=dim(Z2)[2], shape="positive+monotone.i") #create constraints

#setting 3: 5 random groups
G &lt;- 5
categoricalRandom &lt;- as.factor(sample(1:G,p,TRUE))
#make group set, i.e. list with G groups:
groupsetRandom &lt;- createGroupset(categoricalRandom)
Z3 &lt;- createZforGroupset(groupsetRandom,p=p)
S1.Z3 &lt;- createS(G=G, categorical = TRUE) #create difference penalty matrix
Con3 &lt;- createCon(G=dim(Z3)[2], shape="positive") #create constraints

#fit ecpc for the three co-data matrices with following penalty matrices and constraints
#note: can also be fitted without paraPen and/or paraCon
Z.all &lt;- list(Z1=Z1,Z2=Z2,Z3=Z3)
paraPen.all &lt;- list(Z2=list(S1=S1.Z2), Z3=list(S1=S1.Z3))
paraCon &lt;- list(Z2=Con2, Z3=Con3)

############
# Fit ecpc #
############
tic&lt;-proc.time()[[3]]
fit &lt;- ecpc(Y=Dat$Y,X=Dat$Xctd,
           Z = Z.all, paraPen = paraPen.all, paraCon = paraCon,
           model="linear",maxsel=c(5,10,15,20),
           Y2=Dat$Y2,X2=Dat$X2ctd)
toc &lt;- proc.time()[[3]]-tic

predictions &lt;- predict(fit, X2=Dat$X2ctd)

</code></pre>

<hr>
<h2 id='print.ecpc'>
Print summary of 'ecpc' object
</h2><span id='topic+print.ecpc'></span><span id='topic+summary.ecpc'></span>

<h3>Description</h3>

<p>Print summary of the fitted model given in an 'ecpc' object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ecpc'
print(x, ...)

## S3 method for class 'ecpc'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ecpc_+3A_x">x</code></td>
<td>

<p>An 'ecpc' object returned by <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
<tr><td><code id="print.ecpc_+3A_object">object</code></td>
<td>

<p>An 'ecpc' object returned by <code><a href="#topic+ecpc">ecpc</a></code>.
</p>
</td></tr>
<tr><td><code id="print.ecpc_+3A_...">...</code></td>
<td>
<p>...</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>See <code><a href="#topic+ecpc">ecpc</a></code> for model fitting.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
#####################
# Simulate toy data #
#####################
p&lt;-300 #number of covariates
n&lt;-100 #sample size training data set
n2&lt;-100 #sample size test data set

#simulate all betas i.i.d. from beta_k~N(mean=0,sd=sqrt(0.1)):
muBeta&lt;-0 #prior mean
varBeta&lt;-0.1 #prior variance
indT1&lt;-rep(1,p) #vector with group numbers all 1 (all simulated from same normal distribution)

#simulate test and training data sets:
Dat&lt;-simDat(n,p,n2,muBeta,varBeta,indT1,sigma=1,model='linear') 
str(Dat) #Dat contains centered observed data, response data and regression coefficients

###################
# Provide co-data #
###################
continuousCodata &lt;- abs(Dat$beta) 
Z1 &lt;- cbind(continuousCodata,sqrt(continuousCodata))

#setting 2: splines for informative continuous
Z2 &lt;- createZforSplines(values=continuousCodata)
S1.Z2 &lt;- createS(orderPen=2, G=dim(Z2)[2]) #create difference penalty matrix
Con2 &lt;- createCon(G=dim(Z2)[2], shape="positive+monotone.i") #create constraints

#setting 3: 5 random groups
G &lt;- 5
categoricalRandom &lt;- as.factor(sample(1:G,p,TRUE))
#make group set, i.e. list with G groups:
groupsetRandom &lt;- createGroupset(categoricalRandom)
Z3 &lt;- createZforGroupset(groupsetRandom,p=p)
S1.Z3 &lt;- createS(G=G, categorical = TRUE) #create difference penalty matrix
Con3 &lt;- createCon(G=dim(Z3)[2], shape="positive") #create constraints

#fit ecpc for the three co-data matrices with following penalty matrices and constraints
#note: can also be fitted without paraPen and/or paraCon
Z.all &lt;- list(Z1=Z1,Z2=Z2,Z3=Z3)
paraPen.all &lt;- list(Z2=list(S1=S1.Z2), Z3=list(S1=S1.Z3))
paraCon &lt;- list(Z2=Con2, Z3=Con3)

############
# Fit ecpc #
############
tic&lt;-proc.time()[[3]]
fit &lt;- ecpc(Y=Dat$Y,X=Dat$Xctd,
           Z = Z.all, paraPen = paraPen.all, paraCon = paraCon,
           model="linear",maxsel=c(5,10,15,20),
           Y2=Dat$Y2,X2=Dat$X2ctd)
toc &lt;- proc.time()[[3]]-tic

print(fit)

summary(fit)


</code></pre>

<hr>
<h2 id='produceFolds'>
Produce folds
</h2><span id='topic+produceFolds'></span>

<h3>Description</h3>

<p>Produce folds for cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>produceFolds(nsam, outerfold, response, model = c("logistic","cox","other"), 
balance = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="produceFolds_+3A_nsam">nsam</code></td>
<td>

<p>Number of samples
</p>
</td></tr>
<tr><td><code id="produceFolds_+3A_outerfold">outerfold</code></td>
<td>

<p>Number of folds.
</p>
</td></tr>
<tr><td><code id="produceFolds_+3A_response">response</code></td>
<td>

<p>Response data.
</p>
</td></tr>
<tr><td><code id="produceFolds_+3A_model">model</code></td>
<td>

<p>Type of model for the response.
</p>
</td></tr>
<tr><td><code id="produceFolds_+3A_balance">balance</code></td>
<td>

<p>Should folds be balanced in response?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with &lsquo;outerfold&rsquo; elements containing a vector of sample indices in each fold.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-100
outerfold &lt;- 10

#linear model
resp &lt;- rnorm(n)
folds &lt;- produceFolds(nsam=n, outerfold=outerfold, response=resp)

#logistic model: keep 0/1 balanced across folds
resp &lt;- as.factor(rnorm(n)&gt;0.5)
folds &lt;- produceFolds(nsam=n, outerfold=outerfold, response=resp, balance = TRUE)

</code></pre>

<hr>
<h2 id='simDat'>
Simulate data
</h2><span id='topic+simDat'></span>

<h3>Description</h3>

<p>Simulate toy data with linear or logistic response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simDat(n, p, n2 = 20, muGrp, varGrp, indT, sigma = 1, 
  model = c("linear","logistic"), flag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simDat_+3A_n">n</code></td>
<td>

<p>Number of samples for the training set.
</p>
</td></tr>
<tr><td><code id="simDat_+3A_p">p</code></td>
<td>

<p>Number of covariates.
</p>
</td></tr>
<tr><td><code id="simDat_+3A_n2">n2</code></td>
<td>

<p>Number of independent samples for the test set.
</p>
</td></tr>
<tr><td><code id="simDat_+3A_mugrp">muGrp</code></td>
<td>

<p>Prior mean for different groups.
</p>
</td></tr>
<tr><td><code id="simDat_+3A_vargrp">varGrp</code></td>
<td>

<p>Prior variance for different groups.
</p>
</td></tr>
<tr><td><code id="simDat_+3A_indt">indT</code></td>
<td>

<p>True group index of each covariate; p-dimensional vector.
</p>
</td></tr>
<tr><td><code id="simDat_+3A_sigma">sigma</code></td>
<td>

<p>Variance parameter for linear model.
</p>
</td></tr>
<tr><td><code id="simDat_+3A_model">model</code></td>
<td>

<p>Type of model.
</p>
</td></tr>
<tr><td><code id="simDat_+3A_flag">flag</code></td>
<td>

<p>Should linear predictors and true response be plotted?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>Simulated regression coefficients</p>
</td></tr>
<tr><td><code>Xctd</code></td>
<td>
<p>Simulated observed data for training set</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>Simulated response data for test set</p>
</td></tr>
<tr><td><code>X2ctd</code></td>
<td>
<p>Simulated observed data for test set</p>
</td></tr>
<tr><td><code>Y2</code></td>
<td>
<p>Simulated response data for test set</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-10
p&lt;-30
#simulate beta from two normal distributions; beta_k ~ N(mu_k,tau^2_k)
muGrp &lt;- c(0,0.1) #mean (mu_1,mu_2)
varGrp &lt;- c(0.05,0.01) #variance (tau^2_1,tau^2_2)
#group number of each covariate; first half in group 1, second half in group 2
indT &lt;- rep(c(1,2),each=15)

dataLin &lt;- simDat(n, p, n2 = 20, muGrp, varGrp, indT, sigma = 1, model = "linear",
    flag = TRUE)
dataLog &lt;- simDat(n, p, n2 = 20, muGrp, varGrp, indT, model = "logistic",
    flag = TRUE)

</code></pre>

<hr>
<h2 id='splitMedian'>
Discretise continuous data in multiple granularities
</h2><span id='topic+splitMedian'></span>

<h3>Description</h3>

<p>Discretise continuous co-data by making groups of covariates of various size. The first group is the group with all covariates.
Each group is then recursively split in two at the median co-data value, until some user-specified minimum group size is reached.
The discretised groups are used for adaptive discretisation of continuous co-data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitMedian(values, index=NULL, depth=NULL, minGroupSize = 50, first = TRUE, 
  split = c("both","lower","higher"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitMedian_+3A_values">values</code></td>
<td>

<p>Vector with the continuous co-data values to be discretised.
</p>
</td></tr>
<tr><td><code id="splitMedian_+3A_index">index</code></td>
<td>

<p>Index of the covariates corresponding to the values supplied. Useful if part of the continuous co-data is missing and only the non-missing part should be discretised.
</p>
</td></tr>
<tr><td><code id="splitMedian_+3A_depth">depth</code></td>
<td>

<p>(optional): if given, a discretisation is returned with 'depth' levels of granularity.
</p>
</td></tr>
<tr><td><code id="splitMedian_+3A_mingroupsize">minGroupSize</code></td>
<td>

<p>Minimum group size that each group of covariates should have.
</p>
</td></tr>
<tr><td><code id="splitMedian_+3A_split">split</code></td>
<td>

<p>&quot;both&quot;, &quot;lower&quot; or &quot;higher&quot;: should both split groups of covariates be further split, or only the group of covariates that corresponds to the lower or higher continuous co-data group?
</p>
</td></tr>
<tr><td><code id="splitMedian_+3A_first">first</code></td>
<td>

<p>Do not change, recursion help variable.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with groups of covariates, which may be used as group set in ecpc.
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+obtainHierarchy">obtainHierarchy</a></code> to obtain a group set on group level defining the hierarchy for adaptive discretisation of continuous co-data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cont.codata &lt;- seq(0,1,length.out=20) #continuous co-data
#full tree with minimum group size 5
groupset1 &lt;- splitMedian(values=cont.codata,minGroupSize=5) 
#only split at lower continous co-data group
groupset2 &lt;- splitMedian(values=cont.codata,split="lower",minGroupSize=5) 

part &lt;- sample(1:length(cont.codata),15) #discretise only for a part of the continuous co-data
cont.codata[-part] &lt;- NaN #suppose rest is missing
#make group set of non-missing values
groupset3 &lt;- splitMedian(values=cont.codata[part],index=part,minGroupSize=5) 
groupset3 &lt;- c(groupset3,list(which(is.nan(cont.codata)))) #add missing data group


</code></pre>

<hr>
<h2 id='visualiseGroupset'>
Visualise a group set
</h2><span id='topic+visualiseGroupset'></span>

<h3>Description</h3>

<p>Visualises a group set in a graph, with directed edges indicating the hierarchy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visualiseGroupset(Groupset, groupweights, groupset.grouplvl, nodeSize = 10, ls = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visualiseGroupset_+3A_groupset">Groupset</code></td>
<td>

<p>List of G groups of covariates.
</p>
</td></tr>
<tr><td><code id="visualiseGroupset_+3A_groupweights">groupweights</code></td>
<td>

<p>(optional) vector with G group weights; if given, group weights are visualised too.
</p>
</td></tr>
<tr><td><code id="visualiseGroupset_+3A_groupset.grouplvl">groupset.grouplvl</code></td>
<td>

<p>List of G_2 groups defining a hierarchy.
</p>
</td></tr>
<tr><td><code id="visualiseGroupset_+3A_nodesize">nodeSize</code></td>
<td>

<p>Size of the nodes in the visualisation; scalar.
</p>
</td></tr>
<tr><td><code id="visualiseGroupset_+3A_ls">ls</code></td>
<td>

<p>Line size; scalar.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+visualiseGroupsetweights">visualiseGroupsetweights</a></code> to plot estimated group set weights. and <code><a href="#topic+visualiseGroupweights">visualiseGroupweights</a></code> to plot estimated group weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#groups without hierarchical constraints
groupset &lt;- list("Group1"=c(1:20),"Group2"=c(15,30))
visualiseGroupset(groupset,c(0.5,2))

#hierarchical groups
cont.codata &lt;- seq(0,1,length.out=20) #continuous co-data
#only split at lower continous co-data group
hierarchicalgroupset &lt;- splitMedian(values=cont.codata,split="lower",minGroupSize=5)
#obtain groups on group level defining the hierarchy
groupset.grouplvl &lt;- obtainHierarchy(hierarchicalgroupset)
visualiseGroupset(hierarchicalgroupset, groupset.grouplvl=groupset.grouplvl)

</code></pre>

<hr>
<h2 id='visualiseGroupsetweights'>
Visualise estimated group set weights
</h2><span id='topic+visualiseGroupsetweights'></span>

<h3>Description</h3>

<p>Plot group set weights from multiple cross-validation folds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visualiseGroupsetweights(dfGrps, GroupsetNames, hist = FALSE, boxplot = TRUE, 
                          jitter = TRUE, ps = 1.5, width = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visualiseGroupsetweights_+3A_dfgrps">dfGrps</code></td>
<td>

<p>Data frame containing the following variables;
'Groupset': factor with group set names;
'Groupset.weight': group set weight of each group set;
'Fold': number indicating which fold in the cross-validation is used.
</p>
</td></tr>
<tr><td><code id="visualiseGroupsetweights_+3A_groupsetnames">GroupsetNames</code></td>
<td>

<p>Vector with names of the group sets.
</p>
</td></tr>
<tr><td><code id="visualiseGroupsetweights_+3A_hist">hist</code></td>
<td>

<p>Should histogram be plotted?
</p>
</td></tr>
<tr><td><code id="visualiseGroupsetweights_+3A_boxplot">boxplot</code></td>
<td>

<p>Should boxplot be used or points?
</p>
</td></tr>
<tr><td><code id="visualiseGroupsetweights_+3A_jitter">jitter</code></td>
<td>

<p>Should group set weights be jittered?
</p>
</td></tr>
<tr><td><code id="visualiseGroupsetweights_+3A_ps">ps</code></td>
<td>

<p>Point size.
</p>
</td></tr>
<tr><td><code id="visualiseGroupsetweights_+3A_width">width</code></td>
<td>

<p>Width of jitter.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plot in ggplot object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+visualiseGroupset">visualiseGroupset</a></code> to visualise group sets and <code><a href="#topic+visualiseGroupweights">visualiseGroupweights</a></code> to plot estimated group weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dfGrps &lt;- data.frame(Groupset=rep(c(1,2),each=10),
                     Groupset.weight=c(rnorm(10,0,0.01),rnorm(10,1,0.05)),
                     Fold=rep(1:10,2))
GroupsetNames &lt;- c("Groupset1","Groupset2")
visualiseGroupsetweights(dfGrps, GroupsetNames, hist = FALSE, boxplot = TRUE,jitter=TRUE)
</code></pre>

<hr>
<h2 id='visualiseGroupweights'>
Visualise estimated group weights
</h2><span id='topic+visualiseGroupweights'></span>

<h3>Description</h3>

<p>Plot group weights from multiple cross-validation folds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visualiseGroupweights(dfGrps, Groupset, groupset.grouplvl, values, 
                      widthBoxplot = 0.05, boxplot = TRUE, jitter = TRUE, 
                      ps = 1.5, ls = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visualiseGroupweights_+3A_dfgrps">dfGrps</code></td>
<td>

<p>Data frame containing the following variables;
'Group': factor with group names;
'Group.weight': group weight of each group;
'Fold': number indicating which fold in the cross-validation is used.
</p>
</td></tr>
<tr><td><code id="visualiseGroupweights_+3A_groupset">Groupset</code></td>
<td>

<p>List of G elements containing covariate indices for each group
</p>
</td></tr>
<tr><td><code id="visualiseGroupweights_+3A_groupset.grouplvl">groupset.grouplvl</code></td>
<td>

<p>(optional): groups on group level, e.g. defining a hierarchical structure. 
</p>
</td></tr>
<tr><td><code id="visualiseGroupweights_+3A_values">values</code></td>
<td>

<p>(optional): values of continuous co-data. If given, group weights are plotted against these value.
</p>
</td></tr>
<tr><td><code id="visualiseGroupweights_+3A_widthboxplot">widthBoxplot</code></td>
<td>

<p>Width of boxplot.
</p>
</td></tr>
<tr><td><code id="visualiseGroupweights_+3A_boxplot">boxplot</code></td>
<td>

<p>Should a boxplot be plotted?
</p>
</td></tr>
<tr><td><code id="visualiseGroupweights_+3A_jitter">jitter</code></td>
<td>

<p>Should point estimates be jittered?
</p>
</td></tr>
<tr><td><code id="visualiseGroupweights_+3A_ps">ps</code></td>
<td>

<p>Point size.
</p>
</td></tr>
<tr><td><code id="visualiseGroupweights_+3A_ls">ls</code></td>
<td>

<p>Line size.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plot in ggplot object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+visualiseGroupset">visualiseGroupset</a></code> to visualise group sets and <code><a href="#topic+visualiseGroupsetweights">visualiseGroupsetweights</a></code> to plot estimated group set weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#discrete groups
groupset1 &lt;- list(1:20,21:40)
dfGrps1 &lt;- data.frame(Group=as.factor(rep(c(1,2),each=10)),
                     Group.weight=c(rnorm(10,0.5,0.01),rnorm(10,2,0.05)),
                     Fold=rep(1:10,2))
visualiseGroupweights(dfGrps1, Groupset=groupset1)

#continous co-data groups
cont.codata &lt;- seq(0,1,length.out=40) #continuous co-data
#only split at lower continous co-data group
groupset2 &lt;- splitMedian(values=cont.codata,split="lower",minGroupSize=10)
#obtain groups on group level defining the hierarchy
groupset.grouplvl &lt;- obtainHierarchy(groupset2)

#simulate random group weights around 1
dfGrps2 &lt;- data.frame(Group=as.factor(rep(1:length(groupset2),each=10)),
                      Group.weight=c(rnorm(10*length(groupset2),1,0.01)),
                      Fold=rep(1:10,length(groupset2)))
#plot group weights per group
visualiseGroupweights(dfGrps2, Groupset=groupset2, groupset.grouplvl=groupset.grouplvl)
#plot group weights per leaf group in the hierarchical tree
visualiseGroupweights(dfGrps2, Groupset=groupset2, groupset.grouplvl=groupset.grouplvl,
                      values=cont.codata)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
