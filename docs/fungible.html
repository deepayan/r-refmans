<!DOCTYPE html><html><head><title>Help for package fungible</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fungible}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ACL'><p>Adjective Checklist Data.</p></a></li>
<li><a href='#adfCor'><p>Asymptotic Distribution-Free Covariance Matrix of Correlations</p></a></li>
<li><a href='#adfCov'><p>Asymptotic Distribution-Free Covariance Matrix of Covariances</p></a></li>
<li><a href='#alphaR'><p>Generate random R matrices with a known coefficient alpha</p></a></li>
<li><a href='#AmzBoxes'><p>Length, width, and height measurements for 98 Amazon shipping boxes</p></a></li>
<li><a href='#BadRBY'><p>Improper correlation matrix reported by Bentler and Yuan</p></a></li>
<li><a href='#BadRJN'><p>Improper R matrix reported by Joseph and Newman</p></a></li>
<li><a href='#BadRKtB'><p>Improper R matrix reported by Knol and ten Berge</p></a></li>
<li><a href='#BadRLG'><p>Improper R matrix reported by Lurie and Goldberg</p></a></li>
<li><a href='#BadRRM'><p>Improper R matrix reported by Rousseeuw and Molenberghs</p></a></li>
<li><a href='#BiFAD'><p>Bifactor Analysis via Direct Schmid-Leiman (DSL) Transformations</p></a></li>
<li><a href='#bigen'><p>Generate Correlated Binary Data</p></a></li>
<li><a href='#Boruch70'><p>Multi-Trait Multi-Method correlation matrix reported by Boruch, Larkin, Wolins, and MacKinney (1970)</p></a></li>
<li><a href='#Box20'><p>Length, width, and height measurements for Thurstone's 20 boxes</p></a></li>
<li><a href='#Box26'><p>R matrix for Thurstone's 26 hypothetical box attributes.</p></a></li>
<li><a href='#cb'><p>Cudeck &amp; Browne (1992) model error method</p></a></li>
<li><a href='#cfi'><p>Calculate CFI for two correlation matrices</p></a></li>
<li><a href='#CompleteRcvx'><p>Complete a Partially Specified Correlation Matrix by Convex Optimization</p></a></li>
<li><a href='#CompleteRdev'><p>Complete a Partially Specified Correlation Matrix by the Method of Differential Evolution</p></a></li>
<li><a href='#CompleteRmap'><p>Complete a Partially Specified Correlation Matrix by the Method of Alternating Projections</p></a></li>
<li><a href='#corDensity'><p>Generate the marginal density of a correlation from a uniformly</p>
sampled R matrix.</a></li>
<li><a href='#corSample'><p>Sample Correlation Matrices from a Population Correlation Matrix</p></a></li>
<li><a href='#corSmooth'><p>Smooth a Non PD Correlation Matrix</p></a></li>
<li><a href='#cosMat'><p>Compute the cosine(s) between either 2 matrices or 2 vectors.</p></a></li>
<li><a href='#d2r'><p>Convert Degrees to Radians</p></a></li>
<li><a href='#eap'><p>Compute eap trait estimates for FMP and FUP models</p></a></li>
<li><a href='#eigGen'><p>Generate eigenvalues for R matrices with underlying component structure</p></a></li>
<li><a href='#enhancement'><p>Find OLS Regression Coefficients that Exhibit Enhancement</p></a></li>
<li><a href='#erf'><p>Utility fnc to compute the components for an empirical response function</p></a></li>
<li><a href='#faAlign'><p>Align the columns of two factor loading matrices</p></a></li>
<li><a href='#faBounds'><p>Bounds on the Correlation Between an External Variable and a Common Factor</p></a></li>
<li><a href='#faEKC'><p>Calculate Reference Eigenvalues for the Empirical Kaiser Criterion</p></a></li>
<li><a href='#faIB'><p>Inter-Battery Factor Analysis by the Method of Maximum Likelihood</p></a></li>
<li><a href='#faLocalMin'><p>Investigate local minima in  faMain objects</p></a></li>
<li><a href='#fals'><p>Unweighted least squares factor analysis</p></a></li>
<li><a href='#faMain'><p>Automatic Factor Rotation from Random Configurations with Bootstrap Standard Errors</p></a></li>
<li><a href='#faMAP'><p>Velicer's minimum partial correlation method for determining the number of</p>
major components for a principal components analysis or a factor analysis</a></li>
<li><a href='#faMB'><p>Multiple Battery Factor Analysis by Maximum Likelihood Methods</p></a></li>
<li><a href='#fapa'><p>Iterated Principal Axis Factor Analysis (fapa)</p></a></li>
<li><a href='#fareg'><p>Regularized Factor Analysis</p></a></li>
<li><a href='#faScores'><p>Factor Scores</p></a></li>
<li><a href='#faSort'><p>Sort a factor loadings matrix</p></a></li>
<li><a href='#faStandardize'><p>Standardize the Unrotated Factor Loadings</p></a></li>
<li><a href='#faX'><p>Factor Extraction (faX) Routines</p></a></li>
<li><a href='#FMP'><p>Estimate the coefficients of a filtered monotonic polynomial IRT model</p></a></li>
<li><a href='#FMPMonotonicityCheck'><p>Utility function for checking FMP monotonicity</p></a></li>
<li><a href='#fsIndeterminacy'><p>Understanding Factor Score Indeterminacy with Finite Dimensional Vector Spaces</p></a></li>
<li><a href='#fungible'><p>Generate Fungible Regression Weights</p></a></li>
<li><a href='#fungibleExtrema'><p>Locate Extrema of Fungible Regression Weights</p></a></li>
<li><a href='#fungibleL'><p>Generate Fungible Logistic Regression Weights</p></a></li>
<li><a href='#fungibleR'><p>Generate Fungible Correlation Matrices</p></a></li>
<li><a href='#FUP'><p>Estimate the coefficients of a filtered unconstrained polynomial IRT model</p></a></li>
<li><a href='#gen4PMData'><p>Generate item response data for 1, 2, 3, or 4-parameter IRT models</p></a></li>
<li><a href='#genCorr'><p>Generate Correlation Matrices with User-Defined Eigenvalues</p></a></li>
<li><a href='#GenerateBoxData'><p>Generate Thurstone's Box Data From length, width, and height box measurements</p></a></li>
<li><a href='#genFMPData'><p>Generate item response data for a filtered monotonic polynomial IRT model</p></a></li>
<li><a href='#genPhi'><p>Create a random Phi matrix with maximum factor correlation</p></a></li>
<li><a href='#get_wb_mod'><p>Find an 'lm' model to use with the Wu &amp; Browne (2015) model error method</p></a></li>
<li><a href='#HS9Var'><p>9 Variables from the Holzinger and Swineford (1939) Dataset</p></a></li>
<li><a href='#HW'><p>Six data sets that  yield a Heywood case</p></a></li>
<li><a href='#irf'><p>Plot item response functions for polynomial IRT models.</p></a></li>
<li><a href='#itemDescriptives'><p>Compute basic descriptives for binary-item analysis</p></a></li>
<li><a href='#Jackson67'><p>Multi-Trait Multi-Method correlation matrix reported by Jackson and Singer (1967)</p></a></li>
<li><a href='#kurt'><p>Calculate Univariate Kurtosis for a Vector or Matrix</p></a></li>
<li><a href='#Ledermann'><p>Ledermann's inequality for factor solution identification</p></a></li>
<li><a href='#Malmi79'><p>Multi-Trait Multi-Method correlation matrix reported by Malmi, Underwood, and Carroll (1979).</p></a></li>
<li><a href='#monte'><p>Simulate Clustered Data with User-Defined Properties</p></a></li>
<li><a href='#monte1'><p>Simulate Multivariate Non-normal Data by Vale &amp; Maurelli (1983) Method</p></a></li>
<li><a href='#noisemaker'><p>Simulate a population correlation matrix with model error</p></a></li>
<li><a href='#normalCor'><p>Compute Normal-Theory Covariances for Correlations</p></a></li>
<li><a href='#normF'><p>Compute the Frobenius norm of a matrix</p></a></li>
<li><a href='#obj_func'><p>Objective function for optimizing RMSEA and CFI</p></a></li>
<li><a href='#Omega'><p>Compute Omega hierarchical</p></a></li>
<li><a href='#orderFactors'><p>Order factor-loadings matrix by the sum of squared factor loadings</p></a></li>
<li><a href='#plot.monte'><p>Plot Method for Class Monte</p></a></li>
<li><a href='#print.faMain'><p>Print  Method for an Object of Class faMain</p></a></li>
<li><a href='#print.faMB'><p>Print  Method for an Object of Class faMB</p></a></li>
<li><a href='#promaxQ'><p>Conduct an Oblique Promax Rotation</p></a></li>
<li><a href='#r2d'><p>Convert Radians to Degrees</p></a></li>
<li><a href='#rarc'><p>Rotate Points on the Surface on an N-Dimensional Ellipsoid</p></a></li>
<li><a href='#Ravgr'><p>Generate a random R matrix with an average rij</p></a></li>
<li><a href='#Rbounds'><p>Generate random R matrices with user-defined bounds on the correlation</p>
coefficients via differential evolution (DE).</a></li>
<li><a href='#rcone'><p>Generate a Cone of Regression Coefficient Vectors</p></a></li>
<li><a href='#rcor'><p>Generate Random PSD Correlation Matrices</p></a></li>
<li><a href='#rellipsoid'><p>Generate Uniformly Spaced OLS Regression Coefficients that Yield a</p>
User-Supplied R-Squared Value</a></li>
<li><a href='#restScore'><p>Plot an ERF using rest scores</p></a></li>
<li><a href='#RGen'><p>Generate random R matrices with various user-defined properties via</p>
differential evolution (DE).</a></li>
<li><a href='#rGivens'><p>Generate Correlation Matrices with Specified Eigenvalues</p></a></li>
<li><a href='#rMAP'><p>Generate Correlation Matrices with Specified Eigenvalues</p></a></li>
<li><a href='#rmsd'><p>Root Mean Squared Deviation of (A - B)</p></a></li>
<li><a href='#rmsea'><p>Calculate RMSEA between two correlation matrices</p></a></li>
<li><a href='#RnpdMAP'><p>Generate Random NPD R matrices from a user-supplied population R</p></a></li>
<li><a href='#rPCA'><p>Generate a Correlation Matrix from a Truncated PCA Loadings Matrix.</p></a></li>
<li><a href='#SchmidLeiman'><p>Schmid-Leiman Orthogonalization to a (Rank-Deficient) Bifactor Structure</p></a></li>
<li><a href='#seBeta'><p>Standard Errors and CIs for Standardized Regression Coefficients</p></a></li>
<li><a href='#seBetaCor'><p>Standard Errors and CIs for Standardized Regression Coefficients from</p>
Correlations</a></li>
<li><a href='#seBetaFixed'><p>Covariance Matrix and Standard Errors for Standardized Regression</p>
Coefficients for Fixed Predictors</a></li>
<li><a href='#semify'><p>Generate an sem model from a simFA model object</p></a></li>
<li><a href='#simFA'><p>Generate Factor Analysis Models and Data Sets for Simulation Studies</p></a></li>
<li><a href='#skew'><p>Calculate Univariate Skewness for a Vector or Matrix</p></a></li>
<li><a href='#SLi'><p>Conduct a Schmid-Leiman Iterated (SLi) Target Rotation</p></a></li>
<li><a href='#smoothAPA'><p>Smooth a NPD R matrix to PD using the Alternating Projection Algorithm</p></a></li>
<li><a href='#smoothBY'><p>Smooth an NPD R matrix to PD using the Bentler Yuan 2011 method</p></a></li>
<li><a href='#smoothKB'><p>Smooth a Non PD Correlation Matrix using the Knol-Berger algorithm</p></a></li>
<li><a href='#smoothLG'><p>Smooth NPD to Nearest PSD or PD Matrix</p></a></li>
<li><a href='#summary.faMain'><p>Summary Method for an Object of Class faMain</p></a></li>
<li><a href='#summary.faMB'><p>Summary Method for an Object of Class faMB</p></a></li>
<li><a href='#summary.monte'><p>Summary Method for an Object of Class Monte</p></a></li>
<li><a href='#summary.monte1'><p>Summary Method for an Object of Class Monte1</p></a></li>
<li><a href='#svdNorm'><p>Compute theta surrogates via normalized SVD scores</p></a></li>
<li><a href='#TaylorRussell'><p>A generalized (multiple predictor) Taylor-Russell function.</p></a></li>
<li><a href='#tetcor'><p>Compute ML Tetrachoric Correlations</p></a></li>
<li><a href='#tetcorQuasi'><p>Correlation between a Naturally and an Artificially Dichotomized Variable</p></a></li>
<li><a href='#Thurstone41'><p>Multi-Trait Multi-Method correlation matrix reported by Thurstone and Thurstone (1941).</p></a></li>
<li><a href='#ThurstoneBox20'><p>Factor Pattern and Factor Correlations for Thurstone's 20 hypothetical box attributes.</p></a></li>
<li><a href='#ThurstoneBox26'><p>Factor Pattern Matrix for Thurstone's 26  box attributes.</p></a></li>
<li><a href='#tkl'><p>Optimize TKL parameters to find a solution with target RMSEA and CFI values</p></a></li>
<li><a href='#TR'><p>Estimate the parameters of the Taylor-Russell function.</p></a></li>
<li><a href='#vcos'><p>Compute the Cosine Between Two Vectors</p></a></li>
<li><a href='#vnorm'><p>Norm a Vector to Unit Length</p></a></li>
<li><a href='#VolElliptope'><p>Compute the volume of the elliptope of possible correlation</p>
matrices of a given dimension.</a></li>
<li><a href='#wb'><p>Wu &amp; Browne model error method</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.4.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-04-05</td>
</tr>
<tr>
<td>Title:</td>
<td>Psychometric Functions from the Waller Lab</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Niels Waller &lt;nwaller@umn.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>crayon (&ge; 1.4.1), clue, CVXR, DEoptim, GA (&ge; 3.2.1),
GPArotation, lattice, MASS, MBESS (&ge; 4.8.0), MCMCpack,
methods, mvtnorm, nleqslv, pbmcapply, Rcsdp, RSpectra, sem (&ge;
3.1-11), utils, graphics, grDevices</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes fungible coefficients and Monte Carlo data. Underlying theory for these functions is described in the following publications:
    Waller, N. (2008). Fungible Weights in Multiple Regression. Psychometrika, 73(4), 691-703, &lt;<a href="https://doi.org/10.1007%2Fs11336-008-9066-z">doi:10.1007/s11336-008-9066-z</a>&gt;.
    Waller, N. &amp; Jones, J. (2009). Locating the Extrema of Fungible Regression Weights.
    Psychometrika, 74(4), 589-602, &lt;<a href="https://doi.org/10.1007%2Fs11336-008-9087-7">doi:10.1007/s11336-008-9087-7</a>&gt;.
    Waller, N. G. (2016). Fungible Correlation Matrices:
    A Method for Generating Nonsingular, Singular, and Improper Correlation Matrices for
    Monte Carlo Research. Multivariate Behavioral Research, 51(4), 554-568.
    Jones, J. A. &amp; Waller, N. G. (2015). The normal-theory and asymptotic distribution-free (ADF)
    covariance matrix of standardized regression coefficients: theoretical extensions
    and finite sample behavior. Psychometrika, 80, 365-378, &lt;<a href="https://doi.org/10.1007%2Fs11336-013-9380-y">doi:10.1007/s11336-013-9380-y</a>&gt;.
    Waller, N. G.  (2018).  Direct Schmid-Leiman transformations and rank-deficient loadings matrices.  Psychometrika, 83, 858-870. &lt;<a href="https://doi.org/10.1007%2Fs11336-017-9599-0">doi:10.1007/s11336-017-9599-0</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, covr (&ge; 3.5.1), testthat (&ge; 3.0.0),</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-09 21:01:41 UTC; nielswaller</td>
</tr>
<tr>
<td>Author:</td>
<td>Niels Waller [aut, cre],
  Justin Kracht [ctb],
  Jeff Jones [ctb],
  Casey Giordano [ctb],
  Hoang V. Nguyen [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-09 22:30:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='ACL'>Adjective Checklist Data.</h2><span id='topic+ACL'></span>

<h3>Description</h3>

<p>Adjective checklist data from the California Twin Registry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ACL)
</code></pre>


<h3>Format</h3>

<p>Adjective Checklist data from the California 
Twin Registry (see Waller, Bouchard, Lykken, Tellegen, A., &amp; Blacker,  
1993). 
<strong>ACL</strong> variables:
</p>

<ol>
<li><p> id
</p>
</li>
<li><p> sex
</p>
</li>
<li><p> age
</p>
</li>
<li><p> items 1 ... 300 
</p>
</li></ol>



<h3>Details</h3>

<p>This is a de-identified subset of the ACL data from the 
California Twin Registry (data collected by Waller in the 1990s).  This 
data set of 257 cases includes complete (i.e., no missing data) ACL 
item responses from a random member of each twin pair.  The item 
response vectors are independent.
</p>


<h3>References</h3>

<p>Gough, H. G. &amp; Heilbrun, A. B. (1980). The Adjective Checklist 
Manual: 1980 Edition. Consulting Psychologists Press.
</p>
<p>Waller, N. G., Bouchard, T. J., Lykken, D. T., Tellegen, A., and Blacker, D. 
(1993).  Creativity, heritability, familiarity: 
Which word does not belong?.  Psychological Inquiry, 
4(3), 235&ndash;237.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

 data(ACL)
 
# Factor analyze a random subset of ACL items
# for illustrative purposes

set.seed(1)
RandomItems &lt;- sample(1:300, 
                      50, 
                      replace = FALSE)

ACL50 &lt;- ACL[, RandomItems + 3]

tetR_ACL50 &lt;- tetcor(x = ACL50)$r

fout &lt;- faMain(R     = tetR_ACL50,
               numFactors    = 5,
               facMethod     = "fals",
               rotate        = "oblimin",
               bootstrapSE   = FALSE,
        rotateControl = list(
               numberStarts = 100,  
               standardize  = "none"),
               Seed = 123)

summary(fout, itemSort = TRUE)  

## End(Not run)   
</code></pre>

<hr>
<h2 id='adfCor'>Asymptotic Distribution-Free Covariance Matrix of Correlations</h2><span id='topic+adfCor'></span>

<h3>Description</h3>

<p>Function for computing an asymptotic distribution-free covariance matrix of
correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adfCor(X, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adfCor_+3A_x">X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code id="adfCor_+3A_y">y</code></td>
<td>
<p>Optional vector of criterion scores.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>adfCorMat</code></td>
<td>
<p>Asymptotic distribution-free estimate of the
covariance matrix of correlations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Jones and Niels Waller
</p>


<h3>References</h3>

<p>Browne, M. W. (1984). Asymptotically distribution-free methods
for the analysis of covariance structures. <em>British Journal of
Mathematical and Statistical Psychology, 37</em>, 62&ndash;83.
</p>
<p>Steiger, J. H. and Hakstian, A. R. (1982). The asymptotic distribution of
elements of a correlation matrix: Theory and application. <em>British
Journal of Mathematical and Statistical Psychology, 35</em>, 208&ndash;215.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Generate non-normal data using monte1
set.seed(123)
## we will simulate data for 1000 subjects
N &lt;- 1000

## R = the desired population correlation matrix among predictors
R &lt;- matrix(c(1, .5, .5, 1), 2, 2)

## Consider a regression model with coefficient of determination (Rsq): 
Rsq &lt;- .50

## and vector of standardized regression coefficients
Beta &lt;- sqrt(Rsq/t(sqrt(c(.5, .5))) %*% R %*% sqrt(c(.5, .5))) * sqrt(c(.5, .5))

## generate non-normal data for the predictors (X)
## x1 has expected skew = 1 and kurtosis = 3
## x2 has expected skew = 2 and kurtosis = 5
X &lt;- monte1(seed = 123, nvar = 2, nsub = N, cormat = R, skewvec = c(1, 2), 
            kurtvec = c(3, 5))$data
            
## generate criterion scores            
y &lt;- X %*% Beta + sqrt(1-Rsq)*rnorm(N)

## Create ADF Covariance Matrix of Correlations
adfCor(X, y)

#&gt;             12           13           23
#&gt; 12 0.0012078454 0.0005331086 0.0004821594
#&gt; 13 0.0005331086 0.0004980130 0.0002712080
#&gt; 23 0.0004821594 0.0002712080 0.0005415301

</code></pre>

<hr>
<h2 id='adfCov'>Asymptotic Distribution-Free Covariance Matrix of Covariances</h2><span id='topic+adfCov'></span>

<h3>Description</h3>

<p>Function for computing an asymptotic distribution-free covariance matrix of
covariances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adfCov(X, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adfCov_+3A_x">X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code id="adfCov_+3A_y">y</code></td>
<td>
<p>Optional vector of criterion scores.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>adfCovMat</code></td>
<td>
<p>Asymptotic distribution-free estimate of the
covariance matrix of covariances</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Jones and Niels Waller
</p>


<h3>References</h3>

<p>Browne, M. W. (1984). Asymptotically distribution-free methods
for the analysis of covariance structures. <em>British Journal of
Mathematical and Statistical Psychology, 37,</em> 62&ndash;83.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Generate non-normal data using monte1
set.seed(123)

## we will simulate data for 1000 subjects
N &lt;- 1000

## R = the desired population correlation matrix among predictors
R &lt;- matrix(c(1, .5, .5, 1), 2, 2)

## Consider a regression model with coefficient of determination (Rsq):
Rsq &lt;- .50

## and vector of standardized regression coefficients
Beta &lt;- sqrt(Rsq/t(sqrt(c(.5, .5))) %*% R %*% sqrt(c(.5, .5))) * sqrt(c(.5, .5))

## generate non-normal data for the predictors (X)
## x1 has expected skew = 1 and kurtosis = 3
## x2 has expected skew = 2 and kurtosis = 5
X &lt;- monte1(seed = 123, nvar = 2, nsub = N, cormat = R, skewvec = c(1, 2), 
           kurtvec = c(3, 5))$data
           
## generate criterion scores 
y &lt;- X %*% Beta + sqrt(1-Rsq)*rnorm(N)

## Create ADF Covariance Matrix of Covariances
adfCov(X, y)

#&gt;         11       12       13       22       23       33
#&gt; 11 3.438760 2.317159 2.269080 2.442003 1.962584 1.688631
#&gt; 12 2.317159 3.171722 2.278212 3.349173 2.692097 2.028701
#&gt; 13 2.269080 2.278212 2.303659 2.395033 2.149316 2.106310
#&gt; 22 2.442003 3.349173 2.395033 6.275088 4.086652 2.687647
#&gt; 23 1.962584 2.692097 2.149316 4.086652 3.287088 2.501094
#&gt; 33 1.688631 2.028701 2.106310 2.687647 2.501094 2.818664
</code></pre>

<hr>
<h2 id='alphaR'>Generate random R matrices with a known coefficient alpha</h2><span id='topic+alphaR'></span>

<h3>Description</h3>

<p><code>alphaR</code> can generate a list of fungible correlation matrices with a 
user-defined  (standardized) coefficient <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alphaR(alpha, k, Nmats, SEED)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alphaR_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) A desired coefficient <code class="reqn">\alpha</code> within 
the range <code class="reqn">\alpha \in (-\infty, 1]</code>.</p>
</td></tr>
<tr><td><code id="alphaR_+3A_k">k</code></td>
<td>
<p>(integer). The order of each R (correlation) matrix.</p>
</td></tr>
<tr><td><code id="alphaR_+3A_nmats">Nmats</code></td>
<td>
<p>(integer) The number of fungible R matrices with a known 
<code class="reqn">\alpha</code>. 
Default (<code>Nmats = 5</code>).</p>
</td></tr>
<tr><td><code id="alphaR_+3A_seed">SEED</code></td>
<td>
<p>(numeric)  The initial seed for the random number generator. 
If SEED is not supplied then the program will generate (and return) a randomly
generated seed.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li>  <p><strong>alpha</strong> The desired (standardized) coefficient <code class="reqn">\alpha</code>.
</p>
</li>
<li> <p><strong>R</strong> The initial correlation matrix with a desired 
coefficient <code class="reqn">\alpha</code>. 
</p>
</li>
<li> <p><strong>Rlist</strong> A list with <code>Nmats</code> fungible correlation 
matrices with a desired coefficient <code class="reqn">\alpha</code>.  
</p>
</li>
<li>  <p><strong>SEED</strong> The initial value for the random number generator.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Waller, N. &amp; Revelle, W. (2023). What are the mathematical 
bounds for coefficient <code class="reqn">\alpha</code>? <em>Psychological Methods</em>.
doi.org/10.1037/met0000583
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Function to compute standardized alpha
Alphaz &lt;- function(Rxx){
  k &lt;- ncol(Rxx)
  k/(k-1) * (1 - (k/sum(Rxx)) ) 
}# END Alphaz

## Example 1
## Generate 25 6 x 6 R matrices with a standardized alpha of .85
alpha =  .85   
k = 6
Nmats =  25 
SEED = 1

out = alphaR(alpha, k , Nmats, SEED)
Alphaz(out$Rlist[[1]])

## Example 2
## Generate 25 6 x 6 R matrices with a standardized alpha of -5
alpha =  -5   
k = 6
Nmats =  25 
SEED = 1

out = alphaR(alpha, k , Nmats, SEED) 
Alphaz(out$Rlist[[5]])

</code></pre>

<hr>
<h2 id='AmzBoxes'>Length, width, and height measurements for 98 Amazon shipping boxes</h2><span id='topic+AmzBoxes'></span>

<h3>Description</h3>

<p>Length, width, and height measurements for 98 Amazon shipping boxes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(AmzBoxes)
</code></pre>


<h3>Format</h3>

<p>A data set of measurements for 98 Amazon shipping boxes. 
These data were downloaded from the  BoxDimensions website: (https://www.boxdimensions.com/).
The data set includes five variables:
</p>

<ul>
<li><p> Amazon Box Size
</p>
</li>
<li><p> Length (inches) 
</p>
</li>
<li><p> Width (inches) 
</p>
</li>
<li><p> Height (inches)
</p>
</li>
<li><p> Volume (inches)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(AmzBoxes)

hist(AmzBoxes$`Length (inches)`,
     main = "Histogram of Box Lengths",
     xlab = "Length",
     col = "blue")


</code></pre>

<hr>
<h2 id='BadRBY'>Improper correlation matrix reported by Bentler and Yuan</h2><span id='topic+BadRBY'></span>

<h3>Description</h3>

<p>Example improper R matrix reported by Bentler and Yuan (2011)
</p>


<h3>Format</h3>

<p>A 12 by 12 non-positive definite correlation matrix.
</p>


<h3>Source</h3>

<p>Bentler, P. M. &amp; Yuan, K. H. (2011). Positive definiteness via
off-diagonal scaling of a symmetric indefinite matrix. Psychometrika, 76(1),
119&ndash;123.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRBY)

</code></pre>

<hr>
<h2 id='BadRJN'>Improper R matrix reported by Joseph and Newman</h2><span id='topic+BadRJN'></span>

<h3>Description</h3>

<p>Example NPD improper correlation matrix reported by Joseph and Newman
</p>


<h3>Format</h3>

<p>A 14 by 14 non-positive definite correlation matrix.
</p>


<h3>Source</h3>

<p>Joseph, D. L. &amp; Newman, D. A. (2010). Emotional intelligence: an
integrative meta-analysis and cascading model. Journal of Applied
Psychology, 95(1), 54&ndash;78.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRJN)

</code></pre>

<hr>
<h2 id='BadRKtB'>Improper R matrix reported by Knol and ten Berge</h2><span id='topic+BadRKtB'></span>

<h3>Description</h3>

<p>Example improper R matrix reported by Knol and ten Berge
</p>


<h3>Format</h3>

<p>A 6 by 6 non-positive definite correlation matrix.
</p>


<h3>Source</h3>

<p>Knol, D. L. and Ten Berge, J. M. F.  (1989).  Least-squares
approximation of an improper correlation matrix by a proper one.
Psychometrika, 54(1), 53-61.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRKtB)

</code></pre>

<hr>
<h2 id='BadRLG'>Improper R matrix reported by Lurie and Goldberg</h2><span id='topic+BadRLG'></span>

<h3>Description</h3>

<p>Example improper R matrix reported by Lurie and Goldberg
</p>


<h3>Format</h3>

<p>A 3 by 3 non-positive definite correlation matrix.
</p>


<h3>Source</h3>

<p>Lurie, P. M. &amp; Goldberg, M. S. (1998). An approximate method for
sampling correlated random variables from partially-specified distributions.
Management Science, 44(2), 203&ndash;218.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRLG)

</code></pre>

<hr>
<h2 id='BadRRM'>Improper R matrix reported by Rousseeuw and Molenberghs</h2><span id='topic+BadRRM'></span>

<h3>Description</h3>

<p>Example improper R matrix reported by Rousseeuw and Molenberghs
</p>


<h3>Format</h3>

<p>A 3 by 3 non-positive definite correlation matrix.
</p>


<h3>Source</h3>

<p>Rousseeuw, P. J. &amp; Molenberghs, G. (1993). Transformation of non
positive semidefinite correlation matrices. Communications in
Statistics&ndash;Theory and Methods, 22(4), 965&ndash;984.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRRM)

</code></pre>

<hr>
<h2 id='BiFAD'>Bifactor Analysis via Direct Schmid-Leiman (DSL) Transformations</h2><span id='topic+BiFAD'></span>

<h3>Description</h3>

<p>This function estimates the (rank-deficient) Direct Schmid-Leiman (DSL) bifactor solution as well as the (full-rank) Direct Bifactor (DBF) solution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BiFAD(
  R,
  B = NULL,
  numFactors = NULL,
  facMethod = "fals",
  rotate = "oblimin",
  salient = 0.25,
  rotateControl = NULL,
  faControl = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BiFAD_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix.</p>
</td></tr>
<tr><td><code id="BiFAD_+3A_b">B</code></td>
<td>
<p>(Matrix) Bifactor target matrix. If B is NULL the program will create an empirically defined target matrix.</p>
</td></tr>
<tr><td><code id="BiFAD_+3A_numfactors">numFactors</code></td>
<td>
<p>(Numeric) The number of group factors to estimate.</p>
</td></tr>
<tr><td><code id="BiFAD_+3A_facmethod">facMethod</code></td>
<td>
<p>(Character) The method used for factor extraction 
(<code><a href="#topic+faX">faX</a></code>). The supported options are &quot;fals&quot; for unweighted least 
squares, &quot;faml&quot; for maximum likelihood, &quot;fapa&quot; for iterated principal axis 
factoring, &quot;faregLS&quot; for regularized least squares,
&quot;faregML&quot; for regularized maximum likelihood, and &quot;pca&quot; for principal components 
analysis. The default method  is &quot;fals&quot;. 
</p>

<ul>
<li> <p><strong>&quot;fals&quot;</strong>: Factors are extracted using the unweighted least 
squares estimation procedure using the <code><a href="#topic+fals">fals</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faml&quot;</strong>: Factors are extracted using the maximum likelihood 
estimation procedure using the <code><a href="stats.html#topic+factanal">factanal</a></code> function.
</p>
</li>
<li> <p><strong>&quot;fapa&quot;</strong>: Factors are extracted using the iterated principal 
axis factoring estimation procedure using the <code><a href="#topic+fapa">fapa</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faregLS&quot;</strong>: Factors are extracted using regularized 
least squares factor analysis using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;faregML&quot;</strong>: Factors are extracted using regularized 
maximum likelihood factor using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;pca&quot;</strong>: Principal components are extracted. 
</p>
</li></ul>
</td></tr>
<tr><td><code id="BiFAD_+3A_rotate">rotate</code></td>
<td>
<p>(Character) Designate which rotation algorithm to apply. See the <code><a href="#topic+faMain">faMain</a></code> function for more details about possible rotations. An oblimin rotation is the default.</p>
</td></tr>
<tr><td><code id="BiFAD_+3A_salient">salient</code></td>
<td>
<p>(Numeric) Threshold value for creating an empirical target matrix.</p>
</td></tr>
<tr><td><code id="BiFAD_+3A_rotatecontrol">rotateControl</code></td>
<td>
<p>(List) A list of control values to pass to the factor rotation algorithms.
</p>

<ul>
<li> <p><strong>numberStarts</strong>: (Numeric) The number of random (orthogonal) 
starting configurations for the chosen rotation method (e.g., oblimin). The first
rotation will always commence from the unrotated factors orientation.
Defaults to numberStarts = 10. 
</p>
</li>
<li> <p><strong>gamma</strong>: (Numeric) This is a tuning parameter (between 0 
and 1, inclusive) for an oblimin rotation.  See the <span class="pkg">GPArotation</span> 
library's oblimin documentation for more details. Defaults to gamma = 0 
(i.e., a quartimin rotation).
</p>
</li>
<li> <p><strong>delta</strong>: (Numeric) This is a tuning parameter for the geomin
rotation. It adds a small number (default = .01) to the squared factor 
loadings before computing the geometric means in the discrepancy function.
</p>
</li>
<li> <p><strong>kappa</strong>: (Numeric) The main parameterization of the 
Crawford-Ferguson (CF) rotations (i.e., &quot;cfT&quot; and &quot;cfQ&quot; for orthogonal and 
oblique CF rotation, respectively). Defaults to kappa = 0. 
</p>
</li>
<li> <p><strong>k</strong>: (Numeric) A specific parameter of the simplimax rotation. 
Defaults to k = the number of observed variables.
</p>
</li>
<li> <p><strong>standardize</strong>: (Character) The standardization routine used 
on the unrotated factor structure. The three options are &quot;none&quot;, &quot;Kaiser&quot;, 
and &quot;CM&quot;. Defaults to standardize = &quot;none&quot;. 
</p>

<ul>
<li> <p><strong>&quot;none&quot;</strong>: No standardization is applied to the unrotated 
factor structure. 
</p>
</li>
<li> <p><strong>&quot;Kaiser&quot;</strong>: Use a factor structure matrix that has been 
normed by Kaiser's method (i.e., normalize all rows to have a unit length).
</p>
</li>
<li> <p><strong>&quot;CM&quot;</strong>: Use a factor structure matrix that has been normed
by the Cureton-Mulaik method.
</p>
</li></ul>

</li>
<li> <p><strong>epsilon</strong>: (Numeric) The rotational convergence criterion to 
use. Defaults to epsilon = 1e-5.
</p>
</li>
<li> <p><strong>power</strong>: (Numeric) Raise factor loadings the the n-th power 
in the <code><a href="#topic+promaxQ">promaxQ</a></code> rotation. Defaults to power = 4.
</p>
</li>
<li> <p><strong>maxItr</strong>: (Numeric) The maximum number of iterations for the 
rotation algorithm. Defaults to maxItr = 15000.
</p>
</li></ul>
</td></tr>
<tr><td><code id="BiFAD_+3A_facontrol">faControl</code></td>
<td>
<p>(List) A list of optional parameters passed to the factor 
extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>

<ul>
<li> <p><strong>treatHeywood</strong>: (Logical) In <code>fals</code>, if treatHeywood is 
true, a penalized least squares function is used to bound the communality 
estimates below 1.0. Defaults to treatHeywood = TRUE.
</p>
</li>
<li> <p><strong>nStart</strong>: (Numeric) The number of starting values to be tried 
in <code>faml</code>. Defaults to nStart = 10.
</p>
</li>
<li> <p><strong>start</strong>: (Matrix) NULL or a matrix of starting values, each column 
giving an initial set of uniquenesses. Defaults to start = NULL. 
</p>
</li>
<li> <p><strong>maxCommunality</strong>: (Numeric) In <code>faml</code>, set the maximum 
communality value for the estimated solution. Defaults to maxCommunality = .995.
</p>
</li>
<li> <p><strong>epsilon</strong>: (Numeric) In <code>fapa</code>, the numeric threshold 
designating when the algorithm has converged. Defaults to epsilon = 1e-4.
</p>
</li>
<li> <p><strong>communality</strong>: (Character) The method used to estimate the 
initial communality values in <code>fapa</code>. Defaults to communality = 'SMC'.
</p>

<ul>
<li> <p><strong>&quot;SMC&quot;</strong>: Initial communalities are estimated by taking the 
squared multiple correlations of each indicator after regressing the 
indicator on the remaining variables.
</p>
</li>
<li> <p><strong>&quot;maxr&quot;</strong>: Initial communalities equal the largest 
(absolute value) correlation in each column of the correlation matrix.
</p>
</li>
<li> <p><strong>&quot;unity&quot;</strong>: Initial communalities equal 1.0 for all variables.
</p>
</li></ul>

</li>
<li> <p><strong>maxItr</strong>: (Numeric) In <code>fapa</code>, the maximum number of 
iterations to reach convergence. Defaults to maxItr = 15,000.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>The following output are returned in addition to the estimated Direct Schmid-Leiman bifactor solution.
</p>

<ul>
<li> <p><strong>B</strong>: (Matrix) The target matrix used for the Procrustes rotation.
</p>
</li>
<li> <p><strong>BstarSL</strong>: (Matrix) The resulting (rank-deficient) matrix of Direct Schmid-Leiman factor loadings.
</p>
</li>
<li> <p><strong>BstarFR</strong>: (Matrix) The resulting (full-rank) matrix of Direct Bifactor factor loadings.
</p>
</li>
<li> <p><strong>rmsrSL</strong>: (Scalar) The root mean squared residual (rmsr) between the known B matrix and the estimated (rank-deficient) Direct Schmid-Leiman rotation. If the B target matrix is empirically generated, this value is NULL.
</p>
</li>
<li> <p><strong>rmsrFR</strong>: (Scalar) The root mean squared residual (rmsr) between the known B matrix and the estimated (full-rank) Direct Bifactor rotation. If the B target matrix is empirically generated, this value is NULL.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>


<ul>
<li><p> Giordano, C. &amp; Waller, N. G. (under review). Recovering bifactor models: A comparison of seven methods.
</p>
</li>
<li><p> Mansolf, M., &amp; Reise, S. P. (2016). Exploratory bifactor analysis: The Schmid-Leiman orthogonalization and Jennrich-Bentler analytic rotations. <em>Multivariate Behavioral Research, 51</em>(5), 698-717.
</p>
</li>
<li><p> Waller, N. G. (2018). Direct Schmid Leiman transformations and rank deficient loadings matrices. <em>Psychometrika, 83</em>, 858-870.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cat("\nExample 1:\nEmpirical Target Matrix:\n")
# Mansolf and Reise Table 2 Example
Btrue &lt;- matrix(c(.48, .40,  0,   0,   0,
                  .51, .35,  0,   0,   0,
                  .67, .62,  0,   0,   0,
                  .34, .55,  0,   0,   0,
                  .44,  0, .45,   0,   0,
                  .40,  0, .48,   0,   0,
                  .32,  0, .70,   0,   0,
                  .45,  0, .54,   0,   0,
                  .55,  0,   0, .43,   0,
                  .33,  0,   0, .33,   0,
                  .52,  0,   0, .51,   0,
                  .35,  0,   0, .69,   0,
                  .32,  0,   0,   0, .65,
                  .66,  0,   0,   0, .51,
                  .68,  0,   0,   0, .39,
                  .32,  0,   0,   0, .56), 16, 5, byrow=TRUE)

Rex1 &lt;- Btrue %*% t(Btrue)
diag(Rex1) &lt;- 1

out.ex1 &lt;- BiFAD(R          = Rex1,
                 B          = NULL,
                 numFactors = 4,
                 facMethod  = "fals",
                 rotate     = "oblimin",
                 salient    = .25)

cat("\nRank Deficient Bifactor Solution:\n")
print( round(out.ex1$BstarSL, 2) )

cat("\nFull Rank Bifactor Solution:\n")
print( round(out.ex1$BstarFR, 2) )

cat("\nExample 2:\nUser Defined Target Matrix:\n")

Bpattern &lt;- matrix(c( 1,  1,  0,   0,   0,
                      1,  1,  0,   0,   0,
                      1,  1,  0,   0,   0,
                      1,  1,  0,   0,   0,
                      1,  0,  1,   0,   0,
                      1,  0,  1,   0,   0,
                      1,  0,  1,   0,   0,
                      1,  0,  1,   0,   0,
                      1,  0,   0,  1,   0,
                      1,  0,   0,  1,   0,
                      1,  0,   0,  1,   0,
                      1,  0,   0,  1,   0,
                      1,  0,   0,   0,  1,
                      1,  0,   0,   0,  1,
                      1,  0,   0,   0,  1,
                      1,  0,   0,   0,  1), 16, 5, byrow=TRUE)

out.ex2 &lt;- BiFAD(R          = Rex1,
                 B          = Bpattern,
                 numFactors = NULL,
                 facMethod  = "fals",
                 rotate     = "oblimin",
                 salient    = .25)

cat("\nRank Deficient Bifactor Solution:\n")
print( round(out.ex2$BstarSL, 2) )

cat("\nFull Rank Bifactor Solution:\n")
print( round(out.ex2$BstarFR, 2) )

</code></pre>

<hr>
<h2 id='bigen'>Generate Correlated Binary Data</h2><span id='topic+bigen'></span>

<h3>Description</h3>

<p>Function for generating binary data with population thresholds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bigen(data, n, thresholds = NULL, Smooth = FALSE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bigen_+3A_data">data</code></td>
<td>
<p>Either a matrix of binary (0/1) indicators or a correlation
matrix.</p>
</td></tr>
<tr><td><code id="bigen_+3A_n">n</code></td>
<td>
<p>The desired sample size of the simulated data.</p>
</td></tr>
<tr><td><code id="bigen_+3A_thresholds">thresholds</code></td>
<td>
<p>If data is a correlation matrix, thresholds must be a
vector of threshold cut points.</p>
</td></tr>
<tr><td><code id="bigen_+3A_smooth">Smooth</code></td>
<td>
<p>(logical) Smooth = TRUE will smooth the tetrachoric correltion
matrix.</p>
</td></tr>
<tr><td><code id="bigen_+3A_seed">seed</code></td>
<td>
<p>Default = FALSE. Optional seed for random number generator.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>data</code></td>
<td>
<p>Simulated binary data</p>
</td></tr> <tr><td><code>r</code></td>
<td>
<p>Input or calculated
(tetrachoric) correlation matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels G Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example: generating binary data to match
## an existing binary data matrix
##
## Generate correlated scores using factor 
## analysis model
## X &lt;- Z *L' + U*D 
## Z is a vector of factor scores
## L is a factor loading matrix
## U is a matrix of unique factor scores
## D is a scaling matrix for U

N &lt;- 5000

# Generate data from a single factor model
# factor patter matrix
L &lt;- matrix( rep(.707, 5), nrow = 5, ncol = 1)

# common factor scores
Z &lt;- as.matrix(rnorm(N))

# unique factor scores
U &lt;- matrix(rnorm(N *5), nrow = N, ncol = 5)
D &lt;- diag(as.vector(sqrt(1 - L^2)))

# observed scores
X &lt;- Z %*% t(L) + U %*% D

cat("\nCorrelation of continuous scores\n")
print(round(cor(X),3))

# desired difficulties (i.e., means) of 
# the dichotomized scores
difficulties &lt;- c(.2, .3, .4, .5, .6)

# cut the observed scores at these thresholds
# to approximate the above difficulties
thresholds &lt;- qnorm(difficulties)

Binary &lt;- matrix(0, N, ncol(X))
for(i in 1:ncol(X)){
  Binary[X[,i] &lt;= thresholds[i],i] &lt;- 1
}   

cat("\nCorrelation of Binary scores\n")
print(round(cor(Binary), 3))

## Now use 'bigen' to generate binary data matrix with 
## same correlations as in Binary

z &lt;- bigen(data = Binary, n = N)

cat("\n\nnames in returned object\n")
print(names(z))

cat("\nCorrelation of Simulated binary scores\n")
print(round(cor(z$data), 3))


cat("Observed thresholds of simulated data:\n")
cat(apply(z$data, 2, mean))
</code></pre>

<hr>
<h2 id='Boruch70'>Multi-Trait Multi-Method correlation matrix reported by Boruch, Larkin, Wolins, and MacKinney (1970)</h2><span id='topic+Boruch70'></span>

<h3>Description</h3>

<p>The original study assessed supervisors on seven dimensions (i.e., 7 
variables) from two sources (i.e., their least effective and most effective subordinate).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Boruch70)
</code></pre>


<h3>Format</h3>

<p>A 14 by 14 correlation matrix with dimension names
</p>


<h3>Details</h3>

<p>The sample size is <em>n</em> = 111.
</p>
<p>The following variables were assessed:
<strong>Variables</strong>:
</p>

<ol>
<li><p> Consideration
</p>
</li>
<li><p> Structure
</p>
</li>
<li><p> Satisfaction with the supervisor
</p>
</li>
<li><p> Job satisfaction
</p>
</li>
<li><p> General effectiveness
</p>
</li>
<li><p> Human relations skill
</p>
</li>
<li><p> Leadership
</p>
</li></ol>

<p>The test structure is as follows:
<strong>Test Structure</strong>:
</p>

<ul>
<li><p> Test One: variables 1 through 7
</p>
</li>
<li><p> Test Two: variables 8 through 14
</p>
</li></ul>



<h3>Source</h3>

<p>Boruch, R. F., Larkin, J. D., Wolins, L., and MacKinney, A. C. (1970). 
Alternative methods of analysis: Multitrait multimethod data. <em>Educational 
and Psychological Measurement, 30</em>, 833-853.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load Boruch et al.'s dataset
data(Boruch70)

Example4Output &lt;- faMB(R             = Boruch70,
                       n             = 111,
                       NB            = 2,
                       NVB           = c(7,7),
                       numFactors    = 2,
                       rotate        = "oblimin",
                       rotateControl = list(standardize  = "Kaiser",
                                            numberStarts = 100))
                                            
summary(Example4Output, digits = 3)                                             
</code></pre>

<hr>
<h2 id='Box20'>Length, width, and height measurements for Thurstone's 20 boxes</h2><span id='topic+Box20'></span>

<h3>Description</h3>

<p>Length, width, and height measurements for Thurstone's 20 hypothetical boxes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Box20)
</code></pre>


<h3>Format</h3>

<p>A data set of measurements for Thurstone's 20 hypothetical boxes. 
The data set includes three variables:
</p>

<ul>
<li> <p><strong>x</strong> Box length
</p>
</li>
<li> <p><strong>y</strong> Box width
</p>
</li>
<li> <p><strong>z</strong> Box height
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(Box20)

hist(Box20$x,
     main = "Histogram of Box Lengths",
     xlab = "Length",
     col = "blue")

# To create the raw data for Thurstone's 20 hypothetical 
# box attributes:
data(Box20)
 ThurstoneBox20 &lt;- GenerateBoxData(XYZ = Box20,
                                 BoxStudy = 20,
                                 Reliability = 1,
                                 ModApproxErrVar = 0)$BoxData  

RThurstoneBox20 &lt;- cor(ThurstoneBox20)   

# Smooth matrix to calculate factor indeterminacy values
RsmThurstoneBox20 &lt;- smoothBY(RThurstoneBox20)$RBY

fout &lt;- faMain(R = RsmThurstoneBox20,
              numFactors = 3,
              rotate = "varimax",
              facMethod = "faregLS",
              rotateControl = list(numberStarts = 100,
                                   maxItr =15000))
summary(fout, digits=3)

# Note that given the small ratio of subjects to variables,
# it is not possible to generate data for this example with model error 
# (unless SampleSize is increased).
</code></pre>

<hr>
<h2 id='Box26'>R matrix for Thurstone's 26 hypothetical box attributes.</h2><span id='topic+Box26'></span>

<h3>Description</h3>

<p>Correlation matrix for Thurstone's 26 hypothetical box attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Box26)
</code></pre>


<h3>Format</h3>

<p>Correlation matrix for Thurstone's 26 hypothetical box attributes. 
The so-called Thurstone invariant box problem contains measurements on the 
following 26 functions of length, width, and height. 
<strong>Box26</strong> variables:
</p>

<ol>
<li><p> x
</p>
</li>
<li><p> y
</p>
</li>
<li><p> z
</p>
</li>
<li><p> xy 
</p>
</li>
<li><p> xz
</p>
</li>
<li><p> yz 
</p>
</li>
<li><p> x^2 * y
</p>
</li>
<li><p> x * y^2
</p>
</li>
<li><p> x^2 * z
</p>
</li>
<li><p> x * z^ 2
</p>
</li>
<li><p> y^2 * z
</p>
</li>
<li><p> y * z^2
</p>
</li>
<li><p> x/y
</p>
</li>
<li><p> y/x
</p>
</li>
<li><p> x/z
</p>
</li>
<li><p>  z/x
</p>
</li>
<li><p>  y/z
</p>
</li>
<li><p>  z/y
</p>
</li>
<li><p> 2x + 2y
</p>
</li>
<li><p> 2x + 2z
</p>
</li>
<li><p> 2y + 2z
</p>
</li>
<li><p> sqrt(x^2 + y^2)
</p>
</li>
<li><p> sqrt(x^2 + z^2)
</p>
</li>
<li><p> sqrt(y^2 + z^2)
</p>
</li>
<li><p> xyz
</p>
</li>
<li><p> sqrt(x^2 + y^2 + z^2)
</p>
</li></ol>


<ul>
<li> <p><strong>x</strong> Box length
</p>
</li>
<li> <p><strong>y</strong> Box width
</p>
</li>
<li> <p><strong>z</strong> Box height
</p>
</li></ul>



<h3>Details</h3>

<p>Two data sets have been described in the literature as Thurstone's Box Data 
(or Thurstone's Box Problem). The first consists of 20 measurements on a set of 20 
hypothetical boxes (i.e., Thurstone made up the data).  Those data are available 
in <strong>Box20</strong>. The second data set,  which is described in this help file, was collected by 
Thurstone to provide an illustration of the invariance of simple structure 
factor loadings. In his classic textbook on multiple factor analysis 
(Thurstone, 1947), Thurstone states that &ldquo;[m]easurements of a random collection 
of thirty boxes were actually made in the Psychometric Laboratory and recorded 
for this numerical example. The three dimensions, x, y, and z, were recorded 
for each box. A list of 26 arbitrary score functions was then prepared&rdquo; (p. 369). The 
raw data for this example were not published.  Rather, Thurstone reported a 
correlation matrix for the 26 score functions (Thurstone, 1947, p. 370). Note that, presumably 
due to rounding error in the reported correlations, the correlation matrix 
for this example is non positive definite.
</p>


<h3>References</h3>

<p>Thurstone, L. L.  (1947).  Multiple factor analysis.  Chicago: University of Chicago Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Box20">Box20</a></code>, <code><a href="#topic+AmzBoxes">AmzBoxes</a></code>
</p>
<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Box26)
fout &lt;- faMain(R     = Box26,
               numFactors    = 3,
               facMethod     = "faregLS",
               rotate        = "varimax",
               bootstrapSE   = FALSE,
        rotateControl = list(
               numberStarts = 100,  
               standardize  = "none"),
               Seed = 123)

summary(fout)  
    
# We now choose Cureton-Mulaik row standardization to reveal 
# the underlying factor structure. 
          
fout &lt;- faMain(R     = Box26,
               numFactors    = 3,
               facMethod     = "faregLS",
               rotate        = "varimax",
               bootstrapSE   = FALSE,
        rotateControl = list(
               numberStarts = 100,  
               standardize  = "CM"),
               Seed = 123)

summary(fout)  


</code></pre>

<hr>
<h2 id='cb'>Cudeck &amp; Browne (1992) model error method</h2><span id='topic+cb'></span>

<h3>Description</h3>

<p>Generate a population correlation matrix using the model described in Cudeck
and Browne (1992). This function uses the implementation of the Cudeck and
Browne method from Ken Kelley's MBESS package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cb(mod, target_rmsea)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cb_+3A_mod">mod</code></td>
<td>
<p>A 'fungible::simFA()' model object.</p>
</td></tr>
<tr><td><code id="cb_+3A_target_rmsea">target_rmsea</code></td>
<td>
<p>(scalar) Target RMSEA value.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cudeck, R., &amp; Browne, M. W. (1992). Constructing a covariance
matrix that yields a specified minimizer and a specified minimum
discrepancy function value. *Psychometrika*, *57*(3), 357369.
&lt;https://doi.org/10/cq6ckd&gt;
</p>
<p>Kelley, K. (2017). MBESS (Version 4.0.0 and higher)
[computer software and manual]. Accessible from http://cran.r-project.org.
</p>

<hr>
<h2 id='cfi'>Calculate CFI for two correlation matrices</h2><span id='topic+cfi'></span>

<h3>Description</h3>

<p>Given two correlation matrices of the same dimension, calculate the CFI value
value using the independence model as the null model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cfi(Sigma, Omega)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cfi_+3A_sigma">Sigma</code></td>
<td>
<p>(matrix) Population correlation or covariance matrix (with model
error).</p>
</td></tr>
<tr><td><code id="cfi_+3A_omega">Omega</code></td>
<td>
<p>(matrix) Model-implied population correlation or covariance
matrix.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(fungible)

mod &lt;- fungible::simFA(Model = list(NFac = 3),
                       Seed = 42)
set.seed(42)
Omega &lt;- mod$Rpop
Sigma &lt;- noisemaker(
  mod = mod,
  method = "CB",
  target_rmsea = 0.05
)$Sigma
cfi(Sigma, Omega)
</code></pre>

<hr>
<h2 id='CompleteRcvx'>Complete a Partially Specified Correlation Matrix by Convex Optimization</h2><span id='topic+CompleteRcvx'></span>

<h3>Description</h3>

<p>This function completes a partially specified
correlation matrix by the method of convex optimization.  The completed
matrix will maximize the log(det(R)) over the space of PSD R matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CompleteRcvx(Rna, Check_Convexity = TRUE, PRINT = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompleteRcvx_+3A_rna">Rna</code></td>
<td>
<p>(matrix) An n x n incomplete correlation matrix.  Missing entries must
be specified by <code>NA</code> values.</p>
</td></tr>
<tr><td><code id="CompleteRcvx_+3A_check_convexity">Check_Convexity</code></td>
<td>
<p>(logical)  If <code>Check_Convexity= FALSE</code> the
program will not check the convexity of the objective function.  Since the
convexity of the R completion problem is known to be true, setting this argument
to FALSE can decrease computation time.</p>
</td></tr>
<tr><td><code id="CompleteRcvx_+3A_print">PRINT</code></td>
<td>
<p>(logical)  If <code>PRINT = TRUE</code> then the program will print the
convergence status of the final solution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>CompleteCvxR</code> function returns the following objects.
</p>

<ul>
<li>  <p><strong>R</strong> (matrix) A PSD completed correlation matrix.
</p>
</li>
<li>  <p><strong>converged</strong>: (Logical) a logical that indicates the convergence status of the optimization.
</p>
</li>
<li>  <p><strong>max_delta</strong> The maximum absolute difference between the
known elements in the partially specified R matrix and the estimated matrix.
</p>
</li>
<li> <p><strong>convergence_status</strong> (list) A list containing additional information about the convergence status of the solution.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Georgescu, D. I., Higham, N. J., and Peters, G. W.  (2018).  Explicit
solutions to correlation matrix completion problems, with
an application to risk management and insurance.  Royal Society Open
Science, 5(3), 172348.
</p>
<p>Olvera Astivia, O. L. (2021). A Note on the general solution to completing
partially specified correlation matrices. Measurement: Interdisciplinary
Research and Perspectives, 19(2), 115&ndash;123.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  Rmiss &lt;- matrix(
    c( 1,  .25, .6,  .55, .65,  0,  .4,   .6,  .2,  .3,
       .25, 1,    0,   0,   0,   0,  NA,   NA,  NA,  NA,
       .6,  0,   1,   .75, .75,  0,  NA,   NA,  NA,  NA,
       .55, 0,   .75, 1,   .5,   0,  NA,   NA,  NA,  NA,
       .65, 0,   .75,  .5, 1,    0,  NA,   NA,  NA,  NA,
       0,  0,    0,   0,   0,  1,   NA,   NA,  NA,  NA,
       .4, NA,   NA,  NA,  NA,  NA, 1,   .25, .25,  .5,
       .6, NA,   NA,  NA,  NA,  NA, .25,  1,  .25,  0,
       .2, NA,   NA,  NA,  NA,  NA, .25,  .25, 1,   0,
       .3, NA,   NA,  NA,  NA,  NA, .5,    0,   0,  1), 10,10)

  out &lt;- CompleteRcvx(Rna = Rmiss,
                      Check_Convexity = FALSE,
                      PRINT = FALSE)

  round(out$R, 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='CompleteRdev'>Complete a Partially Specified Correlation Matrix by the Method of Differential Evolution</h2><span id='topic+CompleteRdev'></span>

<h3>Description</h3>

<p>This function completes a partially specified
correlation matrix by the method of differential evolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CompleteRdev(
  Rna,
  NMatrices = 1,
  MaxDet = FALSE,
  MaxIter = 200,
  delta = 1e-08,
  PRINT = FALSE,
  Seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompleteRdev_+3A_rna">Rna</code></td>
<td>
<p>(matrix) An n x n incomplete correlation matrix.  Missing entries must
be specified by <code>NA</code> values.</p>
</td></tr>
<tr><td><code id="CompleteRdev_+3A_nmatrices">NMatrices</code></td>
<td>
<p>(integer) <code>CompleteRDEV</code> will complete <code>NMatrices</code>
correlation matrices.</p>
</td></tr>
<tr><td><code id="CompleteRdev_+3A_maxdet">MaxDet</code></td>
<td>
<p>(logical) If MaxDet = TRUE then the correlation matrix will
be completed with entries that maximize the determinant of R.</p>
</td></tr>
<tr><td><code id="CompleteRdev_+3A_maxiter">MaxIter</code></td>
<td>
<p>(integer) The maximum number of iterations
(i.e., generations) allowed. Default <code>MaxIter = 200</code>.</p>
</td></tr>
<tr><td><code id="CompleteRdev_+3A_delta">delta</code></td>
<td>
<p>(numeric &gt; 0) A number that controls the convergence
accuracy of the differential evolution algorithm. Default <code>delta = 1E-8</code>.</p>
</td></tr>
<tr><td><code id="CompleteRdev_+3A_print">PRINT</code></td>
<td>
<p>(logical) When PRINT = TRUE the algorithm convergence status is printed.
Default  <code>PRINT = FALSE</code>.</p>
</td></tr>
<tr><td><code id="CompleteRdev_+3A_seed">Seed</code></td>
<td>
<p>(integer) Initial random number seed. Default (<code>Seed = NULL</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>CompleteRdev</code> returns the following objects:
</p>

<ul>
<li>  <p><strong>R</strong> (matrix) A PSD completed correlation matrix.
</p>
</li>
<li>  <p><strong>converged</strong>: (logical) a logical that indicates the convergence status of the optimizaton.
</p>
</li>
<li> <p><strong>iter</strong> (integer) The number of cycles needed to reach converged solution.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Ardia, D., Boudt, K., Carl, P., Mullen, K.M., Peterson, B.G. (2011) Differential
Evolution with DEoptim. An Application to Non-Convex Portfolio Optimization.
URL The R Journal, 3(1), 27-34.
URL https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Ardia~et~al.pdf.
</p>
<p>Georgescu, D. I., Higham, N. J., and Peters, G. W.  (2018).  Explicit
solutions to correlation matrix completion problems, with
an application to risk management and insurance.  Royal Society Open
Science, 5(3), 172348.
</p>
<p>Mauro, R.  (1990).  Understanding L.O.V.E. (left out variables
error): a method for estimating the effects of omitted variables.
Psychological Bulletin, 108(2), 314-329.
</p>
<p>Mishra, S. K.  (2007).  Completing correlation matrices
of arbitrary order by differential evolution method of global optimization:
a Fortran program.  Available at SSRN 968373.
</p>
<p>Mullen, K.M, Ardia, D., Gil, D., Windover, D., Cline, J. (2011). DEoptim: An
R Package for Global Optimization by Differential Evolution. Journal of Statistical Software, 40(6), 1-26. URL http://www.jstatsoft.org/v40/i06/.
</p>
<p>Price, K.V., Storn, R.M., Lampinen J.A. (2005) Differential Evolution - A Practical Approach to Global Optimization. Berlin Heidelberg:
Springer-Verlag. ISBN 3540209506.
</p>
<p>Zhang, J. and Sanderson, A. (2009) Adaptive Differential
Evolution Springer-Verlag. ISBN 978-3-642-01526-7
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1: Generate random 4 x 4 Correlation matrices.
  Rmiss &lt;- matrix(NA, nrow = 4, ncol = 4)
  diag(Rmiss) &lt;- 1

  out &lt;- CompleteRdev(Rna = Rmiss,
                      NMatrices = 4,
                      PRINT = TRUE,
                      Seed = 1)

  print( round( out$R[[1]] , 3) )

## Not run: 
# Example 2: Complete a partially specified R matrix.
# Example from Georgescu, D. I., Higham, N. J., and
#              Peters, G. W.  (2018).

Rmiss &lt;- matrix(
     c( 1,  .25, .6,  .55, .65,  0,  .4,   .6,  .2,  .3,
       .25, 1,    0,   0,   0,   0,  NA,   NA,  NA,  NA,
       .6,  0,   1,   .75, .75,  0,  NA,   NA,  NA,  NA,
       .55, 0,   .75, 1,   .5,   0,  NA,   NA,  NA,  NA,
       .65, 0,   .75,  .5, 1,    0,  NA,   NA,  NA,  NA,
        0,  0,    0,   0,   0,  1,   NA,   NA,  NA,  NA,
        .4, NA,   NA,  NA,  NA,  NA, 1,   .25, .25,  .5,
        .6, NA,   NA,  NA,  NA,  NA, .25,  1,  .25,  0,
        .2, NA,   NA,  NA,  NA,  NA, .25,  .25, 1,   0,
        .3, NA,   NA,  NA,  NA,  NA, .5,    0,   0,  1), 10,10)

# Complete Rmiss with values that maximize
# the matrix determinant (this is the MLE solution)
 set.seed(123)
 out &lt;- CompleteRdev(Rna = Rmiss,
                     MaxDet = TRUE,
                     MaxIter = 1000,
                     delta = 1E-8,
                     PRINT = FALSE)

cat("\nConverged = ", out$converged,"\n")
print( round(out$R, 3))
print( det(out$R))
print( eigen(out$R)$values, digits = 5)

## End(Not run)

</code></pre>

<hr>
<h2 id='CompleteRmap'>Complete a Partially Specified Correlation Matrix by the Method of Alternating Projections</h2><span id='topic+CompleteRmap'></span>

<h3>Description</h3>

<p>This function completes a (possibly) partially specified
correlation matrix by a modified alternating projections algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CompleteRmap(
  Rna,
  NMatrices = 1,
  RBounds = FALSE,
  LB = -1,
  UB = 1,
  delta = 1e-16,
  MinLambda = 0,
  MaxIter = 1000,
  detSort = FALSE,
  Parallel = FALSE,
  ProgressBar = FALSE,
  PrintLevel = 0,
  Digits = 3,
  Seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompleteRmap_+3A_rna">Rna</code></td>
<td>
<p>(matrix) An n x n incomplete correlation matrix.  Missing entries must
be specified by NA values. If all off diagonal values are NA then the function
will generate a random correlation matrix.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_nmatrices">NMatrices</code></td>
<td>
<p>(integer) <code>CompleteRmap</code> will complete <code>NMatrices</code>
correlation matrices.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_rbounds">RBounds</code></td>
<td>
<p>(logical) If <code>RBounds = TRUE</code> then the function will attempt to
produce a matrix on the surface of the associated elliptope (i.e., the space of all
possible PSD R matrices of a given dimension).
When <code>RBounds = FALSE</code>, during each cycle of the alternating projections
algorithm all negative eigenvalues of the provisional R matrix are replaced by
(sorted) uniform random numbers between the smallest positive eigenvalue and zero (inclusive) of the indefinite matrix.
Default <code>RBounds = FALSE</code>.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_lb">LB</code></td>
<td>
<p>(numeric) The lower bound for the random number generator when generating
initial estimates for the missing elements of a partially specified correlation matrix.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_ub">UB</code></td>
<td>
<p>(numeric) The upper bound for the random number generator when generating
initial estimates for the missing elements of a partially specified correlation matrix. Start values
(for missing correlations) are sampled from a uniform distribution with bounds <code>[LB, UB]</code>.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_delta">delta</code></td>
<td>
<p>(numeric) A small number that controls the precision of the estimated solution.
Default <code>delta = 1E-16</code>.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_minlambda">MinLambda</code></td>
<td>
<p>(numeric) A small value greater than or equal to 0  used to replace negative
eigenvalues during the modified alternating projections algorithm.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_maxiter">MaxIter</code></td>
<td>
<p>(integer) The maximum number of cycles of the
alternating projections algorithm. Default <code>MaxIter = 1000</code>.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_detsort">detSort</code></td>
<td>
<p>(logical). If <code>detSort = TRUE</code> then all results will be sorted
according to the sizes of the matrix determinants (det(Ri)). Default <code>detSort = FALSE</code></p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_parallel">Parallel</code></td>
<td>
<p>(logical). If <code>Parallel = TRUE</code> parallel processing will be used to
generate the completed correlation matrices. Default:  <code>Parallel = FALSE</code>.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_progressbar">ProgressBar</code></td>
<td>
<p>(logical).  If <code>Parallel = TRUE</code> and <code>ProgressBar = TRUE</code> a progress bar
will be printed to screen. Default <code>ProgressBar = FALSE</code>.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(integer) The <code>PrintLevel</code> argument can take one of three values:
</p>

<ul>
<li><p> 0  No output will be printed. Default (PrintLevel = 0).
</p>
</li>
<li><p> 1  Print <code>Delta</code> and the minimum eigenvalue of the currently completed correlation matrix.
</p>
</li>
<li><p> 2  Print convergence history.
</p>
</li></ul>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_digits">Digits</code></td>
<td>
<p>(integer) Controls the number of printed significant digits if PrintLevel = 2.</p>
</td></tr>
<tr><td><code id="CompleteRmap_+3A_seed">Seed</code></td>
<td>
<p>(integer) Initial random number seed. If reproducible results are desired then
it is necessary to specify  <code>ProgressBar = FALSE</code>. Default <code>Seed = NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li>  <p><strong>CALL</strong> The function call.
</p>
</li>
<li> <p><strong>NMatrices</strong> The number of completed R matrices.
</p>
</li>
<li> <p><strong>Rna</strong> The input partially specified R matrix.
</p>
</li>
<li>  <p><strong>Ri</strong> A list of the completed R matrices.
</p>
</li>
<li> <p><strong>RiEigs</strong> A list of eigenvalues for each <code>Ri</code>.
</p>
</li>
<li> <p><strong>RiDet</strong>  A list of the determinants for each <code>Ri</code>.
</p>
</li>
<li> <p><strong>converged</strong> The convergence status (TRUE/FALSE) for each <code>Ri</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Higham, N. J.  (2002).  Computing the nearest correlation matrix: A problem
from finance.  IMA Journal of Numerical Analysis, 22(3), 329&ndash;343.
</p>
<p>Waller, N. G.  (2020).  Generating correlation matrices with specified
eigenvalues using the method of alternating projections.
The American Statistician, 74(1), 21-28.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Rna4 &lt;- matrix(c( 1,  NA,  .29, .18,
                  NA, 1,   .11, .24,
                 .29, .11, 1,   .06,
                 .18, .24, .06, 1), 4, 4)

Out4  &lt;- CompleteRmap(Rna = Rna4,
                      NMatrices = 5,
                      RBounds = FALSE,
                      LB = -1,
                      UB = 1,
                      delta = 1e-16,
                      MinLambda = 0,
                      MaxIter = 5000,
                      detSort = FALSE,
                      ProgressBar = TRUE,
                      Parallel = TRUE,
                      PrintLevel = 1,
                      Digits = 3,
                      Seed = 1)

summary(Out4,
        PrintLevel = 2,
        Digits = 5)

## End(Not run)
</code></pre>

<hr>
<h2 id='corDensity'>Generate the marginal density of a correlation from a uniformly 
sampled R matrix.</h2><span id='topic+corDensity'></span>

<h3>Description</h3>

<p>Generate the marginal density of a correlation from a uniformly 
sampled R matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corDensity(NVar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corDensity_+3A_nvar">NVar</code></td>
<td>
<p>(integer) The order of the correlation matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>corDensity</code> returns the following objects:
</p>

<ul>
<li>  <p><strong>r</strong> (numeric) A sequence of numbers from -1, to 1 in .001 
increments.
</p>
</li>
<li>  <p><strong>rDensity</strong> (numeric) The density of <code>r</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Hrlimann, W.  (2012).  Positive semi-definite correlation 
matrices: Recursive algorithmic generation and volume measure.  
Pure Mathematical Science, 1(3), 137&ndash;149.  
</p>
<p>Joe, H.  (2006).  Generating random correlation matrices based on 
partial correlations. Journal of Multivariate Analysis, 97(10), 2177&ndash;2189.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  out &lt;- corDensity(NVar = 5)
  
  plot(out$r, out$rDensity, 
       typ = "l",
       xlab = "r",
       ylab = "Density of r",
       main = "")
</code></pre>

<hr>
<h2 id='corSample'>Sample Correlation Matrices from a Population Correlation Matrix</h2><span id='topic+corSample'></span>

<h3>Description</h3>

<p>Sample correlation (covariance) matrices from a population correlation
matrix (see Browne, 1968; Kshirsagar, 1959)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corSample(R, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corSample_+3A_r">R</code></td>
<td>
<p>A population correlation matrix.</p>
</td></tr>
<tr><td><code id="corSample_+3A_n">n</code></td>
<td>
<p>Sample correlation (covariance) matrices will be generated assuming
a sample size of n.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>cor.sample</code></td>
<td>
<p>Sample correlation matrix.</p>
</td></tr>
<tr><td><code>cov.sample</code></td>
<td>
<p>Sample covariance matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Browne, M. (1968). A comparison of factor analytic techniques.
<em>Psychometrika, 33(3)</em>, 267-334.
</p>
<p>Kshirsagar, A. (1959). Bartlett decomposition and Wishart distribution.
<em>The Annals of Mathematical Statistics, 30(1)</em>, 239-241.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
R &lt;- matrix(c(1, .5, .5, 1), 2, 2)
# generate a sample correlation from pop R with n = 25
out &lt;- corSample(R, n = 25)
out$cor.sample
out$cov.sample
</code></pre>

<hr>
<h2 id='corSmooth'>Smooth a Non PD Correlation Matrix</h2><span id='topic+corSmooth'></span>

<h3>Description</h3>

<p>A function for smoothing a non-positive definite correlation matrix by the
method of Knol and Berger (1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corSmooth(R, eps = 1e+08 * .Machine$double.eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corSmooth_+3A_r">R</code></td>
<td>
<p>A non-positive definite correlation matrix.</p>
</td></tr>
<tr><td><code id="corSmooth_+3A_eps">eps</code></td>
<td>
<p>Small positive number to control the size of the non-scaled
smallest eigenvalue of the smoothed R matrix. Default = 1E8 *
.Machine$double.eps</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Rsmoothed</code></td>
<td>
<p>A Smoothed (positive definite) correlation matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Knol, D. L., and Berger, M. P. F., (1991). Empirical comparison
between factor analysis and multidimensional item response
models.<em>Multivariate Behavioral Research, 26</em>, 457-477.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## choose eigenvalues such that R is NPD
l &lt;- c(3.0749126,  0.9328397,  0.5523868,  0.4408609, -0.0010000)

## Generate NPD R
R &lt;- genCorr(eigenval = l, seed = 123)
print(eigen(R)$values)

#&gt; [1]  3.0749126  0.9328397  0.5523868  0.4408609 -0.0010000

## Smooth R
Rsm&lt;-corSmooth(R, eps = 1E8 * .Machine$double.eps)
print(eigen(Rsm)$values)

#&gt; [1] 3.074184e+00 9.326669e-01 5.523345e-01 4.408146e-01 2.219607e-08

</code></pre>

<hr>
<h2 id='cosMat'>Compute the cosine(s) between either 2 matrices or 2 vectors.</h2><span id='topic+cosMat'></span>

<h3>Description</h3>

<p>This function will compute the cosines (i.e., the angle) between two vectors or matrices. When applied to matrices, it will compare the two matrices one vector (i.e., column) at a time. For instance, the cosine (angle) between factor 1 in matrix A and factor 1 in matrix B.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cosMat(A, B, align = FALSE, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cosMat_+3A_a">A</code></td>
<td>
<p>(Matrix, Vector) Either a matrix or vector.</p>
</td></tr>
<tr><td><code id="cosMat_+3A_b">B</code></td>
<td>
<p>(Matrix, Vector) Either a matrix or vector (must be of the same dimensions as A).</p>
</td></tr>
<tr><td><code id="cosMat_+3A_align">align</code></td>
<td>
<p>(Logical) Whether to run a factor alignment before computing the cosine.</p>
</td></tr>
<tr><td><code id="cosMat_+3A_digits">digits</code></td>
<td>
<p>(Numeric) The number of digits to round the output to.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Chance Congruence</strong>: Factor cosines were originally described by Burt (1948) and later popularized by Tucker (1951). Several authors have noted the tendency for two factors to have spuriously large factor cosines. Paunonen (1997) provides a good overview and describes how factor cosines between two vectors of random numbers can appear to be congruent.
</p>
</li>
<li> <p><strong>Effect Size Benchmarks</strong>: When computing congruence coefficients (cosines) in factor analytic studies, it can be useful to know what constitutes large versus small congruence. Lorenzo-Seva and ten Berge (2006) currently provide the most popular (i.e., most frequently cited) recommended benchmarks for congruence. &ldquo;A value in the range .85-.94 means that the two factors compared display <em>fair</em> similarity. This result should prevent congruence below .85 from being interpreted as indicative of any factor similarity at all. A value higher than .95 means that the two factors or components compared can be considered equal. That is what we have called a <em>good</em> similarity in our study&rdquo; (Lorenzo-Seva &amp; ten Berge, 2006, p. 61, emphasis theirs).
</p>
</li></ul>



<h3>Value</h3>

<p>A vector of cosines will be returned. When comparing two vectors, only one cosine can be computed. When comparing matrices, one cosine is computed per column.
</p>

<ul>
<li> <p><strong>cosine</strong>: (Matrix) A matrix of cosines between the two inputs. 
</p>
</li>
<li> <p><strong>A</strong>: (Matrix) The A input matrix.
</p>
</li>
<li> <p><strong>B</strong>: (Matrix) The B input matrix. 
</p>
</li>
<li> <p><strong>align</strong>: (Logical) Whether Matrix B was aligned to A.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Burt, C. (1948). The factorial study of temperament traits. <em>British Journal of Psychology, Statistical Section, 1</em>, 178-203.
</p>
<p>Lorenzo-Seva, U., &amp; ten Berge, J. M. F. (2006). Tuckers Congruence Coefficient as a meaningful index of factor similarity. <em>Methodology, 2</em>(2), 57-64.
</p>
<p>Paunonen, S. V. (1997). On chance and factor congruence following orthogonal Procrustes rotation. <em>Educational and Psychological Measurement</em>, 57, 33-59.
</p>
<p>Tucker, L. R. (1951). <em>A method for synthesis of factor analysis studies</em> (Personnel Research Section Report No. 984). Washington, DC: Department of the Army.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Cosine between two vectors
A &lt;- rnorm(5)
B &lt;- rnorm(5)

cosMat(A, B)

## Cosine between the columns of two matrices
A &lt;- matrix(rnorm(5 * 5), 5, 5)
B &lt;- matrix(rnorm(5 * 5), 5, 5)

cosMat(A, B)

</code></pre>

<hr>
<h2 id='d2r'>Convert Degrees to Radians</h2><span id='topic+d2r'></span>

<h3>Description</h3>

<p>A simple function to convert degrees to radians
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d2r(deg)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d2r_+3A_deg">deg</code></td>
<td>
<p>Angle in degrees.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Angle in radians.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
d2r(90)

</code></pre>

<hr>
<h2 id='eap'>Compute eap trait estimates for FMP and FUP models</h2><span id='topic+eap'></span>

<h3>Description</h3>

<p>Compute eap trait estimates for items fit by filtered monotonic polynomial
IRT models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eap(data, bParams, NQuad = 21, priorVar = 2, mintheta = -4, maxtheta = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eap_+3A_data">data</code></td>
<td>
<p>N(subjects)-by-p(items) matrix of 0/1 item response data.</p>
</td></tr>
<tr><td><code id="eap_+3A_bparams">bParams</code></td>
<td>
<p>A p-by-9 matrix of FMP or FUP item parameters and model
designations. Columns 1 - 8 hold the (possibly zero valued) polynomial
coefficients; column 9 holds the value of <code>k</code>.</p>
</td></tr>
<tr><td><code id="eap_+3A_nquad">NQuad</code></td>
<td>
<p>Number of quadrature points used to calculate the eap
estimates.</p>
</td></tr>
<tr><td><code id="eap_+3A_priorvar">priorVar</code></td>
<td>
<p>Variance of the normal prior for the eap estimates. The
prior mean equals 0.</p>
</td></tr>
<tr><td><code id="eap_+3A_mintheta">mintheta</code>, <code id="eap_+3A_maxtheta">maxtheta</code></td>
<td>
<p>NQuad quadrature points will be evenly spaced
between <code>mintheta</code> and <code>maxtheta</code></p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>eap trait estimates.</code></td>
<td>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## this example demonstrates how to calculate 
## eap trait estimates for a scale composed of items 
## that have been fit to FMP models of different 
## degree 

NSubjects &lt;- 2000

## Assume that 
## items 1 - 5 fit a k=0 model,
## items 6 - 10 fit a k=1 model, and 
## items 11 - 15 fit a k=2 model.


 itmParameters &lt;- matrix(c(
  #  b0    b1     b2    b3    b4  b5, b6, b7,  k
  -1.05, 1.63,  0.00, 0.00, 0.00,  0,     0,  0,   0, #1
  -1.97, 1.75,  0.00, 0.00, 0.00,  0,     0,  0,   0, #2
  -1.77, 1.82,  0.00, 0.00, 0.00,  0,     0,  0,   0, #3
  -4.76, 2.67,  0.00, 0.00, 0.00,  0,     0,  0,   0, #4
  -2.15, 1.93,  0.00, 0.00, 0.00,  0,     0,  0,   0, #5
  -1.25, 1.17, -0.25, 0.12, 0.00,  0,     0,  0,   1, #6
   1.65, 0.01,  0.02, 0.03, 0.00,  0,     0,  0,   1, #7
  -2.99, 1.64,  0.17, 0.03, 0.00,  0,     0,  0,   1, #8
  -3.22, 2.40, -0.12, 0.10, 0.00,  0,     0,  0,   1, #9
  -0.75, 1.09, -0.39, 0.31, 0.00,  0,     0,  0,   1, #10
  -1.21, 9.07,  1.20,-0.01,-0.01,  0.01,  0,  0,   2, #11
  -1.92, 1.55, -0.17, 0.50,-0.01,  0.01,  0,  0,   2, #12
  -1.76, 1.29, -0.13, 1.60,-0.01,  0.01,  0,  0,   2, #13
  -2.32, 1.40,  0.55, 0.05,-0.01,  0.01,  0,  0,   2, #14
  -1.24, 2.48, -0.65, 0.60,-0.01,  0.01,  0,  0,   2),#15
  15, 9, byrow=TRUE)
 
# generate data using the above item parameters
ex1.data&lt;-genFMPData(NSubj = NSubjects, bParams = itmParameters, 
                    seed = 345)$data


## calculate eap estimates for mixed models
thetaEAP&lt;-eap(data = ex1.data, bParams = itmParameters, 
                   NQuad = 25, priorVar = 2, 
                   mintheta = -4, maxtheta = 4)

## compare eap estimates with initial theta surrogates

if(FALSE){     #set to TRUE to see plot

  thetaInit &lt;- svdNorm(ex1.data)
  plot(thetaInit,thetaEAP, xlim = c(-3.5,3.5), 
                         ylim = c(-3.5,3.5),
                         xlab = "Initial theta surrogates",
                         ylab = "EAP trait estimates (Mixed models)")
}                         

</code></pre>

<hr>
<h2 id='eigGen'>Generate eigenvalues for R matrices with underlying component structure</h2><span id='topic+eigGen'></span>

<h3>Description</h3>

<p>Generate eigenvalues for R matrices with underlying component structure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigGen(nDimensions = 15, nMajorFactors = 5, PrcntMajor = 0.8, threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eigGen_+3A_ndimensions">nDimensions</code></td>
<td>
<p>Total number of dimensions (variables).</p>
</td></tr>
<tr><td><code id="eigGen_+3A_nmajorfactors">nMajorFactors</code></td>
<td>
<p>Number of major factors.</p>
</td></tr>
<tr><td><code id="eigGen_+3A_prcntmajor">PrcntMajor</code></td>
<td>
<p>Percentage of variance accounted for by major factors.</p>
</td></tr>
<tr><td><code id="eigGen_+3A_threshold">threshold</code></td>
<td>
<p>Minimm difference in eigenvalues between the last major
factor and the first minor factor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of eigenvalues that satisfies the above criteria.
</p>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example
set.seed(323)
nDim &lt;- 25   # number of dimensions
nMaj &lt;- 5    # number of major components
pmaj &lt;- 0.70 # percentage of variance accounted for
             # by major components
thresh &lt;- 1  # eigenvalue difference between last major component 
             # and first minor component
 
L &lt;- eigGen(nDimensions = nDim, nMajorFactors = nMaj, 
            PrcntMajor = pmaj, threshold = thresh)

maxy &lt;- max(L+1)

plotTitle &lt;- paste("  n Dimensions = ", nDim, 
                   ",  n Major Factors = ", nMaj, 
				           "\n % Variance Major Factors = ", pmaj*100, 
						   "%", sep = "")
				 
plot(1:length(L), L, 
     type = "b", 
     main = plotTitle,
     ylim = c(0, maxy),
     xlab = "Dimensions", 
	   ylab = "Eigenvalues",
	   cex.main = .9)				 


</code></pre>

<hr>
<h2 id='enhancement'>Find OLS Regression Coefficients that Exhibit Enhancement</h2><span id='topic+enhancement'></span>

<h3>Description</h3>

<p>Find OLS regression coefficients that exhibit a specified degree of
enhancement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>enhancement(R, br, rr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="enhancement_+3A_r">R</code></td>
<td>
<p>Predictor correlation matrix.</p>
</td></tr>
<tr><td><code id="enhancement_+3A_br">br</code></td>
<td>
<p>Model R-squared = b' r. That is, br is the model coefficient of
determination: b'Rb= Rsq = br</p>
</td></tr>
<tr><td><code id="enhancement_+3A_rr">rr</code></td>
<td>
<p>Sum of squared predictor-criterion correlations (rxy). That is, rr
= r'r = Sum(rxy^2)</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>b</code></td>
<td>
<p>Vector of standardized regression coefficients.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>Vector of predictor-criterion correlations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Waller, N. G. (2011). The geometry of enhancement in multiple
regression. <em>Psychometrika, 76</em>, 634&ndash;649.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example: For a given predictor correlation  matrix (R) generate 
## regression coefficient vectors that produce enhancement (br - rr &gt; 0)

## Predictor correlation matrix
R &lt;- matrix(c( 1,  .5, .25,
              .5, 1,   .30,
              .25, .30, 1), 3, 3) 
 
## Model coefficient of determination
Rsq &lt;- .60
 
output&lt;-enhancement(R, br = Rsq, rr =.40) 
 
r &lt;- output$r
b &lt;- output$b
  
##Standardized regression coefficients
print(t(b)) 

##Predictor-criterion correlations
print(t(r)) 
 
##Coefficient of determinations (b'r)
print(t(b) %*% r)

##Sum of squared correlations (r'r)
print(t(r) %*% r)

</code></pre>

<hr>
<h2 id='erf'>Utility fnc to compute the components for an empirical response function</h2><span id='topic+erf'></span>

<h3>Description</h3>

<p>Utility function to compute empirical response functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>erf(theta, data, whichItem, min = -3, max = 3, Ncuts = 12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="erf_+3A_theta">theta</code></td>
<td>
<p>Vector of estimated latent trait scores.</p>
</td></tr>
<tr><td><code id="erf_+3A_data">data</code></td>
<td>
<p>A matrix of binary item responses.</p>
</td></tr>
<tr><td><code id="erf_+3A_whichitem">whichItem</code></td>
<td>
<p>Data for an erf will be generated for whichItem.</p>
</td></tr>
<tr><td><code id="erf_+3A_min">min</code></td>
<td>
<p>Default = -3. Minimum value of theta.</p>
</td></tr>
<tr><td><code id="erf_+3A_max">max</code></td>
<td>
<p>Default = 3. Maximum value of theta.</p>
</td></tr>
<tr><td><code id="erf_+3A_ncuts">Ncuts</code></td>
<td>
<p>Number of score groups for erf.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>probs</code></td>
<td>
<p>A vector (of length Ncuts) of bin response
probabilities for the empirical response function.</p>
</td></tr> <tr><td><code>centers</code></td>
<td>
<p>A vector
of bin centers. </p>
</td></tr> <tr><td><code>Ni</code></td>
<td>
<p>Bin sample sizes.</p>
</td></tr> <tr><td><code>se.p</code></td>
<td>
<p>Standard errors
of the estimated bin response probabilities.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
NSubj &lt;- 2000

#generate sample k=1 FMP  data
b &lt;- matrix(c(
    #b0    b1     b2    b3      b4   b5 b6 b7  k
  1.675, 1.974, -0.068, 0.053,  0,  0,  0,  0, 1,
  1.550, 1.805, -0.230, 0.032,  0,  0,  0,  0, 1,
  1.282, 1.063, -0.103, 0.003,  0,  0,  0,  0, 1,
  0.704, 1.376, -0.107, 0.040,  0,  0,  0,  0, 1,
  1.417, 1.413,  0.021, 0.000,  0,  0,  0,  0, 1,
 -0.008, 1.349, -0.195, 0.144,  0,  0,  0,  0, 1,
  0.512, 1.538, -0.089, 0.082,  0,  0,  0,  0, 1,
  0.122, 0.601, -0.082, 0.119,  0,  0,  0,  0, 1,
  1.801, 1.211,  0.015, 0.000,  0,  0,  0,  0, 1,
 -0.207, 1.191,  0.066, 0.033,  0,  0,  0,  0, 1,
 -0.215, 1.291, -0.087, 0.029,  0,  0,  0,  0, 1,
  0.259, 0.875,  0.177, 0.072,  0,  0,  0,  0, 1,
 -0.423, 0.942,  0.064, 0.094,  0,  0,  0,  0, 1,
  0.113, 0.795,  0.124, 0.110,  0,  0,  0,  0, 1,
  1.030, 1.525,  0.200, 0.076,  0,  0,  0,  0, 1,
  0.140, 1.209,  0.082, 0.148,  0,  0,  0,  0, 1,
  0.429, 1.480, -0.008, 0.061,  0,  0,  0,  0, 1,
  0.089, 0.785, -0.065, 0.018,  0,  0,  0,  0, 1,
 -0.516, 1.013,  0.016, 0.023,  0,  0,  0,  0, 1,
  0.143, 1.315, -0.011, 0.136,  0,  0,  0,  0, 1,
  0.347, 0.733, -0.121, 0.041,  0,  0,  0,  0, 1,
 -0.074, 0.869,  0.013, 0.026,  0,  0,  0,  0, 1,
  0.630, 1.484, -0.001, 0.000,  0,  0,  0,  0, 1), 
  nrow=23, ncol=9, byrow=TRUE)  
 
theta &lt;- rnorm(NSubj)  
data&lt;-genFMPData(NSubj = NSubj, bParam = b, theta = theta, seed = 345)$data

erfItem1 &lt;- erf(theta, data, whichItem = 1, min = -3, max = 3, Ncuts = 12)

plot( erfItem1$centers, erfItem1$probs, type="b", 
      main="Empirical Response Function",
      xlab = expression(theta),
      ylab="Probability",
      cex.lab=1.5)

</code></pre>

<hr>
<h2 id='faAlign'>Align the columns of two factor loading matrices</h2><span id='topic+faAlign'></span>

<h3>Description</h3>

<p>Align factor loading matrices across solutions using the Hungarian algorithm
to locate optimal matches. faAlign will match the factors of F2 (the input
matrix) to those in F1 (the target matrix) to minimize a least squares
discrepancy function or to maximize factor congruence coefficients (i.e.,
vector cosines).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faAlign(F1, F2, Phi2 = NULL, MatchMethod = "LS")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faAlign_+3A_f1">F1</code></td>
<td>
<p>target Factor Loadings Matrix.</p>
</td></tr>
<tr><td><code id="faAlign_+3A_f2">F2</code></td>
<td>
<p>input Factor Loadings Matrix. F2 will be aligned with the target
matrix, F1.</p>
</td></tr>
<tr><td><code id="faAlign_+3A_phi2">Phi2</code></td>
<td>
<p>optional factor correlation matrix for F2 (default = NULL).</p>
</td></tr>
<tr><td><code id="faAlign_+3A_matchmethod">MatchMethod</code></td>
<td>
<p>&quot;LS&quot; (Least Squares) or &quot;CC&quot; (congruence coefficients).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>F2</code></td>
<td>
<p>re-ordered and reflected loadings of F2.</p>
</td></tr>
<tr><td><code>Phi2</code></td>
<td>
<p>reordered and reflected factor correlations.</p>
</td></tr> 
<tr><td><code>FactorMap</code></td>
<td>
<p>a 2 x k matrix (where k is the number of columns of F1) structured such that
row 1: the original column order of F2; row 2: the sorted column order of
F2.</p>
</td></tr> 
<tr><td><code>UniqueMatch</code></td>
<td>
<p>(logical) indicates whether a unique match was
found.</p>
</td></tr> 
<tr><td><code>MatchMethod</code></td>
<td>
<p>&quot;LS&quot; (least squares) or &quot;CC&quot; (congruence
coefficients, i.e., cosines).</p>
</td></tr> 
<tr><td><code>CC</code></td>
<td>
<p>Congruence coefficients for the
matched factors.</p>
</td></tr> 
<tr><td><code>LS</code></td>
<td>
<p>Root-mean-squared-deviations (least squares
criterion) for the matched factors.</p>
</td></tr>
<tr><td><code>Dsgn</code></td>
<td>
<p>The Diagonal Sign Matrix that reflects the matched factors to 
have positive salient loadings.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Hungarian algorithm is implemented with the clue (Cluster
Ensembles, Hornik, 2005) package. See Hornik K (2005). A CLUE for CLUster
Ensembles. <em>Journal of Statistical Software, 14</em>(12). doi:
10.18637/jss.v014.i12 (URL: http://doi.org/10.18637/jss.v014.i12).
</p>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Kuhn, H. W. (1955). The Hungarian Method for the assignment
problem. <em>Naval Research Logistics Quarterly, 2</em>, 83-97.
</p>
<p>Kuhn, H. W. (1956). Variants of the Hungarian method for assignment
problems. <em>Naval Research Logistics Quarterly, 3</em>, 253-258.
</p>
<p>Papadimitriou, C. &amp; Steiglitz, K. (1982). Combinatorial Optimization:
Algorithms and Complexity. Englewood Cliffs: Prentice Hall.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# This example demonstrates the computation of 
# non-parametric bootstrap confidence intervals
# for rotated factor loadings.


library(GPArotation)

data(HS9Var)

HS9 &lt;- HS9Var[HS9Var$school == "Grant-White",7:15]

# Compute an R matrix for the HSVar9 Mental Abilities Data
R.HS9 &lt;- cor(HS9)

varnames &lt;- c( "vis.per", "cubes", 
            "lozenges", "paragraph.comp",
            "sentence.comp","word.mean",
            "speed.add", "speed.count.dots",
            "speed.discr")



# Extract and rotate a 3-factor solution
# via unweighted least squares factor extraction 
# and oblimin rotation. 

NFac &lt;- 3
NVar &lt;- 9
B &lt;- 200      # Number of boostrap samples
NSubj &lt;- nrow(HS9)

# Unrotated 3 factor uls solution 
 F3.uls &lt;- fals(R = R.HS9, nfactors = NFac)
 
# Rotate via oblimin 
 F3.rot &lt;- oblimin(F3.uls$loadings, 
                      gam = 0, 
                      normalize = FALSE)

 F3.loadings &lt;- F3.rot$loadings
 F3.phi &lt;- F3.rot$Phi
 
 # Reflect factors so that salient loadings are positive
 Dsgn &lt;- diag(sign(colSums(F3.loadings^3)))
 F3.loadings &lt;- F3.loadings %*% Dsgn
 F3.phi &lt;- Dsgn %*% F3.phi %*% Dsgn
 
 rownames(F3.loadings) &lt;- varnames
 colnames(F3.loadings) &lt;- paste0("f", 1:3)
 colnames(F3.phi) &lt;- rownames(F3.phi) &lt;- paste0("f", 1:3)
 
 cat("\nOblimin rotated factor loadings for 9 Mental Abilities Variables")
 print( round(F3.loadings, 2))
 
 cat("\nFactor correlation matrix")
 print( round( F3.phi, 2))
 
  # Declare variables to hold bootstrap output
  Flist &lt;- Philist &lt;- as.list(rep(0, B))
  UniqueMatchVec &lt;- rep(0, B)
  rows &lt;- 1:NSubj
 
  # Analyze bootstrap samples and record results 
  for(i in 1:B){
    cat("\nWorking on sample ", i)
    set.seed(i)
    
    # Create bootstrap sanples
    bsRows &lt;- sample(rows, NSubj, replace= TRUE)
    Fuls &lt;- fals(R = cor(HS9[bsRows, ]), nfactors = NFac)
    # rotated loadings
    Fboot &lt;- oblimin(Fuls$loadings,
                             gam = 0, 
                             normalize = FALSE)
    
    
    out &lt;- faAlign(F1 = F3.loadings, 
                   F2 = Fboot$loadings, 
                   MatchMethod = "LS")
    
    Flist[[i]] &lt;- out$F2 # aligned version of Fboot$loadings
    UniqueMatchVec[i] &lt;- out$UniqueMatch
  }
  
  cat("\nNumber of Unique Matches: ", 
      100*round(mean(UniqueMatchVec),2),"%\n")

  
  #  Make a 3D array from list of matrices
  arr &lt;- array( unlist(Flist) , c(NVar, NFac, B) )
  
  #  Get quantiles of factor elements over third dimension (samples)
  F95 &lt;- apply( arr , 1:2 , quantile, .975 )
  F05 &lt;- apply( arr , 1:2 , quantile, .025 )
  Fse &lt;- apply( arr , 1:2, sd  )
  
  cat("\nUpper Bound 95% CI\n")
  print( round(F95,3))
  cat("\n\nLower Bound 95% CI\n")
  print( round(F05,3))
  
  # plot distribution of bootstrap estimates
  # for example element
  hist(arr[5,1,], xlim=c(.4,1),
       main = "Bootstrap Distribution for F[5,1]",
       xlab = "F[5,1]")
  
  print(round (F3.loadings, 2))
  cat("\nStandard Errors")
  print( round( Fse, 2))

</code></pre>

<hr>
<h2 id='faBounds'>Bounds on the Correlation Between an External Variable and a Common Factor</h2><span id='topic+faBounds'></span>

<h3>Description</h3>

<p>This function computes the  bounds on the correlation between an 
external variable and a common factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faBounds(Lambda, RX, rXY, alphaY = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faBounds_+3A_lambda">Lambda</code></td>
<td>
<p>(matrix) A p x 1 matrix of factor loadings.</p>
</td></tr>
<tr><td><code id="faBounds_+3A_rx">RX</code></td>
<td>
<p>(matrix) A p x p matrix of correlations for the factor indicators.</p>
</td></tr>
<tr><td><code id="faBounds_+3A_rxy">rXY</code></td>
<td>
<p>(vector) A p x 1 vector of correlations between the factor
indicators (X) and the external variable (Y).</p>
</td></tr>
<tr><td><code id="faBounds_+3A_alphay">alphaY</code></td>
<td>
<p>(scalar)  The reliability of Y. Default <code>alphaY = 1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>faBounds</code> returns the following objects:
</p>

<ul>
<li> <p><strong>Lambda</strong> (matrix) A p x 1 vector of factor loadings. 
</p>
</li>
<li>  <p><strong>RX</strong> (matrix) The indicator correlation matrix. 
</p>
</li>
<li>  <p><strong>rXY</strong>: (vector) The correlations between the factor indicators (X) and the 
external variable (Y).
</p>
</li>
<li> <p><strong>alphaY</strong> (integer) The reliability of the external variable.
</p>
</li>
<li> <p><strong>bounds</strong> (vector)  A 2 x 1 vector that includes the lower and upper bounds 
for the correlation between an external variable and a common factor. 
</p>
</li>
<li> <p><strong>rUiY</strong> (vector) Correlations between the unique factors and the 
external variable for the lower bound estimate.
</p>
</li>
<li> <p><strong>rUjY</strong> (vector) Correlations between the unique factors and the 
external variable for the upper bound estimate.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Steiger, J. H.  (1979).  The relationship between external 
variables and common factors. Psychometrika, 44, 93-97.
</p>
<p>Waller, N. G. (under review). New results on the relationship 
between an external variable and a common factor.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 
## We wish to compute the bounds between the Speed factor from the 
## Holzinger (H) and Swineford data and a hypothetical external 
## variable, Y.

## RH = R matrix for *H*olzinger Swineford data
RH &lt;- 
 matrix(c( 1.00,   0,    0,     0,     0,     0,
           .73, 1.00,    0,     0,     0,     0, 
           .70,  .72,  1.00,    0,     0,     0,
           .17,  .10,   .12,  1.00,    0,     0,
           .11,  .14,   .15,   .49,  1.00,    0,
           .21,  .23,   .21,   .34,   .45,  1.00), 6, 6)

RH &lt;- RH + t(RH) - diag(6)
RX &lt;- RH[4:6, 4:6]

## S-C = Straight-curved
 colnames(RX) &lt;- rownames(RX) &lt;-
        c("Addition", "Counting dots", "S-C capitals")
print( RX, digits = 2 ) 

## Extract 1 MLE factor  
fout &lt;- faMain(R = RX, 
              numFactors = 1, 
              facMethod = "faml", 
              rotate="none")

## Lambda = factor loadings matrix  
Lambda &lt;- fout$loadings
print( Lambda, digits = 3 ) 

## rXY = correlations between the factor indicators (X) and
## the external variable (Y)

 rXY = c(.1, .2, .3)
 
 # Assume that the reliability of Y = .75
 
 faBounds(Lambda, RX, rXY, alphaY = .75)
 
</code></pre>

<hr>
<h2 id='faEKC'>Calculate Reference Eigenvalues for the Empirical Kaiser Criterion</h2><span id='topic+faEKC'></span>

<h3>Description</h3>

<p>Calculate Reference Eigenvalues for the Empirical Kaiser Criterion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faEKC(R = NULL, NSubj = NULL, Plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faEKC_+3A_r">R</code></td>
<td>
<p>Input correlation matrix.</p>
</td></tr>
<tr><td><code id="faEKC_+3A_nsubj">NSubj</code></td>
<td>
<p>Number of subjects (observations) used to create R.</p>
</td></tr>
<tr><td><code id="faEKC_+3A_plot">Plot</code></td>
<td>
<p>(logical). If <code>Plot = TRUE</code> the function will plot
the observed and reference eigenvalues of R.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li><p>ljEKC, 
</p>
</li>
<li><p>ljEKC1,
</p>
</li>
<li><p>dimensions The estimated number of common factors.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Braeken, J. &amp; Van Assen, M. A.  (2017).  An empirical Kaiser criterion. 
<em>Psychological Methods, 22</em>(3), 450-466.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(AmzBoxes)
AmzBox20&lt;- GenerateBoxData(XYZ = AmzBoxes[,2:4], 
                           BoxStudy = 20)$BoxData
RAmzBox20 &lt;- cor(AmzBox20)
EKCout  &lt;- faEKC(R = RAmzBox20, 
                NSubj = 98,
                Plot = TRUE)


</code></pre>

<hr>
<h2 id='faIB'>Inter-Battery Factor Analysis by the Method of Maximum Likelihood</h2><span id='topic+faIB'></span>

<h3>Description</h3>

<p>This function conducts maximum likelihood inter-battery factor analysis using procedures described by Browne (1979). 
The unrotated solution can be rotated  (using the <span class="pkg">GPArotation</span> package) 
from a user-specified number of random (orthogonal) starting configurations. 
Based on the resulting complexity function value, the function determines the 
number of local minima and, among these local solutions, will find the 
&quot;global minimum&quot; (i.e., the minimized complexity value from the finite 
number of solutions). See Details below for an elaboration on the global 
minimum. This function can also return bootstrap standard errors of the factor solution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faIB(
  X = NULL,
  R = NULL,
  n = NULL,
  NVarX = 4,
  numFactors = 2,
  itemSort = FALSE,
  rotate = "oblimin",
  bootstrapSE = FALSE,
  numBoot = 1000,
  CILevel = 0.95,
  rotateControl = NULL,
  Seed = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faIB_+3A_x">X</code></td>
<td>
<p>(Matrix) A raw data matrix (or data frame) structured in a subject 
(row) by variable (column) format. Defaults to <code>X = NULL</code>.</p>
</td></tr>
<tr><td><code id="faIB_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix. Defaults to <code>R = NULL</code>.</p>
</td></tr>
<tr><td><code id="faIB_+3A_n">n</code></td>
<td>
<p>(Numeric) Sample size associated with either the raw data (X) or 
the correlation matrix (R). Defaults to <code>n = NULL</code>.</p>
</td></tr>
<tr><td><code id="faIB_+3A_nvarx">NVarX</code></td>
<td>
<p>(Integer) Given batteries X and Y, <code>NVarX</code> denotes the number of variables in battery X.</p>
</td></tr>
<tr><td><code id="faIB_+3A_numfactors">numFactors</code></td>
<td>
<p>(Numeric) The number of factors to extract for subsequent 
rotation. Defaults to <code>numFactors = NULL</code>.</p>
</td></tr>
<tr><td><code id="faIB_+3A_itemsort">itemSort</code></td>
<td>
<p>(Logical) if <code>itemSort = TRUE</code> the factor loadings will be sorted within batteries.</p>
</td></tr>
<tr><td><code id="faIB_+3A_rotate">rotate</code></td>
<td>
<p>(Character) Designate which rotation algorithm to apply. The 
following are available rotation options: &quot;oblimin&quot;, &quot;quartimin&quot;, 
&quot;oblimax&quot;, &quot;entropy&quot;, &quot;quartimax&quot;, &quot;varimax&quot;, &quot;simplimax&quot;, 
&quot;bentlerT&quot;, &quot;bentlerQ&quot;, &quot;tandemI&quot;, &quot;tandemII&quot;, &quot;geominT&quot;, &quot;geominQ&quot;, &quot;cfT&quot;, 
&quot;cfQ&quot;, &quot;infomaxT&quot;, &quot;infomaxQ&quot;, &quot;mccammon&quot;, &quot;bifactorT&quot;, &quot;bifactorQ&quot;, and 
&quot;none&quot;. Defaults to rotate = &quot;oblimin&quot;. See <span class="pkg">GPArotation</span> package for more 
details. Note that rotations ending in &quot;T&quot; and &quot;Q&quot; represent orthogonal and 
oblique rotations, respectively.</p>
</td></tr>
<tr><td><code id="faIB_+3A_bootstrapse">bootstrapSE</code></td>
<td>
<p>(Logical) Computes bootstrap standard errors. All bootstrap 
samples are aligned to the global minimum solution. Defaults to 
bootstrapSE = FALSE (no standard errors).</p>
</td></tr>
<tr><td><code id="faIB_+3A_numboot">numBoot</code></td>
<td>
<p>(Numeric) The number bootstraps. Defaults to numBoot = 1000.</p>
</td></tr>
<tr><td><code id="faIB_+3A_cilevel">CILevel</code></td>
<td>
<p>(Numeric) The confidence level (between 0 and 1) of the bootstrap 
confidence interval. Defaults to CILevel = .95.</p>
</td></tr>
<tr><td><code id="faIB_+3A_rotatecontrol">rotateControl</code></td>
<td>
<p>(List) A list of control values to pass to the factor rotation algorithms.
</p>

<ul>
<li> <p><strong>numberStarts</strong>: (Numeric) The number of random (orthogonal) 
starting configurations for the chosen rotation method (e.g., oblimin). The first
rotation will always commence from the unrotated factors orientation.
Defaults to numberStarts = 10. 
</p>
</li>
<li> <p><strong>gamma</strong>: (Numeric) This is a tuning parameter (between 0 
and 1, inclusive) for an oblimin rotation.  See the <span class="pkg">GPArotation</span> 
library's oblimin documentation for more details. Defaults to gamma = 0 
(i.e., a quartimin rotation).
</p>
</li>
<li> <p><strong>delta</strong>: (Numeric) This is a tuning parameter for the geomin
rotation. It adds a small number (default = .01) to the squared factor 
loadings before computing the geometric means in the discrepancy function.
</p>
</li>
<li> <p><strong>kappa</strong>: (Numeric) The main parameterization of the 
Crawford-Ferguson (CF) rotations (i.e., &quot;cfT&quot; and &quot;cfQ&quot; for orthogonal and 
oblique CF rotation, respectively). Defaults to kappa = 0. 
</p>
</li>
<li> <p><strong>k</strong>: (Numeric) A specific parameter of the simplimax rotation. 
Defaults to k = the number of observed variables.
</p>
</li>
<li> <p><strong>standardize</strong>: (Character) The standardization routine used 
on the unrotated factor structure. The three options are &quot;none&quot;, &quot;Kaiser&quot;, 
and &quot;CM&quot;. Defaults to standardize = &quot;none&quot;. 
</p>

<ul>
<li> <p><strong>&quot;none&quot;</strong>: No standardization is applied to the unrotated 
factor structure. 
</p>
</li>
<li> <p><strong>&quot;Kaiser&quot;</strong>: Use a factor structure matrix that has been 
normed by Kaiser's method (i.e., normalize all rows to have a unit length).
</p>
</li>
<li> <p><strong>&quot;CM&quot;</strong>: Use a factor structure matrix that has been normed
by the Cureton-Mulaik method.
</p>
</li></ul>

</li>
<li> <p><strong>epsilon</strong>: (Numeric) The rotational convergence criterion to 
use. Defaults to epsilon = 1e-5.
</p>
</li>
<li> <p><strong>power</strong>: (Numeric) Raise factor loadings the the n-th power 
in the <code><a href="#topic+promaxQ">promaxQ</a></code> rotation. Defaults to power = 4.
</p>
</li>
<li> <p><strong>maxItr</strong>: (Numeric) The maximum number of iterations for the 
rotation algorithm. Defaults to maxItr = 15000.
</p>
</li></ul>
</td></tr>
<tr><td><code id="faIB_+3A_seed">Seed</code></td>
<td>
<p>(Integer) Starting seed for the random number generator.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Global Minimum</strong>: This function uses several random starting 
configurations for factor rotations in an attempt to find the global 
minimum solution. However, this function is not guaranteed to find the 
global minimum. Furthermore, the global minimum solution need not be 
more psychologically interpretable than any of the local solutions (cf. 
Rozeboom, 1992). As is recommended, our function returns all local 
solutions so users can make their own judgements.
</p>
</li>
<li> <p><strong>Finding clusters of local minima</strong>: We find local-solution sets by sorting the rounded  
rotation complexity values (to the number of  digits specified in the <code>epsilon</code> 
argument of the <code>rotateControl</code> list) into sets with equivalent values. For example, 
by default <code>epsilon = 1e-5.</code> and thus  will only evaluate the complexity 
values to five significant digits. Any differences beyond that value will not effect the final sorting. 
</p>
</li></ul>



<h3>Value</h3>

<p>The <code>faIB</code> function will produce abundant output in addition 
to the rotated inter-battery factor pattern and factor correlation matrices. 
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) The rotated inter-battery factor solution with the 
lowest evaluated discrepancy function. This solution has the lowest 
discrepancy function <em>of the examined random starting configurations</em>. 
It is not guaranteed to find the &quot;true&quot; global minimum. Note that multiple
(or even all) local solutions can have the same discrepancy functions.
</p>
</li>
<li> <p><strong>Phi</strong>: (Matrix) The factor correlations of the rotated factor 
solution with the lowest evaluated discrepancy function (see Details).
</p>
</li>
<li> <p><strong>fit</strong>: (Vector) A vector containing the following fit statistics:
</p>

<ul>
<li> <p><strong>chiSq</strong>: Chi-square goodness of fit value (see Browne, 1979, for details). Note that we apply Lawley's (1959) correction when computing the chi-square value.
</p>
</li>
<li> <p><strong>DF</strong>: Degrees of freedom for the estimated model. 
</p>
</li>
<li> <p><strong>p-value</strong>: P-value associated with the above chi-square statistic.
</p>
</li>
<li> <p><strong>MAD</strong>: Mean absolute difference between the model-implied and the sample across-battery correlation matrices. A lower value indicates better fit. 
</p>
</li>
<li> <p><strong>AIC</strong>: Akaike's Information Criterion where a lower value indicates better fit. 
</p>
</li>
<li> <p><strong>BIC</strong>: Bayesian Information Criterion where a lower value indicates better fit. 
</p>
</li></ul>

</li>
<li> <p><strong>R</strong>: (Matrix) Returns the (possibly sorted) correlation matrix, useful when raw data are supplied. 
If <code>itemSort = TRUE</code> then the returned matrix is sorted to be consistent with the factor loading matrix.
</p>
</li>
<li> <p><strong>Rhat</strong>: (Matrix) The (possibly sorted) reproduced correlation matrix.If <code>itemSort = TRUE</code> then the returned matrix is sorted to be consistent with the factor loading matrix.
</p>
</li>
<li> <p><strong>Resid</strong>: (Matrix) A (possibly sorted) residual matrix (R - Rhat) for the between battery correlations. 
</p>
</li>
<li> <p><strong>facIndeterminacy</strong>: (Vector) A vector (with length equal to the number of factors)
containing Guttman's (1955) index of factor indeterminacy for each factor. 
</p>
</li>
<li> <p><strong>localSolutions</strong>: (List) A list containing all local solutions 
in ascending order of their factor loadings, rotation complexity values (i.e., the first solution 
is the &quot;global&quot; minimum). Each solution returns the 
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) the factor loadings, 
</p>
</li>
<li> <p><strong>Phi</strong>: (Matrix) factor correlations, 
</p>
</li>
<li> <p><strong>RotationComplexityValue</strong>: (Numeric) the complexity value of the rotation algorithm, 
</p>
</li>
<li> <p><strong>facIndeterminacy</strong>: (Vector) A vector of factor indeterminacy indices for each common factor, and 
</p>
</li>
<li> <p><strong>RotationConverged</strong>: (Logical) convergence status of the rotation algorithm. 
</p>
</li></ul>

</li>
<li> <p><strong>numLocalSets</strong> (Numeric) How many sets of local solutions
with the same discrepancy value were obtained. 
</p>
</li>
<li> <p><strong>localSolutionSets</strong>: (List) A list containing the sets of 
unique local minima solutions. There is one list element for every unique 
local solution that includes (a) the factor loadings matrix, (b) the factor 
correlation matrix (if estimated), and (c) the discrepancy value of the rotation algorithm. 
</p>
</li>
<li> <p><strong>rotate</strong> (Character) The chosen rotation algorithm.
</p>
</li>
<li> <p><strong>rotateControl</strong>: (List) A list of the control parameters 
passed to the rotation algorithm.
</p>
</li>
<li> <p><strong>unSpunSolution</strong>: (List) A list of output parameters (e.g., loadings, Phi, etc) from 
the rotated solution that was obtained by rotating directly from the unrotated (i.e., unspun) common factor orientation. 
</p>
</li>
<li> <p><strong>Call</strong>: (call) A copy of the function call.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Boruch, R. F., Larkin, J. D., Wolins, L., &amp; MacKinney, A. C. (1970). 
Alternative methods of analysis: Multitrait-multimethod data. <em>Educational 
and Psychological Measurement, 30</em>(4), 833853. 
https://doi.org/10.1177/0013164470030004055
</p>
<p>Browne, M. W.  (1979).  The maximum-likelihood solution in inter-battery factor analysis. 
<em>British Journal of Mathematical and Statistical Psychology, 32</em>(1), 75-86.
</p>
<p>Browne, M. W.  (1980).  Factor analysis of multiple batteries by maximum likelihood.  
<em>British Journal of Mathematical and Statistical Psychology, 33</em>(2), 184-199.
</p>
<p>Browne, M. W. (2001). An overview of analytic rotation in 
exploratory factor analysis. <em>Multivariate Behavioral Research, 36</em>(1), 111-150.
</p>
<p>Burnham, K. P. &amp; Anderson, D. R.  (2004).  Multimodel inference: Understanding AIC and BIC in model selection.  
<em>Sociological methods and research, 33</em>, 261-304.
</p>
<p>Cudeck, R. (1982). Methods for estimating between-battery factors,
<em>Multivariate Behavioral Research, 17</em>(1), 47-68. 10.1207/s15327906mbr1701_3
</p>
<p>Cureton, E. E., &amp; Mulaik, S. A. (1975). The weighted varimax 
rotation and the promax rotation. <em>Psychometrika, 40</em>(2), 183-195.
</p>
<p>Guttman, L. (1955). The determinacy of factor score matrices with 
implications for five other basic problems of common factor theory. 
<em>British Journal of Statistical Psychology, 8</em>(2), 65-81.
</p>
<p>Tucker, L. R.  (1958).  An inter-battery method of factor analysis.  
<em>Psychometrika, 23</em>(2), 111-136.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example 1:
# Example from: Browne, M. W.  (1979). 
#
# Data originally reported in:
# Thurstone, L. L. &amp; Thurstone, T. G. (1941). Factorial studies 
# of intelligence. Psychometric Monograph (2), Chicago: Univ. 
# Chicago Press.

R.XY &lt;- matrix(c(
 1.00, .554, .227, .189, .461, .506, .408, .280, .241,
 .554, 1.00, .296, .219, .479, .530, .425, .311, .311,
 .227, .296, 1.00, .769, .237, .243, .304, .718, .730,
 .189, .219, .769, 1.00, .212, .226, .291, .681, .661,
 .461, .479, .237, .212, 1.00, .520, .514, .313, .245,
 .506, .530, .243, .226, .520, 1.00, .473, .348, .290,
 .408, .425, .304, .291, .514, .473, 1.00, .374, .306,
 .280, .311, .718, .681, .313, .348, .374, 1.00, .672,
 .241, .311, .730, .661, .245, .290, .306, .672, 1.00), 9, 9)


dimnames(R.XY) &lt;- list(c( paste0("X", 1:4),
                         paste0("Y", 1:5)),
                       c( paste0("X", 1:4),
                         paste0("Y", 1:5)))
                         
    out &lt;- faIB(R = R.XY,  
                n = 710,
                NVarX = 4, 
                numFactors = 2,
                itemSort = FALSE,
                rotate = "oblimin",
                rotateControl = list(standardize  = "Kaiser",
                                     numberStarts = 10),
                Seed = 1)

 # Compare with Browne 1979 Table 2.
 print(round(out$loadings, 2))
 cat("\n\n")
 print(round(out$Phi,2))
 cat("\n\n MAD = ", round(out$fit["MAD"], 2),"\n\n")
 print( round(out$facIndeterminacy,2) )
 
 
 # Example 2:
 ## Correlation values taken from Boruch et al.(1970) Table 2 (p. 838)
 ## See also, Cudeck (1982) Table 1 (p. 59)
 corValues &lt;- c(
   1.0,
   .11,  1.0,
   .61,  .47, 1.0,
   .42, -.02, .18,  1.0,
   .75,  .33, .58,  .44, 1.0, 
   .82,  .01, .52,  .33, .68,  1.0,
   .77,  .32, .64,  .37, .80,  .65, 1.0,
   .15, -.02, .04,  .08, .12,  .11, .13, 1.0,
   -.04,  .22, .26, -.06, .07, -.10, .07, .09,  1.0,
   .13,  .21, .23,  .05, .07,  .06, .12, .64,  .40, 1.0,
   .01,  .04, .01,  .16, .05,  .07, .05, .41, -.10, .29, 1.0,
   .27,  .13, .18,  .17, .27,  .27, .27, .68,  .18, .47, .33, 1.0,
   .24,  .02, .12,  .12, .16,  .23, .18, .82,  .08, .55, .35, .76, 1.0,
   .20,  .18, .16,  .17, .22,  .11, .29, .69,  .20, .54, .34, .68, .68, 1.0)
 
 ## Generate empty correlation matrix
 BoruchCorr &lt;- matrix(0, nrow = 14, ncol = 14)
 
 ## Add upper-triangle correlations
 BoruchCorr[upper.tri(BoruchCorr, diag = TRUE)] &lt;- corValues
 BoruchCorr &lt;- BoruchCorr + t(BoruchCorr) - diag(14)
 
 ## Add variable names to the correlation matrix
 varNames &lt;- c("Consideration", "Structure", "Sup.Satisfaction", 
 "Job.Satisfaction", "Gen.Effectiveness", "Hum.Relations", "Leadership")
 
 ## Distinguish between rater X and rater Y
 varNames &lt;- paste0(c(rep("X.", 7), rep("Y.", 7)), varNames)
 
 ## Add row/col names to correlation matrix
 dimnames(BoruchCorr) &lt;- list(varNames, varNames)
 
 ## Estimate a model with one, two, and three factors
 for (jFactors in 1:3) {
   tempOutput &lt;- faIB(R          = BoruchCorr,
                      n          = 111,
                      NVarX      = 7,
                      numFactors = jFactors,
                      rotate     = "oblimin",
                      rotateControl = list(standardize  = "Kaiser",
                                           numberStarts = 100))
   
   cat("\nNumber of inter-battery factors:", jFactors,"\n")
   print( round(tempOutput$fit,2) )
 } # END for (jFactors in 1:3) 
 
 ## Compare output with Cudeck (1982) Table 2 (p. 60)
 BoruchOutput &lt;- 
   faIB(R             = BoruchCorr,
        n             = 111,
        NVarX         = 7,
        numFactors    = 2,
        rotate        = "oblimin",
        rotateControl = list(standardize = "Kaiser"))
 
 ## Print the inter-battery factor loadings
 print(round(BoruchOutput$loadings, 3)) 
 print(round(BoruchOutput$Phi, 3)) 
 
 
 
</code></pre>

<hr>
<h2 id='faLocalMin'>Investigate local minima in  faMain objects</h2><span id='topic+faLocalMin'></span>

<h3>Description</h3>

<p>Compute pairwise root mean squared deviations (RMSD) 
among rotated factor patterns in an <code>faMain</code> object. 
Prior to computing the RMSD values, each pair of solutions is aligned to 
the first member of the pair.  Alignment is accomplished using the 
Hungarian algorithm as described in <code>faAlign</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faLocalMin(fout, Set = 1, HPthreshold = 0.1, digits = 5, PrintLevel = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faLocalMin_+3A_fout">fout</code></td>
<td>
<p>(Object from class  <code>faMain</code>).</p>
</td></tr>
<tr><td><code id="faLocalMin_+3A_set">Set</code></td>
<td>
<p>(Integer) The index of the solution set (i.e., the collection of 
rotated factor patterns with a common complexity value) from an 
<code>faMain</code> object.</p>
</td></tr>
<tr><td><code id="faLocalMin_+3A_hpthreshold">HPthreshold</code></td>
<td>
<p>(Scalar) A number between [0, 1] that defines the 
hyperplane threshold. Factor pattern elements below <code>HPthreshold</code> in absolute 
value are counted in the hyperplane count.</p>
</td></tr>
<tr><td><code id="faLocalMin_+3A_digits">digits</code></td>
<td>
<p>(Integer) Specifies the  number of significant 
digits in the printed output. Default <code>digits = 5</code>.</p>
</td></tr>
<tr><td><code id="faLocalMin_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(Integer) Determines the level of printed output.
PrintLevel = 
</p>

<ul>
<li> <p><strong>0</strong>: No output is printed. 
</p>
</li>
<li> <p><strong>1</strong>: Print output for the six most discrepant pairs of 
rotated factor patterns.
</p>
</li>
<li> <p><strong>2</strong>: Print output for all  pairs of rotated factor patterns.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute pairwise RMSD values among rotated factor patterns from 
an <code>faMain</code> object.
</p>


<h3>Value</h3>

<p><code>faLocalMin</code> function will produce the following output.
</p>

<ul>
<li> <p><strong>rmsdTable</strong>: (Matrix) A table of <code>RMSD</code> values for each  pair of 
rotated factor patterns in  solution set <code>Set</code>.
</p>
</li>
<li> <p><strong>Set</strong>: (Integer) The index of the user-specified solution set.
</p>
</li>
<li> <p><strong>complexity.val</strong> (Numeric): The common complexity value for all members 
in the user-specified solution set.
</p>
</li>
<li> <p><strong>HPcount</strong>: (Integer) The hyperplane count for each factor pattern in the solution set.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  ## Generate Population Model and Monte Carlo Samples ####
  sout &lt;- simFA(Model = list(NFac = 5,
                          NItemPerFac = 5,
                           Model = "orthogonal"),
              Loadings = list(FacLoadDist = "fixed",
                              FacLoadRange = .8),
              MonteCarlo = list(NSamples = 100, 
                                SampleSize = 500),
              Seed = 655342)

  ## Population EFA loadings
  (True_A &lt;- sout$loadings)

  ## Population Phi matrix
  sout$Phi

  ## Compute EFA on Sample 67 ####
  fout &lt;- faMain (R = sout$Monte$MCData[[67]],
                numFactors = 5,
                targetMatrix = sout$loadings,
                facMethod = "fals",
                rotate= "cfT",
                rotateControl = list(numberStarts = 50,
                                     standardize="CM",
                                     kappa = 1/25),
                Seed=3366805)

  ## Summarize output from faMain
  summary(fout, Set = 1, DiagnosticsLevel = 2, digits=4)

  ## Investigate Local Solutions
  LMout &lt;- faLocalMin(fout, 
                    Set = 1,
                    HPthreshold = .15,
                    digits= 5, 
                    PrintLevel = 1)
                    
  ## Print hyperplane count for each factor pattern 
  ## in the solution set
  LMout$HPcount
  
## End(Not run)
</code></pre>

<hr>
<h2 id='fals'>Unweighted least squares factor analysis</h2><span id='topic+fals'></span>

<h3>Description</h3>

<p>Unweighted least squares factor analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fals(R, nfactors, TreatHeywood = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fals_+3A_r">R</code></td>
<td>
<p>Input correlation matrix.</p>
</td></tr>
<tr><td><code id="fals_+3A_nfactors">nfactors</code></td>
<td>
<p>Number of factors to extract.</p>
</td></tr>
<tr><td><code id="fals_+3A_treatheywood">TreatHeywood</code></td>
<td>
<p>If TreatHeywood = TRUE then a penalized least squares
function is used to bound the commonality estimates below 1.0.
Default(TreatHeywood = TRUE).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>loadings</code></td>
<td>
<p>Unrotated factor loadings. If a Heywood case is
present in the initial solution then the model is re-estimated via
non-iterated principal axes with max(rij^2) as fixed communaility (h2)
estimates.</p>
</td></tr> <tr><td><code>h2</code></td>
<td>
<p>Vector of final commonality estimates.</p>
</td></tr>
<tr><td><code>uniqueness</code></td>
<td>
<p>Vector of factor uniquenesses, i.e. (1 - h2).</p>
</td></tr>
<tr><td><code>Heywood</code></td>
<td>
<p>(logical) TRUE if a Heywood case was produced in the LS
solution.</p>
</td></tr> <tr><td><code>TreatHeywood</code></td>
<td>
<p>(logical) Value of the TreatHeywood
argument.</p>
</td></tr> <tr><td><code>converged</code></td>
<td>
<p>(logical) TRUE if all values of the gradient are
sufficiently close to zero.</p>
</td></tr> <tr><td><code>MaxAbsGrad</code></td>
<td>
<p>The maximum absolute value of
the gradient at the solution.</p>
</td></tr>  
<tr><td><code>f.value</code></td>
<td>
<p>The discrepancy value associated with the final solution.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

Rbig &lt;- fungible::rcor(120)                   
out1 &lt;- fals(R = Rbig, 
             nfactors = 2,
             TreatHeywood = TRUE)

</code></pre>

<hr>
<h2 id='faMain'>Automatic Factor Rotation from Random Configurations with Bootstrap Standard Errors</h2><span id='topic+faMain'></span>

<h3>Description</h3>

<p>This function conducts factor rotations (using the <span class="pkg">GPArotation</span> package) 
from a user-specified number of random (orthogonal) starting configurations. 
Based on the resulting complexity function value, the function determines the 
number of local minima and, among these local solutions, will find the 
&quot;global minimum&quot; (i.e., the minimized complexity value from the finite 
number of solutions). See Details below for an elaboration on the global 
minimum. This function can also return bootstrap standard errors of the factor solution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faMain(
  X = NULL,
  R = NULL,
  n = NULL,
  numFactors = NULL,
  facMethod = "fals",
  urLoadings = NULL,
  rotate = "oblimin",
  targetMatrix = NULL,
  bootstrapSE = FALSE,
  numBoot = 1000,
  CILevel = 0.95,
  Seed = 1,
  digits = NULL,
  faControl = NULL,
  rotateControl = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faMain_+3A_x">X</code></td>
<td>
<p>(Matrix) A raw data matrix (or data frame).</p>
</td></tr>
<tr><td><code id="faMain_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix.</p>
</td></tr>
<tr><td><code id="faMain_+3A_n">n</code></td>
<td>
<p>(Numeric) Sample size associated with the correlation matrix. Defaults to n = NULL.</p>
</td></tr>
<tr><td><code id="faMain_+3A_numfactors">numFactors</code></td>
<td>
<p>(Numeric) The number of factors to extract for subsequent rotation.</p>
</td></tr>
<tr><td><code id="faMain_+3A_facmethod">facMethod</code></td>
<td>
<p>(Character) The method used for factor extraction 
(<code><a href="#topic+faX">faX</a></code>). The supported options are &quot;fals&quot; for unweighted least 
squares, &quot;faml&quot; for maximum likelihood, &quot;fapa&quot; for iterated principal axis 
factoring, &quot;faregLS&quot; for regularized least squares,
&quot;faregML&quot; for regularized maximum likelihood, and &quot;pca&quot; for principal components 
analysis. The default method  is &quot;fals&quot;. 
</p>

<ul>
<li> <p><strong>&quot;fals&quot;</strong>: Factors are extracted using the unweighted least 
squares estimation procedure using the <code><a href="#topic+fals">fals</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faml&quot;</strong>: Factors are extracted using the maximum likelihood 
estimation procedure using the <code><a href="stats.html#topic+factanal">factanal</a></code> function.
</p>
</li>
<li> <p><strong>&quot;fapa&quot;</strong>: Factors are extracted using the iterated principal 
axis factoring estimation procedure using the <code><a href="#topic+fapa">fapa</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faregLS&quot;</strong>: Factors are extracted using regularized 
least squares factor analysis using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;faregML&quot;</strong>: Factors are extracted using regularized 
maximum likelihood factor using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;pca&quot;</strong>: Principal components are extracted. 
</p>
</li></ul>
</td></tr>
<tr><td><code id="faMain_+3A_urloadings">urLoadings</code></td>
<td>
<p>(Matrix) An unrotated factor-structure matrix to be rotated.</p>
</td></tr>
<tr><td><code id="faMain_+3A_rotate">rotate</code></td>
<td>
<p>(Character) Designate which rotation algorithm to apply. The 
following are available rotation options: &quot;oblimin&quot;, &quot;quartimin&quot;, &quot;targetT&quot;, 
&quot;targetQ&quot;, &quot;oblimax&quot;, &quot;entropy&quot;, &quot;quartimax&quot;, &quot;varimax&quot;, &quot;simplimax&quot;, 
&quot;bentlerT&quot;, &quot;bentlerQ&quot;, &quot;tandemI&quot;, &quot;tandemII&quot;, &quot;geominT&quot;, &quot;geominQ&quot;, &quot;cfT&quot;, 
&quot;cfQ&quot;, &quot;infomaxT&quot;, &quot;infomaxQ&quot;, &quot;mccammon&quot;, &quot;bifactorT&quot;, &quot;bifactorQ&quot;, and 
&quot;none&quot;. Defaults to rotate = &quot;oblimin&quot;. See <span class="pkg">GPArotation</span> package for more 
details. Note that rotations ending in &quot;T&quot; and &quot;Q&quot; represent orthogonal and 
oblique rotations, respectively.</p>
</td></tr>
<tr><td><code id="faMain_+3A_targetmatrix">targetMatrix</code></td>
<td>
<p>(Matrix) This argument serves two functions. First, if a 
user has requested either a &quot;targetT&quot; or &quot;targetQ' rotation, then 
the target matrix is used to conduct a fully or partially
specified target rotation. In the latter case,  freely estimated factor 
loadings are designated by &quot;NA&quot; values and rotation will be conducted using  
Browne's (1972a, 1972b, 2001) method for a partially-specified 
target rotation. Second, if any other rotation option is chosen then all 
rotated loadings matrices (and assorted output) will be aligned 
(but not rotated) with the target solution.</p>
</td></tr>
<tr><td><code id="faMain_+3A_bootstrapse">bootstrapSE</code></td>
<td>
<p>(Logical) Computes bootstrap standard errors. All bootstrap 
samples are aligned to the global minimum solution. Defaults to 
bootstrapSE = FALSE (no standard errors).</p>
</td></tr>
<tr><td><code id="faMain_+3A_numboot">numBoot</code></td>
<td>
<p>(Numeric) The number bootstraps. Defaults to numBoot = 1000.</p>
</td></tr>
<tr><td><code id="faMain_+3A_cilevel">CILevel</code></td>
<td>
<p>(Numeric) The confidence level (between 0 and 1) of the bootstrap 
confidence interval. Defaults to CILevel = .95.</p>
</td></tr>
<tr><td><code id="faMain_+3A_seed">Seed</code></td>
<td>
<p>(Numeric) Starting seed for reproducible bootstrap results and factor rotations. 
Defaults to Seed = 1.</p>
</td></tr>
<tr><td><code id="faMain_+3A_digits">digits</code></td>
<td>
<p>(Numeric) Rounds the values to the specified number of decimal 
places. Defaults to digits = NULL (no rounding).</p>
</td></tr>
<tr><td><code id="faMain_+3A_facontrol">faControl</code></td>
<td>
<p>(List) A list of optional parameters passed to the factor 
extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>

<ul>
<li> <p><strong>treatHeywood</strong>: (Logical) In <code>fals</code>, if treatHeywood is 
true, a penalized least squares function is used to bound the communality 
estimates below 1.0. Defaults to treatHeywood = TRUE.
</p>
</li>
<li> <p><strong>nStart</strong>: (Numeric) The number of starting values to be tried 
in <code>faml</code>. Defaults to nStart = 10.
</p>
</li>
<li> <p><strong>start</strong>: (Matrix) NULL or a matrix of starting values, each column 
giving an initial set of uniquenesses. Defaults to start = NULL. 
</p>
</li>
<li> <p><strong>maxCommunality</strong>: (Numeric) In <code>faml</code>, set the maximum 
communality value for the estimated solution. Defaults to maxCommunality = .995.
</p>
</li>
<li> <p><strong>epsilon</strong>: (Numeric) In <code>fapa</code>, the numeric threshold 
designating when the algorithm has converged. Defaults to epsilon = 1e-4.
</p>
</li>
<li> <p><strong>communality</strong>: (Character) The method used to estimate the 
initial communality values in <code>fapa</code>. Defaults to communality = 'SMC'.
</p>

<ul>
<li> <p><strong>&quot;SMC&quot;</strong>: Initial communalities are estimated by taking the 
squared multiple correlations of each indicator after regressing the 
indicator on the remaining variables.
</p>
</li>
<li> <p><strong>&quot;maxr&quot;</strong>: Initial communalities equal the largest 
(absolute value) correlation in each column of the correlation matrix.
</p>
</li>
<li> <p><strong>&quot;unity&quot;</strong>: Initial communalities equal 1.0 for all variables.
</p>
</li></ul>

</li>
<li> <p><strong>maxItr</strong>: (Numeric) In <code>fapa</code>, the maximum number of 
iterations to reach convergence. Defaults to maxItr = 15,000.
</p>
</li></ul>
</td></tr>
<tr><td><code id="faMain_+3A_rotatecontrol">rotateControl</code></td>
<td>
<p>(List) A list of control values to pass to the factor rotation algorithms.
</p>

<ul>
<li> <p><strong>numberStarts</strong>: (Numeric) The number of random (orthogonal) 
starting configurations for the chosen rotation method (e.g., oblimin). The first
rotation will always commence from the unrotated factors orientation.
Defaults to numberStarts = 10. 
</p>
</li>
<li> <p><strong>gamma</strong>: (Numeric) This is a tuning parameter (between 0 
and 1, inclusive) for an oblimin rotation.  See the <span class="pkg">GPArotation</span> 
library's oblimin documentation for more details. Defaults to gamma = 0 
(i.e., a quartimin rotation).
</p>
</li>
<li> <p><strong>delta</strong>: (Numeric) This is a tuning parameter for the geomin
rotation. It adds a small number (default = .01) to the squared factor 
loadings before computing the geometric means in the discrepancy function.
</p>
</li>
<li> <p><strong>kappa</strong>: (Numeric) The main parameterization of the 
Crawford-Ferguson (CF) rotations (i.e., &quot;cfT&quot; and &quot;cfQ&quot; for orthogonal and 
oblique CF rotation, respectively). Defaults to kappa = 0. 
</p>
</li>
<li> <p><strong>k</strong>: (Numeric) A specific parameter of the simplimax rotation. 
Defaults to k = the number of observed variables.
</p>
</li>
<li> <p><strong>standardize</strong>: (Character) The standardization routine used 
on the unrotated factor structure. The three options are &quot;none&quot;, &quot;Kaiser&quot;, 
and &quot;CM&quot;. Defaults to standardize = &quot;none&quot;. 
</p>

<ul>
<li> <p><strong>&quot;none&quot;</strong>: No standardization is applied to the unrotated 
factor structure. 
</p>
</li>
<li> <p><strong>&quot;Kaiser&quot;</strong>: Use a factor structure matrix that has been 
normed by Kaiser's method (i.e., normalize all rows to have a unit length).
</p>
</li>
<li> <p><strong>&quot;CM&quot;</strong>: Use a factor structure matrix that has been normed
by the Cureton-Mulaik method.
</p>
</li></ul>

</li>
<li> <p><strong>epsilon</strong>: (Numeric) The rotational convergence criterion to 
use. Defaults to epsilon = 1e-5.
</p>
</li>
<li> <p><strong>power</strong>: (Numeric) Raise factor loadings the the n-th power 
in the <code><a href="#topic+promaxQ">promaxQ</a></code> rotation. Defaults to power = 4.
</p>
</li>
<li> <p><strong>maxItr</strong>: (Numeric) The maximum number of iterations for the 
rotation algorithm. Defaults to maxItr = 15000.
</p>
</li></ul>
</td></tr>
<tr><td><code id="faMain_+3A_...">...</code></td>
<td>
<p>Values to be passed to the <code><a href="stats.html#topic+cor">cor</a></code> function.
</p>

<ul>
<li> <p><strong>use</strong>: (Character) A character string giving a method for 
computing correlations in the presence of missing values: &quot;everything&quot; 
(the default), &quot;all.obs&quot;, &quot;complete.obs&quot;, &quot;na.or.complete&quot;, or 
&quot;pairwise.complete.obs&quot;.
</p>
</li>
<li> <p><strong>method</strong>: (Character) A character string indicating which 
correlation coefficient is to be computed: &quot;pearson&quot; (the default), 
&quot;kendall&quot;, or &quot;spearman&quot;. 
</p>
</li>
<li> <p><strong>na.rm</strong>: (Logical) Should missing values be removed (TRUE) 
or not (FALSE)?
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Global Minimum</strong>: This function uses several random starting 
configurations for factor rotations in an attempt to find the global 
minimum solution. However, this function is not guaranteed to find the 
global minimum. Furthermore, the global minimum solution need not be 
more psychologically interpretable than any of the local solutions (cf. 
Rozeboom, 1992). As is recommended, our function returns all local 
solutions so users can make their own judgements.
</p>
</li>
<li> <p><strong>Finding clusters of local minima</strong>: We find local-solution sets by sorting the rounded 
rotation complexity values (to the number of  digits specified in the <code>epsilon</code> 
argument of the <code>rotateControl</code> list) into sets with equivalent values. For example, 
by default <code>epsilon = 1e-5.</code> will only evaluate the complexity 
values to five significant digits. Any differences beyond that value will not effect the final sorting. 
</p>
</li></ul>



<h3>Value</h3>

<p>The <code>faMain</code> function will produce a lot of output in addition 
to the rotated factor pattern matrix and the factor correlations.
</p>

<ul>
<li> <p><strong>R</strong>: (Matrix) Returns the correlation matrix, useful when raw data are supplied.
</p>
</li>
<li> <p><strong>loadings</strong>: (Matrix) The rotated factor solution with the 
lowest evaluated discrepancy function. This solution has the lowest 
discrepancy function <em>of the examined random starting configurations</em>. 
It is not guaranteed to find the &quot;true&quot; global minimum. Note that multiple
(or even all) local solutions can have the same discrepancy functions.
</p>
</li>
<li> <p><strong>Phi</strong>: (Matrix) The factor correlations of the rotated factor 
solution with the lowest evaluated discrepancy function (see Details).
</p>
</li>
<li> <p><strong>facIndeterminacy</strong>: (Vector) A vector (with length equal to the number of factors)
containing Guttman's (1955) index of factor indeterminacy for each factor. 
</p>
</li>
<li> <p><strong>h2</strong>: (Vector) The vector of final communality estimates. 
</p>
</li>
<li> <p><strong>loadingsSE</strong>: (Matrix) The matrix of factor-loading standard 
errors across the bootstrapped factor solutions. Each matrix element is 
the standard deviation of all bootstrapped factor loadings for that element position.
</p>
</li>
<li> <p><strong>CILevel</strong> (Numeric) The user-defined confidence level (between 0 and 1) of the bootstrap 
confidence interval. Defaults to CILevel = .95.
</p>
</li>
<li> <p><strong>loadingsCIupper</strong>: (Matrix) Contains the upper confidence 
interval of the bootstrapped factor loadings matrix. The confidence 
interval width is specified by the user.
</p>
</li>
<li> <p><strong>loadingsCIlower</strong>: (Matrix) Contains the lower confidence 
interval of the bootstrapped factor loadings matrix. The confidence 
interval width is specified by the user.
</p>
</li>
<li> <p><strong>PhiSE</strong>: (Matrix) The matrix of factor correlation standard 
errors across the bootstrapped factor solutions. Each matrix element is 
the standard deviation of all bootstrapped factor correlations for that element position.
</p>
</li>
<li> <p><strong>PhiCIupper</strong>: (Matrix) Contains the upper confidence interval 
of the bootstrapped factor correlation matrix. The confidence interval 
width is specified by the user.
</p>
</li>
<li> <p><strong>PhiCIlower</strong>: (Matrix) Contains the lower confidence interval 
of the bootstrapped factor correlation matrix. The confidence interval 
width is specified by the user.
</p>
</li>
<li> <p><strong>facIndeterminacySE</strong>: (Matrix) A row vector containing the 
standard errors of Guttman's (1955) factor indeterminacy indices across the 
bootstrap factor solutions. 
</p>
</li>
<li> <p><strong>localSolutions</strong>: (List) A list containing all local solutions 
in ascending order of their factor loadings, rotation complexity values (i.e., the first solution 
is the &quot;global&quot; minimum). Each solution returns the 
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) the factor loadings, 
</p>
</li>
<li> <p><strong>Phi</strong>: (Matrix) factor correlations, 
</p>
</li>
<li> <p><strong>RotationComplexityValue</strong>: (Numeric) the complexity value of the rotation algorithm, 
</p>
</li>
<li> <p><strong>facIndeterminacy</strong>: (Vector) A vector of factor indeterminacy indices for each common factor, and 
</p>
</li>
<li> <p><strong>RotationConverged</strong>: (Logical) convergence status of the rotation algorithm. 
</p>
</li></ul>

</li>
<li> <p><strong>numLocalSets</strong> (Numeric) How many sets of local solutions
with the same discrepancy value were obtained. 
</p>
</li>
<li> <p><strong>localSolutionSets</strong>: (List) A list containing the sets of 
unique local minima solutions. There is one list element for every unique 
local solution that includes (a) the factor loadings matrix, (b) the factor 
correlation matrix (if estimated), and (c) the discrepancy value of the rotation algorithm. 
</p>
</li>
<li> <p><strong>loadingsArray</strong>: (Array) Contains an array of all bootstrapped 
factor loadings. The dimensions are factor indicators, factors, and the 
number of bootstrapped samples (representing the row, column, and depth, respectively).
</p>
</li>
<li> <p><strong>PhiArray</strong>: (Array) Contains an array of all bootstrapped 
factor correlations. The dimension are the number of factors, the number 
of factors, and the number of bootstrapped samples (representing the row,
column, and depth, respectively).
</p>
</li>
<li> <p><strong>facIndeterminacyArray</strong>: (Array) Contains an array of all 
bootstrap factor indeterminacy indices. The dimensions are 1, the number 
of factors, and the number of bootstrap samples (representing the row, 
column, and depth order, respectively).
</p>
</li>
<li> <p><strong>faControl</strong>: (List) A list of the control parameters passed 
to the factor extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>
</li>
<li> <p><strong>faFit</strong>: (List) A list of additional output from the factor
extraction routines. 
</p>

<ul>
<li> <p><strong>facMethod</strong>: (Character) The factor extraction routine.
</p>
</li>
<li> <p><strong>df</strong>: (Numeric) Degrees of Freedom from the maximum 
likelihood factor extraction routine.
</p>
</li>
<li> <p><strong>n</strong>: (Numeric) Sample size associated with the correlation matrix.
</p>
</li>
<li> <p><strong>objectiveFunc</strong>: (Numeric) The evaluated objective function for the 
maximum likelihood factor extraction routine. 
</p>
</li>
<li> <p><strong>RMSEA</strong>: (Numeric) Root mean squared error of approximation 
from Steiger &amp; Lind (1980). Note that bias correction is computed if the 
sample size is provided.
</p>
</li>
<li> <p><strong>testStat</strong>: (Numeric) The significance test statistic for the maximum 
likelihood procedure. Cannot be computed unless a sample size is provided. 
</p>
</li>
<li> <p><strong>pValue</strong>: (Numeric) The p value associated with the significance test 
statistic for the maximum likelihood procedure. Cannot be computed unless 
a sample size is provided. 
</p>
</li>
<li> <p><strong>gradient</strong>: (Matrix) The solution gradient for the least squares factor 
extraction routine. 
</p>
</li>
<li> <p><strong>maxAbsGradient</strong>: (Numeric) The maximum absolute value of the 
gradient at the least squares solution. 
</p>
</li>
<li> <p><strong>Heywood</strong>: (Logical) TRUE if a Heywood case was produced.
</p>
</li>
<li> <p><strong>convergedX</strong>: (Logical) TRUE if the factor 
<strong>extraction</strong> routine converged. 
</p>
</li>
<li> <p><strong>convergedR</strong>: (Logical) TRUE if the factor <strong>rotation</strong> 
routine converged (for the local solution with the minimum discrepancy 
value).
</p>
</li></ul>

</li>
<li> <p><strong>rotateControl</strong>: (List) A list of the control parameters 
passed to the rotation algorithm.
</p>
</li>
<li> <p><strong>unSpunSolution</strong>: (List) A list of output parameters (e.g., loadings, Phi, etc) from 
the rotated solution that was obtained by rotating directly from the unrotated (i.e., unspun) common factor orientation. 
</p>
</li>
<li> <p><strong>targetMatrix</strong> (Matrix) The input target matrix if supplied by the user.
</p>
</li>
<li> <p><strong>Call</strong>: (call) A copy of the function call.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li>
<li><p> The authors thank Allie Cooperman and Hoang
Nguyen for their help implementing the standard error estimation and the 
Cureton-Mulaik standardization procedure.
</p>
</li></ul>



<h3>References</h3>

<p>Browne, M. W.  (1972).  Oblique rotation to a partially specified 
target.  <em>British Journal of Mathematical and Statistical Psychology, 25</em>,(1), 
207-212.
</p>
<p>Browne, M. W. (1972b). Orthogonal rotation to a partially specifed
target. <em>British Journal of Statistical Psychology, 25</em>,(1), 115-120.
</p>
<p>Browne, M. W. (2001). An overview of analytic rotation in 
exploratory factor analysis. <em>Multivariate Behavioral Research, 36</em>(1), 111-150.
</p>
<p>Cureton, E. E., &amp; Mulaik, S. A. (1975). The weighted varimax 
rotation and the promax rotation. <em>Psychometrika, 40</em>(2), 183-195.
</p>
<p>Guttman, L. (1955). The determinacy of factor score matrices with 
implications for five other basic problems of common factor theory. 
<em>British Journal of Statistical Psychology, 8</em>(2), 65-81.
</p>
<p>Jung, S. &amp; Takane, Y.  (2008).  Regularized common factor analysis.  
<em>New Trends in Psychometrics</em>, 141-149.
</p>
<p>Mansolf, M., &amp; Reise, S. P. (2016). Exploratory bifactor 
analysis: The Schmid-Leiman orthogonalization and Jennrich-Bentler 
analytic rotations. <em>Multivariate Behavioral Research, 51</em>(5), 698-717.
</p>
<p>Rozeboom, W. W. (1992). The glory of suboptimal factor rotation: 
Why local minima in analytic optimization of simple structure are more 
blessing than curse. <em>Multivariate Behavioral Research, 27</em>(4), 585-599.
</p>
<p>Zhang, G. (2014). Estimating standard errors in exploratory factor 
analysis. <em>Multivariate Behavioral Research, 49</em>(4), 339-353.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1

## Generate an oblique factor model
lambda &lt;- matrix(c(.41, .00, .00,
                   .45, .00, .00,
                   .53, .00, .00,
                   .00, .66, .00,
                   .00, .38, .00,
                   .00, .66, .00,
                   .00, .00, .68,
                   .00, .00, .56,
                   .00, .00, .55),
                 nrow = 9, ncol = 3, byrow = TRUE)

## Generate factor correlation matrix
Phi &lt;- matrix(.50, nrow = 3, ncol = 3)
diag(Phi) &lt;- 1

## Model-implied correlation matrix
R &lt;- lambda %*% Phi %*% t(lambda)
diag(R) &lt;- 1

## Load the MASS package to create multivariate normal data
library(MASS)

## Generate raw data to perfectly reproduce R
X &lt;- mvrnorm(Sigma = R, mu = rep(0, nrow(R)), empirical = TRUE, n = 300)

## Not run: 
## Execute 50 promax rotations from a least squares factor extraction
## Compute 100 bootstrap samples to compute standard errors and 
## 80 percent confidence intervals
Out1 &lt;- faMain(X             = X,
               numFactors    = 3,
               facMethod     = "fals",
               rotate        = "promaxQ",
               bootstrapSE   = TRUE,
               numBoot       = 100,
               CILevel       = .80,
               faControl     = list(treatHeywood = TRUE),
               rotateControl = list(numberStarts = 2,  
                                    power        = 4,
                                    standardize  = "Kaiser"),
               digits        = 2)
Out1[c("loadings", "Phi")] 

## End(Not run)

## Example 2

## Load Thurstone's (in)famous box data
data(Thurstone, package = "GPArotation")

## Execute 5 oblimin rotations with Cureton-Mulaik standardization 
Out2 &lt;- faMain(urLoadings    = box26,
               rotate        = "oblimin",
               bootstrapSE   = FALSE,
               rotateControl = list(numberStarts = 5,
                                    standardize  = "CM",
                                    gamma        = 0,
                                    epsilon      = 1e-6),
               digits        = 2)
               
Out2[c("loadings", "Phi")]     

## Example 3

## Factor matrix from Browne 1972
lambda &lt;- matrix(c(.664,  .322, -.075,
                   .688,  .248,  .192,
                   .492,  .304,  .224,
                   .837, -.291,  .037,
                   .705, -.314,  .155,
                   .820, -.377, -.104,
                   .661,  .397,  .077,
                   .457,  .294, -.488,
                   .765,  .428,  .009), 
                 nrow = 9, ncol = 3, byrow = TRUE)   
                 
## Create partially-specified target matrix
Targ &lt;- matrix(c(NA, 0,  NA,
                 NA, 0,  0,
                 NA, 0,  0,
                 NA, NA, NA,
                 NA, NA, 0,
                 NA, NA, NA,
                 .7, NA, NA,
                 0,  NA, NA,
                 .7, NA, NA), 
               nrow = 9, ncol = 3, byrow = TRUE)  
               
## Perform target rotation              
Out3 &lt;- faMain(urLoadings   = lambda,
               rotate       = "targetT",
               targetMatrix = Targ,
               digits       = 3)$loadings
Out3
</code></pre>

<hr>
<h2 id='faMAP'>Velicer's minimum partial correlation method for determining the number of
major components for a principal components analysis or a factor analysis</h2><span id='topic+faMAP'></span>

<h3>Description</h3>

<p>Uses Velicer's MAP (i.e., matrix of partial correlations) procedure to
determine the number of components from a matrix of partial correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faMAP(R, max.fac = 8, Print = TRUE, Plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faMAP_+3A_r">R</code></td>
<td>
<p>input data in the form of a correlation matrix.</p>
</td></tr>
<tr><td><code id="faMAP_+3A_max.fac">max.fac</code></td>
<td>
<p>maximum number of dimensions to extract.</p>
</td></tr>
<tr><td><code id="faMAP_+3A_print">Print</code></td>
<td>
<p>(logical) Print = TRUE will print complete results.</p>
</td></tr>
<tr><td><code id="faMAP_+3A_plot">Plot</code></td>
<td>
<p>(logical) Plot = TRUE will plot the MAP values.</p>
</td></tr>
<tr><td><code id="faMAP_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to the plot functions (see <code>par</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>MAP</code></td>
<td>
<p>Minimum partial correlations</p>
</td></tr> <tr><td><code>MAP4</code></td>
<td>
<p>Minimum partial
correlations</p>
</td></tr> <tr><td><code>fm</code></td>
<td>
<p>average of the squared partial correlations after
the first m components are partialed out.</p>
</td></tr> <tr><td><code>fm4</code></td>
<td>
<p>see Velicer, Eaton, &amp;
Fava, 2000.</p>
</td></tr> <tr><td><code>PlotAvgSq</code></td>
<td>
<p>A saved object of the original MAP plot (based
on the average squared partial r's.)</p>
</td></tr> <tr><td><code>PlotAvg4th</code></td>
<td>
<p>A saved object of
the revised MAP plot (based on the average 4th power of the partial r's.)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Velicer, W. (1976). Determining the number of components from
the matrix of partial correlations. Psychometrika, 41(3):321&ndash;327.
</p>
<p>Velicer,W. F., Eaton, C. A. , &amp; Fava, J. L. (2000). Construct explication
through factor or component analysis: A review and evaluation of alternative
procedures for determining the number of factors or components. In R. D.
Goffin &amp; E. Helmes (Eds.). Problems and Solutions in Human Assessment:
Honoring Douglas N. Jackson at Seventy (pp. 41-71. Boston, MA: Kluwer
Academic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
	# Harman's data (1967, p 80) 
	# R = matrix(c(
	# 1.000,  .846,  .805,  .859,  .473,  .398,  .301,  .382,
	#  .846, 1.000,  .881,  .826,  .376,  .326,  .277,  .415,
	#  .805,  .881, 1.000,  .801,  .380,  .319,  .237,  .345,
	#  .859,  .826,  .801, 1.000,  .436,  .329,  .327,  .365,
	#  .473,  .376,  .380,  .436, 1.000,  .762,  .730,  .629,
	#  .398,  .326,  .319,  .329,  .762, 1.000,  .583,  .577,
	#  .301,  .277,  .237,  .327,  .730,  .583, 1.000,  .539,
	#  .382,  .415,  .345,  .365,  .629,  .577,  .539, 1.000), 8,8)

	  F &lt;- matrix(c(  .4,  .1,  .0,
	                  .5,  .0,  .1,
	                  .6,  .03, .1,
	                  .4, -.2,  .0,
	                   0,  .6,  .1,
	                  .1,  .7,  .2,
	                  .3,  .7,  .1,
	                   0,  .4,  .1,
	                   0,   0,  .5,
	                  .1, -.2,  .6, 
	                  .1,  .2,  .7,
	                 -.2,  .1,  .7),12,3)
					 
	  R &lt;- F %*% t(F)
	  diag(R) &lt;- 1 
	  
  	faMAP(R, max.fac = 8, Print = TRUE, Plot = TRUE) 

</code></pre>

<hr>
<h2 id='faMB'>Multiple Battery Factor Analysis by Maximum Likelihood Methods</h2><span id='topic+faMB'></span>

<h3>Description</h3>

<p><code>faMB</code> estimates multiple battery factor analysis using maximum 
likelihood estimation procedures described by Browne (1979, 1980). Unrotated
multiple battery solutions are rotated (using the <span class="pkg">GPArotation</span> package) 
from a user-specified number of of random (orthogonal) starting configurations. 
Based on procedures analogous to those in the <code><a href="#topic+faMain">faMain</a></code> function,
rotation complexity values of all solutions are ordered to determine
the number of local solutions and the &quot;global&quot; minimum solution (i.e., the 
minimized rotation complexity value from the finite number of solutions).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faMB(
  X = NULL,
  R = NULL,
  n = NULL,
  NB = NULL,
  NVB = NULL,
  numFactors = NULL,
  epsilon = 1e-06,
  rotate = "oblimin",
  rotateControl = NULL,
  PrintLevel = 0,
  Seed = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faMB_+3A_x">X</code></td>
<td>
<p>(Matrix) A raw data matrix (or data frame) structured in a subject 
(row) by variable (column) format. Defaults to <code>X = NULL</code>.</p>
</td></tr>
<tr><td><code id="faMB_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix. Defaults to <code>R = NULL</code>.</p>
</td></tr>
<tr><td><code id="faMB_+3A_n">n</code></td>
<td>
<p>(Numeric) Sample size associated with either the raw data (X) or 
the correlation matrix (R). Defaults to <code>n = NULL</code>.</p>
</td></tr>
<tr><td><code id="faMB_+3A_nb">NB</code></td>
<td>
<p>(Numeric) The number of batteries to analyze. In interbattery factor analysis NB = 2.</p>
</td></tr>
<tr><td><code id="faMB_+3A_nvb">NVB</code></td>
<td>
<p>(Vector) The number of variables in each battery. For example, 
analyzing three batteries including seven, four, and five variables 
(respectively) would be specified as <code>NVB = c(7, 4, 5)</code>.</p>
</td></tr>
<tr><td><code id="faMB_+3A_numfactors">numFactors</code></td>
<td>
<p>(Numeric) The number of factors to extract for subsequent 
rotation. Defaults to <code>numFactors = NULL</code>.</p>
</td></tr>
<tr><td><code id="faMB_+3A_epsilon">epsilon</code></td>
<td>
<p>(Numeric) The convergence threshold for the Gauss-Seidel iterator
when analyzing three or more batteries. Defaults to <code>epsilon = 1e-06</code>.</p>
</td></tr>
<tr><td><code id="faMB_+3A_rotate">rotate</code></td>
<td>
<p>(Character) Designate which rotation algorithm to apply. The 
following are available rotation options: &quot;oblimin&quot;, &quot;quartimin&quot;, 
&quot;oblimax&quot;, &quot;entropy&quot;, &quot;quartimax&quot;, &quot;varimax&quot;, &quot;simplimax&quot;, 
&quot;bentlerT&quot;, &quot;bentlerQ&quot;, &quot;tandemI&quot;, &quot;tandemII&quot;, &quot;geominT&quot;, &quot;geominQ&quot;, &quot;cfT&quot;, 
&quot;cfQ&quot;, &quot;infomaxT&quot;, &quot;infomaxQ&quot;, &quot;mccammon&quot;, &quot;bifactorT&quot;, &quot;bifactorQ&quot;, and 
&quot;none&quot;. Defaults to rotate = &quot;oblimin&quot;. See <span class="pkg">GPArotation</span> package for more 
details. Note that rotations ending in &quot;T&quot; and &quot;Q&quot; represent orthogonal and 
oblique rotations, respectively.</p>
</td></tr>
<tr><td><code id="faMB_+3A_rotatecontrol">rotateControl</code></td>
<td>
<p>(List) A list of control values to pass to the factor rotation algorithms.
</p>

<ul>
<li> <p><strong>numberStarts</strong>: (Numeric) The number of random (orthogonal) 
starting configurations for the chosen rotation method (e.g., oblimin). The first
rotation will always commence from the unrotated factors orientation.
Defaults to numberStarts = 10. 
</p>
</li>
<li> <p><strong>gamma</strong>: (Numeric) This is a tuning parameter (between 0 
and 1, inclusive) for an oblimin rotation.  See the <span class="pkg">GPArotation</span> 
library's oblimin documentation for more details. Defaults to gamma = 0 
(i.e., a quartimin rotation).
</p>
</li>
<li> <p><strong>delta</strong>: (Numeric) This is a tuning parameter for the geomin
rotation. It adds a small number (default = .01) to the squared factor 
loadings before computing the geometric means in the discrepancy function.
</p>
</li>
<li> <p><strong>kappa</strong>: (Numeric) The main parameterization of the 
Crawford-Ferguson (CF) rotations (i.e., &quot;cfT&quot; and &quot;cfQ&quot; for orthogonal and 
oblique CF rotation, respectively). Defaults to kappa = 0. 
</p>
</li>
<li> <p><strong>k</strong>: (Numeric) A specific parameter of the simplimax rotation. 
Defaults to k = the number of observed variables.
</p>
</li>
<li> <p><strong>standardize</strong>: (Character) The standardization routine used 
on the unrotated factor structure. The three options are &quot;none&quot;, &quot;Kaiser&quot;, 
and &quot;CM&quot;. Defaults to standardize = &quot;none&quot;. 
</p>

<ul>
<li> <p><strong>&quot;none&quot;</strong>: No standardization is applied to the unrotated 
factor structure. 
</p>
</li>
<li> <p><strong>&quot;Kaiser&quot;</strong>: Use a factor structure matrix that has been 
normed by Kaiser's method (i.e., normalize all rows to have a unit length).
</p>
</li>
<li> <p><strong>&quot;CM&quot;</strong>: Use a factor structure matrix that has been normed
by the Cureton-Mulaik method.
</p>
</li></ul>

</li>
<li> <p><strong>epsilon</strong>: (Numeric) The rotational convergence criterion to 
use. Defaults to epsilon = 1e-5.
</p>
</li>
<li> <p><strong>power</strong>: (Numeric) Raise factor loadings the the n-th power 
in the <code><a href="#topic+promaxQ">promaxQ</a></code> rotation. Defaults to power = 4.
</p>
</li>
<li> <p><strong>maxItr</strong>: (Numeric) The maximum number of iterations for the 
rotation algorithm. Defaults to maxItr = 15000.
</p>
</li></ul>
</td></tr>
<tr><td><code id="faMB_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(Numeric) When a value greater than zero is specified, 
<code>PrintLevel</code> prints the maximum change in communality estimates 
for each iteration of the Gauss-Seidel function. Note that Gauss-Seidel 
iteration is only called when three or more 
batteries are analyzed. Defaults to <code>PrintLevel = 0</code>.</p>
</td></tr>
<tr><td><code id="faMB_+3A_seed">Seed</code></td>
<td>
<p>(Integer) Starting seed for the random number generator. 
Defaults to <code>Seed = 1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>faMB</code> function will produce abundant output in addition
to the rotated multiple battery factor pattern and factor correlation matrices. 
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) The (possibly) rotated multiple battery factor solution with the 
lowest evaluated complexity value <em>of the examined random starting configurations</em>. 
It is not guaranteed to find the &quot;true&quot; global minimum. Note that multiple
(or even all) local solutions can have the same discrepancy functions.
</p>
</li>
<li> <p><strong>Phi</strong>: (Matrix) The factor correlations of the rotated factor 
solution with the lowest evaluated discrepancy function (see Details).
</p>
</li>
<li> <p><strong>fit</strong>: (Vector) A vector containing the following fit statistics:
</p>

<ul>
<li> <p><strong>ChiSq</strong>: Chi-square goodness of fit value. 
Note that, as recommended by Browne (1979), we apply Lawley's (1959) correction when computing the chi-square value when <code>NB = 2</code>.
</p>
</li>
<li> <p><strong>DF</strong>: Degrees of freedom for the estimated model. 
</p>
</li>
<li> <p><strong>pvalue</strong>: P-value associated with the above chi-square statistic.
</p>
</li>
<li> <p><strong>AIC</strong>: Akaike's Information Criterion where a lower value indicates better fit. 
</p>
</li>
<li> <p><strong>BIC</strong>: Bayesian Information Criterion where a lower value indicates better fit. 
</p>
</li>
<li> <p><strong>RMSEA</strong>: Root mean squared error of approximation (Steiger &amp; Lind, 1980).
</p>
</li></ul>

</li>
<li> <p><strong>R</strong>: (Matrix) The <em>sample</em> correlation matrix, 
useful when raw data are supplied. 
</p>
</li>
<li> <p><strong>Rhat</strong>: (Matrix) The <em>reproduced</em> correlation matrix with communalities on the diagonal. 
</p>
</li>
<li> <p><strong>Resid</strong>: (Matrix) A residual matrix (R - Rhat). 
</p>
</li>
<li> <p><strong>facIndeterminacy</strong>: (Vector) A vector (with length equal to the number of factors)
containing Guttman's (1955) index of factor indeterminacy for each factor. 
</p>
</li>
<li> <p><strong>localSolutions</strong>: (List) A list (of length equal to the 
<code>numberStarts</code> argument within <code>rotateControl</code>) containing all local solutions 
in ascending order of their rotation complexity values (i.e., the first solution 
is the &quot;global&quot; minimum). Each solution returns the following:
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) the factor loadings, 
</p>
</li>
<li> <p><strong>Phi</strong>: (Matrix) factor correlations, 
</p>
</li>
<li> <p><strong>RotationComplexityValue</strong>: (Numeric) the complexity value of the rotation algorithm, 
</p>
</li>
<li> <p><strong>facIndeterminacy</strong>: (Vector) A vector of factor indeterminacy indices for each common factor, and 
</p>
</li>
<li> <p><strong>RotationConverged</strong>: (Logical) convergence status of the rotation algorithm. 
</p>
</li></ul>

</li>
<li> <p><strong>numLocalSets</strong>: (Numeric) An integer indicating how many sets of local solutions
with the same discrepancy value were obtained. 
</p>
</li>
<li> <p><strong>localSolutionSets</strong>: (List) A list (of length equal to the 
<code>numLocalSets</code>) that contains all local solutions with the same 
rotation complexity value. Note that it is not guarenteed that all 
solutions with the same complexity values have equivalent factor loading patterns. 
</p>
</li>
<li> <p><strong>rotate</strong>: (Character) The chosen rotation algorithm.
</p>
</li>
<li> <p><strong>rotateControl</strong>: (List) A list of the control parameters 
passed to the rotation algorithm.
</p>
</li>
<li> <p><strong>unSpunSolution</strong>: (List) A list of output parameters (e.g., loadings, Phi, etc) from 
the rotated solution that was obtained by rotating directly from the unspun 
(i.e., not multiplied by a random orthogonal transformation matrix) common 
factor orientation. 
</p>
</li>
<li> <p><strong>Call</strong>: (call) A copy of the function call.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Boruch, R. F., Larkin, J. D., Wolins, L., &amp; MacKinney, A. C. (1970). 
Alternative methods of analysis: Multitrait-multimethod data. <em>Educational 
and Psychological Measurement, 30</em>(4), 833853. 
https://doi.org/10.1177/0013164470030004055
</p>
<p>Browne, M. W.  (1979).  The maximum-likelihood solution in inter-battery factor analysis. 
<em>British Journal of Mathematical and Statistical Psychology, 32</em>(1), 75-86.
</p>
<p>Browne, M. W.  (1980).  Factor analysis of multiple batteries by maximum likelihood.  
<em>British Journal of Mathematical and Statistical Psychology, 33</em>(2), 184-199.
</p>
<p>Browne, M. W. (2001). An overview of analytic rotation in 
exploratory factor analysis. <em>Multivariate Behavioral Research, 36</em>(1), 111-150.
</p>
<p>Browne, M. and Cudeck, R. (1992). Alternative ways of assessing model fit. 
<em>Sociological Methods and Research, 21(2)</em>, 230-258.
</p>
<p>Burnham, K. P. &amp; Anderson, D. R.  (2004).  Multimodel inference: Understanding AIC and BIC in model selection.  
<em>Sociological methods and research, 33</em>, 261-304.
</p>
<p>Cudeck, R. (1982). Methods for estimating between-battery factors,
<em>Multivariate Behavioral Research, 17</em>(1), 47-68. 10.1207/s15327906mbr1701_3
</p>
<p>Cureton, E. E., &amp; Mulaik, S. A. (1975). The weighted varimax 
rotation and the promax rotation. <em>Psychometrika, 40</em>(2), 183-195.
</p>
<p>Guttman, L. (1955). The determinacy of factor score matrices with 
implications for five other basic problems of common factor theory. 
<em>British Journal of Statistical Psychology, 8</em>(2), 65-81.
</p>
<p>Steiger, J. &amp; Lind, J. (1980). Statistically based tests for the
number of common factors. In <em>Annual meeting of the Psychometric Society, 
Iowa City, IA, volume 758</em>.
</p>
<p>Tucker, L. R.  (1958).  An inter-battery method of factor analysis.  
<em>Psychometrika, 23</em>(2), 111-136.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># These examples reproduce published multiple battery analyses. 

# ----EXAMPLE 1: Browne, M. W. (1979)----
#
# Data originally reported in:
# Thurstone, L. L. &amp; Thurstone, T. G. (1941). Factorial studies 
# of intelligence. Psychometric Monograph (2), Chicago: Univ. 
# Chicago Press.

## Load Thurstone &amp; Thurstone's data used by Browne (1979)
data(Thurstone41)

Example1Output &lt;-  faMB(R             = Thurstone41, 
                        n             = 710,
                        NB            = 2, 
                        NVB           = c(4,5), 
                        numFactors    = 2,
                        rotate        = "oblimin",
                        rotateControl = list(standardize = "Kaiser"))
                        
summary(Example1Output, PrintLevel = 2)                         

# ----EXAMPLE 2: Browne, M. W. (1980)----
# Data originally reported in:
# Jackson, D. N. &amp; Singer, J. E. (1967). Judgments, items and 
# personality. Journal of Experimental Research in Personality, 20, 70-79.

## Load Jackson and Singer's dataset
data(Jackson67)



Example2Output &lt;-  faMB(R             = Jackson67, 
                        n             = 480,
                        NB            = 5, 
                        NVB           = rep(4,5), 
                        numFactors    = 4,
                        rotate        = "varimax",
                        rotateControl = list(standardize = "Kaiser"),
                        PrintLevel    = 1)
                        
summary(Example2Output)                         



# ----EXAMPLE 3: Cudeck (1982)----
# Data originally reported by:
# Malmi, R. A., Underwood, B. J., &amp; Carroll, J. B. (1979).
# The interrelationships among some associative learning tasks. 
# Bulletin of the Psychonomic Society, 13(3), 121-123. DOI: 10.3758/BF03335032 

## Load Malmi et al.'s dataset
data(Malmi79)

Example3Output &lt;- faMB(R             = Malmi79, 
                       n             = 97,
                       NB            = 3, 
                       NVB           = c(3, 3, 6), 
                       numFactors    = 2,
                       rotate        = "oblimin",
                       rotateControl = list(standardize = "Kaiser"))
                       
summary(Example3Output)                        



# ----Example 4: Cudeck (1982)----
# Data originally reported by: 
# Boruch, R. F., Larkin, J. D., Wolins, L. and MacKinney, A. C. (1970). 
#  Alternative methods of analysis: Multitrait-multimethod data. Educational 
#  and Psychological Measurement, 30,833-853.

## Load Boruch et al.'s dataset
data(Boruch70)

Example4Output &lt;- faMB(R             = Boruch70,
                       n             = 111,
                       NB            = 2,
                       NVB           = c(7,7),
                       numFactors    = 2,
                       rotate        = "oblimin",
                       rotateControl = list(standardize  = "Kaiser",
                                            numberStarts = 100))
                                            
summary(Example4Output, digits = 3)                                             

</code></pre>

<hr>
<h2 id='fapa'>Iterated Principal Axis Factor Analysis (fapa)</h2><span id='topic+fapa'></span>

<h3>Description</h3>

<p>This function applies the iterated principal axis factoring method to extract an unrotated factor structure matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fapa(
  R,
  numFactors = NULL,
  epsilon = 1e-04,
  communality = "SMC",
  maxItr = 15000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fapa_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix to be analyzed.</p>
</td></tr>
<tr><td><code id="fapa_+3A_numfactors">numFactors</code></td>
<td>
<p>(Numeric) The number of factors to extract.</p>
</td></tr>
<tr><td><code id="fapa_+3A_epsilon">epsilon</code></td>
<td>
<p>(Numeric) A numeric threshold to designate whether the function has converged. The default value is 1e-4.</p>
</td></tr>
<tr><td><code id="fapa_+3A_communality">communality</code></td>
<td>
<p>(Character) The routine requires an initial estimate of the communality values. There are three options (see below) with &quot;SMC&quot; (i.e., squared multiple correlation) being the default.
</p>

<ul>
<li> <p><strong>&quot;SMC&quot;</strong>: Initial communalities are estimated by taking the squared multiple correlations of each indicator after regressing the indicator on the remaining variables. The following equation is employed to find the squared multiple correlation: <code class="reqn">1 - 1 / diag(R^-1)</code>.
</p>
</li>
<li> <p><strong>&quot;maxr&quot;</strong>: Initial communalities equal the largest (absolute value) correlation in each column of the correlation matrix.
</p>
</li>
<li> <p><strong>&quot;unity&quot;</strong>: Initial communalities equal 1.0 for all variables.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fapa_+3A_maxitr">maxItr</code></td>
<td>
<p>(Numeric) The maximum number of iterations to reach convergence. The default is 15,000.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Initial communality estimate</strong>: The choice of the initial communality estimate can impact the resulting principal axis factor solution.
</p>

<ul>
<li> <p><strong>Impact on the Estimated Factor Structure</strong>: According to Widaman and Herringer (1985), the initial communality estimate does not have much bearing on the resulting solution <em>when a stringent convergence criterion is used</em>. In their analyses, a convergence criterion of .001 (i.e., slightly less stringent than the default of 1e-4) is sufficiently stringent to produce virtually identical communality estimates irrespective of the initial estimate used. Based on their findings, it is not recommended to use a convergence criterion lower than 1e-3.
</p>
</li>
<li> <p><strong>Impact on the Iteration Procedure</strong>: The initial communality estimates have little impact on the <em>final factor structure</em> but they can impact the iterated procedure. It is possible that poor communality estimates produce a non-positive definite correlation matrix (i.e., eigenvalues &lt;= 0) whereas different communality estimates  result in a converged solution. If the fapa procedure fails to converge due to a non-positive definite matrix, try using different communality estimates before changing the convergence criterion.
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p>The main output is the matrix of unrotated factor loadings.
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) A matrix of unrotated factor loadings extracted via iterated principal axis factoring.
</p>
</li>
<li> <p><strong>h2</strong>: (Vector) A vector containing the resulting communality values.
</p>
</li>
<li> <p><strong>iterations</strong>: (Numeric) The number of iterations required to converge.
</p>
</li>
<li> <p><strong>converged</strong>: (Logical) TRUE if the iterative procedure converged.
</p>
</li>
<li> <p><strong>faControl</strong>: (List) A list of the control parameters used to generate the factor structure.
</p>

<ul>
<li> <p><strong>epsilon</strong>: (Numeric) The convergence criterion used for evaluating each iteration.
</p>
</li>
<li> <p><strong>communality</strong>: (Character) The method for estimating the initial communality values.
</p>
</li>
<li> <p><strong>maxItr</strong>: (Numeric) The maximum number of allowed iterations to reach convergence.
</p>
</li></ul>

</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Widaman, K. F., &amp; Herringer, L. G. (1985). Iterative least squares estimates of communality: Initial estimate need not affect stabilized value. <em>Psychometrika, 50</em>(4), 469-477.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate an example factor structure matrix
lambda &lt;- matrix(c(.62, .00, .00,
                   .54, .00, .00,
                   .41, .00, .00,
                   .00, .31, .00,
                   .00, .58, .00,
                   .00, .62, .00,
                   .00, .00, .38,
                   .00, .00, .43,
                   .00, .00, .37),
                 nrow = 9, ncol = 3, byrow = TRUE)

## Find the model implied correlation matrix
R &lt;- lambda %*% t(lambda)
diag(R) &lt;- 1

## Extract factors using the fapa function
Out1 &lt;- fapa(R           = R,
             numFactors  = 3,
             communality = "SMC")

## Call fapa through the factExtract function
Out2 &lt;- faX(R          = R,
            numFactors = 3,
            facMethod  = "fapa",
            faControl  = list(communality = "maxr",
                              epsilon     = 1e-4))

## Check for equivalence of the two results
all.equal(Out1$loadings, Out2$loadings)


</code></pre>

<hr>
<h2 id='fareg'>Regularized Factor Analysis</h2><span id='topic+fareg'></span>

<h3>Description</h3>

<p>This function applies the regularized factoring method to extract an unrotated factor structure matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fareg(R, numFactors = 1, facMethod = "rls")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fareg_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix to be analyzed.</p>
</td></tr>
<tr><td><code id="fareg_+3A_numfactors">numFactors</code></td>
<td>
<p>(Integer) The number of factors to extract. Default: numFactors = 1.</p>
</td></tr>
<tr><td><code id="fareg_+3A_facmethod">facMethod</code></td>
<td>
<p>(Character) &quot;rls&quot; for regularized least squares estimation or 
&quot;rml&quot; for regularized maximum likelihood estimation. Default: facMethod = &quot;rls&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The main output is the matrix of unrotated factor loadings.
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) A matrix of unrotated factor loadings.
</p>
</li>
<li> <p><strong>h2</strong>: (Vector) A vector of estimated communality values.
</p>
</li>
<li> <p><strong>L</strong>: (Numeric) Value of the estimated penality parameter.
</p>
</li>
<li> <p><strong>Heywood</strong> (Logical) TRUE if a Heywood case is detected 
(this should never happen).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller (nwaller@umn.edu)
</p>


<h3>References</h3>

<p>Jung, S. &amp; Takane, Y.  (2008).  Regularized common factor analysis.  
New trends in psychometrics, 141-149.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("HW")

# load first HW data set

RHW &lt;- cor(x = HW$HW6)

# Compute principal axis factor analysis
fapaOut &lt;- faMain(R = RHW, 
                 numFactors = 3, 
                 facMethod = "fapa", 
                 rotate = "oblimin",
                 faControl = list(treatHeywood = FALSE))


fapaOut$faFit$Heywood
round(fapaOut$h2, 2)

 # Conduct a regularized factor analysis
regOut &lt;- fareg(R = RHW, 
               numFactors = 3,
               facMethod = "rls")
regOut$L
regOut$Heywood


# rotate regularized loadings and align with 
# population structure
regOutRot &lt;- faMain(urLoadings = regOut$loadings,
                   rotate = "oblimin")

# ALign
FHW  &lt;- faAlign(HW$popLoadings, fapaOut$loadings)$F2
Freg &lt;- faAlign(HW$popLoadings, regOutRot$loadings)$F2

AllSolutions &lt;- round(cbind(HW$popLoadings, Freg, FHW),2) 
colnames(AllSolutions) &lt;- c("F1", "F2", "F3", "Fr1", "Fr2", "Fr3", 
                           "Fhw1", "Fhw2", "Fhw3")
AllSolutions


rmsdHW &lt;- rmsd(HW$popLoadings, FHW, 
              IncludeDiag = FALSE, 
              Symmetric = FALSE)

rmsdReg &lt;- rmsd(HW$popLoadings, Freg, 
               IncludeDiag = FALSE, 
               Symmetric = FALSE)

cat("\nrmsd HW =  ", round(rmsdHW,3),
    "\nrmsd reg = ", round(rmsdReg,3))



</code></pre>

<hr>
<h2 id='faScores'>Factor Scores</h2><span id='topic+faScores'></span>

<h3>Description</h3>

<p>This function computes factor scores by various methods. The function will acceptan an 
object of class  <code>faMain</code> or, alternatively,  user-input factor pattern (i.e., <code>Loadings</code>) and 
factor correlation (<code>Phi</code>) matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faScores(
  X = NULL,
  faMainObject = NULL,
  Loadings = NULL,
  Phi = NULL,
  Method = "Thurstone"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faScores_+3A_x">X</code></td>
<td>
<p>(Matrix) An N <code>x</code>  variables data matrix.  If X is a matrix of raw scores then
<code>faScores</code> will convert the data to z scores.</p>
</td></tr>
<tr><td><code id="faScores_+3A_famainobject">faMainObject</code></td>
<td>
<p>(Object of class <strong>faMain</strong>) The returned object 
from a call to <strong>faMain</strong>. Default = NULL</p>
</td></tr>
<tr><td><code id="faScores_+3A_loadings">Loadings</code></td>
<td>
<p>(Matrix) A factor pattern matrix. Default = NULL.</p>
</td></tr>
<tr><td><code id="faScores_+3A_phi">Phi</code></td>
<td>
<p>(Matrix) A factor correlation matrix.  Default = NULL. If a factor pattern 
is entered via the <strong>Loadings</strong> argument but <strong>Phi = NULL</strong> the program 
will set <code>Phi</code> to an identity matrix.</p>
</td></tr>
<tr><td><code id="faScores_+3A_method">Method</code></td>
<td>
<p>(Character) Factor scoring method. Defaults to the Thurstone or regression based method.
Available options include: 
</p>

<ul>
<li><p><strong>Thurstone</strong> Generates regression based factor score estimates.
</p>
</li>
<li><p><strong>Bartlett</strong>  Generates Bartlett method factor score estimates.
</p>
</li>
<li><p><strong>tenBerge</strong>  Generates factor score estimates with correlations identical 
to that found in <strong>Phi</strong>.
</p>
</li>
<li><p><strong>Anderson</strong> The Anderson Rubin method. Generates uncorrelated factor score estimates.  This 
method is only appropriate for orthogonal factor models. 
</p>
</li>
<li><p><strong>Harman</strong> Generates estimated factor scores by Harman's idealized variables method.
</p>
</li>
<li><p><strong>PCA</strong> Returns unrotated principal component scores.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>faScores</strong> can be used to calculate estimated factor scores by various methods.  
In general, to calculate score estimates,  users must input a data matrix <strong>X</strong> and either (a) 
an object of class <strong>faMain</strong> or (b) a factor loadings matrix, <strong>Loadings</strong> and 
an optional (for oblique models) factor correlation matrix <strong>Phi</strong>. The one exception to this rule 
concerns scores for the principal components model.  To calculate unrotated PCA scores (i.e., when 
<strong>Method = &quot;PCA&quot;</strong>) users need only enter a data matrix, <strong>X</strong>.
</p>


<h3>Value</h3>


<ul>
<li><p><strong>fscores</strong> A matrix om common factor score estimates. 
</p>
</li>
<li><p><strong>Method</strong> The method used to create the factor score estimates.  
</p>
</li>
<li><p><strong>W</strong> The factor scoring coefficient matrix. 
</p>
</li>
<li><p><strong>Z</strong> A matrix of standardized data used to create the estimated factor scores.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

 
<ul>
<li><p>Bartlett, M. S. (1937). The statistical conception of 
mental factors.British Journal of Psychology, 28,97-104.
</p>
</li>
<li><p>Grice, J.  (2001).  Computing and evaluating factor scores.
Psychological Methods, 6(4), 430-450.
</p>
</li>
<li><p>Harman, H. H.  (1976).  Modern factor analysis.  
University of Chicago press. 
</p>
</li>
<li><p>McDonald, R. P. and Burr, E. J.  (1967).  A Comparison of Four Methods of 
Constructing Factor Scores.  Psychometrika, 32, 381-401.
</p>
</li>
<li><p>Ten Berge, J. M. F., Krijnen, W. P., Wansbeek, T., and Shapiro, A.  
(1999).  Some new results on correlation-preserving factor scores 
prediction methods.  Linear Algebra and its Applications, 
289(1-3), 311-318.  
</p>
</li>
<li><p>Tucker, L.  (1971).  Relations of factor score estimates to their use.
Psychometrika, 36, 427-436.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lambda.Pop &lt;- matrix(c(.41, .00, .00,
                       .45, .00, .00,
                       .53, .00, .00,
                       .00, .66, .00,
                       .00, .38, .00,
                       .00, .66, .00,
                       .00, .00, .68,
                       .00, .00, .56,
                       .00, .00, .55),
                       nrow = 9, ncol = 3, byrow = TRUE)
 NVar &lt;- nrow(lambda.Pop)
 NFac &lt;- 3

## Factor correlation matrix
Phi.Pop &lt;- matrix(.50, nrow = 3, ncol = 3)
diag(Phi.Pop) &lt;- 1

#Model-implied correlation matrix
R &lt;- lambda.Pop %*% Phi.Pop %*% t(lambda.Pop)
diag(R) &lt;- 1


#Generate population data to perfectly reproduce pop R
Out &lt;- simFA( Model = list(Model = "oblique"),
             Loadings = list(FacPattern = lambda.Pop),
             Phi = list(PhiType = "user",
                        UserPhi = Phi.Pop),
             FactorScores = list(FS = TRUE,
                                 CFSeed = 1,
                                 SFSeed = 2,
                                 EFSeed = 3,
                                 Population = TRUE,
                                 NFacScores = 100),
             Seed = 1)

PopFactorScores &lt;- Out$Scores$FactorScores
X &lt;- PopObservedScores &lt;- Out$Scores$ObservedScores


fout &lt;- faMain(X             = X,
              numFactors    = 3,
              facMethod     = "fals",
              rotate        = "oblimin")


print( round(fout$loadings, 2) )
print( round(fout$Phi,2) )

fload &lt;- fout$loadings
Phi &lt;- fout$Phi

  fsOut &lt;- faScores(X = X, 
                    faMainObject = fout, 
                    Method = "Thurstone")

  fscores &lt;- fsOut$fscores

  print( round(cor(fscores), 2 ))
  print(round(Phi,2)) 

 CommonFS &lt;- PopFactorScores[,1:NFac]
 SpecificFS &lt;-PopFactorScores[ ,(NFac+1):(NFac+NVar)]
 ErrorFS &lt;-   PopFactorScores[ , (NFac + NVar + 1):(NFac + 2*NVar) ]

print( cor(fscores, CommonFS) )
</code></pre>

<hr>
<h2 id='faSort'>Sort a factor loadings matrix</h2><span id='topic+faSort'></span>

<h3>Description</h3>

<p>faSort takes an unsorted factor pattern or structure matrix and returns a
sorted matrix with (possibly) reflected columns. Sorting is done such that
variables that load on a common factor are grouped together for ease of
interpretation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faSort(fmat, phi = NULL, BiFactor = FALSE, salient = 0.25, reflect = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faSort_+3A_fmat">fmat</code></td>
<td>
<p>factor loadings (pattern or structure) matrix.</p>
</td></tr>
<tr><td><code id="faSort_+3A_phi">phi</code></td>
<td>
<p>factor correlation matrix. Default = NULL. If reflect = TRUE then
phi will be corrected to match the new factor orientations.</p>
</td></tr>
<tr><td><code id="faSort_+3A_bifactor">BiFactor</code></td>
<td>
<p>(logical) Is the solution a bifactor model?</p>
</td></tr>
<tr><td><code id="faSort_+3A_salient">salient</code></td>
<td>
<p>factor markers with loadings &gt;= abs(salient) will be saved in
the markers list. Note that a variable can be a marker of more than one
factor.</p>
</td></tr>
<tr><td><code id="faSort_+3A_reflect">reflect</code></td>
<td>
<p>(logical) if reflect = TRUE then the factors will be
reflected such that salient loadings are mostly positive. Default <code>Reflect = TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>loadings</code></td>
<td>
<p>sorted factor loadings matrix.</p>
</td></tr> 
<tr><td><code>phi</code></td>
<td>
<p>reflected factor correlation matrix when phi is given as an argument.</p>
</td></tr>
<tr><td><code>markers</code></td>
<td>
<p>A list of factor specific markers with loadings &gt;=
abs(salient). Markers are sorted by the absolute value of the salient factor
loadings.</p>
</td></tr> <tr><td><code>sortOrder</code></td>
<td>
<p>sorted row numbers.</p>
</td></tr> 
<tr><td><code>SEmat</code></td>
<td>
<p>The SEmat is a
so-called Start-End matrix that lists the first (start) and last (end) row
for each factor in the sorted pattern matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fals">fals</a></code>
</p>
<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
F &lt;- matrix( c( .5,  0, 
                .6,  0,
                 0, .6,
                .6,  0,
                 0, .5,
                .7,  0,
                 0, .7,
                 0, .6), nrow = 8, ncol = 2, byrow=TRUE)

Rex1 &lt;- F %*% t(F); diag(Rex1) &lt;- 1

Items &lt;- c("1. I am often tense.\n",
           "2. I feel anxious much of the time.\n",
           "3. I am a naturally curious individual.\n",
           "4. I have many fears.\n",
           "5. I read many books each year.\n",
           "6. My hands perspire easily.\n",
           "7. I have many interests.\n",
           "8. I enjoy learning new words.\n")

exampleOut &lt;- fals(R = Rex1, nfactors = 2)

# Varimax rotation
Fload &lt;- varimax(exampleOut$loadings)$loadings[]

# Add some row labels
rownames(Fload) &lt;- paste0("V", 1:nrow(Fload))

cat("\nUnsorted fator loadings\n")
print(round( Fload, 2) )

# Sort items and reflect factors
out1 &lt;- faSort(fmat = Fload, 
               salient = .25, 
               reflect = TRUE)
               
FloadSorted &lt;- out1$loadings

cat("\nSorted fator loadings\n")
print(round( FloadSorted, 2) )

# Print sorted items
cat("\n Items sorted by Factor\n")
cat("\n",Items[out1$sortOrder])
</code></pre>

<hr>
<h2 id='faStandardize'>Standardize the Unrotated Factor Loadings</h2><span id='topic+faStandardize'></span>

<h3>Description</h3>

<p>This function standardizes the unrotated factor loadings using two methods: Kaiser's normalization and Cureton-Mulaik standardization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faStandardize(method, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faStandardize_+3A_method">method</code></td>
<td>
<p>(Character) The method used for standardization. There are three option: &quot;none&quot;, &quot;Kaiser&quot;, and &quot;CM&quot;.
</p>

<ul>
<li> <p><strong>&quot;none&quot;</strong>: No standardization is conducted on the unrotated factor loadings matrix
</p>
</li>
<li> <p><strong>&quot;Kaiser&quot;</strong>: The rows of the unrotated factor loadings matrix are rescaled to have unit-lengths.
</p>
</li>
<li> <p><strong>&quot;CM&quot;</strong>: Apply the Cureton-Mulaik standardization to the unrotated factor loadings matrix.
</p>
</li></ul>
</td></tr>
<tr><td><code id="faStandardize_+3A_lambda">lambda</code></td>
<td>
<p>(Matrix) The unrotated factor loadings matrix (or data frame).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The resulting output can be used to standardize the factor loadings as well as providing the inverse matrix used to unstandardize the factor loadings after rotating the factor solution.
</p>

<ul>
<li> <p><strong>Dv</strong>: (Matrix) A diagonal weight matrix used to standardize the unrotated factor loadings. Pre-multiplying the loadings matrix by the diagonal weight matrix (i.e., Dv 
</p>
</li>
<li> <p><strong>DvInv</strong>: (Matrix) The inverse of the diagonal weight matrix used to standardize. To unstandardize the ultimate rotated solution, pre-multiply the rotated factor loadings by the inverse of Dv (i.e., DvInv 
</p>
</li>
<li> <p><strong>lambda</strong>: (Matrix) The standardized, unrotated factor loadings matrix.
</p>
</li>
<li> <p><strong>unstndLambda</strong>: (Matrix) The original, unstandardized, unrotated factor loadings matrix. (DvInv 
</p>
</li></ul>



<h3>References</h3>

<p>Browne, M. W. (2001). An overview of analytic rotation in exploratory factor analysis. <em>Multivariate Behavioral Research, 36</em>(1), 111-150.
</p>
<p>Cureton, E. E., &amp; Mulaik, S. A. (1975). The weighted varimax rotation and the promax rotation. <em>Psychometrika, 40</em>(2), 183-195.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>

<hr>
<h2 id='faX'>Factor Extraction (faX) Routines</h2><span id='topic+faX'></span>

<h3>Description</h3>

<p>This function can be used to extract an unrotated factor structure matrix 
using the following algorithms: (a) unweighted least squares (&quot;fals&quot;); 
(b) maximum likelihood (&quot;faml&quot;); (c) iterated principal axis factoring (&quot;fapa&quot;);
and (d) principal components analysis (&quot;pca&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>faX(R, n = NULL, numFactors = NULL, facMethod = "fals", faControl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="faX_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix used for factor extraction.</p>
</td></tr>
<tr><td><code id="faX_+3A_n">n</code></td>
<td>
<p>(Numeric) Sample size associated with the correlation matrix. 
Defaults to n = NULL.</p>
</td></tr>
<tr><td><code id="faX_+3A_numfactors">numFactors</code></td>
<td>
<p>(Numeric) The number of factors to extract for subsequent rotation.</p>
</td></tr>
<tr><td><code id="faX_+3A_facmethod">facMethod</code></td>
<td>
<p>(Character) The method used for factor extraction. The 
supported options are &quot;fals&quot; for unweighted least squares, &quot;faml&quot; for maximum 
likelihood, &quot;fapa&quot; for iterated principal axis factoring, and &quot;pca&quot; for 
principal components analysis. The default method is &quot;fals&quot;.
</p>

<ul>
<li> <p><strong>&quot;fals&quot;</strong>: Factors are extracted using the unweighted least 
squares estimation procedure using the <code><a href="#topic+fals">fals</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faml&quot;</strong>: Factors are extracted using the maximum likelihood 
estimation procedure using the <code><a href="stats.html#topic+factanal">factanal</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faregLS&quot;</strong>: Factors are extracted using regularized 
least squares factor analysis using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;faregML&quot;</strong>: Factors are extracted using regularized 
maximum likelihood factor using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;fapa&quot;</strong>: Factors are extracted using the iterated principal 
axis factoring estimation procedure using the <code><a href="#topic+fapa">fapa</a></code> function.
</p>
</li>
<li> <p><strong>&quot;pca&quot;</strong>: Principal components are extracted. 
</p>
</li></ul>
</td></tr>
<tr><td><code id="faX_+3A_facontrol">faControl</code></td>
<td>
<p>(List) A list of optional parameters passed to the factor 
extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>

<ul>
<li> <p><strong>treatHeywood</strong>: (Logical) In <code>fals</code>, if treatHeywood is 
true, a penalized least squares function is used to bound the communality 
estimates below 1.0. Defaults to treatHeywood = TRUE.
</p>
</li>
<li> <p><strong>nStart</strong>: (Numeric) The number of starting values to be tried 
in <code>faml</code>. Defaults to nStart = 10.
</p>
</li>
<li> <p><strong>start</strong>: (Matrix) NULL or a matrix of starting values, each column 
giving an initial set of uniquenesses. Defaults to start = NULL. 
</p>
</li>
<li> <p><strong>maxCommunality</strong>: (Numeric) In <code>faml</code>, set the maximum 
communality value for the estimated solution. Defaults to maxCommunality = .995.
</p>
</li>
<li> <p><strong>epsilon</strong>: (Numeric) In <code>fapa</code>, the numeric threshold 
designating when the algorithm has converged. Defaults to epsilon = 1e-4.
</p>
</li>
<li> <p><strong>communality</strong>: (Character) The method used to estimate the 
initial communality values in <code>fapa</code>. Defaults to communality = 'SMC'.
</p>

<ul>
<li> <p><strong>&quot;SMC&quot;</strong>: Initial communalities are estimated by taking the 
squared multiple correlations of each indicator after regressing the 
indicator on the remaining variables.
</p>
</li>
<li> <p><strong>&quot;maxr&quot;</strong>: Initial communalities equal the largest 
(absolute value) correlation in each column of the correlation matrix.
</p>
</li>
<li> <p><strong>&quot;unity&quot;</strong>: Initial communalities equal 1.0 for all variables.
</p>
</li></ul>

</li>
<li> <p><strong>maxItr</strong>: (Numeric) In <code>fapa</code>, the maximum number of 
iterations to reach convergence. Defaults to maxItr = 15,000.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Initial communality estimate</strong>: According to Widaman and 
Herringer (1985), the initial communality estimate does not have much 
bearing on the resulting solution <em>when the a stringent convergence 
criterion is used</em>. In their analyses, a convergence criterion of .001 
(i.e., slightly less stringent than the default of 1e-4) is sufficiently 
stringent to produce virtually identical communality estimates irrespective 
of the initial estimate used. It should be noted that all four methods for 
estimating the initial communality in Widaman and Herringer (1985) are the 
exact same used in this function. Based on their findings, it is not 
recommended to use a convergence criterion lower than 1e-3.
</p>
</li></ul>



<h3>Value</h3>

<p>This function returns a list of output relating to the extracted factor loadings.
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) An unrotated factor structure matrix.
</p>
</li>
<li> <p><strong>h2</strong>: (Vector) Vector of final communality estimates.
</p>
</li>
<li> <p><strong>faFit</strong>: (List) A list of additional factor extraction output.
</p>

<ul>
<li> <p><strong>facMethod</strong>: (Character) The factor extraction routine.
</p>
</li>
<li> <p><strong>df</strong>: (Numeric) Degrees of Freedom from the maximum 
likelihood factor extraction routine.
</p>
</li>
<li> <p><strong>n</strong>: (Numeric) Sample size associated with the correlation matrix.
</p>
</li>
<li> <p><strong>objectiveFunc</strong>: (Numeric) The evaluated objective function for the 
maximum likelihood factor extraction routine. 
</p>
</li>
<li> <p><strong>RMSEA</strong>: (Numeric) Root mean squared error of approximation 
from Steiger &amp; Lind (1980). Note that bias correction is computed if the 
sample size is provided.
</p>
</li>
<li> <p><strong>testStat</strong>: (Numeric) The significance test statistic for the maximum 
likelihood procedure. Cannot be computed unless a sample size is provided. 
</p>
</li>
<li> <p><strong>pValue</strong>: (Numeric) The p value associated with the significance test 
statistic for the maximum likelihood procedure. Cannot be computed unless 
a sample size is provided. 
</p>
</li>
<li> <p><strong>gradient</strong>: (Matrix) The solution gradient for the least squares factor 
extraction routine. 
</p>
</li>
<li> <p><strong>maxAbsGradient</strong>: (Numeric) The maximum absolute value of the 
gradient at the least squares solution. 
</p>
</li>
<li> <p><strong>Heywood</strong>: (Logical) TRUE if a Heywood case was produced.
</p>
</li>
<li> <p><strong>converged</strong>: (Logical) TRUE if the least squares or 
principal axis factor extraction routine converged. 
</p>
</li></ul>

</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Jung, S. &amp; Takane, Y.  (2008).  Regularized common factor analysis.  
New trends in psychometrics, 141-149.
</p>
<p>Steiger, J. H., &amp; Lind, J. (1980). Paper presented at the annual 
meeting of the Psychometric Society. <em>Statistically-based tests for the 
number of common factors.</em>
</p>
<p>Widaman, K. F., &amp; Herringer, L. G. (1985). Iterative least squares 
estimates of communality: Initial estimate need not affect stabilized value. 
<em>Psychometrika, 50</em>(4), 469-477.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate an example factor structure matrix
lambda &lt;- matrix(c(.62, .00, .00,
                   .54, .00, .00,
                   .41, .00, .00,
                   .00, .31, .00,
                   .00, .58, .00,
                   .00, .62, .00,
                   .00, .00, .38,
                   .00, .00, .43,
                   .00, .00, .37),
                 nrow = 9, ncol = 3, byrow = TRUE)

## Find the model implied correlation matrix
R &lt;- lambda %*% t(lambda)
diag(R) &lt;- 1

## Extract (principal axis) factors using the factExtract function
Out1 &lt;- faX(R          = R,
            numFactors = 3,
            facMethod  = "fapa",
            faControl  = list(communality = "maxr",
                              epsilon     = 1e-4))

## Extract (least squares) factors using the factExtract function
Out2 &lt;- faX(R          = R,
            numFactors = 3,
            facMethod  = "fals",
            faControl  = list(treatHeywood = TRUE))

</code></pre>

<hr>
<h2 id='FMP'>Estimate the coefficients of a filtered monotonic polynomial IRT model</h2><span id='topic+FMP'></span>

<h3>Description</h3>

<p>Estimate the coefficients of a filtered monotonic polynomial IRT model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FMP(data, thetaInit, item, startvals, k = 0, eps = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FMP_+3A_data">data</code></td>
<td>
<p>N(subjects)-by-p(items) matrix of 0/1 item response data.</p>
</td></tr>
<tr><td><code id="FMP_+3A_thetainit">thetaInit</code></td>
<td>
<p>Initial theta (<code class="reqn">\theta</code>) surrogates (e.g., calculated
by <a href="#topic+svdNorm">svdNorm</a>).</p>
</td></tr>
<tr><td><code id="FMP_+3A_item">item</code></td>
<td>
<p>Item number for coefficient estimation.</p>
</td></tr>
<tr><td><code id="FMP_+3A_startvals">startvals</code></td>
<td>
<p>Start values for function minimization. Start values are in
the gamma metric (see Liang &amp; Browne, 2015)</p>
</td></tr>
<tr><td><code id="FMP_+3A_k">k</code></td>
<td>
<p>Order of monotonic polynomial = 2k+1 (see Liang &amp; Browne, 2015). k
can equal 0, 1, 2, or 3.</p>
</td></tr>
<tr><td><code id="FMP_+3A_eps">eps</code></td>
<td>
<p>Step size for gradient approximation, default = 1e-6. If a
convergence failure occurs during function optimization reducing the value
of eps will often produce a converged solution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As described by Liang and Browne (2015), the filtered polynomial model (FMP)
is a quasi-parametric IRT model in which the IRF is a composition of a
logistic function and a polynomial function, <code class="reqn">m(\theta)</code>, of degree 2k +
1.  When k = 0, <code class="reqn">m(\theta) = b_0 + b_1 \theta</code> (the slope intercept form
of the 2PL). When k = 1, 2k + 1 equals 3 resulting in <code class="reqn">m(\theta) = b_0 +
b_1 \theta + b_2 \theta^2 + b_3 \theta^3</code>. Acceptable values of k = 0,1,2,3.
According to Liang and Browne, the &quot;FMP IRF may be used to approximate any
IRF with a continuous derivative arbitrarily closely by increasing the
number of parameters in the monotonic polynomial&quot; (2015, p. 2) The FMP model
assumes that the IRF is monotonically increasing, bounded by 0 and 1, and
everywhere differentiable with respect to theta (the latent trait).
</p>


<h3>Value</h3>

<table>
<tr><td><code>b</code></td>
<td>
<p>Vector of polynomial coefficients.</p>
</td></tr> <tr><td><code>gamma</code></td>
<td>
<p>Polynomial
coefficients in gamma metric (see Liang &amp; Browne, 2015).</p>
</td></tr>
<tr><td><code>FHAT</code></td>
<td>
<p>Function value at convergence.</p>
</td></tr> <tr><td><code>counts</code></td>
<td>
<p>Number of function
evaluations during minimization (see optim documentation for further
details).</p>
</td></tr> <tr><td><code>AIC</code></td>
<td>
<p>Pseudo scaled Akaike Information Criterion (AIC).
Candidate models that produce the smallest AIC suggest the optimal number of
parameters given the sample size. Scaling is accomplished by dividing the
non-scaled AIC by sample size.</p>
</td></tr> <tr><td><code>BIC</code></td>
<td>
<p>Pseudo scaled Bayesian
Information Criterion (BIC). Candidate models that produce the smallest BIC
suggest the optimal number of parameters given the sample size. Scaling is
accomplished by dividing the non-scaled BIC by sample size.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence = 0 indicates that the optimization algorithm
converged; convergence=1 indicates that the optimization failed to
converge.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Liang, L. &amp; Browne, M. W. (2015). A quasi-parametric method for
fitting flexible item response functions. <em>Journal of Educational and
Behavioral Statistics, 40</em>, 5&ndash;34.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
## In this example we will generate 2000 item response vectors 
## for a k = 1 order filtered polynomial model and then recover 
## the estimated item parameters with the FMP function.  

k &lt;- 1  # order of polynomial

NSubjects &lt;- 2000


## generate a sample of 2000 item response vectors 
## for a k = 1 FMP model using the following
## coefficients
b &lt;- matrix(c(
   #b0     b1      b2     b3   b4  b5  b6  b7  k
  1.675, 1.974, -0.068, 0.053,  0,  0,  0,  0, 1,
  1.550, 1.805, -0.230, 0.032,  0,  0,  0,  0, 1,
  1.282, 1.063, -0.103, 0.003,  0,  0,  0,  0, 1,
  0.704, 1.376, -0.107, 0.040,  0,  0,  0,  0, 1,
  1.417, 1.413,  0.021, 0.000,  0,  0,  0,  0, 1,
 -0.008, 1.349, -0.195, 0.144,  0,  0,  0,  0, 1,
  0.512, 1.538, -0.089, 0.082,  0,  0,  0,  0, 1,
  0.122, 0.601, -0.082, 0.119,  0,  0,  0,  0, 1,
  1.801, 1.211,  0.015, 0.000,  0,  0,  0,  0, 1,
 -0.207, 1.191,  0.066, 0.033,  0,  0,  0,  0, 1,
 -0.215, 1.291, -0.087, 0.029,  0,  0,  0,  0, 1,
  0.259, 0.875,  0.177, 0.072,  0,  0,  0,  0, 1,
 -0.423, 0.942,  0.064, 0.094,  0,  0,  0,  0, 1,
  0.113, 0.795,  0.124, 0.110,  0,  0,  0,  0, 1,
  1.030, 1.525,  0.200, 0.076,  0,  0,  0,  0, 1,
  0.140, 1.209,  0.082, 0.148,  0,  0,  0,  0, 1,
  0.429, 1.480, -0.008, 0.061,  0,  0,  0,  0, 1,
  0.089, 0.785, -0.065, 0.018,  0,  0,  0,  0, 1,
 -0.516, 1.013,  0.016, 0.023,  0,  0,  0,  0, 1,
  0.143, 1.315, -0.011, 0.136,  0,  0,  0,  0, 1,
  0.347, 0.733, -0.121, 0.041,  0,  0,  0,  0, 1,
 -0.074, 0.869,  0.013, 0.026,  0,  0,  0,  0, 1,
  0.630, 1.484, -0.001, 0.000,  0,  0,  0,  0, 1), 
  nrow=23, ncol=9, byrow=TRUE)  
  
ex1.data&lt;-genFMPData(NSubj = NSubjects, bParams = b, seed = 345)$data

## number of items in the data matrix
NItems &lt;- ncol(ex1.data)

# compute (initial) surrogate theta values from 
# the normed left singular vector of the centered 
# data matrix
thetaInit &lt;- svdNorm(ex1.data)


## earlier we defined k = 1
  if(k == 0) {
            startVals &lt;- c(1.5, 1.5)
            bmat &lt;- matrix(0, NItems, 6)
            colnames(bmat) &lt;- c(paste("b", 0:1, sep = ""),"FHAT", "AIC", "BIC", "convergence") 
  }
  if(k == 1) {
           startVals &lt;- c(1.5, 1.5, .10, .10)
           bmat &lt;- matrix(0, NItems, 8)
           colnames(bmat) &lt;- c(paste("b", 0:3, sep = ""),"FHAT", "AIC", "BIC", "convergence") 
  }
  if(k == 2) {
           startVals &lt;- c(1.5, 1.5, .10, .10, .10, .10)
           bmat &lt;- matrix(0, NItems, 10)
           colnames(bmat) &lt;- c(paste("b", 0:5, sep = ""),"FHAT", "AIC", "BIC", "convergence") 
  }
  if(k == 3) {
           startVals &lt;- c(1.5, 1.5, .10, .10, .10, .10, .10, .10)
           bmat &lt;- matrix(0, NItems, 12)
           colnames(bmat) &lt;- c(paste("b", 0:7, sep = ""),"FHAT", "AIC", "BIC", "convergence") 
  }         
  
# estimate item parameters and fit statistics  
  for(i in 1:NItems){
    out &lt;- FMP(data = ex1.data, thetaInit, item = i, startvals = startVals, k = k)
    Nb &lt;- length(out$b)
    bmat[i,1:Nb] &lt;- out$b
    bmat[i,Nb+1] &lt;- out$FHAT
    bmat[i,Nb+2] &lt;- out$AIC
    bmat[i,Nb+3] &lt;- out$BIC
    bmat[i,Nb+4] &lt;- out$convergence
  }

# print output 
print(bmat)

## End(Not run)

</code></pre>

<hr>
<h2 id='FMPMonotonicityCheck'>Utility function for checking FMP monotonicity</h2><span id='topic+FMPMonotonicityCheck'></span>

<h3>Description</h3>

<p>Utility function for checking whether candidate FMP coefficients yield a
monotonically increasing polynomial.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FMPMonotonicityCheck(b, lower = -20, upper = 20, PLOT = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FMPMonotonicityCheck_+3A_b">b</code></td>
<td>
<p>A vector of 8 polynomial coefficients (<code class="reqn">b</code>) for
<code class="reqn">m(\theta)=b_0 + b_1 \theta + b_2 \theta^2 + b_3 \theta^3 + b_4 \theta^4
+ b_5 \theta^5 + b_6 \theta^6 + b_7 \theta^7</code>.</p>
</td></tr>
<tr><td><code id="FMPMonotonicityCheck_+3A_lower">lower</code>, <code id="FMPMonotonicityCheck_+3A_upper">upper</code></td>
<td>
<p><code class="reqn">\theta</code> bounds for monotonicity check.</p>
</td></tr>
<tr><td><code id="FMPMonotonicityCheck_+3A_plot">PLOT</code></td>
<td>
<p>Logical (default = FALSE).  If PLOT = TRUE the function will
plot the original polynomial function for <code class="reqn">\theta</code> between lower and
upper.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>increasing</code></td>
<td>
<p>Logical indicating whether function is
monotonically increasing.</p>
</td></tr> <tr><td><code>minDeriv</code></td>
<td>
<p>Minimum value of the derivative
for the polynomial.</p>
</td></tr> <tr><td><code>minTheta</code></td>
<td>
<p>Value of <code class="reqn">\theta</code> at derivative
minimum.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## A set of candidate coefficients for an FMP model.
## These coefficients fail the test and thus
## should not be used with genFMPdata to generate
## item response data that are consistent with an 
## FMP model.
 b &lt;- c(1.21, 1.87, -1.02, 0.18, 0.18, 0, 0, 0)
 FMPMonotonicityCheck(b)

</code></pre>

<hr>
<h2 id='fsIndeterminacy'>Understanding Factor Score Indeterminacy with Finite Dimensional Vector Spaces</h2><span id='topic+fsIndeterminacy'></span>

<h3>Description</h3>

<p>This function illustrates the algebra of factor score indeterminacy 
using concepts from finite dimensional vector spaces. Given any factor loading 
matrix, factor correlation matrix, and desired sample size, the program will 
compute a matrix of observed scores and multiple sets of factors
scores.  Each set of (m common and p unique) factors scores will fit the model 
perfectly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fsIndeterminacy(
  Lambda = NULL,
  Phi = NULL,
  N = NULL,
  X = NULL,
  SeedX = NULL,
  SeedBasis = NULL,
  SeedW = NULL,
  SeedT = 1,
  DoFCorrection = TRUE,
  Print = "short",
  Digits = 3,
  Example = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fsIndeterminacy_+3A_lambda">Lambda</code></td>
<td>
<p>(Matrix) A p x m matrix of factor loadings.</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_phi">Phi</code></td>
<td>
<p>(Matrix) An m x m factor correlation matrix.</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_n">N</code></td>
<td>
<p>(Integer) The desired sample size.</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_x">X</code></td>
<td>
<p>(Matrix) an optional N x p matrix of observed scores. Note that the observed scores
are expected to fit the factor model (as they will if they are generated 
from simFA and Population = TRUE is specified). Default (<code>X = NULL</code>).</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_seedx">SeedX</code></td>
<td>
<p>(Integer) Starting seed for generating the matrix of observed scores, X.</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_seedbasis">SeedBasis</code></td>
<td>
<p>(Integer) Starting seed for generating a basis for all scores.</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_seedw">SeedW</code></td>
<td>
<p>(Integer) Starting seed for generating a weight matrix that is 
used to construct those parts of the factor scores that lie outside of span(X).</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_seedt">SeedT</code></td>
<td>
<p>(Integer) Starting seed for generating a rotation matrix that 
creates a new set of factor scores from an existing set of scores such that 
the new set also perfectly fits the factor model.</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_dofcorrection">DoFCorrection</code></td>
<td>
<p>(Logical) Degrees of freedom correction.  If DoFCorrection = TRUE
then var(x) = 1/(N-1) * t(x) %*% x; else var(x) = 1/N * t(x) %*% x. 
Default (<code>DoFCorrection = TRUE</code>).</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_print">Print</code></td>
<td>
<p>(Character) If <code>Print = "none"</code> no summary information
will be printed.  If <code>Print = "short"</code> then basic output for evaluating
the factor scores will be printed. If <code>Print = "long"</code> extended output
will be printed. Default (<code>Print = "short"</code>).</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_digits">Digits</code></td>
<td>
<p>(Integer) Sets the number of significant digits to print when
printing is requested.</p>
</td></tr>
<tr><td><code id="fsIndeterminacy_+3A_example">Example</code></td>
<td>
<p>(Logical) If Example = TRUE the program will
execute the orthogonal two factor model  described  in Waller (2021).</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><strong>&quot;Sigma&quot;</strong>: The p x p model implied covariance matrix.
</p>
</li>
<li> <p><strong>&quot;X&quot;</strong>:  An N x p data matrix for the observed variables. 
</p>
</li>
<li> <p><strong>&quot;Fhat&quot;</strong>: An N x (m + p) matrix of regression factor score estimates. 
</p>
</li>
<li> <p><strong>&quot;Fi&quot;</strong>:  A possible set of common and unique factor scores.
</p>
</li>
<li> <p><strong>&quot;Fj&quot;</strong>: The set of factor scores that are minimally correlated with Fi. 
</p>
</li>
<li> <p><strong>&quot;Fk&quot;</strong>: Another set of common and unique factor scores. 
Note that in a 1-factor model, Fk = Fi.
</p>
</li>
<li> <p><strong>&quot;Fl&quot;</strong>: The set of factor scores that are minimally correlated with Fk. 
Note that in a 1-factor model, Fj = Fl. 
</p>
</li>
<li> <p><strong>&quot;Ei&quot;</strong>: Residual scores for Fi.
</p>
</li>
<li> <p><strong>&quot;Ej&quot;</strong>: Residual scores for Fj.
</p>
</li>
<li> <p><strong>&quot;Ek&quot;</strong>: Residual scores for Fk.
</p>
</li>
<li> <p><strong>&quot;El&quot;</strong>: Residual scores for Fl. 
</p>
</li>
<li> <p><strong>&quot;L&quot;</strong>: The factor loading super matrix.
</p>
</li>
<li> <p><strong>&quot;C&quot;</strong>: The factor correlation super matrix.
</p>
</li>
<li> <p><strong>&quot;V&quot;</strong>: A (non unique) basis for R^N.
</p>
</li>
<li> <p><strong>&quot;W&quot;</strong>: Weight matrix for generating  Zi.
</p>
</li>
<li> <p><strong>&quot;Tmat&quot;</strong>: The orthogonal transformation matrix used to construct Fk  from Fi .
</p>
</li>
<li> <p><strong>&quot;B</strong>:  The matrix that takes Ei to Ek (Ek = Ei B).
</p>
</li>
<li> <p><strong>&quot;Bstar&quot;</strong> In an orthogonal factor model, Bstar takes Fi to Fk (Fk = Fi Bstar). 
In an oblique model the program returns Bstar=NULL.
</p>
</li>
<li> <p><strong>&quot;P&quot;</strong>: The matrix that imposes the proper covariance structure on Ei.
</p>
</li>
<li> <p><strong>&quot;SeedX&quot;</strong>: Starting seed for X.   
</p>
</li>
<li> <p><strong>&quot;SeedBasis&quot;</strong>: Starting seed for the basis. 
</p>
</li>
<li> <p><strong>&quot;SeedW&quot;</strong>: Starting seed for weight matrix W. 
</p>
</li>
<li> <p><strong>&quot;SeedT&quot;</strong>: Starting seed for rotation matrix T.
</p>
</li>
<li> <p><strong>&quot;Guttman&quot;</strong>:  Guttman indeterminacy measures for the common and unique factors.
</p>
</li>
<li> <p><strong>&quot;CovFhat&quot;</strong>: Covariance matrix of estimated factor scores.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller (nwaller@umn.edu)
</p>


<h3>References</h3>

<p>Guttman, L.  (1955).  The determinacy of factor score matrices 
with applications for five other problems of common factor theory.  
<em>British Journal of Statistical Psychology, 8</em>, 65-82.
</p>
<p>Ledermann, W.  (1938).  The orthogonal transformation of a factorial matrix 
into itself.  <em>Psychometrika, 3</em>, 181-187.
</p>
<p>Schnemann, P. H. (1971). The minimum average correlation 
between equivalent sets of uncorrelated factors. <em>Psychometrika, 36</em>, 
21-30.
</p>
<p>Steiger, J. H. and Schonemann, P. H.  (1978).  In Shye, S. (Ed.), 
<em>A history of factor indeterminacy</em> (pp. 136&ndash;178). San  Francisco: Jossey-Bass.
</p>
<p>Waller, N. G. (2021) Understanding factor indeterminacy through the lens of finite 
dimensional vector spaces. Manuscript under review.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ---- Example 1: ----
# To run the example in Waller (2021) enter:
out1 &lt;- fsIndeterminacy(Example = TRUE)

# ---- Example 1: Extended Version: ----

N &lt;- 10 # number of observations
# Generate Lambda: common factor loadings 
#          Phi: Common factor correlation matrix

Lambda &lt;- matrix(c(.8,  0,
                   .7,  0,
                   .6,  0,
                    0, .5,
                    0, .4,
                    0, .3), 6, 2, byrow=TRUE)

out1  &lt;- fsIndeterminacy(Lambda,
                         Phi = NULL,    # orthogonal model
                         SeedX = 1,     # Seed for X
                         SeedBasis = 2, # Seed for Basis
                         SeedW = 3,     # Seed for Weight matrix
                         SeedT = 5,     # Seed for Transformation matrix
                         N = 10,        # Number of subjects
                         Print = "long",
                         Digits = 3)

# Four sets of factor scores
  Fi &lt;- out1$Fi
  Fj &lt;- out1$Fj
  Fk &lt;- out1$Fk
  Fl &lt;- out1$Fl

# Estimated Factor scores
  Fhat &lt;- out1$Fhat

# B wipes out Fhat (in an orthogonal model)
  B &lt;- out1$B
  round( cbind(Fhat[1:5,1:2], (Fhat %*% B)[1:5,1:2]), 3) 

# B takes Ei -&gt; Ek
  Ei &lt;- out1$Ei
  Ek &lt;- out1$Ek
  Ek - (Ei %*% B)

# The Transformation Approach
# Bstar takes Fi --&gt; Fk
  Bstar &lt;- out1$Bstar
  round( Fk - Fi %*% Bstar, 3)

# Bstar L' = L'
  L &lt;- out1$L
  round( L %*% t(Bstar), 3)[,1:2]  


# ---- Example 3 ----
# We choose a different seed for T

out2  &lt;- fsIndeterminacy(Lambda , 
                        Phi = NULL, 
                        X = NULL,
                        SeedX = 1,     # Seed for X 
                        SeedBasis = 2, #  Seed for Basis
                        SeedW = 3,     #  Seed for Weight matrix
                        SeedT = 4,     # Seed for Transformation matrix
                        N,             
                        Print = "long",
                        Digits = 3,
                        Example = FALSE)
 Fi &lt;- out2$Fi
 Fj &lt;- out2$Fj
 Fk &lt;- out2$Fk
 Fl &lt;- out2$Fl
 X  &lt;- out2$X
 
# Notice that all sets of factor scores are model consistent 
 round( t( solve(t(Fi) %*% Fi) %*% t(Fi) %*% X) ,3)
 round( t( solve(t(Fj) %*% Fj) %*% t(Fj) %*% X) ,3)
 round( t( solve(t(Fk) %*% Fk) %*% t(Fk) %*% X) ,3)
 round( t( solve(t(Fl) %*% Fl) %*% t(Fl) %*% X) ,3)
 
# Guttman's Indeterminacy Index
round( (1/N * t(Fi) %*% Fj)[1:2,1:2], 3)

</code></pre>

<hr>
<h2 id='fungible'>Generate Fungible Regression Weights</h2><span id='topic+fungible'></span>

<h3>Description</h3>

<p>Generate fungible weights for OLS Regression Models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fungible(R.X, rxy, r.yhata.yhatb, sets, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungible_+3A_r.x">R.X</code></td>
<td>
<p>p x p Predictor correlation matrix.</p>
</td></tr>
<tr><td><code id="fungible_+3A_rxy">rxy</code></td>
<td>
<p>p x 1 Vector of predictor-criterion correlations.</p>
</td></tr>
<tr><td><code id="fungible_+3A_r.yhata.yhatb">r.yhata.yhatb</code></td>
<td>
<p>Correlation between least squares (yhatb) and
alternate-weight (yhata) composites.</p>
</td></tr>
<tr><td><code id="fungible_+3A_sets">sets</code></td>
<td>
<p>Number of returned sets of fungible weights.</p>
</td></tr>
<tr><td><code id="fungible_+3A_print">print</code></td>
<td>
<p>Logical, if TRUE then print 5-point summaries of alternative
weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>a</code></td>
<td>
<p>Number of sets x p matrix of fungible weights.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of sets x p matrix of k weights.</p>
</td></tr> <tr><td><code>b</code></td>
<td>
<p>p x 1 vector of
LS weights.</p>
</td></tr> <tr><td><code>u</code></td>
<td>
<p>p x 1 vector of u weights.</p>
</td></tr>
<tr><td><code>r.yhata.yhatb</code></td>
<td>
<p>Correlation between yhata and yhatb.</p>
</td></tr>
<tr><td><code>r.y.yhatb</code></td>
<td>
<p>Correlation between y and yhatb.</p>
</td></tr> <tr><td><code>cov.a</code></td>
<td>
<p>Expected
covariance matrix for a.</p>
</td></tr> <tr><td><code>cor.a</code></td>
<td>
<p>Expected correlation matrix for a.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Waller, N. (2008). Fungible weights in multiple regression.
<em>Psychometrika, 73</em>, 69&ndash;703.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Predictor correlation matrix
R.X &lt;- matrix(c(1.00,   .56,  .77,
                 .56,  1.00,  .73,
                 .77,   .73, 1.00), 3, 3)
 
## vector of predictor-criterion correlations 
rxy &lt;- c(.39, .34, .38)
 
 
## OLS standardized regression coefficients
b &lt;- solve(R.X) %*% rxy
 
## Coefficient of determination (Rsq)
OLSRSQ &lt;- t(b) %*% R.X %*% b

## theta controls the correlation between 
## yhatb: predicted criterion scores using OLS coefficients
## yhata: predicted criterion scores using alternate weights
theta &lt;- .01

## desired correlation between yhata and yhatb 
r.yhata.yhatb &lt;- sqrt( 1 - (theta)/OLSRSQ)

## number of returned sets of fungible weight vectors
Nsets &lt;- 50

output &lt;- fungible(R.X, rxy, r.yhata.yhatb, sets = Nsets, print = TRUE)

</code></pre>

<hr>
<h2 id='fungibleExtrema'>Locate Extrema of Fungible Regression Weights</h2><span id='topic+fungibleExtrema'></span>

<h3>Description</h3>

<p>Locate extrema of fungible regression weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fungibleExtrema(
  R.X,
  rxy,
  r.yhata.yhatb,
  Nstarts = 100,
  MaxMin = "Max",
  Seed = NULL,
  maxGrad = 1e-05,
  PrintLevel = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungibleExtrema_+3A_r.x">R.X</code></td>
<td>
<p>p x p Predictor variable correlation matrix.</p>
</td></tr>
<tr><td><code id="fungibleExtrema_+3A_rxy">rxy</code></td>
<td>
<p>p x 1 Vector of predictor-criterion correlations.</p>
</td></tr>
<tr><td><code id="fungibleExtrema_+3A_r.yhata.yhatb">r.yhata.yhatb</code></td>
<td>
<p>Correlation between least squares (yhatb) and
alternate-weight (yhata) composites.</p>
</td></tr>
<tr><td><code id="fungibleExtrema_+3A_nstarts">Nstarts</code></td>
<td>
<p>Maximum number of (max) minimizations from random starting
configurations.</p>
</td></tr>
<tr><td><code id="fungibleExtrema_+3A_maxmin">MaxMin</code></td>
<td>
<p>Character: &quot;Max&quot; = maximize cos(a,b); &quot;Min&quot; = minimize
cos(a,b).</p>
</td></tr>
<tr><td><code id="fungibleExtrema_+3A_seed">Seed</code></td>
<td>
<p>Starting seed for the random number generator. If Seed = NULL 
then the program will sample a random integer in the (0, 100,000) interval.
Default (Seed = NULL).</p>
</td></tr>
<tr><td><code id="fungibleExtrema_+3A_maxgrad">maxGrad</code></td>
<td>
<p>The optimization routine will end when the maximimum of
the (absolute value of the ) function gradient falls below the value specified in 
maxGrad. Default (maxGrad = 1E-05).</p>
</td></tr>
<tr><td><code id="fungibleExtrema_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(integer). If PrintLevel = 1 then the program will print 
additional output during function convergence. Default (PrintLevel = 1).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>cos.ab</code></td>
<td>
<p>cosine between OLS and alternate weights.</p>
</td></tr>
<tr><td><code>a</code></td>
<td>
<p>extrema of fungible weights.</p>
</td></tr> <tr><td><code>k</code></td>
<td>
<p>k weights.</p>
</td></tr> <tr><td><code>z</code></td>
<td>
<p>z
weights: a normalized random vector.</p>
</td></tr> <tr><td><code>b</code></td>
<td>
<p>OLS weights.</p>
</td></tr> <tr><td><code>u</code></td>
<td>
<p>p x 1
vector of u weights.</p>
</td></tr> <tr><td><code>r.yhata.yhatb</code></td>
<td>
<p>Correlation between yhata and
yhatb.</p>
</td></tr> <tr><td><code>r.y.yhatb</code></td>
<td>
<p>Correlation between y and yhatb.</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>Gradient of converged solution.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller and Jeff Jones
</p>


<h3>References</h3>

<p>Koopman, R. F.  (1988).  On the sensitivity of a composite to
its weights.  <em>Psychometrika, 53(4)</em>, 547&ndash;552.
</p>
<p>Waller, N. &amp; Jones, J. (2009). Locating the extrema of fungible regression
weights in multiple regression. <em>Psychometrika, 74</em>, 589&ndash;602.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:   
## Example 
## This is Koopman's Table 2 Example


R.X &lt;- matrix(c(1.00,  .69,  .49,  .39,
                .69, 1.00,  .38,  .19,
                .49,  .38, 1.00,  .27,
                .39,  .19,  .27, 1.00),4,4)


b &lt;- c(.39, .22, .02, .43)
rxy &lt;- R.X %*% b

OLSRSQ &lt;- t(b) %*% R.X %*% b

theta &lt;- .02
r.yhata.yhatb &lt;- sqrt( 1 - (theta)/OLSRSQ)

Converged = FALSE
SEED = 1234
MaxTries = 100 
iter = 1

while( iter &lt;= MaxTries){
   SEED &lt;- SEED + 1
  
   cat("\nCurrent Seed = ", SEED, "\n")
   output &lt;- fungibleExtrema(R.X, rxy, 
                             r.yhata.yhatb, 
                             Nstarts = 5,
                             MaxMin = "Min", 
                             Seed = SEED,
                             maxGrad = 1E-05,
                             PrintLevel = 1)
  
   Converged &lt;- output$converged
   if(Converged) break
   iter = iter + 1
}  

print( output )

## Scale to replicate Koopman
a &lt;- output$a
a.old &lt;- a
aRa &lt;- t(a) %*% R.X %*% a

## Scale a such that a' R a = .68659
## vc = variance of composite
vc &lt;- aRa
## sf = scale factor
sf &lt;- .68659/vc
a &lt;- as.numeric(sqrt(sf)) * a
cat("\nKoopman Scaling\n")
print(round(a,2))

## End(Not run)
</code></pre>

<hr>
<h2 id='fungibleL'>Generate Fungible Logistic Regression Weights</h2><span id='topic+fungibleL'></span>

<h3>Description</h3>

<p>Generate fungible weights for Logistic Regression Models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fungibleL(
  X,
  y,
  Nsets = 1000,
  method = "LLM",
  RsqDelta = NULL,
  rLaLb = NULL,
  s = 0.3,
  Print = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungibleL_+3A_x">X</code></td>
<td>
<p>An n by nvar matrix of predictor scores without the leading column
of ones.</p>
</td></tr>
<tr><td><code id="fungibleL_+3A_y">y</code></td>
<td>
<p>An n by 1 vector of dichotomous criterion scores.</p>
</td></tr>
<tr><td><code id="fungibleL_+3A_nsets">Nsets</code></td>
<td>
<p>The desired number of fungible coefficient vectors.</p>
</td></tr>
<tr><td><code id="fungibleL_+3A_method">method</code></td>
<td>
<p>Character: &quot;LLM&quot; = Log-Likelihood method. &quot;EM&quot; = Ellipsoid
Method. Default: method = &quot;LLM&quot;.</p>
</td></tr>
<tr><td><code id="fungibleL_+3A_rsqdelta">RsqDelta</code></td>
<td>
<p>The desired decrement in the pseudo-R-squared - used when
method = &quot;LLM&quot;.</p>
</td></tr>
<tr><td><code id="fungibleL_+3A_rlalb">rLaLb</code></td>
<td>
<p>The desired correlation between the logits - used when method =
&quot;EM&quot;.</p>
</td></tr>
<tr><td><code id="fungibleL_+3A_s">s</code></td>
<td>
<p>Scale factor for random deviates. s controls the range of random
start values for the optimization routine. Recommended 0 &lt;= s &lt; 1. Default:
s = 0.3.</p>
</td></tr>
<tr><td><code id="fungibleL_+3A_print">Print</code></td>
<td>
<p>Boolean (TRUE/FALSE) for printing output summary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>fungibleL provides two methods for evaluating parameter sensitivity in
logistic regression models by computing fungible logistic regression
weights. For for additional information on the underlying theory of these
methods see Jones and Waller (in press).
</p>


<h3>Value</h3>

<table>
<tr><td><code>model</code></td>
<td>
<p>A glm model object.</p>
</td></tr> <tr><td><code>call</code></td>
<td>
<p>The function call to
glm().</p>
</td></tr> <tr><td><code>ftable</code></td>
<td>
<p>A data frame with the mle estimates and the minimum
and maximum fungible coefficients.</p>
</td></tr> <tr><td><code>lnLML</code></td>
<td>
<p>The maximum likelihood log
likelihood value.</p>
</td></tr> <tr><td><code>lnLf</code></td>
<td>
<p>The decremented, fungible log likelihood
value.</p>
</td></tr> <tr><td><code>pseudoRsq</code></td>
<td>
<p>The pseudo R-squared.</p>
</td></tr> <tr><td><code>fungibleRsq</code></td>
<td>
<p>The
fungible pseudo R-squared.</p>
</td></tr> <tr><td><code>fungiblea</code></td>
<td>
<p>The Nsets by Nvar + 1 matrix of
fungible (alternate) coefficients.</p>
</td></tr> <tr><td><code>rLaLb</code></td>
<td>
<p>The correlation between the
logits.</p>
</td></tr> <tr><td><code>maxPosCoefChange</code></td>
<td>
<p>The maximum positive change in a single
coefficient holding all other coefficients constant.</p>
</td></tr>
<tr><td><code>maxNegCoefChange</code></td>
<td>
<p>The maximum negative change in a single coefficient
holding all other coefficients constant.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Jones and Niels Waller
</p>


<h3>References</h3>

<p>Jones, J. A. &amp; Waller, N. G. (in press). Fungible weights in
logistic regression. <em>Psychological Methods</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example: Low Birth Weight Data from Hosmer Jr, D. W. &amp; Lemeshow, S.(2000).         
# low : low birth rate (0 &gt;= 2500 grams, 1 &lt; 2500 grams)
# race: 1 = white, 2 = black, 3 = other
# ftv : number of physician visits during the first trimester

library(MASS)
attach(birthwt)

race &lt;- factor(race, labels = c("white", "black", "other"))
predictors &lt;- cbind(lwt, model.matrix(~ race)[, -1])

# compute mle estimates
BWght.out &lt;- glm(low ~ lwt + race, family = "binomial")

# compute fungible coefficients
fungible.LLM &lt;- fungibleL(X = predictors, y = low, method = "LLM", 
                          Nsets = 10, RsqDelta = .005, s = .3)

# Compare with Table 2.3 (page 38) Hosmer Jr, D. W. &amp; Lemeshow, S.(2000). 
# Applied logistic regression.  New York, Wiley.  

print(summary(BWght.out))
print(fungible.LLM$call)
print(fungible.LLM$ftable)
cat("\nMLE log likelihod       = ", fungible.LLM$lnLML,
    "\nfungible log likelihood = ", fungible.LLM$lnLf)
cat("\nPseudo Rsq              = ", round(fungible.LLM$pseudoRsq, 3))
cat("\nfungible Pseudo Rsq     = ", round(fungible.LLM$fungibleRsq, 3))


fungible.EM &lt;- fungibleL(X = predictors, y = low, method = "EM" , 
                         Nsets = 10, rLaLb = 0.99)

print(fungible.EM$call)
print(fungible.EM$ftable)

cat("\nrLaLb = ", round(fungible.EM$rLaLb, 3))

</code></pre>

<hr>
<h2 id='fungibleR'>Generate Fungible Correlation Matrices</h2><span id='topic+fungibleR'></span>

<h3>Description</h3>

<p>Generate fungible correlation matrices. For a given vector of standardized
regression coefficients, Beta, and a user-define R-squared value, Rsq, find
predictor correlation matrices, R, such that Beta' R Beta = Rsq. The size of
the smallest eigenvalue (Lp) of R can be defined.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fungibleR(R, Beta, Lp = 0, eps = 1e-08, Print.Warnings = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungibleR_+3A_r">R</code></td>
<td>
<p>A p x p predictor correlation matrix.</p>
</td></tr>
<tr><td><code id="fungibleR_+3A_beta">Beta</code></td>
<td>
<p>A p x 1 vector of standardized regression coefficients.</p>
</td></tr>
<tr><td><code id="fungibleR_+3A_lp">Lp</code></td>
<td>
<p>Controls the size of the smallest eigenvalue of RstarLp.</p>
</td></tr>
<tr><td><code id="fungibleR_+3A_eps">eps</code></td>
<td>
<p>Convergence criterion.</p>
</td></tr>
<tr><td><code id="fungibleR_+3A_print.warnings">Print.Warnings</code></td>
<td>
<p>Logical, default = TRUE. When TRUE, convergence
failures are printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>R</code></td>
<td>
<p>Any input correlation matrix that satisfies Beta' R Beta =
Rsq.</p>
</td></tr> <tr><td><code>Beta</code></td>
<td>
<p>Input vector of std reg coefficients.</p>
</td></tr> <tr><td><code>Rstar</code></td>
<td>
<p>A
random fungible correlation matrix.</p>
</td></tr> <tr><td><code>RstarLp</code></td>
<td>
<p>A fungible correlation
matrix with a fixed minimum eigenvalue (RstarLp can be PD, PSD, or ID).</p>
</td></tr>
<tr><td><code>s</code></td>
<td>
<p>Scaling constant for Rstar.</p>
</td></tr> <tr><td><code>sLp</code></td>
<td>
<p>Scaling constant for
RstarLp.</p>
</td></tr> <tr><td><code>Delta</code></td>
<td>
<p>Vector in the null space of vecp(Beta Beta').</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>Left null space of Beta.</p>
</td></tr> <tr><td><code>FrobNorm</code></td>
<td>
<p>Frobenius norm ||R -
Rstar||_F.</p>
</td></tr> <tr><td><code>FrobNormLp</code></td>
<td>
<p>Frobenius norm ||R - RstarLp||_F given random
Delta.</p>
</td></tr> <tr><td><code>converged</code></td>
<td>
<p>An integer code. 0 indicates successful
completion.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Waller, N. (2016). Fungible Correlation Matrices: A method for
generating nonsingular, singular, and improper correlation matrices for
Monte Carlo research. Multivariate Behavioral Research.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(fungible)

## ===== Example 1 =====
## Generate 5 random PD fungible R matrices
## that are consistent with a user-defined predictive 
## structure: B' Rxx B = .30

set.seed(246)
## Create a 5 x 5 correlation matrix, R,  with all r_ij = .25
R.ex1 &lt;- matrix(.25, 5, 5)
diag(R.ex1) &lt;- 1

## create a 5 x 1 vector of standardized regression coefficients, 
## Beta.ex1 
Beta.ex1 &lt;- c(-.4, -.2, 0, .2, .4)
cat("\nModel Rsq = ",  t(Beta.ex1) %*% R.ex1 %*% Beta.ex1)

## Generate fungible correlation matrices, Rstar, with smallest
## eigenvalues &gt; 0.

Rstar.list &lt;- list(rep(99,5)) 
i &lt;- 0
while(i &lt;= 5){
  out &lt;- fungibleR(R = R.ex1, Beta = Beta.ex1, Lp = 1e-8, eps = 1e-8, 
                   Print.Warnings = TRUE)
  if(out$converged==0){
    i &lt;- i + 1
    Rstar.list[[i]] &lt;- out$Rstar
  }
}

## Check Results
cat("\n *** Check Results ***")
for(i in 1:5){
  cat("\n\n\n+++++++++++++++++++++++++++++++++++++++++++++++++")
  cat("\nRstar", i,"\n")
  print(round(Rstar.list[[i]], 2),)
  cat("\neigenvalues of Rstar", i,"\n")
  print(eigen(Rstar.list[[i]])$values)
  cat("\nBeta' Rstar",i, "Beta = ",  
      t(Beta.ex1) %*% Rstar.list[[i]] %*% Beta.ex1)
}  



## ===== Example 2 =====
## Generate a PD fungible R matrix with a fixed smallest 
## eigenvalue (Lp).

## Create a 5 x 5 correlation matrix, R,  with all r_ij = .5
R &lt;- matrix(.5, 5, 5)
diag(R) &lt;- 1

## create a 5 x 1 vector of standardized regression coefficients, Beta, 
## such that Beta_i = .1 for all i 
Beta &lt;- rep(.1, 5)

## Generate fungible correlation matrices (a) Rstar and (b) RstarLp.
## Set Lp = 0.12345678 so that the smallest eigenvalue (Lp) of RstarLp
## = 0.12345678
out &lt;- fungibleR(R, Beta, Lp = 0.12345678, eps = 1e-10, Print.Warnings = TRUE)

## print R
cat("\nR: a user-specified seed matrix")
print(round(out$R,3)) 

## Rstar
cat("\nRstar: A random fungible correlation matrix for R")
print(round(out$Rstar,3)) 

cat("\nCoefficient of determination when using R\n")
print(  t(Beta) %*% R %*% Beta )

cat("\nCoefficient of determination when using Rstar\n")
print( t(Beta) %*% out$Rstar %*% Beta)

## Eigenvalues of  R
cat("\nEigenvalues of R\n")
print(round(eigen(out$R)$values, 9)) 

## Eigenvalues of  Rstar
cat("\nEigenvalues of Rstar\n")
print(round(eigen(out$Rstar)$values, 9)) 

## What is the Frobenius norm (Euclidean distance) between
## R and Rstar
cat("\nFrobenious norm ||R - Rstar||\n")
print( out$FrobNorm)

## RstarLp is a random fungible correlation matrix with 
## a fixed smallest eigenvalue of 0.12345678
cat("\nRstarLp: a random fungible correlation matrix with a user-defined
smallest eigenvalue\n")
print(round(out$RstarLp, 3)) 

## Eigenvalues of RstarLp
cat("\nEigenvalues of RstarLp")
print(eigen(out$RstarLp)$values, digits = 9) 

cat("\nCoefficient of determination when using RstarLp\n")
print( t(Beta) %*% out$RstarLp %*% Beta)

## Check function convergence
if(out$converged) print("Falied to converge")


## ===== Example 3 =====
## This examples demonstrates how fungibleR  can be used
## to generate improper correlation matrices (i.e., pseudo 
## correlation matrices with negative eigenvalues).
library(fungible)

## We desire an improper correlation matrix that
## is close to a user-supplied seed matrix.  Create an 
## interesting seed matrix that reflects a Big Five 
## factor structure.

set.seed(123)
minCrossLoading &lt;- -.2
maxCrossLoading &lt;-  .2
F1 &lt;- c(rep(.6,5),runif(20,minCrossLoading, maxCrossLoading))
F2 &lt;- c(runif(5,minCrossLoading, maxCrossLoading), rep(.6,5), 
      runif(15,minCrossLoading, maxCrossLoading))
F3 &lt;- c(runif(10,minCrossLoading,maxCrossLoading), rep(.6,5), 
      runif(10,minCrossLoading,maxCrossLoading) )
F4 &lt;- c(runif(15,minCrossLoading,maxCrossLoading), rep(.6,5), 
      runif(5,minCrossLoading,maxCrossLoading))
F5 &lt;- c(runif(20,minCrossLoading,maxCrossLoading), rep(.6,5))
FacMat &lt;- cbind(F1,F2,F3,F4,F5)
R.bfi &lt;- FacMat %*% t(FacMat)
diag(R.bfi) &lt;- 1

## Set Beta to a null vector to inform fungibleR that we are 
## not interested in placing constraints on the predictive structure 
## of the fungible R matrices. 
Beta &lt;- rep(0, 25)


## We seek a NPD fungible R matrix that is close to the bfi seed matrix.
## To find a suitable matrix we generate a large number (e.g., 50000) 
## fungible R matrices. For illustration purposes I will set Nmatrices
## to a smaller number: 10.
Nmatrices&lt;-10

## Initialize a list to contain the Nmatrices fungible R objects
RstarLp.list &lt;- as.list( rep(0, Nmatrices ) )
## Initialize a vector for the Nmatrices Frobeius norms ||R - RstarLp||
FrobLp.vec &lt;- rep(0, Nmatrices)


## Constraint the smallest eigenvalue of RStarLp by setting
## Lp = -.1 (or any suitably chosen user-defined value).

## Generate Nmatrices fungibleR matrices and identify the NPD correlation 
## matrix that is "closest" (has the smallest Frobenious norm) to the bfi 
## seed matrix.
BestR.i &lt;- 0
BestFrob &lt;- 99
i &lt;- 0

set.seed(1)
while(i &lt; Nmatrices){
  out&lt;-fungibleR(R = R.bfi, Beta, Lp = -.1, eps=1e-10) 
  ## retain solution if algorithm converged
  if(out$converged == 0)
  { 
    i&lt;- i + 1
  ## print progress  
    cat("\nGenerating matrix ", i, " Current minimum ||R - RstarLp|| = ",BestFrob)
    tmp &lt;- FrobLp.vec[i] &lt;- out$FrobNormLp #Frobenious Norm ||R - RstarLp||
    RstarLp.list[[i]]&lt;-out$RstarLp
    if( tmp &lt; BestFrob )
    {
      BestR.i &lt;- i     # matrix with lowest ||R - RstarLp||
      BestFrob &lt;- tmp  # value of lowest ||R - RstarLp||
    }
  }
}



# CloseR is an improper correlation matrix that is close to the seed matrix. 
CloseR&lt;-RstarLp.list[[BestR.i]]

plot(1:25, eigen(R.bfi)$values,
     type = "b", 
     lwd = 2,
     main = "Scree Plots for R and RstarLp",
     cex.main = 1.5,
     ylim = c(-.2,6),
     ylab = "Eigenvalues",
     xlab = "Dimensions")
points(1:25,eigen(CloseR)$values,
       type = "b",
       lty = 2,
       lwd = 2,
       col = "red")
	   abline(h = 0, col = "grey")
legend(legend=c(expression(paste(lambda[i]~" of R",sep = "")),
                expression(paste(lambda[i]~" of RstarLp",sep = ""))),
       lty=c(1,2),
       x = 17,y = 5.75,
       cex = 1.5,
       col=c("black","red"),
       text.width = 5.5,
       lwd = 2)

</code></pre>

<hr>
<h2 id='FUP'>Estimate the coefficients of a filtered unconstrained polynomial IRT model</h2><span id='topic+FUP'></span>

<h3>Description</h3>

<p>Estimate the coefficients of a filtered unconstrained polynomial IRT model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FUP(data, thetaInit, item, startvals, k = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FUP_+3A_data">data</code></td>
<td>
<p>N(subjects)-by-p(items) matrix of 0/1 item response data.</p>
</td></tr>
<tr><td><code id="FUP_+3A_thetainit">thetaInit</code></td>
<td>
<p>Initial theta surrogates (e.g., calculated by
<a href="#topic+svdNorm">svdNorm</a>).</p>
</td></tr>
<tr><td><code id="FUP_+3A_item">item</code></td>
<td>
<p>item number for coefficient estimation.</p>
</td></tr>
<tr><td><code id="FUP_+3A_startvals">startvals</code></td>
<td>
<p>start values for function minimization.</p>
</td></tr>
<tr><td><code id="FUP_+3A_k">k</code></td>
<td>
<p>order of monotonic polynomial = 2k+1 (see Liang &amp; Browne, 2015).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>b</code></td>
<td>
<p>Vector of polynomial coefficients.</p>
</td></tr> <tr><td><code>FHAT</code></td>
<td>
<p>Function
value at convergence.</p>
</td></tr> <tr><td><code>counts</code></td>
<td>
<p>Number of function evaluations during
minimization (see optim documentation for further details).</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Pseudo scaled Akaike Information Criterion (AIC). Candidate
models that produce the smallest AIC suggest the optimal number of
parameters given the sample size. Scaling is accomplished by dividing the
non-scaled AIC by sample size.</p>
</td></tr> <tr><td><code>BIC</code></td>
<td>
<p>Pseudo scaled Bayesian
Information Criterion (BIC). Candidate models that produce the smallest BIC
suggest the optimal number of parameters given the sample size. Scaling is
accomplished by dividing the non-scaled BIC by sample size.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence = 0 indicates that the optimization algorithm
converged; convergence=1 indicates that the optimization failed to converge.
</p>
<p>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Liang, L. &amp; Browne, M. W. (2015). A quasi-parametric method for
fitting flexible item response functions. <em>Journal of Educational and
Behavioral Statistics, 40</em>, 5&ndash;34.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
NSubjects &lt;- 2000


## generate sample k=1 FMP data
b &lt;- matrix(c(
    #b0    b1     b2    b3      b4   b5 b6 b7  k
  1.675, 1.974, -0.068, 0.053,  0,  0,  0,  0, 1,
  1.550, 1.805, -0.230, 0.032,  0,  0,  0,  0, 1,
  1.282, 1.063, -0.103, 0.003,  0,  0,  0,  0, 1,
  0.704, 1.376, -0.107, 0.040,  0,  0,  0,  0, 1,
  1.417, 1.413,  0.021, 0.000,  0,  0,  0,  0, 1,
 -0.008, 1.349, -0.195, 0.144,  0,  0,  0,  0, 1,
  0.512, 1.538, -0.089, 0.082,  0,  0,  0,  0, 1,
  0.122, 0.601, -0.082, 0.119,  0,  0,  0,  0, 1,
  1.801, 1.211,  0.015, 0.000,  0,  0,  0,  0, 1,
 -0.207, 1.191,  0.066, 0.033,  0,  0,  0,  0, 1,
 -0.215, 1.291, -0.087, 0.029,  0,  0,  0,  0, 1,
  0.259, 0.875,  0.177, 0.072,  0,  0,  0,  0, 1,
 -0.423, 0.942,  0.064, 0.094,  0,  0,  0,  0, 1,
  0.113, 0.795,  0.124, 0.110,  0,  0,  0,  0, 1,
  1.030, 1.525,  0.200, 0.076,  0,  0,  0,  0, 1,
  0.140, 1.209,  0.082, 0.148,  0,  0,  0,  0, 1,
  0.429, 1.480, -0.008, 0.061,  0,  0,  0,  0, 1,
  0.089, 0.785, -0.065, 0.018,  0,  0,  0,  0, 1,
 -0.516, 1.013,  0.016, 0.023,  0,  0,  0,  0, 1,
  0.143, 1.315, -0.011, 0.136,  0,  0,  0,  0, 1,
  0.347, 0.733, -0.121, 0.041,  0,  0,  0,  0, 1,
 -0.074, 0.869,  0.013, 0.026,  0,  0,  0,  0, 1,
  0.630, 1.484, -0.001, 0.000,  0,  0,  0,  0, 1), 
  nrow=23, ncol=9, byrow=TRUE)  
 
# generate data using the above item parameters 
ex1.data&lt;-genFMPData(NSubj = NSubjects, bParams = b, seed = 345)$data

NItems &lt;- ncol(ex1.data)

# compute (initial) surrogate theta values from 
# the normed left singular vector of the centered 
# data matrix
thetaInit &lt;- svdNorm(ex1.data)

# Choose model
k &lt;- 1  # order of polynomial = 2k+1

# Initialize matrices to hold output
if(k == 0) {
  startVals &lt;- c(1.5, 1.5)
  bmat &lt;- matrix(0,NItems,6)
  colnames(bmat) &lt;- c(paste("b", 0:1, sep = ""),"FHAT", "AIC", "BIC", "convergence") 
}

if(k == 1) {
  startVals &lt;- c(1.5, 1.5, .10, .10)
  bmat &lt;- matrix(0,NItems,8)
  colnames(bmat) &lt;- c(paste("b", 0:3, sep = ""),"FHAT", "AIC", "BIC", "convergence") 
}

if(k == 2) {
  startVals &lt;- c(1.5, 1.5, .10, .10, .10, .10)
  bmat &lt;- matrix(0,NItems,10)
  colnames(bmat) &lt;- c(paste("b", 0:5, sep = ""),"FHAT", "AIC", "BIC", "convergence") 
}

if(k == 3) {
  startVals &lt;- c(1.5, 1.5, .10, .10, .10, .10, .10, .10)
  bmat &lt;- matrix(0,NItems,12)
  colnames(bmat) &lt;- c(paste("b", 0:7, sep = ""),"FHAT", "AIC", "BIC", "convergence") 
}   


# estimate item parameters and fit statistics
for(i in 1:NItems){
  out&lt;-FUP(data = ex1.data,thetaInit = thetaInit, item = i, startvals = startVals, k = k)
  Nb &lt;- length(out$b)
  bmat[i,1:Nb] &lt;- out$b
  bmat[i,Nb+1] &lt;- out$FHAT
  bmat[i,Nb+2] &lt;- out$AIC
  bmat[i,Nb+3] &lt;- out$BIC
  bmat[i,Nb+4] &lt;- out$convergence
}

# print results
print(bmat)

## End(Not run)

</code></pre>

<hr>
<h2 id='gen4PMData'>Generate item response data for 1, 2, 3, or 4-parameter IRT models</h2><span id='topic+gen4PMData'></span>

<h3>Description</h3>

<p>Generate item response data for or 1, 2, 3 or 4-parameter IRT Models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen4PMData(
  NSubj = NULL,
  abcdParams,
  D = 1.702,
  seed = NULL,
  theta = NULL,
  thetaMN = 0,
  thetaVar = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen4PMData_+3A_nsubj">NSubj</code></td>
<td>
<p>the desired number of subject response vectors.</p>
</td></tr>
<tr><td><code id="gen4PMData_+3A_abcdparams">abcdParams</code></td>
<td>
<p>a p(items)-by-4 matrix of IRT item parameters: a =
discrimination, b = difficulty, c = lower asymptote, and d = upper
asymptote.</p>
</td></tr>
<tr><td><code id="gen4PMData_+3A_d">D</code></td>
<td>
<p>Scaling constant to place the IRF on the normal ogive or logistic
metric. Default = 1.702 (normal ogive metric)</p>
</td></tr>
<tr><td><code id="gen4PMData_+3A_seed">seed</code></td>
<td>
<p>Optional seed for the random number generator.</p>
</td></tr>
<tr><td><code id="gen4PMData_+3A_theta">theta</code></td>
<td>
<p>Optional vector of latent trait scores. If theta = NULL (the
default value) then gen4PMData will simulate theta from a normal
distribution.</p>
</td></tr>
<tr><td><code id="gen4PMData_+3A_thetamn">thetaMN</code></td>
<td>
<p>Mean of simulated theta distribution. Default = 0.</p>
</td></tr>
<tr><td><code id="gen4PMData_+3A_thetavar">thetaVar</code></td>
<td>
<p>Variance of simulated theta distribution. Default = 1</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>data</code></td>
<td>
<p>N(subject)-by-p(items) matrix of item response data.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Latent trait scores.</p>
</td></tr> <tr><td><code>seed</code></td>
<td>
<p>Value of the random number
seed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Generate simulated 4PM data for 2,000 subjects
# 4PM Item parameters from MMPI-A CYN scale

Params&lt;-matrix(c(1.41, -0.79, .01, .98, #1  
                 1.19, -0.81, .02, .96, #2 
                 0.79, -1.11, .05, .94, #3
                 0.94, -0.53, .02, .93, #4
                 0.90, -1.02, .04, .95, #5
                 1.00, -0.21, .02, .84, #6
                 1.05, -0.27, .02, .97, #7
                 0.90, -0.75, .04, .73, #8  
                 0.80, -1.42, .06, .98, #9
                 0.71,  0.13, .05, .94, #10
                 1.01, -0.14, .02, .81, #11
                 0.63,  0.18, .18, .97, #12
                 0.68,  0.18, .02, .87, #13
                 0.60, -0.14, .09, .96, #14
                 0.85, -0.71, .04, .99, #15
                 0.83, -0.07, .05, .97, #16
                 0.86, -0.36, .03, .95, #17
                 0.66, -0.64, .04, .77, #18
                 0.60,  0.52, .04, .94, #19
                 0.90, -0.06, .02, .96, #20
                 0.62, -0.47, .05, .86, #21
                 0.57,  0.13, .06, .93, #22
                 0.77, -0.43, .04, .97),23,4, byrow=TRUE) 

 data &lt;- gen4PMData(NSubj=2000, abcdParams = Params, D = 1.702,  
                    seed = 123, thetaMN = 0, thetaVar = 1)$data
 
 cat("\nClassical item difficulties for simulated data")                   
 print( round( apply(data,2,mean),2) )

</code></pre>

<hr>
<h2 id='genCorr'>Generate Correlation Matrices with User-Defined Eigenvalues</h2><span id='topic+genCorr'></span>

<h3>Description</h3>

<p>Uses the Marsaglia and Olkin (1984) algorithm to generate correlation
matrices with user-defined eigenvalues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genCorr(eigenval, seed = "rand")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genCorr_+3A_eigenval">eigenval</code></td>
<td>
<p>A vector of eigenvalues that must sum to the order of the
desired correlation matrix.  For example: if you want a correlation matrix
of order 4, then you need 4 eigenvalues that sum to 4. A warning message
will display if sum(eigenval) != length(eigenval)</p>
</td></tr>
<tr><td><code id="genCorr_+3A_seed">seed</code></td>
<td>
<p>Either a user supplied seed for the random number generator or
&lsquo;rand&rsquo; for a function generated seed. Default seed=&lsquo;rand&rsquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a correlation matrix with the eigen-stucture specified by
eigenval.
</p>


<h3>Author(s)</h3>

<p>Jeff Jones
</p>


<h3>References</h3>

<p>Jones, J. A. (2010). GenCorr: An R routine to generate
correlation matrices from a user-defined eigenvalue structure. <em>Applied
Psychological Measurement, 34</em>, 68-69.
</p>
<p>Marsaglia, G., &amp; Olkin, I. (1984). Generating correlation matrices.
<em>SIAM J. Sci. and Stat. Comput., 5</em>, 470-475.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Example
## Generate a correlation matrix with user-specified eigenvalues
set.seed(123)
R &lt;- genCorr(c(2.5, 1, 1, .3, .2))

print(round(R, 2))

#&gt;       [,1]  [,2]  [,3]  [,4]  [,5]
#&gt; [1,]  1.00  0.08 -0.07 -0.07  0.00
#&gt; [2,]  0.08  1.00  0.00 -0.60  0.53
#&gt; [3,] -0.07  0.00  1.00  0.51 -0.45
#&gt; [4,] -0.07 -0.60  0.51  1.00 -0.75
#&gt; [5,]  0.00  0.53 -0.45 -0.75  1.00

print(eigen(R)$values)

#[1] 2.5 1.0 1.0 0.3 0.2


</code></pre>

<hr>
<h2 id='GenerateBoxData'>Generate Thurstone's Box Data From length, width, and height box measurements</h2><span id='topic+GenerateBoxData'></span>

<h3>Description</h3>

<p>Generate data for Thurstone's 20 variable and 26 variable Box Study From length, width, and height box measurements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GenerateBoxData(
  XYZ,
  BoxStudy = 20,
  Reliability = 0.75,
  ModApproxErrVar = 0.1,
  SampleSize = NULL,
  NMinorFac = 50,
  epsTKL = 0.2,
  Seed = 1,
  SeedErrorFactors = 2,
  SeedMinorFactors = 3,
  PRINT = FALSE,
  LB = FALSE,
  LBVal = 1,
  Constant = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GenerateBoxData_+3A_xyz">XYZ</code></td>
<td>
<p>(Matrix) Length, width, and height measurements for N boxes.   The Amazon Box data 
can be accessed by calling <code>data(AmxBoxes)</code>. The Thurstone Box data (20 hypothetical boxes) 
can be accessed by calling <code>data(Thurstone20Boxes)</code>.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_boxstudy">BoxStudy</code></td>
<td>
<p>(Integer) If BoxStudy = 20 then data will be generated for 
Thurstone's classic 20 variable box problem. If BoxStudy = 26 then data will 
be generated for Thurstone's 26 variable box problem. Default: <code>BoxStudy = 20</code>.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_reliability">Reliability</code></td>
<td>
<p>(Scalar [0, 1] ) The common reliability value for each 
measured variable. Default: Reliability = .75.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_modapproxerrvar">ModApproxErrVar</code></td>
<td>
<p>(Scalar [0, 1] ) The proportion of reliable 
variance (for each variable) that is due to all minor common factors. 
Thus, if <code>x</code> (i.e., error free length) has variance <code>var(x)</code> and  
<code>ModApproxErrVar = .10</code>, then <code>var(e.ma)/var(x + e.ma) = .10</code>.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_samplesize">SampleSize</code></td>
<td>
<p>(Integer) Specifies the number of boxes to be sampled from 
the population.  If <code>SampleSize = NULL</code> then measurements will be 
generated for the original input box sizes.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_nminorfac">NMinorFac</code></td>
<td>
<p>(Integer) The number of minor factors to use while 
generating model approximation error. Default: <code>NMinorFac = 50.</code></p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_epstkl">epsTKL</code></td>
<td>
<p>(Numeric [0, 1])  A parameter of the 
Tucker, Koopman, and Linn (1969) algorithm that controls the spread of the influence of the minor factors.
Default: <code>epsTKL = .20.</code></p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_seed">Seed</code></td>
<td>
<p>(Integer)  Starting seed for box sampling.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_seederrorfactors">SeedErrorFactors</code></td>
<td>
<p>(Integer)  Starting seed for the error-factor scores.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_seedminorfactors">SeedMinorFactors</code></td>
<td>
<p>(Integer)  Starting seed for the minor common-factor scores.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_print">PRINT</code></td>
<td>
<p>(Logical) If PRINT = TRUE then the computed reliabilites will 
be printed. Default: <code>PRINT = FALSE</code>.  Setting <code>PRINT</code> to TRUE can be useful 
when <code>LB = TRUE</code>.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_lb">LB</code></td>
<td>
<p>(lower bound; logical)  If LB = TRUE then minimum box measurements will be 
set to LBVal (inches) if they
fall below 0 after adding measurement error. If LB = FALSE then negative 
attribute values will not be modified. This argument has no effect
on data that include model approximation error.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_lbval">LBVal</code></td>
<td>
<p>(Numeric) If <code>LB = TRUE</code> then values in <code>BoxDataE</code> will be bounded 
from below at <code>LBVal</code>.  This can be used to avoid negative or very small box 
measurements.</p>
</td></tr>
<tr><td><code id="GenerateBoxData_+3A_constant">Constant</code></td>
<td>
<p>(Numeric) Optional value to add to all box measurements. 
Default: <code>Constant = 0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used with the Amazon boxes dataset (<code>data(AmzBoxes)</code>) or with any collection  
of user-supplied scores on three variables. The Amazon Boxes data were downloaded from the 
<code>BoxDimensions</code> website: (<a href="https://www.boxdimensions.com/">https://www.boxdimensions.com/</a>). These data contain 
length (x),  width (y), and height (z) measurements for 98 Amazon shipping boxes.  In his 
classical monograph on Multiple Factor Analysis (Thurstone, 1947) Thurstone describes two data sets 
(one that he created from fictitious data and a second data set that he created from actual box measurements) 
that  were used to illustrate topics in factor analysis. The  first (fictitious) data set is 
known as the Thurstone Box problem (see Kaiser and Horst, 1975).  To create his data for the Box problem, 
Thurstone constructed 20 nonlinear combinations of fictitious length, width, and height measurements. 
<strong>Box20</strong> variables:
</p>

<ol>
<li><p>   x^2
</p>
</li>
<li><p>   y^2
</p>
</li>
<li><p>   z^2
</p>
</li>
<li><p>   xy
</p>
</li>
<li><p>   xz
</p>
</li>
<li><p>   yz
</p>
</li>
<li><p>   sqrt(x^2 + y^2)
</p>
</li>
<li><p>   sqrt(x^2 + z^2)
</p>
</li>
<li><p>   sqrt(y^2 + z^2)
</p>
</li>
<li><p>   2x + 2y
</p>
</li>
<li><p>   2x + 2z
</p>
</li>
<li><p>   2y + 2z 
</p>
</li>
<li><p>   log(x)
</p>
</li>
<li><p>   log(y)
</p>
</li>
<li><p>   log(z)
</p>
</li>
<li><p>   xyz
</p>
</li>
<li><p>   sqrt(x^2 + y^2 + z^2)
</p>
</li>
<li><p>   exp(x)
</p>
</li>
<li><p>   exp(y)
</p>
</li>
<li><p>   exp(z)
</p>
</li></ol>

<p>The second Thurstone Box problem contains measurements on the following 26 functions of length, width, and height. 
<strong>Box26</strong> variables:
</p>

<ol>
<li><p> x
</p>
</li>
<li><p> y
</p>
</li>
<li><p> z
</p>
</li>
<li><p> xy 
</p>
</li>
<li><p> xz
</p>
</li>
<li><p> yz 
</p>
</li>
<li><p> x^2 * y
</p>
</li>
<li><p> x * y^2
</p>
</li>
<li><p> x^2 * z
</p>
</li>
<li><p> x * z^ 2
</p>
</li>
<li><p> y^2 * z
</p>
</li>
<li><p> y * z^2
</p>
</li>
<li><p> x/y
</p>
</li>
<li><p> y/x
</p>
</li>
<li><p> x/z
</p>
</li>
<li><p>  z/x
</p>
</li>
<li><p>  y/z
</p>
</li>
<li><p>  z/y
</p>
</li>
<li><p> 2x + 2y
</p>
</li>
<li><p> 2x + 2z
</p>
</li>
<li><p> 2y + 2z
</p>
</li>
<li><p> sqrt(x^2 + y^2)
</p>
</li>
<li><p> sqrt(x^2 + z^2)
</p>
</li>
<li><p> sqrt(y^2 + z^2)
</p>
</li>
<li><p> xyz
</p>
</li>
<li><p> sqrt(x^2 + y^2 + z^2)
</p>
</li></ol>

<p>Note that when generating unreliable data (i.e., variables with 
reliability values less than 1) and/or data with model error, 
<strong>SampleSize</strong> must be greater than <strong>NMinorFac</strong>.
</p>


<h3>Value</h3>


<ul>
<li> <p><strong>XYZ</strong> The length (x), width (y), and height (z) measurements for the sampled boxes. 
If <code>SampleSize = NULL</code> then <code>XYZ</code> contains the x, y, z values for the 
original 98 boxes.
</p>
</li>
<li> <p><strong>BoxData</strong> Error free box measurements.  
</p>
</li>
<li> <p><strong>BoxDataE</strong> Box data with added measurement error. 
</p>
</li>
<li> <p><strong>BoxDataEME</strong>  Box data with added (reliable) model approximation and (unreliable) measurement error.
</p>
</li>
<li> <p><strong>Rel.E</strong>  Classical reliabilities for the scores in <code>BoxDataE</code>.
</p>
</li>
<li> <p><strong>Rel.EME</strong>  Classical reliabilities for the scores in <code>BoxDataEME</code>.
</p>
</li>
<li> <p><strong>NMinorFac</strong>  Number of minor common factors used to generate <code>BoxDataEME</code>.
</p>
</li>
<li> <p><strong>epsTKL</strong>  Minor factor spread parameter for the Tucker, Koopman, Linn algorithm.
</p>
</li>
<li> <p><strong>SeedErrorFactors</strong>  Starting seed for the error-factor scores.
</p>
</li>
<li> <p><strong>SeedMinorFactors</strong> Starting seed for the minor common-factor scores. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller (nwaller@umn.edu)
</p>


<h3>References</h3>

<p>Cureton, E. E. &amp; Mulaik, S. A. (1975). The weighted varimax rotation and the 
promax rotation. Psychometrika, 40(2), 183-195. 
Kaiser, H. F. and Horst, P.  (1975).  A score matrix for Thurstone's box problem.  
Multivariate Behavioral Research, 10(1), 17-26.  
</p>
<p>Thurstone, L. L.  (1947).  Multiple Factor Analysis.  Chicago: 
University of Chicago Press. 
</p>
<p>Tucker, L. R., Koopman, R. F., and Linn, R. L.  (1969).  Evaluation of factor 
analytic research procedures by means of simulated correlation matrices. 
<em>Psychometrika, 34</em>(4), 421-459.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  data(AmzBoxes)
  BoxList &lt;- GenerateBoxData (XYZ = AmzBoxes[,2:4],
                              BoxStudy = 20,  
                              Reliability = .75,
                              ModApproxErrVar = .10,
                              SampleSize = 300, 
                              NMinorFac = 50,
                              epsTKL = .20,
                              Seed = 1,
                              SeedErrorFactors = 1,
                              SeedMinorFactors = 2,
                              PRINT = FALSE,
                              LB = FALSE,
                              LBVal = 1,
                              Constant = 0)
                                
   BoxData &lt;- BoxList$BoxData
   
   RBoxes &lt;- cor(BoxData)
   fout &lt;- faMain(R = RBoxes,
                 numFactors = 3,
                 facMethod = "fals",
                 rotate = "geominQ",
                 rotateControl = list(numberStarts = 100,
                                      standardize = "CM")) 
                                      
  summary(fout)  
</code></pre>

<hr>
<h2 id='genFMPData'>Generate item response data for a filtered monotonic polynomial IRT model</h2><span id='topic+genFMPData'></span>

<h3>Description</h3>

<p>Generate item response data for the filtered polynomial IRT model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genFMPData(NSubj, bParams, theta = NULL, thetaMN = 0, thetaVar = 1, seed)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genFMPData_+3A_nsubj">NSubj</code></td>
<td>
<p>the desired number of subject response vectors.</p>
</td></tr>
<tr><td><code id="genFMPData_+3A_bparams">bParams</code></td>
<td>
<p>a p(items)-by-9 matrix of polynomial coefficients and model
designations. Columns 1 - 8 hold the polynomial coefficients; column 9 holds
the value of <code>k</code>.</p>
</td></tr>
<tr><td><code id="genFMPData_+3A_theta">theta</code></td>
<td>
<p>A user-supplied vector of latent trait scores. Default theta =
NULL.</p>
</td></tr>
<tr><td><code id="genFMPData_+3A_thetamn">thetaMN</code></td>
<td>
<p>If theta = NULL genFMPdata will simulate random normal
deviates from a population with mean thetaMN and variance thetaVar.</p>
</td></tr>
<tr><td><code id="genFMPData_+3A_thetavar">thetaVar</code></td>
<td>
<p>If theta = NULL genFMPData will simulate random normal
deviates from a population with mean thetaMN and variance thetaVar.</p>
</td></tr>
<tr><td><code id="genFMPData_+3A_seed">seed</code></td>
<td>
<p>initial seed for the random number generator.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>theta</code></td>
<td>
<p>theta values used for data generation</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>N(subject)-by-p(items) matrix of item response data.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>Value of the random number seed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# The following code illustrates data generation for 
# an FMP of order 3 (i.e., 2k+1)

# data will be generated for 2000 examinees
NSubjects &lt;- 2000


## Example item paramters, k=1 FMP 
b &lt;- matrix(c(
    #b0    b1     b2    b3      b4   b5 b6 b7  k
  1.675, 1.974, -0.068, 0.053,  0,  0,  0,  0, 1,
  1.550, 1.805, -0.230, 0.032,  0,  0,  0,  0, 1,
  1.282, 1.063, -0.103, 0.003,  0,  0,  0,  0, 1,
  0.704, 1.376, -0.107, 0.040,  0,  0,  0,  0, 1,
  1.417, 1.413,  0.021, 0.000,  0,  0,  0,  0, 1,
 -0.008, 1.349, -0.195, 0.144,  0,  0,  0,  0, 1,
  0.512, 1.538, -0.089, 0.082,  0,  0,  0,  0, 1,
  0.122, 0.601, -0.082, 0.119,  0,  0,  0,  0, 1,
  1.801, 1.211,  0.015, 0.000,  0,  0,  0,  0, 1,
 -0.207, 1.191,  0.066, 0.033,  0,  0,  0,  0, 1,
 -0.215, 1.291, -0.087, 0.029,  0,  0,  0,  0, 1,
  0.259, 0.875,  0.177, 0.072,  0,  0,  0,  0, 1,
 -0.423, 0.942,  0.064, 0.094,  0,  0,  0,  0, 1,
  0.113, 0.795,  0.124, 0.110,  0,  0,  0,  0, 1,
  1.030, 1.525,  0.200, 0.076,  0,  0,  0,  0, 1,
  0.140, 1.209,  0.082, 0.148,  0,  0,  0,  0, 1,
  0.429, 1.480, -0.008, 0.061,  0,  0,  0,  0, 1,
  0.089, 0.785, -0.065, 0.018,  0,  0,  0,  0, 1,
 -0.516, 1.013,  0.016, 0.023,  0,  0,  0,  0, 1,
  0.143, 1.315, -0.011, 0.136,  0,  0,  0,  0, 1,
  0.347, 0.733, -0.121, 0.041,  0,  0,  0,  0, 1,
 -0.074, 0.869,  0.013, 0.026,  0,  0,  0,  0, 1,
  0.630, 1.484, -0.001, 0.000,  0,  0,  0,  0, 1), 
  nrow=23, ncol=9, byrow=TRUE)  

# generate data using the above item paramters
data&lt;-genFMPData(NSubj = NSubjects, bParams=b, seed=345)$data

</code></pre>

<hr>
<h2 id='genPhi'>Create a random Phi matrix with maximum factor correlation</h2><span id='topic+genPhi'></span>

<h3>Description</h3>

<p>Create a random Phi matrix with maximum factor correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genPhi(NFac, EigenValPower = 6, MaxAbsPhi = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genPhi_+3A_nfac">NFac</code></td>
<td>
<p>Number of factors.</p>
</td></tr>
<tr><td><code id="genPhi_+3A_eigenvalpower">EigenValPower</code></td>
<td>
<p>(Scalar &gt; 1) A scalar than controls the positive
skewness of the distribution of eigenvalues of Phi.</p>
</td></tr>
<tr><td><code id="genPhi_+3A_maxabsphi">MaxAbsPhi</code></td>
<td>
<p>(Scaler in [0,1]) The maximum off diagonal of Phi (the
factor correlation matrix).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A factor correlation matrix. Note that the returned matrix is not guaranteed 
to be positive definite. However, a PD check is performed in simFA so that simFA always 
produces a PD Phi matrix.
</p>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
NFac &lt;- 5
par(mfrow=c(2,2))
  for(i in 1:4){
     R &lt;- genPhi(NFac, 
               EigenValPower = 6, 
               MaxAbsPhi = 0.5)
               
    L &lt;- eigen(R)$values
    plot(1:NFac, L, 
        type="b",
        ylab = "Eigenvalues of Phi",
        xlab = "Dimensions",
        ylim=c(0,L[1]+.5))
  }

</code></pre>

<hr>
<h2 id='get_wb_mod'>Find an 'lm' model to use with the Wu &amp; Browne (2015) model error method</h2><span id='topic+get_wb_mod'></span>

<h3>Description</h3>

<p>The Wu &amp; Browne (2015) model error method takes advantage of the relationship
between v and RMSEA:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_wb_mod(mod, n = 50, values = 10, lower = 0.01, upper = 0.095)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_wb_mod_+3A_mod">mod</code></td>
<td>
<p>A 'fungible::simFA()' model object.</p>
</td></tr>
<tr><td><code id="get_wb_mod_+3A_n">n</code></td>
<td>
<p>The number of times to evaluate 'wb()' at each point.</p>
</td></tr>
<tr><td><code id="get_wb_mod_+3A_values">values</code></td>
<td>
<p>The number of target RMSEA values to evaluate between 0.02 and
0.1.</p>
</td></tr>
<tr><td><code id="get_wb_mod_+3A_lower">lower</code></td>
<td>
<p>(scalar) The smallest target RMSEA value to use.</p>
</td></tr>
<tr><td><code id="get_wb_mod_+3A_upper">upper</code></td>
<td>
<p>(scalar) The largest target RMSEA value to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">v = RMSEA^2 + o(RMSEA^2).</code>
</p>

<p>As RMSEA increases, the approximation <code class="reqn">v ~= RMSEA^2</code> becomes worse. This
function generates population correlation matrices with model error for
multiple target RMSEA values and then regresses the target RMSEA values on
the median observed RMSEA values for each target. The fitted model can then
be used to predict a 'target_rmsea' value that will give solutions with RMSEA
values that are close to the desired value.
</p>


<h3>Value</h3>

<p>('lm' object) An 'lm' object to use with the <code><a href="#topic+wb">wb</a></code>
function to obtain population correlation matrices with model error that
have RMSEA values closer to the target RMSEA values. The 'lm' object will
predict a 'target_rmsea' value that will give solutions with (median) RMSEA
values close to the desired RMSEA value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod &lt;- fungible::simFA(Seed = 42)
set.seed(42)
wb_mod &lt;- get_wb_mod(mod)
noisemaker(mod, method = "WB", target_rmsea = 0.05, wb_mod = wb_mod)
</code></pre>

<hr>
<h2 id='HS9Var'>9 Variables from the Holzinger and Swineford (1939) Dataset</h2><span id='topic+HS9Var'></span>

<h3>Description</h3>

<p>Mental abilities data on seventh- and eighth-grade children from the classic
Holzinger and Swineford (1939) dataset.
</p>


<h3>Format</h3>

<p>A data frame with 301 observations on the following 15 variables.
</p>
 <dl>
<dt>id</dt><dd><p>subject identifier</p>
</dd> <dt>sex</dt><dd><p>gender</p>
</dd>
<dt>ageyr</dt><dd><p>age, year part</p>
</dd> <dt>agemo</dt><dd><p>age, month part</p>
</dd>
<dt>school</dt><dd><p>school name (Pasteur or Grant-White)</p>
</dd> <dt>grade</dt><dd><p>grade</p>
</dd>
<dt>x1</dt><dd><p>Visual perception</p>
</dd> <dt>x2</dt><dd><p>Cubes</p>
</dd> <dt>x3</dt><dd><p>Lozenges</p>
</dd>
<dt>x4</dt><dd><p>Paragraph comprehension</p>
</dd> <dt>x5</dt><dd><p>Sentence completion</p>
</dd>
<dt>x6</dt><dd><p>Word meaning</p>
</dd> <dt>x7</dt><dd><p>Speeded addition</p>
</dd> <dt>x8</dt><dd><p>Speeded
counting of dots</p>
</dd> <dt>x9</dt><dd><p>Speeded discrimination straight and curved
capitals</p>
</dd> </dl>



<h3>Source</h3>

<p>These data were retrieved from the lavaan package. The complete data
for all 26 tests are available in the MBESS package.
</p>


<h3>References</h3>

<p>Holzinger, K., and Swineford, F. (1939). A study in factor
analysis: The stability of a bifactor solution. Supplementary Educational
Monograph, no. 48. Chicago: University of Chicago Press.
</p>
<p>Joreskog, K. G. (1969). A general approach to confirmatory maximum
likelihood factor analysis. <em>Psychometrika, 34</em>, 183-202.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(HS9Var)
head(HS9Var)

</code></pre>

<hr>
<h2 id='HW'>Six data sets that  yield a Heywood case</h2><span id='topic+HW'></span>

<h3>Description</h3>

<p>Six data sets that  yield a Heywood case in a 3-factor model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HW)
</code></pre>


<h3>Format</h3>

<p>Each data set is a  matrix with 150 rows and 12 variables:
</p>
<p> Each data set (HW1, HW2, ... HW6) represents a hypothetical sample
of 150 subjects from a population 3-factor model.  
The population factor loadings are given in <code>HW$popLoadings</code>.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HW)

# Compute a principal axis factor analysis 
# on the first data set  
RHW &lt;- cor(HW$HW1)  
fapaOut &lt;- faMain(R = RHW, 
                 numFactors = 3, 
                 facMethod = "fapa", 
                 rotate = "oblimin",
                 faControl = list(treatHeywood = FALSE))


fapaOut$faFit$Heywood
round(fapaOut$h2, 2)


</code></pre>

<hr>
<h2 id='irf'>Plot item response functions for polynomial IRT models.</h2><span id='topic+irf'></span>

<h3>Description</h3>

<p>Plot model-implied (and possibly empirical) item response function for
polynomial IRT models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irf(
  data,
  bParams,
  item,
  plotERF = TRUE,
  thetaEAP = NULL,
  minCut = -3,
  maxCut = 3,
  NCuts = 9
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="irf_+3A_data">data</code></td>
<td>
<p>N(subjects)-by-p(items) matrix of 0/1 item response data.</p>
</td></tr>
<tr><td><code id="irf_+3A_bparams">bParams</code></td>
<td>
<p>p(items)-by-9 matrix.  The first 8 columns of the matrix
should contain the FMP or FUP polynomial coefficients for the p items.  The
9th column contains the value of k for each item (where the item specific
order of the polynomial is 2k+1).</p>
</td></tr>
<tr><td><code id="irf_+3A_item">item</code></td>
<td>
<p>The IRF for <code>item</code> will be plotted.</p>
</td></tr>
<tr><td><code id="irf_+3A_ploterf">plotERF</code></td>
<td>
<p>A logical that determines whether to plot discrete values of
the empirical response function.</p>
</td></tr>
<tr><td><code id="irf_+3A_thetaeap">thetaEAP</code></td>
<td>
<p>If <code>plotERF=TRUE</code>, the user must supply previously
calculated eap trait estimates to <code>thetaEAP</code>.</p>
</td></tr>
<tr><td><code id="irf_+3A_mincut">minCut</code>, <code id="irf_+3A_maxcut">maxCut</code></td>
<td>
<p>If <code>plotERF=TRUE</code>, the program will (attempt to)
plot <code>NCuts</code> points of the empirical response function between trait
values of <code>minCut</code> and <code>maxCut</code> Default minCut = -3. Default
maxCut = 3.</p>
</td></tr>
<tr><td><code id="irf_+3A_ncuts">NCuts</code></td>
<td>
<p>Desired number of bins for the empirical response function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
NSubjects &lt;- 2000
NItems &lt;- 15

itmParameters &lt;- matrix(c(
 #  b0    b1     b2    b3    b4  b5,    b6,  b7,  k
 -1.05, 1.63,  0.00, 0.00, 0.00,  0,     0,  0,   0, #1
 -1.97, 1.75,  0.00, 0.00, 0.00,  0,     0,  0,   0, #2
 -1.77, 1.82,  0.00, 0.00, 0.00,  0,     0,  0,   0, #3
 -4.76, 2.67,  0.00, 0.00, 0.00,  0,     0,  0,   0, #4
 -2.15, 1.93,  0.00, 0.00, 0.00,  0,     0,  0,   0, #5
 -1.25, 1.17, -0.25, 0.12, 0.00,  0,     0,  0,   1, #6
  1.65, 0.01,  0.02, 0.03, 0.00,  0,     0,  0,   1, #7
 -2.99, 1.64,  0.17, 0.03, 0.00,  0,     0,  0,   1, #8
 -3.22, 2.40, -0.12, 0.10, 0.00,  0,     0,  0,   1, #9
 -0.75, 1.09, -0.39, 0.31, 0.00,  0,     0,  0,   1, #10
 -1.21, 9.07,  1.20,-0.01,-0.01,  0.01,  0,  0,   2, #11
 -1.92, 1.55, -0.17, 0.50,-0.01,  0.01,  0,  0,   2, #12
 -1.76, 1.29, -0.13, 1.60,-0.01,  0.01,  0,  0,   2, #13
 -2.32, 1.40,  0.55, 0.05,-0.01,  0.01,  0,  0,   2, #14
 -1.24, 2.48, -0.65, 0.60,-0.01,  0.01,  0,  0,   2),#15
 15, 9, byrow=TRUE)
 
  
ex1.data&lt;-genFMPData(NSubj = NSubjects, bParams = itmParameters, 
                     seed = 345)$data

## compute initial theta surrogates
thetaInit &lt;- svdNorm(ex1.data)

## For convenience we assume that the item parameter
## estimates equal their population values.  In practice,
## item parameters would be estimated at this step. 
itmEstimates &lt;- itmParameters

## calculate eap estimates for mixed models
thetaEAP &lt;- eap(data = ex1.data, bParams = itmEstimates, NQuad = 21, 
                priorVar = 2, 
                mintheta = -4, maxtheta = 4)

## plot irf and erf for item 1
irf(data = ex1.data, bParams = itmEstimates, 
    item = 1, 
    plotERF = TRUE, 
    thetaEAP)

## plot irf and erf for item 12
irf(data = ex1.data, bParams = itmEstimates, 
    item = 12, 
    plotERF = TRUE, 
    thetaEAP)  


</code></pre>

<hr>
<h2 id='itemDescriptives'>Compute basic descriptives for binary-item analysis</h2><span id='topic+itemDescriptives'></span>

<h3>Description</h3>

<p>Compute basic descriptives for binary item analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itemDescriptives(X, digits = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itemDescriptives_+3A_x">X</code></td>
<td>
<p>a matrix of binary (0/1) item responses.</p>
</td></tr>
<tr><td><code id="itemDescriptives_+3A_digits">digits</code></td>
<td>
<p>number of digits to print.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>alpha</code></td>
<td>
<p>Coefficient alpha for the total scale.</p>
</td></tr>
<tr><td><code>means</code></td>
<td>
<p>item means.</p>
</td></tr> <tr><td><code>standard deviations</code></td>
<td>
<p>item standard
deviations.</p>
</td></tr> <tr><td><code>pt. biserial correlations</code></td>
<td>
<p>corrected item-total point
biserial correlations.</p>
</td></tr> <tr><td><code>biserial correlations</code></td>
<td>
<p>corrected item-total
point biserial correlations.</p>
</td></tr> <tr><td><code>corrected.alpha</code></td>
<td>
<p>corrected (leave item
out) alpha coefficients.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
	## Example 1: generating binary data to match
	## an existing binary data matrix
	##
	## Generate correlated scores using factor 
	## analysis model
	## X &lt;- Z *L' + U*D 
	## Z is a vector of factor scores
	## L is a factor loading matrix
	## U is a matrix of unique factor scores
	## D is a scaling matrix for U

	Nsubj &lt;- 2000
	L &lt;- matrix( rep(.707,5), nrow = 5, ncol = 1)
	Z &lt;-as.matrix(rnorm(Nsubj))
	U &lt;-matrix(rnorm(Nsubj * 5),nrow = Nsubj, ncol = 5)
	tmp &lt;-  sqrt(1 - L^2) 
	D&lt;-matrix(0, 5, 5)
	diag(D) &lt;- tmp
	X &lt;- Z %*% t(L) + U%*%D

	cat("\nCorrelation of continuous scores\n")
	print(round(cor(X),3))

	thresholds &lt;- c(.2,.3,.4,.5,.6)

	Binary&lt;-matrix(0,Nsubj,5)
	for(i in 1:5){
	  Binary[X[,i]&lt;=thresholds[i],i]&lt;-1
	}   

	cat("\nCorrelation of Binary scores\n")
	print(round(cor(Binary),3))

	## Now use 'bigen' to generate binary data matrix with 
	## same correlations as in Binary

	z &lt;- bigen(data = Binary, n = 5000)

	cat("\n\nnames in returned object\n")
	print(names(z))

	cat("\nCorrelation of Simulated binary scores\n")
	print(round( cor(z$data), 3))


	cat("Observed thresholds of simulated data:\n")
	cat( apply(z$data, 2, mean) )
	
	itemDescriptives(z$data)

</code></pre>

<hr>
<h2 id='Jackson67'>Multi-Trait Multi-Method correlation matrix reported by Jackson and Singer (1967)</h2><span id='topic+Jackson67'></span>

<h3>Description</h3>

<p>The original study assessed four personality traits (i.e., femininity, 
anxiety, somatic complaints, and socially-deviant attitudes) from five 
judgemental perspectives (i.e., ratings about (a) desirability in self, 
(b) desirability in others, (c) what others find desirable, (d) frequency,
and (e) harmfulness). The harmfulness variable was reverse coded. 
</p>
<p>The sample size is <em>n</em> = 480.
</p>
<p>The following four variables were assessed (abbreviations in parentheses):
<strong>Variables</strong>:
</p>

<ol>
<li><p> Femininity (Fem)
</p>
</li>
<li><p> Anxiety (Anx)
</p>
</li>
<li><p> Somatic Complaints (SomatComplaint)
</p>
</li>
<li><p> Socially-Deviant Attitudes (SDAttitude)
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>data(Jackson67)
</code></pre>


<h3>Format</h3>

<p>A 20 by 20 correlation matrix with dimension names
</p>


<h3>Details</h3>

<p>The above variables were assessed from the following methodological judgement
perspectives (abbreviations in parentheses): 
<strong>Test Structure</strong>:
</p>

<ul>
<li><p> Desirability in the Self (DiS)
</p>
</li>
<li><p> Desirability in Others (DiO)
</p>
</li>
<li><p> What Others Find Desirable (WOFD)
</p>
</li>
<li><p> Frequency (Freq)
</p>
</li>
<li><p> Harmfulness (Harm)
</p>
</li></ul>



<h3>Source</h3>

<p>Jackson, D. N., &amp; Singer, J. E. (1967). Judgments, items, and 
personality. <em>Journal of Experimental Research in Personality, 2</em>(1), 70-79.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load Jackson and Singer's dataset
data(Jackson67)



Example2Output &lt;-  faMB(R             = Jackson67, 
                        n             = 480,
                        NB            = 5, 
                        NVB           = rep(4,5), 
                        numFactors    = 4,
                        rotate        = "varimax",
                        rotateControl = list(standardize = "Kaiser"),
                        PrintLevel    = 1)
                        
summary(Example2Output)                         
</code></pre>

<hr>
<h2 id='kurt'>Calculate Univariate Kurtosis for a Vector or Matrix</h2><span id='topic+kurt'></span>

<h3>Description</h3>

<p>Calculate univariate kurtosis for a vector or matrix (algorithm G2 in Joanes
&amp; Gill, 1998). Note that, as defined in this function, the expected kurtosis of 
a normally distributed variable is 0 (i.e., not 3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kurt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kurt_+3A_x">x</code></td>
<td>
<p>Either a vector or matrix of numeric values.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Kurtosis for each column in x.</code></td>
<td>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Joanes, D. N. &amp; Gill, C. A. (1998). Comparing measures of sample
skewness and kurtosis. <em>The Statistician, 47</em>, 183-189.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+skew">skew</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(rnorm(1000), 100, 10)
print(kurt(x))

</code></pre>

<hr>
<h2 id='Ledermann'>Ledermann's inequality for factor solution identification</h2><span id='topic+Ledermann'></span>

<h3>Description</h3>

<p>Ledermann's (1937) inequality to determine either (a) how many factor 
indicators are needed to uniquely estimate a user-specified number 
of factors or (b) how many factors can be uniquely estimated from 
a user-specified number of factor indicators. See the <strong>Details</strong> 
section for more information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ledermann(numFactors = NULL, numVariables = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ledermann_+3A_numfactors">numFactors</code></td>
<td>
<p>(Numeric) Determine the number of variables needed
to uniquely estimate the [user-specifed] number of factors. Defaults 
to <code>numFactors = NULL</code>.</p>
</td></tr>
<tr><td><code id="Ledermann_+3A_numvariables">numVariables</code></td>
<td>
<p>(Numeric) Determine the number of factors that can be
uniquely estimated from the [user-specifed] number of variables Defaults 
to <code>numVariables = NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user will specified either (a) <code>numFactors</code> or (b) 
<code>numVariables</code>. When one value is specified, the obtained estimate 
for the other may be a non-whole number. If estimating the number of 
required variables, the obtained estimate is rounded up 
(using <code><a href="base.html#topic+ceiling">ceiling</a></code>). If estimating the number of factors,
the obtained estimate is rounded down (using <code><a href="base.html#topic+floor">floor</a></code>). For example,
if <code>numFactors = 2</code>, roughly 4.56 variables are required for an identified
solution. However, the function returns an estimate of 5.
</p>
<p>For the relevant equations, see Thurstone (1947, p. 293) Equations 10 
and 11.
</p>


<h3>Value</h3>


<ul>
<li> <p><b>numFactors</b> (Numeric) Given the inputs, the number of factors 
to be estimated from the <code>numVariables</code> number of factor indicators. 
</p>
</li>
<li> <p><b>numVariables</b> (Numeric) Given the inputs, the number of 
variables needed to estimate <code>numFactorso</code>. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Casey Giordano
</p>


<h3>References</h3>

<p>Ledermann, W. (1937). On the rank of the reduced correlational 
matrix in multiple-factor analysis. <em>Psychometrika, 2</em>(2), 85-93.
</p>
<p>Thurstone, L. L. (1947). Multiple-factor analysis; a development and expansion of The Vectors of Mind.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## To estimate 3 factors, how many variables are needed?
Ledermann(numFactors   = 3,
          numVariables = NULL) 
          
## Provided 10 variables are collected, how many factors 
  ## can be estimated?
Ledermann(numFactors   = NULL,
          numVariables = 10)

</code></pre>

<hr>
<h2 id='Malmi79'>Multi-Trait Multi-Method correlation matrix reported by Malmi, Underwood, and Carroll (1979).</h2><span id='topic+Malmi79'></span>

<h3>Description</h3>

<p>The original study assessed six variables across three separate 
assessment methods. Note that only the last method included six variables whereas 
the other two methods included three variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Malmi79)
</code></pre>


<h3>Format</h3>

<p>A 12 by 12 correlation matrix with dimension names
</p>


<h3>Details</h3>

<p>The sample size is <em>n</em> = 97.
</p>
<p>The following variables were assessed (abbreviations in parentheses):
<strong>Variables</strong>:
</p>

<ol>
<li><p> Words (Words)
</p>
</li>
<li><p> Triads (Triads)
</p>
</li>
<li><p> Sentences (Sentences)
</p>
</li>
<li><p> 12 stimuli with 2 responses each (12s.2r)
</p>
</li>
<li><p> 4 stimuli with 6 responses each (4s.6r)
</p>
</li>
<li><p> 2 stimuli with 12 responses each (2s.12r)
</p>
</li></ol>

<p>The above variables were assessed from the following three assessment methods 
(abbreviations in parentheses): 
<strong>Test Structure</strong>:
</p>

<ul>
<li> <p><strong>Free Recall</strong> (FR)
</p>

<ul>
<li><p> Words
</p>
</li>
<li><p> Triads
</p>
</li>
<li><p> Sentences
</p>
</li></ul>

</li>
<li> <p><strong>Serial List</strong> (SL)
</p>

<ul>
<li><p> Words
</p>
</li>
<li><p> Triads
</p>
</li>
<li><p> Sentences
</p>
</li></ul>

</li>
<li> <p><strong>Paired Association</strong> (PA)
</p>

<ul>
<li><p> Words
</p>
</li>
<li><p> Triads
</p>
</li>
<li><p> Sentences
</p>
</li>
<li><p> 12 stimuli with 4 responses
</p>
</li>
<li><p> 4 stimuli with 6 responses
</p>
</li>
<li><p> 2 stimuli with 12 responses
</p>
</li></ul>

</li></ul>



<h3>Source</h3>

<p>Malmi, R. A., Underwood, 3. J. &amp; Carroll, J. B. The interrelationships among
some associative learning tasks. <em>Bulletin of the Psychrmomic Society, 13</em>(3), 121-123.
https://doi.org/10.3758/BF03335032
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load Malmi et al.'s dataset
data(Malmi79)

Example3Output &lt;- faMB(R             = Malmi79, 
                       n             = 97,
                       NB            = 3, 
                       NVB           = c(3, 3, 6), 
                       numFactors    = 2,
                       rotate        = "oblimin",
                       rotateControl = list(standardize = "Kaiser"))
                       
summary(Example3Output)                        
</code></pre>

<hr>
<h2 id='monte'>Simulate Clustered Data with User-Defined Properties</h2><span id='topic+monte'></span>

<h3>Description</h3>

<p>Function for simulating clustered data with user defined characteristics
such as: within cluster indicator correlations, within cluster indicator
skewness values, within cluster indicator kurtosis values, and cluster
separations as indexed by each variable (indicator validities).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>monte(
  seed = 123,
  nvar = 4,
  nclus = 3,
  clus.size = c(50, 50, 50),
  eta2 = c(0.619, 0.401, 0.941, 0.929),
  cor.list = NULL,
  random.cor = FALSE,
  skew.list = NULL,
  kurt.list = NULL,
  secor = NULL,
  compactness = NULL,
  sortMeans = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="monte_+3A_seed">seed</code></td>
<td>
<p>Required: An integer to be used as the random number seed.</p>
</td></tr>
<tr><td><code id="monte_+3A_nvar">nvar</code></td>
<td>
<p>Required: Number of variables to simulate.</p>
</td></tr>
<tr><td><code id="monte_+3A_nclus">nclus</code></td>
<td>
<p>Required: Number of clusters to simulate. <em>Note</em> that
number of clusters must be equal to or greater than 2.</p>
</td></tr>
<tr><td><code id="monte_+3A_clus.size">clus.size</code></td>
<td>
<p>Required: Number of objects in each cluster.</p>
</td></tr>
<tr><td><code id="monte_+3A_eta2">eta2</code></td>
<td>
<p>Required: A vector of indicator validities that range from 0 to
1. Higher numbers produce clusters with greater separation on that
indicator.</p>
</td></tr>
<tr><td><code id="monte_+3A_cor.list">cor.list</code></td>
<td>
<p>Optional: A list of correlation matrices. There should be
one correlation matrix for each cluster.  The first correlation matrix will
represent the indicator correlations within cluster 1.  The second
correlation matrix will represent the indicator correlations for cluster 2.
Etc.</p>
</td></tr>
<tr><td><code id="monte_+3A_random.cor">random.cor</code></td>
<td>
<p>Optional: Set to TRUE to generate a common within cluster
correlation matrix.</p>
</td></tr>
<tr><td><code id="monte_+3A_skew.list">skew.list</code></td>
<td>
<p>Optional: A list of within cluster indicator skewness
values.</p>
</td></tr>
<tr><td><code id="monte_+3A_kurt.list">kurt.list</code></td>
<td>
<p>Optional: A list of within cluster indicator kurtosis
values.</p>
</td></tr>
<tr><td><code id="monte_+3A_secor">secor</code></td>
<td>
<p>Optional: If 'random.cor = TRUE' then 'secor' determines the
standard error of the simulated within group correlation matrices.</p>
</td></tr>
<tr><td><code id="monte_+3A_compactness">compactness</code></td>
<td>
<p>Optional: A vector of cluster compactness parameters. The
meaning of this option is explained Waller et al. (1999). Basically,
'compactness' allows users some control over cluster overlap without
changing indicator validities. See the example below for an illustration.</p>
</td></tr>
<tr><td><code id="monte_+3A_sortmeans">sortMeans</code></td>
<td>
<p>Optional: A logical that determines whether the latent
means will be sorted by taxon. Default = TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>data</code></td>
<td>
<p>The simulated data. The 1st column of 'data' denotes
cluster membership.</p>
</td></tr> <tr><td><code>lmn</code></td>
<td>
<p>The cluster indicator means.</p>
</td></tr> <tr><td><code>fl</code></td>
<td>
<p>The
factor loading matrix as described in Waller, et al. 1999.</p>
</td></tr> <tr><td><code>fs</code></td>
<td>
<p>The
unique values of the linearized factor scores.</p>
</td></tr> <tr><td><code>call</code></td>
<td>
<p>The call.</p>
</td></tr>
<tr><td><code>nclus</code></td>
<td>
<p>Number of clusters.</p>
</td></tr> <tr><td><code>nvar</code></td>
<td>
<p>Number of variables.</p>
</td></tr>
<tr><td><code>cor.list</code></td>
<td>
<p>The input within cluster correlation matrices.</p>
</td></tr>
<tr><td><code>skew.list</code></td>
<td>
<p>The input within cluster indicator skewness values.</p>
</td></tr>
<tr><td><code>kurt.list</code></td>
<td>
<p>The input within cluster indicator kurtosis values.</p>
</td></tr>
<tr><td><code>clus.size</code></td>
<td>
<p>The number of observations in each cluster.</p>
</td></tr>
<tr><td><code>eta2</code></td>
<td>
<p>Vector of indicator validities.</p>
</td></tr> <tr><td><code>seed</code></td>
<td>
<p>The random number
seed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Fleishman, A. I (1978). A method for simulating non-normal
distributions. <em>Psychometrika, 43</em>, 521-532.
</p>
<p>Olvera Astivia, O. L. &amp; Zumbo, B. D. (2018). On the solution 
multiplicity of the Fleishman method and its impact in 
simulation studies. <em>British Journal of Mathematical and Statistical Psychology, 71</em>
(3), 437-458. 
</p>
<p>Vale, D. C., &amp; Maurelli, V. A. (1983). Simulating multivariate nonnormal
distributions. <em>Psychometrika, 48</em>, 465-471.
</p>
<p>Waller, N. G., Underhill, J. M., &amp; Kaiser, H. A. (1999).  A method for
generating simulated plasmodes and artificial test clusters with
user-defined shape, size, and orientation. <em>Multivariate Behavioral
Research, 34</em>, 123-142.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example 1
## Simulating Fisher's Iris data
# The original data were reported in: 
# Fisher, R. A. (1936) The use of multiple measurements in taxonomic
#     problems. Annals of Eugenics, 7, Part II, 179-188.
#
# This example includes 3 clusters. Each cluster represents
# an Iris species: Setosa, Versicolor, and Virginica.
# On each species, four variables were measured: Sepal Length, 
# Sepal Width, Petal Length, and Petal Width.
#
# The within species (cluster) correlations of the flower
# indicators are as follows:
#
# Iris Type 1: 
#      [,1]  [,2]  [,3]  [,4]
# [1,] 1.000 0.743 0.267 0.178
# [2,] 0.743 1.000 0.278 0.233
# [3,] 0.267 0.278 1.000 0.332
# [4,] 0.178 0.233 0.332 1.000
#
# Iris Type 2
#      [,1]  [,2]  [,3]  [,4]
# [1,] 1.000 0.526 0.754 0.546
# [2,] 0.526 1.000 0.561 0.664
# [3,] 0.754 0.561 1.000 0.787
# [4,] 0.546 0.664 0.787 1.000
#
# Iris Type 3
#      [,1]  [,2]  [,3]  [,4]
# [1,] 1.000 0.457 0.864 0.281
# [2,] 0.457 1.000 0.401 0.538
# [3,] 0.864 0.401 1.000 0.322
# [4,] 0.281 0.538 0.322 1.000
#
# 'monte' expects a list of correlation matrices
# 

#create a list of within species correlations
data(iris)
cormat &lt;- cm &lt;- lapply(split(iris[,1:4], iris[,5]), cor)
 
# create a list of within species indicator 
# skewness and kurtosis
 sk.lst &lt;- list(c(0.120,  0.041,  0.106,  1.254),                     
                c(0.105, -0.363, -0.607, -0.031),
                c(0.118,  0.366,  0.549, -0.129) )
              
              
 kt.lst &lt;- list(c(-0.253, 0.955,  1.022,  1.719),
                c(-0.533,-0.366,  0.048, -0.410),
                c( 0.033, 0.706, -0.154, -0.602) )    


#Generate a new sample of iris data
my.iris &lt;- monte(seed=123, nvar = 4, nclus = 3, cor.list = cormat, 
                clus.size = c(50, 50, 50),
                eta2=c(0.619, 0.401, 0.941, 0.929), 
                random.cor = FALSE,
                skew.list = sk.lst, 
                kurt.list = kt.lst, 
                secor = .3, compactness=c(1, 1, 1),
                sortMeans = TRUE)


summary(my.iris)
plot(my.iris)

# Now generate a new data set with the sample indicator validities 
# as before but with different cluster compactness values.

my.iris2&lt;-monte(seed = 123, nvar = 4, nclus = 3, 
               cor.list = cormat, clus.size = c(50, 50, 50),
               eta2 = c(0.619, 0.401, 0.941, 0.929), random.cor = FALSE,
               skew.list = sk.lst ,kurt.list = kt.lst, 
               secor = .3,
               compactness=c(2, .5, .5), 
               sortMeans = TRUE)


summary(my.iris2)

# Notice that cluster 1 has been blow up whereas clusters 2 and 3 have been shrunk.
plot(my.iris2)


### Now compare your original results with the actual 
## Fisher iris data
library(lattice)
data(iris)
super.sym &lt;- trellis.par.get("superpose.symbol")
splom(~iris[1:4], groups = Species, data = iris,
      #panel = panel.superpose,
      key = list(title = "Three Varieties of Iris",
                 columns = 3, 
                 points = list(pch = super.sym$pch[1:3],
                 col = super.sym$col[1:3]),
                 text = list(c("Setosa", "Versicolor", "Virginica"))))


############### EXAMPLE 2 ##################################

## Example 2
## Simulating data for Taxometric
## Monte Carlo Studies.
##
## In this four part example we will 
## generate two group mixtures 
## (Complement and Taxon groups)
## under four conditions.
##
## In all conditions 
## base rate (BR) = .20
## 3 indicators
## indicator validities = .50 
## (This means that 50 percent of the total
## variance is due to the mixture.)
##
##
## Condition 1:
## All variables have a slight degree
## of skewness (.10) and kurtosis (.10).
## Within group correlations = 0.00.
##
##
##
## Condition 2:
## In this conditon we generate data in which the 
## complement and taxon distributions differ in shape.
## In the complement group all indicators have 
## skewness values of 1.75 and kurtosis values of 3.75.
## In the taxon group all indicators have skewness values
## of .50 and kurtosis values of 0.
## As in the previous condition, all within group
## correlations (nuisance covariance) are 0.00.
##
##
## Conditon 3:
## In this condition we retain all previous 
## characteristics except that the within group
## indicator correlations now equal .80
## (they can differ between groups).
##
##
## Conditon 4:
## In this final condition we retain
## all previous data characteristics except that 
## the variances of the indicators in the complement 
## class are now 5 times the indicator variances
## in the taxon class (while maintaining indicator skewness, 
## kurtosis, correlations, etc.).
 

##----------------------------


library(lattice)


############################
##      Condition 1  
############################
in.nvar &lt;- 3  ##Number of variables
in.nclus &lt;-2  ##Number of taxa
in.seed &lt;- 123                
BR &lt;- .20     ## Base rate of higher taxon

## Within taxon indicator skew and kurtosis
in.skew.list &lt;- list(c(.1, .1, .1),c(.1, .1, .1)) 
in.kurt.list &lt;- list(c(.1, .1, .1),c(.1, .1, .1))          

## Indicator validities
in.eta2 &lt;- c(.50, .50, .50)

## Groups sizes for Population
BigN &lt;- 100000
in.clus.size &lt;- c(BigN*(1-BR), BR * BigN) 
 
## Generate Population of scores with "monte"
sample.data &lt;- monte(seed = in.seed, 
                nvar=in.nvar, 
                nclus = in.nclus, 
                clus.size = in.clus.size, 
                eta2 = in.eta2, 
                skew.list = in.skew.list, 
                kurt.list = in.kurt.list)
               
          
output &lt;- summary(sample.data)

z &lt;- data.frame(sample.data$data[sample(1:BigN, 600, replace=FALSE),])
z[,2:4] &lt;- scale(z[,2:4])
names(z) &lt;- c("id","v1","v2","v3")

#trellis.device()
trellis.par.set( col.whitebg() )
print(
 cloud(v3 ~ v1 * v2,
       groups = as.factor(id),data=z, 
       subpanel = panel.superpose,
       zlim=c(-4, 4),
       xlim=c(-4, 4),
       ylim=c(-4, 4),
       main="",
       screen = list(z = 20, x = -70)),
   position=c(.1, .5, .5, 1), more = TRUE)
               
                 

############################
##      Condition 2  
############################

## Within taxon indicator skew and kurtosis
in.skew.list &lt;- list(c(1.75, 1.75, 1.75),c(.50, .50, .50)) 
in.kurt.list &lt;- list(c(3.75, 3.75, 3.75),c(0, 0, 0))          

## Generate Population of scores with "monte"
sample.data &lt;- monte(seed = in.seed, 
               nvar = in.nvar, 
               nclus = in.nclus, 
               clus.size = in.clus.size, 
               eta2 = in.eta2, 
               skew.list = in.skew.list, 
               kurt.list = in.kurt.list)
               
          
output &lt;- summary(sample.data)

z &lt;- data.frame(sample.data$data[sample(1:BigN, 600, replace=FALSE),])
z[,2:4] &lt;- scale(z[, 2:4])
names(z) &lt;-c("id", "v1","v2", "v3")

print(
 cloud(v3 ~ v1 * v2,
       groups = as.factor(id), data = z, 
       subpanel = panel.superpose,
       zlim = c(-4, 4),
       xlim = c(-4, 4),
       ylim = c(-4, 4),
       main="",
       screen = list(z = 20, x = -70)),
       position = c(.5, .5, 1, 1), more = TRUE)
               
                 
############################
##      Condition 3  
############################ 

## Set within group correlations to .80
cormat &lt;- matrix(.80, 3, 3)
diag(cormat) &lt;- rep(1, 3)
in.cor.list &lt;- list(cormat, cormat)

## Generate Population of scores with "monte"
sample.data &lt;- monte(seed = in.seed, 
               nvar = in.nvar, 
               nclus = in.nclus, 
               clus.size = in.clus.size, 
               eta2 = in.eta2, 
               skew.list = in.skew.list, 
               kurt.list = in.kurt.list,
               cor.list = in.cor.list)
               
output &lt;- summary(sample.data)

z &lt;- data.frame(sample.data$data[sample(1:BigN, 600, 
                replace = FALSE), ])
z[,2:4] &lt;- scale(z[, 2:4])
names(z) &lt;- c("id", "v1", "v2", "v3")

##trellis.device()
##trellis.par.set( col.whitebg() )
print(
  cloud(v3 ~ v1 * v2,
       groups = as.factor(id),data=z, 
       subpanel = panel.superpose,
       zlim = c(-4, 4),
       xlim = c(-4, 4),
       ylim = c(-4, 4),
       main="",
       screen = list(z = 20, x = -70)),
position = c(.1, .0, .5, .5), more = TRUE)
                                

############################
##      Condition 4  
############################

## Change compactness so that variance of
## complement indicators is 5 times
## greater than variance of taxon indicators
                     
 v &lt;-  ( 2 * sqrt(5))/(1 + sqrt(5)) 
 in.compactness &lt;- c(v, 2-v)   
 
## Generate Population of scores with "monte"
sample.data &lt;- monte(seed = in.seed, 
               nvar = in.nvar, 
               nclus = in.nclus, 
               clus.size = in.clus.size, 
               eta2 = in.eta2, 
               skew.list = in.skew.list, 
               kurt.list = in.kurt.list,
               cor.list = in.cor.list,
               compactness = in.compactness)
               
output &lt;- summary(sample.data)

z &lt;- data.frame(sample.data$data[sample(1:BigN, 600, replace = FALSE), ])
z[, 2:4] &lt;- scale(z[, 2:4])
names(z) &lt;- c("id", "v1", "v2", "v3")
print(
  cloud(v3 ~ v1 * v2,
       groups = as.factor(id),data=z, 
       subpanel = panel.superpose,
       zlim = c(-4, 4),
       xlim = c(-4, 4),
       ylim = c(-4, 4),
       main="",
       screen = list(z = 20, x = -70)),
 position = c(.5, .0, 1, .5), more = TRUE)

</code></pre>

<hr>
<h2 id='monte1'>Simulate Multivariate Non-normal Data by Vale &amp; Maurelli (1983) Method</h2><span id='topic+monte1'></span>

<h3>Description</h3>

<p>Function for simulating multivariate nonnormal data by the methods described
by Fleishman (1978) and Vale &amp; Maurelli (1983).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>monte1(seed, nvar, nsub, cormat, skewvec, kurtvec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="monte1_+3A_seed">seed</code></td>
<td>
<p>An integer to be used as the random number seed.</p>
</td></tr>
<tr><td><code id="monte1_+3A_nvar">nvar</code></td>
<td>
<p>Number of variables to simulate.</p>
</td></tr>
<tr><td><code id="monte1_+3A_nsub">nsub</code></td>
<td>
<p>Number of simulated subjects (response vectors).</p>
</td></tr>
<tr><td><code id="monte1_+3A_cormat">cormat</code></td>
<td>
<p>The desired correlation matrix.</p>
</td></tr>
<tr><td><code id="monte1_+3A_skewvec">skewvec</code></td>
<td>
<p>A vector of indicator skewness values.</p>
</td></tr>
<tr><td><code id="monte1_+3A_kurtvec">kurtvec</code></td>
<td>
<p>A vector of indicator kurtosis values.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>data</code></td>
<td>
<p>The simulated data.</p>
</td></tr> <tr><td><code>call</code></td>
<td>
<p>The call.</p>
</td></tr>
<tr><td><code>nsub</code></td>
<td>
<p>Number of subjects.</p>
</td></tr> <tr><td><code>nvar</code></td>
<td>
<p>Number of variables.</p>
</td></tr>
<tr><td><code>cormat</code></td>
<td>
<p>The desired correlation matrix.</p>
</td></tr> <tr><td><code>skewvec</code></td>
<td>
<p>The desired
indicator skewness values.</p>
</td></tr> <tr><td><code>kurtvec</code></td>
<td>
<p>The desired indicator kurtosis
values.</p>
</td></tr> <tr><td><code>seed</code></td>
<td>
<p>The random number seed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Fleishman, A. I (1978). A method for simulating non-normal
distributions. <em>Psychometrika, 43</em>, 521-532.
</p>
<p>Olvera Astivia, O. L. &amp; Zumbo, B. D. (2018). On the solution 
multiplicity of the Fleishman method and its impact in 
simulation studies. <em>British Journal of Mathematical and Statistical Psychology, 71</em>
(3), 437-458. 
</p>
<p>Vale, D. C., &amp; Maurelli, V. A. (1983). Simulating multivariate nonnormal
distributions. <em>Psychometrika, 48</em>, 465-471.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+monte">monte</a></code>, <code><a href="#topic+summary.monte">summary.monte</a></code>,
<code><a href="#topic+summary.monte1">summary.monte1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Generate dimensional data for 4 variables. 
## All correlations = .60; all variable
## skewness = 1.75; 
## all variable kurtosis = 3.75
 
cormat &lt;- matrix(.60,4,4)
diag(cormat) &lt;- 1

nontaxon.dat &lt;- monte1(seed = 123, nsub = 100000, nvar = 4, skewvec = rep(1.75, 4),
               kurtvec = rep(3.75, 4), cormat = cormat)
 
print(cor(nontaxon.dat$data), digits = 3)
print(apply(nontaxon.dat$data, 2, skew), digits = 3)
print(apply(nontaxon.dat$data, 2, kurt), digits = 3)               

</code></pre>

<hr>
<h2 id='noisemaker'>Simulate a population correlation matrix with model error</h2><span id='topic+noisemaker'></span>

<h3>Description</h3>

<p>This tool lets the user generate a population correlation matrix with model
error using one of three methods: (1) the Tucker, Koopman, and Linn (TKL;
1969) method, (2) the Cudeck and Browne (CB; 1992) method, or (3) the Wu and
Browne (WB; 2015) method. If the CB or WB methods are used, the user can
specify the desired RMSEA value. If the TKL method is used, an optimization
procedure finds a solution that produces RMSEA and/or CFI values that are
close to the user-specified values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>noisemaker(
  mod,
  method = c("TKL", "CB", "WB"),
  target_rmsea = 0.05,
  target_cfi = NULL,
  tkl_ctrl = list(),
  wb_mod = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="noisemaker_+3A_mod">mod</code></td>
<td>
<p>A <code><a href="#topic+simFA">simFA</a></code> model object.</p>
</td></tr>
<tr><td><code id="noisemaker_+3A_method">method</code></td>
<td>
<p>(character) Model error method to use (&quot;TKL&quot;, &quot;CB&quot;, or &quot;WB&quot;).</p>
</td></tr>
<tr><td><code id="noisemaker_+3A_target_rmsea">target_rmsea</code></td>
<td>
<p>(scalar) Target RMSEA value.</p>
</td></tr>
<tr><td><code id="noisemaker_+3A_target_cfi">target_cfi</code></td>
<td>
<p>(scalar) Target CFI value.</p>
</td></tr>
<tr><td><code id="noisemaker_+3A_tkl_ctrl">tkl_ctrl</code></td>
<td>
<p>(list) A control list containing the following TKL-specific
arguments. See the <code><a href="#topic+tkl">tkl</a></code> help file for more details.</p>
</td></tr>
<tr><td><code id="noisemaker_+3A_wb_mod">wb_mod</code></td>
<td>
<p>('lm' object) An optional <code><a href="stats.html#topic+lm">lm</a></code> object used
to find a target RMSEA value that results in solutions with RMSEA values
close to the desired value. Note that if no 'wb_mod' is provided, a model
will be estimated at run time. If many population correlation matrices are
going to be simulated using the same model, it will be considerably faster
to estimate 'wb_mod' ahead of time. See also <code><a href="#topic+get_wb_mod">get_wb_mod</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing <code class="reqn">\Sigma</code>, RMSEA and CFI values, and the TKL
parameters (if applicable).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod &lt;- fungible::simFA(Seed = 42)

set.seed(42)
# Simulate a population correlation matrix using the TKL method with target
# RMSEA and CFI values specified.
noisemaker(mod, method = "TKL",
           target_rmsea = 0.05,
           target_cfi = 0.95,
           tkl_ctrl = list(optim_type = "optim"))

# Simulate a population correlation matrix using the CB method with target
# RMSEA value specified.
noisemaker(mod, method = "CB",
           target_rmsea = 0.05)

# Simulation a population correlation matrix using the WB method with target
# RMSEA value specified.
noisemaker(mod,
           method = "WB",
           target_rmsea = 0.05)
</code></pre>

<hr>
<h2 id='normalCor'>Compute Normal-Theory Covariances for Correlations</h2><span id='topic+normalCor'></span>

<h3>Description</h3>

<p>Compute normal-theory covariances for correlations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalCor(R, Nobs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalCor_+3A_r">R</code></td>
<td>
<p>a p x p matrix of correlations.</p>
</td></tr>
<tr><td><code id="normalCor_+3A_nobs">Nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A normal-theory covariance matrix of correlations.
</p>


<h3>Author(s)</h3>

<p>Jeff Jones and Niels Waller
</p>


<h3>References</h3>

<p>Nel, D.G. (1985). A matrix derivation of the asymptotic
covariance matrix of sample correlation coefficients. <em>Linear algebra
and its applications, 67</em>, 137&ndash;145.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adfCor">adfCor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
	data(Harman23.cor)
	normalCor(Harman23.cor$cov, Nobs = 305)

</code></pre>

<hr>
<h2 id='normF'>Compute the Frobenius norm of a matrix</h2><span id='topic+normF'></span>

<h3>Description</h3>

<p>A function to compute the Frobenius norm of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normF(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normF_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Frobenius norm of X.
</p>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRLG)
out &lt;- smoothLG(R = BadRLG, Penalty = 50000)
cat("\nGradient at solution:", out$gr,"\n")
cat("\nNearest Correlation Matrix\n")
print( round(out$RLG,8) )
cat("\nFrobenius norm of (NPD - PSD) matrix\n")
print(normF(BadRLG - out$RLG ))

</code></pre>

<hr>
<h2 id='obj_func'>Objective function for optimizing RMSEA and CFI</h2><span id='topic+obj_func'></span>

<h3>Description</h3>

<p>This is the objective function that is minimized by the <code><a href="#topic+tkl">tkl</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obj_func(
  par = c(v, eps),
  Rpop,
  W,
  p,
  u,
  df,
  target_rmsea,
  target_cfi,
  weights = c(1, 1),
  WmaxLoading = NULL,
  NWmaxLoading = 2,
  penalty = 0,
  return_values = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="obj_func_+3A_par">par</code></td>
<td>
<p>(vector) Values of model error variance (<code class="reqn">\nu_{\textrm{e}}</code>) and
epsilon (<code class="reqn">\epsilon</code>).</p>
</td></tr>
<tr><td><code id="obj_func_+3A_rpop">Rpop</code></td>
<td>
<p>(matrix) The model-implied correlation matrix.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_w">W</code></td>
<td>
<p>(matrix) Matrix of provisional minor common factor loadings with
unit column variances.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_p">p</code></td>
<td>
<p>(scalar) Number of variables.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_u">u</code></td>
<td>
<p>(vector) Major common factor variances.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_df">df</code></td>
<td>
<p>(scalar) Model degrees of freedom.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_target_rmsea">target_rmsea</code></td>
<td>
<p>(scalar) Target RMSEA value.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_target_cfi">target_cfi</code></td>
<td>
<p>(scalar) Target CFI value.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_weights">weights</code></td>
<td>
<p>(vector) Vector of length two indicating how much weight to
give RMSEA and CFI, e.g., 'c(1,1)' (default) gives equal weight to both
indices; 'c(1,0)' ignores the CFI value.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_wmaxloading">WmaxLoading</code></td>
<td>
<p>(scalar) Threshold value for 'NWmaxLoading'.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_nwmaxloading">NWmaxLoading</code></td>
<td>
<p>(scalar) Maximum number of absolute loadings <code class="reqn">\ge</code>
'WmaxLoading' in any column of 'W'.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_penalty">penalty</code></td>
<td>
<p>(scalar) Large (positive) penalty value to apply if the
NWmaxLoading condition is violated.</p>
</td></tr>
<tr><td><code id="obj_func_+3A_return_values">return_values</code></td>
<td>
<p>(boolean) If 'TRUE', return the objective function value
along with 'Rpop', 'RpopME', 'W', 'RMSEA', 'CFI', 'v', and 'eps' values. If
'FALSE', return only the objective function value.</p>
</td></tr>
</table>

<hr>
<h2 id='Omega'>Compute Omega hierarchical</h2><span id='topic+Omega'></span>

<h3>Description</h3>

<p>This function computes McDonald's Omega hierarchical to determine the proportions of variance (for a given test) associated with the latent factors and with the general factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Omega(lambda, genFac = 1, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Omega_+3A_lambda">lambda</code></td>
<td>
<p>(Matrix) A factor pattern matrix to be analyzed.</p>
</td></tr>
<tr><td><code id="Omega_+3A_genfac">genFac</code></td>
<td>
<p>(Scalar, Vector) Which column(s) contains the general factor(s). The default value is the first column.</p>
</td></tr>
<tr><td><code id="Omega_+3A_digits">digits</code></td>
<td>
<p>(Scalar) The number of digits to round all output to.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Omega Hierarchical</strong>: For a reader-friendly description (with some examples), see the Rodriguez et al., (2016) <em>Psychological Methods</em> article. Most of the relevant equations and descriptions are found on page 141.
</p>
</li></ul>



<h3>Value</h3>


<ul>
<li> <p><strong>omegaTotal</strong>: (Scalar) The total reliability of the latent, common factors for the given test.
</p>
</li>
<li> <p><strong>omegaGeneral</strong>: (Scalar) The proportion of total variance that is accounted for by the general factor(s).
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>McDonald, R. P. (1999). <em>Test theory: A unified approach</em>. Mahwah, NJ:Erlbaum.
</p>
<p>Rodriguez, A., Reise, S. P., &amp; Haviland, M. G. (2016). Evaluating bifactor models: Calculating and interpreting statistical indices. <em>Psychological Methods, 21</em>(2), 137.
</p>
<p>Zinbarg, R.E., Revelle, W., Yovel, I., &amp; Li. W. (2005). Cronbach's Alpha, Revelle's Beta, McDonald's Omega: Their relations with each and two alternative conceptualizations of reliability. <em>Psychometrika. </em>70, 123-133. https://personality-project.org/revelle/publications/zinbarg.revelle.pmet.05.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create a bifactor structure
bifactor &lt;- matrix(c(.21, .49, .00, .00,
                     .12, .28, .00, .00,
                     .17, .38, .00, .00,
                     .23, .00, .34, .00,
                     .34, .00, .52, .00,
                     .22, .00, .34, .00,
                     .41, .00, .00, .42,
                     .46, .00, .00, .47,
                     .48, .00, .00, .49),
                   nrow = 9, ncol = 4, byrow = TRUE)

## Compute Omega
Out1 &lt;- Omega(lambda = bifactor)

</code></pre>

<hr>
<h2 id='orderFactors'>Order factor-loadings matrix by the sum of squared factor loadings</h2><span id='topic+orderFactors'></span>

<h3>Description</h3>

<p>Order the columns of a factor loadings matrix in descending order based on 
the sum of squared factor loadings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orderFactors(Lambda, PhiMat, salient = 0.29, reflect = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orderFactors_+3A_lambda">Lambda</code></td>
<td>
<p>(Matrix) Factor loadings matrix to be reordered.</p>
</td></tr>
<tr><td><code id="orderFactors_+3A_phimat">PhiMat</code></td>
<td>
<p>(Matrix, NULL) Factor correlation matrix to be reordered.</p>
</td></tr>
<tr><td><code id="orderFactors_+3A_salient">salient</code></td>
<td>
<p>(Numeric) Indicators with loadings &lt; <code>salient</code> will be 
suppressed when computing the factor sum of squares values. Defaults to 
salient = .29.</p>
</td></tr>
<tr><td><code id="orderFactors_+3A_reflect">reflect</code></td>
<td>
<p>(Logical) If true, negatively-keyed factors will be reflected.
Defaults to reflect = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the sorted factor loading and factor correlation matrices. 
</p>

<ul>
<li> <p><strong>Lambda</strong>: (Matrix) The sorted factor loadings matrix.
</p>
</li>
<li> <p><strong>Phi</strong>: (Matrix) The sorted factor correlation matrix.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Loadings &lt;- 
  matrix(c(.49, .41, .00, .00,
           .73, .45, .00, .00,
           .47, .53, .00, .00,
           .54, .00, .66, .00,
           .60, .00, .38, .00,
           .55, .00, .66, .00,
           .39, .00, .00, .68,
           .71, .00, .00, .56,
           .63, .00, .00, .55), 
         nrow = 9, ncol = 4, byrow = TRUE)
         
fungible::orderFactors(Lambda = Loadings,
                        PhiMat = NULL)$Lambda

## End(Not run)

</code></pre>

<hr>
<h2 id='plot.monte'>Plot Method for Class Monte</h2><span id='topic+plot.monte'></span>

<h3>Description</h3>

<p>plot method for class &quot;monte&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'monte'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.monte_+3A_x">x</code></td>
<td>
<p>An object of class 'monte', usually, a result of a call to
<code>monte</code>.</p>
</td></tr>
<tr><td><code id="plot.monte_+3A_...">...</code></td>
<td>
<p>Optional arguments passed to plotting function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>plot.monte</code> creates a scatter plot of matrices
plot (a splom plot).  Cluster membership is denoted by different colors in
the plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#plot(monte.object)

</code></pre>

<hr>
<h2 id='print.faMain'>Print  Method for an Object of Class faMain</h2><span id='topic+print.faMain'></span>

<h3>Description</h3>

<p>Print  Method for an Object of Class faMain
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'faMain'
print(x, ..., digits = 2, Set = 1, itemSort = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.faMain_+3A_x">x</code></td>
<td>
<p>(Object of class <strong>faMain</strong>) The returned object 
from a call to <strong>faMain</strong>.</p>
</td></tr>
<tr><td><code id="print.faMain_+3A_...">...</code></td>
<td>
<p>Additional arguments affecting the summary produced.</p>
</td></tr>
<tr><td><code id="print.faMain_+3A_digits">digits</code></td>
<td>
<p>(Integer) Print output with user-specified number of significant digits. Default <code>digits = 2</code>.</p>
</td></tr>
<tr><td><code id="print.faMain_+3A_set">Set</code></td>
<td>

<ul>
<li><p>integer (Integer) Summarize the solution from the specified solution set. 
</p>
</li>
<li><p>'UnSpun' (Character) Summarize the solution from the rotated output that was 
produced by rotating from the unrotated (i.e., unspun) factor orientation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="print.faMain_+3A_itemsort">itemSort</code></td>
<td>
<p>(Logical) If TRUE, sort the order of the observed variables to produce
a &quot;staircase&quot;-like pattern. In bifactor models (i.e., bifactorT and bifactorQ) item 
sorting is determined by  the magnitudes of the group factor loadings.
Defaults to <code>itemSort</code> = FALSE.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>

<hr>
<h2 id='print.faMB'>Print  Method for an Object of Class faMB</h2><span id='topic+print.faMB'></span>

<h3>Description</h3>

<p>Print  Method for an Object of Class faMB
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'faMB'
print(x, ..., digits = 2, Set = 1, itemSort = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.faMB_+3A_x">x</code></td>
<td>
<p>(Object of class <strong>faMB</strong>) The returned object 
from a call to <strong>faMB</strong>.</p>
</td></tr>
<tr><td><code id="print.faMB_+3A_...">...</code></td>
<td>
<p>Additional arguments affecting the summary produced.</p>
</td></tr>
<tr><td><code id="print.faMB_+3A_digits">digits</code></td>
<td>
<p>(Integer) Print output with user-specified number of significant digits. Default <code>digits = 2</code>.</p>
</td></tr>
<tr><td><code id="print.faMB_+3A_set">Set</code></td>
<td>

<ul>
<li><p>integer (Integer) Summarize the solution from the specified solution set. 
</p>
</li>
<li><p>'UnSpun' (Character) Summarize the solution from the rotated output that was 
produced by rotating from the unrotated (i.e., unspun) factor orientation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="print.faMB_+3A_itemsort">itemSort</code></td>
<td>
<p>(Logical) If TRUE, sort the order of the observed variables to produce
a &quot;staircase&quot;-like pattern.  Defaults to <code>itemSort</code> = FALSE.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>

<hr>
<h2 id='promaxQ'>Conduct an Oblique Promax Rotation</h2><span id='topic+promaxQ'></span>

<h3>Description</h3>

<p>This function is an extension of the <code><a href="stats.html#topic+promax">promax</a></code> function. 
This function will extract the unrotated factor loadings (with three algorithm 
options, see <code><a href="#topic+faX">faX</a></code>) if they are not provided. The factor 
intercorrelations (Phi) are also computed within this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>promaxQ(
  R = NULL,
  urLoadings = NULL,
  facMethod = "fals",
  numFactors = NULL,
  power = 4,
  standardize = "Kaiser",
  epsilon = 1e-04,
  maxItr = 15000,
  faControl = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="promaxQ_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix.</p>
</td></tr>
<tr><td><code id="promaxQ_+3A_urloadings">urLoadings</code></td>
<td>
<p>(Matrix) An unrotated factor-structure matrix to be rotated.</p>
</td></tr>
<tr><td><code id="promaxQ_+3A_facmethod">facMethod</code></td>
<td>
<p>(Character) The method used for factor extraction 
(<code><a href="#topic+faX">faX</a></code>). The supported options are &quot;fals&quot; for unweighted least 
squares, &quot;faml&quot; for maximum likelihood, &quot;fapa&quot; for iterated principal axis 
factoring, &quot;faregLS&quot; for regularized least squares,
&quot;faregML&quot; for regularized maximum likelihood, and &quot;pca&quot; for principal components 
analysis. The default method  is &quot;fals&quot;. 
</p>

<ul>
<li> <p><strong>&quot;fals&quot;</strong>: Factors are extracted using the unweighted least 
squares estimation procedure using the <code><a href="#topic+fals">fals</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faml&quot;</strong>: Factors are extracted using the maximum likelihood 
estimation procedure using the <code><a href="stats.html#topic+factanal">factanal</a></code> function.
</p>
</li>
<li> <p><strong>&quot;fapa&quot;</strong>: Factors are extracted using the iterated principal 
axis factoring estimation procedure using the <code><a href="#topic+fapa">fapa</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faregLS&quot;</strong>: Factors are extracted using regularized 
least squares factor analysis using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;faregML&quot;</strong>: Factors are extracted using regularized 
maximum likelihood factor using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;pca&quot;</strong>: Principal components are extracted. 
</p>
</li></ul>
</td></tr>
<tr><td><code id="promaxQ_+3A_numfactors">numFactors</code></td>
<td>
<p>(Scalar) The number of factors to extract if the lambda 
matrix is not provided.</p>
</td></tr>
<tr><td><code id="promaxQ_+3A_power">power</code></td>
<td>
<p>(Scalar) The power with which to raise factor loadings for 
minimizing trivial loadings. The default value is 4.</p>
</td></tr>
<tr><td><code id="promaxQ_+3A_standardize">standardize</code></td>
<td>
<p>(Character) Which standardization routine is applied to the 
unrotated factor structure. The three options are &quot;none&quot;, &quot;Kaiser&quot;, and &quot;CM&quot;. 
The default option is &quot;Kaiser&quot; as is recommended by Kaiser and others. See 
<code><a href="#topic+faStandardize">faStandardize</a></code> for more details. 
</p>

<ul>
<li> <p><strong>&quot;none&quot;</strong>: Do <em>not</em> rotate the normalized factor structure 
matrix.
</p>
</li>
<li> <p><strong>&quot;Kaiser&quot;</strong>: Use a factor structure matrix that has been normed 
by Kaiser's method (i.e., normalize all rows to have a unit length).
</p>
</li>
<li> <p><strong>&quot;CM&quot;</strong>: Use a factor structure matrix that has been normed by 
the Cureton-Mulaik method.
</p>
</li></ul>
</td></tr>
<tr><td><code id="promaxQ_+3A_epsilon">epsilon</code></td>
<td>
<p>(Scalar) The convergence criterion used for evaluating the 
varimax rotation. The default value is 1e-4 (i.e., .0001).</p>
</td></tr>
<tr><td><code id="promaxQ_+3A_maxitr">maxItr</code></td>
<td>
<p>(Scalar) The maximum number of iterations allowed for computing 
the varimax rotation. The default value is 15,000 iterations.</p>
</td></tr>
<tr><td><code id="promaxQ_+3A_facontrol">faControl</code></td>
<td>
<p>(List) A list of optional parameters passed to the factor 
extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>

<ul>
<li> <p><strong>treatHeywood</strong>: (Logical) In <code>fals</code>, if treatHeywood is 
true, a penalized least squares function is used to bound the communality 
estimates below 1.0. Defaults to treatHeywood = TRUE.
</p>
</li>
<li> <p><strong>nStart</strong>: (Numeric) The number of starting values to be tried 
in <code>faml</code>. Defaults to nStart = 10.
</p>
</li>
<li> <p><strong>start</strong>: (Matrix) NULL or a matrix of starting values, each column 
giving an initial set of uniquenesses. Defaults to start = NULL. 
</p>
</li>
<li> <p><strong>maxCommunality</strong>: (Numeric) In <code>faml</code>, set the maximum 
communality value for the estimated solution. Defaults to maxCommunality = .995.
</p>
</li>
<li> <p><strong>epsilon</strong>: (Numeric) In <code>fapa</code>, the numeric threshold 
designating when the algorithm has converged. Defaults to epsilon = 1e-4.
</p>
</li>
<li> <p><strong>communality</strong>: (Character) The method used to estimate the 
initial communality values in <code>fapa</code>. Defaults to communality = 'SMC'.
</p>

<ul>
<li> <p><strong>&quot;SMC&quot;</strong>: Initial communalities are estimated by taking the 
squared multiple correlations of each indicator after regressing the 
indicator on the remaining variables.
</p>
</li>
<li> <p><strong>&quot;maxr&quot;</strong>: Initial communalities equal the largest 
(absolute value) correlation in each column of the correlation matrix.
</p>
</li>
<li> <p><strong>&quot;unity&quot;</strong>: Initial communalities equal 1.0 for all variables.
</p>
</li></ul>

</li>
<li> <p><strong>maxItr</strong>: (Numeric) In <code>fapa</code>, the maximum number of 
iterations to reach convergence. Defaults to maxItr = 15,000.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Varimax Standardization</strong>: When conducting the varimax 
rotation, it is recommended to standardize the factor loadings using 
Kaiser's normalization (i.e., rescaling the factor indicators [rows] so 
that the vectors have unit length). The standardization/normalization 
occurs by pre-multiplying the unrotated factor structure, <strong>A</strong>, by 
the inverse of <strong>H</strong>, where <strong>H</strong>^2 is a diagonal matrix with the 
communality estimates on the diagonal. A varimax rotation is then applied 
to the normalized, unrotated factor structure. Then, the varimax-rotated 
factor structure is rescaled to its original metric by pre-multiplying the 
varimax factor structure by <strong>H</strong>. For details, see Mulaik (2009).
</p>
</li>
<li> <p><strong>Oblique Procrustes Rotation of the Varimax Solution</strong>: 
According to Hendrickson &amp; White (1964), an unrestricted (i.e., oblique) 
Procrustes rotation is applied to the orthogonal varimax solution. 
Specifically, a target matrix is generated by raising the varimax factor 
loadings to the user-specified power (typically, power = 4) (must retain 
the signs of the original factor loadings). This should quickly diminish 
trivial factor loadings while retaining larger factor loadings. The 
Procrustes rotation takes the varimax solution and rotates it toward the 
promax-generated target matrix. For a modern description of this approach, 
see Mulaik (2009, ch. 12, p. 342-343).
</p>
</li>
<li> <p><strong>Choice of a Power</strong>: Changing the power in which varimax factor 
loadings are raised will change the target matrix in the oblique Procrustes 
rotation. After raising factor loadings to some power, there will be a 
larger discrepancy between high and low loadings than before (e.g., squaring 
factor loadings of .6 and .7 yields loadings of .36 and .49 and cubing 
yields loadings of .216 and .343). Furthermore, increasing the power will 
increase the number of near-zero loadings, resulting in larger factor 
intercorrelations. Many (cf. Gorsuch, 1983; Hendrickson &amp; White, 1964; 
Mulaik, 2009) advocate for raising varimax loadings to the fourth power 
(the default) but some (e.g., Gorsuch) advocate for trying power = 2 and 
power = 6 to see if there is an improvement in the simple structure without 
overly inflating factor correlations.
</p>
</li></ul>



<h3>Value</h3>

<p>A list of the following elements are produced:
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) The oblique, promax-rotated, 
factor-pattern matrix.
</p>
</li>
<li> <p><strong>vmaxLoadings</strong>: (Matrix) The orthogonal, varimax-rotated, 
factor-structure matrix used as the input matrix for the promax rotation.
</p>
</li>
<li> <p><strong>rotMatrix</strong>: (Matrix) The (rescaled) transformation matrix 
used in an attempt to minimize the Euclidean distance between the varimax 
loadings and the generated promax target matrix (cf. Hendrickson &amp; White, 
1964; Mulaik, 2009, p. 342-343, eqn. 12.44).
</p>
</li>
<li> <p><strong>Phi</strong>: (Matrix) The factor correlation matrix associated with 
the promax solution. Phi is found by taking the inverse of the inner 
product of the (rescaled) rotation matrix (rotMatrix) with itself (i.e., 
<code class="reqn">solve(T' T)</code>, where T is the (rescaled) rotation matrix).
</p>
</li>
<li> <p><strong>vmaxDiscrepancy</strong>: (Scalar) The value of the minimized varimax 
discrepancy function. promax does not have a rotational criterion but the 
varimax rotation does.
</p>
</li>
<li> <p><strong>convergence</strong>: (Logical) Whether the varimax rotation
congerged.
</p>
</li>
<li> <p><strong>Table</strong>: (Matrix) The table returned from <code><a href="GPArotation.html#topic+GPForth">GPForth</a></code> 
from the <code>GPArotation</code> package.
</p>
</li>
<li> <p><strong>rotateControl</strong>: (List) A list containing (a) the power 
parameter used, (b) whether the varimax rotation used Kaiser normalization, 
(c) the varimax epsilon convergence criterion, and (d) the maximum number 
of iterations specified.
</p>

<ul>
<li> <p><strong>power</strong>: The power in which the varimax-rotated factor 
loadings are raised.
</p>
</li>
<li> <p><strong>standardize</strong>: Which standardization routine was used.
</p>
</li>
<li> <p><strong>epsilon</strong>: The convergence criterion set for the varimax rotation.
</p>
</li>
<li> <p><strong>maxItr</strong>: The maximum number of iterations allowed for 
reaching convergence in the varimax rotation.
</p>
</li></ul>

</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Gorsuch, R. L. (1983). <em>Factor Analysis</em>, 2nd. Hillsdale, 
NJ: LEA.
</p>
<p>Hendrickson, A. E., &amp; White, P. O. (1964). Promax: A quick 
method for rotation to oblique simple structure. <em>British Journal of 
Statistical Psychology, 17</em>(1), 65-70.
</p>
<p>Mulaik, S. A. (2009). <em>Foundations of Factor Analysis</em>. 
Chapman and Hall/CRC.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate an orthgonal factor model
lambda &lt;- matrix(c(.41, .00, .00,
                   .45, .00, .00,
                   .53, .00, .00,
                   .00, .66, .00,
                   .00, .38, .00,
                   .00, .66, .00,
                   .00, .00, .68,
                   .00, .00, .56,
                   .00, .00, .55),
                 nrow = 9, ncol = 3, byrow = TRUE)

## Model-implied correlation (covariance) matrix
R &lt;- lambda %*% t(lambda)

## Unit diagonal elements
diag(R) &lt;- 1

## Start from just a correlation matrix
Out1 &lt;- promaxQ(R           = R,
                facMethod   = "fals",
                numFactors  = 3,
                power       = 4,
                standardize = "Kaiser")$loadings

## Iterate the promaxQ rotation using the rotate function
Out2 &lt;- faMain(R             = R,
               facMethod     = "fals",
               numFactors    = 3,
               rotate        = "promaxQ",
               rotateControl = list(power       = 4,
                                    standardize = "Kaiser"))$loadings

## Align the factors to have the same orientation
Out1 &lt;- faAlign(F1 = Out2,
                F2 = Out1)$F2

## Show the equivalence of factor solutions from promaxQ and rotate
all.equal(Out1, Out2, check.attributes = FALSE)

</code></pre>

<hr>
<h2 id='r2d'>Convert Radians to Degrees</h2><span id='topic+r2d'></span>

<h3>Description</h3>

<p>Convert radian measure to degrees.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r2d(radian)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r2d_+3A_radian">radian</code></td>
<td>
<p>Radian measure of an angle.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Degree measure of an angle.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 r2d(.5*pi)

</code></pre>

<hr>
<h2 id='rarc'>Rotate Points on the Surface on an N-Dimensional Ellipsoid</h2><span id='topic+rarc'></span>

<h3>Description</h3>

<p>Rotate between two points on the surface on an n-dimensional ellipsoid. The
hyper-ellipsoid is composed of all points, B, such that B' Rxx B = Rsq.
Vector B contains standardized regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rarc(Rxx, Rsq, b1, b2, Npoints)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rarc_+3A_rxx">Rxx</code></td>
<td>
<p>Predictor correlation matrix.</p>
</td></tr>
<tr><td><code id="rarc_+3A_rsq">Rsq</code></td>
<td>
<p>Model coefficient of determination.</p>
</td></tr>
<tr><td><code id="rarc_+3A_b1">b1</code></td>
<td>
<p>First point on ellipsoid. If b1 and b2 are scalars then choose
scaled eigenvectors v[b1] and v[b2] as the start and end vectors.</p>
</td></tr>
<tr><td><code id="rarc_+3A_b2">b2</code></td>
<td>
<p>Second point on ellipsoid. If b1 and b2 are scalars then choose
scaled eigenvectors v[b1] and v[b2] as the start and end vectors.</p>
</td></tr>
<tr><td><code id="rarc_+3A_npoints">Npoints</code></td>
<td>
<p>Generate &ldquo;Npoints&rdquo; +1 OLS coefficient vectors between b1
and b2.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>b</code></td>
<td>
<p>N+1 sets of OLS coefficient vectors between b1 and b2.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller and Jeff Jones.
</p>


<h3>References</h3>

<p>Waller, N. G. &amp; Jones, J. A. (2011). Investigating the
performance of alternate regression weights by studying all possible
criteria in regression models with a fixed set of predictors.
<em>Psychometrika, 76</em>, 410-439.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Example
## GRE/GPA Data
##-------------------##
R &lt;- Rxx &lt;- matrix(c(1.00, .56, .77,
                      .56, 1.00, .73,
                      .77, .73, 1.00), 3, 3)
                  
## GPA validity correlations                 
rxy &lt;- c(.39, .34, .38)
b &lt;- solve(Rxx) %*% rxy
 
Rsq &lt;- t(b) %*% Rxx %*% b
N &lt;- 200       
                   
b &lt;- rarc(Rxx = R, Rsq, b1 = 1, b2 = 3, Npoints = N) 
 
## compute validity vectors
r &lt;- Rxx %*% b
N &lt;- N + 1
Rsq.r &lt;- Rsq.unit &lt;- rep(0, N)

for(i in 1:N){
## eval performance of unit weights
  Rsq.unit[i] &lt;- (t(sign(r[,i])) %*% r[,i])^2 /
 		           (t(sign(r[,i])) %*% R %*% sign(r[,i]))
 		           
## eval performance of correlation weights               
  Rsq.r[i] &lt;- (t(r[,i]) %*% r[,i])^2 /(t(r[,i]) %*% R %*% r[,i])	
}
 
cat("\nAverage relative performance of unit weights across elliptical arc:",
 	    round(mean(Rsq.unit)/Rsq,3) )     
cat("\n\nAverage relative performance of r weights across elliptical arc:",
 	    round(mean(Rsq.r)/Rsq,3) ) 
 

plot(seq(0, 90, length = N), Rsq.r, typ = "l", 
          ylim = c(0, .20),
          xlim = c(0, 95),
          lwd = 3,
          ylab = expression(R^2),
          xlab = expression(paste("Degrees from ",b[1]," in the direction of ",b[2])),
          cex.lab = 1.25, lab = c(10, 5, 5))
 points(seq(0, 90, length = N), Rsq.unit, 
          type = "l", 
          lty = 2, lwd = 3)
 legend(x = 0,y = .12,
        legend = c("r weights", "unit weights"), 
        lty = c(1, 2),
        lwd = c(4, 3),
        cex = 1.5)               

</code></pre>

<hr>
<h2 id='Ravgr'>Generate a random R matrix with an average rij</h2><span id='topic+Ravgr'></span>

<h3>Description</h3>

<p>Ravgr(Rseed, NVar = NULL, u = NULL, rdist = &quot;U&quot;, alpha = 4, beta = 2, SEED = NULL)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ravgr(
  Rseed,
  NVar = NULL,
  u = NULL,
  rdist = "U",
  alpha = 4,
  beta = 2,
  SEED = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ravgr_+3A_rseed">Rseed</code></td>
<td>
<p>(matrix or scalar) This argument can take one of two alternative inputs. 
The first input is an <code class="reqn">n \times n</code> <strong>R</strong> matrix with a known, 
average rij.  The second type of input is a scalar <code class="reqn">\bar{r}_{ij}</code>.</p>
</td></tr>
<tr><td><code id="Ravgr_+3A_nvar">NVar</code></td>
<td>
<p>(integer)  If <code>Rseed</code> is a scalar then the user must specify
<code>NVar</code>, the number of variables in the desired <strong>R</strong> matrix. Default(<code>NVar = NULL</code>).</p>
</td></tr>
<tr><td><code id="Ravgr_+3A_u">u</code></td>
<td>
<p>(scalar). A scalar <code class="reqn">\in [0,1]</code>. Higher values of u will produce
<strong>R</strong> matrices with more variable off-diagonal elements.</p>
</td></tr>
<tr><td><code id="Ravgr_+3A_rdist">rdist</code></td>
<td>
<p>(character). A character that controls the variance of the off 
diagonal elements of the generated <strong>R</strong>. If <code>u = NULL</code> and <code>rdist="U"</code> then the <strong>R</strong> 
matrices are uniformly  sampled from the space of all <code class="reqn">n\times n</code> <strong>R</strong> matrices with a 
fixed average rij.  If <code>u = NULL</code> and <code>rdist = "B"</code> then the <strong>R</strong> matrices are 
selected as a function of the <code>alpha</code> and <code>beta</code> arguments of a 
Beta distribution. Default <code>rdist= "U"</code>. See Waller (2024) for details.</p>
</td></tr>
<tr><td><code id="Ravgr_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) The shape1 parameter of a beta distribution.</p>
</td></tr>
<tr><td><code id="Ravgr_+3A_beta">beta</code></td>
<td>
<p>(numeric)  The shape2 parameter of a beta distribution.</p>
</td></tr>
<tr><td><code id="Ravgr_+3A_seed">SEED</code></td>
<td>
<p>(numeric)  The initial seed for the random number generator. 
If SEED is not supplied then the program will generate (and return) a randomly
generated seed.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><strong>R</strong> A random <strong>R</strong> matrix with a known, average off-diagonal 
element rij.
</p>
</li>
<li> <p><strong>Rseed</strong> The input <strong>R</strong> matrix or scalar with the
desired average rij.
</p>
</li>
<li> <p><strong>u</strong> A random number <code class="reqn">\in [0,1]</code>.
</p>
</li>
<li> <p><strong>s</strong> Scaling factor for hollow matrix <code>H</code>.
</p>
</li>
<li> <p><strong>H</strong>  A hollow matrix used to create a fungible <strong>R</strong> matrix.
</p>
</li>
<li> <p><strong>alpha</strong>  First argument of the beta distribution. If 
<code>rdist= "U"</code> then <code>alpha = NULL</code>.
</p>
</li>
<li> <p><strong>beta</strong>  Second argument of the beta distribution. 
If <code>rdist= "U"</code> then <code>beta = NULL</code>.
</p>
</li>
<li>  <p><strong>SEED</strong> The initial value for the random number generator.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Waller, N. G. (2024). Generating correlation matrices with a 
user-defined average correlation. Manuscript under review.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Example 1
  R &lt;- matrix(.35, 6, 6)
  diag(R) &lt;- 1
  
  Rout &lt;- Ravgr(Rseed = R, 
               rdist = "U", SEED = 123)$R
               
  Rout |&gt; round(3)            
  mean( Rout[upper.tri(Rout, diag = FALSE)] )
  
  # Example 2 
  Rout &lt;- Ravgr(Rseed = .35, NVar = 6, 
               rdist = "U", SEED = 123)$R
               
  Rout |&gt; round(3)            
  mean( Rout[upper.tri(Rout, diag = FALSE)] )   
  
  # Example 3
  # Generate an R matrix with a larger var(rij)
  Rout &lt;- Ravgr(Rseed = .35,
               NVar = 6, 
               rdist = "B",
               alpha = 7,
               beta = 2)$R
               
  Rout |&gt; round(3)            
  mean( Rout[upper.tri(Rout, diag = FALSE)] )
  
  # Example 4: Demonstrate the function of u
  sdR &lt;- function(R){
    sd(R[lower.tri(R, diag = FALSE)])
  }
  
  Rout &lt;- Ravgr(Rseed = .35,
               NVar = 6, 
               u = 0,
               SEED = 123)
  sdR(Rout$R)  
  
  Rout &lt;- Ravgr(Rseed = .35,
               NVar = 6, 
               u = .5,
               SEED = 123)
  sdR(Rout$R)   
  
  Rout &lt;- Ravgr(Rseed = .35,
               NVar = 6, 
               u = 1,
               SEED = 123)
  sdR(Rout$R)          
   
</code></pre>

<hr>
<h2 id='Rbounds'>Generate random R matrices with user-defined bounds on the correlation 
coefficients via differential evolution (DE).</h2><span id='topic+Rbounds'></span>

<h3>Description</h3>

<p><code>Rbounds</code> can generate uniformly sampled correlation matrices with 
user-defined bounds on the correlation coefficients via differential 
evolution (DE). Unconstrained <code class="reqn">R</code> matrices (i.e., with no constraints placed 
on the <code class="reqn">r_{ij}</code>) computed from 12 or fewer variables can be generated relatively 
quickly on a personal computer.  Larger matrices may require 
very long execution times. <code>Rbounds</code> can 
generate larger matrices when the correlations are tightly 
bounded (e.g., <code class="reqn">0 &lt; r_{ij} &lt; .5</code> for all <code class="reqn">i \neq j</code>). To generate 
uniformly sampled <code class="reqn">R</code> matrices, users should leave  
<code>NPopFactor</code> and <code>crAdaption</code> at 
their default values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rbounds(
  Nvar = 3,
  NMatrices = 1,
  Minr = -1,
  Maxr = 1,
  MinEig = 0,
  MaxIter = 200,
  NPopFactor = 10,
  crAdaption = 0,
  delta = 1e-08,
  PRINT = FALSE,
  Seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rbounds_+3A_nvar">Nvar</code></td>
<td>
<p>(integer) The order of the generated correlation matrices.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_nmatrices">NMatrices</code></td>
<td>
<p>(integer) Generate <code>NMatrices</code>
correlation matrices.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_minr">Minr</code></td>
<td>
<p>(numeric &gt; -1 and &lt; Maxr)  The lower bound for all  <code class="reqn">r_{ij}</code> in 
the generated R matrices.  Default <code>Minr = -1</code>.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_maxr">Maxr</code></td>
<td>
<p>(numeric &gt; Minr and &lt;= 1). The upper bound for all <code class="reqn">r_{ij}</code> in the 
generated <code class="reqn">R</code> matrices.  Default <code>Maxr = 1</code>.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_mineig">MinEig</code></td>
<td>
<p>(numeric). Minimum size of the last eigenvalue of R. Default 
<code>MinEig = 0</code>. By setting <code>MinEig</code> to a value slightly greater than 
0 (e.g., 1E-3), all generated matrices will be positive definite.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_maxiter">MaxIter</code></td>
<td>
<p>(integer) The maximum number of iterations
(i.e., generations) for the DE optimizer. Default <code>MaxIter = 200</code>.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_npopfactor">NPopFactor</code></td>
<td>
<p>(numeric &gt; 0). If <code class="reqn">R</code> is an <code class="reqn">n \times n</code> matrix, then each generation
will contain <code>NPopFactor</code> <code class="reqn">\times n(n-1)/2</code>  members.   Default <code>NPOP = 10</code>.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_cradaption">crAdaption</code></td>
<td>
<p>(numeric (0,1]). Controls the speed of the crossover adaption.
This parameter is called &lsquo;c&rsquo; in the  DEoptim.control help page.  
Default <code>crAdaption = 0</code>.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_delta">delta</code></td>
<td>
<p>(numeric &gt; 0) A number that controls the convergence. See the DEoptim.control
accuracy of the differential evolution algorithm. Default <code>delta = 1E-8</code>.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_print">PRINT</code></td>
<td>
<p>(logical) When PRINT = TRUE the algorithm convergence status is printed.
Default  <code>PRINT = FALSE</code>.</p>
</td></tr>
<tr><td><code id="Rbounds_+3A_seed">Seed</code></td>
<td>
<p>(integer) Initial random number seed. Default (<code>Seed = NULL</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Rbounds</code> returns the following objects:
</p>

<ul>
<li>  <p><strong>R</strong> (matrix) A list of generated correlation matrices.
</p>
</li>
<li>  <p><strong>converged</strong>: (logical) a logical that indicates the 
convergence status of the optimization for each matrix.
</p>
</li>
<li> <p><strong>iter</strong> (integer) The number of cycles needed to reach a 
converged solution for each matrix.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Ardia, D., Boudt, K., Carl, P., Mullen, K.M., Peterson, B.G. (2011) Differential
Evolution with DEoptim. An Application to Non-Convex Portfolio Optimization.
URL The R Journal, 3(1), 27-34.
URL https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Ardia~et~al.pdf.
</p>
<p>Georgescu, D. I., Higham, N. J., and Peters, G. W.  (2018).  Explicit
solutions to correlation matrix completion problems, with
an application to risk management and insurance.  Royal Society Open
Science, 5(3), 172348.
</p>
<p>Mishra, S. K.  (2007).  Completing correlation matrices
of arbitrary order by differential evolution method of global optimization:
a Fortran program.  Available at SSRN 968373.
</p>
<p>Mullen, K.M, Ardia, D., Gil, D., Windover, D., Cline, J. (2011). DEoptim: An
R Package for Global Optimization by Differential Evolution. <em>Journal of Statistical Software, 40</em>, 1-26. URL http://www.jstatsoft.org/v40/i06/.
</p>
<p>Price, K.V., Storn, R.M., Lampinen J.A. (2005) <em>Differential Evolution - A Practical Approach 
to Global Optimization</em>. Berlin Heidelberg: Springer-Verlag. ISBN 3540209506.
</p>
<p>Zhang, J. and Sanderson, A. (2009) <em>Adaptive Differential
Evolution</em>. Springer-Verlag. ISBN 978-3-642-01526-7
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1: Generate random 4 x 4 Correlation matrices with all rij &gt;= 0.

  out &lt;- Rbounds(Nvar = 4,
              NMatrices = 4,
              Minr = 0,
              Maxr = 1,
              PRINT = TRUE,
              Seed = 1)
                      
  # Check convergence status of matrices                     
  print( table(out$converged) )                     

  print( round( out$R[[1]] , 3) )


</code></pre>

<hr>
<h2 id='rcone'>Generate a Cone of Regression Coefficient Vectors</h2><span id='topic+rcone'></span>

<h3>Description</h3>

<p>Compute a cone of regression vectors with a constant R-squared around a
target vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcone(R, Rsq, b, axis1, axis2, deg, Npoints = 360)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcone_+3A_r">R</code></td>
<td>
<p>Predictor correlation matrix.</p>
</td></tr>
<tr><td><code id="rcone_+3A_rsq">Rsq</code></td>
<td>
<p>Coefficient of determination.</p>
</td></tr>
<tr><td><code id="rcone_+3A_b">b</code></td>
<td>
<p>Target vector of OLS regression coefficients.</p>
</td></tr>
<tr><td><code id="rcone_+3A_axis1">axis1</code></td>
<td>
<p>1st axis of rotation plane.</p>
</td></tr>
<tr><td><code id="rcone_+3A_axis2">axis2</code></td>
<td>
<p>2nd axis of rotation plane.</p>
</td></tr>
<tr><td><code id="rcone_+3A_deg">deg</code></td>
<td>
<p>All vectors b.i will be &lsquo;deg&rsquo; degrees from b.</p>
</td></tr>
<tr><td><code id="rcone_+3A_npoints">Npoints</code></td>
<td>
<p>Number of rotation vectors, default = 360.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>b.i</code></td>
<td>
<p>Npoints values of b.i</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller and Jeff Jones
</p>


<h3>References</h3>

<p>Waller, N. G. &amp; Jones, J. A. (2011). Investigating the
performance of alternate regression weights by studying all possible
criteria in regression models with a fixed set of predictors.
<em>Psychometrika, 76</em>, 410-439.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
R &lt;- matrix(.5, 4, 4)
diag(R) &lt;- 1

Npoints &lt;- 1000
Rsq &lt;- .40
NumDeg &lt;- 20
V &lt;- eigen(R)$vectors

## create b parallel to v[,3]
## rotate in the 2 - 4 plane
b &lt;- V[,3]
bsq &lt;- t(b) %*% R %*% b 
b &lt;- b * sqrt(Rsq/bsq)                
b.i &lt;- rcone(R, Rsq,b, V[,2], V[,4], deg = NumDeg, Npoints)

t(b.i[,1]) %*% R %*% b.i[,1]
t(b.i[,25]) %*% R %*% b.i[,25]

</code></pre>

<hr>
<h2 id='rcor'>Generate Random PSD Correlation Matrices</h2><span id='topic+rcor'></span>

<h3>Description</h3>

<p>Generate random PSD correlation matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcor(Nvar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcor_+3A_nvar">Nvar</code></td>
<td>
<p>An integer that determines the order of the random correlation
matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>rcor generates random PSD correlation matrices by (1) generating Nvar
squared random normal deviates, (2) scaling the deviates to sum to Nvar, and
then (3) placing the scaled values into a diagonal matrix L. Next, (4) an
Nvar x Nvar orthogonal matrix, Q, is created by performing a QR
decomposition of a matrix, M, that contains random normal deviates.  (5) A
PSD covariance matrix, C, is created from Q L Q^T and then (6) scaled to a
correlation metric.
</p>


<h3>Value</h3>

<table>
<tr><td><code>A random correlation matrix.</code></td>
<td>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+genCorr">genCorr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
R &lt;- rcor(4)
print( R )

</code></pre>

<hr>
<h2 id='rellipsoid'>Generate Uniformly Spaced OLS Regression Coefficients that Yield a
User-Supplied R-Squared Value</h2><span id='topic+rellipsoid'></span>

<h3>Description</h3>

<p>Given predictor matrix R, generate OLS regression coefficients that yield a
user-supplied R-Squared value. These regression coefficient vectors will be
uniformly spaced on the surface of a (hyper) ellipsoid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rellipsoid(R, Rsq, Npoints)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rellipsoid_+3A_r">R</code></td>
<td>
<p>A p x p predictor correlation matrix.</p>
</td></tr>
<tr><td><code id="rellipsoid_+3A_rsq">Rsq</code></td>
<td>
<p>A user-supplied R-squared value.</p>
</td></tr>
<tr><td><code id="rellipsoid_+3A_npoints">Npoints</code></td>
<td>
<p>Desired number of generated regression vectors.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>b</code></td>
<td>
<p>A p x Npoints matrix of regression coefficients</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller and Jeff Jones.
</p>


<h3>References</h3>

<p>Waller, N. G. and Jones, J. A. (2011). Investigating the
performance of alternate regression weights by studying all possible
criteria in regression models with a fixed set of predictors.
<em>Psychometrika, 76</em>, 410-439.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## generate uniformly distributed regression vectors
## on the surface of a 14-dimensional ellipsoid 
N &lt;- 10000
Rsq &lt;- .21

# Correlations from page 224 WAIS-III manual 
# The Psychological Corporation (1997).
wais3 &lt;- matrix(
 c(1, .76, .58, .43, .75, .75, .42, .54, .41, .57, .64, .54, .50, .53,
 .76,   1, .57, .36, .69, .71, .45, .52, .36, .63, .68, .51, .47, .54,
 .58, .57,   1, .45, .65, .60, .47, .48, .43, .59, .60, .49, .56, .47,
 .43, .36, .45,   1, .37, .40, .60, .30, .32, .34, .35, .28, .35, .29,
 .75, .69, .65, .37,   1, .70, .44, .54, .34, .59, .62, .54, .45, .50,
 .75, .71, .60, .40, .70,   1, .42, .51, .44, .53, .60, .50, .52, .44,
 .42, .45, .47, .60, .44, .42,   1, .46, .49, .47, .43, .27, .50, .42,
 .54, .52, .48, .30, .54, .51, .46,   1, .45, .50, .58, .55, .53, .56,
 .41, .36, .43, .32, .34, .44, .49, .45,   1, .47, .49, .41, .70, .38,
 .57, .63, .59, .34, .59, .53, .47, .50, .47,   1, .63, .62, .58, .66,
 .64, .68, .60, .35, .62, .60, .43, .58, .49, .63,   1, .59, .50, .59,
 .54, .51, .49, .28, .54, .50, .27, .55, .41, .62, .59,   1, .48, .53,
 .50, .47, .56, .35, .45, .52, .50, .53, .70, .58, .50, .48,   1, .51,
 .53, .54, .47, .29, .50, .44, .42, .56, .38, .66, .59, .53, .51,   1),
 nrow = 14, ncol = 14)

R &lt;- wais3[1:6,1:6]             
b &lt;- rellipsoid(R, Rsq, Npoints = N)
b &lt;- b$b
# 
plot(b[1,],b[2,])

</code></pre>

<hr>
<h2 id='restScore'>Plot an ERF using rest scores</h2><span id='topic+restScore'></span>

<h3>Description</h3>

<p>Plot an empirical response function using rest scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>restScore(data, item, NCuts = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="restScore_+3A_data">data</code></td>
<td>
<p>N(subjects)-by-p(items) matrix of 0/1 item response data.</p>
</td></tr>
<tr><td><code id="restScore_+3A_item">item</code></td>
<td>
<p>Generate a rest score plot for item <code>item</code>.</p>
</td></tr>
<tr><td><code id="restScore_+3A_ncuts">NCuts</code></td>
<td>
<p>Divide the rest scores into <code>NCuts</code> bins of equal width.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A restscore plot with 95% confidence interval bars for the
conditional probability estimates. </p>
<table>
<tr><td><code>item</code></td>
<td>
<p>The item number.</p>
</td></tr>
<tr><td><code>bins</code></td>
<td>
<p>A vector of bin limits and bin sample sizes.</p>
</td></tr> <tr><td><code>binProb</code></td>
<td>
<p>A
vector of bin conditional probabilities.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
NSubj &lt;- 2000

#generate sample k=1 FMP  data
b &lt;- matrix(c(
    #b0    b1     b2    b3      b4   b5 b6 b7  k
  1.675, 1.974, -0.068, 0.053,  0,  0,  0,  0, 1,
  1.550, 1.805, -0.230, 0.032,  0,  0,  0,  0, 1,
  1.282, 1.063, -0.103, 0.003,  0,  0,  0,  0, 1,
  0.704, 1.376, -0.107, 0.040,  0,  0,  0,  0, 1,
  1.417, 1.413,  0.021, 0.000,  0,  0,  0,  0, 1,
 -0.008, 1.349, -0.195, 0.144,  0,  0,  0,  0, 1,
  0.512, 1.538, -0.089, 0.082,  0,  0,  0,  0, 1,
  0.122, 0.601, -0.082, 0.119,  0,  0,  0,  0, 1,
  1.801, 1.211,  0.015, 0.000,  0,  0,  0,  0, 1,
 -0.207, 1.191,  0.066, 0.033,  0,  0,  0,  0, 1,
 -0.215, 1.291, -0.087, 0.029,  0,  0,  0,  0, 1,
  0.259, 0.875,  0.177, 0.072,  0,  0,  0,  0, 1,
 -0.423, 0.942,  0.064, 0.094,  0,  0,  0,  0, 1,
  0.113, 0.795,  0.124, 0.110,  0,  0,  0,  0, 1,
  1.030, 1.525,  0.200, 0.076,  0,  0,  0,  0, 1,
  0.140, 1.209,  0.082, 0.148,  0,  0,  0,  0, 1,
  0.429, 1.480, -0.008, 0.061,  0,  0,  0,  0, 1,
  0.089, 0.785, -0.065, 0.018,  0,  0,  0,  0, 1,
 -0.516, 1.013,  0.016, 0.023,  0,  0,  0,  0, 1,
  0.143, 1.315, -0.011, 0.136,  0,  0,  0,  0, 1,
  0.347, 0.733, -0.121, 0.041,  0,  0,  0,  0, 1,
 -0.074, 0.869,  0.013, 0.026,  0,  0,  0,  0, 1,
  0.630, 1.484, -0.001, 0.000,  0,  0,  0,  0, 1), 
  nrow=23, ncol=9, byrow=TRUE)  
  
data&lt;-genFMPData(NSubj = NSubj, bParam = b, seed = 345)$data

## generate a rest score plot for item 12.
## the grey horizontal lines in the plot
## respresent pseudo asymptotes that
## are significantly different from the 
## (0,1) boundaries
restScore(data, item = 12, NCuts = 9)

</code></pre>

<hr>
<h2 id='RGen'>Generate random R matrices with various user-defined properties via 
differential evolution (DE).</h2><span id='topic+RGen'></span>

<h3>Description</h3>

<p>Generate random R matrices with various user-defined properties via 
differential evolution (DE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RGen(
  Nvar = 3,
  NMatrices = 1,
  Minr = -1,
  Maxr = 1,
  MinEig = 0,
  MaxIter = 200,
  delta = 1e-08,
  PRINT = FALSE,
  Seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RGen_+3A_nvar">Nvar</code></td>
<td>
<p>(integer) The order of the generated correlation matrices.</p>
</td></tr>
<tr><td><code id="RGen_+3A_nmatrices">NMatrices</code></td>
<td>
<p>(integer) Generate <code>NMatrices</code>
correlation matrices.</p>
</td></tr>
<tr><td><code id="RGen_+3A_minr">Minr</code></td>
<td>
<p>(numeric &gt; -1 and &lt; Maxr)  The minimum  rij in 
the generated R matrices.  Default <code>Minr = -1</code>.</p>
</td></tr>
<tr><td><code id="RGen_+3A_maxr">Maxr</code></td>
<td>
<p>(numeric &gt; Minr and &lt;= 1). The maximum  rij in the 
generated R matrices.  Default <code>Maxr = 1</code>.</p>
</td></tr>
<tr><td><code id="RGen_+3A_mineig">MinEig</code></td>
<td>
<p>(numeric). Minimum size of the last eigenvalue of R. Default 
<code>MinEig = 0</code>. By setting <code>MinEig</code> to a value slightly greater than 
0 (e.g., 1E-3), all generated matrices will be positive definite.</p>
</td></tr>
<tr><td><code id="RGen_+3A_maxiter">MaxIter</code></td>
<td>
<p>(integer) The maximum number of iterations
(i.e., generations) for the DE optimizer. Default <code>MaxIter = 200</code>.</p>
</td></tr>
<tr><td><code id="RGen_+3A_delta">delta</code></td>
<td>
<p>(numeric &gt; 0) A number that controls the convergence
accuracy of the differential evolution algorithm. Default <code>delta = 1E-8</code>.</p>
</td></tr>
<tr><td><code id="RGen_+3A_print">PRINT</code></td>
<td>
<p>(logical) When PRINT = TRUE the algorithm convergence status is printed.
Default  <code>PRINT = FALSE</code>.</p>
</td></tr>
<tr><td><code id="RGen_+3A_seed">Seed</code></td>
<td>
<p>(integer) Initial random number seed. Default (<code>Seed = NULL</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RGen</code> returns the following objects:
</p>

<ul>
<li>  <p><strong>R</strong> (matrix) A list of generated correlation matrices.
</p>
</li>
<li>  <p><strong>converged</strong>: (logical) a logical that indicates the 
convergence status of the optimization for each matrix.
</p>
</li>
<li> <p><strong>iter</strong> (integer) The number of cycles needed to reach a 
converged solution for each matrix.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Ardia, D., Boudt, K., Carl, P., Mullen, K.M., Peterson, B.G. (2011) Differential
Evolution with DEoptim. An Application to Non-Convex Portfolio Optimization.
URL The R Journal, 3(1), 27-34.
URL https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Ardia~et~al.pdf.
</p>
<p>Georgescu, D. I., Higham, N. J., and Peters, G. W.  (2018).  Explicit
solutions to correlation matrix completion problems, with
an application to risk management and insurance.  Royal Society Open
Science, 5(3), 172348.
</p>
<p>Mishra, S. K.  (2007).  Completing correlation matrices
of arbitrary order by differential evolution method of global optimization:
a Fortran program.  Available at SSRN 968373.
</p>
<p>Mullen, K.M, Ardia, D., Gil, D., Windover, D., Cline, J. (2011). DEoptim: An
R Package for Global Optimization by Differential Evolution. Journal of Statistical Software, 40(6), 1-26. URL http://www.jstatsoft.org/v40/i06/.
</p>
<p>Price, K.V., Storn, R.M., Lampinen J.A. (2005) Differential Evolution - A Practical Approach to Global Optimization. Berlin Heidelberg:
Springer-Verlag. ISBN 3540209506.
</p>
<p>Zhang, J. and Sanderson, A. (2009) Adaptive Differential
Evolution Springer-Verlag. ISBN 978-3-642-01526-7
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1: Generate random 4 x 4 Correlation matrices.

  out &lt;- RGen(Nvar = 4,
              NMatrices = 4,
              PRINT = TRUE,
              Seed = 1)
                      
  # Check convergence status of all matrices                     
  print( table(out$converged) )                     

  print( round( out$R[[1]] , 3) )


</code></pre>

<hr>
<h2 id='rGivens'>Generate Correlation Matrices with Specified Eigenvalues</h2><span id='topic+rGivens'></span>

<h3>Description</h3>

<p>rGivens generates correlation matrices with user-specified eigenvalues via a
series of Givens rotations by methods described in Bendel &amp; Mickey (1978)
and Davis &amp; Higham (2000).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rGivens(eigs, Seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rGivens_+3A_eigs">eigs</code></td>
<td>
<p>A vector of eigenvalues that must sum to the order of the
desired correlation matrix. A fatal error will occur if sum(eigs) !=
length(eigs).</p>
</td></tr>
<tr><td><code id="rGivens_+3A_seed">Seed</code></td>
<td>
<p>Either a user supplied seed for the random number generator or
&lsquo;NULL&rsquo; for a function generated seed. Default Seed = &lsquo;NULL&rsquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>R</code></td>
<td>
<p>A correlation matrix with desired spectrum.</p>
</td></tr>
<tr><td><code>Frob</code></td>
<td>
<p>The Frobenius norm of the difference between the initial and
final matrices with the desired spectrum.</p>
</td></tr> <tr><td><code>convergence</code></td>
<td>
<p>(Logical) TRUE
if rGivens converged to a feasible solution, otherwise FALSE.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bendel, R. B. &amp; Mickey, M. R. (1978). Population correlation
matrices for sampling experiments, Commun. Statist. Simulation Comput., B7,
pp. 163-182.
</p>
<p>Davies, P. I, &amp; Higham,N. J. (2000). Numerically stable generation of
correlation matrices and their factors, BIT, 40 (2000), pp. 640-651.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Example
## Generate a correlation matrix with user-specified eigenvalues

out &lt;- rGivens(c(2.5, 1, 1, .3, .2), Seed = 123)

#&gt; eigen(out$R)$values
#[1] 2.5 1.0 1.0 0.3 0.2

print(out)
#$R
#           [,1]       [,2]        [,3]        [,4]       [,5]
#[1,]  1.0000000 -0.1104098 -0.24512327  0.46497370  0.2392817
#[2,] -0.1104098  1.0000000  0.33564370 -0.46640155 -0.7645915
#[3,] -0.2451233  0.3356437  1.00000000 -0.02935466 -0.2024926
#[4,]  0.4649737 -0.4664016 -0.02935466  1.00000000  0.6225880
#[5,]  0.2392817 -0.7645915 -0.20249261  0.62258797  1.0000000
#
#$Frob
#[1] 2.691613
#
##$S0
#           [,1]        [,2]        [,3]        [,4]        [,5]
#[1,]  1.0349665  0.22537748 -0.46827121 -0.10448336 -0.24730565
#[2,]  0.2253775  0.31833805 -0.23208078  0.06591368 -0.14504161
#[3,] -0.4682712 -0.23208078  2.28911499  0.05430754  0.06964858
#[4,] -0.1044834  0.06591368  0.05430754  0.94884439 -0.14439623
#[5,] -0.2473056 -0.14504161  0.06964858 -0.14439623  0.40873606
#
#$convergence
#[1] TRUE


</code></pre>

<hr>
<h2 id='rMAP'>Generate Correlation Matrices with Specified Eigenvalues</h2><span id='topic+rMAP'></span>

<h3>Description</h3>

<p>rMAP uses the method of alternating projections (MAP) to generate
correlation matrices with specified eigenvalues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rMAP(eigenval, eps = 1e-12, maxits = 5000, Seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rMAP_+3A_eigenval">eigenval</code></td>
<td>
<p>A vector of eigenvalues that must sum to the order of the
desired correlation matrix. A fatal error will occur if sum(eigenval) !=
length(eigenval).</p>
</td></tr>
<tr><td><code id="rMAP_+3A_eps">eps</code></td>
<td>
<p>Convergence criterion. Default = 1e-12.</p>
</td></tr>
<tr><td><code id="rMAP_+3A_maxits">maxits</code></td>
<td>
<p>Maximm number of iterations of MAP.</p>
</td></tr>
<tr><td><code id="rMAP_+3A_seed">Seed</code></td>
<td>
<p>Either a user supplied seed for the random number generator or
&lsquo;NULL&rsquo; for a function generated seed. Default Seed = &lsquo;NULL&rsquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>R</code></td>
<td>
<p>A correlation matrix with the desired spectrum.</p>
</td></tr>
<tr><td><code>evals</code></td>
<td>
<p>Eigenvalues of the returned matrix, R.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>(Logical) TRUE if MAP converged to a feasible solution,
otherwise FALSE.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Waller, N. G. (2016). Generating correlation matrices with
specified eigenvalues using the method of alternating projections.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Example
## Generate a correlation matrix with user-specified eigenvalues

R &lt;- rMAP(c(2.5, 1, 1, .3, .2), Seed = 123)$R
print(R, 2)

#       [,1]    [,2]   [,3]    [,4]   [,5]
#[1,]  1.000  0.5355 -0.746 -0.0688 -0.545
#[2,]  0.535  1.0000 -0.671 -0.0016 -0.056
#[3,] -0.746 -0.6711  1.000  0.0608  0.298
#[4,] -0.069 -0.0016  0.061  1.0000  0.002
#[5,] -0.545 -0.0564  0.298  0.0020  1.000


eigen(R)$values
#[1] 2.5 1.0 1.0 0.3 0.2

</code></pre>

<hr>
<h2 id='rmsd'>Root Mean Squared Deviation of (A - B)</h2><span id='topic+rmsd'></span>

<h3>Description</h3>

<p>Calculates the root mean squared deviation of matrices A and B.  If these
matrices are symmetric (Symmetric = TRUE) then the calculation is based on
the upper triangles of each matrix. When the matrices are symmetric, the
diagonal of each matrix can be included or excluded from the calculation
(IncludeDiag = FALSE)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmsd(A, B, Symmetric = TRUE, IncludeDiag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmsd_+3A_a">A</code></td>
<td>
<p>A possibly non square matrix.</p>
</td></tr>
<tr><td><code id="rmsd_+3A_b">B</code></td>
<td>
<p>A matrix of the same dimensions as matrix A.</p>
</td></tr>
<tr><td><code id="rmsd_+3A_symmetric">Symmetric</code></td>
<td>
<p>Logical indicating whether A and B are symmetric matrices.
(Default: Symmetric = TRUE)</p>
</td></tr>
<tr><td><code id="rmsd_+3A_includediag">IncludeDiag</code></td>
<td>
<p>Logical indicating whether to include the diagonals in
the calculation. (Default: IncludeDiag = FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the root mean squared deviation of (A - B).
</p>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
A &lt;- matrix(rnorm(9), nrow = 3)
B &lt;- matrix(rnorm(9), nrow = 3)

( rmsd(A, B, Symmetric = FALSE, IncludeDiag = TRUE) )
</code></pre>

<hr>
<h2 id='rmsea'>Calculate RMSEA between two correlation matrices</h2><span id='topic+rmsea'></span>

<h3>Description</h3>

<p>Given two correlation matrices of the same dimension, calculate the RMSEA
value using the degrees of freedom for the exploratory factor analysis model
(see details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmsea(Sigma, Omega, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmsea_+3A_sigma">Sigma</code></td>
<td>
<p>(matrix) Population correlation or covariance matrix (with model
error).</p>
</td></tr>
<tr><td><code id="rmsea_+3A_omega">Omega</code></td>
<td>
<p>(matrix) Model-implied population correlation or covariance
matrix.</p>
</td></tr>
<tr><td><code id="rmsea_+3A_k">k</code></td>
<td>
<p>(scalar) Number of major common factors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this function uses the degrees of freedom for an
exploratory factor analysis model: </p>
<p style="text-align: center;"><code class="reqn">df = p(p-1)/2-(pk)+k(k-1)/2,</code>
</p>

<p>where <code class="reqn">p</code> is the number of items and <code class="reqn">k</code> is the number of major
factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod &lt;- fungible::simFA(Model = list(NFac = 3),
                       Seed = 42)
set.seed(42)
Omega &lt;- mod$Rpop
Sigma &lt;- noisemaker(
  mod = mod,
  method = "CB",
  target_rmsea = 0.05
)$Sigma
rmsea(Sigma, Omega, k = 3)
</code></pre>

<hr>
<h2 id='RnpdMAP'>Generate Random NPD R matrices from a user-supplied population R</h2><span id='topic+RnpdMAP'></span>

<h3>Description</h3>

<p>Generate a list of Random NPD (pseudo) R matrices with a user-defined fixed
minimum eigenvalue from a user-supplied population R using the method of
alternating projections.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RnpdMAP(
  Rpop,
  Lp = NULL,
  NNegEigs = 1,
  NSmoothPosEigs = 4,
  NSubjects = NULL,
  NSamples = 0,
  MaxIts = 15000,
  PRINT = FALSE,
  Seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RnpdMAP_+3A_rpop">Rpop</code></td>
<td>
<p>input (PD or PSD) p x p Population correlation matrix.</p>
</td></tr>
<tr><td><code id="RnpdMAP_+3A_lp">Lp</code></td>
<td>
<p>desired minimum eigenvalue in the NPD matrices.</p>
</td></tr>
<tr><td><code id="RnpdMAP_+3A_nnegeigs">NNegEigs</code></td>
<td>
<p>number of eigenvalues &lt; 0 in Rnpd.</p>
</td></tr>
<tr><td><code id="RnpdMAP_+3A_nsmoothposeigs">NSmoothPosEigs</code></td>
<td>
<p>number of eigenvalues &gt; 0 to smooth: the smallest
NSmoothPosEigs &gt; 0  will be smoothed toward 0.</p>
</td></tr>
<tr><td><code id="RnpdMAP_+3A_nsubjects">NSubjects</code></td>
<td>
<p>sample size (required when NSamples &gt; 0) parameter used to
generate sample correlation matrices. Default = NULL.</p>
</td></tr>
<tr><td><code id="RnpdMAP_+3A_nsamples">NSamples</code></td>
<td>
<p>generate NSamples sample R matrices. If NSamples = 0 the
program will attempt to find Rnpd such that ||Rpop - Rnpd||_2 is minimized.</p>
</td></tr>
<tr><td><code id="RnpdMAP_+3A_maxits">MaxIts</code></td>
<td>
<p>maximum number of projection iterations.</p>
</td></tr>
<tr><td><code id="RnpdMAP_+3A_print">PRINT</code></td>
<td>
<p>(logical) If TRUE the program will print the iteration history
for Lp. Default = NULL.</p>
</td></tr>
<tr><td><code id="RnpdMAP_+3A_seed">Seed</code></td>
<td>
<p>Optional seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Rpop</code></td>
<td>
<p>population (PD) correlation matrix.</p>
</td></tr> <tr><td><code>R</code></td>
<td>
<p>sample
correlation matrix.</p>
</td></tr> <tr><td><code>Rnpd</code></td>
<td>
<p>NPD improper (pseudo) correlation matrix.</p>
</td></tr>
<tr><td><code>Lp</code></td>
<td>
<p>desired value of minimum eigenvalue.</p>
</td></tr> <tr><td><code>minEig</code></td>
<td>
<p>observed value
of minimum eigenvalue of Rnpd.</p>
</td></tr> <tr><td><code>convergence</code></td>
<td>
<p>0 = converged; 1 = not
converged in MaxIts iterations of the alternating projections algorithm.</p>
</td></tr>
<tr><td><code>feasible</code></td>
<td>
<p>logical) TRUE if max(abs(r_ij)) &lt;= 1. If FALSE then one or
more values in Rnpd &gt; 1 in absolute value.</p>
</td></tr> <tr><td><code>Seed</code></td>
<td>
<p>saved seed for
random number generator.</p>
</td></tr> <tr><td><code>prbs1</code></td>
<td>
<p>vector probabilities used to generate
eigenvalues &lt; 0.</p>
</td></tr> <tr><td><code>prbs2</code></td>
<td>
<p>vector of probabilities used to smooth the
smallest NSmoothPosEigs towards zero.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)

Nvar = 20
Nfac = 4
NSubj = 2000
Seed = 123    

set.seed(Seed)

## Generate a vector of classical item difficulties
p &lt;- runif(Nvar)

cat("\nClassical Item Difficulties:\n")

print(rbind(1:Nvar,round(p,2)) )

summary(p)


## Convert item difficulties to quantiles
b &lt;- qnorm(p)


## fnc to compute root mean squared standard deviation
RMSD &lt;- function(A, B){
  sqrt(mean( ( A[lower.tri(A, diag = FALSE)] - B[lower.tri(B, diag = FALSE)] )^2))
}


## Generate vector of eigenvalues with clear factor structure
  L &lt;- eigGen(nDimensions = Nvar, 
            nMajorFactors = Nfac, 
            PrcntMajor = .60, 
            threshold  = .50)
          

## Generate a population R matrix with the eigenvalues in L
  Rpop &lt;- rGivens(eigs = L)$R
  
## Generate continuous data that will reproduce Rpop (exactly)
  X &lt;- mvrnorm(n = NSubj, mu = rep(0, Nvar), 
               Sigma = Rpop, empirical = TRUE)
               
while( any(colSums(X) == 0) ){
  warning("One or more variables have zero variance. Generating a new data set.") 
   X &lt;- mvrnorm(n = NSubj, mu = rep(0, Nvar), 
               Sigma = Rpop, empirical = TRUE)              
 }
 
## Cut X at thresholds given in b to produce binary data U
  U &lt;- matrix(0, nrow(X), ncol(X))
  for(j in 1:Nvar){
    U[X[,j] &lt;= b[j],j] &lt;- 1
  }
  
## Compute tetrachoric correlations
  Rtet &lt;- tetcor(U, Smooth = FALSE, PRINT = TRUE)$r
  # Calculate eigenvalues of tetrachoric R matrix
  Ltet &lt;- eigen(Rtet)$values
  
  if(Ltet[Nvar] &gt;= 0) stop("Rtet is P(S)D")
  
## Simulate NPD R matrix with minimum eigenvalue equal to 
  # min(Ltet)
  out &lt;- RnpdMAP(Rpop, 
               Lp = Ltet[Nvar], 
               NNegEigs = Nvar/5,
               NSmoothPosEigs = Nvar/5, 
               NSubjects = 150, 
               NSamples = 1, 
               MaxIts = 15000, 
               PRINT = FALSE, 
               Seed = Seed) 

## RLp is a NPD pseudo R matrix with min eigenvalue = min(Ltet)
  RLp &lt;- out[[1]]$Rnpd

## Calculate eigenvalues of simulated NPD R matrix (Rnpd)
  Lnpd &lt;- eigen(RLp, only.values = TRUE)$values
  
## Scree plots for observed and simulated NPD R matrices.  
  ytop &lt;- max(c(L,Lnpd,Ltet))
  pointSize = .8
  plot(1:Nvar, L, typ = "b", col = "darkgrey", lwd=3, 
       lty=1, 
       main = 
       "Eigenvalues of Rpop, Tet R, and Sim Tet R:
       \nSimulated vs Observed npd Tetrachoric R Matrices",
       ylim = c(-1, ytop),
       xlab = "Dimensions", 
       ylab = "Eigenvalues",
       cex = pointSize,cex.main = 1.2)
  points(1:Nvar, Lnpd, typ="b", 
         col = "red", lwd = 3, lty=2, cex=pointSize)
  points(1:Nvar, Ltet, typ="b", 
         col = "darkgreen", lwd = 3, lty = 3, cex= pointSize)
 
  legend("topright", 
         legend = c("eigs Rpop", "eigs Sim Rnpd", "eigs Emp Rnpd"), 
         col = c("darkgrey", "red","darkgreen"), 
         lty = c(1,2,3), 
         lwd = c(4,4,4), cex = 1.5)
  
  abline(h = 0, col = "grey", lty = 2, lwd = 4)
 
  cat("\nRMSD(Rpop, Rtet) = ", round(rmsd(Rpop, Rtet), 3))
  cat("\nRMSD(Rpop, RLp) = ",  round(rmsd(Rpop, RLp),  3))

</code></pre>

<hr>
<h2 id='rPCA'>Generate a Correlation Matrix from a Truncated PCA Loadings Matrix.</h2><span id='topic+rPCA'></span>

<h3>Description</h3>

<p>This function generates a random (or possibly unique) correlation matrix (R) from an unrotated 
or orthogonally rotated PCA loadings matrix via a modified alternating 
projections algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rPCA(
  F,
  epsMax = 1e-18,
  maxit = 2000,
  Seed = NULL,
  InitP2 = 2,
  Eigs = NULL,
  PrintLevel = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rPCA_+3A_f">F</code></td>
<td>
<p>(Matrix) A p (variables) by k (components) PCA loadings matrix. 
F can equal either an unrotated or an orthogonally rotated 
loadings matrix.</p>
</td></tr>
<tr><td><code id="rPCA_+3A_epsmax">epsMax</code></td>
<td>
<p>(Scalar) A small number used to evaluate function convergence. 
Default (epsMax = 1E-18).</p>
</td></tr>
<tr><td><code id="rPCA_+3A_maxit">maxit</code></td>
<td>
<p>(Integer) An integer that specifies the maximum  number of 
iterations of the modified alternating projections algorithm (APA).</p>
</td></tr>
<tr><td><code id="rPCA_+3A_seed">Seed</code></td>
<td>
<p>(Integer) A user-defined starting seed for the 
random number generator.  If Seed = NULL then rPCA will generate a 
random starting seed. Setting Seed to a positive integer will generate 
reproducible results.  Default (Seed = NULL)</p>
</td></tr>
<tr><td><code id="rPCA_+3A_initp2">InitP2</code></td>
<td>
<p>(Integer) The method used to initiate the remaining columns of the
truncated principal components solution.  If <code>InitP2 = 1</code> then the 
starting P2 will be a random semi-orthogonal matrix.  If If <code>InitP2 = 2</code> then 
the starting P2 will be a semi-orthogonal matrix that is in the left 
null space of P1. Default (<code>InitP2 = 2</code>). Of the two options, 
<code>InitP2 = 2</code> generally converges to a single feasible solution in less time.
<code>InitP2 = 1</code> can be used to generate different solutions from different 
starting seeds.</p>
</td></tr>
<tr><td><code id="rPCA_+3A_eigs">Eigs</code></td>
<td>
<p>(Vector) Under some conditions, <code>rPCA</code> can generate (or 
reproduce)  a unique correlation matrix with known (i.e., user-specified) 
eigenvalues from a truncated PC loadings matrix, <code>F</code>, even when 
the rank of <code>F</code> is less than p (the number of observed variables). 
<code>Eigs</code> is an optional p-length vector of eigenvalues for <code>R</code>. 
Default (<code>Eigs = NULL</code>).</p>
</td></tr>
<tr><td><code id="rPCA_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(Integer) If PrintLevel = 0 no output will be printed
(choose this option for Monte Carlo simulations). If PrintLevel = 1 the 
program will print the APA convergence status and the number of iterations 
used to achieve convergence.  If PrintLevel = 2 then rPCA will print the 
iteration convergence history of the modified APA algorithm. Default 
(PrintLevel = 1).</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><strong>R</strong> (Matrix) A p by p correlation matrix that 
generates the desired PCA loadings.
</p>
</li>
<li> <p><strong>Tmat</strong> (Matrix) A k by k orthogonal rotation matrix 
that will rotate the unrotated PCA loadings matrix, P1, to F (if F is an 
orthogonally rotated loadings matrix).
</p>
</li>
<li> <p><strong>P1</strong> (Matrix)  The p by k unrotated PCA loadings matrix 
that is associated  with F.
</p>
</li>
<li> <p><strong>Fhat</strong> (Matrix) The p by k estimated (and possibly rotated) 
PCA loadings matrix from the simulated matrix R.
</p>
</li>
<li> <p><strong>error</strong>  (Logical) A logical that indicates whether 
F is a legitimate PCA loadings matrix. 
</p>
</li>
<li> <p><strong>Lambda</strong> (Vector) The sorted eigenvalues of R.
</p>
</li>
<li> <p><strong>iterHx</strong> (Vector) Criterion (i.e., fit) values for  
for each iteration of the modified APA algorithm.
</p>
</li>
<li> <p><strong>converged</strong> (Logical) A logical that signifies function 
convergence.
</p>
</li>
<li> <p><strong>Seed</strong> (Integer) Either a user-defined or function generated 
starting seed for the random number generator. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller (nwaller@umn.edu)
</p>


<h3>References</h3>

<p>Escalante, R. and Raydan, M.  (2011).  Alternating projection 
methods.   Society for Industrial and Applied Mathematics.
</p>
<p>ten Berge, J. M. and Kiers, H. A.  (1999).  Retrieving the 
correlation matrix from a truncated PCA solution: The inverse principal 
component problem.  Psychometrika, 64(3), 317&ndash;324.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# External PCA function ---
# used to check results
 
PCA &lt;- function(R, k = NULL){
  if(is.null(k)) k &lt;- ncol(R)
  VLV &lt;- eigen(R)
 V &lt;- VLV$vectors
 L &lt;- VLV$values

 
 if( k &gt; 1){
   P &lt;-  V[, 1:k] %*% diag(L[1:k]^.5)
 }
 else{
   P &lt;- as.matrix(V[, 1], drop=False) * L[1]^.5
 }
  Psign &lt;- sign(apply(P, 2, sum))
  if(k &gt; 1) Psign = diag(Psign)
  P &lt;- P %*%  Psign
 P
}#END PCA  

  
## Generate Desired Population rotated PCA loadings matrix
## Example = 1
 k = 2
 F &lt;- matrix(0, 8, 2) 
 F[1:4, 1] &lt;- seq(.75, .72, length= 4)  
 F[5:8, 2] &lt;- seq(.65, .62, length= 4)  
 F[1,2] &lt;- .1234
 F[8,1] &lt;- .4321
 colnames(F) &lt;-   paste0("F", 1:k) 
 (F)
 
 ## Run Example 1
 pout &lt;- rPCA(F, 
              maxit = 5000, 
              Seed = 1, 
              epsMax = 1E-18,
              PrintLevel = 1)
pout$converged
eigen(pout$R)$values
if(pout$error == FALSE &amp; pout$converged){ 
    Fhat &lt;- pout$Fhat
    cat("\nPCA Loadings\n")
    ( round( cbind(F,Fhat ), 5) )
 }
 
 ## Example = 2      
 ## Single component example from Widaman 2018

 k = 1
 F &lt;- matrix(rep(c(.8,.6, .4), each = 3 ), nrow = 9, ncol = 1)
 colnames(F) &lt;-   paste0("F", 1:k) 
 (F)

 ## Run Example 2
 pout &lt;- rPCA(F, 
              maxit = 5000, 
              Seed = 1, 
              epsMax = 1E-18,
              PrintLevel = 1)
 pout$converged
 pout$Fhat
 eigen(pout$R)$values
if(pout$error == FALSE &amp; pout$converged){ 
    Fhat &lt;- pout$Fhat
    cat("\nPCA Loadings\n")
    ( round( cbind(F,Fhat ), 5) )
 }
  
## Example 3 ----
## 2 Component example from Goldberg and Velicer (2006).
 k = 2
 F = matrix(c( .18, .75,
               .65, .19,
               .12, .69,
               .74, .06,
               .19, .80,
               .80, .14,
              -.05, .65,
               .71, .02), 8, 2, byrow=TRUE)
 colnames(F) &lt;-   paste0("F", 1:k) 
 (F)

## Run Example 3
pout &lt;- rPCA(F, 
            maxit = 5000, 
            Seed = 1, 
            epsMax = 1E-18,
            PrintLevel = 1)
pout$converged

eigen(pout$R)$values

if(pout$error == FALSE &amp; pout$converged){ 
  Fhat &lt;- pout$Fhat
  cat("\nPCA Loadings\n")
  ( round( cbind(F,Fhat ), 5) )
#
#
## Example 4
#
SEED = 4321
set.seed(SEED)
k= 3
## Generate eigenvalues for example R matrix
L7 &lt;- eigGen(nDimensions = 7,
             nMaj = 3,
             PrcntMajor = .85,
             threshold = .8)

## Scree Plot
plot(1:7, L7, 
    type = "b", 
    ylim = c(0,4),
    main = "Scree Plot for R",
    ylab = "Eigenvalues",
    xlab = "Dimensions")

## Generate R
R &lt;- rGivens(eigs=L7, Seed = SEED)$R
print( R, digits = 4)

#Extract loadings for 3 principal components
F &lt;- PCA(R, k = k)

# rotate loadings with varimax to examine underlying structure
print( round(varimax(F)$loadings[], 3) )

## run rPCA with user-defined eigenvalues
rout &lt;- rPCA(F,
            epsMax = 1e-20, 
            maxit = 25000, 
            Seed = SEED,   
            InitP2 = 1,
            Eigs = L7,
            PrintLevel = 1) 

## Compute PCA on generated R

Fhat &lt;- PCA(rout$R, k = 3)
#
## align factors
Fhat &lt;- fungible::faAlign(F, Fhat)$F2

## Compare solutions
print( round( cbind(F, Fhat), 5) )

## Compare Eigenvalues
print( cbind(L7, eigen(rout$R)$values ), digits=8) 
#
## Compare R matrices: 8 digit accuracy
print( round(R - rout$R, 8) )

}
</code></pre>

<hr>
<h2 id='SchmidLeiman'>Schmid-Leiman Orthogonalization to a (Rank-Deficient) Bifactor Structure</h2><span id='topic+SchmidLeiman'></span>

<h3>Description</h3>

<p>The Schmid-Leiman (SL) procedure orthogonalizes a higher-order factor 
structure into a rank-deficient bifactor structure. The Schmid-Leiman method 
is a generalization of Thomson's orthogonalization routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SchmidLeiman(
  R,
  numFactors,
  facMethod = "fals",
  rotate = "oblimin",
  rescaleH2 = 0.98,
  faControl = NULL,
  rotateControl = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SchmidLeiman_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix.</p>
</td></tr>
<tr><td><code id="SchmidLeiman_+3A_numfactors">numFactors</code></td>
<td>
<p>(Vector) The number of latent factors at each level of 
analysis. For example, c(3, 1) estimates three latent factors in the first-order 
common factor model and one latent factor in the second-order common factor 
model (i.e., 3 group factors and 1 general factor). This function can 
orthogonalize up to (and including) a three-order factor solution.</p>
</td></tr>
<tr><td><code id="SchmidLeiman_+3A_facmethod">facMethod</code></td>
<td>
<p>(Character) The method used for factor extraction 
(<code><a href="#topic+faX">faX</a></code>). The supported options are &quot;fals&quot; for unweighted least 
squares, &quot;faml&quot; for maximum likelihood, &quot;fapa&quot; for iterated principal axis 
factoring, &quot;faregLS&quot; for regularized least squares,
&quot;faregML&quot; for regularized maximum likelihood, and &quot;pca&quot; for principal components 
analysis. The default method  is &quot;fals&quot;. 
</p>

<ul>
<li> <p><strong>&quot;fals&quot;</strong>: Factors are extracted using the unweighted least 
squares estimation procedure using the <code><a href="#topic+fals">fals</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faml&quot;</strong>: Factors are extracted using the maximum likelihood 
estimation procedure using the <code><a href="stats.html#topic+factanal">factanal</a></code> function.
</p>
</li>
<li> <p><strong>&quot;fapa&quot;</strong>: Factors are extracted using the iterated principal 
axis factoring estimation procedure using the <code><a href="#topic+fapa">fapa</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faregLS&quot;</strong>: Factors are extracted using regularized 
least squares factor analysis using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;faregML&quot;</strong>: Factors are extracted using regularized 
maximum likelihood factor using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;pca&quot;</strong>: Principal components are extracted. 
</p>
</li></ul>
</td></tr>
<tr><td><code id="SchmidLeiman_+3A_rotate">rotate</code></td>
<td>
<p>(Character) Designate which rotation algorithm to apply. See 
the <code><a href="#topic+faMain">faMain</a></code> function for more details about possible rotations. 
Defaults to rotate = &quot;oblimin&quot;.</p>
</td></tr>
<tr><td><code id="SchmidLeiman_+3A_rescaleh2">rescaleH2</code></td>
<td>
<p>(Numeric) If a Heywood case is detected at any level of the 
higher-order factor analyses, rescale the communality value to continue with 
the matrix algebra. When a Heywood case occurs, the uniquenesses (i.e., 
specific-factor variances) will be negative and the SL orthogonalization of 
the group factors is no longer correct.</p>
</td></tr>
<tr><td><code id="SchmidLeiman_+3A_facontrol">faControl</code></td>
<td>
<p>(List) A list of optional parameters passed to the factor 
extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>

<ul>
<li> <p><strong>treatHeywood</strong>: (Logical) In <code>fals</code>, if treatHeywood is 
true, a penalized least squares function is used to bound the communality 
estimates below 1.0. Defaults to treatHeywood = TRUE.
</p>
</li>
<li> <p><strong>nStart</strong>: (Numeric) The number of starting values to be tried 
in <code>faml</code>. Defaults to nStart = 10.
</p>
</li>
<li> <p><strong>start</strong>: (Matrix) NULL or a matrix of starting values, each column 
giving an initial set of uniquenesses. Defaults to start = NULL. 
</p>
</li>
<li> <p><strong>maxCommunality</strong>: (Numeric) In <code>faml</code>, set the maximum 
communality value for the estimated solution. Defaults to maxCommunality = .995.
</p>
</li>
<li> <p><strong>epsilon</strong>: (Numeric) In <code>fapa</code>, the numeric threshold 
designating when the algorithm has converged. Defaults to epsilon = 1e-4.
</p>
</li>
<li> <p><strong>communality</strong>: (Character) The method used to estimate the 
initial communality values in <code>fapa</code>. Defaults to communality = 'SMC'.
</p>

<ul>
<li> <p><strong>&quot;SMC&quot;</strong>: Initial communalities are estimated by taking the 
squared multiple correlations of each indicator after regressing the 
indicator on the remaining variables.
</p>
</li>
<li> <p><strong>&quot;maxr&quot;</strong>: Initial communalities equal the largest 
(absolute value) correlation in each column of the correlation matrix.
</p>
</li>
<li> <p><strong>&quot;unity&quot;</strong>: Initial communalities equal 1.0 for all variables.
</p>
</li></ul>

</li>
<li> <p><strong>maxItr</strong>: (Numeric) In <code>fapa</code>, the maximum number of 
iterations to reach convergence. Defaults to maxItr = 15,000.
</p>
</li></ul>
</td></tr>
<tr><td><code id="SchmidLeiman_+3A_rotatecontrol">rotateControl</code></td>
<td>
<p>(List) A list of control values to pass to the factor rotation algorithms.
</p>

<ul>
<li> <p><strong>numberStarts</strong>: (Numeric) The number of random (orthogonal) 
starting configurations for the chosen rotation method (e.g., oblimin). The first
rotation will always commence from the unrotated factors orientation.
Defaults to numberStarts = 10. 
</p>
</li>
<li> <p><strong>gamma</strong>: (Numeric) This is a tuning parameter (between 0 
and 1, inclusive) for an oblimin rotation.  See the <span class="pkg">GPArotation</span> 
library's oblimin documentation for more details. Defaults to gamma = 0 
(i.e., a quartimin rotation).
</p>
</li>
<li> <p><strong>delta</strong>: (Numeric) This is a tuning parameter for the geomin
rotation. It adds a small number (default = .01) to the squared factor 
loadings before computing the geometric means in the discrepancy function.
</p>
</li>
<li> <p><strong>kappa</strong>: (Numeric) The main parameterization of the 
Crawford-Ferguson (CF) rotations (i.e., &quot;cfT&quot; and &quot;cfQ&quot; for orthogonal and 
oblique CF rotation, respectively). Defaults to kappa = 0. 
</p>
</li>
<li> <p><strong>k</strong>: (Numeric) A specific parameter of the simplimax rotation. 
Defaults to k = the number of observed variables.
</p>
</li>
<li> <p><strong>standardize</strong>: (Character) The standardization routine used 
on the unrotated factor structure. The three options are &quot;none&quot;, &quot;Kaiser&quot;, 
and &quot;CM&quot;. Defaults to standardize = &quot;none&quot;. 
</p>

<ul>
<li> <p><strong>&quot;none&quot;</strong>: No standardization is applied to the unrotated 
factor structure. 
</p>
</li>
<li> <p><strong>&quot;Kaiser&quot;</strong>: Use a factor structure matrix that has been 
normed by Kaiser's method (i.e., normalize all rows to have a unit length).
</p>
</li>
<li> <p><strong>&quot;CM&quot;</strong>: Use a factor structure matrix that has been normed
by the Cureton-Mulaik method.
</p>
</li></ul>

</li>
<li> <p><strong>epsilon</strong>: (Numeric) The rotational convergence criterion to 
use. Defaults to epsilon = 1e-5.
</p>
</li>
<li> <p><strong>power</strong>: (Numeric) Raise factor loadings the the n-th power 
in the <code><a href="#topic+promaxQ">promaxQ</a></code> rotation. Defaults to power = 4.
</p>
</li>
<li> <p><strong>maxItr</strong>: (Numeric) The maximum number of iterations for the 
rotation algorithm. Defaults to maxItr = 15000.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The obtained Schmid-Leiman (SL) factor structure matrix is rescaled if 
its communalities differ from those of the  original first-order 
solution (due to the presence of one or more Heywood cases in a solution of any order). 
Rescaling will produce SL communalities that match those of 
the original first-order  solution.
</p>


<h3>Value</h3>


<ul>
<li> <p><strong>L1</strong>: (Matrix) The first-order (oblique) factor pattern matrix.
</p>
</li>
<li> <p><strong>L2</strong>: (Matrix) The second-order (oblique) factor pattern matrix.
</p>
</li>
<li> <p><strong>L3</strong>: (Matrix, NULL) The third-order (oblique) factor pattern 
matrix (if applicable).
</p>
</li>
<li> <p><strong>Phi1</strong>: (Matrix) The first-order factor correlation matrix.
</p>
</li>
<li> <p><strong>Phi2</strong>: (Matrix) The second-order factor correlation matrix.
</p>
</li>
<li> <p><strong>Phi3</strong>: (Matrix, NULL) The third-order factor pattern matrix 
(if applicable).
</p>
</li>
<li> <p><strong>U1</strong>: (Matrix) The square root of the first-order factor 
uniquenesses (i.e., factor standard deviations).
</p>
</li>
<li> <p><strong>U2</strong>: (Matrix) The square root of the second-order factor 
uniquenesses (i.e., factor standard deviations).
</p>
</li>
<li> <p><strong>U3</strong>: (Matrix, NULL) The square root of the third-order factor 
uniquenesses (i.e., factor standard deviations) (if applicable).
</p>
</li>
<li> <p><strong>B</strong>: (Matrix) The resulting Schmid-Leiman transformation.
</p>
</li>
<li> <p><strong>rotateControl</strong>: (List) A list of the control parameters 
passed to the <code><a href="#topic+faMain">faMain</a></code> function.
</p>
</li>
<li> <p><strong>faControl</strong>: (List) A list of optional parameters passed to 
the factor extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>
</li>
<li><p><strong>HeywoodFlag</strong>(Integer) An integer indicating whether one or more 
Heywood cases were encountered during estimation.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Abad, F. J., Garcia-Garzon, E., Garrido, L. E., &amp; Barrada, J. R. 
(2017). Iteration of partially specified target matrices: application to the 
bi-factor case. <em>Multivariate Behavioral Research, 52</em>(4), 416-429.
</p>
<p>Giordano, C. &amp; Waller, N. G. (under review). Recovering bifactor 
models: A comparison of seven methods.
</p>
<p>Schmid, J., &amp; Leiman, J. M. (1957). The development of 
hierarchical factor solutions. <em>Psychometrika, 22</em>(1), 53-61.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Dataset used in Schmid &amp; Leiman (1957) rounded to 2 decimal places
SLdata &lt;-
  matrix(c(1.0, .72, .31, .27, .10, .05, .13, .04, .29, .16, .06, .08,
           .72, 1.0, .35, .30, .11, .06, .15, .04, .33, .18, .07, .08,
           .31, .35, 1.0, .42, .08, .04, .10, .03, .22, .12, .05, .06,
           .27, .30, .42, 1.0, .06, .03, .08, .02, .19, .11, .04, .05,
           .10, .11, .08, .06, 1.0, .32, .13, .04, .11, .06, .02, .03,
           .05, .06, .04, .03, .32, 1.0, .07, .02, .05, .03, .01, .01,
           .13, .15, .10, .08, .13, .07, 1.0, .14, .14, .08, .03, .04,
           .04, .04, .03, .02, .04, .02, .14, 1.0, .04, .02, .01, .01,
           .29, .33, .22, .19, .11, .05, .14, .04, 1.0, .45, .15, .17,
           .16, .18, .12, .11, .06, .03, .08, .02, .45, 1.0, .08, .09,
           .06, .07, .05, .04, .02, .01, .03, .01, .15, .08, 1.0, .42,
           .08, .08, .06, .05, .03, .01, .04, .01, .17, .09, .42, 1.0),
         nrow = 12, ncol = 12, byrow = TRUE)

Out1 &lt;- SchmidLeiman(R          = SLdata,
                     numFactors = c(6, 3, 1))$B

## An orthogonalization of a two-order structure
bifactor &lt;- matrix(c(.46, .57, .00, .00,
                     .48, .61, .00, .00,
                     .61, .58, .00, .00,
                     .46, .00, .55, .00,
                     .51, .00, .62, .00,
                     .46, .00, .55, .00,
                     .47, .00, .00, .48,
                     .50, .00, .00, .50,
                     .49, .00, .00, .49),
                   nrow = 9, ncol = 4, byrow = TRUE)

## Model-implied correlation (covariance) matrix
R &lt;- bifactor %*% t(bifactor)

## Unit diagonal elements
diag(R) &lt;- 1

Out2 &lt;- SchmidLeiman(R          = R,
                     numFactors = c(3, 1),
                     rotate     = "oblimin")$B

</code></pre>

<hr>
<h2 id='seBeta'>Standard Errors and CIs for Standardized Regression Coefficients</h2><span id='topic+seBeta'></span>

<h3>Description</h3>

<p>Computes Normal Theory and ADF Standard Errors and CIs for Standardized
Regression Coefficients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seBeta(
  X = NULL,
  y = NULL,
  cov.x = NULL,
  cov.xy = NULL,
  var.y = NULL,
  Nobs = NULL,
  alpha = 0.05,
  estimator = "ADF",
  digits = 3
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seBeta_+3A_x">X</code></td>
<td>
<p>Matrix of predictor scores.</p>
</td></tr>
<tr><td><code id="seBeta_+3A_y">y</code></td>
<td>
<p>Vector of criterion scores.</p>
</td></tr>
<tr><td><code id="seBeta_+3A_cov.x">cov.x</code></td>
<td>
<p>Covariance or correlation matrix of predictors.</p>
</td></tr>
<tr><td><code id="seBeta_+3A_cov.xy">cov.xy</code></td>
<td>
<p>Vector of covariances or correlations between predictors and
criterion.</p>
</td></tr>
<tr><td><code id="seBeta_+3A_var.y">var.y</code></td>
<td>
<p>Criterion variance.</p>
</td></tr>
<tr><td><code id="seBeta_+3A_nobs">Nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="seBeta_+3A_alpha">alpha</code></td>
<td>
<p>Desired Type I error rate; default = .05.</p>
</td></tr>
<tr><td><code id="seBeta_+3A_estimator">estimator</code></td>
<td>
<p>'ADF' or 'Normal' confidence intervals - requires raw X and
raw y; default = 'ADF'.</p>
</td></tr>
<tr><td><code id="seBeta_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits to print; default = 3.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>cov.Beta</code></td>
<td>
<p>Normal theory or ADF covariance matrix of
standardized regression coefficients.</p>
</td></tr> <tr><td><code>se.Beta</code></td>
<td>
<p>standard errors for
standardized regression coefficients.</p>
</td></tr> <tr><td><code>alpha</code></td>
<td>
<p>desired Type-I error
rate.</p>
</td></tr> <tr><td><code>CI.Beta</code></td>
<td>
<p>Normal theory or ADF (1-alpha)% confidence intervals
for standardized regression coefficients.</p>
</td></tr> <tr><td><code>estimator</code></td>
<td>
<p>estimator =
&quot;ADF&quot; or &quot;Normal&quot;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Jones and Niels Waller
</p>


<h3>References</h3>

<p>Jones, J. A, and Waller, N. G. (2015). The Normal-Theory and
Asymptotic Distribution-Free (ADF) covariance matrix of standardized
regression coefficients: Theoretical extensions and finite sample behavior.
<em>Psychometrika, 80</em>, 365-378.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)

set.seed(123)

R &lt;- matrix(.5, 3, 3)
diag(R) &lt;- 1
X &lt;- mvrnorm(n = 200, mu = rep(0, 3), Sigma = R, empirical = TRUE)
Beta &lt;- c(.2, .3, .4)
y &lt;- X%*% Beta + .64 * scale(rnorm(200))
seBeta(X, y, Nobs = 200, alpha = .05, estimator = 'ADF')

# 95% CIs for Standardized Regression Coefficients:
#
#        lbound estimate ubound
# beta_1  0.104    0.223  0.341
# beta_2  0.245    0.359  0.473
# beta_3  0.245    0.360  0.476


</code></pre>

<hr>
<h2 id='seBetaCor'>Standard Errors and CIs for Standardized Regression Coefficients from
Correlations</h2><span id='topic+seBetaCor'></span>

<h3>Description</h3>

<p>Computes Normal Theory and ADF Standard Errors and CIs for Standardized
Regression Coefficients from Correlations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seBetaCor(R, rxy, Nobs, alpha = 0.05, digits = 3, covmat = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seBetaCor_+3A_r">R</code></td>
<td>
<p>A p x p predictor correlation matrix.</p>
</td></tr>
<tr><td><code id="seBetaCor_+3A_rxy">rxy</code></td>
<td>
<p>A p x 1 vector of predictor-criterion correlations</p>
</td></tr>
<tr><td><code id="seBetaCor_+3A_nobs">Nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="seBetaCor_+3A_alpha">alpha</code></td>
<td>
<p>Desired Type I error rate; default = .05.</p>
</td></tr>
<tr><td><code id="seBetaCor_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits to print; default = 3.</p>
</td></tr>
<tr><td><code id="seBetaCor_+3A_covmat">covmat</code></td>
<td>
<p>String = 'normal' (the default) or a (p+1)p/2 x (p+1)p/2
covariance matrix of correlations.  The default option computes an
asymptotic covariance matrix under the assumption of multivariate normal
data. Users can supply a covariance matrix under asymptotic distribution
free (ADF) or elliptical distributions when available.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>cov.Beta</code></td>
<td>
<p>Covariance matrix of standardized regression
coefficients.</p>
</td></tr> <tr><td><code>se.Beta</code></td>
<td>
<p>Vector of standard errors for the standardized
regression coefficients.</p>
</td></tr> <tr><td><code>alpha</code></td>
<td>
<p>Type-I error rate. </p>
</td></tr>
<tr><td><code>CI.Beta</code></td>
<td>
<p>(1-alpha)% confidence intervals for standardized regression
coefficients. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Jones and Niels Waller
</p>


<h3>References</h3>

<p>Jones, J. A, and Waller, N. G. (2013). The Normal-Theory and
asymptotic distribution-free (ADF) covariance matrix of standardized
regression coefficients: Theoretical extensions and finite sample
behavior.Technical Report (052913)[TR052913]
</p>
<p>Nel, D.A.G. (1985). A matrix derivation of the asymptotic covariance matrix
of sample correlation coefficients. <em>Linear Algebra and its
Applications, 67</em>, 137-145.
</p>
<p>Yuan, K. and Chan, W. (2011). Biases and standard errors of standardized
regression coefficients. <em>Psychometrika</em>, 76(4), 670&ndash;690.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
R &lt;- matrix(c(1.0000, 0.3511, 0.3661,
	          0.3511, 1.0000, 0.4359,
	          0.3661, 0.4359, 1.0000), 3, 3) 

rxy &lt;- c(0.5820, 0.6997, 0.7621)
Nobs &lt;- 46
out &lt;- seBetaCor(R = R, rxy = rxy, Nobs = Nobs) 

# 95% CIs for Standardized Regression Coefficients: 
#
#        lbound estimate ubound
# beta_1  0.107    0.263  0.419
# beta_2  0.231    0.391  0.552
# beta_3  0.337    0.495  0.653

</code></pre>

<hr>
<h2 id='seBetaFixed'>Covariance Matrix and Standard Errors for Standardized Regression
Coefficients for Fixed Predictors</h2><span id='topic+seBetaFixed'></span>

<h3>Description</h3>

<p>Computes Normal Theory Covariance Matrix and Standard Errors for
Standardized Regression Coefficients for Fixed Predictors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seBetaFixed(
  X = NULL,
  y = NULL,
  cov.x = NULL,
  cov.xy = NULL,
  var.y = NULL,
  var.error = NULL,
  Nobs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seBetaFixed_+3A_x">X</code></td>
<td>
<p>Matrix of predictor scores.</p>
</td></tr>
<tr><td><code id="seBetaFixed_+3A_y">y</code></td>
<td>
<p>Vector of criterion scores.</p>
</td></tr>
<tr><td><code id="seBetaFixed_+3A_cov.x">cov.x</code></td>
<td>
<p>Covariance or correlation matrix of predictors.</p>
</td></tr>
<tr><td><code id="seBetaFixed_+3A_cov.xy">cov.xy</code></td>
<td>
<p>Vector of covariances or correlations between predictors and
criterion.</p>
</td></tr>
<tr><td><code id="seBetaFixed_+3A_var.y">var.y</code></td>
<td>
<p>Criterion variance.</p>
</td></tr>
<tr><td><code id="seBetaFixed_+3A_var.error">var.error</code></td>
<td>
<p>Optional argument to supply the error variance: var(y -
yhat).</p>
</td></tr>
<tr><td><code id="seBetaFixed_+3A_nobs">Nobs</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>cov.Beta</code></td>
<td>
<p>Normal theory covariance matrix of standardized
regression coefficients for fixed predictors.</p>
</td></tr> <tr><td><code>se.Beta</code></td>
<td>
<p>Standard
errors for standardized regression coefficients for fixed predictors.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Jones and Niels Waller
</p>


<h3>References</h3>

<p>Yuan, K. &amp; Chan, W. (2011). Biases and standard errors of
standardized regression coefficients. <em>Psychometrika, 76(4)</em>, 670-690.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+seBeta">seBeta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## We will generate some data and pretend that the Predictors are being held fixed

library(MASS)
R &lt;- matrix(.5, 3, 3); diag(R) &lt;- 1
Beta &lt;- c(.2, .3, .4)

rm(list = ".Random.seed", envir = globalenv()); set.seed(123)
X &lt;- mvrnorm(n = 200, mu = rep(0, 3), Sigma = R, empirical = TRUE)
y &lt;- X %*% Beta + .64*scale(rnorm(200))

seBetaFixed(X, y)

# $covBeta
#              b1           b2           b3
# b1  0.003275127 -0.001235665 -0.001274303
# b2 -0.001235665  0.003037100 -0.001491736
# b3 -0.001274303 -0.001491736  0.002830157
# 
# $seBeta
#         b1         b2         b3 
# 0.05722872 0.05510989 0.05319922

## you can also supply covariances instead of raw data

seBetaFixed(cov.x = cov(X), cov.xy = cov(X, y), var.y = var(y), Nobs = 200)

# $covBeta
#              b1           b2           b3
# b1  0.003275127 -0.001235665 -0.001274303
# b2 -0.001235665  0.003037100 -0.001491736
# b3 -0.001274303 -0.001491736  0.002830157
# 
# $seBeta
#         b1         b2         b3 
# 0.05722872 0.05510989 0.05319922


</code></pre>

<hr>
<h2 id='semify'>Generate an sem model from a simFA model object</h2><span id='topic+semify'></span>

<h3>Description</h3>

<p>Generate an sem model from a simFA model object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semify(mod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semify_+3A_mod">mod</code></td>
<td>
<p>A 'fungible::simFA()' model object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>ex_mod &lt;- fungible::simFA(Seed = 42)
semify(mod = ex_mod)
</code></pre>

<hr>
<h2 id='simFA'>Generate Factor Analysis Models and Data Sets for Simulation Studies</h2><span id='topic+simFA'></span>

<h3>Description</h3>

<p>A function to simulate factor loadings matrices and Monte Carlo
data sets for common factor models, bifactor models, and IRT
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simFA(
  Model = list(),
  Loadings = list(),
  CrossLoadings = list(),
  Phi = list(),
  ModelError = list(),
  Bifactor = list(),
  MonteCarlo = list(),
  FactorScores = list(),
  Missing = list(),
  Control = list(),
  Seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simFA_+3A_model">Model</code></td>
<td>
<p>(list)
</p>

<ul>
<li> <p><code>NFac</code> (scalar) Number of common or group
factors; defaults to <code>NFac = 3</code>.
</p>
</li>
<li> <p><code>NItemPerFac</code>
</p>

<ul>
<li><p> (scalar) All factors have the same number
of primary loadings.
</p>
</li>
<li><p> (vector) A vector of length <code>NFac</code>
specifying the number of primary loadings for
each factor; defaults to
<code>NItemPerFac = 3</code>.
</p>
</li></ul>

</li>
<li> <p><code>Model</code> (character) <code>"orthogonal"</code> or
<code>"oblique"</code>; defaults to <code>Model = "orthogonal"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_loadings">Loadings</code></td>
<td>
<p>(list)
</p>

<ul>
<li> <p><code>FacPattern</code> (<code>NULL</code> or matrix).
</p>

<ul>
<li> <p><code>FacPattern = M</code> where <code>M</code> is
a user-defined factor pattern matrix.
</p>
</li>
<li> <p><code>FacPattern = NULL</code>; <code>simFA</code>
will generate a factor pattern based on
the arguments specified  under other keywords
(e.g., <code>Model</code>, <code>CrossLoadings</code>, etc.);
defaults to <code>FacPattern = NULL</code>.
</p>
</li></ul>

</li>
<li> <p><code>FacLoadDist</code>  (character) Specifies the
sampling distribution for the common factor loadings.
Possible values are <code>"runif"</code>, <code>"rnorm"</code>,
<code>"sequential"</code>, and <code>"fixed"</code>; defaults
to <code>FacLoadDist = "runif"</code>.
</p>
</li>
<li> <p><code>FacLoadRange</code> (vector of length <code>NFac</code>,
2, or 1); defaults to <code>FacLoadRange = c(.3, .7)</code>.
</p>

<ul>
<li><p> If <code>FacLoadDist = "runif"</code> the vector
defines the bounds of the uniform distribution;
</p>
</li>
<li><p> If <code>FacLoadDist = "rnorm"</code> the vector
defines the mean and standard deviation of
the normal distribution from which loadings
are sampled.
</p>
</li>
<li><p> If <code>FacLoadDist = "sequential"</code> the
vector specifies the lower and upper bound
of the loadings sequence.
</p>
</li>
<li><p> If <code>FacLoadDist = "fixed"</code> and
<code>FacLoadRange</code> is a vector of length 1
then all common loadings will equal the constant
specified in <code>FacLoadRange</code>. If
<code>FacLoadDist = "fixed"</code> and
<code>FacLoadRange</code> is a vector of length
<code>NFac</code> then each factor will have fixed
loadings as specified by the associated
element in <code>FacLoadRange</code>.
</p>
</li></ul>

</li>
<li> <p><code>h2</code> (vector) An optional vector of communalities
used to constrain the population communalities to
user-defined values; defaults to <code>h2 = NULL</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_crossloadings">CrossLoadings</code></td>
<td>
<p>(list)
</p>

<ul>
<li> <p><code>ProbCrossLoad</code> (scalar) A value in the (0,1)
interval that determines the probability that a cross
loading will be present in elements of the loadings
matrix that do not have salient (primary) factor loadings.
If set to <code>ProbCrossLoad = 1</code>, a single cross
loading will be added to each factor;  defaults to
<code>ProbCrossLoad = 0</code>.
</p>
</li>
<li> <p><code>CrossLoadRange</code> (vector of length 2) Controls
size of the cross loadings; defaults to
<code>CrossLoadRange = c(.20, .25)</code>.
</p>
</li>
<li> <p><code>CrossLoadPositions</code> (matrix) Specifies the
row and column positions of (optional) cross loadings;
defaults to <code>CrossLoadPositions = NULL</code>.
</p>
</li>
<li> <p><code>CrossLoadValues</code> (vector) If
<code>CrossLoadPositions</code> is specified then
<code>CrossLoadValues</code> is a vector of user-supplied
cross-loadings; defaults to <code>CrossLoadValues = NULL</code>.
</p>
</li>
<li> <p><code>CrudFactor</code> (scalar) Controls the size of
tertiary factor loadings. If <code>CrudFactor != 0</code>
then elements of the loadings matrix with neither
primary nor secondary (i.e., cross) loadings will
be sampled from a \[-(CrudFactor), (CrudFactor)\]
uniform distribution; defaults to <code>CrudFactor = 0</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_phi">Phi</code></td>
<td>
<p>(list)
</p>

<ul>
<li> <p><code>MaxAbsPhi</code> (scalar) Upper (absolute) bound
on factor correlations; defaults to
<code>MaxAbsPhi = .5</code>.
</p>
</li>
<li> <p><code>EigenValPower</code> (scalar) Controls the skewness
of the eigenvalues of Phi. Larger values of
<code>EigenValPower</code> result in a Phi spectrum that
is more right-skewed (and thus closer to a
unidimensional model); defaults to
<code>EigenValPower = 2</code>.
</p>
</li>
<li> <p><code>PhiType</code> (character); defaults to
<code>PhiType = "free"</code>.
</p>

<ul>
<li><p> If <code>PhiType = "free"</code> factor correlations
will be randomly generated under the constraints
of <code>MaxAbsPhi</code> and <code>EigenValPower</code>.
</p>
</li>
<li><p> If <code>PhiType = "fixed"</code> all factor
correlations will equal the value specified
in <code>MaxAbsPhi</code>. A fatal error will be
produced if <code>Phi</code> is not positive
semidefinite.
</p>
</li>
<li><p> If <code>PhiType = "user"</code> the factor
correlations are defined by the matrix
specified in <code>UserPhi</code> (see below).
</p>
</li></ul>

</li>
<li> <p><code>UserPhi</code> (matrix) A positive semidefinite
(PSD) matrix of user-defined factor correlations;
defaults to <code>UserPhi = NULL</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_modelerror">ModelError</code></td>
<td>
<p>(list)
</p>

<ul>
<li> <p><code>ModelError</code> (logical) If <code>ModelError = TRUE</code>
model error will be introduced into the factor
pattern via the method described by Tucker, Koopman,
and Linn (TKL, 1969); defaults to
<code>ModelError = FALSE</code>.
</p>
</li>
<li> <p><code>W</code> (matrix) An optional user-supplied factor
loading matrix for the <code>NMinorFac</code> minor common
factors; defaults to <code>W = NULL</code>.
</p>
</li>
<li> <p><code>NMinorFac</code> (scalar) Number of minor factors
in the TKL model; defaults to <code>NMinorFac = 150</code>.
</p>
</li>
<li> <p><code>ModelErrorType</code> (character) If
<code>ModelErrorType = "U"</code> then <code>ModelErrorVar</code>
is the proportion of uniqueness variance that is due
to model error. If <code>ModelErrorType = "V"</code> then
<code>ModelErrorVar</code> is the proportion of total
variance that is due to model error; defaults to
<code>ModelErrorType = "U"</code>.
</p>
</li>
<li> <p><code>ModelErrorVar</code> (scalar \[0,1\]) The proportion
of uniqueness (U) or total (V) variance that is due
to model error; defaults to
<code>ModelErrorVar = .10</code>.
</p>
</li>
<li> <p><code>epsTKL</code> (scalar \[0,1\]) Controls the size
of the factor loadings in successive minor factors;
defaults to <code>epsTKL = .20</code>.
</p>
</li>
<li> <p><code>Wattempts</code> (scalar &gt; 0)  Maximum number of
tries when attempting to generate a suitable W
matrix. Default = 10000.
</p>
</li>
<li> <p><code>WmaxLoading</code> (scalar &gt; 0) Threshold value for
<code>NWmaxLoading</code>. Default <code> WmaxLoading = .30</code>.
</p>
</li>
<li> <p><code>NWmaxLoading</code> (scalar &gt;= 0)  Maximum number
of absolute loadings &gt;= <code>WmaxLoading</code> in any
column of W (matrix of model approximation error
factor loadings). Default <code>NWmaxLoading = 2</code>.
Under the defaults, no column of W will have 3 or
more loadings &gt; |.30|.
</p>
</li>
<li> <p><code>PrintW</code> (Boolean) If <code>PrintW = TRUE</code>
then simFA will print the attempt history when
searching for a suitable W matrix given the
constraints defined in <code>WmaxLoading</code> and
<code>NWmaxLoading</code>. Default <code>PrintW = FALSE</code>.
</p>
</li>
<li> <p><code>RSpecific</code> (matrix) Optional correlation
matrix for specific factors;
defaults to <code>RSpecific = NULL</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_bifactor">Bifactor</code></td>
<td>
<p>(list)
</p>

<ul>
<li><p> Bifactor (logical) If <code>Bifactor = TRUE</code>
parameters for the bifactor model will be generated;
defaults to <code>Bifactor = FALSE</code>.
</p>
</li>
<li><p> Hierarchical (logical) If <code>Hierarchical = TRUE</code>
then a hierarchical Schmid Leiman (1957) bifactor
model will be generated;
defaults to <code>Hierarchical = FALSE</code>.
</p>
</li>
<li> <p><code>F1FactorDist</code> (character) Specifies the
sampling distribution for the general factor loadings.
Possible values are <code>"runif"</code>, <code>"rnorm"</code>,
<code>"sequential"</code>, and <code>"fixed"</code>; defaults
to <code>F1FactorDist = "sequential"</code>.
</p>
</li>
<li> <p><code>F1FactorRange</code> (vector of length 1 or 2)
Controls the sizes of the general factor loadings in
non-hierarchical bifactor models; defaults to
<code>F1FactorRange = c(.4, .7)</code>.
</p>

<ul>
<li><p> If <code>F1FactorDist = "runif"</code>, the vector
of length 2 defines the bounds of the uniform
distribution, c(lower, upper);
</p>
</li>
<li><p> If <code>F1FactorDist = "rnorm"</code>, the
vector defines the mean and standard
deviation of the normal distribution from
which loadings are sampled, c(MN, SD).
</p>
</li>
<li><p> If <code>F1FactorDist = "sequential"</code>,
the vector specifies the lower and upper
bound of the loadings sequence, c(lower, upper).
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_montecarlo">MonteCarlo</code></td>
<td>
<p>(list)
</p>

<ul>
<li> <p><code>NSamples</code> (integer) Defines number of Monte
Carlo Samples; defaults to <code>NSamples = 0</code>.
</p>
</li>
<li> <p><code>SampleSize</code> (integer) Sample size for each
Monte Carlo sample; defaults to <code>SampleSize = 250</code>.
</p>
</li>
<li> <p><code>Raw</code> (logical) If <code>Raw = TRUE</code>, simulated
data sets will contain raw data. If <code>Raw = FALSE</code>,
simulated data sets will contain correlation matrices;
defaults to <code>Raw = FALSE</code>.
</p>
</li>
<li> <p><code>Thresholds</code> (list) List elements contain
thresholds for each item. Thresholds are required
when generating Likert variables.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_factorscores">FactorScores</code></td>
<td>
<p>(list)
</p>

<ul>
<li> <p><code>FS</code> (logical) If <code>FS = TRUE</code> (true)
factor scores will be simulated; defaults to
<code>FS = FALSE</code>.
</p>
</li>
<li> <p><code>CFSeed</code> (integer) Optional starting seed for
the common factor scores; defaults to
<code>CFSeed = NULL</code> in which case a random seed is
used.
</p>
</li>
<li> <p><code>MCFSeed</code> (integer) Optional starting seed
for the minor common factor scores; defaults to
<code>MCFSeed = NULL</code>.
</p>
</li>
<li> <p><code>SFSeed</code> (integer) Optional starting seed
for the specific factor scores; defaults to
<code>SFSeed = NULL</code> in which case a random seed is
used.
</p>
</li>
<li> <p><code>EFSeed</code> (integer) Optional starting seed
for the error factor scores; defaults to
<code>EFSeed = NULL</code> in which case a random seed
is used. Note that <code>CFSeed</code>, <code>MCFSeed</code>,
<code>SFSeed</code>, and <code>EFSeed</code> must be different
numbers (a fatal error is produced when two or more
seeds are specified as equal).
</p>
</li>
<li> <p><code>VarRel</code> (vector) A vector of manifest variable
reliabilities. The specific factor variance for
variable <em>i</em> will equal <code class="reqn">VarRel[i] - h^2[i]</code>
(the manifest variable reliability minus its
commonality). By default, <code class="reqn">VarRel = h^2</code>
(resulting in uniformly zero specific factor
variances).
</p>
</li>
<li> <p><code>Population</code> (logical) If <code>Population =
        TRUE</code>, factor scores will fit the correlational
constraints of the factor model exactly (e.g., the
common factors will be orthogonal to the unique
factors); defaults to <code>Population = FALSE</code>.
</p>
</li>
<li> <p><code>NFacScores</code> (scalar) Sample size for the
factor scores; defaults to <code>NFacScores = 250</code>.
</p>
</li>
<li> <p><code>Thresholds</code> (list) A list of quantiles used
to polychotomize the observed data that will be
generated from the factor scores.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_missing">Missing</code></td>
<td>
<p>(list)
</p>

<ul>
<li><p> Missing (logical) If <code>Missing = TRUE</code> all
data sets will contain missing values; defaults to
<code>Missing = FALSE</code>.
</p>
</li>
<li> <p><code>Mechanism</code> (character) Specifies the missing
data mechanism. Currently, the program only supports
missing completely at random (MCAR):
<code>Missing = "MCAR"</code>.
</p>
</li>
<li> <p><code>MSProb</code> (scalar or vector of length
<code>NVar</code>) Specifies the probability of
missingness for each variable; defaults to
<code>MSprob = 0</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_control">Control</code></td>
<td>
<p>(list)
</p>

<ul>
<li> <p><code>IRT</code> (logical) If <code>IRT = TRUE</code> then
user-supplied thresholds will be interpreted as
item intercepts; defaults to <code>IRT = FALSE</code>.
</p>
</li>
<li> <p><code>Dparam</code> (scalar).  If <code>Dparam = 1</code> then item
intercepts should be scaled in the logistic metric.
If <code>Dparam = 1.702</code> then intercepts should be
scaled in the probit metric.
</p>
</li>
<li> <p><code>Maxh2</code> (scalar) Rows of the loadings matrix
will be rescaled to have a maximum communality of
<code>Maxh2</code>; defaults to <code>Maxh2 = .98</code>.
</p>
</li>
<li> <p><code>Reflect</code> (logical) If <code>Reflect =
        TRUE</code> loadings on the common factors will be
randomly reflected; defaults to
<code>Reflect = FALSE</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="simFA_+3A_seed">Seed</code></td>
<td>
<p>(integer) Starting seed for the random number
generator; defaults to <code>Seed = NULL</code>. When no seed
is specified by the user, the program will generate a random
seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a complete description of <code>simFA</code>'s
capabilities, users are encouraged to consult the <code>simFABook</code>
at http://users.cla.umn.edu/~nwaller/simFA/simFABook.pdf.
</p>
<p><code>simFA</code> is a program for exploring factor analysis
models via simulation studies.
After calling <code>simFA</code>  all relevant output can be saved
for further processing by calling one or more of the following
object names.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>loadings</code> A common factor or bifactor
loadings matrix.
</p>
</li>
<li> <p><code>Phi</code> A factor correlation matrix.
</p>
</li>
<li> <p><code>urloadings</code> The unrotated loadings matrix.
</p>
</li>
<li> <p><code>h2</code> A vector of item communalities.
</p>
</li>
<li> <p><code>h2PopME</code> A vector item communalities that
may include model approximation error.
</p>
</li>
<li> <p><code>Rpop</code> The model-implied population correlation
matrix.
</p>
</li>
<li> <p><code>RpopME</code> The model-implied population
correlation matrix with model error.
</p>
</li>
<li> <p><code>W</code> The factor loadings for the minor factors
(when <code>ModelError = TRUE</code>). Default = NULL.
</p>
</li>
<li> <p><code>Xm</code> That part of the observed scores that
is due to the minor common factors.
</p>
</li>
<li> <p><code>SFSvars</code>  Variances of the Specific Factors
in the metric of the observed scores.
</p>
</li>
<li> <p><code>ModelErrorFitStats</code> A list of model fit
indices (for the underlying equations, see: Bentler,
1990; Hu &amp; Bentler, 1999; Marsh, Hau, &amp; Grayson,
2005; Steiger, 2016):
</p>

<ul>
<li> <p><code>SRMR_theta</code> Standardized Root Mean
Square Residual based on the model that is
implied  by the error free major factors
only (underlying Rpop),
</p>
</li>
<li> <p><code>SRMR_thetahat</code>  Standardized Root
Mean Square Residual based on an exploratory
factor analysis of the population
correlation matrix, RpopME,
</p>
</li>
<li> <p><code>CRMR_theta</code>  Correlation Root Mean
Square Residual based on the model that is
implied  by the error free major factors
only (underlying Rpop),
</p>
</li>
<li> <p><code>CRMR_thetahat</code> Correlation Root Mean
Square Residual  based on an exploratory factor
analysis of the population correlation matrix,
RpopME,
</p>
</li>
<li> <p><code>RMSEA_theta</code> Root Mean Square Error
of Approximation (Steiger, 2016) based on the
model that is implied  by the error free major
factors only (underlying Rpop),
</p>
</li>
<li> <p><code>RMSEA_thetahat</code> Root Mean Square
Error of Approximation (Steiger, 2016) based
on an exploratory factor analysis of the
population correlation matrix, RpopME,
</p>
</li>
<li> <p><code>CFI_theta</code>  Comparative Fit Index
(Bentler, 1990) based on the model that is
implied  by the error free major factors
only (underlying Rpop),
</p>
</li>
<li> <p><code>CFI_thetahat</code> Comparative Fit Index
(Bentler, 1990)  based on an exploratory
factor analysis of the population
correlation matrix, RpopME.
</p>
</li>
<li> <p><code>Fm</code> MLE fit function for population
target model.
</p>
</li>
<li> <p><code>Fb</code> MLE fit function for population
baseline model.
</p>
</li>
<li> <p><code>DFm</code> Degrees of freedom for
population target model.
</p>
</li></ul>

</li>
<li> <p><code>CovMatrices</code> A list containing:
</p>

<ul>
<li> <p><code>CovMajor</code> The model implied
covariances from the major factors.
</p>
</li>
<li> <p><code>CovMinor</code> The model implied
covariances from the minor factors.
</p>
</li>
<li> <p><code>CovUnique</code> The model implied
variances from the uniqueness factors.
</p>
</li></ul>

</li>
<li> <p><code>Bifactor</code> A list containing:
</p>

<ul>
<li> <p><code>loadingsHier</code> Factor loadings of the
1st order solution of a hierarchical
bifactor model.
</p>
</li>
<li> <p><code>PhiHier</code> Factor correlations of the
1st order solution of a hierarchical bifactor
model.
</p>
</li></ul>

</li>
<li> <p><code>Scores</code> A list containing:
</p>

<ul>
<li> <p><code>FactorScores</code> Factor scores for the
common and uniqueness factors.
</p>
</li>
<li> <p><code>FacInd</code> Factor indeterminacy indices
for the error free population model.
</p>
</li>
<li> <p><code>FacIndME</code> Factor score indeterminacy
indices for the population model with model
error.
</p>
</li>
<li> <p><code>ObservedScores</code> A matrix of model
implied <code>ObservedScores</code>. If
<code>Thresholds</code> were supplied under
Keyword <code>FactorScores</code>,
<code>ObservedScores</code> will be transformed
into Likert scores.
</p>
</li></ul>

</li>
<li> <p><code>Monte</code> A list containing output from the
Monte Carlo simulations if generated.
</p>
</li>
<li> <p><code>IRT</code> Factor loadings expressed in the normal
ogive IRT metric. If <code>Thresholds</code> were given
then IRT difficulty values will also be returned.
</p>
</li>
<li> <p><code>Seed</code> The initial seed for the random
number generator.
</p>
</li>
<li> <p><code>call</code> A copy of the function call.
</p>
</li>
<li> <p><code>cn</code> A list of all active and nonactive
function arguments.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller with contributions by Hoang V. Nguyen
</p>


<h3>References</h3>

<p>Bentler, P. M. (1990). Comparative fit indexes in structural
models. Psychological Bulletin, 107(2), 238&ndash;246.
</p>
<p>Hu, L.-T. &amp; Bentler, P. M. (1999). Cutoff criteria for fit
indexes in covariance structure analysis: Conventional criteria
versus new alternatives. Structural Equation Modeling:
A Multidisciplinary Journal, 6(1), 1&ndash;55.
</p>
<p>Marsh, H. W., Hau, K.-T., &amp; Grayson, D. (2005). Goodness of fit
in structural equation models. In A. Maydeu-Olivares &amp; J. J.
McArdle (Eds.), Multivariate applications book series.
Contemporary psychometrics: A festschrift for Roderick P.
McDonald (p. 275&ndash;340). Lawrence Erlbaum Associates Publishers.
</p>
<p>Schmid, J. and Leiman, J. M. (1957). The development of hierarchical
factor solutions. Psychometrika, 22(1), 53&ndash;61.
</p>
<p>Steiger, J. H. (2016). Notes on the SteigerLind (1980) handout.
Structural Equation Modeling: A Multidisciplinary Journal, 23:6,
777-781.
</p>
<p>Tucker, L. R., Koopman, R. F., and Linn, R. L. (1969). Evaluation
of factor analytic research procedures by means of simulated
correlation matrices. Psychometrika, 34(4), 421&ndash;459.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run:
#  Ex 1. Three Factor Simple Structure Model with Cross loadings and
#  Ideal Non salient Loadings
   out &lt;-  simFA(Seed = 1)
   print( round( out$loadings, 2 ) )

# Ex 2. Non Hierarchical bifactor model 3 group factors
# with constant loadings on the general factor
   out &lt;- simFA(Bifactor = list(Bifactor = TRUE,
                                Hierarchical = FALSE,
                                F1FactorRange = c(.4, .4),
                                F1FactorDist = "runif"),
                Seed = 1)
   print( round( out$loadings, 2 ) )

   # Ex 3.  Model Fit Statistics for Population Data with
   # Model Approximation Error. Three Factor model.
       out &lt;- simFA(Loadings = list(FacLoadDist = "fixed",
                                    FacLoadRange = .5),
                    ModelError = list(ModelError = TRUE,
                                      NMinorFac = 150,
                                      ModelErrorType = "V",
                                      ModelErrorVar = .1,
                                      Wattempts = 10000,
                                      epsTKL = .2),
                    Seed = 1)

       print( out$loadings )
       print( out$ModelErrorFitStats[seq(2,8,2)] )

## End(**Not run**)

</code></pre>

<hr>
<h2 id='skew'>Calculate Univariate Skewness for a Vector or Matrix</h2><span id='topic+skew'></span>

<h3>Description</h3>

<p>Calculate univariate skewness for vector or matrix (algorithm G1 in Joanes &amp;
Gill, 1998).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skew(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skew_+3A_x">x</code></td>
<td>
<p>Either a vector or matrix of numeric values.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Skewness for each column in x.</code></td>
<td>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Joanes, D. N. &amp; Gill, C. A. (1998). Comparing measures of sample
skewness and kurtosis. <em>The Statistician, 47</em>, 183-189.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kurt">kurt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(rnorm(1000), 100, 10)
skew(x)

</code></pre>

<hr>
<h2 id='SLi'>Conduct a Schmid-Leiman Iterated (SLi) Target Rotation</h2><span id='topic+SLi'></span>

<h3>Description</h3>

<p>Compute an iterated Schmid-Leiman target rotation (SLi). This algorithm applies Browne's partially-specified Procrustes target rotation to obtain a full-rank bifactor solution from a rank-deficient (Direct) Schmid-Leiman procedure. Note that the target matrix is automatically generated based on the salient argument. Note also that the algorithm will converge when the partially-specified target pattern in the n-th iteration is equivalent to the partially-specified target pattern in the (n-1)th iteration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLi(
  R,
  SL = NULL,
  rotate = "geominQ",
  numFactors = NULL,
  facMethod = "fals",
  salient = 0.2,
  urLoadings = NULL,
  freelyEstG = TRUE,
  gFac = 1,
  maxSLiItr = 20,
  rotateControl = NULL,
  faControl = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SLi_+3A_r">R</code></td>
<td>
<p>(Matrix) A correlation matrix</p>
</td></tr>
<tr><td><code id="SLi_+3A_sl">SL</code></td>
<td>
<p>(Matrix, NULL) A (rank-deficient) Schmid-Leiman (SL) bifactor solution (e.g., from a Schmid-Leiman or Direct Schmid-Leiman rotation). If NULL, the function will estimate the SL solution using the <code><a href="#topic+SchmidLeiman">SchmidLeiman</a></code> function.</p>
</td></tr>
<tr><td><code id="SLi_+3A_rotate">rotate</code></td>
<td>
<p>(Character) Designate which rotation algorithm to apply. See the <code><a href="#topic+faMain">faMain</a></code> function for more details about possible rotations. A geomin rotation is the default.</p>
</td></tr>
<tr><td><code id="SLi_+3A_numfactors">numFactors</code></td>
<td>
<p>(Vector) The number of latent factors at each level of analysis. For example, c(3, 1) estimates three latent factors in the first-order common factor model and one latent factor in the second-order common factor model (i.e., 3 group factors and 1 general factor).</p>
</td></tr>
<tr><td><code id="SLi_+3A_facmethod">facMethod</code></td>
<td>
<p>(Character) The method used for factor extraction 
(<code><a href="#topic+faX">faX</a></code>). The supported options are &quot;fals&quot; for unweighted least 
squares, &quot;faml&quot; for maximum likelihood, &quot;fapa&quot; for iterated principal axis 
factoring, &quot;faregLS&quot; for regularized least squares,
&quot;faregML&quot; for regularized maximum likelihood, and &quot;pca&quot; for principal components 
analysis. The default method  is &quot;fals&quot;. 
</p>

<ul>
<li> <p><strong>&quot;fals&quot;</strong>: Factors are extracted using the unweighted least 
squares estimation procedure using the <code><a href="#topic+fals">fals</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faml&quot;</strong>: Factors are extracted using the maximum likelihood 
estimation procedure using the <code><a href="stats.html#topic+factanal">factanal</a></code> function.
</p>
</li>
<li> <p><strong>&quot;fapa&quot;</strong>: Factors are extracted using the iterated principal 
axis factoring estimation procedure using the <code><a href="#topic+fapa">fapa</a></code> function.
</p>
</li>
<li> <p><strong>&quot;faregLS&quot;</strong>: Factors are extracted using regularized 
least squares factor analysis using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;faregML&quot;</strong>: Factors are extracted using regularized 
maximum likelihood factor using the <code><a href="#topic+fareg">fareg</a></code> function. 
</p>
</li>
<li> <p><strong>&quot;pca&quot;</strong>: Principal components are extracted. 
</p>
</li></ul>
</td></tr>
<tr><td><code id="SLi_+3A_salient">salient</code></td>
<td>
<p>(Numeric) A threshold parameter used to dichotomize factor loadings to create the target matrix. The default value is .20 (in absolute value) which is based on the Abad et al., 2017 application of this method.</p>
</td></tr>
<tr><td><code id="SLi_+3A_urloadings">urLoadings</code></td>
<td>
<p>(Matrix, NULL) A full-rank matrix of unrotated factor loadings to be rotated using the (automatically generated) target matrix. If specified as NULL, a full-rank matrix of factor loadings will be extracted using the <code><a href="#topic+faX">faX</a></code> function. An unweighted least squares (&quot;fals&quot;) procedure is the default.</p>
</td></tr>
<tr><td><code id="SLi_+3A_freelyestg">freelyEstG</code></td>
<td>
<p>(Logical) Specify whether the general factor loadings are freely estimated (in the partially-specified target matrix). If set to FALSE, only general factor loadings above the salient threshold will be estimated in the partially-specified target rotation.</p>
</td></tr>
<tr><td><code id="SLi_+3A_gfac">gFac</code></td>
<td>
<p>(Numeric, Vector) The position of the general factor(s) to be estimated. Solutions with multiple general factors may be estimated. Must either (a) freely estimate all loadings on the general factors or (b) only freely estimate general factor loadings that are above the salient threshold. The default column position is 1.</p>
</td></tr>
<tr><td><code id="SLi_+3A_maxsliitr">maxSLiItr</code></td>
<td>
<p>(Numeric) The maximum number of iterations for the SLi procedure. Typically, 10 iterations is usually sufficient to converge (cf. Abad et al., 2017). The default is 20 iterations.</p>
</td></tr>
<tr><td><code id="SLi_+3A_rotatecontrol">rotateControl</code></td>
<td>
<p>(List) A list of control values to pass to the factor rotation algorithms.
</p>

<ul>
<li> <p><strong>numberStarts</strong>: (Numeric) The number of random (orthogonal) 
starting configurations for the chosen rotation method (e.g., oblimin). The first
rotation will always commence from the unrotated factors orientation.
Defaults to numberStarts = 10. 
</p>
</li>
<li> <p><strong>gamma</strong>: (Numeric) This is a tuning parameter (between 0 
and 1, inclusive) for an oblimin rotation.  See the <span class="pkg">GPArotation</span> 
library's oblimin documentation for more details. Defaults to gamma = 0 
(i.e., a quartimin rotation).
</p>
</li>
<li> <p><strong>delta</strong>: (Numeric) This is a tuning parameter for the geomin
rotation. It adds a small number (default = .01) to the squared factor 
loadings before computing the geometric means in the discrepancy function.
</p>
</li>
<li> <p><strong>kappa</strong>: (Numeric) The main parameterization of the 
Crawford-Ferguson (CF) rotations (i.e., &quot;cfT&quot; and &quot;cfQ&quot; for orthogonal and 
oblique CF rotation, respectively). Defaults to kappa = 0. 
</p>
</li>
<li> <p><strong>k</strong>: (Numeric) A specific parameter of the simplimax rotation. 
Defaults to k = the number of observed variables.
</p>
</li>
<li> <p><strong>standardize</strong>: (Character) The standardization routine used 
on the unrotated factor structure. The three options are &quot;none&quot;, &quot;Kaiser&quot;, 
and &quot;CM&quot;. Defaults to standardize = &quot;none&quot;. 
</p>

<ul>
<li> <p><strong>&quot;none&quot;</strong>: No standardization is applied to the unrotated 
factor structure. 
</p>
</li>
<li> <p><strong>&quot;Kaiser&quot;</strong>: Use a factor structure matrix that has been 
normed by Kaiser's method (i.e., normalize all rows to have a unit length).
</p>
</li>
<li> <p><strong>&quot;CM&quot;</strong>: Use a factor structure matrix that has been normed
by the Cureton-Mulaik method.
</p>
</li></ul>

</li>
<li> <p><strong>epsilon</strong>: (Numeric) The rotational convergence criterion to 
use. Defaults to epsilon = 1e-5.
</p>
</li>
<li> <p><strong>power</strong>: (Numeric) Raise factor loadings the the n-th power 
in the <code><a href="#topic+promaxQ">promaxQ</a></code> rotation. Defaults to power = 4.
</p>
</li>
<li> <p><strong>maxItr</strong>: (Numeric) The maximum number of iterations for the 
rotation algorithm. Defaults to maxItr = 15000.
</p>
</li></ul>
</td></tr>
<tr><td><code id="SLi_+3A_facontrol">faControl</code></td>
<td>
<p>(List) A list of optional parameters passed to the factor 
extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>

<ul>
<li> <p><strong>treatHeywood</strong>: (Logical) In <code>fals</code>, if treatHeywood is 
true, a penalized least squares function is used to bound the communality 
estimates below 1.0. Defaults to treatHeywood = TRUE.
</p>
</li>
<li> <p><strong>nStart</strong>: (Numeric) The number of starting values to be tried 
in <code>faml</code>. Defaults to nStart = 10.
</p>
</li>
<li> <p><strong>start</strong>: (Matrix) NULL or a matrix of starting values, each column 
giving an initial set of uniquenesses. Defaults to start = NULL. 
</p>
</li>
<li> <p><strong>maxCommunality</strong>: (Numeric) In <code>faml</code>, set the maximum 
communality value for the estimated solution. Defaults to maxCommunality = .995.
</p>
</li>
<li> <p><strong>epsilon</strong>: (Numeric) In <code>fapa</code>, the numeric threshold 
designating when the algorithm has converged. Defaults to epsilon = 1e-4.
</p>
</li>
<li> <p><strong>communality</strong>: (Character) The method used to estimate the 
initial communality values in <code>fapa</code>. Defaults to communality = 'SMC'.
</p>

<ul>
<li> <p><strong>&quot;SMC&quot;</strong>: Initial communalities are estimated by taking the 
squared multiple correlations of each indicator after regressing the 
indicator on the remaining variables.
</p>
</li>
<li> <p><strong>&quot;maxr&quot;</strong>: Initial communalities equal the largest 
(absolute value) correlation in each column of the correlation matrix.
</p>
</li>
<li> <p><strong>&quot;unity&quot;</strong>: Initial communalities equal 1.0 for all variables.
</p>
</li></ul>

</li>
<li> <p><strong>maxItr</strong>: (Numeric) In <code>fapa</code>, the maximum number of 
iterations to reach convergence. Defaults to maxItr = 15,000.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>This function iterates the Schmid-Leiman target rotation and returns several relevant output.
</p>

<ul>
<li> <p><strong>loadings</strong>: (Matrix) The bifactor solution obtain from the SLi procedure.
</p>
</li>
<li> <p><strong>iterations</strong>: (Numeric) The number of iterations required for convergence
</p>
</li>
<li> <p><strong>rotateControl</strong>: (List) A list of the control parameters passed to the <code><a href="#topic+faMain">faMain</a></code> function.
</p>
</li>
<li> <p><strong>faControl</strong>: (List) A list of optional parameters passed to the factor extraction (<code><a href="#topic+faX">faX</a></code>) function.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Abad, F. J., Garcia-Garzon, E., Garrido, L. E., &amp; Barrada, J. R. (2017). Iteration of partially specified target matrices: Application to the bi-factor case. <em>Multivariate Behavioral Research, 52</em>(4), 416-429.
</p>
<p>Giordano, C. &amp; Waller, N. G. (under review). Recovering bifactor models: A comparison of seven methods.
</p>
<p>Moore, T. M., Reise, S. P., Depaoli, S., &amp; Haviland, M. G. (2015). Iteration of partially specified target matrices: Applications in exploratory and Bayesian confirmatory factor analysis. <em>Multivariate Behavioral Research, 50</em>(2), 149-161.
</p>
<p>Reise, S. P., Moore, T. M., &amp; Haviland, M. G. (2010). Bifactor models and rotations: Exploring the extent to which multidimensional data yield univocal scale scores. <em>Journal of Personality Assessment, 92</em>(6), 544-559.
</p>
<p>Schmid, J., &amp; Leiman, J. M. (1957). The development of hierarchical factor solutions. <em>Psychometrika, 22</em>(1), 53-61.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate a bifactor model
bifactor &lt;- matrix(c(.35, .61, .00, .00,
                     .35, .61, .00, .00,
                     .35, .61, .00, .00,
                     .35, .00, .61, .00,
                     .35, .00, .61, .00,
                     .35, .00, .61, .00,
                     .35, .00, .00, .61,
                     .35, .00, .00, .61,
                     .35, .00, .00, .61),
                   nrow = 9, ncol = 4, byrow = TRUE)

## Model-implied correlation (covariance) matrix
R &lt;- bifactor %*% t(bifactor)

## Unit diagonal elements
diag(R) &lt;- 1

Out1 &lt;- SLi(R          = R,
            numFactors = c(3, 1))

</code></pre>

<hr>
<h2 id='smoothAPA'>Smooth a NPD R matrix to PD using the Alternating Projection Algorithm</h2><span id='topic+smoothAPA'></span>

<h3>Description</h3>

<p>Smooth a Non positive defnite (NPD) correlation matrix to PD using the
Alternating Projection Algorithm with Dykstra's correction via Theory
described in Higham 2002.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothAPA(R, delta = 1e-06, fixR = NULL, Wghts = NULL, maxTries = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothAPA_+3A_r">R</code></td>
<td>
<p>A p x p indefinite matrix.</p>
</td></tr>
<tr><td><code id="smoothAPA_+3A_delta">delta</code></td>
<td>
<p>Desired value of the smallest eigenvalue of smoothed matrix,
RAPA. (Default = 1e-06).</p>
</td></tr>
<tr><td><code id="smoothAPA_+3A_fixr">fixR</code></td>
<td>
<p>User-supplied integer list that instructs the program to
constrain elements in RAPA to equal corresponding elements in R. For
example if fixR = c(1,2) then smoothed matrix, RAPA[1:2,1:2] = R[1:2,1:2].
Default (fixR = NULL).</p>
</td></tr>
<tr><td><code id="smoothAPA_+3A_wghts">Wghts</code></td>
<td>
<p>A p-length vector of weights for differential variable
weighting. Default (Wghts = NULL).</p>
</td></tr>
<tr><td><code id="smoothAPA_+3A_maxtries">maxTries</code></td>
<td>
<p>Maximum number of iterations in the alternating projections
algorithm. Default (maxTries = 1000).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>RAPA</code></td>
<td>
<p>A smoothed matrix.</p>
</td></tr> <tr><td><code>delta</code></td>
<td>
<p>User-supplied delta
value.</p>
</td></tr> <tr><td><code>Wghts</code></td>
<td>
<p>User-supplied weight vector.</p>
</td></tr> <tr><td><code>fixR</code></td>
<td>
<p>User-supplied
integer list that instructs the program to constrain elements in RAPA to
equal corresponding elements in R.</p>
</td></tr> <tr><td><code>convergence</code></td>
<td>
<p>A value of 0
indicates that the algorithm located a feasible solution. A value of 1
indicates that no feasible solution was located within maxTries.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRKtB)

###################################################################
##  Replicate analyses in Table 2 of Knol and ten Berge (1989).
###################################################################

## n1 = 0,1
out&lt;-smoothAPA(R = BadRKtB, delta = .0, fixR = NULL, Wghts = NULL, maxTries=1e06)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

## n1 = 2
out&lt;-smoothAPA(R = BadRKtB, fixR =c(1,2), delta=.0, Wghts = NULL, maxTries=1e06)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

## n1 = 4
out&lt;-smoothAPA(R = BadRKtB, fixR = 1:4, delta=.0, Wghts = NULL, maxTries=1e06)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

## n1 = 5
out&lt;-smoothAPA(R = BadRKtB, fixR = 1:5, delta=0, Wghts = NULL, maxTries=1e06)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

###################################################################
##  Replicate analyses in Table 3 of Knol and ten Berge (1989).
###################################################################

## n1 = 0,1
out&lt;-smoothAPA(R = BadRKtB, delta = .05, fixR = NULL, Wghts = NULL, maxTries=1e06)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

## n1 = 2
out&lt;-smoothAPA(R = BadRKtB, fixR =c(1,2), delta=.05, Wghts = NULL, maxTries=1e06)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

## n1 = 4
out&lt;-smoothAPA(R = BadRKtB, fixR = 1:4, delta=.05, Wghts = NULL, maxTries=1e06)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

## n1 = 5
out&lt;-smoothAPA(R = BadRKtB, fixR = 1:5, delta=.05, Wghts = NULL, maxTries=1e06)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

###################################################################
## This example illustrates differential variable weighting.
## 
## Imagine a scenerio in which variables 1 &amp; 2 were collected with 
## 5 times more subjects than variables 4 - 6 then . . .
###################################################################
## n1 = 2
out&lt;-smoothAPA(R = BadRKtB, delta=.0, fixR = NULL, Wghts = c(5, 5, rep(1,4)), maxTries=1e5)
S &lt;- out$RAPA
round(S - BadRKtB,3)
normF(S - BadRKtB)
eigen(S)$val

</code></pre>

<hr>
<h2 id='smoothBY'>Smooth an NPD R matrix to PD using the Bentler Yuan 2011 method</h2><span id='topic+smoothBY'></span>

<h3>Description</h3>

<p>Smooth a NPD correlation matrix to PD using the Bentler and Yuan method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothBY(R, const = 0.98, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothBY_+3A_r">R</code></td>
<td>
<p>Indefinite Matrix.</p>
</td></tr>
<tr><td><code id="smoothBY_+3A_const">const</code></td>
<td>
<p>const is a user-defined parameter that is defined as k in
Bentler and Yuan (2011). If 0 &lt; const &lt; 1, then const is treated as a fixed
value. If const = 1 then the program will attempt to find the highest value
of const such that R is positive (semi) definite.</p>
</td></tr>
<tr><td><code id="smoothBY_+3A_eps">eps</code></td>
<td>
<p>If const = 1 then the program will iteratively reduce const by
eps until either (a) the program converges or (b) const &lt; = 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>RBY</code></td>
<td>
<p>smoothed correlation matrix.</p>
</td></tr> <tr><td><code>constant</code></td>
<td>
<p>The final
value of const.</p>
</td></tr> <tr><td><code>convergence</code></td>
<td>
<p>(Logical) a value of TRUE indicates that
the function converged.</p>
</td></tr> <tr><td><code>outStatus</code></td>
<td>
<p>Convergence state for Rcsdp::csdp
function. <br /> <br /> 0: <br /> <br /> Success. Problem solved to full accuracy <br />
<br /> 1: <br /> <br /> Success. Problem is primal infeasible <br /> <br /> 2: <br /> <br />
Success. Problem is dual infeasible <br /> <br /> 3: <br /> <br /> Partial Success.
Solution found but full accuracy was not achieved <br /> <br /> 4: <br /> <br />
Failure. Maximum number of iterations reached <br /> <br /> 5: <br /> <br /> Failure.
Stuck at edge of primal feasibility <br /> <br /> 6: <br /> <br /> Failure. Stuch at
edge of dual infeasibility <br /> <br /> 7: <br /> <br /> Failure. Lack of progress <br />
<br /> 8:<br /> <br /> Failure. X or Z (or Newton system O) is singular <br /> <br /> 9:
<br /> <br /> Failure. Detected NaN or Inf values</p>
</td></tr> </table>
<p><br /> </p>
<table>
<tr><td><code>glb</code></td>
<td>
<p>Greatest lower
bound reliability estimates.</p>
</td></tr> <tr><td><code>eps</code></td>
<td>
<p>Default value (eps = 1E-03) or
user-supplied value of eps.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Code modified from that reported in Debelak, R. &amp; Tran, U. S.
(2011).
</p>


<h3>References</h3>

<p>Bentler, P. M. &amp; Yuan, K. H.  (2011).  Positive definiteness via
off-diagonal scaling of a symmetric indefinite matrix.  <em>Psychometrika,
76</em>(1), 119&ndash;123.
</p>
<p>Debelak, R. &amp; Tran, U. S. (2013). Principal component analysis of smoothed
tetrachoric correlation matrices as a measure of dimensionality.
<em>Educational and Psychological Measurement, 73</em>(1), 63&ndash;77.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRBY)

out&lt;-smoothBY(R = BadRBY, const = .98)
cat("\nSmoothed Correlation Matrix\n")
print( round(out$RBY,8) )
cat("\nEigenvalues of smoothed matrix\n")
print( eigen(out$RBY)$val  )

</code></pre>

<hr>
<h2 id='smoothKB'>Smooth a Non PD Correlation Matrix using the Knol-Berger algorithm</h2><span id='topic+smoothKB'></span>

<h3>Description</h3>

<p>A function for smoothing a non-positive definite correlation matrix by the
method of Knol and Berger (1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothKB(R, eps = 1e+08 * .Machine$double.eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothKB_+3A_r">R</code></td>
<td>
<p>A non-positive definite correlation matrix.</p>
</td></tr>
<tr><td><code id="smoothKB_+3A_eps">eps</code></td>
<td>
<p>Small positive number to control the size of the non-scaled
smallest eigenvalue of the smoothed R matrix. Default = 1E8 *
.Machine$double.eps</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>RKB</code></td>
<td>
<p>A Smoothed (positive definite) correlation matrix.</p>
</td></tr>
<tr><td><code>eps</code></td>
<td>
<p>Small positive number to control the size of the non-scaled
smallest eigenvalue of the smoothed R matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Knol, D. L., &amp; Berger, M. P. F., (1991). Empirical comparison
between factor analysis and multidimensional item response
models.<em>Multivariate Behavioral Research, 26</em>, 457-477.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRLG)

## RKB = smoothed R
RKB&lt;-smoothKB(R=BadRLG, eps = 1E8 * .Machine$double.eps)$RKB
print(eigen(RKB)$values)


</code></pre>

<hr>
<h2 id='smoothLG'>Smooth NPD to Nearest PSD or PD Matrix</h2><span id='topic+smoothLG'></span>

<h3>Description</h3>

<p>Smoothing an indefinite matrix to a PSD matrix via theory described by Lurie
and Goldberg
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothLG(
  R,
  start.val = NULL,
  Wghts = NULL,
  PD = FALSE,
  Penalty = 50000,
  eps = 1e-07
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothLG_+3A_r">R</code></td>
<td>
<p>Indefinite Matrix.</p>
</td></tr>
<tr><td><code id="smoothLG_+3A_start.val">start.val</code></td>
<td>
<p>Optional vector of start values for Cholesky factor of S.</p>
</td></tr>
<tr><td><code id="smoothLG_+3A_wghts">Wghts</code></td>
<td>
<p>An optional matrix of weights such that the objective function
minimizes wij(rij - sij)^2, where wij is Wghts[i,j].</p>
</td></tr>
<tr><td><code id="smoothLG_+3A_pd">PD</code></td>
<td>
<p>Logical (default = FALSE). If PD = TRUE then the objective
function will smooth the least squares solution to insure Positive
Definitness.</p>
</td></tr>
<tr><td><code id="smoothLG_+3A_penalty">Penalty</code></td>
<td>
<p>A scalar weight to scale the Lagrangian multiplier. Default =
50000.</p>
</td></tr>
<tr><td><code id="smoothLG_+3A_eps">eps</code></td>
<td>
<p>A small value to add to zero eigenvalues if smoothed matrix must
be PD. Default = 1e-07.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>RLG</code></td>
<td>
<p>Lurie Goldberg smoothed matrix.</p>
</td></tr> <tr><td><code>RKB</code></td>
<td>
<p>Knol and
Berger smoothed matrix.</p>
</td></tr> <tr><td><code>convergence</code></td>
<td>
<p>0 = converged solution, 1 =
convergence failure.</p>
</td></tr> <tr><td><code>start.val</code></td>
<td>
<p>Vector of start.values.</p>
</td></tr>
<tr><td><code>gr</code></td>
<td>
<p>Analytic gradient at solution.</p>
</td></tr> <tr><td><code>Penalty</code></td>
<td>
<p>Scalar used to
scale the Lagrange multiplier.</p>
</td></tr> <tr><td><code>PD</code></td>
<td>
<p>User-supplied value of PD.</p>
</td></tr>
<tr><td><code>Wghts</code></td>
<td>
<p>Weights used to scale the squared euclidean distances.</p>
</td></tr>
<tr><td><code>eps</code></td>
<td>
<p>Value added to zero eigenvalue to produce PD matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(BadRLG)

out&lt;-smoothLG(R = BadRLG, Penalty = 50000)
cat("\nGradient at solution:", out$gr,"\n")
cat("\nNearest Correlation Matrix\n")
print( round(out$RLG,8) )

################################
##  Rousseeuw Molenbergh example
data(BadRRM)

out &lt;- smoothLG(R = BadRRM, PD=TRUE)
cat("\nGradient at solution:", out$gr,"\n")
cat("\nNearest Correlation Matrix\n")
print( round(out$RLG,8) )

## Weights for the weighted solution
W &lt;- matrix(c(1,  1, .5,
              1,  1,  1,
              .5,  1,  1), nrow = 3, ncol = 3)
tmp &lt;- smoothLG(R = BadRRM,  PD = TRUE, eps=.001)
cat("\nGradient at solution:", out$gr,"\n")
cat("\nNearest Correlation Matrix\n")
print( round(out$RLG,8) )
print( eigen(out$RLG)$val )

## Rousseeuw Molenbergh 
## non symmetric matrix
T &lt;- matrix(c(.8, -.9, -.9, 
            -1.2,  1.1, .3, 
             -.8, .4, .9),  nrow = 3, ncol = 3,byrow=TRUE)
out &lt;- smoothLG(R = T,  PD = FALSE, eps=.001)

cat("\nGradient at solution:", out$gr,"\n")
cat("\nNearest Correlation Matrix\n")
print( round(out$RLG,8) )    

</code></pre>

<hr>
<h2 id='summary.faMain'>Summary Method for an Object of Class faMain</h2><span id='topic+summary.faMain'></span>

<h3>Description</h3>

<p>This function summarizes results from a call to <strong>faMain</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'faMain'
summary(
  object,
  digits = 2,
  Set = 1,
  HPthreshold = 0.05,
  PrintLevel = 1,
  DiagnosticsLevel = 1,
  itemSort = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.faMain_+3A_object">object</code></td>
<td>
<p>(Object of class <code><a href="#topic+faMain">faMain</a></code>) The returned object 
from a call to <strong>faMain</strong>.</p>
</td></tr>
<tr><td><code id="summary.faMain_+3A_digits">digits</code></td>
<td>
<p>(Integer) Print output with user-specified number of significant digits. 
Default <code>digits = 2</code>.</p>
</td></tr>
<tr><td><code id="summary.faMain_+3A_set">Set</code></td>
<td>
<p>The argument <code>Set</code> can be specified as either an integer 
value (i.e., 1 through the number of unique solution sets) or a character 
value (i.e., 'UnSpun'). 
</p>

<ul>
<li><p><strong>Integer</strong> Summarize the solution from the specified 
solution set. If <code>Set = 1</code>, the &quot;global minimum&quot; solution is 
reported. See <code><a href="#topic+faMain">faMain</a></code> for more details about finding 
the &quot;global&quot; and local minima. 
</p>
</li>
<li><p><strong>'UnSpun'</strong> Summarize the solution from the rotated 
output that was produced by rotating from the unrotated (i.e., unspun) 
factor orientation. All other solutions are rotated from a randomly 'spun' rotation 
(i.e., by orientating the unrotated factor solution via a random orthonormal 
matrix) . 
</p>
</li></ul>
</td></tr>
<tr><td><code id="summary.faMain_+3A_hpthreshold">HPthreshold</code></td>
<td>
<p>(Numeric) User-defined threshold for declaring that the 
absolute value of a factor pattern coefficient is in a hyperplane. The hyperplane count is the number of 
near-zero (as defined by HPthreshold; see Cattell, 1978, p. 105) elements in the factor pattern matrix. 
Default <code>HPthreshold = .05</code>.</p>
</td></tr>
<tr><td><code id="summary.faMain_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(Integer) Controls the level of printing. If <code>PrintLevel = 0</code> then no output is printed. 
If <code>PrintLevel = 1</code> then the standard output 
will be printed. If <code>PrintLevel = 2</code> more extensive output (e.g., the Factor Structure Matrix) will 
be printed. Default <code>PrintLevel = 1</code>.</p>
</td></tr>
<tr><td><code id="summary.faMain_+3A_diagnosticslevel">DiagnosticsLevel</code></td>
<td>
<p>(Integer) Controls the amount of diagnostics information that is computed on the 
rotation local minima. If <code>DiagnosticsLevel = 1</code> then only the number 
of local solution sets will be reported. If <code>DiagnosticsLevel = 2</code> then
the program will determine whether all solutions within a solution set are identicial.
Default <code>DiagnosticsLevel = 1</code>.</p>
</td></tr>
<tr><td><code id="summary.faMain_+3A_itemsort">itemSort</code></td>
<td>
<p>(Logical) If TRUE, sort the order of the observed variables to produce
a &quot;staircase&quot;-like pattern. Note that this argument cannot handle bifactor models at this time.
Defaults to <code>itemSort</code> = FALSE.</p>
</td></tr>
<tr><td><code id="summary.faMain_+3A_...">...</code></td>
<td>
<p>Additional arguments affecting the summary produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>summary.faMain</strong> provides various criteria for judging the adequacy of 
the rotated factor solution(s). After reporting the number of solution sets.
(i.e., rotated solutions with the same complexity value) the following measures 
of factor adequacy are reported for each solution set:
</p>

<ul>
<li> <p><strong>Complexity Value</strong>: The rotation complexity value (see <code><a href="#topic+faMain">faMain</a></code> for details).
</p>
</li>
<li> <p><strong>Hyperplane Count</strong>: The number of near-zero loadings (defined by <strong>HPthreshold</strong>) 
for all factor patterns in a solution set (if <strong>MaxWithinSetRMSD &gt; 0</strong> then Hyperplane Count refers to 
the first factor pattern in the solution set). 
</p>
</li>
<li> <p><strong>% Cases (x 100) in Set</strong>: The percentage of factor patterns in each solution set.
</p>
</li>
<li> <p><strong>RMSD</strong>: The root mean squared deviation between the first factor pattern 
in each solution set with the first factor pattern  in the solution set specified by the <strong>Set</strong> parameter. By default, <strong>Set = 1</strong>.
</p>
</li>
<li> <p><strong>MaxWithinSetRMSD</strong>: The maximum root mean squared deviation between all within set solutions and 
the first element in the solution set. When <strong>MaxWithinSetRMSD &gt; 0</strong> then the solution 
set contains non-identical rotated factor patterns with identical complexity values. 
</p>
</li>
<li> <p><strong>Converged</strong>: A Logical (TRUE/FALSE) that  indicates whether the first solution 
in a solution set  has a TRUE convergence status. 
</p>
</li></ul>

<p>Note that  the printed factor pattern is not sorted even if <strong>itemSort</strong> 
is requested in <a href="#topic+faMain">faMain</a>.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>loadings</code> (Matrix) Factor loadings for the solution associated with the 
minimum (maximum) rotation complexity value (default) or the user-chosen solution.
</p>
</li>
<li> <p><code>Phi</code> (Matrix) Factor correlation matrix for the solution associated with the 
minimum (maximum) rotation complexity value (default) or the user-chosen solution.
</p>
</li>
<li> <p><code>FS</code> (Matrix) Factor structure matrix  for the solution associated with the 
minimum (maximum) rotation complexity value (default) or the user-chosen solution.
</p>
</li>
<li> <p><code>Set</code> (Integer) The returned Set number. 
</p>
</li>
<li> <p><code>h2</code> (Matrix) Communalities for the returned factor solution. If <code>Boostrap = TRUE</code> then
<code>h2</code> also returns the bootstrap standard errors and associated confidence bounds from 
the bootstrap distribution.
</p>
</li>
<li><p>facIndeterminacy (Vector) Factor Indeterminacy values (correlations between the factors and factor scores). If <code>Boostrap = TRUE</code> then
<code>facIndeterminacy</code> also returns the bootstrap standard errors and associated confidence bounds from 
the boostrap distribution.          
</p>
</li>
<li> <p><code>SetComplexityValues</code> (Vector) Rotation complexity value for each solution set. 
</p>
</li>
<li> <p><code>HP_counts</code> (Vector) Hyperplane count for each solution set.  
</p>
</li>
<li> <p><code>MaxWithinSetRMSD</code> (Vector) If <code>DiagnosticsLevel = 2</code> the the program will compute
within set RMSD values.  These values represent the root mean squared deviations of each 
within set solution with the first solution in a set. If the <code>MaxWithinSetRMSD = 0</code> 
for a set, then all within set solutions are identical. If  <code>MaxWithinSetRMSD &gt; 0</code> 
then at least one solution differs from the remaining solutions within a set (i.e., two solutions 
with different factor loadings produced identical complexity values). 
</p>
</li>
<li> <p><code>RMSD</code> (Numeric) The root mean squared deviation between the 
observed and model-implied correlation matrix.
</p>
</li>
<li> <p><code>RMSAD</code> (Numeric) The root mean squared absolute deviation between the 
observed and model-implied correlation matrix. 
</p>
</li>
<li> <p><code>NumberLocalSolutions</code> (Integer) The number of local solution sets.     
</p>
</li>
<li> <p><code>LocalSolutions</code> (List) A list of local solutions (factor loadings, factor correlations, etc). 
</p>
</li>
<li><p><code>rotate</code> Designates which rotation method was applied.
</p>
</li>
<li><p><code>itemOrder</code> The item order of the (possibly) sorted factor loadings.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Cattell, R. (1978). The scientific use of factor analysis in behavioral and life sciences. 
New York, New York, Plenum.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMB">summary.faMB</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load Thurstone's Box data from the fungible library
library(fungible)
data(Box26)

## Create a matrix from Thurstone's solution
## Used as a target matrix to sort columns of the estimated solution
ThurstoneSolution &lt;- matrix(c(   .95,  .01,  .01,
                                 .02,  .92,  .01,
                                 .02,  .05,  .91,
                                 .59,  .64, -.03,
                                 .60,  .00,  .62,
                                -.04,  .60,  .58,
                                 .81,  .38,  .01,
                                 .35,  .79,  .01,
                                 .79, -.01,  .41,
                                 .40, -.02,  .79,
                                -.04,  .74,  .40,
                                -.02,  .41,  .74,
                                 .74, -.77,  .06,
                                -.74,  .77, -.06,
                                 .74,  .02, -.73,
                                -.74, -.02,  .73,
                                -.07,  .80, -.76,
                                 .07, -.80,  .76,
                                 .51,  .70, -.03,
                                 .56, -.04,  .69,
                                -.02,  .60,  .58,
                                 .50,  .69, -.03,
                                 .52, -.01,  .68,
                                -.01,  .60,  .55,
                                 .43,  .46,  .45,
                                 .31,  .51,  .46), nrow = 26, ncol = 3,
                                                            byrow=TRUE)
## Example 1: Multiple solution sets.
## Ignore warnings about non-positive definite sample correlation matrix
suppressWarnings(
  fout &lt;- faMain(R             = Box26,
                 numFactors    = 3,
                 facMethod     = 'faregLS',
                 rotate        = 'infomaxQ',
                 targetMatrix  = ThurstoneSolution,
                 rotateControl = 
                   list(numberStarts = 25, ## increase in real problem
                        standardize  = 'none'),
                 Seed          = 123)
)

## Summarize the factor analytic output                                     
summary(object           = fout, 
        digits           = 2,
        Set              = 2, 
        HPthreshold      = .10,
        PrintLevel       = 1,
        DiagnosticsLevel = 2)
          
     
## Example 2: Bootstrap Illustration 
## Step 1: In an initial analysis, confirm that all rotations converge
  ## to a single minimum complexity value.
## Step 2: If Step 1 is satisfied then generate bootstrap samples.

## Load Amazon box data             
data("AmzBoxes")

## Convert box dimensions into Thurstone's indicators
BoxData &lt;- 
  GenerateBoxData(AmzBoxes[, 2:4],          ## Select columns 2, 3, &amp; 4
                  BoxStudy         = 26,    ## 26 indicators
                  Reliability      = 0.75,  ## Add unreliability
                  SampleSize       = 200,   ## Add sampling error
                  ModApproxErrVar  = 0.1,   ## Add model approx error
                  NMinorFac        = 50,    ## Number of minor factors
                  epsTKL           = 0.2,   ## Spread of minor factor influence
                  SeedErrorFactors = 1,     ## Reproducible starting seed
                  SeedMinorFactors = 2,     ## Reproducible starting seed
                  PRINT            = FALSE, ## Suppress some output
                  LB               = FALSE, ## Do not set lower-bounds
                  LBVal            = 1,     ## Lower bound value (ignored)
                  Constant         = 0)     ## Do not add constant to data
                           
## Analyze new box data with added measurement error
fout &lt;- faMain(X             = BoxData$BoxDataE,
               numFactors    = 3,
               facMethod     = 'fapa',
               rotate        = 'infomaxQ',
               targetMatrix  = ThurstoneSolution,
               bootstrapSE   = FALSE,
               rotateControl = 
                 list(numberStarts = 25, ## increase in real problem
                      standardize  = 'CM'),
               Seed          = 1)
               
## Summarize factor analytic output                
sout &lt;- summary(object     = fout, 
                Set        = 1,
                PrintLevel = 1)
                
## Generate bootstrap samples
fout &lt;- faMain(X             = BoxData$BoxDataE,
               numFactors    = 3,
               facMethod     = 'fapa',
               rotate        = 'infomaxQ',
               targetMatrix  = ThurstoneSolution,
               bootstrapSE   = TRUE,
               numBoot       = 25,   ## increase in real problem
               rotateControl = 
                 list(numberStarts = 1,
                      standardize  = 'CM'),
               Seed          = 1)

## Summarize factor analytic output with bootstraps
sout &lt;- summary(object     = fout, 
                Set        = 1,
                PrintLevel = 2)  
                  
 ## To print a specific solution without computing diagnostics and 
   ## summary information, use the print function.
 
   print(fout, 
         Set = 1)                 
 
</code></pre>

<hr>
<h2 id='summary.faMB'>Summary Method for an Object of Class faMB</h2><span id='topic+summary.faMB'></span>

<h3>Description</h3>

<p>This function summarizes results from a call to <strong>faMB</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'faMB'
summary(
  object,
  digits = 2,
  Set = 1,
  HPthreshold = 0.05,
  PrintLevel = 1,
  DiagnosticsLevel = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.faMB_+3A_object">object</code></td>
<td>
<p>(Object of class <code><a href="#topic+faMB">faMB</a></code>) The returned object 
from a call to <strong>faMB</strong>.</p>
</td></tr>
<tr><td><code id="summary.faMB_+3A_digits">digits</code></td>
<td>
<p>(Integer) Print output with user-specified number of significant digits. 
Default <code>digits = 2</code>.</p>
</td></tr>
<tr><td><code id="summary.faMB_+3A_set">Set</code></td>
<td>
<p>The argument <code>Set</code> can be specified as either an integer 
value (i.e., 1 through the number of unique solution sets) or a character 
value (i.e., 'UnSpun'). 
</p>

<ul>
<li><p><strong>Integer</strong> Summarize the solution from the specified 
solution set. If <code>Set = 1</code>, the &quot;global minimum&quot; solution is 
reported. See <code><a href="#topic+faMain">faMain</a></code> for more details about finding 
the &quot;global&quot; and local minima. 
</p>
</li>
<li><p><strong>'UnSpun'</strong> Summarize the solution from the rotated 
output that was produced by rotating from the unrotated (i.e., unspun) 
factor orientation. All other solutions are rotated from a randomly 'spun' rotation 
(i.e., by orientating the unrotated factor solution via a random orthonormal 
matrix) . 
</p>
</li></ul>
</td></tr>
<tr><td><code id="summary.faMB_+3A_hpthreshold">HPthreshold</code></td>
<td>
<p>(Numeric) User-defined threshold for declaring that the 
absolute value of a factor pattern coefficient is in a hyperplane. The hyperplane count is the number of 
near-zero (as defined by HPthreshold; see Cattell, 1978, p. 105) elements in the factor pattern matrix. 
Default <code>HPthreshold = .05</code>.</p>
</td></tr>
<tr><td><code id="summary.faMB_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(Integer) Controls the level of printing. If <code>PrintLevel = 0</code> then no output is printed. 
If <code>PrintLevel = 1</code> then the standard output 
will be printed. If <code>PrintLevel = 2</code> more extensive output (e.g., the Factor Structure Matrix, 
the Residuals Matrix [i.e., Observed - fitted R]) will 
be printed. Default <code>PrintLevel = 1</code>.</p>
</td></tr>
<tr><td><code id="summary.faMB_+3A_diagnosticslevel">DiagnosticsLevel</code></td>
<td>
<p>(Integer) Controls the amount of diagnostics information that is computed on the 
rotation local minima. If <code>DiagnosticsLevel = 1</code> then only the number 
of local solution sets will be reported. If <code>DiagnosticsLevel = 2</code> then
the program will determine whether all solutions within a solution set are identicial.
Default <code>DiagnosticsLevel = 1</code>.</p>
</td></tr>
<tr><td><code id="summary.faMB_+3A_...">...</code></td>
<td>
<p>Additional arguments affecting the summary produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>summary.faMB</strong> provides various criteria for judging the adequacy of 
the rotated factor solution(s). After reporting the number of solution sets.
(i.e., rotated solutions with the same complexity value) the following measures 
of factor adequacy are reported for each solution set:
</p>

<ul>
<li> <p><strong>Complexity Value</strong>: The rotation complexity value (see <code><a href="#topic+faMain">faMain</a></code> for details).
</p>
</li>
<li> <p><strong>Hyperplane Count</strong>: The number of near-zero loadings (defined by <strong>HPthreshold</strong>) 
for all factor patterns in a solution set (if <strong>MaxWithinSetRMSD &gt; 0</strong> then Hyperplane Count refers to 
the first factor pattern in the solution set). 
</p>
</li>
<li> <p><strong>% Cases (x 100) in Set</strong>: The percentage of factor patterns in each solution set.
</p>
</li>
<li> <p><strong>RMSD</strong>: The root mean squared deviation between the first factor pattern 
in each solution set with the first factor pattern  in the solution set specified by the <strong>Set</strong> parameter. By default, <strong>Set = 1</strong>.
</p>
</li>
<li> <p><strong>MaxWithinSetRMSD</strong>: The maximum root mean squared deviation between all within set solutions and 
the first element in the solution set. When <strong>MaxWithinSetRMSD &gt; 0</strong> then the solution 
set contains non-identical rotated factor patterns with identical complexity values. 
</p>
</li>
<li> <p><strong>Converged</strong>: A Logical (TRUE/FALSE) that  indicates whether all within set rotations converged.
</p>
</li></ul>



<h3>Value</h3>


<ul>
<li> <p><code>loadings</code> (Matrix) Factor loadings for the solution associated with the 
minimum (maximum) rotation complexity value (default) or the user-chosen solution.
</p>
</li>
<li> <p><code>Phi</code> (Matrix) Factor correlation matrix for the solution associated with the 
minimum (maximum) rotation complexity value (default) or the user-chosen solution.
</p>
</li>
<li> <p><code>FS</code> (Matrix) Factor structure matrix  for the solution associated with the 
minimum (maximum) rotation complexity value (default) or the user-chosen solution.
</p>
</li>
<li> <p><code>Set</code> (Integer) The returned Set number. 
</p>
</li>
<li> <p><code>facIndeterminacy</code> (Matrix) Factor Indeterminacy values. 
</p>
</li>
<li> <p><code>SetComplexityValues</code> (vector) Rotation complexity value for each solution set. 
</p>
</li>
<li> <p><code>HP_counts</code> (vector) Hyperplane count for each solution set.  
</p>
</li>
<li> <p><code>MaxWithinSetRMSD</code> (vector) If <code>DiagnosticsLevel = 2</code> the the program will compute
within set RMSD values.  These values represent the root mean squared deviations of each 
within set solution with the first solution in a set. If the <code>MaxWithinSetRMSD = 0</code> 
for a set, then all within set solutions are identical. If  <code>MaxWithinSetRMSD &gt; 0</code> 
then at least one solution differs from the remaining solutions within a set (i.e., two solutions 
with different factor loadings produced identical complexity values). 
</p>
</li>
<li> <p><code>ChiSq</code> (Numeric) Chi-square goodness of fit value. As recommended by Browne (1979), 
we apply Lawley's (1959) correction when computing the chi-square value when <code>NB = 2</code>.
</p>
</li>
<li> <p><code>DF</code> (Numeric) Degrees of freedom for the estimated model. 
</p>
</li>
<li> <p><code>pvalue</code> (Numeric) P-value associated with the above chi-square statistic.
</p>
</li>
<li> <p><code>AIC</code> (Numeric) Akaike's Information Criterion where a lower value indicates better fit. 
</p>
</li>
<li> <p><code>BIC</code> (Numeric) Bayesian Information Criterion where a lower value indicates better fit. 
</p>
</li>
<li> <p><code>RMSEA</code> (Numeric) The root mean squared error of approximation (Steiger &amp; Lind, 1980).
</p>
</li>
<li> <p><code>Resid</code> (Matrix) The residuals matrix (R - Rhat). 
</p>
</li>
<li> <p><code>NumberLocalSolutions</code> (Integer) The number of local solution sets.     
</p>
</li>
<li> <p><code>LocalSolutions</code> (List) A list of local solutions (factor loadings, factor correlations, etc). 
</p>
</li>
<li><p><code>rotate</code> Designates which rotation method was applied.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li>
<li><p> Casey Giordano (Giord023@umn.edu)
</p>
</li></ul>



<h3>References</h3>

<p>Cattell, R. (1978). The scientific use of factor analysis in behavioral and life sciences. 
New York, New York, Plenum.
</p>


<h3>See Also</h3>

<p>Other Factor Analysis Routines: 
<code><a href="#topic+BiFAD">BiFAD</a>()</code>,
<code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a>()</code>,
<code><a href="#topic+Ledermann">Ledermann</a>()</code>,
<code><a href="#topic+SLi">SLi</a>()</code>,
<code><a href="#topic+SchmidLeiman">SchmidLeiman</a>()</code>,
<code><a href="#topic+faAlign">faAlign</a>()</code>,
<code><a href="#topic+faEKC">faEKC</a>()</code>,
<code><a href="#topic+faIB">faIB</a>()</code>,
<code><a href="#topic+faLocalMin">faLocalMin</a>()</code>,
<code><a href="#topic+faMB">faMB</a>()</code>,
<code><a href="#topic+faMain">faMain</a>()</code>,
<code><a href="#topic+faScores">faScores</a>()</code>,
<code><a href="#topic+faSort">faSort</a>()</code>,
<code><a href="#topic+faStandardize">faStandardize</a>()</code>,
<code><a href="#topic+faX">faX</a>()</code>,
<code><a href="#topic+fals">fals</a>()</code>,
<code><a href="#topic+fapa">fapa</a>()</code>,
<code><a href="#topic+fareg">fareg</a>()</code>,
<code><a href="#topic+fsIndeterminacy">fsIndeterminacy</a>()</code>,
<code><a href="#topic+orderFactors">orderFactors</a>()</code>,
<code><a href="#topic+print.faMB">print.faMB</a>()</code>,
<code><a href="#topic+print.faMain">print.faMain</a>()</code>,
<code><a href="#topic+promaxQ">promaxQ</a>()</code>,
<code><a href="#topic+summary.faMain">summary.faMain</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># These examples reproduce published multiple battery analyses. 

# ----EXAMPLE 1: Browne, M. W. (1979)----
#
# Data originally reported in:
# Thurstone, L. L. &amp; Thurstone, T. G. (1941). Factorial studies 
# of intelligence. Psychometric Monograph (2), Chicago: Univ. 
# Chicago Press.

## Load Thurstone &amp; Thurstone's data used by Browne (1979)
data(Thurstone41)

Example1Output &lt;-  faMB(R             = Thurstone41, 
                        n             = 710,
                        NB            = 2, 
                        NVB           = c(4,5), 
                        numFactors    = 2,
                        rotate        = "oblimin",
                        rotateControl = list(standardize = "Kaiser"))
                        
## Call the summary function
summary(Example1Output)

# ----EXAMPLE 2: Browne, M. W. (1980)----
# Data originally reported in:
# Jackson, D. N. &amp; Singer, J. E. (1967). Judgments, items and 
# personality. Journal of Experimental Research in Personality, 20, 70-79.

## Load Jackson and Singer's dataset
data(Jackson67)

Example2Output &lt;-  faMB(R             = Jackson67, 
                        n             = 480,
                        NB            = 5, 
                        NVB           = rep(4,5), 
                        numFactors    = 4,
                        rotate        = "varimax",
                        rotateControl = list(standardize = "Kaiser"),
                        PrintLevel    = 1)

## Call the summary function
summary(object     = Example2Output,
        Set        = 1,
        PrintLevel = 1)

# ----EXAMPLE 3: Cudeck (1982)----
# Data originally reported by:
# Malmi, R. A., Underwood, B. J., &amp; Carroll, J. B. (1979).
# The interrelationships among some associative learning tasks. 
# Bulletin of the Psychonomic Society, 13(3), 121-123. DOI: 10.3758/BF03335032 

## Load Malmi et al.'s dataset
data(Malmi79)

Example3Output &lt;- faMB(R             = Malmi79, 
                       n             = 97,
                       NB            = 3, 
                       NVB           = c(3, 3, 6), 
                       numFactors    = 2,
                       rotate        = "oblimin",
                       rotateControl = list(standardize = "Kaiser"))

## Call the summary function
summary(object     = Example3Output,
        Set        = 1,
        PrintLevel = 2)
        
# ----Example 4: Cudeck (1982)----
# Data originally reported by: 
# Boruch, R. F., Larkin, J. D., Wolins, L. and MacKinney, A. C. (1970). 
#  Alternative methods of analysis: Multitrait-multimethod data. Educational 
#  and Psychological Measurement, 30,833-853.

## Load Boruch et al.'s dataset
data(Boruch70)

Example4Output &lt;- faMB(R             = Boruch70,
                       n             = 111,
                       NB            = 2,
                       NVB           = c(7,7),
                       numFactors    = 2,
                       rotate        = "oblimin",
                       rotateControl = list(standardize  = "Kaiser",
                                            numberStarts = 100))

## Call the summary function
summary(Example4Output)

</code></pre>

<hr>
<h2 id='summary.monte'>Summary Method for an Object of Class Monte</h2><span id='topic+summary.monte'></span><span id='topic+print.summary.monte'></span>

<h3>Description</h3>

<p>summary method for class &ldquo;monte&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'monte'
summary(
  object,
  digits = 3,
  compute.validities = FALSE,
  Total.stats = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.monte_+3A_object">object</code></td>
<td>
<p>An object of class <code>monte</code>, usually, a result of a call
to <code>monte</code>.</p>
</td></tr>
<tr><td><code id="summary.monte_+3A_digits">digits</code></td>
<td>
<p>Number of digits to print. Default = 3.</p>
</td></tr>
<tr><td><code id="summary.monte_+3A_compute.validities">compute.validities</code></td>
<td>
<p>Logical: If TRUE then the program will calculate
the indicator validities (eta^2) for the generated data.</p>
</td></tr>
<tr><td><code id="summary.monte_+3A_total.stats">Total.stats</code></td>
<td>
<p>Logical: If TRUE then the program will return the
following statistics for the total sample: (1) indicator correlation matrix,
(2) indicator skewness, (3) indicator kurtosis.</p>
</td></tr>
<tr><td><code id="summary.monte_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Various descriptive statistics will be computed within groups
including&quot;
</p>

<dl>
<dt>clus.size</dt><dd><p>Number of objects within each group.</p>
</dd>
<dt>centroids</dt><dd><p>Group centroids.</p>
</dd>
<dt>var.matrix</dt><dd><p>Within group variances.</p>
</dd>
<dt>cor.list</dt><dd><p>Expected within group correlations.</p>
</dd>
<dt>obs.cor</dt><dd><p>Observed within group correlations.</p>
</dd>
<dt>skew.list</dt><dd><p>Expected within group indicator skewness values.</p>
</dd>
<dt>obs.skew</dt><dd><p>Observed within group indicator skewness values.</p>
</dd>
<dt>kurt.list</dt><dd><p>Expected within group indicator kurtosis values.</p>
</dd>
<dt>obs.kurt</dt><dd><p>Observed within group indicator kurtosis values.</p>
</dd>
<dt>validities</dt><dd><p>Observed indicator validities.</p>
</dd>
<dt>Total.cor</dt><dd><p>Total sample correlation matrix.</p>
</dd>
<dt>Total.skew</dt><dd><p>Total sample indicator skewness.</p>
</dd>
<dt>Total.kurt</dt><dd><p>Total sample indicator kurtosis.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
## set up a 'monte' run for the Fisher iris data

sk.lst &lt;- list(c(0.120,  0.041,  0.106,  1.254),                     #
                c(0.105, -0.363, -0.607, -0.031),
                c(0.118,  0.366,  0.549, -0.129) )
              
              
kt.lst &lt;- list(c(-0.253, 0.955,  1.022,  1.719),
                c(-0.533,-0.366,  0.048, -0.410),
                c( 0.033, 0.706, -0.154, -0.602))
                
cormat &lt;- lapply(split(iris[,1:4],iris[,5]), cor)

my.iris &lt;- monte(seed = 123, nvar = 4, nclus = 3, cor.list = cormat, 
	              clus.size = c(50, 50, 50),
                eta2 = c(0.619, 0.401, 0.941, 0.929), 
                random.cor = FALSE,
                skew.list = sk.lst, kurt.list = kt.lst, 
                secor = .3, 
                compactness = c(1, 1, 1), 
                sortMeans = TRUE)
summary(my.iris)

</code></pre>

<hr>
<h2 id='summary.monte1'>Summary Method for an Object of Class Monte1</h2><span id='topic+summary.monte1'></span><span id='topic+print.summary.monte1'></span>

<h3>Description</h3>

<p>summary method for class &quot;monte1&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'monte1'
summary(object, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.monte1_+3A_object">object</code></td>
<td>
<p>An object of class <code>monte1</code>, usually, a result of a call
to <code>monte1</code>.</p>
</td></tr>
<tr><td><code id="summary.monte1_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits to print in final results.</p>
</td></tr>
<tr><td><code id="summary.monte1_+3A_...">...</code></td>
<td>
<p>Additional argument affecting the summary produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Various descriptive statistics will be computed including
</p>

<ol>
<li><p>Expected correlation matrix.
</p>
</li>
<li><p>Observed correlation matrix.
</p>
</li>
<li><p>Expected indicator skewness values.
</p>
</li>
<li><p>Observed indicator skewness values.
</p>
</li>
<li><p>Expected indicator kurtosis values.
</p>
</li>
<li><p>Observed indicator kurtosis values.
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>
## Generate dimensional data for 4 variables. 
## All correlations = .60; all variable
## skewness = 1.75; 
## all variable kurtosis = 3.75

cormat &lt;- matrix(.60, 4, 4)
diag(cormat) &lt;- 1

nontaxon.dat &lt;- monte1(seed = 123, nsub = 100000, nvar = 4, skewvec = rep(1.75, 4),
                 kurtvec = rep(3.75, 4), cormat = cormat)

summary(nontaxon.dat)

</code></pre>

<hr>
<h2 id='svdNorm'>Compute theta surrogates via normalized SVD scores</h2><span id='topic+svdNorm'></span>

<h3>Description</h3>

<p>Compute theta surrogates by calculating the normalized left singular vector
of a (mean-centered) data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svdNorm(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="svdNorm_+3A_data">data</code></td>
<td>
<p>N(subjects)-by-p(items) matrix of 0/1 item response data.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>the normalized left singular vector of the mean centered data
matrix.</code></td>
<td>
<p><code>svdNorm</code> will center the data automatically.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
NSubj &lt;- 2000

## example item parameters for sample data: k=1 FMP 
b &lt;- matrix(c(
    #b0    b1     b2    b3      b4   b5 b6 b7  k
  1.675, 1.974, -0.068, 0.053,  0,  0,  0,  0, 1,
  1.550, 1.805, -0.230, 0.032,  0,  0,  0,  0, 1,
  1.282, 1.063, -0.103, 0.003,  0,  0,  0,  0, 1,
  0.704, 1.376, -0.107, 0.040,  0,  0,  0,  0, 1,
  1.417, 1.413,  0.021, 0.000,  0,  0,  0,  0, 1,
 -0.008, 1.349, -0.195, 0.144,  0,  0,  0,  0, 1,
  0.512, 1.538, -0.089, 0.082,  0,  0,  0,  0, 1,
  0.122, 0.601, -0.082, 0.119,  0,  0,  0,  0, 1,
  1.801, 1.211,  0.015, 0.000,  0,  0,  0,  0, 1,
 -0.207, 1.191,  0.066, 0.033,  0,  0,  0,  0, 1,
 -0.215, 1.291, -0.087, 0.029,  0,  0,  0,  0, 1,
  0.259, 0.875,  0.177, 0.072,  0,  0,  0,  0, 1,
 -0.423, 0.942,  0.064, 0.094,  0,  0,  0,  0, 1,
  0.113, 0.795,  0.124, 0.110,  0,  0,  0,  0, 1,
  1.030, 1.525,  0.200, 0.076,  0,  0,  0,  0, 1,
  0.140, 1.209,  0.082, 0.148,  0,  0,  0,  0, 1,
  0.429, 1.480, -0.008, 0.061,  0,  0,  0,  0, 1,
  0.089, 0.785, -0.065, 0.018,  0,  0,  0,  0, 1,
 -0.516, 1.013,  0.016, 0.023,  0,  0,  0,  0, 1,
  0.143, 1.315, -0.011, 0.136,  0,  0,  0,  0, 1,
  0.347, 0.733, -0.121, 0.041,  0,  0,  0,  0, 1,
 -0.074, 0.869,  0.013, 0.026,  0,  0,  0,  0, 1,
  0.630, 1.484, -0.001, 0.000,  0,  0,  0,  0, 1), 
  nrow=23, ncol=9, byrow=TRUE)  
 
# generate data using the above item paramters
data&lt;-genFMPData(NSubj=NSubj, bParam=b, seed=345)$data

# compute (initial) surrogate theta values from 
# the normed left singular vector of the centered 
# data matrix
thetaInit&lt;-svdNorm(data)

</code></pre>

<hr>
<h2 id='TaylorRussell'>A generalized (multiple predictor) Taylor-Russell function.</h2><span id='topic+TaylorRussell'></span>

<h3>Description</h3>

<p>Generalized Taylor-Russell Function for Multiple Predictors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TaylorRussell(SR = NULL, BR = NULL, R = NULL, PrintLevel = 0, Digits = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TaylorRussell_+3A_sr">SR</code></td>
<td>
<p>(vector)  A vector of Selection Ratios for N selection tests.</p>
</td></tr>
<tr><td><code id="TaylorRussell_+3A_br">BR</code></td>
<td>
<p>(scalar)  The Base Rate of criterion performance.</p>
</td></tr>
<tr><td><code id="TaylorRussell_+3A_r">R</code></td>
<td>
<p>(matrix)  An (N + 1) x (N + 1) correlation matrix in which the 
predictor/criterion correlations are in column  N + 1 of R.</p>
</td></tr>
<tr><td><code id="TaylorRussell_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(integer). If <code>PrintLevel = 0</code> then no output is 
printed to screen. If <code>PrintLevel &gt; 0</code> then output is printed to screen. 
Defaults to <code>PrintLevel = 0</code>.</p>
</td></tr>
<tr><td><code id="TaylorRussell_+3A_digits">Digits</code></td>
<td>
<p>(integer)  The number of significant digits in the printed 
output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The following output variables are returned.
</p>

<ul>
<li> <p><strong>BR</strong>: (scalar) The Base Rate of criterion performance. 
</p>
</li>
<li> <p><strong>SR</strong>: (vector) The user-defined vector of predictor Selection 
Ratios.
</p>
</li>
<li> <p><strong>R</strong>: (matrix) The input correlation matrix.  
</p>
</li>
<li> <p><strong>TP</strong>: (scalar) The percentage of True Positives.
</p>
</li>
<li> <p><strong>FP</strong>: (scalar) The percentage of False Positives.
</p>
</li>
<li> <p><strong>TN</strong>: (scalar) The percentage of True Negatives.
</p>
</li>
<li> <p><strong>FN</strong>: (scalar) The percentage of False Negatives.
</p>
</li>
<li> <p><strong>Accepted</strong>: The percentage of selected individuals 
(i.e., TP + FP).
</p>
</li>
<li> <p><strong>PPV</strong>: The Positive Predictive Value. This is the probability 
that a selected individual is a True Positive.
</p>
</li>
<li> <p><strong>Sensitivity</strong>: The test battery Sensitivity rate.  This is the 
probability that a person who is acceptable on the criterion is called  
acceptable by the test battery.
</p>
</li>
<li> <p><strong>Specificity</strong>: The test battery Specificity rate.  This is the 
probability that a person who falls below the criterion threshold 
is deemed unacceptable by the test battery.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>


<ul>
<li><p> Taylor, H. C. &amp; Russell, J. (1939). The relationship of validity 
coefficients to the practical effectiveness of tests in selection: 
Discussion and tables. Journal of Applied Psychology, 23(5), 565&ndash;578.
</p>
</li>
<li><p> Thomas, J. G., Owen, D., &amp; Gunst, R. (1977). Improving the use 
of educational tests as selection tools. Journal of Educational 
Statistics, 2(1), 55&ndash;77. 
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Example 1
# Reproduce Table 3 (p. 574) of Taylor and Russell

r &lt;- seq(0, 1, by = .05)
sr &lt;- c(.05, seq(.10, .90, by = .10), .95)
num.r &lt;- length(r)
num.sr &lt;- length(sr)

old &lt;- options(width = 132)

Table3 &lt;- matrix(0, num.r, num.sr)
for(i in 1 : num.r){
   for(j in 1:num.sr){
   
     Table3[i,j] &lt;-  TaylorRussell(
                       SR = sr[j],
                       BR = .20, 
                       R = matrix(c(1, r[i], r[i], 1), 2, 2), 
                       PrintLevel = 0,
                       Digits = 3)$PPV  
   
  }# END over j
}# END over i

rownames(Table3) &lt;- r
colnames(Table3) &lt;- sr
Table3 |&gt; round(2)

# Example 2
# Thomas, Owen, &amp; Gunst (1977) -- Example 1: Criterion = GPA

R &lt;- matrix(c(1, .5, .7,
             .5, 1, .7,
            .7, .7, 1), 3, 3)

 # See Table 6: Target Acceptance = 20%
 out.20 &lt;- TaylorRussell(
 SR = c(.354, .354),  # the marginal probabilities
 BR = .60, 
 R = R,
 PrintLevel = 1) 

# See Table 6:  Target Acceptance = 50%
out.50 &lt;- TaylorRussell(
 SR = c(.653, .653),   # the marginal probabilities
 BR = .60, 
 R = R,
 PrintLevel = 1) 
 
 options(old)
 
</code></pre>

<hr>
<h2 id='tetcor'>Compute ML Tetrachoric Correlations</h2><span id='topic+tetcor'></span>

<h3>Description</h3>

<p>Compute ML tetrachoric correlations with optional bias correction and
smoothing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tetcor(
  X,
  y = NULL,
  BiasCorrect = TRUE,
  stderror = FALSE,
  Smooth = TRUE,
  max.iter = 5000,
  PRINT = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tetcor_+3A_x">X</code></td>
<td>
<p>Either a matrix or vector of (0/1) binary data.</p>
</td></tr>
<tr><td><code id="tetcor_+3A_y">y</code></td>
<td>
<p>An optional(if X is a matrix) vector of (0/1) binary data.</p>
</td></tr>
<tr><td><code id="tetcor_+3A_biascorrect">BiasCorrect</code></td>
<td>
<p>A logical that determines whether bias correction (Brown
&amp; Benedetti, 1977) is performed. Default = TRUE.</p>
</td></tr>
<tr><td><code id="tetcor_+3A_stderror">stderror</code></td>
<td>
<p>A logical that determines whether standard errors are
calulated.  Default = FALSE.</p>
</td></tr>
<tr><td><code id="tetcor_+3A_smooth">Smooth</code></td>
<td>
<p>A logical which determines whether the tetrachoric correlation
matrix should be smoothed.  A smoothed matrix is always positive definite.</p>
</td></tr>
<tr><td><code id="tetcor_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations. Default = 50.</p>
</td></tr>
<tr><td><code id="tetcor_+3A_print">PRINT</code></td>
<td>
<p>A logical that determines whether to print progress updates
during calculations. Default = TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If stderror = FALSE, <code>tetcor</code> returns a matrix of tetrachoric
correlations. If <code>stderror</code> = TRUE then <code>tetcor</code> returns a list
the first component of which is a matrix of tetrachoric correlations and the
second component is a matrix of standard errors (see Hamdan, 1970).
</p>
<table>
<tr><td><code>r</code></td>
<td>
<p>The tetrachoric correlation matrix</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code>se</code></td>
<td>
<p>A matrix of standard errors.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>(logical) The convergence status of the algorithm. A value of 
TRUE denotes that the algorithm converged. A value of FALSE denotes that the 
algorithm did not converge and the returned correlations 
are Pearson product moments.</p>
</td></tr>
<tr><td><code>Warnings</code></td>
<td>
<p>A list of warnings.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Brown, M. B. &amp; Benedetti, J. K. (1977). On the mean and variance
of the tetrachoric correlation coefficient. <em>Psychometrika, 42</em>,
347&ndash;355.
</p>
<p>Divgi, D. R. (1979) Calculation of the tetrachoric correlation coefficient.
<em>Psychometrika, 44</em>, 169-172.
</p>
<p>Hamdan, M. A. (1970). The equivalence of tetrachoric and maximum likelihood
estimates of rho in 2 by 2 tables. <em>Biometrika, 57</em>, 212-215.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## generate bivariate normal data
library(MASS)
set.seed(123)
rho &lt;- .85
xy &lt;- mvrnorm(100000, mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), ncol = 2))

# dichotomize at difficulty values
p1 &lt;- .7
p2 &lt;- .1
xy[,1] &lt;- xy[,1] &lt; qnorm(p1) 
xy[,2] &lt;- xy[,2] &lt; qnorm(p2)

print( apply(xy,2,mean), digits = 2)
#[1] 0.700 0.099

tetcor(X = xy, BiasCorrect = TRUE, 
       stderror = TRUE, Smooth = TRUE, max.iter = 5000)

# $r
# [,1]      [,2]
# [1,] 1.0000000 0.8552535
# [2,] 0.8552535 1.0000000
# 
# $se
# [,1]           [,2]
# [1,] NA         0.01458171
# [2,] 0.01458171 NA
# 
# $Warnings
# list()



</code></pre>

<hr>
<h2 id='tetcorQuasi'>Correlation between a Naturally and an Artificially Dichotomized Variable</h2><span id='topic+tetcorQuasi'></span>

<h3>Description</h3>

<p>A function to compute Ulrich and Wirtz's correlation of a naturally and an
artificially dichotomized variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tetcorQuasi(x, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tetcorQuasi_+3A_x">x</code></td>
<td>
<p>An N x 2 matrix or an N x 1 vector of binary responses coded 0/1.</p>
</td></tr>
<tr><td><code id="tetcorQuasi_+3A_y">y</code></td>
<td>
<p>An optional (if x is a vector) vector of 0/1 responses.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>A quasi tetrachoric correlation</code></td>
<td>
<p>...</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>References</h3>

<p>Ulrich, R. &amp; Wirtz, M. (2004). On the correlation of a naturally
and an artificially dichotomized variable. <em>British Journal of
Mathematical and Statistical Psychology, 57</em>, 235-252.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(321)
Nsubj &lt;- 5000

## Generate mvn data with rxy = .5
R &lt;- matrix(c(1, .5, .5, 1), 2, 2)
X &lt;- MASS::mvrnorm(n = Nsubj, mu = c(0, 0), Sigma = R, empirical = TRUE)

## dichotomize data
thresholds &lt;- qnorm(c(.2, .3))
binaryData &lt;- matrix(0, Nsubj, 2)

for(i in 1:2){
  binaryData[X[,i] &lt;= thresholds[i],i] &lt;- 1
}   

## calculate Pearson correlation
cat("\nPearson r: ", round(cor(X)[1,2], 2))

## calculate Pearson Phi correlation
cat("\nPhi r: ", round(cor(binaryData)[1,2], 2))

## calculate tetrachoric correlation
cat("\nTetrachoric r: ", round(tetcor(binaryData)$r[1,2], 2))

## calculate Quasi-tetrachoric correlation
cat("\nQuasi-tetrachoric r: ", round(tetcorQuasi(binaryData), 2))

</code></pre>

<hr>
<h2 id='Thurstone41'>Multi-Trait Multi-Method correlation matrix reported by Thurstone and Thurstone (1941).</h2><span id='topic+Thurstone41'></span>

<h3>Description</h3>

<p>The original study assessed a total of 63 variables.
However, we report the 9 variables, across 2 tests,
used to reproduce the multiple battery factor analyses of Browne (1979).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Thurstone41)
</code></pre>


<h3>Format</h3>

<p>A 9 by 9 correlation matrix with dimension names
</p>


<h3>Details</h3>

<p>The sample size is <em>n</em> = 710.
</p>
<p>The following variables were assessed (abbreviations in parentheses):
<strong>Variables</strong>:
</p>

<ul>
<li> <p><strong>Test #1</strong> (X)
</p>

<ul>
<li><p> Prefixes (Prefix)
</p>
</li>
<li><p> Suffixes (Suffix)
</p>
</li>
<li><p> Sentences (Sentences)
</p>
</li>
<li><p> Chicago Reading Test: Vocabulary (Vocab)
</p>
</li>
<li><p> Chicago Reading Test: Sentences (Sentence)
</p>
</li></ul>

</li>
<li> <p><strong>Test #2</strong> (Y)
</p>

<ul>
<li><p> First and Last Letters (FLLetters)
</p>
</li>
<li><p> First Letters (Letters)
</p>
</li>
<li><p> Four-Letter Words (Words)
</p>
</li>
<li><p> Completion (Completion)
</p>
</li>
<li><p> Same and Opposite (SameOpposite)
</p>
</li></ul>

</li></ul>



<h3>Source</h3>

<p>Thurstone, L. L. and Thurstone, T. G. (1941). Factorial studies of 
intelligence. <em>Psychometric Monographs, 2</em>. Chicago: University Chicago Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load Thurstone &amp; Thurstone's data used by Browne (1979)
data(Thurstone41)
Example1Output &lt;-  faMB(R             = Thurstone41, 
                        n             = 710,
                        NB            = 2, 
                        NVB           = c(4,5), 
                        numFactors    = 2,
                        rotate        = "oblimin",
                        rotateControl = list(standardize = "Kaiser"))

summary(Example1Output, PrintLevel = 2)                         

</code></pre>

<hr>
<h2 id='ThurstoneBox20'>Factor Pattern and Factor Correlations for Thurstone's 20 hypothetical box attributes.</h2><span id='topic+ThurstoneBox20'></span>

<h3>Description</h3>

<p>Factor Pattern and Factor Correlations for Thurstone's 20 hypothetical box attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ThurstoneBox20)
</code></pre>


<h3>Format</h3>

<p>This is a list containing the <code>Loadings</code> (original factor pattern) and <code>Phi</code>
matrix (factor correlation matrix) from Thurstone's 20 Box problem (Thurstone, 1940, p. 227). 
The original 20-variable Box problem  contains measurements on the following score
functions of box length (x), width (y), and height (z). 
<strong>Box20</strong> variables:
</p>

<ol>
<li><p>   x^2
</p>
</li>
<li><p>   y^2
</p>
</li>
<li><p>   z^2
</p>
</li>
<li><p>   xy
</p>
</li>
<li><p>   xz
</p>
</li>
<li><p>   yz
</p>
</li>
<li><p>   sqrt(x^2 + y^2)
</p>
</li>
<li><p>   sqrt(x^2 + z^2)
</p>
</li>
<li><p>   sqrt(y^2 + z^2)
</p>
</li>
<li><p>   2x + 2y
</p>
</li>
<li><p>   2x + 2z
</p>
</li>
<li><p>   2y + 2z 
</p>
</li>
<li><p>   log(x)
</p>
</li>
<li><p>   log(y)
</p>
</li>
<li><p>   log(z)
</p>
</li>
<li><p>   xyz
</p>
</li>
<li><p>   sqrt(x^2 + y^2 + z^2)
</p>
</li>
<li><p>   exp(x)
</p>
</li>
<li><p>   exp(y)
</p>
</li>
<li><p>   exp(z)
</p>
</li></ol>



<h3>Details</h3>

<p>Two data sets have been described in the literature as Thurstone's Box Data 
(or Thurstone's Box Problem). The first consists of 20 measurements on a set of 20 
hypothetical boxes (i.e., Thurstone made up the data).  Those data are available 
in <strong>Box20</strong>.
</p>


<h3>References</h3>

<p>Thurstone, L. L. (1940). Current issues in factor analysis. Psychological Bulletin, 37(4), 189. 
Thurstone, L. L.  (1947).  Multiple factor analysis.  Chicago: University of Chicago Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AmzBoxes">AmzBoxes</a></code>, <code><a href="#topic+Box20">Box20</a></code>, <code><a href="#topic+Box26">Box26</a></code>,
<code><a href="#topic+GenerateBoxData">GenerateBoxData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ThurstoneBox20)  
ThurstoneBox20
</code></pre>

<hr>
<h2 id='ThurstoneBox26'>Factor Pattern Matrix for Thurstone's 26  box attributes.</h2><span id='topic+ThurstoneBox26'></span>

<h3>Description</h3>

<p>Factor Pattern Matrix for Thurstone's 26  box attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ThurstoneBox26)
</code></pre>


<h3>Format</h3>

<p>The original factor pattern (3 graphically rotated centroid factors) from Thurstone's 26 hypothetical box data as 
reported by Thurstone (1947, p. 371). The so-called Thurstone invariant box problem 
contains measurements on the following 26 functions of length (x), width (y), and height (z). 
<strong>Box26</strong> variables:
</p>

<ol>
<li><p> x
</p>
</li>
<li><p> y
</p>
</li>
<li><p> z
</p>
</li>
<li><p> xy 
</p>
</li>
<li><p> xz
</p>
</li>
<li><p> yz 
</p>
</li>
<li><p> x^2 * y
</p>
</li>
<li><p> x * y^2
</p>
</li>
<li><p> x^2 * z
</p>
</li>
<li><p> x * z^ 2
</p>
</li>
<li><p> y^2 * z
</p>
</li>
<li><p> y * z^2
</p>
</li>
<li><p> x/y
</p>
</li>
<li><p> y/x
</p>
</li>
<li><p> x/z
</p>
</li>
<li><p>  z/x
</p>
</li>
<li><p>  y/z
</p>
</li>
<li><p>  z/y
</p>
</li>
<li><p> 2x + 2y
</p>
</li>
<li><p> 2x + 2z
</p>
</li>
<li><p> 2y + 2z
</p>
</li>
<li><p> sqrt(x^2 + y^2)
</p>
</li>
<li><p> sqrt(x^2 + z^2)
</p>
</li>
<li><p> sqrt(y^2 + z^2)
</p>
</li>
<li><p> xyz
</p>
</li>
<li><p> sqrt(x^2 + y^2 + z^2)
</p>
</li></ol>



<h3>Details</h3>

<p>Two data sets have been described in the literature as Thurstone's Box Data 
(or Thurstone's Box Problem). The first consists of 20 measurements on a set of 20 
hypothetical boxes (i.e., Thurstone made up the data).  Those data are available 
in <strong>Box20</strong>. The second data set was collected by 
Thurstone to provide an illustration of the invariance of simple structure 
factor loadings. In his classic textbook on multiple factor analysis 
(Thurstone, 1947), Thurstone states that &ldquo;[m]easurements of a random collection 
of thirty boxes were actually made in the Psychometric Laboratory and recorded 
for this numerical example. The three dimensions, x, y, and z, were recorded 
for each box. A list of 26 arbitrary score functions was then prepared&rdquo; (p. 369). The 
raw data for this example were not published.  Rather, Thurstone reported a 
correlation matrix for the 26 score functions (Thurstone, 1947, p. 370). Note that, presumably 
due to rounding error in the reported correlations, the correlation matrix 
for this example is non positive definite. This file includes the rotated centroid solution 
that is reported in his book (Thurstone, 1947, p. 371).
</p>


<h3>References</h3>

<p>Thurstone, L. L.  (1947).  Multiple factor analysis.  Chicago: University of Chicago Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Box20">Box20</a></code>, <code><a href="#topic+AmzBoxes">AmzBoxes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ThurstoneBox26)  
ThurstoneBox26
</code></pre>

<hr>
<h2 id='tkl'>Optimize TKL parameters to find a solution with target RMSEA and CFI values</h2><span id='topic+tkl'></span>

<h3>Description</h3>

<p>Find the optimal W matrix such that the RMSEA and CFI values are as close as
possible to the user-specified target values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tkl(mod, target_rmsea = NULL, target_cfi = NULL, tkl_ctrl = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tkl_+3A_mod">mod</code></td>
<td>
<p>A <code><a href="#topic+simFA">simFA</a></code> model object.</p>
</td></tr>
<tr><td><code id="tkl_+3A_target_rmsea">target_rmsea</code></td>
<td>
<p>(scalar) Target RMSEA value.</p>
</td></tr>
<tr><td><code id="tkl_+3A_target_cfi">target_cfi</code></td>
<td>
<p>(scalar) Target CFI value.</p>
</td></tr>
<tr><td><code id="tkl_+3A_tkl_ctrl">tkl_ctrl</code></td>
<td>
<p>(list) A control list containing the following TKL-specific
arguments:
</p>

<ul>
<li><p> weights (vector) Vector of length two indicating how much weight to give
RMSEA and CFI, e.g., <code>c(1,1)</code> (default) gives equal weight
to both indices; <code>c(1,0)</code> ignores the CFI value.
</p>
</li>
<li><p> v_start (scalar) Starting value to use for <code class="reqn">\nu</code>, the proportion
of uniqueness variance reallocated to the minor common factors. Note that
only <code>v</code> as a proportion of the unique (not total) variance is supported
in this function.
</p>
</li>
<li><p> eps_start (scalar) Starting value to use for <code class="reqn">\epsilon</code>, which
controls how common variance is distributed among the minor common factors.
</p>
</li>
<li><p> v_start (vector) A vector of length two specifying the lowest and highest acceptable values of <code class="reqn">\nu</code>.
</p>
</li>
<li><p> eps_start (vector) A vector of length two specifying the lowest and highest acceptable values of <code class="reqn">\epsilon</code>.
</p>
</li>
<li><p> NMinorFac (scalar) Number of minor common factors.
</p>
</li>
<li><p> WmaxLoading (scalar) Threshold value for <code>NWmaxLoading</code>.
</p>
</li>
<li><p> NWmaxLoading (scalar) Maximum number of absolute loadings <code class="reqn">\ge</code>
<code>WmaxLoading</code> in any column of <code class="reqn">W</code>.
</p>
</li>
<li><p> penalty (scalar) Penalty applied to objective function if the
<code>NmaxLoading</code> condition isn't satisfied.
</p>
</li>
<li><p> optim_type (character)  Which optimization function to use,
<code><a href="stats.html#topic+optim">optim</a></code> or <code><a href="GA.html#topic+ga">ga</a></code>?
<code><a href="stats.html#topic+optim">optim</a></code> is faster, but might not converge in some cases.
If <code><a href="stats.html#topic+optim">optim</a></code> doesn't converge, <a href="GA.html#topic+ga">ga</a> will be used
as a fallback option.
</p>
</li>
<li><p> max_tries (numeric) How many times to restart optimization with new start
parameter values if optimization doesn't converge?
</p>
</li>
<li><p> factr (numeric) controls the convergence of the &quot;L-BFGS-B&quot; method.
Convergence occurs when the reduction in the objective is within this
factor of the machine tolerance. Default is 1e7, that is a tolerance of
about 1e-8. (when using <code><a href="stats.html#topic+optim">optim</a></code>).
</p>
</li>
<li><p> maxit (number) Maximum number of iterations to use (when using
<code><a href="stats.html#topic+optim">optim</a></code>).
</p>
</li>
<li><p> ncores (boolean/scalar) Controls whether <a href="GA.html#topic+ga">ga</a> optimization is done in
parallel. If <code>TRUE</code>, uses the maximum available number of processor cores.
If <code>FALSE</code>, does not use parallel processing. If an integer is provided,
that's how many processor cores will be used (if available).
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>This function attempts to find optimal values of the TKL parameters
<code class="reqn">\nu</code> and <code class="reqn">\epsilon</code> such that the resulting correlation
matrix with model error (<code class="reqn">\Sigma</code>) has population RMSEA and/or CFI
values that are close to the user-specified values. It is important to note
that solutions are not guaranteed to produce RMSEA and CFI values that are
reasonably close to the target values; in fact, some combinations of RMSEA
and CFI will be difficult or impossible to obtain for certain models (see
Lai &amp; Green, 2016). It can be particularly difficult to find good solutions
when additional restrictions are placed on the minor factor loadings (i.e.,
using the <code>WmaxLoading</code> and <code>NWmaxLoading</code> arguments).
</p>
<p>Optimization is fastest when the <code>optim_type = optim</code> optimization method
is chosen. This indicates that optimization should be done using the
<code>L-BFGS-B</code> algorithm implemented in the <code><a href="stats.html#topic+optim">optim</a></code>
function. However, this method can sometimes fail to find a solution.
In that case, I recommend setting <code>optim_type = ga</code>, which indicates that a
genetic algorithm (implemented in <code><a href="GA.html#topic+ga">ga</a></code>) will be used.
This method takes longer than <code><a href="stats.html#topic+optim">optim</a></code> but is more likely to
find a solution.
</p>


<h3>References</h3>

<p>Tucker, L. R., Koopman, R. F., &amp; Linn, R. L. (1969). Evaluation
of factor analytic research procedures by means of simulated correlation
matrices. <em>Psychometrika</em>, <em>34</em>(4), 421459.
</p>

<hr>
<h2 id='TR'>Estimate the parameters of the Taylor-Russell function.</h2><span id='topic+TR'></span>

<h3>Description</h3>

<p>A Taylor-Russell function can be computed with any three of the following 
four variables: the Base Rate (BR); the Selection Ratio (SR); 
the Criterion Validity (CV) and the Positive Predictive Value (PPV). 
The <code>TR()</code> function will compute a Taylor Russell function 
when given any three of these parameters and estimate the remaining parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TR(BR = NULL, SR = NULL, CV = NULL, PPV = NULL, PrintLevel = 1, Digits = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TR_+3A_br">BR</code></td>
<td>
<p>(numeric): The Base Rate of successful criterion performance 
(i.e., within the target population, the proportion of individuals who can 
successfully execute the job demands).</p>
</td></tr>
<tr><td><code id="TR_+3A_sr">SR</code></td>
<td>
<p>(numeric): The Selection Ratio. A real number between 0 and 1
that denotes the test selection ratio (i.e., the proportion of hired 
candidates from the target population).</p>
</td></tr>
<tr><td><code id="TR_+3A_cv">CV</code></td>
<td>
<p>(numeric) The correlation (Criterion Validity) between the selection test 
and a measure of job performance.</p>
</td></tr>
<tr><td><code id="TR_+3A_ppv">PPV</code></td>
<td>
<p>(numeric): The Positive Predicted Value. The PPV denotes 
the probability that a hired candidate has the necessary skills to 
succeed on the job.</p>
</td></tr>
<tr><td><code id="TR_+3A_printlevel">PrintLevel</code></td>
<td>
<p>(integer): If <code>PrintLevel = 0</code> then no output will be printed to screen. 
If <code>PrintLevel = 1</code> then a brief summary of output is printed to screen. Default <code>PrintLevel = 1</code>.</p>
</td></tr>
<tr><td><code id="TR_+3A_digits">Digits</code></td>
<td>
<p>(integer) Controls the number of significant digits 
in the printed output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When any three of the main program arguments (BR, SR, CV, PPV) are specified (with the 
remaining argument given a NULL value), <code>TR()</code> will calculate 
the model-implied value for the remaining variable.  It will also compute the test Sensitivity 
(defined as the probability that a qualified individual will be hired) and 
test Specificity (defined as the probability that an unqualified individual 
will not be hired), the True Positive rate, the False Positive rate, the 
True Negative rate, and the False Negative rate.
</p>


<h3>Value</h3>


<ul>
<li>  <p><strong>BR</strong> The base rate.
</p>
</li>
<li> <p><strong>SR</strong> The selection ratio.
</p>
</li>
<li> <p><strong>CV</strong> The criterion validity.
</p>
</li>
<li>  <p><strong>PPV</strong> The positive predictive value.
</p>
</li>
<li> <p><strong>Sensitivity</strong> The test sensitivity rate. 
</p>
</li>
<li> <p><strong>Specificity</strong>  The test specificity rate. 
</p>
</li>
<li> <p><strong>TP</strong> The selection True Positive rate. 
</p>
</li>
<li> <p><strong>FP</strong> The selection False Positive rate. 
</p>
</li>
<li> <p><strong>TN</strong> The selection True Negative rate. 
</p>
</li>
<li> <p><strong>FN</strong> The selection False Negative rate. 
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Niels G. Waller (nwaller@umn.edu)
</p>
</li></ul>



<h3>References</h3>


<ul>
<li><p> Taylor, H. C. &amp; Russell, J. (1939). The relationship of validity 
coefficients to the practical effectiveness of tests in selection: 
Discussion and tables. <em>Journal of Applied Psychology, 23</em>, 565&ndash;578.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
## Example 1:
       TR(BR = .3, 
          SR = NULL, 
          CV = .3, 
          PPV = .5,
          PrintLevel = 1,
          Digits = 3)
  
## Example 2:

       TR(BR = NULL, 
          SR = .1012, 
          CV = .3, 
          PPV = .5,
          PrintLevel = 1,
          Digits = 3)
   
## Example 3: A really bad test!
 # If the BR &gt; PPV then the actual test
 # validity is zero. Thus, do not use the test!

       TR(BR = .50, 
          SR = NULL, 
          CV = .3, 
          PPV = .25,
          PrintLevel = 1,
          Digits = 3)   
</code></pre>

<hr>
<h2 id='vcos'>Compute the Cosine Between Two Vectors</h2><span id='topic+vcos'></span>

<h3>Description</h3>

<p>Compute the cosine between two vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcos(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcos_+3A_x">x</code></td>
<td>
<p>A p x 1 vector.</p>
</td></tr>
<tr><td><code id="vcos_+3A_y">y</code></td>
<td>
<p>A p x 1 vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Cosine between x and y</code></td>
<td>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rnorm(5)
y &lt;- rnorm(5)
vcos(x, y)

</code></pre>

<hr>
<h2 id='vnorm'>Norm a Vector to Unit Length</h2><span id='topic+vnorm'></span>

<h3>Description</h3>

<p>Norm a vector to unit length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vnorm(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vnorm_+3A_x">x</code></td>
<td>
<p>An n by 1 vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the scaled (i.e., unit length) input vector
</p>


<h3>Author(s)</h3>

<p>Niels Waller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 x &lt;- rnorm(5)
 v &lt;- vnorm(x)
 print(v)

</code></pre>

<hr>
<h2 id='VolElliptope'>Compute the volume of the elliptope of possible correlation 
matrices of a given dimension.</h2><span id='topic+VolElliptope'></span>

<h3>Description</h3>

<p>Compute the volume of the elliptope of possible correlation 
matrices of a given dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VolElliptope(NVar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VolElliptope_+3A_nvar">NVar</code></td>
<td>
<p>(integer) The size of each correlation matrix in the elliptope. 
For instance, if we are interested in the volume of the space of all possible 
5 x 5  correlation matrices then <code>NVar = 5</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>VolElliptope</code> returns the following objects:
</p>

<ul>
<li>  <p><strong>VolElliptope</strong> (numeric) The volume of the elliptope.
</p>
</li>
<li>  <p><strong>VolCube</strong>: (numeric) The volume of the embedding 
hyper-cube.
</p>
</li>
<li> <p><strong>PrcntCube</strong> (numeric) The percent of the hyper-cube that is 
occupied by the elliptope. <code>PrcntCube = 100 x VolElliptope/VolCube</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Niels G. Waller
</p>


<h3>References</h3>

<p>Joe, H. (2006). Generating random correlation matrices 
based on partial correlations. *Journal of Multivariate Analysis*, 
*97* (10), 2177&ndash;2189. 
</p>
<p>Hrlimann, W. (2012). Positive semi-definite 
correlation matrices: Recursive algorithmic generation and volume 
measure. *Pure Mathematical Science, 1* (3), 137&ndash;149.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the volume of a 5 x 5 correlation matrix.

VolElliptope(NVar = 5)

</code></pre>

<hr>
<h2 id='wb'>Wu &amp; Browne model error method</h2><span id='topic+wb'></span>

<h3>Description</h3>

<p>Generate a population correlation matrix using the model described in Wu and
Browne (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wb(mod, target_rmsea, wb_mod = NULL, adjust_target = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wb_+3A_mod">mod</code></td>
<td>
<p>A 'fungible::simFA()' model object.</p>
</td></tr>
<tr><td><code id="wb_+3A_target_rmsea">target_rmsea</code></td>
<td>
<p>(scalar) Target RMSEA value.</p>
</td></tr>
<tr><td><code id="wb_+3A_wb_mod">wb_mod</code></td>
<td>
<p>('lm' object) An optional 'lm' object used to find a target
RMSEA value that results in solutions with RMSEA values close to the
desired value. Note that if no 'wb_mod' is provided, a model will be
estimated at run time. If many population correlation matrices are going to
be simulated using the same model, it will be considerably faster to
estimate 'wb_mod' ahead of time. See also 'get_wb_mod()'.</p>
</td></tr>
<tr><td><code id="wb_+3A_adjust_target">adjust_target</code></td>
<td>
<p>(TRUE; logical) Should the target_rmsea value be
adjusted to ensure that solutions have RMSEA values that are close to the
provided target RMSEA value? Defaults to TRUE and should stay there unless
you have a compelling reason to change it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wu and Browne method generates a correlation matrix with model
error (<code class="reqn">\Sigma</code>) using
</p>
<p style="text-align: center;"><code class="reqn">(\Sigma | \Omega) ~ IW(m, m \Omega),</code>
</p>

<p>where <code class="reqn">m ~= 1/\epsilon^2</code> is a precision parameter related to RMSEA
(<code class="reqn">\epsilon</code>) and <code class="reqn">IW(m, m \Omega)</code> denotes an inverse Wishart
distribution. Note that *there is no guarantee that the RMSEA will be very
close to the target RMSEA*, particularly when the target RMSEA value is
large. Based on experience, the method tends to give solutions with RMSEA
values that are larger than the target RMSEA values. Therefore, it might be
worth using a target RMSEA value that is somewhat lower than what is
actually needed. Alternatively, the <code><a href="#topic+get_wb_mod">get_wb_mod</a></code> function can
be used to estimate a coefficient to shrink the target RMSEA value by an
appropriate amount so that the solution RMSEA values are close to the
(nominal) target values.
</p>


<h3>Author(s)</h3>

<p>Justin Kracht &lt;krach018@umn.edu&gt;
</p>


<h3>References</h3>

<p>Wu, H., &amp; Browne, M. W. (2015). Quantifying adventitious error in
a covariance structure as a random effect. *Psychometrika*, *80*(3),
571600. &lt;https://doi.org/10/gjrkc4&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Specify a default model using simFA()
mod &lt;- fungible::simFA(Seed = 42)

set.seed(42)
wb(mod, target_rmsea = 0.05)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
