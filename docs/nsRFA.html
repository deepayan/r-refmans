<!DOCTYPE html><html><head><title>Help for package nsRFA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nsRFA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AD.dist'><p>Anderson-Darling distance matrix for growth curves</p></a></li>
<li><a href='#Ardechedata'><p>Data-sample</p></a></li>
<li><a href='#BayesianMCMC'><p>Bayesian MCMC frequency analysis</p></a></li>
<li><a href='#bestlm'><p>Subsets regression</p></a></li>
<li><a href='#DIAGNOSTICS'><p>Diagnostics of models</p></a></li>
<li><a href='#DISTPLOTS'><p>Empirical distribution plots</p></a></li>
<li><a href='#EXP'><p>Two parameter exponential distribution and L-moments</p></a></li>
<li><a href='#FEH1000'><p>Data-sample</p></a></li>
<li><a href='#functionsLaio'><p>Data-sample</p></a></li>
<li><a href='#GENLOGIS'><p>Three parameter generalized logistic distribution and L-moments</p></a></li>
<li><a href='#GENPAR'><p>Three parameter generalized Pareto distribution and L-moments</p></a></li>
<li><a href='#GEV'><p>Three parameter generalized extreme value distribution and L-moments</p></a></li>
<li><a href='#GOFlaio2004'><p>Goodness of fit tests</p></a></li>
<li><a href='#GOFmontecarlo'><p>Goodness of fit tests</p></a></li>
<li><a href='#GUMBEL'><p>Two parameter Gumbel distribution and L-moments</p></a></li>
<li><a href='#HOMTESTS'><p>Homogeneity tests</p></a></li>
<li><a href='#HW.original'><p>Original Hosking and Wallis Fortran routine</p></a></li>
<li><a href='#hydroSIMN'><p>Data-sample</p></a></li>
<li><a href='#KAPPA'><p>Four parameter kappa distribution and L-moments</p></a></li>
<li><a href='#Lmoments'><p>Hosking and Wallis sample L-moments</p></a></li>
<li><a href='#LOGNORM'><p>Three parameter lognormal distribution and L-moments</p></a></li>
<li><a href='#MLlaio2004'><p>Maximum likelihood parameters estimation</p></a></li>
<li><a href='#moments'><p>Sample moments</p></a></li>
<li><a href='#MSClaio2008'><p>Model Selection Criteria</p></a></li>
<li><a href='#nsRFA-internal'><p>Internal functions</p></a></li>
<li><a href='#nsRFA-package'>
<p>Non-supervised Regional Frequency Analysis</p></a></li>
<li><a href='#P3'><p>Three parameters Pearson type III distribution and L-moments</p></a></li>
<li><a href='#REGRDIAGNOSTICS'><p>Diagnostics of regressions</p></a></li>
<li><a href='#roi'><p>Region of influence</p></a></li>
<li><a href='#SERIESPLOTS'><p>Series plots</p></a></li>
<li><a href='#STATICPLOTS'><p>Static plots</p></a></li>
<li><a href='#traceWminim'><p>Cluster analysis: disjoint regions</p></a></li>
<li><a href='#varLmoments'><p>Exact variance structure of sample L-moments</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.7-16</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-13</td>
</tr>
<tr>
<td>Title:</td>
<td>Non-Supervised Regional Frequency Analysis</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), stats, graphics, methods</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of statistical tools for objective (non-supervised) applications 
             of the Regional Frequency Analysis methods in hydrology. 
             The package refers to the index-value method and, more precisely, helps the
             hydrologist to: (1) regionalize the index-value; (2) form homogeneous regions 
             with similar growth curves; (3) fit distribution functions to the 
             empirical regional growth curves.
             Most of the methods are those described in the Flood Estimation Handbook 
            (Centre for Ecology &amp; Hydrology, 1999, ISBN:9781906698003).
             Homogeneity tests from Hosking and Wallis (1993) &lt;<a href="https://doi.org/10.1029%2F92WR01980">doi:10.1029/92WR01980</a>&gt; 
             and Viglione et al. (2007) &lt;<a href="https://doi.org/10.1029%2F2006WR005095">doi:10.1029/2006WR005095</a>&gt; are available.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Copyright:</td>
<td>The fortran routines for the function HW.original are from
Jonathan R. M. Hosking and are available at the url
http://www.research.ibm.com/people/h/hosking/lmoments.html. The
functions `MLlaio2004.R', `GOFlaio2004.R' and `MSClaio2008.R'
are derived from original Francesco Laio Matlab code (non
published material). The fortran routines for the function
'bestlm' are from Alan Miller and were obtained from his R
package 'leaps'.</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-13 08:22:36 UTC; alviglio</td>
</tr>
<tr>
<td>Author:</td>
<td>Alberto Viglione [aut, cre],
  Jonathan R. M. Hosking [ctb],
  Francesco Laio [ctb],
  Alan Miller [ctb],
  Eric Gaume [ctb],
  Olivier Payrastre [ctb],
  Jose Luis Salinas [ctb],
  Chi Cong N'guyen [ctb],
  Karine Halbert [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alberto Viglione &lt;alberto.viglione@polito.it&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-13 13:33:20 UTC</td>
</tr>
</table>
<hr>
<h2 id='AD.dist'>Anderson-Darling distance matrix for growth curves</h2><span id='topic+AD.dist'></span>

<h3>Description</h3>

<p>Distance matrix for growth curves. Every element of the matrix is the Anderson-Darling statistic calculated between two series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> AD.dist (x, cod, index=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AD.dist_+3A_x">x</code></td>
<td>
<p>vector representing data from many samples defined with <code>cod</code></p>
</td></tr>
<tr><td><code id="AD.dist_+3A_cod">cod</code></td>
<td>
<p>array that defines the data subdivision among sites</p>
</td></tr>
<tr><td><code id="AD.dist_+3A_index">index</code></td>
<td>
<p>if <code>index</code>=1 samples are divided by their average value;
if <code>index</code>=2 (default) samples are divided by their median value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Anderson-Darling statistic used here is the one defined in <a href="https://en.wikipedia.org/wiki/Anderson-Darling_test">https://en.wikipedia.org/wiki/Anderson-Darling_test</a> as <code class="reqn">A^2</code>.</p>


<h3>Value</h3>

<p><code>AD.dist</code> returns the distance matrix between growth-curves built with the Anderson-Darling statistic.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+traceWminim">traceWminim</a></code>, <code><a href="#topic+roi">roi</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)

annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]

# Ad.dist
AD.dist(x,cod)             # it takes some time
</code></pre>

<hr>
<h2 id='Ardechedata'>Data-sample</h2><span id='topic+Ardechedata'></span><span id='topic+Ardeche_areas'></span><span id='topic+Ardeche_ungauged_extremes'></span><span id='topic+Beauvene_cont'></span><span id='topic+Chambonas_cont'></span><span id='topic+SaintLaurent_cont'></span><span id='topic+SaintMartin_cont'></span><span id='topic+SaintMartin_hist'></span><span id='topic+Vogue_cont'></span>

<h3>Description</h3>

<p>Systematic flood data and historical flood data for the Ard\'eche region (France) as described in: \
Naulet, R. (2002). Utilisation de l'information des crues historiques pour une meilleure pr\'ed\'etermination du risque d'inondation. Application au bassin de l'Ard\&lsquo;eche \'a Vallon Pont-d&rsquo;Arc et St-Martin d'Ard\&lsquo;eche. PhD thesis at CEMAGREF, Lyon, and at the Universit\&rsquo;e du Qu\'ebec, pp. 322. \ 
and \
Nguyen, C.C. (2012). Am\'elioration des approches Bay\'esiennes MCMC pour l'analyse r\'egionale des crues (Improvement of BayesianMCMC approaches for regional flood frequency analyses). PhD thesis at the University of Nantes, pp. 192. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'> data(Ardechedata)
</code></pre>


<h3>Format</h3>

<p><code>Ardeche_areas</code>, areas (km2) of the gauged and ungauged catchments in the Ard\'eche region (France); 
<code>Ardeche_ungauged_extremes</code>, flood peaks (m3/s) reconstructed in ungauged catchments and number of years for which the peak was not exceeded;
<code>Beauvene_cont</code>, sistematic flood peaks (m3/s) recorded at one station;
<code>Chambonas_cont</code>, sistematic flood peaks (m3/s) recorded at one station;
<code>SaintLaurent_cont</code>, sistematic flood peaks (m3/s) recorded at one station;
<code>SaintMartin_cont</code>, sistematic flood peaks (m3/s) recorded at one station;
<code>SaintMartin_hist</code>, values for historical peaks (m3/s) for one station and for flood perception thresholds (m3/s) non exceeded in the periods indicated;
<code>Vogue_cont</code>, sistematic flood peaks (m3/s) recorded at one station.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Ardechedata)
SaintMartin_cont
SaintMartin_hist
</code></pre>

<hr>
<h2 id='BayesianMCMC'>Bayesian MCMC frequency analysis</h2><span id='topic+BayesianMCMC'></span><span id='topic+BayesianMCMCcont'></span><span id='topic+BayesianMCMCreg'></span><span id='topic+BayesianMCMCregcont'></span><span id='topic+plotBayesianMCMCreg_surf'></span><span id='topic+print.BayesianMCMC'></span><span id='topic+plot.BayesianMCMC'></span><span id='topic+print.BayesianMCMCreg'></span><span id='topic+plot.BayesianMCMCreg'></span><span id='topic+.thresML'></span><span id='topic+.plotdiagnMCMC01'></span><span id='topic+.plotdiagnMCMC02'></span><span id='topic+.plotdiagnMCMC03'></span><span id='topic+.plotdiagnMCMC04'></span><span id='topic+.plotdiagnMCMC05'></span><span id='topic+.plotdiagnMCMC06'></span><span id='topic+.pointspos3'></span><span id='topic+.points1'></span><span id='topic+.chooseparameters0'></span><span id='topic+.parameterscandMOD'></span><span id='topic+.quantilesMOD'></span><span id='topic+.lnvrais5'></span><span id='topic+.lnvrais1'></span><span id='topic+.lnvrais2'></span><span id='topic+.lnvrais4'></span><span id='topic+.datachange'></span><span id='topic+.thresMLreg'></span><span id='topic+.plotdiagnMCMCreg01'></span><span id='topic+.plotdiagnMCMCreg02'></span><span id='topic+.plotdiagnMCMCreg03'></span><span id='topic+.plotdiagnMCMCreg04'></span><span id='topic+.plotdiagnMCMCreg05'></span><span id='topic+.plotdiagnMCMCreg06'></span><span id='topic+.pointspos3reg'></span><span id='topic+.points1reg'></span><span id='topic+.chooseparameters0reg'></span><span id='topic+.parameterscandMODreg'></span><span id='topic+.quantilesMODreg'></span><span id='topic+.lnvrais5reg'></span><span id='topic+.lnvrais1reg'></span><span id='topic+.lnvrais2reg'></span><span id='topic+.lnvrais4reg'></span>

<h3>Description</h3>

<p>Bayesian Markov Chain Monte Carlo algorithm for flood frequency analysis with historical and other information. The user can choose between a local and a regional analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> BayesianMCMC (xcont, xhist=NA, infhist=NA, suphist=NA, 
               nbans=NA, seuil=NA, nbpas=1000, nbchaines=3, 
               confint=c(0.05, 0.95), dist="GEV",
               apriori=function(...){1}, 
               parameters0=NA, varparameters0=NA)
 BayesianMCMCcont (x, nbpas=NA)
 BayesianMCMCreg (xcont, scont, xhist=NA, infhist=NA, suphist=NA, shist=NA, 
                  nbans=NA, seuil=NA, nbpas=1000, nbchaines=3,
                  confint=c(0.05, 0.95), dist="GEV",
                  apriori=function(...){1},
                  parameters0=NA, varparameters0=NA) 
 BayesianMCMCregcont (x, nbpas=NA)
 plotBayesianMCMCreg_surf (x, surf, ask=FALSE, ...)
 ## S3 method for class 'BayesianMCMC'
 plot(x, which=1, ask=FALSE, ...)
 ## S3 method for class 'BayesianMCMC'
 print(x, ...)
 ## S3 method for class 'BayesianMCMCreg'
 plot(x, which=1, ask=FALSE, ...)
 ## S3 method for class 'BayesianMCMCreg'
 print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BayesianMCMC_+3A_x">x</code></td>
<td>
<p>object of class <code>BayesianMCMC</code>, output of function <code>BayesianMCMC</code></p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_xcont">xcont</code></td>
<td>
<p>vector of systematic data</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_scont">scont</code></td>
<td>
<p>vector of upstream catchment surfaces of systematic data</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_xhist">xhist</code></td>
<td>
<p>vector of historical data and/or extreme discharges at ungauged sites</p>
</td></tr>                     
<tr><td><code id="BayesianMCMC_+3A_infhist">infhist</code></td>
<td>
<p>vector of inferior limit for historical data and/or extreme discharges at ungauged sites</p>
</td></tr>         
<tr><td><code id="BayesianMCMC_+3A_suphist">suphist</code></td>
<td>
<p>vector of superior limit for historical data and/or extreme discharges at ungauged sites</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_shist">shist</code></td>
<td>
<p>vector of upstream catchment surfaces of extreme discharges at ungauged sites </p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_nbans">nbans</code></td>
<td>
<p>period (in years) over which every threshold has not been exceeded except for the historical data and/or extreme discharges at ungauged sites. If several values of xhist for a same threshold, put the number of years associated to the threshold on the first row, then put 0 (see examples)</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_seuil">seuil</code></td>
<td>
<p>threshold not exceeded in the historical period except for the historical data and/or extreme discharges at ungauged sites (several thresholds allowed).</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_nbpas">nbpas</code></td>
<td>
<p>number of iterations for the MCMC algorithm</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_nbchaines">nbchaines</code></td>
<td>
<p>number of chains for the MCMC algorithm</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_confint">confint</code></td>
<td>
<p>confidence limits for the flood quantiles</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_dist">dist</code></td>
<td>
<p>distribution: normal <code>"NORM"</code>, log-normal with 2 parameters <code>"LN"</code>, Exponential <code>"EXP"</code>, Gumbel <code>"GUMBEL"</code>, Generalized Extreme Value <code>"GEV"</code>, Generalized Logistic <code>"GENLOGIS"</code>, Generalized Pareto <code>"GENPAR"</code>, log-normal with 3 parameters <code>"LN3"</code>, Pearson type III <code>"P3"</code>, (log-Pearson type III <code>"LP3"</code>, not implemented yet)</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_apriori">apriori</code></td>
<td>
<p>function of the parameters of the model &lsquo;proportional to&rsquo; their a-priori guessed distribution.
The default fuction returns always 1, i.e. there is no a-priori information</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_parameters0">parameters0</code></td>
<td>
<p>initial values of the parameters for the MCMC algorithm</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_varparameters0">varparameters0</code></td>
<td>
<p>initial values of the parameter variances for the MCMC algorithm</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_which">which</code></td>
<td>
<p>a number of a vector of numbers that defines the graph to plot (see details)</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_ask">ask</code></td>
<td>
<p>if TRUE, the interactive mode is run</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_surf">surf</code></td>
<td>
<p>a particular surface (number or vector), not necessarily being a surface included in the scont or shist vectors</p>
</td></tr>
<tr><td><code id="BayesianMCMC_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>

</table>


<h3>Details</h3>

<p><b>Supported cases</b>
</p>
<p>These functions are taking 4 cases into account, depending on the type of data provided:
- Using only the systematic data: xcont provided, xhist=NA, infhist=NA and suphist=NA
- Using censored information, historical flood known: xcont and xhist provided, infhist=NA and suphist=NA
- Using censored information, historical flood unknown precisely but its lower limit known: xcont and infhist provided, xhist=NA and suphist=NA
- Taking into account flood estimation intervals: infhist and suphist (respectively lower and upper limits) provided, xcont provided, xhist=NA  
- Please note that every other case is NOT supported. For example, you can't have some historical flood values perfectly known as well as some other for which you only know a lower limit or an interval.
</p>
<p>Regarding the perception thresholds:
- By definition, the number of exceedances of each perception threshold within its application period has to be known precisely, and all the floods exceeding the threshold have to be included in xhist (or infhist or suphist).  
- Several thresholds are allowed.
- It is possible to include in xhist (or infhist or suphist) historical values that do not exceed the associated perception threshold.
- If for one or several thresholds you only know that this or these threshold have never been exceeded and no more information is available on floods that did not exceed the threshold(s), this case is also supported. In this case, put for the historical flood corresponding to the threshold xhist=-1 (or infhist=-1 or infhist=suphist=-1). 
</p>
<p><b>Bayesian inference</b>
</p>
<p>Bayesian inference uses a numerical estimate of the degree of belief in a hypothesis before evidence has been observed and calculates a numerical estimate of the degree of belief in the hypothesis after evidence has been observed.
The name &lsquo;Bayesian&rsquo; comes from the frequent use of Bayes' theorem in the inference process.
In our case the problem is: which is the probability that a frequency function <code class="reqn">P</code> (of type defined in <code>dist</code>) has parameters <code class="reqn">\theta</code>, given that we have observed the realizations <code class="reqn">D</code> (defined in <code>xcont</code>, <code>xhist</code>, <code>infhist</code>, <code>suphist</code>, <code>nbans</code>, <code>seuil</code>).
The Bayes' theorem writes
</p>
<p style="text-align: center;"><code class="reqn">P(\theta|D) = \frac{P(D|\theta) \cdot P(\theta)}{P(D)}</code>
</p>

<p>where 
<code class="reqn">P(\theta|D)</code> is the conditional probability of <code class="reqn">\theta</code>, given <code class="reqn">D</code> (it is also called the posterior probability because it is derived from or depends upon the specified value of <code class="reqn">D</code>) and is the result we are interested in;
<code class="reqn">P(\theta)</code> is the prior probability or marginal probability of <code class="reqn">\theta</code> (&lsquo;prior&rsquo; in the sense that it does not take into account any information about <code class="reqn">D</code>), and can be given using the input <code>apriori</code> (it can be used to account for causal information); 
<code class="reqn">P(D|\theta)</code> is the conditional probability of <code class="reqn">D</code> given <code class="reqn">\theta</code> and it is defined choosing <code>dist</code> and depending on the availability of historical data;
<code class="reqn">P(D)</code> is the prior or marginal probability of <code class="reqn">D</code>, and acts as a normalizing constant.
Intuitively, Bayes' theorem in this form describes the way in which one's beliefs about observing <code class="reqn">\theta</code> are updated by having observed <code class="reqn">D</code>.
</p>
<p>Since complex models cannot be processed in closed form by a Bayesian analysis, namely because of the extreme difficulty in computing the normalization factor <code class="reqn">P(D)</code>, simulation-based Monte Carlo techniques as the MCMC approaches are used.
</p>
<p><b>MCMC Metropolis algorithm</b>
</p>
<p>Markov chain Monte Carlo (MCMC) methods (which include random walk Monte Carlo methods), are a class of algorithms for sampling from probability distributions based on constructing a Markov chain that has the desired distribution as its equilibrium distribution. The state of the chain after a large number of steps is then used as a sample from the desired distribution.
The quality of the sample improves as a function of the number of steps.
</p>
<p>The MCMC is performed here through a simple Metropolis algorithm, i.e. a Metropolis-Hastings algorithm with symmetric proposal density.
The Metropolis-Hastings algorithm can draw samples from any probability distribution <code class="reqn">P(x)</code>, requiring only that a function proportional to the density can be calculated at <code class="reqn">x</code>.
In Bayesian applications, the normalization factor is often extremely difficult to compute, so the ability to generate a sample without knowing this constant of proportionality is a major virtue of the algorithm.
The algorithm generates a Markov chain in which each state <code class="reqn">x_t + 1</code> depends only on the previous state <code class="reqn">x_t</code>.
The algorithm uses a Gaussian proposal density <code class="reqn">N(x_t, \sigma_x)</code>, which depends on the current state <code class="reqn">x_t</code>, to generate a new proposed sample <code class="reqn">x'</code>.
This proposal is accepted as the next value <code class="reqn">x_t + 1 = x'</code> if <code class="reqn">\alpha</code> drawn from <code class="reqn">U(0,1)</code> satisfies
</p>
<p style="text-align: center;"><code class="reqn">\alpha &lt; \frac{P(x')}{P(x_t)}</code>
</p>

<p>If the proposal is not accepted, then the current value of <code class="reqn">x</code> is retained (<code class="reqn">x_t + 1 = x_t</code>).
</p>
<p>The Markov chain is started from a random initial value <code class="reqn">x_0</code> and the algorithm is run for many iterations until this initial state is forgotten. 
These samples, which are discarded, are known as burn-in. 
The remaining set of accepted values of <code class="reqn">x</code> represent a sample from the distribution <code class="reqn">P(x)</code>.
As a Gaussian proposal density (or a lognormal one for definite-positive parameters) is used, the variance parameter <code class="reqn">\sigma_x^2</code> has to be tuned during the burn-in period.
This is done by calculating the acceptance rate, which is the fraction of proposed samples that is accepted in a window of the last <code class="reqn">N</code> samples. 
The desired acceptance rate depends on the target distribution, however it has been shown theoretically that the ideal acceptance rate for a one dimensional Gaussian distribution is approx 50%, decreasing to approx 23% for an N-dimensional Gaussian target distribution.
If <code class="reqn">\sigma_x^2</code> is too small the chain will mix slowly (i.e., the acceptance rate will be too high, so the sampling will move around the space slowly and converge slowly to <code class="reqn">P(x)</code>).
If <code class="reqn">\sigma_x^2</code> is too large the acceptance rate will be very low because the proposals are likely to land in regions of much lower probability density.
The desired acceptance rate is fixed here to 34%.
</p>
<p>The MCMC algorithm is based on a code developed by Eric Gaume on Scilab.
It is still unstable and not all the distributions have been tested.
</p>


<h3>Value</h3>

<p><code>BayesianMCMC</code> and <code>BayesianMCMCcont</code> (which just continues the simulations of <code>BayesianMCMC</code> for local analyses and <code>BayesianMCMCreg</code> and <code>BayesianMCMCregcont</code> for regional analyses return the following values:
</p>
<p><code>BayesianMCMCreg</code> and <code>BayesianMCMCregcont</code> (which just continues the simulations of <code>BayesianMCMC</code> starting from its output) return the following values:
</p>
<p><code>parameters</code> matrix (nbpas)x(nbchaines) with the simulated sets of parameters with the MCMC algorithm;
</p>
<p><code>parametersML</code> set of parameters correspondent to the maximum likelihood;
</p>
<p><code>returnperiods</code> return periods for which <code>quantilesML</code> and <code>intervals</code> are calculated;
</p>
<p><code>quantilesML</code> quantiles correspondent to <code>returnperiods</code> for the distribution whose parameters are <code>parametersML</code>;
</p>
<p><code>logML</code> maximum log-likelihood;
</p>
<p><code>intervals</code> confidence intervals for the quantiles <code>quantilesML</code> for limits <code>confint</code>;
</p>
<p><code>varparameters</code> matrix (nbpas)x(nbchaines)x(number of parameters) with the simulated variances for the MCMC algorithm;
</p>
<p><code>vraisdist</code> likelihoods for the sets <code>parameters</code>;
</p>
<p><code>propsaut</code> vector showing the evolution of the acceptance rate during the Bayesian MCMC fitting;
</p>
<p><code>plot.BayesianMCMC</code> and <code>plot.BayesianMCMCreg</code> (for a normalized surface of 1 km2) plot the following figures:
</p>
<p><code>1</code> data as plotting position (the Cunanne plotting position <code class="reqn">a = 0.4</code> is used), fitted distribution (maximum likelihood) and confidence intervals;
</p>
<p><code>2</code> diagnostic plot of the MCMC simulation (parameters);
</p>
<p><code>3</code> diagnostic plot of the MCMC simulation (likelihood and MCMC acceptance rate);
</p>
<p><code>4</code> posterior distribution of parameters obtained with the MCMC simulation (cloud plots);
</p>
<p><code>5</code> a-priori distribution of parameters (contour plots);
</p>
<p><code>plotBayesianMCMCreg_surf</code> plots the same plot as the first one given by <code>plot.BayesianMCMCreg</code> but for each surface in argument, as well as its mean as a function of the surfaces; 
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>Author(s)</h3>

<p>Eric Gaume, Alberto Viglione, Jose Luis Salinas, Olivier Payrastre, Chi Cong N'guyen, Karine Halbert</p>


<h3>See Also</h3>

<p>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2988)
serie &lt;- rand.GEV(120, xi=40, alfa=20, k=-0.4)
serie100 &lt;- serie[1:100]
serie100[serie100 &lt; 250] &lt;- NA
serie20 &lt;- serie[101:120]
serie &lt;- c(serie100, serie20)


plot(serie, type="h", ylim=c(0, 600), xlab="", 
     ylab="Annual flood peaks [m3/s]", lwd=3)
abline(h=0)
points(serie100, col=2)


## Not run: 
# Using only sistematic data
only_sist &lt;- BayesianMCMC (xcont=serie20, nbpas=5000, nbchaines=3, varparameters0=c(70, 20, 0.5), 
                           confint=c(0.05, 0.95), dist="GEV")
plot(only_sist, which=c(1:3), ask=TRUE, ylim=c(1,600))
only_sist &lt;- BayesianMCMCcont(only_sist)
plot(only_sist, which=c(1:3), ask=TRUE, ylim=c(1,600))
only_sist &lt;- BayesianMCMCcont(only_sist)
plot(only_sist, which=c(1:3), ask=TRUE, ylim=c(1,600))



# Adding the information that the threshold 250 m3/s was exceeded 
#   3 times in the past 100 years
with_hist_thresh &lt;- BayesianMCMC (xcont=serie20, infhist=rep(250,3), 
                                  nbans=100, seuil=250,
                                  nbpas=5000, nbchaines=3, 
                                  confint=c(0.05, 0.95), dist="GEV")
plot(with_hist_thresh, which=c(1:3), ask=TRUE, ylim=c(1,600))



# Assuming that the 3 historical events are known with high uncertainty
with_hist_limits &lt;- BayesianMCMC (xcont=serie20,  
                                  infhist=c(320,320,250), 
                                  suphist=c(360,400,270), 
                                  nbans=100, seuil=250,
                                  nbpas=5000, nbchaines=3, 
                                  confint=c(0.05, 0.95), dist="GEV")
plot(with_hist_limits, which=c(1:3), ask=TRUE, ylim=c(1,600))



# Assuming that the 3 historical events are perfectly known
with_hist_known &lt;- BayesianMCMC (xcont=serie20, xhist=serie100[!is.na(serie100)], 
                                 nbans=100, seuil=250,
                                 nbpas=5000, nbchaines=3, 
                                 confint=c(0.05, 0.95), dist="GEV")
plot(with_hist_known, which=c(1:3), ask=TRUE, ylim=c(1,600))




# Perception threshold without available information on floods
without_info &lt;- BayesianMCMC (xcont=serie20, xhist=-1, 
                                 nbans=100, seuil=2400,
                                 nbpas=5000, nbchaines=3, 
                                 confint=c(0.05, 0.95), dist="GEV")
plot(without_info, which=c(1:3), ask=TRUE, ylim=c(1,600))




# Using one reasonable a-priori distribution
fNORM3 &lt;- function (x) {
 # x = vector of values
 # mu = vector of means
 mu = c(44, 26, -0.40)
 # CM = covariance matrix
 CM = matrix(c(13, 7.8, -0.055,
               7.8, 15, -0.42,
               -0.055, -0.42, 0.056), nrow=3, ncol=3)
 CMm1 &lt;- solve(CM)
 term2 &lt;- exp(-((x - mu) %*% CMm1 %*% (x - mu))/2)
 term1 &lt;- 1/(2*pi)^(3/2)/sqrt(det(CM))
 term1*term2
}

with_hist_known2 &lt;- BayesianMCMC (xcont=serie20, xhist=serie100[!is.na(serie100)], 
                                  nbans=100, seuil=250,
                                  nbpas=5000, nbchaines=3, apriori=fNORM3,
                                  confint=c(0.05, 0.95), dist="GEV")
plot(with_hist_known2, 5)
plot(with_hist_known2, 4)
plot(with_hist_known, 4)
plot(with_hist_known)
plot(with_hist_known2)



# Using one non-reasonable a-priori distribution
fNORM3 &lt;- function (x) {
 # x = vector of values
 # mu = vector of means
 mu = c(30, 50, -0.10)
 # CM = covariance matrix
 CM = matrix(c(13, 7.8, -0.055,
               7.8, 15, -0.42,
               -0.055, -0.42, 0.056), nrow=3, ncol=3)
 CMm1 &lt;- solve(CM)
 term2 &lt;- exp(-((x - mu) %*% CMm1 %*% (x - mu))/2)
 term2
}

with_hist_known3 &lt;- BayesianMCMC (xcont=serie20, xhist=serie100[!is.na(serie100)], 
                                  nbans=100, seuil=250,
                                  nbpas=5000, nbchaines=3, apriori=fNORM3,
                                  confint=c(0.05, 0.95), dist="GEV")
plot(with_hist_known3, 5)
plot(with_hist_known3, 4)
plot(with_hist_known, 4)
plot(with_hist_known)
plot(with_hist_known3)

## End(Not run)

## Not run: 
# Assuming that the historical events are perfectly known and there are 4 different thresholds 
# The data file is presenting this way: 

# xhist nbans seuil 
#  6000    55  6000 
#  7400    28  7250 
#  6350     8  3050 
#  4000     0  3050 
#  4550     0  3050 
#  3950     0  3050 
#  7550    58  2400 
#  4650     0  2400 
#  3950     0  2400 

## Warning: nbans and seuil should have the same length as xhist. 

# So when a threshold is exceeded several times, replicate it as many times it is exceeded 
# and part the number of years of exceedance into the number of times of exceedance 
# (the way you part the nbans vector is not important, what is important is that you have 
# length(nbans)=length(xhist) and the total of years for one same threshold equals the number 
# of years covered by the perception threshold) 
xhist_thres &lt;- c(6000, 7400, 6350, 4000, 4550, 3950, 7550, 4650, 3950) 
seuil_thres &lt;- c(6000, 7250, rep(3050, 4), rep(2400, 3)) 
nbans_thres &lt;- c(55, 28, 8, 0, 0, 0, 58, 0, 0) 

# The threshold at 6000 has been exceeded for 55 years, the one at 7250 for 28 years, 
# the one at 3050 for 8 years and the one at 2400 for 58 years 
with_hist_known_several_thresholds &lt;- BayesianMCMC (xcont=serie20, 
                                                    xhist=xhist_thres, 
                                                    nbans=nbans_thres, seuil=seuil_thres, 
                                                    nbpas=5000, nbchaines=3, 
                                                    confint=c(0.05, 0.95), dist="GEV", 
                                                    varparameters0=c(NA, NA, 0.5)) 
plot(with_hist_known_several_thresholds, which=c(1:3), ask=TRUE)


## REGIONAL:
# Regional analysis, assuming that the 3 historical events are perfectly known and 
# there are 2 perception thresholds
regional_with_hist_known &lt;- BayesianMCMCreg (xcont=serie20, 
                                             scont=c(rep(507,9),rep(2240,11)), 
                                             xhist=serie100[!is.na(serie100)],
				             shist=c(495, 495, 87), 
                                             nbans=c(100, 0, 50), seuil=c(312, 312, 221),
                                             nbpas=5000, nbchaines=3, 
                                             confint=c(0.05, 0.95), dist="GEV", 
                                             varparameters0=c(NA, NA, NA, 0.5))
plot(regional_with_hist_known, which=1:3, ask=TRUE, ylim=c(1,600))

surf=c(571, 2240)
plotBayesianMCMCreg_surf(regional_with_hist_known, surf)

## End(Not run)
</code></pre>

<hr>
<h2 id='bestlm'>Subsets regression</h2><span id='topic+bestlm'></span><span id='topic+print.bestlm'></span><span id='topic+summary.bestlm'></span><span id='topic+.leaps.setup'></span><span id='topic+.leaps.exhaustive'></span><span id='topic+.leaps.backward'></span><span id='topic+.leaps.forward'></span><span id='topic+.leaps.seqrep'></span><span id='topic+.summary.regsubsets'></span><span id='topic+.leaps'></span>

<h3>Description</h3>

<p><code>bestlm</code> performs an exhaustive search for the best subsets of the variables in <code>ind</code> 
for predicting <code>dip</code> in linear regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> bestlm (dip, ind, kmax=4, nbest=3)
 ## S3 method for class 'bestlm'
 print(x, ...)
 ## S3 method for class 'bestlm'
 summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bestlm_+3A_x">x</code></td>
<td>
<p>object of class <code>bestlm</code>, output of function <code>bestlm</code></p>
</td></tr>
<tr><td><code id="bestlm_+3A_object">object</code></td>
<td>
<p>object of class <code>bestlm</code>, output of function <code>bestlm</code></p>
</td></tr>
<tr><td><code id="bestlm_+3A_dip">dip</code></td>
<td>
<p>vector n x 1 of dependent variable to be predicted</p>
</td></tr>
<tr><td><code id="bestlm_+3A_ind">ind</code></td>
<td>
<p>matrix n x K of the K independent variables (candidate predictors)</p>
</td></tr>
<tr><td><code id="bestlm_+3A_kmax">kmax</code></td>
<td>
<p>maximum size (number of regressors) to report</p>
</td></tr>
<tr><td><code id="bestlm_+3A_nbest">nbest</code></td>
<td>
<p>number of subsets of each size to report</p>
</td></tr>
<tr><td><code id="bestlm_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function has been obtained using the function <code>leaps</code> of the R package <code>leaps</code>.
It is based on the Alan Miller's FORTRAN routines.
</p>
<p>Warning:
the function will stop with an error if <code>ind</code> is not of full rank or if it has more than 31 columns.
</p>


<h3>Value</h3>

<p><code>bestlm</code> returns the following values:
</p>
<p><code>subselect</code> matrix (kmax*nbest)x(ncol(ind)) with the sets of chosen linear models, ordered
in function of the adjusted coefficient of determination (R2adj);
</p>
<p><code>R2adj</code> the ordered adjusted coefficient of determination;
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+REGRDIAGNOSTICS">REGRDIAGNOSTICS</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)

bestlm(parameters[,"Dm"], parameters[,-c(1:2)])

regr &lt;- lm(Dm ~ Am + S2000 + NORD, parameters); regr
summary(regr)
</code></pre>

<hr>
<h2 id='DIAGNOSTICS'>Diagnostics of models</h2><span id='topic+DIAGNOSTICS'></span><span id='topic+R2'></span><span id='topic+RMSE'></span><span id='topic+MAE'></span><span id='topic+RMSEP'></span><span id='topic+MAEP'></span>

<h3>Description</h3>

<p>Diagnostics of model results, it compares estimated values <code>y</code> with observed values <code>x</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'> R2 (x, y, na.rm=FALSE)
 RMSE (x, y, na.rm=FALSE) 
 MAE (x, y, na.rm=FALSE)
 RMSEP (x, y, na.rm=FALSE)
 MAEP (x, y, na.rm=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DIAGNOSTICS_+3A_x">x</code></td>
<td>
<p>observed values</p>
</td></tr>
<tr><td><code id="DIAGNOSTICS_+3A_y">y</code></td>
<td>
<p>estimated values</p>
</td></tr>
<tr><td><code id="DIAGNOSTICS_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">x_i</code> are the observed values, <code class="reqn">y_i</code> the estimated values, with <code class="reqn">i=1,...,n</code>, and <code class="reqn">\bar{x}</code> the sample mean of <code class="reqn">x_i</code>, then:
</p>
<p style="text-align: center;"><code class="reqn">R^2 = 1 - \frac{\sum_1^n (x_i-y_i)^2}{\sum_1^n x_i^2 - n \bar{x}^2}</code>
</p>

<p style="text-align: center;"><code class="reqn">RMSE = \sqrt{\frac{1}{n} \sum_1^n (x_i-y_i)^2}</code>
</p>

<p style="text-align: center;"><code class="reqn">MAE = \frac{1}{n} \sum_1^n |x_i-y_i|</code>
</p>

<p style="text-align: center;"><code class="reqn">RMSEP = \sqrt{\frac{1}{n} \sum_1^n ((x_i-y_i)/x_i)^2}</code>
</p>

<p style="text-align: center;"><code class="reqn">MAEP = \frac{1}{n} \sum_1^n |(x_i-y_i)/x_i|</code>
</p>

<p>See <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination">https://en.wikipedia.org/wiki/Coefficient_of_determination</a>, <a href="https://en.wikipedia.org/wiki/Mean_squared_error">https://en.wikipedia.org/wiki/Mean_squared_error</a> and <a href="https://en.wikipedia.org/wiki/Mean_absolute_error">https://en.wikipedia.org/wiki/Mean_absolute_error</a> for other details.
</p>


<h3>Value</h3>

<p><code>R2</code> returns the coefficient of determination <code class="reqn">R^2</code> of a model.
</p>
<p><code>RMSE</code> returns the root mean squared error of a model.
</p>
<p><code>MAE</code> returns the mean absolute error of a model.
</p>
<p><code>RMSE</code> returns the percentual root mean squared error of a model.
</p>
<p><code>MAE</code> returns the percentual mean absolute error of a model.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+summary.lm">summary.lm</a></code>, <code><a href="stats.html#topic+predict.lm">predict.lm</a></code>, <code><a href="#topic+REGRDIAGNOSTICS">REGRDIAGNOSTICS</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)

datregr &lt;- parameters
regr0 &lt;- lm(Dm ~ .,datregr); summary(regr0)
regr1 &lt;- lm(Dm ~ Am + Hm + Ybar,datregr); summary(regr1)

obs &lt;- parameters[,"Dm"]
est0 &lt;- regr0$fitted.values
est1 &lt;- regr1$fitted.values

R2(obs, est0)
R2(obs, est1)

RMSE(obs, est0)
RMSE(obs, est1)

MAE(obs, est0)
MAE(obs, est1)

RMSEP(obs, est0)
RMSEP(obs, est1)

MAEP(obs, est0)
MAEP(obs, est1)
</code></pre>

<hr>
<h2 id='DISTPLOTS'>Empirical distribution plots</h2><span id='topic+DISTPLOTS'></span><span id='topic+plotpos'></span><span id='topic+plotposRP'></span><span id='topic+loglogplot'></span><span id='topic+unifplot'></span><span id='topic+normplot'></span><span id='topic+lognormplot'></span><span id='topic+studentplot'></span><span id='topic+logisplot'></span><span id='topic+gammaplot'></span><span id='topic+expplot'></span><span id='topic+paretoplot'></span><span id='topic+gumbelplot'></span><span id='topic+frechetplot'></span><span id='topic+weibullplot'></span><span id='topic+plotposRPhist'></span><span id='topic+pointspos'></span><span id='topic+pointsposRP'></span><span id='topic+loglogpoints'></span><span id='topic+unifpoints'></span><span id='topic+normpoints'></span><span id='topic+studentpoints'></span><span id='topic+logispoints'></span><span id='topic+gammapoints'></span><span id='topic+exppoints'></span><span id='topic+gumbelpoints'></span><span id='topic+weibullpoints'></span><span id='topic+regionalplotpos'></span><span id='topic+regionalnormplot'></span><span id='topic+regionallognormplot'></span><span id='topic+regionalexpplot'></span><span id='topic+regionalparetoplot'></span><span id='topic+regionalgumbelplot'></span><span id='topic+regionalfrechetplot'></span><span id='topic+pointsposRPhist'></span>

<h3>Description</h3>

<p>Sample values are plotted against their empirical distribution in graphs where points belonging to a particular distribution should lie on a straight line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> plotpos (x, a=0, orient="xF", ...)
 plotposRP (x, a=0, orient="xF", ...)
 loglogplot (x, a=0, orient="xF", ...)
 unifplot (x, a=0, orient="xF", line=FALSE, ...)
 normplot (x, a=0, orient="xF", line=FALSE, ...)
 lognormplot (x, a=0, orient="xF", line=FALSE, ...)
 studentplot (x, df, a=0, orient="xF", line=FALSE,...)
 logisplot (x, a=0, orient="xF", line=FALSE,...)
 gammaplot (x, shape, a=0, orient="xF", line=FALSE,...)
 expplot (x, a=0, orient="xF", line=FALSE,...)
 paretoplot (x, a=0, orient="xF", line=FALSE,...)
 gumbelplot (x, a=0, orient="xF", line=FALSE, ...)
 frechetplot (x, a=0, orient="xF", line=FALSE,...)
 weibullplot (x, a=0, orient="xF", line=FALSE,...)
 plotposRPhist (xcont, xhist=NA, infhist=NA, suphist=NA, nbans=NA, seuil=NA, 
                col12=c(1,1), a=0, orient="xF", ...)
 pointspos (x, a=0, orient="xF", ...)
 pointsposRP (x, a=0, orient="xF", ...)
 loglogpoints (x, a=0, orient="xF", ...)
 unifpoints (x, a=0, orient="xF", ...)
 normpoints (x, a=0, orient="xF", ...)
 studentpoints (x, df, a=0, orient="xF", ...)
 logispoints (x, a=0, orient="xF", ...)
 gammapoints (x, shape, a=0, orient="xF", ...)
 exppoints (x, a=0, orient="xF", ...)
 gumbelpoints (x, a=0, orient="xF", ...)
 weibullpoints (x, a=0, orient="xF", ...)
 regionalplotpos (x, cod, a=0, orient="xF", ...)
 regionalnormplot (x, cod, a=0, orient="xF", ...)
 regionallognormplot (x, cod, a=0, orient="xF", ...)
 regionalexpplot (x, cod, a=0, orient="xF", ...)
 regionalparetoplot (x, cod, a=0, orient="xF", ...)
 regionalgumbelplot (x, cod, a=0, orient="xF", ...)
 regionalfrechetplot (x, cod, a=0, orient="xF", ...)
 pointsposRPhist (xcont, xhist=NA, infhist=NA, suphist=NA, nbans=NA, seuil=NA, 
                  col12=c(1,1), a=0, orient="xF", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DISTPLOTS_+3A_x">x</code></td>
<td>
<p>vector representing a data-sample</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_xcont">xcont</code></td>
<td>
<p>vector of systematic data (see <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_xhist">xhist</code></td>
<td>
<p>vector of historical data (see <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_infhist">infhist</code></td>
<td>
<p>inferior limit for historical data (see <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_suphist">suphist</code></td>
<td>
<p>superior limit for historical data (see <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_nbans">nbans</code></td>
<td>
<p>period (in years) over which the threshold has not been exceeded except for the historical data (see <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_seuil">seuil</code></td>
<td>
<p>threshold non exceeded in the historical period except for the historical data (see <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_df">df</code></td>
<td>
<p>degrees of freedom (&gt; 0, maybe non-integer) of the Student t distribution.  'df = Inf' is allowed.</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_shape">shape</code></td>
<td>
<p>shape parameter of the distribution</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_a">a</code></td>
<td>
<p>plotting position parameter, normally between 0 and 0.5 (the default value here, corresponding to the Hazen plotting position, see details)</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_orient">orient</code></td>
<td>
<p>if <code>orient="xF"</code> the abscissa will be x and the ordinate F</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_line">line</code></td>
<td>
<p>if TRUE (default) a straight line indicating the normal, lognormal, ..., distribution with parameters estimated from <code>x</code> is plotted</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_cod">cod</code></td>
<td>
<p>array that defines the data subdivision among sites</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_col12">col12</code></td>
<td>
<p>vector of 2 elements containing the colors for the systematic and historical data respectively</p>
</td></tr>
<tr><td><code id="DISTPLOTS_+3A_...">...</code></td>
<td>
<p>graphical parameters as <code>xlab</code>, <code>ylab</code>, <code>main</code>, ...</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A brief introduction on Probability Plots (or Quantile-Quantile plots) is available on <a href="https://en.wikipedia.org/wiki/Q-Q_plot">https://en.wikipedia.org/wiki/Q-Q_plot</a>.
For plotting positions see <a href="https://en.wikipedia.org/wiki/Plotting_position">https://en.wikipedia.org/wiki/Plotting_position</a>.
</p>
<p>For the quantiles of the comparison distribution typically the Weibull formula <code class="reqn">k/(n + 1)</code> is used (default here). 
Several different formulas have been used or proposed as symmetrical plotting positions. 
Such formulas have the form 
</p>
<p style="text-align: center;"><code class="reqn">(k - a)/(n + 1 - 2a)</code>
</p>
 
<p>for some value of <code class="reqn">a</code> in the range from 0 to 1/2. 
The above expression <code class="reqn">k/(n+1)</code> is one example of these, for <code class="reqn">a=0</code>. 
The Filliben plotting position has <code class="reqn">a = 0.3175</code> and the Cunanne plotting position has <code class="reqn">a = 0.4</code> should be nearly quantile-unbiased for a range of distributions.
The Hazen plotting position, widely used by engineers, has <code class="reqn">a = 0.5</code>.
The Blom's plotting position, <code class="reqn">a = 3/8</code>, gives nearly unbiased quantiles for the normal distribution, while the Gringeton plotting position, <code class="reqn">a = 0.44</code>, is optimized for the largest observations from a Gumbel distribution.
For the generalized Pareto, the GEV and related distributions of the Type I (Gumbel) and Weibull, <code class="reqn">a = 0.35</code> is suggested.
</p>
<p>For large sample size, <code class="reqn">n</code>, there is little difference between these various expressions.
</p>


<h3>Value</h3>

<p>Representation of the values of <code>x</code> vs their empirical probability function <code class="reqn">F</code> in a cartesian, uniform, normal, lognormal or Gumbel plot. 
<code>plotpos</code> and <code>unifplot</code> are analogous except for the axis notation, <code>unifplot</code> has the same notation as <code>normplot</code>, <code>lognormplot</code>, ...
<code>plotposRP</code> is analogous to <code>plotpos</code> but the frequencies <code class="reqn">F</code> are expressed as Return Periods <code class="reqn">T=1/(1-F)</code>.
With the default settings, <code class="reqn">F</code> is defined with the Weibull plotting position <code class="reqn">F=k/(n+1)</code>.
The straight line (if <code>line</code>=TRUE) indicate the uniform, normal, lognormal or Gumbel distribution with parameters estimated from <code>x</code>.
The regional plots draw samples of a region on the same plot. 
</p>
<p><code>pointspos</code>, <code>normpoints</code>, ... are the analogous of <code>points</code>, they can be used to add points or lines to <code>plotpos</code>, <code>normplot</code>, ...
<code>normpoints</code> can be used either on <code>normplot</code> or <code>lognormplot</code>.
<code>exppoints</code> can be used either on <code>expplot</code> or <code>paretoplot</code> (since the log-transformed Pareto random variable is exponentially distributed).
<code>gumbelpoints</code> can be used either on <code>gumbelplot</code> or <code>frechetplot</code> (since the log-transformed Frechet random variable is distributed as a Gumbel).
</p>
<p><code>loglogplot</code> plots the logarithm of sample vs the logarithm of the empirical exceedance probability. For the log-log plot, the tail probability is represented by a straight line for power-law distributions (e.g. log-pearson, log-logistic, Frechet, ..., HEAVY TAIL), but not for the other subexponential or exponential distributions (e.g. gumbel, gamma, Pearson type III, ..., MODERATE TAIL); see El Adlouni et al. (2008).
</p>
<p><code>plotposRPhist</code> is based on the method in Stedinger et al. (1993, pp. 18.41-42).
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p>These functons are analogous to <code><a href="stats.html#topic+qqnorm">qqnorm</a></code>; for the distributions, see <code><a href="stats.html#topic+Normal">Normal</a></code>, <code><a href="stats.html#topic+Lognormal">Lognormal</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(30,10,2)
plotpos(x)
normplot(x)
normplot(x,xlab=expression(D[m]),ylab=expression(hat(F)),
         main="Normal plot",cex.main=1,font.main=1)
normplot(x,line=FALSE)

x &lt;- rlnorm(30,log(100),log(10))
normplot(x)
lognormplot(x)

x &lt;- rand.gumb(30,1000,100)
normplot(x)
gumbelplot(x)

x &lt;- rnorm(30,10,2)
y &lt;- rnorm(50,10,3)
z &lt;- c(x,y)
codz &lt;- c(rep(1,30),rep(2,50))
regionalplotpos(z,codz)
regionalnormplot(z,codz,xlab="z")
regionallognormplot(z,codz)
regionalgumbelplot(z,codz)

plotpos(x)
pointspos(y,pch=2,col=2)

x &lt;- rnorm(50,10,2)
F &lt;- seq(0.01,0.99,by=0.01)
qq &lt;- qnorm(F,10,2)
plotpos(x)
pointspos(qq,type="l")

normplot(x,line=FALSE)
normpoints(x,type="l",lty=2,col=3)

lognormplot(x)
normpoints(x,type="l",lty=2,col=3)

gumbelplot(x)
gumbelpoints(x,type="l",lty=2,col=3)

# distributions comparison in probabilistic graphs
x &lt;- rnorm(50,10,2)
F &lt;- seq(0.001,0.999,by=0.001)
loglikelhood &lt;- function(param) {-sum(dgamma(x, shape=param[1], 
                scale=param[2], log=TRUE))}
parameters &lt;- optim(c(1,1),loglikelhood)$par
qq &lt;- qgamma(F,shape=parameters[1],scale=parameters[2])
plotpos(x)
pointspos(qq,type="l")

normplot(x,line=FALSE)
normpoints(qq,type="l")

lognormplot(x,line=FALSE)
normpoints(qq,type="l")

</code></pre>

<hr>
<h2 id='EXP'>Two parameter exponential distribution and L-moments</h2><span id='topic+EXP'></span><span id='topic+f.exp'></span><span id='topic+F.exp'></span><span id='topic+invF.exp'></span><span id='topic+Lmom.exp'></span><span id='topic+par.exp'></span><span id='topic+rand.exp'></span>

<h3>Description</h3>

<p><code>EXP</code> provides the link between L-moments of a sample and the two parameter
exponential distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.exp (x, xi, alfa)
F.exp (x, xi, alfa)
invF.exp (F, xi, alfa)
Lmom.exp (xi, alfa)
par.exp (lambda1, lambda2)
rand.exp (numerosita, xi, alfa)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EXP_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="EXP_+3A_xi">xi</code></td>
<td>
<p>vector of exp location parameters</p>
</td></tr>
<tr><td><code id="EXP_+3A_alfa">alfa</code></td>
<td>
<p>vector of exp scale parameters</p>
</td></tr>
<tr><td><code id="EXP_+3A_f">F</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="EXP_+3A_lambda1">lambda1</code></td>
<td>
<p>vector of sample means</p>
</td></tr>
<tr><td><code id="EXP_+3A_lambda2">lambda2</code></td>
<td>
<p>vector of L-variances</p>
</td></tr>
<tr><td><code id="EXP_+3A_numerosita">numerosita</code></td>
<td>
<p>numeric value indicating the length of the vector to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://en.wikipedia.org/wiki/Exponential_distribution">https://en.wikipedia.org/wiki/Exponential_distribution</a> for a brief introduction on the Exponential distribution.
</p>
<p><b>Definition</b>
</p>
<p>Parameters (2): <code class="reqn">\xi</code> (lower endpoint of the distribution), <code class="reqn">\alpha</code> (scale).
</p>
<p>Range of <code class="reqn">x</code>: <code class="reqn">\xi \le x &lt; \infty</code>.
</p>
<p>Probability density function:
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} \exp\{-(x-\xi)/\alpha\}</code>
</p>

<p>Cumulative distribution function:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \exp\{-(x-\xi)/\alpha\}</code>
</p>

<p>Quantile function:
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi - \alpha \log(1-F)</code>
</p>

<p><b>L-moments</b>
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = 1/2 \cdot \alpha</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = 1/3</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = 1/6</code>
</p>

<p><b>Parameters</b>
</p>
<p>If <code class="reqn">\xi</code> is known, <code class="reqn">\alpha</code> is given by <code class="reqn">\alpha = \lambda_1 - \xi</code> and the L-moment, moment, and maximum-likelihood estimators are identical.
If <code class="reqn">\xi</code> is unknown, the parameters are given by
</p>
<p style="text-align: center;"><code class="reqn">\alpha = 2 \lambda_2</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \lambda_1 - \alpha</code>
</p>

<p>For estimation based on a single sample these estimates are inefficient, but in regional frequency analysis they can give reasonable estimates of upper-tail quantiles.
</p>
<p><code>Lmom.exp</code> and <code>par.exp</code> accept input as vectors of equal length. In <code>f.exp</code>, <code>F.exp</code>, <code>invF.exp</code> and <code>rand.exp</code> parameters (<code>xi</code>, <code>alfa</code>) must be atomic.
</p>


<h3>Value</h3>

<p><code>f.exp</code> gives the density <code class="reqn">f</code>, <code>F.exp</code> gives the distribution function <code class="reqn">F</code>, <code>invFexp</code> gives
the quantile function <code class="reqn">x</code>, <code>Lmom.exp</code> gives the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>), <code>par.exp</code> gives the parameters (<code>xi</code>, <code>alfa</code>), and <code>rand.exp</code> generates random deviates.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="#topic+GENLOGIS">GENLOGIS</a></code>, <code><a href="#topic+GENPAR">GENPAR</a></code>, <code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>, <code><a href="#topic+KAPPA">KAPPA</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>, <code><a href="#topic+P3">P3</a></code>; <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>, <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
fac &lt;- factor(annualflows["cod"][,])
split(x,fac)

camp &lt;- split(x,fac)$"45"
ll &lt;- Lmoments(camp)
parameters &lt;- par.exp(ll[1],ll[2])
f.exp(1800,parameters$xi,parameters$alfa)
F.exp(1800,parameters$xi,parameters$alfa)
invF.exp(0.7870856,parameters$xi,parameters$alfa)
Lmom.exp(parameters$xi,parameters$alfa)
rand.exp(100,parameters$xi,parameters$alfa)

Rll &lt;- regionalLmoments(x,fac); Rll
parameters &lt;- par.exp(Rll[1],Rll[2])
Lmom.exp(parameters$xi,parameters$alfa)
</code></pre>

<hr>
<h2 id='FEH1000'>Data-sample</h2><span id='topic+FEH1000'></span><span id='topic+cd'></span><span id='topic+am'></span>

<h3>Description</h3>

<p>Flood Estimation Handbook flood peak data CD-ROM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> data(FEH1000)
</code></pre>


<h3>Format</h3>

<p>Data.frames:
</p>
<p><code>am</code> is the data.frame of the annual maximum flows with 3 columns: 
<code>number</code>, the code of the station; 
<code>date</code>, date of the annual maximum; 
<code>year</code>, year of the annual maximum (we consider hydrologic year: 1 october - 30 september);
<code>am</code>, the value of the annual maximum flow [m3/s].
</p>
<p><code>cd</code> is the data.frame of parameters of 1000 catchements with 24 columns: 
<code>number</code>, the code of the station;
<code>nominal_area</code>, catchment drainage area [km2];
<code>nominal_ngr_x</code>, basin outflow coordinates [m];
<code>nominal_ngr_y</code>, basin outflow coordinates [m];
<code>ihdtm_ngr_x</code>, basin outflow coordinates by Institute of Hydrology digital terrain model [m]; 
<code>ihdtm_ngr_y</code>, basin outflow coordinates by Institute of Hydrology digital terrain model [m];
<code>dtm_area</code>, catchment drainage area [km2] derived by CEH using their DTM (IHDTM);
<code>saar4170</code>, standard average annual rainfall 1941-1970 [mm]; 
<code>bfihost</code>, baseflow index derived from HOST soils data;
<code>sprhost</code>, standard percentage runoff derived from HOST soils data;
<code>farl</code>, index of flood attenuation due to reservoirs and lakes; 
<code>saar</code>, standard average annual rainfall 1961-1990 [mm];
<code>rmed_1d</code>, median annual maximum 1-day rainfall [mm];
<code>rmed_2d</code>, median annual maximum 2-days rainfall [mm];
<code>rmed_1h</code>, median annual maximum 1-hour rainfall [mm];
<code>smdbar</code>, mean SMD (soil moisture deficit) for the period 1961-1990 calculated from MORECS month-end values [mm];
<code>propwet</code>, proportion of time when soil moisture deficit &lt;=6 mm during 1961-90, defined using MORECS;
<code>ldp</code>, longest drainage path [km], defined by recording the greatest distance from a catchment node to the defined outlet;
<code>dplbar</code>, mean drainage path length [km];
<code>altbar</code>, mean catchment altitude [m];
<code>dpsbar</code>, mean catchement slope [m/km];
<code>aspbar</code>, index representing the dominant aspect of catchment slopes (its values increase clockwise from zero to 360, starting from the north). Mean direction of all inter-nodal slopes with north being zero;
<code>aspvar</code>, index describing the invariability in aspect of catchment slopes. Values close to one when all slopes face a similar direction;
<code>urbext1990</code>, extent of urban and suburban land cover in 1990 [fraction].
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>Source</h3>

<p>http://www.environment-agency.gov.uk/hiflowsuk/</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(FEH1000)
names(cd)
am[1:20,]
</code></pre>

<hr>
<h2 id='functionsLaio'>Data-sample</h2><span id='topic+df.kgev'></span><span id='topic+df.polig'></span>

<h3>Description</h3>

<p>Functions for inversion calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> data(functionsLaio)
</code></pre>


<h3>Format</h3>

<p>Data.frames:
</p>
<p><code>df.kgev</code> is a data.frame with the skewness coefficient (first column) and the corresponding shape parameter of the GEV (second column) 
</p>
<p><code>df.polig</code> represents the poligamma function.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>

<hr>
<h2 id='GENLOGIS'>Three parameter generalized logistic distribution and L-moments</h2><span id='topic+GENLOGIS'></span><span id='topic+f.genlogis'></span><span id='topic+F.genlogis'></span><span id='topic+invF.genlogis'></span><span id='topic+Lmom.genlogis'></span><span id='topic+par.genlogis'></span><span id='topic+rand.genlogis'></span>

<h3>Description</h3>

<p><code>GENLOGIS</code> provides the link between L-moments of a sample and the three parameter
generalized logistic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.genlogis (x, xi, alfa, k)
F.genlogis (x, xi, alfa, k)
invF.genlogis (F, xi, alfa, k)
Lmom.genlogis (xi, alfa, k)
par.genlogis (lambda1, lambda2, tau3)
rand.genlogis (numerosita, xi, alfa, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GENLOGIS_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="GENLOGIS_+3A_xi">xi</code></td>
<td>
<p>vector of genlogis location parameters</p>
</td></tr>
<tr><td><code id="GENLOGIS_+3A_alfa">alfa</code></td>
<td>
<p>vector of genlogis scale parameters</p>
</td></tr>
<tr><td><code id="GENLOGIS_+3A_k">k</code></td>
<td>
<p>vector of genlogis shape parameters</p>
</td></tr>
<tr><td><code id="GENLOGIS_+3A_f">F</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="GENLOGIS_+3A_lambda1">lambda1</code></td>
<td>
<p>vector of sample means</p>
</td></tr>
<tr><td><code id="GENLOGIS_+3A_lambda2">lambda2</code></td>
<td>
<p>vector of L-variances</p>
</td></tr>
<tr><td><code id="GENLOGIS_+3A_tau3">tau3</code></td>
<td>
<p>vector of L-CA (or L-skewness)</p>
</td></tr>
<tr><td><code id="GENLOGIS_+3A_numerosita">numerosita</code></td>
<td>
<p>numeric value indicating the length of the vector to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://en.wikipedia.org/wiki/Logistic_distribution">https://en.wikipedia.org/wiki/Logistic_distribution</a> for an introduction to the Logistic Distribution.
</p>
<p><b>Definition</b>
</p>
<p>Parameters (3): <code class="reqn">\xi</code> (location), <code class="reqn">\alpha</code> (scale), <code class="reqn">k</code> (shape).
</p>
<p>Range of <code class="reqn">x</code>: <code class="reqn">-\infty &lt; x \le \xi + \alpha / k</code> if <code class="reqn">k&gt;0</code>;
<code class="reqn">-\infty &lt; x &lt; \infty</code> if <code class="reqn">k=0</code>;
<code class="reqn">\xi + \alpha / k \le x &lt; \infty</code> if <code class="reqn">k&lt;0</code>.
</p>
<p>Probability density function:
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\alpha^{-1} e^{-(1-k)y}}{(1+e^{-y})^2}</code>
</p>

<p>where <code class="reqn">y = -k^{-1}\log\{1 - k(x - \xi)/\alpha\}</code> if <code class="reqn">k \ne 0</code>,
<code class="reqn">y = (x-\xi)/\alpha</code> if <code class="reqn">k=0</code>.
</p>
<p>Cumulative distribution function:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1/(1+e^{-y})</code>
</p>

<p>Quantile function:
<code class="reqn">x(F) = \xi + \alpha[1-\{(1-F)/F\}^k]/k</code> if <code class="reqn">k \ne 0</code>,
<code class="reqn">x(F) = \xi - \alpha \log\{(1-F)/F\}</code> if <code class="reqn">k=0</code>.
</p>
<p><code class="reqn">k=0</code> is the logistic distribution.
</p>
<p><b>L-moments</b>
</p>
<p>L-moments are defined for <code class="reqn">-1&lt;k&lt;1</code>.
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha[1/k - \pi / \sin (k \pi)]</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \alpha k \pi / \sin (k \pi)</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = -k</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = (1+5 k^2)/6</code>
</p>

<p><b>Parameters</b>
</p>
<p><code class="reqn">k=-\tau_3</code>, <code class="reqn">\alpha = \frac{\lambda_2 \sin (k \pi)}{k \pi}</code>, 
<code class="reqn">\xi = \lambda_1 - \alpha (\frac{1}{k} - \frac{\pi}{\sin (k \pi)})</code>.
</p>
<p><code>Lmom.genlogis</code> and <code>par.genlogis</code> accept input as vectors of equal length. In <code>f.genlogis</code>, <code>F.genlogis</code>, <code>invF.genlogis</code> and <code>rand.genlogis</code> parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>) must be atomic.
</p>


<h3>Value</h3>

<p><code>f.genlogis</code> gives the density <code class="reqn">f</code>, <code>F.genlogis</code> gives the distribution function <code class="reqn">F</code>, <code>invF.genlogis</code> gives the quantile function <code class="reqn">x</code>, <code>Lmom.genlogis</code> gives the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>), <code>par.genlogis</code> gives the parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>), and <code>rand.genlogis</code> generates random deviates.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="#topic+EXP">EXP</a></code>, <code><a href="#topic+GENPAR">GENPAR</a></code>, <code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>, <code><a href="#topic+KAPPA">KAPPA</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>, <code><a href="#topic+P3">P3</a></code>; <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>, <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
fac &lt;- factor(annualflows["cod"][,])
split(x,fac)

camp &lt;- split(x,fac)$"45"
ll &lt;- Lmoments(camp)
parameters &lt;- par.genlogis(ll[1],ll[2],ll[4])
f.genlogis(1800,parameters$xi,parameters$alfa,parameters$k)
F.genlogis(1800,parameters$xi,parameters$alfa,parameters$k)
invF.genlogis(0.7697433,parameters$xi,parameters$alfa,parameters$k)
Lmom.genlogis(parameters$xi,parameters$alfa,parameters$k)
rand.genlogis(100,parameters$xi,parameters$alfa,parameters$k)

Rll &lt;- regionalLmoments(x,fac); Rll
parameters &lt;- par.genlogis(Rll[1],Rll[2],Rll[4])
Lmom.genlogis(parameters$xi,parameters$alfa,parameters$k)
</code></pre>

<hr>
<h2 id='GENPAR'>Three parameter generalized Pareto distribution and L-moments</h2><span id='topic+GENPAR'></span><span id='topic+f.genpar'></span><span id='topic+F.genpar'></span><span id='topic+invF.genpar'></span><span id='topic+Lmom.genpar'></span><span id='topic+par.genpar'></span><span id='topic+rand.genpar'></span>

<h3>Description</h3>

<p><code>GENPAR</code> provides the link between L-moments of a sample and the three parameter
generalized Pareto distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.genpar (x, xi, alfa, k)
F.genpar (x, xi, alfa, k)
invF.genpar (F, xi, alfa, k)
Lmom.genpar (xi, alfa, k)
par.genpar (lambda1, lambda2, tau3)
rand.genpar (numerosita, xi, alfa, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GENPAR_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="GENPAR_+3A_xi">xi</code></td>
<td>
<p>vector of genpar location parameters</p>
</td></tr>
<tr><td><code id="GENPAR_+3A_alfa">alfa</code></td>
<td>
<p>vector of genpar scale parameters</p>
</td></tr>
<tr><td><code id="GENPAR_+3A_k">k</code></td>
<td>
<p>vector of genpar shape parameters</p>
</td></tr>
<tr><td><code id="GENPAR_+3A_f">F</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="GENPAR_+3A_lambda1">lambda1</code></td>
<td>
<p>vector of sample means</p>
</td></tr>
<tr><td><code id="GENPAR_+3A_lambda2">lambda2</code></td>
<td>
<p>vector of L-variances</p>
</td></tr>
<tr><td><code id="GENPAR_+3A_tau3">tau3</code></td>
<td>
<p>vector of L-CA (or L-skewness)</p>
</td></tr>
<tr><td><code id="GENPAR_+3A_numerosita">numerosita</code></td>
<td>
<p>numeric value indicating the length of the vector to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://en.wikipedia.org/wiki/Pareto_distribution">https://en.wikipedia.org/wiki/Pareto_distribution</a> for an introduction to the Pareto distribution.
</p>
<p><b>Definition</b>
</p>
<p>Parameters (3): <code class="reqn">\xi</code> (location), <code class="reqn">\alpha</code> (scale), <code class="reqn">k</code> (shape).
</p>
<p>Range of <code class="reqn">x</code>: <code class="reqn">\xi &lt; x \le \xi + \alpha / k</code> if <code class="reqn">k&gt;0</code>;
<code class="reqn">\xi \le x &lt; \infty</code> if <code class="reqn">k \le 0</code>.
</p>
<p>Probability density function:
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} e^{-(1-k)y}</code>
</p>

<p>where <code class="reqn">y = -k^{-1}\log\{1 - k(x - \xi)/\alpha\}</code> if <code class="reqn">k \ne 0</code>,
<code class="reqn">y = (x-\xi)/\alpha</code> if <code class="reqn">k=0</code>.
</p>
<p>Cumulative distribution function:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1-e^{-y}</code>
</p>

<p>Quantile function:
<code class="reqn">x(F) = \xi + \alpha[1-(1-F)^k]/k</code> if <code class="reqn">k \ne 0</code>,
<code class="reqn">x(F) = \xi - \alpha \log(1-F)</code> if <code class="reqn">k=0</code>.
</p>
<p><code class="reqn">k=0</code> is the exponential distribution; <code class="reqn">k=1</code> is the uniform distribution on the interval <code class="reqn">\xi &lt; x \le \xi + \alpha</code>.
</p>
<p><b>L-moments</b>
</p>
<p>L-moments are defined for <code class="reqn">k&gt;-1</code>.
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha/(1+k)]</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \alpha/[(1+k)(2+k)]</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = (1-k)/(3+k)</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = (1-k)(2-k)/[(3+k)(4+k)]</code>
</p>

<p>The relation between <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{\tau_3 (1 + 5 \tau_3)}{5+\tau_3}</code>
</p>

<p><b>Parameters</b>
</p>
<p>If <code class="reqn">\xi</code> is known, <code class="reqn">k=(\lambda_1 - \xi)/\lambda_2 - 2</code> and <code class="reqn">\alpha=(1+k)(\lambda_1 - \xi)</code>;
if <code class="reqn">\xi</code> is unknown, <code class="reqn">k=(1 - 3 \tau_3)/(1 + \tau_3)</code>, <code class="reqn">\alpha=(1+k)(2+k)\lambda_2</code> and
<code class="reqn">\xi=\lambda_1 - (2+k)\lambda_2</code>.
</p>
<p><code>Lmom.genpar</code> and <code>par.genpar</code> accept input as vectors of equal length. In <code>f.genpar</code>, <code>F.genpar</code>, <code>invF.genpar</code> and <code>rand.genpar</code> parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>) must be atomic.
</p>


<h3>Value</h3>

<p><code>f.genpar</code> gives the density <code class="reqn">f</code>, <code>F.genpar</code> gives the distribution function <code class="reqn">F</code>, <code>invF.genpar</code> gives
the quantile function <code class="reqn">x</code>, <code>Lmom.genpar</code> gives the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>), <code>par.genpar</code>
gives the parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>), and <code>rand.genpar</code> generates random deviates.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="#topic+EXP">EXP</a></code>, <code><a href="#topic+GENLOGIS">GENLOGIS</a></code>, <code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>, <code><a href="#topic+KAPPA">KAPPA</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>, <code><a href="#topic+P3">P3</a></code>; <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>, <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
fac &lt;- factor(annualflows["cod"][,])
split(x,fac)

camp &lt;- split(x,fac)$"45"
ll &lt;- Lmoments(camp)
parameters &lt;- par.genpar(ll[1],ll[2],ll[4])
f.genpar(1800,parameters$xi,parameters$alfa,parameters$k)
F.genpar(1800,parameters$xi,parameters$alfa,parameters$k)
invF.genpar(0.7161775,parameters$xi,parameters$alfa,parameters$k)
Lmom.genpar(parameters$xi,parameters$alfa,parameters$k)
rand.genpar(100,parameters$xi,parameters$alfa,parameters$k)

Rll &lt;- regionalLmoments(x,fac); Rll
parameters &lt;- par.genpar(Rll[1],Rll[2],Rll[4])
Lmom.genpar(parameters$xi,parameters$alfa,parameters$k)
</code></pre>

<hr>
<h2 id='GEV'>Three parameter generalized extreme value distribution and L-moments</h2><span id='topic+GEV'></span><span id='topic+f.GEV'></span><span id='topic+F.GEV'></span><span id='topic+invF.GEV'></span><span id='topic+Lmom.GEV'></span><span id='topic+par.GEV'></span><span id='topic+rand.GEV'></span>

<h3>Description</h3>

<p><code>GEV</code> provides the link between L-moments of a sample and the three parameter
generalized extreme value distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.GEV (x, xi, alfa, k)
F.GEV (x, xi, alfa, k)
invF.GEV (F, xi, alfa, k)
Lmom.GEV (xi, alfa, k)
par.GEV (lambda1, lambda2, tau3)
rand.GEV (numerosita, xi, alfa, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GEV_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="GEV_+3A_xi">xi</code></td>
<td>
<p>vector of GEV location parameters</p>
</td></tr>
<tr><td><code id="GEV_+3A_alfa">alfa</code></td>
<td>
<p>vector of GEV scale parameters</p>
</td></tr>
<tr><td><code id="GEV_+3A_k">k</code></td>
<td>
<p>vector of GEV shape parameters</p>
</td></tr>
<tr><td><code id="GEV_+3A_f">F</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="GEV_+3A_lambda1">lambda1</code></td>
<td>
<p>vector of sample means</p>
</td></tr>
<tr><td><code id="GEV_+3A_lambda2">lambda2</code></td>
<td>
<p>vector of L-variances</p>
</td></tr>
<tr><td><code id="GEV_+3A_tau3">tau3</code></td>
<td>
<p>vector of L-CA (or L-skewness)</p>
</td></tr>
<tr><td><code id="GEV_+3A_numerosita">numerosita</code></td>
<td>
<p>numeric value indicating the length of the vector to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution">https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution</a> for an introduction to the GEV distribution.
</p>
<p><b>Definition</b>
</p>
<p>Parameters (3): <code class="reqn">\xi</code> (location), <code class="reqn">\alpha</code> (scale), <code class="reqn">k</code> (shape).
</p>
<p>Range of <code class="reqn">x</code>: <code class="reqn">-\infty &lt; x \le \xi + \alpha / k</code> if <code class="reqn">k&gt;0</code>;
<code class="reqn">-\infty &lt; x &lt; \infty</code> if <code class="reqn">k=0</code>;
<code class="reqn">\xi + \alpha / k \le x &lt; \infty</code> if <code class="reqn">k&lt;0</code>.
</p>
<p>Probability density function:
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} e^{-(1-k)y - e^{-y}}</code>
</p>

<p>where <code class="reqn">y = -k^{-1}\log\{1 - k(x - \xi)/\alpha\}</code> if <code class="reqn">k \ne 0</code>,
<code class="reqn">y = (x-\xi)/\alpha</code> if <code class="reqn">k=0</code>.
</p>
<p>Cumulative distribution function:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = e^{-e^{-y}}</code>
</p>

<p>Quantile function:
<code class="reqn">x(F) = \xi + \alpha[1-(-\log F)^k]/k</code> if <code class="reqn">k \ne 0</code>,
<code class="reqn">x(F) = \xi - \alpha \log(-\log F)</code> if <code class="reqn">k=0</code>.
</p>
<p><code class="reqn">k=0</code> is the Gumbel distribution; <code class="reqn">k=1</code> is the reverse exponential distribution.
</p>
<p><b>L-moments</b>
</p>
<p>L-moments are defined for <code class="reqn">k&gt;-1</code>.
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha[1 - \Gamma (1+k)]/k</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \alpha (1-2^{-k}) \Gamma (1+k)]/k</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = 2(1-3^{-k})/(1-2^{-k})-3</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = [5(1-4^{-k})-10(1-3^{-k})+6(1-2^{-k})]/(1-2^{-k})</code>
</p>

<p>Here <code class="reqn">\Gamma</code> denote the gamma function
</p>
<p style="text-align: center;"><code class="reqn">\Gamma (x) = \int_0^{\infty} t^{x-1} e^{-t} dt</code>
</p>

<p><b>Parameters</b>
</p>
<p>To estimate <code class="reqn">k</code>, no explicit solution is possible, but the following approximation has accurancy better than <code class="reqn">9 \times 10^{-4}</code> for <code class="reqn">-0.5 \le \tau_3 \le 0.5</code>:
</p>
<p style="text-align: center;"><code class="reqn">k \approx 7.8590 c + 2.9554 c^2</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">c = \frac{2}{3+\tau_3} - \frac{\log 2}{\log 3}</code>
</p>

<p>The other parameters are then given by
</p>
<p style="text-align: center;"><code class="reqn">\alpha = \frac{\lambda_2 k}{(1-2^{-k})\Gamma(1+k)}</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \lambda_1 - \alpha[1 - \Gamma(1+k)]/k</code>
</p>

<p><code>Lmom.GEV</code> and <code>par.GEV</code> accept input as vectors of equal length. In <code>f.GEV</code>, <code>F.GEV</code>, <code>invF.GEV</code> and <code>rand.GEV</code> parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>) must be atomic.
</p>


<h3>Value</h3>

<p><code>f.GEV</code> gives the density <code class="reqn">f</code>, <code>F.GEV</code> gives the distribution function <code class="reqn">F</code>, <code>invF.GEV</code> gives
the quantile function <code class="reqn">x</code>, <code>Lmom.GEV</code> gives the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>), <code>par.GEV</code> gives the parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>), and <code>rand.GEV</code> generates random deviates.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="#topic+EXP">EXP</a></code>, <code><a href="#topic+GENLOGIS">GENLOGIS</a></code>, <code><a href="#topic+GENPAR">GENPAR</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>, <code><a href="#topic+KAPPA">KAPPA</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>, <code><a href="#topic+P3">P3</a></code>; <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>, <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
fac &lt;- factor(annualflows["cod"][,])
split(x,fac)

camp &lt;- split(x,fac)$"45"
ll &lt;- Lmoments(camp)
parameters &lt;- par.GEV(ll[1],ll[2],ll[4])
f.GEV(1800,parameters$xi,parameters$alfa,parameters$k)
F.GEV(1800,parameters$xi,parameters$alfa,parameters$k)
invF.GEV(0.7518357,parameters$xi,parameters$alfa,parameters$k)
Lmom.GEV(parameters$xi,parameters$alfa,parameters$k)
rand.GEV(100,parameters$xi,parameters$alfa,parameters$k)

Rll &lt;- regionalLmoments(x,fac); Rll
parameters &lt;- par.GEV(Rll[1],Rll[2],Rll[4])
Lmom.GEV(parameters$xi,parameters$alfa,parameters$k)
</code></pre>

<hr>
<h2 id='GOFlaio2004'>Goodness of fit tests</h2><span id='topic+GOFlaio2004'></span><span id='topic+A2_GOFlaio'></span><span id='topic+A2'></span><span id='topic+W2'></span><span id='topic+fw2'></span><span id='topic+.typeIerrorA2_GOFlaio'></span>

<h3>Description</h3>

<p>Anderson-Darling goodness of fit tests for extreme-value distributions, from Laio (2004).
</p>


<h3>Usage</h3>

<pre><code class='language-R'> A2_GOFlaio (x, dist="NORM")
 A2 (F)
 W2 (F)

 fw2 (w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GOFlaio2004_+3A_x">x</code></td>
<td>
<p>data sample</p>
</td></tr>
<tr><td><code id="GOFlaio2004_+3A_dist">dist</code></td>
<td>
<p>distribution: normal <code>"NORM"</code>, log-normal <code>"LN"</code>, Gumbel <code>"GUMBEL"</code>, Frechet <code>"EV2"</code>, Generalized Extreme Value <code>"GEV"</code>, Pearson type III <code>"P3"</code>, log-Pearson type III <code>"LP3"</code></p>
</td></tr>
<tr><td><code id="GOFlaio2004_+3A_f">F</code></td>
<td>
<p>cumulative distribution function (that has to be sorted increasingly)</p>
</td></tr>

<tr><td><code id="GOFlaio2004_+3A_w">w</code></td>
<td>
<p>Transformed test statistic (Laio, 2004)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An introduction on the Anderson-Darling test is available on <a href="https://en.wikipedia.org/wiki/Anderson-Darling_test">https://en.wikipedia.org/wiki/Anderson-Darling_test</a> and in the <code>GOFmontecarlo</code> help page.
The original paper of Laio (2004) is available on his web site.
</p>


<h3>Value</h3>

<p><code>A2_GOFlaio</code> tests the goodness of fit of a distribution with the sample <code>x</code>; it return the value <code class="reqn">A_2</code> of the Anderson-Darling statistics and its non-exceedence probability <code class="reqn">P(A_2)</code>. 
Note that <code class="reqn">P</code> is the probability of obtaining the test statistic <code class="reqn">A_2</code> lower than the one that was actually observed, assuming that the null hypothesis is true, i.e., <code class="reqn">P</code> is one minus the p-value usually employed in statistical testing (see <a href="https://en.wikipedia.org/wiki/P-value">https://en.wikipedia.org/wiki/P-value</a>).
If <code class="reqn">P(A_2)</code> is, for example, greater than 0.90, the null hypothesis at significance level <code class="reqn">\alpha=10\%</code> is rejected.

</p>
<p><code>A2</code> is the Anderson-Darling test statistic; it is used by <code>A2_GOFlaio</code>.
</p>
<p><code>W2</code> is the Cramer-von Mises test statistic.
</p>
<p><code>fw2</code> is the approximation of the probability distribution of <code>w</code> (first 2 terms) when <code class="reqn">H_0</code> is true (Anderson-Darling, 1952); it is used by <code>A2_GOFlaio</code>.
</p>



<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+MLlaio2004">MLlaio2004</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>sm &lt;- rand.gumb(100, 0, 1)
ml &lt;- ML_estimation (sm, dist="GEV"); ml
F.GEV(sm, ml[1], ml[2], ml[3])
A2(sort(F.GEV(sm, ml[1], ml[2], ml[3])))
A2_GOFlaio(sm, dist="GEV")

ml &lt;- ML_estimation (sm, dist="P3"); ml
A2(sort(sort(F.gamma(sm, ml[1], ml[2], ml[3]))))
A2_GOFlaio(sm, dist="P3")
</code></pre>

<hr>
<h2 id='GOFmontecarlo'>Goodness of fit tests</h2><span id='topic+GOFmontecarlo'></span><span id='topic+gofNORMtest'></span><span id='topic+gofEXPtest'></span><span id='topic+gofGUMBELtest'></span><span id='topic+gofGENLOGIStest'></span><span id='topic+gofGENPARtest'></span><span id='topic+gofGEVtest'></span><span id='topic+gofLOGNORMtest'></span><span id='topic+gofP3test'></span><span id='topic+.test.GOFmontecarlo'></span>

<h3>Description</h3>

<p>Anderson-Darling goodness of fit tests for Regional Frequency Analysis: Monte-Carlo method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> gofNORMtest (x)
 gofEXPtest (x, Nsim=1000)
 gofGUMBELtest (x, Nsim=1000)
 gofGENLOGIStest (x, Nsim=1000)
 gofGENPARtest (x, Nsim=1000)
 gofGEVtest (x, Nsim=1000)
 gofLOGNORMtest (x, Nsim=1000)
 gofP3test (x, Nsim=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GOFmontecarlo_+3A_x">x</code></td>
<td>
<p>data sample</p>
</td></tr>
<tr><td><code id="GOFmontecarlo_+3A_nsim">Nsim</code></td>
<td>
<p>number of simulated samples from the hypothetical parent distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An introduction, analogous to the following one, on the Anderson-Darling test is available on <a href="https://en.wikipedia.org/wiki/Anderson-Darling_test">https://en.wikipedia.org/wiki/Anderson-Darling_test</a>.
</p>
<p>Given a sample <code class="reqn">x_i \  (i=1,\ldots,m)</code> of data extracted from a distribution <code class="reqn">F_R(x)</code>, the test is used to check the null hypothesis <code class="reqn">H_0 : F_R(x) = F(x,\theta)</code>, where <code class="reqn">F(x,\theta)</code> is the hypothetical distribution and <code class="reqn">\theta</code> is an array of parameters estimated from the sample <code class="reqn">x_i</code>.
</p>
<p>The Anderson-Darling goodness of fit test measures the departure between the hypothetical distribution <code class="reqn">F(x,\theta)</code> and the cumulative frequency function <code class="reqn">F_m(x)</code> defined as:
</p>
<p style="text-align: center;"><code class="reqn">F_m(x) = 0 \ , \ x &lt; x_{(1)}</code>
</p>

<p style="text-align: center;"><code class="reqn">F_m(x) = i/m \ , \  x_{(i)} \leq x &lt; x_{(i+1)}</code>
</p>

<p style="text-align: center;"><code class="reqn">F_m(x) = 1 \ , \ x_{(m)} \leq x</code>
</p>

<p>where <code class="reqn">x_{(i)}</code> is the <code class="reqn">i</code>-th element of the ordered sample (in increasing order).
</p>
<p>The test statistic is:
</p>
<p style="text-align: center;"><code class="reqn">Q^2 = m \! \int_x \left[ F_m(x) - F(x,\theta) \right]^2 \Psi(x) \,dF(x)</code>
</p>

<p>where <code class="reqn">\Psi(x)</code>, in the case of the Anderson-Darling test (Laio, 2004), is <code class="reqn">\Psi(x) = [F(x,\theta) (1 - F(x,\theta))]^{-1}</code>.
In practice, the statistic is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">A^2 = -m -\frac{1}{m} \sum_{i=1}^m \left\{ (2i-1)\ln[F(x_{(i)},\theta)] + (2m+1-2i)\ln[1 - F(x_{(i)},\theta)] \right\}</code>
</p>

<p>The statistic <code class="reqn">A^2</code>, obtained in this way, may be confronted with the population of the <code class="reqn">A^2</code>'s that one obtain if samples effectively belongs to the <code class="reqn">F(x,\theta)</code> hypothetical distribution.
In the case of the test of normality, this distribution is defined (see Laio, 2004).
In other cases, e.g. the Pearson Type III case, can be derived with a Monte-Carlo procedure.
</p>


<h3>Value</h3>

<p><code>gofNORMtest</code> tests the goodness of fit of a normal (Gauss) distribution with the sample <code>x</code>.
</p>
<p><code>gofEXPtest</code> tests the goodness of fit of a exponential distribution with the sample <code>x</code>.
</p>
<p><code>gofGUMBELtest</code> tests the goodness of fit of a Gumbel (EV1) distribution with the sample <code>x</code>.
</p>
<p><code>gofGENLOGIStest</code> tests the goodness of fit of a Generalized Logistic distribution with the sample <code>x</code>.
</p>
<p><code>gofGENPARtest</code> tests the goodness of fit of a Generalized Pareto distribution with the sample <code>x</code>.
</p>
<p><code>gofGEVtest</code> tests the goodness of fit of a Generalized Extreme Value distribution with the sample <code>x</code>.
</p>
<p><code>gofLOGNORMtest</code> tests the goodness of fit of a 3 parameters Lognormal distribution with the sample <code>x</code>.
</p>
<p><code>gofP3test</code> tests the goodness of fit of a Pearson type III (gamma) distribution with the sample <code>x</code>.
</p>
<p>They return the value <code class="reqn">A_2</code> of the Anderson-Darling statistics and its non exceedence probability <code class="reqn">P</code>.
Note that <code class="reqn">P</code> is the probability of obtaining the test statistic <code class="reqn">A_2</code> lower than the one that was actually observed, assuming that the null hypothesis is true, i.e., <code class="reqn">P</code> is one minus the p-value usually employed in statistical testing (see <a href="https://en.wikipedia.org/wiki/P-value">https://en.wikipedia.org/wiki/P-value</a>).
If <code class="reqn">P(A_2)</code> is, for example, greater than 0.90, the null hypothesis at significance level <code class="reqn">\alpha=10\%</code> is rejected.

</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+traceWminim">traceWminim</a></code>, <code><a href="#topic+roi">roi</a></code>, <code><a href="#topic+HOMTESTS">HOMTESTS</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(30,10,1)
gofNORMtest(x)

x &lt;- rand.gamma(50, 100, 15, 7)
gofP3test(x, Nsim=200)

x &lt;- rand.GEV(50, 0.907, 0.169, 0.0304)
gofGEVtest(x, Nsim=200)

x &lt;- rand.genlogis(50, 0.907, 0.169, 0.0304)
gofGENLOGIStest(x, Nsim=200)

x &lt;- rand.genpar(50, 0.716, 0.418, 0.476)
gofGENPARtest(x, Nsim=200)

x &lt;- rand.lognorm(50, 0.716, 0.418, 0.476)
gofLOGNORMtest(x, Nsim=200)

</code></pre>

<hr>
<h2 id='GUMBEL'>Two parameter Gumbel distribution and L-moments</h2><span id='topic+GUMBEL'></span><span id='topic+f.gumb'></span><span id='topic+F.gumb'></span><span id='topic+invF.gumb'></span><span id='topic+Lmom.gumb'></span><span id='topic+par.gumb'></span><span id='topic+rand.gumb'></span>

<h3>Description</h3>

<p><code>GUMBEL</code> provides the link between L-moments of a sample and the two parameter
Gumbel distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.gumb (x, xi, alfa)
F.gumb (x, xi, alfa)
invF.gumb (F, xi, alfa)
Lmom.gumb (xi, alfa)
par.gumb (lambda1, lambda2)
rand.gumb (numerosita, xi, alfa)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GUMBEL_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="GUMBEL_+3A_xi">xi</code></td>
<td>
<p>vector of gumb location parameters</p>
</td></tr>
<tr><td><code id="GUMBEL_+3A_alfa">alfa</code></td>
<td>
<p>vector of gumb scale parameters</p>
</td></tr>
<tr><td><code id="GUMBEL_+3A_f">F</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="GUMBEL_+3A_lambda1">lambda1</code></td>
<td>
<p>vector of sample means</p>
</td></tr>
<tr><td><code id="GUMBEL_+3A_lambda2">lambda2</code></td>
<td>
<p>vector of L-variances</p>
</td></tr>
<tr><td><code id="GUMBEL_+3A_numerosita">numerosita</code></td>
<td>
<p>numeric value indicating the length of the vector to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://en.wikipedia.org/wiki/Fisher-Tippett_distribution">https://en.wikipedia.org/wiki/Fisher-Tippett_distribution</a> for an introduction to the Gumbel distribution.
</p>
<p><b>Definition</b>
</p>
<p>Parameters (2): <code class="reqn">\xi</code> (location), <code class="reqn">\alpha</code> (scale).
</p>
<p>Range of <code class="reqn">x</code>: <code class="reqn">-\infty &lt; x &lt; \infty</code>.
</p>
<p>Probability density function:
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} \exp[-(x-\xi)/\alpha] \exp\{- \exp[-(x-\xi)/\alpha]\}</code>
</p>

<p>Cumulative distribution function:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \exp[-\exp(-(x-\xi)/\alpha)]</code>
</p>

<p>Quantile function:
<code class="reqn">x(F) = \xi - \alpha \log(-\log F)</code>.
</p>
<p><b>L-moments</b>
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha \gamma</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \alpha \log 2</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = 0.1699 = \log(9/8)/ \log 2</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = 0.1504 = (16 \log 2 - 10 \log 3)/ \log 2</code>
</p>

<p>Here <code class="reqn">\gamma</code> is Euler's constant, 0.5772...
</p>
<p><b>Parameters</b>
</p>
<p style="text-align: center;"><code class="reqn">\alpha=\lambda_2 / \log 2</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \lambda_1 - \gamma \alpha</code>
</p>

<p><code>Lmom.gumb</code> and <code>par.gumb</code> accept input as vectors of equal length. In <code>f.gumb</code>, <code>F.gumb</code>, <code>invF.gumb</code> and <code>rand.gumb</code> parameters (<code>xi</code>, <code>alfa</code>) must be atomic.
</p>


<h3>Value</h3>

<p><code>f.gumb</code> gives the density <code class="reqn">f</code>, <code>F.gumb</code> gives the distribution function <code class="reqn">F</code>, <code>invF.gumb</code> gives
the quantile function <code class="reqn">x</code>, <code>Lmom.gumb</code> gives the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>)), <code>par.gumb</code> gives the parameters (<code>xi</code>, <code>alfa</code>), and <code>rand.gumb</code> generates random deviates.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="#topic+EXP">EXP</a></code>, <code><a href="#topic+GENLOGIS">GENLOGIS</a></code>, <code><a href="#topic+GENPAR">GENPAR</a></code>, <code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+KAPPA">KAPPA</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>, <code><a href="#topic+P3">P3</a></code>; <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>, <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows[1:10,]
summary(annualflows)
x &lt;- annualflows["dato"][,]
fac &lt;- factor(annualflows["cod"][,])
split(x,fac)

camp &lt;- split(x,fac)$"45"
ll &lt;- Lmoments(camp)
parameters &lt;- par.gumb(ll[1],ll[2])
f.gumb(1800,parameters$xi,parameters$alfa)
F.gumb(1800,parameters$xi,parameters$alfa)
invF.gumb(0.7686843,parameters$xi,parameters$alfa)
Lmom.gumb(parameters$xi,parameters$alfa)
rand.gumb(100,parameters$xi,parameters$alfa)

Rll &lt;- regionalLmoments(x,fac); Rll
parameters &lt;- par.gumb(Rll[1],Rll[2])
Lmom.gumb(parameters$xi,parameters$alfa)
</code></pre>

<hr>
<h2 id='HOMTESTS'>Homogeneity tests</h2><span id='topic+HOMTESTS'></span><span id='topic+ADbootstrap.test'></span><span id='topic+HW.tests'></span><span id='topic+DK.test'></span><span id='topic+discordancy'></span><span id='topic+criticalD'></span>

<h3>Description</h3>

<p>Homogeneity tests for Regional Frequency Analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ADbootstrap.test (x, cod, Nsim=500, index=2)
 HW.tests (x, cod, Nsim=500)
 DK.test (x, cod)
 discordancy (x, cod)
 criticalD ()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HOMTESTS_+3A_x">x</code></td>
<td>
<p>vector representing data from many samples defined with <code>cod</code></p>
</td></tr>
<tr><td><code id="HOMTESTS_+3A_cod">cod</code></td>
<td>
<p>array that defines the data subdivision among sites</p>
</td></tr>
<tr><td><code id="HOMTESTS_+3A_nsim">Nsim</code></td>
<td>
<p>number of regions simulated with the bootstrap of the original region</p>
</td></tr>
<tr><td><code id="HOMTESTS_+3A_index">index</code></td>
<td>
<p>if <code>index</code>=1 samples are divided by their average value;
if <code>index</code>=2 (default) samples are divided by their median value</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>The Hosking and Wallis heterogeneity measures</b>
</p>
<p>The idea underlying Hosking and Wallis (1993) heterogeneity
statistics is to measure the sample variability of the L-moment
ratios and compare it to the variation that would be expected in a
homogeneous region. The latter is estimated through repeated
simulations of homogeneous regions with samples drawn from a four
parameter kappa distribution (see e.g., Hosking and Wallis,
1997, pp. 202-204). 
More in detail, the steps are the following:
with regards to the <code class="reqn">k</code> samples belonging to the region under analysis, find
the sample L-moment ratios (see, Hosking and Wallis, 1997)
pertaining to the <code class="reqn">i</code>-th site: these are the
L-coefficient of variation (L-CV),
</p>
<p style="text-align: center;"><code class="reqn">t^{(i)}=\frac{\frac{1}{n_i}\sum_{j=1}^{n_i}\left(\frac{2(j-1)}{(n_i-1)}-1\right)Y_{i,j}}{\frac{1}{n_i}\sum_{j=1}^{n_i}Y_{i,j}}</code>
</p>

<p>the coefficient of L-skewness,
</p>
<p style="text-align: center;"><code class="reqn">t_3^{(i)}=\frac{\frac{1}{n_i}\sum_{j=1}^{n_i}\left(\frac{6(j-1)(j-2)}{(n_i-1)(n_i-2)}-\frac{6(j-1)}{(n_i-1)}+1\right)Y_{i,j}}{\frac{1}{n_i}\sum_{j=1}^{n_i}\left(\frac{2(j-1)}{(n_i-1)}-1\right)Y_{i,j}}</code>
</p>

<p>and the coefficient of L-kurtosis
</p>
<p style="text-align: center;"><code class="reqn">t_4^{(i)}=\frac{\frac{1}{n_i}\sum_{j=1}^{n_i}\left(\frac{20(j-1)(j-2)(j-3)}{(n_i-1)(n_i-2)(n_i-3)}-\frac{30(j-1)(j-2)}{(n_i-1)(n_i-2)}+\frac{12(j-1)}{(n_i-1)}-1\right)Y_{i,j}}{\frac{1}{n_i}\sum_{j=1}^{n_i}\left(\frac{2(j-1)}{(n_i-1)}-1\right)Y_{i,j}}</code>
</p>

<p>Note that the L-moment ratios are not affected by the
normalization by the index value, i.e. it is the same to use
<code class="reqn">X_{i,j}</code> or <code class="reqn">Y_{i,j}</code> in Equations.
</p>
<p>Define the regional averaged L-CV, L-skewness and
L-kurtosis coefficients,
</p>
<p style="text-align: center;"><code class="reqn">t^R = \frac{\sum_{i=1}^k n_i t^{(i)}}{ \sum_{i=1}^k n_i}</code>
</p>

<p style="text-align: center;"><code class="reqn">t_3^R =\frac{ \sum_{i=1}^k n_i t_3^{(i)}}{ \sum_{i=1}^k n_i}</code>
</p>

<p style="text-align: center;"><code class="reqn">t_4^R =\frac{ \sum_{i=1}^k n_i t_4^{(i)}}{\sum_{i=1}^k n_i}</code>
</p>

<p>and compute the statistic
</p>
<p style="text-align: center;"><code class="reqn">V = \left\{ \sum_{i=1}^k n_i (t^{(i)} - t^R )^2 / \sum_{i=1}^k n_i\right\} ^{1/2}</code>
</p>

<p>Fit the parameters of a
four-parameters kappa distribution to the regional averaged L-moment ratios
<code class="reqn">t^R</code>, <code class="reqn">t_3^R</code> and <code class="reqn">t_4^R</code>, and then generate a large number
<code class="reqn">N_{sim}</code> of realizations of sets of <code class="reqn">k</code> samples. The <code class="reqn">i</code>-th site sample in each set 
has a kappa distribution as its parent and
record length equal to <code class="reqn">n_i</code>. For each simulated
homogeneous set, calculate the statistic <code class="reqn">V</code>, obtaining <code class="reqn">N_{sim}</code> values. 
On this vector of <code class="reqn">V</code> values determine the mean <code class="reqn">\mu_V</code> and standard
deviation <code class="reqn">\sigma_V</code> that relate to the hypothesis of homogeneity
(actually, under the composite hypothesis of homogeneity and kappa
parent distribution).
</p>
<p>An heterogeneity measure, which is called here
<code class="reqn">HW_1</code>, is finally found as
</p>
<p style="text-align: center;"><code class="reqn">\theta_{HW_1} = \frac{V - \mu_V}{\sigma_V}</code>
</p>

<p><code class="reqn">\theta_{HW_1}</code>  can be approximated by a normal distributed with zero
mean and unit variance: following Hosking and Wallis (1997),
the region under analysis can therefore be regarded as
&lsquo;acceptably homogeneous&rsquo; if <code class="reqn">\theta_{HW_1}&lt;1</code>, &lsquo;possibly
heterogeneous&rsquo; if <code class="reqn">1 \leq \theta_{HW_1} &lt; 2</code>, and &lsquo;definitely
heterogeneous&rsquo; if <code class="reqn">\theta_{HW_1}\geq2</code>. Hosking and Wallis
(1997) suggest that these limits should be treated as useful
guidelines. Even if the <code class="reqn">\theta_{HW_1}</code> statistic is constructed
like a significance test, significance levels obtained from such a
test would in fact be accurate only under special assumptions: to have
independent data both serially and between sites, and the true
regional distribution being kappa.
</p>
<p>Hosking and Wallis (1993) also give alternative heterogeneity measures
(that we call <code class="reqn">HW_2</code> and <code class="reqn">HW_3</code>), in which <code class="reqn">V</code> is
replaced by:
</p>
<p style="text-align: center;"><code class="reqn">V_2 = \sum_{i=1}^k n_i \left\{ (t^{(i)} - t^R)^2 + (t_3^{(i)} - t_3^R)^2\right\}^{1/2} / \sum_{i=1}^k n_i</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">V_3 = \sum_{i=1}^k n_i \left\{ (t_3^{(i)} - t_3^R)^2 + (t_4^{(i)} - t_4^R)^2\right\}^{1/2} / \sum_{i=1}^k n_i</code>
</p>

<p>The test statistic in this case becomes
</p>
<p style="text-align: center;"><code class="reqn">\theta_{HW_2} = \frac{V_2 - \mu_{V_2}}{\sigma_{V_2}}</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">\theta_{HW_3} = \frac{V_3 - \mu_{V_3}}{\sigma_{V_3}}</code>
</p>

<p>with similar acceptability limits as the <code class="reqn">HW_1</code> statistic. 
Hosking and Wallis (1997) judge <code class="reqn">\theta_{HW_2}</code> and <code class="reqn">\theta_{HW_3}</code> to be inferior to
<code class="reqn">\theta_{HW_1}</code> and say that it rarely yields values larger than 2 even for grossly heterogeneous regions.
</p>
<p><b>The bootstrap Anderson-Darling test</b>
</p>
<p>A test that does not make any assumption on the parent distribution is the
Anderson-Darling (<code class="reqn">AD</code>) rank test (Scholz and Stephens, 1987).
The <code class="reqn">AD</code> test is the generalization of the classical
Anderson-Darling goodness of fit test (e.g., D'Agostino and
Stephens, 1986), and it is used to test the hypothesis that <code class="reqn">k</code>
independent samples belong to the same population without
specifying their common distribution function.
</p>
<p>The test is based on the comparison between local and regional
empirical distribution functions. The empirical distribution
function, or sample distribution function, is defined by
<code class="reqn">F(x)=\frac{j}{\eta}, x_{(j)}\leq x &lt; x_{(j+1)}</code>, where <code class="reqn">\eta</code> is
the size of the sample and <code class="reqn">x_{(j)}</code> are the order statistics,
i.e. the observations arranged in ascending order. Denote the
empirical distribution function of the <code class="reqn">i</code>-th sample (local) by <code class="reqn">\hat{F}_i(x)</code>, and that of the pooled sample of all <code class="reqn">N = n_1 + ... + n_k</code>
observations (regional) by <code class="reqn">H_N (x)</code>. The <code class="reqn">k</code>-sample Anderson-Darling test
statistic is then defined as
</p>
<p style="text-align: center;"><code class="reqn">\theta_{AD} = \sum_{i=1}^k n_i \int _{{\rm all}\ x} \frac{[\hat{F}_i (x) - H_N (x) ]^2}{H_N (x) [ 1 - H_N (x) ] } dH_N (x)</code>
</p>

<p>If the pooled ordered sample is <code class="reqn">Z_1 &lt; ... &lt; Z_N</code>, the
computational formula to evaluate <code class="reqn">\theta_{AD}</code> is:
</p>
<p style="text-align: center;"><code class="reqn">\theta_{AD} = \frac{1}{N} \sum_{i=1}^k \frac{1}{n_i}\sum_{j=1}^{N-1} \frac{(N M_{ij} - j n_i)^2 }{j (N-j)}</code>
</p>

<p>where <code class="reqn">M_{ij}</code> is the number of observations in the <code class="reqn">i</code>-th sample
that are not greater than <code class="reqn">Z_j</code>. The homogeneity test can be
carried out by comparing the obtained <code class="reqn">\theta_{AD}</code> value to the
tabulated percentage points reported by Scholz and Stephens
(1987) for different significance levels.
</p>
<p>The statistic <code class="reqn">\theta_{AD}</code> depends on the sample values only
through their ranks. This guarantees that the test statistic
remains unchanged when the samples undergo monotonic
transformations, an important stability property not possessed by
<code class="reqn">HW</code> heterogeneity measures. However, problems arise in applying this test in a
common index value procedure. In fact, the index
value procedure corresponds to dividing each site sample by a different
value, thus modifying the ranks in the pooled sample. In
particular, this has the effect of making the
local empirical distribution functions much more similar to the
other, providing an impression of homogeneity even when the
samples are highly heterogeneous. The effect is analogous to that
encountered when applying goodness-of-fit tests to distributions
whose parameters are estimated from the same sample used for the
test (e.g., D'Agostino and Stephens, 1986; Laio,
2004). In both cases, the percentage points for the test should be
opportunely redetermined. This can be done with a nonparametric bootstrap approach
presenting the following steps:
build up the pooled sample <code class="reqn">\cal S</code> of the observed
non-dimensional data.
Sample with replacement from <code class="reqn">\cal S</code> and generate <code class="reqn">k</code>
artificial local samples, of size <code class="reqn">n_1, \dots ,n_k</code>.
Divide each sample for its index value, and calculate
<code class="reqn">\theta^{(1)}_{AD}</code>.
Repeat the procedure for <code class="reqn">N_{sim}</code> times and obtain a sample
of <code class="reqn">\theta^{(j)}_{AD}</code>, <code class="reqn">j=1,\dots , N_{sim}</code> values, whose
empirical distribution function can be used as an approximation of
<code class="reqn">G_{H_0}(\theta_{AD})</code>, the distribution of <code class="reqn">\theta_{AD}</code> under
the null hypothesis of homogeneity.
The acceptance limits for the test, corresponding to any
significance level <code class="reqn">\alpha</code>, are then easily determined as the
quantiles of <code class="reqn">G_{H_0}(\theta_{AD})</code> corresponding to a probability
<code class="reqn">(1-\alpha)</code>.
</p>
<p>We will call the test obtained with the above procedure the bootstrap Anderson-Darling test, hereafter referred to as <code class="reqn">AD</code>.
</p>
<p><b>Durbin and Knott test</b>
</p>
<p>The last considered homogeneity test derives from a
goodness-of-fit statistic originally proposed by Durbin and
Knott (1971). The test is formulated to measure discrepancies in
the dispersion of the samples, without accounting for the possible
presence of discrepancies in the mean or skewness of the data.
Under this aspect, the test is similar to the <code class="reqn">HW_1</code> test, while it
is analogous to the <code class="reqn">AD</code> test for the fact that it is a rank test.
The original goodness-of-fit test is very simple: suppose to have
a sample <code class="reqn">X_i</code>, <code class="reqn">i = 1, ..., n</code>, with hypothetical
distribution <code class="reqn">F(x)</code>; under the null hypothesis the random variable
<code class="reqn">F(X_i)</code> has a uniform distribution in the <code class="reqn">(0,1)</code> interval, and
the statistic <code class="reqn">D = \sum_{i=1}^n \cos[2 \pi F(X_i)]</code> is
approximately normally distributed with mean 0 and variance 1
(Durbin and Knott, 1971). <code class="reqn">D</code> serves the purpose of
detecting discrepancy in data dispersion: if the variance of <code class="reqn">X_i</code>
is greater than that of the hypothetical distribution <code class="reqn">F(x)</code>, <code class="reqn">D</code> is significantly greater than
0, while <code class="reqn">D</code> is significantly below 0 in the reverse case.
Differences between the mean (or the median) of <code class="reqn">X_i</code> and <code class="reqn">F(x)</code>
are instead not detected by <code class="reqn">D</code>, which guarantees that the
normalization by the index value does not affect the test.
</p>
<p>The extension to homogeneity testing of the  Durbin and
Knott (<code class="reqn">DK</code>) statistic is straightforward: we substitute the empirical
distribution function obtained with the pooled observed data,
<code class="reqn">H_N(x)</code>, for <code class="reqn">F(x)</code> in <code class="reqn">D</code>, obtaining at each site a statistic
</p>
<p style="text-align: center;"><code class="reqn">D_i = \sum_{j=1}^{n_i} \cos[2 \pi H_N(X_j)]</code>
</p>

<p>which is normal under the hypothesis of homogeneity. The statistic
<code class="reqn">\theta_{DK} = \sum_{i=1}^k D_i^2</code> has then a chi-squared
distribution with <code class="reqn">k-1</code> degrees of freedom, which allows one to
determine the acceptability limits for the test, corresponding to
any significance level <code class="reqn">\alpha</code>. 
</p>
<p><b>Comparison among tests</b>
</p>
<p>The comparison (Viglione et al, 2007) shows that the Hosking and Wallis heterogeneity measure <code class="reqn">HW_1</code> (only based on L-CV) is preferable when skewness is low, while the bootstrap Anderson-Darling test should be used for more skewed regions.
As for <code class="reqn">HW_2</code>, the Hosking and Wallis heterogeneity measure based on L-CV and L-CA, it is shown once more how much it lacks power.
</p>
<p>Our suggestion is to guide the choice of the test according to a compromise between power and Type I error of the <code class="reqn">HW_1</code> and <code class="reqn">AD</code> tests.
The L-moment space is divided into two regions: 
if the <code class="reqn">t_3^R</code> coefficient for the region under analysis is lower than 0.23, we propose to use the Hosking and Wallis heterogeneity measure <code class="reqn">HW_1</code>;
if <code class="reqn">t_3^R &gt; 0.23</code>, the bootstrap Anderson-Darling test is preferable.
</p>


<h3>Value</h3>

<p><code>ADbootstrap.test</code> and <code>DK.test</code> test gives its test statistic and its distribution value <code class="reqn">P</code>.
If <code class="reqn">P</code> is, for example, 0.92, samples shouldn't be considered heterogeneous with significance level minor of 8%.
</p>
<p><code>HW.tests</code> gives the two Hosking and Wallis heterogeneity measures <code class="reqn">H_1</code> and <code class="reqn">H_2</code>; following Hosking and Wallis (1997), the region under analysis can therefore be regarded as &lsquo;acceptably homogeneous&rsquo; if <code class="reqn">H_1&lt;1</code>, &lsquo;possibly heterogeneous&rsquo; if <code class="reqn">1 \leq H_1 &lt; 2</code>, and &lsquo;definitely heterogeneous&rsquo; if <code class="reqn">H \geq 2</code>.
</p>
<p><code>discordancy</code> returns the discordancy measure <code class="reqn">D</code> of Hosking and Wallis for all sites. 
Hosking and Wallis suggest to consider a site discordant if <code class="reqn">D \geq 3</code> if <code class="reqn">N \geq 15</code> (where <code class="reqn">N</code> is the number of sites considered in the region). For <code class="reqn">N&lt;15</code> the critical values of <code class="reqn">D</code> can be listed with <code>criticalD</code>.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+traceWminim">traceWminim</a></code>, <code><a href="#topic+roi">roi</a></code>, <code><a href="#topic+KAPPA">KAPPA</a></code>, <code>HW.original</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]
split(x,cod)

#ADbootstrap.test(x,cod,Nsim=100)   # it takes some time
#HW.tests(x,cod)                    # it takes some time
DK.test(x,cod)

fac &lt;- factor(annualflows["cod"][,],levels=c(34:38))
x2 &lt;- annualflows[!is.na(fac),"dato"]
cod2 &lt;- annualflows[!is.na(fac),"cod"]

ADbootstrap.test(x2,cod2,Nsim=100)
ADbootstrap.test(x2,cod2,index=1,Nsim=200)
HW.tests(x2,cod2,Nsim=100)
DK.test(x2,cod2)

discordancy(x,cod)

criticalD()
</code></pre>

<hr>
<h2 id='HW.original'>Original Hosking and Wallis Fortran routine</h2><span id='topic+HW.original'></span><span id='topic+print.HWorig'></span><span id='topic+plot.HWorig'></span><span id='topic+LMR'></span><span id='topic+PEL'></span><span id='topic+SAMLMR'></span><span id='topic+SAMLMU'></span><span id='topic+SAMPWM'></span><span id='topic+REGLMR'></span><span id='topic+REGTST'></span>

<h3>Description</h3>

<p>The original Fortran routine by Hosking is here used to analyse a region.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> HW.original (data, cod, Nsim=500)
 ## S3 method for class 'HWorig'
 print(x, ...)
 ## S3 method for class 'HWorig'
 plot(x, interactive=TRUE, ...)
 LMR (PARA, distr="EXP")
 PEL (XMOM, distr="EXP")
 SAMLMR (X, A=0, B=0)
 SAMLMU (X)
 SAMPWM (X, A=0, B=0)
 REGLMR (data, cod)
 REGTST (data, cod, A=0, B=0, Nsim=500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HW.original_+3A_x">x</code></td>
<td>
<p>object of class <code>HWorig</code></p>
</td></tr>
<tr><td><code id="HW.original_+3A_data">data</code></td>
<td>
<p>vector representing data from many samples defined with <code>cod</code></p>
</td></tr>
<tr><td><code id="HW.original_+3A_cod">cod</code></td>
<td>
<p>array that defines the data subdivision among sites</p>
</td></tr>
<tr><td><code id="HW.original_+3A_nsim">Nsim</code></td>
<td>
<p>number of regions simulated with the bootstrap of the original region</p>
</td></tr>
<tr><td><code id="HW.original_+3A_interactive">interactive</code></td>
<td>
<p>logical: if TRUE the graphic showing is interactive</p>
</td></tr>
<tr><td><code id="HW.original_+3A_...">...</code></td>
<td>
<p>additional parameter for <code>print</code></p>
</td></tr>
<tr><td><code id="HW.original_+3A_para">PARA</code></td>
<td>
<p>parameters of the distribution (vector)</p>
</td></tr>
<tr><td><code id="HW.original_+3A_distr">distr</code></td>
<td>
<p>distribution:
<code>EXP</code> = Exponential (2 parameters: xi, alfa);
<code>GAM</code> = Gamma (2 parameters: alfa, beta);
<code>GEV</code> = Generalized extreme value (3 parameters: xi, alfa, k);
<code>GLO</code> = Generalized logistic (3 parameters: xi, alfa, k);
<code>GNO</code> = Generalized Normal (3 parameters: xi, alfa, k);
<code>GPA</code> = Generalized Pareto (3 parameters: xi, alfa, k);
<code>GUM</code> = Gumbel (2 parameters: xi, alfa);
<code>KAP</code> = Kappa (4 parameters: xi, alfa, k, h);
<code>NOR</code> = Normal (2 parameters: mu, sigma);
<code>PE3</code> = Pearson type III (3 parameters: mu, sigma, gamm);
<code>WAK</code> = Wakeby (5 parameters: xi, alfa, beta, gamm, delta).</p>
</td></tr>
<tr><td><code id="HW.original_+3A_xmom">XMOM</code></td>
<td>
<p>the L-moment ratios of the distribution, in order <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>, <code class="reqn">\tau_5</code>...</p>
</td></tr>
<tr><td><code id="HW.original_+3A_x">X</code></td>
<td>
<p>a data vector</p>
</td></tr>
<tr><td><code id="HW.original_+3A_a">A</code>, <code id="HW.original_+3A_b">B</code></td>
<td>
<p>Parameters of plotting position: for unbiased estimates (of the <code class="reqn">\lambda</code>'s) set A=B=zero. 
Otherwise, plotting-position estimators are used, based on the plotting position <code class="reqn">(j+a)/(n+b)</code> 
for the <code class="reqn">j</code>'th smallest of <code class="reqn">n</code> observations. 
For example,  A=-0.35 and B=0.0 yields the estimators recommended by 
Hosking et al. (1985, technometrics) for the GEV distribution.</p>
</td></tr>
</table>


<h3>Details</h3>



<p>Differences among <code>HW.original</code> and <code>HW.tests</code> should depend on differences among <code>PEL</code> and <code>par.kappa</code> for the kappa distribution.
A numerical algorithm is used to resolve the implicit Equations (A.99) and (A.100) in Hosking and Wallis (1997, pag. 203-204).
The algorithms in <code>PEL</code> and <code>par.kappa</code> are different.
Anyway the risults of the tests should converge asymptotically.
</p>
<p><b>IBM software disclaimer</b>
</p>
<p>LMOMENTS: Fortran routines for use with the method of L-moments
</p>
<p>Permission to use, copy, modify and distribute this software for any purpose and without fee is hereby granted,
provided that this copyright and permission notice appear on all copies of the software.
The name of the IBM Corporation may not be used in any advertising or publicity pertaining to the use
of the software. IBM makes no warranty or representations about the suitability of the software for any purpose.
It is provided &quot;AS IS&quot; without any express or implied warranty, including the implied warranties of merchantability,
fitness for a particular purpose and non-infringement. IBM shall not be liable for any direct, indirect,
special or consequential damages resulting from the loss of use, data or projects, whether in an action of contract
or tort, arising out of or in connection with the use or performance of this software.
</p>


<h3>Value</h3>

<p><code>HW.original</code> returns an object of class <code>HWorig</code> (what the Fortran subroutine REGTST return).
</p>
<p><code>LMR</code> calculates the L-moment ratios of a distribution given its parameters.
</p>
<p><code>PEL</code> calculates the parameters of a distribution given its L-moments.
</p>
<p><code>SAMLMR</code> calculates the sample L-moments ratios of a data-set.
</p>
<p><code>SAMLMU</code> calculates the &lsquo;unbiased&rsquo; sample L-moments ratios of a data-set.
</p>
<p><code>SAMPWM</code> calculates the sample probability weighted moments of a data-set.
</p>
<p><code>REGLMR</code> calculates regional weighted averages of the sample L-moments ratios.
</p>
<p><code>REGTST</code> calculates statistics useful in regional frequency analysis.
1) Discordancy measure, d(i), for individual sites in a region.
Large values might be used as a flag to indicate potential errors
in the data at the site.  &quot;large&quot; might be 3 for regions with 15
or more sites, but less (exact values in array dc1) for smaller
regions.
2) Heterogeneity measures, H(j), for a region based upon either:-
j=1: the weighted s.d. of the l-cvs or
j=2: the average distance from the site to the regional average
on a graph of l-cv vs. l-skewness
j=3: the average distance from the site to the regional average
on a graph of l-skewness vs. l-kurtosis.
In practice H(1) is probably sufficient.  a value greater than
(say) 1.0 suggests that further subdivision of the region should
be considered as it might improve quantile estimates.
3) Goodness-of-fit measures, Z(k), for 5 candidate distributions:
k=1: generalized logistic
k=2: generalized extreme value
k=3: generalized normal (lognormal)
k=4: pearson type iii (3-parameter gamma)
k=5: generalized pareto.
Provided that the region is acceptably close to homogeneous,
the fit may be judged acceptable at 10
if Z(k) is less than 1.645 in absolute value.
</p>
<p>For further details see Hosking and Wallis (1997),
&quot;Regional frequency analysis: an approach based on L-moments&quot;,
cambridge university press, chapters 3-5.  
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+HW.tests">HW.tests</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]
split(x,cod)

HW.original(x,cod)

fac &lt;- factor(annualflows["cod"][,],levels=c(34:38))
x2 &lt;- annualflows[!is.na(fac),"dato"]
cod2 &lt;- annualflows[!is.na(fac),"cod"]

HW.original(x2,cod2)

plot(HW.original(x2,cod2))
</code></pre>

<hr>
<h2 id='hydroSIMN'>Data-sample</h2><span id='topic+hydroSIMN'></span><span id='topic+annualflows'></span><span id='topic+parameters'></span><span id='topic+meanmonthlyflows'></span><span id='topic+monthlyflows'></span>

<h3>Description</h3>

<p>SIMN (Servizio Idrografico e Mareografico Nazionale) flow data samples and catchment parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> data(hydroSIMN)
</code></pre>


<h3>Format</h3>

<p>Data.frames:
</p>
<p><code>annualflows</code> is the data.frame of the annual flows with 3 columns: 
<code>cod</code>, the code of the station; 
<code>anno</code>, the year; 
<code>dato</code>, the value of the annual flow [mm].
</p>
<p><code>parameters</code> is the data.frame of parameters of 47 catchements with 16 columns: 
<code>cod</code>, the code of the station;
<code>Dm</code>, the mean annual streamflow [mm] as reported in the &lsquo;Pubblicazione n. 17&rsquo;;
<code>Am</code>, the mean annual rainfall [mm] as reported in the &lsquo;Pubblicazione n. 17&rsquo;;
<code>S</code>, area of the plane projection of the drainage basin [km2];
<code>Hm</code>, mean elevation of the drainage basin [m a.s.l.]; 
<code>Pm</code>, mean slope of the basin [%]:
</p>
<p style="text-align: center;"><code class="reqn">P_m=arctg(2(H_{med} - H_{min})/\sqrt{S})</code>
</p>
 
<p>where <code class="reqn">S</code> is the basin area, <code class="reqn">H_{med}</code> the median elevation and <code class="reqn">H_{min}</code> the elevation of the closing section. 
<code>Pm</code> is a slope measure of a square equivalent basin, and does not account for basin shape;
<code>LLDP</code>,  length of the longest drainage path [km]. 
The longest drainage path is the longest path between the basin outlet and the most distant point on the basin border, following drainage directions. 
Actually the longest drainage path corresponds to the main stream plus the path on the hillslope that connects the stream source to the basin border;
<code>PLDP</code>, slope of the longest drainage path [%]. Average of the slope values associated to each pixel in the longest drainage path;
<code>S2000</code>, area above 2000 m a.s.l. [%];
<code>EST</code>, &lsquo;easting&rsquo;, sine of the angle between the segment connecting the center of mass and the outlet of the basin and the north. 
<code>EST</code> is 1 if the basin is oriented eastward, -1 if it is oriented westward;
<code>NORD</code>, &lsquo;northing&rsquo;, cosine of the angle between the segment connecting the center of mass and the outlet of the basin and the north.
<code>NORD</code> is 1 if the basin is oriented northward, -1 if it is oriented southward;
<code>Rc</code>, circularity ratio Rc.
Ratio between the basin area and the area of a circle having the same perimeter:
</p>
<p style="text-align: center;"><code class="reqn">R_c = \frac{4 \pi S}{P^2}</code>
</p>

<p>where <code class="reqn">P</code> is the watershed perimeter;
<code>Xbar</code>, longitude [deg] of the centroid of the plane projection of the drainage basin;
<code>Ybar</code>, latitude [deg] of the centroid of the plane projection of the drainage basin;
<code>IT</code>, Thornthwaite index:  a global moisture index that can be estimated, in its simplest form, as the ratio
</p>
<p style="text-align: center;"><code class="reqn">I_T=\frac{A_m - ET_0}{ET_0}</code>
</p>

<p>where <code class="reqn">ET_0</code> is the mean annual potential evapotranspiration on the basin;
<code>IB</code>, Budyko index: a radiational aridity index expressed as
</p>
<p style="text-align: center;"><code class="reqn">I_B=\frac{R_n}{\lambda A_m}</code>
</p>

<p>where <code class="reqn">R_n</code> is the mean annual net radiation and <code class="reqn">\lambda</code> is the latent vaporization heat. 
Values assumed by <code class="reqn">I_B</code> are lower than 1 for humid regions and greater than 1 in arid regions.
</p>
<p><code>meanmonthlyflows</code> is the data.frame of the mean monthly streamflows [mm] as reported in the &lsquo;Pubblicazione n. 17&rsquo;.
It has 13 columns because the first one, <code>cod</code>, is the code of the station.
</p>
<p><code>monthlyflows</code> is the data.frame of the monthly streamflows [mm] with 4 columns:
<code>cod</code>, the code of the station;
<code>anno</code>, the year;
<code>mese</code>, the month;
<code>dato</code>, the value of the annual flow [mm].
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,] 
split(x,cod)
sapply(split(x,cod),mean)
sapply(split(x,cod),median)
sapply(split(x,cod),quantile)
sapply(split(x,cod),Lmoments)

parameters
</code></pre>

<hr>
<h2 id='KAPPA'>Four parameter kappa distribution and L-moments</h2><span id='topic+KAPPA'></span><span id='topic+f.kappa'></span><span id='topic+F.kappa'></span><span id='topic+invF.kappa'></span><span id='topic+Lmom.kappa'></span><span id='topic+par.kappa'></span><span id='topic+rand.kappa'></span>

<h3>Description</h3>

<p><code>KAPPA</code> provides the link between L-moments of a sample and the four parameter
kappa distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.kappa (x, xi, alfa, k, h)
F.kappa (x, xi, alfa, k, h)
invF.kappa (F, xi, alfa, k, h)
Lmom.kappa (xi, alfa, k, h)
par.kappa (lambda1, lambda2, tau3, tau4)
rand.kappa (numerosita, xi, alfa, k, h)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KAPPA_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_xi">xi</code></td>
<td>
<p>vector of kappa location parameters</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_alfa">alfa</code></td>
<td>
<p>vector of kappa scale parameters</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_k">k</code></td>
<td>
<p>vector of kappa third parameters</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_h">h</code></td>
<td>
<p>vector of kappa fourth parameters</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_f">F</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_lambda1">lambda1</code></td>
<td>
<p>vector of sample means</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_lambda2">lambda2</code></td>
<td>
<p>vector of L-variances</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_tau3">tau3</code></td>
<td>
<p>vector of L-CA (or L-skewness)</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_tau4">tau4</code></td>
<td>
<p>vector of L-kurtosis</p>
</td></tr>
<tr><td><code id="KAPPA_+3A_numerosita">numerosita</code></td>
<td>
<p>numeric value indicating the length of the vector to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Definition</b>
</p>
<p>Parameters (4): <code class="reqn">\xi</code> (location), <code class="reqn">\alpha</code> (scale), <code class="reqn">k</code>, <code class="reqn">h</code>.
</p>
<p>Range of <code class="reqn">x</code>: upper bound is <code class="reqn">\xi + \alpha/k</code> if <code class="reqn">k&gt;0</code>, <code class="reqn">\infty</code> if <code class="reqn">k \le 0</code>;
lower bound is <code class="reqn">\xi + \alpha(1-h^{-k})/k</code> if <code class="reqn">h&gt;0</code>, <code class="reqn">\xi + \alpha/k</code> if <code class="reqn">h \le 0</code> and <code class="reqn">k&lt;0</code> and <code class="reqn">-\infty</code> if <code class="reqn">h \le 0</code> and <code class="reqn">k \ge 0</code>
</p>
<p>Probability density function:
</p>
<p style="text-align: center;"><code class="reqn">f(x)=\alpha^{-1} [1-k(x-\xi)/\alpha]^{1/k-1} [F(x)]^{1-h}</code>
</p>

<p>Cumulative distribution function:
</p>
<p style="text-align: center;"><code class="reqn">F(x)=\{1-h[1-k(x-\xi)/\alpha]^{1/k}\}^{1/h}</code>
</p>

<p>Quantile function:
</p>
<p style="text-align: center;"><code class="reqn">x(F)= \xi + \frac{\alpha}{k} \left[ 1-\left( \frac{1-F^h}{h} \right)^k \right]</code>
</p>

<p><code class="reqn">h=-1</code> is the generalized logistic distribution; 
<code class="reqn">h=0</code> is the generalized eztreme value distribution;
<code class="reqn">h=1</code> is the generalized Pareto distribution.
</p>
<p><b>L-moments</b>
</p>
<p>L-moments are defined for <code class="reqn">h \ge 0</code> and <code class="reqn">k&gt;-1</code>, or if <code class="reqn">h&lt;0</code> and <code class="reqn">-1&lt;k&lt;-1/h</code>.
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha(1-g_1)/k</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \alpha(g_1 - g_2)/k</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = (-g_1 + 3g_2 - 2g_3)/(g_1 - g_2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = (-g_1 + 6g_2 - 10g_3 + 5g_4)/(g_1 - g_2)</code>
</p>

<p>where
<code class="reqn">g_r = \frac{r\Gamma(1+k)\Gamma(r/h)}{h^{1+k}\Gamma(1+k+r/h)}</code> if <code class="reqn">h&gt;0</code>;
<code class="reqn">g_r = \frac{r \Gamma(1+k)\Gamma(-k-r/h)}{(-h)^{1+k}\Gamma(1-r/h)}</code> if <code class="reqn">h&lt;0</code>;
</p>
<p>Here <code class="reqn">\Gamma</code> denote the gamma function
</p>
<p style="text-align: center;"><code class="reqn">\Gamma (x) = \int_0^{\infty} t^{x-1} e^{-t} dt</code>
</p>

<p><b>Parameters</b>
</p>
<p>There are no simple expressions for the parameters in terms of the L-moments.
However they can be obtained with a numerical algorithm considering the formulations of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> in terms of <code class="reqn">k</code> and <code class="reqn">h</code>.
Here we use the function <code>optim</code> to minimize <code class="reqn">(t_3-\tau_3)^2 + (t_4-\tau_4)^2</code> where <code class="reqn">t_3</code> and <code class="reqn">t_4</code> are the sample L-moment ratios.
</p>
<p><code>Lmom.kappa</code> and <code>par.kappa</code> accept input as vectors of equal length. In <code>f.kappa</code>, <code>F.kappa</code>, 
<code>invF.kappa</code> and <code>rand.kappa</code> parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>, <code>h</code>) must be atomic.
</p>


<h3>Value</h3>

<p><code>f.kappa</code> gives the density <code class="reqn">f</code>, <code>F.kappa</code> gives the distribution function <code class="reqn">F</code>, <code>invFkappa</code> gives
the quantile function <code class="reqn">x</code>, <code>Lmom.kappa</code> gives the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>), <code>par.kappa</code> gives the parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>, <code>h</code>), and <code>rand.kappa</code> generates random deviates.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="#topic+EXP">EXP</a></code>, <code><a href="#topic+GENLOGIS">GENLOGIS</a></code>, <code><a href="#topic+GENPAR">GENPAR</a></code>, <code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>, <code><a href="#topic+P3">P3</a></code>; <code><a href="stats.html#topic+optim">optim</a></code>, <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>, <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
fac &lt;- factor(annualflows["cod"][,])
split(x,fac)

camp &lt;- split(x,fac)$"45"
ll &lt;- Lmoments(camp)
parameters &lt;- par.kappa(ll[1],ll[2],ll[4],ll[5])
f.kappa(1800,parameters$xi,parameters$alfa,parameters$k,parameters$h)
F.kappa(1800,parameters$xi,parameters$alfa,parameters$k,parameters$h)
invF.kappa(0.771088,parameters$xi,parameters$alfa,parameters$k,parameters$h)
Lmom.kappa(parameters$xi,parameters$alfa,parameters$k,parameters$h)
rand.kappa(100,parameters$xi,parameters$alfa,parameters$k,parameters$h)

Rll &lt;- regionalLmoments(x,fac); Rll
parameters &lt;- par.kappa(Rll[1],Rll[2],Rll[4],Rll[5])
Lmom.kappa(parameters$xi,parameters$alfa,parameters$k,parameters$h)
</code></pre>

<hr>
<h2 id='Lmoments'>Hosking and Wallis sample L-moments</h2><span id='topic+Lmoments'></span><span id='topic+regionalLmoments'></span><span id='topic+LCV'></span><span id='topic+LCA'></span><span id='topic+Lkur'></span>

<h3>Description</h3>

<p><code>Lmoments</code> provides the estimate of L-moments of a sample or regional L-moments of a region.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> Lmoments (x)
 regionalLmoments (x,cod)
 LCV (x)
 LCA (x)
 Lkur (x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lmoments_+3A_x">x</code></td>
<td>
<p>vector representing a data-sample (or data from many samples defined with <code>cod</code> in the case of <code>regionalLmoments</code>)</p>
</td></tr>
<tr><td><code id="Lmoments_+3A_cod">cod</code></td>
<td>
<p>array that defines the data subdivision among sites</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimation of L-moments is based on a sample of size <code class="reqn">n</code>, arranged in ascending order.
Let <code class="reqn">x_{1:n} \le x_{2:n} \le \dots \le x_{n:n}</code> be the ordered sample.
An unbiased estimator of the probability weighted moments <code class="reqn">\beta_r</code> is:
</p>
<p style="text-align: center;"><code class="reqn">b_r = n^{-1} \sum_{j=r+1}^n \frac{(j-1)(j-2)\dots(j-r)}{(n-1)(n-2)\dots(n-r)} x_{j:n}</code>
</p>

<p>The sample L-moments are defined by:
</p>
<p style="text-align: center;"><code class="reqn">l_1 = b_0</code>
</p>

<p style="text-align: center;"><code class="reqn">l_2 = 2b_1 - b_0</code>
</p>

<p style="text-align: center;"><code class="reqn">l_3 = 6b_2 - 6b_1 + b_0</code>
</p>

<p style="text-align: center;"><code class="reqn">l_4 = 20b_3-30b_2+12b_1-b_0</code>
</p>

<p>and in general
</p>
<p style="text-align: center;"><code class="reqn">l_{r+1} = \sum_{k=0}^r \frac{(-1)^{r-k}(r+k)!}{(k!)^2(r-k)!} b_k</code>
</p>

<p>where <code class="reqn">r=0,1,\dots,n-1</code>.
</p>
<p>The sample L-moment ratios are defined by
</p>
<p style="text-align: center;"><code class="reqn">t_r=l_r/l_2</code>
</p>

<p>and the sample L-CV by
</p>
<p style="text-align: center;"><code class="reqn">t=l_2/l_1</code>
</p>

<p>Sample regional L-CV, L-skewness and L-kurtosis coefficients are defined as
</p>
<p style="text-align: center;"><code class="reqn">t^R = \frac{\sum_{i=1}^k n_i t^{(i)}}{ \sum_{i=1}^k n_i}</code>
</p>

<p style="text-align: center;"><code class="reqn">t_3^R =\frac{ \sum_{i=1}^k n_i t_3^{(i)}}{ \sum_{i=1}^k n_i}</code>
</p>

<p style="text-align: center;"><code class="reqn">t_4^R =\frac{ \sum_{i=1}^k n_i t_4^{(i)}}{\sum_{i=1}^k n_i}</code>
</p>



<h3>Value</h3>

<p><code>Lmoments</code> gives the L-moments (<code class="reqn">l_1</code>, <code class="reqn">l_2</code>, <code class="reqn">t</code>, <code class="reqn">t_3</code>, <code class="reqn">t_4</code>), <code>regionalLmoments</code> gives the regional weighted L-moments (<code class="reqn">l_1^R</code>, <code class="reqn">l_2^R</code>, <code class="reqn">t^R</code>, <code class="reqn">t_3^R</code>, <code class="reqn">t_4^R</code>), <code>LCV</code> gives the coefficient of L-variation, <code>LCA</code> gives the L-skewness and <code>Lkur</code> gives the L-kurtosis of <code>x</code>.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+mean">mean</a></code>, <code><a href="stats.html#topic+var">var</a></code>, <code><a href="stats.html#topic+sd">sd</a></code>, <code><a href="#topic+HOMTESTS">HOMTESTS</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(30,10,2)
Lmoments(x)

data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]
split(x,cod)
camp &lt;- split(x,cod)$"45"
Lmoments(camp)
sapply(split(x,cod),Lmoments)

regionalLmoments(x,cod)
</code></pre>

<hr>
<h2 id='LOGNORM'>Three parameter lognormal distribution and L-moments</h2><span id='topic+LOGNORM'></span><span id='topic+f.lognorm'></span><span id='topic+F.lognorm'></span><span id='topic+invF.lognorm'></span><span id='topic+Lmom.lognorm'></span><span id='topic+par.lognorm'></span><span id='topic+rand.lognorm'></span>

<h3>Description</h3>

<p><code>LOGNORM</code> provides the link between L-moments of a sample and the three parameter
log-normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.lognorm (x, xi, alfa, k)
F.lognorm (x, xi, alfa, k)
invF.lognorm (F, xi, alfa, k)
Lmom.lognorm (xi, alfa, k)
par.lognorm (lambda1, lambda2, tau3)
rand.lognorm (numerosita, xi, alfa, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LOGNORM_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="LOGNORM_+3A_xi">xi</code></td>
<td>
<p>vector of lognorm location parameters</p>
</td></tr>
<tr><td><code id="LOGNORM_+3A_alfa">alfa</code></td>
<td>
<p>vector of lognorm scale parameters</p>
</td></tr>
<tr><td><code id="LOGNORM_+3A_k">k</code></td>
<td>
<p>vector of lognorm shape parameters</p>
</td></tr>
<tr><td><code id="LOGNORM_+3A_f">F</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="LOGNORM_+3A_lambda1">lambda1</code></td>
<td>
<p>vector of sample means</p>
</td></tr>
<tr><td><code id="LOGNORM_+3A_lambda2">lambda2</code></td>
<td>
<p>vector of L-variances</p>
</td></tr>
<tr><td><code id="LOGNORM_+3A_tau3">tau3</code></td>
<td>
<p>vector of L-CA (or L-skewness)</p>
</td></tr>
<tr><td><code id="LOGNORM_+3A_numerosita">numerosita</code></td>
<td>
<p>numeric value indicating the length of the vector to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://en.wikipedia.org/wiki/Log-normal_distribution">https://en.wikipedia.org/wiki/Log-normal_distribution</a> for an introduction to the lognormal distribution.
</p>
<p><b>Definition</b>
</p>
<p>Parameters (3): <code class="reqn">\xi</code> (location), <code class="reqn">\alpha</code> (scale), <code class="reqn">k</code> (shape).
</p>
<p>Range of <code class="reqn">x</code>: <code class="reqn">-\infty &lt; x \le \xi + \alpha / k</code> if <code class="reqn">k&gt;0</code>;
<code class="reqn">-\infty &lt; x &lt; \infty</code> if <code class="reqn">k=0</code>;
<code class="reqn">\xi + \alpha / k \le x &lt; \infty</code> if <code class="reqn">k&lt;0</code>.
</p>
<p>Probability density function:
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{e^{ky-y^2/2}}{\alpha \sqrt{2\pi}}</code>
</p>

<p>where <code class="reqn">y = -k^{-1}\log\{1 - k(x - \xi)/\alpha\}</code> if <code class="reqn">k \ne 0</code>,
<code class="reqn">y = (x-\xi)/\alpha</code> if <code class="reqn">k=0</code>.
</p>
<p>Cumulative distribution function:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \Phi(x)</code>
</p>

<p>where
<code class="reqn">\Phi(x)=\int_{-\infty}^x \phi(t)dt</code>.
</p>
<p>Quantile function:
<code class="reqn">x(F)</code> has no explicit analytical form.
</p>
<p><code class="reqn">k=0</code> is the Normal distribution with parameters <code class="reqn">\xi</code> and <code class="reqn">alpha</code>.
</p>
<p><b>L-moments</b>
</p>
<p>L-moments are defined for all values of <code class="reqn">k</code>.
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha(1 - e^{k^2/2})/k</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \alpha/k e^{k^2/2} [1 - 2 \Phi(-k/\sqrt{2})]</code>
</p>

<p>There are no simple expressions for the L-moment ratios <code class="reqn">\tau_r</code> with <code class="reqn">r \ge 3</code>.
Here we use the rational-function approximation given in Hosking and Wallis (1997, p. 199).
</p>
<p><b>Parameters</b>
</p>
<p>The shape parameter <code class="reqn">k</code> is a function of <code class="reqn">\tau_3</code> alone.
No explicit solution is possible.
Here we use the approximation given in Hosking and Wallis (1997, p. 199).
</p>
<p>Given <code class="reqn">k</code>, the other parameters are given by
</p>
<p style="text-align: center;"><code class="reqn">\alpha = \frac{\lambda_2 k e^{-k^2/2}}{1-2 \Phi(-k/\sqrt{2})}</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \lambda_1 - \frac{\alpha}{k} (1 - e^{k^2/2})</code>
</p>

<p><code>Lmom.lognorm</code> and <code>par.lognorm</code> accept input as vectors of equal length. In <code>f.lognorm</code>, <code>F.lognorm</code>, <code>invF.lognorm</code> and <code>rand.lognorm</code> parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>) must be atomic.
</p>


<h3>Value</h3>

<p><code>f.lognorm</code> gives the density <code class="reqn">f</code>, <code>F.lognorm</code> gives the distribution function <code class="reqn">F</code>, <code>invFlognorm</code> gives the quantile function <code class="reqn">x</code>, <code>Lmom.lognorm</code> gives the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>), <code>par.lognorm</code> gives the parameters (<code>xi</code>, <code>alfa</code>, <code>k</code>), and <code>rand.lognorm</code> generates random deviates.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="#topic+EXP">EXP</a></code>, <code><a href="#topic+GENLOGIS">GENLOGIS</a></code>, <code><a href="#topic+GENPAR">GENPAR</a></code>, <code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>, <code><a href="#topic+KAPPA">KAPPA</a></code>, <code><a href="#topic+P3">P3</a></code>; <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>, <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
fac &lt;- factor(annualflows["cod"][,])
split(x,fac)

camp &lt;- split(x,fac)$"45"
ll &lt;- Lmoments(camp)
parameters &lt;- par.lognorm(ll[1],ll[2],ll[4])
f.lognorm(1800,parameters$xi,parameters$alfa,parameters$k)
F.lognorm(1800,parameters$xi,parameters$alfa,parameters$k)
invF.lognorm(0.7529877,parameters$xi,parameters$alfa,parameters$k)
Lmom.lognorm(parameters$xi,parameters$alfa,parameters$k)
rand.lognorm(100,parameters$xi,parameters$alfa,parameters$k)

Rll &lt;- regionalLmoments(x,fac); Rll
parameters &lt;- par.lognorm(Rll[1],Rll[2],Rll[4])
Lmom.lognorm(parameters$xi,parameters$alfa,parameters$k)
</code></pre>

<hr>
<h2 id='MLlaio2004'>Maximum likelihood parameters estimation</h2><span id='topic+MLlaio2004'></span><span id='topic+ML_estimation'></span><span id='topic+moment_estimation'></span><span id='topic+.Fx'></span><span id='topic+.logLgumb'></span><span id='topic+.logLgev'></span><span id='topic+.logLgam'></span><span id='topic+.sample_generator'></span>

<h3>Description</h3>

<p>Maximum Likelihood estimation of parameters for extreme-value distributions, from Laio (2004).
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ML_estimation (x, dist="NORM")
 moment_estimation (x, dist="NORM")




</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLlaio2004_+3A_x">x</code></td>
<td>
<p>data sample</p>
</td></tr>
<tr><td><code id="MLlaio2004_+3A_dist">dist</code></td>
<td>
<p>distribution: normal <code>"NORM"</code>, Gumbel <code>"GUMBEL"</code>, Generalized Extreme Value <code>"GEV"</code>, Pearson type III <code>"P3"</code> and, only for <code>sample_generator</code>, Exponential <code>"EXP"</code></p>
</td></tr>




</table>


<h3>Value</h3>

<p><code>ML_estimation</code> estimate the parameters of the distribution <code>dist</code> from a sample <code>x</code> using the maximum likelihood approach. 
</p>
<p><code>moment_estimation</code> estimate the parameters of the distribution <code>dist</code> from a sample <code>x</code> using the moment method.
</p>






<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+GOFlaio2004">GOFlaio2004</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># sample from an EV1 distribution
sm &lt;- rand.gumb(100, 0, 1)
moment_estimation (sm, dist="GEV")
ML_estimation (sm, dist="GEV")

F.GEV(sm, -0.051, 0.97, -0.024)
rand.GEV (100, -0.051, 0.97, -0.024)
moment_estimation (sm, dist="P3")
ML_estimation (sm, dist="P3")
</code></pre>

<hr>
<h2 id='moments'>Sample moments</h2><span id='topic+moments'></span><span id='topic+CV'></span><span id='topic+skew'></span><span id='topic+kurt'></span>

<h3>Description</h3>

<p><code>moments</code> provides the estimate of the first 4 moment-statistics of a sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> moments (x)
 CV (x)
 skew (x)
 kurt (x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="moments_+3A_x">x</code></td>
<td>
<p>vector representing a data-sample</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Skewness and kurtosis are defined as:
</p>
<p style="text-align: center;"><code class="reqn">skew = n^{-1} \frac{\sum_{i=1}^n \left(x_i - mean(x)\right)^3}{sd(x)^{3}}</code>
</p>

<p style="text-align: center;"><code class="reqn">kurt = n^{-1} \frac{\sum_{i=1}^n \left(x_i - mean(x)\right)^4}{sd(x)^{4}} - 3</code>
</p>

<p>where <code class="reqn">n</code> is the size of <code>x</code>.
See <a href="https://en.wikipedia.org/wiki/Skewness">https://en.wikipedia.org/wiki/Skewness</a> and <a href="https://en.wikipedia.org/wiki/Kurtosis">https://en.wikipedia.org/wiki/Kurtosis</a> for additional informations.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+mean">mean</a></code>, <code><a href="stats.html#topic+var">var</a></code>, <code><a href="stats.html#topic+sd">sd</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(30,10,2)
moments(x)

data(hydroSIMN)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]
sapply(split(x,cod),moments)
</code></pre>

<hr>
<h2 id='MSClaio2008'>Model Selection Criteria</h2><span id='topic+MSClaio2008'></span><span id='topic+print.MSClaio2008'></span><span id='topic+plot.MSClaio2008'></span><span id='topic+summary.MSClaio2008'></span><span id='topic+.lnML'></span><span id='topic+.AIC'></span><span id='topic+.AICc'></span><span id='topic+.BIC'></span><span id='topic+.ADC'></span>

<h3>Description</h3>

<p>Model selection criteria for the frequency analysis of hydrological extremes, from Laio et al (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'> MSClaio2008 (sample, dist=c("NORM","LN","GUMBEL","EV2","GEV","P3","LP3"), 
              crit=c("AIC", "AICc", "BIC", "ADC"))
 ## S3 method for class 'MSClaio2008'
 print(x, digits=max(3, getOption("digits") - 3), ...)
 ## S3 method for class 'MSClaio2008'
 summary(object, ...)
 ## S3 method for class 'MSClaio2008'
 plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSClaio2008_+3A_sample">sample</code></td>
<td>
<p>data sample</p>
</td></tr>
<tr><td><code id="MSClaio2008_+3A_dist">dist</code></td>
<td>
<p>distributions: normal <code>"NORM"</code>, 2 parameter log-normal <code>"LN"</code>, Gumbel <code>"GUMBEL"</code>, Frechet <code>"EV2"</code>, Generalized Extreme Value <code>"GEV"</code>, Pearson type III <code>"P3"</code>, log-Pearson type III <code>"LP3"</code></p>
</td></tr>
<tr><td><code id="MSClaio2008_+3A_crit">crit</code></td>
<td>
<p>Model-selection criteria: Akaike Information Criterion <code>"AIC"</code>, Akaike Information Criterion corrected <code>"AICc"</code>, Bayesian Information Criterion <code>"BIC"</code>, Anderson-Darling Criterion <code>"ADC"</code></p>
</td></tr>
<tr><td><code id="MSClaio2008_+3A_x">x</code></td>
<td>
<p>object of class <code>MSClaio2008</code>, output of <code>MSClaio2008()</code></p>
</td></tr>
<tr><td><code id="MSClaio2008_+3A_object">object</code></td>
<td>
<p>object of class <code>MSClaio2008</code>, output of <code>MSClaio2008()</code></p>
</td></tr>
<tr><td><code id="MSClaio2008_+3A_digits">digits</code></td>
<td>
<p>minimal number of &quot;significant&quot; digits, see 'print.default'</p>
</td></tr>
<tr><td><code id="MSClaio2008_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following lines are extracted from Laio et al. (2008). See the paper for more details and references.
</p>
<p><b>Model selection criteria</b>
</p>
<p>The problem of model selection can be formalized as follows: a sample of <code class="reqn">n</code> data, <code class="reqn">D=(x_1, \dots, x_n)</code>, arranged in ascending order is available, sampled from an unknown parent distribution <code class="reqn">f(x)</code>; 
<code class="reqn">N_m</code> operating models, <code class="reqn">M_j</code>, <code class="reqn">j=1,\dots, N_m</code>, are used to represent the data. 
The operating models are in the form of probability distributions, <code class="reqn">M_j = g_j(x,\hat{\theta})</code>, with parameters <code class="reqn">\hat{\theta}</code> estimated from the available data sample <code class="reqn">D</code>. 
The scope of model selection is to identify the model <code class="reqn">M_{opt}</code> which is better suited to represent the data, i.e. the model which is closer in some sense to the parent distribution <code class="reqn">f(x)</code>. 
</p>
<p>Three different model selection criteria are considered here, namely, the Akaike Information Criterion (AIC), the Bayesian Information Criterion (BIC), and the Anderson-Darling Criterion (ADC).
Of the three methods, the first two belong to the category of classical literature approaches, while the third derives from a heuristic interpretation of the results of a standard goodness-of-fit test (see Laio, 2004).
</p>
<p><b>Akalike Information Criterion</b>
</p>
<p>The Akaike information Criterion (AIC) for the j-th operational model can be computed as
</p>
<p style="text-align: center;"><code class="reqn">AIC_j = -2 ln (L_j(\hat{\theta})) + 2 p_j</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">L_j(\hat{\theta}) = \prod_{i=1}^n g_j(x_i, \hat{\theta})</code>
</p>

<p>is the likelihood function, evaluated at the point <code class="reqn">\theta=\hat{\theta}</code> corresponding to the maximum likelihood estimator of the parameter vector <code class="reqn">\theta</code> and <code class="reqn">p_j</code> is the number of estimated parameter of the j-th operational model.
In practice, after the computation of the <code class="reqn">AIC_j</code>, for all of the operating models, one selects the model with the minimum AIC value, <code class="reqn">AIC_{min}</code>.
</p>
<p>When the sample size, <code class="reqn">n</code>, is small, with respect to the number of estimated parameters, <code class="reqn">p</code>, the AIC may perform inadequately. In those cases a second-order variant of AIC, called AICc, should be used:
</p>
<p style="text-align: center;"><code class="reqn">AICc_j = -2 ln (L_j(\hat{\theta})) + 2 p_j (n/(n - p_j - 1))</code>
</p>

<p>Indicatively, AICc should be used when <code class="reqn">n/p &lt; 40</code>.
</p>
<p><b>Bayesian Information Criterion</b>
</p>
<p>The Bayesian Information Criterion (BIC) for the j-th operational model reads
</p>
<p style="text-align: center;"><code class="reqn">BIC_j = -2 ln (L_j(\hat{\theta})) + ln(n) p_j</code>
</p>

<p>In practical application, after the computation of the <code class="reqn">BIC_j</code>, for all of the operating models, one selects the model with the minimum BIC value, <code class="reqn">BIC_{min}</code>.
</p>
<p><b>Anderson-Darling Criterion</b>
</p>
<p>The Anderson-Darling criterion has the form:
</p>
<p style="text-align: center;"><code class="reqn">ADC_j = 0.0403 + 0.116 ((\Delta_{AD,j} - \epsilon_j)/\beta_j)^{(\eta_j/0.851)}</code>
</p>

<p>if <code class="reqn">1.2 \epsilon_j &lt; \Delta_{AD,j}</code>,
</p>
<p style="text-align: center;"><code class="reqn">ADC_j = [0.0403 + 0.116 ((0.2 \epsilon_j)/\beta_j)^{(\eta_j/0.851)}] (\Delta_{AD,j} - 0.2 \epsilon_j / \epsilon_j)</code>
</p>

<p>if <code class="reqn">1.2 \epsilon_j \ge \Delta_{AD,j}</code>,
where <code class="reqn">\Delta_{AD,j}</code> is the discrepancy measure characterizing the criterion, the Anderson-Darling statistic <code>A2</code> in <code><a href="#topic+GOFlaio2004">GOFlaio2004</a></code>, and <code class="reqn">\epsilon_j</code>, <code class="reqn">\beta_j</code> and <code class="reqn">\eta_j</code> are distribution-dependent coefficients that are tabled by Laio [2004, Tables 3 and 5] for a set of seven distributions commonly employed for the frequency analysis of extreme events. 
In practice, after the computation of the <code class="reqn">ADC_j</code>, for all of the operating models, one selects the model with the minimum ADC value, <code class="reqn">ADC_{min}</code>.
</p>


<h3>Value</h3>

<p><code>MSClaio2008</code> returns the value of the criteria <code>crit</code> (see Details) chosen applied to the <code>sample</code>, for every distribution <code>dist</code>.
</p>
<p><code>plot.MSClaio2008</code> plots the empirical distribution function of <code>sample</code> (Weibull plotting position) on a log-normal probability plot, plots the candidate distributions <code>dist</code> (whose parameters are evaluated with the maximum likelihood technique, see <code><a href="#topic+MLlaio2004">MLlaio2004</a></code>, and highlights the ones chosen by the criteria <code>crit</code>.)
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+GOFlaio2004">GOFlaio2004</a></code>, <code><a href="#topic+MLlaio2004">MLlaio2004</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(FEH1000)

sitedata &lt;- am[am[,1]==53004, ] # data of site 53004
serieplot(sitedata[,4], sitedata[,3])
MSC &lt;- MSClaio2008(sitedata[,4])
MSC
summary(MSC)
plot(MSC)

sitedata &lt;- am[am[,1]==69023, ]	# data of site 69023
serieplot(sitedata[,4], sitedata[,3])
MSC &lt;- MSClaio2008(sitedata[,4], crit=c("AIC", "ADC"))
MSC
summary(MSC)
plot(MSC)

sitedata &lt;- am[am[,1]==83802, ] # data of site 83802
serieplot(sitedata[,4], sitedata[,3])
MSC &lt;- MSClaio2008(sitedata[,4], dist=c("GEV", "P3", "LP3"))
MSC
summary(MSC)
plot(MSC)

# short sample, high positive L-CA
sitedata &lt;- am[am[,1]==40012, ] # data of site 40012
serieplot(sitedata[,4], sitedata[,3])
MSC &lt;- MSClaio2008(sitedata[,4])
MSC
summary(MSC)
plot(MSC)

# negative L-CA
sitedata &lt;- am[am[,1]==68002, ] # data of site 68002
serieplot(sitedata[,4], sitedata[,3])
MSC &lt;- MSClaio2008(sitedata[,4])
MSC
summary(MSC)
plot(MSC)

</code></pre>

<hr>
<h2 id='nsRFA-internal'>Internal functions</h2><span id='topic+nsRFA-internal'></span><span id='topic+ksampleA2'></span><span id='topic+nonparboot'></span>

<h3>Description</h3>

<p>User-level objects which are for &lsquo;internal&rsquo; use only
</p>
<p><code>ksampleA2</code> provides the Anderson-Darling test statistic;
</p>
<p><code>nonparboot</code> provides a non-parametric bootstrap;
</p>





<h3>Usage</h3>

<pre><code class='language-R'> ksampleA2 (x,cod)
 nonparboot (z,n=length(z))



</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nsRFA-internal_+3A_x">x</code></td>
<td>
<p>vector representing data from many samples defined with <code>cod</code></p>
</td></tr>
<tr><td><code id="nsRFA-internal_+3A_cod">cod</code></td>
<td>
<p>array that defines the data subdivision among sites</p>
</td></tr>
<tr><td><code id="nsRFA-internal_+3A_z">z</code></td>
<td>
<p>data sample, used for bootstrap</p>
</td></tr>
<tr><td><code id="nsRFA-internal_+3A_n">n</code></td>
<td>
<p>length of sample (extracted in <code>nonparboot</code>)</p>
</td></tr>








</table>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>

<hr>
<h2 id='nsRFA-package'>
Non-supervised Regional Frequency Analysis
</h2><span id='topic+nsRFA-package'></span><span id='topic+nsRFA'></span>

<h3>Description</h3>

<p>The estimation of hydrological variables in ungauged basins is a very important topic for many purposes, from research to engineering applications and water management (see the PUB project, Sivapalan et al., 2003). 
Regardless of the method used to perform such estimation, the underlying idea is to transfer the hydrological information from gauged to ungauged sites. 
When observations of the same variable at different measuring sites are available and many data samples are used together as source of information, the methods are called regional methods. 
The well known regional frequency analysis (e.g. Hosking and Wallis, 1997), where the interest is in the assessment of the frequency of hydrological events, belong to this class of methods. 
In literature, the main studied variable is the flood peak and the most used regional approach is the index-flood method of Dalrymple (1960), in which it is implicitly assumed that the flood frequency distribution for different sites belonging to a
homogeneous region is the same except for a site-specific scale factor, the index-flood (see Hosking and Wallis, 1997, for details). 
Hence, the estimation of the flood frequency distribution for an ungauged site can be divided into two parts:
estimation of the index-flood (more in general, the index-value) through linear/non-linear relations with climatic and basin descriptors;
estimation of the adimentional flood frequency distribution, the growth curve, assigning the ungauged basin to one homogeneous region.
</p>
<p><code>nsRFA</code> is a collection of statistical tools for objective (non-supervised) applications of the Regional Frequency Analysis methods in hydrology.
This does not mean that Regional Frequency Analysis should be non-supervised.
These tools are addressed to experts, to help their expert judgement.
The functions in <code>nsRFA</code> allow the application of the index-flood method in the following points:
</p>

<table>
<tr>
 <td style="text-align: left;">
- </td><td style="text-align: left;"> regionalization of the index-value;</td>
</tr>
<tr>
 <td style="text-align: left;">
- </td><td style="text-align: left;"> formation of homogeneous regions for the growth curves;</td>
</tr>
<tr>
 <td style="text-align: left;">
- </td><td style="text-align: left;"> fit of a distribution function to the empirical growth curve of each region;</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p><b>Regionalization of the index-value</b>
</p>
<p>The index-value can be either the sample mean (e.g. Hosking and Wallis, 1997) or the sample median (e.g. Robson and Reed, 1999) or another scale parameter.
Many methodological approaches are available for the index-value estimation, and their differences can be related to the amount of information available.
Excluding direct methods, that use information provided by flow data available at the station of interest, regional estimation methods require ancillary hydrological and physical information.
Those methods can be divided in two classes: the multiregressive approach and the hydrological simulation approach.
For both of them, the best estimator is the one that optimizes some criterion, such as the minimum error, the minimum variance or the maximum efficiency.
Due to its simplicity, the most frequently used method is the multiregressive approach (see e.g. Kottegoda &amp; Rosso, 1998; Viglione et al., 2007a), that relates the index-flow to catchment characteristics, such as climatic indices, geologic and morphologic parameters, land cover type, etc., through linear or non-linear equations.
</p>
<p>R provides the functions <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+nls">nls</a></code> for linear and non-linear regressions (package <code><a href="stats.html#topic+stats">stats</a></code>).
With the package <code>nsRFA</code>, a tool to select the best linear regressions given a set of candidate descriptors, <code><a href="#topic+bestlm">bestlm</a></code>, is provided.
In <code><a href="#topic+REGRDIAGNOSTICS">REGRDIAGNOSTICS</a></code> several functions are provided to analyze the output of <code><a href="stats.html#topic+lm">lm</a></code>, such as: 
the coefficient of determination (classic and adjusted);
the Student t significance test;
the variance inflation factor (VIF);
the root mean squared error (RMSE);
the mean absolute error (MAE);
the prediction intervals;
predicted values by a jackknife (cross-validation) procedure.
The functions in <code><a href="#topic+DIAGNOSTICS">DIAGNOSTICS</a></code> provide more general diagnostics of model results (that can be also non-linear), comparing estimated values with observed values.
</p>
<p>More details are provided in vignettes:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>nsRFA_ex01</code> </td><td style="text-align: left;"> How to use the package nsRFA (example 1):</td>
</tr>
<tr>
 <td style="text-align: left;">
                  </td><td style="text-align: left;"> Regional frequency analysis of the annual flows in Piemonte</td>
</tr>
<tr>
 <td style="text-align: left;">
                  </td><td style="text-align: left;"> and Valle d'Aosta</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>that can be accessed via <code>vignette("nsRFA_ex01", package="nsRFA")</code>.
</p>
<p><b>Formation of homogeneous regions for the growth curves</b>
</p>
<p>Different techniques exist, for example those that lead to the formation of fixed regions through cluster analysis (Hosking and Wallis, 1997, Viglione, 2007), or those based on the method of the region of influence (ROI, Burn, 1990).
The regional procedure can be divided into two parts: the formation of regions and the assignment of an ungauged site to one
of them.
Concerning the first point, the sites are grouped according to their similarity in terms of those basin descriptors that are assumed to explain the shape of the growth curve.
This shape is usually quantified in a parametric way.
For instance, the coefficient of variation (CV) or the L-CV of the curve can be used for this purpose.
The package <code>nsRFA</code> provide the functions in <code><a href="#topic+moments">moments</a></code> and <code><a href="#topic+Lmoments">Lmoments</a></code> to calculate sample moments and L-moments.
Subsequently, the selected parameter is related with basin descriptors through a linear or a more complex model.
A regression analysis is performed with different combination of descriptors, and descriptors that are strongly related with the parameter are used to group sites in regions.
The same tools used for the regionalization of the index value, i.e. <code><a href="#topic+bestlm">bestlm</a></code>, <code><a href="#topic+REGRDIAGNOSTICS">REGRDIAGNOSTICS</a></code> and <code><a href="#topic+DIAGNOSTICS">DIAGNOSTICS</a></code>, can be used if the parametric method is chosen.
</p>
<p><code>nsRFA</code> also provide a non-parametric approach that considers the dimensionless growth curve as a whole (see, Viglione et al., 2006; Viglione, 2007). 
The multiregressive approach can still be used if we reason in terms of (dis)similarity between pairs of basins in the following way:
(1) for each couple of stations, a dissimilarity index between non-dimensional curves is calculated using a quantitatively predefined metric, for example using the Anderson-Darling statistic (<code><a href="#topic+A2">A2</a></code>), and organising the distances in a matrix with <code><a href="#topic+AD.dist">AD.dist</a></code>;
(2) for each basin descriptor, the absolute value (or another metric) of the difference between its measure in two basins is used as distance between them, using <code><a href="stats.html#topic+dist">dist</a></code> of the package <code><a href="stats.html#topic+stats">stats</a></code> to obtain distance matrices;
(4) a multiregressive approach (<code><a href="#topic+bestlm">bestlm</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>) is applied considering the matrices as variables and the basin descriptors associated to the best regression are chosen;
(5) the significance of the linear relationship between distance matrices is assessed through the Mantel test with <code><a href="#topic+mantel.lm">mantel.lm</a></code>.
</p>
<p>In the suitable-descriptor's space, stations with similar descriptor values can be grouped into disjoint regions through a cluster analysis (using functions in <code><a href="#topic+traceWminim">traceWminim</a></code>) or the ROI method can be used adapting a region to the ungauged basin (<code><a href="#topic+roi">roi</a></code>).
In both cases, the homogeneity of the regions can be assessed with the functions in <code><a href="#topic+HOMTESTS">HOMTESTS</a></code>, where the Hosking and Wallis heterogeneity measures (<code><a href="#topic+HW.tests">HW.tests</a></code>, see Hosking and Wallis, 1997) and the Anderson-Darling homogeneity test (<code><a href="#topic+ADbootstrap.test">ADbootstrap.test</a></code>, see Viglione et al., 2007b) are provided.
</p>
<p>More details are provided in vignettes:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>nsRFA_ex01</code> </td><td style="text-align: left;"> How to use the package nsRFA (example 1):</td>
</tr>
<tr>
 <td style="text-align: left;">
                  </td><td style="text-align: left;"> Regional frequency analysis of the annual flows in Piemonte</td>
</tr>
<tr>
 <td style="text-align: left;">
                  </td><td style="text-align: left;"> and Valle d'Aosta</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nsRFA_ex02</code> </td><td style="text-align: left;"> How to use the package nsRFA (example 2):</td>
</tr>
<tr>
 <td style="text-align: left;">
                  </td><td style="text-align: left;"> Region-Of-Influence approach, some FEH examples</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>that can be accessed via <code>vignette("nsRFA_ex01", package="nsRFA")</code>.
</p>
<p><b>Fit of a distribution function to the empirical growth curve of each region</b>
</p>
<p>Once an homogeneous region is defined, the empirical growth curves can be pooled together and a probability distribution can be fitted to the pooled sample.
The choice of the best distribution can be assisted by a Model Selection Criteria with <code><a href="#topic+MSClaio2008">MSClaio2008</a></code> (see, Laio et al., 2008).
The parameters of the selected distribution can be estimated using the method of moments (<code><a href="#topic+moment_estimation">moment_estimation</a></code>), L-moments (<code><a href="#topic+par.GEV">par.GEV</a></code>, <code><a href="#topic+par.genpar">par.genpar</a></code>, <code><a href="#topic+par.gamma">par.gamma</a></code>, ...) or maximum-likelihood (<code><a href="#topic+MLlaio2004">MLlaio2004</a></code>).
Goodness-of-fit tests are also available: the Anderson-Darling goodness of fit test with <code><a href="#topic+GOFlaio2004">GOFlaio2004</a></code> (Laio. 2004), and Monte-Carlo based tests with <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>.
Confidence intervals for the fitted distribution can be calculated with a Markov Chain Monte Carlo algorithm, using <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>.
</p>
<p>More details are provided in vignettes:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>nsRFA_ex01</code> </td><td style="text-align: left;"> How to use the package nsRFA (example 1):</td>
</tr>
<tr>
 <td style="text-align: left;">
                  </td><td style="text-align: left;"> Regional frequency analysis of the annual flows in Piemonte</td>
</tr>
<tr>
 <td style="text-align: left;">
                  </td><td style="text-align: left;"> and Valle d'Aosta</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>MSClaio2008</code> </td><td style="text-align: left;"> Model selection techniques for the frequency analysis</td>
</tr>
<tr>
 <td style="text-align: left;"> 
                   </td><td style="text-align: left;"> of hydrological extremes: the MSClaio2008 R function</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>that can be accessed via <code>vignette("nsRFA_ex01", package="nsRFA")</code>.
</p>

<p><b>Other functions</b>
</p>
<p><code><a href="#topic+varLmoments">varLmoments</a></code> provides distribution-free unbiased estimators of the variances and covariances of sample L-moments, as described in Elamir and Seheult (2004).
</p>
<p>More details are provided in vignettes:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Fig1ElamirSeheult</code> </td><td style="text-align: left;"> Figure 1 in Elamir and Seheult (2004)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> nsRFA</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.7</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The package provides several tools for Regional Frequency Analysis of hydrological variables.
The first version dates to 2006 and was developed in Turin at the Politecnico by Alberto Viglione.
</p>
<p>For a complete list of the functions, use <code>library(help="nsRFA").</code>
</p>
<p><b>Main changes in version 0.7</b>
</p>

<table>
<tr>
 <td style="text-align: left;">
0.7-12: </td><td style="text-align: left;"> refinement of function <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code> allowing several threshold and new function <code><a href="#topic+BayesianMCMCreg">BayesianMCMCreg</a></code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.7-1: </td><td style="text-align: left;"> refinement of function <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.7-0: </td><td style="text-align: left;"> plotting position for historical information in <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p><b>Main changes in version 0.6</b>
</p>

<table>
<tr>
 <td style="text-align: left;">
0.6-9: </td><td style="text-align: left;"> new vignette <code>Fig11GriffisStedinger</code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-8: </td><td style="text-align: left;"> exponential and Gumbel distributions added in <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-6: </td><td style="text-align: left;"> some plotting position/probability plots have been added in <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-4: </td><td style="text-align: left;"> refinement of function <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-2: </td><td style="text-align: left;"> new vignette <code>nsRFA_ex02</code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-2: </td><td style="text-align: left;"> refinement of function <code><a href="#topic+BayesianMCMC">BayesianMCMC</a></code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-0: </td><td style="text-align: left;"> new vignette <code>nsRFA_ex01</code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-0: </td><td style="text-align: left;"> new function <code><a href="#topic+bestlm">bestlm</a></code>;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-0: </td><td style="text-align: left;"> the plotting position/probability plots in <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code> have been reshaped;</td>
</tr>
<tr>
 <td style="text-align: left;">
0.6-0: </td><td style="text-align: left;"> this list of changes has been added;</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Alberto Viglione
</p>
<p>Maintainer: Alberto Viglione &lt;viglione@hydro.tuwien.ac.at&gt;
</p>


<h3>References</h3>

<p>All the manual references are listed here:
</p>
<p>Beirlant, J., Goegebeur, Y., Teugels, J., Segers, J., 2004. Statistics of 
Extremes: Theory and Applications. John Wiley and Sons Inc., 490 pp.
</p>
<p>Burn, D.H., 1990. Evaluation of regional flood frequency analysis with a
region of influence approach. Water Resources Research 26(10), 2257-2265.
</p>
<p>Castellarin, A., Burn, D.H., Brath, A., 2001. Assessing the effectiveness of
hydrological similarity measures for flood frequency analysis. Journal of
Hydrology 241, 270-285.
</p>
<p>Chowdhury, J.U., Stedinger, J.R., Lu, L.H., Jul. 1991. Goodness-of-fit tests
for regional generalized extreme value flood distributions. Water Resources
Research 27(7), 1765-1776.
</p>
<p>D'Agostino, R., Stephens, M., 1986. Goodness-of-fit techniques. Vol.68 of
Statistics: textBooks and monographs. Department of Statistics, Southern
Methodist University, Dallas, Texas.
</p>
<p>Dalrymple, T., 1960. Flood frequency analyses. Vol. 1543-A of Water Supply
Paper. U.S. Geological Survey, Reston, Va.
</p>
<p>Durbin, J., Knott, M., 1971. Components of Cramer-von Mises statistics. 
London School of Economics and Political Science, pp. 290-307.
</p>
<p>El Adlouni, S., Bob\'ee, B., Ouarda, T.B.M.J., 2008. On the tails of extreme 
event distributions in hydrology. Journal of Hydrology 355(1-4), 16-33.
</p>
<p>Elamir, E. A.H., Seheult, A.H., 2004. Exact variance structure of sample
l-moments. Journal of Statistical Planning and Inference 124, 337-359.
</p>
<p>Everitt, B., 1974. Cluster Analysis. Social Science Research Council. 
Halsted Press, New York.
</p>
<p>Fill, H., Stedinger, J., 1998. Using regional regression within index flood
procedures and an empirical bayesian estimator. Journal of Hydrology
210(1-4), 128-145.
</p>
<p>Greenwood, J., Landwehr, J., Matalas, N., Wallis, J., 1979. Probability
weighted moments: Definition and relation to parameters of several
distributions expressible in inverse form. Water Resources Research 15,
1049-1054.
</p>
<p>Hosking, J., 1986. The theory of probability weighted moments. Tech. Rep.
RC12210, IBM Research, Yorktown Heights, NY.
</p>
<p>Hosking, J., 1990. L-moments: analysis and estimation of distributions using
linear combinations of order statistics. J. Royal Statistical Soc. 52,
105-124.
</p>
<p>Hosking, J., Wallis, J., 1993. Some statistics useful in regional frequency
analysis. Water Resources Research 29(2), 271-281.
</p>
<p>Hosking, J., Wallis, J., 1997. Regional Frequency Analysis: An Approach Based
on L-Moments. Cambridge University Press.
</p>
<p>Institute of Hydrology, 1999. Flood Estimation Handbook, Institute of 
Hydrology, Oxford.
</p>
<p>Kendall, M., Stuart, A., 1961-1979. The Advanced Theory of Statistics.
Charles Griffin &amp; Company Limited, London.
</p>
<p>Kottegoda, N.T., Rosso, R., 1997. Statistics, Probability, and Reliability for
Civil and Environmental Engineers, international Edition. McGraw-Hill
Companies.
</p>
<p>Laio, F., 2004. Cramer-von Mises and Anderson-Darling goodness of fit tests for 
extreme value distributions with unknown parameters, Water Resour. Res., 
40, W09308, doi:10.1029/2004WR003204.
</p>
<p>Laio, F., Tamea, S., 2007. Verification tools for probabilistic forecast of
continuous hydrological variables. Hydrology and Earth System Sciences 11,
1267-1277.
</p>
<p>Laio, F., Di Baldassarre G., Montanari A., 2008. Model selection techniques 
for the frequency analysis of hydrological extremes, Water Resour. Res., 
Under Revision.
</p>
<p>Regione Piemonte, 2004. Piano di tutela delle acque. Direzione Pianificazione 
Risorse Idriche.
</p>
<p>Robson, A., Reed, D., 1999. Statistical procedures for flood frequency
estimation. In: Flood Estimation HandBook. Vol.~3. Institute of Hydrology
Crowmarsh Gifford, Wallingford, Oxfordshire.
</p>
<p>Sankarasubramanian, A., Srinivasan, K., 1999. Investigation and comparison of
sampling properties of l-moments and conventional moments. Journal of
Hydrology 218, 13-34.
</p>
<p>Scholz, F., Stephens, M., 1987. K-sample Anderson-Darling tests. Journal of 
American Statistical Association, 82(399), pp. 918-924.
</p>
<p>Sivapalan, M., Takeuchi, K., Franks, S.W., Gupta, V.K., Karambiri, H., Lakshmi, V.,
Liang, X., McDonnell, J.J., Mendiondo, E.M., O'Connell, P.E., Oki, T., Pomeroy, J.W,
Schertzer, D., Uhlenbrook, S., Zehe, E., 2003. IAHS decade on Predictions in 
Ungauged Basins (PUB), 2003-2012: Shaping an exciting future for the hydrological 
sciences, Hydrological Sciences - Journal - des Sciences Hydrologiques, 48(6), 
857-880.
</p>
<p>Smouse, P.E., Long, J.C., Sokal, R.R., 1986. Multiple regression and correlation 
extensions of the Mantel test of matrix correspondence. Systematic Zoology, 
35(4), 627-632.
</p>
<p>Stedinger, J., Lu, L., 1995. Appraisal of regional and index flood quantile
estimators. Stochastic Hydrology and Hydraulics 9(1), 49-75.
</p>
<p>Stedinger, J.R., Vogel, R.M. and Foufoula-Georgiou, E., 1993. Frequency analysis of extreme events. 
In David R. Maidment, editor, Hand-Book of Hydrology, chapter 18. McGraw-Hill Companies, 
international edition.
</p>
<p>Viglione, A., Claps, P., Laio, F., 2006. Utilizzo di criteri di prossimit\'a 
nell'analisi regionale del deflusso annuo, XXX Convegno di Idraulica e 
Costruzioni Idrauliche - IDRA 2006, Roma, 10-15 Settembre 2006.
</p>
<p>Viglione, A., 2007. Metodi statistici non-supervised per la stima di grandezze 
idrologiche in siti non strumentati, PhD thesis at the Politecnico of Turin,
February 2007.
</p>
<p>Viglione, A., Claps, P., Laio, F., 2007a. Mean annual runoff estimation in 
North-Western Italy, In: G. La Loggia (Ed.) Water resources assessment 
and management under water scarcity scenarios, CDSU Publ. Milano. 
</p>
<p>Viglione, A., Laio, F., Claps, P., 2007b. A comparison of homogeneity tests
for regional frequency analysis. Water Resources Research 43~(3).
</p>
<p>Vogel, R., Fennessey, N., 1993. L moment diagrams should replace product moment
diagrams. Water Resources Research 29(6), 1745-1752.
</p>
<p>Vogel, R., Wilson, I., 1996. Probability distribution of annual maximum, mean,
and minimum streamflows in the united states. Journal of Hydrologic
Engineering 1(2), 69-76.
</p>
<p>Ward, J., 1963. Hierarchical grouping to optimize an objective function, Journal 
of the American Statistical Association, 58, pp. 236-244.
</p>

<hr>
<h2 id='P3'>Three parameters Pearson type III distribution and L-moments</h2><span id='topic+P3'></span><span id='topic+f.gamma'></span><span id='topic+F.gamma'></span><span id='topic+invF.gamma'></span><span id='topic+Lmom.gamma'></span><span id='topic+par.gamma'></span><span id='topic+rand.gamma'></span><span id='topic+mom2par.gamma'></span><span id='topic+par2mom.gamma'></span>

<h3>Description</h3>

<p><code>P3</code> provides the link between L-moments of a sample and the three parameter
Pearson type III distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.gamma (x, xi, beta, alfa)
F.gamma (x, xi, beta, alfa)
invF.gamma (F, xi, beta, alfa)
Lmom.gamma (xi, beta, alfa)
par.gamma (lambda1, lambda2, tau3)
rand.gamma (numerosita, xi, beta, alfa)
mom2par.gamma (mu, sigma, gamm)
par2mom.gamma (alfa, beta, xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="P3_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="P3_+3A_mu">mu</code></td>
<td>
<p>vector of gamma mean</p>
</td></tr>
<tr><td><code id="P3_+3A_sigma">sigma</code></td>
<td>
<p>vector of gamma standard deviation</p>
</td></tr>
<tr><td><code id="P3_+3A_gamm">gamm</code></td>
<td>
<p>vector of gamma third moment</p>
</td></tr>
<tr><td><code id="P3_+3A_f">F</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="P3_+3A_lambda1">lambda1</code></td>
<td>
<p>vector of sample means</p>
</td></tr>
<tr><td><code id="P3_+3A_lambda2">lambda2</code></td>
<td>
<p>vector of L-variances</p>
</td></tr>
<tr><td><code id="P3_+3A_tau3">tau3</code></td>
<td>
<p>vector of L-CA (or L-skewness)</p>
</td></tr>
<tr><td><code id="P3_+3A_numerosita">numerosita</code></td>
<td>
<p>numeric value indicating the length of the vector to be generated</p>
</td></tr>
<tr><td><code id="P3_+3A_alfa">alfa</code></td>
<td>
<p>vector of gamma shape parameters</p>
</td></tr>
<tr><td><code id="P3_+3A_beta">beta</code></td>
<td>
<p>vector of gamma scale parameters</p>
</td></tr>
<tr><td><code id="P3_+3A_xi">xi</code></td>
<td>
<p>vector of gamma location parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://en.wikipedia.org/wiki/Pearson_distribution">https://en.wikipedia.org/wiki/Pearson_distribution</a> for an introduction to the Pearson distribution, and <a href="https://en.wikipedia.org/wiki/Gamma_distribution">https://en.wikipedia.org/wiki/Gamma_distribution</a> for an introduction to the Gamma distribution (the Pearson type III distribution is, essentially, a Gamma distribution with 3 parameters).
</p>
<p><b>Definition</b>
</p>
<p>Parameters (3): <code class="reqn">\xi</code> (location), <code class="reqn">\beta</code> (scale), <code class="reqn">\alpha</code> (shape).
Moments (3): <code class="reqn">\mu</code> (mean), <code class="reqn">\sigma</code> (standard deviation), <code class="reqn">\gamma</code> (skewness).
</p>
<p>If <code class="reqn">\gamma \ne 0</code>, let <code class="reqn">\alpha=4/\gamma^2</code>, <code class="reqn">\beta=\frac{1}{2}\sigma |\gamma|</code>, and <code class="reqn">\xi= \mu - 2 \sigma/\gamma</code>.
If <code class="reqn">\gamma &gt; 0</code>, then the range of <code class="reqn">x</code> is <code class="reqn">\xi \le x &lt; \infty</code> and
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{(x - \xi)^{\alpha - 1} e^{-(x-\xi)/\beta}}{\beta^{\alpha} \Gamma(\alpha)}</code>
</p>

<p style="text-align: center;"><code class="reqn">F(x) = G \left(\alpha, \frac{x-\xi}{\beta}\right)/ \Gamma(\alpha)</code>
</p>

<p>If <code class="reqn">\gamma=0</code>, then the distribution is Normal, the range of <code class="reqn">x</code> is <code class="reqn">-\infty &lt; x &lt; \infty</code> and
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \phi \left(\frac{x-\mu}{\sigma}\right)</code>
</p>

<p style="text-align: center;"><code class="reqn">F(x) = \Phi \left(\frac{x-\mu}{\sigma}\right)</code>
</p>

<p>where
<code class="reqn">\phi(x)=(2\pi)^{-1/2}\exp(-x^2/2)</code> and
<code class="reqn">\Phi(x)=\int_{-\infty}^x \phi(t)dt</code>.
</p>
<p>If <code class="reqn">\gamma &lt; 0</code>, then the range of <code class="reqn">x</code> is <code class="reqn">-\infty &lt; x \le \xi</code> and
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{(\xi - x)^{\alpha - 1} e^{-(\xi-x)/\beta}}{\beta^{\alpha} \Gamma(\alpha)}</code>
</p>

<p style="text-align: center;"><code class="reqn">F(x) = G \left(\alpha, \frac{\xi-x}{\beta}\right)/ \Gamma(\alpha)</code>
</p>

<p>In each case, <code class="reqn">x(F)</code> has no explicit analytical form.
Here <code class="reqn">\Gamma</code> is the gamma function, defined as </p>
<p style="text-align: center;"><code class="reqn">\Gamma (x) = \int_0^{\infty} t^{x-1} e^{-t} dt</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">G(\alpha, x) = \int_0^x t^{\alpha-1} e^{-t} dt</code>
</p>

<p>is the incomplete gamma function.
</p>
<p><code class="reqn">\gamma=2</code> is the exponential distribution; <code class="reqn">\gamma=0</code> is the Normal distribution; <code class="reqn">\gamma=-2</code> is the reverse exponential distribution.
</p>
<p>The parameters <code class="reqn">\mu</code>, <code class="reqn">\sigma</code> and <code class="reqn">\gamma</code> are the conventional moments of the distribution.
</p>
<p><b>L-moments</b>
</p>
<p>Assuming <code class="reqn">\gamma&gt;0</code>, L-moments are defined for <code class="reqn">0&lt;\alpha&lt;\infty</code>.
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha \beta</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \pi^{-1/2} \beta \Gamma(\alpha + 1/2)/\Gamma(\alpha)</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = 6 I_{1/3} (\alpha, 2 \alpha)-3</code>
</p>

<p>where <code class="reqn">I_x(p,q)</code> is the incomplete beta function ratio
</p>
<p style="text-align: center;"><code class="reqn">I_x(p,q) = \frac{\Gamma(p+q)}{\Gamma(p)\Gamma(q)} \int_0^x t^{p-1} (1-t)^{q-1} dt</code>
</p>

<p>There is no simple expression for <code class="reqn">\tau_4</code>.
Here we use the rational-funcion approximation given by Hosking and Wallis (1997, pp. 201-202).
</p>
<p>The corresponding results for <code class="reqn">\gamma &lt;0</code> are obtained by changing the signs of <code class="reqn">\lambda_1</code>, <code class="reqn">\tau_3</code> and <code class="reqn">\xi</code> wherever they occur above.
</p>
<p><b>Parameters</b>
</p>
<p><code class="reqn">alpha</code> is obtained with an approximation.
If <code class="reqn">0&lt;|\tau_3|&lt;1/3</code>, let <code class="reqn">z=3 \pi \tau_3^2</code> and use
</p>
<p style="text-align: center;"><code class="reqn">\alpha \approx \frac{1+0.2906 z}{z + 0.1882 z^2 + 0.0442 z^3}</code>
</p>

<p>if <code class="reqn">1/3&lt;|\tau_3|&lt;1</code>, let <code class="reqn">z=1-|\tau_3|</code> and use
</p>
<p style="text-align: center;"><code class="reqn">\alpha \approx \frac{0.36067 z - 0.59567 z^2 + 0.25361 z^3}{1-2.78861 z + 2.56096 z^2 -0.77045 z^3}</code>
</p>

<p>Given <code class="reqn">\alpha</code>, then
<code class="reqn">\gamma=2 \alpha^{-1/2} sign(\tau_3)</code>,
<code class="reqn">\sigma=\lambda_2 \pi^{1/2} \alpha^{1/2} \Gamma(\alpha)/\Gamma(\alpha+1/2)</code>,
<code class="reqn">\mu=\lambda_1</code>.
</p>
<p><code>Lmom.gamma</code> and <code>par.gamma</code> accept input as vectors of equal length. 
In <code>f.gamma</code>, <code>F.gamma</code>, <code>invF.gamma</code> and <code>rand.gamma</code> parameters (<code>mu</code>, <code>sigma</code>, <code>gamm</code>) must be atomic.
</p>


<h3>Value</h3>

<p><code>f.gamma</code> gives the density <code class="reqn">f</code>, <code>F.gamma</code> gives the distribution function <code class="reqn">F</code>, <code>invFgamma</code> gives
the quantile function <code class="reqn">x</code>, <code>Lmom.gamma</code> gives the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>), <code>par.gamma</code> gives the parameters (<code>mu</code>, <code>sigma</code>, <code>gamm</code>), and <code>rand.gamma</code> generates random deviates.
</p>
<p><code>mom2par.gamma</code> returns the parameters <code class="reqn">\alpha</code>, <code class="reqn">\beta</code> and <code class="reqn">\xi</code>, given the parameters (moments) <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\gamma</code>.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="#topic+EXP">EXP</a></code>, <code><a href="#topic+GENLOGIS">GENLOGIS</a></code>, <code><a href="#topic+GENPAR">GENPAR</a></code>, <code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>, <code><a href="#topic+KAPPA">KAPPA</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>; <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code>, <code><a href="#topic+GOFmontecarlo">GOFmontecarlo</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
fac &lt;- factor(annualflows["cod"][,])
split(x,fac)

camp &lt;- split(x,fac)$"45"
ll &lt;- Lmoments(camp)
parameters &lt;- par.gamma(ll[1],ll[2],ll[4])
f.gamma(1800,parameters$xi,parameters$beta,parameters$alfa)
F.gamma(1800,parameters$xi,parameters$beta,parameters$alfa)
invF.gamma(0.7511627,parameters$xi,parameters$beta,parameters$alfa)
Lmom.gamma(parameters$xi,parameters$beta,parameters$alfa)
rand.gamma(100,parameters$xi,parameters$beta,parameters$alfa)

Rll &lt;- regionalLmoments(x,fac); Rll
parameters &lt;- par.gamma(Rll[1],Rll[2],Rll[4])
Lmom.gamma(parameters$xi,parameters$beta,parameters$alfa)

moments &lt;- par2mom.gamma(parameters$alfa,parameters$beta,parameters$xi); moments
mom2par.gamma(moments$mu,moments$sigma,moments$gamm)
</code></pre>

<hr>
<h2 id='REGRDIAGNOSTICS'>Diagnostics of regressions</h2><span id='topic+REGRDIAGNOSTICS'></span><span id='topic+R2.lm'></span><span id='topic+prt.lm'></span><span id='topic+mantel.lm'></span><span id='topic+vif.lm'></span><span id='topic+RMSE.lm'></span><span id='topic+MAE.lm'></span><span id='topic+predinterval.lm'></span><span id='topic+jackknife1.lm'></span><span id='topic+RMSEjk.lm'></span><span id='topic+MAEjk.lm'></span>

<h3>Description</h3>

<p>Diagnostics of the output of <code>lm</code>, that is used to fit linear models. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'> R2.lm (x)
 prt.lm (x)
 mantel.lm (x, Nperm = 1000)
 vif.lm (x)
 RMSE.lm (x) 
 MAE.lm (x)
 predinterval.lm (x, level = 0.95)
 jackknife1.lm (x)
 RMSEjk.lm (x)
 MAEjk.lm (x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="REGRDIAGNOSTICS_+3A_x">x</code></td>
<td>
<p>object of class &ldquo;lm&rdquo; (output of &lsquo;lm&rsquo;)</p>
</td></tr>
<tr><td><code id="REGRDIAGNOSTICS_+3A_nperm">Nperm</code></td>
<td>
<p>number of permutations</p>
</td></tr>
<tr><td><code id="REGRDIAGNOSTICS_+3A_level">level</code></td>
<td>
<p>significance level</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mantel.lm</code> is performed under the assumption that the dependent distance matrix is variable, while the independent distance matrices are fixed and measured without error (they are not related to random variables, see Smouse et al., 1986).
Under this assumption, the significance of the regression between distance matrices can be evaluated simultaneously permuting the rows and corresponding columns in only the dependent distance matrix, while the others are held constant.
</p>


<h3>Value</h3>

<p><code>R2.lm</code> returns the coefficient of determination <code class="reqn">R^2</code> and the adjusted coefficient of determination <code class="reqn">R^2_{adj}</code> of the regression.
</p>
<p><code>prt.lm</code> returns the probability <code class="reqn">Pr(&gt;|t|)</code> of the significance test (Student t) of the independent variables.
If the value is 0.06 for a regressor, its coefficient is not significantly different from 0 for a test with significance level of 5%. 
</p>
<p><code>mantel.lm</code> returns the probability <code class="reqn">P</code> of the Mantel test on every variable conditionated to the others.
It substitutes <code>prt.lm</code> when dealing with distance matrices.
If <code class="reqn">P</code> is, for example, 0.92, the variable should be considered significant with significance level greater of 8%.
</p>
<p><code>vif.lm</code> returns the variance inflation factors (VIF) of the independent values of the regression. If <code class="reqn">VIF &gt; 5</code> (or 10) there is a problem of multicollinearity.
</p>
<p><code>RMSE.lm</code> returns the root mean squared error of the regression.
</p>
<p><code>MAE.lm</code> returns the mean absolute error of the regression.
</p>
<p><code>predinterval.lm</code> returns the prediction intervals at a specified <code>level</code> in correspondence to the fitted data.
</p>
<p><code>jackknife1.lm</code> returns predicted values by a jackknife (cross-validation) procedure. 
The procedure (remove 1 observation, fit the model, estimate in the removed point) is repeated for all the points.
</p>
<p><code>RMSEjk.lm</code> returns the root mean squared error of the cross-validation (performed with <code>jackknife1.lm</code>).
</p>
<p><code>MAEjk.lm</code> returns the mean absolute error of the cross-validation (performed with <code>jackknife1.lm</code>).
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+summary.lm">summary.lm</a></code>, <code><a href="stats.html#topic+predict.lm">predict.lm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)

D &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]

#Dm &lt;- tapply(D,cod,mean)
#datregr &lt;- cbind(Dm,parameters)
datregr &lt;- parameters
regr0 &lt;- lm(Dm ~ .,datregr); summary(regr0)
regr1 &lt;- lm(Dm ~ Am + Hm + Ybar,datregr); summary(regr1)

R2.lm(regr0)
R2.lm(regr1)

prt.lm(regr0)
prt.lm(regr1)

vif.lm(regr0)
vif.lm(regr1)

RMSE.lm(regr0)
RMSE.lm(regr1)

MAE.lm(regr0)
MAE.lm(regr1)

predinterval.lm(regr0)

jackknife1.lm(regr0)
jackknife1.lm(regr1)

RMSEjk.lm(regr0)
RMSEjk.lm(regr1)

MAEjk.lm(regr0)
MAEjk.lm(regr1)

# mantel test on distance matrices
#Y &lt;- AD.dist(D,cod)             # it takes some time
#X &lt;- data.frame(apply(datregr[,c("Hm","Ybar")],2,dist))
#dati &lt;- cbind(X)
#modello &lt;- lm(Y ~ Hm + Ybar, dati)
#mantel.lm(modello, Nperm=100)

</code></pre>

<hr>
<h2 id='roi'>Region of influence</h2><span id='topic+roi'></span><span id='topic+roi.hom'></span><span id='topic+roi.st.year'></span>

<h3>Description</h3>

<p>Formation of clusters for Regional Frequency Analysis: region of influence (Burn, 1990).
</p>


<h3>Usage</h3>

<pre><code class='language-R'> roi (p.ungauged, p.gauged, cod.p, x=NULL, cod=NULL)
 roi.hom (p.ungauged, p.gauged, cod.p, x, cod,
   test="HW", limit=2, Nsim=500, index=2)
 roi.st.year (p.ungauged, p.gauged, cod.p, x, cod,
   test="HW", station.year=500, Nsim=500, index=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roi_+3A_x">x</code></td>
<td>
<p>vector representing data from many samples defined with <code>cod</code></p>
</td></tr>
<tr><td><code id="roi_+3A_cod">cod</code></td>
<td>
<p>array that defines the data subdivision among sites</p>
</td></tr>
<tr><td><code id="roi_+3A_index">index</code></td>
<td>
<p>if <code>index</code>=1 samples are divided by their average value;
if <code>index</code>=2 (default) samples are divided by their median value</p>
</td></tr>
<tr><td><code id="roi_+3A_p.ungauged">p.ungauged</code></td>
<td>
<p>parameters of the ungauged site (1 row)</p>
</td></tr>
<tr><td><code id="roi_+3A_p.gauged">p.gauged</code></td>
<td>
<p>parameters of gauged sites</p>
</td></tr>
<tr><td><code id="roi_+3A_cod.p">cod.p</code></td>
<td>
<p>code of gauged sites</p>
</td></tr>
<tr><td><code id="roi_+3A_test">test</code></td>
<td>
<p>homogeneity test to apply: <code>"HW"</code> (default) or <code>"AD"</code> (in <code>roi.st.year</code> you can choose <code>"HW and AD"</code> too</p>
</td></tr>
<tr><td><code id="roi_+3A_limit">limit</code></td>
<td>
<p>limit over which regions must be considered heterogeneous: for example 2 for <code>"HW"</code> or .95 for <code>"AD"</code></p>
</td></tr>
<tr><td><code id="roi_+3A_nsim">Nsim</code></td>
<td>
<p>number of simulations in <code>"HW"</code> or <code>"AD"</code> tests</p>
</td></tr>
<tr><td><code id="roi_+3A_station.year">station.year</code></td>
<td>
<p>number of station years to form the region</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Euclidean distance is used.
Given <code class="reqn">p</code> different classification variables, the distance between two elements <code class="reqn">i</code> and <code class="reqn">j</code> is:
</p>
<p style="text-align: center;"><code class="reqn">d_{i j} = \sqrt{\frac{1}{p} \sum_{h=1}^{p} (x_{h i} - x_{h j})^2}</code>
</p>

<p>where <code class="reqn">x_{h i}</code> is the value of the <code class="reqn">h</code>-th variable of the <code class="reqn">i</code>-th element.
</p>


<h3>Value</h3>

<p><code>roi</code> returns the &lsquo;region of influence&rsquo; for the site defined with <code>p.ungauged</code>.
It the gauged sites ordered according to the euclidean distance against the site of interest (the distance is evaluated in the space defined by parameters <code>p.ungauged</code> and <code>p.gauged</code>).
If <code>x=NULL</code> and <code>cod=NULL</code> (default), a data.frame with the ordered sites and the distances against the site of interest is returned.
If <code>x</code> and <code>cod</code> are provided, the data.frame will contain also statistics of samples (number of data <code>n</code> and L-moments).
</p>
<p><code>roi.hom</code> returns the &lsquo;region of influence&rsquo; for the site defined with <code>p.ungauged</code>.
It returns codes of gauged sites that form an homogeneous region according to the Hosking and Wallis <code>"HW"</code> or Anderson-Darling <code>"AD"</code> tests.
The region is formed using distances in the space defined by parameters <code>p.ungauged</code> and <code>p.gauged</code>.
</p>
<p><code>roi.st.year</code> returns the &lsquo;region of influence&rsquo; for the site defined with <code>p.ungauged</code>.
It returns codes of gauged sites that form a region and the risult of homogeneity tests, according to the station-year criterion.
It also return the similarity ranking factor <code class="reqn">S_i</code>, the weights <code class="reqn">w_i</code> and the regional L-moments as evaluated in the Flood Estimation Handbook (Robson and Reed, 1999).
The region is formed using distances in the space defined by parameters <code>p.ungauged</code> and <code>p.gauged</code>.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+traceWminim">traceWminim</a></code>, <code><a href="#topic+AD.dist">AD.dist</a></code>, <code><a href="#topic+HOMTESTS">HOMTESTS</a></code> for the definition of the Hosking and Wallis <code>"HW"</code> or Anderson-Darling <code>"AD"</code> tests.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
parameters
summary(parameters)

annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]

roi(parameters[5,3:5],parameters[-5,3:5],parameters[-5,1])
roi(parameters[5,3:5],parameters[-5,3:5],parameters[-5,1],x,cod)

# roi.hom
#roi.hom(parameters[5,3:5],parameters[-5,3:5],parameters[-5,1],x,cod)
                            # it takes some time
#roi.hom(parameters[5,3:5],parameters[-5,3:5],parameters[-5,1],x,cod,
#        test="AD",limit=.95)      # it takes some time

#roi.hom(parameters[8,3:5],parameters[-8,3:5],
#         parameters[-8,1],x,cod)    # it takes some time


# roi.st.year
roi.st.year(parameters[5,3:5],parameters[-5,3:5],
            parameters[-5,1],x,cod)
roi.st.year(parameters[5,3:5],parameters[-5,3:5],parameters[-5,1],
            x,cod,test="AD",station.year=100)

</code></pre>

<hr>
<h2 id='SERIESPLOTS'>Series plots</h2><span id='topic+SERIESPLOTS'></span><span id='topic+serieplot'></span><span id='topic+consistencyplot'></span>

<h3>Description</h3>

<p>Plots for time-series investigation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> serieplot (x, t, lim.x=c(min(x),max(x)), lim.t=c(min(t),max(t)), 
            ...)
 consistencyplot (t, cod, cex.axis=.8, mark.code=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SERIESPLOTS_+3A_x">x</code></td>
<td>
<p>data sample</p>
</td></tr>
<tr><td><code id="SERIESPLOTS_+3A_t">t</code></td>
<td>
<p>vector representing time (e.g. years) of data-samples defined with <code>cod</code></p>
</td></tr>
<tr><td><code id="SERIESPLOTS_+3A_lim.x">lim.x</code>, <code id="SERIESPLOTS_+3A_lim.t">lim.t</code></td>
<td>
<p>plot limits</p>
</td></tr>
<tr><td><code id="SERIESPLOTS_+3A_cod">cod</code></td>
<td>
<p>array that defines the data subdivision among sites</p>
</td></tr>
<tr><td><code id="SERIESPLOTS_+3A_cex.axis">cex.axis</code></td>
<td>
<p>dimensions of points and labels</p>
</td></tr>
<tr><td><code id="SERIESPLOTS_+3A_mark.code">mark.code</code></td>
<td>
<p>if TRUE (default) codes of samples are plotted on y axis</p>
</td></tr>
<tr><td><code id="SERIESPLOTS_+3A_...">...</code></td>
<td>
<p>graphical parameters as <code>xlab</code>, <code>ylab</code>, <code>main</code>, ...</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>consistencyplot</code> displays time-series consistency.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="#topic+DISTPLOTS">DISTPLOTS</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(hydroSIMN)
annualflows[c(1:10),]
x &lt;- annualflows["dato"][,]
y &lt;- annualflows["anno"][,]
cod &lt;- annualflows["cod"][,]
consistencyplot(y,cod)


for (i in unique(cod)) {
 serieplot(x[cod==i], y[cod==i], c(0,max(x)), c(min(y),max(y)),
           xlab="", ylab="D [mm]", main=i)
 readline()
}
</code></pre>

<hr>
<h2 id='STATICPLOTS'>Static plots</h2><span id='topic+STATICPLOTS'></span><span id='topic+Lmoment.ratio.diagram'></span><span id='topic+Lspace.HWvsAD'></span><span id='topic+Lspace.limits'></span>

<h3>Description</h3>

<p>Plots from books and articles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> Lmoment.ratio.diagram (grid=TRUE, ...)
 Lspace.HWvsAD (grid=TRUE, ...)
 Lspace.limits (grid=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="STATICPLOTS_+3A_grid">grid</code></td>
<td>
<p>should a grid be plotted?</p>
</td></tr>
<tr><td><code id="STATICPLOTS_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Lmoment.ratio.diagram</code> plots points corresponding to two parameters distributions and lines corresponding to three parameters distributions on the 'L-CA - L-kur' plane.
The distributions are:
E = exponential,
G = gumbel,
L = logistic,
N = normal,
U = uniform,
GLO = generalized logistic,
GEV = generalized extreme-value,
GPA = generalized Pareto,
LN3 = lognormal,
PE3 = Pearson type III.
</p>
<p><code>Lspace.HWvsAD</code> separate regions, in 'L-CA - L-CV' space, where the homogeneity tests of Hosking and Wallis (HW) and Anderson-Darling (AD) are preferable.
</p>
<p><code>Lspace.limits</code> displays limits for regional L-moments in the 'L-CA - L-CV'.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+EXP">EXP</a></code>, <code><a href="#topic+GENLOGIS">GENLOGIS</a></code>, <code><a href="#topic+GENPAR">GENPAR</a></code>, <code><a href="#topic+LOGNORM">LOGNORM</a></code>, <code><a href="#topic+GUMBEL">GUMBEL</a></code>, <code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+P3">P3</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Lmoment.ratio.diagram()
Lspace.HWvsAD()
Lspace.limits()

data(hydroSIMN)
annualflows[c(1:10),]
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]
rlm &lt;- regionalLmoments(x,cod)
Lmoment.ratio.diagram()
points(rlm["lcaR"],rlm["lkurR"],col="red",pch=19)

Lspace.HWvsAD()
points(rlm["lcaR"],rlm["lcvR"],col="red",pch=19)
</code></pre>

<hr>
<h2 id='traceWminim'>Cluster analysis: disjoint regions</h2><span id='topic+traceWminim'></span><span id='topic+sumtraceW'></span><span id='topic+nearest'></span>

<h3>Description</h3>

<p>Formation of disjoint regions for Regional Frequency Analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> traceWminim (X, centers)
 sumtraceW (clusters, X)
 nearest (clusters, X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="traceWminim_+3A_x">X</code></td>
<td>
<p>a numeric matrix of characteristics, or an object that can be coerced to
such a matrix (such as a numeric vector or a data frame with
all numeric columns)</p>
</td></tr>
<tr><td><code id="traceWminim_+3A_centers">centers</code></td>
<td>
<p>the number of clusters</p>
</td></tr>
<tr><td><code id="traceWminim_+3A_clusters">clusters</code></td>
<td>
<p>a numeric vector containing the subdivision of <code>X</code> in clusters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Euclidean distance is used.
Given <code class="reqn">p</code> different classification variables, the distance between two elements <code class="reqn">i</code> and <code class="reqn">j</code> is:
</p>
<p style="text-align: center;"><code class="reqn">d_{i j} = \sqrt{\frac{1}{p} \sum_{h=1}^{p} (x_{h i} - x_{h j})^2}</code>
</p>

<p>where <code class="reqn">x_{h i}</code> is the value of the <code class="reqn">h</code>-th variable of the <code class="reqn">i</code>-th element.
</p>
<p>The function <code>traceWminim</code> is a composition of a jerarchical algorithm, the Ward (1963) one, and an optimisation procedure consisting in the minimisation of:
</p>
<p style="text-align: center;"><code class="reqn">W = \sum_{i=1}^k \left( \sum_{j=1}^{n_i} \delta_{i j}^2 \right)</code>
</p>

<p>where
<code class="reqn">k</code> is the number of clusters (obtained initially with Ward's algorithm), <code class="reqn">n_i</code> is the number of sites in the <code class="reqn">i</code>-th cluster and <code class="reqn">\delta_{i j}</code> is the Euclidean distance between the <code class="reqn">j</code>-th element of the <code class="reqn">i</code>-th group and the center of mass of the <code class="reqn">i</code>-th cluster.
<code class="reqn">W</code> is calculated with <code>sumtraceW</code>.
The algorithm consist in moving a site from one cluster to another if this makes <code class="reqn">W</code> decrease.
</p>


<h3>Value</h3>

<p><code>traceWminim</code> gives a vector defining the subdivision of elements characterized by <code>X</code> in n=<code>centers</code> clusters.
</p>
<p><code>sumtraceW</code> gives <code class="reqn">W</code> (it is used by <code>traceWminim</code>).
</p>
<p><code>nearest</code> gives the nearest site to the centers of mass of clusters (it is used by <code>traceWminim</code>).
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+roi">roi</a></code>, <code><a href="#topic+AD.dist">AD.dist</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hydroSIMN)
parameters
summary(parameters)

# traceWminim
param &lt;- parameters[c("Hm","Ybar")]
n &lt;- dim(param)[1]; k &lt;- dim(param)[2]
param.norm &lt;- (param - matrix(apply(param,2,mean),nrow=n,ncol=k,
               byrow=TRUE))/matrix(apply(param,2,sd),
               nrow=n,ncol=k,byrow=TRUE)
clusters &lt;- traceWminim(param.norm,4); 
names(clusters) &lt;- parameters["cod"][,]
clusters

annualflows
summary(annualflows)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]

fac &lt;- factor(annualflows["cod"][,],
              levels=names(clusters[clusters==1]))
x1 &lt;- annualflows[!is.na(fac),"dato"]
cod1 &lt;- annualflows[!is.na(fac),"cod"]
#HW.tests(x1,cod1)          # it takes some time

fac &lt;- factor(annualflows["cod"][,],
              levels=names(clusters[clusters==3]))
x3 &lt;- annualflows[!is.na(fac),"dato"]
cod3 &lt;- annualflows[!is.na(fac),"cod"]
#HW.tests(x3,cod3)          # it takes some time
</code></pre>

<hr>
<h2 id='varLmoments'>Exact variance structure of sample L-moments</h2><span id='topic+varLmoments'></span><span id='topic+varLCV'></span><span id='topic+varLCA'></span><span id='topic+varLkur'></span>

<h3>Description</h3>

<p><code>varLmoments</code> provides distribution-free unbiased estimators of the variances and covariances of sample L-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> varLmoments (x, matrix=TRUE)
 varLCV (x)
 varLCA (x)
 varLkur (x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varLmoments_+3A_x">x</code></td>
<td>
<p>vector representing a data-sample</p>
</td></tr>
<tr><td><code id="varLmoments_+3A_matrix">matrix</code></td>
<td>
<p>if <code>TRUE</code> (default), the matrix of estimates of the variance structure (variance and covariance) i
of sample L-moments is returned; if <code>FALSE</code>, a vector containing <code class="reqn">var(l_1)</code>, 
<code class="reqn">var(l_2)</code>, <code class="reqn">var(l_3)</code>, <code class="reqn">var(l_4)</code>, <code class="reqn">var(t)</code>, 
<code class="reqn">var(t_3)</code> and <code class="reqn">var(t_4)</code> is returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimation of the exact variance structure of sample L-moments is based on Elamir et Seheult (2004).
</p>


<h3>Value</h3>

<p><code>varLmoments</code> gives the matrix of unbiased estimates of the variance structure of sample L-moments: 
this is a 4x4 matrix containg <code class="reqn">var(l_1)</code>, <code class="reqn">var(l_2)</code>, <code class="reqn">var(l_3)</code>, 
<code class="reqn">var(l_4)</code> on the main diagonal, 
and the correspondant covariances elsewhere (<code class="reqn">cov(l_1,l_2)</code>, <code class="reqn">cov(l_1,l_3)</code>, etc.);
</p>
<p><code>varLCV</code> gives the unbiased estimate of the variance of sample coefficient of L-variation of <code>x</code>;
</p>
<p><code>varLCA</code> gives the unbiased estimate of the variance of sample L-skewness of <code>x</code>;
</p>
<p><code>varLkur</code> gives the unbiased estimate of the variance of sample L-kurtosis of <code>x</code>.
</p>


<h3>Note</h3>

<p>For information on the package and the Author, and for all the references, see <code><a href="#topic+nsRFA">nsRFA</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+var">var</a></code>, <code><a href="#topic+Lmoments">Lmoments</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(30,10,2)
varLmoments(x)
varLmoments(x, FALSE)

varLCV(x)
varLCA(x)
varLkur(x)

data(hydroSIMN)
x &lt;- annualflows["dato"][,]
cod &lt;- annualflows["cod"][,]
dvarLmom &lt;- function(x) {diag(varLmoments(x))}
sapply(split(x,cod),dvarLmom)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
