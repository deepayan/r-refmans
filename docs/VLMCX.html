<!DOCTYPE html><html><head><title>Help for package VLMCX</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {VLMCX}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AIC'>
<p>Akaike Information Criteria for <code>VLMCX</code> objects that compose Variable Length Markov Chains with Exogenous Covariates</p></a></li>
<li><a href='#BIC'>
<p>Bayesian Information Criteria for for <code>VLMCX</code> objects that compose Variable Length Markov Chains with Exogenous Covariates</p></a></li>
<li><a href='#coef'>
<p>Coefficients from a Variable Length Markov Chain with Exogenous Covariates</p></a></li>
<li><a href='#context.algorithm'>
<p>Context Algorithm using exogenous covariates</p></a></li>
<li><a href='#draw'>
<p>Draw the Variable Length Markov Chain estimated model</p></a></li>
<li><a href='#estimate'>
<p>Estimation of Variable Length Markov Chain with Exogenous Covariates</p></a></li>
<li><a href='#LogLik'>
<p>Log Likelihood for Variable Length Markov Chains with Exopgenous Covariates</p></a></li>
<li><a href='#maximum.context'>
<p>Maximum Context Tree</p></a></li>
<li><a href='#predict'>
<p>Prediction of the next state of the Markov Chain/Categorical Time series</p></a></li>
<li><a href='#simulate'>
<p>Simulate a Variable Length Markov Chain with Exogenous covariates</p></a></li>
<li><a href='#VLMCX'>
<p>Variable Length Markov Chain with Exogenous Covariates</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Length Markov Chain with Exogenous Covariates</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-01</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, nnet, berryFunctions, stats, utils</td>
</tr>
<tr>
<td>Description:</td>
<td>Models categorical time series through a Markov Chain when a) covariates are predictors for transitioning into the next state/symbol and b) when the dependence in the past states has variable length. The probability of transitioning to the next state in the Markov Chain is defined by a multinomial regression whose parameters depend on the past states of the chain and, moreover, the number of states in the past needed to predict the next state also depends on the observed states themselves. See Zambom, Kim, and Garcia (2022) &lt;<a href="https://doi.org/10.1111%2Fjtsa.12615">doi:10.1111/jtsa.12615</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-07 07:14:39 UTC; adrianozambom</td>
</tr>
<tr>
<td>Author:</td>
<td>Adriano Zanin Zambom Developer [aut, cre, cph],
  Seonjin Kim Developer [aut],
  Nancy Lopes Garcia Developer [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adriano Zanin Zambom Developer &lt;adriano.zambom@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-08 21:10:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='AIC'>
Akaike Information Criteria for <code>VLMCX</code> objects that compose Variable Length Markov Chains with Exogenous Covariates
</h2><span id='topic+AIC'></span>

<h3>Description</h3>

<p>Computes the Akaike Information Criteria for the data using the estimated parameters of the multinomial logistic regression in the VLMCX fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AIC(fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AIC_+3A_fit">fit</code></td>
<td>

<p>a betaVLMC object.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> a numeric value with the corresponding AIC.
</p>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(1)
n = 1000
d = 2

X = cbind(rnorm(n), rnorm(n))
p = 1/(1 + exp(0.5 + -2*X[,1] - 3.5*X[,2]))

y = c(sample(1:0,1), rbinom(n,1, p)) 

fit = maximum.context(y[1:n], X, max.depth = 3, n.min = 25)
draw(fit)
AIC(fit)
##[1] 563.5249

fit = VLMCX(y[1:n], X, alpha.level = 0.001, max.depth = 3, n.min = 25)
draw(fit)
AIC(fit)
##[1] 559.4967

</code></pre>

<hr>
<h2 id='BIC'>
Bayesian Information Criteria for for <code>VLMCX</code> objects that compose Variable Length Markov Chains with Exogenous Covariates
</h2><span id='topic+BIC'></span>

<h3>Description</h3>

<p>Computes the Bayesian Information Criteria for the data using the estimated parameters of the multinomial logistic regression in the VLMCX fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BIC(fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BIC_+3A_fit">fit</code></td>
<td>

<p>a betaVLMC object.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> a numeric value with the corresponding BIC.
</p>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>



set.seed(1)
n = 1000
d = 2

X = cbind(rnorm(n), rnorm(n))
p = 1/(1 + exp(0.5 + -2*X[,1] - 3.5*X[,2]))

y = c(sample(1:0,1), rbinom(n,1, p)) 

fit = maximum.context(y[1:n], X, max.depth = 3, n.min = 25)
draw(fit)
BIC(fit)
##[1] 696.0343

fit = VLMCX(y[1:n], X, alpha.level = 0.001, max.depth = 3, n.min = 25)
draw(fit)
BIC(fit)
##[1] 588.9432

</code></pre>

<hr>
<h2 id='coef'>
Coefficients from a Variable Length Markov Chain with Exogenous Covariates
</h2><span id='topic+coef'></span>

<h3>Description</h3>

<p>Extracts the estimated coefficients from a VLMCX object for a specific context (sequence of states in the past used to predict the next state/symbol of the chain).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coef(fit, context)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef_+3A_fit">fit</code></td>
<td>

<p>a VLMCX object.
</p>
</td></tr>
<tr><td><code id="coef_+3A_context">context</code></td>
<td>

<p>the context whose coefficients are desired.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> an object with two items: 
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>a vector with coefficients corresponding to the intercept for the transition into the states in the state space of <code>y</code>.</p>
</td></tr> 
<tr><td><code>beta</code></td>
<td>
<p>a 3 dimensional-array of estimated coefficients corresponding to [steps in the past, number of covariate, symbol (in the state space) to transition into].</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(1)
n = 1000
d = 2

X = cbind(rnorm(n), rnorm(n))

y = rbinom(n,1,.5)
fit = maximum.context(y, X)

coef(fit, c(0,0,1,0)) 
## context in the order: y_{t-1} = 0, y_{t-2} = 0, y_{t-3} = 1, y_{t-4} = 0

</code></pre>

<hr>
<h2 id='context.algorithm'>
Context Algorithm using exogenous covariates
</h2><span id='topic+context.algorithm'></span>

<h3>Description</h3>

<p>Prunes the given tree according to the significance of the covariates and the contexts that are determined by a multinomial regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>context.algorithm(fit, node, alpha.level = 0.05, max.depth = 5, n.min = 5, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="context.algorithm_+3A_fit">fit</code></td>
<td>

<p>a VLMCX object
</p>
</td></tr>
<tr><td><code id="context.algorithm_+3A_node">node</code></td>
<td>

<p>The top most node up to which the prunning is allowed.
</p>
</td></tr>
<tr><td><code id="context.algorithm_+3A_alpha.level">alpha.level</code></td>
<td>

<p>the alpha level for rejection of each hypothesis in the algorithm.
</p>
</td></tr>
<tr><td><code id="context.algorithm_+3A_max.depth">max.depth</code></td>
<td>

<p>the maximum depth of the initial &quot;maximal&quot; tree.
</p>
</td></tr>
<tr><td><code id="context.algorithm_+3A_n.min">n.min</code></td>
<td>

<p>minimum number of observations for each parameter needed in the estimation of that context
</p>
</td></tr>
<tr><td><code id="context.algorithm_+3A_trace">trace</code></td>
<td>

<p>if trace == TRUE then information is printed during the running of the prunning algorithm.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> context.algorithm returns an object of class <code>"VLMCX"</code>. The generic functions <code><a href="#topic+coef">coef</a></code>, <code><a href="#topic+AIC">AIC</a></code>,<code><a href="#topic+BIC">BIC</a></code>, <code><a href="#topic+draw">draw</a></code>, and <code><a href="#topic+LogLik">LogLik</a></code> extract various useful features of the fitted object returned by <em>VLMCX</em>.
</p>
<p>An object of class <code>"VLMCX"</code> is a list containing at least the following components:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>the time series data corresponding to the states inputed by the user.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the time series covariates data inputed by the user.</p>
</td></tr>
<tr><td><code>tree</code></td>
<td>
<p>the estimated rooted tree estimated by the algorithm. Each node contains the <code>context</code>, the intercept (<code>alpha</code>) and regression parameters (<code>beta</code>) corresponding to the covariates of that regression and a list <code>child</code>, whose entries are <code>nodes</code> with the same structure.</p>
</td></tr>
<tr><td><code>LogLik</code></td>
<td>
<p>the log-likelihood of the data using the estimated context tree.</p>
</td></tr>
<tr><td><code>baseline.state</code></td>
<td>
<p>the state used as a baseline fore the multinomial regression.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n = 500

X = cbind(rnorm(n), rnorm(n))
y = rbinom(n,1,.5)

fit = maximum.context(y, X, max.depth = 3)
pruned.fit = context.algorithm(fit, fit$tree)
draw(pruned.fit)

</code></pre>

<hr>
<h2 id='draw'>
Draw the Variable Length Markov Chain estimated model
</h2><span id='topic+draw'></span>

<h3>Description</h3>

<p>Draws the rooted tree corresponding to the estimated contexts in a <code>VLMCX</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw(fit, title = "VLMCX Context Tree", print.coef = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw_+3A_fit">fit</code></td>
<td>

<p>a VLMCX object.
</p>
</td></tr>
<tr><td><code id="draw_+3A_title">title</code></td>
<td>

<p>the title in the graph.
</p>
</td></tr>
<tr><td><code id="draw_+3A_print.coef">print.coef</code></td>
<td>

<p>It TRUE the algorithm prints in the console the list of all contexts and their corresponding alpha and beta coefficients for the multinomial regression. If FALSE, the algorithm prints in the console a text version of the rooted context tree.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The graph contains circles corresponding to the estimated nodes of the contexts estimated by the algorithm but does not include the structure and covariate parameter vectors.
</p>


<h3>Value</h3>

<p> No return value, called for plotting only.
</p>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

n = 1000
d = 2
set.seed(1)
X = cbind(rnorm(n), rnorm(n))

y = rbinom(n,1,.2)
fit = maximum.context(y, X)

draw(fit)

fit = VLMCX(y, X, alpha.level = 0.0001, max.depth = 3, n.min = 15, trace = TRUE)
draw(fit)

draw(fit, print.coef = FALSE)



</code></pre>

<hr>
<h2 id='estimate'>
Estimation of Variable Length Markov Chain with Exogenous Covariates
</h2><span id='topic+estimate'></span>

<h3>Description</h3>

<p>Estimates the parameters of the multinomial logistic model in the VLMCX tree for each context in the tree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate(VLMCXtree, y, X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_+3A_vlmcxtree">VLMCXtree</code></td>
<td>

<p>a VLMCX tree
</p>
</td></tr>
<tr><td><code id="estimate_+3A_y">y</code></td>
<td>

<p>a &quot;time series&quot; vector (numeric, charachter, or factor)
</p>
</td></tr>
<tr><td><code id="estimate_+3A_x">X</code></td>
<td>

<p>Numeric matrix of predictors with rows corresponding to the y observations (over time) and columns corresponding to covariates.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> A tree from an object of type VLMCX. The tree contains the items
</p>
<table>
<tr><td><code>context</code></td>
<td>
<p>the context, or sequence of symbols.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>a vector with coefficients corresponding to the intercept for the transition into the states in the state space of <code>y</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>a 3 dimensional-array of estimated coefficients corresponding to [steps in the past, number of covariate, symbol (in the state space) to transition into].</p>
</td></tr>
<tr><td><code>child</code></td>
<td>
<p>list whose entries are <code>nodes</code> with the same structure.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(1)
n = 4000
d = 2

X = cbind(rnorm(n), rnorm(n))
alphabet = 0:2 ### state space
y = sample(alphabet,2, replace = TRUE)
for (i in 3:n)
{
	if (identical(as.numeric(y[(i-1):(i-2)]), c(0,0)))
		value =  c(exp(-0.5 + -1*X[i-1,1] + 2.5*X[i-1,2]),      
		           exp(0.5 + -2*X[i-1,1] - 3.5*X[i-1,2]))
	else if (identical(as.numeric(y[(i-1):(i-2)]), c(0,1)))
		value = c(exp(-0.5),     exp(0.5))
	else
		value = c(runif(1,0,3), runif(1,0,3))


    prob = c(1,value)/(1 + sum(value)) ## compute probs with baseline state probability
    y[i] = sample(alphabet,1,prob=prob)
    
}
  

tree = NULL
tree$context = "x"  ## this is the root
tree$alpha = NULL
tree$beta = NULL
tree$child = list()
this_child = NULL
this_child$context = "0"
this_child$alpha = 0
this_child$child = list()
tree$child[[1]] = this_child

this_grandchild = NULL
this_grandchild$context = c(0, 0)
this_grandchild$alpha = 0
this_grandchild$beta = array(c(0,0,0,0),c(1, 2, 2)) ## steps, d, alphabet (state space)
this_grandchild$child = list()

tree$child[[1]]$child[[1]] = this_grandchild

this_other_grandchild = NULL
this_other_grandchild$context = c(0, 1)
this_other_grandchild$alpha = 0
this_other_grandchild$beta = NULL
this_other_grandchild$child = list()

tree$child[[1]]$child[[2]] = this_other_grandchild

estimate(tree, y, X)

fit = VLMCX(y, X, alpha.level = 0.0001, max.depth = 2, n.min = 15, trace = TRUE)
estimate(fit$tree, y, X)



</code></pre>

<hr>
<h2 id='LogLik'>
Log Likelihood for Variable Length Markov Chains with Exopgenous Covariates
</h2><span id='topic+LogLik'></span>

<h3>Description</h3>

<p>Computes the log-likelihood of the data using the estimated parameters of the multinomial logistic regression based on contexts of variable length, that is, a finite suffix of the past, called &quot;context&quot;, is used to predict the next symbol, which can have different lengths depending on the past observations themselves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LogLik(fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LogLik_+3A_fit">fit</code></td>
<td>

<p>a VLMCX object.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> a numeric value with the corresponding log-likelihood
</p>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


n = 1000
d = 2

X = cbind(rnorm(n), rnorm(n))

y = rbinom(n,1,.5)
fit = maximum.context(y, X)

LogLik(fit)

</code></pre>

<hr>
<h2 id='maximum.context'>
Maximum Context Tree
</h2><span id='topic+maximum.context'></span>

<h3>Description</h3>

<p>Build the largest context tree, which is the biggest context tree such that all elements in it have been observed at least <code>n.min</code> times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maximum.context(y, X, max.depth = 5, n.min = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maximum.context_+3A_y">y</code></td>
<td>

<p>a &quot;time series&quot; vector (numeric, charachter, or factor)
</p>
</td></tr>
<tr><td><code id="maximum.context_+3A_x">X</code></td>
<td>

<p>Numeric matrix of predictors with rows corresponding to the y observations (over time) and columns corresponding to covariates.
</p>
</td></tr>
<tr><td><code id="maximum.context_+3A_max.depth">max.depth</code></td>
<td>

<p>Maximum depth of the desired tree.
</p>
</td></tr>
<tr><td><code id="maximum.context_+3A_n.min">n.min</code></td>
<td>

<p>Minimum number of observations per coefficient to be estimated.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> maximum.context returns an object of class <code>"VLMCX"</code>. The generic functions <code><a href="#topic+coef">coef</a></code>, <code><a href="#topic+AIC">AIC</a></code>,<code><a href="#topic+BIC">BIC</a></code>, <code><a href="#topic+draw">draw</a></code>, and <code><a href="#topic+LogLik">LogLik</a></code> extract various useful features of the value returned by <em>VLMCX</em>.
</p>
<p>An object of class <code>"VLMCX"</code> is a list containing at least the following components:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>the time series data corresponding to the states inputed by the user.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the time series covariates data inputed by the user.</p>
</td></tr>
<tr><td><code>tree</code></td>
<td>
<p>the estimated rooted tree estimated by the algorithm. Each node contains the <code>context</code>, the intercept (<code>alpha</code>) and regression parameters (<code>beta</code>) corresponding to the covariates of that regression and a list <code>child</code>, whose entries are <code>nodes</code> with the same structure.</p>
</td></tr>
<tr><td><code>LogLik</code></td>
<td>
<p>the log-likelihood of the data using the estimated context tree.</p>
</td></tr>
<tr><td><code>baseline.state</code></td>
<td>
<p>the state used as a baseline fore the multinomial regression.</p>
</td></tr></table>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


n = 1000
d = 2

X = cbind(rnorm(n), rnorm(n))

y = rbinom(n,1,.5)
fit = maximum.context(y, X)

</code></pre>

<hr>
<h2 id='predict'>
Prediction of the next state of the Markov Chain/Categorical Time series
</h2><span id='topic+predict'></span>

<h3>Description</h3>

<p>Uses the estimated coefficients from a VLMCX object to estimate the next state of the Markov Chain either using new data or the original data with which the model was fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict(fit, new.y = NULL, new.X = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_fit">fit</code></td>
<td>

<p>a VLMCX object.
</p>
</td></tr>
<tr><td><code id="predict_+3A_new.y">new.y</code></td>
<td>

<p>the new sequency of observations of the &quot;time series&quot; as a vector (numeric, charachter, or factor). The values of y.new must be of the same type as the ones used to fit the VLMCX object. If new.y is NULL (or if new.X is NULL) the algorithm uses the original data used to fit the VLMCX object.
</p>
</td></tr>
<tr><td><code id="predict_+3A_new.x">new.X</code></td>
<td>

<p>Numeric matrix of predictors with rows corresponding to the new.y observations (over time) and columns corresponding to covariates.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> a value of the predicted symbol of the next state of the Markoc Chain corresponding to the type of the imput (numeric, charachter, or factor).
</p>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(1)
n = 1000

X = cbind(rnorm(n))

y = rbinom(n,1,.5)
fit = maximum.context(y, X)

## using the original data
predict(fit) 

## using new data
predict(fit, new.y = c(0,0,1,0,0), new.X = c(2.3, 1.1, -.2, -3,1))

</code></pre>

<hr>
<h2 id='simulate'>
Simulate a Variable Length Markov Chain with Exogenous covariates
</h2><span id='topic+simulate'></span>

<h3>Description</h3>

<p>Simulate the states of a Markov Chain based on VLMCX model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate(VLMCXtree, nsim = 500, X = NULL, seed = NULL, n.start = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_+3A_vlmcxtree">VLMCXtree</code></td>
<td>

<p>a VLMCX tree (a VLMCX object can also be used, in which case its tree is used).
</p>
</td></tr>
<tr><td><code id="simulate_+3A_nsim">nsim</code></td>
<td>

<p>non-negative integer, giving the length of the result.
</p>
</td></tr>
<tr><td><code id="simulate_+3A_x">X</code></td>
<td>

<p>A vector or matrix of exogenous variables. If vector, its length must be equal to nsim+n.start, if matrix, its first dimension must be of length nsim+n.start, if NULL a univariate independent and identically distributed Normal vector is used.
</p>
</td></tr>
<tr><td><code id="simulate_+3A_seed">seed</code></td>
<td>

<p>random seed initializer.
</p>
</td></tr>
<tr><td><code id="simulate_+3A_n.start">n.start</code></td>
<td>

<p>the number of initial values to be discarded (because of initial effects).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> a vector with nsim simulated states.
</p>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

tree = NULL
  tree$context = "x"  ## this is the root
  tree$alpha = NULL
  tree$beta = NULL
  tree$child = list()
  this_child = NULL
  this_child$context = "left"
  this_child$alpha = 0.5
  this_child$child = list()
  tree$child[[1]] = this_child

  this_grandchild = NULL
  this_grandchild$context = c("left", "left")
  this_grandchild$alpha = 0.6
  this_grandchild$beta = array(c(1.9, 1.6, 2.6, -1.6),c(2, 2, 1)) ## steps, d, alphabet
  this_grandchild$child = list()

  tree$child[[1]]$child[[1]] = this_grandchild

  this_other_grandchild = NULL
  this_other_grandchild$context = c("left", "right")
  this_other_grandchild$alpha = -0.6
  this_other_grandchild$beta = array(c(-1.3, -1.5, 2.3, -1.2),c(2, 2, 1)) 
  this_other_grandchild$child = list()

  tree$child[[1]]$child[[2]] = this_other_grandchild

  other_child = NULL
  other_child$context = "right"
  other_child$alpha = -0.7
  other_child$beta = array(c(1,-.3),c(1, 2, 1)) ## steps, d, alphabet
  other_child$child = list()
  tree$child[[2]] = other_child

  set.seed(1)
  X = cbind(rnorm(1100), rnorm(1100))
  simulated.data = simulate(tree, nsim = 1000, X, seed = 1, n.start = 100)
  fit = VLMCX(simulated.data$y, simulated.data$X, alpha.level = 0.001, 
                 max.depth = 4, n.min = 20, trace = TRUE)
  draw(fit)
  fit

</code></pre>

<hr>
<h2 id='VLMCX'>
Variable Length Markov Chain with Exogenous Covariates
</h2><span id='topic+VLMCX'></span>

<h3>Description</h3>

<p>Estimates a Variable Length Markov Chain model, which can also be seen as a categorical time series model, where exogenous covariates can compose the multinomial regression that predicts the next state/symbol in the chain. This type of approach is a parsimonious model where only a finite suffix of the past, called &quot;context&quot;, is enough to predict the next symbol. The length of the each context can differ depending on the past observations themselves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VLMCX(y, X, alpha.level = 0.05, max.depth = 5, n.min = 5, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VLMCX_+3A_y">y</code></td>
<td>

<p>a &quot;time series&quot; vector (numeric, charachter, or factor)
</p>
</td></tr>
<tr><td><code id="VLMCX_+3A_x">X</code></td>
<td>

<p>Numeric matrix of predictors with rows corresponding to the y observations (over time) and columns corresponding to covariates.
</p>
</td></tr>
<tr><td><code id="VLMCX_+3A_alpha.level">alpha.level</code></td>
<td>

<p>the alpha level for rejection of each hypothesis in the algorithm.
</p>
</td></tr>
<tr><td><code id="VLMCX_+3A_max.depth">max.depth</code></td>
<td>

<p>the maximum depth of the initial &quot;maximal&quot; tree.
</p>
</td></tr>
<tr><td><code id="VLMCX_+3A_n.min">n.min</code></td>
<td>

<p>minimum number of observations for each parameter needed in the estimation of that context
</p>
</td></tr>
<tr><td><code id="VLMCX_+3A_trace">trace</code></td>
<td>

<p>if trace == TRUE then information is printed during the running of the prunning algorithm.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is a backward selection procedure that starts with the maximal context, which is the biggest context tree such that all elements in it have been observed at least <code>n.min</code> times. Then, final nodes (past most state in each context) are prunned according to the p-value from the likelihood ratio test for removing the covariates corresponding to that node and the significance of that node itself. The algorithm continues iteratively prunning until nodes cannot be prunned because the covariates or the node context itself is significant.
</p>


<h3>Value</h3>

<p> VLMCX returns an object of class <code>"VLMCX"</code>. The generic functions <code><a href="#topic+coef">coef</a></code>, <code><a href="#topic+AIC">AIC</a></code>,<code><a href="#topic+BIC">BIC</a></code>, <code><a href="#topic+draw">draw</a></code>, and <code><a href="#topic+LogLik">LogLik</a></code> extract various useful features of the fitted object returned by <em>VLMCX</em>.
</p>
<p>An object of class <code>"VLMCX"</code> is a list containing at least the following components:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>the time series data corresponding to the states inputed by the user.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the time series covariates data inputed by the user.</p>
</td></tr>
<tr><td><code>tree</code></td>
<td>
<p>the estimated rooted tree estimated by the algorithm. Each node contains the <code>context</code>, the intercept (<code>alpha</code>) and regression parameters (<code>beta</code>) corresponding to the covariates of that regression and a list <code>child</code>, whose entries are <code>nodes</code> with the same structure.</p>
</td></tr>
<tr><td><code>LogLik</code></td>
<td>
<p>the log-likelihood of the data using the estimated context tree.</p>
</td></tr>
<tr><td><code>baseline.state</code></td>
<td>
<p>the state used as a baseline fore the multinomial regression.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adriano Zanin Zambom &lt;adriano.zambom@csun.edu&gt; 
</p>


<h3>References</h3>

<p>Zambom, Kim, Garcia (2022) Variable length Markov chain with exogenous covariates. Journal of Time Series Analysis, 43, 321-328.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>



 #### Example 1

 set.seed(1)
 n = 3000
 d = 2

 X = cbind(rnorm(n), rnorm(n))
 alphabet = 0:2
 y = sample(alphabet,2, replace = TRUE)
 for (i in 3:n)
 {
   if (identical(as.numeric(y[(i-1):(i-2)]), c(0,0)))
     value =  c(exp(-0.5 + -1*X[i-1,1] + 2.5*X[i-1,2]),      
            exp(0.5 + -2*X[i-1,1] - 3.5*X[i-1,2]))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(0,1)))
     value = c(exp(-0.5),     exp(0.5))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(0,2)))
     value = c(exp(1),     exp(1))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(2,0)))
     value = c(exp(0.5 + 1.2*X[i-1,1] + 0.5*X[i-1,2] + 2*X[i-2,1] + 1.5*X[i-2,2]),     
               exp(-0.5  -2*X[i-1,1] - .5*X[i-1,2] +1.3*X[i-2,1] + 1.5*X[i-2,2]))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(2,1)))
     value  = c(exp(-1 + -X[i-1,1] + 2.5*X[i-1,2]),       
                exp(0.1 + -0.5*X[i-1,1] - 1.5*X[i-1,2]))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(2,2)))
     value = c(exp(-0.5 + -X[i-1,1] - 2.5*X[i-1,2]),      
               exp(0.5 + -2*X[i-1,1] - 3.5*X[i-1,2]))
   else
     value = c(runif(1,0,3), runif(1,0,3))


     prob = c(1,value)/(1 + sum(value)) ## compute probs with baseline state probability
     y[i] = sample(alphabet,1,prob=prob)
    
 }
  
 fit = VLMCX(y, X, alpha.level = 0.001, max.depth = 4, n.min = 15, trace = TRUE)
 draw(fit) 
 ## Note the only context that was estimated but not in the true 
 ## model is (1): removing it or not does not change the likelihood, 
 ## so the algorithm keeps it.
 coef(fit, c(0,2))

 predict(fit,new.y = c(0,0), new.X = matrix(c(1,1,1,1), nrow=2))
 #[1] 0.2259747309 0.7738175143 0.0002077548

 predict(fit,new.y = c(0,0,0), new.X = matrix(c(1,1,1,1,1,1), nrow=3))
 # [1] 0.2259747309 0.7738175143 0.0002077548


 #### Example 2

 set.seed(1)
 n = 2000
 d = 1

 X = rnorm(n)
 alphabet = 0:1
 y = sample(alphabet,2, replace = TRUE)
 for (i in 3:n)
 {
   if (identical(as.numeric(y[(i-1):(i-3)]), c(0,0, 0)))
     value =  c(exp(-0.5 -1*X[i-1]  + 2*X[i-2]))
   else if (identical(as.numeric(y[(i-1):(i-3)]), c(0, 0, 1)))
     value = c(exp(-0.5))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(1,0)))
     value = c(exp(0.5 + 1.2*X[i-1] + 2*X[i-2] ))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(1,1)))
     value  = c(exp(-1 + -X[i-1] +2*X[i-2]))
   else
     value = c(runif(1,0,3))

     prob = c(1,value)/(1 + sum(value)) ## compute probs with baseline state probability
     y[i] = sample(alphabet,1,prob=prob)
 }
 fit = VLMCX(y, X, alpha.level = 0.001, max.depth = 4, n.min = 15, trace = TRUE)
 draw(fit) 
 coef(fit, c(1,0))



 #### Example 3

 set.seed(1)
 n = 4000
 d = 1

 X = cbind(rnorm(n))
 alphabet = 0:3
 y = sample(alphabet,2, replace = TRUE)
 for (i in 3:n)
 {
   if (identical(as.numeric(y[(i-1):(i-2)]), c(3, 3)))
     value =  c(exp(-0.5 -1*X[i-1] + 2.5*X[i-2]),      
            exp(0.5 -2*X[i-1] - 3.5*X[i-2]),
            exp(0.5 +2*X[i-1] + 3.5*X[i-2]))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(3, 1)))
     value = c(exp(-0.5 + X[i-1]),     
               exp(0.5 -1.4*X[i-1]), 
               exp(0.9 +1.4*X[i-1]))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(1, 0)))
     value = c(exp(-.5),     
               exp(.5), 
               exp(.8))
   else if (identical(as.numeric(y[(i-1):(i-2)]), c(1, 2)))
     value = c(exp(.4),     
               exp(-.5),
               exp(.8))
   else
     value = c(runif(1,0,3), runif(1,0,3), runif(1,0,3))


     prob = c(1,value)/(1 + sum(value)) ## compute probs with baseline state probability
     y[i] = sample(alphabet,1,prob=prob)
    
 }
  
 fit = VLMCX(y, X, alpha.level = 0.00001, max.depth = 3, n.min = 15, trace = TRUE)
 ## The context (0, 1) was not identified because the 
 draw(fit) 
 coef(fit, c(3,1))




</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
