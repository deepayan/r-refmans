<!DOCTYPE html><html><head><title>Help for package fairness</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fairness}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#acc_parity'><p>Accuracy parity</p></a></li>
<li><a href='#compas'><p>Modified COMPAS dataset</p></a></li>
<li><a href='#dem_parity'><p>Demographic parity</p></a></li>
<li><a href='#equal_odds'><p>Equalized Odds</p></a></li>
<li><a href='#fairness'><p>fairness: Algorithmic Fairness Metrics</p></a></li>
<li><a href='#fnr_parity'><p>False Negative Rate parity</p></a></li>
<li><a href='#fpr_parity'><p>False Positive Rate parity</p></a></li>
<li><a href='#germancredit'><p>Modified german credit dataset</p></a></li>
<li><a href='#mcc_parity'><p>Matthews Correlation Coefficient parity</p></a></li>
<li><a href='#npv_parity'><p>Negative Predictive Value parity</p></a></li>
<li><a href='#pred_rate_parity'><p>Predictive Rate Parity</p></a></li>
<li><a href='#prop_parity'><p>Proportional parity</p></a></li>
<li><a href='#roc_parity'><p>ROC AUC parity</p></a></li>
<li><a href='#spec_parity'><p>Specificity parity</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Algorithmic Fairness Metrics</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nikita Kozodoi &lt;n.kozodoi@icloud.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Offers calculation, visualization and comparison of algorithmic fairness metrics. Fair machine learning is an emerging topic with the overarching aim to critically assess whether ML algorithms reinforce existing social biases. Unfair algorithms can propagate such biases and produce predictions with a disparate impact on various sensitive groups of individuals (defined by sex, gender, ethnicity, religion, income, socioeconomic status, physical or mental disabilities). Fair algorithms possess the underlying foundation that these groups should be treated similarly or have similar prediction outcomes. The fairness R package offers the calculation and comparisons of commonly and less commonly used fairness metrics in population subgroups. These methods are described by Calders and Verwer (2010) &lt;<a href="https://doi.org/10.1007%2Fs10618-010-0190-x">doi:10.1007/s10618-010-0190-x</a>&gt;, Chouldechova (2017) &lt;<a href="https://doi.org/10.1089%2Fbig.2016.0047">doi:10.1089/big.2016.0047</a>&gt;, Feldman et al. (2015) &lt;<a href="https://doi.org/10.1145%2F2783258.2783311">doi:10.1145/2783258.2783311</a>&gt; , Friedler et al. (2018) &lt;<a href="https://doi.org/10.1145%2F3287560.3287589">doi:10.1145/3287560.3287589</a>&gt; and Zafar et al. (2017) &lt;<a href="https://doi.org/10.1145%2F3038912.3052660">doi:10.1145/3038912.3052660</a>&gt;. The package also offers convenient visualizations to help understand fairness metrics.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://kozodoi.me/r/fairness/packages/2020/05/01/fairness-tutorial.html">https://kozodoi.me/r/fairness/packages/2020/05/01/fairness-tutorial.html</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kozodoi/fairness/issues">https://github.com/kozodoi/fairness/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, devtools, e1071, ggplot2, pROC</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-04-14 14:39:30 UTC; kozodoi</td>
</tr>
<tr>
<td>Author:</td>
<td>Nikita Kozodoi [aut, cre],
  Tibor V. Varga <a href="https://orcid.org/0000-0002-2383-699X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-04-14 15:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='acc_parity'>Accuracy parity</h2><span id='topic+acc_parity'></span>

<h3>Description</h3>

<p>This function computes the Accuracy parity metric
</p>
<p>Formula: (TP + TN) / (TP + FP + TN + FN)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acc_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acc_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="acc_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="acc_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="acc_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="acc_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="acc_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="acc_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="acc_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="acc_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Accuracy parity metric as described by Friedler et al., 2018.
Accuracy metrics are calculated by the division of correctly predicted observations (the sum
of all true positives and true negatives) with the number of all predictions. In the returned
named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their accuracies are lower or higher compared to the reference group. Lower
accuracies will be reflected in numbers lower than 1 in the returned named vector, thus numbers
lower than 1 mean WORSE prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw accuracy metrics for all groups and metrics standardized for the base group (accuracy parity metric). Lower values compared to the reference group mean lower accuracies in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of Accuracy parity metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
acc_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
acc_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='compas'>Modified COMPAS dataset</h2><span id='topic+compas'></span>

<h3>Description</h3>

<p><code><a href="#topic+compas">compas</a></code> is a landmark dataset to study algorithmic (un)fairness. This data was used to
predict recidivism (whether a criminal will reoffend or not) in the USA. The tool was meant to overcome
human biases and offer an algorithmic, fair solution to predict recidivism in a diverse population.
However, the algorithm ended up propagating existing social biases and thus, offered an unfair algorithmic
solution to the problem. In this dataset, a model to predict recidivism has already been fit and predicted
probabilities and predicted status (yes/no) for recidivism have been concatenated to the original data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compas
</code></pre>


<h3>Format</h3>

<p>A data frame with 6172 rows and 9 variables:
</p>

<dl>
<dt>Two_yr_Recidivism</dt><dd><p>factor, yes/no for recidivism or no recidivism. This is the outcome or target in this dataset</p>
</dd>
<dt>Number_of_Priors</dt><dd><p>numeric, number of priors, normalized to mean = 0 and standard deviation = 1</p>
</dd>
<dt>Age_Above_FourtyFive</dt><dd><p>factor, yes/no for age above 45 years or not</p>
</dd>
<dt>Age_Below_TwentyFive</dt><dd><p>factor, yes/no for age below 25 years or not</p>
</dd>
<dt>Female</dt><dd><p>factor, female/male for gender</p>
</dd>
<dt>Misdemeanor</dt><dd><p>factor, yes/no for having recorded misdemeanor(s) or not</p>
</dd>
<dt>ethnicity</dt><dd><p>factor, Caucasian, African American, Asian, Hispanic, Native American or Other</p>
</dd>
<dt>probability</dt><dd><p>numeric, predicted probabilities for recidivism, ranges from 0 to 1</p>
</dd>
<dt>predicted</dt><dd><p>numeric, predicted values for recidivism, 0/1 for no/yes</p>
</dd>
</dl>



<h3>Source</h3>

<p>The dataset is downloaded from Kaggle <a href="https://www.kaggle.com/danofer/compass">https://www.kaggle.com/danofer/compass</a> and has undergone modifications (e.g. ethnicity was originally encoded using one-hot encoding, number or priors have been normalized, variables have been renamed, prediction model was fit and predicted probabilities and predicted status were concatenated to the original dataset).
</p>

<hr>
<h2 id='dem_parity'>Demographic parity</h2><span id='topic+dem_parity'></span>

<h3>Description</h3>

<p>This function computes the Demographic parity metric
</p>
<p>Formula: (TP + FP)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dem_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dem_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="dem_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="dem_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="dem_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="dem_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="dem_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="dem_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="dem_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="dem_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Demographic parity metric (also known as Statistical Parity, Equal Parity,
Equal Acceptance Rate or Independence) as described by Calders and Verwer 2010. Demographic parity is calculated
based on the comparison of the absolute number of all positively classified individuals in all subgroups of the data. In the returned
named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their proportion of positively predicted observations are lower or higher compared to the reference group. Lower
proportions will be reflected in numbers lower than 1 in the returned named vector.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Absolute number of positive classifications for all groups and metrics standardized for the base group (demographic parity metric). Lower values compared to the reference group mean lower number of positively predicted observations in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of Demographic parity metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
dem_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
dem_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='equal_odds'>Equalized Odds</h2><span id='topic+equal_odds'></span>

<h3>Description</h3>

<p>This function computes the Equalized Odds metric
</p>
<p>Formula: TP / (TP + FN)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equal_odds(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="equal_odds_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="equal_odds_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="equal_odds_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="equal_odds_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="equal_odds_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="equal_odds_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="equal_odds_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="equal_odds_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="equal_odds_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Equalized Odds metric (also known as Equal Opportunity, Positive Rate Parity or Separation). Equalized Odds are calculated
by the division of true positives with all positives (irrespective of predicted values). This metrics equals to
what is traditionally known as sensitivity. In the returned
named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their sensitivities are lower or higher compared to the reference group. Lower
sensitivities will be reflected in numbers lower than 1 in the returned named vector, thus numbers
lower than 1 mean WORSE prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw sensitivities for all groups and metrics standardized for the base group (equalized odds parity metric). Lower values compared to the reference group mean lower sensitivities in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of Equalized Odds metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
equal_odds(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
equal_odds(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='fairness'>fairness: Algorithmic Fairness Metrics</h2><span id='topic+fairness'></span>

<h3>Description</h3>

<p>The <strong>fairness</strong> package offers calculation, visualization and comparison of algorithmic fairness metrics. Fair machine learning is an emerging topic with the overarching aim to critically assess whether ML algorithms reinforce existing social biases. Unfair algorithms can propagate such biases and produce predictions with a disparate impact on various sensitive groups of individuals (defined by sex, gender, ethnicity, religion, income, socioeconomic status, physical or mental disabilities). Fair algorithms possess the underlying foundation that these groups should be treated similarly or have similar prediction outcomes. The <strong>fairness</strong> R package offers the calculation and comparisons of commonly and less commonly used fairness metrics in population subgroups. The package also offers convenient visualizations to help understand fairness metrics.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> fairness</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.5.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version:  </td><td style="text-align: left;"> 1.2.2</td>
</tr>
<tr>
 <td style="text-align: left;">
Date:  </td><td style="text-align: left;"> 2021-04-14</td>
</tr>
<tr>
 <td style="text-align: left;">
License:  </td><td style="text-align: left;"> MIT</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad:  </td><td style="text-align: left;"> Yes
</td>
</tr>

</table>



<h3>Author(s)</h3>


<ul>
<li><p> Nikita Kozodoi <a href="mailto:n.kozodoi@icloud.com">n.kozodoi@icloud.com</a>
</p>
</li>
<li><p> Tibor V. Varga <a href="mailto:tirgit@hotmail.com">tirgit@hotmail.com</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="https://github.com/kozodoi/fairness">https://github.com/kozodoi/fairness</a>
<a href="https://kozodoi.me/r/fairness/packages/2020/05/01/fairness-tutorial.html">https://kozodoi.me/r/fairness/packages/2020/05/01/fairness-tutorial.html</a>
</p>

<hr>
<h2 id='fnr_parity'>False Negative Rate parity</h2><span id='topic+fnr_parity'></span>

<h3>Description</h3>

<p>This function computes the False Negative Rate (FNR) parity metric
</p>
<p>Formula: FN / (TP + FN)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnr_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fnr_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="fnr_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="fnr_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="fnr_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="fnr_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="fnr_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="fnr_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="fnr_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="fnr_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the False Negative Rate (FNR) parity metric as described by Chouldechova 2017. False negative rates are calculated
by the division of false negatives with all positives (irrespective of predicted values). In the returned
named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their false negative rates are lower or higher compared to the reference group. Lower
false negative error rates will be reflected in numbers lower than 1 in the returned named vector, thus numbers
lower than 1 mean BETTER prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw false negative rates for all groups and metrics standardized for the base group (false negative rate parity metric). Lower values compared to the reference group mean lower false negative error rates in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of False Negative Rate parity metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
fnr_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
fnr_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='fpr_parity'>False Positive Rate parity</h2><span id='topic+fpr_parity'></span>

<h3>Description</h3>

<p>This function computes the False Positive Rate (FPR) parity metric
</p>
<p>Formula: FP / (TN + FP)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpr_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpr_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="fpr_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="fpr_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="fpr_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="fpr_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="fpr_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="fpr_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="fpr_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="fpr_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the False Positive Rate (FPR) parity metric as described by Chouldechova 2017. False positive rates are calculated
by the division of false positives with all negatives (irrespective of predicted values). In the returned
named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their false positive rates are lower or higher compared to the reference group. Lower
false positives error rates will be reflected in numbers lower than 1 in the returned named vector, thus numbers
lower than 1 mean BETTER prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw false positive rates for all groups and metrics standardized for the base group (false positive rate parity metric). Lower values compared to the reference group mean lower false positive error rates in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of False Positives Rate metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
fpr_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
fpr_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='germancredit'>Modified german credit dataset</h2><span id='topic+germancredit'></span>

<h3>Description</h3>

<p><code><a href="#topic+germancredit">germancredit</a></code> is a credit scoring data set that can be used to study algorithmic (un)fairness.
This data was used to predict defaults on consumer loans in the German market. In this dataset, a model
to predict default has already been fit and predicted probabilities and predicted status (yes/no)
for default have been concatenated to the original data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>germancredit
</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 rows and 23 variables:
</p>

<dl>
<dt>Account_status</dt><dd><p>factor, status of existing checking account</p>
</dd>
<dt>Duration</dt><dd><p>numeric, loan duration in month</p>
</dd>
<dt>Credit_history</dt><dd><p>factor, previous credit history</p>
</dd>
<dt>Purpose</dt><dd><p>factor, loan purpose</p>
</dd>
<dt>Amount</dt><dd><p>numeric, credit amount</p>
</dd>
<dt>Savings</dt><dd><p>factor, savings account/bonds</p>
</dd>
<dt>Employment</dt><dd><p>factor, present employment since</p>
</dd>
<dt>Installment_rate</dt><dd><p>numeric, installment rate in percentage of disposable income</p>
</dd>
<dt>Guarantors</dt><dd><p>factor, other debtors / guarantors</p>
</dd>
<dt>Resident_since</dt><dd><p>factor, present residence since</p>
</dd>
<dt>Property</dt><dd><p>factor, property</p>
</dd>
<dt>Age</dt><dd><p>numeric, age in years</p>
</dd>
<dt>Other_plans</dt><dd><p>factor, other installment plans </p>
</dd>
<dt>Housing</dt><dd><p>factor, housing</p>
</dd>
<dt>Num_credits</dt><dd><p>numeric, Number of existing credits at this bank</p>
</dd>
<dt>Job</dt><dd><p>factor, job</p>
</dd>
<dt>People_maintenance</dt><dd><p>numeric, number of people being liable to provide maintenance for</p>
</dd>
<dt>Phone</dt><dd><p>factor, telephone</p>
</dd>
<dt>Foreign</dt><dd><p>factor, foreign worker</p>
</dd>
<dt>BAD</dt><dd><p>factor, GOOD/BAD for whether a customer has defaulted on a loan. This is the outcome or target in this dataset</p>
</dd>
<dt>Female</dt><dd><p>factor, female/male for gender</p>
</dd>
<dt>probability</dt><dd><p>numeric, predicted probabilities for default, ranges from 0 to 1</p>
</dd>
<dt>predicted</dt><dd><p>numeric, predicted values for default, 0/1 for no/yes</p>
</dd>
</dl>



<h3>Source</h3>

<p>The dataset has undergone modifications (e.g. categorical variables were encoded, prediction model was fit and predicted probabilities and predicted status were concatenated to the original dataset).
</p>

<hr>
<h2 id='mcc_parity'>Matthews Correlation Coefficient parity</h2><span id='topic+mcc_parity'></span>

<h3>Description</h3>

<p>This function computes the Matthews Correlation Coefficient (MCC) parity metric
</p>
<p>Formula: (TP × TN - FP × FN) / sqrt((TP + FP) × (TP + FN) × (TN + FP) × (TN + FN))
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcc_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcc_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="mcc_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="mcc_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="mcc_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="mcc_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="mcc_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="mcc_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="mcc_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="mcc_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Matthews Correlation Coefficient (MCC) parity metric. In the returned
named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their Matthews Correlation Coefficients are lower or higher compared to the reference group. Lower
Matthews Correlation Coefficients rates will be reflected in numbers lower than 1 in the returned named vector, thus numbers
lower than 1 mean WORSE prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw Matthews Correlation Coefficient metrics for all groups and metrics standardized for the base group (parity metric). Lower values compared to the reference group mean Matthews Correlation Coefficients in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of Matthews Correlation Coefficient metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
mcc_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
mcc_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='npv_parity'>Negative Predictive Value parity</h2><span id='topic+npv_parity'></span>

<h3>Description</h3>

<p>This function computes the Negative Predictive Value (NPV) parity metric
</p>
<p>Formula: TN / (TN + FN)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npv_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npv_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="npv_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="npv_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="npv_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="npv_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="npv_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="npv_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="npv_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="npv_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Negative Predictive Value (NPV) parity metric as described by the Aequitas bias toolkit.
Negative Predictive Values are calculated
by the division of true negatives with all predicted negatives. In the returned
named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their negative predictive values are lower or higher compared to the reference group. Lower
negative predictive values will be reflected in numbers lower than 1 in the returned named vector, thus numbers
lower than 1 mean WORSE prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw negative predictive values for all groups and metrics standardized for the base group (negative predictive value parity metric). Lower values compared to the reference group mean lower negative predictive values in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of Negative Predictive Value metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
npv_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
npv_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='pred_rate_parity'>Predictive Rate Parity</h2><span id='topic+pred_rate_parity'></span>

<h3>Description</h3>

<p>This function computes the Predictive Rate Parity metric.
</p>
<p>Formula: TP / (TP + FP)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pred_rate_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pred_rate_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="pred_rate_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="pred_rate_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="pred_rate_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="pred_rate_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="pred_rate_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="pred_rate_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="pred_rate_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="pred_rate_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Predictive Rate Parity metric (also known as Sufficiency) as described by
Zafar et al., 2017. Predictive rate parity is calculated by the division of true positives with all
observations predicted positives. This metrics equals to what is traditionally known as precision
or positive predictive value. In the returned named vector, the reference group will be assigned 1,
while all other groups will be assigned values according to whether their precisions are lower or
higher compared to the reference group. Lower precisions will be reflected in numbers lower than 1
in the returned named vector, thus numbers lower than 1 mean WORSE prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw precision metrics for all groups and metrics standardized for the base group (predictive rate parity metric). Lower values compared to the reference group mean lower precisions in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of Predictive Rate Parity metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
pred_rate_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
pred_rate_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='prop_parity'>Proportional parity</h2><span id='topic+prop_parity'></span>

<h3>Description</h3>

<p>This function computes the Proportional parity metric
</p>
<p>Formula: (TP + FP) / (TP + FP + TN + FN)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prop_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prop_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="prop_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="prop_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="prop_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="prop_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="prop_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="prop_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="prop_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="prop_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Proportional parity metric (also known as Impact Parity or Minimizing Disparate Impact) as described by Calders and Verwer 2010.
Proportional parity is calculated based on the comparison of the proportion of all positively classified individuals in all subgroups of the data.
In the returned named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their proportion of positively predicted observations are lower or higher compared to the reference group. Lower
proportions will be reflected in numbers lower than 1 in the returned named vector.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw proportions for all groups and metrics standardized for the base group (proportional parity metric). Lower values compared to the reference group mean lower proportion of positively predicted observations in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of Proportional parity metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
prop_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
prop_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

<hr>
<h2 id='roc_parity'>ROC AUC parity</h2><span id='topic+roc_parity'></span>

<h3>Description</h3>

<p>This function computes the ROC AUC parity metric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roc_parity(data, outcome, group, probs, base = NULL, group_breaks = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roc_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="roc_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="roc_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="roc_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1).</p>
</td></tr>
<tr><td><code id="roc_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="roc_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the ROC AUC values for each subgroup. In the returned table,
the reference group will be assigned 1, while all other groups will be assigned values
according to whether their ROC AUC values are lower or higher compared to the reference group. Lower
ROC AUC will be reflected in numbers lower than 1 in the returned named vector, thus numbers
lower than 1 mean WORSE prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw ROC AUC metrics for all groups and metrics standardized for the base group (parity metric). Lower values compared to the reference group mean lower ROC AUC values in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of ROC AUC metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup</p>
</td></tr>
<tr><td><code>ROCAUC_plot</code></td>
<td>
<p>ROC plots for all subgroups</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
roc_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', base = 'Caucasian')
roc_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', base = 'African_American')

</code></pre>

<hr>
<h2 id='spec_parity'>Specificity parity</h2><span id='topic+spec_parity'></span>

<h3>Description</h3>

<p>This function computes the Specificity parity metric
</p>
<p>Formula: TN / (TN + FP)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spec_parity(
  data,
  outcome,
  group,
  probs = NULL,
  preds = NULL,
  outcome_base = NULL,
  cutoff = 0.5,
  base = NULL,
  group_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spec_parity_+3A_data">data</code></td>
<td>
<p>Data.frame that contains the necessary columns.</p>
</td></tr>
<tr><td><code id="spec_parity_+3A_outcome">outcome</code></td>
<td>
<p>Column name indicating the binary outcome variable (character).</p>
</td></tr>
<tr><td><code id="spec_parity_+3A_group">group</code></td>
<td>
<p>Column name indicating the sensitive group (character).</p>
</td></tr>
<tr><td><code id="spec_parity_+3A_probs">probs</code></td>
<td>
<p>Column name or vector with the predicted probabilities (numeric between 0 - 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="spec_parity_+3A_preds">preds</code></td>
<td>
<p>Column name or vector with the predicted binary outcome (0 or 1). Either probs or preds need to be supplied.</p>
</td></tr>
<tr><td><code id="spec_parity_+3A_outcome_base">outcome_base</code></td>
<td>
<p>Base level of the outcome variable (i.e., negative class). Default is the first level of the outcome variable.</p>
</td></tr>
<tr><td><code id="spec_parity_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff to generate predicted outcomes from predicted probabilities. Default set to 0.5.</p>
</td></tr>
<tr><td><code id="spec_parity_+3A_base">base</code></td>
<td>
<p>Base level of the sensitive group (character).</p>
</td></tr>
<tr><td><code id="spec_parity_+3A_group_breaks">group_breaks</code></td>
<td>
<p>If group is continuous (e.g., age): either a numeric vector of two or more unique cut points or a single number &gt;= 2 giving the number of intervals into which group feature is to be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Specificity parity metric. Specificities are calculated
by the division of true negatives with all negatives (irrespective of predicted values). In the returned
named vector, the reference group will be assigned 1, while all other groups will be assigned values
according to whether their specificities are lower or higher compared to the reference group. Lower
specificities will be reflected in numbers lower than 1 in the returned named vector, thus numbers
lower than 1 mean WORSE prediction for the subgroup.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Metric</code></td>
<td>
<p>Raw specificity metrics for all groups and metrics standardized for the base group (specificity parity metric). Lower values compared to the reference group mean lower specificities in the selected subgroups</p>
</td></tr>
<tr><td><code>Metric_plot</code></td>
<td>
<p>Bar plot of Specificity parity metric</p>
</td></tr>
<tr><td><code>Probability_plot</code></td>
<td>
<p>Density plot of predicted probabilities per subgroup. Only plotted if probabilities are defined</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(compas)
compas$Two_yr_Recidivism_01 &lt;- ifelse(compas$Two_yr_Recidivism == 'yes', 1, 0) 
spec_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
probs = 'probability', cutoff = 0.4, base = 'Caucasian')
spec_parity(data = compas, outcome = 'Two_yr_Recidivism_01', group = 'ethnicity',
preds = 'predicted', cutoff = 0.5, base = 'Hispanic')

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
