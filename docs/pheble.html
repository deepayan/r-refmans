<!DOCTYPE html><html lang="en"><head><title>Help for package pheble</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pheble}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Global+20variables.'><p>Global variables.</p></a></li>
<li><a href='#ph_anomaly'><p>Detect anomalies.</p></a></li>
<li><a href='#ph_crocs'><p>Data from: The utility of cranial ontogeny for phylogenetic inference: a case study in crocodylians using geometric morphometrics</p></a></li>
<li><a href='#ph_ctrl'><p>Parameters for resampling and training a dataset.</p></a></li>
<li><a href='#ph_ensemble'><p>Classify phenotypes via ensemble learning.</p></a></li>
<li><a href='#ph_equate'><p>Equate factors levels.</p></a></li>
<li><a href='#ph_eval'><p>Evaluate a phenotype classification model.</p></a></li>
<li><a href='#ph_iqr'><p>Compute interquartile range.</p></a></li>
<li><a href='#ph_outs'><p>Find outlier indices.</p></a></li>
<li><a href='#ph_prep'><p>Preprocessing for phenotype classification via ensemble learning.</p></a></li>
<li><a href='#ph_stickleback'><p>Data from: Sexually mediated phenotypic variation within and between sexes as a continuum structured by ecology: The mosaic nature of skeletal variation across body regions in Threespine stickleback (Gasterosteus aculeatus L.)</p></a></li>
<li><a href='#ph_train'><p>Generate predictions for phenotype ensemble.</p></a></li>
<li><a href='#reexports'><p>Pipe.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Classifying High-Dimensional Phenotypes with Ensemble Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A system for binary and multi-class classification of
    high-dimensional phenotypic data using ensemble learning. By combining
    predictions from different classification models, this package attempts
    to improve performance over individual learners. The pre-processing,
    training, validation, and testing are performed end-to-end to minimize
    user input and simplify the process of classification.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>adabag, base, C50, caret, caTools, data.table, doParallel,
dplyr, e1071, earth, evtree, frbs, glmnet, gmodels, hda,
HDclassif, ipred, kernlab, kknn, klaR, magrittr, MASS, Matrix,
mda, MLmetrics, nnet, parallel, party, pls, randomForest,
rpartScore, sparseLDA, stats, themis, utils</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>h2o</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-16 20:35:33 UTC; bhlab</td>
</tr>
<tr>
<td>Author:</td>
<td>Jay Devine [aut, cre, cph],
  Bened'ikt Hallgrimsson [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jay Devine &lt;jay.devine1@ucalgary.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-17 08:50:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='Global+20variables.'>Global variables.</h2><span id='topic+Global+20variables.'></span>

<h3>Description</h3>

<p>Global variables.
</p>

<hr>
<h2 id='ph_anomaly'>Detect anomalies.</h2><span id='topic+ph_anomaly'></span>

<h3>Description</h3>

<p>The <code>ph_anomaly</code> function detects and removes anomalies with an autoencoder. Because it is general
purpose, it can be applied to a variety of data types. The parameters in this function (e.g., activation,
hidden, dropout_ratio) can be supplied as lists or vectors (see parameter details) to perform a grid search
for the optimal hyperparameter combination. The autoencoder with the lowest reconstruction error is selected as
the best model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_anomaly(
  df,
  ids_col,
  class_col,
  method = "ae",
  scale = FALSE,
  center = NULL,
  sd = NULL,
  max_mem_size = "15g",
  port = 54321,
  train_seed = 123,
  hyper_params = list(),
  search = "random",
  tune_length = 100
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_anomaly_+3A_df">df</code></td>
<td>
<p>A <code>data.frame</code> containing a column of ids, a column of classes, and an arbitrary number of predictors.</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_ids_col">ids_col</code></td>
<td>
<p>A <code>character</code> value for the name of the ids column.</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_class_col">class_col</code></td>
<td>
<p>A <code>character</code> value for the name of the class column.</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_method">method</code></td>
<td>
<p>A <code>character</code> value for the anomaly detection method: &quot;ae&quot; (default), &quot;iso&quot; (abbv. for extended isolation forest).</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_scale">scale</code></td>
<td>
<p>A <code>logical</code> value for whether to scale the data: FALSE (default). Recommended if <code>method = "ae"</code> and if user intends to train other models.</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_center">center</code></td>
<td>
<p>Either a <code>logical</code> value or numeric-alike vector of length equal to the number of columns of data to scale in <code>df</code>, where ‘numeric-alike’ means that as.numeric(.) will be applied successfully if is.numeric(.) is not true: NULL (default). If <code>scale = TRUE</code>, this is set to <code>TRUE</code> and is used to subtract the mean.</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_sd">sd</code></td>
<td>
<p>Either a <code>logical</code> value or a numeric-alike vector of length equal to the number of columns of data to scale in <code>df</code>: NULL (default). If <code>scale = TRUE</code>, this is set to <code>TRUE</code> and is used to divide by the standard deviation.</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_max_mem_size">max_mem_size</code></td>
<td>
<p>A <code>character</code> value for the memory of an h2o session: &quot;15g&quot; (default).</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_port">port</code></td>
<td>
<p>A <code>numeric</code> value for the port number of the H2O server.</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_train_seed">train_seed</code></td>
<td>
<p>A <code>numeric</code> value to set the control the randomness of creating resamples: 123 (default).</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_hyper_params">hyper_params</code></td>
<td>
<p>A <code>list</code> of hyperparameters to perform a grid search.
</p>

<ul>
<li><p> If <code>method = "ae"</code>, the &quot;default&quot; list is: list(missing_values_handling = &quot;Skip&quot;, activation = c(&quot;Rectifier&quot;, &quot;Tanh&quot;), hidden = list(5, 25, 50, 100, 250, 500, nrow(df_h2o)), input_dropout_ratio = c(0, 0.1, 0.2, 0.3), rate = c(0, 0.01, 0.005, 0.001))
</p>
</li>
<li><p> If <code>method = "iso"</code>, the &quot;default&quot; list is: list(ntrees = c(50, 100, 150, 200), sample_size = c(64, 128, 256, 512))
</p>
</li></ul>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_search">search</code></td>
<td>
<p>A <code>character</code> value for the hyperparameter search strategy: &quot;random&quot; (default), &quot;grid&quot;.</p>
</td></tr>
<tr><td><code id="ph_anomaly_+3A_tune_length">tune_length</code></td>
<td>
<p>A <code>numeric</code> value (integer) for either the maximum number of hyperparameter combinations (&quot;random&quot;) or individual hyperparameter depth (&quot;grid&quot;): 100 (default).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:</p>

<table>
<tr>
 <td style="text-align: left;">
<code>df</code> </td><td style="text-align: left;"> The data frame with anomalies removed. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>model</code> </td><td style="text-align: left;"> The best model from the grid search used to detect anomalies. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>anom_score</code> </td><td style="text-align: left;"> A data frame of predicted anomaly scores. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>## Import data.
data(ph_crocs)

## Remove anomalies with autoencoder.
rm_outs &lt;- ph_anomaly(df = ph_crocs, ids_col = "Biosample",
                      class_col = "Species", method = "ae")
## Alternatively, remove anomalies with extended isolation forest. Notice
## that port is defined, because running H2O sessions one after another
## can return connection errors.
rm_outs &lt;- ph_anomaly(df = ph_crocs, ids_col = "Biosample",
                      class_col = "Species", method = "iso",
                      port = 50001)

</code></pre>

<hr>
<h2 id='ph_crocs'>Data from: The utility of cranial ontogeny for phylogenetic inference: a case study in crocodylians using geometric morphometrics</h2><span id='topic+ph_crocs'></span>

<h3>Description</h3>

<p>Abstract: The degree to which the ontogeny of organisms could facilitate our understanding of phylogenetic relationships
has long been a subject of contention in evolutionary biology. The famed notion that ‘ontogeny recapitulates phylogeny’ has
been largely discredited, but there remains an expectation that closely related organisms undergo similar morphological
transformations throughout ontogeny. To test this assumption, we used three-dimensional geometric morphometric methods to
characterize the cranial morphology of 10 extant crocodylian species and construct allometric trajectories that model the
post-natal ontogenetic shape changes. Using time-calibrated molecular and morphological trees, we employed a suite of
comparative phylogenetic methods to assess the extent of phylogenetic signal in these trajectories. All analyses largely
demonstrated a lack of significant phylogenetic signal, indicating that ontogenetic shape changes contain little phylogenetic
information. Notably, some Mantel tests yielded marginally significant results when analysed with the morphological tree,
which suggest that the underlying signal in these trajectories is correlated with similarities in the adult cranial morphology.
However, despite these instances, all other analyses, including more powerful tests for phylogenetic signal, recovered
statistical and visual evidence against the assumption that similarities in ontogenetic shape changes are commensurate with
phylogenetic relatedness and thus bring into question the efficacy of using allometric trajectories for phylogenetic inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_crocs
</code></pre>


<h3>Format</h3>



<h4><code>ph_crocs</code></h4>

<p>A data frame of Procrustes superimposed shape data with 183 rows and 236 columns:
</p>

<dl>
<dt>Biosample</dt><dd><p>Biosample</p>
</dd>
<dt>Species</dt><dd><p>Species</p>
</dd>
</dl>
<p>...

</p>



<h3>Source</h3>

<p>Downloaded from
<\doi{dx.doi.org/10.5061/dryad.14fn1}>
</p>

<hr>
<h2 id='ph_ctrl'>Parameters for resampling and training a dataset.</h2><span id='topic+ph_ctrl'></span>

<h3>Description</h3>

<p>The <code>ph_ctrl</code> function automatically generates a <code>trControl</code> object. This can be used in the <code>train</code>
function to automatically tune hyperparameters for every classification model in the ensemble.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_ctrl(
  class,
  resample_method = "boot",
  number = ifelse(grepl("cv", resample_method, ignore.case = TRUE), 10, 25),
  repeats = ifelse(grepl("dcv$", resample_method, ignore.case = TRUE), 3, NA),
  search = "random",
  sampling = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_ctrl_+3A_class">class</code></td>
<td>
<p>A <code>factor</code> value for training data classes.</p>
</td></tr>
<tr><td><code id="ph_ctrl_+3A_resample_method">resample_method</code></td>
<td>
<p>A <code>character</code> value for the resampling training method: &quot;boot&quot; (default), &quot;cv&quot;, LOOCV&quot;, &quot;repeatedcv&quot;.</p>
</td></tr>
<tr><td><code id="ph_ctrl_+3A_number">number</code></td>
<td>
<p>An <code>integer</code> value for the number of resampling iterations (25 default for boot) or folds (10 default for cross-validation).</p>
</td></tr>
<tr><td><code id="ph_ctrl_+3A_repeats">repeats</code></td>
<td>
<p>An <code>integer</code> value for the number of sets of folds for repeated cross-validation.</p>
</td></tr>
<tr><td><code id="ph_ctrl_+3A_search">search</code></td>
<td>
<p>A <code>character</code> value for the hyperparameter search strategy: &quot;random&quot; (default), &quot;grid&quot;.</p>
</td></tr>
<tr><td><code id="ph_ctrl_+3A_sampling">sampling</code></td>
<td>
<p>A <code>character</code> value for the sampling strategy, sometimes used to fix class imbalances: <code>NULL</code> (default), &quot;up&quot;, &quot;down&quot;, &quot;smote&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>trainControl</code> object for the <code>train</code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Import data.
data(ph_crocs)
## Echo control object for train function.
ctrl &lt;- ph_ctrl(ph_crocs$Species, resample_method = "boot")
</code></pre>

<hr>
<h2 id='ph_ensemble'>Classify phenotypes via ensemble learning.</h2><span id='topic+ph_ensemble'></span>

<h3>Description</h3>

<p>The <code>ph_ensemble</code> function uses classification predictions from a list of algorithms to train an ensemble model.
This can be a list of manually trained algorithms from <code>train</code> or, more conveniently, the output from <code>ph_train</code>.
The hyperparameter tuning and model evaluations are handled internally to simplify the ensembling process. This function
assumes some preprocessing has been performed, hence the training, validation, and test set requirements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_ensemble(
  train_models,
  train_df,
  vali_df,
  test_df,
  class_col,
  ctrl,
  train_seed = 123,
  n_cores = 2,
  task = "multi",
  metric = ifelse(task == "multi", "Kappa", "ROC"),
  top_models = 3,
  metalearner = ifelse(task == "multi", "glmnet", "rf"),
  tune_length = 10,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_ensemble_+3A_train_models">train_models</code></td>
<td>
<p>A <code>list</code> of at least two <code>train</code> models.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_train_df">train_df</code></td>
<td>
<p>A <code>data.frame</code> containing a class column and the training data.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_vali_df">vali_df</code></td>
<td>
<p>A <code>data.frame</code> containing a class column and the validation data.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_test_df">test_df</code></td>
<td>
<p>A <code>data.frame</code> containing a class column and the test data.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_class_col">class_col</code></td>
<td>
<p>A <code>character</code> value for the name of the class column. This should be consistent across data frames.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_ctrl">ctrl</code></td>
<td>
<p>A <code>list</code> containing the resampling strategy (e.g., &quot;boot&quot;) and other parameters for <code>trainControl</code>. Automatically create one via <code>ph_ctrl</code> or manually create it with <code>trainControl</code>.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_train_seed">train_seed</code></td>
<td>
<p>A <code>numeric</code> value to set the training seed and control the randomness of creating resamples: 123 (default).</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_n_cores">n_cores</code></td>
<td>
<p>An <code>integer</code> value for the number of cores to include in the cluster: 2 (default). We highly recommend increasing this value to, e.g., parallel::detectCores() - 1.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_task">task</code></td>
<td>
<p>A <code>character</code> value for the type of classification <code>task</code>: &quot;multi&quot; (default), &quot;binary&quot;.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_metric">metric</code></td>
<td>
<p>A <code>character</code> value for which summary metric should be used to select the optimal model: &quot;ROC&quot; (default for &quot;binary&quot;) and &quot;Kappa&quot; (default for &quot;multi&quot;). Other options include &quot;logLoss&quot;, &quot;Accuracy&quot;, &quot;Mean_Balanced_Accuracy&quot;, and &quot;Mean_F1&quot;.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_top_models">top_models</code></td>
<td>
<p>A <code>numeric</code> value for the top n training models to ensemble: 3 (default). Every training model is ordered according to their final metric value (e.g., &quot;ROC&quot; or &quot;Kappa&quot;) and the top n models are selected.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_metalearner">metalearner</code></td>
<td>
<p>A <code>character</code> value for the algorithm used to train the ensemble: &quot;glmnet&quot; (default), &quot;rf&quot;. Other methods, such as those listed in ph_train methods, may also be used.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_tune_length">tune_length</code></td>
<td>
<p>If <code>search = "random"</code> (default), this is an <code>integer</code> value for the maximum number of hyperparameter combinations to test for each training model in the ensemble; if <code>search = "grid"</code>, this is an <code>integer</code> value for the number of levels of each hyperparameter to test for each model.</p>
</td></tr>
<tr><td><code id="ph_ensemble_+3A_quiet">quiet</code></td>
<td>
<p>A <code>logical</code> value for whether progress should be printed: TRUE (default), FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:</p>

<table>
<tr>
 <td style="text-align: left;">
<code>ensemble_test_preds</code> </td><td style="text-align: left;"> The ensemble predictions for the test set. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>vali_preds</code> </td><td style="text-align: left;"> The validation predictions for the top models. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>test_preds</code> </td><td style="text-align: left;"> The test predictions for the top models. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>all_test_preds</code> </td><td style="text-align: left;"> The test predictions for every successfully trained model. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>all_test_results</code> </td><td style="text-align: left;"> The confusion matrix results obtained from comparing the model test predictions (i.e., original models and ensemble) against the actual test classes.  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ensemble_model</code> </td><td style="text-align: left;"> The ensemble <code>train</code> object. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>var_imps</code> </td><td style="text-align: left;"> The ensemble variable importances obtained via weighted averaging. The original train importances are multiplied by the model's importance in the ensemble, then averaged across models and normalized.  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>train_df</code> </td><td style="text-align: left;"> The training data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>vali_df</code> </td><td style="text-align: left;"> The validation data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>test_df</code> </td><td style="text-align: left;"> The test data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>train_models</code> </td><td style="text-align: left;"> The <code>train</code> models for the ensemble. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ctrl</code> </td><td style="text-align: left;"> A <code>trainControl</code> object. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>metric</code> </td><td style="text-align: left;"> The summary metric used to select the optimal model. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>task</code> </td><td style="text-align: left;"> The type of classification task. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>tune_length</code> </td><td style="text-align: left;"> The maximum number of hyperparameter combinations ("random") or individual hyperparameter depth ("grid").  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>top_models</code> </td><td style="text-align: left;"> The number of top methods selected for the ensemble.  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>metalearner</code> </td><td style="text-align: left;"> The algorithm used to train the ensemble. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>## Import data.
data(ph_crocs)

## Remove anomalies with autoencoder.
rm_outs &lt;- ph_anomaly(df = ph_crocs, ids_col = "Biosample",
                      class_col = "Species", method = "ae")
## Preprocess anomaly-free data frame into train, validation, and test sets
## with PCs as predictors.
pc_dfs &lt;- ph_prep(df = rm_outs$df, ids_col = "Biosample",
                  class_col = "Species", vali_pct = 0.15,
                  test_pct = 0.15, method = "pca")
## Echo control object for train function.
ctrl &lt;- ph_ctrl(ph_crocs$Species, resample_method = "boot")
## Train all models for ensemble.
## Note: Increasing n_cores will dramatically reduce train time.
train_models &lt;- ph_train(train_df = pc_dfs$train_df,
                         vali_df = pc_dfs$vali_df,
                         test_df = pc_dfs$test_df,
                         class_col = "Species",
                         ctrl = ctrl,
                         task = "multi",
                         methods = "all",
                         tune_length = 5,
                         quiet = FALSE)
## You can also train just a few, although more is preferable.
## Note: Increasing n_cores will dramatically reduce train time.
train_models &lt;- ph_train(train_df = pc_dfs$train_df,
                         vali_df = pc_dfs$vali_df,
                         test_df = pc_dfs$test_df,
                         class_col = "Species",
                         ctrl = ctrl,
                         task = "multi",
                         methods = c("lda", "mda",
                         "nnet", "pda", "sparseLDA"),
                         tune_length = 5,
                         quiet = FALSE)
## Train the ensemble.
## Note: Increasing n_cores will dramatically reduce train time.
ensemble_model &lt;- ph_ensemble(train_models = train_models$train_models,
                              train_df = pc_dfs$train_df,
                              vali_df = pc_dfs$vali_df,
                              test_df = pc_dfs$test_df,
                              class_col = "Species",
                              ctrl = ctrl,
                              task = "multi",
                              top_models = 3,
                              metalearner = "glmnet",
                              tune_length = 25,
                              quiet = FALSE)

</code></pre>

<hr>
<h2 id='ph_equate'>Equate factors levels.</h2><span id='topic+ph_equate'></span>

<h3>Description</h3>

<p>The <code>ph_equate</code> function ensures that the factor levels in all columns are equal. When classification are heavily biased or inaccurate, they can return new class predictions that do not contain every level in the original data. This can interfere with model evaluation functions e.g. via a confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_equate(df, class)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_equate_+3A_df">df</code></td>
<td>
<p>A <code>data.frame</code> of column-wise class predictions.</p>
</td></tr>
<tr><td><code id="ph_equate_+3A_class">class</code></td>
<td>
<p>A <code>factor</code> value for the observed or classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of column-wise class predictions with class levels equal to the observed class.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Make data frame of predicted classes with different levels.
## An internal or external column should contain the observed
## classes with every possible level.
obs &lt;- as.factor(c("A", "C", "B", "D", "E"))
method_a &lt;- c("A", "B", "B", "C", "D")
method_b &lt;- c("A", "C", "B", "D", "C")
method_c &lt;- c("A", "C", "B", "B", "C")
df &lt;- data.frame(method_a, method_b, method_c)
df &lt;- ph_equate(df = df, class = obs)
</code></pre>

<hr>
<h2 id='ph_eval'>Evaluate a phenotype classification model.</h2><span id='topic+ph_eval'></span>

<h3>Description</h3>

<p>The <code>ph_eval</code> function generates a confusion matrix for binary or multi-class classification; for the multi-class case, the results are averaged across all class levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_eval(pred, obs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_eval_+3A_pred">pred</code></td>
<td>
<p>A <code>factor</code> value of predicted classes.</p>
</td></tr>
<tr><td><code id="ph_eval_+3A_obs">obs</code></td>
<td>
<p>A <code>factor</code> value of the observed or actual classes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> of confusion matrix evaluation results; for the multi-class case, the results are averaged across all class levels.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Import data.
data(ph_crocs)

## Remove anomalies with autoencoder.
rm_outs &lt;- ph_anomaly(df = ph_crocs, ids_col = "Biosample",
                      class_col = "Species", method = "ae")
## Preprocess anomaly-free data frame into train, validation, and test sets
## with PCs as predictors.
pc_dfs &lt;- ph_prep(df = rm_outs$df, ids_col = "Biosample",
                  class_col = "Species", vali_pct = 0.15,
                  test_pct = 0.15, method = "pca")
## Echo control object for train function.
ctrl &lt;- ph_ctrl(ph_crocs$Species, resample_method = "boot")
## Train a few models for ensemble, although more is preferable.
## Note: Increasing n_cores will dramatically reduce train time.
train_models &lt;- ph_train(train_df = pc_dfs$train_df,
                         vali_df = pc_dfs$vali_df,
                         test_df = pc_dfs$test_df,
                         class_col = "Species",
                         ctrl = ctrl,
                         task = "multi",
                         methods = c("lda", "mda",
                         "nnet", "pda", "sparseLDA"),
                         tune_length = 5,
                         quiet = FALSE)
## Evaluate e.g. the first model.
test_pred &lt;- predict(train_models$train_models[[1]], pc_dfs$test_df)
test_obs &lt;- as.factor(pc_dfs$test_df$Species)
test_cm &lt;- ph_eval(pred = test_pred, obs = test_obs)

</code></pre>

<hr>
<h2 id='ph_iqr'>Compute interquartile range.</h2><span id='topic+ph_iqr'></span>

<h3>Description</h3>

<p>The <code>ph_iqr</code> function computes the interquartile range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_iqr(x, na.rm = FALSE, type = 7)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_iqr_+3A_x">x</code></td>
<td>
<p>A <code>numeric</code> vector.</p>
</td></tr>
<tr><td><code id="ph_iqr_+3A_na.rm">na.rm</code></td>
<td>
<p>A <code>logical</code> value: FALSE (default). If true, any NA is removed before quantiles are computed.</p>
</td></tr>
<tr><td><code id="ph_iqr_+3A_type">type</code></td>
<td>
<p>An <code>integer</code> value (1:9) selecting one of 9 quantile algorithms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The interquartile range.
</p>

<hr>
<h2 id='ph_outs'>Find outlier indices.</h2><span id='topic+ph_outs'></span>

<h3>Description</h3>

<p>The <code>ph_outs</code> function computes outliers with the interquartile method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_outs(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_outs_+3A_x">x</code></td>
<td>
<p>A <code>numeric</code> vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The outlier indices.
</p>

<hr>
<h2 id='ph_prep'>Preprocessing for phenotype classification via ensemble learning.</h2><span id='topic+ph_prep'></span>

<h3>Description</h3>

<p>The <code>ph_prep</code> function splits a data frame into training, validation, and test sets, all while ensuring that
every class is represented in each dataset. By default, it performs a Principal Component Analysis on the training
set data and projects the validation and test data into that space. If a non-linear dimensionality reduction
strategy is preferred instead, an autoencoder can be used to extract deep features. Note that the parameters
<code>max_mem_size</code>, <code>activation</code>, <code>hidden</code>, <code>dropout_ratio</code>, <code>rate</code>, <code>search</code>, and
<code>tune_length</code> are <code>NULL</code> unless an autoencoder, <code>method = "ae"</code>, is used. In this case,
lists or vectors can be supplied to these parameters (see parameter details) to perform a grid search for the
optimal hyperparameter combination. The autoencoder with the lowest reconstruction error is selected as
the best model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_prep(
  df,
  ids_col,
  class_col,
  vali_pct = 0.15,
  test_pct = 0.15,
  scale = FALSE,
  center = NULL,
  sd = NULL,
  split_seed = 123,
  method = "pca",
  pca_pct = 0.95,
  max_mem_size = "15g",
  port = 54321,
  train_seed = 123,
  hyper_params = list(),
  search = "random",
  tune_length = 100
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_prep_+3A_df">df</code></td>
<td>
<p>A <code>data.frame</code> containing a column of unique ids, a column of classes, and an arbitrary number of <code>numeric</code> columns.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_ids_col">ids_col</code></td>
<td>
<p>A <code>character</code> value for the name of the ids column.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_class_col">class_col</code></td>
<td>
<p>A <code>character</code> value for the name of the class column.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_vali_pct">vali_pct</code></td>
<td>
<p>A <code>numeric</code> value for the percentage of training data to use as validation data: 0.15 (default).</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_test_pct">test_pct</code></td>
<td>
<p>A <code>numeric</code> value for the percentage of total data to use as test data: 0.15 (default).</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_scale">scale</code></td>
<td>
<p>A <code>logical</code> value for whether to scale the data: FALSE (default). Recommended if <code>method = "ae"</code> and if user intends to train other models.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_center">center</code></td>
<td>
<p>Either a <code>logical</code> value or numeric-alike vector of length equal to the number of columns of data to scale in <code>df</code>, where ‘numeric-alike’ means that as.numeric(.) will be applied successfully if is.numeric(.) is not true: NULL (default). If <code>scale = TRUE</code>, this is set to <code>TRUE</code> and is used to subtract the mean.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_sd">sd</code></td>
<td>
<p>Either a <code>logical</code> value or a numeric-alike vector of length equal to the number of columns of data to scale in <code>df</code>: NULL (default). If <code>scale = TRUE</code>, this is set to <code>TRUE</code> and is used to divide by the standard deviation.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_split_seed">split_seed</code></td>
<td>
<p>A <code>numeric</code> value to set the seed and control the randomness of splitting the data: 123 (default).</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_method">method</code></td>
<td>
<p>A <code>character</code> value for the dimensionality reduction method: &quot;pca&quot; (default), &quot;ae&quot;, &quot;none&quot;.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_pca_pct">pca_pct</code></td>
<td>
<p>If <code>method = "pca"</code>, a <code>numeric</code> value for the proportion of variance to subset the PCA with: 0.95 (default).</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_max_mem_size">max_mem_size</code></td>
<td>
<p>If <code>method = "ae"</code>, a <code>character</code> value for the memory of an h2o session: &quot;15g&quot; (default).</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_port">port</code></td>
<td>
<p>A <code>numeric</code> value for the port number of the H2O server.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_train_seed">train_seed</code></td>
<td>
<p>A <code>numeric</code> value to set the control the randomness of creating resamples: 123 (default).</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_hyper_params">hyper_params</code></td>
<td>
<p>A <code>list</code> of hyperparameters to perform a grid search. the &quot;default&quot; list is: list(missing_values_handling = &quot;Skip&quot;, activation = c(&quot;Rectifier&quot;, &quot;Tanh&quot;), hidden = list(5, 25, 50, 100, 250, 500, nrow(df_h2o)), input_dropout_ratio = c(0, 0.1, 0.2, 0.3), rate = c(0, 0.01, 0.005, 0.001)).</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_search">search</code></td>
<td>
<p>If <code>method = "ae"</code>, a <code>character</code> value for the hyperparameter search strategy: &quot;random&quot; (default), &quot;grid&quot;.</p>
</td></tr>
<tr><td><code id="ph_prep_+3A_tune_length">tune_length</code></td>
<td>
<p>If <code>method = "ae"</code>, a <code>numeric</code> value (integer) for either the maximum number of hyperparameter combinations (&quot;random&quot;) or individual hyperparameter depth (&quot;grid&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:</p>

<table>
<tr>
 <td style="text-align: left;">
<code>train_df</code> </td><td style="text-align: left;"> The training set data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>vali_df</code> </td><td style="text-align: left;"> The validation set data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>test_df</code> </td><td style="text-align: left;"> The test set data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>train_split</code> </td><td style="text-align: left;"> The training set indices from the original data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>vali_split</code> </td><td style="text-align: left;"> The validation set indices from the original data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>test_split</code> </td><td style="text-align: left;"> The test set indices from the original data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>vali_pct</code> </td><td style="text-align: left;"> The percentage of training data used as validation data. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>test_pct</code> </td><td style="text-align: left;"> The percentage of total data used as test data. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>method</code> </td><td style="text-align: left;"> The dimensionality reduction method. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>## Import data.
data(ph_crocs)

## Remove anomalies with autoencoder.
rm_outs &lt;- ph_anomaly(df = ph_crocs, ids_col = "Biosample",
                      class_col = "Species", method = "ae")
## Preprocess anomaly-free data frame into train, validation, and test sets
## with PCs as predictors.
pc_dfs &lt;- ph_prep(df = rm_outs$df, ids_col = "Biosample",
                  class_col = "Species", vali_pct = 0.15,
                  test_pct = 0.15, method = "pca")
## Alternatively, preprocess data frame into train, validation, and test
## sets with latent variables as predictors. Notice that port is defined,
## because running H2O sessions one after another can cause connection
## errors.
ae_dfs &lt;- ph_prep(df = rm_outs$df, ids_col = "Biosample", class_col = "Species",
                  vali_pct = 0.15, test_pct = 0.15, method = "ae", port = 50001)

</code></pre>

<hr>
<h2 id='ph_stickleback'>Data from: Sexually mediated phenotypic variation within and between sexes as a continuum structured by ecology: The mosaic nature of skeletal variation across body regions in Threespine stickleback (Gasterosteus aculeatus L.)</h2><span id='topic+ph_stickleback'></span>

<h3>Description</h3>

<p>Abstract: Ecological character displacement between the sexes, and sexual selection, integrate into a convergent set of
factors that produce sexual variation. Ecologically-modulated, sexually mediated variation within and between
sexes may be a major contributor to the amount of total variation that selection can act on in species. Threespine
stickleback (Gasterosteus aculeatus) display rapid adaptive responses and sexual variation in many phenotypic
traits. We examined phenotypic variation in the skull, pectoral and pelvic girdles of threespine stickleback from
two freshwater and two coastal marine sites on the Sunshine Coast of British Columbia, Canada, using an approach
that avoids a priori assumptions about bimodal patterns of variation. We quantified shape and size of the cranial,
pectoral and pelvic regions of sticklebacks in marine and freshwater habitats using 3D geometric morphometrics and
an index of sexually mediated variation. We show that the expression of phenotypic variation is structured in part
by the effects of both habitat marine vs freshwater and the effects of individual sites within each habitat.
Relative size exerts variable influence, and patterns of phenotypic variation associated with sex vary among body
regions. This fine-grained quantification of sexually mediated variation in the context of habitat difference and
different anatomical structures indicates a complex relationship between genetically inferred sex and environmental
factors, demonstrating that the interplay between shared genetic background and sexually mediated, ecologically-
based selective pressures structures the phenotypic expression of complex traits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_stickleback
</code></pre>


<h3>Format</h3>



<h4><code>ph_stickleback</code></h4>

<p>A data frame of Procrustes superimposed shape data with 190 rows and 214 columns:
</p>

<dl>
<dt>Biosample</dt><dd><p>Biosample</p>
</dd>
<dt>Habitat</dt><dd><p>Habitat</p>
</dd>
<dt>Population</dt><dd><p>Population</p>
</dd>
<dt>Sex</dt><dd><p>Sex</p>
</dd>
</dl>
<p>...

</p>



<h3>Source</h3>

<p>Downloaded from
&lt;<a href="https://doi.org/doi.org/10.5061/dryad.xd2547dkw">doi:doi.org/10.5061/dryad.xd2547dkw</a>&gt;
</p>

<hr>
<h2 id='ph_train'>Generate predictions for phenotype ensemble.</h2><span id='topic+ph_train'></span>

<h3>Description</h3>

<p>The <code>ph_train</code> function automatically trains a set of binary or multi-class classification models to ultimately
build a new dataset of predictions. The data preprocessing and hyperparameter tuning are handled internally to
minimize user input and simplify the training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_train(
  train_df,
  vali_df,
  test_df,
  class_col,
  ctrl,
  train_seed = 123,
  n_cores = 2,
  task = "multi",
  methods = "all",
  metric = ifelse(task == "multi", "Kappa", "ROC"),
  tune_length = 10,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ph_train_+3A_train_df">train_df</code></td>
<td>
<p>A <code>data.frame</code> containing a class column and the training data.</p>
</td></tr>
<tr><td><code id="ph_train_+3A_vali_df">vali_df</code></td>
<td>
<p>A <code>data.frame</code> containing a class column and the validation data.</p>
</td></tr>
<tr><td><code id="ph_train_+3A_test_df">test_df</code></td>
<td>
<p>A <code>data.frame</code> containing a class column and the test d</p>
</td></tr>
<tr><td><code id="ph_train_+3A_class_col">class_col</code></td>
<td>
<p>A <code>character</code> value for the name of the class column shared across the train, validation, and test sets.</p>
</td></tr>
<tr><td><code id="ph_train_+3A_ctrl">ctrl</code></td>
<td>
<p>A <code>list</code> containing the resampling strategy (e.g., &quot;boot&quot;) and other parameters for <code>trainControl</code>. Automatically create one via <code>ph_ctrl</code> or manually create it with <code>trainControl</code>.</p>
</td></tr>
<tr><td><code id="ph_train_+3A_train_seed">train_seed</code></td>
<td>
<p>A <code>numeric</code> value to set the training seed and control the randomness of creating resamples: 123 (default).</p>
</td></tr>
<tr><td><code id="ph_train_+3A_n_cores">n_cores</code></td>
<td>
<p>An <code>integer</code> value for the number of cores to include in the cluster: 2 (default). We highly recommend increasing this value to, e.g., parallel::detectCores() - 1.</p>
</td></tr>
<tr><td><code id="ph_train_+3A_task">task</code></td>
<td>
<p>A <code>character</code> value for the type of classification <code>task</code>: &quot;multi&quot; (default), &quot;binary&quot;.</p>
</td></tr>
<tr><td><code id="ph_train_+3A_methods">methods</code></td>
<td>
<p>A <code>character</code> value enumerating the names (at least two, unless &quot;all&quot;) of the classification methods to ensemble: &quot;all&quot; (default).
</p>

<ul>
<li><p> If <code>task = "binary"</code>, there are 33 methods to choose from: &quot;AdaBag&quot;, &quot;AdaBoost.M1&quot;, &quot;C5.0&quot;, &quot;evtree&quot;, &quot;glmnet&quot;, &quot;hda&quot;, &quot;kernelpls&quot;, &quot;kknn&quot;, &quot;lda&quot;, &quot;loclda&quot;, &quot;mda&quot;, &quot;nb&quot;, &quot;nnet&quot;, &quot;pda&quot;, &quot;pls&quot;, &quot;qda&quot;, &quot;rda&quot;, &quot;rf&quot;, &quot;sparseLDA&quot;, &quot;stepLDA&quot;, &quot;stepQDA&quot;, &quot;treebag&quot;, &quot;svmLinear&quot;, &quot;svmPoly&quot;,&quot;svmRadial&quot;, &quot;gaussprLinear&quot; (slow), &quot;gaussprPoly&quot; (slow), &quot;gaussprRadial&quot; (slow), &quot;bagEarthGCV&quot;, &quot;cforest&quot;, &quot;earth&quot;, &quot;fda&quot;, &quot;hdda&quot;.
</p>
</li>
<li><p> If <code>task = "multi"</code>, there are 30 methods to choose from:  &quot;AdaBag&quot;, &quot;AdaBoost.M1&quot;,  &quot;C5.0&quot;, &quot;evtree&quot;, &quot;glmnet&quot;, &quot;hda&quot;, &quot;kernelpls&quot;, &quot;kknn&quot;, &quot;lda&quot;, &quot;loclda&quot;, &quot;mda&quot;, &quot;nb&quot;, &quot;nnet&quot;, &quot;pda&quot;, &quot;pls&quot;, &quot;qda&quot;, &quot;rda&quot;, &quot;rf&quot;, &quot;sparseLDA&quot;, &quot;stepLDA&quot;, &quot;stepQDA&quot;, &quot;treebag&quot;, &quot;svmLinear&quot;, &quot;svmPoly&quot;, &quot;svmRadial&quot;, &quot;bagEarthGCV&quot;, &quot;cforest&quot;, &quot;earth&quot;, &quot;fda&quot;, &quot;hdda&quot;.
</p>
</li></ul>
</td></tr>
<tr><td><code id="ph_train_+3A_metric">metric</code></td>
<td>
<p>A <code>character</code> value for which summary metric should be used to select the optimal model: &quot;ROC&quot; (default for &quot;binary&quot;) and &quot;Kappa&quot; (default for &quot;multi&quot;). Other options include &quot;logLoss&quot;, &quot;Accuracy&quot;, &quot;Mean_Balanced_Accuracy&quot;, and &quot;Mean_F1&quot;.</p>
</td></tr>
<tr><td><code id="ph_train_+3A_tune_length">tune_length</code></td>
<td>
<p>If <code>search = "random"</code> (default), this is an <code>integer</code> value for the maximum number of hyperparameter combinations to test for each training model in the ensemble; if <code>search = "grid"</code>, this is an <code>integer</code> value for the number of levels of each hyperparameter to test for each model.</p>
</td></tr>
<tr><td><code id="ph_train_+3A_quiet">quiet</code></td>
<td>
<p>A <code>logical</code> value for whether progress should be printed: TRUE (default), FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:</p>

<table>
<tr>
 <td style="text-align: left;">
<code>train_models</code> </td><td style="text-align: left;"> The <code>train</code> models for the ensemble. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>train_df</code> </td><td style="text-align: left;"> The training data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>vali_df</code> </td><td style="text-align: left;"> The validation data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>test_df</code> </td><td style="text-align: left;"> The test data frame. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>task</code> </td><td style="text-align: left;"> The type of classification task. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ctrl</code> </td><td style="text-align: left;"> A list of resampling parameters used in <code>trainControl</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>methods</code> </td><td style="text-align: left;"> The names of the classification methods to ensemble. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>search</code> </td><td style="text-align: left;"> The hyperparameter search strategy. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>n_cores</code> </td><td style="text-align: left;"> The number of cores for parallel processing. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>metric</code> </td><td style="text-align: left;"> The summary metric used to select the optimal model. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>tune_length</code> </td><td style="text-align: left;"> The maximum number of hyperparameter combinations ("random") or individual hyperparameter depth ("grid").  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>## Import data.
data(ph_crocs)

## Remove anomalies with autoencoder.
rm_outs &lt;- ph_anomaly(df = ph_crocs, ids_col = "Biosample",
                      class_col = "Species", method = "ae")
## Preprocess anomaly-free data frame into train, validation, and test sets
## with PCs as predictors.
pc_dfs &lt;- ph_prep(df = rm_outs$df, ids_col = "Biosample",
                  class_col = "Species", vali_pct = 0.15,
                  test_pct = 0.15, method = "pca")
## Echo control object for train function.
ctrl &lt;- ph_ctrl(ph_crocs$Species, resample_method = "boot")
## Train all models for ensemble.
## Note: Increasing n_cores will dramatically reduce train time.
train_models &lt;- ph_train(train_df = pc_dfs$train_df,
                         vali_df = pc_dfs$vali_df,
                         test_df = pc_dfs$test_df,
                         class_col = "Species",
                         ctrl = ctrl,
                         task = "multi",
                         methods = "all",
                         tune_length = 5,
                         quiet = FALSE)
## You can also train just a few, although more is preferable.
## Note: Increasing n_cores will dramatically reduce train time.
train_models &lt;- ph_train(train_df = pc_dfs$train_df,
                         vali_df = pc_dfs$vali_df,
                         test_df = pc_dfs$test_df,
                         class_col = "Species",
                         ctrl = ctrl,
                         task = "multi",
                         methods = c("lda", "mda",
                         "nnet", "pda", "sparseLDA"),
                         tune_length = 5,
                         quiet = FALSE)

</code></pre>

<hr>
<h2 id='reexports'>Pipe.</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
</dl>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
