<!DOCTYPE html><html lang="en"><head><title>Help for package OlinkAnalyze</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {OlinkAnalyze}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#check_data_completeness'><p>Check data completeness</p></a></li>
<li><a href='#manifest'><p>Example Sample Manifest</p></a></li>
<li><a href='#mapping_file_id'><p>Identifying which mapping file to use</p></a></li>
<li><a href='#norm_internal_adjust'><p>Combine reference and non-reference datasets</p></a></li>
<li><a href='#norm_internal_adjust_not_ref'><p>Add adjustment factors to a dataset</p></a></li>
<li><a href='#norm_internal_adjust_ref'><p>Modify the reference dataset to be combined with the non-reference normalized</p>
dataset</a></li>
<li><a href='#norm_internal_assay_median'><p>Compute median value of the quantification method for each Olink assay</p></a></li>
<li><a href='#norm_internal_bridge'><p>Internal bridge normalization function</p></a></li>
<li><a href='#norm_internal_cross_product'><p>Internal function normalizing Olink Explore 3k to Olink Explore 3072</p></a></li>
<li><a href='#norm_internal_reference_median'><p>Internal reference median normalization function</p></a></li>
<li><a href='#norm_internal_rename_cols'><p>Update column names of non-reference dataset based on those of reference</p>
dataset</a></li>
<li><a href='#norm_internal_subset'><p>Internal subset normalization function</p></a></li>
<li><a href='#norm_internal_update_maxlod'><p>Update MaxLOD to the maximum MaxLOD across normalized datasets.</p></a></li>
<li><a href='#npx_data1'><p>NPX Data in Long format</p></a></li>
<li><a href='#npx_data2'><p>NPX Data in Long format, Follow-up</p></a></li>
<li><a href='#olink_anova'><p>Function which performs an ANOVA per protein</p></a></li>
<li><a href='#olink_anova_posthoc'><p>Function which performs an ANOVA posthoc test per protein.</p></a></li>
<li><a href='#olink_boxplot'><p>Function which plots boxplots of selected variables</p></a></li>
<li><a href='#olink_bridgeability_plot'><p>Plots for each bridgeable assays between two platforms / products</p>
Author : Amrita Kar</a></li>
<li><a href='#olink_bridgeselector'><p>Bridge selection function</p></a></li>
<li><a href='#olink_color_discrete'><p>Olink color scale for discrete ggplots</p></a></li>
<li><a href='#olink_color_gradient'><p>Olink color scale for continuous ggplots</p></a></li>
<li><a href='#olink_displayPlateDistributions'><p>Plot distributions of a given variable for all plates</p></a></li>
<li><a href='#olink_displayPlateLayout'><p>Plot all plates colored by a variable</p></a></li>
<li><a href='#olink_dist_plot'><p>Function to plot the NPX distribution by panel</p></a></li>
<li><a href='#olink_fill_discrete'><p>Olink fill scale for discrete ggplots</p></a></li>
<li><a href='#olink_fill_gradient'><p>Olink fill scale for continuous ggplots</p></a></li>
<li><a href='#olink_heatmap_plot'><p>Function to plot a heatmap of the NPX data</p></a></li>
<li><a href='#olink_iqr'><p>Compute inter-quartile range (IQR) of multiplied by a fixed value</p></a></li>
<li><a href='#olink_lmer'><p>Function which performs a linear mixed model per protein</p></a></li>
<li><a href='#olink_lmer_plot'><p>Function which performs a point-range plot per protein on a linear mixed model</p></a></li>
<li><a href='#olink_lmer_posthoc'><p>Function which performs a linear mixed model posthoc per protein.</p></a></li>
<li><a href='#olink_lod'><p>Calculate LOD using Negative Controls or Fixed LOD</p></a></li>
<li><a href='#olink_median'><p>Compute median of quantified value</p></a></li>
<li><a href='#olink_median_iqr_outlier'><p>Compute outliers based on median +/- iqr_sd * IQR</p></a></li>
<li><a href='#olink_norm_input_assay_overlap'><p>Check <var>datasets</var> and <var>reference_medians</var> for Olink identifiers not</p>
shared across datasets.</a></li>
<li><a href='#olink_norm_input_check'><p>Check inputs of <code>olink_normalization</code> function.</p></a></li>
<li><a href='#olink_norm_input_check_df_cols'><p>Check columns of a list of datasets to be normalized.</p></a></li>
<li><a href='#olink_norm_input_check_samples'><p>Check reference samples to be used for normalization</p></a></li>
<li><a href='#olink_norm_input_class'><p>Check classes of input in olink_normalization function</p></a></li>
<li><a href='#olink_norm_input_clean_assays'><p>Check <var>datasets</var> and <var>reference_medians</var> for unexpected Olink</p>
identifiers or excluded assays</a></li>
<li><a href='#olink_norm_input_cross_product'><p>Check if bridge or cross-platform normalization</p></a></li>
<li><a href='#olink_norm_input_norm_method'><p>Check <var>datasets</var> and <var>reference_medians</var> for Olink identifiers not</p>
shared across datasets.</a></li>
<li><a href='#olink_norm_input_ref_medians'><p>Check datasets of <var>reference_medians</var></p></a></li>
<li><a href='#olink_norm_input_validate'><p>Validate inputs of normalization function</p></a></li>
<li><a href='#olink_norm_product_id'><p>Identify names of product for each project</p></a></li>
<li><a href='#olink_norm_reference_id'><p>Identify reference project.</p></a></li>
<li><a href='#olink_normalization'><p>Normalize two Olink datasets</p></a></li>
<li><a href='#olink_normalization_bridge'><p>Bridge normalization of all proteins between two NPX projects.</p></a></li>
<li><a href='#olink_normalization_bridgeable'><p>Identify if assays shared between Olink Explore 3072 and Olink Explore HT can</p>
be bridged</a></li>
<li><a href='#olink_normalization_n'><p>Bridge and/or subset normalization of all proteins among multiple NPX</p>
projects.</a></li>
<li><a href='#olink_normalization_n_check'><p>An internal function to perform checks on the input of the function</p>
olink_normalization_n.</a></li>
<li><a href='#olink_normalization_product_format'><p>Formatting the output of olink_normalization_product for seamless use with</p>
downstream Olink Analyze functions.</a></li>
<li><a href='#olink_normalization_project_name_check'><p>An internal function to perform checks on the input project names in the</p>
functions olink_normalization_bridge and olink_normalization_subset. The
function is expected to run all checks on project names to make sure that
normalization can be performed smoothly. It should work independently of the
function calling it.</a></li>
<li><a href='#olink_normalization_qs'><p>Quantile smoothing normalization of all proteins between two NPX projects.</p></a></li>
<li><a href='#olink_normalization_sample_check'><p>An internal function to perform checks on the input samples in the functions</p>
olink_normalization_bridge and olink_normalization_subset. The function is
expected to run all checks on SampleID to make sure that normalization can
be performed smoothly. It should work independently of the function calling
it.</a></li>
<li><a href='#olink_normalization_subset'><p>Subset normalization of all proteins between two NPX projects.</p></a></li>
<li><a href='#olink_one_non_parametric'><p>Function which performs a Kruskal-Wallis Test or Friedman Test per protein</p></a></li>
<li><a href='#olink_one_non_parametric_posthoc'><p>Function which performs posthoc test per protein for the results from Friedman or Kruskal-Wallis Test.</p></a></li>
<li><a href='#olink_ordinalRegression'><p>Function which A two-way ordinal analysis of variance can address an experimental design with two independent variables, each of which is a factor variable.  The main effect of each independent variable can be tested, as well as the effect of the interaction of the two factors.</p></a></li>
<li><a href='#olink_ordinalRegression_posthoc'><p>Function which performs an posthoc test per protein.</p></a></li>
<li><a href='#olink_pal'><p>Olink color panel for plotting</p></a></li>
<li><a href='#olink_pathway_enrichment'><p>Performs pathway enrichment using over-representation analysis (ORA) or gene set enrichment analysis (GSEA)</p></a></li>
<li><a href='#olink_pathway_heatmap'><p>Creates a heatmap of selected pathways and proteins</p></a></li>
<li><a href='#olink_pathway_visualization'><p>Creates bargraph of top/selected enrichment terms from GSEA or ORA results from olink_pathway_enrichment()</p></a></li>
<li><a href='#olink_pca_plot'><p>Function to plot a PCA of the data</p></a></li>
<li><a href='#olink_plate_randomizer'><p>Randomly assign samples to plates</p></a></li>
<li><a href='#olink_qc_plot'><p>Function to plot an overview of a sample cohort per Panel</p></a></li>
<li><a href='#olink_ttest'><p>Function which performs a t-test per protein</p></a></li>
<li><a href='#olink_umap_plot'><p>Function to make a UMAP plot from the data</p></a></li>
<li><a href='#olink_volcano_plot'><p>Easy volcano plot with Olink theme</p></a></li>
<li><a href='#olink_wilcox'><p>Function which performs a Mann-Whitney U Test per protein</p></a></li>
<li><a href='#print_and_capture'><p>Capture the output of printing an object</p></a></li>
<li><a href='#read_flex'><p>Read in flex data</p></a></li>
<li><a href='#read_NPX'><p>Function to read NPX data into long format</p></a></li>
<li><a href='#read_npx_csv'><p>Helper function to read in Olink Explore csv or txt files</p></a></li>
<li><a href='#read_npx_parquet'><p>Helper function to read in Olink Explore parquet output files</p></a></li>
<li><a href='#read_npx_zip'><p>Helper function to read in Olink Explore zip csv files</p></a></li>
<li><a href='#set_plot_theme'><p>Function to set plot theme</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Facilitate Analysis of Proteomic Data from Olink</td>
</tr>
<tr>
<td>Version:</td>
<td>4.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of functions to facilitate analysis of proteomic
    data from Olink, primarily NPX data that has been exported from Olink
    Software. The functions also work on QUANT data from
    Olink by log- transforming the QUANT data. The functions are focused
    on reading data, facilitating data wrangling and quality control
    analysis, performing statistical analysis and generating figures to
    visualize the results of the statistical analysis. The goal of this
    package is to help users extract biological insights from proteomic
    data run on the Olink platform.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/AGPL-3">AGPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Contact:</td>
<td>biostattools@olink.com</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>broom, car, cli (&ge; 3.6.2), dplyr (&ge; 1.1.1), data.table,
emmeans, forcats, generics, ggplot2, ggpubr, ggrepel,
grDevices, grid, magrittr, methods, readxl, rlang, rstatix,
stats, stringr, tibble, tidyr, tidyselect, tools, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>arrow, clusterProfiler, extrafont, FSA, ggplotify,
kableExtra, knitr, lme4, lmerTest, markdown, msigdbr, openssl,
ordinal, pheatmap, rmarkdown, scales, systemfonts, testthat (&ge;
3.0.0), umap, vdiffr, withr, zip</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>kableExtra, knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://olink.com/">https://olink.com/</a>
<a href="https://github.com/Olink-Proteomics/OlinkRPackage">https://github.com/Olink-Proteomics/OlinkRPackage</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-24 21:14:45 UTC; kathy.nevola</td>
</tr>
<tr>
<td>Author:</td>
<td>Kathleen Nevola <a href="https://orcid.org/0000-0002-5183-6444"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre] (kathy-nevola),
  Marianne Sandin <a href="https://orcid.org/0000-0001-6186-963X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (marisand),
  Jamey Guess <a href="https://orcid.org/0000-0002-4017-0923"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]
    (jrguess),
  Simon Forsberg <a href="https://orcid.org/0000-0002-7451-9222"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (simfor),
  Christoffer Cambronero [aut] (Orbmac),
  Pascal Pucholt <a href="https://orcid.org/0000-0003-3342-1373"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (AskPascal),
  Boxi Zhang <a href="https://orcid.org/0000-0001-7758-6204"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]
    (boxizhang),
  Masoumeh Sheikhi [aut] (MasoumehSheikhi),
  Klev Diamanti <a href="https://orcid.org/0000-0002-4922-8415"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (klevdiamanti),
  Amrita Kar [aut] (amrita-kar),
  Lei Conze [aut] (leiliuC),
  Kristyn Chin [aut] (kristynchin-olink),
  Danai Topouza <a href="https://orcid.org/0000-0002-6897-9281"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (dtopouza),
  Stephen Pollo <a href="https://orcid.org/0000-0001-9252-4976"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (spollo-olprot),
  Kang Dong <a href="https://orcid.org/0000-0002-4567-5007"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]
    (KangD-dev),
  Kristian Hodén <a href="https://orcid.org/0000-0003-0354-0662"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (kristianHoden),
  Per Eriksson <a href="https://orcid.org/0000-0001-7633-403X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (b_watcher),
  Nicola Moloney <a href="https://orcid.org/0000-0003-4967-3284"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Britta Lötstedt <a href="https://orcid.org/0000-0003-3545-5489"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Emmett Sprecher <a href="https://orcid.org/0000-0002-7710-695X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Jessica Barbagallo [ctb] (jbarbagallo),
  Olof Mansson [ctr] (olofmansson),
  Ola Caster [ctb] (OlaCaster),
  Olink [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kathleen Nevola &lt;biostattools@olink.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-24 21:40:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling <code>rhs(lhs)</code>.
</p>

<hr>
<h2 id='check_data_completeness'>Check data completeness</h2><span id='topic+check_data_completeness'></span>

<h3>Description</h3>

<p>Throw informative warnings if a dataset appears to have problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_data_completeness(df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_data_completeness_+3A_df">df</code></td>
<td>
<p>a NPX dataframe, e.g. from read_NPX()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None. Used for side effects (warnings)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
npx_data1 %&gt;%
    dplyr::mutate(NPX = dplyr::if_else(
                         SampleID == "A1" &amp; Panel == "Olink Cardiometabolic",
                         NA_real_,
                         NPX)) %&gt;%
    OlinkAnalyze:::check_data_completeness()
</code></pre>

<hr>
<h2 id='manifest'>Example Sample Manifest</h2><span id='topic+manifest'></span>

<h3>Description</h3>

<p>Sample manifest is generated randomly to demonstrate use of functions in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manifest
</code></pre>


<h3>Format</h3>

<p>This dataset  contains columns:
</p>

<dl>
<dt>SubjectID</dt><dd><p>Subject Identifier, A-Z</p>
</dd>
<dt>Visit</dt><dd><p>Visit Number, 1-6</p>
</dd>
<dt>SampleID</dt><dd><p>138 unique sample IDs</p>
</dd>
<dt>Site</dt><dd><p>Site1 or Site2</p>
</dd>
</dl>



<h3>Details</h3>

<p>A tibble with 138 rows and 4 columns. This manifest contains 26 example subjects, with 6 visits and 2 sites.
</p>

<hr>
<h2 id='mapping_file_id'>Identifying which mapping file to use</h2><span id='topic+mapping_file_id'></span>

<h3>Description</h3>

<p>Identifying which mapping file to use
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapping_file_id(ref_product)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mapping_file_id_+3A_ref_product">ref_product</code></td>
<td>
<p>one of &quot;HT&quot; or &quot;Reveal&quot; depending on reference product</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe of mapping file to use for OlinkID mapping
(eHT_e3072_mapping or reveal_e3072_mapping)
</p>

<hr>
<h2 id='norm_internal_adjust'>Combine reference and non-reference datasets</h2><span id='topic+norm_internal_adjust'></span>

<h3>Description</h3>

<p>The function is used by <code><a href="#topic+norm_internal_subset">norm_internal_subset</a></code> and
<code><a href="#topic+norm_internal_bridge">norm_internal_bridge</a></code> to combine the reference dataset that has
<code>Adj_factor = 0</code> and the non-reference dataset that used the adjustment
factors provided in <code>adj_fct_df</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_adjust(
  ref_df,
  ref_name,
  ref_cols,
  not_ref_df,
  not_ref_name,
  not_ref_cols,
  adj_fct_df
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_adjust_+3A_ref_df">ref_df</code></td>
<td>
<p>The reference dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_+3A_ref_name">ref_name</code></td>
<td>
<p>Project name of the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_+3A_ref_cols">ref_cols</code></td>
<td>
<p>Named list of column names in the reference dataset
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_+3A_not_ref_df">not_ref_df</code></td>
<td>
<p>The non-reference dataset to be used in normalization
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_+3A_not_ref_name">not_ref_name</code></td>
<td>
<p>Project name of the non-reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_+3A_not_ref_cols">not_ref_cols</code></td>
<td>
<p>Named list of column names in the non-reference dataset
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_+3A_adj_fct_df">adj_fct_df</code></td>
<td>
<p>Dataset containing the adjustment factors to be applied to
the non-reference dataset for (required).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calls <code><a href="#topic+norm_internal_adjust_ref">norm_internal_adjust_ref</a></code> and
<code><a href="#topic+norm_internal_adjust_not_ref">norm_internal_adjust_not_ref</a></code> and combines their outputs.
</p>


<h3>Value</h3>

<p>Tibble or ArrowObject with the normalized dataset.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_adjust_not_ref'>Add adjustment factors to a dataset</h2><span id='topic+norm_internal_adjust_not_ref'></span>

<h3>Description</h3>

<p>Add adjustment factors to a dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_adjust_not_ref(df, name, cols, adj_fct_df, adj_fct_cols)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_adjust_not_ref_+3A_df">df</code></td>
<td>
<p>The dataset to be normalized (required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_not_ref_+3A_name">name</code></td>
<td>
<p>Project name of the dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_not_ref_+3A_cols">cols</code></td>
<td>
<p>Named list of column names in the dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_not_ref_+3A_adj_fct_df">adj_fct_df</code></td>
<td>
<p>Dataset containing the adjustment factors to be applied to
the dataset <code>not_ref_df</code> (required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_not_ref_+3A_adj_fct_cols">adj_fct_cols</code></td>
<td>
<p>Named list of column names in the dataset containing
adjustment factors (required).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble or ArrowObject with the normalized dataset with additional
columns &quot;Project&quot; and &quot;Adj_factor&quot;.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_adjust_ref'>Modify the reference dataset to be combined with the non-reference normalized
dataset</h2><span id='topic+norm_internal_adjust_ref'></span>

<h3>Description</h3>

<p>Modify the reference dataset to be combined with the non-reference normalized
dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_adjust_ref(ref_df, ref_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_adjust_ref_+3A_ref_df">ref_df</code></td>
<td>
<p>The reference dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="norm_internal_adjust_ref_+3A_ref_name">ref_name</code></td>
<td>
<p>Project name of the reference dataset (required).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble or ArrowObject with the reference dataset with additional
columns &quot;Project&quot; and &quot;Adj_factor&quot;.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_assay_median'>Compute median value of the quantification method for each Olink assay</h2><span id='topic+norm_internal_assay_median'></span>

<h3>Description</h3>

<p>The function computes the median value of the the quantification method for
each Olink assay in the set of samples <code>samples</code>, and it adds the column
<code>Project</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_assay_median(df, samples, name, cols)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_assay_median_+3A_df">df</code></td>
<td>
<p>The dataset to calculate medians from (required).</p>
</td></tr>
<tr><td><code id="norm_internal_assay_median_+3A_samples">samples</code></td>
<td>
<p>Character vector of sample identifiers to be used for
adjustment factor calculation in the dataset <code>df</code> (required).</p>
</td></tr>
<tr><td><code id="norm_internal_assay_median_+3A_name">name</code></td>
<td>
<p>Project name of the dataset that will be added in the column
<code>Project</code> (required).</p>
</td></tr>
<tr><td><code id="norm_internal_assay_median_+3A_cols">cols</code></td>
<td>
<p>Named list of column names identified in the dataset <code>df</code>
(required).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is typically used by internal functions
<code><a href="#topic+norm_internal_subset">norm_internal_subset</a></code> and
<code><a href="#topic+norm_internal_reference_median">norm_internal_reference_median</a></code> that compute median
quantification value for each assay across multiple samples specified by
<code>samples</code>.
</p>


<h3>Value</h3>

<p>Tibble or ArrowObject with one row per Olink assay and the columns
OlinkID, Project, and assay_med
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_bridge'>Internal bridge normalization function</h2><span id='topic+norm_internal_bridge'></span>

<h3>Description</h3>

<p>Internal bridge normalization function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_bridge(
  ref_df,
  ref_samples,
  ref_name,
  ref_cols,
  not_ref_df,
  not_ref_name,
  not_ref_cols
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_bridge_+3A_ref_df">ref_df</code></td>
<td>
<p>The reference dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="norm_internal_bridge_+3A_ref_samples">ref_samples</code></td>
<td>
<p>Character vector of sample identifiers to be used for
adjustment factor calculation in the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_bridge_+3A_ref_name">ref_name</code></td>
<td>
<p>Project name of the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_bridge_+3A_ref_cols">ref_cols</code></td>
<td>
<p>Named list of column names in the reference dataset
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_bridge_+3A_not_ref_df">not_ref_df</code></td>
<td>
<p>The non-reference dataset to be used in normalization
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_bridge_+3A_not_ref_name">not_ref_name</code></td>
<td>
<p>Project name of the non-reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_bridge_+3A_not_ref_cols">not_ref_cols</code></td>
<td>
<p>Named list of column names in the non-reference dataset
(required).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble or ArrowObject with the normalized dataset.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_cross_product'>Internal function normalizing Olink Explore 3k to Olink Explore 3072</h2><span id='topic+norm_internal_cross_product'></span>

<h3>Description</h3>

<p>Internal function normalizing Olink Explore 3k to Olink Explore 3072
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_cross_product(
  ref_df,
  ref_samples,
  ref_name,
  ref_cols,
  ref_product,
  not_ref_df,
  not_ref_name,
  not_ref_cols
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_cross_product_+3A_ref_df">ref_df</code></td>
<td>
<p>The reference dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="norm_internal_cross_product_+3A_ref_samples">ref_samples</code></td>
<td>
<p>Character vector of sample identifiers to be used for
adjustment factor calculation in the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_cross_product_+3A_ref_name">ref_name</code></td>
<td>
<p>Project name of the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_cross_product_+3A_ref_cols">ref_cols</code></td>
<td>
<p>Named list of column names in the reference dataset
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_cross_product_+3A_ref_product">ref_product</code></td>
<td>
<p>Name of reference product (required).</p>
</td></tr>
<tr><td><code id="norm_internal_cross_product_+3A_not_ref_df">not_ref_df</code></td>
<td>
<p>The non-reference dataset to be used in normalization
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_cross_product_+3A_not_ref_name">not_ref_name</code></td>
<td>
<p>Project name of the non-reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_cross_product_+3A_not_ref_cols">not_ref_cols</code></td>
<td>
<p>Named list of column names in the non-reference dataset
(required).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble or ArrowObject with a dataset with the following additional
columns:
</p>

<ul>
<li><p>OlinkID_E3072: Corresponding assay identifier from Olink Explore
3072.
</p>
</li>
<li><p>Project: Project of origin.
</p>
</li>
<li><p>BridgingRecommendation: Recommendation of whether the assay is
bridgeable or not. One of &quot;NotBridgeable&quot;, &quot;MedianCentering&quot;, or
&quot;QuantileSmoothing&quot;.
</p>
</li>
<li><p>MedianCenteredNPX: NPX values adjusted based on the median of the
pair-wise differences of NPX values between bridge samples.
</p>
</li>
<li><p>QSNormalizedNPX: NPX values adjusted based on the quantile
smoothing normalization among bridge samples.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_reference_median'>Internal reference median normalization function</h2><span id='topic+norm_internal_reference_median'></span>

<h3>Description</h3>

<p>Internal reference median normalization function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_reference_median(
  ref_df,
  ref_samples,
  ref_name,
  ref_cols,
  reference_medians
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_reference_median_+3A_ref_df">ref_df</code></td>
<td>
<p>The reference dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="norm_internal_reference_median_+3A_ref_samples">ref_samples</code></td>
<td>
<p>Character vector of sample identifiers to be used for
adjustment factor calculation in the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_reference_median_+3A_ref_name">ref_name</code></td>
<td>
<p>Project name of the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_reference_median_+3A_ref_cols">ref_cols</code></td>
<td>
<p>Named list of column names in the reference dataset
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_reference_median_+3A_reference_medians">reference_medians</code></td>
<td>
<p>Dataset with columns &quot;OlinkID&quot; and &quot;Reference_NPX&quot;
(required). Used for reference median normalization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble or ArrowObject with the normalized dataset.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_rename_cols'>Update column names of non-reference dataset based on those of reference
dataset</h2><span id='topic+norm_internal_rename_cols'></span>

<h3>Description</h3>

<p>This function handles cases when specific columns referring to the same thing
are named differently in <code>df1</code> and <code>df2</code> normalization datasets. It only
renames columns
panel_version, qc_warn, and assay_warn based on
their names in the reference dataset.#'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_rename_cols(ref_cols, not_ref_cols, not_ref_df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_rename_cols_+3A_ref_cols">ref_cols</code></td>
<td>
<p>Named list of column names identified in the reference
dataset.</p>
</td></tr>
<tr><td><code id="norm_internal_rename_cols_+3A_not_ref_cols">not_ref_cols</code></td>
<td>
<p>Named list of column names identified in the
non-reference dataset.</p>
</td></tr>
<tr><td><code id="norm_internal_rename_cols_+3A_not_ref_df">not_ref_df</code></td>
<td>
<p>Non-reference dataset to be used in normalization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>not_ref_df</code> with updated column names.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_subset'>Internal subset normalization function</h2><span id='topic+norm_internal_subset'></span>

<h3>Description</h3>

<p>This function performs subset normalization using a subset of the samples
from either or both reference and non-reference datasets. When all samples
from each dataset are used, the function performs intensity normalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_subset(
  ref_df,
  ref_samples,
  ref_name,
  ref_cols,
  not_ref_df,
  not_ref_samples,
  not_ref_name,
  not_ref_cols
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_subset_+3A_ref_df">ref_df</code></td>
<td>
<p>The reference dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="norm_internal_subset_+3A_ref_samples">ref_samples</code></td>
<td>
<p>Character vector of sample identifiers to be used for
adjustment factor calculation in the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_subset_+3A_ref_name">ref_name</code></td>
<td>
<p>Project name of the reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_subset_+3A_ref_cols">ref_cols</code></td>
<td>
<p>Named list of column names in the reference dataset
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_subset_+3A_not_ref_df">not_ref_df</code></td>
<td>
<p>The non-reference dataset to be used in normalization
(required).</p>
</td></tr>
<tr><td><code id="norm_internal_subset_+3A_not_ref_samples">not_ref_samples</code></td>
<td>
<p>Character vector of sample identifiers to be used for
adjustment factor calculation in the non-reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_subset_+3A_not_ref_name">not_ref_name</code></td>
<td>
<p>Project name of the non-reference dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_subset_+3A_not_ref_cols">not_ref_cols</code></td>
<td>
<p>Named list of column names in the non-reference dataset
(required).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble or ArrowObject with the normalized dataset.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='norm_internal_update_maxlod'>Update MaxLOD to the maximum MaxLOD across normalized datasets.</h2><span id='topic+norm_internal_update_maxlod'></span>

<h3>Description</h3>

<p>Update MaxLOD to the maximum MaxLOD across normalized datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm_internal_update_maxlod(df, cols)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm_internal_update_maxlod_+3A_df">df</code></td>
<td>
<p>Normalized Olink dataset (required).</p>
</td></tr>
<tr><td><code id="norm_internal_update_maxlod_+3A_cols">cols</code></td>
<td>
<p>Named list of column names in the dataset (required).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The same dataset as the input <var>df</var> with the column reflecting
MaxLOD updated.
</p>

<hr>
<h2 id='npx_data1'>NPX Data in Long format</h2><span id='topic+npx_data1'></span>

<h3>Description</h3>

<p>Data is generated randomly to demonstrate use of functions in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npx_data1
</code></pre>


<h3>Format</h3>

<p>In addition to standard read_NPX() columns, this dataset also contains columns:
</p>

<dl>
<dt>Subject</dt><dd><p>Subject Identifier</p>
</dd>
<dt>Treatment</dt><dd><p> Treated or Untreated</p>
</dd>
<dt>Site</dt><dd><p>Site indicator, 5 unique values</p>
</dd>
<dt>Time</dt><dd><p>Baseline, Week.6 and Week.12</p>
</dd>
<dt>Project</dt><dd><p>Project ID number</p>
</dd>
</dl>



<h3>Details</h3>

<p>A tibble with 29,440 rows and 17 columns.
Dataset npx_data1 is an Olink NPX data file (tibble) in long format with 158 unique Sample ID's
(including 2 repeats each of control samples: CONTROL_SAMPLE_AS 1 CONTROL_SAMPLE_AS 2).
The data also contains 1104 assays (uniquely identified using OlinkID) over 2 Panels.
</p>

<hr>
<h2 id='npx_data2'>NPX Data in Long format, Follow-up</h2><span id='topic+npx_data2'></span>

<h3>Description</h3>

<p>Data is generated randomly to demonstrate use of functions in this package. The format is very similar to data(npx_data1). Both datasets can be used together to demonstrate the use of normalization functionality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npx_data2
</code></pre>


<h3>Format</h3>

<p>In addition to standard read_NPX() columns, this dataset also contains columns:
</p>

<dl>
<dt>Subject</dt><dd><p>Subject Identifier</p>
</dd>
<dt>Treatment</dt><dd><p>Treated or Untreated</p>
</dd>
<dt>Site</dt><dd><p>Site indicator, 5 unique values</p>
</dd>
<dt>Time</dt><dd><p>Baseline, Week.6 and Week.12</p>
</dd>
<dt>Project</dt><dd><p>Project ID number</p>
</dd>
</dl>



<h3>Details</h3>

<p>A tibble with 32,384 rows and 17 columns. npx_data2 is an Olink NPX data file (tibble) in long format  with 174 unique Sample ID's (including 2 repeats each of control samples: CONTROL_SAMPLE_AS 1 CONTROL_SAMPLE_AS 2). The data also contains 1104 assays (uniquely identified using OlinkID) over 2 Panels. This dataset also contain 16 bridge samples with SampleID's that are also present in data(npx_data1). These sample ID's are: A13, A29, A30, A36, A45, A46, A52, A63, A71, A73, B3, B4, B37, B45, B63, B75
</p>

<hr>
<h2 id='olink_anova'>Function which performs an ANOVA per protein</h2><span id='topic+olink_anova'></span>

<h3>Description</h3>

<p>Performs an ANOVA F-test for each assay (by OlinkID) in every panel using car::Anova and Type III sum of squares.
The function handles both factor and numerical variables and/or covariates. <br /><br />
Samples that have no variable information or missing factor levels are automatically removed from the analysis (specified in a message if verbose = TRUE).
Character columns in the input dataframe are automatically converted to factors (specified in a message if verbose = TRUE).
Numerical variables are not converted to factors.
Control samples should be removed before using this function.
Control assays (AssayType is not &quot;assay&quot;, or Assay contains &quot;control&quot; or &quot;ctrl&quot;) should be removed before using this function.
If a numerical variable is to be used as a factor, this conversion needs to be done on the dataframe before the function call. <br /><br />
Crossed analysis, i.e. A*B formula notation, is inferred from the variable argument in the following cases: <br />
</p>

<ul>
<li><p> c('A','B')
</p>
</li>
<li><p> c('A: B')
</p>
</li>
<li><p> c('A: B', 'B') or c('A: B', 'A')
</p>
</li></ul>

<p>Inference is specified in a message if verbose = TRUE. <br />
For covariates, crossed analyses need to be specified explicitly, i.e. two main effects will not be expanded with a c('A','B') notation. Main effects present in the variable takes precedence.
The formula notation of the final model is specified in a message if verbose = TRUE. <br /><br />
Adjusted p-values are calculated by stats::p.adjust according to the Benjamini &amp; Hochberg (1995) method (“fdr”).
The threshold is determined by logic evaluation of Adjusted_pval &lt; 0.05. Covariates are not included in the p-value adjustment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_anova(
  df,
  variable,
  outcome = "NPX",
  covariates = NULL,
  model_formula,
  return.covariates = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_anova_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID, UniProt, Panel and a factor with at least 3 levels.</p>
</td></tr>
<tr><td><code id="olink_anova_+3A_variable">variable</code></td>
<td>
<p>Single character value or character array.
Variable(s) to test. If length &gt; 1, the included variable names will be used in crossed analyses .
Also takes ':' or '*' notation.</p>
</td></tr>
<tr><td><code id="olink_anova_+3A_outcome">outcome</code></td>
<td>
<p>Character. The dependent variable. Default: NPX.</p>
</td></tr>
<tr><td><code id="olink_anova_+3A_covariates">covariates</code></td>
<td>
<p>Single character value or character array. Default: NULL.
Covariates to include. Takes ':' or '*' notation. Crossed analysis will not be inferred from main effects.</p>
</td></tr>
<tr><td><code id="olink_anova_+3A_model_formula">model_formula</code></td>
<td>
<p>(optional) Symbolic description of the model to be fitted in standard formula notation (e.g. &quot;NPX~A*B&quot;). If provided, this will override the <code>outcome</code>, <code>variable</code> and <code>covariates</code> arguments. Can be a string or of class <code>stats::formula()</code>.</p>
</td></tr>
<tr><td><code id="olink_anova_+3A_return.covariates">return.covariates</code></td>
<td>
<p>Boolean. Default: False. Returns F-test results for the covariates. Note: Adjusted p-values will be NA for the covariates.</p>
</td></tr>
<tr><td><code id="olink_anova_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. Default: True. If information about removed samples, factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; containing the ANOVA results for every protein. The tibble is arranged by ascending p-values.
Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>term: &quot;character&quot; term in model
</p>
</li>
<li><p>df: &quot;numeric&quot; degrees of freedom
</p>
</li>
<li><p>sumsq: &quot;numeric&quot; sum of square
</p>
</li>
<li><p>meansq: &quot;numeric&quot; mean of square
</p>
</li>
<li><p>statistic: &quot;numeric&quot; value of the statistic
</p>
</li>
<li><p>p.value: &quot;numeric&quot; nominal p-value
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test (Benjamini&amp;Hochberg)
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)

npx_df &lt;- npx_data1 |&gt; filter(!grepl('control|ctrl',SampleID, ignore.case = TRUE))

#One-way ANOVA, no covariates.
#Results in a model NPX~Time
anova_results &lt;- olink_anova(df = npx_df, variable = "Time")

#Two-way ANOVA, one main effect covariate.
#Results in model NPX~Treatment*Time+Site.
anova_results &lt;- olink_anova(df = npx_df,
                             variable=c("Treatment:Time"),
                             covariates="Site")

#One-way ANOVA, interaction effect covariate.
#Results in model NPX~Treatment+Site:Time+Site+Time.
anova_results &lt;- olink_anova(df = npx_df,
                             variable="Treatment",
                             covariates="Site:Time")
</code></pre>

<hr>
<h2 id='olink_anova_posthoc'>Function which performs an ANOVA posthoc test per protein.</h2><span id='topic+olink_anova_posthoc'></span>

<h3>Description</h3>

<p>Performs a post hoc ANOVA test using emmeans::emmeans with Tukey p-value adjustment per assay (by OlinkID) for each panel at confidence level 0.95.
See <code>olink_anova</code> for details of input notation. <br /><br />
The function handles both factor and numerical variables and/or covariates.
Control samples should be removed before using this function.
Control assays (AssayType is not &quot;assay&quot;, or Assay contains &quot;control&quot; or &quot;ctrl&quot;) should be removed before using this function.
The posthoc test for a numerical variable compares the difference in means of the outcome variable (default: NPX) for 1 standard deviation difference in the numerical variable, e.g.
mean NPX at mean(numerical variable) versus mean NPX at mean(numerical variable) + 1*SD(numerical variable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_anova_posthoc(
  df,
  olinkid_list = NULL,
  variable,
  covariates = NULL,
  outcome = "NPX",
  model_formula,
  effect,
  effect_formula,
  mean_return = FALSE,
  post_hoc_padjust_method = "tukey",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_anova_posthoc_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID, UniProt, Panel and a factor with at least 3 levels.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_olinkid_list">olinkid_list</code></td>
<td>
<p>Character vector of OlinkID's on which to perform post hoc analysis. If not specified, all assays in df are used.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_variable">variable</code></td>
<td>
<p>Single character value or character array.
Variable(s) to test. If length &gt; 1, the included variable names will be used in crossed analyses .
Also takes ':' notation.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_covariates">covariates</code></td>
<td>
<p>Single character value or character array. Default: NULL. Covariates to include. Takes ':' or '*' notation. Crossed analysis will not be inferred from main effects.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_outcome">outcome</code></td>
<td>
<p>Character. The dependent variable. Default: NPX.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_model_formula">model_formula</code></td>
<td>
<p>(optional) Symbolic description of the model to be fitted in standard formula notation (e.g. &quot;NPX~A*B&quot;). If provided, this will override the <code>outcome</code>, <code>variable</code> and <code>covariates</code> arguments. Can be a string or of class <code>stats::formula()</code>.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_effect">effect</code></td>
<td>
<p>Term on which to perform post-hoc. Character vector. Must be subset of or identical to variable.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_effect_formula">effect_formula</code></td>
<td>
<p>(optional) A character vector specifying the names of the predictors over which estimated marginal means are desired as defined in the <code>emmeans</code> package. May also be a formula. If provided, this will override the <code>effect</code> argument. See <code>?emmeans::emmeans()</code> for more information.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_mean_return">mean_return</code></td>
<td>
<p>Boolean. If true, returns the mean of each factor level rather than the difference in means (default). Note that no p-value is returned for mean_return = TRUE and no adjustment is performed.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_post_hoc_padjust_method">post_hoc_padjust_method</code></td>
<td>
<p>P-value adjustment method to use for post-hoc comparisons within an assay. Options include <code>tukey</code>, <code>sidak</code>, <code>bonferroni</code> and <code>none</code>.</p>
</td></tr>
<tr><td><code id="olink_anova_posthoc_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. Default: True. If information about removed samples, factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; of posthoc tests for specified effect, arranged by ascending adjusted p-values.
Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>term: &quot;character&quot; term in model
</p>
</li>
<li><p>contrast: &quot;character&quot; the groups that were compared
</p>
</li>
<li><p>estimate: &quot;numeric&quot; difference in mean NPX between groups
</p>
</li>
<li><p>conf.low: &quot;numeric&quot; confidence interval for the mean (lower end)
</p>
</li>
<li><p>conf.high: &quot;numeric&quot; confidence interval for the mean (upper end)
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)

npx_df &lt;- npx_data1 |&gt; filter(!grepl('control|ctrl',SampleID, ignore.case = TRUE))

#Two-way ANOVA, one main effect (Site) covariate.
#Results in model NPX~Treatment*Time+Site.
anova_results &lt;- olink_anova(df = npx_df,
                             variable=c("Treatment:Time"),
                             covariates="Site")

#Posthoc test for the model NPX~Treatment*Time+Site,
#on the interaction effect Treatment:Time with covariate Site.

#Filtering out significant and relevant results.
significant_assays &lt;- anova_results |&gt;
filter(Threshold == 'Significant' &amp; term == 'Treatment:Time') |&gt;
select(OlinkID) |&gt;
distinct() |&gt;
pull()

#Posthoc, all pairwise comparisons
anova_posthoc_results &lt;- olink_anova_posthoc(npx_df,
variable=c("Treatment:Time"),
covariates="Site",
olinkid_list = significant_assays,
effect = "Treatment:Time")


#Posthoc, treated vs untreated at each timepoint, adjusted for Site effect
anova_posthoc_results &lt;- olink_anova_posthoc(npx_df,
model_formula = "NPX~Treatment*Time+Site",
olinkid_list = significant_assays,
effect_formula = "pairwise~Treatment|Time")



</code></pre>

<hr>
<h2 id='olink_boxplot'>Function which plots boxplots of selected variables</h2><span id='topic+olink_boxplot'></span>

<h3>Description</h3>

<p>Generates faceted boxplots of NPX vs. grouping variable(s) for a given list of proteins (OlinkIDs) using ggplot and ggplot2::geom_boxplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_boxplot(
  df,
  variable,
  olinkid_list,
  verbose = FALSE,
  number_of_proteins_per_plot = 6,
  posthoc_results = NULL,
  ttest_results = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_boxplot_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID (unique), UniProt and at least one grouping variable.</p>
</td></tr>
<tr><td><code id="olink_boxplot_+3A_variable">variable</code></td>
<td>
<p>A character vector or character value indicating which column to use as the x-axis and fill grouping variable.
The first or single value is used as x-axis, the second as fill. Further values in a vector are not plotted.</p>
</td></tr>
<tr><td><code id="olink_boxplot_+3A_olinkid_list">olinkid_list</code></td>
<td>
<p>Character vector indicating which proteins (OlinkIDs) to plot.</p>
</td></tr>
<tr><td><code id="olink_boxplot_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. If the plots are shown as well as returned in the list (default is false).</p>
</td></tr>
<tr><td><code id="olink_boxplot_+3A_number_of_proteins_per_plot">number_of_proteins_per_plot</code></td>
<td>
<p>Number of boxplots to include in the facet plot (default 6).</p>
</td></tr>
<tr><td><code id="olink_boxplot_+3A_posthoc_results">posthoc_results</code></td>
<td>
<p>Data frame from ANOVA posthoc analysis using olink_anova_posthoc() function.</p>
</td></tr>
<tr><td><code id="olink_boxplot_+3A_ttest_results">ttest_results</code></td>
<td>
<p>Data frame from ttest analysis using olink_ttest() function.</p>
</td></tr>
<tr><td><code id="olink_boxplot_+3A_...">...</code></td>
<td>
<p>coloroption passed to specify color order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of objects of class “ggplot” (the actual ggplot object is entry 1 in the list). Box and whisker plot of NPX (y-axis) by variable (x-axis) for each Assay
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)
npx_df &lt;- npx_data1 |&gt; filter(!grepl('control|ctrl',SampleID, ignore.case = TRUE))
anova_results &lt;- olink_anova(npx_df, variable = "Site")
significant_assays &lt;- anova_results |&gt;
    filter(Threshold == 'Significant') |&gt;
    pull(OlinkID)
olink_boxplot(npx_df,
              variable = "Site",
              olinkid_list = significant_assays,
              verbose = TRUE,
              number_of_proteins_per_plot = 3)

</code></pre>

<hr>
<h2 id='olink_bridgeability_plot'>Plots for each bridgeable assays between two platforms / products
Author : Amrita Kar</h2><span id='topic+olink_bridgeability_plot'></span>

<h3>Description</h3>

<p>Generates a combined plot per assay containing a violin and boxplot plot
for IQR ranges ;
correlation plot of NPX values ;
a median count bar plot and
KS plots from 2 platforms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_bridgeability_plot(data, median_counts_threshold = 150, min_count = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_bridgeability_plot_+3A_data">data</code></td>
<td>
<p>data frame of cross-product bridge normalized data generated by
olink_normalization()</p>
</td></tr>
<tr><td><code id="olink_bridgeability_plot_+3A_median_counts_threshold">median_counts_threshold</code></td>
<td>
<p>Numeric value to use for median counts
threshold for the two platforms. Default is 150</p>
</td></tr>
<tr><td><code id="olink_bridgeability_plot_+3A_min_count">min_count</code></td>
<td>
<p>Numeric value to use for minimum counts
for the two platforms. Default is 10</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot;, 4 combined plots for each protein.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

npx_ht &lt;- OlinkAnalyze:::data_ht_small |&gt;
 dplyr::filter(SampleType == "SAMPLE") |&gt;
 dplyr::mutate(Project = "data1")

npx_3072 &lt;- OlinkAnalyze:::data_3k_small |&gt;
 dplyr::filter(SampleType == "SAMPLE") |&gt;
 dplyr::mutate(Project = "data2")

overlapping_samples &lt;- unique(intersect(npx_ht |&gt;
                                         dplyr::distinct(SampleID) |&gt;
                                         dplyr::pull(),
                                       npx_3072 |&gt;
                                         dplyr::distinct(SampleID) |&gt;
                                         dplyr::pull()))

data &lt;- OlinkAnalyze::olink_normalization(df1 = npx_ht,
                                         df2 = npx_3072,
                                         overlapping_samples_df1 =
                                           overlapping_samples,
                                         df1_project_nr = "Explore HT",
                                         df2_project_nr = "Explore 3072",
                                         reference_project = "Explore HT")

olinkids &lt;- unique(paste0(data$OlinkID,"_",data$Assay))
results &lt;- olink_bridgeability_plot(data = data,
                          median_counts_threshold = 150,
                          min_count = 10)
names(results) &lt;- olinkids

</code></pre>

<hr>
<h2 id='olink_bridgeselector'>Bridge selection function</h2><span id='topic+olink_bridgeselector'></span>

<h3>Description</h3>

<p>The bridge selection function will select a number of bridge samples based on the input data. It selects samples with
good detection, which passes QC and cover a good range of the data. If possible, Olink recommends 8-16 bridge samples.
When running the selector, Olink recommends starting at sampleMissingFreq = 0.10 which represents a maximum of 10\
data below LOD per sample. If there are not enough samples output, increase to 20\
The function accepts NPX Excel files with data &lt; LOD replaced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_bridgeselector(df, sampleMissingFreq, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_bridgeselector_+3A_df">df</code></td>
<td>
<p>Tibble/data frame in long format such as produced by the Olink Analyze read_NPX function.</p>
</td></tr>
<tr><td><code id="olink_bridgeselector_+3A_samplemissingfreq">sampleMissingFreq</code></td>
<td>
<p>The threshold for sample wise missingness.</p>
</td></tr>
<tr><td><code id="olink_bridgeselector_+3A_n">n</code></td>
<td>
<p>Number of bridge samples to be selected.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; with sample IDs and mean NPX for a defined number of bridging samples. Columns include:
</p>

<ul>
<li><p>SampleID: Sample ID
</p>
</li>
<li><p>PercAssaysBelowLOD: Percent of Assays that are below LOD for the sample
</p>
</li>
<li><p>MeanNPX: Mean NPX for the sample
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>bridge_samples &lt;- olink_bridgeselector(npx_data1, sampleMissingFreq = 0.1, n = 20)
</code></pre>

<hr>
<h2 id='olink_color_discrete'>Olink color scale for discrete ggplots</h2><span id='topic+olink_color_discrete'></span>

<h3>Description</h3>

<p>Olink color scale for discrete ggplots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_color_discrete(..., alpha = 1, coloroption = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_color_discrete_+3A_...">...</code></td>
<td>
<p>Optional. Additional arguments to pass to ggplot2::discrete_scale()</p>
</td></tr>
<tr><td><code id="olink_color_discrete_+3A_alpha">alpha</code></td>
<td>
<p>transparency</p>
</td></tr>
<tr><td><code id="olink_color_discrete_+3A_coloroption">coloroption</code></td>
<td>
<p>string, one or more of the following:
c('red', 'orange', 'yellow', 'green', 'teal', 'turqoise', 'lightblue', 'darkblue', 'purple', 'pink')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)

ggplot(mtcars, aes(x=wt, y=mpg, color=as.factor(cyl))) +
geom_point(size = 4) +
olink_color_discrete() +
theme_bw()

ggplot(mtcars, aes(x=wt, y=mpg, color=as.factor(cyl))) +
geom_point(size = 4) +
olink_color_discrete(coloroption = c('lightblue', 'red', 'green')) +
theme_bw()
</code></pre>

<hr>
<h2 id='olink_color_gradient'>Olink color scale for continuous ggplots</h2><span id='topic+olink_color_gradient'></span>

<h3>Description</h3>

<p>Olink color scale for continuous ggplots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_color_gradient(..., alpha = 1, coloroption = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_color_gradient_+3A_...">...</code></td>
<td>
<p>Optional. Additional arguments to pass to scale_color_gradientn()</p>
</td></tr>
<tr><td><code id="olink_color_gradient_+3A_alpha">alpha</code></td>
<td>
<p>transparency (optional)</p>
</td></tr>
<tr><td><code id="olink_color_gradient_+3A_coloroption">coloroption</code></td>
<td>
<p>string, one or more of the following:
c('red', 'orange', 'yellow', 'green', 'teal', 'turqoise', 'lightblue', 'darkblue', 'purple', 'pink')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(ggplot2)

dsub &lt;- subset(diamonds, x &gt; 5 &amp; x &lt; 6 &amp; y &gt; 5 &amp; y &lt; 6)
dsub$diff &lt;- with(dsub, sqrt(abs(x-y))* sign(x-y))

ggplot(dsub, aes(x, y, colour=diff)) +
geom_point() +
 theme_bw() +
 olink_color_gradient()

</code></pre>

<hr>
<h2 id='olink_displayPlateDistributions'>Plot distributions of a given variable for all plates</h2><span id='topic+olink_displayPlateDistributions'></span>

<h3>Description</h3>

<p>Displays a bar chart for each plate representing the distribution of the given grouping variable on each plate using ggplot2::ggplot and ggplot2::geom_bar.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_displayPlateDistributions(data, fill.color)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_displayPlateDistributions_+3A_data">data</code></td>
<td>
<p>tibble/data frame in long format returned from the olink_plate_randomizer function.</p>
</td></tr>
<tr><td><code id="olink_displayPlateDistributions_+3A_fill.color">fill.color</code></td>
<td>
<p>Column name to be used as coloring variable for wells.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot; showing the percent distribution of fill.color in each plate (x-axis)
</p>


<h3>See Also</h3>


<ul>
<li><p><code><a href="#topic+olink_plate_randomizer">olink_plate_randomizer()</a></code> for generating a plating scheme
</p>
</li>
<li><p><code><a href="#topic+olink_displayPlateLayout">olink_displayPlateLayout()</a></code> for visualizing the generated plate layouts
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>randomized.manifest &lt;- olink_plate_randomizer(manifest)
olink_displayPlateDistributions(data=randomized.manifest,fill.color="Site")
</code></pre>

<hr>
<h2 id='olink_displayPlateLayout'>Plot all plates colored by a variable</h2><span id='topic+olink_displayPlateLayout'></span>

<h3>Description</h3>

<p>Displays each plate in a facet with cells colored by the given variable using ggplot and ggplot2::geom_tile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_displayPlateLayout(
  data,
  fill.color,
  PlateSize = 96,
  num_ctrl = 8,
  rand_ctrl = FALSE,
  Product,
  include.label = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_displayPlateLayout_+3A_data">data</code></td>
<td>
<p>tibble/data frame in long format returned from the olink_plate_randomizer function.</p>
</td></tr>
<tr><td><code id="olink_displayPlateLayout_+3A_fill.color">fill.color</code></td>
<td>
<p>Column name to be used as coloring variable for wells.</p>
</td></tr>
<tr><td><code id="olink_displayPlateLayout_+3A_platesize">PlateSize</code></td>
<td>
<p>Integer. Either 96 or 48. 96 is default.</p>
</td></tr>
<tr><td><code id="olink_displayPlateLayout_+3A_num_ctrl">num_ctrl</code></td>
<td>
<p>Numeric. Number of controls on each plate (default = 8)</p>
</td></tr>
<tr><td><code id="olink_displayPlateLayout_+3A_rand_ctrl">rand_ctrl</code></td>
<td>
<p>Logical. Whether controls are added to be randomized across the plate (default = FALSE)</p>
</td></tr>
<tr><td><code id="olink_displayPlateLayout_+3A_product">Product</code></td>
<td>
<p>String. Name of Olink product used to set PlateSize if not provided. Optional.</p>
</td></tr>
<tr><td><code id="olink_displayPlateLayout_+3A_include.label">include.label</code></td>
<td>
<p>Should the variable group be shown in the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot; showing each plate in a facet with the cells colored by values in column fill.color in input <code>data</code>.
</p>


<h3>See Also</h3>


<ul>
<li><p><code><a href="#topic+olink_plate_randomizer">olink_plate_randomizer()</a></code> for generating a plating scheme
</p>
</li>
<li><p><code><a href="#topic+olink_displayPlateDistributions">olink_displayPlateDistributions()</a></code> for validating that sites are properly randomized
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>randomized.manifest &lt;- olink_plate_randomizer(manifest)
olink_displayPlateLayout(data = randomized.manifest, fill.color="Site")

</code></pre>

<hr>
<h2 id='olink_dist_plot'>Function to plot the NPX distribution by panel</h2><span id='topic+olink_dist_plot'></span>

<h3>Description</h3>

<p>Generates boxplots of NPX vs. SampleID colored by QC_Warning (default) or any other grouping variable
and faceted by Panel using ggplot and ggplot2::geom_boxplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_dist_plot(df, color_g = "QC_Warning", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_dist_plot_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format. Must have columns SampleID, NPX and Panel</p>
</td></tr>
<tr><td><code id="olink_dist_plot_+3A_color_g">color_g</code></td>
<td>
<p>Character value indicating which column to use as fill color (default: QC_Warning)</p>
</td></tr>
<tr><td><code id="olink_dist_plot_+3A_...">...</code></td>
<td>
<p>Color option passed to specify color order.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot; which displays NPX distribution for each sample per panel
</p>


<h3>Examples</h3>

<pre><code class='language-R'>olink_dist_plot(npx_data1, color_g = "QC_Warning")
</code></pre>

<hr>
<h2 id='olink_fill_discrete'>Olink fill scale for discrete ggplots</h2><span id='topic+olink_fill_discrete'></span>

<h3>Description</h3>

<p>Olink fill scale for discrete ggplots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_fill_discrete(..., alpha = 1, coloroption = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_fill_discrete_+3A_...">...</code></td>
<td>
<p>Optional. Additional arguments to pass to ggplot2::discrete_scale()</p>
</td></tr>
<tr><td><code id="olink_fill_discrete_+3A_alpha">alpha</code></td>
<td>
<p>transparency (optional)</p>
</td></tr>
<tr><td><code id="olink_fill_discrete_+3A_coloroption">coloroption</code></td>
<td>
<p>string, one or more of the following:
c('red', 'orange', 'yellow', 'green', 'teal', 'turqoise', 'lightblue', 'darkblue', 'purple', 'pink')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(ggplot2)

dsub &lt;- subset(diamonds, x &gt; 5 &amp; x &lt; 6 &amp; y &gt; 5 &amp; y &lt; 6)
dsub$diff &lt;- with(dsub, sqrt(abs(x-y))* sign(x-y))

ggplot(dsub, aes(x, y, colour=diff)) +
geom_point() +
 theme_bw() +
 olink_fill_discrete()

</code></pre>

<hr>
<h2 id='olink_fill_gradient'>Olink fill scale for continuous ggplots</h2><span id='topic+olink_fill_gradient'></span>

<h3>Description</h3>

<p>Olink fill scale for continuous ggplots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_fill_gradient(..., alpha = 1, coloroption = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_fill_gradient_+3A_...">...</code></td>
<td>
<p>Optional. Additional arguments to pass to ggplot2::scale_fill_gradientn()</p>
</td></tr>
<tr><td><code id="olink_fill_gradient_+3A_alpha">alpha</code></td>
<td>
<p>transparency (optional)</p>
</td></tr>
<tr><td><code id="olink_fill_gradient_+3A_coloroption">coloroption</code></td>
<td>
<p>string, one or more of the following:
c('red', 'orange', 'yellow', 'green', 'teal', 'turqoise', 'lightblue', 'darkblue', 'purple', 'pink')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(ggplot2)

dsub &lt;- subset(diamonds, x &gt; 5 &amp; x &lt; 6 &amp; y &gt; 5 &amp; y &lt; 6)
dsub$diff &lt;- with(dsub, sqrt(abs(x-y))* sign(x-y))
ggplot(dsub, aes(x, y, colour=diff)) +
geom_point() +
 theme_bw() +
 olink_fill_gradient()

</code></pre>

<hr>
<h2 id='olink_heatmap_plot'>Function to plot a heatmap of the NPX data</h2><span id='topic+olink_heatmap_plot'></span>

<h3>Description</h3>

<p>Generates a heatmap using <code>pheatmap::pheatmap</code> of all samples from NPX data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_heatmap_plot(
  df,
  variable_row_list = NULL,
  variable_col_list = NULL,
  center_scale = TRUE,
  cluster_rows = TRUE,
  cluster_cols = TRUE,
  show_rownames = TRUE,
  show_colnames = TRUE,
  colnames = "both",
  annotation_legend = TRUE,
  fontsize = 10,
  na_col = "black",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_heatmap_plot_+3A_df">df</code></td>
<td>
<p>Data frame in long format with SampleID, NPX, OlinkID, Assay and columns of choice for annotations.</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_variable_row_list">variable_row_list</code></td>
<td>
<p>Columns in <code>df</code> to be annotated for rows in the heatmap.</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_variable_col_list">variable_col_list</code></td>
<td>
<p>Columns in <code>df</code> to be annotated for columns in the heatmap.</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_center_scale">center_scale</code></td>
<td>
<p>Logical. If data should be centered and scaled across assays (default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_cluster_rows">cluster_rows</code></td>
<td>
<p>Logical. Determining if rows should be clustered (default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_cluster_cols">cluster_cols</code></td>
<td>
<p>Logical. Determining if columns should be clustered (default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_show_rownames">show_rownames</code></td>
<td>
<p>Logical. Determining if row names are shown (default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_show_colnames">show_colnames</code></td>
<td>
<p>Logical. Determining if column names are shown (default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_colnames">colnames</code></td>
<td>
<p>Character. Determines how to label the columns. Must be 'assay', 'oid', or 'both' (default 'both').</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_annotation_legend">annotation_legend</code></td>
<td>
<p>Logical. Determining if legend for annotations should be shown (default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_fontsize">fontsize</code></td>
<td>
<p>Fontsize (default 10)</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_na_col">na_col</code></td>
<td>
<p>Color of cells with <code>NA</code> (default black)</p>
</td></tr>
<tr><td><code id="olink_heatmap_plot_+3A_...">...</code></td>
<td>
<p>Additional arguments used in <code>pheatmap::pheatmap</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The values are by default scaled across and centered in the heatmap. Columns
and rows are by default sorted by by dendrogram.
Unique sample names are required.
</p>


<h3>Value</h3>

<p>An object of class <code>ggplot</code>, generated from the <code>gtable</code> returned by <code>pheatmap::pheatmap</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)
npx_data &lt;- npx_data1 %&gt;%
      filter(!stringr::str_detect(SampleID,'CONT'))
try({ # This will fail if ggplotify is not installed
#Heatmap
  olink_heatmap_plot(df=npx_data)

#Heatmap with annotation
  olink_heatmap_plot(df=npx_data, variable_row_list = c('Time','Site'))

#Heatmap with calls from pheatmap
  olink_heatmap_plot(df=npx_data, cutree_rows = 3)
})



</code></pre>

<hr>
<h2 id='olink_iqr'>Compute inter-quartile range (IQR) of multiplied by a fixed value</h2><span id='topic+olink_iqr'></span>

<h3>Description</h3>

<p>Compute inter-quartile range (IQR) of multiplied by a fixed value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_iqr(df, quant_col, iqr_group, iqr_sd)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_iqr_+3A_df">df</code></td>
<td>
<p>Olink dataset</p>
</td></tr>
<tr><td><code id="olink_iqr_+3A_quant_col">quant_col</code></td>
<td>
<p>Character vector of name of quantification column</p>
</td></tr>
<tr><td><code id="olink_iqr_+3A_iqr_group">iqr_group</code></td>
<td>
<p>Grouping for which to compute IQR for</p>
</td></tr>
<tr><td><code id="olink_iqr_+3A_iqr_sd">iqr_sd</code></td>
<td>
<p>Fixed value to multiply IQR with</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Input dataset with two additional columns, iqr and iqr_sd
</p>

<hr>
<h2 id='olink_lmer'>Function which performs a linear mixed model per protein</h2><span id='topic+olink_lmer'></span>

<h3>Description</h3>

<p>Fits a linear mixed effects model for every protein (by OlinkID) in every
panel, using lmerTest::lmer and stats::anova.
The function handles both factor and numerical variables and/or
covariates. <br /><br />
Samples that have no variable information or missing factor levels are
automatically removed from the analysis (specified in a message if verbose = TRUE).
Character columns in the input dataframe are automatically converted to
factors (specified in a message if verbose = TRUE).
Numerical variables are not converted to factors.
If a numerical variable is to be used as a factor, this conversion needs to
be done on the dataframe before the function call. <br /><br />
Crossed analysis, i.e. A*B formula notation, is inferred from the variable
argument in the following cases: <br />
</p>

<ul>
<li><p> c('A','B')
</p>
</li>
<li><p> c('A:B')
</p>
</li>
<li><p> c('A:B', 'B') or c('A:B', 'A')
</p>
</li></ul>

<p>Inference is specified in a message if verbose = TRUE. <br />
For covariates, crossed analyses need to be specified explicitly, i.e. two
main effects will not be expanded with a c('A','B') notation. Main effects
present in the variable takes precedence. <br />
The random variable only takes main effect(s). <br />
The formula notation of the final model is specified in a message
if verbose = TRUE. <br /><br />
Output p-values are adjusted by stats::p.adjust according to the
Benjamini-Hochberg method (“fdr”).
Adjusted p-values are logically evaluated towards adjusted p-value&lt;0.05.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_lmer(
  df,
  variable,
  outcome = "NPX",
  random,
  covariates = NULL,
  model_formula,
  return.covariates = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_lmer_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein
name (Assay), OlinkID, UniProt, 1-2 variables with at least 2 levels.</p>
</td></tr>
<tr><td><code id="olink_lmer_+3A_variable">variable</code></td>
<td>
<p>Single character value or character array.
Variable(s) to test. If length &gt; 1, the included variable
names will be used in crossed analyses .
Also takes ':' or '*' notation.</p>
</td></tr>
<tr><td><code id="olink_lmer_+3A_outcome">outcome</code></td>
<td>
<p>Character. The dependent variable. Default: NPX.</p>
</td></tr>
<tr><td><code id="olink_lmer_+3A_random">random</code></td>
<td>
<p>Single character value or character array.</p>
</td></tr>
<tr><td><code id="olink_lmer_+3A_covariates">covariates</code></td>
<td>
<p>Single character value or character array. Default: NULL.
Covariates to include. Takes ':' or '*' notation. Crossed analysis will not be inferred from main effects.</p>
</td></tr>
<tr><td><code id="olink_lmer_+3A_model_formula">model_formula</code></td>
<td>
<p>(optional) Symbolic description of the model to be
fitted in standard formula notation (e.g. &quot;NPX~A*B + (1|ID)&quot;). If provided,
this will override the <code>outcome</code>, <code>variable</code> and <code>covariates</code>
arguments. Can be a string or of class <code>stats::formula()</code>.</p>
</td></tr>
<tr><td><code id="olink_lmer_+3A_return.covariates">return.covariates</code></td>
<td>
<p>Boolean. Default: False. Returns results for the
covariates. Note: Adjusted p-values will be NA for the covariates.</p>
</td></tr>
<tr><td><code id="olink_lmer_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. Default: True. If information about removed samples,
factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; containing the results of fitting the linear mixed
effects model to every protein by OlinkID, ordered by ascending p-value.
Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>term: &quot;character&quot; term in model
</p>
</li>
<li><p>sumsq: &quot;numeric&quot; sum of square
</p>
</li>
<li><p>meansq: &quot;numeric&quot; mean of square
</p>
</li>
<li><p>NumDF: &quot;integer&quot; numerator of degrees of freedom
</p>
</li>
<li><p>DenDF: &quot;numeric&quot; denominator of decrees of freedom
</p>
</li>
<li><p>statistic: &quot;numeric&quot; value of the statistic
</p>
</li>
<li><p>p.value: &quot;numeric&quot; nominal p-value
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test
(Benjamini&amp;Hochberg)
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or
not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
if (requireNamespace("lme4", quietly = TRUE) &amp; requireNamespace("lmerTest", quietly = TRUE)){
  # Results in model NPX~Time*Treatment+(1|Subject)+(1|Site)
  lmer_results &lt;- olink_lmer(df = npx_data1,
  variable=c("Time", 'Treatment'),
  random = c('Subject', 'Site'))
}

</code></pre>

<hr>
<h2 id='olink_lmer_plot'>Function which performs a point-range plot per protein on a linear mixed model</h2><span id='topic+olink_lmer_plot'></span>

<h3>Description</h3>

<p>Generates a point-range plot faceted by Assay using ggplot and ggplot2::geom_pointrange based on a linear mixed effects model using lmerTest:lmer and emmeans::emmeans.
See <code>olink_lmer</code> for details of input notation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_lmer_plot(
  df,
  variable,
  outcome = "NPX",
  random,
  olinkid_list = NULL,
  covariates = NULL,
  x_axis_variable,
  col_variable = NULL,
  number_of_proteins_per_plot = 6,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_lmer_plot_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID, UniProt, 1-2 variables with at least 2 levels.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_variable">variable</code></td>
<td>
<p>Single character value or character array.
Variable(s) to test. If length &gt; 1, the included variable names will be used in crossed analyses .
Also takes ':' or '*' notation.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_outcome">outcome</code></td>
<td>
<p>Character. The dependent variable. Default: NPX.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_random">random</code></td>
<td>
<p>Single character value or character array.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_olinkid_list">olinkid_list</code></td>
<td>
<p>Character vector indicating which proteins (by OlinkID) for which to create figures.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_covariates">covariates</code></td>
<td>
<p>Single character value or character array. Default: NULL.
Covariates to include. Takes ':' or '*' notation. Crossed analysis will not be inferred from main effects.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_x_axis_variable">x_axis_variable</code></td>
<td>
<p>Character. Which main effect to use as x-axis in the plot.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_col_variable">col_variable</code></td>
<td>
<p>Character. If provided, the interaction effect col_variable:x_axis_variable will be plotted with x_axis_variable on the x-axis and col_variable as color.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_number_of_proteins_per_plot">number_of_proteins_per_plot</code></td>
<td>
<p>Number plots to include in the list of point-range plots. Defaults to 6 plots per figure</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. Default: True. If information about removed samples, factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
<tr><td><code id="olink_lmer_plot_+3A_...">...</code></td>
<td>
<p>coloroption for color ordering</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of objects of class &quot;ggplot&quot; showing point-range plot of NPX (y-axis) over x_axis_variable for each assay (facet), colored by col_variable if provided.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)
if (requireNamespace("lme4", quietly = TRUE) &amp; requireNamespace("lmerTest", quietly = TRUE)){
lmer_results &lt;- olink_lmer(df = npx_data1,
                           variable=c("Time", 'Treatment'),
                           random = c('Subject'))

assay_list &lt;- lmer_results %&gt;%
    filter(Threshold == 'Significant' &amp; term == 'Time:Treatment') %&gt;%
    select(OlinkID) %&gt;%
    distinct() %&gt;%
    pull()

list_of_pointrange_plots &lt;- olink_lmer_plot(df = npx_data1,
                                            variable=c("Time", 'Treatment'),
                                            random = c('Subject'),
                                            x_axis_variable = 'Time',
                                            col_variable = 'Treatment',
                                            verbose=TRUE,
                                            olinkid_list = assay_list,
                                            number_of_proteins_per_plot = 10)
}

</code></pre>

<hr>
<h2 id='olink_lmer_posthoc'>Function which performs a linear mixed model posthoc per protein.</h2><span id='topic+olink_lmer_posthoc'></span>

<h3>Description</h3>

<p>Similar to olink_lmer but performs a post hoc analysis based on a linear mixed model effects model using lmerTest::lmer and emmeans::emmeans on proteins.
See <code>olink_lmer</code> for details of input notation. <br /><br />
The function handles both factor and numerical variables and/or covariates.
Differences in estimated marginal means are calculated for all pairwise levels of a given variable.
Degrees of freedom are estimated using Satterthwaite’s approximation.
The posthoc test for a numerical variable compares the difference in means of the outcome variable (default: NPX) for 1 standard deviation difference in the numerical variable, e.g.
mean NPX at mean(numerical variable) versus mean NPX at mean(numerical variable) + 1*SD(numerical variable).
The output tibble is arranged by ascending Tukey adjusted p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_lmer_posthoc(
  df,
  olinkid_list = NULL,
  variable,
  outcome = "NPX",
  random,
  model_formula,
  effect,
  effect_formula,
  covariates = NULL,
  mean_return = FALSE,
  post_hoc_padjust_method = "tukey",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_lmer_posthoc_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID, UniProt, 1-2 variables with at least 2 levels and subject ID.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_olinkid_list">olinkid_list</code></td>
<td>
<p>Character vector of OlinkID's on which to perform post hoc analysis. If not specified, all assays in df are used.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_variable">variable</code></td>
<td>
<p>Single character value or character array.
Variable(s) to test. If length &gt; 1, the included variable names will be used in crossed analyses .
Also takes ':' or '*' notation.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_outcome">outcome</code></td>
<td>
<p>Character. The dependent variable. Default: NPX.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_random">random</code></td>
<td>
<p>Single character value or character array.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_model_formula">model_formula</code></td>
<td>
<p>(optional) Symbolic description of the model to be fitted in standard formula notation (e.g. &quot;NPX~A*B + (1|ID)&quot;). If provided, this will override the <code>outcome</code>, <code>variable</code> and <code>covariates</code> arguments. Can be a string or of class <code>stats::formula()</code>.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_effect">effect</code></td>
<td>
<p>Term on which to perform post-hoc. Character vector. Must be subset of or identical to variable.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_effect_formula">effect_formula</code></td>
<td>
<p>(optional) A character vector specifying the names of the predictors over which estimated marginal means are desired as defined in the <code>emmeans</code> package. May also be a formula. If provided, this will override the <code>effect</code> argument. See <code>?emmeans::emmeans()</code> for more information.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_covariates">covariates</code></td>
<td>
<p>Single character value or character array. Default: NULL. Covariates to include. Takes ':' or '*' notation. Crossed analysis will not be inferred from main effects.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_mean_return">mean_return</code></td>
<td>
<p>Boolean. If true, returns the mean of each factor level rather than the difference in means (default). Note that no p-value is returned for mean_return = TRUE and no adjustment is performed.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_post_hoc_padjust_method">post_hoc_padjust_method</code></td>
<td>
<p>P-value adjustment method to use for post-hoc comparisons within an assay. Options include <code>tukey</code>, <code>sidak</code>, <code>bonferroni</code> and <code>none</code>.</p>
</td></tr>
<tr><td><code id="olink_lmer_posthoc_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. Default: True. If information about removed samples, factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; containing the results of the pairwise comparisons between given variable levels for proteins specified in olinkid_list (or full df).
Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>term: &quot;character&quot; term in model
</p>
</li>
<li><p>contrast: &quot;character&quot; the groups that were compared
</p>
</li>
<li><p>estimate: &quot;numeric&quot; difference in mean NPX between groups
</p>
</li>
<li><p>conf.low: &quot;numeric&quot; confidence interval for the mean (lower end)
</p>
</li>
<li><p>conf.high: &quot;numeric&quot; confidence interval for the mean (upper end)
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)
if (requireNamespace("lme4", quietly = TRUE) &amp; requireNamespace("lmerTest", quietly = TRUE)){

lmer_results &lt;- olink_lmer(df = npx_data1,
                           variable=c("Time", 'Treatment'),
                           random = c('Subject'))

assay_list &lt;- lmer_results %&gt;%
    filter(Threshold == 'Significant' &amp; term == 'Time:Treatment') %&gt;%
    select(OlinkID) %&gt;%
    distinct() %&gt;%
    pull()

results_lmer_posthoc &lt;- olink_lmer_posthoc(df = npx_data1,
                                           olinkid_list = assay_list,
                                           variable=c("Time", 'Treatment'),
                                           effect = 'Time:Treatment',
                                           random = 'Subject',
                                           verbose = TRUE)

#Estimate treated vs untreated at each timepoint


results_lmer_posthoc &lt;- olink_lmer_posthoc(df = npx_data1,
                                           olinkid_list = assay_list,
                                           model_formula = "NPX~Time*Treatment+(1|Subject)",
                                           effect_formula = "pairwise~Treatment|Time",
                                           verbose = TRUE)
}


</code></pre>

<hr>
<h2 id='olink_lod'>Calculate LOD using Negative Controls or Fixed LOD</h2><span id='topic+olink_lod'></span>

<h3>Description</h3>

<p>Calculate LOD using Negative Controls or Fixed LOD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_lod(data, lod_file_path = NULL, lod_method = "NCLOD")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_lod_+3A_data">data</code></td>
<td>
<p>npx data file</p>
</td></tr>
<tr><td><code id="olink_lod_+3A_lod_file_path">lod_file_path</code></td>
<td>
<p>location of lod file from Olink. Only needed if
lod_method = &quot;FixedLOD&quot; or &quot;Both&quot;. Default <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="olink_lod_+3A_lod_method">lod_method</code></td>
<td>
<p>method for calculating LOD using either &quot;FixedLOD&quot; or
negative controls (&quot;NCLOD&quot;), or both (&quot;Both&quot;). Default <code>NCLOD</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with 2 additional columns, LOD and PCNormalizedLOD if <code>lod_method</code> is FixedLOD or NCLOD. When <code>Normalization = "Plate Control"</code>, LOD and PCNormalizedLOD are identical.
</p>
<p>If <code>lod_method</code> is &quot;Both&quot;, 4 additional columns will be added:
</p>

<ul>
<li><p> NCLOD - LOD calculated from negative controls and normalized based on normalization column
</p>
</li>
<li><p> NCPCNormalizedLOD - PC Normalized LOD calculated from negative controls
</p>
</li>
<li><p> FixedLOD - LOD calculated from fixed LOD file and normalized based on normalization column
</p>
</li>
<li><p> FixedPCNormalizedLOD - PC Normalized LOD calculated from fixed LOD file
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
   \donttest{
  try({ # This will fail if the files do not exist.

  # Import NPX data
    npx_data &lt;- read_NPX("path/to/npx_file")

  # Estimate LOD from negative controls
    npx_data_lod_NC &lt;- olink_lod(data = npx_data,  lod_method = "NCLOD")

  # Estimate LOD from fixed LOD
  ## Locate the fixed LOD file
    lod_file_path &lt;- "path/to/lod_file"

    npx_data_lod_Fixed &lt;- olink_lod(data = npx_data,
                                    lod_file_path = lod_file_path,
                                    lod_method = "FixedLOD")
     })
  }

## End(Not run)

</code></pre>

<hr>
<h2 id='olink_median'>Compute median of quantified value</h2><span id='topic+olink_median'></span>

<h3>Description</h3>

<p>Compute median of quantified value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_median(df, quant_col, median_group)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_median_+3A_df">df</code></td>
<td>
<p>Olink dataset</p>
</td></tr>
<tr><td><code id="olink_median_+3A_quant_col">quant_col</code></td>
<td>
<p>Character vector of name of quantification column</p>
</td></tr>
<tr><td><code id="olink_median_+3A_median_group">median_group</code></td>
<td>
<p>Grouping for which to compute median for</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Input dataset with one additional columns, median
</p>

<hr>
<h2 id='olink_median_iqr_outlier'>Compute outliers based on median +/- iqr_sd * IQR</h2><span id='topic+olink_median_iqr_outlier'></span>

<h3>Description</h3>

<p>Compute outliers based on median +/- iqr_sd * IQR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_median_iqr_outlier(df, quant_col, group, iqr_sd)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_median_iqr_outlier_+3A_df">df</code></td>
<td>
<p>Olink dataset</p>
</td></tr>
<tr><td><code id="olink_median_iqr_outlier_+3A_quant_col">quant_col</code></td>
<td>
<p>Character vector of name of quantification column</p>
</td></tr>
<tr><td><code id="olink_median_iqr_outlier_+3A_group">group</code></td>
<td>
<p>Grouping for which to compute median for</p>
</td></tr>
<tr><td><code id="olink_median_iqr_outlier_+3A_iqr_sd">iqr_sd</code></td>
<td>
<p>Fixed value to multiply IQR with</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Boolean vector with length equal to the number of input rows
indicating outlier.
</p>

<hr>
<h2 id='olink_norm_input_assay_overlap'>Check <var>datasets</var> and <var>reference_medians</var> for Olink identifiers not
shared across datasets.</h2><span id='topic+olink_norm_input_assay_overlap'></span>

<h3>Description</h3>

<p>Check <var>datasets</var> and <var>reference_medians</var> for Olink identifiers not
shared across datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_assay_overlap(
  lst_df,
  reference_medians,
  lst_cols,
  norm_mode = norm_mode
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_assay_overlap_+3A_lst_df">lst_df</code></td>
<td>
<p>Named list of datasets to be normalized.</p>
</td></tr>
<tr><td><code id="olink_norm_input_assay_overlap_+3A_reference_medians">reference_medians</code></td>
<td>
<p>Dataset with columns &quot;OlinkID&quot; and &quot;Reference_NPX&quot;.
Used for reference median normalization.</p>
</td></tr>
<tr><td><code id="olink_norm_input_assay_overlap_+3A_lst_cols">lst_cols</code></td>
<td>
<p>Named list of vectors with the required column names for each
dataset in <var>lst_df</var>.</p>
</td></tr>
<tr><td><code id="olink_norm_input_assay_overlap_+3A_norm_mode">norm_mode</code></td>
<td>
<p>Character string indicating the type of normalization to be
performed. Expecting one of
bridge, subset, ref_median or norm_cross_product. # nolint</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing <var>lst_df</var> and <var>reference_medians</var>
will assays shared across all datasets.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='olink_norm_input_check'>Check inputs of <code><a href="#topic+olink_normalization">olink_normalization</a></code> function.</h2><span id='topic+olink_norm_input_check'></span>

<h3>Description</h3>

<p>This function is a wrapper of multiple help functions which check the inputs
of the <code><a href="#topic+olink_normalization">olink_normalization</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_check(
  df1,
  df2,
  overlapping_samples_df1,
  overlapping_samples_df2,
  df1_project_nr,
  df2_project_nr,
  reference_project,
  reference_medians
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_check_+3A_df1">df1</code></td>
<td>
<p>First dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_+3A_df2">df2</code></td>
<td>
<p>Second dataset to be used in normalization.</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_+3A_overlapping_samples_df1">overlapping_samples_df1</code></td>
<td>
<p>Samples to be used for adjustment factor
calculation in df1 (required).</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_+3A_overlapping_samples_df2">overlapping_samples_df2</code></td>
<td>
<p>Samples to be used for adjustment factor
calculation in df2.</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_+3A_df1_project_nr">df1_project_nr</code></td>
<td>
<p>Project name of first dataset (df1).</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_+3A_df2_project_nr">df2_project_nr</code></td>
<td>
<p>Project name of first dataset (df2).</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_+3A_reference_project">reference_project</code></td>
<td>
<p>Project name of reference_project. Should be one of
<var>df1_project_nr</var> or <var>df2_project_nr</var>. Indicates the project to which
the other project is adjusted to.</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_+3A_reference_medians">reference_medians</code></td>
<td>
<p>Dataset with columns &quot;OlinkID&quot; and &quot;Reference_NPX&quot;.
Used for reference median normalization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following checks are performed:
</p>

<ul>
<li> <p><code><a href="#topic+olink_norm_input_validate">olink_norm_input_validate</a></code>:
</p>

<ul>
<li><p> Determines the normalization to be performed by intersecting inputs with
internal global variable <code>olink_norm_mode_combos</code>.
</p>
</li>
<li><p> Returns the type of normalization to be performed from
<code>olink_norm_modes</code>.
</p>
</li>
<li><p> Message with the normalization type.
</p>
</li>
<li><p> Error message if input is invalid.
</p>
</li></ul>

</li>
<li> <p><code><a href="#topic+olink_norm_input_class">olink_norm_input_class</a></code>:
</p>

<ul>
<li><p> Checks if all inputs are of the expected class:
</p>

<ul>
<li> <p><code>df1</code>, <code>df2</code> and <code>reference_medians</code>: tibble or R6 ArrowObject
</p>
</li>
<li> <p><code>overlapping_samples_df1</code>, <code>overlapping_samples_df2</code>,
<code>df1_project_nr</code>, <code>df2_project_nr</code> and <code>reference_project</code>: Character
vector
</p>
</li></ul>

</li>
<li><p> Also checks the validity of names of project and reference project.
</p>
</li>
<li><p> Error if invalid input classes are detected.
</p>
</li></ul>

</li>
<li> <p><code><a href="#topic+olink_norm_input_check_df_cols">olink_norm_input_check_df_cols</a></code>:
</p>

<ul>
<li><p> Detects the column names of input datasets <code>df1</code> and <code>df2</code> to allow for
alternative names.
</p>
</li>
<li><p> Returns named list of column names to use downstream.
</p>
</li>
<li><p> Warning if <code>Normalization</code> column missing from all datasets.
</p>
</li>
<li><p> Warning if <code>LOD</code> is missing or if there are multiple <code>LOD</code> columns.
</p>
</li>
<li><p> Error if required columns are missing.
</p>
</li>
<li><p> Error if not all input datasets have or lack <code>Normalization</code> column.
</p>
</li>
<li><p> Error if input datasets have been quantified with different methods.
</p>
</li></ul>

</li>
<li> <p><code><a href="#topic+olink_norm_input_ref_medians">olink_norm_input_ref_medians</a></code>:
</p>

<ul>
<li><p> Checks validity of dataset containing <code>reference_medians</code>.
</p>
</li>
<li><p> Error if required columns are missing based on
<code>olink_norm_ref_median_cols</code>.
</p>
</li>
<li><p> Error if columns are not of the correct class bases on
<code>olink_norm_ref_median_cols</code>.
</p>
</li>
<li><p> Error if there duplicate assay identifiers.
</p>
</li></ul>

</li>
<li> <p><code><a href="#topic+olink_norm_input_check_samples">olink_norm_input_check_samples</a></code>:
</p>

<ul>
<li><p> Check character vectors of reference sample identifiers for:
</p>

<ul>
<li><p> Being present in <code>df1</code> and/or <code>df2</code>.
</p>
</li>
<li><p> Duplicate identifiers.
</p>
</li></ul>

</li></ul>

</li>
<li> <p><code><a href="#topic+olink_norm_input_clean_assays">olink_norm_input_clean_assays</a></code>:
</p>

<ul>
<li><p> Returns a named list with the updated <code>df1</code>, <code>df2</code> and/or
<code>reference_medians</code>.
</p>
</li>
<li><p> Removes assays that are not of the format OID followed by 5 digits.
</p>
</li>
<li><p> Removes assays that are marked with <code>Normalization = EXCLUDED</code>.
</p>
</li></ul>

</li>
<li> <p><code><a href="#topic+olink_norm_input_assay_overlap">olink_norm_input_assay_overlap</a></code>:
</p>

<ul>
<li><p> Returns a named list with the updated <code>df1</code>, <code>df2</code> and/or
<code>reference_medians</code>.
</p>
</li>
<li><p> Remove assays not shared between <code>df1</code> and <code>df2</code>, or between <code>df1</code> and
<code>reference_medians</code>.
</p>
</li></ul>

</li>
<li> <p><code><a href="#topic+olink_norm_input_norm_method">olink_norm_input_norm_method</a></code>:
</p>

<ul>
<li><p> Check if all assays in <code>df1</code> and <code>df2</code> have been originally normalized
with the same method &quot;Intensity&quot; or &quot;Plate control&quot;.
</p>
</li>
<li><p> Warning is thrown if not.
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p>Named list of updated inputs to use for normalization:
</p>

<ul>
<li> <p><code>df1</code>: dataset df1.
</p>
</li>
<li> <p><code>df2</code>: <code>NULL</code> if reference median normalization, or dataset df2.
</p>
</li>
<li> <p><code>overlapping_samples_df1</code>: character vector of reference samples from df1.
</p>
</li>
<li> <p><code>overlapping_samples_df2</code>: <code>NULL</code> if reference median normalization, or
character vector of reference samples from df1.
</p>
</li>
<li> <p><code>df1_project_nr</code>: name of df1 project.
</p>
</li>
<li> <p><code>df2_project_nr</code>: <code>NULL</code> if reference median normalization, or name of df2
project.
</p>
</li>
<li> <p><code>reference_project</code>: <code>NULL</code> if reference median normalization, or name of
reference project.
</p>
</li>
<li> <p><code>reference_medians</code>: <code>NULL</code> if bridge or subset normalization, or dataset
with reference_medians.
</p>
</li>
<li> <p><code>df1_cols</code>: column names of df1 to use downstream.
</p>
</li>
<li> <p><code>df2_cols</code>: <code>NULL</code> if reference median normalization, or column names of
df2 to use downstream.
</p>
</li>
<li> <p><code>norm_mode</code>: one of bridge, subset, ref_median, and norm_cross_product
indicating the normalization to be performed.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='olink_norm_input_check_df_cols'>Check columns of a list of datasets to be normalized.</h2><span id='topic+olink_norm_input_check_df_cols'></span>

<h3>Description</h3>

<p>This function takes as input a named list of datasets and checks if their
columns allow the normalization to be performed. The input may contain
&quot;tibble&quot;, &quot;ArrowTable&quot; or a mixture of them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_check_df_cols(lst_df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_check_df_cols_+3A_lst_df">lst_df</code></td>
<td>
<p>Named list of datasets to be normalized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list of vectors with the required column names for each dataset
in <var>lst_df</var> if no error.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# One dataset
OlinkAnalyze:::olink_norm_input_check_df_cols(
  lst_df = list(
    "p1" = npx_data1
  ) |&gt;
    lapply(function(l_df) {
      l_df |&gt;
        dplyr::select(
          -dplyr::any_of(c("Normalization"))
        )
     })
  )

# Two datasets
OlinkAnalyze:::olink_norm_input_check_df_cols(
  lst_df = list(
    "p1" = npx_data1,
    "p2" = npx_data2
  ) |&gt;
    lapply(function(l_df) {
      l_df |&gt;
        dplyr::select(
          -dplyr::any_of(c("Normalization"))
        )
     })
  )

# Multiple datasets
OlinkAnalyze:::olink_norm_input_check_df_cols(
  lst_df = list(
    "p1" = npx_data1,
    "p2" = npx_data2,
    "p3" = npx_data1,
    "p4" = npx_data2
  ) |&gt;
    lapply(function(l_df) {
      l_df |&gt;
        dplyr::select(
          -dplyr::any_of(c("Normalization"))
        )
     })
  )


</code></pre>

<hr>
<h2 id='olink_norm_input_check_samples'>Check reference samples to be used for normalization</h2><span id='topic+olink_norm_input_check_samples'></span>

<h3>Description</h3>

<p>This function takes as input a two named lists of character vectors with
matching names and checks the validity of the reference samples. In case of 1
set of df samples, then all checks are skipped as reference median
normalization is to be performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_check_samples(lst_df_samples, lst_ref_samples, norm_mode)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_check_samples_+3A_lst_df_samples">lst_df_samples</code></td>
<td>
<p>Named list of all sample identifiers from datasets to
be normalized.</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_samples_+3A_lst_ref_samples">lst_ref_samples</code></td>
<td>
<p>Named list of reference sample identifiers to be used
for normalization.</p>
</td></tr>
<tr><td><code id="olink_norm_input_check_samples_+3A_norm_mode">norm_mode</code></td>
<td>
<p>Character string indicating the type of normalization to be
performed. Expecting one of
bridge, subset, ref_median or norm_cross_product. # nolint</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code> if no warning or error.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Reference median normalization
OlinkAnalyze:::olink_norm_input_check_samples(
  lst_df_samples = list(
    "p1" = unique(npx_data1$SampleID)
  ),
  lst_ref_samples = list(
    "p1" = npx_data1 |&gt;
      dplyr::filter(
        !grepl(pattern = "CONTROL_SAMPLE",
        x = .data[["SampleID"]],
        fixed = TRUE)
      ) |&gt;
      dplyr::pull(.data[["SampleID"]]) |&gt;
      unique() |&gt;
      sort() |&gt;
      head(n = 6L)
  ),
  norm_mode = "ref_median"
)

# Bridge normalization
ref_samples_bridge &lt;- intersect(x = npx_data1$SampleID,
                                y = npx_data2$SampleID) |&gt;
  (\(x) x[!grepl(pattern = "CONTROL_SAMPLE", x = x, fixed = TRUE)])()

OlinkAnalyze:::olink_norm_input_check_samples(
  lst_df_samples = list(
    "p1" = unique(npx_data1$SampleID),
    "p2" = unique(npx_data2$SampleID)
  ),
  lst_ref_samples = list(
    "p1" = ref_samples_bridge,
    "p2" = ref_samples_bridge
  ),
  norm_mode = "bridge"
)

# Subset normalization
ref_samples_subset_1 &lt;- npx_data1 |&gt;
  dplyr::filter(
    !grepl(pattern = "CONTROL_SAMPLE",
           x = .data[["SampleID"]],
           fixed = TRUE)
    &amp; .data[["QC_Warning"]] == "Pass"
  ) |&gt;
  dplyr::pull(
    .data[["SampleID"]]
  ) |&gt;
  unique()
ref_samples_subset_2 &lt;- npx_data2 |&gt;
  dplyr::filter(
    !grepl(pattern = "CONTROL_SAMPLE",
           x = .data[["SampleID"]],
           fixed = TRUE)
    &amp; .data[["QC_Warning"]] == "Pass"
  ) |&gt;
  dplyr::pull(
    .data[["SampleID"]]
  ) |&gt;
  unique()

OlinkAnalyze:::olink_norm_input_check_samples(
  lst_df_samples = list(
    "p1" = unique(npx_data1$SampleID),
    "p2" = unique(npx_data2$SampleID)
  ),
  lst_ref_samples = list(
    "p1" = ref_samples_subset_1,
    "p2" = ref_samples_subset_2
  ),
  norm_mode = "subset"
)


</code></pre>

<hr>
<h2 id='olink_norm_input_class'>Check classes of input in olink_normalization function</h2><span id='topic+olink_norm_input_class'></span>

<h3>Description</h3>

<p>Check if <var>df1</var>, <var>df2</var> and/or <var>reference_medians</var> are tibble or
ArrowDataset datasets; if <var>overlapping_samples_df1</var> and/or
<var>overlapping_samples_df2</var> are character vectors; and if
<var>df1_project_nr</var>, <var>df2_project_nr</var> and/or <var>reference_project</var> are
scalar character vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_class(
  df1,
  df2,
  overlapping_samples_df1,
  overlapping_samples_df2,
  df1_project_nr,
  df2_project_nr,
  reference_project,
  reference_medians,
  norm_mode
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_class_+3A_df1">df1</code></td>
<td>
<p>First dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="olink_norm_input_class_+3A_df2">df2</code></td>
<td>
<p>Second dataset to be used in normalization.</p>
</td></tr>
<tr><td><code id="olink_norm_input_class_+3A_overlapping_samples_df1">overlapping_samples_df1</code></td>
<td>
<p>Samples to be used for adjustment factor
calculation in df1 (required).</p>
</td></tr>
<tr><td><code id="olink_norm_input_class_+3A_overlapping_samples_df2">overlapping_samples_df2</code></td>
<td>
<p>Samples to be used for adjustment factor
calculation in df2.</p>
</td></tr>
<tr><td><code id="olink_norm_input_class_+3A_df1_project_nr">df1_project_nr</code></td>
<td>
<p>Project name of first dataset (df1).</p>
</td></tr>
<tr><td><code id="olink_norm_input_class_+3A_df2_project_nr">df2_project_nr</code></td>
<td>
<p>Project name of first dataset (df2).</p>
</td></tr>
<tr><td><code id="olink_norm_input_class_+3A_reference_project">reference_project</code></td>
<td>
<p>Project name of reference_project. Should be one of
<var>df1_project_nr</var> or <var>df2_project_nr</var>. Indicates the project to which
the other project is adjusted to.</p>
</td></tr>
<tr><td><code id="olink_norm_input_class_+3A_reference_medians">reference_medians</code></td>
<td>
<p>Dataset with columns &quot;OlinkID&quot; and &quot;Reference_NPX&quot;.
Used for reference median normalization.</p>
</td></tr>
<tr><td><code id="olink_norm_input_class_+3A_norm_mode">norm_mode</code></td>
<td>
<p>Scalar character from <var>olink_norm_modes</var> with the
normalization to be performed. Output from
<code><a href="#topic+olink_norm_input_validate">olink_norm_input_validate</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code> unless there is an error
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='olink_norm_input_clean_assays'>Check <var>datasets</var> and <var>reference_medians</var> for unexpected Olink
identifiers or excluded assays</h2><span id='topic+olink_norm_input_clean_assays'></span>

<h3>Description</h3>

<p>Check <var>datasets</var> and <var>reference_medians</var> for unexpected Olink
identifiers or excluded assays
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_clean_assays(lst_df, reference_medians, lst_cols, norm_mode)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_clean_assays_+3A_lst_df">lst_df</code></td>
<td>
<p>Named list of datasets to be normalized.</p>
</td></tr>
<tr><td><code id="olink_norm_input_clean_assays_+3A_reference_medians">reference_medians</code></td>
<td>
<p>Dataset with columns &quot;OlinkID&quot; and &quot;Reference_NPX&quot;.
Used for reference median normalization.</p>
</td></tr>
<tr><td><code id="olink_norm_input_clean_assays_+3A_lst_cols">lst_cols</code></td>
<td>
<p>Named list of vectors with the required column names for each
dataset in <var>lst_df</var>.</p>
</td></tr>
<tr><td><code id="olink_norm_input_clean_assays_+3A_norm_mode">norm_mode</code></td>
<td>
<p>Character string indicating the type of normalization to be
performed. Expecting one of
bridge, subset, ref_median or norm_cross_product. # nolint</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing <var>lst_df</var> and <var>reference_medians</var>
stripped from unexpected Olink identifiers or excluded assays
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='olink_norm_input_cross_product'>Check if bridge or cross-platform normalization</h2><span id='topic+olink_norm_input_cross_product'></span>

<h3>Description</h3>

<p>A function to check whether we are to perform simple bridge normalization, or
cross-platform (Olink Explore 3072 - Olink Explore HT/Olink Reveal)
normalization.
</p>
<p>The function uses the internal dataset <var>eHT_e3072_mapping</var> to determine
the product source of each dataset. If both datasets originate from the same
Olink product, then it will return
bridge. If the datasets to be normalized
originate from Olink Explore HT and Olink Explore 3072
or Olink Reveal and Olink Explore 3072, it will return
norm_cross_product. In any other case an
error is thrown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_cross_product(
  lst_df,
  lst_cols,
  reference_project,
  product_ids,
  ref_ids
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_cross_product_+3A_lst_df">lst_df</code></td>
<td>
<p>Named list of datasets to be normalized.</p>
</td></tr>
<tr><td><code id="olink_norm_input_cross_product_+3A_lst_cols">lst_cols</code></td>
<td>
<p>Named list of vectors with the required column names for each
dataset in <var>lst_df</var>.</p>
</td></tr>
<tr><td><code id="olink_norm_input_cross_product_+3A_reference_project">reference_project</code></td>
<td>
<p>Project name of reference_project. Should be one of
<var>df1_project_nr</var> or <var>df2_project_nr</var>. Indicates the project to which
the other project is adjusted to.</p>
</td></tr>
<tr><td><code id="olink_norm_input_cross_product_+3A_product_ids">product_ids</code></td>
<td>
<p>Named character vector with the Olink product name that
each input dataset matches to.</p>
</td></tr>
<tr><td><code id="olink_norm_input_cross_product_+3A_ref_ids">ref_ids</code></td>
<td>
<p>Named character vector with <var>df1_project_nr</var> and
<var>df2_project_nr</var> marked as &quot;ref&quot; and &quot;not_ref&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character string indicating the type of normalization to be
performed. One of
bridge, subset, ref_median or norm_cross_product. # nolint
And the updated list of datasets in case of cross-platform normalization.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='olink_norm_input_norm_method'>Check <var>datasets</var> and <var>reference_medians</var> for Olink identifiers not
shared across datasets.</h2><span id='topic+olink_norm_input_norm_method'></span>

<h3>Description</h3>

<p>Check <var>datasets</var> and <var>reference_medians</var> for Olink identifiers not
shared across datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_norm_method(lst_df, lst_cols)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_norm_method_+3A_lst_df">lst_df</code></td>
<td>
<p>Named list of datasets to be normalized.</p>
</td></tr>
<tr><td><code id="olink_norm_input_norm_method_+3A_lst_cols">lst_cols</code></td>
<td>
<p>Named list of vectors with the required column names for each
dataset in <var>lst_df</var>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code> if all assays are normalized with the same approach.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti;
Kathleen Nevola
</p>

<hr>
<h2 id='olink_norm_input_ref_medians'>Check datasets of <var>reference_medians</var></h2><span id='topic+olink_norm_input_ref_medians'></span>

<h3>Description</h3>

<p>Check datasets of <var>reference_medians</var>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_ref_medians(reference_medians)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_ref_medians_+3A_reference_medians">reference_medians</code></td>
<td>
<p>Dataset with columns &quot;OlinkID&quot; and &quot;Reference_NPX&quot;.
Used for reference median normalization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code> otherwise error.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='olink_norm_input_validate'>Validate inputs of normalization function</h2><span id='topic+olink_norm_input_validate'></span>

<h3>Description</h3>

<p>This function takes as input some of the inputs of the Olink normalization
function and checks the validity of the input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_input_validate(
  df1,
  df2,
  overlapping_samples_df1,
  overlapping_samples_df2,
  reference_medians
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_input_validate_+3A_df1">df1</code></td>
<td>
<p>First dataset to be used in normalization (required).</p>
</td></tr>
<tr><td><code id="olink_norm_input_validate_+3A_df2">df2</code></td>
<td>
<p>Second dataset to be used in normalization.</p>
</td></tr>
<tr><td><code id="olink_norm_input_validate_+3A_overlapping_samples_df1">overlapping_samples_df1</code></td>
<td>
<p>Samples to be used for adjustment factor
calculation in df1 (required).</p>
</td></tr>
<tr><td><code id="olink_norm_input_validate_+3A_overlapping_samples_df2">overlapping_samples_df2</code></td>
<td>
<p>Samples to be used for adjustment factor
calculation in df2.</p>
</td></tr>
<tr><td><code id="olink_norm_input_validate_+3A_reference_medians">reference_medians</code></td>
<td>
<p>Dataset with columns &quot;OlinkID&quot; and &quot;Reference_NPX&quot;.
Used for reference median normalization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Depending on the input the function will return:
</p>

<ul>
<li> <p><strong>Error</strong>: if the required components are lacking from the input
or if the normalization cannot be performed.
</p>
</li>
<li> <p><strong>Warning</strong>: if the normalization can be determined but extra
inputs are provided. This will be followed by a message and the type of
normalization to be performed.
</p>
</li>
<li> <p><strong>Message</strong>: Information about the type of
normalization to be performed.
</p>
</li></ul>

<p><strong>Note</strong> that input are passed directly from the main
<code><a href="#topic+olink_normalization">olink_normalization</a></code> function.
</p>


<h3>Value</h3>

<p>Scalar character from <var>olink_norm_modes</var> if normalization can be
determined from the input, otherwise see details.
</p>


<h3>Author(s)</h3>

<p>Klev Diamanti
</p>

<hr>
<h2 id='olink_norm_product_id'>Identify names of product for each project</h2><span id='topic+olink_norm_product_id'></span>

<h3>Description</h3>

<p>Identify names of product for each project
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_product_id(lst_df, lst_cols)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_product_id_+3A_lst_df">lst_df</code></td>
<td>
<p>Named list of datasets to be normalized.</p>
</td></tr>
<tr><td><code id="olink_norm_product_id_+3A_lst_cols">lst_cols</code></td>
<td>
<p>Named list of vectors with the required column names for each
dataset in <var>lst_df</var>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named character vector with the Olink product name that each input
dataset matches to.
</p>


<h3>Author(s)</h3>

<p>Kathy Nevola
Klev Diamanti
</p>

<hr>
<h2 id='olink_norm_reference_id'>Identify reference project.</h2><span id='topic+olink_norm_reference_id'></span>

<h3>Description</h3>

<p>Identify reference project.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_norm_reference_id(lst_product, reference_project)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_norm_reference_id_+3A_lst_product">lst_product</code></td>
<td>
<p>Named character vector with the Olink product name that
each input dataset matches to.</p>
</td></tr>
<tr><td><code id="olink_norm_reference_id_+3A_reference_project">reference_project</code></td>
<td>
<p>Project name of reference_project. Should be one of
<var>df1_project_nr</var> or <var>df2_project_nr</var>. Indicates the project to which
the other project is adjusted to.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named character vector with <var>df1_project_nr</var> and
<var>df2_project_nr</var> marked as &quot;ref&quot; and &quot;not_ref&quot;.
</p>


<h3>Author(s)</h3>

<p>Kathy Nevola
Klev Diamanti
</p>

<hr>
<h2 id='olink_normalization'>Normalize two Olink datasets</h2><span id='topic+olink_normalization'></span>

<h3>Description</h3>

<p>Normalizes two Olink datasets to each other, or one Olink dataset to a
reference set of medians values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization(
  df1,
  df2 = NULL,
  overlapping_samples_df1,
  overlapping_samples_df2 = NULL,
  df1_project_nr = "P1",
  df2_project_nr = "P2",
  reference_project = "P1",
  reference_medians = NULL,
  format = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_+3A_df1">df1</code></td>
<td>
<p>First dataset to be used for normalization (required).</p>
</td></tr>
<tr><td><code id="olink_normalization_+3A_df2">df2</code></td>
<td>
<p>Second dataset to be used for normalization. Required for bridge
and subset normalization.</p>
</td></tr>
<tr><td><code id="olink_normalization_+3A_overlapping_samples_df1">overlapping_samples_df1</code></td>
<td>
<p>Character vector of samples to be used for the
calculation of adjustment factors in <code>df1</code> (required).</p>
</td></tr>
<tr><td><code id="olink_normalization_+3A_overlapping_samples_df2">overlapping_samples_df2</code></td>
<td>
<p>Character vector of samples to be used for the
calculation of adjustment factors in <code>df2</code>. Required for subset
normalization.</p>
</td></tr>
<tr><td><code id="olink_normalization_+3A_df1_project_nr">df1_project_nr</code></td>
<td>
<p>Project name of first dataset (required).</p>
</td></tr>
<tr><td><code id="olink_normalization_+3A_df2_project_nr">df2_project_nr</code></td>
<td>
<p>Project name of second dataset. Required for bridge and
subset normalization.</p>
</td></tr>
<tr><td><code id="olink_normalization_+3A_reference_project">reference_project</code></td>
<td>
<p>Project to be used as reference project. Should
be one of <code>df1_project_nr</code> and <code>df2_project_nr</code>. Required for bridge and
subset normalization.</p>
</td></tr>
<tr><td><code id="olink_normalization_+3A_reference_medians">reference_medians</code></td>
<td>
<p>Dataset with columns &quot;OlinkID&quot; and &quot;Reference_NPX&quot;.
Required for reference median normalization.</p>
</td></tr>
<tr><td><code id="olink_normalization_+3A_format">format</code></td>
<td>
<p>Boolean that controls whether the normalized dataset will be
formatted for input to downstream analysis. Only applicable for cross-product
bridge normalization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function handles four different types of normalization:
</p>

<ul>
<li> <p><strong>Bridge normalization</strong>: One of the datasets is adjusted to another
using overlapping samples (bridge samples). Overlapping samples need to have
the same identifiers in both datasets. Normalization is performed using the
median of the pair-wise differences between the bridge samples in the two
datasets. The two datasets are provided as <code>df1</code> and <code>df2</code>, and the one
being adjusted to is specified in the input <code>reference_project</code>; overlapping
samples are specified in <code>overlapping_samples_df1</code>. Only
<code>overlapping_samples_df1</code> should be provided regardless of the dataset used
as <code>reference_project</code>.
</p>
</li>
<li> <p><strong>Subset normalization</strong>: One of the datasets is adjusted to another
using a subset of samples from each. Normalization is performed using the
differences of the medians between the subsets from the two datasets. Both
<code>overlapping_samples_df1</code> and <code>overlapping_samples_df2</code> need to be provided,
and sample identifiers do not need to be the same.
</p>

<ul>
<li><p> A special case of subset normalization occurs when all samples (except
control samples and samples with QC warnings) from each dataset are used
for normalization; this special case is called intensity normalization. In
intensity normalization all unique sample identifiers from <code>df1</code> are
provided as input in <code>overlapping_samples_df1</code> and all unique sample
identifiers from <code>df2</code> are provided as input in <code>overlapping_samples_df2</code>.
</p>
</li></ul>

</li>
<li> <p><strong>Reference median normalization</strong>: One of the datasets (<code>df1</code>) is
adjusted to a predefined set of adjustment factors. This is effectively
subset normalization, but using differences of medians to pre-recorded
median values. <code>df1</code>, <code>overlapping_samples_df1</code>, <code>df1_project_nr</code> and
<code>reference_medians</code> need to be specified. Dataset <code>df1</code> is normalized using
the differences in median between the overlapping samples and the reference
medians.
</p>
</li>
<li> <p><strong>Cross-product normalization</strong>: One of the datasets is adjusted to
another using the median of pair-wise differences of overlapping samples
(bridge samples) or quantile smoothing using overlapping
samples as reference to adjust the distributions. Overlapping samples need
to have the same identifiers in both datasets. The two datasets are provided
as <code>df1</code> and <code>df2</code>, and the one being adjusted to is specified in the input
<code>reference_project</code>; <strong>Note that</strong> in cross-product normalization the
reference project is predefined, and in case the argument
<code>reference_project</code> does not match the expected reference project an error
will be returned. Overlapping samples are specified in
<code>overlapping_samples_df1</code>. Only <code>overlapping_samples_df1</code> should be provided
regardless of the dataset used as <code>reference_project</code>. This functionality
<strong>does not</strong> modify the column with original quantification values
(e.g. NPX), instead it normalizes it with 2 different approaches in columns
&quot;MedianCenteredNPX&quot; and &quot;QSNormalizedNPX&quot;, and provides a recommendation in
&quot;BridgingRecommendation&quot; about which of the two columns is to be used.
</p>
</li></ul>

<p>The output dataset is <code>df1</code> if reference median normalization, or <code>df2</code>
appended to <code>df1</code> if bridge, subset or cross-product normalization. The
output dataset contains all original columns from the original dataset(s),
and the columns:
</p>

<ul>
<li><p> &quot;Project&quot; and &quot;Adj_factor&quot; in case of reference median, bridge and subset
normalization. The former marks the project of origin based on
<code>df1_project_nr</code> and <code>df2_project_nr</code>, and the latter the adjustment factor
that was applied to the non-reference dataset.
</p>
</li>
<li><p> &quot;Project&quot;, &quot;OlinkID_E3072&quot;, &quot;MedianCenteredNPX&quot;, &quot;QSNormalizedNPX&quot;,
&quot;BridgingRecommendation&quot; in case of cross-product normalization. The columns
correspond to the project of origin based on <code>df1_project_nr</code> and
<code>df2_project_nr</code>, the assay identifier in the non-reference project, the
bridge-normalized quantification value, the quantile smoothing-normalized
quantification value, and the recommendation about which of the two
normalized values is more suitable for downstream analysis.
</p>
</li></ul>



<h3>Value</h3>

<p>Tibble or ArrowObject with the normalized dataset.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# prepare datasets
npx_df1 &lt;- npx_data1 |&gt;
  dplyr::mutate(
    Normalization = "Intensity"
  )
npx_df2 &lt;- npx_data2 |&gt;
  dplyr::mutate(
    Normalization = "Intensity"
  )

# bridge normalization

# overlapping samples - exclude control samples
overlap_samples &lt;- intersect(x = npx_df1$SampleID,
                             y = npx_df2$SampleID) |&gt;
  (\(x) x[!grepl("^CONTROL_SAMPLE", x)])()

# normalize
olink_normalization(
  df1 = npx_df1,
  df2 = npx_df2,
  overlapping_samples_df1 = overlap_samples,
  df1_project_nr = "P1",
  df2_project_nr = "P2",
  reference_project = "P1"
)

# subset normalization

# find a suitable subset of samples from each dataset:
# exclude control samples
# exclude samples that do not pass QC
df1_samples &lt;- npx_df1 |&gt;
  dplyr::group_by(
    dplyr::pick(
      dplyr::all_of("SampleID")
    )
  )|&gt;
  dplyr::filter(
    all(.data[["QC_Warning"]] == 'Pass')
  ) |&gt;
  dplyr::ungroup() |&gt;
  dplyr::filter(
    !grepl(pattern = "^CONTROL_SAMPLE", x = .data[["SampleID"]])
  ) |&gt;
  dplyr::pull(
    .data[["SampleID"]]
  ) |&gt;
  unique()
df2_samples &lt;- npx_df2 |&gt;
  dplyr::group_by(
    dplyr::pick(
      dplyr::all_of("SampleID")
    )
  )|&gt;
  dplyr::filter(
    all(.data[["QC_Warning"]] == 'Pass')
  ) |&gt;
  dplyr::ungroup() |&gt;
  dplyr::filter(
    !grepl(pattern = "^CONTROL_SAMPLE", x = .data[["SampleID"]])
  ) |&gt;
  dplyr::pull(
    .data[["SampleID"]]
  ) |&gt;
  unique()

# select a subset of samples from each set from above
df1_subset &lt;- sample(x = df1_samples, size = 16L)
df2_subset &lt;- sample(x = df2_samples, size = 20L)

# normalize
olink_normalization(
  df1 = npx_df1,
  df2 = npx_df2,
  overlapping_samples_df1 = df1_subset,
  overlapping_samples_df2 = df2_subset,
  df1_project_nr = "P1",
  df2_project_nr = "P2",
  reference_project = "P1"
)

# special case of subset normalization using all samples
olink_normalization(
  df1 = npx_df1,
  df2 = npx_df2,
  overlapping_samples_df1 = df1_samples,
  overlapping_samples_df2 = df2_samples,
  df1_project_nr = "P1",
  df2_project_nr = "P2",
  reference_project = "P1"
)

# reference median normalization

# For the sake of this example, set the reference median to 1
ref_med_df &lt;- npx_data1 |&gt;
  dplyr::select(
    dplyr::all_of(
      c("OlinkID")
    )
  ) |&gt;
  dplyr::distinct() |&gt;
  dplyr::mutate(
    Reference_NPX = runif(n = dplyr::n(),
                          min = -1,
                          max = 1)
  )

# normalize
olink_normalization(
  df1 = npx_df1,
  overlapping_samples_df1 = df1_subset,
  reference_medians = ref_med_df
)

# cross-product normalization

# get reference samples
overlap_samples_product &lt;- intersect(
  x = unique(OlinkAnalyze:::data_ht_small$SampleID),
  y = unique(OlinkAnalyze:::data_3k_small$SampleID)
) |&gt;
  (\(.) .[!grepl("CONTROL", .)])()

# normalize
olink_normalization(
  df1 = OlinkAnalyze:::data_ht_small,
  df2 = OlinkAnalyze:::data_3k_small,
  overlapping_samples_df1 = overlap_samples_product,
  df1_project_nr = "proj_ht",
  df2_project_nr = "proj_3k",
  reference_project = "proj_ht",
  format = FALSE
)


</code></pre>

<hr>
<h2 id='olink_normalization_bridge'>Bridge normalization of all proteins between two NPX projects.</h2><span id='topic+olink_normalization_bridge'></span>

<h3>Description</h3>

<p>Normalizes two NPX projects (data frames) using shared samples.<br /><br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_bridge(
  project_1_df,
  project_2_df,
  bridge_samples,
  project_1_name = "P1",
  project_2_name = "P2",
  project_ref_name = "P1"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_bridge_+3A_project_1_df">project_1_df</code></td>
<td>
<p>Data frame of the first project (required).</p>
</td></tr>
<tr><td><code id="olink_normalization_bridge_+3A_project_2_df">project_2_df</code></td>
<td>
<p>Data frame of the second project (required).</p>
</td></tr>
<tr><td><code id="olink_normalization_bridge_+3A_bridge_samples">bridge_samples</code></td>
<td>
<p>Named list of 2 arrays containing SampleID of shared
samples to be used for the calculation of adjustment factor. The
names of the two arrays should be DF1 and DF2 corresponding to projects 1
and 2, respectively. Arrays should be of equal length and index of each entry
should correspond to the same sample. (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_bridge_+3A_project_1_name">project_1_name</code></td>
<td>
<p>Name of the first project (default: P1).</p>
</td></tr>
<tr><td><code id="olink_normalization_bridge_+3A_project_2_name">project_2_name</code></td>
<td>
<p>Name of the second project (default: P2).</p>
</td></tr>
<tr><td><code id="olink_normalization_bridge_+3A_project_ref_name">project_ref_name</code></td>
<td>
<p>Name of the project to be used as reference set.
Needs to be one of the project_1_name or project_2_name. It marks the
project to which the other project will be adjusted to (default: P1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a wrapper of olink_normalization.<br /><br />
</p>
<p>In bridging normalization one of the projects is adjusted to another using
shared samples (bridge samples). It is not necessary for the shared
samples to be named the same in each project. Adjustment between the two
projects is made using the median of the paired differences between the
shared samples. The two data frames are inputs project_1_df and project_2_df,
the one being adjusted to is specified in the input project_ref_name and the
shared samples are specified in bridge_samples.<br /><br />
</p>


<h3>Value</h3>

<p>A &quot;tibble&quot; of NPX data in long format containing normalized NPX
values, including adjustment factors and name of project.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
npx_df1 &lt;- npx_data1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")
npx_df2 &lt;- npx_data2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

# Find overlapping samples, but exclude Olink control
overlap_samples &lt;- dplyr::intersect(unique(npx_df1$SampleID),
                                    unique(npx_df2$SampleID))
overlap_samples_list &lt;- list("DF1" = overlap_samples,
                             "DF2" = overlap_samples)

# Normalize
olink_normalization_bridge(project_1_df = npx_df1,
                           project_2_df = npx_df2,
                           bridge_samples = overlap_samples_list,
                           project_1_name = "P1",
                           project_2_name = "P2",
                           project_ref_name = "P1")


</code></pre>

<hr>
<h2 id='olink_normalization_bridgeable'>Identify if assays shared between Olink Explore 3072 and Olink Explore HT can
be bridged</h2><span id='topic+olink_normalization_bridgeable'></span>

<h3>Description</h3>

<p>The function uses a dataset from Olink Explore 3072 and a dataset from Olink
Explore HT, and examines if the matched assays between the two products can
be normalized to each other. The input datasets should be exported from Olink
software and should not be altered prior to importing them to this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_bridgeable(lst_df, ref_cols, not_ref_cols, seed = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_bridgeable_+3A_lst_df">lst_df</code></td>
<td>
<p>A named list of the 2 input datasets. First element should be
the reference dataset from Olink Explore HT and the second element should
originate from Olink Explore 3072.</p>
</td></tr>
<tr><td><code id="olink_normalization_bridgeable_+3A_ref_cols">ref_cols</code></td>
<td>
<p>A named list with the column names to use. Exported from
olink_norm_input_check.</p>
</td></tr>
<tr><td><code id="olink_normalization_bridgeable_+3A_not_ref_cols">not_ref_cols</code></td>
<td>
<p>A named list with the column names from the non-reference
dataset. Exported from olink_norm_input_check.</p>
</td></tr>
<tr><td><code id="olink_normalization_bridgeable_+3A_seed">seed</code></td>
<td>
<p>Integer random seed (Default: seek = 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All processes below assume that the first element from <var>lst_df</var> is the
reference dataset (e.g. Olink Explore HT), and the other element of the list
is the non-reference dataset (e.g. Olink Explore 3072). The input datasets
<strong>have to be pre-processed</strong> by <code><a href="#topic+olink_norm_input_check">olink_norm_input_check</a></code>
which will take care of mapping of assay identifiers and various checks.
Also, the input datasets should exclusively contain datapoints from bridge
samples. When this function is called from the function
<code><a href="#topic+olink_normalization">olink_normalization</a></code>, then the list is created seamlessly in the
background, and the datasets have been already processed by
<code><a href="#topic+olink_norm_input_check">olink_norm_input_check</a></code>.
</p>
<p>The input <var>ref_cols</var> is a named list masking column names of the
reference dataset. This list is generated automatically from
<code><a href="#topic+olink_norm_input_check">olink_norm_input_check</a></code> when it is called from
<code><a href="#topic+olink_normalization">olink_normalization</a></code>. In addition,
<code><a href="#topic+olink_normalization">olink_normalization</a></code> has also utilized
<code><a href="#topic+norm_internal_rename_cols">norm_internal_rename_cols</a></code> to rename the columns of the
non-reference dataset according to the ones of the reference dataset, hence
all column names should match.
</p>


<h3>Value</h3>

<p>A &quot;tibble&quot; in long format with the following columns:
</p>

<ul>
<li><p>OlinkID: Underscore-separated Olink identifiers of matching assays
between Olink Explore HT and Olink Explore 3072.
</p>
</li>
<li><p>BridgingRecommendation: A character vector indicating whether the
matching assays are considered as bridgeable or not, and the recommended
type of normalization to perform.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Amrita Kar
Marianne Sandin
Danai G. Topouza
Klev Diamanti
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# check input datasets
data_explore_check &lt;- OlinkAnalyze:::olink_norm_input_check(
  df1 = OlinkAnalyze:::data_3k_small,
  df2 = OlinkAnalyze:::data_ht_small,
  overlapping_samples_df1 = intersect(
    x = unique(OlinkAnalyze:::data_3k_small$SampleID),
    y = unique(OlinkAnalyze:::data_ht_small$SampleID)
  ) |&gt;
    (\(x) x[!grepl("CONTROL", x)])() |&gt;
    head(20L),
  overlapping_samples_df2 = NULL,
  df1_project_nr = "P1",
  df2_project_nr = "P2",
  reference_project = "P2",
  reference_medians = NULL
)

# create lst_df
lst_df &lt;- list(
  data_explore_check$ref_df,
  data_explore_check$not_ref_df
)
names(lst_df) &lt;- c(data_explore_check$ref_name,
                   data_explore_check$not_ref_name)

# create ref_cols
ref_cols &lt;- data_explore_check$ref_cols
not_ref_cols &lt;- data_explore_check$not_ref_cols

# run olink_normalization_bridgeable
is_bridgeable_result &lt;- OlinkAnalyze:::olink_normalization_bridgeable(
  lst_df = lst_df,
  ref_cols = ref_cols,
  not_ref_cols = not_ref_cols,
  seed = 1
)


</code></pre>

<hr>
<h2 id='olink_normalization_n'>Bridge and/or subset normalization of all proteins among multiple NPX
projects.</h2><span id='topic+olink_normalization_n'></span>

<h3>Description</h3>

<p>This function normalizes pairs of NPX projects (data frames) using shared
samples or subsets of samples.<br /><br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_n(norm_schema)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_n_+3A_norm_schema">norm_schema</code></td>
<td>
<p>A tibble with more than 1 rows and (strictly) the
following columns: &quot;order&quot;, &quot;name&quot;, &quot;data&quot;, &quot;samples&quot;, &quot;normalization_type&quot;,
&quot;normalize_to&quot;. See &quot;Details&quot; for the structure of the data frame
(required)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a wrapper of olink_normalization_bridge and
olink_normalization_subset.<br /><br />
</p>
<p>The input of this function is a tibble that contains all the necessary
information to normalize multiple NPX projects. This tibble is called the
normalization schema. The basic idea is that every row of the data frame is
a separate project to be normalized. We assume that there is always one
baseline project that does not normalize to any other. All other project
normalize to one or more projects. The function handles projects that are
normalized in a chain, for example:
</p>

<ul>
<li><p>1. project 2 normalizes to project 1, and project 3 normalizes to
project 2.
</p>
</li>
<li><p>2. project 2 normalizes to project 1, and project 3 normalizes to
the combined data frame of projects 1 and 2 (that is already normalized).
</p>
</li></ul>

<p>The function can also handle a mixed schema of bridge and subset
normalization.
</p>
<p>Specifications of the normalization schema data frame:
</p>

<ul>
<li><p>order: should strictly be a numeric or integer array with unique
identifiers for each project. It is necessary that this array starts from
1 and that it contains no NAs.
</p>
</li>
<li><p>name: should strictly be a character array with unique identifiers
for each project. Each entry should represent the name of the project
located in the same row. No NAs are allowed.
</p>
</li>
<li><p>data: a named list of NPX data frames representing the projects to
be normalized. Names of the items of the list should be identical to
&quot;names&quot;. No NAs are allowed.
</p>
</li>
<li><p>samples: a two-level nested named list of sample identifiers from
each NPX project from &quot;data&quot;. Names of the first level of the nested list
should be identical to &quot;names&quot; and to the names of the list from &quot;data&quot;.
Projects that will be used only as reference should have their
corresponding element in the list as NA, while all other projects should
contain a named list of 2 arrays containing identifiers of samples to be
used for the calculation of adjustment factor. The names of the two
arrays should be DF1 and DF2 corresponding to the reference project and
the project in the current row, respectively. For bridge normalization
arrays should be of equal length and the index of each entry should
correspond to the same sample. For subset normalization arrays do not
need to be of equal length and the order the samples appear in does not
matter. DF1 might contain sample identifiers from more than one project
as long as the project in the current row is to be normalized to multiple
other projects.
</p>
</li>
<li><p>normalization_type: a character array containing the flags &quot;Bridge&quot;
or &quot;Subset&quot;. Projects that will be used only as reference should have
their corresponding element in the array as NA, while all other projects
should contain a flag. For the time being the flag &quot;Median&quot; is not
supported.
</p>
</li>
<li><p>normalize_to: a character array pointing to the project this
project is to be normalized to. Elements of the array should be
exclusively from the &quot;order&quot; column. Elements of the array may be
comma-separated if the project is to be normalized to multiple projects.
</p>
</li></ul>



<h3>Value</h3>

<p>A &quot;tibble&quot; of NPX data in long format containing normalized NPX
values, including adjustment factors and name of project.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Bridge normalization of two projects

# prepare datasets
npx_df1 &lt;- npx_data1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")
npx_df2 &lt;- npx_data2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

# Find overlapping samples, but exclude Olink control
overlap_samples &lt;- dplyr::intersect(unique(npx_df1$SampleID),
                                    unique(npx_df2$SampleID))
overlap_samples_list &lt;- list("DF1" = overlap_samples,
                             "DF2" = overlap_samples)

# create tibble for input
norm_schema_bridge &lt;- dplyr::tibble(
  order              = c(1, 2),
  name               = c("NPX_DF1", "NPX_DF2"),
  data               = list("NPX_DF1" = npx_df1,
                            "NPX_DF2" = npx_df2),
  samples            = list("NPX_DF1" = NA_character_,
                            "NPX_DF2" = overlap_samples_list),
  normalization_type = c(NA_character_, "Bridge"),
  normalize_to       = c(NA_character_, "1")
)

# normalize
olink_normalization_n(norm_schema = norm_schema_bridge)

#### Subset normalization of two projects

# datasets
npx_df1 &lt;- npx_data1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")
npx_df2 &lt;- npx_data2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

# Find a suitable subset of samples from both projects, but exclude Olink
# controls and samples that fail QC.
df1_samples &lt;- npx_df1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::group_by(SampleID) |&gt;
  dplyr::filter(all(QC_Warning == 'Pass')) |&gt;
  dplyr::pull(SampleID) |&gt;
  unique() |&gt;
  sample(size = 16, replace = FALSE)
df2_samples &lt;- npx_df2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::group_by(SampleID) |&gt;
  dplyr::filter(all(QC_Warning == 'Pass')) |&gt;
  dplyr::pull(SampleID) |&gt;
  unique() |&gt;
  sample(size = 16, replace = FALSE)

# create named list
subset_samples_list &lt;- list("DF1" = df1_samples,
                            "DF2" = df2_samples)

# create tibble for input
norm_schema_subset &lt;- dplyr::tibble(
  order              = c(1, 2),
  name               = c("NPX_DF1", "NPX_DF2"),
  data               = list("NPX_DF1" = npx_df1,
                            "NPX_DF2" = npx_df2),
  samples            = list("NPX_DF1" = NA_character_,
                            "NPX_DF2" = subset_samples_list),
  normalization_type = c(NA_character_, "Subset"),
  normalize_to       = c(NA_character_, "1")
)

# Normalize
olink_normalization_n(norm_schema = norm_schema_subset)

#### Subset normalization  of two projects using all samples

# datasets
npx_df1 &lt;- npx_data1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")
npx_df2 &lt;- npx_data2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

# Find a suitable subset of samples from both projects, but exclude Olink
# controls and samples that fail QC.
df1_samples_all &lt;- npx_df1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::group_by(SampleID) |&gt;
  dplyr::filter(all(QC_Warning == 'Pass')) |&gt;
  dplyr::pull(SampleID) |&gt;
  unique()
df2_samples_all &lt;- npx_df2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::group_by(SampleID) |&gt;
  dplyr::filter(all(QC_Warning == 'Pass')) |&gt;
  dplyr::pull(SampleID) |&gt;
  unique()

# create named list
subset_samples_all_list &lt;- list("DF1" = df1_samples_all,
                                "DF2" = df2_samples_all)

# create tibble for input
norm_schema_subset_all &lt;- dplyr::tibble(
  order              = c(1, 2),
  name               = c("NPX_DF1", "NPX_DF2"),
  data               = list("NPX_DF1" = npx_df1,
                            "NPX_DF2" = npx_df2),
  samples            = list("NPX_DF1" = NA_character_,
                            "NPX_DF2" = subset_samples_all_list),
 normalization_type = c(NA_character_, "Subset"),
 normalize_to       = c(NA_character_, "1")
)

# Normalize
olink_normalization_n(norm_schema = norm_schema_subset_all)

#### Multi-project normalization using bridge and subset samples

## NPX data frames to bridge
npx_df1 &lt;- npx_data1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

npx_df2 &lt;- npx_data2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

# manipulating the sample NPX datasets to create another two random ones
npx_df3 &lt;- npx_data2 |&gt;
  dplyr::mutate(SampleID = paste(SampleID, "_mod", sep = ""),
                PlateID = paste(PlateID, "_mod", sep = ""),
                NPX = sample(x = NPX, size = dplyr::n(), replace = FALSE)) |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

npx_df4 &lt;- npx_data1 |&gt;
  dplyr::mutate(SampleID = paste(SampleID, "_mod2", sep = ""),
                PlateID = paste(PlateID, "_mod2", sep = ""),
                NPX = sample(x = NPX, size = dplyr::n(), replace = FALSE)) |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

## samples to use for normalization
# Bridge samples with same identifiers between npx_df1 and npx_df2
overlap_samples &lt;- dplyr::intersect(unique(npx_df1$SampleID),
                                    unique(npx_df2$SampleID))
overlap_samples_df1_df2 &lt;- list("DF1" = overlap_samples,
                                "DF2" = overlap_samples)
rm(overlap_samples)

# Bridge samples with different identifiers between npx_df2 and npx_df3
overlap_samples_df2_df3 &lt;- list("DF1" = sample(x = unique(npx_df2$SampleID),
                                               size = 10,
                                               replace = FALSE),
                                "DF2" = sample(x = unique(npx_df3$SampleID),
                                               size = 10,
                                               replace = FALSE))

# Samples to use for intensity normalization between npx_df4 and the
# normalized dataset of npx_df1 and npx_df2
overlap_samples_df12_df4 &lt;- list("DF1" = sample(x = c(unique(npx_df1$SampleID),
                                                      unique(npx_df2$SampleID)),
                                                size = 100,
                                                replace = FALSE) |&gt;
                                   unique(),
                                 "DF2" = sample(x = unique(npx_df4$SampleID),
                                                size = 40,
                                                replace = FALSE))

# create tibble for input
norm_schema_n &lt;- dplyr::tibble(
  order              = c(1, 2, 3, 4),
  name               = c("NPX_DF1", "NPX_DF2", "NPX_DF3", "NPX_DF4"),
  data               = list("NPX_DF1" = npx_df1,
                            "NPX_DF2" = npx_df2,
                            "NPX_DF3" = npx_df3,
                            "NPX_DF4" = npx_df4),
  samples            = list("NPX_DF1" = NA_character_,
                            "NPX_DF2" = overlap_samples_df1_df2,
                            "NPX_DF3" = overlap_samples_df2_df3,
                            "NPX_DF4" = overlap_samples_df12_df4),
  normalization_type = c(NA_character_, "Bridge", "Bridge", "Subset"),
  normalize_to       = c(NA_character_, "1", "2", "1,2")
)

olink_normalization_n(norm_schema = norm_schema_n)



</code></pre>

<hr>
<h2 id='olink_normalization_n_check'>An internal function to perform checks on the input of the function
olink_normalization_n.</h2><span id='topic+olink_normalization_n_check'></span>

<h3>Description</h3>

<p>An internal function to perform checks on the input of the function
olink_normalization_n.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_n_check(norm_schema)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_n_check_+3A_norm_schema">norm_schema</code></td>
<td>
<p>A tibble with more than 1 rows and (strictly) the
following columns: &quot;order&quot;, &quot;name&quot;, &quot;data&quot;, &quot;samples&quot;, &quot;normalization_type&quot;,
&quot;normalize_to&quot;. See above for details of the structure of the data frame. See
details in help for olink_normalization_n. (required)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character message. If the message is &quot;TRUE&quot; then all checks passed,
otherwise an error message will be printed.
</p>

<hr>
<h2 id='olink_normalization_product_format'>Formatting the output of olink_normalization_product for seamless use with
downstream Olink Analyze functions.</h2><span id='topic+olink_normalization_product_format'></span>

<h3>Description</h3>

<p>Replaces the NPX values of the non-reference project by the Median Centered
or QS Normalized NPX, according to the Bridging Recommendation. Edits the
BridgingRecommendation column to indicate whether an assay is NotBridgeable,
NotOverlapping, MedianCentering, or QuantileSmoothing bridged. Replaces
OlinkID by the concatenation of the Explore HT and Explore 3072 OlinkIDs to
record the OlinkIDs from both projects for bridgeable assays. Assays that are
NotBridgeable or NotOverlapping retain their original non-reference OlinkIDs
and NPX values. Replaces SampleID with the concatenation of SampleID and
Project to make unique sample IDs for downstream analysis. Removes internal
and external controls. Removes  MedianCenteredNPX, QSNormalizedNPX,
OlinkID_E3072 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_product_format(
  bridged_df,
  df1,
  df1_project_nr,
  df2,
  df2_project_nr,
  reference_project
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_product_format_+3A_bridged_df">bridged_df</code></td>
<td>
<p>A &quot;tibble&quot; of Olink data in long format resulting from the
olink_normalization_product function.</p>
</td></tr>
<tr><td><code id="olink_normalization_product_format_+3A_df1">df1</code></td>
<td>
<p>First dataset to be used for normalization, pre-normalization.
Must match df1 used in olink_normalization product bridging.</p>
</td></tr>
<tr><td><code id="olink_normalization_product_format_+3A_df1_project_nr">df1_project_nr</code></td>
<td>
<p>Project name of first dataset. Must match name used in
olink_normalization product bridging.</p>
</td></tr>
<tr><td><code id="olink_normalization_product_format_+3A_df2">df2</code></td>
<td>
<p>Second dataset to be used for normalization, pre-normalization.
Must match df2 used in olink_normalization product bridging.</p>
</td></tr>
<tr><td><code id="olink_normalization_product_format_+3A_df2_project_nr">df2_project_nr</code></td>
<td>
<p>Project name of second dataset. Must match name used in
olink_normalization product bridging.</p>
</td></tr>
<tr><td><code id="olink_normalization_product_format_+3A_reference_project">reference_project</code></td>
<td>
<p>Project name of reference project. Must match name
used in olink_normalization product bridging and be one of df1_project_nr or
df2_project_nr.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; of Olink data in long format containing both input
datasets with the bridged NPX quantifications, with the above
modifications.
</p>


<h3>Author(s)</h3>

<p>Danai G. Topouza
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Bridge samples
bridge_samples &lt;- intersect(
  x = unique(OlinkAnalyze:::data_ht_small$SampleID),
  y = unique(OlinkAnalyze:::data_3k_small$SampleID)
) |&gt;
  (\(x) x[!grepl("CONTROL", x)])()

# Run olink_normalization_product
npx_br_data &lt;- olink_normalization(
df1 = OlinkAnalyze:::data_ht_small,
df2 = OlinkAnalyze:::data_3k_small,
overlapping_samples_df1 = bridge_samples,
df1_project_nr = "Explore HT",
df2_project_nr = "Explore 3072",
reference_project = "Explore HT")

# Format output
npx_br_data_format &lt;- OlinkAnalyze:::olink_normalization_product_format(
bridged_df = npx_br_data,
df1 = OlinkAnalyze:::data_ht_small,
df2 = OlinkAnalyze:::data_3k_small,
df1_project_nr = "Explore HT",
df2_project_nr = "Explore 3072",
reference_project = "Explore HT")


</code></pre>

<hr>
<h2 id='olink_normalization_project_name_check'>An internal function to perform checks on the input project names in the
functions olink_normalization_bridge and olink_normalization_subset. The
function is expected to run all checks on project names to make sure that
normalization can be performed smoothly. It should work independently of the
function calling it.</h2><span id='topic+olink_normalization_project_name_check'></span>

<h3>Description</h3>

<p>An internal function to perform checks on the input project names in the
functions olink_normalization_bridge and olink_normalization_subset. The
function is expected to run all checks on project names to make sure that
normalization can be performed smoothly. It should work independently of the
function calling it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_project_name_check(
  project_1_name,
  project_2_name,
  project_ref_name
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_project_name_check_+3A_project_1_name">project_1_name</code></td>
<td>
<p>Name of project 1 (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_project_name_check_+3A_project_2_name">project_2_name</code></td>
<td>
<p>Name of project 2 (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_project_name_check_+3A_project_ref_name">project_ref_name</code></td>
<td>
<p>Name of reference project (required)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character message. If the message is &quot;TRUE&quot; then all checks passed,
otherwise an error message will be printed.
</p>

<hr>
<h2 id='olink_normalization_qs'>Quantile smoothing normalization of all proteins between two NPX projects.</h2><span id='topic+olink_normalization_qs'></span>

<h3>Description</h3>

<p>This function uses bridge samples to map quantiles of the non-reference
dataset to the ones of the reference dataset. Mapped quantiles are used to
transform the quantifications of the the non-reference dataset to the
reference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_qs(
  lst_df,
  ref_cols,
  not_ref_cols,
  bridge_samples,
  ref_product
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_qs_+3A_lst_df">lst_df</code></td>
<td>
<p>A named list of the 2 input datasets. First element should be
the reference dataset from Olink Explore HT and the second element should
originate from Olink Explore 3072. (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_qs_+3A_ref_cols">ref_cols</code></td>
<td>
<p>A named list with the column names to use. Exported from
olink_norm_input_check. (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_qs_+3A_not_ref_cols">not_ref_cols</code></td>
<td>
<p>A named list with the column names from the non-reference
dataset. Exported from olink_norm_input_check. (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_qs_+3A_bridge_samples">bridge_samples</code></td>
<td>
<p>Character vector of samples to be used for the
quantile mapping. (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_qs_+3A_ref_product">ref_product</code></td>
<td>
<p>Name of reference product.
Must be one of &quot;HT&quot; or &quot;Reveal&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case when a study is separated into multiple projects,
an additional normalization step is needed to allow the data to be
comparable across projects. Across different Olink products, some of the
assays exist in corresponding but distinct NPX spaces. For those assays,
the median of paired differences is insufficient for bridging as it only
considers one anchor point (the median/50% quantile). Instead, quantile
smoothing (QS) using multiple anchor points (5%, 10%, 25%, 50%, 75%, 90%
and 95% quantiles) is favored to map the Explore 3072 data to the Explore
HT distribution. The <code>olink_normalization_qs()</code> performs quantile smoothing
bridging normalization between datasets from two Olink products (for example
Olink Explore 3072 and Olink Explore HT) by performing the following
steps: <br />
</p>

<ul>
<li><p> An empirical cumulative distribution function is used to map
datapoints for the bridging samples from one product to the equivalent
space in the other product.
</p>
</li>
<li><p> A spline regression model is constructed using unmapped
and mapped data from one product, using anchor points from the
quantiles defined above.
</p>
</li>
<li><p> The spline regression model is used to predict the normalized
NPX values for all datapoints
</p>
</li></ul>

<p>More information on quantile smoothing and between product normalization
can be found in the Bridging Olink Explore 3072 to Olink Explore HT tutorial.
</p>


<h3>Value</h3>

<p>A &quot;tibble&quot; of Olink data in long format containing both input
datasets with the quantile normalized quantifications.
</p>


<h3>Author(s)</h3>

<p>Amrita Kar
Marianne Sandin
Masoumeh Sheikhi
Klev Diamanti
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Bridge samples
bridge_samples &lt;- intersect(
  x = unique(OlinkAnalyze:::data_ht_small$SampleID),
  y = unique(OlinkAnalyze:::data_3k_small$SampleID)
) |&gt;
  (\(x) x[!grepl("CONTROL", x)])()

# Run the internal function olink_norm_input_check
check_norm &lt;- OlinkAnalyze:::olink_norm_input_check(
  df1 = OlinkAnalyze:::data_ht_small,
  df2 = OlinkAnalyze:::data_3k_small,
  overlapping_samples_df1 = bridge_samples,
  overlapping_samples_df2 = NULL,
  df1_project_nr = "P1",
  df2_project_nr = "P2",
  reference_project = "P1",
  reference_medians = NULL
)

# Named list of input datasets
lst_df &lt;- list(
  check_norm$ref_df,
  check_norm$not_ref_df
)
names(lst_df) &lt;- c(check_norm$ref_name, check_norm$not_ref_name)

ref_cols &lt;- check_norm$ref_cols
not_ref_cols &lt;- check_norm$not_ref_cols

qs_result &lt;- OlinkAnalyze:::olink_normalization_qs(
 lst_df = lst_df,
 ref_cols = ref_cols,
 not_ref_cols = not_ref_cols,
 bridge_samples = bridge_samples,
 ref_product = "HT"
)


</code></pre>

<hr>
<h2 id='olink_normalization_sample_check'>An internal function to perform checks on the input samples in the functions
olink_normalization_bridge and olink_normalization_subset. The function is
expected to run all checks on SampleID to make sure that normalization can
be performed smoothly. It should work independently of the function calling
it.</h2><span id='topic+olink_normalization_sample_check'></span>

<h3>Description</h3>

<p>An internal function to perform checks on the input samples in the functions
olink_normalization_bridge and olink_normalization_subset. The function is
expected to run all checks on SampleID to make sure that normalization can
be performed smoothly. It should work independently of the function calling
it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_sample_check(
  list_samples,
  check_mode,
  project_1_all_samples,
  project_2_all_samples
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_sample_check_+3A_list_samples">list_samples</code></td>
<td>
<p>Named list of 2 arrays containing SampleID of the
subset or bridge samples to be used for normalization. The names of the two
arrays should be DF1 and DF2 corresponding to projects 1 and 2, respectively.
(required)</p>
</td></tr>
<tr><td><code id="olink_normalization_sample_check_+3A_check_mode">check_mode</code></td>
<td>
<p>Flag &quot;bridge&quot; or &quot;subset&quot; indicating the type of
normalization the check should be tailored to (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_sample_check_+3A_project_1_all_samples">project_1_all_samples</code></td>
<td>
<p>Array of all samples from project 1 (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_sample_check_+3A_project_2_all_samples">project_2_all_samples</code></td>
<td>
<p>Array of all samples from project 2 (required)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character message. If the message is &quot;TRUE&quot; then all checks passed,
otherwise an error message will be printed.
</p>

<hr>
<h2 id='olink_normalization_subset'>Subset normalization of all proteins between two NPX projects.</h2><span id='topic+olink_normalization_subset'></span>

<h3>Description</h3>

<p>Normalizes two NPX projects (data frames) using all or a subset of samples.<br /><br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_normalization_subset(
  project_1_df,
  project_2_df,
  reference_samples,
  project_1_name = "P1",
  project_2_name = "P2",
  project_ref_name = "P1"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_normalization_subset_+3A_project_1_df">project_1_df</code></td>
<td>
<p>Data frame of the first project (required).</p>
</td></tr>
<tr><td><code id="olink_normalization_subset_+3A_project_2_df">project_2_df</code></td>
<td>
<p>Data frame of the second project (required).</p>
</td></tr>
<tr><td><code id="olink_normalization_subset_+3A_reference_samples">reference_samples</code></td>
<td>
<p>Named list of 2 arrays containing SampleID of the
subset of samples to be used for the calculation of median NPX within each
project. The names of the two arrays should be DF1 and DF2 corresponding to
projects 1 and 2, respectively. Arrays do not need to be of equal length and
the order the samples appear in does not play any role. (required)</p>
</td></tr>
<tr><td><code id="olink_normalization_subset_+3A_project_1_name">project_1_name</code></td>
<td>
<p>Name of the first project (default: P1).</p>
</td></tr>
<tr><td><code id="olink_normalization_subset_+3A_project_2_name">project_2_name</code></td>
<td>
<p>Name of the second project (default: P2).</p>
</td></tr>
<tr><td><code id="olink_normalization_subset_+3A_project_ref_name">project_ref_name</code></td>
<td>
<p>Name of the project to be used as reference set.
Needs to be one of the project_1_name or project_2_name. It marks the
project to which the other project will be adjusted to (default: P1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a wrapper of olink_normalization.<br /><br />
</p>
<p>In subset normalization one of the projects is adjusted to another using
a subset of all samples from each. Please note that the subsets of samples
are not expected to be replicates of each other or to have the SampleID.
Adjustment between the two projects is made using the assay-specific
differences in median between the subsets of samples from the two projects.
The two data frames are inputs project_1_df and project_2_df, the one being
adjusted to is specified in the input project_ref_name and the shared
samples are specified in reference_samples. <br /><br />
</p>
<p>A special case of subset normalization is to use all samples (except control
samples) from each project as a subset. <br /><br />
</p>


<h3>Value</h3>

<p>A &quot;tibble&quot; of NPX data in long format containing normalized NPX
values, including adjustment factors and name of project.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Subset normalization

# datasets
npx_df1 &lt;- npx_data1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")
npx_df2 &lt;- npx_data2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

# Find a suitable subset of samples from both projects, but exclude Olink
# controls and samples that fail QC.
df1_samples &lt;- npx_df1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::group_by(SampleID) |&gt;
  dplyr::filter(all(QC_Warning == 'Pass')) |&gt;
  dplyr::pull(SampleID) |&gt;
  unique() |&gt;
  sample(size = 16, replace = FALSE)
df2_samples &lt;- npx_df2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::group_by(SampleID) |&gt;
  dplyr::filter(all(QC_Warning == 'Pass')) |&gt;
  dplyr::pull(SampleID) |&gt;
  unique() |&gt;
  sample(size = 16, replace = FALSE)

# create named list
subset_samples_list &lt;- list("DF1" = df1_samples,
                            "DF2" = df2_samples)

# Normalize
olink_normalization_subset(project_1_df = npx_df1,
                           project_2_df = npx_df2,
                           reference_samples = subset_samples_list,
                           project_1_name = "P1",
                           project_2_name = "P2",
                           project_ref_name = "P1")


#### Special case of subset normalization using all samples

# datasets
npx_df1 &lt;- npx_data1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")
npx_df2 &lt;- npx_data2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::select(-Project) |&gt;
  dplyr::mutate(Normalization = "Intensity")

# Find a suitable subset of samples from both projects, but exclude Olink
# controls and samples that fail QC.
df1_samples_all &lt;- npx_df1 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::group_by(SampleID) |&gt;
  dplyr::filter(all(QC_Warning == 'Pass')) |&gt;
  dplyr::pull(SampleID) |&gt;
  unique()
df2_samples_all &lt;- npx_df2 |&gt;
  dplyr::filter(!stringr::str_detect(SampleID, "CONTROL_")) |&gt;
  dplyr::group_by(SampleID) |&gt;
  dplyr::filter(all(QC_Warning == 'Pass')) |&gt;
  dplyr::pull(SampleID) |&gt;
  unique()

# create named list
subset_samples_all_list &lt;- list("DF1" = df1_samples_all,
                            "DF2" = df2_samples_all)

# Normalize
olink_normalization_subset(project_1_df = npx_df1,
                           project_2_df = npx_df2,
                           reference_samples = subset_samples_all_list,
                           project_1_name = "P1",
                           project_2_name = "P2",
                           project_ref_name = "P1")


</code></pre>

<hr>
<h2 id='olink_one_non_parametric'>Function which performs a Kruskal-Wallis Test or Friedman Test per protein</h2><span id='topic+olink_one_non_parametric'></span>

<h3>Description</h3>

<p>Performs an Kruskal-Wallis Test for each assay (by OlinkID) in every panel using stats::kruskal.test.
Performs an Friedman Test for each assay (by OlinkID) in every panel using rstatix::friedman_test.
The function handles factor variable. <br /><br />
Samples that have no variable information or missing factor levels are automatically removed from the analysis (specified in a message if verbose = TRUE).
Character columns in the input dataframe are automatically converted to factors (specified in a message if verbose = T).
Numerical variables are not converted to factors.
If a numerical variable is to be used as a factor, this conversion needs to be done on the dataframe before the function call. <br /><br />
Inference is specified in a message if verbose = TRUE. <br />
The formula notation of the final model is specified in a message if verbose = TRUE. <br /><br />
Adjusted p-values are calculated by stats::p.adjust according to the Benjamini &amp; Hochberg (1995) method (“fdr”).
The threshold is determined by logic evaluation of Adjusted_pval &lt; 0.05.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_one_non_parametric(
  df,
  variable,
  dependence = FALSE,
  subject = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_one_non_parametric_+3A_df">df</code></td>
<td>
<p>NPX or Quantified_value data frame in long format with at least protein name (Assay), OlinkID, UniProt, Panel and a factor with at least 3 levels.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_+3A_variable">variable</code></td>
<td>
<p>Single character value.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_+3A_dependence">dependence</code></td>
<td>
<p>Boolean. Default: FALSE. When the groups are independent, the kruskal-Wallis will run, when the groups are dependent, the Friedman test will run.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_+3A_subject">subject</code></td>
<td>
<p>Group information for the repeated measurement. If (dependence = TRUE), this parameter need to be specified.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. Default: True. If information about removed samples, factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the Kruskal-Wallis Test or Friedman Test results for every protein.
</p>
<p>Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>term: &quot;character&quot; term in model
</p>
</li>
<li><p>df: &quot;numeric&quot; degrees of freedom
</p>
</li>
<li><p>method: &quot;character&quot; which method was used
</p>
</li>
<li><p>statistic: &quot;named numeric&quot; the value of the test statistic with a name describing it
</p>
</li>
<li><p>p.value: &quot;numeric&quot; p-value for the test
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test (Benjamini&amp;Hochberg)
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)

# One-way Kruskal-Wallis Test
try({ # May fail if dependencies are not installed
kruskal_results &lt;- olink_one_non_parametric(df = npx_data1,
                                            variable = "Site")
})

#Friedman Test
friedman_results &lt;- olink_one_non_parametric(df = npx_data1,
                                             variable = "Time",
                                             subject = "Subject",
                                             dependence = TRUE)

</code></pre>

<hr>
<h2 id='olink_one_non_parametric_posthoc'>Function which performs posthoc test per protein for the results from Friedman or Kruskal-Wallis Test.</h2><span id='topic+olink_one_non_parametric_posthoc'></span>

<h3>Description</h3>

<p>Performs a posthoc test using rstatix::wilcox_test or FSA::dunnTest with Benjamini-Hochberg p-value adjustment per assay (by OlinkID) for each panel at confidence level 0.95.
See <code>olink_one_non_parametric</code> for details of input notation. <br /><br />
The function handles both factor and numerical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_one_non_parametric_posthoc(
  df,
  olinkid_list = NULL,
  variable,
  test = "kruskal",
  subject = "Subject",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_one_non_parametric_posthoc_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID, UniProt, Panel and a factor with at least 3 levels.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_posthoc_+3A_olinkid_list">olinkid_list</code></td>
<td>
<p>Character vector of OlinkID's on which to perform post hoc analysis. If not specified, all assays in df are used.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_posthoc_+3A_variable">variable</code></td>
<td>
<p>Single character value or character array.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_posthoc_+3A_test">test</code></td>
<td>
<p>Single character value indicates running the post hoc test for friedman or kruskal.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_posthoc_+3A_subject">subject</code></td>
<td>
<p>Group information for the repeated measurement. If (dependence = TRUE), this parameter need to be specified.</p>
</td></tr>
<tr><td><code id="olink_one_non_parametric_posthoc_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. Default: True. If information about removed samples, factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble of posthoc tests for specified effect, arranged by ascending adjusted p-values.
</p>
<p>Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>term: &quot;character&quot; term in model
</p>
</li>
<li><p>contrast: &quot;character&quot; the groups that were compared
</p>
</li>
<li><p>estimate: &quot;numeric&quot; the value of the test statistic with a name describing it
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)

try({ # May fail if dependencies are not installed
# One-way Kruskal-Wallis Test
kruskal_results &lt;- olink_one_non_parametric(df = npx_data1,
                                            variable = "Site")
})

#Friedman Test
friedman_results &lt;- olink_one_non_parametric(df = npx_data1,
                                            variable = "Time",
                                            subject = "Subject",
                                            dependence = TRUE)

#Posthoc test for the results from Friedman Test
friedman_posthoc_results &lt;- olink_one_non_parametric_posthoc(npx_data1,
                                                            variable = "Time",
                                                            test = "friedman",
                                                            olinkid_list = {friedman_results %&gt;%
                                                              filter(Threshold == 'Significant') %&gt;%
                                                              dplyr::select(OlinkID) %&gt;%
                                                              distinct() %&gt;%
                                                              pull()})

</code></pre>

<hr>
<h2 id='olink_ordinalRegression'>Function which A two-way ordinal analysis of variance can address an experimental design with two independent variables, each of which is a factor variable.  The main effect of each independent variable can be tested, as well as the effect of the interaction of the two factors.</h2><span id='topic+olink_ordinalRegression'></span>

<h3>Description</h3>

<p>Performs an ANOVA F-test for each assay (by OlinkID) in every panel using stats::Anova and Type III sum of squares. Dependent variable will be treated as ordered factor.
The function handles only factor and/or covariates. <br /><br />
Samples that have no variable information or missing factor levels are automatically removed from the analysis (specified in a message if verbose = T).
Character columns in the input dataframe are automatically converted to factors (specified in a message if verbose = T).
Crossed analysis, i.e. A*B formula notation, is inferred from the variable argument in the following cases: <br />
</p>

<ul>
<li><p> c('A','B')
</p>
</li>
<li><p> c('A: B')
</p>
</li>
<li><p> c('A: B', 'B') or c('A: B', 'A')
</p>
</li></ul>

<p>Inference is specified in a message if verbose = T. <br />
The formula notation of the final model is specified in a message if verbose = T. <br /><br />
Adjusted p-values are calculated by stats::p.adjust according to the Benjamini &amp; Hochberg (1995) method (“fdr”).
The threshold is determined by logic evaluation of Adjusted_pval &lt; 0.05. Covariates are not included in the p-value adjustment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_ordinalRegression(
  df,
  variable,
  covariates = NULL,
  return.covariates = F,
  verbose = T
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_ordinalRegression_+3A_df">df</code></td>
<td>
<p>NPX or Quantified_value data frame in long format with at least protein name (Assay), OlinkID, UniProt, Panel and a factor with at least 3 levels.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_+3A_variable">variable</code></td>
<td>
<p>Single character value or character array.
Variable(s) to test. If length &gt; 1, the included variable names will be used in crossed analyses .
Also takes ':'/'*' notation.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_+3A_covariates">covariates</code></td>
<td>
<p>Single character value or character array. Default: NULL.
Covariates to include. Takes ':'/'*' notation. Crossed analysis will not be inferred from main effects.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_+3A_return.covariates">return.covariates</code></td>
<td>
<p>Logical. Default: False. Returns F-test results for the covariates. Note: Adjusted p-values will be NA for the covariates.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Default: True. If information about removed samples, factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the ANOVA results for every protein.
The tibble is arranged by ascending p-values.
</p>
<p>Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>term: &quot;character&quot; term in model
</p>
</li>
<li><p>statistic: &quot;numeric&quot; value of the statistic
</p>
</li>
<li><p>p.value: &quot;numeric&quot; nominal p-value
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)

try({ # May fail if dependencies are not installed.
#Two-way Ordinal Regression with CLM.
#Results in model NPX~Treatment+Time+Treatment:Time.
   ordinalRegression_results &lt;- olink_ordinalRegression(df = npx_data1,
                                                       variable="Treatment:Time")
})


</code></pre>

<hr>
<h2 id='olink_ordinalRegression_posthoc'>Function which performs an posthoc test per protein.</h2><span id='topic+olink_ordinalRegression_posthoc'></span>

<h3>Description</h3>

<p>Performs a post hoc ANOVA test using emmeans::emmeans with Tukey p-value adjustment per assay (by OlinkID) for each panel at confidence level 0.95.
See <code>olink_anova</code> for details of input notation. <br /><br />
The function handles both factor and numerical variables and/or covariates.
The posthoc test for a numerical variable compares the difference in means of the ordinal outcome variable (default: NPX) for 1 standard deviation difference in the numerical variable, e.g.
mean ordinal NPX at mean(numerical variable) versus mean NPX at mean(numerical variable) + 1*SD(numerical variable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_ordinalRegression_posthoc(
  df,
  olinkid_list = NULL,
  variable,
  covariates = NULL,
  effect,
  effect_formula,
  mean_return = FALSE,
  post_hoc_padjust_method = "tukey",
  verbose = T
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID, UniProt, Panel and a factor with at least 3 levels.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_olinkid_list">olinkid_list</code></td>
<td>
<p>Character vector of OlinkID's on which to perform post hoc analysis. If not specified, all assays in df are used.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_variable">variable</code></td>
<td>
<p>Single character value or character array.
Variable(s) to test. If length &gt; 1, the included variable names will be used in crossed analyses .
Also takes ':' notation.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_covariates">covariates</code></td>
<td>
<p>Single character value or character array. Default: NULL.
Covariates to include. Takes ':'/'*' notation. Crossed analysis will not be inferred from main effects.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_effect">effect</code></td>
<td>
<p>Term on which to perform post-hoc. Character vector. Must be subset of or identical to variable.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_effect_formula">effect_formula</code></td>
<td>
<p>(optional) A character vector specifying the names of the predictors over which estimated marginal means are desired as defined in the <code>emmeans</code> package. May also be a formula. If provided, this will override the <code>effect</code> argument. See <code>?emmeans::emmeans()</code> for more information.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_mean_return">mean_return</code></td>
<td>
<p>Boolean. If true, returns the mean of each factor level rather than the difference in means (default). Note that no p-value is returned for mean_return = TRUE and no adjustment is performed.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_post_hoc_padjust_method">post_hoc_padjust_method</code></td>
<td>
<p>P-value adjustment method to use for post-hoc comparisons within an assay. Options include <code>tukey</code>, <code>sidak</code>, <code>bonferroni</code> and <code>none</code>.</p>
</td></tr>
<tr><td><code id="olink_ordinalRegression_posthoc_+3A_verbose">verbose</code></td>
<td>
<p>Boolean. Default: True. If information about removed samples, factor conversion and final model formula is to be printed to the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble of posthoc tests for specified effect, arranged by ascending adjusted p-values.
</p>
<p>#' Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>term: &quot;character&quot; term in model
</p>
</li>
<li><p>contrast: &quot;character&quot; the groups that were compared
</p>
</li>
<li><p>estimate: &quot;numeric&quot; difference in mean of the ordinal NPX between groups
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)
#Two-way Ordinal Regression.
#Results in model NPX~Treatment*Time.
try({ # May not work if dependencies are not installed.
ordinalRegression_results &lt;- olink_ordinalRegression(df = npx_data1,
                              variable="Treatment:Time")

#Filtering out significant and relevant results.
significant_assays &lt;- ordinalRegression_results %&gt;%
  filter(Threshold == 'Significant' &amp; term == 'Time') %&gt;%
  select(OlinkID) %&gt;%
  distinct() %&gt;%
  pull()

#Posthoc test for the model NPX~Treatment*Time,
#on the effect Time.

#Posthoc
ordinalRegression_results_posthoc_results &lt;- olink_ordinalRegression_posthoc(npx_data1,
                                                   variable=c("Treatment:Time"),
                                                   olinkid_list = significant_assays,
                                                   effect = "Time")
                                                   })
                                                   

</code></pre>

<hr>
<h2 id='olink_pal'>Olink color panel for plotting</h2><span id='topic+olink_pal'></span>

<h3>Description</h3>

<p>Olink color panel for plotting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_pal(alpha = 1, coloroption = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_pal_+3A_alpha">alpha</code></td>
<td>
<p>transparency (optional)</p>
</td></tr>
<tr><td><code id="olink_pal_+3A_coloroption">coloroption</code></td>
<td>
<p>string, one or more of the following:
c('red', 'orange', 'yellow', 'green', 'teal', 'turqoise', 'lightblue', 'darkblue', 'purple', 'pink')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of palette hex codes for colors
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(scales)

#Color matrices
show_col(olink_pal()(10), labels = FALSE)
show_col(olink_pal(coloroption = c('lightblue', 'green'))(2), labels = FALSE)

#Contour plot
filled.contour(volcano, color.palette = olink_pal(), asp = 1)
filled.contour(volcano, color.palette = hue_pal(), asp = 1)


</code></pre>

<hr>
<h2 id='olink_pathway_enrichment'>Performs pathway enrichment using over-representation analysis (ORA) or gene set enrichment analysis (GSEA)</h2><span id='topic+olink_pathway_enrichment'></span>

<h3>Description</h3>

<p>This function performs enrichment analysis based on statistical test results and full data using clusterProfiler's gsea and enrich functions for MSigDB.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_pathway_enrichment(
  data,
  test_results,
  method = "GSEA",
  ontology = "MSigDb",
  organism = "human",
  pvalue_cutoff = 0.05,
  estimate_cutoff = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_pathway_enrichment_+3A_data">data</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID, UniProt,SampleID, QC_Warning, NPX, and LOD</p>
</td></tr>
<tr><td><code id="olink_pathway_enrichment_+3A_test_results">test_results</code></td>
<td>
<p>a dataframe of statistical test results including Adjusted_pval and estimate columns.</p>
</td></tr>
<tr><td><code id="olink_pathway_enrichment_+3A_method">method</code></td>
<td>
<p>Either &quot;GSEA&quot; (default) or &quot;ORA&quot;</p>
</td></tr>
<tr><td><code id="olink_pathway_enrichment_+3A_ontology">ontology</code></td>
<td>
<p>Supports &quot;MSigDb&quot; (default), &quot;KEGG&quot;, &quot;GO&quot;, and &quot;Reactome&quot; as arguments. MSigDb contains C2 and C5 genesets. C2 and C5 encompass KEGG, GO, and Reactome.</p>
</td></tr>
<tr><td><code id="olink_pathway_enrichment_+3A_organism">organism</code></td>
<td>
<p>Either &quot;human&quot; (default) or &quot;mouse&quot;</p>
</td></tr>
<tr><td><code id="olink_pathway_enrichment_+3A_pvalue_cutoff">pvalue_cutoff</code></td>
<td>
<p>(numeric) maximum Adjusted p-value cutoff for ORA filtering of foreground set (default = 0.05). This argument is not used for GSEA.</p>
</td></tr>
<tr><td><code id="olink_pathway_enrichment_+3A_estimate_cutoff">estimate_cutoff</code></td>
<td>
<p>(numeric) minimum estimate cutoff for ORA filtering of foreground set (default = 0) This argument is not used for GSEA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MSigDB is subset if the  ontology argument is KEGG, GO, or Reactome. test_results must contain estimates for all assays.
Posthoc results can be used but should be filtered for one contrast to improve interpretability.
Alternative statistical results can be used as input as long as they include the columns
&quot;OlinkID&quot;, &quot;Assay&quot;, and &quot;estimate&quot;. A column named &quot;Adjusted_pal&quot; is also needed for ORA. Any statistical results that contains one estimate per protein will work as long as the estimates are comparable to each other.
</p>
<p>clusterProfiler is originally developed by Guangchuang Yu at the School of Basic Medical Sciences at Southern Medical University.
</p>
<p>T Wu, E Hu, S Xu, M Chen, P Guo, Z Dai, T Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo, and G Yu.
clusterProfiler 4.0: A universal enrichment tool for interpreting omics data. The Innovation. 2021, 2(3):100141.
doi: 10.1016/j.xinn.2021.100141
</p>
<p><strong>NB:</strong> We strongly recommend to set a seed prior to running this function to ensure reproducibility of the results.
</p>
<p><strong>A few notes on Pathway Enrichment with Olink Data</strong>
</p>
<p>It is important to note that sometimes the proteins that are assayed in Olink Panels
are related to specific biological areas and therefore do not represent an unbiased overview of the proteome as a whole.
Pathways can only interpreted based on the background/context they came from. For this reason, an estimate for all assays measured must
be provided. Furthermore, certain pathways cannot come up based on Olink's  coverage in this area.  Additionally,
if only the Inflammation panel was run, then the available pathways would be given based on a background
of proteins related to inflammation. Both ORA and GSEA can provide mechanistic and disease related insight and are best to use when
trying to uncover pathways/annotations of interest. It is recommended to only use pathway enrichment for hypothesis generating data, which
is more well suited for data on the Explore platform or on multiple Target 96 panels. For smaller lists of proteins it may be more informative to use biological annotation in directed research,
to discover which significant assay are related to keywords of interest.
</p>


<h3>Value</h3>

<p>A data frame of enrichment results.
Columns for ORA include:
</p>

<ul>
<li><p>ID: &quot;character&quot; Pathway ID from MSigDB
</p>
</li>
<li><p>Description: &quot;character&quot; Description of Pathway from MSigDB
</p>
</li>
<li><p>GeneRatio: &quot;character&quot; ratio of input proteins that are annotated in a term
</p>
</li>
<li><p>BgRatio: &quot;character&quot; ratio of all genes that are annotated in this term
</p>
</li>
<li><p>pvalue: &quot;numeric&quot; p-value of enrichment
</p>
</li>
<li><p>p.adjust: &quot;numeric&quot; Adjusted p-value (Benjamini-Hochberg)
</p>
</li>
<li><p>qvalue: &quot;numeric&quot; false discovery rate, the estimated probability that the normalized enrichment score represents
a false positive finding
</p>
</li>
<li><p>geneID: &quot;character&quot; list of input proteins (Gene Symbols) annotated in a term delimited by &quot;/&quot;
</p>
</li>
<li><p>Count: &quot;integer&quot; Number of input proteins that are annotated in a term
</p>
</li></ul>

<p>Columns for GSEA:
</p>

<ul>
<li><p>ID: &quot;character&quot; Pathway ID from MSigDB
</p>
</li>
<li><p>Description: &quot;character&quot; Description of Pathway from MSigDB
</p>
</li>
<li><p>setSize: &quot;integer&quot; ratio of input proteins that are annotated in a term
</p>
</li>
<li><p>enrichmentScore: &quot;numeric&quot; Enrichment score, degree to which a gene set is over-represented at the top or
bottom of the ranked list of genes
</p>
</li>
<li><p>NES: &quot;numeric&quot; Normalized Enrichment Score, normalized to account for differences in gene set size and in
correlations between gene sets and expression data sets. NES can be used to compare analysis results
across gene sets.
</p>
</li>
<li><p>pvalue: &quot;numeric&quot; p-value of enrichment
</p>
</li>
<li><p>p.adjust: &quot;numeric&quot; Adjusted p-value (Benjamini-Hochberg)
</p>
</li>
<li><p>qvalue: &quot;numeric&quot; false discovery rate, the estimated probability that the normalized enrichment score represents
a false positive finding
</p>
</li>
<li><p>rank: &quot;numeric&quot; the position in the ranked list where the maximum enrichment score occurred
</p>
</li>
<li><p>leading_edge: &quot;character&quot; contains tags, list, and signal. Tags gives an indication of the percentage of genes
contributing to the enrichment score. List gives an indication of where in the list the enrichment
score is obtained. Signal represents the enrichment signal strength and combines the tag and list.
</p>
</li>
<li><p>core_enrichment: &quot;character&quot; list of input proteins (Gene Symbols) annotated in a term delimited by &quot;/&quot;
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li><p><code><a href="#topic+olink_pathway_heatmap">olink_pathway_heatmap</a></code> for generating a heat map of results
</p>
</li>
<li><p><code><a href="#topic+olink_pathway_visualization">olink_pathway_visualization</a></code> for generating a bar graph of results
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)
npx_df &lt;- npx_data1 %&gt;% filter(!grepl("control", SampleID, ignore.case = TRUE))
ttest_results &lt;- olink_ttest(
  df = npx_df,
  variable = "Treatment",
  alternative = "two.sided"
)
try({ # This expression might fail if dependencies are not installed
gsea_results &lt;- olink_pathway_enrichment(data = npx_data1, test_results = ttest_results)
ora_results &lt;- olink_pathway_enrichment(
  data = npx_data1,
  test_results = ttest_results, method = "ORA"
)
}, silent = TRUE)

</code></pre>

<hr>
<h2 id='olink_pathway_heatmap'>Creates a heatmap of selected pathways and proteins</h2><span id='topic+olink_pathway_heatmap'></span>

<h3>Description</h3>

<p>Creates a heatmap of proteins related to pathways using enrichment results from olink_pathway_enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_pathway_heatmap(
  enrich_results,
  test_results,
  method = "GSEA",
  keyword = NULL,
  number_of_terms = 20
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_pathway_heatmap_+3A_enrich_results">enrich_results</code></td>
<td>
<p>data frame of enrichment results from olink_pathway_enrichment()</p>
</td></tr>
<tr><td><code id="olink_pathway_heatmap_+3A_test_results">test_results</code></td>
<td>
<p>filtered results from statistical test with Assay, OlinkID, and estimate columns</p>
</td></tr>
<tr><td><code id="olink_pathway_heatmap_+3A_method">method</code></td>
<td>
<p>method used in olink_pathway_enrichment (&quot;GSEA&quot; (default) or &quot;ORA&quot;)</p>
</td></tr>
<tr><td><code id="olink_pathway_heatmap_+3A_keyword">keyword</code></td>
<td>
<p>(optional) keyword to filter enrichment results on, if not specified, displays top terms</p>
</td></tr>
<tr><td><code id="olink_pathway_heatmap_+3A_number_of_terms">number_of_terms</code></td>
<td>
<p>number of terms to display, default is 20</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A heatmap as a ggplot object
</p>


<h3>See Also</h3>


<ul>
<li><p><code><a href="#topic+olink_pathway_enrichment">olink_pathway_enrichment</a></code> for generating enrichment results
</p>
</li>
<li><p><code><a href="#topic+olink_pathway_visualization">olink_pathway_visualization</a></code> for generating a bar graph of results
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)
# Run t-test results (see olink_ttest documentation)
npx_df &lt;- npx_data1 %&gt;% filter(!grepl('control',SampleID, ignore.case = TRUE))
ttest_results &lt;- olink_ttest(df=npx_df,
                             variable = 'Treatment',
                            alternative = 'two.sided')

try({ # This expression might fail if dependencies are not installed
#  Run olink_pathway_enrichment (see documentation)
gsea_results &lt;- olink_pathway_enrichment(data = npx_data1, test_results = ttest_results)
ora_results &lt;- olink_pathway_enrichment(data = npx_data1,
                                        test_results = ttest_results, method = "ORA")
olink_pathway_heatmap(enrich_results = gsea_results, test_results = ttest_results)
olink_pathway_heatmap(enrich_results = ora_results, test_results = ttest_results,
                      method = "ORA", keyword = "cell")
})




</code></pre>

<hr>
<h2 id='olink_pathway_visualization'>Creates bargraph of top/selected enrichment terms from GSEA or ORA results from olink_pathway_enrichment()</h2><span id='topic+olink_pathway_visualization'></span>

<h3>Description</h3>

<p>Pathways are ordered by increasing p-value (unadjusted)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_pathway_visualization(
  enrich_results,
  method = "GSEA",
  keyword = NULL,
  number_of_terms = 20
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_pathway_visualization_+3A_enrich_results">enrich_results</code></td>
<td>
<p>data frame of enrichment results from olink_pathway_enrichment()</p>
</td></tr>
<tr><td><code id="olink_pathway_visualization_+3A_method">method</code></td>
<td>
<p>method used in olink_pathway_enrichment (&quot;GSEA&quot; (default) or &quot;ORA&quot;)</p>
</td></tr>
<tr><td><code id="olink_pathway_visualization_+3A_keyword">keyword</code></td>
<td>
<p>(optional) keyword to filter enrichment results on, if not specified, displays top terms</p>
</td></tr>
<tr><td><code id="olink_pathway_visualization_+3A_number_of_terms">number_of_terms</code></td>
<td>
<p>number of terms to display, default is 20</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bargraph as a ggplot object
</p>


<h3>See Also</h3>


<ul>
<li><p><code><a href="#topic+olink_pathway_enrichment">olink_pathway_enrichment</a></code> for generating enrichment results
</p>
</li>
<li><p><code><a href="#topic+olink_pathway_heatmap">olink_pathway_heatmap</a></code> for generating a heat map of results
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)
# Run olink_ttest or other stats test (see documentaiton )
npx_df &lt;- npx_data1 %&gt;% filter(!grepl('control',SampleID, ignore.case = TRUE))
ttest_results &lt;- olink_ttest(df=npx_df,
                             variable = 'Treatment',
                             alternative = 'two.sided')

try({ # This expression might fail if dependencies are not installed
# Run olink_pathway_enrichment (see documentation)
gsea_results &lt;- olink_pathway_enrichment(data = npx_data1, test_results = ttest_results)
ora_results &lt;- olink_pathway_enrichment(data = npx_data1,
                                       test_results = ttest_results, method = "ORA")
olink_pathway_visualization(enrich_results = gsea_results)
olink_pathway_visualization(enrich_results = gsea_results, keyword = "immune")
olink_pathway_visualization(enrich_results = ora_results, method = "ORA", number_of_terms = 15)
})



</code></pre>

<hr>
<h2 id='olink_pca_plot'>Function to plot a PCA of the data</h2><span id='topic+olink_pca_plot'></span>

<h3>Description</h3>

<p>Generates a PCA projection of all samples from NPX data along two principal components (default PC2 vs. PC1) including the explained variance and dots colored by QC_Warning using stats::prcomp and ggplot2::ggplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_pca_plot(
  df,
  color_g = "QC_Warning",
  x_val = 1,
  y_val = 2,
  label_samples = FALSE,
  drop_assays = FALSE,
  drop_samples = FALSE,
  n_loadings = 0,
  loadings_list = NULL,
  byPanel = FALSE,
  outlierDefX = NA,
  outlierDefY = NA,
  outlierLines = FALSE,
  label_outliers = TRUE,
  quiet = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_pca_plot_+3A_df">df</code></td>
<td>
<p>data frame in long format with Sample Id, NPX and column of choice for colors</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_color_g">color_g</code></td>
<td>
<p>Character value indicating which column to use for colors (default QC_Warning)</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_x_val">x_val</code></td>
<td>
<p>Integer indicating which principal component to plot along the x-axis (default 1)</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_y_val">y_val</code></td>
<td>
<p>Integer indicating which principal component to plot along the y-axis (default 2)</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_label_samples">label_samples</code></td>
<td>
<p>Logical. If TRUE, points are replaced with SampleID (default FALSE)</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_drop_assays">drop_assays</code></td>
<td>
<p>Logical. All assays with any missing values will be dropped. Takes precedence over sample drop.</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_drop_samples">drop_samples</code></td>
<td>
<p>Logical. All samples with any missing values will be dropped.</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_n_loadings">n_loadings</code></td>
<td>
<p>Integer. Will plot the top n_loadings based on size.</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_loadings_list">loadings_list</code></td>
<td>
<p>Character vector indicating for which OlinkID's to plot as loadings. It is possible to use n_loadings and loadings_list simultaneously.</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_bypanel">byPanel</code></td>
<td>
<p>Perform the PCA per panel (default FALSE)</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_outlierdefx">outlierDefX</code></td>
<td>
<p>The number standard deviations along the PC plotted on the x-axis that defines an outlier. See also 'Details&quot;</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_outlierdefy">outlierDefY</code></td>
<td>
<p>The number standard deviations along the PC plotted on the y-axis that defines an outlier. See also 'Details&quot;</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_outlierlines">outlierLines</code></td>
<td>
<p>Draw dashed lines at +/- outlierDefX and outlierDefY standard deviations from the mean of the plotted PCs (default FALSE)</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_label_outliers">label_outliers</code></td>
<td>
<p>Use ggrepel to label samples lying outside the limits set by the outlierLines (default TRUE)</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_quiet">quiet</code></td>
<td>
<p>Logical. If TRUE, the resulting plot is not printed</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Whether warnings about the number of samples and/or assays dropped or imputed should be printed to the console.</p>
</td></tr>
<tr><td><code id="olink_pca_plot_+3A_...">...</code></td>
<td>
<p>coloroption passed to specify color order.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The values are by default scaled and centered in the PCA and proteins with missing NPX values are by default removed from the corresponding assay.
Unique sample names are required.
Imputation by the median is done for assays with missingness &lt;10\
The plot is printed, and a list of ggplot objects is returned. <br /><br />
If byPanel = TRUE, the data processing (imputation of missing values etc) and subsequent PCA is performed separately per panel. A faceted plot is printed, while the individual ggplot objects are returned. <br /><br />
The arguments outlierDefX and outlierDefY can be used to identify outliers in the PCA. Samples more than +/- outlierDefX and outlierDefY standard deviations from the mean of the plotted PC will be labelled. Both arguments have to be specified.
</p>


<h3>Value</h3>

<p>A list of objects of class &quot;ggplot&quot;, each plot contains scatter plot of PCs
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)
npx_data &lt;- npx_data1 %&gt;%
    filter(!grepl('CONTROL', SampleID))

#PCA using all the data
olink_pca_plot(df=npx_data, color_g = "QC_Warning")

#PCA per panel
g &lt;- olink_pca_plot(df=npx_data, color_g = "QC_Warning", byPanel = TRUE)
g[[2]] #Plot only the second panel

#Label outliers
olink_pca_plot(df=npx_data, color_g = "QC_Warning",
               outlierDefX = 2, outlierDefY = 4) #All data
olink_pca_plot(df=npx_data, color_g = "QC_Warning",
               outlierDefX = 2.5, outlierDefY = 4, byPanel = TRUE) #Per panel

#Retrieve the outliers
g &lt;- olink_pca_plot(df=npx_data, color_g = "QC_Warning",
                    outlierDefX = 2.5, outlierDefY = 4, byPanel = TRUE)
outliers &lt;- lapply(g, function(x){x$data}) %&gt;%
    bind_rows() %&gt;%
    filter(Outlier == 1)

</code></pre>

<hr>
<h2 id='olink_plate_randomizer'>Randomly assign samples to plates</h2><span id='topic+olink_plate_randomizer'></span>

<h3>Description</h3>

<p>Generates a scheme for how to plate samples with an option to keep subjects on the same plate and/or to keep studies together.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_plate_randomizer(
  Manifest,
  PlateSize = 96,
  Product,
  SubjectColumn,
  iterations = 500,
  available.spots,
  num_ctrl = 8,
  rand_ctrl = FALSE,
  seed,
  study = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_plate_randomizer_+3A_manifest">Manifest</code></td>
<td>
<p>tibble/data frame in long format containing all sample ID's. Sample ID column must be named SampleID.</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_platesize">PlateSize</code></td>
<td>
<p>Integer. Either 96 or 48. 96 is default.</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_product">Product</code></td>
<td>
<p>String. Name of Olink product used to set PlateSize if not provided. Optional.</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_subjectcolumn">SubjectColumn</code></td>
<td>
<p>(Optional) Column name of the subject ID column. Cannot contain missing values. If provided, subjects are kept on the same plate. This argument is used for longitudinal studies and must be a separate column from the SampleID column.</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations for fitting subjects on the same plate.</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_available.spots">available.spots</code></td>
<td>
<p>Numeric. Number of wells available on each plate. Maximum 40 for T48 and 88 for T96. Takes a vector equal to the number of plates to be used indicating the number of wells available on each plate.</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_num_ctrl">num_ctrl</code></td>
<td>
<p>Numeric. Number of controls on each plate (default = 8)</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_rand_ctrl">rand_ctrl</code></td>
<td>
<p>Logical. Whether controls are added to be randomized across the plate (default = FALSE)</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_seed">seed</code></td>
<td>
<p>Seed to set. Highly recommend setting this for reproducibility.</p>
</td></tr>
<tr><td><code id="olink_plate_randomizer_+3A_study">study</code></td>
<td>
<p>String. Optional. Name of column that includes study information. For when multiple studies are being plated and randomizing within studies. If <code>study</code> column is present in manifest, within study randomization will be performed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variables of interest should if possible be randomized across plates to avoid confounding with potential plate effects. In the case of multiple samples per subject (e.g. in longitudinal studies), Olink recommends keeping each subject on the same plate. This can be achieved using the SubjectColumn argument.
</p>


<h3>Value</h3>

<p>A &quot;tibble&quot; including SampleID, SubjectID etc. assigned to well positions.
Columns include same columns as Manifest with additional columns:
</p>

<ul>
<li><p>plate: Plate number
</p>
</li>
<li><p>column: Column on the plate
</p>
</li>
<li><p>row: Row on the plate
</p>
</li>
<li><p>well: Well location on the plate
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li><p><code><a href="#topic+olink_displayPlateLayout">olink_displayPlateLayout()</a></code> for visualizing the generated plate layouts
</p>
</li>
<li><p><code><a href="#topic+olink_displayPlateDistributions">olink_displayPlateDistributions()</a></code> for validating that sites are properly randomized
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
#Generate randomization scheme using complete randomization
randomized.manifest_a &lt;- olink_plate_randomizer(manifest, seed=12345)

#Generate randomization scheme that keeps subjects on the same plate (for longitudinal studies)
randomized.manifest_b &lt;- olink_plate_randomizer(manifest,SubjectColumn="SubjectID",
                                                        available.spots=c(88,88), seed=12345)

# Generate randomization scheme that keeps samples from the same study together
randomized.manifest_c &lt;- olink_plate_randomizer(manifest, study = "Site")

#Visualize the generated plate layouts
olink_displayPlateLayout(randomized.manifest_a, fill.color = 'Site')
olink_displayPlateLayout(randomized.manifest_a, fill.color = 'SubjectID')
olink_displayPlateLayout(randomized.manifest_b, fill.color = 'Site')
olink_displayPlateLayout(randomized.manifest_b, fill.color = 'SubjectID')
olink_displayPlateLayout(randomized.manifest_c, fill.color = 'Site')

#Validate that sites are properly randomized
olink_displayPlateDistributions(randomized.manifest_a, fill.color = 'Site')
olink_displayPlateDistributions(randomized.manifest_b, fill.color = 'Site')



</code></pre>

<hr>
<h2 id='olink_qc_plot'>Function to plot an overview of a sample cohort per Panel</h2><span id='topic+olink_qc_plot'></span>

<h3>Description</h3>

<p>Generates a facet plot per Panel using ggplot2::ggplot and ggplot2::geom_point and stats::IQR plotting IQR vs. median for all samples.
Horizontal dashed lines indicate +/-IQR_outlierDef standard deviations from the mean IQR (default 3).
Vertical dashed lines indicate +/-median_outlierDef standard deviations from the mean sample median (default 3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_qc_plot(
  df,
  color_g = "QC_Warning",
  plot_index = FALSE,
  label_outliers = TRUE,
  IQR_outlierDef = 3,
  median_outlierDef = 3,
  outlierLines = TRUE,
  facetNrow = NULL,
  facetNcol = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_qc_plot_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format. Must have columns SampleID, NPX and Panel</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_color_g">color_g</code></td>
<td>
<p>Character value indicating which column to use as fill color (default QC_Warning)</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_plot_index">plot_index</code></td>
<td>
<p>Boolean. If FALSE (default), a point will be plotted for a sample. If TRUE,
a sample's unique index number is displayed.</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_label_outliers">label_outliers</code></td>
<td>
<p>Boolean. If TRUE, an outlier sample will be labelled with its SampleID.</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_iqr_outlierdef">IQR_outlierDef</code></td>
<td>
<p>The number of standard deviations from the mean IQR that defines an outlier (default 3)</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_median_outlierdef">median_outlierDef</code></td>
<td>
<p>The number of standard deviations from the mean sample median that defines an outlier. (default 3)</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_outlierlines">outlierLines</code></td>
<td>
<p>Draw dashed lines at +/-IQR_outlierDef and +/-median_outlierDef standard deviations from the mean IQR and sample median respectively (default TRUE)</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_facetnrow">facetNrow</code></td>
<td>
<p>The number of rows that the panels are arranged on</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_facetncol">facetNcol</code></td>
<td>
<p>The number of columns that the panels are arranged on</p>
</td></tr>
<tr><td><code id="olink_qc_plot_+3A_...">...</code></td>
<td>
<p>coloroption passed to specify color order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot;. Scatterplot shows IQR vs median for all samples per panel
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)

olink_qc_plot(npx_data1, color_g = "QC_Warning")

#Change the outlier threshold to +-4SD
olink_qc_plot(npx_data1, color_g = "QC_Warning", IQR_outlierDef = 4, median_outlierDef = 4)

#Identify the outliers
qc &lt;- olink_qc_plot(npx_data1, color_g = "QC_Warning", IQR_outlierDef = 4, median_outlierDef = 4)
outliers &lt;- qc$data %&gt;% filter(Outlier == 1)

</code></pre>

<hr>
<h2 id='olink_ttest'>Function which performs a t-test per protein</h2><span id='topic+olink_ttest'></span>

<h3>Description</h3>

<p>Performs a Welch 2-sample t-test or paired t-test at confidence level 0.95 for every protein (by OlinkID)
for a given grouping variable using stats::t.test and corrects for multiple testing by
the Benjamini-Hochberg method (“fdr”) using stats::p.adjust.
Adjusted p-values are logically evaluated towards adjusted p-value&lt;0.05.
The resulting t-test table is arranged by ascending p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_ttest(df, variable, pair_id, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_ttest_+3A_df">df</code></td>
<td>
<p>NPX data frame in long format with at least protein name (Assay), OlinkID, UniProt and a factor with 2 levels.</p>
</td></tr>
<tr><td><code id="olink_ttest_+3A_variable">variable</code></td>
<td>
<p>Character value indicating which column should be used as the grouping variable. Needs to have exactly 2 levels.</p>
</td></tr>
<tr><td><code id="olink_ttest_+3A_pair_id">pair_id</code></td>
<td>
<p>Character value indicating which column indicates the paired sample identifier.</p>
</td></tr>
<tr><td><code id="olink_ttest_+3A_...">...</code></td>
<td>
<p>Options to be passed to t.test. See <code>?t.test</code> for more information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; containing the t-test results for every protein.
Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>estimate: &quot;numeric&quot; difference in mean NPX between groups
</p>
</li>
<li><p>Group 1: &quot;numeric&quot; Column is named first level of variable when converted to factor, contains mean NPX for that group
</p>
</li>
<li><p>Group 2: &quot;numeric&quot; Column is named second level of variable when converted to factor, contains mean NPX for that group
</p>
</li>
<li><p>statistic: &quot;named numeric&quot; value of the t-statistic
</p>
</li>
<li><p>p.value: &quot;numeric&quot; p-value for the test
</p>
</li>
<li><p>parameter: &quot;named numeric&quot; degrees of freedom for the t-statistic
</p>
</li>
<li><p>conf.low: &quot;numeric&quot; confidence interval for the mean (lower end)
</p>
</li>
<li><p>conf.high: &quot;numeric&quot; confidence interval for the mean (upper end)
</p>
</li>
<li><p>method: &quot;character&quot; which t-test method was used
</p>
</li>
<li><p>alternative: &quot;character&quot; describes the alternative hypothesis
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test (Benjamini&amp;Hochberg)
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)

npx_df &lt;- npx_data1 %&gt;% filter(!grepl('control',SampleID, ignore.case = TRUE))

ttest_results &lt;- olink_ttest(df=npx_df,
                             variable = 'Treatment',
                             alternative = 'two.sided')

#Paired t-test
npx_df %&gt;%
   filter(Time %in% c("Baseline","Week.6")) %&gt;%
   olink_ttest(variable = "Time", pair_id = "Subject")

</code></pre>

<hr>
<h2 id='olink_umap_plot'>Function to make a UMAP plot from the data</h2><span id='topic+olink_umap_plot'></span>

<h3>Description</h3>

<p>Computes a manifold approximation and projection using umap::umap and plots the two specified components.
Unique sample names are required and imputation by the median is done for assays with missingness &lt;10\
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_umap_plot(
  df,
  color_g = "QC_Warning",
  x_val = 1,
  y_val = 2,
  config = NULL,
  label_samples = FALSE,
  drop_assays = FALSE,
  drop_samples = FALSE,
  byPanel = FALSE,
  outlierDefX = NA,
  outlierDefY = NA,
  outlierLines = FALSE,
  label_outliers = TRUE,
  quiet = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_umap_plot_+3A_df">df</code></td>
<td>
<p>data frame in long format with Sample Id, NPX and column of choice for colors</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_color_g">color_g</code></td>
<td>
<p>Character value indicating which column to use for colors (default QC_Warning)</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_x_val">x_val</code></td>
<td>
<p>Integer indicating which UMAP component to plot along the x-axis (default 1)</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_y_val">y_val</code></td>
<td>
<p>Integer indicating which UMAP component to plot along the y-axis (default 2)</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_config">config</code></td>
<td>
<p>object of class umap.config, specifying the parameters for the UMAP algorithm (default umap::umap.defaults)</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_label_samples">label_samples</code></td>
<td>
<p>Logical. If TRUE, points are replaced with SampleID (default FALSE)</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_drop_assays">drop_assays</code></td>
<td>
<p>Logical. All assays with any missing values will be dropped. Takes precedence over sample drop.</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_drop_samples">drop_samples</code></td>
<td>
<p>Logical. All samples with any missing values will be dropped.</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_bypanel">byPanel</code></td>
<td>
<p>Perform the UMAP per panel (default FALSE)</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_outlierdefx">outlierDefX</code></td>
<td>
<p>The number standard deviations along the UMAP dimension plotted on the x-axis that defines an outlier. See also 'Details&quot;</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_outlierdefy">outlierDefY</code></td>
<td>
<p>The number standard deviations along the UMAP dimension plotted on the y-axis that defines an outlier. See also 'Details&quot;</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_outlierlines">outlierLines</code></td>
<td>
<p>Draw dashed lines at +/- outlierDefX and outlierDefY standard deviations from the mean of the plotted PCs (default FALSE)</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_label_outliers">label_outliers</code></td>
<td>
<p>Use ggrepel to label samples lying outside the limits set by the outlierLines (default TRUE)</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_quiet">quiet</code></td>
<td>
<p>Logical. If TRUE, the resulting plot is not printed</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Whether warnings about the number of samples and/or assays dropped or imputed should be printed to the console.</p>
</td></tr>
<tr><td><code id="olink_umap_plot_+3A_...">...</code></td>
<td>
<p>coloroption passed to specify color order.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot is printed, and a list of ggplot objects is returned. <br /><br />
If byPanel = TRUE, the data processing (imputation of missing values etc) and subsequent UMAP is performed separately per panel. A faceted plot is printed, while the individual ggplot objects are returned. <br /><br />
The arguments outlierDefX and outlierDefY can be used to identify outliers in the UMAP results. Samples more than +/- outlierDefX and outlierDefY standard deviations from the mean of the plotted UMAP component will be labelled. Both arguments have to be specified.
NOTE: UMAP is a non-linear data transformation that might not accurately preserve the properties of the data. Distances in the UMAP plane should therefore be interpreted with caution.
</p>


<h3>Value</h3>

<p>A list of objects of class &quot;ggplot&quot;, each plot contains scatter plot of UMAPs
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)
npx_data &lt;- npx_data1 %&gt;%
    mutate(SampleID = paste(SampleID, "_", Index, sep = ""))
try({ # Requires umap package dependency
#UMAP using all the data
olink_umap_plot(df=npx_data, color_g = "QC_Warning")

#UMAP per panel
g &lt;- olink_umap_plot(df=npx_data, color_g = "QC_Warning", byPanel = TRUE)
g$Inflammation #Plot only the Inflammation panel

#Label outliers
olink_umap_plot(df=npx_data, color_g = "QC_Warning",
               outlierDefX = 2, outlierDefY = 4) #All data
olink_umap_plot(df=npx_data, color_g = "QC_Warning",
               outlierDefX = 3, outlierDefY = 2, byPanel = TRUE) #Per panel

#Retrieve the outliers
g &lt;- olink_umap_plot(df=npx_data, color_g = "QC_Warning",
                    outlierDefX = 3, outlierDefY = 2, byPanel = TRUE)
outliers &lt;- lapply(g, function(x){x$data}) %&gt;%
    bind_rows() %&gt;%
    filter(Outlier == 1)
})

</code></pre>

<hr>
<h2 id='olink_volcano_plot'>Easy volcano plot with Olink theme</h2><span id='topic+olink_volcano_plot'></span>

<h3>Description</h3>

<p>Generates a volcano plot using the results of the olink_ttest function using ggplot and ggplot2::geom_point.
The estimated difference is plotted on the x-axis and the negative 10-log p-value on the y-axis.
The horizontal dotted line indicates p-value=0.05.
Dots are colored based on the Benjamini-Hochberg adjusted p-value cutoff 0.05 and can optionally be annotated by OlinkID.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_volcano_plot(p.val_tbl, x_lab = "Estimate", olinkid_list = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_volcano_plot_+3A_p.val_tbl">p.val_tbl</code></td>
<td>
<p>a data frame of results generated by olink_ttest()</p>
</td></tr>
<tr><td><code id="olink_volcano_plot_+3A_x_lab">x_lab</code></td>
<td>
<p>Optional. Character value to use as the X-axis label</p>
</td></tr>
<tr><td><code id="olink_volcano_plot_+3A_olinkid_list">olinkid_list</code></td>
<td>
<p>Optional. Character vector of proteins (by OlinkID) to label in the plot. If not provided, default is to label all significant proteins.</p>
</td></tr>
<tr><td><code id="olink_volcano_plot_+3A_...">...</code></td>
<td>
<p>Optional. Additional arguments for  olink_color_discrete()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot;, plotting significance (y-axis) by estimated difference between groups (x-axis) for each protein.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)

npx_df &lt;- npx_data1 %&gt;% filter(!grepl('control',SampleID, ignore.case = TRUE))
ttest_results &lt;- olink_ttest(df=npx_df,
                             variable = 'Treatment',
                             alternative = 'two.sided')
olink_volcano_plot(ttest_results)
</code></pre>

<hr>
<h2 id='olink_wilcox'>Function which performs a Mann-Whitney U Test per protein</h2><span id='topic+olink_wilcox'></span>

<h3>Description</h3>

<p>Performs a Welch 2-sample Mann-Whitney U Test at confidence level 0.95 for every protein (by OlinkID)
for a given grouping variable using stats::wilcox.test and corrects for multiple testing by
the Benjamini-Hochberg method (“fdr”) using stats::p.adjust.
Adjusted p-values are logically evaluated towards adjusted p-value&lt;0.05.
The resulting Mann-Whitney U Test table is arranged by ascending p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olink_wilcox(df, variable, pair_id, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olink_wilcox_+3A_df">df</code></td>
<td>
<p>NPX or Quantified_value data frame in long format with at least protein name (Assay), OlinkID, UniProt and a factor with 2 levels.</p>
</td></tr>
<tr><td><code id="olink_wilcox_+3A_variable">variable</code></td>
<td>
<p>Character value indicating which column should be used as the grouping variable. Needs to have exactly 2 levels.</p>
</td></tr>
<tr><td><code id="olink_wilcox_+3A_pair_id">pair_id</code></td>
<td>
<p>Character value indicating which column indicates the paired sample identifier.</p>
</td></tr>
<tr><td><code id="olink_wilcox_+3A_...">...</code></td>
<td>
<p>Options to be passed to wilcox.test. See <code>?wilcox_test</code> for more information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the Mann-Whitney U Test results for every protein.
</p>
<p>Columns include:
</p>

<ul>
<li><p>Assay: &quot;character&quot; Protein symbol
</p>
</li>
<li><p>OlinkID: &quot;character&quot; Olink specific ID
</p>
</li>
<li><p>UniProt: &quot;character&quot; UniProt ID
</p>
</li>
<li><p>Panel: &quot;character&quot; Name of Olink Panel
</p>
</li>
<li><p>estimate: &quot;numeric&quot; median of NPX differences between groups
</p>
</li>
<li><p>statistic: &quot;named numeric&quot; the value of the test statistic with a name describing it
</p>
</li>
<li><p>p.value: &quot;numeric&quot; p-value for the test
</p>
</li>
<li><p>conf.low: &quot;numeric&quot; confidence interval for the median of differences (lower end)
</p>
</li>
<li><p>conf.high: &quot;numeric&quot; confidence interval for the median of differences (upper end)
</p>
</li>
<li><p>method: &quot;character&quot; which wilcoxon method was used
</p>
</li>
<li><p>alternative: &quot;character&quot; describes the alternative hypothesis
</p>
</li>
<li><p>Adjusted_pval: &quot;numeric&quot; adjusted p-value for the test (Benjamini&amp;Hochberg)
</p>
</li>
<li><p>Threshold: &quot;character&quot; if adjusted p-value is significant or not (&lt; 0.05)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

library(dplyr)

npx_df &lt;- npx_data1 %&gt;% filter(!grepl('control',SampleID, ignore.case = TRUE))

wilcox_results &lt;- olink_wilcox(df = npx_df,
                               variable = 'Treatment',
                               alternative = 'two.sided')

#Paired Mann-Whitney U Test
npx_df %&gt;%
   filter(Time %in% c("Baseline","Week.6")) %&gt;%
   olink_wilcox(variable = "Time", pair_id = "Subject")

</code></pre>

<hr>
<h2 id='print_and_capture'>Capture the output of printing an object</h2><span id='topic+print_and_capture'></span>

<h3>Description</h3>

<p>Capture the output of printing an object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print_and_capture(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print_and_capture_+3A_x">x</code></td>
<td>
<p>printable object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string representation of the provided object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
OlinkAnalyze:::print_and_capture(npx_data1)

</code></pre>

<hr>
<h2 id='read_flex'>Read in flex data</h2><span id='topic+read_flex'></span>

<h3>Description</h3>

<p>Called by read_NPX
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_flex(filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_flex_+3A_filename">filename</code></td>
<td>
<p>where the file is located</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tibble of data
</p>

<hr>
<h2 id='read_NPX'>Function to read NPX data into long format</h2><span id='topic+read_NPX'></span>

<h3>Description</h3>

<p>Imports an NPX or QUANT file exported from Olink Software.
No alterations to the output format is allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_NPX(filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_NPX_+3A_filename">filename</code></td>
<td>
<p>Path to Olink Software output file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; in long format. Columns include:
</p>

<ul>
<li><p>SampleID: Sample ID
</p>
</li>
<li><p>Index: Index
</p>
</li>
<li><p>OlinkID: Olink ID
</p>
</li>
<li><p>UniProt: UniProt ID
</p>
</li>
<li><p>Assay: Protein symbol
</p>
</li>
<li><p>MissingFreq: Proportion of sample below LOD
</p>
</li>
<li><p>Panel_Version: Panel Version
</p>
</li>
<li><p>PlateID: Plate ID
</p>
</li>
<li><p>QC_Warning: QC Warning Status
</p>
</li>
<li><p>LOD: Limit of detection
</p>
</li>
<li><p>NPX: Normalized Protein Expression
</p>
</li></ul>

<p>Additional columns may be present or missing depending on the platform
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
file &lt;- system.file("extdata", "Example_NPX_Data.csv", package = "OlinkAnalyze")
read_NPX(file)

</code></pre>

<hr>
<h2 id='read_npx_csv'>Helper function to read in Olink Explore csv or txt files</h2><span id='topic+read_npx_csv'></span>

<h3>Description</h3>

<p>Helper function to read in Olink Explore csv or txt files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_npx_csv(filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_npx_csv_+3A_filename">filename</code></td>
<td>
<p>Path to Olink Software output txt of csv file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; in long format. Some of the columns are:
</p>

<ul>
<li><p>SampleID: Sample ID
</p>
</li>
<li><p>Index: Index
</p>
</li>
<li><p>OlinkID: Olink ID
</p>
</li>
<li><p>UniProt: UniProt ID
</p>
</li>
<li><p>Assay: Protein symbol
</p>
</li>
<li><p>MissingFreq: Proportion of sample below LOD
</p>
</li>
<li><p>Panel_Version: Panel Version
</p>
</li>
<li><p>PlateID: Plate ID
</p>
</li>
<li><p>QC_Warning: QC Warning Status
</p>
</li>
<li><p>LOD: Limit of detection
</p>
</li>
<li><p>NPX: Normalized Protein Expression
</p>
</li></ul>

<p>Additional columns may be present or missing depending on the platform
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
file &lt;- system.file("extdata", "Example_NPX_Data.csv", package = "OlinkAnalyze")
read_NPX(file)


</code></pre>

<hr>
<h2 id='read_npx_parquet'>Helper function to read in Olink Explore parquet output files</h2><span id='topic+read_npx_parquet'></span>

<h3>Description</h3>

<p>Helper function to read in Olink Explore parquet output files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_npx_parquet(filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_npx_parquet_+3A_filename">filename</code></td>
<td>
<p>Path to Olink Software parquet output file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; in long format. Some of the columns are:
</p>

<ul>
<li><p>SampleID: Sample ID
</p>
</li>
<li><p>OlinkID: Olink ID
</p>
</li>
<li><p>UniProt: UniProt ID
</p>
</li>
<li><p>Assay: Protein symbol
</p>
</li>
<li><p>PlateID: Plate ID
</p>
</li>
<li><p>Count: Counts from sequences
</p>
</li>
<li><p>ExtNPX: External control normalized counts
</p>
</li>
<li><p>NPX: Normalized Protein Expression
</p>
</li></ul>

<p>Additional columns may be present or missing depending on the platform
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
file &lt;- system.file("extdata", "Example_NPX_Data.csv", package = "OlinkAnalyze")
read_NPX(file)


</code></pre>

<hr>
<h2 id='read_npx_zip'>Helper function to read in Olink Explore zip csv files</h2><span id='topic+read_npx_zip'></span>

<h3>Description</h3>

<p>Helper function to read in Olink Explore zip csv files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_npx_zip(filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_npx_zip_+3A_filename">filename</code></td>
<td>
<p>Path to Olink Software output zip file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;tibble&quot; in long format. Some of the columns are:
</p>

<ul>
<li><p>SampleID: Sample ID
</p>
</li>
<li><p>Index: Index
</p>
</li>
<li><p>OlinkID: Olink ID
</p>
</li>
<li><p>UniProt: UniProt ID
</p>
</li>
<li><p>Assay: Protein symbol
</p>
</li>
<li><p>MissingFreq: Proportion of sample below LOD
</p>
</li>
<li><p>Panel_Version: Panel Version
</p>
</li>
<li><p>PlateID: Plate ID
</p>
</li>
<li><p>QC_Warning: QC Warning Status
</p>
</li>
<li><p>LOD: Limit of detection
</p>
</li>
<li><p>NPX: Normalized Protein Expression
</p>
</li></ul>

<p>Additional columns may be present or missing depending on the platform
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
try({ # May fail if dependencies are not installed
file &lt;- system.file("extdata", "Example_NPX_Data.csv", package = "OlinkAnalyze")
read_NPX(file)
})



</code></pre>

<hr>
<h2 id='set_plot_theme'>Function to set plot theme</h2><span id='topic+set_plot_theme'></span>

<h3>Description</h3>

<p>This function sets a coherent plot theme for functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_plot_theme(font = "Swedish Gothic Thin")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_plot_theme_+3A_font">font</code></td>
<td>
<p>Font family to use for text elements. Depends on extrafont package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, used as theme for ggplots
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)

ggplot(mtcars, aes(x = wt, y = mpg, color = as.factor(cyl))) +
  geom_point(size = 4) +
  set_plot_theme()

ggplot(mtcars, aes(x = wt, y = mpg, color = as.factor(cyl))) +
  geom_point(size = 4) +
  set_plot_theme(font = "")


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
