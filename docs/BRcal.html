<!DOCTYPE html><html lang="en"><head><title>Help for package BRcal</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BRcal}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bayes_ms'><p>Bayesian Model Selection-Based Calibration Assessment</p></a></li>
<li><a href='#brcal'><p>Boldness-Recalibration for Binary Events</p></a></li>
<li><a href='#foreclosure'><p>Foreclosure Monitoring Predictions data</p></a></li>
<li><a href='#hockey'><p>Hockey Home Team Win Predictions data</p></a></li>
<li><a href='#lineplot'><p>Lineplot for LLO-adjusted Probability Predictions</p></a></li>
<li><a href='#LLO'><p>Linear Log Odds (LLO) Recalibration Function</p></a></li>
<li><a href='#llo_lrt'><p>Likelihood Ratio Test for Calibration</p></a></li>
<li><a href='#mle_recal'><p>Recalibration via Maximum Likelihood Estimates (MLEs)</p></a></li>
<li><a href='#plot_params'><p>Draw image plot of posterior model probability surface.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Boldness-Recalibration of Binary Events</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Boldness-recalibration maximally spreads out probability predictions while maintaining a user specified level of calibration, facilitated the brcal() function. Supporting functions to assess calibration via Bayesian and Frequentist approaches, Maximum Likelihood Estimator (MLE) recalibration, Linear in Log Odds (LLO)-adjust via any specified parameters, and visualize results are also provided. Methodological details can be found in Guthrie &amp; Franck (2024) &lt;<a href="https://doi.org/10.1080%2F00031305.2024.2339266">doi:10.1080/00031305.2024.2339266</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>nloptr, fields, ggplot2, lifecycle</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, devtools, xfun, gridExtra, testthat (&ge;
3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/apguthrie/BRcal">https://github.com/apguthrie/BRcal</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/apguthrie/BRcal/issues">https://github.com/apguthrie/BRcal/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-14 13:19:41 UTC; apgut</td>
</tr>
<tr>
<td>Author:</td>
<td>Adeline P. Guthrie
    <a href="https://orcid.org/0009-0000-1548-3648"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Christopher T. Franck [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adeline P. Guthrie &lt;apguthrie47@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-14 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bayes_ms'>Bayesian Model Selection-Based Calibration Assessment</h2><span id='topic+bayes_ms'></span>

<h3>Description</h3>

<p>Perform Bayesian model selection-based approach to determine if a set of
predicted probabilities <code>x</code> is well calibrated given the corresponding set of
binary event outcomes <code>y</code> as described in Guthrie and Franck (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayes_ms(
  x,
  y,
  Pmc = 0.5,
  event = 1,
  optim_details = TRUE,
  epsilon = .Machine$double.eps,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bayes_ms_+3A_x">x</code></td>
<td>
<p>a numeric vector of predicted probabilities of an event. Must only
contain values in [0,1].</p>
</td></tr>
<tr><td><code id="bayes_ms_+3A_y">y</code></td>
<td>
<p>a vector of outcomes corresponding to probabilities in <code>x</code>. Must
only contain two unique values (one for &quot;events&quot; and one for &quot;non-events&quot;).
By default, this function expects a vector of 0s (non-events) and 1s
(events).</p>
</td></tr>
<tr><td><code id="bayes_ms_+3A_pmc">Pmc</code></td>
<td>
<p>The prior model probability for the calibrated model <code class="reqn">M_c</code>.</p>
</td></tr>
<tr><td><code id="bayes_ms_+3A_event">event</code></td>
<td>
<p>Value in <code>y</code> that represents an &quot;event&quot;.  Default value is 1.</p>
</td></tr>
<tr><td><code id="bayes_ms_+3A_optim_details">optim_details</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the list returned by <a href="stats.html#topic+optim">optim</a> when
minimizing the negative log likelihood is also returned by this function.</p>
</td></tr>
<tr><td><code id="bayes_ms_+3A_epsilon">epsilon</code></td>
<td>
<p>Amount by which probabilities are pushed away from 0 or 1
boundary for numerical stability. If a value in <code>x</code> &lt; <code>epsilon</code>, it will be
replaced with <code>epsilon</code>.  If a value in <code>x</code> &gt; <code>1-epsilon</code>, that value will
be replaced with <code>1-epsilon</code>.</p>
</td></tr>
<tr><td><code id="bayes_ms_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <a href="stats.html#topic+optim">optim</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function compares a well calibrated model, <code class="reqn">M_c</code> where <code class="reqn">\delta =
\gamma = 1</code> to an uncalibrated model, <code class="reqn">M_u</code> where <code class="reqn">\delta&gt;0, \gamma \in
\mathbb{R}</code>.
</p>
<p>The posterior model probability of <code class="reqn">M_c</code> given the observed
outcomes <code>y</code> (returned as <code>posterior_model_prob</code>) is expressed as </p>
<p style="text-align: center;"><code class="reqn">P(M_c|\mathbf{y})
= \frac{P(\mathbf{y}|M_c) P(M_c)}{P(\mathbf{y}|M_c) P(M_c) + P(\mathbf{y}|M_{u}) P(M_{u})}</code>
</p>

<p>where <code class="reqn">P(\mathbf{y}|M_i)</code> is the integrated likelihoof of <code>y</code> given
<code class="reqn">M_i</code> and <code class="reqn">P(M_i)</code> is the prior probability of model i, <code class="reqn">i \in
\{c,u\}</code>. By default, this function uses <code class="reqn">P(M_c) = P(M_u) = 0.5</code>. To set a
different prior for <code class="reqn">P(M_c)</code>, use <code>Pmc</code>, and <code class="reqn">P(M_u)</code> will be set to
<code>1 - Pmc</code>.
</p>
<p>The Bayes factor (returned as <code>BF</code>) compares <code class="reqn">M_u</code> to <code class="reqn">M_c</code>.  This
value is approximated via the following large sample Bayesian Information
Criteria (BIC) approximation (see Kass &amp; Raftery 1995, Kass &amp; Wasserman 1995) </p>
<p style="text-align: center;"><code class="reqn">BF =
\frac{P(\mathbf{y}|M_{u})}{P(\mathbf{y}|M_c)} = \approx exp\left\{
-\frac{1}{2}(BIC_u - BIC_c) \right\}</code>
</p>
<p> where the BIC for the calibrated model
(returned as <code>BIC_mc</code>) is </p>
<p style="text-align: center;"><code class="reqn">BIC_c = - 2 \times log(\pi(\delta = 1, \gamma =1|\mathbf{x},\mathbf{y}))</code>
</p>

<p>and the BIC for the uncalibrated model (returned as <code>BIC_mu</code>) is </p>
<p style="text-align: center;"><code class="reqn">BIC_u =
2\times log(n) - 2\times log(\pi(\hat\delta_{MLE}, \hat\gamma_{MLE}|\mathbf{x},\mathbf{y})).</code>
</p>



<h3>Value</h3>

<p>A list with the following attributes:
</p>
<table role = "presentation">
<tr><td><code>Pmc</code></td>
<td>
<p>The prior
model probability for the calibrated model <code class="reqn">M_c</code>.</p>
</td></tr>
<tr><td><code>BIC_Mc</code></td>
<td>
<p>The Bayesian Information Criteria (BIC) for the
calibrated model <code class="reqn">M_c</code>.</p>
</td></tr>
<tr><td><code>BIC_Mu</code></td>
<td>
<p>The Bayesian Information Criteria
(BIC) for the uncalibrated model <code class="reqn">M_u</code>.</p>
</td></tr>
<tr><td><code>BF</code></td>
<td>
<p>The Bayes Factor of uncalibrated model over calibrated
model.</p>
</td></tr>
<tr><td><code>posterior_model_prob</code></td>
<td>
<p>The posterior model probability of the
calibrated model <code class="reqn">M_c</code> given the observed outcomes <code>y</code>, i.e. <code class="reqn">P(M_c|y)</code>.</p>
</td></tr>
<tr><td><code>MLEs</code></td>
<td>
<p>Maximum likelihood estimates for <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>.</p>
</td></tr>
<tr><td><code>optim_details</code></td>
<td>
<p>If <code>optim_details = TRUE</code>, the list returned by
<a href="stats.html#topic+optim">optim</a> when minimizing the negative log likelihood, includes convergence
information, number of iterations, and achieved negative log likelihood
value and MLEs.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Guthrie, A. P., and Franck, C. T. (2024) Boldness-Recalibration
for Binary Event Predictions, <em>The American Statistician</em> 1-17.
</p>
<p>Kass, R. E., and Raftery, A. E. (1995) Bayes factors. <em>Journal of the
American Statistical Association</em>
</p>
<p>Kass, R. E., and Wassermann, L. (1995) A reference bayesian test for nested
hypotheses and its relationship to the schwarz criterion. <em>Journal of
the American Statistical Association</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate 100 predicted probabilities
x &lt;- runif(100)
# Simulated 100 binary event outcomes using x
y &lt;- rbinom(100, 1, x)  # By construction, x is well calibrated.

# Use bayesian model selection approach to check calibration of x given outcomes y
bayes_ms(x, y, optim_details=FALSE)

# To specify different prior model probability of calibration, use Pmc
# Prior model prob of 0.7:
bayes_ms(x, y, Pmc=0.7)
# Prior model prob of 0.2
bayes_ms(x, y, Pmc=0.2)

# Use optim_details = TRUE to see returned info from call to optim(),
# details useful for checking convergence
bayes_ms(x, y, optim_details=TRUE)  # no convergence problems in this example

# Pass additional arguments to optim() via ... (see optim() for details)
# Specify different start values via par in optim() call, start at delta = 5, gamma = 5:
bayes_ms(x, y, optim_details=TRUE, par=c(5,5))
# Specify different optimization algorithm via method, L-BFGS-B instead of Nelder-Mead:
bayes_ms(x, y, optim_details=TRUE, method = "L-BFGS-B")  # same result

# What if events are defined by text instead of 0 or 1?
y2 &lt;- ifelse(y==0, "Loss", "Win")
bayes_ms(x, y2, event="Win", optim_details=FALSE)  # same result

# What if we're interested in the probability of loss instead of win?
x2 &lt;- 1 - x
bayes_ms(x2, y2, event="Loss", optim_details=FALSE)

# Push probabilities away from bounds by 0.000001
x3 &lt;- c(runif(50, 0, 0.0001), runif(50, .9999, 1))
y3 &lt;- rbinom(100, 1, 0.5)
bayes_ms(x3, y3, epsilon=0.000001)

</code></pre>

<hr>
<h2 id='brcal'>Boldness-Recalibration for Binary Events</h2><span id='topic+brcal'></span>

<h3>Description</h3>

<p>Perform Bayesian boldness-recalibration as specified in Guthrie and Franck
(2024). Boldness-recalibration maximizes the spread in predictions (<code>x</code>)
subject to a constraint on the minimum tolerable posterior probability of
calibration (<code>t</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brcal(
  x,
  y,
  t = 0.95,
  Pmc = 0.5,
  tau = FALSE,
  event = 1,
  start_at_MLEs = TRUE,
  x0 = NULL,
  lb = c(1e-05, -Inf),
  ub = c(Inf, Inf),
  maxeval = 500,
  maxtime = NULL,
  xtol_rel_inner = 1e-06,
  xtol_rel_outer = 1e-06,
  print_level = 3,
  epsilon = .Machine$double.eps,
  opts = NULL,
  optim_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="brcal_+3A_x">x</code></td>
<td>
<p>a numeric vector of predicted probabilities of an event. Must only
contain values in [0,1].</p>
</td></tr>
<tr><td><code id="brcal_+3A_y">y</code></td>
<td>
<p>a vector of outcomes corresponding to probabilities in <code>x</code>. Must
only contain two unique values (one for &quot;events&quot; and one for &quot;non-events&quot;).
By default, this function expects a vector of 0s (non-events) and 1s
(events).</p>
</td></tr>
<tr><td><code id="brcal_+3A_t">t</code></td>
<td>
<p>Minimum tolerable level of calibration in [0,1].</p>
</td></tr>
<tr><td><code id="brcal_+3A_pmc">Pmc</code></td>
<td>
<p>The prior model probability for the calibrated model <code class="reqn">M_c</code>.</p>
</td></tr>
<tr><td><code id="brcal_+3A_tau">tau</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the optimization operates on <code class="reqn">\tau =
log(\delta)</code> instead of <code class="reqn">\delta</code>. See details.</p>
</td></tr>
<tr><td><code id="brcal_+3A_event">event</code></td>
<td>
<p>Value in <code>y</code> that represents an &quot;event&quot;.  Default value is 1.</p>
</td></tr>
<tr><td><code id="brcal_+3A_start_at_mles">start_at_MLEs</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the optimizer will start at
<code class="reqn">x_0</code> = the maximum likelihood estimates for <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>. Otherwise, the user must specify <code class="reqn">x_0</code>.</p>
</td></tr>
<tr><td><code id="brcal_+3A_x0">x0</code></td>
<td>
<p>Vector with starting locations for <code class="reqn">\delta</code> and <code class="reqn">\gamma</code>.
This argument is ignored when start_at_MLEs = TRUE.</p>
</td></tr>
<tr><td><code id="brcal_+3A_lb">lb</code></td>
<td>
<p>Vector with lower bounds for <code class="reqn">\delta</code> and <code class="reqn">\gamma</code>. Use
<code>-Inf</code> to indicate no lower bound.</p>
</td></tr>
<tr><td><code id="brcal_+3A_ub">ub</code></td>
<td>
<p>Vector with upper bounds for <code class="reqn">\delta</code> and <code class="reqn">\gamma</code>. Use
<code>Inf</code> to indicate no upper bound.</p>
</td></tr>
<tr><td><code id="brcal_+3A_maxeval">maxeval</code></td>
<td>
<p>Value passed to <code>nloptr()</code> to stop optimization when the
number of function evaluations exceeds <code>maxeval</code>.</p>
</td></tr>
<tr><td><code id="brcal_+3A_maxtime">maxtime</code></td>
<td>
<p>Value passed to <code>nloptr()</code> to stop optimization when
evaluation time (in seconds) exceeds <code>maxtime</code>.</p>
</td></tr>
<tr><td><code id="brcal_+3A_xtol_rel_inner">xtol_rel_inner</code></td>
<td>
<p>Value passed to <code>nloptr()</code> to stop the inner
optimization routine when the parameter estimates for <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code> change by less than <code>xtol_rel_inner</code>.</p>
</td></tr>
<tr><td><code id="brcal_+3A_xtol_rel_outer">xtol_rel_outer</code></td>
<td>
<p>Value passed to <code>nloptr()</code> to stop the outer
optimization routine when the parameter estimates for <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code> change by less than <code>xtol_rel_inner</code>.</p>
</td></tr>
<tr><td><code id="brcal_+3A_print_level">print_level</code></td>
<td>
<p>Value passed to <code>nloptr()</code> to control how much output is
printed during optimization. Default is to print the most information
allowable by <code>nloptr()</code>. Specify <code>0</code> to suppress all output.</p>
</td></tr>
<tr><td><code id="brcal_+3A_epsilon">epsilon</code></td>
<td>
<p>Amount by which probabilities are pushed away from 0 or 1
boundary for numerical stability. If a value in <code>x</code> &lt; <code>epsilon</code>, it will be
replaced with <code>epsilon</code>.  If a value in <code>x</code> &gt; <code>1-epsilon</code>, that value will
be replaced with <code>1-epsilon</code>.</p>
</td></tr>
<tr><td><code id="brcal_+3A_opts">opts</code></td>
<td>
<p>List with options to be passed to <code>nloptr</code>.</p>
</td></tr>
<tr><td><code id="brcal_+3A_optim_options">optim_options</code></td>
<td>
<p>List with options to be passed to <code>optim</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The objective function in boldness-recalibration is </p>
<p style="text-align: center;"><code class="reqn"> f(\delta, \gamma)
= -sd(\mathbf{x}')</code>
</p>
<p> and the constraint is </p>
<p style="text-align: center;"><code class="reqn">g(\delta, \gamma) =
-(P(M_c|\mathbf{y}, \mathbf{x}')-t) \leq 0.</code>
</p>
<p>  As both the objective and
constraint functions are non-linear with respect to <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>, we use <a href="nloptr.html#topic+nloptr">nloptr</a> for this optimization rather than
<a href="stats.html#topic+optim">optim</a>. Note that we use <code>x</code> to denote a vector of predicted
probabilities, <code>nloptr()</code> uses <code>x</code> to denote the parameters being optimized.
Thus, starting values for <code class="reqn">\delta</code> and <code class="reqn">\gamma</code> are passed via
argument <code>x0</code> and all output refers to the objective and constraint as <code>f(x)</code>
and <code>g(x)</code>.
</p>
<p>By default, this function uses the Augmented Lagrangian Algorithm (AUGLAG)
(Conn et. al. 1991, Birgin and Martinez 2008) as the outer optimization
routine and Sequential Least-Squares Quadratic Programming (SLSQP) (Dieter
1988, Dieter 1994) as the inner optimization routine.
</p>


<h3>Value</h3>

<p>A list with the following attributes:
</p>
<table role = "presentation">
<tr><td><code>nloptr</code></td>
<td>
<p>The list returned by <code>nloptr()</code> including convergence
information, number of iterations, and more.</p>
</td></tr>
<tr><td><code>Pmc</code></td>
<td>
<p>The prior model probability for the calibrated model
<code class="reqn">M_c</code> specified in function call.</p>
</td></tr>
<tr><td><code>t</code></td>
<td>
<p>Desired level of
calibration in [0,1] specified in function call.</p>
</td></tr>
<tr><td><code>BR_params</code></td>
<td>
<p>(100<code class="reqn">*</code>t)% Boldness-recalibration estimates for <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>.</p>
</td></tr>
<tr><td><code>sb</code></td>
<td>
<p>The Bayesian Information Criteria (BIC) for the
calibrated model <code class="reqn">M_c</code>.</p>
</td></tr>
<tr><td><code>probs</code></td>
<td>
<p>Vector of (100<code class="reqn">*</code>t)% boldness-recalibrated
probabilities.</p>
</td></tr>
</table>


<h3>Adjusting call to <code>nloptr()</code></h3>

<p>For more control over the optimization routine conducted by <code>nloptr()</code>, the
user may specify their own options via the <code>opts</code> argument.  Note that any
objective, constraint, or gradient functions specified by the user will be
overwritten by those specified in this package. See the documentation for
<code>nloptr()</code> and the NLopt website for full details
(<a href="https://nlopt.readthedocs.io/en/latest/">https://nlopt.readthedocs.io/en/latest/</a>).
</p>


<h3>Adjusting call to <code>optim()</code></h3>

<p>While <code>optim()</code> is not used for the non-linear constrained optimization for
finding he boldness-recalibration parameters, it is used in the constraint
function as it involves the posterior model posterior.  Because of this,
we do allow users to pass additional arguments to <code>optim</code> to be used in this
calculation.  However, rather than use the <code>...</code>,
users should pass these arguments to <code>optim_options</code> via a list.
</p>


<h3>Optimizing over <code class="reqn">\tau</code></h3>

<p>When <code>tau=TRUE</code>, the optimization routine operates relative to <code class="reqn">\tau =
log(\delta)</code> instead of <code class="reqn">\delta</code>.  Specification of start location <code>x0</code>
and bounds <code>lb</code>, <code>ub</code> should still be specified in terms of <code class="reqn">\delta</code>. The
<code>brcal</code> function will automatically convert from <code class="reqn">\delta</code> to <code class="reqn">\tau</code>.
In the returned list, <code>BR_params</code> will always report in terms of
<code class="reqn">\delta</code>. However, the results returned in <code>nloptr</code> will reflect
whichever scale <code>nloptr()</code> optimized on.
</p>


<h3>References</h3>

<p>Birgin, E. G., and Martínez, J. M. (2008) Improving ultimate
convergence of an augmented Lagrangian method, <em>Optimization Methods
and Software</em> vol. 23, no. 2, p. 177-195.
</p>
<p>Conn, A. R., Gould, N. I. M., and Toint, P. L. (1991) A globally convergent
augmented Lagrangian algorithm for optimization with general constraints
and simple bounds, <em>SIAM Journal of Numerical Analysis</em> vol. 28, no.
2, p. 545-572.
</p>
<p>Guthrie, A. P., and Franck, C. T. (2024) Boldness-Recalibration for Binary
Event Predictions, <em>The American Statistician</em> 1-17.
</p>
<p>Johnson, S. G., The NLopt nonlinear-optimization package,
<a href="https://nlopt.readthedocs.io/en/latest/">https://nlopt.readthedocs.io/en/latest/</a>.
</p>
<p>Kraft, D. (1988) A software package for sequential quadratic programming&quot;,
<em>Technical Report</em> DFVLR-FB 88-28, Institut für Dynamik der
Flugsysteme, Oberpfaffenhofen.
</p>
<p>Kraft, D. (1994) Algorithm 733: TOMP-Fortran modules for optimal control
calculations, <em>ACM Transactions on Mathematical Software</em>, vol. 20,
no. 3, pp. 262-281.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate 50 predicted probabilities
x &lt;- runif(50)
# Simulated 50 binary event outcomes using x
y &lt;- rbinom(50, 1, x)  # By construction, x is well calibrated.

# Perform 90% boldness-recalibration by setting t=0.9
# To suppress all output from nloptr() for each iteration use print_level=0
# (For reduced output at each iteration used print_level=1 or 2)
# To specify different starting values, use x0 and set start_at_MLEs=FALSE
brcal(x, y, t=0.9, x0=c(1,1), start_at_MLEs=FALSE, print_level=0)

# Adjust stopping criteria set max number of evaluations to 50 (maxeval) OR 
# stop after 0.5 second (maxtime)
# and set optimization bounds using lb and ub
brcal(x, y, maxeval = 50, maxtime = 0.5, lb=c(0.001, 0), ub=c(10, 10), print_level=0)

# Specify different options for nloptr &amp; optim
brcal(x, y, opts=list(xtol_abs=0.01,
                     local_opts=list(algorithm="NLOPT_LD_MMA")), 
                     optim_options=list(method = "L-BFGS-B", lower = c(0, -1), 
                              upper = c(10, 25), control=list(factr=0.01)),
                              print_level=0)
                              
# Push probabilities away from bounds by 0.000001 and
# Stop outer optimization when parameters change by less than .001
x3 &lt;- c(runif(25, 0, 0.0001), runif(25, .9999, 1))
y3 &lt;- rbinom(50, 1, 0.5)
brcal(x3, y3, epsilon=0.000001, xtol_rel_outer = .01, print_level=0)

# See vignette for more examples

</code></pre>

<hr>
<h2 id='foreclosure'>Foreclosure Monitoring Predictions data</h2><span id='topic+foreclosure'></span>

<h3>Description</h3>

<p>Foreclosure monitoring probability predictions and the true foreclosure
status pertaining of 5,000 housing transactions in 2010
from Wayne County, Michigan. These data were a randomly selected subset from
data from presented in Keefe et al. (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>foreclosure
</code></pre>


<h3>Format</h3>



<h4><code>foreclosure</code></h4>

<p>A data frame with 5,000 rows and 3 columns:
</p>

<dl>
<dt>y</dt><dd><p>sale type, 1 = foreclosure, 0 = regular sale</p>
</dd>
<dt>x</dt><dd><p>predicted probabilities of foreclosure</p>
</dd>
<dt>year</dt><dd><p>year of observed foreclosure or regular sale</p>
</dd>
</dl>




<h3>Source</h3>

<p>Keefe, M.J., Franck, C.T., Woodall, W.H. (2017): Monitoring foreclosure
rates with a spatially risk-adjusted bernoulli cusum chart for concurrent
observations. <em>Journal of Applied Statistics</em> 44(2), 325–341
<a href="https://doi.org/10.1080/02664763.2016.1169257">doi:10.1080/02664763.2016.1169257</a>
</p>

<hr>
<h2 id='hockey'>Hockey Home Team Win Predictions data</h2><span id='topic+hockey'></span>

<h3>Description</h3>

<p>Home team win probability predictions and outcomes pertaining to the 2020-21
National Hockey League (NHL) Season. Probability predictions x were obtained
from FiveThirtyEight via downloadable spreadsheet on their website (see below
for link).  The win/loss game results were obtained by web-scraping from
NHL.com using the NHL API.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hockey
</code></pre>


<h3>Format</h3>



<h4><code>hockey</code></h4>

<p>A data frame with 868 rows and 4 columns:
</p>

<dl>
<dt>y</dt><dd><p>game result, 1 = home team win, 0 = home team loss</p>
</dd>
<dt>x</dt><dd><p>predicted probabilities of a home team win from FiveThirtyEight</p>
</dd>
<dt>rand</dt><dd><p>uniformly random generated predicted probability of a home team from range [0.26, 0.78] </p>
</dd>
<dt>winner</dt><dd><p>game result (string), &quot;home&quot; = home team win, &quot;away&quot; = home team loss</p>
</dd>
</dl>




<h3>Source</h3>

<p><a href="https://data.fivethirtyeight.com/">https://data.fivethirtyeight.com/</a>
</p>

<hr>
<h2 id='lineplot'>Lineplot for LLO-adjusted Probability Predictions</h2><span id='topic+lineplot'></span>

<h3>Description</h3>

<p>Function to visualize how predicted probabilities change under
MLE-recalibration and boldness-recalibration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lineplot(
  x = NULL,
  y = NULL,
  t_levels = NULL,
  plot_original = TRUE,
  plot_MLE = TRUE,
  df = NULL,
  Pmc = 0.5,
  event = 1,
  return_df = FALSE,
  epsilon = .Machine$double.eps,
  title = "Line Plot",
  ylab = "Probability",
  xlab = "Posterior Model Probability",
  ylim = c(0, 1),
  breaks = seq(0, 1, by = 0.2),
  thin_to = NULL,
  thin_prop = NULL,
  thin_by = NULL,
  thin_percent = deprecated(),
  seed = 0,
  optim_options = NULL,
  nloptr_options = NULL,
  ggpoint_options = list(alpha = 0.35, size = 1.5, show.legend = FALSE),
  ggline_options = list(alpha = 0.25, linewidth = 0.5, show.legend = FALSE)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lineplot_+3A_x">x</code></td>
<td>
<p>a numeric vector of predicted probabilities of an event. Must only
contain values in [0,1].</p>
</td></tr>
<tr><td><code id="lineplot_+3A_y">y</code></td>
<td>
<p>a vector of outcomes corresponding to probabilities in <code>x</code>. Must
only contain two unique values (one for &quot;events&quot; and one for &quot;non-events&quot;).
By default, this function expects a vector of 0s (non-events) and 1s
(events).</p>
</td></tr>
<tr><td><code id="lineplot_+3A_t_levels">t_levels</code></td>
<td>
<p>Vector of desired level(s) of calibration at which to plot
contours.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_plot_original">plot_original</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the original probabilities passed
in <code>x</code> are plotted.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_plot_mle">plot_MLE</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the MLE-recalibrated probabilities are
plotted.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_df">df</code></td>
<td>
<p>Dataframe returned by previous call to lineplot() specially
formatted for use in this function. Only used for faster plotting when
making minor cosmetic changes to a previous call.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_pmc">Pmc</code></td>
<td>
<p>The prior model probability for the calibrated model <code class="reqn">M_c</code>.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_event">event</code></td>
<td>
<p>Value in <code>y</code> that represents an &quot;event&quot;.  Default value is 1.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_return_df">return_df</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the dataframe used to build this plot
will be returned.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_epsilon">epsilon</code></td>
<td>
<p>Amount by which probabilities are pushed away from 0 or 1
boundary for numerical stability. If a value in <code>x</code> &lt; <code>epsilon</code>, it will be
replaced with <code>epsilon</code>.  If a value in <code>x</code> &gt; <code>1-epsilon</code>, that value will
be replaced with <code>1-epsilon</code>.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_title">title</code></td>
<td>
<p>Plot title.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_ylab">ylab</code></td>
<td>
<p>Label for x-axis.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_xlab">xlab</code></td>
<td>
<p>Label for x-axis.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_ylim">ylim</code></td>
<td>
<p>Vector with bounds for y-axis, must be in [0,1].</p>
</td></tr>
<tr><td><code id="lineplot_+3A_breaks">breaks</code></td>
<td>
<p>Locations along y-axis at which to draw horizontal guidelines,
passed to <code>scale_y_continous()</code>.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_thin_to">thin_to</code></td>
<td>
<p>When non-null, the observations in (x,y) are randomly sampled
without replacement to form a set of size <code>thin_to</code>.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_thin_prop">thin_prop</code></td>
<td>
<p>When non-null, the observations in (x,y) are randomly
sampled without replacement to form a set that is <code>thin_prop</code> * 100% of
the original size of (x,y).</p>
</td></tr>
<tr><td><code id="lineplot_+3A_thin_by">thin_by</code></td>
<td>
<p>When non-null, the observations in (x,y) are thinned by
selecting every <code>thin_by</code> observation.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_thin_percent">thin_percent</code></td>
<td>
<p>This argument is deprecated, use <code>thin_prop</code> instead.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_seed">seed</code></td>
<td>
<p>Seed for random thinning.  Set to NULL for no seed.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_optim_options">optim_options</code></td>
<td>
<p>List of additional arguments to be passed to <a href="stats.html#topic+optim">optim</a>().</p>
</td></tr>
<tr><td><code id="lineplot_+3A_nloptr_options">nloptr_options</code></td>
<td>
<p>List with options to be passed to <code>nloptr()</code>.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_ggpoint_options">ggpoint_options</code></td>
<td>
<p>List with options to be passed to <code>geom_point()</code>.</p>
</td></tr>
<tr><td><code id="lineplot_+3A_ggline_options">ggline_options</code></td>
<td>
<p>List with options to be passed to <code>geom_line()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function leverages <code>ggplot()</code> and related functions from the <code>ggplot2</code>
package (REF).
</p>
<p>The goal of this function is to visualize how predicted probabilities change
under different recalibration parameters. By default this function only shows
how the original probabilities change after MLE recalibration.  Argument
<code>t_levels</code> can be used to specify a vector of levels of
boldness-recalibration to visualize in addition to MLE recalibration.
</p>
<p>While the x-axis shows the posterior model probabilities of each set of
probabilities, note the posterior model probabilities are not in ascending or
descending order.  Instead, they simply follow the ordering of how one might
use the <code>BRcal</code> package: first looking at the original predictions, then
maximizing calibration, then examining how far they can spread out
predictions while maintaining calibration with boldness-recalibration.
</p>


<h3>Value</h3>

<p>If <code>return_df = TRUE</code>, a list with the following attributes is
returned: </p>
<table role = "presentation">
<tr><td><code>plot</code></td>
<td>
<p>A <code>ggplot</code> object showing how the predicted
probabilities under MLE recalibration and specified levels of
boldness-recalibration.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Dataframe used to create <code>plot</code>, specially
formatted for use in <code>lineplot()</code>.</p>
</td></tr>
</table>
<p>Otherwise just the <code>ggplot</code> object of the plot is returned.
</p>


<h3>Reusing underlying dataframe via <code>return_df</code></h3>

<p>While this function does not typically come with a large burden on time
under moderate sample sizes, there is still a call to <code>optim()</code> under the
hood for MLE recalibration and a call to <code>nloptr()</code> for each level of
boldness-recalibration that could cause a bottleneck on time.  With this in
mind, users can specify <code>return_df=TRUE</code> to return the underlying dataframe
used to build the resulting lineplot.  Then, users can pass this dataframe
to <code>df</code> in subsequent calls of <code>lineplot</code> to circumvent these calls to
<code>optim</code> and <code>nloptr</code> and make cosmetic changes to the plot.
</p>
<p>When <code>return_df=TRUE</code>, both the plot and the dataframe are returned in a
list. The dataframe contains 6 columns:
</p>

<ul>
<li> <p><code>probs</code>: the values of each predicted probability under each set
</p>
</li>
<li> <p><code>outcome</code>: the corresponding outcome for each predicted probability
</p>
</li>
<li> <p><code>post</code>: the posterior model probability of the set as a whole
</p>
</li>
<li> <p><code>id</code>: the id of each individual probability used for mapping observations between sets
</p>
</li>
<li> <p><code>set</code>: the set with which the probability belongs to
</p>
</li>
<li> <p><code>label</code>: the label used for the x-axis in the lineplot
</p>
</li></ul>

<p>Essentially, each set of probabilities (original, MLE-, and each level of
boldness-recalibration) and outcomes are &quot;stacked&quot; on top of each other.
The <code>id</code> tells the plotting function how to connect (with line) the same
observation as is changes from the original set to MLE- or
boldness-recalibration.
</p>


<h3>Thinning</h3>

<p>Another strategy to save time when plotting is to thin the amount of data
plotted.  When sample sizes are large, the plot can become overcrowded and
slow to plot.  We provide three options for thinning: <code>thin_to</code>,
<code>thin_prop</code>, and <code>thin_by</code>.  By default, all three of these settings are
set to <code>NULL</code>, meaning no thinning is performed.  Users can only specify
one thinning strategy at a time. Care should be taken in selecting a
thinning approach based on the nature of your data and problem.  Note that
MLE recalibration and boldness-recalibration will be done using the full
set.
</p>
<p>Also note that if a thinning strategy is used with <code>return_df=TRUE</code>, the
returned data frame will <strong>only contain the reduced set</strong> (i.e. the data
<em>after</em> thinning).
</p>


<h3>Passing additional arguments to <code>geom_point()</code> and <code>geom_line()</code></h3>

<p>To make cosmetic changes to the points and lines plotted, users can pass a
list of any desired arguments of <code>geom_point()</code> and <code>geom_line()</code> to
<code>ggpoint_options</code> and <code>ggline_options</code>, respectively.  These will overwrite
everything passed to <code>geom_point()</code> or <code>geom_line()</code> except any aesthetic
arguments in <code>aes()</code>.
</p>


<h3>References</h3>

<p>Guthrie, A. P., and Franck, C. T. (2024) Boldness-Recalibration
for Binary Event Predictions, <em>The American Statistician</em> 1-17.
</p>
<p>Wickham, H. (2016) ggplot2: Elegant Graphics for Data Analysis.
Springer-Verlag New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(28)
# Simulate 100 predicted probabilities
x &lt;- runif(100)
# Simulated 100 binary event outcomes using x
y &lt;- rbinom(100, 1, x)  # By construction, x is well calibrated.

# Lineplot show change in probabilities from original to MLE-recalibration to 
# specified Levels of Boldness-Recalibration via t_levels
# Return a list with dataframe used to construct plot with return_df=TRUE
lp1 &lt;- lineplot(x, y, t_levels=c(0.98, 0.95), return_df=TRUE)
lp1$plot

# Reusing the previous dataframe to save calculation time
lineplot(df=lp1$df)

# Adjust geom_point cosmetics via ggpoint
# Increase point size and change to open circles
lineplot(df=lp1$df, ggpoint_options=list(size=3, shape=4))

# Adjust geom_line cosmetics via ggline
# Increase line size and change transparencys
lineplot(df=lp1$df, ggline_options=list(linewidth=2, alpha=0.1))

# Thinning down to 75 randomly selected observation
lineplot(df=lp1$df, thin_to=75)

# Thinning down to 53% of the data
lineplot(df=lp1$df, thin_prop=0.53)

# Thinning down to every 3rd observation
lineplot(df=lp1$df, thin_by=3)

# Setting a different seed for thinning
lineplot(df=lp1$df, thin_prop=0.53, seed=47)

# Setting NO seed for thinning (plot will be different every time)
lineplot(df=lp1$df, thin_to=75, seed=NULL)

</code></pre>

<hr>
<h2 id='LLO'>Linear Log Odds (LLO) Recalibration Function</h2><span id='topic+LLO'></span>

<h3>Description</h3>

<p>LLO-adjust predicted probabilities based on specified <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LLO(x, delta, gamma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LLO_+3A_x">x</code></td>
<td>
<p>a numeric vector of predicted probabilities of an event. Must only
contain values in [0,1].</p>
</td></tr>
<tr><td><code id="LLO_+3A_delta">delta</code></td>
<td>
<p>numeric, must be &gt; 0, parameter <code class="reqn">\delta</code> in LLO
recalibration function.</p>
</td></tr>
<tr><td><code id="LLO_+3A_gamma">gamma</code></td>
<td>
<p>numeric, parameter <code class="reqn">\gamma</code> in LLO recalibration function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Linear Log Odds (LLO) recalibration function can be written as
</p>
<p style="text-align: center;"><code class="reqn">c(x_i;\delta, \gamma) = \frac{\delta x_i^\gamma}{\delta x_i^\gamma +
(1-x_i)^\gamma}</code>
</p>
<p> where <code class="reqn">x_i</code> is a predicted probability,
<code class="reqn">\delta &gt; 0</code> and <code class="reqn">\gamma \in \mathbb{R}</code>.  Then <code class="reqn">c(x_i;\delta,
\gamma)</code> is the corresponding LLO-adjusted probability that has been shifted
by <code class="reqn">\delta</code> and scaled by <code class="reqn">\gamma</code> on the log odds scale.  When
<code class="reqn">\delta = \gamma = 1</code>, there is no shifting or scaling imposed on <code>x</code>.
</p>


<h3>Value</h3>

<p>Vector of LLO-adjusted probabilities via specified <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>.
</p>


<h3>References</h3>

<p>Turner, B., Steyvers, M., Merkle, E., Budescu, D., and Wallsten,
T. (2014) Forecast aggregation via recalibration, <em>Machine Learning</em>
95, 261–289.
</p>
<p>Gonzalez, R., and Wu, G. (1999), On the shape of probability weighting
function, <em>Cognitive Psychology</em> 38, 129–66.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Vector of probability predictions from 0 to 1
x1 &lt;- seq(0, 1, by=0.1)
x1

# LLO-adjusted predictions via delta = 2, gamma = 3
x1_llo23 &lt;- LLO(x1, 2, 3)
x1_llo23  

# LLO-adjusted predictions via delta = 1, gamma = 1
x1_llo11 &lt;- LLO(x1, 1, 1)
x1_llo11  # no change

# Create vector of 100 probability predictions
x2 &lt;- runif(100)

# LLO-adjust via delta = 2, gamma = 3
x2_llo23 &lt;- LLO(x2, 2, 3)

plot(x2, x2_llo23)
</code></pre>

<hr>
<h2 id='llo_lrt'>Likelihood Ratio Test for Calibration</h2><span id='topic+llo_lrt'></span>

<h3>Description</h3>

<p>Perform a likelihood ratio test for if calibration a set of probability
predictions, <code>x</code>, are well-calibrated given a corresponding set of binary
event outcomes, <code>y</code>. See Guthrie and Franck (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llo_lrt(
  x,
  y,
  event = 1,
  optim_details = TRUE,
  epsilon = .Machine$double.eps,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="llo_lrt_+3A_x">x</code></td>
<td>
<p>a numeric vector of predicted probabilities of an event. Must only
contain values in [0,1].</p>
</td></tr>
<tr><td><code id="llo_lrt_+3A_y">y</code></td>
<td>
<p>a vector of outcomes corresponding to probabilities in <code>x</code>. Must
only contain two unique values (one for &quot;events&quot; and one for &quot;non-events&quot;).
By default, this function expects a vector of 0s (non-events) and 1s
(events).</p>
</td></tr>
<tr><td><code id="llo_lrt_+3A_event">event</code></td>
<td>
<p>Value in <code>y</code> that represents an &quot;event&quot;.  Default value is 1.</p>
</td></tr>
<tr><td><code id="llo_lrt_+3A_optim_details">optim_details</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the list returned by <a href="stats.html#topic+optim">optim</a> when
minimizing the negative log likelihood is also returned by this function.</p>
</td></tr>
<tr><td><code id="llo_lrt_+3A_epsilon">epsilon</code></td>
<td>
<p>Amount by which probabilities are pushed away from 0 or 1
boundary for numerical stability. If a value in <code>x</code> &lt; <code>epsilon</code>, it will be
replaced with <code>epsilon</code>.  If a value in <code>x</code> &gt; <code>1-epsilon</code>, that value will
be replaced with <code>1-epsilon</code>.</p>
</td></tr>
<tr><td><code id="llo_lrt_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <a href="stats.html#topic+optim">optim</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This likelihood ratio test is based on the following likelihood
</p>
<p style="text-align: center;"><code class="reqn">\pi(\mathbf{x}, \mathbf{y} | \delta, \gamma) = \prod_{i=1}^n
c(x_i;\delta, \gamma)^{y_i} \left[1-c(x_i;\delta, \gamma)\right]^{1-y_i}</code>
</p>

<p>where <code class="reqn">c(x_i; \delta, \gamma)</code> is the Linear in Log Odds
(<a href="#topic+LLO">LLO</a>) function, <code class="reqn">\delta&gt;0</code> is the shift parameter on the
logs odds scale, and <code class="reqn">\gamma \in \mathbb{R}</code> is the scale parameter on
the log odds scale.
</p>
<p>As <code class="reqn">\delta = \gamma = 1</code> corresponds to no shift or scaling of
probabilities, i.e. <code>x</code> is well calibrated given corresponding outcomes <code>y</code>.
Thus the hypotheses for this test are as follows: </p>
<p style="text-align: center;"><code class="reqn">H_0: \delta = 1,
\gamma = 1 \text{  (Probabilities are well calibrated)}</code>
</p>
 <p style="text-align: center;"><code class="reqn">H_1: \delta
\neq 1 \text{ and/or } \gamma \neq 1 \text{  (Probabilities are poorly
calibrated)}.</code>
</p>

<p>The likelihood ratio test statistics for <code class="reqn">H_0</code> is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_{LR} = -2 log\left[\frac{\pi(\delta =1, \gamma=1|\mathbf{x},
\mathbf{y})}{\pi(\delta = \hat\delta_{MLE}, \gamma = \hat\gamma_{MLE}|
\mathbf{x},\mathbf{y})}\right]</code>
</p>
<p> where <code class="reqn">\lambda_{LR}\stackrel{H_0}{\sim}{\chi^2_2}</code>
asymptotically under the null hypothesis <code class="reqn">H_0</code>, and
<code class="reqn">\hat{\delta}_{MLE}</code> and <code class="reqn">\hat{\gamma}_{MLE}</code> are the maximum
likelihood estimates for <code class="reqn">\delta</code> and <code class="reqn">\gamma</code>.
</p>


<h3>Value</h3>

<p>A list with the following attributes: </p>
<table role = "presentation">
<tr><td><code>test_stat</code></td>
<td>
<p>The
test statistic <code class="reqn">\lambda_{LR}</code> from the likelihood ratio test.</p>
</td></tr>
<tr><td><code>pval</code></td>
<td>
<p>The p-value from the likelihood ratio test.</p>
</td></tr>
<tr><td><code>MLEs</code></td>
<td>
<p>Maximum likelihood estimates for <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>.</p>
</td></tr>
<tr><td><code>optim_details</code></td>
<td>
<p>If <code>optim_details = TRUE</code>, the list returned by
<a href="stats.html#topic+optim">optim</a> when minimizing the negative log likelihood, includes convergence
information, number of iterations, and achieved negative log likelihood
value and MLEs.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Guthrie, A. P., and Franck, C. T. (2024) Boldness-Recalibration
for Binary Event Predictions, <em>The American Statistician</em> 1-17.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate 100 predicted probabilities
x &lt;- runif(100)
# Simulated 100 binary event outcomes using `x`
y &lt;- rbinom(100, 1, x)  # By construction, `x` is well calibrated.

# Run the likelihood ratio test on `x` and `y`
llo_lrt(x, y, optim_details=FALSE)

# Use optim_details = TRUE to see returned info from call to optim(),
# details useful for checking convergence
llo_lrt(x, y, optim_details=TRUE)  # no convergence problems in this example

# Use different start value in `optim()` call, start at delta = 5, gamma = 5
llo_lrt(x, y, optim_details=TRUE, par=c(5,5))

# Use `L-BFGS-B` instead of `Nelder-Mead`
llo_lrt(x, y, optim_details=TRUE, method = "L-BFGS-B")  # same result

# What if events are defined by text instead of 0 or 1?
y2 &lt;- ifelse(y==0, "Loss", "Win")
llo_lrt(x, y2, event="Win", optim_details=FALSE)  # same result

# What if we're interested in the probability of loss instead of win?
x2 &lt;- 1 - x
llo_lrt(x2, y2, event="Loss", optim_details=FALSE)

# Push probabilities away from bounds by 0.000001
x3 &lt;- c(runif(50, 0, 0.0001), runif(50, .9999, 1))
y3 &lt;- rbinom(100, 1, 0.5)
llo_lrt(x3, y3, epsilon=0.000001)

</code></pre>

<hr>
<h2 id='mle_recal'>Recalibration via Maximum Likelihood Estimates (MLEs)</h2><span id='topic+mle_recal'></span>

<h3>Description</h3>

<p>MLE recalibrate (i.e. LLO-adjust via <code class="reqn">\hat{\delta}_{MLE}</code> and
<code class="reqn">\hat{\gamma}_{MLE}</code> as specified in Guthrie and Franck (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mle_recal(x, y, probs_only = FALSE, event = 1, optim_details = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mle_recal_+3A_x">x</code></td>
<td>
<p>a numeric vector of predicted probabilities of an event. Must only
contain values in [0,1].</p>
</td></tr>
<tr><td><code id="mle_recal_+3A_y">y</code></td>
<td>
<p>a vector of outcomes corresponding to probabilities in <code>x</code>. Must
only contain two unique values (one for &quot;events&quot; and one for &quot;non-events&quot;).
By default, this function expects a vector of 0s (non-events) and 1s
(events).</p>
</td></tr>
<tr><td><code id="mle_recal_+3A_probs_only">probs_only</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, <code>mle_recal()</code> returns only the vector
of MLE recalibrated probabilities.</p>
</td></tr>
<tr><td><code id="mle_recal_+3A_event">event</code></td>
<td>
<p>Value in <code>y</code> that represents an &quot;event&quot;.  Default value is 1.</p>
</td></tr>
<tr><td><code id="mle_recal_+3A_optim_details">optim_details</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the list returned by <a href="stats.html#topic+optim">optim</a> when
minimizing the negative log likelihood is also returned by this function.</p>
</td></tr>
<tr><td><code id="mle_recal_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <a href="stats.html#topic+optim">optim</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a set of probability predictions <code>x</code>, the corresponding MLE
recalibrated set is <code class="reqn">c(x; \hat{\delta}_{MLE}, \hat{\gamma}_{MLE})</code> (see
<a href="#topic+LLO">LLO</a>).
</p>


<h3>Value</h3>

<p>If <code>probs_only=TRUE</code>, <code>mle_recal()</code>returns a vector of MLE
recalibrated probabilities.  Otherwise, <code>mle_recal()</code> returns a list with
the following attributes:
</p>
<table role = "presentation">
<tr><td><code>probs</code></td>
<td>
<p>The vector of MLE
recalibrated probabilities.</p>
</td></tr>
<tr><td><code>MLEs</code></td>
<td>
<p>Maximum likelihood estimates for <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>.</p>
</td></tr>
<tr><td><code>optim_details</code></td>
<td>
<p>If <code>optim_details = TRUE</code>, the list returned by
<a href="stats.html#topic+optim">optim</a> when minimizing the negative log likelihood, includes convergence
information, number of iterations, and achieved negative log likelihood
value and MLEs.  This arguement is ignored when <code>probs_only=TRUE</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Guthrie, A. P., and Franck, C. T. (2024) Boldness-Recalibration
for Binary Event Predictions, <em>The American Statistician</em> 1-17.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate 100 predicted probabilities
x &lt;- runif(100)
# Simulated 100 binary event outcomes using `x` 
y &lt;- rbinom(100, 1, x)

# MLE recalibrate `x`
mle_recal(x, y, optim_details=FALSE)  

# Just return the vector of MLE recalibrated probabilities
x_mle &lt;- mle_recal(x, y, optim_details=FALSE, probs_only=TRUE)
x_mle

plot(x, x_mle)

# Use optim_details = TRUE to see returned info from call to optim(),
# details useful for checking convergence
mle_recal(x, y, optim_details=TRUE)  # no convergence problems in this example

# Use different start value in `optim()` call, start at delta = 5, gamma = 5
mle_recal(x, y, optim_details=TRUE, par=c(5,5))

# Use `L-BFGS-B` instead of `Nelder-Mead` 
mle_recal(x, y, optim_details=TRUE, method = "L-BFGS-B")  # same result

# What if events are defined by text instead of 0 or 1? 
y2 &lt;- ifelse(y==0, "Loss", "Win")
mle_recal(x, y2, event="Win", optim_details=FALSE)  # same result

# What if we're interested in the probability of loss instead of win?
x2 &lt;- 1 - x
mle_recal(x2, y2, event="Loss", optim_details=FALSE)

</code></pre>

<hr>
<h2 id='plot_params'>Draw image plot of posterior model probability surface.</h2><span id='topic+plot_params'></span>

<h3>Description</h3>

<p>Function to visualize the posterior model probability of the given set of
probabilities, <code>x</code>, after LLO-adjustment via a grid of uniformly spaced set
of <code class="reqn">\delta</code> and <code class="reqn">\gamma</code> values with optional contours.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_params(
  x = NULL,
  y = NULL,
  z = NULL,
  t_levels = NULL,
  Pmc = 0.5,
  event = 1,
  k = 100,
  dlim = c(1e-04, 5),
  glim = c(1e-04, 5),
  zlim = c(0, 1),
  return_z = FALSE,
  epsilon = .Machine$double.eps,
  contours_only = FALSE,
  main = "Posterior Model Probability of Calibration",
  xlab = "delta",
  ylab = "gamma",
  optim_options = NULL,
  imgplt_options = list(legend.lab = ""),
  contour_options = list(drawlabels = TRUE, labcex = 0.6, lwd = 1, col =
    ifelse(contours_only, "black", "white"))
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_params_+3A_x">x</code></td>
<td>
<p>a numeric vector of predicted probabilities of an event. Must only
contain values in [0,1].</p>
</td></tr>
<tr><td><code id="plot_params_+3A_y">y</code></td>
<td>
<p>a vector of outcomes corresponding to probabilities in <code>x</code>. Must
only contain two unique values (one for &quot;events&quot; and one for &quot;non-events&quot;).
By default, this function expects a vector of 0s (non-events) and 1s
(events).</p>
</td></tr>
<tr><td><code id="plot_params_+3A_z">z</code></td>
<td>
<p>Matrix returned by previous call to <code>plot_params()</code> containing
posterior model probabilities across k<code class="reqn">\times</code>k grid of <code class="reqn">\delta</code>
and <code class="reqn">\gamma</code>. Assumes <code>z</code> was constructed using the same <code>k</code>, <code>dlim</code>,
and <code>glim</code> as the current function call.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_t_levels">t_levels</code></td>
<td>
<p>Vector of desired level(s) of calibration at which to plot
contours.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_pmc">Pmc</code></td>
<td>
<p>The prior model probability for the calibrated model <code class="reqn">M_c</code>.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_event">event</code></td>
<td>
<p>Value in <code>y</code> that represents an &quot;event&quot;.  Default value is 1.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_k">k</code></td>
<td>
<p>The number of uniformly spaced <code class="reqn">\delta</code> and <code class="reqn">\gamma</code> values
used to construct the k<code class="reqn">\times</code>k grid.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_dlim">dlim</code></td>
<td>
<p>Vector with bounds for <code class="reqn">\delta</code>, must be finite.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_glim">glim</code></td>
<td>
<p>Vector with bounds for <code class="reqn">\gamma</code>, must be finite.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_zlim">zlim</code></td>
<td>
<p>Vector with bounds for posterior probability of calibration, must
be in [0,1].</p>
</td></tr>
<tr><td><code id="plot_params_+3A_return_z">return_z</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, the matrix of posterior model
probabilities across the specified k<code class="reqn">\times</code>k grid of <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code> will be returned.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_epsilon">epsilon</code></td>
<td>
<p>Amount by which probabilities are pushed away from 0 or 1
boundary for numerical stability. If a value in <code>x</code> &lt; <code>epsilon</code>, it will be
replaced with <code>epsilon</code>.  If a value in <code>x</code> &gt; <code>1-epsilon</code>, that value will
be replaced with <code>1-epsilon</code>.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_contours_only">contours_only</code></td>
<td>
<p>Logical.  If <code>TRUE</code>, only the contours at the specified
<code>t_levels</code> will be plotted with no color for the posterior model
probability across the k<code class="reqn">\times</code>k grid of <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code>.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_main">main</code></td>
<td>
<p>Plot title.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_xlab">xlab</code></td>
<td>
<p>Label for x-axis.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_ylab">ylab</code></td>
<td>
<p>Label for x-axis.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_optim_options">optim_options</code></td>
<td>
<p>List of additional arguments to be passed to <a href="stats.html#topic+optim">optim</a>().</p>
</td></tr>
<tr><td><code id="plot_params_+3A_imgplt_options">imgplt_options</code></td>
<td>
<p>List of additional arguments to be passed to <a href="fields.html#topic+image.plot">image.plot</a>().</p>
</td></tr>
<tr><td><code id="plot_params_+3A_contour_options">contour_options</code></td>
<td>
<p>List of additional arguments to be passed to <a href="graphics.html#topic+contour">contour</a>().</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function leverages the <a href="fields.html#topic+image.plot">image.plot</a> function from the
<a href="fields.html#topic+fields">fields</a> package and the <a href="graphics.html#topic+contour">contour</a> function from
the <a href="graphics.html#topic+graphics">graphics</a> package.
</p>
<p>The goal of this function is to visualize how the posterior model probability
changes under different recalibration parameters, as this is used in
boldness-recalibration.  To do so, a <code>k</code> by <code>k</code> grid of uniformly spaced
potential values for <code class="reqn">\delta</code> and <code class="reqn">\gamma</code> are constructed.  Then <code>x</code>
is LLO-adjusted under each pair of <code class="reqn">\delta</code> and <code class="reqn">\gamma</code> values. The
posterior model probability of each LLO-adjusted set is calculated and this
is the quantity we use to color each grid cell in the image plot to visualize
change in calibration.  See below for more details on setting the grid.
</p>
<p>By default, only the posterior model probability surface is plotted. Argument
<code>t_levels</code> can be used to optionally add contours at specified levels of the
posterior model probability of calibration.   The goal of this is to help
visualize different values of <code class="reqn">t</code> at which they may want to
boldness-recalibrate. To only draw the contours without the colored posterior
model probability surface, users can set <code>contours_only=TRUE</code>.
</p>


<h3>Value</h3>

<p>If <code>return_z = TRUE</code>, a list with the following attributes is
returned: </p>
<table role = "presentation">
<tr><td><code>z</code></td>
<td>
<p>Matrix containing posterior model probabilities
across k<code class="reqn">\times</code>k grid of uniformly spaced values of <code class="reqn">\delta</code> and <code class="reqn">\gamma</code>
in the specified ranges <code>dlim</code> and <code>glim</code>, respectively.</p>
</td></tr>
<tr><td><code>dlim</code></td>
<td>
<p>Vector with bounds for
<code class="reqn">\delta</code> used to construct z.</p>
</td></tr>
<tr><td><code>glim</code></td>
<td>
<p>Vector with bounds for <code class="reqn">\gamma</code> used to construct
z.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>The number of uniformly spaced <code class="reqn">\delta</code> and <code class="reqn">\gamma</code>
values used to construct z</p>
</td></tr>
</table>


<h3>Setting grid for <code class="reqn">\delta</code> and <code class="reqn">\gamma</code></h3>

<p>Arguments <code>dlim</code> and <code>glim</code> are used to set the bounds of the <code class="reqn">\delta</code>,
<code class="reqn">\gamma</code> grid and the size is dictated by argument <code>k</code>. Some care is
required for the selection of these arguments. The goal is to determine
what range of <code class="reqn">\delta</code> and <code class="reqn">\gamma</code> encompasses the region of
non-zero posterior probabilities of calibration.  However, it is not
feasible to check the entire parameter space (as it is unbounded) and even
at smaller regions it can be difficult to detect the region in which
non-zero posterior probabilities are produced without as very dense grid
(large <code>k</code>), as the region is often quite small relative to the entire
parameter space. This is problematic, as computation time increases as <code>k</code>
grows.
</p>
<p>We suggest the following scheme setting <code>k</code>, <code>dlim</code>, and <code>glim</code>. First, fix
<code>k</code> at some small number, less than 20 for sake of computation time. Then,
center a grid with small range around the MLEs for <code class="reqn">\delta</code> and
<code class="reqn">\gamma</code> for the given <code>x</code> and <code>y</code>. Increase the size of <code>k</code> until your
grid detects approximated the probability of calibration at the MLEs that
you expect. Then, expand your grid until it the region with high
probability of calibration is covered or contract your grid to &quot;zoom in&quot; on
the region. Then, increase <code>k</code> to create a fine grid of values.
</p>
<p>Additionally, we caution users from including <code class="reqn">\gamma = 0</code> in the grid.
This setting recalibrates all values in <code>x</code> to a single value which is not
desirable in practice.  Unless the single value is near the base rate, the
set will be poorly calibrated and minimally bold, which does not align with
the goal of boldness-recalibration.
</p>


<h3>Reusing matrix <code>z</code> via <code>return_z</code></h3>

<p>The time bottleneck for this function occurs when calculating the posterior
model probabilities across the grid of parameter values. Thus it can be
useful to save the resulting matrix of values to be re-used to save time
when making minor cosmetic changes to your plot. If these adjustments do
not change the grid bounds or density, users can set <code>return_z=TRUE</code> to
return the underlying matrix of posterior mode probabilities for plotting.
Then, instead of specifying <code>x</code> and <code>y</code> users can just pass the returned
matrix as <code>z</code>.  Note this assumes you are NOT making any changes to <code>k</code>,
<code>dlim</code>, or <code>glim</code>.  Also, it is not recommended that you construct your
own matrix to pass via <code>z</code> as this function relies on the structure as
returned by a previous call of <code>plot_params()</code>.
</p>


<h3>Thinning</h3>

<p>Another approach to speed up the calculations of this function is to thin
the data used. However, this is generally not recommended unless the sample
size is very large as the calculations of the posterior model probability
may change drastically under small sample sizes.  This can lead to
misleading results. Under large sample sizes where thinning is used, note
this is only an approximate visual of the posterior model probability.
</p>


<h3>Grid cells that show up white / inaccuracies warning message</h3>

<p>In some cases, grid cells in the plot may show up as white instead of one
of the colors from red to blue shown on the legend.  A white grid cell
indicates that there is no calculated posterior model probability at that
cell. There are two common reasons for this: (1) that grid cell location is
not covered by the <code>z</code> matrix used (i.e. you've adjusted the bounds without
recalculating z) or (2) the values of the parameters at these locations
cause the values in <code>x</code> to be LLO-adjusted such that they virtually equal 0
or 1.  This invokes the use of <code>epsilon</code> to push them away from these
boundaries for stability.   This typically happens when |gamma| is very large.
However, in these extreme cases this can cause inaccuracies in this plot.
For this reason, we either throw the warning message: &quot;Probs too close to 0
or 1 under very large |gamma|&quot; and allow the cell to be plotted as white
to notify the user and avoid plotting artifacts.
</p>
<p>Additionally, when gamma is very close to 0, we cannot directly calculate
the MLEs for the grid shifted prediction and thus must use <code>optim()</code>
to approximate them.  In this case, we throw a <code>warning</code> to notify users there
may be inaccuracies.
</p>


<h3>References</h3>

<p>Guthrie, A. P., and Franck, C. T. (2024) Boldness-Recalibration
for Binary Event Predictions, <em>The American Statistician</em> 1-17.
</p>
<p>Nychka, D., Furrer, R., Paige, J., Sain, S. (2021). fields: Tools for
spatial data. R package version 15.2,
<a href="https://github.com/dnychka/fieldsRPackage">https://github.com/dnychka/fieldsRPackage</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate 50 predicted probabilities
set.seed(49)
x &lt;- runif(50)
# Simulated 50 binary event outcomes using x
y &lt;- rbinom(50, 1, x)  # By construction, x is well calibrated.

#' # Set grid density k=20
plot_params(x, y, k=20)

# Adjust bounds on delta and gamma
plot_params(x, y, k=20, dlim=c(0.001, 3), glim=c(0.01,2))

# Increase grid density via k &amp; save z matrix for faster plotting
zmat_list &lt;- plot_params(x, y, k=100, dlim=c(0.001, 3), glim=c(0.01,2), return_z=TRUE)

# Reuse z matrix
plot_params(z=zmat_list$z, k=100, dlim=c(0.001, 3), glim=c(0.01,2))

# Add contours at t=0.95, 0.9, and 0.8
plot_params(z=zmat_list$z, k=100, dlim=c(0.001, 3), glim=c(0.01,2), t_levels=c(0.95, 0.9, 0.8))

# Add points for 95% boldness-recalibration parameters
br95 &lt;- brcal(x, y, t=0.95, print_level=0)
plot_params(z=zmat_list$z, k=100, dlim=c(0.001, 3), glim=c(0.01,2), t_levels=c(0.95, 0.9, 0.8))
points(br95$BR_params[1], br95$BR_params[2], pch=19, col="white")

# Change color and size of contours
plot_params(z=zmat_list$z, k=100, dlim=c(0.001, 3), glim=c(0.01,2), t_levels = c(0.99, 0.1), 
contour_options=list(col="orchid", lwd=2))

# Plot contours only
plot_params(z=zmat_list$z, k=100, dlim=c(0.001, 3), glim=c(0.01,2), t_levels=c(0.95, 0.9, 0.8),
contours_only=TRUE)

# Pass arguments to image.plot()
plot_params(z=zmat_list$z, k=100, dlim=c(0.001, 3), glim=c(0.01,2),
            imgplt_options=list(horizontal = TRUE, nlevel=10, 
            legend.lab="Posterior Model Prob"))

# See vignette for more examples

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
