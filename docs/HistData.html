<!DOCTYPE html><html lang="en-US"><head><title>Help for package HistData</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HistData}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#HistData-package'>
<p>Data sets from the History of Statistics and Data Visualization</p></a></li>
<li><a href='#Arbuthnot'>
<p>Arbuthnot's data on male and female birth ratios in London from 1629-1710.</p></a></li>
<li><a href='#Armada'>
<p>La Felicisima Armada</p></a></li>
<li><a href='#Bowley'>
<p>Bowley's data on values of British and Irish trade, 1855-1899</p></a></li>
<li><a href='#Breslau'>
<p>Halley's Breslau Life Table</p></a></li>
<li><a href='#Cavendish'>
<p>Cavendish's Determinations of the Density of the Earth</p></a></li>
<li><a href='#ChestSizes'>
<p>Chest measurements of Scottish Militiamen</p></a></li>
<li><a href='#Cholera'>
<p>William Farr's Data on Cholera in London, 1849</p></a></li>
<li><a href='#CholeraDeaths1849'>
<p>Daily Deaths from Cholera and Diarrhaea in England, 1849</p></a></li>
<li><a href='#CushnyPeebles'>
<p>Cushny-Peebles Data: Soporific Effects of Scopolamine Derivatives</p></a></li>
<li><a href='#Dactyl'>
<p>Edgeworth's counts of dactyls in Virgil's Aeneid</p></a></li>
<li><a href='#DrinksWages'>
<p>Elderton and Pearson's (1910) data on drinking and wages</p></a></li>
<li><a href='#EdgeworthDeaths'>
<p>Edgeworth's Data on Death Rates in British Counties</p></a></li>
<li><a href='#Fingerprints'>
<p>Waite's data on Patterns in Fingerprints</p></a></li>
<li><a href='#Galton'>
<p>Galton's data on the heights of parents and their children</p></a></li>
<li><a href='#GaltonFamilies'>
<p>Galton's data on the heights of parents and their children, by child</p></a></li>
<li><a href='#Guerry'>
<p>Data from A.-M. Guerry, &quot;Essay on the Moral Statistics of France&quot;</p></a></li>
<li><a href='#HalleyLifeTable'>
<p>Halley's Life Table</p></a></li>
<li><a href='#Jevons'>
<p>W. Stanley Jevons' data on numerical discrimination</p></a></li>
<li><a href='#Langren'>
<p>van Langren's Data on Longitude Distance between Toledo and Rome</p></a></li>
<li><a href='#Macdonell'>
<p>Macdonell's Data on Height and Finger Length of Criminals, used by Gosset (1908)</p></a></li>
<li><a href='#Mayer'>
<p>Mayer's Data on the Libration of the Moon.</p></a></li>
<li><a href='#Michelson'>
<p>Michelson's Determinations of the Velocity of Light</p></a></li>
<li><a href='#Minard'>
<p>Data from Minard's famous graphic map of Napoleon's march on Moscow</p></a></li>
<li><a href='#Nightingale'>
<p>Florence Nightingale's data on deaths from various causes in the Crimean War</p></a></li>
<li><a href='#OldMaps'>
<p>Latitudes and Longitudes of 39 Points in 11 Old Maps</p></a></li>
<li><a href='#PearsonLee'>
<p>Pearson and Lee's  data on the heights of parents and children classified by gender</p></a></li>
<li><a href='#PolioTrials'>
<p>Polio Field Trials Data</p></a></li>
<li><a href='#Pollen'>
<p>Pollen Data Challenge</p></a></li>
<li><a href='#Prostitutes'>
<p>Parent-Duchatelet's time-series data on the number of prostitutes in Paris</p></a></li>
<li><a href='#Pyx'>
<p>Trial of the Pyx</p></a></li>
<li><a href='#Quarrels'>
<p>Statistics of Deadly Quarrels</p></a></li>
<li><a href='#Saturn'>
<p>Laplace's Saturn data.</p></a></li>
<li><a href='#Snow'>
<p>John Snow's Map and Data on the 1854 London Cholera Outbreak</p></a></li>
<li><a href='#SnowMap'>
<p>Draw John Snow's Map of Cholera in London</p></a></li>
<li><a href='#Virginis'>
<p>John F. W. Herschel's Data on the Orbit of the Twin Stars <code class="reqn">\gamma</code> <em>Virginis</em></p></a></li>
<li><a href='#Wheat'>
<p>Playfair's Data on Wages and the Price of Wheat</p></a></li>
<li><a href='#Yeast'>
<p>Student's (1906) Yeast Cell Counts</p></a></li>
<li><a href='#ZeaMays'>
<p>Darwin's Heights of Cross- and Self-fertilized Zea May Pairs</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Data Sets from the History of Statistics and Data Visualization</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9-1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-01</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael Friendly &lt;friendly@yorku.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The 'HistData' package provides a collection of small data sets
    that are interesting and important in the history of statistics and data
    visualization. The goal of the package is to make these available, both for
    instructional use and for historical research. Some of these present interesting
    challenges for graphics or analysis in R.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gtools, KernSmooth, maps, ggplot2, dplyr, scales, proto,
grid, reshape, plyr, lattice, jpeg, car, gplots, sp, heplots,
knitr, rmarkdown, effects, lubridate, gridExtra, vcd, MASS</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/friendly/HistData/issues">https://github.com/friendly/HistData/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://friendly.github.io/HistData/">https://friendly.github.io/HistData/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-08 16:00:25 UTC; friendly</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael Friendly [aut, cre],
  Stephane Dray [ctb],
  Hadley Wickham [ctb],
  James Hanley [ctb],
  Dennis Murphy [ctb],
  Peter Li [ctb],
  Luiz Droubi [ctb],
  James Riley [ctb],
  Antoine de Falguerolles [ctb],
  Monique Graf [ctb],
  Neville Verlander [ctb],
  Brian Clair [ctb],
  Jim Oeppen [ctb],
  David Bellhouse [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-09 23:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='HistData-package'>
Data sets from the History of Statistics and Data Visualization</h2><span id='topic+HistData-package'></span><span id='topic+HistData'></span>

<h3>Description</h3>

<p>The HistData package provides a collection of data sets
that are interesting and important in the history of statistics and data visualization.
The goal of the package is to make these available, both for instructional use
and for historical research.
</p>
<p>Some of the data sets have examples which reproduce an historical graph or analysis.
These are meant mainly as starters for more extensive re-analysis or graphical
elaboration. Some of these present graphical challenges to reproduce in R.
</p>
<p>They are part of a program of research called <em>statistical historiography</em>,
meaning the use of statistical methods to study problems and questions in the
history of statistics and graphics.  A main aspect of this is the increased
understanding of historical problems in science and data analysis
trough the process of trying to reproduce a graph or analysis using
modern methods. I call this &quot;Re-visioning&quot;, meaning to <em>see again,
hopefully in a new light</em>.
</p>
<p>A number of these are illustrated in our book,
Friendly &amp; Wainer (2021), <em>A History of Data Visualization and Graphic Communication</em>,
and some are re-produced in R in the companion web site, <a href="https://friendly.github.io/HistDataVis/">https://friendly.github.io/HistDataVis/</a>.
</p>


<h3>Details</h3>

<p>Descriptions of each DataSet can be found using <code>help(DataSet)</code>;
<code>example(DataSet)</code> will likely show applications similar to the
historical use.
</p>
<p>Data sets included in the HistData package are:
</p>

<dl>
<dt><code><a href="#topic+Arbuthnot">Arbuthnot</a></code></dt><dd><p>Arbuthnot's data on male and female birth ratios in London from 1629-1710</p>
</dd>
<dt><code><a href="#topic+Armada">Armada</a></code></dt><dd><p>The Spanish Armada</p>
</dd>
<dt><code><a href="#topic+Bowley">Bowley</a></code></dt><dd><p>Bowley's data on values of British and Irish trade, 1855-1899</p>
</dd>
<dt><code><a href="#topic+Breslau">Breslau</a></code></dt><dd><p>Halley's Breslau Life Table</p>
</dd>
<dt><code><a href="#topic+Cavendish">Cavendish</a></code></dt><dd><p>Cavendish's 1798 determinations of the density of the earth</p>
</dd>
<dt><code><a href="#topic+ChestSizes">ChestSizes</a></code></dt><dd><p>Quetelet's data on chest measurements of Scottish militiamen</p>
</dd>
<dt><code><a href="#topic+Cholera">Cholera</a></code></dt><dd><p>William Farr's Data on Cholera in London, 1849</p>
</dd>
<dt><code><a href="#topic+CholeraDeaths1849">CholeraDeaths1849</a></code></dt><dd><p>Daily Deaths from Cholera and Diarrhaea in England, 1849</p>
</dd>
<dt><code><a href="#topic+CushnyPeebles">CushnyPeebles</a></code></dt><dd><p>Cushny-Peebles data: Soporific effects of scopolamine derivatives</p>
</dd>
<dt><code><a href="#topic+Dactyl">Dactyl</a></code></dt><dd><p>Edgeworth's counts of dactyls in Virgil's Aeneid</p>
</dd>
<dt><code><a href="#topic+DrinksWages">DrinksWages</a></code></dt><dd><p>Elderton and Pearson's (1910) data on drinking and wages</p>
</dd>
<dt><code><a href="#topic+EdgeworthDeaths">EdgeworthDeaths</a></code></dt><dd><p>Edgeworth's Data on Death Rates in British Counties</p>
</dd>
<dt><code><a href="#topic+Fingerprints">Fingerprints</a></code></dt><dd><p>Waite's data on Patterns in Fingerprints</p>
</dd>
<dt><code><a href="#topic+Galton">Galton</a></code></dt><dd><p>Galton's data on the heights of parents and their children</p>
</dd>
<dt><code><a href="#topic+GaltonFamilies">GaltonFamilies</a></code></dt><dd><p>Galton's data on the heights of parents and their children, by family</p>
</dd>
<dt><code><a href="#topic+Guerry">Guerry</a></code></dt><dd><p>Data from A.-M. Guerry, &quot;Essay on the Moral Statistics of France&quot;</p>
</dd>
<dt><code><a href="#topic+HalleyLifeTable">HalleyLifeTable</a></code></dt><dd><p>Halley's Life Table</p>
</dd>
<dt><code><a href="#topic+Jevons">Jevons</a></code></dt><dd><p>W. Stanley Jevons' data on numerical discrimination</p>
</dd>
<dt><code><a href="#topic+Langren">Langren</a></code></dt><dd><p>van Langren's data on longitude distance between Toledo and Rome</p>
</dd>
<dt><code><a href="#topic+Macdonell">Macdonell</a></code></dt><dd><p>Macdonell's data on height and finger length of criminals, used by Gosset (1908)</p>
</dd>
<dt><code><a href="#topic+Mayer">Mayer</a></code></dt><dd><p>Mayer's data on the libration of the moon</p>
</dd>
<dt><code><a href="#topic+Michelson">Michelson</a></code></dt><dd><p>Michelson's 1879 determinations of the velocity of light</p>
</dd>
<dt><code><a href="#topic+Minard">Minard</a></code></dt><dd><p>Data from Minard's famous graphic map of Napoleon's march on Moscow</p>
</dd>
<dt><code><a href="#topic+Nightingale">Nightingale</a></code></dt><dd><p>Florence Nightingale's data on deaths from various causes in the Crimean War</p>
</dd>
<dt><code><a href="#topic+OldMaps">OldMaps</a></code></dt><dd><p>Latitudes and Longitudes of 39 Points in 11 Old Maps</p>
</dd>
<dt><code><a href="#topic+PearsonLee">PearsonLee</a></code></dt><dd><p>Pearson and Lee's 1896 data on the heights of parents and children classified by gender</p>
</dd>
<dt><code><a href="#topic+PolioTrials">PolioTrials</a></code></dt><dd><p>Polio Field Trials Data on the Salk vaccine</p>
</dd>
<dt><code><a href="#topic+Pollen">Pollen</a></code></dt><dd><p>5D dataset from the 1986 JSM Challenge</p>
</dd>
<dt><code><a href="#topic+Prostitutes">Prostitutes</a></code></dt><dd><p>Parent-Duchatelet's time-series data on the number of prostitutes in Paris</p>
</dd>
<dt><code><a href="#topic+Pyx">Pyx</a></code></dt><dd><p>Trial of the Pyx</p>
</dd>
<dt><code><a href="#topic+Quarrels">Quarrels</a></code></dt><dd><p>Statistics of Deadly Quarrels</p>
</dd>
<dt><code><a href="#topic+Saturn">Saturn</a></code></dt><dd><p>Laplace's Saturn data</p>
</dd>
<dt><code><a href="#topic+Snow">Snow</a></code></dt><dd><p>John Snow's map and data on the 1854 London Cholera outbreak</p>
</dd>
<dt><code><a href="#topic+Virginis">Virginis</a></code></dt><dd><p>J. F. W. Herschel's data on the orbit of the twin star gamma Virginis</p>
</dd>
<dt><code><a href="#topic+Wheat">Wheat</a></code></dt><dd><p>Playfair's data on wages and the price of wheat</p>
</dd>
<dt><code><a href="#topic+Yeast">Yeast</a></code></dt><dd><p>Student's (1906) Yeast Cell Counts</p>
</dd>
<dt><code><a href="#topic+ZeaMays">ZeaMays</a></code></dt><dd><p>Darwin's Heights of Cross- and Self-fertilized Zea May Pairs</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Michael Friendly
</p>
<p>Maintainer: Michael Friendly &lt;friendly@yorku.ca&gt;
</p>


<h3>References</h3>

<p>Friendly, M. (2007). A Brief History of Data Visualization.
In Chen, C., Hardle, W. &amp; Unwin, A. (eds.)  
<em>Handbook of Computational Statistics: Data Visualization</em>, Springer-Verlag, III, Ch. 1, 1-34.
</p>
<p>Friendly, M. &amp; Denis, D. (2001).
Milestones in the history of thematic cartography, statistical graphics, and data visualization.
<a href="http://datavis.ca/milestones/">http://datavis.ca/milestones/</a>
</p>
<p>Friendly, M. &amp; Denis, D. (2005). The early origins and development of the scatterplot. 
<em>Journal of the History of the Behavioral Sciences</em>, 
41, 103-130.
</p>
<p>Friendly, M. &amp; Sigal, M. &amp; Harnanansingh, D. (2016).
&quot;The Milestones Project: A Database for the History of Data Visualization,&quot;  
In Kostelnick, C. &amp; Kimball, M. (ed.),  
<em>Visible Numbers: The History of Data Visualization</em>, Ashgate Press, Chapter 10.
</p>
<p>Friendly, M. &amp; Wainer, H. (2021). <em>A History of Data Visualization and Graphic Communication</em>.
Harvard University Press. Book: <a href="https://www.hup.harvard.edu/catalog.php?isbn=9780674975231">https://www.hup.harvard.edu/catalog.php?isbn=9780674975231</a>, Web site:
<a href="https://friendly.github.io/HistDataVis/">https://friendly.github.io/HistDataVis/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Arbuthnot">Arbuthnot</a></code>, 
<code><a href="#topic+Armada">Armada</a></code>, 
<code><a href="#topic+Bowley">Bowley</a></code>,
<code><a href="#topic+Cavendish">Cavendish</a></code>, 
<code><a href="#topic+ChestSizes">ChestSizes</a></code>, 
<code><a href="#topic+Cholera">Cholera</a></code>, 
<code><a href="#topic+CholeraDeaths1849">CholeraDeaths1849</a></code>, 
<code><a href="#topic+CushnyPeebles">CushnyPeebles</a></code>,
</p>
<p><code><a href="#topic+Dactyl">Dactyl</a></code>, 
<code><a href="#topic+DrinksWages">DrinksWages</a></code>, 
<code><a href="#topic+EdgeworthDeaths">EdgeworthDeaths</a></code>, 
<code><a href="#topic+Fingerprints">Fingerprints</a></code>,
<code><a href="#topic+Galton">Galton</a></code>, 
<code><a href="#topic+GaltonFamilies">GaltonFamilies</a></code>, 
<code><a href="#topic+Guerry">Guerry</a></code>,
<code><a href="#topic+HalleyLifeTable">HalleyLifeTable</a></code>,
</p>
<p><code><a href="#topic+Jevons">Jevons</a></code>, 
<code><a href="#topic+Langren">Langren</a></code>,
<code><a href="#topic+Macdonell">Macdonell</a></code>, 
<code><a href="#topic+Michelson">Michelson</a></code>, 
<code><a href="#topic+Minard">Minard</a></code>,
<code><a href="#topic+Nightingale">Nightingale</a></code>,
</p>
<p><code><a href="#topic+OldMaps">OldMaps</a></code>, 
<code><a href="#topic+PearsonLee">PearsonLee</a></code>,
<code><a href="#topic+PolioTrials">PolioTrials</a></code>, 
<code><a href="#topic+Pollen">Pollen</a></code>, 
<code><a href="#topic+Prostitutes">Prostitutes</a></code>, 
<code><a href="#topic+Pyx">Pyx</a></code>,
</p>
<p><code><a href="#topic+Quarrels">Quarrels</a></code>,
<code><a href="#topic+Snow">Snow</a></code>,
<code><a href="#topic+Wheat">Wheat</a></code>,
<code><a href="#topic+Yeast">Yeast</a></code>,
<code><a href="#topic+ZeaMays">ZeaMays</a>
</code>
</p>
<p>Other packages containing data sets of historical interest include:
</p>
<p>The <code><a href="Guerry.html#topic+Guerry-package">Guerry-package</a></code>, containing maps and
other data sets related to Guerry's (1833) <em>Moral Statistics of France</em>.
</p>
<p><code>morsecodes</code> from the (defunct) <span class="pkg">xgobi</span> package
for data from Rothkopf (1957) on errors in learning Morse code, a classical
example for MDS.
</p>
<p>The <span class="pkg">psych</span> package, containing Galton's <code>peas</code> data.
The same data set is contained in <span class="pkg">alr4</span> as <code><a href="alr4.html#topic+galtonpeas">galtonpeas</a></code>.
</p>
<p>The <span class="pkg">agridat</span> contains a large number of data sets of agricultural data,
including some extra data sets related to
the classical barley data 
(<code><a href="MASS.html#topic+immer">immer</a></code> and <code><a href="lattice.html#topic+barley">barley</a></code>)
from Immer (1934): 
<code><a href="agridat.html#topic+minnesota.barley.yield">minnesota.barley.yield</a></code>,
<code><a href="agridat.html#topic+minnesota.barley.weather">minnesota.barley.weather</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see examples for the separate data sets
</code></pre>

<hr>
<h2 id='Arbuthnot'>
Arbuthnot's data on male and female birth ratios in London from 1629-1710.
</h2><span id='topic+Arbuthnot'></span>

<h3>Description</h3>

<p>John Arbuthnot (1710) used these time series data on the ratios of
male to female christenings in London from 1629-1710 to carry out the first known
significance test, comparing observed data to a null hypothesis.
The data for these 81 years showed that in every year there were
more male than female christenings.
</p>
<p>On the assumption that male and female births were equally likely,
he showed that the probability of observing 82 years with more
males than females was vanishingly small (<code class="reqn">~ 4.14 x 10^{-25}</code>).
He used this to argue that a nearly constant birth ratio &gt; 1
could be interpreted to show the guiding hand of a devine being.
The data set adds variables of deaths from the plague and total
mortality obtained by Campbell and from Creighton (1965).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Arbuthnot)</code></pre>


<h3>Format</h3>

<p>A data frame with 82 observations on the following 7 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>a numeric vector, 1629-1710</p>
</dd>
<dt><code>Males</code></dt><dd><p>a numeric vector, number of male christenings</p>
</dd>
<dt><code>Females</code></dt><dd><p>a numeric vector, number of female christenings</p>
</dd>
<dt><code>Plague</code></dt><dd><p>a numeric vector, number of deaths from plague</p>
</dd>
<dt><code>Mortality</code></dt><dd><p>a numeric vector, total mortality</p>
</dd>
<dt><code>Ratio</code></dt><dd><p>a numeric vector, ratio of Males/Females</p>
</dd>
<dt><code>Total</code></dt><dd><p>a numeric vector, total christenings in London (000s)</p>
</dd>
</dl>



<h3>Details</h3>

<p>Sandy Zabell (1976) pointed out several errors and inconsistencies in the
Arbuthnot data.  In particular, the values for 1674 and 1704 are identical,
suggesting that the latter were copied erroneously from the former.
</p>
<p>Jim Oeppen &lt;joeppen@health.sdu.dk&gt; points out that:
&quot;Arbuthnot's data are annual counts of public baptisms, not births.
Birth-baptism delay meant that infant deaths could occur before
baptism.  As male infants are more likely to die than females, the sex
ratio at baptism might be expected to be lower than the 'normal' male-
female birth ratio of 105:100.  These effects were not constant as
there were trends in birth-baptism delay, and in early infant
mortality.  In addition, the English Civil War and Commonwealth period
1642-1660 is thought to have been a period of both under-registration
and lower fertility, but it is not clear whether these had sex-specific effects.&quot;
</p>


<h3>Source</h3>

<p>Arbuthnot, John (1710). &quot;An argument for Devine Providence, taken from the constant Regularity
observ'd in the Births of both Sexes,&quot; <em>Philosophical transactions</em>, 27, 186-190.
Published in 1711.
</p>


<h3>References</h3>

<p>Campbell, R. B., Arbuthnot and the Human Sex Ratio (2001).
<em>Human Biology</em>, 73:4, 605-610.
</p>
<p>Creighton, C. (1965). A History of Epidemics in Britain, 2nd edition, vol. 1 and 2. 
NY: Barnes and Noble.
</p>
<p>S. Zabell (1976). Arbuthnot, Heberden, and the <em>Bills of Mortality</em>.
Technical Report No. 40, Department of Statistics, University of Chicago.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Arbuthnot)
# plot the sex ratios
with(Arbuthnot, plot(Year,Ratio, type='b', ylim=c(1, 1.20), ylab="Sex Ratio (M/F)"))
abline(h=1, col="red")
#  add loess smooth
Arb.smooth &lt;- with(Arbuthnot, loess.smooth(Year,Ratio))
lines(Arb.smooth$x, Arb.smooth$y, col="blue", lwd=2)

# plot the total christenings to observe the anomalie in 1704
with(Arbuthnot, plot(Year,Total, type='b', ylab="Total Christenings"))
</code></pre>

<hr>
<h2 id='Armada'>
La Felicisima Armada
</h2><span id='topic+Armada'></span>

<h3>Description</h3>

<p>The Spanish Armada (Spanish: <em>Grande y Felicisima Armada</em>, literally &quot;Great and Most Fortunate Navy&quot;) was a Spanish fleet of 130 ships 
that sailed from La Coruna in August 1588.
During its preparation, several accounts of its formidable strength
were circulated to reassure allied powers of Spain or to intimidate its enemies.
One such account was given by Paz Salas et Alvarez (1588).
The intent was bring the forces of Spain to invade England, overthrow
Queen Elizabeth I, and re-establish Spanish control of the Netherlands.
However the Armada
was not as fortunate as hoped: it was all destroyed in one week's fighting.
</p>
<p>de Falguerolles (2008) reports the table given here as <code>Armada</code>
as an early example of data to which multivariate methods might be applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Armada")</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 11 variables.
</p>

<dl>
<dt><code>Armada</code></dt><dd><p>designation of the fleet, a factor with levels <code>Andalucia</code> <code>Castilla</code> <code>Galeras</code> <code>Guipuscua</code> <code>Napoles</code> <code>Pataches</code> <code>Portugal</code> <code>Uantiscas</code> <code>Vizca</code> <code>Vrcas</code></p>
</dd>
<dt><code>ships</code></dt><dd><p>number of ships, a numeric vector</p>
</dd>
<dt><code>tons</code></dt><dd><p>total tons, a numeric vector</p>
</dd>
<dt><code>soldiers</code></dt><dd><p>number of soldiers, a numeric vector</p>
</dd>
<dt><code>sailors</code></dt><dd><p>number of sailors, a numeric vector</p>
</dd>
<dt><code>men</code></dt><dd><p>total of soldiers plus sailors, a numeric vector</p>
</dd>
<dt><code>artillery</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>balls</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>gunpowder</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>lead</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>rope</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Note that <code>men = soldiers + sailors</code>
</p>


<h3>Source</h3>

<p>de Falguerolles, A. (2008)
L'analyse des donnees; before and around.
<em>Journal Electronique  d'Histoire des
Probabilites et de la Statistique</em>,
4 (2),
http://www.jehps.net/Decembre2008/Falguerolles.pdf
</p>


<h3>References</h3>

<p>Pedro de Paz Salas and Antonio Alvares. La felicisima armada que elrey Don
Felipe nuestro Senor mando juntar enel puerto de la ciudad de Lisboa enel Reyno
de Portugal. Lisbon, 1588.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Armada)
# delete character and redundant variable
armada &lt;- Armada[,-c(1,6)]

armada.pca &lt;- prcomp(armada, scale.=TRUE)
summary(armada.pca)

plot(armada.pca, type="lines", pch=16, cex=2)
biplot(armada.pca)
</code></pre>

<hr>
<h2 id='Bowley'>
Bowley's data on values of British and Irish trade, 1855-1899
</h2><span id='topic+Bowley'></span>

<h3>Description</h3>

<p>In one of the first statistical textbooks, Arthur Bowley (1901)
used these data to illustrate an arithmetic and graphical analysis
of time-series data using the total value of British and Irish
exports from 1855-1899.  He presented a line graph of the time-series
data, supplemented by overlaid line graphs of 3-, 5- and 10-year moving
averages.  His goal was to show that while the initial series
showed wide variability, moving averages made the series progressively
smoother.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Bowley)</code></pre>


<h3>Format</h3>

<p>A data frame with 45 observations on the following 2 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>Year, from 1855-1899</p>
</dd>
<dt><code>Value</code></dt><dd><p>total value of British and Irish exports (millions of Pounds)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Bowley, A. L. (1901). <em>Elements of Statistics</em>. London: P. S. King and Son,
p. 151-154.
</p>
<p>Digitized from Bowley's graph.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Bowley)

# plot the data 
with(Bowley,plot(Year, Value, type='b', lwd=2, 
	ylab="Value of British and Irish Exports",
	main="Bowley's example of the method of smoothing curves"))

# find moving averages
# simpler version using stats::filter
running &lt;- function(x, width = 5){
  as.vector(stats::filter(x, rep(1 / width, width), sides = 2))
  }

mav3&lt;-running(Bowley$Value, width=3)
mav5&lt;-running(Bowley$Value, width=5)
mav9&lt;-running(Bowley$Value, width=9)
lines(Bowley$Year, mav3, col='blue', lty=2)
lines(Bowley$Year, mav5, col='green3', lty=3)
lines(Bowley$Year, mav9, col='brown', lty=4)

# add lowess smooth
lines(lowess(Bowley), col='red', lwd=2)

# Initial version, using ggplot
library(ggplot2)
ggplot(aes(x=Year, y=Value), data=Bowley) +
  geom_point() +
  geom_smooth(method="loess", formula=y~x)
</code></pre>

<hr>
<h2 id='Breslau'>
Halley's Breslau Life Table
</h2><span id='topic+Breslau'></span>

<h3>Description</h3>

<p>Edmond Halley published his Breslau life table in 1693, which was arguably the first
in the world based on population data. David Bellhouse (2011) resurrected the original
sources of these data, collected by Caspar Neumann in the city of Breslau (now called Wroclaw),
and then reconstructed in the 1880s by Jonas Graetzer, the medical officer
in Breslau at that time.  
</p>
<p>The dataset here follows Graetzer, and gives the number of deaths
at ages <code>1:100</code> recorded in each of the years <code>1687:1691</code>. Halley's analysis was based on the total
over those years.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Breslau")</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 8 variables. The <code>yearXXXX</code> variables give the number of deaths for persons of a given <code>age</code> recorded in that year.
</p>

<dl>
<dt><code>age</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>year1687</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>year1688</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>year1689</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>year1690</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>year1691</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>total</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>average</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset was kindly provided by David Bellhouse.
</p>


<h3>Source</h3>

<p>Bellhouse, D.R. (2011), A new look at Halley's life table. 
<em>Journal of the Royal Statistical Society</em>: Series A, <b>174</b>, 823-832. 
<a href="https://doi.org/10.1111/j.1467-985X.2010.00684.x">doi:10.1111/j.1467-985X.2010.00684.x</a>
</p>


<h3>References</h3>

<p>Halley, E. (1693). An estimate of the degrees of mortality of mankind, drawn from the curious tables of births and
funerals in the City of Breslaw; with an attempt to ascertain the price of annuities upon lives. 
<em>Phil. Trans.</em>, <b>17</b>, 596-610.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Arbuthnot">Arbuthnot</a></code>, <code><a href="#topic+HalleyLifeTable">HalleyLifeTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Breslau)

# Reproduce Figure 1 in Bellhouse (2011)
# He excluded age &lt; 5 and made a point of the over-representation of deaths in quinquennial years.
library(ggplot2)
library(dplyr, warn.conflicts = FALSE)
Breslau5 &lt;- Breslau |&gt;
  filter(age &gt;= 5) |&gt;
  mutate(div5 = factor(age %% 5 == 0))

ggplot(Breslau5, aes(x=age, y=total), size=1.5) +
  geom_point(aes(color=div5)) +
  scale_color_manual(labels = c(FALSE, TRUE), 
                     values = c("blue", "red")) +
  guides(color=guide_legend("Age divisible by 5")) +
  theme(legend.position = "top") +
  labs(x = "Age current at death",
       y = "Total number of deaths") +
  theme_bw()

</code></pre>

<hr>
<h2 id='Cavendish'>
Cavendish's Determinations of the Density of the Earth
</h2><span id='topic+Cavendish'></span>

<h3>Description</h3>

<p>Henry Cavendish carried out a series of experiments in 1798 to determine the
mean density of the earth, as an indirect means to calculate the
gravitational constant, G, in Newton's formula for the force (f) of
gravitational attraction,
<code class="reqn">f = G m M / r^2</code>
between two bodies of mass m and M.
</p>
<p>Stigler (1977) used these data to illustrate properties of robust estimators
with real, historical data.  For these data sets, he found that trimmed means
performed as well or better than more elaborate robust estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Cavendish)</code></pre>


<h3>Format</h3>

<p>A data frame with 29 observations on the following 3 variables.
</p>

<dl>
<dt><code>density</code></dt><dd><p>Cavendish's 29 determinations of the mean density of the earth</p>
</dd>
<dt><code>density2</code></dt><dd><p>same as <code>density</code>, with the third value (4.88) replaced by 5.88</p>
</dd>
<dt><code>density3</code></dt><dd><p>same as <code>density</code>, omitting the the first 6 observations</p>
</dd>
</dl>



<h3>Details</h3>

<p>Density values (D) of the earth are given as relative to that of water.  If the earth is
regarded as a sphere of radius R, Newton's law can be expressed as
<code class="reqn">G D = 3 g / (4 \pi R)</code>, where <code class="reqn">g=9.806 m/s^2</code> is the acceleration due to gravity; so G is proportional to 1/D.
</p>
<p><code>density</code> contains Cavendish's measurements as analyzed, where he treated the
value 4.88 as if it were 5.88.   <code>density2</code> corrects this.
Cavendish also changed his experimental apparatus after the sixth determination,
using a stiffer wire in the torsion balance. <code>density3</code> replaces the first
6 values with <code>NA</code>.
</p>
<p>The modern &quot;true&quot; value of D is taken as 5.517. 
The gravitational constant can be expressed as <code class="reqn">G = 6.674 * 10^-11 m^3/kg/s^2</code>.
</p>


<h3>Source</h3>

<p>Kyle Siegrist, &quot;Virtual Laboratories in Probability and Statistics&quot;, <a href="http://www.math.uah.edu/stat/data/Cavendish.html">http://www.math.uah.edu/stat/data/Cavendish.html</a>
</p>
<p>Stephen M. Stigler (1977), &quot;Do robust estimators work with <em>real</em> data?&quot;, <em>Annals of Statistics</em>,  5, 1055-1098
</p>


<h3>References</h3>

<p>Cavendish, H. (1798). Experiments to determine the density of the earth.
<em>Philosophical Transactions of the Royal Society of London</em>, 88 (Part II),
469-527.
Reprinted in A. S. Mackenzie (ed.), <em>The Laws of Gravitation</em>, 1900, 
New York: American.
</p>
<p>Brownlee, K. A. (1965). <em>Statistical theory and methodology in science and engineering</em>,
NY: Wiley, p. 520.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Cavendish)
summary(Cavendish)
boxplot(Cavendish, ylab='Density', xlab='Data set')
abline(h=5.517, col="red", lwd=2)

# trimmed means
sapply(Cavendish, mean, trim=.1, na.rm=TRUE)

# express in terms of G
G &lt;- function(D, g=9.806, R=6371) 3*g / (4 * pi * R * D)
 
boxplot(10^5 * G(Cavendish), ylab='~ Gravitational constant (G)', xlab='Data set')
abline(h=10^5 * G(5.517), col="red", lwd=2)

</code></pre>

<hr>
<h2 id='ChestSizes'>
Chest measurements of Scottish Militiamen
</h2><span id='topic+ChestSizes'></span><span id='topic+ChestStigler'></span>

<h3>Description</h3>

<p>Quetelet's data on chest measurements of 5738 Scottish Militiamen. Quetelet (1846) used this
data as a demonstration of the normal distribution of physical characteristics and the
concept of <em>l'homme moyen</em>.
</p>
<p>Stigler (1986) compared this table to the original 1817 source, and discovered some transcription
errors, which he corrected (p. 208).  These data are given separately in
<code>ChestStigler</code>.
Gallagher (2020) used these data sets to re-consider the question of normality in these distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ChestSizes)</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 2 variables. Total count=5738.
</p>

<dl>
<dt><code>chest</code></dt><dd><p>Chest size (in inches)</p>
</dd>
<dt><code>count</code></dt><dd><p>Number of soldiers with this chest size</p>
</dd>
</dl>



<h3>Source</h3>

<p>Velleman, P. F. and Hoaglin, D. C. (1981). 
<em>Applications, Basics, and Computing of Exploratory Data Analysis</em>. Belmont. CA: Wadsworth.
Retrieved from Statlib: <code>https://www.stat.cmu.edu/StatDat/Datafiles/MilitiamenChests.html</code>
</p>


<h3>References</h3>

<p>A. Quetelet, <em>Lettres a S.A.R. le Duc Regnant de Saxe-Cobourg et Gotha, sur la Theorie des Probabilites, 
Appliquee aux Sciences Morales et Politiques</em>. Brussels: M. Hayes, 1846, p. 400.
</p>
<p>Eugene D. Gallagher (2020). Was Quetelet's Average Man Normal?, <em>The American Statistician</em>, 74:3, 301-306, 
DOI: 10.1080/00031305.2019.1706635 
</p>
<p>Stephen M. Stigler (1986). <em>The History of Statistics: The Measurement of Uncertainty before 1900</em>. Cambridge, MA: Harvard University Press, 1986, p. 208.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ChestSizes)

# frequency polygon
plot(ChestSizes, type='b')
# barplot
barplot(ChestSizes[,2], ylab="Frequency", xlab="Chest size")

# calculate expected frequencies under normality, chest ~ N(xbar, std)
n_obs &lt;- sum(ChestSizes$count)
xbar  &lt;- with(ChestSizes, weighted.mean(chest, count))
std   &lt;- with(ChestSizes, sd(rep(chest, count)))

expected &lt;- 
with(ChestSizes, diff(pnorm(c(32, chest) + .5, xbar, std)) * sum(count))


</code></pre>

<hr>
<h2 id='Cholera'>
William Farr's Data on Cholera in London, 1849
</h2><span id='topic+Cholera'></span>

<h3>Description</h3>

<p>In 1852, William Farr, published a report of the Registrar-General on mortality
due to cholera in England in the years 1848-1849, during which there was a
large epidemic throughout the country.  Farr initially believed that cholera
arose from bad air (&quot;miasma&quot;) associated with low elevation above the
River Thames. John Snow (1855) later showed that the disease was principally
spread by contaminated water.
</p>
<p>This data set comes from a paper by Brigham et al. (2003) that analyses some
tables from Farr's report to examine the prevalence of death from cholera
in the districts of London in relation to the available predictors from
Farr's table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Cholera")</code></pre>


<h3>Format</h3>

<p>A data frame with 38 observations on the following 15 variables.
</p>

<dl>
<dt><code>district</code></dt><dd><p>name of the district in London, a character vector</p>
</dd>
<dt><code>cholera_drate</code></dt><dd><p>deaths from cholera in 1849 per 10,000 inhabitants, a numeric vector</p>
</dd>
<dt><code>cholera_deaths</code></dt><dd><p>number of deaths registered from cholera in 1849, a numeric vector</p>
</dd>
<dt><code>popn</code></dt><dd><p>population, in the middle of 1849, a numeric vector</p>
</dd>
<dt><code>elevation</code></dt><dd><p>elevation, in feet above the high water mark, a numeric vector</p>
</dd>
<dt><code>region</code></dt><dd><p>a grouping of the London districts, a factor with levels <code>West</code> <code>North</code> <code>Central</code> <code>South</code> <code>Kent</code></p>
</dd>
<dt><code>water</code></dt><dd><p>water supply region, a factor with levels <code>Battersea</code> <code>New River</code> <code>Kew</code>; see Details</p>
</dd>
<dt><code>annual_deaths</code></dt><dd><p>annual deaths from all causes, 1838-1844, a numeric vector</p>
</dd>
<dt><code>pop_dens</code></dt><dd><p>population density (persons per acre), a numeric vector</p>
</dd>
<dt><code>persons_house</code></dt><dd><p>persons per inhabited house, a numeric vector</p>
</dd>
<dt><code>house_valpp</code></dt><dd><p>average annual value of house, per person (pounds), a numeric vector</p>
</dd>
<dt><code>poor_rate</code></dt><dd><p>poor rate precept per pound of house value, a numeric vector</p>
</dd>
<dt><code>area</code></dt><dd><p>district area, a numeric vector</p>
</dd>
<dt><code>houses</code></dt><dd><p>number of houses, a numeric vector</p>
</dd>
<dt><code>house_val</code></dt><dd><p>total house values, a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The supply of <code>water</code> was classified as &ldquo;Thames, between Battersea and Waterloo Bridges&rdquo;
(central London), 
&ldquo;New River, Rivers Lea and Ravensbourne&rdquo;, and &ldquo;Thames, at Kew and Hammersmith&rdquo;
(western London).
The factor levels use abbreviations for these.
</p>
<p>The data frame is sorted by increasing elevation above the high water mark.
</p>


<h3>Source</h3>

<p>Bingham P., Verlander, N. Q., Cheal M. J. (2004).
John Snow, William Farr and the 1849 outbreak of cholera that affected London: 
a reworking of the data highlights the importance of the water supply.
<em>Public Health</em>, 118(6), 387-394, Table 2.
(The data was kindly supplied by Neville Verlander, including additional variables
not shown in their Table 2.)
</p>


<h3>References</h3>

<p>Registrar-General (1852). <em>Report on the Mortality of Cholera in England 1848-49</em>,
W. Clowes and Sons, for Her Majesty's Stationary Office.
Written by William Farr.
<a href="https://ia800309.us.archive.org/22/items/b24751297/b24751297.pdf">https://ia800309.us.archive.org/22/items/b24751297/b24751297.pdf</a>
The relevant tables are at pages clii &ndash; clvii.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CholeraDeaths1849">CholeraDeaths1849</a></code>, <code><a href="#topic+Snow.deaths">Snow.deaths</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Cholera)

# plot cholera deaths vs. elevation
plot(cholera_drate ~ elevation, data=Cholera, 
	pch=16, cex.lab=1.2, cex=1.2,
	xlab="Elevation above high water mark (ft)",
	ylab="Deaths from cholera in 1849 per 10,000")

# Farr's mortality ~ 1/ elevation law
elev &lt;- c(0, 10, 30, 50, 70, 90, 100, 350)
mort &lt;- c(174, 99, 53, 34, 27, 22, 20, 6)
lines(mort ~ elev, lwd=2, col="blue")

# better plots, using car::scatterplot

if(require("car", quietly=TRUE)) {
# show separate regression lines for each water supply
  scatterplot(cholera_drate ~ elevation | water, data=Cholera, 
              smooth=FALSE, pch=15:17,
              id=list(n=2, labels=sub(",.*", "", Cholera$district)),
              col=c("red", "darkgreen", "blue"),
              legend=list(coords="topleft", title="Water supply"),
              xlab="Elevation above high water mark (ft)",
              ylab="Deaths from cholera in 1849 per 10,000")
  
  scatterplot(cholera_drate ~ poor_rate | water, data=Cholera, 
              smooth=FALSE, pch=15:17,
              id=list(n=2, labels=sub(",.*", "", Cholera$district)),
              col=c("red", "darkgreen", "blue"),
              legend=list(coords="topleft", title="Water supply"),
              xlab="Poor rate per pound of house value",
              ylab="Deaths from cholera in 1849 per 10,000")
  }

# fit a logistic regression model a la Bingham etal.
fit &lt;- glm( cbind(cholera_deaths, popn) ~ 
            water + elevation + poor_rate + annual_deaths +
            pop_dens + persons_house,
            data=Cholera, family=binomial)
summary(fit)

# odds ratios
cbind( OR = exp(coef(fit))[-1], exp(confint(fit))[-1,] )

if (require(effects)) {
  eff &lt;- allEffects(fit)
  plot(eff)
}

</code></pre>

<hr>
<h2 id='CholeraDeaths1849'>
Daily Deaths from Cholera and Diarrhaea in England, 1849
</h2><span id='topic+CholeraDeaths1849'></span>

<h3>Description</h3>

<p>Deaths from Cholera and Diarrhaea, for each day of the month of each of the 12 months of 1849.
</p>
<p>This was used by William Farr (GRO &amp; Farr, 1852, Plate 2) to produce a time series chart of these deaths,
in which he also recorded various meteorological phenomena (barometer, wind, rain),
to see if he could find any patterns. This chart is available on the web site
for Friendly &amp; Wainer (2021) as Fig 4.1, <a href="https://friendly.github.io/HistDataVis/figs-web/04_1-cholera-diarrhea.png">https://friendly.github.io/HistDataVis/figs-web/04_1-cholera-diarrhea.png</a>.
</p>
<p>James Riley (2023) notes, &quot;Cholera 1849 has special significance &mdash; it is likely to be one of few modern pandemics that was completely unmitigated.&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CholeraDeaths1849")</code></pre>


<h3>Format</h3>

<p>A data frame with 730 observations on the following 6 variables.
</p>

<dl>
<dt><code>month</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>cause_of_death</code></dt><dd><p>a factor with levels <code>Cholera</code> <code>Diarrhaea</code></p>
</dd>
<dt><code>day_of_month</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>deaths</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>date</code></dt><dd><p>a Date</p>
</dd>
<dt><code>day_of_week</code></dt><dd><p>an ordered factor with levels <code>Mon</code> &lt; <code>Tue</code> &lt; <code>Wed</code> &lt; <code>Thu</code> &lt; <code>Fri</code> &lt; <code>Sat</code> &lt; <code>Sun</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>The data set was transcribed by James Riley to a spreadsheet, <a href="https://github.com/jimr1603/1849-cholera">https://github.com/jimr1603/1849-cholera</a>.
He notes, &quot;the scan at Internet Archive has a fold on day 11. I have derived this column from the row totals.&quot;
</p>


<h3>Source</h3>

<p>The original source is:
General Register Office, William Farr (1852), <em>Report on the Mortality of Cholera in England, 1848-49</em>. London: Printed by W. Clowes, for HMSO; scanned by the Internet Archive from the collection of King's College London
and available at <a href="https://archive.org/details/b21308251/page/20/mode/2up">https://archive.org/details/b21308251/page/20/mode/2up</a>.
</p>


<h3>References</h3>

<p>Friendly, M. &amp; Wainer, H. (2021). 
<em>A History of Data Visualization and Graphic Communication</em>,
Harvard University Press.
<a href="https://www.hup.harvard.edu/catalog.php?isbn=9780674975231">https://www.hup.harvard.edu/catalog.php?isbn=9780674975231</a>.
</p>
<p>Riley, J. (2023). &quot;Cholera in Victorian England&quot;, blog post,
<a href="https://openor.blog/2023/07/27/cholera-in-victorian-england/">https://openor.blog/2023/07/27/cholera-in-victorian-england/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Cholera">Cholera</a></code>, <code><a href="#topic+Snow.deaths">Snow.deaths</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(CholeraDeaths1849)
str(CholeraDeaths1849)

# Reproduce Farr's (1852) plate 2
library(ggplot2)
CholeraDeaths1849  |&gt;
  ggplot(aes(x = date, y = deaths, colour = cause_of_death)) +
  geom_line(linewidth = 1.2) +
  theme_bw(base_size = 14) +
  theme(legend.position = "top")

</code></pre>

<hr>
<h2 id='CushnyPeebles'>
Cushny-Peebles Data: Soporific Effects of Scopolamine Derivatives
</h2><span id='topic+CushnyPeebles'></span><span id='topic+CushnyPeeblesN'></span>

<h3>Description</h3>

<p>Cushny and Peebles (1905) studied the effects of hydrobromides
related to scopolamine and atropine
in producing sleep. The sleep of mental patients was
measured without hypnotic (<code>Control</code>) and after treatment 
with one of three drugs: L. hyoscyamine hydrobromide (<code>L_hyoscyamine</code>),
L. hyoscine hydrobromide (<code>L_hyoscyine</code>), and
a mixture (racemic) form, <code>DL_hyoscine</code>, called atropine.  
The L (levo) and D (detro)
form of a given molecule are optical isomers (mirror images).
</p>
<p>The drugs were given on alternate evenings, and the hours
of sleep were compared with the intervening control night.
Each of the drugs was tested in this manner a varying number of times in each subject.
The average number of hours of sleep for each treatment is the response.
</p>
<p>Student (1908) used these data to illustrate the paired-sample t-test
in small samples, testing the hypothesis that the mean difference between
a given drug and the control condition was zero.  
This data set became well known when used by Fisher (1925).  Both Student
and Fisher had problems labeling the drugs correctly (see Senn &amp; Richardson (1994)),
and consequently came to wrong conclusions.
</p>
<p>But as well, the sample sizes (number of nights) for each mean differed widely,
ranging from 3-9, and this was not taken into account in their analyses.
To allow weighted analyses, the number of observations for each mean
is contained in the data frame <code>CushnyPeeblesN</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(CushnyPeebles)
data(CushnyPeeblesN)
	</code></pre>


<h3>Format</h3>

<p><code>CushnyPeebles</code>: A data frame with 11 observations on the following 4 variables.
</p>

<dl>
<dt><code>Control</code></dt><dd><p>a numeric vector: mean hours of sleep</p>
</dd>
<dt><code>L_hyoscyamine</code></dt><dd><p>a numeric vector: mean hours of sleep</p>
</dd>
<dt><code>L_hyoscine</code></dt><dd><p>a numeric vector: mean hours of sleep</p>
</dd>
<dt><code>D_hyoscine</code></dt><dd><p>a numeric vector: mean hours of sleep</p>
</dd>
</dl>

<p><code>CushnyPeeblesN</code>:   A data frame with 11 observations on the following 4 variables.
</p>

<dl>
<dt><code>Control</code></dt><dd><p>a numeric vector: number of observations</p>
</dd>
<dt><code>L_hyoscyamine</code></dt><dd><p>a numeric vector: number of observations</p>
</dd>
<dt><code>L_hyoscine</code></dt><dd><p>a numeric vector: number of observations</p>
</dd>
<dt><code>DL_hyoscine</code></dt><dd><p>a numeric vector: number of observations</p>
</dd>
</dl>



<h3>Details</h3>

<p>The last patient (11) has no <code>Control</code> observations, and so is often excluded
in analyses or other versions of this data set.
</p>


<h3>Source</h3>

<p>Cushny, A. R., and Peebles, A. R. (1905), &quot;The Action of Optical Isomers. II:
Hyoscines,&quot; <em>Journal of Physiology</em>, 32, 501-510.
</p>


<h3>References</h3>

<p>Fisher, R. A. (1925), <em>Statistical Methods for Research Workers</em>, Edinburgh and London:
Oliver &amp; Boyd.
</p>
<p>Student (1908), &quot;The Probable Error of a Mean,&quot; <em>Biometrika</em>, 6, 1-25.
</p>
<p>Senn, S.J. and Richardson, W. (1994), &quot;The first t-test&quot;, <em>Statistics in Medicine</em>, 13, 785-803.
</p>


<h3>See Also</h3>

<p><code><a href="datasets.html#topic+sleep">sleep</a></code> for an alternative form of this data set.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(CushnyPeebles)
# quick looks at the data
plot(CushnyPeebles)
boxplot(CushnyPeebles, ylab="Hours of Sleep", xlab="Treatment")

##########################
# Repeated measures MANOVA

CPmod &lt;- lm(cbind(Control, L_hyoscyamine, L_hyoscine, DL_hyoscine) ~ 1, data=CushnyPeebles)

# Assign within-S factor and contrasts
Treatment &lt;- factor(colnames(CushnyPeebles), levels=colnames(CushnyPeebles))
contrasts(Treatment) &lt;- matrix(
	c(-3, 1, 1, 1,
	   0,-2, 1, 1,
	   0, 0,-1, 1), ncol=3)
colnames(contrasts(Treatment)) &lt;- c("Control.Drug", "L.DL", "L_hy.DL_hy")

Treats &lt;- data.frame(Treatment)
if (require(car)) {
(CPaov &lt;- Anova(CPmod, idata=Treats, idesign= ~Treatment))
}
summary(CPaov, univariate=FALSE)

if (require(heplots)) {
  heplot(CPmod, idata=Treats, idesign= ~Treatment, iterm="Treatment", 
	xlab="Control vs Drugs", ylab="L vs DL drug")
  pairs(CPmod, idata=Treats, idesign= ~Treatment, iterm="Treatment")
}

################################
# reshape to long format, add Ns

CPlong &lt;- stack(CushnyPeebles)[,2:1]
colnames(CPlong) &lt;- c("treatment", "sleep")
CPN &lt;- stack(CushnyPeeblesN)
CPlong &lt;- data.frame(patient=rep(1:11,4), CPlong, n=CPN$values)
str(CPlong)

</code></pre>

<hr>
<h2 id='Dactyl'>
Edgeworth's counts of dactyls in Virgil's Aeneid
</h2><span id='topic+Dactyl'></span>

<h3>Description</h3>

<p>Edgeworth (1885) took the first 75 lines in Book XI of
Virgil's <em>Aeneid</em> and classified each of the first four &quot;feet&quot; of the line 
as a dactyl (one long syllable followed by two short ones) or not.
</p>
<p>Grouping the lines in blocks of five gave a 4 x 25 table of counts,
represented here as a data frame with ordered factors, <code>Foot</code> and
<code>Lines</code>. Edgeworth used this table in what was among the first
examples of analysis of variance applied to a two-way
classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Dactyl)</code></pre>


<h3>Format</h3>

<p>A data frame with 60 observations on the following 3 variables.
</p>

<dl>
<dt><code>Foot</code></dt><dd><p>an ordered factor with levels <code>1</code> &lt; <code>2</code> &lt; <code>3</code> &lt; <code>4</code></p>
</dd>
<dt><code>Lines</code></dt><dd><p>an ordered factor with levels <code>1:5</code> &lt; <code>6:10</code> &lt; <code>11:15</code> &lt; <code>16:20</code> &lt; <code>21:25</code> &lt; <code>26:30</code> &lt; <code>31:35</code> &lt; <code>36:40</code> &lt; <code>41:45</code> &lt; <code>46:50</code> &lt; <code>51:55</code> &lt; <code>56:60</code> &lt; <code>61:65</code> &lt; <code>66:70</code> &lt; <code>71:75</code></p>
</dd>
<dt><code>count</code></dt><dd><p>number of dactyls</p>
</dd>
</dl>



<h3>Source</h3>

<p>Stigler, S. (1999)
<em>Statistics on the Table</em>
Cambridge, MA: Harvard University Press, table 5.1.
</p>


<h3>References</h3>

<p>Edgeworth, F. Y. (1885).
On methods of ascertaining variations in the rate of births, deaths and marriages.
<em>Journal of the [Royal] Statistical Society</em>, 48, 628-649.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Dactyl)

# display the basic table
xtabs(count ~ Foot+Lines, data=Dactyl)

# simple two-way anova
anova(dact.lm &lt;- lm(count ~ Foot+Lines, data=Dactyl))

# plot the lm-quartet
op &lt;- par(mfrow=c(2,2))
plot(dact.lm)
par(op)

# show table as a simple mosaicplot
mosaicplot(xtabs(count ~ Foot+Lines, data=Dactyl), shade=TRUE)
</code></pre>

<hr>
<h2 id='DrinksWages'>
Elderton and Pearson's (1910) data on drinking and wages
</h2><span id='topic+DrinksWages'></span>

<h3>Description</h3>

<p>In 1910, Karl Pearson weighed in on the debate, fostered by the temperance movement,
on the evils done by alcohol not only to drinkers, but to their families.
The report &quot;A first study of the influence
of parental alcoholism on the physique and ability of their offspring&quot;
was an ambitious attempt to the new methods of statistics to bear on
an important question of social policy, to see if the hypothesis that
children were damaged by parental alcoholism would stand up to
statistical scrutiny.
</p>
<p>Working with his assistant, Ethel M. Elderton, Pearson collected voluminous
data in Edinburgh and Manchester on many aspects of health, stature,
intelligence, etc. of children classified according to the drinking
habits of their parents.  His conclusions where almost invariably
negative:  the tendency of parents to drink appeared unrelated
to any thing he had measured.
</p>
<p>The firestorm that this report set off is well described by Stigler (1999),
Chapter 1.  The data set <code>DrinksWages</code> is just one of Pearson's
many tables, that he published in a letter to <em>The Times</em>,
August 10, 1910. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DrinksWages)</code></pre>


<h3>Format</h3>

<p>A data frame with 70 observations on the following 6 variables, giving the number of non-drinkers (<code>sober</code>)
and drinkers (<code>drinks</code>) in various occupational categories (<code>trade</code>).
</p>

<dl>
<dt><code>class</code></dt><dd><p>wage class: a factor with levels <code>A</code> <code>B</code> <code>C</code></p>
</dd>
<dt><code>trade</code></dt><dd><p>a factor with levels <code>baker</code> <code>barman</code> <code>billposter</code> ...  <code>wellsinker</code> <code>wireworker</code></p>
</dd>
<dt><code>sober</code></dt><dd><p>the number of non-drinkers, a numeric vector</p>
</dd>
<dt><code>drinks</code></dt><dd><p>the number of drinkers, a numeric vector</p>
</dd>
<dt><code>wage</code></dt><dd><p>weekly wage (in shillings), a numeric vector</p>
</dd>
<dt><code>n</code></dt><dd><p>total number, a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data give Karl Pearson's tabulation of the father's trades from
an Edinburgh sample, classified by whether they drink or are sober,
and giving average weekly wage.
</p>
<p>The wages are averages of the individuals' nominal wages.
Class A is those with wages under 2.5s.; B: those with wages 2.5s. to 30s.; C:
wages over 30s.
</p>


<h3>Source</h3>

<p>Pearson, K. (1910). <em>The Times</em>, August 10, 1910.
</p>
<p>Stigler, S. M. (1999).
<em>Statistics on the Table: The History of Statistical Concepts and Methods</em>.
Harvard University Press, Table 1.1
</p>


<h3>References</h3>

<p>M. E. Elderton &amp; K. Pearson (1910). A first study of the influence
of parental alcoholism on the physique and ability of their offspring,
Eugenics Laboratory Memoirs, 10.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DrinksWages)
plot(DrinksWages) 

# plot proportion sober vs. wage | class
with(DrinksWages, plot(wage, sober/n, col=c("blue","red","green")[class]))

# fit logistic regression model of sober on wage
mod.sober &lt;- glm(cbind(sober, n) ~ wage, family=binomial, data=DrinksWages)
summary(mod.sober)
op &lt;- par(mfrow=c(2,2))
plot(mod.sober)
par(op)

# TODO: plot fitted model
</code></pre>

<hr>
<h2 id='EdgeworthDeaths'>
Edgeworth's Data on Death Rates in British Counties
</h2><span id='topic+EdgeworthDeaths'></span>

<h3>Description</h3>

<p>In 1885, Francis Edgeworth published a paper, <em>On methods of ascertaining variations in the rate of births, deaths and marriages</em>.
It contained among the first examples of two-way tables, analyzed to show variation among row and column factors,
in a way that Fisher would later formulate as the Analysis of Variance. 
</p>
<p>Although the data are rates per 1000, they provide a good example of a two-way ANOVA with n=1 per cell,
where an additive model fits reasonably well. 
</p>
<p>Treated as frequencies, the data is also a good example of a case where the independence model fits
reasonably well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EdgeworthDeaths")</code></pre>


<h3>Format</h3>

<p>A data frame with 42 observations on the following 3 variables.
</p>

<dl>
<dt><code>County</code></dt><dd><p>a factor with levels <code>Berks</code> <code>Herts</code> <code>Bucks</code> <code>Oxford</code> <code>Bedford</code> <code>Cambridge</code></p>
</dd>
<dt><code>year</code></dt><dd><p>an ordered factor with levels <code>1876</code> &lt; <code>1877</code> &lt; <code>1878</code> &lt; <code>1879</code> &lt; <code>1880</code> &lt; <code>1881</code> &lt; <code>1882</code></p>
</dd>
<dt><code>Freq</code></dt><dd><p>a numeric vector, death rate per 1000 population</p>
</dd>
</dl>



<h3>Details</h3>

<p>Edgeworth's data came from the Registrar General's report for the final year, 1883.
The <code>Freq</code> variable represents death rates per 1000 population in the six counties listed.
</p>


<h3>Source</h3>

<p>The data were scanned from Table 5.2 in 
Stigler, S. M. (1999) <em>Statistics on the Table: The History of Statistical Concepts and Methods</em>,
Harvard University Press.
</p>


<h3>References</h3>

<p>Edgeworth, F. Y. (1885). On Methods of Ascertaining Variations in the Rate of Births, Deaths, and Marriages. 
<em>Journal of the Statistical Society of London</em>, 48(4), 628-649. doi:10.2307/2979201
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(EdgeworthDeaths)

# fit the additive ANOVA model
library(car)  # for Anova()
EDmod &lt;- lm(Freq ~ County + year, data=EdgeworthDeaths)
Anova(EDmod)

# now, consider as a two-way table of frequencies

library(vcd)
library(MASS)
structable( ~ County + year, data=EdgeworthDeaths)
loglm( Freq ~ County + year, data=EdgeworthDeaths)

mosaic( ~ County + year, data=EdgeworthDeaths, 
	shade=TRUE, legend=FALSE, labeling=labeling_values, 
	gp=shading_Friendly)


</code></pre>

<hr>
<h2 id='Fingerprints'>
Waite's data on Patterns in Fingerprints
</h2><span id='topic+Fingerprints'></span>

<h3>Description</h3>

<p>Waite (1915) was interested in analyzing the association of patterns in fingerprints,
and produced a table of counts for 2000 right hands, classified by the number of fingers
describable as a &quot;whorl&quot;, a &quot;small loop&quot; (or neither).
Because each hand contributes five fingers, the number of <code>Whorls + Loops</code> cannot exceed 5,
so the contingency table is necessarily triangular.
</p>
<p>Karl Pearson (1904) introduced the test for independence in contingency tables, and by 1913
had developed methods for &quot;restricted contingency tables,&quot; such as the triangular table
analyzed by Waite.  The general formulation of such tests for association in restricted
tables is now referred to as models for quasi-independence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Fingerprints)</code></pre>


<h3>Format</h3>

<p>A frequency data frame with 36 observations on the following 3 variables, 
representing a 6 x 6 table giving
the cross-classification of the fingers on 2000 right hands as a whorl, small loop
or neither.
</p>

<dl>
<dt><code>Whorls</code></dt><dd><p>Number of whorls, an ordered factor with levels <code>0</code> &lt; <code>1</code> &lt; <code>2</code> &lt; <code>3</code> &lt; <code>4</code> &lt; <code>5</code></p>
</dd>
<dt><code>Loops</code></dt><dd><p>Number of small loops, an ordered factor with levels <code>0</code> &lt; <code>1</code> &lt; <code>2</code> &lt; <code>3</code> &lt; <code>4</code> &lt; <code>5</code></p>
</dd>
<dt><code>count</code></dt><dd><p>Number of hands</p>
</dd>
</dl>



<h3>Details</h3>

<p>Cells for which <code>Whorls + Loops&gt;5</code> have <code>NA</code> for <code>count</code>
</p>


<h3>Source</h3>

<p>Stigler, S. M. (1999).
<em>Statistics on the Table</em>.
Cambridge, MA: Harvard University Press, table 19.4.
</p>


<h3>References</h3>

<p>Pearson, K. (1904).
Mathematical contributions to the theory of evolution. XIII.
On the theory of contingency and its relation to association and normal correlation.
Reprinted in <em>Karl Pearson's Early Statistical Papers</em>, Cambridge:
Cambridge University Press, 1948, 443-475.
</p>
<p>Waite, H. (1915).
The analysis of fingerprints, <em>Biometrika</em>, 10, 421-478.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Fingerprints)
xtabs(count ~ Whorls + Loops, data=Fingerprints)
</code></pre>

<hr>
<h2 id='Galton'>
Galton's data on the heights of parents and their children
</h2><span id='topic+Galton'></span>

<h3>Description</h3>

<p>Galton (1886) presented these data in a table, showing a cross-tabulation of
928 adult children born to 205 fathers and mothers, by their height and
their mid-parent's height.
He visually smoothed the bivariate frequency distribution and showed that the
contours formed concentric and similar ellipses, thus setting the stage for
correlation, regression and the bivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Galton)</code></pre>


<h3>Format</h3>

<p>A data frame with 928 observations on the following 2 variables.
</p>

<dl>
<dt><code>parent</code></dt><dd><p>a numeric vector: height of the mid-parent (average of father and mother)</p>
</dd>
<dt><code>child</code></dt><dd><p>a numeric vector: height of the child</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data are recorded in class intervals of width 1.0 in. He used non-integer
values for the center of each class interval because of the strong bias toward
integral inches.
</p>
<p>All of the heights of female children were multiplied by 1.08  before tabulation
to compensate for sex differences.  See Hanley (2004) for a reanalysis of
Galton's raw data questioning whether this was appropriate.
</p>


<h3>Source</h3>

<p>Galton, F. (1886). Regression Towards Mediocrity in Hereditary Stature
<em>Journal of the Anthropological Institute</em>, 15, 246-263
</p>


<h3>References</h3>

<p>Friendly, M. &amp; Denis, D. (2005). The early origins and development of the scatterplot. 
<em>Journal of the History of the Behavioral Sciences</em>, 
41, 103-130.
</p>
<p>Galton, F. (1869). <em>Hereditary Genius: An Inquiry into its Laws and Consequences</em>.
London: Macmillan.
</p>
<p>Hanley, J. A. (2004). &quot;Transmuting&quot; Women into Men: Galton's Family Data on Human Stature.
<em>The American Statistician</em>, 58, 237-243.
See: <a href="http://www.medicine.mcgill.ca/epidemiology/hanley/galton/">http://www.medicine.mcgill.ca/epidemiology/hanley/galton/</a> for source materials.
</p>
<p>Stigler, S. M. (1986). 
<em>The History of Statistics: The Measurement of Uncertainty before 1900</em>.
Cambridge, MA: Harvard University Press, Table 8.1
</p>
<p>Wachsmuth, A. W., Wilkinson L., Dallal G. E. (2003). 
Galton's bend: A previously undiscovered nonlinearity in Galton's family stature regression data. 
<em>The American Statistician</em>, 57, 190-192. 
<a href="https://www.cs.uic.edu/~wilkinson/Publications/galton.pdf">https://www.cs.uic.edu/~wilkinson/Publications/galton.pdf</a>
</p>


<h3>See Also</h3>

<p><code>link{GaltonFamilies}</code>,
<code><a href="#topic+PearsonLee">PearsonLee</a></code>,
<code>galton</code> in the <span class="pkg">psych</span> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Galton)

###########################################################################
# sunflower plot with regression line and data ellipses and lowess smooth
###########################################################################

with(Galton, 
	{
	sunflowerplot(parent,child, xlim=c(62,74), ylim=c(62,74))
	reg &lt;- lm(child ~ parent)
	abline(reg)
	lines(lowess(parent, child), col="blue", lwd=2)
	if(require(car)) {
	dataEllipse(parent,child, xlim=c(62,74), ylim=c(62,74), plot.points=FALSE)
		}
  })

</code></pre>

<hr>
<h2 id='GaltonFamilies'>
Galton's data on the heights of parents and their children, by child
</h2><span id='topic+GaltonFamilies'></span>

<h3>Description</h3>

<p>This data set lists the individual observations for 934 children in 205 families
on which Galton (1886) based his cross-tabulation. 
</p>
<p>In addition to the question of the relation between heights of parents and their offspring,
for which this data is mainly famous, Galton had another purpose which the
data in this form allows to address:
Does marriage selection indicate a relationship between the heights of husbands and
wives, a topic he called <em>assortative mating</em>?
Keen [p. 297-298](2010) provides a brief discussion of this topic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(GaltonFamilies)</code></pre>


<h3>Format</h3>

<p>A data frame with 934 observations on the following 8 variables.
</p>

<dl>
<dt><code>family</code></dt><dd><p>family ID, a factor with levels <code>001</code>-<code>204</code></p>
</dd>
<dt><code>father</code></dt><dd><p>height of father</p>
</dd>
<dt><code>mother</code></dt><dd><p>height of mother</p>
</dd>
<dt><code>midparentHeight</code></dt><dd><p>mid-parent height, calculated as <code>(father + 1.08*mother)/2</code></p>
</dd>
<dt><code>children</code></dt><dd><p>number of children in this family</p>
</dd>
<dt><code>childNum</code></dt><dd><p>number of this child within family. Children are listed in decreasing order
of height for boys followed by girls</p>
</dd>
<dt><code>gender</code></dt><dd><p>child gender, a factor with levels <code>female</code> <code>male</code></p>
</dd>
<dt><code>childHeight</code></dt><dd><p>height of child</p>
</dd>
</dl>



<h3>Details</h3>

<p>Galton's notebook lists 963 children in 205 families ranging from 1-15 adult children children.
Of these, 29 had non-numeric heights recorded and are not included here.
</p>
<p>Families are largely listed in descending order of fathers and mothers height.
</p>


<h3>Source</h3>

<p>Galton's notebook,
<a href="http://www.medicine.mcgill.ca/epidemiology/hanley/galton/notebook/">http://www.medicine.mcgill.ca/epidemiology/hanley/galton/notebook/</a>,
transcribed by Beverley Shipley in 2001.
</p>


<h3>References</h3>

<p>Galton, F. (1886). Regression Towards Mediocrity in Hereditary Stature
<em>Journal of the Anthropological Institute</em>, 15, 246-263
</p>
<p>Hanley, J. A. (2004). &quot;Transmuting&quot; Women into Men: Galton's Family Data on Human Stature.
<em>The American Statistician</em>, 58, 237-243.
See: <a href="http://www.medicine.mcgill.ca/epidemiology/hanley/galton/">http://www.medicine.mcgill.ca/epidemiology/hanley/galton/</a> for source materials.
</p>
<p>Keen, K. J. (2010). <em>Graphics for Statistics and Data Analysis with R</em>, 
Boca Raton: CRC Press,
<a href="https://www.unbc.ca/keen/graphics-for-statistics-and-data-analysis-with-r">https://www.unbc.ca/keen/graphics-for-statistics-and-data-analysis-with-r</a>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Galton">Galton</a></code>,
<code><a href="#topic+PearsonLee">PearsonLee</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(GaltonFamilies)
str(GaltonFamilies)

## reproduce Fig 2 in Hanley (2004)
library(car)
scatterplot(childHeight ~ midparentHeight | gender, data=GaltonFamilies, 
    ellipse=TRUE, levels=0.68, legend.coords=list(x=64, y=78))

# multiply daughters' heights by 1.08
GF1 &lt;- within(GaltonFamilies, 
              {childHeight &lt;- ifelse (gender=="female", 1.08*childHeight, childHeight)} )
scatterplot(childHeight ~ midparentHeight | gender, data=GF1, 
    ellipse=TRUE, levels=0.68, legend.coords=list(x=64, y=78))

# add 5.2 to daughters' heights 
GF2 &lt;- within(GaltonFamilies, 
              {childHeight &lt;- ifelse (gender=="female", childHeight+5.2, childHeight)} )
scatterplot(childHeight ~ midparentHeight | gender, data=GF2, 
    ellipse=TRUE, levels=0.68, legend.coords=list(x=64, y=78))

#########################################
# relationship between heights of parents
#########################################

Parents &lt;- subset(GaltonFamilies, !duplicated(GaltonFamilies$family))

with(Parents, {
  sunflowerplot(mother, father, rotate=TRUE, pch=16, 
     xlab="Mother height", ylab="Father height")
	dataEllipse(mother, father, add=TRUE, plot.points=FALSE, 
     center.pch=NULL, levels=0.68)
	abline(lm(father ~ mother), col="red", lwd=2)
	}
	)

</code></pre>

<hr>
<h2 id='Guerry'>
Data from A.-M. Guerry, &quot;Essay on the Moral Statistics of France&quot;
</h2><span id='topic+Guerry'></span>

<h3>Description</h3>

<p>Andre-Michel Guerry (1833) was the first to systematically collect and analyze
social data on such things as crime, literacy and suicide with the view
to determining social laws and the relations among these variables.
</p>
<p>The Guerry data frame comprises a collection of 'moral variables' on the 86
departments of France around 1830.  A few additional variables have been 
added from other sources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Guerry)</code></pre>


<h3>Format</h3>

<p>A data frame with 86 observations (the departments of France) on the following 23 variables.
</p>

<dl>
<dt><code>dept</code></dt><dd><p>Department ID: Standard numbers for the departments, except for Corsica (200)</p>
</dd>
<dt><code>Region</code></dt><dd><p>Region of France ('N'='North', 'S'='South', 'E'='East', 'W'='West', 'C'='Central'). Corsica is coded as NA </p>
</dd>
<dt><code>Department</code></dt><dd><p>Department name: Departments are named according to usage in 1830, but without accents.
A factor with levels <code>Ain</code> <code>Aisne</code> <code>Allier</code> ... <code>Vosges</code> <code>Yonne</code></p>
</dd>
<dt><code>Crime_pers</code></dt><dd><p>Population per Crime against persons. Source: A2 (Compte general, 1825-1830)</p>
</dd>
<dt><code>Crime_prop</code></dt><dd><p>Population per Crime against property. Source: A2 (Compte general, 1825-1830)</p>
</dd>
<dt><code>Literacy</code></dt><dd><p>Percent Read &amp; Write: Percent of military conscripts who can read and write. Source: A2 </p>
</dd>
<dt><code>Donations</code></dt><dd><p>Donations to the poor. Source: A2 (Bulletin des lois)</p>
</dd>
<dt><code>Infants</code></dt><dd><p>Population per illegitimate birth. Source: A2 (Bureau des Longitudes, 1817-1821)</p>
</dd>
<dt><code>Suicides</code></dt><dd><p>Population per suicide. Source: A2 (Compte general, 1827-1830)</p>
</dd>
<dt><code>MainCity</code></dt><dd><p>Size of principal city ('1:Sm', '2:Med', '3:Lg'), used as a surrogate for population density. Large refers to the top 10, small to the bottom 10; all the rest are classed Medium.
Source: A1. An ordered factor with levels <code>1:Sm</code> &lt; <code>2:Med</code> &lt; <code>3:Lg</code></p>
</dd>
<dt><code>Wealth</code></dt><dd><p>Per capita tax on personal property. A ranked index based on taxes on personal and movable property per inhabitant.
Source: A1</p>
</dd>
<dt><code>Commerce</code></dt><dd><p>Commerce and Industry, measured by the rank of the number of patents / population. Source: A1</p>
</dd>
<dt><code>Clergy</code></dt><dd><p>Distribution of clergy, measured by the rank of the number of Catholic priests in active service / population. Source: A1 (Almanach officiel du clergy, 1829)</p>
</dd>
<dt><code>Crime_parents</code></dt><dd><p>Crimes against parents, measured by the rank of the ratio of crimes against parents to all crimes&ndash; Average for the years 1825-1830. Source: A1 (Compte general) </p>
</dd>
<dt><code>Infanticide</code></dt><dd><p>Infanticides per capita. A ranked ratio of number of infanticides to population&ndash; Average for the years 1825-1830. Source: A1 (Compte general) </p>
</dd>
<dt><code>Donation_clergy</code></dt><dd><p>Donations to the clergy. A ranked ratio of the number of bequests and donations inter vivios to population&ndash; Average for the years 1815-1824. Source: A1 (Bull. des lois, ordunn. d'autorisation) </p>
</dd>
<dt><code>Lottery</code></dt><dd><p>Per capita wager on Royal Lottery. Ranked ratio of the proceeds bet on the royal lottery to population&mdash; Average for the years 1822-1826. Source: A1 (Compte rendus par le ministere des finances)</p>
</dd>
<dt><code>Desertion</code></dt><dd><p>Military desertion, ratio of the number of young soldiers accused of desertion to the force of the military contingent, minus the deficit produced by the insufficiency of available billets&ndash; Average of the years 1825-1827.
Source: A1 (Compte du ministere du guerre, 1829 etat V) </p>
</dd>
<dt><code>Instruction</code></dt><dd><p>Instruction. Ranks recorded from Guerry's map of Instruction. Note: this is inversely related to <code>Literacy</code> (as defined here)</p>
</dd>
<dt><code>Prostitutes</code></dt><dd><p>Prostitutes in Paris.
Number of prostitutes registered in Paris from 1816 to 1834, classified by the department of their birth
Source: Parent-Duchatelet (1836), <em>De la prostitution en Paris</em></p>
</dd>
<dt><code>Distance</code></dt><dd><p>Distance to Paris (km). Distance of each department centroid to the centroid of the Seine (Paris)
Source: calculated from department centroids </p>
</dd>
<dt><code>Area</code></dt><dd><p>Area (1000 km^2). Source: Angeville (1836) </p>
</dd>
<dt><code>Pop1831</code></dt><dd><p>1831 population. Population in 1831, taken from Angeville (1836), <em>Essai sur la Statistique de la Population fran?ais</em>, in 1000s </p>
</dd>
</dl>



<h3>Details</h3>

<p>Note that most of the variables (e.g., <code>Crime_pers</code>) are scaled so that 'more is better' morally.
</p>
<p>Values for the quantitative variables displayed on Guerry's maps were taken from Table A2 in the 
English translation of Guerry (1833) by Whitt and Reinking. 
Values for the ranked variables were taken from Table A1, with some corrections applied. 
The maximum is indicated by rank 1, and the minimum by rank 86.
</p>


<h3>Source</h3>

<p>Angeville, A. (1836). <em>Essai sur la Statistique de la Population fran?aise</em> Paris: F. Doufour.
</p>
<p>Guerry, A.-M. (1833). <em>Essai sur la statistique morale de la France</em> Paris: Crochard.
English translation: Hugh P. Whitt and Victor W. Reinking, Lewiston, N.Y. : Edwin Mellen Press, 2002.
</p>
<p>Parent-Duchatelet, A. (1836). <em>De la prostitution dans la ville de Paris</em>, 3rd ed, 1857,  p. 32, 36
</p>


<h3>References</h3>

<p>Dray, S. and Jombart, T. (2011). A Revisit Of Guerry's Data: Introducing
Spatial Constraints In Multivariate Analysis. 
<em>The Annals of Applied Statistics</em>,
Vol. 5, No. 4, 2278-2299. <a href="https://arxiv.org/pdf/1202.6485.pdf">https://arxiv.org/pdf/1202.6485.pdf</a>,
DOI: 10.1214/10-AOAS356.
</p>
<p>Brunsdon, C. and Dykes, J. (2007). 
Geographically weighted visualization: interactive graphics
for scale-varying exploratory analysis. 
Geographical Information Science Research Conference (GISRUK 07),
NUI Maynooth, Ireland, April, 2007.
</p>
<p>Friendly, M. (2007). A.-M. Guerry's Moral Statistics of France: Challenges for Multivariable Spatial Analysis.
<em>Statistical Science</em>, 22, 368-399.
</p>
<p>Friendly, M. (2007). Data from A.-M. Guerry, Essay on the Moral Statistics of France (1833),
<a href="http://datavis.ca/gallery/guerry/guerrydat.html">http://datavis.ca/gallery/guerry/guerrydat.html</a>.
</p>


<h3>See Also</h3>

<p>The <span class="pkg">Guerry</span> package for maps of France: <code><a href="Guerry.html#topic+gfrance">gfrance</a></code>
and related data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Guerry)
## maybe str(Guerry) ; plot(Guerry) ...
</code></pre>

<hr>
<h2 id='HalleyLifeTable'>
Halley's Life Table
</h2><span id='topic+HalleyLifeTable'></span>

<h3>Description</h3>

<p>In 1693 the famous English astronomer Edmond Halley studied
the birth and death records of the city of Breslau, which
had been transmitted to the Royal Society by Caspar Neumann.
He produced a life table showing the number of people
surviving to any age from a cohort born the same year. He
also used his table to compute the price of life annuities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("HalleyLifeTable")</code></pre>


<h3>Format</h3>

<p>A data frame with 84 observations on the following 4 variables.
</p>

<dl>
<dt><code>age</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>deaths</code></dt><dd><p>number of deaths, <code class="reqn">D_k</code>, among people of age k, a numeric vector</p>
</dd>
<dt><code>number</code></dt><dd><p>size of the population, <code class="reqn">P_k</code> surviving until this age, a numeric vector</p>
</dd>
<dt><code>ratio</code></dt><dd><p>the ratio <code class="reqn">P_{k+1}/P_k</code>, the conditional probability
of surviving until age k + 1 given that one had already reached age k, a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Halley's table contained only <code>age</code> and <code>number</code>.
For people aged over 84 years, Halley just noted that their total number was 107.
This value is not included in the data set.
</p>
<p>The data from Breslau had a mean of 1,238 births per year: this is the value that
Halley took for the size, <code class="reqn">P_0</code> of the population cohort at age 0. 
From the data, he could compute the annual mean
<code class="reqn">D_k</code> of the number of deaths among people aged <code class="reqn">k</code> for all <code class="reqn">k &gt;= 0</code>.
From this, he calculated the number <code class="reqn">P_{k+1}</code> surviving one more year,
</p>
<p style="text-align: center;"><code class="reqn">P_{k+1} = P_k - D_k</code>
</p>

<p>This method had the great advantage of not requiring a general census but only knowledge of the
number of births and deaths and of the age at which people died during a few years.
</p>


<h3>Source</h3>

<p>N. Bacaer (2011), &quot;Halley's life table (1693)&quot;, Ch 2, pp 5-10.
In <em>A Short History of Mathematical Population Dynamics</em>,
Springer-Verlag London,
DOI 10.1007/978-0-85729-115-8_2.  Data taken from Table 1.
</p>


<h3>References</h3>

<p>Halley, E. (1693). An estimate of the degrees of the mortality of mankind, drawn from
curious tables of the births and funerals at the city of Breslau; with an attempt
to ascertain the price of annuities upon lives. 
<em>Philosophical Transactions of the Royal Society, London</em>, 17,
596-610.
</p>
<p>The text of Halley's paper was found at
<a href="http://www.pierre-marteau.com/editions/1693-mortality.html">http://www.pierre-marteau.com/editions/1693-mortality.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Arbuthnot">Arbuthnot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HalleyLifeTable)
# what was the estimated population of Breslau?
sum(HalleyLifeTable$number)

# plot survival vs. age
plot(number ~ age, data=HalleyLifeTable, type="h", ylab="Number surviving")

# population pyramid is transpose of this
plot(age ~ number, data=HalleyLifeTable, type="l", xlab="Number surviving")
with(HalleyLifeTable, segments(0, age, number, age, lwd=2))

# conditional probability of survival, one more year
plot(ratio ~ age, data=HalleyLifeTable, ylab="Probability survive one more year")


</code></pre>

<hr>
<h2 id='Jevons'>
W. Stanley Jevons' data on numerical discrimination
</h2><span id='topic+Jevons'></span>

<h3>Description</h3>

<p>In a remarkable brief note in <em>Nature</em>, 1871, W. Stanley Jevons described the results of
an experiment he had conducted on himself to determine the limits of the
number of objects an observer could comprehend immediately without counting
them.  This was an important philosophical question: How many objects can the mind embrace at once?
</p>
<p>He carried out 1027 trials in which he tossed an &quot;uncertain number&quot; of
uniform black beans into a box and immediately attempted to estimate the number
&quot;without the least hesitation&quot;.  His questions, procedure and analysis anticipated 
by 75 years one of the most influential papers in modern cognitive psychology
by George Miller (1956), &quot;The magical number 7 plus or minus 2: Some limits on
...&quot; 
For Jevons, the magical number was 4.5, representing an empirical law of
complete accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Jevons)</code></pre>


<h3>Format</h3>

<p>A frequency data frame with 50 observations on the following 4 variables.
</p>

<dl>
<dt><code>actual</code></dt><dd><p>Actual number: a numeric vector</p>
</dd>
<dt><code>estimated</code></dt><dd><p>Estimated number: a numeric vector</p>
</dd>
<dt><code>frequency</code></dt><dd><p>Frequency of this combination of (actual, estimated): a numeric vector</p>
</dd>
<dt><code>error</code></dt><dd><p><code>actual</code>-<code>estimated</code>: a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The original data were presented in a two-way, 13 x 13 frequency table,
<code>estimated</code> (3:15) x <code>actual</code> (3:15).
</p>


<h3>Source</h3>

<p>Jevons, W. S. (1871).
The Power of Numerical Discrimination, <em>Nature</em>, 1871, III (281-282)
</p>


<h3>References</h3>

<p>Miller, G. A. (1956).
The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information,
<em>Psychological Review</em>, 63, 81-97, <a href="http://www.musanim.com/miller1956/">http://www.musanim.com/miller1956/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Jevons)
# show as tables
xtabs(frequency ~ estimated+actual, data=Jevons)
xtabs(frequency ~ error+actual, data=Jevons)

# show as sunflowerplot with regression line
with(Jevons, sunflowerplot(actual, estimated, frequency, 
  main="Jevons data on numerical estimation"))
Jmod &lt;-lm(estimated ~ actual, data=Jevons, weights=frequency)
abline(Jmod)

# show as balloonplots
if (require(gplots)) {

with(Jevons, balloonplot(actual, estimated, frequency, xlab="actual", ylab="estimated", 
  main="Jevons data on numerical estimation\nBubble area proportional to frequency",
  text.size=0.8))

with(Jevons, balloonplot(actual, error, frequency, xlab="actual", ylab="error", 
  main="Jevons data on numerical estimation: Errors\nBubble area proportional to frequency", 
  text.size=0.8))
}

# plot average error
if(require(reshape)) {
unJevons &lt;- untable(Jevons, Jevons$frequency)
str(unJevons)

require(plyr)
mean_error &lt;- function(df) mean(df$error, na.rm=TRUE)
Jmean &lt;- ddply(unJevons, .(actual), mean_error)
with(Jmean, plot(actual, V1, ylab='Mean error', xlab='Actual number', type='b', main='Jevons data'))
abline(h=0)
}

</code></pre>

<hr>
<h2 id='Langren'>
van Langren's Data on Longitude Distance between Toledo and Rome
</h2><span id='topic+Langren'></span><span id='topic+Langren1644'></span><span id='topic+Langren.all'></span>

<h3>Description</h3>

<p>Michael Florent van Langren (1598-1675) was a Dutch mathematician and astronomer, who served
as a royal mathematician to King Phillip IV of Spain, and who worked on one of the most significant
problems of his time&mdash; the accurate determination of longitude, particularly for navigation at sea.
</p>
<p>In order to convince the Spanish court of the seriousness of the problem (often resulting in
great losses through ship wrecks), he prepared a 1-dimensional line graph, showing all the 
available estimates of the distance in longitude between Toledo and Rome, which showed
large errors, for even this modest distance.  This 1D line graph, from Langren (1644), is believed
to be the first known graph of statistical data (Friendly etal., 2010).
It provides a compelling example of the notions of statistical variability and bias.
</p>
<p>The data frame <code>Langren1644</code> gives the estimates and other information derived from the
previously known 1644 graph.  
It turns out that van Langren produced other versions of this graph, as early as 1628.
The data frame <code>Langren.all</code> gives the estimates derived
from all known versions of this graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	data(Langren1644)
	data(Langren.all)
	</code></pre>


<h3>Format</h3>

<p><code>Langren1644</code>: A data frame with 12 observations on the following 9 variables,
giving determinations of the distance in longitude between Toledo and Rome, from the 1644 graph.
</p>

<dl>
<dt><code>Name</code></dt><dd><p>The name of the person giving a determination, a factor with levels <code>A. Argelius</code> ... <code>T. Brahe</code></p>
</dd>
<dt><code>Longitude</code></dt><dd><p>Estimated value of the longitude distance between Toledo and Rome</p>
</dd>
<dt><code>Year</code></dt><dd><p>Year associated with this determination</p>
</dd>
<dt><code>Longname</code></dt><dd><p>A longer version of the <code>Name</code>, where appropriate; a factor with levels <code>Andrea Argoli</code> <code>Christoph Clavius</code>  <code>Tycho Brahe</code></p>
</dd>
<dt><code>City</code></dt><dd><p>The principal city where this person worked; a factor with levels <code>Alexandria</code> <code>Amsterdam</code> <code>Bamberg</code> <code>Bologna</code> <code>Frankfurt</code> <code>Hven</code> <code>Leuven</code> <code>Middelburg</code> <code>Nuremberg</code> <code>Padua</code> <code>Paris</code> <code>Rome</code></p>
</dd>
<dt><code>Country</code></dt><dd><p>The country where this person worked; a factor with levels <code>Belgium</code> <code>Denmark</code> <code>Egypt</code> <code>Flanders</code> <code>France</code> <code>Germany</code> <code>Italy</code> <code>Italy </code></p>
</dd>
<dt><code>Latitude</code></dt><dd><p>Latitude of this <code>City</code>; a numeric vector</p>
</dd>
<dt><code>Source</code></dt><dd><p>Likely source for this determination of Longitude; a factor with levels <code>Astron</code> <code>Map</code></p>
</dd>
<dt><code>Gap</code></dt><dd><p>A numeric vector indicating whether the <code>Longitude</code> value is below or above the median</p>
</dd>
</dl>

<p><code>Langren.all</code>: A data frame with 61 observations on the following 4 variables,
giving determinations of Longitude between Toledo and Rome from all known versions of van Langren's graph.
</p>

<dl>
<dt><code>Author</code></dt><dd><p>Author of the graph, a factor with levels <code>Langren</code> <code>Lelewel</code></p>
</dd>
<dt><code>Year</code></dt><dd><p>Year of publication</p>
</dd>
<dt><code>Name</code></dt><dd><p>The name of the  person giving a determination,  a factor
with levels  <code>Algunos1</code> <code>Algunos2</code>  <code>Apianus</code> ... <code>Schonerus</code></p>
</dd>
<dt><code>Longitude</code></dt><dd><p>Estimated value of the longitude distance between Toledo and Rome</p>
</dd>
</dl>



<h3>Details</h3>

<p>In all the graphs, Toledo is implicitly at the origin and Rome is located relatively at the value of <code>Longitude</code>  
To judge correspondence with an actual map, the positions in (lat, long) are
</p>
<p><code>
	toledo &lt;- c(39.86, -4.03);
	rome   &lt;- c(41.89, 12.5)
</code>
</p>


<h3>Source</h3>

<p>The longitude values were digitized from images of the various graphs, which may be
found on the Supplementary materials page for Friendly etal. (2009).
</p>


<h3>References</h3>

<p>Friendly, M., Valero-Mora, P. and Ulargui, J. I. (2010).
The First (Known) Statistical Graph: Michael Florent van Langren and the &quot;Secret&quot; of Longitude.
<em>The American Statistician</em>, <b>64</b> (2), 185-191. 
Supplementary materials: <a href="http://datavis.ca/gallery/langren/">http://datavis.ca/gallery/langren/</a>. 
</p>
<p>Langren, M. F. van. (1644).  <em>La Verdadera Longitud por Mar y Tierra</em>. Antwerp: (n.p.), 1644.
English translation available at <a href="http://datavis.ca/gallery/langren/verdadera.pdf">http://datavis.ca/gallery/langren/verdadera.pdf</a>.
</p>
<p>Lelewel, J. (1851). <em>Geographie du Moyen Age</em>. Paris: Pilliet, 1851.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Langren1644)

####################################################
# reproductions of Langren's graph overlaid on a map
####################################################

if (require(jpeg, quietly=TRUE)) {

  gimage &lt;- readJPEG(system.file("images", "google-toledo-rome3.jpg", package="HistData"))
  # NB: dimensions from readJPEG are y, x, colors

  gdim &lt;- dim(gimage)[1:2]
  ylim &lt;- c(1,gdim[1])
  xlim &lt;- c(1,gdim[2])
  op &lt;- par(bty="n", xaxt="n", yaxt="n", mar=c(2, 1, 1, 1) + 0.1)
  # NB: necessary to scale the plot to the pixel coordinates, and use asp=1
  plot(xlim, ylim, xlim=xlim, ylim=ylim, type="n", ann=FALSE, asp=1 )
  rasterImage(gimage, 1, 1, gdim[2], gdim[1])

  # pixel coordinates of Toledo and Rome in the image, measured from the bottom left corner
  toledo.map &lt;- c(131, 59)
  rome.map &lt;- c(506, 119)
  
  # confirm locations of Toledo and Rome
  points(rbind(toledo.map, rome.map), cex=2)
  text(131, 95, "Toledo", cex=1.5)
  text(506, 104, "Roma", cex=1.5)

  # set a scale for translation of lat,long to pixel x,y
  scale &lt;- data.frame(x=c(131, 856), y=c(52,52))
  rownames(scale)=c(0,30)

  # translate from degrees longitude to pixels
  xlate &lt;- function(x) {
    131+x*726/30	
  }

  # draw an axis
  lines(scale)
  ticks &lt;- xlate(seq(0,30,5))
  segments(ticks, 52, ticks, 45)
  text(ticks, 40, seq(0,30,5))
  text(xlate(8), 17, "Grados de la Longitud", cex=1.7)

  # label the observations with the names
  points(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), 
         pch=25, col="blue", bg="blue")
  text(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), 
       labels=Langren1644$Name, srt=90, adj=c(-.1, .5), cex=0.8)
  par(op)
}

### Original implementation using ReadImages, now deprecated &amp; shortly to be removed
## Not run: 
if (require(ReadImages)) {
  gimage &lt;- read.jpeg(system.file("images", "google-toledo-rome3.jpg", package="HistData"))
  plot(gimage)
  
  # pixel coordinates of Toledo and Rome in the image, measured from the bottom left corner
  toledo.map &lt;- c(130, 59)
  rome.map &lt;- c(505, 119)
  
  # confirm locations of Toledo and Rome
  points(rbind(toledo.map, rome.map), cex=2)
  
  # set a scale for translation of lat,long to pixel x,y
  scale &lt;- data.frame(x=c(130, 856), y=c(52,52))
  rownames(scale)=c(0,30)
  lines(scale)
  
  xlate &lt;- function(x) {
    130+x*726/30	
  }
  points(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), 
         pch=25, col="blue")
  text(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), 
         labels=Langren1644$Name, srt=90, adj=c(0, 0.5), cex=0.8)
}

## End(Not run)

### First attempt using ggplot2; temporarily abandonned.
## Not run: 
require(maps)
require(ggplot2)
require(reshape)
require(plyr)
require(scales)

# set latitude to that of Toledo
Langren1644$Latitude &lt;- 39.68

#          x/long   y/lat
bbox &lt;- c( 38.186, -9.184,
           43.692, 28.674 )
bbox &lt;- matrix(bbox, 2, 2, byrow=TRUE)

borders &lt;- as.data.frame(map("world", plot = FALSE,
  xlim = expand_range(bbox[,2], 0.2),
  ylim = expand_range(bbox[,1], 0.2))[c("x", "y")])

data(world.cities)
# get actual locations of Toledo &amp; Rome
cities &lt;- subset(world.cities,
  name %in% c("Rome", "Toledo") &amp; country.etc %in% c("Spain", "Italy"))
colnames(cities)[4:5]&lt;-c("Latitude", "Longitude")

mplot &lt;- ggplot(Langren1644, aes(Longitude, Latitude) ) +
  geom_path(aes(x, y), borders, colour = "grey60") +
  geom_point(y = 40) +
  geom_text(aes(label = Name), y = 40.1, angle = 90, hjust = 0, size = 3)
mplot &lt;- mplot +
	geom_segment(aes(x=-4.03, y=40, xend=30, yend=40))

mplot &lt;- mplot +
  geom_point(data = cities, colour = "red", size = 2) +
  geom_text(data=cities, aes(label=name), color="red", size=3, vjust=-0.5) +
  coord_cartesian(xlim=bbox[,2], ylim=bbox[,1])

# make the plot have approximately aspect ratio = 1
windows(width=10, height=2)
mplot

## End(Not run)


###########################################
# show variation in estimates across graphs
###########################################

library(lattice)
graph &lt;- paste(Langren.all$Author, Langren.all$Year)
dotplot(Name ~ Longitude, data=Langren.all)

dotplot( as.factor(Year) ~ Longitude, data=Langren.all, groups=Name, type="o")

dotplot(Name ~ Longitude|graph, data=Langren.all, groups=graph)

# why the gap?
gap.mod &lt;- glm(Gap ~ Year + Source + Latitude, family=binomial, data=Langren1644)
anova(gap.mod, test="Chisq")


</code></pre>

<hr>
<h2 id='Macdonell'>
Macdonell's Data on Height and Finger Length of Criminals, used by Gosset (1908)
</h2><span id='topic+Macdonell'></span><span id='topic+MacdonellDF'></span>

<h3>Description</h3>

<p>In the second issue of <em>Biometrika</em>, W. R. Macdonell (1902) published an extensive
paper, <em>On Criminal Anthropometry and the Identification of Criminals</em>
in which he included numerous tables of physical characteristics 3000 non-habitual 
male criminals serving their sentences in England and Wales.  His Table III (p. 216)
recorded a bivariate frequency distribution of <code>height</code> by <code>finger</code> length.
His main purpose was to show that Scotland Yard 
could have indexed their material more efficiently, and find a given profile more quickly. 
</p>
<p>W. S. Gosset (aka &quot;Student&quot;) used these data in two classic papers in 1908,
in which he derived various
characteristics of the sampling distributions of the mean, standard deviation and
Pearson's r. He said, &quot;Before I had succeeded in solving my problem analytically, I
had endeavoured to do so empirically.&quot;  Among his experiments, he randomly shuffled
the 3000 observations from Macdonell's table, and then grouped them into samples
of size 4, 8, ..., calculating the sample means, standard deviations and correlations
for each sample. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Macdonell)
data(MacdonellDF)
</code></pre>


<h3>Format</h3>

<p><code>Macdonell</code>: A frequency data frame with 924 observations on the following 3 variables giving
the bivariate frequency distribution of <code>height</code> and <code>finger</code>.
</p>

<dl>
<dt><code>height</code></dt><dd><p>lower class boundaries of height, in decimal ft.</p>
</dd>
<dt><code>finger</code></dt><dd><p>length of the left middle finger, in mm.</p>
</dd>
<dt><code>frequency</code></dt><dd><p>frequency of this combination of <code>height</code> and <code>finger</code></p>
</dd>
</dl>

<p><code>MacdonellDF</code>: A data frame with 3000 observations on the following 2 variables.
</p>

<dl>
<dt><code>height</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>finger</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Class intervals for <code>height</code> in Macdonell's table were given in 1 in.
ranges, from (4' 7&quot; 9/16 - 4' 8&quot; 9/16), to (6' 4&quot; 9/16 - 6' 5&quot; 9/16).
The values of <code>height</code> are taken as the lower class boundaries.
</p>
<p>For convenience, the data frame <code>MacdonellDF</code> presents the same data, in expanded form, with
each combination of <code>height</code> and <code>finger</code> replicated <code>frequency</code> times.
</p>


<h3>Source</h3>

<p>Macdonell, W. R. (1902).
On Criminal Anthropometry and the Identification of Criminals.
<em>Biometrika</em>, 1(2), 177-227. 
<a href="https://doi.org/10.1093/biomet/1.2.177">doi:10.1093/biomet/1.2.177</a>
</p>
<p>The data used here were obtained from:
</p>
<p>Hanley, J. (2008).
Macdonell data used by Student.
<a href="http://www.medicine.mcgill.ca/epidemiology/hanley/Student/">http://www.medicine.mcgill.ca/epidemiology/hanley/Student/</a>
</p>


<h3>References</h3>

<p>Hanley, J. and Julien, M. and Moodie, E. (2008).
Student's z, t, and s: What if Gosset had R?
<em>The American Statistician</em>, 62(1), 64-69.
</p>
<p>Gosset, W. S. [Student] (1908).
Probable error of a mean.
<em>Biometrika</em>, 6(1), 1-25.
<a href="https://www.york.ac.uk/depts/maths/histstat/student.pdf">https://www.york.ac.uk/depts/maths/histstat/student.pdf</a>
</p>
<p>Gosset, W. S. [Student] (1908).
Probable error of a correlation coefficient.
<em>Biometrika</em>, 6, 302-310.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Macdonell)

# display the frequency table
xtabs(frequency ~ finger+round(height,3), data=Macdonell)

## Some examples by james.hanley@mcgill.ca    October 16, 2011
## http://www.biostat.mcgill.ca/hanley/
## See:  http://www.biostat.mcgill.ca/hanley/Student/

###############################################
##  naive contour plots of height and finger ##
###############################################
 
# make a 22 x 42 table
attach(Macdonell)
ht &lt;- unique(height) 
fi &lt;- unique(finger)
fr &lt;- t(matrix(frequency, nrow=42))
detach(Macdonell)


dev.new(width=10, height=5)  # make plot double wide
op &lt;- par(mfrow=c(1,2),mar=c(0.5,0.5,0.5,0.5),oma=c(2,2,0,0))

dx &lt;- 0.5/12
dy &lt;- 0.5/12

plot(ht,ht,xlim=c(min(ht)-dx,max(ht)+dx),
           ylim=c(min(fi)-dy,max(fi)+dy), xlab="", ylab="", type="n" )

# unpack  3000 heights while looping though the frequencies 
heights &lt;- c()
for(i in 1:22) {
	for (j in 1:42) {
	 f  &lt;-  fr[i,j]
	 if(f&gt;0) heights &lt;- c(heights,rep(ht[i],f))
	 if(f&gt;0) text(ht[i], fi[j], toString(f), cex=0.4, col="grey40" ) 
	}
}
text(4.65,13.5, "Finger length (cm)",adj=c(0,1), col="black") ;
text(5.75,9.5, "Height (feet)", adj=c(0,1), col="black") ;
text(6.1,11, "Observed bin\nfrequencies", adj=c(0.5,1), col="grey40",cex=0.85) ;
# crude countour plot
contour(ht, fi, fr, add=TRUE, drawlabels=FALSE, col="grey60")


# smoother contour plot (Galton smoothed 2-D frequencies this way)
# [Galton had experience with plotting isobars for meteorological data]
# it was the smoothed plot that made him remember his 'conic sections'
# and ask a mathematician to work out for him the iso-density
# contours of a bivariate Gaussian distribution... 

dx &lt;- 0.5/12; dy &lt;- 0.05  ; # shifts caused by averaging

plot(ht,ht,xlim=c(min(ht),max(ht)),ylim=c(min(fi),max(fi)), xlab="", ylab="", type="n"  )
 
sm.fr &lt;- matrix(rep(0,21*41),nrow &lt;- 21)
for(i in 1:21) {
	for (j in 1:41) {
	   smooth.freq  &lt;-  (1/4) * sum( fr[i:(i+1), j:(j+1)] ) 
	   sm.fr[i,j]  &lt;-  smooth.freq
	   if(smooth.freq &gt; 0 )
	   text(ht[i]+dx, fi[j]+dy, sub("^0.", ".",toString(smooth.freq)), cex=0.4, col="grey40" )
	   }
	}
 
contour(ht[1:21]+dx, fi[1:41]+dy, sm.fr, add=TRUE, drawlabels=FALSE, col="grey60")
text(6.05,11, "Smoothed bin\nfrequencies", adj=c(0.5,1), col="grey40", cex=0.85) ;
par(op)
dev.new()    # new default device

#######################################
## bivariate kernel density estimate
#######################################

if(require(KernSmooth)) {
MDest &lt;- bkde2D(MacdonellDF, bandwidth=c(1/8, 1/8))
contour(x=MDest$x1, y=MDest$x2, z=MDest$fhat,
	xlab="Height (feet)", ylab="Finger length (cm)", col="red", lwd=2)
with(MacdonellDF, points(jitter(height), jitter(finger), cex=0.5))
}

#############################################################
## sunflower plot of height and finger with data ellipses  ##
#############################################################

with(MacdonellDF, 
	{
	sunflowerplot(height, finger, size=1/12, seg.col="green3",
		xlab="Height (feet)", ylab="Finger length (cm)")
	reg &lt;- lm(finger ~ height)
	abline(reg, lwd=2)
	if(require(car)) {
	dataEllipse(height, finger, plot.points=FALSE, levels=c(.40, .68, .95))
		}
  })


############################################################
## Sampling distributions of sample sd (s) and z=(ybar-mu)/s
############################################################

# note that Gosset used a divisor of n (not n-1) to get the sd.
# He also used Sheppard's correction for the 'binning' or grouping.
# with concatenated height measurements...

mu &lt;- mean(heights) ; sigma &lt;- sqrt( 3000 * var(heights)/2999 )
c(mu,sigma)

# 750 samples of size n=4 (as Gosset did)

# see Student's z, t, and s: What if Gosset had R? 
# [Hanley J, Julien M, and Moodie E. The American Statistician, February 2008] 

# see also the photographs from Student's notebook ('Original small sample data and notes")
# under the link "Gosset' 750 samples of size n=4" 
# on website http://www.biostat.mcgill.ca/hanley/Student/
# and while there, look at the cover of the Notebook containing his yeast-cell counts
# http://www.medicine.mcgill.ca/epidemiology/hanley/Student/750samplesOf4/Covers.JPG
# (Biometrika 1907) and decide for yourself why Gosset, when forced to write under a 
# pen-name, might have taken the name he did!

# PS: Can you figure out what the 750 pairs of numbers signify?
# hint: look again at the numbers of rows and columns in Macdonell's (frequency) Table III.


n &lt;- 4
Nsamples &lt;- 750

y.bar.values &lt;- s.over.sigma.values &lt;- z.values &lt;- c()
for (samp in 1:Nsamples) {
	y &lt;- sample(heights,n)
	y.bar &lt;- mean(y)
	s  &lt;-  sqrt( (n/(n-1))*var(y) ) 
	z &lt;- (y.bar-mu)/s
	y.bar.values &lt;- c(y.bar.values,y.bar) 
	s.over.sigma.values &lt;- c(s.over.sigma.values,s/sigma)
	z.values &lt;- c(z.values,z)
	}

	
op &lt;- par(mfrow=c(2,2),mar=c(2.5,2.5,2.5,2.5),oma=c(2,2,0,0))
# sampling distributions
hist(heights,breaks=seq(4.5,6.5,1/12), main="Histogram of heights (N=3000)")
hist(y.bar.values, main=paste("Histogram of y.bar (n=",n,")",sep=""))

hist(s.over.sigma.values,breaks=seq(0,4,0.1),
	main=paste("Histogram of s/sigma (n=",n,")",sep="")); 
z=seq(-5,5,0.25)+0.125
hist(z.values,breaks=z-0.125, main="Histogram of z=(ybar-mu)/s")
# theoretical
lines(z, 750*0.25*sqrt(n-1)*dt(sqrt(n-1)*z,3), col="red", lwd=1)
par(op)

#####################################################
## Chisquare probability plot for bivariate normality
#####################################################

mu &lt;- colMeans(MacdonellDF)
sigma &lt;- var(MacdonellDF)
Dsq &lt;- mahalanobis(MacdonellDF, mu, sigma)

Q &lt;- qchisq(1:3000/3000, 2)
plot(Q, sort(Dsq), xlab="Chisquare (2) quantile", ylab="Squared distance")
abline(a=0, b=1, col="red", lwd=2)



</code></pre>

<hr>
<h2 id='Mayer'>
Mayer's Data on the Libration of the Moon.
</h2><span id='topic+Mayer'></span>

<h3>Description</h3>

<p>Mayer had twenty-seven days' observations of Manilius and only three unknowns.
The form of Mayer's problem is almost the same as that of Legendre, who
developed later the least squares method.
</p>
<p>&quot;How did Mayer address his overdetermined system of equations? His approach was
a simple and straightforward one, so simple and straightforward that a
twentieth-century reader might arrive at the very mistaken opinion that the
procedure was not remarkable at all. Mayer divided his equations into three
groups of nine equations each, added each of the three groups separately, and
solved the resulting three linear equations for <code class="reqn">\alpha</code>, <code class="reqn">\beta</code> and
<code class="reqn">\alpha sin\theta</code> (and then solved for <code class="reqn">\theta</code>). His choice of which
equations belonged in which groups was based upon the coefficients of
<code class="reqn">\alpha</code> and <code class="reqn">\alpha sin \theta</code>.
The first group consisted of the nine equations with the largest positive
values for the coefficient of a, namely, equations 1,2, 3, 6, 9, 10, 11,12,
and 27. The second group were those with the nine largest negative values
for this coefficient: equations 8, 18, 19, 21, 22, 23, 24, 25, and 26. The
remaining nine equations formed the third group, which he described as
having the largest values for the coefficient of <code class="reqn">\alpha sin \theta</code>.&quot;
</p>
<p>Stigler (1986, p.21)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Mayer)</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 4 variables.
</p>

<dl>
<dt><code>Equation</code></dt><dd><p>an integer vector, id of the Equation</p>
</dd>
<dt><code>Y</code></dt><dd><p>a numeric vector, representing the term <code class="reqn">(h-90)</code> (see details)</p>
</dd>
<dt><code>X1</code></dt><dd><p>a numeric vector, representing <code class="reqn">\beta</code></p>
</dd>
<dt><code>X2</code></dt><dd><p>a numeric vector, representing <code class="reqn">\alpha</code></p>
</dd>
<dt><code>X3</code></dt><dd><p>a numeric vector, representing the term <code class="reqn">\alpha sin\theta</code></p>
</dd>
<dt><code>Group</code></dt><dd><p>a character vector, representing the Mayer grouping</p>
</dd>
</dl>



<h3>Details</h3>

<p>Stigler (1986):
</p>
<p>&quot;The development of the method of least squares was closely associated with three
of the major scientific problems of the eighteenth century: (1) to determine and
represent mathematically the motions of the moon; (2) to account for an
apparently secular (that is, nonperiodic) inequality that had been observed in
the motions of the planets Jupiter and Saturn; and (3) to determine the shape or
figure of the earth. These problems all involved astronomical observations and
the theory of gravitational attraction, and they all presented intellectual
challenges that engaged the attention of many of the ablest mathematical
scientists of the period.
</p>
<p>Over the period from April 1748 to March 1749, Mayer made numerous observations
of the positions of several prominent lunar features; and in his 1750 memoir he
showed how these data could be used to determine various characteristics of the
moon's orbit. His method of handling the data was novel, and it is well worth
considering this method in detail, both for the light it sheds on his
pioneering, if limited, understanding of the problem and because his approach
was widely circulated in the major contemporary treatise on astronomy, having
signal influence upon later work.&quot;
</p>
<p>His analysis led to this equation:
</p>
<p style="text-align: center;"><code class="reqn">\beta - (90-h) = \alpha sin(g-k) - \alpha sin\theta cos(g-k)</code>
</p>

<p>According to Stigler (1986, p. 21), this &quot;equation would hold if no errors were
present. The modern tendency would be to write, say&quot;:
</p>
<p style="text-align: center;"><code class="reqn">(h - 90) = - \beta + \alpha sin (g - k) - \alpha sin\theta cos(g - k) + E</code>
</p>

<p>treating <code class="reqn">(h - 90)</code> as the dependent variable and  <code class="reqn">-\beta</code>, <code class="reqn">\alpha</code>,
and <code class="reqn">-\alpha sin \theta</code> as the parameters in a linear regression model.
</p>


<h3>Author(s)</h3>

<p>Luiz Fernando Palin Droubi</p>


<h3>Source</h3>

<p>Stigler, Stephen M. (1986).
<em>The History of Statistics: The Measurement of Uncertainty before 1900</em>.
Cambridge, MA: Harvard University Press, 1986, Table 1.1, p. 22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sp)
library(effects)
data(Mayer)

# some scatterplots
plot(Y ~ X2, pch=(15:17)[as.factor(Group)], 
             col=c("red", "blue", "darkgreen")[as.factor(Group)], data=Mayer)
abline(lm(Y ~ X2, data=Mayer), lwd=2)

plot(Y ~ X3, pch=(15:17)[as.factor(Group)], 
             col=c("red", "blue", "darkgreen")[as.factor(Group)], data=Mayer)
abline(lm(Y ~ X3, data=Mayer), lwd=2)


fit &lt;- lm(Y ~ X2 + X3, data=Mayer)
plot(predictorEffects(fit, residuals=TRUE))


Avg_Method &lt;- aggregate(Mayer[, 2:5], by = list(Group = Mayer$Group), FUN=sum)
fit_Mayer &lt;- lm(Y ~ X1 + X2 + X3 - 1, Avg_Method)

## See Stigler (1986, p. 23)
## W means that the angle found is negative.

coeffs &lt;- coef(fit_Mayer)
(alpha &lt;- dd2dms(coeffs[2]))
(beta &lt;- dd2dms(coeffs[1]))
(theta &lt;- dd2dms(asin(coeffs[3]/coeffs[2])*180/pi))
</code></pre>

<hr>
<h2 id='Michelson'>
Michelson's Determinations of the Velocity of Light
</h2><span id='topic+Michelson'></span><span id='topic+MichelsonSets'></span>

<h3>Description</h3>

<p>The data frame <code>Michelson</code> gives Albert Michelson's measurements of the velocity of light in air, 
made from June 5 to July 2, 1879, reported in Michelson (1882). 
The given values + 299,000 are Michelson's measurements in km/sec. 
The number of cases is 100 and the &quot;true&quot; value on this scale is 734.5.
</p>
<p>Stigler (1977) used these data to illustrate properties of robust estimators
with real, historical data.  For this purpose, he divided the 100 measurements
into 5 sets of 20 each.  These are contained in  <code>MichelsonSets</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Michelson)
data(MichelsonSets)
</code></pre>


<h3>Format</h3>

<p><code>Michelson</code>: A data frame with 100 observations on the following variable, given in time order of
data collection
</p>

<dl>
<dt><code>velocity</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>

<p><code>MichelsonSets</code>: A 20 x 5 matrix, with format 
int [1:20, 1:5] 850 850 1000 810 960 800 830 830 880 720 ...
- attr(*, &quot;dimnames&quot;)=List of 2
..$ : NULL
..$ : chr [1:5] &quot;ds12&quot; &quot;ds13&quot; &quot;ds14&quot; &quot;ds15&quot; ...
</p>


<h3>Details</h3>

<p>The &quot;true&quot; value is taken to be 734.5, arrived at by taking the &quot;true&quot; speed of light
in a vacuum to be 299,792.5 km/sec, and adjusting for the velocity in air.
</p>
<p>The data values are recorded in order, and so may also be taken as a time series.
</p>


<h3>Source</h3>

<p>Kyle Siegrist, &quot;Virtual Laboratories in Probability and Statistics&quot;, <a href="http://www.math.uah.edu/stat/data/Michelson.html">http://www.math.uah.edu/stat/data/Michelson.html</a>
</p>
<p>Stephen M. Stigler (1977), &quot;Do robust estimators work with <em>real</em> data?&quot;, <em>Annals of Statistics</em>,  5, 1055-1098
</p>


<h3>References</h3>

<p>Michelson, A. A. (1882). &quot;Experimental determination of the velocity of light made at the
United States Naval Academy, Anapolis&quot;. <em>Astronomical Papers</em>, 1,109-145,
U. S. Nautical Almanac Office.
</p>


<h3>See Also</h3>

<p><code><a href="datasets.html#topic+morley">morley</a></code> for these data in another format
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Michelson)

# density plot (default bandwidth &amp; 0.6 * bw)
plot(density(Michelson$velocity), xlab="Speed of light - 299000 (km/s)",
	main="Density plots of Michelson data")
lines(density(Michelson$velocity, adjust=0.6), lty=2)
rug(jitter(Michelson$velocity))
abline(v=mean(Michelson$velocity), col="blue")
abline(v=734.5, col="red", lwd=2)
text(mean(Michelson$velocity), .004, "mean", srt=90, pos=2)
text(734.5, .004, "true", srt=90, pos=2)

# index / time series plot
plot(Michelson$velocity, type="b")
abline(h=734.5, col="red", lwd=2)
lines(lowess(Michelson$velocity), col="blue", lwd=2)

# examine lag=1 differences
plot(diff(Michelson$velocity), type="b")
lines(lowess(diff(Michelson$velocity)), col="blue", lwd=2)

# examine different data sets
boxplot(MichelsonSets, ylab="Velocity of light - 299000 (km/s)", xlab="Data set")
abline(h=734.5, col="red", lwd=2)

# means and trimmed means
(mn &lt;-apply(MichelsonSets, 2, mean))
(tm &lt;- apply(MichelsonSets, 2, mean, trim=.1))
points(1:5, mn)
points(1:5+.05, tm, pch=16, col="blue")

</code></pre>

<hr>
<h2 id='Minard'>
Data from Minard's famous graphic map of Napoleon's march on Moscow
</h2><span id='topic+Minard'></span><span id='topic+Minard.cities'></span><span id='topic+Minard.troops'></span><span id='topic+Minard.temp'></span>

<h3>Description</h3>

<p>Charles Joseph Minard's graphic depiction of the fate of Napoleon's Grand
Army in the Russian campaign of 1815 has been called the &quot;greatest statistical graphic
ever drawn&quot; (Tufte, 1983).   Friendly (2002) describes some background
for this graphic, and presented it as Minard's Challenge: to reproduce it using
modern statistical or graphic software, in a way that showed the elegance of
some computer language to both describe and produce this graphic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Minard.troops)
data(Minard.cities)
data(Minard.temp)
</code></pre>


<h3>Format</h3>

<p><code>Minard.troops</code>: A data frame with 51 observations on the following 5 variables giving the number
of surviving troops.
</p>

<dl>
<dt><code>long</code></dt><dd><p>Longitude</p>
</dd>
<dt><code>lat</code></dt><dd><p>Latitude</p>
</dd>
<dt><code>survivors</code></dt><dd><p>Number of surviving troops, a numeric vector</p>
</dd>
<dt><code>direction</code></dt><dd><p>a factor with levels <code>A</code> (&quot;Advance&quot;) <code>R</code> (&quot;Retreat&quot;)</p>
</dd>
<dt><code>group</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>

<p><code>Minard.cities</code>: A data frame with 20 observations on the following 3 variables giving the locations of
various places along the path of Napoleon's army.
</p>

<dl>
<dt><code>long</code></dt><dd><p>Longitude</p>
</dd>
<dt><code>lat</code></dt><dd><p>Latitude</p>
</dd>
<dt><code>city</code></dt><dd><p>City name: a factor with levels <code>Bobr</code> <code>Chjat</code>  ... <code>Witebsk</code> <code>Wixma</code></p>
</dd>
</dl>

<p><code>Minard.temp</code>: A data frame with 9 observations on the following 4 variables, giving the temperature
at various places along the march of retreat from Moscow.
</p>

<dl>
<dt><code>long</code></dt><dd><p>Longitude</p>
</dd>
<dt><code>temp</code></dt><dd><p>Temperature</p>
</dd>
<dt><code>days</code></dt><dd><p>Number of days on the retreat march</p>
</dd>
<dt><code>date</code></dt><dd><p>a factor with levels <code>Dec01</code> <code>Dec06</code> <code>Dec07</code> <code>Nov09</code> <code>Nov14</code> <code>Nov28</code> <code>Oct18</code> <code>Oct24</code></p>
</dd>
</dl>



<h3>Details</h3>

<p><code>date</code> in <code>Minard.temp</code> should be made a real date in 1815.
</p>


<h3>Source</h3>

<p><a href="https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/minard.txt">https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/minard.txt</a>
</p>


<h3>References</h3>

<p>Friendly, M. (2002). 
Visions and Re-visions of Charles Joseph Minard,
<em>Journal of Educational and Behavioral Statistics</em>, 27, No. 1, 31-51.
</p>
<p>Friendly, M. (2003). Re-Visions of Minard.
<a href="http://datavis.ca/gallery/re-minard.html">http://datavis.ca/gallery/re-minard.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Minard.troops)
data(Minard.cities)
data(Minard.temp)

## Not run: 
#' ## Load required packages
require(ggplot2)
require(scales)
require(gridExtra)

#' ## plot path of troops, and another layer for city names
 plot_troops &lt;- ggplot(Minard.troops, aes(long, lat)) +
		geom_path(aes(size = survivors, colour = direction, group = group),
                 lineend = "round", linejoin = "round")
 plot_cities &lt;- geom_text(aes(label = city), size = 4, data = Minard.cities)
 
#' ## Combine these, and add scale information, labels, etc.
#' Set the x-axis limits for longitude explicitly, to coincide with those for temperature

breaks &lt;- c(1, 2, 3) * 10^5 
plot_minard &lt;- plot_troops + plot_cities +
 	scale_size("Survivors", range = c(1, 10), 
 	            breaks = breaks, labels = scales::comma(breaks)) +
  scale_color_manual("Direction", 
                     values = c("grey50", "red"), 
                     labels=c("Advance", "Retreat")) +
  coord_cartesian(xlim = c(24, 38)) +
  xlab(NULL) + 
  ylab("Latitude") + 
  ggtitle("Napoleon's March on Moscow") +
  theme_bw() +
  theme(legend.position=c(.8, .2), legend.box="horizontal")
 
#' ## plot temperature vs. longitude, with labels for dates
plot_temp &lt;- ggplot(Minard.temp, aes(long, temp)) +
	geom_path(color="grey", size=1.5) +
	geom_point(size=2) +
	geom_text(aes(label=date)) +
	xlab("Longitude") + ylab("Temperature") +
	coord_cartesian(xlim = c(24, 38)) + 
	theme_bw()
	

#' The plot works best if we  re-scale the plot window to an aspect ratio of ~ 2 x 1
# windows(width=10, height=5)

#' Combine the two plots into one
grid.arrange(plot_minard, plot_temp, nrow=2, heights=c(3,1))


## End(Not run)
</code></pre>

<hr>
<h2 id='Nightingale'>
Florence Nightingale's data on deaths from various causes in the Crimean War
</h2><span id='topic+Nightingale'></span>

<h3>Description</h3>

<p>In the history of data visualization, Florence Nightingale is best remembered 
for her role as a social activist and her view that statistical data,  presented in
charts and diagrams, could be used as powerful arguments for medical reform. 
</p>
<p>After witnessing deplorable sanitary conditions  in the Crimea, she wrote  
several influential texts (Nightingale, 1858, 1859), including polar-area
graphs (sometimes called &quot;Coxcombs&quot; or rose diagrams), showing the number of deaths in the
Crimean from battle compared to disease or preventable causes that could be reduced by
better battlefield nursing care.  
</p>
<p>Her <em>Diagram of the Causes of Mortality in the Army in the East</em>
showed that  most of the  British soldiers who  died  during the  Crimean War
died of sickness rather than of wounds  or other causes.
It also  showed that  the death  rate was  higher in  the first  year of the war,
before a Sanitary Commissioners arrived in March 1855 to improve hygiene in the camps and hospitals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Nightingale)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 10 variables.
</p>

<dl>
<dt><code>Date</code></dt><dd><p>a Date, composed as <code>as.Date(paste(Year, Month, 1, sep='-'), "%Y-%b-%d")</code></p>
</dd>
<dt><code>Month</code></dt><dd><p>Month of the Crimean War, an ordered factor</p>
</dd>
<dt><code>Year</code></dt><dd><p>Year of the Crimean War</p>
</dd>
<dt><code>Army</code></dt><dd><p>Estimated average monthly strength of the British army</p>
</dd>
<dt><code>Disease</code></dt><dd><p>Number of deaths from preventable or mitagable zymotic diseases</p>
</dd>
<dt><code>Wounds</code></dt><dd><p>Number of deaths directly from battle wounds</p>
</dd>
<dt><code>Other</code></dt><dd><p>Number of deaths from other causes</p>
</dd>
<dt><code>Disease.rate</code></dt><dd><p>Annual rate of deaths from preventable or mitagable zymotic diseases, per 1000</p>
</dd>
<dt><code>Wounds.rate</code></dt><dd><p>Annual rate of deaths directly from battle wounds, per 1000</p>
</dd>
<dt><code>Other.rate</code></dt><dd><p>Annual rate of deaths from other causes, per 1000</p>
</dd>
</dl>



<h3>Details</h3>

<p>For a given cause of death, <code>D</code>, annual rates per 1000 are calculated as <code>12 * 1000 * D / Army</code>,
rounded to 1 decimal.
</p>
<p>The two panels of Nightingale's Coxcomb correspond to dates before and after March 1855
</p>


<h3>Source</h3>

<p>The data were obtained from:
</p>
<p>Pearson, M. and Short, I. (2007).
Understanding Uncertainty: Mathematics of the Coxcomb.
<a href="http://understandinguncertainty.org/node/214">http://understandinguncertainty.org/node/214</a>.
</p>


<h3>References</h3>

<p>Nightingale, F. (1858)
<em>Notes on Matters Affecting the Health, Efficiency, and Hospital Administration of the British Army</em>
Harrison and Sons, 1858
</p>
<p>Nightingale, F. (1859)
<em>A Contribution to the Sanitary History of the British Army during the Late War with Russia</em>
London: John W. Parker and Son.
</p>
<p>Small, H. (1998)
Florence Nightingale's statistical diagrams
<a href="http://www.florence-nightingale-avenging-angel.co.uk/GraphicsPaper/Graphics.htm">http://www.florence-nightingale-avenging-angel.co.uk/GraphicsPaper/Graphics.htm</a>
</p>
<p>Pearson, M. and Short, I. (2008)
Nightingale's Rose (flash animation).
<a href="http://understandinguncertainty.org/files/animations/Nightingale11/Nightingale1.html">http://understandinguncertainty.org/files/animations/Nightingale11/Nightingale1.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Nightingale)

# For some graphs, it is more convenient to reshape death rates to long format
#  keep only Date and death rates
require(reshape)
Night&lt;- Nightingale[,c(1,8:10)]
melted &lt;- melt(Night, "Date")
names(melted) &lt;- c("Date", "Cause", "Deaths")
melted$Cause &lt;- sub("\\.rate", "", melted$Cause)
melted$Regime &lt;- ordered( rep(c(rep('Before', 12), rep('After', 12)), 3), 
                          levels=c('Before', 'After'))
Night &lt;- melted

# subsets, to facilitate separate plotting
Night1 &lt;- subset(Night, Date &lt; as.Date("1855-04-01"))
Night2 &lt;- subset(Night, Date &gt;= as.Date("1855-04-01"))

# sort according to Deaths in decreasing order, so counts are not obscured [thx: Monique Graf]
Night1 &lt;- Night1[order(Night1$Deaths, decreasing=TRUE),]
Night2 &lt;- Night2[order(Night2$Deaths, decreasing=TRUE),]

# merge the two sorted files
Night &lt;- rbind(Night1, Night2)


require(ggplot2)
# Before plot
cxc1 &lt;- ggplot(Night1, aes(x = factor(Date), y=Deaths, fill = Cause)) +
		# do it as a stacked bar chart first
   geom_bar(width = 1, position="identity", stat="identity", color="black") +
		# set scale so area ~ Deaths	
   scale_y_sqrt() 
		# A coxcomb plot = bar chart + polar coordinates
cxc1 + coord_polar(start=3*pi/2) + 
	ggtitle("Causes of Mortality in the Army in the East") + 
	xlab("")

# After plot
cxc2 &lt;- ggplot(Night2, aes(x = factor(Date), y=Deaths, fill = Cause)) +
   geom_bar(width = 1, position="identity", stat="identity", color="black") +
   scale_y_sqrt()
cxc2 + coord_polar(start=3*pi/2) +
	ggtitle("Causes of Mortality in the Army in the East") + 
	xlab("")

## Not run: 
# do both together, with faceting
cxc &lt;- ggplot(Night, aes(x = factor(Date), y=Deaths, fill = Cause)) +
 geom_bar(width = 1, position="identity", stat="identity", color="black") + 
 scale_y_sqrt() +
 facet_grid(. ~ Regime, scales="free", labeller=label_both)
cxc + coord_polar(start=3*pi/2) +
	ggtitle("Causes of Mortality in the Army in the East") + 
	xlab("")

## End(Not run)

## What if she had made a set of line graphs?

# these plots are best viewed with width ~ 2 * height 
colors &lt;- c("blue", "red", "black")
with(Nightingale, {
	plot(Date, Disease.rate, type="n", cex.lab=1.25, 
		ylab="Annual Death Rate", xlab="Date", xaxt="n",
		main="Causes of Mortality of the British Army in the East");
	# background, to separate before, after
	rect(as.Date("1854/4/1"), -10, as.Date("1855/3/1"), 
		1.02*max(Disease.rate), col=gray(.90), border="transparent");
	text( as.Date("1854/4/1"), .98*max(Disease.rate), "Before Sanitary\nCommission", pos=4);
	text( as.Date("1855/4/1"), .98*max(Disease.rate), "After Sanitary\nCommission", pos=4);
	# plot the data
	points(Date, Disease.rate, type="b", col=colors[1], lwd=3);
	points(Date, Wounds.rate, type="b", col=colors[2], lwd=2);
	points(Date, Other.rate, type="b", col=colors[3], lwd=2)
	}
)
# add custom Date axis and legend
axis.Date(1, at=seq(as.Date("1854/4/1"), as.Date("1856/3/1"), "3 months"), format="%b %Y")
legend(as.Date("1855/10/20"), 700, c("Preventable disease", "Wounds and injuries", "Other"),
	col=colors, fill=colors, title="Cause", cex=1.25)

# Alternatively, show each cause of death as percent of total
Nightingale &lt;- within(Nightingale, {
	Total &lt;- Disease + Wounds + Other
	Disease.pct &lt;- 100*Disease/Total
	Wounds.pct &lt;- 100*Wounds/Total
	Other.pct &lt;- 100*Other/Total
	})

colors &lt;- c("blue", "red", "black")
with(Nightingale, {
	plot(Date, Disease.pct, type="n",  ylim=c(0,100), cex.lab=1.25,
		ylab="Percent deaths", xlab="Date", xaxt="n",
		main="Percentage of Deaths by Cause");
	# background, to separate before, after
	rect(as.Date("1854/4/1"), -10, as.Date("1855/3/1"), 
		1.02*max(Disease.rate), col=gray(.90), border="transparent");
	text( as.Date("1854/4/1"), .98*max(Disease.pct), "Before Sanitary\nCommission", pos=4);
	text( as.Date("1855/4/1"), .98*max(Disease.pct), "After Sanitary\nCommission", pos=4);
	# plot the data
	points(Date, Disease.pct, type="b", col=colors[1], lwd=3);
	points(Date, Wounds.pct, type="b", col=colors[2], lwd=2);
	points(Date, Other.pct, type="b", col=colors[3], lwd=2)
	}
)
# add custom Date axis and legend
axis.Date(1, at=seq(as.Date("1854/4/1"), as.Date("1856/3/1"), "3 months"), format="%b %Y")
legend(as.Date("1854/8/20"), 60, c("Preventable disease", "Wounds and injuries", "Other"),
	col=colors, fill=colors, title="Cause", cex=1.25)

</code></pre>

<hr>
<h2 id='OldMaps'>
Latitudes and Longitudes of 39 Points in 11 Old Maps
</h2><span id='topic+OldMaps'></span>

<h3>Description</h3>

<p>The data set is concerned with the problem of aligning the coordinates of points
read from old maps (1688 - 1818) of the Great Lakes area.  
39 easily identifiable
points were selected  in the Great Lakes area, and their (lat, long) coordinates
were recorded using a grid overlaid on each of 11 old maps, and using linear interpolation.
</p>
<p>It was conjectured that maps might be systematically in error in five key ways:
(a) constant error in latitude; (b)constant error in longitude;
(c) proportional error in latitude; (d)proportional error in longitude;
(e) angular error from a non-zero difference between true North and the map's North.
</p>
<p>One challenge from these data is to produce useful analyses and graphical displays
that relate to these characteristics or to other aspects of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(OldMaps)</code></pre>


<h3>Format</h3>

<p>A data frame with 468 observations on the following 6 variables, giving the latitude
and longitude of 39 points recorded from 12 sources (Actual + 11 maps).
</p>

<dl>
<dt><code>point</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>col</code></dt><dd><p>Column in the table a numeric vector</p>
</dd>
<dt><code>name</code></dt><dd><p>Name of the map maker, using <code>Actual</code> for the true coordinates of the points.
A factor with levels <code>Actual</code> 
<code>Arrowsmith</code> <code>Belin</code> <code>Cary</code> <code>Coronelli</code> <code>D'Anville} \code{Del'Isle</code> <code>Lattre</code> <code>Melish</code> <code>Mitchell</code> <code>Popple</code></p>
</dd>
<dt><code>year</code></dt><dd><p>Year of the map</p>
</dd>
<dt><code>lat</code></dt><dd><p>Latitude</p>
</dd>
<dt><code>long</code></dt><dd><p>Longitude</p>
</dd>
</dl>



<h3>Details</h3>

<p>Some of the latitude and longitude values are inexplicably negative.
It is probable that this is an error in type setting, because the table footnote
says &quot;* denotes that interpolation accuracy is not good,&quot; yet no &quot;*&quot;s appear in
the body of the table.
</p>


<h3>Source</h3>

<p>Andrews, D. F., and Herzberg, A. M. (1985).
<em>Data: A Collection of Problems from Many fields for the Student and Research Worker</em>.
New York: Springer, Table 10.1.  
The data were obtained from <code>http://www.stat.duke.edu/courses/Spring01/sta114/data/Andrews/T10.1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(OldMaps)
## maybe str(OldMaps) ; plot(OldMaps) ...

with(OldMaps, plot(abs(long),abs(lat), pch=col, col=colors()[point]))
</code></pre>

<hr>
<h2 id='PearsonLee'>
Pearson and Lee's  data on the heights of parents and children classified by gender
</h2><span id='topic+PearsonLee'></span>

<h3>Description</h3>

<p>Wachsmuth et. al (2003) noticed that a loess smooth through Galton's data
on heights of mid-parents and their offspring exhibited a slightly non-linear
trend, and asked whether this might be due to Galton having pooled the heights of
fathers and mothers and sons and daughters in constructing his tables and graphs.
</p>
<p>To answer this question, they used analogous data from English families at about the
same time, tabulated by Karl Pearson and Alice Lee (1896, 1903), but where the heights
of parents and children were each classified by gender of the parent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PearsonLee)</code></pre>


<h3>Format</h3>

<p>A frequency data frame with 746 observations on the following 6 variables.
</p>

<dl>
<dt><code>child</code></dt><dd><p>child height in inches, a numeric vector</p>
</dd>
<dt><code>parent</code></dt><dd><p>parent height in inches, a numeric vector</p>
</dd>
<dt><code>frequency</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>gp</code></dt><dd><p>a factor with levels <code>fd</code> <code>fs</code> <code>md</code> <code>ms</code></p>
</dd>
<dt><code>par</code></dt><dd><p>a factor with levels <code>Father</code> <code>Mother</code></p>
</dd>
<dt><code>chl</code></dt><dd><p>a factor with levels <code>Daughter</code> <code>Son</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>The variables <code>gp</code>, <code>par</code> and <code>chl</code> are provided to allow stratifying
the data according to the gender of the father/mother and son/daughter.
</p>


<h3>Source</h3>

<p>Pearson, K. and Lee, A. (1896). Mathematical contributions to the theory
of evolution. On telegony in man, etc. <em>Proceedings of the Royal Society of
London</em>, 60 , 273-283.
</p>
<p>Pearson, K. and Lee, A. (1903). 
On the laws of inheritance in man: I. Inheritance of physical characters. <em>Biometika</em>, 2(4), 357-462.
(Tables XXII, p. 415; XXV, p. 417; XXVIII, p. 419 and XXXI, p. 421.)
</p>


<h3>References</h3>

<p>Wachsmuth, A.W., Wilkinson L., Dallal G.E. (2003). 
Galton's bend: A previously undiscovered nonlinearity in Galton's family stature regression data. 
<em>The American Statistician</em>, 57, 190-192. 
<a href="https://www.cs.uic.edu/~wilkinson/Publications/galton.pdf">https://www.cs.uic.edu/~wilkinson/Publications/galton.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Galton">Galton</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(PearsonLee)
str(PearsonLee)

with(PearsonLee, 
    {
    lim &lt;- c(55,80)
    xv &lt;- seq(55,80, .5)
    sunflowerplot(parent,child, number=frequency, xlim=lim, ylim=lim, seg.col="gray", size=.1)
    abline(lm(child ~ parent, weights=frequency), col="blue", lwd=2)
    lines(xv, predict(loess(child ~ parent, weights=frequency), data.frame(parent=xv)), 
          col="blue", lwd=2)
    # NB: dataEllipse doesn't take frequency into account
    if(require(car)) {
    dataEllipse(parent,child, xlim=lim, ylim=lim, plot.points=FALSE)
        }
  })

## separate plots for combinations of (chl, par)

# this doesn't quite work, because xyplot can't handle weights
require(lattice)
xyplot(child ~ parent|par+chl, data=PearsonLee, type=c("p", "r", "smooth"), col.line="red")

# Using ggplot [thx: Dennis Murphy]
require(ggplot2)
ggplot(PearsonLee, aes(x = parent, y = child, weight=frequency)) +
   geom_point(size = 1.5, position = position_jitter(width = 0.2)) +
   geom_smooth(method = lm, aes(weight = PearsonLee$frequency,
               colour = 'Linear'), se = FALSE, size = 1.5) +
   geom_smooth(aes(weight = PearsonLee$frequency,
               colour = 'Loess'), se = FALSE, size = 1.5) +
   facet_grid(chl ~ par) +
   scale_colour_manual(breaks = c('Linear', 'Loess'),
                       values = c('green', 'red')) +
   theme(legend.position = c(0.14, 0.885),
        legend.background = element_rect(fill = 'white'))

# inverse regression, as in Wachmuth et al. (2003)

ggplot(PearsonLee, aes(x = child, y = parent, weight=frequency)) +
   geom_point(size = 1.5, position = position_jitter(width = 0.2)) +
   geom_smooth(method = lm, aes(weight = PearsonLee$frequency,
               colour = 'Linear'), se = FALSE, size = 1.5) +
   geom_smooth(aes(weight = PearsonLee$frequency,
               colour = 'Loess'), se = FALSE, size = 1.5) +
   facet_grid(chl ~ par) +
   scale_colour_manual(breaks = c('Linear', 'Loess'),
                       values = c('green', 'red')) +
   theme(legend.position = c(0.14, 0.885),
        legend.background = element_rect(fill = 'white'))

</code></pre>

<hr>
<h2 id='PolioTrials'>
Polio Field Trials Data
</h2><span id='topic+PolioTrials'></span>

<h3>Description</h3>

<p>The data frame <code>PolioTrials</code> gives the results of the 1954 field trials to test the Salk polio vaccine 
(named for the developer, Jonas Salk), conducted by the National Foundation for Infantile Paralysis (NFIP). 
It is adapted from data in the article by Francis et al. (1955).  
There were actually two clinical trials, corresponding to two statistical designs (<code>Experiment</code>),
discussed by Brownlee (1955).  The comparison of designs and results represented a
milestone in the development of randomized clinical trials. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PolioTrials)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 6 variables.
</p>

<dl>
<dt><code>Experiment</code></dt><dd><p>a factor with levels <code>ObservedControl</code> <code>RandomizedControl</code></p>
</dd>
<dt><code>Group</code></dt><dd><p>a factor with levels <code>Controls</code> <code>Grade2NotInoculated</code> <code>IncompleteVaccinations</code> <code>NotInoculated</code> <code>Placebo</code> <code>Vaccinated</code></p>
</dd>
<dt><code>Population</code></dt><dd><p>the size of the population in each group in each experiment</p>
</dd>
<dt><code>Paralytic</code></dt><dd><p>the number of cases of paralytic polio observed in that group</p>
</dd>
<dt><code>NonParalytic</code></dt><dd><p>the number of cases of paralytic polio observed in that group</p>
</dd>
<dt><code>FalseReports</code></dt><dd><p>the number of cases initially reported as polio, but later determined
not to be polio in that group</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data frame is in the form of a single table, but actually comprises the results of two separate
field trials, given by <code>Experiment</code>.  Each should be analyzed separately, because the designs
differ markedly.
</p>
<p>The original design (<code>Experiment == "ObservedControl"</code>)
called for vaccination of second-graders at selected schools in selected areas  
of the country (with the consent of the children's parents, of course). 
The <code>Vaccinated</code> second-graders  formed the treatment group. 
The first and third-graders at the schools were not given the vaccination, and formed the 
<code>Controls</code> group. 
</p>
<p>In the second design  (<code>Experiment == "RandomizedControl"</code>)
children were selected (again in various schools in various areas), 
all of whose parents consented to vaccination. 
The sample was randomly divided into treatment (<code>Group == "Vaccinated"</code>),
given the real polio vaccination, 
and control groups (<code>Group == "Placebo"</code>), 
a placebo dose that looked just like the real vaccine.   
The experiment was also double blind:  neither the parents of a child in the study nor the doctors treating the child knew which group the child belonged to.  
</p>
<p>In both experiments, <code>NotInnoculated</code> refers to children who did not participate in the experiment.
<code>IncompleteVaccinations</code> refers to children who received one or two, but not all three
administrations of the vaccine.
</p>


<h3>Source</h3>

<p>Kyle Siegrist, &quot;Virtual Laboratories in Probability and Statistics&quot;, <a href="http://www.math.uah.edu/stat/data/Polio.html">http://www.math.uah.edu/stat/data/Polio.html</a>
</p>
<p>Thomas Francis, Robert Korn, et al. (1955). &quot;An Evaluation of the 1954 Poliomyelitis Vaccine Trials&quot;, 
<em>American Journal of Public Health</em>,  45, (50 page supplement with a 63 page appendix).
</p>


<h3>References</h3>

<p>K. A.  Brownlee (1955). &quot;Statistics of the 1954 Polio Vaccine Trials&quot;,  
<em>Journal of the American Statistical Association</em>,  50, 1005-1013.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(PolioTrials)
## maybe str(PolioTrials) ; plot(PolioTrials) ...
</code></pre>

<hr>
<h2 id='Pollen'>
Pollen Data Challenge
</h2><span id='topic+Pollen'></span>

<h3>Description</h3>

<p>A synthetic dataset generated by David Coleman at RCA Laboratories in Princeton, N.J
and used in the 1986 American Statistical Association JSM meeting as
a data challenge for the Statistical Graphics Section.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Pollen")</code></pre>


<h3>Format</h3>

<p>A data frame with 3848 observations on the following 5 variables, representing
ficticious measurements of grains of pollen.
</p>

<dl>
<dt><code>ridge</code></dt><dd><p>along X, a numeric vector</p>
</dd>
<dt><code>nub</code></dt><dd><p>along y, a numeric vector</p>
</dd>
<dt><code>crack</code></dt><dd><p>along z, a numeric vector</p>
</dd>
<dt><code>weight</code></dt><dd><p>weight of pollen grain, a numeric vector</p>
</dd>
<dt><code>density</code></dt><dd><p>weight of pollen grain, a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The first three variables are the
lengths of geometric features observed sampled pollen grains - in the
x, y, and z dimensions: a &quot;ridge&quot; along x, a &quot;nub&quot; in the y
direction, and a &quot;crack&quot; in along the z dimension.  The fourth
variable is pollen grain weight, and the fifth is density.
</p>
<p>In the description for the data challenge:
&quot;the data analyst is advised that there is more than one &quot;feature&quot; to
these data.  Each feature can be observed through various graphical
techniques, but analytic methods, as well, can help &quot;crack&quot; the
dataset.&quot;
</p>
<p>There were several features embedded in this dataset: clusters of points,
5D ellipsoidal voids with no points, and finally, a collection of points
which spelled out &quot;EUREKA&quot;.
</p>
<p>Papers by Becker et al. (1986) and Slomka (1986) describe their work on
this problem.
</p>
<p>Yihui Xie used this data as an illustration of the <span class="pkg">animate</span> package,
using <span class="pkg">rgl</span> to zoom in on the magic word.
See the video on <a href="https://vimeo.com/1982725">https://vimeo.com/1982725</a>.
</p>


<h3>Source</h3>

<p>The canonical source for this data is the StatLib &ndash; Datasets Archive
<a href="http://lib.stat.cmu.edu/datasets/pollen.data">http://lib.stat.cmu.edu/datasets/pollen.data</a>
in the inconvenient form of .sh archive.
</p>
<p>It is also available as <code>data(pollen, package="animate")</code>.
</p>


<h3>References</h3>

<p>Becker, R.A., Denby, L., McGill, R., and Wilks, A. (1986). 
Datacryptanalysis: A Case Study.
<em>Proceedings of the Section on Statistical Graphics</em>, 92-97.
</p>
<p>Slomka, M. (1986). The Analysis of a Synthetic Data Set.
<em>Proceedings of the Section on Statistical Graphics</em>, 113-116.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Pollen)
pairs(Pollen)
</code></pre>

<hr>
<h2 id='Prostitutes'>
Parent-Duchatelet's time-series data on the number of prostitutes in Paris
</h2><span id='topic+Prostitutes'></span>

<h3>Description</h3>

<p>A table indicating month by month, for the years 1812-1854, the number of prostitutes on the 
registers of the administration of the city of Paris.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Prostitutes)</code></pre>


<h3>Format</h3>

<p>A data frame with 516 observations on the following 5 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>month</code></dt><dd><p>a factor with levels <code>Apr</code> <code>Aug</code> <code>Dec</code> <code>Feb</code> <code>Jan</code> <code>Jul</code> <code>Jun</code> <code>Mar</code> <code>May</code> <code>Nov</code> <code>Oct</code> <code>Sep</code></p>
</dd>
<dt><code>count</code></dt><dd><p>a numeric vector: number of prostitutes</p>
</dd>
<dt><code>mon</code></dt><dd><p>a numeric vector: numeric month</p>
</dd>
<dt><code>date</code></dt><dd><p>a Date</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data table was digitally scanned with OCR, and errors were corrected by comparing the
yearly totals recorded in the table to the row sums of the scanned data.
</p>


<h3>Source</h3>

<p>Parent-Duchatelet, A. (1857), <em>De la prostitution dans la ville de Paris</em>, 3rd ed,  p. 32, 36
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Prostitutes)
## maybe str(Prostitutes) ; plot(Prostitutes) ...
</code></pre>

<hr>
<h2 id='Pyx'>
Trial of the Pyx
</h2><span id='topic+Pyx'></span>

<h3>Description</h3>

<p>Stigler (1997, 1999) recounts the history of one of the oldest continuous schemes of
sampling inspection carried out by the Royal Mint in London for about eight centuries.
The Trial of the Pyx was the final, ceremonial stage in a process designed to ensure that
the weight and quality of gold and silver coins from the mint met the standards for
coinage.  
</p>
<p>At regular intervals, coins would be taken from production and deposited into
a box called the Pyx.
When a Trial of the Pyx was called, the contents of the Pyx would be counted, weighed
and assayed for content, and the results would be compared with the standard set 
for the Royal Mint. 
</p>
<p>The data frame <code>Pyx</code> gives the results for the year 1848 (Great Britain, 1848) in which 10,000
gold sovereigns were assayed. The coins in each bag were classified according to the
deviation from the standard content of gold for each coin, called the Remedy,
R = 123 * (12/5760) = .25625, in grains, for a single sovereign. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Pyx)</code></pre>


<h3>Format</h3>

<p>A frequency data frame with 72 observations on the following 4 variables giving the
distribution of 10,000 sovereigns, classified according to the <code>Bags</code> in which
they were collected and the <code>Deviation</code> from the standard weight.
</p>

<dl>
<dt><code>Bags</code></dt><dd><p>an ordered factor with levels <code>1 and 2</code> &lt; <code>3</code> &lt; <code>4</code> &lt; <code>5</code> &lt; <code>6</code> &lt; <code>7</code> &lt; <code>8</code> &lt; <code>9</code> &lt; <code>10</code></p>
</dd>
<dt><code>Group</code></dt><dd><p>an ordered factor with levels <code>below std</code> &lt; <code>near std</code> &lt; <code>above std</code></p>
</dd>
<dt><code>Deviation</code></dt><dd><p>an ordered factor with levels <code>Below -R</code> &lt; <code>(-R to -.2)</code> &lt; <code>(-.2 to -.l)</code> &lt; <code>(-.1 to 0)</code> &lt; <code>(0 to .l)</code> &lt; <code>(.1 to .2)</code> &lt; <code>(.2 to R)</code> &lt; <code>Above R</code></p>
</dd>
<dt><code>count</code></dt><dd><p>number of sovereigns</p>
</dd>
</dl>



<h3>Details</h3>

<p><code>Bags</code> 1-4 were selected as &quot;near to standard&quot;, bags 5-7 as below standard, bags 8-10 as above standard.
This classification is reflected in <code>Group</code>.
</p>


<h3>Source</h3>

<p>Stigler, S. M. (1999).
<em>Statistics on the Table</em>.
Cambridge, MA: Harvard University Press, table 21.1.
</p>


<h3>References</h3>

<p>Great Britain (1848).
&quot;Report of the Commissioners Appointed to Inquire into the Constitution, Management
and Expense of the Royal Mint.&quot;
In Vol 28 of <em>House Documents for 1849</em>.
</p>
<p>Stigler, S. M. (1997).
Eight Centuries of Sampling Inspection: The Trial of the Pyx
<em>Journal of the American Statistical Association</em>, 72(359), 493-500 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Pyx)
# display as table
xtabs(count ~ Bags+Deviation, data=Pyx)
</code></pre>

<hr>
<h2 id='Quarrels'>
Statistics of Deadly Quarrels
</h2><span id='topic+Quarrels'></span>

<h3>Description</h3>

<p><em>The Statistics Of Deadly Quarrels</em> by                            
Lewis Fry Richardson (1960) is one of the earlier attempts                   
at quantification of historical conflict behavior.                    
</p>
<p>The data set contains 779 dyadic deadly quarrels that cover a             
time period from 1809 to 1949.  A quarrel consists of one             
pair of belligerents, and is identified by its
beginning date and magnitude (log 10 of the number of deaths).
Neither actor in a quarrel is identified by name.
</p>
<p>Because Richardson took a dyad of belligerents as his unit,
a given war, such as World War I or World War II comprises
multiple observations, for all pairs of belligerents. 
For example, there are forty-four pairs of belligerents coded for              
World War I.
</p>
<p>For each quarrel, the nominal variables
include the type of quarrel, as well as political, cultural, and economic
similarities and dissimilarities between the pair of combatants.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Quarrels)</code></pre>


<h3>Format</h3>

<p>A data frame with 779 observations on the following 84 variables.
</p>

<dl>
<dt><code>ID </code></dt><dd><p>V84: Id sequence </p>
</dd>
<dt><code>year </code></dt><dd><p>V1: Begin date of quarrel </p>
</dd>
<dt><code>international </code></dt><dd><p>V2: Nation vs nation </p>
</dd>
<dt><code>colonial </code></dt><dd><p>V3: Nation vs colony </p>
</dd>
<dt><code>revolution </code></dt><dd><p>V4: Revolution or civil war </p>
</dd>
<dt><code>nat.grp </code></dt><dd><p>V5: Nation vs gp in other nation </p>
</dd>
<dt><code>grp.grpSame </code></dt><dd><p>V6: Grp vs grp (same nation) </p>
</dd>
<dt><code>grp.grpDif </code></dt><dd><p>V7: Grp vs grp (between nations) </p>
</dd>
<dt><code>numGroups </code></dt><dd><p>V8: Number groups against which fighting </p>
</dd>
<dt><code>months </code></dt><dd><p>V9: Number months fighting </p>
</dd>
<dt><code>pairs </code></dt><dd><p>V10: Number pairs in whole matrix </p>
</dd>
<dt><code>monthsPairs </code></dt><dd><p>V11: Num mons for all in matrix </p>
</dd>
<dt><code>logDeaths </code></dt><dd><p>V12: Log (killed) matrix </p>
</dd>
<dt><code>deaths </code></dt><dd><p>V13: Total killed for matrix </p>
</dd>
<dt><code>exchangeGoods </code></dt><dd><p>V14: Gp sent goods to other </p>
</dd>
<dt><code>obstacleGoods </code></dt><dd><p>V15: Gp puts obstacles to goods </p>
</dd>
<dt><code>intermarriageOK </code></dt><dd><p>V16: Present intermarriages </p>
</dd>
<dt><code>intermarriageBan </code></dt><dd><p>V17: Intermarriages banned </p>
</dd>
<dt><code>simBody </code></dt><dd><p>V18: Similar body characteristics </p>
</dd>
<dt><code>difBody </code></dt><dd><p>V19: Difference in body characteristics </p>
</dd>
<dt><code>simDress </code></dt><dd><p>V20: Similarity of customs (dress) </p>
</dd>
<dt><code>difDress </code></dt><dd><p>V21: Difference of customs (dress) </p>
</dd>
<dt><code>eqWealth </code></dt><dd><p>V22: Common level of wealth </p>
</dd>
<dt><code>difWealth </code></dt><dd><p>V23: Difference in wealth </p>
</dd>
<dt><code>simMariagCust </code></dt><dd><p>V24: Similar marriage cusomst </p>
</dd>
<dt><code>difMariagCust </code></dt><dd><p>V25: Different marriage customs </p>
</dd>
<dt><code>simRelig </code></dt><dd><p>V26: Similar religion or philosophy of life </p>
</dd>
<dt><code>difRelig </code></dt><dd><p>V27: Religion or philosophy felt different </p>
</dd>
<dt><code>philanthropy </code></dt><dd><p>V28: General philanthropy </p>
</dd>
<dt><code>restrictMigration </code></dt><dd><p>V29: Restricted immigrations </p>
</dd>
<dt><code>sameLanguage </code></dt><dd><p>V30: Common mother tongue </p>
</dd>
<dt><code>difLanguage </code></dt><dd><p>V31: Different languages </p>
</dd>
<dt><code>simArtSci </code></dt><dd><p>V32: Similar science, arts </p>
</dd>
<dt><code>travel </code></dt><dd><p>V33: Travel </p>
</dd>
<dt><code>ignorance </code></dt><dd><p>V34: Ignorant of other/both </p>
</dd>
<dt><code>simPersLiberty </code></dt><dd><p>V35: Personal liberty similar </p>
</dd>
<dt><code>difPersLiberty </code></dt><dd><p>V36: More personal liberty </p>
</dd>
<dt><code>sameGov </code></dt><dd><p>V37: Common government </p>
</dd>
<dt><code>sameGovYrs </code></dt><dd><p>V38: Years since common govt established </p>
</dd>
<dt><code>prevConflict </code></dt><dd><p>V39: Belligerents fought previously </p>
</dd>
<dt><code>prevConflictYrs </code></dt><dd><p>V40: Years since belligerents fought </p>
</dd>
<dt><code>chronicFighting </code></dt><dd><p>V41: Chronic fighting between belligerents </p>
</dd>
<dt><code>persFriendship </code></dt><dd><p>V42: Autocrats personal friends </p>
</dd>
<dt><code>persResentment </code></dt><dd><p>V43: Leaders personal resentment </p>
</dd>
<dt><code>difLegal </code></dt><dd><p>V44: Annoyingly different legal systems </p>
</dd>
<dt><code>nonintervention </code></dt><dd><p>V45: Policy of nonintervention </p>
</dd>
<dt><code>thirdParty </code></dt><dd><p>V46: Led by 3rd group to conflict </p>
</dd>
<dt><code>supportEnemy </code></dt><dd><p>V47: Supported others enemy </p>
</dd>
<dt><code>attackAlly </code></dt><dd><p>V48: Attacked ally of other </p>
</dd>
<dt><code>rivalsLand </code></dt><dd><p>V49: Rivals territory concess </p>
</dd>
<dt><code>rivalsTrade </code></dt><dd><p>V50: Rivals trade </p>
</dd>
<dt><code>churchPower </code></dt><dd><p>V51: Church civil power </p>
</dd>
<dt><code>noExtension </code></dt><dd><p>V52: Policy not extending term </p>
</dd>
<dt><code>territory </code></dt><dd><p>V53: Desired territory </p>
</dd>
<dt><code>habitation </code></dt><dd><p>V54: Wanted habitation </p>
</dd>
<dt><code>minerals </code></dt><dd><p>V55: Desired minerals </p>
</dd>
<dt><code>StrongHold </code></dt><dd><p>V56: Wanted strategic stronghold </p>
</dd>
<dt><code>taxation </code></dt><dd><p>V57: Taxed other </p>
</dd>
<dt><code>loot </code></dt><dd><p>V58: Wanted loot </p>
</dd>
<dt><code>objectedWar </code></dt><dd><p>V59: Objected to war </p>
</dd>
<dt><code>enjoyFight </code></dt><dd><p>V60: Enjoyed fighting </p>
</dd>
<dt><code>pride </code></dt><dd><p>V61: Elated by strong pride </p>
</dd>
<dt><code>overpopulated </code></dt><dd><p>V62: Insufficient land for population </p>
</dd>
<dt><code>fightForPay </code></dt><dd><p>V63: Fought only for pay </p>
</dd>
<dt><code>joinWinner </code></dt><dd><p>V64: Desired to join winners </p>
</dd>
<dt><code>otherDesiredWar </code></dt><dd><p>V65: Quarrel desired by other </p>
</dd>
<dt><code>propaganda3rd </code></dt><dd><p>V66: Issued of propaganda to third parties </p>
</dd>
<dt><code>protection </code></dt><dd><p>V67: Offered protection </p>
</dd>
<dt><code>sympathy </code></dt><dd><p>V68: Sympathized under control </p>
</dd>
<dt><code>debt </code></dt><dd><p>V69: Owed money to others </p>
</dd>
<dt><code>prevAllies </code></dt><dd><p>V70: Had fought as allies </p>
</dd>
<dt><code>yearsAllies </code></dt><dd><p>V71: Years since fought as allies </p>
</dd>
<dt><code>intermingled </code></dt><dd><p>V72: Had intermingled on territory </p>
</dd>
<dt><code>interbreeding </code></dt><dd><p>V73: Interbreeding between groups </p>
</dd>
<dt><code>propadanda </code></dt><dd><p>V74: Issued propaganda to other group </p>
</dd>
<dt><code>orderedObey </code></dt><dd><p>V75: Ordered other to obey </p>
</dd>
<dt><code>commerceOther </code></dt><dd><p>V76: Commercial enterprises </p>
</dd>
<dt><code>feltStronger </code></dt><dd><p>V77: Felt stronger </p>
</dd>
<dt><code>competeIntellect </code></dt><dd><p>V78: Competed successfully intellectual occ </p>
</dd>
<dt><code>insecureGovt </code></dt><dd><p>V79: Government insecure </p>
</dd>
<dt><code>prepWar </code></dt><dd><p>V80: Preparations for war </p>
</dd>
<dt><code>RegionalError </code></dt><dd><p>V81: Regional error measure </p>
</dd>
<dt><code>CasualtyError </code></dt><dd><p>V82: Casualty error measure </p>
</dd>
<dt><code>Auxiliaries </code></dt><dd><p>V83: Auxiliaries in service of nation at war </p>
</dd>
</dl>



<h3>Details</h3>

<p>In the original data set obtained from ICPSR, variables were
named <code>V1</code>-<code>V84</code>.  These were renamed to make them more
meaningful. <code>V84</code>, renamed <code>ID</code> was moved to the first position,
but otherwise the order of variables is the same.
</p>
<p>In many of the <code>factor</code> variables, <code>0</code> is used to indicate
&quot;irrelevant to quarrel&quot;.  This refers to those relations that              
Richardson found absent or irrelevant to the particular               
quarrel, and did not subsequently mention.                            
</p>
<p>See the original codebook at
<a href="http://www.icpsr.umich.edu/cgi-bin/file?comp=none&amp;study=5407&amp;ds=1&amp;file_id=652814">http://www.icpsr.umich.edu/cgi-bin/file?comp=none&amp;study=5407&amp;ds=1&amp;file_id=652814</a>
for details not contained here.
</p>


<h3>Source</h3>

<p><a href="http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/05407">http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/05407</a>
</p>


<h3>References</h3>

<p>Lewis F. Richardson, (1960).
<em>The Statistics Of Deadly Quarrels</em>. (Edited by Q. Wright and C. C. Lienau). 
Pittsburgh: Boxwood Press.  
</p>
<p>Rummel, Rudolph J. (1967), &quot;Dimensions of Dyadic War, 1820-1952.&quot; <em>Journal of
Conflict Resolution</em>. 11, (2), 176 - 183.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Quarrels)
str(Quarrels)
</code></pre>

<hr>
<h2 id='Saturn'>
Laplace's Saturn data.
</h2><span id='topic+Saturn'></span>

<h3>Description</h3>

<p>With this dataset Laplace (1787) showed that &quot;noticed defects in the then
existing tables of the motions of Jupiter and Saturn&quot; were, <em>de facto</em>,
due to &quot;a very long, 917-year, periodic inequality in the planets' mean motion,
due to their mutual attraction and the coincidence that their times of revolution
about the sun are approximately in the ratio 5:2&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Saturn)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 6 variables.
</p>

<dl>
<dt><code>Equation</code></dt><dd><p>an integer vector, id of the Equation</p>
</dd>
<dt><code>Year</code></dt><dd><p>an integer vector, year of the observations</p>
</dd>
<dt><code>Y</code></dt><dd><p>a numeric vector, adjusted measure of the observed longitude
of Saturn, in minutes</p>
</dd>
<dt><code>X1</code></dt><dd><p>a numeric vector, the rate of change of the mean annual
motion of Saturn</p>
</dd>
<dt><code>X2</code></dt><dd><p>a numeric vector, the rate of change of the eccentricity of
Saturn's orbit</p>
</dd>
<dt><code>X3</code></dt><dd><p>a numeric vector, a variable compound of the rate of change
of Saturn's aphelion minus rates of change of the mean longitude of Saturn
in 1750, multiplied by 2 times the mean eccentricity of Saturn</p>
</dd>
</dl>



<h3>Details</h3>

<p>Stigler (1986, pp. 25-39):
</p>
<p>&quot;In 1676 Halley had verified an earlier suspicion of Horrocks that the
motions of Jupiter and Saturn were subject to slight, apparently secular,
inequalities. When the actual positions of Jupiter and Saturn were
compared with the tabulated observations of many centuries, it appeared that
the mean motion of Jupiter was accelerating, whereas that of Saturn was
retarding. Halley was able to improve the accuracy of the tables by an
empirical adjustment, and he speculated that the irregularity was
somehow due to the mutual attraction of the planets. But he was unable to
provide a mathematical theory that would account for this inequality.
</p>
<p>If the observed trends were to continue indefinitely, Jupiter would crash into
the sun as Saturn receded into space! The problem posed by the Academy could be
(and was) interpreted as requiring the development of an extension of existing
theories of attraction to incorporate the mutual attraction of three bodies, in
order to see whether such a theory could account for at least the major observed
inequalities as, it was hoped, periodic in nature. Thus stability would be
restored to the solar system, and Newtonian gravitational theory would have
overcome another obstacle.
</p>
<p>The problem was an extraordinarily difficult one for the time, and
Euler's attempts to grope for a solution are most revealing. Euler's work
was, in comparison with Mayer's a year later, a statistical failure. After he
had found values for <em>n</em> and <em>u</em>, Euler had the data needed to
produce seventy-five equations, all linear in <em>x, y, m, z, a</em>, and
<em>k</em>. He might have added them together in six groups and solved for the
unknowns, but he attempted no such overall combination of the equations.
</p>
<p>Laplace had come quite a bit closer to providing a general method than
<code><a href="#topic+Mayer">Mayer</a></code> had. Indeed, it was Laplace's generalization that enjoyed
popularity throughout the first half of the nineteenth century, as a method that
provided some of the accuracy expected from least squares, with much less
labor. Because the multipliers were all -1, 0, or 1, no multiplication, only
addition, was required.&quot;
</p>


<h3>Author(s)</h3>

<p>Luiz Fernando Palin Droubi</p>


<h3>Source</h3>

<p>Stigler, Stephen (1975). &quot;Napoleonic statistics: The work of Laplace&quot;,
<em>Biometrika</em>, 62, 503-517.
</p>


<h3>References</h3>

<p>Stigler, Stephen M. (1986).
<em>The History of Statistics: The Measurement of Uncertainty before 1900</em>.
Cambridge, MA: Harvard University Press, 1986, Table 1.3, p. 34.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Saturn)

# some scatterplots
pairs(Saturn[,2:6])
plot(Y ~ X1, data=Saturn)
plot(Y ~ X2, data=Saturn)

# Fit the LS model
fit &lt;- lm(Y ~ X1 + X2 + X3, data = Saturn)
# Same residuals of Stigler (1975), Table 1, last column.
library(sp)
dd2dms(residuals(fit)/60)
</code></pre>

<hr>
<h2 id='Snow'>
John Snow's Map and Data on the 1854 London Cholera Outbreak
</h2><span id='topic+Snow'></span><span id='topic+Snow.deaths'></span><span id='topic+Snow.deaths2'></span><span id='topic+Snow.pumps'></span><span id='topic+Snow.streets'></span><span id='topic+Snow.polygons'></span><span id='topic+Snow.dates'></span>

<h3>Description</h3>

<p>The <code>Snow</code> data consists of the relevant 1854 London streets, the location of 578 
deaths from cholera, and the position of 13 water pumps (wells)
that can be used to re-create John Snow's map showing deaths from
cholera in the area surrounding Broad Street, London in the 1854 outbreak.
Another data frame provides boundaries of a tessellation of the map into 
Thiessen (Voronoi) regions which include all cholera deaths nearer to
a given pump than to any other.
</p>
<p>The apocryphal story of the significance of Snow's map is that, by closing  the
Broad Street pump (by removing its  handle), Dr. Snow  stopped the epidemic,  and
demonstrated that  cholera is  a water  borne disease.  The method of contagion of cholera
was  not previously
understood. Snow's map is the most famous and classical example in the field  of
medical cartography, even if  it didn't happen exactly  this way.
(the apocryphal part is that the epidemic ended when the pump handle was removed.)
At any  rate,
the map, together with  various statistical annotations,  is  compelling because
it points to the Broad Street pump as the source of the outbreak.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	data(Snow.deaths)
	data(Snow.pumps)
	data(Snow.streets)
	data(Snow.polygons)
	data(Snow.dates)
</code></pre>


<h3>Format</h3>

<p><code>Snow.deaths</code>: A  data frame  with 578  observations on  the following  3
variables, giving the  address of a  person who died  from cholera. When  many
points are associated with  a single street address,  they are &quot;stacked&quot; in  a
line away from the street so that they are more easily visualized. This is how
they are displayed on  John Snow's original map.  The dates of the  deaths are
not individually recorded in this data set.
</p>

<dl>
<dt><code>case</code></dt><dd><p>Sequential case number, in some arbitrary, randomized order</p>
</dd>
<dt><code>x</code></dt><dd><p>x coordinate</p>
</dd>
<dt><code>y</code></dt><dd><p>y coordinate</p>
</dd>
</dl>

<p><code>Snow.pumps</code>: A data frame with 13 observations on the following 4 variables,
giving the locations of water pumps within the boundaries of the map.
</p>

<dl>
<dt><code>pump</code></dt><dd><p>pump number</p>
</dd>
<dt><code>label</code></dt><dd><p>pump label:  <code>Briddle St</code> <code>Broad St</code> ... <code>Warwick</code></p>
</dd>
<dt><code>x</code></dt><dd><p>x coordinate</p>
</dd>
<dt><code>y</code></dt><dd><p>y coordinate</p>
</dd>
</dl>

<p><code>Snow.streets</code>: A data frame with 1241 observations on the following 4 variables,
giving coordinates used to draw the 528 street segment lines within the boundaries of the map.
The map is created by drawing lines connecting the <code>n</code> points in each street segment.
</p>

<dl>
<dt><code>street</code></dt><dd><p>street segment number: <code>1:528</code></p>
</dd>
<dt><code>n</code></dt><dd><p>number of points in this street line segment</p>
</dd>
<dt><code>x</code></dt><dd><p>x coordinate</p>
</dd>
<dt><code>y</code></dt><dd><p>y coordinate</p>
</dd>
</dl>

<p><code>Snow.polygons</code>: A list of 13 data frames, giving the vertices of
Thiessen  (Voronoi) polygons  containing each  pump. Their
boundaries define the area that is closest to each pump relative to all  other
pumps. They are mathematically defined  by the perpendicular bisectors of  the
lines between all pumps. Each data frame contains:
</p>

<dl>
<dt><code>x</code></dt><dd><p>x coordinate</p>
</dd>
<dt><code>y</code></dt><dd><p>y coordinate</p>
</dd>
</dl>

<p><code>Snow.deaths2</code>: An alternative version of <code>Snow.deaths</code> correcting some possible
duplicate and missing cases, as described in <code>vignette("Snow_deaths-duplicates")</code>.
</p>
<p><code>Snow.dates</code>: A data frame of 44 observations and 3 variables from Table 1
of Snow (1855), giving the number of fatal attacks and number of deaths by date from Aug. 19 &ndash; Sept. 30, 1854.  There are a total of 616 deaths represented in both
columns <code>attacks</code> and <code>deaths</code>; of these, the date of the attack is unknown 
for 45 cases.
</p>


<h3>Details</h3>

<p>The scale of the source map is approx. 1:2000.  The <code>(x, y)</code> coordinate units are 100 meters,
with an arbitrary origin. 
</p>
<p>Of the data in the <code>Snow.dates</code> table, Snow says,
&ldquo;The deaths in the above table are compiled from the sources mentioned above in describing the map; but some deaths which were omitted from the map on account of the number of the house not being known, are included in the table.&rdquo; 
</p>
<p>One limitation of these data sets is the lack of exact street addresses. Another
is the lack of any data that would serve as a population denominator to
allow for  a comparison  of mortality  rates in  the Broad  Street pump  area as
opposed to  others.  
See Koch (2000), Koch (2004),  Koch
&amp; Denike (2009) and Tufte (1999), p. 27-37,  for further discussion. 
</p>


<h3>Source</h3>

<p>Tobler, W. (1994). Snow's Cholera Map, 
<code>http://www.ncgia.ucsb.edu/pubs/snow/snow.html</code>; data files were obtained from
<code>http://ncgia.ucsb.edu/Publications/Software/cholera/</code>, but these sites
seem to be down.
</p>
<p>The data in  these files were first digitized in 1992  by Rusty Dodson  of the NCGIA,
Santa  Barbara,  from the  map  included in  the  book by  John  Snow: &quot;Snow  on
Cholera...&quot;, London, Oxford University Press, 1936.  
</p>


<h3>References</h3>

<p>Koch, T. (2000). <em>Cartographies of Disease: Maps, Mapping, and Medicine</em>.
ESRI Press. 
ISBN: 9781589481206.
</p>
<p>Koch, T. (2004).
The Map as Intent: Variations on the Theme of John Snow
<em>Cartographica</em>, 39 (4), 1-14.
</p>
<p>Koch, T. and Denike, K. (2009).
Crediting his critics' concerns: Remaking John Snow's map of Broad Street
cholera, 1854.
<em>Social Science &amp; Medicine</em> 69, 1246-1251.
</p>
<p>Snow, J. (1885). <em>On the Mode of Communication of Cholera</em>.
London: John Churchill.
<a href="https://www.ph.ucla.edu/epi/snow/snowbook.html">https://www.ph.ucla.edu/epi/snow/snowbook.html</a>.
</p>
<p>Tufte, E. (1997). <em>Visual Explanations</em>. Cheshire, CT: Graphics Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SnowMap">SnowMap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Snow.deaths)
data(Snow.pumps)
data(Snow.streets)
data(Snow.polygons)
data(Snow.deaths)

## Plot deaths over time
require(lubridate)
clr &lt;- ifelse(Snow.dates$date &lt; mdy("09/08/1854"), "red", "darkgreen")
plot(deaths ~ date, data=Snow.dates, type="h", lwd=2, col=clr)
points(deaths ~ date, data=Snow.dates, cex=0.5, pch=16, col=clr)
text( mdy("09/08/1854"), 40, "Pump handle\nremoved Sept. 8", pos=4)


## draw Snow's map and data

SnowMap()

# add polygons
SnowMap(polygons=TRUE, main="Snow's Cholera Map with Pump Polygons")

# zoom in a bit, and show density estimate
SnowMap(xlim=c(7.5,16.5), ylim=c(7,16), polygons=TRUE, density=TRUE,
        main="Snow's Cholera Map, Annotated")


## re-do this the sp way... [thx: Stephane Dray]
library(sp)

# streets
slist &lt;- split(Snow.streets[,c("x","y")],as.factor(Snow.streets[,"street"]))
Ll1 &lt;- lapply(slist,Line)
Lsl1 &lt;- Lines(Ll1,"Street")
Snow.streets.sp &lt;- SpatialLines(list(Lsl1))
plot(Snow.streets.sp, col="gray")
title(main="Snow's Cholera Map of London (sp)")

# deaths
Snow.deaths.sp = SpatialPoints(Snow.deaths[,c("x","y")])
plot(Snow.deaths.sp, add=TRUE, col ='red', pch=15, cex=0.6)

# pumps
spp &lt;- SpatialPoints(Snow.pumps[,c("x","y")])
Snow.pumps.sp &lt;- SpatialPointsDataFrame(spp,Snow.pumps[,c("x","y")])
plot(Snow.pumps.sp, add=TRUE, col='blue', pch=17, cex=1.5)
text(Snow.pumps[,c("x","y")], labels=Snow.pumps$label, pos=1, cex=0.8)
</code></pre>

<hr>
<h2 id='SnowMap'>
Draw John Snow's Map of Cholera in London
</h2><span id='topic+SnowMap'></span><span id='topic+Splot'></span><span id='topic+Sdeaths'></span><span id='topic+Spumps'></span><span id='topic+Sstreets'></span><span id='topic+Sscale'></span><span id='topic+Spolygons'></span><span id='topic+Sdensity'></span>

<h3>Description</h3>

<p>The main function <code>SnowMap</code> draws versions of John Snow's map of cholera deaths in 
the South London area surrounding the Borad Street pump.
during the 1854 outbreak.
</p>
<p>It is a wrapper for the various subfunctions also listed here:<br />
<code>Splot</code> sets up the basic plot<br />
<code>Sstreets</code> draws the streets<br />
<code>Sdeaths</code> plots the deaths<br />
<code>Sdeaths</code> plots the pump locations<br />
<code>Sscale</code> draws the scale<br />
<code>Spolygons</code> draws the boundaries of the Voronoi polygons separating the pumps<br />
<code>Sdensity</code> draws and fills contours of the 2D density of deaths
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
SnowMap(xlim = c(3, 20), ylim = c(3, 20), 
        axis.labels = FALSE, main = "Snow's Cholera Map of London", 
        scale = TRUE, polygons = FALSE, density=FALSE,
        streets.args = list(col = "grey", lwd = 1), 
        deaths.args = list(col = "red", pch = 15, cex = 0.6), 
        pumps.args = list(col = "blue", pch = 17, cex = 1.5, cex.lab = 0.9), 
        scale.args = list(xs = 3.5, ys = 19.7), 
        polygons.args = list(col=NA, border="brown", lwd=2, lty=1),
        density.args=list(bandwidth=c(0.5,0.5), 
                  col1=rgb(0,1,0,0),
                  col2=rgb(1,0,0,.8))
)

Splot(xlim = c(3, 20), ylim = c(3, 20), 
      xlab = "", ylab = "", 
      axis.labels = FALSE, 
      main = "Snow's Cholera Map of London")

Sdeaths(col = "red", pch = 15, cex = 0.6)

Spumps(col = "blue", pch = 17, cex = 1.5, cex.lab = 0.9)

Sstreets(col = "gray", lwd = 1)

Sscale(xs = 3.5, ys = 19.7)

Spolygons(col=NA, border="brown", lwd=2, lty=1)

Sdensity(bandwidth = c(0.5, 0.5), col1 = rgb(0, 1, 0, 0), col2 = rgb(1, 0, 0, 0.8))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SnowMap_+3A_xlim">xlim</code></td>
<td>

<p>Limit for the horizontal axis.  Specify ranges smaller than the defaults
to zoom the plot.
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_ylim">ylim</code></td>
<td>

<p>Limit for the vertical axis.
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_axis.labels">axis.labels</code></td>
<td>

<p>Logical. Show axis tick mark labels?
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_main">main</code></td>
<td>

<p>Plot title
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_scale">scale</code></td>
<td>

<p>Logical; draw a scale (in meters) on the plot
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_polygons">polygons</code></td>
<td>

<p>Logical; Use <code>Spolygons</code> to draw the <code>Snow.polygons</code> on the plot?
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_density">density</code></td>
<td>

<p>Logical; Use <code>Sdensity</code> to draw the 2D bivariate density of deaths on the plot?
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_streets.args">streets.args</code></td>
<td>

<p>List of arguments passed to <code>Sstreets</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_deaths.args">deaths.args</code></td>
<td>

<p>List of arguments passed to <code>Sdeaths</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_pumps.args">pumps.args</code></td>
<td>

<p>List of arguments passed to <code>Spumps</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_scale.args">scale.args</code></td>
<td>

<p>List of arguments passed to <code>Sscale</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_polygons.args">polygons.args</code></td>
<td>

<p>List of arguments passed to <code>Spolygons</code>. Note that <code>col</code> here now refers to the fill colors,
passed to <code><a href="graphics.html#topic+polygon">polygon</a></code>. The <code>col</code> argument here can be a vector of up to
13 colors, one for each pump region.
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_density.args">density.args</code></td>
<td>

<p>List of arguments passed to <code>Sdensity</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_xlab">xlab</code></td>
<td>

<p>Label for horizontal axis
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_ylab">ylab</code></td>
<td>

<p>Label for vertical axis
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_col">col</code></td>
<td>

<p>Color of points and lines used by various functions
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_pch">pch</code></td>
<td>

<p>Point character used by by various functions
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_cex">cex</code></td>
<td>

<p>Character size used by by various functions
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_cex.lab">cex.lab</code></td>
<td>

<p>Character size for labels used by <code>Spumps</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_lwd">lwd</code></td>
<td>

<p>Line width used by by various functions
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_border">border</code></td>
<td>

<p>Color of border lines used by <code>Spolygons</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_xs">xs</code></td>
<td>

<p>x location of the scale used by <code>Sscale</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_ys">ys</code></td>
<td>

<p>y location of the scale used by <code>Sscale</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_lty">lty</code></td>
<td>

<p>Line type used by by various functions
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_bandwidth">bandwidth</code></td>
<td>

<p>Bandwidth used by <code><a href="KernSmooth.html#topic+bkde2D">bkde2D</a></code> in <code>Sdensity</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_col1">col1</code></td>
<td>

<p>Lower level of color range used by <code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code> in <code>Sdensity</code>
</p>
</td></tr>
<tr><td><code id="SnowMap_+3A_col2">col2</code></td>
<td>

<p>Upper level of color range used by <code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code> in <code>Sdensity</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p>Michael Friendly
</p>


<h3>References</h3>

<p>Snow, J. (1885). <em>On the Mode of Communication of Cholera</em>. London: John Churchill
</p>
<p>Thomas Coleman, &quot;John Snow Research project&quot;,
<code>https://www.hilerun.org/econ/papers/snow/index.html</code>
gives extensive analyses of Snow's data with R notebooks on Github.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Snow">Snow</a></code> for description of the data sets
</p>
<p><code><a href="KernSmooth.html#topic+bkde2D">bkde2D</a></code>,
<code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SnowMap()
SnowMap(axis.labels=TRUE)
SnowMap(deaths.args=list(col="darkgreen"))

SnowMap(polygons=TRUE, main="Snow's Cholera Map with Pump Polygons")

SnowMap(density=TRUE)

</code></pre>

<hr>
<h2 id='Virginis'>
John F. W. Herschel's Data on the Orbit of the Twin Stars <code class="reqn">\gamma</code> <em>Virginis</em>
</h2><span id='topic+Virginis'></span><span id='topic+Virginis.interp'></span>

<h3>Description</h3>

<p>In 1833 J. F. W. Herschel published two papers in the <em>Memoirs of the Royal Astronomical Society</em>
detailing his investigations of calculating the orbits of twin stars from observations of
their relative position angle and angular distance.  
</p>
<p>In the process, he invented the scatterplot, and the use of visual smoothing to obtain a reliable
curve that surpassed the accuracy of individual observations (Friendly &amp; Denis, 2005).
His data on the recordings of the twin stars <code class="reqn">\gamma</code> <em>Virginis</em> provide an
accessible example of his methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	data("Virginis")
	data("Virginis.interp")
</code></pre>


<h3>Format</h3>

<p><code>Virgins</code>: A data frame with 18 observations on the following 6 variables giving
the measurements of position angle and angular distance between the central (brightest)
star and its twin, recorded by various observers over more than 100 years. 
</p>

<dl>
<dt><code>year</code></dt><dd><p>year (&quot;epoch&quot;) of the observation, a decimal numeric vector</p>
</dd>
<dt><code>posangle</code></dt><dd><p>recorded position angle between the two stars, a numeric vector</p>
</dd>
<dt><code>distance</code></dt><dd><p>separation distance between the two stars, a numeric vector</p>
</dd>
<dt><code>weight</code></dt><dd><p>a subjective weight attributed to the accuracy of this observation, a numeric vector</p>
</dd>
<dt><code>notes</code></dt><dd><p>Herschel's notes on this observation, a character vector</p>
</dd>
<dt><code>authority</code></dt><dd><p>A simplified version of the notes giving just the attribution of authority of the observation, a character vector</p>
</dd>
</dl>

<p><code>Virgins.interp</code>: A data frame with 14 observations on the following 4 variables, giving the
position angles and angular distance that Herschel interpolated from his smoothed curve.
</p>

<dl>
<dt><code>year</code></dt><dd><p>year (&quot;epoch&quot;) of the observation, a decimal numeric vector</p>
</dd>
<dt><code>posangle</code></dt><dd><p>recorded position angle between the two stars, a numeric vector</p>
</dd>
<dt><code>distance</code></dt><dd><p>separation distance, calculated <code class="reqn">1/sqrt(velocity)</code></p>
</dd>
<dt><code>velocity</code></dt><dd><p>angular velocity, calculated as the instantaneous slopes of 
tangents to the smoothed curve, a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data in <code>Virginis</code> come from the table on p. 35 of the &ldquo;Micrometrical Measures&rdquo;
paper.  
</p>
<p>The <code>weight</code> variable was assigned by the package author, reflecting Herschel's comments
and for use in any weighted analysis.
</p>
<p>In the <code>notes</code> and <code>authority</code> variables, <code>"H"</code> refers to William Herschel
(John's farther, the discoverer of the planet Uranus), <code>"h"</code> refers to John Herschel
himself, and <code>"Sigma"</code>, rendered <code class="reqn">\Sigma</code> in the table on p. 35 refers to
Joseph Fraunhofer.
</p>
<p>The data in <code>Virginis.interp</code> come from Table 1 on p. 190 of the supplementary
paper.
</p>


<h3>Source</h3>

<p>Herschel, J. F. W. 
III. Micrometrical Measures of 364 Double Stars with a 7-feet Equatorial Acromatic Telescope, taken at Slough, in the years 1828, 1829, and 1830 
<em>Memoirs of the Royal Astronomical Society</em>, 1833, 5, 13-91.
</p>
<p>Herschel, J. F. W. 
On the Investigation of the Orbits of Revolving Double Stars: Being a Supplement to a Paper Entitled &quot;Micrometrical Measures of 364 Double Stars&quot; 
<em>Memoirs of the Royal Astronomical Society</em>, 1833, 5, 171-222.
</p>


<h3>References</h3>

<p>Friendly, M. &amp; Denis, D. 
The early origins and development of the scatterplot.
<em>Journal of the History of the Behavioral Sciences</em>, 
2005, 41, 103-130.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Virginis)
data(Virginis.interp)

# Herschel's interpolated curve
plot(posangle ~ year, data=Virginis.interp, 
	pch=15, type="b", col="red", cex=0.8, lwd=2,
	xlim=c(1710,1840), ylim=c(80, 170),
	ylab="Position angle (deg.)", xlab="Year",
	cex.lab=1.5)

# The data points, and indication of their uncertainty
points(posangle ~ year, data=Virginis, pch=16)
points(posangle ~ year, data=Virginis, cex=weight/2)

</code></pre>

<hr>
<h2 id='Wheat'>
Playfair's Data on Wages and the Price of Wheat
</h2><span id='topic+Wheat'></span><span id='topic+Wheat.monarchs'></span>

<h3>Description</h3>

<p>Playfair (1821) used a graph, showing parallel time-series of the price of wheat
and the typical weekly wage for a &quot;good mechanic&quot; from 1565 to 1821 to argue
that working men had never been as well-off in terms of purchasing power as
they had become toward the end of this period. 
</p>
<p>His graph is a classic in the history of data visualization, but commits the
sin of showing two non-commensurable Y variables on different axes.
Scatterplots of wages vs. price or plots of ratios (e.g., wages/price) 
are in some ways better, but both of these ideas were unknown in 1821.
</p>
<p>In this version, information on the reigns of British monarchs is provided
in a separate data.frame, <code>Wheat.monarch</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Wheat)
data(Wheat.monarchs)
</code></pre>


<h3>Format</h3>

<p><code>Wheat</code>
A data frame with 53 observations on the following 3 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>Year, in intervals of 5 from 1565 to 1821: a numeric vector</p>
</dd>
<dt><code>Wheat</code></dt><dd><p>Price of Wheat (Shillings/Quarter bushel): a numeric vector</p>
</dd>
<dt><code>Wages</code></dt><dd><p>Weekly wage (Shillings): a numeric vector</p>
</dd>
</dl>

<p><code>Wheat.monarchs</code>
A data frame with 12 observations on the following 4 variables.
</p>

<dl>
<dt><code>name</code></dt><dd><p>Reigning monarch, a factor with levels <code>Anne</code> <code>Charles I</code> <code>Charles II</code> <code>Cromwell</code> <code>Elizabeth</code> <code>George I</code> <code>George II</code> <code>George III</code> <code>George IV</code> <code>James I</code> <code>James II</code> <code>W&amp;M</code></p>
</dd>
<dt><code>start</code></dt><dd><p>Starting year of reign, a numeric vector</p>
</dd>
<dt><code>end</code></dt><dd><p>Starting year of reign, a numeric vector</p>
</dd>
<dt><code>commonwealth</code></dt><dd><p>A binary variable indicating the period of the Commonwealth under Cromwell</p>
</dd>
</dl>



<h3>Source</h3>

<p>Playfair, W. (1821). <em>Letter on our Agricultural Distresses, Their Causes and Remedies</em>. London: W. Sams, 1821
</p>
<p>Data values:
originally digitized from <a href="http://datavis.ca/gallery/images/playfair-wheat1.gif">http://datavis.ca/gallery/images/playfair-wheat1.gif</a>
now taken from <a href="http://mbostock.github.io/protovis/ex/wheat.js">http://mbostock.github.io/protovis/ex/wheat.js</a>
</p>


<h3>References</h3>

<p>Friendly, M. &amp; Denis, D. (2005). The early origins and development of the scatterplot 
<em>Journal of the History of the Behavioral Sciences</em>, 
41, 103-130.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Wheat)

data(Wheat)

# ------------------------------------
# Playfair's graph, largely reproduced
# ------------------------------------

# convenience function to fill area under a curve down to a minimum value
fillpoly &lt;- function(x,y, low=min(y),  ...) {
    n &lt;- length(x)
    polygon( c(x, x[n], x[1]), c(y, low, low), ...)
}

# For best results, this graph should be viewed with width ~ 2 * height
# Note use of type='s' to plot a step function for Wheat
#   and panel.first to provide a background grid()
#     The curve for Wages is plotted after the polygon below it is filled
with(Wheat, {
    plot(Year, Wheat, type="s", ylim=c(0,105), 
        ylab="Price of the Quarter of Wheat (shillings)", 
        panel.first=grid(col=gray(.9), lty=1))
    fillpoly(Year, Wages, low=0, col="lightskyblue", border=NA)
    lines(Year, Wages, lwd=3, col="red")
    })


# add some annotations
text(1625,10, "Weekly wages of a good mechanic", cex=0.8, srt=3, col="red")

# cartouche
text(1650, 85, "Chart", cex=2, font=2)
text(1650, 70, 
	paste("Shewing at One View", 
        "The Price of the Quarter of Wheat", 
        "&amp; Wages of Labor by the Week", 
        "from the Year 1565 to 1821",
        "by William Playfair",
        sep="\n"), font=3)

# add the time series bars to show reigning monarchs
# distinguish Cromwell visually, as Playfair did
with(Wheat.monarchs, {
	y &lt;- ifelse( !commonwealth &amp; (!seq_along(start) %% 2), 102, 104)
	segments(start, y, end, y, col="black", lwd=7, lend=1)
	segments(start, y, end, y, col=ifelse(commonwealth, "white", NA), lwd=4, lend=1)
	text((start+end)/2, y-2, name, cex=0.5)
	})

# -----------------------------------------
# plot the labor cost of a quarter of wheat
# -----------------------------------------
Wheat1 &lt;- within(na.omit(Wheat), {Labor=Wheat/Wages})
with(Wheat1, {
	plot(Year, Labor, type='b', pch=16, cex=1.5, lwd=1.5, 
	     ylab="Labor cost of a Quarter of Wheat (weeks)",
	     ylim=c(1,12.5));
	lines(lowess(Year, Labor), col="red", lwd=2)
	})
	
# cartouche
text(1740, 10, "Chart", cex=2, font=2)
text(1740, 8.5, 
	paste("Shewing at One View", 
        "The Work Required to Purchase", 
        "One Quarter of Wheat", 
        sep="\n"), cex=1.5, font=3)

with(Wheat.monarchs, {
	y &lt;- ifelse( !commonwealth &amp; (!seq_along(start) %% 2), 12.3, 12.5)
	segments(start, y, end, y, col="black", lwd=7, lend=1)
	segments(start, y, end, y, col=ifelse(commonwealth, "white", NA), lwd=4, lend=1)
	text((start+end)/2, y-0.2, name, cex=0.5)
	})
</code></pre>

<hr>
<h2 id='Yeast'>
Student's (1906) Yeast Cell Counts
</h2><span id='topic+Yeast'></span><span id='topic+YeastD.mat'></span>

<h3>Description</h3>

<p>Counts of the number of yeast cells were made each of 400 regions in a 20 x 20 grid on a microscope
slide, comprising a 1 sq. mm. area.
This experiment was repeated four times, giving samples A, B, C and D.
</p>
<p>Student (1906) used these data to investigate the errors in random sampling.
He says &quot;there are two sources of error: (a) the drop taken may not be representative
of the bulk of the liquid; (b) the distribution of the cells over the area 
which is examined is never exactly uniform, so that there is an 'error of
random sampling.'&quot;
</p>
<p>The data in the paper are provided in the form of discrete frequency distributions
for the four samples.  Each shows the frequency distribution squares containing
a <code>count</code> of 0, 1, 2, ... yeast cells. These are combined here in <code>Yeast</code>. 
In addition, he gives a table
(Table I) showing the actual number of yeast cells counted in the 20 x 20
grid for sample D, given here as <code>YeastD.mat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	data(Yeast)
	data(YeastD.mat)
	</code></pre>


<h3>Format</h3>

<p><code>Yeast</code>: A frequency data frame with 36 observations on the following 3 variables,
giving the frequencies of 
</p>

<dl>
<dt><code>sample</code></dt><dd><p>Sample identifier, a factor with levels <code>A</code> <code>B</code> <code>C</code> <code>D</code></p>
</dd>
<dt><code>count</code></dt><dd><p>The number of yeast cells counted in a square</p>
</dd>
<dt><code>freq</code></dt><dd><p>The number of squares with the given <code>count</code></p>
</dd>
</dl>

<p><code>YeastD.mat</code>: A 20 x 20 matrix containing the count of yeast cells in each square for
sample D.  
</p>


<h3>Details</h3>

<p>Student considers the distribution of a total of <code class="reqn">Nm</code> particles distributed over
<code class="reqn">N</code> unit areas with an average of <code class="reqn">m</code> particles per unit area.
With uniform mixing, for a given particle, the probability of it falling on any one
area is <code class="reqn">p = 1/N</code>, and not falling on that area is <code class="reqn">q = 1 - 1/N</code>.
He derives the probability distribution of 0, 1, 2, 3, ...
particles on a single unit area from the binomial expansion of <code class="reqn">(p + q)^{mN}</code>.
</p>


<h3>Source</h3>

<p>D. J. Hand, F. Daly,  D. Lunn, K. McConway and E. Ostrowski (1994). 
<em>A Handbook of Small Data Sets</em>.
London: Chapman &amp; Hall.
The data were originally found at:
https://www2.stat.duke.edu/courses/Spring98/sta113/Data/Hand/yeast.dat
</p>


<h3>References</h3>

<p>&quot;Student&quot; (1906)
On the error of counting with a haemocytometer.
Biometrika, 5, 351-360.
<a href="http://www.medicine.mcgill.ca/epidemiology/hanley/c626/Student_counting.pdf">http://www.medicine.mcgill.ca/epidemiology/hanley/c626/Student_counting.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Yeast)

require(lattice)
# basic bar charts 
# TODO: frequencies should start at 0, not 1.
barchart(count~freq|sample, data=Yeast, ylab="Number of Cells", xlab="Frequency")
barchart(freq~count|sample, data=Yeast, xlab="Number of Cells", ylab="Frequency",
	horizontal=FALSE, origin=0)

# same, using xyplot
xyplot(freq~count|sample, data=Yeast, xlab="Number of Cells", ylab="Frequency",
	horizontal=FALSE, origin=0, type="h", lwd=10)
</code></pre>

<hr>
<h2 id='ZeaMays'>
Darwin's Heights of Cross- and Self-fertilized Zea May Pairs
</h2><span id='topic+ZeaMays'></span>

<h3>Description</h3>

<p>Darwin (1876) studied the growth of pairs of zea may (aka corn)
seedlings, one produced by cross-fertilization and the other
produced by self-fertilization, but otherwise grown under identical 
conditions.
His goal was to demonstrate the greater vigour of the cross-fertilized plants.
The data recorded are the final height (inches, to the nearest 1/8th)  of the plants in each pair.
</p>
<p>In the <em>Design of Experiments</em>, Fisher (1935) used these data to illustrate
a paired t-test (well, a one-sample test on the mean difference, <code>cross - self</code>).
Later in the book (section 21), he used this data to illustrate an early example of a non-parametric permutation
test, treating each paired difference as having (randomly) either a positive or negative sign. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ZeaMays)</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 4 variables.
</p>

<dl>
<dt><code>pair</code></dt><dd><p>pair number, a numeric vector</p>
</dd>
<dt><code>pot</code></dt><dd><p>pot, a factor with levels <code>1</code> <code>2</code> <code>3</code> <code>4</code></p>
</dd>
<dt><code>cross</code></dt><dd><p>height of cross fertilized plant, a numeric vector</p>
</dd>
<dt><code>self</code></dt><dd><p>height of self fertilized plant, a numeric vector</p>
</dd>
<dt><code>diff</code></dt><dd><p><code>cross - self</code> for each pair</p>
</dd>
</dl>



<h3>Details</h3>

<p>In addition to the standard paired t-test,
several types of non-parametric tests can be contemplated:
</p>
<p>(a) Permutation test, where the values of, say <code>self</code> are permuted and <code>diff=cross - self</code>
is calculated for each permutation.  There are 15! permutations, but a reasonably
large number of random permutations would suffice.  But this doesn't take the paired samples
into account.
</p>
<p>(b) Permutation test based on assigning each <code>abs(diff)</code> a + or - sign, and calculating the mean(diff).
There are <code class="reqn">2^{15}</code> such possible values.  This is essentially what Fisher 
proposed.  The p-value for the test is the proportion of absolute mean differences
under such randomization which exceed the observed mean difference.
</p>
<p>(c) Wilcoxon signed rank test: tests the hypothesis that the median signed rank of the <code>diff</code> is zero,
or that the distribution of <code>diff</code> is symmetric about 0, vs. a location shifted alternative.
</p>


<h3>Source</h3>

<p>Darwin, C. (1876). <em>The Effect of Cross- and Self-fertilization in the Vegetable Kingdom</em>,
2nd Ed. London: John Murray.
</p>
<p>Andrews, D. and Herzberg, A. (1985) <em>Data:
a collection of problems from many fields for the student and research worker</em>.
New York: Springer. Data retrieved from: <code>https://www.stat.cmu.edu/StatDat/</code>
</p>


<h3>References</h3>

<p>Fisher, R. A. (1935). <em>The Design of Experiments</em>. London: Oliver &amp; Boyd.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>
</p>
<p><code><a href="coin.html#topic+independence_test">independence_test</a></code> in the <code>coin</code> package, a general framework for conditional inference procedures
(permutation tests)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ZeaMays)

##################################
## Some preliminary exploration ##
##################################
boxplot(ZeaMays[,c("cross", "self")], ylab="Height (in)", xlab="Fertilization")

# examine large individual diff/ces
largediff &lt;- subset(ZeaMays, abs(diff) &gt; 2*sd(abs(diff)))
with(largediff, segments(1, cross, 2, self, col="red"))

# plot cross vs. self.  NB: unusual trend and some unusual points
with(ZeaMays, plot(self, cross, pch=16, cex=1.5))
abline(lm(cross ~ self, data=ZeaMays), col="red", lwd=2)

# pot effects ?
 anova(lm(diff ~ pot, data=ZeaMays))

##############################
## Tests of mean difference ##
##############################
# Wilcoxon signed rank test
# signed ranks:
with(ZeaMays, sign(diff) * rank(abs(diff)))
wilcox.test(ZeaMays$cross, ZeaMays$self, conf.int=TRUE, exact=FALSE)

# t-tests
with(ZeaMays, t.test(cross, self))
with(ZeaMays, t.test(diff))

mean(ZeaMays$diff)
# complete permutation distribution of diff, for all 2^15 ways of assigning
# one value to cross and the other to self (thx: Bert Gunter)
N &lt;- nrow(ZeaMays)
allmeans &lt;- as.matrix(expand.grid(as.data.frame(
                         matrix(rep(c(-1,1),N), nr =2))))  %*% abs(ZeaMays$diff) / N

# upper-tail p-value
sum(allmeans &gt; mean(ZeaMays$diff)) / 2^N
# two-tailed p-value
sum(abs(allmeans) &gt; mean(ZeaMays$diff)) / 2^N

hist(allmeans, breaks=64, xlab="Mean difference, cross-self",
	main="Histogram of all mean differences")
abline(v=c(1, -1)*mean(ZeaMays$diff), col="red", lwd=2, lty=1:2)

plot(density(allmeans), xlab="Mean difference, cross-self",
	main="Density plot of all mean differences")
abline(v=c(1, -1)*mean(ZeaMays$diff), col="red", lwd=2, lty=1:2)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
