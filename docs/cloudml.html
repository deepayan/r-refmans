<!DOCTYPE html><html><head><title>Help for package cloudml</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cloudml}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cloudml-package'><p>Interface to the Google Cloud Machine Learning Platform</p></a></li>
<li><a href='#cloudml_deploy'><p>Deploy SavedModel to CloudML</p></a></li>
<li><a href='#cloudml_predict'><p>Perform Prediction over a CloudML Model.</p></a></li>
<li><a href='#cloudml_train'><p>Train a model using Cloud ML</p></a></li>
<li><a href='#gcloud_exec'><p>Executes a Google Cloud Command</p></a></li>
<li><a href='#gcloud_init'><p>Initialize the Google Cloud SDK</p></a></li>
<li><a href='#gcloud_install'><p>Install the Google Cloud SDK</p></a></li>
<li><a href='#gcloud_terminal'><p>Create an RStudio terminal with access to the Google Cloud SDK</p></a></li>
<li><a href='#gcloud_version'><p>Gcloud version</p></a></li>
<li><a href='#gs_copy'><p>Copy files to / from Google Storage</p></a></li>
<li><a href='#gs_data_dir'><p>Google storage bucket path that syncs to local storage when not</p>
running on CloudML.</a></li>
<li><a href='#gs_data_dir_local'><p>Get a local path to the contents of Google Storage bucket</p></a></li>
<li><a href='#gs_local_dir'><p>Alias to gs_data_dir_local() function</p></a></li>
<li><a href='#gs_rsync'><p>Synchronize content of two buckets/directories</p></a></li>
<li><a href='#gsutil_exec'><p>Executes a Google Utils Command</p></a></li>
<li><a href='#job_cancel'><p>Cancel a job</p></a></li>
<li><a href='#job_collect'><p>Collect job output</p></a></li>
<li><a href='#job_list'><p>List all jobs</p></a></li>
<li><a href='#job_status'><p>Current status of a job</p></a></li>
<li><a href='#job_stream_logs'><p>Show job log stream</p></a></li>
<li><a href='#job_trials'><p>Current trials of a job</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Interface to the Google Cloud Machine Learning Platform</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Interface to the Google Cloud Machine Learning Platform
  <a href="https://cloud.google.com/ml-engine">https://cloud.google.com/ml-engine</a>, which provides cloud tools for training machine
  learning models.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0), tfruns (&ge; 1.3)</td>
</tr>
<tr>
<td>Imports:</td>
<td>config, jsonlite, packrat, processx, rprojroot, rstudioapi,
tools, utils, withr, yaml</td>
</tr>
<tr>
<td>Suggests:</td>
<td>tensorflow (&ge; 1.4.2), keras (&ge; 2.1.2), knitr, testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Python (&gt;= 2.7.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-09-03 19:12:58 UTC; dfalbel</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel Falbel [aut, cre],
  Javier Luraschi [aut],
  JJ Allaire [aut],
  Kevin Ushey [aut],
  RStudio [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel Falbel &lt;daniel@rstudio.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-09-03 21:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='cloudml-package'>Interface to the Google Cloud Machine Learning Platform</h2><span id='topic+cloudml-package'></span><span id='topic+_PACKAGE'></span><span id='topic+cloudml'></span>

<h3>Description</h3>

<p>The <strong>cloudml</strong> package provides an R interface to <a href="https://cloud.google.com/ml-engine/">Google Cloud Machine Learning Engine</a>, a managed service that
enables:
</p>

<ul>
<li><p> Scalable training of models built with the
<a href="https://keras.rstudio.com/">keras</a>,
<a href="https://tensorflow.rstudio.com/tfestimators">tfestimators</a>, and
<a href="https://tensorflow.rstudio.com/">tensorflow</a> R packages.
</p>
</li>
<li><p> On-demand access to training on GPUs, including the new <a href="http://www.nvidia.com/object/tesla-p100.html">Tesla P100 GPUs</a> from NVIDIAÂ®.
</p>
</li>
<li><p> Hyperparameter tuning to optimize key attributes of model architectures in
order to maximize predictive accuracy.
</p>
</li>
<li><p> Deployment of trained models to the Google global prediction platform that
can support thousands of users and TBs of data.
</p>
</li></ul>



<h3>Details</h3>

<p>CloudML is a managed service where you pay only for the hardware resources
that you use. Prices vary depending on configuration (e.g. CPU vs. GPU vs.
multiple GPUs). See <a href="https://cloud.google.com/ml-engine/pricing">https://cloud.google.com/ml-engine/pricing</a> for
additional details.
</p>
<p>For documentation on using the R interface to CloudML see the package website
at <a href="https://tensorflow.rstudio.com/tools/cloudml/">https://tensorflow.rstudio.com/tools/cloudml/</a>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Daniel Falbel <a href="mailto:daniel@rstudio.com">daniel@rstudio.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Javier Luraschi
</p>
</li>
<li><p> JJ Allaire
</p>
</li>
<li><p> Kevin Ushey
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p>  RStudio [copyright holder]
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://tensorflow.rstudio.com/tools/cloudml/">https://tensorflow.rstudio.com/tools/cloudml/</a>
</p>

<hr>
<h2 id='cloudml_deploy'>Deploy SavedModel to CloudML</h2><span id='topic+cloudml_deploy'></span>

<h3>Description</h3>

<p>Deploys a SavedModel to CloudML model for online predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloudml_deploy(export_dir_base, name, version = paste0(name, "_1"),
  region = NULL, config = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cloudml_deploy_+3A_export_dir_base">export_dir_base</code></td>
<td>
<p>A string containing a directory containing an
exported SavedModels. Consider using <code><a href="tensorflow.html#topic+export_savedmodel">tensorflow::export_savedmodel()</a></code>
to export this SavedModel.</p>
</td></tr>
<tr><td><code id="cloudml_deploy_+3A_name">name</code></td>
<td>
<p>The name for this model (required)</p>
</td></tr>
<tr><td><code id="cloudml_deploy_+3A_version">version</code></td>
<td>
<p>The version for this model. Versions start with a letter and
contain only letters, numbers and underscores. Defaults to name_1</p>
</td></tr>
<tr><td><code id="cloudml_deploy_+3A_region">region</code></td>
<td>
<p>The region to be used to deploy this model.</p>
</td></tr>
<tr><td><code id="cloudml_deploy_+3A_config">config</code></td>
<td>
<p>A list, <code>YAML</code> or <code>JSON</code> configuration file as described
<a href="https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs">https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs</a>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+cloudml_predict">cloudml_predict()</a></code>
</p>
<p>Other CloudML functions: <code><a href="#topic+cloudml_predict">cloudml_predict</a></code>,
<code><a href="#topic+cloudml_train">cloudml_train</a></code>
</p>

<hr>
<h2 id='cloudml_predict'>Perform Prediction over a CloudML Model.</h2><span id='topic+cloudml_predict'></span>

<h3>Description</h3>

<p>Perform online prediction over a CloudML model, usually, created using
<code><a href="#topic+cloudml_deploy">cloudml_deploy()</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloudml_predict(instances, name, version = paste0(name, "_1"),
  verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cloudml_predict_+3A_instances">instances</code></td>
<td>
<p>A list of instances to be predicted. While predicting
a single instance, list wrapping this single instance is still expected.</p>
</td></tr>
<tr><td><code id="cloudml_predict_+3A_name">name</code></td>
<td>
<p>The name for this model (required)</p>
</td></tr>
<tr><td><code id="cloudml_predict_+3A_version">version</code></td>
<td>
<p>The version for this model. Versions start with a letter and
contain only letters, numbers and underscores. Defaults to name_1</p>
</td></tr>
<tr><td><code id="cloudml_predict_+3A_verbose">verbose</code></td>
<td>
<p>Should additional information be reported?</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+cloudml_deploy">cloudml_deploy()</a></code>
</p>
<p>Other CloudML functions: <code><a href="#topic+cloudml_deploy">cloudml_deploy</a></code>,
<code><a href="#topic+cloudml_train">cloudml_train</a></code>
</p>

<hr>
<h2 id='cloudml_train'>Train a model using Cloud ML</h2><span id='topic+cloudml_train'></span>

<h3>Description</h3>

<p>Upload a TensorFlow application to Google Cloud, and use that application to
train a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloudml_train(file = "train.R", master_type = NULL, flags = NULL,
  region = NULL, config = NULL, collect = "ask", dry_run = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cloudml_train_+3A_file">file</code></td>
<td>
<p>File to be used as entrypoint for training.</p>
</td></tr>
<tr><td><code id="cloudml_train_+3A_master_type">master_type</code></td>
<td>
<p>Training master node machine type. &quot;standard&quot; provides a
basic machine configuration suitable for training simple models with small
to moderate datasets. See the documentation at
<a href="https://cloud.google.com/ml-engine/docs/tensorflow/machine-types#machine_type_table">https://cloud.google.com/ml-engine/docs/tensorflow/machine-types#machine_type_table</a>
for details on available machine types.</p>
</td></tr>
<tr><td><code id="cloudml_train_+3A_flags">flags</code></td>
<td>
<p>Named list with flag values (see <code><a href="tfruns.html#topic+flags">flags()</a></code>) or path
to YAML file containing flag values.</p>
</td></tr>
<tr><td><code id="cloudml_train_+3A_region">region</code></td>
<td>
<p>The region to be used for training.</p>
</td></tr>
<tr><td><code id="cloudml_train_+3A_config">config</code></td>
<td>
<p>A list, <code>YAML</code> or <code>JSON</code> configuration file as described
<a href="https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs">https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs</a>.</p>
</td></tr>
<tr><td><code id="cloudml_train_+3A_collect">collect</code></td>
<td>
<p>Logical. If TRUE, collect job when training is completed
(blocks waiting for the job to complete). The default (<code>"ask"</code>) will
interactively prompt the user whether to collect the results or not.</p>
</td></tr>
<tr><td><code id="cloudml_train_+3A_dry_run">dry_run</code></td>
<td>
<p>Triggers a local dry run over the deployment phase to
validate packages and packing work as expected.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+job_status">job_status()</a></code>, <code><a href="#topic+job_collect">job_collect()</a></code>, <code><a href="#topic+job_cancel">job_cancel()</a></code>
</p>
<p>Other CloudML functions: <code><a href="#topic+cloudml_deploy">cloudml_deploy</a></code>,
<code><a href="#topic+cloudml_predict">cloudml_predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(cloudml)

gcloud_install()
job &lt;- cloudml_train("train.R")

## End(Not run)

</code></pre>

<hr>
<h2 id='gcloud_exec'>Executes a Google Cloud Command</h2><span id='topic+gcloud_exec'></span>

<h3>Description</h3>

<p>Executes a Google Cloud command with the given parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcloud_exec(..., args = NULL, echo = TRUE, dry_run = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcloud_exec_+3A_...">...</code></td>
<td>
<p>Parameters to use specified based on position.</p>
</td></tr>
<tr><td><code id="gcloud_exec_+3A_args">args</code></td>
<td>
<p>Parameters to use specified as a list.</p>
</td></tr>
<tr><td><code id="gcloud_exec_+3A_echo">echo</code></td>
<td>
<p>Echo command output to console.</p>
</td></tr>
<tr><td><code id="gcloud_exec_+3A_dry_run">dry_run</code></td>
<td>
<p>Echo but not execute the command?</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
gcloud_exec("help", "info")

## End(Not run)
</code></pre>

<hr>
<h2 id='gcloud_init'>Initialize the Google Cloud SDK</h2><span id='topic+gcloud_init'></span>

<h3>Description</h3>

<p>Initialize the Google Cloud SDK
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcloud_init()
</code></pre>


<h3>See Also</h3>

<p>Other Google Cloud SDK functions: <code><a href="#topic+gcloud_install">gcloud_install</a></code>,
<code><a href="#topic+gcloud_terminal">gcloud_terminal</a></code>
</p>

<hr>
<h2 id='gcloud_install'>Install the Google Cloud SDK</h2><span id='topic+gcloud_install'></span>

<h3>Description</h3>

<p>Installs the Google Cloud SDK which enables CloudML operations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcloud_install(update = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcloud_install_+3A_update">update</code></td>
<td>
<p>Attempt to update an existing installation.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Google Cloud SDK functions: <code><a href="#topic+gcloud_init">gcloud_init</a></code>,
<code><a href="#topic+gcloud_terminal">gcloud_terminal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(cloudml)
gcloud_install()

## End(Not run)

</code></pre>

<hr>
<h2 id='gcloud_terminal'>Create an RStudio terminal with access to the Google Cloud SDK</h2><span id='topic+gcloud_terminal'></span>

<h3>Description</h3>

<p>Create an RStudio terminal with access to the Google Cloud SDK
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcloud_terminal(command = NULL, clear = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcloud_terminal_+3A_command">command</code></td>
<td>
<p>Command to send to terminal</p>
</td></tr>
<tr><td><code id="gcloud_terminal_+3A_clear">clear</code></td>
<td>
<p>Clear terminal buffer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Terminal id (invisibly)
</p>


<h3>See Also</h3>

<p>Other Google Cloud SDK functions: <code><a href="#topic+gcloud_init">gcloud_init</a></code>,
<code><a href="#topic+gcloud_install">gcloud_install</a></code>
</p>

<hr>
<h2 id='gcloud_version'>Gcloud version</h2><span id='topic+gcloud_version'></span>

<h3>Description</h3>

<p>Get version of Google Cloud SDK components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcloud_version()
</code></pre>


<h3>Value</h3>

<p>a list with the version of each component.
</p>

<hr>
<h2 id='gs_copy'>Copy files to / from Google Storage</h2><span id='topic+gs_copy'></span>

<h3>Description</h3>

<p>Use the <code>gsutil cp</code> command to copy data between your local file system and
the cloud, copy data within the cloud, and copy data between cloud storage
providers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs_copy(source, destination, recursive = FALSE, echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gs_copy_+3A_source">source</code></td>
<td>
<p>The file to be copied. This can be either a path on the local
filesystem, or a Google Storage URI (e.g. <code>gs://[BUCKET_NAME]/[FILENAME.CSV]</code>).</p>
</td></tr>
<tr><td><code id="gs_copy_+3A_destination">destination</code></td>
<td>
<p>The location where the <code>source</code> file should be copied to. This can be
either a path on the local filesystem, or a Google Storage URI (e.g.
<code>gs://[BUCKET_NAME]/[FILENAME.CSV]</code>).</p>
</td></tr>
<tr><td><code id="gs_copy_+3A_recursive">recursive</code></td>
<td>
<p>Boolean; perform a recursive copy? This must be specified if you intend on
copying directories.</p>
</td></tr>
<tr><td><code id="gs_copy_+3A_echo">echo</code></td>
<td>
<p>Echo command output to console.</p>
</td></tr>
</table>

<hr>
<h2 id='gs_data_dir'>Google storage bucket path that syncs to local storage when not
running on CloudML.</h2><span id='topic+gs_data_dir'></span>

<h3>Description</h3>

<p>Refer to data within a Google Storage bucket. When running on CloudML
the bucket will be read from directly. Otherwise, the bucket will be
automatically synchronized to a local directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs_data_dir(url, local_dir = "gs", force_sync = FALSE, echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gs_data_dir_+3A_url">url</code></td>
<td>
<p>Google Storage bucket URL (e.g. <code>gs://&lt;your-bucket&gt;</code>).</p>
</td></tr>
<tr><td><code id="gs_data_dir_+3A_local_dir">local_dir</code></td>
<td>
<p>Local directory to synchonize Google Storage bucket(s) to.</p>
</td></tr>
<tr><td><code id="gs_data_dir_+3A_force_sync">force_sync</code></td>
<td>
<p>Force local synchonization even if the data
directory already exists.</p>
</td></tr>
<tr><td><code id="gs_data_dir_+3A_echo">echo</code></td>
<td>
<p>Echo command output to console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is suitable for use in TensorFlow APIs that accept
gs:// URLs (e.g. TensorFlow datasets). However, many package functions
accept only local filesystem paths as input (rather than
gs:// URLs). For these cases you can the <code><a href="#topic+gs_data_dir_local">gs_data_dir_local()</a></code> function,
which will always synchronize gs:// buckets to the local filesystem and
provide a local path interface to their contents.
</p>


<h3>Value</h3>

<p>Path to contents of data directory.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gs_data_dir_local">gs_data_dir_local()</a></code>
</p>

<hr>
<h2 id='gs_data_dir_local'>Get a local path to the contents of Google Storage bucket</h2><span id='topic+gs_data_dir_local'></span>

<h3>Description</h3>

<p>Provides a local filesystem interface to Google Storage buckets. Many
package functions accept only local filesystem paths as input (rather than
gs:// URLs). For these cases the <code>gcloud_path()</code> function will synchronize
gs:// buckets to the local filesystem and provide a local path interface
to their contents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs_data_dir_local(url, local_dir = "gs", echo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gs_data_dir_local_+3A_url">url</code></td>
<td>
<p>Google Storage bucket URL (e.g. <code>gs://&lt;your-bucket&gt;</code>).</p>
</td></tr>
<tr><td><code id="gs_data_dir_local_+3A_local_dir">local_dir</code></td>
<td>
<p>Local directory to synchonize Google Storage bucket(s) to.</p>
</td></tr>
<tr><td><code id="gs_data_dir_local_+3A_echo">echo</code></td>
<td>
<p>Echo command output to console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you pass a local path as the <code>url</code> it will be returned
unmodified. This allows you to for example use a training flag for the
location of data which points to a local directory during
development and a Google Cloud bucket during cloud training.
</p>


<h3>Value</h3>

<p>Local path to contents of bucket.
</p>


<h3>Note</h3>

<p>For APIs that accept gs:// URLs directly (e.g. TensorFlow datasets)
you should use the <code><a href="#topic+gs_data_dir">gs_data_dir()</a></code> function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gs_data_dir">gs_data_dir()</a></code>
</p>

<hr>
<h2 id='gs_local_dir'>Alias to gs_data_dir_local() function</h2><span id='topic+gs_local_dir'></span>

<h3>Description</h3>

<p>This function is deprecated, please use <code><a href="#topic+gs_data_dir_local">gs_data_dir_local()</a></code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs_local_dir(url, local_dir = "gs", echo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gs_local_dir_+3A_url">url</code></td>
<td>
<p>Google Storage bucket URL (e.g. <code>gs://&lt;your-bucket&gt;</code>).</p>
</td></tr>
<tr><td><code id="gs_local_dir_+3A_local_dir">local_dir</code></td>
<td>
<p>Local directory to synchonize Google Storage bucket(s) to.</p>
</td></tr>
<tr><td><code id="gs_local_dir_+3A_echo">echo</code></td>
<td>
<p>Echo command output to console.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gs_data_dir_local">gs_data_dir_local()</a></code>
</p>

<hr>
<h2 id='gs_rsync'>Synchronize content of two buckets/directories</h2><span id='topic+gs_rsync'></span>

<h3>Description</h3>

<p>The <code>gs_rsync</code> function makes the contents under <code>destination</code> the same
as the contents under <code>source</code>, by copying any missing files/objects (or
those whose data has changed), and (if the <code>delete</code> option is specified)
deleting any extra files/objects. <code>source</code> must specify a directory, bucket,
or bucket subdirectory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs_rsync(source, destination, delete = FALSE, recursive = FALSE,
  parallel = TRUE, dry_run = FALSE, options = NULL, echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gs_rsync_+3A_source">source</code></td>
<td>
<p>The file to be copied. This can be either a path on the local
filesystem, or a Google Storage URI (e.g. <code>gs://[BUCKET_NAME]/[FILENAME.CSV]</code>).</p>
</td></tr>
<tr><td><code id="gs_rsync_+3A_destination">destination</code></td>
<td>
<p>The location where the <code>source</code> file should be copied to. This can be
either a path on the local filesystem, or a Google Storage URI (e.g.
<code>gs://[BUCKET_NAME]/[FILENAME.CSV]</code>).</p>
</td></tr>
<tr><td><code id="gs_rsync_+3A_delete">delete</code></td>
<td>
<p>Delete extra files under <code>destination</code> not found under
<code>source</code> By default extra files are not deleted.</p>
</td></tr>
<tr><td><code id="gs_rsync_+3A_recursive">recursive</code></td>
<td>
<p>Causes directories, buckets, and bucket subdirectories to
be synchronized recursively. If you neglect to use this option
<code>gs_rsync()</code> will make only the top-level directory in the source and
destination URLs match, skipping any sub-directories.</p>
</td></tr>
<tr><td><code id="gs_rsync_+3A_parallel">parallel</code></td>
<td>
<p>Causes synchronization to run in parallel. This can
significantly improve performance if you are performing operations on a
large number of files over a reasonably fast network connection.</p>
</td></tr>
<tr><td><code id="gs_rsync_+3A_dry_run">dry_run</code></td>
<td>
<p>Causes rsync to run in &quot;dry run&quot; mode, i.e., just outputting
what would be copied or deleted without actually doing any
copying/deleting.</p>
</td></tr>
<tr><td><code id="gs_rsync_+3A_options">options</code></td>
<td>
<p>Character vector of additional command line options to the
gsutil rsync command (as specified at
<a href="https://cloud.google.com/storage/docs/gsutil/commands/rsync">https://cloud.google.com/storage/docs/gsutil/commands/rsync</a>).</p>
</td></tr>
<tr><td><code id="gs_rsync_+3A_echo">echo</code></td>
<td>
<p>Echo command output to console.</p>
</td></tr>
</table>

<hr>
<h2 id='gsutil_exec'>Executes a Google Utils Command</h2><span id='topic+gsutil_exec'></span>

<h3>Description</h3>

<p>Executes a Google Utils command with the given parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsutil_exec(..., args = NULL, echo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsutil_exec_+3A_...">...</code></td>
<td>
<p>Parameters to use specified based on position.</p>
</td></tr>
<tr><td><code id="gsutil_exec_+3A_args">args</code></td>
<td>
<p>Parameters to use specified as a list.</p>
</td></tr>
<tr><td><code id="gsutil_exec_+3A_echo">echo</code></td>
<td>
<p>Echo command output to console.</p>
</td></tr>
</table>

<hr>
<h2 id='job_cancel'>Cancel a job</h2><span id='topic+job_cancel'></span>

<h3>Description</h3>

<p>Cancel a job.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>job_cancel(job = "latest")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="job_cancel_+3A_job">job</code></td>
<td>
<p>Job name or job object. Pass &quot;latest&quot; to indicate the
most recently submitted job.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other job management functions: <code><a href="#topic+job_collect">job_collect</a></code>,
<code><a href="#topic+job_list">job_list</a></code>, <code><a href="#topic+job_status">job_status</a></code>,
<code><a href="#topic+job_stream_logs">job_stream_logs</a></code>, <code><a href="#topic+job_trials">job_trials</a></code>
</p>

<hr>
<h2 id='job_collect'>Collect job output</h2><span id='topic+job_collect'></span>

<h3>Description</h3>

<p>Collect the job outputs (e.g. fitted model) from a job. If the job has not
yet finished running, <code>job_collect()</code> will block and wait until the job has
finished.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>job_collect(job = "latest", trials = "best", destination = "runs",
  timeout = NULL, view = interactive())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="job_collect_+3A_job">job</code></td>
<td>
<p>Job name or job object. Pass &quot;latest&quot; to indicate the
most recently submitted job.</p>
</td></tr>
<tr><td><code id="job_collect_+3A_trials">trials</code></td>
<td>
<p>Under hyperparameter tuning, specifies which trials to
download. Use <code>"best"</code> to download best trial, <code>"all"</code> to
download all, or a vector of trials <code>c(1,2)</code> or <code>1</code>.</p>
</td></tr>
<tr><td><code id="job_collect_+3A_destination">destination</code></td>
<td>
<p>The destination directory in which model outputs should
be downloaded. Defaults to <code>runs</code>.</p>
</td></tr>
<tr><td><code id="job_collect_+3A_timeout">timeout</code></td>
<td>
<p>Give up collecting job after the specified minutes.</p>
</td></tr>
<tr><td><code id="job_collect_+3A_view">view</code></td>
<td>
<p>View the job results after collecting it. You can also pass
&quot;save&quot; to save a copy of the run report at <code>tfruns.d/view.html</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other job management functions: <code><a href="#topic+job_cancel">job_cancel</a></code>,
<code><a href="#topic+job_list">job_list</a></code>, <code><a href="#topic+job_status">job_status</a></code>,
<code><a href="#topic+job_stream_logs">job_stream_logs</a></code>, <code><a href="#topic+job_trials">job_trials</a></code>
</p>

<hr>
<h2 id='job_list'>List all jobs</h2><span id='topic+job_list'></span>

<h3>Description</h3>

<p>List existing Google Cloud ML jobs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>job_list(filter = NULL, limit = NULL, page_size = NULL,
  sort_by = NULL, uri = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="job_list_+3A_filter">filter</code></td>
<td>
<p>Filter the set of jobs to be returned.</p>
</td></tr>
<tr><td><code id="job_list_+3A_limit">limit</code></td>
<td>
<p>The maximum number of resources to list. By default,
all jobs will be listed.</p>
</td></tr>
<tr><td><code id="job_list_+3A_page_size">page_size</code></td>
<td>
<p>Some services group resource list output into pages.
This flag specifies the maximum number of resources per
page. The default is determined by the service if it
supports paging, otherwise it is unlimited (no paging).</p>
</td></tr>
<tr><td><code id="job_list_+3A_sort_by">sort_by</code></td>
<td>
<p>A comma-separated list of resource field key names to
sort by. The default order is ascending. Prefix a field
with <code>~</code> for descending order on that field.</p>
</td></tr>
<tr><td><code id="job_list_+3A_uri">uri</code></td>
<td>
<p>Print a list of resource URIs instead of the default
output.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other job management functions: <code><a href="#topic+job_cancel">job_cancel</a></code>,
<code><a href="#topic+job_collect">job_collect</a></code>, <code><a href="#topic+job_status">job_status</a></code>,
<code><a href="#topic+job_stream_logs">job_stream_logs</a></code>, <code><a href="#topic+job_trials">job_trials</a></code>
</p>

<hr>
<h2 id='job_status'>Current status of a job</h2><span id='topic+job_status'></span>

<h3>Description</h3>

<p>Get the status of a job, as an <span class="rlang"><b>R</b></span> list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>job_status(job = "latest")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="job_status_+3A_job">job</code></td>
<td>
<p>Job name or job object. Pass &quot;latest&quot; to indicate the
most recently submitted job.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other job management functions: <code><a href="#topic+job_cancel">job_cancel</a></code>,
<code><a href="#topic+job_collect">job_collect</a></code>, <code><a href="#topic+job_list">job_list</a></code>,
<code><a href="#topic+job_stream_logs">job_stream_logs</a></code>, <code><a href="#topic+job_trials">job_trials</a></code>
</p>

<hr>
<h2 id='job_stream_logs'>Show job log stream</h2><span id='topic+job_stream_logs'></span>

<h3>Description</h3>

<p>Show logs from a running Cloud ML Engine job.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>job_stream_logs(job = "latest",
  polling_interval = getOption("cloudml.stream_logs.polling", 5),
  task_name = NULL, allow_multiline_logs = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="job_stream_logs_+3A_job">job</code></td>
<td>
<p>Job name or job object. Pass &quot;latest&quot; to indicate the
most recently submitted job.</p>
</td></tr>
<tr><td><code id="job_stream_logs_+3A_polling_interval">polling_interval</code></td>
<td>
<p>Number of seconds to wait between efforts to fetch the
latest log messages.</p>
</td></tr>
<tr><td><code id="job_stream_logs_+3A_task_name">task_name</code></td>
<td>
<p>If set, display only the logs for this particular task.</p>
</td></tr>
<tr><td><code id="job_stream_logs_+3A_allow_multiline_logs">allow_multiline_logs</code></td>
<td>
<p>Output multiline log messages as single records.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other job management functions: <code><a href="#topic+job_cancel">job_cancel</a></code>,
<code><a href="#topic+job_collect">job_collect</a></code>, <code><a href="#topic+job_list">job_list</a></code>,
<code><a href="#topic+job_status">job_status</a></code>, <code><a href="#topic+job_trials">job_trials</a></code>
</p>

<hr>
<h2 id='job_trials'>Current trials of a job</h2><span id='topic+job_trials'></span>

<h3>Description</h3>

<p>Get the hyperparameter trials for job, as an <span class="rlang"><b>R</b></span> data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>job_trials(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="job_trials_+3A_x">x</code></td>
<td>
<p>Job name or job object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other job management functions: <code><a href="#topic+job_cancel">job_cancel</a></code>,
<code><a href="#topic+job_collect">job_collect</a></code>, <code><a href="#topic+job_list">job_list</a></code>,
<code><a href="#topic+job_status">job_status</a></code>, <code><a href="#topic+job_stream_logs">job_stream_logs</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
