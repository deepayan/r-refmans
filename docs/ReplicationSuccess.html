<!DOCTYPE html><html><head><title>Help for package ReplicationSuccess</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ReplicationSuccess}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ci2se'><p>Convert between estimates, z-values, p-values, and confidence intervals</p></a></li>
<li><a href='#effectSizeReplicationSuccess'><p>Computes the minimum relative effect size to achieve replication success</p>
with the sceptical p-value</a></li>
<li><a href='#effectSizeSignificance'><p>Computes the minimum relative effect size to achieve significance of the replication study</p></a></li>
<li><a href='#hMeanChiSq'><p>harmonic mean chi-squared test</p></a></li>
<li><a href='#levelSceptical'><p>Computes the replication success level</p></a></li>
<li><a href='#pBox'><p>Computes Box's tail probability</p></a></li>
<li><a href='#pIntrinsic'><p>Computes the p-value for intrinsic credibility</p></a></li>
<li><a href='#powerReplicationSuccess'><p>Computes the power for replication success with the sceptical p-value</p></a></li>
<li><a href='#powerSignificance'><p>Computes the power for significance</p></a></li>
<li><a href='#powerSignificanceInterim'><p>Interim power of a replication study</p></a></li>
<li><a href='#PPpSceptical'><p>Compute project power of the sceptical p-value</p></a></li>
<li><a href='#predictionInterval'><p>Prediction interval for effect estimate of replication study</p></a></li>
<li><a href='#pReplicate'><p>Probability of replicating an effect by Killeen (2005)</p></a></li>
<li><a href='#protzko2020'><p>Data from Protzko et al. (2020)</p></a></li>
<li><a href='#pSceptical'><p>Computes the sceptical p-value and z-value</p></a></li>
<li><a href='#pvalueBound'><p>Bound for the p-values entering the harmonic mean chi-squared test</p></a></li>
<li><a href='#Qtest'><p>Q-test to assess compatibility between original and replication effect estimate</p></a></li>
<li><a href='#RProjects'><p>Data from four large-scale replication projects</p></a></li>
<li><a href='#sampleSizeReplicationSuccess'><p>Computes the required relative sample size to achieve replication success</p>
with the sceptical p-value</a></li>
<li><a href='#sampleSizeSignificance'><p>Computes the required relative sample size to achieve significance</p>
based on power</a></li>
<li><a href='#SSRP'><p>Data from the Social Sciences Replication Project</p></a></li>
<li><a href='#T1EpSceptical'><p>Compute overall type-I error rate of the sceptical p-value</p></a></li>
<li><a href='#thresholdIntrinsic'><p>Computes the p-value threshold for intrinsic credibility</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Design and Analysis of Replication Studies</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-22</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides utilities for the design and analysis of replication
    studies.  Features both traditional methods based on statistical
    significance and more recent methods such as the sceptical p-value;
    Held L. (2020) &lt;<a href="https://doi.org/10.1111%2Frssa.12493">doi:10.1111/rssa.12493</a>&gt;, Held et al. (2022)
    &lt;<a href="https://doi.org/10.1214%2F21-AOAS1502">doi:10.1214/21-AOAS1502</a>&gt;, Micheloud et al. (2023) &lt;<a href="https://doi.org/10.1111%2Fstan.12312">doi:10.1111/stan.12312</a>&gt;.
    Also provides related methods including the harmonic mean chi-squared
    test; Held, L. (2020) &lt;<a href="https://doi.org/10.1111%2Frssc.12410">doi:10.1111/rssc.12410</a>&gt;, and intrinsic
    credibility; Held, L. (2019) &lt;<a href="https://doi.org/10.1098%2Frsos.181534">doi:10.1098/rsos.181534</a>&gt;. Contains
    datasets from five large-scale replication projects.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://crsuzh.github.io/ReplicationSuccess/">https://crsuzh.github.io/ReplicationSuccess/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/crsuzh/ReplicationSuccess/issues/">https://github.com/crsuzh/ReplicationSuccess/issues/</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, roxygen2, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-22 14:27:05 UTC; sam</td>
</tr>
<tr>
<td>Author:</td>
<td>Leonhard Held <a href="https://orcid.org/0000-0002-8686-5325"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Samuel Pawel <a href="https://orcid.org/0000-0003-2779-320X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre],
  Charlotte Micheloud
    <a href="https://orcid.org/0000-0002-4995-4505"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Florian Gerber <a href="https://orcid.org/0000-0001-8545-5263"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Felix Hofmann <a href="https://orcid.org/0000-0002-3891-6239"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Samuel Pawel &lt;samuel.pawel@uzh.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-22 17:20:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='ci2se'>Convert between estimates, z-values, p-values, and confidence intervals</h2><span id='topic+ci2se'></span><span id='topic+ci2estimate'></span><span id='topic+ci2z'></span><span id='topic+ci2p'></span><span id='topic+z2p'></span><span id='topic+p2z'></span>

<h3>Description</h3>

<p>Convert between estimates, z-values, p-values, and confidence intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci2se(lower, upper, conf.level = 0.95, ratio = FALSE)

ci2estimate(lower, upper, ratio = FALSE, antilog = FALSE)

ci2z(lower, upper, conf.level = 0.95, ratio = FALSE)

ci2p(lower, upper, conf.level = 0.95, ratio = FALSE, alternative = "two.sided")

z2p(z, alternative = "two.sided")

p2z(p, alternative = "two.sided")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci2se_+3A_lower">lower</code></td>
<td>
<p>Numeric vector of lower confidence interval bounds.</p>
</td></tr>
<tr><td><code id="ci2se_+3A_upper">upper</code></td>
<td>
<p>Numeric vector of upper confidence interval bounds.</p>
</td></tr>
<tr><td><code id="ci2se_+3A_conf.level">conf.level</code></td>
<td>
<p>The confidence level of the confidence intervals.
Default is 0.95.</p>
</td></tr>
<tr><td><code id="ci2se_+3A_ratio">ratio</code></td>
<td>
<p>Indicates whether the confidence interval is for a
ratio, e.g. an odds ratio, relative risk or hazard ratio.
If <code>TRUE</code>, the standard error of the log ratio is computed.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ci2se_+3A_antilog">antilog</code></td>
<td>
<p>Indicates whether the estimate is reported on the ratio scale.
Only applies if <code>ratio = TRUE</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ci2se_+3A_alternative">alternative</code></td>
<td>
<p>Direction of the alternative of the p-value.
Either &quot;two.sided&quot; (default), &quot;one.sided&quot;, &quot;less&quot;, or &quot;greater&quot;.
If &quot;one.sided&quot; or &quot;two.sided&quot; is specified, the z-value is assumed
to be positive.</p>
</td></tr>
<tr><td><code id="ci2se_+3A_z">z</code></td>
<td>
<p>Numeric vector of z-values.</p>
</td></tr>
<tr><td><code id="ci2se_+3A_p">p</code></td>
<td>
<p>Numeric vector of p-values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>z2p</code> is vectorized over all arguments.
</p>
<p><code>p2z</code> is vectorized over all arguments.
</p>


<h3>Value</h3>

<p><code>ci2se</code> returns a numeric vector of standard errors.
</p>
<p><code>ci2estimate</code> returns a numeric vector of parameter estimates.
</p>
<p><code>ci2z</code> returns a numeric vector of z-values.
</p>
<p><code>ci2p</code> returns a numeric vector of p-values.
</p>
<p><code>z2p</code> returns a numeric vector of p-values. The
dimension of the output depends on the input. In general,
the output will be an array of dimension
<code>c(nrow(z), ncol(z), length(alternative))</code>. If any of these
dimensions is 1, it will be dropped.
</p>
<p><code>p2z</code> returns a numeric vector of z-values. The
dimension of the output depends on the input. In general,
the output will be an array of dimension
<code>c(nrow(p), ncol(p), length(alternative))</code>. If any of these
dimensions is 1, it will be dropped.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ci2se(lower = 1, upper = 3)
ci2se(lower = 1, upper = 3, ratio = TRUE)
ci2se(lower = 1, upper = 3, conf.level = 0.9)

ci2estimate(lower = 1, upper = 3)
ci2estimate(lower = 1, upper = 3, ratio = TRUE)
ci2estimate(lower = 1, upper = 3, ratio = TRUE, antilog = TRUE)

ci2z(lower = 1, upper = 3)
ci2z(lower = 1, upper = 3, ratio = TRUE)
ci2z(lower = 1, upper = 3, conf.level = 0.9)

ci2p(lower = 1, upper = 3)
ci2p(lower = 1, upper = 3, alternative = "one.sided")

z2p(z = c(1, 2, 5))
z2p(z = c(1, 2, 5), alternative = "less")
z2p(z = c(1, 2, 5), alternative = "greater")
z &lt;- seq(-3, 3, by = 0.01)
plot(z, z2p(z), type = "l", xlab = "z", ylab = "p", ylim = c(0, 1))
lines(z, z2p(z, alternative = "greater"), lty = 2)
legend("topright", c("two-sided", "greater"), lty = c(1, 2), bty = "n")

p2z(p = c(0.005, 0.01, 0.05))
p2z(p = c(0.005, 0.01, 0.05), alternative = "greater")
p2z(p = c(0.005, 0.01, 0.05), alternative = "less")
p &lt;- seq(0.001, 0.05, 0.0001)
plot(p, p2z(p), type = "l", ylim = c(0, 3.5), ylab = "z")
lines(p, p2z(p, alternative = "greater"), lty = 2)
legend("bottomleft", c("two-sided", "greater"), lty = c(1, 2), bty = "n")
</code></pre>

<hr>
<h2 id='effectSizeReplicationSuccess'>Computes the minimum relative effect size to achieve replication success
with the sceptical p-value</h2><span id='topic+effectSizeReplicationSuccess'></span>

<h3>Description</h3>

<p>The minimum relative effect size (replication to original) to achieve
replication success with the sceptical p-value is computed based on the
result of the original study and the corresponding variance ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>effectSizeReplicationSuccess(
  zo,
  c = 1,
  level = 0.025,
  alternative = c("one.sided", "two.sided"),
  type = c("golden", "nominal", "controlled")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="effectSizeReplicationSuccess_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from original studies.</p>
</td></tr>
<tr><td><code id="effectSizeReplicationSuccess_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication
effect estimates. This is usually the ratio of the sample size of the
replication study to the sample size of the original study.</p>
</td></tr>
<tr><td><code id="effectSizeReplicationSuccess_+3A_level">level</code></td>
<td>
<p>Threshold for the calibrated sceptical p-value.
Default is 0.025.</p>
</td></tr>
<tr><td><code id="effectSizeReplicationSuccess_+3A_alternative">alternative</code></td>
<td>
<p>Specifies if <code>level</code> is &quot;one.sided&quot; (default) or
&quot;two.sided&quot;. If &quot;one.sided&quot;, then effect size calculations are based on a
one-sided assessment of replication success in the direction of the original
effect estimate.</p>
</td></tr>
<tr><td><code id="effectSizeReplicationSuccess_+3A_type">type</code></td>
<td>
<p>Type of recalibration. Can be either &quot;golden&quot; (default),
&quot;nominal&quot; (no recalibration), or &quot;controlled&quot;. &quot;golden&quot; ensures that for an
original study just significant at the specified <code>level</code>, replication
success is only possible for replication effect estimates larger than the
original one. &quot;controlled&quot; ensures exact overall Type-I error control at
level <code>level</code>^2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>effectSizeReplicationSuccess</code> is the vectorized version of
the internal function <code>.effectSizeReplicationSuccess_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The minimum relative effect size to achieve replication success
with the sceptical p-value.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held, Charlotte Micheloud, Samuel Pawel, Florian Gerber
</p>


<h3>References</h3>

<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of
replication success based on relative effect size. The Annals of Applied
Statistics. 16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Balabdaoui, F., Held, L. (2023). Assessing replicability
with the sceptical p-value: Type-I error control and
sample size planning. <em>Statistica Neerlandica</em>. <a href="https://doi.org/10.1111/stan.12312">doi:10.1111/stan.12312</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleSizeReplicationSuccess">sampleSizeReplicationSuccess</a></code>, <code><a href="#topic+levelSceptical">levelSceptical</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>po &lt;- c(0.001, 0.002, 0.01, 0.02, 0.025)
zo &lt;- p2z(po, alternative = "one.sided")

effectSizeReplicationSuccess(zo = zo, c = 1, level = 0.025,
                             alternative = "one.sided", type = "golden")

effectSizeReplicationSuccess(zo = zo, c = 10, level = 0.025,
                             alternative = "one.sided", type = "golden")
effectSizeReplicationSuccess(zo = zo, c = 10, level = 0.025,
                             alternative = "one.sided", type = "controlled")
effectSizeReplicationSuccess(zo = zo, c= 2, level = 0.025,
                             alternative = "one.sided", type = "nominal")

effectSizeReplicationSuccess(zo = zo, c = 2, level = 0.05,
                             alternative = "two.sided", type = "nominal")
</code></pre>

<hr>
<h2 id='effectSizeSignificance'>Computes the minimum relative effect size to achieve significance of the replication study</h2><span id='topic+effectSizeSignificance'></span>

<h3>Description</h3>

<p>The minimum relative effect size (replication to original) to achieve significance
of the replication study is computed based on the result of the original study and
the corresponding variance ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>effectSizeSignificance(
  zo,
  c = 1,
  level = 0.025,
  alternative = c("one.sided", "two.sided")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="effectSizeSignificance_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from original studies.</p>
</td></tr>
<tr><td><code id="effectSizeSignificance_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication effect estimates.
This is usually the ratio of the sample size of the replication study to the sample
size of the original study.</p>
</td></tr>
<tr><td><code id="effectSizeSignificance_+3A_level">level</code></td>
<td>
<p>Significance level. Default is 0.025.</p>
</td></tr>
<tr><td><code id="effectSizeSignificance_+3A_alternative">alternative</code></td>
<td>
<p>Specifies if the significance level is &quot;one.sided&quot; (default) or &quot;two.sided&quot;.
If the significance level is one-sided, then effect size calculations are based on a one-sided assessment of
significance in the direction of the original effect estimate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>effectSizeSignificance</code> is the vectorized version of
the internal function <code>.effectSizeSignificance_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The minimum relative effect size to achieve significance in the replication study.
</p>


<h3>Author(s)</h3>

<p>Charlotte Micheloud, Samuel Pawel, Florian Gerber
</p>


<h3>References</h3>

<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of
replication success based on relative effect size. The Annals of Applied
Statistics. 16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+effectSizeReplicationSuccess">effectSizeReplicationSuccess</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>po &lt;- c(0.001, 0.002, 0.01, 0.02, 0.025)
zo &lt;- p2z(po, alternative = "one.sided")

effectSizeSignificance(zo = zo, c = 1, level = 0.025,
                       alternative = "one.sided")

effectSizeSignificance(zo = zo, c = 1, level = 0.05,
                       alternative = "two.sided")

effectSizeSignificance(zo = zo, c = 50, level = 0.025,
                       alternative = "one.sided")
</code></pre>

<hr>
<h2 id='hMeanChiSq'>harmonic mean chi-squared test</h2><span id='topic+hMeanChiSq'></span><span id='topic+hMeanChiSqMu'></span><span id='topic+hMeanChiSqCI'></span>

<h3>Description</h3>

<p>p-values and confidence intervals from the harmonic mean chi-squared test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hMeanChiSq(
  z,
  w = rep(1, length(z)),
  alternative = c("greater", "less", "two.sided", "none"),
  bound = FALSE
)

hMeanChiSqMu(
  thetahat,
  se,
  w = rep(1, length(thetahat)),
  mu = 0,
  alternative = c("greater", "less", "two.sided", "none"),
  bound = FALSE
)

hMeanChiSqCI(
  thetahat,
  se,
  w = rep(1, length(thetahat)),
  alternative = c("two.sided", "greater", "less", "none"),
  conf.level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hMeanChiSq_+3A_z">z</code></td>
<td>
<p>Numeric vector of z-values.</p>
</td></tr>
<tr><td><code id="hMeanChiSq_+3A_w">w</code></td>
<td>
<p>Numeric vector of weights.</p>
</td></tr>
<tr><td><code id="hMeanChiSq_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;greater&quot; (default), &quot;less&quot;, &quot;two.sided&quot;, or &quot;none&quot;.
Specifies the alternative to be considered in the computation of the p-value.</p>
</td></tr>
<tr><td><code id="hMeanChiSq_+3A_bound">bound</code></td>
<td>
<p>If <code>FALSE</code> (default), p-values that cannot be computed are reported as <code>NaN</code>.
If <code>TRUE</code>, they are reported as &quot;&gt; bound&quot;.</p>
</td></tr>
<tr><td><code id="hMeanChiSq_+3A_thetahat">thetahat</code></td>
<td>
<p>Numeric vector of parameter estimates.</p>
</td></tr>
<tr><td><code id="hMeanChiSq_+3A_se">se</code></td>
<td>
<p>Numeric vector of standard errors.</p>
</td></tr>
<tr><td><code id="hMeanChiSq_+3A_mu">mu</code></td>
<td>
<p>The null hypothesis value. Defaults to 0.</p>
</td></tr>
<tr><td><code id="hMeanChiSq_+3A_conf.level">conf.level</code></td>
<td>
<p>Numeric vector specifying the conf.level of the confidence interval. Defaults to 0.95.
summarize the gamma values, i.e.,
the local minima of the p-value function between the thetahats. Defaults is a vector of 1s.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>hMeanChiSq</code>: returns the p-values from the harmonic mean chi-squared test
based on the study-specific z-values.
</p>
<p><code>hMeanChiSqMu</code>: returns the p-value from the harmonic mean chi-squared test
based on study-specific estimates and standard errors.
</p>
<p><code>hMeanChiSqCI</code>: returns a list containing confidence interval(s)
obtained by inverting the harmonic mean chi-squared test based on study-specific
estimates and standard errors. The list contains:
</p>
<table>
<tr><td><code>CI</code></td>
<td>
<p>Confidence interval(s).</p>
</td></tr></table>
<p><br /><br />
If the <code>alternative</code> is &quot;none&quot;, the list also contains:
</p>
<table>
<tr><td><code>gamma</code></td>
<td>
<p>Local minima of the p-value function between the thetahats.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonhard Held, Florian Gerber
</p>


<h3>References</h3>

<p>Held, L. (2020). The harmonic mean chi-squared test to substantiate scientific findings.
<em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em>, <b>69</b>, 697-708.
<a href="https://doi.org/10.1111/rssc.12410">doi:10.1111/rssc.12410</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example from Fisher (1999) as discussed in Held (2020)
pvalues &lt;- c(0.0245, 0.1305, 0.00025, 0.2575, 0.128)
lower &lt;- c(0.04, 0.21, 0.12, 0.07, 0.41)
upper &lt;- c(1.14, 1.54, 0.60, 3.75, 1.27)
se &lt;- ci2se(lower = lower, upper = upper, ratio = TRUE)
thetahat &lt;- ci2estimate(lower = lower, upper = upper, ratio = TRUE)

## hMeanChiSq() --------
hMeanChiSq(z = p2z(p = pvalues, alternative = "less"),
           alternative = "less")
hMeanChiSq(z = p2z(p = pvalues, alternative = "less"),
           alternative = "two.sided")
hMeanChiSq(z = p2z(p = pvalues, alternative = "less"),
           alternative = "none")

hMeanChiSq(z = p2z(p = pvalues, alternative = "less"),
           w = 1 / se^2, alternative = "less")
hMeanChiSq(z = p2z(p = pvalues, alternative = "less"),
           w = 1 / se^2, alternative = "two.sided")
hMeanChiSq(z = p2z(p = pvalues, alternative = "less"),
           w = 1 / se^2, alternative = "none")


## hMeanChiSqMu() --------
hMeanChiSqMu(thetahat = thetahat, se = se, alternative = "two.sided")
hMeanChiSqMu(thetahat = thetahat, se = se, w = 1 / se^2,
             alternative = "two.sided")
hMeanChiSqMu(thetahat = thetahat, se = se, alternative = "two.sided",
             mu = -0.1)

## hMeanChiSqCI() --------
## two-sided
CI1 &lt;- hMeanChiSqCI(thetahat = thetahat, se = se, w = 1 / se^2,
                    alternative = "two.sided")
CI2 &lt;- hMeanChiSqCI(thetahat = thetahat, se = se, w = 1 / se^2,
                    alternative = "two.sided", conf.level = 0.99875)
## one-sided
CI1b &lt;- hMeanChiSqCI(thetahat = thetahat, se = se, w = 1 / se^2,
                     alternative = "less", conf.level = 0.975)
CI2b &lt;- hMeanChiSqCI(thetahat = thetahat, se = se, w = 1 / se^2,
                     alternative = "less", conf.level = 1 - 0.025^2)

## confidence intervals on hazard ratio scale
print(exp(CI1$CI), digits = 2)
print(exp(CI2$CI), digits = 2)
print(exp(CI1b$CI), digits = 2)
print(exp(CI2b$CI), digits = 2)


## example with confidence region consisting of disjunct intervals
thetahat2 &lt;- c(-3.7, 2.1, 2.5)
se2 &lt;- c(1.5, 2.2, 3.1)
conf.level &lt;- 0.95; alpha &lt;- 1 - conf.level
muSeq &lt;- seq(-7, 6, length.out = 1000)
pValueSeq &lt;- hMeanChiSqMu(thetahat = thetahat2, se = se2,
                          alternative = "none", mu = muSeq)
(hm &lt;- hMeanChiSqCI(thetahat = thetahat2, se = se2, alternative = "none"))

plot(x = muSeq, y = pValueSeq, type = "l", panel.first = grid(lty = 1),
     xlab = expression(mu), ylab = "p-value")
abline(v = thetahat2, h = alpha, lty = 2)
arrows(x0 = hm$CI[, 1], x1 = hm$CI[, 2], y0 = alpha,
       y1 = alpha, col = "darkgreen", lwd = 3, angle = 90, code = 3)
points(hm$gamma, col = "red", pch = 19, cex = 2)

</code></pre>

<hr>
<h2 id='levelSceptical'>Computes the replication success level</h2><span id='topic+levelSceptical'></span>

<h3>Description</h3>

<p>The replication success level is computed based on the specified
alternative and recalibration type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>levelSceptical(
  level,
  c = NA,
  alternative = c("one.sided", "two.sided"),
  type = c("golden", "nominal", "controlled")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="levelSceptical_+3A_level">level</code></td>
<td>
<p>Threshold for the calibrated sceptical p-value.
Default is 0.025.</p>
</td></tr>
<tr><td><code id="levelSceptical_+3A_c">c</code></td>
<td>
<p>The variance ratio. Only required when <code>type = </code> &quot;controlled&quot;.</p>
</td></tr>
<tr><td><code id="levelSceptical_+3A_alternative">alternative</code></td>
<td>
<p>Specifies if <code>level</code> is &quot;one.sided&quot; (default) or
&quot;two.sided&quot;. If &quot;one-sided&quot;,
then a one-sided replication success level is computed.</p>
</td></tr>
<tr><td><code id="levelSceptical_+3A_type">type</code></td>
<td>
<p>Type of recalibration. Can be either &quot;golden&quot; (default), &quot;nominal&quot; (no recalibration),
or &quot;controlled&quot;. &quot;golden&quot; ensures that for an original study just significant at
the specified <code>level</code>, replication success is only possible for 
replication effect estimates larger than the original one.
&quot;controlled&quot; ensures exact overall Type-I error control at level <code>level</code>^2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>levelSceptical</code> is the vectorized version of
the internal function <code>.levelSceptical_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>Replication success levels
</p>


<h3>Author(s)</h3>

<p>Leonhard Held
</p>


<h3>References</h3>

<p>Held, L. (2020). A new standard for the analysis and design of
replication studies (with discussion). <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>, <b>183</b>,
431-448. <a href="https://doi.org/10.1111/rssa.12493">doi:10.1111/rssa.12493</a>
</p>
<p>Held, L. (2020). The harmonic mean chi-squared test to substantiate
scientific findings. <em>Journal of the Royal Statistical
Society: Series C (Applied Statistics)</em>, <b>69</b>, 697-708.
<a href="https://doi.org/10.1111/rssc.12410">doi:10.1111/rssc.12410</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size.
<em>The Annals of Applied Statistics</em>, <b>16</b>, 706-720.
<a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Balabdaoui, F., Held, L. (2023). Assessing replicability
with the sceptical p-value: Type-I error control and
sample size planning. <em>Statistica Neerlandica</em>. <a href="https://doi.org/10.1111/stan.12312">doi:10.1111/stan.12312</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>levelSceptical(level = 0.025, alternative = "one.sided", type = "nominal")
levelSceptical(
  level = 0.025,
  alternative = "one.sided",
  type = "controlled",
  c = 1
)
levelSceptical(level = 0.025, alternative = "one.sided", type = "golden")
</code></pre>

<hr>
<h2 id='pBox'>Computes Box's tail probability</h2><span id='topic+pBox'></span><span id='topic+zBox'></span>

<h3>Description</h3>

<p><code>pBox</code> computes Box's tail probabilities based on the z-values of the
original and the replication study, the corresponding variance ratio,
and the significance level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pBox(zo, zr, c, level = 0.05, alternative = c("two.sided", "one.sided"))

zBox(zo, zr, c, level = 0.05, alternative = c("two.sided", "one.sided"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pBox_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from the original studies.</p>
</td></tr>
<tr><td><code id="pBox_+3A_zr">zr</code></td>
<td>
<p>Numeric vector of z-values from replication studies.</p>
</td></tr>
<tr><td><code id="pBox_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication
effect estimates. This is usually the ratio of the sample
size of the replication study to the sample size of the
original study.</p>
</td></tr>
<tr><td><code id="pBox_+3A_level">level</code></td>
<td>
<p>Numeric vector of significance levels. Default is 0.05.</p>
</td></tr>
<tr><td><code id="pBox_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;two.sided&quot; (default) or &quot;one.sided&quot;.
Specifies whether two-sided or one-sided Box's tail
probabilities are computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pBox</code> quantifies the conflict between the sceptical prior
that would render the original study non-significant and the result
from the replication study. If the original study was not significant
at level <code>level</code>, the sceptical prior does not exist and <code>pBox</code>
cannot be calculated.
</p>


<h3>Value</h3>

<p><code>pBox</code> returns Box's tail probabilities.
</p>
<p><code>zBox</code> returns the z-values used in <code>pBox</code>.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held
</p>


<h3>References</h3>

<p>Box, G.E.P. (1980). Sampling and Bayes' inference in scientific
modelling and robustness (with discussion). <em>Journal of the Royal
Statistical Society, Series A</em>, <b>143</b>, 383-430.
</p>
<p>Held, L. (2020). A new standard for the analysis and design of replication
studies (with discussion). <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <b>183</b>, 431-448.
<a href="https://doi.org/10.1111/rssa.12493">doi:10.1111/rssa.12493</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pBox(zo = p2z(0.01), zr = p2z(0.02), c = 2)
pBox(zo = p2z(0.02), zr = p2z(0.01), c = 1/2)
pBox(zo = p2z(0.02, alternative = "one.sided"),
     zr = p2z(0.01, alternative = "one.sided"),
     c = 1/2, alternative = "one.sided")
</code></pre>

<hr>
<h2 id='pIntrinsic'>Computes the p-value for intrinsic credibility</h2><span id='topic+pIntrinsic'></span>

<h3>Description</h3>

<p>Computes the p-value for intrinsic credibility
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pIntrinsic(
  p = z2p(z, alternative = alternative),
  z = NULL,
  alternative = c("two.sided", "one.sided", "less", "greater"),
  type = c("Held", "Matthews")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pIntrinsic_+3A_p">p</code></td>
<td>
<p>numeric vector of p-values.</p>
</td></tr>
<tr><td><code id="pIntrinsic_+3A_z">z</code></td>
<td>
<p>numeric vector of z-values. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="pIntrinsic_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;two.sided&quot; (default) or &quot;one.sided&quot;.
Specifies if the p-value is two-sided or one-sided.
If the p-value is one-sided, then a one-sided p-value for
intrinsic credibility is computed.</p>
</td></tr>
<tr><td><code id="pIntrinsic_+3A_type">type</code></td>
<td>
<p>Type of intrinsic p-value. Default is &quot;Held&quot; as in
Held (2019). The other option is &quot;Matthews&quot; as in Matthews (2018).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>p-values for intrinsic credibility.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held
</p>


<h3>References</h3>

<p>Matthews, R. A. J. (2018). Beyond 'significance': principles and
practice of the analysis of credibility. <em>Royal Society Open
Science</em>, <b>5</b>, 171047. <a href="https://doi.org/10.1098/rsos.171047">doi:10.1098/rsos.171047</a>
</p>
<p>Held, L. (2019). The assessment of intrinsic credibility and a new argument
for <em>p &lt; 0.005</em>. <em>Royal Society Open Science</em>, <b>6</b>, 181534.
<a href="https://doi.org/10.1098/rsos.181534">doi:10.1098/rsos.181534</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- c(0.005, 0.01, 0.05)
pIntrinsic(p = p)
pIntrinsic(p = p, type = "Matthews")
pIntrinsic(p = p, alternative = "one.sided")
pIntrinsic(p = p, alternative = "one.sided", type = "Matthews")

pIntrinsic(z = 2)
</code></pre>

<hr>
<h2 id='powerReplicationSuccess'>Computes the power for replication success with the sceptical p-value</h2><span id='topic+powerReplicationSuccess'></span>

<h3>Description</h3>

<p>Computes the power for replication success with the sceptical
p-value  based on the result of the
original study, the corresponding variance ratio, and the design prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerReplicationSuccess(
  zo,
  c = 1,
  level = 0.025,
  designPrior = c("conditional", "predictive", "EB"),
  alternative = c("one.sided", "two.sided"),
  type = c("golden", "nominal", "controlled"),
  shrinkage = 0,
  h = 0,
  strict = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerReplicationSuccess_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from original studies.</p>
</td></tr>
<tr><td><code id="powerReplicationSuccess_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication
effect estimates. This is usually the ratio of the sample size of the
replication study to the sample size of the original study.</p>
</td></tr>
<tr><td><code id="powerReplicationSuccess_+3A_level">level</code></td>
<td>
<p>Threshold for the calibrated sceptical p-value.
Default is 0.025.</p>
</td></tr>
<tr><td><code id="powerReplicationSuccess_+3A_designprior">designPrior</code></td>
<td>
<p>Either &quot;conditional&quot; (default), &quot;predictive&quot;, or &quot;EB&quot;. If
&quot;EB&quot;, the power is computed under a predictive distribution, where
the contribution of the original study is shrunken towards zero based on
the evidence in the original study (with an empirical Bayes shrinkage
estimator).</p>
</td></tr>
<tr><td><code id="powerReplicationSuccess_+3A_alternative">alternative</code></td>
<td>
<p>Specifies if <code>level</code> is &quot;one.sided&quot; (default) or &quot;two.sided&quot;.
If &quot;one.sided&quot; then power calculations are based
on a one-sided assessment of replication success in the direction of the
original effect estimates.</p>
</td></tr>
<tr><td><code id="powerReplicationSuccess_+3A_type">type</code></td>
<td>
<p>Type of recalibration. Can be either &quot;golden&quot; (default), &quot;nominal&quot; (no recalibration),
or &quot;controlled&quot;. &quot;golden&quot; ensures that for an original study just significant at
the specified <code>level</code>, replication success is only possible for
replication effect estimates larger than the original one.
&quot;controlled&quot; ensures exact overall Type-I error control at level <code>level</code>^2.</p>
</td></tr>
<tr><td><code id="powerReplicationSuccess_+3A_shrinkage">shrinkage</code></td>
<td>
<p>Numeric vector with values in [0,1). Defaults to 0.
Specifies the shrinkage of the original effect estimate towards zero,
e.g., the effect is shrunken by a factor of 25% for
<code>shrinkage = 0.25</code>. Is only taken into account if the
<code>designPrior</code> is &quot;conditional&quot; or &quot;predictive&quot;.</p>
</td></tr>
<tr><td><code id="powerReplicationSuccess_+3A_h">h</code></td>
<td>
<p>Numeric vector of relative heterogeneity variances i.e., the ratios
of the heterogeneity variance to the variance of the original effect
estimate. Default is 0 (no heterogeneity). Is only taken into account
when <code>designPrior</code> = &quot;predictive&quot; or <code>designPrior</code> = &quot;EB&quot;.</p>
</td></tr>
<tr><td><code id="powerReplicationSuccess_+3A_strict">strict</code></td>
<td>
<p>Logical vector indicating whether the probability for
replication success in the opposite direction of the original effect
estimate should also be taken into account. Default is <code>FALSE</code>.
Only taken into account when <code>alternative</code> = &quot;two.sided&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>powerReplicationSuccess</code> is the vectorized version of
the internal function <code>.powerReplicationSuccess_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The power for replication success with the sceptical p-value
</p>


<h3>Author(s)</h3>

<p>Leonhard Held, Charlotte Micheloud, Samuel Pawel
</p>


<h3>References</h3>

<p>Held, L. (2020). A new standard for the analysis and design of replication
studies (with discussion). <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <b>183</b>, 431-448.
<a href="https://doi.org/10.1111/rssa.12493">doi:10.1111/rssa.12493</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size. <em>The Annals of Applied
Statistics</em>. 16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Balabdaoui, F., Held, L. (2023). Assessing replicability
with the sceptical p-value: Type-I error control and
sample size planning. <em>Statistica Neerlandica</em>. <a href="https://doi.org/10.1111/stan.12312">doi:10.1111/stan.12312</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleSizeReplicationSuccess">sampleSizeReplicationSuccess</a></code>, <code><a href="#topic+pSceptical">pSceptical</a></code>,
<code><a href="#topic+levelSceptical">levelSceptical</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## larger sample size in replication (c &gt; 1)
powerReplicationSuccess(zo = p2z(0.005), c = 2, level = 0.025, designPrior = "conditional")
powerReplicationSuccess(zo = p2z(0.005), c = 2, level = 0.025, designPrior = "predictive")

## smaller sample size in replication (c &lt; 1)
powerReplicationSuccess(zo = p2z(0.005), c = 1/2, level = 0.025, designPrior = "conditional")
powerReplicationSuccess(zo = p2z(0.005), c = 1/2, level = 0.025, designPrior = "predictive")

powerReplicationSuccess(zo = p2z(0.00005), c = 2, level = 0.05,
                        alternative = "two.sided",  strict = TRUE, shrinkage = 0.9)
powerReplicationSuccess(zo = p2z(0.00005), c = 2, level = 0.05,
                        alternative = "two.sided", strict = FALSE, shrinkage = 0.9)

</code></pre>

<hr>
<h2 id='powerSignificance'>Computes the power for significance</h2><span id='topic+powerSignificance'></span>

<h3>Description</h3>

<p>The power for significance is computed based on the result of
the original study, the corresponding variance ratio,
and the design prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerSignificance(
  zo,
  c = 1,
  level = 0.025,
  designPrior = c("conditional", "predictive", "EB"),
  alternative = c("one.sided", "two.sided"),
  h = 0,
  shrinkage = 0,
  strict = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerSignificance_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from original studies.</p>
</td></tr>
<tr><td><code id="powerSignificance_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication
effect estimates. This is usually the ratio of the sample
size of the replication study to the sample size of the original study.</p>
</td></tr>
<tr><td><code id="powerSignificance_+3A_level">level</code></td>
<td>
<p>Significance level. Default is 0.025.</p>
</td></tr>
<tr><td><code id="powerSignificance_+3A_designprior">designPrior</code></td>
<td>
<p>Either &quot;conditional&quot; (default), &quot;predictive&quot;, or &quot;EB&quot;.
If &quot;EB&quot;, the power is computed under a predictive distribution, where
the contribution of the original study is shrunken towards zero based
on the evidence in the original study (with an empirical Bayes shrinkage estimator).</p>
</td></tr>
<tr><td><code id="powerSignificance_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;one.sided&quot; (default) or &quot;two.sided&quot;.
Specifies if the significance level is one-sided or two-sided.
If the significance level is one-sided, then power calculations are based on a
one-sided assessment of significance in the direction of the
original effect estimates.</p>
</td></tr>
<tr><td><code id="powerSignificance_+3A_h">h</code></td>
<td>
<p>The relative between-study heterogeneity, i.e., the ratio of the heterogeneity
variance to the variance of the original effect estimate.
Default is 0 (no heterogeneity).
Is only taken into account when <code>designPrior</code> = &quot;predictive&quot; or
<code>designPrior</code> = &quot;EB&quot;.</p>
</td></tr>
<tr><td><code id="powerSignificance_+3A_shrinkage">shrinkage</code></td>
<td>
<p>Numeric vector with values in [0,1). Defaults to 0.
Specifies the shrinkage of the original effect estimate towards zero, e.g.,
the effect is shrunken by a factor of 25% for <code>shrinkage = 0.25</code>.
Is only taken into account if the <code>designPrior</code> is &quot;conditional&quot; or &quot;predictive&quot;.</p>
</td></tr>
<tr><td><code id="powerSignificance_+3A_strict">strict</code></td>
<td>
<p>Logical vector indicating whether the probability for significance
in the opposite direction of the original effect estimate should also be
taken into account. Default is <code>FALSE</code>.
Only taken into account when <code>alternative</code> = &quot;two.sided&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>powerSignificance</code> is the vectorized version of
the internal function <code>.powerSignificance_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The probability that a replication study yields a significant effect estimate
in the specified direction.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held, Samuel Pawel, Charlotte Micheloud, Florian Gerber
</p>


<h3>References</h3>

<p>Goodman, S. N. (1992). A comment on replication, p-values and evidence,
<em>Statistics in Medicine</em>, <b>11</b>, 875&ndash;879.
<a href="https://doi.org/10.1002/sim.4780110705">doi:10.1002/sim.4780110705</a>
</p>
<p>Senn, S. (2002). Letter to the Editor, <em>Statistics in Medicine</em>,
<b>21</b>, 2437&ndash;2444.
</p>
<p>Held, L. (2020). A new standard for the analysis and design of replication
studies (with discussion). <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <b>183</b>, 431-448.
<a href="https://doi.org/10.1111/rssa.12493">doi:10.1111/rssa.12493</a>
</p>
<p>Pawel, S., Held, L. (2020). Probabilistic forecasting of replication studies.
<em>PLoS ONE</em>. <b>15</b>, e0231416. <a href="https://doi.org/10.1371/journal.pone.0231416">doi:10.1371/journal.pone.0231416</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size. The Annals of Applied Statistics.
16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Held, L. (2022). Power Calculations for Replication Studies.
Statistical Science. 37:369-379. <a href="https://doi.org/10.1214/21-STS828">doi:10.1214/21-STS828</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleSizeSignificance">sampleSizeSignificance</a></code>,
<code><a href="#topic+powerSignificanceInterim">powerSignificanceInterim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>powerSignificance(zo = p2z(0.005), c = 2)
powerSignificance(zo = p2z(0.005), c = 2, designPrior = "predictive")
powerSignificance(zo = p2z(0.005), c = 2, alternative = "two.sided")
powerSignificance(zo = -3, c = 2, designPrior = "predictive",
                  alternative = "one.sided")
powerSignificance(zo = p2z(0.005), c = 1/2)
powerSignificance(zo = p2z(0.005), c = 1/2, designPrior = "predictive")
powerSignificance(zo = p2z(0.005), c = 1/2, alternative = "two.sided")
powerSignificance(zo = p2z(0.005), c = 1/2, designPrior = "predictive",
                  alternative = "two.sided")
powerSignificance(zo = p2z(0.005), c = 1/2, designPrior = "predictive",
                  alternative = "one.sided", h = 0.5, shrinkage = 0.5)
powerSignificance(zo = p2z(0.005), c = 1/2, designPrior = "EB",
                  alternative = "two.sided", h = 0.5)

# power as function of original p-value
po &lt;- seq(0.0001, 0.06, 0.0001)
plot(po, powerSignificance(zo = p2z(po), designPrior = "conditional"),
     type = "l", ylim = c(0, 1), lwd = 1.5, las = 1, ylab = "Power",
     xlab = expression(italic(p)[o]))
lines(po, powerSignificance(zo = p2z(po), designPrior = "predictive"),
      lwd = 2, lty = 2)
lines(po, powerSignificance(zo = p2z(po), designPrior = "EB"),
      lwd = 1.5, lty = 3)
legend("topright", legend = c("conditional", "predictive", "EB"),
       title = "Design prior", lty = c(1, 2, 3), lwd = 1.5, bty = "n")
</code></pre>

<hr>
<h2 id='powerSignificanceInterim'>Interim power of a replication study</h2><span id='topic+powerSignificanceInterim'></span>

<h3>Description</h3>

<p>Computes the power of a replication study taking into account data from an interim analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerSignificanceInterim(
  zo,
  zi,
  c = 1,
  f = 1/2,
  level = 0.025,
  designPrior = c("conditional", "informed predictive", "predictive"),
  analysisPrior = c("flat", "original"),
  alternative = c("one.sided", "two.sided"),
  shrinkage = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerSignificanceInterim_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from original studies.</p>
</td></tr>
<tr><td><code id="powerSignificanceInterim_+3A_zi">zi</code></td>
<td>
<p>Numeric vector of z-values from interim analyses of replication studies.</p>
</td></tr>
<tr><td><code id="powerSignificanceInterim_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication effect estimates.
This is usually the ratio of the sample size of the replication study to the sample
size of the original study. Default is 1.</p>
</td></tr>
<tr><td><code id="powerSignificanceInterim_+3A_f">f</code></td>
<td>
<p>Fraction of the replication study already completed. Default is 0.5.</p>
</td></tr>
<tr><td><code id="powerSignificanceInterim_+3A_level">level</code></td>
<td>
<p>Significance level. Default is 0.025.</p>
</td></tr>
<tr><td><code id="powerSignificanceInterim_+3A_designprior">designPrior</code></td>
<td>
<p>Either &quot;conditional&quot; (default), &quot;informed predictive&quot;, or &quot;predictive&quot;.
&quot;informed predictive&quot; refers to an informative normal prior coming from the original study.
&quot;predictive&quot; refers to a flat prior.</p>
</td></tr>
<tr><td><code id="powerSignificanceInterim_+3A_analysisprior">analysisPrior</code></td>
<td>
<p>Either &quot;flat&quot; (default) or &quot;original&quot;.</p>
</td></tr>
<tr><td><code id="powerSignificanceInterim_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;one.sided&quot; (default) or &quot;two.sided&quot;.
Specifies if the significance level is one-sided or two-sided.</p>
</td></tr>
<tr><td><code id="powerSignificanceInterim_+3A_shrinkage">shrinkage</code></td>
<td>
<p>Numeric vector with values in [0,1). Defaults to 0.
Specifies the shrinkage of the original effect estimate towards zero, e.g.,
the effect is shrunken by a factor of 25% for <code>shrinkage=0.25</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an extension of <code>powerSignificance()</code> and adapts the &lsquo;interim power&rsquo;
from section 6.6.3 of Spiegelhalter et al. (2004) to the setting of replication studies.
</p>
<p><code>powerSignificanceInterim</code> is the vectorized version of
<code>.powerSignificanceInterim_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The probability of statistical significance in the specified direction
at the end of the replication study given the data collected so far
in the replication study.
</p>


<h3>Author(s)</h3>

<p>Charlotte Micheloud
</p>


<h3>References</h3>

<p>Spiegelhalter, D. J., Abrams, K. R., and Myles, J. P. (2004).
Bayesian Approaches to Clinical Trials and Health-Care
Evaluation, volume 13. John Wiley &amp; Sons
</p>
<p>Micheloud, C., Held, L. (2022). Power Calculations for Replication Studies.
<em>Statistical Science</em>, <b>37</b>, 369-379.
<a href="https://doi.org/10.1214/21-STS828">doi:10.1214/21-STS828</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleSizeSignificance">sampleSizeSignificance</a></code>, <code><a href="#topic+powerSignificance">powerSignificance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>powerSignificanceInterim(zo = 2, zi = 2, c = 1, f = 1/2,
                         designPrior = "conditional",
                         analysisPrior = "flat")

powerSignificanceInterim(zo = 2, zi = 2, c = 1, f = 1/2,
                         designPrior = "informed predictive",
                         analysisPrior = "flat")

powerSignificanceInterim(zo = 2, zi = 2, c = 1, f = 1/2,
                         designPrior = "predictive",
                         analysisPrior = "flat")

powerSignificanceInterim(zo = 2, zi = -2, c = 1, f = 1/2,
                         designPrior = "conditional",
                         analysisPrior = "flat")

powerSignificanceInterim(zo = 2, zi = 2, c = 1, f = 1/2,
                         designPrior = "conditional",
                         analysisPrior = "flat",
                         shrinkage = 0.25)
</code></pre>

<hr>
<h2 id='PPpSceptical'>Compute project power of the sceptical p-value</h2><span id='topic+PPpSceptical'></span>

<h3>Description</h3>

<p>The project power of the sceptical p-value is computed for a
specified level, the relative variance,
significance level and power for a standard significance test of
the original study, and the alternative hypothesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PPpSceptical(
  level,
  c,
  alpha,
  power,
  alternative = c("one.sided", "two.sided"),
  type = c("golden", "nominal", "controlled")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PPpSceptical_+3A_level">level</code></td>
<td>
<p>Threshold for the calibrated sceptical p-value.
Default is 0.025.</p>
</td></tr>
<tr><td><code id="PPpSceptical_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication
effect estimates. This is usually the ratio of the sample
size of the replication study to the sample size of the
original study.</p>
</td></tr>
<tr><td><code id="PPpSceptical_+3A_alpha">alpha</code></td>
<td>
<p>Significance level for a standard significance test in
the original study. Default is 0.025.</p>
</td></tr>
<tr><td><code id="PPpSceptical_+3A_power">power</code></td>
<td>
<p>Power to detect the assumed effect with a standard significance test
in the original study.</p>
</td></tr>
<tr><td><code id="PPpSceptical_+3A_alternative">alternative</code></td>
<td>
<p>Specifies if <code>level</code> and
<code>alpha</code> are &quot;two.sided&quot; or &quot;one.sided&quot;.</p>
</td></tr>
<tr><td><code id="PPpSceptical_+3A_type">type</code></td>
<td>
<p>Type of recalibration. Can be either &quot;golden&quot; (default), &quot;nominal&quot; (no recalibration),
or &quot;controlled&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PPpSceptical</code> is the vectorized version of
the internal function <code>.PPpSceptical_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The project power of the sceptical p-value
</p>


<h3>Author(s)</h3>

<p>Leonhard Held, Samuel Pawel
</p>


<h3>References</h3>

<p>Held, L. (2020). The harmonic mean chi-squared test to substantiate
scientific findings. <em>Journal of the Royal Statistical Society: Series C
(Applied Statistics)</em>, <b>69</b>, 697-708. <a href="https://doi.org/10.1111/rssc.12410">doi:10.1111/rssc.12410</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size. The Annals of Applied Statistics.
16:706-720.<a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Maca, J., Gallo, P., Branson, M., and Maurer, W. (2002).  Reconsidering some aspects
of the two-trials paradigm. <em>Journal of Biopharmaceutical Statistics</em>, <b>12</b>,
107-119. <a href="https://doi.org/10.1081/bip-120006450">doi:10.1081/bip-120006450</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pSceptical">pSceptical</a></code>, <code><a href="#topic+levelSceptical">levelSceptical</a></code>, <code><a href="#topic+T1EpSceptical">T1EpSceptical</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## compare project power for different recalibration types
types &lt;- c("nominal", "golden", "controlled")
c &lt;- seq(0.4, 5, by = 0.01)
alpha &lt;- 0.025
power &lt;- 0.9
pp &lt;- sapply(X = types, FUN = function(t) {
  PPpSceptical(type = t, c = c, alpha, power, alternative = "one.sided",
               level = 0.025)
})

## compute project power of 2 trials rule
za &lt;- qnorm(p = 1 - alpha)
mu &lt;- za + qnorm(p = power)
pp2TR &lt;- power * pnorm(q = za, mean = sqrt(c) * mu, lower.tail = FALSE)

matplot(x = c, y = pp * 100, type = "l", lty = 1, lwd = 2, las = 1, log = "x",
        xlab = bquote(italic(c)), ylab = "Project power (%)", xlim = c(0.4, 5),
        ylim = c(0, 100))
lines(x = c, y = pp2TR * 100, col = length(types) + 1, lwd = 2)
abline(v = 1, lty = 2)
abline(h = 90, lty = 2, col = "lightgrey")
legend("bottomright", legend = c(types, "2TR"), lty = 1, lwd = 2,
       col = seq(1, length(types) + 1))
</code></pre>

<hr>
<h2 id='predictionInterval'>Prediction interval for effect estimate of replication study</h2><span id='topic+predictionInterval'></span>

<h3>Description</h3>

<p>Computes a prediction interval for the effect estimate of the replication study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictionInterval(
  thetao,
  seo,
  ser,
  tau = 0,
  conf.level = 0.95,
  designPrior = "predictive"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictionInterval_+3A_thetao">thetao</code></td>
<td>
<p>Numeric vector of effect estimates from original studies.</p>
</td></tr>
<tr><td><code id="predictionInterval_+3A_seo">seo</code></td>
<td>
<p>Numeric vector of standard errors of the original effect estimates.</p>
</td></tr>
<tr><td><code id="predictionInterval_+3A_ser">ser</code></td>
<td>
<p>Numeric vector of standard errors of the replication effect estimates.</p>
</td></tr>
<tr><td><code id="predictionInterval_+3A_tau">tau</code></td>
<td>
<p>Between-study heterogeneity standard error.
Default is <code>0</code> (no heterogeneity).
Is only taken into account when <code>designPrior</code> is &quot;predictive&quot; or &quot;EB&quot;.</p>
</td></tr>
<tr><td><code id="predictionInterval_+3A_conf.level">conf.level</code></td>
<td>
<p>The confidence level of the prediction intervals. Default is 0.95.</p>
</td></tr>
<tr><td><code id="predictionInterval_+3A_designprior">designPrior</code></td>
<td>
<p>Either &quot;predictive&quot; (default), &quot;conditional&quot;, or &quot;EB&quot;.
If &quot;EB&quot;, the contribution of the original study to the predictive distribution is
shrunken towards zero based on the evidence in the original study (with empirical Bayes).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes a prediction interval and a mean estimate under a
specified predictive distribution of the replication effect estimate. Setting
<code>designPrior = "conditional"</code> is not recommended since this ignores the
uncertainty of the original effect estimate. See Patil, Peng, and Leek (2016)
and Pawel and Held (2020) for details.
</p>
<p><code>predictionInterval</code> is the vectorized version of <code>.predictionInterval_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>A data frame with the following columns
</p>
<table>
<tr><td><code>lower</code></td>
<td>
<p>Lower limit of prediction interval,</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>Mean of predictive distribution,</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>Upper limit of prediction interval.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Samuel Pawel
</p>


<h3>References</h3>

<p>Patil, P., Peng, R. D., Leek, J. T. (2016).
What should researchers expect when they replicate studies? A statistical view of
replicability in psychological science. <em>Perspectives on Psychological Science</em>,
<b>11</b>, 539-544.  <a href="https://doi.org/10.1177/1745691616646366">doi:10.1177/1745691616646366</a>
</p>
<p>Pawel, S., Held, L. (2020). Probabilistic forecasting of replication studies.
<em>PLoS ONE</em>. <b>15</b>, e0231416. <a href="https://doi.org/10.1371/journal.pone.0231416">doi:10.1371/journal.pone.0231416</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>predictionInterval(thetao = c(1.5, 2, 5), seo = 1, ser = 0.5, designPrior = "EB")

# compute prediction intervals for replication projects
data("RProjects", package = "ReplicationSuccess")
parOld &lt;- par(mfrow = c(2, 2))
for (p in unique(RProjects$project)) {
  data_project &lt;- subset(RProjects, project == p)
  PI &lt;- predictionInterval(thetao = data_project$fiso, seo = data_project$se_fiso,
                           ser = data_project$se_fisr)
  PI &lt;- tanh(PI) # transforming back to correlation scale
  within &lt;- (data_project$rr &lt; PI$upper) &amp; (data_project$rr &gt; PI$lower)
  coverage &lt;- mean(within)
  color &lt;- ifelse(within == TRUE, "#333333B3", "#8B0000B3")
  study &lt;- seq(1, nrow(data_project))
  plot(data_project$rr, study, col = color, pch = 20,
       xlim = c(-0.5, 1), xlab = expression(italic(r)[r]),
       main = paste0(p, ": ", round(coverage*100, 1), "% coverage"))
  arrows(PI$lower, study, PI$upper, study, length = 0.02, angle = 90,
         code = 3, col = color)
  abline(v = 0, lty = 3)
}
par(parOld)
</code></pre>

<hr>
<h2 id='pReplicate'>Probability of replicating an effect by Killeen (2005)</h2><span id='topic+pReplicate'></span>

<h3>Description</h3>

<p>Computes the probability that a replication study yields an effect
estimate in the same direction as in the original study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pReplicate(
  po = NULL,
  zo = p2z(p = po, alternative = alternative),
  c,
  alternative = "two.sided"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pReplicate_+3A_po">po</code></td>
<td>
<p>Numeric vector of p-values from the original study, default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="pReplicate_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from the original study.
Is calculated from <code>po</code>, if necessary.</p>
</td></tr>
<tr><td><code id="pReplicate_+3A_c">c</code></td>
<td>
<p>The ratio of the variances of the original and replication effect estimates.
This is usually the ratio of the sample size of the replication study to the sample
size of the original study.</p>
</td></tr>
<tr><td><code id="pReplicate_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;two.sided&quot; (default) or &quot;one.sided&quot;.
Specifies whether the p-value is two-sided or one-sided.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This extends the statistic p_rep (&quot;the probability of replicating an effect&quot;)
by Killeen (2005) to the case of possibly unequal sample sizes, see also Senn (2002).
</p>


<h3>Value</h3>

<p>The probability that a replication study yields an effect
estimate in the same direction as in the original study.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held
</p>


<h3>References</h3>

<p>Killeen, P. R. (2005). An alternative to null-hypothesis significance
tests. <em>Psychological Science</em>, <b>16</b>, 345&ndash;353. <a href="https://doi.org/10.1111/j.0956-7976.2005.01538.x">doi:10.1111/j.0956-7976.2005.01538.x</a>
</p>
<p>Senn, S. (2002). Letter to the Editor, <em>Statistics in Medicine</em>, <b>21</b>, 2437&ndash;2444.
</p>
<p>Held, L. (2019). The assessment of intrinsic credibility and a new argument
for <em>p &lt; 0.005</em>. <em>Royal Society Open Science</em>, <b>6</b>, 181534.
<a href="https://doi.org/10.1098/rsos.181534">doi:10.1098/rsos.181534</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pReplicate(po = c(0.05, 0.01, 0.001), c = 1)
pReplicate(po = c(0.05, 0.01, 0.001), c = 2)
pReplicate(po = c(0.05, 0.01, 0.001), c = 2, alternative = "one.sided")
pReplicate(zo = c(2, 3, 4), c = 1)
</code></pre>

<hr>
<h2 id='protzko2020'>Data from Protzko et al. (2020)</h2><span id='topic+protzko2020'></span>

<h3>Description</h3>

<p>Data from &quot;High Replicability of Newly-Discovered Social-behavioral
Findings is Achievable&quot; by Protzko et al. (2020). The variables are as follows:
</p>

<dl>
<dt><code>experiment</code></dt><dd><p>Experiment name</p>
</dd>
<dt><code>type</code></dt><dd><p>Type of study, either &quot;original&quot;, &quot;self-replication&quot;, or
&quot;external-replication&quot;</p>
</dd>
<dt><code>lab</code></dt><dd><p>The lab which conducted the study, either 1, 2, 3, or 4.</p>
</dd>
<dt><code>smd</code></dt><dd><p>Standardized mean difference effect estimate</p>
</dd>
<dt><code>se</code></dt><dd><p>Standard error of standardized mean difference effect estimate</p>
</dd>
<dt><code>n</code></dt><dd><p>Total sample size of the study</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data("protzko2020")
</code></pre>


<h3>Format</h3>

<p>A data frame with 80 rows and 6 variables
</p>


<h3>Details</h3>

<p>This data set originates from a prospective replication project
involving four laboratories. Each of them conducted four original studies
and for each original study a replication study was carried out within
the same lab (self-replication) and by the other three labs
(external-replication). Most studies used simple between-subject designs
with two groups and a continuous outcome so that for each study, an
estimate of the standardized mean difference (SMD) could be computed from
the group means, group standard deviations, and group sample sizes. For
studies with covariate adjustment and/or binary outcomes, effect size
transformations as described in the supplementary material of Protzko
(2020) were used to obtain effect estimates and standard errors on SMD
scale. The data set is licensed under a CC-By Attribution 4.0
International license, see
<a href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a> for the terms of
reuse.
</p>


<h3>Source</h3>

<p>The relevant files were downloaded from <a href="https://osf.io/42ef9/">https://osf.io/42ef9/</a>
on January 24, 2022. The R markdown script
&quot;Decline effects main analysis.Rmd&quot; was executed and the relevant
variables from the objects &quot;ES_experiments&quot; and &quot;decline_effects&quot; were
saved.
</p>


<h3>References</h3>

<p>Protzko, J., Krosnick, J., Nelson, L. D., Nosek, B. A., Axt, J.,
Berent, M., ... Schooler, J. (2020, September 10). High Replicability of
Newly-Discovered Social-behavioral Findings is Achievable.
<a href="https://doi.org/10.31234/osf.io/n2a9x">doi:10.31234/osf.io/n2a9x</a>
</p>
<p>Protzko, J., Berent, M., Buttrick, N., DeBell, M., Roeder, S. S., Walleczek,
J., ... Nosek, B. A. (2021, January 5). Results &amp; Data. Retrieved from
<a href="https://osf.io/42ef9/">https://osf.io/42ef9/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("protzko2020", package = "ReplicationSuccess")

## forestplots of effect estimates
graphics.off()
parOld &lt;- par(mar = c(5, 8, 4, 2), mfrow = c(4, 4))
experiments &lt;- unique(protzko2020$experiment)
for (ex in experiments) {
  ## compute CIs
  dat &lt;- subset(protzko2020, experiment == ex)
  za &lt;- qnorm(p = 0.975)
  plotDF &lt;- data.frame(lower = dat$smd - za*dat$se,
                       est = dat$smd,
                       upper = dat$smd + za*dat$se)
colpalette &lt;- c("#000000", "#1B9E77", "#D95F02")
cols &lt;- colpalette[dat$type]
yseq &lt;- seq(1, nrow(dat))

## forestplot
plot(x = plotDF$est, y = yseq, xlim = c(-0.15, 0.8),
     ylim = c(0.8*min(yseq), 1.05*max(yseq)), type = "n",
     yaxt = "n", xlab = "Effect estimate (SMD)", ylab = "")
abline(v = 0, col = "#0000004D")
arrows(x0 = plotDF$lower, x1 = plotDF$upper, y0 = yseq, angle = 90,
       code = 3, length = 0.05, col = cols)
points(y = yseq, x = plotDF$est, pch = 20, lwd = 2, col = cols)
axis(side = 2, at = yseq, las = 1, labels = dat$type, cex.axis = 0.85)
title(main = ex)
}
par(parOld)
</code></pre>

<hr>
<h2 id='pSceptical'>Computes the sceptical p-value and z-value</h2><span id='topic+pSceptical'></span><span id='topic+zSceptical'></span>

<h3>Description</h3>

<p>Computes sceptical p-values and z-values based on the z-values of the
original and the replication study and the corresponding variance ratios.
If specified, the sceptical p-values are recalibrated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pSceptical(
  zo,
  zr,
  c,
  alternative = c("one.sided", "two.sided"),
  type = c("golden", "nominal", "controlled")
)

zSceptical(zo, zr, c)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pSceptical_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from original studies.</p>
</td></tr>
<tr><td><code id="pSceptical_+3A_zr">zr</code></td>
<td>
<p>Numeric vector of z-values from replication studies.</p>
</td></tr>
<tr><td><code id="pSceptical_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication
effect estimates. This is usually the ratio of the sample
size of the replication study to the sample size of the
original study.</p>
</td></tr>
<tr><td><code id="pSceptical_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;one.sided&quot; (default) or &quot;two.sided&quot;.
If &quot;one.sided&quot;, the sceptical p-value is based on a one-sided
assessment of replication success in the direction of the original effect
estimate. If &quot;two.sided&quot;, the sceptical p-value is based on a two-sided
assessment of replication success regardless of the direction of the
original and replication effect estimate.</p>
</td></tr>
<tr><td><code id="pSceptical_+3A_type">type</code></td>
<td>
<p>Type of recalibration. Can be either &quot;golden&quot; (default),
&quot;nominal&quot;, or &quot;controlled&quot;. Setting <code>type</code> to &quot;nominal&quot; corresponds
to no recalibration as in Held et al. (2020). A recalibration is applied if
<code>type</code> is  &quot;controlled&quot;, or &quot;golden&quot;, and the sceptical p-value
can then be interpreted on the same scale as an ordinary
p-value (e.g., a one-sided
sceptical p-value can be thresholded at the conventional 0.025 level).
&quot;golden&quot; ensures that
for an original study just significant at the specified <code>level</code>,
replication success is only possible if the replication effect estimate is at
least as large as the original one.
&quot;controlled&quot; ensures exact overall Type-I error control at
level <code>level</code>^2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pSceptical</code> is the vectorized version of
the internal function <code>.pSceptical_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p><code>pSceptical</code> returns the sceptical p-value.
</p>
<p><code>zSceptical</code> returns the z-value of the sceptical p-value.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held
</p>


<h3>References</h3>

<p>Held, L. (2020). A new standard for the analysis and design of replication
studies (with discussion). <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <b>183</b>, 431-448.
<a href="https://doi.org/10.1111/rssa.12493">doi:10.1111/rssa.12493</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size. <em>The Annals of Applied
Statistics</em>. 16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Balabdaoui, F., Held, L. (2023). Assessing replicability
with the sceptical p-value: Type-I error control and
sample size planning. <em>Statistica Neerlandica</em>. <a href="https://doi.org/10.1111/stan.12312">doi:10.1111/stan.12312</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleSizeReplicationSuccess">sampleSizeReplicationSuccess</a></code>,
<code><a href="#topic+powerReplicationSuccess">powerReplicationSuccess</a></code>, <code><a href="#topic+levelSceptical">levelSceptical</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## no recalibration (type = "nominal") as in Held (2020)
pSceptical(zo = p2z(0.01), zr = p2z(0.02), c = 2, alternative = "one.sided",
           type = "nominal")

## recalibration with golden level as in Held, Micheloud, Pawel (2020)
pSceptical(zo = p2z(0.01), zr = p2z(0.02), c = 2, alternative = "one.sided",
           type = "golden")

## two-sided p-values 0.01 and 0.02, relative sample size 2
pSceptical(zo = p2z(0.01), zr = p2z(0.02), c = 2, alternative = "one.sided")
## reverse the studies
pSceptical(
  zo = p2z(0.02),
  zr = p2z(0.01),
  c = 1/2,
  alternative = "one.sided"
)
## both p-values 0.01, relative sample size 2
pSceptical(zo = p2z(0.01), zr = p2z(0.01), c = 2, alternative = "two.sided")

zSceptical(zo = 2, zr = 3, c = 2)
zSceptical(zo = 3, zr = 2, c = 2)
</code></pre>

<hr>
<h2 id='pvalueBound'>Bound for the p-values entering the harmonic mean chi-squared test</h2><span id='topic+pvalueBound'></span>

<h3>Description</h3>

<p>Necessary or sufficient bounds for significance of the harmonic mean
chi-squared test are computed for n one-sided p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvalueBound(alpha, n, type = c("necessary", "sufficient"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvalueBound_+3A_alpha">alpha</code></td>
<td>
<p>Numeric vector specifying the significance level.</p>
</td></tr>
<tr><td><code id="pvalueBound_+3A_n">n</code></td>
<td>
<p>The number of p-values.</p>
</td></tr>
<tr><td><code id="pvalueBound_+3A_type">type</code></td>
<td>
<p>Either &quot;necessary&quot; (default) or &quot;sufficient&quot;.
If &quot;necessary&quot;, the necessary bounds are computed.
If &quot;sufficient&quot;, the sufficient bounds are computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The bound for the p-values.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held
</p>


<h3>References</h3>

<p>Held, L. (2020). The harmonic mean chi-squared test to substantiate
scientific findings. <em>Journal of the Royal Statistical Society: Series C
(Applied Statistics)</em>, <b>69</b>, 697-708. <a href="https://doi.org/10.1111/rssc.12410">doi:10.1111/rssc.12410</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hMeanChiSq">hMeanChiSq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pvalueBound(alpha = 0.025^2, n = 2, type = "necessary")
pvalueBound(alpha = 0.025^2, n = 2, type = "sufficient")
</code></pre>

<hr>
<h2 id='Qtest'>Q-test to assess compatibility between original and replication effect estimate</h2><span id='topic+Qtest'></span>

<h3>Description</h3>

<p>Computes p-value from meta-analytic Q-test to assess compatibility between
original and replication effect estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Qtest(thetao, thetar, seo, ser)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Qtest_+3A_thetao">thetao</code></td>
<td>
<p>Numeric vector of effect estimates from original studies.</p>
</td></tr>
<tr><td><code id="Qtest_+3A_thetar">thetar</code></td>
<td>
<p>Numeric vector of effect estimates from replication studies.</p>
</td></tr>
<tr><td><code id="Qtest_+3A_seo">seo</code></td>
<td>
<p>Numeric vector of standard errors of the original effect estimates.</p>
</td></tr>
<tr><td><code id="Qtest_+3A_ser">ser</code></td>
<td>
<p>Numeric vector of standard errors of the replication effect estimates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the p-value from a meta-analytic Q-test assessing
compatibility between original and replication effect estimate. Rejecting
compatibility when the p-value is smaller than alpha is equivalent with
rejecting compatibility based on a (1 - alpha) prediction interval.
</p>


<h3>Value</h3>

<p>p-value from Q-test.
</p>


<h3>Author(s)</h3>

<p>Samuel Pawel
</p>


<h3>References</h3>

<p>Hedges, L. V., Schauer, J. M. (2019). More Than One Replication Study Is
Needed for Unambiguous Tests of Replication. <em>Journal of Educational and
Behavioral Statistics</em>, <b>44</b>, 543-570.
<a href="https://doi.org/10.3102/1076998619852953">doi:10.3102/1076998619852953</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predictionInterval">predictionInterval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Qtest(thetao = 2, thetar = 0.5, seo = 1, ser = 0.5)
</code></pre>

<hr>
<h2 id='RProjects'>Data from four large-scale replication projects</h2><span id='topic+RProjects'></span>

<h3>Description</h3>

<p>Data from <em>Reproduciblity Project Psychology</em> (RPP),
<em>Experimental Economics Replication Project</em> (EERP), <em>Social
Sciences Replication Project</em> (SSRP), <em>Experimental Philosophy
Replicability Project</em> (EPRP). The variables are as follows:
</p>

<dl>
<dt><code>study</code></dt><dd><p>Study identifier, usually names of authors
from original study</p>
</dd>
<dt><code>project</code></dt><dd><p>Name of replication project</p>
</dd>
<dt><code>ro</code></dt><dd><p>Effect estimate of original study on correlation scale</p>
</dd>
<dt><code>rr</code></dt><dd><p>Effect estimate of replication study on correlation scale</p>
</dd>
<dt><code>fiso</code></dt><dd><p>Effect estimate of original study transformed to
Fisher-z scale</p>
</dd>
<dt><code>fisr</code></dt><dd><p>Effect estimate of replication study transformed
to Fisher-z scale</p>
</dd>
<dt><code>se_fiso</code></dt><dd><p>Standard error of Fisher-z transformed effect estimate
of original study</p>
</dd>
<dt><code>se_fisr</code></dt><dd><p>Standard error of Fisher-z transformed effect estimate
of replication study</p>
</dd>
<dt><code>po</code></dt><dd><p>Two-sided p-value from significance test of effect estimate
from original study</p>
</dd>
<dt><code>pr</code></dt><dd><p>Two-sided p-value from significance test of effect estimate
from replication study</p>
</dd>
<dt><code>po1</code></dt><dd><p>One-sided p-value from significance test of effect estimate
from original study (in the direction of the original effect estimate)</p>
</dd>
<dt><code>pr1</code></dt><dd><p>One-sided p-value from significance test of effect estimate
from replication study (in the direction of the original effect estimate)</p>
</dd>
<dt><code>pm_belief</code></dt><dd><p>Peer belief about whether replication effect estimate
will achieve statistical significance elicited through prediction market (only
available for EERP and SSRP)</p>
</dd>
<dt><code>no</code></dt><dd><p>Sample size in original study</p>
</dd>
<dt><code>nr</code></dt><dd><p>Sample size in replication study</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(RProjects)
</code></pre>


<h3>Format</h3>

<p>A data frame with 143 rows and 15 variables
</p>


<h3>Details</h3>

<p>Two-sided p-values were calculated assuming normality of Fisher-z
transformed effect estimates. From the RPP only the <em>meta-analytic
subset</em> is included, which consists of 73 out of 100 study pairs for
which the standard error of the z-transformed correlation coefficient can
be computed. For the RPP sample sizes were recalculated from the reported
standard errors of Fisher z-transformed correlation coefficients. From
the EPRP only 31 out of 40 study pairs are included where effective
sample size for original and replication study are available
simultaneously. For more details about how the the data was preprocessed
see source below and supplement S1 of Pawel and Held (2020).
</p>


<h3>Source</h3>

<p>RPP: The source files were downloaded from
<a href="https://github.com/CenterForOpenScience/rpp/">https://github.com/CenterForOpenScience/rpp/</a>. The &quot;masterscript.R&quot;
file was executed and the relevant variables were extracted from the
generated &quot;final&quot; object (standard errors of Fisher-z transformed
correlations) and &quot;MASTER&quot; object (everything else). The data set is
licensed under a CC0 1.0 Universal license, see
<a href="https://creativecommons.org/publicdomain/zero/1.0/">https://creativecommons.org/publicdomain/zero/1.0/</a> for the terms of
reuse.
</p>
<p>EERP: The source files were downloaded from <a href="https://osf.io/pnwuz/">https://osf.io/pnwuz/</a>. The
required data were then manually extracted from the code in the files
&quot;effectdata.py&quot; (sample sizes) and &quot;create_studydetails.do&quot; (everything
else). Data regarding the prediction market and survey beliefs were manually
extracted from table S3 of the supplementary materials of the EERP. The
authors of this R package have been granted permission to share this data set
by the coordinators of the EERP.
</p>
<p>SSRP: The relevant variables were extracted from the file
&quot;D3 - ReplicationResults.csv&quot; downloaded from <a href="https://osf.io/abu7k">https://osf.io/abu7k</a>. For
replications which underwent only the first stage, the data from the first
stage were taken as the data for the replication study. For the replications
which reached the second stage, the pooled data from both stages were taken
as the data for the replication study. Data regarding survey and prediction
market beliefs were extracted from the &quot;D6 - MeanPeerBeliefs.csv&quot; file, which
was downloaded from <a href="https://osf.io/vr6p8/">https://osf.io/vr6p8/</a>. The data set is licensed
under a CC0 1.0 Universal license, see
<a href="https://creativecommons.org/publicdomain/zero/1.0/">https://creativecommons.org/publicdomain/zero/1.0/</a> for the terms of
reuse.
</p>
<p>EPRP: Data were taken from the &quot;XPhiReplicability_CompleteData.csv&quot; file,
which was downloaded from <a href="https://osf.io/4ewkh/">https://osf.io/4ewkh/</a>. The authors of this R
package have been granted permission to share this data set by the
coordinators of the EPRP.
</p>


<h3>References</h3>

<p>Camerer, C. F., Dreber, A., Forsell, E., Ho, T.-H., Huber, J.,
Johannesson, M., ... Hang, W. (2016). Evaluating replicability of
laboratory experiments in economics. <em>Science</em>, <b>351</b>, 1433-1436.
<a href="https://doi.org/10.1126/science.aaf0918">doi:10.1126/science.aaf0918</a>
</p>
<p>Camerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J.,
Johannesson, M., ... Wu, H. (2018). Evaluating the replicability of
social science experiments in Nature and Science between 2010 and 2015.
<em>Nature Human Behaviour</em>, <b>2</b>, 637-644.
<a href="https://doi.org/10.1038/s41562-018-0399-z">doi:10.1038/s41562-018-0399-z</a>
</p>
<p>Cova, F., Strickland, B., Abatista, A., Allard, A., Andow, J., Attie, M., ...
Zhou, X. (2018). Estimating the reproducibility of experimental philosophy.
<em>Review of Philosophy and Psychology</em>. <a href="https://doi.org/10.1007/s13164-018-0400-9">doi:10.1007/s13164-018-0400-9</a>
</p>
<p>Open Science Collaboration. (2015). Estimating the reproducibility of
psychological science. <em>Science</em>, <b>349</b>, aac4716.
<a href="https://doi.org/10.1126/science.aac4716">doi:10.1126/science.aac4716</a>
</p>
<p>Pawel, S., Held, L. (2020). Probabilistic forecasting of replication studies.
<em>PLoS ONE</em>. <b>15</b>, e0231416. <a href="https://doi.org/10.1371/journal.pone.0231416">doi:10.1371/journal.pone.0231416</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SSRP">SSRP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("RProjects", package = "ReplicationSuccess")

## Computing key quantities
RProjects$zo &lt;- RProjects$fiso/RProjects$se_fiso
RProjects$zr &lt;- RProjects$fisr/RProjects$se_fisr
RProjects$c &lt;- RProjects$se_fiso^2/RProjects$se_fisr^2

## Computing one-sided p-values for alternative = "greater"
RProjects$po1 &lt;- z2p(z = RProjects$zo, alternative = "greater")
RProjects$pr1 &lt;- z2p(z = RProjects$zr, alternative = "greater")

## Plots of effect estimates
parOld &lt;- par(mfrow = c(2, 2))
for (p in unique(RProjects$project)) {
  data_project &lt;- subset(RProjects, project == p)
  plot(rr ~ ro, data = data_project, ylim = c(-0.5, 1),
       xlim = c(-0.5, 1), main = p, xlab = expression(italic(r)[o]),
       ylab = expression(italic(r)[r]))
  abline(h = 0, lty = 2)
  abline(a = 0, b = 1, col = "grey")
}
par(parOld)

## Plots of peer beliefs
RProjects$significant &lt;- factor(RProjects$pr &lt; 0.05,
                                levels = c(FALSE, TRUE),
                                labels = c("no", "yes"))
parOld &lt;- par(mfrow = c(1, 2))
for (p in c("Experimental Economics", "Social Sciences")) {
  data_project &lt;- subset(RProjects, project == p)
  boxplot(pm_belief ~ significant, data = data_project, ylim = c(0, 1),
          main = p, xlab = "Replication effect significant", ylab = "Peer belief")
  stripchart(pm_belief ~ significant, data = data_project, vertical = TRUE,
             add = TRUE, pch = 1, method = "jitter")
}
par(parOld)

## Computing the sceptical p-value
ps &lt;- with(RProjects, pSceptical(zo = fiso/se_fiso,
                                 zr = fisr/se_fisr,
                                 c = se_fiso^2/se_fisr^2))
</code></pre>

<hr>
<h2 id='sampleSizeReplicationSuccess'>Computes the required relative sample size to achieve replication success
with the sceptical p-value</h2><span id='topic+sampleSizeReplicationSuccess'></span>

<h3>Description</h3>

<p>The relative sample size to achieve replication success is computed based on
the z-value of the original study,  the type of
recalibration, the power and the design prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleSizeReplicationSuccess(
  zo,
  power = NA,
  level = 0.025,
  alternative = c("one.sided", "two.sided"),
  type = c("golden", "nominal", "controlled"),
  designPrior = c("conditional", "predictive", "EB"),
  shrinkage = 0,
  h = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleSizeReplicationSuccess_+3A_zo">zo</code></td>
<td>
<p>Numeric vector of z-values from original studies.</p>
</td></tr>
<tr><td><code id="sampleSizeReplicationSuccess_+3A_power">power</code></td>
<td>
<p>The power to achieve replication success.</p>
</td></tr>
<tr><td><code id="sampleSizeReplicationSuccess_+3A_level">level</code></td>
<td>
<p>Threshold for the calibrated sceptical p-value.
Default is 0.025.</p>
</td></tr>
<tr><td><code id="sampleSizeReplicationSuccess_+3A_alternative">alternative</code></td>
<td>
<p>Specifies if <code>level</code> is &quot;one.sided&quot; (default) or
&quot;two.sided&quot;. If &quot;one.sided&quot; then sample size calculations are based
on a one-sided assessment of replication success in the direction of the
original effect estimates.</p>
</td></tr>
<tr><td><code id="sampleSizeReplicationSuccess_+3A_type">type</code></td>
<td>
<p>Type of recalibration. Can be either &quot;golden&quot; (default),
&quot;nominal&quot; (no recalibration), or &quot;controlled&quot;. &quot;golden&quot; ensures that for
an original study just significant at the specified <code>level</code>,
replication success is only possible for replication effect estimates
larger than the original one. &quot;controlled&quot; ensures exact overall Type-I
error control at level <code>level</code>^2.</p>
</td></tr>
<tr><td><code id="sampleSizeReplicationSuccess_+3A_designprior">designPrior</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified.
Either &quot;conditional&quot; (default), &quot;predictive&quot;, or &quot;EB&quot;. If &quot;EB&quot;, the power
is computed under a predictive distribution where the contribution of the
original study is shrunken towards zero based on the evidence in the
original study (with an empirical Bayes shrinkage estimator).</p>
</td></tr>
<tr><td><code id="sampleSizeReplicationSuccess_+3A_shrinkage">shrinkage</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified. A
number in [0,1) with default 0. Specifies the shrinkage of the original
effect estimate towards zero (e.g., the effect is shrunken by a factor of
25% for <code>shrinkage = 0.25</code>). Is only taken into account when the
<code>designPrior</code> is &quot;conditional&quot; or &quot;predictive&quot;.</p>
</td></tr>
<tr><td><code id="sampleSizeReplicationSuccess_+3A_h">h</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified and
<code>designPrior</code> is &quot;predictive&quot; or &quot;EB&quot;. The relative between-study
heterogeneity, i.e., the ratio of the heterogeneity variance to the
variance of the original effect estimate. Default is 0 (no
heterogeneity).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sampleSizeReplicationSuccess</code> is the vectorized version of
the internal function <code>.sampleSizeReplicationSuccess_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The relative sample size for replication success. If impossible to
achieve the desired power for specified inputs <code>NaN</code> is returned.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held, Charlotte Micheloud, Samuel Pawel, Florian Gerber
</p>


<h3>References</h3>

<p>Held, L. (2020). A new standard for the analysis and design of replication
studies (with discussion). <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <b>183</b>, 431-448.
<a href="https://doi.org/10.1111/rssa.12493">doi:10.1111/rssa.12493</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size. <em>The Annals of Applied
Statistics</em>. 16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Balabdaoui, F., Held, L. (2023). Assessing replicability
with the sceptical p-value: Type-I error control and
sample size planning. <em>Statistica Neerlandica</em>. <a href="https://doi.org/10.1111/stan.12312">doi:10.1111/stan.12312</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pSceptical">pSceptical</a></code>, <code><a href="#topic+powerReplicationSuccess">powerReplicationSuccess</a></code>,
<code><a href="#topic+levelSceptical">levelSceptical</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## based on power
sampleSizeReplicationSuccess(zo = p2z(0.0025), power = 0.8, level = 0.025,
                             type = "golden")
sampleSizeReplicationSuccess(zo = p2z(0.0025), power = 0.8, level = 0.025,
                             type = "golden", designPrior = "predictive")
</code></pre>

<hr>
<h2 id='sampleSizeSignificance'>Computes the required relative sample size to achieve significance
based on power</h2><span id='topic+sampleSizeSignificance'></span>

<h3>Description</h3>

<p>The relative sample size to achieve significance of the replication study is
computed based on the z-value of the original study, the significance level
and the power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleSizeSignificance(
  zo,
  power = NA,
  level = 0.025,
  alternative = c("one.sided", "two.sided"),
  designPrior = c("conditional", "predictive", "EB"),
  h = 0,
  shrinkage = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleSizeSignificance_+3A_zo">zo</code></td>
<td>
<p>A vector of z-values from original studies.</p>
</td></tr>
<tr><td><code id="sampleSizeSignificance_+3A_power">power</code></td>
<td>
<p>The power to achieve replication success.</p>
</td></tr>
<tr><td><code id="sampleSizeSignificance_+3A_level">level</code></td>
<td>
<p>Significance level. Default is 0.025.</p>
</td></tr>
<tr><td><code id="sampleSizeSignificance_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;one.sided&quot; (default) or &quot;two.sided&quot;.
Specifies if the significance level is one-sided or two-sided.
If the significance level is one-sided, then sample size calculations are based on a
one-sided assessment of significance in the direction of the
original effect estimate.</p>
</td></tr>
<tr><td><code id="sampleSizeSignificance_+3A_designprior">designPrior</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified.
Either &quot;conditional&quot; (default), &quot;predictive&quot;, or &quot;EB&quot;. If &quot;EB&quot;, the power
is computed under a predictive distribution where the contribution of the
original study is shrunken towards zero based on the evidence in the
original study (with an empirical Bayes shrinkage estimator).</p>
</td></tr>
<tr><td><code id="sampleSizeSignificance_+3A_h">h</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified and
<code>designPrior</code> is &quot;predictive&quot; or &quot;EB&quot;. The relative between-study
heterogeneity, i.e., the ratio of the heterogeneity variance to the
variance of the original effect estimate. Default is 0 (no
heterogeneity).</p>
</td></tr>
<tr><td><code id="sampleSizeSignificance_+3A_shrinkage">shrinkage</code></td>
<td>
<p>Is only taken into account when <code>power</code> is specified. A
number in [0,1) with default 0. Specifies the shrinkage of the original effect
towards zero (e.g., <code>shrinkage = 0.25</code> implies shrinkage by a
factor of 25%). Is only taken into account when <code>designPrior</code> is
&quot;conditional&quot; or &quot;predictive&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sampleSizeSignificance</code> is the vectorized version of
<code>.sampleSizeSignificance_</code>. <code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to
vectorize the function.
</p>


<h3>Value</h3>

<p>The relative sample size to achieve significance in the specified
direction. If impossible to achieve the desired power for specified
inputs <code>NaN</code> is returned.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held, Samuel Pawel, Charlotte Micheloud, Florian Gerber
</p>


<h3>References</h3>

<p>Held, L. (2020). A new standard for the analysis and design of replication
studies (with discussion). <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <b>183</b>, 431-448.
<a href="https://doi.org/10.1111/rssa.12493">doi:10.1111/rssa.12493</a>
</p>
<p>Pawel, S., Held, L. (2020). Probabilistic forecasting of replication studies.
<em>PLoS ONE</em>. <b>15</b>, e0231416. <a href="https://doi.org/10.1371/journal.pone.0231416">doi:10.1371/journal.pone.0231416</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size. The Annals of Applied Statistics.
16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Held, L. (2022). Power Calculations for Replication Studies.
Statistical Science. 37:369-379. <a href="https://doi.org/10.1214/21-STS828">doi:10.1214/21-STS828</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+powerSignificance">powerSignificance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sampleSizeSignificance(zo = p2z(0.005), power = 0.8)
sampleSizeSignificance(zo = p2z(0.005, alternative = "two.sided"), power = 0.8)
sampleSizeSignificance(zo = p2z(0.005), power = 0.8, designPrior = "predictive")

sampleSizeSignificance(zo = 3, power = 0.8, designPrior = "predictive",
                       shrinkage = 0.5, h = 0.25)
sampleSizeSignificance(zo = 3, power = 0.8, designPrior = "EB",  h = 0.5)

# sample size to achieve  0.8 power as function of original p-value
zo &lt;- p2z(seq(0.0001, 0.05, 0.0001))
oldPar &lt;- par(mfrow = c(1,2))
plot(z2p(zo), sampleSizeSignificance(zo = zo, designPrior = "conditional", power = 0.8),
     type = "l", ylim = c(0.5, 10), log = "y", lwd = 1.5, ylab = "Relative sample size",
     xlab = expression(italic(p)[o]), las = 1)
lines(z2p(zo), sampleSizeSignificance(zo = zo, designPrior = "predictive", power = 0.8),
      lwd = 2, lty = 2)
lines(z2p(zo), sampleSizeSignificance(zo = zo, designPrior = "EB", power = 0.8),
      lwd = 1.5, lty = 3)
legend("topleft", legend = c("conditional", "predictive", "EB"),
       title = "Design prior", lty = c(1, 2, 3), lwd = 1.5, bty = "n")

par(oldPar)
</code></pre>

<hr>
<h2 id='SSRP'>Data from the Social Sciences Replication Project</h2><span id='topic+SSRP'></span>

<h3>Description</h3>

<p>Data from the <em>Social Sciences Replication Project</em> (SSRP)
including the details of the interim analysis. The variables are as follows:
</p>

<dl>
<dt><code>study</code></dt><dd><p>Study identifier, usually names of authors
from original study</p>
</dd>
<dt><code>ro</code></dt><dd><p>Effect estimate of original study on correlation scale</p>
</dd>
<dt><code>ri</code></dt><dd><p>Effect estimate of replication study at the interim analysis
on correlation scale</p>
</dd>
<dt><code>rr</code></dt><dd><p>Effect estimate of replication study at the final analysis
on correlation scale</p>
</dd>
<dt><code>fiso</code></dt><dd><p>Effect estimate of original study transformed to
Fisher-z scale</p>
</dd>
<dt><code>fisi</code></dt><dd><p>Effect estimate of replication study at
the interim analysis transformed to Fisher-z scale</p>
</dd>
<dt><code>fisr</code></dt><dd><p>Effect estimate of replication study at the final analysis
transformed to Fisher-z scale</p>
</dd>
<dt><code>se_fiso</code></dt><dd><p>Standard error of Fisher-z transformed effect estimate
of original study</p>
</dd>
<dt><code>se_fisi</code></dt><dd><p>Standard error of Fisher-z transformed effect estimate
of replication study at the interim analysis</p>
</dd>
<dt><code>se_fisr</code></dt><dd><p>Standard error of Fisher-z transformed effect estimate
of replication study at the final analysis</p>
</dd>
<dt><code>no</code></dt><dd><p> Sample size in original study</p>
</dd>
<dt><code>ni</code></dt><dd><p>Sample size in replication study at the interim analysis</p>
</dd>
<dt><code>nr</code></dt><dd><p>Sample size in replication study at the final analysis</p>
</dd>
<dt><code>po</code></dt><dd><p>Two-sided p-value from significance test of effect estimate
from original study</p>
</dd>
<dt><code>pi</code></dt><dd><p>Two-sided p-value from significance test of effect
estimate from replication study at the interim analysis</p>
</dd>
<dt><code>pr</code></dt><dd><p>Two-sided p-value from significance test of effect estimate
from replication study at the final analysis</p>
</dd>
<dt><code>n75</code></dt><dd><p>Sample size calculated to have 90% power in replication study
to detect 75% of the original effect size (expressed as the correlation
coefficient r)</p>
</dd>
<dt><code>n50</code></dt><dd><p>Sample size calculated to have 90% power in replication
study to detect 50% of the original effect size (expressed as the correlation
coefficient r)</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(SSRP)
</code></pre>


<h3>Format</h3>

<p>A data frame with 21 rows and 18 variables
</p>


<h3>Details</h3>

<p>Two-sided p-values were calculated assuming normality of Fisher-z
transformed effect estimates.A two-stage procedure was used for the
replications. In stage 1, the authors had 90% power to detect 75% of
the original effect size at the 5% significance level in a two-sided
test. If the original result replicated in stage 1 (two-sided P-value &lt;
0.05 and effect in the same direction as in the original study), the data
collection was stopped. If not, a second data collection was carried out
in stage 2 to have 90% power to detect 50% of the original effect size
for the first and the second data collections pooled. <code>n75</code> and
<code>n50</code> are the planned sample sizes calculated to reach 90% power in
stage 1 and 2, respectively. They sometimes differ from the sample sizes
that were actually collected (<code>ni</code> and <code>nr</code>, respectively). See
supplementary information of Camerer et al. (2018) for details.
</p>


<h3>Source</h3>

<p><a href="https://osf.io/abu7k">https://osf.io/abu7k</a>
</p>


<h3>References</h3>

<p>Camerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber,
J., Johannesson, M., ... Wu, H. (2018). Evaluating the replicability of
social science experiments in Nature and Science between 2010 and 2015.
<em>Nature Human Behaviour</em>, <b>2</b>, 637-644.
<a href="https://doi.org/10.1038/s41562-018-0399-z">doi:10.1038/s41562-018-0399-z</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RProjects">RProjects</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># plot of the sample sizes
plot(ni ~ no, data = SSRP, ylim = c(0, 2500), xlim = c(0, 400),
     xlab = expression(n[o]), ylab = expression(n[i]))
abline(a = 0, b = 1, col = "grey")


plot(nr ~ no, data = SSRP, ylim = c(0, 2500), xlim = c(0, 400),
     xlab = expression(n[o]), ylab = expression(n[r]))
abline(a = 0, b = 1, col = "grey")


</code></pre>

<hr>
<h2 id='T1EpSceptical'>Compute overall type-I error rate of the sceptical p-value</h2><span id='topic+T1EpSceptical'></span>

<h3>Description</h3>

<p>The overall type-I error rate of the sceptical p-value is computed for a
specified level, the relative variance,
and the alternative hypothesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>T1EpSceptical(
  level,
  c,
  alternative = c("one.sided", "two.sided"),
  type = c("golden", "nominal", "controlled")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="T1EpSceptical_+3A_level">level</code></td>
<td>
<p>Threshold for the calibrated sceptical p-value.
Default is 0.025.</p>
</td></tr>
<tr><td><code id="T1EpSceptical_+3A_c">c</code></td>
<td>
<p>Numeric vector of variance ratios of the original and replication
effect estimates. This is usually the ratio of the sample
size of the replication study to the sample size of the
original study.</p>
</td></tr>
<tr><td><code id="T1EpSceptical_+3A_alternative">alternative</code></td>
<td>
<p>Specifies if <code>level</code>
is &quot;two.sided&quot; or &quot;one.sided&quot;.</p>
</td></tr>
<tr><td><code id="T1EpSceptical_+3A_type">type</code></td>
<td>
<p>Type of recalibration. Recalibration type can be either &quot;golden&quot;
(default), &quot;nominal&quot; (no recalibration), or &quot;controlled&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>T1EpSceptical</code> is the vectorized version of
the internal function <code>.T1EpSceptical_</code>.
<code><a href="base.html#topic+Vectorize">Vectorize</a></code> is used to vectorize the function.
</p>


<h3>Value</h3>

<p>The overall type-I error rate.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held, Samuel Pawel
</p>


<h3>References</h3>

<p>Held, L. (2020). The harmonic mean chi-squared test to substantiate
scientific findings. <em>Journal of the Royal Statistical Society: Series C
(Applied Statistics)</em>, <b>69</b>, 697-708. <a href="https://doi.org/10.1111/rssc.12410">doi:10.1111/rssc.12410</a>
</p>
<p>Held, L., Micheloud, C., Pawel, S. (2022). The assessment of replication
success based on relative effect size. The Annals of Applied Statistics.
16:706-720. <a href="https://doi.org/10.1214/21-AOAS1502">doi:10.1214/21-AOAS1502</a>
</p>
<p>Micheloud, C., Balabdaoui, F., Held, L. (2023). Assessing replicability
with the sceptical p-value: Type-I error control and
sample size planning. <em>Statistica Neerlandica</em>. <a href="https://doi.org/10.1111/stan.12312">doi:10.1111/stan.12312</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pSceptical">pSceptical</a></code>, <code><a href="#topic+levelSceptical">levelSceptical</a></code>,
<code><a href="#topic+PPpSceptical">PPpSceptical</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## compare type-I error rate for different recalibration types
types &lt;- c("nominal", "golden", "controlled")
c &lt;- seq(0.2, 5, by = 0.05)
t1 &lt;- sapply(X = types, FUN = function(t) {
  T1EpSceptical(type = t, c = c, alternative = "one.sided", level = 0.025)
})
matplot(
  x = c, y = t1*100, type = "l", lty = 1, lwd = 2, las = 1, log = "x",
  xlab = bquote(italic(c)), ylab = "Type-I error (%)",
  xlim = c(0.2, 5)
)
legend("topright", legend = types, lty = 1, lwd = 2, col = seq_along(types))

</code></pre>

<hr>
<h2 id='thresholdIntrinsic'>Computes the p-value threshold for intrinsic credibility</h2><span id='topic+thresholdIntrinsic'></span>

<h3>Description</h3>

<p>Computes the p-value threshold for intrinsic credibility
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thresholdIntrinsic(
  alpha,
  alternative = c("two.sided", "one.sided"),
  type = c("Held", "Matthews")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thresholdIntrinsic_+3A_alpha">alpha</code></td>
<td>
<p>Numeric vector of intrinsic credibility levels.</p>
</td></tr>
<tr><td><code id="thresholdIntrinsic_+3A_alternative">alternative</code></td>
<td>
<p>Either &quot;two.sided&quot; (default) or &quot;one.sided&quot;.
Specifies if the threshold is for one-sided or two-sided p-values.</p>
</td></tr>
<tr><td><code id="thresholdIntrinsic_+3A_type">type</code></td>
<td>
<p>Either &quot;Held&quot; (default) or &quot;Matthews&quot;.
Type of intrinsic p-value threshold, see Held (2019) and Matthews (2018)
for more information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The threshold for intrinsic credibility.
</p>


<h3>Author(s)</h3>

<p>Leonhard Held
</p>


<h3>References</h3>

<p>Matthews, R. A. J. (2018). Beyond 'significance': principles and
practice of the analysis of credibility. <em>Royal Society Open
Science</em>, <b>5</b>, 171047. <a href="https://doi.org/10.1098/rsos.171047">doi:10.1098/rsos.171047</a>
</p>
<p>Held, L. (2019). The assessment of intrinsic credibility and a new argument
for <em>p &lt; 0.005</em>. <em>Royal Society Open Science</em>, <b>6</b>, 181534.
<a href="https://doi.org/10.1098/rsos.181534">doi:10.1098/rsos.181534</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>thresholdIntrinsic(alpha = c(0.005, 0.01, 0.05))
thresholdIntrinsic(alpha = c(0.005, 0.01, 0.05), alternative = "one.sided")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
