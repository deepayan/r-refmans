<!DOCTYPE html><html><head><title>Help for package VarSelLCM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {VarSelLCM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AIC'><p>AIC criterion.</p></a></li>
<li><a href='#ARI'><p>Adjusted Rand Index</p></a></li>
<li><a href='#BIC'><p>BIC criterion.</p></a></li>
<li><a href='#coef'><p>Extract the parameters</p></a></li>
<li><a href='#coefficients'><p>Extract the parameters</p></a></li>
<li><a href='#fitted'><p>Extract the partition or the probabilities of classification</p></a></li>
<li><a href='#fitted.values'><p>Extract the partition or the probabilities of classification</p></a></li>
<li><a href='#heart'><p>Statlog (Heart) Data Set</p></a></li>
<li><a href='#ICL'><p>ICL criterion</p></a></li>
<li><a href='#MICL'><p>MICL criterion</p></a></li>
<li><a href='#plot'><p>Plots of an instance of <code>VSLCMresults</code></p></a></li>
<li><a href='#predict'><p>Prediction of the cluster memberships</p></a></li>
<li><a href='#print'><p>Print function.</p></a></li>
<li><a href='#summary'><p>Summary function.</p></a></li>
<li><a href='#VarSelCluster'><p>Variable selection and clustering.</p></a></li>
<li><a href='#VarSelImputation'><p>Imputation of missing values</p></a></li>
<li><a href='#VarSelLCM-package'><p>Variable Selection for Model-Based Clustering of Mixed-Type Data Set with Missing Values</p></a></li>
<li><a href='#VarSelShiny'><p>Shiny app for analyzing results from VarSelCluster</p></a></li>
<li><a href='#VSLCMcriteria-class'><p>Constructor of <code>VSLCMcriteria</code> class</p></a></li>
<li><a href='#VSLCMdata-class'><p>Constructor of <code>VSLCMdata</code> class</p></a></li>
<li><a href='#VSLCMmodel-class'><p>Constructor of <code>VSLCMmodel</code> class</p></a></li>
<li><a href='#VSLCMparam-class'><p>Constructor of <code>VSLCMparam</code> class</p></a></li>
<li><a href='#VSLCMparamCategorical-class'><p>Constructor of <code>VSLCMparamCategorical</code> class</p></a></li>
<li><a href='#VSLCMparamContinuous-class'><p>Constructor of <code>VSLCMparamContinuous</code> class</p></a></li>
<li><a href='#VSLCMparamInteger-class'><p>Constructor of <code>VSLCMparamInteger</code> class</p></a></li>
<li><a href='#VSLCMpartitions-class'><p>Constructor of <code>VSLCMpartitions</code> class</p></a></li>
<li><a href='#VSLCMresults-class'><p>Constructor of <code>VSLCMresults</code> class</p></a></li>
<li><a href='#VSLCMstrategy-class'><p>Constructor of <code>VSLCMstrategy</code> class</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Selection for Model-Based Clustering of Mixed-Type Data
Set with Missing Values</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.3.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-08-27</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthieu Marbac and Mohammed Sedki</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mohammed Sedki &lt;mohammed.sedki@u-psud.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Full model selection (detection of the relevant features and estimation of the number of clusters) for model-based clustering (see reference here &lt;<a href="https://doi.org/10.1007%2Fs11222-016-9670-1">doi:10.1007/s11222-016-9670-1</a>&gt;). Data to analyze can be continuous, categorical, integer or mixed. Moreover, missing values can occur and do not necessitate any pre-processing. Shiny application permits an easy interpretation of the results.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, Rcpp (&ge; 0.11.1), parallel, mgcv, ggplot2, shiny</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://varsellcm.r-forge.r-project.org/">http://varsellcm.r-forge.r-project.org/</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Collate:</td>
<td>'CheckInputs.R' 'data.R' 'model.R' 'param.R' 'results.R'
'ICLexact.R' 'DesignOutput.R' 'Summary.R' 'Print.R'
'VarSelLCM.R' 'RcppExports.R' 'Plot.R' 'Imputation.R'
'withoutmixture.R' 'VarSelShiny.R' 'ARI.R' 'Extractors.R'
'Predict.R'</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-10-14 15:20:36 UTC; hornik</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-10-14 16:34:36 UTC</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, dplyr, htmltools, scales, plyr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>BuildVignettes:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository/R-Forge/Project:</td>
<td>varsellcm</td>
</tr>
<tr>
<td>Repository/R-Forge/Revision:</td>
<td>234</td>
</tr>
<tr>
<td>Repository/R-Forge/DateTimeStamp:</td>
<td>2018-08-27 18:56:49</td>
</tr>
</table>
<hr>
<h2 id='AIC'>AIC criterion.</h2><span id='topic+AIC'></span><span id='topic+AIC+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function gives the AIC criterion of an instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>. 
AIC is computed according to the formula</p>
<p style="text-align: center;"><code class="reqn">AIC=log-likelihood - \nu</code>
</p>
<p> where  <code class="reqn">\nu</code> denotes the number of parameters in the fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
AIC(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AIC_+3A_object">object</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Akaike, H. (1974), &quot;A new look at the statistical model identification&quot;, IEEE Transactions on Automatic Control, 19 (6): 716-723.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data loading:
data(heart)

# Cluster analysis without variable selection
res &lt;- VarSelCluster(heart[,-13], 2, vbleSelec = FALSE)

# Get the AIC value
AIC(res)
</code></pre>

<hr>
<h2 id='ARI'>Adjusted Rand Index</h2><span id='topic+ARI'></span>

<h3>Description</h3>

<p>This function computes the Adjusted Rand Index
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ARI(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ARI_+3A_x">x</code></td>
<td>
<p>vector defining a partition.</p>
</td></tr>
<tr><td><code id="ARI_+3A_y">y</code></td>
<td>
<p>vector defining a partition of whose length is equal to the length of x.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric
</p>


<h3>References</h3>

<p>L. Hubert and P. Arabie (1985) Comparing Partitions, Journal of the Classification, 2, pp. 193-218.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- sample(1:2, 20, replace=TRUE)
y &lt;- x
y[1:5] &lt;- sample(1:2, 5, replace=TRUE)
ARI(x, y)
</code></pre>

<hr>
<h2 id='BIC'>BIC criterion.</h2><span id='topic+BIC'></span><span id='topic+BIC+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function gives the BIC criterion of an instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>. 
BIC is computed according to the formula </p>
<p style="text-align: center;"><code class="reqn">BIC=log-likelihood - 0.5*\nu*log(n)</code>
</p>
 
<p>where  <code class="reqn">\nu</code> denotes the number of parameters in the fitted model and <code class="reqn">n</code> represents the sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
BIC(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BIC_+3A_object">object</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Schwarz, G. (1978). Estimating the dimension of a model. Annals of Statistics, 6(2), 461-464.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data loading:
data(heart)

# Cluster analysis without variable selection (number of clusters between 1 and 3)
res&lt;- VarSelCluster(heart[,-13], 2, vbleSelec = FALSE)

# Get the BIC value
BIC(res)
</code></pre>

<hr>
<h2 id='coef'>Extract the parameters</h2><span id='topic+coef'></span><span id='topic+coef+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function returns an instance of class <code><a href="#topic+VSLCMparam-class">VSLCMparam</a></code> which contains the model parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
coef(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef_+3A_object">object</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Data loading:
data(heart)

# Cluster analysis without variable selection (number of clusters between 1 and 3)
res  &lt;- VarSelCluster(heart[,-13], 1:3, vbleSelec = FALSE)

# Get the ICL value
coef(res)
</code></pre>

<hr>
<h2 id='coefficients'>Extract the parameters</h2><span id='topic+coefficients'></span><span id='topic+coefficients+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function returns an instance of class <code><a href="#topic+VSLCMparam-class">VSLCMparam</a></code> which contains the model parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
coefficients(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefficients_+3A_object">object</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Data loading:
data(heart)

# Cluster analysis without variable selection (number of clusters between 1 and 3)
res  &lt;- VarSelCluster(heart[,-13], 1:3, vbleSelec = FALSE)

# Get the ICL value
coefficients(res)
</code></pre>

<hr>
<h2 id='fitted'>Extract the partition or the probabilities of classification</h2><span id='topic+fitted'></span><span id='topic+fitted+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function returns the probabilities of classification or the partition among the observations of an instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
fitted(object, type = "partition")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted_+3A_object">object</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
<tr><td><code id="fitted_+3A_type">type</code></td>
<td>
<p>the type of prediction: probability of classification (probability) or the partition (partition)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Data loading:
data(heart)

# Cluster analysis without variable selection (number of clusters between 1 and 3)
res &lt;- VarSelCluster(heart[,-13], 2, vbleSelec = FALSE)

# Get the ICL value
fitted(res)
</code></pre>

<hr>
<h2 id='fitted.values'>Extract the partition or the probabilities of classification</h2><span id='topic+fitted.values'></span><span id='topic+fitted.values+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function returns the probabilities of classification or the partition among the observations of an instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
fitted.values(object, type = "partition")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.values_+3A_object">object</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
<tr><td><code id="fitted.values_+3A_type">type</code></td>
<td>
<p>the type of prediction: probability of classification (probability) or the partition (partition)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Data loading:
data(heart)

# Cluster analysis without variable selection (number of clusters between 1 and 3)
res &lt;- VarSelCluster(heart[,-13], 2, vbleSelec = FALSE)

# Get the ICL value
fitted.values(res)
</code></pre>

<hr>
<h2 id='heart'>Statlog (Heart) Data Set</h2><span id='topic+heart'></span>

<h3>Description</h3>

<p>This dataset is a heart disease database similar to a database already present in the repository (Heart Disease databases) but in a slightly different form.
</p>


<h3>Details</h3>

<p>12 variables are used to cluster the observations 
</p>

<ul>
<li><p>age (integer)
</p>
</li>
<li><p>sex (binary)
</p>
</li>
<li><p>chest pain type (categorical with 4 levels)
</p>
</li>
<li><p>resting blood pressure (continuous)
</p>
</li>
<li><p>serum cholestoral in mg/dl (continuous)
</p>
</li>
<li><p>fasting blood sugar &gt; 120 mg/dl (binary)
</p>
</li>
<li><p>resting electrocardiographic results (categorical with 3 levels)
</p>
</li>
<li><p>maximum heart rate achieved (continuous)
</p>
</li>
<li><p>exercise induced angina (binary)
</p>
</li>
<li><p>the slope of the peak exercise ST segment (categorical with 3 levels)
</p>
</li>
<li><p>number of major vessels  colored by flourosopy  (categorical with 4 levels)
</p>
</li>
<li><p>thal: 3 = normal; 6 = fixed defect; 7 = reversable defect (categorical with 3 levels)
</p>
</li></ul>

<p>1 variable define a &rdquo;true&rdquo; partition: Absence (1) or presence (2) of heart disease
</p>


<h3>References</h3>

<p>UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science: http://archive.ics.uci.edu/ml/datasets/statlog+(heart)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(heart)
</code></pre>

<hr>
<h2 id='ICL'>ICL criterion</h2><span id='topic+ICL'></span>

<h3>Description</h3>

<p>This function gives the ICL criterion for an instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ICL(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICL_+3A_object">object</code></td>
<td>
<p><code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Biernacki, C., Celeux, G., and Govaert, G. (2000). Assessing a mixture model for clustering with the integrated completed likelihood. IEEE transactions on pattern analysis and machine intelligence, 22(7), 719-725.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data loading:
data(heart)

# Cluster analysis without variable selection
res &lt;- VarSelCluster(heart[,-13], 2, vbleSelec = FALSE)

# Get the ICL value
ICL(res)

</code></pre>

<hr>
<h2 id='MICL'>MICL criterion</h2><span id='topic+MICL'></span>

<h3>Description</h3>

<p>This function gives the MICL criterion for an instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MICL(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MICL_+3A_object">object</code></td>
<td>
<p><code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Marbac, M. and Sedki, M. (2017). Variable selection for model-based clustering using the integrated completed-data likelihood. Statistics and Computing, 27 (4), 1049-1063.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Data loading:
data("heart")

# Cluster analysis with variable selection
object &lt;- VarSelCluster(heart[,-13], 2, vbleSelec = TRUE, crit.varsel = "MICL")

# Get the MICL value
MICL(object)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot'>Plots of an instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code></h2><span id='topic+plot'></span><span id='topic+plot+2CVSLCMresults-method'></span><span id='topic+plot+2CVSLCMresults+2Ccharacter-method'></span><span id='topic+plot+2CVSLCMresults+2CANY-method'></span>

<h3>Description</h3>

<p>This function proposes different plots of an instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.
It permits to visualize:
</p>

<ul>
<li><p>the discriminative power of the variables (type=&quot;bar&quot; or type=&quot;pie&quot;). The larger is the discriminative power of a variable, the more explained are the clusters by this variable.
</p>
</li>
<li><p>the probabilities of misclassification (type=&quot;probs-overall&quot; or type=&quot;probs-class&quot;).
</p>
</li>
<li><p>the distribution of a signle variable (y is the name of the variable and type=&quot;boxplot&quot; or type=&quot;cdf&quot;).
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults,character'
plot(x, y, type = "boxplot", ylim = c(1,
  x@data@d))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>instance of  <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>character. The name of the variable to ploted (only used if type=&quot;boxplot&quot; or type=&quot;cdf&quot;).</p>
</td></tr>
<tr><td><code id="plot_+3A_type">type</code></td>
<td>
<p>character. The type of plot (&quot;bar&quot;: barplot of the disciminative power, &quot;pie&quot;: pie of the discriminative power, &quot;probs-overall&quot;: histogram of the probabilities of misclassification, &quot;probs-class&quot;: histogram of the probabilities of misclassification per cluster, &quot;boxplot&quot;: boxplot of a single variable per cluster, &quot;cdf&quot;: distribution of a single variable per cluster).</p>
</td></tr>
<tr><td><code id="plot_+3A_ylim">ylim</code></td>
<td>
<p>numeric. Define the range of the most discriminative variables to considered (only use if type=&quot;pie&quot; or type=&quot;bar&quot;)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(VarSelLCM)

# Data loading:
# x contains the observed variables
# z the known statu (i.e. 1: absence and 2: presence of heart disease)
data(heart)
ztrue &lt;- heart[,"Class"]
x &lt;- heart[,-13]

# Cluster analysis with variable selection (with parallelisation)
res_with &lt;- VarSelCluster(x, 2, nbcores = 2, initModel=40)

# Summary of the probabilities of missclassification
plot(res_with, type="probs-class")

# Discriminative power of the variables (here, the most discriminative variable is MaxHeartRate)
plot(res_with)

# Boxplot for the continuous variable MaxHeartRate
plot(res_with, y="MaxHeartRate")

# Empirical and theoretical distributions (to check that the distribution is well-fitted)
plot(res_with, y="MaxHeartRate", type="cdf")

# Summary of categorical variable
plot(res_with, y="Sex")

## End(Not run)
</code></pre>

<hr>
<h2 id='predict'>Prediction of the cluster memberships</h2><span id='topic+predict'></span><span id='topic+predict+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function gives the probabilities of classification for new observations by using the mixture model fit with the function <code><a href="#topic+VarSelCluster">VarSelCluster</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
predict(object, newdata, type = "probability")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_newdata">newdata</code></td>
<td>
<p>data.frame of the observations to classify.</p>
</td></tr>
<tr><td><code id="predict_+3A_type">type</code></td>
<td>
<p>the type of prediction: probability of classification (probability) or the partition (partition)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix of the probabilities of classification.
</p>

<hr>
<h2 id='print'>Print function.</h2><span id='topic+print'></span><span id='topic+print+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function gives the print of an instance of  <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
print(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_+3A_x">x</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='summary'>Summary function.</h2><span id='topic+summary'></span><span id='topic+summary+2CVSLCMresults-method'></span>

<h3>Description</h3>

<p>This function gives the summary of an instance of  <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VSLCMresults'
summary(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>instance of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='VarSelCluster'>Variable selection and clustering.</h2><span id='topic+VarSelCluster'></span>

<h3>Description</h3>

<p>This function performs the model selection and the maximum likelihood estimation.
It can be used for clustering only (i.e., all the variables are assumed to be discriminative). In this case, you must specify the data to cluster (arg. x), the number of clusters (arg. g) and the option vbleSelec must be FALSE.
This function can also be used for variable selection in clustering. In this case, you must specify the data to analyse (arg. x), the number of clusters (arg. g) and the option vbleSelec must be TRUE. Variable selection can be done with BIC, MICL or AIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VarSelCluster(x, gvals, vbleSelec = TRUE, crit.varsel = "BIC",
  initModel = 50, nbcores = 1, discrim = rep(1, ncol(x)), nbSmall = 250,
  iterSmall = 20, nbKeep = 50, iterKeep = 1000, tolKeep = 10^(-6))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VarSelCluster_+3A_x">x</code></td>
<td>
<p>data.frame/matrix. Rows correspond to observations and columns correspond to variables. Continuous variables must be &quot;numeric&quot;, count variables must be &quot;integer&quot; and categorical variables must be &quot;factor&quot;</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_gvals">gvals</code></td>
<td>
<p>numeric. It defines number of components to consider.</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_vbleselec">vbleSelec</code></td>
<td>
<p>logical. It indicates if a variable selection is done</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_crit.varsel">crit.varsel</code></td>
<td>
<p>character. It defines the information criterion used for model selection. Without variable selection, you can use one of the three criteria: &quot;AIC&quot;, &quot;BIC&quot; and &quot;ICL&quot;. With variable selection, you can use &quot;AIC&quot;, BIC&quot; and &quot;MICL&quot;.</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_initmodel">initModel</code></td>
<td>
<p>numeric. It gives the number of initializations of the alternated algorithm maximizing the MICL criterion (only used if crit.varsel=&quot;MICL&quot;)</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_nbcores">nbcores</code></td>
<td>
<p>numeric.  It defines the numerber of cores used by the alogrithm</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_discrim">discrim</code></td>
<td>
<p>numeric. It indicates if each variable is discrimiative (1) or irrelevant (0) (only used if vbleSelec=0)</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_nbsmall">nbSmall</code></td>
<td>
<p>numeric. It indicates  the number of SmallEM algorithms performed for the ML inference</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_itersmall">iterSmall</code></td>
<td>
<p>numeric. It indicates  the number of iterations for each SmallEM algorithm</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_nbkeep">nbKeep</code></td>
<td>
<p>numeric. It indicates the number of chains used for the final EM algorithm</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_iterkeep">iterKeep</code></td>
<td>
<p>numeric. It indicates the maximal number of iterations for each EM algorithm</p>
</td></tr>
<tr><td><code id="VarSelCluster_+3A_tolkeep">tolKeep</code></td>
<td>
<p>numeric. It indicates the maximal gap between two successive iterations of EM algorithm which stops the algorithm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an instance of <a href="#topic+VSLCMresults-class">VSLCMresults</a>.
</p>


<h3>References</h3>

<p>Marbac, M. and Sedki, M. (2017). Variable selection for model-based clustering using the integrated completed-data likelihood. Statistics and Computing, 27 (4), 1049-1063.
</p>
<p>Marbac, M. and Patin, E. and Sedki, M. (2018). Variable selection for mixed data clustering: Application in human population genomics. Journal of Classification, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Package loading
require(VarSelLCM)

# Data loading:
# x contains the observed variables
# z the known statu (i.e. 1: absence and 2: presence of heart disease)
data(heart)
ztrue &lt;- heart[,"Class"]
x &lt;- heart[,-13]

# Cluster analysis without variable selection
res_without &lt;- VarSelCluster(x, 2, vbleSelec = FALSE, crit.varsel = "BIC")

# Cluster analysis with variable selection (with parallelisation)
res_with &lt;- VarSelCluster(x, 2, nbcores = 2, initModel=40, crit.varsel = "BIC")

# Comparison of the BIC for both models:
# variable selection permits to improve the BIC
BIC(res_without)
BIC(res_with)

# Confusion matrices and ARI (only possible because the "true" partition is known).
# ARI is computed between the true partition (ztrue) and its estimators
# ARI is an index between 0 (partitions are independent) and 1 (partitions are equals)
# variable selection permits to improve the ARI
# Note that ARI cannot be used for model selection in clustering, because there is no true partition
# variable selection decreases the misclassification error rate
table(ztrue, fitted(res_without))
table(ztrue, fitted(res_with))
ARI(ztrue,  fitted(res_without))
ARI(ztrue, fitted(res_with))
 
# Estimated partition
fitted(res_with)

# Estimated probabilities of classification
head(fitted(res_with, type="probability"))

# Summary of the probabilities of missclassification
plot(res_with, type="probs-class")

# Summary of the best model
summary(res_with)

# Discriminative power of the variables (here, the most discriminative variable is MaxHeartRate)
plot(res_with)

# More detailed output
print(res_with)

# Print model parameter
coef(res_with)

# Boxplot for the continuous variable MaxHeartRate
plot(x=res_with, y="MaxHeartRate")

# Empirical and theoretical distributions of the most discriminative variable 
# (to check that the distribution is well-fitted)
plot(res_with, y="MaxHeartRate", type="cdf")

# Summary of categorical variable
plot(res_with, y="Sex")

# Probabilities of classification for new observations 
predict(res_with, newdata = x[1:3,])

# Imputation by posterior mean for the first observation
not.imputed &lt;- x[1,]
imputed &lt;- VarSelImputation(res_with, x[1,], method = "sampling")
rbind(not.imputed, imputed)

# Opening Shiny application to easily see the results
VarSelShiny(res_with)



## End(Not run)

</code></pre>

<hr>
<h2 id='VarSelImputation'>Imputation of missing values</h2><span id='topic+VarSelImputation'></span>

<h3>Description</h3>

<p>This function permits imputation of missing values in a dataset by using mixture model.
Two methods can be used for imputation:
</p>

<ul>
<li><p>posterior mean (method=&quot;postmean&quot;)
</p>
</li>
<li><p>sampling from the full conditionnal distribution (method=&quot;sampling&quot;)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>VarSelImputation(obj, newdata, method = "postmean")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VarSelImputation_+3A_obj">obj</code></td>
<td>
<p>an instance of <a href="#topic+VSLCMresults-class">VSLCMresults</a>  which defines the model used for imputation.</p>
</td></tr>
<tr><td><code id="VarSelImputation_+3A_newdata">newdata</code></td>
<td>
<p>data.frame Dataset containing the missing values to impute.</p>
</td></tr>
<tr><td><code id="VarSelImputation_+3A_method">method</code></td>
<td>
<p>character definiting the method of imputation: &quot;postmean&quot; or &quot;sampling&quot;</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Data loading
data("heart")

# Clustering en 2 classes
results &lt;- VarSelCluster(heart[,-13], 2)

# Data where missing values will be imputed
newdata &lt;- heart[1:2,-13]
newdata[1,1] &lt;- NA
newdata[2,2] &lt;- NA

# Imputation
VarSelImputation(results, newdata)

</code></pre>

<hr>
<h2 id='VarSelLCM-package'>Variable Selection for Model-Based Clustering of Mixed-Type Data Set with Missing Values</h2><span id='topic+VarSelLCM-package'></span><span id='topic+VarSelLCM'></span>

<h3>Description</h3>

<p>Model-based clustering with variable selection and estimation of the number of clusters. Data to analyze can be continuous, categorical, integer or mixed. Moreover, missing values can occur and do not necessitate any pre-processing. Shiny application permits an easy interpretation of the results.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
  Package: </td><td style="text-align: left;"> VarSelLCM</td>
</tr>
<tr>
 <td style="text-align: left;"> 
  Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;"> 
  Version: </td><td style="text-align: left;"> 2.1.2</td>
</tr>
<tr>
 <td style="text-align: left;">
  Date: </td><td style="text-align: left;"> 2018-06-04</td>
</tr>
<tr>
 <td style="text-align: left;"> 
  License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">  
  LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
  URL:  </td><td style="text-align: left;"> http://varsellcm.r-forge.r-project.org/</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The main function to use is <a href="#topic+VarSelCluster">VarSelCluster</a>. Function <a href="#topic+VarSelCluster">VarSelCluster</a> carries out the model selection (according to AIC, BIC or MICL) and maximum likelihood estimation.
</p>
<p>Function <a href="#topic+VarSelShiny">VarSelShiny</a> runs a shiny application which permits an easy interpretation of the clustering results.
</p>
<p>Function <a href="#topic+VarSelImputation">VarSelImputation</a> permits the imputation of missing values by using the model parameters.
</p>
<p>Standard tool methods (e.g., <a href="#topic+summary">summary</a>, <a href="#topic+print">print</a>, <a href="#topic+plot">plot</a>, <a href="#topic+coef">coef</a>, <a href="#topic+fitted">fitted</a>, <a href="#topic+predict">predict</a>...) are available for facilitating the interpretation.
</p>


<h3>Author(s)</h3>

<p>Matthieu Marbac and Mohammed Sedki. Maintainer: Mohammed Sedki &lt;mohammed.sedki@u-psud.fr&gt;
</p>


<h3>References</h3>

<p>Marbac, M. and Sedki, M. (2017). Variable selection for model-based clustering using the integrated completed-data likelihood. Statistics and Computing, 27 (4), 1049-1063.
</p>
<p>Marbac, M. and Patin, E. and Sedki, M. (2018). Variable selection for mixed data clustering: Application in human population genomics. Journal of classification, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Package loading
require(VarSelLCM)

# Data loading:
# x contains the observed variables
# z the known statu (i.e. 1: absence and 2: presence of heart disease)
data(heart)
ztrue &lt;- heart[,"Class"]
x &lt;- heart[,-13]

# Cluster analysis without variable selection
res_without &lt;- VarSelCluster(x, 2, vbleSelec = FALSE, crit.varsel = "BIC")

# Cluster analysis with variable selection (with parallelisation)
res_with &lt;- VarSelCluster(x, 2, nbcores = 2, initModel=40, crit.varsel = "BIC")

# Comparison of the BIC for both models:
# variable selection permits to improve the BIC
BIC(res_without)
BIC(res_with)

# Comparison of the partition accuracy. 
# ARI is computed between the true partition (ztrue) and its estimators
# ARI is an index between 0 (partitions are independent) and 1 (partitions are equals)
# variable selection permits to improve the ARI
# Note that ARI cannot be used for model selection in clustering, because there is no true partition
ARI(ztrue, fitted(res_without))
ARI(ztrue, fitted(res_with))

# Estimated partition
fitted(res_with)

# Estimated probabilities of classification
head(fitted(res_with, type="probability"))

# Summary of the probabilities of missclassification
plot(res_with, type="probs-class")

# Confusion matrices and ARI (only possible because the "true" partition is known).
# ARI is computed between the true partition (ztrue) and its estimators
# ARI is an index between 0 (partitions are independent) and 1 (partitions are equals)
# variable selection permits to improve the ARI
# Note that ARI cannot be used for model selection in clustering, because there is no true partition
# variable selection decreases the misclassification error rate
table(ztrue, fitted(res_without))
table(ztrue, fitted(res_with))
ARI(ztrue,  fitted(res_without))
ARI(ztrue, fitted(res_with))

# Summary of the best model
summary(res_with)

# Discriminative power of the variables (here, the most discriminative variable is MaxHeartRate)
plot(res_with)

# More detailed output
print(res_with)

# Print model parameter
coef(res_with)

# Boxplot for the continuous variable MaxHeartRate
plot(x=res_with, y="MaxHeartRate")

# Empirical and theoretical distributions of the most discriminative variable
# (to check that the distribution is well-fitted)
plot(res_with, y="MaxHeartRate", type="cdf")

# Summary of categorical variable
plot(res_with, y="Sex")

# Probabilities of classification for new observations 
predict(res_with, newdata = x[1:3,])

# Imputation by posterior mean for the first observation
not.imputed &lt;- x[1,]
imputed &lt;- VarSelImputation(res_with, x[1,], method = "sampling")
rbind(not.imputed, imputed)

# Opening Shiny application to easily see the results
VarSelShiny(res_with)



## End(Not run)

</code></pre>

<hr>
<h2 id='VarSelShiny'>Shiny app for analyzing results from VarSelCluster</h2><span id='topic+VarSelShiny'></span>

<h3>Description</h3>

<p>Shiny app for analyzing results from VarSelCluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VarSelShiny(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VarSelShiny_+3A_x">X</code></td>
<td>
<p>an instance of <a href="#topic+VSLCMresults-class">VSLCMresults</a> returned by function <a href="#topic+VarSelCluster">VarSelCluster</a>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Data loading
data("heart")
# Clustering en 2 classes
results &lt;- VarSelCluster(heart[,-13], 2)
# Opening Shiny application to easily see the results
VarSelShiny(results)

## End(Not run)

</code></pre>

<hr>
<h2 id='VSLCMcriteria-class'>Constructor of <code><a href="#topic+VSLCMcriteria-class">VSLCMcriteria</a></code> class</h2><span id='topic+VSLCMcriteria-class'></span>

<h3>Description</h3>


<dl>
<dt>loglikelihood</dt><dd><p>numeric. Log-likelihood</p>
</dd>
<dt>AIC</dt><dd><p>numeric. Value of the AIC criterion.</p>
</dd>
<dt>BIC</dt><dd><p>numeric. Value of the BIC criterion.</p>
</dd>
<dt>ICL</dt><dd><p>numeric. Value of the ICL criterion.</p>
</dd>
<dt>MICL</dt><dd><p>numeric. Value of the MICL criterion.</p>
</dd>
<dt>nbparam</dt><dd><p>integer. Number of parameters.</p>
</dd>
<dt>cvrate</dt><dd><p>numeric.  Rate of convergence of the alternated algorithm for optimizing the MICL criterion.</p>
</dd>
<dt>degeneracyrate</dt><dd><p>numeric.  Rate of degeneracy for the selected model.</p>
</dd>
<dt>discrim</dt><dd><p>numeric.  Discriminative power of each variable.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMcriteria")

</code></pre>

<hr>
<h2 id='VSLCMdata-class'>Constructor of <code><a href="#topic+VSLCMdata-class">VSLCMdata</a></code> class</h2><span id='topic+VSLCMdata-class'></span>

<h3>Description</h3>


<dl>
<dt>n</dt><dd><p>number of observations</p>
</dd>
<dt>d</dt><dd><p>number of variables</p>
</dd>
<dt>withContinuous</dt><dd><p>logical indicating if some variables are continuous</p>
</dd>
<dt>withInteger</dt><dd><p>logical indicating if some variables are integer</p>
</dd>
<dt>withCategorica</dt><dd><p>logical indicating if some variables are categorical</p>
</dd> 
<dt>dataContinuous</dt><dd><p>instance of VSLCMdataContinuous containing the continuous data</p>
</dd>
<dt>dataInteger</dt><dd><p>instance of VSLCMdataContinuous containing the integer data</p>
</dd>
<dt>dataCategorical</dt><dd><p>instance of VSLCMdataContinuous containing the categorical data</p>
</dd>
<dt>var.names</dt><dd><p>labels of the variables</p>
</dd> 
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMdata")

</code></pre>

<hr>
<h2 id='VSLCMmodel-class'>Constructor of <code><a href="#topic+VSLCMmodel-class">VSLCMmodel</a></code> class</h2><span id='topic+VSLCMmodel-class'></span>

<h3>Description</h3>


<dl>
<dt>g</dt><dd><p>numeric. Number of components.</p>
</dd>
<dt>omega</dt><dd><p>logical. Vector indicating if each variable is irrelevant (1) or not (0) to the clustering.</p>
</dd>
<dt>names.relevant</dt><dd><p>character. Names of the relevant variables.</p>
</dd>
<dt>names.irrelevant</dt><dd><p>character. Names of the irrelevant variables.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMmodel")

</code></pre>

<hr>
<h2 id='VSLCMparam-class'>Constructor of <code><a href="#topic+VSLCMparam-class">VSLCMparam</a></code> class</h2><span id='topic+VSLCMparam-class'></span>

<h3>Description</h3>


<dl>
<dt>pi</dt><dd><p>numeric. Proportions of the mixture components.</p>
</dd>
<dt>paramContinuous</dt><dd><p><a href="#topic+VSLCMparamContinuous-class">VSLCMparamContinuous</a>. Parameters of the continuous variables.</p>
</dd>
<dt>paramInteger</dt><dd><p><a href="#topic+VSLCMparamInteger-class">VSLCMparamInteger</a>. Parameters of the integer variables.</p>
</dd>
<dt>paramCategorical</dt><dd><p><a href="#topic+VSLCMparamCategorical-class">VSLCMparamCategorical</a>. Parameters of the categorical variables.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMparam")

</code></pre>

<hr>
<h2 id='VSLCMparamCategorical-class'>Constructor of <code><a href="#topic+VSLCMparamCategorical-class">VSLCMparamCategorical</a></code> class</h2><span id='topic+VSLCMparamCategorical-class'></span>

<h3>Description</h3>


<dl>
<dt>pi</dt><dd><p>numeric. Proportions of the mixture components.</p>
</dd>
<dt>alpha</dt><dd><p>list. Parameters of the multinomial distributions.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMparamCategorical")

</code></pre>

<hr>
<h2 id='VSLCMparamContinuous-class'>Constructor of <code><a href="#topic+VSLCMparamContinuous-class">VSLCMparamContinuous</a></code> class</h2><span id='topic+VSLCMparamContinuous-class'></span>

<h3>Description</h3>


<dl>
<dt>pi</dt><dd><p>numeric. Proportions of the mixture components.</p>
</dd>
<dt>mu</dt><dd><p>matrix. Mean for each component (column) and each variable (row).</p>
</dd>
<dt>sd</dt><dd><p>matrix. Standard deviation for each component (column) and each variable (row).</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMparamContinuous")

</code></pre>

<hr>
<h2 id='VSLCMparamInteger-class'>Constructor of <code><a href="#topic+VSLCMparamInteger-class">VSLCMparamInteger</a></code> class</h2><span id='topic+VSLCMparamInteger-class'></span>

<h3>Description</h3>


<dl>
<dt>pi</dt><dd><p>numeric. Proportions of the mixture components.</p>
</dd>
<dt>lambda</dt><dd><p>matrix. Mean for each component (column) and each variable (row).</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMparamInteger")

</code></pre>

<hr>
<h2 id='VSLCMpartitions-class'>Constructor of <code><a href="#topic+VSLCMpartitions-class">VSLCMpartitions</a></code> class</h2><span id='topic+VSLCMpartitions-class'></span>

<h3>Description</h3>


<dl>
<dt>zMAP</dt><dd><p>numeric. A vector indicating the class membership of each individual by using the MAP rule computed for the best model with its maximum likelihood estimates.</p>
</dd>
<dt>zOPT</dt><dd><p>numeric. Partition maximizing the integrated complete-data likelihood of the selected model.</p>
</dd>
<dt>tik</dt><dd><p>numeric. Fuzzy partition computed for the best model with its maximum likelihood estimates.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMpartitions")

</code></pre>

<hr>
<h2 id='VSLCMresults-class'>Constructor of <code><a href="#topic+VSLCMresults-class">VSLCMresults</a></code> class</h2><span id='topic+VSLCMresults-class'></span>

<h3>Description</h3>


<dl>
<dt>data</dt><dd><p><a href="#topic+VSLCMdata-class">VSLCMdata</a>. Results relied to the data.</p>
</dd>
<dt>criteria</dt><dd><p><a href="#topic+VSLCMcriteria-class">VSLCMcriteria</a>. Results relied to the information criteria.</p>
</dd>
<dt>partitions</dt><dd><p><a href="#topic+VSLCMpartitions-class">VSLCMpartitions</a>. Results relied to the partitions.</p>
</dd>
<dt>model</dt><dd><p><a href="#topic+VSLCMmodel-class">VSLCMmodel</a>. Results relied to the selected model.</p>
</dd>
<dt>strategy</dt><dd><p><a href="#topic+VSLCMstrategy-class">VSLCMstrategy</a>. Results relied to the tune parameters.</p>
</dd>
<dt>param</dt><dd><p><a href="#topic+VSLCMparam-class">VSLCMparam</a>. Results relied to the parameters.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMresults")

</code></pre>

<hr>
<h2 id='VSLCMstrategy-class'>Constructor of <code><a href="#topic+VSLCMstrategy-class">VSLCMstrategy</a></code> class</h2><span id='topic+VSLCMstrategy-class'></span>

<h3>Description</h3>


<dl>
<dt>initModel</dt><dd><p>numeric. Number of initialisations for the model selection algorithm.</p>
</dd>
<dt>vbleSelec</dt><dd><p>logical. It indicates if the selection of the variables is performed.</p>
</dd>
<dt>paramEstim</dt><dd><p>logical. It indicates if the parameter estimation is performed.</p>
</dd>
<dt>parallel</dt><dd><p>logical. It indicates  if a parallelisation is done.</p>
</dd>
<dt>nbSmall</dt><dd><p>numeric. It indicates the number of small EM.</p>
</dd>
<dt>iterSmall</dt><dd><p>numeric. It indicates the number of iteration for the small EM</p>
</dd>
<dt>nbKeep</dt><dd><p>numeric. It indicates the number of chains kept for the EM.</p>
</dd>
<dt>iterKeep</dt><dd><p>numeric. It indicates the maximum number of iteration for the EM.</p>
</dd>
<dt>tolKeep</dt><dd><p>numeric. It indicates the value of the difference between successive iterations of EM stopping the EM.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  getSlots("VSLCMstrategy")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
