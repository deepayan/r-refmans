<!DOCTYPE html><html><head><title>Help for package MadanTextNetwork</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MadanTextNetwork}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ASDATA.FRAME'><p>Convert to Data Frame</p></a></li>
<li><a href='#cluster.graph'><p>Cluster a Graph and Extract Largest Component</p></a></li>
<li><a href='#Community.Detection.Membership'><p>Get Community Membership of a Graph</p></a></li>
<li><a href='#Community.Detection.Plot'><p>Plot Community Detection in a Graph</p></a></li>
<li><a href='#f3'><p>Persian Text Normalization and Stemming</p></a></li>
<li><a href='#f5'><p>Filter Data Frame by Document ID</p></a></li>
<li><a href='#f6'><p>Extract Token Information from Data Frame</p></a></li>
<li><a href='#f7'><p>Extract and Count Specific Parts of Speech</p></a></li>
<li><a href='#fun.all.sums'><p>Apply Suffix Modifications to Persian Words</p></a></li>
<li><a href='#fun.one.sums'><p>General Persian Suffix Modification</p></a></li>
<li><a href='#FUNbigrams'><p>Extract Bigram Information and Count Frequency</p></a></li>
<li><a href='#fungan'><p>Persian Suffix Modification for 'Persian text here' Suffix</p></a></li>
<li><a href='#fungi'><p>Persian Suffix Modification</p></a></li>
<li><a href='#funmi'><p>Modify Persian Words Starting with 'Persian text here'</p></a></li>
<li><a href='#LEMMA'><p>Persian Lemmatization</p></a></li>
<li><a href='#network.cor'><p>Create and Plot a Correlation Network</p></a></li>
<li><a href='#PMI'><p>Calculate Pointwise Mutual Information (PMI)</p></a></li>
<li><a href='#ScaleWeight'><p>Scale a Numeric Vector</p></a></li>
<li><a href='#server'><p>Server Logic for MadanText Shiny Application</p></a></li>
<li><a href='#set.graph'><p>Set Graph Attributes</p></a></li>
<li><a href='#ui'><p>User Interface for MadanText</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Persian Text Mining Tool for Co-Occurrence Network</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides an extension to 'MadanText' for creating and analyzing co-occurrence networks in Persian text data.
             This package mainly makes use of the 'PersianStemmer' (Safshekan, R., et al. (2019). <a href="https://CRAN.R-project.org/package=PersianStemmer">https://CRAN.R-project.org/package=PersianStemmer</a>),
             'udpipe' (Wijffels, J., et al. (2023). <a href="https://CRAN.R-project.org/package=udpipe">https://CRAN.R-project.org/package=udpipe</a>),
             and 'shiny' (Chang, W., et al. (2023). <a href="https://CRAN.R-project.org/package=shiny">https://CRAN.R-project.org/package=shiny</a>) packages.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>xlsx, glue, lattice, stopwords,textmineR, tidytext, tidyr,
udpipe, PersianStemmer, shiny (&ge; 1.8.0), shinythemes, tm,
dplyr, hwordcloud, stringr, stringi, topicmodels, igraph,
ngram, visNetwork</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-08 03:48:05 UTC; trial</td>
</tr>
<tr>
<td>Author:</td>
<td>Kido Ishikawa [aut, cre],
  Hasan Khosravi [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kido Ishikawa &lt;kido.ishikawa6@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-08 11:30:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='ASDATA.FRAME'>Convert to Data Frame</h2><span id='topic+ASDATA.FRAME'></span>

<h3>Description</h3>

<p>This function converts the given object to a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ASDATA.FRAME(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ASDATA.FRAME_+3A_x">x</code></td>
<td>
<p>An object to be converted into a data frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame with rows and columns corresponding to the
original object's structure. If 'x' is a matrix, each column in the matrix
becomes a column in the data frame. If 'x' is a list where all elements
are of the same length, each element of the list becomes a column in the
data frame. Attributes such as rownames, colnames, and dimnames (if any)
are preserved in the conversion.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- ASDATA.FRAME(matrix(1:4, ncol = 2))
</code></pre>

<hr>
<h2 id='cluster.graph'>Cluster a Graph and Extract Largest Component</h2><span id='topic+cluster.graph'></span>

<h3>Description</h3>

<p>This function applies clustering to a graph and extracts the largest
connected component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster.graph(network)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster.graph_+3A_network">network</code></td>
<td>
<p>A graph object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing three elements: 'gr' with the largest connected
component of the graph, 'cl' with a data frame of nodes and their
cluster membership, and 'node.impo' with a data frame of node
importance measures like degree, closeness, and betweenness.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Assuming 'network' is a predefined graph object
  cluster.graph(network)

## End(Not run)
</code></pre>

<hr>
<h2 id='Community.Detection.Membership'>Get Community Membership of a Graph</h2><span id='topic+Community.Detection.Membership'></span>

<h3>Description</h3>

<p>This function applies community detection to a graph and returns the
membership information of each node.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Community.Detection.Membership(network)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Community.Detection.Membership_+3A_network">network</code></td>
<td>
<p>A graph object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame where each row represents a node in the graph,
with columns for the node name and its corresponding community
membership number. This information is useful for understanding
the community structure within the graph.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  network &lt;- make_graph("Zachary")
  membership_info &lt;- Community.Detection.Membership(network)
  print(membership_info)

## End(Not run)
</code></pre>

<hr>
<h2 id='Community.Detection.Plot'>Plot Community Detection in a Graph</h2><span id='topic+Community.Detection.Plot'></span>

<h3>Description</h3>

<p>This function applies community detection to a graph and plots the result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Community.Detection.Plot(network)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Community.Detection.Plot_+3A_network">network</code></td>
<td>
<p>A graph object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot visualizing the graph with nodes colored according to their
community membership. The plot also displays the modularity score
as a sub-title, indicating the strength of the community structure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Assuming 'network' is a predefined graph object
  # network &lt;- make_graph("Zachary")
  Community.Detection.Plot(network)

## End(Not run)
</code></pre>

<hr>
<h2 id='f3'>Persian Text Normalization and Stemming</h2><span id='topic+f3'></span>

<h3>Description</h3>

<p>This function normalizes Persian text by replacing specific characters
and applies stemming.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f3(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f3_+3A_x">x</code></td>
<td>
<p>A character vector of Persian text.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector where each element is the normalized
and stemmed version of the corresponding element in the input vector.
Specifically, it performs character replacement and stemming on each
element of the input, thereby returning a vector of the same length
but with processed text. If an element cannot be processed, it will be
returned as NA in the output vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  text &lt;- c("Persian text here")
  normalized_text &lt;- f3(text)

## End(Not run)
</code></pre>

<hr>
<h2 id='f5'>Filter Data Frame by Document ID</h2><span id='topic+f5'></span>

<h3>Description</h3>

<p>This function filters a data frame by the specified document ID.
If the ID is 0, the entire data frame is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f5(UPIP, I)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f5_+3A_upip">UPIP</code></td>
<td>
<p>A data frame with a column named 'doc_id'.</p>
</td></tr>
<tr><td><code id="f5_+3A_i">I</code></td>
<td>
<p>An integer representing the document ID.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a subset of the input data frame ('UPIP') containing only
the rows where the 'doc_id' column matches the specified document ID 'I'.
If 'I' is 0, the function returns the entire data frame unmodified. The
output is a data frame with the same structure as the input but potentially
fewer rows, depending on the presence and frequency of the specified ID.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- data.frame(doc_id = 1:5, text = letters[1:5])
filtered_data &lt;- f5(data, 2)
</code></pre>

<hr>
<h2 id='f6'>Extract Token Information from Data Frame</h2><span id='topic+f6'></span>

<h3>Description</h3>

<p>This function extracts token, lemma, and part-of-speech (POS) tag information
from a given data frame and compiles them into a new data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f6(UPIP)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f6_+3A_upip">UPIP</code></td>
<td>
<p>A data frame containing columns 'token', 'lemma', and 'upos'
for tokens, their lemmatized forms, and POS tags respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a new data frame with three columns: 'TOKEN', 'LEMMA', and
'TYPE'. 'TOKEN' contains the original tokens from the 'token' column
of the input data frame. 'LEMMA' contains the lemmatized forms of
these tokens, as provided in the 'lemma' column. 'TYPE' contains POS
tags corresponding to each token, as provided in the 'upos' column.
The returned data frame has the same number of rows as the input
data frame, with each row representing the token, its lemma, and
its POS tag from the corresponding row of the input.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- data.frame(token = c("running", "jumps"),
                   lemma = c("run", "jump"),
                   upos = c("VERB", "VERB"))
token_info &lt;- f6(data)
</code></pre>

<hr>
<h2 id='f7'>Extract and Count Specific Parts of Speech</h2><span id='topic+f7'></span>

<h3>Description</h3>

<p>This function extracts tokens of a specified part of speech (POS)
from the given data frame and counts their frequency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f7(UPIP, type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f7_+3A_upip">UPIP</code></td>
<td>
<p>A data frame with columns 'upos' (POS tags) and 'lemma' (lemmatized tokens).</p>
</td></tr>
<tr><td><code id="f7_+3A_type">type</code></td>
<td>
<p>A string representing the POS to filter (e.g., 'NOUN', 'VERB').</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame where each row corresponds to a unique lemma
of the specified POS type. The data frame has two columns: 'key',
which contains the lemma, and 'freq', which contains the frequency
count of that lemma in the data. The rows are ordered in decreasing
frequency of occurrence. This format is useful for quickly
identifying the most common terms of a particular POS in the data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- data.frame(upos = c('NOUN', 'VERB'), lemma = c('house', 'run'))
noun_freq &lt;- f7(data, 'NOUN')
</code></pre>

<hr>
<h2 id='fun.all.sums'>Apply Suffix Modifications to Persian Words</h2><span id='topic+fun.all.sums'></span>

<h3>Description</h3>

<p>This function iteratively applies a series of suffix modifications to a vector of Persian words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fun.all.sums(v, TYPE = TYPE.org)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fun.all.sums_+3A_v">v</code></td>
<td>
<p>A character vector of Persian words.</p>
</td></tr>
<tr><td><code id="fun.all.sums_+3A_type">TYPE</code></td>
<td>
<p>A vector of suffix types for modification.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector where each element corresponds to a word
from the input vector 'v' with all specified suffix modifications applied.
This results in a transformed vector where each word has been modified
according to the series of suffix types provided in 'TYPE'. The length
of the returned vector matches the length of the input vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  words &lt;- c("Persian text here")
  modified_words &lt;- fun.all.sums(words, TYPE)

## End(Not run)
</code></pre>

<hr>
<h2 id='fun.one.sums'>General Persian Suffix Modification</h2><span id='topic+fun.one.sums'></span>

<h3>Description</h3>

<p>This function modifies Persian words based on a specified suffix type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fun.one.sums(v, type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fun.one.sums_+3A_v">v</code></td>
<td>
<p>A character vector of Persian words.</p>
</td></tr>
<tr><td><code id="fun.one.sums_+3A_type">type</code></td>
<td>
<p>A character string representing the suffix type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector where each element corresponds to a word
from the input vector 'v' with the specified suffix type modified.
This results in a transformed vector where each word has been modified
to remove or alter the specified suffix. The length of the returned
vector matches the length of the input vector, and each word is
modified independently based on the specified suffix type.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  words &lt;- c("Persian text here")
  modified_words &lt;- fun.one.sums(words, "Persian text here")

## End(Not run)
</code></pre>

<hr>
<h2 id='FUNbigrams'>Extract Bigram Information and Count Frequency</h2><span id='topic+FUNbigrams'></span>

<h3>Description</h3>

<p>This function processes a data frame containing bigrams and their frequency,
and creates a new data frame with separated words and their frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FUNbigrams(tf.bigrams)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FUNbigrams_+3A_tf.bigrams">tf.bigrams</code></td>
<td>
<p>A data frame with bigram terms and their frequency.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble data frame where each row represents a unique bigram from
the input data. The data frame contains three columns: 'word1' and
'word2' representing the individual words in the bigram, and 'weight'
representing the frequency of the bigram in the corpus. This structure
facilitates further analysis of the bigram relationships and their
occurrences.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tf_bigrams &lt;- data.frame(term = c("hello_world", "shiny_app"),
                         term_freq = c(3, 2))
bigram_info &lt;- FUNbigrams(tf_bigrams)
</code></pre>

<hr>
<h2 id='fungan'>Persian Suffix Modification for 'Persian text here' Suffix</h2><span id='topic+fungan'></span>

<h3>Description</h3>

<p>This function modifies Persian words ending with 'Persian text here' suffix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fungan(v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungan_+3A_v">v</code></td>
<td>
<p>A character vector of Persian words.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector where each element corresponds to a word
from the input vector &lsquo;v' with the &rsquo;Persian text here' suffix modified.
This results in a transformed vector where each word ending with
the specified suffix is altered. The length of the returned vector
matches the length of the input vector, and each word is modified
independently based on the presence of the specified suffix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  words &lt;- c("Persian text here")
  modified_words &lt;- fungan(words)

## End(Not run)
</code></pre>

<hr>
<h2 id='fungi'>Persian Suffix Modification</h2><span id='topic+fungi'></span>

<h3>Description</h3>

<p>This function modifies Persian words ending with 'Persian text here' suffix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fungi(v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungi_+3A_v">v</code></td>
<td>
<p>A character vector of Persian words.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector where each element corresponds to a word
from the input vector 'v' with the specified suffix modified.
This results in a transformed vector where each word ending with
the specified suffix is altered. The length of the returned vector
matches the length of the input vector, and each word is modified
independently based on the presence of the specified suffix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  words &lt;- c("Persian text here")
  modified_words &lt;- fungi(words)

## End(Not run)
</code></pre>

<hr>
<h2 id='funmi'>Modify Persian Words Starting with 'Persian text here'</h2><span id='topic+funmi'></span>

<h3>Description</h3>

<p>This function modifies Persian words starting with the prefix 'Persian text here'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>funmi(v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="funmi_+3A_v">v</code></td>
<td>
<p>A character vector of Persian words.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector where each element corresponds to a word
from the input vector 'v' with the specified suffix modified.
This results in a transformed vector where each word ending with
the specified suffix is altered. The length of the returned vector
matches the length of the input vector, and each word is modified
independently based on the presence of the specified suffix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  words &lt;- c("Persian text here")
  modified_words &lt;- funmi(words)

## End(Not run)
</code></pre>

<hr>
<h2 id='LEMMA'>Persian Lemmatization</h2><span id='topic+LEMMA'></span>

<h3>Description</h3>

<p>This function performs lemmatization on a vector of Persian words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LEMMA(Y, TYPE = TYPE.org)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LEMMA_+3A_y">Y</code></td>
<td>
<p>A character vector of Persian words.</p>
</td></tr>
<tr><td><code id="LEMMA_+3A_type">TYPE</code></td>
<td>
<p>A vector of suffix types for modification.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector where each element is the lemmatized
form of the corresponding element in the input vector 'Y'.
Lemmatization involves removing inflectional endings and returning
the word to its base or dictionary form. The length of the returned
vector matches the length of the input vector, and each word is
lemmatized independently based on the specified suffix types in 'TYPE'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  words &lt;- c("Persian text here")
  lemmatized_words &lt;- LEMMA(words, TYPE)

## End(Not run)
</code></pre>

<hr>
<h2 id='network.cor'>Create and Plot a Correlation Network</h2><span id='topic+network.cor'></span>

<h3>Description</h3>

<p>This function creates a correlation network based on specified terms
and a threshold, and optionally plots it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>network.cor(dt, Terms, threshold = 0.4, pl = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="network.cor_+3A_dt">dt</code></td>
<td>
<p>A document-term matrix.</p>
</td></tr>
<tr><td><code id="network.cor_+3A_terms">Terms</code></td>
<td>
<p>A vector of terms to check for correlation.</p>
</td></tr>
<tr><td><code id="network.cor_+3A_threshold">threshold</code></td>
<td>
<p>A numeric threshold for correlation.</p>
</td></tr>
<tr><td><code id="network.cor_+3A_pl">pl</code></td>
<td>
<p>A logical value to plot the network or not.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If 'pl' is TRUE, a plot of the correlation network is displayed,
highlighting the strength of associations between terms. If 'pl' is FALSE,
a data frame with correlation pairs and their corresponding weights is returned.
</p>

<hr>
<h2 id='PMI'>Calculate Pointwise Mutual Information (PMI)</h2><span id='topic+PMI'></span>

<h3>Description</h3>

<p>This function calculates the PMI for collocations in a given text data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PMI(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PMI_+3A_x">x</code></td>
<td>
<p>A data frame with columns 'token' and 'doc_id'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame where each row represents a unique keyword
(collocation) in the input data. The data frame contains columns
such as 'keyword', representing the keyword, and 'pmi', representing
the PMI score of that keyword. Higher PMI scores indicate a stronger
association between the components of the collocation within the corpus.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- data.frame(token = c("word1", "word2"), doc_id = c(1, 1))
pmi_scores &lt;- PMI(data)
</code></pre>

<hr>
<h2 id='ScaleWeight'>Scale a Numeric Vector</h2><span id='topic+ScaleWeight'></span>

<h3>Description</h3>

<p>This function scales a numeric vector by a specified lambda value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScaleWeight(x, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScaleWeight_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="ScaleWeight_+3A_lambda">lambda</code></td>
<td>
<p>A numeric scaling factor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector where each element of the input vector 'x' is
divided by the scaling factor 'lambda'. This results in a scaled
version of the input vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>scaled_vector &lt;- ScaleWeight(1:10, 2)
</code></pre>

<hr>
<h2 id='server'>Server Logic for MadanText Shiny Application</h2><span id='topic+server'></span>

<h3>Description</h3>

<p>This function contains the server-side logic for the MadanText application.
It handles user inputs, processes data, and creates outputs to be displayed
in the UI.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>server(input, output)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="server_+3A_input">input</code></td>
<td>
<p>List of Shiny inputs.</p>
</td></tr>
<tr><td><code id="server_+3A_output">output</code></td>
<td>
<p>List of Shiny outputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function sets up the reactive environment and output elements in
the Shiny application. It does not return any value but modifies the Shiny app's
UI based on user inputs and reactive expressions. It returns a Shiny Server object.
</p>

<hr>
<h2 id='set.graph'>Set Graph Attributes</h2><span id='topic+set.graph'></span>

<h3>Description</h3>

<p>This function sets various attributes for a given graph object, including
vertex degree and edge width.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.graph(network)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set.graph_+3A_network">network</code></td>
<td>
<p>A graph object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input graph object with added attributes: 'degree' for each vertex
and 'width' for each edge. These attributes enhance the graph's
visual representation and analytical capabilities.
</p>

<hr>
<h2 id='ui'>User Interface for MadanText</h2><span id='topic+ui'></span>

<h3>Description</h3>

<p>This function creates a user interface for the MadanText Shiny application.
It includes various input and output widgets for file uploads, text input,
and visualization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ui
</code></pre>


<h3>Format</h3>

<p>An object of class <code>shiny.tag.list</code> (inherits from <code>list</code>) of length 4.
</p>


<h3>Value</h3>

<p>A Shiny UI object.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
