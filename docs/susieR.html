<!DOCTYPE html><html><head><title>Help for package susieR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {susieR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#susieR-package'><p>susieR: Sum of Single Effects Linear Regression</p></a></li>
<li><a href='#coef.susie'><p>Extract regression coefficients from susie fit</p></a></li>
<li><a href='#compute_ss'><p>Compute sufficient statistics for input to <code>susie_suff_stat</code></p></a></li>
<li><a href='#compute_suff_stat'><p>Compute sufficient statistics for input to <code>susie_suff_stat</code></p></a></li>
<li><a href='#estimate_s_rss'><p>Estimate s in <code>susie_rss</code> Model Using Regularized LD</p></a></li>
<li><a href='#FinemappingConvergence'><p>Simulated Fine-mapping Data with Convergence Problem.</p></a></li>
<li><a href='#get_cs_correlation'><p>Get Correlations Between CSs, using Variable with Maximum PIP From Each CS</p></a></li>
<li><a href='#kriging_rss'><p>Compute Distribution of z-scores of Variant j Given Other z-scores, and Detect Possible Allele Switch Issue</p></a></li>
<li><a href='#N2finemapping'><p>Simulated Fine-mapping Data with Two Effect Variables</p></a></li>
<li><a href='#N3finemapping'><p>Simulated Fine-mapping Data with Three Effect Variables.</p></a></li>
<li><a href='#predict.susie'><p>Predict outcomes or extract coefficients from susie fit.</p></a></li>
<li><a href='#single_effect_regression'><p>Bayesian single-effect linear regression</p></a></li>
<li><a href='#summary.susie'><p>Summarize Susie Fit.</p></a></li>
<li><a href='#SummaryConsistency'><p>Simulated Fine-mapping Data with LD matrix From Reference Panel.</p></a></li>
<li><a href='#susie'><p>Sum of Single Effects (SuSiE) Regression</p></a></li>
<li><a href='#susie_auto'><p>Attempt at Automating SuSiE for Hard Problems</p></a></li>
<li><a href='#susie_get_objective'><p>Inferences From Fitted SuSiE Model</p></a></li>
<li><a href='#susie_init_coef'><p>Initialize a susie object using regression coefficients</p></a></li>
<li><a href='#susie_plot'><p>SuSiE Plots.</p></a></li>
<li><a href='#susie_plot_changepoint'><p>Plot changepoint data and susie fit using ggplot2</p></a></li>
<li><a href='#susie_rss'><p>Sum of Single Effects (SuSiE) Regression using Summary Statistics</p></a></li>
<li><a href='#susie_trendfilter'><p>Apply susie to trend filtering (especially changepoint</p>
problems), a type of non-parametric regression.</a></li>
<li><a href='#univariate_regression'><p>Perform Univariate Linear Regression Separately for Columns of X</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sum of Single Effects Linear Regression</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements methods for variable selection in linear
    regression based on the "Sum of Single Effects" (SuSiE) model, as
    described in Wang et al (2020) &lt;<a href="https://doi.org/10.1101%2F501114">doi:10.1101/501114</a>&gt; and Zou et al
    (2021) &lt;<a href="https://doi.org/10.1101%2F2021.11.03.467167">doi:10.1101/2021.11.03.467167</a>&gt;. These methods provide
    simple summaries, called "Credible Sets", for accurately
    quantifying uncertainty in which variables should be selected.
    The methods are motivated by genetic fine-mapping applications,
    and are particularly well-suited to settings where variables are
    highly correlated and detectable effects are sparse. The fitting
    algorithm, a Bayesian analogue of stepwise selection methods
    called "Iterative Bayesian Stepwise Selection" (IBSS), is simple
    and fast, allowing the SuSiE model be fit to large data sets
    (thousands of samples and hundreds of thousands of variables).</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-02-17</td>
</tr>
<tr>
<td>Version:</td>
<td>0.12.35</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/stephenslab/susieR">https://github.com/stephenslab/susieR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/stephenslab/susieR/issues">https://github.com/stephenslab/susieR/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, graphics, grDevices, stats, Matrix, matrixStats,
mixsqp, reshape, crayon, ggplot2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>curl, testthat, microbenchmark, knitr, rmarkdown, Rfast,
cowplot</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-02-17 16:39:00 UTC; pcarbo</td>
</tr>
<tr>
<td>Author:</td>
<td>Gao Wang [aut],
  Yuxin Zou [aut],
  Kaiqian Zhang [aut],
  Peter Carbonetto [aut, cre],
  Matthew Stephens [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Peter Carbonetto &lt;peter.carbonetto@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-02-17 17:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='susieR-package'>susieR: Sum of Single Effects Linear Regression</h2><span id='topic+susieR'></span><span id='topic+susieR-package'></span>

<h3>Description</h3>

<p>Implements methods for variable selection in linear
regression based on the &quot;Sum of Single Effects&quot; (SuSiE) model, as
described in Wang et al (2020) doi: <a href="https://doi.org/10.1101/501114">10.1101/501114</a> and Zou et al
(2021) doi: <a href="https://doi.org/10.1101/2021.11.03.467167">10.1101/2021.11.03.467167</a>. These methods provide
simple summaries, called &quot;Credible Sets&quot;, for accurately
quantifying uncertainty in which variables should be selected.
The methods are motivated by genetic fine-mapping applications,
and are particularly well-suited to settings where variables are
highly correlated and detectable effects are sparse. The fitting
algorithm, a Bayesian analogue of stepwise selection methods
called &quot;Iterative Bayesian Stepwise Selection&quot; (IBSS), is simple
and fast, allowing the SuSiE model be fit to large data sets
(thousands of samples and hundreds of thousands of variables).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Peter Carbonetto <a href="mailto:peter.carbonetto@gmail.com">peter.carbonetto@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Gao Wang <a href="mailto:wang.gao@columbia.edu">wang.gao@columbia.edu</a>
</p>
</li>
<li><p> Yuxin Zou
</p>
</li>
<li><p> Kaiqian Zhang
</p>
</li>
<li><p> Matthew Stephens
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/stephenslab/susieR">https://github.com/stephenslab/susieR</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/stephenslab/susieR/issues">https://github.com/stephenslab/susieR/issues</a>
</p>
</li></ul>


<hr>
<h2 id='coef.susie'>Extract regression coefficients from susie fit</h2><span id='topic+coef.susie'></span>

<h3>Description</h3>

<p>Extract regression coefficients from susie fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'susie'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.susie_+3A_object">object</code></td>
<td>
<p>A susie fit.</p>
</td></tr>
<tr><td><code id="coef.susie_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the generic <code>coef</code>
method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A p+1 vector, the first element being an intercept, and the
remaining p elements being estimated regression coefficients.
</p>

<hr>
<h2 id='compute_ss'>Compute sufficient statistics for input to <code>susie_suff_stat</code></h2><span id='topic+compute_ss'></span>

<h3>Description</h3>

<p>This is a synonym for <code>compute_suff_stat</code>
included for historical reasons (deprecated).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_ss(X, y, standardize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_ss_+3A_x">X</code></td>
<td>
<p>An n by p matrix of covariates.</p>
</td></tr>
<tr><td><code id="compute_ss_+3A_y">y</code></td>
<td>
<p>An n vector.</p>
</td></tr>
<tr><td><code id="compute_ss_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag indicating whether to standardize
columns of X to unit variance prior to computing summary data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of sufficient statistics (X'X, X'y, y'y and n)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(N2finemapping)
ss = compute_ss(N2finemapping$X, N2finemapping$Y[,1])

</code></pre>

<hr>
<h2 id='compute_suff_stat'>Compute sufficient statistics for input to <code>susie_suff_stat</code></h2><span id='topic+compute_suff_stat'></span>

<h3>Description</h3>

<p>Computes the sufficient statistics <code class="reqn">X'X, X'y, y'y</code>
and <code class="reqn">n</code> after centering (and possibly standardizing) the
columns of <code class="reqn">X</code> and centering <code class="reqn">y</code> to have mean zero. We also
store the column means of <code class="reqn">X</code> and mean of <code class="reqn">y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_suff_stat(X, y, standardize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_suff_stat_+3A_x">X</code></td>
<td>
<p>An n by p matrix of covariates.</p>
</td></tr>
<tr><td><code id="compute_suff_stat_+3A_y">y</code></td>
<td>
<p>An n vector.</p>
</td></tr>
<tr><td><code id="compute_suff_stat_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag indicating whether to standardize
columns of X to unit variance prior to computing summary data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of sufficient statistics (<code>XtX, Xty, yty, n</code>)
and <code>X_colmeans</code>, <code>y_mean</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(N2finemapping)
ss = compute_suff_stat(N2finemapping$X, N2finemapping$Y[,1])

</code></pre>

<hr>
<h2 id='estimate_s_rss'>Estimate s in <code>susie_rss</code> Model Using Regularized LD</h2><span id='topic+estimate_s_rss'></span>

<h3>Description</h3>

<p>The estimated s gives information about the
consistency between the z scores and LD matrix. A larger <code class="reqn">s</code>
means there is a strong inconsistency between z scores and LD
matrix. The &ldquo;null-mle&rdquo; method obtains mle of <code class="reqn">s</code> under
<code class="reqn">z | R ~ N(0,(1-s)R + s I)</code>, <code class="reqn">0 &lt; s &lt; 1</code>. The
&ldquo;null-partialmle&rdquo; method obtains mle of <code class="reqn">s</code> under
<code class="reqn">U^T z | R ~ N(0,s I)</code>, in which <code class="reqn">U</code> is a matrix containing
the of eigenvectors that span the null space of R; that is, the
eigenvectors corresponding to zero eigenvalues of R. The estimated
<code class="reqn">s</code> from &ldquo;null-partialmle&rdquo; could be greater than 1. The
&ldquo;null-pseudomle&rdquo; method obtains mle of <code class="reqn">s</code> under
pseudolikelihood <code class="reqn">L(s) = \prod_{j=1}^{p} p(z_j | z_{-j}, s,
  R)</code>, <code class="reqn">0 &lt; s &lt; 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_s_rss(z, R, n, r_tol = 1e-08, method = "null-mle")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_s_rss_+3A_z">z</code></td>
<td>
<p>A p-vector of z scores.</p>
</td></tr>
<tr><td><code id="estimate_s_rss_+3A_r">R</code></td>
<td>
<p>A p by p symmetric, positive semidefinite correlation
matrix.</p>
</td></tr>
<tr><td><code id="estimate_s_rss_+3A_n">n</code></td>
<td>
<p>The sample size. (Optional, but highly recommended.)</p>
</td></tr>
<tr><td><code id="estimate_s_rss_+3A_r_tol">r_tol</code></td>
<td>
<p>Tolerance level for eigenvalue check of positive
semidefinite matrix of R.</p>
</td></tr>
<tr><td><code id="estimate_s_rss_+3A_method">method</code></td>
<td>
<p>a string specifies the method to estimate <code class="reqn">s</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number between 0 and 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n = 500
p = 1000
beta = rep(0,p)
beta[1:4] = 0.01
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))
input_ss = compute_suff_stat(X,y,standardize = TRUE)
ss = univariate_regression(X,y)
R = cor(X)
attr(R,"eigen") = eigen(R,symmetric = TRUE)
zhat = with(ss,betahat/sebetahat)

# Estimate s using the unadjusted z-scores.
s0 = estimate_s_rss(zhat,R)

# Estimate s using the adjusted z-scores.
s1 = estimate_s_rss(zhat,R,n)

</code></pre>

<hr>
<h2 id='FinemappingConvergence'>Simulated Fine-mapping Data with Convergence Problem.</h2><span id='topic+FinemappingConvergence'></span>

<h3>Description</h3>

<p>Data simulated using real genotypes from 50,000
individuals and 200 SNPs. Two of the SNPs have non-zero effects
on the multivariate response. The response data are generated under
a linear regression model. The simulated response and the columns
of the genotype matrix are centered.
</p>


<h3>Format</h3>

<p><code>FinemappingConvergence</code> is a list with the following
elements:
</p>

<dl>
<dt>XtX</dt><dd><p>Summary statistics computed using the centered and
scaled genotype matrix.</p>
</dd>
<dt>Xty</dt><dd><p>Summary statistics computed using the centered and
scaled genotype data, and the centered simulated response.</p>
</dd>
<dt>yty</dt><dd><p>yty is computed using the centered simulated response.</p>
</dd>
<dt>n</dt><dd><p>The sample size (50,000).</p>
</dd>
<dt>true_coef</dt><dd><p>The coefficients used to simulate the responses.</p>
</dd>
<dt>z</dt><dd><p>z-scores from a simple (single-SNP) linear regression.</p>
</dd></dl>



<h3>See Also</h3>

<p>A similar data set with more SNPs is used in the
&ldquo;Refine SuSiE model&rdquo; vignette.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(FinemappingConvergence)
</code></pre>

<hr>
<h2 id='get_cs_correlation'>Get Correlations Between CSs, using Variable with Maximum PIP From Each CS</h2><span id='topic+get_cs_correlation'></span>

<h3>Description</h3>

<p>This function evaluates the correlation between single effect
CSs. It is not part of the SuSiE inference. Rather, it is designed as
a diagnostic tool to assess how correlated the reported CS are.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_cs_correlation(model, X = NULL, Xcorr = NULL, max = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_cs_correlation_+3A_model">model</code></td>
<td>
<p>A SuSiE fit, typically an output from
<code><a href="#topic+susie">susie</a></code> or one of its variants.</p>
</td></tr>
<tr><td><code id="get_cs_correlation_+3A_x">X</code></td>
<td>
<p>n by p matrix of values of the p variables (covariates) in
n samples. When provided, correlation between variables will be
computed and used to remove CSs whose minimum correlation among
variables is smaller than <code>min_abs_corr</code>.</p>
</td></tr>
<tr><td><code id="get_cs_correlation_+3A_xcorr">Xcorr</code></td>
<td>
<p>p by p matrix of correlations between variables
(covariates). When provided, it will be used to remove CSs whose
minimum correlation among variables is smaller than
<code>min_abs_corr</code>.</p>
</td></tr>
<tr><td><code id="get_cs_correlation_+3A_max">max</code></td>
<td>
<p>When <code>max = FAFLSE</code>, return a matrix of CS
correlations. When <code>max = TRUE</code>, return only the maximum
absolute correlation among all pairs of correlations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of correlations between CSs, or the maximum
absolute correlation when <code>max = TRUE</code>.
</p>

<hr>
<h2 id='kriging_rss'>Compute Distribution of z-scores of Variant j Given Other z-scores, and Detect Possible Allele Switch Issue</h2><span id='topic+kriging_rss'></span>

<h3>Description</h3>

<p>Under the null, the rss model with regularized LD
matrix is <code class="reqn">z|R,s ~ N(0, (1-s)R + s I))</code>. We use a mixture of
normals to model the conditional distribution of z_j given other z
scores, <code class="reqn">z_j | z_{-j}, R, s ~ \sum_{k=1}^{K} \pi_k
  N(-\Omega_{j,-j} z_{-j}/\Omega_{jj}, \sigma_{k}^2/\Omega_{jj})</code>,
<code class="reqn">\Omega = ((1-s)R + sI)^{-1}</code>, <code class="reqn">\sigma_1, ..., \sigma_k</code>
is a grid of fixed positive numbers. We estimate the mixture
weights <code class="reqn">\pi</code>  We detect the possible allele switch issue
using likelihood ratio for each variant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kriging_rss(
  z,
  R,
  n,
  r_tol = 1e-08,
  s = estimate_s_rss(z, R, n, r_tol, method = "null-mle")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kriging_rss_+3A_z">z</code></td>
<td>
<p>A p-vector of z scores.</p>
</td></tr>
<tr><td><code id="kriging_rss_+3A_r">R</code></td>
<td>
<p>A p by p symmetric, positive semidefinite correlation
matrix.</p>
</td></tr>
<tr><td><code id="kriging_rss_+3A_n">n</code></td>
<td>
<p>The sample size. (Optional, but highly recommended.)</p>
</td></tr>
<tr><td><code id="kriging_rss_+3A_r_tol">r_tol</code></td>
<td>
<p>Tolerance level for eigenvalue check of positive
semidefinite matrix of R.</p>
</td></tr>
<tr><td><code id="kriging_rss_+3A_s">s</code></td>
<td>
<p>an estimated s from <code>estimate_s_rss</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing a ggplot2 plot object and a table. The plot
compares observed z score vs the expected value. The possible allele
switched variants are labeled as red points (log LR &gt; 2 and abs(z) &gt; 2).
The table summarizes the conditional distribution for each variant
and the likelihood ratio test. The table has the following columns:
the observed z scores, the conditional expectation, the conditional
variance, the standardized differences between the observed z score
and expected value, the log likelihood ratio statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See also the vignette, "Diagnostic for fine-mapping with summary
# statistics."
set.seed(1)
n = 500
p = 1000
beta = rep(0,p)
beta[1:4] = 0.01
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))
ss = univariate_regression(X,y)
R = cor(X)
attr(R,"eigen") = eigen(R,symmetric = TRUE)
zhat = with(ss,betahat/sebetahat)
cond_dist = kriging_rss(zhat,R,n = n)
cond_dist$plot

</code></pre>

<hr>
<h2 id='N2finemapping'>Simulated Fine-mapping Data with Two Effect Variables</h2><span id='topic+N2finemapping'></span>

<h3>Description</h3>

<p>This data set contains a genotype matrix for 574
individuals and 1,002 variables. The variables are genotypes after
centering and scaling, and therefore retain the correlation
structure of the original genotype data. Two of the variables have
non-zero effects on the multivariate response. The response data
are generated under a multivariate linear regression model. See
Wang <em>et al</em> (2020) for details.
</p>


<h3>Format</h3>

<p><code>N2finemapping</code> is a list with the following elements:
</p>

<dl>
<dt>X</dt><dd><p>Centered and scaled genotype data.</p>
</dd>
<dt>chrom</dt><dd><p>Chromomsome of the original data, in hg38 coordinates.</p>
</dd>
<dt>pos</dt><dd><p>Chromomosomal position of the original data, in hg38
coordinates. The information can be used to compare impact of using
other genotype references of the same variables in <code>susie_rss</code>
application.</p>
</dd>
<dt>true_coef</dt><dd><p>Simulated effect sizes.</p>
</dd>
<dt>residual_variance</dt><dd><p>Simulated residual covariance matrix.</p>
</dd>
<dt>Y</dt><dd><p>Simulated multivariate response.</p>
</dd>
<dt>allele_freq</dt><dd><p>Allele frequencies based on the original
genotype data.</p>
</dd>
<dt>V</dt><dd><p>Suggested prior covariance matrix for effect sizes of
the two non-zero effect variables.</p>
</dd>
</dl>



<h3>References</h3>

<p>G. Wang, A. Sarkar, P. Carbonetto and M. Stephens (2020). A simple
new approach to variable selection in regression, with application
to genetic fine-mapping. <em>Journal of the Royal Statistical
Society, Series B</em> doi: <a href="https://doi.org/10.1101/501114">10.1101/501114</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(N2finemapping)
</code></pre>

<hr>
<h2 id='N3finemapping'>Simulated Fine-mapping Data with Three Effect Variables.</h2><span id='topic+N3finemapping'></span>

<h3>Description</h3>

<p>The data-set contains a matrix of 574
individuals and 1,001 variables. These variables are real-world
genotypes centered and scaled, and therefore retains the
correlation structure of variables in the original genotype data. 3
out of the variables have non-zero effects.  The response data is
generated under a multivariate linear regression model. See Wang
<em>et al</em> (2020) for more details.
</p>


<h3>Format</h3>

<p><code>N3finemapping</code> is a list with the following elements:
</p>

<dl>
<dt>X</dt><dd><p>N by P variable matrix of centered and scaled genotype
data.</p>
</dd>
<dt>chrom</dt><dd><p>Chromomsome of the original data, in hg38 coordinate.</p>
</dd>
<dt>pos</dt><dd><p>Chromomosomal positoin of the original data, in hg38
coordinate. The information can be used to compare impact of using
other genotype references of the same variables in susie_rss
application.</p>
</dd>
<dt>true_coef</dt><dd><p>The simulated effect sizes.</p>
</dd>
<dt>residual_variance</dt><dd><p>The simulated residual covariance matrix.</p>
</dd>
<dt>Y</dt><dd><p>The simulated response variables.</p>
</dd>
<dt>allele_freq</dt><dd><p>Allele frequency of the original genotype data.</p>
</dd>
<dt>V</dt><dd><p>Prior covariance matrix for effect size of the three
non-zero effect variables.</p>
</dd>  </dl>



<h3>References</h3>

<p>G. Wang, A. Sarkar, P. Carbonetto and M. Stephens (2020). A simple
new approach to variable selection in regression, with application
to genetic fine-mapping. <em>Journal of the Royal Statistical
Society, Series B</em> doi: <a href="https://doi.org/10.1101/501114">10.1101/501114</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(N3finemapping)
</code></pre>

<hr>
<h2 id='predict.susie'>Predict outcomes or extract coefficients from susie fit.</h2><span id='topic+predict.susie'></span>

<h3>Description</h3>

<p>Predict outcomes or extract coefficients from susie fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'susie'
predict(object, newx = NULL, type = c("response", "coefficients"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.susie_+3A_object">object</code></td>
<td>
<p>A susie fit.</p>
</td></tr>
<tr><td><code id="predict.susie_+3A_newx">newx</code></td>
<td>
<p>A new value for X at which to do predictions.</p>
</td></tr>
<tr><td><code id="predict.susie_+3A_type">type</code></td>
<td>
<p>The type of output. For <code>type = "response"</code>,
predicted or fitted outcomes are returned; for <code>type =
"coefficients"</code>, the estimated coefficients are returned.</p>
</td></tr>
<tr><td><code id="predict.susie_+3A_...">...</code></td>
<td>
<p>Other arguments used by generic predict function. These
extra arguments are not used here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>type = "response"</code>, predicted or fitted outcomes
are returned; for <code>type = "coefficients"</code>, the estimated
coefficients are returned. If the susie fit has intercept =
<code>NA</code> (which is common when using <code>susie_suff_stat</code>) then
predictions are computed using an intercept of 0, and a warning is
emitted.
</p>

<hr>
<h2 id='single_effect_regression'>Bayesian single-effect linear regression</h2><span id='topic+single_effect_regression'></span><span id='topic+single_effect_regression_rss'></span><span id='topic+single_effect_regression_ss'></span>

<h3>Description</h3>

<p>These methods fit the regression model <code class="reqn">y = Xb +
  e</code>, where elements of e are <em>i.i.d.</em>  <code class="reqn">N(0,s^2)</code>, and b is
a p-vector of effects to be estimated. The assumption is that b has
exactly one non-zero element, with all elements equally likely to
be non-zero. The prior on the coefficient of the non-zero element
is <code class="reqn">N(0,V)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>single_effect_regression(
  y,
  X,
  V,
  residual_variance = 1,
  prior_weights = NULL,
  optimize_V = c("none", "optim", "uniroot", "EM", "simple"),
  check_null_threshold = 0
)

single_effect_regression_rss(
  z,
  Sigma,
  V = 1,
  prior_weights = NULL,
  optimize_V = c("none", "optim", "uniroot", "EM", "simple"),
  check_null_threshold = 0
)

single_effect_regression_ss(
  Xty,
  dXtX,
  V = 1,
  residual_variance = 1,
  prior_weights = NULL,
  optimize_V = c("none", "optim", "uniroot", "EM", "simple"),
  check_null_threshold = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="single_effect_regression_+3A_y">y</code></td>
<td>
<p>An n-vector.</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_x">X</code></td>
<td>
<p>An n by p matrix of covariates.</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_v">V</code></td>
<td>
<p>A scalar giving the (initial) prior variance</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_residual_variance">residual_variance</code></td>
<td>
<p>The residual variance.</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_prior_weights">prior_weights</code></td>
<td>
<p>A p-vector of prior weights.</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_optimize_v">optimize_V</code></td>
<td>
<p>The optimization method to use for fitting the
prior variance.</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_check_null_threshold">check_null_threshold</code></td>
<td>
<p>Scalar specifying threshold on the
log-scale to compare likelihood between current estimate and zero
the null.</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_z">z</code></td>
<td>
<p>A p-vector of z scores.</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_sigma">Sigma</code></td>
<td>
<p><code>residual_var*R + lambda*I</code></p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_xty">Xty</code></td>
<td>
<p>A p-vector.</p>
</td></tr>
<tr><td><code id="single_effect_regression_+3A_dxtx">dXtX</code></td>
<td>
<p>A p-vector containing the diagonal elements of
<code>crossprod(X)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>single_effect_regression_ss</code> performs single-effect
linear regression with summary data, in which only the statistcs
<code class="reqn">X^Ty</code> and diagonal elements of <code class="reqn">X^TX</code> are provided to the
method.
</p>
<p><code>single_effect_regression_rss</code> performs single-effect linear
regression with z scores. That is, this function fits the
regression model <code class="reqn">z = R*b + e</code>, where e is <code class="reqn">N(0,Sigma)</code>,
<code class="reqn">Sigma = residual_var*R + lambda*I</code>, and the b is a p-vector of
effects to be estimated. The assumption is that b has exactly one
non-zero element, with all elements equally likely to be non-zero.
The prior on the non-zero element is <code class="reqn">N(0,V)</code>. The required
summary data are the p-vector <code>z</code> and the p by p matrix
<code>Sigma</code>. The summary statistics should come from the same
individuals.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>Vector of posterior inclusion probabilities;
<code>alpha[i]</code> is posterior probability that the ith coefficient
is non-zero.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>Vector of posterior means (conditional on inclusion).</p>
</td></tr>
<tr><td><code>mu2</code></td>
<td>
<p>Vector of posterior second moments (conditional on
inclusion).</p>
</td></tr>
<tr><td><code>lbf</code></td>
<td>
<p>Vector of log-Bayes factors for each variable.</p>
</td></tr>
<tr><td><code>lbf_model</code></td>
<td>
<p>Log-Bayes factor for the single effect regression.</p>
</td></tr>
</table>
<p><code>single_effect_regression</code> and <code>single_effect_regression_ss</code>
additionally output:
</p>
<table>
<tr><td><code>V</code></td>
<td>
<p>Prior variance (after optimization if <code>optimize_V !=
  "none"</code>).</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The log-likelihood, <code class="reqn">\log p(y | X, V)</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='summary.susie'>Summarize Susie Fit.</h2><span id='topic+summary.susie'></span><span id='topic+print.summary.susie'></span>

<h3>Description</h3>

<p><code>summary</code> method for the &ldquo;susie&rdquo; class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'susie'
summary(object, ...)

## S3 method for class 'summary.susie'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.susie_+3A_object">object</code></td>
<td>
<p>A susie fit.</p>
</td></tr>
<tr><td><code id="summary.susie_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the generic <code>summary</code>
or <code>print.summary</code> method.</p>
</td></tr>
<tr><td><code id="summary.susie_+3A_x">x</code></td>
<td>
<p>A susie summary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.susie</code> returns a list containing a data frame
of variables and a data frame of credible sets.
</p>

<hr>
<h2 id='SummaryConsistency'>Simulated Fine-mapping Data with LD matrix From Reference Panel.</h2><span id='topic+SummaryConsistency'></span>

<h3>Description</h3>

<p>Data simulated using real genotypes from 10,000
individuals and 200 SNPs. One SNP have non-zero effect
on the multivariate response. The response data are generated under
a linear regression model. There is also one SNP with flipped allele
between summary statistics and the reference panel.
</p>


<h3>Format</h3>

<p><code>SummaryConsistency</code> is a list with the following
elements:
</p>

<dl>
<dt>z</dt><dd><p>z-scores computed by fitting univariate simple regression
variable-by-variable.</p>
</dd>
<dt>ldref</dt><dd><p>LD matrix estimated from the reference panel.</p>
</dd>
<dt>flip_id</dt><dd><p>The index of the SNP with the flipped allele.</p>
</dd>
<dt>signal_id</dt><dd><p>The index of the SNP with the non-zero effect.</p>
</dd></dl>



<h3>See Also</h3>

<p>A similar data set with more samples is used in the
&ldquo;Diagnostic for fine-mapping with summary statistics&rdquo;
vignette.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SummaryConsistency)
</code></pre>

<hr>
<h2 id='susie'>Sum of Single Effects (SuSiE) Regression</h2><span id='topic+susie'></span><span id='topic+susie_suff_stat'></span>

<h3>Description</h3>

<p>Performs a sparse Bayesian multiple linear regression
of y on X, using the &quot;Sum of Single Effects&quot; model from Wang et al
(2020). In brief, this function fits the regression model <code class="reqn">y =
  \mu + X b + e</code>, where elements of <code class="reqn">e</code> are <em>i.i.d.</em> normal
with zero mean and variance <code>residual_variance</code>, <code class="reqn">\mu</code> is
an intercept term and <code class="reqn">b</code> is a vector of length p representing
the effects to be estimated. The &ldquo;susie assumption&rdquo; is that
<code class="reqn">b = \sum_{l=1}^L b_l</code> where each <code class="reqn">b_l</code> is a vector of
length p with exactly one non-zero element. The prior on the
non-zero element is normal with zero mean and variance <code>var(y)
  * scaled_prior_variance</code>. The value of <code>L</code> is fixed, and
should be chosen to provide a reasonable upper bound on the number
of non-zero effects to be detected. Typically, the hyperparameters
<code>residual_variance</code> and <code>scaled_prior_variance</code> will be
estimated during model fitting, although they can also be fixed as
specified by the user. See functions <code><a href="#topic+susie_get_cs">susie_get_cs</a></code> and
other functions of form <code>susie_get_*</code> to extract the most
commonly-used results from a susie fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>susie(
  X,
  y,
  L = min(10, ncol(X)),
  scaled_prior_variance = 0.2,
  residual_variance = NULL,
  prior_weights = NULL,
  null_weight = 0,
  standardize = TRUE,
  intercept = TRUE,
  estimate_residual_variance = TRUE,
  estimate_prior_variance = TRUE,
  estimate_prior_method = c("optim", "EM", "simple"),
  check_null_threshold = 0,
  prior_tol = 1e-09,
  residual_variance_upperbound = Inf,
  s_init = NULL,
  coverage = 0.95,
  min_abs_corr = 0.5,
  compute_univariate_zscore = FALSE,
  na.rm = FALSE,
  max_iter = 100,
  tol = 0.001,
  verbose = FALSE,
  track_fit = FALSE,
  residual_variance_lowerbound = var(drop(y))/10000,
  refine = FALSE,
  n_purity = 100
)

susie_suff_stat(
  XtX,
  Xty,
  yty,
  n,
  X_colmeans = NA,
  y_mean = NA,
  maf = NULL,
  maf_thresh = 0,
  L = 10,
  scaled_prior_variance = 0.2,
  residual_variance = NULL,
  estimate_residual_variance = TRUE,
  estimate_prior_variance = TRUE,
  estimate_prior_method = c("optim", "EM", "simple"),
  check_null_threshold = 0,
  prior_tol = 1e-09,
  r_tol = 1e-08,
  prior_weights = NULL,
  null_weight = 0,
  standardize = TRUE,
  max_iter = 100,
  s_init = NULL,
  coverage = 0.95,
  min_abs_corr = 0.5,
  tol = 0.001,
  verbose = FALSE,
  track_fit = FALSE,
  check_input = FALSE,
  refine = FALSE,
  check_prior = FALSE,
  n_purity = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="susie_+3A_x">X</code></td>
<td>
<p>An n by p matrix of covariates.</p>
</td></tr>
<tr><td><code id="susie_+3A_y">y</code></td>
<td>
<p>The observed responses, a vector of length n.</p>
</td></tr>
<tr><td><code id="susie_+3A_l">L</code></td>
<td>
<p>Maximum number of non-zero effects in the susie
regression model. If L is larger than the number of covariates, p,
L is set to p.</p>
</td></tr>
<tr><td><code id="susie_+3A_scaled_prior_variance">scaled_prior_variance</code></td>
<td>
<p>The prior variance, divided by
<code>var(y)</code> (or by <code>(1/(n-1))yty</code> for
<code>susie_suff_stat</code>); that is, the prior variance of each
non-zero element of b is <code>var(y) * scaled_prior_variance</code>. The
value provided should be either a scalar or a vector of length
<code>L</code>. If <code>estimate_prior_variance = TRUE</code>, this provides
initial estimates of the prior variances.</p>
</td></tr>
<tr><td><code id="susie_+3A_residual_variance">residual_variance</code></td>
<td>
<p>Variance of the residual. If
<code>estimate_residual_variance = TRUE</code>, this value provides the
initial estimate of the residual variance. By default, it is set to
<code>var(y)</code> in <code>susie</code> and <code>(1/(n-1))yty</code> in
<code>susie_suff_stat</code>.</p>
</td></tr>
<tr><td><code id="susie_+3A_prior_weights">prior_weights</code></td>
<td>
<p>A vector of length p, in which each entry
gives the prior probability that corresponding column of X has a
nonzero effect on the outcome, y.</p>
</td></tr>
<tr><td><code id="susie_+3A_null_weight">null_weight</code></td>
<td>
<p>Prior probability of no effect (a number between
0 and 1, and cannot be exactly 1).</p>
</td></tr>
<tr><td><code id="susie_+3A_standardize">standardize</code></td>
<td>
<p>If <code>standardize = TRUE</code>, standardize the
columns of X to unit variance prior to fitting (or equivalently
standardize XtX and Xty to have the same effect). Note that
<code>scaled_prior_variance</code> specifies the prior on the
coefficients of X <em>after</em> standardization (if it is
performed). If you do not standardize, you may need to think more
carefully about specifying <code>scaled_prior_variance</code>. Whatever
your choice, the coefficients returned by <code>coef</code> are given for
<code>X</code> on the original input scale. Any column of <code>X</code> that
has zero variance is not standardized.</p>
</td></tr>
<tr><td><code id="susie_+3A_intercept">intercept</code></td>
<td>
<p>If <code>intercept = TRUE</code>, the intercept is
fitted; it <code>intercept = FALSE</code>, the intercept is set to
zero. Setting <code>intercept = FALSE</code> is generally not
recommended.</p>
</td></tr>
<tr><td><code id="susie_+3A_estimate_residual_variance">estimate_residual_variance</code></td>
<td>
<p>If
<code>estimate_residual_variance = TRUE</code>, the residual variance is
estimated, using <code>residual_variance</code> as an initial value. If
<code>estimate_residual_variance = FALSE</code>, the residual variance is
fixed to the value supplied by <code>residual_variance</code>.</p>
</td></tr>
<tr><td><code id="susie_+3A_estimate_prior_variance">estimate_prior_variance</code></td>
<td>
<p>If <code>estimate_prior_variance =
TRUE</code>, the prior variance is estimated (this is a separate
parameter for each of the L effects). If provided,
<code>scaled_prior_variance</code> is then used as an initial value for
the optimization. When <code>estimate_prior_variance = FALSE</code>, the
prior variance for each of the L effects is determined by the
value supplied to <code>scaled_prior_variance</code>.</p>
</td></tr>
<tr><td><code id="susie_+3A_estimate_prior_method">estimate_prior_method</code></td>
<td>
<p>The method used for estimating prior
variance. When <code>estimate_prior_method = "simple"</code> is used, the
likelihood at the specified prior variance is compared to the
likelihood at a variance of zero, and the setting with the larger
likelihood is retained.</p>
</td></tr>
<tr><td><code id="susie_+3A_check_null_threshold">check_null_threshold</code></td>
<td>
<p>When the prior variance is estimated,
compare the estimate with the null, and set the prior variance to
zero unless the log-likelihood using the estimate is larger by this
threshold amount. For example, if you set
<code>check_null_threshold = 0.1</code>, this will &quot;nudge&quot; the estimate
towards zero when the difference in log-likelihoods is small. A
note of caution that setting this to a value greater than zero may
lead the IBSS fitting procedure to occasionally decrease the ELBO.</p>
</td></tr>
<tr><td><code id="susie_+3A_prior_tol">prior_tol</code></td>
<td>
<p>When the prior variance is estimated, compare the
estimated value to <code>prior_tol</code> at the end of the computation,
and exclude a single effect from PIP computation if the estimated
prior variance is smaller than this tolerance value.</p>
</td></tr>
<tr><td><code id="susie_+3A_residual_variance_upperbound">residual_variance_upperbound</code></td>
<td>
<p>Upper limit on the estimated
residual variance. It is only relevant when
<code>estimate_residual_variance = TRUE</code>.</p>
</td></tr>
<tr><td><code id="susie_+3A_s_init">s_init</code></td>
<td>
<p>A previous susie fit with which to initialize.</p>
</td></tr>
<tr><td><code id="susie_+3A_coverage">coverage</code></td>
<td>
<p>A number between 0 and 1 specifying the
&ldquo;coverage&rdquo; of the estimated confidence sets.</p>
</td></tr>
<tr><td><code id="susie_+3A_min_abs_corr">min_abs_corr</code></td>
<td>
<p>Minimum absolute correlation allowed in a
credible set. The default, 0.5, corresponds to a squared
correlation of 0.25, which is a commonly used threshold for
genotype data in genetic studies.</p>
</td></tr>
<tr><td><code id="susie_+3A_compute_univariate_zscore">compute_univariate_zscore</code></td>
<td>
<p>If <code>compute_univariate_zscore
= TRUE</code>, the univariate regression z-scores are outputted for each
variable.</p>
</td></tr>
<tr><td><code id="susie_+3A_na.rm">na.rm</code></td>
<td>
<p>Drop any missing values in y from both X and y.</p>
</td></tr>
<tr><td><code id="susie_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of IBSS iterations to perform.</p>
</td></tr>
<tr><td><code id="susie_+3A_tol">tol</code></td>
<td>
<p>A small, non-negative number specifying the convergence
tolerance for the IBSS fitting procedure. The fitting procedure
will halt when the difference in the variational lower bound, or
&ldquo;ELBO&rdquo; (the objective function to be maximized), is
less than <code>tol</code>.</p>
</td></tr>
<tr><td><code id="susie_+3A_verbose">verbose</code></td>
<td>
<p>If <code>verbose = TRUE</code>, the algorithm's progress,
and a summary of the optimization settings, are printed to the
console.</p>
</td></tr>
<tr><td><code id="susie_+3A_track_fit">track_fit</code></td>
<td>
<p>If <code>track_fit = TRUE</code>, <code>trace</code>
is also returned containing detailed information about the
estimates at each iteration of the IBSS fitting procedure.</p>
</td></tr>
<tr><td><code id="susie_+3A_residual_variance_lowerbound">residual_variance_lowerbound</code></td>
<td>
<p>Lower limit on the estimated
residual variance. It is only relevant when
<code>estimate_residual_variance = TRUE</code>.</p>
</td></tr>
<tr><td><code id="susie_+3A_refine">refine</code></td>
<td>
<p>If <code>refine = TRUE</code>, then an additional
iterative refinement procedure is used, after the IBSS algorithm,
to check and escape from local optima (see details).</p>
</td></tr>
<tr><td><code id="susie_+3A_n_purity">n_purity</code></td>
<td>
<p>Passed as argument <code>n_purity</code> to
<code><a href="#topic+susie_get_cs">susie_get_cs</a></code>.</p>
</td></tr>
<tr><td><code id="susie_+3A_xtx">XtX</code></td>
<td>
<p>A p by p matrix <code class="reqn">X'X</code> in which the columns of X
are centered to have mean zero.</p>
</td></tr>
<tr><td><code id="susie_+3A_xty">Xty</code></td>
<td>
<p>A p-vector <code class="reqn">X'y</code> in which y and the columns of X are
centered to have mean zero.</p>
</td></tr>
<tr><td><code id="susie_+3A_yty">yty</code></td>
<td>
<p>A scalar <code class="reqn">y'y</code> in which y is centered to have mean
zero.</p>
</td></tr>
<tr><td><code id="susie_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code id="susie_+3A_x_colmeans">X_colmeans</code></td>
<td>
<p>A p-vector of column means of <code>X</code>. If both
<code>X_colmeans</code> and <code>y_mean</code> are provided, the intercept
is estimated; otherwise, the intercept is NA.</p>
</td></tr>
<tr><td><code id="susie_+3A_y_mean">y_mean</code></td>
<td>
<p>A scalar containing the mean of <code>y</code>. If both
<code>X_colmeans</code> and <code>y_mean</code> are provided, the intercept
is estimated; otherwise, the intercept is NA.</p>
</td></tr>
<tr><td><code id="susie_+3A_maf">maf</code></td>
<td>
<p>Minor allele frequency; to be used along with
<code>maf_thresh</code> to filter input summary statistics.</p>
</td></tr>
<tr><td><code id="susie_+3A_maf_thresh">maf_thresh</code></td>
<td>
<p>Variants having a minor allele frequency smaller
than this threshold are not used.</p>
</td></tr>
<tr><td><code id="susie_+3A_r_tol">r_tol</code></td>
<td>
<p>Tolerance level for eigenvalue check of positive
semidefinite matrix of R.</p>
</td></tr>
<tr><td><code id="susie_+3A_check_input">check_input</code></td>
<td>
<p>If <code>check_input = TRUE</code>,
<code>susie_suff_stat</code> performs additional checks on <code>XtX</code> and
<code>Xty</code>. The checks are: (1) check that <code>XtX</code> is positive
semidefinite; (2) check that <code>Xty</code> is in the space spanned by
the non-zero eigenvectors of <code>XtX</code>.</p>
</td></tr>
<tr><td><code id="susie_+3A_check_prior">check_prior</code></td>
<td>
<p>If <code>check_prior = TRUE</code>, it checks if the
estimated prior variance becomes unreasonably large (comparing with
10 * max(abs(z))^2).</p>
</td></tr>
<tr><td><code id="susie_+3A_...">...</code></td>
<td>
<p>Additional arguments to provide backward compatibility
with earlier versions of <code>susie_suff_stat</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>susie</code> implements the IBSS algorithm
from Wang et al (2020). The option <code>refine = TRUE</code> implements
an additional step to help reduce problems caused by convergence of
the IBSS algorithm to poor local optima (which is rare in our
experience, but can provide misleading results when it occurs). The
refinement step incurs additional computational expense that
increases with the number of CSs found in the initial run.
</p>
<p>The function <code>susie_suff_stat</code> implements essentially the same
algorithms, but using sufficient statistics. (The statistics are
sufficient for the regression coefficients <code class="reqn">b</code>, but not for the
intercept <code class="reqn">\mu</code>; see below for how the intercept is treated.)
If the sufficient statistics are computed correctly then the
results from <code>susie_suff_stat</code> should be the same as (or very
similar to) <code>susie</code>, although runtimes will differ as
discussed below. The sufficient statistics are the sample
size <code>n</code>, and then the p by p matrix <code class="reqn">X'X</code>, the p-vector
<code class="reqn">X'y</code>, and the sum of squared y values <code class="reqn">y'y</code>, all computed
after centering the columns of <code class="reqn">X</code> and the vector <code class="reqn">y</code> to
have mean 0; these can be computed using <code>compute_suff_stat</code>.
</p>
<p>The handling of the intercept term in <code>susie_suff_stat</code> needs
some additional explanation. Computing the summary data after
centering <code>X</code> and <code>y</code> effectively ensures that the
resulting posterior quantities for <code class="reqn">b</code> allow for an intercept
in the model; however, the actual value of the intercept cannot be
estimated from these centered data. To estimate the intercept term
the user must also provide the column means of <code class="reqn">X</code> and the mean
of <code class="reqn">y</code> (<code>X_colmeans</code> and <code>y_mean</code>). If these are not
provided, they are treated as <code>NA</code>, which results in the
intercept being <code>NA</code>. If for some reason you prefer to have
the intercept be 0 instead of <code>NA</code> then set
<code>X_colmeans = 0,y_mean = 0</code>.
</p>
<p>For completeness, we note that if <code>susie_suff_stat</code> is run on
<code class="reqn">X'X, X'y, y'y</code> computed <em>without</em> centering <code class="reqn">X</code> and
<code class="reqn">y</code>, and with <code>X_colmeans = 0,y_mean = 0</code>, this is
equivalent to <code>susie</code> applied to <code class="reqn">X, y</code> with
<code>intercept = FALSE</code> (although results may differ due to
different initializations of <code>residual_variance</code> and
<code>scaled_prior_variance</code>). However, this usage is not
recommended for for most situations.
</p>
<p>The computational complexity of <code>susie</code> is <code class="reqn">O(npL)</code> per
iteration, whereas <code>susie_suff_stat</code> is <code class="reqn">O(p^2L)</code> per
iteration (not including the cost of computing the sufficient
statistics, which is dominated by the <code class="reqn">O(np^2)</code> cost of
computing <code class="reqn">X'X</code>). Because of the cost of computing <code class="reqn">X'X</code>,
<code>susie</code> will usually be faster. However, if <code class="reqn">n &gt;&gt; p</code>,
and/or if <code class="reqn">X'X</code> is already computed, then
<code>susie_suff_stat</code> may be faster.
</p>


<h3>Value</h3>

<p>A <code>"susie"</code> object with some or all of the following
elements:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>An L by p matrix of posterior inclusion probabilites.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>An L by p matrix of posterior means, conditional on
inclusion.</p>
</td></tr>
<tr><td><code>mu2</code></td>
<td>
<p>An L by p matrix of posterior second moments,
conditional on inclusion.</p>
</td></tr>
<tr><td><code>Xr</code></td>
<td>
<p>A vector of length n, equal to <code>X %*% colSums(alpha
  * mu)</code>.</p>
</td></tr>
<tr><td><code>lbf</code></td>
<td>
<p>log-Bayes Factor for each single effect.</p>
</td></tr>
<tr><td><code>lbf_variable</code></td>
<td>
<p>log-Bayes Factor for each variable and single effect.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Intercept (fixed or estimated).</p>
</td></tr>
<tr><td><code>sigma2</code></td>
<td>
<p>Residual variance (fixed or estimated).</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>Prior variance of the non-zero elements of b, equal to
<code>scaled_prior_variance * var(y)</code>.</p>
</td></tr>
<tr><td><code>elbo</code></td>
<td>
<p>The value of the variational lower bound, or
&ldquo;ELBO&rdquo; (objective function to be maximized), achieved at
each iteration of the IBSS fitting procedure.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>Vector of length n containing the fitted values of
the outcome.</p>
</td></tr>
<tr><td><code>sets</code></td>
<td>
<p>Credible sets estimated from model fit; see
<code><a href="#topic+susie_get_cs">susie_get_cs</a></code> for details.</p>
</td></tr>
<tr><td><code>pip</code></td>
<td>
<p>A vector of length p giving the (marginal) posterior
inclusion probabilities for all p covariates.</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>A vector of univariate z-scores.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>Number of IBSS iterations that were performed.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> indicating whether
the IBSS converged to a solution within the chosen tolerance
level.</p>
</td></tr>
</table>
<p><code>susie_suff_stat</code> returns also outputs:
</p>
<table>
<tr><td><code>XtXr</code></td>
<td>
<p>A p-vector of <code>t(X)</code> times the fitted values,
<code>X %*% colSums(alpha*mu)</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>G. Wang, A. Sarkar, P. Carbonetto and M. Stephens (2020). A simple
new approach to variable selection in regression, with application
to genetic fine-mapping. <em>Journal of the Royal Statistical
Society, Series B</em> <b>82</b>, 1273-1300 doi: <a href="https://doi.org/10.1101/501114">10.1101/501114</a>.
</p>
<p>Y. Zou, P. Carbonetto, G. Wang, G and M. Stephens
(2022). Fine-mapping from summary data with the &ldquo;Sum of
Single Effects&rdquo; model. <em>PLoS Genetics</em> <b>18</b>,
e1010299. doi: <a href="https://doi.org/10.1371/journal.pgen.1010299">10.1371/journal.pgen.1010299</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+susie_get_cs">susie_get_cs</a></code> and other <code>susie_get_*</code>
functions for extracting results; <code><a href="#topic+susie_trendfilter">susie_trendfilter</a></code> for
applying the SuSiE model to non-parametric regression, particularly
changepoint problems, and <code><a href="#topic+susie_rss">susie_rss</a></code> for applying the
SuSiE model when one only has access to limited summary statistics
related to <code class="reqn">X</code> and <code class="reqn">y</code> (typically in genetic applications).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># susie example
set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[1:4] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))
res1 = susie(X,y,L = 10)
susie_get_cs(res1) # extract credible sets from fit
plot(beta,coef(res1)[-1])
abline(a = 0,b = 1,col = "skyblue",lty = "dashed")
plot(y,predict(res1))
abline(a = 0,b = 1,col = "skyblue",lty = "dashed")

# susie_suff_stat example
input_ss = compute_suff_stat(X,y)
res2 = with(input_ss,
            susie_suff_stat(XtX = XtX,Xty = Xty,yty = yty,n = n,
                            X_colmeans = X_colmeans,y_mean = y_mean,L = 10))
plot(coef(res1),coef(res2))
abline(a = 0,b = 1,col = "skyblue",lty = "dashed")

</code></pre>

<hr>
<h2 id='susie_auto'>Attempt at Automating SuSiE for Hard Problems</h2><span id='topic+susie_auto'></span>

<h3>Description</h3>

<p><code>susie_auto</code> is an attempt to automate reliable
running of susie even on hard problems. It implements a three-stage
strategy for each L: first, fit susie with very small residual
error; next, estimate residual error; finally, estimate the prior
variance. If the last step estimates some prior variances to be
zero, stop. Otherwise, double L, and repeat. Initial runs are
performed with relaxed tolerance; the final run is performed using
the default susie tolerance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>susie_auto(
  X,
  y,
  L_init = 1,
  L_max = 512,
  verbose = FALSE,
  init_tol = 1,
  standardize = TRUE,
  intercept = TRUE,
  max_iter = 100,
  tol = 0.01,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="susie_auto_+3A_x">X</code></td>
<td>
<p>An n by p matrix of covariates.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_y">y</code></td>
<td>
<p>The observed responses, a vector of length n.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_l_init">L_init</code></td>
<td>
<p>The initial value of L.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_l_max">L_max</code></td>
<td>
<p>The largest value of L to consider.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_verbose">verbose</code></td>
<td>
<p>If <code>verbose = TRUE</code>, the algorithm's progress,
and a summary of the optimization settings, are printed to the
console.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_init_tol">init_tol</code></td>
<td>
<p>The tolerance to passed to <code>susie</code> during
early runs (set large to shorten the initial runs).</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_standardize">standardize</code></td>
<td>
<p>If <code>standardize = TRUE</code>, standardize the
columns of X to unit variance prior to fitting. Note that
<code>scaled_prior_variance</code> specifies the prior on the
coefficients of X <em>after</em> standardization (if it is
performed). If you do not standardize, you may need to think more
carefully about specifying <code>scaled_prior_variance</code>. Whatever
your choice, the coefficients returned by <code>coef</code> are given for
<code>X</code> on the original input scale. Any column of <code>X</code> that
has zero variance is not standardized.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_intercept">intercept</code></td>
<td>
<p>If <code>intercept = TRUE</code>, the intercept is
fitted; it <code>intercept = FALSE</code>, the intercept is set to
zero. Setting <code>intercept = FALSE</code> is generally not
recommended.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of IBSS iterations to perform.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_tol">tol</code></td>
<td>
<p>A small, non-negative number specifying the convergence
tolerance for the IBSS fitting procedure. The fitting procedure
will halt when the difference in the variational lower bound, or
&ldquo;ELBO&rdquo; (the objective function to be maximized), is
less than <code>tol</code>.</p>
</td></tr>
<tr><td><code id="susie_auto_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+susie">susie</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See <code><a href="#topic+susie">susie</a></code> for a description of return values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+susie">susie</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[1:4] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))
res = susie_auto(X,y)
plot(beta,coef(res)[-1])
abline(a = 0,b = 1,col = "skyblue",lty = "dashed")
plot(y,predict(res))
abline(a = 0,b = 1,col = "skyblue",lty = "dashed")

</code></pre>

<hr>
<h2 id='susie_get_objective'>Inferences From Fitted SuSiE Model</h2><span id='topic+susie_get_objective'></span><span id='topic+susie_get_posterior_mean'></span><span id='topic+susie_get_posterior_sd'></span><span id='topic+susie_get_niter'></span><span id='topic+susie_get_prior_variance'></span><span id='topic+susie_get_residual_variance'></span><span id='topic+susie_get_lfsr'></span><span id='topic+susie_get_posterior_samples'></span><span id='topic+susie_get_cs'></span><span id='topic+susie_get_pip'></span>

<h3>Description</h3>

<p>These functions access basic properties or draw
inferences from a fitted susie model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>susie_get_objective(res, last_only = TRUE, warning_tol = 1e-06)

susie_get_posterior_mean(res, prior_tol = 1e-09)

susie_get_posterior_sd(res, prior_tol = 1e-09)

susie_get_niter(res)

susie_get_prior_variance(res)

susie_get_residual_variance(res)

susie_get_lfsr(res)

susie_get_posterior_samples(susie_fit, num_samples)

susie_get_cs(
  res,
  X = NULL,
  Xcorr = NULL,
  coverage = 0.95,
  min_abs_corr = 0.5,
  dedup = TRUE,
  squared = FALSE,
  check_symmetric = TRUE,
  n_purity = 100,
  use_rfast
)

susie_get_pip(res, prune_by_cs = FALSE, prior_tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="susie_get_objective_+3A_res">res</code></td>
<td>
<p>A susie fit, typically an output from
<code><a href="#topic+susie">susie</a></code> or one of its variants. For
<code>susie_get_pip</code> and <code>susie_get_cs</code>, this may instead be
the posterior inclusion probability matrix, <code>alpha</code>.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_last_only">last_only</code></td>
<td>
<p>If <code>last_only = FALSE</code>, return the ELBO from
all iterations; otherwise return the ELBO from the last iteration
only.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_warning_tol">warning_tol</code></td>
<td>
<p>Warn if ELBO is decreasing by this
tolerance level.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_prior_tol">prior_tol</code></td>
<td>
<p>Filter out effects having estimated prior variance
smaller than this threshold.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_susie_fit">susie_fit</code></td>
<td>
<p>A susie fit, an output from <code><a href="#topic+susie">susie</a></code>.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_num_samples">num_samples</code></td>
<td>
<p>The number of draws from the posterior
distribution.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_x">X</code></td>
<td>
<p>n by p matrix of values of the p variables (covariates) in
n samples. When provided, correlation between variables will be
computed and used to remove CSs whose minimum correlation among
variables is smaller than <code>min_abs_corr</code>.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_xcorr">Xcorr</code></td>
<td>
<p>p by p matrix of correlations between variables
(covariates). When provided, it will be used to remove CSs whose
minimum correlation among variables is smaller than
<code>min_abs_corr</code>.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_coverage">coverage</code></td>
<td>
<p>A number between 0 and 1 specifying desired
coverage of each CS.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_min_abs_corr">min_abs_corr</code></td>
<td>
<p>A &quot;purity&quot; threshold for the CS. Any CS that
contains a pair of variables with correlation less than this
threshold will be filtered out and not reported.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_dedup">dedup</code></td>
<td>
<p>If <code>dedup = TRUE</code>, remove duplicate CSs.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_squared">squared</code></td>
<td>
<p>If <code>squared = TRUE</code>, report min, mean and
median of squared correlation instead of the absolute correlation.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_check_symmetric">check_symmetric</code></td>
<td>
<p>If <code>check_symmetric = TRUE</code>, perform a
check for symmetry of matrix <code>Xcorr</code> when <code>Xcorr</code> is
provided (not <code>NULL</code>).</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_n_purity">n_purity</code></td>
<td>
<p>The maximum number of credible set (CS) variables
used in calculating the correlation (&ldquo;purity&rdquo;)
statistics. When the number of variables included in the CS is
greater than this number, the CS variables are randomly subsampled.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_use_rfast">use_rfast</code></td>
<td>
<p>Use the Rfast package for the purity calculations.
By default <code>use_rfast = TRUE</code> if the Rfast package is
installed.</p>
</td></tr>
<tr><td><code id="susie_get_objective_+3A_prune_by_cs">prune_by_cs</code></td>
<td>
<p>Whether or not to ignore single effects not in
a reported CS when calculating PIP.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>susie_get_objective</code> returns the evidence lower bound
(ELBO) achieved by the fitted susie model and, optionally, at each
iteration of the IBSS fitting procedure.
</p>
<p><code>susie_get_residual_variance</code> returns the (estimated or
fixed) residual variance parameter.
</p>
<p><code>susie_get_prior_variance</code> returns the (estimated or fixed)
prior variance parameters.
</p>
<p><code>susie_get_posterior_mean</code> returns the posterior mean for the
regression coefficients of the fitted susie model.
</p>
<p><code>susie_get_posterior_sd</code> returns the posterior standard
deviation for coefficients of the fitted susie model.
</p>
<p><code>susie_get_niter</code> returns the number of model fitting
iterations performed.
</p>
<p><code>susie_get_pip</code> returns a vector containing the posterior
inclusion probabilities (PIPs) for all variables.
</p>
<p><code>susie_get_lfsr</code> returns a vector containing the average lfsr
across variables for each single-effect, weighted by the posterior
inclusion probability (alpha).
</p>
<p><code>susie_get_posterior_samples</code> returns a list containing the
effect sizes samples and causal status with two components: <code>b</code>,
an <code>num_variables</code> x <code>num_samples</code> matrix of effect
sizes; <code>gamma</code>, an <code>num_variables</code> x <code>num_samples</code>
matrix of causal status random draws.
</p>
<p><code>susie_get_cs</code> returns credible sets (CSs) from a susie fit,
as well as summaries of correlation among the variables included in
each CS. If desired, one can filter out CSs that do not meet a
specified &ldquo;purity&rdquo; threshold; to do this, either <code>X</code> or
<code>Xcorr</code> must be supplied. It returns a list with the following
elements:
</p>
<table>
<tr><td><code>cs</code></td>
<td>
<p>A list in which each list element is a vector containing
the indices of the variables in the CS.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>The nominal coverage specified for each CS.</p>
</td></tr>
<tr><td><code>purity</code></td>
<td>
<p>If <code>X</code> or <code>Xcorr</code> iis provided), the
purity of each CS.</p>
</td></tr>
<tr><td><code>cs_index</code></td>
<td>
<p>If <code>X</code> or <code>Xcorr</code> is provided) the index
(number between 1 and L) of each reported CS in the supplied susie
fit.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[1:4] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))
s = susie(X,y,L = 10)
susie_get_objective(s)
susie_get_objective(s, last_only=FALSE)
susie_get_residual_variance(s)
susie_get_prior_variance(s)
susie_get_posterior_mean(s)
susie_get_posterior_sd(s)
susie_get_niter(s)
susie_get_pip(s)
susie_get_lfsr(s)

</code></pre>

<hr>
<h2 id='susie_init_coef'>Initialize a susie object using regression coefficients</h2><span id='topic+susie_init_coef'></span>

<h3>Description</h3>

<p>Initialize a susie object using regression coefficients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>susie_init_coef(coef_index, coef_value, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="susie_init_coef_+3A_coef_index">coef_index</code></td>
<td>
<p>An L-vector containing the the indices of the
nonzero coefficients.</p>
</td></tr>
<tr><td><code id="susie_init_coef_+3A_coef_value">coef_value</code></td>
<td>
<p>An L-vector containing initial coefficient
estimates.</p>
</td></tr>
<tr><td><code id="susie_init_coef_+3A_p">p</code></td>
<td>
<p>A scalar giving the number of variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with elements <code>alpha</code>, <code>mu</code> and <code>mu2</code>
to be used by <code>susie</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[sample(1:1000,4)] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))

# Initialize susie to ground-truth coefficients.
s = susie_init_coef(which(beta != 0),beta[beta != 0],length(beta))
res = susie(X,y,L = 10,s_init=s)

</code></pre>

<hr>
<h2 id='susie_plot'>SuSiE Plots.</h2><span id='topic+susie_plot'></span><span id='topic+susie_plot_iteration'></span>

<h3>Description</h3>

<p><code>susie_plot</code> produces a per-variable summary of
the SuSiE credible sets. <code>susie_plot_iteration</code> produces a
diagnostic plot for the susie model fitting. For
<code>susie_plot_iteration</code>, several plots will be created if
<code>track_fit = TRUE</code> when calling <code>susie</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>susie_plot(
  model,
  y,
  add_bar = FALSE,
  pos = NULL,
  b = NULL,
  max_cs = 400,
  add_legend = NULL,
  ...
)

susie_plot_iteration(model, L, file_prefix, pos = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="susie_plot_+3A_model">model</code></td>
<td>
<p>A SuSiE fit, typically an output from
<code><a href="#topic+susie">susie</a></code> or one of its variants. For <code>suse_plot</code>,
the susie fit must have <code>model$z</code>, <code>model$PIP</code>, and may
include <code>model$sets</code>. <code>model</code> may also be a vector of
z-scores or PIPs.</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_y">y</code></td>
<td>
<p>A string indicating what to plot: either <code>"z_original"</code> for
z-scores, <code>"z"</code> for z-score derived p-values on (base-10) log-scale, 
<code>"PIP"</code> for posterior inclusion probabilities,
<code>"log10PIP"</code> for posterior inclusion probabiliities on the
(base-10) log-scale. For any other setting, the data are plotted as
is.</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_add_bar">add_bar</code></td>
<td>
<p>If <code>add_bar = TRUE</code>, add horizontal bar to
signals in credible interval.</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_pos">pos</code></td>
<td>
<p>Indices of variables to plot. If <code>pos = NULL</code> all
variables are plotted.</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_b">b</code></td>
<td>
<p>For simulated data, set <code>b = TRUE</code> to highlight
&quot;true&quot; effects (highlights in red).</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_max_cs">max_cs</code></td>
<td>
<p>The largest credible set to display, either based on
purity (set <code>max_cs</code> between 0 and 1), or based on size (set
<code>max_cs &gt; 1</code>).</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_add_legend">add_legend</code></td>
<td>
<p>If <code>add_legend = TRUE</code>, add a legend to
annotate the size and purity of each CS discovered. It can also be
specified as location where legends should be added, e.g.,
<code>add_legend = "bottomright"</code> (default location is
<code>"topright"</code>).</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to
<code><a href="graphics.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_l">L</code></td>
<td>
<p>An integer specifying the number of credible sets to plot.</p>
</td></tr>
<tr><td><code id="susie_plot_+3A_file_prefix">file_prefix</code></td>
<td>
<p>Prefix to path of output plot file. If not
specified, the plot, or plots, will be saved to a temporary
directory generated using <code><a href="base.html#topic+tempdir">tempdir</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns <code>NULL</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+susie_plot_changepoint">susie_plot_changepoint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[sample(1:1000,4)] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))
res = susie(X,y,L = 10)
susie_plot(res,"PIP")
susie_plot(res,"PIP",add_bar = TRUE)
susie_plot(res,"PIP",add_legend = TRUE)
susie_plot(res,"PIP", pos=1:500, add_legend = TRUE)
# Plot selected regions with adjusted x-axis position label
res$genomic_position = 1000 + (1:length(res$pip))
susie_plot(res,"PIP",add_legend = TRUE,
           pos = list(attr = "genomic_position",start = 1000,end = 1500))
# True effects are shown in red.
susie_plot(res,"PIP",b = beta,add_legend = TRUE)

set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[sample(1:1000,4)] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))
res = susie(X,y,L = 10)
susie_plot_iteration(res, L=10)

</code></pre>

<hr>
<h2 id='susie_plot_changepoint'>Plot changepoint data and susie fit using ggplot2</h2><span id='topic+susie_plot_changepoint'></span>

<h3>Description</h3>

<p>Plots original data, y, overlaid with line showing
susie fitted value and shaded rectangles showing credible sets for
changepoint locations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>susie_plot_changepoint(
  s,
  y,
  line_col = "blue",
  line_size = 1.5,
  cs_col = "red"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="susie_plot_changepoint_+3A_s">s</code></td>
<td>
<p>A susie fit generated by
<code>susie_trendfilter(y,order = 0)</code>.</p>
</td></tr>
<tr><td><code id="susie_plot_changepoint_+3A_y">y</code></td>
<td>
<p>An n-vector of observations that are ordered in time or
space (assumed equally-spaced).</p>
</td></tr>
<tr><td><code id="susie_plot_changepoint_+3A_line_col">line_col</code></td>
<td>
<p>Color for the line showing fitted values.</p>
</td></tr>
<tr><td><code id="susie_plot_changepoint_+3A_line_size">line_size</code></td>
<td>
<p>Size of the lines showing fitted values</p>
</td></tr>
<tr><td><code id="susie_plot_changepoint_+3A_cs_col">cs_col</code></td>
<td>
<p>Color of the shaded rectangles showing credible
sets.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 plot object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
mu = c(rep(0,50),rep(1,50),rep(3,50),rep(-2,50),rep(0,300))
y = mu + rnorm(500)
# Here we use a less sensitive tolerance so that the example takes
# less time; in practice you will likely want to use a more stringent
# setting such as tol = 0.001.
s = susie_trendfilter(y,tol = 0.1)

# Produces ggplot with credible sets for changepoints.
susie_plot_changepoint(s,y) 

</code></pre>

<hr>
<h2 id='susie_rss'>Sum of Single Effects (SuSiE) Regression using Summary Statistics</h2><span id='topic+susie_rss'></span>

<h3>Description</h3>

<p><code>susie_rss</code> performs variable selection under a
sparse Bayesian multiple linear regression of <code class="reqn">Y</code> on <code class="reqn">X</code>
using the z-scores from standard univariate regression
of <code class="reqn">Y</code> on each column of <code class="reqn">X</code>, an estimate, <code class="reqn">R</code>, of
the correlation matrix for the columns of <code class="reqn">X</code>, and optionally,
<em>but strongly recommended</em>, the sample size n. See
&ldquo;Details&rdquo; for other ways to call <code>susie_rss</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>susie_rss(
  z,
  R,
  n,
  bhat,
  shat,
  var_y,
  z_ld_weight = 0,
  estimate_residual_variance = FALSE,
  prior_variance = 50,
  check_prior = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="susie_rss_+3A_z">z</code></td>
<td>
<p>p-vector of z-scores.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_r">R</code></td>
<td>
<p>p x p correlation matrix.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_bhat">bhat</code></td>
<td>
<p>Alternative summary data giving the estimated effects
(a vector of length p). This, together with <code>shat</code>, may be
provided instead of <code>z</code>.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_shat">shat</code></td>
<td>
<p>Alternative summary data giving the standard errors of
the estimated effects (a vector of length p). This, together with
<code>bhat</code>, may be provided instead of <code>z</code>.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_var_y">var_y</code></td>
<td>
<p>The sample variance of y, defined as <code class="reqn">y'y/(n-1)</code>.
When the sample variance is not provided, the coefficients
(returned from <code>coef</code>) are computed on the
&ldquo;standardized&rdquo; X, y scale.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_z_ld_weight">z_ld_weight</code></td>
<td>
<p>This parameter is included for backwards
compatibility with previous versions of the function, but it is no
longer recommended to set this to a non-zero value. When
<code>z_ld_weight &gt; 0</code>, the matrix <code>R</code> is adjusted to be
<code>cov2cor((1-w)*R + w*tcrossprod(z))</code>, where <code>w =
z_ld_weight</code>.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_estimate_residual_variance">estimate_residual_variance</code></td>
<td>
<p>The default is FALSE, the
residual variance is fixed to 1 or variance of y. If the in-sample
LD matrix is provided, we recommend setting
<code>estimate_residual_variance = TRUE</code>.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_prior_variance">prior_variance</code></td>
<td>
<p>The prior variance(s) for the non-zero
noncentrality parameterss <code class="reqn">\tilde{b}_l</code>. It is either a scalar,
or a vector of length L. When the <code>susie_suff_stat</code> option
<code>estimate_prior_variance</code> is set to <code>TRUE</code> (which is
highly recommended) this simply provides an initial value for the
prior variance. The default value of 50 is simply intended to be a
large initial value. Note this setting is only relevant when
<code>n</code> is unknown. If <code>n</code> is known, the relevant option is
<code>scaled_prior_variance</code> in <code><a href="#topic+susie_suff_stat">susie_suff_stat</a></code>.</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_check_prior">check_prior</code></td>
<td>
<p>When <code>check_prior = TRUE</code>, it checks if the
estimated prior variance becomes unreasonably large (comparing with
100 * max(abs(z))^2).</p>
</td></tr>
<tr><td><code id="susie_rss_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed to
<code><a href="#topic+susie_suff_stat">susie_suff_stat</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In some applications, particularly genetic applications,
it is desired to fit a regression model (<code class="reqn">Y = Xb + E</code> say,
which we refer to as &quot;the original regression model&quot; or ORM)
without access to the actual values of <code class="reqn">Y</code> and <code class="reqn">X</code>, but
given only some summary statistics. <code>susie_rss</code> assumes
availability of z-scores from standard univariate regression of
<code class="reqn">Y</code> on each column of <code class="reqn">X</code>, and an estimate, <code class="reqn">R</code>, of the
correlation matrix for the columns of <code class="reqn">X</code> (in genetic
applications <code class="reqn">R</code> is sometimes called the &ldquo;LD matrix&rdquo;).
</p>
<p>With the inputs <code>z</code>, <code>R</code> and sample size <code>n</code>,
<code>susie_rss</code> computes PVE-adjusted z-scores <code>z_tilde</code>, and
calls <code>susie_suff_stat</code> with <code>XtX = (n-1)R</code>, <code>Xty =
</code> <code class="reqn">\sqrt{n-1} z_tilde</code>, <code>yty = n-1</code>, <code>n = n</code>. The
output effect estimates are on the scale of <code class="reqn">b</code> in the ORM with
<em>standardized</em> <code class="reqn">X</code> and <code class="reqn">y</code>. When the LD matrix
<code>R</code> and the z-scores <code>z</code> are computed using the same
matrix <code class="reqn">X</code>, the results from <code>susie_rss</code> are same as, or
very similar to, <code>susie</code> with <em>standardized</em> <code class="reqn">X</code> and
<code class="reqn">y</code>.
</p>
<p>Alternatively, if the user provides <code>n</code>, <code>bhat</code> (the
univariate OLS estimates from regressing <code class="reqn">y</code> on each column of
<code class="reqn">X</code>), <code>shat</code> (the standard errors from these OLS
regressions), the in-sample correlation matrix <code class="reqn">R =
cov2cor(crossprod(X))</code>, and the variance of <code class="reqn">y</code>, the results
from <code>susie_rss</code> are same as <code>susie</code> with <code class="reqn">X</code> and
<code class="reqn">y</code>. The effect estimates are on the same scale as the
coefficients <code class="reqn">b</code> in the ORM with <code class="reqn">X</code> and <code class="reqn">y</code>.
</p>
<p>In rare cases in which the sample size, <code class="reqn">n</code>, is unknown,
<code>susie_rss</code> calls <code>susie_suff_stat</code> with <code>XtX = R</code>
and <code>Xty = z</code>, and with <code>residual_variance = 1</code>. The
underlying assumption of performing the analysis in this way is
that the sample size is large (<em>i.e.</em>, infinity), and/or the
effects are small. More formally, this combines the log-likelihood
for the noncentrality parameters, <code class="reqn">\tilde{b} = \sqrt{n} b</code>,
</p>
<p style="text-align: center;"><code class="reqn">L(\tilde{b}; z, R) = -(\tilde{b}'R\tilde{b} -
2z'\tilde{b})/2,</code>
</p>
<p> with the &ldquo;susie prior&rdquo; on
<code class="reqn">\tilde{b}</code>; see <code><a href="#topic+susie">susie</a></code> and Wang <em>et al</em>
(2020) for details. In this case, the effect estimates returned by
<code>susie_rss</code> are on the noncentrality parameter scale.
</p>
<p>The <code>estimate_residual_variance</code> setting is <code>FALSE</code> by
default, which is recommended when the LD matrix is estimated from
a reference panel. When the LD matrix <code>R</code> and the summary
statistics <code>z</code> (or <code>bhat</code>, <code>shat</code>) are computed
using the same matrix <code class="reqn">X</code>, we recommend setting
<code>estimate_residual_variance = TRUE</code>.
</p>


<h3>Value</h3>

<p>A <code>"susie"</code> object with the following
elements:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>An L by p matrix of posterior inclusion probabilites.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>An L by p matrix of posterior means, conditional on
inclusion.</p>
</td></tr>
<tr><td><code>mu2</code></td>
<td>
<p>An L by p matrix of posterior second moments,
conditional on inclusion.</p>
</td></tr>
<tr><td><code>lbf</code></td>
<td>
<p>log-Bayes Factor for each single effect.</p>
</td></tr>
<tr><td><code>lbf_variable</code></td>
<td>
<p>log-Bayes Factor for each variable and single effect.</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>Prior variance of the non-zero elements of b.</p>
</td></tr>
<tr><td><code>elbo</code></td>
<td>
<p>The value of the variational lower bound, or
&ldquo;ELBO&rdquo; (objective function to be maximized), achieved at
each iteration of the IBSS fitting procedure.</p>
</td></tr>
<tr><td><code>sets</code></td>
<td>
<p>Credible sets estimated from model fit; see
<code><a href="#topic+susie_get_cs">susie_get_cs</a></code> for details.</p>
</td></tr>
<tr><td><code>pip</code></td>
<td>
<p>A vector of length p giving the (marginal) posterior
inclusion probabilities for all p covariates.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>Number of IBSS iterations that were performed.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> indicating whether
the IBSS converged to a solution within the chosen tolerance
level.</p>
</td></tr>
</table>


<h3>References</h3>

<p>G. Wang, A. Sarkar, P. Carbonetto and M. Stephens (2020). A simple
new approach to variable selection in regression, with application
to genetic fine-mapping. <em>Journal of the Royal Statistical
Society, Series B</em> <b>82</b>, 1273-1300 doi: <a href="https://doi.org/10.1101/501114">10.1101/501114</a>.
</p>
<p>Y. Zou, P. Carbonetto, G. Wang, G and M. Stephens
(2022). Fine-mapping from summary data with the &ldquo;Sum of
Single Effects&rdquo; model. <em>PLoS Genetics</em> <b>18</b>,
e1010299. doi: <a href="https://doi.org/10.1371/journal.pgen.1010299">10.1371/journal.pgen.1010299</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[1:4] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))

input_ss = compute_suff_stat(X,y,standardize = TRUE)
ss   = univariate_regression(X,y)
R    = with(input_ss,cov2cor(XtX))
zhat = with(ss,betahat/sebetahat)
res  = susie_rss(zhat,R, n=n)

# Toy example illustrating behaviour susie_rss when the z-scores
# are mostly consistent with a non-invertible correlation matrix.
# Here the CS should contain both variables, and two PIPs should
# be nearly the same.
z = c(6,6.01)
R = matrix(1,2,2)
fit = susie_rss(z,R)
print(fit$sets$cs)
print(fit$pip)

# In this second toy example, the only difference is that one
# z-score is much larger than the other. Here we expect that the
# second PIP will be much larger than the first.
z = c(6,7)
R = matrix(1,2,2)
fit = susie_rss(z,R)
print(fit$sets$cs)
print(fit$pip)

</code></pre>

<hr>
<h2 id='susie_trendfilter'>Apply susie to trend filtering (especially changepoint
problems), a type of non-parametric regression.</h2><span id='topic+susie_trendfilter'></span>

<h3>Description</h3>

<p>Fits the non-parametric Gaussian regression model
<code class="reqn">y = mu + e</code>, where the mean <code class="reqn">mu</code> is modelled as <code class="reqn">mu =
  Xb</code>, X is a matrix with columns containing an appropriate basis,
and b is vector with a (sparse) SuSiE prior. In particular, when
<code>order = 0</code>, the jth column of X is a vector with the first j
elements equal to zero, and the remaining elements equal to 1, so
that <code class="reqn">b_j</code> corresponds to the change in the mean of y between
indices j and j+1. For background on trend filtering, see
Tibshirani (2014). See also the &quot;Trend filtering&quot; vignette,
<code>vignette("trend_filtering")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>susie_trendfilter(y, order = 0, standardize = FALSE, use_mad = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="susie_trendfilter_+3A_y">y</code></td>
<td>
<p>An n-vector of observations ordered in time or space
(assumed to be equally spaced).</p>
</td></tr>
<tr><td><code id="susie_trendfilter_+3A_order">order</code></td>
<td>
<p>An integer specifying the order of trend filtering.
The default, <code>order = 0</code>, corresponds to &quot;changepoint&quot;
problems (<em>i.e.</em>, piecewise constant <code class="reqn">mu</code>). Although
<code>order &gt; 0</code> is implemented, we do not recommend its use; in
practice, we have found problems with convergence of the algorithm
to poor local optima, producing unreliable inferences.</p>
</td></tr>
<tr><td><code id="susie_trendfilter_+3A_standardize">standardize</code></td>
<td>
<p>Logical indicating whether to standardize the X
variables (&quot;basis functions&quot;); <code>standardize = FALSE</code> is
recommended as these basis functions already have a natural scale.</p>
</td></tr>
<tr><td><code id="susie_trendfilter_+3A_use_mad">use_mad</code></td>
<td>
<p>Logical indicating whether to use the &quot;median
absolute deviation&quot; (MAD) method to the estimate residual
variance. If <code>use_mad = TRUE</code>, susie is run twice, first by
fixing the residual variance to the MAD value, then a second time,
initialized to the first fit, but with residual variance estimated
the usual way (by maximizing the ELBO). We have found this strategy
typically improves reliability of the results by reducing a
tendency to converge to poor local optima of the ELBO.</p>
</td></tr>
<tr><td><code id="susie_trendfilter_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+susie">susie</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation exploits the special structure of X,
which means that the matrix-vector product <code class="reqn">X^Ty</code> is fast to
compute; in particular, the computation time is <code class="reqn">O(n)</code> rather
than <code class="reqn">O(n^2)</code> if <code>X</code> were formed explicitly. For
implementation details, see the &quot;Implementation of SuSiE trend
filtering&quot; vignette by running
<code>vignette("trendfiltering_derivations")</code>.
</p>


<h3>Value</h3>

<p>A &quot;susie&quot; fit; see <code><a href="#topic+susie">susie</a></code> for details.
</p>


<h3>References</h3>

<p>R. J. Tibshirani (2014). Adaptive piecewise polynomial
estimation via trend filtering. <em>Annals of Statistics</em>
<b>42</b>, 285-323.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
mu = c(rep(0,50),rep(1,50),rep(3,50),rep(-2,50),rep(0,200))
y = mu + rnorm(400)
s = susie_trendfilter(y)
plot(y)
lines(mu,col = 1,lwd = 3)
lines(predict(s),col = 2,lwd = 2)

# Calculate credible sets (indices of y that occur just before
# changepoints).
susie_get_cs(s)

# Plot with credible sets for changepoints.
susie_plot_changepoint(s,y) 

</code></pre>

<hr>
<h2 id='univariate_regression'>Perform Univariate Linear Regression Separately for Columns of X</h2><span id='topic+univariate_regression'></span>

<h3>Description</h3>

<p>This function performs the univariate linear
regression y ~ x separately for each column x of X. Each regression
is implemented using <code>.lm.fit()</code>. The estimated effect size
and stardard error for each variable are outputted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>univariate_regression(
  X,
  y,
  Z = NULL,
  center = TRUE,
  scale = FALSE,
  return_residuals = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="univariate_regression_+3A_x">X</code></td>
<td>
<p>n by p matrix of regressors.</p>
</td></tr>
<tr><td><code id="univariate_regression_+3A_y">y</code></td>
<td>
<p>n-vector of response variables.</p>
</td></tr>
<tr><td><code id="univariate_regression_+3A_z">Z</code></td>
<td>
<p>Optional n by k matrix of covariates to be included in all
regresions. If Z is not <code>NULL</code>, the linear effects of
covariates are removed from y first, and the resulting residuals
are used in place of y.</p>
</td></tr>
<tr><td><code id="univariate_regression_+3A_center">center</code></td>
<td>
<p>If <code>center = TRUE</code>, center X, y and Z.</p>
</td></tr>
<tr><td><code id="univariate_regression_+3A_scale">scale</code></td>
<td>
<p>If <code>scale = TRUE</code>, scale X, y and Z.</p>
</td></tr>
<tr><td><code id="univariate_regression_+3A_return_residuals">return_residuals</code></td>
<td>
<p>Whether or not to output the residuals if Z
is not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two vectors containing the least-squares
estimates of the coefficients (<code>betahat</code>) and their standard
errors (<code>sebetahat</code>). Optionally, and only when a matrix of
covariates <code>Z</code> is provided, a third vector <code>residuals</code>
containing the residuals is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[1:4] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))
res = univariate_regression(X,y)
plot(res$betahat/res$sebetahat)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
