<!DOCTYPE html><html><head><title>Help for package voice</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {voice}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#audio_time'><p>Returns the total time of audio files in seconds</p></a></li>
<li><a href='#diarize'><p>Who spoke when?</p></a></li>
<li><a href='#duration'><p>Duration of sequences</p></a></li>
<li><a href='#enrich_rttm'><p>Enrich RTTM files</p></a></li>
<li><a href='#expand_model'><p>Expand model</p></a></li>
<li><a href='#extract_features'><p>Extract audio features</p></a></li>
<li><a href='#feat_summary'><p>Features summary</p></a></li>
<li><a href='#get_bit'><p>Get bit rate</p></a></li>
<li><a href='#get_dur'><p>Time duration</p></a></li>
<li><a href='#get_left'><p>Get left channel</p></a></li>
<li><a href='#get_right'><p>Get right channel</p></a></li>
<li><a href='#get_samp.rate'><p>Get sample rate</p></a></li>
<li><a href='#get_tbeg'><p>Time beginning</p></a></li>
<li><a href='#get_tdur'><p>Time duration</p></a></li>
<li><a href='#interp'><p>Interpolate vectors</p></a></li>
<li><a href='#interp_df'><p>Inperpolate data frames</p></a></li>
<li><a href='#interp_mc'><p>Interpolate vectors using multicore</p></a></li>
<li><a href='#is_mono'><p>Verify if an audio is mono</p></a></li>
<li><a href='#mozilla_id_path'><p>Sample IDs and paths</p></a></li>
<li><a href='#notes'><p>Assign notes to frequencies</p></a></li>
<li><a href='#notes_freq'><p>Frequencies on Scientific Pitch Notation (SPN)</p></a></li>
<li><a href='#read_rttm'><p>Read RTTM files</p></a></li>
<li><a href='#rm0'><p>Compress zeros.</p></a></li>
<li><a href='#smooth_df'><p>Smooth numeric variables in a data frame</p></a></li>
<li><a href='#splitw'><p>Split Wave</p></a></li>
<li><a href='#tag'><p>Tag a data frame with media information</p></a></li>
<li><a href='#write_list'><p>Writes a list to a path</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Voice Analysis, Speaker Recognition and Mood Inference</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.21</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-20</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Zabala Filipe J. &lt;filipezabala@gmail.com&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/filipezabala/voice">https://github.com/filipezabala/voice</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/filipezabala/voice/issues">https://github.com/filipezabala/voice/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for voice analysis, speaker recognition and mood inference. 
    Gathers 'R' and 'Python' tools to solve problems concerning voice and audio 
    in general.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, R.utils, reticulate, seewave, tibble, tidyselect,
tuneR, wrassp, zoo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gm, knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-19 10:33:52 UTC; fz</td>
</tr>
<tr>
<td>Author:</td>
<td>Zabala Filipe J. [cre, aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-19 11:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='audio_time'>Returns the total time of audio files in seconds</h2><span id='topic+audio_time'></span>

<h3>Description</h3>

<p>Returns the total time of audio files in seconds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audio_time(x, filesRange = NULL, recursive = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="audio_time_+3A_x">x</code></td>
<td>
<p>Either a WAV file or a directory containing WAV files.</p>
</td></tr>
<tr><td><code id="audio_time_+3A_filesrange">filesRange</code></td>
<td>
<p>The desired range of directory files (default: <code>NULL</code>, i.e., all files).</p>
</td></tr>
<tr><td><code id="audio_time_+3A_recursive">recursive</code></td>
<td>
<p>Logical. Should the listing recursively into directories? (default: <code>FALSE</code>) Used by <code>base::list.files</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing file name &lt;chr&gt; and audio time &lt;dbl&gt; in seconds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern &lt;- glob2rx('*.wav'), full.names = TRUE)

# Tibble containing file name and audio time
(at &lt;- voice::audio_time(unique(dirname(path2wav))))
str(at)
</code></pre>

<hr>
<h2 id='diarize'>Who spoke when?</h2><span id='topic+diarize'></span>

<h3>Description</h3>

<p>Diarization of WAV audios.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diarize(
  fromWav,
  toRttm = NULL,
  autoDir = FALSE,
  pycall = "~/miniconda3/envs/pyvoice38/bin/python3.8",
  token = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diarize_+3A_fromwav">fromWav</code></td>
<td>
<p>Either a file or a directory containing WAV files.</p>
</td></tr>
<tr><td><code id="diarize_+3A_torttm">toRttm</code></td>
<td>
<p>A directory to write RTTM files. If the default <code>toRttm = NULL</code> is used, <code>'./voiceAudios/rttm'</code> is created and used.</p>
</td></tr>
<tr><td><code id="diarize_+3A_autodir">autoDir</code></td>
<td>
<p>Logical. Must the directories tree be created? Default: <code>FALSE</code>. See 'Details'.</p>
</td></tr>
<tr><td><code id="diarize_+3A_pycall">pycall</code></td>
<td>
<p>Python call. See <a href="https://github.com/filipezabala/voice">https://github.com/filipezabala/voice</a> for details.</p>
</td></tr>
<tr><td><code id="diarize_+3A_token">token</code></td>
<td>
<p>Access token needed to instantiate pretrained speaker diarization pipeline from pyannote.audio. #1. Visit <a href="https://hf.co/pyannote/speaker-diarization">https://hf.co/pyannote/speaker-diarization</a> and accept user conditions. #2. Visit <a href="https://hf.co/pyannote/segmentation">https://hf.co/pyannote/segmentation</a> and accept user conditions. #3. Visit <a href="https://hf.co/settings/tokens">https://hf.co/settings/tokens</a> to create an access token. More details at <a href="https://github.com/pyannote/pyannote-audio">https://github.com/pyannote/pyannote-audio</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>autoDir = TRUE</code>, the following directories are created: <code>'../mp3'</code>,<code>'../rttm'</code>, <code>'../split'</code> and <code>'../musicxml'</code>. Use <code>getwd()</code> to find the parent directory <code>'../'</code>.
</p>


<h3>Value</h3>

<p>RTTM files in NIST standard. See 'voice::read_rttm'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(voice)

wavDir &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern = glob2rx('*.wav'), full.names = TRUE)

voice::diarize(fromWav = unique(dirname(wavDir)),
toRttm = tempdir(),
token = NULL) # Must enter a token! See documentation.

(rttm &lt;- dir(tempdir(), '.[Rr][Tt][Tt][Mm]$', full.names = TRUE))
file.info(rttm)

## End(Not run)
</code></pre>

<hr>
<h2 id='duration'>Duration of sequences</h2><span id='topic+duration'></span>

<h3>Description</h3>

<p>Duration of sequences
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duration(x, windowShift = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duration_+3A_x">x</code></td>
<td>
<p>A vector containing symbols and <code>NA</code>.</p>
</td></tr>
<tr><td><code id="duration_+3A_windowshift">windowShift</code></td>
<td>
<p>Window shift to duration in ms (default: 5.0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with duration in number of lines/ocurrences (<code>dur_line</code>), milliseconds (<code>dur_ms</code>) and proportional (<code>dur_prop</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)
duration(letters)
duration(c('a','a','a',letters,'z'))

nts &lt;- c('NA','NA','A3','A3','A3','A3','A#3','B3','B3','C4','C4','C4','C4',
'C4','C4','C#4','C4','C4','C4','B3','A#3','NA','NA','NA','NA','NA','NA','NA',
'NA','NA','NA','NA','NA','NA','NA','NA','NA','NA','NA','D4','D4','D4','C#4',
'C#4','C#4','C4','C4','B3','B3','A#3','A#3','A3','A3','G3','G#3','G3','F#3')
duration(nts)
</code></pre>

<hr>
<h2 id='enrich_rttm'>Enrich RTTM files</h2><span id='topic+enrich_rttm'></span>

<h3>Description</h3>

<p>Enrich Rich Transcription Time Marked (RTTM) files obtained from '<code>voice::read_rttm</code>'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>enrich_rttm(listRttm, silence.gap = 0.5, as.tibble = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="enrich_rttm_+3A_listrttm">listRttm</code></td>
<td>
<p>A list containing RTTM files.</p>
</td></tr>
<tr><td><code id="enrich_rttm_+3A_silence.gap">silence.gap</code></td>
<td>
<p>The silence gap (in seconds) between adjacent words in a keyword. Rows with <code>tdur &lt;= silence.gap</code> are removed. (default: <code>0.5</code>)</p>
</td></tr>
<tr><td><code id="enrich_rttm_+3A_as.tibble">as.tibble</code></td>
<td>
<p>Logical. Should it return a tibble?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing either data frames or tibbles obtained from standard RTTM files. See 'voice::read_rttm'.
</p>


<h3>References</h3>

<p><a href="https://www.nist.gov/system/files/documents/itl/iad/mig/KWS15-evalplan-v05.pdf">https://www.nist.gov/system/files/documents/itl/iad/mig/KWS15-evalplan-v05.pdf</a>
</p>


<h3>See Also</h3>

<p><code>voice::read_rttm</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(voice)

url0 &lt;- 'https://raw.githubusercontent.com/filipezabala/voiceAudios/main/rttm/sherlock0.rttm'
destfile0 &lt;- paste0(tempdir(), '/sherlock0.rttm')
download.file(url0, destfile = destfile0)
url1 &lt;- 'https://raw.githubusercontent.com/filipezabala/voiceAudios/main/rttm/sherlock1.rttm'
destfile1 &lt;- paste0(tempdir(), '/sherlock1.rttm')
download.file(url0, destfile = destfile1)

rttm &lt;- voice::read_rttm(dirname(destfile0))
(er &lt;- voice::enrich_rttm(rttm))
class(er)
lapply(er, class)

</code></pre>

<hr>
<h2 id='expand_model'>Expand model</h2><span id='topic+expand_model'></span>

<h3>Description</h3>

<p>Expand model given <code>y</code> and <code>x</code> variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand_model(y, x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expand_model_+3A_y">y</code></td>
<td>
<p>The Y variable.</p>
</td></tr>
<tr><td><code id="expand_model_+3A_x">x</code></td>
<td>
<p>The X variables.</p>
</td></tr>
<tr><td><code id="expand_model_+3A_k">k</code></td>
<td>
<p>Number of additive components.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>char</code> vector containing the expanded models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

expand_model('y', LETTERS[1:4], 1)
expand_model('y', LETTERS[1:4], 2)
expand_model('y', LETTERS[1:4], 3)
expand_model('y', LETTERS[1:4], 4)

# multiple models using apply functions
nx &lt;- 10 # number of X variables to be used
models &lt;- lapply(1:nx, expand_model, y = 'y', x = LETTERS[1:nx])
names(models) &lt;- 1:nx
models
sum(sapply(models, length)) # total of models
</code></pre>

<hr>
<h2 id='extract_features'>Extract audio features</h2><span id='topic+extract_features'></span>

<h3>Description</h3>

<p>Extracts features from WAV audio files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_features(
  x,
  features = c("f0", "fmt", "rf", "rpf", "rcf", "rfc", "mfcc"),
  filesRange = NULL,
  sex = "u",
  windowShift = 10,
  numFormants = 8,
  numcep = 12,
  dcttype = c("t2", "t1", "t3", "t4"),
  fbtype = c("mel", "htkmel", "fcmel", "bark"),
  resolution = 40,
  usecmp = FALSE,
  mc.cores = 1,
  full.names = TRUE,
  recursive = FALSE,
  check.mono = FALSE,
  stereo2mono = FALSE,
  overwrite = FALSE,
  freq = 44100,
  round.to = NULL,
  verbose = FALSE,
  pycall = "~/miniconda3/envs/pyvoice38/bin/python3.8"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_features_+3A_x">x</code></td>
<td>
<p>A vector containing either files or directories of audio files in WAV format.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_features">features</code></td>
<td>
<p>Vector of features to be extracted. (Default: <code>'f0','fmt','rf','rcf','rpf','rfc','mfcc'</code>). The <code>'fmt_praat'</code> feature may take long time processing. The following features may contain a variable number of columns: <code>'cep'</code>, <code>'dft'</code>, <code>'css'</code> and <code>'lps'</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_filesrange">filesRange</code></td>
<td>
<p>The desired range of directory files (Default: <code>NULL</code>, i.e., all files). Should only be used when all the WAV files are in the same folder.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_sex">sex</code></td>
<td>
<p><code>= &lt;code&gt;</code> set sex specific parameters where &lt;code&gt; = <code>'f'</code>[emale], <code>'m'</code>[ale] or <code>'u'</code>[nknown] (Default: <code>'u'</code>). Used as 'gender' by <code>wrassp::ksvF0</code>, <code>wrassp::forest</code> and <code>wrassp::mhsF0</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_windowshift">windowShift</code></td>
<td>
<p><code>= &lt;dur&gt;</code> set analysis window shift to &lt;dur&gt;ation in ms (Default: <code>5.0</code>). Used by <code>wrassp::ksvF0</code>, <code>wrassp::forest</code>, <code>wrassp::mhsF0</code>, <code>wrassp::zcrana</code>, <code>wrassp::rfcana</code>, <code>wrassp::acfana</code>, <code>wrassp::cepstrum</code>, <code>wrassp::dftSpectrum</code>, <code>wrassp::cssSpectrum</code> and <code>wrassp::lpsSpectrum</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_numformants">numFormants</code></td>
<td>
<p><code>= &lt;num&gt;</code> &lt;num&gt;ber of formants (Default: <code>8</code>). Used by <code>wrassp::forest</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_numcep">numcep</code></td>
<td>
<p>Number of Mel-frequency cepstral coefficients (cepstra) to return (Default: <code>12</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_dcttype">dcttype</code></td>
<td>
<p>Type of DCT used. <code>'t1'</code> or <code>'t2'</code>, <code>'t3'</code> for HTK <code>'t4'</code> for feacalc (Default: <code>'t2'</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_fbtype">fbtype</code></td>
<td>
<p>Auditory frequency scale to use: <code>'mel'</code>, <code>'bark'</code>, <code>'htkmel'</code>, <code>'fcmel'</code> (Default: <code>'mel'</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_resolution">resolution</code></td>
<td>
<p><code>= &lt;freq&gt;</code> set FFT length to the smallest value which results in a frequency resolution of &lt;freq&gt; Hz or better (Default: <code>40.0</code>). Used by <code>wrassp::cssSpectrum</code>, <code>wrassp::dftSpectrum</code> and <code>wrassp::lpsSpectrum</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_usecmp">usecmp</code></td>
<td>
<p>Logical. Apply equal-loudness weighting and cube-root compression (PLP instead of LPC) (Default: <code>FALSE</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Number of cores to be used in parallel processing. (Default: <code>1</code>)</p>
</td></tr>
<tr><td><code id="extract_features_+3A_full.names">full.names</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the directory path is prepended to the file names to give a relative file path. If <code>FALSE</code>, the file names (rather than paths) are returned. (Default: <code>TRUE</code>) Used by <code>base::list.files</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_recursive">recursive</code></td>
<td>
<p>Logical. Should the listing recursively into directories? (Default: <code>FALSE</code>) Used by <code>base::list.files</code>.</p>
</td></tr>
<tr><td><code id="extract_features_+3A_check.mono">check.mono</code></td>
<td>
<p>Logical. Check if the WAV file is mono. (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="extract_features_+3A_stereo2mono">stereo2mono</code></td>
<td>
<p>(Experimental) Logical. Should files be converted from stereo to mono? (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="extract_features_+3A_overwrite">overwrite</code></td>
<td>
<p>(Experimental) Logical. Should converted files be overwritten? If not, the file gets the suffix <code>_mono</code>. (Default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="extract_features_+3A_freq">freq</code></td>
<td>
<p>Frequency in Hz to write the converted files when <code>stereo2mono=TRUE</code>. (Default: <code>44100</code>)</p>
</td></tr>
<tr><td><code id="extract_features_+3A_round.to">round.to</code></td>
<td>
<p>Number of decimal places to round to. (Default: <code>NULL</code>)</p>
</td></tr>
<tr><td><code id="extract_features_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Should the running status be showed? (Default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="extract_features_+3A_pycall">pycall</code></td>
<td>
<p>Python call. See <a href="https://github.com/filipezabala/voice">https://github.com/filipezabala/voice</a> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The feature 'df' corresponds to 'formant dispersion' (df2:df8) by Fitch (1997), 'pf' to formant position' (pf1:pf8) by Puts, Apicella &amp; Cárdena (2011), 'rf' to 'formant removal' (rf1:rf8) by Zabala (2023), 'rcf' to 'formant cumulated removal' (rcf2:rcf8) by Zabala (2023) and 'rpf' to 'formant position removal' (rpf2:rpf8) by Zabala (2023).
</p>


<h3>Value</h3>

<p>A Media data frame containing the selected features.
</p>


<h3>References</h3>

<p>Levinson N. (1946). The Wiener (root mean square) error criterion in filter design and prediction. Journal of Mathematics and Physics, 25(1-4), 261–278. (<a href="https://doi.org/10.1002/SAPM1946251261">doi:10.1002/SAPM1946251261</a>)
</p>
<p>Durbin J. (1960). “The fitting of time-series models.” Revue de l’Institut International de Statistique, pp. 233–244. (<a href="https://www.jstor.org/stable/1401322">https://www.jstor.org/stable/1401322</a>)
</p>
<p>Cooley J.W., Tukey J.W. (1965). “An algorithm for the machine calculation of complex Fourier series.” Mathematics of computation, 19(90), 297–301. (<a href="https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/">https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/</a>)
</p>
<p>Wasson D., Donaldson R. (1975). “Speech amplitude and zero crossings for automated identification of human speakers.” IEEE Transactions on Acoustics, Speech, and Signal Processing, 23(4), 390–392. (<a href="https://ieeexplore.ieee.org/document/1162690">https://ieeexplore.ieee.org/document/1162690</a>)
</p>
<p>Allen J. (1977). “Short term spectral analysis, synthesis, and modification by discrete Fourier transform.” IEEE Transactions on Acoustics, Speech, and Signal Processing, 25(3), 235– 238. (<a href="https://ieeexplore.ieee.org/document/1162950">https://ieeexplore.ieee.org/document/1162950</a>)
</p>
<p>Schäfer-Vincent K. (1982). &quot;Significant points: Pitch period detection as a problem of segmentation.&quot; Phonetica, 39(4-5), 241–253. (<a href="https://doi.org/10.1159/000261665">doi:10.1159/000261665</a> )
</p>
<p>Schäfer-Vincent K. (1983). &quot;Pitch period detection and chaining: Method and evaluation.&quot; Phonetica, 40(3), 177–202. (<a href="https://doi.org/10.1159/000261691">doi:10.1159/000261691</a>)
</p>
<p>Ephraim Y., Malah D. (1984). “Speech enhancement using a minimum-mean square error short-time spectral amplitude estimator.” IEEE Transactions on acoustics, speech, and signal processing, 32(6), 1109–1121. (<a href="https://ieeexplore.ieee.org/document/1164453">https://ieeexplore.ieee.org/document/1164453</a>)
</p>
<p>Delsarte P., Genin Y. (1986). “The split Levinson algorithm.” IEEE transactions on acoustics, speech, and signal processing, 34(3), 470–478. (<a href="https://ieeexplore.ieee.org/document/1164830">https://ieeexplore.ieee.org/document/1164830</a>)
</p>
<p>Jackson J.C. (1995). &quot;The Harmonic Sieve: A Novel Application of Fourier Analysis to Machine Learning Theory and Practice.&quot; Technical report, Carnegie-Mellon University Pittsburgh PA Schoo; of Computer Science. (<a href="https://apps.dtic.mil/sti/pdfs/ADA303368.pdf">https://apps.dtic.mil/sti/pdfs/ADA303368.pdf</a>)
</p>
<p>Fitch, W.T. (1997) &quot;Vocal tract length and formant frequency dispersion correlate with body size in rhesus macaques.&quot; J. Acoust. Soc. Am. 102, 1213 – 1222. (<a href="https://doi.org/10.1121/1.421048">doi:10.1121/1.421048</a>)
</p>
<p>Boersma P., van Heuven V. (2001). Praat, a system for doing phonetics by computer. Glot. Int., 5(9/10), 341–347. (<a href="https://www.fon.hum.uva.nl/paul/papers/speakUnspeakPraat_glot2001.pdf">https://www.fon.hum.uva.nl/paul/papers/speakUnspeakPraat_glot2001.pdf</a>)
</p>
<p>Ellis DPW (2005). “PLP and RASTA (and MFCC, and inversion) in Matlab.” Online web resource. (<a href="https://www.ee.columbia.edu/~dpwe/resources/matlab/rastamat/">https://www.ee.columbia.edu/~dpwe/resources/matlab/rastamat/</a>)
</p>
<p>Puts, D.A., Apicella, C.L., Cardenas, R.A. (2012) &quot;Masculine voices signal men's threat potential in forager and industrial societies.&quot; Proc. R. Soc. B Biol. Sci. 279, 601–609. (<a href="https://doi.org/10.1098/rspb.2011.0829">doi:10.1098/rspb.2011.0829</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern = glob2rx('*.wav'), full.names = TRUE)

# minimal usage
M1 &lt;- extract_features(path2wav)
M2 &lt;- extract_features(dirname(path2wav))
identical(M1,M2)
table(basename(M1$wav_path))

# limiting filesRange
M3 &lt;- extract_features(path2wav, filesRange = 3:6)
table(basename(M3$wav_path))
</code></pre>

<hr>
<h2 id='feat_summary'>Features summary</h2><span id='topic+feat_summary'></span>

<h3>Description</h3>

<p>Returns summary measures of 'voice::extract_features'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feat_summary(
  x,
  groupBy = "wav_path",
  wavPath = unique(x$wav_path),
  wavPathName = "wav_path",
  features = "f0",
  filesRange = NULL,
  sex = "u",
  windowShift = 10,
  numFormants = 8,
  numcep = 12,
  dcttype = c("t2", "t1", "t3", "t4"),
  fbtype = c("mel", "htkmel", "fcmel", "bark"),
  resolution = 40,
  usecmp = FALSE,
  mc.cores = 1,
  full.names = TRUE,
  recursive = FALSE,
  check.mono = FALSE,
  stereo2mono = FALSE,
  overwrite = FALSE,
  freq = 44100,
  round.to = 4,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="feat_summary_+3A_x">x</code></td>
<td>
<p>An Extended data frame to be tagged with media information.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_groupby">groupBy</code></td>
<td>
<p>A variable to group the summary measures. The argument must be a character vector. (Default: <code>groupBy = 'wav_path'</code>).</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_wavpath">wavPath</code></td>
<td>
<p>A vector containing the path(s) to WAV files. May be both as <code>dirname</code> or <code>basename</code> formats.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_wavpathname">wavPathName</code></td>
<td>
<p>A string containing the WAV path name. (Default: <code>wavPathName = 'wav_path'</code>).</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_features">features</code></td>
<td>
<p>Vector of features to be extracted. (Default: <code>'f0'</code>).</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_filesrange">filesRange</code></td>
<td>
<p>The desired range of directory files (default: <code>NULL</code>, i.e., all files). Should only be used when all the WAV files are in the same folder.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_sex">sex</code></td>
<td>
<p><code>= &lt;code&gt;</code> set sex specific parameters where &lt;code&gt; = <code>'f'</code>[emale], <code>'m'</code>[ale] or <code>'u'</code>[nknown] (Default: <code>'u'</code>). Used as 'gender' by <code>wrassp::ksvF0</code>, <code>wrassp::forest</code> and <code>wrassp::mhsF0</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_windowshift">windowShift</code></td>
<td>
<p><code>= &lt;dur&gt;</code> set analysis window shift to &lt;dur&gt;ation in ms (Default: <code>5.0</code>). Used by <code>wrassp::ksvF0</code>, <code>wrassp::forest</code>, <code>wrassp::mhsF0</code>, <code>wrassp::zcrana</code>, <code>wrassp::rfcana</code>, <code>wrassp::acfana</code>, <code>wrassp::cepstrum</code>, <code>wrassp::dftSpectrum</code>, <code>wrassp::cssSpectrum</code> and <code>wrassp::lpsSpectrum</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_numformants">numFormants</code></td>
<td>
<p><code>= &lt;num&gt;</code> &lt;num&gt;ber of formants (Default: <code>8</code>). Used by <code>wrassp::forest</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_numcep">numcep</code></td>
<td>
<p>Number of Mel-frequency cepstral coefficients (cepstra) to return (Default: <code>12</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_dcttype">dcttype</code></td>
<td>
<p>Type of DCT used. <code>'t1'</code> or <code>'t2'</code>, <code>'t3'</code> for HTK <code>'t4'</code> for feacalc (Default: <code>'t2'</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_fbtype">fbtype</code></td>
<td>
<p>Auditory frequency scale to use: <code>'mel'</code>, <code>'bark'</code>, <code>'htkmel'</code>, <code>'fcmel'</code> (Default: <code>'mel'</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_resolution">resolution</code></td>
<td>
<p><code>= &lt;freq&gt;</code> set FFT length to the smallest value which results in a frequency resolution of &lt;freq&gt; Hz or better (Default: <code>40.0</code>). Used by <code>wrassp::cssSpectrum</code>, <code>wrassp::dftSpectrum</code> and <code>wrassp::lpsSpectrum</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_usecmp">usecmp</code></td>
<td>
<p>Logical. Apply equal-loudness weighting and cube-root compression (PLP instead of LPC) (Default: <code>FALSE</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Number of cores to be used in parallel processing. (Default: <code>1</code>)</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_full.names">full.names</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the directory path is prepended to the file names to give a relative file path. If <code>FALSE</code>, the file names (rather than paths) are returned. (Default: <code>TRUE</code>). Used by <code>base::list.files</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_recursive">recursive</code></td>
<td>
<p>Logical. Should the listing recursively into directories? (Default: <code>FALSE</code>) Used by <code>base::list.files</code>.</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_check.mono">check.mono</code></td>
<td>
<p>Logical. Check if the WAV file is mono. (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_stereo2mono">stereo2mono</code></td>
<td>
<p>(Experimental) Logical. Should files be converted from stereo to mono? (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_overwrite">overwrite</code></td>
<td>
<p>(Experimental) Logical. Should converted files be overwritten? If not, the file gets the suffix <code>_mono</code>. (Default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_freq">freq</code></td>
<td>
<p>Frequency in Hz to write the converted files when <code>stereo2mono=TRUE</code>. (Default: <code>44100</code>)</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_round.to">round.to</code></td>
<td>
<p>Number of decimal places to round to. (Default: <code>NULL</code>)</p>
</td></tr>
<tr><td><code id="feat_summary_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Should the running status be showed? (Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>filesRange</code> should only be used when all the WAV files are in the same folder.
</p>


<h3>Value</h3>

<p>A tibble data frame containing summarized numeric columns using (1) mean, (2) standard deviation, (3) variation coefficient, (4) median, (5) interquartile range and (6) median absolute deviation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern = glob2rx('*.wav'), full.names = TRUE)

# creating Extended synthetic data
E &lt;- dplyr::tibble(subject_id = c(1,1,1,2,2,2,3,3,3),
wav_path = path2wav)

# minimal usage
feat_summary(E)

# canonical data
feat_summary(E, groupBy = 'subject_id')
</code></pre>

<hr>
<h2 id='get_bit'>Get bit rate</h2><span id='topic+get_bit'></span>

<h3>Description</h3>

<p>Get bit rate from WAV file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_bit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_bit_+3A_x">x</code></td>
<td>
<p>Wave object from 'tuneR::readWave'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Integer indicating the bit rate from a WAV file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern &lt;- glob2rx('*.wav'), full.names = TRUE)

rw &lt;- tuneR::readWave(path2wav[1])
voice::get_bit(rw)

rwl &lt;- lapply(path2wav, tuneR::readWave)
sapply(rwl, voice::get_bit)
</code></pre>

<hr>
<h2 id='get_dur'>Time duration</h2><span id='topic+get_dur'></span>

<h3>Description</h3>

<p>Get time duration from WAV file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_dur(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_dur_+3A_x">x</code></td>
<td>
<p>Wave object from 'tuneR::readWave'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric indicating the time duration in seconds from a WAV file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern &lt;- glob2rx('*.wav'), full.names = TRUE)

rw &lt;- tuneR::readWave(path2wav[1])
voice::get_dur(rw)

rwl &lt;- lapply(path2wav, tuneR::readWave)
sapply(rwl, voice::get_dur)
</code></pre>

<hr>
<h2 id='get_left'>Get left channel</h2><span id='topic+get_left'></span>

<h3>Description</h3>

<p>Get left channel from WAV file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_left(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_left_+3A_x">x</code></td>
<td>
<p>Wave object from 'tuneR::readWave'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector indicating the left channel from a WAV file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern &lt;- glob2rx('*.wav'), full.names = TRUE)

rw &lt;- tuneR::readWave(path2wav[1])
l &lt;- voice::get_left(rw)
head(l)
length(l)
</code></pre>

<hr>
<h2 id='get_right'>Get right channel</h2><span id='topic+get_right'></span>

<h3>Description</h3>

<p>Get right channel from WAV file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_right(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_right_+3A_x">x</code></td>
<td>
<p>Wave object from 'tuneR::readWave'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector indicating the right channel from a WAV file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern &lt;- glob2rx('*.wav'), full.names = TRUE)

rw &lt;- tuneR::readWave(path2wav[1])
r &lt;- voice::get_right(rw)
head(r)
length(r)
</code></pre>

<hr>
<h2 id='get_samp.rate'>Get sample rate</h2><span id='topic+get_samp.rate'></span>

<h3>Description</h3>

<p>Get sample rate from WAV file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_samp.rate(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_samp.rate_+3A_x">x</code></td>
<td>
<p>Wave object from 'tuneR::readWave'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Integer indicating the sample rate from a WAV file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern &lt;- glob2rx('*.wav'), full.names = TRUE)

rw &lt;- tuneR::readWave(path2wav[1])
voice::get_samp.rate(rw)

rwl &lt;- lapply(path2wav, tuneR::readWave)
sapply(rwl, voice::get_samp.rate)
</code></pre>

<hr>
<h2 id='get_tbeg'>Time beginning</h2><span id='topic+get_tbeg'></span>

<h3>Description</h3>

<p>Get time beginning from a data frame in RTTM standard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_tbeg(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_tbeg_+3A_x">x</code></td>
<td>
<p>A data frame in RTTM standard. See 'voice::read_rttm'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector containing the time beginning in seconds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

url0 &lt;- 'https://raw.githubusercontent.com/filipezabala/voiceAudios/main/rttm/sherlock0.rttm'
download.file(url0, destfile = paste0(tempdir(), '/sherlock0.rttm'))

rttm &lt;- voice::read_rttm(tempdir())
(gtb &lt;- voice::get_tbeg(rttm$sherlock0.rttm))
class(gtb)
</code></pre>

<hr>
<h2 id='get_tdur'>Time duration</h2><span id='topic+get_tdur'></span>

<h3>Description</h3>

<p>Get time duration from a data frame in RTTM standard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_tdur(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_tdur_+3A_x">x</code></td>
<td>
<p>A data frame in RTTM standard. See 'voice::read_rttm'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector containing the time duration in seconds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

url0 &lt;- 'https://raw.githubusercontent.com/filipezabala/voiceAudios/main/rttm/sherlock0.rttm'
download.file(url0, destfile = paste0(tempdir(), '/sherlock0.rttm'))

rttm &lt;- voice::read_rttm(tempdir())
(gtd &lt;- voice::get_tdur(rttm$sherlock0.rttm))
class(gtd)
</code></pre>

<hr>
<h2 id='interp'>Interpolate vectors</h2><span id='topic+interp'></span>

<h3>Description</h3>

<p>Interpolate vactors, compressing to <code>compact.to</code> fraction. May remove zeros.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interp(
  y,
  compact.to,
  drop.zeros = FALSE,
  to.data.frame = FALSE,
  round.off = NULL,
  weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interp_+3A_y">y</code></td>
<td>
<p>A vector or time series.</p>
</td></tr>
<tr><td><code id="interp_+3A_compact.to">compact.to</code></td>
<td>
<p>Proportion of remaining points after compaction, between (including) 0 and 1. If equals to 1 and keep.zeros = TRUE, the original vector is presented.</p>
</td></tr>
<tr><td><code id="interp_+3A_drop.zeros">drop.zeros</code></td>
<td>
<p>Logical. Drop repeated zeros? Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="interp_+3A_to.data.frame">to.data.frame</code></td>
<td>
<p>Logical. Convert to data frame? Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="interp_+3A_round.off">round.off</code></td>
<td>
<p>Number of decimal places of the interpolated <code>y</code> Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="interp_+3A_weight">weight</code></td>
<td>
<p>Vector of weights with same length of <code>y</code>. Default: <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of interpolated <code>x</code> and <code>y</code> values with length near to <code>compact.to*length(y)</code>.
</p>


<h3>See Also</h3>

<p><code>rm0</code>, <code>interp_mc</code>, <code>interp_df</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

v1 &lt;- 1:100
(c1 &lt;- interp(v1, compact.to = 0.2))
length(c1$y)
plot(1:100, type = 'l')
points(c1$x, c1$y, col='red')

# with weight
(c2 &lt;- interp(v1, compact.to = 0.2, weight = rev(v1)))
plot(c1$y)
points(c2$y, col = 'red')

(v2 &lt;- c(1:5, rep(0,10), 1:10, rep(0,5), 10:20, rep(0,10)))
length(v2)
interp(v2, 0.1, drop.zeros = TRUE, to.data.frame = FALSE)
interp(v2, 0.1, drop.zeros = TRUE, to.data.frame = TRUE)
interp(v2, 0.2, drop.zeros = TRUE)
interp(v2, 0.2, drop.zeros = FALSE)

(v3 &lt;- c(rep(0,10), 1:20, rep(0,3)))
(c3 &lt;- interp(v3, 1/3, drop.zeros = FALSE, to.data.frame = FALSE))
lapply(c3, length)
plot(v3, type = 'l')
points(c3$x, c3$y, col = 'red')

(v4 &lt;- c(rnorm(1:100)))
(c4 &lt;- interp(v4, 1/4, round.off = 3))
</code></pre>

<hr>
<h2 id='interp_df'>Inperpolate data frames</h2><span id='topic+interp_df'></span>

<h3>Description</h3>

<p>Interpolate data frames using multicore, compressing to <code>compact.to</code> fraction. May remove zeros.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interp_df(
  x,
  compact.to,
  id = colnames(x)[1],
  colnum = NULL,
  drop.x = TRUE,
  drop.zeros = FALSE,
  to.data.frame = TRUE,
  round.off = NULL,
  weight = NULL,
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interp_df_+3A_x">x</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_compact.to">compact.to</code></td>
<td>
<p>Proportion of remaining points after interpolation. If equals to 1 and keep.zeros = TRUE, the original vector is presented.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_id">id</code></td>
<td>
<p>The identification column. Default: <code>colname</code> of the first column of <code>x</code>.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_colnum">colnum</code></td>
<td>
<p>A <code>char</code> vector indicating the numeric colnames. If <code>NULL</code>, uses the columns of the <code>numeric</code> class.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_drop.x">drop.x</code></td>
<td>
<p>Logical. Drop columns containing .x? Default: <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_drop.zeros">drop.zeros</code></td>
<td>
<p>Logical. Drop repeated zeros or keep 1 zero per null set? Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_to.data.frame">to.data.frame</code></td>
<td>
<p>Logical. Should return a data frame? If <code>FALSE</code> returns a list. Default: <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_round.off">round.off</code></td>
<td>
<p>Number of decimal places of the interpolated <code>y</code>. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_weight">weight</code></td>
<td>
<p>Vector of weights with same length of <code>y</code>. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="interp_df_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of cores to mclapply. Default: <code>1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of interpolated values with nrow near to <code>compact.to*length(x)</code>.
</p>


<h3>See Also</h3>

<p><code>interp</code>, <code>interp_mc</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern = glob2rx('*.wav'), full.names = TRUE)

# getting Media data frame via lean call
M &lt;- extract_features(dirname(path2wav), features = c('f0','fmt'),
mc.cores = 1, verbose = FALSE)


(cM.df &lt;- interp_df(M[,-(1:2)], 0.1, mc.cores = 1))
(cM.df2 &lt;- interp_df(M[,-(1:2)], 0.1, drop.x = FALSE, mc.cores = 1))

dim(M)
dim(cM.df)
dim(cM.df2)
(cM.list &lt;- interp_df(M[,-(1:2)], 0.1, to.data.frame = FALSE, mc.cores = 1))

</code></pre>

<hr>
<h2 id='interp_mc'>Interpolate vectors using multicore</h2><span id='topic+interp_mc'></span>

<h3>Description</h3>

<p>Interpolate vectors using multicore
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interp_mc(
  y,
  compact.to,
  drop.zeros = FALSE,
  to.data.frame = FALSE,
  round.off = NULL,
  weight = NULL,
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interp_mc_+3A_y">y</code></td>
<td>
<p>A numeric vector, matrix or data frame.</p>
</td></tr>
<tr><td><code id="interp_mc_+3A_compact.to">compact.to</code></td>
<td>
<p>Proportion of remaining points after compression. If equals to 1 and keep.zeros = TRUE, the original vector is presented.</p>
</td></tr>
<tr><td><code id="interp_mc_+3A_drop.zeros">drop.zeros</code></td>
<td>
<p>Logical. Drop repeated zeros? Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="interp_mc_+3A_to.data.frame">to.data.frame</code></td>
<td>
<p>Logical. Convert to data frame? Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="interp_mc_+3A_round.off">round.off</code></td>
<td>
<p>Number of decimal places of the interpolated <code>y</code>. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="interp_mc_+3A_weight">weight</code></td>
<td>
<p>Vector of weights with same length of <code>y</code>. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="interp_mc_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of cores to mclapply. Default: <code>1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of x and y convoluted values with length near to <code>compact.to*length(y)</code>.
</p>


<h3>See Also</h3>

<p><code>rm0</code>, <code>interp</code>, <code>interp_df</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)
# Same result of interp() function if x is a vector
interp(1:100, compact.to = 0.1, drop.zeros = TRUE, to.data.frame = FALSE)
interp_mc(1:100, compact.to = 0.1, drop.zeros = TRUE, to.data.frame = FALSE)

interp(1:100, compact.to = 0.1, drop.zeros = TRUE, to.data.frame = TRUE)
interp_mc(1:100, compact.to = 0.1, drop.zeros = TRUE, to.data.frame = TRUE)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern = glob2rx('*.wav'), full.names = TRUE)


# getting Media data frame
M &lt;- voice::extract_features(dirname(path2wav), mc.cores = 1, verbose = FALSE)

M.num &lt;- M[,-(1:3)]
nrow(M.num)
cm1 &lt;- interp_mc(M.num, compact.to = 0.1, drop.zeros = TRUE,
to.data.frame = FALSE, mc.cores = 1)
names(cm1)
lapply(cm1$f0, length)

</code></pre>

<hr>
<h2 id='is_mono'>Verify if an audio is mono</h2><span id='topic+is_mono'></span>

<h3>Description</h3>

<p>Verify if an audio is mono
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_mono(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_mono_+3A_x">x</code></td>
<td>
<p>Path to WAV audio file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Logical. 'TRUE' indicates a mono (one-channel) file. 'FALSE' indicates a non-mono (two-channel) file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern = glob2rx('*.wav'), full.names = TRUE)

is_mono(path2wav[1])
sapply(path2wav, is_mono)
</code></pre>

<hr>
<h2 id='mozilla_id_path'>Sample IDs and paths</h2><span id='topic+mozilla_id_path'></span>

<h3>Description</h3>

<p>A dataset containing sample IDs and paths from Ardila et al (2019)
'Common voice: A massively-multilingual speech corpus',
used in Zabala (2023) 'voice: new approaches to audio analysis'.
The considered sample contains 34,425 rows associated with
838 IDs (p_s = 2.4%).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mozilla_id_path
</code></pre>


<h3>References</h3>

<p>Ardila R, Branson M, Davis K, Henretty M, Kohler M, Meyer J, Morais R, Saunders L, Tyers FM, Weber G (2019). &quot;Common voice: A massively-multilingual speech corpus.&quot; arXiv preprint <a href="https://arxiv.org/abs/1912.06670v2">arXiv:1912.06670</a>. URL <a href="https://arxiv.org/abs/1912.06670">https://arxiv.org/abs/1912.06670</a>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract_features">extract_features</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)
mozilla_id_path
</code></pre>

<hr>
<h2 id='notes'>Assign notes to frequencies</h2><span id='topic+notes'></span>

<h3>Description</h3>

<p>Returns a vector of notes for equal-tempered scale, A4 = 440 Hz.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>notes(x, method = "spn", moving.average = FALSE, k = 11)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="notes_+3A_x">x</code></td>
<td>
<p>Numeric vector of frequencies in Hz.</p>
</td></tr>
<tr><td><code id="notes_+3A_method">method</code></td>
<td>
<p>Method of specifying musical pitch. (Default: <code>spn</code>, i.e., Scientific Pitch Notation).</p>
</td></tr>
<tr><td><code id="notes_+3A_moving.average">moving.average</code></td>
<td>
<p>Logical. Must apply moving average? (Default: <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="notes_+3A_k">k</code></td>
<td>
<p>Integer width of the rolling window used if moving.average is TRUE. (Default: <code>11</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The symbol '#' is being used to represent a sharp note, the higher
in pitch by one semitone on Scientific Pitch Notation (SPN).
</p>


<h3>Value</h3>

<p>A vector containing the notes for equal-tempered scale, A4 = 440 Hz. When &lsquo;method = &rsquo;spn'&lsquo; the vector is of class &rsquo;ordered factor'. When &lsquo;method = &rsquo;octave'&lsquo; the vector is of class &rsquo;factor'.  When &lsquo;method = &rsquo;midi'&lsquo; the vector is of class &rsquo;integer'.
</p>


<h3>References</h3>

<p><a href="https://pages.mtu.edu/~suits/notefreqs.html">https://pages.mtu.edu/~suits/notefreqs.html</a>
</p>


<h3>See Also</h3>

<p><code>notes_freq</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)
notes(c(220,440,880))
notes(c(220,440,880), method = 'octave')
notes(c(220,440,880), method = 'midi')
</code></pre>

<hr>
<h2 id='notes_freq'>Frequencies on Scientific Pitch Notation (SPN)</h2><span id='topic+notes_freq'></span>

<h3>Description</h3>

<p>Returns a tibble of frequencies on Scientific Pitch Notation (SPN) for equal-tempered scale, A4 = 440 Hz.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>notes_freq()
</code></pre>


<h3>Details</h3>

<p>The symbol '#' is being used to represent a sharp note, the higher in pitch by one semitone. The SPN is also known as American Standard Pitch Notation (ASPN) or International Pitch Notation (IPN).
</p>


<h3>Value</h3>

<p>A tibble with frequencies for equal-tempered scale, A4 = 440 Hz.
</p>


<h3>References</h3>

<p><a href="https://pages.mtu.edu/~suits/notefreqs.html">https://pages.mtu.edu/~suits/notefreqs.html</a>
</p>


<h3>See Also</h3>

<p><code>notes</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)
notes_freq()
</code></pre>

<hr>
<h2 id='read_rttm'>Read RTTM files</h2><span id='topic+read_rttm'></span>

<h3>Description</h3>

<p>Read Rich Transcription Time Marked (RTTM) files in <code>fromRttm</code> directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_rttm(fromRttm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_rttm_+3A_fromrttm">fromRttm</code></td>
<td>
<p>A directory/folder containing RTTM files.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Rich Transcription Time Marked (RTTM) files are space-delimited text files containing one turn per line defined by NIST - National Institute of Standards and Technology. Each line containing ten fields:
</p>
<p><code>type</code> Type: segment type; should always by SPEAKER.
</p>
<p><code>file</code> File ID: file name; basename of the recording minus extension (e.g., rec1_a).
</p>
<p><code>chnl</code> Channel ID: channel (1-indexed) that turn is on; should always be 1.
</p>
<p><code>tbeg</code> Turn Onset &ndash; onset of turn in seconds from beginning of recording.
</p>
<p><code>tdur</code> Turn Duration &ndash; duration of turn in seconds.
</p>
<p><code>ortho</code> Orthography Field &ndash; should always by &lt;NA&gt;.
</p>
<p><code>stype</code> Speaker Type &ndash; should always be &lt;NA&gt;.
</p>
<p><code>name</code> Speaker Name &ndash; name of speaker of turn; should be unique within scope of each file.
</p>
<p><code>conf</code> Confidence Score &ndash; system confidence (probability) that information is correct; should always be &lt;NA&gt;.
</p>
<p><code>slat</code> Signal Lookahead Time &ndash; should always be &lt;NA&gt;.
</p>


<h3>Value</h3>

<p>A list containing data frames obtained from standard RTTM files. See 'Details'.
</p>


<h3>References</h3>

<p><a href="https://www.nist.gov/system/files/documents/itl/iad/mig/KWS15-evalplan-v05.pdf">https://www.nist.gov/system/files/documents/itl/iad/mig/KWS15-evalplan-v05.pdf</a>
</p>


<h3>See Also</h3>

<p><code>voice::enrich_rttm</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

url0 &lt;- 'https://raw.githubusercontent.com/filipezabala/voiceAudios/main/rttm/sherlock0.rttm'
download.file(url0, destfile = paste0(tempdir(), '/sherlock0.rttm'))
url1 &lt;- 'https://raw.githubusercontent.com/filipezabala/voiceAudios/main/rttm/sherlock1.rttm'
download.file(url0, destfile = paste0(tempdir(), '/sherlock1.rttm'))

(rttm &lt;- voice::read_rttm(tempdir()))
class(rttm)
lapply(rttm, class)
</code></pre>

<hr>
<h2 id='rm0'>Compress zeros.</h2><span id='topic+rm0'></span>

<h3>Description</h3>

<p>Transforms <code>n</code> sets of <code>m&gt;n</code> zeros (alternated with sets of non zeros) into <code>n</code> sets of <code>n</code> zeros.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rm0(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rm0_+3A_y">y</code></td>
<td>
<p>A vector or time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with n zeros.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

(v0 &lt;- c(1:20,rep(0,10)))
(r0 &lt;- rm0(v0))
length(v0)
length(r0)
sum(v0 == 0)

(v1 &lt;- c(rep(0,10),1:20))
(r1 &lt;- rm0(v1))
length(r1)

(v2 &lt;- rep(0,10))
(r2 &lt;- rm0(v2))
length(r2)

(v3 &lt;- c(0:10))
(r3 &lt;- rm0(v3))
length(r3)

(v4 &lt;- c(rep(0,10), 1:10, rep(0,5), 10:20, rep(0,10)))
(r4 &lt;- rm0(v4))
length(r4)
sum(v4 == 0)
</code></pre>

<hr>
<h2 id='smooth_df'>Smooth numeric variables in a data frame</h2><span id='topic+smooth_df'></span>

<h3>Description</h3>

<p>Smooth numeric variables in a data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smooth_df(x, k = 11, id = colnames(x)[1], colnum = NULL, mc.cores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth_df_+3A_x">x</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="smooth_df_+3A_k">k</code></td>
<td>
<p>Integer width of the rolling window. Default: <code>11</code>.</p>
</td></tr>
<tr><td><code id="smooth_df_+3A_id">id</code></td>
<td>
<p>The identification column. Default: <code>colname</code> of the first column of <code>x</code>.</p>
</td></tr>
<tr><td><code id="smooth_df_+3A_colnum">colnum</code></td>
<td>
<p>A <code>char</code> vector indicating the numeric colnames. If <code>NULL</code>, uses the columns of the <code>numeric</code> class.</p>
</td></tr>
<tr><td><code id="smooth_df_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of cores to mclapply. By default uses <code>1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of interpolated values with length near to <code>compact.to*length(x)</code>.
</p>


<h3>See Also</h3>

<p><code>extract_features</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern = glob2rx('*.wav'), full.names = TRUE)

# minimal usage
M &lt;- extract_features(path2wav, features = c('f0', 'fmt'))
(Ms &lt;- smooth_df(M[-(1:2)]))
dim(M)
dim(Ms)
</code></pre>

<hr>
<h2 id='splitw'>Split Wave</h2><span id='topic+splitw'></span>

<h3>Description</h3>

<p>Split WAV files either in <code>fromWav</code> directory or using (same names) RTTM files/subdirectories as guidance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitw(
  fromWav,
  fromRttm = NULL,
  toSplit = NULL,
  autoDir = FALSE,
  subDir = FALSE,
  output = "wave",
  filesRange = NULL,
  full.names = TRUE,
  recursive = FALSE,
  silence.gap = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitw_+3A_fromwav">fromWav</code></td>
<td>
<p>Either WAV file or directory containing WAV files.</p>
</td></tr>
<tr><td><code id="splitw_+3A_fromrttm">fromRttm</code></td>
<td>
<p>Either RTTM file or directory containing RTTM files. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="splitw_+3A_tosplit">toSplit</code></td>
<td>
<p>A directory to write generated files. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="splitw_+3A_autodir">autoDir</code></td>
<td>
<p>Logical. Must the directories tree be created? Default: <code>FALSE</code>. See 'Details'.</p>
</td></tr>
<tr><td><code id="splitw_+3A_subdir">subDir</code></td>
<td>
<p>Logical. Must the splitted files be placed in subdirectories? Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="splitw_+3A_output">output</code></td>
<td>
<p>Character string, the class of the object to return, either 'wave' or 'list'.</p>
</td></tr>
<tr><td><code id="splitw_+3A_filesrange">filesRange</code></td>
<td>
<p>The desired range of directory files (default: <code>NULL</code>, i.e., all files). Must be TRUE only if <code>fromWav</code> is a directory.</p>
</td></tr>
<tr><td><code id="splitw_+3A_full.names">full.names</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the directory path is prepended to the file names to give a relative file path. If <code>FALSE</code>, the file names (rather than paths) are returned. (default: <code>TRUE</code>) Used by <code>base::list.files</code>.</p>
</td></tr>
<tr><td><code id="splitw_+3A_recursive">recursive</code></td>
<td>
<p>Logical. Should the listing recursively into directories? (default: <code>FALSE</code>) Used by <code>base::list.files</code>. Inactive if <code>fromWav</code> is a file.</p>
</td></tr>
<tr><td><code id="splitw_+3A_silence.gap">silence.gap</code></td>
<td>
<p>The silence gap (in seconds) between adjacent words in a keyword. Rows with <code>tdur &lt;= silence.gap</code> are removed. (default: <code>0.5</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>autoDir = TRUE</code>, the following directories are created: <code>'../mp3'</code>,<code>'../rttm'</code>, <code>'../split'</code> and <code>'../musicxml'</code>. Use <code>getwd()</code> to find the parent directory <code>'../'</code>.
</p>


<h3>Value</h3>

<p>Splited audio files according to the correspondent RTTM file(s). See '<code>voice::diarize</code>'.
</p>


<h3>See Also</h3>

<p><code>voice::diarize</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(voice)

urlWav &lt;- 'https://raw.githubusercontent.com/filipezabala/voiceAudios/main/wav/sherlock0.wav'
destWav &lt;- paste0(tempdir(), '/sherlock0.wav')
download.file(urlWav, destfile = destWav)

urlRttm &lt;- 'https://raw.githubusercontent.com/filipezabala/voiceAudios/main/rttm/sherlock0.rttm'
destRttm &lt;- paste0(tempdir(), '/sherlock0.rttm')
download.file(urlRttm, destfile = destRttm)

splitDir &lt;- paste0(tempdir(), '/split')
dir.create(splitDir)
splitw(destWav, fromRttm = destRttm, toSplit = splitDir)

dir(splitDir)

## End(Not run)
</code></pre>

<hr>
<h2 id='tag'>Tag a data frame with media information</h2><span id='topic+tag'></span>

<h3>Description</h3>

<p>Tag a data frame with media information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tag(
  x,
  groupBy = "wav_path",
  wavPath = unique(x$wav_path),
  wavPathName = "wav_path",
  tags = c("feat_summary"),
  sortByGroupBy = TRUE,
  filesRange = NULL,
  features = "f0",
  sex = "u",
  windowShift = 5,
  numFormants = 8,
  numcep = 12,
  dcttype = c("t2", "t1", "t3", "t4"),
  fbtype = c("mel", "htkmel", "fcmel", "bark"),
  resolution = 40,
  usecmp = FALSE,
  mc.cores = 1,
  full.names = TRUE,
  recursive = FALSE,
  check.mono = FALSE,
  stereo2mono = FALSE,
  overwrite = FALSE,
  freq = 44100,
  round.to = 4,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tag_+3A_x">x</code></td>
<td>
<p>An Extended data frame to be tagged with media information. See references.</p>
</td></tr>
<tr><td><code id="tag_+3A_groupby">groupBy</code></td>
<td>
<p>A variable to group the summary measures. The argument must be a character vector. (Default: <code>groupBy = 'wav_path'</code>).</p>
</td></tr>
<tr><td><code id="tag_+3A_wavpath">wavPath</code></td>
<td>
<p>A vector containing the path(s) to WAV files. May be both as <code>dirname</code> or <code>basename</code> formats.</p>
</td></tr>
<tr><td><code id="tag_+3A_wavpathname">wavPathName</code></td>
<td>
<p>A string containing the WAV path name. (Default: <code>wavPathName = 'wav_path'</code>).</p>
</td></tr>
<tr><td><code id="tag_+3A_tags">tags</code></td>
<td>
<p>Tags to be added to <code>x</code>. See Details. (Default: <code>'feat_summary'</code>).</p>
</td></tr>
<tr><td><code id="tag_+3A_sortbygroupby">sortByGroupBy</code></td>
<td>
<p>Logical. Should the function sort the Extended data frame <code>x</code> by <code>gropuBy</code>? (Default: <code>sortByGroupBy = TRUE</code>).</p>
</td></tr>
<tr><td><code id="tag_+3A_filesrange">filesRange</code></td>
<td>
<p>The desired range of directory files. Should only be used when all the WAV files are in the same folder. (Default: <code>NULL</code>, i.e., all files).</p>
</td></tr>
<tr><td><code id="tag_+3A_features">features</code></td>
<td>
<p>Vector of features to be extracted. (Default: <code>'f0'</code>).</p>
</td></tr>
<tr><td><code id="tag_+3A_sex">sex</code></td>
<td>
<p><code>= &lt;code&gt;</code> set sex specific parameters where &lt;code&gt; = <code>'f'</code>[emale], <code>'m'</code>[ale] or <code>'u'</code>[nknown] (default: <code>'u'</code>). Used as 'gender' by <code>wrassp::ksvF0</code>, <code>wrassp::forest</code> and <code>wrassp::mhsF0</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_windowshift">windowShift</code></td>
<td>
<p><code>= &lt;dur&gt;</code> set analysis window shift to &lt;dur&gt;ation in ms (default: 5.0). Used by <code>wrassp::ksvF0</code>, <code>wrassp::forest</code>, <code>wrassp::mhsF0</code>, <code>wrassp::zcrana</code>, <code>wrassp::rfcana</code>, <code>wrassp::acfana</code>, <code>wrassp::cepstrum</code>, <code>wrassp::dftSpectrum</code>, <code>wrassp::cssSpectrum</code> and <code>wrassp::lpsSpectrum</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_numformants">numFormants</code></td>
<td>
<p><code>= &lt;num&gt;</code> &lt;num&gt;ber of formants (Default: <code>8</code>). Used by <code>wrassp::forest</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_numcep">numcep</code></td>
<td>
<p>Number of Mel-frequency cepstral coefficients (cepstra) to return (Default: <code>12</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_dcttype">dcttype</code></td>
<td>
<p>Type of DCT used. <code>'t1'</code> or <code>'t2'</code>, <code>'t3'</code> for HTK <code>'t4'</code> for feacalc (Default: <code>'t2'</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_fbtype">fbtype</code></td>
<td>
<p>Auditory frequency scale to use: <code>'mel'</code>, <code>'bark'</code>, <code>'htkmel'</code>, <code>'fcmel'</code> (Default: <code>'mel'</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_resolution">resolution</code></td>
<td>
<p><code>= &lt;freq&gt;</code> set FFT length to the smallest value which results in a frequency resolution of &lt;freq&gt; Hz or better (Default: <code>40.0</code>). Used by <code>wrassp::cssSpectrum</code>, <code>wrassp::dftSpectrum</code> and <code>wrassp::lpsSpectrum</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_usecmp">usecmp</code></td>
<td>
<p>Logical. Apply equal-loudness weighting and cube-root compression (PLP instead of LPC) (Default: <code>FALSE</code>). Used by <code>tuneR::melfcc</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Number of cores to be used in parallel processing. (Default: <code>1</code>)</p>
</td></tr>
<tr><td><code id="tag_+3A_full.names">full.names</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the directory path is prepended to the file names to give a relative file path. If <code>FALSE</code>, the file names (rather than paths) are returned. (Default: <code>TRUE</code>) Used by <code>base::list.files</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_recursive">recursive</code></td>
<td>
<p>Logical. Should the listing recursively into directories? (Default: <code>FALSE</code>) Used by <code>base::list.files</code>.</p>
</td></tr>
<tr><td><code id="tag_+3A_check.mono">check.mono</code></td>
<td>
<p>Logical. Check if the WAV file is mono. (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="tag_+3A_stereo2mono">stereo2mono</code></td>
<td>
<p>(Experimental) Logical. Should files be converted from stereo to mono? (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="tag_+3A_overwrite">overwrite</code></td>
<td>
<p>(Experimental) Logical. Should converted files be overwritten? If not, the file gets the suffix <code>_mono</code>. (Default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="tag_+3A_freq">freq</code></td>
<td>
<p>Frequency in Hz to write the converted files when <code>stereo2mono=TRUE</code>. (Default: <code>44100</code>)</p>
</td></tr>
<tr><td><code id="tag_+3A_round.to">round.to</code></td>
<td>
<p>Number of decimal places to round to. (Default: <code>NULL</code>)</p>
</td></tr>
<tr><td><code id="tag_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Should the running status be showed? (Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>filesRange</code> should only be used when all the WAV files are in the same folder.
</p>


<h3>Value</h3>

<p>A tibble data frame containing summarized numeric columns using (1) mean, (2) standard deviation, (3) variation coefficient, (4) median, (5) interquartile range and (6) median absolute deviation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(voice)

# get path to audio file
path2wav &lt;- list.files(system.file('extdata', package = 'wrassp'),
pattern = glob2rx('*.wav'), full.names = TRUE)

# creating Extended synthetic data
E &lt;- dplyr::tibble(subject_id = c(1,1,1,2,2,2,3,3,3),
wav_path = path2wav)
E

# minimal usage
tag(E)

# canonical data
tag(E, groupBy = 'subject_id')

# limiting filesRange
tag(E, filesRange = 3:6)

# more features
Et &lt;- tag(E, features = c('f0', 'fmt', 'rf', 'rcf', 'rpf', 'rfc', 'mfcc'),
groupBy = 'subject_id')
Et
str(Et)
</code></pre>

<hr>
<h2 id='write_list'>Writes a list to a path</h2><span id='topic+write_list'></span>

<h3>Description</h3>

<p>Writes a list to a path
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_list(x, path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_list_+3A_x">x</code></td>
<td>
<p>A list.</p>
</td></tr>
<tr><td><code id="write_list_+3A_path">path</code></td>
<td>
<p>A full path to file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A file named 'list.txt' in 'path'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(voice)

pts &lt;- list(x = cars[,1], y = cars[,2])
listFile &lt;- paste0(tempdir(), '/list.txt')
voice::write_list(pts, listFile)
file.info(listFile)
system(paste0('head ', listFile))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
