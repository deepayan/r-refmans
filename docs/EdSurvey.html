<!DOCTYPE html><html><head><title>Help for package EdSurvey</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EdSurvey}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EdSurvey-package'><p>Analysis of NCES Education Survey and Assessment Data</p></a></li>
<li><a href='#achievementLevels'><p>Achievement Levels</p></a></li>
<li><a href='#as.data.frame'><p>Coerce to a Data Frame</p></a></li>
<li><a href='#cbind.light.edsurvey.data.frame'><p>Combine R Objects by Rows or Columns</p></a></li>
<li><a href='#checkIdVar'><p>Give warning if idVar is null on on light edsurvey dataframe.</p></a></li>
<li><a href='#checkPsuStrata'><p>Give error if Strata and PSU var not present on light edsurvey data frame.</p></a></li>
<li><a href='#contourPlot'><p>Overlaid Scatter and Contour Plots</p></a></li>
<li><a href='#cor.sdf'><p>Bivariate Correlation</p></a></li>
<li><a href='#dim.edsurvey.data.frame'><p>Dimensions of an edsurvey.data.frame or an edsurvey.data.frame.list</p></a></li>
<li><a href='#DoFCorrection'><p>Degrees of Freedom</p></a></li>
<li><a href='#download_ePIRLS'><p>Download and Unzip ePIRLS Files</p></a></li>
<li><a href='#downloadCivEDICCS'><p>Instructions for Downloading and Unzipping CivED or ICCS Files</p></a></li>
<li><a href='#downloadECLS_K'><p>Download and Unzip ECLS_K Files</p></a></li>
<li><a href='#downloadELS'><p>Download and Unzip ELS Files</p></a></li>
<li><a href='#downloadHSLS'><p>Download and Unzip HSLS Files</p></a></li>
<li><a href='#downloadICILS'><p>Instructions for Downloading and Unzipping ICILS Files</p></a></li>
<li><a href='#downloadNHES'><p>Instructions for Downloading and Unzipping NHES Files</p></a></li>
<li><a href='#downloadPIAAC'><p>Download and Unzip PIAAC Files</p></a></li>
<li><a href='#downloadPIRLS'><p>Download and Unzip PIRLS Files</p></a></li>
<li><a href='#downloadPISA'><p>Download and Unzip PISA Files</p></a></li>
<li><a href='#downloadPISA_YAFS'><p>Instructions for Downloading and Unzipping PISA YAFS Files</p></a></li>
<li><a href='#downloadSSOCS'><p>Instructions for Downloading and Unzipping SSOCS Files</p></a></li>
<li><a href='#downloadTALIS'><p>Download and Unzip TALIS Files</p></a></li>
<li><a href='#downloadTIMSS'><p>Download and Unzip TIMSS Files</p></a></li>
<li><a href='#downloadTIMSSAdv'><p>Download and Unzip TIMSS Advanced Files</p></a></li>
<li><a href='#drawPVs.sdf'><p>Draw plausible values from an mml fit</p></a></li>
<li><a href='#edsurvey.data.frame'><p>EdSurvey Class Constructors and Helpers</p></a></li>
<li><a href='#edsurvey.data.frame.list'><p>EdSurvey Dataset Vectorization</p></a></li>
<li><a href='#edsurveyTable'><p>EdSurvey Tables With Conditional Means</p></a></li>
<li><a href='#edsurveyTable2pdf'><p>PDF File From an edsurveyTable</p></a></li>
<li><a href='#gap'><p>Gap Analysis</p></a></li>
<li><a href='#getAllItems'><p>Retrieve IRT Item Variable Names</p></a></li>
<li><a href='#getData'><p>Read Data to a Data Frame</p></a></li>
<li><a href='#getNHES_SurveyInfo'><p>Get NHES Survey Code Definitions and Survey Meta-data</p></a></li>
<li><a href='#getPlausibleValue'><p>Get Plausible Value Variables</p></a></li>
<li><a href='#getWeightJkReplicates'><p>Retrieve the Jackknife Replicate Weights</p></a></li>
<li><a href='#glm.sdf'><p>EdSurvey Generalized Linear Models</p></a></li>
<li><a href='#hasPlausibleValue'><p>Plausible Value Test</p></a></li>
<li><a href='#isWeight'><p>Weight Test</p></a></li>
<li><a href='#levelsSDF'><p>Print Levels and Labels</p></a></li>
<li><a href='#lm.sdf'><p>EdSurvey Linear Models</p></a></li>
<li><a href='#merge.edsurvey.data'><p>EdSurvey Merge</p></a></li>
<li><a href='#mergev'><p>mergev</p></a></li>
<li><a href='#mixed.sdf'><p>EdSurvey Mixed-Effects Model</p></a></li>
<li><a href='#mml.sdf'><p>EdSurvey Direct Estimation</p></a></li>
<li><a href='#mvrlm.sdf'><p>Multivariate Regression</p></a></li>
<li><a href='#oddsRatio'><p>Odds Ratios for edsurveyGlm Models</p></a></li>
<li><a href='#parseNAEPdct'><p>Format AM dct File for Use with DirectEstimation</p></a></li>
<li><a href='#parseScript_SPSS'><p>Parse SPSS Syntax Script for Fixed-Width Data Files</p></a></li>
<li><a href='#percentile'><p>EdSurvey Percentiles</p></a></li>
<li><a href='#print.achievementLevels'><p>Print AchievementLevels Results</p></a></li>
<li><a href='#print.edsurvey.data.frame'><p>EdSurvey Metadata Summary</p></a></li>
<li><a href='#print.gap'><p>Gap Analysis Printing</p></a></li>
<li><a href='#read_ePIRLS'><p>Connect to ePIRLS Data</p></a></li>
<li><a href='#readBTLS'><p>Connect to BTLS Data</p></a></li>
<li><a href='#readCivEDICCS'><p>Connect to ICCS and CivED Data</p></a></li>
<li><a href='#readECLS_B'><p>Connect to ECLS-B Data</p></a></li>
<li><a href='#readECLS_K1998'><p>Connect to ECLS&ndash;K 1998 Data</p></a></li>
<li><a href='#readECLS_K2011'><p>Connect to ECLS&ndash;K 2011 Data</p></a></li>
<li><a href='#readELS'><p>Connect to Education Longitudinal Study (ELS:2002) Data</p></a></li>
<li><a href='#readHSB_Senior'><p>Connect to HS&amp;B Study Senior Data</p></a></li>
<li><a href='#readHSB_Sophomore'><p>Connect to HS&amp;B Study Sophomore Data</p></a></li>
<li><a href='#readHSLS'><p>Connect to High School Longitudinal Study 2009 (HSLS:2009) Data</p></a></li>
<li><a href='#readHSTS'><p>Connect to HSTS Data</p></a></li>
<li><a href='#readICILS'><p>Connect to ICILS Data</p></a></li>
<li><a href='#readNAEP'><p>Connect to NAEP Data</p></a></li>
<li><a href='#readNHES'><p>Connect to NHES Survey Data</p></a></li>
<li><a href='#readPIAAC'><p>Connect to PIAAC Data</p></a></li>
<li><a href='#readPIRLS'><p>Connect to PIRLS Data</p></a></li>
<li><a href='#readPISA'><p>Connect to PISA Data</p></a></li>
<li><a href='#readPISA_YAFS'><p>PISA YAFS (Young Adult Follow-up Study)</p></a></li>
<li><a href='#readSSOCS'><p>Connect to School Survey on Crime and Safety Data</p></a></li>
<li><a href='#readTALIS'><p>Connect to TALIS Data</p></a></li>
<li><a href='#readTIMSS'><p>Connect to TIMSS Data</p></a></li>
<li><a href='#readTIMSSAdv'><p>Connect to TIMSS Advanced Data</p></a></li>
<li><a href='#rebindAttributes'><p>Copy Data Frame Attributes</p></a></li>
<li><a href='#recode.sdf'><p>Recode Levels Within Variables</p></a></li>
<li><a href='#rename.sdf'><p>Modify Variable Names</p></a></li>
<li><a href='#rq.sdf'><p>EdSurvey Quantile Regression Models</p></a></li>
<li><a href='#scoreDefault'><p>Assessment scoring</p></a></li>
<li><a href='#scoreTIMSS'><p>EdSurvey Direct Estimation - TIMSS scoring</p></a></li>
<li><a href='#SD'><p>EdSurvey Standard Deviation</p></a></li>
<li><a href='#searchSDF'><p>EdSurvey Codebook Search</p></a></li>
<li><a href='#setNAEPScoreCard'><p>set NAEP Score Card</p></a></li>
<li><a href='#showCodebook'><p>Summary Codebook</p></a></li>
<li><a href='#showCutPoints'><p>Retrieve Achievement Level Cutpoints</p></a></li>
<li><a href='#showPlausibleValues'><p>Plausible Value Variable Names</p></a></li>
<li><a href='#showWeights'><p>Retrieve Weight Variables</p></a></li>
<li><a href='#suggestWeights'><p>Weight suggestions for ECLS-K:2011 data</p></a></li>
<li><a href='#summary2'><p>Summarize edsurvey.data.frame Variables</p></a></li>
<li><a href='#UnclassCols'><p>remove non-standard classes from data frame columns</p></a></li>
<li><a href='#updatePlausibleValue'><p>Update Plausible Value Variable Names</p></a></li>
<li><a href='#varEstToCov'><p>Covariance Estimation</p></a></li>
<li><a href='#viewNHES_SurveyCodes'><p>View NHES Survey Code Definitions</p></a></li>
<li><a href='#waldTest'><p>Wald Tests</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>4.0.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-24</td>
</tr>
<tr>
<td>Title:</td>
<td>Analysis of NCES Education Survey and Assessment Data</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul Bailey &lt;pbailey@air.org&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), car (&ge; 3.1-2), lfactors (&ge; 1.0.3), Dire (&ge;
2.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table (&ge; 1.11.4), Formula, glm2, haven (&ge; 2.2.0), LaF
(&ge; 0.8.4), lifecycle, lme4, MASS, Matrix (&ge; 1.6-1.1),
methods, NAEPprimer (&ge; 1.0.1), quantreg, readxl, tibble, wCorr
(&ge; 1.9.8), NAEPirtparams (&ge; 1.0.0), WeMix (&ge; 4.0.0), xtable,
xml2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.air.org/project/nces-data-r-project-edsurvey">https://www.air.org/project/nces-data-r-project-edsurvey</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/American-Institutes-for-Research/EdSurvey/issues">https://github.com/American-Institutes-for-Research/EdSurvey/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Read in and analyze functions for education survey and assessment data from the National Center for Education Statistics (NCES) <a href="https://nces.ed.gov/">https://nces.ed.gov/</a>, including National Assessment of Educational Progress (NAEP) data <a href="https://nces.ed.gov/nationsreportcard/">https://nces.ed.gov/nationsreportcard/</a> and data from the International Assessment Database: Organisation for Economic Co-operation and Development (OECD) <a href="https://www.oecd.org/">https://www.oecd.org/</a>, including Programme for International Student Assessment (PISA), Teaching and Learning International Survey (TALIS), Programme for the International Assessment of Adult Competencies (PIAAC), and International Association for the Evaluation of Educational Achievement (IEA) <a href="https://www.iea.nl/">https://www.iea.nl/</a>, including Trends in International Mathematics and Science Study (TIMSS), TIMSS Advanced, Progress in International Reading Literacy Study (PIRLS), International Civic and Citizenship Study (ICCS), International Computer and Information Literacy Study (ICILS), and Civic Education Study (CivEd).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, testthat, withr, rmarkdown, RColorBrewer, doParallel,
parallel</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Note:</td>
<td>This publication was prepared for NCES under Contract No.
ED-IES-12-D-0002 with the American Institutes for Research.
Mention of trade names, commercial products, or organizations
does not imply endorsement by the U.S. Government.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-26 23:19:09 UTC; pbailey</td>
</tr>
<tr>
<td>Author:</td>
<td>Paul Bailey <a href="https://orcid.org/0000-0003-0989-8729"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Ahmad Emad [aut],
  Huade Huo <a href="https://orcid.org/0009-0004-5014-646X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Michael Lee <a href="https://orcid.org/0009-0006-0959-787X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Yuqi Liao <a href="https://orcid.org/0000-0001-9359-6015"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Alex Lishinski <a href="https://orcid.org/0000-0003-4506-1600"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Trang Nguyen <a href="https://orcid.org/0009-0001-0167-8775"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Qingshu Xie [aut],
  Jiao Yu [aut],
  Ting Zhang <a href="https://orcid.org/0009-0001-1724-6141"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Eric Buehler <a href="https://orcid.org/0009-0004-6354-2015"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Sun-joo Lee [aut],
  Blue Webb <a href="https://orcid.org/0009-0004-4080-9864"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Emmanuel Sikali [pdr],
  Claire Kelley [ctb],
  Jeppe Bundsgaard [ctb],
  Ren C'deBaca [ctb],
  Anders Astrup Christensen [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-27 22:40:22 UTC</td>
</tr>
</table>
<hr>
<h2 id='EdSurvey-package'>Analysis of NCES Education Survey and Assessment Data</h2><span id='topic+EdSurvey-package'></span>

<h3>Description</h3>

<p>The <code>EdSurvey</code> package uses appropriate methods for analyzing NCES
datasets with a small memory
footprint. Existing system control files, included with the
data, are used
to read in and format the data for further processing.
</p>


<h3>Details</h3>

<p>To get started using <code>EdSurvey</code>, see the vignettes
for tutorials and the statistical methodologies. Use
<code>vignette("introduction", package="EdSurvey")</code> to see the vignettes.
</p>
<p>The package provides functions called <code><a href="#topic+readNAEP">readNAEP</a></code>,
<code><a href="#topic+readCivEDICCS">readCivEDICCS</a></code>, <code><a href="#topic+readICILS">readICILS</a></code>, <code><a href="#topic+readPIAAC">readPIAAC</a></code>,
<code><a href="#topic+readPIRLS">readPIRLS</a></code>, <code><a href="#topic+read_ePIRLS">read_ePIRLS</a></code>, <code><a href="#topic+readPISA">readPISA</a></code>, <code><a href="#topic+readTALIS">readTALIS</a></code>,
<code><a href="#topic+readTIMSS">readTIMSS</a></code>, <code><a href="#topic+readTIMSSAdv">readTIMSSAdv</a></code>, and <code><a href="#topic+readECLS_K2011">readECLS_K2011</a></code>
to read in NCES datasets.
The functions
<code><a href="#topic+achievementLevels">achievementLevels</a></code>,
<code><a href="#topic+cor.sdf">cor.sdf</a></code>,
<code><a href="#topic+edsurveyTable">edsurveyTable</a></code>,
<code><a href="#topic+summary2">summary2</a></code>,
<code><a href="#topic+lm.sdf">lm.sdf</a></code>,
<code><a href="#topic+logit.sdf">logit.sdf</a></code>,
<code><a href="#topic+mixed.sdf">mixed.sdf</a></code>,
<code><a href="#topic+rq.sdf">rq.sdf</a></code>,
<code><a href="#topic+percentile">percentile</a></code>, and
<code><a href="#topic+gap">gap</a></code>
can then be used to analyze data.
For advanced users, <code><a href="#topic+getData">getData</a></code> extracts
the data of interest as a data frame for further processing.
</p>

<hr>
<h2 id='achievementLevels'>Achievement Levels</h2><span id='topic+achievementLevels'></span>

<h3>Description</h3>

<p>Returns achievement levels using weights and variance estimates appropriate for the <code>edsurvey.data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>achievementLevels(
  achievementVars = NULL,
  aggregateBy = NULL,
  data,
  cutpoints = NULL,
  returnDiscrete = TRUE,
  returnCumulative = FALSE,
  weightVar = NULL,
  jrrIMax = 1,
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  returnNumberOfPSU = FALSE,
  returnVarEstInputs = FALSE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="achievementLevels_+3A_achievementvars">achievementVars</code></td>
<td>
<p>character vector indicating variables to be included in the achievement
levels table, potentially with a subject scale or subscale. When the subject
scale or subscale is omitted, the default subject scale or subscale is
used. You can find the default composite scale and all subscales using the
function <code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_aggregateby">aggregateBy</code></td>
<td>
<p>character vector specifying variables by which to aggregate achievement levels. The percentage
column sums up to 100 for all levels of all variables specified here. When set to the
default of <code>NULL</code>, the percentage column sums up to 100 for all
levels of all variables specified in <code>achievementVars</code>.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_cutpoints">cutpoints</code></td>
<td>
<p>numeric vector indicating cutpoints. Set to standard NAEP cutpoints for
Basic, Proficient, and Advanced by default.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_returndiscrete">returnDiscrete</code></td>
<td>
<p>logical indicating if discrete achievement levels should be returned. Defaults
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_returncumulative">returnCumulative</code></td>
<td>
<p>logical indicating if cumulative achievement levels should be returned. Defaults
to <code>FALSE</code>. The first and last categories are the same as defined for discrete levels.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_weightvar">weightVar</code></td>
<td>
<p>character string indicating the weight variable to use.
Only the name of the
weight variable needs to be included here, and any
replicate weights will be automatically included.
When this argument is <code>NULL</code>, the function uses the default.
Use <code><a href="#topic+showWeights">showWeights</a></code> to find the default.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>a numeric value. When using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=1</code>, uses the
sampling variance from the first plausible value as the component for sampling variance estimation. The <code class="reqn">V_{jrr}</code>
term (see <a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a> for the definition of <code class="reqn">V_{jrr}</code>)
can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value (<code>TRUE</code>), it drops those levels in all factor variables
that are specified in <code>achievementVars</code> and <code>aggregateBy</code>.
Use <code>print</code> on an <code>edsurvey.data.frame</code> to see the omitted levels.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, uses the default
conditions stored in an <code>edsurvey.data.frame</code> to subset the data.
Use <code>print</code> on an <code>edsurvey.data.frame</code> to see the default
conditions.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>. Can be set as
<code>recode</code> <code>=</code> <code>list(var1=</code> <code>list(from=c("a",</code> <code>"b",</code> <code>"c"),</code> <code>to ="d"))</code>. See Examples.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_returnnumberofpsu">returnNumberOfPSU</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the number of
primary sampling units (PSUs)</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_returnvarestinputs">returnVarEstInputs</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the
inputs to the jackknife and imputation variance
estimates, which allows for the computation
of covariances between estimates.</p>
</td></tr>
<tr><td><code id="achievementLevels_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>achievementLevels</code> function applies appropriate weights
and the variance estimation method for each
<code>edsurvey.data.frame</code>, with several arguments for customizing
the aggregation and output of the analysis
results. Namely, by using these optional arguments, users can choose
to generate the percentage of students
performing at each achievement level (discrete), generate the
percentage of students performing at or above each achievement level
(cumulative),
calculate the percentage distribution of students by achievement
level (discrete or cumulative) and
selected characteristics (specified in <code>aggregateBy</code>), and
compute the percentage distribution of students
by selected characteristics within a specific achievement level.
</p>


<h4>Calculation of percentages</h4>

<p>The details of the methods are shown in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf">Statistical Methods Used in EdSurvey</a> in
&ldquo;Estimation of Weighted Percentages When Plausible Values Are Present&rdquo; and are used to calculate
all cumulative and discrete probabilities.
</p>
<p>When the requested achievement levels are discrete (<code>returnDiscrete = TRUE</code>),
the percentage <code class="reqn">\mathcal{A}</code> is the percentage of students (within the categories specified in <code>aggregateBy</code>)
whose scores lie in the range  <code class="reqn">[cutPoints_i, cutPoints_{i+1}), i = 0,1,...,n</code>.
<code>cutPoints</code> is the score thresholds provided by the user with <code class="reqn">cutPoints_0</code> taken
to be 0. <code>cutPoints</code> are set to NAEP standard cutpoints for achievement levels by default.
To aggregate by a specific variable, for example, <code>dsex</code>, specify <code>dsex</code> in <code>aggregateBy</code>
and all other variables in <code>achievementVars</code>. To aggregate by subscale, specify
the name of the subscale (e.g., <code>num_oper</code>) in <code>aggregateBy</code> and all other variables in
<code>achievementVars</code>.
</p>
<p>When the requested achievement levels are cumulative (<code>returnCumulative = TRUE</code>),
the percentage <code class="reqn">\mathcal{A}</code> is the percentage of students (within the categories specified in <code>aggregateBy</code>)
whose scores lie in the range  [<code class="reqn">cutPoints_i</code>, <code class="reqn">\infty</code>), <code class="reqn">i = 1, 2, ..., n-1</code>. The
first and last categories are the same as defined for discrete levels.
</p>



<h4>Calculation of standard error of percentages</h4>

<p>The method used to calculate the standard error of the percentages is described in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf">Statistical Methods Used in EdSurvey</a>
in the sections &ldquo;Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Present, Using the Jackknife Method&rdquo;
and &ldquo;Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Not Present, Using the Taylor Series Method.&rdquo;
For &ldquo;Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Present, Using the Jackknife Method,&rdquo;
the value of <code>jrrIMax</code> sets the value of <code class="reqn">m^*</code>.
</p>



<h3>Value</h3>

<p>A <code>list</code> containing up to two data frames, one discrete achievement levels (when <code>returnDiscrete</code> is <code>TRUE</code>)
and one for cumulative achievement levels (when <code>returnCumulative</code> is <code>TRUE</code>). The <code>data.frame</code> contains the following columns:
</p>
<table>
<tr><td><code>Level</code></td>
<td>
<p>one row for each level of the specified achievement cutpoints</p>
</td></tr>
<tr><td><code>Variables in achievementVars</code></td>
<td>
<p>one column for each variable in <code>achievementVars</code>
and one row for each level of each variable in <code>achievementVars</code></p>
</td></tr>
<tr><td><code>Percent</code></td>
<td>
<p>the percentage of students at or above each achievement level aggregated as specified by <code>aggregateBy</code></p>
</td></tr>
<tr><td><code>StandardError</code></td>
<td>
<p>the standard error of the percentage, accounting for the survey sampling methodology.
See the vignette titled <a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf">Statistical Methods Used in EdSurvey</a>.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>the number of observations in the incoming data (the
number of rows when <code>omittedLevels</code> and
<code>defaultConditions</code> are set to <code>FALSE</code>)</p>
</td></tr>
<tr><td><code>wtdN</code></td>
<td>
<p>the weighted number of observations in the data</p>
</td></tr>
<tr><td><code>nPSU</code></td>
<td>
<p>the number of PSUs at or above each achievement level aggregated as specified by <code>aggregateBy</code>. Only returned with <code>returnNumberOfPSU=TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Huade Huo, Ahmad Emad, and Trang Nguyen
</p>


<h3>References</h3>

<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>. New York, NY: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# discrete achievement levels
achievementLevels(achievementVars=c("composite"), aggregateBy=NULL, data=sdf)

# discrete achievement levels with a different subscale
achievementLevels(achievementVars=c("num_oper"), aggregateBy=NULL, data=sdf)

# cumulative achievement levels
achievementLevels(achievementVars=c("composite"), aggregateBy=NULL, data=sdf, 
                  returnCumulative=TRUE) 

# cumulative achievement levels with a different subscale
achievementLevels(achievementVars=c("num_oper"), aggregateBy=NULL, data=sdf, 
                  returnCumulative=TRUE) 

# achievement levels as independent variables, by sex aggregated by composite
achievementLevels(achievementVars=c("composite", "dsex"), aggregateBy="composite",
                  data=sdf, returnCumulative=TRUE) 

# achievement levels as independent variables, by sex aggregated by sex
achievementLevels(achievementVars=c("composite", "dsex"), aggregateBy="dsex", 
                  data=sdf, returnCumulative=TRUE) 

# achievement levels as independent variables, by race aggregated by race
achievementLevels(achievementVars=c("composite", "sdracem"),
                  aggregateBy="sdracem", data=sdf, returnCumulative=TRUE) 

# use customized cutpoints
achievementLevels(achievementVars=c("composite"), aggregateBy=NULL, data=sdf, 
                  cutpoints = c("Customized Basic" = 200, 
                                "Customized Proficient" = 300, 
                                "Customized Advanced" = 400))

# use recode to change values for specified variables:
achievementLevels(achievementVars=c("composite", "dsex", "b017451"),
                  aggregateBy = "dsex", sdf,
                  recode=list(b017451=list(from=c("Never or hardly ever",
                                                  "Once every few weeks",
                                                  "About once a week"),
                                           to="Infrequently"),
                              b017451=list(from=c("2 or 3 times a week",
                                                  "Every day"),
                                           to="Frequently")))

## End(Not run)
</code></pre>

<hr>
<h2 id='as.data.frame'>Coerce to a Data Frame</h2><span id='topic+as.data.frame'></span><span id='topic+as.data.frame.light.edsurvey.data.frame'></span>

<h3>Description</h3>

<p>Function to coerce a <code>light.edsurvey.data.frame</code> to a <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'light.edsurvey.data.frame'
as.data.frame(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.data.frame_+3A_x">x</code></td>
<td>
<p>a <code>light.edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code>
</p>


<h3>Author(s)</h3>

<p>Trang Nguyen
</p>

<hr>
<h2 id='cbind.light.edsurvey.data.frame'>Combine R Objects by Rows or Columns</h2><span id='topic+cbind.light.edsurvey.data.frame'></span><span id='topic+rbind.light.edsurvey.data.frame'></span>

<h3>Description</h3>

<p>Implements <code><a href="base.html#topic+cbind">cbind</a></code> and <code><a href="base.html#topic+rbind">rbind</a></code> for <code>light.edsurvey.data.frame</code> class.
It takes a sequence of <code>vector</code>, <code>matrix</code>, <code>data.frame</code>, or <code>light.edsurvey.data.frame</code> arguments and combines
by columns or rows, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'light.edsurvey.data.frame'
cbind(..., deparse.level = 1)

## S3 method for class 'light.edsurvey.data.frame'
rbind(..., deparse.level = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cbind.light.edsurvey.data.frame_+3A_...">...</code></td>
<td>
<p>one or more objects of class <code>vector</code>, <code>data.frame</code>, <code>matrix</code>, or <code>light.edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="cbind.light.edsurvey.data.frame_+3A_deparse.level">deparse.level</code></td>
<td>
<p>integer determining under which circumstances column and row names are built from the actual arguments. See <code><a href="base.html#topic+cbind">cbind</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because <code>cbind</code> and <code>rbind</code> are standard generic functions that do not use method dispatch, we set this function as generic,
which means it overwrites <code>base::cbind</code> and <code>base::rbind</code> on loading. If none of the specified elements are of class <code>light.edsurvey.data.frame</code>,
the function will revert to the standard <code>base</code> method. However, to be safe, you might want to explicitly use <code>base::cbind</code> when needed after loading the package.
</p>
<p>The returned object will contain attributes only from the first <code>light.edsurvey.data.frame</code> object in the call to
<code>cbind.light.edsurvey.data.frame</code>.
</p>


<h3>Value</h3>

<p>a matrix-like object like <code>matrix</code> or <code>data.frame</code>. Returns a <code>light.edsurvey.data.frame</code> if there is
at least one <code>light.edsurvey.data.frame</code> in the list of arguments.
</p>


<h3>Author(s)</h3>

<p>Trang Nguyen, Michael Lee, and Paul Bailey
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cbind">cbind</a></code>
</p>

<hr>
<h2 id='checkIdVar'>Give warning if idVar is null on on light edsurvey dataframe.</h2><span id='topic+checkIdVar'></span>

<h3>Description</h3>

<p>Give warning if idVar is null on on light edsurvey dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkIdVar(data, idVar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkIdVar_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, <code>light.edsurvey.data.frame</code>, or <code>data.frame</code> to look for the <code>idVar</code> on</p>
</td></tr>
<tr><td><code id="checkIdVar_+3A_idvar">idVar</code></td>
<td>
<p>the variable to look for
Without an idVar the users won't be able to merge PVs back to the data after running an mml.  If there is no idVar, a default is chosen.</p>
</td></tr>
</table>

<hr>
<h2 id='checkPsuStrata'>Give error if Strata and PSU var not present on light edsurvey data frame.</h2><span id='topic+checkPsuStrata'></span>

<h3>Description</h3>

<p>Give error if Strata and PSU var not present on light edsurvey data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkPsuStrata(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkPsuStrata_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or <code>light.edsurvey.data.frame</code> to check for PSU and Strata variables</p>
</td></tr>
</table>

<hr>
<h2 id='contourPlot'>Overlaid Scatter and Contour Plots</h2><span id='topic+contourPlot'></span>

<h3>Description</h3>

<p>Diagnostic plots for regressions can become too dense to interpret.
This function helps by adding a contour plot over the points to
allow the density of points to be seen, even when an area is entirely covered in points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contourPlot(
  x,
  y,
  m = 30L,
  xrange,
  yrange,
  xkernel,
  ykernel,
  nlevels = 9L,
  densityColors = heat.colors(nlevels),
  pointColors = "gray",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contourPlot_+3A_x">x</code></td>
<td>
<p>numeric vector of the <code>x</code> data to be plotted</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_y">y</code></td>
<td>
<p>numeric vector of the <code>y</code> data to be plotted</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_m">m</code></td>
<td>
<p>integer value of the number of <code>x</code> and <code>y</code> grid points</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_xrange">xrange</code></td>
<td>
<p>numeric vector of length two indicating <code>x</code>-range of plot;
defaults to range(x)</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_yrange">yrange</code></td>
<td>
<p>numeric vector of length two indicating <code>y</code>-range of plot;
defaults to range(y)</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_xkernel">xkernel</code></td>
<td>
<p>numeric indicating the standard deviation of Normal
<code>x</code> kernel to use in generating contour plot</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_ykernel">ykernel</code></td>
<td>
<p>numeric indicating the standard deviation of Normal
<code>y</code> kernel to use in generating contour plot</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_nlevels">nlevels</code></td>
<td>
<p>integer with the number of levels of the contour plot</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_densitycolors">densityColors</code></td>
<td>
<p>colors to use, specified as in <code><a href="graphics.html#topic+par">par</a></code>.
Defaults to the <code><a href="grDevices.html#topic+heat.colors">heat.colors</a></code>
with <code>nlevels</code>. When specified, <code>colors</code> overrides <code>nlevels</code>.</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_pointcolors">pointColors</code></td>
<td>
<p>color for the plot points</p>
</td></tr>
<tr><td><code id="contourPlot_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to a plot call that generates the
scatter plot and the contour plot</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuqi Liao and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))
lm1 &lt;- lm.sdf(composite ~ pared * dsex + sdracem, sdf)
# plot the results
contourPlot(x=lm1$fitted.values,
	          y=lm1$residuals[,1], # use only the first plausible value
	          m=30,
	          xlab="fitted values",
	          ylab="residuals",
	          main="Figure 1")
# add a line indicating where the residual is zero
abline(0,0)

## End(Not run)
</code></pre>

<hr>
<h2 id='cor.sdf'>Bivariate Correlation</h2><span id='topic+cor.sdf'></span>

<h3>Description</h3>

<p>Computes the correlation of two variables on an <code>edsurvey.data.frame</code>,
a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
The correlation accounts for plausible values and the survey design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.sdf(
  x,
  y,
  data,
  method = c("Pearson", "Spearman", "Polychoric", "Polyserial"),
  weightVar = "default",
  reorder = NULL,
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  condenseLevels = TRUE,
  fisherZ = if (match.arg(method) %in% "Pearson") {
     TRUE
 } else {
     FALSE
 },
  jrrIMax = Inf,
  verbose = TRUE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor.sdf_+3A_x">x</code></td>
<td>
<p>a character variable name from the <code>data</code> to be correlated with <code>y</code></p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_y">y</code></td>
<td>
<p>a character variable name from the <code>data</code> to be correlated with <code>x</code></p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_method">method</code></td>
<td>
<p>a character string indicating which correlation coefficient (or covariance) is to be computed.
One of <code>Pearson</code> (default), <code>Spearman</code>, <code>Polychoric</code>, or <code>Polyserial</code>. For Polyserial, the continuous argument must be <code>x</code>.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_weightvar">weightVar</code></td>
<td>
<p>character indicating the weight variable to use. See Details section in <code><a href="#topic+lm.sdf">lm.sdf</a></code>.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_reorder">reorder</code></td>
<td>
<p>a list of variables to reorder. Defaults to <code>NULL</code> (no variables are reordered). Can be set as
<code>reorder</code> <code>=</code> <code>list(var1</code> <code>=</code> <code>c("a","b","c"),</code> <code>var2</code> <code>=</code> <code>c("4", "3", "2", "1"))</code>. See Examples.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, drops those levels of all factor variables that are specified
in an <code>edsurvey.data.frame</code>. Use <code>print</code> on an <code>edsurvey.data.frame</code> to see the omitted levels.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, uses the default conditions stored in an <code>edsurvey.data.frame</code>
to subset the data. Use <code>print</code> on an <code>edsurvey.data.frame</code> to see the default conditions.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>. Can be set as
<code>recode</code> <code>=</code> <code>list(var1</code> <code>=</code> <code>list(from</code> <code>=</code> <code>c("a","b","c"), to</code> <code>=</code> <code>"d"))</code>. See Examples.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_condenselevels">condenseLevels</code></td>
<td>
<p>a logical value. When set to the default value of
<code>TRUE</code> and either <code>x</code> or <code>y</code> is a
categorical variable, the function will drop all unused
levels and rank the levels of the variable before
calculating the correlation. When set to <code>FALSE</code>,
the numeric levels of the variable remain the same as
in the codebook. See Examples.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_fisherz">fisherZ</code></td>
<td>
<p>for standard error and mean calculations, set to <code>TRUE</code> to use
the Fisher Z-transformation (see details), or <code>FALSE</code>
to use no transformation of the data. The <code>fisherZ</code> argument defaults
to Fisher Z-transformation for Pearson and no transformation
for other correlation types.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>a numeric value; when using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=Inf</code>, uses the
sampling variance from all plausible values as the component for sampling variance estimation. The <code>Vjrr</code>
term (see
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>)
can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_verbose">verbose</code></td>
<td>
<p>a logical value. Set to <code>FALSE</code> to avoid messages about variable conversion.</p>
</td></tr>
<tr><td><code id="cor.sdf_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+getData">getData</a></code> arguments and <code><a href="#topic+recode.sdf">recode.sdf</a></code> may be useful. (See Examples.)
The correlation methods are calculated as described in the documentation for the <code>wCorr</code> package&mdash;see <code>browseVignettes(package="wCorr")</code>.
</p>
<p>When <code>method</code> is set to <code>polyserial</code>, all <code>x</code> arguments are assumed to be continuous and all <code>y</code> assumed discrete. Therefore,
be mindful of variable selection as this may result in calculations taking a very long time to complete.
</p>
<p>The Fisher Z-transformation is both a variance stabilizing  and normalizing transformation
for the Pearson correlation coefficient (Fisher, 1915).
The transformation takes the inverse hyperbolic tangent of the correlation coefficients and then calculates all variances and confidence intervals.
These are then transformed back to the correlation space (values between -1 and 1, inclusive) using the hyperbolic tangent function.
The Taylor series approximation (or delta method) is applied for the standard errors.
</p>


<h3>Value</h3>

<p>An <code>edsurvey.cor</code> that has print and summary methods.
</p>
<p>The class includes the following elements:
</p>
<table>
<tr><td><code>correlation</code></td>
<td>
<p>numeric estimated correlation coefficient</p>
</td></tr>
<tr><td><code>Zse</code></td>
<td>
<p>standard error of the correlation (<code>Vimp</code> + <code>Vjrr</code>). In the case of Pearson, this is calculated in the linear atanh space and is not a standard error in the usual sense.</p>
</td></tr>
<tr><td><code>correlates</code></td>
<td>
<p>a vector of length two showing the columns for which the correlation coefficient was calculated</p>
</td></tr>
<tr><td><code>variables</code></td>
<td>
<p><code>correlates</code> that are discrete</p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>a list that shows the order of each variable</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the type of correlation estimated</p>
</td></tr>
<tr><td><code>Vjrr</code></td>
<td>
<p>the jackknife component of the variance estimate. For Pearson, in the atanh space.</p>
</td></tr>
<tr><td><code>Vimp</code></td>
<td>
<p>the imputation component of the variance estimate. For Pearson, in the atanh space.</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>
<p>the weight variable used</p>
</td></tr>
<tr><td><code>npv</code></td>
<td>
<p>the number of plausible values used</p>
</td></tr>
<tr><td><code>njk</code></td>
<td>
<p>the number of the jackknife replicates used</p>
</td></tr>
<tr><td><code>n0</code></td>
<td>
<p>the original number of observations</p>
</td></tr>
<tr><td><code>nUsed</code></td>
<td>
<p>the number of observations used in the analysis&mdash;after any conditions and any listwise deletion of missings is applied</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard error of the correlation, in the correlation ([-1,1]) space</p>
</td></tr>
<tr><td><code>ZconfidenceInterval</code></td>
<td>
<p>the confidence interval of the correlation in the transformation space</p>
</td></tr>
<tr><td><code>confidenceInterval</code></td>
<td>
<p>the confidence interval of the correlation in the correlation ([-1,1]) space</p>
</td></tr>
<tr><td><code>transformation</code></td>
<td>
<p>the name of the transformation used when calculating standard errors</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Bailey; relies heavily on the <code>wCorr</code> package, written by Ahmad Emad and Paul Bailey
</p>


<h3>References</h3>

<p>Fisher, R. A. (1915). Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population. <em>Biometrika</em>, <em>10</em>(4), 507&ndash;521.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code> and <code><a href="wCorr.html#topic+weightedCorr">weightedCorr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# for two categorical variables any of the following work
c1_pears &lt;- cor.sdf(x="b017451", y="b003501", data=sdf, method="Pearson",
                    weightVar="origwt")
c1_spear &lt;- cor.sdf(x="b017451", y="b003501", data=sdf, method="Spearman",
                    weightVar="origwt")
c1_polyc &lt;- cor.sdf(x="b017451", y="b003501", data=sdf, method="Polychoric",
                    weightVar="origwt")

c1_pears
c1_spear
c1_polyc

# for categorical variables, users can either keep the original numeric levels of the variables
# or condense the levels (default)
# the following call condenses the levels of the variable 'c046501'
cor.sdf(x="c046501", y="c044006", data=sdf)

# the following call keeps the original levels of the variable 'c046501'
cor.sdf(x="c046501", y="c044006", data=sdf, condenseLevels = FALSE)

# these take awhile to calculate for large datasets, so limit to a subset
sdf_dnf &lt;- subset(sdf, b003601 == 1)

# for a categorical variable and a scale score any of the following work
c2_pears &lt;- cor.sdf(x="composite", y="b017451", data=sdf_dnf, method="Pearson",
                    weightVar="origwt")
c2_spear &lt;- cor.sdf(x="composite", y="b017451", data=sdf_dnf, method="Spearman",
                    weightVar="origwt")
c2_polys &lt;- cor.sdf(x="composite", y="b017451", data=sdf_dnf, method="Polyserial",
                    weightVar="origwt")

c2_pears
c2_spear
c2_polys

# recode two variables
cor.sdf(x="c046501", y="c044006", data=sdf, method="Spearman", weightVar="origwt",
        recode=list(c046501=list(from="0%",to="None"),
                    c046501=list(from=c("1-5%", "6-10%", "11-25%", "26-50%",
                                        "51-75%", "76-90%", "Over 90%"),
                                 to="Between 0% and 100%"),
                    c044006=list(from=c("1-5%", "6-10%", "11-25%", "26-50%",
                                        "51-75%", "76-90%", "Over 90%"),
                                 to="Between 0% and 100%")))

# reorder two variables
cor.sdf(x="b017451", y="sdracem", data=sdf, method="Spearman", weightVar="origwt", 
        reorder=list(sdracem=c("White", "Hispanic", "Black", "Asian/Pacific Island",
                               "Amer Ind/Alaska Natv", "Other"),
                     b017451=c("Every day", "2 or 3 times a week", "About once a week",
                               "Once every few weeks", "Never or hardly ever")))

# recode two variables and reorder
cor.sdf(x="pared", y="b013801", data=subset(sdf, !pared %in% "I Don\'t Know"),
        method="Spearman", weightVar = "origwt",
        recode=list(pared=list(from="Some ed after H.S.", to="Graduated H.S."), 
                    pared=list(from="Graduated college", to="Graduated H.S."),
                    b013801=list(from="0-10", to="Less than 100"), 
                    b013801=list(from="11-25", to="Less than 100"),
                    b013801=list(from="26-100", to="Less than 100")),
        reorder=list(b013801=c("Less than 100", "&gt;100")))

## End(Not run)
</code></pre>

<hr>
<h2 id='dim.edsurvey.data.frame'>Dimensions of an edsurvey.data.frame or an edsurvey.data.frame.list</h2><span id='topic+dim.edsurvey.data.frame'></span><span id='topic+dim.edsurvey.data.frame.list'></span>

<h3>Description</h3>

<p>Returns the dimensions of an <code>edsurvey.data.frame</code> or an
<code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'edsurvey.data.frame'
dim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dim.edsurvey.data.frame_+3A_x">x</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>For an <code>edsurvey.data.frame</code>, returns a
numeric vector of length two, with the first element being the number
of rows and the second element being the number of columns.
</p>
<p>For an <code>edsurvey.data.frame.list</code>, returns a list of length
two, where the first element is named <code>nrow</code> and is a
numeric vector containing the number of rows for each element of the
<code>edsurvey.data.frame.list</code>. The second element is named
<code>ncol</code> and is the number of columns for each element.
This is done so that the <code>nrow</code> and <code>ncol</code> functions
return meaningful results, even if nonstandard.
</p>


<h3>Author(s)</h3>

<p>Paul Bailey
</p>

<hr>
<h2 id='DoFCorrection'>Degrees of Freedom</h2><span id='topic+DoFCorrection'></span>

<h3>Description</h3>

<p>Calculates the degrees of freedom for a statistic
(or of a contrast between two statistics) based on the
jackknife and imputation variance estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DoFCorrection(
  varEstA,
  varEstB = varEstA,
  varA,
  varB = varA,
  method = c("WS", "JR")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DoFCorrection_+3A_varesta">varEstA</code></td>
<td>
<p>the <code>varEstInput</code> object returned from certain functions, such as
<code><a href="#topic+lm.sdf">lm.sdf</a></code> when <code>returnVarEstInputs=</code><code>TRUE</code>).
The variable <code>varA</code> must be on this dataset.
See Examples.</p>
</td></tr>
<tr><td><code id="DoFCorrection_+3A_varestb">varEstB</code></td>
<td>
<p>similar to the <code>varEstA</code> argument.
If left blank, both are assumed to come
from <code>varEstA</code>. When set, the degrees of freedom
are for a contrast between <code>varA</code> and <code>varB</code>,
and the <code>varB</code> values are taken from <code>varEstB</code>.</p>
</td></tr>
<tr><td><code id="DoFCorrection_+3A_vara">varA</code></td>
<td>
<p>a character that names the statistic in the <code>varEstA</code>
argument for which the degrees of freedom calculation is required.</p>
</td></tr>
<tr><td><code id="DoFCorrection_+3A_varb">varB</code></td>
<td>
<p>a character that names the statistic in the <code>varEstB</code>
argument for which a covariance is required. When <code>varB</code>
is specified, returns the degrees of freedom for
the contrast between <code>varA</code> and <code>varB</code>.</p>
</td></tr>
<tr><td><code id="DoFCorrection_+3A_method">method</code></td>
<td>
<p>a character that is either <code>WS</code> for the Welch-Satterthwaite
formula or
<code>JR</code> for the Johnson-Rust correction to the
Welch-Satterthwaite formula</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This calculation happens under the notion that statistics
have little variance within strata, and
some strata will contribute fewer than a full degree of freedom.
</p>
<p>The functions are not vectorized, so both <code>varA</code> and
<code>varB</code> must contain exactly one variable name.
</p>
<p>The method used to compute the degrees of freedom is in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
section &ldquo;Estimation of Degrees of Freedom.&rdquo;
</p>


<h3>Value</h3>

<p>numeric; the estimated degrees of freedom
</p>


<h3>Author(s)</h3>

<p>Paul Bailey
</p>


<h3>References</h3>

<p>Johnson, E. G., &amp; Rust, K. F. (1992). Population inferences and variance estimation for NAEP data. <em>Journal of Educational Statistics,</em> <em>17,</em> 175&ndash;190.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))
lm1 &lt;- lm.sdf(composite ~ dsex + b017451, sdf, returnVarEstInputs=TRUE)
summary(lm1)
# this output agrees with summary of lm1 coefficient for dsex
DoFCorrection(lm1$varEstInputs,
              varA="dsexFemale",
              method="JR")
# second example, a covariance term requires more work
# first, estimate the covariance between two regression coefficients
# note that the variable names are parallel to what they are called in lm1 output
covFEveryDay &lt;- varEstToCov(lm1$varEstInputs,
                            varA="dsexFemale",
                            varB="b017451Every day",
                            jkSumMultiplier=EdSurvey:::getAttributes(sdf, "jkSumMultiplier"))
# second, find the difference and the SE of the difference
se &lt;- lm1$coefmat["dsexFemale","se"] + lm1$coefmat["b017451Every day","se"] +
      -2*covFEveryDay
# third, calculate the t-statistic
tv &lt;- (coef(lm1)["dsexFemale"] - coef(lm1)["b017451Every day"])/se
# fourth, calculate the p-value, which requires the estimated degrees of freedom
dofFEveryDay &lt;- DoFCorrection(lm1$varEstInputs,
                              varA="dsexFemale",
                              varB="b017451Every day",
                              method="JR")
# finally, the p-value
2*(1-pt(abs(tv), df=dofFEveryDay))

## End(Not run)
</code></pre>

<hr>
<h2 id='download_ePIRLS'>Download and Unzip ePIRLS Files</h2><span id='topic+download_ePIRLS'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download ePIRLS data.
Data come from <a href="https://timssandpirls.bc.edu/">timssandpirls.bc.edu</a> zip files. This
function works for 2016 data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_ePIRLS(root, years = c(2016), cache = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_ePIRLS_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the ePIRLS
data should be stored. Files are placed in a
subdirectory named ePIRLS/[year].</p>
</td></tr>
<tr><td><code id="download_ePIRLS_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years to download. Valid year is 2016 only.</p>
</td></tr>
<tr><td><code id="download_ePIRLS_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="download_ePIRLS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_ePIRLS">read_ePIRLS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# root argument will vary by operating system conventions
download_ePIRLS(years=2016, root = "~/")

# cache=TRUE will download then process the datafiles
download_ePIRLS(years=2016, root = "~/", cache = TRUE)

# set verbose=FALSE for silent output
# if year not specified, download all years
download_ePIRLS(root="~/", verbose = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadCivEDICCS'>Instructions for Downloading and Unzipping CivED or ICCS Files</h2><span id='topic+downloadCivEDICCS'></span>

<h3>Description</h3>

<p>Provides instructions to download CivED or ICCS data to be processed in <code>readCivEDICCS</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadCivEDICCS(years = c(1999, 2009, 2016))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadCivEDICCS_+3A_years">years</code></td>
<td>
<p>an integer vector indicating the study year. Valid years are 1999, 2009, and 2016.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readCivEDICCS">readCivEDICCS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# view instructions to manually download study data
downloadCivEDICCS()

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadECLS_K'>Download and Unzip ECLS_K Files</h2><span id='topic+downloadECLS_K'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download ECLS_K data.
Data come from <a href="https://nces.ed.gov/edat/">nces.ed.gov</a> zip files. This
function works for 1998 and 2011 data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadECLS_K(root, years = c(1998, 2011), cache = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadECLS_K_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the ECLS_K
data should be stored. Files are placed in a
subdirectory named ECLS_K/[year].</p>
</td></tr>
<tr><td><code id="downloadECLS_K_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years to download. Valid years are 1998 and 2011.</p>
</td></tr>
<tr><td><code id="downloadECLS_K_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadECLS_K_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Beginning for the ECLS_K 2011 Study Grade 5 data files, the <code>ChildK5p.zip</code> source data file is a <code>DEFLATE64</code> compressed zip file.
This means that the user must manually extract the contained <code>childK5p.dat</code> file using an external zip
program capable of handling <code>DEFLATE64</code> zip format. As existing R functions are unable to handle this zip format natively.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readECLS_K1998">readECLS_K1998</a></code> and <code><a href="#topic+readECLS_K2011">readECLS_K2011</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# root argument will vary by operating system conventions
downloadECLS_K(years=c(1998, 2011), root = "~/")

# cache=TRUE will download then process the datafiles
downloadECLS_K(years=c(1998, 2011), root = "~/", cache = TRUE)

# set verbose=FALSE for silent output
# if year not specified, download all years
downloadECLS_K(root="~/", verbose = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadELS'>Download and Unzip ELS Files</h2><span id='topic+downloadELS'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download ELS data.
Data come from <a href="https://nces.ed.gov/edat/">nces.ed.gov</a> zip files. This
function works for 2002 data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadELS(root, years = c(2002), cache = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadELS_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the ELS
data should be stored. Files are placed in a
subdirectory named ELS/[year].</p>
</td></tr>
<tr><td><code id="downloadELS_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years to download. Valid year is 2002 only.</p>
</td></tr>
<tr><td><code id="downloadELS_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadELS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readELS">readELS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# root argument will vary by operating system conventions
downloadELS(years=2002, root = "~/")

# cache=TRUE will download then process the datafiles
downloadELS(years=2002, root = "~/", cache = TRUE)

# set verbose=FALSE for silent output
# if year not specified, download all years
downloadELS(root="~/", verbose = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadHSLS'>Download and Unzip HSLS Files</h2><span id='topic+downloadHSLS'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download HSLS data.
Data come from <a href="https://nces.ed.gov/edat/">nces.ed.gov</a> zip files. This
function works for 2009 data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadHSLS(root, years = c(2009), cache = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadHSLS_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the HSLS
data should be stored. Files are placed in a
subdirectory named HSLS/[year].</p>
</td></tr>
<tr><td><code id="downloadHSLS_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years to download. Valid year is 2009 only.</p>
</td></tr>
<tr><td><code id="downloadHSLS_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadHSLS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readHSLS">readHSLS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# root argument will vary by operating system conventions
downloadHSLS(root = "~/", years=2009)

# set verbose=FALSE for silent output
# if year not specified, download all years
downloadHSLS(root="~/", verbose = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadICILS'>Instructions for Downloading and Unzipping ICILS Files</h2><span id='topic+downloadICILS'></span>

<h3>Description</h3>

<p>Provides instructions to download ICILS data to be processed in <code>readICILS</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadICILS(years = c(2013, 2018))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadICILS_+3A_years">years</code></td>
<td>
<p>an integer vector indicating the study year. Valid year is 2013 only.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readICILS">readICILS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# view instructions to manually download study data
downloadICILS()

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadNHES'>Instructions for Downloading and Unzipping NHES Files</h2><span id='topic+downloadNHES'></span>

<h3>Description</h3>

<p>Provides instructions to download the public-use National Household Education Survey (NHES) data in SPSS (*.sav) format
for use with the <code>readNHES</code> function.
The data originates from the <a href="https://nces.ed.gov/OnlineCodebook">NCES Online Codebook</a> zip files.
This function works for data from the years
1991, 1993, 1995, 1996, 1999, 2001, 2003, 2005, 2007, 2012, 2016, and 2019.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadNHES(
  years = c(1991, 1993, 1995, 1996, 1999, 2001, 2003, 2005, 2007, 2012, 2016, 2019)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadNHES_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years. Valid years are
1991, 1993, 1995, 1996, 1999, 2001, 2003, 2005, 2007, 2012, 2016, and 2019.
The instructions are the same for each year, this is used as reference only.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The NHES data files are additionally available from the <a href="https://nces.ed.gov/nhes/dataproducts.asp">NHES data product page</a>.  However,
the data files provided at that page do not include all available years of data, and contain inconsistent data file formats.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readNHES">readNHES</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#view instructions to manually download NHES data
downloadNHES()

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadPIAAC'>Download and Unzip PIAAC Files</h2><span id='topic+downloadPIAAC'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download PIAAC data to a
computer. Data come from the OECD website.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadPIAAC(root, cycle = 1, cache = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadPIAAC_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the PIAAC data should
be stored. Files are placed in a folder named PIAAC/cycle [cycle number].</p>
</td></tr>
<tr><td><code id="downloadPIAAC_+3A_cycle">cycle</code></td>
<td>
<p>a numeric value indicating the assessment cycle to download.
Valid cycle is 1 only.</p>
</td></tr>
<tr><td><code id="downloadPIAAC_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadPIAAC_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eric Buehler, Paul Bailey, and Trang Nguyen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# download all available data for PIAAC round 1 to "~/PIAAC/Round 1" folder
# root argument will vary by operating system conventions
downloadPIAAC(root="~/")

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadPIRLS'>Download and Unzip PIRLS Files</h2><span id='topic+downloadPIRLS'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download PIRLS data.
Data come from <a href="https://timssandpirls.bc.edu/">timssandpirls.bc.edu</a> zip files. This
function works for 2001, 2006, 2011, 2016, and 2021 data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadPIRLS(
  root,
  years = c(2001, 2006, 2011, 2016, 2021),
  cache = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadPIRLS_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the PIRLS
data should be stored. Files are placed in a
subdirectory named PIRLS/[year].</p>
</td></tr>
<tr><td><code id="downloadPIRLS_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years to download. Valid years are 2001, 2006, 2011, 2016, and 2021.</p>
</td></tr>
<tr><td><code id="downloadPIRLS_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadPIRLS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readPIRLS">readPIRLS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# root argument will vary by operating system conventions
downloadPIRLS(year=c(2006, 2011), root = "~/")

# cache=TRUE will download then process the datafiles
downloadPIRLS(year=2011, root = "~/", cache = TRUE)

# set verbose=FALSE for silent output
# if year not specified, download all years
downloadPIRLS(root="~/", verbose = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadPISA'>Download and Unzip PISA Files</h2><span id='topic+downloadPISA'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download PISA data to a
computer. Data come from the OECD website.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadPISA(
  root,
  years = c(2000, 2003, 2006, 2009, 2012, 2015, 2018),
  database = c("INT", "CBA", "FIN"),
  cache = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadPISA_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the PISA data should
be stored. Files are placed in a folder named PISA/[year].</p>
</td></tr>
<tr><td><code id="downloadPISA_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years to download. Valid years are 2000, 2003,
2006, 2009, 2012, 2015, and 2018.</p>
</td></tr>
<tr><td><code id="downloadPISA_+3A_database">database</code></td>
<td>
<p>a character vector to indicate which database to download from. For 2012,
three databases are available (<code>INT</code> = International, <code>CBA</code> = Computer-Based Assessment, and
<code>FIN</code> = Financial Literacy). For other years, only <code>INT</code> is available (for example, if PISA
2015 financial literacy is to be downloaded, the database argument should be set to <code>INT</code>).
Defaults to <code>INT</code>.</p>
</td></tr>
<tr><td><code id="downloadPISA_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadPISA_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses
<code><a href="utils.html#topic+download.file">download.file</a></code>
to download files from provided URLs. Some machines might require a different
user agent in HTTP(S) requests. If the downloading gives an error or behaves
unexpectedly (e.g., a zip file cannot be unzipped or a data file is
significantly smaller than expected), users can toggle <code>HTTPUserAgent</code>
options to find one that works for their machines. One common alternative option is
</p>
<p><code>options(HTTPUserAgent="Mozilla/5.0 (Windows NT 6.1; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0")</code>
</p>
<p>Beginning in the 2018 data files, the <code>SPSS_STU_COG.zip</code> source data file is a <code>DEFLATE64</code> compressed zip file.
This means that the user must manually extract the contained <code>CY07_MSU_STU_COG.sav</code> file using an external zip
program capable of handling <code>DEFLATE64</code> zip format, as existing R functions are unable to handle this zip format natively.
</p>


<h3>Author(s)</h3>

<p>Yuqi Liao, Paul Bailey, and Trang Nguyen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readPISA">readPISA</a></code>, <code><a href="utils.html#topic+download.file">download.file</a></code>, <code><a href="base.html#topic+options">options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# download PISA 2012 data (for all three databases)
downloadPISA(years = 2012, database = c("INT","CBA","FIN"), root="~/")

# download PISA 2009, 2012, and 2015 data (International Database only) 
# to C:/PISA/2009, C:/PISA/2012, and C:/PISA/2015 folders, respectively
downloadPISA(years = c(2009,2012,2015), root="~/")  

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadPISA_YAFS'>Instructions for Downloading and Unzipping PISA YAFS Files</h2><span id='topic+downloadPISA_YAFS'></span>

<h3>Description</h3>

<p>Provides instructions to download PISA YAFS data to be processed in <code>readPISA_YAFS</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadPISA_YAFS(years = c(2016))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadPISA_YAFS_+3A_years">years</code></td>
<td>
<p>an integer vector indicating the study year. Valid year is 2016 only.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readPISA_YAFS">readPISA_YAFS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# view instructions to manually download study data
downloadPISA_YAFS()

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadSSOCS'>Instructions for Downloading and Unzipping SSOCS Files</h2><span id='topic+downloadSSOCS'></span>

<h3>Description</h3>

<p>Provides instructions to download School Survey on Crime and Safety (SSOCS) data in SAS (*.sas7bdat) format
for use with the <code>readSSOCS</code> function.
The data originates from the SSOCS Data Products website at <a href="https://nces.ed.gov/surveys/ssocs/data_products.asp">nces.ed.gov</a>.
This function works for the following school year datasets: 2000 (1999&ndash;2000), 2004 (2003&ndash;2004), 2006 (2005&ndash;2006),
2008 (2007&ndash;2008), 2010 (2009&ndash;2010), 2016 (2015&ndash;2016), and 2018 (2017&ndash;2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadSSOCS(years = c(2000, 2004, 2006, 2008, 2010, 2016, 2018))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadSSOCS_+3A_years">years</code></td>
<td>
<p>an integer vector of the study years to download. Valid years are as follows:
2000, 2004, 2006, 2008, 2010, 2016, 2018 (see description).  The instructions are the same for each year, this is for reference only.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The year parameter value is shortened to the ending year of the school year (e.g., 2006 refers to the 2005&ndash;2006 school year data).
Manually downloading the data files is required to fulfill the data usage agreement.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readSSOCS">readSSOCS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#see instructions for downloading SSOCS Data
downloadSSOCS()

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadTALIS'>Download and Unzip TALIS Files</h2><span id='topic+downloadTALIS'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download TALIS data.
Data come from <a href="https://www.oecd.org/education/talis/">OECD TALIS site</a> international zip files. This
function works for 2008, 2013,and 2018 data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadTALIS(root, years = c(2008, 2013, 2018), cache = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadTALIS_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the TALIS
data should be stored. Files are placed in a
subdirectory named TALIS/[year].</p>
</td></tr>
<tr><td><code id="downloadTALIS_+3A_years">years</code></td>
<td>
<p>a numeric value indicating the assessment year. Available years are 2008, 2013, and 2018.</p>
</td></tr>
<tr><td><code id="downloadTALIS_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadTALIS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink and Trang Nguyen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readTALIS">readTALIS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# root argument will vary by operating system conventions
downloadTALIS(root = "~/", years = 2018)
  
# cache=TRUE will download then process the datafiles
downloadTALIS(root = "~/", years = 2015, cache = TRUE)
  
# set verbose=FALSE for silent output
# if year not specified, download all years
downloadTALIS(root="~/", verbose = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadTIMSS'>Download and Unzip TIMSS Files</h2><span id='topic+downloadTIMSS'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download TIMSS data.
Data come from <a href="https://timssandpirls.bc.edu/">timssandpirls.bc.edu</a> zip files. This
function works for 2003, 2007, 2011, 2015, and 2019 data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadTIMSS(
  root,
  years = c(2003, 2007, 2011, 2015, 2019),
  cache = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadTIMSS_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the TIMSS
data should be stored. Files are placed in a
subdirectory named TIMSS/[year].</p>
</td></tr>
<tr><td><code id="downloadTIMSS_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years to download. Valid years are 2003, 2007, 2011,
2015, and 2019.</p>
</td></tr>
<tr><td><code id="downloadTIMSS_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadTIMSS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readTIMSS">readTIMSS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# root argument will vary by operating system conventions
downloadTIMSS(year=c(2019, 2015, 2011), root = "~/")

# cache=TRUE will download then process the datafiles
downloadTIMSS(year=2015, root = "~/", cache = TRUE)

# set verbose=FALSE for silent output
# if year not specified, download all years
downloadTIMSS(root="~/", verbose = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='downloadTIMSSAdv'>Download and Unzip TIMSS Advanced Files</h2><span id='topic+downloadTIMSSAdv'></span>

<h3>Description</h3>

<p>Uses an Internet connection to download TIMSS Advanced data.
Data come from <a href="https://timssandpirls.bc.edu/">timssandpirls.bc.edu</a> zip files. This
function works for 1995, 2008, and 2015 data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadTIMSSAdv(
  root,
  years = c(1995, 2008, 2015),
  cache = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadTIMSSAdv_+3A_root">root</code></td>
<td>
<p>a character string indicating the directory where the TIMSS Advanced
data should be stored. Files are placed in a
subdirectory named TIMSSAdv/[year].</p>
</td></tr>
<tr><td><code id="downloadTIMSSAdv_+3A_years">years</code></td>
<td>
<p>an integer vector of the assessment years to download. Valid years are 1995, 2008, and 2015.</p>
</td></tr>
<tr><td><code id="downloadTIMSSAdv_+3A_cache">cache</code></td>
<td>
<p>a logical value set to process and cache the text (.txt) version of files.
This takes a very long time but saves time for future uses of
the data. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="downloadTIMSSAdv_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readTIMSSAdv">readTIMSSAdv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# root argument will vary by operating system conventions
downloadTIMSSAdv(year=c(2008, 2015), root = "~/")

# cache=TRUE will download then process the datafiles
downloadTIMSSAdv(year=2015, root = "~/", cache = TRUE)

# set verbose=FALSE for silent output
# if year not specified, download all years
downloadTIMSSAdv(root="~/", verbose = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='drawPVs.sdf'>Draw plausible values from an mml fit</h2><span id='topic+drawPVs.sdf'></span>

<h3>Description</h3>

<p>Draw plausible values from an mml fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdf'
drawPVs(
  x,
  npv = 5L,
  pvVariableNameSuffix = "_dire",
  data,
  stochasticBeta = FALSE,
  construct = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drawPVs.sdf_+3A_x">x</code></td>
<td>
<p>a fit from a call to <code><a href="#topic+mml.sdf">mml.sdf</a></code>, or a <code>summary.mml.sdf</code>, which is a  <code>summary</code> of
<code>mml.sdf</code> call.</p>
</td></tr>
<tr><td><code id="drawPVs.sdf_+3A_npv">npv</code></td>
<td>
<p>integer indicating the number of plausible values to draw</p>
</td></tr>
<tr><td><code id="drawPVs.sdf_+3A_pvvariablenamesuffix">pvVariableNameSuffix</code></td>
<td>
<p>suffix to append to the name of the new plausible values</p>
</td></tr>
<tr><td><code id="drawPVs.sdf_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or <code>light.edsurvey.data.frame</code> to which the plausible values will be added and from which the covariates and item responses will be taken to generate them</p>
</td></tr>
<tr><td><code id="drawPVs.sdf_+3A_stochasticbeta">stochasticBeta</code></td>
<td>
<p>logical when <code>TRUE</code> the regressopm coefficients will be drawn from their posterior distribution. Can also be a data frame of values (see Details).</p>
</td></tr>
<tr><td><code id="drawPVs.sdf_+3A_construct">construct</code></td>
<td>
<p>the construct to draw PVs for</p>
</td></tr>
<tr><td><code id="drawPVs.sdf_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>

<hr>
<h2 id='edsurvey.data.frame'>EdSurvey Class Constructors and Helpers</h2><span id='topic+edsurvey.data.frame'></span><span id='topic++24.edsurvey.data.frame'></span><span id='topic++24+3C-.edsurvey.data.frame'></span><span id='topic++25in+25+2Cedsurvey.data.frame+2CANY-method'></span><span id='topic++25in+25+2Cedsurvey.data.frame.list+2CANY-method'></span><span id='topic+getAttributes'></span><span id='topic+setAttributes'></span><span id='topic+getPSUVar'></span><span id='topic+getStratumVar'></span>

<h3>Description</h3>

<p>Two new classes in <code>EdSurvey</code> are described in this section: the <code>edsurvey.data.frame</code>
and <code>light.edsurvey.data.frame</code>. The <code>edsurvey.data.frame</code>
class stores metadata about survey data, and data are stored on the
disk (via the <code>LaF</code> package), allowing gigabytes of data to be used easily on a machine otherwise
inappropriate for manipulating large datasets.
The <code>light.edsurvey.data.frame</code> is typically generated
by the <code>getData</code> function and stores the data in a
<code>data.frame</code>.
Both classes use attributes to manage metadata and allow
for correct statistics to be used in calculating results; the
<code>getAttributes</code> acts as an accessor for these attributes, whereas
<code>setAttributes</code> acts as a mutator for the attributes.
As a convenience, <code>edsurvey.data.frame</code>
implements the <code>$</code> function to extract a variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edsurvey.data.frame(
  userConditions,
  defaultConditions,
  dataList = list(),
  weights,
  pvvars,
  subject,
  year,
  assessmentCode,
  dataType,
  gradeLevel,
  achievementLevels,
  omittedLevels,
  survey,
  country,
  psuVar,
  stratumVar,
  jkSumMultiplier,
  recodes = NULL,
  validateFactorLabels = FALSE,
  forceLower = TRUE,
  reqDecimalConversion = TRUE,
  fr2Path = NULL,
  dim0 = NULL,
  cacheDataLevelName = NULL
)

## S3 method for class 'edsurvey.data.frame'
x$i

## S3 replacement method for class 'edsurvey.data.frame'
x$name &lt;- value

## S4 method for signature 'edsurvey.data.frame,ANY'
x %in% table

## S4 method for signature 'edsurvey.data.frame.list,ANY'
x %in% table

getAttributes(data, attribute = NULL, errorCheck = TRUE)

setAttributes(data, attribute, value)

getPSUVar(
  data,
  weightVar = attributes(getAttributes(data, "weights"))[["default"]]
)

getStratumVar(
  data,
  weightVar = attributes(getAttributes(data, "weights"))[["default"]]
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="edsurvey.data.frame_+3A_userconditions">userConditions</code></td>
<td>
<p>a list of user conditions that includes subsetting or recoding conditions</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a list of default conditions that often are set for each survey</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_datalist">dataList</code></td>
<td>
<p>a list of <code>dataListItem</code> objects to model the data structure of the survey</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_weights">weights</code></td>
<td>
<p>a list that stores information regarding weight variables. See Details.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_pvvars">pvvars</code></td>
<td>
<p>a list that stores information regarding plausible values. See Details.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_subject">subject</code></td>
<td>
<p>a character that indicates the subject domain of the given data</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_year">year</code></td>
<td>
<p>a character or numeric that indicates the year of the given data</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_assessmentcode">assessmentCode</code></td>
<td>
<p>a character that indicates the code of the assessment.
Can be <code>National</code> or <code>International</code>.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_datatype">dataType</code></td>
<td>
<p>a character that indicates the unit level of the main data.
Examples include <code>Student</code>, <code>teacher</code>, <code>school</code>,
<code>Adult Data</code>.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_gradelevel">gradeLevel</code></td>
<td>
<p>a character that indicates the grade level of the given data</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_achievementlevels">achievementLevels</code></td>
<td>
<p>a list of achievement-level categories and cutpoints</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>a list of default omitted levels for the given data</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_survey">survey</code></td>
<td>
<p>a character that indicates the name of the survey</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_country">country</code></td>
<td>
<p>a character that indicates the country of the given data</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_psuvar">psuVar</code></td>
<td>
<p>a character that indicates the PSU sampling unit variable. Ignored when weights have <code>psuVar</code> defined.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_stratumvar">stratumVar</code></td>
<td>
<p>a character that indicates the stratum variable. Ignored when weights have <code>stratumVar</code> defined.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_jksummultiplier">jkSumMultiplier</code></td>
<td>
<p>a numeric value of the jackknife coefficient (used in calculating the jackknife replication estimation)</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_recodes">recodes</code></td>
<td>
<p>a list of variable recodes of the given data</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_validatefactorlabels">validateFactorLabels</code></td>
<td>
<p>a Boolean that indicates whether the <code>getData</code> function needs to validate factor variables</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_forcelower">forceLower</code></td>
<td>
<p>a Boolean; when set to <code>TRUE</code>, will automatically lowercase variable names</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_reqdecimalconversion">reqDecimalConversion</code></td>
<td>
<p>a Boolean; when set to <code>TRUE</code>, a <code>getData</code> call will multiply the raw file value by a decimal multiplier</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_fr2path">fr2Path</code></td>
<td>
<p>a character file location for NAEP assessments to identify the location of the codebook file in <code>fr2</code> format</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_dim0">dim0</code></td>
<td>
<p>numeric vector of length two. To speed construction, the dimensions of the data can be provided</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_cachedatalevelname">cacheDataLevelName</code></td>
<td>
<p>a character value set to match the named element in the <code>dataList</code> to utilize the data caching scheme.  See details.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_x">x</code></td>
<td>
<p>an <code>edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_i">i</code></td>
<td>
<p>a character, the column name to extract</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_name">name</code></td>
<td>
<p>a character vector of the column to edit</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_value">value</code></td>
<td>
<p>outside of the assignment context, new value of the given <code>attribute</code></p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_table">table</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or <code>edsurvey.data.frame.list</code> where <code>x</code> is searched for</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_attribute">attribute</code></td>
<td>
<p>a character, name of an attribute to get or set</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_errorcheck">errorCheck</code></td>
<td>
<p>logical; see Details</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame_+3A_weightvar">weightVar</code></td>
<td>
<p>a character indicating the full sample weights. Required in <code>getPSUVar</code> and <code>getStratumVar</code> when there is no default weight.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>weight</code> list has an element named after each weight variable name
that is a list with elements <code>jkbase</code> and <code>jksuffixes</code>. The
<code>jkbase</code> variable is a single character indicating the jackknife replicate
weight base name, whereas <code>jksuffixes</code> is a vector with one element for each
jackknife replicate weight. When the two are pasted together, they should form
the complete set of the jackknife replicate weights. The <code>weights</code> argument
also can have an attribute that is the default weight. If the primary sampling
unit and stratum variables change by weight, they also can be defined on the weight
list as <code>psuVar</code> and <code>stratumVar</code>. When this option is used, it overrides
the <code>psuVar</code> and <code>stratumVar</code> on the <code>edsurvey.data.frame</code>,
which can be left blank. A weight must define only one of <code>psuVar</code>
and <code>stratumVar</code>.
</p>
<p>The <code>pvvars</code> list has an element for each subject or subscale score
that has plausible values. Each element is a list with a <code>varnames</code>
element that indicates the column names of the plausible values and an
<code>achievementLevel</code> argument that is a named vector of the
achievement-level cutpoints.
</p>
<p>An <code>edsurvey.data.frame</code> implements a unique data caching mechanism that allows users to create and merge data columns for flexibility.
This <code>cache</code> object is a single <code>data.frame</code> that is an element in the <code>edsurvey.data.frame</code>. To accommodate studies with complex data models
the cache can only support one data level at this time. The <code>cacheDataLevelName</code> parameter indicates which named element in the <code>dataList</code>
the cache is indicated. The default value <code>cacheDataLevelName = NULL</code> will set the first item in the <code>dataList</code> as the <code>cache</code> level for an <code>edsurvey.data.frame</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>edsurvey.data.frame</code> with the following elements:
</p>
<p><em>Elements that store data connections and data codebooks</em>
</p>
<table>
<tr><td><code>dataList</code></td>
<td>
<p>a <code>list</code> object containing the surveys <code>dataListItem</code> objects</p>
</td></tr>
</table>
<p><em>Elements that store sample design and default subsetting information of the given survey data</em>
</p>
<table>
<tr><td><code>userConditions</code></td>
<td>
<p>a list containing all user conditions, set using the <code>subset.edsurvey.data.frame</code> method</p>
</td></tr>
<tr><td><code>defaultConditions</code></td>
<td>
<p>the default subsample conditions</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>a list containing the weights. See Details.</p>
</td></tr>
<tr><td><code>stratumVar</code></td>
<td>
<p>a character that indicates the default strata identification variable name in the data. Often used in Taylor series estimation.</p>
</td></tr>
<tr><td><code>psuVar</code></td>
<td>
<p>a character that indicates the default PSU (sampling unit) identification variable name in the data. Often used in Taylor series estimation.</p>
</td></tr>
<tr><td><code>pvvars</code></td>
<td>
<p>a list containing the plausible values. See Details.</p>
</td></tr>
<tr><td><code>achievementLevels</code></td>
<td>
<p>default achievement cutoff scores and names. See Details.</p>
</td></tr>
<tr><td><code>omittedLevels</code></td>
<td>
<p>the levels of the factor variables that will be omitted from the <code>edsurvey.data.frame</code></p>
</td></tr>
</table>
<p><em>Elements that store descriptive information of the survey</em>
</p>
<table>
<tr><td><code>survey</code></td>
<td>
<p>the type of survey data</p>
</td></tr>
<tr><td><code>subject</code></td>
<td>
<p>the subject of the data</p>
</td></tr>
<tr><td><code>year</code></td>
<td>
<p>the year of assessment</p>
</td></tr>
<tr><td><code>assessmentCode</code></td>
<td>
<p>the assessment code</p>
</td></tr>
<tr><td><code>dataType</code></td>
<td>
<p>the type of data (e.g., <code>student</code> or <code>school</code>)</p>
</td></tr>
<tr><td><code>gradeLevel</code></td>
<td>
<p>the grade of the dataset contained in the <code>edsurvey.data.frame</code></p>
</td></tr>
</table>
<p><em>Elements used in <code>mml.sdf</code></em>
</p>
<table>
<tr><td><code>dichotParamTab</code></td>
<td>
<p>IRT item parameters for dichotomous items in a data frame</p>
</td></tr>
<tr><td><code>polyParamTab</code></td>
<td>
<p>IRT item parameters for polytomous items in a data frame</p>
</td></tr>
<tr><td><code>adjustedData</code></td>
<td>
<p>IRT item parameter adjustment information in a data frame</p>
</td></tr>
<tr><td><code>testData</code></td>
<td>
<p>IRT transformation constants in a data frame</p>
</td></tr>
<tr><td><code>scoreCard</code></td>
<td>
<p>item scoring information in a data frame</p>
</td></tr>
<tr><td><code>scoreDict</code></td>
<td>
<p>generic scoring information in a data frame</p>
</td></tr>
<tr><td><code>scoreFunction</code></td>
<td>
<p>a function that turns the variables with items in them into numeric scores</p>
</td></tr>
</table>


<h3>EdSurvey Classes</h3>

<p><code>edsurvey.data.frame</code> is an object that stores connection to data on the
disk along with important survey sample design information.
</p>
<p><code>edsurvey.data.frame.list</code> is a list of <code>edsurvey.data.frame</code>
objects. It often is used in trend or cross-regional analysis in the
<code><a href="#topic+gap">gap</a></code> function. See <code><a href="#topic+edsurvey.data.frame.list">edsurvey.data.frame.list</a></code> for
more information on how to create an <code>edsurvey.data.frame.list</code>. Users
also can refer to the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Trend.pdf"><em>Using EdSurvey for Trend Analysis</em></a>
for examples.
</p>
<p>Besides <code>edsurvey.data.frame</code> class, the <code>EdSurvey</code> package also
implements the <code>light.edsurvey.data.frame</code> class, which can be used by both
<code>EdSurvey</code> and non-<code>EdSurvey</code> functions. More particularly,
<code>light.edsurvey.data.frame</code> is a <code>data.frame</code> that has basic
survey and sample design information (i.e., plausible values and weights), which
will be used for variance estimation in analytical functions. Because it
also is a base R <code>data.frame</code>, users can apply base R functions for
data manipulation.
See the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-getData.pdf"><em>Using the <code>getData</code> Function in EdSurvey</em></a>
for more examples.
</p>
<p>Many functions will remove attributes from a data frame, such as
a <code>light.edsurvey.data.frame</code>, and the
<code><a href="#topic+rebindAttributes">rebindAttributes</a></code> function can add them back.
</p>
<p>Users can get a <code>light.edsurvey.data.frame</code> object by using the
<code><a href="#topic+getData">getData</a></code> method with <code>addAttributes=TRUE</code>.
</p>


<h3>Basic Methods for EdSurvey Classes</h3>

<p><em>Extracting a column from an <code>edsurvey.data.frame</code></em>
</p>
<p>Users can extract a column from an <code>edsurvey.data.frame</code> object using <code>$</code> or <code>[]</code> like a normal data frame.
</p>
<p><em>Extracting and updating attributes of an object of class <code>edsurvey.data.frame</code> or <code>light.edsurvey.data.frame</code></em>
</p>
<p>Users can use the <code>getAttributes</code> method to extract any attribute of
an <code>edsurvey.data.frame</code> or a <code>light.edsurvey.data.frame</code>.
The <code>errorCheck</code> parameter has a default value of<code>TRUE</code>, which throws an error if an attribute is not found.
Setting <code>errorCheck = FALSE</code> will suppress error checking, and return <code>NULL</code> if an attribute can't be found.
</p>
<p>A <code>light.edsurvey.data.frame</code> will not have attributes related to data connection
because data have already been read in memory.
</p>
<p>If users want to update an attribute (i.e., <code>omittedLevels</code>), they can
use the <code>setAttributes</code> method.
</p>


<h3>Author(s)</h3>

<p>Tom Fink, Trang Nguyen, and Paul Bailey
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rebindAttributes">rebindAttributes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# run a base R function on a column of edsurvey.data.frame
table(sdf$dsex)
# assignment
table(sdf$b013801)
sdf$books &lt;- ifelse(sdf$b013801 %in% c("0-10", "11-25"), "0-25 books", "26+ books")
table(sdf$books, sdf$b013801)

# extract default omitted levels of NAEP primer data
getAttributes(sdf, "omittedLevels") #[1] "Multiple" NA         "Omitted"

# update default omitted levels of NAEP primer data
sdf &lt;- setAttributes(sdf, "omittedLevels", c("Multiple", "Omitted", NA, "(Missing)"))
getAttributes(sdf, "omittedLevels") #[1] "Multiple"  "Omitted"   NA          "(Missing)"

## End(Not run)
</code></pre>

<hr>
<h2 id='edsurvey.data.frame.list'>EdSurvey Dataset Vectorization</h2><span id='topic+edsurvey.data.frame.list'></span><span id='topic+append.edsurvey.data.frame.list'></span>

<h3>Description</h3>

<p>The <code>edsurvey.data.frame.list</code> function creates an
<code>edsurvey.data.frame.list</code> object from a series of
<code>edsurvey.data.frame</code> objects.
<code>append.edsurvey.data.frame.list</code> creates an
<code>edsurvey.data.frame.list</code> from two
<code>edsurvey.data.frame</code> or <code>edsurvey.data.frame.list</code> objects.
</p>
<p>An <code>edsurvey.data.frame.list</code> is useful for looking at
data, for example, across time or graphically, and reduces
repetition in function calls.
The user may specify a variable that varies across the
<code>edsurvey.data.frame</code> objects that is
then included in further output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edsurvey.data.frame.list(datalist, cov = NULL, labels = NULL)

append.edsurvey.data.frame.list(sdfA, sdfB, labelsA = NULL, labelsB = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="edsurvey.data.frame.list_+3A_datalist">datalist</code></td>
<td>
<p>a list of <code>edsurvey.data.frame</code>s to be combined</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame.list_+3A_cov">cov</code></td>
<td>
<p>a character vector that indicates what varies across
the <code>edsurvey.data.frame</code> objects.
Guessed if not supplied. For example,
if several <code>edsurvey.data.frame</code>s for several
different countries are supplied, then <code>cov</code> would
be set to the country.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame.list_+3A_labels">labels</code></td>
<td>
<p>a character vector that specifies labels. Must be the
same length
as <code>datalist</code>. Not needed if <code>cov</code> exists or can be
guessed. See Examples.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame.list_+3A_sdfa">sdfA</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or an <code>edsurvey.data.frame.list</code> to be combined</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame.list_+3A_sdfb">sdfB</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or an <code>edsurvey.data.frame.list</code> to be combined</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame.list_+3A_labelsa">labelsA</code></td>
<td>
<p>a character vector that specifies <code>labels</code> for <code>sdfA</code> when creating
the new <code>edsurvey.data.frame.list</code>.</p>
</td></tr>
<tr><td><code id="edsurvey.data.frame.list_+3A_labelsb">labelsB</code></td>
<td>
<p>a character vector that specifies <code>labels</code> for <code>sdfB</code> when creating
the new <code>edsurvey.data.frame.list</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>edsurvey.data.frame.list</code> can be used in place of an
<code>edsurvey.data.frame</code> in function calls, and results are returned
for each of the component <code>edsurvey.data.frame</code>s, with the
organization of the results varying by the particular method.
</p>
<p>An <code>edsurvey.data.frame.list</code> can be created from several
<code>edsurvey.data.frame</code> objects that are related;
for example, all are NAEP mathematics assessments but have one or more
differences (e.g.,  they are all from different years).
Another example could be data from multiple countries for an
international assessment.
</p>
<p>When <code>cov</code> and <code>labels</code> are both missing, <code>edsurvey.data.frame.list</code>
attempts to guess what variables may be varying and uses those. When there are no
varying covariates, generic labels are automatically generated.
</p>


<h3>Value</h3>

<p><code>edsurvey.data.frame.list</code> returns an <code>edsurvey.data.frame.list</code> with
elements
</p>
<table>
<tr><td><code>datalist</code></td>
<td>
<p>a list of <code>edsurvey.data.frame</code> objects</p>
</td></tr>
<tr><td><code>covs</code></td>
<td>
<p>a character vector of key variables that vary within
the <code>edsurvey.data.frame.list</code>.
When labels are included, they will be included in
<code>covs</code>. In the unusual circumstance that <code>sdfA</code> or <code>sdfB</code>
is an <code>edsurvey.data.frame.list</code>
has <code>covs</code>, and labels are not supplied, the <code>covs</code>
are simply pasted together with colons between them.</p>
</td></tr>
</table>
<p><code>append.edsurvey.data.frame.list</code> returns an <code>edsurvey.data.frame.list</code> with
elements
</p>
<table>
<tr><td><code>datalist</code></td>
<td>
<p>a list of <code>edsurvey.data.frame</code> objects</p>
</td></tr>
<tr><td><code>covs</code></td>
<td>
<p>a character vector of key variables that vary within
the <code>edsurvey.data.frame.list</code>.
When labels are included, they will be included in
<code>covs</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Bailey, Huade Huo
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# NOTE: the following code would not normally have to be run but is used here
# to generate demo data.
# Specifically, make subsets of sdf by the scrpsu variable,
# "Scrambled PSU and school code"
sdfA &lt;- subset(sdf, scrpsu %in% c(5,45,56))
sdfB &lt;- subset(sdf, scrpsu %in% c(75,76,78))
sdfC &lt;- subset(sdf, scrpsu %in% 100:200)
sdfD &lt;- subset(sdf, scrpsu %in% 201:300)

# construct an edsurvey.data.frame.list from these four data sets
sdfl &lt;- edsurvey.data.frame.list(list(sdfA, sdfB, sdfC, sdfD),
                                 labels=c("A locations",
                                          "B locations",
                                          "C locations",
                                          "D locations"))

# alternative method of building
sdfl2 &lt;- sdfA + sdfB + sdfC

# check contents
sdfA %in% sdfl
# note %in% checks by survey (NAEP 2005 Math for sdf,
# sdfA, sdfB, sdfC, and sdfD) not by subset, so this also return TRUE
sdfD %in% sdfl2

# this shows how these datasets will be described
sdfl$covs 
# get the gaps between Male and Female for each data set
gap1 &lt;- gap("composite", sdfl, dsex=="Male", dsex=="Female")
gap1

# make combine sdfA and sdfB
sdfl1a &lt;- edsurvey.data.frame.list(list(sdfA, sdfB),
                                   labels=c("A locations",
                                            "B locations"))

# combine sdfC and sdfD
sdfl1b &lt;- edsurvey.data.frame.list(list(sdfC, sdfD),
                                   labels=c("C locations",
                                            "D locations"))

# append to make sdf3 the same as sdfl
sdfl3 &lt;- append.edsurvey.data.frame.list(sdfl1a, sdfl1b)
identical(sdfl, sdfl3) #TRUE

# append to make sdf4 the same as sdfl
sdfl4 &lt;- append.edsurvey.data.frame.list(
  append.edsurvey.data.frame.list(sdfl1a, sdfC, labelsB = "C locations"),
  sdfD,
  labelsB = "D locations")
identical(sdfl, sdfl4) #TRUE

# show label deconflicting
downloadTIMSS(root="~/", years=c(2011, 2015))
t11 &lt;- readTIMSS("~/TIMSS/2011", countries = c("fin", "usa"), gradeLvl = 4)
t15 &lt;- readTIMSS("~/TIMSS/2015", countries = c("fin", "usa"), gradeLvl = 4)
# these would not be unique
t11$covs
t15$covs
# resulting values includes year now
t11_15 &lt;- append.edsurvey.data.frame.list(t11, t15)
t11_15$covs


## End(Not run)
</code></pre>

<hr>
<h2 id='edsurveyTable'>EdSurvey Tables With Conditional Means</h2><span id='topic+edsurveyTable'></span>

<h3>Description</h3>

<p>Returns a summary table (as a <code><a href="base.html#topic+data.frame">data.frame</a></code>)
that shows the number of students, the percentage of students, and the mean
value of the outcome (or left-hand side) variable by the
predictor (or right-hand side) variable(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edsurveyTable(
  formula,
  data,
  weightVar = NULL,
  jrrIMax = 1,
  pctAggregationLevel = NULL,
  returnMeans = TRUE,
  returnSepct = TRUE,
  varMethod = c("jackknife", "Taylor"),
  drop = FALSE,
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  returnVarEstInputs = FALSE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="edsurveyTable_+3A_formula">formula</code></td>
<td>
<p>object of class <code><a href="stats.html#topic+formula">formula</a></code>,
potentially with
a subject scale or subscale
on the left-hand side and
variables to tabulate
on the right-hand side.
When the left-hand side of the
formula is omitted and <code>returnMeans</code> is <code>TRUE</code>,
then the default subject scale or subscale is used.
You can find the default composite scale and all subscales
using the function <code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>.
Note that the order of the right-hand side variables affects the output.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_data">data</code></td>
<td>
<p>object of class <code>edsurvey.data.frame</code>. See <code><a href="#topic+readNAEP">readNAEP</a></code>
for how to generate an <code>edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_weightvar">weightVar</code></td>
<td>
<p>character string indicating the weight variable to use.
Note that only the name of the
weight variable needs to be included here, and any
replicate weights will be automatically included.
When this argument is <code>NULL</code>, the function uses the default.
Use <code><a href="#topic+showWeights">showWeights</a></code> to find the default.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>a numeric value; when using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=1</code>, uses the
sampling variance from the first plausible value as the component for sampling variance estimation. The <code class="reqn">V_{jrr}</code>
term (see the Details section of
<code><a href="#topic+lm.sdf">lm.sdf</a></code> to see the definition of <code class="reqn">V_{jrr}</code>) can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all of the plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_pctaggregationlevel">pctAggregationLevel</code></td>
<td>
<p>the percentage variable sums up to 100 for the first
<code>pctAggregationLevel</code> columns.
So, when set to <code>0</code>, the <code>PCT</code> column adds up to 1
across the entire sample.
When set to <code>1</code>, the <code>PCT</code> column adds up to 1
within each level of the first variable on the
right-hand side of the formula; when set to <code>2</code>,
then the percentage
adds up to 100 within the interaction of the
first and second variable, and so on.
Default is <code>NULL</code>, which will result in the
lowest feasible aggregation level.
See Examples section.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_returnmeans">returnMeans</code></td>
<td>
<p>a logical value; set to <code>TRUE</code> (the default) to get the <code>MEAN</code> and
<code>SE(MEAN)</code> columns in the returned table described in the Value section.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_returnsepct">returnSepct</code></td>
<td>
<p>set to <code>TRUE</code> (the default) to get the <code>SEPCT</code> column in the returned table described in the Value section.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_varmethod">varMethod</code></td>
<td>
<p>a character set to <code>jackknife</code> or <code>Taylor</code> that indicates the variance estimation method
to be used.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_drop">drop</code></td>
<td>
<p>a logical value. When set to the default value of <code>FALSE</code>, when a single column is returned, it is still represented as a <code>data.frame</code> and is
not converted to a vector.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, drops those levels of all factor variables that are specified
in an <code>edsurvey.data.frame</code>. Use <code>print</code> on an <code>edsurvey.data.frame</code> to see the omitted levels.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, uses the default conditions stored in an <code>edsurvey.data.frame</code>
to subset the data. Use <code>print</code> on an <code>edsurvey.data.frame</code> to see the default conditions.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>. Can be set as
<code>recode</code> <code>=</code> <code>list(var1</code> <code>=</code> <code>list(from</code> <code>=</code> <code>c("a", "b", "c"),</code> <code>to</code> <code>=</code> <code>"c"))</code>.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_returnvarestinputs">returnVarEstInputs</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the
inputs to the jackknife and imputation variance
estimates, which allows for
the computation
of covariances between estimates.</p>
</td></tr>
<tr><td><code id="edsurveyTable_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method can be used to generate a simple one-way, two-way, or
<em>n</em>-way
table with unweighted and weighted <em>n</em> values and percentages. It also
can calculate the average of the subject scale or subscale for students at
each level of the cross-tabulation table.
</p>
<p>A detailed description of all statistics is given in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>.
</p>


<h3>Value</h3>

<p>A table with the following columns:
</p>
<table>
<tr><td><code>RHS levels</code></td>
<td>
<p>one column for each right-hand side variable. Each row
regards students who are at the levels shown in that row.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>count of the number of students in the survey in the <code>RHS levels</code></p>
</td></tr>
<tr><td><code>WTD_N</code></td>
<td>
<p>the weighted <em>N</em> count of students in the survey in <code>RHS levels</code></p>
</td></tr>
<tr><td><code>PCT</code></td>
<td>
<p>the percentage of students at the aggregation level specified by <code>pctAggregationLevel</code> (see Arguments).
See the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
in the section
&ldquo;Estimation of Weighted Percentages&rdquo; and its first subsection
&ldquo;Estimation of Weighted Percentages When Plausible Values Are Not Present.&rdquo;</p>
</td></tr>
<tr><td><code>SE(PCT)</code></td>
<td>
<p>the standard  error of the percentage, accounting
for the survey sampling methodology. When <code>varMethod</code>
is the <code>jackknife</code>, the calculation of this column is
described in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
in the section
&ldquo;Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Not Present, Using the Jackknife Method.&rdquo;
When <code>varMethod</code> is set to <code>Taylor</code>, the calculation of this column is described in
&ldquo;Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Not Present, Using the Taylor Series Method.&rdquo;
</p>
</td></tr>
<tr><td><code>MEAN</code></td>
<td>
<p>the mean assessment score for units in the <code>RHS levels</code>, calculated according to the  vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
in the section
&ldquo;Estimation of Weighted Means When Plausible Values Are Present.&rdquo;</p>
</td></tr>
<tr><td><code>SE(MEAN)</code></td>
<td>
<p>the standard error of the <code>MEAN</code> column (the mean assessment score for units in the <code>RHS levels</code>), calculated according to the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
in the sections
&ldquo;Estimation of Standard Errors of Weighted Means When Plausible Values Are Present, Using the Jackknife Method&rdquo;
or
&ldquo;Estimation of Standard Errors of Weighted Means When Plausible Values Are Present, Using the Taylor Series Method,&rdquo;
depending on the value of <code>varMethod</code>.</p>
</td></tr>
</table>
<p>When <code>returnVarEstInputs</code> is <code>TRUE</code>, two additional elements are
returned. These are <code>meanVarEstInputs</code> and <code>pctVarEstInputs</code> and
regard the <code>MEAN</code> and <code>PCT</code> columns, respectively. These two
objects can be used for calculating covariances with
<code><a href="#topic+varEstToCov">varEstToCov</a></code>.
</p>


<h3>Author(s)</h3>

<p>Paul Bailey and Ahmad Emad
</p>


<h3>References</h3>

<p>Binder, D. A. (1983). On the variances of asymptotically normal estimators from complex surveys. <em>International Statistical Review</em>, <em>51</em>(3), 279&ndash;292.
</p>
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>. New York, NY: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)

sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# create a table that shows only the breakdown of dsex
edsurveyTable(composite ~ dsex, data=sdf, returnMeans=FALSE, returnSepct=FALSE)

# create a table with composite scores by dsex
edsurveyTable(composite ~ dsex, data=sdf)

# add a second variable
edsurveyTable(composite ~ dsex + b017451, data=sdf)

# add a second variable, do not omit any levels
edsurveyTable(composite ~ dsex + b017451 + b003501, data=sdf, omittedLevels=FALSE)

# add a second variable, do not omit any levels, change aggregation level
edsurveyTable(composite ~ dsex + b017451 + b003501, data=sdf, omittedLevels=FALSE,
	            pctAggregationLevel=0)

edsurveyTable(composite ~ dsex + b017451 + b003501, data=sdf, omittedLevels=FALSE,
	            pctAggregationLevel=1)

edsurveyTable(composite ~ dsex + b017451 + b003501, data=sdf, omittedLevels=FALSE,
	            pctAggregationLevel=2)

# variance estimation using the Taylor series 
edsurveyTable(composite ~ dsex + b017451 + b003501, data=sdf, varMethod="Taylor")

## End(Not run)
</code></pre>

<hr>
<h2 id='edsurveyTable2pdf'>PDF File From an edsurveyTable</h2><span id='topic+edsurveyTable2pdf'></span>

<h3>Description</h3>

<p>Produces the LaTeX code and compiles to a PDF file from the <code>edsurveyTable</code> results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edsurveyTable2pdf(
  data,
  formula,
  caption = NULL,
  filename = "",
  toCSV = "",
  returnMeans = TRUE,
  estDigits = 2,
  seDigits = 3
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="edsurveyTable2pdf_+3A_data">data</code></td>
<td>
<p>the result of a call to <code><a href="#topic+edsurveyTable">edsurveyTable</a></code></p>
</td></tr>
<tr><td><code id="edsurveyTable2pdf_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>LHS ~ RHS</code> to cast the <code>edsurveyTable</code>
results from long format to wide format. This formula takes the form
<code>LHS ~ RHS</code> (e.g., <code>var1 + var2 ~ var3</code>).
The order of the entries in the formula is essential.</p>
</td></tr>
<tr><td><code id="edsurveyTable2pdf_+3A_caption">caption</code></td>
<td>
<p>character vector of length one or two containing the table's caption or title.
If the length is two, the second item is the &ldquo;short caption&rdquo; used when LaTeX generates
a <code>List of Tables</code>.
Set to <code>NULL</code> to suppress the caption. Default value is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="edsurveyTable2pdf_+3A_filename">filename</code></td>
<td>
<p>a character string containing filenames and paths. By default (<code>filename = ""</code>),
table will be saved in the working directory (<code>getwd()</code>).
Use <code>filename = "CONSOLE"</code> to
print LaTeX code in R console without generating a PDF file.</p>
</td></tr>
<tr><td><code id="edsurveyTable2pdf_+3A_tocsv">toCSV</code></td>
<td>
<p>a character string containing filenames and paths of .csv table output.
<code>""</code> indicates no .csv output. <code>toCSV</code> is
independent to <code>filename</code>, so both
a csv file and PDF file would be generated if both <code>filename</code>
and <code>toCSV</code> were specified.</p>
</td></tr>
<tr><td><code id="edsurveyTable2pdf_+3A_returnmeans">returnMeans</code></td>
<td>
<p>a logical value set to <code>TRUE</code> (the default) to generate a PDF with
the <code>MEAN</code> and <code>SE(MEAN)</code>. It is set to <code>FALSE</code> to generate a PDF with
the <code>PCT</code> and <code>SE(PCT)</code>. See Value
in <code><a href="#topic+edsurveyTable">edsurveyTable</a></code>.</p>
</td></tr>
<tr><td><code id="edsurveyTable2pdf_+3A_estdigits">estDigits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used for estimates.
Negative values are allowed. See Details.</p>
</td></tr>
<tr><td><code id="edsurveyTable2pdf_+3A_sedigits">seDigits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used for standard errors.
Negative values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rounding to a negative number of digits means rounding to a power of 10,
so, for example, <code>estDigits = -2</code> rounds estimates to the nearest hundred.
</p>


<h3>Note</h3>

<p>For more details, see the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-LaTeXtables.pdf"><em>Producing <code>LaTeX</code> Tables From <code>edsurveyTable</code> Results With <code>edsurveyTable2pdf</code></em></a>.
</p>


<h3>Author(s)</h3>

<p>Huade Huo
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# create a table with composite scores by dsex and b017451
est1 &lt;- edsurveyTable(composite ~ dsex + b017451, sdf)

# create a table with csv output
edsurveyTable2pdf(data = est1, 
                  formula = b017451~dsex, 
                  toCSV = "C:/example table.csv",
                  filename = "C:/example table.pdf",
                  returnMeans = FALSE)

# create a pdf file using the default subject scale or subscale
# and keep two digits for estimates and three digits for SE after decimal point
edsurveyTable2pdf(est1, b017451~dsex, 
                  returnMeans = TRUE, estDigits = 2, seDigits = 3)

# create a pdf file using the percentage of students at the 
# aggregation level specified by \code{pctAggregationLevel}
# output will be saved as "C:/example table.pdf"
edsurveyTable2pdf(est1, 
                  b017451~dsex, 
                  "C:/example table.pdf",
                  returnMeans = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='gap'>Gap Analysis</h2><span id='topic+gap'></span>

<h3>Description</h3>

<p>Compares the average levels of a variable between two groups
that potentially share members.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gap(
  variable,
  data,
  groupA = "default",
  groupB = "default",
  percentiles = NULL,
  achievementLevel = NULL,
  achievementDiscrete = FALSE,
  stDev = FALSE,
  targetLevel = NULL,
  weightVar = NULL,
  jrrIMax = 1,
  varMethod = c("jackknife"),
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  referenceDataIndex = 1,
  returnVarEstInputs = FALSE,
  returnSimpleDoF = FALSE,
  returnSimpleN = FALSE,
  returnNumberOfPSU = FALSE,
  noCov = FALSE,
  pctMethod = c("unbiased", "symmetric", "simple"),
  includeLinkingError = FALSE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gap_+3A_variable">variable</code></td>
<td>
<p>a character indicating the variable to be compared,
potentially with a subject scale or subscale</p>
</td></tr>
<tr><td><code id="gap_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="gap_+3A_groupa">groupA</code></td>
<td>
<p>an expression or character expression that defines a condition for the subset.
This subset will be compared to <code>groupB</code>. If not specified, it will define
a whole sample as in <code>data</code>.</p>
</td></tr>
<tr><td><code id="gap_+3A_groupb">groupB</code></td>
<td>
<p>an expression or character expression that defines a condition for the subset.
This subset will be compared to <code>groupA</code>. If not specified, it will define
a whole sample as in <code>data</code>. If set to <code>NULL</code>, estimates for the second group
will be dropped.</p>
</td></tr>
<tr><td><code id="gap_+3A_percentiles">percentiles</code></td>
<td>
<p>a numeric vector. The <code>gap</code> function calculates the
mean when this
argument is omitted or set to <code>NULL</code>. Otherwise,
the gap at the percentile given is calculated.</p>
</td></tr>
<tr><td><code id="gap_+3A_achievementlevel">achievementLevel</code></td>
<td>
<p>the achievement level(s) at which percentages
should be calculated</p>
</td></tr>
<tr><td><code id="gap_+3A_achievementdiscrete">achievementDiscrete</code></td>
<td>
<p>a logical indicating if the achievement level
specified in the <code>achievementLevel</code>
argument should be interpreted as discrete
so that
just the percentage in that particular achievement
level
will be included. Defaults to <code>FALSE</code>
so that
the percentage at or above that achievement level
will be
included in the percentage.</p>
</td></tr>
<tr><td><code id="gap_+3A_stdev">stDev</code></td>
<td>
<p>a logical, set to <code>TRUE</code> to calculate the gap in standard deviations.</p>
</td></tr>
<tr><td><code id="gap_+3A_targetlevel">targetLevel</code></td>
<td>
<p>a character string. When specified, calculates the gap in
the percentage of students at
<code>targetLevel</code> in the <code>variable</code> argument. This is useful for
comparing the gap in the percentage of students at a
survey response level.</p>
</td></tr>
<tr><td><code id="gap_+3A_weightvar">weightVar</code></td>
<td>
<p>a character indicating the weight variable to use.
See Details.</p>
</td></tr>
<tr><td><code id="gap_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>a numeric value; when using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=1</code>, uses the
sampling variance from the first plausible value as the component for sampling variance estimation. The <code>Vjrr</code>
term, or sampeling variance term, can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="gap_+3A_varmethod">varMethod</code></td>
<td>
<p>deprecated parameter, <code>gap</code> always uses the jackknife variance estimation</p>
</td></tr>
<tr><td><code id="gap_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of
<code>TRUE</code>, drops those levels of
all factor variables.
Use <code>print</code> on an <code>edsurvey.data.frame</code>
to see the omitted levels.</p>
</td></tr>
<tr><td><code id="gap_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value
of <code>TRUE</code>, uses the default
conditions stored in <code>edsurvey.data.frame</code>
to subset the data.
Use <code>print</code> on an <code>edsurvey.data.frame</code>
to see the default conditions.</p>
</td></tr>
<tr><td><code id="gap_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>.
Can be set as
<code>recode</code> <code>=</code> <code>list(var1</code> <code>=</code>
<code>list(from</code> <code>=</code> <code>c("a",</code> <code>"b",</code>
<code>"c"),</code> <code>to</code> <code>=</code> <code>"d"))</code>.</p>
</td></tr>
<tr><td><code id="gap_+3A_referencedataindex">referenceDataIndex</code></td>
<td>
<p>a numeric used only when the <code>data</code> argument is an
<code>edsurvey.data.frame.list</code>,
indicating which dataset is the reference
dataset that other datasets are compared with.
Defaults to 1.</p>
</td></tr>
<tr><td><code id="gap_+3A_returnvarestinputs">returnVarEstInputs</code></td>
<td>
<p>a logical value; set to <code>TRUE</code> to return the
inputs to the jackknife and imputation variance
estimates which allows for the
computation
of covariances between estimates.</p>
</td></tr>
<tr><td><code id="gap_+3A_returnsimpledof">returnSimpleDoF</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the degrees
of freedom for some statistics (see Value
section) that do not have a
<em>t</em>-test; useful primarily for further computation</p>
</td></tr>
<tr><td><code id="gap_+3A_returnsimplen">returnSimpleN</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to add the count
(<em>n</em>-size) of observations included in groups A and B
in the percentage object</p>
</td></tr>
<tr><td><code id="gap_+3A_returnnumberofpsu">returnNumberOfPSU</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the number of
PSUs used in the calculation</p>
</td></tr>
<tr><td><code id="gap_+3A_nocov">noCov</code></td>
<td>
<p>set the covariances to zero in result</p>
</td></tr>
<tr><td><code id="gap_+3A_pctmethod">pctMethod</code></td>
<td>
<p>a character that is one of <code>unbiased</code> or <code>simple</code>.
See the help for <code><a href="#topic+percentile">percentile</a></code> for more information.</p>
</td></tr>
<tr><td><code id="gap_+3A_includelinkingerror">includeLinkingError</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to include the
linking error in variance estimation.
Standard errors (e.g., <code>diffAAse</code>, <code>diffBBse</code>,
and <code>diffABABse</code>) and <em>p</em>-values (e.g., <code>diffAApValue</code>,
<code>diffBBpValue</code>, and <code>diffABABpValue</code>) would be adjusted for
comparisons between digitally based assessments (DBA) and
paper-based assessments (PBA) data.
This option is supported only for NAEP data.</p>
</td></tr>
<tr><td><code id="gap_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the gap between <code>groupA</code> and <code>groupB</code> (which
may be omitted to indicate the full sample). The gap is
calculated for one of four statistics:
</p>

<dl>
<dt>the gap in means</dt><dd><p>The mean score gap (in the score
variable) identified in the <code>variable</code> argument.
This is the default. The means and their standard errors are
calculated using the methods
described in the <code><a href="#topic+lm.sdf">lm.sdf</a></code> function documentation.</p>
</dd>
<dt>the gap in percentiles</dt><dd><p>The gap between respondents at
the percentiles specified in the <code>percentiles</code> argument.
This is returned when the <code>percentiles</code> argument is
defined. The mean and standard error are computed as described in the
<code><a href="#topic+percentile">percentile</a></code> function documentation.</p>
</dd>
<dt>the gap in achievement levels</dt><dd><p>The gap in the percentage of
students at (when <code>achievementDiscrete</code> is <code>TRUE</code>) or at
or above (when <code>achievementDiscrete</code> is <code>FALSE</code>) a
particular achievement level. This is used when the
<code>achievementLevel</code> argument is defined. The mean and standard error
are calculated as described in the <code><a href="#topic+achievementLevels">achievementLevels</a></code>
function documentation.</p>
</dd>
<dt>the gap in a survey response</dt><dd><p>The gap in the percentage of
respondents responding at <code>targetLevel</code> to
<code>variable</code>. This is used when <code>targetLevel</code> is
defined. The mean and standard deviation are calculated as described in
the <code><a href="#topic+edsurveyTable">edsurveyTable</a></code> function documentation.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The return type depends on if the class of the <code>data</code> argument is an
<code>edsurvey.data.frame</code> or an <code>edsurvey.data.frame.list</code>. Both
include the call (called <code>call</code>), a list called <code>labels</code>,
an object named <code>percentage</code>
that shows the percentage in <code>groupA</code> and <code>groupB</code>, and an object
that shows the gap called <code>results</code>.
</p>
<p>The labels include the following elements:
</p>
<table>
<tr><td><code>definition</code></td>
<td>
<p>the definitions of the groups</p>
</td></tr>
<tr><td><code>nFullData</code></td>
<td>
<p>the <em>n</em>-size for the full dataset (before applying the definition)</p>
</td></tr>
<tr><td><code>nUsed</code></td>
<td>
<p>the <em>n</em>-size for the data after the group is subsetted and other
restrictions (such as omitted values) are applied</p>
</td></tr>
<tr><td><code>nPSU</code></td>
<td>
<p>the number of PSUs used in calculation&ndash;only returned when
<code>returnNumberOfPSU</code> <code>=</code> <code>TRUE</code></p>
</td></tr>
</table>
<p>The percentages are computed according to the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
in the section
&ldquo;Estimation of Weighted Percentages When Plausible Values Are Not Present.&rdquo;
The standard errors are calculated according to
&ldquo;Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Not Present, Using the Jackknife Method.&rdquo;
Standard errors of differences are calculated as the square root of the typical
variance formula
</p>
<p style="text-align: center;"><code class="reqn">Var(A-B) = Var(A) + Var(B) - 2 Cov(A,B)</code>
</p>

<p>where the covariance term is calculated as described in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
in the section
&ldquo;Estimation of Covariances.&rdquo; These degrees of freedom are available only
with the jackknife variance estimation. The degrees of freedom used for hypothesis testing
are always set to the number of jackknife replicates in the data.
</p>
<p><strong>the data argument is an edsurvey.data.frame</strong>
When the <code>data</code> argument is an <code>edsurvey.data.frame</code>,
<code>gap</code> returns an S3 object of class <code>gap</code>.
</p>
<p>The <code>percentage</code> object is a numeric vector with the following elements:
</p>
<table>
<tr><td><code>pctA</code></td>
<td>
<p>the percentage of respondents in <code>groupA</code> compared with the whole sample in <code>data</code></p>
</td></tr>
<tr><td><code>pctAse</code></td>
<td>
<p>the standard error on the percentage of respondents in
<code>groupA</code></p>
</td></tr>
<tr><td><code>dofA</code></td>
<td>
<p>degrees of freedom appropriate for a <em>t</em>-test involving <code>pctA</code>.
This value is returned only if
<code>returnSimpleDoF</code><code>=</code><code>TRUE</code>.</p>
</td></tr>
<tr><td><code>pctB</code></td>
<td>
<p>the percentage of respondents in <code>groupB</code>.</p>
</td></tr>
<tr><td><code>pctBse</code></td>
<td>
<p>the standard error on the percentage of respondents in
<code>groupB</code></p>
</td></tr>
<tr><td><code>dofB</code></td>
<td>
<p>degrees of freedom appropriate for a <em>t</em>-test involving <code>pctA</code>.
This value is returned only if
<code>returnSimpleDoF</code><code>=</code><code>TRUE</code>.</p>
</td></tr>
<tr><td><code>diffAB</code></td>
<td>
<p>the value of <code>pctA</code> minus <code>pctB</code></p>
</td></tr>
<tr><td><code>covAB</code></td>
<td>
<p>the covariance of <code>pctA</code> and <code>pctB</code>; used in
calculating <code>diffABse</code>.</p>
</td></tr>
<tr><td><code>diffABse</code></td>
<td>
<p>the standard error of <code>pctA</code>
minus <code>pctB</code></p>
</td></tr>
<tr><td><code>diffABpValue</code></td>
<td>
<p>the <em>p</em>-value associated with the <em>t</em>-test used
for the hypothesis test that <code>diffAB</code>
is zero</p>
</td></tr>
<tr><td><code>dofAB</code></td>
<td>
<p>degrees of freedom used in calculating
<code>diffABpValue</code></p>
</td></tr>
</table>
<p>The <code>results</code> object is a numeric data frame with the following elements:
</p>
<table>
<tr><td><code>estimateA</code></td>
<td>
<p>the mean estimate of <code>groupA</code> (or the percentage estimate
if <code>achievementLevel</code> or <code>targetLevel</code> is specified)</p>
</td></tr>
<tr><td><code>estimateAse</code></td>
<td>
<p>the standard error of <code>estimateA</code></p>
</td></tr>
<tr><td><code>dofA</code></td>
<td>
<p>degrees of freedom appropriate for a <em>t</em>-test involving <code>meanA</code>.
This value is returned only if
<code>returnSimpleDoF</code><code>=</code><code>TRUE</code>.</p>
</td></tr>
<tr><td><code>estimateB</code></td>
<td>
<p>the mean estimate of <code>groupB</code> (or the percentage estimate
if <code>achievementLevel</code> or <code>targetLevel</code> is specified)</p>
</td></tr>
<tr><td><code>estimateBse</code></td>
<td>
<p>the standard error of <code>estimateB</code></p>
</td></tr>
<tr><td><code>dofB</code></td>
<td>
<p>degrees of freedom appropriate for a <em>t</em>-test involving <code>meanB</code>.
This value is returned only if
<code>returnSimpleDoF</code><code>=</code><code>TRUE</code>.</p>
</td></tr>
<tr><td><code>diffAB</code></td>
<td>
<p>the value of <code>estimateA</code> minus <code>estimateB</code></p>
</td></tr>
<tr><td><code>covAB</code></td>
<td>
<p>the covariance of <code>estimateA</code> and <code>estimateB</code>. Used in
calculating <code>diffABse</code>.</p>
</td></tr>
<tr><td><code>diffABse</code></td>
<td>
<p>the standard error of <code>diffAB</code></p>
</td></tr>
<tr><td><code>diffABpValue</code></td>
<td>
<p>the <em>p</em>-value associated with the <em>t</em>-test used
for the hypothesis test that <code>diffAB</code>
is zero.</p>
</td></tr>
<tr><td><code>dofAB</code></td>
<td>
<p>degrees of freedom used for the <em>t</em>-test on <code>diffAB</code></p>
</td></tr>
</table>
<p>If the gap was in  achievement levels or percentiles and more
than one percentile or achievement level is requested,
then an additional column
labeled <code>percentiles</code> or <code>achievementLevel</code> is included
in the <code>results</code> object.
</p>
<p>When <code>results</code> has a single row and when <code>returnVarEstInputs</code>
is <code>TRUE</code>, the additional elements <code>varEstInputs</code> and
<code>pctVarEstInputs</code> also are returned. These can be used for calculating
covariances with <code><a href="#topic+varEstToCov">varEstToCov</a></code>.
</p>
<p><strong>the data argument is an edsurvey.data.frame.list</strong>
When the <code>data</code> argument is an <code>edsurvey.data.frame.list</code>,
<code>gap</code> returns an S3 object of class <code>gapList</code>.
</p>
<p>The <code>results</code> object in the <code>edsurveyResultList</code> is
a <code>data.frame</code>. Each row regards a particular dataset from the
<code>edsurvey.data.frame</code>, and a reference dataset is dictated by
the <code>referenceDataIndex</code> argument.
</p>
<p>The <code>percentage</code> object is a <code>data.frame</code> with the following elements:
</p>
<table>
<tr><td><code>covs</code></td>
<td>
<p>a data frame with a column for each column in the <code>covs</code>. See previous
section for more details.</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>all elements in the <code>percentage</code> object in the
previous section</p>
</td></tr>
<tr><td><code>diffAA</code></td>
<td>
<p>the difference in <code>pctA</code> between the reference data
and this dataset. Set to <code>NA</code> for the
reference dataset.</p>
</td></tr>
<tr><td><code>covAA</code></td>
<td>
<p>the covariance of <code>pctA</code> in the reference data and
<code>pctA</code> on this row. Used in
calculating <code>diffAAse</code>.</p>
</td></tr>
<tr><td><code>diffAAse</code></td>
<td>
<p>the standard error for <code>diffAA</code></p>
</td></tr>
<tr><td><code>diffAApValue</code></td>
<td>
<p>the <em>p</em>-value associated with the <em>t</em>-test used
for the hypothesis test that <code>diffAA</code>
is zero</p>
</td></tr>
<tr><td><code>diffBB</code></td>
<td>
<p>the difference in <code>pctB</code> between the reference data
and this dataset. Set to <code>NA</code> for the
reference dataset.</p>
</td></tr>
<tr><td><code>covBB</code></td>
<td>
<p>the covariance of <code>pctB</code> in the reference data and
<code>pctB</code> on this row. Used in
calculating <code>diffAAse</code>.</p>
</td></tr>
<tr><td><code>diffBBse</code></td>
<td>
<p>the standard error for <code>diffBB</code></p>
</td></tr>
<tr><td><code>diffBBpValue</code></td>
<td>
<p>the <em>p</em>-value associated with the <em>t</em>-test used
for the hypothesis test that <code>diffBB</code>
is zero</p>
</td></tr>
<tr><td><code>diffABAB</code></td>
<td>
<p>the value of <code>diffAB</code> in the reference dataset
minus the value of <code>diffAB</code> in this dataset. Set
to <code>NA</code> for the reference dataset.</p>
</td></tr>
<tr><td><code>covABAB</code></td>
<td>
<p>the covariance of <code>diffAB</code> in the reference data and
<code>diffAB</code> on this row. Used in
calculating <code>diffABABse</code>.</p>
</td></tr>
<tr><td><code>diffABABse</code></td>
<td>
<p>the standard error for <code>diffABAB</code></p>
</td></tr>
<tr><td><code>diffABABpValue</code></td>
<td>
<p>the <em>p</em>-value associated with the <em>t</em>-test used
for the hypothesis test that <code>diffABAB</code>
is zero</p>
</td></tr>
</table>
<p>The <code>results</code> object is a <code>data.frame</code> with the following elements:
</p>
<table>
<tr><td><code>...</code></td>
<td>
<p>all elements in the <code>results</code> object in the
previous section</p>
</td></tr>
<tr><td><code>diffAA</code></td>
<td>
<p>the value of <code>groupA</code> in the reference dataset minus
the value in this dataset. Set to <code>NA</code> for the
reference dataset.</p>
</td></tr>
<tr><td><code>covAA</code></td>
<td>
<p>the covariance of <code>meanA</code> in the reference data and
<code>meanA</code> on this row. Used in
calculating <code>diffAAse</code>.</p>
</td></tr>
<tr><td><code>diffAAse</code></td>
<td>
<p>the standard error for <code>diffAA</code></p>
</td></tr>
<tr><td><code>diffAApValue</code></td>
<td>
<p>the <em>p</em>-value associated with the <em>t</em>-test used
for the hypothesis test that <code>diffAA</code>
is zero</p>
</td></tr>
<tr><td><code>diffBB</code></td>
<td>
<p>the value of <code>groupB</code> in the reference dataset minus
the value in this dataset. Set to <code>NA</code> for the
reference dataset.</p>
</td></tr>
<tr><td><code>covBB</code></td>
<td>
<p>the covariance of <code>meanB</code> in the reference data and
<code>meanB</code> on this row. Used in
calculating <code>diffBBse</code>.</p>
</td></tr>
<tr><td><code>diffBBse</code></td>
<td>
<p>the standard error for <code>diffBB</code></p>
</td></tr>
<tr><td><code>diffBBpValue</code></td>
<td>
<p>the <em>p</em>-value associated with the <em>t</em>-test used
for the hypothesis test that <code>diffBB</code>
is zero</p>
</td></tr>
<tr><td><code>diffABAB</code></td>
<td>
<p>the value of <code>diffAB</code> in the reference dataset
minus the value of <code>diffAB</code>
in this dataset. Set
to <code>NA</code> for the reference dataset.</p>
</td></tr>
<tr><td><code>covABAB</code></td>
<td>
<p>the covariance of <code>diffAB</code> in the reference data and
<code>diffAB</code> on this row. Used in
calculating <code>diffABABse</code>.</p>
</td></tr>
<tr><td><code>diffABABse</code></td>
<td>
<p>the standard error for <code>diffABAB</code></p>
</td></tr>
<tr><td><code>diffABABpValue</code></td>
<td>
<p>the <em>p</em>-value associated with the <em>t</em>-test used
for the hypothesis test that <code>diffABAB</code>
is zero</p>
</td></tr>
<tr><td><code>sameSurvey</code></td>
<td>
<p>a logical value indicating if this line uses the same
survey as the reference line. Set to <code>NA</code> for the
reference line.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Bailey, Trang Nguyen, and Huade Huo
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# find the mean score gap in the primer data between males and females
gap("composite", sdf, dsex=="Male", dsex=="Female")

# find the score gap of the quartiles in the primer data between males and females
gap("composite", sdf, dsex=="Male", dsex=="Female", percentile=50)
gap("composite", sdf, dsex=="Male", dsex=="Female", percentile=c(25, 50, 75))

# find the percent proficient (or higher) gap in the primer data between males and females
gap("composite", sdf, dsex=="Male", dsex=="Female", 
    achievementLevel=c("Basic", "Proficient", "Advanced"))

# find the discrete achievement level gap--this is harder to interpret
gap("composite", sdf, dsex=="Male", dsex=="Female",
    achievementLevel="Proficient", achievementDiscrete=TRUE)

# find the percent talk about studies at home (b017451) never or hardly
# ever gap in the primer data between males and females
gap("b017451", sdf, dsex=="Male", dsex=="Female", 
    targetLevel="Never or hardly ever")

# example showing how to compare multiple levels
gap("b017451",sdf, dsex=="Male", dsex=="Female", targetLevel="Infrequently",
    recode=list(b017451=list(from=c("Never or hardly ever",
                                    "Once every few weeks",
                                    "About once a week"),
                             to=c("Infrequently"))))

# make subsets of sdf by scrpsu, "Scrambled PSU and school code"
sdfA &lt;- subset(sdf, scrpsu %in% c(5,45,56))
sdfB &lt;- subset(sdf, scrpsu %in% c(75,76,78))
sdfC &lt;- subset(sdf, scrpsu %in% 100:200)
sdfD &lt;- subset(sdf, scrpsu %in% 201:300)

sdfl &lt;- edsurvey.data.frame.list(list(sdfA, sdfB, sdfC, sdfD),
                                 labels=c("A locations", "B locations",
                                          "C locations", "D locations"))

gap("composite", sdfl, dsex=="Male", dsex=="Female", percentile=c(50))

## End(Not run)

## Not run: 
# example showing using linking error with gap
# load Grade 4 math data
# requires NAEP RUD license with these files in the folder the user is currectly in
g4math2015 &lt;- readNAEP("M46NT1AT.dat")
g4math2017 &lt;- readNAEP("M48NT1AT.dat")
g4math2019 &lt;- readNAEP("M50NT1AT.dat")

# make an edsurvey.data.frame.list from math grade 4 2015, 2017, and 2019 data
g4math &lt;- edsurvey.data.frame.list(list(g4math2019, g4math2017, g4math2015),
                                   labels = c("2019", "2017", "2015"))

# gap analysis with linking error in variance estimation across surveys
gap("composite", g4math, dsex == "Male", dsex == "Female", includeLinkingError=TRUE)
gap("composite", g4math, dsex == "Male", dsex == "Female", percentiles = c(10, 25), 
    includeLinkingError=TRUE)
gap("composite", g4math, dsex == "Male", dsex == "Female", 
    achievementDiscrete = TRUE, achievementLevel=c("Basic", "Proficient", "Advanced"), 
    includeLinkingError=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='getAllItems'>Retrieve IRT Item Variable Names</h2><span id='topic+getAllItems'></span>

<h3>Description</h3>

<p>Retrieves the IRT item variable names associated with construct names for use with <code>mml.sdf</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAllItems(sdf, construct = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getAllItems_+3A_sdf">sdf</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or <code>light.edsurvey.data.frame</code> containing IRT information. Supports NAEP and TIMSS 2011, 2015, and 2019 studies only.</p>
</td></tr>
<tr><td><code id="getAllItems_+3A_construct">construct</code></td>
<td>
<p>a character value (or vector) for which to return the associated item variable names. Default value is <code>NULL</code> which returns all IRT item variable names.
Use the <code>showPlausibleValues</code> function to view construct details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector of the items names associated for the values in <code>construct</code>.
</p>


<h3>Note</h3>

<p>if <code>construct</code> is a vector, all item names will be returned for those constructs. Use <code>getAllItems</code> with <code>getData</code> when creating a <code>light.edsurvey.data.frame</code>, see example for use.
</p>


<h3>Author(s)</h3>

<p>Tom Fink, Sun-Joo Lee, Eric Buehler, and Paul Bailey
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mml.sdf">mml.sdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  #TIMSS Example
  t15 &lt;- readTIMSS("~/TIMSS/2015", "usa", 4)
  
  showPlausibleValues(t15) #view constructs in console
  
  #ensure we have all data needed for mml.sdf on light.edsurvey.data.frame
  #must be specified ahead of time.  the 'getAllItems' function makes this easy
  mathItems &lt;- getAllItems(t15, "mmat") #get mathematics items
  sciItems &lt;- getAllItems(t15, "ssci") #get science items
  allItems &lt;- getAllItems(t15, construct = "NULL")
  
  wgtVar &lt;- "totwgt"
  psustr &lt;- c(getPSUVar(t15, wgtVar), getStratumVar(t15, wgtVar))
  lsdf &lt;- getData(data = t15,
                  varnames = c("ROWID", "mmat", mathItems, psustr, wgtVar),
                  omittedLevels = FALSE,
                  addAttributes = TRUE) #builds light.edsurvey.data.frame
  
  #as a light.edsurvey.data.frame all elements must be present
  mml.sdf(mmat ~ 1, lsdf, weightVar = "totwgt")
  
  #as edsurvey.data.frame elements retrieved automatically for user
  mml.sdf(mmat ~ 1, t15, weightVar = "totwgt") 
  
  #NAEP example
  sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))
  
  allItems &lt;- getAllItems(sdf, construct = NULL)
  algebraItems &lt;- getAllItems(sdf, construct = "algebra")

## End(Not run)
</code></pre>

<hr>
<h2 id='getData'>Read Data to a Data Frame</h2><span id='topic+getData'></span>

<h3>Description</h3>

<p>Reads in selected columns to a <code>data.frame</code> or a
<code>light.edsurvey.data.frame</code>. On an <code>edsurvey.data.frame</code>,
the data are stored on disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getData(
  data,
  varnames = NULL,
  drop = FALSE,
  dropUnusedLevels = TRUE,
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  formula = NULL,
  recode = NULL,
  includeNaLabel = FALSE,
  addAttributes = FALSE,
  returnJKreplicates = TRUE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getData_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or
a <code>light.edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="getData_+3A_varnames">varnames</code></td>
<td>
<p>a character vector of variable names that will be returned.
When both <code>varnames</code> and
a <code>formula</code> are specified, variables associated with both are
returned. Set to <code>NULL</code> by default.</p>
</td></tr>
<tr><td><code id="getData_+3A_drop">drop</code></td>
<td>
<p>a logical value. When set to the default value of <code>FALSE</code>,
when a single column is returned, it is still represented as a
<code>data.frame</code> and is not converted to a vector.</p>
</td></tr>
<tr><td><code id="getData_+3A_dropunusedlevels">dropUnusedLevels</code></td>
<td>
<p>a logical value. When set to the default value of
<code>TRUE</code>, drops unused levels of all factor
variables.</p>
</td></tr>
<tr><td><code id="getData_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of
<code>TRUE</code>, drops those levels of all factor variables
that are specified in an <code>edsurvey.data.frame</code>. Use
<code>print</code> on an <code>edsurvey.data.frame</code> to see
the omitted levels. The omitted levels also can be
adjusted with <code>setAttributes</code>; see Examples.</p>
</td></tr>
<tr><td><code id="getData_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of
<code>TRUE</code>, uses the default conditions stored in
an <code>edsurvey.data.frame</code> to subset the data. Use
<code>print</code> on an <code>edsurvey.data.frame</code> to
see the default conditions.</p>
</td></tr>
<tr><td><code id="getData_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code>.
When included, <code>getData</code> returns data associated with
all variables of the <code>formula</code>. When both <code>varnames</code> and a
formula are specified, the variables associated with both are
returned. Set to <code>NULL</code> by default.</p>
</td></tr>
<tr><td><code id="getData_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>.
Can be set as <code>recode</code> <code>=</code> <code>list(var1</code>
<code>=</code> <code>list(from</code> <code>=</code> <code>c("a","b","c"), to</code>
<code>=</code> <code>"d"))</code>. See Examples.</p>
</td></tr>
<tr><td><code id="getData_+3A_includenalabel">includeNaLabel</code></td>
<td>
<p>a logical value to indicate if <code>NA</code> (missing) values are
returned as literal <code>NA</code> values or as factor levels
coded as <code>NA</code></p>
</td></tr>
<tr><td><code id="getData_+3A_addattributes">addAttributes</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to get a
<code>data.frame</code> that can be used in calls to
other functions that usually would take an
<code>edsurvey.data.frame</code>. This <code>data.frame</code> also is called a <code>light.edsurvey.data.frame</code>.
See Description section in <code><a href="#topic+edsurvey.data.frame">edsurvey.data.frame</a></code> for
more information on <code>light.edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="getData_+3A_returnjkreplicates">returnJKreplicates</code></td>
<td>
<p>a logical value indicating if JK replicate weights
should be returned. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="getData_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, an <code>edsurvey.data.frame</code> does not have data read
into memory until <code>getData</code> is called and returns a data frame.
This structure allows <code>EdSurvey</code> to have a minimal memory footprint.
To keep the footprint small, you need to limit <code>varnames</code> to just
the necessary variables.
</p>
<p>There are two methods of attaching survey attributes to a <code>data.frame</code>
to make it usable by the functions in the <code>EdSurvey</code> package (e.g., <code>lm.sdf</code>):
(a) setting the <code>addAttributes</code> argument to <code>TRUE</code> at in the call to <code>getData</code>
or (b) by appending the attributes to the data frame with <code>rebindAttributes</code>.
</p>
<p>When <code>getData</code> is called, it returns a data frame. Setting the
<code>addAttributes</code> argument to <code>TRUE</code> adds the survey attributes and
changes the resultant <code>data.frame</code> to a <code>light.edsurvey.data.frame</code>.
</p>
<p>Alternatively, a <code>data.frame</code> can be coerced into a <code>light.edsurvey.data.frame</code>
using <code>rebindAttributes</code>. See Examples in the <code><a href="#topic+rebindAttributes">rebindAttributes</a></code> documentation.
</p>
<p>If both <code>formula</code> and <code>varnames</code> are populated, the
variables on both will be included.
</p>
<p>See the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-getData.pdf"><em>Using the <code>getData</code> Function in EdSurvey</em></a>
for long-form documentation on this function.
</p>


<h3>Value</h3>

<p>When <code>addAttributes</code> is <code>FALSE</code>, <code>getData</code> returns a
<code>data.frame</code> containing data associated with the requested
variables. When <code>addAttributes</code> is <code>TRUE</code>, <code>getData</code> returns a
<code>light.edsurvey.data.frame</code>.
</p>


<h3>Author(s)</h3>

<p>Tom Fink, Paul Bailey, and Ahmad Emad
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rebindAttributes">rebindAttributes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# get two variables, without weights
df &lt;- getData(data=sdf, varnames=c("dsex", "b017451"))
table(df)

# example of using recode
df2 &lt;- getData(data=sdf, varnames=c("dsex", "t088301"),
               recode=list(t088301=list(from=c("Yes, available","Yes, I have access"),
                                        to=c("Yes")),
                           t088301=list(from=c("No, have no access"),
                                        to=c("No"))))
table(df2)

# when readNAEP is called on a data file, it appends a default 
# condition to the edsurvey.data.frame. You can see these conditions
# by printing the sdf
sdf

# As per the default condition specified, getData restricts the data to only
# Reporting Sample. This behavior can be changed as follows:
df2 &lt;- getData(data=sdf, varnames=c("dsex", "b017451"), defaultConditions = FALSE)
table(df2)

# similarly, the default behavior of omitting certain levels specified
# in the edsurvey.data.frame can be changed as follows:
df2 &lt;- getData(data=sdf, varnames=c("dsex", "b017451"), omittedLevels = FALSE)
table(df2)

# omittedLevels can also be edited with setAttributes()
# here, the omitted level "Multiple" is removed from the list
sdfIncludeMultiple &lt;- setAttributes(sdf, "omittedLevels", c(NA, "Omitted"))
# check that it was set
getAttributes(sdfIncludeMultiple, "omittedLevels")
# notice that omittedLevels is TRUE, removing NA and "Omitted" still
dfIncludeMultiple &lt;- getData(data=sdfIncludeMultiple, varnames=c("dsex", "b017451"))
table(dfIncludeMultiple)

# the variable "c052601" is from the school-level data file; merging is handled automatically.
# returns a light.edsurvey.data.frame using addAttributes=TRUE argument
gddat &lt;- getData(data=sdf, 
                 varnames=c("composite", "dsex", "b017451","c052601"),
                 addAttributes = TRUE)
class(gddat)
# look at the first few lines
head(gddat)

# get a selection of variables, recode using ifelse, and reappend attributes
# with rebindAttributes so that it can be used with EdSurvey analysis functions
df0 &lt;- getData(sdf, c("composite", "dsex", "b017451", "origwt"))
df0$sex &lt;- ifelse(df0$dsex=="Male", "boy", "girl")
df0 &lt;- rebindAttributes(df0, sdf)

# getting all the data can use up all the memory and is generally a bad idea
df0 &lt;- getData(sdf, varnames=colnames(sdf),
               omittedLevels=FALSE, defaultConditions=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='getNHES_SurveyInfo'>Get NHES Survey Code Definitions and Survey Meta-data</h2><span id='topic+getNHES_SurveyInfo'></span>

<h3>Description</h3>

<p>This function returns a <code>data.frame</code> object that defines NHES Survey Codes and survey parameters that are compatible with the <code>readNHES</code> function for use.
The resulting <code>data.frame</code> object is useful for user reference or other advanced techniques.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNHES_SurveyInfo()
</code></pre>


<h3>Note</h3>

<p>Any changes or modifications to the <code>data.frame</code> object will not change the behavior of <code>readNHES</code>.
This function should be treated only as a read-only source of information.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code>readNHES</code>, <code>viewNHES_SurveyCodes</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  #retrieves the NHES survey meta-data to a data.frame
  surveyInfo &lt;- getNHES_SurveyInfo()
  
  #View the survey data where the year is equal to 2016 in RStudio
  View(subset(surveyInfo, surveyInfo$Year==2016))

## End(Not run)
</code></pre>

<hr>
<h2 id='getPlausibleValue'>Get Plausible Value Variables</h2><span id='topic+getPlausibleValue'></span>

<h3>Description</h3>

<p>Gets the set of variables on an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code> associated with the given subject or subscale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPlausibleValue(var, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPlausibleValue_+3A_var">var</code></td>
<td>
<p>a character vector naming the subject scale or subscale</p>
</td></tr>
<tr><td><code id="getPlausibleValue_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will return a set of plausible value names for variables that
<code><a href="#topic+hasPlausibleValue">hasPlausibleValue</a></code> returns as true.
</p>


<h3>Value</h3>

<p>a character vector of the set of variable names for the plausible values
</p>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>See Also</h3>

<p><code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>, <code><a href="#topic+updatePlausibleValue">updatePlausibleValue</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

getPlausibleValue(var="composite", data=sdf)

## End(Not run)
</code></pre>

<hr>
<h2 id='getWeightJkReplicates'>Retrieve the Jackknife Replicate Weights</h2><span id='topic+getWeightJkReplicates'></span>

<h3>Description</h3>

<p>Returns the jackknife replicate weights on an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code> associated with a weight variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getWeightJkReplicates(var, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getWeightJkReplicates_+3A_var">var</code></td>
<td>
<p>character indicating the name of the weight variable for which the
jackknife replicate weights are desired</p>
</td></tr>
<tr><td><code id="getWeightJkReplicates_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector of the jackknife replicate weights
</p>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

getWeightJkReplicates(var="origwt", data=sdf)

## End(Not run)
</code></pre>

<hr>
<h2 id='glm.sdf'>EdSurvey Generalized Linear Models</h2><span id='topic+glm.sdf'></span><span id='topic+logit.sdf'></span><span id='topic+probit.sdf'></span>

<h3>Description</h3>

<p>Fits a logit or probit that
uses weights and variance estimates
appropriate for the <code>edsurvey.data.frame</code>,
the <code>light.edsurvey.data.frame</code>, or the <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.sdf(formula, family = binomial(link = "logit"), data,
  weightVar = NULL, relevels = list(),
  varMethod=c("jackknife", "Taylor"), jrrIMax = 1,
  dropOmittedLevels = TRUE, defaultConditions = TRUE, recode = NULL,
  returnNumberOfPSU=FALSE, returnVarEstInputs = FALSE,
  omittedLevels = deprecated())

logit.sdf(
  formula,
  data,
  weightVar = NULL,
  relevels = list(),
  varMethod = c("jackknife", "Taylor"),
  jrrIMax = 1,
  omittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  returnNumberOfPSU = FALSE,
  returnVarEstInputs = FALSE
)

probit.sdf(
  formula,
  data,
  weightVar = NULL,
  relevels = list(),
  varMethod = c("jackknife", "Taylor"),
  jrrIMax = 1,
  omittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  returnVarEstInputs = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glm.sdf_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code> for the
linear model. See <code><a href="stats.html#topic+glm">glm</a></code>.
For logit and probit, we recommend using the <code>I()</code> function
to define the level used for success. (See Examples.)</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_family">family</code></td>
<td>
<p>the <code>glm.sdf</code> function currently fits only the binomial
outcome models, such as logit and probit, although other link
functions are available for binomial models. See the <code>link</code>
argument in the help for
<code><a href="stats.html#topic+family">family</a></code>.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_weightvar">weightVar</code></td>
<td>
<p>character indicating the weight variable to use (see Details).
The <code>weightVar</code> must be one of the weights for the
<code>edsurvey.data.frame</code>. If <code>NULL</code>, uses the default
for the <code>edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_relevels">relevels</code></td>
<td>
<p>a list; used to change the contrasts from the
default treatment contrasts to the treatment contrasts with a chosen omitted
group. The name of each element should be the variable name, and the value
should be the group to be omitted.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_varmethod">varMethod</code></td>
<td>
<p>a character set to &ldquo;jackknife&rdquo; or &ldquo;Taylor&rdquo; that indicates the variance
estimation method to be used. See Details.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>the <code>Vjrr</code> sampling variance term (see
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>)
can be estimated with
any positive number of plausible values and is estimated on
the lower
of the number of available plausible values and <code>jrrIMax</code>. When
<code>jrrIMax</code> is set to <code>Inf</code>, all plausible values will be used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more
accurate variance estimates.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, drops
those levels of all factor variables that are specified
in <code>edsurvey.data.frame</code>. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the omitted levels.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, uses
the default conditions stored in an <code>edsurvey.data.frame</code>
to subset the data. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the default conditions.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>. Can be set as
<code>recode=</code> <code>list(</code><code>var1=</code> <code>list(from=</code> <code>c("a",</code> <code>"b",</code> <code>"c"),</code> <code>to=</code><code>"d"))</code>.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_returnnumberofpsu">returnNumberOfPSU</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the number of
primary sampling units (PSUs)</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_returnvarestinputs">returnVarEstInputs</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the
inputs to the jackknife and imputation variance
estimates, which allow for
the computation
of covariances between estimates.</p>
</td></tr>
<tr><td><code id="glm.sdf_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements an estimator that correctly handles left-hand side
variables that are logical, allows for survey sampling weights, and estimates
variances using the jackknife replication or Taylor series.
The vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
describes estimation of the reported statistics and how it depends on <code>varMethod</code>.
</p>
<p>The coefficients are estimated
using the sample weights according to the section
&ldquo;Estimation of Weighted Means When Plausible Values Are Not Present&rdquo;
or the section
&ldquo;Estimation of Weighted Means When Plausible Values Are Present,&rdquo;
depending on if there are assessment variables or variables with plausible values
in them.
</p>
<p>How the standard errors of the coefficients are estimated depends on the
presence of plausible values (assessment variables),
But once it is obtained, the <em>t</em> statistic
is given by </p>
<p style="text-align: center;"><code class="reqn">t=\frac{\hat{\beta}}{\sqrt{\mathrm{var}(\hat{\beta})}}</code>
</p>
<p> where
<code class="reqn"> \hat{\beta} </code> is the estimated coefficient and <code class="reqn">\mathrm{var}(\hat{\beta})</code> is
its variance of that estimate.
</p>
<p><code>logit.sdf</code> and <code>probit.sdf</code> are included for convenience only;
they give the same results as a call to <code>glm.sdf</code> with the binomial family
and the link function named in the function call (logit or probit).
By default, <code>glm</code> fits a logistic regression when <code>family</code> is not set,
so the two are expected to give the same results in that case.
Other types of generalized linear models are not supported.
</p>


<h4>Variance estimation of coefficients</h4>

<p>All variance estimation methods are shown in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>.
When the predicted
value does not have plausible values and <code>varMethod</code> is set to
<code>jackknife</code>, the variance of the coefficients
is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When
Plausible Values Are Not Present, Using the Jackknife Method.&rdquo;
</p>
<p>When plausible values are present and <code>varMethod</code> is set to
<code>jackknife</code>, the
variance of the coefficients is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When
Plausible Values Are Present, Using the Jackknife Method.&rdquo;
</p>
<p>When the predicted
value does not have plausible values and <code>varMethod</code> is set to
<code>Taylor</code>, the variance of the coefficients
is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When
Plausible Values Are Not Present, Using the Taylor Series Method.&rdquo;
</p>
<p>When plausible values are present and <code>varMethod</code> is set to
<code>Taylor</code>, the
variance of the coefficients is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When
Plausible Values Are Present, Using the Taylor Series Method.&rdquo;
</p>



<h3>Value</h3>

<p>An <code>edsurveyGlm</code> with the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula used to fit the model</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>the estimates of the coefficients</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard error estimates of the coefficients</p>
</td></tr>
<tr><td><code>Vimp</code></td>
<td>
<p>the estimated variance caused by uncertainty in the scores (plausible value variables)</p>
</td></tr>
<tr><td><code>Vjrr</code></td>
<td>
<p>the estimated variance from sampling</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>nPSU</code></td>
<td>
<p>the number of PSUs used in the calculation</p>
</td></tr>
<tr><td><code>varm</code></td>
<td>
<p>the variance estimates under the various plausible values</p>
</td></tr>
<tr><td><code>coefm</code></td>
<td>
<p>the values of the coefficients under the various plausible values</p>
</td></tr>
<tr><td><code>coefmat</code></td>
<td>
<p>the coefficient matrix (typically produced by the summary of a model)</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>
<p>the name of the weight variable</p>
</td></tr>
<tr><td><code>npv</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>njk</code></td>
<td>
<p>the number of the jackknife replicates used</p>
</td></tr>
<tr><td><code>varMethod</code></td>
<td>
<p>always <code>jackknife</code></p>
</td></tr>
<tr><td><code>varEstInputs</code></td>
<td>
<p>when <code>returnVarEstInputs</code> is <code>TRUE</code>,
this element is returned. These are
used for calculating covariances with
<code><a href="#topic+varEstToCov">varEstToCov</a></code>.</p>
</td></tr>
</table>


<h3>Testing</h3>

<p>Of the common hypothesis tests for joint parameter testing, only the Wald
test is widely used with plausible values and sample weights. As such, it
replaces, if imperfectly, the Akaike Information Criteria (AIC), the
likelihood ratio test, chi-squared, and analysis of variance (ANOVA, including <em>F</em>-tests).
See <code><a href="#topic+waldTest">waldTest</a></code> or
the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-WaldTest.pdf"><em>Methods and Overview of Using EdSurvey for Running Wald Tests</em></a>.
</p>


<h3>Author(s)</h3>

<p>Paul Bailey
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# by default uses the jackknife variance method using replicate weights
table(sdf$b013801)
logit1 &lt;- logit.sdf(I(b013801 %in% c("26-100", "&gt;100")) ~ dsex + b017451, data=sdf)
# use summary to get detailed results
summary(logit1)

# Taylor series variance estimation
logit1t &lt;- logit.sdf(I(b013801 %in% c("26-100", "&gt;100")) ~ dsex + b017451, data=sdf,
                     varMethod="Taylor")
summary(logit1t)

logit2 &lt;- logit.sdf(I(composite &gt;= 300) ~ dsex + b013801, data=sdf)
summary(logit2)

logit3 &lt;- glm.sdf(I(composite &gt;= 300) ~ dsex + b013801, data=sdf, 
                  family=quasibinomial(link="logit"))

# Wald test for joint hypothesis that all coefficients in b013801 are zero
waldTest(logit3, "b013801")

summary(logit3)

## End(Not run)
</code></pre>

<hr>
<h2 id='hasPlausibleValue'>Plausible Value Test</h2><span id='topic+hasPlausibleValue'></span>

<h3>Description</h3>

<p>Returns a value indicating if this variable has associated plausible values in an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hasPlausibleValue(var, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hasPlausibleValue_+3A_var">var</code></td>
<td>
<p>a character indicating the variable in question</p>
</td></tr>
<tr><td><code id="hasPlausibleValue_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns <code>TRUE</code> only when the variable passed to it is the name for a set of plausible values but
not if it is an individual plausible value from such a set. Thus, on the NAEP Primer, <code>composite</code> has plausible
values (and so <code>TRUE</code> would be returned by this function), but any of the plausible values or variable names defined in
the actual data (such as <code>"mrpcm1"</code> or <code>"dsex"</code>) are not.
</p>


<h3>Value</h3>

<p>a Boolean (or vector when <code>var</code> is a vector) indicating if each element of <code>var</code> has
plausible values associated with it
</p>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# TRUE
hasPlausibleValue(var="composite", data=sdf)

# FALSE
hasPlausibleValue(var="dsex", data=sdf)

## End(Not run)
</code></pre>

<hr>
<h2 id='isWeight'>Weight Test</h2><span id='topic+isWeight'></span>

<h3>Description</h3>

<p>Returns logical values indicating whether a vector of variables is a weight for an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isWeight(var, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isWeight_+3A_var">var</code></td>
<td>
<p>a character vector of variables</p>
</td></tr>
<tr><td><code id="isWeight_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this function returns <code>TRUE</code> only when the <code>var</code> element is the name of the weight used
for making estimates but not if it is one of the individual jackknife replicates.
</p>


<h3>Value</h3>

<p>a logical vector of values indicating if each element of <code>var</code>
is a weight
</p>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# TRUE
isWeight(var="origwt", data=sdf)

# FALSE
isWeight(var="dsex", data=sdf)

## End(Not run)
</code></pre>

<hr>
<h2 id='levelsSDF'>Print Levels and Labels</h2><span id='topic+levelsSDF'></span>

<h3>Description</h3>

<p>Retrieve the levels and labels of a variable from an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>levelsSDF(varnames, data, showOmitted = TRUE, showN = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="levelsSDF_+3A_varnames">varnames</code></td>
<td>
<p>a vector of character strings to search for in the database connection object (<code>data</code>)</p>
</td></tr>
<tr><td><code id="levelsSDF_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="levelsSDF_+3A_showomitted">showOmitted</code></td>
<td>
<p>a Boolean indicating if omitted levels should be shown</p>
</td></tr>
<tr><td><code id="levelsSDF_+3A_shown">showN</code></td>
<td>
<p>a Boolean indicating if (unweighted) <em>n</em>-sizes should be shown for each response level</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# search variables in the sdf
levelsSDF(varnames="pared", data=sdf)

# search multiple variables
levelsSDF(varnames=c("pared","ell3"), data=sdf)

# search multiple variables in a light.edsurvey.data.frame with recodes
df2 &lt;- getData(data=sdf, varnames=c("dsex", "t088301"),
               recode=list(t088301=list(from=c("Yes, available","Yes, I have access"),
                                        to=c("Yes")),
                           t088301=list(from=c("No, have no access"),
                                        to=c("No"))),
               addAttributes=TRUE)
levelsSDF(varnames=c("dsex","t088301"), data=df2)

## End(Not run)
</code></pre>

<hr>
<h2 id='lm.sdf'>EdSurvey Linear Models</h2><span id='topic+lm.sdf'></span>

<h3>Description</h3>

<p>Fits a linear model that uses weights and variance estimates appropriate for the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lm.sdf(formula, data, weightVar = NULL, relevels = list(),
              varMethod = c("jackknife", "Taylor"), jrrIMax = 1,
              dropOmittedLevels = TRUE, defaultConditions = TRUE, recode = NULL,
              returnVarEstInputs = FALSE, returnNumberOfPSU = FALSE,
              standardizeWithSamplingVar = FALSE, verbose=TRUE,
              omittedLevels = deprecated())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lm.sdf_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code> for the
linear model. See <code><a href="stats.html#topic+lm">lm</a></code>.
If <em>y</em> is left blank, the default subject scale or subscale variable
will be used. (You can find the default using
<code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>.)
If <em>y</em> is a variable for a subject scale or subscale (one of the
names shown by <code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>),
then that subject scale or subscale is used.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_weightvar">weightVar</code></td>
<td>
<p>a character indicating the weight variable to use (see Details).
The <code>weightVar</code> must be one of the weights for the
<code>edsurvey.data.frame</code>. If <code>NULL</code>, it  uses the default
for the <code>edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_relevels">relevels</code></td>
<td>
<p>a list. Used to change the contrasts from the
default treatment contrasts to the treatment contrasts with a chosen omitted
group (the reference group). The name of each element should be the variable name, and the value
should be the group to be omitted (the reference group).</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_varmethod">varMethod</code></td>
<td>
<p>a character set to &ldquo;jackknife&rdquo; or &ldquo;Taylor&rdquo; that indicates the variance
estimation method to be used. See Details.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>a numeric value; when using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=1</code>, uses the
sampling variance from the first plausible value as the component for sampling variance estimation. The <code>Vjrr</code>
term (see
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>)
can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, drops
those levels of all factor variables that are specified
in an <code>edsurvey.data.frame</code>. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the omitted levels.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, uses
the default conditions stored in an <code>edsurvey.data.frame</code>
to subset the data. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the default conditions.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>. Can be set as
<code>recode=</code><code>list(</code><code>var1</code> <code>=</code> <code>list(</code><code>from=</code> <code>c("a",</code> <code>"b",</code> <code>"c"),</code> <code>to=</code> <code>"d"))</code>. See Examples.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_returnvarestinputs">returnVarEstInputs</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the
inputs to the jackknife and imputation variance
estimates, which allow for the computation
of covariances between estimates.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_returnnumberofpsu">returnNumberOfPSU</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the number of
primary sampling units (PSUs)</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_standardizewithsamplingvar">standardizeWithSamplingVar</code></td>
<td>
<p>a logical value indicating if the standardized coefficients
should have the variance of the regressors and outcome measured
with sampling variance. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_verbose">verbose</code></td>
<td>
<p>logical; indicates whether a detailed printout should display during execution</p>
</td></tr>
<tr><td><code id="lm.sdf_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements an estimator that correctly handles left-hand
side variables that are either numeric or plausible values and allows for survey
sampling weights and estimates variances using the jackknife replication method.
The vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
describes estimation of the reported statistics.
</p>
<p>Regardless of the variance estimation, the coefficients are estimated
using the sample weights according to the sections
&ldquo;Estimation of Weighted Means When Plausible Values Are Not Present&rdquo;
or
&ldquo;Estimation of Weighted Means When Plausible Values Are Present,&rdquo;
depending on if there are assessment variables or variables with plausible values
in them.
</p>
<p>How the standard errors of the coefficients are estimated depends on the
value of <code>varMethod</code> and the presence of plausible values (assessment variables),
But once it is obtained, the <em>t</em> statistic
is given by </p>
<p style="text-align: center;"><code class="reqn">t=\frac{\hat{\beta}}{\sqrt{\mathrm{var}(\hat{\beta})}}</code>
</p>
<p> where
<code class="reqn"> \hat{\beta} </code> is the estimated coefficient and <code class="reqn">\mathrm{var}(\hat{\beta})</code> is
the variance of that estimate.
</p>
<p>The <b>coefficient of determination (<em>R</em>-squared value)</b> is similarly estimated by finding
the average <em>R</em>-squared using the average across the plausible values.
</p>


<h4>Standardized regression coefficients</h4>

<p>Standardized regression coefficients can be returned in a call to <code>summary</code>,
by setting the argument <code>src</code> to <code>TRUE</code>. See Examples.
</p>
<p>By default, the standardized coefficients are calculated using standard
deviations of the variables themselves, including averaging the standard
deviation across any plausible values. When <code>standardizeWithSamplingVar</code>
is set to <code>TRUE</code>, the variance of the standardized coefficient is
calculated similar to a regression coefficient and therefore includes the
sampling variance in the variance estimate of the outcome variable.
</p>



<h4>Variance estimation of coefficients</h4>

<p>All variance estimation methods are shown in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>.
When <code>varMethod</code> is set to the <code>jackknife</code> and the predicted
value does not have plausible values, the variance of the coefficients
is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When
Plausible Values Are Not Present, Using the Jackknife Method.&rdquo;
</p>
<p>When plausible values are present and <code>varMethod</code> is <code>jackknife</code>, the
variance of the coefficients is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When
Plausible Values Are Present, Using the Jackknife Method.&rdquo;
</p>
<p>When plausible values are not present and <code>varMethod</code> is <code>Taylor</code>, the
variance of the coefficients is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When Plausible
Values Are Not Present, Using the Taylor Series Method.&rdquo;
</p>
<p>When plausible values are present and <code>varMethod</code> is <code>Taylor</code>, the
variance of the coefficients is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When Plausible
Values Are Present, Using the Taylor Series Method.&rdquo;
</p>



<h3>Value</h3>

<p>An <code>edsurvey.lm</code> with the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula used to fit the model</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>the estimates of the coefficients</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard error estimates of the coefficients</p>
</td></tr>
<tr><td><code>Vimp</code></td>
<td>
<p>the estimated variance from uncertainty in the scores (plausible value variables)</p>
</td></tr>
<tr><td><code>Vjrr</code></td>
<td>
<p>the estimated variance from sampling</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>varm</code></td>
<td>
<p>the variance estimates under the various plausible values</p>
</td></tr>
<tr><td><code>coefm</code></td>
<td>
<p>the values of the coefficients under the various plausible values</p>
</td></tr>
<tr><td><code>coefmat</code></td>
<td>
<p>the coefficient matrix (typically produced by the summary of a model)</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>the coefficient of determination</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>
<p>the name of the weight variable</p>
</td></tr>
<tr><td><code>npv</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>jrrIMax</code></td>
<td>
<p>the <code>jrrIMax</code> value used in computation</p>
</td></tr>
<tr><td><code>njk</code></td>
<td>
<p>the number of the jackknife replicates used; set to <code>NA</code>
when Taylor series variance estimates are used</p>
</td></tr>
<tr><td><code>varMethod</code></td>
<td>
<p>one of <code>Taylor series</code> or the <code>jackknife</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>residuals from the average regression coefficients</p>
</td></tr>
<tr><td><code>PV.residuals</code></td>
<td>
<p>residuals from the by plausible value coefficients</p>
</td></tr>
<tr><td><code>PV.fitted.values</code></td>
<td>
<p>fitted values from the by plausible value coefficients</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>imputation variance covariance matrix, before multiplication by (M+1)/M</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>sampling variance covariance matrix</p>
</td></tr>
<tr><td><code>rbar</code></td>
<td>
<p>average relative increase in variance; see van Buuren (2012, eq. 2.29)</p>
</td></tr>
<tr><td><code>nPSU</code></td>
<td>
<p>number of PSUs used in calculation</p>
</td></tr>
<tr><td><code>n0</code></td>
<td>
<p>number of rows on an <code>edsurvey.data.frame</code> before any conditions were applied</p>
</td></tr>
<tr><td><code>nUsed</code></td>
<td>
<p>number of observations with valid data and weights larger than zero</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data used for the computation</p>
</td></tr>
<tr><td><code>Xstdev</code></td>
<td>
<p>standard deviations of regressors, used for computing standardized
regression coefficients when <code>standardizeWithSamplingVar</code> is set to
<code>FALSE</code> (the default)</p>
</td></tr>
<tr><td><code>varSummary</code></td>
<td>
<p>the result of running <code>summary2</code> (unweighted) on each variable in the
regression</p>
</td></tr>
<tr><td><code>varEstInputs</code></td>
<td>
<p>when <code>returnVarEstInputs</code> is <code>TRUE</code>,
this element is returned. These are
used for calculating covariances with
<code><a href="#topic+varEstToCov">varEstToCov</a></code>.</p>
</td></tr>
<tr><td><code>standardizeWithSamplingVar</code></td>
<td>
<p>when <code>standardizeWithSamplingVar</code>
is set to <code>TRUE</code>, this element is
returned. Calculates the standard deviation
of the standardized
regression coefficients like any other
variable.</p>
</td></tr>
</table>


<h3>Testing</h3>

<p>Of the common hypothesis tests for joint parameter testing, only the Wald
test is widely used with plausible values and sample weights. As such, it
replaces, if imperfectly, the Akaike Information Criteria (AIC), the
likelihood ratio test, chi-squared, and analysis of variance (ANOVA, including <em>F</em>-tests). See <code><a href="#topic+waldTest">waldTest</a></code> or
the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-WaldTest.pdf"><em>Methods and Overview of Using EdSurvey for Running Wald Tests</em></a>.
</p>


<h3>Author(s)</h3>

<p>Paul Bailey
</p>


<h3>References</h3>

<p>Binder, D. A. (1983). On the variances of asymptotically normal estimators from complex surveys. <em>International Statistical Review</em>, <em>51</em>(3), 279&ndash;292.
</p>
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>. New York, NY: Wiley.
</p>
<p>van Buuren, S. (2012). <em>Flexible imputation of missing data</em>. New York, NY: CRC Press.
</p>
<p>Weisberg, S. (1985). <em>Applied linear regression</em> (2nd ed.). New York, NY: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# by default uses jackknife variance method using replicate weights
lm1 &lt;- lm.sdf(composite ~ dsex + b017451, data=sdf)
lm1

# the summary function displays detailed results
summary(lm1)

# to show standardized regression coefficients
summary(lm1, src=TRUE)

# to specify a variance method, use varMethod
lm2 &lt;- lm.sdf(composite ~ dsex + b017451, data=sdf, varMethod="Taylor")
lm2
summary(lm2)

# use relevel to set a new omitted category
lm3 &lt;- lm.sdf(composite ~ dsex + b017451, data=sdf, relevels=list(dsex="Female"))
summary(lm3)
# test of a simple joint hypothesis
waldTest(lm3, "b017451")

# use recode to change values for specified variables
lm4 &lt;- lm.sdf(composite ~ dsex + b017451, data=sdf,
              recode=list(b017451=list(from=c("Never or hardly ever",
                                              "Once every few weeks",
                                              "About once a week"),
                                       to=c("Infrequently")),
                          b017451=list(from=c("2 or 3 times a week","Every day"),
                                       to=c("Frequently"))))
# Note: "Infrequently" is the dropped level for the recoded b017451
summary(lm4)

## End(Not run)
</code></pre>

<hr>
<h2 id='merge.edsurvey.data'>EdSurvey Merge</h2><span id='topic+merge.edsurvey.data'></span><span id='topic+merge.edsurvey.data.frame'></span>

<h3>Description</h3>

<p>Takes a <code>data.frame</code> or a <code>light.edsurvey.data.frame</code> and merges with a <code>edsurvey.data.frame</code> into it's internal data cache.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'edsurvey.data.frame'
merge(x, y, by = "id", by.x = by, by.y = by, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge.edsurvey.data_+3A_x">x</code></td>
<td>
<p>a <code>edsurvey.data.frame</code>. The <code>x</code> object is retained and has y values stored in the internal cache in memory.
<code>x</code> also supports <code>light.edusrvey.data.frame</code> objects if <code>y</code> is a <code>data.frame</code> or <code>light.edsurvey.data.frame</code> object.</p>
</td></tr>
<tr><td><code id="merge.edsurvey.data_+3A_y">y</code></td>
<td>
<p>either a <code>light.edsurvey.data.frame</code> or a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="merge.edsurvey.data_+3A_by">by</code></td>
<td>
<p>the column name(s) to perform the data merge operation.  If differing column names between the <code>x</code> and <code>y</code> objects, use the <code>by.x</code> and <code>by.y</code> arguments.</p>
</td></tr>
<tr><td><code id="merge.edsurvey.data_+3A_by.x">by.x</code></td>
<td>
<p>the column name(s) to perform the data merge operation for the <code>x</code> object.  Defaults to <code>by</code> value.</p>
</td></tr>
<tr><td><code id="merge.edsurvey.data_+3A_by.y">by.y</code></td>
<td>
<p>the column name(s) to perform the data merge operation for the <code>y</code> object.  Defaults to <code>by</code> value.</p>
</td></tr>
<tr><td><code id="merge.edsurvey.data_+3A_...">...</code></td>
<td>
<p>arguments passed to merge, note that <code>all.x</code> will always be <code>TRUE</code> (the data on the <code>edsurvey.data.frame</code> will always be kept) and <code>all.y</code> will always be <code>FALSE</code> to avoid adding data not on the <code>edsurvey.data.frame</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a merged data set the same object type as <code>x</code>. For <code>edsurvey.data.frame</code> objects then resulting merged data is stored in the objects internal data cache.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+merge">merge</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in NAEP primer data
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))
lsdf &lt;- getData(data=sdf, varnames=c("dsex", "b017451"), addAttributes = TRUE)
df &lt;- data.frame(dsex = c("Male","Female"), dsex2 = c("Boy","Girl"))

#merging an edsurvey.data.frame with a data.frame/light.edsurvey.data.frame
#returns an edsurvey.data.frame object
sdf2 &lt;- merge(sdf, df, by = "dsex")
table(sdf2$dsex2)

# merging a light.edsurvey.data.frame with a data.frame
# returns a light.edsurvey.data.frame object
merged_lsdf &lt;- merge(lsdf,df, by = "dsex")
class(merged_lsdf) #  "light.edsurvey.data.frame" "data.frame"
head(merged_lsdf) # shows merge results

# merging behaves similarly to base::merge
df2 &lt;- data.frame(dsex = c("Male","Female"), b017451 = c(1,2))
merged_lsdf2 &lt;- merge(lsdf,df2, by = "dsex")
names(merged_lsdf2) # "dsex"      "b017451.x" "b017451.y"
head(merged_lsdf2) # shows merge results

## End(Not run)
</code></pre>

<hr>
<h2 id='mergev'>mergev</h2><span id='topic+mergev'></span>

<h3>Description</h3>

<p>More verbose merge function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mergev(
  x,
  y,
  by = NULL,
  by.x = NULL,
  by.y = NULL,
  all.x = NULL,
  all.y = NULL,
  all = FALSE,
  order = c("sort", "unsorted", "x", "y"),
  fast = FALSE,
  merge.type.colname = "merge.type",
  return.list = FALSE,
  verbose = TRUE,
  showWarnings = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mergev_+3A_x">x</code></td>
<td>
<p>first data.frame to merge, same as in <code><a href="base.html#topic+merge">merge</a></code>.</p>
</td></tr>
<tr><td><code id="mergev_+3A_y">y</code></td>
<td>
<p>second data.frame to merge, same as in <code><a href="base.html#topic+merge">merge</a></code>.</p>
</td></tr>
<tr><td><code id="mergev_+3A_by">by</code></td>
<td>
<p>character vector of column names to merge by. When <code>by</code> is used, the column names
must be the same in <code>x</code> and <code>y</code>. Silently overrides <code>by.x</code>
and <code>by.y</code></p>
</td></tr>
<tr><td><code id="mergev_+3A_by.x">by.x</code></td>
<td>
<p>character vector of column names on <code>x</code> to merge by. The resulting file will have
these names.</p>
</td></tr>
<tr><td><code id="mergev_+3A_by.y">by.y</code></td>
<td>
<p>character vector of column names on <code>y</code> to merge by.</p>
</td></tr>
<tr><td><code id="mergev_+3A_all.x">all.x</code></td>
<td>
<p>logical value indicating if unmerged rows from <code>x</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="mergev_+3A_all.y">all.y</code></td>
<td>
<p>logical value indicating if unmerged rows from <code>y</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="mergev_+3A_all">all</code></td>
<td>
<p>logical value indicating if unmerged rows from <code>x</code> and <code>y</code> should be included in the output.
Silently overrides <code>all.x</code> and <code>all.y</code>.</p>
</td></tr>
<tr><td><code id="mergev_+3A_order">order</code></td>
<td>
<p>character string from &quot;sort&quot;, &quot;unsorted&quot;, &quot;x&quot;, and &quot;y&quot;.
Specifies the order of the output. Setting this to &quot;sort&quot;
gives the same result as <code><a href="base.html#topic+merge">merge</a></code> with sort=TRUE.
unsorted gives the same result as sort=FALSE. &quot;x&quot; and &quot;y&quot; sort by the incoming
sort order of <code>x</code> and <code>y</code>, respectively.</p>
</td></tr>
<tr><td><code id="mergev_+3A_fast">fast</code></td>
<td>
<p>logical value indicating if <code>data.table</code> should be used to do the merge.</p>
</td></tr>
<tr><td><code id="mergev_+3A_merge.type.colname">merge.type.colname</code></td>
<td>
<p>character indicating the column name of the resulting merge type column.
See description.</p>
</td></tr>
<tr><td><code id="mergev_+3A_return.list">return.list</code></td>
<td>
<p>logical value indicating if the merged data.frame and verbose output should be
returned as elements of a list. Defaults to FALSE where the function
simply returns a data.frame.</p>
</td></tr>
<tr><td><code id="mergev_+3A_verbose">verbose</code></td>
<td>
<p>logical value indicating if output should be reported. Defaults to TRUE. Useful for testing.</p>
</td></tr>
<tr><td><code id="mergev_+3A_showwarnings">showWarnings</code></td>
<td>
<p>logical value to output warning messages (TRUE) or suppress (FALSE).  Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="mergev_+3A_...">...</code></td>
<td>
<p>additional parameters passed to merge.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a wrapper for the base package merge function that prints out verbose information
about the merge, including the merge type (one/many to one/many), the overlapping column
names that will have suffixes applied, the number of rows and the number of unique
keys that are in each dataset and in the resulting dataset.
</p>
<p>Also gives more detailed errors when, e.g. the columns named in the <code>by</code> argument are
not on the <code>x</code> or <code>y</code> data.frames.
</p>


<h3>Value</h3>

<p>depends on the value of <code>return.list</code>.
</p>
<p>When <code>return.list</code> is <code>FALSE</code>, returns a <code>data.frame</code>.
</p>
<p>When <code>return.list</code> is <code>TRUE</code>, returns a list with two elements. The first is the same <code>data.frame</code> result. The second
is a list with the values that were printed out. Elements include merge.type with two elements, each &quot;one&quot; or &quot;many&quot; indicating the
merge type for <code>x</code> and <code>y</code>, respectively; inBoth, the list of column names in both merged data.frames; and merge.matrix
the matrix printed out by this function.
</p>

<hr>
<h2 id='mixed.sdf'>EdSurvey Mixed-Effects Model</h2><span id='topic+mixed.sdf'></span>

<h3>Description</h3>

<p>Fits a linear weighted mixed-effects model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixed.sdf(
  formula,
  data,
  weightVars = NULL,
  weightTransformation = TRUE,
  recode = NULL,
  defaultConditions = TRUE,
  tolerance = 0.01,
  nQuad = NULL,
  verbose = 0,
  family = NULL,
  centerGroup = NULL,
  centerGrand = NULL,
  fast = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixed.sdf_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code>
for the multilevel regression or mixed model. See Examples and the vignette titled
<em><a href="https://www.air.org/sites/default/files/EdSurvey-Mixed_Models.pdf">Methods Used for Estimating Mixed-Effects Models in EdSurvey</a></em>
for more details on how to specify a mixed model. If <em>y</em> is
left blank, the default subject scale or subscale variable
will be used. (You can find the default using
<code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>.) If <em>y</em> is a variable
for a subject scale or subscale (one of the names shown by
<code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>), then that subject scale
or subscale is used.</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or a <code>light.edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_weightvars">weightVars</code></td>
<td>
<p>character vector indicating weight variables for
corresponding levels to use. The <code>weightVar</code> must be
the weights for the <code>edsurvey.data.frame</code>. The weight variables
must be in the order of level (from lowest to highest level).</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_weighttransformation">weightTransformation</code></td>
<td>
<p>a logical value to indicate whether the function
should standardize weights before using it in the
multilevel model. If set to <code>TRUE</code>, the
function will look up standard weight
transformation methods often used for a specific
survey. Weight transformation can be found in the vignette titled
<em><a href="https://www.air.org/sites/default/files/EdSurvey-Mixed_Models.pdf">Methods Used for Estimating Mixed-Effects Models in EdSurvey</a></em>.
If set to <code>FALSE</code> or if the survey of the specified <code>data</code> does
not have a standard weight transformation method,
raw weights will be used.</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>. Can be set as
<code>recode=</code><code>list(</code><code>var1</code> <code>=</code> <code>list(</code><code>from=</code> <code>c("a",</code> <code>"b",</code> <code>"c"),</code> <code>to=</code> <code>"d"))</code>.
See Examples in <code><a href="#topic+lm.sdf">lm.sdf</a></code>.</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of
<code>TRUE</code>, uses the default conditions stored in
an <code>edsurvey.data.frame</code> to subset the data.
Use <code>print</code> on an <code>edsurvey.data.frame</code>
to see the default conditions.</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_tolerance">tolerance</code></td>
<td>
<p>depreciated, no effect</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_nquad">nQuad</code></td>
<td>
<p>depreciated, no effect</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_verbose">verbose</code></td>
<td>
<p>an integer; when set to <code>1</code>, it will print out
the brief progress of the function <code>mix.sdf</code>.
Users can use these traced messages for further diagnosis.
When set to <code>2</code>, it will print
out the detailed progress, including temporary estimates
during the optimization. Defaults to <code>0</code>, which
will run the function without output.</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_family">family</code></td>
<td>
<p>this argument is depreciated; please use the <code>WeMix</code>
package's <code>mix</code> function directly for binomial models.</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_centergroup">centerGroup</code></td>
<td>
<p>a list in which the name of each element is the name of the aggregation level,
and the element is a formula of variable names to be group mean centered. For example, to group mean center
gender and age within the group student: <code>list("student"= ~gender+age)</code>. Defaults to <code>NULL</code>, which means
predictors are not adjusted by group centering. See Examples in the <code>WeMix</code> function <code><a href="WeMix.html#topic+mix">mix</a></code>.</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_centergrand">centerGrand</code></td>
<td>
<p>a formula of variable names to be grand mean centered. For example, to center the
variable education by overall mean of education: <code>~education</code>. Defaults to <code>NULL</code>, which means predictors
are not adjusted by grand centering.</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_fast">fast</code></td>
<td>
<p>depreciated, no effect</p>
</td></tr>
<tr><td><code id="mixed.sdf_+3A_...">...</code></td>
<td>
<p>other potential arguments to be used in <code><a href="WeMix.html#topic+mix">mix</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code>mix</code> call in the <code>WeMix</code> package to fit mixed models.
When the outcome does not have plausible values, the variance estimator directly from
the <code>mix</code> function is used; these account for covariance at the top level
of the model specified by the user.
</p>
<p>When the outcome has plausible values, the coefficients are estimated in the same
way as in <code>lm.sdf</code>, that is, averaged across the plausible values.
In addition, the variance of the coefficients is estimated
as the sum of the variance estimate from the <code>mix</code> function and the
imputation variance. The formula for the imputation variance is, again, the same
as for <code>lm.sdf</code>,
with the same estimators as in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>.
In the section
&ldquo;Estimation of Standard Errors of Weighted Means When Plausible Values Are Present, Using the Jackknife Method&rdquo;
in the formula for <code class="reqn">V_{imp}</code>, the variance
and estimates of the variance components are estimated with the same formulas as
the regression coefficients.
</p>


<h3>Value</h3>

<p>A <code>mixedSdfResults</code> object with the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the original call used in <code>mixed.sdf</code> </p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula used to fit the model</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>a vector of coefficient estimates</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>a vector with the standard error estimates of the coefficients and the standard error of the variance components</p>
</td></tr>
<tr><td><code>vars</code></td>
<td>
<p>estimated variance components of the model</p>
</td></tr>
<tr><td><code>levels</code></td>
<td>
<p>the number of levels in the model</p>
</td></tr>
<tr><td><code>ICC</code></td>
<td>
<p>the intraclass correlation coefficient of the model</p>
</td></tr>
<tr><td><code>npv</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>ngroups</code></td>
<td>
<p>a <code>data.frame</code> that includes the number of observations for each group</p>
</td></tr>
<tr><td><code>n0</code></td>
<td>
<p>the number of observations in the original data</p>
</td></tr>
<tr><td><code>nused</code></td>
<td>
<p>the number of observations used in the analysis</p>
</td></tr>
<tr><td><code>model.frame</code></td>
<td>
<p>the data used in the model</p>
</td></tr>
</table>
<p>If the formula does not involve plausible values, the function will return the following additional elements:
</p>
<table>
<tr><td><code>lnlf</code></td>
<td>
<p>the likelihood function </p>
</td></tr>
<tr><td><code>lnl</code></td>
<td>
<p>the log-likelihood of the model </p>
</td></tr>
</table>
<p>If the formula involves plausible values, the function will return the following additional elements:
</p>
<table>
<tr><td><code>Vimp</code></td>
<td>
<p>the estimated variance from uncertainty in the scores</p>
</td></tr>
<tr><td><code>Vjrr</code></td>
<td>
<p>the estimated variance from sampling</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Bailey, Trang Nguyen, and Claire Kelley
</p>


<h3>References</h3>

<p>Rabe-Hesketh, S., &amp; Skrondal, A. (2006). Multilevel modelling of complex
survey data. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society), 169</em>(4), 805&ndash;827.
</p>


<h3>See Also</h3>

<p><code><a href="WeMix.html#topic+mix">mix</a></code> and <code><a href="#topic+lm.sdf">lm.sdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# save TIMSS 2015 data to ~/TIMSS/2015
downloadTIMSS(root="~/", years=2015)
fin &lt;- readTIMSS("~/TIMSS/2015", countries="fin", gradeLvl=4)
# uses all plausible values
mix1 &lt;- mixed.sdf(mmat ~ itsex + (1|idschool), data = fin,
                  weightVar=c("totwgt","schwgt"), weightTransformation=FALSE)
summary(mix1)
# uses only one plausible value
mix2 &lt;- mixed.sdf(asmmat01 ~ itsex + (1|idschool), data = fin,
                  weightVar=c("totwgt","schwgt"), weightTransformation=FALSE)
summary(mix2)

## End(Not run)
</code></pre>

<hr>
<h2 id='mml.sdf'>EdSurvey Direct Estimation</h2><span id='topic+mml.sdf'></span><span id='topic+defaultNAEPScoreCard'></span><span id='topic+defaultTIMSSScoreDict'></span>

<h3>Description</h3>

<p>Prepare IRT parameters and score items and then estimate a linear model with direct estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mml.sdf(
  formula,
  data,
  weightVar = NULL,
  dropOmittedLevels = TRUE,
  composite = TRUE,
  verbose = 0,
  multiCore = FALSE,
  numberOfCores = NULL,
  minNode = -4,
  maxNode = 4,
  Q = 34,
  idVar = NULL,
  returnMmlCall = FALSE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mml.sdf_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code> for the
model.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> for the National Assessment of Educational Progress (NAEP)
and the Trends in International Mathematics and Science Study (TIMSS).
The attributes <code>dichotParamTab</code>, <code>polyParamTab</code>, <code>testData</code>,
<code>scoreCard</code> (for NAEP), and <code>scoreDict</code> (for TIMSS) must not be <code>NULL</code>.
Use the function <code>setNAEPScoreCard</code> or <code>setAttributes</code> to set attributes.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_weightvar">weightVar</code></td>
<td>
<p>a character indicating the weight variable to use.
The <code>weightVar</code> must be one of the weights for the
<code>edsurvey.data.frame</code>. If <code>NULL</code>, it  uses the default
for the <code>edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the value of <code>TRUE</code>, drops
the levels of all factor variables that are specified
in an <code>edsurvey.data.frame</code>. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the omitted levels.
To draw plausible values for the full dataset, the user must set this to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_composite">composite</code></td>
<td>
<p>logical; for a NAEP composite, setting to <code>FALSE</code> fits the model to all items at once,
in a single construct, whereas setting to <code>TRUE</code> fits the model as a NAEP composite
(i.e., a weighted average of the subscales). This argument is not applicable for TIMSS which is always
fit as an overall (non-composite).</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_verbose">verbose</code></td>
<td>
<p>logical; indicates whether a detailed printout should display during execution, only for NAEP data.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_multicore">multiCore</code></td>
<td>
<p>allows the <code>foreach</code> package to be used. This function will setup and take down the cluster.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_numberofcores">numberOfCores</code></td>
<td>
<p>the number of cores to be used when using <code>multiCore</code>. Defaults to 75% of available cores. Users
can check available cores with <code>detectCores()</code>.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_minnode">minNode</code></td>
<td>
<p>numeric; minimum integration point in direct estimation; see <code><a href="Dire.html#topic+mml">mml</a></code>.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_maxnode">maxNode</code></td>
<td>
<p>numeric; maximum integration point in direct estimation; see <code><a href="Dire.html#topic+mml">mml</a></code>.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_q">Q</code></td>
<td>
<p>integer; number of integration points per student used when integrating over the levels of the latent outcome construct.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_idvar">idVar</code></td>
<td>
<p>a variable that is used to explicitly define the name of the student identifier
variable to be used from <code>data</code>. Defaults to <code>NULL</code>, and <code>sid</code> is used
as the student identifier.</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_returnmmlcall">returnMmlCall</code></td>
<td>
<p>logical; when <code>TRUE</code>, do not process the mml call but instead return it for the user to edit before calling</p>
</td></tr>
<tr><td><code id="mml.sdf_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Typically, models are fit with NAEP data using plausible values to integrate out the uncertainty in the measurement of individual
student outcomes. When direct estimation is used, the measurement error is integrated out explicitly using <code>Q</code> quadrature points.
See documentation for <code><a href="Dire.html#topic+mml">mml</a></code> in the <code>Dire</code> package.
</p>
<p>The <code>scoreDict</code> helps turn response categories that are not simple item responses, such as <code>Not Reached</code> and <code>Multiple</code>,
to something coded as inputs for the <code>mml</code> function in <code>Dire</code>. How <code>mml</code> treats these values depends on the test.
For NAEP, for a dichotomous item, 8 is scored as the same proportion correct as the guessing parameter for that item, 0 is
an incorrect response, an NA does not change the student's score, and 1 is correct. TIMSS does not require a <code>scoreDict</code>.
</p>


<h3>Value</h3>

<p>An <code>mml.sdf</code> object, which is the outcome from <code>mml.sdf</code>, with the following elements:
</p>
<table>
<tr><td><code>mml</code></td>
<td>
<p>an object containing information from the <code>mml</code> procedure.
<code>?mml</code> can be used for further information.</p>
</td></tr>
<tr><td><code>scoreDict</code></td>
<td>
<p>the scoring used in the <code>mml</code> procedure</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code>itemMapping</code></td>
<td>
<p>the item mapping used in the <code>mml</code> procedure</p>
</td></tr></table>
<p>.
</p>


<h3>References</h3>

<p>Cohen, J., &amp; Jiang, T. (1999). Comparison of partially measured latent traits across nominal subgroups.
<em>Journal of the American Statistical Association</em>, <em>94</em>(448), 1035&ndash;1044. https://doi.org/10.2307/2669917
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Direct Estimation with NAEP 
# Load data 
sdfNAEP &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# Inspect scoring guidelines
defaultNAEPScoreCard()

# example output: 
#          resCat pointMult pointConst
# 1     Multiple         8          0
# 2  Not Reached        NA         NA
# 3      Missing        NA         NA
# 4      Omitted         8          0
# 5    Illegible         0          0
# 6 Non-Rateable         0          0
# 7     Off Task         0          0

# Run NAEP model, warnings are about item codings
mmlNAEP &lt;- mml.sdf(algebra ~ dsex + b013801, sdfNAEP, weightVar='origwt')

# Call with Taylor
summary(mmlNAEP, varType="Taylor", strataVar="repgrp1", PSUVar="jkunit")

## Direct Estimation with TIMSS 
# Load data 
downloadTIMSS("~/", year=2015)
sdfTIMSS &lt;- readTIMSS("~/TIMSS/2015", countries="usa", grade = "4")

# Run TIMSS model, warnings are about item codings 
mmlTIMSS &lt;- mml.sdf(mmat ~ itsex + asbg04, sdfTIMSS, weightVar='totwgt')

# Call with Taylor
summary(mmlTIMSS, varType="Taylor", strataVar="jkzone", PSUVar="jkrep")

## End(Not run)


</code></pre>

<hr>
<h2 id='mvrlm.sdf'>Multivariate Regression</h2><span id='topic+mvrlm.sdf'></span>

<h3>Description</h3>

<p>Fits a multivariate linear model that uses weights and variance
estimates appropriate for the <code>edsurvey.data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrlm.sdf(
  formula,
  data,
  weightVar = NULL,
  relevels = list(),
  jrrIMax = 1,
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  returnVarEstInputs = FALSE,
  estMethod = "OLS",
  verbose = TRUE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvrlm.sdf_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="Formula.html#topic+Formula">Formula</a></code> for the
linear model. See <code><a href="Formula.html#topic+Formula">Formula</a></code>;
left-hand side variables are separated with
vertical pipes (<code>|</code>). See Examples.</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_weightvar">weightVar</code></td>
<td>
<p>character indicating the weight variable to use (see Details).
The <code>weightVar</code> must be one of the weights for the
<code>edsurvey.data.frame</code>. If <code>NULL</code>, uses the default
for the <code>edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_relevels">relevels</code></td>
<td>
<p>a list. Used to change the contrasts from the
default treatment contrasts to treatment contrasts with a chosen omitted
group (the reference group).
To do this, the user puts an element on the list with the same name as
a variable to change contrasts on
and then make the value for that list element equal to the value
that should
be the omitted group (the reference group).</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>a numeric value; when using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=1</code>, uses the
sampling variance from the first plausible value as the component for sampling variance estimation. The <code class="reqn">V_{jrr}</code>
term (see
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>)
can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, drops
those levels of all factor variables that are specified
in <code>edsurvey.data.frame</code>. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the omitted levels.</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, uses
the default conditions stored in <code>edsurvey.data.frame</code>
to subset the data. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the default conditions.</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>. Can be set as
<code>recode</code> <code>=</code> <code>list(var1=</code> <code>list(from=c("a","b","c"),</code> <code>to ="d"))</code>.</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_returnvarestinputs">returnVarEstInputs</code></td>
<td>
<p>a logical value. Set to <code>TRUE</code> to return the
inputs to the jackknife and imputation variance
estimates, which allow for
computation of covariances between estimates.</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_estmethod">estMethod</code></td>
<td>
<p>a character value indicating which estimation method to use.
Default is <code>OLS</code>; other option is <code>GLS</code>.</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_verbose">verbose</code></td>
<td>
<p>logical; indicates whether a detailed printout should display during execution</p>
</td></tr>
<tr><td><code id="mvrlm.sdf_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements an estimator that correctly handles multiple left-hand
side variables that are either numeric or plausible values, allows for survey
sampling weights, and estimates variances using the jackknife replication method.
The vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
describes estimation of the reported statistics.
</p>
<p>The <b>coefficients</b> are estimated using the sample weights according to the section
&ldquo;Estimation of Weighted Means When Plausible Values Are Not Present&rdquo;
or the section
&ldquo;Estimation of Weighted Means When Plausible Values Are Present,&rdquo;
depending on if there are assessment variables or variables with plausible values in them.
</p>
<p>The <b>coefficient of determination (R-squared value)</b> is similarly estimated by finding
the average R-squared using the sample weights for each set of plausible values.
</p>


<h4>Variance estimation of coefficients</h4>

<p>All variance estimation methods are shown in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>.
</p>
<p>When the predicted value does not have plausible values, the variance of the coefficients
is estimated according to the section &ldquo;Estimation of Standard Errors
of Weighted Means When Plausible Values Are Not Present, Using the Jackknife Method.&rdquo;
</p>
<p>When plausible values are present, the variance of the coefficients is estimated according to the section
&ldquo;Estimation of Standard Errors of Weighted Means When
Plausible Values Are Present, Using the Jackknife Method.&rdquo;
</p>

<p>For more information on the specifics of multivariate regression, see the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Multivariate_Regression.pdf">Methods and Overview of Using EdSurvey for Multivariate Regression</a>.
</p>


<h3>Value</h3>

<p>An <code>edsurvey.mvrlm</code> with elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula used to fit the model</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>the estimates of the coefficients</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard error estimates of the coefficients</p>
</td></tr>
<tr><td><code>Vimp</code></td>
<td>
<p>the estimated variance caused by uncertainty in the scores (plausible value variables)</p>
</td></tr>
<tr><td><code>Vjrr</code></td>
<td>
<p>the estimated variance caused by sampling</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>varm</code></td>
<td>
<p>the variance estimates under the various plausible values</p>
</td></tr>
<tr><td><code>coefm</code></td>
<td>
<p>the values of the coefficients under the various plausible values</p>
</td></tr>
<tr><td><code>coefmat</code></td>
<td>
<p>the coefficient matrix (typically produced by the summary of a model)</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>the coefficient of determination</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>
<p>the name of the weight variable</p>
</td></tr>
<tr><td><code>npv</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>njk</code></td>
<td>
<p>the number of the jackknife replicates used</p>
</td></tr>
<tr><td><code>varEstInputs</code></td>
<td>
<p>When <code>returnVarEstInputs</code> is <code>TRUE</code>,
this element is returned. These are
used for calculating covariances with
<code><a href="#topic+varEstToCov">varEstToCov</a></code>.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>residuals for each of the PV models</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>model fitted values</p>
</td></tr>
<tr><td><code>residCov</code></td>
<td>
<p>residual covariance matrix for dependent variables</p>
</td></tr>
<tr><td><code>residPV</code></td>
<td>
<p>residuals for each dependent variable</p>
</td></tr>
<tr><td><code>inputs</code></td>
<td>
<p>coefficient estimation input matrices</p>
</td></tr>
<tr><td><code>n0</code></td>
<td>
<p>full data <em>n</em></p>
</td></tr>
<tr><td><code>nUsed</code></td>
<td>
<p><em>n</em> used for model</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>imputation variance-covariance matrix, before multiplication by (M+1)/M</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>sampling variance-covariance matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alex Lishinski and Paul Bailey
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+lm.sdf">lm.sdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# use | symbol to separate dependent variables in the left-hand side of formula
mvrlm.fit &lt;- mvrlm.sdf(algebra | geometry ~ dsex + m072801, jrrIMax = 5, data = sdf)

# print method returns coefficients, as does coef method
mvrlm.fit
coef(mvrlm.fit)

# for more detailed results, use summary:
summary(mvrlm.fit)

# details of model can also be accessed through components of the returned object; for example:

# coefficients (one column per dependent variable)
mvrlm.fit$coef
# coefficient table with standard errors and p-values (1 table per dependent variable)
mvrlm.fit$coefmat
# R-squared values (one per dependent variable)
mvrlm.fit$r.squared
# residual covariance matrix
mvrlm.fit$residCov

# dependent variables can have plausible values or not (or a combination)

mvrlm.fit &lt;- mvrlm.sdf(composite | mrps22 ~ dsex + m072801, data = sdf, jrrIMax = 5)
summary(mvrlm.fit)

mvrlm.fit &lt;- mvrlm.sdf(algebra | geometry | measurement ~ dsex + m072801, data = sdf, jrrIMax = 5)
summary(mvrlm.fit)

mvrlm.fit &lt;- mvrlm.sdf(mrps51 | mrps22 ~ dsex + m072801, data = sdf, jrrIMax = 5)
summary(mvrlm.fit)

# hypotheses about coefficient restrictions can also be tested using the Wald test

mvr &lt;- mvrlm.sdf(algebra | geometry ~ dsex + m072801, data = sdf)

hypothesis &lt;- c("geometry_dsexFemale = 0", "algebra_dsexFemale = 0")

# test statistics based on the F and chi-squared distribution are available
linearHypothesis(mvr, hypothesis = hypothesis, test = "F")
linearHypothesis(mvr, hypothesis = hypothesis, test = "Chisq")

## End(Not run)
</code></pre>

<hr>
<h2 id='oddsRatio'>Odds Ratios for edsurveyGlm Models</h2><span id='topic+oddsRatio'></span>

<h3>Description</h3>

<p>Converts coefficients from <code>edsurveyGlm</code> logit regression model to odds ratios.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oddsRatio(model, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oddsRatio_+3A_model">model</code></td>
<td>
<p>an <code>edsurveyGlm</code> model</p>
</td></tr>
<tr><td><code id="oddsRatio_+3A_alpha">alpha</code></td>
<td>
<p>the alpha level for the confidence level</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>oddsRatio.edsurveyGlm</code> object with the following elements:
</p>
<table>
<tr><td><code>OR</code></td>
<td>
<p>odds ratio coefficient estimates</p>
</td></tr>
<tr><td><code>2.5%</code></td>
<td>
<p>lower bound 95% confidence interval</p>
</td></tr>
<tr><td><code>97.5%</code></td>
<td>
<p>upper bound 95% confidence interval</p>
</td></tr>
</table>

<hr>
<h2 id='parseNAEPdct'>Format AM dct File for Use with DirectEstimation</h2><span id='topic+parseNAEPdct'></span>

<h3>Description</h3>

<p>Takes an <code>AM dct</code> file and formats it for use with the <code>mml</code> method
as <code>paramTab</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parseNAEPdct(dct, mml = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parseNAEPdct_+3A_dct">dct</code></td>
<td>
<p>a file location from which to read the <code>dct</code> file</p>
</td></tr>
<tr><td><code id="parseNAEPdct_+3A_mml">mml</code></td>
<td>
<p>a logical for if the paramTab is being used in <code>mml.sdf</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> in a format suitable for use with <code>mml</code> as
a <code>paramTab</code>.
</p>


<h3>Author(s)</h3>

<p>Sun-Joo Lee
</p>

<hr>
<h2 id='parseScript_SPSS'>Parse SPSS Syntax Script for Fixed-Width Data Files</h2><span id='topic+parseScript_SPSS'></span>

<h3>Description</h3>

<p>Parses an SPSS Syntax Script (.sps) file to return information relating to fixed-width data files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parseScript_SPSS(
  spsFilePath,
  verbose = FALSE,
  outputFormat = c("data.frame"),
  encoding = getOption("encoding")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parseScript_SPSS_+3A_spsfilepath">spsFilePath</code></td>
<td>
<p>a character value of the file path to the SPSS script to parse.</p>
</td></tr>
<tr><td><code id="parseScript_SPSS_+3A_verbose">verbose</code></td>
<td>
<p>a logic value to indicate if user wishes to print parsing activity to console. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="parseScript_SPSS_+3A_outputformat">outputFormat</code></td>
<td>
<p>a named argument to indicate which output format the resulting object should be.  See details for information on each format.
Currently, <code>data.frame</code> format is only supported.</p>
</td></tr>
<tr><td><code id="parseScript_SPSS_+3A_encoding">encoding</code></td>
<td>
<p>a character value to indicate the encoding specification that is used by <code>readLines</code> base function for the <code>spsFilePath</code> parameter.
Only adjust this parameter if the original file encoding of the file is known, is not producing correct string values, or other errors occur.
See <code>?readLines</code> help for details about it's use for file encoding, and additional details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>NOT CURRENTLY EXPORTED!  In Future this could potentially be made to a separate R package
THIS parseScript_SPSS function should be used 100
Old/Previous SPSS script parsers should be slowly transitioned to utilize this function when possible to maximize code use.
</p>
<p>The SPSS syntax script parser is focused on gathering details for use with fixed-width data files.  This function scans for the following SPSS commands:
</p>

<ul>
<li><p>FILE HANDLE
</p>
</li>
<li><p>DATA LIST
</p>
</li>
<li><p>VARIABLE LABEL
</p>
</li>
<li><p>VALUE LABEL
</p>
</li>
<li><p>MISSING VALUE
</p>
</li></ul>

<p>The <code>outputFormat</code> specified will determine the result object returned.  This function currently supports the following formats.
</p>

<ul>
<li><p>data.frame
</p>

<ul>
<li><p>variableName - The variable name as defined in the script
</p>
</li>
<li><p>Start - The start number index of the variable defined for the fixed-width format layout
</p>
</li>
<li><p>End - The end number index of the variable defined for the fixed-width format layout
</p>
</li>
<li><p>Width - The length of how many columns the variable uses in the fixed-width format layout
</p>
</li>
<li><p>Attributes - Any SPSS attributes that are defined in the DATA LIST command.  This is typically only for field formatting.
</p>
</li>
<li><p>RecordNumber - Some fixed-width data files are considered &quot;multi-line&quot; where one record of data can span multiple rows in the file.
The RecordNumber indicates which line the variable is assigned.
</p>
</li>
<li><p>Labels - The descriptive label associated with the variable name to give more detail or context.
</p>
</li>
<li><p>labelValues - For categorical variables a stored value will typically be assigned a longer label/definition. This string identifies these mappings.
The '^' symbol is used to delimit each individual label value. Then additionally, the '=' is used to split the value from the left side of the '=' symbol,
and the remaining right-hand side of '=' is the text label for that value.
</p>
</li>
<li><p>dataType - A best-guess of the data type (either 'numeric' or 'character') without actually examining the data-file.
</p>
</li>
<li><p>missingValues - If a MISSING VALUE clause is included in the script this will list the values that are considered 'Missing'.
If multiple values specified, they will be delimited by a ';' (semi-colon) symbol.
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p>returns an object containing information specified by the <code>outputFormat</code> argument.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>

<hr>
<h2 id='percentile'>EdSurvey Percentiles</h2><span id='topic+percentile'></span>

<h3>Description</h3>

<p>Calculates the percentiles of a numeric variable in an
<code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentile(
  variable,
  percentiles,
  data,
  weightVar = NULL,
  jrrIMax = 1,
  varMethod = c("jackknife", "Taylor"),
  alpha = 0.05,
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  returnVarEstInputs = FALSE,
  returnNumberOfPSU = FALSE,
  pctMethod = c("symmetric", "unbiased", "simple"),
  confInt = TRUE,
  dofMethod = c("JR", "WS"),
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="percentile_+3A_variable">variable</code></td>
<td>
<p>the character name of the variable to percentiles computed,
typically a subject scale or subscale</p>
</td></tr>
<tr><td><code id="percentile_+3A_percentiles">percentiles</code></td>
<td>
<p>a numeric vector of percentiles in the range of 0 to 100
(inclusive)</p>
</td></tr>
<tr><td><code id="percentile_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or an
<code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="percentile_+3A_weightvar">weightVar</code></td>
<td>
<p>a character indicating the weight variable to use.</p>
</td></tr>
<tr><td><code id="percentile_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>a numeric value; when using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=1</code>, uses the
sampling variance from the first plausible value as the component for sampling variance estimation. The <code class="reqn">V_{jrr}</code>
term (see
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>)
can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="percentile_+3A_varmethod">varMethod</code></td>
<td>
<p>a character set to <code>jackknife</code> or <code>Taylor</code>
that indicates the variance estimation method used when
constructing the confidence intervals. The jackknife
variance estimation method is always
used to calculate the standard error.</p>
</td></tr>
<tr><td><code id="percentile_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level.
An <code>alpha</code> value of 0.05 would indicate a 95%
confidence interval and is the default.</p>
</td></tr>
<tr><td><code id="percentile_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of
<code>TRUE</code>, drops those levels of
all factor variables that are specified in
<code>achievementVars</code> and <code>aggregatBy</code>.
Use <code>print</code> on an <code>edsurvey.data.frame</code>
to see the omitted levels.</p>
</td></tr>
<tr><td><code id="percentile_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value
of <code>TRUE</code>, uses the default
conditions stored in an <code>edsurvey.data.frame</code>
to subset the data.
Use <code>print</code> on an <code>edsurvey.data.frame</code>
to see the default conditions.</p>
</td></tr>
<tr><td><code id="percentile_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to
<code>NULL</code>. Can be set as
<code>recode=</code><code>list(var1=</code> <code>list(from=</code> <code>c("a",</code>
<code>"b",</code> <code>"c"),</code>
<code>to=</code> <code>"d"))</code>.</p>
</td></tr>
<tr><td><code id="percentile_+3A_returnvarestinputs">returnVarEstInputs</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the
inputs to the jackknife and imputation variance
estimates which allows for the computation
of covariances between estimates.</p>
</td></tr>
<tr><td><code id="percentile_+3A_returnnumberofpsu">returnNumberOfPSU</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the number of
primary sampling units (PSUs)</p>
</td></tr>
<tr><td><code id="percentile_+3A_pctmethod">pctMethod</code></td>
<td>
<p>one of &ldquo;unbiased&rdquo;, &ldquo;symmetric&rdquo;, &ldquo;simple&rdquo;;
unbiased produces a weighted median unbiased percentile estimate,
whereas simple uses a basic formula that matches previously
published results. Symmetric uses a more basic formula
but requires that the percentile is symetric to multiplying
the quantity by negative one.</p>
</td></tr>
<tr><td><code id="percentile_+3A_confint">confInt</code></td>
<td>
<p>a Boolean indicating if the confidence interval should be returned</p>
</td></tr>
<tr><td><code id="percentile_+3A_dofmethod">dofMethod</code></td>
<td>
<p>passed to <code><a href="#topic+DoFCorrection">DoFCorrection</a></code> as the <code>method</code> argument</p>
</td></tr>
<tr><td><code id="percentile_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Percentiles, their standard errors, and confidence intervals
are calculated according to the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>.
The standard errors and confidence intervals are based
on separate formulas and assumptions.
</p>
<p>The Taylor series variance estimation procedure is not relevant to percentiles
because percentiles are not continuously differentiable.
</p>


<h3>Value</h3>

<p>The return type depends on whether the class of the <code>data</code> argument is an
<code>edsurvey.data.frame</code> or an <code>edsurvey.data.frame.list</code>.
</p>
<p><strong>The data argument is an edsurvey.data.frame</strong>
When the <code>data</code> argument is an <code>edsurvey.data.frame</code>,
<code>percentile</code> returns an S3 object of class <code>percentile</code>.
This is a <code>data.frame</code> with typical attributes (<code>names</code>,
<code>row.names</code>, and <code>class</code>) and additional attributes as follows:
</p>
<table>
<tr><td><code>n0</code></td>
<td>
<p>number of rows on <code>edsurvey.data.frame</code> before any conditions were applied</p>
</td></tr>
<tr><td><code>nUsed</code></td>
<td>
<p>number of observations with valid data and weights larger than zero</p>
</td></tr>
<tr><td><code>nPSU</code></td>
<td>
<p>number of PSUs used in the calculation</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call used to generate these results</p>
</td></tr>
</table>
<p>The columns of the <code>data.frame</code> are as follows:
</p>
<table>
<tr><td><code>percentile</code></td>
<td>
<p>the percentile of this row</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the estimated value of the percentile</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the jackknife standard error of the estimated percentile</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>confInt.ci_lower</code></td>
<td>
<p>the lower bound
of the confidence interval</p>
</td></tr>
<tr><td><code>confInt.ci_upper</code></td>
<td>
<p>the upper bound
of the confidence interval</p>
</td></tr>
<tr><td><code>nsmall</code></td>
<td>
<p>the number of units with more extreme results, averaged
across plausible values</p>
</td></tr>
</table>
<p>When the <code>confInt</code> argument is set to <code>FALSE</code>, the confidence
intervals are not returned.
</p>
<p><strong>The data argument is an edsurvey.data.frame.list</strong>
When the <code>data</code> argument is an <code>edsurvey.data.frame.list</code>,
<code>percentile</code> returns an S3 object of class <code>percentileList</code>.
This is a data.frame with a <code>call</code> attribute.
The columns in the <code>data.frame</code> are identical to those in the previous
section, but there also are columns from the <code>edsurvey.data.frame.list</code>.
</p>
<table>
<tr><td><code>covs</code></td>
<td>
<p>a column for each column in the <code>covs</code> value of the
<code>edsurvey.data.frame.list</code>.
See Examples.</p>
</td></tr>
</table>
<p>When <code>returnVarEstInputs</code> is <code>TRUE</code>, an attribute
<code>varEstInputs</code> also is returned that includes the variance estimate
inputs used for calculating covariances with <code><a href="#topic+varEstToCov">varEstToCov</a></code>.
</p>


<h3>Author(s)</h3>

<p>Paul Bailey
</p>


<h3>References</h3>

<p>Hyndman, R. J., &amp; Fan, Y. (1996). Sample quantiles in statistical packages. <em>American Statistician</em>, <em>50</em>, 361&ndash;365.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# get the median of the composite
percentile("composite", 50, sdf)

# get several percentiles
percentile("composite", c(0,1,25,50,75,99,100), sdf)
# build an edsurvey.data.frame.list
sdfA &lt;- subset(sdf, scrpsu %in% c(5,45,56))
sdfB &lt;- subset(sdf, scrpsu %in% c(75,76,78))
sdfC &lt;- subset(sdf, scrpsu %in% 100:200)
sdfD &lt;- subset(sdf, scrpsu %in% 201:300)

sdfl &lt;- edsurvey.data.frame.list(list(sdfA, sdfB, sdfC, sdfD),
                                 labels=c("A locations",
                                           "B locations",
                                           "C locations",
                                           "D locations"))
# this shows how these datasets will be described:
sdfl$covs

percentile("composite", 50, sdfl)
percentile("composite", c(25, 50, 75), sdfl)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.achievementLevels'>Print AchievementLevels Results</h2><span id='topic+print.achievementLevels'></span>

<h3>Description</h3>

<p>Prints details of discrete and cumulative achievement levels
calculated using weights and variance
estimates appropriate for the <code>edsurvey.data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'achievementLevels'
print(x, printCall = TRUE, printDiscrete = TRUE, printCumulative = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.achievementLevels_+3A_x">x</code></td>
<td>
<p>an <code>achievementLevels</code> object</p>
</td></tr>
<tr><td><code id="print.achievementLevels_+3A_printcall">printCall</code></td>
<td>
<p>a logical value; by default (<code>TRUE</code>), prints details about plausible
values and weights used for calculating achievement levels</p>
</td></tr>
<tr><td><code id="print.achievementLevels_+3A_printdiscrete">printDiscrete</code></td>
<td>
<p>a logical value; by default (<code>TRUE</code>), prints discrete achievement
levels if they are present in <code>x</code></p>
</td></tr>
<tr><td><code id="print.achievementLevels_+3A_printcumulative">printCumulative</code></td>
<td>
<p>a logical value; by default (<code>TRUE</code>), prints cumulative achievement
levels if they are present in <code>x</code></p>
</td></tr>
<tr><td><code id="print.achievementLevels_+3A_...">...</code></td>
<td>
<p>these arguments are not passed anywhere and are included only for compatibility</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Huade Huo and Ahmad Emad
</p>

<hr>
<h2 id='print.edsurvey.data.frame'>EdSurvey Metadata Summary</h2><span id='topic+print.edsurvey.data.frame'></span><span id='topic+print.edsurvey.data.frame.list'></span>

<h3>Description</h3>

<p>Prints metadata regarding an <code>edsurvey.data.frame</code> or an <code>edsurvey.data.frame.list</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'edsurvey.data.frame'
print(x, printColnames = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.edsurvey.data.frame_+3A_x">x</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="print.edsurvey.data.frame_+3A_printcolnames">printColnames</code></td>
<td>
<p>a logical value; set to <code>TRUE</code> to see all column names in the <code>edsurvey.data.frame</code>
or the <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="print.edsurvey.data.frame_+3A_...">...</code></td>
<td>
<p>these arguments are not passed anywhere and are included only for compatibility</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>

<hr>
<h2 id='print.gap'>Gap Analysis Printing</h2><span id='topic+print.gap'></span><span id='topic+print.gapList'></span>

<h3>Description</h3>

<p>Prints labels and a results vector of a gap analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gap'
print(x, ..., printPercentage = TRUE)

## S3 method for class 'gapList'
print(x, ..., printPercentage = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.gap_+3A_x">x</code></td>
<td>
<p>an <code>R</code> object representing a <code>gap</code> of class <code>gap</code> or <code>gapList</code></p>
</td></tr>
<tr><td><code id="print.gap_+3A_...">...</code></td>
<td>
<p>these arguments are not passed anywhere and are included only for compatibility</p>
</td></tr>
<tr><td><code id="print.gap_+3A_printpercentage">printPercentage</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to request printing
of the percentage in the groups. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Bailey
</p>

<hr>
<h2 id='read_ePIRLS'>Connect to ePIRLS Data</h2><span id='topic+read_ePIRLS'></span>

<h3>Description</h3>

<p>Opens a connection to an ePIRLS data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_ePIRLS(path, countries, forceReread = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_ePIRLS_+3A_path">path</code></td>
<td>
<p>a character value to the full directory path to the ePIRLS extracted SPSS (.sav) set of data</p>
</td></tr>
<tr><td><code id="read_ePIRLS_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include using
the three-digit ISO country code.
A list of country codes can be found on Wikipedia at
<a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>
or other online sources. Consult the <em>ePIRLS User Guide</em> to help determine what countries
are included within a specific testing year of ePIRLS.
To select all countries, use a wildcard value of <strong><code>*</code></strong>.</p>
</td></tr>
<tr><td><code id="read_ePIRLS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the <code>read_ePIRLS</code> function by
using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="read_ePIRLS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the ePIRLS international
database(s) using the <a href="https://www.iea.nl/data-tools/repository">IEA Study Data Repository</a>.
Data files require the SPSS data file (.sav) format using the default filenames.
</p>
<p>An ePIRLS <code>edsurvey.data.frame</code> includes three distinct data levels:
</p>

<ul>
<li><p> student
</p>
</li>
<li><p> school
</p>
</li>
<li><p> teacher
</p>
</li></ul>

<p>When the <code>getData</code> function is called using an ePIRLS <code>edsurvey.data.frame</code>,
the requested data variables are inspected, and it handles any necessary data merges automatically.
The <code>school</code> data always will be returned merged to the <code>student</code>
data, even if only <code>school</code> variables are requested.
If <code>teacher</code> variables are requested by the <code>getData</code> call, it will cause <code>teacher</code> data to be merged.
A <code>student</code> can be linked to many <code>teachers</code>, which varies widely between countries.
</p>
<p>Please note that calling the <code>dim</code> function for an ePIRLS <code>edsurvey.data.frame</code> will result in
the row count as if the <code>teacher</code> dataset was merged.
This row count will be considered the <code>full data N</code> of the <code>edsurvey.data.frame</code>, even if no <code>teacher</code> data were included in an analysis.
The column count returned by <code>dim</code> will be the count of unique column variables across all three data levels.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or an
<code>edsurvey.data.frame.list</code> if multiple countries are specified
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+readTIMSS">readTIMSS</a></code>, <code><a href="#topic+getData">getData</a></code>, and <code><a href="#topic+download_ePIRLS">download_ePIRLS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
usa &lt;- read_ePIRLS("~/ePIRLS/2016", countries = c("usa"))
gg &lt;- getData(usa, c("itsex", "totwgt", "erea"))
head(gg)
edsurveyTable(erea ~ itsex, usa)

## End(Not run)
</code></pre>

<hr>
<h2 id='readBTLS'>Connect to BTLS Data</h2><span id='topic+readBTLS'></span>

<h3>Description</h3>

<p>Opens a connection to the Beginning Teacher Longitudinal Study (BTLS) waves 1 through 5 data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readBTLS(dat_FilePath, spss_FilePath, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readBTLS_+3A_dat_filepath">dat_FilePath</code></td>
<td>
<p>a character value to the full path of the BTLS fixed-width (.dat) data file</p>
</td></tr>
<tr><td><code id="readBTLS_+3A_spss_filepath">spss_FilePath</code></td>
<td>
<p>a character value to the full path of the SPSS syntax file to process the <code>dat_FilePath</code></p>
</td></tr>
<tr><td><code id="readBTLS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose output while the <code>readBTLS</code> function is running to indicate processing progress
(the default value is <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads the <code>spss_FilePath</code> file to parse the <code>dat_FilePath</code> to an <code>edsurvey.data.frame</code>.
There is no cached data because the <code>dat_FilePath</code> format already is in fixed-width format.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for the BTLS waves 1 to 5 longitudinal dataset.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readECLS_K2011">readECLS_K2011</a></code>, <code><a href="#topic+readNAEP">readNAEP</a></code>, and <code><a href="#topic+getData">getData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

fld &lt;- "~/EdSurveyData/BTLS"
datPath &lt;- file.path(fld, "ASCII Data File", "BTLS2011_12.dat")
spsPath &lt;- file.path(fld, "Input Syntax for Stata and SPSS", "BTLS2011_12.sps")

#read in the data to an edsurvey.data.frame
btls &lt;- readBTLS(datPath, spsPath, verbose = TRUE)

dim(btls)

## End(Not run)
</code></pre>

<hr>
<h2 id='readCivEDICCS'>Connect to ICCS and CivED Data</h2><span id='topic+readCivEDICCS'></span>

<h3>Description</h3>

<p>Opens a connection to an ICCS (2009, 2016) or CivEd (1999) data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readCivEDICCS(
  path,
  countries,
  dataSet = c("student", "teacher"),
  gradeLvl = c("8", "9", "12"),
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readCivEDICCS_+3A_path">path</code></td>
<td>
<p>a character value of the full directory to the ICCS/CivED extracted SPSS (.sav) set of data</p>
</td></tr>
<tr><td><code id="readCivEDICCS_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include using
the three-digit International Organization for Standardization (ISO) country code.
A list of country codes can be found on Wikipedia at
<a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>
or other online sources. Consult the <em>ICCS/CivED User Guide</em> to help determine what countries
are included within a specific testing year of ICCS/CivED.
To select all countries, use a wildcard value of <strong><code>*</code></strong>.</p>
</td></tr>
<tr><td><code id="readCivEDICCS_+3A_dataset">dataSet</code></td>
<td>
<p>a character value of either <code>student</code> or <code>teacher</code> to indicate which set of data is returned.
The student-level and teacher-level datasets cannot both be returned at the same time, unlike other IEA datasets.
Note: The CivED 1999 study also included student-to-teacher data for Grade 8.  Specifying <code>dataSet="student"</code> and <code>gradeLvl=8</code>
will include both the <code>student</code> and <code>teacher</code> data in the resulting <code>edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="readCivEDICCS_+3A_gradelvl">gradeLvl</code></td>
<td>
<p>a character value of the grade level to return
</p>

<ul>
<li><p><strong>8</strong> = eighth grade (the default if not specified)
</p>
</li>
<li><p><strong>9</strong> = ninth grade
</p>
</li>
<li><p><strong>12</strong> = 12th grade (for CivED 1999 only)
</p>
</li></ul>
</td></tr>
<tr><td><code id="readCivEDICCS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the <code>readCivEDICCS</code> function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readCivEDICCS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the international database(s) using the <a href="https://www.iea.nl/data-tools/repository">IEA Study Data Repository</a>.
Data files require the SPSS data file (.sav) format using the default filenames.
</p>
<p>When using the <code>getData</code> function with a CivED or ICCS study <code>edsurvey.data.frame</code>,
the requested data variables are inspected, and it handles any necessary data merges automatically.
The <code>school</code> data always will be returned merged to the <code>student</code>
data, even if only <code>school</code> variables are requested.
If a 1999 CivED Grade 8 <code>edsurvey.data.frame</code> with <code>teacher</code> data variables is requested by the <code>getData</code> call,
it will cause <code>teacher</code> data to be merged.
Many <code>students</code> can be linked to many <code>teachers</code>, which varies widely between countries,
and not all countries contain <code>teacher</code> data.
</p>
<p>Calling the <code>dim</code> function for a CivED 1999 Grade 8 <code>edsurvey.data.frame</code> will result in the row count as if the <code>teacher</code> dataset was merged.
This row count will be considered the <code>full data N</code> of the <code>edsurvey.data.frame</code>, even if no <code>teacher</code> data were included in an analysis.
The column count returned by <code>dim</code> will be the count of unique column variables across all data levels.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or an <code>edsurvey.data.frame.list</code> if multiple countries specified
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+readTIMSS">readTIMSS</a></code>, <code><a href="#topic+getData">getData</a></code>, and <code><a href="#topic+downloadCivEDICCS">downloadCivEDICCS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
eng &lt;- readCivEDICCS("~/ICCS/2009/", countries = c("eng"),
                     gradeLvl = 8, dataSet = "student")
gg &lt;- getData(eng, c("famstruc", "totwgts", "civ"))
head(gg)
edsurveyTable(civ ~ famstruc, eng)

## End(Not run)
</code></pre>

<hr>
<h2 id='readECLS_B'>Connect to ECLS-B Data</h2><span id='topic+readECLS_B'></span>

<h3>Description</h3>

<p>Opens a connection to an ECLS-B data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readECLS_B(
  path = getwd(),
  filename,
  layoutFilename,
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readECLS_B_+3A_path">path</code></td>
<td>
<p>a character value to the full directory path(s) to the ECLS-B extracted fixed-with-format (.dat) set of datafiles.</p>
</td></tr>
<tr><td><code id="readECLS_B_+3A_filename">filename</code></td>
<td>
<p>a character value of the name of the fixed-width-file (.dat) data file in the specificed <code>path</code> to be read.</p>
</td></tr>
<tr><td><code id="readECLS_B_+3A_layoutfilename">layoutFilename</code></td>
<td>
<p>a character value of the filename of either the ASCII text (.txt) layout file of the <code>filename</code> within the specified <code>path</code>,
OR a character value of the  filename of the SPSS syntax (.sps) layout file of the <code>filename</code> within the specified <code>path</code></p>
</td></tr>
<tr><td><code id="readECLS_B_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the read function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readECLS_B_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose output while the <code>readECLS-K2011</code> function is running to indicate processing progress.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the ECLS-B longitudinal Database.
</p>


<h3>Value</h3>

<p>An <code>edsurvey.data.frame</code> for the ECLS-B longitudinal dataset.
</p>


<h3>Author(s)</h3>

<p>Trang Nguyen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+getData">getData</a></code>
</p>

<hr>
<h2 id='readECLS_K1998'>Connect to ECLS&ndash;K 1998 Data</h2><span id='topic+readECLS_K1998'></span>

<h3>Description</h3>

<p>Opens a connection to an ECLS&ndash;K 1998 data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readECLS_K1998(
  path = getwd(),
  filename = "eclsk_98_99_k8_child_v1_0.dat",
  layoutFilename = "Layout_k8_child.txt",
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readECLS_K1998_+3A_path">path</code></td>
<td>
<p>a character value to the full directory path(s) to the
ECLS&ndash;K-extracted fixed-width-format (.dat) set of data files</p>
</td></tr>
<tr><td><code id="readECLS_K1998_+3A_filename">filename</code></td>
<td>
<p>a character value of the name of the fixed-width (.dat)
data file in the specified <code>path</code> to be read</p>
</td></tr>
<tr><td><code id="readECLS_K1998_+3A_layoutfilename">layoutFilename</code></td>
<td>
<p>a character value of the filename of either the ASCII
(.txt) layout file of the <code>filename</code> within
the specified <code>path</code>
or a character value of the  filename of the SPSS syntax (.sps) layout file of the <code>filename</code> within the specified <code>path</code></p>
</td></tr>
<tr><td><code id="readECLS_K1998_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the read function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readECLS_K1998_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose output while the <code>readECLS-K1998</code> function is running to indicate processing progress.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the ECLS&ndash;K 1998 longitudinal dataset(s) to an <code>edsurvey.data.frame</code>.  The ECLS&ndash;K 1998&ndash;99 study consisted of
three distinct separate datasets that cannot be combined: (1) Child Grades K&ndash;8 Data, (2) School Base-Year Data, and (3) Teacher Base-Year Data.
The <code>filename</code> and <code>layoutFilename</code> arguments default to the corresponding Child K&ndash;8 default filenames.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for the ECLS&ndash;K 1998 longitudinal dataset
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readECLS_K2011">readECLS_K2011</a></code>, <code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+getData">getData</a></code>, <code><a href="#topic+downloadECLS_K">downloadECLS_K</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read-in student file with defaults
eclsk_df &lt;- readECLS_K1998(path="~/ECLS_K/1998") #using defaults
d &lt;- getData(eclsk_df, c("childid", "gender", "race"))
summary(d)

## End(Not run)

## Not run: 
# read-in with parameters specified
eclsk_df &lt;- readECLS_K1998(path = "~/ECLS_K/1998", 
                           filename = "eclsk_98_99_k8_child_v1_0.dat", 
                           layoutFilename = "Layout_k8_child.txt", 
                           verbose = TRUE, 
                           forceReread = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='readECLS_K2011'>Connect to ECLS&ndash;K 2011 Data</h2><span id='topic+readECLS_K2011'></span>

<h3>Description</h3>

<p>Opens a connection to an ECLS&ndash;K 2011 data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readECLS_K2011(
  path = getwd(),
  filename = "childK5p.dat",
  layoutFilename = "ECLSK2011_K5PUF.sps",
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readECLS_K2011_+3A_path">path</code></td>
<td>
<p>a character value to the full directory path(s) to the ECLS&ndash;K 2010&ndash;11 extracted fixed-with-format (.dat) set of data files</p>
</td></tr>
<tr><td><code id="readECLS_K2011_+3A_filename">filename</code></td>
<td>
<p>a character value of the name of the fixed-width (.dat) data file in the specified <code>path</code> to be read</p>
</td></tr>
<tr><td><code id="readECLS_K2011_+3A_layoutfilename">layoutFilename</code></td>
<td>
<p>a character value of the filename of either the ASCII (.txt) layout file of the <code>filename</code> within the specified <code>path</code>
or a character value of the  filename of the SPSS syntax (.sps) layout file of the <code>filename</code> within the specified <code>path</code></p>
</td></tr>
<tr><td><code id="readECLS_K2011_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the read function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readECLS_K2011_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose output while the <code>readECLS--K2011</code> function is running to indicate processing progress.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the ECLS&ndash;K 2010&ndash;11 longitudinal dataset.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for the ECLS&ndash;K 2010&ndash;11 longitudinal dataset
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readECLS_K1998">readECLS_K1998</a></code>, <code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+getData">getData</a></code>, and <code><a href="#topic+downloadECLS_K">downloadECLS_K</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read-in student file with defaults
eclsk_df &lt;- readECLS_K2011(path="~/ECLS_K/2011") #using defaults
d &lt;- getData(eclsk_df, c("childid", "c1hgt1", "c1wgt1"))
summary(d)

## End(Not run)

## Not run: 
# read-in with parameters specified
eclsk_df &lt;- readECLS_K2011(path = "~/ECLS_K/2011",
                           filename = "childK5p.dat",
                           layoutFilename = "ECLSK2011_K5PUF.sps",
                           forceReread = FALSE,
                           verbose = TRUE) 

## End(Not run)
</code></pre>

<hr>
<h2 id='readELS'>Connect to Education Longitudinal Study (ELS:2002) Data</h2><span id='topic+readELS'></span>

<h3>Description</h3>

<p>Opens a connection to an ELS data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readELS(
  path = getwd(),
  filename = "els_02_12_byf3pststu_v1_0.sav",
  wgtFilename = ifelse(filename == "els_02_12_byf3pststu_v1_0.sav",
    "els_02_12_byf3stubrr_v1_0.sav", NA),
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readELS_+3A_path">path</code></td>
<td>
<p>a character value to the directory path of the extracted set of
data files and layout files.</p>
</td></tr>
<tr><td><code id="readELS_+3A_filename">filename</code></td>
<td>
<p>a character value of the name of the SPSS (.sav) data file
in the specified <code>path</code> to be read.</p>
</td></tr>
<tr><td><code id="readELS_+3A_wgtfilename">wgtFilename</code></td>
<td>
<p>a character value of the name of the associated balanced
repeated replication (BRR) weight SPSS (.sav) data file
in the specified <code>path</code> to be read. This argument
is applicable only for the student-level data, which
contains a separate data file containing the weight
replicate information. If using default filenames
(recommended), then you shouldn't need to specify
this parameter because it will inspect the <code>filename</code>
argument. For data files with no BRR weight file
associated, specify a value of <code>NULL</code> or <code>NA</code>.</p>
</td></tr>
<tr><td><code id="readELS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the read
function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readELS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose output
while the <code>readELS</code> function is running to indicate
processing progress.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the ELS longitudinal dataset(s)
to an <code>edsurvey.data.frame</code>.  The ELS 2002 study consisted of
four distinct separate datasets that cannot be combined:
</p>

<ul>
<li><p>Student: bas -year through follow-up three (default)
</p>
</li>
<li><p>School: base year through follow-up one
</p>
</li>
<li><p>Institution: follow-up two
</p>
</li>
<li><p>Institution: follow-up three
</p>
</li></ul>



<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for the ELS longitudinal dataset
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readECLS_K2011">readECLS_K2011</a></code>, <code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+getData">getData</a></code>, and <code><a href="#topic+downloadECLS_K">downloadECLS_K</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read-in student file including weight file as default
els_df &lt;- readELS("~/ELS/2002") #student level with weights)
d &lt;- getData(els_df, c("stu_id", "bysex", "bystlang"))
summary(d)



# read-in with parameters specified (student level with weights)
els_wgt_df &lt;- readELS(path = "~/ELS/2002", 
                      filename = "els_02_12_byf3pststu_v1_0.sav", 
                      wgtFilename = "els_02_12_byf3stubrr_v1_0.sav",
                      verbose = TRUE, 
                      forceReread = FALSE)

# read-in with parameters specified (school level, no separate weight replicate file)
els_sch_df &lt;- readELS(path = "~/ELS/2002", 
                      filename = "els_02_12_byf1sch_v1_0.sav", 
                      wgtFilename = NA,
                      verbose = TRUE, 
                      forceReread = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='readHSB_Senior'>Connect to HS&amp;B Study Senior Data</h2><span id='topic+readHSB_Senior'></span>

<h3>Description</h3>

<p>Opens a connection to a High School &amp; Beyond 1980&ndash;1986 Senior cohort data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readHSB_Senior(
  HSR8086_PRI_FilePath,
  HSR8086_SASSyntax_Path,
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readHSB_Senior_+3A_hsr8086_pri_filepath">HSR8086_PRI_FilePath</code></td>
<td>
<p>a character value to the main study-derived
analytical data file (HSR8086_REV.PRI).
Located within the <code>REVISED_ASCII</code> Folder.</p>
</td></tr>
<tr><td><code id="readHSB_Senior_+3A_hsr8086_sassyntax_path">HSR8086_SASSyntax_Path</code></td>
<td>
<p>a character value to the SAS syntax file for
parsing the <code>HSR8086_REV.PRI</code> data file.
Located within the <code>SAS_EXTRACT_LOGIC</code> Folder.</p>
</td></tr>
<tr><td><code id="readHSB_Senior_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the read
function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readHSB_Senior_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose output
while the <code>readHSB_Senior</code> function is running to
indicate processing progress. The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the specified <code>HSR8086_SASSyntax_Path</code> file to parse
the <code>HSR8086_PRI_FilePath</code> file.
A cached data file and metadata file will be saved in the same
directory and filename as the <code>HSR8086_PRI_FilePath</code> file,
having new file extensions of .txt and .meta, respectively.
</p>
<p>Please note the original source <code>repcode</code> variable has been split
into two variables named <code>repcode_str</code> for the stratum value
and <code>repcode_psu</code> for the primary sampling unit (PSU) value in the resulting
cache data.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for the HS&amp;B Senior 1980&ndash;1986 longitudinal dataset
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readECLS_K2011">readECLS_K2011</a></code>, <code><a href="#topic+readNAEP">readNAEP</a></code>, and <code><a href="#topic+getData">getData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
wrkFld &lt;- "~/HSB/SENIOR"

dataPath &lt;- file.path(wrkFld, "REVISED_ASCII", "HSR8086_REV.PRI")
sasPath &lt;- file.path(wrkFld, "SAS_EXTRACT_LOGIC", "HSBsr_READ_HSR8086.SAS")

# with verbose output as default
hsbSR &lt;- readHSB_Senior(dataPath, sasPath)

# silent output
hsbSR &lt;- readHSB_Senior(dataPath, sasPath, verbose = FALSE)

# force cache update
hsbSR &lt;- readHSB_Senior(dataPath, sasPath, forceReread = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='readHSB_Sophomore'>Connect to HS&amp;B Study Sophomore Data</h2><span id='topic+readHSB_Sophomore'></span>

<h3>Description</h3>

<p>Opens a connection to a High School &amp; Beyond 1980&ndash;1992 Sophomore cohort data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readHSB_Sophomore(
  HSO8092_PRI_FilePath,
  HSO8092_SASSyntax_Path,
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readHSB_Sophomore_+3A_hso8092_pri_filepath">HSO8092_PRI_FilePath</code></td>
<td>
<p>a character value to the main study-derived
analytical data file (HSO8092_REV.PRI).
Located within the <code>REVISED_ASCII</code> folder.</p>
</td></tr>
<tr><td><code id="readHSB_Sophomore_+3A_hso8092_sassyntax_path">HSO8092_SASSyntax_Path</code></td>
<td>
<p>a character value to the SAS syntax file for
parsing the <code>HSO8092_REV.PRI</code> data file.
Located within the <code>SAS_EXTRACT_LOGIC</code> folder.</p>
</td></tr>
<tr><td><code id="readHSB_Sophomore_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the read
function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readHSB_Sophomore_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose
output while the <code>readHSB_Sophomore</code> function is running
to indicate processing progress.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the specified <code>HSO8092_SASSyntax_Path</code> file to parse
the <code>HSO8092_PRI_FilePath</code> file.
A cached data file and metadata file will be saved in the same
directory and filename as the <code>HSO8092_PRI_FilePath</code> file,
having new file extensions of .txt and .meta, respectively.
</p>
<p>Please note the original source <code>repcode</code> variable has been split
into two variables named <code>repcode_str</code> for the stratum value
and <code>repcode_psu</code> for the primary sampling unit (PSU) value in the resulting cache data.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for the HS&amp;B Sophomore 1980&ndash;1992 longitudinal dataset
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readECLS_K2011">readECLS_K2011</a></code>, <code><a href="#topic+readNAEP">readNAEP</a></code>, and <code><a href="#topic+getData">getData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
wrkFld &lt;- "~/HSB/SOPHOMORE"

dataPath &lt;- file.path(wrkFld, "REVISED_ASCII", "HSO8092_REV.PRI")
sasPath &lt;- file.path(wrkFld, "SAS_EXTRACT_LOGIC", "HSBso_READ_HSO8092.SAS")

# with verbose output as default
hsbSO &lt;- readHSB_Sophomore(dataPath, sasPath)

# silent output
hsbSO &lt;- readHSB_Sophomore(dataPath, sasPath, verbose = FALSE)

# force cache update
hsbSO &lt;- readHSB_Sophomore(dataPath, sasPath, forceReread = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='readHSLS'>Connect to High School Longitudinal Study 2009 (HSLS:2009) Data</h2><span id='topic+readHSLS'></span>

<h3>Description</h3>

<p>Opens a connection to an HSLS data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readHSLS(
  path = getwd(),
  filename = "hsls_16_student_v1_0.sav",
  wgtFilename = NA,
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readHSLS_+3A_path">path</code></td>
<td>
<p>a character value to the full directory path(s) to the HSLS
extracted SPSS (.sav) set of data files</p>
</td></tr>
<tr><td><code id="readHSLS_+3A_filename">filename</code></td>
<td>
<p>a character value of the name of the SPSS (.sav) datafile to be read</p>
</td></tr>
<tr><td><code id="readHSLS_+3A_wgtfilename">wgtFilename</code></td>
<td>
<p>a character value of the name of the associated BRR
weight SPSS (.sav) data file in the specificed <code>path</code>
to be read.
This argument is only applicable for the restricted-use
student level data, which contains a separate data-file
containing the weight replicate information.
For data files with no balanced
repeated replication (BRR) weight file associated,
specify a value of <code>NULL</code> or <code>NA</code>.</p>
</td></tr>
<tr><td><code id="readHSLS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logic value to force a rereading of all processed data.
The default value of <code>FALSE</code> speeds up the
<code>readHSLS</code> function by using existing read-in data
already processed.</p>
</td></tr>
<tr><td><code id="readHSLS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value set to <code>TRUE</code> for verbose output that
indicates progress</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the HSLS longitudinal dataset.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for the HSLS longitudinal dataset
</p>


<h3>Note</h3>

<p>The SPSS (.sav) format is preferred over the fixed-width-format (.dat)
ASCII file format at this time relating to value label issues identified
with the ASCII layout specifications.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readECLS_K2011">readECLS_K2011</a></code>, <code><a href="#topic+readNAEP">readNAEP</a></code>, and <code><a href="#topic+getData">getData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# use function default values at working directory
hsls &lt;- readHSLS("~/HSLS/2009")

# specify parameters with verbose output
hsls &lt;- readHSLS(path="~/HSLS/2009", 
                 filename = "hsls_16_student_v1_0.sav", 
                 forceReread = FALSE, 
                 verbose = TRUE)

# specify parameters silent output
hsls &lt;- readHSLS(path="~/HSLS/2009", 
                 filename = "hsls_16_student_v1_0.sav", 
                 forceReread = FALSE, 
                 verbose = FALSE)

#for restricted-use student data, replicate weights stored in separate file
hslsRUD &lt;- readHSLS(path="~/HSLS/2009", 
                    filename = "hsls_16_student_v1_0.sav", 
                    wgtFilename = "hsls_16_student_BRR_v1_0.sav",
                    forceReread = FALSE, 
                    verbose = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='readHSTS'>Connect to HSTS Data</h2><span id='topic+readHSTS'></span>

<h3>Description</h3>

<p>Opens a connection to a High School Transcript Study (HSTS) data files for years 2019.
Returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readHSTS(
  dataFilePath = getwd(),
  spssPrgPath = dataFilePath,
  year = c("2019"),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readHSTS_+3A_datafilepath">dataFilePath</code></td>
<td>
<p>a character value to the root directory path of extracted set of ASCII data files (.txt or .dat file extension).
<code>readHSTS</code> will search within sub-directories of this parameter for expected data files based on the specified <code>year</code> parameter.</p>
</td></tr>
<tr><td><code id="readHSTS_+3A_spssprgpath">spssPrgPath</code></td>
<td>
<p>a character value to the directory path of where the extracted set of .sps program files are located.
The data file and associated SPSS program filenames *must match* (having different file extensions) to determine which files are associated together.
<code>readHSTS</code> will search within sub-directories of this parameter for expected SPSS programe files based on the specified <code>year</code> parameter.</p>
</td></tr>
<tr><td><code id="readHSTS_+3A_year">year</code></td>
<td>
<p>a character value to indicate the year of the dataset.  Only one year is supported for a single <code>readHSTS</code> data call.
The year is required to help determine specific study information.  Only 2019 study is currently supported.</p>
</td></tr>
<tr><td><code id="readHSTS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose output while the <code>readHSTS</code> function is running to indicate processing progress.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The HSTS data has a complex structure and unique characteristics all handled internally within <code>EdSurvey</code>. 
The structure allows for automatic dynamic linking across all various data 'levels' based the requested variables. The <code>student</code> data level is the primary analysis unit. 
Dynamic linking for variables that include both <code>tests</code> and <code>transcript</code> level details will result in an error, as they cannot be simultaneously returned in a single call. 
Situations may arise where the analyst must derive variables for analysis. See the documentation for <code>merge</code> and <code>$&lt;-</code> functions for more detail. All merge operations are done at the <code>student</code> level (the main analysis unit).
</p>
<p>File Layout for HSTS 2019:
</p>

<ul>
<li><p> School (school.dat) - School level variables.
</p>

<ul>
<li><p> School Catalog (catalog.dat) - Catalog variables joined to School data. Variables renamed to begin with <code>SchCat_</code> to distinguish from Transcript Catalog.  Cannot be merged with any <code>Student</code> data.
</p>
</li></ul>

</li>
<li><p> Student (student.dat) - Student level variables.  Primary analysis unit, all merged/cached data must be at this level.
</p>

<ul>
<li><p> NAEP Math (naepmath.dat) - Subset of students containing NAEP Math variables.  Variables begin with <code>math_</code> to ensure they are unique from the NAEP Science variables.
</p>
</li>
<li><p> NAEP Science (naepsci.dat) - Subset of students containing NAEP Science variables.  Variables begin with <code>sci_</code> to ensure they are unique from the NAEP Math variables.
</p>
</li>
<li><p> Tests (tests.dat) - Students may have many test records.  Contains ACT/SAT testing score details for students.  Cannot be merged together with any Transcript or Transcript Catalog data.
</p>
</li>
<li><p> Transcripts (trnscrpt.dat) - Students may have many transcript records.  Contains transcript level details. Cannot be merged together with Test data.
</p>

<ul>
<li><p> Transcript Catalog (catalog.dat) - Each transcript record is associated to a catalog record for giving context to the transcript record.  2019 uses <a href="https://nces.ed.gov/scedfinder">SCED codes</a> for categorizing courses.
</p>
</li></ul>

</li></ul>

</li></ul>



<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for the HSTS dataset.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+showCodebook">showCodebook</a></code>, <code><a href="#topic+searchSDF">searchSDF</a></code>, <code><a href="#topic+edsurvey.data.frame">edsurvey.data.frame</a></code>, <code><a href="#topic+merge.edsurvey.data.frame">merge.edsurvey.data.frame</a></code>, and <code><a href="#topic+getData">getData</a></code>
</p>

<hr>
<h2 id='readICILS'>Connect to ICILS Data</h2><span id='topic+readICILS'></span>

<h3>Description</h3>

<p>Opens a connection to an ICILS data file residing
on the disk and returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readICILS(
  path,
  countries,
  dataSet = c("student", "teacher"),
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readICILS_+3A_path">path</code></td>
<td>
<p>a character value to the full directory path to the ICILS
extracted SPSS (.sav) set of data</p>
</td></tr>
<tr><td><code id="readICILS_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include using
the three-digit ISO country code.
A list of country codes can be found on Wikipedia at
<a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>
or other online sources. Consult the <em>ICILS User Guide</em>
to help determine what countries
are included within a specific testing year of ICILS.
To select all countries, use a wildcard value of <strong><code>*</code></strong>.</p>
</td></tr>
<tr><td><code id="readICILS_+3A_dataset">dataSet</code></td>
<td>
<p>a character value of either <code>student</code> (the default if
not specified) or <code>teacher</code> to
indicate which set of data is returned.
The student-level and teacher-level datasets cannot both be
returned at the same time, unlike other IEA datasets.</p>
</td></tr>
<tr><td><code id="readICILS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the <code>readICILS</code> function
by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readICILS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the ICILS international
dataset(s) using the
<a href="https://www.iea.nl/data-tools/repository">IEA Study Data Repository</a>.
Data files require the SPSS data file (.sav) format using the default filenames.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or an
<code>edsurvey.data.frame.list</code> if multiple countries specified
</p>


<h3>Author(s)</h3>

<p>Tom Fink and Jeppe Bundsgaard (updated for 2018)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+readTIMSS">readTIMSS</a></code>, and <code><a href="#topic+getData">getData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
pol &lt;- readICILS("~/ICILS/2013", countries = "pol", dataSet = "student")
gg &lt;- getData(pol, c("idstud", "cil", "is1g18b"))
head(gg)
edsurveyTable(cil ~ is1g18b, pol)

## End(Not run)
</code></pre>

<hr>
<h2 id='readNAEP'>Connect to NAEP Data</h2><span id='topic+readNAEP'></span>

<h3>Description</h3>

<p>Opens a connection to a Main NAEP, or Long-Term Trend NAEP data file residing
on the disk. Returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readNAEP(
  path,
  defaultWeight = "origwt",
  defaultPvs = "composite",
  omittedLevels = c("Multiple", NA, "Omitted"),
  frPath = NULL,
  xmlPath = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readNAEP_+3A_path">path</code></td>
<td>
<p>a character value indicating the full filepath location and name
of the (.dat) data file</p>
</td></tr>
<tr><td><code id="readNAEP_+3A_defaultweight">defaultWeight</code></td>
<td>
<p>a character value that indicates the default weight
specified in the resulting <code>edsurvey.data.frame</code>.
Default value is <code>origwt</code> if not specified.</p>
</td></tr>
<tr><td><code id="readNAEP_+3A_defaultpvs">defaultPvs</code></td>
<td>
<p>a character value that indicates the default plausible value
specified in the resulting <code>edsurvey.data.frame</code>.
Default value is <code>composite</code> if not specified.</p>
</td></tr>
<tr><td><code id="readNAEP_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>a character vector indicating which factor levels/labels
should be excluded. When set to the default value of
<code>c('Multiple',NA,'Omitted')</code>, adds the vector to
the <code>edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="readNAEP_+3A_frpath">frPath</code></td>
<td>
<p>a character value indicating the file location of the <code>.fr2</code>
parameter layout file included with the data companion to
parse the specified <code>path</code> data file.
The default value of <code>NULL</code> will attempt to search the parent directory for the corresponding <code>.fr2</code> file for the specified <code>path</code> data file.</p>
</td></tr>
<tr><td><code id="readNAEP_+3A_xmlpath">xmlPath</code></td>
<td>
<p>a character value indicating the file path of the <code>.xml</code> parameter layout file included as part of the NAEPEX companion. This file provides necessary
information required to read and parse the (.dat) data file. The default value of <code>NULL</code> will attempt to search
the parent directory for the corresponding <code>.xml</code> file for the specified <code>path</code> data file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>frPath</code> file layout information will take precedence over the <code>xmlPath</code> file when the <code>xmlPath</code> is not explicitly set, or when the <code>xmlPath</code> file cannot be located.
</p>
<p>The <code>readNAEP</code> function includes both scaled scores and theta scores, with the latter having names ending in <code>\_theta</code>.
</p>
<p>When a NAEP administration includes a linking error variable those variables are included and end in <code>_linking</code>.
When present, simply use the <code>_linking</code> version of a variable to get a standard error estimate that includes linking error.
</p>
<p>This function supports both the Main NAEP data files, and Long-Term Trend NAEP data files.
A table outlining the differences can be found on the <a href="https://nces.ed.gov/nationsreportcard/about/ltt_main_diff.aspx">NAEP Nations Report Card website</a>.
</p>


<h3>Value</h3>

<p>An <code>edsurvey.data.frame</code> for a NAEP data file.
</p>


<h3>Author(s)</h3>

<p>Tom Fink and Ahmad Emad
</p>


<h3>See Also</h3>

<p><code><a href="#topic+edsurvey.data.frame">edsurvey.data.frame</a></code> <code><a href="#topic+getData">getData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))
sdf

# To read in an NCES file first set the directory to the /Data subfolder,
# then read in the appropriate .dat file:
setwd("location/of/Data")
sdf &lt;- readNAEP(path="M36NT2PM.dat")

# Or read in the .dat file directly through the folder pathway:
sdf &lt;- readNAEP(path="location/of/Data/M36NT2PM.dat")

## End(Not run)
</code></pre>

<hr>
<h2 id='readNHES'>Connect to NHES Survey Data</h2><span id='topic+readNHES'></span>

<h3>Description</h3>

<p>Opens a connection to a National Household Education Survey (NHES) data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readNHES(savFiles, surveyCode = "auto", forceReread = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readNHES_+3A_savfiles">savFiles</code></td>
<td>
<p>a character vector to the full file path(s) to the NHES
extracted SPSS (*.sav) data files.</p>
</td></tr>
<tr><td><code id="readNHES_+3A_surveycode">surveyCode</code></td>
<td>
<p>a character vector of the <code>surveyCode</code> to identify the year and survey type of the passed <code>savFiles</code> data file(s).
The default value is set to <code>auto</code> which attempts to automatically identify the survey/year based on the file attributes.
Occasionally, the <code>auto</code> lookup may be unable to determine the <code>surveyCode</code> and must be explicitly set by the user.
The lengths of the <code>savFiles</code> vector and <code>surveyCode</code> vector must match, unless <code>surveyCode</code> is set to <code>auto</code>.
To view the <code>surveyCodes</code> available, use the <code>getNHES_SurveyInfo</code>, or <code>viewNHES_SurveyCodes</code> function to view the codes.</p>
</td></tr>
<tr><td><code id="readNHES_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force a rereading of all processed data.
The default value of <code>FALSE</code> speeds up the
<code>readNHES</code> function by using existing read-in data if already processed.</p>
</td></tr>
<tr><td><code id="readNHES_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that defaults to <code>TRUE</code> for verbose console output that indicates progress information.
If <code>verbose = FALSE</code>, no information will be printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped public-use files downloaded from the NCES Online Codebook (<a href="https://nces.ed.gov/OnlineCodebook">https://nces.ed.gov/OnlineCodebook</a>) in SPSS (*.sav) format.
Other sources of NHES data, such as restricted-use files or other websites, may require additional conversion steps to generate the required SPSS data format
and/or explicitly setting the <code>surveyCode</code> parameter.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> if only one NHES file is specified for the <code>savFiles</code> argument,
or an <code>edsurvey.data.frame.list</code> if multiple files are passed to the <code>savFiles</code> argument
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+downloadNHES">downloadNHES</a></code>, <code><a href="#topic+getNHES_SurveyInfo">getNHES_SurveyInfo</a></code>, and <code><a href="#topic+viewNHES_SurveyCodes">viewNHES_SurveyCodes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
rootPath &lt;- "~/"

#get instructions for obtaining NHES data 
downloadNHES()

#get SPSS *.sav file paths of all NHES files for 2012 and 2016
filesToImport &lt;- list.files(path = file.path(rootPath, "NHES", c(2012, 2016)), 
                            pattern="\\.sav$", 
                            full.names = TRUE, 
                            recursive = TRUE)

#import all files to edsurvey.data.frame.list object
esdfList &lt;- readNHES(savFiles = filesToImport, surveyCode = "auto", 
                     forceReread = FALSE, verbose = TRUE)

viewNHES_SurveyCodes() #view NHES survey codes in console

#get the full file path to the 2016 ATES NHES survey
path_ates2016 &lt;- list.files(path = file.path(rootPath, "NHES", "2016"), 
                            pattern=".*ates.*[.]sav$", full.names = TRUE)

#explicitly setting the surveyCode parameter (if required)
esdf &lt;- readNHES(savFiles = path_ates2016, surveyCode = "ATES_2016", 
                 forceReread = FALSE, verbose = TRUE)

#search for variables in the edsurvey.data.frame
searchSDF("sex", esdf)

## End(Not run)
</code></pre>

<hr>
<h2 id='readPIAAC'>Connect to PIAAC Data</h2><span id='topic+readPIAAC'></span>

<h3>Description</h3>

<p>Opens a connection to a PIAAC data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readPIAAC(
  path,
  countries,
  forceReread = FALSE,
  verbose = TRUE,
  usaOption = "12_14"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readPIAAC_+3A_path">path</code></td>
<td>
<p>a character value to the full directory path to the PIAAC .csv
files and Microsoft Excel codebook</p>
</td></tr>
<tr><td><code id="readPIAAC_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include
using the three-digit ISO country code. A list of country
codes can be found in the PIAAC codebook or
<a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>.
If files are downloaded using <code><a href="#topic+downloadPIAAC">downloadPIAAC</a></code>,
a country dictionary text file can be
found in the filepath. You can use <code>*</code> to indicate
all countries available. For the <code>usa</code>, the year must
be specified using: <code>usa12_14</code> or  <code>usa17</code>.</p>
</td></tr>
<tr><td><code id="readPIAAC_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
Defaults to <code>FALSE</code>.
Setting <code>forceReread</code> to be <code>TRUE</code> will cause
PIAAC data to be reread and increase the processing time.</p>
</td></tr>
<tr><td><code id="readPIAAC_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose
output while the function is running to indicate the progress.
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="readPIAAC_+3A_usaoption">usaOption</code></td>
<td>
<p>a character value of <code>12_14</code> or <code>17</code> that specifies
what year of the USA survey should be used when loading all countries by
using <code>*</code> in the <code>countries</code> argument. This will only make a difference
when loading all countries. Defaults to <code>12_14</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped .csv files downloaded from the PIAAC dataset using
the OECD repository (<a href="https://www.oecd.org/skills/piaac/">https://www.oecd.org/skills/piaac/</a>). Users can use
<code><a href="#topic+downloadPIAAC">downloadPIAAC</a></code> to download all required files automatically.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or
an <code>edsurvey.data.frame.list</code> if multiple countries specified
</p>


<h3>Author(s)</h3>

<p>Trang Nguyen
</p>


<h3>References</h3>

<p>Organisation for Economic Co-operation and Development. (2016). <em>Technical report of the survey of adult skills (PIAAC)</em> (2nd ed.). Paris, France: Author. Retrieved from <em><a href="https://www.oecd.org/skills/piaac/PIAAC_Technical_Report_2nd_Edition_Full_Report.pdf">https://www.oecd.org/skills/piaac/PIAAC_Technical_Report_2nd_Edition_Full_Report.pdf</a></em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getData">getData</a></code> and <code><a href="#topic+downloadPIAAC">downloadPIAAC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# the following call returns an edsurvey.data.frame to PIAAC for Canada
can &lt;- readPIAAC("~/PIAAC/Cycle 1/", countries = "can")

# extract a data.frame with a few variables
gg &lt;- getData(can, c("c_d05","ageg10lfs"))  
head(gg)

# conduct an analysis on the edsurvey.data.frame
edsurveyTable(~ c_d05 + ageg10lfs, data = can)

# the following call returns an edsurvey.data.frame to PIAAC for Canada
can &lt;- readPIAAC("~/PIAAC/Cycle 1/", countries = "can", us)

# There are two years of usa data for round 1: 2012-2014 and 2017. 
# The user must specify which usa year they want with the optional "usaOption" argument. 
# Otherwise, the read function will return usa 2012-2014. See "?readPIACC()" for more info. 

# read in usa 2012-2014 
usa12 &lt;- readPIAAC("~/PIAAC/Cycle 1",
                   countries = "usa", usaOption="12_14")
# read in usa 2017 
usa17 &lt;- readPIAAC("~/PIAAC/Cycle 1",
                   countries = "usa", usaOption="17")
# if reading in all piaac data, the user can still specify usa option. 
# Otherwise, by default 2012-1014 will be used when reading in all piaac data. 
all_piaac &lt;- readPIAAC("~/PIAAC/Cycle 1",
                       countries = "*", usaOption="17")

## End(Not run)
</code></pre>

<hr>
<h2 id='readPIRLS'>Connect to PIRLS Data</h2><span id='topic+readPIRLS'></span>

<h3>Description</h3>

<p>Opens a connection to a PIRLS data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readPIRLS(path, countries, forceReread = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readPIRLS_+3A_path">path</code></td>
<td>
<p>a character value to the full directory path to the PIRLS extracted
SPSS (.sav) set of data</p>
</td></tr>
<tr><td><code id="readPIRLS_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include using
the three-digit ISO country code.
A list of country codes can be found on Wikipedia at
<a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>
or other online sources. Consult the <em>PIRLS User Guide</em>
to help determine what countries
are included within a specific testing year of PIRLS.
To select all countries, use a wildcard value of <strong><code>*</code></strong>.</p>
</td></tr>
<tr><td><code id="readPIRLS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the <code>readPIRLS</code> function by
using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readPIRLS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the PIRLS international
database(s) using the <a href="https://www.iea.nl/data-tools/repository">IEA Study Data Repository</a>.
Data files require the SPSS data file (.sav) format using the default
filenames.
</p>
<p>A PIRLS <code>edsurvey.data.frame</code> includes three distinct data levels:
</p>

<ul>
<li><p> student
</p>
</li>
<li><p> school
</p>
</li>
<li><p> teacher
</p>
</li></ul>

<p>When the <code>getData</code> function is called using a PIRLS <code>edsurvey.data.frame</code>,
the requested data variables are inspected, and it handles any necessary data merges automatically.
The <code>school</code> data always will be returned merged to the <code>student</code>
data, even if only <code>school</code> variables are requested.
If <code>teacher</code> variables are requested by the <code>getData</code> call, it
will cause <code>teacher</code> data to be merged.
Many <code>students</code> can be linked to many <code>teachers</code>, which varies widely between countries.
</p>
<p>Please note that calling the <code>dim</code> function for a PIRLS
<code>edsurvey.data.frame</code> will result in
the row count as if the <code>teacher</code> dataset was merged.
This row count will be considered the <code>full data N</code> of the
<code>edsurvey.data.frame</code>, even if no <code>teacher</code> data were
included in an analysis.
The column count returned by <code>dim</code> will be the count of unique
column variables across all three data levels.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or an
<code>edsurvey.data.frame.list</code> if multiple countries specified
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+readTIMSS">readTIMSS</a></code>, <code><a href="#topic+getData">getData</a></code>, and <code><a href="#topic+downloadPIRLS">downloadPIRLS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
nor &lt;- readPIRLS("~/PIRLS/2011", countries = c("nor"))
gg &lt;- getData(nor, c("itsex", "totwgt", "rrea"))
head(gg)
edsurveyTable(rrea ~ itsex, nor)

## End(Not run)
</code></pre>

<hr>
<h2 id='readPISA'>Connect to PISA Data</h2><span id='topic+readPISA'></span>

<h3>Description</h3>

<p>Opens a connection to a PISA data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readPISA(
  path,
  database = c("INT", "CBA", "FIN"),
  countries,
  cognitive = c("score", "response", "none"),
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readPISA_+3A_path">path</code></td>
<td>
<p>a character vector to the full directory path(s) to the
PISA-extracted fixed-width files and SPSS control files (.txt).</p>
</td></tr>
<tr><td><code id="readPISA_+3A_database">database</code></td>
<td>
<p>a character to indicate a selected database. Must be one of
<code>INT</code> (general database that most people use),
<code>CBA</code> (computer-based database in PISA 2012 only),
or <code>FIN</code> (financial literacy database in PISA 2012 and 2018).
Defaults to <code>INT</code>.</p>
</td></tr>
<tr><td><code id="readPISA_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include using the
three-digit ISO country code. A list of country codes can be found
in the PISA codebook or <a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>.
If files are downloaded using <code><a href="#topic+downloadPISA">downloadPISA</a></code>,
a country dictionary text file can be
found in the filepath.</p>
</td></tr>
<tr><td><code id="readPISA_+3A_cognitive">cognitive</code></td>
<td>
<p>one of <code>none</code>, <code>score</code>, or <code>response</code>. Default
is <code>score</code>. The PISA database often has three student
files: student questionnaire, cognitive item
response, and scored cognitive item response. The first
file is used as the main student file with student
background information. Users can choose whether to
merge <code>score</code> or
<code>response</code> data into the main file or not (if <code>none</code>).</p>
</td></tr>
<tr><td><code id="readPISA_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
Defaults to <code>FALSE</code>. Setting <code>forceReread</code>
to be <code>TRUE</code> will cause PISA data to be reread and
increase processing time.</p>
</td></tr>
<tr><td><code id="readPISA_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose
output while the function is running to indicate progress.
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the PISA database using the
OECD Repository (<a href="https://www.oecd.org/pisa/">https://www.oecd.org/pisa/</a>). Users can use
<code><a href="#topic+downloadPISA">downloadPISA</a></code> to download all required files.
Student questionnaire files (with weights and plausible values) are used as
main files, which are then
merged with cognitive, school, and parent files (if available).
</p>
<p>The average first-time processing time for 1 year and one database for all
countries is 10&ndash;15 minutes. If <code>forceReread</code> is set
to be <code>FALSE</code>, the next time this function is called will take only
5&ndash;10 seconds.
</p>
<p>For the PISA 2000 study, please note that the study weights are subject
specific. Each weight has different adjustment factors for reading, mathematics, and science
based on it's original subject source file.  For example, the <code>w_fstuwt_read</code> weight is associated with the reading
subject data file.  Special care must be used to select the correct weight based on your specific analysis.  See the OECD
documentation for further details.  Use the <code>showWeights</code> function to see all three student level subject weights:
</p>

<ul>
<li> <p><strong>w_fstuwt_read</strong> = Reading (default)
</p>
</li>
<li> <p><strong>w_fstuwt_scie</strong> = Science
</p>
</li>
<li> <p><strong>w_fstuwt_math</strong> = Mathematics
</p>
</li></ul>



<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or
an <code>edsurvey.data.frame.list</code> if multiple countries are specified
</p>


<h3>Author(s)</h3>

<p>Tom Fink, Trang Nguyen, and Paul Bailey
</p>


<h3>References</h3>

<p>Organisation for Economic Co-operation and Development. (2017). <em>PISA 2015 technical report</em>. Paris, France: OECD Publishing. Retrieved from <em><a href="https://www.oecd.org/pisa/data/2015-technical-report/">https://www.oecd.org/pisa/data/2015-technical-report/</a></em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getData">getData</a></code> and <code><a href="#topic+downloadPISA">downloadPISA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# the following call returns an edsurvey.data.frame to 
# PISA 2012 International Database for Singapore
sgp2012 &lt;- readPISA(path = "~/PISA/2012", database = "INT", countries = "sgp")

# extract a data.frame with a few variables
gg &lt;- getData(sgp2012, c("cnt","read","w_fstuwt"))  
head(gg)

# conduct an analysis on the edsurvey.data.frame
edsurveyTable(read ~ st04q01 + st20q01, data = sgp2012)

## End(Not run)
</code></pre>

<hr>
<h2 id='readPISA_YAFS'>PISA YAFS (Young Adult Follow-up Study)</h2><span id='topic+readPISA_YAFS'></span>

<h3>Description</h3>

<p>Opens a connection to the Programme for International Student Assessment (PISA) YAFS 2016 data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readPISA_YAFS(
  datPath = file.path(getwd(), "PISA_YAFS2016_Data.dat"),
  spsPath = file.path(getwd(), "PISA_YAFS2016_SPSS.sps"),
  esdf_PISA2012_USA = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readPISA_YAFS_+3A_datpath">datPath</code></td>
<td>
<p>a character value of the file location where the data file (.dat) file is saved.</p>
</td></tr>
<tr><td><code id="readPISA_YAFS_+3A_spspath">spsPath</code></td>
<td>
<p>a character value of the file location where the SPSS (.sps) script file is saved to parse the <code>datPath</code> data file.</p>
</td></tr>
<tr><td><code id="readPISA_YAFS_+3A_esdf_pisa2012_usa">esdf_PISA2012_USA</code></td>
<td>
<p>(optional) an <code>edsurvey.data.frame</code> of the USA PISA 2012 data if planning to analyze the PISA YAFS data alongside the USA PISA 2012 dataset.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files for the PISA YAFS.  The PISA YAFS dataset is a follow-up study of a subset of the students who
participated in the PISA 2012 USA study.  It can be analyzed on its own as a singular dataset or optionally merged with the PISA 2012 USA data,
in which case there will be two sets of weights in the merged dataset (the default PISA YAFS weights and the PISA 2012 USA weights).
</p>


<h3>Value</h3>

<p>An <code>edsurvey.data.frame</code> for the PISA YAFS dataset if the <code>esdf_PISA2012_USA</code> parameter is <code>NULL</code>.  If the PISA 2012 USA <code>edsurvey.data.frame</code> is specified for the <code>esdf_PISA2012_USA</code>
parameter, then the resulting dataset will return an <code>edsurvey.data.frame</code> allowing analysis for a combined dataset.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readPISA">readPISA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Return an edsurvey.data.frame for only the PISA YAFS dataset.
#Either omit, or set the esdf_PISA2012_USA to a NULL value.
yafs &lt;- readPISA_YAFS(datPath = "~/PISA YAFS/2016/PISA_YAFS2016_Data.dat",
                      spsPath = "~/PISA YAFS/2016/PISA_YAFS2016_SPSS.sps",
                      esdf_PISA2012_USA = NULL)
  
#If wanting to analyze the PISA YAFS dataset in conjunction with the PISA 2012 
#United States of America (USA) dataset, it should be read in first to an edsurvey.data.frame.
#Then pass the resulting edsurvey.data.frame as a parameter for the
#esdf_PISA2012_USA argument. No other edsurvey.data.frames are supported.
usa2012 &lt;- readPISA("~/PISA/2012", database = "INT", countries = "usa")
  
yafs &lt;- readPISA_YAFS(datPath = "~/PISA YAFS/2016/PISA_YAFS2016_Data.dat",
                      spsPath = "~/PISA YAFS/2016/PISA_YAFS2016_SPSS.sps",
                      esdf_PISA2012_USA = usa2012)
head(yafs)

## End(Not run)
</code></pre>

<hr>
<h2 id='readSSOCS'>Connect to School Survey on Crime and Safety Data</h2><span id='topic+readSSOCS'></span>

<h3>Description</h3>

<p>Opens a connection to a School Survey on Crime and Safety (SSOCS) data file and
returns an <code>edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code> if multiple files specified,
with information about the file(s) and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readSSOCS(sasDataFiles, years, forceReread = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readSSOCS_+3A_sasdatafiles">sasDataFiles</code></td>
<td>
<p>a character vector to the full SAS (*.sas7bdat) data file path(s) you wish to read.
If multiple paths are specified as a vector, it will return an <code>edsurvey.data.frame.list</code>.</p>
</td></tr>
<tr><td><code id="readSSOCS_+3A_years">years</code></td>
<td>
<p>an integer vector of the year associated with the index position of the <code>sasDataFile</code> data file vector.
The year is required to correctly determine required metadata about the file.
Valid year values are as follows: 2000 (1999&ndash;2000), 2004 (2003&ndash;2004), 2006 (2005&ndash;2006), 2008 (2007&ndash;2008),
2010 (2009&ndash;2010), 2016 (2015&ndash;2016), 2018 (2017&ndash;2018).</p>
</td></tr>
<tr><td><code id="readSSOCS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the <code>readSSOCS</code> function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readSSOCS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the SSOCS Data Products website in SAS format.  Other sources of SSOCS data, such as
restricted-use data or other websites, may require additional conversion steps to generate the required SAS format.
</p>


<h3>Value</h3>

<p>An <code>edsurvey.data.frame</code> if one data file is specified or an <code>edsurvey.data.frame.list</code> if multiple files are specified in the <code>sasDataFiles</code> parameter.
</p>


<h3>Note</h3>

<p>For the <code>readSSOCS</code> function, value label information is stored and retrieved automatically within the <code>EdSurvey</code> package (based on the year parameter),
as the SAS files contain only raw data values.
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+downloadSSOCS">downloadSSOCS</a></code>, and <code><a href="#topic+getData">getData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#download SSOCS data for years 2016 and 2018 
downloadSSOCS(years = c(2016, 2018))

rootPath &lt;- "~/"# may need to change this 
#get SAS *.sas7bdat file paths of all SSOCS files for 2016 and 2018
filesToImport &lt;- list.files(path = file.path(rootPath, "SSOCS", c(2016, 2018)),
                            pattern="\\.sas7bdat$",
                            full.names = TRUE)
  
#import all files to edsurvey.data.frame.list object
esdfList &lt;- readSSOCS(sasDataFiles = filesToImport,
                      years = c(2016, 2018),
                      forceReread = FALSE,
                      verbose = TRUE)

#reading in the 2018 to an edsurvey.data.frame object
esdf &lt;- readSSOCS(sasDataFiles = file.path(rootPath, "SSOCS/2018/pu_ssocs18.sas7bdat"),
                  years = 2018,
                  forceReread = FALSE,
                  verbose = TRUE)
  
#search for variables in the edsurvey.data.frame containing the word 'bully'
searchSDF("bully", esdf)

## End(Not run)
</code></pre>

<hr>
<h2 id='readTALIS'>Connect to TALIS Data</h2><span id='topic+readTALIS'></span>

<h3>Description</h3>

<p>Opens a connection to a TALIS data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readTALIS(
  path,
  countries,
  isced = c("b", "a", "c"),
  dataLevel = c("teacher", "school"),
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readTALIS_+3A_path">path</code></td>
<td>
<p>a character vector to the full directory path(s) to the TALIS SPSS files (.sav)</p>
</td></tr>
<tr><td><code id="readTALIS_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include using the
three-digit ISO country code. A list of country codes can be found in
the TALIS codebook, or you can use
<a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>.
You can use <code>*</code> to indicate all countries available.</p>
</td></tr>
<tr><td><code id="readTALIS_+3A_isced">isced</code></td>
<td>
<p>a character value that is one of <code>a</code>, <code>b</code>, or <code>c</code>. <code>a</code> stands for <em>Primary Level</em>,
<code>b</code> is for <em>Lower Secondary Level</em>, and <code>c</code> is for <em>Upper Secondary Level</em>. Default to <code>b</code>.</p>
</td></tr>
<tr><td><code id="readTALIS_+3A_datalevel">dataLevel</code></td>
<td>
<p>a character value that indicates which data level to be used. It can be <code>teacher</code> (the default) or <code>school</code> (see details).</p>
</td></tr>
<tr><td><code id="readTALIS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data. Defaults to <code>FALSE</code>.
Setting <code>forceReread</code> to be <code>TRUE</code> will cause <code>readTALIS</code> data to be reread and increase processing time.</p>
</td></tr>
<tr><td><code id="readTALIS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value that will determine if you want verbose output while the function is running to indicate the progress.
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the TALIS database using the OECD Repository (<a href="https://www.oecd.org/education/talis/">https://www.oecd.org/education/talis/</a>).
If <code>dataLevel</code> is set to be <code>teacher</code>, it treats the teacher data file as the main dataset, and merges school data into teacher data for
each country automatically. Use this option if wanting to analyze just teacher variables, or both teacher and school level variables together.
If <code>dataLevel</code> is set <code>school</code>, it uses only the school data file (no teacher data will be available).
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or
an <code>edsurvey.data.frame.list</code> if multiple countries specified
</p>


<h3>Author(s)</h3>

<p>Paul Bailey, Tom Fink, and Trang Nguyen
</p>


<h3>References</h3>

<p>Organisation for Economic Co-operation and Development. (2018). <em>TALIS 2018 technical report</em>. Retrieved from <em><a href="https://www.oecd.org/education/talis/TALIS_2018_Technical_Report.pdf">https://www.oecd.org/education/talis/TALIS_2018_Technical_Report.pdf</a></em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getData">getData</a></code> and <code><a href="#topic+downloadTALIS">downloadTALIS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#TALIS 2018 - school level data for all countries
talis18 &lt;- readTALIS(path = "~/TALIS/2018", 
                     isced = "b", 
                     dataLevel = "school", 
                     countries = "*")

#unweighted summary
result &lt;- summary2(talis18, "tc3g01", weightVar = "")

#print usa results to console
result$usa

# the following call returns an edsurvey.data.frame to TALIS 2013 
# for US teacher-level data at secondary level
usa2013 &lt;- readTALIS(path = "~/TALIS/2013", isced = "b",
                     dataLevel = "teacher", countries = "usa")

# extract a data.frame with a few variables
gg &lt;- getData(usa2013, c("tt2g05b", "tt2g01"))  
head(gg)

# conduct an analysis on the edsurvey.data.frame
edsurveyTable(tt2g05b ~ tt2g01, data = usa2013) 

## End(Not run)
</code></pre>

<hr>
<h2 id='readTIMSS'>Connect to TIMSS Data</h2><span id='topic+readTIMSS'></span>

<h3>Description</h3>

<p>Opens a connection to a TIMSS data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readTIMSS(
  path,
  countries,
  gradeLvl = c("4", "8", "4b", "8b"),
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readTIMSS_+3A_path">path</code></td>
<td>
<p>a character vector to the full directory path(s) to the TIMSS
extracted SPSS (.sav) set of data</p>
</td></tr>
<tr><td><code id="readTIMSS_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include using
the three-digit ISO country code.
A list of country codes can be found on Wikipedia at
<a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>
or other online sources. Consult the <em>TIMSS User Guide</em>
documentation to help determine what countries
are included within a specific testing year of TIMSS and
for country code definitions.
To select all countries available, use a wildcard value of <strong><code>*</code></strong>.</p>
</td></tr>
<tr><td><code id="readTIMSS_+3A_gradelvl">gradeLvl</code></td>
<td>
<p>a character value to indicate the specific grade level you wish to return
</p>

<ul>
<li><p><strong>4</strong> = fourth grade (the default if not specified)
</p>
</li>
<li><p><strong>8</strong> = eighth grade
</p>
</li>
<li><p><strong>4B</strong> = fourth grade bridge study (TIMSS 2019 only)
</p>
</li>
<li><p><strong>8B</strong> = eight grade bridge study (TIMSS 2019 only)
</p>
</li></ul>
</td></tr>
<tr><td><code id="readTIMSS_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the <code>readTIMSS</code> function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readTIMSS_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the TIMSS international
database(s) using the <a href="https://www.iea.nl/data-tools/repository">IEA Study Data Repository</a>.
Data files require the SPSS data file (.sav) format using the default
filenames.
</p>
<p>A TIMSS <code>edsurvey.data.frame</code> includes three distinct data levels:
</p>

<ul>
<li><p> student
</p>
</li>
<li><p> school
</p>
</li>
<li><p> teacher
</p>
</li></ul>

<p>When the <code>getData</code> function is called using a TIMSS <code>edsurvey.data.frame</code>,
the requested data variables are inspected, and it handles any necessary data merges automatically.
The <code>school</code> data always will be returned merged to the <code>student</code>
data, even if only <code>school</code> variables are requested.
If <code>teacher</code> variables are requested by the <code>getData</code> call, it
will cause <code>teacher</code> data to be merged.
Many <code>students</code> can be linked to many <code>teachers</code>, which varies
widely between countries.
</p>
<p>Please note that calling the <code>dim</code> function for a TIMSS
<code>edsurvey.data.frame</code> will result in the row count as if the
<code>teacher</code> dataset was merged.
This row count will be considered the <code>full data N</code> of the
<code>edsurvey.data.frame</code>, even if no <code>teacher</code> data were included in an analysis.
The column count returned by <code>dim</code> will be the count of unique column
variables across all three data levels.
</p>
<p>Beginning with TIMSS 2015, a <code>numeracy</code> dataset was designed to assess
mathematics at the end of the primary school cycle
for countries where most children are still developing fundamental mathematics skills.
The <code>numeracy</code> dataset is handled automatically for the user and is
included within the fourth-grade dataset <code>gradeLvl=4</code>.
Most <code>numeracy</code> countries have a <code>4th grade</code> dataset in addition
to their <code>numeracy</code> dataset, but some do not.
For countries that have both a <code>numeracy</code> and a <code>4th grade</code> dataset,
the two datasets are combined into one <code>edsurvey.data.frame</code> for that country.
Data variables missing from either dataset are kept, with <code>NA</code> values
inserted for the dataset records where that variable did not exist.
Data variables common to both datasets are kept as a single data variable,
with records retaining their original values from the source dataset.
Consult the <em>TIMSS User Guide</em> for further information.
</p>
<p>For the TIMSS 2019 study, a bridge study was conducted to help compute adjustment factors
between the electronic test format and the paper/pencil format.  The bridge study is
considered separate from the normal TIMSS 2019 study. The <code>gradeLvl</code> parameter now
includes a <code>"4B"</code> option for the Grade 4 bridge study, and the <code>"8B"</code> option
for the Grade 8 bridge study files.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or an <code>edsurvey.data.frame.list</code> if multiple countries specified
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+getData">getData</a></code>, and <code><a href="#topic+downloadTIMSS">downloadTIMSS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# single country specified
fin &lt;- readTIMSS("~/TIMSS/2015", countries = c("fin"), gradeLvl = 4)
gg &lt;- getData(fin, c("asbg01", "totwgt", "srea"))
head(gg)
edsurveyTable(srea ~ asbg01, fin)

# multiple countries returned as edsurvey.data.frame.list, specify all countries with '*' argument
timss2011 &lt;- readTIMSS("~/TIMSS/2011", countries="*", gradeLvl = 8, verbose = TRUE)
# print out edsurvey.data.frame.list covariates
timss2011$covs

## End(Not run)
</code></pre>

<hr>
<h2 id='readTIMSSAdv'>Connect to TIMSS Advanced Data</h2><span id='topic+readTIMSSAdv'></span>

<h3>Description</h3>

<p>Opens a connection to a TIMSS Advanced data file and
returns an <code>edsurvey.data.frame</code> with
information about the file and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readTIMSSAdv(
  path,
  countries,
  subject = c("math", "physics"),
  forceReread = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readTIMSSAdv_+3A_path">path</code></td>
<td>
<p>a character vector to the full directory path to the TIMSS Advanced extracted SPSS (.sav) set of data</p>
</td></tr>
<tr><td><code id="readTIMSSAdv_+3A_countries">countries</code></td>
<td>
<p>a character vector of the country/countries to include using
the three-digit ISO country code.
A list of country codes can be found on Wikipedia at
<a href="https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes">https://en.wikipedia.org/wiki/ISO_3166-1#Current_codes</a>
or other online sources. Consult the <em>TIMSS Advanced User Guide</em> to help determine what countries
are included within a specific testing year of TIMSS Advanced.
To select all countries, use a wildcard value of <strong><code>*</code></strong>.</p>
</td></tr>
<tr><td><code id="readTIMSSAdv_+3A_subject">subject</code></td>
<td>
<p>a character value to indicate if you wish to import the <code>math</code> or <code>physics</code> dataset.
Only one subject can be read in at a time.</p>
</td></tr>
<tr><td><code id="readTIMSSAdv_+3A_forcereread">forceReread</code></td>
<td>
<p>a logical value to force rereading of all processed data.
The default value of <code>FALSE</code> will speed up the <code>readTIMSSAdv</code> function by using existing read-in data already processed.</p>
</td></tr>
<tr><td><code id="readTIMSSAdv_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.
The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in the unzipped files downloaded from the TIMSS Advanced
international database(s) using the
<a href="https://www.iea.nl/data-tools/repository">IEA Study Data Repository</a>.
Data files require the SPSS data file (.sav) format using the default
filenames.
</p>
<p>A TIMSS Advanced <code>edsurvey.data.frame</code> includes three distinct data levels:
</p>

<ul>
<li><p> student
</p>
</li>
<li><p> school
</p>
</li>
<li><p> teacher
</p>
</li></ul>

<p>When the <code>getData</code> function is called using a TIMSS Advanced <code>edsurvey.data.frame</code>,
the requested data variables are inspected, and it handles any necessary data merges automatically.
The <code>school</code> data always will be returned merged to the <code>student</code>
data, even if only <code>school</code> variables are requested.
If <code>teacher</code> variables are requested by the <code>getData</code> call it will cause the <code>teacher</code> data to be merged.
Many <code>students</code> can be linked to many <code>teachers</code>, which varies widely between countries.
</p>
<p>Please note that calling the <code>dim</code> function for a TIMSS Advanced <code>edsurvey.data.frame</code> will result in the row count as if the <code>teacher</code> dataset was merged.
This row count will be considered the <code>full data N</code> of the <code>edsurvey.data.frame</code>, even if no <code>teacher</code> data were included in an analysis.
The column count returned by <code>dim</code> will be the count of unique column variables across all three data levels.
</p>


<h3>Value</h3>

<p>an <code>edsurvey.data.frame</code> for a single specified country or an <code>edsurvey.data.frame.list</code> if multiple countries specified
</p>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readNAEP">readNAEP</a></code>, <code><a href="#topic+readTIMSS">readTIMSS</a></code>, <code><a href="#topic+getData">getData</a></code>, and <code><a href="#topic+downloadTIMSSAdv">downloadTIMSSAdv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
swe &lt;- readTIMSSAdv("~/TIMSSAdv/2015",
                    countries = c("swe"), subject = "math")
gg &lt;- getData(swe, c("itsex", "totwgt", "malg"))
head(gg)
edsurveyTable(malg ~ itsex, swe)

## End(Not run)
</code></pre>

<hr>
<h2 id='rebindAttributes'>Copy Data Frame Attributes</h2><span id='topic+rebindAttributes'></span>

<h3>Description</h3>

<p>Many R functions strip attributes from data frame objects. This
function assigns the attributes from the <code>attributeData</code> argument
to the data frame in the <code>data</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rebindAttributes(data, attributeData)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rebindAttributes_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="rebindAttributes_+3A_attributedata">attributeData</code></td>
<td>
<p>an <code>edsurvey.data.frame</code> or <code>light.edsurvey.data.frame</code>
that contains the desired attributes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> with a class of a <code>light.edsurvey.data.frame</code> containing
all elements of data and the attributes (except
<code>names</code> and <code>row.names</code>) from <code>attributeData</code>
</p>


<h3>Author(s)</h3>

<p>Paul Bailey and Trang Nguyen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(dplyr)
PISA2012 &lt;- readPISA(path = paste0(edsurveyHome, "PISA/2012"),
                     database = "INT",
                     countries = "ALB", verbose=TRUE)
ledf &lt;- getData(data = PISA2012, varnames = c("cnt", "oecd", "w_fstuwt",
                                              "st62q04", "st62q11",
                                              "st62q13", "math"),
                dropOmittedLevels = FALSE, addAttributes = TRUE)

omittedLevels &lt;- c('Invalid', 'N/A', 'Missing', 'Miss', 'NA', '(Missing)')
for (i in c("st62q04", "st62q11", "st62q13")) {
  ledf[,i] &lt;- factor(ledf[,i], exclude=omittedLevels)
  ledf[,i] &lt;- as.numeric(ledf[,i])
}

# after applying some dplyr functions, the "light.edsurvey.data.frame" becomes just "data.frame"
PISA2012_ledf &lt;- ledf %&gt;%        
  rowwise() %&gt;% 
  mutate(avg_3 = mean(c(st62q04, st62q11, st62q13), na.rm = TRUE)) %&gt;% 
  ungroup() %&gt;%
  rebindAttributes(PISA2012) # could also be called with ledf
class(PISA2012_ledf) 
# again, a light.edsurvey.data.frame
lma &lt;- lm.sdf(math ~ avg_3,data=PISA2012_ledf)
summary(lma)

PISA2012_ledf &lt;- ledf %&gt;%        
  rowwise() %&gt;% 
  mutate(avg_3 = mean(c(st62q04, st62q11, st62q13), na.rm = TRUE)) %&gt;% 
  ungroup() %&gt;%
  rebindAttributes(ledf) # return attributes and make a light.edsurvey.data.frame 
# again a light.edsurvey.data.frame
lma &lt;- lm.sdf(math ~ avg_3,data=PISA2012_ledf)
summary(lma)

## End(Not run)
</code></pre>

<hr>
<h2 id='recode.sdf'>Recode Levels Within Variables</h2><span id='topic+recode.sdf'></span>

<h3>Description</h3>

<p>Recodes variables in an <code>edsurvey.data.frame</code>,
a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recode.sdf(x, recode)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recode.sdf_+3A_x">x</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="recode.sdf_+3A_recode">recode</code></td>
<td>
<p>a list of recoding rules. See Examples for the format of recoding rules.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of the same class as <code>x</code> with the <code>recode</code> added to it
</p>


<h3>Author(s)</h3>

<p>Trang Nguyen and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# filepath argument will vary by operating system conventions
usaG4.15 &lt;- readTIMSS("~/TIMSS/2015", "usa", 4)
d &lt;- getData(usaG4.15, "itsex")
summary(d) #show details: MALE/FEMALE
usaG4.15 &lt;- recode.sdf(usaG4.15,
                       recode = list(itsex=list(from=c("MALE"),
                                                to=c("BOY")),
                                     itsex=list(from=c("FEMALE"),
                                                to=c("GIRL"))))

d &lt;- getData(usaG4.15, "itsex") #apply recode
summary(d) #show details: BOY/GIRL

## End(Not run)
</code></pre>

<hr>
<h2 id='rename.sdf'>Modify Variable Names</h2><span id='topic+rename.sdf'></span>

<h3>Description</h3>

<p>Renames variables in an <code>edsurvey.data.frame</code>,
a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
This function often is used when users want to conduct a gap analysis across
years but variable names differ across two years of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rename.sdf(x, oldnames, newnames, avoid_duplicated = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rename.sdf_+3A_x">x</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="rename.sdf_+3A_oldnames">oldnames</code></td>
<td>
<p>a character vector of old variable names</p>
</td></tr>
<tr><td><code id="rename.sdf_+3A_newnames">newnames</code></td>
<td>
<p>a character vector of new variable names to replace the
corresponding old names</p>
</td></tr>
<tr><td><code id="rename.sdf_+3A_avoid_duplicated">avoid_duplicated</code></td>
<td>
<p>a logical value to indicate whether to avoid renaming the
variable if the corresponding new name already exists in the data.
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All variable names are coerced to lowercase to comply with
the <code>EdSurvey</code> standard.
</p>


<h3>Value</h3>

<p>an object of the same class as <code>x</code> with new variable names
</p>


<h3>Author(s)</h3>

<p>Trang Nguyen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gap">gap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
usaG4.15 &lt;- readTIMSS("~/TIMSS/2015", "usa", 4)
usaG4.15.renamed &lt;- rename.sdf(usaG4.15,
                               c("itsex", "mmat"),
                               c("gender", "math_overall"))
lm1 &lt;- lm.sdf(math_overall ~ gender, data = usaG4.15.renamed)
summary(lm1)

## End(Not run)
</code></pre>

<hr>
<h2 id='rq.sdf'>EdSurvey Quantile Regression Models</h2><span id='topic+rq.sdf'></span><span id='topic+rq'></span>

<h3>Description</h3>

<p>Fits a quantile regression model that uses weights and variance estimates appropriate for the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.sdf(
  formula,
  data,
  tau = 0.5,
  weightVar = NULL,
  relevels = list(),
  jrrIMax = 1,
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  returnNumberOfPSU = FALSE,
  omittedLevels = deprecated(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.sdf_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code> for the
quantile regression model. See <code><a href="quantreg.html#topic+rq">rq</a></code>.
If <em>y</em> is left blank, the default subject scale or subscale variable
will be used. (You can find the default using
<code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>.)
If <em>y</em> is a variable for a subject scale or subscale (one of the
names shown by <code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>),
then that subject scale or subscale is used.</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_tau">tau</code></td>
<td>
<p>the quantile to be estimated. The value could be set between 0 and 1 with a default of 0.5.</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_weightvar">weightVar</code></td>
<td>
<p>a character indicating the weight variable to use.
The <code>weightVar</code> must be one of the weights for the
<code>edsurvey.data.frame</code>. If <code>NULL</code>, it  uses the default
for the <code>edsurvey.data.frame</code>.</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_relevels">relevels</code></td>
<td>
<p>a list. Used to change the contrasts from the
default treatment contrasts to the treatment contrasts with a chosen omitted
group (the reference group). The name of each element should be the variable name, and the value
should be the group to be omitted (the reference group).</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>when using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=1</code>, uses the
sampling variance from the first plausible value as the component for sampling variance estimation. The <code class="reqn">V_{jrr}</code>
term can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, drops
those levels of all factor variables that are specified
in an <code>edsurvey.data.frame</code>. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the omitted levels.</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of <code>TRUE</code>, uses
the default conditions stored in an <code>edsurvey.data.frame</code>
to subset the data. Use <code>print</code> on an
<code>edsurvey.data.frame</code> to see the default conditions.</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>. Can be set as
<code>recode=</code><code>list(</code><code>var1</code> <code>=</code> <code>list(</code><code>from=</code>
<code>c("a",</code> <code>"b",</code> <code>"c"),</code> <code>to=</code> <code>"d"))</code>.</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_returnnumberofpsu">returnNumberOfPSU</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the number of
primary sampling units (PSUs)</p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code></p>
</td></tr>
<tr><td><code id="rq.sdf_+3A_...">...</code></td>
<td>
<p>additional parameters passed from <code><a href="quantreg.html#topic+rq">rq</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes an estimate on the <code>tau</code>-th conditional quantile function of the response,
given the covariates, as specified by the formula argument. Like <code>lm.sdf()</code>, the
function presumes a linear specification for the quantile regression model (i.e., that the
formula defines a model that is linear in parameters). Unlike <code>lm.sdf()</code>, the jackknife is the
only applicable variance estimation method used by the function.
</p>
<p>For further details on quantile regression models and how they are implemented in R, see Koenker
and Bassett (1978), Koenker (2005), and the vignette from the <code>quantreg</code> package&mdash;
accessible by <code>vignette("rq",package="quantreg")</code>&mdash;on which this function is
built.
</p>
<p>For further details on how left-hand side variables, survey sampling weights, and estimated
variances are correctly handled, see <code><a href="#topic+lm.sdf">lm.sdf</a></code> or the vignette titled
<em><a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf">Statistical Methods Used in EdSurvey</a></em>.
</p>


<h3>Value</h3>

<p>An <code>edsurvey.rq</code> with the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula used to fit the model</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>the quantile to be estimated</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>the estimates of the coefficients</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard error estimates of the coefficients</p>
</td></tr>
<tr><td><code>Vimp</code></td>
<td>
<p>the estimated variance from uncertainty in the scores (plausible value variables)</p>
</td></tr>
<tr><td><code>Vjrr</code></td>
<td>
<p>the estimated variance from sampling</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>varm</code></td>
<td>
<p>the variance estimates under the various plausible values</p>
</td></tr>
<tr><td><code>coefm</code></td>
<td>
<p>the values of the coefficients under the various plausible values</p>
</td></tr>
<tr><td><code>coefmat</code></td>
<td>
<p>the coefficient matrix (typically produced by the summary of a model)</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>
<p>the name of the weight variable</p>
</td></tr>
<tr><td><code>npv</code></td>
<td>
<p>the number of plausible values</p>
</td></tr>
<tr><td><code>njk</code></td>
<td>
<p>the number of the jackknife replicates used; set to <code>NA</code> when Taylor series variance
estimates are used</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>the mean value of the objective function across the plausible values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Trang Nguyen, Paul Bailey, and Yuqi Liao
</p>


<h3>References</h3>

<p>Binder, D. A. (1983). On the variances of asymptotically normal estimators from complex surveys.
<em>International Statistical Review</em>, <em>51</em>(3), 279&ndash;292.
</p>
<p>Johnson, E. G., &amp; Rust, K. F. (1992). Population inferences and variance estimation for NAEP
data. <em>Journal of Education Statistics</em>, <em>17</em>(2), 175&ndash;190.
</p>
<p>Koenker, R. W., &amp; Bassett, G. W. (1978). Regression quantiles, <em>Econometrica, 46,</em> 33&ndash;50.
</p>
<p>Koenker, R. W. (2005). <em>Quantile regression</em>. Cambridge, UK: Cambridge University Press.
</p>
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>. New York, NY: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# conduct quantile regression at a given tau value (by default, tau is set to be 0.5) 
rq1 &lt;- rq.sdf(composite ~ dsex + b017451, data=sdf, tau = 0.8)
summary(rq1)

## End(Not run)
</code></pre>

<hr>
<h2 id='scoreDefault'>Assessment scoring</h2><span id='topic+scoreDefault'></span>

<h3>Description</h3>

<p>Score assessments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreDefault(edf, polyParamTab, dichotParamTab, scoreDict)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scoreDefault_+3A_edf">edf</code></td>
<td>
<p>the data</p>
</td></tr>
<tr><td><code id="scoreDefault_+3A_polyparamtab">polyParamTab</code></td>
<td>
<p>see <code><a href="#topic+mml.sdf">mml.sdf</a></code></p>
</td></tr>
<tr><td><code id="scoreDefault_+3A_dichotparamtab">dichotParamTab</code></td>
<td>
<p>see <code><a href="#topic+mml.sdf">mml.sdf</a></code></p>
</td></tr>
<tr><td><code id="scoreDefault_+3A_scoredict">scoreDict</code></td>
<td>
<p>a data frame; see Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>default scorer
scores column on edf identified by polyParamTab$ItemID, dichotParamTab$ItemID using a crosswalk in scoreDict
</p>
<p>the <code>scoreDict</code> is a data frame in long format with columns <code>key</code>, <code>answer</code>, and <code>score</code>.
the function maps, within the item identified by <code>key</code> from <code>answer</code> to <code>score</code>.
</p>


<h3>Value</h3>

<p>a data frame with the columns in the <code>scoreDict</code> <code>key</code> column mapped from <code>answer</code> to <code>score</code>.
</p>


<h3>Author(s)</h3>

<p>Paul Bailey and  Tom Fink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mml.sdf">mml.sdf</a></code>
</p>

<hr>
<h2 id='scoreTIMSS'>EdSurvey Direct Estimation - TIMSS scoring</h2><span id='topic+scoreTIMSS'></span>

<h3>Description</h3>

<p>Scoring TIMSS data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreTIMSS(edf, polyParamTab, dichotParamTab, scoreCard = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scoreTIMSS_+3A_edf">edf</code></td>
<td>
<p>a TIMSS <code>light.edsurvey.data.frame</code> or <code>edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="scoreTIMSS_+3A_polyparamtab">polyParamTab</code></td>
<td>
<p>a dataframe containing IRT parameters for all polytomous items in <code>edf</code></p>
</td></tr>
<tr><td><code id="scoreTIMSS_+3A_dichotparamtab">dichotParamTab</code></td>
<td>
<p>a dataframe containing IRT parameters for all dichotomous items in <code>edf</code></p>
</td></tr>
<tr><td><code id="scoreTIMSS_+3A_scorecard">scoreCard</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function scores TIMSS data.
For multiple choice items, correct answers are assigned 1 point, and incorrect answers are assigned 0 points.
For constructed response items, correct answers are assigned 2 points, partially correct answers are assigned 1 point,
and incorrect answers are assigned 0 points. For both types of items, &quot;NOT REACHED&quot; and &quot;OMITTED OR INVALID&quot; are assigned 0 points.
these defaults can be changed by modifying the <code>scoreDict</code> columns <code>pointMult</code> and <code>pointConst</code>, respectively.
</p>


<h3>Value</h3>

<p>scored <code>edf</code>
</p>

<hr>
<h2 id='SD'>EdSurvey Standard Deviation</h2><span id='topic+SD'></span>

<h3>Description</h3>

<p>Calculate the standard deviation of a numeric variable in an <code>edsurvey.data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SD(
  data,
  variable,
  weightVar = NULL,
  jrrIMax = 1,
  varMethod = "jackknife",
  dropOmittedLevels = TRUE,
  defaultConditions = TRUE,
  recode = NULL,
  targetLevel = NULL,
  jkSumMultiplier = getAttributes(data, "jkSumMultiplier"),
  returnVarEstInputs = FALSE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SD_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, an <code>edsurvey.data.frame.list</code>, or a <code>light.edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="SD_+3A_variable">variable</code></td>
<td>
<p>character vector of variable names</p>
</td></tr>
<tr><td><code id="SD_+3A_weightvar">weightVar</code></td>
<td>
<p>character weight variable name. Default is the default weight of <code>data</code> if it exists.
If the given survey data do not have a default weight,
the function will produce unweighted statistics instead.
Can be set to <code>NULL</code> to return unweighted statistics.</p>
</td></tr>
<tr><td><code id="SD_+3A_jrrimax">jrrIMax</code></td>
<td>
<p>a numeric value; when using the jackknife variance estimation method, the default estimation option, <code>jrrIMax=1</code>, uses the
sampling variance from the first plausible value as the component for sampling variance estimation. The <code>Vjrr</code>
term (see
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>)
can be estimated with any number of plausible values, and values larger than the number of
plausible values on the survey (including <code>Inf</code>) will result in all plausible values being used.
Higher values of <code>jrrIMax</code> lead to longer computing times and more accurate variance estimates.</p>
</td></tr>
<tr><td><code id="SD_+3A_varmethod">varMethod</code></td>
<td>
<p>deprecated parameter; <code>gap</code> always uses the jackknife variance estimation</p>
</td></tr>
<tr><td><code id="SD_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to <code>TRUE</code>, drops those levels of the specified <code>variable</code>.
Use print on an <code>edsurvey.data.frame</code> to see the omitted levels. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="SD_+3A_defaultconditions">defaultConditions</code></td>
<td>
<p>a logical value. When set to the default value of
<code>TRUE</code>, uses the default conditions stored in
an <code>edsurvey.data.frame</code> to subset the data. Use
<code>print</code> on an <code>edsurvey.data.frame</code> to
see the default conditions.</p>
</td></tr>
<tr><td><code id="SD_+3A_recode">recode</code></td>
<td>
<p>a list of lists to recode variables. Defaults to <code>NULL</code>.
Can be set as <code>recode</code> <code>=</code> <code>list(var1</code>
<code>=</code> <code>list(from</code> <code>=</code> <code>c("a","b","c"), to</code>
<code>=</code> <code>"d"))</code>.</p>
</td></tr>
<tr><td><code id="SD_+3A_targetlevel">targetLevel</code></td>
<td>
<p>a character string. When specified, calculates the gap in
the percentage of students at
<code>targetLevel</code> in the <code>variable</code> argument, which is useful for
comparing the gap in the percentage of students at a
survey response level.</p>
</td></tr>
<tr><td><code id="SD_+3A_jksummultiplier">jkSumMultiplier</code></td>
<td>
<p>when the jackknife variance estimation method&mdash;or
balanced repeated replication (BRR)
method&mdash;multiplies the final jackknife variance estimate by a value,
set <code>jkSumMultiplier</code> to that value.
For an <code>edsurvey.data.frame</code>, or
a <code>light.edsurvey.data.frame</code>,
the recommended value can be recovered with
<code>EdSurvey::getAttributes(</code><code>myData,</code> <code>"jkSumMultiplier")</code>.</p>
</td></tr>
<tr><td><code id="SD_+3A_returnvarestinputs">returnVarEstInputs</code></td>
<td>
<p>a logical value set to <code>TRUE</code> to return the
inputs to the jackknife and imputation variance
estimates, which allows for
the computation
of covariances between estimates.</p>
</td></tr>
<tr><td><code id="SD_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list object with elements:
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>the mean assessment score for <code>variable</code>, calculated according to the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf">Statistical Methods Used in EdSurvey</a></p>
</td></tr>
<tr><td><code>std</code></td>
<td>
<p>the standard deviation of the <code>mean</code></p>
</td></tr>
<tr><td><code>stdSE</code></td>
<td>
<p>the standard error of the <code>std</code></p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the degrees of freedom of the <code>std</code></p>
</td></tr>
<tr><td><code>varEstInputs</code></td>
<td>
<p>the variance estimate inputs used for calculating covariances with <code><a href="#topic+varEstToCov">varEstToCov</a></code>. Only returned with <code>returnVarEstInputs</code> is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Bailey and Huade Huo
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# get standard deviation for Male's composite score
SD(data = subset(sdf, dsex == "Male"), variable = "composite")

# get several standard deviations

# build an edsurvey.data.frame.list
sdfA &lt;- subset(sdf, scrpsu %in% c(5,45,56))
sdfB &lt;- subset(sdf, scrpsu %in% c(75,76,78))
sdfC &lt;- subset(sdf, scrpsu %in% 100:200)
sdfD &lt;- subset(sdf, scrpsu %in% 201:300)

sdfl &lt;- edsurvey.data.frame.list(list(sdfA, sdfB, sdfC, sdfD),
                                 labels=c("A locations",
                                          "B locations",
                                          "C locations",
                                          "D locations"))

# this shows how these datasets will be described:
sdfl$covs

# SD results for each survey
SD(data = sdfl, variable = "composite")
# SD results more compactly and with comparisons
gap(variable="composite", data=sdfl, stDev=TRUE, returnSimpleDoF=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='searchSDF'>EdSurvey Codebook Search</h2><span id='topic+searchSDF'></span>

<h3>Description</h3>

<p>Retrieves variable names and labels for an <code>edsurvey.data.frame</code>,
a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>
using character string matching.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>searchSDF(string, data, fileFormat = NULL, levels = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="searchSDF_+3A_string">string</code></td>
<td>
<p>a vector of character strings to search for in the database connection object (<code>data</code>).
The function will search the codebook
for a matching character string using regular expressions. When a
string has several elements, all must be present for a
variable to be returned.</p>
</td></tr>
<tr><td><code id="searchSDF_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="searchSDF_+3A_fileformat">fileFormat</code></td>
<td>
<p>a character vector indicating the data source to search for variables.
The default <code>NULL</code> argument searches all codebooks.</p>
</td></tr>
<tr><td><code id="searchSDF_+3A_levels">levels</code></td>
<td>
<p>a logical value; set to <code>TRUE</code> to return a snapshot of the levels in
an <code>edsurvey.data.frame</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> that shows the variable names, labels,
and levels (if applicable) from an <code>edsurvey.data.frame</code> or a <code>light.edsurvey.data.frame</code> based on a matching character string
</p>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# search both the student and school files by a character string
searchSDF(string="book", data=sdf)

# use the `|` (OR) operator to search several strings simultaneously
searchSDF(string="book|home|value", data=sdf)

# use a vector of strings to search for variables that contain multiple strings,
# such as both "book" and "home"
searchSDF(string=c("book","home"), data=sdf)

# search only the student files by a character string
searchSDF(string="algebra", data=sdf, fileFormat="student")

# search both the student and school files and return a glimpse of levels
searchSDF(string="value", data=sdf, levels=TRUE)

# save the search as an object to return a full data.frame of search
ddf &lt;- searchSDF(string="value", data=sdf, levels=TRUE)
ddf

## End(Not run)
</code></pre>

<hr>
<h2 id='setNAEPScoreCard'>set NAEP Score Card</h2><span id='topic+setNAEPScoreCard'></span>

<h3>Description</h3>

<p>add item response theory data necessary to use <code>mml.sdf</code> on NAEP data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setNAEPScoreCard(data, dctPath = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setNAEPScoreCard_+3A_data">data</code></td>
<td>
<p>a NAEP <code>edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="setNAEPScoreCard_+3A_dctpath">dctPath</code></td>
<td>
<p>a file location that points to the location of a NAEP <code>.dct</code> file (usually in the <code>AM</code> folder). A <code>.dct</code> file can be
used to input custom item response theory (IRT)
parameters and subscale/subtest weights for NAEP assessments compared with those provided in the <code>NAEPirtparams</code> package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a NAEP <code>edsurvey.data.frame</code> with updated attributes
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
datFP &lt;- "~/NAEP_Folder/Data/M50NT3AT.dat"
sdf &lt;- readNAEP(datFP)

#how to set NAEP mml attributes
#if readNAEP does not detect them automatically
dctFP &lt;- "~/NAEP_Folder/AM/M50NT3AT.dct"
sdf &lt;- setNAEPScoreCard(sdf, dctFP)

## End(Not run)
</code></pre>

<hr>
<h2 id='showCodebook'>Summary Codebook</h2><span id='topic+showCodebook'></span>

<h3>Description</h3>

<p>Retrieves variable names, variable labels, and value labels for an
<code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>showCodebook(
  data,
  fileFormat = NULL,
  labelLevels = FALSE,
  includeRecodes = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="showCodebook_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="showCodebook_+3A_fileformat">fileFormat</code></td>
<td>
<p>a character string indicating the data source to search for variables.
The default <code>NULL</code> argument searches all available codebooks in the database connection object.</p>
</td></tr>
<tr><td><code id="showCodebook_+3A_labellevels">labelLevels</code></td>
<td>
<p>a logical value; set to <code>TRUE</code> to return a snapshot of the label levels in
an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>. When set to <code>FALSE</code>
(the default), label levels are removed.</p>
</td></tr>
<tr><td><code id="showCodebook_+3A_includerecodes">includeRecodes</code></td>
<td>
<p>a logical value; set to <code>TRUE</code> to return value labels that have been recoded in
an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>. When set to <code>FALSE</code>
(the default), only the original value labels are included in the returned <code>data.frame</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> that shows the variable names, variable labels, value labels,
value levels (if applicable), and the file format data source from an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code>
</p>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# search both the student and school files, returning levels for variable values
showCodebook(sdf, c("student","school"), labelLevels = TRUE, includeRecodes = FALSE)

# return codebook information for the student file, excluding variable value levels,
# including recoded variables
sdf &lt;- recode.sdf(sdf, recode = list(dsex = list(from = c("Male"), to = c("MALE"))))
showCodebook(sdf, c("student"), labelLevels = FALSE, includeRecodes = TRUE)

# return codebook information for the student file, including variable value levels
# and recoded variables
showCodebook(sdf, c("student","school"), labelLevels = FALSE, includeRecodes = TRUE)

# return codebook information for all codebooks in an edsurvey.data.frame; commonly use View()
View(showCodebook(sdf))

## End(Not run)
</code></pre>

<hr>
<h2 id='showCutPoints'>Retrieve Achievement Level Cutpoints</h2><span id='topic+showCutPoints'></span>

<h3>Description</h3>

<p>Retrieves a summary of the achievement level cutpoints for a
selected study represented in an
<code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>showCutPoints(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="showCutPoints_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>If there are achievement levels defined, prints one line per subject scale.
Each line names the subject and then shows the cut point for each achievement level.
</p>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# show the cut points
showCutPoints(data=sdf)

## End(Not run)
</code></pre>

<hr>
<h2 id='showPlausibleValues'>Plausible Value Variable Names</h2><span id='topic+showPlausibleValues'></span>

<h3>Description</h3>

<p>Prints a summary of the subject scale or subscale and the associated variables for their
plausible values for an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>showPlausibleValues(data, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="showPlausibleValues_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="showPlausibleValues_+3A_verbose">verbose</code></td>
<td>
<p>a logical value; set to <code>TRUE</code> to get the variable names for plausible values.
Otherwise, prints only the subject scale or subscale names for variables
that use plausible values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# show the plausible values
showPlausibleValues(data=sdf, verbose=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='showWeights'>Retrieve Weight Variables</h2><span id='topic+showWeights'></span>

<h3>Description</h3>

<p>Prints a summary of the weights in an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>showWeights(data, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="showWeights_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="showWeights_+3A_verbose">verbose</code></td>
<td>
<p>a logical value; set to TRUE to print the complete list of jackknife
replicate weights associated with each full sample weight;
otherwise, prints only the full sample weights</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# show the weights
showWeights(sdf, TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='suggestWeights'>Weight suggestions for ECLS-K:2011 data</h2><span id='topic+suggestWeights'></span>

<h3>Description</h3>

<p>Suggest Weights for ECLS-K:2011 data based on inputting variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>suggestWeights(
  varnames = NULL,
  data,
  showAllWeightSuggestions = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="suggestWeights_+3A_varnames">varnames</code></td>
<td>
<p>character vector indicating variables to be included in the weight suggestion.</p>
</td></tr>
<tr><td><code id="suggestWeights_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>,
or an <code>edsurvey.data.frame.list</code></p>
</td></tr>
<tr><td><code id="suggestWeights_+3A_showallweightsuggestions">showAllWeightSuggestions</code></td>
<td>
<p>a logical value. When set to <code>TRUE</code>, all applicable weights that covers
more components, which typically are more conservative with
smaller sample size, will be returned. By default (i.e., <code>FALSE</code>), only the most approperate
weight is displayed.</p>
</td></tr>
<tr><td><code id="suggestWeights_+3A_verbose">verbose</code></td>
<td>
<p>a logical value to either print or suppress status message output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>suggestWeights</code> provides one additional way to assist researchers in deciding which weight to use for analyses.
This function find the intersect of possible weights given variables provided, and rank this intersect
based on the number of components a weight can adjust.
</p>
<p>The best weight would adjust for each and every source used and only those sources.
However, for many analyses, there will be no weight that adjusts for nonresponse
to all the sources of data that are included and for only those source.
When no weight corresponds exactly to the combination of components included in the desired analysis,
researchers might prefer to use a weight that includes nonresponse adjustments for more components
than they are using in their analysis if that weight also includes
nonresponse adjustments for the components they are using.
</p>
<p>Researchers should always consult their research questions for optimal weight choice.
</p>


<h3>Value</h3>

<p>A list of weight variables. The first one is the most approperate choice.
</p>


<h3>Author(s)</h3>

<p>Huade Huo
</p>


<h3>References</h3>

<p>Tourangeau, K., Nord, C., Le, T., Sorongon, A.G., Hagedorn, M.C., Daly, P., and Najarian, M. (2015). <em>Early Childhood Longitudinal Study, Kindergarten Class of 2010-11 (ECLS-K:2011), User's Manual for the ECLS-K:2011 Kindergarten Data File and Electronic Codebook, Public Version</em> (NCES 2015-074). U.S. Department of Education. Washington, DC: National Center for Education Statistics.
</p>
<p>Tourangeau, K., Nord, C., Le, T., Wallner-Allen, K., Hagedorn, M.C., Leggitt, J., and Najarian, M. (2015). <em>Early Childhood Longitudinal Study, Kindergarten Class of 2010-11 (ECLS-K:2011), User's Manual for the ECLS-K:2011 Kindergarten-First Grade Data File and Electronic Codebook, Public Version</em> (NCES 2015-078). U.S. Department of Education. Washington, DC: National Center for Education Statistics.
</p>
<p>Tourangeau, K., Nord, C., Le, T., Wallner-Allen, K., Vaden-Kiernan, N., Blaker, L. and Najarian, M. (2017). <em>Early Childhood Longitudinal Study, Kindergarten Class of 2010-11 (ECLS-K:2011) User's Manual for the ECLS-K:2011 Kindergarten-Second Grade Data File and Electronic Codebook, Public Version</em> (NCES 2017-285). U.S. Department of Education. Washington, DC: National Center for Education Statistics.
</p>
<p>Tourangeau, K., Nord, C., Le, T., Wallner-Allen, K., Vaden-Kiernan, N., Blaker, L. and Najarian, M. (2018). <em>Early Childhood Longitudinal Study, Kindergarten Class of 2010-11 ( ECLS -K:2011) User's Manual for the ECLS-K:2011 Kindergarten-Third G rade Data File and Electronic Codebook, Public Version</em> (NCES 2018-034). U.S. Department of Education. Washington, DC: National Center for Education Statistics
</p>
<p>Tourangeau, K., Nord, C., Le, T., Wallner-Allen, K., Vaden-Kiernan, N., Blaker, L. and Najarian, M. (2018). <em>Early Childhood Longitudinal Study, Kindergarten Class of 2010-11 (ECLS-K:2011) User's Manual for the ECLS-K:2011 Kindergarten-Fourth Grade Data File and Electronic Codebook, Public Version</em> (NCES 2018-032). U.S. Department of Education. Washington, DC: National Center for Education Statistics.
</p>
<p>Tourangeau, K., Nord, C., Le, T., Wallner-Allen, K., Vaden-Kiernan, N., Blaker, L. and Najarian, M. (2019). <em>Early Childhood Longitudinal Study, Kindergarten Class of 2010-11 (ECLS-K:2011) User's Manual for the ECLS-K:2011 Kindergarten-Fifth Grade Data File and Electronic Codebook, Public Version</em> (NCES 2019-051). U.S. Department of Education. Washington, DC: National Center for Education Statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read-in ECLS-K:2011 data file with parameters specified
eclsk11 &lt;- readECLS_K2011(file.path("~/", "ECLS_K", "2011"), filename = "childK5p.dat",
                           layoutFilename = "ECLSK2011_K5PUF.sps", verbose = FALSE)

# suggest weight for individual variable
suggestWeights("x8mscalk5", eclsk11)

# suggest weight for multiple variables
suggestWeights(c("x8mscalk5", "x_chsex_r", "x12sesl"), eclsk11)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary2'>Summarize edsurvey.data.frame Variables</h2><span id='topic+summary2'></span>

<h3>Description</h3>

<p>Summarizes <code>edsurvey.data.frame</code> variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary2(
  data,
  variable,
  weightVar = attr(getAttributes(data, "weights"), "default"),
  dropOmittedLevels = FALSE,
  omittedLevels = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary2_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, an <code>edsurvey.data.frame.list</code>, or <code>light.edsurvey.data.frame</code></p>
</td></tr>
<tr><td><code id="summary2_+3A_variable">variable</code></td>
<td>
<p>character vector of variable names</p>
</td></tr>
<tr><td><code id="summary2_+3A_weightvar">weightVar</code></td>
<td>
<p>character weight variable name. Default is the default weight of <code>data</code> if it exists.
If the given survey data do not have a default weight,
the function will produce unweighted statistics instead.
Can be set to <code>NULL</code> to return unweighted statistics.</p>
</td></tr>
<tr><td><code id="summary2_+3A_dropomittedlevels">dropOmittedLevels</code></td>
<td>
<p>a logical value. When set to <code>TRUE</code>, drops those levels of the specified <code>variable</code>.
Use print on an <code>edsurvey.data.frame</code> to see the omitted levels. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summary2_+3A_omittedlevels">omittedLevels</code></td>
<td>
<p>this argument is deprecated. Use <code>dropOmittedLevels</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>summary of weighted or unweighted statistics of a given variable in an <code>edsurvey.data.frame</code>
</p>
<p>For categorical variables, the summary results are a crosstab of all variables and include the following:
</p>
<table>
<tr><td><code>[variable name]</code></td>
<td>
<p>level of the variable in the column name that the row regards. There is one column per element of <code>variable</code>.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>number of cases for each category. Weighted N also is produced if users choose to produce weighted statistics.</p>
</td></tr>
<tr><td><code>Percent</code></td>
<td>
<p>percentage of each category. Weighted percent also is produced if users choose to produce weighted statistics.</p>
</td></tr>
<tr><td><code>SE</code></td>
<td>
<p>standard error of the percentage statistics</p>
</td></tr>
</table>
<p>For continuous variables, the summary results are by variable and include the following:
</p>
<table>
<tr><td><code>Variable</code></td>
<td>
<p>name of the variable the row regards</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>total number of cases (both valid and invalid cases)</p>
</td></tr>
<tr><td><code>Min.</code></td>
<td>
<p>smallest value of the variable</p>
</td></tr>
<tr><td><code>1st Qu.</code></td>
<td>
<p>first quantile of the variable</p>
</td></tr>
<tr><td><code>Median</code></td>
<td>
<p>median value of the variable</p>
</td></tr>
<tr><td><code>Mean</code></td>
<td>
<p>mean of the variable</p>
</td></tr>
<tr><td><code>3rd Qu.</code></td>
<td>
<p>third quantile of the variable</p>
</td></tr>
<tr><td><code>Max.</code></td>
<td>
<p>largest value of the variable</p>
</td></tr>
<tr><td><code>SD</code></td>
<td>
<p>standard deviation or weighted standard deviation</p>
</td></tr>
<tr><td><code>NA's</code></td>
<td>
<p>number of <code>NA</code> in variable and in weight variables</p>
</td></tr>
<tr><td><code>Zero weights</code></td>
<td>
<p>number of zero weight cases if users choose to produce weighted statistics</p>
</td></tr>
</table>
<p>If the weight option is chosen, the function produces weighted percentile and standard deviation. Refer to the vignette titled
<em><a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf">Statistical Methods Used in EdSurvey</a></em> and
the vignette titled
<em><a href="https://www.air.org/sites/default/files/EdSurvey-Percentiles.pdf">Methods Used for Estimating Percentiles in EdSurvey</a></em>
for how the function calculates these statistics (with and without plausible values).
</p>


<h3>Author(s)</h3>

<p>Paul Bailey and Trang Nguyen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+percentile">percentile</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# print out summary of weighted statistics of a continuous variable
summary2(sdf, "composite")
# print out summary of weighted statistics of a variable, including omitted levels
summary2(sdf, "b017451", omittedLevels = FALSE)
# make a crosstab
summary2(sdf, c("b017451", "dsex"), omittedLevels = FALSE)

# print out summary of unweighted statistics of a variable
summary2(sdf, "composite", weightVar = NULL)

## End(Not run)
</code></pre>

<hr>
<h2 id='UnclassCols'>remove non-standard classes from data frame columns</h2><span id='topic+UnclassCols'></span>

<h3>Description</h3>

<p>removes the haven defined column classes from a returned tibble
needed for issues revolving around &lsquo;user_na=TRUE' argument of haven &rsquo;read_sav' method parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UnclassCols(tbl)
</code></pre>

<hr>
<h2 id='updatePlausibleValue'>Update Plausible Value Variable Names</h2><span id='topic+updatePlausibleValue'></span>

<h3>Description</h3>

<p>Changes the name used to refer to a set of plausible values from <code>oldVar</code> to <code>newVar</code> in an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or an <code>edsurvey.data.frame.list</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updatePlausibleValue(oldVar, newVar, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="updatePlausibleValue_+3A_oldvar">oldVar</code></td>
<td>
<p>a character value indicating the existing name of the variable</p>
</td></tr>
<tr><td><code id="updatePlausibleValue_+3A_newvar">newVar</code></td>
<td>
<p>a character value indicating the new name of the variable</p>
</td></tr>
<tr><td><code id="updatePlausibleValue_+3A_data">data</code></td>
<td>
<p>an <code>edsurvey.data.frame</code>, a <code>light.edsurvey.data.frame</code>, or
an <code>edsurvey.data.frame.list</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of the same class as the <code>data</code> argument, with the name of
the plausible value updated from <code>oldVar</code> to <code>newVar</code>
</p>


<h3>Author(s)</h3>

<p>Michael Lee and Paul Bailey
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getPlausibleValue">getPlausibleValue</a></code> and <code><a href="#topic+showPlausibleValues">showPlausibleValues</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))

# get the PVs before
showPlausibleValues(sdf)
sdf2 &lt;- updatePlausibleValue("composite", "overall", sdf)
showPlausibleValues(sdf2)
lm1 &lt;- lm.sdf(overall ~ b017451, data=sdf2)
summary(lm1)

## End(Not run)
</code></pre>

<hr>
<h2 id='varEstToCov'>Covariance Estimation</h2><span id='topic+varEstToCov'></span>

<h3>Description</h3>

<p>When the variance of a derived statistic (e.g., a difference) is
required, the covariance between the two statistics must be
calculated. This function uses results generated by various
functions (e.g., a <code><a href="#topic+lm.sdf">lm.sdf</a></code>) to find the covariance
between two statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varEstToCov(
  varEstA,
  varEstB = varEstA,
  varA,
  varB = varA,
  jkSumMultiplier,
  returnComponents = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varEstToCov_+3A_varesta">varEstA</code></td>
<td>
<p>a list of two <code>data.frame</code>s returned by a function after
the <code>returnVarEstInputs</code> argument was turned on.
The statistic named in the <code>varA</code> argument must be
present in each <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="varEstToCov_+3A_varestb">varEstB</code></td>
<td>
<p>a list of two <code>data.frame</code>s returned by a function after
the <code>returnVarEstInputs</code> argument was turned on.
The statistic named in the <code>varA</code> argument must be
present in each <code>data.frame</code>. When the same as
<code>varEstA</code>, the covariance is within one result.</p>
</td></tr>
<tr><td><code id="varEstToCov_+3A_vara">varA</code></td>
<td>
<p>a character that names the statistic in the <code>varEstA</code>
argument for which a covariance is required</p>
</td></tr>
<tr><td><code id="varEstToCov_+3A_varb">varB</code></td>
<td>
<p>a character that names the statistic in the <code>varEstB</code>
argument for which a covariance is required</p>
</td></tr>
<tr><td><code id="varEstToCov_+3A_jksummultiplier">jkSumMultiplier</code></td>
<td>
<p>when the jackknife variance estimation method&mdash;or
balanced repeated replication (BRR)
method&mdash;multiplies the final jackknife variance estimate by a value,
set <code>jkSumMultiplier</code> to that value.
For an <code>edsurvey.data.frame</code> or
a <code>light.edsurvey.data.frame</code>,
the recommended value can be recovered with
<code>EdSurvey::getAttributes(</code><code>myData,</code> <code>"jkSumMultiplier")</code>.</p>
</td></tr>
<tr><td><code id="varEstToCov_+3A_returncomponents">returnComponents</code></td>
<td>
<p>set to <code>TRUE</code> to return the imputation variance seperate from the sampling variance</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are not vectorized, so <code>varA</code> and
<code>varB</code> must contain exactly one variable name.
</p>
<p>The method used to compute the covariance is in
the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
</p>
<p>The method used to compute the degrees of freedom is in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-Statistics.pdf"><em>Statistical Methods Used in EdSurvey</em></a>
in the section &ldquo;Estimation of Degrees of Freedom.&rdquo;
</p>


<h3>Value</h3>

<p>a numeric value; the jackknife covariance estimate. If <code>returnComponents</code> is <code>TRUE</code>, returns a vector of
length three, <code>V</code> is the variance estimate, <code>Vsamp</code> is the sampling component of the variance, and <code>Vimp</code> is the imputation component of the variance
</p>


<h3>Author(s)</h3>

<p>Paul Bailey
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# estimate a regression
lm1 &lt;- lm.sdf(composite ~ dsex + b017451, sdf, returnVarEstInputs=TRUE)
summary(lm1)
# estimate the covariance between two regression coefficients
# note that the variable names are parallel to what they are called in lm1 output
covFEveryDay &lt;- varEstToCov(lm1$varEstInputs,
                            varA="dsexFemale",
                            varB="b017451Every day",
                            jkSumMultiplier=EdSurvey:::getAttributes(sdf, "jkSumMultiplier"))
# the estimated difference between the two coefficients
# note: unname prevents output from being named after the first coefficient
unname(coef(lm1)["dsexFemale"] - coef(lm1)["b017451Every day"])
# the standard error of the difference
# uses the formula SE(A-B) = sqrt(var(A) + var(B) - 2*cov(A,B))
sqrt(lm1$coefmat["dsexFemale", "se"]^2
     + lm1$coefmat["b017451Every day", "se"]^2
     - 2 * covFEveryDay)

## End(Not run)
</code></pre>

<hr>
<h2 id='viewNHES_SurveyCodes'>View NHES Survey Code Definitions</h2><span id='topic+viewNHES_SurveyCodes'></span>

<h3>Description</h3>

<p>This function prints the defined NHES Survey Codes to console output that are compatible with the <code>readNHES</code> function for use.
Typically a user will only need to manually set these codes if the 'auto' survey parameter is not able to correctly identify the
correct survey type, or for other unusual situations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>viewNHES_SurveyCodes()
</code></pre>


<h3>Author(s)</h3>

<p>Tom Fink
</p>


<h3>See Also</h3>

<p><code>readNHES</code>, <code>getNHES_SurveyInfo</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  #print the NHES survey information to the console for quick reference
  viewNHES_SurveyCodes()

## End(Not run)
</code></pre>

<hr>
<h2 id='waldTest'>Wald Tests</h2><span id='topic+waldTest'></span>

<h3>Description</h3>

<p>Tests on coefficient(s) of <code>edsurveyGlm</code>
and <code>edsurveyLm</code> models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>waldTest(model, coefficients, H0 = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="waldTest_+3A_model">model</code></td>
<td>
<p>an <code>edsurveyGlm</code> and <code>edsurveyLm</code></p>
</td></tr>
<tr><td><code id="waldTest_+3A_coefficients">coefficients</code></td>
<td>
<p>coefficients to be tested, by name or position in
<code>coef</code> vector. See Details.</p>
</td></tr>
<tr><td><code id="waldTest_+3A_h0">H0</code></td>
<td>
<p>reference values to test coefficients against, default = 0</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When plausible values are present, likelihood ratio tests cannot be used.
However, the Wald test can be used to test estimated parameters in a model,
with the null hypothesis being that a parameter(s) is equal to some value(s).
In the default case where the null hypothesis value of the parameters is 0,
if the test fails to reject the null hypothesis, removing the variables from
the model will not substantially harm the fit of that model. Alternative null
hypothesis values also can be specified with the <code>H0</code> argument.
See Examples.
</p>
<p>Coefficients to test can be specified by an integer (or integer vector)
corresponding to the order of coefficients in the summary output. Coefficients
also can be specified using a character vector, to specify coefficient names
to test. The name of a factor variable can be used to test all levels of that
variable.
</p>
<p>This test produces both chi-square and <em>F</em>-tests; their calculation is described
in the vignette titled
<a href="https://www.air.org/sites/default/files/EdSurvey-WaldTest.pdf"><em>Methods and Overview of Using EdSurvey for Running Wald Tests</em></a>.
</p>


<h3>Value</h3>

<p>An <code>edsurveyWaldTest</code> object with the following elements:
</p>
<table>
<tr><td><code>Sigma</code></td>
<td>
<p>coefficient covariance matrix</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>indices of the coefficients tested</p>
</td></tr>
<tr><td><code>H0</code></td>
<td>
<p>null hypothesis values of coefficients tested</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result object containing the values of the chi-square and <em>F</em>-tests</p>
</td></tr>
<tr><td><code>hypoMatrix</code></td>
<td>
<p>hypothesis matrix used for the Wald Test</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alex Lishinski and Paul Bailey
</p>


<h3>References</h3>

<p>Diggle, P. J., Liang, K.-Y., &amp; Zeger, S. L. (1994). <em>Analysis of longitudinal data</em>. Oxford, UK: Clarendon Press.
</p>
<p>Draper, N. R., &amp; Smith, H. (1998). <em>Applied regression analysis</em>. New York, NY: Wiley.
</p>
<p>Fox, J. (1997). <em>Applied regression analysis, linear models, and related methods</em>. Thousand Oaks, CA: SAGE.
</p>
<p>[Institute for Digital Research and Education. (n.d.). FAQ: How are the likelihood ratio, Wald, and LaGrange multiplier (score) tests different and/or similar?](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-are-the-likelihood-ratio-wald-and-lagrange-multiplier-score-tests-different-andor-similar/). Los Angeles: University of California at Los Angeles. Retrieved from [https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-are-the-likelihood-ratio-wald-and-lagrange-multiplier-score-tests-different-andor-similar/](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-are-the-likelihood-ratio-wald-and-lagrange-multiplier-score-tests-different-andor-similar/)
</p>
<p>Korn, E., &amp; Graubard, B. (1990). Simultaneous testing of regression coefficients with complex survey data: Use of Bonferroni t statistics. <em>The American Statistician</em>, <em>44</em>(4), 270&ndash;276.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# read in the example data (generated, not real student data)
sdf &lt;- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package = "NAEPprimer"))

# example with glm model
myLogit &lt;- logit.sdf(dsex ~ b017451 + b003501, data = sdf, returnVarEstInputs = T)

# single coefficient integer
waldTest(model = myLogit, coefficients = 2)

# set of coefficients integer vector
waldTest(model = myLogit, coefficients = 2:5)

# specify levels of factor variable to test
waldTest(myLogit, c("b017451Every day", "b017451About once a week"))

# specify all levels of factor variable to test
waldTest(myLogit, "b017451")

# example with lm model
fit &lt;- lm.sdf(composite ~ dsex + b017451, data = sdf, returnVarEstInputs = T)

waldTest(model = fit, coefficients = "b017451")

# examples with alternative (nonzero) null hypothesis values
waldTest(model = myLogit, coefficients = 2, H0 = 0.5)

waldTest(model = myLogit, coefficients = 2:5, H0 = c(0.5, 0.6, 0.7, 0.8))

waldTest(model = myLogit, coefficients = "b017451", H0 = c(0.5, 0.6, 0.7, 0.8))

waldTest(model = myLogit, coefficients = c("b017451Every day", "b017451About once a week"),
         H0 = c(0.1, 0.2))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
