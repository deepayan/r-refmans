<!DOCTYPE html><html><head><title>Help for package tfNeuralODE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tfNeuralODE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#backward'><p>Backward pass of the Neural ODE</p></a></li>
<li><a href='#backward_dynamics'><p>Internal function to solve the backwards dynamics of the Neural ODE</p></a></li>
<li><a href='#euler_step'><p>A function to employ the Euler Method to solve an ODE.</p></a></li>
<li><a href='#euler_update'><p>A Euler method state updater.</p></a></li>
<li><a href='#forward'><p>Forward pass of the Neural ODE network</p></a></li>
<li><a href='#rk4_step'><p>Runge Kutta solver for ordinary differential equations</p></a></li>
<li><a href='#rk4_step_backwards'><p>Custom internal RK4 solver for solving the backward pass of the Neural ODE.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Create Neural Ordinary Differential Equations with 'tensorflow'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Shayaan Emran &lt;shayaan.emran@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a framework for the creation and use of Neural ordinary
    differential equations with the 'tensorflow' and 'keras' packages. 
    The idea of Neural ordinary differential equations comes from 
    Chen et al. (2018) &lt;<a href="https://doi.org/10.48550%2FarXiv.1806.07366">doi:10.48550/arXiv.1806.07366</a>&gt;, and 
    presents a novel way of learning and solving differential systems. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>tensorflow, keras, reticulate, deSolve</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/semran9/tfNeuralODE">https://github.com/semran9/tfNeuralODE</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/semran9/tfNeuralODE/issues">https://github.com/semran9/tfNeuralODE/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-15 19:28:58 UTC; shayaanemran</td>
</tr>
<tr>
<td>Author:</td>
<td>Shayaan Emran [aut, cre, cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-16 17:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='backward'>Backward pass of the Neural ODE</h2><span id='topic+backward'></span>

<h3>Description</h3>

<p>Backward pass of the Neural ODE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backward(model, tsteps, outputs, output_gradients = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backward_+3A_model">model</code></td>
<td>
<p>A keras neural network that defines the Neural ODE.</p>
</td></tr>
<tr><td><code id="backward_+3A_tsteps">tsteps</code></td>
<td>
<p>A vector of each time step upon which the Neural ODE is solved to get to the final solution.</p>
</td></tr>
<tr><td><code id="backward_+3A_outputs">outputs</code></td>
<td>
<p>The tensor outputs of the forward pass of the Neural ODE.</p>
</td></tr>
<tr><td><code id="backward_+3A_output_gradients">output_gradients</code></td>
<td>
<p>The tensor gradients of the loss function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The model input at the last time step.
</p>
<p>The gradient of loss with respect to the inputs for use with the Adjoint Method.
</p>
<p>The gradients of loss the neural ODE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
reticulate::py_module_available("tensorflow")

# example code
# single training example
OdeModel(keras$Model) %py_class% {
 initialize &lt;- function() {
   super$initialize()
   self$block_1 &lt;- layer_dense(units = 50, activation = 'tanh')
   self$block_2 &lt;- layer_dense(units = 2, activation = 'linear')
 }

 call &lt;- function(inputs) {
   x&lt;- inputs ^ 3
   x &lt;- self$block_1(x)
   self$block_2(x)
 }
}
tsteps &lt;- seq(0, 2.5, by = 2.5/10)
true_y0 = t(c(2., 0.))
model&lt;- OdeModel()
optimizer = tf$keras$optimizers$legacy$Adam(learning_rate = 1e-3)
# single training iteration
pred = forward(model, true_y0, tsteps)
with(tf$GradientTape() %as% tape, {
  tape$watch(pred)
  loss = tf$reduce_mean(tf$abs(pred - inp[[2]]))
})
dLoss = tape$gradient(loss, pred)
list_w = backward(model, tsteps[1:batch_time], pred, output_gradients = dLoss)
optimizer$apply_gradients(zip_lists(list_w[[3]], model$trainable_variables))

</code></pre>

<hr>
<h2 id='backward_dynamics'>Internal function to solve the backwards dynamics of the Neural ODE</h2><span id='topic+backward_dynamics'></span>

<h3>Description</h3>

<p>Internal function to solve the backwards dynamics of the Neural ODE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backward_dynamics(state, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backward_dynamics_+3A_state">state</code></td>
<td>
<p>The current state of the differential equation</p>
</td></tr>
<tr><td><code id="backward_dynamics_+3A_model">model</code></td>
<td>
<p>The neural network that defines the Neural ODE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of the number 1, the new backwards state of the differential equation and the gradients calculated for the network.
</p>

<hr>
<h2 id='euler_step'>A function to employ the Euler Method to solve an ODE.</h2><span id='topic+euler_step'></span>

<h3>Description</h3>

<p>A function to employ the Euler Method to solve an ODE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euler_step(func, dt, state)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euler_step_+3A_func">func</code></td>
<td>
<p>The derivative function.</p>
</td></tr>
<tr><td><code id="euler_step_+3A_dt">dt</code></td>
<td>
<p>The time step for the Euler solver.</p>
</td></tr>
<tr><td><code id="euler_step_+3A_state">state</code></td>
<td>
<p>A list that defines the current state of the ODE, with one entry
being a number, and the other being a tensor which describes the function state.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list that describes the updated state of the ODE.
</p>

<hr>
<h2 id='euler_update'>A Euler method state updater.</h2><span id='topic+euler_update'></span>

<h3>Description</h3>

<p>A Euler method state updater.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euler_update(h_list, dh_list, dt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euler_update_+3A_h_list">h_list</code></td>
<td>
<p>The initial state of the ODE.</p>
</td></tr>
<tr><td><code id="euler_update_+3A_dh_list">dh_list</code></td>
<td>
<p>description</p>
</td></tr>
<tr><td><code id="euler_update_+3A_dt">dt</code></td>
<td>
<p>The time step to update the initial state with.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated state of the ODE.
</p>

<hr>
<h2 id='forward'>Forward pass of the Neural ODE network</h2><span id='topic+forward'></span>

<h3>Description</h3>

<p>Forward pass of the Neural ODE network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward(model, inputs, tsteps, return_states = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_+3A_model">model</code></td>
<td>
<p>A keras neural network that defines the Neural ODE.</p>
</td></tr>
<tr><td><code id="forward_+3A_inputs">inputs</code></td>
<td>
<p>Matrix or vector inputs to the neural network.</p>
</td></tr>
<tr><td><code id="forward_+3A_tsteps">tsteps</code></td>
<td>
<p>A vector of each time step upon which the Neural ODE is solved to get to the final solution.</p>
</td></tr>
<tr><td><code id="forward_+3A_return_states">return_states</code></td>
<td>
<p>A boolean which dictates whether the intermediary states between the input and the final solution are returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>solution of the forward pass of Neural ODE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
reticulate::py_module_available("tensorflow")

# example code

library(tensorflow)
library(keras)

OdeModel(keras$Model) %py_class% {
 initialize &lt;- function() {
   super$initialize()
   self$block_1 &lt;- layer_dense(units = 50, activation = 'tanh')
   self$block_2 &lt;- layer_dense(units = 2, activation = 'linear')
 }

 call &lt;- function(inputs) {
   x&lt;- inputs ^ 3
   x &lt;- self$block_1(x)
   self$block_2(x)
 }
}
tsteps &lt;- seq(0, 2.5, by = 2.5/10)
true_y0 = t(c(2., 0.))
model&lt;- OdeModel()
forward(model, true_y0, tsteps)


</code></pre>

<hr>
<h2 id='rk4_step'>Runge Kutta solver for ordinary differential equations</h2><span id='topic+rk4_step'></span>

<h3>Description</h3>

<p>Runge Kutta solver for ordinary differential equations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rk4_step(func, dt, state)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rk4_step_+3A_func">func</code></td>
<td>
<p>The function to be numerically integrated.</p>
</td></tr>
<tr><td><code id="rk4_step_+3A_dt">dt</code></td>
<td>
<p>Time step.</p>
</td></tr>
<tr><td><code id="rk4_step_+3A_state">state</code></td>
<td>
<p>A list describing the state of the function, with the first element
being 1, and the second being a tensor that represents state</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a new time and the numerical integration of of the
function across the time step to the new time.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
reticulate::py_module_available("tensorflow")
# example code
library(tensorflow)
ode_fun&lt;- function(u){
  r = u ^ 3
  true_A = rbind(c(-0.1, 2.0), c(-2.0, -0.1))
  du &lt;- r %*% (true_A)
  return(as.matrix(du))
}
y&lt;- tensorflow::tf$cast(t(as.matrix(c(2, 0))), dtype = tf$float32)
x&lt;- rk4_step(ode_fun,  dt = 0.25,
            state = list(1.0, y))
x

</code></pre>

<hr>
<h2 id='rk4_step_backwards'>Custom internal RK4 solver for solving the backward pass of the Neural ODE.</h2><span id='topic+rk4_step_backwards'></span>

<h3>Description</h3>

<p>Custom internal RK4 solver for solving the backward pass of the Neural ODE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rk4_step_backwards(backward_dynamics, dt, state, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rk4_step_backwards_+3A_backward_dynamics">backward_dynamics</code></td>
<td>
<p>The backward dynamics function for the Neural ODE.</p>
</td></tr>
<tr><td><code id="rk4_step_backwards_+3A_dt">dt</code></td>
<td>
<p>The time step to solve the ODE on.</p>
</td></tr>
<tr><td><code id="rk4_step_backwards_+3A_state">state</code></td>
<td>
<p>The current state of the differential equation.</p>
</td></tr>
<tr><td><code id="rk4_step_backwards_+3A_model">model</code></td>
<td>
<p>The neural network that defines the Neural ODE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An output list with the updated backwards state.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
