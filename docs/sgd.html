<!DOCTYPE html><html><head><title>Help for package sgd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sgd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coef.sgd'><p>Extract Model Coefficients</p></a></li>
<li><a href='#fitted.sgd'><p>Extract Model Fitted Values</p></a></li>
<li><a href='#plot.sgd'><p>Plot objects of class <code>sgd</code>.</p></a></li>
<li><a href='#predict.sgd'><p>Model Predictions</p></a></li>
<li><a href='#print.sgd'><p>Print objects of class <code>sgd</code>.</p></a></li>
<li><a href='#residuals.sgd'><p>Extract Model Residuals</p></a></li>
<li><a href='#sgd'><p>Stochastic gradient descent</p></a></li>
<li><a href='#winequality'><p>Wine quality data of white wine samples from Portugal</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Stochastic Gradient Descent for Scalable Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Junhyung Lyle Kim &lt;jlylekim@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A fast and flexible set of tools for large scale estimation. It
    features many stochastic gradient methods, built-in models, visualization
    tools, automated hyperparameter tuning, model checking, interval estimation,
    and convergence diagnostics.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/airoldilab/sgd">https://github.com/airoldilab/sgd</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/airoldilab/sgd/issues">https://github.com/airoldilab/sgd/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, MASS, methods, Rcpp (&ge; 0.11.3), stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bigmemory, glmnet, gridExtra, R.rsp, testthat</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH, bigmemory, Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-31 13:09:36 UTC; jlylekim</td>
</tr>
<tr>
<td>Author:</td>
<td>Junhyung Lyle Kim [cre, aut],
  Dustin Tran [aut],
  Panos Toulis [aut],
  Tian Lian [ctb],
  Ye Kuang [ctb],
  Edoardo Airoldi [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-31 13:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='coef.sgd'>Extract Model Coefficients</h2><span id='topic+coef.sgd'></span>

<h3>Description</h3>

<p>Extract model coefficients from <code>sgd</code> objects. <code>coefficients</code>
is an <em>alias</em> for it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgd'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.sgd_+3A_object">object</code></td>
<td>
<p>object of class <code>sgd</code>.</p>
</td></tr>
<tr><td><code id="coef.sgd_+3A_...">...</code></td>
<td>
<p>some methods for this generic require additional
arguments. None are used in this method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Coefficients extracted from the model object <code>object</code>.
</p>

<hr>
<h2 id='fitted.sgd'>Extract Model Fitted Values</h2><span id='topic+fitted.sgd'></span>

<h3>Description</h3>

<p>Extract fitted values from from <code>sgd</code> objects.
<code>fitted.values</code> is an <em>alias</em> for it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgd'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.sgd_+3A_object">object</code></td>
<td>
<p>object of class <code>sgd</code>.</p>
</td></tr>
<tr><td><code id="fitted.sgd_+3A_...">...</code></td>
<td>
<p>some methods for this generic require additional
arguments. None are used in this method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Fitted values extracted from the object <code>object</code>.
</p>

<hr>
<h2 id='plot.sgd'>Plot objects of class <code>sgd</code>.</h2><span id='topic+plot.sgd'></span><span id='topic+plot.list'></span>

<h3>Description</h3>

<p>Plot objects of class <code>sgd</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgd'
plot(x, ..., type = "mse", xaxis = "iteration")

## S3 method for class 'list'
plot(x, ..., type = "mse", xaxis = "iteration")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sgd_+3A_x">x</code></td>
<td>
<p>object of class <code>sgd</code>.</p>
</td></tr>
<tr><td><code id="plot.sgd_+3A_...">...</code></td>
<td>
<p>additional arguments used for each type of plot. See
&lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="plot.sgd_+3A_type">type</code></td>
<td>
<p>character specifying the type of plot: <code>"mse"</code>,
<code>"clf"</code>, <code>"mse-param"</code>. See &lsquo;Details&rsquo;. Default is
<code>"mse"</code>.</p>
</td></tr>
<tr><td><code id="plot.sgd_+3A_xaxis">xaxis</code></td>
<td>
<p>character specifying the x-axis of plot: <code>"iteration"</code>
plots the y values over the log-iteration of the algorithm;
<code>"runtime"</code> plots the y values over the time in seconds to reach them.
Default is <code>"iteration"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Types of plots available:
</p>

<dl>
<dt><code>mse</code></dt><dd><p>Mean squared error in predictions, which takes the
following arguments:
</p>

<dl>
<dt><code>x_test</code></dt><dd><p>test set</p>
</dd>
<dt><code>y_test</code></dt><dd><p>test responses to compare predictions to</p>
</dd>
</dl>
</dd>
<dt><code>clf</code></dt><dd><p>Classification error in predictions, which takes the
following arguments:
</p>

<dl>
<dt><code>x_test</code></dt><dd><p>test set</p>
</dd>
<dt><code>y_test</code></dt><dd><p>test responses to compare predictions to</p>
</dd>
</dl>
</dd>
<dt><code>mse-param</code></dt><dd><p>Mean squared error in parameters, which takes the
following arguments:
</p>

<dl>
<dt><code>true_param</code></dt><dd><p>true vector of parameters to compare to</p>
</dd>
</dl>
</dd>
</dl>


<hr>
<h2 id='predict.sgd'>Model Predictions</h2><span id='topic+predict.sgd'></span><span id='topic+predict_all'></span>

<h3>Description</h3>

<p>Form predictions using the estimated model parameters from stochastic
gradient descent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgd'
predict(object, newdata, type = "link", ...)

predict_all(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.sgd_+3A_object">object</code></td>
<td>
<p>object of class <code>sgd</code>.</p>
</td></tr>
<tr><td><code id="predict.sgd_+3A_newdata">newdata</code></td>
<td>
<p>design matrix to form predictions on</p>
</td></tr>
<tr><td><code id="predict.sgd_+3A_type">type</code></td>
<td>
<p>the type of prediction required. The default &quot;link&quot; is
on the scale of the linear predictors; the alternative '&quot;response&quot;'
is on the scale of the response variable. Thus for a default
binomial model the default predictions are of log-odds
(probabilities on logit scale) and 'type = &quot;response&quot;' gives the
predicted probabilities. The '&quot;terms&quot;' option returns a matrix
giving the fitted values of each term in the model formula on the
linear predictor scale.</p>
</td></tr>
<tr><td><code id="predict.sgd_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A column of 1's must be included to <code>newdata</code> if the
parameters include a bias (intercept) term.
</p>

<hr>
<h2 id='print.sgd'>Print objects of class <code>sgd</code>.</h2><span id='topic+print.sgd'></span>

<h3>Description</h3>

<p>Print objects of class <code>sgd</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgd'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sgd_+3A_x">x</code></td>
<td>
<p>object of class <code>sgd</code>.</p>
</td></tr>
<tr><td><code id="print.sgd_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='residuals.sgd'>Extract Model Residuals</h2><span id='topic+residuals.sgd'></span>

<h3>Description</h3>

<p>Extract model residuals from <code>sgd</code> objects. <code>resid</code> is an
<em>alias</em> for it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgd'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.sgd_+3A_object">object</code></td>
<td>
<p>object of class <code>sgd</code>.</p>
</td></tr>
<tr><td><code id="residuals.sgd_+3A_...">...</code></td>
<td>
<p>some methods for this generic require additional
arguments. None are used in this method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Residuals extracted from the object <code>object</code>.
</p>

<hr>
<h2 id='sgd'>Stochastic gradient descent</h2><span id='topic+sgd'></span><span id='topic+sgd.formula'></span><span id='topic+sgd.matrix'></span><span id='topic+sgd.big.matrix'></span>

<h3>Description</h3>

<p>Run stochastic gradient descent in order to optimize the induced loss
function given a model and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sgd(x, ...)

## S3 method for class 'formula'
sgd(formula, data, model, model.control = list(), sgd.control = list(...), ...)

## S3 method for class 'matrix'
sgd(x, y, model, model.control = list(), sgd.control = list(...), ...)

## S3 method for class 'big.matrix'
sgd(x, y, model, model.control = list(), sgd.control = list(...), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sgd_+3A_x">x</code>, <code id="sgd_+3A_y">y</code></td>
<td>
<p>a design matrix and the respective vector of outcomes.</p>
</td></tr>
<tr><td><code id="sgd_+3A_...">...</code></td>
<td>
<p>arguments to be used to form the default <code>sgd.control</code>
arguments if it is not supplied directly.</p>
</td></tr>
<tr><td><code id="sgd_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that can be
coerced to that class): a symbolic description of the model to be fitted.
The details can be found in <code>"<a href="stats.html#topic+glm">glm</a>"</code>.</p>
</td></tr>
<tr><td><code id="sgd_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object coercible
by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing the
variables in the model. If not found in data, the variables are taken from
environment(formula), typically the environment from which glm is called.</p>
</td></tr>
<tr><td><code id="sgd_+3A_model">model</code></td>
<td>
<p>character specifying the model to be used: <code>"lm"</code> (linear
model), <code>"glm"</code> (generalized linear model), <code>"cox"</code> (Cox
proportional hazards model), <code>"gmm"</code> (generalized method of moments),
<code>"m"</code> (M-estimation). See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="sgd_+3A_model.control">model.control</code></td>
<td>
<p>a list of parameters for controlling the model.
</p>

<dl>
<dt><code>family</code> (<code>"glm"</code>)</dt><dd><p>a description of the error distribution and
link function to be used in the model. This can be a character string
naming a family function, a family function or the result of a call to
a family function. (See <code><a href="stats.html#topic+family">family</a></code> for details of
family functions.)</p>
</dd>
<dt><code>rank</code> (<code>"glm"</code>)</dt><dd><p>logical. Should the rank of the design matrix
be checked?</p>
</dd>
<dt><code>fn</code> (<code>"gmm"</code>)</dt><dd><p>a function <code class="reqn">g(\theta,x)</code> which returns a
<code class="reqn">k</code>-vector corresponding to the <code class="reqn">k</code> moment conditions. It is a
required argument if <code>gr</code> not specified.</p>
</dd>
<dt><code>gr</code> (<code>"gmm"</code>)</dt><dd><p>a function to return the gradient. If
unspecified, a finite-difference approximation will be used.</p>
</dd>
<dt><code>nparams</code> (<code>"gmm"</code>)</dt><dd><p>number of model parameters. This is
automatically determined for other models.</p>
</dd>
<dt><code>type</code> (<code>"gmm"</code>)</dt><dd><p>character specifying the generalized method of
moments procedure: <code>"twostep"</code> (Hansen, 1982), <code>"iterative"</code>
(Hansen et al., 1996). Defaults to <code>"iterative"</code>.</p>
</dd>
<dt><code>wmatrix</code> (<code>"gmm"</code>)</dt><dd><p>weighting matrix to be used in the loss
function. Defaults to the identity matrix.</p>
</dd>
<dt><code>loss</code> (<code>"m"</code>)</dt><dd><p>character specifying the loss function to be
used in the estimating equation. Default is the Huber loss.</p>
</dd>
<dt><code>lambda1</code></dt><dd><p>L1 regularization parameter. Default is 0.</p>
</dd>
<dt><code>lambda2</code></dt><dd><p>L2 regularization parameter. Default is 0.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="sgd_+3A_sgd.control">sgd.control</code></td>
<td>
<p>an optional list of parameters for controlling the estimation.
</p>

<dl>
<dt><code>method</code></dt><dd><p>character specifying the method to be used: <code>"sgd"</code>,
<code>"implicit"</code>, <code>"asgd"</code>, <code>"ai-sgd"</code>, <code>"momentum"</code>,
<code>"nesterov"</code>. Default is <code>"ai-sgd"</code>. See &lsquo;Details&rsquo;.</p>
</dd>
<dt><code>lr</code></dt><dd><p>character specifying the learning rate to be used:
<code>"one-dim"</code>, <code>"one-dim-eigen"</code>, <code>"d-dim"</code>,
<code>"adagrad"</code>, <code>"rmsprop"</code>. Default is <code>"one-dim"</code>.
See &lsquo;Details&rsquo;.</p>
</dd>
<dt><code>lr.control</code></dt><dd><p>vector of scalar hyperparameters one can
set dependent on the learning rate. For hyperparameters aimed
to be left as default, specify <code>NA</code> in the corresponding
entries. See &lsquo;Details&rsquo;.</p>
</dd>
<dt><code>start</code></dt><dd><p>starting values for the parameter estimates. Default is
random initialization around zero.</p>
</dd>
<dt><code>size</code></dt><dd><p>number of SGD estimates to store for diagnostic purposes
(distributed log-uniformly over total number of iterations)</p>
</dd>
<dt><code>reltol</code></dt><dd><p>relative convergence tolerance. The algorithm stops
if it is unable to change the relative mean squared difference in the
parameters by more than the amount. Default is <code>1e-05</code>.</p>
</dd>
<dt><code>npasses</code></dt><dd><p>the maximum number of passes over the data. Default
is 3.</p>
</dd>
<dt><code>pass</code></dt><dd><p>logical. Should <code>tol</code> be ignored and run the
algorithm for all of <code>npasses</code>?</p>
</dd>
<dt><code>shuffle</code></dt><dd><p>logical. Should the algorithm shuffle the data set
including for each pass?</p>
</dd>
<dt><code>verbose</code></dt><dd><p>logical. Should the algorithm print progress?</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>Models:
The Cox model assumes that the survival data is ordered when passed
in, i.e., such that the risk set of an observation i is all data points after
it.
</p>
<p>Methods:
</p>

<dl>
<dt><code>sgd</code></dt><dd><p>stochastic gradient descent (Robbins and Monro, 1951)</p>
</dd>
<dt><code>implicit</code></dt><dd><p>implicit stochastic gradient descent (Toulis et al.,
2014)</p>
</dd>
<dt><code>asgd</code></dt><dd><p>stochastic gradient with averaging (Polyak and Juditsky,
1992)</p>
</dd>
<dt><code>ai-sgd</code></dt><dd><p>implicit stochastic gradient with averaging (Toulis et
al., 2015)</p>
</dd>
<dt><code>momentum</code></dt><dd><p>&quot;classical&quot; momentum (Polyak, 1964)</p>
</dd>
<dt><code>nesterov</code></dt><dd><p>Nesterov's accelerated gradient (Nesterov, 1983)</p>
</dd>
</dl>

<p>Learning rates and hyperparameters:
</p>

<dl>
<dt><code>one-dim</code></dt><dd><p>scalar value prescribed in Xu (2011) as
</p>
<p style="text-align: center;"><code class="reqn">a_n = scale * gamma/(1 + alpha*gamma*n)^(-c)</code>
</p>

<p>where the defaults are
<code>lr.control = (scale=1, gamma=1, alpha=1, c)</code>
where <code>c</code> is <code>1</code> if implemented without averaging,
<code>2/3</code> if with averaging</p>
</dd>
<dt><code>one-dim-eigen</code></dt><dd><p>diagonal matrix
<code>lr.control = NULL</code></p>
</dd>
<dt><code>d-dim</code></dt><dd><p>diagonal matrix
<code>lr.control = (epsilon=1e-6)</code></p>
</dd>
<dt><code>adagrad</code></dt><dd><p>diagonal matrix prescribed in Duchi et al. (2011) as
<code>lr.control = (eta=1, epsilon=1e-6)</code></p>
</dd>
<dt><code>rmsprop</code></dt><dd><p>diagonal matrix prescribed in Tieleman and Hinton
(2012) as
<code>lr.control = (eta=1, gamma=0.9, epsilon=1e-6)</code></p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class <code>"sgd"</code>, which is a list containing the following
components:
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>name of the model</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a named vector of coefficients</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>logical. Was the algorithm judged to have converged?</p>
</td></tr>
<tr><td><code>estimates</code></td>
<td>
<p>estimates from algorithm stored at each iteration
specified in <code>pos</code></p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted mean values</p>
</td></tr>
<tr><td><code>pos</code></td>
<td>
<p>vector of indices specifying the iteration number each estimate
was stored for</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals, that is response minus fitted values</p>
</td></tr>
<tr><td><code>times</code></td>
<td>
<p>vector of times in seconds it took to complete the number of
iterations specified in <code>pos</code></p>
</td></tr>
<tr><td><code>model.out</code></td>
<td>
<p>a list of model-specific output attributes</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dustin Tran, Tian Lan, Panos Toulis, Ye Kuang, Edoardo Airoldi
</p>


<h3>References</h3>

<p>John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for
online learning and stochastic optimization. <em>Journal of Machine
Learning Research</em>, 12:2121-2159, 2011.
</p>
<p>Yurii Nesterov. A method for solving a convex programming problem with
convergence rate <code class="reqn">O(1/k^2)</code>. <em>Soviet Mathematics Doklady</em>,
27(2):372-376, 1983.
</p>
<p>Boris T. Polyak. Some methods of speeding up the convergence of iteration
methods. <em>USSR Computational Mathematics and Mathematical Physics</em>,
4(5):1-17, 1964.
</p>
<p>Boris T. Polyak and Anatoli B. Juditsky. Acceleration of stochastic
approximation by averaging. <em>SIAM Journal on Control and Optimization</em>,
30(4):838-855, 1992.
</p>
<p>Herbert Robbins and Sutton Monro. A stochastic approximation method.
<em>The Annals of Mathematical Statistics</em>, pp. 400-407, 1951.
</p>
<p>Panos Toulis, Jason Rennie, and Edoardo M. Airoldi, &quot;Statistical analysis of
stochastic gradient methods for generalized linear models&quot;, In
<em>Proceedings of the 31st International Conference on Machine Learning</em>,
2014.
</p>
<p>Panos Toulis, Dustin Tran, and Edoardo M. Airoldi, &quot;Stability and optimality
in stochastic gradient descent&quot;, arXiv preprint arXiv:1505.02417, 2015.
</p>
<p>Wei Xu. Towards optimal one pass large scale learning with averaged
stochastic gradient descent. arXiv preprint arXiv:1107.2490, 2011.
</p>
<p># Dimensions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Linear regression
set.seed(42)
N &lt;- 1e4
d &lt;- 5
X &lt;- matrix(rnorm(N*d), ncol=d)
theta &lt;- rep(5, d+1)
eps &lt;- rnorm(N)
y &lt;- cbind(1, X) %*% theta + eps
dat &lt;- data.frame(y=y, x=X)
sgd.theta &lt;- sgd(y ~ ., data=dat, model="lm")
sprintf("Mean squared error: %0.3f", mean((theta - as.numeric(sgd.theta$coefficients))^2))


</code></pre>

<hr>
<h2 id='winequality'>Wine quality data of white wine samples from Portugal</h2><span id='topic+winequality'></span>

<h3>Description</h3>

<p>This dataset is a collection of white &quot;Vinho Verde&quot; wine
samples from the north of Portugal. Due to privacy and logistic
issues, only physicochemical (inputs) and sensory (the output)
variables are available (e.g. there is no data about grape types,
wine brand, wine selling price, etc.).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>winequality
</code></pre>


<h3>Format</h3>

<p>A data frame with 4898 rows and 12 variables
</p>

<ul>
<li><p> fixed acidity.
</p>
</li>
<li><p> volatile acidity.
</p>
</li>
<li><p> citric acid.
</p>
</li>
<li><p> residual sugar.
</p>
</li>
<li><p> chlorides.
</p>
</li>
<li><p> free sulfur dioxide.
</p>
</li>
<li><p> total sulfur dioxide.
</p>
</li>
<li><p> density.
</p>
</li>
<li><p> pH.
</p>
</li>
<li><p> sulphates.
</p>
</li>
<li><p> alcohol.
</p>
</li>
<li><p> quality (score between 0 and 10).
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Wine+Quality">https://archive.ics.uci.edu/ml/datasets/Wine+Quality</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
