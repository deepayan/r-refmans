<!DOCTYPE html><html><head><title>Help for package mle.tools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mle.tools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mle.tools-package'><p>Overview of the &ldquo;mle.tools&rdquo; Package</p></a></li>
<li><a href='#coxsnell.bc'><p>Bias-Corrected Maximum Likelihood Estimate(s)</p></a></li>
<li><a href='#expected.varcov'><p>Expected Fisher Information</p></a></li>
<li><a href='#observed.varcov'><p>Observed Fisher Information</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Expected/Observed Fisher Information and Bias-Corrected Maximum
Likelihood Estimate(s)</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-02-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Josmar Mazucheli</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Josmar Mazucheli &lt;jmazucheli@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculates the expected/observed Fisher information and the bias-corrected maximum likelihood estimate(s) via Cox-Snell Methodology.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>fitdistrplus (&ge; 1.0-6)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-02-21 13:06:25 UTC; josmar</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-02-21 15:17:08</td>
</tr>
</table>
<hr>
<h2 id='mle.tools-package'>Overview of the &ldquo;mle.tools&rdquo; Package</h2><span id='topic+mle.tools-package'></span>

<h3>Description</h3>

<p>The current version of the <span class="pkg">mle.tools</span> package has implemented three functions which are of great interest in maximum likelihood estimation. These functions calculates the expected /observed Fisher information and the bias-corrected maximum likelihood estimate(s) using the bias formula introduced by Cox and Snell (1968). They can be applied to any probability density function whose terms are available in the derivatives table of <code>D</code> function (see &ldquo;deriv.c&rdquo; source code for further details). Integrals, when required, are computed numerically via <code>integrate</code> function. Below are some mathematical details of how the returned values are calculated.
</p>
<p>Let <code class="reqn">X_{1},\ldots ,X_{n}</code> be <em>i.i.d.</em> random variables with
probability density functions <code class="reqn">f(x_{i}\mid \bold{\theta })</code> depending on a <code class="reqn">p</code>-dimensional parameter vector <code class="reqn">\bold{\theta } = (\theta_1,\ldots,\theta_p)</code>. The <em>(j,k)-th</em> element of the observed, <code class="reqn">H_{jk}</code>, and expected, <code class="reqn">I_{jk}</code>, Fisher information are calculated, respectively,  as
</p>
<p style="text-align: center;"><code class="reqn">H_{jk} =\left. {-\sum\limits_{i=1}^{n}\frac{%
\partial ^{2}}{\partial \theta _{j}\partial \theta _{k}}\log f\left(
x_{i}\mid {\bold{\theta} }\right) }\right\vert _{\bold{\theta }=\widehat{\bold{%
\theta }}}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">I_{jk}=-n\times E\left( \frac{\partial ^{2}}{\partial \theta _{j}\partial
\theta _{k}}\log f\left( x\mid \bold{\theta }\right) \right) =\left. -n\times
\int\limits_{\mathcal{X} }\frac{\partial ^{2}}{\partial \theta _{j}\partial
\theta _{k}}\log f\left( x\mid \bold{\theta }\right) \times f\left(
x\mid \bold{\theta }\right) dx\right\vert _{\bold{\theta }=\widehat{\bold{%
\theta }}}</code>
</p>

<p>where <code class="reqn">(j,k=1,\ldots,p)</code>, <code class="reqn">\bold{\widehat{\theta}}</code> is the maximum likelihood estimate of <code class="reqn">\bold{\theta}</code> and <code class="reqn">\mathcal{X}</code> denotes the support of the random variable <code class="reqn">X</code>.
</p>
<p>The <code>observed.varcov</code> function returns the inputted maximum likelihood estimate(s) and the inverse of <code class="reqn">\bold{H}</code> while the <code>expected.varcov</code> function returns the inputted maximum likelihood estimate(s) and the inverse of <code class="reqn">\bold{I}</code>. If <code class="reqn">\bold{H}</code> and/or <code class="reqn">\bold{I}</code> are singular an error message is returned.
</p>
<p>Furthermore, the bias corrected maximum likelihood estimate of <code class="reqn">\theta_s</code>   (<code class="reqn">s=1,\ldots,p)</code>, denoted by <code class="reqn">\widetilde{\theta_s}</code>, is
calculated as <code class="reqn">\widetilde{\theta_s} = \widehat{\theta} - \widehat{Bias}(\widehat{\theta}_s)</code>, where <code class="reqn">\widehat{\theta}_s</code> is the maximum likelihood estimate of <code class="reqn">{\theta}_s</code> and
</p>
<p style="text-align: center;"><code class="reqn">{\widehat{Bias}\left( {\widehat{\theta }}_{s}\right) =}\left. {%
\sum\limits_{j=1}^{p}\sum\limits_{k=1}^{p}\sum\limits_{l=1}^{p}\kappa
^{sj}\kappa ^{kl}\left[ 0.5\kappa _{{jkl}}+\kappa _{{jk,l}}\right] }%
\right\vert _{\bold{\theta }=\widehat{\bold{\theta }}}</code>
</p>
<p> where <code class="reqn">\kappa ^{jk}</code> is the <em>(j,k)-th</em> element of the inverse of the expected Fisher information, <code class="reqn">{\kappa_{jkl}=} n\times E\left( \frac{\partial ^{3}}{\partial \theta _{j}\partial {{\theta}}_{k}{\theta }_{l}}\log f\left( x\mid \bold{\theta }\right) \right)</code> and
<code class="reqn">\kappa_{jk,l}= n \times E\left( \frac{\partial ^{2}}{\partial \theta _{j}\partial \theta_{k}}\log f\left( x\mid\bold{\theta }\right) \times \frac{\partial }{{\theta }_{l}}\log f\left( x\mid\bold{\theta }\right) \right) </code>.
</p>
<p>The bias-corrected maximum likelihood estimate(s) and some other quantities are calculated via <code>coxsnell.bc</code> function. If the numerical integration fails
and/or <code class="reqn">\bold{I}</code> is singular an error message is returned.
</p>
<p>It is noteworthy that for a series of probability distributions it is possible, after extensive algebra, to obtain the analytical expressions for <code class="reqn">Bias({\widehat{\theta}_s)}</code>. In Stosic and Cordeiro (2009) are the analytic expressions for 22 two-parameter continuous probability distributions. They also present the <em>Maple</em> and <em>Mathematica</em> scripts used to obtain all analytic expressions (see Cordeiro and Cribari-Neto 2014 for further details).
</p>


<h3>Author(s)</h3>

<p>Josmar Mazucheli <a href="mailto:jmazucheli@gmail.com">jmazucheli@gmail.com</a>
</p>


<h3>References</h3>

<p>Azzalini, A. (1996). <em>Statistical Inference: Based on the Likelihood</em>. London: Chapman and Hall.
</p>
<p>Cordeiro, G. M. and Cribari-Neto, F., (2014). An introduction to Bartlett correction and bias reduction. SpringerBriefs in Statistics, New-York.
</p>
<p>Cordeiro, G. M. and McCullagh, P., (1991). Bias correction in generalized linear models. <em>Journal of the Royal Statistical Society, Series B</em>, <b>53</b>, 3, 629&ndash;643.
</p>
<p>Cox, D. R. and Hinkley, D. V. (1974). <em>Theoretical Statistics</em>. London: Chapman and Hall.
</p>
<p>Cox, D. R. and Snell, E. J., (1968). A general definition of residuals (with discussion). <em>Journal of the Royal Statistical Society, Series B</em>, <b>30</b>, 2, 24&ndash;275.
</p>
<p>Efron, B. and Hinkley, D. V. (1978). Assessing the accuracy of the maximum likelihood estimator: Observed versus expected Fisher information. <em>Biometrika</em>, <b>65</b>, 3, 457&ndash;482.
</p>
<p>Pawitan, Y. (2001). <em>In All Likelihood: Statistical Modelling and Inference Using Likelihood</em>. Oxford: Oxford University Press.
</p>
<p>Stosic, B. D. and Cordeiro, G. M., (2009). Using Maple and Mathematica to derive bias corrections for two parameter distributions. <em>Journal of Statistical Computation and Simulation</em>, <b>79</b>, 6, 751&ndash;767.
</p>

<hr>
<h2 id='coxsnell.bc'>Bias-Corrected Maximum Likelihood Estimate(s)</h2><span id='topic+coxsnell.bc'></span>

<h3>Description</h3>

<p><code>coxsnell.bc</code> calculates the bias-corrected maximum likelihood estimate(s) using the bias formula introduced by Cox and Snell (1968).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coxsnell.bc(density, logdensity, n, parms, mle, lower = "-Inf",
  upper = "Inf", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coxsnell.bc_+3A_density">density</code></td>
<td>
<p>An expression with the probability density function.</p>
</td></tr>
<tr><td><code id="coxsnell.bc_+3A_logdensity">logdensity</code></td>
<td>
<p>An expression with the logarithm of the probability density function.</p>
</td></tr>
<tr><td><code id="coxsnell.bc_+3A_n">n</code></td>
<td>
<p>A numeric scalar with the sample size.</p>
</td></tr>
<tr><td><code id="coxsnell.bc_+3A_parms">parms</code></td>
<td>
<p>A character vector with the parameter name(s) specified in the density and logdensity expressions.</p>
</td></tr>
<tr><td><code id="coxsnell.bc_+3A_mle">mle</code></td>
<td>
<p>A numeric vector with the parameter estimate(s).</p>
</td></tr>
<tr><td><code id="coxsnell.bc_+3A_lower">lower</code></td>
<td>
<p>The lower integration limit (lower = &ldquo;-Inf&rdquo; is the default).</p>
</td></tr>
<tr><td><code id="coxsnell.bc_+3A_upper">upper</code></td>
<td>
<p>The upper integration limit (upper = &ldquo;Inf&rdquo; is the default).</p>
</td></tr>
<tr><td><code id="coxsnell.bc_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>integrate</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first, second and third-order partial log-density derivatives are analytically calculated via <code>D</code> function. The expected values of the partial log-density derivatives are calculated via <code>integrate</code> function.
</p>


<h3>Value</h3>

<p><code>coxsnell.bc</code> returns a list with five components (i) <b>mle</b>: the inputted maximum likelihood estimate(s), (ii) <b>varcov</b>: the expected variance-covariance evaluated at the inputted mle argument, (iii) <b>mle.bc</b>: the bias-corrected maximum likelihood estimate(s), (iv) <b>varcov.bc</b>: the expected variance-covariance evaluated at the bias-corrected maximum likelihood estimate(s) and (v) <b>bias</b>: the bias estimate(s).
</p>
<p>If the numerical integration fails and/or the expected information is singular an error message is returned.
</p>


<h3>Author(s)</h3>

<p>Josmar Mazucheli <a href="mailto:jmazucheli@gmail.com">jmazucheli@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+deriv">deriv</a></code>, <code><a href="stats.html#topic+D">D</a></code>, <code><a href="#topic+expected.varcov">expected.varcov</a></code>, <code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+observed.varcov">observed.varcov</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{library(mle.tools); library(fitdistrplus); set.seed(1)};

## Normal distribution
pdf &lt;- quote(1 / (sqrt(2 * pi) * sigma) * exp(-0.5 / sigma ^ 2 * (x - mu) ^ 2))
lpdf &lt;- quote(- log(sigma) - 0.5 / sigma ^ 2 * (x - mu) ^ 2)

x &lt;- rnorm(n = 100, mean = 0.0, sd = 1.0)
{mu.hat &lt;- mean(x); sigma.hat = sqrt((length(x) - 1) * var(x) / length(x))}

coxsnell.bc(density = pdf, logdensity = lpdf, n = length(x), parms = c("mu", "sigma"),
 mle = c(mu.hat, sigma.hat), lower = '-Inf', upper = 'Inf')

################################################################################

## Weibull distribution
pdf &lt;- quote(shape / scale ^ shape * x ^ (shape - 1) * exp(-(x / scale) ^ shape))
lpdf &lt;- quote(log(shape) - shape * log(scale) + shape * log(x) -
 (x / scale) ^ shape)

x &lt;- rweibull(n = 100, shape = 1.5, scale = 2.0)

fit &lt;- fitdist(data = x, distr = 'weibull')
fit$vcov

coxsnell.bc(density = pdf, logdensity = lpdf, n = length(x), parms = c("shape", "scale"),
 mle = fit$estimate, lower = 0)

################################################################################

## Exponentiated Weibull distribution
pdf &lt;- quote(alpha * shape / scale ^ shape * x ^ (shape - 1) * exp(-(x / scale) ^ shape) *
 (1 - exp(-(x / scale) ^ shape)) ^ (alpha - 1))
lpdf &lt;- quote(log(alpha) + log(shape) - shape * log(scale) + shape * log(x) -
 (x / scale) ^ shape + (alpha - 1) * log((1 - exp(-(x / scale) ^ shape))))

coxsnell.bc(density = pdf, logdensity = lpdf, n = 100, parms = c("shape", "scale", "alpha"),
 mle = c(1.5, 2.0, 1.0), lower = 0)

################################################################################

## Exponetial distribution
pdf &lt;- quote(rate * exp(-rate * x))
lpdf &lt;- quote(log(rate) - rate * x)

x &lt;- rexp(n = 100, rate = 0.5)

fit &lt;- fitdist(data = x, distr = 'exp')
fit$vcov

coxsnell.bc(density = pdf, logdensity = lpdf, n = length(x), parms = c("rate"),
 mle = fit$estimate, lower = 0)

################################################################################

## Gamma distribution
pdf &lt;- quote(1 /(scale ^ shape * gamma(shape)) * x ^ (shape - 1) * exp(-x / scale))
lpdf &lt;- quote(-shape * log(scale) - lgamma(shape) + shape * log(x) -
 x / scale)

x &lt;- rgamma(n = 100, shape = 1.5, scale = 2.0)

fit &lt;- fitdist(data = x, distr = 'gamma', start = list(shape = 1.5, scale =  2.0))
fit$vcov

coxsnell.bc(density = pdf, logdensity = lpdf, n = length(x), parms = c("shape", "scale"),
 mle = fit$estimate, lower = 0)

################################################################################

## Beta distribution
pdf &lt;- quote(gamma(shape1 + shape2) / (gamma(shape1) * gamma(shape2)) * x ^ (shape1 - 1) *
 (1 - x) ^ (shape2 - 1))
lpdf &lt;- quote(lgamma(shape1 + shape2) - lgamma(shape1) - lgamma(shape2) +
 shape1 * log(x) + shape2 * log(1 - x))

x &lt;- rbeta(n = 100, shape1 = 2.0, shape2 = 2.0)

fit &lt;- fitdist(data = x, distr = 'beta', start = list(shape1 = 2.0, shape2 =  2.0))
fit$vcov

coxsnell.bc(density = pdf, logdensity = lpdf, n = length(x), parms = c("shape1", "shape2"),
mle = fit$estimate, lower = 0, upper = 1)

</code></pre>

<hr>
<h2 id='expected.varcov'>Expected Fisher Information</h2><span id='topic+expected.varcov'></span>

<h3>Description</h3>

<p><code>expected.varcov</code> calculates the inverse of the expected Fisher information. Analytical second-order partial log-density derivatives and numerical integration are used in the calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expected.varcov(density, logdensity, n, parms, mle, lower = "-Inf",
  upper = "Inf", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expected.varcov_+3A_density">density</code></td>
<td>
<p>An expression with the probability density function.</p>
</td></tr>
<tr><td><code id="expected.varcov_+3A_logdensity">logdensity</code></td>
<td>
<p>An expression with the log of the probability density function.</p>
</td></tr>
<tr><td><code id="expected.varcov_+3A_n">n</code></td>
<td>
<p>A numeric scalar with the sample size.</p>
</td></tr>
<tr><td><code id="expected.varcov_+3A_parms">parms</code></td>
<td>
<p>A character vector with the parameter name(s) specified in the density and logdensity expressions.</p>
</td></tr>
<tr><td><code id="expected.varcov_+3A_mle">mle</code></td>
<td>
<p>A numeric vector with the parameter estimate(s).</p>
</td></tr>
<tr><td><code id="expected.varcov_+3A_lower">lower</code></td>
<td>
<p>The lower integration limit (lower = &ldquo;-Inf&rdquo; is the default).</p>
</td></tr>
<tr><td><code id="expected.varcov_+3A_upper">upper</code></td>
<td>
<p>The upper integration limit (upper = &ldquo;Inf&rdquo; is the default).</p>
</td></tr>
<tr><td><code id="expected.varcov_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>integrate</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The second-order partial log-density derivatives and its expected values are calculated via <code>D</code> and <code>integrate</code> functions, respectively.
</p>


<h3>Value</h3>

<p><code>expected.varcov</code> returns a list with two components (i) <b>mle</b>: the inputted maximum likelihood estimate(s) and (ii) <b>varcov</b>: the expected variance-covariance evaluated at the inputted mle argument.
</p>
<p>If the numerical integration fails and/or the expected information is singular an error message is returned.
</p>


<h3>Author(s)</h3>

<p>Josmar Mazucheli <a href="mailto:jmazucheli@gmail.com">jmazucheli@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+deriv">deriv</a></code>, <code><a href="stats.html#topic+D">D</a></code>, <code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+expected.varcov">expected.varcov</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{library(mle.tools); library(fitdistrplus); set.seed(1)};

## Normal distribution
pdf &lt;- quote(1 / (sqrt(2 * pi) * sigma) * exp(-0.5 / sigma ^ 2 * (x - mu) ^ 2))
lpdf &lt;- quote(-log(sigma) - 0.5 / sigma ^ 2 * (x - mu) ^ 2)

x &lt;- rnorm(n = 100, mean = 0.0, sd = 1.0)

expected.varcov(density = pdf, logdensity = lpdf, n = length(x), parms = c("mu", "sigma"),
 mle = c(mean(x), sd(x)), lower = '-Inf', upper = 'Inf')

################################################################################

## Weibull distribution
pdf &lt;- quote(shape / scale ^ shape * x ^ (shape - 1) * exp(-(x / scale) ^ shape))
lpdf &lt;- quote(log(shape) - shape * log(scale) + shape * log(x) -
 (x / scale) ^ shape)

x &lt;- rweibull(n = 100, shape = 1.5, scale = 2.0)

fit &lt;- fitdist(data = x, distr = 'weibull')
fit$vcov

expected.varcov(density = pdf, logdensity = lpdf, n = length(x), parms = c("shape", "scale"),
 mle = fit$estimate, lower = 0)

################################################################################

## Expoentiated Weibull distribution
pdf &lt;- quote(alpha * shape / scale ^ shape * x ^ (shape - 1) * exp(-(x / scale) ^ shape) *
 (1 - exp(-(x / scale) ^ shape)) ^ (alpha - 1))
lpdf &lt;- quote(log(alpha) + log(shape) - shape * log(scale) + shape * log(x) -
 (x / scale) ^ shape + (alpha - 1) * log((1 - exp(-(x / scale) ^ shape))))

expected.varcov(density = pdf, logdensity = lpdf, n = 100, parms = c("shape", "scale", "alpha"),
 mle = c(1.5, 2.0, 1.0), lower = 0)
################################################################################

## Exponetial distribution
pdf &lt;- quote(rate * exp(-rate * x))
lpdf &lt;- quote(log(rate) - rate * x)

x &lt;- rexp(n = 100, rate = 0.5)

fit &lt;- fitdist(data = x, distr = 'exp')
fit$vcov

expected.varcov(density = pdf, logdensity = lpdf, n = length(x), parms = c("rate"),
 mle = fit$estimate, lower = 0)

################################################################################

## Gamma distribution
pdf &lt;- quote(1 /(scale ^ shape * gamma(shape)) * x ^ (shape - 1) * exp(-x / scale))
lpdf &lt;- quote(-shape * log(scale) - lgamma(shape) + shape * log(x) -
 x / scale)

x &lt;- rgamma(n = 100, shape = 1.5, scale = 2.0)

fit &lt;- fitdist(data = x, distr = 'gamma', start = list(shape = 1.5, scale =  2.0))
fit$vcov

expected.varcov(density = pdf, logdensity = lpdf, n = length(x), parms = c("shape", "scale"),
 mle = fit$estimate, lower = 0)

################################################################################

## Beta distribution
pdf &lt;- quote(gamma(shape1 + shape2) / (gamma(shape1) * gamma(shape2)) * x ^ (shape1 - 1) *
(1 - x) ^ (shape2 - 1))
lpdf &lt;- quote(lgamma(shape1 + shape2) - lgamma(shape1) - lgamma(shape2) +
 shape1 * log(x) + shape2 * log(1 - x))

x &lt;- rbeta(n = 100, shape1 = 2.0, shape2 = 2.0)

fit &lt;- fitdist(data = x, distr = 'beta', start = list(shape1 = 2.0, shape2 =  2.0))
fit$vcov

expected.varcov(density = pdf, logdensity = lpdf, n = length(x), parms = c("shape1", "shape2"),
 mle = fit$estimate, lower = 0, upper = 1)

</code></pre>

<hr>
<h2 id='observed.varcov'>Observed Fisher Information</h2><span id='topic+observed.varcov'></span>

<h3>Description</h3>

<p><code>observed.varcov</code> calculates the inverse of the observed Fisher Information. Analytical second-order partial log-density derivatives are used in the calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>observed.varcov(logdensity, X, parms, mle)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="observed.varcov_+3A_logdensity">logdensity</code></td>
<td>
<p>An expression with the log of the probability density function.</p>
</td></tr>
<tr><td><code id="observed.varcov_+3A_x">X</code></td>
<td>
<p>A numeric vector with the observations.</p>
</td></tr>
<tr><td><code id="observed.varcov_+3A_parms">parms</code></td>
<td>
<p>A character vector with the parameter name(s) specified in the logdensity expression.</p>
</td></tr>
<tr><td><code id="observed.varcov_+3A_mle">mle</code></td>
<td>
<p>A numeric vector with the parameter estimate(s).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The second-order partial log-density derivatives are calculated via <code>D</code> function.
</p>


<h3>Value</h3>

<p><code>observed.varcov</code> returns a list with two components (i) <b>mle</b>: the inputted maximum likelihood estimate(s) and (ii) <b>varcov</b>: the observed variance-covariance evaluated at the inputted mle argument.
</p>
<p>If the observed information is singular an error message is returned.
</p>


<h3>Author(s)</h3>

<p>Josmar Mazucheli <a href="mailto:jmazucheli@gmail.com">jmazucheli@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+deriv">deriv</a></code>, <code><a href="stats.html#topic+D">D</a></code>, <code><a href="#topic+expected.varcov">expected.varcov</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{library(mle.tools); library(fitdistrplus); set.seed(1)};

##Normal distribution
lpdf &lt;- quote(-log(sigma) - 0.5 / sigma ^ 2 * (x - mu) ^ 2)

x &lt;- rnorm(n = 100, mean = 0.0, sd = 1.0)

observed.varcov(logdensity = lpdf, X = x, parms = c("mu", "sigma"),
 mle = c(mean(x), sd(x)))

################################################################################

## Weibull distribution
lpdf &lt;- quote(log(shape) - shape * log(scale) + shape * log(x) - (x / scale) ^ shape)

x &lt;- rweibull(n = 100, shape = 1.5, scale = 2.0)

fit &lt;- fitdist(data = x, distr = 'weibull')
fit$vcov

observed.varcov(logdensity = lpdf, X = x, parms = c("shape", "scale"), mle = fit$estimate)

################################################################################

## Exponetial distribution
lpdf &lt;- quote(log(rate) - rate * x)

x &lt;- rexp(n = 100, rate = 0.5)

fit &lt;- fitdist(data = x, distr = 'exp')
fit$vcov

observed.varcov(logdensity = lpdf, X = x, parms = c("rate"), mle = fit$estimate)

################################################################################

## Gamma distribution
lpdf &lt;- quote(-shape * log(scale) - lgamma(shape) + shape * log(x) -
 x / scale)

x &lt;- rgamma(n = 100, shape = 1.5, scale = 2.0)

fit &lt;- fitdist(data = x, distr = 'gamma', start = list(shape = 1.5, scale =  2.0))
fit$vcov

observed.varcov(logdensity = lpdf, X = x, parms = c("shape", "scale"), mle = fit$estimate)

################################################################################

## Beta distribution
lpdf &lt;- quote(lgamma(shape1 + shape2) - lgamma(shape1) - lgamma(shape2) +
  shape1 * log(x) + shape2 * log(1 - x))

x &lt;- rbeta(n = 100, shape1 = 2.0, shape2 = 2.0)

fit &lt;- fitdist(data = x, distr = 'beta', start = list(shape1 = 2.0, shape2 =  2.0))
fit$vcov

observed.varcov(logdensity = lpdf, X = x, parms = c("shape1", "shape2"), mle = fit$estimate)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
