<!DOCTYPE html><html lang="en"><head><title>Help for package spass</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {spass}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bssr.1subgroup'><p>Blinded Sample Size Recalculation for a One Subgroup Design</p></a></li>
<li><a href='#bssr.gee.1subgroup'><p>Blinded Sample Size Recalculation for longitudinal data in a One Subgroup Design</p></a></li>
<li><a href='#bssr.nb.gf'><p>Blinded Sample Size Reestimation for Longitudinal Count Data with marginal Negative Binomial Distribution and underlying Gamma Frailty with Autoregressive Correlation Structure of Order One</p></a></li>
<li><a href='#bssr.nb.inar1'><p>Blinded Sample Size Reestimation for Longitudinal Count Data using the NB-INAR(1) Model</p></a></li>
<li><a href='#estimcov'><p>Estimation of simulation parameters</p></a></li>
<li><a href='#fit.nb.gf'><p>Fitting Longitudinal Data from a Gamma Frailty Model with Frailty of Autoregressive Correlation Structure of Order One</p></a></li>
<li><a href='#fit.nb.inar1'><p>Fitting Longitudinal Data with Negative Binomial Marginal Distribution and Autoregressive Correlation Structure of Order One: NB-INAR(1)</p></a></li>
<li><a href='#gen_cov_cor'><p>Generation of a covariance or a correlation matrix</p></a></li>
<li><a href='#get.groups'><p>Generate Time Series with Negative Binomial Distribution and Multivariate Gamma Frailty with Autoregressive Correlation Structure of Order One with Trend</p></a></li>
<li><a href='#n.1subgroup'><p>Sample Size Calculation for a One Subgroup Design</p></a></li>
<li><a href='#n.gee.1subgroup'><p>Sample Size estimation for longitudinal GEE models</p></a></li>
<li><a href='#n.nb.gf'><p>Sample Size Calculation for Comparing Two Groups when observing Longitudinal Count Data with marginal Negative Binomial Distribution and underlying Gamma Frailty with Autoregressive Correlation Structure of Order One</p></a></li>
<li><a href='#n.nb.inar1'><p>Sample Size Calculation for Comparing Two Groups when observing Longitudinal Count Data with marginal Negative Binomial Distribution and Autoregressive Correlation Structure of Order One: NB-INAR(1)</p></a></li>
<li><a href='#r.1subgroup'><p>Generate dataset of normal distributed observations in a one subgroup design</p></a></li>
<li><a href='#r.gee.1subgroup'><p>Generate dataset of normal distributed repeated observations in a one subgroup design</p></a></li>
<li><a href='#rnbinom.gf'><p>Generate Time Series with Negative Binomial Distribution and Multivariate Gamma Frailty with Autoregressive Correlation Structure of Order One</p></a></li>
<li><a href='#rnbinom.inar1'><p>Generate Time Series with Negative Binomial Distribution and Autoregressive Correlation Structure of Order One: NB-INAR(1)</p></a></li>
<li><a href='#sandwich'><p>Calculate the robust covariance estimator for GEE given an</p></a></li>
<li><a href='#sandwich2'><p>Generate Time Series with Negative Binomial Distribution and Autoregressive Correlation Structure of Order One: NB-INAR(1)</p></a></li>
<li><a href='#sim.bssr.1subgroup'><p>Simulation of a One Subgroup Design with Internal Pilot Study</p></a></li>
<li><a href='#sim.bssr.gee.1subgroup'><p>Simulation of a longitudinal one subgroup design with internal pilot Study</p></a></li>
<li><a href='#summary.bssrest'><p>Summarizing Blinded Sample Size Reestimation</p></a></li>
<li><a href='#summary.ssest'><p>Summarizing Initial Sample Size Estimates</p></a></li>
<li><a href='#test.nb.gf'><p>Testing Hypotheses in Gamma Frailty models</p></a></li>
<li><a href='#test.nb.inar1'><p>Testing Hypotheses in NB-INAR(1) model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Study Planning and Adaptation of Sample Size</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-12-01</td>
</tr>
<tr>
<td>Author:</td>
<td>T. Asendorf, R. Gera, S. Islam, M. Harden and M. Placzek</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marius Placzek &lt;marius.placzek@med.uni-goettingen.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Sample size estimation and blinded sample size reestimation in Adaptive Study Design.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp,mvtnorm,multcomp,MASS,geepack,stats,utils</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-12-02 16:01:42 UTC; tasendorf</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-12-07 22:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bssr.1subgroup'>Blinded Sample Size Recalculation for a One Subgroup Design</h2><span id='topic+bssr.1subgroup'></span>

<h3>Description</h3>

<p>Given data from an Internal Pilot Study (IPS), <code>bssr.1subgroup</code> reestimates the nuisance parameters, i.e. variances and prevalence, and recalculates the required sample size for proving a desired alternative when testing for an effect in the full or subpopulation. See 'Details' for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bssr.1subgroup(
  data,
  alpha,
  beta,
  delta,
  eps = 0.001,
  approx = c("conservative.t", "liberal.t", "normal"),
  df = c("n", "n1"),
  adjust = c("YES", "NO"),
  k = 1,
  nmax = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bssr.1subgroup_+3A_data">data</code></td>
<td>
<p>data matrix with data from ongoing trial: see 'Details'.</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_beta">beta</code></td>
<td>
<p>type II error (power=1-beta) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_delta">delta</code></td>
<td>
<p>vector of treatment effects to be proven, c(outside subgroup, inside subgroup).</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_eps">eps</code></td>
<td>
<p>precision parameter concerning the power calculation in the iterative sample size search algorithm.</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_approx">approx</code></td>
<td>
<p>approximation method: Use a conservative multivariate t distribution (&quot;conservative.t&quot;), a liberal multivariate t distribution (&quot;liberal.t&quot;) or a multivariate normal distribution (&quot;normal&quot;) to approximate the joint distribution of the standardized test statistics.</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_df">df</code></td>
<td>
<p>in case of a multivariate t distribution approximation, recalculate sample size with degrees of freedom depending on the size of the IPS (df=n1) or depending on the final sample size (df=n).</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_adjust">adjust</code></td>
<td>
<p>adjust blinded estimators for assumed treatment effect (&quot;YES&quot;,&quot;No&quot;).</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="bssr.1subgroup_+3A_nmax">nmax</code></td>
<td>
<p>maximum total sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs blinded nuisance parameter reestimation in a design with a subgroup within a full population where we want to test for treatment effects between a control and a treatment group.
Then the required sample size for the control and treatment group to prove an existing
alternative <code>delta</code> with a specified power 1-<code>beta</code> when testing the global null hypothesis <code class="reqn">H_0: \Delta_F=\Delta_S=0</code> to level <code>alpha</code> is calculated.
</p>
<p>The data matrix <code>data</code> should have three columns: The first column has to be a binary variable (0=treatment group, 1=control group). The second column should also contain a binary variable giving the full population/subgroup differentiation (0=full population, 1=subpopulation). The last column contains the observations.
</p>
<p>For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the
sample size allocation factor, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>
<p>The parameter <code>df</code> provides a difference to the standard sample size calculation procedure implemented in <code><a href="#topic+n.1subgroup">n.1subgroup</a></code>.
When applying a multivariate t distribution approximation to approximate the joint distribution of the standardized test statistics it gives the opportunity to use degrees of freedom depending on the number of subjects in the IPS instead of degrees of freedom depending on the projected final sample size.
Note that this leads to better performance when dealing with extremely small subgroup sample sizes but significantly increases the calculated final sample size.
</p>


<h3>Value</h3>

<p><code>bssr.1subgroup</code> returns a list containing the recalculated required sample size within the control group and treatment group along with all relevant parameters. Use <code><a href="#topic+summary.bssrest">summary.bssrest</a></code> for a structured overview.
</p>


<h3>Source</h3>

<p><code>bssr.1subgroup</code> uses code contributed by Marius Placzek.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+n.1subgroup">n.1subgroup</a></code> for sample size calculation prior to the trial.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Given data from the Internal Pilot Study, reestimate the nuisance parameters and
#recalculate the required sample size to correctly reject with
#80% probability when testing the global Nullhypothesis H_0: Delta_F=Delta_S = 0
#assuming the true effect Delta_S=1 is in the subgroup (no effect outside of the subgroup).

random&lt;-r.1subgroup(n=50, delta=c(0,1), sigma=c(1,1.2), tau=0.4, fix.tau="YES", k=2)
reestimate&lt;-bssr.1subgroup(data=random,alpha=0.05,beta=0.1,delta=c(0,1),eps=0.001,
approx="conservative.t",df="n1",k=2,adjust="NO")
summary(reestimate)

</code></pre>

<hr>
<h2 id='bssr.gee.1subgroup'>Blinded Sample Size Recalculation for longitudinal data in a One Subgroup Design</h2><span id='topic+bssr.gee.1subgroup'></span>

<h3>Description</h3>

<p>Given re-estimations from an Internal Pilot Study (IPS), <code>bssr.GEE.1subgroup</code> re-estimates required sample size given the re-estimated nuisance parameters are given. <code>bssr.gee.1subgroup</code> is a wrapper for <code>n.gee.1subgroup</code> where the re-estimation of the variances can be highly dependable on the user and should be supplied separately. see &quot;detail&quot; for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bssr.gee.1subgroup(
  alpha,
  tail = "both",
  beta = NULL,
  delta,
  estsigma,
  tau = 0.5,
  k = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bssr.gee.1subgroup_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="bssr.gee.1subgroup_+3A_tail">tail</code></td>
<td>
<p>which type of test is used, e.g. which quartile und H0 is calculated.</p>
</td></tr>
<tr><td><code id="bssr.gee.1subgroup_+3A_beta">beta</code></td>
<td>
<p>type II error (power=1-beta) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="bssr.gee.1subgroup_+3A_delta">delta</code></td>
<td>
<p>vector of estimated treatment effect in overall and sub population, c(overall population, only subpopulation).</p>
</td></tr>
<tr><td><code id="bssr.gee.1subgroup_+3A_estsigma">estsigma</code></td>
<td>
<p>vector of re-estimated standard deviations, c(full population, subpopulation). See 'Details'.</p>
</td></tr>
<tr><td><code id="bssr.gee.1subgroup_+3A_tau">tau</code></td>
<td>
<p>ratio between complementary F/S and sub-population S.</p>
</td></tr>
<tr><td><code id="bssr.gee.1subgroup_+3A_k">k</code></td>
<td>
<p>treatment allocation factor between groups: see 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides a simple warped for <code>n.gee.1subgroup</code> where instead of initial assumptions, reestimated nuisance parameter are used.
For more information see <code>n.gee.1subgroup</code>.
Required samplesize to test alternative <code>delta</code> with specified power 1-<code>beta</code> when testing the global null hypothesis <code class="reqn">H_0: \beta_3^F=\beta_3^S=0</code> to level <code>alpha</code> is estimated. When testing outcomes have variance <code>estsigma</code>.
</p>
<p>For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group respectively, the argument <code>k</code> is the
sample size allocation factor, i.e. <code class="reqn">k = n_T/n_C</code> and <code>tau</code> represents the ratio of the sub-population.
</p>


<h3>Value</h3>

<p><code>bssr.gee.1subgroup</code> returns a list containing the recalculated sample sizes along with all relevant parameters. Use <code><a href="#topic+summary.bssrest">summary.bssrest</a></code> for a structured overview.
</p>


<h3>Source</h3>

<p><code>bssr.gee.1subgroup</code> uses code contributed by Roland Gerard Gera.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+n.gee.1subgroup">n.gee.1subgroup</a></code> for sample size calculation prior to a trial and <code>estimcov</code> how the re-estimate nuisance parameters. See <code class="reqn">sim.gee</code> for a working example for an initial sample size estimation and a re-estimation mid trial.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimate&lt;-bssr.gee.1subgroup(alpha=0.05,beta=0.2,delta=c(0.1,0.1),estsigma=c(0.8,0.4),tau=0.4, k=1)
summary(estimate)
</code></pre>

<hr>
<h2 id='bssr.nb.gf'>Blinded Sample Size Reestimation for Longitudinal Count Data with marginal Negative Binomial Distribution and underlying Gamma Frailty with Autoregressive Correlation Structure of Order One</h2><span id='topic+bssr.nb.gf'></span>

<h3>Description</h3>

<p><code>bssr.nb.gf</code> fits blinded observations and recalculates the sample size required for sustaining power at desired alternative when testing for
trend parameters in a Gamma frailty models. See 'Details' for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bssr.nb.gf(
  data,
  alpha = 0.025,
  power = 0.8,
  delta,
  h0 = 0,
  tp,
  k,
  trend = c("constant", "exponential", "custom"),
  approx = 20
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bssr.nb.gf_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing count data which is to be fitted. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="bssr.nb.gf_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="bssr.nb.gf_+3A_power">power</code></td>
<td>
<p>power (1 - type II error) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="bssr.nb.gf_+3A_delta">delta</code></td>
<td>
<p>the relevant effect size, which is assumed to be true, see 'Details'.</p>
</td></tr>
<tr><td><code id="bssr.nb.gf_+3A_h0">h0</code></td>
<td>
<p>the value against which h is tested, see 'Details'.</p>
</td></tr>
<tr><td><code id="bssr.nb.gf_+3A_tp">tp</code></td>
<td>
<p>number of observed time points. (see <code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code>)</p>
</td></tr>
<tr><td><code id="bssr.nb.gf_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="bssr.nb.gf_+3A_trend">trend</code></td>
<td>
<p>the trend which assumed to underlying in the data.</p>
</td></tr>
<tr><td><code id="bssr.nb.gf_+3A_approx">approx</code></td>
<td>
<p>numer of iterations in numerical calculation of the sandwich estimator, see 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function recalculates a sample size for testing in constant and exponential trends.
</p>
<p>Under a constant trend, the means in control and experiment group are equal to <code class="reqn">\lambda_1</code> and  <code class="reqn">\lambda_1 + \lambda_2</code>, respectively.
The treatment effect <code>delta</code> is therefore equal to <code class="reqn">\lambda_2</code>.
</p>
<p>Under an exponential trend, the means in control and experiment group are equal to <code class="reqn">exp(\lambda_1+t \cdot \lambda_2)</code> and  <code class="reqn">\lambda_1 + t\cdot \lambda_2 + t\cdot \lambda_3</code>, respectively.
The treatment effect <code>delta</code> is therefore equal to <code class="reqn">\lambda_3</code>.
</p>
<p><code>bssr.nb.gf</code> returns the required sample size for the control and treatment group required to prove an existing
alternative <code>delta</code> with a specified power <code>power</code> when testing the null hypothesis <code class="reqn">H_0: \delta \ge h_0</code> at level <code>alpha</code>.
Nuisance parameters are estimated through the blinded observations <code>data</code>, thus not further required.
For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the desired
sample size allocation factor at the end of the study, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>


<h3>Value</h3>

<p><code>bssr.nb.gf</code> returns the required sample size within the control group and treatment group.
</p>


<h3>Source</h3>

<p><code>bssr.nb.gf</code> uses code contributed by Thomas Asendorf.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code> for information on the Gamma Frailty model, <code><a href="#topic+n.nb.gf">n.nb.gf</a></code> for calculating
initial sample size required when performing inference, <code><a href="#topic+fit.nb.gf">fit.nb.gf</a></code> for calculating
initial parameters required when performing sample size estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##The example is commented as it may take longer than 10 seconds to run.
##Please uncomment prior to execution.

##Example for constant rates
#set.seed(12)
#h&lt;-function(lambda.eta){
#   lambda.eta[2]
#}
#hgrad&lt;-function(lambda.eta){
#   c(0, 1, 0)
#}

##Calculate initial sample size
#estimate&lt;-n.nb.gf(lambda=c(0,-0.3), size=1, rho=0.5, tp=6, k=1, h=h, hgrad=hgrad,
#   h0=0, trend="constant", approx=20)

##Generate and permutate data with different nuisance parameters
#random&lt;-get.groups(n=round(estimate$n/2), size=c(0.8, 0.8), lambda=c(0.5, -0.3),
#   rho=c(0.4, 0.4), tp=6, trend="constant")
#random&lt;-random[sample(1:nrow(random), nrow(random)), ]

##Recalculate sample size with data
#reestimate&lt;-bssr.nb.gf(data=random, alpha=0.025, power=0.8, delta=-0.3, h0=0,
#   tp=6, k=1, trend="constant", approx = 20)

#summary(reestimate)

</code></pre>

<hr>
<h2 id='bssr.nb.inar1'>Blinded Sample Size Reestimation for Longitudinal Count Data using the NB-INAR(1) Model</h2><span id='topic+bssr.nb.inar1'></span>

<h3>Description</h3>

<p><code>bssr.nb.inar1</code> fits blinded observations and recalculates the sample size required for proving a desired alternative when testing for
a rate ratio between two groups unequal to one. See 'Details' for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bssr.nb.inar1(alpha, power, delta, x, n, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bssr.nb.inar1_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="bssr.nb.inar1_+3A_power">power</code></td>
<td>
<p>power (1 - type II error) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="bssr.nb.inar1_+3A_delta">delta</code></td>
<td>
<p>the rate ratio which is to be proven.</p>
</td></tr>
<tr><td><code id="bssr.nb.inar1_+3A_x">x</code></td>
<td>
<p>a matrix or data frame containing count data which is to be fitted. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="bssr.nb.inar1_+3A_n">n</code></td>
<td>
<p>a vector giving the sample size within the control group and the treatment group, respecitvely.</p>
</td></tr>
<tr><td><code id="bssr.nb.inar1_+3A_k">k</code></td>
<td>
<p>planned sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When testing for differences between rates <code class="reqn">\mu_C</code> and <code class="reqn">\mu_T</code> of two groups, a control and a treatment group respectively, we usually
test for the ratio between the two rates, i.e. <code class="reqn">\mu_T/\mu_C = 1</code>. The ratio of the two rates is refered to as <code class="reqn">\delta</code>, i.e.
<code class="reqn">\delta = \mu_T/\mu_C</code>.
</p>
<p><code>bssr.nb.inar1</code> gives back the required sample size for the control and treatment group required to prove an existing
alternative <code>theta</code> with a specified power <code>power</code> when testing the null hypothesis <code class="reqn">H_0: \mu_T/\mu_C \ge 1</code> to level <code>alpha</code>.
Nuisance parameters are estimated through the blinded observations <code>x</code>, thus not further required.
</p>
<p>for sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the desired
sample size allocation factor at the end of the study, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>


<h3>Value</h3>

<p><code>rnbinom.inar1</code> returns the required sample size within the control group and treatment group.
</p>


<h3>Source</h3>

<p><code>rnbinom.inar1</code> uses code contributed by Thomas Asendorf.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.inar1">rnbinom.inar1</a></code> for information on the NB-INAR(1) model, <code><a href="#topic+n.nb.inar1">n.nb.inar1</a></code> for calculating
initial sample size required when performing inference, <code><a href="#topic+fit.nb.inar1">fit.nb.inar1</a></code> for calculating
initial parameters required when performing sample size estimation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Calculate required sample size to find significant difference with
#80% probability when testing the Nullhypothesis H_0: mu_T/mu_C &gt;= 1
#assuming the true effect delta is 0.8 and rate, size and correlation
#parameter in the control group are 2, 1 and 0.5, respectively.

estimate&lt;-n.nb.inar1(alpha=0.025, power=0.8, delta=0.8, muC=2, size=1, rho=0.5, tp=7, k=1)

#Simulate data
placebo&lt;-rnbinom.inar1(n=50, size=1, mu=2, rho=0.5, tp=7)
treatment&lt;-rnbinom.inar1(n=50, size=1, mu=1.6, rho=0.5, tp=7)

#Blinded sample size reestimation
blinded.data&lt;-rbind(placebo, treatment)[sample(1:100),]
estimate&lt;-bssr.nb.inar1(alpha=0.025, power=0.8, delta=0.8, x=blinded.data, n=c(50,50), k=1)
summary(estimate)
</code></pre>

<hr>
<h2 id='estimcov'>Estimation of simulation parameters</h2><span id='topic+estimcov'></span>

<h3>Description</h3>

<p><code>estimcov</code> estimates the covariance matrix and dropout rates given a dataset and observation-times
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimcov(
  data,
  Time,
  Startvalues = c(3, 0.5, 1),
  stepwidth = c(0.001, 0.001, 0.001),
  maxiter = 10000,
  lower = c(1e-04, 1e-04, 1e-04),
  upper = c(Inf, 5, 3)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimcov_+3A_data">data</code></td>
<td>
<p>matrix with the dataset which is used to estimate the covariance and dropout structure.</p>
</td></tr>
<tr><td><code id="estimcov_+3A_time">Time</code></td>
<td>
<p>vector with observation-times.</p>
</td></tr>
<tr><td><code id="estimcov_+3A_startvalues">Startvalues</code></td>
<td>
<p>vector with starting values for variance, <code>rho</code> and <code>theta</code> respectively.</p>
</td></tr>
<tr><td><code id="estimcov_+3A_stepwidth">stepwidth</code></td>
<td>
<p>vector describing the step length of previously mentioned values.</p>
</td></tr>
<tr><td><code id="estimcov_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum amount of iterations</p>
</td></tr>
<tr><td><code id="estimcov_+3A_lower">lower</code></td>
<td>
<p>vector with minimum for the parameters described in Startvalues</p>
</td></tr>
<tr><td><code id="estimcov_+3A_upper">upper</code></td>
<td>
<p>vector with maximum for the parameters described in Startvalues</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is designed to estimate the variance, <code>rho</code> and <code>theta</code> and a vector with the dropout rate in the data.
</p>


<h3>Value</h3>

<p><code>estimcov</code> returns a list with two entries. In the first the parameters variance, <code>rho</code> and <code>theta</code> are returned and in the second a vector with the dropout-rate is returned.
</p>


<h3>Source</h3>

<p><code>estimcov</code> uses code contributed by Roland Gerard Gera.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># First generate a dataset with 200 patients, rho =0.25 and tau = 0.5 and
# then estimate the parameters using estimcov.

set.seed(2015)
dataset &lt;- r.gee.1subgroup(n=200, reg=list(c(0,0,0,0.1),c(0,0,0,0.1)), sigma=c(3,2.5),
  tau=0.5, rho=0.25, theta=1, k=1.5, Time=c(0:5), OD=0)

estimations &lt;- estimcov(data=dataset,Time=c(0:5))
estimations[[1]]
estimations[[2]]

</code></pre>

<hr>
<h2 id='fit.nb.gf'>Fitting Longitudinal Data from a Gamma Frailty Model with Frailty of Autoregressive Correlation Structure of Order One</h2><span id='topic+fit.nb.gf'></span>

<h3>Description</h3>

<p><code>fit.nb.gf</code> fits data using the pseudo maximum likelihood of a Gamma frailty model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.nb.gf(
  dataC,
  dataE,
  trend = c("constant", "exponential"),
  lower,
  upper,
  method = "L-BFGS-B",
  start,
  approx = 20,
  rho = FALSE,
  H0 = FALSE,
  h0 = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.nb.gf_+3A_datac">dataC</code></td>
<td>
<p>a matrix containing count data from the control group, which is to be fitted. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_datae">dataE</code></td>
<td>
<p>a matrix containing count data from the experiment group, which is to be fitted. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_trend">trend</code></td>
<td>
<p>the trend which assumed to underlying in the data.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for estimated parameters <code>lambda</code>, <code>size</code> and <code>rho</code>, respectively.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for estimated parameters <code>lambda</code>, <code>size</code> and <code>rho</code>, respectively.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_method">method</code></td>
<td>
<p>algorithm used for minimization of the likelihood, see <code><a href="stats.html#topic+optim">optim</a></code> for details.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_start">start</code></td>
<td>
<p>vector of starting values for estimated parameters <code>mu</code>, <code>size</code> and <code>rho</code>, respectively, used for optimization.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_approx">approx</code></td>
<td>
<p>numer of iterations in numerical calculation of the sandwich estimator, see 'Details'.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_rho">rho</code></td>
<td>
<p>indicates whether or not to calculate the correlation coefficient of Gamma frailties. Must be TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_h0">H0</code></td>
<td>
<p>indicates whether or not to calculate the hessian and outer gradient matrix under the null hypothesis, see 'Details'.</p>
</td></tr>
<tr><td><code id="fit.nb.gf_+3A_h0">h0</code></td>
<td>
<p>the value against which is tested under the null</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the function <code>fit.nb.gf</code> fits a Gamma frailty model as found in Fiocco (2009). The fitting function allows for incomplete follow up,
but not for intermittent missingness.
</p>
<p>When calculating the expected sandwich estimator required for the sample size, certain terms can not be computed analytically and have
to be approximated numerically. The value <code>approx</code> defines how close the approximation is to the true expected sandwich estimator.
High values of <code>approx</code> provide better approximations but are compuationally more expensive.
</p>
<p>If parameter H0 is set to TRUE, the hessian and outer gradient are calculated under the assumption that <code>lambda[2]</code> <code class="reqn">\geq</code> <code>h0</code> if
<code>trend = "constant"</code> or <code>lambda[3]</code> <code class="reqn">\geq</code> <code>h0</code> if <code>trend = "exponential"</code>.
</p>


<h3>Value</h3>

<p><code>fit.nb.gf</code> returns estimates of the trend parameters <code>lambda</code>, dispersion parameter <code>size</code>,
Hessian matrix <code>hessian</code>, outer gradient product matrix <code>ogradient</code> and, if inquired, correlation coefficient <code>rho</code>.
</p>


<h3>Source</h3>

<p><code>fit.nb.gf</code> uses code contributed by Thomas Asendorf.
</p>


<h3>References</h3>

<p>Fiocco M, Putter H, Van Houwelingen JC, (2009), A new serially correlated gamma-frailty process for longitudinal count data <em>Biostatistics</em> Vol. 10, No. 2, pp. 245-257.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code> for information on the Gamma frailty model, <code><a href="#topic+n.nb.gf">n.nb.gf</a></code> for calculating
initial sample size required when performing inference, <code><a href="#topic+bssr.nb.gf">bssr.nb.gf</a></code> for blinded
sample size reestimation within a running trial, <code><a href="stats.html#topic+optim">optim</a></code> for more information on the used minimization algorithms.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate data from the Gamma frailty model
random&lt;-get.groups(n=c(1000,1000), size=c(0.7, 0.7), lambda=c(0.8, -0.5), rho=c(0.6, 0.6),
  tp=7, trend="constant")
fit.nb.gf(dataC=random[1001:2000,], dataE=random[1:1000,], trend="constant")
</code></pre>

<hr>
<h2 id='fit.nb.inar1'>Fitting Longitudinal Data with Negative Binomial Marginal Distribution and Autoregressive Correlation Structure of Order One: NB-INAR(1)</h2><span id='topic+fit.nb.inar1'></span>

<h3>Description</h3>

<p><code>fit.nb.inar1</code> fits data using the maximum likelihood of a reparametrized NB-INAR(1) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.nb.inar1(
  x,
  lower = rep(10, 3)^-5,
  upper = c(10^5, 10^5, 1 - 10^-5),
  method = "L-BFGS-B",
  start
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.nb.inar1_+3A_x">x</code></td>
<td>
<p>a matrix or data frame containing count data which is to be fitted. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="fit.nb.inar1_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for estimated parameters <code>mu</code>, <code>size</code> and <code>rho</code>, respectively.</p>
</td></tr>
<tr><td><code id="fit.nb.inar1_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for estimated parameters <code>mu</code>, <code>size</code> and <code>rho</code>, respectively.</p>
</td></tr>
<tr><td><code id="fit.nb.inar1_+3A_method">method</code></td>
<td>
<p>algorithm used for minimization of the likelihood, see <code><a href="stats.html#topic+optim">optim</a></code> for details.</p>
</td></tr>
<tr><td><code id="fit.nb.inar1_+3A_start">start</code></td>
<td>
<p>vector of starting values for estimated parameters <code>mu</code>, <code>size</code> and <code>rho</code>, respectively, used for optimization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the function <code>fit.nb.inar1</code> fits a reparametrization of the NB-INAR(1) model as found in McKenzie (1986). The reparametrized model
assumes equal means and dispersion parameter between time points with an autoregressive correlation structure. The function is especially useful
for estimating parameters for an initial sample size calculation using <code><a href="#topic+n.nb.inar1">n.nb.inar1</a></code>. The fitting function allows for incomplete follow up,
but not for intermittent missingness.
</p>


<h3>Value</h3>

<p><code>fit.nb.inar1</code> return estimates of the mean <code>mu</code>, dispersion parameter <code>size</code> and correlation coefficient <code>rho</code>.
</p>


<h3>Source</h3>

<p><code>fit.nb.inar1</code> uses code contributed by Thomas Asendorf.
</p>


<h3>References</h3>

<p>McKenzie Ed (1986), Autoregressive Moving-Average Processes with Negative-Binomial and Geometric Marginal Distributions. <em>Advances in Applied Probability</em> Vol. 18, No. 3, pp. 679-705.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.inar1">rnbinom.inar1</a></code> for information on the NB-INAR(1) model, <code><a href="#topic+n.nb.inar1">n.nb.inar1</a></code> for calculating
initial sample size required when performing inference, <code><a href="#topic+bssr.nb.inar1">bssr.nb.inar1</a></code> for blinded
sample size reestimation within a running trial, <code><a href="stats.html#topic+optim">optim</a></code> for more information on the used minimization algorithms.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate data from the NB-INAR(1) model
set.seed(8)
random&lt;-rnbinom.inar1(n=1000, size=1.5, mu=2, rho=0.6, tp=7)

estimate&lt;-fit.nb.inar1(random)
estimate
</code></pre>

<hr>
<h2 id='gen_cov_cor'>Generation of a covariance or a correlation matrix</h2><span id='topic+gen_cov_cor'></span>

<h3>Description</h3>

<p>Generate a covariance or correlation matrix given parameters <code>var</code>, <code>rho</code>, <code>theta</code> for the covariance structure, <code>Time</code> for the observed timepoints and <code>cov=TRUE</code> if a covariance or <code>cov=FALSE</code> if a correlation-matrix is generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_cov_cor(var = 1, rho, theta, Time, cov = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_cov_cor_+3A_var">var</code></td>
<td>
<p>variance at each timepoint</p>
</td></tr>
<tr><td><code id="gen_cov_cor_+3A_rho">rho</code></td>
<td>
<p>correlation between two adjacent timepoints 1 timeunit appart</p>
</td></tr>
<tr><td><code id="gen_cov_cor_+3A_theta">theta</code></td>
<td>
<p>variable specifying the type of the correlation structure: see 'Details'</p>
</td></tr>
<tr><td><code id="gen_cov_cor_+3A_time">Time</code></td>
<td>
<p>list with time measures which are used to generate the covariance- or correlation-structure: see 'Details'</p>
</td></tr>
<tr><td><code id="gen_cov_cor_+3A_cov">cov</code></td>
<td>
<p>TRUE/FALSE statement which determines if a covariance- or a correlation-matrix is generated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gen_cov_cor</code> is used to generate either a covariance or a correlation matrix. Given vector <code>Time</code> and parameters <code>var</code>, <code>rho</code> and <code>theta</code> the following two equations are used to calculate the covariance and the correlation between two timepoints, respectively:
cov(Time[i],Time[j])=var*(rho^(abs(Time[i]-Time[j])^theta))
corr(Time[i],Time[j])=rho^(abs(Time[i]-Time[j])^theta) ]]
</p>


<h3>Value</h3>

<p><code>gen_cov_cor</code> returns a covariance or correlation matrix.
</p>


<h3>Source</h3>

<p><code>gen_cov_cor</code> uses code contributed by Roland Gerard Gera
</p>
<p>@seealso <code><a href="#topic+r.gee.1subgroup">r.gee.1subgroup</a></code> for information on the generated longitudinal data and <code><a href="#topic+n.gee.1subgroup">n.gee.1subgroup</a></code> for the calculation of
initial sample sizes for longitudinal GEE-models and <code><a href="#topic+bssr.gee.1subgroup">bssr.gee.1subgroup</a></code> for blinded
sample size re-estimation within a trial. See <code><a href="#topic+estimcov">estimcov</a></code> for more information on the used minimization algorithms.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a covariance-matrix with measurements at Baseline and at times c(1,1.5,2,5)

covar&lt;-gen_cov_cor(var=3,rho=0.25,theta=1,Time=c(0,1,1.5,2,5),cov=TRUE)
covar

#Generate a correlation-matrix with the same values

corr&lt;-gen_cov_cor(rho=0.25,theta=1,Time=c(0,1,1.5,2,5),cov=FALSE)
corr
</code></pre>

<hr>
<h2 id='get.groups'>Generate Time Series with Negative Binomial Distribution and Multivariate Gamma Frailty with Autoregressive Correlation Structure of Order One with Trend</h2><span id='topic+get.groups'></span>

<h3>Description</h3>

<p><code>rnbinom.gf</code> generates one or more independent time series following the Gamma frailty model. The generated data has negative binomial marginal distribution and the underlying multivariate Gamma frailty an autoregressive covariance structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.groups(n, size, lambda, rho, tp, trend)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.groups_+3A_n">n</code></td>
<td>
<p>number of observations.</p>
</td></tr>
<tr><td><code id="get.groups_+3A_size">size</code></td>
<td>
<p>dispersion parameter (the shape parameter of the gamma mixing distribution). Must be strictly positive, need not be integer.</p>
</td></tr>
<tr><td><code id="get.groups_+3A_lambda">lambda</code></td>
<td>
<p>vector of means of trend parameters.</p>
</td></tr>
<tr><td><code id="get.groups_+3A_rho">rho</code></td>
<td>
<p>correlation coefficient of the underlying autoregressive Gamma frailty. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="get.groups_+3A_tp">tp</code></td>
<td>
<p>number of observed time points.</p>
</td></tr>
<tr><td><code id="get.groups_+3A_trend">trend</code></td>
<td>
<p>a string giving the trend which is to be simulated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function relies on <code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code> for creating data with underlying constant or exponential trends.
</p>


<h3>Value</h3>

<p><code>get.groups</code> returns a matrix of dimension <code>n</code> x <code>tp</code> with marginal negative binomial
distribution with means corresponding to trend parameters <code>lambda</code>, common dispersion parameter <code>size</code> and a correlation induce by <code>rho</code>,
the correlation coefficient of the autoregressive multivariate Gamma frailty.
</p>


<h3>Source</h3>

<p><code>rnbinom.gf</code> computes observations from a Gamma frailty model by <em>Fiocco et. al. 2009</em> using code contributed by Thomas Asendorf.
</p>


<h3>References</h3>

<p>Fiocco M, Putter H, Van Houwelingen JC, (2009), A new serially correlated gamma-frailty process for longitudinal count data <em>Biostatistics</em> Vol. 10, No. 2, pp. 245-257.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code> for information on the Gamma frailty model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>random&lt;-get.groups(n=c(1000,1000), size=c(0.5, 0.5), lambda=c(1, 2), rho=c(0.6, 0.6), tp=7,
  trend="constant")
head(random)

</code></pre>

<hr>
<h2 id='n.1subgroup'>Sample Size Calculation for a One Subgroup Design</h2><span id='topic+n.1subgroup'></span>

<h3>Description</h3>

<p><code>n.1subgroup</code> calculates the required sample size for proving a desired alternative when testing for
an effect in the full or subpopulation. See 'Details' for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n.1subgroup(
  alpha,
  beta,
  delta,
  sigma,
  tau,
  eps = 0.001,
  approx = c("conservative.t", "liberal.t", "normal"),
  k = 1,
  nmax = 1000,
  nmin = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="n.1subgroup_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_beta">beta</code></td>
<td>
<p>type II error (power=1-beta) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_delta">delta</code></td>
<td>
<p>vector of treatment effects to be proven, c(outside subgroup, inside subgroup).</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_sigma">sigma</code></td>
<td>
<p>vector of standard deviations, c(outside subgroup, inside subgroup).</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_tau">tau</code></td>
<td>
<p>subgroup prevalence.</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_eps">eps</code></td>
<td>
<p>precision parameter concerning the power calculation in the iterative sample size search algorithm.</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_approx">approx</code></td>
<td>
<p>approximation method: Use a conservative multivariate t distribution (&quot;conservative.t&quot;), a liberal multivariate t distribution (&quot;liberal.t&quot;) or a multivariate normal distribution (&quot;normal&quot;) to approximate the joint distribution of the standardized teststatistics.</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_nmax">nmax</code></td>
<td>
<p>maximum total sample size.</p>
</td></tr>
<tr><td><code id="n.1subgroup_+3A_nmin">nmin</code></td>
<td>
<p>minimum total sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs sample size estimation in a design with a subgroup within a full population where we want to test for treatment effects between a control and a treatment group. Since patients from the subgroup might potentially benefit from the treatment more than patients not included in that subgroup, one might prefer testing hypothesis cercerning the full population and the subpopulation at the same time. Here standardized test statistics are their joined distributions are used to calculate the
required sample size for the control and treatment group to prove an existing
alternative <code>delta</code> with a specified power 1-<code>beta</code> when testing the global null hypothesis <code class="reqn">H_0: \Delta_F=\Delta_S=0</code> to level <code>alpha</code>.
</p>
<p>For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the
sample size allocation factor, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>


<h3>Value</h3>

<p><code>n.1subgroup</code> returns the required sample size within the control group and treatment group.
</p>


<h3>Source</h3>

<p><code>n.1subgroup</code> uses code contributed by Marius Placzek.
</p>


<h3>See Also</h3>

<p>#' <code><a href="#topic+bssr.1subgroup">bssr.1subgroup</a></code> for blinded sample size reestimation within a running trial.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Calculate required sample size to correctly reject with
#80% probability when testing the global Nullhypothesis H_0: Delta_F=Delta_S = 0
#assuming the true effect Delta_S=1 is in the subgroup (no effect outside of the subgroup)
#with subgroup prevalence tau=0.4.
#The variances in and outside of the subgroup are unequal, sigma=c(1,1.2).

estimate&lt;-n.1subgroup(alpha=0.025,beta=0.1,delta=c(0,1),sigma=c(1,1.2),tau=0.4,eps=0.0001,
approx="conservative.t",k=2)
summary(estimate)
</code></pre>

<hr>
<h2 id='n.gee.1subgroup'>Sample Size estimation for longitudinal GEE models</h2><span id='topic+n.gee.1subgroup'></span>

<h3>Description</h3>

<p><code>n.gee.1subgroup</code> calculates the required sample size for proving a desired alternative when testing a regression coefficients in a full and/or a subpopulation. See 'Details' for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n.gee.1subgroup(
  alpha,
  tail = "both",
  beta = NULL,
  delta,
  sigma,
  tau = 0.5,
  k = 1,
  npow = NULL,
  nmax = Inf
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="n.gee.1subgroup_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="n.gee.1subgroup_+3A_tail">tail</code></td>
<td>
<p>which type of test is used, e.g. which quartile und H0 is calculated.</p>
</td></tr>
<tr><td><code id="n.gee.1subgroup_+3A_beta">beta</code></td>
<td>
<p>type II error (power=1-beta) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="n.gee.1subgroup_+3A_delta">delta</code></td>
<td>
<p>vector of estimated treatment effect in overall and sub population, c(overall population, only subpopulation).</p>
</td></tr>
<tr><td><code id="n.gee.1subgroup_+3A_sigma">sigma</code></td>
<td>
<p>vector of estimated standard deviations, c(full population, subpopulation). See 'Details'.</p>
</td></tr>
<tr><td><code id="n.gee.1subgroup_+3A_tau">tau</code></td>
<td>
<p>subgroup prevalence.</p>
</td></tr>
<tr><td><code id="n.gee.1subgroup_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between control and treatment: see 'Details'.</p>
</td></tr>
<tr><td><code id="n.gee.1subgroup_+3A_npow">npow</code></td>
<td>
<p>calculates power of a test if <code>npow</code> is a sample size.</p>
</td></tr>
<tr><td><code id="n.gee.1subgroup_+3A_nmax">nmax</code></td>
<td>
<p>maximum total sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs a sample size estimation in a design with a nested subgroup within an overall population. To calculate the required sample only the value of tested regressor needs to inserted as <code>delta</code>. <code>sigma</code> is the variance of that regressor.
The power for the global null hypothesis is given by 1-<code>beta</code> and <code>alpha</code> specifies the false positve level for rejecting <code class="reqn">H_0: \Delta_F=\Delta_S=0</code> to level <code>alpha</code>.
</p>
<p>Here argument <code>k</code> denotes the
sample size allocation factor between treatment groups, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>


<h3>Value</h3>

<p><code>n.gee.1subgroup</code> returns the required sample size within the control group and treatment group.
</p>


<h3>Source</h3>

<p><code>n.gee.1subgroup</code> uses code contributed by Roland Gerard Gera.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bssr.1subgroup">bssr.1subgroup</a></code> for blinded sample size re-estimation within a running trial and <code><a href="#topic+sandwich">sandwich</a></code> for estimating asymptotic covarianc mtrices in GEE models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Calculate required sample size to correctly reject Null with
#80% probability when testing global Nullhypothesis H_0: Delta_F=Delta_S = 0, while
#assuming the coefficient in and outside of the subgroup is Delta=c(0.1,0,1) with a
#subgroup-prevalence of tau=0.4.
#The variances of regressors in delta when variances are unequal sigma=c(0.8,0.4).

estimate&lt;-n.gee.1subgroup(alpha=0.05,beta=0.2,delta=c(0.1,0.1),sigma=c(0.8,0.4),tau=0.4, k=1)
summary(estimate)

#Alternatively we can estimate the power our study would have
#if we know the effect in and outside our subgroup as
#well as the variance of the regressors. Here we
#estimate that only 300 Patiens total can be recruited and we are interested
#in the power that would give us.

n.gee.1subgroup(alpha=0.05,delta=c(0.1,0.1),sigma=c(0.8,0.4),tau=0.4, k=1, npow=300)

</code></pre>

<hr>
<h2 id='n.nb.gf'>Sample Size Calculation for Comparing Two Groups when observing Longitudinal Count Data with marginal Negative Binomial Distribution and underlying Gamma Frailty with Autoregressive Correlation Structure of Order One</h2><span id='topic+n.nb.gf'></span>

<h3>Description</h3>

<p><code>n.nb.gf</code> calculates required sample sizes for testing trend parameters in a Gamma frailty model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n.nb.gf(
  alpha = 0.025,
  power = 0.8,
  lambda,
  size,
  rho,
  tp,
  k = 1,
  h,
  hgrad,
  h0,
  trend = c("constant", "exponential", "custom"),
  approx = 20
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="n.nb.gf_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_power">power</code></td>
<td>
<p>power (1 - type II error) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_lambda">lambda</code></td>
<td>
<p>the set of trend parameters assumed to be true at the beginning prior to trial onset</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_size">size</code></td>
<td>
<p>dispersion parameter (the shape parameter of the gamma mixing distribution). Must be strictly positive, need not be integer (see <code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code>).</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_rho">rho</code></td>
<td>
<p>correlation coefficient of the autoregressive correlation structure of the underlying Gamma frailty. Must be between 0 and 1 (see <code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code>).</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_tp">tp</code></td>
<td>
<p>number of observed time points. (see <code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code>)</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_h">h</code></td>
<td>
<p>hypothesis to be tested. The function must return a single value when evaluated on lambda.</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_hgrad">hgrad</code></td>
<td>
<p>gradient of function h</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_h0">h0</code></td>
<td>
<p>the value against which h is tested, see 'Details'.</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_trend">trend</code></td>
<td>
<p>the trend which assumed to underlying in the data.</p>
</td></tr>
<tr><td><code id="n.nb.gf_+3A_approx">approx</code></td>
<td>
<p>numer of iterations in numerical calculation of the sandwich estimator, see 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates required samples sizes for testing trend parameters of trends in longitudinal negative binomial data. The underlying
one-sided null-hypothesis is defined by <code class="reqn">H_0: h(\eta, \lambda) \geq h_0</code> vs. the alternative <code class="reqn">H_A: h(\eta, \lambda) &lt; h_0</code>. For testing
these hypothesis, the program therefore requires a function <code>h</code> and a value <code>h0</code>.
</p>
<p><code>n.nb.gf</code> gives back the required sample size for the control and treatment group, to prove an existing alternative <code class="reqn">h(\eta, \lambda) - h_0</code>
with a power of <code>power</code> when testing at level <code>alpha</code>. For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the
sample size allocation factor, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>
<p>When calculating the expected sandwich estimator required for the sample size, certain terms can not be computed analytically and have
to be approximated numerically. The value <code>approx</code> defines how close the approximation is to the true expected sandwich estimator.
High values of <code>approx</code> provide better approximations but are compuationally more expensive.
</p>


<h3>Value</h3>

<p><code>n.nb.gf</code> returns the required sample size within the control group and treatment group.
</p>


<h3>Source</h3>

<p><code>n.nb.gf</code> uses code contributed by Thomas Asendorf.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code> for information on the Gamma frailty model, <code><a href="#topic+fit.nb.gf">fit.nb.gf</a></code> for calculating
initial parameters required when performing sample size estimation, <code><a href="#topic+bssr.nb.gf">bssr.nb.gf</a></code> for blinded
sample size reestimation within a running trial.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##The example is commented as it may take longer than 10 seconds to run.
##Please uncomment prior to execution.

##Example for constant rates
#h&lt;-function(lambda.eta){
#   lambda.eta[2]
#}
#hgrad&lt;-function(lambda.eta){
#   c(0, 1, 0)
#}

##We assume the rate in the control group to be exp(lambda[1]) = exp(0) and an
##effect of lambda[2] = -0.3. The \code{size} is assumed to be 1 and the correlation
##coefficient \code{\rho} 0.5. At the end of the study, we would like to test
##the treatment effect specified in lambda[2], and therefore define function
##\code{h} and value \code{h0} accordingly.

#estimate&lt;-n.nb.gf(lambda=c(0,-0.3), size=1, rho=1, tp=6, k=1, h=h, hgrad=hgrad,
#   h0=0.2, trend="constant", approx=20)
#summary(estimate)

##Example for exponential trend
#h&lt;-function(lambda.eta){
#   lambda.eta[3]
#}
#hgrad&lt;-function(lambda.eta){
#   c(0, 0, 1, 0)
#}

#estimate&lt;-n.nb.gf(lambda=c(0, 0, -0.3/6), size=1, rho=0.5, tp=7, k=1, h=h, hgrad=hgrad,
#   h0=0, trend="exponential", approx=20)
#summary(estimate)

</code></pre>

<hr>
<h2 id='n.nb.inar1'>Sample Size Calculation for Comparing Two Groups when observing Longitudinal Count Data with marginal Negative Binomial Distribution and Autoregressive Correlation Structure of Order One: NB-INAR(1)</h2><span id='topic+n.nb.inar1'></span>

<h3>Description</h3>

<p><code>n.nb.inar1</code> calculates the required sample size for proving a desired alternative when testing for
a rate ratio between two groups unequal to one. Also gives back power for a specified sample size. See 'Details' for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n.nb.inar1(
  alpha,
  power = NULL,
  delta,
  muC,
  size,
  rho,
  tp,
  k,
  npow = NULL,
  nmax = Inf
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="n.nb.inar1_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_power">power</code></td>
<td>
<p>power (1 - type II error) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_delta">delta</code></td>
<td>
<p>the rate ratio which is to be proven.</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_muc">muC</code></td>
<td>
<p>the rate observed within the control group.</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_size">size</code></td>
<td>
<p>dispersion parameter (the shape parameter of the gamma mixing distribution). Must be strictly positive, need not be integer (see <code><a href="#topic+rnbinom.inar1">rnbinom.inar1</a></code>).</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_rho">rho</code></td>
<td>
<p>correlation coefficient of the underlying autoregressive correlation structure. Must be between 0 and 1 (see <code><a href="#topic+rnbinom.inar1">rnbinom.inar1</a></code>).</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_tp">tp</code></td>
<td>
<p>number of observed time points. (see <code><a href="#topic+rnbinom.inar1">rnbinom.inar1</a></code>)</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_npow">npow</code></td>
<td>
<p>sample size for which a power is to be calculated. Can not be specified if power is also specified.</p>
</td></tr>
<tr><td><code id="n.nb.inar1_+3A_nmax">nmax</code></td>
<td>
<p>maximum total sample size of both groups. If maximum is reached a warning message is broadcasted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When testing for differences between rates <code class="reqn">\mu_C</code> and <code class="reqn">\mu_T</code> of two groups, a control and a treatment group respectively, we usually
test for the ratio between the two rates, i.e. <code class="reqn">\mu_T/\mu_C = 1</code>. The ratio of the two rates is refered to as <code class="reqn">\delta</code>, i.e.
<code class="reqn">\delta = \mu_T/\mu_C</code>.
</p>
<p><code>n.nb.inar1</code> gives back the required sample size for the control and treatment group required to prove an existing
alternative <code>theta</code> with a specified power <code>power</code> when testing the null hypothesis <code class="reqn">H_0: \mu_T/\mu_C \ge 1</code> to level <code>alpha</code>.
If <code>power</code> is not specified but instead <code>npow</code>, the power achieved with a total sample size of <code>npow</code> is calculated.
</p>
<p>For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the
sample size allocation factor, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>


<h3>Value</h3>

<p><code>rnbinom.inar1</code> returns the required sample size within the control group and treatment group.
</p>


<h3>Source</h3>

<p><code>rnbinom.inar1</code> uses code contributed by Thomas Asendorf.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.inar1">rnbinom.inar1</a></code> for information on the NB-INAR(1) model, <code><a href="#topic+fit.nb.inar1">fit.nb.inar1</a></code> for calculating
initial parameters required when performing sample size estimation, <code><a href="#topic+bssr.nb.inar1">bssr.nb.inar1</a></code> for blinded
sample size reestimation within a running trial.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Calculate required sample size to find significant difference with
#80% probability when testing the Nullhypothesis H_0: mu_T/mu_C &gt;= 1
#assuming the true effect delta is 0.8 and rate, size and correlation
#parameter in the control group are 2, 1 and 0.5, respectively.

estimate&lt;-n.nb.inar1(alpha=0.025, power=0.8, delta=0.8, muC=2, size=1, rho=0.5, tp=7, k=1)
summary(estimate)

estimate&lt;-n.nb.inar1(alpha=0.025, npow=200, delta=0.8, muC=2, size=1, rho=0.5, tp=7, k=1)
summary(estimate)
</code></pre>

<hr>
<h2 id='r.1subgroup'>Generate dataset of normal distributed observations in a one subgroup design</h2><span id='topic+r.1subgroup'></span>

<h3>Description</h3>

<p><code>r.1subgroup</code> generates data for a design with one subgroup within a full population. Each observation is normal distributed with mean 0 in the placebo group and a potential effect in the treatment group. Whether the effect is solely in the subgroup or additionally a certain amount outside of the subgroup can be specified as well as potentially different variances within the subgroup and outside of the subgroup.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.1subgroup(n, delta, sigma, tau, fix.tau = c("YES", "NO"), k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r.1subgroup_+3A_n">n</code></td>
<td>
<p>number of observations. If length(n) &gt; 1, the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="r.1subgroup_+3A_delta">delta</code></td>
<td>
<p>vector of treatment effects in the treatment group, c(outside subgroup, within subgroup).</p>
</td></tr>
<tr><td><code id="r.1subgroup_+3A_sigma">sigma</code></td>
<td>
<p>vector of standard deviations, c(outside subgroup, inside subgroup).</p>
</td></tr>
<tr><td><code id="r.1subgroup_+3A_tau">tau</code></td>
<td>
<p>subgroup prevalence.</p>
</td></tr>
<tr><td><code id="r.1subgroup_+3A_fix.tau">fix.tau</code></td>
<td>
<p>subgroup prevalence fix or simulated according to tau, see 'Details'.</p>
</td></tr>
<tr><td><code id="r.1subgroup_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>delta</code><code class="reqn">=(\Delta_F\S, \Delta_S)'</code> and <code>sigma</code><code class="reqn">=(\sigma_F\S, \sigma_S)'</code>
this function <code>r.1subgroup</code> generates data as follows:
</p>
<p>Placebo group outside of subgroup <code class="reqn">~N(0,\sigma^2_F\S)</code>,
Placebo group within subgroup <code class="reqn">~N(0,\sigma^2_S)</code>,
Treatment group outside of subgroup <code class="reqn">~N(\Delta_F\S,\sigma^2_F\S)</code>,
Treatment group within subgroup <code class="reqn">~N(\Delta_S,\sigma^2_S)</code>.
</p>
<p>If <code>fix.tau=YES</code> the subgroup size is generated according to the prevalence <code>tau</code>, i.e. <code class="reqn">n_S=\tau*n</code>.
If <code>fix.tau=YES</code>, then each new generated observations probability to belong to the subgroup is <code class="reqn">Ber(\code{tau})</code>
distributed and therefore only <code class="reqn">E(n_s)=\tau*n</code> holds.
</p>
<p>The argument <code>k</code> is the
sample size allocation factor, i.e. let <code class="reqn">n_C</code> and <code class="reqn">n_T</code> denote the sample sizes of of the control and
treatment group, respectively, then <code class="reqn">k = n_T/n_C</code>.
</p>


<h3>Value</h3>

<p><code>r.1subgroup</code> returns a data matrix of dimension <code>n</code> x <code>3</code>. The first column <code>TrPl</code> defines whether
the observation belongs to the treatment group (<code>TrPl=0</code>) or to the placebo group (<code>TrPl=1</code>). Second column
contains the grouping variable <code>FS</code>. For <code>FS=1</code> the observation stems from the subgroup, for <code>FS=0</code> from
the full population without the subgroup. In the last column <code>value</code> the observation can be found.
between time points.
</p>


<h3>Source</h3>

<p><code>r.1subgroup</code> uses code contributed by Marius Placzek.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(142)
random&lt;-r.1subgroup(n=50, delta=c(0,1), sigma=c(1,1), tau=0.4, fix.tau="YES", k=2)
random 
</code></pre>

<hr>
<h2 id='r.gee.1subgroup'>Generate dataset of normal distributed repeated observations in a one subgroup design</h2><span id='topic+r.gee.1subgroup'></span>

<h3>Description</h3>

<p><code>r.gee.1subgroup</code> generates data for a design with one subgroup within a full population. Each baseline-observation is normal distributed with mean </p>
<p style="text-align: center;"><code class="reqn">\beta_0</code>
</p>
<p> in placebo group and </p>
<p style="text-align: center;"><code class="reqn">\beta_0+\beta_1</code>
</p>
<p> in treatment group.
Measurements after baseline have mean </p>
<p style="text-align: center;"><code class="reqn">\beta_0+\beta_2*t</code>
</p>
<p> in placebo group and </p>
<p style="text-align: center;"><code class="reqn">\beta_0+\beta_1+\beta_2*t+\beta_3*t</code>
</p>
<p> in treatment group where </p>
<p style="text-align: center;"><code class="reqn">t</code>
</p>
<p> is the measurement time. Whether the effect can be found solely in the subgroup or additionally a certain amount outside of the subgroup can be specified as well as a potential different covariance-structure within subgroup and in the complementary subgroup.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.gee.1subgroup(n, reg, sigma, rho, theta, tau, k, Time, OD)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r.gee.1subgroup_+3A_n">n</code></td>
<td>
<p>overall sample size for the overall population</p>
</td></tr>
<tr><td><code id="r.gee.1subgroup_+3A_reg">reg</code></td>
<td>
<p>list containing coefficients </p>
<p style="text-align: center;"><code class="reqn">\beta_0</code>
</p>
<p> to </p>
<p style="text-align: center;"><code class="reqn">\beta_0</code>
</p>
<p> for complementary population, <code>reg[[1]]</code> and subpopulation, <code>reg[[2]]</code>: see 'Details'.</p>
</td></tr>
<tr><td><code id="r.gee.1subgroup_+3A_sigma">sigma</code></td>
<td>
<p>vector with standard deviations for generated observations c(complementary population, subpopulation).</p>
</td></tr>
<tr><td><code id="r.gee.1subgroup_+3A_rho">rho</code></td>
<td>
<p>variable used together with <code>theta</code> to describe correlation between two adjacent timepoints: see 'Details'.</p>
</td></tr>
<tr><td><code id="r.gee.1subgroup_+3A_theta">theta</code></td>
<td>
<p>variable used together with <code>rho</code> to describe correlation between two adjacent timepoints: see 'Details'.</p>
</td></tr>
<tr><td><code id="r.gee.1subgroup_+3A_tau">tau</code></td>
<td>
<p>subgroup prevalence.</p>
</td></tr>
<tr><td><code id="r.gee.1subgroup_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between treatment groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="r.gee.1subgroup_+3A_time">Time</code></td>
<td>
<p>list of timepoints <code class="reqn">t</code> that have to be generated: see 'Details'.</p>
</td></tr>
<tr><td><code id="r.gee.1subgroup_+3A_od">OD</code></td>
<td>
<p>percentage of observed overall dropout at last timepoint: see 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>reg</code><code>list</code>(c(<code class="reqn">\beta_0^F\S,\beta_1^F\S,\beta_2^F\S,\beta_3^F\S</code>), c(<code class="reqn">\beta_0^S,\beta_1^S,\beta_2^S,\beta_3^S</code>)) and variances <code>sigma</code>=(<code class="reqn">\sigma_F\S, \sigma_S</code>) function <code>r.gee.1subgroup</code> generates data given correlation-variables <code class="reqn">\rho</code> and <code class="reqn">\theta</code> as follows (and let t=0 be the baseline measurement):
</p>
<p>Placebo group - complementary population <code class="reqn">y_{it}=N(\beta_0+\beta_2*t,\sigma_F\S)</code>,
Placebo group - within subgroup <code class="reqn">y_{it}=N(\beta_0+\beta_2*t,\sigma_S)</code>,
Treatment group - complementary population <code class="reqn">y_{it}=N(\beta_0+\beta_1+\beta_2*t+\beta_3*t,\sigma_F\S)</code>,
Treatment group - within subgroup <code class="reqn">y_{it}=N(\beta_0+\beta_1+\beta_2*t+\beta_3*t,\sigma_S)</code>.
Correlation between measurements - <code class="reqn">corr(\epsilon_it,\epsilon_io)=\rho^{(t-o)^\theta}</code>
</p>
<p>Argument <code>k</code> is the sample size allocation factor, i.e. the ratio between control and treatment. Let <code class="reqn">n_C</code> and <code class="reqn">n_T</code> denote sample sizes of control and treatment groups respectively, then <code class="reqn">k = n_T/n_C</code>.
</p>
<p>Argument <code>Time</code> is the vector denoting all measuring-times, i. e. every value for <code class="reqn">t</code>.
</p>
<p>Argument <code>OD</code> sets the overall dropout rate observed at the last timepoint. For <code>OD</code>=0.5, 50 percent of all observation had a dropout event at some point. If a subject experienced a dropout the starting time of the dropout is equally distributed over all timepoints.
</p>


<h3>Value</h3>

<p><code>r.gee.1subgroup</code> returns a list with 7 different entries. Every Matrix rows are the simulated subjects and the columns are the observed time points.
</p>
<p>The first list element is a vector containing subject ids.
The second element contains a matrix with the outcomes of a subject with row being the subjects and columns being the measuring-timepoints
Elements 3 to 5 return matrices with the information of which patients have baseline-measurements, which patients belong to treatment and which to control and what are the observed timepoints for each patient respectively.
The sixth entry returns a matrix which contains the residuals of each measurement.
The seventh entry returns the sub-population identification.
</p>


<h3>Source</h3>

<p><code>r.gee.1subgroup</code> uses code contributed by Roland Gerard Gera
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(2015)
dataset&lt;-r.gee.1subgroup(n=200, reg=list(c(0,0,0,0.1),c(0,0,0,0.1)), sigma=c(3,2.5),
tau=0.5, rho=0.25, theta=1, k=1.5, Time=c(0:5), OD=0)
dataset
</code></pre>

<hr>
<h2 id='rnbinom.gf'>Generate Time Series with Negative Binomial Distribution and Multivariate Gamma Frailty with Autoregressive Correlation Structure of Order One</h2><span id='topic+rnbinom.gf'></span>

<h3>Description</h3>

<p><code>rnbinom.gf</code> generates one or more independent time series following the Gamma frailty model. The generated data has negative binomial marginal distribution and the underlying multivariate Gamma frailty an autoregressive covariance structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnbinom.gf(n, size, mu, rho, tp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rnbinom.gf_+3A_n">n</code></td>
<td>
<p>number of observations. If length(n) &gt; 1, the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="rnbinom.gf_+3A_size">size</code></td>
<td>
<p>dispersion parameter (the shape parameter of the gamma mixing distribution). Must be strictly positive, need not be integer.</p>
</td></tr>
<tr><td><code id="rnbinom.gf_+3A_mu">mu</code></td>
<td>
<p>vector of means of time points: see 'Details'.</p>
</td></tr>
<tr><td><code id="rnbinom.gf_+3A_rho">rho</code></td>
<td>
<p>correlation coefficient of the underlying autoregressive Gamma frailty. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="rnbinom.gf_+3A_tp">tp</code></td>
<td>
<p>number of observed time points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generated marginal negative binomial distribution with mean <code>mu</code> = <code class="reqn">\mu</code> and <code>size</code> = <code class="reqn">\eta</code> has density
</p>
<p style="text-align: center;"><code class="reqn">(\mu/(\mu+\eta))^x \Gamma(x + \eta)/(\Gamma(x+1)\Gamma(\eta)) (\eta/(\mu+\eta))^\eta</code>
</p>

<p>for <code class="reqn">0 &lt; \mu</code>, <code class="reqn">0 &lt; \eta</code> and <code class="reqn">x=0, 1, 2, ...</code>. Hereby, each entry of vector <code>mu</code> corresponds to
one time point. Therefore, each timepoint can have its distinct mean.
</p>
<p>Within the Gamma frailty model, the correlation between two frailties of time points <code class="reqn">t</code> and <code class="reqn">s</code> for <code>rho</code> = <code class="reqn">\rho</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">\rho^|t-s|</code>
</p>

<p>for <code class="reqn">0 \le \rho \le 1</code>. Note: this does not correspond to the correlation of observations.
</p>


<h3>Value</h3>

<p><code>rnbinom.gf</code> returns a matrix of dimension <code>n</code> x <code>tp</code> with marginal negative binomial
distribution with means <code>mu</code>, common dispersion parameter <code>size</code> and a correlation induce by the autoregressive
multivariate Gamma frailty.
</p>


<h3>Source</h3>

<p><code>rnbinom.gf</code> computes observations from a Gamma frailty model by <em>Fiocco et. al. 2009</em> using code contributed by Thomas Asendorf.
</p>


<h3>References</h3>

<p>Fiocco M, Putter H, Van Houwelingen JC, (2009), A new serially correlated gamma-frailty process for longitudinal count data <em>Biostatistics</em> Vol. 10, No. 2, pp. 245-257.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
random&lt;-rnbinom.gf(n=1000, size=0.6, mu=1:6, rho=0.8, tp=6)
cor(random)

#Check the marginal distribution of time point 3
plot(table(random[,3])/1000, xlab="Probability", ylab="Observation")
lines(0:26, dnbinom(0:26, mu=3, size=0.6), col="red")
legend("topright",legend=c("Theoretical Marginal Distribution", "Observed Distribution"),
  col=c("red", "black"), lty=1, lwd=c(1,2))

</code></pre>

<hr>
<h2 id='rnbinom.inar1'>Generate Time Series with Negative Binomial Distribution and Autoregressive Correlation Structure of Order One: NB-INAR(1)</h2><span id='topic+rnbinom.inar1'></span>

<h3>Description</h3>

<p><code>rnbinom.inar1</code> generates one or more independent time series following the NB-INAR(1) model. The generated data has negative binomial marginal distribution and an autoregressive covariance structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnbinom.inar1(n, size, mu, rho, tp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rnbinom.inar1_+3A_n">n</code></td>
<td>
<p>number of observations. If length(n) &gt; 1, the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="rnbinom.inar1_+3A_size">size</code></td>
<td>
<p>dispersion parameter (the shape parameter of the gamma mixing distribution). Must be strictly positive, need not be integer.</p>
</td></tr>
<tr><td><code id="rnbinom.inar1_+3A_mu">mu</code></td>
<td>
<p>parametrization via mean: see 'Details'.</p>
</td></tr>
<tr><td><code id="rnbinom.inar1_+3A_rho">rho</code></td>
<td>
<p>correlation coefficient of the underlying autoregressive correlation structure. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="rnbinom.inar1_+3A_tp">tp</code></td>
<td>
<p>number of observed time points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generated marginal negative binomial distribution with mean <code>mu</code> = <code class="reqn">\mu</code> and <code>size</code> = <code class="reqn">\eta</code> has density
</p>
<p style="text-align: center;"><code class="reqn">(\mu/(\mu+\eta))^x \Gamma(x + \eta)/(\Gamma(x+1)\Gamma(\eta)) (\eta/(\mu+\eta))^\eta</code>
</p>

<p>for <code class="reqn">0 &lt; \mu</code>, <code class="reqn">0 &lt; \eta</code> and <code class="reqn">x=0, 1, 2, ...</code>.
</p>
<p>Within the NB-INAR(1) model, the correlation between two time points <code class="reqn">t</code> and <code class="reqn">s</code> for <code>rho</code> = <code class="reqn">\rho</code> is given through
</p>
<p style="text-align: center;"><code class="reqn">\rho^|t-s|</code>
</p>

<p>for <code class="reqn">0 \le \rho \le 1</code>.
</p>


<h3>Value</h3>

<p><code>rnbinom.inar1</code> returns a matrix of dimension <code>n</code> x <code>tp</code> with marginal negative binomial
distribution with mean <code>mu</code> and dispersion parameter <code>size</code>, and an autoregressive correlation structure
between time points.
</p>


<h3>Source</h3>

<p><code>rnbinom.inar1</code> computes a reparametrization of the NB-INAR(1) model by <em>McKenzie 1986</em> using code contributed by Thomas Asendorf.
</p>


<h3>References</h3>

<p>McKenzie Ed (1986), Autoregressive Moving-Average Processes with Negative-Binomial and Geometric Marginal Distributions. <em>Advances in Applied Probability</em> Vol. 18, No. 3, pp. 679-705.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
random&lt;-rnbinom.inar1(n=1000, size=0.6, mu=2, rho=0.8, tp=6)
cor(random)

#Check the marginal distribution of time point 3
plot(table(random[,3])/1000, xlab="Probability", ylab="Observation")
lines(0:26, dnbinom(0:26, mu=2, size=0.6), col="red")
legend("topright",legend=c("Theoretical Marginal Distribution", "Observed Distribution"), 
col=c("red", "black"), lty=1, lwd=c(1,2))

</code></pre>

<hr>
<h2 id='sandwich'>Calculate the robust covariance estimator for GEE given an</h2><span id='topic+sandwich'></span>

<h3>Description</h3>

<p><code>sandwich</code> calculates the covariance structure between timepoints given matrices <code>yCov</code>, <code>D</code>,<code>V</code> and <code>correctionmatrix</code>. This is done to be able to account for missingness in the Data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sandwich(
  yCov,
  D,
  V,
  correctionmatrix,
  missing = rep(0, dim(yCov)[[2]]),
  missingtype = c("none", "monotone", "intermittened")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sandwich_+3A_ycov">yCov</code></td>
<td>
<p><code class="reqn">yCov</code> matrix containing either an estimation for the covariance between timepoints or an empirical covariance matrix itsel. see 'Details'.</p>
</td></tr>
<tr><td><code id="sandwich_+3A_d">D</code></td>
<td>
<p><code class="reqn">D</code> denotes the mean matrix of all entries of <code class="reqn">\Delta\mu_i/\delta\beta</code>, where this is the average over all <code>i</code> patiens. see 'Details'.</p>
</td></tr>
<tr><td><code id="sandwich_+3A_v">V</code></td>
<td>
<p><code class="reqn">V</code> denotes the working covariance matrix.  see 'Details'.</p>
</td></tr>
<tr><td><code id="sandwich_+3A_correctionmatrix">correctionmatrix</code></td>
<td>
<p>As of this version this matrix is needed to correct some calculations. see 'Details' to see for more details and how to correctly select matrices.</p>
</td></tr>
<tr><td><code id="sandwich_+3A_missing">missing</code></td>
<td>
<p>vector which denotes the probability to experience a dropout at each timepoint. If <code>missingtype</code> is <code>"none"</code> then all entries are 0.</p>
</td></tr>
<tr><td><code id="sandwich_+3A_missingtype">missingtype</code></td>
<td>
<p>String which describes the type of missingness occuring in the data. <code>none</code> if no missingnes occured, <code>"monotone"</code> if missing was monotone and <code>"intermittened"</code> if the missingness was independent across all timepoints.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>yCov</code> is either empirical or the estimated covariance-matrix between timepoints which is needed to calculate the sandwich estimator. This matrix can either be generated by estimating the empirical covariance matrix using existing data or by using function <code>gen_cov_cor</code> to calculate a estimation for the covariance.
</p>
<p><code>D</code> denotes the estimation of <code class="reqn">n^-1* \sum_i^N \Delta\mu_i/\delta\beta</code>, which means that <code class="reqn">D=E(D_i)</code>. As of yet this has the unfortunate side effect that E(D_i
</p>


<h3>Value</h3>

<p><code>sandwich</code> returns the robust covariance estimator of regression coefficients which are implicitly defined by <code>D</code>.
</p>


<h3>Source</h3>

<p><code>sandwich</code> computes the asymptotic sandwich covariance estimator and uses code contributed by Roland Gerard Gera.
</p>


<h3>References</h3>

<p>Liang Kung-Yee, Zeger Scott L. (1986); Jung Sin-Ho, Ahn Chul (2003); Wachtlin Daniel Kieser Meinhard (2013)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Let's assume we wish to calculate the robust variance estimator for  equation
#\eqn{y_{it}=\beta_0+\beta_1*I_{treat}+\beta_2*t+\beta_3*I _{treat}*t+\epsilon_{it}}.
#Furthermore we use the identitiy matrix as the working covariance matrix.
#The chance to get treatment is 60 percent and the observed timerange ranges from 0:5.

  ycov = gen_cov_cor(var = 3,rho = 0.25,theta = 1,Time = 0:5,cov = TRUE)
  D = matrix(c(1,0.6,0,0,
               1,0.6,1,0.6,
               1,0.6,2,1.2,
               1,0.6,3,1.8,
               1,0.6,4,2.4,
               1,0.6,5,3.0),nrow=4)

 D=t(D)
 V=diag(1,length(0:5))
 #We correct entries where E(D_i %*% D_i) is unequal to E(D_i)%*%E(D_i) (D %*% D).
 correctionmatrix=matrix(c(1,1,1,1,1,1/0.6,1,1/0.6,1,1,1,1,1,1/0.6,1,1/0.6),nrow=4)
 missingtype = "none"

 robust=sandwich(yCov=ycov,D=D,V=V,missingtype=missingtype,correctionmatrix=correctionmatrix)
 robust

</code></pre>

<hr>
<h2 id='sandwich2'>Generate Time Series with Negative Binomial Distribution and Autoregressive Correlation Structure of Order One: NB-INAR(1)</h2><span id='topic+sandwich2'></span>

<h3>Description</h3>

<p><code>rnbinom.inar1</code> generates one or more independent time series following the NB-INAR(1) model. The generated data has negative binomial marginal distribution and an autoregressive covariance structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sandwich2(sigma, rho, theta, k, Time, dropout, Model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sandwich2_+3A_sigma">sigma</code></td>
<td>
<p>assymptotic standard deviation for Full and subpupulation</p>
</td></tr>
<tr><td><code id="sandwich2_+3A_rho">rho</code></td>
<td>
<p>correlation coefficient of the underlying autoregressive correlation structure. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="sandwich2_+3A_theta">theta</code></td>
<td>
<p>correlation absorption coefficient if tinepoints are farther appart</p>
</td></tr>
<tr><td><code id="sandwich2_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="sandwich2_+3A_time">Time</code></td>
<td>
<p>vector of measured timepoints</p>
</td></tr>
<tr><td><code id="sandwich2_+3A_dropout">dropout</code></td>
<td>
<p>vector describing the percentage of dropout in every timepoint</p>
</td></tr>
<tr><td><code id="sandwich2_+3A_model">Model</code></td>
<td>
<p>either 1 or 2, describing if 4-regressor or 3-regressor model was used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generated marginal negative binomial distribution with mean <code>mu</code> = <code class="reqn">\mu</code> and <code>size</code> = <code class="reqn">\eta</code> has density
</p>
<p style="text-align: center;"><code class="reqn">(\mu/(\mu+\eta))^x \Gamma(x + \eta)/(\Gamma(x+1)\Gamma(\eta)) (\eta/(\mu+\eta))^\eta</code>
</p>

<p>for <code class="reqn">0 &lt; \mu</code>, <code class="reqn">0 &lt; \eta</code> and <code class="reqn">x=0, 1, 2, ...</code>.
</p>
<p>Within the NB-INAR(1) model, the correlation between two time points <code class="reqn">t</code> and <code class="reqn">s</code> for <code>rho</code> = <code class="reqn">\rho</code> is given through
</p>
<p style="text-align: center;"><code class="reqn">\rho^|t-s|</code>
</p>

<p>for <code class="reqn">0 \le \rho \le 1</code>.
</p>


<h3>Value</h3>

<p><code>rnbinom.inar1</code> returns a matrix of dimension <code>n</code> x <code>tp</code> with marginal negative binomial
distribution with mean <code>mu</code> and dispersion parameter <code>size</code>, and an autoregressive correlation structure
between time points.
</p>


<h3>Source</h3>

<p><code>rnbinom.inar1</code> computes a reparametrization of the NB-INAR(1) model by <em>McKenzie 1986</em> using code contributed by Thomas Asendorf.
</p>


<h3>References</h3>

<p>McKenzie Ed (1986), Autoregressive Moving-Average Processes with Negative-Binomial and Geometric Marginal Distributions. <em>Advances in Applied Probability</em> Vol. 18, No. 3, pp. 679-705.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
random&lt;-rnbinom.inar1(n=1000, size=0.6, mu=2, rho=0.8, tp=6)
cor(random)

#Check the marginal distribution of time point 3
plot(table(random[,3])/1000, xlab="Probability", ylab="Observation")
lines(0:26, dnbinom(0:26, mu=2, size=0.6), col="red")
legend("topright",legend=c("Theoretical Marginal Distribution", "Observed Distribution"), 
col=c("red", "black"), lty=1, lwd=c(1,2))

</code></pre>

<hr>
<h2 id='sim.bssr.1subgroup'>Simulation of a One Subgroup Design with Internal Pilot Study</h2><span id='topic+sim.bssr.1subgroup'></span>

<h3>Description</h3>

<p>Given estimates of the treatment effects to be proven, the variances, and the prevalence,
<code>sim.bssr.1subgroup</code> calculates a initial sample size and performes a blinded sample size recalculation
after a prespecified number of subjects have been enrolled. Each oberservation is simulated and a final analysis executed.
Several variations are included, such as different approximations or sample size allocation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.bssr.1subgroup(
  nsim = 1000,
  alpha,
  beta,
  delta,
  sigma,
  tau,
  vdelta,
  vsigma,
  vtau,
  rec.at = 1/2,
  eps = 0.001,
  approx = c("conservative.t", "liberal.t", "normal"),
  df = c("n", "n1"),
  fix.tau = c("YES", "NO"),
  k = 1,
  adjust = c("YES", "NO")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.bssr.1subgroup_+3A_nsim">nsim</code></td>
<td>
<p>number of simulation runs.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_beta">beta</code></td>
<td>
<p>type II error (power=1-beta) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_delta">delta</code></td>
<td>
<p>vector of true treatment effects, c(outside subgroup, inside subgroup).</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_sigma">sigma</code></td>
<td>
<p>vector of true standard deviations, c(outside subgroup, inside subgroup).</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_tau">tau</code></td>
<td>
<p>subgroup prevalence.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_vdelta">vdelta</code></td>
<td>
<p>vector of treatment effects to be proven, c(outside subgroup, inside subgroup).</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_vsigma">vsigma</code></td>
<td>
<p>vector of assumed standard deviations, c(outside subgroup, inside subgroup).</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_vtau">vtau</code></td>
<td>
<p>expected subgroup prevalence.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_rec.at">rec.at</code></td>
<td>
<p>blinded sample size review is performed after <code>rec.at</code>*<code class="reqn">100\%</code> subjects of the initial sample size calculation.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_eps">eps</code></td>
<td>
<p>precision parameter concerning the power calculation in the iterative sample size search algorithm.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_approx">approx</code></td>
<td>
<p>approximation method: Use a conservative multivariate t distribution (&quot;conservative.t&quot;), a liberal multivariate t distribution (&quot;liberal.t&quot;) or a multivariate normal distribution (&quot;normal&quot;) to approximate the joint distribution of the standardized teststatistics.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_df">df</code></td>
<td>
<p>in case of a multivariate t distribution approximation, recalculate sample size with degrees of freedom depending on the size of the IPS (df=n1) or depending on the final sample size (df=n).</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_fix.tau">fix.tau</code></td>
<td>
<p>subgroup prevalence is fixed by design (e.g. determined by recruitment) or is simulated and has to be reestimated during the blinded review.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="sim.bssr.1subgroup_+3A_adjust">adjust</code></td>
<td>
<p>adjust blinded estimators for assumed treatment effect (&quot;YES&quot;,&quot;No&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function combines sample size estimation, blinded sample size reestimation and analysis in a design with a subgroup within a full population where we want to test for treatment effects between a control and a treatment group.
The required sample size for the control and treatment group to prove an existing
alternative <code>delta</code> with a specified power 1-<code>beta</code> when testing the global null hypothesis <code class="reqn">H_0: \Delta_F=\Delta_S=0</code> to level <code>alpha</code> is calculated prior to the study and then recalculated in an internal pilot study.
</p>
<p>For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the
sample size allocation factor, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>
<p>The parameter <code>df</code> provides a difference to the standard sample size calculation procedure implemented in <code><a href="#topic+n.1subgroup">n.1subgroup</a></code>.
When applying a multivariate t distribution approximation to approximate the joint distribution of the standardized test statistics it gives the opportunity to use degrees of freedom depending on the number of subjects in the IPS instead of degrees of freedom depending on the projected final sample size.
Note that this leads to better performance when dealing with extremely small subgroup sample sizes but significantly increases the calculated final sample size.
</p>


<h3>Value</h3>

<p><code>sim.bssr.1subgroup</code> returns a data.frame containing the mean recalculated sample size within the control group and treatment group and the achieved simulated power along with all relevant parameters.
</p>


<h3>Source</h3>

<p><code>sim.bssr.1subgroup</code> uses code contributed by Marius Placzek.
</p>


<h3>See Also</h3>

<p><code>sim.bssr.1subgroup</code> makes use of <code><a href="#topic+n.1subgroup">n.1subgroup</a></code>, <code><a href="#topic+bssr.1subgroup">bssr.1subgroup</a></code>, and <code><a href="#topic+r.1subgroup">r.1subgroup</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.bssr.1subgroup(nsim=10,alpha=0.025,beta=0.1,delta=c(0,1),sigma=c(1,1.3),tau=0.2,
vdelta=c(0,1),vsigma=c(1,1),vtau=0.3,eps=0.002, approx="conservative.t",df="n",
fix.tau="YES",k=1,adjust="NO")

</code></pre>

<hr>
<h2 id='sim.bssr.gee.1subgroup'>Simulation of a longitudinal one subgroup design with internal pilot Study</h2><span id='topic+sim.bssr.gee.1subgroup'></span>

<h3>Description</h3>

<p>Given estimates of the treatment effects to be proven, the variances, and the prevalence,
<code>sim.bssr.gee.1subgroup</code> calculates an initial sample size and performs a blinded sample size recalculation
after a pre-specified number of subjects have been enrolled. Each observation is simulated and a final analysis executed.
Several variations are included, such as different approximations or sample size allocation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.bssr.gee.1subgroup(
  nsim = 1000,
  alpha = 0.05,
  tail = "both",
  beta = 0.2,
  delta = c(0.1, 0.1),
  vdelta = c(0.1, 0.1),
  sigma_pop = c(3, 3),
  vsigma_pop = c(3, 3),
  tau = 0.5,
  rho = 0.25,
  vrho = 0.25,
  theta = 1,
  vtheta = 1,
  Time = 0:5,
  rec.at = 0.5,
  k = 1,
  model = 1,
  V = diag(rep(1, length(Time))),
  OD = 0,
  vdropout = rep(0, length(Time)),
  missingtype = "none",
  vmissingtype = "none",
  seed = 2015
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_nsim">nsim</code></td>
<td>
<p>number of simulation runs.</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_alpha">alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_tail">tail</code></td>
<td>
<p>which type of test is used, e.g. which quartile und H0 is calculated</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_beta">beta</code></td>
<td>
<p>type II error (power=1-beta) to which an alternative should be proven.</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_delta">delta</code></td>
<td>
<p>vector of true treatment effects, c(overall population, inside subgroup).</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_vdelta">vdelta</code></td>
<td>
<p>vector of treatment effects to be proven, c(overall population, inside subgroup).</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_sigma_pop">sigma_pop</code></td>
<td>
<p>vector of true standard deviations of the treatment effects, c(overall population, subgroup).</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_vsigma_pop">vsigma_pop</code></td>
<td>
<p>vector of assumed standard deviations, c(overall population, inside subgroup).</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_tau">tau</code></td>
<td>
<p>subgroup prevalence.</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_rho">rho</code></td>
<td>
<p>true correlation coefficient between two adjacent timepoints</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_vrho">vrho</code></td>
<td>
<p>initial expectation of the correlation coefficient between two adjacent timepoints</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_theta">theta</code></td>
<td>
<p>true correlation absorption coefficient if timepoints are farther apart</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_vtheta">vtheta</code></td>
<td>
<p>expected correlation absorption coefficient if timepoints are farther apart</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_time">Time</code></td>
<td>
<p>vector of measured timepoints</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_rec.at">rec.at</code></td>
<td>
<p>blinded sample size review is performed after <code>rec.at</code>*<code class="reqn">100\%</code> subjects of the initial sample size calculation.</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_k">k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_model">model</code></td>
<td>
<p>which of the two often revered statistical models should be used?: see 'Details'.</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_v">V</code></td>
<td>
<p>working covariance matrix.</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_od">OD</code></td>
<td>
<p>overall dropout measured at last timepoint</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_vdropout">vdropout</code></td>
<td>
<p>vector of expected dropouts per timepoint if missingness is to be expected</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_missingtype">missingtype</code></td>
<td>
<p>true missingtype underlying the missingness</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_vmissingtype">vmissingtype</code></td>
<td>
<p>initial assumptions about the missingtype underlying the missingness</p>
</td></tr>
<tr><td><code id="sim.bssr.gee.1subgroup_+3A_seed">seed</code></td>
<td>
<p>set seed value for the simulations to compare results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function combines sample size estimation, blinded sample size re-estimation and analysis in a design with a subgroup within a full population where we want to test for treatment effects between a control and a treatment group.
The required sample size for the control and treatment group to prove an existing
alternative <code>delta</code> with a specified power 1-<code>beta</code> when testing the global null hypothesis <code class="reqn">H_0: \Delta_F=\Delta_S=0</code> to level <code>alpha</code> is calculated prior to the study and then recalculated in an internal pilot study.
</p>
<p>For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the
sample size allocation factor, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>


<h3>Value</h3>

<p><code>sim.bssr.1subgroup</code> returns a data.frame containing the mean and variance of recalculated sample sizes within the control group and treatment group respectively and the achieved simulated power along with all relevant parameters.
</p>


<h3>Source</h3>

<p><code>sim.bssr.gee.1subgroup</code> uses code contributed by Roland Gerard Gera.
</p>


<h3>See Also</h3>

<p><code>sim.bssr.gee.1subgroup</code> makes use of <code><a href="#topic+n.gee.1subgroup">n.gee.1subgroup</a></code>, <code><a href="#topic+bssr.gee.1subgroup">bssr.gee.1subgroup</a></code>, and <code><a href="#topic+r.gee.1subgroup">r.gee.1subgroup</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.bssr.gee.1subgroup(nsim = 5,missingtype = "intermittened")

</code></pre>

<hr>
<h2 id='summary.bssrest'>Summarizing Blinded Sample Size Reestimation</h2><span id='topic+summary.bssrest'></span>

<h3>Description</h3>

<p><code>summary</code> method for class &quot;<code>bssrest</code>&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bssrest'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.bssrest_+3A_object">object</code></td>
<td>
<p>an object of class &quot;<code>bssrest</code>&quot;.</p>
</td></tr>
<tr><td><code id="summary.bssrest_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>summary.bssrest</code> gives back blinded sample size estimates. Furthermore, inputs are displayed for double checking.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+n.nb.inar1">n.nb.inar1</a></code> for initial sample size estimates within the NB-INAR(1) model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Calculate required sample size to find significant difference with
#80% probability when testing the Nullhypothesis H_0: mu_T/mu_C &gt;= 1
#assuming the true effect delta is 0.8 and rate, size and correlation
#parameter in the control group are 2, 1 and 0.5, respectively.

estimate&lt;-n.nb.inar1(alpha=0.025, power=0.8, delta=0.8, muC=2, size=1, rho=0.5, tp=7, k=1)

#Simulate data
set.seed(8)
placebo&lt;-rnbinom.inar1(n=50, size=1, mu=2, rho=0.5, tp=7)
treatment&lt;-rnbinom.inar1(n=50, size=1, mu=1.6, rho=0.5, tp=7)

#Blinded sample size reestimation
estimate&lt;-bssr.nb.inar1(alpha=0.025, power=0.8, delta=0.8, x=rbind(placebo, treatment),
  n=c(50,50), k=1)
summary(estimate)
</code></pre>

<hr>
<h2 id='summary.ssest'>Summarizing Initial Sample Size Estimates</h2><span id='topic+summary.ssest'></span>

<h3>Description</h3>

<p><code>summary</code> method for class &quot;<code>ssest</code>&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ssest'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.ssest_+3A_object">object</code></td>
<td>
<p>an object of class &quot;<code>ssest</code>&quot;.</p>
</td></tr>
<tr><td><code id="summary.ssest_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>summary.ssest</code> gives back initial sample size estimates required. Furthermore, inputs are displayed for double checking.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+n.nb.inar1">n.nb.inar1</a></code> for initial sample size estimates within the NB-INAR(1) model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Calculate required sample size to find significant difference with
#80% probability when testing the Nullhypothesis H_0: mu_T/mu_C &gt;= 1
#assuming the true effect delta is 0.8 and rate, size and correlation
#parameter in the control group are 2, 1 and 0.5, respectively.

estimate&lt;-n.nb.inar1(alpha=0.025, power=0.8, delta=0.8, muC=2, size=1, rho=0.5, tp=7, k=1)
summary(estimate)
</code></pre>

<hr>
<h2 id='test.nb.gf'>Testing Hypotheses in Gamma Frailty models</h2><span id='topic+test.nb.gf'></span>

<h3>Description</h3>

<p><code>test.nb.gf</code> tests hypotheses for certain trends in Gamma frailty models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.nb.gf(
  dataC,
  dataE,
  h,
  hgrad,
  h0 = 0,
  trend = c("constant", "exponential", "custom"),
  H0 = FALSE,
  one.sided = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.nb.gf_+3A_datac">dataC</code></td>
<td>
<p>a matrix or data frame containing count data from the control group. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="test.nb.gf_+3A_datae">dataE</code></td>
<td>
<p>a matrix or data frame containing count data from the experiment group. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="test.nb.gf_+3A_h">h</code></td>
<td>
<p>hypothesis to be tested. The function must return a single value when evaluated on lambda.</p>
</td></tr>
<tr><td><code id="test.nb.gf_+3A_hgrad">hgrad</code></td>
<td>
<p>gradient of function h</p>
</td></tr>
<tr><td><code id="test.nb.gf_+3A_h0">h0</code></td>
<td>
<p>the value against which h is tested, see 'Details'.</p>
</td></tr>
<tr><td><code id="test.nb.gf_+3A_trend">trend</code></td>
<td>
<p>the trend which assumed to be underlying in the data.</p>
</td></tr>
<tr><td><code id="test.nb.gf_+3A_h0">H0</code></td>
<td>
<p>indicates if the sandwich estimator is calculated under the null hypothesis or alternative.</p>
</td></tr>
<tr><td><code id="test.nb.gf_+3A_one.sided">one.sided</code></td>
<td>
<p>indicates if the hypothesis should be tested one- or two-sided</p>
</td></tr>
<tr><td><code id="test.nb.gf_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to function <code>fit.nb.gf()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the function <code>test.nb.gf</code> tests for the null hypothesis <code class="reqn">h(\eta, \lambda) = h_0</code> against the alternative <code class="reqn">h(\eta, \lambda) \neq h_0</code>.
The fitting function allows for incomplete follow up, but not for intermittent missingness.
</p>
<p>If parameter H0 is set to TRUE, the hessian and outer gradient are calculated under the assumption that <code>lambda[2]</code> <code class="reqn">\geq</code> <code>h0</code> if
<code>trend = "constant"</code> or <code>lambda[3]</code> <code class="reqn">\geq</code> <code>h0</code> if <code>trend = "exponential"</code>.
</p>


<h3>Value</h3>

<p><code>test.nb.gf</code> returns effect size, standard error, Z-statistic and p-value attained through standard normal approximation.
</p>


<h3>Source</h3>

<p><code>test.nb.gf</code> uses code contributed by Thomas Asendorf.
</p>


<h3>References</h3>

<p>Fiocco M, Putter H, Van Houwelingen JC, (2009), A new serially correlated gamma-frailty process for longitudinal count data <em>Biostatistics</em> Vol. 10, No. 2, pp. 245-257.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.gf">rnbinom.gf</a></code> for information on the Gamma Frailty model, <code><a href="#topic+n.nb.gf">n.nb.gf</a></code> for calculating
initial sample size required when performing inference, <code><a href="#topic+fit.nb.gf">fit.nb.gf</a></code> for calculating
initial parameters required when performing sample size estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create data from two groups
random&lt;-get.groups(n=c(100,100), size=c(0.7, 0.7), lambda=c(0.8, 0), rho=c(0.6, 0.6),
  tp=7, trend="constant")

#Define hypothesis
h&lt;-function(lambda.eta){
  lambda.eta[2]
}
hgrad&lt;-function(lambda.eta){
  c(0, 1, 0)
}
test.nb.gf(dataC=random[101:200,], dataE=random[1:100,], h=h, hgrad=hgrad, h0=0,
  trend="constant", H0=FALSE)
</code></pre>

<hr>
<h2 id='test.nb.inar1'>Testing Hypotheses in NB-INAR(1) model</h2><span id='topic+test.nb.inar1'></span>

<h3>Description</h3>

<p><code>test.nb.inar1</code> tests hypotheses for rate ratios of two groups in an NB-INAR(1) model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.nb.inar1(dataC, dataE, h0 = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.nb.inar1_+3A_datac">dataC</code></td>
<td>
<p>a matrix or data frame containing count data from the control group. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="test.nb.inar1_+3A_datae">dataE</code></td>
<td>
<p>a matrix or data frame containing count data from the experiment group. Columns correspond to time points, rows to observations.</p>
</td></tr>
<tr><td><code id="test.nb.inar1_+3A_h0">h0</code></td>
<td>
<p>the value against which h is tested, see 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the function <code>test.nb.inar1</code> tests for the null hypothesis <code class="reqn">\lambda_T/\lambda_C = h0</code> against the alternative <code class="reqn">\lambda_T/\lambda_C \neq h_0</code>.
For attaining estimates, method of moments estimators are used.
</p>


<h3>Value</h3>

<p><code>test.nb.inar1</code> returns effect size, standard error, Z-statistic and p-value attained through standard normal approximation.
</p>


<h3>Source</h3>

<p><code>test.nb.inar1</code> uses code contributed by Thomas Asendorf.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnbinom.inar1">rnbinom.inar1</a></code> for information on the NB-INAR(1) model, <code><a href="#topic+n.nb.inar1">n.nb.inar1</a></code> for calculating
initial sample size required when performing inference, <code><a href="#topic+fit.nb.inar1">fit.nb.inar1</a></code> for calculating
initial parameters required when performing sample size estimation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
groupE&lt;-rnbinom.inar1(n=1000, size=0.6, mu=2, rho=0.8, tp=6)
groupC&lt;-rnbinom.inar1(n=1000, size=0.6, mu=2, rho=0.8, tp=6)

test.nb.inar1(dataC=groupC, dataE=groupE, h0=1)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
