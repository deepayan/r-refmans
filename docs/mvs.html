<!DOCTYPE html><html><head><title>Help for package mvs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mvs}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mvs-package'><p>mvs: Methods for High-Dimensional Multi-View Learning.</p></a></li>
<li><a href='#coef.MVS'><p>Extract coefficients from an &quot;MVS&quot; object.</p></a></li>
<li><a href='#coef.StaPLR'><p>Extract coefficients from a &quot;StaPLR&quot; object.</p></a></li>
<li><a href='#MVS'><p>Multi-View Stacking</p></a></li>
<li><a href='#predict.MVS'><p>Make predictions from an &quot;MVS&quot; object.</p></a></li>
<li><a href='#predict.StaPLR'><p>Make predictions from a &quot;StaPLR&quot; object.</p></a></li>
<li><a href='#predict.StaPLRcoef'><p>Make predictions from a &quot;StaPLRcoef&quot; object.</p></a></li>
<li><a href='#StaPLR'><p>Stacked Penalized Logistic Regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Methods for High-Dimensional Multi-View Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods for high-dimensional multi-view learning based on the multi-view stacking (MVS) framework.
    For technical details on the MVS and stacked penalized logistic regression (StaPLR) methods see Van Loon, Fokkema, Szabo, &amp; De Rooij (2020) &lt;<a href="https://doi.org/10.1016%2Fj.inffus.2020.03.007">doi:10.1016/j.inffus.2020.03.007</a>&gt; and Van Loon et al. (2022) &lt;<a href="https://doi.org/10.3389%2Ffnins.2022.830630">doi:10.3389/fnins.2022.830630</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>glmnet (&ge; 1.9-8)</td>
</tr>
<tr>
<td>Imports:</td>
<td>foreach (&ge; 1.4.4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-14 09:50:02 UTC; woute</td>
</tr>
<tr>
<td>Author:</td>
<td>Wouter van Loon [aut, cre],
  Marjolein Fokkema [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Wouter van Loon &lt;w.s.van.loon@fsw.leidenuniv.nl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-15 11:00:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='mvs-package'>mvs: Methods for High-Dimensional Multi-View Learning.</h2><span id='topic+mvs-package'></span>

<h3>Description</h3>

<p>Methods for high-dimensional multi-view learning based on the multi-view stacking (MVS) framework. For technical details on the MVS and StaPLR methods see &lt;doi:10.1016/j.inffus.2020.03.007&gt; and &lt;doi:10.3389/fnins.2022.830630&gt;.
</p>


<h3>Author(s)</h3>

<p>Wouter van Loon [cre, aut]  &lt;<a href="mailto:w.s.van.loon@fsw.leidenuniv.nl">w.s.van.loon@fsw.leidenuniv.nl</a>&gt;
</p>
<p>Marjolein Fokkema [ctb]
</p>

<hr>
<h2 id='coef.MVS'>Extract coefficients from an &quot;MVS&quot; object.</h2><span id='topic+coef.MVS'></span>

<h3>Description</h3>

<p>Extract coefficients at each level from an &quot;MVS&quot; object at the CV-optimal values of the penalty parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MVS'
coef(object, cvlambda = "lambda.min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.MVS_+3A_object">object</code></td>
<td>
<p>An object of class &quot;MVS&quot;.</p>
</td></tr>
<tr><td><code id="coef.MVS_+3A_cvlambda">cvlambda</code></td>
<td>
<p>By default, the coefficients are extracted at the CV-optimal values of the penalty parameters. Choosing &quot;lambda.1se&quot; will extract them at the largest values within one standard error of the minima.</p>
</td></tr>
<tr><td><code id="coef.MVS_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of S3 class &quot;MVScoef&quot;.
</p>


<h3>Author(s)</h3>

<p>Wouter van Loon &lt;w.s.van.loon@fsw.leidenuniv.nl&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
set.seed(012)
n &lt;- 1000
X &lt;- matrix(rnorm(8500), nrow=n, ncol=85)
top_level &lt;- c(rep(1,45), rep(2,20), rep(3,20))
bottom_level &lt;- c(rep(1:3, each=15), rep(4:5, each=10), rep(6:9, each=5))
views &lt;- cbind(bottom_level, top_level)
beta &lt;- c(rep(10, 55), rep(0, 30)) * ((rbinom(85, 1, 0.5)*2)-1)
eta &lt;- X %*% beta
p &lt;- 1 /(1 + exp(-eta))
y &lt;- rbinom(n, 1, p)

fit &lt;- MVS(x=X, y=y, views=views, type="StaPLR", levels=3, alphas=c(0,1,1), nnc=c(0,1,1))
coefficients &lt;- coef(fit)

new_X &lt;- matrix(rnorm(2*85), nrow=2)
predict(fit, new_X)
</code></pre>

<hr>
<h2 id='coef.StaPLR'>Extract coefficients from a &quot;StaPLR&quot; object.</h2><span id='topic+coef.StaPLR'></span>

<h3>Description</h3>

<p>Extract base- and meta-level coefficients from a &quot;StaPLR&quot; object at the CV-optimal values of the penalty parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'StaPLR'
coef(object, cvlambda = "lambda.min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.StaPLR_+3A_object">object</code></td>
<td>
<p>Fitted &quot;StaPLR&quot; model object.</p>
</td></tr>
<tr><td><code id="coef.StaPLR_+3A_cvlambda">cvlambda</code></td>
<td>
<p>By default, the coefficients are extracted at the CV-optimal values of the penalty parameters. Choosing &quot;lambda.1se&quot; will extract them at the largest values within one standard error of the minima.</p>
</td></tr>
<tr><td><code id="coef.StaPLR_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="glmnet.html#topic+coef.cv.glmnet">coef.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class &quot;StaPLRcoef&quot;.
</p>


<h3>Author(s)</h3>

<p>Wouter van Loon &lt;w.s.van.loon@fsw.leidenuniv.nl&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(012)
n &lt;- 1000
cors &lt;- seq(0.1,0.7,0.1)
X &lt;- matrix(NA, nrow=n, ncol=length(cors)+1)
X[,1] &lt;- rnorm(n)

for(i in 1:length(cors)){
  X[,i+1] &lt;- X[,1]*cors[i] + rnorm(n, 0, sqrt(1-cors[i]^2))
}

beta &lt;- c(1,0,0,0,0,0,0,0)
eta &lt;- X %*% beta
p &lt;- exp(eta)/(1+exp(eta))
y &lt;- rbinom(n, 1, p)
view_index &lt;- rep(1:(ncol(X)/2), each=2)

fit &lt;- StaPLR(X, y, view_index)
coef(fit)$meta

new_X &lt;- matrix(rnorm(16), nrow=2)
predict(fit, new_X)
</code></pre>

<hr>
<h2 id='MVS'>Multi-View Stacking</h2><span id='topic+MVS'></span><span id='topic+mvs'></span>

<h3>Description</h3>

<p>Fit a multi-view stacking model with two or more levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MVS(
  x,
  y,
  views,
  type = "StaPLR",
  levels = 2,
  alphas = c(0, 1),
  nnc = c(0, 1),
  parallel = FALSE,
  seeds = NULL,
  progress = TRUE,
  ...
)

mvs(
  x,
  y,
  views,
  type = "StaPLR",
  levels = 2,
  alphas = c(0, 1),
  nnc = c(0, 1),
  parallel = FALSE,
  seeds = NULL,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MVS_+3A_x">x</code></td>
<td>
<p>input matrix of dimension nobs x nvars.</p>
</td></tr>
<tr><td><code id="MVS_+3A_y">y</code></td>
<td>
<p>outcome vector of length nobs.</p>
</td></tr>
<tr><td><code id="MVS_+3A_views">views</code></td>
<td>
<p>a matrix of dimension nvars x (levels - 1), where each entry is an integer describing to which view each feature corresponds.</p>
</td></tr>
<tr><td><code id="MVS_+3A_type">type</code></td>
<td>
<p>the type of MVS model to be fitted. Currently only type &quot;StaPLR&quot; is supported.</p>
</td></tr>
<tr><td><code id="MVS_+3A_levels">levels</code></td>
<td>
<p>an integer &gt;= 2, specifying the number of levels in the MVS procedure.</p>
</td></tr>
<tr><td><code id="MVS_+3A_alphas">alphas</code></td>
<td>
<p>a vector specifying the value of the alpha parameter to use at each level.</p>
</td></tr>
<tr><td><code id="MVS_+3A_nnc">nnc</code></td>
<td>
<p>a binary vector specifying whether to apply nonnegativity constraints or not (1/0) at each level.</p>
</td></tr>
<tr><td><code id="MVS_+3A_parallel">parallel</code></td>
<td>
<p>whether to use foreach to fit the learners and obtain the cross-validated predictions at each level in parallel. Executes sequentially unless a parallel back-end is registered beforehand.</p>
</td></tr>
<tr><td><code id="MVS_+3A_seeds">seeds</code></td>
<td>
<p>(optional) a vector specifying the seed to use at each level.</p>
</td></tr>
<tr><td><code id="MVS_+3A_progress">progress</code></td>
<td>
<p>whether to show a progress bar (only supported when parallel = FALSE).</p>
</td></tr>
<tr><td><code id="MVS_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to the learning algorithm. See e.g. ?StaPLR. Note that these arguments are passed to the the learner at every level of the MVS procedure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of S3 class &quot;MVS&quot;.
</p>


<h3>Author(s)</h3>

<p>Wouter van Loon &lt;w.s.van.loon@fsw.leidenuniv.nl&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
set.seed(012)
n &lt;- 1000
X &lt;- matrix(rnorm(8500), nrow=n, ncol=85)
top_level &lt;- c(rep(1,45), rep(2,20), rep(3,20))
bottom_level &lt;- c(rep(1:3, each=15), rep(4:5, each=10), rep(6:9, each=5))
views &lt;- cbind(bottom_level, top_level)
beta &lt;- c(rep(10, 55), rep(0, 30)) * ((rbinom(85, 1, 0.5)*2)-1)
eta &lt;- X %*% beta
p &lt;- 1 /(1 + exp(-eta))
y &lt;- rbinom(n, 1, p)

fit &lt;- MVS(x=X, y=y, views=views, type="StaPLR", levels=3, alphas=c(0,1,1), nnc=c(0,1,1))
coefficients &lt;- coef(fit)

new_X &lt;- matrix(rnorm(2*85), nrow=2)
predict(fit, new_X)
</code></pre>

<hr>
<h2 id='predict.MVS'>Make predictions from an &quot;MVS&quot; object.</h2><span id='topic+predict.MVS'></span>

<h3>Description</h3>

<p>Make predictions from a &quot;MVS&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MVS'
predict(object, newx, predtype = "response", cvlambda = "lambda.min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.MVS_+3A_object">object</code></td>
<td>
<p>An object of class &quot;MVS&quot;.</p>
</td></tr>
<tr><td><code id="predict.MVS_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for x at which predictions are to be made. Must be a matrix.</p>
</td></tr>
<tr><td><code id="predict.MVS_+3A_predtype">predtype</code></td>
<td>
<p>The type of prediction returned by the meta-learner. Supported are types &quot;response&quot;, &quot;class&quot; and &quot;link&quot;.</p>
</td></tr>
<tr><td><code id="predict.MVS_+3A_cvlambda">cvlambda</code></td>
<td>
<p>Values of the penalty parameters at which predictions are to be made. Defaults to the values giving minimum cross-validation error.</p>
</td></tr>
<tr><td><code id="predict.MVS_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="glmnet.html#topic+predict.cv.glmnet">predict.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictions.
</p>


<h3>Author(s)</h3>

<p>Wouter van Loon &lt;w.s.van.loon@fsw.leidenuniv.nl&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
set.seed(012)
n &lt;- 1000
X &lt;- matrix(rnorm(8500), nrow=n, ncol=85)
top_level &lt;- c(rep(1,45), rep(2,20), rep(3,20))
bottom_level &lt;- c(rep(1:3, each=15), rep(4:5, each=10), rep(6:9, each=5))
views &lt;- cbind(bottom_level, top_level)
beta &lt;- c(rep(10, 55), rep(0, 30)) * ((rbinom(85, 1, 0.5)*2)-1)
eta &lt;- X %*% beta
p &lt;- 1 /(1 + exp(-eta))
y &lt;- rbinom(n, 1, p)

fit &lt;- MVS(x=X, y=y, views=views, type="StaPLR", levels=3, alphas=c(0,1,1), nnc=c(0,1,1))
coefficients &lt;- coef(fit)

new_X &lt;- matrix(rnorm(2*85), nrow=2)
predict(fit, new_X)
</code></pre>

<hr>
<h2 id='predict.StaPLR'>Make predictions from a &quot;StaPLR&quot; object.</h2><span id='topic+predict.StaPLR'></span>

<h3>Description</h3>

<p>Make predictions from a &quot;StaPLR&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'StaPLR'
predict(
  object,
  newx,
  newcf = NULL,
  predtype = "response",
  cvlambda = "lambda.min",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.StaPLR_+3A_object">object</code></td>
<td>
<p>Fitted &quot;StaPLR&quot; model object.</p>
</td></tr>
<tr><td><code id="predict.StaPLR_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for x at which predictions are to be made. Must be a matrix.</p>
</td></tr>
<tr><td><code id="predict.StaPLR_+3A_newcf">newcf</code></td>
<td>
<p>Matrix of new values of correction features, if correct.for was specified during model fitting.</p>
</td></tr>
<tr><td><code id="predict.StaPLR_+3A_predtype">predtype</code></td>
<td>
<p>The type of prediction returned by the meta-learner.</p>
</td></tr>
<tr><td><code id="predict.StaPLR_+3A_cvlambda">cvlambda</code></td>
<td>
<p>Values of the penalty parameters at which predictions are to be made. Defaults to the values giving minimum cross-validation error.</p>
</td></tr>
<tr><td><code id="predict.StaPLR_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code><a href="glmnet.html#topic+predict.cv.glmnet">predict.cv.glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictions.
</p>


<h3>Author(s)</h3>

<p>Wouter van Loon &lt;w.s.van.loon@fsw.leidenuniv.nl&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
set.seed(012)
n &lt;- 1000
cors &lt;- seq(0.1,0.7,0.1)
X &lt;- matrix(NA, nrow=n, ncol=length(cors)+1)
X[,1] &lt;- rnorm(n)

for(i in 1:length(cors)){
  X[,i+1] &lt;- X[,1]*cors[i] + rnorm(n, 0, sqrt(1-cors[i]^2))
}

beta &lt;- c(1,0,0,0,0,0,0,0)
eta &lt;- X %*% beta
p &lt;- exp(eta)/(1+exp(eta))
y &lt;- rbinom(n, 1, p)
view_index &lt;- rep(1:(ncol(X)/2), each=2)

fit &lt;- StaPLR(X, y, view_index)
coef(fit)$meta

new_X &lt;- matrix(rnorm(16), nrow=2)
predict(fit, new_X)
</code></pre>

<hr>
<h2 id='predict.StaPLRcoef'>Make predictions from a &quot;StaPLRcoef&quot; object.</h2><span id='topic+predict.StaPLRcoef'></span>

<h3>Description</h3>

<p>Predict using a &quot;StaPLRcoef&quot; object. A &quot;StaPLRcoef&quot; object can be considerably smaller than a full &quot;StaPLR&quot; object for large data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'StaPLRcoef'
predict(object, newx, view, newcf = NULL, predtype = "response", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.StaPLRcoef_+3A_object">object</code></td>
<td>
<p>Extracted StaPLR coefficients as a &quot;StaPLRcoef&quot; object.</p>
</td></tr>
<tr><td><code id="predict.StaPLRcoef_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for x at which predictions are to be made. Must be a matrix.</p>
</td></tr>
<tr><td><code id="predict.StaPLRcoef_+3A_view">view</code></td>
<td>
<p>a vector of length nvars, where each entry is an integer describing to which view each feature corresponds.</p>
</td></tr>
<tr><td><code id="predict.StaPLRcoef_+3A_newcf">newcf</code></td>
<td>
<p>Matrix of new values of correction features, if correct.for was specified during model fitting.</p>
</td></tr>
<tr><td><code id="predict.StaPLRcoef_+3A_predtype">predtype</code></td>
<td>
<p>The type of prediction returned by the meta-learner. Allowed values are &quot;response&quot;, &quot;link&quot;, and &quot;class&quot;.</p>
</td></tr>
<tr><td><code id="predict.StaPLRcoef_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictions.
</p>


<h3>Author(s)</h3>

<p>Wouter van Loon &lt;w.s.van.loon@fsw.leidenuniv.nl&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(012)
n &lt;- 1000
cors &lt;- seq(0.1,0.7,0.1)
X &lt;- matrix(NA, nrow=n, ncol=length(cors)+1)
X[,1] &lt;- rnorm(n)

for(i in 1:length(cors)){
  X[,i+1] &lt;- X[,1]*cors[i] + rnorm(n, 0, sqrt(1-cors[i]^2))
}

beta &lt;- c(1,0,0,0,0,0,0,0)
eta &lt;- X %*% beta
p &lt;- exp(eta)/(1+exp(eta))
y &lt;- rbinom(n, 1, p)
view_index &lt;- rep(1:(ncol(X)/2), each=2)

fit &lt;- StaPLR(X, y, view_index)
coefficients &lt;- coef(fit)

new_X &lt;- matrix(rnorm(16), nrow=2)
predict(coefficients, new_X, view_index)
</code></pre>

<hr>
<h2 id='StaPLR'>Stacked Penalized Logistic Regression</h2><span id='topic+StaPLR'></span><span id='topic+staplr'></span>

<h3>Description</h3>

<p>Fit a two-level stacked penalized (logistic) regression model with a single base-learner and a single meta-learner. Stacked penalized regression models with a Gaussian or Poisson outcome can be fitted using the family argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StaPLR(
  x,
  y,
  view,
  view.names = NULL,
  family = "binomial",
  correct.for = NULL,
  alpha1 = 0,
  alpha2 = 1,
  nfolds = 10,
  seed = NULL,
  std.base = FALSE,
  std.meta = FALSE,
  ll1 = -Inf,
  ul1 = Inf,
  ll2 = 0,
  ul2 = Inf,
  cvloss = "deviance",
  metadat = "response",
  cvlambda = "lambda.min",
  cvparallel = FALSE,
  lambda.ratio = 1e-04,
  fdev = 0,
  penalty.weights = NULL,
  parallel = FALSE,
  skip.version = TRUE,
  skip.meta = FALSE,
  skip.cv = FALSE,
  progress = TRUE
)

staplr(
  x,
  y,
  view,
  view.names = NULL,
  family = "binomial",
  correct.for = NULL,
  alpha1 = 0,
  alpha2 = 1,
  nfolds = 10,
  seed = NULL,
  std.base = FALSE,
  std.meta = FALSE,
  ll1 = -Inf,
  ul1 = Inf,
  ll2 = 0,
  ul2 = Inf,
  cvloss = "deviance",
  metadat = "response",
  cvlambda = "lambda.min",
  cvparallel = FALSE,
  lambda.ratio = 1e-04,
  fdev = 0,
  penalty.weights = NULL,
  parallel = FALSE,
  skip.version = TRUE,
  skip.meta = FALSE,
  skip.cv = FALSE,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StaPLR_+3A_x">x</code></td>
<td>
<p>input matrix of dimension nobs x nvars</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_y">y</code></td>
<td>
<p>outcome vector of length nobs</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_view">view</code></td>
<td>
<p>a vector of length nvars, where each entry is an integer describing to which view each feature corresponds.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_view.names">view.names</code></td>
<td>
<p>(optional) a character vector of length nviews specifying a name for each view.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_family">family</code></td>
<td>
<p>Either a character string representing one of the built-in families, or else a <code>glm()</code> family object. 
For more information, see <code>family</code> argument's documentation in <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Note
that &quot;multinomial&quot;, &quot;mgaussian&quot;, &quot;cox&quot;, or 2-column responses with &quot;binomial&quot; family are not yet supported.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_correct.for">correct.for</code></td>
<td>
<p>(optional) a matrix with nrow = nobs, where each column is a feature which should be included directly into the meta.learner. By default these features are not penalized (see penalty.weights) and appear at the top of the coefficient list.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_alpha1">alpha1</code></td>
<td>
<p>(base) alpha parameter for glmnet: lasso(1) / ridge(0)</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_alpha2">alpha2</code></td>
<td>
<p>(meta) alpha parameter for glmnet: lasso(1) / ridge(0)</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds to use for all cross-validation.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_seed">seed</code></td>
<td>
<p>(optional) numeric value specifying the seed. Setting the seed this way ensures the results are reproducible even when the computations are performed in parallel.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_std.base">std.base</code></td>
<td>
<p>should features be standardized at the base level?</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_std.meta">std.meta</code></td>
<td>
<p>should cross-validated predictions be standardized at the meta level?</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_ll1">ll1</code></td>
<td>
<p>lower limit(s) for each coefficient at the base-level. Defaults to -Inf.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_ul1">ul1</code></td>
<td>
<p>upper limit(s) for each coefficient at the base-level. Defaults to Inf.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_ll2">ll2</code></td>
<td>
<p>lower limit(s) for each coefficient at the meta-level. Defaults to 0 (non-negativity constraints). Does not apply to correct.for features.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_ul2">ul2</code></td>
<td>
<p>upper limit(s) for each coefficient at the meta-level. Defaults to Inf. Does not apply to correct.for features.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_cvloss">cvloss</code></td>
<td>
<p>loss to use for cross-validation.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_metadat">metadat</code></td>
<td>
<p>which attribute of the base learners should be used as input for the meta learner? Allowed values are &quot;response&quot;, &quot;link&quot;, and &quot;class&quot;.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_cvlambda">cvlambda</code></td>
<td>
<p>value of lambda at which cross-validated predictions are made. Defaults to the value giving minimum internal cross-validation error.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_cvparallel">cvparallel</code></td>
<td>
<p>whether to use 'foreach' to fit each CV fold (DO NOT USE, USE OPTION parallel INSTEAD).</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_lambda.ratio">lambda.ratio</code></td>
<td>
<p>the ratio between the largest and smallest lambda value.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_fdev">fdev</code></td>
<td>
<p>sets the minimum fractional change in deviance for stopping the path to the specified value, ignoring the value of fdev set through glmnet.control. Setting fdev=NULL will use the value set through glmnet.control instead. It is strongly recommended to use the default value of zero.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_penalty.weights">penalty.weights</code></td>
<td>
<p>(optional) a vector of length nviews, containing different penalty factors for the meta-learner. Defaults to rep(1,nviews). The penalty factor is set to 0 for correct.for features.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_parallel">parallel</code></td>
<td>
<p>whether to use foreach to fit the base-learners and obtain the cross-validated predictions in parallel. Executes sequentially unless a parallel backend is registered beforehand.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_skip.version">skip.version</code></td>
<td>
<p>whether to skip checking the version of the glmnet package.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_skip.meta">skip.meta</code></td>
<td>
<p>whether to skip training the metalearner.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_skip.cv">skip.cv</code></td>
<td>
<p>whether to skip generating the cross-validated predictions.</p>
</td></tr>
<tr><td><code id="StaPLR_+3A_progress">progress</code></td>
<td>
<p>whether to show a progress bar (only supported when parallel = FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class &quot;StaPLR&quot;.
</p>


<h3>Author(s)</h3>

<p>Wouter van Loon &lt;w.s.van.loon@fsw.leidenuniv.nl&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(012)
n &lt;- 1000
cors &lt;- seq(0.1,0.7,0.1)
X &lt;- matrix(NA, nrow=n, ncol=length(cors)+1)
X[,1] &lt;- rnorm(n)

for(i in 1:length(cors)){
  X[,i+1] &lt;- X[,1]*cors[i] + rnorm(n, 0, sqrt(1-cors[i]^2))
}

beta &lt;- c(1,0,0,0,0,0,0,0)
eta &lt;- X %*% beta
p &lt;- exp(eta)/(1+exp(eta))
y &lt;- rbinom(n, 1, p) ## create binary response
view_index &lt;- rep(1:(ncol(X)/2), each=2)

# Stacked penalized logistic regression
fit &lt;- StaPLR(X, y, view_index)
coef(fit)$meta

new_X &lt;- matrix(rnorm(16), nrow=2)
predict(fit, new_X)

# Stacked penalized linear regression
y &lt;- eta + rnorm(100) ## create continuous response
fit &lt;- StaPLR(X, y, view_index, family = "gaussian")
coef(fit)$meta
coef(fit)$base
new_X &lt;- matrix(rnorm(16), nrow=2)
predict(fit, new_X)

# Stacked penalized Poisson regression
y &lt;- ceiling(eta + 4) ## create count response
fit &lt;- StaPLR(X, y, view_index, family = "poisson")
coef(fit)$meta
coef(fit)$base
new_X &lt;- matrix(rnorm(16), nrow=2)
predict(fit, new_X)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
