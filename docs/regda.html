<!DOCTYPE html><html><head><title>Help for package regda</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {regda}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Cross-validation for the regularised maximum likelihood linear discriminant analysis'>
<p>Cross-validation for the regularised maximum likelihood linear discriminant analysis</p></a></li>
<li><a href='#regda-package'>
<p>Regularised Discriminant Analysis</p></a></li>
<li><a href='#Regularised discriminant analysis for Euclidean data'>
<p>Regularised discriminant analysis for Euclidean data</p></a></li>
<li><a href='#Regularised maximum likelihood linear discriminant analysis'><p>Regularised maximum likelihood linear discriminant analysis</p></a></li>
<li><a href='#Tuning the parameters of the regularised discriminant analysis'>
<p>Tuning the parameters of the regularised discriminant analysis</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Regularised Discriminant Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Michail Tsagris [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michail Tsagris &lt;mtsagris@uoc.gr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>doParallel, foreach, parallel, Rfast, Rfast2, stats</td>
</tr>
<tr>
<td>Description:</td>
<td>Regularised discriminant analysis functions. The classical regularised discriminant analysis proposed by Friedman in 1989, including cross-validation, of which the linear and quadratic discriminant analyses are special cases. Further, the regularised maximum likelihood linear discriminant analysis, including cross-validation. References: Friedman J.H. (1989): "Regularized Discriminant Analysis". Journal of the American Statistical Association 84(405): 165&ndash;175. &lt;<a href="https://doi.org/10.2307%2F2289860">doi:10.2307/2289860</a>&gt;. Friedman J., Hastie T. and Tibshirani R. (2009). "The elements of statistical learning", 2nd edition. Springer, Berlin. &lt;<a href="https://doi.org/10.1007%2F978-0-387-84858-7">doi:10.1007/978-0-387-84858-7</a>&gt;. Tsagris M., Preston S. and Wood A.T.A. (2016). "Improved classification for compositional data using the alpha-transformation". Journal of Classification, 33(2): 243&ndash;261. &lt;<a href="https://doi.org/10.1007%2Fs00357-016-9207-5">doi:10.1007/s00357-016-9207-5</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-05 19:53:48 UTC; mtsag</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-06 17:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Cross-validation+20for+20the+20regularised+20maximum+20likelihood+20linear+20discriminant+20analysis'>
Cross-validation for the regularised maximum likelihood linear discriminant analysis
</h2><span id='topic+regmlelda.cv'></span>

<h3>Description</h3>

<p>Cross-validation for the regularised maximum likelihood linear discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regmlelda.cv(x, ina, lambda = seq(0, 1, by = 0.1), folds = NULL, nfolds = 10,
             stratified = TRUE, seed = FALSE, pred.ret = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_x">x</code></td>
<td>

<p>A matrix with numerical data.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_ina">ina</code></td>
<td>

<p>A numerical vector or factor with consecutive numbers indicating the group to which each
observation belongs to.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_lambda">lambda</code></td>
<td>

<p>A vector of regularization values <code class="reqn">\lambda</code> such as (0, 0.1, 0.2,...).
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_folds">folds</code></td>
<td>

<p>A list with the indices of the folds.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if &quot;folds&quot; is NULL.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be selected using stratified random sampling? This preserves the analogy of the samples of each group. Make this TRUE if you wish.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_seed">seed</code></td>
<td>

<p>If you set this to TRUE, the same folds will be created every time.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_pred.ret">pred.ret</code></td>
<td>

<p>If you want the predicted values returned set this to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cross-validation for the regularised maximum likelihood linear discriminant analysis is performed.
The function is not extremely fast, yet is pretty fast.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>preds</code></td>
<td>

<p>If pred.ret is TRUE the predicted values for each fold are returned as elements in a list.
</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>

<p>A vector whose length is equal to the number of k and is the accuracy metric for each k.
For the classification case it is the percentage of correct classification. For the regression
case the mean square of prediction error.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning.
New York: Springer.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+reg.mle.lda">reg.mle.lda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
mod &lt;- regmlelda.cv(x, iris[, 5])
</code></pre>

<hr>
<h2 id='regda-package'>
Regularised Discriminant Analysis
</h2><span id='topic+regda-package'></span>

<h3>Description</h3>

<p>Description: Regularised discriminant analysis functions. The classical regularised discriminant analysis proposed by Friedman in 1989, including cross-validation, of which the linear and quadratic discriminant analyses are special cases. Further, the regularised maximum likelihood linear discriminant analysis, including cross-validation.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> regda</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0 </td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-11-05</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Maintainers</h3>

<p>Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
</p>


<h3>References</h3>

<p>Friedman J.H. (1989): Regularized Discriminant Analysis. Journal of the American Statistical
Association 84(405): 165&ndash;175.
</p>
<p>Friedman Jerome, Trevor Hastie and Robert Tibshirani (2009).
The elements of statistical learning, 2nd edition. Springer, Berlin.
</p>
<p>Tsagris M., Preston S. and Wood A.T.A. (2016). Improved classification for
compositional data using the <code class="reqn">\alpha</code>-transformation.
Journal of Classification, 33(2): 243&ndash;261.
</p>

<hr>
<h2 id='Regularised+20discriminant+20analysis+20for+20Euclidean+20data'>
Regularised discriminant analysis for Euclidean data
</h2><span id='topic+rda'></span>

<h3>Description</h3>

<p>Regularised discriminant analysis for Euclidean data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rda(xnew, x, ina, gam = 1, del = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Regularised+2B20discriminant+2B20analysis+2B20for+2B20Euclidean+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new data whose group is to be predicted. They have to be continuous.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20discriminant+2B20analysis+2B20for+2B20Euclidean+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available data. They have to be continuous.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20discriminant+2B20analysis+2B20for+2B20Euclidean+2B20data_+3A_ina">ina</code></td>
<td>

<p>A group indicator variable for the avaiable data.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20discriminant+2B20analysis+2B20for+2B20Euclidean+2B20data_+3A_gam">gam</code></td>
<td>

<p>This is a number between 0 and 1. It is the weight of the pooled covariance and the diagonal matrix.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20discriminant+2B20analysis+2B20for+2B20Euclidean+2B20data_+3A_del">del</code></td>
<td>

<p>This is a number between 0 and 1. It is the weight of the LDA and QDA.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The covariance matrix of each group is calculated and then the pooled covariance matrix. The spherical covariance matrix consists of the average of the pooled variances in its diagonal and zeros in the off-diagonal elements. gam is the weight of the pooled covariance matrix and 1-gam is the weight of the spherical covariance matrix, Sa = gam * Sp + (1-gam) * sp. Then it is a compromise between LDA and QDA. del is the weight of Sa and 1-del the weight of each group covariance group.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>prob</code></td>
<td>

<p>The estimated probabilities of the new data of belonging to each group.
</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>

<p>The estimated socres of the new data of each group.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated group membership of the new data.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J.H. (1989): Regularized Discriminant Analysis. Journal of the American Statistical
Association 84(405): 165&ndash;175.
</p>
<p>Friedman Jerome, Trevor Hastie and Robert Tibshirani (2009).
The elements of statistical learning, 2nd edition. Springer, Berlin.
</p>
<p>Tsagris M., Preston S. and Wood A.T.A. (2016). Improved classification for
compositional data using the <code class="reqn">\alpha</code>-transformation.
Journal of Classification, 33(2): 243&ndash;261.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rda.tune">rda.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
ina &lt;- iris[, 5]
mod &lt;- rda(x, x, ina)
table(ina, mod$est)
</code></pre>

<hr>
<h2 id='Regularised+20maximum+20likelihood+20linear+20discriminant+20analysis'>Regularised maximum likelihood linear discriminant analysis
</h2><span id='topic+reg.mle.lda'></span>

<h3>Description</h3>

<p>Regularised maximum likelihood linear discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reg.mle.lda(xnew, x, ina, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_xnew">xnew</code></td>
<td>

<p>A numerical vector or a matrix with the new observations, continuous data.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_x">x</code></td>
<td>

<p>A matrix with numerical data.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_ina">ina</code></td>
<td>

<p>A numerical vector or factor with consecutive numbers indicating the group to which each
observation belongs to.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20maximum+2B20likelihood+2B20linear+2B20discriminant+2B20analysis_+3A_lambda">lambda</code></td>
<td>

<p>A vector of regularization values <code class="reqn">\lambda</code> such as (0, 0.1, 0.2,...).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Regularised maximum likelihood linear discriminant analysis is performed. The function is not extremely fast, yet is pretty fast.
</p>


<h3>Value</h3>

<p>A matrix with the predicted group of each observation in &quot;xnew&quot;.
Every column corresponds to a <code class="reqn">\lambda</code> value. If you have just on value of <code class="reqn">\lambda</code>, then
you will have one column only.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+regmlelda.cv">regmlelda.cv</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
ina &lt;- iris[, 5]
a &lt;- reg.mle.lda(x, x, ina, lambda = seq(0, 1, by = 0.1) )
</code></pre>

<hr>
<h2 id='Tuning+20the+20parameters+20of+20the+20regularised+20discriminant+20analysis'>
Tuning the parameters of the regularised discriminant analysis
</h2><span id='topic+rda.tune'></span>

<h3>Description</h3>

<p>Tuning the parameters of the regularised discriminant analysis for Eucldiean data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rda.tune(x, ina, nfolds = 10, gam = seq(0, 1, by = 0.1), del = seq(0, 1, by = 0.1),
ncores = 1, folds = NULL, stratified = TRUE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_x">x</code></td>
<td>

<p>A matrix with the data.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_ina">ina</code></td>
<td>

<p>A group indicator variable for the avaiable data.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds in the cross validation.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_gam">gam</code></td>
<td>

<p>A grid of values for the <code class="reqn">\gamma</code> parameter as defined in Tsagris et al. (2016).
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_del">del</code></td>
<td>

<p>A grid of values for the <code class="reqn">\delta</code> parameter as defined in Tsagris et al. (2016).
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_ncores">ncores</code></td>
<td>

<p>The number of cores to use. If more than 1, parallel computing will take place. It is advisable to use it if you have many observations and or
many variables, otherwise it will slow down th process.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be created in a stratified way? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20parameters+2B20of+2B20the+2B20regularised+2B20discriminant+2B20analysis_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cross validation is performed to select the optimal parameters for the regularisded discriminant analysis and also estimate the rate of accuracy.
</p>
<p>The covariance matrix of each group is calcualted and then the pooled covariance matrix. The spherical covariance matrix consists of the average of the pooled variances in its diagonal and zeros in the off-diagonal elements. gam is the weight of the pooled covariance matrix and 1-gam is the weight of the spherical covariance matrix, Sa = gam * Sp + (1-gam) * sp. Then it is a compromise between LDA and QDA. del is the weight of Sa and 1-del the weight of each group covariance group.
</p>


<h3>Value</h3>

<p>A list including:
If graph is TRUE a plot of a heatmap of the performance s will appear.
</p>
<table>
<tr><td><code>per</code></td>
<td>

<p>An array with the estimate rate of correct classification for every fold. For each of the M matrices, the row values correspond to gam and the columns to the del parameter.
</p>
</td></tr>
<tr><td><code>percent</code></td>
<td>

<p>A matrix with the mean estimated rates of correct classification. The row values correspond to gam and the columns to the del parameter.
</p>
</td></tr>
<tr><td><code>se</code></td>
<td>

<p>A matrix with the standard error of the mean estimated rates of correct classification. The row values correspond to gam and the columns to the del parameter.
</p>
</td></tr>
<tr><td><code>result</code></td>
<td>

<p>The estimated rate of correct classification along with the best gam and del parameters.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J.H. (1989): Regularized Discriminant Analysis. Journal of the American Statistical
Association 84(405): 165&ndash;175.
</p>
<p>Friedman Jerome, Trevor Hastie and Robert Tibshirani (2009).
The elements of statistical learning, 2nd edition. Springer, Berlin.
</p>
<p>Tsagris M., Preston S. and Wood A.T.A. (2016). Improved classification for
compositional data using the <code class="reqn">\alpha</code>-transformation.
Journal of Classification, 33(2): 243&ndash;261.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rda">rda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod &lt;- rda.tune(as.matrix(iris[, 1:4]), iris[, 5], gam = seq(0, 1, by = 0.2),
del = seq(0, 1, by = 0.2) )
mod
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
