<!DOCTYPE html><html><head><title>Help for package dbarts</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dbarts}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bart'><p>Bayesian Additive Regression Trees</p></a></li>
<li><a href='#dbarts'><p>Discrete Bayesian Additive Regression Trees Sampler</p></a></li>
<li><a href='#dbartsControl'><p>Discrete Bayesian Additive Regression Trees Sampler Control</p></a></li>
<li><a href='#dbartsData'><p>Discrete Bayesian Additive Regression Trees Sampler Data</p></a></li>
<li><a href='#dbartsSampler-class'><p>Class &quot;dbartsSampler&quot; of Discrete Bayesian Additive Regression Trees Sampler</p></a></li>
<li><a href='#guessNumCores'><p>Guess Number of Cores</p></a></li>
<li><a href='#makeModelMatrixFromDataFrame'><p>Make Model Matrix from Data Frame</p></a></li>
<li><a href='#pdbart'><p>Partial Dependence Plots for BART</p></a></li>
<li><a href='#rbart'><p>Bayesian Additive Regression Trees with Random Effects</p></a></li>
<li><a href='#xbart'><p>Crossvalidation For Bayesian Additive Regression Trees</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.9-26</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-03</td>
</tr>
<tr>
<td>Title:</td>
<td>Discrete Bayesian Additive Regression Trees Sampler</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1-0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, methods, graphics, parallel</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 0.9-0), knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits Bayesian additive regression trees (BART; Chipman, George, and McCulloch (2010) &lt;<a href="https://doi.org/10.1214%2F09-AOAS285">doi:10.1214/09-AOAS285</a>&gt;) while allowing the updating of predictors or response so that BART can be incorporated as a conditional model in a Gibbs/Metropolis-Hastings sampler. Also serves as a drop-in replacement for package 'BayesTree'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Biarch:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/vdorie/dbarts">https://github.com/vdorie/dbarts</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/vdorie/dbarts/issues">https://github.com/vdorie/dbarts/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-03 22:36:39 UTC; vdorie</td>
</tr>
<tr>
<td>Author:</td>
<td>Vincent Dorie <a href="https://orcid.org/0000-0002-9576-3064"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Hugh Chipman [aut],
  Robert McCulloch [aut],
  Armon Dadgar [ctb] (adaptive radix tree),
  R Core Team [ctb] (basis of RNG),
  Guido U Draheim [ctb] (ax_check_compile_flag.m4),
  Maarten Bosmans [ctb] (ax_check_compile_flag.m4),
  Christophe Tournayre [ctb] (ax_compiler_ext.m4, ax_ext.m4),
  Michael Petch [ctb] (ax_compiler_ext.m4, ax_ext.m4,
    ax_gcc_x86_avx_xgetbv.m4, ax_gcc_x86_cpuid.m4),
  Rafael de Lucena Valle [ctb] (ax_compiler_ext.m4, ax_ext.m4),
  Steven G. Johnson <a href="https://orcid.org/0000-0001-7327-4967"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (ax_compiler_vendor.m4, ax_gcc_x86_cpuid.m4, ax_pthread.m4),
  Matteo Frigo [ctb] (ax_compiler_vendor.m4, ax_gcc_x86_cpuid.m4),
  John Zaitseff [ctb] (ax_compiler_vendor.m4),
  Todd Veldhuizen [ctb] (ax_cxx_namespace_std.m4),
  Luc Maisonobe [ctb] (ax_cxx_namespace_std.m4),
  Scott Pakin <a href="https://orcid.org/0000-0002-5220-1985"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]
    (ax_func_posix_memalign.m4),
  Daniel Richard G. [ctb] (ax_pthread.m4)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Vincent Dorie &lt;vdorie@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-03 23:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bart'>Bayesian Additive Regression Trees</h2><span id='topic+bart'></span><span id='topic+bart2'></span><span id='topic+plot.bart'></span><span id='topic+extract'></span><span id='topic+predict.bart'></span><span id='topic+extract.bart'></span><span id='topic+fitted.bart'></span><span id='topic+residuals.bart'></span>

<h3>Description</h3>

<p>BART is a Bayesian &ldquo;sum-of-trees&rdquo; model in which each tree is constrained by a prior to be a weak learner.
</p>

<ul>
<li><p> For numeric response <code class="reqn">y = f(x) + \epsilon</code>, where <code class="reqn">\epsilon \sim N(0, \sigma^2)</code>.
</p>
</li>
<li><p> For binary response <code class="reqn">y</code>, <code class="reqn">P(Y = 1 \mid x) = \Phi(f(x))</code>, where <code class="reqn">\Phi</code> denotes the standard normal cdf (probit link).
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bart(
    x.train, y.train, x.test = matrix(0.0, 0, 0),
    sigest = NA, sigdf = 3, sigquant = 0.90,
    k = 2.0,
    power = 2.0, base = 0.95, splitprobs = 1 / numvars,
    binaryOffset = 0.0, weights = NULL,
    ntree = 200,
    ndpost = 1000, nskip = 100,
    printevery = 100, keepevery = 1, keeptrainfits = TRUE,
    usequants = FALSE, numcut = 100, printcutoffs = 0,
    verbose = TRUE, nchain = 1, nthread = 1, combinechains = TRUE,
    keeptrees = FALSE, keepcall = TRUE, sampleronly = FALSE,
    seed = NA_integer_,
    proposalprobs = NULL,
    keepsampler = keeptrees)

bart2(
    formula, data, test, subset, weights, offset, offset.test = offset,
    sigest = NA_real_, sigdf = 3.0, sigquant = 0.90,
    k = NULL,
    power = 2.0, base = 0.95, split.probs = 1 / num.vars,
    n.trees = 75L,
    n.samples = 500L, n.burn = 500L,
    n.chains = 4L, n.threads = min(dbarts::guessNumCores(), n.chains),
    combineChains = FALSE,
    n.cuts = 100L, useQuantiles = FALSE,
    n.thin = 1L, keepTrainingFits = TRUE,
    printEvery = 100L, printCutoffs = 0L,
    verbose = TRUE, keepTrees = FALSE, 
    keepCall = TRUE, samplerOnly = FALSE,
    seed = NA_integer_,
    proposal.probs = NULL,
    keepSampler = keepTrees,
    ...)

## S3 method for class 'bart'
plot(
    x,
    plquants = c(0.05, 0.95), cols = c('blue', 'black'),
    ...)

## S3 method for class 'bart'
predict(
    object, newdata, offset, weights,
    type = c("ev", "ppd", "bart"),
    combineChains = TRUE, ...)

extract(object, ...)
## S3 method for class 'bart'
extract(
    object,
    type = c("ev", "ppd", "bart", "trees"),
    sample = c("train", "test"),
    combineChains = TRUE, ...)

## S3 method for class 'bart'
fitted(
    object,
    type = c("ev", "ppd", "bart"),
    sample = c("train", "test"),
    ...)

## S3 method for class 'bart'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bart_+3A_x.train">x.train</code></td>
<td>

<p>Explanatory variables for training (in sample) data. May be a matrix or a data frame, with rows corresponding to observations and columns to variables. If a variable is a factor in a data frame, it is replaced with dummies. Note that <code class="reqn">q</code> dummies are created if <code class="reqn">q &gt; 2</code> and one dummy is created if <code class="reqn">q = 2</code>, where <code class="reqn">q</code> is the number of levels of the factor.
</p>
</td></tr>
<tr><td><code id="bart_+3A_y.train">y.train</code></td>
<td>

<p>Dependent variable for training (in sample) data. If <code>y.train</code> is numeric a continous response model is fit (normal errors). If <code>y.train</code> is a binary factor or has only values 0 and 1, then a binary response model with a probit link is fit.
</p>
</td></tr>
<tr><td><code id="bart_+3A_x.test">x.test</code></td>
<td>

<p>Explanatory variables for test (out of sample) data. Should have same column structure as <code>x.train</code>. <code>bart</code> will generate draws of <code class="reqn">f(x)</code> for each <code class="reqn">x</code> which is a row of <code>x.test</code>.
</p>
</td></tr>
<tr><td><code id="bart_+3A_sigest">sigest</code></td>
<td>

<p>For continuous response models, an estimate of the error variance, <code class="reqn">\sigma^2</code>, used to calibrate an inverse-chi-squared prior used on that parameter. If not supplied, the least-squares estimate is derived instead. See <code>sigquant</code> for more information. Not applicable when <code class="reqn">y</code> is binary.
</p>
</td></tr>
<tr><td><code id="bart_+3A_sigdf">sigdf</code></td>
<td>

<p>Degrees of freedom for error variance prior. Not applicable when <code class="reqn">y</code> is binary.
</p>
</td></tr>
<tr><td><code id="bart_+3A_sigquant">sigquant</code></td>
<td>

<p>The quantile of the error variance prior that the rough estimate (<code>sigest</code>) is placed at. The closer the quantile is to 1, the more aggresive the fit will be as you are putting more prior weight on error standard deviations (<code class="reqn">\sigma</code>) less than the rough estimate. Not applicable when <code class="reqn">y</code> is binary.
</p>
</td></tr>
<tr><td><code id="bart_+3A_k">k</code></td>
<td>

<p>For numeric <code class="reqn">y</code>, <code>k</code> is the number of prior standard deviations <code class="reqn">E(Y|x) = f(x)</code> is away from <code class="reqn">\pm 0.5</code>. The response (<code>y.train</code>) is internally scaled to range from <code class="reqn">-0.5</code> to <code class="reqn">0.5</code>. For binary <code class="reqn">y</code>, <code>k</code> is the number of prior standard deviations <code class="reqn">f(x)</code> is away from <code class="reqn">\pm 3</code>. In both cases, the bigger <code class="reqn">k</code> is, the more conservative the fitting will be. The value can be either a fixed number, or the a <em>hyperprior</em> of the form <code>chi(degreesOfFreedom = 1.25, scale = Inf)</code>. For <code>bart2</code>, the default of <code>NULL</code> uses the value 2 for continuous reponses and a <code>chi</code> hyperprior for binary ones. The default <code>chi</code> hyperprior is improper, and slightly penalizes small values of <code>k</code>.
</p>
</td></tr>
<tr><td><code id="bart_+3A_power">power</code></td>
<td>

<p>Power parameter for tree prior.
</p>
</td></tr>
<tr><td><code id="bart_+3A_base">base</code></td>
<td>

<p>Base parameter for tree prior.
</p>
</td></tr>
<tr><td><code id="bart_+3A_splitprobs">splitprobs</code>, <code id="bart_+3A_split.probs">split.probs</code></td>
<td>

<p>Prior and transition probabilities of variables used to generate splits. Can be missing/empty/<code>NULL</code> for equiprobability, a numeric vector of length equal to the number variables, or a named numeric vector with only a subset of the variables specified and a <code>.default</code> named value. Values given for factor variables are replicated for each resulting column in the generated model matrix. <code>numvars</code> and <code>num.vars</code> symbols will be rebound before execution to the number of columns in the model matrix.
</p>
</td></tr>
<tr><td><code id="bart_+3A_binaryoffset">binaryOffset</code></td>
<td>

<p>Used for binary <code class="reqn">y</code>. When present, the model is <code class="reqn">P(Y = 1 \mid x) = \Phi(f(x) + \mathrm{binaryOffset})</code>, allowing fits with probabilities shrunk towards values other than <code class="reqn">0.5</code>.
</p>
</td></tr>
<tr><td><code id="bart_+3A_weights">weights</code></td>
<td>

<p>An optional vector of weights to be used in the fitting process. When present, BART fits a model with observations <code class="reqn">y \mid x \sim N(f(x), \sigma^2 / w)</code>, where <code class="reqn">f(x)</code> is the unknown function.
</p>
</td></tr>
<tr><td><code id="bart_+3A_ntree">ntree</code>, <code id="bart_+3A_n.trees">n.trees</code></td>
<td>

<p>The number of trees in the sum-of-trees formulation.
</p>
</td></tr>
<tr><td><code id="bart_+3A_ndpost">ndpost</code>, <code id="bart_+3A_n.samples">n.samples</code></td>
<td>

<p>The number of posterior draws after burn in, <code>ndpost / keepevery</code> will actually be returned.
</p>
</td></tr>
<tr><td><code id="bart_+3A_nskip">nskip</code>, <code id="bart_+3A_n.burn">n.burn</code></td>
<td>

<p>Number of MCMC iterations to be treated as burn in.
</p>
</td></tr>
<tr><td><code id="bart_+3A_printevery">printevery</code>, <code id="bart_+3A_printevery">printEvery</code></td>
<td>

<p>As the MCMC runs, a message is printed every <code>printevery</code> draws.
</p>
</td></tr>
<tr><td><code id="bart_+3A_keepevery">keepevery</code>, <code id="bart_+3A_n.thin">n.thin</code></td>
<td>

<p>Every <code>keepevery</code> draw is kept to be returned to the user. Useful for &ldquo;thinning&rdquo; samples.
</p>
</td></tr>
<tr><td><code id="bart_+3A_keeptrainfits">keeptrainfits</code>, <code id="bart_+3A_keeptrainingfits">keepTrainingFits</code></td>
<td>

<p>If <code>TRUE</code> the draws of <code class="reqn">f(x)</code> for <code class="reqn">x</code> corresponding to the rows of <code>x.train</code> are returned.
</p>
</td></tr>
<tr><td><code id="bart_+3A_usequants">usequants</code>, <code id="bart_+3A_usequantiles">useQuantiles</code></td>
<td>

<p>When <code>TRUE</code>, determine tree decision rules using estimated quantiles derived from the <code>x.train</code> variables. When <code>FALSE</code>, splits are determined using values equally spaced across the range of a variable. See details for more information.
</p>
</td></tr>
<tr><td><code id="bart_+3A_numcut">numcut</code>, <code id="bart_+3A_n.cuts">n.cuts</code></td>
<td>

<p>The maximum number of possible values used in decision rules (see <code>usequants</code>, details). If a single number, it is recycled for all variables; otherwise must be a vector of length equal to <code>ncol(x.train)</code>. Fewer rules may be used if a covariate lacks enough unique values.
</p>
</td></tr>
<tr><td><code id="bart_+3A_printcutoffs">printcutoffs</code>, <code id="bart_+3A_printcutoffs">printCutoffs</code></td>
<td>

<p>The number of cutoff rules to printed to screen before the MCMC is run. Given a single integer, the same value will be used for all variables. If 0, nothing is printed.
</p>
</td></tr>
<tr><td><code id="bart_+3A_verbose">verbose</code></td>
<td>

<p>Logical; if <code>FALSE</code> supress printing.
</p>
</td></tr>
<tr><td><code id="bart_+3A_nchain">nchain</code>, <code id="bart_+3A_n.chains">n.chains</code></td>
<td>

<p>Integer specifying how many independent tree sets and fits should be calculated.
</p>
</td></tr>
<tr><td><code id="bart_+3A_nthread">nthread</code>, <code id="bart_+3A_n.threads">n.threads</code></td>
<td>

<p>Integer specifying how many threads to use. Depending on the CPU architecture, using more than the number of chains can degrade performance for small/medium data sets. As such some calculations may be executed single threaded regardless.
</p>
</td></tr>
<tr><td><code id="bart_+3A_combinechains">combinechains</code>, <code id="bart_+3A_combinechains">combineChains</code></td>
<td>

<p>Logical; if <code>TRUE</code>, samples will be returned in arrays of dimensions equal to <code>nchain</code> <code class="reqn">\times</code> <code>ndpost</code> <code class="reqn">\times</code> number of observations.
</p>
</td></tr>
<tr><td><code id="bart_+3A_keeptrees">keeptrees</code>, <code id="bart_+3A_keeptrees">keepTrees</code></td>
<td>

<p>Logical; must be <code>TRUE</code> in order to use <code>predict</code> with the result of a <code>bart</code> fit. Note that for models with a large number of observations or a large number of trees, keeping the trees can be very memory intensive.
</p>
</td></tr>
<tr><td><code id="bart_+3A_keepcall">keepcall</code>, <code id="bart_+3A_keepcall">keepCall</code></td>
<td>

<p>Logical; if <code>FALSE</code>, returned object will have <code>call</code> set to <code>call("NULL")</code>, otherwise the call used to instantiate BART.
</p>
</td></tr>
<tr><td><code id="bart_+3A_seed">seed</code></td>
<td>

<p>Optional integer specifying the desired pRNG <a href="base.html#topic+set.seed">seed</a>. It should not be needed when running single-threaded - <code><a href="base.html#topic+set.seed">set.seed</a></code> will suffice, and can be used to obtain reproducible results when multi-threaded. See Reproducibility section below.
</p>
</td></tr>
<tr><td><code id="bart_+3A_proposalprobs">proposalprobs</code>, <code id="bart_+3A_proposal.probs">proposal.probs</code></td>
<td>

<p>Named numeric vector or <code>NULL</code>, optionally specifying the proposal rules and their probabilities. Elements should be <code>"birth_death"</code>, <code>"change"</code>, and <code>"swap"</code> to control tree change proposals, and <code>"birth"</code> to give the relative frequency of birth/death in the <code>"birth_death"</code> step. Defaults are 0.5, 0.1, 0.4, and 0.5 respectively.
</p>
</td></tr>
<tr><td><code id="bart_+3A_keepsampler">keepsampler</code>, <code id="bart_+3A_keepsampler">keepSampler</code></td>
<td>

<p>Logical that can be used to save the underlying <code><a href="#topic+dbartsSampler-class">dbartsSampler-class</a></code> object even if <code>keepTrees</code> is false.
</p>
</td></tr>
<tr><td><code id="bart_+3A_formula">formula</code></td>
<td>

<p>The same as <code>x.train</code>, the name reflecting that a formula object can be used instead.
</p>
</td></tr>
<tr><td><code id="bart_+3A_data">data</code></td>
<td>

<p>The same as <code>y.train</code>, the name reflecting that a data frame can be specified when a formula is given instead.
</p>
</td></tr>
<tr><td><code id="bart_+3A_test">test</code></td>
<td>

<p>The same as <code>x.train</code>. Can be missing.
</p>
</td></tr>
<tr><td><code id="bart_+3A_subset">subset</code></td>
<td>

<p>A vector of logicals or indicies used to subset of the data. Can be missing.
</p>
</td></tr>
<tr><td><code id="bart_+3A_offset">offset</code></td>
<td>

<p>The same as <code>binaryOffset</code>. Can be missing.
</p>
</td></tr>
<tr><td><code id="bart_+3A_offset.test">offset.test</code></td>
<td>

<p>A vector of offsets to be used with test data, in case it is different than the training offset. If <code>offest</code> is missing, defaults to <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="bart_+3A_object">object</code></td>
<td>

<p>An object of class <code>bart</code>, returned from either the function <code>bart</code> or <code>bart2</code>.
</p>
</td></tr>
<tr><td><code id="bart_+3A_newdata">newdata</code></td>
<td>

<p>Test data for prediction. Obeys all the same rules as <code>x.train</code> but cannot be missing.
</p>
</td></tr>
<tr><td><code id="bart_+3A_sampleronly">sampleronly</code>, <code id="bart_+3A_sampleronly">samplerOnly</code></td>
<td>

<p>Builds the sampler from its arguments and returns it without running it. Useful to use the <code>bart2</code> interface in more complicated models.
</p>
</td></tr>
<tr><td><code id="bart_+3A_x">x</code></td>
<td>

<p>Object of class <code>bart</code>, returned by function <code>bart</code>, which contains the information to be plotted.
</p>
</td></tr>
<tr><td><code id="bart_+3A_plquants">plquants</code></td>
<td>

<p>In the plots, beliefs about <code class="reqn">f(x)</code> are indicated by plotting the posterior median and a lower and upper quantile. <code>plquants</code> is a double vector of length two giving the lower and upper quantiles.
</p>
</td></tr>
<tr><td><code id="bart_+3A_cols">cols</code></td>
<td>

<p>Vector of two colors. First color is used to plot the median of <code class="reqn">f(x)</code> and the second color is used to plot the lower and upper quantiles.
</p>
</td></tr>
<tr><td><code id="bart_+3A_type">type</code></td>
<td>

<p>The quantity to be returned by generic functions. Options are <code>"ev"</code> - samples from the posterior of the individual level expected value, <code>"bart"</code> - the sum of trees component; same as <code>"ev"</code> for linear models but on the probit scale for binary ones, <code>"ppd"</code> - samples from the posterior predictive distribution, and <code>"trees"</code> - a data frame with tree information for when model was fit with <code>keepTrees</code> equal to <code>TRUE</code>. To synergize with <code><a href="stats.html#topic+predict.glm">predict.glm</a></code>, <code>"response"</code> can be used as a synonym for <code>"ev"</code> and <code>"link"</code> can be used as a synonym for <code>"bart"</code>. For information on extracting trees, see the subsection below.
</p>
</td></tr>
<tr><td><code id="bart_+3A_sample">sample</code></td>
<td>

<p>Either <code>"train"</code> or <code>"test"</code>.
</p>
</td></tr>
<tr><td><code id="bart_+3A_...">...</code></td>
<td>

<p>Additional arguments passed on to <code>plot</code>, <code>dbartsControl</code>, or <code>extract</code> when <code>type</code> is <code>"trees"</code>. Not used in <code>predict</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>BART is an Bayesian MCMC method. At each MCMC interation, we produce a draw from the joint posterior <code class="reqn">(f, \sigma) \mid (x, y)</code> in the numeric <code class="reqn">y</code> case and just <code class="reqn">f</code> in the binary <code class="reqn">y</code> case.
</p>
<p>Thus, unlike a lot of other modeling methods in R, <code>bart</code> does not produce a single model object from which fits and summaries may be extracted. The output consists of values <code class="reqn">f^*(x)</code> (and <code class="reqn">\sigma^*</code> in the numeric case) where * denotes a particular draw. The <code class="reqn">x</code> is either a row from the training data (<code>x.train</code>) or the test data (<code>x.test</code>).
</p>


<h4>Decision Rules</h4>

<p>Decision rules for any tree are of the form <code class="reqn">x \le c</code>  vs. <code class="reqn">x &gt; c</code> for each &lsquo;<code class="reqn">x</code>&rsquo; corresponding to a column of <code>x.train</code>. <code>usequants</code> determines the means by which the set of possible <code class="reqn">c</code> is determined. If <code>usequants</code> is <code>TRUE</code>, then the <code class="reqn">c</code> are a subset of the values interpolated half-way between the unique, sorted values obtained from the corresponding column of <code>x.train</code>. If <code>usequants</code> is <code>FALSE</code>, the cutoffs are equally spaced across the range of values taken on by the corresponding column of <code>x.train</code>.
</p>
<p>The number of possible values of <code class="reqn">c</code> is determined by <code>numcut</code>. If <code>usequants</code> is <code>FALSE</code>, <code>numcut</code> equally spaced cutoffs are used covering the range of values in the corresponding column of <code>x.train</code>. If <code>usequants</code> is <code>TRUE</code>, then for a variable the minimum of <code>numcut</code> and one less than the number of unique elements for that variable are used.
</p>



<h4>End-node prior parameter <code>k</code></h4>

<p>The amount of shrinkage of the node parameters is controlled by <code>k</code>. <code>k</code> can be given as either a fixed, positive number, or as any value that can be used to build a supported hyperprior. At present, only <code class="reqn">\chi_\nu s</code> priors are supported, where <code class="reqn">\nu</code> is a degrees of freedom and <code class="reqn">s</code> is a scale. Both values must be positive, however the scale can be infinite which yields an improper prior, which is interpretted as just the polynomial part of the distribution. If <code class="reqn">nu</code> is 1 and <code class="reqn">s</code> is <code class="reqn">\infty</code>, the prior is &ldquo;flat&rdquo;.
</p>
<p>For BART on binary outcomes, the degree of overfitting can be highly sensitive to <code>k</code> so it is encouraged to consider a number of values. The default hyperprior for binary BART, <code>chi(1.25, Inf)</code>, has been shown to work well in a large number of datasets, however crossvalidation may be helpful. Running for a short time with a flat prior may be helpful to see the range of values of <code>k</code> that are consistent with the data.
</p>



<h4>Generics</h4>

<p><code>bart</code> and <code><a href="#topic+rbart_vi">rbart_vi</a></code> support <code><a href="stats.html#topic+fitted">fitted</a></code> to return the posterior mean of a predicted quantity, as well as <code><a href="stats.html#topic+predict">predict</a></code> to return a set of posterior samples for a different sample. In addition, the <code>extract</code> generic can be used to obtain the posterior samples for the training data or test data supplied during the initial fit.
</p>
<p>Using <code>predict</code> with a <code>bart</code> object requires that it be fitted with the option <code>keeptrees</code>/<code>keepTrees</code> as <code>TRUE</code>. Keeping the trees for a fit can require a sizeable amount of memory and is off by default.
</p>
<p>All generics return values on the scale of expected value of the response by default. This means that <code>predict</code>, <code>extract</code>, and <code>fitted</code> for binary outcomes return probabilities unless specifically the sum-of-trees component is requested (<code>type = "bart"</code>). This is in contrast to <code>yhat.train</code>/<code>yhat.test</code> that are returned with the fitted model.
</p>



<h4>Saving</h4>

<p><code><a href="base.html#topic+save">save</a></code>ing and <code><a href="base.html#topic+load">load</a></code>ing fitted BART objects for use with <code>predict</code> requires that R's serialization mechanism be able to access the underlying trees, in addition to being fit with <code>keeptrees</code>/<code>keepTrees</code> as <code>TRUE</code>. For memory purposes, the trees are not stored as R objects unless specifically requested. To do this, one must &ldquo;touch&rdquo; the sampler's state object before saving, e.g. for a fitted object <code>bartFit</code>, execute <code>invisible(bartFit$fit$state)</code>.
</p>



<h4>Reproducibility</h4>

<p>Behavior differs when running multi- and single-threaded, as the pseudo random number generators (pRNG) used by R are not thread safe. When single-threaded, R's built-in generator is used; if set at the start, the global <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> will be used and its value updated as samples are drawn. When multi-threaded, the default behavior is to draw new random seeds for each thread using the clock and use thread-specific pRNGs.
</p>
<p>This behavior can be modified by setting <code>seed</code>, or by using <code>...</code> to pass arguments to <code><a href="#topic+dbartsControl">dbartsControl</a></code>. For the single-threaded case, a new pRNG is built using that seed that is separate from R's native generator. As such, the global state will not be modified by subsequent calls to the generator. For multi-threaded, the seeds for threads are drawn sequentially using the supplied seed, and will again be separate from R's native generator.
</p>
<p>Consequently, the <code>seed</code> argument is not needed when running single-threaded - <code><a href="base.html#topic+set.seed">set.seed</a></code> will suffice. However, when multi-threaded the <code>seed</code> argument can be used to obtain reproducible results.
</p>



<h4>Extracting Trees</h4>

<p>When a model is fit with <code>keeptrees</code> (<code>bart</code>) or <code>keepTrees</code> (<code>bart2</code>) equal to <code>TRUE</code>, the generic <code>extract</code> can be used to retrieve a data frame containing the tree fit information. In this case, <code>extract</code> will accept the additional, optional arguments: <code>chainNums</code>, <code>sampleNums</code>, and <code>treeNums</code>. Each should be an integer vector detailing the desired trees to be returned.
</p>
<p>The result of <code>extract</code> will be a data frame with columns:
</p>

<ul>
<li> <p><code>sample</code>, <code>chain</code>, <code>tree</code> - index variables
</p>
</li>
<li> <p><code>n</code> - number of observations in node
</p>
</li>
<li> <p><code>var</code> - either the index of the variable used for splitting or -1 if the node is a leaf
</p>
</li>
<li> <p><code>value</code> - either the value such that observations less than or equal to it are sent down the left path of the tree or the predicted value for a leaf node
</p>
</li></ul>

<p>The order of nodes in the result corresponds to a depth-first traversal, going down the left-side first. The names of variables used in splitting can be recovered by examining the column names of the <code>fit$data@x</code> element of a fitted <code>bart</code> or <code>bart2</code> model. See the package vignette &ldquo;Working with dbarts Saved Trees&rdquo;.
</p>



<h3>Value</h3>

<p><code>bart</code> and <code>bart2</code> return lists assigned the class <code>bart</code>. For applicable quantities, <code>ndpost / keepevery</code> samples are returned. In the numeric <code class="reqn">y</code> case, the list has components:
</p>
<table>
<tr><td><code>yhat.train</code></td>
<td>

<p>A array/matrix of posterior samples. The <code class="reqn">(i, j, k)</code> value is the <code class="reqn">j</code>th draw of the posterior of <code class="reqn">f</code> evaluated at the <code class="reqn">k</code>th row of <code>x.train</code> (i.e. <code class="reqn">f^*(x_k)</code>) corresponding to chain <code class="reqn">i</code>. When <code>nchain</code> is one or <code>combinechains</code> is <code>TRUE</code>, the result is a collapsed down to a matrix.
</p>
</td></tr>
<tr><td><code>yhat.test</code></td>
<td>

<p>Same as <code>yhat.train</code> but now the <code class="reqn">x</code>s are the rows of the test data.
</p>
</td></tr>
<tr><td><code>yhat.train.mean</code></td>
<td>

<p>Vector of means of <code>yhat.train</code> across columns and chains, with length equal to the number of training observations.
</p>
</td></tr>
<tr><td><code>yhat.test.mean</code></td>
<td>

<p>Vector of means of <code>yhat.test</code> across columns and chains.
</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>

<p>Matrix of posterior samples of <code>sigma</code>, the residual/error standard deviation. Dimensions are equal to the number of chains times the numbers of samples unless <code>nchain</code> is one or <code>combinechains</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code>first.sigma</code></td>
<td>

<p>Burn-in draws of <code>sigma</code>.
</p>
</td></tr>
<tr><td><code>varcount</code></td>
<td>

<p>A matrix with number of rows equal to the number of kept draws and each column corresponding to a training variable. Contains the total count of the number of times that variable is used in a tree decision rule (over all trees).
</p>
</td></tr>
<tr><td><code>sigest</code></td>
<td>

<p>The rough error standard deviation (<code class="reqn">\sigma</code>) used in the prior.
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>

<p>The input dependent vector of values for the dependent variable. This is used in <code>plot.bart</code>.
</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>

<p>Optional sampler object which stores the values of the tree splits. Required for using <code>predict</code> and only stored if <code>keeptrees</code> or <code>keepsampler</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code>n.chains</code></td>
<td>

<p>Information that can be lost if <code>combinechains</code> is <code>TRUE</code> is tracked here.
</p>
</td></tr>
<tr><td><code>k</code></td>
<td>

<p>Optional matrix of posterior samples of <code>k</code>. Only present when <code>k</code> is modeled, i.e. there is a hyperprior.
</p>
</td></tr>
<tr><td><code>first.k</code></td>
<td>

<p>Burn-in draws of <code>k</code>, if modeled.
</p>
</td></tr>
</table>
<p>In the binary <code class="reqn">y</code> case, the returned list has the components <code>yhat.train</code>, <code>yhat.test</code>, and <code>varcount</code> as above.  In addition the list has a <code>binaryOffset</code> component giving the value used.
</p>
<p>Note that in the binary <code class="reqn">y</code>, case <code>yhat.train</code> and <code>yhat.test</code> are <code class="reqn">f(x) + \mathrm{binaryOffset}</code>. For draws of the probability <code class="reqn">P(Y = 1 | x)</code>, apply the normal cdf (<code>pnorm</code>) to these values.
</p>
<p>The <code>plot</code> method sets <code>mfrow</code> to <code>c(1, 2)</code> and makes two plots. The first plot is the sequence of kept draws of <code class="reqn">\sigma</code> including the burn-in draws. Initially these draws will decline as BART finds a good fit and then level off when the MCMC has burnt in. The second plot has <code class="reqn">y</code> on the horizontal axis and posterior intervals for the corresponding <code class="reqn">f(x)</code> on the vertical axis.
</p>


<h3>Author(s)</h3>

<p>Hugh Chipman: <a href="mailto:hugh.chipman@gmail.com">hugh.chipman@gmail.com</a>,
Robert McCulloch: <a href="mailto:robert.mcculloch1@gmail.com">robert.mcculloch1@gmail.com</a>,
Vincent Dorie: <a href="mailto:vdorie@gmail.com">vdorie@gmail.com</a>.
</p>


<h3>References</h3>

<p>Chipman, H., George, E., and McCulloch, R. (2009)
BART: Bayesian Additive Regression Trees.
</p>
<p>Chipman, H., George, E., and McCulloch R. (2006)
Bayesian Ensemble Learning. 
Advances in Neural Information Processing Systems 19,
Scholkopf, Platt and Hoffman, Eds., MIT Press, Cambridge, MA, 265-272.
</p>
<p>both of the above at:
<a href="https://www.rob-mcculloch.org">https://www.rob-mcculloch.org</a>
</p>
<p>Friedman, J.H. (1991)
Multivariate adaptive regression splines.
<em>The Annals of Statistics</em>, <b>19</b>, 1&ndash;67.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdbart">pdbart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## simulate data (example from Friedman MARS paper)
## y = f(x) + epsilon , epsilon ~ N(0, sigma)
## x consists of 10 variables, only first 5 matter

f &lt;- function(x) {
    10 * sin(pi * x[,1] * x[,2]) + 20 * (x[,3] - 0.5)^2 +
        10 * x[,4] + 5 * x[,5]
}

set.seed(99)
sigma &lt;- 1.0
n     &lt;- 100

x  &lt;- matrix(runif(n * 10), n, 10)
Ey &lt;- f(x)
y  &lt;- rnorm(n, Ey, sigma)

## run BART
set.seed(99)
bartFit &lt;- bart(x, y)

plot(bartFit)

## compare BART fit to linear matter and truth = Ey
lmFit &lt;- lm(y ~ ., data.frame(x, y))

fitmat &lt;- cbind(y, Ey, lmFit$fitted, bartFit$yhat.train.mean)
colnames(fitmat) &lt;- c('y', 'Ey', 'lm', 'bart')
print(cor(fitmat))
</code></pre>

<hr>
<h2 id='dbarts'>Discrete Bayesian Additive Regression Trees Sampler</h2><span id='topic+dbarts'></span>

<h3>Description</h3>

<p>Creates a sampler object for a given problem which fits a Bayesian Additive Regreesion Trees model. Internally stores state in such a way as to be mutable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbarts(
    formula, data, test, subset, weights, offset, offset.test = offset,
    verbose = FALSE, n.samples = 800L,
    tree.prior = cgm, node.prior = normal, resid.prior = chisq,
    proposal.probs = c(
        birth_death = 0.5, swap = 0.1, change = 0.4, birth = 0.5),
    control = dbarts::dbartsControl(), sigma = NA_real_)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbarts_+3A_formula">formula</code></td>
<td>

<p>An object of class <code><a href="stats.html#topic+formula">formula</a></code> following an analogous model description syntax as <code><a href="stats.html#topic+lm">lm</a></code>. For backwards compatibility, can also be the <code><a href="#topic+bart">bart</a></code> matrix <code>x.train</code>.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_data">data</code></td>
<td>

<p>An optional data frame, list, or environment containing predictors to be used with the model. For backwards compatibility, can also be the <code><a href="#topic+bart">bart</a></code> vector <code>y.train</code>.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_test">test</code></td>
<td>

<p>An optional matrix or data frame with the same number of predictors as <code>data</code>, or <code>formula</code> in backwards compatibility mode. If column names are present, a matching algorithm is used.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_subset">subset</code></td>
<td>

<p>An optional vector specifying a subset of observations to be used in the fitting process.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_weights">weights</code></td>
<td>

<p>An optional vector of weights to be used in the fitting process. When present, BART fits a model with observations <code class="reqn">y \mid x \sim N(f(x), \sigma^2 / w)</code>, where <code class="reqn">f(x)</code> is the unknown function.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_offset">offset</code></td>
<td>

<p>An optional vector specifying an offset from 0 for the relationship between the underyling function, <code class="reqn">f(x)</code>, and the response <code class="reqn">y</code>. Only is useful for binary responses, in which case the model fit is to assume <code class="reqn">P(Y = 1 \mid X = x) = \Phi(f(x) + \mathrm{offset})</code>, where <code class="reqn">\Phi</code> is the standard normal cumulative distribution function.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_offset.test">offset.test</code></td>
<td>

<p>The equivalent of <code>offset</code> for test observations. Will attempt to use <code>offset</code> when applicable.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_verbose">verbose</code></td>
<td>

<p>A logical determining if additional output is printed to the console. See <code><a href="#topic+dbartsControl">dbartsControl</a></code>.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_n.samples">n.samples</code></td>
<td>

<p>A positive integer setting the default number of posterior samples to be returned for each run of the sampler. Can be overriden at run-time. See <code><a href="#topic+dbartsControl">dbartsControl</a></code>.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_tree.prior">tree.prior</code></td>
<td>

<p>An expression of the form <code>cgm</code> or <code>cgm(power, base, split.probs)</code> setting the tree prior used in fitting.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_node.prior">node.prior</code></td>
<td>

<p>An expression of the form <code>normal</code> or <code>normal(k)</code> that sets the prior used on the averages within nodes.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_resid.prior">resid.prior</code></td>
<td>

<p>An expression of the form <code>chisq</code> or <code>chisq(df, quant)</code> that sets the prior used on the residual/error variance.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_proposal.probs">proposal.probs</code></td>
<td>

<p>Named numeric vector or <code>NULL</code>, optionally specifying the proposal rules and their probabilities. Elements should be <code>"birth_death"</code>, <code>"change"</code>, and <code>"swap"</code> to control tree change proposals, and <code>"birth"</code> to give the relative frequency of birth/death in the <code>"birth_death"</code> step.
</p>
</td></tr>
<tr><td><code id="dbarts_+3A_control">control</code></td>
<td>

<p>An object inheriting from <code>dbartsControl</code>, created by the <code><a href="#topic+dbartsControl">dbartsControl</a></code> function.</p>
</td></tr> <tr><td><code id="dbarts_+3A_sigma">sigma</code></td>
<td>
<p>A positive numeric estimate of the residual standard deviation. If <code>NA</code>, a linear model is used with all of the predictors to obtain one.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&ldquo;Discrete sampler&rdquo; refers to that <code>dbarts</code> is implemented using <a href="methods.html#topic+ReferenceClasses">ReferenceClasses</a>, so that there exists a mutable object constructed in C++ that is largely obscured from R. The <code>dbarts</code> function is the primary way of creating a <code><a href="#topic+dbartsSampler-class">dbartsSampler</a></code>, for which a variety of methods exist.
</p>


<h3>Value</h3>

<p>A reference object of <code><a href="#topic+dbartsSampler-class">dbartsSampler</a></code>.
</p>

<hr>
<h2 id='dbartsControl'>Discrete Bayesian Additive Regression Trees Sampler Control</h2><span id='topic+dbartsControl'></span>

<h3>Description</h3>

<p>Convenience function to create a control object for use with a <code><a href="#topic+dbarts">dbarts</a></code> sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbartsControl(
    verbose = FALSE, keepTrainingFits = TRUE, useQuantiles = FALSE,
    keepTrees = FALSE, n.samples = NA_integer_,
    n.cuts = 100L, n.burn = 200L, n.trees = 75L, n.chains = 4L,
    n.threads = dbarts::guessNumCores(), n.thin = 1L, printEvery = 100L,
    printCutoffs = 0L,
    rngKind = "default", rngNormalKind = "default", rngSeed = NA_integer_,
    updateState = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbartsControl_+3A_verbose">verbose</code></td>
<td>

<p>Logical controlling sampler output to console.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_keeptrainingfits">keepTrainingFits</code></td>
<td>

<p>Logical controlling whether or not training fits are returned when the sampler runs. These are always computed as part of the fitting procedure, so disabling will not substantially impact running time.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_usequantiles">useQuantiles</code></td>
<td>

<p>Logical to determine if the empirical quantiles of a columns of predictors should be used to determine the tree decision rules. If <code>FALSE</code>, the rules are spaced uniformly throughout the range of covariate values.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_keeptrees">keepTrees</code></td>
<td>

<p>A logical that determines whether or not trees are cached as they are sampled. In all cases, the current state of the sampler is stored as a single set of <code>n.trees</code>. When <code>keepTrees</code> is <code>TRUE</code>, a set of <code>n.trees * n.samples</code> trees are set aside and populated as the sampler runs. If the sampler is stopped and restarted, samples proceed from the previously stored tree, looping over if necessary.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_n.samples">n.samples</code></td>
<td>

<p>A non-negative integer giving the default number of samples to return each time the sampler is run. Generally specified by <code><a href="#topic+dbarts">dbarts</a></code> instead, and can be overridden on a per-use basis whenever the sampler is <code><a href="#topic+dbartsSampler-class">run</a></code>.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_n.cuts">n.cuts</code></td>
<td>

<p>A positive integer or integer vector giving the number of decision rules to be used for each given predictor. If of length less than the number of predictors, earlier values are recycled. If for any predictor more values are specified than are coherent, fewer may be used. See details for more information.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_n.burn">n.burn</code></td>
<td>

<p>A non-negative integer determining how many samples, if any, are thrown away at the beginning of a run of the sampler.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_n.trees">n.trees</code></td>
<td>

<p>A positive integer giving the number of trees used in the sum-of-trees formulation.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_n.chains">n.chains</code></td>
<td>

<p>A positive integer detailing the number of independent chains for the sampler to use.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_n.threads">n.threads</code></td>
<td>

<p>A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (&gt;10k), so that it is often not necessary to have the number of threads exceed the number of chains.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_n.thin">n.thin</code></td>
<td>

<p>A positive integer determining how many iterations the MCMC chain should jump on the decision trees alone before recording a sample. Serves to &ldquo;thin&rdquo; the samples against serial correlation. <code>n.samples</code> are returned regardless of the value of <code>n.thin</code>.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_printevery">printEvery</code></td>
<td>

<p>If <code>verbose</code> is <code>TRUE</code>, every <code>printEvery</code> potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_printcutoffs">printCutoffs</code></td>
<td>

<p>A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_rngkind">rngKind</code></td>
<td>

<p>Random number generator kind, as used in <code><a href="base.html#topic+Random">set.seed</a></code>. For type <code>"default"</code>, the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator's type. Success depends on the number of threads.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_rngnormalkind">rngNormalKind</code></td>
<td>

<p>Random number generator normal kind, as used in <code><a href="base.html#topic+Random">set.seed</a></code>. For type <code>"default"</code>, the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator's type. Success depends on the number of threads and the <code>rngKind</code>.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_rngseed">rngSeed</code></td>
<td>

<p>Random number generator seed, as used in <code><a href="base.html#topic+Random">set.seed</a></code>. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the thread-specific pRNGs. If equal to <code>NA</code>, the clock will be used to seed pRNGs when applicable.
</p>
</td></tr>
<tr><td><code id="dbartsControl_+3A_updatestate">updateState</code></td>
<td>

<p>Logical setting the default behavior for many <a href="#topic+dbartsSampler-class">sampler</a> methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when <a href="base.html#topic+save">saving</a>/<a href="base.html#topic+load">loading</a> the sampler.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>dbartControl</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbarts">dbarts</a></code>
</p>

<hr>
<h2 id='dbartsData'>Discrete Bayesian Additive Regression Trees Sampler Data</h2><span id='topic+dbartsData'></span>

<h3>Description</h3>

<p>Convenience function to create a data object for use with a <code><a href="#topic+dbarts">dbarts</a></code> sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbartsData(
    formula, data, test, subset, weights,
    offset, offset.test = offset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbartsData_+3A_formula">formula</code>, <code id="dbartsData_+3A_data">data</code>, <code id="dbartsData_+3A_test">test</code>, <code id="dbartsData_+3A_subset">subset</code>, <code id="dbartsData_+3A_weights">weights</code>, <code id="dbartsData_+3A_offset">offset</code>, <code id="dbartsData_+3A_offset.test">offset.test</code></td>
<td>

<p>As in <code><a href="#topic+dbarts">dbarts</a></code>. Retains backwards compatibility with <code><a href="#topic+bart">bart</a></code>, so that <code>formula</code>/<code>data</code> can be a <code><a href="stats.html#topic+formula">formula</a></code>/<code><a href="base.html#topic+data.frame">data.frame</a></code> pair, or a pair of <code>x.train</code>/<code>y.train</code> matrices/vector.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>dbartData</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbarts">dbarts</a></code>
</p>

<hr>
<h2 id='dbartsSampler-class'>Class &quot;dbartsSampler&quot; of Discrete Bayesian Additive Regression Trees Sampler</h2><span id='topic+dbartsSampler'></span><span id='topic+dbartsSampler-class'></span><span id='topic++5CS4method+7Brun+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsampleTreesFromPrior+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsampleNodeParametersFromPrior+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7Bcopy+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7Bshow+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7Bpredict+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetControl+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetModel+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetData+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetResponse+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetOffset+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetSigma+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetPredictor+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetTestPredictor+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetTestPredictorAndOffset+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BsetTestOffset+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BprintTrees+7D+7BdbartsSampler+7D'></span><span id='topic++5CS4method+7BplotTree+7D+7BdbartsSampler+7D'></span>

<h3>Description</h3>

<p>A reference class object that contains a Bayesian Additive Regression Trees sampler in such a way that it can be modified, stopped, and started all while maintaining its own state.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dbartsSampler'
run(numBurnIn, numSamples, updateState = NA)
## S4 method for signature 'dbartsSampler'
sampleTreesFromPrior(updateState = NA)
## S4 method for signature 'dbartsSampler'
sampleNodeParametersFromPrior(updateState = NA)
## S4 method for signature 'dbartsSampler'
copy(shallow = FALSE)
## S4 method for signature 'dbartsSampler'
show()
## S4 method for signature 'dbartsSampler'
predict(x.test, offset.test)
## S4 method for signature 'dbartsSampler'
setControl(control)
## S4 method for signature 'dbartsSampler'
setModel(model)
## S4 method for signature 'dbartsSampler'
setData(data)
## S4 method for signature 'dbartsSampler'
setResponse(y, updateState = NA)
## S4 method for signature 'dbartsSampler'
setOffset(offset, updateScale = FALSE, updateState = NA)
## S4 method for signature 'dbartsSampler'
setSigma(sigma, updateState = NA)
## S4 method for signature 'dbartsSampler'
setPredictor(x, column, updateState = NA)
## S4 method for signature 'dbartsSampler'
setTestPredictor(x.test, column, updateState = NA)
## S4 method for signature 'dbartsSampler'
setTestPredictorAndOffset(x.test, offset.test, updateState = NA)
## S4 method for signature 'dbartsSampler'
setTestOffset(offset.test, updateState = NA)
## S4 method for signature 'dbartsSampler'
printTrees(treeNums)
## S4 method for signature 'dbartsSampler'
plotTree(
    treeNum, treePlotPars = c(
        nodeHeight = 12, nodeWidth = 40, nodeGap = 8),
    ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbartsSampler-class_+3A_numburnin">numBurnIn</code></td>
<td>

<p>A non-negative integer determining how many iterations the sampler should skip before storing results. If missing or <code>NA</code>, the default is filled in from the sampler's <code><a href="#topic+dbartsControl">control</a></code> object.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_numsamples">numSamples</code></td>
<td>

<p>A positive integer determining how many posterior samples should be returned. If missing or <code>NA</code>, the default is also filled in from the control object.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_updatestate">updateState</code></td>
<td>

<p>A logical determining if the local cache of the sampler's state should be updated after the completion of the run. If <code>NA</code>, the default is also filled in from the control object.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_shallow">shallow</code></td>
<td>

<p>A logical determining if the copy should retain the underlying data of the sampler (<code>TRUE</code>) or have its own copies (<code>FALSE</code>).
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_control">control</code></td>
<td>

<p>An object inheriting from <code><a href="#topic+dbartsControl">dbartsControl</a></code>.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_model">model</code></td>
<td>

<p>An object inheriting from <code>dbartsModel</code>.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_data">data</code></td>
<td>

<p>An object inheriting from <code><a href="#topic+dbartsData">dbartsData</a></code>.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_y">y</code></td>
<td>

<p>A numeric response vector of length equal to that with which the sampler was created.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_x">x</code></td>
<td>

<p>A numeric predictor vector of length equal to that with which the sampler was created. Can be of a distinct number of rows for <code>setTestPredictor</code>.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_x.test">x.test</code></td>
<td>

<p>A new matrix of test predictors, of the number of columns equal to that in the current model.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_offset">offset</code></td>
<td>

<p>A numeric vector of length equal to that with which the sampler was created, or <code>NULL</code>. If <code>offset.test</code> was set from <code>offset</code>, will attempt to update that as well.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_updatescale">updateScale</code></td>
<td>

<p>Logical indicating whether BART's internal scale should update with the new offset. Should only be <code>TRUE</code> during burn-in.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_offset.test">offset.test</code></td>
<td>

<p>A numeric vector of length equal to that of the test matrix, or <code>NULL</code>. Can be missing for <code>setTestPredictors</code>.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_sigma">sigma</code></td>
<td>

<p>Numeric vector of residual standard deviations, one for each chain.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_column">column</code></td>
<td>

<p>An integer or character string vector specifying which column/columns of the predictor matrix is to be replaced. If missing, the entire matrix is substituted.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_treenums">treeNums</code></td>
<td>

<p>An integer vector listing the indices of the trees to print.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_treenum">treeNum</code></td>
<td>

<p>An integer listing the indices of the tree to plot.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_treeplotpars">treePlotPars</code></td>
<td>

<p>A named numeric vector containing the quantities <code>nodeHeight</code>, <code>nodeWidth</code>, and <code>nodeGap</code>, all of which control aspects of the resulting plot.
</p>
</td></tr>
<tr><td><code id="dbartsSampler-class_+3A_...">...</code></td>
<td>

<p>Extra arguments to <code><a href="base.html#topic+plot">plot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <code>dbartsSampler</code> is a mutable object which contains information pertaining to fitting a Bayesian additive regression tree model. The sampler is first created and then, in a separate instruction, run or modified. In this way, MCMC samplers can be constructed with BART components filling arbitrary roles.
</p>


<h4>Saving</h4>

<p><code><a href="base.html#topic+save">save</a></code>-ing and <code><a href="base.html#topic+load">load</a></code>ing a <code>dbarts</code> sampler for future use requires that R's serialization mechanism be able to access the state of the sampler which, for memory purposes, is only made available to R on request. To do this, one must &ldquo;touch&rdquo; the sampler's state object before saving, e.g. for the object <code>sampler</code>, execute <code>invisible(sampler$state)</code>. This is in addition to guaranteeing that the <code>state</code> object is not <code>NULL</code>, which can be done by setting the sampler's control to an object with <code>updateState</code> as <code>TRUE</code> or passing <code>TRUE</code> as the <code>updateState</code> argument to any of the sampler's applicable methods.
</p>



<h3>Value</h3>

<p>For <code>run</code>, a named-list with contents <code>sigma</code>, <code>train</code>, <code>test</code>, and <code>varcount</code>.
</p>
<p>For <code>setPredictor</code>, <code>TRUE</code>/<code>FALSE</code> depending on whether or not the operation was successful. The operation can fail if the new predictor results in a tree with an empty leaf-node. If only single columns were replaced, on the update is rolled-back so that the sampler remains in a valid state.
</p>
<p><code>predict</code> keeps the current test matrix in place and uses the current set of tree splits. This function has two use cases. The first is when <code>keepTrees</code> of <code><a href="#topic+dbartsControl">dbartsControl</a></code> is <code>TRUE</code>, in which case the sampler should be run to completion and the function can be used to interrogate the existing fit. When <code>keepTrees</code> is <code>FALSE</code>, the function can be used to obtain the likelihood as part of a proposed new set of covariates in a Metropolis-Hastings step in a full-Bayes sampler. This would typically be followed by a call to <code>setPredictor</code> if the step is accepted.
</p>

<hr>
<h2 id='guessNumCores'>Guess Number of Cores</h2><span id='topic+guessNumCores'></span>

<h3>Description</h3>

<p>Attempts to guess the number of CPU &lsquo;cores&rsquo;, both physical and logical.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>guessNumCores(logical = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="guessNumCores_+3A_logical">logical</code></td>
<td>

<p>A logical value. When <code>FALSE</code>, an estimate of the number of physical cores is returned. When <code>TRUE</code>, so-called &ldquo;logical&rdquo; cores as also included.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because of different definitions of cores used by different manufacturers, the distinction between logical and physical cores is not universally recognized. This function will attempt to use operating system definitions when available, which should usually match the CPU itself.
</p>


<h3>Value</h3>

<p>An integer, or NA if no clear answer was obtained.
</p>


<h3>Author(s)</h3>

<p>Vincent Dorie: <a href="mailto:vdorie@gmail.com">vdorie@gmail.com</a>.
</p>

<hr>
<h2 id='makeModelMatrixFromDataFrame'>Make Model Matrix from Data Frame</h2><span id='topic+makeModelMatrixFromDataFrame'></span><span id='topic+makeind'></span><span id='topic+makeTestModelMatrix'></span>

<h3>Description</h3>

<p>Converts a data frame with numeric and factor contents into a matrix, suitable for use with <code><a href="#topic+bart">bart</a></code>. Unlike in linear regression, factors containing more than two levels result in dummy variables being created for each level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeModelMatrixFromDataFrame(x, drop = TRUE)
makeind(x, all = TRUE)
makeTestModelMatrix(data, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeModelMatrixFromDataFrame_+3A_x">x</code></td>
<td>

<p>Data frame of explanatory variables.
</p>
</td></tr>
<tr><td><code id="makeModelMatrixFromDataFrame_+3A_drop">drop</code></td>
<td>
<p>Logical or list controling whether or not columns that are constants or factor levels with no instances are omitted from the result. When a list, must be of length equal to <code>x</code>. Elements correspond to <code>x</code> according to:
</p>

<ul>
<li><p> vector - single logical
</p>
</li>
<li><p> matrix - vector of logicals, one per column
</p>
</li>
<li><p> factor - table of factor levels to be referenced; levels with counts of 0 are to be dropped
</p>
</li></ul>

</td></tr>
<tr><td><code id="makeModelMatrixFromDataFrame_+3A_all">all</code></td>
<td>

<p>Not currently implemented.
</p>
</td></tr>
<tr><td><code id="makeModelMatrixFromDataFrame_+3A_data">data</code></td>
<td>

<p>An existing <code><a href="#topic+dbartsData">dbartsData</a></code> object.
</p>
</td></tr>
<tr><td><code id="makeModelMatrixFromDataFrame_+3A_newdata">newdata</code></td>
<td>

<p>Test data frame.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Character vectors are included as factors. If you have numeric data coded as characters, convert it using <code>as.numeric</code> first.
</p>
<p>Note that if you have train and test data frames, it may be best to <code><a href="base.html#topic+rbind">rbind</a></code> the two together, apply <code>makeModelMatrixFromDataFrame</code> to the result, and then pull them back apart. Alternatively, save the drop attribute used in creating the training data and use it when creating a matrix from the test data, as in the example given below.
</p>
<p>Use of these functions is not required when using <code><a href="#topic+bart">bart</a></code>, <code>bart2</code>, or <code><a href="#topic+dbartsSampler">dbartsSampler</a></code>; they exist to allow the user finer control and to assist with writing packages that separate the creation of training from test data.
</p>


<h3>Value</h3>

<p>A matrix with columns corresponding to the elements of the data frame. If <code>drop = TRUE</code> or is a list, the attribute <code>drop</code> on the result is set to the list used when creating the matrix.
</p>


<h3>Author(s)</h3>

<p>Vincent Dorie: <a href="mailto:vdorie@gmail.com">vdorie@gmail.com</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>iv &lt;- 1:10
rv &lt;- runif(10)
f &lt;- factor(rep(seq.int(3), c(4L, 4L, 2L)),
            labels = c("alice", "bob", "charlie"))
df &lt;- data.frame(iv, rv, f)

mm &lt;- makeModelMatrixFromDataFrame(df)

## create test and train matrices with disjoint factor levels
train.df &lt;- df[1:8,]
test.df &lt;- df[9:10,]
train.mm &lt;- makeModelMatrixFromDataFrame(train.df)
test.mm &lt;- makeModelMatrixFromDataFrame(test.df, attr(train.mm, "drop"))
</code></pre>

<hr>
<h2 id='pdbart'>Partial Dependence Plots for BART</h2><span id='topic+pdbart'></span><span id='topic+plot.pdbart'></span><span id='topic+pd2bart'></span><span id='topic+plot.pd2bart'></span>

<h3>Description</h3>

<p>Run <code><a href="#topic+bart">bart</a></code> at test observations constructed so that a plot can be created displaying the effect of a single variable (<code>pdbart</code>) or pair of variables (<code>pd2bart</code>). Note that if <code class="reqn">y</code> is a binary with <code class="reqn">P(Y=1 | x) = F(f(x))</code>, <code class="reqn">F</code> the standard normal cdf, then the plots are all on the <code class="reqn">f</code> scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdbart(
    x.train, y.train,
    xind = NULL,
    levs = NULL, levquants = c(0.05, seq(0.1, 0.9, 0.1), 0.95),
    pl = TRUE, plquants = c(0.05, 0.95),
    ...)

## S3 method for class 'pdbart'
plot(
    x,
    xind = seq_len(length(x$fd)),
    plquants = c(0.05, 0.95), cols = c('black', 'blue'),
    ...)

pd2bart(
    x.train, y.train,
    xind = NULL,
    levs = NULL, levquants = c(0.05, seq(0.1, 0.9, 0.1), 0.95),
    pl = TRUE, plquants = c(0.05, 0.95),
    ...)

## S3 method for class 'pd2bart'
plot(
    x,
    plquants = c(0.05, 0.95), contour.color = 'white',
    justmedian = TRUE,
    ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdbart_+3A_x.train">x.train</code></td>
<td>

<p>Explanatory variables for training (in sample) data. Can be any valid input to <code><a href="#topic+bart">bart</a></code>, such as a matrix or a formula. Also accepted are fitted <code>bart</code> models or <code><a href="#topic+dbartsSampler-class">dbartsSampler</a></code> with <code>keepTrees</code> equal to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_y.train">y.train</code></td>
<td>

<p>Dependent variable for training (in sample) data. Can be a numeric vector or, when passing <code>x.train</code> as a formula, a <code>data.frame</code> or other object used to find variables. Not required if <code>x.train</code> is a fitted model or sampler.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_xind">xind</code></td>
<td>

<p>Integer, character vector, or the right-hand side of a formula indicating which variables are to be plotted. In <code>pdbart</code>, corresponds to the variables (columns of <code>x.train</code>) for which a plot is to be constructed. In <code>plot.pdbart</code>, corresponds to the indices in list returned by <code>pdbart</code> for which plot is to be constructed. In <code>pd2bart</code>, the indicies of a pair of variables (columns of <code>x.train</code>) to plot. If <code>NULL</code> a default of all columns is used for <code>pdbart</code> and the first two columns is used for <code>pd2bart</code>.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_levs">levs</code></td>
<td>

<p>Gives the values of a variable at which the plot is to be constructed. Must be a list, where the <code class="reqn">i</code>th component gives the values for the <code class="reqn">i</code>th variable. In <code>pdbart</code>, it should have same length as <code>xind</code>. In <code>pd2bart</code>, it should have length 2. See also argument <code>levquants</code>.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_levquants">levquants</code></td>
<td>

<p>If <code>levs</code> in <code>NULL</code>, the values of each variable used in the plot is  set to the quantiles (in <code>x.train</code>) indicated by levquants. Must be a vector of numeric type.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_pl">pl</code></td>
<td>

<p>For <code>pdbart</code> and <code>pd2bart</code>, if <code>TRUE</code>, plot is subsequently made (by calling <code>plot.*</code>).
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_plquants">plquants</code></td>
<td>

<p>In the plots, beliefs about <code class="reqn">f(x)</code> are indicated by plotting the posterior median and a lower and upper quantile. <code>plquants</code> is a double vector of length two giving the lower and upper quantiles.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_...">...</code></td>
<td>

<p>Additional arguments. In <code>pdbart</code> and <code>pd2bart</code>, arguments are passed on to <code><a href="#topic+bart">bart</a></code>. In <code>plot.pdbart</code>, they are passed on to <code><a href="base.html#topic+plot">plot</a></code>. In <code>plot.pd2bart</code>, they are passed on to <code><a href="graphics.html#topic+image">image</a></code>.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_x">x</code></td>
<td>

<p>For <code>plot.*</code>, object returned from <code>pdbart</code> or <code>pd2bart</code>.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_cols">cols</code></td>
<td>

<p>Vector of two colors. The first color is for the median of <code class="reqn">f</code>, while the second color is for the upper and lower quantiles.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_contour.color">contour.color</code></td>
<td>

<p>Color for contours plotted on top of the image.
</p>
</td></tr>
<tr><td><code id="pdbart_+3A_justmedian">justmedian</code></td>
<td>

<p>A logical where if <code>TRUE</code> just one plot is created for the median of <code class="reqn">f(x)</code> draws. If <code>FALSE</code>, three plots are created one for the median and two additional ones for the lower and upper quantiles. In this case, <code><a href="graphics.html#topic+par">mfrow</a></code> is set to <code>c(1,3)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We divide the predictor vector <code class="reqn">x</code> into a subgroup of interest, <code class="reqn">x_s</code> and the complement <code class="reqn">x_c = x \setminus x_s</code>. A prediction <code class="reqn">f(x)</code> can then be written as <code class="reqn">f(x_s, x_c)</code>. To estimate the effect of <code class="reqn">x_s</code> on the prediction, Friedman suggests the partial dependence function </p>
<p style="text-align: center;"><code class="reqn">f_s(x_s) = \frac{1}{n}\sum_{i=1}^n f(x_s,x_{ic})</code>
</p>
<p> where <code class="reqn">x_{ic}</code> is the <code class="reqn">i</code>th observation of <code class="reqn">x_c</code> in the data. Note that <code class="reqn">(x_s, x_{ic})</code> will generally not be one of the observed data points. Using BART it is straightforward to then estimate and even obtain uncertainty bounds for <code class="reqn">f_s(x_s)</code>. A draw of <code class="reqn">f^*_s(x_s)</code> from the induced BART posterior on <code class="reqn">f_s(x_s)</code> is obtained by simply computing <code class="reqn">f^*_s(x_s)</code> as a byproduct of each MCMC draw <code class="reqn">f^*</code>. The median (or average) of these MCMC draws <code class="reqn">f^*_s(x_s)</code> then yields an estimate of <code class="reqn">f_s(x_s)</code>, and lower and upper quantiles can be used to obtain intervals for <code class="reqn">f_s(x_s)</code>.
</p>
<p>In <code>pdbart</code> <code class="reqn">x_s</code> consists of a single variable in <code class="reqn">x</code> and in <code>pd2bart</code> it is a pair of variables.
</p>
<p>This is a computationally intensive procedure. For example, in <code>pdbart</code>, to compute the partial dependence plot for 5 <code class="reqn">x_s</code> values, we need to compute <code class="reqn">f(x_s, x_c)</code> for all possible <code class="reqn">(x_s, x_{ic})</code> and there would be <code class="reqn">5n</code> of these where <code class="reqn">n</code> is the sample size. All of that computation would be done for each kept BART draw. For this reason running BART with <code>keepevery</code> larger than 1 (eg. 10) makes the procedure much faster.
</p>


<h3>Value</h3>

<p>The plot methods produce the plots and don't return anything.
</p>
<p><code>pdbart</code> and <code>pd2bart</code> return lists with components given below. The list returned by <code>pdbart</code> is assigned class <code>pdbart</code> and the list returned by <code>pd2bart</code> is assigned class <code>pd2bart</code>.
</p>
<table>
<tr><td><code>fd</code></td>
<td>

<p>A matrix whose <code class="reqn">(i, j)</code> value is the <code class="reqn">i</code>th draw of <code class="reqn">f_s(x_s)</code> for the <code class="reqn">j</code>th value of <code class="reqn">x_s</code>. &ldquo;fd&rdquo; is for &ldquo;function draws&rdquo;.
</p>
<p>For <code>pdbart</code> <code>fd</code> is actually a list whose <code class="reqn">k</code>th component is the matrix described above corresponding to the <code class="reqn">k</code>th variable chosen by argument <code>xind</code>. The number of columns in each matrix will equal the number of values  given in the corresponding component of argument <code>levs</code> (or number of values in <code>levquants</code>).
</p>
<p>For <code>pd2bart</code>, <code>fd</code> is a single matrix. The columns correspond to all possible pairs of values for the pair of variables indicated by <code>xind</code>. That is, all possible <code class="reqn">(x_i, x_j)</code> where <code class="reqn">x_i</code> is a value in the levs component corresponding to the first <code class="reqn">x</code> and <code class="reqn">x_j</code> is a value in the levs components corresponding to the second one. The first <code class="reqn">x</code> changes first.
</p>
</td></tr>
<tr><td><code>levs</code></td>
<td>

<p>The list of levels used, each component corresponding to a variable. If argument <code>levs</code> was supplied it is unchanged. Otherwise, the levels in <code>levs</code> are as constructed using argument <code>levquants</code>.
</p>
</td></tr>
<tr><td><code>xlbs</code></td>
<td>

<p>A vector of character strings which are the plotting labels used for the variables.
</p>
</td></tr>
</table>
<p>The remaining components returned in the list are the same as in the value of <code><a href="#topic+bart">bart</a></code>. They are simply passed on from the BART run used to create the partial dependence plot. The function <code><a href="#topic+plot.bart">plot.bart</a></code> can be applied to the object returned by <code>pdbart</code> or <code>pd2bart</code> to examine the BART run.
</p>


<h3>Author(s)</h3>

<p>Hugh Chipman: <a href="mailto:hugh.chipman@acadiau.ca">hugh.chipman@acadiau.ca</a>.<br />
Robert McCulloch: <a href="mailto:robert.mcculloch@chicagogsb.edu">robert.mcculloch@chicagogsb.edu</a>.
</p>


<h3>References</h3>

<p>Chipman, H., George, E., and McCulloch, R. (2006)
BART: Bayesian Additive Regression Trees.
</p>
<p>Chipman, H., George, E., and McCulloch R. (2006)
Bayesian Ensemble Learning.
</p>
<p>both of the above at:
<a href="https://www.rob-mcculloch.org/">https://www.rob-mcculloch.org/</a>
</p>
<p>Friedman, J.H. (2001)
Greedy function approximation: A gradient boosting machine.
<em>The Annals of Statistics</em>, <b>29</b>, 1189&ndash;1232.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## simulate data 
f &lt;- function(x) 
    return(0.5 * x[,1] + 2 * x[,2] * x[,3])

sigma &lt;- 0.2
n     &lt;- 100

set.seed(27)
x &lt;- matrix(2 * runif(n * 3) - 1, ncol = 3)
colnames(x) &lt;- c('rob', 'hugh', 'ed')

Ey &lt;- f(x)
y  &lt;- rnorm(n, Ey, sigma)

## first two plot regions are for pdbart, third for pd2bart
par(mfrow = c(1, 3))

## pdbart: one dimensional partial dependence plot
set.seed(99)
pdb1 &lt;- pdbart(
    x, y, xind = c(1, 2),
    levs = list(seq(-1, 1, 0.2), seq(-1, 1, 0.2)),
    pl = FALSE, keepevery = 10, ntree = 100
)
plot(pdb1, ylim = c(-0.6, 0.6))

## pd2bart: two dimensional partial dependence plot
set.seed(99)
pdb2 &lt;- pd2bart(
    x, y, xind = c(2, 3),
    levquants = c(0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95),
    pl = FALSE, ntree = 100, keepevery = 10, verbose = FALSE)
plot(pdb2)

## compare BART fit to linear model and truth = Ey
lmFit  &lt;- lm(y ~ ., data.frame(x, y))
fitmat &lt;- cbind(y, Ey, lmFit$fitted, pdb1$yhat.train.mean)
colnames(fitmat) &lt;- c('y', 'Ey', 'lm', 'bart')
print(cor(fitmat))

## example showing the use of a pre-fitted model
df &lt;- data.frame(y, x)
set.seed(99)
bartFit &lt;- bart(
    y ~ rob + hugh + ed, df,
    keepevery = 10, ntree = 100, keeptrees = TRUE)
pdb1 &lt;- pdbart(bartFit, xind = rob + ed, pl = FALSE)

## End(Not run)</code></pre>

<hr>
<h2 id='rbart'>Bayesian Additive Regression Trees with Random Effects</h2><span id='topic+rbart_vi'></span><span id='topic+plot.rbart'></span><span id='topic+fitted.rbart'></span><span id='topic+extract.rbart'></span><span id='topic+predict.rbart'></span><span id='topic+residuals.rbart'></span>

<h3>Description</h3>

<p>Fits a varying intercept/random effect BART model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbart_vi(
    formula, data, test, subset, weights, offset, offset.test = offset,
    group.by, group.by.test, prior = cauchy,
    sigest = NA_real_, sigdf = 3.0, sigquant = 0.90,
    k = 2.0,
    power = 2.0, base = 0.95,
    n.trees = 75L,
    n.samples = 1500L, n.burn = 1500L,
    n.chains = 4L, n.threads = min(dbarts::guessNumCores(), n.chains),
    combineChains = FALSE,
    n.cuts = 100L, useQuantiles = FALSE,
    n.thin = 5L, keepTrainingFits = TRUE,
    printEvery = 100L, printCutoffs = 0L,
    verbose = TRUE,
    keepTrees = TRUE, keepCall = TRUE,
    seed = NA_integer_,
    keepSampler = keepTrees,
    keepTestFits = TRUE,
    callback = NULL,
    ...)

## S3 method for class 'rbart'
plot(
    x, plquants = c(0.05, 0.95), cols = c('blue', 'black'), ...)

## S3 method for class 'rbart'
fitted(
    object,
    type = c("ev", "ppd", "bart", "ranef"),
    sample = c("train", "test"),
    ...)

## S3 method for class 'rbart'
extract(
    object,
    type = c("ev", "ppd", "bart", "ranef", "trees"),
    sample = c("train", "test"),
    combineChains = TRUE,
    ...)

## S3 method for class 'rbart'
predict(
    object, newdata, group.by, offset,
    type = c("ev", "ppd", "bart", "ranef"),
    combineChains = TRUE,
    ...)

## S3 method for class 'rbart'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbart_+3A_group.by">group.by</code></td>
<td>

<p>Grouping factor. Can be an integer vector/factor, or a reference to such in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_group.by.test">group.by.test</code></td>
<td>

<p>Grouping factor for test data, of the same type as <code>group.by</code>. Can be missing.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_prior">prior</code></td>
<td>

<p>A function or symbolic reference to built-in priors. Determines the prior over the standard deviation of the random effects. Supplied functions take two arguments, <code>x</code> - the standard deviation, and <code>rel.scale</code> - the standard deviation of the response variable before random effects are fit. Built in priors are <code>cauchy</code> with a scale of 2.5 times the relative scale and <code>gamma</code> with a shape of 2.5 and scale of 2.5 times the relative scale.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_n.thin">n.thin</code></td>
<td>

<p>The number of tree jumps taken for every stored sample, but also the number of samples from the posterior of the standard deviation of the random effects before one is kept.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_keeptestfits">keepTestFits</code></td>
<td>

<p>Logical where, if false, test fits are obtained while running but not returned. Useful with <code>callback</code>.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_callback">callback</code></td>
<td>

<p>Optional function of <code>trainFits</code>, <code>testFits</code>, <code>ranef</code>, <code>sigma</code>, and <code>tau</code>. Called after every post-burn-in iteration and the results of which are collected and stored in the final object.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_formula">formula</code>, <code id="rbart_+3A_data">data</code>, <code id="rbart_+3A_test">test</code>, <code id="rbart_+3A_subset">subset</code>, <code id="rbart_+3A_weights">weights</code>, <code id="rbart_+3A_offset">offset</code>, <code id="rbart_+3A_offset.test">offset.test</code>, <code id="rbart_+3A_sigest">sigest</code>, <code id="rbart_+3A_sigdf">sigdf</code>, <code id="rbart_+3A_sigquant">sigquant</code>, <code id="rbart_+3A_k">k</code>, <code id="rbart_+3A_power">power</code>, <code id="rbart_+3A_base">base</code>, <code id="rbart_+3A_n.trees">n.trees</code>, <code id="rbart_+3A_n.samples">n.samples</code>, <code id="rbart_+3A_n.burn">n.burn</code>, <code id="rbart_+3A_n.chains">n.chains</code>, <code id="rbart_+3A_n.threads">n.threads</code>, <code id="rbart_+3A_combinechains">combineChains</code>, <code id="rbart_+3A_n.cuts">n.cuts</code>, <code id="rbart_+3A_usequantiles">useQuantiles</code>, <code id="rbart_+3A_keeptrainingfits">keepTrainingFits</code>, <code id="rbart_+3A_printevery">printEvery</code>, <code id="rbart_+3A_printcutoffs">printCutoffs</code>, <code id="rbart_+3A_verbose">verbose</code>, <code id="rbart_+3A_keeptrees">keepTrees</code>, <code id="rbart_+3A_keepcall">keepCall</code>, <code id="rbart_+3A_seed">seed</code>, <code id="rbart_+3A_keepsampler">keepSampler</code>, <code id="rbart_+3A_...">...</code></td>
<td>

<p>Same as in <code><a href="#topic+bart2">bart2</a></code>.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_object">object</code></td>
<td>

<p>A fitted <code>rbart</code> model.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_newdata">newdata</code></td>
<td>

<p>Same as <code>test</code>, but named to match <code><a href="stats.html#topic+predict">predict</a></code> generic.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_type">type</code></td>
<td>

<p>One of <code>"ev"</code>, <code>"ppd"</code>, <code>"bart"</code>, <code>"ranef"</code>, or <code>"trees"</code> for the posterior of the expected value, posterior predictive distribution, non-parametric/BART component, random effect, or saved trees respectively. The expected value is the sum of the BART component and the random effects, while the posterior predictive distribution is a response sampled with that mean. To synergize with <code><a href="stats.html#topic+predict.glm">predict.glm</a></code>, <code>"response"</code> can be used as a synonym for <code>"value"</code> and <code>"link"</code> can be used as a synonym for <code>"bart"</code>. For additional details on tree extraction, see the corresponding subsection in <code><a href="#topic+bart">bart</a></code>.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_sample">sample</code></td>
<td>

<p>One of <code>"train"</code> or <code>"test"</code>, referring to the training or tests samples respectively.
</p>
</td></tr>
<tr><td><code id="rbart_+3A_x">x</code>, <code id="rbart_+3A_plquants">plquants</code>, <code id="rbart_+3A_cols">cols</code></td>
<td>

<p>Same as in <code><a href="#topic+plot.bart">plot.bart</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fits a BART model with additive random intercepts, one for each factor level of <code>group.by</code>. For continuous responses:
</p>

<ul>
<li> <p><code class="reqn">y_i \sim N(f(x_i) + \alpha_{g[i]}, \sigma^2)</code>
</p>
</li>
<li> <p><code class="reqn">\alpha_j \sim N(0, \tau^2)</code>.
</p>
</li></ul>

<p>For binary outcomes the response model is changed to <code class="reqn">P(Y_i = 1) = \Phi(f(x_i) + \alpha_{g[i]})</code>. <code class="reqn">i</code> indexes observations, <code class="reqn">g[i]</code> is the group index of observation <code class="reqn">i</code>, <code class="reqn">f(x)</code> and <code class="reqn">\sigma_y</code> come from a BART model, and <code class="reqn">\alpha_j</code> are the independent and identically distributed random intercepts. Draws from the posterior of <code class="reqn">tau</code> are made using a slice sampler, with a width dynamically determined by assessing the curvature of the posterior distribution at its mode.
</p>


<h4>Out Of Sample Groups</h4>

<p>Predicting random effects for groups not in the training sample is supported by sampling from their posterior predictive distribution, that is a draw is taken from <code class="reqn">p(\alpha \mid y) = \int p(\alpha \mid \tau)p(\tau \mid y)d\alpha</code>. For out-of-sample groups in the test data, these random effect draws can be kept with the saved object. For those supplied to <code>predict</code>, they cannot and may change for subsequent calls.
</p>



<h4>Generics</h4>

<p>See the generics section of <code><a href="#topic+bart">bart</a></code>.
</p>



<h3>Value</h3>

<p>An object of class <code>rbart</code>. Contains all of the same elements of an object of class <code><a href="#topic+bart">bart</a></code>, as well as the elements:
</p>
<table>
<tr><td><code>ranef</code></td>
<td>

<p>Samples from the posterior of the random effects. A array/matrix of posterior samples. The <code class="reqn">(k, l, j)</code> value is the <code class="reqn">l</code>th draw of the posterior of the random effect for group <code class="reqn">j</code> (i.e. <code class="reqn">\alpha^*_j</code>) corresponding to chain <code class="reqn">k</code>. When <code>n.chains</code> is one or <code>combineChains</code> is <code>TRUE</code>, the result is a collapsed down to a matrix.
</p>
</td></tr>
<tr><td><code>ranef.mean</code></td>
<td>

<p>Posterior mean of random effects, derived by taking mean across group index of samples.
</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>

<p>Matrix of posterior samples of <code>tau</code>, the standard deviation of the random effects. Dimensions are equal to the number of chains times the numbers of samples unless <code>n.chains</code> is one or <code>combineChains</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code>first.tau</code></td>
<td>

<p>Burn-in draws of <code>tau</code>.
</p>
</td></tr>
<tr><td><code>callback</code></td>
<td>

<p>Optional results of <code>callback</code> function.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vincent Dorie: <a href="mailto:vdorie@gmail.com">vdorie@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bart">bart</a></code>, <code><a href="#topic+dbarts">dbarts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) {
    10 * sin(pi * x[,1] * x[,2]) + 20 * (x[,3] - 0.5)^2 +
        10 * x[,4] + 5 * x[,5]
}

set.seed(99)
sigma &lt;- 1.0
n     &lt;- 100

x  &lt;- matrix(runif(n * 10), n, 10)
Ey &lt;- f(x)
y  &lt;- rnorm(n, Ey, sigma)

n.g &lt;- 10
g &lt;- sample(n.g, length(y), replace = TRUE)
sigma.b &lt;- 1.5
b &lt;- rnorm(n.g, 0, sigma.b)

y &lt;- y + b[g]

df &lt;- as.data.frame(x)
colnames(df) &lt;- paste0("x_", seq_len(ncol(x)))
df$y &lt;- y
df$g &lt;- g

## low numbers to reduce run time
rbartFit &lt;- rbart_vi(y ~ . - g, df, group.by = g,
                     n.samples = 40L, n.burn = 10L, n.thin = 2L,
                     n.chains = 1L,
                     n.trees = 25L, n.threads = 1L)
</code></pre>

<hr>
<h2 id='xbart'>Crossvalidation For Bayesian Additive Regression Trees</h2><span id='topic+xbart'></span>

<h3>Description</h3>

<p>Fits the BART model against varying <code>k</code>, <code>power</code>, <code>base</code>, and <code>ntree</code> parameters using <code class="reqn">K</code>-fold or repeated random subsampling crossvalidation, sharing burn-in between parameter settings. Results are given an array of evalulations of a loss functions on the held-out sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xbart(
    formula, data, subset, weights, offset, verbose = FALSE, n.samples = 200L,
    method = c("k-fold", "random subsample"), n.test = c(5, 0.2),
    n.reps = 40L, n.burn = c(200L, 150L, 50L),
    loss = c("rmse", "log", "mcr"), n.threads = dbarts::guessNumCores(), n.trees = 75L,
    k = NULL, power = 2, base = 0.95, drop = TRUE,
    resid.prior = chisq, control = dbarts::dbartsControl(), sigma = NA_real_,
    seed = NA_integer_)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xbart_+3A_formula">formula</code></td>
<td>

<p>An object of class <code><a href="stats.html#topic+formula">formula</a></code> following an analogous model description syntax as <code><a href="stats.html#topic+lm">lm</a></code>. For backwards compatibility, can also be the <code><a href="#topic+bart">bart</a></code> matrix <code>x.train</code>. See <code><a href="#topic+dbarts">dbarts</a></code>.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_data">data</code></td>
<td>

<p>An optional data frame, list, or environment containing predictors to be used with the model. For backwards compatibility, can also be the <code><a href="#topic+bart">bart</a></code> vector <code>y.train</code>.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_subset">subset</code></td>
<td>

<p>An optional vector specifying a subset of observations to be used in the fitting process.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_weights">weights</code></td>
<td>

<p>An optional vector of weights to be used in the fitting process. When present, BART fits a model with observations <code class="reqn">y \mid x \sim N(f(x), \sigma^2 / w)</code>, where <code class="reqn">f(x)</code> is the unknown function.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_offset">offset</code></td>
<td>

<p>An optional vector specifying an offset from 0 for the relationship between the underyling function, <code class="reqn">f(x)</code>, and the response <code class="reqn">y</code>. Only is useful for binary responses, in which case the model fit is to assume <code class="reqn">P(Y = 1 \mid X = x) = \Phi(f(x) + \mathrm{offset})</code>, where <code class="reqn">\Phi</code> is the standard normal cumulative distribution function.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_verbose">verbose</code></td>
<td>

<p>A logical determining if additional output is printed to the console.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_n.samples">n.samples</code></td>
<td>

<p>A positive integer, setting the number of posterior samples drawn for each fit of training data and used by the loss function.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_method">method</code></td>
<td>

<p>Character string, either <code>"k-fold"</code> or <code>"random subsample"</code>.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_n.test">n.test</code></td>
<td>

<p>For each fit, the test sample size or proportion. For method <code>"k-fold"</code>, is expected to be the number of folds, and in <code class="reqn">[2, n]</code>. For method <code>"random subsample"</code>, can be a real number in <code class="reqn">(0, 1)</code> or a positive integer in <code class="reqn">(1, n)</code>. When a given as proportion, the number of test observations used is the proportion times the sample size rounded to the nearest integer.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_n.reps">n.reps</code></td>
<td>

<p>A positive integer setting the number of cross validation steps that will be taken. For <code>"k-fold"</code>, each replication corresponds to fitting each of the <code class="reqn">K</code> folds in turn, while for <code>"random subsample"</code> a replication is a single fit.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_n.burn">n.burn</code></td>
<td>

<p>Between one and three positive integers, specifying the 1) initial burn-in, 2) burn-in when moving from one parameter setting to another, and 3) the burn-in between each random subsample replication. The third parameter is also the burn in when moving between folds in <code>"k-fold"</code> crossvalidation.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_loss">loss</code></td>
<td>

<p>Either a one of the pre-set loss functions as character-strings (<code>mcr</code> - missclassification rate for binary responses, <code>rmse</code> - root-mean-squared-error for continuous response), <code>log</code> - negative log-loss for binary response (<code>rmse</code> serves this purpose for continuous responses), a function, or a function-evaluation environment list-pair. Functions should have prototypes of the form <code>function(y.test, y.test.hat, weights)</code>, where <code>y.test</code> is the held out test subsample, <code>y.test.hat</code> is a matrix of dimension <code>length(y.test) * n.samples</code>, and <code>weights</code> are an optional vector of user-supplied weights. See examples.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_n.threads">n.threads</code></td>
<td>

<p>Across different sets of parameters (<code>k</code> <code class="reqn">\times</code> <code>power</code> <code class="reqn">\times</code> <code>base</code> <code class="reqn">\times</code> <code>n.trees</code>) and <code>n.reps</code>, results are independent. For <code>n.threads &gt; 1</code>, evaluations of the above are divided into approximately equal size evaluations chunks and executed in parallel. The default uses <code>link{guessNumCores}</code>, which should work across the most common operating system/hardware pairs. A value of <code>NA</code> is interpretted as 1.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_n.trees">n.trees</code></td>
<td>

<p>A vector of positive integers setting the BART hyperparameter for the number of trees in the sum-of-trees formulation. See <code><a href="#topic+bart">bart</a></code>.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_k">k</code></td>
<td>

<p>A vector of positive real numbers, setting the BART hyperparameter for the node-mean prior standard deviation. If <code>NULL</code>, the default of <code>bart2</code> will be used - 2 for continuous response and a Chi hyperprior for binary. Hyperprior crossvalidation not possible at this time.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_power">power</code></td>
<td>

<p>A vector of real numbers greater than one, setting the BART hyperparameter for the tree prior's growth probability, given by <code class="reqn">{base} / (1 + depth)^{power}</code>.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_base">base</code></td>
<td>

<p>A vector of real numbers in <code class="reqn">(0, 1)</code>, setting the BART hyperparameter for the tree prior's growth probability.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_drop">drop</code></td>
<td>

<p>Logical, determining if dimensions with a single value are dropped from the result.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_resid.prior">resid.prior</code></td>
<td>

<p>An expression of the form <code>chisq</code> or <code>chisq(df, quant)</code> that sets the prior used on the residual/error variance.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_control">control</code></td>
<td>

<p>An object inheriting from <code>dbartsControl</code>, created by the <code><a href="#topic+dbartsControl">dbartsControl</a></code> function.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_sigma">sigma</code></td>
<td>

<p>A positive numeric estimate of the residual standard deviation. If <code>NA</code>, a linear model is used with all of the predictors to obtain one.
</p>
</td></tr>
<tr><td><code id="xbart_+3A_seed">seed</code></td>
<td>

<p>Optional integer specifying the desired pRNG <a href="base.html#topic+set.seed">seed</a>. It should not be needed when running single-threaded - <code><a href="base.html#topic+set.seed">set.seed</a></code>  will suffice, and can be used to obtain reproducible results when multi-threaded. See Reproducibility section of <code><a href="#topic+bart">bart</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Crossvalidates <code>n.reps</code> replications against the crossproduct of given hyperparameter vectors <code>n.trees</code> <code class="reqn">\times</code> <code>k</code> <code class="reqn">\times</code> <code>power</code> <code class="reqn">\times</code> <code>base</code>. For each fit, either one fold is withheld as test data and <code>n.test - 1</code> folds are used as training data or <code>n * n.test</code> observations are withheld as test data and <code>n * (1 - n.test)</code> used as training. A replication corresponds to fitting all <code class="reqn">K</code> folds in <code>"k-fold"</code> crossvalidation or a single fit with <code>"random subsample"</code>. The training data is used to fit a model and make predictions on the test data which are used together with the test data itself to evaluate the <code>loss</code> function.
</p>
<p><code>loss</code> functions are either the default of average negative log-loss for binary outcomes and root-mean-squared error for continuous outcomes, missclassification rates for binary outcomes, or a <code>function</code> with arguments <code>y.test</code> and <code>y.test.hat</code>. <code>y.test.hat</code> is of dimensions equal to <code>length(y.test)</code> <code class="reqn">\times</code> <code>n.samples</code>. A third option is to pass a list of <code>list(function, evaluationEnvironment)</code>, so as to provide default bindings. RMSE is a monotonic transformation of the average log-loss for continuous outcomes, so specifying log-loss in that case calculates RMSE instead.
</p>


<h3>Value</h3>

<p>An array of dimensions <code>n.reps</code> <code class="reqn">\times</code> <code>length(n.trees)</code> <code class="reqn">\times</code> <code>length(k)</code> <code class="reqn">\times</code> <code>length(power)</code> <code class="reqn">\times</code> <code>length(base)</code>. If <code>drop</code> is <code>TRUE</code>, dimensions of length 1 are omitted. If all hyperparameters are of length 1, then the result will be a vector of length <code>n.reps</code>. When the result is an array, the <code>dimnames</code> of the result shall be set to the corresponding hyperparameters.
</p>
<p>For method <code>"k-fold"</code>, each element is an average across the <code class="reqn">K</code> fits. For <code>"random subsample"</code>, each element represents a single fit.
</p>


<h3>Author(s)</h3>

<p>Vincent Dorie: <a href="mailto:vdorie@gmail.com">vdorie@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bart">bart</a></code>, <code><a href="#topic+dbarts">dbarts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) {
    10 * sin(pi * x[,1] * x[,2]) + 20 * (x[,3] - 0.5)^2 +
        10 * x[,4] + 5 * x[,5]
}

set.seed(99)
sigma &lt;- 1.0
n     &lt;- 100

x  &lt;- matrix(runif(n * 10), n, 10)
Ey &lt;- f(x)
y  &lt;- rnorm(n, Ey, sigma)

mad &lt;- function(y.train, y.train.hat, weights) {
    # note, weights are ignored
    mean(abs(y.train - apply(y.train.hat, 1L, mean)))
}



## low iteration numbers to to run quickly
xval &lt;- xbart(x, y, n.samples = 15L, n.reps = 4L, n.burn = c(10L, 3L, 1L),
              n.trees = c(5L, 7L),
              k = c(1, 2, 4),
              power = c(1.5, 2),
              base = c(0.75, 0.8, 0.95), n.threads = 1L,
              loss = mad)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
