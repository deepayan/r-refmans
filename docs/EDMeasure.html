<!DOCTYPE html><html><head><title>Help for package EDMeasure</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EDMeasure}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EDMeasure-package'><p>Energy-Based Dependence Measures</p></a></li>
<li><a href='#cmdm_test'><p>Conditional Mean Independence Tests</p></a></li>
<li><a href='#mdc'><p>Martingale Difference Correlation</p></a></li>
<li><a href='#mdd'><p>Martingale Difference Divergence</p></a></li>
<li><a href='#mddm'><p>Martingale Difference Divergence Matrix</p></a></li>
<li><a href='#mdm'><p>Mutual Dependence Measures</p></a></li>
<li><a href='#mdm_ica'><p>Independent Component Analysis via Mutual Dependence Measures</p></a></li>
<li><a href='#mdm_test'><p>Mutual Independence Tests</p></a></li>
<li><a href='#pmdc'><p>Partial Martingale Difference Correlation</p></a></li>
<li><a href='#pmdd'><p>Partial Martingale Difference Divergence</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Energy-Based Dependence Measures</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-01-30</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementations of (1) mutual dependence measures and mutual independence tests in 
    Jin, Z., and Matteson, D. S. (2017) &lt;<a href="https://doi.org/10.48550/arXiv.1709.02532">doi:10.48550/arXiv.1709.02532</a>&gt;;
    (2) independent component analysis methods based on mutual dependence measures in 
    Jin, Z., and Matteson, D. S. (2017) &lt;<a href="https://doi.org/10.48550/arXiv.1709.02532">doi:10.48550/arXiv.1709.02532</a>&gt; 
    and Pfister, N., et al. (2018) &lt;<a href="https://doi.org/10.1111%2Frssb.12235">doi:10.1111/rssb.12235</a>&gt;;
    (3) conditional mean dependence measures and conditional mean independence tests in 
    Shao, X., and Zhang, J. (2014) &lt;<a href="https://doi.org/10.1080%2F01621459.2014.887012">doi:10.1080/01621459.2014.887012</a>&gt;,
    Park, T., et al. (2015) &lt;<a href="https://doi.org/10.1214%2F15-EJS1047">doi:10.1214/15-EJS1047</a>&gt;,
    and Lee, C. E., and Shao, X. (2017) &lt;<a href="https://doi.org/10.1080%2F01621459.2016.1240083">doi:10.1080/01621459.2016.1240083</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>energy (&ge; 1.7-0), dHSIC (&ge; 2.0), rBayesianOptimization (&ge;
1.1.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 2.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Collate:</td>
<td>'EDMeasure-package.R' 'cmdm_functions.R' 'pmdd.R' 'mdd.R'
'cmdm_test.R' 'mdc.R' 'mddm.R' 'mdm.R' 'mdm_ica_functions.R'
'mdm_ica.R' 'mdm_test.R' 'pmdc.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-02-25 22:43:36 UTC; btluck</td>
</tr>
<tr>
<td>Author:</td>
<td>Ze Jin [aut, cre],
  Shun Yao [aut],
  David S. Matteson [aut],
  Xiaofeng Shao [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ze Jin &lt;zj58@cornell.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-02-25 22:49:47 UTC</td>
</tr>
</table>
<hr>
<h2 id='EDMeasure-package'>Energy-Based Dependence Measures</h2><span id='topic+EDMeasure-package'></span><span id='topic+EDMeasure'></span>

<h3>Description</h3>

<p>EDMeasure: A package for energy-based dependence measures
</p>


<h3>Details</h3>

<p>The EDMeasure package provides measures of mutual dependence and tests of mutual independence, 
independent component analysis methods based on mutual dependence measures,
and measures of conditional mean dependence and tests of conditional mean independence.
</p>
<p>The three main parts are:
</p>

<ul>
<li><p> mutual dependence measures via energy statistics
</p>
   
<ul>
<li><p> measuring mutual dependence
</p>
</li>
<li><p> testing mutual independence
</p>
</li></ul>

</li>
<li><p> independent component analysis via mutual dependence measures
</p>
  
<ul>
<li><p> applying mutual dependence measures
</p>
</li>
<li><p> initializing local optimization methods
</p>
</li></ul>

</li>
<li><p> conditional mean dependence measures via energy statistics
</p>
 
<ul>
<li><p> measuring conditional mean dependence
</p>
</li>
<li><p> testing conditional mean independence
</p>
</li></ul>

</li></ul>



<h3>Mutual Dependence Measures via Energy Statistics</h3>

<p><strong>Measuring mutual dependence</strong>
</p>
<p>The mutual dependence measures include: 
</p>

<ul>
<li><p> asymmetric measure <code class="reqn">\mathcal{R}_n</code> based on distance covariance <code class="reqn">\mathcal{V}_n</code>
</p>
</li>
<li><p> symmetric measure <code class="reqn">\mathcal{S}_n</code> based on distance covariance <code class="reqn">\mathcal{V}_n</code>
</p>
</li>
<li><p> complete measure <code class="reqn">\mathcal{Q}_n</code> based on complete V-statistics
</p>
</li>
<li><p> simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code> based on incomplete V-statistics
</p>
</li>
<li><p> asymmetric measure <code class="reqn">\mathcal{J}_n</code> based on complete measure <code class="reqn">\mathcal{Q}_n</code>
</p>
</li>
<li><p> simplified asymmetric measure <code class="reqn">\mathcal{J}_n^\star</code> based on simplified complete measure 
<code class="reqn">\mathcal{Q}_n^\star</code>
</p>
</li>
<li><p> symmetric measure <code class="reqn">\mathcal{I}_n</code> based on complete measure <code class="reqn">\mathcal{Q}_n</code>
</p>
</li>
<li><p> simplified symmetric measure <code class="reqn">\mathcal{I}_n^\star</code> based on simplified complete measure 
<code class="reqn">\mathcal{Q}_n^\star</code>
</p>
</li></ul>

<p><strong>Testing mutual independence</strong>
</p>
<p>The mutual independence tests based on the mutual dependence measures are implemented as permutation 
tests.
</p>


<h3>Independent Component Analysis via Mutual Dependence Measures</h3>

<p><strong>Applying mutual dependence measures</strong>
</p>
<p>The mutual dependence measures include:
</p>
 
<ul>
<li><p> distance-based energy statistics
</p>

<ul>
<li><p> asymmetric measure <code class="reqn">\mathcal{R}_n</code> based on distance covariance <code class="reqn">\mathcal{V}_n</code>
</p>
</li>
<li><p> symmetric measure <code class="reqn">\mathcal{S}_n</code> based on distance covariance <code class="reqn">\mathcal{V}_n</code>
</p>
</li>
<li><p> simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code> based on incomplete V-statistics
</p>
</li></ul>

</li></ul>

  
<ul>
<li><p> kernel-based maximum mean discrepancies
</p>

<ul>
<li><p> d-variable Hilbert&ndash;Schmidt independence criterion dHSIC<code class="reqn">_n</code> based on
Hilbert&ndash;Schmidt independence criterion HSIC<code class="reqn">_n</code> 
</p>
</li></ul>

</li></ul>

<p><strong>Initializing local optimization methods</strong>
</p>
<p>The initialization methods include:
</p>

<ul>
<li><p> Latin hypercube sampling 
</p>
</li>
<li><p> Bayesian optimization 
</p>
</li></ul>



<h3>Conditional Mean Dependence Measures via Energy Statistics</h3>

<p><strong>Measuring conditional mean dependence</strong>
</p>
<p>The conditional mean dependence measures include: 
</p>
 
<ul>
<li><p> conditional mean dependence of <code>Y</code> given <code>X</code>
</p>

<ul>
<li><p> martingale difference divergence
</p>
</li>
<li><p> martingale difference correlation
</p>
</li>
<li><p> martingale difference divergence matrix
</p>
</li></ul>

</li></ul>

  
<ul>
<li><p> conditional mean dependence of <code>Y</code> given <code>X</code> adjusting for the dependence on <code>Z</code>
</p>

<ul>
<li><p> partial martingale difference divergence
</p>
</li>
<li><p> partial martingale difference correlation
</p>
</li></ul>

</li></ul>

<p><strong>Testing conditional mean independence</strong>
</p>
<p>The conditional mean independence tests include: 
</p>
  
<ul>
<li><p> conditional mean independence of <code>Y</code> given <code>X</code> conditioning on <code>Z</code>
</p>

<ul>
<li><p> martingale difference divergence under a linear assumption
</p>
</li>
<li><p> partial martingale difference divergence
</p>
</li></ul>

</li></ul>

<p>The conditional mean independence tests based on the conditional mean dependence measures are 
implemented as permutation tests.
</p>


<h3>Author(s)</h3>

<p>Ze Jin <a href="mailto:zj58@cornell.edu">zj58@cornell.edu</a>,
Shun Yao <a href="mailto:shunyao2@illinois.edu">shunyao2@illinois.edu</a>, <br />
David S. Matteson <a href="mailto:matteson@cornell.edu">matteson@cornell.edu</a>,
Xiaofeng Shao <a href="mailto:xshao@illinois.edu">xshao@illinois.edu</a>
</p>

<hr>
<h2 id='cmdm_test'>Conditional Mean Independence Tests</h2><span id='topic+cmdm_test'></span>

<h3>Description</h3>

<p><code>cmdm_test</code> tests conditional mean independence of <code>Y</code> given <code>X</code> conditioning on <code>Z</code>,
where each contains one variable (univariate) or more variables (multivariate).
All tests are implemented as permutation tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmdm_test(X, Y, Z, num_perm = 500, type = "linmdd", compute = "C",
  center = "U")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cmdm_test_+3A_x">X</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="cmdm_test_+3A_y">Y</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="cmdm_test_+3A_z">Z</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="cmdm_test_+3A_num_perm">num_perm</code></td>
<td>
<p>The number of permutation samples drawn to approximate the asymptotic distributions
of mutual dependence measures.</p>
</td></tr>
<tr><td><code id="cmdm_test_+3A_type">type</code></td>
<td>
<p>The type of conditional mean dependence measures, including
</p>

<ul>
<li> <p><code>linmdd</code>: martingale difference divergence under a linear assumption; 
</p>
</li>
<li> <p><code>pmdd</code>: partial martingale difference divergence.
</p>
</li></ul>
</td></tr>
<tr><td><code id="cmdm_test_+3A_compute">compute</code></td>
<td>
<p>The computation method for martingale difference divergence, including
</p>

<ul>
<li> <p><code>C</code>: computation implemented in C code;
</p>
</li>
<li> <p><code>R</code>: computation implemented in R code.
</p>
</li></ul>
</td></tr>
<tr><td><code id="cmdm_test_+3A_center">center</code></td>
<td>
<p>The centering approach for martingale difference divergence, including
</p>

<ul>
<li> <p><code>U</code>: U-centering which leads to an unbiased estimator;
</p>
</li>
<li> <p><code>D</code>: double-centering which leads to a biased estimator.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p><code>cmdm_test</code> returns a list including the following components:
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p>The value of the conditional mean dependence measure.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>The p-value of the conditional mean independence test.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Shao, X., and Zhang, J. (2014).
Martingale difference correlation and its use in high-dimensional variable screening.
Journal of the American Statistical Association, 109(507), 1302-1318.
<a href="http://dx.doi.org/10.1080/01621459.2014.887012">http://dx.doi.org/10.1080/01621459.2014.887012</a>.
</p>
<p>Park, T., Shao, X., and Yao, S. (2015).
Partial martingale difference correlation.
Electronic Journal of Statistics, 9(1), 1492-1517.
<a href="http://dx.doi.org/10.1214/15-EJS1047">http://dx.doi.org/10.1214/15-EJS1047</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# X, Y, Z are vectors with 10 samples and 1 variable
X &lt;- rnorm(10)
Y &lt;- rnorm(10)
Z &lt;- rnorm(10)

cmdm_test(X, Y, Z, type = "linmdd")

# X, Y, Z are 10 x 2 matrices with 10 samples and 2 variables
X &lt;- matrix(rnorm(10 * 2), 10, 2)
Y &lt;- matrix(rnorm(10 * 2), 10, 2)
Z &lt;- matrix(rnorm(10 * 2), 10, 2)

cmdm_test(X, Y, Z, type = "pmdd")

## End(Not run)
</code></pre>

<hr>
<h2 id='mdc'>Martingale Difference Correlation</h2><span id='topic+mdc'></span>

<h3>Description</h3>

<p><code>mdc</code> measures conditional mean dependence of <code>Y</code> given <code>X</code>,
where each contains one variable (univariate) or more variables (multivariate).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdc(X, Y, center = "U")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdc_+3A_x">X</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="mdc_+3A_y">Y</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="mdc_+3A_center">center</code></td>
<td>
<p>The approach for centering, including
</p>

<ul>
<li> <p><code>U</code>: U-centering which leads to an unbiased estimator;
</p>
</li>
<li> <p><code>D</code>: double-centering which leads to a biased estimator. 
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p><code>mdc</code> returns the squared martingale difference correlation of <code>Y</code> given <code>X</code>.
</p>


<h3>References</h3>

<p>Shao, X., and Zhang, J. (2014).
Martingale difference correlation and its use in high-dimensional variable screening.
Journal of the American Statistical Association, 109(507), 1302-1318.
<a href="http://dx.doi.org/10.1080/01621459.2014.887012">http://dx.doi.org/10.1080/01621459.2014.887012</a>.
</p>
<p>Park, T., Shao, X., and Yao, S. (2015).
Partial martingale difference correlation.
Electronic Journal of Statistics, 9(1), 1492-1517.
<a href="http://dx.doi.org/10.1214/15-EJS1047">http://dx.doi.org/10.1214/15-EJS1047</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># X, Y are 10 x 2 matrices with 10 samples and 2 variables
X &lt;- matrix(rnorm(10 * 2), 10, 2)
Y &lt;- matrix(rnorm(10 * 2), 10, 2)

mdc(X, Y, center = "U")
mdc(X, Y, center = "D")
</code></pre>

<hr>
<h2 id='mdd'>Martingale Difference Divergence</h2><span id='topic+mdd'></span>

<h3>Description</h3>

<p><code>mdd</code> measures conditional mean dependence of <code>Y</code> given <code>X</code>,
where each contains one variable (univariate) or more variables (multivariate).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdd(X, Y, compute = "C", center = "U")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdd_+3A_x">X</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="mdd_+3A_y">Y</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="mdd_+3A_compute">compute</code></td>
<td>
<p>The method for computation, including
</p>

<ul>
<li> <p><code>C</code>: computation implemented in C code;
</p>
</li>
<li> <p><code>R</code>: computation implemented in R code.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mdd_+3A_center">center</code></td>
<td>
<p>The approach for centering, including
</p>

<ul>
<li> <p><code>U</code>: U-centering which leads to an unbiased estimator;
</p>
</li>
<li> <p><code>D</code>: double-centering which leads to a biased estimator.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p><code>mdd</code> returns the squared martingale difference divergence of <code>Y</code> given <code>X</code>.
</p>


<h3>References</h3>

<p>Shao, X., and Zhang, J. (2014).
Martingale difference correlation and its use in high-dimensional variable screening.
Journal of the American Statistical Association, 109(507), 1302-1318.
<a href="http://dx.doi.org/10.1080/01621459.2014.887012">http://dx.doi.org/10.1080/01621459.2014.887012</a>.
</p>
<p>Park, T., Shao, X., and Yao, S. (2015).
Partial martingale difference correlation.
Electronic Journal of Statistics, 9(1), 1492-1517.
<a href="http://dx.doi.org/10.1214/15-EJS1047">http://dx.doi.org/10.1214/15-EJS1047</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># X, Y are vectors with 10 samples and 1 variable
X &lt;- rnorm(10)
Y &lt;- rnorm(10)

mdd(X, Y, compute = "C")
mdd(X, Y, compute = "R")

# X, Y are 10 x 2 matrices with 10 samples and 2 variables
X &lt;- matrix(rnorm(10 * 2), 10, 2)
Y &lt;- matrix(rnorm(10 * 2), 10, 2)

mdd(X, Y, center = "U")
mdd(X, Y, center = "D")
</code></pre>

<hr>
<h2 id='mddm'>Martingale Difference Divergence Matrix</h2><span id='topic+mddm'></span>

<h3>Description</h3>

<p><code>mddm</code> extends martingale difference divergence from a scalar to a matrix.
It encodes the linear combinations of all univariate components in <code>Y</code>
that are conditionally mean independent of <code>X</code>.
Only the double-centering approach is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mddm(X, Y, compute = "C")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mddm_+3A_x">X</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="mddm_+3A_y">Y</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="mddm_+3A_compute">compute</code></td>
<td>
<p>The method for computation, including
</p>

<ul>
<li> <p><code>C</code>: computation implemented in C code;
</p>
</li>
<li> <p><code>R</code>: computation implemented in R code.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p><code>mddm</code> returns the martingale difference divergence matrix of <code>Y</code> given <code>X</code>.
</p>


<h3>References</h3>

<p>Lee, C. E., and Shao, X. (2017).
Martingale Difference Divergence Matrix and Its Application to Dimension Reduction for
Stationary Multivariate Time Series.
Journal of the American Statistical Association, 1-14.
<a href="http://dx.doi.org/10.1080/01621459.2016.1240083">http://dx.doi.org/10.1080/01621459.2016.1240083</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># X, Y are vectors with 10 samples and 1 variable
X &lt;- rnorm(10)
Y &lt;- rnorm(10)

mddm(X, Y, compute = "C")
mddm(X, Y, compute = "R")

# X, Y are 10 x 2 matrices with 10 samples and 2 variables
X &lt;- matrix(rnorm(10 * 2), 10, 2)
Y &lt;- matrix(rnorm(10 * 2), 10, 2)

mddm(X, Y, compute = "C")
mddm(X, Y, compute = "R")
</code></pre>

<hr>
<h2 id='mdm'>Mutual Dependence Measures</h2><span id='topic+mdm'></span>

<h3>Description</h3>

<p><code>mdm</code> measures mutual dependence of all components in <code>X</code>,
where each component contains one variable (univariate) or more variables (multivariate).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdm(X, dim_comp = NULL, dist_comp = FALSE, type = "comp_simp")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdm_+3A_x">X</code></td>
<td>
<p>A matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="mdm_+3A_dim_comp">dim_comp</code></td>
<td>
<p>The numbers of variables contained by all components in <code>X</code>.
If omitted, each component is assumed to contain exactly one variable.</p>
</td></tr>
<tr><td><code id="mdm_+3A_dist_comp">dist_comp</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the distances between all components from all samples
in <code>X</code> will be returned.</p>
</td></tr>
<tr><td><code id="mdm_+3A_type">type</code></td>
<td>
<p>The type of mutual dependence measures, including
</p>

<ul>
<li> <p><code>asym_dcov</code>: asymmetric measure <code class="reqn">\mathcal{R}_n</code> based on distance covariance
<code class="reqn">\mathcal{V}_n</code>; 
</p>
</li>
<li> <p><code>sym_dcov</code>: symmetric measure <code class="reqn">\mathcal{S}_n</code> based on distance covariance
<code class="reqn">\mathcal{V}_n</code>; 
</p>
</li>
<li> <p><code>comp</code>: complete measure <code class="reqn">\mathcal{Q}_n</code> based on complete V-statistics;
</p>
</li>
<li> <p><code>comp_simp</code>: simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code> based on
incomplete V-statistics; 
</p>
</li>
<li> <p><code>asym_comp</code>: asymmetric measure <code class="reqn">\mathcal{J}_n</code> based on complete measure
<code class="reqn">\mathcal{Q}_n</code>; 
</p>
</li>
<li> <p><code>asym_comp_simp</code>: simplified asymmetric measure <code class="reqn">\mathcal{J}_n^\star</code> based on
simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code>; 
</p>
</li>
<li> <p><code>sym_comp</code>: symmetric measure <code class="reqn">\mathcal{I}_n</code> based on complete measure
<code class="reqn">\mathcal{Q}_n</code>; 
</p>
</li>
<li> <p><code>sym_comp_simp</code>: simplified symmetric measure <code class="reqn">\mathcal{I}_n^\star</code> based on
simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code>.
</p>
</li></ul>

<p>From experiments, <code>asym_dcov</code>, <code>sym_dcov</code>, <code>comp_simp</code> are recommended.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>mdm</code> returns a list including the following components:
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p>The value of the mutual dependence measure.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>The distances between all components from all samples.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Jin, Z., and Matteson, D. S. (2017).
Generalizing Distance Covariance to Measure and Test Multivariate Mutual Dependence.
arXiv preprint arXiv:1709.02532.
<a href="https://arxiv.org/abs/1709.02532">https://arxiv.org/abs/1709.02532</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># X is a 10 x 3 matrix with 10 samples and 3 variables
X &lt;- matrix(rnorm(10 * 3), 10, 3)

# assume X = (X1, X2) where X1 is 1-dim, X2 is 2-dim
mdm(X, dim_comp = c(1, 2), type = "asym_dcov")

# assume X = (X1, X2) where X1 is 2-dim, X2 is 1-dim
mdm(X, dim_comp = c(2, 1), type = "sym_dcov")

# assume X = (X1, X2, X3) where X1 is 1-dim, X2 is 1-dim, X3 is 1-dim
mdm(X, dim_comp = c(1, 1, 1), type = "comp_simp")
</code></pre>

<hr>
<h2 id='mdm_ica'>Independent Component Analysis via Mutual Dependence Measures</h2><span id='topic+mdm_ica'></span>

<h3>Description</h3>

<p><code>mdm_ica</code> performs independent component analysis by minimizing mutual dependence measures 
of all univariate components in <code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdm_ica(X, num_lhs = NULL, type = "comp", num_bo = NULL, kernel = "exp",
  algo = "par")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdm_ica_+3A_x">X</code></td>
<td>
<p>A matrix or data frame, where rows represent samples, and columns represent components.</p>
</td></tr>
<tr><td><code id="mdm_ica_+3A_num_lhs">num_lhs</code></td>
<td>
<p>The number of points generated by Latin hypercube sampling.
If omitted, an adaptive number is used.</p>
</td></tr>
<tr><td><code id="mdm_ica_+3A_type">type</code></td>
<td>
<p>The type of mutual dependence measures, including
</p>

<ul>
<li> <p><code>asym</code>: asymmetric measure <code class="reqn">\mathcal{R}_n</code> based on distance covariance 
<code class="reqn">\mathcal{V}_n</code>;
</p>
</li>
<li> <p><code>sym</code>: symmetric measure <code class="reqn">\mathcal{S}_n</code> based on distance covariance 
<code class="reqn">\mathcal{V}_n</code>;
</p>
</li>
<li> <p><code>comp</code>: simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code> based on 
incomplete V-statistics;
</p>
</li>
<li> <p><code>dhsic</code>: d-variable Hilbert&ndash;Schmidt independence criterion dHSIC<code class="reqn">_n</code> based on 
Hilbert&ndash;Schmidt independence criterion HSIC<code class="reqn">_n</code>. 
</p>
</li></ul>
</td></tr>
<tr><td><code id="mdm_ica_+3A_num_bo">num_bo</code></td>
<td>
<p>The number of points evaluated by Bayesian optimization.</p>
</td></tr>
<tr><td><code id="mdm_ica_+3A_kernel">kernel</code></td>
<td>
<p>The kernel of the underlying Gaussian process in Bayesian optimization, including
</p>

<ul>
<li> <p><code>exp</code>: squared exponential kernel;
</p>
</li>
<li> <p><code>mat</code>: Matern 5/2 kernel.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mdm_ica_+3A_algo">algo</code></td>
<td>
<p>The algorithm of optimization, including
</p>

<ul>
<li> <p><code>def</code>: deflation algorithm, where the components are extracted one at a time;
</p>
</li>
<li> <p><code>par</code>: parallel algorithm, where the components are extracted simultaneously.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p><code>mdm_ica</code> returns a list including the following components:
</p>
<table>
<tr><td><code>theta</code></td>
<td>
<p>The rotation angles of the estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>The estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>obj</code></td>
<td>
<p>The objective value of the estimated independence components.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>The estimated independence components.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Jin, Z., and Matteson, D. S. (2017).
Generalizing Distance Covariance to Measure and Test Multivariate Mutual Dependence.
arXiv preprint arXiv:1709.02532.
<a href="https://arxiv.org/abs/1709.02532">https://arxiv.org/abs/1709.02532</a>.
</p>
<p>Pfister, N., et al. (2018).
Kernel-based tests for joint independence.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 80(1), 5-31.
<a href="http://dx.doi.org/10.1111/rssb.12235">http://dx.doi.org/10.1111/rssb.12235</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># X is a 10 x 3 matrix with 10 samples and 3 components
X &lt;- matrix(rnorm(10 * 3), 10, 3)

# deflation algorithm
mdm_ica(X, type = "asym", algo = "def")
# parallel algorithm
mdm_ica(X, type = "asym", algo = "par")

## Not run: 
# bayesian optimization with exponential kernel
mdm_ica(X, type = "sym", num_bo = 1, kernel = "exp", algo = "par")
# bayesian optimization with matern kernel
mdm_ica(X, type = "comp", num_bo = 1, kernel = "mat", algo = "par")

## End(Not run)
</code></pre>

<hr>
<h2 id='mdm_test'>Mutual Independence Tests</h2><span id='topic+mdm_test'></span>

<h3>Description</h3>

<p><code>mdm_test</code> tests mutual independence of all components in <code>X</code>,
where each component contains one variable (univariate) or more variables (multivariate).
All tests are implemented as permutation tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdm_test(X, dim_comp = NULL, num_perm = NULL, type = "comp_simp")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdm_test_+3A_x">X</code></td>
<td>
<p>A matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="mdm_test_+3A_dim_comp">dim_comp</code></td>
<td>
<p>The numbers of variables contained by all components in <code>X</code>.
If omitted, each component is assumed to contain exactly one variable.</p>
</td></tr>
<tr><td><code id="mdm_test_+3A_num_perm">num_perm</code></td>
<td>
<p>The number of permutation samples drawn to approximate the asymptotic distributions
of mutual dependence measures. If omitted, an adaptive number is used.</p>
</td></tr>
<tr><td><code id="mdm_test_+3A_type">type</code></td>
<td>
<p>The type of mutual dependence measures, including
</p>

<ul>
<li> <p><code>asym_dcov</code>: asymmetric measure <code class="reqn">\mathcal{R}_n</code> based on distance covariance
<code class="reqn">\mathcal{V}_n</code>; 
</p>
</li>
<li> <p><code>sym_dcov</code>: symmetric measure <code class="reqn">\mathcal{S}_n</code> based on distance covariance
<code class="reqn">\mathcal{V}_n</code>; 
</p>
</li>
<li> <p><code>comp</code>: complete measure <code class="reqn">\mathcal{Q}_n</code> based on complete V-statistics;
</p>
</li>
<li> <p><code>comp_simp</code>: simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code> based on
incomplete V-statistics; 
</p>
</li>
<li> <p><code>asym_comp</code>: asymmetric measure <code class="reqn">\mathcal{J}_n</code> based on complete measure
<code class="reqn">\mathcal{Q}_n</code>; 
</p>
</li>
<li> <p><code>asym_comp_simp</code>: simplified asymmetric measure <code class="reqn">\mathcal{J}_n^\star</code> based on
simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code>; 
</p>
</li>
<li> <p><code>sym_comp</code>: symmetric measure <code class="reqn">\mathcal{I}_n</code> based on complete measure
<code class="reqn">\mathcal{Q}_n</code>; 
</p>
</li>
<li> <p><code>sym_comp_simp</code>: simplified symmetric measure <code class="reqn">\mathcal{I}_n^\star</code> based on
simplified complete measure <code class="reqn">\mathcal{Q}_n^\star</code>.
</p>
</li></ul>

<p>From experiments, <code>asym_dcov</code>, <code>sym_dcov</code>, <code>comp_simp</code> are recommended.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>mdm_test</code> returns a list including the following components:
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p>The value of the mutual dependence measure.</p>
</td></tr>
<tr><td><code>pval</code></td>
<td>
<p>The p-value of the mutual independence test.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Jin, Z., and Matteson, D. S. (2017).
Generalizing Distance Covariance to Measure and Test Multivariate Mutual Dependence.
arXiv preprint arXiv:1709.02532.
<a href="https://arxiv.org/abs/1709.02532">https://arxiv.org/abs/1709.02532</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# X is a 10 x 3 matrix with 10 samples and 3 variables
X &lt;- matrix(rnorm(10 * 3), 10, 3)

# assume X = (X1, X2) where X1 is 1-dim, X2 is 2-dim
mdm_test(X, dim_comp = c(1, 2), type = "asym_dcov")

# assume X = (X1, X2) where X1 is 2-dim, X2 is 1-dim
mdm_test(X, dim_comp = c(2, 1), type = "sym_dcov")

# assume X = (X1, X2, X3) where X1 is 1-dim, X2 is 1-dim, X3 is 1-dim
mdm_test(X, dim_comp = c(1, 1, 1), type = "comp_simp")

## End(Not run)
</code></pre>

<hr>
<h2 id='pmdc'>Partial Martingale Difference Correlation</h2><span id='topic+pmdc'></span>

<h3>Description</h3>

<p><code>pmdc</code> measures conditional mean dependence of <code>Y</code> given <code>X</code> adjusting for the 
dependence on <code>Z</code>, where each contains one variable (univariate) or more variables (multivariate).
Only the U-centering approach is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmdc(X, Y, Z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmdc_+3A_x">X</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="pmdc_+3A_y">Y</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="pmdc_+3A_z">Z</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>pmdc</code> returns the squared partial martingale difference correlation 
of <code>Y</code> given <code>X</code> adjusting for the dependence on <code>Z</code>.
</p>


<h3>References</h3>

<p>Park, T., Shao, X., and Yao, S. (2015).
Partial martingale difference correlation.
Electronic Journal of Statistics, 9(1), 1492-1517.
<a href="http://dx.doi.org/10.1214/15-EJS1047">http://dx.doi.org/10.1214/15-EJS1047</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># X, Y, Z are 10 x 2 matrices with 10 samples and 2 variables
X &lt;- matrix(rnorm(10 * 2), 10, 2)
Y &lt;- matrix(rnorm(10 * 2), 10, 2)
Z &lt;- matrix(rnorm(10 * 2), 10, 2)

pmdc(X, Y, Z)
</code></pre>

<hr>
<h2 id='pmdd'>Partial Martingale Difference Divergence</h2><span id='topic+pmdd'></span>

<h3>Description</h3>

<p><code>pmdd</code> measures conditional mean dependence of <code>Y</code> given <code>X</code> adjusting for the 
dependence on <code>Z</code>, where each contains one variable (univariate) or more variables (multivariate).
Only the U-centering approach is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmdd(X, Y, Z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmdd_+3A_x">X</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="pmdd_+3A_y">Y</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
<tr><td><code id="pmdd_+3A_z">Z</code></td>
<td>
<p>A vector, matrix or data frame, where rows represent samples, and columns represent variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>pmdd</code> returns the squared partial martingale difference divergence
of <code>Y</code> given <code>X</code> adjusting for the dependence on <code>Z</code>.
</p>


<h3>References</h3>

<p>Park, T., Shao, X., and Yao, S. (2015).
Partial martingale difference correlation.
Electronic Journal of Statistics, 9(1), 1492-1517.
<a href="http://dx.doi.org/10.1214/15-EJS1047">http://dx.doi.org/10.1214/15-EJS1047</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># X, Y, Z are vectors with 10 samples and 1 variable
X &lt;- rnorm(10)
Y &lt;- rnorm(10)
Z &lt;- rnorm(10)

pmdd(X, Y, Z)

# X, Y, Z are 10 x 2 matrices with 10 samples and 2 variables
X &lt;- matrix(rnorm(10 * 2), 10, 2)
Y &lt;- matrix(rnorm(10 * 2), 10, 2)
Z &lt;- matrix(rnorm(10 * 2), 10, 2)

pmdd(X, Y, Z)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
