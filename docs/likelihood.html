<!DOCTYPE html><html><head><title>Help for package likelihood</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {likelihood}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#likelihood-package'>
<p>Package for maximum likelihood estimation</p></a></li>
<li><a href='#anneal'><p>Perform Simulated Annealing for Maximum Likelihood Estimation</p></a></li>
<li><a href='#crown_rad'><p>Dataset of Tree DBH and Crown Radius</p></a></li>
<li><a href='#from_sortie'><p>Generated Tree Allometry Dataset</p></a></li>
<li><a href='#likeli'><p>Calculate Likelihood</p></a></li>
<li><a href='#likeli_4_optim'><p>Use Likelihood with Optim</p></a></li>
<li><a href='#Likelihood Calculation'><p>Details on the Calculation of Likelihood</p></a></li>
<li><a href='#predicted_results'><p>Calculate Model Predicted Results</p></a></li>
<li><a href='#Simulated Annealing Algorithm'><p>Details on the Simulated Annealing Algorithm</p></a></li>
<li><a href='#support_limits'><p>Calculate Support Limits</p></a></li>
<li><a href='#write_results'><p>Write the Results of Simulated Annealing to File</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.9</td>
</tr>
<tr>
<td>Title:</td>
<td>Methods for Maximum Likelihood Estimation</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-30</td>
</tr>
<tr>
<td>Author:</td>
<td>Lora Murphy [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lora Murphy &lt;murphyl@caryinstitute.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for maximum likelihood estimation of parameters 
  of scientific models. Based on Goffe et al (1994) &lt;<a href="https://doi.org/10.1016%2F0304-4076%2894%2990038-8">doi:10.1016/0304-4076(94)90038-8</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.1.1), nlme</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-30 14:44:19 UTC; lora</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-30 16:50:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='likelihood-package'>
Package for maximum likelihood estimation
</h2><span id='topic+likelihood-package'></span><span id='topic+likelihood'></span>

<h3>Description</h3>

<p>This package allows you to find the maximum likelihood estimates of statistical models using simulated annealing, a global optimization algorithm.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.5</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2012-01-27</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 2.1.1, nlme</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GNU Public License</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Several demonstration scripts are included in the demo directory.
</p>


<h3>Author(s)</h3>

<p>Lora Murphy &lt;murphyl@caryinstitute.org&gt;
Maintainer: Lora Murphy &lt;murphyl@caryinstitute.org&gt;
</p>

<hr>
<h2 id='anneal'>Perform Simulated Annealing for Maximum Likelihood Estimation</h2><span id='topic+anneal'></span>

<h3>Description</h3>

<p>Performs simulated annealing - a global optimization algorithm - for
maximum likelihood estimation of model parameters.  Bounded, unbounded, and
mixed searches can all be performed. See the 
<a href="#topic+Simulated+20Annealing+20Algorithm">Simulated Annealing Algorithm</a> help page for more on how simulated
annealing is actually performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anneal(model, par, var, source_data, par_lo = NULL, par_hi = NULL, pdf, 
dep_var, initial_temp = 3, temp_red = 0.95, ns = 20, nt = 100, 
max_iter = 50000, min_change = 0, min_drops = 100, hessian = TRUE, 
delta = 100, slimit = 2, c = 2, note = "", show_display = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anneal_+3A_model">model</code></td>
<td>
<p>Scientific model for whose parameters <code>anneal</code> will find
maximum likelihood estimates. This is an R function.</p>
</td></tr>
<tr><td><code id="anneal_+3A_par">par</code></td>
<td>
<p>List object of parameters for which to find maximum likelihood 
estimates using simulated annealing. The name of each component in <code>par</code>
matches the name of an argument in one of the functions passed to
<code>anneal</code> (either <code>model</code>, <code>pdf</code>, or any other function that
you pass in).  The value of each component is the initial value. All
components in <code>par</code> must be numeric vectors.  Vectors of length greater
than one have each of their elements treated separately as individual
parameters to estimate.</p>
</td></tr>
<tr><td><code id="anneal_+3A_var">var</code></td>
<td>
<p>List object with the source for all other arguments and
data used by <code>model</code>, <code>pdf</code>, and any other functions.</p>
</td></tr>
<tr><td><code id="anneal_+3A_source_data">source_data</code></td>
<td>
<p>Data frame containing any needed source data. You can 
reference the data frame columns by name to <code>anneal</code>.</p>
</td></tr>
<tr><td><code id="anneal_+3A_par_lo">par_lo</code></td>
<td>
<p>List object with the lower search bounds for each parameter to
estimate.  The list component names and sizes should each match a component
in <code>par</code>. Any individual component (up to and including the entire
<code>par_lo</code> argument) is optional. For any component of <code>par</code> that is
omitted, the lower search bound for that parameter is assumed to be negative
infinity. (Infinity isn't quite infinity - see details section for more.)</p>
</td></tr>
<tr><td><code id="anneal_+3A_par_hi">par_hi</code></td>
<td>
<p>List object with the upper search bounds for each parameter to
estimate.  The list component names and sizes should each match a component
in <code>par</code>. Any individual component (up to and including the entire
<code>par_hi</code> argument) is optional.  For any component of <code>par</code> that is
omitted, the upper search bound for that parameter is assumed to be infinity.
(Infinity isn't quite infinity - see details section for more.)</p>
</td></tr>
<tr><td><code id="anneal_+3A_pdf">pdf</code></td>
<td>
<p>Probability density function to use in likelihood calculations.
<code>anneal</code> depends on a log likelihood value, so you must instruct
<code>pdf</code> to calculate the log of its result.  This is an option with all of
R's built-in PDFs.</p>
</td></tr>
<tr><td><code id="anneal_+3A_dep_var">dep_var</code></td>
<td>
<p>The name of the column in <code>source_data</code>, as a string, that
contains the dependent variable (the &ldquo;observed&rdquo; value).</p>
</td></tr>
<tr><td><code id="anneal_+3A_initial_temp">initial_temp</code></td>
<td>
<p>The temperature at which to start the annealing process.</p>
</td></tr>
<tr><td><code id="anneal_+3A_temp_red">temp_red</code></td>
<td>
<p>The rate of temperature reduction (a fractional number less
than 1).</p>
</td></tr>
<tr><td><code id="anneal_+3A_ns">ns</code></td>
<td>
<p>Number of iterations between changes in parameter search ranges. One
iteration varies all parameters one time.</p>
</td></tr>
<tr><td><code id="anneal_+3A_nt">nt</code></td>
<td>
<p>Controls number of iterations between drops in temperature. Temperature
drops occur at nt * ns iterations. One iteration varies all parameters one time.</p>
</td></tr>
<tr><td><code id="anneal_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations to perform. One iteration varies
all parameters one time.</p>
</td></tr>
<tr><td><code id="anneal_+3A_min_change">min_change</code></td>
<td>
<p>An alternate (and optional) way to specify quitting
conditions for the run. This is the minimum amount of change in likelihood
in <code>min_drop</code> number of temperature drops.  If the change is less than
<code>min_change</code>, execution stops even if <code>max_iter</code> number of
iterations have not been performed.</p>
</td></tr>
<tr><td><code id="anneal_+3A_min_drops">min_drops</code></td>
<td>
<p>The companion to <code>min_change</code> for alternate quitting
conditions.  This is the number of temperature drops over which the
likelihood must have changed more than <code>min_change</code> for execution to
continue.</p>
</td></tr>
<tr><td><code id="anneal_+3A_hessian">hessian</code></td>
<td>
<p>if TRUE, the Hessian matrix is used to calculate the standard
error for each parameter and the parameter variance-covariance matrix. These
are included in the output.  If FALSE, this step is skipped.</p>
</td></tr>
<tr><td><code id="anneal_+3A_delta">delta</code></td>
<td>
<p>The number by which to divide each parameter maximum likelihood   
estimate value when searching for support limits. The bigger the number, the 
finer the search. See <code><a href="#topic+support_limits">support_limits</a></code> for more on how support
limits are calculated.</p>
</td></tr>
<tr><td><code id="anneal_+3A_slimit">slimit</code></td>
<td>
<p>When calculating support limits for the parameter maximum
likelihood estimates, this is the number of likelihood units less than the
optimum likelihood for which to search the parameter ranges. 2 units is 
standard.  1.92 units corresponds roughly to a 95 percent confidence 
interval.</p>
</td></tr>
<tr><td><code id="anneal_+3A_c">c</code></td>
<td>
<p>Controls the reduction in parameter search range. A value of 0 would
keep the search range permanently between the values set in <code>par_lo</code> and
<code>par_hi</code>. A higher value will restrict the search more when range
adjustments are made. A value of 2 is recommended by Goffe.</p>
</td></tr>
<tr><td><code id="anneal_+3A_note">note</code></td>
<td>
<p>A note about the run.  This can be any character string.  This 
will be written to output files by <code><a href="#topic+write_results">write_results</a></code>.</p>
</td></tr>
<tr><td><code id="anneal_+3A_show_display">show_display</code></td>
<td>
<p>Whether or not to show the progress display.</p>
</td></tr>
<tr><td><code id="anneal_+3A_...">...</code></td>
<td>
<p>Any other data needed by <code>model</code>, <code>pdf</code>, or any other
function to be called by <code>anneal</code>.  This is an alternative to providing
the data in <code>var</code>; however, passing all values in <code>var</code> is strongly
recommended.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulated annealing is a search algorithm that attempts to find the global
maximum of the likelihood surface produced by all possible values of the
parameters being estimated.  The value of the maximum that <code>anneal</code> finds
is the maximum likelihood value, and the value of the parameters that produced
it are their maximum likelihood estimates.  See the
<a href="#topic+Simulated+20Annealing+20Algorithm">Simulated Annealing Algorithm</a> page for details on how the search is
performed. See the <a href="#topic+Likelihood+20Calculation">Likelihood Calculation</a> page for details on how
likelihood is calculated.  Simulated annealing is an algorithm that can 
search any function; but <code>anneal</code> specifically searches likelihood.
</p>
<p>The <code>model</code> function is the scientific model, which generally takes as
arguments the parameters for which to estimate maximum likelihood.  It 
returns a predicted value of the dependent variable for each record in the
<code>source_data</code> dataset, which is compared to the actual (observed) value
when likelihood is calculated.  Write <code>model</code> so that it returns a
vector of numeric values, one for each record in the dataset.
</p>
<p>The probability density function calculates the likelihood using the
predicted and observed values of the dependent variable.  You can provide 
your own function, but R has many built-in functions that you can use.  You 
can read more about R's probability density functions in the help file
&ldquo;An Introduction to R&rdquo;, but here is a brief list: <code><a href="stats.html#topic+dbeta">dbeta</a></code>
(beta), <code><a href="stats.html#topic+dexp">dexp</a></code> (exponential), <code><a href="stats.html#topic+dgamma">dgamma</a></code> (gamma),
<code><a href="stats.html#topic+dlnorm">dlnorm</a></code> (lognormal), <code><a href="stats.html#topic+dnbinom">dnbinom</a></code> (negative binomial),
<code><a href="stats.html#topic+dnorm">dnorm</a></code> (normal), and <code><a href="stats.html#topic+dpois">dpois</a></code> (poisson).  These all
take a <code>log</code> argument which you should set to TRUE in <code>var</code> in
order to calculate the log likelihood.  If you write your own probability
density function, it should return a vector of values, one for each record
in the dataset.
</p>
<p>If you wish, some of the arguments passed to <code>model</code> or <code>pdf</code> by
<code>anneal</code> can be the results of other functions.  <code>anneal</code>
will make sure these functions are evaluated at each search iteration.
</p>
<p><code>anneal</code> handles all function calls and data.  You tell <code>anneal</code>
how to use your functions and data using <code>par</code> and <code>var</code>.
Use <code>par</code> to give <code>anneal</code> the list of parameters for which to
find maximum likelihood estimates.  All values must be numeric vectors.  The
name of each list component must match the function argument where the
value should go.  For example, if your model function takes an argument 
called &ldquo;a&rdquo;, and you want the maximum likelihood estimate for a, there 
should be a <code>par$a</code>.  If any component of <code>par</code> is a vector of 
length greater than one, each value is treated as a separate parameter to 
estimate.  This is useful if, for example, you wish to estimate a parameter 
that has a different value for different sites or species.
</p>
<p>Use <code>var</code> to tell <code>anneal</code> where all other functions and data come
from.  <code>var</code> is a list, and each component's name matches the function
argument it should be used for (as with <code>par</code>).  The value can be of any
data type that makes sense to the function.  To indicate that the source of a
function argument is a column of data from a dataset, set that value of
<code>var</code> to the name of the data frame's column, as a character string (for
example, <code>var$dbh&lt;-"DBH"</code>).  Case matters!  You will get the best
results if all function arguments and column names are unique, so that there
is no ambiguity. You are also free to reference values directly from the global environment in your functions if you prefer.
</p>
<p>The reserved character string &ldquo;predicted&rdquo;, used in <code>var</code>, means
the predicted value of the dependent variable, as calculated by <code>model</code>.
</p>
<p>If you want <code>anneal</code> to pass the results of another function as an
argument to the <code>model</code> or <code>pdf</code> functions, define the function
and then set the appropriate argument in <code>var</code> to the name of the
function.  Then provide all arguments to the sub-function in <code>var</code> as
well.  For instance, if your model function takes an argument called
<code>x</code>, and you wish <code>x</code> to be the result of function <code>fun1</code>,
then set <code>var$x &lt;- fun1</code>, and add any arguments to <code>fun1</code> to
<code>var</code>.  <code>anneal</code> will ensure that all functions are evaluated in 
the proper order.
</p>
<p>If the likelihood is calculated as infinity or NaN (which can easily
happen), the likelihood is arbitrarily set to -1000000 to preserve the
ability to graph results and compare values.  If your best likelihood is 
-1000000, it is possible that no valid likelihood value was found.
</p>
<p>The search ranges for parameters can be set to (or allowed to default to)
negative and positive infinity. In practice, the search is bounded by the
largest and smallest values the computer can work with.  To find out what the
actual limits are on your computer, use <code>.Machine$double.xmax</code>.
</p>
<p>When looking at the examples provided in the demos that come with this
package, check those for <code>likeli</code> as well, since the parameter setup
techniques are the same.
</p>


<h3>Value</h3>

<p>A list object with information on the annealing run.  If you stop the run by
pressing Esc, you will get this data structure with the results of the run at
the point where you stopped it.
</p>
<table>
<tr><td><code>best_pars</code></td>
<td>
<p>The maximum likelihood estimates for each value in
<code>par</code>.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>A copy of the <code>var</code> argument, to help you keep track of your
analysis. To save space, any data frames are removed.</p>
</td></tr>
<tr><td><code>source_data</code></td>
<td>
<p>A copy of the <code>source_data</code> data frame, with a column
added for the predicted values calculated by <code>model</code> using the maximum
likelihood estimates of the parameters.</p>
</td></tr>
<tr><td><code>pdf</code></td>
<td>
<p>The name of the <code>pdf</code> function.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The name of the <code>model</code> function.</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>The number of annealing iterations completed.  One iteration
varies all parameters one time.  If the run does not complete, this may not
be an integer.</p>
</td></tr>
<tr><td><code>max_likeli</code></td>
<td>
<p>The maximum likelihood value found.</p>
</td></tr>
<tr><td><code>aic_corr</code></td>
<td>
<p>The value of Akaike's Information Criterion, &ldquo;corrected&rdquo;
for small sample size. See the <a href="#topic+Simulated+20Annealing+20Algorithm">Simulated Annealing Algorithm</a> help page
for more.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>The value of Akaike's Information Criterion. See the
<a href="#topic+Simulated+20Annealing+20Algorithm">Simulated Annealing Algorithm</a> help page for more.</p>
</td></tr>
<tr><td><code>slope</code></td>
<td>
<p>Slope of observed values linearly regressed on those predicted by
<code>model</code>, using the parameter maximum likelihood estimates. The intercept
is forced at zero.</p>
</td></tr>
<tr><td><code>R2</code></td>
<td>
<p>Proportion of variance explained by the model relative to that
explained by the simple mean of the data.</p>
</td></tr>
<tr><td><code>likeli_hist</code></td>
<td>
<p>Data frame with the history of likelihood change throughout
the run. All changes in likelihood are recorded, along with regular periodic
checkpoints. The columns are: &ldquo;temp&rdquo;, the temperature at that point,
&ldquo;iter&rdquo;, the number of iterations completed, and &ldquo;likeli&rdquo;, the
maximum likelihood value.</p>
</td></tr>
<tr><td><code>par_lo</code></td>
<td>
<p>List object with the lower bounds for each of the parameters. If
any value was omitted in the original arguments, it is recorded here as a
value that approximates negative infinity.</p>
</td></tr>
<tr><td><code>par_hi</code></td>
<td>
<p>List object with upper bounds for varying parameters. If
any value was omitted in the original arguments, it is recorded here as a
value that approximates infinity.</p>
</td></tr>
<tr><td><code>par_step</code></td>
<td>
<p>List object with final size of the search range for each
parameter.</p>
</td></tr>
<tr><td><code>note</code></td>
<td>
<p>The value of the <code>note</code> argument, above.</p>
</td></tr>
<tr><td><code>upper_limits</code></td>
<td>
<p>List object with upper support limits for each parameter.
For more on support limits, see the <code><a href="#topic+support_limits">support_limits</a></code> function.</p>
</td></tr>
<tr><td><code>lower_limits</code></td>
<td>
<p>List object with lower support limits for each parameters.
For more on support limits, see the <code><a href="#topic+support_limits">support_limits</a></code> function.</p>
</td></tr>
<tr><td><code>std_errs</code></td>
<td>
<p>If <code>anneal</code> was run with <code>hessian = TRUE</code>, this is
a list object with the standard errors for each parameter.</p>
</td></tr>
<tr><td><code>var_covar_mat</code></td>
<td>
<p>If <code>anneal</code> was run with <code>hessian = TRUE</code>, this
is the parameter variance / covariance matrix.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Goffe, W.L., G.D. Ferrier, and J. Rogers. 1994.  Global optimization of
statistical functions with simulated annealing.  Journal of Econometrics
60:65-99.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##
## Simulated annealing to maximize log
## likelihood for the following:
## Model: Radius = a + b * DBH
## Dataset: included crown_rad dataset
## We want to use simulated annealing to
## find maximum likelihood estimates of
## the parameters "a" and "b".
##
## Not run: 
library(likelihood)

## Set up our dataset
data(crown_rad)
dataset &lt;- crown_rad

## Create our model function
modelfun &lt;- function (a, b, DBH) {a + b * DBH}

## Create the list for the parameters to estimate and
## set initial values for a and b
par &lt;- list(a = 0, b = 0)

## Create a place to put all the other data needed by
## the model and PDF, and indicate that DBH comes from 
## the column marked "DBH" in the dataset
var &lt;- list(DBH = "DBH")

## Set bounds and initial search ranges within which to search for parameters
par_lo &lt;- list(a = 0, b = 0)
par_hi &lt;- list(a = 50, b = 50)

## We'll use the normal probability density function -
## add the options for it to our parameter list
## "x" value in PDF is observed value
var$x &lt;- "Radius"

## Mean in normal PDF
var$mean &lt;- "predicted"
var$sd &lt;- 0.815585

## Have it calculate log likelihood
var$log &lt;- TRUE

results&lt;-anneal(model = modelfun, par = par, var = var,
  source_data = dataset, par_lo = par_lo, par_hi = par_hi,
  pdf = dnorm, dep_var = "Radius", max_iter = 20000)

## Alternately: reference crown_rad$DBH directly in the function without
## using var
modelfun &lt;- function (a, b) {a + b * crown_rad$DBH}
var &lt;- list(x = "Radius",
            mean = "predicted",
            sd = 0.815585,
            log = TRUE)
results&lt;-anneal(model = modelfun, par = par, var = var,
  source_data = dataset, par_lo = par_lo, par_hi = par_hi,
  pdf = dnorm, dep_var = "Radius", max_iter = 20000)

## End(Not run)  
</code></pre>

<hr>
<h2 id='crown_rad'>Dataset of Tree DBH and Crown Radius</h2><span id='topic+crown_rad'></span>

<h3>Description</h3>

<p>This is a set of imaginary data for DBH and crown radius for a set of trees.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crown_rad</code></pre>


<h3>Format</h3>

<p>Tab-delimited text.</p>

<hr>
<h2 id='from_sortie'>Generated Tree Allometry Dataset</h2><span id='topic+from_sortie'></span>

<h3>Description</h3>

<p>This is a set of generated data for tree allometry.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>from_sortie</code></pre>


<h3>Format</h3>

<p>Tab-delimited text.</p>

<hr>
<h2 id='likeli'>Calculate Likelihood</h2><span id='topic+likeli'></span>

<h3>Description</h3>

<p>Calculate likelihood of a model, given a dataset.  Typically this is
log likelihood. See the <a href="#topic+Likelihood+20Calculation">Likelihood Calculation</a> page for details on how
likelihood is calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likeli(model, par, var, source_data, pdf, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="likeli_+3A_model">model</code></td>
<td>
<p>Model function for which to calculate likelihood.  See details for 
how to set up this function.</p>
</td></tr>
<tr><td><code id="likeli_+3A_par">par</code></td>
<td>
<p>List object of parameters for which to calculate likelihood. The 
name of each component in <code>par</code> matches the name of an argument in one
of the functions passed to <code>likeli</code> (either <code>model</code>, <code>pdf</code>, or
another function that does initial calculations). All elements in <code>par</code>
must be numeric vectors. This is the same as the argument that you pass to 
<code><a href="#topic+anneal">anneal</a></code>.</p>
</td></tr>
<tr><td><code id="likeli_+3A_var">var</code></td>
<td>
<p>List object with the source for all other non-parameter arguments and
data used by <code>model</code>, <code>pdf</code>, and any other functions. This is the 
same as the argument that you pass to <code><a href="#topic+anneal">anneal</a></code>.</p>
</td></tr>
<tr><td><code id="likeli_+3A_source_data">source_data</code></td>
<td>
<p>Data frame containing any needed source data. You can 
reference the data frame columns by name to <code>likeli</code>.</p>
</td></tr>
<tr><td><code id="likeli_+3A_pdf">pdf</code></td>
<td>
<p>Probability density function to use in the likelihood calculation.
If you want a log likelihood value, which is usual and matches what 
<code><a href="#topic+anneal">anneal</a></code> does, instruct <code>pdf</code> to calculate the log of its 
result.  This is an option with all of R's built-in PDFs.</p>
</td></tr>
<tr><td><code id="likeli_+3A_...">...</code></td>
<td>
<p>Any other data that may be needed by <code>model</code>, <code>pdf</code>, or
any other function to be called by <code>likeli</code>.  This is an alternative to 
providing the data in <code>var</code>; however, passing values in <code>var</code> is
strongly recommended.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the <a href="#topic+Likelihood+20Calculation">Likelihood Calculation</a> page for details on how
likelihood is calculated. <code><a href="#topic+anneal">anneal</a></code> uses the same parameters and
is set up in the same way.
</p>
<p>The <code>model</code> function is the scientific model, which generally takes as
arguments the parameters for which to estimate maximum likelihood.  It 
returns a predicted value of the dependent variable for each record in the
<code>source_data</code> dataset, which is compared to the actual (observed) value
when likelihood is calculated.  Write <code>model</code> so that it returns a
vector of numeric values, one for each record in the dataset.
</p>
<p>The probability density function calculates the likelihood using the
predicted and observed values of the dependent variable.  You can provide 
your own function, but R has many built-in functions that you can use. You 
can read more about R's probability density functions in the help file
&ldquo;An Introduction to R&rdquo;, but here is a brief list: <code><a href="stats.html#topic+dbeta">dbeta</a></code>
(beta), <code><a href="stats.html#topic+dexp">dexp</a></code> (exponential), <code><a href="stats.html#topic+dgamma">dgamma</a></code> (gamma),
<code><a href="stats.html#topic+dlnorm">dlnorm</a></code> (lognormal), <code><a href="stats.html#topic+dnbinom">dnbinom</a></code> (negative binomial),
<code><a href="stats.html#topic+dnorm">dnorm</a></code> (normal), and <code><a href="stats.html#topic+dpois">dpois</a></code> (poisson).  These all
take a <code>log</code> argument which you should set to TRUE in <code>var</code> in
order to calculate the log likelihood.  If you write your own probability
density function, it should return a vector of values, one for each record
in the dataset.
</p>
<p>If you wish, some of the arguments passed to <code>model</code> or <code>pdf</code> by
<code>likeli</code> can be the results of other functions.
</p>
<p><code>likeli</code> handles all function calls and data.  You tell <code>likeli</code>
how to use your functions and data using <code>par</code> and <code>var</code>.
Use <code>par</code> to give <code>likeli</code> the list of parameters for the model.
Use <code>var</code> to tell <code>likeli</code> where all other functions and data come
from.  <code>var</code> and <code>var</code> are lists, and each component's name matches
the function argument it should be used for.  For example, if the 
<code>model</code> function takes an argument called &ldquo;<code>a</code>&rdquo;, there 
should be a <code>par$a</code> or a <code>var$a</code> with the value of <code>a</code>.  For
<code>par</code>, all values must be numeric vectors.  For <code>var</code>, the values 
can be of any data type that makes sense to the function.  To indicate that 
the source of a function argument is a column of data from a dataset, set 
that value of <code>var</code> to the name of the data frame's column, as a 
character string (for example, <code>var$dbh&lt;-"DBH"</code>).  Case matters!  You 
will get the best results if all function arguments and column names are 
unique, so that there is no ambiguity. You are also free to reference values directly from the global environment in your functions if you prefer.
</p>
<p>The difference between <code>par</code> and <code>var</code> is important to
<code><a href="#topic+anneal">anneal</a></code> but not to <code>likeli</code>.
</p>
<p>The reserved character string &ldquo;predicted&rdquo;, used in <code>var</code>, means
the predicted value of the dependent variable, as calculated by <code>model</code>.
</p>
<p>If you want <code>likeli</code> to pass the results of another function as an
argument to the <code>model</code> or <code>pdf</code> functions, define the function
and then set the appropriate argument in <code>var</code> to the name of the
function.  Then provide all arguments to the sub-function in <code>var</code> as
well.  For instance, if your model function takes an argument called
<code>x</code>, and you wish <code>x</code> to be the result of function <code>fun1</code>,
then set <code>var$x &lt;- fun1</code>, and add any arguments to <code>fun1</code> to
<code>var</code>.  <code>likeli</code> will ensure that all functions are evaluated in
the proper order.
</p>


<h3>Value</h3>

<p>A single numeric value for the likelihood.  It is possible for this to be 
<code>NaN</code> or <code>Inf</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(likelihood)

## Use the included crown_rad dataset
data( crown_rad )

## Create our model function - crown radius is a linear function of DBH.
## DBH is a column of data from the crown_rad dataset; a and b are single
## parameter values.
model &lt;- function (a, b, DBH) {a + b * DBH}

## Create our parameters list and set values for a and b
par &lt;- list(a = 1.12, b = 0.07)

## Create a place to put all the other data needed by
## the model and PDF, and indicate that DBH comes from 
## the column marked "DBH" in the dataset
var &lt;- list(DBH = "DBH")

## We'll use the normal probability density function dnorm - add its
## arguments to our parameter list

## "x" value in PDF is observed value
var$x &lt;- "Radius"

## The mean is the predicted value, the outcome of the model statement. Use
## the reserved word "predicted"
var$mean &lt;- "predicted"
## Use a fixed value of the standard deviation for this example
var$sd &lt;- 0.815585

## Have dnorm calculate log likelihood
var$log &lt;- TRUE

result &lt;- likeli(model, par, var, crown_rad, dnorm)

## Alternately: reference crown_rad$DBH directly in the function without
## using var
model &lt;- function (a, b) {a + b * crown_rad$DBH}
var &lt;- list(x = "Radius",
            mean = "predicted",
            sd = 0.815585,
            log = TRUE)
result &lt;- likeli(model, par, var, crown_rad, dnorm)
</code></pre>

<hr>
<h2 id='likeli_4_optim'>Use Likelihood with Optim</h2><span id='topic+likeli_4_optim'></span>

<h3>Description</h3>

<p>Wraps the function <code><a href="#topic+likeli">likeli</a></code> so you can use it with
<code><a href="stats.html#topic+optim">optim</a></code>.  This allows you to use other optimization methods to
find maximum likelihood estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likeli_4_optim(par_2_analyze, model, par_names, var, source_data, pdf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="likeli_4_optim_+3A_par_2_analyze">par_2_analyze</code></td>
<td>
<p>Vector of initial values for those parameters that are
to be optimized.  This should be a vector, NOT a list.  This MUST be a 
one-dimensional vector - i.e. none of the vector members can be vectors
themselves (in contrast to the rules for <code>anneal</code>).  <code>optim</code> will
pass this argument to <code>likeli_4_optim</code> automatically. See the example
for more.</p>
</td></tr>
<tr><td><code id="likeli_4_optim_+3A_model">model</code></td>
<td>
<p>Model function for which to calculate likelihood.</p>
</td></tr>
<tr><td><code id="likeli_4_optim_+3A_par_names">par_names</code></td>
<td>
<p>Character vector with the name for each value in
<code>par_2_analyze</code>.</p>
</td></tr>
<tr><td><code id="likeli_4_optim_+3A_var">var</code></td>
<td>
<p>List object with the source for all other non-parameter arguments and
data used by the model, the PDF, and any sub-functions. This is the same as
the argument that you pass to <code><a href="#topic+anneal">anneal</a></code> or <code><a href="#topic+likeli">likeli</a></code>.</p>
</td></tr>
<tr><td><code id="likeli_4_optim_+3A_source_data">source_data</code></td>
<td>
<p>Data frame containing any needed source data, including
observed values.</p>
</td></tr>
<tr><td><code id="likeli_4_optim_+3A_pdf">pdf</code></td>
<td>
<p>Probability density function to use.  If you want a log
likelihood value, which is usual, the PDF must calculate the log of its
result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This wraps the <code><a href="#topic+likeli">likeli</a></code> function so that it can conform to the
requirements of <code><a href="stats.html#topic+optim">optim</a></code>.  Setting up to use this function is
exactly like setting up to use <code>likeli</code>.
</p>
<p>Remember to set the <code>fnscale</code> option in the control list for 
<code>optim</code> to -1 so that <code>optim</code> performs a maximization rather than 
the default minimization (see example for details).
</p>


<h3>Value</h3>

<p>A single numeric value for the likelihood.  It is possible for this to be 
<code>NAN</code> or <code>Inf</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#################
## Set up for likeli
#################
## Use the included crown_rad dataset
data(crown_rad)

## Create our model function - crown radius is a linear function of DBH.
## DBH is a column of data from the crown_rad dataset; a and b are single
## parameter values.
model &lt;- function (a, b, DBH) {a + b * DBH}

## We are planning to get maximum likelihood estimates for a and b.  Create
## the list that says where all other functions and data are to be found.
## Indicate that DBH comes from the column marked "DBH" in the crown_rad dataset.
var&lt;-list(DBH = "DBH")

## We'll use the normal probability density function dnorm - add its
## arguments to our parameter list
## "x" value in PDF is observed value
var$x &lt;- "Radius"

## The mean is the predicted value, the outcome of the model statement. Use
## the reserved word "predicted"
var$mean &lt;- "predicted"
var$sd &lt;- 1.0

## Have dnorm calculate log likelihood
var$log &lt;- TRUE

## Set up a vector with initial values for a and b
par_2_analyze &lt;- c(0.1, 0.1)

## Set up the vector with the names of a and b, so likeli_4_optim knows
## what the values in for_optim are
par_names &lt;- c("a", "b")

## Set your choice of optim controls - pass the other likeli_4_optim arguments
## by name so optim knows they are for likeli_4_optim
## Remember to set the fnscale option of optim to a negative value to perform
## a maximization rather than a minimization

## Not run: optim(par_2_analyze, likeli_4_optim, method = "Nelder-Mead",
  control = list(fnscale = -1), model = model, par_names = par_names,
  var = var, source_data = crown_rad, pdf = dnorm)
## End(Not run)
</code></pre>

<hr>
<h2 id='Likelihood+20Calculation'>Details on the Calculation of Likelihood</h2><span id='topic+Likelihood+20Calculation'></span>

<h3>Description</h3>

<p>There are four inputs to a likelihood calculation: a scientific model, a probability model, parameters for the model, and data. The scientific model mathematically describes one or more relationships that have been captured by the data. The probability model describes the error in the data. The parameters are the variables of interest for the scientific and probability models, for which you are trying to find the best values.
</p>
<p>The dataset contains a dependent variable of interest. The values for this variable in the dataset are the &ldquo;observed&rdquo; values. The scientific model predicts values for this same dependent variable, based on other data and parameters. The values produced by the scientific model for the dependent variable are the &ldquo;predicted&rdquo; values. The differences between the observed and predicted values are the residuals.
</p>
<p>The probability model is the core of likelihood estimation. Given the scientific model and a set of specific values for its parameters, there is a certain probability of observing the actual data. The mathematical relationship that describes that probability is the probability density function. This PDF is used to calculate the likelihood of the specific parameter values, given the data.
</p>
<p>In order to do a likelihood calculation, you must identify your scientific model, choose a probability density function, and choose values for each of your parameters. To help you identify these pieces, here is an example. Suppose research is being conducted to study how cold weather affects sales at coffee shops. A dataset is gathered, with outdoor temperature and number of coffees sold. The researcher proposes that the number of coffees sold is a linear function of the outdoor temperature. The scientific model is:
</p>
<p style="text-align: center;"><code class="reqn">Sales = a + b * Temp</code>
</p>

<p>The observed values for the dependent variable (coffee sales) are the sales data gathered. The parameters are a and b. Once test values have been chosen for a and b, we can calculate the likelihood of those values. To calculate the likelihood, the test values of a and b, along with the temperature data, are plugged into the scientific model, which gives us a set of predicted values for sales.
</p>
<p>The error, the difference between the predicted and observed values, is described by the probability model. In our example, we will assume that the error is normally distributed. The normal probability distribution function is then the probability model. The probability model compares the predicted and observed values to produce the final likelihood.
</p>
<p>If we repeat the likelihood calculation with another set of values for a and b, we can compare the two likelihood values. The values that produce the higher likelihood value are better. The values that produce the best likelihood possible are the maximum likelihood estimates for those parameters.
</p>
<p><strong>Details</strong>
</p>
<p>For eqni = 1... N independent observations in a vector <var>X</var>, with individual observations <code class="reqn">x_i</code>, and a set of parameter values <code class="reqn">\theta</code>:
</p>
<p style="text-align: center;"><code class="reqn">Likelihood=L(\theta|X)=\prod_{i=1}^{N}g(x_i|\theta)</code>
</p>
 
<p>where <code class="reqn">L(\theta | X)</code> is the likelihood of the set of parameters <code class="reqn">\theta</code> given the observations <var>X</var>, and <code class="reqn">g(x_i|\theta)</code> is the probability density function of the probability model (i.e. the probability of each observation, given the parameters). Because logarithms are easier to work with, the preferred value is log likelihood, calculated as:
</p>
<p style="text-align: center;"><code class="reqn">Log likelihood=ln[L(\theta|X)] = \sum_{i=1}^{N}ln[g(x_i|\theta)]</code>
</p>

<p>Thus to calculate likelihood, we use the parameter values and the scientific model to calculate a set of predicted values for each of the observed values in the dataset. Then we use the probability density function to calculate the natural log of the probability of each pair of predicted and observed values. Then we sum the result over all observations in the dataset. For each data point, the mean of the probability density function is the observed value. The point for which the probability is being calculated, given that mean (generally called &ldquo;x&rdquo; in R's PDFs), is the predicted value.
</p>

<hr>
<h2 id='predicted_results'>Calculate Model Predicted Results</h2><span id='topic+predicted_results'></span>

<h3>Description</h3>

<p>Calculate predicted results of the dependent variable from a model with 
parameters set up as for the <code><a href="#topic+likeli">likeli</a></code> and <code><a href="#topic+anneal">anneal</a></code>
functions. These predicted results are useful for various statistical
calculations when compared to observed results from a dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predicted_results(model, par, var, source_data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predicted_results_+3A_model">model</code></td>
<td>
<p>Model function to use to calculate predicted results.</p>
</td></tr>
<tr><td><code id="predicted_results_+3A_par">par</code></td>
<td>
<p>List of parameters for which likelihood is being estimated.
All elements in <code>par</code> must be numeric vectors.</p>
</td></tr>
<tr><td><code id="predicted_results_+3A_var">var</code></td>
<td>
<p>List object with the source for all other non-parameter arguments
and data used by <code>model</code>, <code>pdf</code>, or any sub-functions.</p>
</td></tr>
<tr><td><code id="predicted_results_+3A_source_data">source_data</code></td>
<td>
<p>Data frame containing any needed source data.</p>
</td></tr>
<tr><td><code id="predicted_results_+3A_...">...</code></td>
<td>
<p>Any other data that may be needed by the model or any of its
sub-functions.  This is an alternative to providing the data in <code>var</code>;
however, passing values in <code>var</code> is strongly recommended.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters for this function are set up exactly as they are in
<code><a href="#topic+anneal">anneal</a></code> and <code><a href="#topic+likeli">likeli</a></code>.  See those pages for details
on how to do this.
</p>
<p>Extra list members in <code>var</code> are ignored, so if
you have set up a <code>var</code> list for use with <code><a href="#topic+likeli">likeli</a></code> or
<code><a href="#topic+anneal">anneal</a></code>, you can use that list with <code>predicted_results</code>
without removing arguments for the PDF.
</p>


<h3>Value</h3>

<p>A vector of predicted results, one for each observation in
<code>source_data</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use the included crown_rad dataset
data( crown_rad )

## Create our model function - crown radius is a linear function of DBH.
## DBH is a column of data from the crown_rad dataset; a and b are single
## parameter values.
model &lt;- function (a, b, DBH) {a + b * DBH}

## Create our parameters list and set values for a and b
par &lt;- list(a = 1.12, b = 0.07)

## Create a place to put all the other data needed by
## the model and PDF, and indicate that DBH comes from 
## the column marked "DBH" in the dataset
var &lt;- list(DBH = "DBH")

predicted &lt;- predicted_results(model, par, var, crown_rad)

## Calculate R2 - proportion of variance explained by the model relative to 
## that explained by the simple mean of the data
meanrad &lt;- mean(crown_rad$Radius)
sse &lt;- (crown_rad$Radius - predicted)^2
sst &lt;- (crown_rad$Radius - meanrad)^2
R2 &lt;- 1 - (sum(sse)/sum(sst))
</code></pre>

<hr>
<h2 id='Simulated+20Annealing+20Algorithm'>Details on the Simulated Annealing Algorithm</h2><span id='topic+Simulated+20Annealing+20Algorithm'></span>

<h3>Description</h3>

<p>This gives details on how the simulated annealing process is performed.</p>


<h3>Details</h3>

<p>When you are using likelihood methods to select the best parameter values for a scientific model, you need a method for searching the space of all possible values to find the global maximum likelihood. There are several search algorithms, and many R implementations of them. The simulated annealing algorithm is a good choice for maximizing likelihood for two reasons. The likelihood function is difficult to analyze using mathematical methods, such as derivation. Also, it often has a complex topology in parameter space, with local maxima, cliffs, ridges, and holes where it is undefined. Simulated annealing is an algorithm designed to deal with these problems. The algorithm of course can be applied to all kinds of problems, but its implementation in this package is for analyzing the likelihood function only.
</p>
<p>An analogy for the search process is walking a mountain range in the dark, trying to find the highest mountain. In the beginning, when the algorithm's &ldquo;temperature&rdquo; is high, the search is energetic. In addition to moving uphill, it will also regularly move downhill to try to find a better uphill path. It will also jump off the mountain it's currently on to see if it lands on another, higher mountain. Later in the search, when the temperature and energy are lower, the algorithm works on reaching the top of the best mountain it has found. It may still move downhill to try to find a better path to the top but this becomes less and less likely. 
</p>
<p>The search (hopefully) ends with the algorithm converging on the global maximum. This may happen quickly or may take a very long time. The algorithm cannot know when it has found the global maximum, so it continues searching until it reaches a predefined end point, and leaves it up to you to judge the result. The set of search controls is called the annealing schedule, and defines the search's initial conditions, its rate of energy drop, and its end point. You can change this schedule to maximize the probability of convergence with the minimum amount of computation time.
</p>
<p>You begin an annealing run by setting up the annealing schedule and the parameter search space. For the annealing schedule, you provide: 
</p>

<ul>
<li><p>Initial temperature (<var>t</var>). The higher the temperature, the more energetic the search.
</p>
</li>
<li><p>Rate of reduction in temperature (<var>rt</var>). This controls how quickly the temperature falls throughout the run.
</p>
</li>
<li><p>Rate of drops in temperature (<var>nt</var>). This controls how long the search stays at a certain temperature before further cooling.
</p>
</li>
<li><p>Interval between changes in range (<var>ns</var>). This controls how often the annealing process adjusts the parameter search range.
</p>
</li>
<li><p>An end point to the search. This is generally a maximum number of search iterations.
</p>
</li></ul>

<p>For the parameters, you provide:
</p>

<ul>
<li><p>Initial values. The values whose likelihood is the point where the search starts. 
</p>
</li>
<li><p>Upper and lower bounds. If desired or mathematically necessary. The annealing can also conduct a global search on one or more parameters.
</p>
</li></ul>

<p>Simulated annealing searches by randomly varying one parameter value, keeping all the other parameter values the same, and calculating the new likelihood. It compares this value to the last likelihood calculated to decide whether to keep the new parameter value or discard it. It then repeats this process by randomly varying the next parameter in the set. When each parameter has been varied one time, that is one search iteration. Simulated annealing then starts over with the first parameter again, beginning a new iteration.
</p>
<p>The latest set of parameter values represents the point in the search space where the algorithm is on its current path. The algorithm also keeps a copy of the values that produced the highest likelihood yet found, so it can go back to that point.
</p>
<p>Each time simulated annealing picks a new parameter value to test, it must decide whether to accept or reject the change. First, it compares the new parameter's likelihood value to the likelihood before the change. If the new value is equal to or greater than the previous value, the change in the parameter is accepted and the algorithm takes a step uphill. It then checks to see if it's at a new overall high point in the search. If so, it saves this set of parameter values as its best yet.
</p>
<p>If the new parameter value's likelihood is worse than the previous one (representing a step downhill), simulated annealing uses the Metropolis criterion to decide whether or not to accept the move. The criterion is:
</p>
<p style="text-align: center;"><code class="reqn">p = e^{-\frac{L1 - L2}{t}}</code>
</p>

<p>where <var>p</var> is the probability the move will be accepted, <var>L1</var> is the previous likelihood, <var>L2</var> is the new likelihood, and <var>T</var> is the current annealing temperature. The algorithm compares a random number to this probability. If the move is accepted, the algorithm steps downhill. If the move is rejected, the new parameter value is discarded and the search stays in the same place, to try a step in a different direction with the next parameter.
</p>
<p>The parameter values are randomly chosen within a range. The search begins with any defined upper and lower bounds, or infinity if there are none. Every <var>ns</var> iterations (where <var>ns</var> is the interval between changes in range in the initial annealing schedule), simulated annealing adjusts its search bounds for each parameter so that 50% of all moves will be accepted, either enlarging the bounds to find new ground to search or shrinking them to narrow in on a maximum. 
</p>
<p>After <var>ns</var> * <var>nt</var> iterations, the temperature <var>T</var> drops as 
</p>
<p style="text-align: center;"><code class="reqn">T'= rt * T</code>
</p>

<p>where <var>rt</var> is the rate of temperature reduction given in the initial annealing schedule.
</p>
<p>The search ends when simulated annealing has reached the end point defined in its annealing schedule; either a maximum number of iterations, or a failure to find a higher likelihood within a set amount of temperature drop. The search may end before the global maximum has been reached.
</p>
<p><strong>Using the algorithm</strong>
</p>
<p>You set up the annealing schedule and search bounds to maximize the probability of convergence on the global maximum while minimizing the computation time. Unfortunately, there are no firm rules for establishing that convergence has occurred. You can conclude that the algorithm has not converged if the maximum likelihood is still trending upwards when the run ends. If the maximum likelihood is stable for many iterations, this is evidence for convergence. Better evidence is multiple runs finding approximately the same maximum likelihood.
</p>
<p>If an annealing run has not converged by the time it finishes, you can change the annealing schedule to improve the chances of convergence on a subsequent run. If the likelihood is changing at a rapid rate when the run finishes, give it more time by increasing the maximum iterations, and possibly increasing <var>ns</var> and <var>nt</var> as well. You can also begin subsequent runs by setting the parameter initial values to the best values found in the previous run, to allow it to continue searching where it left off.
</p>
<p>If the maximum likelihood value does not change much throughout the run, but the maximum likelihood estimates for the parameters are not very good and you suspect that better values exist but were not found, it's possible the run was not effectively searching the parameter space. Try increasing the parameter bounds and the initial temperature to start a more energetic search.
</p>
<p><strong>Other information calculated</strong>
</p>
<p>The simulated annealing algorithm returns many pieces of information to allow evaluation of the maximum likelihood estimates and comparison between models.
</p>
<p><b>Akaike's Information Criterion.</b> Akaike's Information Criterion is a measure of how well a model approximates reality. Its most common use is to compare models (based on the same dataset) that differ in their number of parameters.  Models with more parameters will generally have higher likelihood, and AIC provides a means to incorporate principles of parsimony in model comparison.
</p>
<p>AIC is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">AIC = -2 ln(L(\theta | y)) + 2K</code>
</p>

<p>where <code class="reqn">ln(L(\theta|y))</code> is the log likelihood and <var>K</var> is the number of model parameters.
</p>
<p>Unless the sample size is large relative to the number of model parameters, AIC corrected for small sample size (AICc) is recommended as an alternative. This is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">AIC_{c} = -2ln(L(\theta|y))+2K(\frac{n}{n-K-1})</code>
</p>

<p>where <var>n</var> = dataset size.
</p>
<p><b>Slope</b>. Slope is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">slope=\frac{\sum_{i=1}^{N}(obs_i)(exp_i)}{\sum_{i=1}^{N}exp_i^2}</code>
</p>

<p>where <code class="reqn">exp_i</code> is the expected value of observation i in the dataset (<code class="reqn">obs_i</code>) given the model.
</p>
<p><b>R2.</b>  <code class="reqn">R^2</code> (different from <code class="reqn">r^2</code>) is the proportion of variance explained by the model relative to that explained by the simple mean of the data. It is not bounded between 0 and 1. It is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">R^2 = 1-\frac{SSE}{SST} = 1 - \frac{\sum_{i=1}^{N}(obs_{i}-exp_{i})^2}{\sum_{i=1}^{N}(obs_{i}-\overline{obs})^2}</code>
</p>

<p>where <code class="reqn">exp_i</code> is the expected value of observation i in the dataset (<code class="reqn">obs_i</code>) given the model, and <code class="reqn">\overline{obs_i}</code> is the mean of the observations.
</p>
<p><b>Support limits.</b> Support limits help you evaluate the strength of support for each parameter's maximum likelihood estimate. For details on how support limits are calculated, see the help page for the <code><a href="#topic+support_limits">support_limits</a></code> function.
</p>
<p><b>Standard errors, variance and covariance.</b> Standard errors are calculated using the Hessian matrix, which is a matrix of numerical approximations of the second partial derivatives of the likelihood function with respect to parameters, evaluated at the maximum likelihood estimates. Inverting the negative of the Hessian matrix gives the parameter variance-covariance matrix. The square roots of the diagonals of the variance-covariance matrix are the parameter standard errors.
</p>


<h3>References</h3>

<p>Goffe, W.L., G.D. Ferrier, and J. Rogers. 1994.  Global optimization of
statistical functions with simulated annealing.  Journal of Econometrics
60:65-99.
</p>

<hr>
<h2 id='support_limits'>Calculate Support Limits</h2><span id='topic+support_limits'></span>

<h3>Description</h3>

<p>Calculates asymptotic support limits for parameter maximum likelihood estimates. For a parameter, support limits are the values above and below the maximum likelihood estimate that cause the likelihood to drop by a given number of units, while holding all other parameters at their maximum likelihood values. Two units is standard. 1.92 units roughly corresponds to a 95% confidence interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>support_limits(model, par, var, source_data, pdf, par_lo = NULL, 
par_hi = NULL, delta = 100, slimit = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="support_limits_+3A_model">model</code></td>
<td>
<p>Model function for which to calculate likelihood.  This is the
same as the argument that you pass to <code><a href="#topic+anneal">anneal</a></code> or
<code><a href="#topic+likeli">likeli</a></code>.</p>
</td></tr>
<tr><td><code id="support_limits_+3A_par">par</code></td>
<td>
<p>List of parameters for which to find the support limits. The name of
each component in <code>par</code> matches the name of an argument in one of the
functions passed to <code>support_limits</code> (either <code>model</code>, <code>pdf</code>,
or another function that does initial calculations).  The value of each
component is the maximum likelihood estimate. All components in <code>par</code>
must be numeric vectors.  Vectors of length greater than one get a set of
support limits calculated separately for each vector value. This is the same
as the argument that you pass to <code><a href="#topic+anneal">anneal</a></code> or
<code><a href="#topic+likeli">likeli</a></code>.</p>
</td></tr>
<tr><td><code id="support_limits_+3A_var">var</code></td>
<td>
<p>List object with the source for all other arguments and data used by
<code>model</code>, <code>pdf</code>, and any other functions. This is the same as
the argument that you pass to <code><a href="#topic+anneal">anneal</a></code> or <code><a href="#topic+likeli">likeli</a></code>.</p>
</td></tr>
<tr><td><code id="support_limits_+3A_source_data">source_data</code></td>
<td>
<p>Data frame containing any needed source data. This is the
same as the argument that you pass to <code><a href="#topic+anneal">anneal</a></code> or
<code><a href="#topic+likeli">likeli</a></code>.</p>
</td></tr>
<tr><td><code id="support_limits_+3A_pdf">pdf</code></td>
<td>
<p>Probability density function to use in likelihood calculations. This
is the same as the argument that you pass to <code><a href="#topic+anneal">anneal</a></code> or
<code><a href="#topic+likeli">likeli</a></code>.</p>
</td></tr>
<tr><td><code id="support_limits_+3A_par_lo">par_lo</code></td>
<td>
<p>List object with lower bounds for the support limit search. The
support limit bounds are in general the same as the simulated annealing
search bounds. The list component names and sizes should each match a component in <code>par</code>. Any individual component (up to and including the entire <code>par_lo</code> argument) is optional. For any component of <code>par</code> that is omitted, the lower search bound for that parameter is assumed to be negative infinity. (Infinity isn't quite infinity - see details section for more.) This is the same as the argument that you pass to <code><a href="#topic+anneal">anneal</a></code>.</p>
</td></tr>
<tr><td><code id="support_limits_+3A_par_hi">par_hi</code></td>
<td>
<p>List object with upper bounds for the support limit search. The
support limit bounds are in general the same as the simulated annealing
search bounds. The list component names and sizes should each match a component in <code>par</code>. Any individual component (up to and including the entire <code>par_hi</code> argument) is optional. For any component of <code>par</code> that is omitted, the lower search bound for that parameter is assumed to be infinity. (Infinity isn't quite infinity - see details section for more.) This is the same as the argument that you pass to <code><a href="#topic+anneal">anneal</a></code>.</p>
</td></tr>
<tr><td><code id="support_limits_+3A_delta">delta</code></td>
<td>
<p>Controls the fineness of the search for support limits.  Each
parameter is divided by this number to arrive at a step size used for
&ldquo;walking&rdquo; the likelihood function.  Bigger numbers mean a finer
search.  See details for more on how the support limits are determined.</p>
</td></tr>
<tr><td><code id="support_limits_+3A_slimit">slimit</code></td>
<td>
<p>The number of units of likelihood that define the support limits.
If <code>slimit</code> is 2, then the limits are those values that cause the 
likelihood to drop by 2 on either side of the parameter maximum likelihood
estimate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Support limits are the values on either side of a parameter's maximum 
likelihood estimate that make the likelihood drop by <code>slimit</code> units, 
holding all other parameters at their maximum likelihood estimate value.  Of
course, support limits are only meaningful if the values in <code>par</code> are
indeed maximum likelihood estimates.  The distance from the maximum 
likelihood estimate of a parameter to its support limits is an indication of
the &ldquo;pointiness&rdquo; of the maximum on the likelihood surface.
</p>
<p>The algorithm produces support limits for a parameter by holding all other
values at their maximum likelihood value and &ldquo;walking&rdquo; the likelihood
function in the plane of that parameter, seeking to find the first spot that
is <code>slimit</code> units below the peak likelihood.  It starts by walking in
big steps, then in progressively smaller steps, until it reaches that point.
The smallest step it takes is found by dividing the parameter value by
<code>delta</code>. This controls the overall fineness of the search.
</p>
<p>The support limits search is bounded by the values in <code>par_lo</code> and
<code>par_hi</code>.  The search uses these bounds to control how it searches.  
This means that different bounds values may produce slightly different 
results.  If a bounds value is omitted, <code>support_limits</code> will attempt 
an unbounded search, up to infinity.  This will work fine as long as the
likelihood surface is not completely flat.  In practice, &ldquo;infinity&rdquo;
means the largest and smallest values the computer can work with.  To find
out what the actual limits are on your computer, use
<code>.Machine$double.xmax</code>.
</p>
<p>This algorithm works best if the surface produced by the likelihood function
is continuous and monotonic from the maximum likelihood value out to the
support limits of all parameters.  This is often not true. However, in most
cases, this will produce reasonably good results with a low amount of total
computation time.
</p>
<p>Support limits are calculated automatically at the end of an
<code><a href="#topic+anneal">anneal</a></code> run.
</p>


<h3>Value</h3>

<p>A list object with two components:  &ldquo;<code>upper_limits</code>&rdquo; and
&ldquo;<code>lower_limits</code>&rdquo;.  <code>upper_limits</code> has the upper support
limits for each member in <code>par</code>, with the maximum possible value being
that parameter's value in <code>par_hi</code>; <code>lower_limits</code> has the lower
support limits, with the minimum possible value being that parameter's value
in <code>par_lo</code>.
</p>
<p>If the likelihood calculated from <code>par</code> is infinite or NA, then the support
limits will also be NA.
</p>


<h3>Note</h3>

<p>The parameter maximum likelihood estimates found by <code><a href="#topic+anneal">anneal</a></code>
are in the list component called <code>best_pars</code>.  These are the values to
pass to <code>support_limits</code> for the <code>par</code> argument.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+likeli">likeli</a></code>,
<code><a href="#topic+anneal">anneal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#################
## Set up for an annealing run
#################
## Use the included crown_rad dataset
data(crown_rad)

## Create our model function - crown radius is a linear function of DBH.
## DBH is a column of data from the crown_rad dataset; a and b are single
## parameter values.
model &lt;- function (a, b, DBH) {a + b * DBH}

## Create our parameters list and set values for a and b, and indicate
## that DBH comes from the column marked "DBH" in the crown_rad dataset
par &lt;- list(a = 1.12, b = 0.07)
var &lt;- list(DBH = "DBH")

## We'll use the normal probability density function dnorm - add its
## arguments to our parameter list

## "x" value in PDF is observed value
var$x &lt;- "Radius"

## The mean is the predicted value, the outcome of the model statement. Use
## the reserved word "predicted"
var$mean &lt;- "predicted"
var$sd &lt;- 0.815585

## Set bounds within which to search for parameters
par_lo &lt;- list(a = 0, b = 0)
par_hi &lt;- list(a = 50, b = 50)

## Have dnorm calculate log likelihood
var$log &lt;- TRUE

## Not run: 
results &lt;- anneal(model, par, var, crown_rad, par_lo, par_hi, dnorm, "Radius", max_iter=20000)

## End(Not run)

##################
## Do support limits - even though there are a set already in results
##################

## Not run: 
limits &lt;- support_limits(model, results$best_pars, var, crown_rad, dnorm, par_lo, par_hi)

## End(Not run)
</code></pre>

<hr>
<h2 id='write_results'>Write the Results of Simulated Annealing to File</h2><span id='topic+write_results'></span>

<h3>Description</h3>

<p>Takes the results produced by the function <code><a href="#topic+anneal">anneal</a></code> and
writes them to a tab-delimited text file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_results(results, filename, data = TRUE, print_whole_hist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_results_+3A_results">results</code></td>
<td>
<p>The output list produced by the function 
<code><a href="#topic+anneal">anneal</a></code>.</p>
</td></tr>
<tr><td><code id="write_results_+3A_filename">filename</code></td>
<td>
<p>A string with the file and path to the file you wish to write.
This will overwrite any existing files of that name.  This will not add any
file extensions so remember to put on the appropriate one.</p>
</td></tr> 
<tr><td><code id="write_results_+3A_data">data</code></td>
<td>
<p>If TRUE, the <code>source_dataset</code> member of <code>results</code> is 
written to the file; if FALSE, it is not. Large datasets can inflate the
size of output files.</p>
</td></tr>
<tr><td><code id="write_results_+3A_print_whole_hist">print_whole_hist</code></td>
<td>
<p>If TRUE, the entire likelihood history of the run is printed; if FALSE, it is not. Long runs can have rather long histories.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A file with the contents of <code>results</code> written as tab-delimited text.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anneal">anneal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Assuming you have performed a simulated annealing run and placed the 
## results in an object called "my_results"...
## Not run: write_results(my_results, "c:\results.txt")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
