<!DOCTYPE html><html><head><title>Help for package gmmsslm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gmmsslm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bayesclassifier'><p>Bayes' rule of allocation</p></a></li>
<li><a href='#bootstrap_gmmsslm'><p>Bootstrap Analysis for gmmsslm</p></a></li>
<li><a href='#cov2vec'><p>Transform a variance matrix into a vector</p></a></li>
<li><a href='#discriminant_beta'><p>Discriminant function</p></a></li>
<li><a href='#erate'><p>Error rate of the Bayes rule for a g-class Gaussian mixture model</p></a></li>
<li><a href='#errorrate'><p>Error rate of the Bayes rule for two-class Gaussian homoscedastic model</p></a></li>
<li><a href='#gastro_data'><p>Gastrointestinal dataset</p></a></li>
<li><a href='#get_clusterprobs'><p>Posterior probability</p></a></li>
<li><a href='#get_entropy'><p>Shannon entropy</p></a></li>
<li><a href='#gmmsslm'><p>Fitting Gaussian mixture model to a complete classified dataset or an incomplete classified dataset with/without the missing-data mechanism.</p></a></li>
<li><a href='#gmmsslmFit-class'><p>gmmsslmFit Class</p></a></li>
<li><a href='#initialvalue'><p>Initial values for ECM</p></a></li>
<li><a href='#list2par'><p>Transfer a list into a vector</p></a></li>
<li><a href='#loglk_full'><p>Full log-likelihood function</p></a></li>
<li><a href='#loglk_ig'><p>Log likelihood for partially classified data with ingoring the missing mechanism</p></a></li>
<li><a href='#loglk_miss'><p>Log likelihood function formed on the basis of the missing-label indicator</p></a></li>
<li><a href='#logsumexp'><p>log summation of exponential function</p></a></li>
<li><a href='#makelabelmatrix'><p>Label matrix</p></a></li>
<li><a href='#neg_objective_function'><p>Negative objective function for gmmssl</p></a></li>
<li><a href='#normalise_logprob'><p>Normalize log-probability</p></a></li>
<li><a href='#par2list'><p>Transfer a vector into a list</p></a></li>
<li><a href='#paraextract'><p>Extract parameter list from gmmsslmFit objects</p></a></li>
<li><a href='#plot_missingness'><p>Plot Missingness Mechanism and Boxplot</p></a></li>
<li><a href='#predict'><p>Predict unclassified label</p></a></li>
<li><a href='#pro2vec'><p>Transfer a probability vector into a vector</p></a></li>
<li><a href='#rlabel'><p>Generation of a missing-data indicator</p></a></li>
<li><a href='#rmix'><p>Normal mixture model generator.</p></a></li>
<li><a href='#summary'><p>Summary method for gmmsslmFit objects</p></a></li>
<li><a href='#vec2cov'><p>Transform a vector into a matrix</p></a></li>
<li><a href='#vec2pro'><p>Transfer an informative vector to a probability vector</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Semi-Supervised Gaussian Mixture Model with a Missing-Data
Mechanism</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.5</td>
</tr>
<tr>
<td>Description:</td>
<td>The algorithm of semi-supervised learning is based on finite Gaussian mixture models and includes a mechanism for handling missing data. It aims to fit a g-class Gaussian mixture model using maximum likelihood. The algorithm treats the labels of unclassified features as missing data, building on the framework introduced by Rubin (1976) &lt;<a href="https://doi.org/10.2307%2F2335739">doi:10.2307/2335739</a>&gt; for missing data analysis. By taking into account the dependencies in the missing pattern, the algorithm provides more information for determining the optimal classifier, as specified by Bayes' rule.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0), mvtnorm,stats,methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-16 04:00:07 UTC; lyu</td>
</tr>
<tr>
<td>Author:</td>
<td>Ziyang Lyu [aut, cre],
  Daniel Ahfock [aut],
  Ryan Thompson [aut],
  Geoffrey J. McLachlan [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ziyang Lyu &lt;ziyang.lyu@unsw.edu.au&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-16 04:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='bayesclassifier'>Bayes' rule of allocation</h2><span id='topic+bayesclassifier'></span>

<h3>Description</h3>

<p>Bayes' rule of allocation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayesclassifier(dat, p, g, pi = NULL, mu = NULL, sigma = NULL, paralist = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayesclassifier_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation.</p>
</td></tr>
<tr><td><code id="bayesclassifier_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="bayesclassifier_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="bayesclassifier_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="bayesclassifier_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="bayesclassifier_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
<tr><td><code id="bayesclassifier_+3A_paralist">paralist</code></td>
<td>
<p>A list containing the required parameters <code class="reqn">(\pi, \mu, \Sigma)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Classifier specified by Bayes' rule
</p>
<p>The classifier/Bayes rule of allocation <code class="reqn">R(y_j;\theta)</code> assigns an entity with observation <code class="reqn">y_j</code> to  class <code class="reqn">C_k </code>(that is, <code class="reqn">R(y_j;\theta)=k</code>) if
<code class="reqn">	k=\arg\max_i \tau_i(y_j;\theta),</code>
</p>


<h3>Value</h3>

<table>
<tr><td><code>clust</code></td>
<td>
<p>Class membership for the ith entity</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 150
pi &lt;- c(0.25, 0.25, 0.25, 0.25)
sigma &lt;- array(0, dim = c(3, 3, 4))
sigma[, , 1] &lt;- diag(1, 3)
sigma[, , 2] &lt;- diag(2, 3)
sigma[, , 3] &lt;- diag(3, 3)
sigma[, , 4] &lt;- diag(4, 3)
mu &lt;- matrix(c(0.2, 0.3, 0.4, 0.2, 0.7, 0.6, 0.1, 0.7, 1.6, 0.2, 1.7, 0.6), 3, 4)
dat &lt;- rmix(n = n, pi = pi, mu = mu, sigma = sigma)
params &lt;- list(pi=pi,mu = mu, sigma = sigma)
clust &lt;- bayesclassifier(dat=dat$Y,p=3,g=4,paralist=params)
</code></pre>

<hr>
<h2 id='bootstrap_gmmsslm'>Bootstrap Analysis for gmmsslm</h2><span id='topic+bootstrap_gmmsslm'></span>

<h3>Description</h3>

<p>This file provides functions to perform bootstrap analysis on the results of the gmmsslm function.
</p>
<p>This function performs non-parametric bootstrap to assess the variability of the gmmsslm function outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap_gmmsslm(
  dat,
  zm,
  pi,
  mu,
  sigma,
  paralist,
  xi,
  type,
  iter.max = 500,
  eval.max = 500,
  rel.tol = 1e-15,
  sing.tol = 1e-15,
  B = 2000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootstrap_gmmsslm_+3A_dat">dat</code></td>
<td>
<p>A matrix where each row represents an individual observation.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_zm">zm</code></td>
<td>
<p>A matrix or data frame of labels corresponding to dat.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_pi">pi</code></td>
<td>
<p>A numeric vector representing the mixing proportions.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_mu">mu</code></td>
<td>
<p>A matrix representing the location parameters.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_sigma">sigma</code></td>
<td>
<p>An array representing the covariance matrix or list of covariance matrices.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_paralist">paralist</code></td>
<td>
<p>A list of parameters.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_xi">xi</code></td>
<td>
<p>A numeric value representing the coefficient for a logistic function of the Shannon entropy.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_type">type</code></td>
<td>
<p>A character value indicating the type of Gaussian mixture model.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_iter.max">iter.max</code></td>
<td>
<p>An integer indicating the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_eval.max">eval.max</code></td>
<td>
<p>An integer indicating the maximum number of evaluations.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_rel.tol">rel.tol</code></td>
<td>
<p>A numeric value indicating the relative tolerance.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_sing.tol">sing.tol</code></td>
<td>
<p>A numeric value indicating the singularity tolerance.</p>
</td></tr>
<tr><td><code id="bootstrap_gmmsslm_+3A_b">B</code></td>
<td>
<p>An integer indicating the number of bootstrap samples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing mean and sd of bootstrap samples for pi, mu, sigma, and xi.
</p>

<hr>
<h2 id='cov2vec'>Transform a variance matrix into a vector</h2><span id='topic+cov2vec'></span>

<h3>Description</h3>

<p>Transform a variance matrix into a vector i.e., Sigma=R^T*R
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov2vec(sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cov2vec_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> variance matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance matrix is decomposed by computing the Choleski factorization of a real symmetric positive-definite square matrix.
Then, storing the upper triangular factor of the Choleski decomposition into a vector.
</p>


<h3>Value</h3>

<p>par A vector representing a variance matrix
</p>

<hr>
<h2 id='discriminant_beta'>Discriminant function</h2><span id='topic+discriminant_beta'></span>

<h3>Description</h3>

<p>Discriminant function in the particular case of g=2 classes with an equal-covariance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discriminant_beta(pi, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discriminant_beta_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="discriminant_beta_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="discriminant_beta_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Discriminant function in the particular case of g=2 classes with an equal-covariance matrix can be expressed
</p>
<p style="text-align: center;"><code class="reqn">d(y_i,\beta)=\beta_0+\beta_1 y_i,</code>
</p>

<p>where <code class="reqn">\beta_0=\log\frac{\pi_1}{\pi_2}-\frac{1}{2}\frac{\mu_1^2-\mu_2^2}{\sigma^2}</code> and <code class="reqn">\beta_1=\frac{\mu_1-\mu_2}{\sigma^2}</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>beta0</code></td>
<td>
<p>An intercept of discriminant function</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A coefficient of discriminant function</p>
</td></tr>
</table>

<hr>
<h2 id='erate'>Error rate of the Bayes rule for a g-class Gaussian mixture model</h2><span id='topic+erate'></span>

<h3>Description</h3>

<p>Error rate of the Bayes rule for a g-class Gaussian mixture model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>erate(dat, p, g, pi = NULL, mu = NULL, sigma = NULL, paralist = NULL, clust)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="erate_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="erate_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="erate_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="erate_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="erate_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="erate_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
<tr><td><code id="erate_+3A_paralist">paralist</code></td>
<td>
<p>A list containing the required parameters <code class="reqn">(\pi, \mu, \Sigma)</code>.</p>
</td></tr>
<tr><td><code id="erate_+3A_clust">clust</code></td>
<td>
<p>An n-dimensional vector of class partition.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The  error rate of the Bayes rule for a g-class Gaussian mixture model is given by
</p>
<p style="text-align: center;"><code class="reqn">
err(y;\theta)=1-\sum_{i=1}^g\pi_i Pr\{R(y;\theta)=i\mid Z \in C_i\}.
</code>
</p>

<p>Here, we write
</p>
<p style="text-align: center;"><code class="reqn">
Pr\{R(y;\theta) \in C_i\mid Z\in C_i\}=\frac{\sum_{j=1}^nI_{C_i}(z_j)Q[z_j,R(y;\theta) ]}{\sum_{j=1}^nI_{C_i}(z_j)},
</code>
</p>

<p>where <code class="reqn">Q[u,v]=1</code> if <code class="reqn">u=v</code> and <code class="reqn">Q[u,v]=0</code> otherwise, and <code class="reqn">I_{C_i}(z_j)</code> is an indicator function for the <code class="reqn">i</code>th class.
</p>


<h3>Value</h3>

<table>
<tr><td><code>errval</code></td>
<td>
<p>a value of error rate</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma)
xi&lt;-c(-0.5,1)
m&lt;-rlabel(dat=dat$Y,pi=pi,mu=mu,sigma=sigma,xi=xi)
zm&lt;-dat$clust
zm[m==1]&lt;-NA
inits&lt;-initialvalue(g=4,zm=zm,dat=dat$Y)

fit_pc&lt;-gmmsslm(dat=dat$Y,zm=zm,pi=inits$pi,mu=inits$mu,sigma=inits$sigma,xi=xi,type='full')
parlist&lt;-paraextract(fit_pc)
erate(dat=dat$Y,p=3,g=4,paralist=parlist,clust=dat$clust)


</code></pre>

<hr>
<h2 id='errorrate'>Error rate of the Bayes rule for two-class Gaussian homoscedastic model</h2><span id='topic+errorrate'></span>

<h3>Description</h3>

<p>The optimal error rate of Bayes rule for two-class Gaussian homoscedastic model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorrate(beta0, beta, pi, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="errorrate_+3A_beta0">beta0</code></td>
<td>
<p>An intercept parameter of the discriminant function coefficients.</p>
</td></tr>
<tr><td><code id="errorrate_+3A_beta">beta</code></td>
<td>
<p>A <code class="reqn">p \times 1</code> vector for the slope parameter of the discriminant function.</p>
</td></tr>
<tr><td><code id="errorrate_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="errorrate_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="errorrate_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimal error rate of Bayes rule for two-class Gaussian homoscedastic model can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
err(\beta)=\pi_1\phi\{-\frac{\beta_0+\beta_1^T\mu_1}{(\beta_1^T\Sigma\beta_1)^{\frac{1}{2}}}\}+\pi_2\phi\{\frac{\beta_0+\beta_1^T\mu_2}{(\beta_1^T\Sigma\beta_1)^{\frac{1}{2}}}\}
</code>
</p>

<p>where <code class="reqn">\phi</code> is a normal probability function with mean <code class="reqn">\mu_i</code> and covariance matrix <code class="reqn">\Sigma_i</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>errval</code></td>
<td>
<p>A vector of error rate.</p>
</td></tr>
</table>

<hr>
<h2 id='gastro_data'>Gastrointestinal dataset</h2><span id='topic+gastro_data'></span>

<h3>Description</h3>

<p>The collected dataset is composed of 76 colonoscopic videos (recorded with both White Light (WL) and Narrow Band Imaging (NBI)), the histology (classification ground truth), and  the endoscopist's opinion (including 4 experts and 3 beginners). There are $n=76$ observations, and each observation consists of 698 features extracted from colonoscopic videos on patients with gastrointestinal lesions.
</p>


<h3>References</h3>

<p><a href="http://www.depeca.uah.es/colonoscopy_dataset/">http://www.depeca.uah.es/colonoscopy_dataset/</a>
</p>

<hr>
<h2 id='get_clusterprobs'>Posterior probability</h2><span id='topic+get_clusterprobs'></span>

<h3>Description</h3>

<p>Get posterior probabilities of class membership
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_clusterprobs(
  dat,
  n,
  p,
  g,
  pi = NULL,
  mu = NULL,
  sigma = NULL,
  paralist = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_clusterprobs_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_paralist">paralist</code></td>
<td>
<p>A list containing the required parameters <code class="reqn">(\pi, \mu, \Sigma)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The posterior probability can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
\tau_i(y_j;\theta)=Prob\{z_{ij}=1|y_j\}=\frac{\pi_i\phi(y_j;\mu_i,\Sigma_i)}{\sum_{h=1}^g\pi_h\phi(y_j;\mu_h,\Sigma_h) },
</code>
</p>

<p>where <code class="reqn">\phi</code> is a normal probability function with mean <code class="reqn">\mu_i</code> and covariance matrix <code class="reqn">\Sigma_i</code>,
and <code class="reqn">z_{ij}</code> is is a zero-one indicator variable denoting the class of origin.
</p>


<h3>Value</h3>

<table>
<tr><td><code>clusprobs</code></td>
<td>
<p>Posterior probabilities of class membership for the ith entity</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma)
tau&lt;-get_clusterprobs(dat=dat$Y,n=150,p=3,g=4,mu=mu,sigma=sigma,pi=pi)
</code></pre>

<hr>
<h2 id='get_entropy'>Shannon entropy</h2><span id='topic+get_entropy'></span>

<h3>Description</h3>

<p>Shannon entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_entropy(dat, n, p, g, pi = NULL, mu = NULL, sigma = NULL, paralist = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_entropy_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_paralist">paralist</code></td>
<td>
<p>A list containing the required parameters <code class="reqn">(\pi, \mu, \Sigma)</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The concept of information entropy was introduced by <cite>shannon1948mathematical</cite>.
The entropy of <code class="reqn">y_j</code> is formally defined as
</p>
<p style="text-align: center;"><code class="reqn">e_j( y_j; \theta)=-\sum_{i=1}^g \tau_i( y_j; \theta) \log\tau_i(y_j;\theta).</code>
</p>



<h3>Value</h3>

<table>
<tr><td><code>clusprobs</code></td>
<td>
<p>The posterior probabilities of the i-th entity that belongs to the j-th group.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma)
en&lt;-get_entropy(dat=dat$Y,n=150,p=3,g=4,mu=mu,sigma=sigma,pi=pi)
</code></pre>

<hr>
<h2 id='gmmsslm'>Fitting Gaussian mixture model to a complete classified dataset or an incomplete classified dataset with/without the missing-data mechanism.</h2><span id='topic+gmmsslm'></span>

<h3>Description</h3>

<p>Fitting Gaussian mixture model to a complete classified dataset or an incomplete classified dataset with/without the missing-data mechanism.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmmsslm(
  dat,
  zm,
  pi = NULL,
  mu = NULL,
  sigma = NULL,
  paralist = NULL,
  xi = NULL,
  type,
  iter.max = 500,
  eval.max = 500,
  rel.tol = 1e-15,
  sing.tol = 1e-15
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmmsslm_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_paralist">paralist</code></td>
<td>
<p>A list containing the required parameters <code class="reqn">(\pi, \mu, \Sigma)</code>.</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional vector containing the initial values of the coefficients in the logistic function of the Shannon entropy.</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_type">type</code></td>
<td>
<p>Three types of Gaussian mixture models, 'ign' indicates fitting the model to a partially classified sample on the basis of the likelihood that ignores the missing label mechanism,
'full' indicates fitting the model to a partially classified sample on the basis of the full likelihood, taking into account the missing-label mechanism,
and 'com' indicate fitting the model to a completed classified sample.</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_iter.max">iter.max</code></td>
<td>
<p>Maximum number of iterations allowed. Defaults to 500</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_eval.max">eval.max</code></td>
<td>
<p>Maximum number of evaluations of the objective function allowed. Defaults to 500</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Relative tolerance. Defaults to 1e-15</p>
</td></tr>
<tr><td><code id="gmmsslm_+3A_sing.tol">sing.tol</code></td>
<td>
<p>Singular convergence tolerance; defaults to 1e-20.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A gmmsslmFit object containing the following slots:
</p>
<table>
<tr><td><code>objective</code></td>
<td>
<p>Value of objective likelihood</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Value of convergence</p>
</td></tr>
<tr><td><code>iteration</code></td>
<td>
<p>Number of iterations</p>
</td></tr>
<tr><td><code>obs</code></td>
<td>
<p>Input data matrix</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>Number of variables</p>
</td></tr>
<tr><td><code>g</code></td>
<td>
<p>Number of Gaussian components</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Type of Gaussian mixture model</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>Estimated vector of the mixing proportions</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>Estimated matrix of the location parameters</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Estimated covariance matrix or list of covariance matrices</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>
<p>Estimated coefficient vector for a logistic function of the Shannon entropy</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma)
xi&lt;-c(-0.5,1)
m&lt;-rlabel(dat=dat$Y,pi=pi,mu=mu,sigma=sigma,xi=xi)
zm&lt;-dat$clust
zm[m==1]&lt;-NA
inits&lt;-initialvalue(g=4,zm=zm,dat=dat$Y)

fit_pc&lt;-gmmsslm(dat=dat$Y,zm=zm,paralist=inits,xi=xi,type='full')

</code></pre>

<hr>
<h2 id='gmmsslmFit-class'>gmmsslmFit Class</h2><span id='topic+gmmsslmFit-class'></span>

<h3>Description</h3>

<p>gmmsslmFit objects store the results of fitting Gaussian mixture models using the gmmsslm function.
</p>
<p>An S4 class representing the result of fitting a Gaussian mixture model using gmmsslm()
</p>


<h3>Slots</h3>


<dl>
<dt><code>objective</code></dt><dd><p>A numeric value representing the objective likelihood.</p>
</dd>
<dt><code>ncov</code></dt><dd><p>A numeric value representing the number of covariance matrices.</p>
</dd>
<dt><code>convergence</code></dt><dd><p>A numeric value representing the convergence value.</p>
</dd>
<dt><code>iteration</code></dt><dd><p>An integer value representing the number of iterations.</p>
</dd>
<dt><code>obs</code></dt><dd><p>A matrix containing the input data.</p>
</dd>
<dt><code>m</code></dt><dd><p>A logical vector representing label indicators.</p>
</dd>
<dt><code>n</code></dt><dd><p>An integer value representing the number of observations.</p>
</dd>
<dt><code>p</code></dt><dd><p>An integer value representing the number of variables.</p>
</dd>
<dt><code>g</code></dt><dd><p>An integer value representing the number of Gaussian components.</p>
</dd>
<dt><code>type</code></dt><dd><p>A character value representing the type of Gaussian mixture model.</p>
</dd>
<dt><code>pi</code></dt><dd><p>A numeric vector representing the mixing proportions.</p>
</dd>
<dt><code>mu</code></dt><dd><p>A matrix representing the location parameters.</p>
</dd>
<dt><code>sigma</code></dt><dd><p>An array representing the covariance matrix or list of covariance matrices.</p>
</dd>
<dt><code>xi</code></dt><dd><p>A numeric value representing the coefficient for a logistic function of the Shannon entropy.</p>
</dd>
</dl>


<h3>See Also</h3>

<p>gmmsslm
</p>

<hr>
<h2 id='initialvalue'>Initial values for ECM</h2><span id='topic+initialvalue'></span>

<h3>Description</h3>

<p>Inittial values for claculating the estimates based on solely on the classified features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initialvalue(dat, zm, g, ncov = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initialvalue_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="initialvalue_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="initialvalue_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="initialvalue_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>pi</code></td>
<td>
<p>A g-dimensional  initial vector of the mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A initial  <code class="reqn">p \times g</code> matrix of the location parameters.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma)
xi&lt;-c(-0.5,1)
m&lt;-rlabel(dat=dat$Y,pi=pi,mu=mu,sigma=sigma,xi=xi)
zm&lt;-dat$clust
zm[m==1]&lt;-NA
initlist&lt;-initialvalue(g=4,zm=zm,dat=dat$Y,ncov=2)

</code></pre>

<hr>
<h2 id='list2par'>Transfer a list into a vector</h2><span id='topic+list2par'></span>

<h3>Description</h3>

<p>Transfer a list into a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list2par(p, g, pi, mu, sigma, xi = NULL, type = c("ign", "full", "com"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="list2par_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="list2par_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="list2par_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="list2par_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="list2par_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
<tr><td><code id="list2par_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional vector containing the initial values of the coefficients in the logistic function of the Shannon entropy.</p>
</td></tr>
<tr><td><code id="list2par_+3A_type">type</code></td>
<td>
<p>Three types to fit to the model, 'ign' indicates fitting the model on the basis of the likelihood that ignores the missing label mechanism,
'full' indicates that the model to be fitted on the basis of the full likelihood, taking into account the missing-label mechanism,
and 'com' indicate that the model to be fitted to a completed classified sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>par</code></td>
<td>
<p>a vector including all list information</p>
</td></tr>
</table>

<hr>
<h2 id='loglk_full'>Full log-likelihood function</h2><span id='topic+loglk_full'></span>

<h3>Description</h3>

<p>Full log-likelihood function with both terms of ignoring and missing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglk_full(dat, zm, pi, mu, sigma, xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglk_full_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional vector containing the initial values of the coefficients in the logistic function of the Shannon entropy.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The full log-likelihood function can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
\log L_{PC}^{({full})}(\boldsymbol{\Psi})=\log L_{PC}^{({ig})}(\theta)+\log L_{PC}^{({miss})}(\theta,\boldsymbol{\xi}),</code>
</p>

<p>where<code class="reqn">\log L_{PC}^{({ig})}(\theta)</code>is the log likelihood function formed ignoring the missing in the label of the unclassified features,
and <code class="reqn">\log L_{PC}^{({miss})}(\theta,\boldsymbol{\xi})</code> is the log likelihood function formed on the basis of the missing-label indicator.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lk</code></td>
<td>
<p>Log-likelihood value</p>
</td></tr>
</table>

<hr>
<h2 id='loglk_ig'>Log likelihood for partially classified data with ingoring the missing mechanism</h2><span id='topic+loglk_ig'></span>

<h3>Description</h3>

<p>Log likelihood for partially classified data with ingoring the missing mechanism
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglk_ig(dat, zm, pi, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglk_ig_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-likelihood function for  partially classified data with ingoring the missing mechanism can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
 \log L_{PC}^{({ig})}(\theta)=\sum_{j=1}^n  \left[
(1-m_j)\sum_{i=1}^g z_{ij}\left\lbrace \log\pi_i+\log  f_i(y_j;\omega_i)\right\rbrace +m_j\log \left\lbrace  \sum_{i=1}^g\pi_i  f_i(y_j;\omega_i)\right\rbrace  \right],
 </code>
</p>

<p>where <code class="reqn">m_j</code> is a missing label indicator, <code class="reqn">z_{ij}</code> is a zero-one indicator variable defining the known group of origin of each,
and <code class="reqn">f_i(y_j;\omega_i)</code> is a probability density function with parameters <code class="reqn">\omega_i</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lk</code></td>
<td>
<p>Log-likelihood value.</p>
</td></tr>
</table>

<hr>
<h2 id='loglk_miss'>Log likelihood function formed on the basis of the missing-label indicator</h2><span id='topic+loglk_miss'></span>

<h3>Description</h3>

<p>Log likelihood for partially classified data based on the missing mechanism with the Shanon entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglk_miss(dat, zm, pi, mu, sigma, xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglk_miss_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional vector containing the initial values of the coefficients in the logistic function of the Shannon entropy.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-likelihood function  formed on the basis of the missing-label indicator can be expressed by
</p>
<p style="text-align: center;"><code class="reqn">
\log L_{PC}^{({miss})}(\theta,\boldsymbol{\xi})=\sum_{j=1}^n\big[ (1-m_j)\log\left\lbrace 1-q(y_j;\theta,\boldsymbol{\xi})\right\rbrace +m_j\log q(y_j;\theta,\boldsymbol{\xi})\big],
</code>
</p>

<p>where <code class="reqn">q(y_j;\theta,\boldsymbol{\xi})</code> is a logistic function of the Shannon entropy <code class="reqn">e_j(y_j;\theta)</code>,
and  <code class="reqn">m_j</code> is a missing label indicator.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lk</code></td>
<td>
<p>loglikelihood value</p>
</td></tr>
</table>

<hr>
<h2 id='logsumexp'>log summation of exponential function</h2><span id='topic+logsumexp'></span>

<h3>Description</h3>

<p>log summation of exponential variable vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logsumexp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logsumexp_+3A_x">x</code></td>
<td>
<p>A variable vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>val</code></td>
<td>
<p>log summation of exponential variable vector.</p>
</td></tr>
</table>

<hr>
<h2 id='makelabelmatrix'>Label matrix</h2><span id='topic+makelabelmatrix'></span>

<h3>Description</h3>

<p>Convert class indicator into a label maxtrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makelabelmatrix(clust)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makelabelmatrix_+3A_clust">clust</code></td>
<td>
<p>An n-dimensional vector of class partition.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Z</code></td>
<td>
<p> A matrix of class indicator.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>cluster&lt;-c(1,1,2,2,3,3)
label_maxtrix&lt;-makelabelmatrix(cluster)
</code></pre>

<hr>
<h2 id='neg_objective_function'>Negative objective function for gmmssl</h2><span id='topic+neg_objective_function'></span>

<h3>Description</h3>

<p>Negative objective function for gmmssl
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg_objective_function(
  dat,
  zm,
  g,
  par,
  ncov = 2,
  type = c("ign", "full", "com")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg_objective_function_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector of group partition including the missing-label, denoted as NA.</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_g">g</code></td>
<td>
<p>Number of multivariate Gaussian groups.</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_par">par</code></td>
<td>
<p>An informative vector including <code>mu</code>, <code>pi</code>,<code>sigma</code> and <code>xi</code>.</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_type">type</code></td>
<td>
<p>Three types to fit to the model, 'ign' indicates fitting the model on the basis of the likelihood that ignores the missing label mechanism,
'full' indicates that the model to be fitted on the basis of the full likelihood, taking into account the missing-label mechanism,
and 'com' indicate that the model to be fitted to a completed classified sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>val</code></td>
<td>
<p>Value of negatvie objective function.</p>
</td></tr>
</table>

<hr>
<h2 id='normalise_logprob'>Normalize log-probability</h2><span id='topic+normalise_logprob'></span>

<h3>Description</h3>

<p>Normalize log-probability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalise_logprob(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalise_logprob_+3A_x">x</code></td>
<td>
<p>A variable vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>val</code></td>
<td>
<p>A normalize log probability of variable vector.</p>
</td></tr>
</table>

<hr>
<h2 id='par2list'>Transfer a vector into a list</h2><span id='topic+par2list'></span>

<h3>Description</h3>

<p>Transfer a vector into a list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2list(par, g, p, ncov = 2, type = c("ign", "full", "com"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2list_+3A_par">par</code></td>
<td>
<p>A vector with list information.</p>
</td></tr>
<tr><td><code id="par2list_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="par2list_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="par2list_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix that <code>sigma</code> is a <code class="reqn">p\times p</code> matrix.
<code>ncov</code> = 2 for the unequal  covariance/scale matrices that
<code>sigma</code> represents a list of g matrices with dimension <code class="reqn">p\times p \times g</code>.</p>
</td></tr>
<tr><td><code id="par2list_+3A_type">type</code></td>
<td>
<p>Three types to fit to the model, 'ign' indicates fitting the model on the basis of the likelihood that ignores the missing label mechanism,
'full' indicates that the model to be fitted on the basis of the full likelihood, taking into account the missing-label mechanism,
and 'com' indicate that the model to be fitted to a completed classified sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parlist</code></td>
<td>
<p>Return a list including <code>mu</code>, <code>pi</code>, <code>sigma</code> and <code>xi</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='paraextract'>Extract parameter list from gmmsslmFit objects</h2><span id='topic+paraextract'></span><span id='topic+paraextract+2CgmmsslmFit-method'></span>

<h3>Description</h3>

<p>This function extracts the parameters from a gmmsslmFit object, including p, g, pi, mu, and sigma.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paraextract(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paraextract_+3A_object">object</code></td>
<td>
<p>A gmmsslmFit object.</p>
</td></tr>
</table>

<hr>
<h2 id='plot_missingness'>Plot Missingness Mechanism and Boxplot</h2><span id='topic+plot_missingness'></span>

<h3>Description</h3>

<p>This function plots the smoothed values of '-log(entropy)' against the missingness mechanism
and a boxplot of entropy for labeled vs. unlabeled observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_missingness(
  dat,
  g,
  parlist,
  zm,
  bandwidth = 5,
  range.x = c(0, 5),
  ylim = NULL,
  kernel = "normal"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_missingness_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="plot_missingness_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="plot_missingness_+3A_parlist">parlist</code></td>
<td>
<p>A list containing the required parameters <code class="reqn">(\pi, \mu, \Sigma)</code>.</p>
</td></tr>
<tr><td><code id="plot_missingness_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="plot_missingness_+3A_bandwidth">bandwidth</code></td>
<td>
<p>Bandwidth for kernel smoothing. Default is 5.</p>
</td></tr>
<tr><td><code id="plot_missingness_+3A_range.x">range.x</code></td>
<td>
<p>Range for x values. Default is c(0, 5).</p>
</td></tr>
<tr><td><code id="plot_missingness_+3A_ylim">ylim</code></td>
<td>
<p>The y-axis limits in the form of c(ylim[1], ylim[2]). Default is NULL.</p>
</td></tr>
<tr><td><code id="plot_missingness_+3A_kernel">kernel</code></td>
<td>
<p>Kernel type for smoothing. Default is 'normal'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot.
</p>

<hr>
<h2 id='predict'>Predict unclassified label</h2><span id='topic+predict'></span><span id='topic+predict+2CgmmsslmFit-method'></span>

<h3>Description</h3>

<p>This function predicts unclassified label from a gmmsslmFit object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>A gmmsslmFit object.</p>
</td></tr>
</table>

<hr>
<h2 id='pro2vec'>Transfer a probability vector into a vector</h2><span id='topic+pro2vec'></span>

<h3>Description</h3>

<p>Transfer a probability vector into an informative vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pro2vec(pro)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pro2vec_+3A_pro">pro</code></td>
<td>
<p>An propability vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>y An informative vector
</p>

<hr>
<h2 id='rlabel'>Generation of a missing-data indicator</h2><span id='topic+rlabel'></span>

<h3>Description</h3>

<p>Generate the missing label indicator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlabel(dat, pi, mu, sigma, xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rlabel_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional coefficient vector for a logistic function of the Shannon entropy.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>m</code></td>
<td>
<p>A n-dimensional vector of missing label indicator. The element of  outputs <code>m</code> represents its label indicator is missing if m equals 1, otherwise its label indicator is available if m equals to 0.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma)
xi&lt;-c(-0.5,1)
m&lt;-rlabel(dat=dat$Y,pi=pi,mu=mu,sigma=sigma,xi=xi)
</code></pre>

<hr>
<h2 id='rmix'>Normal mixture model generator.</h2><span id='topic+rmix'></span>

<h3>Description</h3>

<p>Generate random observations from the normal mixture distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmix(n, pi, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmix_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="rmix_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="rmix_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="rmix_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix,or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code>.
It is assumed to fit the model with a common covariance matrix if <code>sigma</code> is a <code class="reqn">p\times p</code> covariance matrix;
otherwise it is assumed to fit the model with unequal covariance matrices.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Y</code></td>
<td>
<p>An <code class="reqn">n\times p</code> numeric matrix with samples drawn in rows.</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p> An <code class="reqn">n\times g</code> numeric matrix; each row represents zero-one indicator variables defining the known class of origin of each.</p>
</td></tr>
<tr><td><code>clust</code></td>
<td>
<p>An n-dimensional vector of class partition.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma)
</code></pre>

<hr>
<h2 id='summary'>Summary method for gmmsslmFit objects</h2><span id='topic+summary'></span><span id='topic+summary+2CgmmsslmFit-method'></span>

<h3>Description</h3>

<p>This function extracts summary information from a gmmsslmFit object, including objective value, ncov, convergence, iteration, and type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>A gmmsslmFit object.</p>
</td></tr>
</table>

<hr>
<h2 id='vec2cov'>Transform a vector into a matrix</h2><span id='topic+vec2cov'></span>

<h3>Description</h3>

<p>Transform a vector into a matrix i.e., Sigma=R^T*R
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2cov(par)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2cov_+3A_par">par</code></td>
<td>
<p>A vector representing a variance matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance matrix is decomposed by computing the Choleski factorization of a real symmetric positive-definite square matrix.
Then, storing the upper triangular factor of the Choleski decomposition into a vector.
</p>


<h3>Value</h3>

<p>sigma A variance matrix
</p>

<hr>
<h2 id='vec2pro'>Transfer an informative vector to a probability vector</h2><span id='topic+vec2pro'></span>

<h3>Description</h3>

<p>Transfer an informative vector to a probability vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2pro(vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2pro_+3A_vec">vec</code></td>
<td>
<p>An informative vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>pro A probability vector
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
