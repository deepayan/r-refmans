<!DOCTYPE html><html lang="en"><head><title>Help for package emon</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {emon}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#emon-package'><p>Tools for environmental and ecological survey design and analysis</p></a></li>
<li><a href='#addnoise'><p>Creates random errors for use in power.trend.</p></a></li>
<li><a href='#detect'>
<p>Probability of circular patch detection</p></a></li>
<li><a href='#detect.prop'>
<p>Probability of detecting a feature that covers a proportion <code>theta</code> of the survey area.</p></a></li>
<li><a href='#expected.nb'>
<p>Expected value of Visual Fast Count Estimator assuming Negative Binomial distribution for counts</p></a></li>
<li><a href='#expected.pois'>
<p>Expected value of Visual Fast Count Estimator assuming Poisson distribution for counts</p></a></li>
<li><a href='#fS.detect'>
<p>Used in the function detect</p></a></li>
<li><a href='#fT.detect'>
<p>Used in function detect</p></a></li>
<li><a href='#generate.trend'>
<p>Generates a set of mean values.</p></a></li>
<li><a href='#GVFC'>
<p>Calculates the raw Visual Fast Count (VFC) estimator of the mean abundance per transect</p></a></li>
<li><a href='#GVFCMOM'><p>Function to calculate the method of moments visual fast count estimator</p></a></li>
<li><a href='#is.wholenumber'>
<p>To check whether an argument is an integer</p></a></li>
<li><a href='#mannkendall'><p> Mann-kendall test for trend</p></a></li>
<li><a href='#mannkendall.stat'>
<p>Mann-Kendall statistic.</p></a></li>
<li><a href='#mom.min.nb'><p>Minimising function for VFC MOM estimator assuming Negative Binomial counts.</p></a></li>
<li><a href='#mom.min.pois'><p>Minimising function for VFC MOM estimator assuming Poisson counts.</p></a></li>
<li><a href='#n.min'><p>Minimising function used in <code>precision</code>.</p></a></li>
<li><a href='#permute.BACI'>
<p>Does non-parametric randomisation test for the interaction term in a BACI design.</p></a></li>
<li><a href='#permute.groups'>
<p>Does randomisation test for the difference in means of two vectors <code>v1</code> and <code>v2</code>.</p></a></li>
<li><a href='#power.BACI'>
<p>Calculates power for a Before and After Control Impact (BACI) design.</p></a></li>
<li><a href='#power.groups'>
<p>Power for comparing mean of two groups</p></a></li>
<li><a href='#power.trend'><p> Calculates power by simulation to detect a specified trend.</p></a></li>
<li><a href='#precision'>
<p>Sample size for given precision or precision for given sample size</p></a></li>
<li><a href='#size2.samevar'>
<p>Calculates negative binomial size to preserve constant variance.</p></a></li>
<li><a href='#svariog'>
<p>Calculates empirical semi-variogram.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Environmental and Ecological Survey Design</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-03-03</td>
</tr>
<tr>
<td>Author:</td>
<td>Jon Barry and David Maxwell</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jon Barry &lt;jon.barry@cefas.co.uk&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>mgcv, MASS</td>
</tr>
<tr>
<td>Description:</td>
<td>Statistical tools for environmental and ecological surveys.
    Simulation-based power and precision analysis; detection probabilities from
    different survey designs; visual fast count estimation.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Repository/R-Forge/Project:</td>
<td>emon</td>
</tr>
<tr>
<td>Repository/R-Forge/Revision:</td>
<td>14</td>
</tr>
<tr>
<td>Repository/R-Forge/DateTimeStamp:</td>
<td>2017-03-09 11:39:30</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-03-09 14:50:09</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-03-09 11:45:22 UTC; rforge</td>
</tr>
</table>
<hr>
<h2 id='emon-package'>Tools for environmental and ecological survey design and analysis</h2><span id='topic+emon-package'></span><span id='topic+emon'></span>

<h3>Description</h3>

<p>This package gives seven tools for designing and analysing ecological and environmental surveys. The tools
are mainly
designed for marine  and benthic ecology applications, but they could easily be adopted for terrestrial
ecology. Three
of the tools give statistical power for specific survey designs (<code><a href="#topic+power.BACI">power.BACI</a></code>,
<code><a href="#topic+power.groups">power.groups</a></code> and
<code><a href="#topic+power.trend">power.trend</a></code>). The fourth tool (<code><a href="#topic+precision">precision</a></code>) calculates the sample size needed to achieve
specified precision
for estimating the mean of some desired statistic together with the precision obtained for given <code>n</code>.
</p>
<p>The other three tools are for more specialised applications. These are: the
generalised visual fast
count estimator for underwater video surveys (<code><a href="#topic+GVFCMOM">GVFCMOM</a></code>); an estimate of the empirical
semi-variogram for
examining spatial correlation between stations (<code><a href="#topic+svariog">svariog</a></code>); and detection
probability for three
spatial sampling designs (<code><a href="#topic+detect">detect</a></code> and <code><a href="#topic+detect.prop">detect.prop</a></code>).
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
    Package: </td><td style="text-align: left;"> emon</td>
</tr>
<tr>
 <td style="text-align: left;">
    Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
    Version: </td><td style="text-align: left;"> 1.3.2</td>
</tr>
<tr>
 <td style="text-align: left;">
    Date: </td><td style="text-align: left;"> 2017-03-03</td>
</tr>
<tr>
 <td style="text-align: left;">
    License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>The seven tools in this package are as follows:
</p>
<p>Power for BACI designs (<code><a href="#topic+power.BACI">power.BACI</a></code>, <code><a href="#topic+generate.trend">generate.trend</a></code>, <code><a href="#topic+addnoise">addnoise</a></code>,
<code><a href="#topic+mannkendall">mannkendall</a></code>, <code><a href="#topic+mannkendall.stat">mannkendall.stat</a></code>, <code><a href="#topic+permute.BACI">permute.BACI</a></code>).
</p>
<p>Power for comparing two groups (<code><a href="#topic+power.groups">power.groups</a></code>, <code><a href="#topic+permute.groups">permute.groups</a></code>,
<code><a href="#topic+size2.samevar">size2.samevar</a></code>).
</p>
<p>Power for detecting trends (<code><a href="#topic+power.trend">power.trend</a></code>, <code><a href="#topic+generate.trend">generate.trend</a></code>, <code><a href="#topic+addnoise">addnoise</a></code>).
</p>
<p>Precision for estimating a mean (<code><a href="#topic+precision">precision</a></code>).
</p>
<p>Sample sizes and probabilities for patch detection with different spatial sampling patterns
(<code><a href="#topic+detect">detect</a></code>, <code><a href="#topic+detect.prop">detect.prop</a></code>, <code><a href="#topic+fS.detect">fS.detect</a></code>, <code><a href="#topic+fT.detect">fT.detect</a></code>).
</p>
<p>Semi-variogram function for investigating spatial dependency (<code><a href="#topic+svariog">svariog</a></code>).
</p>
<p>Method of moments estimator for Generalised Visual Fast Count estimation for video surveys
(<code><a href="#topic+GVFCMOM">GVFCMOM</a></code>, <code><a href="#topic+GVFC">GVFC</a></code>, <code><a href="#topic+expected.pois">expected.pois</a></code>,
<code><a href="#topic+expected.nb">expected.nb</a></code>, <code><a href="#topic+mom.min.pois">mom.min.pois</a></code>, <code><a href="#topic+mom.min.nb">mom.min.nb</a></code>).
</p>
<p>The help functions for the individual functions describe the methods used. However, perhaps
the unique feature of
the power functions in <code>emon</code> is that the statistical power is calculated by simulation.
This has the disadvantage
of increased computing time; however, the advantage is that the power calculations does not rely
on the assumptions
behind many of the theoretical results. The simulation method also means that power can be
calculated for a range of
data distributions and for a variety of statistical tests that might be used to evaluate p-values.
</p>


<h3>Author(s)</h3>

<p>Jon Barry and David Maxwell
</p>
<p>Maintainer: Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+power.BACI">power.BACI</a></code>, <code><a href="#topic+power.groups">power.groups</a></code>, <code><a href="#topic+power.trend">power.trend</a></code>,
<code><a href="#topic+precision">precision</a></code>.
<code><a href="#topic+detect">detect</a></code>, <code><a href="#topic+svariog">svariog</a></code>, <code><a href="#topic+GVFCMOM">GVFCMOM</a></code></p>

<hr>
<h2 id='addnoise'>Creates random errors for use in power.trend.</h2><span id='topic+addnoise'></span>

<h3>Description</h3>

<p>This function is used within <code><a href="#topic+power.trend">power.trend</a></code>.
Distribution of noise can be either Normal, Poisson or Negative Binomial. The mean values are entered
as a parameter (possibly generated by function <code><a href="#topic+generate.trend">generate.trend</a></code>). Other parameters (<code>sd</code> for Normal,
<code>nbsize</code>
for Negative Binomial) need to be given. Values in <code>meanvalues</code> are used as the mean values for one of the three
specified distributions and then a random allocation is made for each of the <code>nobs</code> values, where <code>nobs</code> is the
length of <code>meanvalues</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addnoise(meanvalues, reps, distribution, sd, nbsize, randeffect, randeffect.sd) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addnoise_+3A_meanvalues">meanvalues</code></td>
<td>
<p> Vector of mean values</p>
</td></tr>
<tr><td><code id="addnoise_+3A_reps">reps</code></td>
<td>
<p>Number of replicates per time point</p>
</td></tr>
<tr><td><code id="addnoise_+3A_distribution">distribution</code></td>
<td>
<p> Character string which must be one of <code>Normal</code> (default), <code>Poisson</code> or <code>Negbin</code></p>
</td></tr> 
<tr><td><code id="addnoise_+3A_sd">sd</code></td>
<td>
<p> Standard Deviation for Normal distribution</p>
</td></tr>
<tr><td><code id="addnoise_+3A_nbsize">nbsize</code></td>
<td>
<p> Size parameter for Negative Binomial distribution</p>
</td></tr>
<tr><td><code id="addnoise_+3A_randeffect">randeffect</code></td>
<td>
<p>Not working yet</p>
</td></tr>
<tr><td><code id="addnoise_+3A_randeffect.sd">randeffect.sd</code></td>
<td>
<p>Not working yet</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output is a vector of the same length as <code>meanvalues</code>.
</p>


<h3>Author(s)</h3>

<p>David Maxwell: David.Maxwell@cefas.co.uk
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generate.trend">generate.trend</a></code>, <code><a href="#topic+power.trend">power.trend</a></code>
</p>

<hr>
<h2 id='detect'>
Probability of circular patch detection
</h2><span id='topic+detect'></span>

<h3>Description</h3>

<p>The function can calculate the probability of detection of a circular patch of specified radius for a 
specified density of points; the density needed to achieve a specified probability of detection; or the
radius of the patch that will be detected with specified probability and sampling density.This is done for
random, square lattice, and triangular lattice spatial sampling designs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect(method, statistic, area=NA, radius=NA, pdetect=NA, ssize=NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="detect_+3A_method">method</code></td>
<td>

<p>Defines the spatial sampling design to be used. The values can be <code>"R"</code> (random), <code>"S"</code> (square lattice)
or <code>"T"</code> (triangular lattice). See Barry and Nicholson (1993) for details and formulae for the 
probabilities of detection for the square
lattice and triangular lattice designs. For the random design, <code>prob(detect)=1 - (1 - a/A)^N</code>, where
<code>a</code> is the patch area and <code>A</code> is the survey area. This gives similar answers to the formula in
Barry and Nicholson, but is exact for fixed sample size.
</p>
</td></tr>
<tr><td><code id="detect_+3A_statistic">statistic</code></td>
<td>

<p>Describes what aspect of design you want calculated. The choices are <code>"P"</code> (probability detection); 
<code>"N"</code> (sample size) or <code>"R"</code> (patch radius).
</p>
</td></tr>
<tr><td><code id="detect_+3A_area">area</code></td>
<td>

<p>The survey area (same units as distance and radius).
</p>
</td></tr>
<tr><td><code id="detect_+3A_radius">radius</code></td>
<td>

<p>Patch radius. Not needed if <code>statistic="R"</code>.
</p>
</td></tr>
<tr><td><code id="detect_+3A_pdetect">pdetect</code></td>
<td>

<p>Probability detection. Not needed if <code>statistic="P"</code>.
</p>
</td></tr>
<tr><td><code id="detect_+3A_ssize">ssize</code></td>
<td>

<p>Sample size. Not needed if <code>statistic="N"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The basic idea is that you wish to conduct a survey in an area <code>area</code> to detect some object (patch) of
interest. This could be a cockle patch, an area of reef or an archaeological deposit. This function asssumes that
the object is circular with radius <code>radius</code>. You have three choices of sampling deign to use: spatial, square
lattice and triangular lattice. In terms of patch detection, for a given sample size, the triangular design gives
the highest probability - because its points are equi-distant apart.
</p>
<p>The simplest application of this function is to assess the patch detection probability for a particular design. This
is obtained using the <code>statistic="P"</code> option. However, the problem can be turned around and this function used to
calculate the sample size needed to obatain a specific patch detection probability (<code>statistic="N"</code>) or the radius
of the patch that would be detected with some desired probability (<code>statistic="R"). Th</code>is last scenario might be
useful if there was some particular size of patch that you wanted to be sure (say, 90 percent) of detecting.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>prob</code></td>
<td>
<p>Probability of patch detection</p>
</td></tr>
<tr><td><code>ssize</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code>rad</code></td>
<td>
<p>Patch radius</p>
</td></tr>
<tr><td><code>sep</code></td>
<td>
<p>Separation distance (for square and triangular lattice designs)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Barry J and Nicholson M D (1993) Measuring the probabilities of patch detection
for four spatial sampling schemes. Journal of Applied Statistics, 20, 353-362.                    
</p>


<h3>Examples</h3>

<pre><code class='language-R'>detect(method='R', statistic='P', area=100, radius=2, ssize=15)$prob
detect(method='R', statistic='N', area=100, radius=2, pdetect=0.95)$ssize
detect(method='R', statistic='R', area=100, pdetect=0.95, ssize=15)$rad

detect(method='S', statistic='P', area=100, radius=1.4, ssize=15)
detect(method='S', statistic='N', area=100, radius=1.4, pdetect=0.6)

# Plot patch detection as a function of radius
square = rep(0,200); rand = square; triang = rand
radius = seq(0.01, 2, 0.01)

for (j in 1:200) {
rand[j] = detect(method='R', statistic='P', area=100, radius=radius[j], ssize=15)$p
square[j] = detect(method='S', statistic='P', area=100, radius=radius[j], ssize=15)$p
triang[j] = detect(method='T', statistic='P', area=100, radius=radius[j], ssize=15)$p
}

plot(radius, rand, ylim=c(0,1), xlab='Patch radius', ylab='Probability detection', type='l')
lines(radius, square, col=2, lty=2)
lines(radius, triang, col=3, lty=3)
legend('topleft', legend=c('Random', 'Square', 'Triangular'), col=c(1,2,3), lty=c(1,2,3))
</code></pre>

<hr>
<h2 id='detect.prop'>
Probability of detecting a feature that covers a proportion <code>theta</code> of the survey area.
</h2><span id='topic+detect.prop'></span>

<h3>Description</h3>

<p>The function can calculate the probability of a feature that occupies
a proportion <code>theta</code> of the sampling area and where the sampling point density of the survey is
specified; the sampling point density needed to achieve a specified probability of detection, where
<code>theta</code> is also specified ; or the value of <code>theta</code> that will be detected with specified
probability and sampling density.Unless the feature is made of a large number of random segments
(see below for how to deal with this situation), these methods apply only when the pattern of points
in the sampling deisgn is random.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect.prop(statistic, theta=NA, pdetect=NA, ssize=NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="detect.prop_+3A_statistic">statistic</code></td>
<td>

<p>Describes what aspect of design you want calculated. The choices are <code>"P"</code> (probability detection); 
<code>"N"</code> (sample size) or <code>"F"</code> (feature proportion).
</p>
</td></tr>
<tr><td><code id="detect.prop_+3A_theta">theta</code></td>
<td>

<p>Feature proportion. Not needed if <code>statistic="F"</code>.
</p>
</td></tr>
<tr><td><code id="detect.prop_+3A_pdetect">pdetect</code></td>
<td>

<p>Probability detection. Not needed if <code>statistic="P"</code>.
</p>
</td></tr>
<tr><td><code id="detect.prop_+3A_ssize">ssize</code></td>
<td>

<p>Sample size. Not needed if <code>statistic="N"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The probability of detection is <code>p = 1 - (1 - theta)^{N}</code>. Formulae for <code>theta</code> and
<code>N</code> are readily obtained from this formula. If the spatial pattern of the feature consists of lots of small,
random uniformly distributed fragments, then we can redefine <code>theta = Na/A</code> where <code>a</code> is the
area of the sampling unit and <code>A</code> is the sampling area.In this situation, the probability of patch detection
applies no matter what the spatial pattern of points in the sampling design. Unlike <code>detect</code>, <code>detect.prop</code>
works for vectors - so long as the input vectors are of the same length.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>prob</code></td>
<td>
<p>Probability of detection</p>
</td></tr>
<tr><td><code>ssize</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code>prop</code></td>
<td>
<p>Feature proportion</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>detect.prop(statistic='P', theta=0.02, ssize=80)
detect.prop(statistic='N', theta=0.02, pdetect=0.9)
detect.prop(statistic='F', pdetect=0.9, ssize=80)
</code></pre>

<hr>
<h2 id='expected.nb'>
Expected value of Visual Fast Count Estimator assuming Negative Binomial distribution for counts
</h2><span id='topic+expected.nb'></span>

<h3>Description</h3>

<p>The function is used to obtain the method of moments estimator within the function <code><a href="#topic+GVFCMOM">GVFCMOM</a></code>.
</p>
<p>Calculates the expected value of the Visual Fast Count method.
The function assumes that the count per segment is Negative Binomial with mean <code>m/s</code> and size <code>k</code>,
and that segment counts are independent. The expected value is also a function of the number of positives
<code>d</code> before segment counting is stopped.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expected.nb(k, m, s, d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expected.nb_+3A_k">k</code></td>
<td>
<p>Size parameter of the Negative Binomial distribution</p>
</td></tr>
<tr><td><code id="expected.nb_+3A_m">m</code></td>
<td>
<p>The mean of the Negative Binomial distribution per transect</p>
</td></tr>
<tr><td><code id="expected.nb_+3A_s">s</code></td>
<td>
<p>The number of segments per transect</p>
</td></tr>
<tr><td><code id="expected.nb_+3A_d">d</code></td>
<td>
<p>The number of positive counts before segment counting is stopped</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The expected value of the Visual Fast Count estimator</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk</p>


<h3>See Also</h3>

<p><code><a href="#topic+expected.pois">expected.pois</a></code>, <code><a href="#topic+GVFCMOM">GVFCMOM</a></code></p>

<hr>
<h2 id='expected.pois'>
Expected value of Visual Fast Count Estimator assuming Poisson distribution for counts
</h2><span id='topic+expected.pois'></span>

<h3>Description</h3>

<p>The function is used to obtain the method of moments estimator within the function <code><a href="#topic+GVFCMOM">GVFCMOM</a></code>.
Calculates the expected value of the Visual Fast Count method.
The function assumes that the count per segment is Poisson
with mean m/s and that segment counts are independent. The expected value is also a function of the number of
positives d before segment counting is stopped.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expected.pois(m, s, d) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expected.pois_+3A_m">m</code></td>
<td>
<p>The underlying mean of the Poisson process per transect</p>
</td></tr>
<tr><td><code id="expected.pois_+3A_s">s</code></td>
<td>
<p>The number of segments per transect</p>
</td></tr>
<tr><td><code id="expected.pois_+3A_d">d</code></td>
<td>
<p>The numbner of positive counts before segment counting is stopped</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The expected value of the Visual Fast Count estimator</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk</p>


<h3>See Also</h3>

<p><code><a href="#topic+expected.nb">expected.nb</a></code>, <code><a href="#topic+GVFCMOM">GVFCMOM</a></code></p>

<hr>
<h2 id='fS.detect'>
Used in the function detect
</h2><span id='topic+fS.detect'></span>

<h3>Description</h3>

<p>Used in the function detect for calculating the sample size for a square lattice design.
It is used by the <code><a href="stats.html#topic+optimize">optimize</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>See Also</h3>

<p><code><a href="#topic+detect">detect</a></code></p>

<hr>
<h2 id='fT.detect'>
Used in function detect
</h2><span id='topic+fT.detect'></span>

<h3>Description</h3>

<p>Used in the function detect for calculating the sample size for a triangular lattice design.
It is used by the <code><a href="stats.html#topic+optimize">optimize</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>See Also</h3>

<p><code><a href="#topic+detect">detect</a></code></p>

<hr>
<h2 id='generate.trend'>
Generates a set of mean values.
</h2><span id='topic+generate.trend'></span>

<h3>Description</h3>

<p>This function is used to generate mean value scenarios for use in <code><a href="#topic+power.trend">power.trend</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> generate.trend(nyears, mu1=0, change, change.type="A", type = c("linear", "incident",
        "step", "updown"), changeyear, symmetric=F) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate.trend_+3A_nyears">nyears</code></td>
<td>
<p>Defines the number of time points for X axis</p>
</td></tr>
<tr><td><code id="generate.trend_+3A_mu1">mu1</code></td>
<td>
<p>The mean Y value for the first time point</p>
</td></tr>
<tr><td><code id="generate.trend_+3A_change">change</code></td>
<td>
<p>Difference between <code>mu1</code> and largest (or smallest) <code>mu_i</code>. Can be negative for a decreasing trend.</p>
</td></tr>
<tr><td><code id="generate.trend_+3A_change.type">change.type</code></td>
<td>
<p>Whether the parameter <code>change</code> represents an additive (&quot;A&quot;) or percentage (&quot;M&quot;) change.</p>
</td></tr>
<tr><td><code id="generate.trend_+3A_type">type</code></td>
<td>
<p>Type of trend to assess the power against. Can be any of <code>"linear"</code>, <code>"incident"</code>,
<code>"step"</code> or <code>"updown"</code>.
See <code>examples</code> below for more details.</p>
</td></tr>
<tr><td><code id="generate.trend_+3A_changeyear">changeyear</code></td>
<td>
<p>Year in which change in gradient occurs, for options <code>'incident'</code> or <code>'updown'</code>.</p>
</td></tr>
<tr><td><code id="generate.trend_+3A_symmetric">symmetric</code></td>
<td>
<p>If <code>symmetric=T</code>, <code>nyears</code> is even and <code>changeyear = nyears / 2</code> then
<code>type='updown'</code> generates a pattern where the two middle years are at level <code>k</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Assumes that surveys take place in years 1 to <code>nyears</code> (or could be any other equally spaced unit).
Generates a set of mean values (or signal) for a specified trend over that time period. The approach
is based on Fryer and Nicholson (1993, 1999). For <code>type="linear"</code>, the slope is generated by <code>b=k/(nyears-1)</code>.
If <code>type="updown"</code>, the slope until <code>changeyear</code> is generated by <code>b=k/(changeyears-1)</code>. After
<code>changeyear</code>, the slope is -b
(except for the special case outlined by the <code>symmetric</code> parameter above, where <code>changeyear</code>
and <code>changeyear+1</code> are k
and then the slope continues as -b).
</p>


<h3>Value</h3>

<p>Generates a data frame where the first column ($i) is year and the second column ($mu) is the mean value.
</p>


<h3>Author(s)</h3>

<p>David Maxwell: David.Maxwell@cefas.co.uk
</p>


<h3>References</h3>

<p>Fryer RJ &amp; Nicholson MD (1993) The power of a contaminant monitoring programme to detect linear trends and
incidents. ICES Journal of Marine Science, 50, 161-168.
</p>
<p>Fryer &amp; Nicholson 1999 Using smoothers for comprehensive assessments of contaminant time series in marine biota.
ICES Journal of Marine Science, 56, 779-790.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.trend">power.trend</a></code>, <code><a href="#topic+addnoise">addnoise</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lin0 = generate.trend(nyears=10, change=0, type="linear")
lin5 = generate.trend(nyears=10, change=5, type="linear")
inc5 = generate.trend(nyears=10, change=5, type="incident", changeyear=6)
step5 = generate.trend(nyears=10, change=5, type="step", changeyear=6)
updeven = generate.trend(nyears=10, change=5, type="updown", changeyear=5, symmetric=TRUE)
updodd = generate.trend(nyears=9, change=5, type="updown", changeyear=3)

par(mfrow=c(2,3))
plot(lin0$i, lin0$mu, type="o", pch=16, xlab='Time', ylab='Y')
plot(lin5$i, lin5$mu, type="o", pch=16, xlab='Time', ylab='Y')
plot(inc5$i, inc5$mu, type="o", pch=16, xlab='Time', ylab='Y')
plot(step5$i, step5$mu, type="o", pch=16, xlab='Time', ylab='Y')
plot(updeven$i, updeven$mu, type="o", pch=16, xlab='Time', ylab='Y')
plot(updodd$i, updodd$mu, type="o", pch=16, xlab='Time', ylab='Y')
</code></pre>

<hr>
<h2 id='GVFC'>
Calculates the raw Visual Fast Count (VFC) estimator of the mean abundance per transect
</h2><span id='topic+GVFC'></span>

<h3>Description</h3>

<p>The function considers the counts per segment and uses them sequentially until <code>d</code> positive counts
are obtained or until all <code>s</code> segments have been considered. If we assume that <code>u</code> counts are used (of
which some may be zero) then
the visual fast count estimator is the mean over the <code>u</code> counts multiplied by <code>s</code>. This function is used
by <code><a href="#topic+GVFCMOM">GVFCMOM</a></code> to obtain the method of moments VFC estimator - which has reduced bias compared to the
raw VFC estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GVFC(counts, s, d) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GVFC_+3A_counts">counts</code></td>
<td>
<p> Vector of length s that contains a count for each segment </p>
</td></tr>
<tr><td><code id="GVFC_+3A_s">s</code></td>
<td>
<p> Number of segments </p>
</td></tr>
<tr><td><code id="GVFC_+3A_d">d</code></td>
<td>
<p> Number of positive segment counts needed before counting stops </p>
</td></tr>
</table>


<h3>Value</h3>

<p>The raw VFC estimate of the segment mean</p>


<h3>Author(s)</h3>

<p>Jon Barry: jon.barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Barry J, Eggleton J, Ware S and Curtis M (2015) Generalizing Visual Fast Count Estimators for Underwater
Video Surveys. Ecosphere. 
http://www.esajournals.org/doi/full/10.1890/ES15-00093.1
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GVFCMOM">GVFCMOM</a></code> </p>

<hr>
<h2 id='GVFCMOM'>Function to calculate the method of moments visual fast count estimator</h2><span id='topic+GVFCMOM'></span>

<h3>Description</h3>

<p>The function takes data in the form of counts per segment along a transect and uses the 
raw Generalised Visual Fast Count estimator (as calculated by <code><a href="#topic+GVFCMOM">GVFCMOM</a></code> and its
expectation (as calculated by <code><a href="#topic+expected.pois">expected.pois</a></code> for Poisson or <code><a href="#topic+expected.nb">expected.nb</a></code> for
negative binomial) to calculate
a method of moments estimator. This effectively,
adjusts the biased raw GVFC estimate. The function allows counts to have either a Poisson or a Negative Binomial
distribution. The method is a generalisation of the methods in Barry and Coggan (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GVFCMOM(counts, s, d, method, k=1, lowint=0, highint=100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GVFCMOM_+3A_counts">counts</code></td>
<td>
<p>Vector of length s that contains a count for each segment</p>
</td></tr>
<tr><td><code id="GVFCMOM_+3A_s">s</code></td>
<td>
<p>Number of segments</p>
</td></tr>
<tr><td><code id="GVFCMOM_+3A_d">d</code></td>
<td>
<p>Number of positive segment counts needed before counting stops</p>
</td></tr>
<tr><td><code id="GVFCMOM_+3A_method">method</code></td>
<td>
<p>Whether Poisson (<code>"pois"</code>) or Negative Binomial Distribution (<code>"nb"</code>) is assumed</p>
</td></tr>
<tr><td><code id="GVFCMOM_+3A_k">k</code></td>
<td>
<p>Size parameter of the Negative Binomial distribution</p>
</td></tr>
<tr><td><code id="GVFCMOM_+3A_lowint">lowint</code></td>
<td>
<p>Minimum value for MOM estimate (default=0)</p>
</td></tr>
<tr><td><code id="GVFCMOM_+3A_highint">highint</code></td>
<td>
<p>Maximum value for MOM estimate (default=100)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The method of moments estimate for the transect is returned</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Barry J, Eggleton J, Ware S and Curtis M (2015) Generalizing Visual Fast Count Estimators for
Underwater Video Surveys. Ecosphere. 
http://www.esajournals.org/doi/full/10.1890/ES15-00093.1
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+GVFC">GVFC</a></code>, <code><a href="#topic+expected.pois">expected.pois</a></code>, <code><a href="#topic+expected.nb">expected.nb</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>counts = c(0, 0, 0, 0, 1, 1, 1, 2, 1)
GVFCMOM(counts, s=9, d=2, method='nb', lowint=0, highint=100)
GVFCMOM(counts, s=9, d=1, method='nb', lowint=0, highint=100)
GVFCMOM(counts, s=9, d=1, method='pois', lowint=0, highint=100)
</code></pre>

<hr>
<h2 id='is.wholenumber'>
To check whether an argument is an integer
</h2><span id='topic+is.wholenumber'></span>

<h3>Description</h3>

<p>Used in error checking to ascertain whether a function argument is an integer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.wholenumber(x, tol = .Machine$double.eps^0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.wholenumber_+3A_x">x</code></td>
<td>
<p>Number to be checked.</p>
</td></tr>
<tr><td><code id="is.wholenumber_+3A_tol">tol</code></td>
<td>
<p>If <code>x</code> is closer to an integer than this, then it passes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of logical values if the corresponding input values is an integer or not.
</p>


<h3>References</h3>

<p><code>is.wholenumber</code> is taken from the <code><a href="base.html#topic+is.integer">is.integer</a></code> help file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.wholenumber( seq(1, 5, by = 0.5) ) #--&gt;  TRUE FALSE TRUE ...
</code></pre>

<hr>
<h2 id='mannkendall'> Mann-kendall test for trend </h2><span id='topic+mannkendall'></span>

<h3>Description</h3>

<p>Calculates the Mann-Kendall statistic for monotonic trend and also the p-value against the null hypothesis of no trend.
Unlike the function <code><a href="Kendall.html#topic+MannKendall">MannKendall</a></code>, works for repeat values of time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> mannkendall(time, Y, nsims.mk=999) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mannkendall_+3A_time">time</code></td>
<td>
<p>Vector of values which define the direction of the trend.</p>
</td></tr>
<tr><td><code id="mannkendall_+3A_y">Y</code></td>
<td>
<p>Vector of values for which you want to determine the trend.</p>
</td></tr>
<tr><td><code id="mannkendall_+3A_nsims.mk">nsims.mk</code></td>
<td>
<p>Number of replicate permuations to calculate the p-value. Default=999.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Error checks of parameters not included so as not to slow down mannkendall. The statistic is calculated by considering
each case <code>j</code> and considering the subset of observations that have time greater than <code>time[j]</code>. The Mann Kendall
statistic is the number of observations in this subset for which <code>Y &gt; Y[j]</code> minus the number for
which <code>Y &lt; Y[j]</code>.
The statistic is summed over all <code>j</code>. The p-value is calculated by <code>nreps</code> random permutations of the Y values.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>mann</code></td>
<td>
<p>Mann-Kendall statistic of observed data, as calculated by <code><a href="#topic+mannkendall.stat">mannkendall.stat</a></code>.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>P-value assuming a null hypothesis of no trend and two-way alternative hypothesis.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Mann, H.B. (1945), Nonparametric tests against trend, Econometrica, 13,
245-259.
</p>
<p>Kendall, M.G. 1975. Rank Correlation Methods, 4th edition, Charles Griffin, 
London.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mannkendall.stat">mannkendall.stat</a></code>, <code><a href="#topic+power.trend">power.trend</a></code>, <code><a href="Kendall.html#topic+MannKendall">MannKendall</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x = rep(1:10,rep(2,10))
y = rnorm(20, 5, 2)
mannkendall(x, y)
</code></pre>

<hr>
<h2 id='mannkendall.stat'>
Mann-Kendall statistic.
</h2><span id='topic+mannkendall.stat'></span>

<h3>Description</h3>

<p>Calculates the Mann-Kendall statistic for monotonic trend. Unlike the function <code><a href="Kendall.html#topic+MannKendall">MannKendall</a></code>, works
for repeat values of time. Used in function <code><a href="#topic+mannkendall">mannkendall</a></code>, which also calculates the p-value by simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> mannkendall.stat(time, Y) </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mannkendall.stat_+3A_time">time</code></td>
<td>
<p> Vector of values which define the direction of the trend. </p>
</td></tr>
<tr><td><code id="mannkendall.stat_+3A_y">Y</code></td>
<td>
<p>Vector of values for which you want to determine the trend.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The statistic is calculated by considering
each case <code>j</code> and considering the subset of observations that have time greater than <code>time[j]</code>. The Mann Kendall
statistic is the number of observations in this subset for which <code>Y &gt; Y[j]</code> minus the number for
which <code>Y &lt; Y[j]</code>.
The statistic is summed over all <code>j</code>. The p-value is calculated by <code>nreps</code> random permutations of the Y values.
</p>


<h3>Value</h3>

<p>Mann-Kendall statistic</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Mann, H.B. (1945), Nonparametric tests against trend, Econometrica, 13,
245-259.
Kendall, M.G. 1975. Rank Correlation Methods, 4th edition, Charles Griffin, 
London.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mannkendall">mannkendall</a></code>, <code><a href="#topic+power.trend">power.trend</a></code>, <code><a href="Kendall.html#topic+MannKendall">MannKendall</a></code></p>

<hr>
<h2 id='mom.min.nb'>Minimising function for VFC MOM estimator assuming Negative Binomial counts.</h2><span id='topic+mom.min.nb'></span>

<h3>Description</h3>

<p>Used by the <code><a href="stats.html#topic+optimize">optimize</a></code> function to obtain the method of moments estimator within the function
<code><a href="#topic+GVFCMOM">GVFCMOM</a></code>.
</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+optimize">optimize</a></code>, <code><a href="#topic+GVFCMOM">GVFCMOM</a></code> </p>

<hr>
<h2 id='mom.min.pois'>Minimising function for VFC MOM estimator assuming Poisson counts.</h2><span id='topic+mom.min.pois'></span>

<h3>Description</h3>

<p>Used by the <code><a href="stats.html#topic+optimize">optimize</a></code> function to obtain the method of moments estimator within the function
<code><a href="#topic+GVFCMOM">GVFCMOM</a></code>.
</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+optimize">optimize</a></code>, <code><a href="#topic+GVFCMOM">GVFCMOM</a></code> </p>

<hr>
<h2 id='n.min'>Minimising function used in <code><a href="#topic+precision">precision</a></code>.</h2><span id='topic+n.min'></span>

<h3>Description</h3>

<p>Used by the <code><a href="stats.html#topic+optimize">optimize</a></code> function to obtain the correct sample size within the function
<code><a href="#topic+precision">precision</a></code> given that the t-distributions is also a function of sample size.
</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+optimize">optimize</a></code>, <code><a href="#topic+precision">precision</a></code> </p>

<hr>
<h2 id='permute.BACI'>
Does non-parametric randomisation test for the interaction term in a BACI design. 
</h2><span id='topic+permute.BACI'></span>

<h3>Description</h3>

<p>We have control and treatment data from time 1 in a BACI design, plus control and treatment
data from time 2. The interaction  the amount that the difference in the control and
treatment meansis different between times 1 and 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permute.BACI(t1, c1, t2, c2, nreps=999)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="permute.BACI_+3A_t1">t1</code></td>
<td>
<p>Data vector for the treatment at time 1</p>
</td></tr> 
<tr><td><code id="permute.BACI_+3A_c1">c1</code></td>
<td>
<p>Data vector for the control at time 1</p>
</td></tr>
<tr><td><code id="permute.BACI_+3A_t2">t2</code></td>
<td>
<p>Data vector for the treatment at time 2</p>
</td></tr> 
<tr><td><code id="permute.BACI_+3A_c2">c2</code></td>
<td>
<p>Data vector for the control at time 2</p>
</td></tr> 
<tr><td><code id="permute.BACI_+3A_nreps">nreps</code></td>
<td>
<p>Number of replications used in the randomisation and generation of
the p-value. Default is <code>nreps=999</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are several permutation that can be used to generate the null distribution for
the interaction (see Manly, 2006 and Anderson and Terr Braak, 2003). The method used here is
to do a complete randomisation of the raw data.
</p>
<p>The p-value is calculated as suggested by Manly (2006).
</p>


<h3>Value</h3>

<p>The p-value is returned as <code>$p.value</code></p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Manly BFJ (2006) Randomization, Bootstrap And Monte Carlo Methods in Biology: 3rd edition. Chapman and Hall.
</p>
<p>Anderson, M.J. and Ter Braak, C.J.F. (2003). Permutation tests for multi-factorial analysis of
variance. Journal of Computation and Simulation, 73, 85-113.</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.BACI">power.BACI</a></code>, <code><a href="#topic+permute.groups">permute.groups</a></code></p>

<hr>
<h2 id='permute.groups'>
Does randomisation test for the difference in means of two vectors <code>v1</code> and <code>v2</code>.
</h2><span id='topic+permute.groups'></span>

<h3>Description</h3>

<p>Does randomisation test for the difference in means mu1, mu2
of two vectors <code>v1</code> and <code>v2</code>. Can do one or two sided tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permute.groups(v1, v2, alternative, nreps)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="permute.groups_+3A_v1">v1</code></td>
<td>
<p>Data vector for variable 1</p>
</td></tr> 
<tr><td><code id="permute.groups_+3A_v2">v2</code></td>
<td>
<p>Data vector for variable 2</p>
</td></tr>
<tr><td><code id="permute.groups_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative
hypothesis, must be one of <code>"two.sided"</code> (default), <code>"greater"</code> (<code>mu1&gt;mu2</code>) or <code>"less"</code>.
You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="permute.groups_+3A_nreps">nreps</code></td>
<td>
<p>Number of replications used in the randomisation and generation of
the p-value. Default is <code>nreps=999</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Under the null hypothesis that <code>mu1=mu2</code>, the labelling of the <code>n1+n2</code> observations is unimportant.
Therefore, we can generate the null distribution for the test statistic <code>m1-m2</code> or <code>|m1-m2|</code> depending
on whether a one
or two sided test is required) by randomly permuting the treatment labels nreps times and calculating the test statistic
each time. The p-value is calculated as suggested by Manly (2006).
</p>


<h3>Value</h3>

<p>The p-value is returned as <code>$p.value</code></p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Manly BFJ (2006) Randomization, Bootstrap And Monte Carlo Methods in Biology: 3rd edition. Chapman and Hall.</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.groups">power.groups</a></code>, <code><a href="#topic+permute.BACI">permute.BACI</a></code>   </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(5)
v1 = rnorm(27,10,2); v2=rnorm(25,11,2)
permute.groups(v1, v2, alternative="two")
permute.groups(v1, v2, alt="l")
</code></pre>

<hr>
<h2 id='power.BACI'>
Calculates power for a Before and After Control Impact (BACI) design.
</h2><span id='topic+power.BACI'></span>

<h3>Description</h3>

<p>BACI designs are commonly used in environmental monitoring. They are relevant where you
want to measure the effect of an impact (e.g. the effect on benthic ecology of dredging
in an area). Observations for treatment and control areas are measured BEFORE and
after the impact. This function allows you to examine the power of particular BACI designs
to detect differences between the control and the treatment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> power.BACI(change, change.type="M", nt, nc, parst, parsc,
          distribution, test="P", alpha=0.05, nsims=1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power.BACI_+3A_change">change</code></td>
<td>
<p>AFTER treatment mean minus BEFORE treatment mean or percentage change of
AFTER treatment mean relative to BEFORE treatment mean (depending on value of
<code>change.type</code>).
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_change.type">change.type</code></td>
<td>
<p>Whether the parameter <code>change</code> represents an additive (&quot;A&quot;) or
percentage (&quot;M&quot;) change.
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_nt">nt</code></td>
<td>
<p>Vector of sample sizes for treatment group. Must be of same dimension as <code>nc</code>.
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_nc">nc</code></td>
<td>
<p>Vector of sample sizes for control group. Must be of same dimension as <code>nt</code>.
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_parst">parst</code></td>
<td>

<p>Parameters for the treatment data.
</p>
<p>If <code>distribution="Normal"</code>, <code>parst[1]</code>
contains the BEFORE mean and <code>parst[2]</code> contains the BEFORE standard deviation. If
<code>distribution="Poisson"</code>, <code>parst[1]</code> contains the BEFORE mean. If
<code>distribution="Lognormal"</code>, <code>parst[1]</code> contains the BEFORE mean of the natural
log data and
<code>parst[2]</code> contains the BEFORE standard deviation of the log data. If
<code>distribution="Negbin"</code>,
<code>parst[1]</code> contains the BEFORE mean, <code>parst[2]</code> contains the BEFORE size, and
<code>parst[3]</code> is the AFTER size.
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_parsc">parsc</code></td>
<td>

<p>Parameters for the control data.
</p>
<p>If <code>distribution="Normal"</code>, <code>parsc[1]</code>
contains the BEFORE mean and <code>parsc[2]</code> contains the BEFORE standard deviation. If
<code>distribution="Poisson"</code>, <code>parsc[1]</code> contains the BEFORE mean. If
<code>distribution="Lognormal"</code>, <code>parsc[1]</code> contains the BEFORE mean of the natural log
data and
<code>parsc[2]</code> contains the BEFORE standard deviation of the log data. If
<code>distribution="Negbin"</code>,
<code>parsc[1]</code> contains the BEFORE mean, and <code>parsc[2]</code> contains the BEFORE size.
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_distribution">distribution</code></td>
<td>

<p>The statistical distribution for the two groups. Can be either: <code>"Normal"</code>,
<code>"Poisson"</code>, <code>"Lognormal"</code> or <code>"Negbin"</code>.
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_test">test</code></td>
<td>
<p>The statistical test used to compare the interaction between the control and treatment
means at the BEFORE and AFTER sampling occasions. If <code>test="NP"</code>, then the
test will be a non-parametric randomisation test, in the spirit of Manly (1997), using the function
<code><a href="#topic+permute.BACI">permute.BACI</a></code>.
</p>
<p>If <code>test="P"</code>, then parametric tests are made to
compare the treatment (i.e. a factor indicating whether an observation is from the treatmment
or the control) by time (i.e. a factor indicating whether observations are BEFORE or AFTER)
interaction. If <code>distribution="Normal"</code> then this is calculated from the usual Analysis
of Variance. The same method is used (but on the log data) if <code>distribution="Lognormal"</code>.
</p>
<p>When <code>distribution="Poisson"</code> or <code>distribution="Negbin"</code>, interactions from analysis
of deviance tables are used to measure the interaction. The p-value is calculated by assuming
that this interaction deviance has a chi-squared distribution on 1 df. For the Negative
Binomial distribution, terms in the analysis of deviance table use the same
value for the size parameter as that estimated from the null model.
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_alpha">alpha</code></td>
<td>
<p> If the p-value for the interaction is less than <code>alpha</code>, a change is deemed
to have been detected. Used to assess power from the <code>nreps</code> simulations.
</p>
</td></tr>
<tr><td><code id="power.BACI_+3A_nsims">nsims</code></td>
<td>
<p> Number of repeat simulations used to calculate the power. Default is 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>BACI designs are relevant where you want to measure the effect of an
impact (e.g. the effect on benthic ecology of dredging in an area).
You take a number of samples both in (treatment) and outside (control) the affected area BEFORE the impact. Those in
the control area should be as similar to the treatment area as possible in terms of benthic ecology. You then sample
the areas again AFTER the impact has taken place. If there is an interaction for the 2x2 crossed design then there is
an effect of the impact. That is, if the control area has changed differently to the treatment area.
</p>
<p>This function allows you to examine the power of particular BACI designs. The distribution of the measure being used
can be Normal, Poisson, Negative Binomial or Lognormal.
</p>
<p>It is also assumed that the sample sizes before and after the impact are the same, although the sample size in the
treatment area can be different to the control area. Thus, if 10 and 8 samples are taken in the treatment and control
areas before the impact, then 10 and 8 samples are assumed to be taken after the impact.
</p>
<p>For the Normal, Poisson and Negative Binomial distributions, the parameter change is simply the percentage or
additive change of the treatment mean from
the BEFORE to the AFTER sampling occasions. For the Lognormal distribution, the percentage change is relative to the
BEFORE treatment mean on the non-log scale. The BEFORE treatment mean is estimated from the mean of the
log data (<code>parst[1]</code>), the standard deviation of the log data (<code>parst[2]</code>) and the proposed sampling size
<code>nt</code>.
</p>
<p>The estimator used is the one proposed by Shen (2006), which did better in terms of mean squared error than both the
sample mean on the non-log scale and the maximum likelihood estimators. This is given by
<code>mean.before = exp(parst[1] + (nt-1)*ss / (2*(nt+4)*(nt-1) + 3*ss)), where ss = (nt-1)*parst[2]**2</code>.
</p>
<p>The Negative Binomial distribution option (<code>parst[3]</code> allows the user to specify the size parameter of the
AFTER treatment distribution. One possibility is to keep the size the same for both the BEFORE and AFTER
distributions. However, because the mean changes and because the variance V = mu+mu^2/size, this means that V
will be different for the BEFORE and AFTER distributions. If you want to keep the variance the same, you can use
the function <code><a href="#topic+size2.samevar">size2.samevar</a></code>.
</p>
<p>Several powers can be calculated per call to this function by specifying more than one values for
the sample sizes <code>nt</code> and <code>nc</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>power</code></td>
<td>
<p> The estimated power for the design. </p>
</td></tr>
<tr><td><code>before.mean</code></td>
<td>
<p> The treatment mean used for the before sampling. Only really of interest if
<code>method="Lognormal"</code> as this gives the Shen estimator.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jon Barry (email Jon.Barry@cefas.co.uk)
</p>


<h3>References</h3>

<p>Shen H, Brown LD and Zhi H (2006) Efficient estimation of log-normal means with application to pharmacokinetic data.
Statistics in Medicine, 25, 3023 to 3038.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.trend">power.trend</a></code>, <code><a href="#topic+power.groups">power.groups</a></code>, <code><a href="#topic+size2.samevar">size2.samevar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data is richness (number of species) and abundance from grab samples from
# the Dogger Bank, UK. In practice, \code{nsims} would be set to at least 1000.

rich = c(15,16,37,12,15,5,13,16,17,34,23,20,22,30,85,55,13,19,30,41,22,8,43,10,38,24,17,
         23,17,17,24,33,30,18,26,18,12,50,19,21,35)
abun = c(50,91,140,21,25,8,28,37,30,90,56,50,40,83,964,180,21,60,81,138,67,17,250,63,152,
         68,42,69,57,67,74,96,75,44,61,49,62,281,55,50,198)

par(mfrow=c(2,2))
hist(rich)
hist(abun)
hist(sqrt(rich))
hist(log(abun))

ssize = seq(10, 50, 10)
parsc.rich = mean(rich); parst.rich = mean(rich)
parsc.abun = rep(0,2); parst.abun = parsc.abun
parst.abun[1] = mean(log(abun)); parst.abun[2] = sd(log(abun))
parsc.abun = parst.abun
power.rich = rep(0, length(ssize))
power.abun = rep(0, length(ssize))

power.rich = power.BACI(change=35, change.type="M", nt=ssize, nc=ssize,
                parst=parst.rich, parsc=parsc.rich,
                distribution="Poisson", test="P", nsims=50)$power

power.abun = power.BACI(change=35, change.type="M", nt=ssize, nc=ssize,
                parst=parst.abun, parsc=parsc.abun, distribution="Lognormal",
                test="P", nsims=50)$power

par(mfrow=c(1,1))
plot(ssize, power.rich, ylim=c(0,1), ylab="Power", xlab="Sample size", type="l")
lines(ssize, power.abun, lty=2, col=2)
legend("bottomright", legend=c("Richness power", "Abundance power"), lty=c(1,2),
       col=c(1,2))
title("BACI power plots")
</code></pre>

<hr>
<h2 id='power.groups'>
Power for comparing mean of two groups
</h2><span id='topic+power.groups'></span>

<h3>Description</h3>

<p>Calculates the power by simulation for comparing the mean of two groups of independent observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.groups(change, change.type="M", n1, n2, pars1, pars2,
           distribution, test, alternative="two", alpha=0.05, nsims=1000, nreps=999)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power.groups_+3A_change">change</code></td>
<td>

<p>Mean of second group minus mean of first group (i.e. <code>mu2-mu1</code>) or percentage change
in <code>mu1</code> to create <code>mu2</code> (depending on value of <code>change.type</code>).
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_change.type">change.type</code></td>
<td>

<p>Whether the parameter <code>change</code> represents an additive (&quot;A&quot;) or percentage (&quot;M&quot;) change.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_n1">n1</code></td>
<td>

<p>Vector of sample sizes for group 1. Must be of same dimension as <code>n2</code>.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_n2">n2</code></td>
<td>

<p>Vector of sample sizes for group 2. Must be of same dimension as <code>n1</code>.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_pars1">pars1</code></td>
<td>

<p>Parameters for the treatment data. If <code>distribution="Normal"</code>, <code>pars1[1]</code>
contains the mean for group 1 and <code>pars1[2]</code> contains the standard deviation. If
<code>distribution="Poisson"</code>, <code>pars1[1]</code> contains the mean for group 1. If
<code>distribution="Lognormal"</code>, <code>pars1[1]</code> contains the group 1 mean of the natural log
data and
<code>pars1[2]</code> contains the standard deviation of the log data. If <code>distribution="Negbin"</code>,
<code>pars1[1]</code> contains the mean and <code>pars1[2]</code> contains the group 1 size parameter.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_pars2">pars2</code></td>
<td>

<p><code>pars2[1]</code> is the standard deviation for group 2 if <code>distribution="Normal"</code>.
If <code>distribution="Lognormal"</code>, <code>pars2[1]</code> is the standard deviation of the log data for
group 2. For <code>distribution="Negbin"</code>, <code>pars2[1]</code> gives the group 2 size.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_distribution">distribution</code></td>
<td>

<p>The statistical distribution for the two groups. Can be either: <code>"Normal"</code>,
<code>"Poisson"</code>, <code>"Lognormal"</code> or <code>"Negbin"</code>.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_test">test</code></td>
<td>

<p>The statistical test used to compare the group means. If <code>test="NP"</code> then the
test will be a
non-parametric randomisation test, in the spirit of Manly (1997), using the function
<code><a href="#topic+permute.groups">permute.groups</a></code>. If <code>test="P"</code>, then parametric tests are made to
compare the group means. If <code>distribution="Normal"</code>, a two sample t-test is
carried out. If the standard deviations (defined by <code>pars1[2]</code> and <code>pars2[1]</code>
are equal, then the t-test calculates the usual pooled standard deviation. However,
if the standard deviations are not equal then the default method used by
<code><a href="stats.html#topic+t.test">t.test</a></code> is adopted.
</p>
<p>When <code>distribution="Lognormal"</code>, natural logs are taken of the simulated data and
a t-test used in a similar way as to when <code>distribution="Lognormal"</code>.
When <code>distribution="Poisson"</code>, the difference in deviances between the null model
and the model with group membership fitted as factor is compared againt a chi-squared
distributiuon on 1 degree of freedom. A similar (but not quite) method is used for when
<code>distribution="Negbin"</code>. The Generalised Linear Model function
<code><a href="MASS.html#topic+glm.nb">glm.nb</a></code> for the Negative Binomial distribution is used. The p-value
for comparing the two groups is taken from the analysis of deviance table after the
model with group membership is fitted as a factor. This p-value, however, uses the same
value for the size parameter, as estimated from the null model, for group member deviance.
This seems to be the correct thing to do as estimating separate size parameters for the two
models mucks up the nesting of the models.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_alternative">alternative</code></td>
<td>

<p>A character string specifying the alternative hypothesis, must be one of <code>"two.sided"</code>
(default), <code>"greater"</code> or <code>"less"</code>. You can specify just the initial letter. As
an example, <code>"less"</code> means that the alternative is that the mean of the first group
is less than the mean of the second.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_alpha">alpha</code></td>
<td>

<p>The type 1 error for assessing statistical significance (default is 0.05) in the power simulations.
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_nsims">nsims</code></td>
<td>

<p>Number of repeat simulations to estimate power (default is 1000).
</p>
</td></tr>
<tr><td><code id="power.groups_+3A_nreps">nreps</code></td>
<td>

<p>Number of repeat permutations for randomisation test (default is 999).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Negative Binomial distribution option allows the user to specify the size parameter for both
groups 1 and 2. One possibility is to keep the size the same for both groupss. However, because the
mean is different between the groups and because the variance V = mu+mu^2/size, this means that V
will be different for the group 1 and group 2 distributions. If you want to keep the variance the
same, you can use the function <code><a href="#topic+size2.samevar">size2.samevar</a></code>.
</p>
<p>Several powers can be calculated per call to this function by specifying more than one values for
the sample sizes <code>n1</code> and <code>n2</code>.
</p>


<h3>Value</h3>

<p>The power is returned. This is the proportion of the <code>nreps</code> simulations that returned
a p-value less than the type1 error.
</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Manly BFJ (1997) Randomization, bootstrap and monte carlo methods in biology:
2nd edition. Chapman and Hall, London, 399 pages.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+permute.groups">permute.groups</a></code>, <code><a href="MASS.html#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+size2.samevar">size2.samevar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)

# In practice, \code{nsims} would be set to at least 1000

power.groups(change=2.5, change.type="A", n1=20, n2=20, pars1=c(10,2),
       pars2=2, test='P', distribution="Normal", nsims=50)

power.groups(change=2.5, change.type="A", n1=seq(5,25,5), n2=seq(5,25,5), pars1=c(10,2),
       pars2=2, test='P', distribution="Normal", nsims=50)

power.groups(change=25, change.type="M", n1=20, n2=20, pars1=10,
       test='P', distribution="Poisson", nsims=50)

power.groups(change=4, change.type="A", n1=20, n2=20, pars1=c(1,2),
       pars2=2, test='P', distribution="Lognormal", nsims=50)


# Keeping size constant
power.groups(change=100, change.type="M", n1=20, n2=20, pars1=c(5,2),
       pars2=2, test='P', distribution="Negbin", nsims=50)

# Keeping variance constant
s2 = size2.samevar(mu1=5, mu2=10, s1=2)   # 13.333
power.groups(change=100, change.type="M", n1=20, n2=20, pars1=c(5,2),
       pars2=s2, test='P', distribution="Negbin", nsims=50)

</code></pre>

<hr>
<h2 id='power.trend'> Calculates power by simulation to detect a specified trend.</h2><span id='topic+power.trend'></span>

<h3>Description</h3>

<p>Calculates power for a specified trend wherethe signal for the trend is specified by xvalues and meanvalues (possibly
generated by generate.trend), and the error distribution is specified by distribution. The statistical method to detect
the trend
is specified by method.The power is the proportion of repeat simulations for which the trend is detected with a p-value
less than alpha (two-sided test).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.trend(xvalues, reps=1,  meanvalues, distribution="Normal", sd=NA,
  nbsize=NA, method="linear regression", alpha=0.05, nsims=1000, nsims.mk=999,
  randeffect=F, randeffect.sd=NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power.trend_+3A_xvalues">xvalues</code></td>
<td>
<p>Vector of, for example, time points at which the trend is evaluated.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_reps">reps</code></td>
<td>
<p>Vector of number of replicates per time point.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_meanvalues">meanvalues</code></td>
<td>
<p>Vector of mean values that identify the signal of the trend.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_distribution">distribution</code></td>
<td>
<p> Distribution (must be one of <code>"Normal"</code>, <code>"Poisson"</code> or <code>"Negbin"</code> used to
generate random values based on the signal in <code>meanvalues</code>.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_sd">sd</code></td>
<td>
<p> Standard deviation if distribution=<code>"Normal"</code>.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_nbsize">nbsize</code></td>
<td>
<p> Size parameter if distribution=<code>"Negbin"</code>.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_method">method</code></td>
<td>
<p> Method used to identify the trend. Can be one of <code>"linear regression"</code>, <code>"mk"</code>, or
<code>"gam"</code>. The last of these fits a Generalised
Additive Model (Wood, 2006) using function <code><a href="mgcv.html#topic+gam">gam</a></code>. It assumes Normal errors.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_alpha">alpha</code></td>
<td>
<p> Type 1 error for detecting trend. Values less than <code>alpha</code> cause the null hypothesis of
<code>no trend</code> to be rejected. Tests are 2-sided. </p>
</td></tr>
<tr><td><code id="power.trend_+3A_nsims">nsims</code></td>
<td>
<p> The number of simulations to be used in calculating the power. Default is 1000.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_nsims.mk">nsims.mk</code></td>
<td>
<p> The number of replicate permutations used in calculating the p-value for the Mann-Kendall test
when <code>method=mk</code>. Default is 999.</p>
</td></tr>
<tr><td><code id="power.trend_+3A_randeffect">randeffect</code></td>
<td>
<p>Not working yet</p>
</td></tr>
<tr><td><code id="power.trend_+3A_randeffect.sd">randeffect.sd</code></td>
<td>
<p>Not working yet</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mann Kendall tests are approriate only for monotonic increasing or decreasing trends, the linear regression
method is
only approriate for linearly increasing or decreasing trend. The GAM is appropriate for changing trends over time.
</p>
<p>Several powers can be calculated on a single call to this function by placing more than one value in <code>reps</code>.
</p>


<h3>Value</h3>

<p> The power is returned. </p>


<h3>Author(s)</h3>

<p>David Maxwell: david.maxwell@cefas.co.uk
</p>


<h3>References</h3>

<p>Fryer RJ &amp; Nicholson MD (1993) Need paper title. ICES Journal of Marine Science, 50, 161-168.
</p>
<p>Fryer &amp; Nicholson 1999 Using smoothers for comprehensive assessments of contaminant time series in marine biota.
ICES Journal of Marine Science, 56, 779-790.
</p>
<p>Wood S.N. (2006) Generalized Additive Models: An Introduction with R. Chapman and Hall/CRC Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mannkendall.stat">mannkendall.stat</a></code>, <code><a href="#topic+addnoise">addnoise</a></code>,
<code><a href="mgcv.html#topic+gam">gam</a></code>, <code><a href="#topic+generate.trend">generate.trend</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mgcv)

# In practice, \code{nsims} would be set to at least 1000

par(mfrow=c(2,2))
lin5 = generate.trend(nyears=10, change=5, type="linear")
plot(lin5$i, lin5$mu)
updown = generate.trend(nyears=15, change=5, type="updown", changeyear=8)
plot(updown$i, updown$mu)

power.trend(xvalues=lin5$i, meanvalues=lin5$mu, distribution="Normal", sd=2,
            method="linear regression", alpha=0.05, nsims=50)
power.trend(xvalues=lin5$i, meanvalues=lin5$mu, distribution="Poisson", method="mk", alpha=0.05,
      nsims=50)
power.trend(xvalues=updown$i, meanvalues=updown$mu, distribution="Normal", sd=2,
            method="gam", alpha=0.05, nsims=50)
</code></pre>

<hr>
<h2 id='precision'>
Sample size for given precision or precision for given sample size
</h2><span id='topic+precision'></span>

<h3>Description</h3>

<p>Precision is measured by the width of a 100(1-alpha)
The function generates the sample size needed to achieve this or the precision achieved for
a specified sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>precision(d, n, pars, method="sample size", alpha=0.05, minint=1, maxint=500) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="precision_+3A_d">d</code></td>
<td>

<p>The Confidence Interval width required (for use with <code>method="sample size"</code>). This can
be a vector.
</p>
</td></tr>
<tr><td><code id="precision_+3A_n">n</code></td>
<td>

<p>Sample size (for use with <code>method="width"</code>). This can be a vector.
</p>
</td></tr>
<tr><td><code id="precision_+3A_pars">pars</code></td>
<td>

<p>Standard deviation of the variable
</p>
</td></tr>
<tr><td><code id="precision_+3A_method">method</code></td>
<td>

<p>Whether sample size is required (<code>"sample size"</code>) or precision (<code>"width"</code>).
</p>
</td></tr>
<tr><td><code id="precision_+3A_alpha">alpha</code></td>
<td>

<p>Defines the (1-alpha/2) percentage point of the t-dristribution used in the confidence interval.
</p>
</td></tr>
<tr><td><code id="precision_+3A_minint">minint</code></td>
<td>

<p>Lower bound to be used in the search interval for the sample size.
</p>
</td></tr>
<tr><td><code id="precision_+3A_maxint">maxint</code></td>
<td>

<p>Upper bound to be used in the search interval for the sample size.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The width of a Confidence Interval for the mean is given by the standard formula
<code>d = 2 * sigma * t(1-alpha/2, n-1) / sqrt(n)</code>, where sigma is the standard deviation and
n is the sample
size. t(.) is the relevant quantile of the t distribution function.If sample size is required then
we can turn this equation round to get <code>n = [2 * sigma * t(1-alpha/2, n-1)/d]^2</code>. To solve this
equation for the sample size <code>n</code>, <code>precision</code> uses the function <code>optimize</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>n</code></td>
<td>

<p>Sample sizes.
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>Confidence interval widths.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
precision(d=c(1,1.2,1.5), pars=1, method="sample size", alpha=0.05)

precision(d=c(4), pars=1, method="sample size", alpha=0.05)

precision(n=c(20,25), pars=1, method="width", alpha=0.05)

</code></pre>

<hr>
<h2 id='size2.samevar'>
Calculates negative binomial size to preserve constant variance.
</h2><span id='topic+size2.samevar'></span>

<h3>Description</h3>

<p>Calculates the Negative Binomial size parameter <code>s2</code> such that the variance of the distribution
with mean <code>mu2</code> and size <code>s2</code> is the same as the Negative Binomial distribution with mean
<code>mu1</code> and size <code>s1</code>. This can be useful when computing power for a Negative Binomial
distribution in the packages <code><a href="#topic+power.groups">power.groups</a></code> and <code><a href="#topic+power.BACI">power.BACI</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size2.samevar(mu1, mu2, s1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="size2.samevar_+3A_mu1">mu1</code></td>
<td>
<p>Negative Binomial mean for group 1</p>
</td></tr>
<tr><td><code id="size2.samevar_+3A_mu2">mu2</code></td>
<td>
<p>Negative Binomial mean for group 2</p>
</td></tr>
<tr><td><code id="size2.samevar_+3A_s1">s1</code></td>
<td>
<p>Negative Binomial size for group 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The size for group 1.
</p>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.groups">power.groups</a></code>, <code><a href="#topic+power.BACI">power.BACI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu1=5; mu2=10; s1=3
s2 = size2.samevar(mu1, mu2, s1)
s2
# Check variances are the same
v1 = mu1 + mu1^2 / s1
v2 = mu2 + mu2^2 / s2
v1; v2
</code></pre>

<hr>
<h2 id='svariog'>
Calculates empirical semi-variogram.
</h2><span id='topic+svariog'></span>

<h3>Description</h3>

<p>Calculates empirical semi-variogram cloud plus classical, robust and median estimators from bins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>           svariog(x, y, z, u) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="svariog_+3A_x">x</code></td>
<td>
<p>Location vector 1 (e.g. longitude).</p>
</td></tr> 
<tr><td><code id="svariog_+3A_y">y</code></td>
<td>
<p>Location vector 2 (e.g. latitude).</p>
</td></tr>
<tr><td><code id="svariog_+3A_z">z</code></td>
<td>
<p>Response vector observed at the locations.</p>
</td></tr>
<tr><td><code id="svariog_+3A_u">u</code></td>
<td>
<p><code>(b+1)</code> cut points used to define the <code>b</code> bins for distances. The cut points define the
boundaries
for each bin.  Distances on the boundary of bins go into the lower bin.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates the <code>n(n-1)/2</code> distances between each of the n points together with the semi-variogram
cloud of
the <code>n(n-1)/2</code> differences <code>(zi-zj)^2 / 2</code> between pairs of observations <code>(i,j)</code>.
This cloud
is smoothed by taking one of three sorts of averages
within each bin - bin end points are defined by the vector <code>u</code>. These averages are the
classical (the
bin mean) estimator, a function of the bin median and a robust estimator. Both the median and the
robust estimators are based on absolute differences between <code>z</code> pairs. These methods are
defined in Cressie (1993).</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>classical</code></td>
<td>
<p>Classical semi-variogram estimator.</p>
</td></tr>
<tr><td><code>med</code></td>
<td>
<p>Median semi-variogram estimator.</p>
</td></tr>
<tr><td><code>robust</code></td>
<td>
<p>Robust semi-variogram estimator.</p>
</td></tr>
<tr><td><code>freq</code></td>
<td>
<p>Frequencies of distances within each bin.</p>
</td></tr>
<tr><td><code>mid</code></td>
<td>
<p>Mid points of each bin.</p>
</td></tr>
<tr><td><code>zcloud</code></td>
<td>
<p>Unsmoothed semi-variogram cloud.</p>
</td></tr>
<tr><td><code>dcloud</code></td>
<td>
<p>Distances between pairs of points for the variogram cloud.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Jon Barry: Jon.Barry@cefas.co.uk
</p>


<h3>References</h3>

<p>Cressie, NAC (1993) Statistics for Spatial Data, Revised Edition. Wiley, New York.</p>


<h3>See Also</h3>

<p><code><a href="geoR.html#topic+variog">variog</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Example based on the number of benthic species found from samples of Hamon Grabs from 50
# locations 
lat = c(54.23, 55.14, 55.14, 55.59, 55.49, 55.38, 55.15, 55.14, 55.25, 55.17, 55.16, 54.86,
54.80, 54.95, 54.82, 54.80, 54.80, 54.77, 54.76, 55.48, 55.48, 54.56, 54.55, 54.54, 54.50,
54.63, 54.59, 54.52, 54.40, 54.37, 54.36, 54.16, 55.47, 55.46, 55.12, 55.43, 55.52, 55.62,
55.58, 55.47, 55.35, 55.30, 55.33, 55.32, 55.17, 54.63, 54.95, 54.94, 54.71, 54.36)

long = c(2.730, 1.329, 1.329, 3.225, 1.954, 1.833, 2.090, 2.085, 1.956, 1.643, 1.641, 2.089,
         2.336, 1.489, 1.180, 1.493, 1.493, 1.960, 1.958, 2.559, 2.559, 1.344, 1.343, 1.498,
         1.652, 2.090, 2.331, 2.089, 1.844, 2.335, 2.335, 2.084, 2.903, 2.904, 2.335, 2.335,
         2.338, 2.340, 1.949, 1.469, 1.483, 1.484, 2.901, 2.901, 2.897, 1.040, 1.024, 2.738,
         2.737, 2.551)

nspecies = c(28,16,22,23,17,13,28,18,20,41,21,14,19,41,28,4,32,31,16,9,14,6,35,
          18,9,35,23,5,18,27,27,16,22,16,
          29,11,8,23,28,23,18,16,16,47,31,17,13,23,19,20)

u = c(0,0.1,0.3,0.5,0.7,1,1.5,2.4)

semiv = svariog(long, lat, nspecies, u)

par(mfrow=c(2,2))
plot(semiv$dcloud, semiv$zcloud, xlab='Distance', ylab='Cloud')
plot(semiv$mid, semiv$cla, xlab='Distance', ylab='Classical')
plot(semiv$mid, semiv$med, xlab='Distance', ylab='Median')
plot(semiv$mid, semiv$rob, xlab='Distance', ylab='Robust')
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
