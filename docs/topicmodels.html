<!DOCTYPE html><html><head><title>Help for package topicmodels</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="/home/deepayan/Rinstall/R-devel/lib/R/doc/html/R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {topicmodels}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AssociatedPress'><p>Associated Press data</p></a></li>
<li><a href='#CTM'><p>Correlated Topic Model</p></a></li>
<li><a href='#distHellinger'><p>Compute Hellinger distance</p></a></li>
<li><a href='#LDA'><p>Latent Dirichlet Allocation</p></a></li>
<li><a href='#ldaformat2dtm'><p>Transform data from and for use with the <span class="pkg">lda</span> package</p></a></li>
<li><a href='#logLik-methods'><p>Methods for Function logLik</p></a></li>
<li><a href='#perplexity'><p>Methods for Function perplexity</p></a></li>
<li><a href='#posterior-methods'><p>Determine posterior probabilities</p></a></li>
<li><a href='#terms_and_topics'>
<p>Extract most likely terms or topics.</p></a></li>
<li><a href='#TopicModel-class'><p>Virtual class &quot;TopicModel&quot;</p></a></li>
<li><a href='#TopicModelcontrol-class'><p>Different classes for controlling the estimation of topic models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Topic Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2-15</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides an interface to the C code for Latent Dirichlet
	     Allocation (LDA) models and Correlated Topics Models
	     (CTM) by David M. Blei and co-authors and the C++ code
	     for fitting LDA models using Gibbs sampling by Xuan-Hieu
	     Phan and co-authors.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats4, methods, modeltools, slam, tm (&ge; 0.6)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>lattice, lda, OAIHarvester, SnowballC, corpus.JSS.papers</td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="https://datacube.wu.ac.at">https://datacube.wu.ac.at</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU Scientific Library version &gt;= 1.8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-27 07:03:36 UTC; gruen</td>
</tr>
<tr>
<td>Author:</td>
<td>Bettina Grün <a href="https://orcid.org/0000-0001-7265-4773"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Kurt Hornik <a href="https://orcid.org/0000-0003-4198-9911"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  David M Blei [ctb, cph] (VEM estimation of LDA and CTM),
  John D Lafferty [ctb, cph] (VEM estimation of CTM),
  Xuan-Hieu Phan [ctb, cph] (MCMC estimation of LDA),
  Makoto Matsumoto [ctb, cph] (Mersenne Twister RNG),
  Takuji Nishimura [ctb, cph] (Mersenne Twister RNG),
  Shawn Cokus [ctb] (Mersenne Twister RNG)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Bettina Grün &lt;Bettina.Gruen@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-27 08:25:00 UTC</td>
</tr>
<tr>
<td>Built:</td>
<td>R 4.4.0; x86_64-pc-linux-gnu; 2024-01-02 07:55:03 UTC; unix</td>
</tr>
</table>
<hr>
<h2 id='AssociatedPress'>Associated Press data</h2><span id='topic+AssociatedPress'></span>

<h3>Description</h3>

<p>Associated Press data from the First Text Retrieval Conference
(TREC-1) 1992.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("AssociatedPress")</code></pre>


<h3>Format</h3>

<p>The data set is an object of class <code>"DocumentTermMatrix"</code>
provided by package <span class="pkg">tm</span>. It is a document-term matrix which
contains the term frequency of 10473 terms in 2246 documents.
</p>


<h3>Source</h3>

<p>Accompanying material to the source code for fitting LDA models
provided by David M. Blei and co-authors. Downloaded from:
<a href="http://www.cs.columbia.edu/~blei/">http://www.cs.columbia.edu/~blei/</a>
</p>


<h3>References</h3>

<p>D. Harman (1992) Overview of the first text retrieval conference
(TREC-1). In Proceedings of the First Text Retrieval Conference
(TREC-1), 1&ndash;20.
</p>

<hr>
<h2 id='CTM'>Correlated Topic Model</h2><span id='topic+CTM'></span>

<h3>Description</h3>

<p>Estimate a CTM model using for example the VEM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CTM(x, k, method = "VEM", control = NULL, model = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CTM_+3A_x">x</code></td>
<td>
<p>Object of class <code>"DocumentTermMatrix"</code> with
term-frequency weighting or an object coercible to a
<code>"simple_triplet_matrix"</code> with integer entries.</p>
</td></tr>
<tr><td><code id="CTM_+3A_k">k</code></td>
<td>
<p>Integer; number of topics.</p>
</td></tr>
<tr><td><code id="CTM_+3A_method">method</code></td>
<td>
<p>The method to be used for fitting; currently only
<code>method = "VEM"</code> is supported.</p>
</td></tr>
<tr><td><code id="CTM_+3A_control">control</code></td>
<td>
<p>A named list of the control parameters for estimation
or an object of class <code>"CTM_VEMcontrol"</code>.</p>
</td></tr>
<tr><td><code id="CTM_+3A_model">model</code></td>
<td>
<p>Object of class <code>"CTM"</code> for initialization.</p>
</td></tr>
<tr><td><code id="CTM_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The C code for CTM from David M. Blei and co-authors is used to
estimate and fit a correlated topic model.
</p>


<h3>Value</h3>

<p><code>CTM()</code> returns an object of class
<code>"<a href="topicmodels.html#topic+CTM-class">CTM</a>"</code>.
</p>


<h3>Author(s)</h3>

<p>Bettina Gruen</p>


<h3>References</h3>

  
<p>Blei D.M., Lafferty J.D. (2007).
A Correlated Topic Model of Science.
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 17&ndash;35. 
</p>


<h3>See Also</h3>

<p><code>"<a href="topicmodels.html#topic+CTM_VEMcontrol-class">CTM_VEMcontrol</a>"</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("AssociatedPress", package = "topicmodels")
ctm &lt;- CTM(AssociatedPress[1:20,], k = 2)
</code></pre>

<hr>
<h2 id='distHellinger'>Compute Hellinger distance</h2><span id='topic+distHellinger'></span><span id='topic+distHellinger.default'></span><span id='topic+distHellinger.simple_triplet_matrix'></span>

<h3>Description</h3>

<p>The Hellinger distance between the rows of two data matrices are
determined or if the second argument is missing between the rows of
one data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
distHellinger(x, y, ...)
## S3 method for class 'simple_triplet_matrix'
distHellinger(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distHellinger_+3A_x">x</code></td>
<td>
<p>A data matrix.</p>
</td></tr>
<tr><td><code id="distHellinger_+3A_y">y</code></td>
<td>
<p>A data matrix.</p>
</td></tr>
<tr><td><code id="distHellinger_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing the distances.
</p>


<h3>Author(s)</h3>

<p>Bettina Gruen
</p>

<hr>
<h2 id='LDA'>Latent Dirichlet Allocation</h2><span id='topic+LDA'></span>

<h3>Description</h3>

<p>Estimate a LDA model using for example the VEM algorithm or Gibbs Sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LDA(x, k, method = "VEM", control = NULL, model = NULL, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LDA_+3A_x">x</code></td>
<td>
<p>Object of class <code>"DocumentTermMatrix"</code> with
term-frequency weighting or an object coercible to a
<code>"simple_triplet_matrix"</code> with integer entries.</p>
</td></tr>
<tr><td><code id="LDA_+3A_k">k</code></td>
<td>
<p>Integer; number of topics.</p>
</td></tr>
<tr><td><code id="LDA_+3A_method">method</code></td>
<td>
<p>The method to be used for fitting; currently 
<code>method = "VEM"</code> or <code>method= "Gibbs"</code> are
supported.</p>
</td></tr>
<tr><td><code id="LDA_+3A_control">control</code></td>
<td>
<p>A named list of the control parameters for estimation
or an object of class <code>"LDAcontrol"</code>.</p>
</td></tr>
<tr><td><code id="LDA_+3A_model">model</code></td>
<td>
<p>Object of class <code>"LDA"</code> for initialization.</p>
</td></tr>
<tr><td><code id="LDA_+3A_...">...</code></td>
<td>
<p>Optional arguments. For <code>method = "Gibbs"</code> an
additional argument <code>seedwords</code> can be specified as a matrix or
an object of class <code>"simple_triplet_matrix"</code>; the default is
<code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The C code for LDA from David M. Blei and co-authors is used to
estimate and fit a latent dirichlet allocation model with the VEM
algorithm. For Gibbs Sampling the C++ code from Xuan-Hieu Phan and
co-authors is used.
</p>
<p>When Gibbs sampling is used for fitting the model, seed words with
their additional weights for the prior parameters can be specified in
order to be able to fit seeded topic models.
</p>


<h3>Value</h3>

<p><code>LDA()</code> returns an object of class <code>"<a href="topicmodels.html#topic+LDA-class">LDA</a>"</code>. 
</p>


<h3>Author(s)</h3>

<p>Bettina Gruen</p>


<h3>References</h3>

<p>Blei D.M., Ng A.Y., Jordan M.I. (2003).
Latent Dirichlet Allocation.
<em>Journal of Machine Learning Research</em>, <b>3</b>, 993&ndash;1022.
</p>
<p>Phan X.H., Nguyen L.M., Horguchi S. (2008).
Learning to Classify Short and Sparse Text &amp; Web with Hidden Topics
from Large-scale Data Collections.
In Proceedings of the 17th International World Wide Web Conference
(WWW 2008), pages 91&ndash;100, Beijing, China.
</p>
<p>Lu, B., Ott, M., Cardie, C., Tsou, B.K. (2011).
Multi-aspect Sentiment Analysis with Topic Models.
In Proceedings of the 2011 IEEE 11th International Conference on Data
Mining Workshops, pages 81&ndash;88.
</p>


<h3>See Also</h3>

<p><code>"<a href="topicmodels.html#topic+LDAcontrol-class">LDAcontrol</a>"</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
lda_inf &lt;- posterior(lda, AssociatedPress[21:30,])
</code></pre>

<hr>
<h2 id='ldaformat2dtm'>Transform data from and for use with the <span class="pkg">lda</span> package</h2><span id='topic+ldaformat2dtm'></span><span id='topic+dtm2ldaformat'></span>

<h3>Description</h3>

<p>Data from the <span class="pkg">lda</span> package is transformed to a document-term
matrix. This data format can be used to fit topic models using package
<span class="pkg">topicmodels</span>.
</p>
<p>Data in form of a document-term matrix is transformed to the LDA
format used by package <span class="pkg">lda</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldaformat2dtm(documents, vocab, omit_empty = TRUE)
dtm2ldaformat(x, omit_empty = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldaformat2dtm_+3A_documents">documents</code></td>
<td>
<p>A <code>list</code> where each entry corresponds to a
document; for each document the number of terms occurring in the
document are stored in a <code>matrix</code> with two rows such that in
each column the first entry corresponds to the vocabulary id of the
term and the second entry to the number of times this term occurred
in the document.</p>
</td></tr>
<tr><td><code id="ldaformat2dtm_+3A_vocab">vocab</code></td>
<td>
<p>A <code>"character"</code> vector of the terms in the
vocabulary.</p>
</td></tr>
<tr><td><code id="ldaformat2dtm_+3A_x">x</code></td>
<td>
<p>An object of class <code>"DocumentTermMatrix"</code> as defined in
package <span class="pkg">tm</span>.</p>
</td></tr>
<tr><td><code id="ldaformat2dtm_+3A_omit_empty">omit_empty</code></td>
<td>
<p>A logical indicating if empty documents should be
removed when converting the objects. By default empty documents are
removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"DocumentTermMatrix"</code> is returned by
<code>ldaformat2dtm()</code> and a list with components <code>"documents"</code>
and <code>"vocab"</code> by <code>dtm2ldaformat()</code>.
</p>


<h3>Author(s)</h3>

<p>Bettina Gruen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("lda")) {
  data("cora.documents", package = "lda")
  data("cora.vocab", package = "lda")
  dtm &lt;- ldaformat2dtm(cora.documents, cora.vocab)
  cora &lt;- dtm2ldaformat(dtm)
  all.equal(cora, list(documents = cora.documents,
                       vocab = cora.vocab))
}
</code></pre>

<hr>
<h2 id='logLik-methods'>Methods for Function logLik</h2><span id='topic+logLik+2CTopicModel-method'></span><span id='topic+logLik+2CGibbs_list-method'></span>

<h3>Description</h3>

<p>Compute the log-likelihood.</p>


<h3>Methods</h3>


<dl>
<dt>object = TopicModel:</dt><dd><p>Compute the log-likelihood of a
<code>"TopicModel"</code> object. For <code>"VEM"</code> objects the sum of
the log-likelihood of all documents given the parameters for the
topic distribution and for the word distribution of each topic is
approximated using the variational parameters and underestimates
the log-likelihood by the Kullback-Leibler divergence between the
variational posterior probability and the true posterior
probability.</p>
</dd>
<dt>object = Gibbs_list:</dt><dd><p>Compute the log-likelihoods of the
<code>"TopicModel"</code> objects contained in the <code>"Gibbs_list"</code>
object.</p>
</dd>
</dl>


<hr>
<h2 id='perplexity'>Methods for Function perplexity</h2><span id='topic+perplexity'></span><span id='topic+perplexity+2CVEM+2Cmissing-method'></span><span id='topic+perplexity+2CANY+2Cmatrix-method'></span><span id='topic+perplexity+2CANY+2CDocumentTermMatrix-method'></span><span id='topic+perplexity+2CVEM+2Csimple_triplet_matrix-method'></span><span id='topic+perplexity+2CGibbs+2Csimple_triplet_matrix-method'></span><span id='topic+perplexity+2CGibbs_list+2Csimple_triplet_matrix-method'></span><span id='topic+perplexity+2Clist+2Cmissing-method'></span><span id='topic+perplexity+2Clist+2Csimple_triplet_matrix-method'></span>

<h3>Description</h3>

<p>Determine the perplexity of a fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perplexity(object, newdata, ...)

## S4 method for signature 'VEM,simple_triplet_matrix'
perplexity(object, newdata, control, ...)

## S4 method for signature 'Gibbs,simple_triplet_matrix'
perplexity(object, newdata, control, use_theta = TRUE,
estimate_theta = TRUE, ...)

## S4 method for signature 'Gibbs_list,simple_triplet_matrix'
perplexity(object, newdata, control, use_theta  = TRUE,
estimate_theta = TRUE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perplexity_+3A_object">object</code></td>
<td>
<p>Object of class <code>"TopicModel"</code> or <code>"Gibbs_list"</code>.</p>
</td></tr>
<tr><td><code id="perplexity_+3A_newdata">newdata</code></td>
<td>
<p>If missing, the perplexity for the data to which the
model was fitted is determined. For objects fitted using Gibbs sampling
<code>newdata</code> needs to be specified.</p>
</td></tr>
<tr><td><code id="perplexity_+3A_control">control</code></td>
<td>
<p>If missing, the <code>control</code> of the fitted model is
used with suitable changes of the relevant parameters (see
<b>Details</b>).</p>
</td></tr>
<tr><td><code id="perplexity_+3A_use_theta">use_theta</code></td>
<td>
<p>Object of class <code>"logical"</code>. If <code>TRUE</code>
the estimated topic distributions for the documents are
used. Otherwise equal weights are assigned to the topics for each document.</p>
</td></tr>
<tr><td><code id="perplexity_+3A_estimate_theta">estimate_theta</code></td>
<td>
<p>Object of class <code>"logical"</code>. If <code>FALSE</code> the
data provided is assumed to be the same as the data used for fitting the
model. The topic distributions therefore do not need to be estimated
and the data in <code>newdata</code> is used for weighting the
term-document occurrences.</p>
</td></tr>
<tr><td><code id="perplexity_+3A_...">...</code></td>
<td>
<p>Further arguments passed to the different methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specified control is modified to ensure that (1)
<code>estimate.beta=FALSE</code> and (2) <code>nstart=1</code>.
</p>
<p>For <code>"Gibbs_list"</code> objects the <code>control</code> is further modified
to have (1) <code>iter=thin</code> and (2) <code>best=TRUE</code> and the model is
fitted to the new data with this control for each available
iteration. The perplexity is then determined by averaging over the
same number of iterations.
</p>
<p>If a <code>list</code> is supplied as <code>object</code>, it is assumed that it
consists of several models which were fitted using different starting
configurations.
</p>


<h3>Value</h3>

<p>A numeric value.
</p>


<h3>Author(s)</h3>

<p>Bettina Gruen</p>


<h3>References</h3>

<p>Blei D.M., Ng A.Y., Jordan M.I. (2003).
Latent Dirichlet Allocation.
<em>Journal of Machine Learning Research</em>, <b>3</b>, 993&ndash;1022.
</p>
<p>Griffiths T.L., Steyvers, M. (2004).
Finding Scientific Topics.
<em>Proceedings of the National Academy of Sciences of the
United States of America</em>, <b>101</b>, Suppl. 1, 5228&ndash;5235.
</p>
<p>Newman D., Asuncion A., Smyth P., Welling M. (2009).
Distributed Algorithms for Topic Models.
<em>Journal of Machine Learning Research</em>, <b>10</b>, 1801&ndash;1828.
</p>

<hr>
<h2 id='posterior-methods'>Determine posterior probabilities</h2><span id='topic+posterior+2CTopicModel+2Cmissing-method'></span><span id='topic+posterior+2CTopicModel+2CANY-method'></span>

<h3>Description</h3>

<p>Determine the posterior probabilities of the topics for each document and
of the terms for each topic for a fitted topic model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'TopicModel,missing'
posterior(object, newdata, ...)
## S4 method for signature 'TopicModel,ANY'
posterior(object, newdata, control = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posterior-methods_+3A_object">object</code></td>
<td>
<p>An object of class &quot;TopicModel&quot;.</p>
</td></tr>
<tr><td><code id="posterior-methods_+3A_newdata">newdata</code></td>
<td>
<p>If missing the posteriors for the original observations
are returned.</p>
</td></tr>
<tr><td><code id="posterior-methods_+3A_control">control</code></td>
<td>
<p>A named list of the control parameters for estimation
or a suitable control object.</p>
</td></tr>
<tr><td><code id="posterior-methods_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Bettina Gruen</p>

<hr>
<h2 id='terms_and_topics'>
Extract most likely terms or topics.
</h2><span id='topic+topics'></span><span id='topic+topics+2CTopicModel-method'></span><span id='topic+terms+2CTopicModel-method'></span><span id='topic+get_terms'></span><span id='topic+get_topics'></span>

<h3>Description</h3>

<p>Function to extract the most likely terms for each topic or the most
likely topics for each document.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'TopicModel'
terms(x, k, threshold, ...)
## S4 method for signature 'TopicModel'
topics(x, k, threshold, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="terms_and_topics_+3A_x">x</code></td>
<td>
<p>Object of class <code>"TopicModel"</code>.</p>
</td></tr>
<tr><td><code id="terms_and_topics_+3A_k">k</code></td>
<td>
<p>The maximum number of terms/topics returned. By default
set to 1 if no threshold is given.</p>
</td></tr>
<tr><td><code id="terms_and_topics_+3A_threshold">threshold</code></td>
<td>
<p>Only the terms/topics which are more likely than
the threshold are returned.</p>
</td></tr>
<tr><td><code id="terms_and_topics_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>sapply</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list or matrix containing the most likely terms for each topic or
the most likely topics for each document.
</p>


<h3>Author(s)</h3>

<p>Bettina Gruen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+posterior-methods">posterior-methods</a></code></p>

<hr>
<h2 id='TopicModel-class'>Virtual class &quot;TopicModel&quot;</h2><span id='topic+TopicModel-class'></span><span id='topic+LDA-class'></span><span id='topic+CTM-class'></span><span id='topic+show+2CTopicModel-method'></span>

<h3>Description</h3>

<p>Fitted topic model.
</p>


<h3>Objects from the Class</h3>

<p>Objects of class <code>"LDA"</code> are returned by <code><a href="text2vec.html#topic+LDA">LDA</a>()</code> and
of class <code>"CTM"</code> by <code><a href="topicmodels.html#topic+CTM">CTM</a>()</code>.
</p>


<h3>Slots</h3>

<p>Class <code>"TopicModel"</code> contains
</p>

<dl>
<dt><code>call</code>:</dt><dd><p>Object of class <code>"call"</code>.</p>
</dd>
<dt><code>Dim</code>:</dt><dd><p>Object of class <code>"integer"</code>; number of
documents and terms.</p>
</dd>
<dt><code>control</code>:</dt><dd><p>Object of class <code>"TopicModelcontrol"</code>;
options used for estimating the topic model.</p>
</dd>
<dt><code>k</code>:</dt><dd><p>Object of class <code>"integer"</code>; number of
topics.</p>
</dd>
<dt><code>terms</code>:</dt><dd><p>Vector containing the term names.</p>
</dd>
<dt><code>documents</code>:</dt><dd><p>Vector containing the document names.</p>
</dd>
<dt><code>beta</code>:</dt><dd><p>Object of class <code>"matrix"</code>; logarithmized
parameters of the word distribution for each topic.</p>
</dd>
<dt><code>gamma</code>:</dt><dd><p>Object of class <code>"matrix"</code>; parameters of
the posterior topic distribution for each document.</p>
</dd>
<dt><code>iter</code>:</dt><dd><p>Object of class <code>"integer"</code>; the number of
iterations made.</p>
</dd>
<dt><code>logLiks</code>:</dt><dd><p>Object of class <code>"numeric"</code>; the vector
of kept intermediate log-likelihood values of the corpus. See
<code>loglikelihood</code> how the log-likelihood is determined.</p>
</dd>
<dt><code>n</code>:</dt><dd><p>Object of class <code>"integer"</code>; number of words
in the data used.</p>
</dd>
<dt><code>wordassignments</code>:</dt><dd><p>Object of class
<code>"simple_triplet_matrix"</code>; most probable topic for each
observed word in each document.</p>
</dd>
</dl>

<p>Class <code>"VEM"</code> contains
</p>

<dl>
<dt><code>loglikelihood</code>:</dt><dd><p>Object of class <code>"numeric"</code>; the
log-likelihood of each document given the parameters for the topic
distribution and for the word distribution of each topic is
approximated using the variational parameters and underestimates
the log-likelihood by the Kullback-Leibler divergence between the
variational posterior probability and the true posterior
probability.</p>
</dd>
</dl>

<p>Class <code>"LDA"</code> extends class <code>"TopicModel"</code> and has the additional
slots
</p>

<dl>
<dt><code>loglikelihood</code>:</dt><dd><p>Object of class <code>"numeric"</code>; the
posterior likelihood of the corpus conditional on the topic
assignments is returned.</p>
</dd>
<dt><code>alpha</code>:</dt><dd><p>Object of class <code>"numeric"</code>; parameter of
the Dirichlet distribution for topics over documents.</p>
</dd>
</dl>

<p>Class <code>"LDA_Gibbs"</code> extends class <code>"LDA"</code> and has
the additional slots
</p>

<dl>
<dt><code>seed</code>:</dt><dd><p>Either <code>NULL</code> or object of class
<code>"simple_triplet_matrix"</code>; parameter for the prior
distribution of the word distribution for topics if seeded.</p>
</dd>
<dt><code>z</code>:</dt><dd><p>Object of class <code>"integer"</code>; topic assignments
of words ordered by terms with suitable repetition within
documents.</p>
</dd>  
</dl>

<p>Class <code>"CTM"</code> extends class <code>"TopicModel"</code> and has the additional
slots
</p>

<dl>
<dt><code>mu</code>:</dt><dd><p>Object of class <code>"numeric"</code>; mean of the
topic distribution on the logit scale.</p>
</dd>
<dt><code>Sigma</code>:</dt><dd><p>Object of class <code>"matrix"</code>;
variance-covariance matrix of topics on the logit scale.</p>
</dd>
</dl>

<p>Class <code>"CTM_VEM"</code> extends classes <code>"CTM"</code> and
<code>"VEM"</code> and has the additional
slots
</p>

<dl>
<dt><code>nusqared</code>:</dt><dd><p>Object of class <code>"matrix"</code>; variance of the
variational distribution on the parameter mu.</p>
</dd>		
</dl>
  


<h3>Author(s)</h3>

<p>Bettina Gruen</p>

<hr>
<h2 id='TopicModelcontrol-class'>Different classes for controlling the estimation of topic models</h2><span id='topic+OPTcontrol-class'></span><span id='topic+TopicModelcontrol-class'></span><span id='topic+CTM_VEMcontrol-class'></span><span id='topic+LDAcontrol-class'></span><span id='topic+LDA_VEMcontrol-class'></span><span id='topic+LDA_Gibbscontrol-class'></span><span id='topic+coerce+2CNULL+2CLDA_VEMcontrol-method'></span><span id='topic+coerce+2Clist+2CLDA_VEMcontrol-method'></span><span id='topic+coerce+2CNULL+2CLDcontrol-method'></span><span id='topic+coerce+2Clist+2CLDA_VEMcontrol-method'></span><span id='topic+coerce+2CNULL+2CCTM_VEMcontrol-method'></span><span id='topic+coerce+2Clist+2CCTM_VEMcontrol-method'></span><span id='topic+coerce+2CNULL+2COPTcontrol-method'></span><span id='topic+coerce+2Clist+2COPTcontrol-method'></span>

<h3>Description</h3>

<p>Classes to control the estimation of topic models which are inheriting
from the virtual base class <code>"TopicModelcontrol"</code>. 
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created from named lists.
</p>


<h3>Slots</h3>

<p>Class <code>"TopicModelcontrol"</code> contains
</p>

<dl>
<dt><code>seed</code>:</dt><dd><p>Object of class <code>"integer"</code>; used to set
the seed in the external code for VEM estimation and to call
<code>set.seed</code> for Gibbs sampling. For Gibbs sampling it can also
be set to <code>NA</code> (default) to avoid changing the seed of the
random number generator in the model fitting call.</p>
</dd>
<dt><code>verbose</code>:</dt><dd><p>Object of class <code>"integer"</code>. If a
positive integer, then the progress is reported every
<code>verbose</code> iterations. If 0 (default), no output is generated
during model fitting.</p>
</dd>
<dt><code>save</code>:</dt><dd><p>Object of class <code>"integer"</code>. If a positive
integer the estimated model is saved all <code>verbose</code>
iterations. If 0 (default), no output is generated during model
fitting.</p>
</dd>
<dt><code>prefix</code>:</dt><dd><p>Object of class <code>"character"</code>; path
indicating where to save the intermediate results.</p>
</dd>
<dt><code>nstart</code>:</dt><dd><p>Object of class <code>"integer"</code>. Number of
repeated random starts.</p>
</dd>
<dt><code>best</code>:</dt><dd><p>Object of class <code>"logical"</code>; if <code>TRUE</code>
only the model with the maximum (posterior) likelihood is returned,
by default equals <code>TRUE</code>.</p>
</dd>
<dt><code>keep</code>:</dt><dd><p>Object of class <code>"integer"</code>; if a positive
integer, the log-likelihood is saved every <code>keep</code> iterations.</p>
</dd>
<dt><code>estimate.beta</code>:</dt><dd><p>Object of class <code>"logical"</code>;
controls if beta, the term distribution of the topics, is fixed,
by default equals <code>TRUE</code>.</p>
</dd>
</dl>

<p>Class <code>"VEMcontrol"</code> contains
</p>

<dl>
<dt><code>var</code>:</dt><dd><p>Object of class <code>"OPTcontrol"</code>; controls the
variational inference for a single document, by default
<code>iter.max</code> equals 500 and <code>tol</code> 10^-6.</p>
</dd>
<dt><code>em</code>:</dt><dd><p>Object of class <code>"OPTcontrol"</code>; controls the
variational EM algorithm, by default <code>iter.max</code> equals 1000
and <code>tol</code> 10^-4.</p>
</dd>
<dt><code>initialize</code>:</dt><dd><p>Object of class <code>"character"</code>; one of
<code>"random"</code>, <code>"seeded"</code> and <code>"model"</code>, by default
equals <code>"random"</code>.</p>
</dd>
</dl>

<p>Class <code>"LDAcontrol"</code> extends class <code>"TopicModelcontrol"</code> and
has the additional slots
</p>

<dl>
<dt><code>alpha</code>:</dt><dd><p>Object of class <code>"numeric"</code>; initial
value for alpha.</p>
</dd>
</dl>

<p>Class <code>"LDA_VEMcontrol"</code> extends classes
<code>"LDAcontrol"</code> and <code>"VEMcontrol"</code> and has the
additional slots
</p>

<dl>
<dt><code>estimate.alpha</code>:</dt><dd><p>Object of class <code>"logical"</code>;
indicates if the parameter alpha is fixed a-priori or estimated, by
default equals <code>TRUE</code>.</p>
</dd>
</dl>

<p>Class <code>"LDA_Gibbscontrol"</code> extends classes
<code>"LDAcontrol"</code> and has the additional slots
</p>

<dl>
<dt><code>delta</code>:</dt><dd><p>Object of class <code>"numeric"</code>; initial value
for delta, by default equals 0.1.</p>
</dd>
<dt><code>iter</code>:</dt><dd><p>Object of class <code>"integer"</code>; number of
Gibbs iterations (after omitting the <code>burnin</code> iterations), by
default equals 2000.</p>
</dd>
<dt><code>thin</code>:</dt><dd><p>Object of class <code>"integer"</code>; number of
omitted in-between Gibbs iterations, by default equals <code>iter</code>.</p>
</dd>
<dt><code>burnin</code>:</dt><dd><p>Object of class <code>"integer"</code>; number of
omitted Gibbs iterations at beginning, by default equals 0.</p>
</dd>
<dt><code>initialize</code>:</dt><dd><p>Object of class <code>"character"</code>;
one of <code>"random"</code>, <code>"beta"</code> and <code>"z"</code>, by
default equals <code>"random"</code>.</p>
</dd>
</dl>

<p>Class <code>"CTM_VEMcontrol"</code> extends classes
<code>"TopicModelcontrol"</code> and <code>"VEMcontrol"</code> and has the
additional slots
</p>

<dl>
<dt><code>cg</code>:</dt><dd><p>Object of class <code>"OPTcontrol"</code>; controls the
conjugate gradient iterations in fitting the variational mean and
variance per document, by default <code>iter.max</code> equals 500 and
<code>tol</code> 10^-5.</p>
</dd>
</dl>

<p>Class <code>"OPTcontrol"</code> contains
</p>

<dl>
<dt><code>iter.max</code>:</dt><dd><p>Object of class <code>"integer"</code>; maximum
number of iterations.</p>
</dd>
<dt><code>tol</code>:</dt><dd><p>Object of class <code>"numeric"</code>; tolerance for
convergence check.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Bettina Gruen</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
