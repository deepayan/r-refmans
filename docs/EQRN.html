<!DOCTYPE html><html lang="en"><head><title>Help for package EQRN</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EQRN}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EQRN-package'><p>EQRN: Extreme Quantile Regression Neural Networks for Risk Forecasting</p></a></li>
<li><a href='#batch_size_default'><p>Default batch size (internal)</p></a></li>
<li><a href='#check_directory'><p>Check directory existence</p></a></li>
<li><a href='#compute_EQRN_GPDLoss'><p>Generalized Pareto likelihood loss of a EQRN_iid predictor</p></a></li>
<li><a href='#compute_EQRN_seq_GPDLoss'><p>Generalized Pareto likelihood loss of a EQRN_seq predictor</p></a></li>
<li><a href='#decay_learning_rate'><p>Performs a learning rate decay step on an optimizer</p></a></li>
<li><a href='#default_device'><p>Default torch device</p></a></li>
<li><a href='#end_doFuture_strategy'><p>End the currently set doFuture strategy</p></a></li>
<li><a href='#EQRN_excess_probability'><p>Tail excess probability prediction using an EQRN_iid object</p></a></li>
<li><a href='#EQRN_excess_probability_seq'><p>Tail excess probability prediction using an EQRN_seq object</p></a></li>
<li><a href='#EQRN_fit'><p>EQRN fit function for independent data</p></a></li>
<li><a href='#EQRN_fit_restart'><p>Wrapper for fitting EQRN with restart for stability</p></a></li>
<li><a href='#EQRN_fit_seq'><p>EQRN fit function for sequential and time series data</p></a></li>
<li><a href='#EQRN_load'><p>Load an EQRN object from disc</p></a></li>
<li><a href='#EQRN_predict'><p>Predict function for an EQRN_iid fitted object</p></a></li>
<li><a href='#EQRN_predict_internal'><p>Internal predict function for an EQRN_iid</p></a></li>
<li><a href='#EQRN_predict_internal_seq'><p>Internal predict function for an EQRN_seq fitted object</p></a></li>
<li><a href='#EQRN_predict_params'><p>GPD parameters prediction function for an EQRN_iid fitted object</p></a></li>
<li><a href='#EQRN_predict_params_seq'><p>GPD parameters prediction function for an EQRN_seq fitted object</p></a></li>
<li><a href='#EQRN_predict_seq'><p>Predict function for an EQRN_seq fitted object</p></a></li>
<li><a href='#EQRN_save'><p>Save an EQRN object on disc</p></a></li>
<li><a href='#excess_probability'><p>Excess Probability Predictions</p></a></li>
<li><a href='#excess_probability.EQRN_iid'><p>Tail excess probability prediction method using an EQRN_iid object</p></a></li>
<li><a href='#excess_probability.EQRN_seq'><p>Tail excess probability prediction method using an EQRN_iid object</p></a></li>
<li><a href='#FC_GPD_net'><p>MLP module for GPD parameter prediction</p></a></li>
<li><a href='#FC_GPD_SNN'><p>Self-normalized fully-connected network module for GPD parameter prediction</p></a></li>
<li><a href='#fit_GPD_unconditional'><p>Maximum likelihood estimates for the GPD distribution using peaks over threshold</p></a></li>
<li><a href='#fix_dimsimplif'><p>(INTERNAL) Corrects a dimension simplification bug from the torch package</p></a></li>
<li><a href='#get_doFuture_operator'><p>Get doFuture operator</p></a></li>
<li><a href='#get_excesses'><p>Computes rescaled excesses over the conditional quantiles</p></a></li>
<li><a href='#GPD_excess_probability'><p>Tail excess probability prediction based on conditional GPD parameters</p></a></li>
<li><a href='#GPD_quantiles'><p>Compute extreme quantile from GPD parameters</p></a></li>
<li><a href='#install_backend'><p>Install Torch Backend</p></a></li>
<li><a href='#instantiate_EQRN_network'><p>Instantiates the default networks for training a EQRN_iid model</p></a></li>
<li><a href='#lagged_features'><p>Covariate lagged replication for temporal dependence</p></a></li>
<li><a href='#last_elem'><p>Last element of a vector</p></a></li>
<li><a href='#legacy_names'><p>Internal renaming function for back-compatibility</p></a></li>
<li><a href='#list2matrix'><p>Convert a list to a matrix</p></a></li>
<li><a href='#loss_GPD'><p>Generalized Pareto likelihood loss</p></a></li>
<li><a href='#loss_GPD_tensor'><p>GPD tensor loss function for training a EQRN network</p></a></li>
<li><a href='#make_folds'><p>Create cross-validation folds</p></a></li>
<li><a href='#mean_absolute_error'><p>Mean absolute error</p></a></li>
<li><a href='#mean_squared_error'><p>Mean squared error</p></a></li>
<li><a href='#mts_dataset'><p>Dataset creator for sequential data</p></a></li>
<li><a href='#multilevel_exceedance_proba_error'><p>Multilevel 'quantile_exceedance_proba_error'</p></a></li>
<li><a href='#multilevel_MAE'><p>Multilevel quantile MAEs</p></a></li>
<li><a href='#multilevel_MSE'><p>Multilevel quantile MSEs</p></a></li>
<li><a href='#multilevel_pred_bias'><p>Multilevel prediction bias</p></a></li>
<li><a href='#multilevel_prop_below'><p>Multilevel 'proportion_below'</p></a></li>
<li><a href='#multilevel_q_loss'><p>Multilevel quantile losses</p></a></li>
<li><a href='#multilevel_q_pred_error'><p>Multilevel 'quantile_prediction_error'</p></a></li>
<li><a href='#multilevel_R_squared'><p>Multilevel R squared</p></a></li>
<li><a href='#multilevel_resid_var'><p>Multilevel residual variance</p></a></li>
<li><a href='#nn_alpha_dropout'><p>Alpha-dropout module</p></a></li>
<li><a href='#nn_dropout_nd'><p>Dropout module</p></a></li>
<li><a href='#onload_backend_installer'><p>On-Load Torch Backend Internal Install helper</p></a></li>
<li><a href='#perform_scaling'><p>Performs feature scaling without overfitting</p></a></li>
<li><a href='#predict_GPD_semiconditional'><p>Predict semi-conditional extreme quantiles using peaks over threshold</p></a></li>
<li><a href='#predict_unconditional_quantiles'><p>Predict unconditional extreme quantiles using peaks over threshold</p></a></li>
<li><a href='#predict.EQRN_iid'><p>Predict method for an EQRN_iid fitted object</p></a></li>
<li><a href='#predict.EQRN_seq'><p>Predict method for an EQRN_seq fitted object</p></a></li>
<li><a href='#predict.QRN_seq'><p>Predict method for a QRN_seq fitted object</p></a></li>
<li><a href='#prediction_bias'><p>Prediction bias</p></a></li>
<li><a href='#prediction_residual_variance'><p>Prediction residual variance</p></a></li>
<li><a href='#process_features'><p>Feature processor for EQRN</p></a></li>
<li><a href='#proportion_below'><p>Proportion of observations below conditional quantile vector</p></a></li>
<li><a href='#QRN_fit_multiple'><p>Wrapper for fitting a recurrent QRN with restart for stability</p></a></li>
<li><a href='#QRN_seq_fit'><p>Recurrent QRN fitting function</p></a></li>
<li><a href='#QRN_seq_predict'><p>Predict function for a QRN_seq fitted object</p></a></li>
<li><a href='#QRN_seq_predict_foldwise'><p>Foldwise fit-predict function using a recurrent QRN</p></a></li>
<li><a href='#QRN_seq_predict_foldwise_sep'><p>Sigle-fold foldwise fit-predict function using a recurrent QRN</p></a></li>
<li><a href='#QRNN_RNN_net'><p>Recurrent quantile regression neural network module</p></a></li>
<li><a href='#quantile_exceedance_proba_error'><p>Quantile exceedance probability prediction calibration error</p></a></li>
<li><a href='#quantile_loss'><p>Quantile loss</p></a></li>
<li><a href='#quantile_loss_tensor'><p>Tensor quantile loss function for training a QRN network</p></a></li>
<li><a href='#quantile_prediction_error'><p>Quantile prediction calibration error</p></a></li>
<li><a href='#R_squared'><p>R squared</p></a></li>
<li><a href='#Recurrent_GPD_net'><p>Recurrent network module for GPD parameter prediction</p></a></li>
<li><a href='#roundm'><p>Mathematical number rounding</p></a></li>
<li><a href='#safe_save_rds'><p>Safe RDS save</p></a></li>
<li><a href='#semiconditional_train_valid_GPD_loss'><p>Semi-conditional GPD MLEs and their train-validation likelihoods</p></a></li>
<li><a href='#Separated_GPD_SNN'><p>Self-normalized separated network module for GPD parameter prediction</p></a></li>
<li><a href='#set_doFuture_strategy'><p>Set a doFuture execution strategy</p></a></li>
<li><a href='#setup_optimizer'><p>Instantiate an optimizer for training an EQRN_iid network</p></a></li>
<li><a href='#setup_optimizer_seq'><p>Instantiate an optimizer for training an EQRN_seq network</p></a></li>
<li><a href='#square_loss'><p>Square loss</p></a></li>
<li><a href='#unconditional_train_valid_GPD_loss'><p>Unconditional GPD MLEs and their train-validation likelihoods</p></a></li>
<li><a href='#vec2mat'><p>Convert a vector to a matrix</p></a></li>
<li><a href='#vector_insert'><p>Insert value in vector</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Extreme Quantile Regression Neural Networks for Risk Forecasting</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>This framework enables forecasting and extrapolating measures of conditional risk
    (e.g. of extreme or unprecedented events), including quantiles and exceedance probabilities,
    using extreme value statistics and flexible neural network architectures.
    It allows for capturing complex multivariate dependencies,
    including dependencies between observations, such as sequential dependence (time-series).
    The methodology was introduced in Pasche and Engelke (2024) &lt;<a href="https://doi.org/10.1214%2F24-AOAS1907">doi:10.1214/24-AOAS1907</a>&gt;
    (also available in preprint: Pasche and Engelke (2022) &lt;<a href="https://doi.org/10.48550%2FarXiv.2208.07590">doi:10.48550/arXiv.2208.07590</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>coro, doFuture, evd, foreach, future, ismev, magrittr, stats,
torch, utils</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/opasche/EQRN">https://github.com/opasche/EQRN</a>, <a href="https://opasche.github.io/EQRN/">https://opasche.github.io/EQRN/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/opasche/EQRN/issues">https://github.com/opasche/EQRN/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-14 15:35:01 UTC; pascheo</td>
</tr>
<tr>
<td>Author:</td>
<td>Olivier C. Pasche <a href="https://orcid.org/0000-0002-1202-9199"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Olivier C. Pasche &lt;olivier_pasche@alumni.epfl.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-17 20:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='EQRN-package'>EQRN: Extreme Quantile Regression Neural Networks for Risk Forecasting</h2><span id='topic+EQRN'></span><span id='topic+EQRN-package'></span>

<h3>Description</h3>

<p>This framework enables forecasting and extrapolating measures of conditional risk (e.g. of extreme or unprecedented events), including quantiles and exceedance probabilities, using extreme value statistics and flexible neural network architectures. It allows for capturing complex multivariate dependencies, including dependencies between observations, such as sequential dependence (time-series). The methodology was introduced in Pasche and Engelke (2024) <a href="https://doi.org/10.1214/24-AOAS1907">doi:10.1214/24-AOAS1907</a> (also available in preprint: Pasche and Engelke (2022) <a href="https://doi.org/10.48550/arXiv.2208.07590">doi:10.48550/arXiv.2208.07590</a>).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Olivier C. Pasche <a href="mailto:olivier_pasche@alumni.epfl.ch">olivier_pasche@alumni.epfl.ch</a> (<a href="https://orcid.org/0000-0002-1202-9199">ORCID</a>) [copyright holder]
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/opasche/EQRN">https://github.com/opasche/EQRN</a>
</p>
</li>
<li> <p><a href="https://opasche.github.io/EQRN/">https://opasche.github.io/EQRN/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/opasche/EQRN/issues">https://github.com/opasche/EQRN/issues</a>
</p>
</li></ul>


<hr>
<h2 id='batch_size_default'>Default batch size (internal)</h2><span id='topic+batch_size_default'></span>

<h3>Description</h3>

<p>Default batch size (internal)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batch_size_default(tensor_dat, batch_size = 256)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="batch_size_default_+3A_tensor_dat">tensor_dat</code></td>
<td>
<p>A <code><a href="torch.html#topic+dataset">torch::dataset()</a></code>.</p>
</td></tr>
<tr><td><code id="batch_size_default_+3A_batch_size">batch_size</code></td>
<td>
<p>An initial batch size, by default <code>256</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The fixed batch_size.
</p>

<hr>
<h2 id='check_directory'>Check directory existence</h2><span id='topic+check_directory'></span>

<h3>Description</h3>

<p>Checks if the desired directory exists. If not, the desired directory is created.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_directory(dir_name, recursive = TRUE, no_warning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_directory_+3A_dir_name">dir_name</code></td>
<td>
<p>Path to the desired directory, as a string.</p>
</td></tr>
<tr><td><code id="check_directory_+3A_recursive">recursive</code></td>
<td>
<p>Should elements of the path other than the last be created?
If <code>TRUE</code>, behaves like the Unix command <code>mkdir -p</code>.</p>
</td></tr>
<tr><td><code id="check_directory_+3A_no_warning">no_warning</code></td>
<td>
<p>Whether to cancel the warning issued if a directory is created (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
check_directory("./some_folder/my_new_folder")

</code></pre>

<hr>
<h2 id='compute_EQRN_GPDLoss'>Generalized Pareto likelihood loss of a EQRN_iid predictor</h2><span id='topic+compute_EQRN_GPDLoss'></span>

<h3>Description</h3>

<p>Generalized Pareto likelihood loss of a EQRN_iid predictor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_EQRN_GPDLoss(
  fit_eqrn,
  X,
  y,
  intermediate_quantiles = NULL,
  interm_lvl = fit_eqrn$interm_lvl,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_EQRN_GPDLoss_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_iid"</code> object.</p>
</td></tr>
<tr><td><code id="compute_EQRN_GPDLoss_+3A_x">X</code></td>
<td>
<p>Matrix of covariates.</p>
</td></tr>
<tr><td><code id="compute_EQRN_GPDLoss_+3A_y">y</code></td>
<td>
<p>Response variable vector.</p>
</td></tr>
<tr><td><code id="compute_EQRN_GPDLoss_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="compute_EQRN_GPDLoss_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="compute_EQRN_GPDLoss_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Negative GPD log likelihood of the conditional EQRN predicted parameters
over the response exceedances over the intermediate quantiles.
</p>

<hr>
<h2 id='compute_EQRN_seq_GPDLoss'>Generalized Pareto likelihood loss of a EQRN_seq predictor</h2><span id='topic+compute_EQRN_seq_GPDLoss'></span>

<h3>Description</h3>

<p>Generalized Pareto likelihood loss of a EQRN_seq predictor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_EQRN_seq_GPDLoss(
  fit_eqrn,
  X,
  Y,
  intermediate_quantiles = NULL,
  interm_lvl = fit_eqrn$interm_lvl,
  seq_len = fit_eqrn$seq_len,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_EQRN_seq_GPDLoss_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="compute_EQRN_seq_GPDLoss_+3A_x">X</code></td>
<td>
<p>Matrix of covariates.</p>
</td></tr>
<tr><td><code id="compute_EQRN_seq_GPDLoss_+3A_y">Y</code></td>
<td>
<p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</td></tr>
<tr><td><code id="compute_EQRN_seq_GPDLoss_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="compute_EQRN_seq_GPDLoss_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="compute_EQRN_seq_GPDLoss_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used to predict each response quantile.
By default, the training <code>fit_eqrn$seq_len</code> is used.</p>
</td></tr>
<tr><td><code id="compute_EQRN_seq_GPDLoss_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Negative GPD log likelihood of the conditional EQRN predicted parameters
over the response exceedances over the intermediate quantiles.
</p>

<hr>
<h2 id='decay_learning_rate'>Performs a learning rate decay step on an optimizer</h2><span id='topic+decay_learning_rate'></span>

<h3>Description</h3>

<p>Performs a learning rate decay step on an optimizer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decay_learning_rate(optimizer, decay_rate)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="decay_learning_rate_+3A_optimizer">optimizer</code></td>
<td>
<p>A <code>torch::optimizer</code> object.</p>
</td></tr>
<tr><td><code id="decay_learning_rate_+3A_decay_rate">decay_rate</code></td>
<td>
<p>Learning rate decay factor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>optimizer</code> with a decayed learning rate.
</p>

<hr>
<h2 id='default_device'>Default torch device</h2><span id='topic+default_device'></span>

<h3>Description</h3>

<p>Default torch device
</p>


<h3>Usage</h3>

<pre><code class='language-R'>default_device()
</code></pre>


<h3>Value</h3>

<p>Returns <code>torch::torch_device("cuda")</code> if <code>torch::cuda_is_available()</code>, or <code>torch::torch_device("cpu")</code> otherwise.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>device &lt;- default_device()
</code></pre>

<hr>
<h2 id='end_doFuture_strategy'>End the currently set doFuture strategy</h2><span id='topic+end_doFuture_strategy'></span>

<h3>Description</h3>

<p>Resets the default strategy using <code>future::plan("default")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>end_doFuture_strategy()
</code></pre>


<h3>Value</h3>

<p>No return value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
`%fun%` &lt;- set_doFuture_strategy("multisession", n_workers=3)
# perform foreach::foreach loop using the %fun% operator
end_doFuture_strategy()

</code></pre>

<hr>
<h2 id='EQRN_excess_probability'>Tail excess probability prediction using an EQRN_iid object</h2><span id='topic+EQRN_excess_probability'></span>

<h3>Description</h3>

<p>Tail excess probability prediction using an EQRN_iid object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_excess_probability(
  val,
  fit_eqrn,
  X,
  intermediate_quantiles,
  interm_lvl = fit_eqrn$interm_lvl,
  body_proba = "default",
  proba_type = c("excess", "cdf"),
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_excess_probability_+3A_val">val</code></td>
<td>
<p>Quantile value(s) used to estimate the conditional excess probability or cdf.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_iid"</code> object.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict the corresponding response's conditional excess probabilities.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_+3A_body_proba">body_proba</code></td>
<td>
<p>Value to use when the predicted conditional probability is below <code>interm_lvl</code>
(in which case it cannot be precisely assessed by the model).
If <code>"default"</code> is given (the default), <code>paste0("&gt;",1-interm_lvl)</code> is used if <code>proba_type=="excess"</code>,
and <code>paste0("&lt;",interm_lvl)</code> is used if <code>proba_type=="cdf"</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_+3A_proba_type">proba_type</code></td>
<td>
<p>Whether to return the <code>"excess"</code> probability over <code>val</code> (default) or the <code>"cdf"</code> at <code>val</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of probabilities (and possibly a few <code>body_proba</code> values if <code>val</code> is not large enough) of length <code>nrow(X)</code>.
</p>

<hr>
<h2 id='EQRN_excess_probability_seq'>Tail excess probability prediction using an EQRN_seq object</h2><span id='topic+EQRN_excess_probability_seq'></span>

<h3>Description</h3>

<p>Tail excess probability prediction using an EQRN_seq object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_excess_probability_seq(
  val,
  fit_eqrn,
  X,
  Y,
  intermediate_quantiles,
  interm_lvl = fit_eqrn$interm_lvl,
  crop_predictions = FALSE,
  body_proba = "default",
  proba_type = c("excess", "cdf"),
  seq_len = fit_eqrn$seq_len,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_excess_probability_seq_+3A_val">val</code></td>
<td>
<p>Quantile value(s) used to estimate the conditional excess probability or cdf.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict the response's conditional excess probabilities.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_y">Y</code></td>
<td>
<p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_crop_predictions">crop_predictions</code></td>
<td>
<p>Whether to crop out the fist <code>seq_len</code> observations (which are <code>NA</code>) from the returned vector</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_body_proba">body_proba</code></td>
<td>
<p>Value to use when the predicted conditional probability is below <code>interm_lvl</code>
(in which case it cannot be precisely assessed by the model).
If <code>"default"</code> is given (the default), <code>paste0("&gt;",1-interm_lvl)</code> is used if <code>proba_type=="excess"</code>,
and <code>paste0("&lt;",interm_lvl)</code> is used if <code>proba_type=="cdf"</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_proba_type">proba_type</code></td>
<td>
<p>Whether to return the <code>"excess"</code> probability over <code>val</code> (default) or the <code>"cdf"</code> at <code>val</code>.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used to predict each response quantile.
By default, the training <code>fit_eqrn$seq_len</code> is used.</p>
</td></tr>
<tr><td><code id="EQRN_excess_probability_seq_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of probabilities (and possibly a few <code>body_proba</code> values if <code>val</code> is not large enough) of length <code>nrow(X)</code>
(or <code>nrow(X)-seq_len</code> if <code>crop_predictions</code>).
</p>

<hr>
<h2 id='EQRN_fit'>EQRN fit function for independent data</h2><span id='topic+EQRN_fit'></span>

<h3>Description</h3>

<p>Use the <code><a href="#topic+EQRN_fit_restart">EQRN_fit_restart()</a></code> wrapper instead, with <code>data_type="iid"</code>, for better stability using fitting restart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_fit(
  X,
  y,
  intermediate_quantiles,
  interm_lvl,
  shape_fixed = FALSE,
  net_structure = c(5, 3, 3),
  hidden_fct = torch::nnf_sigmoid,
  p_drop = 0,
  intermediate_q_feature = TRUE,
  learning_rate = 1e-04,
  L2_pen = 0,
  shape_penalty = 0,
  scale_features = TRUE,
  n_epochs = 500,
  batch_size = 256,
  X_valid = NULL,
  y_valid = NULL,
  quant_valid = NULL,
  lr_decay = 1,
  patience_decay = n_epochs,
  min_lr = 0,
  patience_stop = n_epochs,
  tol = 1e-06,
  orthogonal_gpd = TRUE,
  patience_lag = 1,
  optim_met = "adam",
  seed = NULL,
  verbose = 2,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_fit_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, for training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_y">y</code></td>
<td>
<p>Response variable vector to model the extreme conditional quantile of, for training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Probability level for the intermediate quantiles <code>intermediate_quantiles</code>.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_shape_fixed">shape_fixed</code></td>
<td>
<p>Whether the shape estimate depends on the covariates or not (bool).</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_net_structure">net_structure</code></td>
<td>
<p>Vector of integers whose length determines the number of layers in the neural network
and entries the number of neurons in each corresponding successive layer.
If <code>hidden_fct=="SSNN"</code>, should instead be a named list with <code>"scale"</code> and <code>"shape"</code> vectors for the two respective sub-networks.
Can also be a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code> network with correct input and output dimensions,
which overrides the <code>hidden_fct</code>, <code>shape_fixed</code> and <code>p_drop</code> arguments.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_hidden_fct">hidden_fct</code></td>
<td>
<p>Activation function for the hidden layers. Can be either a callable function (preferably from the <code>torch</code> library),
or one of the the strings <code>"SNN"</code>, <code>"SSNN"</code> for self normalizing networks (with common or separated networks for the scale and shape estimates, respectively).
In the latter cases, <code>shape_fixed</code> has no effect.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_p_drop">p_drop</code></td>
<td>
<p>Probability parameter for dropout before each hidden layer for regularization during training.
<code>alpha-dropout</code> is used with SNNs.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_intermediate_q_feature">intermediate_q_feature</code></td>
<td>
<p>Whether to use the <code>intermediate_quantiles</code> as an additional covariate, by appending it to the <code>X</code> matrix (bool).</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Initial learning rate for the optimizer during training of the neural network.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_l2_pen">L2_pen</code></td>
<td>
<p>L2 weight penalty parameter for regularization during training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_shape_penalty">shape_penalty</code></td>
<td>
<p>Penalty parameter for the shape estimate, to potentially regularize its variation from the fixed prior estimate.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_scale_features">scale_features</code></td>
<td>
<p>Whether to rescale each input covariates to zero mean and unit variance before applying the network (recommended).</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_n_epochs">n_epochs</code></td>
<td>
<p>Number of training epochs.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_batch_size">batch_size</code></td>
<td>
<p>Batch size used during training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_x_valid">X_valid</code></td>
<td>
<p>Covariates in a validation set, or <code>NULL</code>.
Used for monitoring validation loss during training, enabling learning-rate decay and early stopping.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_y_valid">y_valid</code></td>
<td>
<p>Response variable in a validation set, or <code>NULL</code>.
Used for monitoring validation loss during training, enabling learning-rate decay and early stopping.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_quant_valid">quant_valid</code></td>
<td>
<p>Intermediate conditional quantiles at level <code>interm_lvl</code> in a validation set, or <code>NULL</code>.
Used for monitoring validation loss during training, enabling learning-rate decay and early stopping.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_lr_decay">lr_decay</code></td>
<td>
<p>Learning rate decay factor.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_patience_decay">patience_decay</code></td>
<td>
<p>Number of epochs of non-improving validation loss before a learning-rate decay is performed.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_min_lr">min_lr</code></td>
<td>
<p>Minimum learning rate, under which no more decay is performed.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_patience_stop">patience_stop</code></td>
<td>
<p>Number of epochs of non-improving validation loss before early stopping is performed.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_tol">tol</code></td>
<td>
<p>Tolerance for stopping training, in case of no significant training loss improvements.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_orthogonal_gpd">orthogonal_gpd</code></td>
<td>
<p>Whether to use the orthogonal reparametrization of the estimated GPD parameters (recommended).</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_patience_lag">patience_lag</code></td>
<td>
<p>The validation loss is considered to be non-improving if it is larger than on any of the previous <code>patience_lag</code> epochs.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_optim_met">optim_met</code></td>
<td>
<p>DEPRECATED. Optimization algorithm to use during training. <code>"adam"</code> is the default.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_seed">seed</code></td>
<td>
<p>Integer random seed for reproducibility in network weight initialization.</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_verbose">verbose</code></td>
<td>
<p>Amount of information printed during training (0:nothing, 1:most important, 2:everything).</p>
</td></tr>
<tr><td><code id="EQRN_fit_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An EQRN object of classes <code>c("EQRN_iid", "EQRN")</code>, containing the fitted network,
as well as all the relevant information for its usage in other functions.
</p>

<hr>
<h2 id='EQRN_fit_restart'>Wrapper for fitting EQRN with restart for stability</h2><span id='topic+EQRN_fit_restart'></span>

<h3>Description</h3>

<p>Wrapper for fitting EQRN with restart for stability
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_fit_restart(
  X,
  y,
  intermediate_quantiles,
  interm_lvl,
  number_fits = 3,
  ...,
  seed = NULL,
  data_type = c("iid", "seq")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_fit_restart_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, for training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_restart_+3A_y">y</code></td>
<td>
<p>Response variable vector to model the extreme conditional quantile of, for training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_restart_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_fit_restart_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Probability level for the intermediate quantiles <code>intermediate_quantiles</code>.</p>
</td></tr>
<tr><td><code id="EQRN_fit_restart_+3A_number_fits">number_fits</code></td>
<td>
<p>Number of restarts.</p>
</td></tr>
<tr><td><code id="EQRN_fit_restart_+3A_...">...</code></td>
<td>
<p>Other parameters given to either <code><a href="#topic+EQRN_fit">EQRN_fit()</a></code> or <code><a href="#topic+EQRN_fit_seq">EQRN_fit_seq()</a></code>, depending on the <code>data_type</code>.</p>
</td></tr>
<tr><td><code id="EQRN_fit_restart_+3A_seed">seed</code></td>
<td>
<p>Integer random seed for reproducibility in network weight initialization.</p>
</td></tr>
<tr><td><code id="EQRN_fit_restart_+3A_data_type">data_type</code></td>
<td>
<p>Type of data dependence, must be one of <code>"iid"</code> (for iid observations) or <code>"seq"</code> (for sequentially dependent observations).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An EQRN object of classes <code>c("EQRN_iid", "EQRN")</code>, if <code style="white-space: pre;">&#8288;data_type=="iid",&#8288;</code> or <code>c("EQRN_seq", "EQRN")</code>, if 'data_type==&quot;seq&quot;,
containing the fitted network, as well as all the relevant information for its usage in other functions.
</p>

<hr>
<h2 id='EQRN_fit_seq'>EQRN fit function for sequential and time series data</h2><span id='topic+EQRN_fit_seq'></span>

<h3>Description</h3>

<p>Use the <code><a href="#topic+EQRN_fit_restart">EQRN_fit_restart()</a></code> wrapper instead, with <code>data_type="seq"</code>, for better stability using fitting restart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_fit_seq(
  X,
  y,
  intermediate_quantiles,
  interm_lvl,
  shape_fixed = FALSE,
  hidden_size = 10,
  num_layers = 1,
  rnn_type = c("lstm", "gru"),
  p_drop = 0,
  intermediate_q_feature = TRUE,
  learning_rate = 1e-04,
  L2_pen = 0,
  seq_len = 10,
  shape_penalty = 0,
  scale_features = TRUE,
  n_epochs = 500,
  batch_size = 256,
  X_valid = NULL,
  y_valid = NULL,
  quant_valid = NULL,
  lr_decay = 1,
  patience_decay = n_epochs,
  min_lr = 0,
  patience_stop = n_epochs,
  tol = 1e-05,
  orthogonal_gpd = TRUE,
  patience_lag = 1,
  fold_separation = NULL,
  optim_met = "adam",
  seed = NULL,
  verbose = 2,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_fit_seq_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_y">y</code></td>
<td>
<p>Response variable vector to model the extreme conditional quantile of, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Probability level for the intermediate quantiles <code>intermediate_quantiles</code>.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_shape_fixed">shape_fixed</code></td>
<td>
<p>Whether the shape estimate depends on the covariates or not (bool).</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_hidden_size">hidden_size</code></td>
<td>
<p>Dimension of the hidden latent state variables in the recurrent network.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_num_layers">num_layers</code></td>
<td>
<p>Number of recurrent layers.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_rnn_type">rnn_type</code></td>
<td>
<p>Type of recurrent architecture, can be one of <code>"lstm"</code> (default) or <code>"gru"</code>.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_p_drop">p_drop</code></td>
<td>
<p>Probability parameter for dropout before each hidden layer for regularization during training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_intermediate_q_feature">intermediate_q_feature</code></td>
<td>
<p>Whether to use the <code>intermediate_quantiles</code> as an additional covariate, by appending it to the <code>X</code> matrix (bool).</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Initial learning rate for the optimizer during training of the neural network.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_l2_pen">L2_pen</code></td>
<td>
<p>L2 weight penalty parameter for regularization during training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used during training to predict each response quantile.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_shape_penalty">shape_penalty</code></td>
<td>
<p>Penalty parameter for the shape estimate, to potentially regularize its variation from the fixed prior estimate.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_scale_features">scale_features</code></td>
<td>
<p>Whether to rescale each input covariates to zero mean and unit covariance before applying the network (recommended).</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_n_epochs">n_epochs</code></td>
<td>
<p>Number of training epochs.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_batch_size">batch_size</code></td>
<td>
<p>Batch size used during training.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_x_valid">X_valid</code></td>
<td>
<p>Covariates in a validation set, or <code>NULL</code>. Entries must be in sequential order.
Used for monitoring validation loss during training, enabling learning-rate decay and early stopping.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_y_valid">y_valid</code></td>
<td>
<p>Response variable in a validation set, or <code>NULL</code>. Entries must be in sequential order.
Used for monitoring validation loss during training, enabling learning-rate decay and early stopping.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_quant_valid">quant_valid</code></td>
<td>
<p>Intermediate conditional quantiles at level <code>interm_lvl</code> in a validation set, or <code>NULL</code>.
Used for monitoring validation loss during training, enabling learning-rate decay and early stopping.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_lr_decay">lr_decay</code></td>
<td>
<p>Learning rate decay factor.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_patience_decay">patience_decay</code></td>
<td>
<p>Number of epochs of non-improving validation loss before a learning-rate decay is performed.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_min_lr">min_lr</code></td>
<td>
<p>Minimum learning rate, under which no more decay is performed.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_patience_stop">patience_stop</code></td>
<td>
<p>Number of epochs of non-improving validation loss before early stopping is performed.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_tol">tol</code></td>
<td>
<p>Tolerance for stopping training, in case of no significant training loss improvements.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_orthogonal_gpd">orthogonal_gpd</code></td>
<td>
<p>Whether to use the orthogonal reparametrization of the estimated GPD parameters (recommended).</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_patience_lag">patience_lag</code></td>
<td>
<p>The validation loss is considered to be non-improving
if it is larger than on any of the previous <code>patience_lag</code> epochs.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_fold_separation">fold_separation</code></td>
<td>
<p>Index of fold separation or sequential discontinuity in the data.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_optim_met">optim_met</code></td>
<td>
<p>DEPRECATED. Optimization algorithm to use during training. <code>"adam"</code> is the default.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_seed">seed</code></td>
<td>
<p>Integer random seed for reproducibility in network weight initialization.</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_verbose">verbose</code></td>
<td>
<p>Amount of information printed during training (0:nothing, 1:most important, 2:everything).</p>
</td></tr>
<tr><td><code id="EQRN_fit_seq_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An EQRN object of classes <code>c("EQRN_seq", "EQRN")</code>, containing the fitted network,
as well as all the relevant information for its usage in other functions.
</p>

<hr>
<h2 id='EQRN_load'>Load an EQRN object from disc</h2><span id='topic+EQRN_load'></span>

<h3>Description</h3>

<p>Loads in memory an <code>"EQRN"</code> object that has previously been saved on disc using <code><a href="#topic+EQRN_save">EQRN_save()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_load(path, name = NULL, device = default_device(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_load_+3A_path">path</code></td>
<td>
<p>Path to the save location as a string.</p>
</td></tr>
<tr><td><code id="EQRN_load_+3A_name">name</code></td>
<td>
<p>String name of the save.
If <code>NULL</code> (default), assumes the save name has been given implicitly in the <code>path</code>.</p>
</td></tr>
<tr><td><code id="EQRN_load_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
<tr><td><code id="EQRN_load_+3A_...">...</code></td>
<td>
<p>DEPRECATED. Used for back-compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The loaded <code>"EQRN"</code> model.
</p>

<hr>
<h2 id='EQRN_predict'>Predict function for an EQRN_iid fitted object</h2><span id='topic+EQRN_predict'></span>

<h3>Description</h3>

<p>Predict function for an EQRN_iid fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_predict(
  fit_eqrn,
  X,
  prob_lvls_predict,
  intermediate_quantiles,
  interm_lvl = fit_eqrn$interm_lvl,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_predict_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_iid"</code> object.</p>
</td></tr>
<tr><td><code id="EQRN_predict_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict the corresponding response's conditional quantiles.</p>
</td></tr>
<tr><td><code id="EQRN_predict_+3A_prob_lvls_predict">prob_lvls_predict</code></td>
<td>
<p>Vector of probability levels at which to predict the conditional quantiles.</p>
</td></tr>
<tr><td><code id="EQRN_predict_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of size <code>nrow(X)</code> times <code>prob_lvls_predict</code>
containing the conditional quantile estimates of the response associated to each covariate observation at each probability level.
Simplifies to a vector if <code>length(prob_lvls_predict)==1</code>.
</p>

<hr>
<h2 id='EQRN_predict_internal'>Internal predict function for an EQRN_iid</h2><span id='topic+EQRN_predict_internal'></span>

<h3>Description</h3>

<p>Internal predict function for an EQRN_iid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_predict_internal(
  fit_eqrn,
  X,
  prob_lvl_predict,
  intermediate_quantiles,
  interm_lvl,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_predict_internal_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_iid"</code> object.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict the corresponding response's conditional quantiles.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_+3A_prob_lvl_predict">prob_lvl_predict</code></td>
<td>
<p>Probability level at which to predict the conditional quantiles.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of length <code>nrow(X)</code> containing the conditional quantile estimates of the response associated to each covariate observation
at each probability level <code>prob_lvl_predict</code>.
</p>

<hr>
<h2 id='EQRN_predict_internal_seq'>Internal predict function for an EQRN_seq fitted object</h2><span id='topic+EQRN_predict_internal_seq'></span>

<h3>Description</h3>

<p>Internal predict function for an EQRN_seq fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_predict_internal_seq(
  fit_eqrn,
  X,
  Y,
  prob_lvl_predict,
  intermediate_quantiles,
  interm_lvl,
  crop_predictions = FALSE,
  seq_len = fit_eqrn$seq_len,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_predict_internal_seq_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_seq_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict the corresponding response's conditional quantiles.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_seq_+3A_y">Y</code></td>
<td>
<p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_seq_+3A_prob_lvl_predict">prob_lvl_predict</code></td>
<td>
<p>Probability level at which to predict the conditional quantile.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_seq_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_seq_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_seq_+3A_crop_predictions">crop_predictions</code></td>
<td>
<p>Whether to crop out the fist <code>seq_len</code> observations (which are <code>NA</code>) from the returned vector</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_seq_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used to predict each response quantile.
By default, the training <code>fit_eqrn$seq_len</code> is used.</p>
</td></tr>
<tr><td><code id="EQRN_predict_internal_seq_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of length <code>nrow(X)</code> (or <code>nrow(X)-seq_len</code> if <code>crop_predictions</code>)
containing the conditional quantile estimates of the response associated to each covariate observation at each probability level.
</p>

<hr>
<h2 id='EQRN_predict_params'>GPD parameters prediction function for an EQRN_iid fitted object</h2><span id='topic+EQRN_predict_params'></span>

<h3>Description</h3>

<p>GPD parameters prediction function for an EQRN_iid fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_predict_params(
  fit_eqrn,
  X,
  intermediate_quantiles = NULL,
  return_parametrization = c("classical", "orthogonal"),
  interm_lvl = fit_eqrn$interm_lvl,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_predict_params_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_iid"</code> object.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict conditional GPD parameters.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_+3A_return_parametrization">return_parametrization</code></td>
<td>
<p>Which parametrization to return the parameters in, either <code>"classical"</code> or <code>"orthogonal"</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing: <code>"scales"</code> and <code>"shapes"</code> as numerical vectors of length <code>nrow(X)</code>.
</p>

<hr>
<h2 id='EQRN_predict_params_seq'>GPD parameters prediction function for an EQRN_seq fitted object</h2><span id='topic+EQRN_predict_params_seq'></span>

<h3>Description</h3>

<p>GPD parameters prediction function for an EQRN_seq fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_predict_params_seq(
  fit_eqrn,
  X,
  Y,
  intermediate_quantiles = NULL,
  return_parametrization = c("classical", "orthogonal"),
  interm_lvl = fit_eqrn$interm_lvl,
  seq_len = fit_eqrn$seq_len,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_predict_params_seq_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_seq_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict conditional GPD parameters.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_seq_+3A_y">Y</code></td>
<td>
<p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_seq_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_seq_+3A_return_parametrization">return_parametrization</code></td>
<td>
<p>Which parametrization to return the parameters in, either <code>"classical"</code> or <code>"orthogonal"</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_seq_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_seq_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used to predict each response quantile.
By default, the training <code>fit_eqrn$seq_len</code> is used.</p>
</td></tr>
<tr><td><code id="EQRN_predict_params_seq_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing: <code>"scales"</code> and <code>"shapes"</code> as numerical vectors of length <code>nrow(X)</code>,
and the <code>seq_len</code> used.
</p>

<hr>
<h2 id='EQRN_predict_seq'>Predict function for an EQRN_seq fitted object</h2><span id='topic+EQRN_predict_seq'></span>

<h3>Description</h3>

<p>Predict function for an EQRN_seq fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_predict_seq(
  fit_eqrn,
  X,
  Y,
  prob_lvls_predict,
  intermediate_quantiles,
  interm_lvl,
  crop_predictions = FALSE,
  seq_len = fit_eqrn$seq_len,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_predict_seq_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>Fitted <code>"EQRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="EQRN_predict_seq_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict the corresponding response's conditional quantiles.</p>
</td></tr>
<tr><td><code id="EQRN_predict_seq_+3A_y">Y</code></td>
<td>
<p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_seq_+3A_prob_lvls_predict">prob_lvls_predict</code></td>
<td>
<p>Vector of probability levels at which to predict the conditional quantiles.</p>
</td></tr>
<tr><td><code id="EQRN_predict_seq_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_seq_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="EQRN_predict_seq_+3A_crop_predictions">crop_predictions</code></td>
<td>
<p>Whether to crop out the fist <code>seq_len</code> observations (which are <code>NA</code>) from the returned matrix.</p>
</td></tr>
<tr><td><code id="EQRN_predict_seq_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used to predict each response quantile.
By default, the training <code>fit_eqrn$seq_len</code> is used.</p>
</td></tr>
<tr><td><code id="EQRN_predict_seq_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of size <code>nrow(X)</code> times <code>prob_lvls_predict</code>
(or <code>nrow(X)-seq_len</code> times <code>prob_lvls_predict</code> if <code>crop_predictions</code>)
containing the conditional quantile estimates of the corresponding response observations at each probability level.
Simplifies to a vector if <code>length(prob_lvls_predict)==1</code>.
</p>

<hr>
<h2 id='EQRN_save'>Save an EQRN object on disc</h2><span id='topic+EQRN_save'></span>

<h3>Description</h3>

<p>Creates a folder named <code>name</code> and located in <code>path</code>, containing binary save files,
so that the given <code>"EQRN"</code> object <code>fit_eqrn</code> can be loaded back in memory from disc using <code><a href="#topic+EQRN_load">EQRN_load()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQRN_save(fit_eqrn, path, name = NULL, no_warning = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EQRN_save_+3A_fit_eqrn">fit_eqrn</code></td>
<td>
<p>An <code>"EQRN"</code> object</p>
</td></tr>
<tr><td><code id="EQRN_save_+3A_path">path</code></td>
<td>
<p>Path to save folder as a string.</p>
</td></tr>
<tr><td><code id="EQRN_save_+3A_name">name</code></td>
<td>
<p>String name of the save.</p>
</td></tr>
<tr><td><code id="EQRN_save_+3A_no_warning">no_warning</code></td>
<td>
<p>Whether to silence the warning raised if a save folder needed beeing created (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>

<hr>
<h2 id='excess_probability'>Excess Probability Predictions</h2><span id='topic+excess_probability'></span>

<h3>Description</h3>

<p>A generic function (method) for excess probability predictions from various fitted EQR models.
The function invokes particular methods which depend on the class of the first argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>excess_probability(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="excess_probability_+3A_object">object</code></td>
<td>
<p>A model object for which excess probability prediction is desired.</p>
</td></tr>
<tr><td><code id="excess_probability_+3A_...">...</code></td>
<td>
<p>additional model-specific arguments affecting the predictions produced.
See the corresponding method documentation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The excess probability estimates from the given EQR model.
</p>

<hr>
<h2 id='excess_probability.EQRN_iid'>Tail excess probability prediction method using an EQRN_iid object</h2><span id='topic+excess_probability.EQRN_iid'></span>

<h3>Description</h3>

<p>Tail excess probability prediction method using an EQRN_iid object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EQRN_iid'
excess_probability(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="excess_probability.EQRN_iid_+3A_object">object</code></td>
<td>
<p>Fitted <code>"EQRN_iid"</code> object.</p>
</td></tr>
<tr><td><code id="excess_probability.EQRN_iid_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+EQRN_excess_probability">EQRN_excess_probability</a></code>
</p>

<dl>
<dt><code>val</code></dt><dd><p>Quantile value(s) used to estimate the conditional excess probability or cdf.</p>
</dd>
<dt><code>X</code></dt><dd><p>Matrix of covariates to predict the corresponding response's conditional excess probabilities.</p>
</dd>
<dt><code>intermediate_quantiles</code></dt><dd><p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</dd>
<dt><code>interm_lvl</code></dt><dd><p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</dd>
<dt><code>body_proba</code></dt><dd><p>Value to use when the predicted conditional probability is below <code>interm_lvl</code>
(in which case it cannot be precisely assessed by the model).
If <code>"default"</code> is given (the default), <code>paste0("&gt;",1-interm_lvl)</code> is used if <code>proba_type=="excess"</code>,
and <code>paste0("&lt;",interm_lvl)</code> is used if <code>proba_type=="cdf"</code>.</p>
</dd>
<dt><code>proba_type</code></dt><dd><p>Whether to return the <code>"excess"</code> probability over <code>val</code> (default) or the <code>"cdf"</code> at <code>val</code>.</p>
</dd>
<dt><code>device</code></dt><dd><p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+EQRN_excess_probability">EQRN_excess_probability()</a></code> for more details.
</p>


<h3>Value</h3>

<p>Vector of probabilities (and possibly a few <code>body_proba</code> values if <code>val</code> is not large enough) of length <code>nrow(X)</code>.
</p>

<hr>
<h2 id='excess_probability.EQRN_seq'>Tail excess probability prediction method using an EQRN_iid object</h2><span id='topic+excess_probability.EQRN_seq'></span>

<h3>Description</h3>

<p>Tail excess probability prediction method using an EQRN_iid object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EQRN_seq'
excess_probability(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="excess_probability.EQRN_seq_+3A_object">object</code></td>
<td>
<p>Fitted <code>"EQRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="excess_probability.EQRN_seq_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+EQRN_excess_probability_seq">EQRN_excess_probability_seq</a></code>
</p>

<dl>
<dt><code>val</code></dt><dd><p>Quantile value(s) used to estimate the conditional excess probability or cdf.</p>
</dd>
<dt><code>X</code></dt><dd><p>Matrix of covariates to predict the response's conditional excess probabilities.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</dd>
<dt><code>intermediate_quantiles</code></dt><dd><p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</dd>
<dt><code>interm_lvl</code></dt><dd><p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</dd>
<dt><code>crop_predictions</code></dt><dd><p>Whether to crop out the fist <code>seq_len</code> observations (which are <code>NA</code>) from the returned vector</p>
</dd>
<dt><code>body_proba</code></dt><dd><p>Value to use when the predicted conditional probability is below <code>interm_lvl</code>
(in which case it cannot be precisely assessed by the model).
If <code>"default"</code> is given (the default), <code>paste0("&gt;",1-interm_lvl)</code> is used if <code>proba_type=="excess"</code>,
and <code>paste0("&lt;",interm_lvl)</code> is used if <code>proba_type=="cdf"</code>.</p>
</dd>
<dt><code>proba_type</code></dt><dd><p>Whether to return the <code>"excess"</code> probability over <code>val</code> (default) or the <code>"cdf"</code> at <code>val</code>.</p>
</dd>
<dt><code>seq_len</code></dt><dd><p>Data sequence length (i.e. number of past observations) used to predict each response quantile.
By default, the training <code>fit_eqrn$seq_len</code> is used.</p>
</dd>
<dt><code>device</code></dt><dd><p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+EQRN_excess_probability_seq">EQRN_excess_probability_seq()</a></code> for more details.
</p>


<h3>Value</h3>

<p>Vector of probabilities (and possibly a few <code>body_proba</code> values if <code>val</code> is not large enough) of length <code>nrow(X)</code>
(or <code>nrow(X)-seq_len</code> if <code>crop_predictions</code>).
</p>

<hr>
<h2 id='FC_GPD_net'>MLP module for GPD parameter prediction</h2><span id='topic+FC_GPD_net'></span>

<h3>Description</h3>

<p>A fully-connected network (or multi-layer perception) as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>,
designed for generalized Pareto distribution parameter prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FC_GPD_net(
  D_in,
  Hidden_vect = c(5, 5, 5),
  activation = torch::nnf_sigmoid,
  p_drop = 0,
  shape_fixed = FALSE,
  device = EQRN::default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FC_GPD_net_+3A_d_in">D_in</code></td>
<td>
<p>the input size (i.e. the number of features),</p>
</td></tr>
<tr><td><code id="FC_GPD_net_+3A_hidden_vect">Hidden_vect</code></td>
<td>
<p>a vector of integers whose length determines the number of layers in the neural network
and entries the number of neurons in each corresponding successive layer,</p>
</td></tr>
<tr><td><code id="FC_GPD_net_+3A_activation">activation</code></td>
<td>
<p>the activation function for the hidden layers
(should be either a callable function, preferably from the <code>torch</code> library),</p>
</td></tr>
<tr><td><code id="FC_GPD_net_+3A_p_drop">p_drop</code></td>
<td>
<p>probability parameter for dropout before each hidden layer for regularization during training,</p>
</td></tr>
<tr><td><code id="FC_GPD_net_+3A_shape_fixed">shape_fixed</code></td>
<td>
<p>whether the shape estimate depends on the covariates or not (bool),</p>
</td></tr>
<tr><td><code id="FC_GPD_net_+3A_device">device</code></td>
<td>
<p>a <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code> for an internal constant vector. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constructor allows specifying:
</p>

<dl>
<dt>D_in</dt><dd><p>the input size (i.e. the number of features),</p>
</dd>
<dt>Hidden_vect</dt><dd><p>a vector of integers whose length determines the number of layers in the neural network
and entries the number of neurons in each corresponding successive layer,</p>
</dd>
<dt>activation</dt><dd><p>the activation function for the hidden layers
(should be either a callable function, preferably from the <code>torch</code> library),</p>
</dd>
<dt>p_drop</dt><dd><p>probability parameter for dropout before each hidden layer for regularization during training,</p>
</dd>
<dt>shape_fixed</dt><dd><p>whether the shape estimate depends on the covariates or not (bool),</p>
</dd>
<dt>device</dt><dd><p>a <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code> for an internal constant vector. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The specified MLP GPD network as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>.
</p>

<hr>
<h2 id='FC_GPD_SNN'>Self-normalized fully-connected network module for GPD parameter prediction</h2><span id='topic+FC_GPD_SNN'></span>

<h3>Description</h3>

<p>A fully-connected self-normalizing network as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>,
designed for generalized Pareto distribution parameter prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FC_GPD_SNN(D_in, Hidden_vect = c(64, 64, 64), p_drop = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FC_GPD_SNN_+3A_d_in">D_in</code></td>
<td>
<p>the input size (i.e. the number of features),</p>
</td></tr>
<tr><td><code id="FC_GPD_SNN_+3A_hidden_vect">Hidden_vect</code></td>
<td>
<p>a vector of integers whose length determines the number of layers in the neural network
and entries the number of neurons in each corresponding successive layer,</p>
</td></tr>
<tr><td><code id="FC_GPD_SNN_+3A_p_drop">p_drop</code></td>
<td>
<p>probability parameter for the <code>alpha-dropout</code> before each hidden layer for regularization during training.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constructor allows specifying:
</p>

<dl>
<dt>D_in</dt><dd><p>the input size (i.e. the number of features),</p>
</dd>
<dt>Hidden_vect</dt><dd><p>a vector of integers whose length determines the number of layers in the neural network
and entries the number of neurons in each corresponding successive layer,</p>
</dd>
<dt>p_drop</dt><dd><p>probability parameter for the <code>alpha-dropout</code> before each hidden layer for regularization during training.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The specified SNN MLP GPD network as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>.
</p>


<h3>References</h3>

<p>Gunter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter. Self-Normalizing Neural Networks.
Advances in Neural Information Processing Systems 30 (NIPS 2017), 2017.
</p>

<hr>
<h2 id='fit_GPD_unconditional'>Maximum likelihood estimates for the GPD distribution using peaks over threshold</h2><span id='topic+fit_GPD_unconditional'></span>

<h3>Description</h3>

<p>Maximum likelihood estimates for the GPD distribution using peaks over threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_GPD_unconditional(Y, interm_lvl = NULL, thresh_quantiles = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_GPD_unconditional_+3A_y">Y</code></td>
<td>
<p>Vector of observations</p>
</td></tr>
<tr><td><code id="fit_GPD_unconditional_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Probability level at which the empirical quantile should be used as the threshold,
if <code>thresh_quantiles</code> is not given.</p>
</td></tr>
<tr><td><code id="fit_GPD_unconditional_+3A_thresh_quantiles">thresh_quantiles</code></td>
<td>
<p>Numerical value or numerical vector of the same length as <code>Y</code>
representing either a fixed or a varying threshold, respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing:
</p>
<table role = "presentation">
<tr><td><code>scale</code></td>
<td>
<p>the GPD scale MLE,</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>
<p>the GPD shape MLE,</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>the fitted <code><a href="ismev.html#topic+gpd.fit">ismev::gpd.fit()</a></code> object.</p>
</td></tr>
</table>

<hr>
<h2 id='fix_dimsimplif'>(INTERNAL) Corrects a dimension simplification bug from the torch package</h2><span id='topic+fix_dimsimplif'></span>

<h3>Description</h3>

<p>(INTERNAL) Issue was raised to the <code>torch</code> maintainers and should be fixed, deprecating this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fix_dimsimplif(dl_i, ..., responses = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fix_dimsimplif_+3A_dl_i">dl_i</code></td>
<td>
<p>batch object from an itteration over a <code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code>.</p>
</td></tr>
<tr><td><code id="fix_dimsimplif_+3A_...">...</code></td>
<td>
<p>dimension(s) of the covariate object (excluding the first &quot;batch&quot; dimension)</p>
</td></tr>
<tr><td><code id="fix_dimsimplif_+3A_responses">responses</code></td>
<td>
<p>Bolean indicating whether the batch object <code>dl_i</code> is a covariates-response pair.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The fixed dl_i object
</p>

<hr>
<h2 id='get_doFuture_operator'>Get doFuture operator</h2><span id='topic+get_doFuture_operator'></span>

<h3>Description</h3>

<p>Get doFuture operator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_doFuture_operator(
  strategy = c("sequential", "multisession", "multicore", "mixed")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_doFuture_operator_+3A_strategy">strategy</code></td>
<td>
<p>One of <code>"sequential"</code> (default), <code>"multisession"</code>, <code>"multicore"</code>, or <code>"mixed"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the appropriate operator to use in a <code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code> loop.
The <code><a href="foreach.html#topic++25do+25">%do%</a></code> operator is returned if <code>strategy=="sequential"</code>.
Otherwise, the <code><a href="foreach.html#topic++25dopar+25">%dopar%</a></code> operator is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>`%fun%` &lt;- get_doFuture_operator("sequential")
</code></pre>

<hr>
<h2 id='get_excesses'>Computes rescaled excesses over the conditional quantiles</h2><span id='topic+get_excesses'></span>

<h3>Description</h3>

<p>Computes rescaled excesses over the conditional quantiles
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_excesses(
  X = NULL,
  y,
  quantiles,
  intermediate_q_feature = FALSE,
  scale_features = FALSE,
  X_scaling = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_excesses_+3A_x">X</code></td>
<td>
<p>A covariate matrix. Can be <code>NULL</code> if there are no covariates.</p>
</td></tr>
<tr><td><code id="get_excesses_+3A_y">y</code></td>
<td>
<p>The response variable vector.</p>
</td></tr>
<tr><td><code id="get_excesses_+3A_quantiles">quantiles</code></td>
<td>
<p>The intermediate quantiles over which to compute the excesses of <code>y</code>.</p>
</td></tr>
<tr><td><code id="get_excesses_+3A_intermediate_q_feature">intermediate_q_feature</code></td>
<td>
<p>Whether to use the intermediate <code>quantiles</code> as an additional covariate,
by appending it to the <code>X</code> matrix (bool).</p>
</td></tr>
<tr><td><code id="get_excesses_+3A_scale_features">scale_features</code></td>
<td>
<p>Whether to rescale each input covariates to zero mean and unit variance before applying the network (recommended).
If <code>X_scaling</code> is given, <code>X_scaling$scaling</code> overrides <code>scale_features</code>.</p>
</td></tr>
<tr><td><code id="get_excesses_+3A_x_scaling">X_scaling</code></td>
<td>
<p>Existing <code>"X_scaling"</code> object containing the precomputed mean and variance for each covariate.
This enables reusing the scaling choice and parameters from the train set, if computing the excesses on a validation or test set,
in order to avoid overfitting. This is performed automatically in the <code>"EQRN"</code> objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing:
</p>
<table role = "presentation">
<tr><td><code>Y_excesses</code></td>
<td>
<p>thematrix of response excesses,</p>
</td></tr>
<tr><td><code>X_excesses</code></td>
<td>
<p>the (possibly rescaled and q_feat transformed) covariate matrix,</p>
</td></tr>
<tr><td><code>X_scaling</code></td>
<td>
<p>object of class <code>"X_scaling"</code> to use for consistent scaling on future datasets,</p>
</td></tr>
<tr><td><code>excesses_ratio</code></td>
<td>
<p>and the ratio of escesses for troubleshooting.</p>
</td></tr>
</table>

<hr>
<h2 id='GPD_excess_probability'>Tail excess probability prediction based on conditional GPD parameters</h2><span id='topic+GPD_excess_probability'></span>

<h3>Description</h3>

<p>Tail excess probability prediction based on conditional GPD parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GPD_excess_probability(
  val,
  sigma,
  xi,
  interm_threshold,
  threshold_p,
  body_proba = "default",
  proba_type = c("excess", "cdf")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GPD_excess_probability_+3A_val">val</code></td>
<td>
<p>Quantile value(s) used to estimate the conditional excess probability or cdf.</p>
</td></tr>
<tr><td><code id="GPD_excess_probability_+3A_sigma">sigma</code></td>
<td>
<p>Value(s) for the GPD scale parameter.</p>
</td></tr>
<tr><td><code id="GPD_excess_probability_+3A_xi">xi</code></td>
<td>
<p>Value(s) for the GPD shape parameter.</p>
</td></tr>
<tr><td><code id="GPD_excess_probability_+3A_interm_threshold">interm_threshold</code></td>
<td>
<p>Intermediate (conditional) quantile(s) at level <code>threshold_p</code> used as a (varying) threshold.</p>
</td></tr>
<tr><td><code id="GPD_excess_probability_+3A_threshold_p">threshold_p</code></td>
<td>
<p>Probability level of the intermediate conditional quantiles <code>interm_threshold</code>.</p>
</td></tr>
<tr><td><code id="GPD_excess_probability_+3A_body_proba">body_proba</code></td>
<td>
<p>Value to use when the predicted conditional probability is below <code>threshold_p</code>
(in which case it cannot be precisely assessed by the model).
If <code>"default"</code> is given (the default), <code>paste0("&gt;",1-threshold_p)</code> is used if <code>proba_type=="excess"</code>,
and <code>paste0("&lt;",threshold_p)</code> is used if <code>proba_type=="cdf"</code>.</p>
</td></tr>
<tr><td><code id="GPD_excess_probability_+3A_proba_type">proba_type</code></td>
<td>
<p>Whether to return the <code>"excess"</code> probability over <code>val</code> (default) or the <code>"cdf"</code> at <code>val</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of probabilities (and possibly a few <code>body_proba</code> values if <code>val</code> is not large enough)
of the same length as the longest vector between <code>val</code>, <code>sigma</code>, <code>xi</code> and <code>interm_threshold</code>.
</p>

<hr>
<h2 id='GPD_quantiles'>Compute extreme quantile from GPD parameters</h2><span id='topic+GPD_quantiles'></span>

<h3>Description</h3>

<p>Compute extreme quantile from GPD parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GPD_quantiles(p, p0, t_x0, sigma, xi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GPD_quantiles_+3A_p">p</code></td>
<td>
<p>Probability level of the desired extreme quantile.</p>
</td></tr>
<tr><td><code id="GPD_quantiles_+3A_p0">p0</code></td>
<td>
<p>Probability level of the (possibly varying) intermediate threshold/quantile.</p>
</td></tr>
<tr><td><code id="GPD_quantiles_+3A_t_x0">t_x0</code></td>
<td>
<p>Value(s) of the (possibly varying) intermediate threshold/quantile.</p>
</td></tr>
<tr><td><code id="GPD_quantiles_+3A_sigma">sigma</code></td>
<td>
<p>Value(s) for the GPD scale parameter.</p>
</td></tr>
<tr><td><code id="GPD_quantiles_+3A_xi">xi</code></td>
<td>
<p>Value(s) for the GPD shape parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The quantile value at probability level <code>p</code>.
</p>

<hr>
<h2 id='install_backend'>Install Torch Backend</h2><span id='topic+install_backend'></span>

<h3>Description</h3>

<p>This function can be called just after installing the EQRN package.
Calling <code>EQRN::install_backend()</code> installs the necessary LibTorch and LibLantern backends of the
<a href="https://torch.mlverse.org/"><code>torch</code></a> dependency by calling <code><a href="torch.html#topic+install_torch">torch::install_torch()</a></code>.
See <a href="https://torch.mlverse.org/docs/articles/installation.html">https://torch.mlverse.org/docs/articles/installation.html</a> for more details and troubleshooting.
Calling this function shouldn't be necessary in interactive environments, as loading EQRN
(e.g. with <code>library(EQRN)</code> or with any <code>EQRN::fct()</code>) should do it automatically (via <code>.onLoad()</code>).
This bahaviour is inherited from the <a href="https://torch.mlverse.org/"><code>torch</code></a> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_backend(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="install_backend_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="torch.html#topic+install_torch">torch::install_torch()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>

<hr>
<h2 id='instantiate_EQRN_network'>Instantiates the default networks for training a EQRN_iid model</h2><span id='topic+instantiate_EQRN_network'></span>

<h3>Description</h3>

<p>Instantiates the default networks for training a EQRN_iid model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>instantiate_EQRN_network(
  net_structure,
  shape_fixed,
  D_in,
  hidden_fct,
  p_drop = 0,
  orthogonal_gpd = TRUE,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="instantiate_EQRN_network_+3A_net_structure">net_structure</code></td>
<td>
<p>Vector of integers whose length determines the number of layers in the neural network
and entries the number of neurons in each corresponding successive layer.</p>
</td></tr>
<tr><td><code id="instantiate_EQRN_network_+3A_shape_fixed">shape_fixed</code></td>
<td>
<p>Whether the shape estimate depends on the covariates or not (bool).</p>
</td></tr>
<tr><td><code id="instantiate_EQRN_network_+3A_d_in">D_in</code></td>
<td>
<p>Number of covariates (including the intermediate quantile feature if used).</p>
</td></tr>
<tr><td><code id="instantiate_EQRN_network_+3A_hidden_fct">hidden_fct</code></td>
<td>
<p>Activation function for the hidden layers. Can be either a callable function (preferably from the <code>torch</code> library),
or one of the the strings <code>"SNN"</code>, <code>"SSNN"</code> for self normalizing networks (with common or separated networks for the scale and shape estimates, respectively).
In the latter cases, <code>shape_fixed</code> has no effect.</p>
</td></tr>
<tr><td><code id="instantiate_EQRN_network_+3A_p_drop">p_drop</code></td>
<td>
<p>Probability parameter for dropout before each hidden layer for regularization during training.
<code>alpha-dropout</code> is used with SNNs.</p>
</td></tr>
<tr><td><code id="instantiate_EQRN_network_+3A_orthogonal_gpd">orthogonal_gpd</code></td>
<td>
<p>Whether to use the orthogonal reparametrization of the estimated GPD parameters (recommended).</p>
</td></tr>
<tr><td><code id="instantiate_EQRN_network_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>torch::nn_module</code> network used to regress the GPD parameters in <code><a href="#topic+EQRN_fit">EQRN_fit()</a></code>.
</p>

<hr>
<h2 id='lagged_features'>Covariate lagged replication for temporal dependence</h2><span id='topic+lagged_features'></span>

<h3>Description</h3>

<p>Covariate lagged replication for temporal dependence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagged_features(X, max_lag, drop_present = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lagged_features_+3A_x">X</code></td>
<td>
<p>Covariate matrix.</p>
</td></tr>
<tr><td><code id="lagged_features_+3A_max_lag">max_lag</code></td>
<td>
<p>Integer giving the maximum lag (i.e. the number of temporal dependence steps).</p>
</td></tr>
<tr><td><code id="lagged_features_+3A_drop_present">drop_present</code></td>
<td>
<p>Whether to drop the &quot;present&quot; features (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with the original columns replicated, and shifted by <code>1:max_lag</code> if <code>drop_present==TRUE</code> (default)
or by <code>0:max_lag</code> if <code>drop_present==FALSE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lagged_features(matrix(seq(20), ncol=2), max_lag=3, drop_present=TRUE)
</code></pre>

<hr>
<h2 id='last_elem'>Last element of a vector</h2><span id='topic+last_elem'></span>

<h3>Description</h3>

<p>Returns the last element of the given vector in the most efficient way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>last_elem(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="last_elem_+3A_x">x</code></td>
<td>
<p>Vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The last element is obtained using <code>x[length(x)]</code>, which is done in <code>O(1)</code> and faster than, for example, any of
<code>Rcpp::mylast(x)</code>, <code>tail(x, n=1)</code>, <code>dplyr::last(x)</code>, <code style="white-space: pre;">&#8288;x[end(x)[1]]]&#8288;</code>, and <code>rev(x)[1]</code>.
</p>


<h3>Value</h3>

<p>The last element in the vector <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>last_elem(c(2, 6, 1, 4))
</code></pre>

<hr>
<h2 id='legacy_names'>Internal renaming function for back-compatibility</h2><span id='topic+legacy_names'></span>

<h3>Description</h3>

<p>Internal renaming function for back-compatibility
</p>


<h3>Usage</h3>

<pre><code class='language-R'>legacy_names(eqrn_fit, classes = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="legacy_names_+3A_eqrn_fit">eqrn_fit</code></td>
<td>
<p>EQRN fitted object.</p>
</td></tr>
<tr><td><code id="legacy_names_+3A_classes">classes</code></td>
<td>
<p>If provided, overrides classes of <code>eqrn_fit</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>eqrn_fit</code> object with updated attribute names and classes.
</p>

<hr>
<h2 id='list2matrix'>Convert a list to a matrix</h2><span id='topic+list2matrix'></span>

<h3>Description</h3>

<p>Convert a list to a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list2matrix(lst, dim = c("row", "col"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="list2matrix_+3A_lst">lst</code></td>
<td>
<p>A list.</p>
</td></tr>
<tr><td><code id="list2matrix_+3A_dim">dim</code></td>
<td>
<p>One of <code>"row"</code> (default) or <code>"col"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The list converted to a matrix, by stacking the elements of <code>lst</code> in the rows or columns of a matrix.
</p>

<hr>
<h2 id='loss_GPD'>Generalized Pareto likelihood loss</h2><span id='topic+loss_GPD'></span>

<h3>Description</h3>

<p>Generalized Pareto likelihood loss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_GPD(
  sigma,
  xi,
  y,
  rescaled = TRUE,
  interm_lvl = NULL,
  return_vector = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loss_GPD_+3A_sigma">sigma</code></td>
<td>
<p>Value(s) for the GPD scale parameter.</p>
</td></tr>
<tr><td><code id="loss_GPD_+3A_xi">xi</code></td>
<td>
<p>Value(s) for the GPD shape parameter.</p>
</td></tr>
<tr><td><code id="loss_GPD_+3A_y">y</code></td>
<td>
<p>Vector of observations</p>
</td></tr>
<tr><td><code id="loss_GPD_+3A_rescaled">rescaled</code></td>
<td>
<p>Whether y already is a vector of excesses (TRUE) or needs rescaling (FALSE).</p>
</td></tr>
<tr><td><code id="loss_GPD_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Probability level at which the empirical quantile should be used as the intermediate threshold
to compute the excesses, if <code>rescaled==FALSE</code>.</p>
</td></tr>
<tr><td><code id="loss_GPD_+3A_return_vector">return_vector</code></td>
<td>
<p>Whether to return the the vector of GPD losses for each observation
instead of the negative log-likelihood (average loss).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>GPD negative log-likelihood of the GPD parameters over the sample of observations.
</p>

<hr>
<h2 id='loss_GPD_tensor'>GPD tensor loss function for training a EQRN network</h2><span id='topic+loss_GPD_tensor'></span>

<h3>Description</h3>

<p>GPD tensor loss function for training a EQRN network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_GPD_tensor(
  out,
  y,
  orthogonal_gpd = TRUE,
  shape_penalty = 0,
  prior_shape = NULL,
  return_agg = c("mean", "sum", "vector", "nanmean", "nansum")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loss_GPD_tensor_+3A_out">out</code></td>
<td>
<p>Batch tensor of GPD parameters output by the network.</p>
</td></tr>
<tr><td><code id="loss_GPD_tensor_+3A_y">y</code></td>
<td>
<p>Batch tensor of corresponding response variable.</p>
</td></tr>
<tr><td><code id="loss_GPD_tensor_+3A_orthogonal_gpd">orthogonal_gpd</code></td>
<td>
<p>Whether the network is supposed to regress in the orthogonal reparametrization of the GPD parameters (recommended).</p>
</td></tr>
<tr><td><code id="loss_GPD_tensor_+3A_shape_penalty">shape_penalty</code></td>
<td>
<p>Penalty parameter for the shape estimate, to potentially regularize its variation from the fixed prior estimate.</p>
</td></tr>
<tr><td><code id="loss_GPD_tensor_+3A_prior_shape">prior_shape</code></td>
<td>
<p>Prior estimate for the shape, used only if <code>shape_penalty&gt;0</code>.</p>
</td></tr>
<tr><td><code id="loss_GPD_tensor_+3A_return_agg">return_agg</code></td>
<td>
<p>The return aggregation of the computed loss over the batch. Must be one of <code style="white-space: pre;">&#8288;"mean", "sum", "vector", "nanmean", "nansum"&#8288;</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The GPD loss over the batch between the network output and the observed responses as a <code>torch::Tensor</code>,
whose dimensions depend on <code>return_agg</code>.
</p>

<hr>
<h2 id='make_folds'>Create cross-validation folds</h2><span id='topic+make_folds'></span>

<h3>Description</h3>

<p>Utility function to create folds of data, used in cross-validation proceidures.
The implementation is originally from the <code>gbex</code> <code>R</code> package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_folds(y, num_folds, stratified = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="make_folds_+3A_y">y</code></td>
<td>
<p>Numerical vector of observations</p>
</td></tr>
<tr><td><code id="make_folds_+3A_num_folds">num_folds</code></td>
<td>
<p>Number of folds to create.</p>
</td></tr>
<tr><td><code id="make_folds_+3A_stratified">stratified</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, the folds are stratified along <code>rank(y)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of indices of the assigned folds for each observation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>make_folds(rnorm(30), 5)
</code></pre>

<hr>
<h2 id='mean_absolute_error'>Mean absolute error</h2><span id='topic+mean_absolute_error'></span>

<h3>Description</h3>

<p>Mean absolute error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mean_absolute_error(
  y,
  y_hat,
  return_agg = c("mean", "sum", "vector"),
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean_absolute_error_+3A_y">y</code></td>
<td>
<p>Vector of observations or ground-truths.</p>
</td></tr>
<tr><td><code id="mean_absolute_error_+3A_y_hat">y_hat</code></td>
<td>
<p>Vector of predictions.</p>
</td></tr>
<tr><td><code id="mean_absolute_error_+3A_return_agg">return_agg</code></td>
<td>
<p>Whether to return the <code>"mean"</code> (default), <code>"sum"</code>, or <code>"vector"</code> of errors.</p>
</td></tr>
<tr><td><code id="mean_absolute_error_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The mean (or total or vectorial) absolute error between <code>y</code> and <code>y_hat</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mean_absolute_error(c(2.3, 4.2, 1.8), c(2.2, 4.6, 1.7))
</code></pre>

<hr>
<h2 id='mean_squared_error'>Mean squared error</h2><span id='topic+mean_squared_error'></span>

<h3>Description</h3>

<p>Mean squared error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mean_squared_error(
  y,
  y_hat,
  return_agg = c("mean", "sum", "vector"),
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean_squared_error_+3A_y">y</code></td>
<td>
<p>Vector of observations or ground-truths.</p>
</td></tr>
<tr><td><code id="mean_squared_error_+3A_y_hat">y_hat</code></td>
<td>
<p>Vector of predictions.</p>
</td></tr>
<tr><td><code id="mean_squared_error_+3A_return_agg">return_agg</code></td>
<td>
<p>Whether to return the <code>"mean"</code> (default), <code>"sum"</code>, or <code>"vector"</code> of errors.</p>
</td></tr>
<tr><td><code id="mean_squared_error_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The mean (or total or vectorial) squared error between <code>y</code> and <code>y_hat</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mean_squared_error(c(2.3, 4.2, 1.8), c(2.2, 4.6, 1.7))
</code></pre>

<hr>
<h2 id='mts_dataset'>Dataset creator for sequential data</h2><span id='topic+mts_dataset'></span>

<h3>Description</h3>

<p>A <code>torch::dataset</code> object that can be initialized with sequential data,
used to feed a recurrent network during training or prediction.
It is used in <code><a href="#topic+EQRN_fit_seq">EQRN_fit_seq()</a></code> and corresponding predict functions,
as well as in other recurrent methods such as <code><a href="#topic+QRN_seq_fit">QRN_seq_fit()</a></code> and its predict functions.
It can perform scaling of the response's past as a covariate, and compute excesses as a response when used in <code><a href="#topic+EQRN_fit_seq">EQRN_fit_seq()</a></code>.
It also allows for fold separation or sequential discontinuity in the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mts_dataset(
  Y,
  X,
  seq_len,
  intermediate_quantiles = NULL,
  scale_Y = TRUE,
  fold_separation = NULL,
  sample_frac = 1,
  device = EQRN::default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mts_dataset_+3A_y">Y</code></td>
<td>
<p>Response variable vector to model the extreme conditional quantile of, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="mts_dataset_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="mts_dataset_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used during training to predict each response quantile.</p>
</td></tr>
<tr><td><code id="mts_dataset_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>Vector of intermediate conditional quantiles at level <code>interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="mts_dataset_+3A_scale_y">scale_Y</code></td>
<td>
<p>Whether to rescale the response past, when considered as an input covariate,
to zero mean and unit covariance before applying the network (recommended).</p>
</td></tr>
<tr><td><code id="mts_dataset_+3A_fold_separation">fold_separation</code></td>
<td>
<p>Fold separation index, when using concatenated folds as data.</p>
</td></tr>
<tr><td><code id="mts_dataset_+3A_sample_frac">sample_frac</code></td>
<td>
<p>Value between <code>0</code> and <code>1</code>. If <code>sample_frac &lt; 1</code>, a subsample of the data is used. Defaults to <code>1</code>.</p>
</td></tr>
<tr><td><code id="mts_dataset_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code><a href="torch.html#topic+dataset">torch::dataset</a></code> containing the given data, to be used with a recurrent neural network.
</p>

<hr>
<h2 id='multilevel_exceedance_proba_error'>Multilevel 'quantile_exceedance_proba_error'</h2><span id='topic+multilevel_exceedance_proba_error'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+quantile_exceedance_proba_error">quantile_exceedance_proba_error()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_exceedance_proba_error(
  Probs,
  proba_levels = NULL,
  return_years = NULL,
  type_probs = c("cdf", "exceedance"),
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_exceedance_proba_error_+3A_probs">Probs</code></td>
<td>
<p>Matrix, whose columns give, for each <code>proba_levels</code>,
the predicted probabilities to exceed or be smaller than a fixed quantile.</p>
</td></tr>
<tr><td><code id="multilevel_exceedance_proba_error_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels of the quantiles.</p>
</td></tr>
<tr><td><code id="multilevel_exceedance_proba_error_+3A_return_years">return_years</code></td>
<td>
<p>The probability levels can be given in term or return years instead.
Only used if <code>proba_levels</code> is not given.</p>
</td></tr>
<tr><td><code id="multilevel_exceedance_proba_error_+3A_type_probs">type_probs</code></td>
<td>
<p>Whether the predictions are the <code>"cdf"</code> (default) or <code>"exceedance"</code> probabilities.</p>
</td></tr>
<tr><td><code id="multilevel_exceedance_proba_error_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_exceedance_proba_error_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_exceedance_proba_error_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output errors (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the <code><a href="#topic+quantile_exceedance_proba_error">quantile_exceedance_proba_error()</a></code>
calibration metric of each column of <code>Probs</code> at the corresponding <code>proba_levels</code>.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "exPrErr_q", proba_levels)</code>
(or <code>paste0(prefix, "exPrErr_", return_years,"y")</code> if <code>return_years</code> are given instead of <code>proba_levels</code>).
</p>

<hr>
<h2 id='multilevel_MAE'>Multilevel quantile MAEs</h2><span id='topic+multilevel_MAE'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+mean_absolute_error">mean_absolute_error()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_MAE(
  True_Q,
  Pred_Q,
  proba_levels,
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE,
  sd = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_MAE_+3A_true_q">True_Q</code></td>
<td>
<p>Matrix of size <code>n_obs</code> times <code>proba_levels</code>,
whose columns are the vectors of ground-truths at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_MAE_+3A_pred_q">Pred_Q</code></td>
<td>
<p>Matrix of the same size as <code>True_Q</code>,
whose columns are the predictions at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_MAE_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels at which the predictions were made.
Must be of length <code>ncol(Pred_Q)</code>.</p>
</td></tr>
<tr><td><code id="multilevel_MAE_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_MAE_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_MAE_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output MAEs (bool).</p>
</td></tr>
<tr><td><code id="multilevel_MAE_+3A_sd">sd</code></td>
<td>
<p>Whether to return the absolute error standard deviation (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the mean absolute errors
between each respective columns of <code>True_Q</code> and <code>Pred_Q</code>.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "MAE_q", proba_levels)</code>.
If <code>sd==TRUE</code> a named list is instead returned, containing the <code>"MAEs"</code> described above and
<code>"SDs"</code>, their standard deviations.
</p>

<hr>
<h2 id='multilevel_MSE'>Multilevel quantile MSEs</h2><span id='topic+multilevel_MSE'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+mean_squared_error">mean_squared_error()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_MSE(
  True_Q,
  Pred_Q,
  proba_levels,
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE,
  sd = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_MSE_+3A_true_q">True_Q</code></td>
<td>
<p>Matrix of size <code>n_obs</code> times <code>proba_levels</code>,
whose columns are the vectors of ground-truths at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_MSE_+3A_pred_q">Pred_Q</code></td>
<td>
<p>Matrix of the same size as <code>True_Q</code>,
whose columns are the predictions at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_MSE_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels at which the predictions were made.
Must be of length <code>ncol(Pred_Q)</code>.</p>
</td></tr>
<tr><td><code id="multilevel_MSE_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_MSE_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_MSE_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output MSEs (bool).</p>
</td></tr>
<tr><td><code id="multilevel_MSE_+3A_sd">sd</code></td>
<td>
<p>Whether to return the squared error standard deviation (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the mean square errors
between each respective columns of <code>True_Q</code> and <code>Pred_Q</code>.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "MSE_q", proba_levels)</code>.
If <code>sd==TRUE</code> a named list is instead returned, containing the <code>"MSEs"</code> described above and
<code>"SDs"</code>, their standard deviations.
</p>

<hr>
<h2 id='multilevel_pred_bias'>Multilevel prediction bias</h2><span id='topic+multilevel_pred_bias'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+prediction_bias">prediction_bias()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_pred_bias(
  True_Q,
  Pred_Q,
  proba_levels,
  square_bias = FALSE,
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_pred_bias_+3A_true_q">True_Q</code></td>
<td>
<p>Matrix of size <code>n_obs</code> times <code>proba_levels</code>,
whose columns are the vectors of ground-truths at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_pred_bias_+3A_pred_q">Pred_Q</code></td>
<td>
<p>Matrix of the same size as <code>True_Q</code>,
whose columns are the predictions at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_pred_bias_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels at which the predictions were made.
Must be of length <code>ncol(Pred_Q)</code>.</p>
</td></tr>
<tr><td><code id="multilevel_pred_bias_+3A_square_bias">square_bias</code></td>
<td>
<p>Whether to return the square bias (bool); defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="multilevel_pred_bias_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_pred_bias_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_pred_bias_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output MSEs (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the (square) bias
of each columns of predictions in <code>Pred_Q</code> for the respective <code>True_Q</code>.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "MSE_q", proba_levels)</code>.
</p>

<hr>
<h2 id='multilevel_prop_below'>Multilevel 'proportion_below'</h2><span id='topic+multilevel_prop_below'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+proportion_below">proportion_below()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_prop_below(
  y,
  Pred_Q,
  proba_levels,
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_prop_below_+3A_y">y</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="multilevel_prop_below_+3A_pred_q">Pred_Q</code></td>
<td>
<p>Matrix of of size <code>length(y)</code> times <code>proba_levels</code>,
whose columns are the quantile predictions at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_prop_below_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels at which the predictions were made.
Must be of length <code>ncol(Pred_Q)</code>.</p>
</td></tr>
<tr><td><code id="multilevel_prop_below_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_prop_below_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_prop_below_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output proportions (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the proportion of observations
below the predictions (<code>Pred_Q</code>) at each probability level.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "propBelow_q", proba_levels)</code>.
</p>

<hr>
<h2 id='multilevel_q_loss'>Multilevel quantile losses</h2><span id='topic+multilevel_q_loss'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+quantile_loss">quantile_loss()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_q_loss(
  y,
  Pred_Q,
  proba_levels,
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_q_loss_+3A_y">y</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="multilevel_q_loss_+3A_pred_q">Pred_Q</code></td>
<td>
<p>Matrix of of size <code>length(y)</code> times <code>proba_levels</code>,
whose columns are the quantile predictions at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_q_loss_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels at which the predictions were made.
Must be of length <code>ncol(Pred_Q)</code>.</p>
</td></tr>
<tr><td><code id="multilevel_q_loss_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_q_loss_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_q_loss_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output quantile errors (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the average quantile losses
between each column of <code>Pred_Q</code> and the observations.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "qloss_q", proba_levels)</code>.
</p>

<hr>
<h2 id='multilevel_q_pred_error'>Multilevel 'quantile_prediction_error'</h2><span id='topic+multilevel_q_pred_error'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+quantile_prediction_error">quantile_prediction_error()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_q_pred_error(
  y,
  Pred_Q,
  proba_levels,
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_q_pred_error_+3A_y">y</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="multilevel_q_pred_error_+3A_pred_q">Pred_Q</code></td>
<td>
<p>Matrix of of size <code>length(y)</code> times <code>proba_levels</code>,
whose columns are the quantile predictions at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_q_pred_error_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels at which the predictions were made.
Must be of length <code>ncol(Pred_Q)</code>.</p>
</td></tr>
<tr><td><code id="multilevel_q_pred_error_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_q_pred_error_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_q_pred_error_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output errors (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the quantile prediction error calibration metrics
between each column of <code>Pred_Q</code> and the observations.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "qPredErr_q", proba_levels)</code>.
</p>

<hr>
<h2 id='multilevel_R_squared'>Multilevel R squared</h2><span id='topic+multilevel_R_squared'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+R_squared">R_squared()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_R_squared(
  True_Q,
  Pred_Q,
  proba_levels,
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_R_squared_+3A_true_q">True_Q</code></td>
<td>
<p>Matrix of size <code>n_obs</code> times <code>proba_levels</code>,
whose columns are the vectors of ground-truths at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_R_squared_+3A_pred_q">Pred_Q</code></td>
<td>
<p>Matrix of the same size as <code>True_Q</code>,
whose columns are the predictions at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_R_squared_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels at which the predictions were made.
Must be of length <code>ncol(Pred_Q)</code>.</p>
</td></tr>
<tr><td><code id="multilevel_R_squared_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_R_squared_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_R_squared_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output MSEs (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the R squared coefficient of determination
of each columns of predictions in <code>Pred_Q</code> for the respective <code>True_Q</code>.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "MSE_q", proba_levels)</code>.
</p>

<hr>
<h2 id='multilevel_resid_var'>Multilevel residual variance</h2><span id='topic+multilevel_resid_var'></span>

<h3>Description</h3>

<p>Multilevel version of <code><a href="#topic+prediction_residual_variance">prediction_residual_variance()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel_resid_var(
  True_Q,
  Pred_Q,
  proba_levels,
  prefix = "",
  na.rm = FALSE,
  give_names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel_resid_var_+3A_true_q">True_Q</code></td>
<td>
<p>Matrix of size <code>n_obs</code> times <code>proba_levels</code>,
whose columns are the vectors of ground-truths at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_resid_var_+3A_pred_q">Pred_Q</code></td>
<td>
<p>Matrix of the same size as <code>True_Q</code>,
whose columns are the predictions at each <code>proba_levels</code> and
each row corresponds to an observation or realisation.</p>
</td></tr>
<tr><td><code id="multilevel_resid_var_+3A_proba_levels">proba_levels</code></td>
<td>
<p>Vector of probability levels at which the predictions were made.
Must be of length <code>ncol(Pred_Q)</code>.</p>
</td></tr>
<tr><td><code id="multilevel_resid_var_+3A_prefix">prefix</code></td>
<td>
<p>A string prefix to add to the output's names (if <code>give_names</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="multilevel_resid_var_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="multilevel_resid_var_+3A_give_names">give_names</code></td>
<td>
<p>Whether to name the output MSEs (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(proba_levels)</code> giving the residual variances
of each columns of predictions in <code>Pred_Q</code> for the respective <code>True_Q</code>.
If <code>give_names</code> is <code>TRUE</code>, the output vector is named <code>paste0(prefix, "MSE_q", proba_levels)</code>.
</p>

<hr>
<h2 id='nn_alpha_dropout'>Alpha-dropout module</h2><span id='topic+nn_alpha_dropout'></span>

<h3>Description</h3>

<p>An alpha-dropout layer as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>, used in self-normalizing networks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_alpha_dropout(p = 0.5, inplace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nn_alpha_dropout_+3A_p">p</code></td>
<td>
<p>probability for dropout.</p>
</td></tr>
<tr><td><code id="nn_alpha_dropout_+3A_inplace">inplace</code></td>
<td>
<p>whether the dropout in performed inplace.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constructor allows specifying:
</p>

<dl>
<dt>p</dt><dd><p>probability of an element to be zeroed (default is 0.5),</p>
</dd>
<dt>inplace</dt><dd><p>if set to TRUE, will do the operation in-place (default is FALSE).</p>
</dd>
</dl>



<h3>References</h3>

<p>Gunter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter. Self-Normalizing Neural Networks.
Advances in Neural Information Processing Systems 30 (NIPS 2017), 2017.
</p>

<hr>
<h2 id='nn_dropout_nd'>Dropout module</h2><span id='topic+nn_dropout_nd'></span>

<h3>Description</h3>

<p>A dropout layer as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_dropout_nd(p = 0.5, inplace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nn_dropout_nd_+3A_p">p</code></td>
<td>
<p>probability for dropout.</p>
</td></tr>
<tr><td><code id="nn_dropout_nd_+3A_inplace">inplace</code></td>
<td>
<p>whether the dropout in performed inplace.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constructor allows specifying:
</p>

<dl>
<dt>p</dt><dd><p>probability of an element to be zeroed (default is 0.5),</p>
</dd>
<dt>inplace</dt><dd><p>if set to TRUE, will do the operation in-place (default is FALSE).</p>
</dd>
</dl>


<hr>
<h2 id='onload_backend_installer'>On-Load Torch Backend Internal Install helper</h2><span id='topic+onload_backend_installer'></span>

<h3>Description</h3>

<p>On-Load Torch Backend Internal Install helper
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onload_backend_installer(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="onload_backend_installer_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="torch.html#topic+install_torch">torch::install_torch()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>

<hr>
<h2 id='perform_scaling'>Performs feature scaling without overfitting</h2><span id='topic+perform_scaling'></span>

<h3>Description</h3>

<p>Performs feature scaling without overfitting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perform_scaling(X, X_scaling = NULL, scale_features = TRUE, stat_attr = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="perform_scaling_+3A_x">X</code></td>
<td>
<p>A covariate matrix.</p>
</td></tr>
<tr><td><code id="perform_scaling_+3A_x_scaling">X_scaling</code></td>
<td>
<p>Existing <code>"X_scaling"</code> object containing the precomputed mean and variance for each covariate.
This enables reusing the scaling choice and parameters from the train set, if computing the excesses on a validation or test set,
in order to avoid overfitting. This is performed automatically in the <code>"EQRN"</code> objects.</p>
</td></tr>
<tr><td><code id="perform_scaling_+3A_scale_features">scale_features</code></td>
<td>
<p>Whether to rescale each input covariates to zero mean and unit variance before applying the model (recommended).
If <code>X_scaling</code> is given, <code>X_scaling$scaling</code> overrides <code>scale_features</code>.</p>
</td></tr>
<tr><td><code id="perform_scaling_+3A_stat_attr">stat_attr</code></td>
<td>
<p>DEPRECATED. Whether to keep attributes in the returned covariate matrix itself.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing:
</p>
<table role = "presentation">
<tr><td><code>X_excesses</code></td>
<td>
<p>the (possibly rescaled and q_feat transformed) covariate matrix,</p>
</td></tr>
<tr><td><code>X_scaling</code></td>
<td>
<p>object of class <code>"X_scaling"</code> to use for consistent scaling on future datasets.</p>
</td></tr>
</table>

<hr>
<h2 id='predict_GPD_semiconditional'>Predict semi-conditional extreme quantiles using peaks over threshold</h2><span id='topic+predict_GPD_semiconditional'></span>

<h3>Description</h3>

<p>Predict semi-conditional extreme quantiles using peaks over threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_GPD_semiconditional(
  Y,
  interm_lvl,
  thresh_quantiles,
  interm_quantiles_test = thresh_quantiles,
  prob_lvls_predict = c(0.99)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_GPD_semiconditional_+3A_y">Y</code></td>
<td>
<p>Vector of (&quot;training&quot;) observations.</p>
</td></tr>
<tr><td><code id="predict_GPD_semiconditional_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Probability level at which the empirical quantile should be used as the intermediate threshold.</p>
</td></tr>
<tr><td><code id="predict_GPD_semiconditional_+3A_thresh_quantiles">thresh_quantiles</code></td>
<td>
<p>Numerical vector of the same length as <code>Y</code>
representing the varying intermediate threshold on the train set.</p>
</td></tr>
<tr><td><code id="predict_GPD_semiconditional_+3A_interm_quantiles_test">interm_quantiles_test</code></td>
<td>
<p>Numerical vector of the same length as <code>Y</code>
representing the varying intermediate threshold used for prediction on the test set.</p>
</td></tr>
<tr><td><code id="predict_GPD_semiconditional_+3A_prob_lvls_predict">prob_lvls_predict</code></td>
<td>
<p>Probability levels at which to predict the extreme semi-conditional quantiles.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing:
</p>
<table role = "presentation">
<tr><td><code>predictions</code></td>
<td>
<p>matrix of dimension <code>length(interm_quantiles_test)</code> times <code>length(prob_lvls_predict)</code>
containing the estimated extreme quantile at levels <code>quantile</code>, for each <code>interm_quantiles_test</code>,</p>
</td></tr>
<tr><td><code>pars</code></td>
<td>
<p>matrix of dimension <code>ntest</code> times <code>2</code>
containing the two GPD parameter MLEs, repeated <code>length(interm_quantiles_test)</code> times.</p>
</td></tr>
</table>

<hr>
<h2 id='predict_unconditional_quantiles'>Predict unconditional extreme quantiles using peaks over threshold</h2><span id='topic+predict_unconditional_quantiles'></span>

<h3>Description</h3>

<p>Predict unconditional extreme quantiles using peaks over threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_unconditional_quantiles(interm_lvl, quantiles = c(0.99), Y, ntest = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_unconditional_quantiles_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Probability level at which the empirical quantile should be used as the intermediate threshold.</p>
</td></tr>
<tr><td><code id="predict_unconditional_quantiles_+3A_quantiles">quantiles</code></td>
<td>
<p>Probability levels at which to predict the extreme quantiles.</p>
</td></tr>
<tr><td><code id="predict_unconditional_quantiles_+3A_y">Y</code></td>
<td>
<p>Vector of (&quot;training&quot;) observations.</p>
</td></tr>
<tr><td><code id="predict_unconditional_quantiles_+3A_ntest">ntest</code></td>
<td>
<p>Number of &quot;test&quot; observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing:
</p>
<table role = "presentation">
<tr><td><code>predictions</code></td>
<td>
<p>matrix of dimension <code>ntest</code> times <code>length(quantiles)</code>
containing the estimated extreme quantile at levels <code>quantile</code>, repeated <code>ntest</code> times,</p>
</td></tr>
<tr><td><code>pars</code></td>
<td>
<p>matrix of dimension <code>ntest</code> times <code>2</code>
containing the two GPD parameter MLEs, repeated <code>ntest</code> times.</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>The threshold for the peaks-over-threshold GPD model.
It is the empirical quantile of <code>Y</code> at level <code>interm_lvl</code>, i.e. <code>stats::quantile(Y, interm_lvl)</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='predict.EQRN_iid'>Predict method for an EQRN_iid fitted object</h2><span id='topic+predict.EQRN_iid'></span>

<h3>Description</h3>

<p>Predict method for an EQRN_iid fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EQRN_iid'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.EQRN_iid_+3A_object">object</code></td>
<td>
<p>Fitted <code>"EQRN_iid"</code> object.</p>
</td></tr>
<tr><td><code id="predict.EQRN_iid_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+EQRN_predict">EQRN_predict</a></code>
</p>

<dl>
<dt><code>X</code></dt><dd><p>Matrix of covariates to predict the corresponding response's conditional quantiles.</p>
</dd>
<dt><code>prob_lvls_predict</code></dt><dd><p>Vector of probability levels at which to predict the conditional quantiles.</p>
</dd>
<dt><code>intermediate_quantiles</code></dt><dd><p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</dd>
<dt><code>interm_lvl</code></dt><dd><p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</dd>
<dt><code>device</code></dt><dd><p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+EQRN_predict">EQRN_predict()</a></code> for more details.
</p>


<h3>Value</h3>

<p>Matrix of size <code>nrow(X)</code> times <code>prob_lvls_predict</code>
containing the conditional quantile estimates of the response associated to each covariate observation at each probability level.
Simplifies to a vector if <code>length(prob_lvls_predict)==1</code>.
</p>

<hr>
<h2 id='predict.EQRN_seq'>Predict method for an EQRN_seq fitted object</h2><span id='topic+predict.EQRN_seq'></span>

<h3>Description</h3>

<p>Predict method for an EQRN_seq fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EQRN_seq'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.EQRN_seq_+3A_object">object</code></td>
<td>
<p>Fitted <code>"EQRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="predict.EQRN_seq_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+EQRN_predict_seq">EQRN_predict_seq</a></code>
</p>

<dl>
<dt><code>X</code></dt><dd><p>Matrix of covariates to predict the corresponding response's conditional quantiles.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</dd>
<dt><code>prob_lvls_predict</code></dt><dd><p>Vector of probability levels at which to predict the conditional quantiles.</p>
</dd>
<dt><code>intermediate_quantiles</code></dt><dd><p>Vector of intermediate conditional quantiles at level <code>fit_eqrn$interm_lvl</code>.</p>
</dd>
<dt><code>interm_lvl</code></dt><dd><p>Optional, checks that <code>interm_lvl == fit_eqrn$interm_lvl</code>.</p>
</dd>
<dt><code>crop_predictions</code></dt><dd><p>Whether to crop out the fist <code>seq_len</code> observations (which are <code>NA</code>) from the returned matrix.</p>
</dd>
<dt><code>seq_len</code></dt><dd><p>Data sequence length (i.e. number of past observations) used to predict each response quantile.
By default, the training <code>fit_eqrn$seq_len</code> is used.</p>
</dd>
<dt><code>device</code></dt><dd><p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+EQRN_predict_seq">EQRN_predict_seq()</a></code> for more details.
</p>


<h3>Value</h3>

<p>Matrix of size <code>nrow(X)</code> times <code>prob_lvls_predict</code>
(or <code>nrow(X)-seq_len</code> times <code>prob_lvls_predict</code> if <code>crop_predictions</code>)
containing the conditional quantile estimates of the corresponding response observations at each probability level.
Simplifies to a vector if <code>length(prob_lvls_predict)==1</code>.
</p>

<hr>
<h2 id='predict.QRN_seq'>Predict method for a QRN_seq fitted object</h2><span id='topic+predict.QRN_seq'></span>

<h3>Description</h3>

<p>Predict method for a QRN_seq fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'QRN_seq'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.QRN_seq_+3A_object">object</code></td>
<td>
<p>Fitted <code>"QRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="predict.QRN_seq_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+QRN_seq_predict">QRN_seq_predict</a></code>
</p>

<dl>
<dt><code>X</code></dt><dd><p>Matrix of covariates to predict the corresponding response's conditional quantiles.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</dd>
<dt><code>q_level</code></dt><dd><p>Optional, checks that <code>q_level == fit_qrn_ts$interm_lvl</code>.</p>
</dd>
<dt><code>crop_predictions</code></dt><dd><p>Whether to crop out the fist <code>seq_len</code> observations (which are <code>NA</code>) from the returned matrix.</p>
</dd>
<dt><code>device</code></dt><dd><p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+QRN_seq_predict">QRN_seq_predict()</a></code> for more details.
</p>


<h3>Value</h3>

<p>Matrix of size <code>nrow(X)</code> times <code>1</code>
(or <code>nrow(X)-seq_len</code> times <code>1</code> if <code>crop_predictions</code>)
containing the conditional quantile estimates of the corresponding response observations.
</p>

<hr>
<h2 id='prediction_bias'>Prediction bias</h2><span id='topic+prediction_bias'></span>

<h3>Description</h3>

<p>Prediction bias
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prediction_bias(y, y_hat, square_bias = FALSE, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prediction_bias_+3A_y">y</code></td>
<td>
<p>Vector of observations or ground-truths.</p>
</td></tr>
<tr><td><code id="prediction_bias_+3A_y_hat">y_hat</code></td>
<td>
<p>Vector of predictions.</p>
</td></tr>
<tr><td><code id="prediction_bias_+3A_square_bias">square_bias</code></td>
<td>
<p>Whether to return the square bias (bool); defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="prediction_bias_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The (square) bias of the predictions <code>y_hat</code> for <code>y</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prediction_bias(c(2.3, 4.2, 1.8), c(2.2, 4.6, 1.7))
</code></pre>

<hr>
<h2 id='prediction_residual_variance'>Prediction residual variance</h2><span id='topic+prediction_residual_variance'></span>

<h3>Description</h3>

<p>Prediction residual variance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prediction_residual_variance(y, y_hat, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prediction_residual_variance_+3A_y">y</code></td>
<td>
<p>Vector of observations or ground-truths.</p>
</td></tr>
<tr><td><code id="prediction_residual_variance_+3A_y_hat">y_hat</code></td>
<td>
<p>Vector of predictions.</p>
</td></tr>
<tr><td><code id="prediction_residual_variance_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The residual variance of the predictions <code>y_hat</code> for <code>y</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prediction_residual_variance(c(2.3, 4.2, 1.8), c(2.2, 4.6, 1.7))
</code></pre>

<hr>
<h2 id='process_features'>Feature processor for EQRN</h2><span id='topic+process_features'></span>

<h3>Description</h3>

<p>Feature processor for EQRN
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process_features(
  X,
  intermediate_q_feature,
  intermediate_quantiles = NULL,
  X_scaling = NULL,
  scale_features = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="process_features_+3A_x">X</code></td>
<td>
<p>A covariate matrix.</p>
</td></tr>
<tr><td><code id="process_features_+3A_intermediate_q_feature">intermediate_q_feature</code></td>
<td>
<p>Whether to use the intermediate <code>quantiles</code> as an additional covariate,
by appending it to the <code>X</code> matrix (bool).</p>
</td></tr>
<tr><td><code id="process_features_+3A_intermediate_quantiles">intermediate_quantiles</code></td>
<td>
<p>The intermediate conditional quantiles.</p>
</td></tr>
<tr><td><code id="process_features_+3A_x_scaling">X_scaling</code></td>
<td>
<p>Existing <code>"X_scaling"</code> object containing the precomputed mean and variance for each covariate.
This enables reusing the scaling choice and parameters from the train set, if computing the excesses on a validation or test set,
in order to avoid overfitting. This is performed automatically in the <code>"EQRN"</code> objects.</p>
</td></tr>
<tr><td><code id="process_features_+3A_scale_features">scale_features</code></td>
<td>
<p>Whether to rescale each input covariates to zero mean and unit variance before applying the network (recommended).
If <code>X_scaling</code> is given, <code>X_scaling$scaling</code> overrides <code>scale_features</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing:
</p>
<table role = "presentation">
<tr><td><code>X_excesses</code></td>
<td>
<p>the (possibly rescaled and q_feat transformed) covariate matrix,</p>
</td></tr>
<tr><td><code>X_scaling</code></td>
<td>
<p>object of class <code>"X_scaling"</code> to use for consistent scaling on future datasets.</p>
</td></tr>
</table>

<hr>
<h2 id='proportion_below'>Proportion of observations below conditional quantile vector</h2><span id='topic+proportion_below'></span>

<h3>Description</h3>

<p>Proportion of observations below conditional quantile vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportion_below(y, Q_hat, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="proportion_below_+3A_y">y</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="proportion_below_+3A_q_hat">Q_hat</code></td>
<td>
<p>Vector of predicted quantiles.</p>
</td></tr>
<tr><td><code id="proportion_below_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The proportion of observation below the predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>proportion_below(c(2.3, 4.2, 1.8), c(2.9, 5.6, 1.7))
</code></pre>

<hr>
<h2 id='QRN_fit_multiple'>Wrapper for fitting a recurrent QRN with restart for stability</h2><span id='topic+QRN_fit_multiple'></span>

<h3>Description</h3>

<p>Wrapper for fitting a recurrent QRN with restart for stability
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QRN_fit_multiple(
  X,
  y,
  q_level,
  number_fits = 3,
  ...,
  seed = NULL,
  data_type = c("seq", "iid")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QRN_fit_multiple_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, for training.</p>
</td></tr>
<tr><td><code id="QRN_fit_multiple_+3A_y">y</code></td>
<td>
<p>Response variable vector to model the conditional quantile of, for training.</p>
</td></tr>
<tr><td><code id="QRN_fit_multiple_+3A_q_level">q_level</code></td>
<td>
<p>Probability level of the desired conditional quantiles to predict.</p>
</td></tr>
<tr><td><code id="QRN_fit_multiple_+3A_number_fits">number_fits</code></td>
<td>
<p>Number of restarts.</p>
</td></tr>
<tr><td><code id="QRN_fit_multiple_+3A_...">...</code></td>
<td>
<p>Other parameters given to <code><a href="#topic+QRN_seq_fit">QRN_seq_fit()</a></code>.</p>
</td></tr>
<tr><td><code id="QRN_fit_multiple_+3A_seed">seed</code></td>
<td>
<p>Integer random seed for reproducibility in network weight initialization.</p>
</td></tr>
<tr><td><code id="QRN_fit_multiple_+3A_data_type">data_type</code></td>
<td>
<p>Type of data dependence, must be one of <code>"iid"</code> (for iid observations) or <code>"seq"</code> (for sequentially dependent observations).
For the moment, only <code>"seq"</code> is accepted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An QRN object of classes <code>c("QRN_seq", "QRN")</code>, containing the fitted network,
as well as all the relevant information for its usage in other functions.
</p>

<hr>
<h2 id='QRN_seq_fit'>Recurrent QRN fitting function</h2><span id='topic+QRN_seq_fit'></span>

<h3>Description</h3>

<p>Used to fit a recurrent quantile regression neural network on a data sample.
Use the <code><a href="#topic+QRN_fit_multiple">QRN_fit_multiple()</a></code> wrapper instead, with <code>data_type="seq"</code>, for better stability using fitting restart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QRN_seq_fit(
  X,
  Y,
  q_level,
  hidden_size = 10,
  num_layers = 1,
  rnn_type = c("lstm", "gru"),
  p_drop = 0,
  learning_rate = 1e-04,
  L2_pen = 0,
  seq_len = 10,
  scale_features = TRUE,
  n_epochs = 10000,
  batch_size = 256,
  X_valid = NULL,
  Y_valid = NULL,
  lr_decay = 1,
  patience_decay = n_epochs,
  min_lr = 0,
  patience_stop = n_epochs,
  tol = 1e-04,
  fold_separation = NULL,
  warm_start_path = NULL,
  patience_lag = 5,
  optim_met = "adam",
  seed = NULL,
  verbose = 2,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QRN_seq_fit_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_y">Y</code></td>
<td>
<p>Response variable vector to model the conditional quantile of, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_q_level">q_level</code></td>
<td>
<p>Probability level of the desired conditional quantiles to predict.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_hidden_size">hidden_size</code></td>
<td>
<p>Dimension of the hidden latent state variables in the recurrent network.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_num_layers">num_layers</code></td>
<td>
<p>Number of recurrent layers.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_rnn_type">rnn_type</code></td>
<td>
<p>Type of recurrent architecture, can be one of <code>"lstm"</code> (default) or <code>"gru"</code>.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_p_drop">p_drop</code></td>
<td>
<p>Probability parameter for dropout before each hidden layer for regularization during training.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Initial learning rate for the optimizer during training of the neural network.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_l2_pen">L2_pen</code></td>
<td>
<p>L2 weight penalty parameter for regularization during training.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used during training to predict each response quantile.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_scale_features">scale_features</code></td>
<td>
<p>Whether to rescale each input covariates to zero mean and unit covariance before applying the network (recommended).</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_n_epochs">n_epochs</code></td>
<td>
<p>Number of training epochs.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_batch_size">batch_size</code></td>
<td>
<p>Batch size used during training.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_x_valid">X_valid</code></td>
<td>
<p>Covariates in a validation set, or <code>NULL</code>. Entries must be in sequential order.
Used for monitoring validation loss during training, enabling learning-rate decay and early stopping.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_y_valid">Y_valid</code></td>
<td>
<p>Response variable in a validation set, or <code>NULL</code>. Entries must be in sequential order.
Used for monitoring validation loss during training, enabling learning-rate decay and early stopping.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_lr_decay">lr_decay</code></td>
<td>
<p>Learning rate decay factor.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_patience_decay">patience_decay</code></td>
<td>
<p>Number of epochs of non-improving validation loss before a learning-rate decay is performed.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_min_lr">min_lr</code></td>
<td>
<p>Minimum learning rate, under which no more decay is performed.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_patience_stop">patience_stop</code></td>
<td>
<p>Number of epochs of non-improving validation loss before early stopping is performed.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_tol">tol</code></td>
<td>
<p>Tolerance for stopping training, in case of no significant training loss improvements.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_fold_separation">fold_separation</code></td>
<td>
<p>Index of fold separation or sequential discontinuity in the data.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_warm_start_path">warm_start_path</code></td>
<td>
<p>Path of a saved network using <code><a href="torch.html#topic+torch_save">torch::torch_save()</a></code>, to load back for a warm start.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_patience_lag">patience_lag</code></td>
<td>
<p>The validation loss is considered to be non-improving
if it is larger than on any of the previous <code>patience_lag</code> epochs.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_optim_met">optim_met</code></td>
<td>
<p>DEPRECATED. Optimization algorithm to use during training. <code>"adam"</code> is the default.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_seed">seed</code></td>
<td>
<p>Integer random seed for reproducibility in network weight initialization.</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_verbose">verbose</code></td>
<td>
<p>Amount of information printed during training (0:nothing, 1:most important, 2:everything).</p>
</td></tr>
<tr><td><code id="QRN_seq_fit_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An QRN object of classes <code>c("QRN_seq", "QRN")</code>, containing the fitted network,
as well as all the relevant information for its usage in other functions.
</p>

<hr>
<h2 id='QRN_seq_predict'>Predict function for a QRN_seq fitted object</h2><span id='topic+QRN_seq_predict'></span>

<h3>Description</h3>

<p>Predict function for a QRN_seq fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QRN_seq_predict(
  fit_qrn_ts,
  X,
  Y,
  q_level = fit_qrn_ts$interm_lvl,
  crop_predictions = FALSE,
  device = default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QRN_seq_predict_+3A_fit_qrn_ts">fit_qrn_ts</code></td>
<td>
<p>Fitted <code>"QRN_seq"</code> object.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_+3A_x">X</code></td>
<td>
<p>Matrix of covariates to predict the corresponding response's conditional quantiles.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_+3A_y">Y</code></td>
<td>
<p>Response variable vector corresponding to the rows of <code>X</code>.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_+3A_q_level">q_level</code></td>
<td>
<p>Optional, checks that <code>q_level == fit_qrn_ts$interm_lvl</code>.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_+3A_crop_predictions">crop_predictions</code></td>
<td>
<p>Whether to crop out the fist <code>seq_len</code> observations (which are <code>NA</code>) from the returned matrix.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_+3A_device">device</code></td>
<td>
<p>(optional) A <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code>. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of size <code>nrow(X)</code> times <code>1</code>
(or <code>nrow(X)-seq_len</code> times <code>1</code> if <code>crop_predictions</code>)
containing the conditional quantile estimates of the corresponding response observations.
</p>

<hr>
<h2 id='QRN_seq_predict_foldwise'>Foldwise fit-predict function using a recurrent QRN</h2><span id='topic+QRN_seq_predict_foldwise'></span>

<h3>Description</h3>

<p>Foldwise fit-predict function using a recurrent QRN
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QRN_seq_predict_foldwise(
  X,
  y,
  q_level,
  n_folds = 3,
  number_fits = 3,
  seq_len = 10,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QRN_seq_predict_foldwise_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_+3A_y">y</code></td>
<td>
<p>Response variable vector to model the conditional quantile of, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_+3A_q_level">q_level</code></td>
<td>
<p>Probability level of the desired conditional quantiles to predict.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_+3A_n_folds">n_folds</code></td>
<td>
<p>Number of folds.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_+3A_number_fits">number_fits</code></td>
<td>
<p>Number of restarts, for stability.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used during training to predict each response quantile.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_+3A_seed">seed</code></td>
<td>
<p>Integer random seed for reproducibility in network weight initialization.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_+3A_...">...</code></td>
<td>
<p>Other parameters given to <code><a href="#topic+QRN_seq_fit">QRN_seq_fit()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing the foldwise predictions and fits. It namely contains:
</p>
<table role = "presentation">
<tr><td><code>predictions</code></td>
<td>
<p>the numerical vector of quantile predictions for each observation entry in y,</p>
</td></tr>
<tr><td><code>fits</code></td>
<td>
<p>a list containing the <code>"QRN_seq"</code> fitted networks for each fold,</p>
</td></tr>
<tr><td><code>cuts</code></td>
<td>
<p>the fold cuts indices,</p>
</td></tr>
<tr><td><code>folds</code></td>
<td>
<p>a list of lists containing the train indices, validation indices and fold separations as a list for each fold setup,</p>
</td></tr>
<tr><td><code>n_folds</code></td>
<td>
<p>number of folds,</p>
</td></tr>
<tr><td><code>q_level</code></td>
<td>
<p>probability level of the predicted quantiles,</p>
</td></tr>
<tr><td><code>train_losses</code></td>
<td>
<p>the vector of train losses on each fold,</p>
</td></tr>
<tr><td><code>valid_losses</code></td>
<td>
<p>the vector of validation losses on each fold,</p>
</td></tr>
<tr><td><code>min_valid_losses</code></td>
<td>
<p>the minimal validation losses obtained on each fold,</p>
</td></tr>
<tr><td><code>min_valid_e</code></td>
<td>
<p>the epoch index of the minimal validation losses obtained on each fold.</p>
</td></tr>
</table>

<hr>
<h2 id='QRN_seq_predict_foldwise_sep'>Sigle-fold foldwise fit-predict function using a recurrent QRN</h2><span id='topic+QRN_seq_predict_foldwise_sep'></span>

<h3>Description</h3>

<p>Separated single-fold version of <code><a href="#topic+QRN_seq_predict_foldwise">QRN_seq_predict_foldwise()</a></code>, for computation purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QRN_seq_predict_foldwise_sep(
  X,
  y,
  q_level,
  n_folds = 3,
  fold_todo = 1,
  number_fits = 3,
  seq_len = 10,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_y">y</code></td>
<td>
<p>Response variable vector to model the conditional quantile of, for training. Entries must be in sequential order.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_q_level">q_level</code></td>
<td>
<p>Probability level of the desired conditional quantiles to predict.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_n_folds">n_folds</code></td>
<td>
<p>Number of folds.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_fold_todo">fold_todo</code></td>
<td>
<p>Index of the fold to do (integer in 1:n_folds).</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_number_fits">number_fits</code></td>
<td>
<p>Number of restarts, for stability.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_seq_len">seq_len</code></td>
<td>
<p>Data sequence length (i.e. number of past observations) used during training to predict each response quantile.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_seed">seed</code></td>
<td>
<p>Integer random seed for reproducibility in network weight initialization.</p>
</td></tr>
<tr><td><code id="QRN_seq_predict_foldwise_sep_+3A_...">...</code></td>
<td>
<p>Other parameters given to <code><a href="#topic+QRN_seq_fit">QRN_seq_fit()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing the foldwise predictions and fits. It namely contains:
</p>
<table role = "presentation">
<tr><td><code>predictions</code></td>
<td>
<p>the numerical vector of quantile predictions for each observation entry in y,</p>
</td></tr>
<tr><td><code>fits</code></td>
<td>
<p>a list containing the <code>"QRN_seq"</code> fitted networks for each fold,</p>
</td></tr>
<tr><td><code>cuts</code></td>
<td>
<p>the fold cuts indices,</p>
</td></tr>
<tr><td><code>folds</code></td>
<td>
<p>a list of lists containing the train indices, validation indices and fold separations as a list for each fold setup,</p>
</td></tr>
<tr><td><code>n_folds</code></td>
<td>
<p>number of folds,</p>
</td></tr>
<tr><td><code>q_level</code></td>
<td>
<p>probability level of the predicted quantiles,</p>
</td></tr>
<tr><td><code>train_losses</code></td>
<td>
<p>the vector of train losses on each fold,</p>
</td></tr>
<tr><td><code>valid_losses</code></td>
<td>
<p>the vector of validation losses on each fold,</p>
</td></tr>
<tr><td><code>min_valid_losses</code></td>
<td>
<p>the minimal validation losses obtained on each fold,</p>
</td></tr>
<tr><td><code>min_valid_e</code></td>
<td>
<p>the epoch index of the minimal validation losses obtained on each fold.</p>
</td></tr>
</table>

<hr>
<h2 id='QRNN_RNN_net'>Recurrent quantile regression neural network module</h2><span id='topic+QRNN_RNN_net'></span>

<h3>Description</h3>

<p>A recurrent neural network as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>,
designed for quantile regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QRNN_RNN_net(
  type = c("lstm", "gru"),
  nb_input_features,
  hidden_size,
  num_layers = 1,
  dropout = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QRNN_RNN_net_+3A_type">type</code></td>
<td>
<p>the type of recurrent architecture, can be one of <code>"lstm"</code> (default) or <code>"gru"</code>,</p>
</td></tr>
<tr><td><code id="QRNN_RNN_net_+3A_nb_input_features">nb_input_features</code></td>
<td>
<p>the input size (i.e. the number of features),</p>
</td></tr>
<tr><td><code id="QRNN_RNN_net_+3A_hidden_size">hidden_size</code></td>
<td>
<p>the dimension of the hidden latent state variables in the recurrent network,</p>
</td></tr>
<tr><td><code id="QRNN_RNN_net_+3A_num_layers">num_layers</code></td>
<td>
<p>the number of recurrent layers,</p>
</td></tr>
<tr><td><code id="QRNN_RNN_net_+3A_dropout">dropout</code></td>
<td>
<p>probability parameter for dropout before each hidden layer for regularization during training.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constructor allows specifying:
</p>

<dl>
<dt>type</dt><dd><p>the type of recurrent architecture, can be one of <code>"lstm"</code> (default) or <code>"gru"</code>,</p>
</dd>
<dt>nb_input_features</dt><dd><p>the input size (i.e. the number of features),</p>
</dd>
<dt>hidden_size</dt><dd><p>the dimension of the hidden latent state variables in the recurrent network,</p>
</dd>
<dt>num_layers</dt><dd><p>the number of recurrent layers,</p>
</dd>
<dt>dropout</dt><dd><p>probability parameter for dropout before each hidden layer for regularization during training.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The specified recurrent QRN as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>.
</p>

<hr>
<h2 id='quantile_exceedance_proba_error'>Quantile exceedance probability prediction calibration error</h2><span id='topic+quantile_exceedance_proba_error'></span>

<h3>Description</h3>

<p>Quantile exceedance probability prediction calibration error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_exceedance_proba_error(
  Probs,
  prob_level = NULL,
  return_years = NULL,
  type_probs = c("cdf", "exceedance"),
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_exceedance_proba_error_+3A_probs">Probs</code></td>
<td>
<p>Predicted probabilities to exceed or be smaller than a fixed quantile.</p>
</td></tr>
<tr><td><code id="quantile_exceedance_proba_error_+3A_prob_level">prob_level</code></td>
<td>
<p>Probability level of the quantile.</p>
</td></tr>
<tr><td><code id="quantile_exceedance_proba_error_+3A_return_years">return_years</code></td>
<td>
<p>The probability level can be given in term or return years instead.
Only used if <code>prob_level</code> is not given.</p>
</td></tr>
<tr><td><code id="quantile_exceedance_proba_error_+3A_type_probs">type_probs</code></td>
<td>
<p>Whether the predictions are the <code>"cdf"</code> (default) or <code>"exceedance"</code> probabilities.</p>
</td></tr>
<tr><td><code id="quantile_exceedance_proba_error_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The calibration metric for the predicted probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quantile_exceedance_proba_error(c(0.1, 0.3, 0.2), prob_level=0.8)
</code></pre>

<hr>
<h2 id='quantile_loss'>Quantile loss</h2><span id='topic+quantile_loss'></span>

<h3>Description</h3>

<p>Quantile loss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_loss(
  y,
  y_hat,
  q,
  return_agg = c("mean", "sum", "vector"),
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_loss_+3A_y">y</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="quantile_loss_+3A_y_hat">y_hat</code></td>
<td>
<p>Vector of predicted quantiles at probability level <code>q</code>.</p>
</td></tr>
<tr><td><code id="quantile_loss_+3A_q">q</code></td>
<td>
<p>Probability level of the predicted quantile.</p>
</td></tr>
<tr><td><code id="quantile_loss_+3A_return_agg">return_agg</code></td>
<td>
<p>Whether to return the <code>"mean"</code> (default), <code>"sum"</code>, or <code>"vector"</code> of losses.</p>
</td></tr>
<tr><td><code id="quantile_loss_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The mean (or total or vectorial) quantile loss between <code>y</code> and <code>y_hat</code> at level <code>q</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quantile_loss(c(2.3, 4.2, 1.8), c(2.9, 5.6, 2.7), q=0.8)
</code></pre>

<hr>
<h2 id='quantile_loss_tensor'>Tensor quantile loss function for training a QRN network</h2><span id='topic+quantile_loss_tensor'></span>

<h3>Description</h3>

<p>Tensor quantile loss function for training a QRN network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_loss_tensor(
  out,
  y,
  q = 0.5,
  return_agg = c("mean", "sum", "vector", "nanmean", "nansum")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_loss_tensor_+3A_out">out</code></td>
<td>
<p>Batch tensor of the quantile output by the network.</p>
</td></tr>
<tr><td><code id="quantile_loss_tensor_+3A_y">y</code></td>
<td>
<p>Batch tensor of corresponding response variable.</p>
</td></tr>
<tr><td><code id="quantile_loss_tensor_+3A_q">q</code></td>
<td>
<p>Probability level of the predicted quantile</p>
</td></tr>
<tr><td><code id="quantile_loss_tensor_+3A_return_agg">return_agg</code></td>
<td>
<p>The return aggregation of the computed loss over the batch. Must be one of <code style="white-space: pre;">&#8288;"mean", "sum", "vector", "nanmean", "nansum"&#8288;</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The quantile loss over the batch between the network output ans the observed responses as a <code>torch::Tensor</code>,
whose dimensions depend on <code>return_agg</code>.
</p>

<hr>
<h2 id='quantile_prediction_error'>Quantile prediction calibration error</h2><span id='topic+quantile_prediction_error'></span>

<h3>Description</h3>

<p>Quantile prediction calibration error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_prediction_error(y, Q_hat, prob_level, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_prediction_error_+3A_y">y</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="quantile_prediction_error_+3A_q_hat">Q_hat</code></td>
<td>
<p>Vector of predicted quantiles at probability level <code>prob_level</code>.</p>
</td></tr>
<tr><td><code id="quantile_prediction_error_+3A_prob_level">prob_level</code></td>
<td>
<p>Probability level of the predicted quantile.</p>
</td></tr>
<tr><td><code id="quantile_prediction_error_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The quantile prediction error calibration metric.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quantile_prediction_error(c(2.3, 4.2, 1.8), c(2.9, 5.6, 2.7), prob_level=0.8)
</code></pre>

<hr>
<h2 id='R_squared'>R squared</h2><span id='topic+R_squared'></span>

<h3>Description</h3>

<p>The coefficient of determination, often called R squared, is the proportion of data variance explained by the predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R_squared(y, y_hat, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="R_squared_+3A_y">y</code></td>
<td>
<p>Vector of observations or ground-truths.</p>
</td></tr>
<tr><td><code id="R_squared_+3A_y_hat">y_hat</code></td>
<td>
<p>Vector of predictions.</p>
</td></tr>
<tr><td><code id="R_squared_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The R squared of the predictions <code>y_hat</code> for <code>y</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>R_squared(c(2.3, 4.2, 1.8), c(2.2, 4.6, 1.7))
</code></pre>

<hr>
<h2 id='Recurrent_GPD_net'>Recurrent network module for GPD parameter prediction</h2><span id='topic+Recurrent_GPD_net'></span>

<h3>Description</h3>

<p>A recurrent neural network as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>,
designed for generalized Pareto distribution parameter prediction, with sequential dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Recurrent_GPD_net(
  type = c("lstm", "gru"),
  nb_input_features,
  hidden_size,
  num_layers = 1,
  dropout = 0,
  shape_fixed = FALSE,
  device = EQRN::default_device()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Recurrent_GPD_net_+3A_type">type</code></td>
<td>
<p>the type of recurrent architecture, can be one of <code>"lstm"</code> (default) or <code>"gru"</code>,</p>
</td></tr>
<tr><td><code id="Recurrent_GPD_net_+3A_nb_input_features">nb_input_features</code></td>
<td>
<p>the input size (i.e. the number of features),</p>
</td></tr>
<tr><td><code id="Recurrent_GPD_net_+3A_hidden_size">hidden_size</code></td>
<td>
<p>the dimension of the hidden latent state variables in the recurrent network,</p>
</td></tr>
<tr><td><code id="Recurrent_GPD_net_+3A_num_layers">num_layers</code></td>
<td>
<p>the number of recurrent layers,</p>
</td></tr>
<tr><td><code id="Recurrent_GPD_net_+3A_dropout">dropout</code></td>
<td>
<p>probability parameter for dropout before each hidden layer for regularization during training,</p>
</td></tr>
<tr><td><code id="Recurrent_GPD_net_+3A_shape_fixed">shape_fixed</code></td>
<td>
<p>whether the shape estimate depends on the covariates or not (bool),</p>
</td></tr>
<tr><td><code id="Recurrent_GPD_net_+3A_device">device</code></td>
<td>
<p>a <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code> for an internal constant vector. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constructor allows specifying:
</p>

<dl>
<dt>type</dt><dd><p>the type of recurrent architecture, can be one of <code>"lstm"</code> (default) or <code>"gru"</code>,</p>
</dd>
<dt>nb_input_features</dt><dd><p>the input size (i.e. the number of features),</p>
</dd>
<dt>hidden_size</dt><dd><p>the dimension of the hidden latent state variables in the recurrent network,</p>
</dd>
<dt>num_layers</dt><dd><p>the number of recurrent layers,</p>
</dd>
<dt>dropout</dt><dd><p>probability parameter for dropout before each hidden layer for regularization during training,</p>
</dd>
<dt>shape_fixed</dt><dd><p>whether the shape estimate depends on the covariates or not (bool),</p>
</dd>
<dt>device</dt><dd><p>a <code><a href="torch.html#topic+torch_device">torch::torch_device()</a></code> for an internal constant vector. Defaults to <code><a href="#topic+default_device">default_device()</a></code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The specified recurrent GPD network as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>.
</p>

<hr>
<h2 id='roundm'>Mathematical number rounding</h2><span id='topic+roundm'></span>

<h3>Description</h3>

<p>This function rounds numbers in the mathematical sense,
as opposed to the base <code>R</code> function <code><a href="base.html#topic+round">round()</a></code> that rounds 'to the even digit'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roundm(x, decimals = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="roundm_+3A_x">x</code></td>
<td>
<p>Vector of numerical values to round.</p>
</td></tr>
<tr><td><code id="roundm_+3A_decimals">decimals</code></td>
<td>
<p>Integer indicating the number of decimal places to be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the entries of <code>x</code>, rounded to <code>decimals</code> decimals.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>roundm(2.25, 1)
</code></pre>

<hr>
<h2 id='safe_save_rds'>Safe RDS save</h2><span id='topic+safe_save_rds'></span>

<h3>Description</h3>

<p>Safe version of <code><a href="base.html#topic+saveRDS">saveRDS()</a></code>.
If the given save path (i.e. <code>dirname(file_path)</code>) does not exist, it is created instead of raising an error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>safe_save_rds(object, file_path, recursive = TRUE, no_warning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="safe_save_rds_+3A_object">object</code></td>
<td>
<p>R variable or object to save on disk.</p>
</td></tr>
<tr><td><code id="safe_save_rds_+3A_file_path">file_path</code></td>
<td>
<p>Path and name of the save file, as a string.</p>
</td></tr>
<tr><td><code id="safe_save_rds_+3A_recursive">recursive</code></td>
<td>
<p>Should elements of the path other than the last be created?
If <code>TRUE</code>, behaves like the Unix command <code>mkdir -p</code>.</p>
</td></tr>
<tr><td><code id="safe_save_rds_+3A_no_warning">no_warning</code></td>
<td>
<p>Whether to cancel the warning issued if a directory is created (bool).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
safe_save_rds(c(1, 2, 8), "./some_folder/my_new_folder/my_vector.rds")

</code></pre>

<hr>
<h2 id='semiconditional_train_valid_GPD_loss'>Semi-conditional GPD MLEs and their train-validation likelihoods</h2><span id='topic+semiconditional_train_valid_GPD_loss'></span>

<h3>Description</h3>

<p>Semi-conditional GPD MLEs and their train-validation likelihoods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semiconditional_train_valid_GPD_loss(
  Y_train,
  Y_valid,
  interm_quant_train,
  interm_quant_valid
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="semiconditional_train_valid_GPD_loss_+3A_y_train">Y_train</code></td>
<td>
<p>Vector of &quot;training&quot; observations on which to estimate the MLEs.</p>
</td></tr>
<tr><td><code id="semiconditional_train_valid_GPD_loss_+3A_y_valid">Y_valid</code></td>
<td>
<p>Vector of &quot;validation&quot; observations, on which to estimate the out of training sample GPD loss.</p>
</td></tr>
<tr><td><code id="semiconditional_train_valid_GPD_loss_+3A_interm_quant_train">interm_quant_train</code></td>
<td>
<p>Vector of intermediate quantiles serving as a varying threshold for each training observation.</p>
</td></tr>
<tr><td><code id="semiconditional_train_valid_GPD_loss_+3A_interm_quant_valid">interm_quant_valid</code></td>
<td>
<p>Vector of intermediate quantiles serving as a varying threshold for each validation observation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing:
</p>
<table role = "presentation">
<tr><td><code>scale</code></td>
<td>
<p>GPD scale MLE inferred from the train set,</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>
<p>GPD shape MLE inferred from the train set,</p>
</td></tr>
<tr><td><code>train_loss</code></td>
<td>
<p>the negative log-likelihoods of the MLEs over the training samples,</p>
</td></tr>
<tr><td><code>valid_loss</code></td>
<td>
<p>the negative log-likelihoods of the MLEs over the validation samples.</p>
</td></tr>
</table>

<hr>
<h2 id='Separated_GPD_SNN'>Self-normalized separated network module for GPD parameter prediction</h2><span id='topic+Separated_GPD_SNN'></span>

<h3>Description</h3>

<p>A parameter-separated self-normalizing network as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>,
designed for generalized Pareto distribution parameter prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Separated_GPD_SNN(
  D_in,
  Hidden_vect_scale = c(64, 64, 64),
  Hidden_vect_shape = c(5, 3),
  p_drop = 0.01
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Separated_GPD_SNN_+3A_d_in">D_in</code></td>
<td>
<p>the input size (i.e. the number of features),</p>
</td></tr>
<tr><td><code id="Separated_GPD_SNN_+3A_hidden_vect_scale">Hidden_vect_scale</code></td>
<td>
<p>a vector of integers whose length determines the number of layers in the sub-network
for the scale parameter and entries the number of neurons in each corresponding successive layer,</p>
</td></tr>
<tr><td><code id="Separated_GPD_SNN_+3A_hidden_vect_shape">Hidden_vect_shape</code></td>
<td>
<p>a vector of integers whose length determines the number of layers in the sub-network
for the shape parameter and entries the number of neurons in each corresponding successive layer,</p>
</td></tr>
<tr><td><code id="Separated_GPD_SNN_+3A_p_drop">p_drop</code></td>
<td>
<p>probability parameter for the <code>alpha-dropout</code> before each hidden layer for regularization during training.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constructor allows specifying:
</p>

<dl>
<dt>D_in</dt><dd><p>the input size (i.e. the number of features),</p>
</dd>
<dt>Hidden_vect_scale</dt><dd><p>a vector of integers whose length determines the number of layers in the sub-network
for the scale parameter and entries the number of neurons in each corresponding successive layer,</p>
</dd>
<dt>Hidden_vect_shape</dt><dd><p>a vector of integers whose length determines the number of layers in the sub-network
for the shape parameter and entries the number of neurons in each corresponding successive layer,</p>
</dd>
<dt>p_drop</dt><dd><p>probability parameter for the <code>alpha-dropout</code> before each hidden layer for regularization during training.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The specified parameter-separated SNN MLP GPD network as a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>.
</p>


<h3>References</h3>

<p>Gunter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter. Self-Normalizing Neural Networks.
Advances in Neural Information Processing Systems 30 (NIPS 2017), 2017.
</p>

<hr>
<h2 id='set_doFuture_strategy'>Set a doFuture execution strategy</h2><span id='topic+set_doFuture_strategy'></span>

<h3>Description</h3>

<p>Set a doFuture execution strategy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_doFuture_strategy(
  strategy = c("sequential", "multisession", "multicore", "mixed"),
  n_workers = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_doFuture_strategy_+3A_strategy">strategy</code></td>
<td>
<p>One of <code>"sequential"</code> (default), <code>"multisession"</code>, <code>"multicore"</code>, or <code>"mixed"</code>.</p>
</td></tr>
<tr><td><code id="set_doFuture_strategy_+3A_n_workers">n_workers</code></td>
<td>
<p>A positive numeric scalar or a function specifying the maximum number of parallel futures
that can be active at the same time before blocking.
If a function, it is called without arguments when the future is created and its value is used to configure the workers.
The function should return a numeric scalar.
Defaults to <code><a href="future.html#topic+re-exports">future::availableCores()</a></code><code>-1</code> if <code>NULL</code> (default), with <code>"multicore"</code> constraint in the relevant case.
Ignored if <code>strategy=="sequential"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The appropriate <code><a href="#topic+get_doFuture_operator">get_doFuture_operator()</a></code> operator to use in a <code><a href="foreach.html#topic+foreach">foreach::foreach()</a></code> loop.
The <code><a href="foreach.html#topic++25do+25">%do%</a></code> operator is returned if <code>strategy=="sequential"</code>.
Otherwise, the <code><a href="foreach.html#topic++25dopar+25">%dopar%</a></code> operator is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
`%fun%` &lt;- set_doFuture_strategy("multisession", n_workers=3)
# perform foreach::foreach loop using the %fun% operator
end_doFuture_strategy()

</code></pre>

<hr>
<h2 id='setup_optimizer'>Instantiate an optimizer for training an EQRN_iid network</h2><span id='topic+setup_optimizer'></span>

<h3>Description</h3>

<p>Instantiate an optimizer for training an EQRN_iid network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_optimizer(network, learning_rate, L2_pen, hidden_fct, optim_met = "adam")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setup_optimizer_+3A_network">network</code></td>
<td>
<p>A <code>torch::nn_module</code> network to be trained in <code><a href="#topic+EQRN_fit">EQRN_fit()</a></code>.</p>
</td></tr>
<tr><td><code id="setup_optimizer_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Initial learning rate for the optimizer during training of the neural network.</p>
</td></tr>
<tr><td><code id="setup_optimizer_+3A_l2_pen">L2_pen</code></td>
<td>
<p>L2 weight penalty parameter for regularization during training.</p>
</td></tr>
<tr><td><code id="setup_optimizer_+3A_hidden_fct">hidden_fct</code></td>
<td>
<p>Activation function for the hidden layers. Can be either a callable function (preferably from the <code>torch</code> library),
or one of the the strings <code>"SNN"</code>, <code>"SSNN"</code> for self normalizing networks (with common or separated networks for the scale and shape estimates, respectively).
This will affect the default choice of optimizer.</p>
</td></tr>
<tr><td><code id="setup_optimizer_+3A_optim_met">optim_met</code></td>
<td>
<p>DEPRECATED. Optimization algorithm to use during training. <code>"adam"</code> is the default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>torch::optimizer</code> object used in <code><a href="#topic+EQRN_fit">EQRN_fit()</a></code> for training.
</p>

<hr>
<h2 id='setup_optimizer_seq'>Instantiate an optimizer for training an EQRN_seq network</h2><span id='topic+setup_optimizer_seq'></span>

<h3>Description</h3>

<p>Instantiate an optimizer for training an EQRN_seq network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_optimizer_seq(network, learning_rate, L2_pen, optim_met = "adam")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setup_optimizer_seq_+3A_network">network</code></td>
<td>
<p>A <code>torch::nn_module</code> network to be trained in <code><a href="#topic+EQRN_fit_seq">EQRN_fit_seq()</a></code>.</p>
</td></tr>
<tr><td><code id="setup_optimizer_seq_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Initial learning rate for the optimizer during training of the neural network.</p>
</td></tr>
<tr><td><code id="setup_optimizer_seq_+3A_l2_pen">L2_pen</code></td>
<td>
<p>L2 weight penalty parameter for regularization during training.</p>
</td></tr>
<tr><td><code id="setup_optimizer_seq_+3A_optim_met">optim_met</code></td>
<td>
<p>DEPRECATED. Optimization algorithm to use during training. <code>"adam"</code> is the default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>torch::optimizer</code> object used in <code><a href="#topic+EQRN_fit_seq">EQRN_fit_seq()</a></code> for training.
</p>

<hr>
<h2 id='square_loss'>Square loss</h2><span id='topic+square_loss'></span>

<h3>Description</h3>

<p>Square loss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>square_loss(y, y_hat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="square_loss_+3A_y">y</code></td>
<td>
<p>Vector of observations or ground-truths.</p>
</td></tr>
<tr><td><code id="square_loss_+3A_y_hat">y_hat</code></td>
<td>
<p>Vector of predictions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The vector of square errors between <code>y</code> and <code>y_hat</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>square_loss(c(2.3, 4.2, 1.8), c(2.2, 4.6, 1.7))
</code></pre>

<hr>
<h2 id='unconditional_train_valid_GPD_loss'>Unconditional GPD MLEs and their train-validation likelihoods</h2><span id='topic+unconditional_train_valid_GPD_loss'></span>

<h3>Description</h3>

<p>Unconditional GPD MLEs and their train-validation likelihoods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unconditional_train_valid_GPD_loss(Y_train, interm_lvl, Y_valid)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unconditional_train_valid_GPD_loss_+3A_y_train">Y_train</code></td>
<td>
<p>Vector of &quot;training&quot; observations on which to estimate the MLEs.</p>
</td></tr>
<tr><td><code id="unconditional_train_valid_GPD_loss_+3A_interm_lvl">interm_lvl</code></td>
<td>
<p>Probability level at which the empirical quantile should be used as the threshold.</p>
</td></tr>
<tr><td><code id="unconditional_train_valid_GPD_loss_+3A_y_valid">Y_valid</code></td>
<td>
<p>Vector of &quot;validation&quot; observations, on which to estimate the out of training sample GPD loss.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list containing:
</p>
<table role = "presentation">
<tr><td><code>scale</code></td>
<td>
<p>GPD scale MLE inferred from the train set,</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>
<p>GPD shape MLE inferred from the train set,</p>
</td></tr>
<tr><td><code>train_loss</code></td>
<td>
<p>the negative log-likelihoods of the MLEs over the training samples,</p>
</td></tr>
<tr><td><code>valid_loss</code></td>
<td>
<p>the negative log-likelihoods of the MLEs over the validation samples.</p>
</td></tr>
</table>

<hr>
<h2 id='vec2mat'>Convert a vector to a matrix</h2><span id='topic+vec2mat'></span>

<h3>Description</h3>

<p>Convert a vector to a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2mat(v, axis = c("col", "row"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vec2mat_+3A_v">v</code></td>
<td>
<p>Vector.</p>
</td></tr>
<tr><td><code id="vec2mat_+3A_axis">axis</code></td>
<td>
<p>One of <code>"col"</code> (default) or <code>"row"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The vector <code>v</code> as a matrix.
If <code>axis=="col"</code> (default) the column vector <code>v</code> is returned as a <code>length(v)</code> times <code>1</code> matrix.
If <code>axis=="row"</code>, the vector <code>v</code> is returned as a transposed <code>1</code> times <code>length(v)</code> matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>vec2mat(c(2, 7, 3, 8), "col")
</code></pre>

<hr>
<h2 id='vector_insert'>Insert value in vector</h2><span id='topic+vector_insert'></span>

<h3>Description</h3>

<p>Insert value in vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vector_insert(vect, val, ind)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vector_insert_+3A_vect">vect</code></td>
<td>
<p>A 1-D vector.</p>
</td></tr>
<tr><td><code id="vector_insert_+3A_val">val</code></td>
<td>
<p>A value to insert in the vector.</p>
</td></tr>
<tr><td><code id="vector_insert_+3A_ind">ind</code></td>
<td>
<p>The index at which to insert the value in the vector,
must be an integer between <code>1</code> and <code>length(vect) + 1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 1-D vector of length <code>length(vect) + 1</code>,
with <code>val</code> inserted at position <code>ind</code> in the original <code>vect</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>vector_insert(c(2, 7, 3, 8), val=5, ind=3)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
