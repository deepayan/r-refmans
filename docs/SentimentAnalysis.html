<!DOCTYPE html><html><head><title>Help for package SentimentAnalysis</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SentimentAnalysis}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SentimentAnalysis-package'><p>SentimentAnalysis: A package for analyzing sentiment of texts</p></a></li>
<li><a href='#analyzeSentiment'><p>Sentiment analysis</p></a></li>
<li><a href='#compareDictionaries'><p>Compares two dictionaries</p></a></li>
<li><a href='#compareToResponse'><p>Compare sentiment values to existing response variable</p></a></li>
<li><a href='#convertToBinaryResponse'><p>Convert continuous sentiment to direction</p></a></li>
<li><a href='#convertToDirection'><p>Convert continuous sentiment to direction</p></a></li>
<li><a href='#countWords'><p>Count words</p></a></li>
<li><a href='#DictionaryGI'><p>Dictionary with opinionated words from the Harvard-IV dictionary as used in</p>
the General Inquirer software</a></li>
<li><a href='#DictionaryHE'><p>Dictionary with opinionated words from Henry's Financial dictionary</p></a></li>
<li><a href='#DictionaryLM'><p>Dictionary with opinionated words from Loughran-McDonald Financial dictionary</p></a></li>
<li><a href='#enetEstimation'><p>Elastic net estimation</p></a></li>
<li><a href='#extractWords'><p>Extract words from dictionary</p></a></li>
<li><a href='#generateDictionary'><p>Generates dictionary of decisive terms</p></a></li>
<li><a href='#glmEstimation'><p>Estimation via generalized least squares</p></a></li>
<li><a href='#lassoEstimation'><p>Lasso estimation</p></a></li>
<li><a href='#lmEstimation'><p>Ordinary least squares estimation</p></a></li>
<li><a href='#loadDictionaryGI'><p>Loads Harvard-IV dictionary into object</p></a></li>
<li><a href='#loadDictionaryHE'><p>Loads Henry's finance-specific dictionary into object</p></a></li>
<li><a href='#loadDictionaryLM'><p>Loads Loughran-McDonald dictionary into object</p></a></li>
<li><a href='#loadDictionaryLM_Uncertainty'><p>Loads uncertainty words from Loughran-McDonald into object</p></a></li>
<li><a href='#loadDictionaryQDAP'><p>Loads polarity words from qdap package into object</p></a></li>
<li><a href='#loadImdb'><p>Retrieves IMDb dataset</p></a></li>
<li><a href='#lookupEstimationMethod'><p>Estimation method</p></a></li>
<li><a href='#ngram_tokenize'><p>N-gram tokenizer</p></a></li>
<li><a href='#numEntries'><p>Number of words in dictionary</p></a></li>
<li><a href='#numNegativeEntries'><p>Number of negative words in dictionary</p></a></li>
<li><a href='#numPositiveEntries'><p>Number of positive words in dictionary</p></a></li>
<li><a href='#plot.SentimentDictionaryWeighted'><p>KDE plot of estimated coefficients</p></a></li>
<li><a href='#plotSentiment'><p>Line plot with sentiment scores</p></a></li>
<li><a href='#plotSentimentResponse'><p>Scatterplot with trend line between sentiment and response</p></a></li>
<li><a href='#predict.SentimentDictionaryWeighted'><p>Prediction for given dictionary</p></a></li>
<li><a href='#preprocessCorpus'><p>Default preprocessing of corpus</p></a></li>
<li><a href='#print.SentimentDictionaryWordlist'><p>Output content of sentiment dictionary</p></a></li>
<li><a href='#read'><p>Read dictionary from text file</p></a></li>
<li><a href='#ridgeEstimation'><p>Ridge estimation</p></a></li>
<li><a href='#ruleLinearModel'><p>Sentiment based on linear model</p></a></li>
<li><a href='#ruleNegativity'><p>Ratio of negative words</p></a></li>
<li><a href='#rulePositivity'><p>Ratio of positive words</p></a></li>
<li><a href='#ruleRatio'><p>Ratio of dictionary words</p></a></li>
<li><a href='#ruleSentiment'><p>Sentiment score</p></a></li>
<li><a href='#ruleSentimentPolarity'><p>Sentiment polarity score</p></a></li>
<li><a href='#ruleWordCount'><p>Counts word frequencies</p></a></li>
<li><a href='#SentimentDictionary'><p>Create new sentiment dictionary based on input</p></a></li>
<li><a href='#SentimentDictionaryBinary'><p>Create a sentiment dictionary of positive and negative words</p></a></li>
<li><a href='#SentimentDictionaryWeighted'><p>Create a sentiment dictionary of words linked to a score</p></a></li>
<li><a href='#SentimentDictionaryWordlist'><p>Create a sentiment dictionary consisting of a simple wordlist</p></a></li>
<li><a href='#spikeslabEstimation'><p>Spike-and-slab estimation</p></a></li>
<li><a href='#summary.SentimentDictionaryWordlist'><p>Output summary information on sentiment dictionary</p></a></li>
<li><a href='#toDocumentTermMatrix'><p>Default preprocessing of corpus and conversion to document-term matrix</p></a></li>
<li><a href='#transformIntoCorpus'><p>Transforms the input into a Corpus object</p></a></li>
<li><a href='#write'><p>Write dictionary to text file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Dictionary-Based Sentiment Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3-5</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-23</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs a sentiment analysis of textual contents in R. This implementation
    utilizes various existing dictionaries, such as Harvard IV, or finance-specific 
    dictionaries. Furthermore, it can also create customized dictionaries. The latter 
    uses LASSO regularization as a statistical approach to select relevant terms based on 
    an exogenous response variable. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/sfeuerriegel/SentimentAnalysis">https://github.com/sfeuerriegel/SentimentAnalysis</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/sfeuerriegel/SentimentAnalysis/issues">https://github.com/sfeuerriegel/SentimentAnalysis/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>tm (&ge; 0.6), qdapDictionaries, ngramrr (&ge; 0.1), moments,
stringdist, glmnet, spikeslab (&ge; 1.1), ggplot2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown, SnowballC, XML, mgcv</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-23 19:43:52 UTC; nproe</td>
</tr>
<tr>
<td>Author:</td>
<td>Nicolas Proellochs [aut, cre],
  Stefan Feuerriegel [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nicolas Proellochs &lt;nicolas@nproellochs.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-23 20:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='SentimentAnalysis-package'>SentimentAnalysis: A package for analyzing sentiment of texts</h2><span id='topic+SentimentAnalysis'></span><span id='topic+SentimentAnalysis-package'></span>

<h3>Description</h3>

<p>The <code>SentimentAnalysis</code> package provides routines to quickly measure
the sentiment of written materials. It ships a dedicated class
SentimentDictionary to store different variants of dictionaries
(including pre-built ones that are ready to go) and helps the
user with routines for constructing domain-specific dictionaries and
evaluating the performance of common rules for analyzing sentiment.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nicolas Proellochs <a href="mailto:nicolas@nproellochs.com">nicolas@nproellochs.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Stefan Feuerriegel <a href="mailto:sentiment@sfeuerriegel.com">sentiment@sfeuerriegel.com</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/sfeuerriegel/SentimentAnalysis">https://github.com/sfeuerriegel/SentimentAnalysis</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/sfeuerriegel/SentimentAnalysis/issues">https://github.com/sfeuerriegel/SentimentAnalysis/issues</a>
</p>
</li></ul>


<hr>
<h2 id='analyzeSentiment'>Sentiment analysis</h2><span id='topic+analyzeSentiment'></span><span id='topic+analyzeSentiment.Corpus'></span><span id='topic+analyzeSentiment.character'></span><span id='topic+analyzeSentiment.data.frame'></span><span id='topic+analyzeSentiment.TermDocumentMatrix'></span><span id='topic+analyzeSentiment.DocumentTermMatrix'></span>

<h3>Description</h3>

<p>Performs sentiment analysis  of given object (vector of strings, document-term 
matrix, corpus).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analyzeSentiment(
  x,
  language = "english",
  aggregate = NULL,
  rules = defaultSentimentRules(),
  removeStopwords = TRUE,
  stemming = TRUE,
  ...
)

## S3 method for class 'Corpus'
analyzeSentiment(
  x,
  language = "english",
  aggregate = NULL,
  rules = defaultSentimentRules(),
  removeStopwords = TRUE,
  stemming = TRUE,
  ...
)

## S3 method for class 'character'
analyzeSentiment(
  x,
  language = "english",
  aggregate = NULL,
  rules = defaultSentimentRules(),
  removeStopwords = TRUE,
  stemming = TRUE,
  ...
)

## S3 method for class 'data.frame'
analyzeSentiment(
  x,
  language = "english",
  aggregate = NULL,
  rules = defaultSentimentRules(),
  removeStopwords = TRUE,
  stemming = TRUE,
  ...
)

## S3 method for class 'TermDocumentMatrix'
analyzeSentiment(
  x,
  language = "english",
  aggregate = NULL,
  rules = defaultSentimentRules(),
  removeStopwords = TRUE,
  stemming = TRUE,
  ...
)

## S3 method for class 'DocumentTermMatrix'
analyzeSentiment(
  x,
  language = "english",
  aggregate = NULL,
  rules = defaultSentimentRules(),
  removeStopwords = TRUE,
  stemming = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="analyzeSentiment_+3A_x">x</code></td>
<td>
<p>A vector of characters, a <code>data.frame</code>, an object of type 
<code><a href="tm.html#topic+Corpus">Corpus</a></code>, <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code> or
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code></p>
</td></tr>
<tr><td><code id="analyzeSentiment_+3A_language">language</code></td>
<td>
<p>Language used for preprocessing operations (default: 
English)</p>
</td></tr>
<tr><td><code id="analyzeSentiment_+3A_aggregate">aggregate</code></td>
<td>
<p>A factor variable by which documents can be grouped. 
This helpful when joining e.g. news from the same day or move reviews
by the same author</p>
</td></tr>
<tr><td><code id="analyzeSentiment_+3A_rules">rules</code></td>
<td>
<p>A named list containing individual sentiment metrics. 
Therefore, each entry consists itself of a list with first a method,
followed by an optional dictionary.</p>
</td></tr>
<tr><td><code id="analyzeSentiment_+3A_removestopwords">removeStopwords</code></td>
<td>
<p>Flag indicating whether to remove stopwords or not (default: yes)</p>
</td></tr>
<tr><td><code id="analyzeSentiment_+3A_stemming">stemming</code></td>
<td>
<p>Perform stemming (default: TRUE)</p>
</td></tr>
<tr><td><code id="analyzeSentiment_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for e.g. 
preprocessing</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns a data.frame with continuous values. If one desires 
other formats, one needs to convert these. Common examples of such formats are
binary response values (positive / negative) or tertiary (positive, neutral, 
negative). Hence, consider using the functions <code><a href="#topic+convertToBinaryResponse">convertToBinaryResponse</a></code> and
<code><a href="#topic+convertToDirection">convertToDirection</a></code>, which can convert a vector of continuous sentiment
scores into a factor object.
</p>


<h3>Value</h3>

<p>Result is a matrix with sentiment values for each document across
all defined rules
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compareToResponse">compareToResponse</a></code> for evaluating the results, 
<code><a href="#topic+convertToBinaryResponse">convertToBinaryResponse</a></code> and <code><a href="#topic+convertToDirection">convertToDirection</a></code> for
for getting binary results, <code><a href="#topic+generateDictionary">generateDictionary</a></code> for dictionary generation, 
<code><a href="#topic+plotSentiment">plotSentiment</a></code> and <code><a href="#topic+plotSentimentResponse">plotSentimentResponse</a></code> for visualization
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(tm)

# via vector of strings
corpus &lt;- c("Positive text", "Neutral but uncertain text", "Negative text")
sentiment &lt;- analyzeSentiment(corpus)
compareToResponse(sentiment, c(+1, 0, -2))

# via Corpus from tm package
data("crude")
sentiment &lt;- analyzeSentiment(crude)
    
# via DocumentTermMatrix (with stemmed entries)
dtm &lt;- DocumentTermMatrix(VCorpus(VectorSource(c("posit posit", "negat neutral")))) 
sentiment &lt;- analyzeSentiment(dtm)
compareToResponse(sentiment, convertToBinaryResponse(c(+1, -1)))

# By adapting the parameter rules, one can incorporate customized dictionaries
# e.g. in order to adapt to arbitrary languages
dictionaryAmplifiers &lt;- SentimentDictionary(c("more", "much"))
sentiment &lt;- analyzeSentiment(corpus,
                              rules=list("Amplifiers"=list(ruleRatio,
                                                           dictionaryAmplifiers)))
                                                           
# On can also restrict the number of computed methods to the ones of interest
# in order to achieve performance optimizations
sentiment &lt;- analyzeSentiment(corpus,
                              rules=list("SentimentLM"=list(ruleSentiment, 
                                                            loadDictionaryLM())))
sentiment

## End(Not run)

</code></pre>

<hr>
<h2 id='compareDictionaries'>Compares two dictionaries</h2><span id='topic+compareDictionaries'></span>

<h3>Description</h3>

<p>Routine compares two dictionaries in terms of how similarities and differences. Among the 
calculated measures are the total of distinct words, the overlap between both 
dictionaries, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareDictionaries(d1, d2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compareDictionaries_+3A_d1">d1</code></td>
<td>
<p>is the first sentiment dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>, 
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
<tr><td><code id="compareDictionaries_+3A_d2">d2</code></td>
<td>
<p>is the first sentiment dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>, 
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns list with different metrics depending on dictionary type
</p>


<h3>Note</h3>

<p>Currently, this routine only supports the case where both dictionaries are of the
same type
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>, 
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code>, 
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code> for the specific classes
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d1 &lt;- SentimentDictionary(c("uncertain", "possible", "likely"))
d2 &lt;- SentimentDictionary(c("rather", "intend", "likely"))
cmp &lt;- compareDictionaries(d1, d2)

d1 &lt;- SentimentDictionary(c("increase", "rise", "more"),
                          c("fall", "drop"))
d2 &lt;- SentimentDictionary(c("positive", "rise", "more"),
                          c("negative", "drop"))
cmp &lt;- compareDictionaries(d1, d2)

d1 &lt;- SentimentDictionary(c("increase", "decrease", "exit"),
                          c(+1, -1, -10),
                          rep(NA, 3))
d2 &lt;- SentimentDictionary(c("increase", "decrease", "drop", "neutral"),
                          c(+2, -5, -1, 0),
                          rep(NA, 4))
cmp &lt;- compareDictionaries(d1, d2)
</code></pre>

<hr>
<h2 id='compareToResponse'>Compare sentiment values to existing response variable</h2><span id='topic+compareToResponse'></span><span id='topic+compareToResponse.logical'></span><span id='topic+compareToResponse.factor'></span><span id='topic+compareToResponse.integer'></span><span id='topic+compareToResponse.data.frame'></span><span id='topic+compareToResponse.numeric'></span>

<h3>Description</h3>

<p>This function compares the calculated sentiment values with an external
response variable. Examples of such an exogenous response are stock market
movements or IMDb move rating. Both usually reflect a &quot;true&quot; value that 
the sentiment should match.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareToResponse(sentiment, response)

## S3 method for class 'logical'
compareToResponse(sentiment, response)

## S3 method for class 'factor'
compareToResponse(sentiment, response)

## S3 method for class 'integer'
compareToResponse(sentiment, response)

## S3 method for class 'data.frame'
compareToResponse(sentiment, response)

## S3 method for class 'numeric'
compareToResponse(sentiment, response)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compareToResponse_+3A_sentiment">sentiment</code></td>
<td>
<p>Matrix with sentiment scores for each document across several 
sentiment rules</p>
</td></tr>
<tr><td><code id="compareToResponse_+3A_response">response</code></td>
<td>
<p>Vector with &quot;true&quot; response. This vector can either be of a 
continuous numeric or binary values. In case of the latter, FALSE is matched 
to a negative sentiment value, while TRUE is matched to a non-negative one.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with different performance metrics for all given sentiment 
rules
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sentiment &lt;- matrix(c(5.5, 2.9, 0.9, -1), 
                    dimnames=list(c("A", "B", "C", "D"), c("Sentiment")))

# continuous numeric response variable
response &lt;- c(5, 3, 1, -1)
compareToResponse(sentiment, response)

# binary response variable
response &lt;- c(TRUE, TRUE, FALSE, FALSE)
compareToResponse(sentiment, response)
</code></pre>

<hr>
<h2 id='convertToBinaryResponse'>Convert continuous sentiment to direction</h2><span id='topic+convertToBinaryResponse'></span>

<h3>Description</h3>

<p>This function converts continuous sentiment scores into a their corresponding
binary sentiment class. As such, the result is a factor with two levels 
indicating positive and negative content. Neutral documents (with a sentiment
score of 0) are counted as positive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertToBinaryResponse(sentiment)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convertToBinaryResponse_+3A_sentiment">sentiment</code></td>
<td>
<p>Vector, matrix or data.frame with sentiment scores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a matrix or data.frame is provided, this routine does not touch
all columns. In fact, it scans for those where the column name starts with
&quot;Sentiment&quot; and changes these columns only. Hence, columns with pure 
negativity, positivity or ratios or word counts are ignored.
</p>


<h3>Value</h3>

<p>If a vector is supplied, it returns a factor with two levels representing 
positive and negative content. Otherwise, it returns a data.frame with the 
corresponding columns being exchanged.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+convertToDirection">convertToDirection</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sentiment &lt;- c(-1, -0.5, +1, 0.6, 0)
convertToBinaryResponse(sentiment)
convertToDirection(sentiment)

df &lt;- data.frame(No=1:5, Sentiment=sentiment)
df
convertToBinaryResponse(df)
convertToDirection(df)
</code></pre>

<hr>
<h2 id='convertToDirection'>Convert continuous sentiment to direction</h2><span id='topic+convertToDirection'></span>

<h3>Description</h3>

<p>This function converts continuous sentiment scores into a their corresponding
sentiment direction. As such, the result is a factor with three levels 
indicating positive, neutral and negative content. In contrast
to <code><a href="#topic+convertToBinaryResponse">convertToBinaryResponse</a></code>, neutral documents have their own category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertToDirection(sentiment)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convertToDirection_+3A_sentiment">sentiment</code></td>
<td>
<p>Vector, matrix or data.frame with sentiment scores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a matrix or data.frame is provided, this routine does not touch
all columns. In fact, it scans for those where the column name starts with
&quot;Sentiment&quot; and changes these columns only. Hence, columns with pure 
negativity, positivity or ratios or word counts are ignored.
</p>


<h3>Value</h3>

<p>If a vector is supplied, it returns a factor with three levels representing 
positive, neutral and negative content. Otherwise, it returns a data.frame with the 
corresponding columns being exchanged.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+convertToBinaryResponse">convertToBinaryResponse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sentiment &lt;- c(-1, -0.5, +1, 0.6, 0)
convertToBinaryResponse(sentiment)
convertToDirection(sentiment)

df &lt;- data.frame(No=1:5, Sentiment=sentiment)
df
convertToBinaryResponse(df)
convertToDirection(df)
</code></pre>

<hr>
<h2 id='countWords'>Count words</h2><span id='topic+countWords'></span><span id='topic+countWords.Corpus'></span><span id='topic+countWords.character'></span><span id='topic+countWords.data.frame'></span><span id='topic+countWords.TermDocumentMatrix'></span><span id='topic+countWords.DocumentTermMatrix'></span>

<h3>Description</h3>

<p>Function counts the words in each document
</p>


<h3>Usage</h3>

<pre><code class='language-R'>countWords(
  x,
  aggregate = NULL,
  removeStopwords = TRUE,
  language = "english",
  ...
)

## S3 method for class 'Corpus'
countWords(
  x,
  aggregate = NULL,
  removeStopwords = TRUE,
  language = "english",
  ...
)

## S3 method for class 'character'
countWords(
  x,
  aggregate = NULL,
  removeStopwords = TRUE,
  language = "english",
  ...
)

## S3 method for class 'data.frame'
countWords(
  x,
  aggregate = NULL,
  removeStopwords = TRUE,
  language = "english",
  ...
)

## S3 method for class 'TermDocumentMatrix'
countWords(
  x,
  aggregate = NULL,
  removeStopwords = TRUE,
  language = "english",
  ...
)

## S3 method for class 'DocumentTermMatrix'
countWords(
  x,
  aggregate = NULL,
  removeStopwords = TRUE,
  language = "english",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="countWords_+3A_x">x</code></td>
<td>
<p>A vector of characters, a <code>data.frame</code>, an object of type 
<code><a href="tm.html#topic+Corpus">Corpus</a></code>, <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code> or
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code></p>
</td></tr>
<tr><td><code id="countWords_+3A_aggregate">aggregate</code></td>
<td>
<p>A factor variable by which documents can be grouped. 
This helpful when joining e.g. news from the same day or move reviews
by the same author</p>
</td></tr>
<tr><td><code id="countWords_+3A_removestopwords">removeStopwords</code></td>
<td>
<p>Flag indicating whether to remove stopwords or not (default: yes)</p>
</td></tr>
<tr><td><code id="countWords_+3A_language">language</code></td>
<td>
<p>Language used for preprocessing operations (default: 
English)</p>
</td></tr>
<tr><td><code id="countWords_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for e.g. 
preprocessing</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result is a matrix with word counts for each document across
</p>


<h3>Examples</h3>

<pre><code class='language-R'>documents &lt;- c("This is a test", "an one more")

# count words (without stopwords)
countWords(documents)

# count all words (including stopwords)
countWords(documents, removeStopwords=FALSE)
</code></pre>

<hr>
<h2 id='DictionaryGI'>Dictionary with opinionated words from the Harvard-IV dictionary as used in 
the General Inquirer software</h2><span id='topic+DictionaryGI'></span>

<h3>Description</h3>

<p>Dictionary with a list of positive and negative words according to the psychological 
Harvard-IV dictionary as used in the General Inquirer software. This is a 
general-purpose dictionary developed by the Harvard University.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DictionaryGI)
</code></pre>


<h3>Format</h3>

<p>A list with different terms according to Henry
</p>


<h3>Note</h3>

<p>All words are in lower case and non-stemmed
</p>


<h3>Source</h3>

<p><a href="https://inquirer.sites.fas.harvard.edu/homecat.htm">https://inquirer.sites.fas.harvard.edu/homecat.htm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DictionaryGI)
summary(DictionaryGI)
</code></pre>

<hr>
<h2 id='DictionaryHE'>Dictionary with opinionated words from Henry's Financial dictionary</h2><span id='topic+DictionaryHE'></span>

<h3>Description</h3>

<p>Dictionary with a list of positive and negative words according to the Henry's 
finance-specific dictionary. This dictionary was first presented in the <em>Journal 
of Business Communication</em> among one of the early adopters of text analysis in the 
finance discipline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DictionaryHE)
</code></pre>


<h3>Format</h3>

<p>A list with different wordlists according to Henry
</p>


<h3>Note</h3>

<p>All words are in lower case and non-stemmed
</p>


<h3>References</h3>

<p>Henry (2008): <em>Are Investors Influenced By How Earnings Press 
Releases Are Written?</em>, Journal of Business Communication, 45:4, 363-407
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DictionaryHE)
summary(DictionaryHE)
</code></pre>

<hr>
<h2 id='DictionaryLM'>Dictionary with opinionated words from Loughran-McDonald Financial dictionary</h2><span id='topic+DictionaryLM'></span>

<h3>Description</h3>

<p>Dictionary with a list of positive, negative and uncertainty words according to the 
Loughran-McDonald finance-specific dictionary. This dictionary was first presented 
in the <em>Journal of Finance</em> and has been widely used in the finance domain ever 
since.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DictionaryLM)
</code></pre>


<h3>Format</h3>

<p>A list with different terms according to Loughran-McDonald
</p>


<h3>Note</h3>

<p>All words are in lower case and non-stemmed
</p>


<h3>Source</h3>

<p><a href="https://sraf.nd.edu/loughranmcdonald-master-dictionary/">https://sraf.nd.edu/loughranmcdonald-master-dictionary/</a>
</p>


<h3>References</h3>

<p>Loughran and McDonald (2011) <em>When is a Liability not a Liability? 
Textual Analysis, Dictionaries, and 10-Ks</em>, Journal of Finance, 66:1, 35-65
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DictionaryLM)
summary(DictionaryLM)
</code></pre>

<hr>
<h2 id='enetEstimation'>Elastic net estimation</h2><span id='topic+enetEstimation'></span>

<h3>Description</h3>

<p>Function estimates coefficients based on elastic net regularization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>enetEstimation(
  x,
  response,
  control = list(alpha = 0.5, s = "lambda.min", family = "gaussian", grouped = FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="enetEstimation_+3A_x">x</code></td>
<td>
<p>An object of type <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.</p>
</td></tr>
<tr><td><code id="enetEstimation_+3A_response">response</code></td>
<td>
<p>Response variable including the given gold standard.</p>
</td></tr>
<tr><td><code id="enetEstimation_+3A_control">control</code></td>
<td>
<p>(optional) A list of parameters defining the model as follows:
</p>

<ul>
<li><p>&quot;alpha&quot;Abstraction parameter for switching between LASSO 
and ridge regularization (with default <code>alpha=0.5</code>). 
Best option is to loop over this parameter and  test different alternatives.
</p>
</li>
<li><p>&quot;s&quot;Value of the parameter lambda at which the elastic net is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li><p>&quot;family&quot;Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> for further details.
</p>
</li>
<li><p>&quot;grouped&quot; Determines whether grouped function is used (with default <code>FALSE</code>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="enetEstimation_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result is a list with coefficients, coefficient names and the model intercept.
</p>

<hr>
<h2 id='extractWords'>Extract words from dictionary</h2><span id='topic+extractWords'></span>

<h3>Description</h3>

<p>Returns all entries from a dictionary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractWords(d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractWords_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>,
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>extractWords(SentimentDictionary(c("uncertain", "possible", "likely"))) # returns 3
extractWords(SentimentDictionary(c("increase", "rise", "more"),
                                 c("fall", "drop"))) # returns 5
extractWords(SentimentDictionary(c("increase", "decrease", "exit"),
                                 c(+1, -1, -10),
                                 rep(NA, 3))) # returns 3
</code></pre>

<hr>
<h2 id='generateDictionary'>Generates dictionary of decisive terms</h2><span id='topic+generateDictionary'></span><span id='topic+generateDictionary.Corpus'></span><span id='topic+generateDictionary.character'></span><span id='topic+generateDictionary.data.frame'></span><span id='topic+generateDictionary.TermDocumentMatrix'></span><span id='topic+generateDictionary.DocumentTermMatrix'></span>

<h3>Description</h3>

<p>Routine applies method for dictionary generation (LASSO, ridge regularization, elastic net, 
ordinary least squares, generalized linear model or spike-and-slab regression) to 
the document-term matrix in order to extract decisive terms that 
have a statistically significant impact on the response variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'Corpus'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'character'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'data.frame'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'TermDocumentMatrix'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'DocumentTermMatrix'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateDictionary_+3A_x">x</code></td>
<td>
<p>A vector of characters, a <code>data.frame</code>, an object of type 
<code><a href="tm.html#topic+Corpus">Corpus</a></code>, <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code> or
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.</p>
</td></tr>
<tr><td><code id="generateDictionary_+3A_response">response</code></td>
<td>
<p>Response variable including the given gold standard.</p>
</td></tr>
<tr><td><code id="generateDictionary_+3A_language">language</code></td>
<td>
<p>Language used for preprocessing operations (default: 
English).</p>
</td></tr>
<tr><td><code id="generateDictionary_+3A_modeltype">modelType</code></td>
<td>
<p>A string denoting the estimation method. Allowed values are <code>lasso</code>, <code>ridge</code>, 
<code>enet</code>, <code>lm</code> or <code>glm</code> or <code>spikeslab</code>.</p>
</td></tr>
<tr><td><code id="generateDictionary_+3A_filterterms">filterTerms</code></td>
<td>
<p>Optional vector of strings (default: <code>NULL</code>) to filter terms that are used
for dictionary generation.</p>
</td></tr>
<tr><td><code id="generateDictionary_+3A_control">control</code></td>
<td>
<p>(optional) A list of parameters defining the model used for dictionary generation.
</p>
<p>If <code>modelType=lasso</code> is selected, individual parameters are as follows:
</p>

<ul>
<li><p>&quot;s&quot; Value of the parameter lambda at which the LASSO is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li><p>&quot;family&quot; Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> for further details.
</p>
</li>
<li><p>&quot;grouped&quot; Determines whether grouped LASSO is used (with default <code>FALSE</code>).
</p>
</li></ul>

<p>If <code>modelType=ridge</code> is selected, individual parameters are as follows:
</p>

<ul>
<li><p>&quot;s&quot; Value of the parameter lambda at which the ridge is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li><p>&quot;family&quot; Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> for further details.
</p>
</li>
<li><p>&quot;grouped&quot; Determines whether grouped function is used (with default <code>FALSE</code>).
</p>
</li></ul>
 
<p>If <code>modelType=enet</code> is selected, individual parameters are as follows:
</p>

<ul>
<li><p>&quot;alpha&quot; Abstraction parameter for switching between LASSO (with <code>alpha=1</code>) and
ridge regression (<code>alpha=0</code>). Default is <code>alpha=0.5</code>. Recommended option is to 
test different values between 0 and 1.
</p>
</li>
<li><p>&quot;s&quot; Value of the parameter lambda at which the elastic net is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li><p>&quot;family&quot; Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> for further details.
</p>
</li>
<li><p>&quot;grouped&quot; Determines whether grouped function is used (with default <code>FALSE</code>).
</p>
</li></ul>

<p>If <code>modelType=lm</code> is selected, no parameters are passed on. 
</p>
<p>If <code>modelType=glm</code> is selected, individual parameters are as follows:
</p>

<ul>
<li><p>&quot;family&quot; Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code><a href="stats.html#topic+glm">glm</a></code> for further details.
</p>
</li></ul>
 
<p>If <code>modelType=spikeslab</code> is selected, individual parameters are as follows:
</p>

<ul>
<li><p>&quot;n.iter1&quot; Number of burn-in Gibbs sampled values (i.e., discarded values). Default is 500.
</p>
</li>
<li><p>&quot;n.iter2&quot; Number of Gibbs sampled values, following burn-in. Default is 500.
</p>
</li></ul>
</td></tr>
<tr><td><code id="generateDictionary_+3A_minwordlength">minWordLength</code></td>
<td>
<p>Removes words given a specific minimum length (default: 3). This 
preprocessing is applied when the input is a character vector or a corpus and the
document-term matrix is generated inside the routine.</p>
</td></tr>
<tr><td><code id="generateDictionary_+3A_sparsity">sparsity</code></td>
<td>
<p>A numeric for removing sparse terms in the document-term matrix. The
argument <code>sparsity</code> specifies the maximal allowed sparsity. Default is 
<code>sparsity=0.9</code>, however, this is only applied when the document-term matrix
is calculated inside the routine.</p>
</td></tr>
<tr><td><code id="generateDictionary_+3A_weighting">weighting</code></td>
<td>
<p>Weights a document-term matrix by e.g. term frequency - inverse
document frequency (default). Other variants can be used from 
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.</p>
</td></tr>
<tr><td><code id="generateDictionary_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for e.g. 
preprocessing or <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result is a matrix which sentiment values for each document across
all defined rules
</p>


<h3>Source</h3>

<p><a href="https://doi.org/10.1371/journal.pone.0209323">doi:10.1371/journal.pone.0209323</a>
</p>


<h3>References</h3>

<p>Pr\&quot;ollochs and Feuerriegel (2018). Statistical inferences for 
Polarity Identification in Natural Language, PloS One 13(12).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+analyzeSentiment">analyzeSentiment</a></code>, <code><a href="#topic+predict.SentimentDictionaryWeighted">predict.SentimentDictionaryWeighted</a></code>, 
<code><a href="#topic+plot.SentimentDictionaryWeighted">plot.SentimentDictionaryWeighted</a></code> and <code><a href="#topic+compareToResponse">compareToResponse</a></code> for
advanced evaluations
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a vector of strings
documents &lt;- c("This is a good thing!",
               "This is a very good thing!",
               "This is okay.",
               "This is a bad thing.",
               "This is a very bad thing.")
response &lt;- c(1, 0.5, 0, -0.5, -1)

# Generate dictionary with LASSO regularization
dictionary &lt;- generateDictionary(documents, response)

# Show dictionary
dictionary
summary(dictionary)
plot(dictionary)

# Compute in-sample performance
sentiment &lt;- predict(dictionary, documents)
compareToResponse(sentiment, response)
plotSentimentResponse(sentiment, response)

# Generate new dictionary with spike-and-slab regression instead of LASSO regularization
library(spikeslab)
dictionary &lt;- generateDictionary(documents, response, modelType="spikeslab")

# Generate new dictionary with tf weighting instead of tf-idf

library(tm)
dictionary &lt;- generateDictionary(documents, response, weighting=weightTf)
sentiment &lt;- predict(dictionary, documents)
compareToResponse(sentiment, response)

# Use instead lambda.min from the LASSO estimation
dictionary &lt;- generateDictionary(documents, response, control=list(s="lambda.min"))
sentiment &lt;- predict(dictionary, documents)
compareToResponse(sentiment, response)

# Use instead OLS as estimation method
dictionary &lt;- generateDictionary(documents, response, modelType="lm")
sentiment &lt;- predict(dictionary, documents)
sentiment

dictionary &lt;- generateDictionary(documents, response, modelType="lm", 
                                 filterTerms = c("good", "bad"))
sentiment &lt;- predict(dictionary, documents)
sentiment

dictionary &lt;- generateDictionary(documents, response, modelType="lm", 
                                 filterTerms = extractWords(loadDictionaryGI()))
sentiment &lt;- predict(dictionary, documents)
sentiment

# Generate dictionary without LASSO intercept
dictionary &lt;- generateDictionary(documents, response, intercept=FALSE)
dictionary$intercept
 
## Not run: 
imdb &lt;- loadImdb()

# Generate Dictionary
dictionary_imdb &lt;- generateDictionary(imdb$Corpus, imdb$Rating, family="poisson")
summary(dictionary_imdb)

compareDictionaries(dictionary_imdb,
                    loadDictionaryGI())
                    
# Show estimated coefficients with Kernel Density Estimation (KDE)
plot(dictionary_imdb)
plot(dictionary_imdb) + xlim(c(-0.1, 0.1))

# Compute in-sample performance
pred_sentiment &lt;- predict(dict_imdb, imdb$Corpus)
compareToResponse(pred_sentiment, imdb$Rating)

# Test a different sparsity parameter
dictionary_imdb &lt;- generateDictionary(imdb$Corpus, imdb$Rating, family="poisson", sparsity=0.99)
summary(dictionary_imdb)
pred_sentiment &lt;- predict(dict_imdb, imdb$Corpus)
compareToResponse(pred_sentiment, imdb$Rating)

## End(Not run)
</code></pre>

<hr>
<h2 id='glmEstimation'>Estimation via generalized least squares</h2><span id='topic+glmEstimation'></span>

<h3>Description</h3>

<p>Function estimates coefficients based on generalized least squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmEstimation(x, response, control = list(family = "gaussian"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmEstimation_+3A_x">x</code></td>
<td>
<p>An object of type <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.</p>
</td></tr>
<tr><td><code id="glmEstimation_+3A_response">response</code></td>
<td>
<p>Response variable including the given gold standard.</p>
</td></tr>
<tr><td><code id="glmEstimation_+3A_control">control</code></td>
<td>
<p>(optional) A list of parameters defining the model as follows:
</p>

<ul>
<li><p>&quot;family&quot;Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code><a href="stats.html#topic+glm">glm</a></code> for further details.
</p>
</li></ul>
</td></tr>
<tr><td><code id="glmEstimation_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result is a list with coefficients, coefficient names and the model intercept.
</p>
<p>Result is a list with coefficients, coefficient names and the model intercept.
</p>

<hr>
<h2 id='lassoEstimation'>Lasso estimation</h2><span id='topic+lassoEstimation'></span>

<h3>Description</h3>

<p>Function estimates coefficients based on LASSO regularization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lassoEstimation(
  x,
  response,
  control = list(alpha = 1, s = "lambda.min", family = "gaussian", grouped = FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lassoEstimation_+3A_x">x</code></td>
<td>
<p>An object of type <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.</p>
</td></tr>
<tr><td><code id="lassoEstimation_+3A_response">response</code></td>
<td>
<p>Response variable including the given gold standard.</p>
</td></tr>
<tr><td><code id="lassoEstimation_+3A_control">control</code></td>
<td>
<p>(optional) A list of parameters defining the LASSO model as follows:
</p>

<ul>
<li><p>&quot;s&quot;Value of the parameter lambda at which the LASSO is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li><p>&quot;family&quot;Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> for further details.
</p>
</li>
<li><p>&quot;grouped&quot; Determines whether grouped LASSO is used (with default <code>FALSE</code>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="lassoEstimation_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result is a list with coefficients, coefficient names and the model intercept.
</p>

<hr>
<h2 id='lmEstimation'>Ordinary least squares estimation</h2><span id='topic+lmEstimation'></span>

<h3>Description</h3>

<p>Function estimates coefficients based on ordinary least squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmEstimation(x, response, control = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmEstimation_+3A_x">x</code></td>
<td>
<p>An object of type <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.</p>
</td></tr>
<tr><td><code id="lmEstimation_+3A_response">response</code></td>
<td>
<p>Response variable including the given gold standard.</p>
</td></tr>
<tr><td><code id="lmEstimation_+3A_control">control</code></td>
<td>
<p>(optional) A list of parameters (not used).</p>
</td></tr>
<tr><td><code id="lmEstimation_+3A_...">...</code></td>
<td>
<p>Additional parameters (not used).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result is a list with coefficients, coefficient names and the model intercept.
</p>

<hr>
<h2 id='loadDictionaryGI'>Loads Harvard-IV dictionary into object</h2><span id='topic+loadDictionaryGI'></span>

<h3>Description</h3>

<p>Loads Harvard-IV dictionary (as used in General Inquirer) into a standardized
dictionary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadDictionaryGI()
</code></pre>


<h3>Value</h3>

<p>object of class <code><a href="#topic+SentimentDictionary">SentimentDictionary</a></code>
</p>


<h3>Note</h3>

<p>Result is a list of stemmed words in lower case
</p>

<hr>
<h2 id='loadDictionaryHE'>Loads Henry's finance-specific dictionary into object</h2><span id='topic+loadDictionaryHE'></span>

<h3>Description</h3>

<p>Loads Henry's finance-specific dictionary into a standardized dictionary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadDictionaryHE()
</code></pre>


<h3>Value</h3>

<p>object of class <code><a href="#topic+SentimentDictionary">SentimentDictionary</a></code>
</p>


<h3>Note</h3>

<p>Result is a list of stemmed words in lower case
</p>

<hr>
<h2 id='loadDictionaryLM'>Loads Loughran-McDonald dictionary into object</h2><span id='topic+loadDictionaryLM'></span>

<h3>Description</h3>

<p>Loads Loughran-McDonald financial dictionary into a standardized dictionary 
object (here, categories positive and negative are considered)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadDictionaryLM()
</code></pre>


<h3>Value</h3>

<p>object of class <code><a href="#topic+SentimentDictionary">SentimentDictionary</a></code>
</p>


<h3>Note</h3>

<p>Result is a list of stemmed words in lower case
</p>

<hr>
<h2 id='loadDictionaryLM_Uncertainty'>Loads uncertainty words from Loughran-McDonald into object</h2><span id='topic+loadDictionaryLM_Uncertainty'></span>

<h3>Description</h3>

<p>Loads uncertainty words from Loughran-McDonald into a standardized
dictionary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadDictionaryLM_Uncertainty()
</code></pre>


<h3>Value</h3>

<p>object of class <code><a href="#topic+SentimentDictionary">SentimentDictionary</a></code>
</p>


<h3>Note</h3>

<p>Result is a list of stemmed words in lower case
</p>

<hr>
<h2 id='loadDictionaryQDAP'>Loads polarity words from qdap package into object</h2><span id='topic+loadDictionaryQDAP'></span>

<h3>Description</h3>

<p>Loads polarity words from data object <code><a href="qdapDictionaries.html#topic+key.pol">key.pol</a></code> 
which is by the package qdap. This is then converted into a standardized
dictionary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadDictionaryQDAP()
</code></pre>


<h3>Value</h3>

<p>object of class <code><a href="#topic+SentimentDictionary">SentimentDictionary</a></code>
</p>


<h3>Note</h3>

<p>Result is a list of stemmed words in lower case
</p>


<h3>Source</h3>

<p><a href="https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html">https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html</a>
</p>


<h3>References</h3>

<p>Hu and Liu (2004). Mining Opinion Features in Customer Reviews. 
National Conference on Artificial Intelligence.
</p>

<hr>
<h2 id='loadImdb'>Retrieves IMDb dataset</h2><span id='topic+loadImdb'></span>

<h3>Description</h3>

<p>Function downloads IMDb dataset and prepares corresponding user ratings for easy
usage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadImdb()
</code></pre>


<h3>Value</h3>

<p>Returns a list where entry named <code>Corpus</code> contains the IMDb reviews,
and <code>Rating</code> is the corresponding scaled rating.
</p>


<h3>References</h3>

<p>Pang and Lee (2015) <em>Seeing Stars: Exploiting Class Relationships 
for Sentiment Categorization with Respect to Rating Scales</em>, Proceeding of the 
ACL. See <a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/">http://www.cs.cornell.edu/people/pabo/movie-review-data/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
imdb &lt;- loadImdb()
dictionary &lt;- generateDictionary(imdb$Corpus, imdb$Rating)

## End(Not run)
</code></pre>

<hr>
<h2 id='lookupEstimationMethod'>Estimation method</h2><span id='topic+lookupEstimationMethod'></span>

<h3>Description</h3>

<p>Decides upon a estimation method for dictionary generation. Input is a name for the estimation method, output is the corresponding function object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lookupEstimationMethod(type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lookupEstimationMethod_+3A_type">type</code></td>
<td>
<p>A string denoting the estimation method. Allowed values are <code>lasso</code>, <code>ridge</code>,
<code>enet</code>, <code>lm</code>, <code>glm</code> or <code>spikeslab</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Function that implements the specific estimation method.
</p>

<hr>
<h2 id='ngram_tokenize'>N-gram tokenizer</h2><span id='topic+ngram_tokenize'></span>

<h3>Description</h3>

<p>A tokenizer for use with a document-term matrix from the tm package. Supports 
both character and word ngrams, including own wrapper to handle non-Latin 
encodings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ngram_tokenize(x, char = FALSE, ngmin = 1, ngmax = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ngram_tokenize_+3A_x">x</code></td>
<td>
<p>input string</p>
</td></tr>
<tr><td><code id="ngram_tokenize_+3A_char">char</code></td>
<td>
<p>boolean value specifying whether to use character (char = TRUE) 
or word n-grams (char = FALSE, default)</p>
</td></tr>
<tr><td><code id="ngram_tokenize_+3A_ngmin">ngmin</code></td>
<td>
<p>integer giving the minimum order of n-gram (default: 1)</p>
</td></tr>
<tr><td><code id="ngram_tokenize_+3A_ngmax">ngmax</code></td>
<td>
<p>integer giving the maximum order of n-gram (default: 3)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(tm)
en &lt;- c("Romeo loves Juliet", "Romeo loves a girl")
en.corpus &lt;- VCorpus(VectorSource(en))
tdm &lt;- TermDocumentMatrix(en.corpus, 
                          control=list(wordLengths=c(1,Inf), 
                                       tokenize=function(x) ngram_tokenize(x, char=TRUE, 
                                                                           ngmin=3, ngmax=3)))
inspect(tdm)

ch &lt;- c("abab", "aabb")
ch.corpus &lt;- VCorpus(VectorSource(ch))
tdm &lt;- TermDocumentMatrix(ch.corpus, 
                          control=list(wordLengths=c(1,Inf), 
                                       tokenize=function(x) ngram_tokenize(x, char=TRUE, 
                                                                           ngmin=1, ngmax=2)))
inspect(tdm)
</code></pre>

<hr>
<h2 id='numEntries'>Number of words in dictionary</h2><span id='topic+numEntries'></span>

<h3>Description</h3>

<p>Counts total number of entries in dictionary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numEntries(d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numEntries_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>,
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+numPositiveEntries">numPositiveEntries</a></code> and 
<code><a href="#topic+numNegativeEntries">numNegativeEntries</a></code> for more option to count the number of entries
</p>


<h3>Examples</h3>

<pre><code class='language-R'>numEntries(SentimentDictionary(c("uncertain", "possible", "likely"))) # returns 3
numEntries(SentimentDictionary(c("increase", "rise", "more"),
                            c("fall", "drop"))) # returns 5
numEntries(SentimentDictionary(c("increase", "decrease", "exit"),
                               c(+1, -1, -10),
                               rep(NA, 3))) # returns 3
</code></pre>

<hr>
<h2 id='numNegativeEntries'>Number of negative words in dictionary</h2><span id='topic+numNegativeEntries'></span>

<h3>Description</h3>

<p>Counts total number of negative entries in dictionary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numNegativeEntries(d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numNegativeEntries_+3A_d">d</code></td>
<td>
<p>is a dictionary of type <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>Entries in <code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code> with a weight of 0 
are not counted here
</p>


<h3>See Also</h3>

<p><code><a href="#topic+numEntries">numEntries</a></code> and 
<code><a href="#topic+numPositiveEntries">numPositiveEntries</a></code> for more option to count the number of entries
</p>


<h3>Examples</h3>

<pre><code class='language-R'>numNegativeEntries(SentimentDictionary(c("increase", "rise", "more"),
                            c("fall", "drop"))) # returns 2
numNegativeEntries(SentimentDictionary(c("increase", "decrease", "exit"),
                               c(+1, -1, -10),
                               rep(NA, 3))) # returns 2
</code></pre>

<hr>
<h2 id='numPositiveEntries'>Number of positive words in dictionary</h2><span id='topic+numPositiveEntries'></span>

<h3>Description</h3>

<p>Counts total number of positive entries in dictionary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numPositiveEntries(d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numPositiveEntries_+3A_d">d</code></td>
<td>
<p>is a dictionary of type <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>Entries in <code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code> with a weight of 0 
are not counted here
</p>


<h3>See Also</h3>

<p><code><a href="#topic+numEntries">numEntries</a></code> and
<code><a href="#topic+numNegativeEntries">numNegativeEntries</a></code> for more option to count the number of entries
</p>


<h3>Examples</h3>

<pre><code class='language-R'>numPositiveEntries(SentimentDictionary(c("increase", "rise", "more"),
                            c("fall", "drop"))) # returns 3
numPositiveEntries(SentimentDictionary(c("increase", "decrease", "exit"),
                               c(+1, -1, -10),
                               rep(NA, 3))) # returns 1
</code></pre>

<hr>
<h2 id='plot.SentimentDictionaryWeighted'>KDE plot of estimated coefficients</h2><span id='topic+plot.SentimentDictionaryWeighted'></span>

<h3>Description</h3>

<p>Function performs a Kernel Density Estimation (KDE) of the coefficients and then
plot these using <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>. This type of plot allows to 
inspect whether the distribution of coefficients is skew. This can reveal if there
are more positive terms than negative or vice versa.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SentimentDictionaryWeighted'
plot(x, color = "gray60", theme = ggplot2::theme_bw(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SentimentDictionaryWeighted_+3A_x">x</code></td>
<td>
<p>Dictionary of class <code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
<tr><td><code id="plot.SentimentDictionaryWeighted_+3A_color">color</code></td>
<td>
<p>Color for filling the density plot (default: gray color)</p>
</td></tr>
<tr><td><code id="plot.SentimentDictionaryWeighted_+3A_theme">theme</code></td>
<td>
<p>Visualization theme for <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code> (default: is a black-white theme)</p>
</td></tr>
<tr><td><code id="plot.SentimentDictionaryWeighted_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot of class <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotSentiment">plotSentiment</a></code> and <code><a href="#topic+plotSentimentResponse">plotSentimentResponse</a></code> for further plotting options
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- SentimentDictionaryWeighted(paste0(character(100), 1:100), rnorm(100), numeric(100))
plot(d)

# Change color in plot
plot(d, color="red")

library(ggplot2)
# Extend plot with additional layout options
plot(d) + ggtitle("KDE plot")
plot(d) + theme_void() 
</code></pre>

<hr>
<h2 id='plotSentiment'>Line plot with sentiment scores</h2><span id='topic+plotSentiment'></span>

<h3>Description</h3>

<p>Simple line plot to visualize the evolvement of sentiment scores.
This is especially helpful when studying a time series of
sentiment scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSentiment(
  sentiment,
  x = NULL,
  cumsum = FALSE,
  xlab = "",
  ylab = "Sentiment"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotSentiment_+3A_sentiment">sentiment</code></td>
<td>
<p><code>data.frame</code> or numeric vector with sentiment scores</p>
</td></tr>
<tr><td><code id="plotSentiment_+3A_x">x</code></td>
<td>
<p>Optional parameter with labels or time stamps on x-axis.</p>
</td></tr>
<tr><td><code id="plotSentiment_+3A_cumsum">cumsum</code></td>
<td>
<p>Parameter deciding whether the cumulative sentiment
is plotted (default: <code>cumsum=FALSE</code>).</p>
</td></tr>
<tr><td><code id="plotSentiment_+3A_xlab">xlab</code></td>
<td>
<p>Name of x-axis (default: empty string).</p>
</td></tr>
<tr><td><code id="plotSentiment_+3A_ylab">ylab</code></td>
<td>
<p>Name of y-axis (default: &quot;Sentiment&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot of class <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotSentimentResponse">plotSentimentResponse</a></code> and <code><a href="#topic+plot.SentimentDictionaryWeighted">plot.SentimentDictionaryWeighted</a></code> for further plotting options
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sentiment &lt;- data.frame(Dictionary=runif(20))

plotSentiment(sentiment)
plotSentiment(sentiment, cumsum=TRUE)

# Change name of x-axis
plotSentiment(sentiment, xlab="Tone")

library(ggplot2)
# Extend plot with additional layout options
plotSentiment(sentiment) + ggtitle("Evolving sentiment")
plotSentiment(sentiment) + theme_void() 
</code></pre>

<hr>
<h2 id='plotSentimentResponse'>Scatterplot with trend line between sentiment and response</h2><span id='topic+plotSentimentResponse'></span>

<h3>Description</h3>

<p>Generates a scatterplot where points pairs of sentiment and
the response variable. In addition, the plot addas a trend line
in the form of a generalized additive model (GAM). Other
smoothing variables are possible based on <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code>.
This functions is helpful for visualization the relationship
between computed sentiment scores and the gold standard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSentimentResponse(
  sentiment,
  response,
  smoothing = "gam",
  xlab = "Sentiment",
  ylab = "Response"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotSentimentResponse_+3A_sentiment">sentiment</code></td>
<td>
<p><code>data.frame</code> with sentiment scores</p>
</td></tr>
<tr><td><code id="plotSentimentResponse_+3A_response">response</code></td>
<td>
<p>Vector with response variables of the same length</p>
</td></tr>
<tr><td><code id="plotSentimentResponse_+3A_smoothing">smoothing</code></td>
<td>
<p>Smoothing functionality. Default is <code>smoothing="gam"</code>
to utilize a generalized additive model (GAM). Other options can be e.g.
a linear trend line (<code>smoothing="lm"</code>); see <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code>
for a full list of options.</p>
</td></tr>
<tr><td><code id="plotSentimentResponse_+3A_xlab">xlab</code></td>
<td>
<p>Description on x-axis (default: &quot;Sentiment&quot;).</p>
</td></tr>
<tr><td><code id="plotSentimentResponse_+3A_ylab">ylab</code></td>
<td>
<p>Description on y-axis (default: &quot;Sentiment&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a plot of class <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotSentiment">plotSentiment</a></code> and <code><a href="#topic+plot.SentimentDictionaryWeighted">plot.SentimentDictionaryWeighted</a></code> for further plotting options
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sentiment &lt;- data.frame(Dictionary=runif(10))
response &lt;- sentiment[[1]] + rnorm(10)

plotSentimentResponse(sentiment, response)

# Change x-axis
plotSentimentResponse(sentiment, response, xlab="Tone")

library(ggplot2)
# Extend plot with additional layout options
plotSentimentResponse(sentiment, response) + ggtitle("Scatterplot")
plotSentimentResponse(sentiment, response) + theme_void() 
</code></pre>

<hr>
<h2 id='predict.SentimentDictionaryWeighted'>Prediction for given dictionary</h2><span id='topic+predict.SentimentDictionaryWeighted'></span>

<h3>Description</h3>

<p>Function takes a dictionary of class <code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code> with weights 
as input. It then applies this dictionary to textual contents in order to calculate
a sentiment score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SentimentDictionaryWeighted'
predict(
  object,
  newdata = NULL,
  language = "english",
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.SentimentDictionaryWeighted_+3A_object">object</code></td>
<td>
<p>Dictionary of class <code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code>.</p>
</td></tr>
<tr><td><code id="predict.SentimentDictionaryWeighted_+3A_newdata">newdata</code></td>
<td>
<p>A vector of characters, a <code>data.frame</code>, an object of type 
<code><a href="tm.html#topic+Corpus">Corpus</a></code>, <code><a href="tm.html#topic+TermDocumentMatrix">TermDocumentMatrix</a></code> or
<code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code> .</p>
</td></tr>
<tr><td><code id="predict.SentimentDictionaryWeighted_+3A_language">language</code></td>
<td>
<p>Language used for preprocessing operations (default: 
English).</p>
</td></tr>
<tr><td><code id="predict.SentimentDictionaryWeighted_+3A_weighting">weighting</code></td>
<td>
<p>Function used for weighting of words; default is a a link to the 
tf-idf scheme.</p>
</td></tr>
<tr><td><code id="predict.SentimentDictionaryWeighted_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for e.g. 
preprocessing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data.frame</code> with predicted sentiment scores.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code>, <code><a href="#topic+generateDictionary">generateDictionary</a></code> and
<code><a href="#topic+compareToResponse">compareToResponse</a></code> for default dictionary generations
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' # Create a vector of strings
documents &lt;- c("This is a good thing!",
               "This is a very good thing!",
               "This is okay.",
               "This is a bad thing.",
               "This is a very bad thing.")
response &lt;- c(1, 0.5, 0, -0.5, -1)

# Generate dictionary with LASSO regularization
dictionary &lt;- generateDictionary(documents, response)

# Compute in-sample performance
sentiment &lt;- predict(dictionary, documents)
compareToResponse(sentiment, response)
</code></pre>

<hr>
<h2 id='preprocessCorpus'>Default preprocessing of corpus</h2><span id='topic+preprocessCorpus'></span>

<h3>Description</h3>

<p>Preprocess existing corpus of type <code><a href="tm.html#topic+Corpus">Corpus</a></code> according to default operations. 
This helper function groups all standard preprocessing steps such that the usage of the 
package is more convenient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocessCorpus(
  corpus,
  language = "english",
  stemming = TRUE,
  verbose = FALSE,
  removeStopwords = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocessCorpus_+3A_corpus">corpus</code></td>
<td>
<p><code><a href="tm.html#topic+Corpus">Corpus</a></code> object which should be processed</p>
</td></tr>
<tr><td><code id="preprocessCorpus_+3A_language">language</code></td>
<td>
<p>Default language used for preprocessing (i.e. stop word removal and stemming)</p>
</td></tr>
<tr><td><code id="preprocessCorpus_+3A_stemming">stemming</code></td>
<td>
<p>Perform stemming (default: TRUE)</p>
</td></tr>
<tr><td><code id="preprocessCorpus_+3A_verbose">verbose</code></td>
<td>
<p>Print preprocessing status information</p>
</td></tr>
<tr><td><code id="preprocessCorpus_+3A_removestopwords">removeStopwords</code></td>
<td>
<p>Flag indicating whether to remove stopwords or not (default: yes)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of <code><a href="tm.html#topic+Corpus">Corpus</a></code>
</p>

<hr>
<h2 id='print.SentimentDictionaryWordlist'>Output content of sentiment dictionary</h2><span id='topic+print.SentimentDictionaryWordlist'></span><span id='topic+print.SentimentDictionaryBinary'></span><span id='topic+print.SentimentDictionaryWeighted'></span>

<h3>Description</h3>

<p>Prints entries of sentiment dictionary to the screen
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SentimentDictionaryWordlist'
print(x, ...)

## S3 method for class 'SentimentDictionaryBinary'
print(x, ...)

## S3 method for class 'SentimentDictionaryWeighted'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.SentimentDictionaryWordlist_+3A_x">x</code></td>
<td>
<p>Sentiment dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>, 
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or <code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
<tr><td><code id="print.SentimentDictionaryWordlist_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to specific sub-routines</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+summary">summary</a></code> for showing a brief summary
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(SentimentDictionary(c("uncertain", "possible", "likely")))
print(SentimentDictionary(c("increase", "rise", "more"),
                          c("fall", "drop")))
print(SentimentDictionary(c("increase", "decrease", "exit"),
                          c(+1, -1, -10),
                          rep(NA, 3)))
</code></pre>

<hr>
<h2 id='read'>Read dictionary from text file</h2><span id='topic+read'></span>

<h3>Description</h3>

<p>This routine reads a sentiment dictionary from a text file. Such a text file can
be created e.g. via <code><a href="#topic+write">write</a></code>. The dictionary type is recognized 
according to the internal format of the file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_+3A_file">file</code></td>
<td>
<p>File name pointing to text file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>,
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write">write</a></code> for creating such a file
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.out &lt;- SentimentDictionary(c("uncertain", "possible", "likely"))
write(d.out, "example.dict")
d.in &lt;- read("example.dict")
print(d.in)

d.out &lt;- SentimentDictionary(c("increase", "rise", "more"),
                             c("fall", "drop"))
write(d.out, "example.dict")
d.in &lt;- read("example.dict")
print(d.in)

d.out &lt;- SentimentDictionary(c("increase", "decrease", "exit"),
                             c(+1, -1, -10),
                             rep(NA, 3),
                             intercept=5)
write(d.out, "example.dict")
d.in &lt;- read("example.dict")
print(d.in)

unlink("example.dict")
</code></pre>

<hr>
<h2 id='ridgeEstimation'>Ridge estimation</h2><span id='topic+ridgeEstimation'></span>

<h3>Description</h3>

<p>Function estimates coefficients based on ridge regularization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ridgeEstimation(
  x,
  response,
  control = list(s = "lambda.min", family = "gaussian", grouped = FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ridgeEstimation_+3A_x">x</code></td>
<td>
<p>An object of type <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.</p>
</td></tr>
<tr><td><code id="ridgeEstimation_+3A_response">response</code></td>
<td>
<p>Response variable including the given gold standard.</p>
</td></tr>
<tr><td><code id="ridgeEstimation_+3A_control">control</code></td>
<td>
<p>(optional) A list of parameters defining the model as follows:
</p>

<ul>
<li><p>&quot;s&quot;Value of the parameter lambda at which the ridge is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li><p>&quot;family&quot;Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> for further details.
</p>
</li>
<li><p>&quot;grouped&quot; Determines whether grouped function is used (with default <code>FALSE</code>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="ridgeEstimation_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result is a list with coefficients, coefficient names and the model intercept.
</p>

<hr>
<h2 id='ruleLinearModel'>Sentiment based on linear model</h2><span id='topic+ruleLinearModel'></span>

<h3>Description</h3>

<p>Sentiment score as denoted by a linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ruleLinearModel(dtm, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ruleLinearModel_+3A_dtm">dtm</code></td>
<td>
<p>Document-term matrix</p>
</td></tr>
<tr><td><code id="ruleLinearModel_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Continuous sentiment score
</p>

<hr>
<h2 id='ruleNegativity'>Ratio of negative words</h2><span id='topic+ruleNegativity'></span>

<h3>Description</h3>

<p>Ratio of words labeled as negative in that dictionary compared to the total 
number of words in the document. Here, it uses the entry <code>negativeWords</code>
of the <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ruleNegativity(dtm, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ruleNegativity_+3A_dtm">dtm</code></td>
<td>
<p>Document-term matrix</p>
</td></tr>
<tr><td><code id="ruleNegativity_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Ratio of negative words compared to all
</p>

<hr>
<h2 id='rulePositivity'>Ratio of positive words</h2><span id='topic+rulePositivity'></span>

<h3>Description</h3>

<p>Ratio of words labeled as positive in that dictionary compared to the total 
number of words in the document. Here, it uses the entry <code>positiveWords</code>
of the <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rulePositivity(dtm, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rulePositivity_+3A_dtm">dtm</code></td>
<td>
<p>Document-term matrix</p>
</td></tr>
<tr><td><code id="rulePositivity_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Ratio of positive words compared to all
</p>

<hr>
<h2 id='ruleRatio'>Ratio of dictionary words</h2><span id='topic+ruleRatio'></span>

<h3>Description</h3>

<p>Ratio of words in that dictionary compared to the total number of words in
the document
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ruleRatio(dtm, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ruleRatio_+3A_dtm">dtm</code></td>
<td>
<p>Document-term matrix</p>
</td></tr>
<tr><td><code id="ruleRatio_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code> with words 
belonging to a single category</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Ratio of dictionary words compared to all
</p>

<hr>
<h2 id='ruleSentiment'>Sentiment score</h2><span id='topic+ruleSentiment'></span>

<h3>Description</h3>

<p>Sentiment score defined as the difference between positive and negative
word counts divided by the total number of words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ruleSentiment(dtm, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ruleSentiment_+3A_dtm">dtm</code></td>
<td>
<p>Document-term matrix</p>
</td></tr>
<tr><td><code id="ruleSentiment_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the number of positive words <code class="reqn">P</code> and the number of 
negative words <code class="reqn">N</code>. Further, let <code class="reqn">T</code> denote the total number of words
in that document. Then, the sentiment ratio is defined as 
</p>
<p style="text-align: center;"><code class="reqn">\frac{P-N}{T}</code>
</p>
<p>. Here, it uses the entries <code>negativeWords</code> and
<code>positiveWords</code> of the <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code>.
</p>


<h3>Value</h3>

<p>Sentiment score in the range of -1 to 1.
</p>

<hr>
<h2 id='ruleSentimentPolarity'>Sentiment polarity score</h2><span id='topic+ruleSentimentPolarity'></span>

<h3>Description</h3>

<p>Sentiment score defined as the difference between positive and negative
word counts divided by the sum of positive and negative words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ruleSentimentPolarity(dtm, d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ruleSentimentPolarity_+3A_dtm">dtm</code></td>
<td>
<p>Document-term matrix</p>
</td></tr>
<tr><td><code id="ruleSentimentPolarity_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the number of positive words <code class="reqn">P</code> and the number of 
negative words <code class="reqn">N</code>. Then, the sentiment ratio is defined as 
</p>
<p style="text-align: center;"><code class="reqn">\frac{P-N}{P+N}</code>
</p>
<p>. Here, it uses the entries <code>negativeWords</code> and
<code>positiveWords</code> of the <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code>.
</p>


<h3>Value</h3>

<p>Sentiment score in the range of -1 to 1.
</p>

<hr>
<h2 id='ruleWordCount'>Counts word frequencies</h2><span id='topic+ruleWordCount'></span>

<h3>Description</h3>

<p>Counts total word frequencies in each document
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ruleWordCount(dtm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ruleWordCount_+3A_dtm">dtm</code></td>
<td>
<p>Document-term matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Total number of words
</p>

<hr>
<h2 id='SentimentDictionary'>Create new sentiment dictionary based on input</h2><span id='topic+SentimentDictionary'></span>

<h3>Description</h3>

<p>Depending on the input, this function creates a new sentiment dictionary of different type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SentimentDictionary(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SentimentDictionary_+3A_...">...</code></td>
<td>
<p>Arguments as passed to one of the three functions 
<code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>, <code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>, 
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code>, 
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code>
</p>

<hr>
<h2 id='SentimentDictionaryBinary'>Create a sentiment dictionary of positive and negative words</h2><span id='topic+SentimentDictionaryBinary'></span>

<h3>Description</h3>

<p>This routines creates a new object of type <code>SentimentDictionaryBinary</code> that
stores two separate vectors of negative and positive words
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SentimentDictionaryBinary(positiveWords, negativeWords)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SentimentDictionaryBinary_+3A_positivewords">positiveWords</code></td>
<td>
<p>is a vector containing the entries labeled as positive</p>
</td></tr>
<tr><td><code id="SentimentDictionaryBinary_+3A_negativewords">negativeWords</code></td>
<td>
<p>is a vector containing the entries labeled as negative</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a new object of type <code>SentimentDictionaryBinary</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SentimentDictionary">SentimentDictionary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate a dictionary with positive and negative words
d &lt;- SentimentDictionaryBinary(c("increase", "rise", "more"),
                               c("fall", "drop"))
summary(d)
# alternative call
d &lt;- SentimentDictionary(c("increase", "rise", "more"),
                         c("fall", "drop"))
summary(d)
</code></pre>

<hr>
<h2 id='SentimentDictionaryWeighted'>Create a sentiment dictionary of words linked to a score</h2><span id='topic+SentimentDictionaryWeighted'></span>

<h3>Description</h3>

<p>This routine creates a new object of type <code>SentimentDictionaryWeighted</code> that
contains a number of words, each linked to a continuous score (i.e. weight) for
specifying its polarity. The scores can later be interpreted as a linear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SentimentDictionaryWeighted(
  words,
  scores,
  idf = rep(1, length(words)),
  intercept = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SentimentDictionaryWeighted_+3A_words">words</code></td>
<td>
<p>is collection (vector) of different words as strings</p>
</td></tr>
<tr><td><code id="SentimentDictionaryWeighted_+3A_scores">scores</code></td>
<td>
<p>are the corresponding scores or weights denoting the word's polarity</p>
</td></tr>
<tr><td><code id="SentimentDictionaryWeighted_+3A_idf">idf</code></td>
<td>
<p>provide further details on the frequency of words in the corpus as an
additional source for normalization</p>
</td></tr>
<tr><td><code id="SentimentDictionaryWeighted_+3A_intercept">intercept</code></td>
<td>
<p>is an optional parameter for shifting the zero level (default: 0)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a new object of type <code>SentimentDictionaryWordlist</code>
</p>


<h3>Note</h3>

<p>The intercept is useful when the mean or median of a response variable is 
not exactly located at zero. For instance, stock market returns have slight positive
bias.
</p>


<h3>Source</h3>

<p><a href="https://doi.org/10.1371/journal.pone.0209323">doi:10.1371/journal.pone.0209323</a>
</p>


<h3>References</h3>

<p>Pr\&quot;ollochs and Feuerriegel (2018). Statistical inferences for 
Polarity Identification in Natural Language, PloS One 13(12).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SentimentDictionary">SentimentDictionary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate dictionary (based on linear model)
d &lt;- SentimentDictionaryWeighted(c("increase", "decrease", "exit"),
                                 c(+1, -1, -10),
                                 rep(NA, 3))
summary(d)
# alternative call
d &lt;- SentimentDictionaryWeighted(c("increase", "decrease", "exit"),
                                 c(+1, -1, -10))
summary(d)
# alternative call
d &lt;- SentimentDictionary(c("increase", "decrease", "exit"),
                         c(+1, -1, -10),
                         rep(NA, 3))
summary(d)                                
</code></pre>

<hr>
<h2 id='SentimentDictionaryWordlist'>Create a sentiment dictionary consisting of a simple wordlist</h2><span id='topic+SentimentDictionaryWordlist'></span>

<h3>Description</h3>

<p>This routine creates a new object of type <code>SentimentDictionaryWordlist</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SentimentDictionaryWordlist(wordlist)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SentimentDictionaryWordlist_+3A_wordlist">wordlist</code></td>
<td>
<p>is a vector containing the individual entries as strings</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a new object of type <code>SentimentDictionaryWordlist</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SentimentDictionary">SentimentDictionary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate a dictionary with "uncertainty" words
d &lt;- SentimentDictionaryWordlist(c("uncertain", "possible", "likely"))
summary(d)
# alternative call
d &lt;- SentimentDictionary(c("uncertain", "possible", "likely"))
summary(d)
</code></pre>

<hr>
<h2 id='spikeslabEstimation'>Spike-and-slab estimation</h2><span id='topic+spikeslabEstimation'></span>

<h3>Description</h3>

<p>Function estimates coefficients based on spike-and-slab regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spikeslabEstimation(
  x,
  response,
  control = list(n.iter1 = 500, n.iter2 = 500),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spikeslabEstimation_+3A_x">x</code></td>
<td>
<p>An object of type <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>.</p>
</td></tr>
<tr><td><code id="spikeslabEstimation_+3A_response">response</code></td>
<td>
<p>Response variable including the given gold standard.</p>
</td></tr>
<tr><td><code id="spikeslabEstimation_+3A_control">control</code></td>
<td>
<p>(optional) A list of parameters defining the LASSO model. Default is<code>n.iter1=500</code> and <code>n.iter2=500</code>.
See <code><a href="spikeslab.html#topic+spikeslab">spikeslab</a></code> for details.</p>
</td></tr>
<tr><td><code id="spikeslabEstimation_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to function for <code><a href="spikeslab.html#topic+spikeslab">spikeslab</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result is a list with coefficients, coefficient names and the model intercept.
</p>

<hr>
<h2 id='summary.SentimentDictionaryWordlist'>Output summary information on sentiment dictionary</h2><span id='topic+summary.SentimentDictionaryWordlist'></span><span id='topic+summary.SentimentDictionaryBinary'></span><span id='topic+summary.SentimentDictionaryWeighted'></span>

<h3>Description</h3>

<p>Output summary information on sentiment dictionary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SentimentDictionaryWordlist'
summary(object, ...)

## S3 method for class 'SentimentDictionaryBinary'
summary(object, ...)

## S3 method for class 'SentimentDictionaryWeighted'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.SentimentDictionaryWordlist_+3A_object">object</code></td>
<td>
<p>Sentiment dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>, 
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or <code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
<tr><td><code id="summary.SentimentDictionaryWordlist_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to specific sub-routines</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+print">print</a></code> for output the entries of a dictionary
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(SentimentDictionary(c("uncertain", "possible", "likely")))
summary(SentimentDictionary(c("increase", "rise", "more"),
                            c("fall", "drop")))
summary(SentimentDictionary(c("increase", "decrease", "exit"),
                            c(+1, -1, -10),
                            rep(NA, 3)))
</code></pre>

<hr>
<h2 id='toDocumentTermMatrix'>Default preprocessing of corpus and conversion to document-term matrix</h2><span id='topic+toDocumentTermMatrix'></span>

<h3>Description</h3>

<p>Preprocess existing corpus of type <code><a href="tm.html#topic+Corpus">Corpus</a></code> according to default operations. 
This helper function groups all standard preprocessing steps such that the usage of the 
package is more convenient. The result is a document-term matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toDocumentTermMatrix(
  x,
  language = "english",
  minWordLength = 3,
  sparsity = NULL,
  removeStopwords = TRUE,
  stemming = TRUE,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="toDocumentTermMatrix_+3A_x">x</code></td>
<td>
<p><code><a href="tm.html#topic+Corpus">Corpus</a></code> object which should be processed</p>
</td></tr>
<tr><td><code id="toDocumentTermMatrix_+3A_language">language</code></td>
<td>
<p>Default language used for preprocessing (i.e. stop word removal and stemming)</p>
</td></tr>
<tr><td><code id="toDocumentTermMatrix_+3A_minwordlength">minWordLength</code></td>
<td>
<p>Minimum length of words used for cut-off; i.e. shorter words are 
removed. Default is 3.</p>
</td></tr>
<tr><td><code id="toDocumentTermMatrix_+3A_sparsity">sparsity</code></td>
<td>
<p>A numeric for the maximal allowed sparsity in the range from bigger zero to 
smaller one. Default is <code>NULL</code> in order suppress this functionality.</p>
</td></tr>
<tr><td><code id="toDocumentTermMatrix_+3A_removestopwords">removeStopwords</code></td>
<td>
<p>Flag indicating whether to remove stopwords or not (default: yes)</p>
</td></tr>
<tr><td><code id="toDocumentTermMatrix_+3A_stemming">stemming</code></td>
<td>
<p>Perform stemming (default: TRUE)</p>
</td></tr>
<tr><td><code id="toDocumentTermMatrix_+3A_weighting">weighting</code></td>
<td>
<p>Function used for weighting of words; default is a a link to the tf-idf scheme.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of <code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="tm.html#topic+DocumentTermMatrix">DocumentTermMatrix</a></code> for the underlying class
</p>

<hr>
<h2 id='transformIntoCorpus'>Transforms the input into a Corpus object</h2><span id='topic+transformIntoCorpus'></span>

<h3>Description</h3>

<p>Takes the given input of characters and transforms it into a <code><a href="tm.html#topic+Corpus">Corpus</a></code>. The input is checked to match the expected class and format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transformIntoCorpus(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transformIntoCorpus_+3A_x">x</code></td>
<td>
<p>A list, data.frame or vector consisting of characters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The generated <code>Corpus</code>
</p>


<h3>Note</h3>

<p>Factors are automatically casted into characters but with printing a warning
</p>


<h3>See Also</h3>

<p><code><a href="#topic+preprocessCorpus">preprocessCorpus</a></code> for further preprocessing, <code><a href="#topic+analyzeSentiment">analyzeSentiment</a></code> for subsequent sentiment analysis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>transformIntoCorpus(c("Document 1", "Document 2", "Document 3"))
transformIntoCorpus(list("Document 1", "Document 2", "Document 3"))
transformIntoCorpus(data.frame("Document 1", "Document 2", "Document 3"))
</code></pre>

<hr>
<h2 id='write'>Write dictionary to text file</h2><span id='topic+write'></span><span id='topic+write.SentimentDictionaryWordlist'></span><span id='topic+write.SentimentDictionaryBinary'></span><span id='topic+write.SentimentDictionaryWeighted'></span>

<h3>Description</h3>

<p>This routine exports a sentiment dictionary to a text file which can be the source
for additional problems or controlling the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write(d, file)

## S3 method for class 'SentimentDictionaryWordlist'
write(d, file)

## S3 method for class 'SentimentDictionaryBinary'
write(d, file)

## S3 method for class 'SentimentDictionaryWeighted'
write(d, file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_+3A_d">d</code></td>
<td>
<p>Dictionary of type <code><a href="#topic+SentimentDictionaryWordlist">SentimentDictionaryWordlist</a></code>,
<code><a href="#topic+SentimentDictionaryBinary">SentimentDictionaryBinary</a></code> or
<code><a href="#topic+SentimentDictionaryWeighted">SentimentDictionaryWeighted</a></code></p>
</td></tr>
<tr><td><code id="write_+3A_file">file</code></td>
<td>
<p>File to which the dictionary should be exported</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+read">read</a></code> for later access
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.out &lt;- SentimentDictionary(c("uncertain", "possible", "likely"))
write(d.out, "example.dict")
d.in &lt;- read("example.dict")
print(d.in)

d.out &lt;- SentimentDictionary(c("increase", "rise", "more"),
                             c("fall", "drop"))
write(d.out, "example.dict")
d.in &lt;- read("example.dict")
print(d.in)

d.out &lt;- SentimentDictionary(c("increase", "decrease", "exit"),
                             c(+1, -1, -10),
                             rep(NA, 3),
                             intercept=5)
write(d.out, "example.dict")
d.in &lt;- read("example.dict")
print(d.in)

unlink("example.dict")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
