<!DOCTYPE html><html><head><title>Help for package itdr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {itdr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#automobile'><p>Automobiles Data</p></a></li>
<li><a href='#d.boots'><p>Bootstrap Estimation for Dimension (d) of Sufficient Dimension Reduction Subspaces.</p></a></li>
<li><a href='#d.test'><p>Dimension Selection Testing Methods for the Central Mean Subspace.</p></a></li>
<li><a href='#dsp'><p>Distance Between Two Subspaces.</p></a></li>
<li><a href='#hyperPara'><p>Bootstrap Estimation for Hyperparameters.</p></a></li>
<li><a href='#itdr'><p>Integral Transformation Methods of Estimating SDR Subspaces in Regression.</p></a></li>
<li><a href='#mitdr'><p>Integral Transformation Methods for SDR Subspaces in Multivariate Regression</p></a></li>
<li><a href='#pdb'><p>Planning Database (Published in year 2015)</p></a></li>
<li><a href='#prostate'><p>Prostate Levels</p></a></li>
<li><a href='#raman'><p>Raman Spectroscopy</p></a></li>
<li><a href='#recumbent'><p>Recumbent Cows</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Integral Transformation Methods for SDR in Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats,utils,MASS,geigen,magic,energy,tidyr</td>
</tr>
<tr>
<td>Description:</td>
<td>The itdr() routine allows  for the estimation of sufficient dimension reduction subspaces in univariate regression such as the central mean subspace or central subspace in regression. This is achieved using Fourier transformation methods proposed by Zhu and Zeng (2006) &lt;<a href="https://doi.org/10.1198%2F016214506000000140">doi:10.1198/016214506000000140</a>&gt;, convolution transformation methods proposed by Zeng and Zhu (2010) &lt;<a href="https://doi.org/10.1016%2Fj.jmva.2009.08.004">doi:10.1016/j.jmva.2009.08.004</a>&gt;, and iterative Hessian transformation methods proposed by Cook and Li (2002) &lt;<a href="https://doi.org/10.1214%2Faos%2F1021379861">doi:10.1214/aos/1021379861</a>&gt;. Additionally, mitdr() function provides optimal estimators for sufficient dimension reduction subspaces in multivariate regression by optimizing a discrepancy function using a Fourier transform approach proposed by Weng and Yin (2022) &lt;<a href="https://doi.org/10.5705%2Fss.202020.0312">doi:10.5705/ss.202020.0312</a>&gt;, and selects the sufficient variables using Fourier transform sparse inverse regression estimators proposed by Weng (2022) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2021.107380">doi:10.1016/j.csda.2021.107380</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-25 17:55:58 UTC; talwis</td>
</tr>
<tr>
<td>Author:</td>
<td>Tharindu P. De Alwis
    <a href="https://orcid.org/0000-0002-3446-0502"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  S. Yaser Samadi <a href="https://orcid.org/0000-0002-6121-0234"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb, aut],
  Jiaying Weng <a href="https://orcid.org/0000-0002-9463-5714"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb, aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tharindu P. De Alwis &lt;talwis@wpi.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-26 13:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='automobile'>Automobiles Data</h2><span id='topic+automobile'></span>

<h3>Description</h3>

<p>This data set contains details about automobiles sources from 1985 Ward's Automotive Yearbook.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(automobile)
</code></pre>


<h3>Format</h3>

<p>A dataset consists of 205 observations and 26 attributes, including
</p>

<dl>
<dt>symboling</dt><dd><p>-3, -2, -1, 0, 1, 2, 3.</p>
</dd>
<dt>normalized</dt><dd><p>continuous Ranging from 65 to 256.</p>
</dd>
<dt>make</dt><dd><p>alfa-romero, audi, bmw, chevrolet, dodge, honda,isuzu, jaguar, mazda, mercedes-benz, mercury,mitsubishi, nissan, peugot, plymouth, porsche,renault, saab, subaru, toyota, volkswagen, volvo</p>
</dd>
<dt>fuel-type</dt><dd><p>diesel, gas.</p>
</dd>
<dt>aspiration</dt><dd><p>std, turbo.</p>
</dd>
<dt>num-of-doors</dt><dd><p>four, two.</p>
</dd>
<dt>body-style</dt><dd><p>hardtop, wagon, sedan, hatchback, convertible.</p>
</dd>
<dt>drive-wheels</dt><dd><p>4wd, fwd, rwd.</p>
</dd>
<dt>engine-location</dt><dd><p>front, rear.</p>
</dd>
<dt>wheel-base</dt><dd><p>continuous values, ranging from 86.6 120.9.</p>
</dd>
<dt>length</dt><dd><p>continuous values, ranging from 141.1 to 208.1.</p>
</dd>
<dt>width</dt><dd><p>continuous values, ranging from 60.3 to 72.3.</p>
</dd>
<dt>height</dt><dd><p>continuous values, ranging from 47.8 to 59.8.</p>
</dd>
<dt>curb-weight</dt><dd><p>continuous values, ranging from 1488 to 4066.</p>
</dd>
<dt>engine-type</dt><dd><p>dohc, dohcv, l, ohc, ohcf, ohcv, rotor.</p>
</dd>
<dt>num-of-cylinders</dt><dd><p>eight, five, four, six, three, twelve, two.</p>
</dd>
<dt>engine-size</dt><dd><p>continuous values, ranging from 61 to 326.</p>
</dd>
<dt>fuel-system</dt><dd><p>1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.</p>
</dd>
<dt>bore</dt><dd><p>continuous values, ranging from 2.54 to 3.94.</p>
</dd>
<dt>stroke</dt><dd><p>continuous values, ranging from 2.07 to 4.17.</p>
</dd>
<dt>compression-ratio</dt><dd><p>continuous values, ranging from 7 to 23.</p>
</dd>
<dt>horsepower</dt><dd><p>continuous values, ranging from 48 to 288.</p>
</dd>
<dt>peak-rpm</dt><dd><p>continuous values, ranging from 4150 to 6600.</p>
</dd>
<dt>city-mpg</dt><dd><p>continuous values, ranging from 13 to 49.</p>
</dd>
<dt>highway-mpg</dt><dd><p>continuous values, ranging from 16 to 54.</p>
</dd>
<dt>price</dt><dd><p>continuous values, ranging from 5118 to 45400.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/automobile">https://archive.ics.uci.edu/ml/datasets/automobile</a>
</p>

<hr>
<h2 id='d.boots'>Bootstrap Estimation for Dimension (d) of Sufficient Dimension Reduction Subspaces.</h2><span id='topic+d.boots'></span>

<h3>Description</h3>

<p>The function &ldquo;<em>d.boots()</em>&rdquo; estimates the dimension of the central mean subspace and the central subspaces in regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.boots(y,x,wx=0.1,wy=1,wh=1.5,B=500,var_plot=FALSE,space="mean"
                                        ,xdensity="normal",method="FM")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.boots_+3A_y">y</code></td>
<td>
<p>The n-dimensional response vector.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_x">x</code></td>
<td>
<p>The design matrix of the predictors with dimension n-by-p.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_wx">wx</code></td>
<td>
<p>(default 0.1). The tuning parameter for predictor variables.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_wy">wy</code></td>
<td>
<p>(default 1). The tuning parameter for the response variable.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_wh">wh</code></td>
<td>
<p>(default 1.5). The bandwidth of the kernel density estimation.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_b">B</code></td>
<td>
<p>(default 500). Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_var_plot">var_plot</code></td>
<td>
<p>(default FALSE). If TRUE, it provides the dimension variability plot.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_space">space</code></td>
<td>
<p>(default &ldquo;mean&rdquo;). The defalult is &ldquo;mean&rdquo; for the central mean subspace. Other option is &ldquo;pdf&rdquo; for estimating the central subspace.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_xdensity">xdensity</code></td>
<td>
<p>(default &ldquo;normal&rdquo;). Density function of predictor variables.
Options are &ldquo;normal&rdquo; for multivariate normal distribution, &ldquo;elliptic&rdquo;  for elliptical contoured distribution function, or &ldquo;kernel&rdquo; for estimating the distribution
using kernel smoothing.</p>
</td></tr>
<tr><td><code id="d.boots_+3A_method">method</code></td>
<td>
<p>(default &ldquo;FM&rdquo;). The integral transformation method. &ldquo;FM&rdquo; for Fourier trans-formation method (Zhu and Zeng 2006), and
&ldquo;CM&rdquo; for convolution transformation method (Zeng and Zhu 2010).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The outputs includes a table of average bootstrap distances between two subspaceses for each candidate value of <em>d</em> and the estimated value for <em>d</em>.
</p>
<table>
<tr><td><code>dis_d</code></td>
<td>
<p>A table of average bootstrap  distances for each candidate value of <em>d</em>.</p>
</td></tr>
<tr><td><code>d.hat</code></td>
<td>
<p>The estimated value for <code class="reqn">d</code>.</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>Provides the dimension variability plot if <em>plot=TRUE</em>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Use dataset available in itdr package
data(automobile)
head(automobile)
automobile.na &lt;- na.omit(automobile)
# prepare response and predictor variables
auto_y &lt;- log(automobile.na[, 26])
auto_xx &lt;- automobile.na[, c(10, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25)]
auto_x &lt;- scale(auto_xx) # Standardize the predictors
# call to the d.boots() function with required arguments
d_est &lt;- d.boots(auto_y, auto_x, var_plot = TRUE, space = "pdf", xdensity = "normal", method = "FM")
auto_d &lt;- d_est$d.hat

</code></pre>

<hr>
<h2 id='d.test'>Dimension Selection Testing Methods for the Central Mean Subspace.</h2><span id='topic+d.test'></span>

<h3>Description</h3>

<p>The &ldquo;<em>d.test()</em>&rdquo; function provides p-values for the hypothesis tests for the dimension of the subpsace. It employs three test statistics: Cook's test, Scaled test, and Adjusted test, using Fourier transform approach for inverse dimension reduction method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.test(y,x,m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.test_+3A_y">y</code></td>
<td>
<p>The n-dimensional response vector.</p>
</td></tr>
<tr><td><code id="d.test_+3A_x">x</code></td>
<td>
<p>The design matrix of the predictors with dimension n-by-p.</p>
</td></tr>
<tr><td><code id="d.test_+3A_m">m</code></td>
<td>
<p>An integer specifying the dimension of the central mean reduction subspace to be tested.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The null and alternative hypothesis are
</p>
<p style="text-align: center;"><code class="reqn">H_0: d=m</code>
</p>
   <p style="text-align: center;"><code class="reqn">H_a: d&gt;m</code>
</p>

<p>1. Weighted Chi-Square test statistics (Weng and Yin, 2018):
</p>
<p style="text-align: center;"><code class="reqn">\hat{\Lambda}=n\sum_{j=m+1}^{p}\hat{\lambda}_j,</code>
</p>

<p>where <code class="reqn">\lambda_j</code>'s are the eigenvalues of <code class="reqn">\widehat{\textbf{V}}</code>, defined under the &ldquo;<em>invFM()</em>&rdquo; function.
</p>
<p>2. Scaled test statistic (Bentler and Xie, 2000):
</p>
<p style="text-align: center;"><code class="reqn">\overline{T}_m=[trace(\hat{\Omega}_n)/p^{\star}]^{-1}n\sum_{j=m+1}^{p}\hat{\lambda}_j \sim \mathcal{X}^2_{p^{\star}},</code>
</p>

<p>where <code class="reqn">\hat{\Omega}_n</code> is a covariance matrix, and <code class="reqn">p^{\star} = (p-m)(2t-m)</code>.
</p>
<p>3. Adjusted test statistic (Bentler and Xie, 2000):
</p>
<p style="text-align: center;"><code class="reqn">\tilde{T}_m=[trace(\hat{\Omega}_n)/d^{\star}]^{-1}n\sum_{j=m+1}^{p}\hat{\lambda}_j \sim \mathcal{X}^2_{d^{\star}},</code>
</p>

<p>where <code class="reqn">d^{\star} = [trace(\hat{\Omega}_n)]^{2}/trace(\hat{\Omega}_n^2)</code> .
</p>


<h3>Value</h3>

<p>The <em>d.test()</em> function returns a table of p-values for each test.
</p>


<h3>References</h3>

<p>Bentler P. M., and Xie, J. (2000). Corrections to Test Statistics in Principal Hessian Directions.
<em>Statistics and Probability Letters</em>. 47, 381-389.
</p>
<p>Weng J., and Yin X. (2018). Fourier Transform Approach for Inverse Dimension Reduction Method. <em>Journal of Nonparametric Statistics</em>. 30, 4, 1029-0311.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pdb)
colnames(pdb) &lt;- NULL
p &lt;- 15
df &lt;- pdb[, c(79, 73, 77, 103, 112, 115, 124, 130, 132, 145, 149, 151, 153, 155, 167, 169)]
dff &lt;- as.matrix(df)
planingdb &lt;- dff[complete.cases(dff), ]
y &lt;- planingdb[, 1]
x &lt;- planingdb[, c(2:(p + 1))]
x &lt;- x + 0.5
xt &lt;- cbind(
  x[, 1]^(.33), x[, 2]^(.33), x[, 3]^(.57), x[, 4]^(.33), x[, 5]^(.4),
  x[, 6]^(.5), x[, 7]^(.33), x[, 8]^(.16), x[, 9]^(.27), x[, 10]^(.5),
  x[, 11]^(.5), x[, 12]^(.33), x[, 13]^(.06), x[, 14]^(.15), x[, 15]^(.1)
)
m &lt;- 1
W &lt;- sapply(1, rnorm)
d.test(y, x, m)

</code></pre>

<hr>
<h2 id='dsp'>Distance Between Two Subspaces.</h2><span id='topic+dsp'></span>

<h3>Description</h3>

<p>The &ldquo;<em>dsp()</em>&rdquo; function calculates the distance between two subspaces, which are spanned by the columns of two matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsp(A, B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsp_+3A_a">A</code></td>
<td>
<p>A matrix with dimension p-by-d.</p>
</td></tr>
<tr><td><code id="dsp_+3A_b">B</code></td>
<td>
<p>A matrix with dimension p-by-d.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <b>A</b> and <b>B</b> be two full rank matrices of size
<code class="reqn">p \times q</code>. Suppose <code class="reqn">\mathcal{S}(\textbf{A})</code> and
<code class="reqn">\mathcal{S}(\textbf{B})</code> are the column subspaces of matrices
<b>A</b> and <b>B</b>, respectively.
And, let <code class="reqn">\lambda_i</code> 's with
<code class="reqn">1 \geq \lambda_1^2 \geq \lambda_2^2 \geq,\cdots,\lambda_p^2\geq 0</code>,
be the eigenvalues of the matrix <code class="reqn">\textbf{B}^T\textbf{A}\textbf{A}^T\textbf{B}</code>.
</p>
<p>1.Trace correlation, (Hotelling, 1936): </p>
<p style="text-align: center;"><code class="reqn">\gamma=\sqrt{\frac{1}{p}\sum_{i=1}^{p}\lambda_i^2}</code>
</p>

<p>2.Vector correlation, (Hooper, 1959): </p>
<p style="text-align: center;"><code class="reqn">\theta=\sqrt{\prod_{i=1}^{p}\lambda_i^2}</code>
</p>



<h3>Value</h3>

<p>Outputs are the following scale values.
</p>
<table>
<tr><td><code>r</code></td>
<td>
<p>One mines the trace correlation. That is, <code class="reqn">r=1-\gamma</code> </p>
</td></tr>
<tr><td><code>q</code></td>
<td>
<p>One mines the vector correlation. That is, <code class="reqn">q=1-\theta</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Hooper J. (1959). Simultaneous Equations and Canonical Correlation Theory. <em>Econometrica</em> 27, 245-256.
</p>
<p>Hotelling H. (1936). Relations Between Two Sets of Variates. <em>Biometrika</em> 28, 321-377.
</p>

<hr>
<h2 id='hyperPara'>Bootstrap Estimation for Hyperparameters.</h2><span id='topic+hyperPara'></span>

<h3>Description</h3>

<p>The &ldquo;<em>hyperPara()</em>&rdquo; function estimates the hyperparameters that required in the Fourier transformation method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hyperPara(y,x,d,wx=0.1,wy=1,wh=1.5,range=seq(0.1,1,by=.1),
xdensity="normal", B=500,space="mean", method="FM",hyper="wy")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hyperPara_+3A_y">y</code></td>
<td>
<p>The n-dimensional response vector.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_x">x</code></td>
<td>
<p>The design matrix of the predictors with dimension n-by-p.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_d">d</code></td>
<td>
<p>An integer specifying the dimension of the sufficient dimension reduction subspace.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_wx">wx</code></td>
<td>
<p>(default 0.1). Tuning parameter for the predictor variables.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_wy">wy</code></td>
<td>
<p>(default 1). Tuning parameter for the response variable.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_wh">wh</code></td>
<td>
<p>(default 1.5). Turning parameter for the bandwidth.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_range">range</code></td>
<td>
<p>(default 0.1,0.2,...,1). A sequence of candidate values for the hyperparameter.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_xdensity">xdensity</code></td>
<td>
<p>Density function of predictor variables.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_b">B</code></td>
<td>
<p>(default 500). Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_space">space</code></td>
<td>
<p>(default &ldquo;mean&rdquo;). Specifies whether to estimate the central mean subspace (&ldquo;mean&rdquo;) or the central subspace (&ldquo;pdf&rdquo;).</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_method">method</code></td>
<td>
<p>(default &ldquo;FM&rdquo;). Integral transformation method. &ldquo;FM&rdquo; for the Fourier trans-formation method (Zhu and Zeng 2006), and
&ldquo;CM&rdquo; for the convolution transformation method (Zeng and Zhu 2010).</p>
</td></tr>
<tr><td><code id="hyperPara_+3A_hyper">hyper</code></td>
<td>
<p>(default &ldquo;wy&rdquo;). The hyperparameter to be estimated. Other choices are &ldquo;wx&rdquo; and &ldquo;wy&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The outputs are a table of average bootstrap distances between two subspaces for each candidate value of the hyper parameter.
</p>
<table>
<tr><td><code>dis_h</code></td>
<td>
<p>A table of average bootstrap distances for each candidate value of the hyperparameter.</p>
</td></tr>
<tr><td><code>h.hat</code></td>
<td>
<p>The estimated hyperparameter.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zeng P. and Zhu Y. (2010).
An Integral Transform Method for Estimating the Central Mean and Central Subspaces. <em>Journal of Multivariate Analysis</em>. 101, 1, 271&ndash;290.
</p>
<p>Zhu Y. and Zeng P. (2006).
Fourier Methods for Estimating the Central Subspace and Central Mean Subspace in Regression. <em>Journal of the American Statistical Association</em>. 101, 476, 1638&ndash;1651.
</p>

<hr>
<h2 id='itdr'>Integral Transformation Methods of Estimating SDR Subspaces in Regression.</h2><span id='topic+itdr'></span>

<h3>Description</h3>

<p>The &ldquo;<em>itdr()</em>&rdquo; function computes a basis for sufficient dimension reduction subspaces
in regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itdr(y,x,d,m=50,wx=0.1,wy=1,wh=1.5,space="mean",
xdensity="normal",method="FM",x.scale=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itdr_+3A_y">y</code></td>
<td>
<p>The n-dimensional response vector.</p>
</td></tr>
<tr><td><code id="itdr_+3A_x">x</code></td>
<td>
<p>The design matrix of the predictors with dimension n-by-p.</p>
</td></tr>
<tr><td><code id="itdr_+3A_d">d</code></td>
<td>
<p>An integer specifying the dimension of the sufficient dimension reduction subspace.</p>
</td></tr>
<tr><td><code id="itdr_+3A_m">m</code></td>
<td>
<p>An integer specifying the number of omega values to use in invFM method.</p>
</td></tr>
<tr><td><code id="itdr_+3A_wx">wx</code></td>
<td>
<p>(default 0.1). Tuning parameter for predictor variables.</p>
</td></tr>
<tr><td><code id="itdr_+3A_wy">wy</code></td>
<td>
<p>(default 1). Tuning parameter for response variable.</p>
</td></tr>
<tr><td><code id="itdr_+3A_wh">wh</code></td>
<td>
<p>(default 1.5). Bandwidth of the kernel density estimation function.</p>
</td></tr>
<tr><td><code id="itdr_+3A_space">space</code></td>
<td>
<p>(default &ldquo;mean&rdquo;). Specifies whether to estimate the central mean subspace (&ldquo;mean&rdquo;) or the central subspace (&ldquo;pdf&rdquo;).</p>
</td></tr>
<tr><td><code id="itdr_+3A_xdensity">xdensity</code></td>
<td>
<p>(default &ldquo;normal&rdquo;). Density function of predictor variables. Options are
&ldquo;normal&rdquo;  for multivariate normal distribution,
&ldquo;elliptic&rdquo;  for elliptical contoured distribution, or
&ldquo;kernel&rdquo; for unkown distribution estimated using kernel smoothing method.</p>
</td></tr>
<tr><td><code id="itdr_+3A_method">method</code></td>
<td>
<p>(default &ldquo;FM&rdquo;). Integral transformation method. &ldquo;FM&rdquo; for the Fourier transformation method (Zhu and Zeng 2006),
&ldquo;CM&rdquo; for convolution transformation method (Zeng and Zhu 2010),
&ldquo;iht&rdquo; for the iterative Hessian transformation method (Cook and Li 2002),
and &ldquo;invFM&rdquo; for the Fourier transformation approach for inverse dimension reduction method (Weng and Yin, 2018).</p>
</td></tr>
<tr><td><code id="itdr_+3A_x.scale">x.scale</code></td>
<td>
<p>(default TURE). If TRUE, scale the predictor variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let m(<b>x</b>)=E[y|<b>X</b>=<b>x</b>]. The &ldquo;<em>itdr()</em>&rdquo; function computes the integral transformation of the gradient of the mean function m(<b>x</b>), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol\psi(\boldsymbol\omega) =\int \frac{\partial}{\partial \textbf{x}}m(\textbf{x}) W(\textbf{x},\boldsymbol\omega)f(\textbf{x})d\textbf{x},</code>
</p>

<p>where <code class="reqn">W(\textbf{x},\boldsymbol\omega)</code> is a non degenerate kernel function and an absolutely integrable function. For Fourier transformation (FM) method and for convolution transformation (CM) method <code class="reqn">W(\textbf{x},\boldsymbol\omega)=\exp(i\boldsymbol\omega^T\textbf{x})</code> 
and <code class="reqn">W(\textbf{x},\boldsymbol\omega)=H(\textbf{x}-\boldsymbol\omega)=(2\pi\sigma_w^2)^{-p/2}\exp(-(\textbf{x}-\boldsymbol{\omega})^T(\textbf{x}-\boldsymbol\omega)/(2\sigma_w^2))</code> 
where is <code class="reqn">\sigma_w^2</code> is the turning parameter for predictor variables.
The candidate matrix to estimate the central mean subspace (CMS) is
</p>
<p style="text-align: center;"><code class="reqn">\textbf{M}_{CMS}=\int \boldsymbol\psi(\boldsymbol\omega) \boldsymbol\psi(\boldsymbol\omega)^T K(\boldsymbol\omega)d\boldsymbol\omega, </code>
</p>

<p>where <code class="reqn">K(\boldsymbol{\omega})=(2\pi \sigma_w^2)^{-p/2}\exp{(-||\boldsymbol{\omega}||}/2\sigma_w^2)</code> under &ldquo;FM&rdquo;, and <code class="reqn">K(\boldsymbol{\omega})=1</code> under &ldquo;CM&rdquo;.
Here, <code class="reqn">\sigma_w^2</code> is a tuning parameter and it refers as &quot;tuning parameter for the predictor variables&quot; and denoted by &ldquo;wx&rdquo; in all functions.
</p>
<p>Let <code class="reqn">\{T_v(y)=H(y,v),~ for~~ y,v\in \mathcal{R}\}</code> be the family of transformations for the response variable. That is, <code class="reqn">v \in \mathcal{R}</code>, the mean
response of <code class="reqn">T_v(y)</code> is <code class="reqn">m(\boldsymbol{\omega},v)=E[H(y,v)\vert \textbf{X}=\textbf{x}]</code>. Then, integral transformation for the gradient of
<code class="reqn">m(\boldsymbol{\omega},v)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol{\psi}(\boldsymbol{\omega},v)=\int \frac{\partial}{\partial \textbf{x}}m(\textbf{x},v) W(\textbf{x},\boldsymbol{\omega})f(\textbf{x})d\textbf{x},</code>
</p>

<p>where <code class="reqn">W(\textbf{x},\boldsymbol{\omega})</code> is define as above. Then, for estimating the central subspace (CS) the
candidate matrix is defined as
</p>
<p style="text-align: center;"><code class="reqn">\textbf{M}_{CS}=\int H(y_1,v)H(y_2,v)dv \int \boldsymbol{\psi}(\boldsymbol{\omega}) \bar{\boldsymbol{\psi}}(\boldsymbol{\omega})^T K(\boldsymbol{\omega})d\boldsymbol{\omega},</code>
</p>

<p>where <code class="reqn">K(\boldsymbol{\omega})</code> is the same as above, and <code class="reqn">H(y,v)=(2\pi \sigma_t^2)^{-1/2}\exp(v^2/(2\sigma_t^2))</code> under  &ldquo;FM&rdquo;,
and <code class="reqn">H(y,v)=(2\pi \sigma_t^2)^{-1/2}\exp((y-v)^2/(2\sigma_t^2))</code> under &ldquo;CM&rdquo;.
Here <code class="reqn">\sigma_t^2</code> is a tuning parameter and it refers as the &quot;tuning parameter for the response variable&quot; and is denote by &ldquo;wy&rdquo; in all functions.
</p>
<p><b>Remark:</b> There is only one tuning parameter in the candidate matrix for estimating of the CMS, and there are two tuning
parameters in the candidate matrix for estimating of the CS.
</p>
<p><b>&ldquo;invFM&rdquo; method:</b>
</p>
<p>Let <code class="reqn">(\textbf{y}_i,\textbf{x}_i), i =1,\cdots,n</code>, be a random sample, and assume that the dimension of <code class="reqn">S_{E(\textbf{Z} | \textbf{Y})}</code> is known to be <em>d</em>.
Then, for a random finite sequence of <code class="reqn">\boldsymbol{\omega}_j \in {R}^p</code>, <code class="reqn">j=1,\cdots,t</code>, compute <code class="reqn">\widehat{\boldsymbol{\psi}}(\boldsymbol{\omega}_j)</code> as follows (Weng and Yin, 2018):
</p>
<p style="text-align: center;"><code class="reqn">\widehat{\boldsymbol{\psi}}(\boldsymbol{\omega}_j)=n^{-1}\sum_{k=1}^n \exp( i \boldsymbol{\omega}_j^T\textbf{y}_k)\widehat{\textbf{Z}}_k, j=1,\cdots,t,</code>
</p>

<p>where <code class="reqn">\widehat{\textbf{Z}}_j=\boldsymbol{\Sigma}_{x}^{-1/2}(\textbf{x}_i-\overline{\textbf{x}})</code>. Now, let
<code class="reqn">\textbf{a}(\boldsymbol{\omega}_j)=Real(\widehat{\boldsymbol{\psi}}(\boldsymbol{\omega}_j))</code>, and <code class="reqn">\textbf{b}(\boldsymbol{\omega}_j)=Image(\widehat{\boldsymbol{\psi}}(\boldsymbol{\omega}_j))</code>. Then,
<code class="reqn">\widehat{\boldsymbol{\Psi}}= (\textbf{a}(\boldsymbol{\omega}_1),\textbf{b}(\boldsymbol{\omega}_1),\cdots,\textbf{a}(\boldsymbol{\omega}_t),\textbf{b}(\boldsymbol{\omega}_t))</code>, for some <code class="reqn">t &gt; 0</code>, and the population kernel matrix is
<code class="reqn">\widehat{\textbf{V}} = \widehat{\boldsymbol{\Psi}}\widehat{\boldsymbol{\Psi}}^T</code>. Finally, use the <em>d</em>-leading eigenvectors of <code class="reqn">\widehat{\textbf{V}}</code> as an estimate for the central subspace.
</p>
<p><b>Remark: </b>We use <em>w</em> instead of <code class="reqn">\boldsymbol{\omega}_1,\cdots,\boldsymbol{\omega}_t</code> in the <em>itdr()</em> function.
</p>


<h3>Value</h3>

<p>The outputs are a p-by-d matrix and a p-by-p matrix defined as follows.
</p>
<table>
<tr><td><code>eta_hat</code></td>
<td>
<p>The estimated p by d matrix, whose coloumns form a basis of the CMS/CS.</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>The estimated p by p candidate matrix.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>Eigenvalues of <code class="reqn">\widehat{\bold{V}}</code> from the &ldquo;invFM&rdquo; method.</p>
</td></tr>
<tr><td><code>psi</code></td>
<td>
<p>Estimation for <code class="reqn">\widehat{\bold{\Psi}}</code> from the &ldquo;invFM&rdquo; method.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cook R. D. and Li, B., (2002).
Dimension Reduction for Conditional Mean in Regression. <em>The Annals of Statistics</em>. 30, 455-474.
</p>
<p>Weng J. and Yin X. (2018).
Fourier Transform Approach for Inverse Dimension Reduction Method. <em>Journal of Nonparametric Statistics</em>. 30, 4, 1029-0311.
</p>
<p>Zeng P. and Zhu Y. (2010).
An Integral Transform Method for Estimating the Central Mean and Central Subspaces. <em>Journal of Multivariate Analysis</em>. 101, 1, 271&ndash;290.
</p>
<p>Zhu Y. and Zeng P. (2006).
Fourier Methods for Estimating the Central Subspace and Central Mean Subspace in Regression. <em>Journal of the American Statistical Association</em>. 101, 476, 1638&ndash;1651.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(automobile)
head(automobile)
automobile.na &lt;- na.omit(automobile)
wx &lt;- .14
wy &lt;- .9
wh &lt;- 1.5
d &lt;- 2
p &lt;- 13
df &lt;- cbind(automobile[, c(26, 10, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25)])
dff &lt;- as.matrix(df)
automobi &lt;- dff[complete.cases(dff), ]
y &lt;- automobi[, 1]
x &lt;- automobi[, c(2:14)]
xt &lt;- scale(x)
fit.F_CMS &lt;- itdr(y, xt, d, wx, wy, wh, space = "pdf", xdensity = "normal", method = "FM")
round(fit.F_CMS$eta_hat, 2)

</code></pre>

<hr>
<h2 id='mitdr'>Integral Transformation Methods for SDR Subspaces in Multivariate Regression</h2><span id='topic+mitdr'></span>

<h3>Description</h3>

<p>The &ldquo;<em>mitdr()</em>&rdquo; function implements transformation method for multivariate regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mitdr(X,Y,d,m,method="FT-IRE",
                lambda=NA,noB = 5,noC = 20,noW = 2,sparse.cov = FALSE, x.scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mitdr_+3A_x">X</code></td>
<td>
<p>Design matrix with dimension n-by-p</p>
</td></tr>
<tr><td><code id="mitdr_+3A_y">Y</code></td>
<td>
<p>Response matrix with dimension n-by-q</p>
</td></tr>
<tr><td><code id="mitdr_+3A_d">d</code></td>
<td>
<p>Structure dimension (default 2).</p>
</td></tr>
<tr><td><code id="mitdr_+3A_m">m</code></td>
<td>
<p>The number of omegas, i.e., 2m number of integral transforms</p>
</td></tr>
<tr><td><code id="mitdr_+3A_method">method</code></td>
<td>
<p>(default &ldquo;FT-IRE&rdquo;) Specify the method of dimension reduction. Other possible choices are &ldquo;FT-DIRE&rdquo;,&ldquo;FT-SIRE&rdquo;,&ldquo;FT-RIRE&rdquo;, &ldquo;FT-DRIRE&rdquo;, and &ldquo;admmft&rdquo;.</p>
</td></tr>
<tr><td><code id="mitdr_+3A_lambda">lambda</code></td>
<td>
<p>Tuning Parameter for &ldquo;admmft&rdquo; method. If it is not provided, the optimal lambda value is chosen by cross-validation of the Fourier transformation method.</p>
</td></tr>
<tr><td><code id="mitdr_+3A_nob">noB</code></td>
<td>
<p>(default 5) Iterations for updating B. Only required for the &ldquo;admmft&rdquo; method.</p>
</td></tr>
<tr><td><code id="mitdr_+3A_noc">noC</code></td>
<td>
<p>(default 20) Iterations for updating C. Only required for the &ldquo;admmft&rdquo; method.</p>
</td></tr>
<tr><td><code id="mitdr_+3A_now">noW</code></td>
<td>
<p>(default 2) Iterations for updating weight. Only required for the &ldquo;admmft&rdquo; method.</p>
</td></tr>
<tr><td><code id="mitdr_+3A_sparse.cov">sparse.cov</code></td>
<td>
<p>(default FALSE) If TRUE, calculates the soft-threshold matrix. Only required for the &ldquo;admmft&rdquo; method.</p>
</td></tr>
<tr><td><code id="mitdr_+3A_x.scale">x.scale</code></td>
<td>
<p>(default FALSE) If TRUE, standardizes each variable for the soft-threshold matrix. Only required for the &ldquo;admmft&rdquo; method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &ldquo;<em>mitdr()</em>&rdquo; function selects the sufficient variables using Fourier transformation sparse inverse regression estimators.
</p>


<h3>Value</h3>

<p>The function output is a p-by-d matrix and the estimated covariance matrix.
</p>
<table>
<tr><td><code>Beta_hat</code></td>
<td>
<p>An estimator for the SDR subspace.</p>
</td></tr>
<tr><td><code>sigma_X</code></td>
<td>
<p>Estimated covariance matrix only from the &ldquo;admmft&rdquo; method and a null matrix for other methods.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Weng, J. (2022), Fourier Transform Sparse Inverse Regression Estimators for Sufficient Variable Selection,
<em> Computational Statistics &amp; Data Analysis</em>, 168, 107380.
</p>
<p>Weng, J., &amp; Yin, X. (2022). A Minimum Discrepancy Approach with Fourier
Transform in Sufficient Dimension Reduction. <em>Statistica Sinica</em>, 32.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(prostate)
Y &lt;- as.matrix(prostate[, 9])
X &lt;- as.matrix(prostate[, -9])
fit.ftire &lt;- mitdr(X, Y, d = 1, method = "FT-DRIRE")
fit.ftire$Beta_hat

## End(Not run)
</code></pre>

<hr>
<h2 id='pdb'>Planning Database (Published in year 2015)</h2><span id='topic+pdb'></span>

<h3>Description</h3>

<p>The Planning Database (pdb) contains selected data from the 2010 Census and the 2009-2013, 5-years American Community Survey (ACS) estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pdb)
</code></pre>


<h3>Format</h3>

<p>A dataset with 815 observations and 344 attributes.
</p>


<h3>Source</h3>

<p><a href="https://www.census.gov/data/datasets/2015/adrm/research/2015-planning-database.html">https://www.census.gov/data/datasets/2015/adrm/research/2015-planning-database.html</a>
</p>

<hr>
<h2 id='prostate'>Prostate Levels</h2><span id='topic+prostate'></span>

<h3>Description</h3>

<p>The dataset comprises the level of prostate-specific antigen
associated with eight clinical measures in 97 male patients
undergoing a radical prostatectomy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prostate)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 97 rows and 9 columns.
</p>


<h3>References</h3>

<p>Stamey, T. A., Kabalin, J. N., McNeal, J. E., Johnstone, I. M., Freiha, F., Redwine, E. A. et al.
(1989). Prostate specific Antigen in the Diagnosis and Treatment of Adenocarcinoma of the
Prostate. II. <em>Radical prostatectomy treated patients. The Journal of Urology</em>.
141, 1076, 1083.
</p>

<hr>
<h2 id='raman'>Raman Spectroscopy</h2><span id='topic+raman'></span>

<h3>Description</h3>

<p>The Raman dataset contains 69 samples of providing fatty acid information in terms of
the percentage of total sample weight and the percentage of total fat content
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raman)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 69 rows and 1100 columns.
</p>


<h3>References</h3>

<p>Naes T., Tomic O., Afseth N.K., Segtnan V., Mage I. (2013)
Multi-Block Regression Based on Combinations of Orthogonalisation, Pls-Regression and Canonical
Correlation Analysis. <em>Chemometrics and Intelligent Laboratory Systems</em>. 124, 32-42.
</p>

<hr>
<h2 id='recumbent'>Recumbent Cows</h2><span id='topic+recumbent'></span>

<h3>Description</h3>

<p>The recumbent dataset contains information on pregnant dairy cows that become
recumbent, i.e., they lie down shortly before or after calving for unknown reasons. This condition
can be severe and frequently leads to death of the cow. Clark, Henderson,
Hoggard, Ellison and Young (1987) analyzed data collected at the Ruakura (N.Z.)
Animal Health Laboratory on a sample of recumbent cows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(recumbent)
</code></pre>


<h3>Format</h3>

<p>A dataset with 9 columns and 435 rows.
</p>


<h3>Source</h3>

<p>Clark, R. G., Henderson, H. V., Hoggard, G. K. Ellison, R. S. and Young, B. J. (1987).
The Abiltiy of Biochemical and Haematolgical Tests to Predict Recovery in Periparturient
Recumbent Cows. <em> NZ Veterinary Journal</em>. 35, 126-133.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
