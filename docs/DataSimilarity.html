<!DOCTYPE html><html lang="en"><head><title>Help for package DataSimilarity</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DataSimilarity}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#DataSimilarity-package'>
<p>Quantifying Similarity of Datasets and Multivariate Two- And k-Sample Testing</p></a></li>
<li><a href='#Bahr'>
<p>Bahr (1996) multivariate two-sample test</p></a></li>
<li><a href='#BallDivergence'>
<p>Ball Divergence based two- or <code class="reqn">k</code>-sample test</p></a></li>
<li><a href='#BF'>
<p>Baringhaus and Franz (2010) rigid motion invariant multivariate two-sample test</p></a></li>
<li><a href='#BG'>
<p>Biau and Gyorfi (2005) two-sample homogeneity test</p></a></li>
<li><a href='#BG2'>
<p>Biswas and Ghosh (2014) Two-Sample Test</p></a></li>
<li><a href='#BMG'>
<p>Biswas et al. (2014) two-sample run test</p></a></li>
<li><a href='#BQS'>
<p>Barakat et al. (1996) Two-Sample Test</p></a></li>
<li><a href='#C2ST'>
<p>Classifier Two-Sample Test</p></a></li>
<li><a href='#CCS'>
<p>Weighted Edge-Count Two-Sample Test</p></a></li>
<li><a href='#CCS_cat'>
<p>Weighted Edge-Count Two-Sample Test for Discrete Data</p></a></li>
<li><a href='#CF'>
<p>Generalized Edge-Count Test</p></a></li>
<li><a href='#CF_cat'>
<p>Generalized Edge-Count Test for Discrete Data</p></a></li>
<li><a href='#CMDistance'>
<p>Constrained Minimum Distance</p></a></li>
<li><a href='#Cramer'>
<p>Cram√©r Two-Sample Test</p></a></li>
<li><a href='#dipro.fun'>
<p>Direction-Projection Functions for DiProPerm Test</p></a></li>
<li><a href='#DiProPerm'>
<p>Direction-Projection-Permutation (DiProPerm) Test</p></a></li>
<li><a href='#DISCOB'>
<p>Distance Components (DISCO) Tests</p></a></li>
<li><a href='#DISCOF'>
<p>Distance Components (DISCO) Tests</p></a></li>
<li><a href='#DS'>
<p>Rank-Based Energy Test (Deb and Sen, 2021)</p></a></li>
<li><a href='#Energy'>
<p>Energy Statistic and Test</p></a></li>
<li><a href='#engineerMetric'>
<p>Engineer Metric</p></a></li>
<li><a href='#FR'>
<p>Friedman-Rafsky Test</p></a></li>
<li><a href='#FR_cat'>
<p>Friedman-Rafsky Test for Discrete Data</p></a></li>
<li><a href='#FStest'>
<p>Multisample FS Test</p></a></li>
<li><a href='#GGRL'>
<p>Decision-Tree Based Measure of Dataset Distance and Two-Sample Test</p></a></li>
<li><a href='#GPK'>
<p>Generalized Permutation-Based Kernel (GPK) Two-Sample Test</p></a></li>
<li><a href='#gTests'>
<p>Graph-Based Tests</p></a></li>
<li><a href='#gTests_cat'>
<p>Graph-Based Tests for Discrete Data</p></a></li>
<li><a href='#gTestsMulti'>
<p>Graph-Based Multi-Sample Test</p></a></li>
<li><a href='#HamiltonPath'>
<p>Shortest Hamilton path</p></a></li>
<li><a href='#HMN'>
<p>Random Forest Based Two-Sample Test</p></a></li>
<li><a href='#Jeffreys'>
<p>Jeffreys divergence</p></a></li>
<li><a href='#kerTests'>
<p>Generalized Permutation-Based Kernel (GPK) Two-Sample Test</p></a></li>
<li><a href='#KMD'>
<p>Kernel Measure of Multi-Sample Dissimilarity (KMD)</p></a></li>
<li><a href='#knn'>
<p>K-Nearest Neighbor Graph</p></a></li>
<li><a href='#LHZ'>
<p>Li et al. (2022) empirical characteristic distance</p></a></li>
<li><a href='#LHZStatistic'>
<p>Calculation of the Li et al. (2022) empirical characteristic distance</p></a></li>
<li><a href='#MMCM'>
<p>Multisample Mahalanobis Crossmatch (MMCM) Test</p></a></li>
<li><a href='#MMD'>
<p>Maximum Mean Discrepancy (MMD) Test</p></a></li>
<li><a href='#MST'>
<p>Minimum Spanning Tree (MST)</p></a></li>
<li><a href='#MW'>
<p>Nonparametric Graph-Based LP (GLP) Test</p></a></li>
<li><a href='#NKT'>
<p>Decision-Tree Based Measure of Dataset Similarity (<cite>Ntoutsi et al., 2008</cite>)</p></a></li>
<li><a href='#OTDD'>
<p>Optimal Transport Dataset Distance</p></a></li>
<li><a href='#Petrie'>
<p>Multisample Crossmatch (MCM) Test</p></a></li>
<li><a href='#rectPartition'>
<p>Calculate a rectangular partition</p></a></li>
<li><a href='#RItest'>
<p>Multisample RI Test</p></a></li>
<li><a href='#Rosenbaum'>
<p>Rosenbaum Crossmatch Test</p></a></li>
<li><a href='#SC'>
<p>Graph-Based Multi-Sample Test</p></a></li>
<li><a href='#SH'>
<p>Schilling-Henze Nearest Neighbor Test</p></a></li>
<li><a href='#stat.fun'>
<p>Univariate Two-Sample Statistics for DiProPerm Test</p></a></li>
<li><a href='#Wasserstein'>
<p>Wasserstein Distance based Test</p></a></li>
<li><a href='#YMRZL'>
<p>Yu et al. (2007) Two-Sample Test</p></a></li>
<li><a href='#ZC'>
<p>Maxtype Edge-Count Test</p></a></li>
<li><a href='#ZC_cat'>
<p>Maxtype Edge-Count Test for Discrete Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Quantifying Similarity of Datasets and Multivariate Two- And
k-Sample Testing</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-03-18</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>boot, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ade4, approxOT, Ball, caret, clue, cramer, crossmatch,
dbscan, densratio, DWDLargeR, e1071, Ecume, energy, expm, FNN,
gTests, gTestsMulti, HDLSSkST, hypoRF, kernlab, kerTests, KMD,
knitr, LPKsample, Matrix, mvtnorm, nbpMatching, pROC, purrr,
randtoolbox, rlemon, rpart, rpart.plot, testthat, RSNNS</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of methods for quantifying the similarity of two or more datasets, many of which can be used for two- or k-sample testing. It provides newly implemented methods as well as wrapper functions for existing methods that enable calling many different methods in a unified framework. The methods were selected from the review and comparison of Stolte et al. (2024) &lt;<a href="https://doi.org/10.1214%2F24-SS149">doi:10.1214/24-SS149</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-18 16:10:24 UTC; stolte</td>
</tr>
<tr>
<td>Author:</td>
<td>Marieke Stolte <a href="https://orcid.org/0009-0002-0711-6789"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Luca Sauer [aut],
  David Alvarez-Melis [ctb] (Original python implementation of OTDD,
    &lt;https://github.com/microsoft/otdd.git&gt;),
  Nabarun Deb [ctb] (Original implementation of rank-based Energy test
    (DS), &lt;https://github.com/NabarunD/MultiDistFree.git&gt;),
  Bodhisattva Sen [ctb] (Original implementation of rank-based Energy
    test (DS), &lt;https://github.com/NabarunD/MultiDistFree.git&gt;)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marieke Stolte &lt;stolte@statistik.tu-dortmund.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-18 21:10:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='DataSimilarity-package'>
Quantifying Similarity of Datasets and Multivariate Two- And k-Sample Testing
</h2><span id='topic+DataSimilarity-package'></span><span id='topic+DataSimilarity'></span>

<h3>Description</h3>

<p>A collection of methods for quantifying the similarity of two or more datasets, many of which can be used for two- or k-sample testing. It provides newly implemented methods as well as wrapper functions for existing methods that enable calling many different methods in a unified framework. The methods were selected from the review and comparison of Stolte et al. (2024) &lt;doi:10.1214/24-SS149&gt;.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> DataSimilarity</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Quantifying Similarity of Datasets and Multivariate Two- And k-Sample Testing</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.1.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2025-03-18</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person(given = "Marieke", family = "Stolte", 
       email = "stolte@statistik.tu-dortmund.de", role = c("aut", "cre", "cph"), 
       comment = c(ORCID = "0009-0002-0711-6789")), 
       person(given = "Luca", family = "Sauer", role = c("aut")), 
       person(given = "David", family = "Alvarez-Melis", role = c("ctb"), 
                comment = "Original python implementation of OTDD, &lt;https://github.com/microsoft/otdd.git&gt;"), 
       person(given = "Nabarun", family = "Deb", role = c("ctb"), 
                comment = "Original implementation of rank-based Energy test (DS), &lt;https://github.com/NabarunD/MultiDistFree.git&gt;"), 
       person(given = "Bodhisattva", family = "Sen", role = c("ctb"), 
                comment = "Original implementation of rank-based Energy test (DS), &lt;https://github.com/NabarunD/MultiDistFree.git&gt;"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.5.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> boot, stats</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> ade4, approxOT, Ball, caret, clue, cramer, crossmatch, dbscan, densratio, DWDLargeR, e1071, Ecume, energy, expm, FNN, gTests, gTestsMulti, HDLSSkST, hypoRF, kernlab, kerTests, KMD, knitr, LPKsample, Matrix, mvtnorm, nbpMatching, pROC, purrr, randtoolbox, rlemon, rpart, rpart.plot, testthat, RSNNS</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> A collection of methods for quantifying the similarity of two or more datasets, many of which can be used for two- or k-sample testing. It provides newly implemented methods as well as wrapper functions for existing methods that enable calling many different methods in a unified framework. The methods were selected from the review and comparison of Stolte et al. (2024) &lt;doi:10.1214/24-SS149&gt;.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=3)</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Marieke Stolte [aut, cre, cph]
    (&lt;https://orcid.org/0009-0002-0711-6789&gt;),
  Luca Sauer [aut],
  David Alvarez-Melis [ctb] (Original python implementation of OTDD,
    &lt;https://github.com/microsoft/otdd.git&gt;),
  Nabarun Deb [ctb] (Original implementation of rank-based Energy test
    (DS), &lt;https://github.com/NabarunD/MultiDistFree.git&gt;),
  Bodhisattva Sen [ctb] (Original implementation of rank-based Energy
    test (DS), &lt;https://github.com/NabarunD/MultiDistFree.git&gt;)</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Marieke Stolte &lt;stolte@statistik.tu-dortmund.de&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
BF                      Baringhaus and Franz (2010) rigid motion
                        invariant multivariate two-sample test
BG                      Biau and Gyorfi (2005) two-sample homogeneity
                        test
BG2                     Biswas and Ghosh (2014) Two-Sample Test
BMG                     Biswas et al. (2014) two-sample run test
BQS                     Barakat et al. (1996) Two-Sample Test
Bahr                    Bahr (1996) multivariate two-sample test
BallDivergence          Ball Divergence based two- or k-sample test
C2ST                    Classifier Two-Sample Test
CCS                     Weighted Edge-Count Two-Sample Test
CCS_cat                 Weighted Edge-Count Two-Sample Test for
                        Discrete Data
CF                      Generalized Edge-Count Test
CF_cat                  Generalized Edge-Count Test for Discrete Data
CMDistance              Constrained Minimum Distance
Cramer                  Cram√©r Two-Sample Test
DISCOB                  Distance Components (DISCO) Tests
DISCOF                  Distance Components (DISCO) Tests
DS                      Rank-Based Energy Test (Deb and Sen, 2021)
DataSimilarity-package
                        Quantifying Similarity of Datasets and
                        Multivariate Two- And k-Sample Testing
DiProPerm               Direction-Projection-Permutation (DiProPerm)
                        Test
Energy                  Energy Statistic and Test
FR                      Friedman-Rafsky Test
FR_cat                  Friedman-Rafsky Test for Discrete Data
FStest                  Multisample FS Test
GGRL                    Decision-Tree Based Measure of Dataset Distance
                        and Two-Sample Test
GPK                     Generalized Permutation-Based Kernel (GPK)
                        Two-Sample Test
HMN                     Random Forest Based Two-Sample Test
HamiltonPath            Shortest Hamilton path
Jeffreys                Jeffreys divergence
KMD                     Kernel Measure of Multi-Sample Dissimilarity
                        (KMD)
LHZ                     Li et al. (2022) empirical characteristic
                        distance
LHZStatistic            Calculation of the Li et al. (2022) empirical
                        characteristic distance
MMCM                    Multisample Mahalanobis Crossmatch (MMCM) Test
MMD                     Maximum Mean Discrepancy (MMD) Test
MST                     Minimum Spanning Tree (MST)
MW                      Nonparametric Graph-Based LP (GLP) Test
NKT                     Decision-Tree Based Measure of Dataset
                        Similarity (Ntoutsi et al., 2008)
OTDD                    Optimal Transport Dataset Distance
Petrie                  Multisample Crossmatch (MCM) Test
RItest                  Multisample RI Test
Rosenbaum               Rosenbaum Crossmatch Test
SC                      Graph-Based Multi-Sample Test
SH                      Schilling-Henze Nearest Neighbor Test
Wasserstein             Wasserstein Distance based Test
YMRZL                   Yu et al. (2007) Two-Sample Test
ZC                      Maxtype Edge-Count Test
ZC_cat                  Maxtype Edge-Count Test for Discrete Data
dipro.fun               Direction-Projection Functions for DiProPerm
                        Test
engineerMetric          Engineer Metric
gTests                  Graph-Based Tests
gTestsMulti             Graph-Based Multi-Sample Test
gTests_cat              Graph-Based Tests for Discrete Data
kerTests                Generalized Permutation-Based Kernel (GPK)
                        Two-Sample Test
knn                     K-Nearest Neighbor Graph
rectPartition           Calculate a rectangular partition
stat.fun                Univariate Two-Sample Statistics for DiProPerm
                        Test
</pre>
<p>The package provides various methods for comparing two or more datasets or their underlying distributions. Often, a permutation or asymptotic test for the null hypothesis of equal distributions <code class="reqn">H_0: F_1 = F_2</code> or <code class="reqn">H_0: F_1 = \dots = F_k</code> is performed.  
</p>


<h3>Author(s)</h3>

<p>Marieke Stolte [aut, cre, cph]
    (&lt;https://orcid.org/0009-0002-0711-6789&gt;),
  Luca Sauer [aut],
  David Alvarez-Melis [ctb] (Original python implementation of OTDD,
    &lt;https://github.com/microsoft/otdd.git&gt;),
  Nabarun Deb [ctb] (Original implementation of rank-based Energy test
    (DS), &lt;https://github.com/NabarunD/MultiDistFree.git&gt;),
  Bodhisattva Sen [ctb] (Original implementation of rank-based Energy
    test (DS), &lt;https://github.com/NabarunD/MultiDistFree.git&gt;)
</p>
<p>Maintainer: Marieke Stolte &lt;stolte@statistik.tu-dortmund.de&gt;
</p>


<h3>References</h3>

<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J. &amp; Bommert, A.  (2024). A Comparison of Methods for Quantifying Dataset Similarity. <a href="https://shiny.statistik.tu-dortmund.de/data-similarity/">https://shiny.statistik.tu-dortmund.de/data-similarity/</a>
</p>

<hr>
<h2 id='Bahr'>
Bahr (1996) multivariate two-sample test
</h2><span id='topic+Bahr'></span>

<h3>Description</h3>

<p>The function implements the <cite>Bahr (1996)</cite> multivariate two-sample test. This test is a special case of the rigid-motion invariant multivariate two-sample test of <cite>Baringhaus and Franz (2010)</cite>. The implementation here uses the <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code> implementation from the <span class="pkg">cramer</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bahr(X1, X2, n.perm = 0, just.statistic = n.perm &lt;= 0, 
      sim = "ordinary", maxM = 2^14, K = 160, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bahr_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Bahr_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Bahr_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation or Bootstrap test, respectively (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="Bahr_+3A_just.statistic">just.statistic</code></td>
<td>

<p>Should only the test statistic be calculated without performing any test (default: <code>TRUE</code> if number of permutations is set to 0 and <code>FALSE</code> if number of permutations is set to any positive number)
</p>
</td></tr>
<tr><td><code id="Bahr_+3A_sim">sim</code></td>
<td>

<p>Type of Bootstrap or eigenvalue method for testing. Possible options are <code>"ordinary"</code> (default) for ordinary Boostrap, <code>"permutation"</code> for permutation testing, or <code>"eigenvalue"</code> for bootstrapping the limit distribution (especially good for datasets too large for performing Bootstrapping). For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>
</p>
</td></tr>
<tr><td><code id="Bahr_+3A_maxm">maxM</code></td>
<td>

<p>Maximum number of points used for fast Fourier transform involved in eigenvalue method for approximating the null distribution (default: 2^14). Ignored if sim is either <code>"ordinary"</code> or <code>"permutation"</code>. For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>.
</p>
</td></tr>
<tr><td><code id="Bahr_+3A_k">K</code></td>
<td>

<p>Upper value up to which the integral for calculating the distribution function from the characteristic function is evaluated (default: 160). Note: when <code>K</code> is increased, it is necessary to also increase <code>maxM</code>. Ignored if sim is either <code>"ordinary"</code> or <code>"permutation"</code>. For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>.
</p>
</td></tr>
<tr><td><code id="Bahr_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <cite>Bahr (1996)</cite> test is a specialcase of the test of <cite>Bahrinhaus and Franz (2010)</cite> 
</p>
<p style="text-align: center;"><code class="reqn">T_{n_1, n_2} = \frac{n_1 n_2}{n_1+n_2}\left(\frac{2}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2} \phi(||X_{1i} - X_{2j}||^2) -  \frac{1}{n_1^2}\sum_{i,j=1}^{n_1} \phi(||X_{1i} - X_{1j}||^2) -  \frac{1}{n_2^2}\sum_{i,j=1}^{n_2} \phi(||X_{2i} - X_{2j}||^2)\right)</code>
</p>

<p>where the kernel function <code class="reqn">\phi</code> is set to </p>
<p style="text-align: center;"><code class="reqn">\phi_{\text{Bahr}}(x) = 1 - \exp(-x/2).</code>
</p>
 
<p>The theoretical statistic underlying this test statistic is zero if and only if 
the distributions coincide. Therefore, low values of the test statistic incidate similarity of the datasets while high values indicate differences between the datasets.
</p>
<p>This implementation is a wrapper function around the function <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Number of variables in each dataset</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>Sample size of first dataset</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size of second dataset</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Boostrap/ permutation p value (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>
<p>Type of Boostrap or eigenvalue method (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>n.perm</code></td>
<td>
<p>Number of permutations for permutation or Boostrap test</p>
</td></tr>
<tr><td><code>hypdist</code></td>
<td>
<p>Distribution function under the null hypothesis reconstructed via fast Fourier transform. <code>$x</code> contains the x-values, <code>$Fx</code> contains the corresponding distribution function values. (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>ev</code></td>
<td>
<p>Eigenvalues and eigenfunctions when using the eigenvalue method (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis
</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Baringhaus, L. and Franz, C. (2010). Rigid motion invariant two-sample tests, Statistica Sinica 20, 1333-1361
</p>
<p>Bahr, R. (1996). Ein neuer Test fuer das mehrdimensionale Zwei-Stichproben-Problem bei allgemeiner Alternative, German, Ph.D. thesis, University of Hanover
</p>
<p>Franz, C. (2024). cramer: Multivariate Nonparametric Cramer-Test for the Two-Sample-Problem. R package version 0.9-4, <a href="https://CRAN.R-project.org/package=cramer">https://CRAN.R-project.org/package=cramer</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BF">BF</a></code>, <code><a href="#topic+Cramer">Cramer</a></code>, <code><a href="#topic+Energy">Energy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Bahr test 
if(requireNamespace("cramer", quietly = TRUE)) {
  Bahr(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='BallDivergence'>
Ball Divergence based two- or <code class="reqn">k</code>-sample test
</h2><span id='topic+BallDivergence'></span>

<h3>Description</h3>

<p>The function implements the <cite>Pan et al. (2018)</cite> multivariate two- or <code class="reqn">k</code>-sample test based on the Ball Divergence. The implementation here uses the <code><a href="Ball.html#topic+bd.test">bd.test</a></code> implementation from the <span class="pkg">Ball</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BallDivergence(X1, X2, ..., n.perm = 0, seed = 42, num.threads = 0, 
                kbd.type = "sum", weight = c("constant", "variance"), 
                args.bd.test = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BallDivergence_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BallDivergence_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BallDivergence_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="BallDivergence_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, no permutation test performed). Note that for more than two samples, no test is performed.
</p>
</td></tr>
<tr><td><code id="BallDivergence_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="BallDivergence_+3A_num.threads">num.threads</code></td>
<td>

<p>Number of threads (default: 0, all available cores are used)
</p>
</td></tr>
<tr><td><code id="BallDivergence_+3A_kbd.type">kbd.type</code></td>
<td>

<p>Character specifying which k-sample test statistic will be used. Must be one of <code>"sum"</code> (default), <code>"maxsum"</code>, or <code>"max"</code>.
</p>
</td></tr>
<tr><td><code id="BallDivergence_+3A_weight">weight</code></td>
<td>

<p>Character specifying the weight form of the Ball Divergence test statistic. Must be one of <code>"constant"</code> (default) or <code>"variance"</code>.
</p>
</td></tr>
<tr><td><code id="BallDivergence_+3A_args.bd.test">args.bd.test</code></td>
<td>

<p>Further arguments passed to <code><a href="Ball.html#topic+bd.test">bd.test</a></code> as a named list.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>n.perm = 0</code>, the asymptotic test is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed.
</p>
<p>The Ball Divergence is defined as the square of the measure difference over a given closed ball collection. The empirical test performed here is based on the difference between averages of metric ranks. It is robust to outliers and heavy-tailed data and suitable for imbalanced sample sizes.
</p>
<p>The Ball Divergence of two distributions is zero if and only if the distributions coincide. Therefore, low values of the test statistic indicate similarity and the test rejects for large values of the test statistic.
</p>
<p>For the <code class="reqn">k</code>-sample problem the pairwise Ball divergences can be summarized in different ways. First, one can simply sum up all pairwise Ball divergences (<code>kbd.type = "sum"</code>). Next, one can find the sample with the largest difference to the other, i.e. take the maximum of the sums of all Ball divergences for each sample with all other samples (<code>kbd.type = "maxsum"</code>). Last, one can sum up the largest <code class="reqn">k-1</code> pairwise Ball divergences (<code>kbd.type = "max"</code>).
</p>
<p>This implementation is a wrapper function around the function <code><a href="Ball.html#topic+bd.test">bd.test</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see <code><a href="Ball.html#topic+bd.test">bd.test</a></code> and <code><a href="Ball.html#topic+bd.test">bd</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation p value (only if <code>n.perm</code> &gt; 0 and for two datasets)</p>
</td></tr>
<tr><td><code>n.perm</code></td>
<td>
<p>Number of permutations for permutation test</p>
</td></tr>
<tr><td><code>size</code></td>
<td>
<p>Number of observations for each dataset</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Pan, W., T. Y. Tian, X. Wang, H. Zhang (2018). Ball Divergence: Nonparametric two sample test, Annals of Statistics 46(3), 1109-1137, <a href="https://doi.org/10.1214/17-AOS1579">doi:10.1214/17-AOS1579</a>.
</p>
<p>J. Zhu, W. Pan, W. Zheng, and X. Wang (2021). Ball: An R Package for Detecting Distribution Difference and Association in Metric Spaces, Journal of Statistical Software, 97(6), <a href="https://doi.org/10.18637/jss.v097.i06">doi:10.18637/jss.v097.i06</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Calculate Ball Divergence and perform test 
if(requireNamespace("Ball", quietly = TRUE)) {
  BallDivergence(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='BF'>
Baringhaus and Franz (2010) rigid motion invariant multivariate two-sample test
</h2><span id='topic+BF'></span>

<h3>Description</h3>

<p>The function implements the <cite>Baringhaus and Franz (2010)</cite> multivariate two-sample test. The implementation here uses the <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code> implementation from the <span class="pkg">cramer</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BF(X1, X2, n.perm = 0, just.statistic = n.perm &lt;= 0, kernel = "phiLog", 
    sim = "ordinary", maxM = 2^14, K = 160, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BF_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BF_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BF_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation or Bootstrap test, respectively (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="BF_+3A_just.statistic">just.statistic</code></td>
<td>

<p>Should only the test statistic be calculated without performing any test (default: <code>TRUE</code> if number of permutations is set to 0 and <code>FALSE</code> if number of permutations is set to any positive number)
</p>
</td></tr>
<tr><td><code id="BF_+3A_kernel">kernel</code></td>
<td>

<p>Name of the kernel function as character. Possible options are <code>"phiLog"</code> (default), <code>"phiFracA"</code>, and <code>"phiFracB"</code>. Alternatively, a user-defined function can be supplied. The function should allow a matrix as input and fulfill the following properties. The output should be non-negative, the value of 0 should be mapped to 0, and the first derivative should be non-constant completely monotone.
</p>
</td></tr>
<tr><td><code id="BF_+3A_sim">sim</code></td>
<td>

<p>Type of Bootstrap or eigenvalue method for testing. Possible options are <code>"ordinary"</code> (default) for ordinary Boostrap, <code>"permutation"</code> for permutation testing, or <code>"eigenvalue"</code> for bootstrapping the limit distribution (especially good for datasets too large for performing Bootstrapping). For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>
</p>
</td></tr>
<tr><td><code id="BF_+3A_maxm">maxM</code></td>
<td>

<p>Maximum number of points used for fast Fourier transform involved in eigenvalue method for approximating the null distribution (default: 2^14). Ignored if <code>sim</code> is either <code>"ordinary"</code> or <code>"permutation"</code>. For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>.
</p>
</td></tr>
<tr><td><code id="BF_+3A_k">K</code></td>
<td>

<p>Upper value up to which the integral for calculating the distribution function from the characteristic function is evaluated (default: 160). Note: when <code>K</code> is increased, it is necessary to also increase <code>maxM</code>. Ignored if sim is either <code>"ordinary"</code> or <code>"permutation"</code>. For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>.
</p>
</td></tr>
<tr><td><code id="BF_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <cite>Bahrinhaus and Franz (2010)</cite> test statistic
</p>
<p style="text-align: center;"><code class="reqn">T_{n_1, n_2} = \frac{n_1 n_2}{n_1+n_2}\left(\frac{2}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2} \phi(||X_{1i} - X_{2j}||^2) -  \frac{1}{n_1^2}\sum_{i,j=1}^{n_1} \phi(||X_{1i} - X_{1j}||^2) -  \frac{1}{n_2^2}\sum_{i,j=1}^{n_2} \phi(||X_{2i} - X_{2j}||^2)\right)</code>
</p>

<p>is defined using a kernel function <code class="reqn">\phi</code>. A choice recommended preferably for location alternatives is </p>
<p style="text-align: center;"><code class="reqn">\phi_{\text{log}}(x) = \log(1 + x),</code>
</p>
<p> two choices recommended preferably for dispersion alternatives are </p>
<p style="text-align: center;"><code class="reqn">\phi_{\text{FracA}}(x) = 1 - \frac{1}{1+x}</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">\phi_{\text{FracB}}(x) = 1 - \frac{1}{(1+x)^2}.</code>
</p>
 
<p>The theoretical statistic underlying this test statistic is zero if and only if  the distributions coincide. Therefore, low values of the test statistic incidate similarity of the datasets while high values indicate differences between the datasets.
</p>
<p>This implementation is a wrapper function around the function <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Number of variables in each dataset</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>Sample size of first dataset</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size of second dataset</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Boostrap/ permutation p value (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>
<p>Type of Boostrap or eigenvalue method (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>n.perm</code></td>
<td>
<p>Number of permutations for permutation or Boostrap test</p>
</td></tr>
<tr><td><code>hypdist</code></td>
<td>
<p>Distribution function under the null hypothesis reconstructed via fast Fourier transform. <code>$x</code> contains the x-values, <code>$Fx</code> contains the corresponding distribution function values. (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>ev</code></td>
<td>
<p>Eigenvalues and eigenfunctions when using the eigenvalue method (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Baringhaus, L. and Franz, C. (2010). Rigid motion invariant two-sample tests, Statistica Sinica 20, 1333-1361
</p>
<p>Franz, C. (2024). cramer: Multivariate Nonparametric Cramer-Test for the Two-Sample-Problem. R package version 0.9-4, https://CRAN.R-project.org/package=cramer.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Bahr">Bahr</a></code>, <code><a href="#topic+Cramer">Cramer</a></code>, <code><a href="#topic+Energy">Energy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Baringhaus and Franz test 
if(requireNamespace("cramer", quietly = TRUE)) {
  BF(X1, X2, n.perm = 100)
  BF(X1, X2, n.perm = 100, kernel = "phiFracA")
  BF(X1, X2, n.perm = 100, kernel = "phiFracB")
}
</code></pre>

<hr>
<h2 id='BG'>
Biau and Gyorfi (2005) two-sample homogeneity test
</h2><span id='topic+BG'></span>

<h3>Description</h3>

<p>The function implements the <cite>Biau and Gyorfi (2005)</cite> two-sample homogeneity test. This test uses the <code class="reqn">L_1</code>-distance between two empicial distribution functions restricted to a finite partition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BG(X1, X2, partition = rectPartition, exponent = 0.8, eps = 0.01, seed = 42, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BG_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame  
</p>
</td></tr>
<tr><td><code id="BG_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame of the same sample size as <code>X1</code>
</p>
</td></tr>
<tr><td><code id="BG_+3A_partition">partition</code></td>
<td>

<p>Function that creates a finite partition for the subspace spanned by the two datasets (default: <code>rectPartition</code>, see Details)
</p>
</td></tr>
<tr><td><code id="BG_+3A_exponent">exponent</code></td>
<td>

<p>Exponent used in the partition function, should be between 0 and 1 (default: 0.8)
</p>
</td></tr>
<tr><td><code id="BG_+3A_eps">eps</code></td>
<td>

<p>Small threshold to guarantee edge points are included (default: 0.01)
</p>
</td></tr>
<tr><td><code id="BG_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="BG_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed to the partition function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <cite>Biau and Gyorfi (2005)</cite> two-sample homogeneity test is defined for two datasets of the same sample size.
</p>
<p>By default a rectangular partition (<code><a href="#topic+rectPartition">rectPartition</a></code>) is being calculated under the assumption of approximately equal cell probabilities. Use the <code>exponent</code> argument to choose the number of elements of the partition <code class="reqn">m_n</code> accoring to the convergence criteria in <cite>Biau and Gyorfi (2005)</cite>. By default choose <code class="reqn">m_n = n^{0.8}</code>. For each of the <code class="reqn">p</code> variables of the datasets, create <code class="reqn">m_n^{1/p} + 1</code> cutpoints along the range of both datasets to define the partition, and ensure at least three cutpoints exist per variable (min, max, and one point splitting the data into two bins).
</p>
<p>The test statistic is the <code class="reqn">L_1</code>-distance between the vectors of the proportions of points falling into each cell of the partition for each dataset.
An asymptotic test is performed using a standardized version of the <code class="reqn">L_1</code> distance that is approximately standard normally distributed (Corollary to Theorem 2 in <cite>Biau and Gyorfi (2005)</cite>).
Low values of the test statistic indicate similarity. Therefore, the test rejects for large values of the test statistic.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the (asymptotic) test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p value</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Biau G. and Gyorfi, L. (2005). On the asymptotic properties of a nonparametric <code class="reqn">L_1</code>-test statistic of homogeneity, IEEE Transactions on Information Theory, 51(11), 3965-3973. <a href="https://doi.org/10.1109/TIT.2005.856979">doi:10.1109/TIT.2005.856979</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rectPartition">rectPartition</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform BG test 
BG(X1, X2)
</code></pre>

<hr>
<h2 id='BG2'>
Biswas and Ghosh (2014) Two-Sample Test
</h2><span id='topic+BG2'></span>

<h3>Description</h3>

<p>Performs the <cite>Biswas and Ghosh (2014)</cite> two-sample test for high-dimensional data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BG2(X1, X2, n.perm = 0, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BG2_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BG2_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BG2_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="BG2_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is based on comparing the means of the distributions of the within-sample and between-sample distances of both samples. It is intended for the high dimension low sample size (HDLSS) setting and claimed to perform better in this setting than the tests of <cite>Friedman and Rafsky (1979)</cite>, <cite>Schilling (1986)</cite> and <cite>Henze (1988)</cite> and the Cram√©r test of <cite>Baringhaus and Franz (2004)</cite>. 
</p>
<p>The statistic is defined as 
</p>
<p style="text-align: center;"><code class="reqn">T = ||\hat{\mu}_{D_F} - \hat{\mu}_{D_G}||^2_2, \text{ where}</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\mu}_{D_F} = \left[\hat{\mu}_{FF} = \frac{2}{n_1(n_1 - 1)}\sum_{i=1}^{n_1}\sum_{j=i+1}^{n_1}||X_{1i} - X_{1j}||, \hat{\mu}_{FG} = \frac{1}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2}||X_{1i} - X_{2j}||\right], </code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\mu}_{D_G} = \left[\hat{\mu}_{FG} = \frac{1}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2}||X_{1i} - X_{2j}||, \hat{\mu}_{GG} = \frac{2}{n_2(n_2 - 1)}\sum_{i=1}^{n_2}\sum_{j=i+1}^{n_2}||X_{2i} - X_{2j}||\right]. </code>
</p>

<p>For testing, the scaled statistic 
</p>
<p style="text-align: center;"><code class="reqn">T^* = \frac{N\hat{\lambda}(1 - \hat{\lambda})}{2\hat{\sigma}_0^2} T \text{ with}</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\lambda} = \frac{n_1}{N},</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\sigma}_0^2 = \frac{n_1S_1 + n_2S_2}{N}, \text{ where}</code>
</p>

<p style="text-align: center;"><code class="reqn">S_1 = \frac{1}{\binom{n_1}{3}} \sum_{1\le i &lt; j &lt; k \le n_1} ||X_{1i} - X_{1j}||\cdot ||X_{1i} - X_{1k}|| - \hat{\mu}_{FF}^2 \text{ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">S_2 = \frac{1}{\binom{n_2}{3}} \sum_{1\le i &lt; j &lt; k \le n_2} ||X_{2i} - X_{2j}||\cdot ||X_{2i} - X_{2k}|| - \hat{\mu}_{GG}^2</code>
</p>

<p>is used as it is asymptotically <code class="reqn">\chi^2_1</code>-distributed.
</p>
<p>In both cases, low values indicate similarity of the datasets. Thus, the test rejects the null hypothesis of equal distributions for large values of the test statistic. 
</p>
<p>For <code>n.perm &gt; 0</code>, a permutation test is conducted. Otherwise, an asymptotic test using the asymptotic distibution of <code class="reqn">T^*</code> is performed.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Biswas, M., Ghosh, A.K. (2014). A nonparametric two-sample test applicable to high dimensional data.
Journal of Multivariate Analysis, 123, 160-171, <a href="https://doi.org/10.1016/j.jmva.2013.09.004">doi:10.1016/j.jmva.2013.09.004</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Energy">Energy</a></code>, <code><a href="#topic+Cramer">Cramer</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Biswas and Ghosh test
BG2(X1, X2)
</code></pre>

<hr>
<h2 id='BMG'>
Biswas et al. (2014) two-sample run test
</h2><span id='topic+BMG'></span>

<h3>Description</h3>

<p>The function implements the <cite>Biswas, Mukhopadhyay and Gosh (2014)</cite> distribution-free two-sample run test. This test uses a heuristic approach to calculate the shortest Hamilton path between the two datasets using the <code>HamiltonPath</code> function. By default the asymptotic version of the test is calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BMG(X1, X2, seed = 42, asymptotic = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BMG_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame  
</p>
</td></tr>
<tr><td><code id="BMG_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BMG_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="BMG_+3A_asymptotic">asymptotic</code></td>
<td>

<p>Should the asymptotic version of the test be performed (default: <code>TRUE</code>)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test counts the number of edges in the shortest Hamilton path calculated on the pooled sample that connect points from different samples, i.e.
</p>
<p style="text-align: center;"><code class="reqn">T_{m,n} = 1 + \sum_{i = 1}^{N-1} U_i, </code>
</p>

<p>where <code class="reqn">U_i</code> is an indicator function with <code class="reqn">U_i = 1</code> if the <code class="reqn">i</code>th edge connects points from different samples and <code class="reqn">U_i = 0</code> otherwise.
</p>
<p>For a combined sample size <code>N</code> smaller or equal to 1030, the exact version of the <cite>Biswas, Mukhopadhyay and Gosh (2014)</cite> test can be calculated. It uses the univariate run statistic (<cite>Wald and Wolfowitz, 1940</cite>) to calculate the test statistic. For <code>N</code> larger than 1030, the calculation for the exact version breaks.
</p>
<p>If an asymptotic test is performed the asymptotic null distribution is given by
</p>
<p style="text-align: center;"><code class="reqn">T_{m, n}^{*} \sim \mathcal{N}(0, 4\lambda^2(1-\lambda)^2)</code>
</p>

<p>where <code class="reqn">T_{m, n}^{*}= \sqrt{N} (T_{m, n} / N - 2  \lambda (1 - \lambda))</code> the asymptotic test statistic, <code class="reqn">\lambda = m/N</code> and <code class="reqn">m</code> is the sample size of the first dataset. Therefore, low absolute values of the asymptotic test statistic indicate similarity of the two datasets whereas high absolute values indicate differences between the datasets.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic (note: this is not the asymptotic test statistic)</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>(asymptotic) p value</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Biswas, M., Mukhopadhyay, M. and Ghosh, A. K. (2014). A distribution-free two-sample run test applicable to high-dimensional data, Biometrika 101 (4), 913-926, <a href="https://doi.org/10.1093/biomet/asu045">doi:10.1093/biomet/asu045</a>
</p>
<p>Wald, A. and Wolfowitz, J. (1940). On a test whether two samples are from the same distribution, Annals of Mathematical Statistic 11, 147-162
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HamiltonPath">HamiltonPath</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform BMG test 
BMG(X1, X2)
</code></pre>

<hr>
<h2 id='BQS'>
Barakat et al. (1996) Two-Sample Test
</h2><span id='topic+BQS'></span>

<h3>Description</h3>

<p>Performs the nearest-neighbor-based multivariate two-sample test of <cite>Barakat et al. (1996).</cite>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BQS(X1, X2, dist.fun = stats::dist, n.perm = 0, dist.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BQS_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BQS_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="BQS_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code>stats::dist</code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="BQS_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, no test is performed).
</p>
</td></tr>
<tr><td><code id="BQS_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="BQS_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an extension of the <cite>Schilling (1986)</cite> and <cite>Henze (1988)</cite> 
neighbor test that bypasses choosing the number of nearest neighbors to consider. 
The Schilling-Henze test statistic is the proportion of edges connecting points 
from the same dataset in a <code>K</code>-nearest neighbor graph calculated on the pooled sample (standardized with expectation and SD under the null). 
<cite>Barakat et al. (1996)</cite> take the weighted sum of the Schilling-Henze test 
statistics for <code class="reqn">K = 1,\dots,N-1</code>, where <code class="reqn">N</code> denotes the pooled sample size. 
</p>
<p>As for the Schilling-Henze test, low values of the test statistic indicate similarity of the datasets. Thus, the null hypothesis of equal distributions is rejected for high values. 
A permutation test is performed if <code>n.perm</code> is set to a positive number. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation p value (if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Barakat, A.S., Quade, D. and Salama, I.A. (1996), Multivariate Homogeneity Testing Using an Extended Concept of Nearest Neighbors. Biom. J., 38: 605-612. <a href="https://doi.org/10.1002/bimj.4710380509">doi:10.1002/bimj.4710380509</a>
</p>
<p>Schilling, M. F. (1986). Multivariate Two-Sample Tests Based on Nearest Neighbors. Journal of the American Statistical Association, 81(395), 799-806. <a href="https://doi.org/10.2307/2289012">doi:10.2307/2289012</a>
</p>
<p>Henze, N. (1988). A Multivariate Two-Sample Test Based on the Number of Nearest Neighbor Type Coincidences. The Annals of Statistics, 16(2), 772-783. 
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SH">SH</a></code>, <code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+ZC">ZC</a></code> for other graph-based tests, 
<code><a href="#topic+FR_cat">FR_cat</a></code>, <code><a href="#topic+CF_cat">CF_cat</a></code>, <code><a href="#topic+CCS_cat">CCS_cat</a></code>, and <code><a href="#topic+ZC_cat">ZC_cat</a></code> for versions of the test for categorical data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Barakat et al. test
BQS(X1, X2)
</code></pre>

<hr>
<h2 id='C2ST'>
Classifier Two-Sample Test
</h2><span id='topic+C2ST'></span>

<h3>Description</h3>

<p>The function implements the Classifier Two-Sample Test (C2ST) of <cite>Lopez-Paz &amp; Oquab (2017)</cite>. The comparison of multiple (<code class="reqn">\ge 2</code>) samples is also possible. The implementation here uses the <code><a href="Ecume.html#topic+classifier_test">classifier_test</a></code> implementation from the <span class="pkg">Ecume</span> package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>C2ST(X1, X2, ..., split = 0.7, thresh = 0, method = "knn", control = NULL, 
      train.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="C2ST_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="C2ST_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="C2ST_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="C2ST_+3A_split">split</code></td>
<td>

<p>Proportion of observations used for training
</p>
</td></tr>
<tr><td><code id="C2ST_+3A_thresh">thresh</code></td>
<td>

<p>Value to add to the null hypothesis value (default:0). The null hypothesis tested can be formulated as <code class="reqn">H_0: t = p_0 + </code> <code>thresh</code>, where <code class="reqn">t</code> denotes the test accuracy of the classifier and <code class="reqn">p_0</code> is the chance level (proportion of largest dataset in pooled sample).
</p>
</td></tr>
<tr><td><code id="C2ST_+3A_method">method</code></td>
<td>

<p>Classifier to use during training (default: <code>"knn"</code>). See details for possible options. 
</p>
</td></tr>
<tr><td><code id="C2ST_+3A_control">control</code></td>
<td>

<p>Control parameters for fitting. See <code><a href="caret.html#topic+trainControl">trainControl</a></code>. Defaults to <code>NULL</code> in which case it is set to <code>caret::trainControl(method = "cv")</code>.
</p>
</td></tr>
<tr><td><code id="C2ST_+3A_train.args">train.args</code></td>
<td>

<p>Further arguments passed to <code><a href="caret.html#topic+train">train</a></code> as a named list.
</p>
</td></tr>
<tr><td><code id="C2ST_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The classifier two-sample test works by first combining the datasets into a pooled dataset and creating a target variable with the dataset membership of each observation. The pooled sample is then split into training and test set and a classifier is trained on the training data. The classification accuracy on the test data is then used as a test statistic. If the distributions of the datasets do not differ, the classifier will be unable to distinguish between the datasets and therefore the test accuracy will be close to chance level. The test rejects if the test accuracy is greater than chance level. 
</p>
<p>All methods available for classification within the <span class="pkg">caret</span> framework can be used as methods. A list of possible models can for example be retrieved via 
</p>
<p><code>names(caret::getModelInfo())[sapply(caret::getModelInfo(), function(x) "Classification" %in% x$type)]</code>
</p>
<p>This implementation is a wrapper function around the function <code><a href="Ecume.html#topic+classifier_test">classifier_test</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="Ecume.html#topic+classifier_test">classifier_test</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>classifier</code></td>
<td>
<p>Chosen classification method</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Lopez-Paz, D., and Oquab, M. (2022). Revisiting classifier two-sample tests. ICLR 2017. <a href="https://openreview.net/forum?id=SJkXfE5xx">https://openreview.net/forum?id=SJkXfE5xx</a>. 
</p>
<p>Roux de Bezieux, H. (2021). Ecume: Equality of 2 (or k) Continuous Univariate and Multivariate Distributions. R package version 0.9.1, <a href="https://CRAN.R-project.org/package=Ecume">https://CRAN.R-project.org/package=Ecume</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HMN">HMN</a></code>, <code><a href="#topic+YMRZL">YMRZL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform classifier two-sample test 
if(requireNamespace("Ecume", quietly = TRUE)) {
  C2ST(X1, X2)
}
</code></pre>

<hr>
<h2 id='CCS'>
Weighted Edge-Count Two-Sample Test
</h2><span id='topic+CCS'></span>

<h3>Description</h3>

<p>Performs the weighted edge-count two-sample test for multivariate data proposed by <cite>Chen, Chen and Su (2018)</cite>. The test is intended for comparing two samples with unequal sample sizes. The implementation here uses the <code><a href="gTests.html#topic+g.tests">g.tests</a></code> implementation from the <span class="pkg">gTests</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CCS(X1, X2, dist.fun = stats::dist, graph.fun = MST, n.perm = 0, 
    dist.args = NULL, graph.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CCS_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CCS_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CCS_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="CCS_+3A_graph.fun">graph.fun</code></td>
<td>

<p>Function for calculating a similarity graph using the distance matrix on the pooled sample (default: <code><a href="#topic+MST">MST</a></code>, Minimum Spanning Tree).
</p>
</td></tr>
<tr><td><code id="CCS_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="CCS_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="CCS_+3A_graph.args">graph.args</code></td>
<td>

<p>Named list of further arguments passed to <code>graph.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="CCS_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an enhancement of the Friedman-Rafsky test (original edge-count test) that aims at improving the test's power for unequal sample sizes by weighting. The test statistic is given as 
</p>
<p style="text-align: center;"><code class="reqn">Z_w = \frac{R_w - \text{E}_{H_0}(R_w)}{\sqrt{\text{Var}_{H_0}(R_w)}}, \text{ where}</code>
</p>

<p style="text-align: center;"><code class="reqn">R_w = \frac{n_1}{n_1+n_2} R_1 + \frac{n_2}{n_1+n_2} R_2</code>
</p>

<p>and <code class="reqn">R_1</code> and <code class="reqn">R_2</code> denote the number of edges in the similarity graph connecting points within the first and second sample <code class="reqn">X_1</code> and <code class="reqn">X_2</code>, respectively. 
</p>
<p>High values of the test statistic indicate dissimilarity of the datasets as the number of edges connecting points within the same sample is high meaning that points are more similar within the datasets than between the datasets.
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Chen, H., Chen, X. and Su, Y. (2018). A Weighted Edge-Count Two-Sample Test for Multivariate and Object Data. Journal of the American Statistical Association, 113(523), 1146-1155, <a href="https://doi.org/10.1080/01621459.2017.1307757">doi:10.1080/01621459.2017.1307757</a>
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR">FR</a></code> for the original edge-count test, <code><a href="#topic+CF">CF</a></code> for the generalized edge-count test, <code><a href="#topic+ZC">ZC</a></code> for the maxtype edge-count test, <code><a href="#topic+gTests">gTests</a></code> for performing all these edge-count tests at once, <code><a href="#topic+SH">SH</a></code> for performing the Schilling-Henze nearest neighbor test,
<code><a href="#topic+CCS_cat">CCS_cat</a></code>, <code><a href="#topic+FR_cat">FR_cat</a></code>, <code><a href="#topic+CF_cat">CF_cat</a></code>, <code><a href="#topic+ZC_cat">ZC_cat</a></code>, and <code><a href="#topic+gTests_cat">gTests_cat</a></code> for versions of the test for categorical data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform weighted edge-count test
if(requireNamespace("gTests", quietly = TRUE)) {
  CCS(X1, X2)
}
</code></pre>

<hr>
<h2 id='CCS_cat'>
Weighted Edge-Count Two-Sample Test for Discrete Data
</h2><span id='topic+CCS_cat'></span>

<h3>Description</h3>

<p>Performs the weighted edge-count two-sample test for multivariate data proposed by <cite>Chen, Chen and Su (2018)</cite>. The test is intended for comparing two samples with unequal sample sizes. The implementation here uses the <code><a href="gTests.html#topic+g.tests">g.tests</a></code> implementation from the <span class="pkg">gTests</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CCS_cat(X1, X2, dist.fun, agg.type, graph.type = "mstree", K = 1, n.perm = 0, 
        seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CCS_cat_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CCS_cat_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CCS_cat_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset.
</p>
</td></tr>
<tr><td><code id="CCS_cat_+3A_agg.type">agg.type</code></td>
<td>

<p>Character giving the method for aggregating over possible similarity graphs. Options are <code>"u"</code> for union of possible similarity graphs and <code>"a"</code> for averaging over test statistics calculated on possible similarity graphs. 
</p>
</td></tr>
<tr><td><code id="CCS_cat_+3A_graph.type">graph.type</code></td>
<td>

<p>Character specifying which similarity graph to use. Possible options are <code>"mstree"</code> (default, Minimum Spanning Tree) and <code>"nnlink"</code> (Nearest Neighbor Graph).
</p>
</td></tr>
<tr><td><code id="CCS_cat_+3A_k">K</code></td>
<td>

<p>Parameter for graph (default: 1). If <code>graph.type = "mstree"</code>, a <code>K</code>-MST is constructed (<code>K=1</code> is the classical MST). If <code>graph.type = "nnlink"</code>, <code>K</code> gives the number of neighbors considered in the <code>K</code>-NN graph.
</p>
</td></tr>
<tr><td><code id="CCS_cat_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="CCS_cat_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an enhancement of the Friedman-Rafsky test (original edge-count test) that aims at improving the test's power for unequal sample sizes by weighting. 
The test statistic is given as 
</p>
<p style="text-align: center;"><code class="reqn">Z_w = \frac{R_w - \text{E}_{H_0}(R_w)}{\sqrt{\text{Var}_{H_0}(R_w)}}, \text{ where}</code>
</p>

<p style="text-align: center;"><code class="reqn">R_w = \frac{n_1}{n_1+n_2} R_1 + \frac{n_2}{n_1+n_2} R_2</code>
</p>

<p>and <code class="reqn">R_1</code> and <code class="reqn">R_2</code> denote the number of edges in the similarity graph connecting points within the first and second sample <code class="reqn">X_1</code> and <code class="reqn">X_2</code>, respectively. 
For discrete data, the similarity graph used in the test is not necessarily unique. This can be solved by either taking a union of all optimal similarity graphs or averaging the test statistics over all optimal similarity graphs. For details, see <cite>Zhang and Chen (2022)</cite>. 
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Chen, H., Chen, X. and Su, Y. (2018). A Weighted Edge-Count Two-Sample Test for Multivariate and Object Data. Journal of the American Statistical Association, 113(523), 1146 - 1155, <a href="https://doi.org/10.1080/01621459.2017.1307757">doi:10.1080/01621459.2017.1307757</a>
</p>
<p>Zhang, J. and Chen, H. (2022). Graph-Based Two-Sample Tests for Data with Repeated Observations. Statistica Sinica 32, 391-415, <a href="https://doi.org/10.5705/ss.202019.0116">doi:10.5705/ss.202019.0116</a>.
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR_cat">FR_cat</a></code> for the original edge-count test, <code><a href="#topic+CF_cat">CF_cat</a></code> for the generalized edge-count test, <code><a href="#topic+ZC_cat">ZC_cat</a></code> for the maxtype edge-count test, <code><a href="#topic+gTests_cat">gTests_cat</a></code> for performing all these edge-count tests at once,
<code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+ZC">ZC</a></code>, and <code><a href="#topic+gTests">gTests</a></code> for versions of the tests for continuous data, and <code><a href="#topic+SH">SH</a></code> for performing the Schilling-Henze nearest neighbor test
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1cat &lt;- matrix(sample(1:4, 300, replace = TRUE), ncol = 3)
X2cat &lt;- matrix(sample(1:4, 300, replace = TRUE, prob = 1:4), ncol = 3)
# Perform weighted edge-count test
if(requireNamespace("gTests", quietly = TRUE)) {
  CCS_cat(X1cat, X2cat, dist.fun = function(x, y) sum(x != y), agg.type = "a")
}
</code></pre>

<hr>
<h2 id='CF'>
Generalized Edge-Count Test
</h2><span id='topic+CF'></span>

<h3>Description</h3>

<p>Performs the generalized edge-count two-sample test for multivariate data proposed by <cite>Chen and Friedman (2017)</cite>. The implementation here uses the <code><a href="gTests.html#topic+g.tests">g.tests</a></code> implementation from the <span class="pkg">gTests</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CF(X1, X2, dist.fun = stats::dist, graph.fun = MST, n.perm = 0, 
    dist.args = NULL, graph.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CF_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CF_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CF_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="CF_+3A_graph.fun">graph.fun</code></td>
<td>

<p>Function for calculating a similarity graph using the distance matrix on the pooled sample (default: <code><a href="#topic+MST">MST</a></code>, Minimum Spanning Tree).
</p>
</td></tr>
<tr><td><code id="CF_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="CF_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="CF_+3A_graph.args">graph.args</code></td>
<td>

<p>Named list of further arguments passed to <code>graph.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="CF_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an enhancement of the Friedman-Rafsky test (original edge-count test) that aims at detecting both location and scale alternatives. The test statistic is given as 
</p>
<p style="text-align: center;"><code class="reqn">S = (R_1 - \mu_1, R_2 - \mu_2)\Sigma^{-1} \binom{R_1 - \mu_1}{R_2 - \mu_2}, \text{ where}</code>
</p>

<p><code class="reqn">R_1</code> and <code class="reqn">R_2</code> denote the number of edges in the similarity graph connecting points within the first and second sample <code class="reqn">X_1</code> and <code class="reqn">X_2</code>, respectively, <code class="reqn">\mu_1 = \text{E}_{H_0}(R_1)</code>, <code class="reqn">\mu_2 = \text{E}_{H_0}(R_2)</code> and <code class="reqn">\Sigma</code> is the covariance matrix of <code class="reqn">R_1</code> and <code class="reqn">R_2</code> under the null. 
</p>
<p>High values of the test statistic indicate dissimilarity of the datasets as the number of edges connecting points within the same sample is high meaning that points are more similar within the datasets than between the datasets.
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic <code class="reqn">\chi^2</code> approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed.
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Degrees of freedom for <code class="reqn">\chi^2</code> distribution under <code class="reqn">H_0</code> (only for asymptotic test)</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Chen, H. and Friedman, J.H. (2017). A New Graph-Based Two-Sample Test for Multivariate and Object Data. Journal of the American Statistical Association, 112(517), 397-409. <a href="https://doi.org/10.1080/01621459.2016.1147356">doi:10.1080/01621459.2016.1147356</a>
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR">FR</a></code> for the original edge-count test, <code><a href="#topic+CCS">CCS</a></code> for the weighted edge-count test, <code><a href="#topic+ZC">ZC</a></code> for the maxtype edge-count test, <code><a href="#topic+gTests">gTests</a></code> for performing all these edge-count tests at once, <code><a href="#topic+SH">SH</a></code> for performing the Schilling-Henze nearest neighbor test,
<code><a href="#topic+CCS_cat">CCS_cat</a></code>, <code><a href="#topic+FR_cat">FR_cat</a></code>, <code><a href="#topic+CF_cat">CF_cat</a></code>, <code><a href="#topic+ZC_cat">ZC_cat</a></code>, and <code><a href="#topic+gTests_cat">gTests_cat</a></code> for versions of the test for categorical data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform generalized edge-count test
if(requireNamespace("gTests", quietly = TRUE)) {
  CF(X1, X2)
}
</code></pre>

<hr>
<h2 id='CF_cat'>
Generalized Edge-Count Test for Discrete Data
</h2><span id='topic+CF_cat'></span>

<h3>Description</h3>

<p>Performs the generalized edge-count two-sample test for multivariate data proposed by <cite>Chen and Friedman (2017)</cite>. The implementation here uses the <code><a href="gTests.html#topic+g.tests">g.tests</a></code> implementation from the <span class="pkg">gTests</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CF_cat(X1, X2, dist.fun, agg.type, graph.type = "mstree", K = 1, n.perm = 0, 
        seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CF_cat_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CF_cat_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CF_cat_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset.
</p>
</td></tr>
<tr><td><code id="CF_cat_+3A_agg.type">agg.type</code></td>
<td>

<p>Character giving the method for aggregating over possible similarity graphs. Options are <code>"u"</code> for union of possible similarity graphs and <code>"a"</code> for averaging over test statistics calculated on possible similarity graphs. 
</p>
</td></tr>
<tr><td><code id="CF_cat_+3A_graph.type">graph.type</code></td>
<td>

<p>Character specifying which similarity graph to use. Possible options are <code>"mstree"</code> (default, Minimum Spanning Tree) and <code>"nnlink"</code> (Nearest Neighbor Graph).
</p>
</td></tr>
<tr><td><code id="CF_cat_+3A_k">K</code></td>
<td>

<p>Parameter for graph (default: 1). If <code>graph.type = "mstree"</code>, a <code>K</code>-MST is constructed (<code>K=1</code> is the classical MST). If <code>graph.type = "nnlink"</code>, <code>K</code> gives the number of neighbors considered in the <code>K</code>-NN graph.
</p>
</td></tr>
<tr><td><code id="CF_cat_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="CF_cat_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an enhancement of the Friedman-Rafsky test (original edge-count test) that aims at detecting both location and scale alternatives. The test statistic is given as 
</p>
<p style="text-align: center;"><code class="reqn">S = (R_1 - \mu_1, R_2 - \mu_2)\Sigma^{-1} \binom{R_1 - \mu_1}{R_2 - \mu_2}, \text{ where}</code>
</p>

<p><code class="reqn">R_1</code> and <code class="reqn">R_2</code> denote the number of edges in the similarity graph connecting points within the first and second sample <code class="reqn">X_1</code> and <code class="reqn">X_2</code>, respectively, <code class="reqn">\mu_1 = \text{E}_{H_0}(R_1)</code>, <code class="reqn">\mu_2 = \text{E}_{H_0}(R_2)</code> and <code class="reqn">\Sigma</code> is the covariance matrix of <code class="reqn">R_1</code> and <code class="reqn">R_2</code> under the null. 
</p>
<p>For discrete data, the similarity graph used in the test is not necessarily unique. This can be solved by either taking a union of all optimal similarity graphs or averaging the test statistics over all optimal similarity graphs. For details, see <cite>Zhang and Chen (2022)</cite>. 
</p>
<p>High values of the test statistic indicate dissimilarity of the datasets as the number of edges connecting points within the same sample is high meaning that points are more similar within the datasets than between the datasets.
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Degrees of freedom for <code class="reqn">\chi^2</code> distribution under <code class="reqn">H_0</code> (only for asymptotic test)</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Chen, H. and Friedman, J.H. (2017). A New Graph-Based Two-Sample
Test for Multivariate and Object Data. Journal of the American Statistical Association, 112(517), 397-409. <a href="https://doi.org/10.1080/01621459.2016.1147356">doi:10.1080/01621459.2016.1147356</a>
</p>
<p>Zhang, J. and Chen, H. (2022). Graph-Based Two-Sample Tests for Data with Repeated Observations. Statistica Sinica 32, 391-415, <a href="https://doi.org/10.5705/ss.202019.0116">doi:10.5705/ss.202019.0116</a>.
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR_cat">FR_cat</a></code> for the original edge-count test, <code><a href="#topic+CCS_cat">CCS_cat</a></code> for the weighted edge-count test, <code><a href="#topic+ZC_cat">ZC_cat</a></code> for the maxtype edge-count test, <code><a href="#topic+gTests_cat">gTests_cat</a></code> for performing all these edge-count tests at once, 
<code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+ZC">ZC</a></code>, and <code><a href="#topic+gTests">gTests</a></code> for versions of the tests for continuous data, and <code><a href="#topic+SH">SH</a></code> for performing the Schilling-Henze nearest neighbor test
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1cat &lt;- matrix(sample(1:4, 300, replace = TRUE), ncol = 3)
X2cat &lt;- matrix(sample(1:4, 300, replace = TRUE, prob = 1:4), ncol = 3)
# Perform generalized edge-count test
if(requireNamespace("gTests", quietly = TRUE)) {
  CF_cat(X1cat, X2cat, dist.fun = function(x, y) sum(x != y), agg.type = "a")
}
</code></pre>

<hr>
<h2 id='CMDistance'>
Constrained Minimum Distance
</h2><span id='topic+CMDistance'></span>

<h3>Description</h3>

<p>Calculates the Constrained Minimum Distance (<cite>Tatti, 2007</cite>) between two datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CMDistance(X1, X2, binary = NULL, cov = FALSE,
            S.fun = function(x) as.numeric(as.character(x)), 
            cov.S = NULL, Omega = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CMDistance_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CMDistance_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="CMDistance_+3A_binary">binary</code></td>
<td>

<p>Should the simplified form for binary data be used? (default: <code>NULL</code>, it is checked internally if each variable in the pooled dataset takes on exactly two distinct values)
</p>
</td></tr>
<tr><td><code id="CMDistance_+3A_cov">cov</code></td>
<td>

<p>If the the binary version is used, should covariances in addition to means be used as features? (default: <code>FALSE</code>, corresponds to example 3 in Tatti (2007), <code>TRUE</code> corresponds to example 4). Ignored if <code>binary = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="CMDistance_+3A_s.fun">S.fun</code></td>
<td>

<p>Feature function (default: <code>NULL</code>). Should be supplied as a function that takes one observation vector as its input. Ignored if <code>binary = TRUE</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="CMDistance_+3A_cov.s">cov.S</code></td>
<td>

<p>Covariance matix of feature function (default: <code>NULL</code>). Ignored if <code>binary = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="CMDistance_+3A_omega">Omega</code></td>
<td>

<p>Sample space as matrix (default: <code>NULL</code>, the sample space is derived from the data internally). Each row represents one value in the sample space. Used for calculating the covariance matrix if <code>cov.S = NULL</code>. Either <code>cov.S</code> or <code>Omega</code> must be given. Ignored if <code>binary = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="CMDistance_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constrained minimum (CM) distance is not a distance between distributions but rather a distance based on summaries. These summaries, called frequencies and denoted by <code class="reqn">\theta</code>, are averages of feature functions <code class="reqn">S</code> taken over the dataset. The constrained minimum distance of two datasets <code class="reqn">X_1</code> and <code class="reqn">X_2</code> can be calculated as 
</p>
<p style="text-align: center;"><code class="reqn">d_{CM}(X_1, X_2 |S)^2 = (\theta_1 - \theta_2)^T\text{Cov}^{-1}(S)(\theta_1 - \theta_2), </code>
</p>

<p>where <code class="reqn">\theta_i = S(X_i)</code> is the frequency with respect to the <code class="reqn">i</code>-th dataset, <code class="reqn">i = 1, 2</code>, and 
</p>
<p style="text-align: center;"><code class="reqn">\text{Cov}(S) = \frac{1}{|\Omega|}\sum_{\omega\in\Omega} S(\omega)S(\omega)^T - \left(\frac{1}{|\Omega|}\sum_{\omega\in\Omega} S(\omega)\right)\left(\frac{1}{|\Omega|}\sum_{\omega\in\Omega} S(\omega)\right)^T,</code>
</p>

<p>where <code class="reqn">\Omega</code> denotes the sample space.
</p>
<p>Note that the implementation can only handle limited dimensions of the sample space. 
The error message 
</p>
<p><code>"Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) : invalid 'times' value"</code> 
</p>
<p>occurs when the sample space becomes too large to enumerate all its elements.
In case of binary data and <code class="reqn">S</code> chosen as a conjunction or parity function <code class="reqn">T_{F}</code> on a family of itemsets, the calculation of the CMD simplifies to 
</p>
<p style="text-align: center;"><code class="reqn">d_{CM}(D_1, D_2 | S_{F}) = 2 ||\theta_1 - \theta_2||_2,</code>
</p>

<p>where <code class="reqn">\theta_i = T_{F}(X_i), i = 1, 2,</code> as the sample space and covariance matrix are known. In case of more than two categories, either the sample space or the covariance matrix of the feature function must be supplied.
</p>
<p>Small values of the CM Distance indicate similarity between the datasets. No test is conducted.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the CM Distance</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>binary</code>, <code>cov</code>, <code>S.fun</code>, <code>cov.S</code>, <code>Omega</code></td>
<td>
<p>Input parameters</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>Note that there is an error in the calculation of the covariance matrix in A.4 Proof of Lemma 8 in Tatti (2007). The correct covariance matrix has the form </p>
<p style="text-align: center;"><code class="reqn">\text{Cov}[T_{\mathcal{F}}] = 0.25I</code>
</p>
<p> since </p>
<p style="text-align: center;"><code class="reqn">\text{Var}[T_A] = \text{E}[T_A^2] - \text{E}[T_A]^2 = 0.5 - 0.5^2 = 0.25</code>
</p>
<p> following from the correct statement that <code class="reqn">\text{E}[T_A^2] = \text{E}[T_A] = 0.5</code>. Therefore, formula (4) changes to </p>
<p style="text-align: center;"><code class="reqn">d_{CM}(D_1, D_2 | S_{\mathcal{F}}) = 2 ||\theta_1 - \theta_2||_2</code>
</p>
<p> and the formula in example 3 changes to </p>
<p style="text-align: center;"><code class="reqn">d_{CM}(D_1, D_2 | S_{I}) = 2 ||\theta_1 - \theta_2||_2.</code>
</p>
<p> Our implementation is based on these corrected formulas. If the original formula was used, the results on the same data calculated with the formula for the binary special case and the results calculated with the general formula differ by a factor of <code class="reqn">\sqrt{2}</code>.
</p>


<h3>References</h3>

<p>Tatti, N. (2007). Distances between Data Sets Based on Summary Statistics. JMRL 8, 131-154. 
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Test example 2 in Tatti (2007)
CMDistance(X1 = data.frame(c("C", "C", "C", "A")), 
           X2 = data.frame(c("C", "A", "B", "A")),
           binary = FALSE, S.fun = function(x) as.numeric(x == "C"),
           Omega = data.frame(c("A", "B", "C")))

# Demonstration of corrected calculation
X1bin &lt;- matrix(sample(0:1, 100 * 3, replace = TRUE), ncol = 3)
X2bin &lt;- matrix(sample(0:1, 100 * 3, replace = TRUE, prob = 1:2), ncol = 3)
CMDistance(X1bin, X2bin, binary = TRUE, cov = FALSE)
Omega &lt;- expand.grid(0:1, 0:1, 0:1)
S.fun &lt;- function(x) x
CMDistance(X1bin, X2bin, binary = FALSE, S.fun = S.fun, Omega = Omega)
CMDistance(X1bin, X2bin, binary = FALSE, S.fun = S.fun, cov.S = 0.5 * diag(3))
CMDistance(X1bin, X2bin, binary = FALSE, S.fun = S.fun, 
            cov.S = 0.5 * diag(3))$statistic * sqrt(2)

# Example for non-binary data
X1cat &lt;- matrix(sample(1:4, 300, replace = TRUE), ncol = 3)
X2cat &lt;- matrix(sample(1:4, 300, replace = TRUE, prob = 1:4), ncol = 3)
CMDistance(X1cat, X2cat, binary = FALSE, S.fun = S.fun, 
           Omega = expand.grid(1:4, 1:4, 1:4))
CMDistance(X1cat, X2cat, binary = FALSE, S.fun = function(x) as.numeric(x == 1), 
           Omega = expand.grid(1:4, 1:4, 1:4))
CMDistance(X1cat, X2cat, binary = FALSE, S.fun = function(x){ 
           c(x, x[1] * x[2], x[1] * x[3], x[2] * x[3])}, 
           Omega = expand.grid(1:4, 1:4, 1:4))
</code></pre>

<hr>
<h2 id='Cramer'>
Cram√©r Two-Sample Test
</h2><span id='topic+Cramer'></span>

<h3>Description</h3>

<p>Performs Two-Sample Cram√©r Test (<cite>Baringhaus and Franz, 2004</cite>). The implementation here uses the <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code> implementation from the <span class="pkg">cramer</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cramer(X1, X2, n.perm = 0, just.statistic = (n.perm &lt;= 0), sim = "ordinary", 
        maxM = 2^14, K = 160, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Cramer_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Cramer_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Cramer_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation or Bootstrap test, respectively (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="Cramer_+3A_just.statistic">just.statistic</code></td>
<td>

<p>Should only the test statistic be calculated without performing any test (default: <code>TRUE</code> if number of permutations is set to 0 and <code>FALSE</code> if number of permutations is set to any positive number)
</p>
</td></tr>
<tr><td><code id="Cramer_+3A_sim">sim</code></td>
<td>

<p>Type of Bootstrap or eigenvalue method for testing. Possible options are <code>"ordinary"</code> (default) for ordinary Boostrap, <code>"permutation"</code> for permutation testing, or <code>"eigenvalue"</code> for bootstrapping the limit distribution (especially good for datasets too large for performing Bootstrapping). For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>
</p>
</td></tr>
<tr><td><code id="Cramer_+3A_maxm">maxM</code></td>
<td>

<p>Maximum number of points used for fast Fourier transform involved in eigenvalue method for approximating the null distribution (default: <code class="reqn">2^14</code>). Ignored if sim is either <code>"ordinary"</code> or <code>"permutation"</code>. For more details see cramer::cramer.test.
</p>
</td></tr>
<tr><td><code id="Cramer_+3A_k">K</code></td>
<td>

<p>Upper value up to which the integral for calculating the distribution function from the characteristic function is evaluated (default: 160). Note: when <code>K</code> is increased, it is necessary to also increase <code>maxM</code>. Ignored if sim is either <code>"ordinary"</code> or <code>"permutation"</code>. For more details see <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>.
</p>
</td></tr>
<tr><td><code id="Cramer_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cram√©r test (<cite>Baringhaus and Franz, 2004</cite>) is a specialcase of the test of <cite>Bahrinhaus and Franz (2010)</cite> where the kernel function <code class="reqn">\phi</code> is set to </p>
<p style="text-align: center;"><code class="reqn">\phi_{\text{Cramer}}(x) = \sqrt{x} / 2</code>
</p>
<p> and can be recommended for location alternatives. The test statistic simplifies to 
</p>
<p style="text-align: center;"><code class="reqn">T_{n_1, n_2} = \frac{n_1 n_2}{n_1+n_2}\left(\frac{1}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2} ||X_{1i} - X_{2j}|| -  \frac{1}{2n_1^2}\sum_{i,j=1}^{n_1} ||X_{1i} - X_{1j}|| -  \frac{1}{2n_2^2}\sum_{i,j=1}^{n_2} ||X_{2i} - X_{2j}||\right).</code>
</p>

<p>This is equal to the Energy statistic (<cite>Sz√©kely and Rizzo, 2004</cite>).
</p>
<p>The theoretical statistic underlying this test statistic is zero if and only if 
the distributions coincide. Therefore, low values of the test statistic incidate similarity of the datasets while high values indicate differences between the datasets.
</p>
<p>This implementation is a wrapper function around the function <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="cramer.html#topic+cramer.test">cramer.test</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Number of variables in each dataset</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>Sample size of first dataset</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size of second dataset</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Boostrap/ permutation p value (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>
<p>Type of Boostrap or eigenvalue method (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>n.perm</code></td>
<td>
<p>Number of permutations for permutation or Boostrap test</p>
</td></tr>
<tr><td><code>hypdist</code></td>
<td>
<p>Distribution function under the null hypothesis reconstructed via fast Fourier transform. <code>$x</code> contains the x-values, <code>$Fx</code> contains the corresponding distribution function values. (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>ev</code></td>
<td>
<p>Eigenvalues and eigenfunctions when using the eigenvalue method (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis
</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>The Cram√©r test (<cite>Baringhaus and Franz, 2004</cite>) is equivalent to the test based on the Energy statistic (<cite>Sz√©kely and Rizzo, 2004</cite>). 
</p>


<h3>References</h3>

<p>Baringhaus, L. and Franz, C. (2010). Rigid motion invariant two-sample tests, Statistica Sinica 20, 1333-1361
</p>
<p>Bahr, R. (1996). Ein neuer Test fuer das mehrdimensionale Zwei-Stichproben-Problem bei allgemeiner Alternative, German, Ph.D. thesis, University of Hanover
</p>
<p>Franz, C. (2024). cramer: Multivariate Nonparametric Cramer-Test for the Two-Sample-Problem. R package version 0.9-4, <a href="https://CRAN.R-project.org/package=cramer">https://CRAN.R-project.org/package=cramer</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Energy">Energy</a></code>, <code><a href="#topic+Bahr">Bahr</a></code>, <code><a href="#topic+BF">BF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Cramer test 
if(requireNamespace("cramer", quietly = TRUE)) {
  Cramer(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='dipro.fun'>
Direction-Projection Functions for DiProPerm Test
</h2><span id='topic+dwdProj'></span><span id='topic+svmProj'></span><span id='topic+dipro.fun'></span>

<h3>Description</h3>

<p>Helper functions performing the direction and projection step using different classifiers for the Direction-Projection-Permutation (DiProPerm) two-sample test for high-dimensional data (<cite>Wei et al., 2016</cite>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dwdProj(X1, X2)
svmProj(X1, X2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dipro.fun_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="dipro.fun_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The DiProPerm test works by first combining the datasets into a pooled dataset and creating a target variable with the dataset membership of each observation.
A binary linear classifier is then trained on the class labels and the normal vector of the separating hyperplane is calculated. 
The data from both samples is projected onto this normal vector. This gives a scalar score for each observation.
On these projection scores, a univariate two-sample statistic is calculated. 
The permutation null distribution of this statistic is calculated by permuting the dataset labels and repeating the whole procedure with the permuted labels. 
The functions here correspond to the direction and projection step for either the DWD or SVM classifier as proposed by <cite>Wei et al., 2016</cite>.
</p>
<p>The DWD model implementation <code><a href="DWDLargeR.html#topic+genDWD">genDWD</a></code> in the <span class="pkg">DWDLargeR</span> package is used with the penalty parameter <code>C</code> calculated with <code><a href="DWDLargeR.html#topic+penaltyParameter">penaltyParameter</a></code> using the recommended default values. More details on the algorithm can be found in <cite>Lam et al. (2018)</cite>. 
</p>
<p>For the SVM, the implementation <code><a href="e1071.html#topic+svm">svm</a></code> in the <span class="pkg">e1071</span> package is used with default parameters. 
</p>


<h3>Value</h3>

<p>A numeric vector containing the projected values for each observation in the pooled sample
</p>


<h3>References</h3>

<p>Lam, X. Y., Marron, J. S., Sun, D., &amp; Toh, K.-C. (2018). Fast Algorithms for Large-Scale Generalized Distance Weighted Discrimination. Journal of Computational and Graphical Statistics, 27(2), 368-379. <a href="https://doi.org/10.1080/10618600.2017.1366915">doi:10.1080/10618600.2017.1366915</a>
</p>
<p>Wei, S., Lee, C., Wichers, L., &amp; Marron, J. S. (2016). Direction-Projection-Permutation for High-Dimensional Hypothesis Tests. Journal of Computational and Graphical Statistics, 25(2), 549-569. <a href="https://doi.org/10.1080/10618600.2015.1027773">doi:10.1080/10618600.2015.1027773</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DiProPerm">DiProPerm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)

# calculate projections separately (only for demonstration)

dwdProj(X1, X2)

svmProj(X1, X2)

# Use within DiProPerm test 
# Note: For real applications, n.perm should be set considerably higher
# No permutations chosen for demonstration due to runtime

if(requireNamespace("DWDLargeR", quietly = TRUE)) {
  DiProPerm(X1, X2, n.perm = 10, dipro.fun = dwdProj)
}
if(requireNamespace("e1071", quietly = TRUE)) {
  DiProPerm(X1, X2, n.perm = 10, dipro.fun = svmProj)
}

</code></pre>

<hr>
<h2 id='DiProPerm'>
Direction-Projection-Permutation (DiProPerm) Test 
</h2><span id='topic+DiProPerm'></span>

<h3>Description</h3>

<p>Performs the Direction-Projection-Permutation (DiProPerm) two-sample test for high-dimensional data (<cite>Wei et al., 2016</cite>). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DiProPerm(X1, X2, n.perm = 0, dipro.fun = dwdProj, stat.fun = MD, 
            direction = "two.sided", seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DiProPerm_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="DiProPerm_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="DiProPerm_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="DiProPerm_+3A_dipro.fun">dipro.fun</code></td>
<td>

<p>Function performing the direction and projection step using a linear classifier. 
Implemented options are <code><a href="#topic+dwdProj">dwdProj</a></code> (default, distance weighted discrimination, DWD), and <code><a href="#topic+svmProj">svmProj</a></code> (support vector machine).
Must take the two datasets as input and output the calculated scores for the pooled sample. 
</p>
</td></tr>
<tr><td><code id="DiProPerm_+3A_stat.fun">stat.fun</code></td>
<td>

<p>Function that calculates a univariate two-sample statistic from two vectors. 
Implemented options are <code><a href="#topic+MD">MD</a></code> (default, mean difference, recommended for detecting mean differendes), <code><a href="#topic+tStat">tStat</a></code> (t test statistic) and <code><a href="#topic+AUC">AUC</a></code> (area under the receiver operating curve).
Must take the two numeric vectors as input and output the two sample statistic as a numeric scalar. 
</p>
</td></tr>
<tr><td><code id="DiProPerm_+3A_direction">direction</code></td>
<td>

<p>Character indicating for which values of the univariate test statistic the test should reject the null hypothesis. 
Possible options are <code>"two.sided"</code> (reject both for low and high values, appropriate for <code>MD</code> and <code>tStat</code>), <code>"greater"</code> (reject for high values, appropriate for <code>AUC</code>), or <code>"smaller"</code> (reject for low values).
</p>
</td></tr>
<tr><td><code id="DiProPerm_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The DiProPerm test works by first combining the datasets into a pooled dataset and creating a target variable with the dataset membership of each observation. A binary linear classifier is then trained on the class labels and the normal vector of the separating hyperplane is calculated. The data from both samples is projected onto this normal vector. This gives a scalar score for each observation. On these projection scores, a univariate two-sample statistic is calculated. The permutation null distribution of this statistic is calculated by permuting the dataset labels and repeating the whole procedure with the permuted labels. 
</p>
<p>At the moment, distance weighted discrimination (DWD), and support vector machine (SVM) are implemented as binary linear classifiers.
</p>
<p>The DWD model implementation <code><a href="DWDLargeR.html#topic+genDWD">genDWD</a></code> in the <span class="pkg">DWDLargeR</span> package is used with the penalty parameter <code>C</code> calculated with <code><a href="DWDLargeR.html#topic+penaltyParameter">penaltyParameter</a></code> using the recommended default values. More details on the algorithm can be found in <cite>Lam et al. (2018)</cite>. 
</p>
<p>For the SVM, the implementation <code><a href="e1071.html#topic+svm">svm</a></code> in the <span class="pkg">e1071</span> package is used with default parameters. 
</p>
<p>Other classifiers can be used by supplying a suitable function for <code><a href="#topic+dipro.fun">dipro.fun</a></code>.
</p>
<p>For the univariate test statistic, implemented options are the mean difference, t statistic and AUC. 
Other suitable statistics can be used by supplying a suitable function of <code><a href="#topic+stat.fun">stat.fun</a></code>.
</p>
<p>Whether high or low values of the test statistic correspond to similarity of the datasets depends on the chosen univariate statistic. 
This is reflected by the <code>direction</code> argument which modifies the behavior of the test to reject the null for appropriate values. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Lam, X. Y., Marron, J. S., Sun, D., &amp; Toh, K.-C. (2018). Fast Algorithms for Large-Scale Generalized Distance Weighted Discrimination. Journal of Computational and Graphical Statistics, 27(2), 368-379. <a href="https://doi.org/10.1080/10618600.2017.1366915">doi:10.1080/10618600.2017.1366915</a>
</p>
<p>Wei, S., Lee, C., Wichers, L., &amp; Marron, J. S. (2016). Direction-Projection-Permutation for High-Dimensional Hypothesis Tests. Journal of Computational and Graphical Statistics, 25(2), 549-569. <a href="https://doi.org/10.1080/10618600.2015.1027773">doi:10.1080/10618600.2015.1027773</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stat.fun">stat.fun</a></code>, <code><a href="#topic+dipro.fun">dipro.fun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform DiProPerm test 
# Note: For real applications, n.perm should be set considerably higher than 10
# Low values for n.perm chosen for demonstration due to runtime

if(requireNamespace("DWDLargeR", quietly = TRUE)) {
  DiProPerm(X1, X2, n.perm = 10)
  DiProPerm(X1, X2, n.perm = 10, stat.fun = tStat)
  if(requireNamespace("pROC", quietly = TRUE)) {
    DiProPerm(X1, X2, n.perm = 10, stat.fun = AUC, direction = "greater")
  }
}

if(requireNamespace("e1071", quietly = TRUE)) {
  DiProPerm(X1, X2, n.perm = 10, dipro.fun = svmProj)
  DiProPerm(X1, X2, n.perm = 10, dipro.fun = svmProj, stat.fun = tStat)
  if(requireNamespace("pROC", quietly = TRUE)) {
    DiProPerm(X1, X2, n.perm = 10, dipro.fun = svmProj, stat.fun = AUC, direction = "greater")
  }
}

</code></pre>

<hr>
<h2 id='DISCOB'>
Distance Components (DISCO) Tests
</h2><span id='topic+DISCOB'></span>

<h3>Description</h3>

<p>Performs Energy statistics distance components (DISCO) multi-sample tests (<cite>Rizzo and Sz√©kely, 2010</cite>). The implementation here uses the <code><a href="energy.html#topic+disco">disco</a></code> implementation from the <span class="pkg">energy</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DISCOB(X1, X2, ..., n.perm = 0, alpha = 1, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DISCOB_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="DISCOB_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="DISCOB_+3A_...">...</code></td>
<td>

<p>Further datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="DISCOB_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for Bootstrap test (default: 0, no Bootstrap test performed)
</p>
</td></tr>
<tr><td><code id="DISCOB_+3A_alpha">alpha</code></td>
<td>

<p>Power of the distance used for generalized Energy statistic (default: 1). Has to lie in <code class="reqn">(0,2]</code>. For values in <code class="reqn">(0, 2)</code>, consistency of the resulting test has been shown.
</p>
</td></tr>
<tr><td><code id="DISCOB_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>DISCO is a method for multi-sample testing based on all pairwise between-sample distances. It is analogous to the classical ANOVA. Instead of decomposing squared differences from the sample mean, the total dispersion (generalized Energy statistic) is composed into distance components (DISCO) consisting of the within-sample and between-sample measures of dispersion. 
</p>
<p><code>DISCOB</code> computes the between-sample DISCO statistic which is the between-sample component.
</p>
<p>In both cases, small values of the statistic indicate similarity of the datasets and therefore, the null hypothesis of equal distributions is rejected for large values of the statistic.
</p>
<p>This implementation is a wrapper function around the function <code><a href="energy.html#topic+disco">disco</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="energy.html#topic+disco">disco</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>The function call</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Bootstrap p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Szekely, G. J. and Rizzo, M. L. (2004) Testing for Equal Distributions in High Dimension, InterStat, November (5).
</p>
<p>Rizzo, M. L. and Szekely, G. J. (2010). DISCO Analysis: A Nonparametric Extension of Analysis of Variance, Annals of Applied Statistics, 4(2), 1034-1055.
doi:10.1214/09-AOAS245
</p>
<p>Szekely, G. J. (2000) Technical Report 03-05: E-statistics: Energy of Statistical Samples, Department of Mathematics and Statistics, Bowling Green State University.
</p>
<p>Rizzo, M., Szekely, G. (2022). energy: E-Statistics: Multivariate Inference via the Energy of Data. R package version 1.7-11, <a href="https://CRAN.R-project.org/package=energy">https://CRAN.R-project.org/package=energy</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DISCOF">DISCOF</a></code>, <code><a href="#topic+Energy">Energy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform DISCO tests
if(requireNamespace("energy", quietly = TRUE)) {
  DISCOB(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='DISCOF'>
Distance Components (DISCO) Tests
</h2><span id='topic+DISCOF'></span>

<h3>Description</h3>

<p>Performs Energy statistics distance components (DISCO) multi-sample tests (<cite>Rizzo and Sz√©kely, 2010</cite>). The implementation here uses the <code><a href="energy.html#topic+disco">disco</a></code> implementation from the <span class="pkg">energy</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DISCOF(X1, X2, ..., n.perm = 0, alpha = 1, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DISCOF_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="DISCOF_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="DISCOF_+3A_...">...</code></td>
<td>

<p>Further datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="DISCOF_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for Bootstrap test (default: 0, no Bootstrap test performed)
</p>
</td></tr>
<tr><td><code id="DISCOF_+3A_alpha">alpha</code></td>
<td>

<p>Power of the distance used for generalized Energy statistic (default: 1). Has to lie in <code class="reqn">(0,2]</code>. For values in <code class="reqn">(0, 2)</code>, consistency of the resulting test has been shown.
</p>
</td></tr>
<tr><td><code id="DISCOF_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>DISCO is a method for multi-sample testing based on all pairwise between-sample distances. It is analogous to the classical ANOVA. Instead of decomposing squared differences from the sample mean, the total dispersion (generalized Energy statistic) is composed into distance components (DISCO) consisting of the within-sample and between-sample measures of dispersion. 
</p>
<p><code>DISCOF</code> is based on the DISCO F ratio of the between-sample and within-sample dispersion. Note that the F ration does not follow an F distribution, but is just called F ratio analogous to the ANOVA.
</p>
<p>In both cases, small values of the statistic indicate similarity of the datasets and therefore, the null hypothesis of equal distributions is rejected for large values of the statistic.
</p>
<p>This implementation is a wrapper function around the function <code><a href="energy.html#topic+disco">disco</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="energy.html#topic+disco">disco</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>disco</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>The function call</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Vector of observed values of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Vector of Bootstrap p values</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of samples</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code>between</code></td>
<td>
<p>Between-sample distance components</p>
</td></tr>
<tr><td><code>withins</code></td>
<td>
<p>One-way within-sample distance components</p>
</td></tr>
<tr><td><code>within</code></td>
<td>
<p>Within-sample distance component</p>
</td></tr>
<tr><td><code>total</code></td>
<td>
<p>Total dispersion</p>
</td></tr>
<tr><td><code>Df.trt</code></td>
<td>
<p>Degrees of freedom for treatments</p>
</td></tr>
<tr><td><code>Df.e</code></td>
<td>
<p>Degrees of freedom for error</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>Alpha (exponent on distance)</p>
</td></tr>
<tr><td><code>factor.names</code></td>
<td>
<p>Factor names</p>
</td></tr>
<tr><td><code>factor.levels</code></td>
<td>
<p>Factor levels</p>
</td></tr>
<tr><td><code>sample.sizes</code></td>
<td>
<p>Sample sizes</p>
</td></tr>
<tr><td><code>stats</code></td>
<td>
<p>Matrix containing decomposition</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Szekely, G. J. and Rizzo, M. L. (2004) Testing for Equal Distributions in High Dimension, InterStat, November (5).
</p>
<p>Rizzo, M. L. and Szekely, G. J. (2010). DISCO Analysis: A Nonparametric Extension of Analysis of Variance, Annals of Applied Statistics, 4(2), 1034-1055.
doi:10.1214/09-AOAS245
</p>
<p>Szekely, G. J. (2000) Technical Report 03-05: E-statistics: Energy of Statistical Samples, Department of Mathematics and Statistics, Bowling Green State University.
</p>
<p>Rizzo, M., Szekely, G. (2022). energy: E-Statistics: Multivariate Inference via the Energy of Data. R package version 1.7-11, <a href="https://CRAN.R-project.org/package=energy">https://CRAN.R-project.org/package=energy</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DISCOB">DISCOB</a></code>, <code><a href="#topic+Energy">Energy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform DISCO tests
if(requireNamespace("energy", quietly = TRUE)) {
  DISCOF(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='DS'>
Rank-Based Energy Test (Deb and Sen, 2021)
</h2><span id='topic+DS'></span>

<h3>Description</h3>

<p>Performs the multivariate rank-based multivariate two-sample test using measure transportation by <cite>Deb and Sen (2021)</cite>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DS(X1, X2, n.perm = 0, rand.gen = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DS_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="DS_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="DS_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permuation test (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="DS_+3A_rand.gen">rand.gen</code></td>
<td>

<p>Function that generates a grid of (random) numbers in <code class="reqn">(0,1)</code> of dimension <code class="reqn">n \times k</code> (<code class="reqn">n</code> and <code class="reqn">k</code> are inputs of this function). Default is <code>NULL</code> in which case, <code><a href="randtoolbox.html#topic+halton">randtoolbox::halton</a></code> is used.
</p>
</td></tr>
<tr><td><code id="DS_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test proposed by <cite>Deb and Sen (2021)</cite> is a rank-based version of the Energy statistic (<cite>Sz√©kely and Rizzo, 2004</cite>) that does not rely on any moment assumptions. Its test statistic is the Energy statistic applied to the rank map of both samples. The multivariate ranks are computed using optimal transport with a multivariate uniform distribution as the reference distribution. 
</p>
<p>For the rank version of the Energy statistic it still holds that the value zero is attained if and only if the two distributions coincide. Therefore, low values of the empirical test statistic indicate similarity between the datasets and the null hypothesis of equal distributions is rejected for large values. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>The implementation is a modification of the code supplied by <cite>Deb and Sen (2021)</cite> for the simulation study presented in the original article. It generalizes the implementation and includes small modifications for computation speed. 
</p>


<h3>Author(s)</h3>

<p>Original implementation by Nabarun Deb, Bodhisattva Sen
</p>
<p>Minor modifications by Marieke Stolte
</p>


<h3>References</h3>

<p>Original implementation: <a href="https://github.com/NabarunD/MultiDistFree">https://github.com/NabarunD/MultiDistFree</a>
</p>
<p>Deb, N. and Sen, B. (2021). Multivariate Rank-Based Distribution-Free Nonparametric Testing Using Measure Transportation, Journal of the American Statistical Association. <a href="https://doi.org/10.1080/01621459.2021.1923508">doi:10.1080/01621459.2021.1923508</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Energy">Energy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Deb and Sen test 
if(requireNamespace("randtoolbox", quietly = TRUE) &amp; 
    requireNamespace("clue", quietly = TRUE)) {
  DS(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='Energy'>
Energy Statistic and Test
</h2><span id='topic+Energy'></span>

<h3>Description</h3>

<p>Performs the Energy statistic multi-sample test (<cite>Sz√©kely and Rizzo, 2004</cite>). The implementation here uses the <code><a href="energy.html#topic+eqdist.etest">eqdist.etest</a></code> implementation from the <span class="pkg">energy</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Energy(X1, X2, ..., n.perm = 0, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Energy_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Energy_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Energy_+3A_...">...</code></td>
<td>

<p>Further datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="Energy_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for Bootstrap test (default: 0, no Bootstrap test performed)
</p>
</td></tr>
<tr><td><code id="Energy_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Energy statistic (<cite>Sz√©kely and Rizzo, 2004</cite>) for two datasets <code class="reqn">X_1</code> and <code class="reqn">X_2</code> is defined as 
</p>
<p style="text-align: center;"><code class="reqn">T_{n_1, n_2} = \frac{n_1 n_2}{n_1+n_2}\left(\frac{1}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2} ||X_{1i} - X_{2j}|| -  \frac{1}{2n_1^2}\sum_{i,j=1}^{n_1} ||X_{1i} - X_{1j}|| -  \frac{1}{2n_2^2}\sum_{i,j=1}^{n_2} ||X_{2i} - X_{2j}||\right).</code>
</p>

<p>This is equal to the Cram√©r test statistitic (<cite>Baringhaus and Franz, 2004</cite>).
The multi-sample version is defined as the sum of the Energy statistics for all pairs of samples. 
</p>
<p>The population Energy statistic for two distributions is equal to zero if and only if the two distributions coincide. Therefore, small values of the empirical statistic indicate similarity between datasets and the permutation test rejects the null hypothesis of equal distributions for large values. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="energy.html#topic+eqdist.etest">eqdist.etest</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="energy.html#topic+eqdist.etest">eqdist.etest</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>The function call</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Bootstrap p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>The test based on the Energy statistic (<cite>Sz√©kely and Rizzo, 2004</cite>) is equivalent to the Cram√©r test (<cite>Baringhaus and Franz, 2004</cite>). 
</p>


<h3>References</h3>

<p>Szekely, G. J. and Rizzo, M. L. (2004) Testing for Equal Distributions in High Dimension, InterStat, November (5).
</p>
<p>Szekely, G. J. (2000) Technical Report 03-05: E-statistics: Energy of Statistical Samples, Department of Mathematics and Statistics, Bowling Green State University.
</p>
<p>Rizzo, M., Szekely, G. (2022). energy: E-Statistics: Multivariate Inference via the Energy of Data. R package version 1.7-11, <a href="https://CRAN.R-project.org/package=energy">https://CRAN.R-project.org/package=energy</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Cramer">Cramer</a></code>, <code><a href="#topic+DISCOB">DISCOB</a></code>, <code><a href="#topic+DISCOF">DISCOF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Energy test
if(requireNamespace("energy", quietly = TRUE)) {
  Energy(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='engineerMetric'>
Engineer Metric
</h2><span id='topic+engineerMetric'></span>

<h3>Description</h3>

<p>The function implements the <code class="reqn">L_q</code>-engineer metric for comparing two multivariate distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>engineerMetric(X1, X2, type = "F", seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="engineerMetric_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="engineerMetric_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="engineerMetric_+3A_type">type</code></td>
<td>

<p>Character specifying the type of <code class="reqn">L_q</code>-norm to use. Reasonable options are <code>"O"</code>, <code>"o"</code>, <code>"1"</code>, for the <code class="reqn">L_1</code>-norm, <code>"I"</code>, and <code>"i"</code>, for the <code class="reqn">L_\infty</code>-norm, and <code>"F"</code>, <code>"f"</code>, <code>"E"</code>, <code>"e"</code> (the default) for the <code class="reqn">L_2</code>-norm (Euclidean norm). 
</p>
</td></tr>
<tr><td><code id="engineerMetric_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42). Method is deterministic, seed is only set for consistency with other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The engineer is a primary propability metric that is defined as 
</p>
<p style="text-align: center;"><code class="reqn">\text{EN}(X_1, X_2; q) = \left[ \sum_{i = 1}^{p} \left| \text{E}\left(X_{1i}\right) - \text{E}\left(X_{2i}\right)\right|^q\right]^{\min(q, 1/q)} \text{ with } q&gt; 0,</code>
</p>

<p>where <code class="reqn">X_{1i}, X_{2i}</code> denote the <code class="reqn">i</code>th component of the <code class="reqn">p</code>-dimensional random vectors <code class="reqn">X_1\sim F_1</code> and <code class="reqn">X_2\sim F_2</code>.
</p>
<p>In the implementation, expectations are estimated by column means of the respective datasets. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis
</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>The seed argument is only included for consistency with other methods. The result of the metric calculation is deteministic.
</p>


<h3>References</h3>

<p>Rachev, S. T. (1991). Probability metrics and the stability of stochastic models. John Wiley &amp; Sons, Chichester.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Jeffreys">Jeffreys</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Calculate engineer metric
engineerMetric(X1, X2)
</code></pre>

<hr>
<h2 id='FR'>
Friedman-Rafsky Test
</h2><span id='topic+FR'></span>

<h3>Description</h3>

<p>Performs the Friedman-Rafsky two-sample test (original edge-count test) for multivariate data (<cite>Friedman and Rafsky, 1979</cite>). The implementation here uses the <code><a href="gTests.html#topic+g.tests">g.tests</a></code> implementation from the <span class="pkg">gTests</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FR(X1, X2, dist.fun = stats::dist, graph.fun = MST, n.perm = 0, 
    dist.args = NULL, graph.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FR_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="FR_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="FR_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="FR_+3A_graph.fun">graph.fun</code></td>
<td>

<p>Function for calculating a similarity graph using the distance matrix on the pooled sample (default: <code><a href="#topic+MST">MST</a></code>, Minimum Spanning Tree).
</p>
</td></tr>
<tr><td><code id="FR_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="FR_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="FR_+3A_graph.args">graph.args</code></td>
<td>

<p>Named list of further arguments passed to <code>graph.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="FR_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is a multivariate extension of the univariate Wald Wolfowitz runs test. The test statistic is the number of edges connecting points from different datasets in a minimum spanning tree calculated on the pooled sample (standardized with expectation and SD under the null). 
</p>
<p>High values of the test statistic indicate similarity of the datasets. Thus, the null hypothesis of equal distributions is rejected for small values. 
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Friedman, J. H., and Rafsky, L. C. (1979). Multivariate Generalizations of the Wald-Wolfowitz and Smirnov Two-Sample Tests. The Annals of Statistics, 7(4), 697-717. 
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CF">CF</a></code> for the generalized edge-count test, <code><a href="#topic+CCS">CCS</a></code> for the weighted edge-count test, <code><a href="#topic+ZC">ZC</a></code> for the maxtype edge-count test, <code><a href="#topic+gTests">gTests</a></code> for performing all these edge-count tests at once, <code><a href="#topic+SH">SH</a></code> for performing the Schilling-Henze nearest neighbor test,
<code><a href="#topic+CCS_cat">CCS_cat</a></code>, <code><a href="#topic+FR_cat">FR_cat</a></code>, <code><a href="#topic+CF_cat">CF_cat</a></code>, <code><a href="#topic+ZC_cat">ZC_cat</a></code>, and <code><a href="#topic+gTests_cat">gTests_cat</a></code> for versions of the test for categorical data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Friedman-Rafsky test
if(requireNamespace("gTests", quietly = TRUE)) {
  FR(X1, X2)
}
</code></pre>

<hr>
<h2 id='FR_cat'>
Friedman-Rafsky Test for Discrete Data
</h2><span id='topic+FR_cat'></span>

<h3>Description</h3>

<p>Performs the Friedman-Rafsky two-sample test (original edge-count test) for multivariate data (<cite>Friedman and Rafsky, 1979</cite>). The implementation here uses the <code><a href="gTests.html#topic+g.tests">g.tests</a></code> implementation from the <span class="pkg">gTests</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FR_cat(X1, X2, dist.fun, agg.type, graph.type = "mstree", K = 1, n.perm = 0, 
        seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FR_cat_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="FR_cat_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="FR_cat_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset.
</p>
</td></tr>
<tr><td><code id="FR_cat_+3A_agg.type">agg.type</code></td>
<td>

<p>Character giving the method for aggregating over possible similarity graphs. Options are <code>"u"</code> for union of possible similarity graphs and <code>"a"</code> for averaging over test statistics calculated on possible similarity graphs. 
</p>
</td></tr>
<tr><td><code id="FR_cat_+3A_graph.type">graph.type</code></td>
<td>

<p>Character specifying which similarity graph to use. Possible options are <code>"mstree"</code> (default, Minimum Spanning Tree) and <code>"nnlink"</code> (Nearest Neighbor Graph).
</p>
</td></tr>
<tr><td><code id="FR_cat_+3A_k">K</code></td>
<td>

<p>Parameter for graph (default: 1). If <code>graph.type = "mstree"</code>, a <code>K</code>-MST is constructed (<code>K=1</code> is the classical MST). If <code>graph.type = "nnlink"</code>, <code>K</code> gives the number of neighbors considered in the <code>K</code>-NN graph.
</p>
</td></tr>
<tr><td><code id="FR_cat_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="FR_cat_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is a multivariate extension of the univariate Wald Wolfowitz runs test. The test statistic is the number of edges connecting points from different datasets in a minimum spanning tree calculated on the pooled sample (standardized with expectation and SD under the null). 
For discrete data, the similarity graph used in the test is not necessarily unique. This can be solved by either taking a union of all optimal similarity graphs or averaging the test statistics over all optimal similarity graphs. For details, see Zhang and Chen (2022). 
</p>
<p>High values of the test statistic indicate similarity of the datasets. Thus, the null hypothesis of equal distributions is rejected for small values. 
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Degrees of freedom for <code class="reqn">\chi^2</code> distribution under <code class="reqn">H_0</code> (only for asymptotic test)</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Friedman, J. H., and Rafsky, L. C. (1979). Multivariate Generalizations of the Wald-Wolfowitz and Smirnov Two-Sample Tests. The Annals of Statistics, 7(4), 697-717.
</p>
<p>Zhang, J. and Chen, H. (2022). Graph-Based Two-Sample Tests for Data with Repeated Observations. Statistica Sinica 32, 391-415, <a href="https://doi.org/10.5705/ss.202019.0116">doi:10.5705/ss.202019.0116</a>.
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CF_cat">CF_cat</a></code> for the generalized edge-count test, <code><a href="#topic+CCS_cat">CCS_cat</a></code> for the weighted edge-count test, <code><a href="#topic+ZC_cat">ZC_cat</a></code> for the maxtype edge-count test, <code><a href="#topic+gTests_cat">gTests_cat</a></code> for performing all these edge-count tests at once, 
<code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+ZC">ZC</a></code>, and <code><a href="#topic+gTests">gTests</a></code> for versions of the tests for continuous data, and <code><a href="#topic+SH">SH</a></code> for performing the Schilling-Henze nearest neighbor test
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1cat &lt;- matrix(sample(1:4, 300, replace = TRUE), ncol = 3)
X2cat &lt;- matrix(sample(1:4, 300, replace = TRUE, prob = 1:4), ncol = 3)
# Perform Friedman-Rafsky test
if(requireNamespace("gTests", quietly = TRUE)) {
  FR_cat(X1cat, X2cat, dist.fun = function(x, y) sum(x != y), agg.type = "a")
}
</code></pre>

<hr>
<h2 id='FStest'>
Multisample FS Test
</h2><span id='topic+FStest'></span>

<h3>Description</h3>

<p>Performs the (modified/ multiscale/ aggregated) FS test (<cite>Paul et al., 2021</cite>). The implementation is based on the <code><a href="HDLSSkST.html#topic+FStest">FStest</a></code>, <code><a href="HDLSSkST.html#topic+MTFStest">MTFStest</a></code>, and <code><a href="HDLSSkST.html#topic+AFStest">AFStest</a></code> implementations from the <span class="pkg">HDLSSkST</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FStest(X1, X2, ..., n.clust, randomization = TRUE, version = "original", 
        mult.test = "Holm", kmax = 2 * n.clust, s.psi = 1, s.h = 1, 
        lb = 1, n.perm = 1/alpha, alpha = 0.05, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FStest_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="FStest_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="FStest_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="FStest_+3A_n.clust">n.clust</code></td>
<td>

<p>Number of clusters (only applicable for <code>version = "original"</code>).
</p>
</td></tr>
<tr><td><code id="FStest_+3A_randomization">randomization</code></td>
<td>

<p>Should a randomized test be performed? (default: <code>TRUE</code>, ranomized test is performed)
</p>
</td></tr>
<tr><td><code id="FStest_+3A_version">version</code></td>
<td>

<p>Which version of the test should be performed? Possible options are <code>"original"</code> (default) for the FS test, <code>"modified"</code> for the MFS test (number of clusters is estimated), <code>"multiscale"</code> for the MSFS test (all numbers of clusters up to <code>kmax</code> are tried and results are summarized), <code>"aggregated-knw"</code> (all pairwise comparisons are tested with the FS test and results are aggregated), and <code>"aggregated-est"</code> (all pairwise comparisons are tested with the MFS test and results are aggregated).
</p>
</td></tr>
<tr><td><code id="FStest_+3A_mult.test">mult.test</code></td>
<td>

<p>Multiple testing adjustment for AFS test and MSFS test. Possible options are <code>"Holm"</code> (default) and <code>"BenHoch"</code>.
</p>
</td></tr>
<tr><td><code id="FStest_+3A_kmax">kmax</code></td>
<td>

<p>Maximum number of clusters to try for estimating the number of clusters (default: <code>2*n.clust</code>).
</p>
</td></tr>
<tr><td><code id="FStest_+3A_s.psi">s.psi</code></td>
<td>

<p>Numeric code for function required for calculating the distance for <code class="reqn">K</code>-means clustering. 
The value <code>1</code> corresponds to <code class="reqn">\psi(t) = t^2</code> (the default), 
<code>2</code> corresponds to <code class="reqn">\psi(t) = 1 - \exp(-t)</code>,
<code>3</code> corresponds to <code class="reqn">\psi(t) = 1 - \exp(-t^2)</code>,
<code>4</code> corresponds to <code class="reqn">\psi(t) = \log(1 + t)</code>,
<code>5</code> corresponds to <code class="reqn">\psi(t) = t</code>.
</p>
</td></tr>
<tr><td><code id="FStest_+3A_s.h">s.h</code></td>
<td>

<p>Numeric code for function required for calculating the distance for <code class="reqn">K</code>-means clustering. 
The value <code>1</code> corresponds to <code class="reqn">h(t) = \sqrt{t}</code> (the default), and 
<code>2</code> corresponds to <code class="reqn">h(t) = t</code>.
</p>
</td></tr>
<tr><td><code id="FStest_+3A_lb">lb</code></td>
<td>

<p>Length of smaller vectors into which each observation is partitioned (default: 1).
</p>
</td></tr>
<tr><td><code id="FStest_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of simulations of the test statistic (default: 1/alpha, minimum number required for running the test, set to a higher value for meaningful test results).
</p>
</td></tr>
<tr><td><code id="FStest_+3A_alpha">alpha</code></td>
<td>

<p>Test level (default: 0.05).
</p>
</td></tr>
<tr><td><code id="FStest_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tests are intended for the high dimension low sample size (HDLSS) setting. The idea is to cluster the pooled sample using a clustering algorithm that is suitable for the HDLSS setting and then to compare the clustering to the true dataset membership and test for dependence using a generalized Fisher test on the contingency table of clustering and dataset membership.
For the original FS test, the number of clusters has to be specified. If no number is specified it is set to the number of samples. 
This is a reasonable number of clusters in many cases. 
</p>
<p>However, in some cases, different numbers of clusters might be needed. 
For example in case of multimodal distributions in the datasets, there might be multiple clusters within each dataset. 
Therefore, the modified (MFS) test allows to estimate the number of clusters from the data. 
</p>
<p>In case of a really unclear number of clusters, the multiscale (MSFS) test can be applied which calculates the test for each number of clusters up to <code>kmax</code> and then summarizes the test results using some adjustment for multiple testing. 
</p>
<p>These three tests take into account all samples simultaneously. The aggregated (AFS) test instead performs all pairwise FS or MFS tests on the samples and aggregates those results by taking the minimum test statistic value and applying a multiple testing procedure.
</p>
<p>For clustering, a <code class="reqn">K</code>-means algorithm using the generalized version of the Mean Absolute Difference of Distances (MADD) (<cite>Sarkar and Ghosh, 2020</cite>) is applied. 
The MADD is defined as 
</p>
<p style="text-align: center;"><code class="reqn">
\rho_{h,\varphi}(z_i, z_j) = \frac{1}{N-2} \sum_{m\in \{1,\dots, N\}\setminus\{i,j\}} \left| \varphi_{h,\psi}(z_i, z_m) - \varphi_{h,\psi}(z_j, z_m)\right|,
</code>
</p>

<p>where <code class="reqn">z_i \in\mathbb{R}^p, i = 1,\dots,N</code>, denote points from the pooled sample and 
</p>
<p style="text-align: center;"><code class="reqn">\varphi_{h,\psi}(z_i, z_j) = h\left(\frac{1}{p}\sum_{i=l}^p\psi|z_{il} - z_{jl}|\right),</code>
</p>

<p>with <code class="reqn">h:\mathbb{R}^{+} \to\mathbb{R}^{+}</code> and <code class="reqn">\psi:\mathbb{R}^{+} \to\mathbb{R}^{+}</code> continuous and strictly increasing functions. 
The functions <code class="reqn">h</code> and <code class="reqn">\psi</code> can be set via changing <code>s.psi</code> and <code>s.h</code>.
</p>
<p>In all cases, high values of the test statistic correspond to similarity between the datasets. Therefore, the null hypothesis of equal distributions is rejected for low values. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>est.cluster.label</code></td>
<td>
<p>The estimated cluster label (not for AFS and MSFS)</p>
</td></tr>
<tr><td><code>observed.cont.table</code></td>
<td>
<p>The observed contingency table of dataset membership and estimated cluster label (not for AFS)</p>
</td></tr>
<tr><td><code>crit.value</code></td>
<td>
<p>The critical value of the test (not for MSFS)</p>
</td></tr>
<tr><td><code>random.gamma</code></td>
<td>
<p>The randomization constant of the test (not for MSFS)</p>
</td></tr>
<tr><td><code>decision</code></td>
<td>
<p>The (overall) test decision</p>
</td></tr>
<tr><td><code>decision.per.k</code></td>
<td>
<p>The test decisions of all individual tests (only for MSFS)</p>
</td></tr>
<tr><td><code>est.cluster.no</code></td>
<td>
<p>The estimated number of clusters (not for MSFS)</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>In case of <code>version = "multiscale"</code> the output is a list object and not of class <code>htest</code> as there are multiple test statistic values and corresponding p values.
</p>
<p>Note that the aggregated test cannot handle univariate data. 
</p>


<h3>References</h3>

<p>Paul, B., De, S. K. and Ghosh, A. K. (2021). Some clustering based exact distribution-free k-sample tests applicable to high dimension, low sample size data, Journal of Multivariate Analysis, <a href="https://doi.org/10.1016/j.jmva.2021.104897">doi:10.1016/j.jmva.2021.104897</a>
</p>
<p>Mehta, C. R. and Patel, N.R. (1983). A network algorithm for performing Fisher's exact test in rxc contingency tables, Journal of the American Statistical Association, 78(382):427-434, <a href="https://doi.org/10.2307/2288652">doi:10.2307/2288652</a>
</p>
<p>Holm, S. (1979). A simple sequentially rejective multiple test procedure, Scandinavian journal of statistics, 65-70
</p>
<p>Benjamini, Y. and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing, Journal of the Royal statistical society: series B (Methodological) 57.1: 289-300, <a href="https://doi.org/10.1111/j.2517-6161.1995.tb02031.x">doi:10.1111/j.2517-6161.1995.tb02031.x</a>
</p>
<p>Sarkar, S. and Ghosh, A. K. (2020). On Perfect Clustering of High Dimension, Low Sample Size Data. IEEE Transactions on Pattern Analysis and Machine Intelligence 42 2257-2272. <a href="https://doi.org/10.1109/TPAMI.2019.2912599">doi:10.1109/TPAMI.2019.2912599</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RItest">RItest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
if(requireNamespace("HDLSSkST", quietly = TRUE)) {
  # Perform FS test 
  FStest(X1, X2, n.clust = 2)
  # Perform MFS test
  FStest(X1, X2, version = "modified")
  # Perform MSFS
  FStest(X1, X2, version = "multiscale")
  # Perform AFS test 
  FStest(X1, X2, n.clust = 2, version = "aggregated-knw")
  FStest(X1, X2, version = "aggregated-est")
}
</code></pre>

<hr>
<h2 id='GGRL'>
Decision-Tree Based Measure of Dataset Distance and Two-Sample Test
</h2><span id='topic+GGRL'></span><span id='topic+GGRLCat'></span><span id='topic+f.s'></span><span id='topic+f.a'></span><span id='topic+f.sCat'></span><span id='topic+f.aCat'></span>

<h3>Description</h3>

<p>Calculates Decision-Tree Based Measure of Dataset Distance by <cite>Ganti et al. (2002)</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GGRL(X1, X2, target1 = "y", target2 = "y", n.perm = 0, m = 1, diff.fun = f.a, 
      agg.fun = sum, tune = TRUE, k = 5, n.eval = 100, seed = 42, ...)
GGRLCat(X1, X2, target1 = "y", target2 = "y", n.perm = 0, m = 1, diff.fun = f.aCat, 
        agg.fun = sum, tune = TRUE, k = 5, n.eval = 100, seed = 42, ...)
f.a(sec.parti, X1, X2)
f.s(sec.parti, X1, X2)
f.aCat(sec.parti, X1, X2)
f.sCat(sec.parti, X1, X2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GGRL_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_target1">target1</code></td>
<td>

<p>Character specifying the column name of the class variable in the first dataset (default: <code>"y"</code>)
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_target2">target2</code></td>
<td>

<p>Character specifying the column name of the class variable in the second dataset (default: <code>"y"</code>)
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permuation test (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_m">m</code></td>
<td>

<p>subsampling rate for Bootstrap test (default: 1). Ganti et al. (2002) suggest that 0.2-0.3 is sufficient in many cases. Ignored if <code>n.perm &lt;= 0</code>.
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_diff.fun">diff.fun</code></td>
<td>

<p>Difference function as function (default: <code>f.a</code>, absolute difference). Other options: <code>f.s</code> (scaled difference), user specified function that takes greatest common refinement (GCR) partition and both datasets as input and returns vector of difference values for each section in the partition.
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_agg.fun">agg.fun</code></td>
<td>

<p>Aggregate function (default: <code>sum</code>). Other options are <code>max</code>, or user specified function that takes output of <code>diff.fun</code> and aggregates it into a single value. Note that only for <code>sum</code> it has been shown that the GCR is optimal.
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_tune">tune</code></td>
<td>

<p>Should the decision tree parameters be tuned? (default: <code>TRUE</code>)
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_k">k</code></td>
<td>

<p>Number of folds used in cross-validation for parameter tuning (default: 5). Ignored if <code>tune = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_n.eval">n.eval</code></td>
<td>

<p>Number of evaluations for random search used for parameter tuning (default: 100). Ignored if <code>tune = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code><a href="rpart.html#topic+rpart">rpart</a></code>. Ignored if <code>tune = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="GGRL_+3A_sec.parti">sec.parti</code></td>
<td>

<p>Intersected partition as output by <code>calculateGCR</code>, i.e. a list containing the intersected partition and each partition on its own as dataframes with limits for each variable. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method first calculates the greatest common refinement (GCR), that is the intersection of the sample space partitions induced by a decision tree fit to the first dataset and a decision tree fit to the second dataset. The proportions of samples falling into each section of the GCR is calculated for each dataset. These proportions are compared using a difference function and the results of this are aggregated by the aggregate function.
</p>
<p>The implementation uses <code><a href="rpart.html#topic+rpart">rpart</a></code> for fitting classification trees to each dataset. 
</p>
<p><code><a href="e1071.html#topic+best.rpart">best.rpart</a></code> is used for hyperparameter tuning if <code>tune = TRUE</code>. The parameters are tuned using cross-validation and random search. The parameter <code>minsplit</code> is tuned over <code>2^(1:7)</code>, <code>minbucket</code> is tuned over <code>2^(0:6)</code> and <code>cp</code> is tuned over <code>10^seq(-4, -1, by = 0.001)</code>. 
</p>
<p>Pre-implemented methods for the difference function are </p>
<p style="text-align: center;"><code class="reqn">f_a(\kappa_1, \kappa_2, n_1, n_2) = |\frac{\kappa_1}{n_1} - \frac{\kappa_2}{n_2}|, </code>
</p>

<p>and </p>
<p style="text-align: center;"><code class="reqn">f_s(\kappa_1, \kappa_2, n_1, n_2) = \frac{|\frac{\kappa_1}{n_1} - \frac{\kappa_2}{n_2}|}{(\frac{\kappa_1}{n_1} + \frac{\kappa_2}{n_2}) / 2}, \text{ if }\kappa_1+\kappa_2&gt;0,</code>
</p>
<p style="text-align: center;"><code class="reqn">= 0 \text{ otherwise,}</code>
</p>
<p> where <code class="reqn">\kappa_i</code> is the number of observations from dataset <code class="reqn">i</code> in the respective region of the greatest common refinement and <code class="reqn">n_i</code> are the sample sizes, <code class="reqn">i = 1, 2</code>.
</p>
<p>The aggregate function aggregates the results of the difference function over all regions in the greatest common refinement.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>The categorical method might not work properly if certain combinations of the categorical variables are not present in both datasets. This might happen e.g. for a large number of categories or variables and for small numbers of observations. In this case it might happen that the decision tree of the dataset where the combination is missing is unable to match a level of the split variable to one of the child nodes. Therefore, this combination is not part of the partition of the sample space induced by the tree and therefore also not of the greatest common refinement. Thus, some points of the other dataset cannot be sorted into any region of the greatest common refinement and the probabilities in the joint distribution calculated over the greatest common refinement do not sum up to one anymore. A warning is printed in these cases. It is unclear how this affects the performance. 
</p>
<p>Note that for small numbers of categories and deep trees it might also happen that the greatest common refinement reduces to all observed combinations of categories in the variables. Then the dataset distance measures is just a complicated way to measure the difference in frequencies of all observed combinations. 
</p>


<h3>References</h3>

<p>Ganti, V., Gehrke, J., Ramakrishnan, R. and Loh W.-Y. (2002). A Framework for Measuring Differences in Data Characteristics, Journal of Computer and System Sciences, 64(3), <a href="https://doi.org/10.1006/jcss.2001.1808">doi:10.1006/jcss.2001.1808</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NKT">NKT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
y1 &lt;- rbinom(100, 1, 1 / (1 + exp(1 - X1 %*% rep(0.5, 10))))
y2 &lt;- rbinom(100, 1, 1 / (1 + exp(1 - X2 %*% rep(0.7, 10))))
X1 &lt;- data.frame(X = X1, y = y1)
X2 &lt;- data.frame(X = X2, y = y2)
# Calculate Ganti et al. statistic (without tuning and testing due to runtime)
if(requireNamespace("rpart", quietly = TRUE)) {
  GGRL(X1, X2, "y", "y", tune = FALSE)
}

# Categorical case
set.seed(1234)
X1 &lt;- data.frame(X1 = factor(sample(letters[1:5], 1000, TRUE)), 
                 X2 = factor(sample(letters[1:4], 1000, TRUE)), 
                 X3 = factor(sample(letters[1:3], 1000, TRUE)), 
                 y = sample(0:1, 100, TRUE))
X2 &lt;- data.frame(X1 = factor(sample(letters[1:5], 1000, TRUE, 1:5)), 
                 X2 = factor(sample(letters[1:4], 1000, TRUE, 1:4)), 
                 X3 = factor(sample(letters[1:3], 1000, TRUE, 1:3)), 
                 y = sample(0:1, 100, TRUE))
# Calculate Ganti et al. statistic (without tuning and testing due to runtime)
if(requireNamespace("rpart", quietly = TRUE)) {
  GGRLCat(X1, X2, "y", "y", tune = FALSE)
}
</code></pre>

<hr>
<h2 id='GPK'>
Generalized Permutation-Based Kernel (GPK) Two-Sample Test
</h2><span id='topic+GPK'></span><span id='topic+findSigma'></span>

<h3>Description</h3>

<p>Performs the generalized permutation-based kernel two-sample test proposed by <cite>Song and Chen (2021)</cite>. The implementation here uses the <code><a href="kerTests.html#topic+kertests">kertests</a></code> implementation from the <span class="pkg">kerTests</span> package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GPK(X1, X2, n.perm = 0, fast = (n.perm == 0), M = FALSE,
    sigma = findSigma(X1, X2), r1 = 1.2, r2 = 0.8, seed = 42)
findSigma(X1, X2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GPK_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="GPK_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="GPK_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, fast test is performed). For <code>fast = FALSE</code>, only the permutation test and no asymptotic test is available. For <code>fast = TRUE</code>, either an asymptotic test (set <code>n.perm = 0</code>) and a permutation test (set <code>n.perm</code> &gt; 0) can be performed.
</p>
</td></tr>
<tr><td><code id="GPK_+3A_fast">fast</code></td>
<td>

<p>Should the fast test be performed? (default: <code>TRUE</code> if <code>n.perm = 0</code>, <code>FALSE</code> if <code>n.perm</code> &gt; 0)
</p>
</td></tr>
<tr><td><code id="GPK_+3A_m">M</code></td>
<td>

<p>Should the MMD approximation test be performed? (default: <code>FALSE</code>). Ignored if <code>fast = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="GPK_+3A_sigma">sigma</code></td>
<td>

<p>Bandwidth parameter of the kernel. By default the median heuristic is used to choose <code>sigma</code>.
</p>
</td></tr>
<tr><td><code id="GPK_+3A_r1">r1</code></td>
<td>

<p>Constant in the test statistic <code class="reqn">Z_{W, r1}</code> for the fast test (default: 1.2, proposed in original article)
</p>
</td></tr>
<tr><td><code id="GPK_+3A_r2">r2</code></td>
<td>

<p>Constant in the test statistic <code class="reqn">Z_{W, r2}</code> for the fast test (default: 0.8, proposed in original article)
</p>
</td></tr>
<tr><td><code id="GPK_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GPK test is motivated by the observation that the MMD test performs poorly for detecting differences in variances. The unbiased MMD<code class="reqn">^2</code> estimator for a given kernel function <code class="reqn">k</code> can be written as 
</p>
<p style="text-align: center;"><code class="reqn">\text{MMD}_u^2 = \alpha + \beta - 2\gamma, \text{ where}</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha = \frac{1}{n_1^2 - n_1}\sum_{i=1}^{n_1}\sum_{j=1, j\ne i}^{n_1} k(X_{1i}, X_{1j}),</code>
</p>

<p style="text-align: center;"><code class="reqn">\beta = \frac{1}{n_2^2 - n_2}\sum_{i=1}^{n_2}\sum_{j=1, j\ne i}^{n_2} k(X_{2i}, X_{2j}),</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma = \frac{1}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2} k(X_{1i}, X_{2j}).</code>
</p>

<p>The GPK test statistic is defined as
</p>
<p style="text-align: center;"><code class="reqn">\text{GPK} = (\alpha - \text{E}(\alpha), \beta - \text{E}(\beta))\Sigma^{-1} \binom{\alpha - \text{E}(\alpha)}{\beta - \text{E}(\beta)}</code>
</p>

<p style="text-align: center;"><code class="reqn">= Z_{W,1}^2 + Z_D^2\text{ with}</code>
</p>

<p style="text-align: center;"><code class="reqn">Z_{W,r} = \frac{W_r - \text{E}(W_r)}{\sqrt{\text{Var}(W_r)}}, W_r = r\frac{n_1 \alpha}{n_1 + n_2}, </code>
</p>

<p style="text-align: center;"><code class="reqn">Z_D = \frac{D - \text{E}(D)}{\sqrt{\text{Var}(D)}}, D = n_1(n_1 - 1)\alpha - n_2(n_2 - 1)\beta,</code>
</p>

<p>where the expectations are calculated under the null and <code class="reqn">\Sigma</code> is the covariance matrix of <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> under the null. 
</p>
<p>The asymptotic null distribution for GPK is unknown. Therefore, only a permutation test can be performed.
</p>
<p>For <code class="reqn">r \ne 1</code>, the asymptotic null distribution of <code class="reqn">Z_{W,r}</code> is normal, but for <code class="reqn">r</code> further away from 1, the test performance decreases. Therefore, <code class="reqn">r_1 = 1.2</code> and <code class="reqn">r_2 = 0.8</code> are proposed as a compromise.  
</p>
<p>For the fast GPK test, three (asymptotic or permutation) tests based on <code class="reqn">Z_{W, r1}</code>, <code class="reqn">Z_{W, r2}</code> and <code class="reqn">Z_{D}</code> are concucted and the overall p value is calculated as 3 times the minimum of the three p values. 
</p>
<p>For the fast MMD test, only the two asymptotic tests based on <code class="reqn">Z_{W, r1}</code>, <code class="reqn">Z_{W, r2}</code> are used and the p value is 2 times the minimum of the two p values. This is an approximation of the MMD-permutation test, see <code><a href="#topic+MMD">MMD</a></code>.
</p>
<p>This implementation is a wrapper function around the function <code><a href="kerTests.html#topic+kertests">kertests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="kerTests.html#topic+kertests">kertests</a></code>. 
</p>
<p><code>findSigma</code> finds the optimal bandwidth parameter of the kernel function using the median heuristic and is a wrapper around <code><a href="kerTests.html#topic+med_sigma">med_sigma</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>Needed for pretty printing of results</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>Needed for pretty printing of results</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>Needed for pretty printing of results</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Song, H. and Chen, H. (2021). Generalized Kernel Two-Sample Tests. arXiv preprint. <a href="https://doi.org/10.1093/biomet/asad068">doi:10.1093/biomet/asad068</a>.
</p>
<p>Song H, Chen H (2023). kerTests: Generalized Kernel Two-Sample Tests. R package version 0.1.4, <a href="https://CRAN.R-project.org/package=kerTests">https://CRAN.R-project.org/package=kerTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MMD">MMD</a></code>, <code><a href="#topic+kerTests">kerTests</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
if(requireNamespace("kerTests", quietly = TRUE)) {
  # Perform GPK test
  GPK(X1, X2, n.perm = 100)
  # Perform fast GPK test (permutation version)
  GPK(X1, X2, n.perm = 100, fast = TRUE)
  # Perform fast GPK test (asymptotic version)
  GPK(X1, X2, n.perm = 0, fast = TRUE)
  # Perform fast MMD test (permutation version)
  GPK(X1, X2, n.perm = 100, fast = TRUE, M = TRUE)
  # Perform fast MMD test (asymptotic version)
  GPK(X1, X2, n.perm = 0, fast = TRUE, M = TRUE)
}
</code></pre>

<hr>
<h2 id='gTests'>
Graph-Based Tests
</h2><span id='topic+gTests'></span>

<h3>Description</h3>

<p>Performs the edge-count two-sample tests for multivariate data implementated in <code><a href="gTests.html#topic+g.tests">g.tests</a></code> from the <span class="pkg">gTests</span> package. This function is inteded to be used e.g. in comparison studies where all four graph-based tests need to be calculated at the same time. Since large parts of the calculation coincide, using this function should be faster than computing all four statistics individually.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gTests(X1, X2, dist.fun = stats::dist, graph.fun = MST, 
        n.perm = 0, dist.args = NULL, graph.args = NULL,
        maxtype.kappa = 1.14,  seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gTests_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="gTests_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="gTests_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="gTests_+3A_graph.fun">graph.fun</code></td>
<td>

<p>Function for calculating a similarity graph using the distance matrix on the pooled sample (default: <code><a href="#topic+MST">MST</a></code>, Minimum Spanning Tree).
</p>
</td></tr>
<tr><td><code id="gTests_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="gTests_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code>.
</p>
</td></tr>
<tr><td><code id="gTests_+3A_graph.args">graph.args</code></td>
<td>

<p>Named list of further arguments passed to <code>graph.fun</code>.
</p>
</td></tr>
<tr><td><code id="gTests_+3A_maxtype.kappa">maxtype.kappa</code></td>
<td>

<p>Parameter <code class="reqn">\kappa</code> of the maxtype test (default: 1.14). See <code><a href="#topic+ZC">ZC</a></code>.
</p>
</td></tr>
<tr><td><code id="gTests_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original, weighted, generalized and maxtype edge-count test are performed.
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed values of the test statistics</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p values</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Friedman, J. H., and Rafsky, L. C. (1979). Multivariate Generalizations of the Wald-Wolfowitz and Smirnov Two-Sample Tests. The Annals of Statistics, 7(4), 697-717. 
</p>
<p>Chen, H. and Friedman, J.H. (2017). A New Graph-Based Two-Sample
Test for Multivariate and Object Data. Journal of the American Statistical Association, 112(517), 397-409. <a href="https://doi.org/10.1080/01621459.2016.1147356">doi:10.1080/01621459.2016.1147356</a>
</p>
<p>Chen, H., Chen, X. and Su, Y. (2018). A Weighted Edge-Count Two-Sample
Test for Multivariate and Object Data. Journal of the American Statistical Association, 113(523), 1146-1155, <a href="https://doi.org/10.1080/01621459.2017.1307757">doi:10.1080/01621459.2017.1307757</a>
</p>
<p>Zhang, J. and Chen, H. (2022). Graph-Based Two-Sample Tests for Data with Repeated Observations. Statistica Sinica 32, 391-415, <a href="https://doi.org/10.5705/ss.202019.0116">doi:10.5705/ss.202019.0116</a>.
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR">FR</a></code> for the original edge-count test, <code><a href="#topic+CF">CF</a></code> for the generalized edge-count test, <code><a href="#topic+CCS">CCS</a></code> for the weighted edge-count test, and <code><a href="#topic+ZC">ZC</a></code> for the maxtype edge-count test,
<code><a href="#topic+gTests_cat">gTests_cat</a></code>, <code><a href="#topic+CCS_cat">CCS_cat</a></code>, <code><a href="#topic+FR_cat">FR_cat</a></code>, <code><a href="#topic+CF_cat">CF_cat</a></code>, and <code><a href="#topic+ZC_cat">ZC_cat</a></code> for versions of the tests for categorical data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform edge-count tests
if(requireNamespace("gTests", quietly = TRUE)) {
  gTests(X1, X2)
}
</code></pre>

<hr>
<h2 id='gTests_cat'>
Graph-Based Tests for Discrete Data
</h2><span id='topic+gTests_cat'></span>

<h3>Description</h3>

<p>Performs the edge-count two-sample tests for multivariate categorical data implementated in <code><a href="gTests.html#topic+g.tests">g.tests</a></code> from the <span class="pkg">gTests</span> package. This function is inteded to be used e.g. in comparison studies where all four graph-based tests need to be calculated at the same time. Since large parts of the calculation coincide, using this function should be faster than computing all four statistics individually.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gTests_cat(X1, X2, dist.fun = function(x, y) sum(x != y), graph.type = "mstree", 
            K = 1, n.perm = 0, maxtype.kappa = 1.14, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gTests_cat_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="gTests_cat_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="gTests_cat_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: Number of unequal components).
</p>
</td></tr>
<tr><td><code id="gTests_cat_+3A_graph.type">graph.type</code></td>
<td>

<p>Character specifying which similarity graph to use. Possible options are <code>"mstree"</code> (default, Minimum Spanning Tree) and <code>"nnlink"</code> (Nearest Neighbor Graph).
</p>
</td></tr>
<tr><td><code id="gTests_cat_+3A_k">K</code></td>
<td>

<p>Parameter for graph (default: 1). If <code>graph.type = "mstree"</code>, a <code>K</code>-MST is constructed (<code>K=1</code> is the classical MST). If <code>graph.type = "nnlink"</code>, <code>K</code> gives the number of neighbors considered in the <code>K</code>-NN graph.
</p>
</td></tr>
<tr><td><code id="gTests_cat_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="gTests_cat_+3A_maxtype.kappa">maxtype.kappa</code></td>
<td>

<p>Parameter <code class="reqn">\kappa</code> of the maxtype test (default: 1.14). See <code><a href="#topic+ZC">ZC</a></code>.
</p>
</td></tr>
<tr><td><code id="gTests_cat_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original, weighted, generalized and maxtype edge-count test are performed.
</p>
<p>For discrete data, the similarity graph used in the test is not necessarily unique. This can be solved by either taking a union (&quot;u&quot;) of all optimal similarity graphs or averaging (&quot;a&quot;) the test statistics over all optimal similarity graphs. For details, see <cite>Zhang and Chen (2022)</cite>. Both options are performed here. 
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed values of the test statistics</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p values</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Friedman, J. H., and Rafsky, L. C. (1979). Multivariate Generalizations of the Wald-Wolfowitz and Smirnov Two-Sample Tests. The Annals of Statistics, 7(4), 697-717. 
</p>
<p>Chen, H. and Friedman, J.H. (2017). A New Graph-Based Two-Sample Test for Multivariate and Object Data. Journal of the American Statistical Association, 112(517), 397-409. <a href="https://doi.org/10.1080/01621459.2016.1147356">doi:10.1080/01621459.2016.1147356</a>
</p>
<p>Chen, H., Chen, X. and Su, Y. (2018). A Weighted Edge-Count Two-Sample Test for Multivariate and Object Data. Journal of the American Statistical Association, 113(523), 1146-1155, <a href="https://doi.org/10.1080/01621459.2017.1307757">doi:10.1080/01621459.2017.1307757</a>
</p>
<p>Zhang, J. and Chen, H. (2022). Graph-Based Two-Sample Tests for Data with Repeated Observations. Statistica Sinica 32, 391-415, <a href="https://doi.org/10.5705/ss.202019.0116">doi:10.5705/ss.202019.0116</a>.
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR_cat">FR_cat</a></code> for the original edge-count test, <code><a href="#topic+CF_cat">CF_cat</a></code> for the generalized edge-count test, <code><a href="#topic+CCS_cat">CCS_cat</a></code> for the weighted edge-count test, and <code><a href="#topic+ZC_cat">ZC_cat</a></code> for the maxtype edge-count test, 
<code><a href="#topic+gTests">gTests</a></code>, <code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+CCS">CCS</a></code>, and <code><a href="#topic+ZC">ZC</a></code> for versions of the test for continuous data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1cat &lt;- matrix(sample(1:4, 300, replace = TRUE), ncol = 3)
X2cat &lt;- matrix(sample(1:4, 300, replace = TRUE, prob = 1:4), ncol = 3)
# Perform edge-count tests
if(requireNamespace("gTests", quietly = TRUE)) {
  gTests_cat(X1cat, X2cat)
}
</code></pre>

<hr>
<h2 id='gTestsMulti'>
Graph-Based Multi-Sample Test
</h2><span id='topic+gTestsMulti'></span>

<h3>Description</h3>

<p>Performs both proposed graph-based multi-sample test for high-dimensional data by <cite>Song and Chen (2022)</cite>. The implementation here uses the <code><a href="gTestsMulti.html#topic+gtestsmulti">gtestsmulti</a></code> implementation from the <span class="pkg">gTestsMulti</span> package. This function is inteded to be used e.g. in comparison studies where both tests need to be calculated at the same time. Since large parts of the calculation coincide, using this function should be faster than computing all four statistics individually.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gTestsMulti(X1, X2, ..., n.perm = 0, dist.fun = stats::dist, graph.fun = MST, 
              dist.args = NULL, graph.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gTestsMulti_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="gTestsMulti_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="gTestsMulti_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="gTestsMulti_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="gTestsMulti_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="gTestsMulti_+3A_graph.fun">graph.fun</code></td>
<td>

<p>Function for calculating a similarity graph using the distance matrix on the pooled sample (default: <code><a href="#topic+MST">MST</a></code>, Minimum Spanning Tree).
</p>
</td></tr>
<tr><td><code id="gTestsMulti_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="gTestsMulti_+3A_graph.args">graph.args</code></td>
<td>

<p>Named list of further arguments passed to <code>graph.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="gTestsMulti_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two multi-sample test statistics are defined by Song and Chen (2022) based on a similarity graph. The first one is defined as 
</p>
<p style="text-align: center;"><code class="reqn">S = S_W + S_B, \text{ where}</code>
</p>

<p style="text-align: center;"><code class="reqn">S_W = (R_W - \text{E}(R_W))^T \Sigma_W^{-1}R_W - \text{E}(R_W)),</code>
</p>

<p style="text-align: center;"><code class="reqn">S_B = (R_B - \text{E}(R_B))^T \Sigma_W^{-1}R_B - \text{E}(R_B)),</code>
</p>

<p>with <code class="reqn">R_W</code> denoting the vector of within-sample edge counts and <code class="reqn">R_B</code> the vector of between-sample edge counts. Expectations and covariance matrix are calculated under the null. 
</p>
<p>The second statistic is defined as 
</p>
<p style="text-align: center;"><code class="reqn">S_A = (R_A - \text{E}(R_A))^T \Sigma_W^{-1}R_A - \text{E}(R_A)), </code>
</p>

<p>where <code class="reqn">R_A</code> is the vector of all linearly independent edge counts, i.e. the edge counts for all pairs of samples except the last pair <code class="reqn">k-1</code> and <code class="reqn">k</code>.
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTestsMulti.html#topic+gtestsmulti">gtestsmulti</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTestsMulti.html#topic+gtestsmulti">gtestsmulti</a></code>.
</p>


<h3>Value</h3>

<p>An list with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Boostrap/ permutation p value (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>Estimated KMD value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Song, H. and Chen, H. (2022). New graph-based multi-sample tests for high-dimensional and non- Euclidean data. arXiv:2205.13787, <a href="https://doi.org/10.48550/arXiv.2205.13787">doi:10.48550/arXiv.2205.13787</a>
</p>
<p>Song, H., Chen, H. (2023). gTestsMulti: New Graph-Based Multi-Sample Tests. R package version 0.1.1, <a href="https://CRAN.R-project.org/package=gTestsMulti">https://CRAN.R-project.org/package=gTestsMulti</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SC">SC</a></code>, <code><a href="#topic+MST">MST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Song and Chen tests
if(requireNamespace("gTestsMulti", quietly = TRUE)) {
  gTestsMulti(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='HamiltonPath'>
Shortest Hamilton path
</h2><span id='topic+HamiltonPath'></span>

<h3>Description</h3>

<p>The function implements a heuristic approach to determine the shortest Hamilton path of a graph based on Kruskal's algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HamiltonPath(X1, X2, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HamiltonPath_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix
</p>
</td></tr>
<tr><td><code id="HamiltonPath_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix
</p>
</td></tr>
<tr><td><code id="HamiltonPath_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses function <code><a href="rlemon.html#topic+IsAcyclic">IsAcyclic</a></code> from package <span class="pkg">rlemon</span> to check if the addition of an edge leads to a cyclic graph.
</p>


<h3>Value</h3>

<p>Returns an edge list containing only the edges needed to construct the Hamilton path
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BMG">BMG</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create data for two datasets
data &lt;- data.frame(x = c(1.5, 2, 4, 5, 4, 6, 5.5, 8), 
                   y = c(6, 4, 5.5, 3, 3.5, 5.5, 7, 6), 
                   dataset = rep(c(1, 2), each = 4))

plot(data$x, data$y, pch = c(21, 19)[data$dataset])

# divide into the two datasets and calculate Hamilton path
X1 &lt;- data[1:4, ]
X2 &lt;- data[5:8, ]

if(requireNamespace("rlemon", quietly = TRUE)) {
  E &lt;- HamiltonPath(X1, X2)
  
  # plot the resulting edges
  segments(x0 = data$x[E[, 1]], y0 = data$y[E[, 1]],
            x1 = data$x[E[, 2]], y1 = data$y[E[, 2]], 
            lwd = 2)
}
</code></pre>

<hr>
<h2 id='HMN'>
Random Forest Based Two-Sample Test
</h2><span id='topic+HMN'></span>

<h3>Description</h3>

<p>Performs the random forest based two-sample test proposed by <cite>Hediger et al. (2022)</cite>. The implementation here uses the <code><a href="hypoRF.html#topic+hypoRF">hypoRF</a></code> implementation from the <span class="pkg">hypoRF</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HMN(X1, X2, n.perm = 0, statistic = "PerClassOOB", normal.approx = FALSE, 
    seed = 42, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HMN_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="HMN_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="HMN_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, binomial test is performed).
</p>
</td></tr>
<tr><td><code id="HMN_+3A_statistic">statistic</code></td>
<td>

<p>Character specifying the test statistic. Possible options are <code>"PerClassOOB"</code> (default) corresponding to the sum of out-of-bag (OOB) per class errors, and <code>"OverallOOB"</code> corresponding to the overall OOB error.
</p>
</td></tr>
<tr><td><code id="HMN_+3A_normal.approx">normal.approx</code></td>
<td>

<p>Should a normal approximation be used in the permutation test procedure? (default: <code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="HMN_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="HMN_+3A_...">...</code></td>
<td>

<p>Arguments passed to <code><a href="ranger.html#topic+ranger">ranger</a></code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the test, a random forest is fitted to the pooled dataset where the target variable is the original dataset membership. The test statistic is either the overall out-of-bag classification accuracy or the sum or mean of the per-class out-of-bag errors for the permutation test. For the asymptotic test (<code>n.perm = 0</code>), the pooled dataset is split into a training and test set and the test statistic is either the overall classification error on the test set or the mean of the per-class classification errors on the test set. In the former case, a binomial test is performed, in the latter case, a Wald test is performed. If the underlying distributions coincide, classification errors close to chance level are expected. The test rejects for small classification errors. 
</p>
<p>Note that the per class OOB statistic differs for the permutation test and approximate test: for the permutation test, the sum of the per class OOB errors is returned, for the asymptotic version, the standardized sum is returned.
</p>
<p>This implementation is a wrapper function around the function <code><a href="hypoRF.html#topic+hypoRF">hypoRF</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see <code><a href="hypoRF.html#topic+hypoRF">hypoRF</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Paremeter(s) of the null distribution</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>val</code></td>
<td>
<p>The OOB statistic values for the permuted data (for <code>n.perm &gt; 0</code>)</p>
</td></tr>
<tr><td><code>varest</code></td>
<td>
<p>The estimated variance of the OOB statistic values for the permuted data (for <code>n.perm &gt; 0</code>)</p>
</td></tr>
<tr><td><code>importance_ranking</code></td>
<td>
<p>Variable importance (for <code>importance = "impurity"</code>)</p>
</td></tr>
<tr><td><code>cutoff</code></td>
<td>
<p>The quantile of the importance distribution at level <code class="reqn">\alpha</code></p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Hediger, S., Michel, L., N√§f, J. (2022). On the use of random forest for two-sample testing. Computational Statistics &amp; Data Analysis, 170, 107435, <a href="https://doi.org/10.1016/j.csda.2022.107435">doi:10.1016/j.csda.2022.107435</a>.
</p>
<p>Simon, H., Michel, L., N√§f, J. (2021). hypoRF: Random Forest Two-Sample Tests. R package version 1.0.0,<a href="https://CRAN.R-project.org/package=hypoRF">https://CRAN.R-project.org/package=hypoRF</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="ranger.html#topic+ranger">ranger</a></code>, <code><a href="#topic+C2ST">C2ST</a></code>, <code><a href="#topic+YMRZL">YMRZL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform random forest based test (low number of permutations due to runtime, 
# should be chosen considerably higher in practice) 
if(requireNamespace("hypoRF", quietly = TRUE)) {
  HMN(X1, X2, n.perm = 10)
}
</code></pre>

<hr>
<h2 id='Jeffreys'>
Jeffreys divergence
</h2><span id='topic+Jeffreys'></span>

<h3>Description</h3>

<p>The function implements Jeffreys divergence by using KL Divergence Approximation (<cite>Sugiyama et al. 2013</cite>). By default, the implementation uses method KLIEP of function <code><a href="densratio.html#topic+densratio">densratio</a></code> from the <span class="pkg">densratio</span> package for density ration estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Jeffreys(X1, X2, method = "KLIEP", verbose = FALSE, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Jeffreys_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame  
</p>
</td></tr>
<tr><td><code id="Jeffreys_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Jeffreys_+3A_method">method</code></td>
<td>

<p>&quot;KLIEP&quot; (default), &quot;uLSIF&quot; or &quot;RuLSIF&quot;
</p>
</td></tr>
<tr><td><code id="Jeffreys_+3A_verbose">verbose</code></td>
<td>

<p>logical (default: FALSE)
</p>
</td></tr>
<tr><td><code id="Jeffreys_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Jeffreys divergence is calculated as the sum of the two KL-divergences
</p>
<p style="text-align: center;"><code class="reqn">\text{KL}(F_1, F_2) = \int \log\left(\frac{f_1}{f_2}\right) \text{d}F_1</code>
</p>

<p>where each dataset is used as the first dataset once. As suggested by <cite>Sugiyama et al. (2013)</cite> the method KLIEP is used for density ratio estimation by default. Low values of Jeffreys Divergence indicate similarity.  
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p value</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Makiyama, K. (2019). densratio: Density Ratio Estimation. R package version 0.2.1, <a href="https://CRAN.R-project.org/package=densratio">https://CRAN.R-project.org/package=densratio</a>.
</p>
<p>Sugiyama, M. and Liu, S. and Plessis, M. and Yamanaka, M. and Yamada, M. and Suzuki, T. and Kanamori, T. (2013). Direct Divergence Approximation between Probability Distributions and Its Applications in Machine Learning. Journal of Computing Science and Engineering. 7. <a href="https://doi.org/10.5626/JCSE.2013.7.2.99">doi:10.5626/JCSE.2013.7.2.99</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="densratio.html#topic+densratio">densratio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Calculate Jeffreys divergence 
if(requireNamespace("densratio", quietly = TRUE)) {
  Jeffreys(X1, X2)
}
</code></pre>

<hr>
<h2 id='kerTests'>
Generalized Permutation-Based Kernel (GPK) Two-Sample Test
</h2><span id='topic+kerTests'></span>

<h3>Description</h3>

<p>Performs the generalized permutation-based kernel two-sample tests proposed by <cite>Song and Chen (2021)</cite>. The implementation here uses the <code><a href="kerTests.html#topic+kertests">kertests</a></code> implementation from the <span class="pkg">kerTests</span> package. This function is inteded to be used e.g. in comparison studies where all four test statistics need to be calculated at the same time. Since large parts of the calculation coincide, using this function should be faster than computing all four statistics individually.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kerTests(X1, X2, n.perm = 0, sigma = findSigma(X1, X2), r1 = 1.2, 
          r2 = 0.8, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kerTests_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="kerTests_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="kerTests_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, fast test is performed). For <code>fast = FALSE</code>, only the permutation test and no asymptotic test is available. For <code>fast = TRUE</code>, either an asymptotic test (set <code>n.perm = 0</code>) and a permutation test (set <code>n.perm</code> &gt; 0) can be performed.
</p>
</td></tr>
<tr><td><code id="kerTests_+3A_sigma">sigma</code></td>
<td>

<p>Bandwidth parameter of the kernel. By default the median heuristic is used to choose <code>sigma</code>.
</p>
</td></tr>
<tr><td><code id="kerTests_+3A_r1">r1</code></td>
<td>

<p>Constant in the test statistic <code class="reqn">Z_{W, r1}</code> for the fast test (default: 1.2, proposed in original article)
</p>
</td></tr>
<tr><td><code id="kerTests_+3A_r2">r2</code></td>
<td>

<p>Constant in the test statistic <code class="reqn">Z_{W, r2}</code> for the fast test (default: 0.8, proposed in original article)
</p>
</td></tr>
<tr><td><code id="kerTests_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GPK test is motivated by the observation that the MMD test performs poorly for detecting differences in variances. The unbiased MMD<code class="reqn">^2</code> estimator for a given kernel function <code class="reqn">k</code> can be written as 
</p>
<p style="text-align: center;"><code class="reqn">\text{MMD}_u^2 = \alpha + \beta - 2\gamma, \text{ where}</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha = \frac{1}{n_1^2 - n_1}\sum_{i=1}^{n_1}\sum_{j=1, j\ne i}^{n_1} k(X_{1i}, X_{1j}),</code>
</p>

<p style="text-align: center;"><code class="reqn">\beta = \frac{1}{n_2^2 - n_2}\sum_{i=1}^{n_2}\sum_{j=1, j\ne i}^{n_2} k(X_{2i}, X_{2j}),</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma = \frac{1}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2} k(X_{1i}, X_{2j}).</code>
</p>

<p>The GPK test statistic is defined as
</p>
<p style="text-align: center;"><code class="reqn">\text{GPK} = (\alpha - \text{E}(\alpha), \beta - \text{E}(\beta))\Sigma^{-1} \binom{\alpha - \text{E}(\alpha)}{\beta - \text{E}(\beta)}</code>
</p>

<p style="text-align: center;"><code class="reqn">= Z_{W,1}^2 + Z_D^2\text{ with}</code>
</p>

<p style="text-align: center;"><code class="reqn">Z_{W,r} = \frac{W_r - \text{E}(W_r)}{\sqrt{\text{Var}(W_r)}}, W_r = r\frac{n_1 \alpha}{n_1 + n_2}, </code>
</p>

<p style="text-align: center;"><code class="reqn">Z_D = \frac{D - \text{E}(D)}{\sqrt{\text{Var}(D)}}, D = n_1(n_1 - 1)\alpha - n_2(n_2 - 1)\beta,</code>
</p>

<p>where the expectations are calculated under the null and <code class="reqn">\Sigma</code> is the covariance matrix of <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> under the null. 
</p>
<p>The asymptotic null distribution for GPK is unknown. Therefore, only a permutation test can be performed.
</p>
<p>For <code class="reqn">r \ne 1</code>, the asymptotic null distribution of <code class="reqn">Z_{W,r}</code> is normal, but for <code class="reqn">r</code> further away from 1, the test performance decreases. Therefore, <code class="reqn">r_1 = 1.2</code> and <code class="reqn">r_2 = 0.8</code> are proposed as a compromise.  
</p>
<p>For the fast GPK test, three (asymptotic or permutation) tests based on <code class="reqn">Z_{W, r1}</code>, <code class="reqn">Z_{W, r2}</code> and <code class="reqn">Z_{D}</code> are concucted and the overall p value is calculated as 3 times the minimum of the three p values. 
</p>
<p>For the fast MMD test, only the two asymptotic tests based on <code class="reqn">Z_{W, r1}</code>, <code class="reqn">Z_{W, r2}</code> are used and the p value is 2 times the minimum of the two p values. This is an approximation of the MMD-permutation test, see <code><a href="#topic+MMD">MMD</a></code>.
</p>
<p>This implementation is a wrapper function around the function <code><a href="kerTests.html#topic+kertests">kertests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="kerTests.html#topic+kertests">kertests</a></code>. 
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed values of the test statistics</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p values</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>Needed for pretty printing of results</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>Needed for pretty printing of results</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>Needed for pretty printing of results</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Song, H. and Chen, H. (2021). Generalized Kernel Two-Sample Tests. arXiv preprint. <a href="https://doi.org/10.1093/biomet/asad068">doi:10.1093/biomet/asad068</a>.
</p>
<p>Song H, Chen H (2023). kerTests: Generalized Kernel Two-Sample Tests. R package version 0.1.4, <a href="https://CRAN.R-project.org/package=kerTests">https://CRAN.R-project.org/package=kerTests</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GPK">GPK</a></code>, <code><a href="#topic+MMD">MMD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform GPK tests
if(requireNamespace("kerTests", quietly = TRUE)) {
  kerTests(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='KMD'>
Kernel Measure of Multi-Sample Dissimilarity (KMD)
</h2><span id='topic+KMD'></span>

<h3>Description</h3>

<p>Calculates the kernel measure of multi-sample dissimilarity (KMD) and performs a permutation multi-sample test (<cite>Huang and Sen, 2023</cite>). The implementation here uses the <code><a href="KMD.html#topic+KMD">KMD</a></code> and <code><a href="KMD.html#topic+KMD_test">KMD_test</a></code> implementations from the <span class="pkg">KMD</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KMD(X1, X2, ..., n.perm = 0, graph = "knn", k = ceiling(N/10), 
    kernel = "discrete", seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KMD_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="KMD_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="KMD_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="KMD_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, no permutation test performed). 
</p>
</td></tr>
<tr><td><code id="KMD_+3A_graph">graph</code></td>
<td>

<p>Graph used in calculation of KMD. Possible options are <code>"knn"</code> (default) and <code>"mst"</code>.
</p>
</td></tr>
<tr><td><code id="KMD_+3A_k">k</code></td>
<td>

<p>Number of neighbors for construction of <code>k</code>-nearest neighbor graph. Ignored for <code>graph = "mst"</code>.
</p>
</td></tr>
<tr><td><code id="KMD_+3A_kernel">kernel</code></td>
<td>

<p>Kernel used in calculation of KMD. Can either be <code>"discrete"</code> (default) for use of the discrete kernel or a kernal matrix with numbers of rows and columns corresponding to the number of datasets. For the latter, the entry in the <code class="reqn">i</code>-th row and <code class="reqn">j</code>-th column corresponds to the kernel value <code class="reqn">k(i,j)</code>.
</p>
</td></tr>
<tr><td><code id="KMD_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the pooled sample <code class="reqn">Z_1, \dots, Z_N</code> and the corresponding sample memberships <code class="reqn">\Delta_1,\dots, \Delta_N</code> let <code class="reqn">\mathcal{G}</code> be a geometric graph on <code class="reqn">\mathcal{X}</code> such that an edge between two points <code class="reqn">Z_i</code> and <code class="reqn">Z_j</code> in the pooled sample implies that <code class="reqn">Z_i</code> and <code class="reqn">Z_j</code> are close, e.g. <code class="reqn">K</code>-nearest neighbor graph with <code class="reqn">K\ge 1</code> or MST. Denote by <code class="reqn">(Z_i,Z_j)\in\mathcal{E}(\mathcal{G})</code> that there is an edge in <code class="reqn">\mathcal{G}</code> connecting <code class="reqn">Z_i</code> and <code class="reqn">Z_j</code>. Moreover, let <code class="reqn">o_i</code> be the out-degree of <code class="reqn">Z_i</code> in <code class="reqn">\mathcal{G}</code>. Then an estimator for the KMD <code class="reqn">\eta</code> is defined as 
</p>
<p style="text-align: center;"><code class="reqn">\hat{\eta} := \frac{\frac{1}{N} \sum_{i=1}^N \frac{1}{o_i} \sum_{j:(Z_i,Z_j)\in\mathcal{E}(\mathcal{G})} K(\Delta_i, \Delta_j) - \frac{1}{N(N-1)} \sum_{i\ne j} K(\Delta_i, \Delta_j)}{\frac{1}{N}\sum_{i=1}^N K(\Delta_i, \Delta_i) - \frac{1}{N(N-1)} \sum_{i\ne j} K(\Delta_i, \Delta_j)}.</code>
</p>

<p>Euclidean distances are used for computing the KNN graph (ties broken at random) and the MST. 
</p>
<p>For <code>n.perm == 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For this, the KMD is standardized by the null mean and standard deviation. For <code>n.perm &gt; 0</code>, a permutation test is performed, i.e. the observed KMD statistic is compared to the permutation KMD statistics. 
</p>
<p>The theoretical KMD of two distributions is zero if and only if the distributions coincide. It is upper bound by one. Therefore, low values of the empirical KMD indicate similarity and the test rejects for high values. 
</p>
<p><cite>Huang and Sen (2023)</cite> recommend using the <code class="reqn">k</code>-NN graph for its flexibility, but the choice of <code class="reqn">k</code> is unclear. Based on the simulation results in the original article, the recommended values are <code class="reqn">k = 0.1 N</code> for testing and <code class="reqn">k = 1</code> for estimation. For increasing power it is beneficial to choose large values of <code class="reqn">k</code>, for consistency of the tests, <code class="reqn">k = o(N / \log(N))</code> together with a continuous distribution of inter-point distances is sufficient, i.e. <code class="reqn">k</code> cannot be chosen too large compared to <code class="reqn">N</code>. On the other hand, in the context of estimating the KMD, choosing <code class="reqn">k</code> is a bias-variance trade-off with small values of <code class="reqn">k</code> decreasing the bias and larger values of <code class="reqn">k</code> decreasing the variance (for more details see discussion in Appendix D.3 of <cite>Huang and Sen (2023)</cite>).
</p>
<p>This implementation is a wrapper function around the functions <code><a href="KMD.html#topic+KMD">KMD</a></code> and <code><a href="KMD.html#topic+KMD_test">KMD_test</a></code> that modifies the in- and output of those functions to match the other functions provided in this package. For more details see <code><a href="KMD.html#topic+KMD">KMD</a></code> and <code><a href="KMD.html#topic+KMD_test">KMD_test</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation / asymptotic p value</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>Estimated KMD value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>graph</code></td>
<td>
<p>Graph used for calculation</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of neighbors used if <code>graph</code> is the KNN graph.</p>
</td></tr>
<tr><td><code>kernel</code></td>
<td>
<p>Kernel used for calculation</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Huang, Z. and Sen, B. (2023). A Kernel Measure of Dissimilarity between <code class="reqn">M</code> Distributions. Journal of the American Statistical Association, 0, 1-27. <a href="https://doi.org/10.1080/01621459.2023.2298036">doi:10.1080/01621459.2023.2298036</a>.
</p>
<p>Huang, Z. (2022). KMD: Kernel Measure of Multi-Sample Dissimilarity. R package version 0.1.0, <a href="https://CRAN.R-project.org/package=KMD">https://CRAN.R-project.org/package=KMD</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MMD">MMD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform KMD test 
if(requireNamespace("KMD", quietly = TRUE)) {
  KMD(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='knn'>
K-Nearest Neighbor Graph
</h2><span id='topic+knn'></span><span id='topic+knn.fast'></span><span id='topic+knn.bf'></span>

<h3>Description</h3>

<p>Calculte the edge matrix of a K-nearest neighbor graph based on a distance matrix, used as helper functions in <code><a href="#topic+SH">SH</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn(dists, K = 1)
knn.fast(dists, K = 1)
knn.bf(dists, K = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="knn_+3A_dists">dists</code></td>
<td>

<p>Distance matrix
</p>
</td></tr>
<tr><td><code id="knn_+3A_k">K</code></td>
<td>

<p>Number of nearest neighbors to consider (default: <code>K = 1</code>)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>knn.bf</code> uses brute force to find the <code>K</code> nearest neighbors but does not require additional packages. 
<code>knn</code> uses the <code><a href="dbscan.html#topic+kNN">kNN</a></code> implementation of the <span class="pkg">dbscan</span> package. 
<code>knn.fast</code> uses the <code><a href="FNN.html#topic+get.knn">get.knn</a></code> implementation of the <span class="pkg">FNN</span> package that uses a kd-tree for fast K-nearest neighbor search. 
</p>


<h3>Value</h3>

<p>The edge matrix of the K-nearest neighbor graph. 
The first column gives the index of the first node of each edge. 
The second column gives the index of the second node of each edge.
Thus, the second entry of each row is one of the K nearest neighbors of the first entry in each row.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SH">SH</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
dists &lt;- stats::dist(rbind(X1, X2))
# Nearest neighbor graph
knn(dists)
knn.fast(dists)
knn.bf(dists)
# 5-Nearest neighbor graph
knn(dists, K = 5)
knn.fast(dists, K = 5)
knn.bf(dists, K = 5)
</code></pre>

<hr>
<h2 id='LHZ'>
Li et al. (2022) empirical characteristic distance
</h2><span id='topic+LHZ'></span>

<h3>Description</h3>

<p>The function implements the <cite>Li et al. (2022)</cite> empirical characteristic distance between two datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LHZ(X1, X2, n.perm = 0, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LHZ_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="LHZ_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="LHZ_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="LHZ_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistic
</p>
<p style="text-align: center;"><code class="reqn">T_{n, m} = \frac{1}{n^2} \sum_{j, q = 1}^n \left( \left\Vert \frac{1}{n} \sum_{k=1}^n e^{i\langle X_k, X_j-X_q \rangle} - \frac{1}{m} \sum_{l=1}^m e^{i\langle Y_l, X_j-X_q\rangle} \right\Vert^2 \right) + \frac{1}{m^2} \sum_{j, q = 1}^m \left( \left\Vert \frac{1}{n} \sum_{k=1}^n e^{i\langle X_k, Y_j-Y_q \rangle} - \frac{1}{m} \sum_{l=1}^m e^{i\langle Y_l, Y_j-Y_q\rangle} \right\Vert^2 \right)
</code>
</p>

<p>is calculated according to <cite>Li et al. (2022)</cite>. The datasets are denoted by <code class="reqn">X</code> and <code class="reqn">Y</code> with respective sample sizes <code class="reqn">n</code> and <code class="reqn">m</code>. By <code class="reqn">X_j</code> the <code class="reqn">i</code>-th row of dataset <code class="reqn">X</code> is denoted. Furthermore, <code class="reqn">\Vert \cdot \Vert</code> indicates the Euclidian norm and <code class="reqn">\langle X_i, X_j \rangle</code> indicates the inner product between <code class="reqn">X_i</code> and <code class="reqn">X_j</code>. 
</p>
<p>Low values of the test statistic indicate similarity. Therefore, the permutation test rejects for large values of the test statistic. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation p value (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Li, X., Hu, W. and Zhang, B. (2022). Measuring and testing homogeneity of distributions by characteristic distance, Statistical Papers 64 (2), 529-556, <a href="https://doi.org/10.1007/s00362-022-01327-7">doi:10.1007/s00362-022-01327-7</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LHZStatistic">LHZStatistic</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Calculate LHZ statistic
LHZ(X1, X2)
</code></pre>

<hr>
<h2 id='LHZStatistic'>
Calculation of the Li et al. (2022) empirical characteristic distance
</h2><span id='topic+LHZStatistic'></span>

<h3>Description</h3>

<p>The function calculates the <cite>Li et al. (2022)</cite> empirical characteristic distance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LHZStatistic(X1, X2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LHZStatistic_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix
</p>
</td></tr>
<tr><td><code id="LHZStatistic_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the calculated value for the empirical characteristic distance
</p>


<h3>References</h3>

<p>Li, X., Hu, W. and Zhang, B. (2022). Measuring and testing homogeneity of distributions by characteristic distance, Statistical Papers 64 (2), 529-556, <a href="https://doi.org/10.1007/s00362-022-01327-7">doi:10.1007/s00362-022-01327-7</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LHZ">LHZ</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Calculate LHZ statistic
LHZStatistic(X1, X2)
</code></pre>

<hr>
<h2 id='MMCM'>
Multisample Mahalanobis Crossmatch (MMCM) Test
</h2><span id='topic+MMCM'></span>

<h3>Description</h3>

<p>Performs the multisample Mahalanobis crossmatch (MMCM) test (<cite>Mukherjee et al., 2022</cite>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MMCM(X1, X2, ..., dist.fun = stats::dist, dist.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MMCM_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="MMCM_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="MMCM_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="MMCM_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="MMCM_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="MMCM_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an extension of the <cite>Rosenbaum (2005)</cite> crossmatch test to multiple samples. Its test statistic is the Mahalanobis distance of the observed cross-counts of all pairs of datasets.
</p>
<p>It aims to improve the power for large dimensions or numbers of groups compared to another extension, the multisample crossmatch (MCM) test (<cite>Petrie, 2016</cite>).
</p>
<p>The observed cross-counts are calculated using the functions <code><a href="nbpMatching.html#topic+distancematrix">distancematrix</a></code> and <code><a href="nbpMatching.html#topic+nonbimatch">nonbimatch</a></code> from the <span class="pkg">nbpMatching</span> package.
</p>
<p>Small values of the test statistic indicate similarity of the datasets, therefore the test rejects the null hypothesis of equal distributions for large values of the test statistic. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>In case of ties in the distance matrix, the optimal non-bipartite matching might not be defined uniquely. 
Here, the observations are matched in the order in which the samples are supplied. 
When searching for a match, the implementation starts at the end of the pooled sample. 
Therefore, with many ties (e.g. for categorical data), observations from the first dataset are often matched with ones from the last dataset and so on.
This might affect the validity of the test negatively.
</p>


<h3>References</h3>

<p>Mukherjee, S., Agarwal, D., Zhang, N. R. and Bhattacharya, B. B. (2022). Distribution-Free Multisample Tests Based on Optimal Matchings With Applications to Single Cell Genomics, Journal of the American Statistical Association, 117(538), 627-638, <a href="https://doi.org/10.1080/01621459.2020.1791131">doi:10.1080/01621459.2020.1791131</a>
</p>
<p>Rosenbaum, P. R. (2005). An Exact Distribution-Free Test Comparing Two Multivariate Distributions Based on Adjacency. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 67(4), 515-530. 
</p>
<p>Petrie, A. (2016). Graph-theoretic multisample tests of equality in distribution for high dimensional data. Computational Statistics &amp; Data Analysis, 96, 145-158, <a href="https://doi.org/10.1016/j.csda.2015.11.003">doi:10.1016/j.csda.2015.11.003</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Petrie">Petrie</a></code>, <code><a href="#topic+Rosenbaum">Rosenbaum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
X3 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform MMCM test 
if(requireNamespace("nbpMatching", quietly = TRUE)) {
   MMCM(X1, X2, X3)
}
</code></pre>

<hr>
<h2 id='MMD'>
Maximum Mean Discrepancy (MMD) Test
</h2><span id='topic+MMD'></span>

<h3>Description</h3>

<p>Performs a two-sample test based on the maximum mean discrepancy (MMD) using either, the Rademacher or the asmyptotic bounds or a permutation testing procedure. The implementation adds a permutation test to the <code><a href="kernlab.html#topic+kmmd">kmmd</a></code> implementation from the <span class="pkg">kernlab</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MMD(X1, X2, n.perm = 0, alpha = 0.05, asymptotic = FALSE, replace = TRUE, 
    n.times = 150, frac = 1, seed = 42, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MMD_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="MMD_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="MMD_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="MMD_+3A_alpha">alpha</code></td>
<td>

<p>Significance level of the test (default: 0.05). Used to calculate asymptotic or Rademacher bound.
</p>
</td></tr>
<tr><td><code id="MMD_+3A_asymptotic">asymptotic</code></td>
<td>

<p>Should the asymptotic bound be calculated? (default: <code>FALSE</code>, Rademacher bound is used, <code>TRUE</code> calculation of asymptotic bounds is suitable for smaller datasets)
</p>
</td></tr>
<tr><td><code id="MMD_+3A_replace">replace</code></td>
<td>

<p>Should sampling with replacement be used in computation of asymptotic bounds? (default: <code>TRUE</code>)
</p>
</td></tr>
<tr><td><code id="MMD_+3A_n.times">n.times</code></td>
<td>

<p>Number of repetitions for sampling procedure (default: 150)
</p>
</td></tr>
<tr><td><code id="MMD_+3A_frac">frac</code></td>
<td>

<p>Fraction of points to sample (default: 1)
</p>
</td></tr>
<tr><td><code id="MMD_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="MMD_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code><a href="kernlab.html#topic+kmmd">kmmd</a></code> specifying the kernel. E.g. <code>kernel</code> for passing the kernel as a character (default: <code>rbfdot</code> RBF kernel function) and <code>kpar</code> for passing the kernel parameter(s) as a named list (default: <code>"automatic"</code> uses heuristic for choosing a good bandwidth for the RBF or Laplace kernel). For details, see <code><a href="kernlab.html#topic+kmmd">kmmd</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a given kernel function <code class="reqn">k</code> an unbiased estimator for MMD<code class="reqn">^2</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\widehat{\text{MMD}}^2(\mathcal{H}, X_1, X_2)_{U} =  \frac{1}{n_1(n_1-1)}\sum_{i=1}^{n_1}\sum_{\substack{j=1 \\ j\neq i}}^{n_1} k\left(X_{1i}, X_{1j}\right) \\ 
     + \frac{1}{n_2(n_2-1)}\sum_{i=1}^{n_2}\sum_{\substack{j=1 \\ j\neq i}}^{n_2} k\left(X_{2i}, X_{2j}\right)\\
	 - \frac{2}{n_1 n_2}\sum_{i=1}^{n_1}\sum_{\substack{j = 1 \\ j\neq i}}^{n_2} k\left(X_{1i}, X_{2j}\right).</code>
</p>

<p>Its square root is returned as the statistic here. 
</p>
<p>The theoretical MMD of two distributions is equal to zero if and only if the two distributions coincide. Therefore, low values indicate similarity of datasets and the test rejects for large values. 
</p>
<p>The orignal proposal of the test is based on critical values calculated asymptotically or using Rademacher bounds. Here, the option for calculating a permutation p value is added. The Rademacher bound is always returned. Additionally, the asymptotic bound can be returned depending on the value of <code>asymptotic</code>. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="kernlab.html#topic+kmmd">kmmd</a></code> that modifies the in- and output of that function to match the other functions provided in this package. Moreover, a permutation test is added. For more details see the <code><a href="kernlab.html#topic+kmmd">kmmd</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation p value</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>H0</code></td>
<td>
<p>Is <code class="reqn">H_0</code> rejected according to the Rademacher bound?</p>
</td></tr>
<tr><td><code>asymp.H0</code></td>
<td>
<p>Is <code class="reqn">H_0</code> rejected according to the asymptotic bound?</p>
</td></tr>
<tr><td><code>kernel.fun</code></td>
<td>
<p>Kernel function used</p>
</td></tr>
<tr><td><code>Rademacher.bound</code></td>
<td>
<p>The Rademacher bound</p>
</td></tr>
<tr><td><code>asymp.bound</code></td>
<td>
<p>The asymptotic bound</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> When suitable kernel function is passed </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Gretton, A., Borgwardt, K., Rasch, M., Sch√∂lkopf, B. and Smola, A. (2006). A Kernel Method for the Two-Sample-Problem. Neural Information Processing Systems 2006, Vancouver. <a href="https://papers.neurips.cc/paper/3110-a-kernel-method-for-the-two-sample-problem.pdf">https://papers.neurips.cc/paper/3110-a-kernel-method-for-the-two-sample-problem.pdf</a>
</p>
<p>Muandet, K., Fukumizu, K., Sriperumbudur, B. and Sch√∂lkopf, B. (2017). Kernel Mean Embedding of Distributions: A Review and Beyond. Foundations and Trends¬Æ in Machine Learning, 10(1-2), 1-141. <a href="https://doi.org/10.1561/2200000060">doi:10.1561/2200000060</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform MMD test 
if(requireNamespace("kernlab", quietly = TRUE)) {
  MMD(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='MST'>
Minimum Spanning Tree (MST)
</h2><span id='topic+MST'></span>

<h3>Description</h3>

<p>Calculte the edge matrix of a minimum spanning tree based on a distance matrix, used as helper functions in <code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+FR">FR</a></code>, and <code><a href="#topic+ZC">ZC</a></code>. 
This function is a wrapper around <code><a href="ade4.html#topic+mstree">mstree</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MST(dists, K = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MST_+3A_dists">dists</code></td>
<td>

<p>Distance matrix as <code>dist</code> object.
</p>
</td></tr>
<tr><td><code id="MST_+3A_k">K</code></td>
<td>

<p>Component number (default: <code>K = 1</code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see <code><a href="ade4.html#topic+mstree">mstree</a></code>.
</p>


<h3>Value</h3>

<p>Object of class <code>neig</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+ZC">ZC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
dists &lt;- stats::dist(rbind(X1, X2))
if(requireNamespace("ade4", quietly = TRUE)) {
  # MST
  MST(dists)
  # 5-MST
  MST(dists, K = 5) 
}
</code></pre>

<hr>
<h2 id='MW'>
Nonparametric Graph-Based LP (GLP) Test
</h2><span id='topic+MW'></span>

<h3>Description</h3>

<p>Performs the nonparametric graph-based LP (GLP) multisample test proposed by <cite>Mokhopadhyay and Wang (2020)</cite>. The implementation here uses the <code><a href="LPKsample.html#topic+GLP">GLP</a></code> implementation from the <span class="pkg">LPKsample</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MW(X1, X2, ..., sum.all = FALSE, m.max = 4, components = NULL, alpha = 0.05, 
    c.poly = 0.5, clust.alg = "kmeans", n.perm = 0, combine.criterion = "kernel", 
    multiple.comparison = TRUE, compress.algorithm = FALSE, nbasis = 8, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MW_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="MW_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="MW_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="MW_+3A_sum.all">sum.all</code></td>
<td>

<p>Should all components be summed up for calculating the test statistic? (default: <code>FALSE</code>, only significant components are summed up)
</p>
</td></tr>
<tr><td><code id="MW_+3A_m.max">m.max</code></td>
<td>

<p>Maximum order of LP components to investigate (default: 4)
</p>
</td></tr>
<tr><td><code id="MW_+3A_components">components</code></td>
<td>

<p>Vector specifying which components to test. If <code>components</code> is not <code>NULL</code> (default), only the specified components are examined and <code>m.max</code> is ignored.
</p>
</td></tr>
<tr><td><code id="MW_+3A_alpha">alpha</code></td>
<td>

<p>Significance level <code class="reqn">\alpha</code> (default: 0.05)
</p>
</td></tr>
<tr><td><code id="MW_+3A_c.poly">c.poly</code></td>
<td>

<p>Parameter for polynomial kernel (default: 0.5)
</p>
</td></tr>
<tr><td><code id="MW_+3A_clust.alg">clust.alg</code></td>
<td>

<p>Character specifying the cluster algorithm used in graph community detection. possible options are <code>"kmeans"</code> (default) and <code>"mclust"</code>.
</p>
</td></tr>
<tr><td><code id="MW_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="MW_+3A_combine.criterion">combine.criterion</code></td>
<td>

<p>Character specifying how to obtain the overall test result based on the component-wise results. Possible options are <code>"kernel"</code> meaning that an overall kernel <code class="reqn">W</code> is computed based on the significant components and the LP graph test is run on <code class="reqn">W</code>, and <code>"pvalue"</code> which uses Fisher's method to combine the p values from each component.
</p>
</td></tr>
<tr><td><code id="MW_+3A_multiple.comparison">multiple.comparison</code></td>
<td>

<p>Should an adjustment for multiple comparisons be used when determining which components are significant? (default: <code>TRUE</code>)
</p>
</td></tr>
<tr><td><code id="MW_+3A_compress.algorithm">compress.algorithm</code></td>
<td>

<p>Should smooth compression of Laplacian spectra be used for testing? (default: <code>FALSE</code>). It is recommended to set this to <code>TRUE</code> for large sample sizes.
</p>
</td></tr>
<tr><td><code id="MW_+3A_nbasis">nbasis</code></td>
<td>

<p>Number of bases used for approximation when <code>compress.algorithm = TRUE</code> (default: 8)
</p>
</td></tr>
<tr><td><code id="MW_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GLP statistic is based on learning an LP graph kernel using a pre-specified number of LP components and performing clustering on the eigenvectors of the Laplacian matrix for this learned kernel. The cluster assignment is tested for association with the true dataset memberships for each component of the LP graph kernel. The results are combined by either constructing a super-kernel using specific components and performing the cluster and test step again or by using the combination of the significant components after adjustment for multiple testing. 
</p>
<p>Small values of the GLP statistic indicate dataset similarity. Therefore, the test rejects for large values. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the GLP test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation overall p value</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>Needed for pretty printing of results</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>Needed for pretty printing of results</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>When <code>sum.all = FALSE</code> and no components are significant, the test statistic value is always set to zero. 
</p>
<p>Note that the implementation cannot handle univariate data.
</p>


<h3>References</h3>

<p>Mukhopadhyay, S. and Wang, K. (2020). A nonparametric approach to high-dimensional k-sample comparison problems, Biometrika, 107(3), 555-572, <a href="https://doi.org/10.1093/biomet/asaa015">doi:10.1093/biomet/asaa015</a>
</p>
<p>Mukhopadhyay, S. and Wang, K. (2019). Towards a unified statistical theory of spectralgraph analysis, <a href="https://doi.org/10.48550/arXiv.1901.07090">doi:10.48550/arXiv.1901.07090</a>
</p>
<p>Mukhopadhyay, S., Wang, K. (2020). LPKsample: LP Nonparametric High Dimensional K-Sample Comparison. R package version 2.1, <a href="https://CRAN.R-project.org/package=LPKsample">https://CRAN.R-project.org/package=LPKsample</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform GLP test 
if(requireNamespace("LPKsample", quietly = TRUE)) {
  MW(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='NKT'>
Decision-Tree Based Measure of Dataset Similarity (<cite>Ntoutsi et al., 2008</cite>)
</h2><span id='topic+NKT'></span>

<h3>Description</h3>

<p>Calculates Decision-Tree Based Measure of Dataset Similarity by <cite>Ntoutsi et al. (2008)</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NKT(X1, X2, target1 = "y", target2 = "y", method = 1, tune = TRUE, k = 5, 
      n.eval = 100, seed = 42, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NKT_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="NKT_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="NKT_+3A_target1">target1</code></td>
<td>

<p>Character specifying the column name of the class variable in the first dataset (default: <code>"y"</code>)
</p>
</td></tr>
<tr><td><code id="NKT_+3A_target2">target2</code></td>
<td>

<p>Character specifying the column name of the class variable in the second dataset (default: <code>"y"</code>)
</p>
</td></tr>
<tr><td><code id="NKT_+3A_method">method</code></td>
<td>

<p>Number in <code>1:3</code> specifying the method for calculating dataset similarity (default:1). See details.
</p>
</td></tr>
<tr><td><code id="NKT_+3A_tune">tune</code></td>
<td>

<p>Should the decision tree parameters be tuned? (default: <code>TRUE</code>)
</p>
</td></tr>
<tr><td><code id="NKT_+3A_k">k</code></td>
<td>

<p>Number of folds used in cross-validation for parameter tuning (default: 5). Ignored if <code>tune = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="NKT_+3A_n.eval">n.eval</code></td>
<td>

<p>Number of evaluations for random search used for parameter tuning (default: 100). Ignored if <code>tune = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="NKT_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="NKT_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code><a href="rpart.html#topic+rpart">rpart</a></code>. Ignored if <code>tune = TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><cite>Ntoutsi et al. (2008)</cite> define three measures of datset similarity based on the intersection of the partitions of the sample space defined by the two decision trees fit to each dataset. Denote by <code class="reqn">\hat{P}_X(\mathcal{X})</code> the proportion of observations in a dataset that fall into each segment of the joint partition and by <code class="reqn">P_X(Y,\mathcal{X})</code> the proportion of observations in a dataset that fall into each segment of the joint partition and belong to each class. </p>
<p style="text-align: center;"><code class="reqn">s(p, q) = \sum_{i} \sqrt{p_i \cdot q_i}</code>
</p>
<p> defines the similarity index for two vectors <code class="reqn">p</code> and <code class="reqn">q</code>. Then the measures of similarity are defined by
</p>
<p style="text-align: center;"><code class="reqn">\text{NTO1} = s(\hat{P}_{X_1}(\mathcal{X}), \hat{P}_{X_2}(\mathcal{X})),</code>
</p>

<p style="text-align: center;"><code class="reqn">\text{NTO2} = s(\hat{P}_{X_1}(Y, \mathcal{X}), \hat{P}_{X_2}(Y, \mathcal{X})),</code>
</p>

<p style="text-align: center;"><code class="reqn">\text{NTO3} = S(Y|\mathcal{X})^{T} \hat{P}_{X_1 \cup X_2}(\mathcal{X}),</code>
</p>

<p>where <code class="reqn">S(Y|\mathcal{X})</code> is the similarity vector with elements 
</p>
<p style="text-align: center;"><code class="reqn">S(Y|\mathcal{X})_i = s(\hat{P}_{X_1}(Y|\mathcal{X})_{i \bullet}, \hat{P}_{X_2}(Y|\mathcal{X})_{i \bullet})</code>
</p>
<p> and index <code class="reqn">i \bullet</code> denotes the <code class="reqn">i</code>-th row.
</p>
<p>The implementation uses <code><a href="rpart.html#topic+rpart">rpart</a></code> for fitting classification trees to each dataset. 
</p>
<p><code><a href="e1071.html#topic+best.rpart">best.rpart</a></code> is used for hyperparameter tuning if <code>tune = TRUE</code>. The parameters are tuned using cross-validation and random search. The parameter <code>minsplit</code> is tuned over <code>2^(1:7)</code>, <code>minbucket</code> is tuned over <code>2^(0:6)</code> and <code>cp</code> is tuned over <code>10^seq(-4, -1, by = 0.001)</code>. 
</p>
<p>High values of each measure indicate similarity of the datasets. The measures are bounded between 0 and 1. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>NA (no p value calculated)</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Ntoutsi, I., Kalousis, A. and Theodoridis, Y. (2008). A general framework for estimating similarity of datasets and decision trees: exploring semantic similarity of decision trees. Proceedings of the 2008 SIAM International Conference on Data Mining, 810-821. <a href="https://doi.org/10.1137/1.9781611972788.7">doi:10.1137/1.9781611972788.7</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GGRL">GGRL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
y1 &lt;- rbinom(100, 1, 1 / (1 + exp(1 - X1 %*% rep(0.5, 10))))
y2 &lt;- rbinom(100, 1, 1 / (1 + exp(1 - X2 %*% rep(0.7, 10))))
X1 &lt;- data.frame(X = X1, y = y1)
X2 &lt;- data.frame(X = X2, y = y2)
if(requireNamespace("rpart", quietly = TRUE)) {
  # Calculate all three similarity measures (without tuning the trees due to runtime)
  NKT(X1, X2, "y", method = 1, tune = FALSE)
  NKT(X1, X2, "y", method = 2, tune = FALSE)
  NKT(X1, X2, "y", method = 3, tune = FALSE)
}
</code></pre>

<hr>
<h2 id='OTDD'>
Optimal Transport Dataset Distance
</h2><span id='topic+OTDD'></span><span id='topic+hammingDist'></span>

<h3>Description</h3>

<p>The function implements the optimal transport dataset distance (<cite>Alvarez-Melis and Fusi, 2020</cite>). The distance combines the distance between features and the distance between label distributions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OTDD(X1, X2, target1 = "y", target2 = "y", method = "precomputed.labeldist", 
      feature.cost = stats::dist, lambda.x = 1, lambda.y = 1, p = 2, ground.p = 2,
      sinkhorn = FALSE, debias = FALSE, inner.ot.method = "exact", inner.ot.p = 2, 
      inner.ot.ground.p = 2, inner.ot.sinkhorn = FALSE, inner.ot.debias = FALSE,
      seed = 42)
hammingDist(x) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="OTDD_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_target1">target1</code></td>
<td>

<p>Character specifying the column name of the class variable in the first dataset (default: <code>"y"</code>)
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_target2">target2</code></td>
<td>

<p>Character specifying the column name of the class variable in the second dataset (default: <code>"y"</code>)
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_method">method</code></td>
<td>

<p>Character specifying the method for computing the OTDD. Possible options are <code>"augmentation"</code>, i.e. computing the optimal transport on the augmented dataset, and <code>"precomputed.labeldist"</code>, i.e. the usual computation of label distances (default).
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_feature.cost">feature.cost</code></td>
<td>

<p>Function that calculates the distance matrix on the pooled feature dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>). Ignored if <code>method = precomputed.labeldist</code>, then <code class="reqn">L_p</code>-distance is used as feature cost. 
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_lambda.x">lambda.x</code>, <code id="OTDD_+3A_lambda.y">lambda.y</code></td>
<td>

<p>Weights of the feature distances and label distances in the overall cost (default: 1, equally weighted). Note that values unequal to one are only supported for <code>method = precomputed.labeldist</code>.
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_p">p</code></td>
<td>

<p>Power <code class="reqn">p</code> of the <code class="reqn">p</code>-Wasserstein distance for the outer optimal transport problem (default: 2).
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_ground.p">ground.p</code></td>
<td>

<p>Power <code class="reqn">p</code> of the <code class="reqn">L_p</code>-norm used in calculation of Wasserstein distance for the outer optimal transport problem (default: 2). Ignored if <code>method = "precomputed.labeldist"</code>.
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_sinkhorn">sinkhorn</code></td>
<td>

<p>Should the Sinkhorn approximation be used for solving the outer optimal transport problem? (default: <code>FALSE</code>, exact solution is used)
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_debias">debias</code></td>
<td>

<p>Should debiased estimator be used when using Sinkhorn approximation for outer optimal transport problem? (default: <code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_inner.ot.method">inner.ot.method</code></td>
<td>

<p>Method for computing the label distances. Possible options are <code>"exact"</code> (the default), i.e. calculating the solution to the optimal transport of the label distributions, <code>"gaussian.approx"</code>, i.e. calculating the Wasserstein distance of the labels using a Gaussian approximation of the label distributions, <code>"naive.upperbound"</code>, i.e. calculating the upperbound <code class="reqn">d_{UB}</code>, <code>"only.means"</code>, i.e. approximating the label distance by computing the Euclidean distance of the mean vectors of the label distributions. Ignored if <code>method = "augmentation"</code>.
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_inner.ot.p">inner.ot.p</code></td>
<td>

<p>Power <code class="reqn">p</code> of the <code class="reqn">p</code>-Wasserstein distance for the inner optimal transport problem (default: 2). Used only if <code>method = "precomputed.labeldist"</code> and <code>inner.ot.method = "exact"</code>.
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_inner.ot.ground.p">inner.ot.ground.p</code></td>
<td>

<p>Power <code class="reqn">p</code> of the <code class="reqn">L_p</code>-norm used in calculation of Wasserstein distance for the outer optimal transport problem (default: 2). Used only if <code>method = "precomputed.labeldist"</code> and <code>inner.ot.method = "exact"</code>.
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_inner.ot.sinkhorn">inner.ot.sinkhorn</code></td>
<td>

<p>Should the Sinkhorn approximation be used for solving the inner optimal transport problem? (default: <code>FALSE</code>, exact solution is used). Used only if <code>method = "precomputed.labeldist"</code> and <code>inner.ot.method = "exact"</code>.
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_inner.ot.debias">inner.ot.debias</code></td>
<td>

<p>Should debiased estimator be used when using Sinkhorn approximation for inner optimal transport problem? (default: <code>FALSE</code>). Used only if <code>method = "precomputed.labeldist"</code> and <code>inner.ot.method = "exact"</code>.
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="OTDD_+3A_x">x</code></td>
<td>

<p>Dataset for which the distance matrix of pairwise Hamming distances is calculated.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><cite>Alvarez-Melis and Fusi (2020)</cite> define a dataset distance that takes into account both the feature variables as well as a target (label) variable. The idea is to compute the optimal transport based on a cost function that is a combination of the feature distance and the Wasserstein distance between the label distributions. The label distribution refers to the distribution of features for a given label. With this, the distance between feature-label pairs <code class="reqn">z:= (x, y)</code> can be defined as 
</p>
<p style="text-align: center;"><code class="reqn">
d_{\mathcal{Z}}(z, z^\prime) := (d_{\mathcal{X}}(x, x^{\prime})^p + W_p^p(\alpha_y, \alpha_{y^{\prime}}))^{1/p},
</code>
</p>

<p>where <code class="reqn">\alpha_y</code> denotes the distribution <code class="reqn">\text{P}(X|Y=y)</code> for label <code class="reqn">y</code> over the feature space. With this, the optimal transport dataset distance is defined as 
</p>
<p style="text-align: center;"><code class="reqn">
d_{OT}(\mathcal{D}_1, \mathcal{D}_2) = \min_{\pi\in\Pi(\alpha, \beta)} \int_{\mathcal{Z}\times\mathcal{Z}} d_{\mathcal{Z}}(z, z^\prime)^p \text{d }\pi(z, z^\prime), 
</code>
</p>

<p>where 
</p>
<p style="text-align: center;"><code class="reqn">
\Pi(\alpha, \beta) := \{\pi_{1,2}\in\mathcal{P}(\mathcal{X}\times\mathcal{X}) | \pi_1 = \alpha, \pi_2 = \beta\}
</code>
</p>

<p>is the set of joint distributions with <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> as marginals. 
</p>
<p>Here, we use the Wasserstein distance implementation from the <span class="pkg">approxOT</span> package for solving the optimal transport problems. 
</p>
<p>There are multiple simplifications implemented. First, under the assumption that the metric on the feature space coincides with the ground metric in the optimal transport problem on the labels and that all covariance matrices of the label distributions commute (rarely fulfilled in practice), the computation reduces to solving the optimal transport problem on the datasets augmented with the means and covariance matrices of the label distributions. This simplification is used when setting <code>method = "augmentation"</code>. Next, the Sinkhorn approximation can be utilized both for calculating the solution of the overall (outer) optimal transport problem (<code>sinkhorn = TRUE</code>) and for the inner optimal transport problem for computing the label distances (<code>inner.ot.sinkhorn = TRUE</code>). The solution of the inner problem can also be sped up by using a normal approximation of the label distributions (<code>inner.ot.method = "gaussian.approx"</code>) which results in a closed form expression of the solution. <code>inner.ot.method = "only.means"</code> further simplifies the calculation by using only the means of these Gaussians, which corresponds to assuming equal covariances in all Gaussian approximations of the label distributions. Using <code>inner.ot.method = "upper.bound"</code> uses a distribution-agnostic upper bound to bypass the solution of the inner optimal transport problem. 
</p>
<p>For categorical data, specify an appropriate <code>feature.cost</code> and use <code>method = "precomputed.labeldist"</code> and <code>inner.ot.method = "exact"</code>. A pre-implemented option is setting <code>feature.cost = hammingDist</code> for using the Hamming distance for categorical data. When implementing an appropriate function that takes the pooled dataset without the target column as input and gives a distance matrix as the output, a mix of categorical and numerical data is also possible.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>Especially for large numbers of variables and low numbers of observations, it can happen that the Gaussian approximation of the inner OT problem fails since the estimated covariance matrix for one label distribution is numerically no longer psd. An error is thrown in that case. 
</p>


<h3>Author(s)</h3>

<p>Original python implementation: David Alvarez-Melis, Chengrun Yang
</p>
<p>R implementation: Marieke Stolte
</p>


<h3>References</h3>

<p>Interactive visualizations: <a href="https://www.microsoft.com/en-us/research/blog/measuring-dataset-similarity-using-optimal-transport/">https://www.microsoft.com/en-us/research/blog/measuring-dataset-similarity-using-optimal-transport/</a>
</p>
<p>Alvarez-Melis, D. and Fusi, N. (2020). Geometric Dataset Distances via Optimal Transport. In Advances in Neural Information Processing Systems 33 21428-21439. 
</p>
<p>Original python implementation: Alvarez-Melis, D., and Yang, C. (2024). Optimal Transport Dataset Distance (OTDD). <a href="https://github.com/microsoft/otdd">https://github.com/microsoft/otdd</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
y1 &lt;- rbinom(100, 1, 1 / (1 + exp(1 - X1 %*% rep(0.5, 10))))
y2 &lt;- rbinom(100, 1, 1 / (1 + exp(1 - X2 %*% rep(0.7, 10))))
X1 &lt;- data.frame(X = X1, y = y1)
X2 &lt;- data.frame(X = X2, y = y2)
# Calculate OTDD

if(requireNamespace("approxOT", quietly = TRUE) &amp; 
    requireNamespace("expm", quietly = TRUE)) {
  OTDD(X1, X2)
  OTDD(X1, X2, sinkhorn = TRUE, inner.ot.sinkhorn = TRUE)
  OTDD(X1, X2, method = "augmentation") 
  OTDD(X1, X2, inner.ot.method = "gaussian.approx")
  OTDD(X1, X2, inner.ot.method = "means.only")
  OTDD(X1, X2, inner.ot.method = "naive.upperbound")
}


# For categorical data
X1cat &lt;- matrix(sample(LETTERS[1:4], 300, replace = TRUE), ncol = 3)
X2cat &lt;- matrix(sample(LETTERS[1:4], 300, replace = TRUE, prob = 1:4), ncol = 3)
y1 &lt;- sample(0:1, 300, TRUE)
y2 &lt;- sample(0:1, 300, TRUE)
X1 &lt;- data.frame(X = X1cat, y = y1)
X2 &lt;- data.frame(X = X2cat, y = y2)

if(requireNamespace("approxOT", quietly = TRUE) &amp;
    requireNamespace("expm", quietly = TRUE)) {
  OTDD(X1, X2, feature.cost = hammingDist)
  OTDD(X1, X2, sinkhorn = TRUE, inner.ot.sinkhorn = TRUE, feature.cost = hammingDist)
}

</code></pre>

<hr>
<h2 id='Petrie'>
Multisample Crossmatch (MCM) Test
</h2><span id='topic+Petrie'></span>

<h3>Description</h3>

<p>Performs the multisample crossmatch (MCM) test (<cite>Petrie, 2016</cite>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Petrie(X1, X2, ..., dist.fun = stats::dist, dist.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Petrie_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Petrie_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Petrie_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="Petrie_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="Petrie_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="Petrie_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an extension of the <cite>Rosenbaum (2005)</cite> crossmatch test to multiple samples that uses the crossmatch count of all pairs of samples. 
</p>
<p>The observed cross-counts are calculated using the functions <code><a href="nbpMatching.html#topic+distancematrix">distancematrix</a></code> and <code><a href="nbpMatching.html#topic+nonbimatch">nonbimatch</a></code> from the <span class="pkg">nbpMatching</span> package.
</p>
<p>High values of the multisample crossmatch statistic indicate similarity between the datasets. Thus, the test rejects the null hypothesis of equal distributions for low values of the test statistic. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>Observed multisample edge-count</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>stderr</code></td>
<td>
<p>Standard deviation under the null</p>
</td></tr>
<tr><td><code>mu0</code></td>
<td>
<p>Expectation under the null</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>In case of ties in the distance matrix, the optimal non-bipartite matching might not be defined uniquely. 
Here, the observations are matched in the order in which the samples are supplied. 
When searching for a match, the implementation starts at the end of the pooled sample. 
Therefore, with many ties (e.g. for categorical data), observations from the first dataset are often matched with ones from the last dataset and so on.
This might affect the validity of the test negatively.
</p>


<h3>References</h3>

<p>Mukherjee, S., Agarwal, D., Zhang, N. R. and Bhattacharya, B. B. (2022). Distribution-Free Multisample Tests Based on Optimal Matchings With Applications to Single Cell Genomics, Journal of the American Statistical Association, 117(538), 627-638, <a href="https://doi.org/10.1080/01621459.2020.1791131">doi:10.1080/01621459.2020.1791131</a>
</p>
<p>Rosenbaum, P. R. (2005). An Exact Distribution-Free Test Comparing Two Multivariate Distributions Based on Adjacency. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 67(4), 515-530. 
</p>
<p>Petrie, A. (2016). Graph-theoretic multisample tests of equality in distribution for high dimensional data. Computational Statistics &amp; Data Analysis, 96, 145-158, <a href="https://doi.org/10.1016/j.csda.2015.11.003">doi:10.1016/j.csda.2015.11.003</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MMCM">MMCM</a></code>, <code><a href="#topic+Rosenbaum">Rosenbaum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform MCM test 
if(requireNamespace("nbpMatching", quietly = TRUE)) {
   Petrie(X1, X2)
}
</code></pre>

<hr>
<h2 id='rectPartition'>
Calculate a rectangular partition
</h2><span id='topic+rectPartition'></span>

<h3>Description</h3>

<p>The function calculates a rectangular partition of the subspace spanned by the data. Used for <code><a href="#topic+BG">BG</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rectPartition(X1, X2, n, p, exponent = 0.8, eps = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rectPartition_+3A_x1">X1</code></td>
<td>

<p>First data set as matrix 
</p>
</td></tr>
<tr><td><code id="rectPartition_+3A_x2">X2</code></td>
<td>

<p>Second data set as matrix
</p>
</td></tr>
<tr><td><code id="rectPartition_+3A_n">n</code></td>
<td>

<p>Number of rows in the data
</p>
</td></tr>
<tr><td><code id="rectPartition_+3A_p">p</code></td>
<td>

<p>Number of columns in the data
</p>
</td></tr>
<tr><td><code id="rectPartition_+3A_exponent">exponent</code></td>
<td>

<p>Exponent to ensure covergence criteria, should be between 0 and 1 (default: 0.8)
</p>
</td></tr>
<tr><td><code id="rectPartition_+3A_eps">eps</code></td>
<td>

<p>Small threshold to guarantee edge points are included (default: 0.01)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p>A list of <code>p</code> elements containing the partition cutpoints for every dimension</p>
</td></tr>
<tr><td><code>m_n</code></td>
<td>
<p>Total number of elements in the partition</p>
</td></tr>
<tr><td><code>m_n_d</code></td>
<td>
<p>Number of partition elements per dimension</p>
</td></tr>
</table>


<h3>References</h3>

<p>Biau G. and Gyorfi, L. (2005). On the asymptotic properties of a nonparametric <code class="reqn">L_1</code>-test statistic of homogeneity, IEEE Transactions on Information Theory, 51(11), 3965-3973. <a href="https://doi.org/10.1109/TIT.2005.856979">doi:10.1109/TIT.2005.856979</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BG">BG</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 5)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 5)
# Calculate partition
rectPartition(X1, X2, n = nrow(X1), p = ncol(X1))
</code></pre>

<hr>
<h2 id='RItest'>
Multisample RI Test
</h2><span id='topic+RItest'></span>

<h3>Description</h3>

<p>Performs the (modified/ multiscale/ aggregated) RI test (<cite>Paul et al., 2021</cite>). The implementation is based on the <code><a href="HDLSSkST.html#topic+RItest">RItest</a></code>, <code><a href="HDLSSkST.html#topic+MTRItest">MTRItest</a></code>, and <code><a href="HDLSSkST.html#topic+ARItest">ARItest</a></code> implementations from the <span class="pkg">HDLSSkST</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RItest(X1, X2, ..., n.clust, randomization = TRUE, version = "original", 
        mult.test = "Holm", kmax = 2 * n.clust, s.psi = 1, s.h = 1, 
        lb = 1, n.perm = 1/alpha, alpha = 0.05, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RItest_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="RItest_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="RItest_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="RItest_+3A_n.clust">n.clust</code></td>
<td>

<p>Number of clusters (only applicable for <code>version = "original"</code>).
</p>
</td></tr>
<tr><td><code id="RItest_+3A_randomization">randomization</code></td>
<td>

<p>Should a randomized test be performed? (default: <code>TRUE</code>, ranomized test is performed)
</p>
</td></tr>
<tr><td><code id="RItest_+3A_version">version</code></td>
<td>

<p>Which version of the test should be performed? Possible options are <code>"original"</code> (default) for the FS test, <code>"modified"</code> for the MFS test (number of clusters is estimated), <code>"multiscale"</code> for the MSFS test (all numbers of clusters up to <code>kmax</code> are tried and results are summarized), <code>"aggregated-knw"</code> (all pairwise comparisons are tested with the FS test and results are aggregated), and <code>"aggregated-est"</code> (all pairwise comparisons are tested with the MFS test and results are aggregated).
</p>
</td></tr>
<tr><td><code id="RItest_+3A_mult.test">mult.test</code></td>
<td>

<p>Multiple testing adjustment for AFS test and MSFS test. Possible options are <code>"Holm"</code> (default) and <code>"BenHoch"</code>.
</p>
</td></tr>
<tr><td><code id="RItest_+3A_kmax">kmax</code></td>
<td>

<p>Maximum number of clusters to try for estimating the number of clusters (default: <code>2*n.clust</code>).
</p>
</td></tr>
<tr><td><code id="RItest_+3A_s.psi">s.psi</code></td>
<td>

<p>Numeric code for function required for calculating the distance for <code class="reqn">K</code>-means clustering. 
The value <code>1</code> corresponds to <code class="reqn">\psi(t) = t^2</code> (the default), 
<code>2</code> corresponds to <code class="reqn">\psi(t) = 1 - \exp(-t)</code>,
<code>3</code> corresponds to <code class="reqn">\psi(t) = 1 - \exp(-t^2)</code>,
<code>4</code> corresponds to <code class="reqn">\psi(t) = \log(1 + t)</code>,
<code>5</code> corresponds to <code class="reqn">\psi(t) = t</code>.
</p>
</td></tr>
<tr><td><code id="RItest_+3A_s.h">s.h</code></td>
<td>

<p>Numeric code for function required for calculating the distance for <code class="reqn">K</code>-means clustering. 
The value <code>1</code> corresponds to <code class="reqn">h(t) = \sqrt{t}</code> (the default), and 
<code>2</code> corresponds to <code class="reqn">h(t) = t</code>.
</p>
</td></tr>
<tr><td><code id="RItest_+3A_lb">lb</code></td>
<td>

<p>Length of smaller vectors into which each observation is partitioned (default: 1).
</p>
</td></tr>
<tr><td><code id="RItest_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of simulations of the test statistic (default: 1/alpha, minimum number required for running the test, set to a higher value for meaningful test results).
</p>
</td></tr>
<tr><td><code id="RItest_+3A_alpha">alpha</code></td>
<td>

<p>Test level (default: 0.05).
</p>
</td></tr>
<tr><td><code id="RItest_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tests are intended for the high dimension low sample size (HDLSS) setting. The idea is to cluster the pooled sample using a clustering algorithm that is suitable for the HDLSS setting and then to compare the clustering to the true dataset membership using the Rand index.
For the original RI test, the number of clusters has to be specified. If no number is specified it is set to the number of samples. 
This is a reasonable number of clusters in many cases. 
</p>
<p>However, in some cases, different numbers of clusters might be needed. 
For example in case of multimodal distributions in the datasets, there might be multiple clusters within each dataset. 
Therefore, the modified (MRI) test allows to estimate the number of clusters from the data. 
</p>
<p>In case of a really unclear number of clusters, the multiscale (MSRI) test can be applied which calculates the test for each number of clusters up to <code>kmax</code> and then summarizes the test results using some adjustment for multiple testing. 
</p>
<p>These three tests take into account all samples simultaneously. The aggregated (ARI) test instead performs all pairwise FS or MFS tests on the samples and aggregates those results by taking the minimum test statistic value and applying a multiple testing procedure.
</p>
<p>For clustering, a <code class="reqn">K</code>-means algorithm using the generalized version of the Mean Absolute Difference of Distances (MADD) (<cite>Sarkar and Ghosh, 2020</cite>) is applied. 
The MADD is defined as 
</p>
<p style="text-align: center;"><code class="reqn">
\rho_{h,\varphi}(z_i, z_j) = \frac{1}{N-2} \sum_{m\in \{1,\dots, N\}\setminus\{i,j\}} \left| \varphi_{h,\psi}(z_i, z_m) - \varphi_{h,\psi}(z_j, z_m)\right|,
</code>
</p>

<p>where <code class="reqn">z_i \in\mathbb{R}^p, i = 1,\dots,N</code>, denote points from the pooled sample and 
</p>
<p style="text-align: center;"><code class="reqn">\varphi_{h,\psi}(z_i, z_j) = h\left(\frac{1}{p}\sum_{i=l}^p\psi|z_{il} - z_{jl}|\right),</code>
</p>

<p>with <code class="reqn">h:\mathbb{R}^{+} \to\mathbb{R}^{+}</code> and <code class="reqn">\psi:\mathbb{R}^{+} \to\mathbb{R}^{+}</code> continuous and strictly increasing functions. 
The functions <code class="reqn">h</code> and <code class="reqn">\psi</code> can be set via changing <code>s.psi</code> and <code>s.h</code>.
</p>
<p>In all cases, high values of the test statistic correspond to similarity between the datasets. Therefore, the null hypothesis of equal distributions is rejected for low values. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>est.cluster.label</code></td>
<td>
<p>The estimated cluster label (not for AFS and MSFS)</p>
</td></tr>
<tr><td><code>observed.cont.table</code></td>
<td>
<p>The observed contingency table of dataset membership and estimated cluster label (not for AFS)</p>
</td></tr>
<tr><td><code>crit.value</code></td>
<td>
<p>The critical value of the test (not for MSFS)</p>
</td></tr>
<tr><td><code>random.gamma</code></td>
<td>
<p>The randomization constant of the test (not for MSFS)</p>
</td></tr>
<tr><td><code>decision</code></td>
<td>
<p>The (overall) test decision</p>
</td></tr>
<tr><td><code>decision.per.k</code></td>
<td>
<p>The test decisions of all individual tests (only for MSFS)</p>
</td></tr>
<tr><td><code>est.cluster.no</code></td>
<td>
<p>The estimated number of clusters (not for MSFS)</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>In case of <code>version = "multiscale"</code> the output is a list object and not of class <code>htest</code> as there are multiple test statistic values and corresponding p values.
</p>
<p>Note that the aggregated test cannot handle univariate data. 
</p>


<h3>References</h3>

<p>Paul, B., De, S. K. and Ghosh, A. K. (2021). Some clustering based exact distribution-free k-sample tests applicable to high dimension, low sample size data, Journal of Multivariate Analysis, <a href="https://doi.org/10.1016/j.jmva.2021.104897">doi:10.1016/j.jmva.2021.104897</a>
</p>
<p>Rand, W. M. (1971). Objective criteria for the evaluation of clustering methods, Journal of the American Statistical association, 66(336):846-850, <a href="https://doi.org/10.1080/01621459.1971.10482356">doi:10.1080/01621459.1971.10482356</a>
</p>
<p>Holm, S. (1979). A simple sequentially rejective multiple test procedure, Scandinavian journal of statistics, 65-70
</p>
<p>Benjamini, Y. and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing, Journal of the Royal statistical society: series B (Methodological) 57.1: 289-300, <a href="https://doi.org/10.1111/j.2517-6161.1995.tb02031.x">doi:10.1111/j.2517-6161.1995.tb02031.x</a>
</p>
<p>Sarkar, S. and Ghosh, A. K. (2020). On Perfect Clustering of High Dimension, Low Sample Size Data. IEEE Transactions on Pattern Analysis and Machine Intelligence 42 2257-2272. <a href="https://doi.org/10.1109/TPAMI.2019.2912599">doi:10.1109/TPAMI.2019.2912599</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FStest">FStest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
if(requireNamespace("HDLSSkST", quietly = TRUE)) {
  # Perform RI test 
  RItest(X1, X2, n.clust = 2)
  # Perform MRI test
  RItest(X1, X2, version = "modified")
  # Perform MSRI
  RItest(X1, X2, version = "multiscale")
  # Perform ARI test 
  RItest(X1, X2, n.clust = 2, version = "aggregated-knw")
  RItest(X1, X2, version = "aggregated-est")
}
</code></pre>

<hr>
<h2 id='Rosenbaum'>
Rosenbaum Crossmatch Test
</h2><span id='topic+Rosenbaum'></span>

<h3>Description</h3>

<p>Performs the <cite>Rosenbaum (2005)</cite> crossmatch two-sample test. The implementation here uses the <code><a href="crossmatch.html#topic+crossmatchtest">crossmatchtest</a></code> implementation from the <span class="pkg">crossmatch</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rosenbaum(X1, X2, exact = FALSE, dist.fun = stats::dist, dist.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Rosenbaum_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Rosenbaum_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Rosenbaum_+3A_exact">exact</code></td>
<td>

<p>Should the exact null distribution be used? (default: <code>FALSE</code>). The exact distribution calculation is only possible for a pooled sample size of less than 340 due to numerical reasons. If <code>exact = FALSE</code> or the sample size limit is reached, an asymptotic test is performed.
</p>
</td></tr>
<tr><td><code id="Rosenbaum_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="Rosenbaum_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="Rosenbaum_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistic is calculated as the standardized number of edges connecting points from different samples in a non-bipartite matching. The non-bipartite matching is calculated using the implementation from the <code><a href="nbpMatching.html#topic+nbpMatching-package">nbpMatching</a></code> package. The null hypothesis of equal distributions is rejected for small values of the test statistic as high values of the crossmatch statistic indicate similarity between datasets. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="crossmatch.html#topic+crossmatchtest">crossmatchtest</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see <code><a href="crossmatch.html#topic+crossmatchtest">crossmatchtest</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>Unstandardized crossmatch count</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>stderr</code></td>
<td>
<p>Standard deviation of the test statistic under the null</p>
</td></tr>
<tr><td><code>mu0</code></td>
<td>
<p>Expectation of the test statistic under the null</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Rosenbaum, P.R. (2005), An exact distribution-free test comparing two multivariate distributions based on adjacency, Journal of the Royal Statistical Society: Series B (Statistical Methodology), 67, 4, 515-530. 
</p>
<p>Heller, R., Small, D., Rosenbaum, P. (2024). crossmatch: The Cross-match Test. R package version 1.4, <a href="https://CRAN.R-project.org/package=crossmatch">https://CRAN.R-project.org/package=crossmatch</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+ZC">ZC</a></code>
</p>
<p><code><a href="#topic+Petrie">Petrie</a></code>, <code><a href="#topic+MMCM">MMCM</a></code> for multi-sample versions of the test
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform crossmatch test
if(requireNamespace("crossmatch", quietly = TRUE)) {
  Rosenbaum(X1, X2)
}
</code></pre>

<hr>
<h2 id='SC'>
Graph-Based Multi-Sample Test
</h2><span id='topic+SC'></span>

<h3>Description</h3>

<p>Performs the graph-based multi-sample test for high-dimensional data proposed by <cite>Song and Chen (2022)</cite>. The implementation here uses the <code><a href="gTestsMulti.html#topic+gtestsmulti">gtestsmulti</a></code> implementation from the <span class="pkg">gTestsMulti</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SC(X1, X2, ..., n.perm = 0, dist.fun = stats::dist, graph.fun = MST, 
    dist.args = NULL, graph.args = NULL, type = "S", seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SC_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="SC_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="SC_+3A_...">...</code></td>
<td>

<p>Optionally more datasets as matrices or data.frames
</p>
</td></tr>
<tr><td><code id="SC_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, no permutation test performed)
</p>
</td></tr>
<tr><td><code id="SC_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="SC_+3A_graph.fun">graph.fun</code></td>
<td>

<p>Function for calculating a similarity graph using the distance matrix on the pooled sample (default: <code><a href="#topic+MST">MST</a></code>, Minimum Spanning Tree).
</p>
</td></tr>
<tr><td><code id="SC_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="SC_+3A_graph.args">graph.args</code></td>
<td>

<p>Named list of further arguments passed to <code>graph.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="SC_+3A_type">type</code></td>
<td>

<p>Character specifying the test statistic to use. Possible options are <code>"S"</code> (default) and <code>"SA"</code>. See details.
</p>
</td></tr>
<tr><td><code id="SC_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two multi-sample test statistics are defined by <cite>Song and Chen (2022)</cite> based on a similarity graph. The first one is defined as 
</p>
<p style="text-align: center;"><code class="reqn">S = S_W + S_B, \text{ where}</code>
</p>

<p style="text-align: center;"><code class="reqn">S_W = (R_W - \text{E}(R_W))^T \Sigma_W^{-1}(R_W - \text{E}(R_W)),</code>
</p>

<p style="text-align: center;"><code class="reqn">S_B = (R_B - \text{E}(R_B))^T \Sigma_W^{-1}(R_B - \text{E}(R_B)),</code>
</p>

<p>with <code class="reqn">R_W</code> denoting the vector of within-sample edge counts and <code class="reqn">R_B</code> the vector of between-sample edge counts. Expectations and covariance matrix are calculated under the null. 
</p>
<p>The second statistic is defined as 
</p>
<p style="text-align: center;"><code class="reqn">S_A = (R_A - \text{E}(R_A))^T \Sigma_W^{-1}(R_A - \text{E}(R_A)), </code>
</p>

<p>where <code class="reqn">R_A</code> is the vector of all linearly independent edge counts, i.e. the edge counts for all pairs of samples except the last pair <code class="reqn">k-1</code> and <code class="reqn">k</code>.
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTestsMulti.html#topic+gtestsmulti">gtestsmulti</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTestsMulti.html#topic+gtestsmulti">gtestsmulti</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Permutation p value (only if <code>n.perm</code> &gt; 0)</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>Estimated KMD value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Song, H. and Chen, H. (2022). New graph-based multi-sample tests for high-dimensional and non- Euclidean data. <a href="https://doi.org/10.48550/arXiv.2205.13787">doi:10.48550/arXiv.2205.13787</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gTestsMulti">gTestsMulti</a></code> for performing both tests at once, <code><a href="#topic+MST">MST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Song and Chen test 
if(requireNamespace("gTestsMulti", quietly = TRUE)) {
  SC(X1, X2, n.perm = 100)
  SC(X1, X2, n.perm = 100, type = "SA")
}
</code></pre>

<hr>
<h2 id='SH'>
Schilling-Henze Nearest Neighbor Test
</h2><span id='topic+SH'></span>

<h3>Description</h3>

<p>Performs the Schilling-Henze two-sample test for multivariate data (<cite>Schilling, 1986; Henze, 1988</cite>). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SH(X1, X2, K = 1, graph.fun = knn.bf, dist.fun = stats::dist, n.perm = 0, 
    dist.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SH_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="SH_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="SH_+3A_k">K</code></td>
<td>

<p>Number of nearest neighbors to consider (default: 1)
</p>
</td></tr>
<tr><td><code id="SH_+3A_graph.fun">graph.fun</code></td>
<td>

<p>Function for calculating a similarity graph using the distance matrix on the pooled sample (default: <code><a href="#topic+knn.bf">knn.bf</a></code> which searches for the <code>K</code> nearest neighbors by ranking all pairwise distances, alternative: <code><a href="#topic+knn">knn</a></code> which is a wrapper for extracting the edge matrix from the result of <code><a href="dbscan.html#topic+kNN">kNN</a></code> in <span class="pkg">dbscan</span>, <code><a href="#topic+knn.fast">knn.fast</a></code> which is a wrapper for the approximative KNN implementation <code><a href="FNN.html#topic+get.knn">get.knn</a></code> in <span class="pkg">FNN</span>, or any other function that calculates the KNN edge matrix from a distance matrix and the number of nearest neighbors <code>K</code>).
</p>
</td></tr>
<tr><td><code id="SH_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="SH_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="SH_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code>.
</p>
</td></tr>
<tr><td><code id="SH_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistic is the proportion of edges connecting points from the same dataset in a <code>K</code>-nearest neighbor graph calculated on the pooled sample (standardized with expectation and SD under the null). 
</p>
<p>Low values of the test statistic indicate similarity of the datasets. Thus, the null hypothesis of equal distributions is rejected for high values. 
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the conditional null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>The number of within-sample edges</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>The default of <code>K=1</code> is chosen rather arbitrary based on computational speed as there is no good rule for chossing <code>K</code> proposed in the literature so far. Typical values for <code>K</code> chosen in the literature are 1 and 5.
</p>


<h3>References</h3>

<p>Schilling, M. F. (1986). Multivariate Two-Sample Tests Based on Nearest Neighbors. Journal of the American Statistical Association, 81(395), 799-806. <a href="https://doi.org/10.2307/2289012">doi:10.2307/2289012</a>
</p>
<p>Henze, N. (1988). A Multivariate Two-Sample Test Based on the Number of Nearest Neighbor Type Coincidences. The Annals of Statistics, 16(2), 772-783. 
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+knn">knn</a></code>, <code><a href="#topic+BQS">BQS</a></code>, <code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+ZC">ZC</a></code> for other graph-based tests, 
<code><a href="#topic+FR_cat">FR_cat</a></code>, <code><a href="#topic+CF_cat">CF_cat</a></code>, <code><a href="#topic+CCS_cat">CCS_cat</a></code>, and <code><a href="#topic+ZC_cat">ZC_cat</a></code> for versions of the test for categorical data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Schilling-Henze test
SH(X1, X2)
</code></pre>

<hr>
<h2 id='stat.fun'>
Univariate Two-Sample Statistics for DiProPerm Test
</h2><span id='topic+MD'></span><span id='topic+tStat'></span><span id='topic+AUC'></span><span id='topic+stat.fun'></span>

<h3>Description</h3>

<p>Helper functions for calculating univariate two-sample statistic for the Direction-Projection-Permutation (DiProPerm) two-sample test for high-dimensional data (<cite>Wei et al., 2016</cite>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MD(x1, x2)
tStat(x1, x2)
AUC(x1, x2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stat.fun_+3A_x1">x1</code></td>
<td>

<p>Numeric vector of scores for the first sample.
</p>
</td></tr>
<tr><td><code id="stat.fun_+3A_x2">x2</code></td>
<td>

<p>Numeric vector of scores for the second sample.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The DiProPerm test works by first combining the datasets into a pooled dataset and creating a target variable with the dataset membership of each observation.
A binary linear classifier is then trained on the class labels and the normal vector of the separating hyperplane is calculated. 
The data from both samples is projected onto this normal vector. This gives a scalar score for each observation.
On these projection scores, a univariate two-sample statistic is calculated. 
The permutation null distribution of this statistic is calculated by permuting the dataset labels and repeating the whole procedure with the permuted labels. 
The functions here correspond to the univariate two-sample statistics suggested in the original article of <cite>Wei et al., 2016</cite>.
</p>


<h3>Value</h3>

<p>A numeric scalar giving the observed two-sample statistic value.
</p>


<h3>References</h3>

<p>Wei, S., Lee, C., Wichers, L., &amp; Marron, J. S. (2016). Direction-Projection-Permutation for High-Dimensional Hypothesis Tests. Journal of Computational and Graphical Statistics, 25(2), 549-569. <a href="https://doi.org/10.1080/10618600.2015.1027773">doi:10.1080/10618600.2015.1027773</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DiProPerm">DiProPerm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Just for demonstration calculate univariate two-sample statistics separately
x1 &lt;- rnorm(100)
x2 &lt;- rnorm(100, mean = 0.5)
MD(x1, x2)
tStat(x1, x2)
if(requireNamespace("pROC", quietly = TRUE)) {
  AUC(x1, x2)
}

# Draw some multivariate data for the DiProPerm test
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform DiProPerm test 
# Note: For real applications, n.perm should be set considerably higher
# Low values for n.perm chosen for demonstration due to runtime

if(requireNamespace("DWDLargeR", quietly = TRUE)) {
  DiProPerm(X1, X2, n.perm = 10, stat.fun = MD)
  DiProPerm(X1, X2, n.perm = 10, stat.fun = tStat)
  if(requireNamespace("pROC", quietly = TRUE)) {
    DiProPerm(X1, X2, n.perm = 10, stat.fun = AUC, direction = "greater")
  }
}

</code></pre>

<hr>
<h2 id='Wasserstein'>
Wasserstein Distance based Test
</h2><span id='topic+Wasserstein'></span>

<h3>Description</h3>

<p>Performs a permutation two-sample test based on the Wasserstein distance.  The implementation here uses the <code><a href="Ecume.html#topic+wasserstein_permut">wasserstein_permut</a></code> implementation from the <span class="pkg">Ecume</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Wasserstein(X1, X2, n.perm = 0, fast = (nrow(X1) + nrow(X2)) &gt; 1000, 
            S = max(1000, (nrow(X1) + nrow(X2))/2), seed = 42, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Wasserstein_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Wasserstein_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="Wasserstein_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, no test is performed).
</p>
</td></tr>
<tr><td><code id="Wasserstein_+3A_fast">fast</code></td>
<td>

<p>Should the <code><a href="transport.html#topic+subwasserstein">subwasserstein</a></code> approximate function be used? (default: <code>TRUE</code> if the pooled sample size is more than 1000)
</p>
</td></tr>
<tr><td><code id="Wasserstein_+3A_s">S</code></td>
<td>

<p>Number of samples to use for approximation if <code>fast = TRUE</code>. See <code><a href="transport.html#topic+subwasserstein">subwasserstein</a></code>
</p>
</td></tr>
<tr><td><code id="Wasserstein_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
<tr><td><code id="Wasserstein_+3A_...">...</code></td>
<td>

<p>Other parameters passed to <code><a href="transport.html#topic+wasserstein">wasserstein</a></code> or <code><a href="transport.html#topic+wasserstein1d">wasserstein1d</a></code>, e.g. the power <code class="reqn">p\ge 1</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A permutation test for the <code class="reqn">p</code>-Wasserstein distance is performed. By default, the 1-Wasserstein distance is calculated using Euclidean distances. The <code class="reqn">p</code>-Wasserstein distance between two probability measures <code class="reqn">\mu</code> and <code class="reqn">\nu</code> on a Euclidean space <code class="reqn">M</code> is defined as 
</p>
<p style="text-align: center;"><code class="reqn">W_p(\mu, \nu) = \left(\inf_{\gamma\in\Gamma(\mu,\nu)}\int_{M\times M} ||x - y||^p \text{d} \gamma(x, y)\right)^{\frac{1}{p}},</code>
</p>

<p>where <code class="reqn">\Gamma(\mu,\nu)</code> is the set of probability measures on <code class="reqn">M\times M</code> such that <code class="reqn">\mu</code> and <code class="reqn">\nu</code> are the marginal distributions.
</p>
<p>As the Wasserstein distance of two distributions is a metric, it is zero if and only if the distributions coincides. Therefore, low values of the statistic indicate similarity of the datasets and the test rejects for high values. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="Ecume.html#topic+wasserstein_permut">wasserstein_permut</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="Ecume.html#topic+wasserstein_permut">wasserstein_permut</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Rachev, S. T. (1991). Probability metrics and the stability of stochastic models. John Wiley &amp; Sons, Chichester.
</p>
<p>Roux de Bezieux, H. (2021). Ecume: Equality of 2 (or <code class="reqn">k</code>) Continuous Univariate and Multivariate Distributions. R package version 0.9.1, <a href="https://CRAN.R-project.org/package=Ecume">https://CRAN.R-project.org/package=Ecume</a>
</p>
<p>Schuhmacher, D., B√§hre, B., Gottschlich, C., Hartmann, V., Heinemann, F., Schmitzer, B. and Schrieber, J. (2019). transport: Computation of Optimal Transport Plans and Wasserstein Distances. R package version 0.15-0. <a href="https://cran.r-project.org/package=transport">https://cran.r-project.org/package=transport</a>
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform Wasserstein distance based test 
if(requireNamespace("Ecume", quietly = TRUE)) {
  Wasserstein(X1, X2, n.perm = 100)
}
</code></pre>

<hr>
<h2 id='YMRZL'>
Yu et al. (2007) Two-Sample Test
</h2><span id='topic+YMRZL'></span>

<h3>Description</h3>

<p>Performs the <cite>Yu et al. (2007)</cite> two-sample test. The implementation here uses the <code>classifier_test</code> implementation from the <span class="pkg">Ecume</span> package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>YMRZL(X1, X2, n.perm = 0, split = 0.7, control = NULL, 
       train.args = NULL, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="YMRZL_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="YMRZL_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="YMRZL_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="YMRZL_+3A_split">split</code></td>
<td>

<p>Proportion of observations used for training
</p>
</td></tr>
<tr><td><code id="YMRZL_+3A_control">control</code></td>
<td>

<p>Control parameters for fitting. See <code><a href="caret.html#topic+trainControl">trainControl</a></code>. Defaults to <code>caret::trainControl(method = "boot")</code> as recommended if <code>control = NULL</code>. The number of Bootstrap samples defaults to 25 and can be set by specifying the <code>number</code> argument of <code>caret::trainControl</code>.
</p>
</td></tr>
<tr><td><code id="YMRZL_+3A_train.args">train.args</code></td>
<td>

<p>Further arguments passed to <code><a href="caret.html#topic+train">train</a></code> as a named list.
</p>
</td></tr>
<tr><td><code id="YMRZL_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two-sample test proposed by <cite>Yu et al. (2007)</cite> works by first combining the datasets into a pooled dataset and creating a target variable with the dataset membership of each observation. The pooled sample is then split into training and test set and a classification tree is trained on the training data. The test classification error is then used as a test statistic. If the distributions of the datasets do not differ, the classifier will be unable to distinguish between the datasets and therefore the test error will be close to chance level. The test rejects if the test error is smaller than chance level. 
</p>
<p>The tree model is fit by <code><a href="rpart.html#topic+rpart">rpart</a></code> and the classification error for tuning is by default predicted using the Bootstrap .632+ estimator as recommended by <cite>Yu et al. (2007)</cite>. 
</p>
<p>For <code>n.perm &gt; 0</code>, a permutation test is conducted. Otherwise, an asymptotic binomial test is performed.
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
<tr><td><code>classifier</code></td>
<td>
<p>Chosen classification method (tree)</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>As the idea of the test is very similar to that of the classifier two-sample test by <cite>Lopez-Paz and Oquab (2022)</cite>, the implementation here is based on that <code><a href="#topic+C2ST">C2ST</a></code>. Note that <cite>Lopez-Paz and Oquab (2022)</cite> utilize the classification accuracy instead of the classification error. Moreover, they propose to use a binomial test instead of the permutation test proposed by <cite>Yu et al.</cite>. Here, we implemented both the binomial and the permutation test. 
</p>


<h3>References</h3>

<p>Yu, K., Martin, R., Rothman, N., Zheng, T., Lan, Q. (2007). Two-sample Comparison Based on Prediction Error, with Applications to Candidate Gene Association Studies. Annals of Human Genetics, 71(1). <a href="https://doi.org/10.1111/j.1469-1809.2006.00306.x">doi:10.1111/j.1469-1809.2006.00306.x</a>
</p>
<p>Lopez-Paz, D., and Oquab, M. (2022). Revisiting classifier two-sample tests. ICLR 2017. <a href="https://openreview.net/forum?id=SJkXfE5xx">https://openreview.net/forum?id=SJkXfE5xx</a>
</p>
<p>Roux de Bezieux, H. (2021). Ecume: Equality of 2 (or k) Continuous Univariate and Multivariate Distributions. R package version 0.9.1, <a href="https://CRAN.R-project.org/package=Ecume">https://CRAN.R-project.org/package=Ecume</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+C2ST">C2ST</a></code>, <code><a href="#topic+HMN">HMN</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform the Yu et al. test
YMRZL(X1, X2)
</code></pre>

<hr>
<h2 id='ZC'>
Maxtype Edge-Count Test
</h2><span id='topic+ZC'></span>

<h3>Description</h3>

<p>Performs the maxtype edge-count two-sample test for multivariate data proposed by <cite>Zhang and Chen (2017)</cite>. The implementation here uses the <code><a href="gTests.html#topic+g.tests">g.tests</a></code> implementation from the <span class="pkg">gTests</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ZC(X1, X2, dist.fun = stats::dist, graph.fun = MST, n.perm = 0, 
    dist.args = NULL, graph.args = NULL, maxtype.kappa = 1.14, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ZC_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="ZC_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="ZC_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset (default: <code><a href="stats.html#topic+dist">stats::dist</a></code>, Euclidean distance).
</p>
</td></tr>
<tr><td><code id="ZC_+3A_graph.fun">graph.fun</code></td>
<td>

<p>Function for calculating a similarity graph using the distance matrix on the pooled sample (default: <code><a href="#topic+MST">MST</a></code>, Minimum Spanning Tree).
</p>
</td></tr>
<tr><td><code id="ZC_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="ZC_+3A_dist.args">dist.args</code></td>
<td>

<p>Named list of further arguments passed to <code>dist.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="ZC_+3A_graph.args">graph.args</code></td>
<td>

<p>Named list of further arguments passed to <code>graph.fun</code> (default: <code>NULL</code>).
</p>
</td></tr>
<tr><td><code id="ZC_+3A_maxtype.kappa">maxtype.kappa</code></td>
<td>

<p>Parameter <code class="reqn">\kappa</code> of the test (default: 1.14). See details.
</p>
</td></tr>
<tr><td><code id="ZC_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an enhancement of the Friedman-Rafsky test (original edge-count test)  that aims at detecting both location and scale alternatives and is more flexible than the generalized edge-count test of Chen and Friedman (2017). The test statistic is the maximum of two statistics. The first statistic ist the weighted edge-count statistic multiplied by a factor <code class="reqn">\kappa</code>. The second statistic is the absolute value of the standardized difference of edge-counts within the first and within the second sample. 
</p>
<p>Low values of the test statistic indicate similarity of the datasets. Thus, the null hypothesis of equal distributions is rejected for high values. 
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Zhang, J. and Chen, H. (2022). Graph-Based Two-Sample Tests for Data with Repeated Observations. Statistica Sinica 32, 391-415, <a href="https://doi.org/10.5705/ss.202019.0116">doi:10.5705/ss.202019.0116</a>.
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR">FR</a></code> for the original edge-count test, <code><a href="#topic+CF">CF</a></code> for the generalized edge-count test, <code><a href="#topic+CCS">CCS</a></code> for the weighted edge-count test, <code><a href="#topic+gTests">gTests</a></code> for performing all these edge-count tests at once, <code><a href="#topic+SH">SH</a></code> for performing the Schilling-Henze nearest neighbor test, 
<code><a href="#topic+CCS_cat">CCS_cat</a></code>, <code><a href="#topic+FR_cat">FR_cat</a></code>, <code><a href="#topic+CF_cat">CF_cat</a></code>, <code><a href="#topic+ZC_cat">ZC_cat</a></code>, and <code><a href="#topic+gTests_cat">gTests_cat</a></code> for versions of the test for categorical data
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1 &lt;- matrix(rnorm(1000), ncol = 10)
X2 &lt;- matrix(rnorm(1000, mean = 0.5), ncol = 10)
# Perform maxtype edge-count test
if(requireNamespace("gTests", quietly = TRUE)) {
  ZC(X1, X2)
}
</code></pre>

<hr>
<h2 id='ZC_cat'>
Maxtype Edge-Count Test for Discrete Data
</h2><span id='topic+ZC_cat'></span>

<h3>Description</h3>

<p>Performs the maxtype edge-count two-sample test for multivariate data proposed by <cite>Zhang and Chen (2022)</cite>. The implementation here uses the <code><a href="gTests.html#topic+g.tests">g.tests</a></code> implementation from the <span class="pkg">gTests</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ZC_cat(X1, X2, dist.fun, agg.type, graph.type = "mstree", K = 1, n.perm = 0, 
        maxtype.kappa = 1.14, seed = 42)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ZC_cat_+3A_x1">X1</code></td>
<td>

<p>First dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="ZC_cat_+3A_x2">X2</code></td>
<td>

<p>Second dataset as matrix or data.frame
</p>
</td></tr>
<tr><td><code id="ZC_cat_+3A_dist.fun">dist.fun</code></td>
<td>

<p>Function for calculating a distance matrix on the pooled dataset.
</p>
</td></tr>
<tr><td><code id="ZC_cat_+3A_agg.type">agg.type</code></td>
<td>

<p>Character giving the method for aggregating over possible similarity graphs. Options are <code>"u"</code> for union of possible similarity graphs and <code>"a"</code> for averaging over test statistics calculated on possible similarity graphs. 
</p>
</td></tr>
<tr><td><code id="ZC_cat_+3A_graph.type">graph.type</code></td>
<td>

<p>Character specifying which similarity graph to use. Possible options are <code>"mstree"</code> (default, Minimum Spanning Tree) and <code>"nnlink"</code> (Nearest Neighbor Graph).
</p>
</td></tr>
<tr><td><code id="ZC_cat_+3A_k">K</code></td>
<td>

<p>Parameter for graph (default: 1). If <code>graph.type = "mstree"</code>, a <code>K</code>-MST is constructed (<code>K=1</code> is the classical MST). If <code>graph.type = "nnlink"</code>, <code>K</code> gives the number of neighbors considered in the <code>K</code>-NN graph.
</p>
</td></tr>
<tr><td><code id="ZC_cat_+3A_n.perm">n.perm</code></td>
<td>

<p>Number of permutations for permutation test (default: 0, asymptotic test is performed).
</p>
</td></tr>
<tr><td><code id="ZC_cat_+3A_maxtype.kappa">maxtype.kappa</code></td>
<td>

<p>Parameter <code class="reqn">\kappa</code> of the test (default: 1.14). See details.
</p>
</td></tr>
<tr><td><code id="ZC_cat_+3A_seed">seed</code></td>
<td>

<p>Random seed (default: 42)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is an enhancement of the Friedman-Rafsky test (original edge-count test)  that aims at detecting both location and scale alternatives and is more flexible than the generalized edge-count test of <cite>Chen and Friedman (2017)</cite>. The test statistic is the maximum of two statistics. The first statistic ist the weighted edge-count statistic multiplied by a factor <code class="reqn">\kappa</code>. The second statistic is the absolute value of the standardized difference of edge-counts within the first and within the second sample. 
</p>
<p>Low values of the test statistic indicate similarity of the datasets. Thus, the null hypothesis of equal distributions is rejected for high values. 
</p>
<p>For discrete data, the similarity graph used in the test is not necessarily unique. This can be solved by either taking a union of all optimal similarity graphs or averaging the test statistics over all optimal similarity graphs. For details, see <cite>Zhang and Chen (2017)</cite>. 
</p>
<p>For <code>n.perm = 0</code>, an asymptotic test using the asymptotic normal approximation of the null distribution is performed. For <code>n.perm &gt; 0</code>, a permutation test is performed. 
</p>
<p>This implementation is a wrapper function around the function <code><a href="gTests.html#topic+g.tests">g.tests</a></code> that modifies the in- and output of that function to match the other functions provided in this package. For more details see the <code><a href="gTests.html#topic+g.tests">g.tests</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>statistic</code></td>
<td>
<p>Observed value of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Asymptotic or permutation p value</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Description of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>The dataset names</p>
</td></tr>
</table>


<h3>Applicability</h3>


<table>
<tr>
 <td style="text-align: left;">
     Target variable?   </td><td style="text-align: left;"> Numeric? </td><td style="text-align: left;"> Categorical? </td><td style="text-align: left;"> K-sample? </td>
</tr>
<tr>
 <td style="text-align: left;">
     No </td><td style="text-align: left;"> No </td><td style="text-align: left;"> Yes </td><td style="text-align: left;"> No </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p>Zhang, J. and Chen, H. (2022). Graph-Based Two-Sample Tests for Data with Repeated Observations. Statistica Sinica 32, 391-415, <a href="https://doi.org/10.5705/ss.202019.0116">doi:10.5705/ss.202019.0116</a>.
</p>
<p>Chen, H., and Zhang, J. (2017). gTests: Graph-Based Two-Sample Tests. R package version 0.2, <a href="https://CRAN.R-project.org/package=gTests">https://CRAN.R-project.org/package=gTests</a>.
</p>
<p>Stolte, M., Kappenberg, F., Rahnenf√ºhrer, J., Bommert, A. (2024). Methods for quantifying dataset similarity: a review, taxonomy and comparison. Statist. Surv. 18, 163 - 298. <a href="https://doi.org/10.1214/24-SS149">doi:10.1214/24-SS149</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FR_cat">FR_cat</a></code> for the original edge-count test, <code><a href="#topic+CF_cat">CF_cat</a></code> for the generalized edge-count test, <code><a href="#topic+CCS_cat">CCS_cat</a></code> for the weighted edge-count test, <code><a href="#topic+gTests_cat">gTests_cat</a></code> for performing all these edge-count tests at once,
<code><a href="#topic+FR">FR</a></code>, <code><a href="#topic+CF">CF</a></code>, <code><a href="#topic+CCS">CCS</a></code>, <code><a href="#topic+ZC">ZC</a></code>, and <code><a href="#topic+gTests">gTests</a></code> for versions of the  tests for continuous data, and <code><a href="#topic+SH">SH</a></code> for performing the Schilling-Henze nearest neighbor test
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw some data
X1cat &lt;- matrix(sample(1:4, 300, replace = TRUE), ncol = 3)
X2cat &lt;- matrix(sample(1:4, 300, replace = TRUE, prob = 1:4), ncol = 3)
# Perform generalized edge-count test
if(requireNamespace("gTests", quietly = TRUE)) {
  ZC_cat(X1cat, X2cat, dist.fun = function(x, y) sum(x != y), agg.type = "a")
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
