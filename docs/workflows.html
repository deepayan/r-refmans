<!DOCTYPE html><html lang="en"><head><title>Help for package workflows</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {workflows}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#workflows-package'><p>workflows: Modeling Workflows</p></a></li>
<li><a href='#add_case_weights'><p>Add case weights to a workflow</p></a></li>
<li><a href='#add_formula'><p>Add formula terms to a workflow</p></a></li>
<li><a href='#add_model'><p>Add a model to a workflow</p></a></li>
<li><a href='#add_recipe'><p>Add a recipe to a workflow</p></a></li>
<li><a href='#add_variables'><p>Add variables to a workflow</p></a></li>
<li><a href='#augment.workflow'><p>Augment data with predictions</p></a></li>
<li><a href='#control_workflow'><p>Control object for a workflow</p></a></li>
<li><a href='#extract-workflow'><p>Extract elements of a workflow</p></a></li>
<li><a href='#fit-workflow'><p>Fit a workflow object</p></a></li>
<li><a href='#glance.workflow'><p>Glance at a workflow model</p></a></li>
<li><a href='#is_trained_workflow'><p>Determine if a workflow has been trained</p></a></li>
<li><a href='#predict-workflow'><p>Predict from a workflow</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#tidy.workflow'><p>Tidy a workflow</p></a></li>
<li><a href='#workflow'><p>Create a workflow</p></a></li>
<li><a href='#workflow-butcher'><p>Butcher methods for a workflow</p></a></li>
<li><a href='#workflow-extractors'><p>Extract elements of a workflow</p></a></li>
<li><a href='#workflows-internals'><p>Internal workflow functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Modeling Workflows</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Managing both a 'parsnip' model and its data preparation steps, 
    such as a model formula or recipe from 'recipes', can often be challenging. 
    The goal of 'workflows' is to streamline this process by bundling the
    model with its data preparation, all within the same object.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tidymodels/workflows">https://github.com/tidymodels/workflows</a>,
<a href="https://workflows.tidymodels.org">https://workflows.tidymodels.org</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tidymodels/workflows/issues">https://github.com/tidymodels/workflows/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cli (&ge; 3.3.0), generics (&ge; 0.1.2), glue (&ge; 1.6.2), hardhat
(&ge; 1.4.1), lifecycle (&ge; 1.0.3), modelenv (&ge; 0.1.0), parsnip
(&ge; 1.3.0), recipes (&ge; 1.1.1), rlang (&ge; 1.1.0), tidyselect
(&ge; 1.2.0), sparsevctrs (&ge; 0.2.0), vctrs (&ge; 0.4.1), withr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>butcher (&ge; 0.2.0), covr, dials (&ge; 1.0.0), glmnet, knitr,
magrittr, Matrix, methods, modeldata (&ge; 1.0.0), probably,
rsample, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>dplyr, ggplot2, tidyr, tidyverse/tidytemplate,
yardstick</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-18 20:59:24 UTC; simoncouch</td>
</tr>
<tr>
<td>Author:</td>
<td>Davis Vaughan [aut],
  Simon Couch <a href="https://orcid.org/0000-0001-5676-5107"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Posit Software, PBC [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Simon Couch &lt;simon.couch@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-19 00:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='workflows-package'>workflows: Modeling Workflows</h2><span id='topic+workflows'></span><span id='topic+workflows-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Managing both a 'parsnip' model and its data preparation steps, such as a model formula or recipe from 'recipes', can often be challenging. The goal of 'workflows' is to streamline this process by bundling the model with its data preparation, all within the same object.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Simon Couch <a href="mailto:simon.couch@posit.co">simon.couch@posit.co</a> (<a href="https://orcid.org/0000-0001-5676-5107">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Davis Vaughan <a href="mailto:davis@posit.co">davis@posit.co</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Posit Software, PBC [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tidymodels/workflows">https://github.com/tidymodels/workflows</a>
</p>
</li>
<li> <p><a href="https://workflows.tidymodels.org">https://workflows.tidymodels.org</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tidymodels/workflows/issues">https://github.com/tidymodels/workflows/issues</a>
</p>
</li></ul>


<hr>
<h2 id='add_case_weights'>Add case weights to a workflow</h2><span id='topic+add_case_weights'></span><span id='topic+remove_case_weights'></span><span id='topic+update_case_weights'></span>

<h3>Description</h3>

<p>This family of functions revolves around selecting a column of <code>data</code> to use
for <em>case weights</em>. This column must be one of the allowed case weight types,
such as <code><a href="hardhat.html#topic+frequency_weights">hardhat::frequency_weights()</a></code> or <code><a href="hardhat.html#topic+importance_weights">hardhat::importance_weights()</a></code>.
Specifically, it must return <code>TRUE</code> from <code><a href="hardhat.html#topic+is_case_weights">hardhat::is_case_weights()</a></code>. The
underlying model will decide whether or not the type of case weights you have
supplied are applicable or not.
</p>

<ul>
<li> <p><code>add_case_weights()</code> specifies the column that will be interpreted as
case weights in the model. This column must be present in the <code>data</code>
supplied to <a href="#topic+fit.workflow">fit()</a>.
</p>
</li>
<li> <p><code>remove_case_weights()</code> removes the case weights. Additionally, if the
model has already been fit, then the fit is removed.
</p>
</li>
<li> <p><code>update_case_weights()</code> first removes the case weights, then replaces them
with the new ones.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>add_case_weights(x, col)

remove_case_weights(x)

update_case_weights(x, col)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_case_weights_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="add_case_weights_+3A_col">col</code></td>
<td>
<p>A single unquoted column name specifying the case weights for
the model. This must be a classed case weights column, as determined by
<code><a href="hardhat.html#topic+is_case_weights">hardhat::is_case_weights()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For formula and variable preprocessors, the case weights <code>col</code> is removed
from the data before the preprocessor is evaluated. This allows you to use
formulas like <code>y ~ .</code> or tidyselection like <code>everything()</code> without fear of
accidentally selecting the case weights column.
</p>
<p>For recipe preprocessors, the case weights <code>col</code> is not removed and is
passed along to the recipe. Typically, your recipe will include steps that
can utilize case weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parsnip)
library(magrittr)
library(hardhat)

mtcars2 &lt;- mtcars
mtcars2$gear &lt;- frequency_weights(mtcars2$gear)

spec &lt;- linear_reg() %&gt;%
  set_engine("lm")

wf &lt;- workflow() %&gt;%
  add_case_weights(gear) %&gt;%
  add_formula(mpg ~ .) %&gt;%
  add_model(spec)

wf &lt;- fit(wf, mtcars2)

# Notice that the case weights (gear) aren't included in the predictors
extract_mold(wf)$predictors

# Strip them out of the workflow, which also resets the model
remove_case_weights(wf)
</code></pre>

<hr>
<h2 id='add_formula'>Add formula terms to a workflow</h2><span id='topic+add_formula'></span><span id='topic+remove_formula'></span><span id='topic+update_formula'></span>

<h3>Description</h3>


<ul>
<li> <p><code>add_formula()</code> specifies the terms of the model through the usage of a
formula.
</p>
</li>
<li> <p><code>remove_formula()</code> removes the formula as well as any downstream objects
that might get created after the formula is used for preprocessing, such as
terms. Additionally, if the model has already been fit, then the fit is
removed.
</p>
</li>
<li> <p><code>update_formula()</code> first removes the formula, then replaces the previous
formula with the new one. Any model that has already been fit based on this
formula will need to be refit.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>add_formula(x, formula, ..., blueprint = NULL)

remove_formula(x)

update_formula(x, formula, ..., blueprint = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_formula_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="add_formula_+3A_formula">formula</code></td>
<td>
<p>A formula specifying the terms of the model. It is advised to
not do preprocessing in the formula, and instead use a recipe if that is
required.</p>
</td></tr>
<tr><td><code id="add_formula_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="add_formula_+3A_blueprint">blueprint</code></td>
<td>
<p>A hardhat blueprint used for fine tuning the preprocessing.
</p>
<p>If <code>NULL</code>, <code><a href="hardhat.html#topic+default_formula_blueprint">hardhat::default_formula_blueprint()</a></code> is used and is passed
arguments that best align with the model present in the workflow.
</p>
<p>Note that preprocessing done here is separate from preprocessing that
might be done by the underlying model. For example, if a blueprint with
<code>indicators = "none"</code> is specified, no dummy variables will be created by
hardhat, but if the underlying model requires a formula interface that
internally uses <code><a href="stats.html#topic+model.matrix">stats::model.matrix()</a></code>, factors will still be expanded to
dummy variables by the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To fit a workflow, exactly one of <code><a href="#topic+add_formula">add_formula()</a></code>, <code><a href="#topic+add_recipe">add_recipe()</a></code>, or
<code><a href="#topic+add_variables">add_variables()</a></code> <em>must</em> be specified.
</p>


<h3>Value</h3>

<p><code>x</code>, updated with either a new or removed formula preprocessor.
</p>


<h3>Formula Handling</h3>

<p>Note that, for different models, the formula given to <code>add_formula()</code>
might be handled in different ways, depending on the parsnip model being
used. For example, a random forest model fit using ranger would not
convert any factor predictors to binary indicator variables. This is
consistent with what <code>ranger::ranger()</code> would do, but is inconsistent
with what <code>stats::model.matrix()</code> would do.
</p>
<p>The documentation for parsnip models provides details about how the data
given in the formula are encoded for the model if they diverge from the
standard <code>model.matrix()</code> methodology. Our goal is to be consistent with
how the underlying model package works.
</p>


<h4>How is this formula used?</h4>

<p>To demonstrate, the example below uses <code>lm()</code> to fit a model. The
formula given to <code>add_formula()</code> is used to create the model matrix and
that is what is passed to <code>lm()</code> with a simple formula of
<code>body_mass_g ~ .</code>:
</p>
<div class="sourceCode r"><pre>library(parsnip)
library(workflows)
library(magrittr)
library(modeldata)
library(hardhat)

data(penguins)

lm_mod &lt;- linear_reg() %&gt;% 
  set_engine("lm")

lm_wflow &lt;- workflow() %&gt;% 
  add_model(lm_mod)

pre_encoded &lt;- lm_wflow %&gt;% 
  add_formula(body_mass_g ~ species + island + bill_depth_mm) %&gt;% 
  fit(data = penguins)

pre_encoded_parsnip_fit &lt;- pre_encoded %&gt;% 
  extract_fit_parsnip()

pre_encoded_fit &lt;- pre_encoded_parsnip_fit$fit

# The `lm()` formula is *not* the same as the `add_formula()` formula: 
pre_encoded_fit
</pre></div>
<div class="sourceCode"><pre>## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
##      (Intercept)  speciesChinstrap     speciesGentoo  
##        -1009.943             1.328          2236.865  
##      islandDream   islandTorgersen     bill_depth_mm  
##            9.221           -18.433           256.913
</pre></div>
<p>This can affect how the results are analyzed. For example, to get
sequential hypothesis tests, each individual term is tested:
</p>
<div class="sourceCode r"><pre>anova(pre_encoded_fit)
</pre></div>
<div class="sourceCode"><pre>## Analysis of Variance Table
## 
## Response: ..y
##                   Df    Sum Sq   Mean Sq  F value Pr(&gt;F)    
## speciesChinstrap   1  18642821  18642821 141.1482 &lt;2e-16 ***
## speciesGentoo      1 128221393 128221393 970.7875 &lt;2e-16 ***
## islandDream        1     13399     13399   0.1014 0.7503    
##  [ reached getOption("max.print") -- omitted 3 rows ]
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</pre></div>



<h4>Overriding the default encodings</h4>

<p>Users can override the model-specific encodings by using a hardhat
blueprint. The blueprint can specify how factors are encoded and whether
intercepts are included. As an example, if you use a formula and would
like the data to be passed to a model untouched:
</p>
<div class="sourceCode r"><pre>minimal &lt;- default_formula_blueprint(indicators = "none", intercept = FALSE)

un_encoded &lt;- lm_wflow %&gt;% 
  add_formula(
    body_mass_g ~ species + island + bill_depth_mm, 
    blueprint = minimal
  ) %&gt;% 
  fit(data = penguins)

un_encoded_parsnip_fit &lt;- un_encoded %&gt;% 
  extract_fit_parsnip()

un_encoded_fit &lt;- un_encoded_parsnip_fit$fit

un_encoded_fit
</pre></div>
<div class="sourceCode"><pre>## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
##      (Intercept)     bill_depth_mm  speciesChinstrap  
##        -1009.943           256.913             1.328  
##    speciesGentoo       islandDream   islandTorgersen  
##         2236.865             9.221           -18.433
</pre></div>
<p>While this looks the same, the raw columns were given to <code>lm()</code> and that
function created the dummy variables. Because of this, the sequential
ANOVA tests groups of parameters to get column-level p-values:
</p>
<div class="sourceCode r"><pre>anova(un_encoded_fit)
</pre></div>
<div class="sourceCode"><pre>## Analysis of Variance Table
## 
## Response: ..y
##                Df    Sum Sq  Mean Sq F value Pr(&gt;F)    
## bill_depth_mm   1  48840779 48840779 369.782 &lt;2e-16 ***
## species         2 126067249 63033624 477.239 &lt;2e-16 ***
## island          2     20864    10432   0.079 0.9241    
##  [ reached getOption("max.print") -- omitted 1 row ]
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</pre></div>



<h4>Overriding the default model formula</h4>

<p>Additionally, the formula passed to the underlying model can also be
customized. In this case, the <code>formula</code> argument of <code>add_model()</code> can be
used. To demonstrate, a spline function will be used for the bill depth:
</p>
<div class="sourceCode r"><pre>library(splines)

custom_formula &lt;- workflow() %&gt;%
  add_model(
    lm_mod, 
    formula = body_mass_g ~ species + island + ns(bill_depth_mm, 3)
  ) %&gt;% 
  add_formula(
    body_mass_g ~ species + island + bill_depth_mm, 
    blueprint = minimal
  ) %&gt;% 
  fit(data = penguins)

custom_parsnip_fit &lt;- custom_formula %&gt;% 
  extract_fit_parsnip()

custom_fit &lt;- custom_parsnip_fit$fit

custom_fit
</pre></div>
<div class="sourceCode"><pre>## 
## Call:
## stats::lm(formula = body_mass_g ~ species + island + ns(bill_depth_mm, 
##     3), data = data)
## 
## Coefficients:
##           (Intercept)       speciesChinstrap          speciesGentoo  
##              1959.090                  8.534               2352.137  
##           islandDream        islandTorgersen  ns(bill_depth_mm, 3)1  
##                 2.425                -12.002               1476.386  
## ns(bill_depth_mm, 3)2  ns(bill_depth_mm, 3)3  
##              3187.839               1686.996
</pre></div>



<h4>Altering the formula</h4>

<p>Finally, when a formula is updated or removed from a fitted workflow,
the corresponding model fit is removed.
</p>
<div class="sourceCode r"><pre>custom_formula_no_fit &lt;- update_formula(custom_formula, body_mass_g ~ species)

try(extract_fit_parsnip(custom_formula_no_fit))
</pre></div>
<div class="sourceCode"><pre>## Error in extract_fit_parsnip(custom_formula_no_fit) : 
##   Can't extract a model fit from an untrained workflow.
## i Do you need to call `fit()`?
</pre></div>



<h3>Examples</h3>

<pre><code class='language-R'>workflow &lt;- workflow()
workflow &lt;- add_formula(workflow, mpg ~ cyl)
workflow

remove_formula(workflow)

update_formula(workflow, mpg ~ disp)
</code></pre>

<hr>
<h2 id='add_model'>Add a model to a workflow</h2><span id='topic+add_model'></span><span id='topic+remove_model'></span><span id='topic+update_model'></span>

<h3>Description</h3>


<ul>
<li> <p><code>add_model()</code> adds a parsnip model to the workflow.
</p>
</li>
<li> <p><code>remove_model()</code> removes the model specification as well as any fitted
model object. Any extra formulas are also removed.
</p>
</li>
<li> <p><code>update_model()</code> first removes the model then adds the new specification to
the workflow.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>add_model(x, spec, ..., formula = NULL)

remove_model(x)

update_model(x, spec, ..., formula = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_model_+3A_x">x</code></td>
<td>
<p>A workflow.</p>
</td></tr>
<tr><td><code id="add_model_+3A_spec">spec</code></td>
<td>
<p>A parsnip model specification.</p>
</td></tr>
<tr><td><code id="add_model_+3A_...">...</code></td>
<td>
<p>These dots are for future extensions and must be empty.</p>
</td></tr>
<tr><td><code id="add_model_+3A_formula">formula</code></td>
<td>
<p>An optional formula override to specify the terms of the
model. Typically, the terms are extracted from the formula or recipe
preprocessing methods. However, some models (like survival and bayesian
models) use the formula not to preprocess, but to specify the structure
of the model. In those cases, a formula specifying the model structure
must be passed unchanged into the model call itself. This argument is
used for those purposes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>add_model()</code> is a required step to construct a minimal workflow.
</p>


<h3>Value</h3>

<p><code>x</code>, updated with either a new or removed model.
</p>


<h3>Indicator Variable Details</h3>

<p>Some modeling functions in R create indicator/dummy variables from
categorical data when you use a model formula, and some do not. When you
specify and fit a model with a <code>workflow()</code>, parsnip and workflows match
and reproduce the underlying behavior of the user-specified model’s
computational engine.
</p>


<h4>Formula Preprocessor</h4>

<p>In the <a href="modeldata.html#topic+Sacramento">modeldata::Sacramento</a> data set of real
estate prices, the <code>type</code> variable has three levels: <code>"Residential"</code>,
<code>"Condo"</code>, and <code>"Multi-Family"</code>. This base <code>workflow()</code> contains a
formula added via <code><a href="#topic+add_formula">add_formula()</a></code> to predict property
price from property type, square footage, number of beds, and number of
baths:
</p>
<div class="sourceCode r"><pre>set.seed(123)

library(parsnip)
library(recipes)
library(workflows)
library(modeldata)

data("Sacramento")

base_wf &lt;- workflow() %&gt;%
  add_formula(price ~ type + sqft + beds + baths)
</pre></div>
<p>This first model does create dummy/indicator variables:
</p>
<div class="sourceCode r"><pre>lm_spec &lt;- linear_reg() %&gt;%
  set_engine("lm")

base_wf %&gt;%
  add_model(lm_spec) %&gt;%
  fit(Sacramento)
</pre></div>
<div class="sourceCode"><pre>## == Workflow [trained] ================================================
## Preprocessor: Formula
## Model: linear_reg()
## 
## -- Preprocessor ------------------------------------------------------
## price ~ type + sqft + beds + baths
## 
## -- Model -------------------------------------------------------------
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
##      (Intercept)  typeMulti_Family   typeResidential  
##          32919.4          -21995.8           33688.6  
##             sqft              beds             baths  
##            156.2          -29788.0            8730.0
</pre></div>
<p>There are <strong>five</strong> independent variables in the fitted model for this
OLS linear regression. With this model type and engine, the factor
predictor <code>type</code> of the real estate properties was converted to two
binary predictors, <code>typeMulti_Family</code> and <code>typeResidential</code>. (The third
type, for condos, does not need its own column because it is the
baseline level).
</p>
<p>This second model does not create dummy/indicator variables:
</p>
<div class="sourceCode r"><pre>rf_spec &lt;- rand_forest() %&gt;%
  set_mode("regression") %&gt;%
  set_engine("ranger")

base_wf %&gt;%
  add_model(rf_spec) %&gt;%
  fit(Sacramento)
</pre></div>
<div class="sourceCode"><pre>## == Workflow [trained] ================================================
## Preprocessor: Formula
## Model: rand_forest()
## 
## -- Preprocessor ------------------------------------------------------
## price ~ type + sqft + beds + baths
## 
## -- Model -------------------------------------------------------------
## Ranger result
## 
## Call:
##  ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) 
## 
## Type:                             Regression 
## Number of trees:                  500 
## Sample size:                      932 
## Number of independent variables:  4 
## Mtry:                             2 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       7058847504 
## R squared (OOB):                  0.5894647
</pre></div>
<p>Note that there are <strong>four</strong> independent variables in the fitted model
for this ranger random forest. With this model type and engine,
indicator variables were not created for the <code>type</code> of real estate
property being sold. Tree-based models such as random forest models can
handle factor predictors directly, and don’t need any conversion to
numeric binary variables.
</p>



<h4>Recipe Preprocessor</h4>

<p>When you specify a model with a <code>workflow()</code> and a recipe preprocessor
via <code><a href="#topic+add_recipe">add_recipe()</a></code>, the <em>recipe</em> controls whether dummy
variables are created or not; the recipe overrides any underlying
behavior from the model’s computational engine.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>library(parsnip)

lm_model &lt;- linear_reg()
lm_model &lt;- set_engine(lm_model, "lm")

regularized_model &lt;- set_engine(lm_model, "glmnet")

workflow &lt;- workflow()
workflow &lt;- add_model(workflow, lm_model)
workflow

workflow &lt;- add_formula(workflow, mpg ~ .)
workflow

remove_model(workflow)

fitted &lt;- fit(workflow, data = mtcars)
fitted

remove_model(fitted)

remove_model(workflow)

update_model(workflow, regularized_model)
update_model(fitted, regularized_model)
</code></pre>

<hr>
<h2 id='add_recipe'>Add a recipe to a workflow</h2><span id='topic+add_recipe'></span><span id='topic+remove_recipe'></span><span id='topic+update_recipe'></span>

<h3>Description</h3>


<ul>
<li> <p><code>add_recipe()</code> specifies the terms of the model and any preprocessing that
is required through the usage of a recipe.
</p>
</li>
<li> <p><code>remove_recipe()</code> removes the recipe as well as any downstream objects
that might get created after the recipe is used for preprocessing, such as
the prepped recipe. Additionally, if the model has already been fit, then
the fit is removed.
</p>
</li>
<li> <p><code>update_recipe()</code> first removes the recipe, then replaces the previous
recipe with the new one. Any model that has already been fit based on this
recipe will need to be refit.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>add_recipe(x, recipe, ..., blueprint = NULL)

remove_recipe(x)

update_recipe(x, recipe, ..., blueprint = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_recipe_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="add_recipe_+3A_recipe">recipe</code></td>
<td>
<p>A recipe created using <code><a href="recipes.html#topic+recipe">recipes::recipe()</a></code>. The recipe
should not have been trained already with <code><a href="recipes.html#topic+prep">recipes::prep()</a></code>; workflows
will handle training internally.</p>
</td></tr>
<tr><td><code id="add_recipe_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="add_recipe_+3A_blueprint">blueprint</code></td>
<td>
<p>A hardhat blueprint used for fine tuning the preprocessing.
</p>
<p>If <code>NULL</code>, <code><a href="hardhat.html#topic+default_recipe_blueprint">hardhat::default_recipe_blueprint()</a></code> is used.
</p>
<p>Note that preprocessing done here is separate from preprocessing that
might be done automatically by the underlying model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To fit a workflow, exactly one of <code><a href="#topic+add_formula">add_formula()</a></code>, <code><a href="#topic+add_recipe">add_recipe()</a></code>, or
<code><a href="#topic+add_variables">add_variables()</a></code> <em>must</em> be specified.
</p>


<h3>Value</h3>

<p><code>x</code>, updated with either a new or removed recipe preprocessor.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
library(magrittr)

recipe &lt;- recipe(mpg ~ cyl, mtcars) %&gt;%
  step_log(cyl)

workflow &lt;- workflow() %&gt;%
  add_recipe(recipe)

workflow

remove_recipe(workflow)

update_recipe(workflow, recipe(mpg ~ cyl, mtcars))

</code></pre>

<hr>
<h2 id='add_variables'>Add variables to a workflow</h2><span id='topic+add_variables'></span><span id='topic+remove_variables'></span><span id='topic+update_variables'></span><span id='topic+workflow_variables'></span>

<h3>Description</h3>


<ul>
<li> <p><code>add_variables()</code> specifies the terms of the model through the usage of
<a href="tidyselect.html#topic+language">tidyselect::select_helpers</a> for the <code>outcomes</code> and <code>predictors</code>.
</p>
</li>
<li> <p><code>remove_variables()</code> removes the variables. Additionally, if the model
has already been fit, then the fit is removed.
</p>
</li>
<li> <p><code>update_variables()</code> first removes the variables, then replaces the
previous variables with the new ones. Any model that has already been
fit based on the original variables will need to be refit.
</p>
</li>
<li> <p><code>workflow_variables()</code> bundles <code>outcomes</code> and <code>predictors</code> into a single
variables object, which can be supplied to <code>add_variables()</code>.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>add_variables(x, outcomes, predictors, ..., blueprint = NULL, variables = NULL)

remove_variables(x)

update_variables(
  x,
  outcomes,
  predictors,
  ...,
  blueprint = NULL,
  variables = NULL
)

workflow_variables(outcomes, predictors)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_variables_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="add_variables_+3A_outcomes">outcomes</code>, <code id="add_variables_+3A_predictors">predictors</code></td>
<td>
<p>Tidyselect expressions specifying the terms
of the model. <code>outcomes</code> is evaluated first, and then all outcome columns
are removed from the data before <code>predictors</code> is evaluated.
See <a href="tidyselect.html#topic+language">tidyselect::select_helpers</a> for the full range of possible ways to
specify terms.</p>
</td></tr>
<tr><td><code id="add_variables_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="add_variables_+3A_blueprint">blueprint</code></td>
<td>
<p>A hardhat blueprint used for fine tuning the preprocessing.
</p>
<p>If <code>NULL</code>, <code><a href="hardhat.html#topic+default_xy_blueprint">hardhat::default_xy_blueprint()</a></code> is used.
</p>
<p>Note that preprocessing done here is separate from preprocessing that
might be done by the underlying model.</p>
</td></tr>
<tr><td><code id="add_variables_+3A_variables">variables</code></td>
<td>
<p>An alternative specification of <code>outcomes</code> and <code>predictors</code>,
useful for supplying variables programmatically.
</p>

<ul>
<li><p> If <code>NULL</code>, this argument is unused, and <code>outcomes</code> and <code>predictors</code> are
used to specify the variables.
</p>
</li>
<li><p> Otherwise, this must be the result of calling <code>workflow_variables()</code> to
create a standalone variables object. In this case, <code>outcomes</code> and
<code>predictors</code> are completely ignored.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>To fit a workflow, exactly one of <code><a href="#topic+add_formula">add_formula()</a></code>, <code><a href="#topic+add_recipe">add_recipe()</a></code>, or
<code><a href="#topic+add_variables">add_variables()</a></code> <em>must</em> be specified.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>add_variables()</code> returns <code>x</code> with a new variables preprocessor.
</p>
</li>
<li> <p><code>remove_variables()</code> returns <code>x</code> after resetting any model fit and
removing the variables preprocessor.
</p>
</li>
<li> <p><code>update_variables()</code> returns <code>x</code> after removing the variables preprocessor,
and then re-specifying it with new variables.
</p>
</li>
<li> <p><code>workflow_variables()</code> returns a 'workflow_variables' object containing
both the <code>outcomes</code> and <code>predictors</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(parsnip)

spec_lm &lt;- linear_reg()
spec_lm &lt;- set_engine(spec_lm, "lm")

workflow &lt;- workflow()
workflow &lt;- add_model(workflow, spec_lm)

# Add terms with tidyselect expressions.
# Outcomes are specified before predictors.
workflow1 &lt;- add_variables(
  workflow,
  outcomes = mpg,
  predictors = c(cyl, disp)
)

workflow1 &lt;- fit(workflow1, mtcars)
workflow1

# Removing the variables of a fit workflow will also remove the model
remove_variables(workflow1)

# Variables can also be updated
update_variables(workflow1, mpg, starts_with("d"))

# The `outcomes` are removed before the `predictors` expression
# is evaluated. This allows you to easily specify the predictors
# as "everything except the outcomes".
workflow2 &lt;- add_variables(workflow, mpg, everything())
workflow2 &lt;- fit(workflow2, mtcars)
extract_mold(workflow2)$predictors

# Variables can also be added from the result of a call to
# `workflow_variables()`, which creates a standalone variables object
variables &lt;- workflow_variables(mpg, c(cyl, disp))
workflow3 &lt;- add_variables(workflow, variables = variables)
fit(workflow3, mtcars)
</code></pre>

<hr>
<h2 id='augment.workflow'>Augment data with predictions</h2><span id='topic+augment.workflow'></span>

<h3>Description</h3>

<p>This is a <code><a href="generics.html#topic+augment">generics::augment()</a></code> method for a workflow that calls
<code>augment()</code> on the underlying parsnip model with <code>new_data</code>.
</p>
<p><code>x</code> must be a trained workflow, resulting in fitted parsnip model to
<code>augment()</code> with.
</p>
<p><code>new_data</code> will be preprocessed using the preprocessor in the workflow,
and that preprocessed data will be used to generate predictions. The
final result will contain the original <code>new_data</code> with new columns containing
the prediction information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow'
augment(x, new_data, eval_time = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="augment.workflow_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="augment.workflow_+3A_new_data">new_data</code></td>
<td>
<p>A data frame of predictors</p>
</td></tr>
<tr><td><code id="augment.workflow_+3A_eval_time">eval_time</code></td>
<td>
<p>For censored regression models, a vector of time points at
which the survival probability is estimated. See
<code><a href="parsnip.html#topic+augment">parsnip::augment.model_fit()</a></code> for more details.</p>
</td></tr>
<tr><td><code id="augment.workflow_+3A_...">...</code></td>
<td>
<p>Arguments passed on to methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>new_data</code> with new prediction specific columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (rlang::is_installed("broom")) {

library(parsnip)
library(magrittr)
library(modeldata)

data("attrition")

model &lt;- logistic_reg() %&gt;%
  set_engine("glm")

wf &lt;- workflow() %&gt;%
  add_model(model) %&gt;%
  add_formula(
    Attrition ~ BusinessTravel + YearsSinceLastPromotion + OverTime
  )

wf_fit &lt;- fit(wf, attrition)

augment(wf_fit, attrition)

}
</code></pre>

<hr>
<h2 id='control_workflow'>Control object for a workflow</h2><span id='topic+control_workflow'></span>

<h3>Description</h3>

<p><code>control_workflow()</code> holds the control parameters for a workflow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>control_workflow(control_parsnip = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="control_workflow_+3A_control_parsnip">control_parsnip</code></td>
<td>
<p>A parsnip control object. If <code>NULL</code>, a default control
argument is constructed from <code><a href="parsnip.html#topic+control_parsnip">parsnip::control_parsnip()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>control_workflow</code> object for tweaking the workflow fitting process.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>control_workflow()
</code></pre>

<hr>
<h2 id='extract-workflow'>Extract elements of a workflow</h2><span id='topic+extract-workflow'></span><span id='topic+extract_spec_parsnip.workflow'></span><span id='topic+extract_recipe.workflow'></span><span id='topic+extract_fit_parsnip.workflow'></span><span id='topic+extract_fit_engine.workflow'></span><span id='topic+extract_mold.workflow'></span><span id='topic+extract_preprocessor.workflow'></span><span id='topic+extract_parameter_set_dials.workflow'></span><span id='topic+extract_parameter_dials.workflow'></span><span id='topic+extract_fit_time.workflow'></span>

<h3>Description</h3>

<p>These functions extract various elements from a workflow object. If they do
not exist yet, an error is thrown.
</p>

<ul>
<li> <p><code>extract_preprocessor()</code> returns the formula, recipe, or variable
expressions used for preprocessing.
</p>
</li>
<li> <p><code>extract_spec_parsnip()</code> returns the parsnip model specification.
</p>
</li>
<li> <p><code>extract_fit_parsnip()</code> returns the parsnip model fit object.
</p>
</li>
<li> <p><code>extract_fit_engine()</code> returns the engine specific fit embedded within
a parsnip model fit. For example, when using <code><a href="parsnip.html#topic+linear_reg">parsnip::linear_reg()</a></code>
with the <code>"lm"</code> engine, this returns the underlying <code>lm</code> object.
</p>
</li>
<li> <p><code>extract_mold()</code> returns the preprocessed &quot;mold&quot; object returned
from <code><a href="hardhat.html#topic+mold">hardhat::mold()</a></code>. It contains information about the preprocessing,
including either the prepped recipe, the formula terms object, or
variable selectors.
</p>
</li>
<li> <p><code>extract_recipe()</code> returns the recipe. The <code>estimated</code> argument specifies
whether the fitted or original recipe is returned.
</p>
</li>
<li> <p><code>extract_parameter_dials()</code> returns a single dials parameter object.
</p>
</li>
<li> <p><code>extract_parameter_set_dials()</code> returns a set of dials parameter objects.
</p>
</li>
<li> <p><code>extract_fit_time()</code> returns a tibble with elapsed fit times. The fit
times correspond to the time for the parsnip engine or recipe steps to fit
(or their sum if <code>summarize = TRUE</code>) and do not include other portions of
the elapsed time in <code><a href="#topic+fit.workflow">fit.workflow()</a></code>.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow'
extract_spec_parsnip(x, ...)

## S3 method for class 'workflow'
extract_recipe(x, ..., estimated = TRUE)

## S3 method for class 'workflow'
extract_fit_parsnip(x, ...)

## S3 method for class 'workflow'
extract_fit_engine(x, ...)

## S3 method for class 'workflow'
extract_mold(x, ...)

## S3 method for class 'workflow'
extract_preprocessor(x, ...)

## S3 method for class 'workflow'
extract_parameter_set_dials(x, ...)

## S3 method for class 'workflow'
extract_parameter_dials(x, parameter, ...)

## S3 method for class 'workflow'
extract_fit_time(x, summarize = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract-workflow_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="extract-workflow_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
<tr><td><code id="extract-workflow_+3A_estimated">estimated</code></td>
<td>
<p>A logical for whether the original (unfit) recipe or the
fitted recipe should be returned. This argument should be named.</p>
</td></tr>
<tr><td><code id="extract-workflow_+3A_parameter">parameter</code></td>
<td>
<p>A single string for the parameter ID.</p>
</td></tr>
<tr><td><code id="extract-workflow_+3A_summarize">summarize</code></td>
<td>
<p>A logical for whether the elapsed fit time should be returned as a
single row or multiple rows.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extracting the underlying engine fit can be helpful for describing the
model (via <code>print()</code>, <code>summary()</code>, <code>plot()</code>, etc.) or for variable
importance/explainers.
</p>
<p>However, users should not invoke the <code>predict()</code> method on an extracted
model. There may be preprocessing operations that <code>workflows</code> has executed on
the data prior to giving it to the model. Bypassing these can lead to errors
or silently generating incorrect predictions.
</p>
<p><em>Good</em>:
</p>
<div class="sourceCode r"><pre>workflow_fit %&gt;% predict(new_data)
</pre></div>
<p><em>Bad</em>:
</p>
<div class="sourceCode r"><pre>workflow_fit %&gt;% extract_fit_engine()  %&gt;% predict(new_data)
# or
workflow_fit %&gt;% extract_fit_parsnip() %&gt;% predict(new_data)
</pre></div>


<h3>Value</h3>

<p>The extracted value from the object, <code>x</code>, as described in the description
section.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parsnip)
library(recipes)
library(magrittr)

model &lt;- linear_reg() %&gt;%
  set_engine("lm")

recipe &lt;- recipe(mpg ~ cyl + disp, mtcars) %&gt;%
  step_log(disp)

base_wf &lt;- workflow() %&gt;%
  add_model(model)

recipe_wf &lt;- add_recipe(base_wf, recipe)
formula_wf &lt;- add_formula(base_wf, mpg ~ cyl + log(disp))
variable_wf &lt;- add_variables(base_wf, mpg, c(cyl, disp))

fit_recipe_wf &lt;- fit(recipe_wf, mtcars)
fit_formula_wf &lt;- fit(formula_wf, mtcars)

# The preprocessor is a recipe, formula, or a list holding the
# tidyselect expressions identifying the outcomes/predictors
extract_preprocessor(recipe_wf)
extract_preprocessor(formula_wf)
extract_preprocessor(variable_wf)

# The `spec` is the parsnip spec before it has been fit.
# The `fit` is the fitted parsnip model.
extract_spec_parsnip(fit_formula_wf)
extract_fit_parsnip(fit_formula_wf)
extract_fit_engine(fit_formula_wf)

# The mold is returned from `hardhat::mold()`, and contains the
# predictors, outcomes, and information about the preprocessing
# for use on new data at `predict()` time.
extract_mold(fit_recipe_wf)

# A useful shortcut is to extract the fitted recipe from the workflow
extract_recipe(fit_recipe_wf)

# That is identical to
identical(
  extract_mold(fit_recipe_wf)$blueprint$recipe,
  extract_recipe(fit_recipe_wf)
)

</code></pre>

<hr>
<h2 id='fit-workflow'>Fit a workflow object</h2><span id='topic+fit-workflow'></span><span id='topic+fit.workflow'></span>

<h3>Description</h3>

<p>Fitting a workflow currently involves two main steps:
</p>

<ul>
<li><p> Preprocessing the data using a formula preprocessor, or by calling
<code><a href="recipes.html#topic+prep">recipes::prep()</a></code> on a recipe.
</p>
</li>
<li><p> Fitting the underlying parsnip model using <code><a href="parsnip.html#topic+fit">parsnip::fit.model_spec()</a></code>.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow'
fit(object, data, ..., control = control_workflow())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit-workflow_+3A_object">object</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="fit-workflow_+3A_data">data</code></td>
<td>
<p>A data frame of predictors and outcomes to use when fitting the
workflow</p>
</td></tr>
<tr><td><code id="fit-workflow_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="fit-workflow_+3A_control">control</code></td>
<td>
<p>A <code><a href="#topic+control_workflow">control_workflow()</a></code> object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the future, there will also be <em>postprocessing</em> steps that can be added
after the model has been fit.
</p>


<h3>Value</h3>

<p>The workflow <code>object</code>, updated with a fit parsnip model in the
<code>object$fit$fit</code> slot.
</p>


<h3>Indicator Variable Details</h3>

<p>Some modeling functions in R create indicator/dummy variables from
categorical data when you use a model formula, and some do not. When you
specify and fit a model with a <code>workflow()</code>, parsnip and workflows match
and reproduce the underlying behavior of the user-specified model’s
computational engine.
</p>


<h4>Formula Preprocessor</h4>

<p>In the <a href="modeldata.html#topic+Sacramento">modeldata::Sacramento</a> data set of real
estate prices, the <code>type</code> variable has three levels: <code>"Residential"</code>,
<code>"Condo"</code>, and <code>"Multi-Family"</code>. This base <code>workflow()</code> contains a
formula added via <code><a href="#topic+add_formula">add_formula()</a></code> to predict property
price from property type, square footage, number of beds, and number of
baths:
</p>
<div class="sourceCode r"><pre>set.seed(123)

library(parsnip)
library(recipes)
library(workflows)
library(modeldata)

data("Sacramento")

base_wf &lt;- workflow() %&gt;%
  add_formula(price ~ type + sqft + beds + baths)
</pre></div>
<p>This first model does create dummy/indicator variables:
</p>
<div class="sourceCode r"><pre>lm_spec &lt;- linear_reg() %&gt;%
  set_engine("lm")

base_wf %&gt;%
  add_model(lm_spec) %&gt;%
  fit(Sacramento)
</pre></div>
<div class="sourceCode"><pre>## == Workflow [trained] ================================================
## Preprocessor: Formula
## Model: linear_reg()
## 
## -- Preprocessor ------------------------------------------------------
## price ~ type + sqft + beds + baths
## 
## -- Model -------------------------------------------------------------
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
##      (Intercept)  typeMulti_Family   typeResidential  
##          32919.4          -21995.8           33688.6  
##             sqft              beds             baths  
##            156.2          -29788.0            8730.0
</pre></div>
<p>There are <strong>five</strong> independent variables in the fitted model for this
OLS linear regression. With this model type and engine, the factor
predictor <code>type</code> of the real estate properties was converted to two
binary predictors, <code>typeMulti_Family</code> and <code>typeResidential</code>. (The third
type, for condos, does not need its own column because it is the
baseline level).
</p>
<p>This second model does not create dummy/indicator variables:
</p>
<div class="sourceCode r"><pre>rf_spec &lt;- rand_forest() %&gt;%
  set_mode("regression") %&gt;%
  set_engine("ranger")

base_wf %&gt;%
  add_model(rf_spec) %&gt;%
  fit(Sacramento)
</pre></div>
<div class="sourceCode"><pre>## == Workflow [trained] ================================================
## Preprocessor: Formula
## Model: rand_forest()
## 
## -- Preprocessor ------------------------------------------------------
## price ~ type + sqft + beds + baths
## 
## -- Model -------------------------------------------------------------
## Ranger result
## 
## Call:
##  ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) 
## 
## Type:                             Regression 
## Number of trees:                  500 
## Sample size:                      932 
## Number of independent variables:  4 
## Mtry:                             2 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       7058847504 
## R squared (OOB):                  0.5894647
</pre></div>
<p>Note that there are <strong>four</strong> independent variables in the fitted model
for this ranger random forest. With this model type and engine,
indicator variables were not created for the <code>type</code> of real estate
property being sold. Tree-based models such as random forest models can
handle factor predictors directly, and don’t need any conversion to
numeric binary variables.
</p>



<h4>Recipe Preprocessor</h4>

<p>When you specify a model with a <code>workflow()</code> and a recipe preprocessor
via <code><a href="#topic+add_recipe">add_recipe()</a></code>, the <em>recipe</em> controls whether dummy
variables are created or not; the recipe overrides any underlying
behavior from the model’s computational engine.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>
library(parsnip)
library(recipes)
library(magrittr)

model &lt;- linear_reg() %&gt;%
  set_engine("lm")

base_wf &lt;- workflow() %&gt;%
  add_model(model)

formula_wf &lt;- base_wf %&gt;%
  add_formula(mpg ~ cyl + log(disp))

fit(formula_wf, mtcars)

recipe &lt;- recipe(mpg ~ cyl + disp, mtcars) %&gt;%
  step_log(disp)

recipe_wf &lt;- base_wf %&gt;%
  add_recipe(recipe)

fit(recipe_wf, mtcars)

</code></pre>

<hr>
<h2 id='glance.workflow'>Glance at a workflow model</h2><span id='topic+glance.workflow'></span>

<h3>Description</h3>

<p>This is a <code><a href="generics.html#topic+glance">generics::glance()</a></code> method for a workflow that calls <code>glance()</code> on
the underlying parsnip model.
</p>
<p><code>x</code> must be a trained workflow, resulting in fitted parsnip model to
<code>glance()</code> at.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow'
glance(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glance.workflow_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="glance.workflow_+3A_...">...</code></td>
<td>
<p>Arguments passed on to methods</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>if (rlang::is_installed(c("broom", "modeldata"))) {

library(parsnip)
library(magrittr)
library(modeldata)

data("attrition")

model &lt;- logistic_reg() %&gt;%
  set_engine("glm")

wf &lt;- workflow() %&gt;%
  add_model(model) %&gt;%
  add_formula(
    Attrition ~ BusinessTravel + YearsSinceLastPromotion + OverTime
  )

# Workflow must be trained to call `glance()`
try(glance(wf))

wf_fit &lt;- fit(wf, attrition)

glance(wf_fit)

}
</code></pre>

<hr>
<h2 id='is_trained_workflow'>Determine if a workflow has been trained</h2><span id='topic+is_trained_workflow'></span>

<h3>Description</h3>

<p>A trained workflow is one that has gone through <code><a href="#topic+fit.workflow">fit()</a></code>,
which preprocesses the underlying data, and fits the parsnip model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_trained_workflow(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_trained_workflow_+3A_x">x</code></td>
<td>
<p>A workflow.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single logical indicating if the workflow has been trained or not.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parsnip)
library(recipes)
library(magrittr)

rec &lt;- recipe(mpg ~ cyl, mtcars)

mod &lt;- linear_reg()
mod &lt;- set_engine(mod, "lm")

wf &lt;- workflow() %&gt;%
  add_recipe(rec) %&gt;%
  add_model(mod)

# Before any preprocessing or model fitting has been done
is_trained_workflow(wf)

wf &lt;- fit(wf, mtcars)

# After all preprocessing and model fitting
is_trained_workflow(wf)

</code></pre>

<hr>
<h2 id='predict-workflow'>Predict from a workflow</h2><span id='topic+predict-workflow'></span><span id='topic+predict.workflow'></span>

<h3>Description</h3>

<p>This is the <code>predict()</code> method for a fit workflow object. The nice thing
about predicting from a workflow is that it will:
</p>

<ul>
<li><p> Preprocess <code>new_data</code> using the preprocessing method specified when the
workflow was created and fit. This is accomplished using
<code><a href="hardhat.html#topic+forge">hardhat::forge()</a></code>, which will apply any formula preprocessing or call
<code><a href="recipes.html#topic+bake">recipes::bake()</a></code> if a recipe was supplied.
</p>
</li>
<li><p> Call <code><a href="parsnip.html#topic+predict.model_fit">parsnip::predict.model_fit()</a></code> for you using the underlying fit
parsnip model.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow'
predict(object, new_data, type = NULL, opts = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict-workflow_+3A_object">object</code></td>
<td>
<p>A workflow that has been fit by <code><a href="#topic+fit.workflow">fit.workflow()</a></code></p>
</td></tr>
<tr><td><code id="predict-workflow_+3A_new_data">new_data</code></td>
<td>
<p>A data frame containing the new predictors to preprocess
and predict on. If using a recipe preprocessor, you should not call
<code><a href="recipes.html#topic+bake">recipes::bake()</a></code> on <code>new_data</code> before passing to this function.</p>
</td></tr>
<tr><td><code id="predict-workflow_+3A_type">type</code></td>
<td>
<p>A single character value or <code>NULL</code>. Possible values
are <code>"numeric"</code>, <code>"class"</code>, <code>"prob"</code>, <code>"conf_int"</code>, <code>"pred_int"</code>,
<code>"quantile"</code>, <code>"time"</code>, <code>"hazard"</code>, <code>"survival"</code>, or <code>"raw"</code>. When <code>NULL</code>,
<code>predict()</code> will choose an appropriate value based on the model's mode.</p>
</td></tr>
<tr><td><code id="predict-workflow_+3A_opts">opts</code></td>
<td>
<p>A list of optional arguments to the underlying
predict function that will be used when <code>type = "raw"</code>. The
list should not include options for the model object or the
new data being predicted.</p>
</td></tr>
<tr><td><code id="predict-workflow_+3A_...">...</code></td>
<td>
<p>Additional <code>parsnip</code>-related options, depending on the
value of <code>type</code>. Arguments to the underlying model's prediction
function cannot be passed here (use the <code>opts</code> argument instead).
Possible arguments are:
</p>

<ul>
<li> <p><code>interval</code>: for <code>type</code> equal to <code>"survival"</code> or <code>"quantile"</code>, should
interval estimates be added, if available? Options are <code>"none"</code>
and <code>"confidence"</code>.
</p>
</li>
<li> <p><code>level</code>: for <code>type</code> equal to <code>"conf_int"</code>, <code>"pred_int"</code>, or <code>"survival"</code>,
this is the parameter for the tail area of the intervals
(e.g. confidence level for confidence intervals).
Default value is <code>0.95</code>.
</p>
</li>
<li> <p><code>std_error</code>: for <code>type</code> equal to <code>"conf_int"</code> or <code>"pred_int"</code>, add
the standard error of fit or prediction (on the scale of the
linear predictors). Default value is <code>FALSE</code>.
</p>
</li>
<li> <p><code>quantile</code>: for <code>type</code> equal to <code>quantile</code>, the quantiles of the
distribution. Default is <code>(1:9)/10</code>.
</p>
</li>
<li> <p><code>eval_time</code>: for <code>type</code> equal to <code>"survival"</code> or <code>"hazard"</code>, the
time points at which the survival probability or hazard is estimated.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of model predictions, with as many rows as <code>new_data</code> has.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parsnip)
library(recipes)
library(magrittr)

training &lt;- mtcars[1:20, ]
testing &lt;- mtcars[21:32, ]

model &lt;- linear_reg() %&gt;%
  set_engine("lm")

workflow &lt;- workflow() %&gt;%
  add_model(model)

recipe &lt;- recipe(mpg ~ cyl + disp, training) %&gt;%
  step_log(disp)

workflow &lt;- add_recipe(workflow, recipe)

fit_workflow &lt;- fit(workflow, training)

# This will automatically `bake()` the recipe on `testing`,
# applying the log step to `disp`, and then fit the regression.
predict(fit_workflow, testing)

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+extract_spec_parsnip'></span><span id='topic+extract_recipe'></span><span id='topic+extract_fit_parsnip'></span><span id='topic+extract_fit_engine'></span><span id='topic+extract_mold'></span><span id='topic+extract_preprocessor'></span><span id='topic+extract_parameter_set_dials'></span><span id='topic+extract_parameter_dials'></span><span id='topic+extract_fit_time'></span><span id='topic+required_pkgs'></span><span id='topic+fit'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+fit">fit</a></code>, <code><a href="generics.html#topic+required_pkgs">required_pkgs</a></code></p>
</dd>
<dt>hardhat</dt><dd><p><code><a href="hardhat.html#topic+hardhat-extract">extract_fit_engine</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_fit_parsnip</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_fit_time</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_mold</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_parameter_dials</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_parameter_set_dials</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_preprocessor</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_recipe</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_spec_parsnip</a></code></p>
</dd>
</dl>

<hr>
<h2 id='tidy.workflow'>Tidy a workflow</h2><span id='topic+tidy.workflow'></span>

<h3>Description</h3>

<p>This is a <code><a href="generics.html#topic+tidy">generics::tidy()</a></code> method for a workflow that calls <code>tidy()</code> on
either the underlying parsnip model or the recipe, depending on the value
of <code>what</code>.
</p>
<p><code>x</code> must be a fitted workflow, resulting in fitted parsnip model or prepped
recipe that you want to tidy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow'
tidy(x, what = "model", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tidy.workflow_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
<tr><td><code id="tidy.workflow_+3A_what">what</code></td>
<td>
<p>A single string. Either <code>"model"</code> or <code>"recipe"</code> to select
which part of the workflow to tidy. Defaults to tidying the model.</p>
</td></tr>
<tr><td><code id="tidy.workflow_+3A_...">...</code></td>
<td>
<p>Arguments passed on to methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To tidy the unprepped recipe, use <code><a href="#topic+extract_preprocessor">extract_preprocessor()</a></code> and <code>tidy()</code>
that directly.
</p>

<hr>
<h2 id='workflow'>Create a workflow</h2><span id='topic+workflow'></span>

<h3>Description</h3>

<p>A <code>workflow</code> is a container object that aggregates information required to
fit and predict from a model. This information might be a recipe used in
preprocessing, specified through <code><a href="#topic+add_recipe">add_recipe()</a></code>, or the model specification
to fit, specified through <code><a href="#topic+add_model">add_model()</a></code>.
</p>
<p>The <code>preprocessor</code> and <code>spec</code> arguments allow you to add components to a
workflow quickly, without having to go through the <code style="white-space: pre;">&#8288;add_*()&#8288;</code> functions, such
as <code><a href="#topic+add_recipe">add_recipe()</a></code> or <code><a href="#topic+add_model">add_model()</a></code>. However, if you need to control any of
the optional arguments to those functions, such as the <code>blueprint</code> or the
model <code>formula</code>, then you should use the <code style="white-space: pre;">&#8288;add_*()&#8288;</code> functions directly
instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>workflow(preprocessor = NULL, spec = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="workflow_+3A_preprocessor">preprocessor</code></td>
<td>
<p>An optional preprocessor to add to the workflow. One of:
</p>

<ul>
<li><p> A formula, passed on to <code><a href="#topic+add_formula">add_formula()</a></code>.
</p>
</li>
<li><p> A recipe, passed on to <code><a href="#topic+add_recipe">add_recipe()</a></code>.
</p>
</li>
<li><p> A <code><a href="#topic+workflow_variables">workflow_variables()</a></code> object, passed on to <code><a href="#topic+add_variables">add_variables()</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="workflow_+3A_spec">spec</code></td>
<td>
<p>An optional parsnip model specification to add to the workflow.
Passed on to <code><a href="#topic+add_model">add_model()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new <code>workflow</code> object.
</p>


<h3>Indicator Variable Details</h3>

<p>Some modeling functions in R create indicator/dummy variables from
categorical data when you use a model formula, and some do not. When you
specify and fit a model with a <code>workflow()</code>, parsnip and workflows match
and reproduce the underlying behavior of the user-specified model’s
computational engine.
</p>


<h4>Formula Preprocessor</h4>

<p>In the <a href="modeldata.html#topic+Sacramento">modeldata::Sacramento</a> data set of real
estate prices, the <code>type</code> variable has three levels: <code>"Residential"</code>,
<code>"Condo"</code>, and <code>"Multi-Family"</code>. This base <code>workflow()</code> contains a
formula added via <code><a href="#topic+add_formula">add_formula()</a></code> to predict property
price from property type, square footage, number of beds, and number of
baths:
</p>
<div class="sourceCode r"><pre>set.seed(123)

library(parsnip)
library(recipes)
library(workflows)
library(modeldata)

data("Sacramento")

base_wf &lt;- workflow() %&gt;%
  add_formula(price ~ type + sqft + beds + baths)
</pre></div>
<p>This first model does create dummy/indicator variables:
</p>
<div class="sourceCode r"><pre>lm_spec &lt;- linear_reg() %&gt;%
  set_engine("lm")

base_wf %&gt;%
  add_model(lm_spec) %&gt;%
  fit(Sacramento)
</pre></div>
<div class="sourceCode"><pre>## == Workflow [trained] ================================================
## Preprocessor: Formula
## Model: linear_reg()
## 
## -- Preprocessor ------------------------------------------------------
## price ~ type + sqft + beds + baths
## 
## -- Model -------------------------------------------------------------
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
##      (Intercept)  typeMulti_Family   typeResidential  
##          32919.4          -21995.8           33688.6  
##             sqft              beds             baths  
##            156.2          -29788.0            8730.0
</pre></div>
<p>There are <strong>five</strong> independent variables in the fitted model for this
OLS linear regression. With this model type and engine, the factor
predictor <code>type</code> of the real estate properties was converted to two
binary predictors, <code>typeMulti_Family</code> and <code>typeResidential</code>. (The third
type, for condos, does not need its own column because it is the
baseline level).
</p>
<p>This second model does not create dummy/indicator variables:
</p>
<div class="sourceCode r"><pre>rf_spec &lt;- rand_forest() %&gt;%
  set_mode("regression") %&gt;%
  set_engine("ranger")

base_wf %&gt;%
  add_model(rf_spec) %&gt;%
  fit(Sacramento)
</pre></div>
<div class="sourceCode"><pre>## == Workflow [trained] ================================================
## Preprocessor: Formula
## Model: rand_forest()
## 
## -- Preprocessor ------------------------------------------------------
## price ~ type + sqft + beds + baths
## 
## -- Model -------------------------------------------------------------
## Ranger result
## 
## Call:
##  ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) 
## 
## Type:                             Regression 
## Number of trees:                  500 
## Sample size:                      932 
## Number of independent variables:  4 
## Mtry:                             2 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       7058847504 
## R squared (OOB):                  0.5894647
</pre></div>
<p>Note that there are <strong>four</strong> independent variables in the fitted model
for this ranger random forest. With this model type and engine,
indicator variables were not created for the <code>type</code> of real estate
property being sold. Tree-based models such as random forest models can
handle factor predictors directly, and don’t need any conversion to
numeric binary variables.
</p>



<h4>Recipe Preprocessor</h4>

<p>When you specify a model with a <code>workflow()</code> and a recipe preprocessor
via <code><a href="#topic+add_recipe">add_recipe()</a></code>, the <em>recipe</em> controls whether dummy
variables are created or not; the recipe overrides any underlying
behavior from the model’s computational engine.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>
library(parsnip)
library(recipes)
library(magrittr)
library(modeldata)

data("attrition")

model &lt;- logistic_reg() %&gt;%
  set_engine("glm")

formula &lt;- Attrition ~ BusinessTravel + YearsSinceLastPromotion + OverTime

wf_formula &lt;- workflow(formula, model)

fit(wf_formula, attrition)

recipe &lt;- recipe(Attrition ~ ., attrition) %&gt;%
  step_dummy(all_nominal(), -Attrition) %&gt;%
  step_corr(all_predictors(), threshold = 0.8)

wf_recipe &lt;- workflow(recipe, model)

fit(wf_recipe, attrition)

variables &lt;- workflow_variables(
  Attrition,
  c(BusinessTravel, YearsSinceLastPromotion, OverTime)
)

wf_variables &lt;- workflow(variables, model)

fit(wf_variables, attrition)

</code></pre>

<hr>
<h2 id='workflow-butcher'>Butcher methods for a workflow</h2><span id='topic+workflow-butcher'></span><span id='topic+axe_call.workflow'></span><span id='topic+axe_ctrl.workflow'></span><span id='topic+axe_data.workflow'></span><span id='topic+axe_env.workflow'></span><span id='topic+axe_fitted.workflow'></span>

<h3>Description</h3>

<p>These methods allow you to use the butcher package to reduce the size of
a workflow. After calling <code>butcher::butcher()</code> on a workflow, the only
guarantee is that you will still be able to <code>predict()</code> from that workflow.
Other functions may not work as expected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>axe_call.workflow(x, verbose = FALSE, ...)

axe_ctrl.workflow(x, verbose = FALSE, ...)

axe_data.workflow(x, verbose = FALSE, ...)

axe_env.workflow(x, verbose = FALSE, ...)

axe_fitted.workflow(x, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="workflow-butcher_+3A_x">x</code></td>
<td>
<p>A workflow.</p>
</td></tr>
<tr><td><code id="workflow-butcher_+3A_verbose">verbose</code></td>
<td>
<p>Should information be printed about how much memory is freed
from butchering?</p>
</td></tr>
<tr><td><code id="workflow-butcher_+3A_...">...</code></td>
<td>
<p>Extra arguments possibly used by underlying methods.</p>
</td></tr>
</table>

<hr>
<h2 id='workflow-extractors'>Extract elements of a workflow</h2><span id='topic+workflow-extractors'></span><span id='topic+pull_workflow_preprocessor'></span><span id='topic+pull_workflow_spec'></span><span id='topic+pull_workflow_fit'></span><span id='topic+pull_workflow_mold'></span><span id='topic+pull_workflow_prepped_recipe'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#soft-deprecated"><img src="../help/figures/lifecycle-soft-deprecated.svg" alt='[Soft-deprecated]' /></a>
</p>
<p>Please use the <code style="white-space: pre;">&#8288;extract_*()&#8288;</code> functions instead of these
(e.g. <code><a href="#topic+extract_mold">extract_mold()</a></code>).
</p>
<p>These functions extract various elements from a workflow object. If they do
not exist yet, an error is thrown.
</p>

<ul>
<li> <p><code>pull_workflow_preprocessor()</code> returns the formula, recipe, or variable
expressions used for preprocessing.
</p>
</li>
<li> <p><code>pull_workflow_spec()</code> returns the parsnip model specification.
</p>
</li>
<li> <p><code>pull_workflow_fit()</code> returns the parsnip model fit.
</p>
</li>
<li> <p><code>pull_workflow_mold()</code> returns the preprocessed &quot;mold&quot; object returned
from <code><a href="hardhat.html#topic+mold">hardhat::mold()</a></code>. It contains information about the preprocessing,
including either the prepped recipe or the formula terms object.
</p>
</li>
<li> <p><code>pull_workflow_prepped_recipe()</code> returns the prepped recipe. It is
extracted from the mold object returned from <code>pull_workflow_mold()</code>.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>pull_workflow_preprocessor(x)

pull_workflow_spec(x)

pull_workflow_fit(x)

pull_workflow_mold(x)

pull_workflow_prepped_recipe(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="workflow-extractors_+3A_x">x</code></td>
<td>
<p>A workflow</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The extracted value from the workflow, <code>x</code>, as described in the description
section.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parsnip)
library(recipes)
library(magrittr)

model &lt;- linear_reg() %&gt;%
  set_engine("lm")

recipe &lt;- recipe(mpg ~ cyl + disp, mtcars) %&gt;%
  step_log(disp)

base_wf &lt;- workflow() %&gt;%
  add_model(model)

recipe_wf &lt;- add_recipe(base_wf, recipe)
formula_wf &lt;- add_formula(base_wf, mpg ~ cyl + log(disp))
variable_wf &lt;- add_variables(base_wf, mpg, c(cyl, disp))

fit_recipe_wf &lt;- fit(recipe_wf, mtcars)
fit_formula_wf &lt;- fit(formula_wf, mtcars)

# The preprocessor is a recipes, formula, or a list holding the
# tidyselect expressions identifying the outcomes/predictors
pull_workflow_preprocessor(recipe_wf)
pull_workflow_preprocessor(formula_wf)
pull_workflow_preprocessor(variable_wf)

# The `spec` is the parsnip spec before it has been fit.
# The `fit` is the fit parsnip model.
pull_workflow_spec(fit_formula_wf)
pull_workflow_fit(fit_formula_wf)

# The mold is returned from `hardhat::mold()`, and contains the
# predictors, outcomes, and information about the preprocessing
# for use on new data at `predict()` time.
pull_workflow_mold(fit_recipe_wf)

# A useful shortcut is to extract the prepped recipe from the workflow
pull_workflow_prepped_recipe(fit_recipe_wf)

# That is identical to
identical(
  pull_workflow_mold(fit_recipe_wf)$blueprint$recipe,
  pull_workflow_prepped_recipe(fit_recipe_wf)
)

</code></pre>

<hr>
<h2 id='workflows-internals'>Internal workflow functions</h2><span id='topic+workflows-internals'></span><span id='topic+.fit_pre'></span><span id='topic+.fit_model'></span><span id='topic+.fit_finalize'></span>

<h3>Description</h3>

<p><code>.fit_pre()</code>, <code>.fit_model()</code>, and <code>.fit_finalize()</code> are internal workflow
functions for <em>partially</em> fitting a workflow object. They are only exported
for usage by the tuning package, <a href="https://github.com/tidymodels/tune">tune</a>,
and the general user should never need to worry about them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.fit_pre(workflow, data)

.fit_model(workflow, control)

.fit_finalize(workflow)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="workflows-internals_+3A_workflow">workflow</code></td>
<td>
<p>A workflow
</p>
<p>For <code>.fit_pre()</code>, this should be a fresh workflow.
</p>
<p>For <code>.fit_model()</code>, this should be a workflow that has already been trained
through <code>.fit_pre()</code>.
</p>
<p>For <code>.fit_finalize()</code>, this should be a workflow that has been through
both <code>.fit_pre()</code> and <code>.fit_model()</code>.</p>
</td></tr>
<tr><td><code id="workflows-internals_+3A_data">data</code></td>
<td>
<p>A data frame of predictors and outcomes to use when fitting the
workflow</p>
</td></tr>
<tr><td><code id="workflows-internals_+3A_control">control</code></td>
<td>
<p>A <code><a href="#topic+control_workflow">control_workflow()</a></code> object</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parsnip)
library(recipes)
library(magrittr)

model &lt;- linear_reg() %&gt;%
  set_engine("lm")

wf_unfit &lt;- workflow() %&gt;%
  add_model(model) %&gt;%
  add_formula(mpg ~ cyl + log(disp))

wf_fit_pre &lt;- .fit_pre(wf_unfit, mtcars)
wf_fit_model &lt;- .fit_model(wf_fit_pre, control_workflow())
wf_fit &lt;- .fit_finalize(wf_fit_model)

# Notice that fitting through the model doesn't mark the
# workflow as being "trained"
wf_fit_model

# Finalizing the workflow marks it as "trained"
wf_fit

# Which allows you to predict from it
try(predict(wf_fit_model, mtcars))

predict(wf_fit, mtcars)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
