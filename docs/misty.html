<!DOCTYPE html><html lang="en"><head><title>Help for package misty</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {misty}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aov.b'><p>Between-Subject Analysis of Variance</p></a></li>
<li><a href='#aov.w'><p>Repeated Measures Analysis of Variance (Within-Subject ANOVA)</p></a></li>
<li><a href='#as.na'><p>Replace User-Specified Values With Missing Values or Missing Values With</p>
User-Specified Values</a></li>
<li><a href='#blimp'><p>Create, Run, and Print Blimp Models</p></a></li>
<li><a href='#blimp.bayes'><p>Blimp Summary Measures, Convergence and Efficiency Diagnostics</p></a></li>
<li><a href='#blimp.plot'><p>Blimp Trace Plots and Posterior Distribution Plots</p></a></li>
<li><a href='#blimp.print'><p>Print Blimp Output</p></a></li>
<li><a href='#blimp.run'><p>Run Blimp Models</p></a></li>
<li><a href='#blimp.update'><p>Blimp Input Updating</p></a></li>
<li><a href='#center'><p>Centering Predictor Variables in Single-Level and Multilevel Data</p></a></li>
<li><a href='#check.collin'><p>Collinearity Diagnostics</p></a></li>
<li><a href='#check.outlier'><p>Statistical Measures for Leverage, Distance, and Influence</p></a></li>
<li><a href='#check.resid'><p>Residual Diagnostics</p></a></li>
<li><a href='#chr.color'><p>Colored and Styled Terminal Output Text</p></a></li>
<li><a href='#chr.grep'><p>Multiple Pattern Matching</p></a></li>
<li><a href='#chr.gsub'><p>Multiple Pattern Matching And Replacements</p></a></li>
<li><a href='#chr.omit'><p>Omit Strings</p></a></li>
<li><a href='#chr.trim'><p>Trim Whitespace from String</p></a></li>
<li><a href='#chr.trunc'><p>Truncate a Character Vector to a Maximum Width</p></a></li>
<li><a href='#ci.cor'><p>(Bootstrap) Confidence Intervals for Correlation Coefficients</p></a></li>
<li><a href='#ci.mean'><p>(Bootstrap) Confidence Intervals for Arithmetic Means and Medians</p></a></li>
<li><a href='#ci.mean.diff'><p>Confidence Interval for the Difference in Arithmetic Means</p></a></li>
<li><a href='#ci.mean.w'><p>Within-Subject Confidence Interval for the Arithmetic Mean</p></a></li>
<li><a href='#ci.prop'><p>(Bootstrap) Confidence Intervals for Proportions</p></a></li>
<li><a href='#ci.prop.diff'><p>Confidence Interval for the Difference in Proportions</p></a></li>
<li><a href='#ci.var'><p>(Bootstrap) Confidence Intervals for Variances and Standard Deviations</p></a></li>
<li><a href='#clear'><p>Clear Console in RStudio</p></a></li>
<li><a href='#cluster.scores'><p>Cluster Scores</p></a></li>
<li><a href='#coding'><p>Coding Categorical Variables</p></a></li>
<li><a href='#cohens.d'><p>Cohen's d</p></a></li>
<li><a href='#cor.matrix'><p>Correlation Matrix</p></a></li>
<li><a href='#crosstab'><p>Cross Tabulation</p></a></li>
<li><a href='#descript'><p>Descriptive Statistics</p></a></li>
<li><a href='#df.check'><p>Data Check</p></a></li>
<li><a href='#df.duplicated'><p>Extract Duplicated or Unique Rows</p></a></li>
<li><a href='#df.head'><p>Print the First and Last Rows of a Data Frame</p></a></li>
<li><a href='#df.merge'><p>Merge Multiple Data Frames</p></a></li>
<li><a href='#df.move'><p>Move Variable(s) in a Data Frame</p></a></li>
<li><a href='#df.rbind'><p>Combine Data Frames by Rows, Filling in Missing Columns</p></a></li>
<li><a href='#df.rename'><p>Rename Columns in a Matrix or Variables in a Data Frame</p></a></li>
<li><a href='#df.sort'><p>Data Frame Sorting</p></a></li>
<li><a href='#df.subset'><p>Subsetting Data Frames</p></a></li>
<li><a href='#dominance'><p>Dominance Analysis</p></a></li>
<li><a href='#dominance.manual'><p>Dominance Analysis, Manually Inputting a Correlation Matrix</p></a></li>
<li><a href='#effsize'><p>Effect Sizes for Categorical Variables</p></a></li>
<li><a href='#freq'><p>Frequency Table</p></a></li>
<li><a href='#indirect'><p>Confidence Intervals for the Indirect Effect</p></a></li>
<li><a href='#item.alpha'><p>Coefficient Alpha and Item Statistics</p></a></li>
<li><a href='#item.cfa'><p>Confirmatory Factor Analysis</p></a></li>
<li><a href='#item.invar'><p>Between-Group and Longitudinal Measurement Invariance Evaluation</p></a></li>
<li><a href='#item.omega'><p>Coefficient Omega, Hierarchical Omega, and Categorical Omega</p></a></li>
<li><a href='#item.reverse'><p>Reverse Code Scale Item</p></a></li>
<li><a href='#item.scores'><p>Scale Scores</p></a></li>
<li><a href='#lagged'><p>Create Lagged Variables</p></a></li>
<li><a href='#libraries'><p>Load and Attach Multiple Packages</p></a></li>
<li><a href='#mplus'><p>Create, Run, and Print Mplus Models</p></a></li>
<li><a href='#mplus.bayes'><p>Mplus Summary Measures, Convergence and Efficiency Diagnostics</p></a></li>
<li><a href='#mplus.lca'><p>Mplus Model Specification for Latent Class Analysis</p></a></li>
<li><a href='#mplus.plot'><p>Plot Mplus GH5 File</p></a></li>
<li><a href='#mplus.print'><p>Print Mplus Output</p></a></li>
<li><a href='#mplus.run'><p>Run Mplus Models</p></a></li>
<li><a href='#mplus.update'><p>Mplus Input Updating</p></a></li>
<li><a href='#multilevel.cfa'><p>Multilevel Confirmatory Factor Analysis</p></a></li>
<li><a href='#multilevel.cor'><p>Within-Group and Between-Group Correlation Matrix</p></a></li>
<li><a href='#multilevel.descript'><p>Multilevel Descriptive Statistics for Two-Level and Three-Level Data</p></a></li>
<li><a href='#multilevel.fit'><p>Simultaneous and Level-Specific Multilevel Model Fit Information</p></a></li>
<li><a href='#multilevel.icc'><p>Intraclass Correlation Coefficient, ICC(1) and ICC(2)</p></a></li>
<li><a href='#multilevel.indirect'><p>Confidence Interval for the Indirect Effect in a 1-1-1 Multilevel Mediation Model</p></a></li>
<li><a href='#multilevel.invar'><p>Cross-Level Measurement Invariance Evaluation</p></a></li>
<li><a href='#multilevel.omega'><p>Multilevel Composite Reliability</p></a></li>
<li><a href='#multilevel.r2'><p>R-Squared Measures for Multilevel and Linear Mixed Effects Models</p></a></li>
<li><a href='#multilevel.r2.manual'><p>R-Squared Measures for Multilevel and Linear Mixed Effects Models by Rights</p>
and Sterba (2019), Manually Inputting Parameter Estimates</a></li>
<li><a href='#na.auxiliary'><p>Auxiliary Variables Analysis</p></a></li>
<li><a href='#na.coverage'><p>Variance-Covariance Coverage</p></a></li>
<li><a href='#na.descript'><p>Descriptive Statistics for Missing Data in Single-Level, Two-Level and Three-Level Data</p></a></li>
<li><a href='#na.indicator'><p>Missing Data Indicator Matrix</p></a></li>
<li><a href='#na.pattern'><p>Missing Data Pattern</p></a></li>
<li><a href='#na.prop'><p>Proportion of Missing Data for Each Case</p></a></li>
<li><a href='#na.satcor'><p>Fit a Saturated Correlates Model</p></a></li>
<li><a href='#na.test'><p>Missing Completely at Random (MCAR) Test</p></a></li>
<li><a href='#plot.misty.object'><p>Plots misty.object object</p></a></li>
<li><a href='#print.misty.object'><p>Print misty.object object</p></a></li>
<li><a href='#read.data'><p>Read Data File in Table format, SPSS, Excel, or Stata DTA File</p></a></li>
<li><a href='#read.dta'><p>Read Stata DTA File</p></a></li>
<li><a href='#read.mplus'><p>Read Mplus Data File and Variable Names</p></a></li>
<li><a href='#read.sav'><p>Read SPSS File</p></a></li>
<li><a href='#read.xlsx'><p>Read Excel File</p></a></li>
<li><a href='#rec'><p>Recode Variable</p></a></li>
<li><a href='#restart'><p>Restart R Session</p></a></li>
<li><a href='#result.lca'><p>Summary Result Table and Grouped Bar Charts for Latent Class Analysis Estimated in Mplus</p></a></li>
<li><a href='#robust.coef'><p>Unstandardized Coefficients with Heteroscedasticity-Consistent Standard Errors</p></a></li>
<li><a href='#rwg.lindell'><p>Lindell, Brandt and Whitney (1999) r*wg(j) Within-Group Agreement Index for</p>
Multi-Item Scales</a></li>
<li><a href='#script.copy'><p>Save Copy of the Current Script in RStudio</p></a></li>
<li><a href='#script.new'><p>Open new R Script, R Markdown script, or SQL Script in RStudio</p></a></li>
<li><a href='#script.open'><p>Open, Close and Save R Script in RStudio</p></a></li>
<li><a href='#setsource'><p>Set Working Directory to the Source File Location</p></a></li>
<li><a href='#size.mean'><p>Sample Size Determination</p></a></li>
<li><a href='#skewness'><p>Univariate and Multivariate Skewness and Kurtosis</p></a></li>
<li><a href='#std.coef'><p>Standardized Coefficients</p></a></li>
<li><a href='#test.levene'><p>Levene's Test for Homogeneity of Variance</p></a></li>
<li><a href='#test.t'><p>t-Test</p></a></li>
<li><a href='#test.welch'><p>Welch's Test</p></a></li>
<li><a href='#test.z'><p>z-Test</p></a></li>
<li><a href='#write.dta'><p>Write Stata DTA File</p></a></li>
<li><a href='#write.mplus'><p>Write Mplus Data File</p></a></li>
<li><a href='#write.result'><p>Write Results of a misty Object into an Excel file</p></a></li>
<li><a href='#write.sav'><p>Write SPSS File</p></a></li>
<li><a href='#write.xlsx'><p>Write Excel File</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Miscellaneous Functions 'T. Yanagida'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-03-10</td>
</tr>
<tr>
<td>Author:</td>
<td>Takuya Yanagida [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Takuya Yanagida &lt;takuya.yanagida@univie.ac.at&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Miscellaneous functions for (1) data management (e.g., grand-mean and group-mean centering, coding variables and reverse coding items, scale and cluster scores, reading and writing Excel and SPSS files), (2) descriptive statistics (e.g., frequency table, cross tabulation, effect size measures), (3) missing data (e.g., descriptive statistics for missing data, missing data pattern, Little's test of Missing Completely at Random, and auxiliary variable analysis), (4) multilevel data (e.g., multilevel descriptive statistics, within-group and between-group correlation matrix, multilevel confirmatory factor analysis, level-specific fit indices, cross-level measurement equivalence evaluation, multilevel composite reliability, and multilevel R-squared measures), (5) item analysis (e.g., confirmatory factor analysis, coefficient alpha and omega, between-group and longitudinal measurement equivalence evaluation), (6) statistical analysis (e.g., bootstrap confidence intervals, collinearity and residual diagnostics, dominance analysis, between- and within-subject analysis of variance, latent class analysis, t-test, z-test, sample size determination), and (7) functions to interact with 'Blimp' and 'Mplus'.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, haven, lavaan, lme4, rstudioapi</td>
</tr>
<tr>
<td>Suggests:</td>
<td>boot, data.table, hdf5r, Matrix, mice, mnormt, mvnmle, nlme,
patchwork, readxl, plyr, writexl</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-10 16:57:43 UTC; takuy</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-10 17:40:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='aov.b'>Between-Subject Analysis of Variance</h2><span id='topic+aov.b'></span>

<h3>Description</h3>

<p>This function performs an one-way between-subject analysis of variance (ANOVA)
including Tukey HSD post hoc tests for multiple comparison and provides descriptive
statistics, effect size measures, and a plot showing bars representing means
for each group and error bars for difference-adjusted confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aov.b(formula, data, posthoc = FALSE, conf.level = 0.95, hypo = TRUE,
      descript = TRUE, effsize = FALSE, weighted = FALSE, correct = FALSE,
      digits = 2, p.digits = 3, as.na = NULL, plot = FALSE, bar = TRUE,
      point = FALSE, ci = TRUE, jitter = FALSE, adjust = TRUE,
      point.size = 3, errorbar.width = 0.1, jitter.size = 1.25,
      jitter.width = 0.05, jitter.height = 0, jitter.alpha = 0.1,
      xlab = NULL, ylab = "y", ylim = NULL, ybreaks = ggplot2::waiver(),
      title = NULL, subtitle = "Confidence Interval", filename = NULL,
      width = NA, height = NA, units = c("in", "cm", "mm", "px"), dpi = 600,
      write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aov.b_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> where <code>y</code> is
a numeric variable giving the data values and <code>group</code>
a numeric variable, character variable or factor with more
than two values or factor levels giving the corresponding
groups.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_posthoc">posthoc</code></td>
<td>
<p>logical: if <code>TRUE</code>, Tukey HSD post hoc test for
multiple comparison is conducted.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measures <code class="reqn">\eta^2</code>
and <code class="reqn">\omega^2</code> for the ANOVA and Cohen's d for the post
hoc tests are shown on the console.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code>, the weighted pooled standard
deviation is used to compute Cohen's d.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor to remove
positive bias in small samples is used.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying descriptive statistics and
confidence interval.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing error bars for
confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_bar">bar</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), bars representing means
for each groups are drawn.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code>, points representing means for
each groups are drawn.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), error bars representing
confidence intervals are drawn.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code>, jittered data points are drawn.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the confidence intervals is applied.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_histogram</code>
function for controlling the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title of
the plot.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle of
the plot.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>filename</code>
argument. Note that plots can only be saved when
<code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Post Hoc Test</strong></dt><dd><p>Tukey HSD post hoc test reports Cohen's d based
on the non-weighted standard deviation (i.e., <code>weighted = FALSE</code>) when
requesting an effect size measure  (i.e., <code>effsize = TRUE</code>) following the
recommendation by Delacre et al. (2021).
</p>
</dd>
<dt><strong>Confidence Intervals</strong></dt><dd><p>Cumming and Finch (2005) pointed out that
when 95% confidence intervals (CI) for two separately plotted means overlap,
it is still possible that the CI for the difference would not include zero.
Baguley (2012) proposed to adjust the width of the CIs by the factor of
<code class="reqn">\sqrt{2}</code> to reflect the correct width of the CI for a mean difference:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu}_{j} \pm t_{n - 1, 1 - \alpha/2} \frac{\sqrt{2}}{2} \hat{\sigma}_{{\hat{\mu}}_j}</code>
</p>
</dd>
</dl>
<p>These difference-adjusted CIs around the individual means can be interpreted
as if it were a CI for their difference. Note that the width of these intervals
is sensitive to differences in the variance and sample size of each sample,
i.e., unequal population variances and unequal <code class="reqn">n</code> alter the interpretation
of difference-adjusted CIs.

</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame with variables used in the current analysis</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>descript</code> for descriptive
statistics, <code>test</code> for the ANOVA table, <code>posthoc</code>
for post hoc tests, and <code>aov</code> for the return object
of the <code>aov</code> function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Baguley, T. S. (2012a). <em>Serious stats: A guide to advanced statistics for
the behavioral sciences</em>. Palgrave Macmillan.
</p>
<p>Cumming, G., and Finch, S. (2005) Inference by eye: Confidence intervals, and
how to read pictures of data. <em>American Psychologist, 60</em>, 170–80.
</p>
<p>Delacre, M., Lakens, D., Ley, C., Liu, L., &amp; Leys, C. (2021). Why Hedges' g*s
based on the non-pooled standard deviation should be reported with Welch's t-test.
https://doi.org/10.31234/osf.io/tu6mp
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.z">test.z</a></code>,
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>,
<code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Between-subject ANOVA
aov.b(mpg ~ gear, data = mtcars)

# Example 2: Between-subject ANOVA
# print effect size measures
aov.b(mpg ~ gear, data = mtcars, effsize = TRUE)

# Example 3: Between-subject ANOVA
# do not print hypotheses and descriptive statistics,
aov.b(mpg ~ gear, data = mtcars, descript = FALSE, hypo = FALSE)

# Example 4: Between-subject ANOVA
# plot results
aov.b(mpg ~ gear, data = mtcars, plot = TRUE)

## Not run: 
# Example 5: Write Results into a text file
aov.b(mpg ~ gear, data = mtcars, write = "ANOVA.txt")

# Example 6: Save plot
aov.b(mpg ~ gear, data = mtcars, plot = TRUE, filename = "Between-Subject_ANOVA.png",
      width = 7, height = 6)

# Example 7: Draw plot in line with the default setting of aov.b()
library(ggplot2)

object &lt;- aov.b(mpg ~ gear, data = mtcars, output = FALSE)

ggplot(object$data, aes(group, y)) +
  geom_bar(stat = "summary", fun = "mean") +
  geom_errorbar(data = ci.mean(object$data, y, group = "group", adjust = TRUE,
                output = FALSE)$result,
                aes(group, m, ymin = low, ymax = upp), width = 0.1) +
  scale_x_discrete(name = NULL) +
  labs(subtitle = "Two-Sided Difference-Adjusted Confidence Interval") +
  theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5))
## End(Not run)
</code></pre>

<hr>
<h2 id='aov.w'>Repeated Measures Analysis of Variance (Within-Subject ANOVA)</h2><span id='topic+aov.w'></span>

<h3>Description</h3>

<p>This function performs an one-way repeated measures analysis of variance (within
subject ANOVA) including paired-samples t-tests for multiple comparison and
provides descriptive statistics, effect size measures, and a plot showing error
bars for difference-adjusted Cousineau-Morey within-subject confidence intervals
with jittered data points including subject-specific lines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aov.w(formula, data, print = c("all", "none", "LB", "GG", "HF"),
      posthoc = FALSE, conf.level = 0.95,
      p.adj = c("none", "bonferroni", "holm", "hochberg", "hommel", "BH", "BY", "fdr"),
      hypo = TRUE, descript = TRUE, epsilon = TRUE, effsize = FALSE, na.omit = TRUE,
      digits = 2, p.digits = 3, as.na = NULL, plot = FALSE, point = TRUE, line = TRUE,
      ci = TRUE, jitter = FALSE, adjust = TRUE, point.size = 3, line.width = 0.5,
      errorbar.width = 0.1, jitter.size = 1.25,jitter.width = 0.05, jitter.alpha = 0.1,
      xlab = NULL, ylab = "y", ylim = NULL, ybreaks = ggplot2::waiver(), title = NULL,
      subtitle = "Confidence Interval", filename = NULL, width = NA, height = NA,
      units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL, append = TRUE,
      check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aov.w_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>cbind(time1, time2, time3) ~ 1</code>
where <code>time1</code>, <code>time2</code>, and <code>time3</code> are
numeric variables representing the levels of the within-subject
factor, i.e., data are specified in wide-format (i.e.,
multivariate person level format).</p>
</td></tr>
<tr><td><code id="aov.w_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_print">print</code></td>
<td>
<p>a character vector indicating which sphericity correction
to use, i.e., <code>all</code> for all corrections, <code>none</code>
for no correction, <code>LB</code> for lower bound correction,
<code>GG</code> for Greenhouse-Geisser correction, and <code>HF</code>,
for Huynh-Feldt correction.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_posthoc">posthoc</code></td>
<td>
<p>logical: if <code>TRUE</code>, paired-samples t-tests for multiple
comparison are conducted.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_p.adj">p.adj</code></td>
<td>
<p>a character string indicating an adjustment method for
multiple testing based on <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>, i.e.,
<code>none</code>, <code>bonferroni</code>, <code>holm</code> (default),
<code>h ochberg</code>, <code>hommel</code>, <code>BH</code>, <code>BY</code>, or
<code>fdr</code>.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_epsilon">epsilon</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), box indices of sphericity (epsilon)
are shown on the console, i.e., lower bound, Greenhouse
and Geiser (GG), Huynh and Feldt (HF) and average of GG
and HF.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measures eta-squared
(<code class="reqn">\eta^2</code>), partial eta-squared (<code class="reqn">\eta^2_p</code>),
omega-squared (<code class="reqn">\omega^2</code>), and partial omega-squared
(<code class="reqn">\omega^2_p</code>) for the repeated measures ANOVA and
Cohen's <em>d</em> for the post hoc tests are shown on
the console.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed
before conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="aov.w_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying descriptive statistics and
confidence interval.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing error bars for
confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), points representing
means for each groups are drawn.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a line connecting means
of each groups and lines connecting data points are drawn
when <code>jitter = TRUE</code>.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), error bars representing
confidence intervals are drawn.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code>, jittered data points with
subject-specific lines are drawn.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the Cousineau-Morey within-subject confidence
intervals is applied.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_line.width">line.width</code></td>
<td>
<p>a numeric value indicating the <code>linewidth</code> aesthetic
for the line connecting means of each groups.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_histogram</code>
function for controlling the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle for
the plot.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>filename</code>
argument. Note that plots can only be saved when
<code>plot = TRUE</code> or <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Sphericity</strong></dt><dd><p>The <em>F</em>-Test of the repeated measures ANOVA
is based on the assumption of sphericity, which is defined as the assumption
that the variance of differences between repeated measures are equal in the
population. The Mauchly's test is commonly used to test this hypothesis.
However, test of assumptions addresses an irrelevant hypothesis because what
matters is the degree of violation rather than its presence (Baguley, 2012a).
Moreover, the test is not recommended because it lacks statistical power (Abdi,
2010). Instead, the Box index of sphericity (<code class="reqn">\varepsilon</code>) should be used to
assess the degree of violation of the sphericity assumption. The <code class="reqn">\varepsilon</code>
parameter indicates the degree to which the population departs from sphericity
with <code class="reqn">\varepsilon = 1</code> indicating that sphericity holds. As the departure
becomes more extreme, <code class="reqn">\varepsilon</code> approaches its lower bound
<code class="reqn">\hat{\varepsilon}_{lb}</code>:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\varepsilon}_{lb} = \frac{1}{J - 1}</code>
</p>

<p>where <code class="reqn">J</code> is the number of levels of the within-subject factor. Box (1954a,
1954b) suggested a measure for sphericity, which applies to a population
covariance matrix. Greenhouse and Geisser (1959) proposed an estimate for
<code class="reqn">\varepsilon</code> known as <code class="reqn">\hat{\varepsilon}_{gg}</code> that can be computed
from the sample covariance matrix, whereas Huynh and Feldt (1976) proposed
an alternative estimate <code class="reqn">\hat{\varepsilon}_{hf}</code>. These estimates can
be used to correct the effect and error <em>df</em> of the <em>F</em>-test.
Simulation studies showed that <code class="reqn">\hat{\varepsilon}_{gg} \leq \hat{\varepsilon}_{hf}</code>
and that <code class="reqn">\hat{\varepsilon}_{gg}</code> tends to be conservative underestimating
<code class="reqn">\varepsilon</code>, whereas <code class="reqn">\hat{\varepsilon}_{hf}</code> tends to be liberal
overestimating <code class="reqn">\varepsilon</code> and occasionally exceeding one. Baguley (2012a)
recommended to compute the average of the conservative estimate <code class="reqn">\hat{\varepsilon}_{gg}</code>
and the liberal estimate <code class="reqn">\hat{\varepsilon}_{hf}</code> to assess the sphericity
assumption.
By default, the function prints results depending on the average
<code class="reqn">\hat{\varepsilon}_{gg}</code> and <code class="reqn">\hat{\varepsilon}_{hf}</code>:
</p>

<ul>
<li><p> If the average is less than 0.75 results of the <em>F</em>-Test based on
Greenhouse-Geiser correction factor (<code class="reqn">\hat{\varepsilon}_{gg}</code>) is printed.
</p>
</li>
<li><p> If the average is less greater or equal 0.75, but less than 0.95
results of the <em>F</em>-Test based on Huynh-Feldt correction factor
(<code class="reqn">\hat{\varepsilon}_{hf}</code>) is printed.
</p>
</li>
<li><p> If the average is greater or equal 0.95 results of the <em>F</em>-Test
without any corrections are printed.
</p>
</li></ul>

</dd>
<dt><strong>Missing Data</strong></dt><dd><p>The function uses listwise deletion by default to
deal with missing data. However, the function also allows to use all available
observations by conducting the repeated measures ANOVA in long data format when
specifying <code>na.omit = FALSE</code>. Note that in the presence of missing data,
the <em>F</em>-Test without any sphericity corrections may be reliable, but it
is not clear whether results based on Greenhouse-Geiser or Huynh-Feldt correction
are trustworthy given that pairwise deletion is used for estimating the
variance-covariance matrix when computing <code class="reqn">\hat{\varepsilon}_{gg}</code> and the total
number of subjects regardless of missing values (i.e., complete and incomplete
cases) are used for computing <code class="reqn">\hat{\varepsilon}_{hf}</code>.
</p>
</dd>
<dt><strong>Within-Subject Confidence Intervals</strong></dt><dd><p>The function provides a
plot showing error bars for difference-adjusted Cousineau-Morey confidence
intervals (Baguley, 2012b). The intervals matches that of a CI for a difference,
i.e., non-overlapping CIs corresponds to an inferences of no statistically
significant difference. The Cousineau-Morey confidence intervals without
adjustment can be used by specifying <code>adjust = FALSE</code>.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the data (<code>data</code>) in wide-format (<code>wide</code>), reshaped data in long-format (<code>long</code>), and within-subject confidence intervals (<code>ci</code>)</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>descript</code> for descriptive
statistics, <code>epsilon</code> for a table with indices of sphericity,
<code>test</code> for the ANOVA table (<code>none</code> for no sphericity
correction, <code>lb</code> for lower bound correction, <code>gg</code>
for Greenhouse and Geiser correction, and <code>hf</code> for
Huynh and Feldt correction), <code>posthoc</code> for post hoc
tests, and <code>aov</code> for the return object of the <code>aov</code>
function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Abdi, H. (2010). The Greenhouse-Geisser correction. In N. J. Salkind (Ed.)
<em>Encyclopedia of Research Design</em> (pp. 630-634), Sage.
https://dx.doi.org/10.4135/9781412961288
</p>
<p>Baguley, T. S. (2012a). <em>Serious stats: A guide to advanced statistics for the
behavioral sciences</em>. Palgrave Macmillan.
</p>
<p>Baguley, T. (2012b). Calculating and graphing within-subject confidence intervals
for ANOVA. <em>Behavior Research Methods, 44</em>, 158-175.
https://doi.org/10.3758/s13428-011-0123-7
</p>
<p>Bakerman, R. (2005). Recommended effect size statistics for repeated measures
designs. <em>Behavior Research Methods</em>, 37, 179-384.
https://doi.org/10.3758/BF03192707
</p>
<p>Box, G. E. P. (1954a) Some Theorems on Quadratic Forms Applied in the Study
of Analysis of Variance Problems, I. Effects of Inequality of Variance in
the One-way Classification. <em>Annals of Mathematical Statistics, 25</em>,
290–302.
</p>
<p>Box, G. E. P. (1954b) Some Theorems on Quadratic Forms Applied in the Study
of Analysis of Variance Problems, II. Effects of Inequality of Variance and
of Correlation between Errors in the Two-way Classification.
<em>Annals of Mathematical Statistics, 25</em>, 484–98.
</p>
<p>Greenhouse, S. W., and Geisser, S. (1959). On methods in the analysis of profile
data.<em>Psychometrika, 24</em>, 95-112. https://doi.org/10.1007/BF02289823
</p>
<p>Huynh, H., and Feldt, L. S. (1976). Estimation of the box correction for degrees
of freedom from sample data in randomized block and splitplot designs.
<em>Journal of Educational Statistics, 1</em>, 69-82.
https://doi.org/10.2307/1164736
</p>
<p>Olejnik, S., &amp; Algina, J. (2000). Measures of effect size for comparative studies:
Applications, interpretations, and limitations. <em>Contemporary Educational
Psychology, 25</em>, 241-286. https://doi.org/10.1006/ceps.2000.1040
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.z">test.z</a></code>,
<code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(time1 = c(3, 2, 1, 4, 5, 2, 3, 5, 6, 7),
                  time2 = c(4, 3, 6, 5, 8, 6, 7, 3, 4, 5),
                  time3 = c(1, 2, 2, 3, 6, 5, 1, 2, 4, 6))

# Example 1: Repeated measures ANOVA
aov.w(cbind(time1, time2, time3) ~ 1, data = dat)

# Example 2: Repeated measures ANOVA, print results of all sphericity corrections
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, print = "all")

# Example 3: Repeated measures ANOVA
# print effect size measures
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, effsize = TRUE)

# Example 4: Repeated measures ANOVA, do not print hypotheses and descriptive statistics,
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, descript = FALSE, hypo = FALSE)

# Example 5: Repeated measures ANOVA, plot results
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, plot = TRUE)

## Not run: 
# Example 6: Write Results into a text file
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, write = "RM-ANOVA.txt")

# Example 7: Save plot
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, plot = TRUE,
      filename = "Repeated_measures_ANOVA.png", width = 7, height = 6)
## End(Not run)
</code></pre>

<hr>
<h2 id='as.na'>Replace User-Specified Values With Missing Values or Missing Values With
User-Specified Values</h2><span id='topic+as.na'></span><span id='topic+na.as'></span>

<h3>Description</h3>

<p>The function <code>as.na</code> replaces user-specified values in the argument
<code>na</code> in a vector, factor, matrix, array, list, or data frame with
<code>NA</code>, while the function <code>na.as</code> replaces <code>NA</code> in a vector,
factor, matrix or data frame with a user-specified value or character string
in the argument <code>na</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.na(data, ..., na, replace = TRUE, check = TRUE)

na.as(data, ..., na, replace = TRUE, as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.na_+3A_data">data</code></td>
<td>
<p>a vector, factor, matrix, array, data frame, or list.</p>
</td></tr>
<tr><td><code id="as.na_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>, e.g.,
<code>as.na(dat, x1, x2)</code> for selecting the variables <code>x1</code>
and <code>x2</code> from the data frame <code>dat</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="as.na_+3A_na">na</code></td>
<td>
<p>a vector indicating values or characters to replace with
<code>NA</code>, or which <code>NA</code> is replaced. Note that a numeric
value or character string needs to be specified for the argument
<code>na</code> when using <code>na.as</code>.</p>
</td></tr>
<tr><td><code id="as.na_+3A_replace">replace</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable(s) specified in
<code>...</code> are replaced in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="as.na_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="as.na_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector or character vector indicating user-defined
missing values, i.e. these values are converted to <code>NA</code>
before conducting the analysis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector, factor, matrix, array, data frame, or list specified in the
argument <code>data</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>,
<code><a href="#topic+na.indicator">na.indicator</a></code>, <code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>,
<code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Numeric vector
num &lt;- c(1, 3, 2, 4, 5)

# Example 1a: Replace 2 with NA
as.na(num, na = 2)

# Example 1b: Replace 2, 3, and 4 with NA
as.na(num, na = c(2, 3, 4))

# Example 1c: Replace NA with 2
na.as(c(1, 3, NA, 4, 5), na = 2)

#----------------------------------------------------------------------------
# Character vector
chr &lt;- c("a", "b", "c", "d", "e")

# Example 2a: Replace "b" with NA
as.na(chr, na = "b")

# Example 2b: Replace "b", "c", and "d" with NA
as.na(chr, na = c("b", "c", "d"))

# Example 2c: Replace NA with "b"
na.as(c("a", NA, "c", "d", "e"), na = "b")

#----------------------------------------------------------------------------
# Factor
fac &lt;- factor(c("a", "a", "b", "b", "c", "c"))

# Example 3a: Replace "b" with NA
as.na(fac, na = "b")

# Example 3b: Replace "b" and "c" with NA
as.na(fac, na = c("b", "c"))

# Example 3c: Replace NA with "b"
na.as(factor(c("a", "a", NA, NA, "c", "c")), na = "b")

#----------------------------------------------------------------------------
# Matrix
mat &lt;- matrix(1:20, ncol = 4)

# Example 4a: Replace 8 with NA
as.na(mat, na = 8)

# Example 4b: Replace 8, 14, and 20 with NA
as.na(mat, na = c(8, 14, 20))

# Example 4c: Replace NA with 2
na.as(matrix(c(1, NA, 3, 4, 5, 6), ncol = 2), na = 2)

#----------------------------------------------------------------------------
# Array

# Example 5: Replace 1 and 10 with NA
as.na(array(1:20, dim = c(2, 3, 2)), na = c(1, 10))

#----------------------------------------------------------------------------
# List

# Example 6:  Replace 1 with NA
as.na(list(x1 = c(1, 2, 3, 1, 2, 3), x2 = c(2, 1, 3, 2, 1)), na = 1)

#----------------------------------------------------------------------------
# Data frame
df &lt;- data.frame(x1 = c(1, 2, 3), x2 = c(2, 1, 3), x3 = c(3, 1, 2))

# Example 7a: Replace 1 with NA
as.na(df, na = 1)

# Example 7b: Replace 1 with NA for the variable x2
as.na(df, x2, na = 1)

# Alternative specification
as.na(df$x2, na = 1)

# Example 7c: Replace 1 and 3 with NA
as.na(df, na = c(1, 3))

# Example 7d: Replace 1 with NA in 'x2' and 'x3'
as.na(df, x2, x3, na = 1)

# Example 7e: Replace NA with -99
na.as(data.frame(x1 = c(NA, 2, 3), x2 = c(2, NA, 3)), na = -99)

# Example 7f: Recode by replacing 30 with NA and then replacing NA with 3
na.as(data.frame(x1 = c(1, 2, 30), x2 = c(2, 1, 30)), na = 3, as.na = 30)</code></pre>

<hr>
<h2 id='blimp'>Create, Run, and Print Blimp Models</h2><span id='topic+blimp'></span>

<h3>Description</h3>

<p>This wrapper function creates a Blimp input file, runs the input file by using
the <code>blimp.run()</code> function, and prints the Blimp output file by using the
<code>blimp.print()</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blimp(x, file = "Blimp_Input.imp", data = NULL, comment = FALSE, replace.inp = TRUE,
      blimp.run = TRUE, posterior = FALSE, folder = "Posterior_",
      format = c("csv", "csv2", "excel", "rds", "workspace"), clear = TRUE,
      replace.out = c("always", "never", "modified"), Blimp = .detect.blimp(),
      result = c("all", "default", "algo.options", "data.info", "model.info",
                 "warn.mess", "error.mess", "out.model", "gen.param"),
      exclude = NULL, color = c("none", "blue", "green"),
      style = c("bold", "regular"), not.result = TRUE, write = NULL,
      append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blimp_+3A_x">x</code></td>
<td>
<p>a character string containing the Blimp input text.</p>
</td></tr>
<tr><td><code id="blimp_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the Blimp input
file with or without the file extension <code>.imp</code>, e.g.,
<code>"Blimp_Input.imp"</code> or <code>"Blimp_Input.imp"</code>.</p>
</td></tr>
<tr><td><code id="blimp_+3A_data">data</code></td>
<td>
<p>a matrix or data frame from which the variables names for
the section <code>VARIABLES</code> are extracted.</p>
</td></tr>
<tr><td><code id="blimp_+3A_comment">comment</code></td>
<td>
<p>logical: if <code>FALSE</code> (default), comments (i.e., text
after the <code>#</code> symbol) are removed from the input text
specified in the argument <code>x</code>.</p>
</td></tr>
<tr><td><code id="blimp_+3A_replace.inp">replace.inp</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), an existing input
file will be replaced.</p>
</td></tr>
<tr><td><code id="blimp_+3A_blimp.run">blimp.run</code></td>
<td>
<p>logical: if <code>TRUE</code>, the input file specified in the
argument <code>file</code> containing the input text specified
in the argument <code>x</code> is run using the <code>blimp.run()</code>
function.</p>
</td></tr>
<tr><td><code id="blimp_+3A_posterior">posterior</code></td>
<td>
<p>logical: if <code>TRUE</code>, the posterior distribution including
burn-in and post-burn-in phase for all parameters are saved
in long format in a file called <code>posterior.*</code> in the
folder specified in the argument <code>folder</code> and <code>.imp</code>
file name in the format specified in the argument <code>format</code>.</p>
</td></tr>
<tr><td><code id="blimp_+3A_folder">folder</code></td>
<td>
<p>a character string indicating the prefix of the folder for
saving the posterior distributions. The default setting is
<code>folder = "Posterior_"</code>.</p>
</td></tr>
<tr><td><code id="blimp_+3A_format">format</code></td>
<td>
<p>a character vector indicating the file format(s) for saving the
posterior distributions, i.e., <code>"csv"</code> (default) for
<code>write.csv()</code>, <code>"csv2"</code> for <code>write.csv2()</code>,
<code>"excel"</code> for <code>write.xlsx()</code>, <code>"rds"</code> for
<code>saveRDS()</code>, and <code>"workspace"</code> for <code>write()</code>.</p>
</td></tr>
<tr><td><code id="blimp_+3A_clear">clear</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the console is cleared
after estimating each model.</p>
</td></tr>
<tr><td><code id="blimp_+3A_replace.out">replace.out</code></td>
<td>
<p>a character string for specifying three settings:
<code>"always"</code> (default), which runs all models, regardless
of whether an output file for the model exists, <code>"never"</code>,
which does not run any model that has an existing output file,
and <code>"modified"</code>, which only runs a model if the
modified date for the input file is more recent than the
output file modified date.</p>
</td></tr>
<tr><td><code id="blimp_+3A_blimp">Blimp</code></td>
<td>
<p>a character string for specifying the name or path of the
Blimp executable to be used for running models. This covers
situations where Blimp is not in the system's path, or where
one wants to test different versions of the Blimp program.
Note that there is no need to specify this argument for most
users since it has intelligent defaults.</p>
</td></tr>
<tr><td><code id="blimp_+3A_result">result</code></td>
<td>
<p>a character vector specifying Blimp result sections included
in the output (see 'Details' in the <code><a href="#topic+blimp.print">blimp.print</a></code>
function).</p>
</td></tr>
<tr><td><code id="blimp_+3A_exclude">exclude</code></td>
<td>
<p>a character vector specifying Blimp input command or result
sections excluded from the output (see 'Details' in the
<code><a href="#topic+blimp.print">blimp.print</a></code> function).</p>
</td></tr>
<tr><td><code id="blimp_+3A_color">color</code></td>
<td>
<p>a character vector with two elements indicating the colors
used for the main headers (e.g., <code>"ALGORITHMIC OPTIONS SPECIFIED:"</code>),
and for the headers <code>Outcome Variable:</code> and
<code>Missing predictor:</code>, <code>Latent Variable:</code>,
and <code>Covariance Matrix:</code>.</p>
</td></tr>
<tr><td><code id="blimp_+3A_style">style</code></td>
<td>
<p>a character vector with two elements indicating the style
used for headers (e.g., <code>"ALGORITHMIC OPTIONS SPECIFIED:"</code>),
and for the main headers (e.g., <code>"ALGORITHMIC OPTIONS SPECIFIED:"</code>),
and for the headers <code>Outcome Variable:</code> and
<code>Missing predictor:</code>, <code>Complete variable:</code>, <code>Latent Variable:</code>,
and <code>Covariance Matrix:</code>.</p>
</td></tr>
<tr><td><code id="blimp_+3A_not.result">not.result</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the result sections not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="blimp_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>).</p>
</td></tr>
<tr><td><code id="blimp_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="blimp_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="blimp_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console by using the function <code>blimp.print()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong><code>VARIABLES</code> Section</strong></dt><dd><p>The <code>VARIABLES</code> section used to
assign names to the variables in the data set can be specified by using
the <code>data</code> argument:
</p>

<ul>
<li><p><code>Write Blimp Data File</code>: In the first step, the Blimp data
file is written by using the <code>write.mplus()</code> function, e.g.
<code>write.mplus(data1, file = "data1.dat")</code>.
</p>
</li>
<li><p><code>Specify Blimp Input</code>: In the second step, the Blimp input
is specified as a character string. The <code>VARIABLES</code> option is left
out from the Blimp input text, e.g.,
<code>input &lt;- 'DATA: data1.dat;\nMODEL: y ~ x1@b1 x2@b2 d2;'</code>.
</p>
</li>
<li><p><code>Run Blimp Input</code>: In the third step, the Blimp input is run
by using the <code>blimp()</code> function. The argument <code>data</code> needs to be
specified given that the <code>VARIABLES</code> section was left out from the
Blimp input text in the previous step, e.g., <code>blimp(input, file = "Ex4.3.imp", data = data1)</code>.
</p>
</li></ul>

<p>Note that unlike Mplus, Blimp allows to specify a CSV data file with variable
names in the first row. Hence, it is recommended to export the data from
R using the <code>write.csv()</code> function to specify the data file in the <code>DATA</code>
section of the Blimp input file without specifying the <code>VARIABLES</code> section.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>a character vector containing the Blimp input text</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>write</code></td>
<td>
<p>write command sections</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result sections (<code>result</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Keller, B. T., &amp; Enders, C. K. (2023). <em>Blimp user’s guide</em> (Version 3).
Retrieved from www.appliedmissingdata.com/blimp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blimp.update">blimp.update</a></code>, <code><a href="#topic+blimp.run">blimp.run</a></code>,
<code><a href="#topic+blimp.print">blimp.print</a></code>, <code><a href="#topic+blimp.plot">blimp.plot</a></code>, <code><a href="#topic+blimp.bayes">blimp.bayes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Example 1: Write data, specify input without VARIABLES section, and run input

# Write Data File
# Note that row.names = FALSE needs to be specified
write.csv(data1, file = "data1.csv", row.names = FALSE)

# Specify Blimp input
input1 &lt;- '
DATA: data1.csv;
ORDINAL: d;
MISSING: 999;
FIXED: d;
CENTER: x1 x2;
MODEL: y ~ x1 x2 d;
SEED: 90291;
BURN: 1000;
ITERATIONS: 10000;
'

# Run Blimp input
blimp(input1, file = "Ex4.3.imp")

#----------------------------------------------------------------------------
# Example 2: Write data, specify input with VARIABLES section, and run input

# Write Data File
write.mplus(data1, file = "data1.dat", input = FALSE)

# Specify Blimp input
input2 &lt;- '
DATA: data1.dat;
VARIABLES: id v1 v2 v3 y x1 d x2 v4;
ORDINAL: d;
MISSING: 999;
FIXED: d;
CENTER: x1 x2;
MODEL: y ~ x1 x2 d;
SEED: 90291;
BURN: 1000;
ITERATIONS: 10000;
'

# Run Blimp input
blimp(input2, file = "Ex4.3.imp")

#----------------------------------------------------------------------------
# Example 3: Alternative specification using the data argument

# Write Data File
write.mplus(data1, file = "data1.dat", input = FALSE)

# Specify Blimp input
input3 &lt;- '
DATA: data1.dat;
ORDINAL: d;
MISSING: 999;
FIXED: d;
CENTER: x1 x2;
MODEL: y ~ x1 x2 d;
SEED: 90291;
BURN: 1000;
ITERATIONS: 10000;
'

# Run Blimp input
blimp(input3, file = "Ex4.3.imp", data = data1)

## End(Not run)
</code></pre>

<hr>
<h2 id='blimp.bayes'>Blimp Summary Measures, Convergence and Efficiency Diagnostics</h2><span id='topic+blimp.bayes'></span>

<h3>Description</h3>

<p>This function reads the posterior distribution for all parameters saved in
long format in a file called <code>posterior.*</code> by the function <code>blimp.run</code>
or <code>blimp</code> when specifying <code>posterior = TRUE</code> to compute point estimates
(i.e., mean, median, and MAP), measures of dispersion (i.e., standard deviation
and mean absolute deviation), measures of shape (i.e., skewness and kurtosis),
credible intervals (i.e., equal-tailed intervals and highest density interval),
convergence and efficiency diagnostics (i.e., potential scale reduction factor
R-hat, effective sample size, and Monte Carlo standard error), probability of
direction, and probability of being in the region of practical equivalence for
the posterior distribution for each parameter. By default, the function computes
the maximum of rank-normalized split-R-hat and rank normalized folded-split-R-hat,
Bulk effective sample size (Bulk-ESS) for rank-normalized values using split
chains, tail effective sample size (Tail-ESS) defined as the minimum of the
effective sample size for 0.025 and 0.975 quantiles, the Bulk Monte Carlo
standard error (Bulk-MCSE) for the median and Tail Monte Carlo standard error
(Tail-MCSE) defined as the maximum of the MCSE for 0.025 and 0.975 quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blimp.bayes(x, param = NULL,
            print = c("all", "default", "m", "med", "map", "sd", "mad",
                      "skew", "kurt", "eti", "hdi",
                      "rhat", "b.ess", "t.ess", "b.mcse", "t.mcse"),
            m.bulk = FALSE, split = TRUE, rank = TRUE, fold = TRUE,
            pd = FALSE, null = 0, rope = NULL,
            ess.tail = c(0.025, 0.975), mcse.tail = c(0.025, 0.975),
            alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
            digits = 2, r.digits = 3, ess.digits = 0, mcse.digits = 3,
            p.digits = 3, write = NULL, append = TRUE, check = TRUE,
            output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blimp.bayes_+3A_x">x</code></td>
<td>
<p>a character string indicating the name of folder containing
the <code>posterior.*</code> file, e.g., <code>"Posterior_Ex4.3"</code>
or the name of the <code>posterior.*</code> file with or without
any file extension, e.g., <code>"Posterior_ExEx4.3/posterior.csv"</code>
or <code>"Posterior_ExEx4.3/posterior"</code>. Alternatively, a
<code>misty.object</code> of type <code>blimp</code> can be specified,
i.e., result object of the <code>blimp.plot()</code> function.
Note that if the <code>posterior</code> file is specified without
file extension while multiple <code>posterior.*</code> files in
different file formats are available, then the file is read
in following order: <code>csv</code>,<code>RData</code>, <code>rds</code>,
and <code>xlsx</code>.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_param">param</code></td>
<td>
<p>a numeric vector indicating which parameters to print.
Note that the number of the parameter (<code>Param</code>) and
the parameter specification (<code>L1</code>, <code>L2</code>, and
<code>L3</code>) are provided in the text file <code>"partable.txt"</code>.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_print">print</code></td>
<td>
<p>a character vector indicating which summary measures,
convergence, and efficiency diagnostics to be printed on
the console, i.e. <code>"all"</code> for all summary measures,
convergence, and efficiency diagnostics, <code>"m"</code> for the
mean, <code>"med"</code> for the median, <code>"MAP"</code> for the
maximum a posteriori probability estimate, <code>"med"</code>
for the standard deviation, <code>"mad"</code> for the mean
absolute deviation, <code>"skew"</code> for the skewness,
<code>"kurt"</code> for the kurtosis, <code>"eti"</code> for the
equal-tailed credible interval, <code>"hdi"</code> for the
highest density credible interval, <code>"rhat"</code> for the
potential scale reduction (PSR) factor R-hat convergence
diagnostic, <code>"b.ess"</code> for the bulk effective sample
size (ESS), <code>"t.ess"</code> for the tail ESS, <code>"b.mcse"</code>
for the bulk Monte Carlo standard error (MCSE), and
<code>"t.mcse"</code> for the tail MCSE. The default setting is
<code>print = c("med", "sd", "skew", "kurt", "eti", "rhat", "b.ess", "t.ess", "b.mcse", "t.mcse")</code>.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_m.bulk">m.bulk</code></td>
<td>
<p>logical: if <code>TRUE</code> the Monte Carlo standard error
for the mean is computed. The default setting is
<code>m.bulk = FALSE</code>, i.e., the Monte Carlo standard error
for the median is computed.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), each MCMC chain is split
in half before computing R-hat. Note that the argument
<code>split</code> is always set to <code>FALSE</code> when computing
ESS.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_rank">rank</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), rank-normalization is
applied to the posterior draws before computing R-hat and
ESS. Note that the argument <code>rank</code> is always set to
<code>FALSE</code> when computing MCSE.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_fold">fold</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the maximum of
rank-normalized split-R-hat and rank normalized folded-split-R-hat
is computed. Note that the arguments <code>split</code> and
<code>rank</code> are always set to <code>TRUE</code> when specifying
<code>fold = TRUE</code>.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_pd">pd</code></td>
<td>
<p>logical: if <code>TRUE</code>, the probability of direction is
printed on the console.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_null">null</code></td>
<td>
<p>a numeric value considered as a null effect for the probability
of direction (default is <code>0</code>). Note that the value
specified in the argument <code>null</code> applies to all parameters
which might not be sensible for all parameters.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_rope">rope</code></td>
<td>
<p>a numeric vector with two elements indicating the ROPE's
lower and upper bounds. ROPE is also depending on the argument
<code>alternative</code>, e.g., if <code>rope = c(-0.1, 0.1)</code>,
then the actual ROPE is <code>[-0.1, 0.1]</code> given
<code>alternative = "two.sided} (default), \code{[-Inf, 0.1]}
given \code{alternative = "greater</code>, and <code>[-0.1, Inf]</code>
given <code>alternative = "less"</code>. Note that the interval
specified in the argument <code>rope</code> applies to all parameters
which might not be sensible for all parameters.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_ess.tail">ess.tail</code></td>
<td>
<p>a numeric vector with two elements to specify the quantiles
for computing the tail ESS. The default setting is
<code>tail = c(0.025, 0.975)</code>, i.e., tail ESS is the minimum
of effective sample sizes for 0.025 and 0.975 quantiles.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_mcse.tail">mcse.tail</code></td>
<td>
<p>a numeric vector with two elements to specify the quantiles
for computing the tail MCSE. The default setting is
<code>tail = c(0.025, 0.975)</code>, i.e., tail MCSE is the maximum
of Monte Carlo standard error for 0.025 and 0.975 quantiles.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis
for the credible intervals, must be one of <code>"two.sided"</code>
(default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the credible interval. The default setting is
<code>conf.level = 0.95</code>.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying point estimates, measures of
dispersion, and credible intervals.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_r.digits">r.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying R-hat values.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_ess.digits">ess.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying effective sample sizes.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_mcse.digits">mcse.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying Monte Carlo standard errors.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the probability of direction
and the probability of being in the region of practical
equivalence (ROPE).</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="blimp.bayes_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console by using the function <code>blimp.print()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Convergence and Efficiency Diagnostics for Markov Chains</strong></dt><dd><p>Convergence
and efficiency diagnostics for Markov chains is based on following numeric
measures:
</p>

<ul>
<li><p><strong>Potential Scale Reduction (PSR) factor R-hat</strong>: The PSR factor
R-hat compares the between- and within-chain variance for a model
parameter, i.e., R-hat larger than 1 indicates that the between-chain
variance is greater than the within-chain variance and chains have not
mixed well. According to the default setting, the function computes the
improved R-hat as recommended by Vehtari et al. (2020) based on rank-normalizing
(i.e., <code>rank = TRUE</code>) and folding (i.e., <code>fold = TRUE</code>) the
posterior draws after splitting each MCMC chain in half (i.e.,
<code>split = TRUE</code>). The traditional R-hat used in Blimp can be requested
by specifying <code>split = TRUE</code>, <code>rank = FALSE</code>, and
<code>fold = FALSE</code>. Note that the traditional R-hat can catch many
problems of poor convergence, but fails if the chains have different
variances with the same mean parameter or if the chains have infinite
variance with one of the chains having a different location parameter to
the others (Vehtari et al., 2020). According to Gelman et al. (2014) a
R-hat value of 1.1 or smaller for all parameters can be considered evidence
for convergence. The Stan Development Team (2024) recommends running at
least four chains and a convergence criterion of less than 1.05 for the
maximum of rank normalized split-R-hat and rank normalized folded-split-R-hat.
Vehtari et al. (2020), however, recommended to only use the posterior
samples if R-hat is less than 1.01 because the R-hat can fall below 1.1
well before convergence in some scenarios (Brooks &amp; Gelman, 1998; Vats &amp;
Knudon, 2018).
</p>
</li>
<li><p><strong>Effective Sample Size (ESS)</strong>: The ESS is the estimated number
of independent samples from the posterior distribution that would lead
to the same precision as the autocorrelated samples at hand. According
to the default setting, the function computes the ESS based on rank-normalized
split-R-hat and within-chain autocorrelation. The function provides the
estimated Bulk-ESS (<code>B.ESS</code>) and the Tail-ESS (<code>T.ESS</code>). The
Bulk-ESS is a useful measure for sampling efficiency in the bulk of the
distribution (i.e, efficiency of the posterior mean), and the Tail-ESS
is useful measure for sampling efficiency in the tails of the distribution
(e.g., efficiency of tail quantile estimates). Note that by default, the
Tail-ESS is the minimum of the effective sample sizes for 2.5% and 97.5%
quantiles (<code>tail = c(0.025, 0.975)</code>). According to Kruschke (2015),
a rank-normalized ESS greater than 400 is usually sufficient to get a
stable estimate of the Monte Carlo standard error. However, a ESS of
at least 1000 is considered optimal (Zitzmann &amp; Hecht, 2019).
</p>
</li>
<li><p><strong>Monte Carlo Standard Error (MCSE)</strong>: The MCSE is defined as
the standard deviation of the chains divided by their effective sample
size and reflects uncertainty due to the stochastic algorithm of the
Markov Chain Monte Carlo method. The function provides the estimated
Bulk-MCSE (<code>B.MCSE</code>) for the margin of error when using the MCMC
samples to estimate the posterior mean and the Tail-ESS (<code>T.MCSE</code>)
for the margin of error when using the MCMC samples for interval
estimation.
</p>
</li></ul>

</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>a character string indicating the name of the <code>posterior.*</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>posterior distribution of each parameter estimate
in long format</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table with summary measures, convergence, and
efficiency diagnostics</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is a modified copy of functions provided in the <span class="pkg">rstan</span>
package by Stan Development Team (2024) and <span class="pkg">bayestestR</span> package by
Makowski et al. (2019).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Brooks, S. P. and Gelman, A. (1998). General Methods for Monitoring Convergence
of Iterative Simulations. <em>Journal of Computational and Graphical Statistics, 7</em>(4):
434–455. MR1665662.
</p>
<p>Gelman, A., &amp; Rubin, D.B. (1992). Inference from iterative simulation using
multiple sequences. <em>Statistical Science, 7</em>, 457-472.
https://doi.org/10.1214/ss/1177011136
</p>
<p>Keller, B. T., &amp; Enders, C. K. (2023). <em>Blimp user’s guide</em> (Version 3).
Retrieved from www.appliedmissingdata.com/blimp
</p>
<p>Kruschke, J. (2015). <em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em>.
Academic Press.
</p>
<p>Makowski, D., Ben-Shachar, M., &amp; Lüdecke, D. (2019). bayestestR: Describing
effects and their uncertainty, existence and significance within the Bayesian
framework. <em>Journal of Open Source Software, 4</em>(40), 1541.
https://doi.org/10.21105/joss.01541
</p>
<p>Stan Development Team (2024). <em>RStan: the R interface to Stan</em>. R package
version 2.32.6. https://mc-stan.org/.
</p>
<p>Vats, D. and Knudson, C. (2018). Revisiting the Gelman-Rubin Diagnostic.
arXiv:1812.09384.
</p>
<p>Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; Bürkner, P.-C. (2020).
Rank-normalization, folding, and localization: An improved R-hat for assessing
convergence of MCMC. <em>Bayesian analysis, 16</em>(2), 667-718.
https://doi.org/110.1214/20-BA1221
</p>
<p>Zitzmann, S., &amp; Hecht, M. (2019). Going beyond convergence in Bayesian estimation:
Why precision matters too and how to assess it. <em>Structural Equation Modeling, 26</em>(4),
646–661. https://doi.org/10.1080/10705511.2018.1545232
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blimp">blimp</a></code>, <code><a href="#topic+blimp.update">blimp.update</a></code>, <code><a href="#topic+blimp.run">blimp.run</a></code>,
<code><a href="#topic+blimp.plot">blimp.plot</a></code>,<code><a href="#topic+blimp.print">blimp.print</a></code>, <code><a href="#topic+blimp.plot">blimp.plot</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Blimp Example 4.3: Linear Regression

# Example 1a: Default setting, specifying name of the folder
blimp.bayes("Posterior_Ex4.3")

# Example 1b: Default setting, specifying the posterior file
blimp.bayes("Posterior_Ex4.3/posterior.csv")

# Example 2a: Print all summary measures, convergence, and efficiency diagnostics
blimp.bayes("Posterior_Ex4.3", print = "all")

# Example 3a: Print default measures plus MAP
blimp.bayes("Posterior_Ex4.3", print = c("default", "map"))

# Example 4: Print traditional R-hat in line with Blimp
blimp.bayes("Posterior_Ex4.3", split = TRUE, rank = FALSE, fold = FALSE)

# Example 5: Print probability of direction and the probability of
# being ROPE [-0.1, 0.1]
blimp.bayes("Posterior_Ex4.3", pd = TRUE, rope = c(-0.1, 0.1))

# Example 6: Write Results into a text file
blimp.bayes("Posterior_Ex4.3", write = "Bayes_Summary.txt")

# Example 7b: Write Results into a Excel file
blimp.bayes("Posterior_Ex4.3", write = "Bayes_Summary.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='blimp.plot'>Blimp Trace Plots and Posterior Distribution Plots</h2><span id='topic+blimp.plot'></span>

<h3>Description</h3>

<p>This function reads the posterior distribution including burn-in and
post-burn-in phase for all parameters saved in long format in a file called
<code>posterior.*</code> by the function <code>blimp.run</code> or <code>blimp</code> when specifying
<code>posterior = TRUE</code> to display trace plots and posterior distribution plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blimp.plot(x, plot = c("none", "trace", "post"), param = NULL, labels = TRUE,
           burnin = TRUE, point = c("all", "none", "m", "med", "map"),
           ci = c("none", "eti", "hdi"), conf.level = 0.95, hist = TRUE,
           density = TRUE, area = TRUE, alpha = 0.4, fill = "gray85",
           facet.nrow = NULL, facet.ncol = NULL,
           facet.scales = c("fixed", "free", "free_x", "free_y"),
           xlab = NULL, ylab = NULL, xlim = NULL, ylim = NULL,
           xbreaks = ggplot2::waiver(), ybreaks = ggplot2::waiver(),
           xexpand = ggplot2::waiver(), yexpand = ggplot2::waiver(),
           palette = "Set 2", binwidth = NULL, bins = NULL,
           density.col = "#0072B2", shape = 21,
           point.col = c("#CC79A7", "#D55E00", "#009E73"),
           linewidth = 0.6, linetype = "dashed", line.col = "black",
           plot.margin = NULL, legend.title.size = 10, legend.text.size = 10,
           legend.box.margin = NULL, saveplot = c("all", "none", "trace", "post"),
           filename = "Blimp_Plot.pdf", file.plot = c("_TRACE", "_POST"),
           width = NA, height = NA, units = c("in", "cm", "mm", "px"), dpi = 600,
           check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blimp.plot_+3A_x">x</code></td>
<td>
<p>a character string indicating the name of folder
containing the <code>posterior.*</code> file, e.g.,
<code>"Posterior_Ex4.3"</code> or the name of the
<code>posterior.*</code> file with or without any file
extension, e.g., <code>"Posterior_ExEx4.3/posterior.csv"</code>
or <code>"Posterior_ExEx4.3/posterior"</code>. Alternatively,
a <code>misty.object</code> of type <code>blimp</code> can be
specified, i.e., result object of the <code>blimp.plot()</code>
function. Note that if the <code>posterior</code> file is
specified without file extension while multiple
<code>posterior.*</code> files in different file formats
are available, then the file is read in following
order: <code>csv</code>,<code>RData</code>, <code>rds</code>,
and <code>xlsx</code>.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_plot">plot</code></td>
<td>
<p>a character string indicating the type of plot to
display, i.e., <code>"none"</code> for not displaying any
plot, <code>"trace"</code> (default) for displaying trace
plots, and <code>post</code> for displaying posterior
distribution plots.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_param">param</code></td>
<td>
<p>a numeric vector indicating which parameters to print
for the trace plots or posterior distribution plots.
Note that the number of the parameter (<code>Param</code>)
and the parameter specification (<code>L1</code>, <code>L2</code>,
and <code>L3</code>) are provided in the text file
<code>"partable.txt"</code>. Note that parameters with zero
variance are excluded by default.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_labels">labels</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), parameter labels
(e.g., <code>y Beta x</code> for the slope of the regression
y on x) are shown in the facet labels. If <code>FALSE</code>,
the numbers of the parameter (e.g., <code>Parameter 1</code>
are shown in the the facet labels.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_burnin">burnin</code></td>
<td>
<p>logical: if <code>FALSE</code>, the burn-in iterations are
discarded when displaying trace plots. The default
setting for <code>plot = "trace"</code> is <code>TRUE</code>.
Note that the burn-in iterations are always discarded
when displaying posterior distribution plots
(<code>plot = "post"</code>) regardless of the setting of
the argument <code>burnin</code>.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_point">point</code></td>
<td>
<p>a character vector indicating the point estimate(s)
to be displayed in the posterior distribution plots,
i.e., <code>"all"</code> for all point estimates, <code>"none"</code>
for not displaying any point estimates, <code>"m"</code>
for the posterior mean estimate, <code>"med"</code> (default)
for the posterior median estimate, and <code>"map"</code>
for the maximum a posterior estimate.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_ci">ci</code></td>
<td>
<p>a character string indicating the type of credible
interval to be displayed in the posterior distribution
plots, i.e., <code>"none"</code> for not displaying any
credible intervals, <code>"eti"</code> (default) for displaying
the equal-tailed intervals and <code>"hdi"</code> for displaying
the highest density interval.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the
confidence level of the credible interval (default is
<code>0.95</code>).</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_hist">hist</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), histograms are
drawn in the posterior probability plots.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_density">density</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), density curves are
drawn in the posterior probability plots.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_area">area</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), statistical not
significant and statistical significant area is
filled with a different color and vertical lines are
drawn.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for the <code>alpha</code>
argument (default is <code>0.4</code>) for the <code>annotate</code>,
and <code>geom_histogram</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_fill">fill</code></td>
<td>
<p>a character string indicating the color for the
<code>"fill"</code> argument (default is <code>"gray85"</code>)
for the <code>annotate</code> and <code>geom_histogram</code>
functions.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_facet.nrow">facet.nrow</code></td>
<td>
<p>a numeric value indicating the <code>nrow</code> argument
(default is <code>NULL</code>) for the <code>facet_wrap</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_facet.ncol">facet.ncol</code></td>
<td>
<p>a numeric value indicating the <code>ncol</code> argument
(default is <code>2</code>) for the <code>facet_wrap</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_facet.scales">facet.scales</code></td>
<td>
<p>a character string indicating the <code>scales</code> argument
(default is <code>"free"</code>) for the <code>facet_wrap</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_xlab">xlab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
for the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_ylab">ylab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
for the <code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_xlim">xlim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument (default it <code>NULL</code>) for
the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument (default it <code>NULL</code>) for
the <code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_xbreaks">xbreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
(default is <code>ggplot2::waiver()</code>) for the
<code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
(default is <code>ggplot2::waiver()</code>) for the
<code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_xexpand">xexpand</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>expand</code> argument (default is <code>(0.02, 0)</code>)
for the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_yexpand">yexpand</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>expand</code> argument for the <code>scale_y_continuous</code>
function. Note that the default setting depends
on the type of plot, e.g., <code>(0.02, 0)</code> for the
trace plots and <code>expansion(mult = c(0, 0.05))</code>
for the posterior distribution plots.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_palette">palette</code></td>
<td>
<p>a character string indicating the palette name (default
is <code>"Set 2"</code>) for the <code>hcl.colors</code> function.
Note that the character string must be one of
<code>hcl.pals()</code>.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_binwidth">binwidth</code></td>
<td>
<p>a numeric value indicating the <code>binwidth</code> argument
(default is to use the number of bins in <code>bins</code>
argument) for the <code>geom_histogram</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_bins">bins</code></td>
<td>
<p>a numeric value indicating the <code>bins</code> argument
(default is <code>30</code>) for the <code>geom_histogram</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_density.col">density.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
(default is <code>"#0072B2"</code>) for the <code>geom_density</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_shape">shape</code></td>
<td>
<p>a numeric value indicating the <code>shape</code> argument
(default is <code>21</code>) for the <code>geom_point</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_point.col">point.col</code></td>
<td>
<p>a character vector with three elements indicating the
<code>values</code> argument (default is
<code>c("#CC79A7", "#D55E00", "#009E73")</code>) for the
<code>scale_color_manual</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_linewidth">linewidth</code></td>
<td>
<p>a numeric value indicating the <code>linewidth</code> argument
(default is <code>0.6</code>) for the <code>geom_vline</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_linetype">linetype</code></td>
<td>
<p>a numeric value indicating the <code>linetype</code> argument
(default is <code>"dashed"</code>) for the <code>geom_vline</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_line.col">line.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
(default is <code>"black"</code>) for the <code>geom_vline</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_plot.margin">plot.margin</code></td>
<td>
<p>a numeric vector indicating the <code>plot.margin</code>
argument for the <code>theme</code> function. Note that the
default setting depends on the type of the plot, e.g.,
<code>c(4, 15, -10, 0)</code> for the trace plots, and
<code>c(4, 15, 4, 4)</code> for the autocorrelation plots.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_legend.title.size">legend.title.size</code></td>
<td>
<p>a numeric value indicating the <code>legend.title</code>
argument (default is <code>element_text(size = 10)</code>)
for the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>a numeric value indicating the <code>legend.text</code>
argument (default is <code>element_text(size = 10)</code>)
for the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_legend.box.margin">legend.box.margin</code></td>
<td>
<p>a numeric vector indicating the <code>legend.box.margin</code>
argument for the <code>theme</code> function. Note that the
default setting depends on the type of plot, e.g.,
<code>c(-16, 6, 6, 6)</code> for the trace plots, and
<code>c(-25, 6, 6, 6)</code> for the posterior distribution
plots with displaying point estimates.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_saveplot">saveplot</code></td>
<td>
<p>a character vector indicating the plot to be saved,
i.e., <code>"all"</code> for saving all plots, <code>"none"</code>
(default) for not saving any plots, <code>"trace"</code>
for saving the trace plots and <code>post</code> for the saving
the posterior distribution plots.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument (default is <code>"Blimp_Plot.pdf"</code>) including
the file extension for the <code>ggsave</code> function.
Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default), <code>".jpeg"</code>,
<code>".tiff"</code>, <code>".png"</code>, <code>".bmp"</code>,
<code>".svg"</code> or <code>".wmf"</code> needs to be specified
as file extension in the <code>filename</code> argument.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_file.plot">file.plot</code></td>
<td>
<p>a character vector with two elements for distinguishing
different types of plots. By default, the character
string specified in the argument <code>"filename"</code>
(<code>"Blimp_Plot"</code>) is concatenated with <code>"_TRACE"</code>
(<code>"Blimp_Plot_TRACE"</code>) for the trace plots,
and <code>"_POST"</code> (<code>"Blimp_Plot_POST"</code>) for
the posterior distribution plots.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="blimp.plot_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument
specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>a character string indicating the name of the <code>posterior.*</code> file</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with posterior distribution of each parameter estimate
in long format (<code>plotdat</code>), plot data for the trace
plots (<code>trace</code>), and plot data for the posterior
distribution plots (<code>post</code>).</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>list with the trace plots (<code>trace</code> and posterior distribution
plots (<code>post</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Keller, B. T., &amp; Enders, C. K. (2023). <em>Blimp user’s guide</em> (Version 3).
Retrieved from www.appliedmissingdata.com/blimp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blimp">blimp</a></code>, <code><a href="#topic+blimp.update">blimp.update</a></code>, <code><a href="#topic+blimp.run">blimp.run</a></code>,
<code><a href="#topic+blimp.print">blimp.print</a></code>, <code><a href="#topic+blimp.plot">blimp.plot</a></code>, <code><a href="#topic+blimp.bayes">blimp.bayes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Blimp Example 4.3: Linear Regression

#..........
# Trace Plots

# Example 1a: Default setting, specifying name of the folder
blimp.plot("Posterior_Ex4.3")

# Example 1b: Default setting, specifying the posterior file
blimp.plot("Posterior_Ex4.3/posterior.csv")

# Example 1c: Print parameters 2, 3, 4, and 5
blimp.plot("Posterior_Ex4.3", param = 2:5)

# Example 1e: Arrange panels in three columns
blimp.plot("Posterior_Ex4.3", ncol = 3)

# Example 1f: Specify "Pastel 1" palette for the hcl.colors function
blimp.plot("Posterior_Ex4.3", palette = "Pastel 1")

#..........
# Posterior Distribution Plots

# Example 2a: Default setting, i.e., posterior median and equal-tailed interval
blimp.plot("Posterior_Ex4.3", plot = "post")

# Example 2b: Display posterior mean and maximum a posteriori
blimp.plot("Posterior_Ex4.3", plot = "post", point = c("m", "map"))

# Example 2c: Display maximum a posteriori and highest density interval
blimp.plot("Posterior_Ex4.3", plot = "post", point = "map", ci = "hdi")

# Example 2d: Do not display any point estimates and credible interval
blimp.plot("Posterior_Ex4.3", plot = "post", point = "none", ci = "none")

# Example 2d: Do not display histograms
blimp.plot("Posterior_Ex4.3", plot = "post", hist = FALSE)

#..........
# Save Plots

# Example 3a: Save all plots in pdf format
blimp.plot("Posterior_Ex4.3", saveplot = "all")

# Example 3b: Save all plots in png format with 300 dpi
blimp.plot("Posterior_Ex4.3", saveplot = "all", filename = "Blimp_Plot.png", dpi = 300)

# Example 3a: Save posterior distribution plot, specify width and height of the plot
blimp.plot("Posterior_Ex4.3", plot = "none", saveplot = "post",
           width = 7.5, height = 7)

#----------------------------------------------------------------------------
# Plot from misty.object

# Create misty.object
object &lt;- blimp.plot("Posterior_Ex4.3", plot = "none")

# Trace plot
blimp.plot(object, plot = "trace")

# Posterior distribution plot
blimp.plot(object, plot = "post")

#----------------------------------------------------------------------------
# Create Plots Manually

# Load ggplot2 package
library(ggplot2)

# Create misty object
object &lt;- blimp.plot("Posterior_Ex4.3", plot = "none")

#..........
# Example 4: Trace Plots

# Extract data
data.trace &lt;- object$data$trace

# Plot
ggplot(data.trace, aes(x = iter, y = value, color = chain)) +
  annotate("rect", xmin = 0, xmax = 1000, ymin = -Inf, ymax = Inf,
           alpha = 0.4, fill = "gray85") +
  geom_line() +
  facet_wrap(~ param, ncol = 2, scales = "free") +
  scale_x_continuous(name = "", expand = c(0.02, 0)) +
  scale_y_continuous(name = "", expand = c(0.02, 0)) +
  scale_colour_manual(name = "Chain",
                      values = hcl.colors(n = 2, palette = "Set 2")) +
  theme_bw() +
  guides(color = guide_legend(nrow = 1, byrow = TRUE)) +
  theme(plot.margin = margin(c(4, 15, -10, 0)),
        legend.position = "bottom",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.box.margin = margin(c(-16, 6, 6, 6)),
        legend.background = element_rect(fill = "transparent"))

#..........
# Example 5: Posterior Distribution Plots

# Extract data
data.post &lt;- object$data$post

# Plot
ggplot(data.post, aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), color = "black", alpha = 0.4,
                 fill = "gray85") +
  geom_density(color = "#0072B2") +
  geom_vline(data = data.frame(param = levels(data.post$param),
                               stat = tapply(data.post$value, data.post$param, median)),
             aes(xintercept = stat, color = "Median"), linewidth = 0.6) +
  geom_vline(data = data.frame(param = levels(data.post$param),
                               low = tapply(data.post$value, data.post$param,
                                            function(y) quantile(y, probs = 0.025))),
             aes(xintercept = low), linetype = "dashed", linewidth = 0.6) +
  geom_vline(data = data.frame(param = levels(data.post$param),
                               upp = tapply(data.post$value, data.post$param,
                                            function(y) quantile(y, probs = 0.975))),
             aes(xintercept = upp), linetype = "dashed", linewidth = 0.6) +
  facet_wrap(~ param, ncol = 2, scales = "free") +
  scale_x_continuous(name = "", expand = c(0.02, 0)) +
  scale_y_continuous(name = "Probability Density, f(x)",
                     expand = expansion(mult = c(0L, 0.05))) +
  scale_color_manual(name = "Point Estimate", values = c(Median = "#D55E00")) +
  labs(caption = "95% Equal-Tailed Interval") +
  theme_bw() +
  theme(plot.margin = margin(c(4, 15, -8, 4)),
        plot.caption = element_text(hjust = 0.5, vjust = 7),
        legend.position = "bottom",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.box.margin = margin(c(-30, 6, 6, 6)),
        legend.background = element_rect(fill = "transparent"))

## End(Not run)
</code></pre>

<hr>
<h2 id='blimp.print'>Print Blimp Output</h2><span id='topic+blimp.print'></span>

<h3>Description</h3>

<p>This function prints the result sections of a Blimp output file (<code>.blimp-out</code>)
on the R console. By default, the function prints selected result sections,
i.e., <code>Algorithmic Options Specified</code>, <code>Data Information</code>,
<code>Model Information</code>, <code>Warning Messages</code>, <code>Outcome Model Estimates</code>,
and <code>Generated Parameters</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blimp.print(x,
            result = c("all", "default", "algo.options", "data.info",
            "model.info", "warn.mess", "error.mess", "out.model", "gen.param"),
            exclude = NULL, color = c("none", "blue", "green"),
            style = c("bold", "regular"), not.result = TRUE,
            write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blimp.print_+3A_x">x</code></td>
<td>
<p>a character string indicating the name of the Blimp output
file with or without the file extension <code>.blimp-out</code>,
e.g., <code>"Blimp_Output.blimp-out"</code> or <code>"Blimp_Output"</code>.
Alternatively, a <code>misty.object</code> of type <code>blimp</code>
can be specified, i.e., result object of the <code>blimp.print()</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_result">result</code></td>
<td>
<p>a character vector specifying Blimp result sections included
in the output (see 'Details').</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_exclude">exclude</code></td>
<td>
<p>a character vector specifying Blimp input command or result
sections excluded from the output (see 'Details').</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_color">color</code></td>
<td>
<p>a character vector with two elements indicating the colors
used for the main headers (e.g., <code>"ALGORITHMIC OPTIONS SPECIFIED:"</code>),
and for the headers <code>Outcome Variable:</code> and
<code>Missing predictor:</code>, <code>Latent Variable:</code>,
and <code>Covariance Matrix:</code>.</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_style">style</code></td>
<td>
<p>a character vector with two elements indicating the style
used for headers (e.g., <code>"ALGORITHMIC OPTIONS SPECIFIED:"</code>),
and for the main headers (e.g., <code>"ALGORITHMIC OPTIONS SPECIFIED:"</code>),
and for the headers <code>Outcome Variable:</code> and
<code>Missing predictor:</code>, <code>Complete variable:</code>, <code>Latent Variable:</code>,
and <code>Covariance Matrix:</code>.</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_not.result">not.result</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the result sections not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>).</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="blimp.print_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Result Sections</strong></dt><dd><p>Following result sections can be selected by
using the <code>result</code> argument or excluded by using the <code>exclude</code>
argument:
</p>

<ul>
<li><p><code>"algo.options"</code> for the <code>ALGORITHMIC OPTIONS SPECIFIED</code> section
</p>
</li>
<li><p><code>"simdat.summary"</code> for the <code>SIMULATED DATA SUMMARIES</code> section
</p>
</li>
<li><p><code>"order.simdat"</code> for the <code>VARIABLE ORDER IN SIMULATED DATA</code> section
</p>
</li>
<li><p><code>"burnin.psr"</code> for the <code>BURN-IN POTENTIAL SCALE REDUCTION (PSR) OUTPUT</code> section
</p>
</li>
<li><p><code>"mh.accept"</code> for the <code>METROPOLIS-HASTINGS ACCEPTANCE RATES</code> section
</p>
</li>
<li><p><code>"data.info"</code> for the <code>DATA INFORMATION</code> section
</p>
</li>
<li><p><code>"var.imp"</code> for the <code>VARIABLES IN IMPUTATION MODEL</code> section
</p>
</li>
<li><p><code>"model.info"</code> for the <code>MODEL INFORMATION</code> section
</p>
</li>
<li><p><code>"param.label"</code> for the <code>PARAMETER LABELS</code> section
</p>
</li>
<li><p><code>"warn.mess"</code> for the <code>WARNING MESSAGES</code> section
</p>
</li>
<li><p><code>"fit"</code> for the <code>MODEL FIT</code> section
</p>
</li>
<li><p><code>"cor.resid"</code> for the <code>CORRELATIONS AMONG RESIDUALS</code> section
</p>
</li>
<li><p><code>"out.model"</code> for the <code>OUTCOME MODEL ESTIMATES</code> section
</p>
</li>
<li><p><code>"pred.model"</code> for the <code>PREDICTOR MODEL ESTIMATES</code> section
</p>
</li>
<li><p><code>"gen.param"</code> for the <code>GENERATED PARAMETERS</code> section
</p>
</li>
<li><p><code>"order.impdat"</code> for the <code>VARIABLE ORDER IN IMPUTED DATA</code> section
</p>
</li></ul>

<p>Note that all result sections are requested by specifying <code>result = "all"</code>.
The <code>result</code> argument is also used to select one (e.g., <code>result = "algo.options"</code>)
or more than one result sections (e.g., <code>result = c("algo.options", "fit")</code>),
or to request result sections in addition to the default setting (e.g.,
<code>result = c("default", "fit")</code>). The <code>exclude</code> argument is used
to exclude result sections from the output (e.g., <code>exclude = "algo.options"</code>).
</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>character string or misty object</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>print</code></td>
<td>
<p>print objects</p>
</td></tr>
<tr><td><code>notprint</code></td>
<td>
<p>character vectors indicating the result sections not requested</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with Blimp version (<code>blimp</code>) and result sections
(<code>result</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Keller, B. T., &amp; Enders, C. K. (2023). <em>Blimp user’s guide</em> (Version 3).
Retrieved from www.appliedmissingdata.com/blimp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blimp">blimp</a></code>, <code><a href="#topic+blimp.update">blimp.update</a></code>, <code><a href="#topic+blimp.run">blimp.run</a></code>, <code><a href="#topic+blimp.plot">blimp.plot</a></code>, <code><a href="#topic+blimp.bayes">blimp.bayes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Blimp Example 4.3: Linear Regression

# Example 1a: Default setting
blimp.print("Ex4.3.blimp-out")

# Example 1c: Print OUTCOME MODEL ESTIMATES only
blimp.print("Ex4.3.blimp-out", result = "out.model")

# Example 1d: Print MODEL FIT in addition to the default setting
blimp.print("Ex4.3.blimp-out", result = c("default", "fit"))

# Example 1e: Exclude DATA INFORMATION section
blimp.print("Ex4.3.blimp-out", exclude = "data.info")

# Example 1f: Print all result sections, but exclude MODEL FIT section
blimp.print("Ex4.3.blimp-out", result = "all", exclude = "fit")

# Example 1g: Print result section in a different order
blimp.print("Ex4.3.blimp-out", result = c("model.info", "fit", "algo.options"))

#----------------------------------------------------------------------------
# misty.object of type 'blimp.print'

# Example 2
# Create misty.object
object &lt;- blimp.print("Ex4.3.blimp-out", output = FALSE)

# Print misty.object
blimp.print(object)

#----------------------------------------------------------------------------
# Write Results

# Example 3: Write Results into a text file
blimp.print("Ex4.3.blimp-out", write = "Output_4-3.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='blimp.run'>Run Blimp Models</h2><span id='topic+blimp.run'></span>

<h3>Description</h3>

<p>This function runs a group of Blimp models (<code>.imp</code> files) located within a
single directory or nested within subdirectories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blimp.run(target = getwd(), recursive = FALSE,
          replace.out = c("always", "never", "modified"), posterior = FALSE,
          folder = "Posterior_", format = c("csv", "csv2", "xlsx", "rds", "RData"),
          clear = FALSE, Blimp = .detect.blimp(), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blimp.run_+3A_target">target</code></td>
<td>
<p>a character string indicating the directory containing
Blimp input files (<code>.imp</code>) to run, a character string
indicating a single <code>.imp</code> file to run, or a character
vector for multiple <code>.imp</code> files to run. May be a full
path, relative path, a file name, or a vector of file names
within the working directory.</p>
</td></tr>
<tr><td><code id="blimp.run_+3A_recursive">recursive</code></td>
<td>
<p>logical: if <code>TRUE</code>, run all models nested in subdirectories
within a directory. Not relevant if a single or multiple <code>.imp</code>
files were specified for the argument <code>target</code>.</p>
</td></tr>
<tr><td><code id="blimp.run_+3A_replace.out">replace.out</code></td>
<td>
<p>a character string for specifying three settings:
<code>"always"</code> (default), which runs all models, regardless
of whether an output file for the model exists, <code>"never"</code>,
which does not run any model that has an existing output file,
and <code>"modified"</code>, which only runs a model if the
modified date for the input file is more recent than the
output file modified date.</p>
</td></tr>
<tr><td><code id="blimp.run_+3A_posterior">posterior</code></td>
<td>
<p>logical: if <code>TRUE</code>, the posterior distribution including
burn-in and post-burn-in phase for all parameters are saved
in long format in a file called <code>posterior.*</code> in the folder
specified in the argument <code>folder</code> and <code>.imp</code> file
name in the format specified in the argument <code>format</code>.</p>
</td></tr>
<tr><td><code id="blimp.run_+3A_folder">folder</code></td>
<td>
<p>a character string indicating the prefix of the folder for
saving the posterior distributions. The default setting is
<code>folder = "Posterior_"</code>.</p>
</td></tr>
<tr><td><code id="blimp.run_+3A_format">format</code></td>
<td>
<p>a character vector indicating the file format(s) for saving the
posterior distributions, i.e., <code>"csv"</code> (default) for
<code>write.csv()</code>, <code>"csv2"</code> for <code>write.csv2()</code>,
<code>"xlsx"</code> for <code>write.xlsx()</code>, <code>"rds"</code> for
<code>saveRDS()</code>, and <code>"RData"</code> for <code>write()</code>.</p>
</td></tr>
<tr><td><code id="blimp.run_+3A_clear">clear</code></td>
<td>
<p>logical: if <code>TRUE</code>, the console is cleared
after estimating each model.</p>
</td></tr>
<tr><td><code id="blimp.run_+3A_blimp">Blimp</code></td>
<td>
<p>a character string for specifying the name or path of the
Blimp executable to be used for running models. This covers
situations where Blimp is not in the system's path, or where
one wants to test different versions of the Blimp program.
Note that there is no need to specify this argument for most
users since it has intelligent defaults.</p>
</td></tr>
<tr><td><code id="blimp.run_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Note</h3>

<p>This function is based on the <code>detect_blimp()</code> and <code>rblimp()</code> function
in the <span class="pkg">rblimp</span> package by Brian T.Keller (2024).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Keller, B. T., &amp; Enders, C. K. (2023). <em>Blimp user’s guide</em> (Version 3). Retrieved
from www.appliedmissingdata.com/blimp
</p>
<p>Keller B (2024). <em>rblimp: Integration of Blimp Software into R</em>. R package
version 0.1.31. https://github.com/blimp-stats/rblimp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blimp">blimp</a></code>, <code><a href="#topic+blimp.update">blimp.update</a></code>, <code><a href="#topic+blimp.print">blimp.print</a></code>, <code><a href="#topic+blimp.plot">blimp.plot</a></code>, <code><a href="#topic+blimp.bayes">blimp.bayes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Run Blimp models located within the current working directory
blimp.run()

# Example 2: Run Blimp models located nested within subdirectories
blimp.run(recursive = TRUE)

# Example 3: Run Blimp input file
blimp.run("Ex4.1a.imp")

# Example 4: Run Blimp input files
blimp.run(c("Ex4.1a.imp", "Ex4.1b.imp"))

# Example 5: Run Blimp models, save posterior distribution in a R workspace
blimp.run(posterior = TRUE, format = "workspace")

## End(Not run)
</code></pre>

<hr>
<h2 id='blimp.update'>Blimp Input Updating</h2><span id='topic+blimp.update'></span>

<h3>Description</h3>

<p>This function updates specific input command sections of a <code>misty.object</code>
of type <code>blimp</code> to create an updated Blimp input file, run the updated
input file by using the <code>blimp.run()</code> function, and print the updated
Blimp output file by using the <code>blimp.print()</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blimp.update(x, update, file = "Blimp_Input_Update.imp", comment = FALSE,
             replace.inp = TRUE, blimp.run = TRUE, posterior = FALSE,
             folder = "Posterior_",
             format = c("csv", "csv2", "xlsx", "rds", "RData"),
             clear = TRUE, replace.out = c("always", "never", "modified"),
             Blimp = .detect.blimp(),
             result = c("all", "default", "algo.options",  "data.info",
                        "model.info", "warn.mess", "out.model", "gen.param"),
             exclude = NULL, color = c("none", "blue", "violet"),
             style = c("bold", "regular"), not.result = TRUE,
             write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blimp.update_+3A_x">x</code></td>
<td>
<p><code>misty.object</code> object of type <code>blimp</code>.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_update">update</code></td>
<td>
<p>a character vector containing the updated input command
sections.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the updated Blimp
input file with or without the file extension <code>.imp</code>,
e.g., <code>"Blimp_Input_Update.imp"</code> or
<code>"Blimp_Input_Update.imp"</code>.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_comment">comment</code></td>
<td>
<p>logical: if <code>FALSE</code> (default), comments (i.e., text
after the <code>#</code> symbol) are removed from the input text
specified in the argument <code>x</code>.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_replace.inp">replace.inp</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), an existing input
file will be replaced.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_blimp.run">blimp.run</code></td>
<td>
<p>logical: if <code>TRUE</code>, the input file specified in the
argument <code>file</code> containing the input text specified
in the argument <code>x</code> is run using the <code>blimp.run()</code>
function.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_posterior">posterior</code></td>
<td>
<p>logical: if <code>TRUE</code>, the posterior distribution including
burn-in and post-burn-in phase for all parameters are saved
in long format in a file called <code>posterior.*</code> in the
folder specified in the argument <code>folder</code> and <code>.imp</code>
file name in the format specified in the argument <code>format</code>.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_folder">folder</code></td>
<td>
<p>a character string indicating the prefix of the folder for
saving the posterior distributions. The default setting is
<code>folder = "Posterior_"</code>.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_format">format</code></td>
<td>
<p>a character vector indicating the file format(s) for saving the
posterior distributions, i.e., <code>"csv"</code> (default) for
<code>write.csv()</code>, <code>"csv2"</code> for <code>write.csv2()</code>,
<code>"xlsx"</code> for <code>write.xlsx()</code>, <code>"rds"</code> for
<code>saveRDS()</code>, and <code>"RData"</code> for <code>write()</code>.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_clear">clear</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the console is cleared
after estimating each model.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_replace.out">replace.out</code></td>
<td>
<p>a character string for specifying three settings:
<code>"always"</code> (default), which runs all models, regardless
of whether an output file for the model exists, <code>"never"</code>,
which does not run any model that has an existing output file,
and <code>"modified"</code>, which only runs a model if the
modified date for the input file is more recent than the
output file modified date.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_blimp">Blimp</code></td>
<td>
<p>a character string for specifying the name or path of the
Blimp executable to be used for running models. This covers
situations where Blimp is not in the system's path, or where
one wants to test different versions of the Blimp program.
Note that there is no need to specify this argument for most
users since it has intelligent defaults.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_result">result</code></td>
<td>
<p>a character vector specifying Blimp result sections included
in the output (see 'Details' in the <code><a href="#topic+blimp.print">blimp.print</a></code>
function).</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_exclude">exclude</code></td>
<td>
<p>a character vector specifying Blimp input command or result
sections excluded from the output (see 'Details' in the
<code><a href="#topic+blimp.print">blimp.print</a></code> function).</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_color">color</code></td>
<td>
<p>a character vector with two elements indicating the colors
used for headers (e.g., <code>"ALGORITHMIC OPTIONS SPECIFIED:"</code>),
and for the header <code>Outcome Variable:</code> and
<code>Missing predictor:</code> including variables names.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_style">style</code></td>
<td>
<p>a character vector with two elements indicating the style
used for headers (e.g., <code>"ALGORITHMIC OPTIONS SPECIFIED:"</code>),
and for the header <code>Outcome Variable:</code> and
<code>Missing predictor:</code> including variables names, i.e.,
<code>regular</code>, for regular text, <code>bold</code> for bold text,
<code>italic</code>, for italic text, and <code>underline</code> for
underline text.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_not.result">not.result</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the result sections not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>).</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console by using the function <code>blimp.print()</code>.</p>
</td></tr>
<tr><td><code id="blimp.update_+3A_data">data</code></td>
<td>
<p>a matrix or data frame from which the variables names for
the section <code>VARIABLES</code> are extracted when using the
<code>...</code> specification in the <code>VARIABLES</code> section.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Bimp Input Sections</strong></dt><dd><p>The function is used to update
following Blimp input sections:
</p>

<ul>
<li><p><code>DATA</code>
</p>
</li>
<li><p><code>VARIABLES</code>
</p>
</li>
<li><p><code>CLUSTERID</code>
</p>
</li>
<li><p><code>ORDINAL</code>
</p>
</li>
<li><p><code>NOMINAL</code>
</p>
</li>
<li><p><code>COUNT</code>
</p>
</li>
<li><p><code>WEIGHT</code>
</p>
</li>
<li><p><code>MISSING</code>
</p>
</li>
<li><p><code>LATENT</code>
</p>
</li>
<li><p><code>RANDOMEFFECT</code>
</p>
</li>
<li><p><code>TRANSFORM</code>
</p>
</li>
<li><p><code>BYGROUP</code>
</p>
</li>
<li><p><code>FIXED</code>
</p>
</li>
<li><p><code>CENTER</code>
</p>
</li>
<li><p><code>MODEL</code>
</p>
</li>
<li><p><code>SIMPLE</code>
</p>
</li>
<li><p><code>PARAMETERS</code>
</p>
</li>
<li><p><code>TEST</code>
</p>
</li>
<li><p><code>FCS</code>
</p>
</li>
<li><p><code>SIMUALTE</code>
</p>
</li>
<li><p><code>SEED</code>
</p>
</li>
<li><p><code>BURN</code>
</p>
</li>
<li><p><code>ITERATIONS</code>
</p>
</li>
<li><p><code>CHAINS</code>
</p>
</li>
<li><p><code>NIMPS</code>
</p>
</li>
<li><p><code>THIN</code>
</p>
</li>
<li><p><code>OPTIONS</code>
</p>
</li>
<li><p><code>OUTPUT</code>
</p>
</li>
<li><p><code>SAVE</code>
</p>
</li></ul>

</dd>
<dt><strong>The <code>---;</code> Specification</strong></dt><dd><p>The <code>---;</code> specification
is used to remove entire sections (e.g., <code>CENTER: ---;</code>) from the Blimp
input. Note that <code>---;</code> including the semicolon <code>;</code> needs to be
specified, i.e., <code>---</code> without the semicolon <code>;</code> will result in an
error message.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p><code>misty.object</code> object of type <code>blimp</code></p>
</td></tr>
<tr><td><code>update</code></td>
<td>
<p>a character vector containing the updated Blimp input command
sections</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>write</code></td>
<td>
<p>updated write command sections</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result sections (<code>result</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Keller, B. T., &amp; Enders, C. K. (2023). <em>Blimp user’s guide</em> (Version 3).
Retrieved from www.appliedmissingdata.com/blimp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blimp.run">blimp.run</a></code>, <code><a href="#topic+blimp.print">blimp.print</a></code>, <code><a href="#topic+blimp.plot">blimp.plot</a></code>, <code><a href="#topic+blimp.bayes">blimp.bayes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Example 1a: Update BURN and ITERATIONS section

# Specify Blimp input
input &lt;- '
DATA: data1.csv;
ORDINAL: d;
MISSING: 999;
FIXED: d;
CENTER: x1 x2;
MODEL: y ~ x1 x2 d;
SEED: 90291;
BURN: 1000;
ITERATIONS: 10000;
'

# Run Blimp input
mod0 &lt;- blimp(input, file = "Ex4.3.imp", clear = FALSE)

# Update sections
update1 &lt;- '
BURN: 5000;
ITERATIONS: 20000;
'

# Run updated Blimp input
mod1 &lt;- blimp.update(mod0, update1, file = "Ex4.3_update1.imp")

#----------------------------------------------------------------------------
# Example 1b: Remove CENTER section

# Remove section
update2 &lt;- '
CENTER: ---;
'

# Run updated Blimp input
mod2 &lt;- blimp.update(mod1, update2, file = "Ex4.3_update2.imp")

## End(Not run)
</code></pre>

<hr>
<h2 id='center'>Centering Predictor Variables in Single-Level and Multilevel Data</h2><span id='topic+center'></span>

<h3>Description</h3>

<p>This function centers predictor variables in single-level data, two-level
data, and three-level data at the grand mean (CGM, i.e., grand mean centering)
or within cluster (CWC, i.e., group mean centering).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>center(data, ..., cluster = NULL, type = c("CGM", "CWC"),
       cwc.mean = c("L2", "L3"), value = NULL, append = TRUE, name = ".c",
       as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="center_+3A_data">data</code></td>
<td>
<p>a numeric vector for centering a predictor variable, or a
data frame for centering more than one predictor variable.</p>
</td></tr>
<tr><td><code id="center_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code> e.g.,
<code>center(dat, x1, x2)</code> for centering the variables <code>x1</code>
and <code>x2</code> in the data frame <code>dat</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="center_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the name of the cluster variable
in <code>data</code> for a two-level model, a character vector
indicating the names of the cluster variables in <code>data</code>
for a three-level model, or a vector or data frame representing
the nested grouping structure (i.e., group or cluster variables).
Alternatively, a character string or character vector indicating
the variable name(s) of the cluster variable(s) in <code>data</code>.
Note that the cluster variable at Level 3 come first in a
three-level model, i.e., <code>cluster = c("level3", "level2")</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of centering, i.e.,
<code>"CGM"</code> for centering at the grand mean (i.e., grand mean
centering, default when <code>cluster = NULL</code>) or <code>"CWC"</code>
for centering within cluster (i.e., group mean centering, default
when specifying the argument <code>cluster</code>).</p>
</td></tr>
<tr><td><code id="center_+3A_cwc.mean">cwc.mean</code></td>
<td>
<p>a character string indicating the type of centering of a level-1
predictor variable in a three-level model, i.e., <code>L2</code>
(default) for centering the predictor variable at the level-2
cluster means, and  <code>L3</code> for centering the predictor
variable at the level-3 cluster means.</p>
</td></tr>
<tr><td><code id="center_+3A_value">value</code></td>
<td>
<p>a numeric value for centering on a specific user-defined value.
Note that this option is only available when specifying a
single-level predictor variable, i.e., <code>cluster = NULL</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), centered variable(s) are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names of
the centered predictor variables. By default, centered predictor
variables are named with the ending <code>".c"</code> resulting in
e.g. <code>"x1.c"</code> and <code>"x2.c"</code>. Variable names can also
be specified by using a character vector matching the number
of variables (e.g., <code>name = c("center.x1", "center.x2")</code>).</p>
</td></tr>
<tr><td><code id="center_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.
these values are converted to <code>NA</code> before conducting the
analysis. Note that <code>as.na()</code> function is only applied to
<code>data</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Single-Level Data</strong></dt><dd><p><strong>Predictor variables in single-level
data</strong> can only be centered at the grand mean (CGM) by specifying
<code>type = "CGM"</code>:
</p>
<p style="text-align: center;"><code class="reqn">x_{i} - \bar{x}_{.}</code>
</p>

<p>where <code class="reqn">x_{i}</code> is the predictor value of observation <code class="reqn">i</code> and
<code class="reqn">\bar{x}_{.}</code> is the average <code class="reqn">x</code> score. Note that predictor variables
can be centered on any meaningful value specifying the argument <code>value</code>,
e.g., a predictor variable centered at 5 by applying following formula:
</p>
<p style="text-align: center;"><code class="reqn">x_{i} - \bar{x}_{.} + 5</code>
</p>

<p>resulting in a mean of the centered predictor variable of 5.
</p>
</dd>
<dt><strong>Two-Level Data</strong></dt><dd><p><strong>Level-1 (L1) predictor variables</strong> in
two-level data can be centered at the grand mean (CGM) by specifying
<code>type = "CGM"</code>:
</p>
<p style="text-align: center;"><code class="reqn">x_{ij} - \bar{x}_{..}</code>
</p>

<p>where <code class="reqn">x_{ij}</code> is the predictor value of observation <code class="reqn">i</code> in L2 cluster
<code class="reqn">j</code> and <code class="reqn">\bar{x}_{..}</code> is the average <code class="reqn">x</code> score.
</p>
<p>L1 predictor variables are centered at the group mean (CWC) by specifying
<code>type = "CWC"</code> (Default):
</p>
<p style="text-align: center;"><code class="reqn">x_{ij} - \bar{x}_{.j}</code>
</p>

<p>where <code class="reqn">\bar{x_{.j}}</code> is the average <code class="reqn">x</code> score in cluster <code class="reqn">j</code>.
</p>
<p><strong>Level-2 (L1) predictor variables</strong> in two-level data can only be
centered at the grand mean:
</p>
<p style="text-align: center;"><code class="reqn">x_{.j} - \bar{x}_{..}</code>
</p>

<p>where <code class="reqn">x_{.j}</code> is the predictor value of Level 2 cluster <code class="reqn">j</code> and
<code class="reqn">\bar{x}_{..}</code> is the average Level-2 cluster score. Note that the cluster
membership variable needs to be specified when centering a L2 predictor variable
in two-level data. Otherwise the average <code class="reqn">x_{ij}</code> individual score instead
of the average <code class="reqn">x_{.j}</code> cluster score is used to center the predictor
variable.
</p>
</dd>
<dt><strong>Three-Level Data</strong></dt><dd><p><strong>Level-1 (L1) predictor variables</strong> in
three-level data can be centered at the grand mean (CGM) by specifying
<code>type = "CGM"</code>:
</p>
<p style="text-align: center;"><code class="reqn">x_{ijk} - \bar{x}_{...}</code>
</p>

<p>where <code class="reqn">x_{ijk}</code> is the predictor value of observation <code class="reqn">i</code> in Level-2
cluster <code class="reqn">j</code> within Level-3 cluster <code class="reqn">k</code> and <code class="reqn">\bar{x}_{...}</code> is the average
<code class="reqn">x</code> score.
</p>
<p>L1 predictor variables are centered within cluster (CWC) by specifying
<code>type = "CWC"</code> (Default). However, L1 predictor variables can be either
centered within Level-2 clusters (<code>cwc.mean = "L2"</code>, Default, see Brincks et
al., 2017):
</p>
<p style="text-align: center;"><code class="reqn">x_{ijk} - \bar{x}_{.jk}</code>
</p>

<p>or within Level-3 clusters (<code>cwc.mean = "L3"</code>, see Enders, 2013):
</p>
<p style="text-align: center;"><code class="reqn">x_{ijk} - \bar{x}_{..k}</code>
</p>

<p>where <code class="reqn">\bar{x}_{.jk}</code> is the average <code class="reqn">x</code> score in Level-2 cluster
<code class="reqn">j</code> within Level-3 cluster <code class="reqn">k</code> and <code class="reqn">\bar{x}_{..k}</code> is the average
<code class="reqn">x</code> score in Level-3 cluster <code class="reqn">k</code>.
</p>
<p><strong>Level-2 (L2) predictor variables</strong> in three-level data can be centered
at the grand mean (CGM) by specifying <code>type = "CGM"</code>:
</p>
<p style="text-align: center;"><code class="reqn">x_{.jk} - \bar{x}_{...}</code>
</p>

<p>where <code class="reqn">x_{.jk}</code> is the predictor value of Level-2 cluster <code class="reqn">j</code> within
Level-3 cluster <code class="reqn">k</code> and <code class="reqn">\bar{x}_{...}</code> is the average Level-2 cluster
score.
</p>
<p>L2 predictor variables are centered within cluster (CWC) by specifying
<code>type = "CWC"</code> (Default):
</p>
<p style="text-align: center;"><code class="reqn">x_{.jk} - \bar{x}_{..k}</code>
</p>

<p>where <code class="reqn">\bar{x}_{..k}</code> is the average <code class="reqn">x</code> score in Level-3 cluster
<code class="reqn">k</code>.
</p>
<p><strong>Level-3 (L3) predictor variables</strong> in three-level data can only be
centered at the grand mean:
</p>
<p style="text-align: center;"><code class="reqn">x_{..k} - \bar{x}_{...}</code>
</p>

<p>where <code class="reqn">x_{..k}</code> is the predictor value of Level-3 cluster <code class="reqn">k</code> and
<code class="reqn">\bar{x}_{...}</code> is the average Level-3 cluster score. Note that the cluster
membership variables at Level 2 and Level 3 need to be specified when centering
a L3 predictor variable in three-level data.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a numeric vector or data frame with the same length or same number of
rows as <code>data</code> containing the centered variable(s).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Brincks, A. M., Enders, C. K., Llabre, M. M., Bulotsky-Shearer, R. J., Prado, G.,
&amp; Feaster, D. J. (2017). Centering predictor variables in three-level contextual
models. <em>Multivariate Behavioral Research, 52</em>(2), 149–163.
https://doi.org/10.1080/00273171.2016.1256753
</p>
<p>Chang, C.-N., &amp; Kwok, O.-M. (2022) Partitioning Variance for a Within-Level
Predictor in Multilevel Models. <em>Structural Equation Modeling: A
Multidisciplinary Journal</em>. Advance online publication.
https://doi.org/10.1080/10705511.2022.2051175
</p>
<p>Enders, C. K. (2013). Centering predictors and contextual effects. In M. A.
Scott, J. S. Simonoff, &amp; B. D. Marx (Eds.), <em>The Sage handbook of
multilevel modeling</em> (pp. 89-109). Sage. https://dx.doi.org/10.4135/9781446247600
</p>
<p>Enders, C. K., &amp; Tofighi, D. (2007). Centering predictor variables in
cross-sectional multilevel models: A new look at an old issue. <em>Psychological
Methods, 12</em>, 121-138. https://doi.org/10.1037/1082-989X.12.2.121
</p>
<p>Rights, J. D., Preacher, K. J., &amp; Cole, D. A. (2020). The danger of conflating
level-specific effects of control variables when primary interest lies in
level-2 effects. <em>British Journal of Mathematical &amp; Statistical Psychology,
73</em>, 194-211. https://doi.org/10.1111/bmsp.12194
</p>
<p>Yaremych, H. E., Preacher, K. J., &amp; Hedeker, D. (2021). Centering categorical
predictors in multilevel models: Best practices and interpretation.
<em>Psychological Methods</em>. Advance online publication.
https://doi.org/10.1037/met0000434
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coding">coding</a></code>, <code><a href="#topic+cluster.scores">cluster.scores</a></code>, <code><a href="#topic+rec">rec</a></code>,
<code><a href="#topic+item.reverse">item.reverse</a></code>, <code><a href="#topic+rwg.lindell">rwg.lindell</a></code>, <code><a href="#topic+item.scores">item.scores</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Predictor Variables in Single-Level Data

# Example 1a: Center predictor 'disp' at the grand mean
center(mtcars, disp, append = FALSE)

# Alternative specification without using the '...' argument
center(mtcars$disp)

# Example 1b: Center predictors 'disp' and 'hp' at the grand mean and append to 'mtcars'
center(mtcars, disp, hp)

# Alternative specification without using the '...' argument
cbind(mtcars, center(mtcars[, c("disp", "hp")]))

# Example 1c: Center predictor 'disp' at the value 3
center(mtcars, disp, value = 3)

# Example 1d: Center predictors 'disp' and 'hp' and label with the suffix ".v"
center(mtcars, disp, hp, name = ".v")

#----------------------------------------------------------------------------
# Predictor Variables in Two-Level Data

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Example 2a: Center L1 predictor 'y1' within cluster
center(Demo.twolevel, y1, cluster = "cluster")

# Alternative specification without using the '...' argument
center(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

# Example 2b: Center L2 predictor 'w2' at the grand mean
center(Demo.twolevel, w1, cluster = "cluster")

# Example 2c: Center L1 predictor 'y1' within cluster and L2 predictor 'w1' at the grand mean
center(Demo.twolevel, y1, w1, cluster = "cluster")

#----------------------------------------------------------------------------
# Predictor Variables in Three-Level Data

# Create arbitrary three-level data
Demo.threelevel &lt;- data.frame(Demo.twolevel, cluster2 = Demo.twolevel$cluster,
                                             cluster3 = rep(1:10, each = 250))

# Example 3a: Center L1 predictor 'y1' within L2 cluster
center(Demo.threelevel, y1, cluster = c("cluster3", "cluster2"))

# Example 3b: Center L1 predictor 'y1' within L3 cluster
center(Demo.threelevel, y1, cluster = c("cluster3", "cluster2"), cwc.mean = "L3")

# Example 3c: Center L1 predictor 'y1' within L2 cluster and L2 predictor 'w1' within L3 cluster
center(Demo.threelevel, y1, w1, cluster = c("cluster3", "cluster2"))</code></pre>

<hr>
<h2 id='check.collin'>Collinearity Diagnostics</h2><span id='topic+check.collin'></span>

<h3>Description</h3>

<p>This function computes tolerance, standard error inflation factor, variance inflation
factor, eigenvalues, condition index, and variance proportions for linear, generalized
linear, and mixed-effects models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.collin(model, print = c("all", "vif", "eigen"), digits = 3, p.digits = 3,
             write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.collin_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lm"</code>, <code>"glm"</code>, <code>"lmerMod"</code>,
<code>"lmerModLmerTest"</code>, <code>"glmerMod"</code>, <code>"lme"</code>, or
<code>"glmmTMB"</code>.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e. <code>"all"</code>,
for all results, <code>"vif"</code> for tolerance, std. error inflation
factor, and variance inflation factor, or <code>eigen</code> for eigenvalue,
condition index, and variance proportions.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying results.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Collinearity diagnostics can be conducted for objects returned from the <code>lm()</code>
and <code>glm()</code> function, but also from objects returned from the <code>lmer()</code>
and <code>glmer()</code> function from the <span class="pkg">lme4</span> package, <code>lme()</code> function
from the <span class="pkg">nlme</span> package, and the <code>glmmTMB()</code> function from the <span class="pkg">glmmTMB</span>
package.
</p>
<p>The generalized variance inflation factor (Fox &amp; Monette, 1992) is computed for
terms with more than 1 df resulting from factors with more than two levels. The
generalized VIF (GVIF) is interpretable as the inflation in size of the confidence
ellipse or ellipsoid for the coefficients of the term in comparison with what would
be obtained for orthogonal data. GVIF is invariant to the coding of the terms in
the model. In order to adjust for the dimension of the confidence ellipsoid,
GVIF<code class="reqn">^\frac{1}{2df}</code> is computed. Note that the adjusted GVIF (aGVIF) is
actually a generalized standard error inflation factor (GSIF). Thus, the aGIF
needs to be squared before applying a common cutoff threshold for the VIF (e.g.,
VIF &gt; 10). Note that the output of <code>check.collin()</code> function reports either
the variance inflation factor or the squared generalized variance inflation factor
in the column <code>VIF</code>, while the standard error inflation factor or the adjusted
generalized variance inflation factor is reported in the column <code>SIF</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in the <code>model</code> argument</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>coef</code> for the regression
table including tolerance, std. error inflation factor and
variance inflation factors, <code>vif</code> for the tolerance,
std. error inflation factor, and variance inflation factor,
and <code>eigen</code> for eigenvalue condition index, and variance
proportion</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The computation of the VIF and the GVIF is based on the <code>vif()</code> function
in the <span class="pkg">car</span> package by John Fox, Sanford Weisberg and Brad Price (2020),
and the computation of eigenvalues, condition index, and variance proportions
is based on the <code>ols_eigen_cindex()</code> function in the <span class="pkg">olsrr</span> package
by Aravind Hebbali (2020).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Fox, J., &amp; Monette, G. (1992). Generalized collinearity diagnostics.
<em>Journal of the American Statistical Association, 87</em>, 178-183.
</p>
<p>Fox, J., Weisberg, S., &amp; Price, B. (2020). <em>car: Companion to Applied
Regression</em>. R package version 3.0-8. https://cran.r-project.org/web/packages/car/
</p>
<p>Hebbali, A. (2020). <em>olsrr: Tools for building OLS regression models</em>.
R package version 0.5.3. https://cran.r-project.org/web/packages/olsrr/
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.outlier">check.outlier</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(group = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4),
                  x1 = c(3, 2, 4, 9, 5, 3, 6, 4, 5, 6, 3, 5),
                  x2 = c(1, 4, 3, 1, 2, 4, 3, 5, 1, 7, 8, 7),
                  x3 = c(7, 3, 4, 2, 5, 6, 4, 2, 3, 5, 2, 8),
                  x4 = c("a", "b", "a", "c", "c", "c", "a", "b", "b", "c", "a", "c"),
                  y1 = c(2, 7, 4, 4, 7, 8, 4, 2, 5, 1, 3, 8),
                  y2 = c(0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1), stringsAsFactors = TRUE)

#-------------------------------------------------------------------------------
# Linear model

# Estimate linear model with continuous predictors
mod.lm1 &lt;- lm(y1 ~ x1 + x2 + x3, data = dat)

# Example 1: Tolerance, std. error, and variance inflation factor
check.collin(mod.lm1)

# Example 2: Tolerance, std. error, and variance inflation factor
# Eigenvalue, Condition index, and variance proportions
check.collin(mod.lm1, print = "all")

# Estimate model with continuous and categorical predictors
mod.lm2 &lt;- lm(y1 ~ x1 + x2 + x3 + x4, data = dat)

# Example 3: Tolerance, generalized std. error, and variance inflation factor
check.collin(mod.lm2)

#-------------------------------------------------------------------------------
# Generalized linear model

# Estimate logistic regression model with continuous predictors
mod.glm &lt;- glm(y2 ~ x1 + x2 + x3, data = dat, family = "binomial")

# Example 4: Tolerance, std. error, and variance inflation factor
check.collin(mod.glm)

## Not run: 
# Load lme4, nlme, and glmmTMB package
libraries(lme4, nlme, glmmTMB)

#----------------------------------------------------------------------------
# Linear mixed-effects model

# Estimate linear mixed-effects model using lme4 package
mod.lmer &lt;- lmer(y1 ~ x1 + x2 + x3 + (1|group), data = dat)

# Example 5: Tolerance, std. error, and variance inflation factor
check.collin(mod.lmer)

# Estimate linear mixed-effects model using nlme package
mod.lme &lt;- lme(y1 ~ x1 + x2 + x3, random = ~ 1 | group, data = dat)

# Example 6: Tolerance, std. error, and variance inflation factor
check.collin(mod.lme)

# Estimate linear mixed-effects model using glmmTMB package
mod.glmmTMB1 &lt;- glmmTMB(y1 ~ x1 + x2 + x3 + (1|group), data = dat)

# Example 7: Tolerance, std. error, and variance inflation factor
check.collin(mod.glmmTMB1)

#----------------------------------------------------------------------------
# Generalized linear mixed-effects model

# Estimate mixed-effects logistic regression model using lme4 package
mod.glmer &lt;- glmer(y2 ~ x1 + x2 + x3 + (1|group), data = dat, family = "binomial")

# Example 8: Tolerance, std. error, and variance inflation factor
check.collin(mod.glmer)

# Estimate mixed-effects logistic regression model using glmmTMB package
mod.glmmTMB2 &lt;- glmmTMB(y2 ~ x1 + x2 + x3 + (1|group), data = dat, family = "binomial")

# Example 9: Tolerance, std. error, and variance inflation factor
check.collin(mod.glmmTMB2)

#----------------------------------------------------------------------------
# Write Results

# Example 10: Write Results into a text file
check.collin(mod.lm1, write = "Diagnostics.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='check.outlier'>Statistical Measures for Leverage, Distance, and Influence</h2><span id='topic+check.outlier'></span>

<h3>Description</h3>

<p>This function computes statistical measures for leverage, distance, and
influence for linear models estimated by using the <code>lm()</code> function.
Mahalanobis distance and hat values are computed for quantifying
<em>leverage</em>, standardized leverage-corrected residuals and
studentized leverage-corrected residuals are computed for quantifying
<em>distance</em>, and Cook's distance and DfBetas are computed
for quantifying <em>influence</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.outlier(model, append = TRUE, check = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.outlier_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lm"</code>.</p>
</td></tr>
<tr><td><code id="check.outlier_+3A_append">append</code></td>
<td>
<p>logical: logical: if <code>TRUE</code> (default), statistical measures for
leverage, distance, and influence are appended to the data frame in <code>model$model</code>.</p>
</td></tr>
<tr><td><code id="check.outlier_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="check.outlier_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In regression analysis, an observation can be extreme in three major ways (see
Darlington &amp; Hayes, p. 484): (1) An observation has high <strong>leverage</strong> if it
has a atypical pattern of values on the predictors, (2) an observation has high
<strong>distance</strong> if its observed outcome value <code class="reqn">Y_i</code> has a large deviation
from the predicted value <code class="reqn">\hat{Y}_i</code>, and (3) an observation has high
<strong>influence</strong> if its inclusion substantially changes the estimates for the
intercept and/or slopes.
</p>


<h3>Value</h3>

<p>Returns a data frame with following entries:
</p>
<table role = "presentation">
<tr><td><code>idout</code></td>
<td>
<p>ID variabl</p>
</td></tr>
<tr><td><code>mahal</code></td>
<td>
<p>Mahalanobis distance</p>
</td></tr>
<tr><td><code>hat</code></td>
<td>
<p>hat values</p>
</td></tr>
<tr><td><code>rstand</code></td>
<td>
<p>standardized leverage-corrected residuals</p>
</td></tr>
<tr><td><code>rstud</code></td>
<td>
<p>studentized leverage-corrected residuals</p>
</td></tr>
<tr><td><code>cook</code></td>
<td>
<p>Cook's distance</p>
</td></tr>
<tr><td><code>Intercept.dfb</code></td>
<td>
<p>DFBetas for the intercept</p>
</td></tr>
<tr><td><code>pred1.dfb</code></td>
<td>
<p>DFBetas for the slope of the predictor pred1</p>
</td></tr>
<tr><td><code>....dfb</code></td>
<td>
<p>DFBetas for the slope of the predictor ...</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Darlington, R. B., &amp;, Hayes, A. F. (2017). <em>Regression analysis and linear
models</em>: Concepts, applications, and implementation. The Guilford Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.collin">check.collin</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Statistical measures for leverage, distance, and influence
check.outlier(lm(mpg ~ cyl + disp + hp, data = mtcars))

# Example 2: Append statistical measures to the mtcars data frame
cbind(mtcars,
      check.outlier(lm(mpg ~ cyl + disp + hp, data = mtcars), append = FALSE))
</code></pre>

<hr>
<h2 id='check.resid'>Residual Diagnostics</h2><span id='topic+check.resid'></span>

<h3>Description</h3>

<p>This function performs residual diagnostics for linear models estimated by
using the <code>lm()</code> function for detecting nonlinearity (partial residual or
component-plus-residual plots), nonconstant error variance (predicted values
vs. residuals plot), and non-normality of residuals (Q-Q plot and histogram
with density plot).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.resid(model, type = c("linear", "homo", "normal"),
            resid = c("unstand", "stand", "student"), plot = TRUE,
            point.shape = 21, point.fill = "gray80", point.size = 1,
            line1 = TRUE, line2 = TRUE, linetype1 = "solid",
            linetype2 = "dashed", linewidth1 = 1, linewidth2 = 1,
            line.col1 = "#0072B2", line.col2 = "#D55E00", bar.width = NULL,
            bar.n = 30, bar.col = "black", bar.fill = "gray95",
            strip.text.size = 11, label.size = 10, axis.text.size = 10,
            xlim = NULL, ylim = NULL, xbreaks = ggplot2::waiver(),
            ybreaks = ggplot2::waiver(), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.resid_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>lm</code>.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_type">type</code></td>
<td>
<p>a character string specifying the type of the plot, i.e.,
<code>"linear"</code> for partial (component-plus-residual) plots,
<code>"homo"</code> (default) for predicted values vs. residuals
plot, and <code>"normal"</code> for Q-Q plot and histogram with
a density plot. Note that partial plots are not available
for models with interaction terms.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_resid">resid</code></td>
<td>
<p>a character string specifying the type of residual used for
the partial (component-plus-residual) plots or Q-Q plot and
histogram, i.e., <code>"unstand"</code> for unstandardized residuals
<code>"stand"</code> for standardized residuals, and <code>"student"</code>
for studentized residual. By default, studentized residuals
are used for predicted values vs. residuals plot and unstandardized
residuals are used for Q-Q plot and histogram.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a plot is drawn.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_point.shape">point.shape</code></td>
<td>
<p>a numeric value for specifying the argument <code>shape</code>
in the <code>geom_point</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_point.fill">point.fill</code></td>
<td>
<p>a character string or numeric value for specifying the
argument <code>fill</code> the <code>geom_point</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value for specifying the argument <code>size</code>
in the <code>geom_point</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line1">line1</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), regression line is drawn
in the partial (component-plus-residual) plots, horizontal
line is drawn in the predicted values vs. residuals plot,
and t-distribution or normal distribution curve is drawn in
the histogram.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line2">line2</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Loess smooth line is drawn
in the partial (component-plus-residual) plots, loess smooth
lines are drawn in the predicted values vs. residuals plot,
and density curve is drawn in the histogram.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_linetype1">linetype1</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>linetype</code> in the <code>geom_smooth</code>, <code>geom_hline</code>,
or <code>stat_function</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_linetype2">linetype2</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>linetype</code> in the <code>geom_smooth</code> or <code>geom_density</code>
function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_linewidth1">linewidth1</code></td>
<td>
<p>a numeric value for specifying the argument <code>linewidth</code>
in the <code>geom_smooth</code>, <code>geom_hline</code>, or <code>stat_function</code>
function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_linewidth2">linewidth2</code></td>
<td>
<p>a numeric value for specifying the argument <code>linewidth</code>
in the <code>geom_smooth</code> or <code>geom_density</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line.col1">line.col1</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>color</code> in the <code>geom_smooth</code>, <code>geom_hline</code>,
or <code>stat_function</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line.col2">line.col2</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>color</code> in the <code>geom_smooth</code> or <code>geom_density</code>
function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_bar.width">bar.width</code></td>
<td>
<p>a numeric value for specifying the argument <code>bins</code> in
the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_bar.n">bar.n</code></td>
<td>
<p>a numeric value for specifying the argument <code>bins</code> in
the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_bar.col">bar.col</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>color</code> in the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_bar.fill">bar.fill</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>fill</code> in the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_strip.text.size">strip.text.size</code></td>
<td>
<p>a numeric value for specifying the argument <code>size</code> in
the <code>element_text</code> function of the <code>strip.text</code>
argument within the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_label.size">label.size</code></td>
<td>
<p>a numeric value for specifying the argument <code>size</code> in
the <code>element_text</code> function of the <code>axis.title</code>
argument within the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_axis.text.size">axis.text.size</code></td>
<td>
<p>a numeric value for specifying the argument <code>size</code> in
the <code>element_text</code> function of the <code>axis.text </code>
argument within the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_xlim">xlim</code></td>
<td>
<p>a numeric vector with two elements for specifying the argument <code>limits</code>
in the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector with two elements for specifying the argument <code>limits</code>
in the <code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_xbreaks">xbreaks</code></td>
<td>
<p>a numeric vector for specifying the argument <code>breaks</code>
in the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector for specifying the argument <code>breaks</code>
in the <code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Nonlinearity</strong></dt><dd><p>The violation of the assumption of linearity
implies that the model cannot accurately capture the systematic pattern of the
relationship between the outcome and predictor variables. In other words, the
specified regression surface does not accurately represent the relationship
between the conditional mean values of <code class="reqn">Y</code> and the <code class="reqn">X</code>s. That means
the average error <code class="reqn">E(\varepsilon)</code> is not 0 at every point on the regression
surface (Fox, 2015).
</p>
<p>In multiple regression, plotting the outcome variable <code class="reqn">Y</code> against each predictor
variable <code class="reqn">X</code> can be misleading because it does not reflect the partial
relationship between <code class="reqn">Y</code> and <code class="reqn">X</code> (i.e., statistically controlling for
the other <code class="reqn">X</code>s), but rather the marginal relationship between <code class="reqn">Y</code> and
<code class="reqn">X</code> (i.e., ignoring the other <code class="reqn">X</code>s). Partial residual plots or
component-plus-residual plots should be used to detect nonlinearity in multiple
regression. The partial residual for the <code class="reqn">j</code>th predictor variable is defined
as
</p>
<p style="text-align: center;"><code class="reqn">e_i^{(j)} = b_jX_{ij} + e_i</code>
</p>

<p>The linear component of the partial relationship between <code class="reqn">Y</code> and <code class="reqn">X_j</code>
is added back to the least-squares residuals, which may include an unmodeled
nonlinear component. Then, the partial residual <code class="reqn">e_i^{(j)}</code> is plotted
against the predictor variable <code class="reqn">X_j</code>. Nonlinearity may become apparent when
a non-parametric regression smoother is applied.
</p>
<p>By default, the function plots
each predictor against the partial residuals, and draws the linear regression
and the loess smooth line to the partial residual plots.</p>
</dd>
<dt><strong>Nonconstant Error Variance</strong></dt><dd><p>The violation of the assumption of
constant error variance, often referred to as heteroscedasticity, implies that
the variance of the outcome variable around the regression surface is not the
same at every point on the regression surface (Fox, 2015).
</p>
<p>Plotting residuals against the outcome variable <code class="reqn">Y</code> instead of the predicted
values <code class="reqn">\hat{Y}</code> is not recommended because <code class="reqn">Y = \hat{Y} + e</code>. Consequently,
the linear correlation between the outcome variable <code class="reqn">Y</code> and the residuals
<code class="reqn">e</code> is <code class="reqn">\sqrt{1 - R^2}</code> where <code class="reqn">R</code> is the multiple correlation coefficient.
In contrast, plotting residuals against the predicted values <code class="reqn">\hat{Y}</code> is
much easier to examine for evidence of nonconstant error variance as the correlation
between <code class="reqn">\hat{Y}</code> and <code class="reqn">e</code> is 0. Note that the least-squares residuals
generally have unequal variance <code class="reqn">Var(e_i) = \sigma^2 / (1 - h_i)</code> where
<code class="reqn">h</code> is the leverage of observation <code class="reqn">i</code>, even if errors have constant
variance <code class="reqn">\sigma^2</code>. The studentized residuals <code class="reqn">e^*_i</code>, however, have
a constant variance under the assumption of the regression model. Residuals
are studentized by dividing them by <code class="reqn">\sigma^2_i(\sqrt{(1 - h_i)}</code> where
<code class="reqn">\sigma^2_i</code> is the estimate of <code class="reqn">\sigma^2</code> obtained after deleting the
<code class="reqn">i</code>th observation, and <code class="reqn">h_i</code> is the leverage of observation <code class="reqn">i</code>
(Meuleman et al, 2015).
</p>
<p>By default, the function plots the predicted values
against the studentized residuals. It also draws a horizontal line at 0, a
loess smooth lines for all residuals as well as separate loess smooth lines
for positive and negative residuals.</p>
</dd>
<dt><strong>Non-normality of Residuals</strong></dt><dd><p>Statistical inference under the
violation of the assumption of normally distributed errors is approximately
valid in all but small samples. However, the efficiency of least squares is
not robust because the least-squares estimator is the most efficient and
unbiased estimator only when the errors are normally distributed. For instance,
when error distributions have heavy tails, the least-squares estimator becomes
much less efficient compared to robust estimators. In addition, error distributions with
heavy-tails result in outliers and compromise the interpretation of conditional
means because the mean is not an accurate measure of central tendency in a highly
skewed distribution. Moreover, a multimodal error distribution suggests the omission
of one or more discrete explanatory variables that naturally divide the data
into groups (Fox, 2016).
</p>
<p>By default, the function plots a Q-Q plot of the unstandardized residuals, and
a histogram of the unstandardized residuals and a density plot. Note that
studentized residuals follow a <code class="reqn">t</code>-distribution with <code class="reqn">n - k - 2</code> degrees
of freedom where <code class="reqn">n</code> is the sample size and <code class="reqn">k</code> is the number of predictors.
However, the normal and <code class="reqn">t</code>-distribution are nearly identical unless the
sample size is small. Moreover, even if the model is correct, the studentized
residuals are not an independent random sample from <code class="reqn">t_{n - k - 2}</code>. Residuals
are correlated with each other depending on the configuration of the predictor
values. The correlation is generally negligible unless the sample size is small.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in <code>model</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>plotdat</code></td>
<td>
<p>data frame used for the plot</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the residuals</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Fox, J. (2016). <em>Applied regression analysis and generalized linear models</em>
(3rd ed.). Sage Publications, Inc.
</p>
<p>Meuleman, B., Loosveldt, G., &amp; Emonds, V. (2015). Regression analysis: Assumptions
and diagnostics. In H. Best &amp; C. Wolf (Eds.), <em>The SAGE handbook of regression analysis and causal inference (pp. 83-110)</em>.
Sage.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.collin">check.collin</a></code>, <code><a href="#topic+check.outlier">check.outlier</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#-------------------------------------------------------------------------------
# Residual diagnostics for a linear model

mod &lt;- lm(Ozone ~ Solar.R + Wind + Temp, data = airquality)

# Example 1: Partial (component-plus-residual) plots
check.resid(mod, type = "linear")

# Example 2: Predicted values vs. residuals plot
check.resid(mod, type = "homo")

# Example 3: Q-Q plot and histogram with density plot
check.resid(mod, type = "normal")

#-------------------------------------------------------------------------------
# Extract data and ggplot2 object

object &lt;- check.resid(mod, type = "linear", plot = FALSE)

# Data frame
object$plotdat

# ggplot object
object$plot

## End(Not run)
</code></pre>

<hr>
<h2 id='chr.color'>Colored and Styled Terminal Output Text</h2><span id='topic+chr.color'></span>

<h3>Description</h3>

<p>This function adds color and style to output texts on terminals that support
'ANSI' color and highlight codes that can be printed by using the <code>cat</code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.color(x, color = c("black", "red", "green", "yellow", "blue", "violet",
                       "cyan", "white", "gray1", "gray2", "gray3",
                       "b.red", "b.green", "b.yellow", "b.blue", "b.violet",
                       "b.cyan", "b.white"),
          bg = c("none", "black", "red", "green", "yellow", "blue", "violet",
                 "cyan", "white"),
          style = c("regular", "bold", "italic", "underline"), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chr.color_+3A_x">x</code></td>
<td>
<p>a character vector.</p>
</td></tr>
<tr><td><code id="chr.color_+3A_color">color</code></td>
<td>
<p>a character string indicating the text color, e.g., <code>red</code>
for red and <code>b.red</code> for bright red text.</p>
</td></tr>
<tr><td><code id="chr.color_+3A_bg">bg</code></td>
<td>
<p>a character string indicating the background color of the text,
e.g., <code>red</code> for red background.</p>
</td></tr>
<tr><td><code id="chr.color_+3A_style">style</code></td>
<td>
<p>a character vector indicating the font style, i.e., <code>regular</code>,
(default) for regular text, <code>bold</code> for bold text, <code>italic</code>,
for italic text, and <code>underline</code> for underline text. Note
that font styles can be combined, e.g., <code>style = c("bold", "italic")</code>
provides a bold and italic text.</p>
</td></tr>
<tr><td><code id="chr.color_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector.
</p>


<h3>Note</h3>

<p>This function is based on functions provided in the <span class="pkg">crayon</span> package
by Gábor Csárdi.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Csárdi G (2022). <em>crayon: Colored Terminal Output</em>. R package version 1.5.2,
https://CRAN.R-project.org/package=crayon
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.grep">chr.grep</a></code>, <code><a href="#topic+chr.grepl">chr.grepl</a></code>, <code><a href="#topic+chr.gsub">chr.gsub</a></code>,
<code><a href="#topic+chr.omit">chr.omit</a></code>,  <code><a href="#topic+chr.trim">chr.trim</a></code>, <code><a href="#topic+chr.trunc">chr.trunc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1:
cat(chr.color("Text in red.", color = "red"))

# Example 2:
cat(chr.color("Text in blue with green background.",
              color = "blue", bg = "yellow"))

# Example 3a:
cat(chr.color("Text in boldface.", style = "bold"))

# Example 3b:
cat(chr.color("Text in boldface and italic.", style = c("bold", "italic")))


## End(Not run)
</code></pre>

<hr>
<h2 id='chr.grep'>Multiple Pattern Matching</h2><span id='topic+chr.grep'></span><span id='topic+chr.grepl'></span>

<h3>Description</h3>

<p>This function searches for matches to the character vector specified in
<code>pattern</code> within each element of the character vector <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.grep(pattern, x, ignore.case = FALSE, perl = FALSE, value = FALSE,
         fixed = FALSE, useBytes = FALSE, invert = FALSE, check = TRUE)

chr.grepl(pattern, x, ignore.case = FALSE, perl = FALSE, fixed = FALSE,
          useBytes = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chr.grep_+3A_pattern">pattern</code></td>
<td>
<p>a character vector with character strings to be matched.</p>
</td></tr>
<tr><td><code id="chr.grep_+3A_x">x</code></td>
<td>
<p>a character vector where matches are sought.</p>
</td></tr>
<tr><td><code id="chr.grep_+3A_ignore.case">ignore.case</code></td>
<td>
<p>logical: if <code>FALSE</code> (default), the pattern matching
is case sensitive and if <code>TRUE</code>, case is ignored during
matching.</p>
</td></tr>
<tr><td><code id="chr.grep_+3A_perl">perl</code></td>
<td>
<p>logical: if <code>TRUE</code> Perl-compatible regexps are used.</p>
</td></tr>
<tr><td><code id="chr.grep_+3A_value">value</code></td>
<td>
<p>logical: if <code>FALSE</code> (default), a vector containing the
(integer) indices of the matches determined by grep is
returned, and if <code>TRUE</code>, a vector containing the
matching elements themselves is returned.</p>
</td></tr>
<tr><td><code id="chr.grep_+3A_fixed">fixed</code></td>
<td>
<p>logical: if <code>TRUE</code>, pattern is a string to be matched
as is. Overrides all conflicting arguments.</p>
</td></tr>
<tr><td><code id="chr.grep_+3A_usebytes">useBytes</code></td>
<td>
<p>logical: if <code>TRUE</code>, the matching is done byte-by-byte
rather than character-by-character. See 'Details'.</p>
</td></tr>
<tr><td><code id="chr.grep_+3A_invert">invert</code></td>
<td>
<p>logical: if <code>TRUE</code>, function returns indices or values
for elements that do not match.</p>
</td></tr>
<tr><td><code id="chr.grep_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a integer vector with the indices of the mathces when <code>value = FALSE</code>,
character vector containing the matching elements when <code>value = TRUE</code>, or
a logical vector when using the <code>chr.grepl</code> function.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.color">chr.color</a></code>, <code><a href="#topic+chr.grepl">chr.grepl</a></code>, <code><a href="#topic+chr.gsub">chr.gsub</a></code>,
<code><a href="#topic+chr.omit">chr.omit</a></code>, <code><a href="#topic+chr.trim">chr.trim</a></code>, <code><a href="#topic+chr.trunc">chr.trunc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>chr.vector &lt;- c("James", "Mary", "Michael", "Patricia", "Robert", "Jennifer")

# Example 1: Indices of matching elements
chr.grep(c("am", "er"), chr.vector)

# Example 2: Values of matching elements
chr.grep(c("am", "er"), chr.vector, value = TRUE)

# Example 3: Matching element?
chr.grepl(c("am", "er"), chr.vector)
</code></pre>

<hr>
<h2 id='chr.gsub'>Multiple Pattern Matching And Replacements</h2><span id='topic+chr.gsub'></span>

<h3>Description</h3>

<p>This function is a multiple global string replacement wrapper that allows access
to multiple methods of specifying matches and replacements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.gsub(pattern, replacement, x, recycle = FALSE, check = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chr.gsub_+3A_pattern">pattern</code></td>
<td>
<p>a character vector with character strings to be matched.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_replacement">replacement</code></td>
<td>
<p>a character vector equal in length to <code>pattern</code> or of
length one which are a replacement for matched patterns.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_x">x</code></td>
<td>
<p>a character vector where matches and replacements are sought.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_recycle">recycle</code></td>
<td>
<p>logical: if <code>TRUE</code>, replacement is recycled if lengths differ.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to the <code>regexpr</code> or <code>sub</code>
function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return a character vector of the same length and with the same attributes as
<code>x</code> (after possible coercion to character).
</p>


<h3>Note</h3>

<p>This function was adapted from the <code>mgsub()</code> function in the <span class="pkg">mgsub</span>
package by Mark Ewing (2019).
</p>


<h3>Author(s)</h3>

<p>Mark Ewing
</p>


<h3>References</h3>

<p>Mark Ewing (2019). <em>mgsub: Safe, Multiple, Simultaneous String Substitution</em>.
R package version 1.7.1. https://CRAN.R-project.org/package=mgsub
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.color">chr.color</a></code>, <code><a href="#topic+chr.grep">chr.grep</a></code>, <code><a href="#topic+chr.grepl">chr.grepl</a></code>,
<code><a href="#topic+chr.omit">chr.omit</a></code>, <code><a href="#topic+chr.trim">chr.trim</a></code>, <code><a href="#topic+chr.trunc">chr.trunc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Replace 'the' and 'they' with 'a' and 'we'
chr.vector &lt;- "they don't understand the value of what they seek."
chr.gsub(c("the", "they"), c("a", "we"), chr.vector)

# Example 2: Replace 'heyy' and 'ho' with 'yo'
chr.vector &lt;- c("hey ho, let's go!")
chr.gsub(c("hey", "ho"), "yo", chr.vector, recycle = TRUE)

# Example 3: Replace with regular expressions
chr.vector &lt;- "Dopazamine is not the same as dopachloride or dopastriamine, yet is still fake."
chr.gsub(c("[Dd]opa([^ ]*?mine)","fake"), c("Meta\1","real"), chr.vector)
</code></pre>

<hr>
<h2 id='chr.omit'>Omit Strings</h2><span id='topic+chr.omit'></span>

<h3>Description</h3>

<p>This function omits user-specified values or strings from a numeric vector,
character vector or factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.omit(x, omit = "", na.omit = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chr.omit_+3A_x">x</code></td>
<td>
<p>a numeric vector, character vector or factor.</p>
</td></tr>
<tr><td><code id="chr.omit_+3A_omit">omit</code></td>
<td>
<p>a numeric vector or character vector indicating values or
strings to be omitted
from the vector <code>x</code>, the default setting is the empty
strings <code>""</code>.</p>
</td></tr>
<tr><td><code id="chr.omit_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, missing values (<code>NA</code>) are also
omitted from the vector.</p>
</td></tr>
<tr><td><code id="chr.omit_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector, character vector or factor with values or strings
specified in <code>omit</code> omitted from the vector specified in <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.color">chr.color</a></code>, <code><a href="#topic+chr.grep">chr.grep</a></code>, <code><a href="#topic+chr.grepl">chr.grepl</a></code>,
<code><a href="#topic+chr.gsub">chr.gsub</a></code>, <code><a href="#topic+chr.trim">chr.trim</a></code>, <code><a href="#topic+chr.trunc">chr.trunc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------------------
# Charater vector
x.chr &lt;- c("a", "", "c", NA, "", "d", "e", NA)

# Example 1: Omit character string ""
chr.omit(x.chr)

# Example 2: Omit character string "" and missing values (NA)
chr.omit(x.chr, na.omit = TRUE)

# Example 3: Omit character string "c" and "e"
chr.omit(x.chr, omit = c("c", "e"))

# Example 4: Omit character string "c", "e", and missing values (NA)
chr.omit(x.chr, omit = c("c", "e"), na.omit = TRUE)

#-------------------------------------------------------------------------------
# Numeric vector
x.num &lt;- c(1, 2, NA, 3, 4, 5, NA)

# Example 5: Omit values 2 and 4
chr.omit(x.num, omit = c(2, 4))

# Example 6: Omit values 2, 4, and missing values (NA)
chr.omit(x.num, omit = c(2, 4), na.omit = TRUE)

#-------------------------------------------------------------------------------
# Factor
x.factor &lt;- factor(letters[1:10])

# Example 7: Omit factor levels "a", "c", "e", and "g"
chr.omit(x.factor, omit = c("a", "c", "e", "g"))
</code></pre>

<hr>
<h2 id='chr.trim'>Trim Whitespace from String</h2><span id='topic+chr.trim'></span>

<h3>Description</h3>

<p>This function removes whitespace from start and/or end of a string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.trim(x, side = c("both", "left", "right"), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chr.trim_+3A_x">x</code></td>
<td>
<p>a character vector.</p>
</td></tr>
<tr><td><code id="chr.trim_+3A_side">side</code></td>
<td>
<p>a character string indicating the side on which to remove whitespace,
i.e., <code>"both"</code> (default), <code>"left"</code> or <code>"right"</code>.</p>
</td></tr>
<tr><td><code id="chr.trim_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector with whitespaces removed from the vector specified
in <code>x</code>.
</p>


<h3>Note</h3>

<p>This function is based on the <code>str_trim()</code> function from the <span class="pkg">stringr</span>
package by Hadley Wickham.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Wickham, H. (2019). <em>stringr: Simple, consistent wrappers for common string
operations</em>.
R package version 1.4.0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.color">chr.color</a></code>, <code><a href="#topic+chr.grep">chr.grep</a></code>, <code><a href="#topic+chr.grepl">chr.grepl</a></code>,
<code><a href="#topic+chr.gsub">chr.gsub</a></code>, <code><a href="#topic+chr.omit">chr.omit</a></code>, <code><a href="#topic+chr.trunc">chr.trunc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- "  string  "

# Example 1: Remove whitespace at both sides
chr.trim(x)

# Example 2: Remove whitespace at the left side
chr.trim(x, side = "left")

# Example 3: Remove whitespace at the right side
chr.trim(x, side = "right")
</code></pre>

<hr>
<h2 id='chr.trunc'>Truncate a Character Vector to a Maximum Width</h2><span id='topic+chr.trunc'></span>

<h3>Description</h3>

<p>This function truncates a character vector, so that the number of characters
of each element of the character vector is always less than or equal to the
width specified in the argument <code>width</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.trunc(x, width, side = c("right", "left", "center"), ellipsis = "...",
          check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chr.trunc_+3A_x">x</code></td>
<td>
<p>a character vector or factor. Note that factors are converted
into a character vector.</p>
</td></tr>
<tr><td><code id="chr.trunc_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the maximum width of the character
strings in the vector. Note that the default setting
switches to <code>".."</code> when <code>width = 3</code>, <code>"."</code> when
<code>width = 2</code>, and <code>""</code> when <code>width = 1</code>.</p>
</td></tr>
<tr><td><code id="chr.trunc_+3A_side">side</code></td>
<td>
<p>a character string indicating the location of the ellipsis,
i.e. <code>"right"</code> (default) for the right side, <code>"left"</code>
for the left side, and <code>"center"</code> for center of the
character strings in the vector</p>
</td></tr>
<tr><td><code id="chr.trunc_+3A_ellipsis">ellipsis</code></td>
<td>
<p>a character string indicating the content of the ellipsis,
i.e., <code>"..."</code> by default.</p>
</td></tr>
<tr><td><code id="chr.trunc_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a truncated character vector.
</p>


<h3>Note</h3>

<p>This function was adapted from the <code>str_trunc()</code> function in the <span class="pkg">stringr</span>
package by Hadley Wickham (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Wickham H (2023). <em>stringr: Simple, Consistent Wrappers for Common String Operations</em>.
R package version 1.5.1, https://CRAN.R-project.org/package=stringr
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.color">chr.color</a></code>, <code><a href="#topic+chr.grep">chr.grep</a></code>, <code><a href="#topic+chr.grepl">chr.grepl</a></code>,
<code><a href="#topic+chr.gsub">chr.gsub</a></code>, <code><a href="#topic+chr.omit">chr.omit</a></code>, <code><a href="#topic+chr.trim">chr.trim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Truncate at the right side with a max. of 10 characters
chr.trunc(row.names(mtcars), width = 10)

# Example 2: Truncate at the left side with a max. of 10 characters
chr.trunc(row.names(mtcars), width = 10, side = "left")

# Example 3: Truncate without ellipses
chr.trunc(row.names(mtcars), width = 10, ellipsis = "")
</code></pre>

<hr>
<h2 id='ci.cor'>(Bootstrap) Confidence Intervals for Correlation Coefficients</h2><span id='topic+ci.cor'></span>

<h3>Description</h3>

<p>This function computes and plots (1) Fisher <code class="reqn">z'</code> confidence intervals
for Pearson product-moment correlation coefficients (a) without non-normality
adjustment, (1b) adjusted via sample joint moments method or (1c) adjusted via
approximate distribution method (Bishara et al., 2018), (2) Spearman's rank-order
correlation coefficients with (2a) Fieller et al. (1957) standard error, (2b)
Bonett and Wright (2000) standard error, or (2c) rank-based inverse normal
transformation, (3) Kendall's Tau-b, and (4) Kendall-Stuart's Tau-c correlation
coefficients with Fieller et al. (1957) standard error, optionally by a grouping
and/or split variable. The function also supports five types of bootstrap
confidence intervals (e.g., bias-corrected (BC) percentile bootstrap or
bias-corrected and accelerated (BCa) bootstrap confidence intervals) and plots
the bootstrap samples with histograms and density curves. By default, the
function computes Pearson product-moment correlation coefficients adjusted via
approximate distribution method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.cor(data, ...,
       method = c("pearson", "spearman", "kendall-b", "kendall-c"),
       adjust = c("none", "joint", "approx"),
       se = c("fisher", "fieller", "bonett", "rin"),
       sample = TRUE, seed = NULL, maxtol = 1e-05, nudge = 0.001,
       boot = c("none", "norm", "basic", "perc", "bc", "bca"), R = 1000,
       fisher = TRUE, alternative = c("two.sided", "less", "greater"),
       conf.level = 0.95, group = NULL, split = NULL, na.omit = FALSE, digits = 2,
       as.na = NULL, plot = c("none", "ci", "boot"), point.size = 2.5,
       point.shape = 19, errorbar.width = 0.3, dodge.width = 0.5, hist = TRUE,
       binwidth = NULL, bins = NULL, hist.alpha = 0.4, fill = "gray85", density = TRUE,
       density.col = "#0072B2", density.linewidth = 0.5, density.linetype = "solid",
       point = TRUE, point.col = "#CC79A7", point.linewidth = 0.6,
       point.linetype = "solid", ci = TRUE, ci.col = "black",
       ci.linewidth = 0.6, ci.linetype = "dashed", line = TRUE, intercept = 0,
       linetype = "solid", line.col = "gray65", xlab = NULL, ylab = NULL,
       xlim = NULL, ylim = NULL, xbreaks = ggplot2::waiver(), ybreaks = ggplot2::waiver(),
       axis.title.size = 11, axis.text.size = 10, strip.text.size = 11, title = NULL,
       subtitle = NULL, group.col = NULL, plot.margin = NA,  legend.title = "",
       legend.position = c("right", "top", "left", "bottom", "none"),
       legend.box.margin = c(-10, 0, 0, 0), facet.ncol = NULL, facet.nrow = NULL,
       facet.scales = "free_y", filename = NULL, width = NA, height = NA,
       units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL,
       append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.cor_+3A_data">data</code></td>
<td>
<p>a data frame with numeric variables, i.e.,
factors and character variables are excluded from
<code>data</code> before conducting the analysis.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>
e.g., <code>ci.cor(x1, x2, data = dat)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used
to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_method">method</code></td>
<td>
<p>a character string indicating which correlation
coefficient is to be computed, i.e., <code>"pearson"</code>
for Pearson product-moment correlation coefficient
(default), <code>"spearman"</code> for Spearman's rank-order
correlation coefficient, <code>"kendall-b"</code> for Kendall's
Tau-b correlation coefficient, <code>"kendall-c"</code> for
Kendall-Stuart's Tau-c correlation coefficient. Note
that confidence intervals are only computed given
at least 4 pairs of observations.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_adjust">adjust</code></td>
<td>
<p>a character string specifying the non-normality
adjustment method, i.e., <code>"none"</code> for the Fisher
<code class="reqn">z'</code> confidence interval for the Pearson
product-moment correlation coefficient without
non-normality adjustment, <code>"joint"</code> for the
confidence interval with non-normality adjustment via
sample joint moments, and <code>"approx"</code> (default)
for the confidence interval with non-normality adjustment
via approximate distribution by skewness and kurtosis.
Note that this argument only applies to the Pearson
product-moment correlation coefficient, i.e.,
<code>method = "pearson"</code></p>
</td></tr>
<tr><td><code id="ci.cor_+3A_se">se</code></td>
<td>
<p>a character string specifying the method for computing
the standard error of the correlation coefficient,
i.e., <code>"fisher"</code> for the Fisher <code class="reqn">z'</code> confidence
interval, <code>"fieller"</code> (default) for the confidence
interval for Spearman's rank-order correlation
coefficient based on approximate standard error by
Fieller et al. (1957), <code>"bonett"</code> for the confidence
interval based on approximate standard error by Bonett
and Wright (2000), and <code>"rin"</code> for the confidence
interval for Spearman's rank-order correlation coefficient
based on rank-based inverse normal (RIN) transformation.
Note that this argument only applies to Spearman's
rank-order correlation coefficient, i.e.,
<code>method = "spearman"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_sample">sample</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the univariate
sample skewness and kurtosis is used when applying
the approximate distribution method and reported in
the result table, while the population skewness and
kurtosis is used when <code>sample = FALSE</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the seed of the pseudo-random
number generator when generating a random set of
starting parameter value when the parameters led to
a sum of squares greater than the maximum tolerance
after optimization when applying the approximate
distribution method (<code>adjust = approx</code>) when
computing the confidence interval for the Pearson
product-moment correlation coefficient, or the seeds
of the pseudo-random numbers used when conducting
bootstrapping.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_maxtol">maxtol</code></td>
<td>
<p>a numeric value indicating the tolerance for total
squared error when applying the approximate distribution
method (<code>adjust = approx</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_nudge">nudge</code></td>
<td>
<p>a numeric value indicating the nudge proportion of
their original values by which sample skewness, kurtosis,
and r are nudged towards 0 when applying the approximate
distribution method (<code>adjust = approx</code>).
are only computed given at least 10 pairs of observations.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_boot">boot</code></td>
<td>
<p>a character string specifying the type of bootstrap
confidence intervals (CI), i.e., <code>"none"</code> (default)
for not conducting bootstrapping, <code>"norm"</code> for
the bias-corrected normal approximation bootstrap CI,
<code>"basic"</code> for the basic bootstrap CI, <code>"perc"</code>,
for the percentile bootstrap CI <code>"bc"</code> (default)
for the bias-corrected (BC) percentile bootstrap CI
(without acceleration), and <code>"bca"</code> for the
bias-corrected and accelerated (BCa) bootstrap CI.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_r">R</code></td>
<td>
<p>a numeric value indicating the number of bootstrap
replicates (default is 1000).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_fisher">fisher</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Fisher <code class="reqn">z</code>
transformation is applied before computing the
confidence intervals to reverse-transformed the limits
of the interval using the inverse of the Fisher
<code class="reqn">z</code> transformation. Note that this argument applies
only  when <code>boot</code> is <code>"norm"</code> or <code>"basic"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name
of the grouping variable in <code>...</code> or <code>data</code>,
or a vector representing the grouping variable. The
grouping variable is excluded from the data
frame specified in <code>data</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_split">split</code></td>
<td>
<p>either a character string indicating the variable name
of the split variable in <code>...</code> or <code>data</code>,
or a vector representing the split variable. The split
variable is excluded from the data frame
specified in <code>data</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed
before conducting the analysis (i.e., listwise deletion);
if <code>FALSE</code> (default), pairwise deletion is used.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal
places to be used.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_plot">plot</code></td>
<td>
<p>a character string indicating the type of the plot
to display, i.e., <code>"none"</code> (default) for not
displaying any plots, <code>"ci"</code> for displaying
confidence intervals for the correlation coefficient,
<code>"boot"</code> for displaying bootstrap samples with
histograms and density curves when the argument
<code>"boot"</code> is other than <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>geom_point</code> function for controlling the
size of points when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_point.shape">point.shape</code></td>
<td>
<p>a numeric value between 0 and 25 or a character string
as plotting symbol indicating the <code>shape</code> argument
in the <code>geom_point</code> function for controlling the
symbols of points. when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
in the <code>geom_errorbar</code> function for controlling
the width of the whiskers in the <code>geom_errorbar</code>
function when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_dodge.width">dodge.width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
controlling the width of the <code>geom</code> elements to
be dodged when specifying a grouping variable using
the argument <code>group</code> when plotting confidence
intervals (<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_hist">hist</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), histograms are
drawn when plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_binwidth">binwidth</code></td>
<td>
<p>a numeric value or a function for specifying the
<code>binwidth</code> argument in the <code>geom_histogram</code>
function for controlling the width of the bins when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_bins">bins</code></td>
<td>
<p>a numeric value for specifying the <code>bins</code> argument
in the <code>geom_histogram</code> function for controlling
the number of bins when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_hist.alpha">hist.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_histogram</code>
function for controlling the opacity of the bars
when plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_fill">fill</code></td>
<td>
<p>a character string specifying the <code>fill</code> argument
in the <code>geom_histogram</code> function controlling the
fill aesthetic when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_density">density</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), density curves are
drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_density.col">density.col</code></td>
<td>
<p>a character string specifying the <code>color</code> argument
in the <code>geom_density</code> function controlling the
color of the density curves when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_density.linewidth">density.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewidth</code>
argument in the <code>geom_density</code> function controlling
the line width of the density curves when plotting
bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_density.linetype">density.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_density</code>
function controlling the line type of the density
curves when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vertical lines
representing the point estimate of the correlation
coefficients are drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_point.col">point.col</code></td>
<td>
<p>a character string specifying the <code>color</code> argument
in the <code>geom_vline</code> function for controlling the
color of the vertical line displaying the correlation
coefficient when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_point.linewidth">point.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewdith</code> argument
in the <code>geom_vline</code> function for controlling the
line width of the vertical line displaying the
correlation coefficient when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_point.linetype">point.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_vline</code>
function controlling the line type of the vertical
line displaying the correlation  coefficient when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vertical lines
representing the bootstrap confidence intervals of
the correlation coefficient are drawn when plotting
bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_ci.col">ci.col</code></td>
<td>
<p>character string specifying the <code>color</code> argument
in the <code>geom_vline</code> function for controlling the
color of the vertical line displaying bootstrap
confidence intervals when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_ci.linewidth">ci.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewdith</code> argument
in the <code>geom_vline</code> function for controlling the
line width of the vertical line displaying bootstrap
confidence intervals when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_ci.linetype">ci.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_vline</code>
function controlling the line type of the vertical
line displaying bootstrap confidence intervals when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a horizontal line
is drawn when <code>plot = "ci"</code> or a vertical line
is drawn when <code>plot = "boot"</code></p>
</td></tr>
<tr><td><code id="ci.cor_+3A_intercept">intercept</code></td>
<td>
<p>a numeric value indicating the <code>yintercept</code> or
<code>xintercept</code> argument in the <code>geom_hline</code>
or <code>geom_vline</code> function controlling the position
of the horizontal or vertical line when <code>plot = "ci"</code>
and <code>line = TRUE</code> or when <code>plot = "boot"</code>
and <code>line = TRUE</code>. By default, the horizontal or
vertical line is drawn at 0.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_linetype">linetype</code></td>
<td>
<p>a character string indicating the <code>linetype</code>
argument in the <code>geom_hline</code> or <code>geom_vline</code>
function controlling the line type of the horizontal
or vertical line (default is <code>linetype = "dashed"</code>).</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_line.col">line.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
in the <code>geom_hline</code> or <code>geom_vline</code> function
for controlling the color of the horizontal or vertical
line.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_xlab">xlab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
in the <code>scale_x_continuous</code> function for labeling
the x-axis. The default setting is <code>xlab = NULL</code>
when <code>plot = "ci"</code> and <code>xlab = "Correlation Coefficient"</code>
when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_ylab">ylab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
in the <code>scale_y_continuous</code> function for labeling
the y-axis. The default setting is <code>ylab = "Correlation Coefficient"</code>
when <code>plot = "ci"</code> and <code>ylab = "Probability Density, f(x)"</code>
when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_xlim">xlim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument in the <code>scale_x_continuous</code>
function for controlling the scale range of the x-axis.
The default setting is <code>xlim = NULL</code>
when <code>plot = "ci"</code> and <code>xlim = c(-1, 1)</code>
when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument in the <code>scale_y_continuous</code>
function for controlling the scale range of the y-axis.
The default setting is <code>ylim = c(-1, 1)</code> when
<code>plot = "ci"</code> and <code>xlim = NULL</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_xbreaks">xbreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
in the <code>scale_x_continuous</code> function for controlling
the x-axis breaks.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
in the <code>scale_y_continuous</code> function for controlling
the y-axis breaks.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_axis.title.size">axis.title.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the axis title,
i.e., <code>theme(axis.title = element_text(size = axis.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_axis.text.size">axis.text.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the axis text,
i.e., <code>theme(axis.text = element_text(size = axis.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_strip.text.size">strip.text.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the strip text,
i.e., <code>theme(strip.text = element_text(size = strip.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_title">title</code></td>
<td>
<p>a character string indicating the <code>title</code> argument
in the <code>labs</code> function for the subtitle of the plot.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string indicating the <code>subtite</code> argument
in the <code>labs</code> function for the subtitle of the plot.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_group.col">group.col</code></td>
<td>
<p>a character vector indicating the <code>color</code> argument
in the <code>scale_color_manual</code> and <code>scale_fill_manual</code>
functions when specifying a grouping variable using
the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_plot.margin">plot.margin</code></td>
<td>
<p>a numeric vector with four elements indicating the
<code>plot.margin</code> argument in the <code>theme</code> function
controlling the plot margins . The default setting
is <code>c(5.5, 5.5, 5.5, 5.5)</code>, but switches
to <code>c(5.5, 5.5, -2.5, 5.5)</code> when specifying a
grouping variable using the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_legend.title">legend.title</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
in the <code>labs</code> function for specifying the legend
title when specifying a grouping variable using the
argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_legend.position">legend.position</code></td>
<td>
<p>a character string indicating the <code>legend.position</code>
in the <code>theme</code> argument for controlling the
position of the legend  function when specifying a
grouping variable using the argument <code>group</code>.
By default, the legend is placed at the bottom the
plot.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_legend.box.margin">legend.box.margin</code></td>
<td>
<p>a numeric vector with four elements indicating the
<code>legend.box.margin</code> argument in the <code>theme</code>
function for controlling the margins around the full
legend area when specifying a grouping variable using
the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_facet.ncol">facet.ncol</code></td>
<td>
<p>a numeric value indicating the <code>ncol</code> argument
in the <code>facet_wrap</code> function for controlling
the number of columns when specifying a split variable
using the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_facet.nrow">facet.nrow</code></td>
<td>
<p>a numeric value indicating the <code>nrow</code> argument
in the <code>facet_wrap</code> function for controlling the
number of rows when specifying a split variable using
the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_facet.scales">facet.scales</code></td>
<td>
<p>a character string indicating the <code>scales</code> argument
in the <code>facet_wrap</code> function for controlling the
scales shared across facets, i.e., <code>"fixed"</code>,
<code>"free_x"</code>, <code>"free_y"</code> (default), or
<code>"free"</code> when specifying a split variable using
the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>filename</code>
argument. Note that plots can only be saved when
<code>plot = "ci"</code> or <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output
into either a text file with file extension <code>".txt"</code>
(e.g., <code>"Output.txt"</code>) or Excel file with file
extension <code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>).
If the file name does not contain any file extension,
an Excel file will be written.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be
appended to an existing text file with extension
<code>.txt</code> specified in <code>write</code>, if <code>FALSE</code>
existing text file will be overwritten.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="ci.cor_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown
on the console.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Pearson Product-Moment Correlation Coefficient</strong></dt><dd><p>The Fisher
<code class="reqn">z'</code> confidence interval method for the Pearson product-moment correlation
coefficient is based on the assumption that <code class="reqn">X</code> and <code class="reqn">Y</code> have a bivariate
normal distribution in the population. Non-normality resulting from either
high kurtosis or high absolute skewness can distort the Fisher <code class="reqn">z'</code>
confidence interval that produces a coverage rate that does not equal the one
intended. The distortion is largest when population correlation is large and
both variables <code class="reqn">X</code> and <code class="reqn">Y</code> were non-normal (Bishara et al., 2017).
Note that increasing sample size improves coverage only when the population
correlation is zero, while increasing the sample size worsens coverage with a
non-zero population correlation (Bishara &amp; Hittner, 2017). The <code>ci.cor</code>
function computes the Fisher <code class="reqn">z'</code> confidence interval without non-normality
adjustment (<code>adjust = "none"</code>), with non-normality adjustment via sample
joint moments (<code>adjust = "joint"</code>), or with non-normality adjustment via
approximate distribution (<code>adjust = "approx"</code>):
</p>

<ul>
<li><p><em>Fisher <code class="reqn">z'</code> confidence interval method</em> uses the
<code class="reqn">r</code>-to<code class="reqn">z'</code> transformation for the correlation coefficient
<code class="reqn">r</code>:
</p>
<p style="text-align: center;"><code class="reqn">z' = 0.5\cdot \ln\left(\frac{1 + r}{1 - r}\right)</code>
</p>

<p>The sampling distribution of <code class="reqn">z</code> is approximately normal with a
standard error of approximately
</p>
<p style="text-align: center;"><code class="reqn">\sigma_z' = \sqrt{\frac{1}{(n - 3)}}</code>
</p>

<p>The two-sided 95% confidence interval is defined as
</p>
<p style="text-align: center;"><code class="reqn">z' \pm 1.96\cdot\sigma_{z'}</code>
</p>

<p>These confidence interval bounds are transformed back to the scale of
<code class="reqn">r</code>:
</p>
<p style="text-align: center;"><code class="reqn">r = \frac{exp(2z') - 1}{exp(2z') + 1}</code>
</p>

<p>The resulting confidence interval of the correlation coefficient is an
approximation and is only accurate when <code class="reqn">X</code> and <code class="reqn">Y</code> have a
bivariate normal distribution in the population or when the population
correlation is zero.
</p>
</li>
<li><p>The <em>Joint Moments Method</em> multiplies the asymptotic variance of
<code class="reqn">z'</code> by <code class="reqn">\tau_f^2</code> (Hawkins, 1989):
</p>
<p style="text-align: center;"><code class="reqn">\tau_f^2 = \frac{(\mu_{40} + 2\mu_{22} + \mu_{04})\rho^2 - 4(\mu_{31} + \mu_{13})\rho + 4\mu_{22})}{4(1 - \rho^2)^2}</code>
</p>

<p>where <code class="reqn">\mu_{jk}</code> represents a population joint moment defined as
</p>
<p style="text-align: center;"><code class="reqn">\mu_{jk} = E[X^jY^k]</code>
</p>

<p>where <code class="reqn">X</code> and <code class="reqn">Y</code> are assumed to be standardized (<code class="reqn">\mu_{10} = \mu_{01} = 0</code>,
<code class="reqn">\mu_{20} = \mu_{02} = 1</code>). The standard error of <code class="reqn">z</code>' can then be
approximated as <code class="reqn">\tilde{\sigma}_{z'}</code>:
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\sigma}_{z'} = \tau_f\sqrt{\frac{1}{n - 3}}</code>
</p>

<p>The corresponding sample moments, <code class="reqn">m_{jk}</code> can be used to estimate
<code class="reqn">\tau_f^2</code>:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu}_{jk} = m_{jk} = \frac{1}{n}\sum_{i=1}^{n}(x_i^jy_i^k)</code>
</p>

<p>However, the higher-order sample joint moments may be unstable estimators
of their population counterparts unless the sample size is extremely
large. Thus, this estimate of <code class="reqn">\tau_f^2</code> may be inaccurate, leading
to inaccurate confidence intervals.
</p>
</li>
<li><p>The <em>Approximate Distribution Method</em> estimates an approximate
distribution that the sample appears to be drawn from to analytically
solve for <code class="reqn">\tau_f^2</code> based on that distribution's parameters. The
<code>ci.cor</code> function uses a third-order polynomial family allowing
estimation of distribution parameters using marginal skewness and kurtosis
that are estimated using the marginal sample skewness and kurtosis
statistics (Bishara et al., 2018).
</p>
</li></ul>

<p>Bishara et al. (2018) conducted two Monte Carlo simulations that showed that
the approximate distribution method was effective in dealing with violations
of the bivariate normality assumption for a wide range of sample sizes, while
the joint moments method was effective mainly when the sample size was
extremely large, in the thousands. However, the third-order polynomial family
used for the approximate distribution method cannot deal with absolute skewness
above 4.4 or kurtosis above 43.4. Note that the approximate distribution method
is accurate even when the bivariate normality assumption is satisfied, while
the sample joint moments method sometimes fails to achieve the intended coverage
even when the bivariate normality was satisfied.</p>
</dd>
<dt><strong>Spearman's Rank-Order Correlation Coefficient</strong></dt><dd><p>The confidence
interval for Spearman's rank-order correlation coefficient is based on the
Fisher's <code class="reqn">z</code> method (<code>se = "fisher"</code>), Fieller et al. (1957)
approximate standard error (<code>se = "fieller"</code>, default), Bonett and Wright
(2000) approximate standard error (<code>se = "bonett"</code>) or rank-based inverse
normal (RIN) transformation (<code>se = "rin"</code>) :
</p>

<ul>
<li><p><em>Fisher's <code class="reqn">z</code> Standard Error</em>
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{\frac{1}{(n - 3)}}</code>
</p>

</li>
<li><p><em>Fieller et al. (1957) Approximate Standard Error</em>
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{\frac{1.06}{(n - 3)}}</code>
</p>

<p>Note that this approximation for the standard error is recommended for
<code class="reqn">n &gt; 10</code> and <code class="reqn">|rs| &lt; 0.8</code>.
</p>
</li>
<li><p><em>Bonett and Wright (2000) Approximate Standard Error</em>
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{\frac{1 + \frac{\hat{\theta}^2}{2}}{(n - 3)}}</code>
</p>

<p>where <code class="reqn">\hat{\theta}</code> is the point estimate of the Spearman's rank-order
correlation coefficient. Note that this approximation for the standard
error is recommended for <code class="reqn">|\tau| \le 0.9</code>.
</p>
</li>
<li><p><em>Rin Transformation</em> involves three steps. First, the variable
is converted to ranks. Second, the ranks are converted to a 0-to-1 scale
using a linear function. Third, this distribution is transformed via the
inverse of the normal cumulative distribution function (i.e., via probit
transformation). The result is an approximately normal distribution
regardless of the original shape of the data, so long as ties are
infrequent and <code class="reqn">n</code> is not too small.
</p>
</li></ul>

</dd>
<dt><strong>Kendall's Tau-b and Tau-c Correlation Coefficient</strong></dt><dd><p>The confidence
interval for Kendall's Tau-b and Tau-c correlation coefficient is based on the
approximate standard error by Fieller et al. (1957):
</p>
<p style="text-align: center;"><code class="reqn">\sigma_z' = \sqrt{\frac{0.437}{(n - 4)}}</code>
</p>

<p>Note that this approximation for the standard error is recommended for
<code class="reqn">n &gt; 10</code> and <code class="reqn">|\tau| &lt; 0.8</code>.
</p>
</dd>
<dt><strong>Bootstrap Confidence Intervals</strong></dt><dd><p>The <code>ci.cor</code> function supports
bootstrap confidence intervals (CI) for the correlation coefficient by changing
the default setting <code>boot = "none"</code> to request one of five different types
of bootstrap CI (see Efron &amp; Tibshirani, 1993; Davidson &amp; Hinkley, 1997):
</p>

<ul>
<li><p><code>"norm"</code>: The bias-corrected normal approximation bootstrap CI
relies on the normal distribution based on the standard deviation of the
bootstrap samples <code class="reqn">\hat{\mathit{SE}}^*</code>. The function corrects for the
bootstrap bias, i.e., difference between the bootstrap estimate <code class="reqn">\hat{\theta}^*</code>
and the sample statistic <code class="reqn">\hat{\theta}</code> centering the interval at <code class="reqn">2\hat{\theta} - \hat{\theta}^*</code>.
The BC normal CI of intended coverage of <code class="reqn">1 - 2(\alpha/2)</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">Normal: (\hat{\theta}_{low}, \hat{\theta}_{upp} = \hat{\theta} - (\hat{\theta}^* - \hat{\theta}) + z^{\alpha/2} \cdot \hat{\mathit{SE}}^*, \hat{\theta} - (\hat{\theta}^* - \hat{\theta}) + z^{1 - \alpha/2} \cdot \hat{\mathit{SE}}^*</code>
</p>

<p>where <code class="reqn">z^{\alpha/2}</code> and <code class="reqn">z^{1 - \alpha/2}</code> denotes the <code class="reqn">\alpha</code> and
the <code class="reqn">1 - \alpha</code> quantile from the standard normal distribution.
</p>
</li>
<li><p><code>"basic"</code>: The basic bootstrap (aka reverse bootstrap percentile)
CI is based on the distribution of <code class="reqn">\hat{\delta} = \hat{\theta} - \theta</code>
which is approximated with the bootstrap distribution of
<code class="reqn">\hat{\delta}^* = \hat{\theta}^* - \hat{\theta}</code>.
</p>
<p style="text-align: center;"><code class="reqn">Basic: (\hat{\theta}_{low}, \hat{\theta}_{upp} = \hat{\theta} - \hat{\delta}^{*1 - (\alpha/2)}, \hat{\theta} - \hat{\delta}^{*\alpha/2} = 2\hat{\theta} - \hat{\theta}^{*(1 - \alpha/2)} , 2\hat{\theta} - \hat{\theta}^{*(\alpha/2)})</code>
</p>

</li>
<li><p><code>"perc"</code>: The percentile bootstrap CI is computed by ordering the
bootstrap estimates <code class="reqn">\hat{\theta}^*_1, \ldots, \hat{\theta}^*_B</code> to determine
the <code class="reqn">(100(\alpha)/2)</code>th and <code class="reqn">(100(1 - \alpha)/2)</code>th empirical percentile
with intended coverage of <code class="reqn">1 - 2(\alpha/2)</code>:
</p>
<p style="text-align: center;"><code class="reqn">Percentile: (\hat{\theta}_{low}, \hat{\theta}_{upp} = \hat{\theta}^{*(1 - \alpha/2)}, \hat{\theta}^{*(\alpha/2)})</code>
</p>

</li>
<li><p><code>"bc"</code> (default): The bias-corrected (BC) percentile bootstrap CI corrects
the percentile bootstrap CI for median bias of <code class="reqn">\hat{\theta^*}</code>, i.e., the
discrepancy between the median of <code class="reqn">\hat{\theta}^*</code> and <code class="reqn">\hat{\theta}</code>
in normal units. The bias correction <code class="reqn">\hat{z}_0</code> is obtained from the
proportion of bootstrap replications less than the sample estimate <code class="reqn">\hat{\theta}</code>:
</p>
<p style="text-align: center;"><code class="reqn">\hat{z}_0 = \Phi^{-1}\left(\frac{\#{\hat{\theta}^*_b &lt; \hat{\theta}}}{B}\right)</code>
</p>

<p>where <code class="reqn">\Phi^{-1}(.)</code> represents the inverse function of the standard normal
cumulative distribution function and <code class="reqn">B</code> is the number of bootstrap
replications. The BC percentile CI of intended coverage of <code class="reqn">1 - 2(\alpha/2)</code>
is given by
</p>
<p style="text-align: center;"><code class="reqn">BC: (\hat{\theta}_{low}, \hat{\theta}_{upp} = \hat{\theta}^{*(\alpha_1)}, \hat{\theta}^{*(\alpha_2)})</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\alpha_1 = \Phi(2\hat{z}_0 + z^{\alpha/2})</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha_2 = \Phi(2\hat{z}_0 + z^{1 - \alpha/2})</code>
</p>

<p>where <code class="reqn">\Phi(.)</code> represents the standard normal cumulative distribution function
and <code class="reqn">z^{\alpha/2}</code> is the <code class="reqn">100(\alpha/2)</code> percentile
of a standard normal distribution.
</p>
</li>
<li><p><code>"bca"</code>: The bias-corrected and accelerated (BCa) bootstrap CI
corrects the percentile bootstrap CI for median bias <code class="reqn">\hat{z}_0</code> and
for  acceleration or skewness <code class="reqn">\hat{a}</code>, i.e., the rate of change of the
standard error of <code class="reqn">\hat{\theta}</code> with respect to the true parameter value
<code class="reqn">\theta</code> on a normalized scale. The standard normal approximation
<code class="reqn">\hat{\theta} \sim N(\theta, \mathit{SE}^2)</code> assumes that the standard error of
<code class="reqn">\hat{\theta}</code> is the same for all <code class="reqn">\theta</code>. The acceleration constant
<code class="reqn">\hat{a}</code> corrects for this unrealistic assumption and can be computed by
using jackknife resampling:
</p>
<p style="text-align: center;"><code class="reqn">\hat{a} = \frac{\sum_{i=1}^{n}(\hat{\theta}_{(.)} - \hat{\theta}_{(i)})^3}{6\{\sum_{i=1}^{n}(\theta_{(.)} - \hat{\theta}_{(i)})^2\}^{3/2}}</code>
</p>

<p>where <code class="reqn">\hat{\theta}_{(i)}</code> is the sample estimate with the <code class="reqn">i</code>th
observation deleted and <code class="reqn">\hat{\theta}_{(.)} = \sum_{i=1}^{n}\frac{\hat{\theta}_{(i)}}{n}</code>.
Note that the function uses infinitesimal jackknife instead of regular
leave-one-out jackknife that down-weights each observation by an infinitesimal
amount of <code class="reqn">\frac{0.001}{n}</code> instead of removing observations. The BCa
percentile CI of intended coverage of <code class="reqn">1 - 2(\alpha/2)</code>
is given by
</p>
<p style="text-align: center;"><code class="reqn">BCa: (\hat{\theta}_{low}, \hat{\theta}_{upp} = \hat{\theta}^{*(\alpha_1)}, \hat{\theta}^{*(\alpha_2)})</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\alpha_1 = \Phi\left(\hat{z}_0 + \frac{\hat{z}_0 + z^{\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z^{\alpha/2})}\right)</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha_2 = \Phi\left(\hat{z}_0 + \frac{\hat{z}_0 + z^{1 - \alpha/2}}{1 - \hat{a}(\hat{z}_0 + z^{1 - \alpha/2})}\right)</code>
</p>

</li></ul>

<p>Note that Fisher transformation is applied before computing the confidence
intervals to reverse-transform the limits of the interval using the inverse
of the Fisher <code class="reqn">z</code> transformation (<code>fisher = TRUE</code>) when specifying
<code>"norm"</code> or <code>"basic"</code> for the argument <code>boot</code>. In addition,
interpolation on the normal quantile scale is applied for <code>"basic"</code>,
<code>"perc"</code>, <code>"bc"</code>, and <code>"bca"</code> when a non-integer order
statistic is required (see equation 5.8 in Davison &amp; Hinkley, 1997).
</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>...</code>, <code>data</code>, <code>group</code>, and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>data frame with bootstrap replicates of the correlation coefficient when bootstrapping was requested</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on a modified copy of the functions provided in the
supporting information in Bishara et al. (2018) for the sample joint moments
method and approximate  distribution method, functions provided in the
supplementary materials in Bishara and Hittner (2017) for Fieller et al. (1957)
and Bonett and Wright (2000) correction, and a function provided by Thom Baguley
(2024) for the rank-based inverse normal (RIN) transformation. Bootstrap confidence
intervals are computed using the R package <code>boot</code> by Angelo Canty and
Brain Ripley (2024).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Baguley, T. (2024). <em>CI for Spearman's rho</em>. seriousstats.
https://rpubs.com/seriousstats/616206
</p>
<p>Bonett, D. G., &amp; Wright, T. A. (2000). Sample size requirements for estimating
Pearson, Kendall and Spearman correlations. <em>Psychometrika, 65</em>, 23-28.
https://doi.org/10.1007/BF02294183
</p>
<p>Bishara, A. J., &amp; Hittner, J. B. (2012). Testing the significance of a correlation
with nonnormal data: Comparison of Pearson, Spearman, transformation, and resampling
approaches. <em>Psychological Methods, 17</em>(3), 399–417.
https://doi.org/10.1037/a0028087
</p>
<p>Bishara, A. J., &amp; Hittner, J.B. (2017). Confidence intervals for correlations
when data are not normal. <em>Behavior Research Methods, 49</em>, 294-309.
https://doi.org/10.3758/s13428-016-0702-8
</p>
<p>Bishara, A. J., Li, J., &amp; Nash, T. (2018). Asymptotic confidence intervals for
the Pearson correlation via skewness and kurtosis. <em>British Journal of
Mathematical and Statistical Psychology, 71</em>(1), 167–185.
https://doi.org/10.1111/bmsp.12113
</p>
<p>Brown, M. B., &amp; Benedetti, J. K. (1977). Sampling behavior of tests for correlation
in two-way contingency tables. <em>Journal of the American Statistical Association, 72</em>
(358), 309-315. https://doi.org/10.1080/01621459.1977.10480995
</p>
<p>Canty, A., &amp; Ripley, B. (2024). <em>boot: Bootstrap R (S-Plus) Functions</em>.
R package version 1.3-31.
</p>
<p>Davison, A. C., &amp; Hinkley, D. V. (1997). <em>Bootstrap methods and their application</em>.
Cambridge University Press.
</p>
<p>Efron, B., &amp; Tibshirani, R. (1993). <em>An introduction to the bootstrap</em>.
Chapman &amp; Hall.
</p>
<p>Fieller, E. C., Hartley, H. O., &amp; Pearson, E. S. (1957). Tests for rank
correlation coefficients: I. <em>Biometrika, 44</em>, 470-481.
https://doi.org/10.2307/2332878
</p>
<p>Fisher, R. A. (1921). On the “Probable Error” of a Coefficient of Correlation
Deduced from a Small Sample. <em>Metron</em>, 1, 3-32.
</p>
<p>Hawkins, D. L. (1989). Using U statistics to derive the asymptotic distribution
of Fisher’s Z statistic. <em>American Statistician, 43</em>, 235–237.
https://doi.org/10.2307/2685369
</p>
<p>Hollander, M., Wolfe, D. A., &amp; Chicken, E. (2015). <em>Nonparametric statistical
methods</em>. Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cor.matrix">cor.matrix</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Pearson product-moment correlation coefficient

# Example 1a: Approximate distribution method
ci.cor(mtcars, mpg, drat, qsec)

# Alternative specification without using the '...' argument
ci.cor(mtcars[, c("mpg", "drat", "qsec")])

# Example 1b: Joint moments method
ci.cor(mtcars, mpg, drat, qsec, adjust = "joint")

#----------------------------------------------------------------------------
# Spearman's rank-order correlation coefficient

# Example 2a: Fieller et al. (1957) approximate standard error
ci.cor(mtcars, mpg, drat, qsec, method = "spearman")

# Example 2b: Bonett and Wright (2000) approximate standard error
ci.cor(mtcars, mpg, drat, qsec, method = "spearman", se = "bonett")

# Example 2c: Rank-based inverse normal (RIN) transformation
ci.cor(mtcars, mpg, drat, qsec, method = "spearman", se = "rin")

#----------------------------------------------------------------------------
# Kendall's Tau

# Example 3a:  Kendall's Tau-b
ci.cor(mtcars, mpg, drat, qsec, method = "kendall-b")

# Example 3b:  Kendall's Tau-c
ci.cor(mtcars, mpg, drat, qsec, method = "kendall-c")

## Not run: 
#----------------------------------------------------------------------------
# Bootstrap Confidence Interval (CI)

# Example 4a: Bias-corrected (BC) percentile bootstrap CI
ci.cor(mtcars, mpg, drat, qsec, boot = "bc")

# Example 4b: Bias-corrected and accelerated (BCa) bootstrap CI,
# 5000 bootstrap replications, set seed of the pseudo-random number generator
ci.cor(mtcars, mpg, drat, qsec, boot = "bca", R = 5000, seed = 123)

#----------------------------------------------------------------------------
# Grouping and Split Variable

# Example 5a: Grouping variable
ci.cor(mtcars, mpg, drat, qsec, group = "vs")

# Alternative specification without using the argument '...'
ci.cor(mtcars[, c("mpg", "drat", "qsec")], group = mtcars$vs)

# Example 5b: Split variable
ci.cor(mtcars, mpg, drat, qsec, split = "am")

# Alternative specification without using the argument '...'
ci.cor(mtcars[, c("mpg", "drat", "qsec")], split = mtcars$am)

# Example 5c: Grouping and split variable
ci.cor(mtcars, mpg, drat, qsec, group = "vs", split = "am")

# Alternative specification without using the argument '...'
ci.cor(mtcars[, c("mpg", "drat", "qsec")], group = mtcars$vs, split = mtcars$am)

#----------------------------------------------------------------------------
# Write Output

# Example 6a: Text file
ci.cor(mtcars, mpg, drat, qsec, write = "CI_Cor_Text.txt")

# Example 6b: Excel file
ci.cor(mtcars, mpg, drat, qsec, write = "CI_Cor_Excel.xlsx")

#----------------------------------------------------------------------------
# Plot Confidence Intervals

# Example 7a: Pearson product-moment correlation coefficient
ci.cor(mtcars, mpg, drat, qsec, plot = "ci")

# Example 7b: Grouping variable
ci.cor(mtcars, mpg, drat, qsec, group = "vs", plot = "ci")

# Example 7c: Split variable
ci.cor(mtcars, mpg, drat, qsec, split = "am", plot = "ci")

# Example 7d: Save plot as PDF file
ci.cor(mtcars, mpg, drat, qsec, plot = "ci", saveplot = "CI_Cor.pdf",
       width = 8, height = 6)

# Example 7e: Save plot as PNG file
ci.cor(mtcars, mpg, drat, qsec, plot = "ci", saveplot = "CI_Cor.png",
       width = 8, height = 6)

#----------------------------------------------------------------------------
# Plot Bootstrap Samples

# Example 8a: Pearson product-moment correlation coefficient
ci.cor(mtcars, mpg, drat, qsec, boot = "bc", plot = "boot")

# Example 8b: Grouping variable
ci.cor(mtcars, mpg, drat, qsec, group = "vs", boot = "bc", plot = "boot")

# Example 8c: Split variable
ci.cor(mtcars, mpg, drat, qsec, split = "am", boot = "bc", plot = "boot")

# Example 8d: Save plot as PDF file
ci.cor(mpg, drat, qsec, data = mtcars, boot = "bc", plot = "boot",
       saveplot = "CI_Cor_Boot.pdf", width = 14, height = 9)

# Example 8e: Save plot as PNG file
ci.cor(mtcars, mpg, drat, qsec, boot = "bc", plot = "boot",
       saveplot = "CI_Cor_Boot.png", width = 14, height = 9)
## End(Not run)
</code></pre>

<hr>
<h2 id='ci.mean'>(Bootstrap) Confidence Intervals for Arithmetic Means and Medians</h2><span id='topic+ci.mean'></span><span id='topic+ci.median'></span>

<h3>Description</h3>

<p>The function <code>ci.mean</code> computes and plots confidence intervals for
arithmetic means with known or unknown population standard deviation or
population variance and the function <code>ci.median</code> computes confidence
intervals for medians, optionally by a grouping and/or split variable. These
functions also supports six types of bootstrap confidence intervals (e.g.,
bias-corrected (BC) percentile bootstrap or bias-corrected and accelerated
(BCa) bootstrap confidence intervals) and plots the bootstrap samples with
histograms and density curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.mean(data, ..., sigma = NULL, sigma2 = NULL, adjust = FALSE,
        boot = c("none", "norm", "basic", "stud", "perc", "bc", "bca"),
        R = 1000, seed = NULL, sample = TRUE,
        alternative = c("two.sided", "less", "greater"),
        conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
        na.omit = FALSE, digits = 2, as.na = NULL,
        plot = c("none", "ci", "boot"), point.size = 2.5, point.shape = 19,
        errorbar.width = 0.3, dodge.width = 0.5, hist = TRUE,
        binwidth = NULL, bins = NULL, hist.alpha = 0.4, fill = "gray85", density = TRUE,
        density.col = "#0072B2", density.linewidth = 0.5, density.linetype = "solid",
        point = TRUE, point.col = "#CC79A7", point.linewidth = 0.6,
        point.linetype = "solid", ci = TRUE, ci.col = "black",
        ci.linewidth = 0.6, ci.linetype = "dashed", line = FALSE, intercept = 0,
        linetype = "solid", line.col = "gray65", xlab = NULL, ylab = NULL,
        xlim = NULL, ylim = NULL, xbreaks = ggplot2::waiver(),
        ybreaks = ggplot2::waiver(), axis.title.size = 11, axis.text.size = 10,
        strip.text.size = 11, title = NULL, subtitle = NULL, group.col = NULL,
        plot.margin = NA, legend.title = "",
        legend.position = c("right", "top", "left", "bottom", "none"),
        legend.box.margin = c(-10, 0, 0, 0), facet.ncol = NULL, facet.nrow = NULL,
        facet.scales = "free", filename = NULL, width = NA, height = NA,
        units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL,
        append = TRUE, check = TRUE, output = TRUE)

ci.median(data, ..., boot = c("none", "norm", "basic", "stud", "perc", "bc", "bca"),
          R = 1000, seed = NULL, sample = TRUE,
          alternative = c("two.sided", "less", "greater"),
          conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
          na.omit = FALSE, digits = 2, as.na = NULL, plot = c("none", "ci", "boot"),
          point.size = 2.5, point.shape = 19, errorbar.width = 0.3, dodge.width = 0.5,
          hist = TRUE, binwidth = NULL, bins = NULL, hist.alpha = 0.4, fill = "gray85",
          density = TRUE, density.col = "#0072B2", density.linewidth = 0.5,
          density.linetype = "solid", point = TRUE, point.col = "#CC79A7",
          point.linewidth = 0.6, point.linetype = "solid", ci = TRUE, ci.col = "black",
          ci.linewidth = 0.6, ci.linetype = "dashed", line = FALSE, intercept = 0,
          linetype = "solid", line.col = "gray65", xlab = NULL, ylab = NULL,
          xlim = NULL, ylim = NULL, xbreaks = ggplot2::waiver(),
          ybreaks = ggplot2::waiver(), axis.title.size = 11, axis.text.size = 10,
          strip.text.size = 11, title = NULL, subtitle = NULL, group.col = NULL,
          plot.margin = NA,  legend.title = "",
          legend.position = c("right", "top", "left", "bottom", "none"),
          legend.box.margin = c(-10, 0, 0, 0), facet.ncol = NULL, facet.nrow = NULL,
          facet.scales = "free", filename = NULL, width = NA, height = NA,
          units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL, append = TRUE,
          check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.mean_+3A_data">data</code></td>
<td>
<p>a numeric vector or data frame with numeric
variables, i.e., factors and character variables are
excluded from <code>data</code> before conducting the
analysis.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>
e.g., <code>ci.mean(x1, x2, data = dat)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used
to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_sigma">sigma</code></td>
<td>
<p>a numeric vector indicating the population standard
deviation when computing confidence intervals for the
arithmetic mean with known standard deviation Note
that either argument <code>sigma</code> or argument
<code>sigma2</code> is specified and it is only possible to
specify one value for the argument <code>sigma</code> even
though multiple variables are specified in <code>data</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_sigma2">sigma2</code></td>
<td>
<p>a numeric vector indicating the population variance
when computing confidence intervals for the arithmetic
mean with known variance. Note that either argument
<code>sigma</code> or argument <code>sigma2</code> is specified
and it is only possible to specify one value for the
argument <code>sigma2</code> even though multiple variables
are specified in <code>data</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code>, difference-adjustment for
the confidence intervals for the arithmetic mean
(Baguley, 2012) is applied.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_boot">boot</code></td>
<td>
<p>a character string specifying the type of bootstrap
confidence intervals (CI), i.e., <code>"none"</code>
(default) for not conducting bootstrapping, <code>"norm"</code>
for the bias-corrected normal approximation bootstrap CI,
<code>"basic"</code> for the basic bootstrap CI, <code>"stud"</code>
for the studentized bootstrap CI, <code>"perc"</code>, for
the percentile bootstrap CI <code>"bc"</code> for the bias-corrected
(BC) percentile bootstrap CI (without acceleration),
and <code>"bca"</code> for the bias-corrected and accelerated
(BCa) bootstrap CI, see 'Details' in the
<code><a href="#topic+ci.cor">ci.cor</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_r">R</code></td>
<td>
<p>a numeric value indicating the number of bootstrap
replicates (default is 1000).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying seeds of the pseudo-random
numbers used in the bootstrap algorithm when conducting
bootstrapping.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_sample">sample</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the univariate
sample skewness and kurtosis is computed, while the
population skewness and kurtosis is computed when
<code>sample = FALSE</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name
of the grouping variable in <code>data</code>,
or a vector representing the grouping variable.  The grouping variable
is excluded from the data frame specified
in <code>data</code>. Notethat a grouping variable can only be used when computing
confidence intervals with unknown population standard
deviation and population variance.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_split">split</code></td>
<td>
<p>either a character string indicating the variable name
of the split variable in <code>data</code>,
or a vector representing the split variable. The split variable
is excluded from the data frame specified
in <code>data</code>.Note that a grouping variable can only be used when computing
confidence intervals with unknown population standard
deviation and population variance.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by
variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed
before conducting the analysis (i.e., listwise deletion)
when specifying more than one outcome variable.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal
places to be used.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing
values, i.e. these values are converted to <code>NA</code>
before conducting the analysis. Note that <code>as.na()</code>
function is only applied to <code>data</code>, but not to
<code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_plot">plot</code></td>
<td>
<p>a character string indicating the type of the plot
to display, i.e., <code>"none"</code> (default) for not
displaying any plots, <code>"ci"</code> for displaying
confidence intervals for the arithmetic mean or median,
<code>"boot"</code> for displaying bootstrap samples with
histograms and density curves when the argument
<code>"boot"</code> is other than <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>geom_point</code> function for controlling the
size of points when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_point.shape">point.shape</code></td>
<td>
<p>a numeric value between 0 and 25 or a character string
as plotting symbol indicating the <code>shape</code> argument
in the <code>geom_point</code> function for controlling the
symbols of points when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
in the <code>geom_errorbar</code> function for controlling
the width of the whiskers in the <code>geom_errorbar</code>
function when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_dodge.width">dodge.width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
controlling the width of the <code>geom</code> elements to
be dodged when specifying a grouping variable using
the argument <code>group</code> and plotting confidence
intervals (<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_hist">hist</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), histograms are
drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_binwidth">binwidth</code></td>
<td>
<p>a numeric value or a function for specifying the
<code>binwidth</code> argument in the <code>geom_histogram</code>
function for controlling the width of the bins when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_bins">bins</code></td>
<td>
<p>a numeric value for specifying the <code>bins</code> argument
in the <code>geom_histogram</code> function for controlling
the number of bins when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_hist.alpha">hist.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_histogram</code>
function for controlling the opacity of the bars
when plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_fill">fill</code></td>
<td>
<p>a character string specifying the <code>fill</code> argument
in the <code>geom_histogram</code> function controlling the
fill aesthetic when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_density">density</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), density curves are
drawn when plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_density.col">density.col</code></td>
<td>
<p>a character string specifying the <code>color</code> argument
in the <code>geom_density</code> function controlling the
color of the density curves when plotting bootstrap
samples (<code>plot = "boot"</code>). Note that this argument
applied only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_density.linewidth">density.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewidth</code>
argument in the <code>geom_density</code> function controlling
the line width of the density curves when plotting
bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_density.linetype">density.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_density</code>
function controlling the line type of the density
curves when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vertical lines
representing the point estimate of the arithmetic
mean or median are drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_point.col">point.col</code></td>
<td>
<p>a character string specifying the <code>color</code> argument
in the <code>geom_vline</code> function for controlling the
color of the vertical line displaying the arithmetic
mean or median when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument
applied only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_point.linewidth">point.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewdith</code>
argument in the <code>geom_vline</code> function for
controlling the line width of the vertical line
displaying the arithmetic mean or median when plotting
bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_point.linetype">point.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_vline</code>
function controlling the line type of the vertical
line displaying the arithmetic mean or median when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vertical lines
representing the bootstrap confidence intervals of
the arithmetic mean or median are drawn when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_ci.col">ci.col</code></td>
<td>
<p>character string specifying the <code>color</code> argument
in the <code>geom_vline</code> function for controlling the
color of the vertical line displaying bootstrap
confidence intervals when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_ci.linewidth">ci.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewdith</code> argument
in the <code>geom_vline</code> function for controlling the
line width of the vertical line displaying bootstrap
confidence intervals when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_ci.linetype">ci.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_vline</code>
function controlling the line type of the vertical
line displaying bootstrap confidence intervals when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code>, a horizontal line
is drawn when <code>plot = "ci"</code> or a vertical line
is drawn when <code>plot = "boot"</code></p>
</td></tr>
<tr><td><code id="ci.mean_+3A_intercept">intercept</code></td>
<td>
<p>a numeric value indicating the <code>yintercept</code> or
<code>xintercept</code> argument in the <code>geom_hline</code>
or <code>geom_vline</code> function controlling the position
of the horizontal or vertical line when <code>plot = "ci"</code>
and <code>line = TRUE</code> or when <code>plot = "boot"</code>
and <code>line = TRUE</code>. By default, the horizontal or
vertical line is drawn at 0.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_linetype">linetype</code></td>
<td>
<p>a character string indicating the <code>linetype</code>
argument in the <code>geom_hline</code> or <code>geom_vline</code>
function controlling the line type of the horizontal
or vertical line (default is <code>linetype = "dashed"</code>).</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_line.col">line.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
in the <code>geom_hline</code> or <code>geom_vline</code> function
for controlling the color of the horizontal or vertical
line.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_xlab">xlab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
in the <code>scale_x_continuous</code> function for labeling
the x-axis. The default setting is <code>xlab = NULL</code>
when <code>plot = "ci"</code> and <code>xlab = "Arithmetic Mean"</code>
or <code>xlab = "Median"</code> when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_ylab">ylab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
in the <code>scale_y_continuous</code> function for labeling
the y-axis. The default setting is <code>ylab = "Arithmetic Mean"</code>
or <code>ylab = "Median"</code> when <code>plot = "ci"</code> and
<code>ylab = "Probability Density, f(x)"</code> when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_xlim">xlim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument in the <code>scale_x_continuous</code>
function for controlling the scale range of the x-axis.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument in the <code>scale_y_continuous</code>
function for controlling the scale range of the y-axis.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_xbreaks">xbreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
in the <code>scale_x_continuous</code> function for controlling
the x-axis breaks. The default setting is
<code>xbreaks = NULL</code> when <code>plot = "ci"</code>
and <code>xbreaks = seq(-1, 1, by = 0.25)</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
in the <code>scale_y_continuous</code> function for controlling
the y-axis breaks. The default setting is
<code>ybreaks = seq(-1, 1, by = 0.25)</code> when
<code>plot = "ci"</code> and <code>ybreaks = NULL</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_axis.title.size">axis.title.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the axis title,
i.e., <code>theme(axis.title = element_text(size = axis.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_axis.text.size">axis.text.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the axis text,
i.e., <code>theme(axis.text = element_text(size = axis.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_strip.text.size">strip.text.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the strip text,
i.e., <code>theme(strip.text = element_text(size = strip.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_title">title</code></td>
<td>
<p>a character string indicating the <code>title</code> argument
in the <code>labs</code> function for the subtitle of the plot.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string indicating the <code>subtite</code> argument
in the <code>labs</code> function for the subtitle of the plot.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_group.col">group.col</code></td>
<td>
<p>a character vector indicating the <code>color</code> argument
in the <code>scale_color_manual</code> and <code>scale_fill_manual</code>
functions when specifying a grouping variable using
the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_plot.margin">plot.margin</code></td>
<td>
<p>a numeric vector with four elements indicating the
<code>plot.margin</code> argument in the <code>theme</code> function
controlling the plot margins . The default setting
is <code>c(5.5, 5.5, 5.5, 5.5)</code>, but switches
to <code>c(5.5, 5.5, -2.5, 5.5)</code> when specifying a
grouping variable using the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_legend.title">legend.title</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
in the <code>labs</code> function for specifying the legend
title when specifying a grouping variable using the
argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_legend.position">legend.position</code></td>
<td>
<p>a character string indicating the <code>legend.position</code>
in the <code>theme</code> argument for controlling the
position of the legend  function when specifying a
grouping variable using the argument <code>group</code>.
By default, the legend is placed at the bottom the
plot.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_legend.box.margin">legend.box.margin</code></td>
<td>
<p>a numeric vector with four elements indicating the
<code>legend.box.margin</code> argument in the <code>theme</code>
function for controlling the margins around the full
legend area when specifying a grouping variable using
the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_facet.ncol">facet.ncol</code></td>
<td>
<p>a numeric value indicating the <code>ncol</code> argument
in the <code>facet_wrap</code> function for controlling
the number of columns when specifying a split variable
using the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_facet.nrow">facet.nrow</code></td>
<td>
<p>a numeric value indicating the <code>nrow</code> argument
in the <code>facet_wrap</code> function for controlling the
number of rows when specifying a split variable using
the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_facet.scales">facet.scales</code></td>
<td>
<p>a character string indicating the <code>scales</code> argument
in the <code>facet_wrap</code> function for controlling the
scales shared across facets, i.e., <code>"fixed"</code>,
<code>"free_x"</code>, <code>"free_y"</code>, or <code>"free"</code>
(default) when specifying a split variable using
the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>file</code>
argument. Note that plots can only be saved when
<code>plot = "ci"</code> or <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output
into either a text file with file extension <code>".txt"</code>
(e.g., <code>"Output.txt"</code>) or Excel file with file
extension <code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>).
If the file name does not contain any file extension,
an Excel file will be written.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be
appended to an existing text file with extension
<code>.txt</code> specified in <code>write</code>, if <code>FALSE</code>
existing text file will be overwritten.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown
on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>data</code>, <code>group</code>, and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>data frame with bootstrap replicates of the arithmetic mean of median when bootstrapping was requested</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results and the data frame used for plotting</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Bootstrap confidence intervals are computed using the R package <code>boot</code>
by Angelo Canty and Brain Ripley (2024).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Baguley, T. S. (2012). <em>Serious stats: A guide to advanced statistics for
the behavioral sciences</em>. Palgrave Macmillan.
</p>
<p>Canty, A., &amp; Ripley, B. (2024). <em>boot: Bootstrap R (S-Plus) Functions</em>.
R package version 1.3-31.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.cor">ci.cor</a></code>, <code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>,
<code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Confidence Interval (CI) for the Arithmetic Mean

# Example 1a: Two-Sided 95% CI
ci.mean(mtcars)

# Example 1b: Two-Sided 95% Difference-Adjusted CI
ci.mean(mtcars, adjust = TRUE)

# Example 1c: Two-Sided 95% CI with known population standard deviation
ci.mean(mtcars, mpg, sigma = 6)

# Alternative specification without using the '...' argument
ci.mean(mtcars$mpg, sigma = 6)

#----------------------------------------------------------------------------
# Confidence Interval (CI) for the Median

# Example 2a: Two-Sided 95% CI
ci.median(mtcars)

# Example 2b: One-Sided 99% CI
ci.median(mtcars, alternative = "less", conf.level = 0.99)

## Not run: 
#----------------------------------------------------------------------------
# Bootstrap Confidence Interval (CI)

# Example 3a: Bias-corrected (BC) percentile bootstrap CI
ci.mean(mtcars, boot = "bc")

# Example 3b: Bias-corrected and accelerated (BCa) bootstrap CI,
# 5000 bootstrap replications, set seed of the pseudo-random number generator
ci.mean(mtcars, boot = "bca", R = 5000, seed = 123)

#----------------------------------------------------------------------------
# Grouping and Split Variable

# Example 4a: Grouping variable
ci.mean(mtcars, mpg, cyl, disp, group = "vs")

# Alternative specification without using the '...' argument
ci.mean(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs)

# Example 4b: Split variable
ci.mean(mtcars, mpg, cyl, disp, split = "am")

# Alternative specification
ci.mean(mtcars[, c("mpg", "cyl", "disp")], split = mtcars$am)

# Example 4c: Grouping and split variable
ci.mean(mtcars, mpg, cyl, disp, group = "vs", split = "am")

# Alternative specification
ci.mean(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs, split = mtcars$am)

#----------------------------------------------------------------------------
# Write Output

# Example 5a: Text file
ci.mean(mtcars, write = "CI_Mean_Text.txt")

# Example 5b: Excel file
ci.mean(mtcars, write = "CI_Mean_Excel.xlsx")

#----------------------------------------------------------------------------
# Plot Confidence Intervals

# Example 6a: Two-Sided 95
ci.mean(mtcars, disp, hp, plot = "ci")

# Example 6b: Grouping variable
ci.mean(mtcars, disp, hp, group = "vs", plot = "ci")

# Example 6c: Split variable
ci.mean(mtcars, disp, hp, split = "am", plot = "ci")

# Example 6d: Save plot as PDF file
ci.mean(mtcars, disp, hp, plot = "ci", saveplot = "CI_Mean.pdf",
        width = 9, height = 6)

# Example 6e: Save plot as PNG file
ci.mean(mtcars, disp, hp, plot = "ci", saveplot = "CI_Mean.png",
        width = 9, height = 6)

#----------------------------------------------------------------------------
# Example 7: Plot Bootstrap Samples

# Example 7a: Two-Sided 95
ci.mean(mtcars, disp, hp, boot = "bc", plot = "boot")

# Example 7b: Grouping variable
ci.mean(mtcars, disp, hp, group = "vs", boot = "bc", plot = "boot")

# Example 7c: Split variable
ci.mean(mtcars, disp, hp, split = "am", boot = "bc", plot = "boot")

# Example 7d: Save plot as PDF file
ci.mean(mtcars, disp, hp, boot = "bc", plot = "boot", saveplot = "CI_Mean_Boot.pdf",
        width = 12, height = 7)

# Example 7e: Save plot as PNG file
ci.mean(mtcars, disp, hp, boot = "bc", plot = "boot", saveplot = "CI_Mean_Boot.png",
        width = 12, height = 7)

## End(Not run)
</code></pre>

<hr>
<h2 id='ci.mean.diff'>Confidence Interval for the Difference in Arithmetic Means</h2><span id='topic+ci.mean.diff'></span><span id='topic+ci.mean.diff.default'></span><span id='topic+ci.mean.diff.formula'></span>

<h3>Description</h3>

<p>This function computes a confidence interval for the difference in arithmetic
means in a one-sample, two-sample and paired-sample design with known or unknown
population standard deviation or population variance for one or more variables,
optionally by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.mean.diff(x, ...)

## Default S3 method:
ci.mean.diff(x, y, mu = 0, sigma = NULL, sigma2 = NULL,
             var.equal = FALSE, paired = FALSE,
             alternative = c("two.sided", "less", "greater"),
             conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
             digits = 2, as.na = NULL, write = NULL, append = TRUE,
             check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
ci.mean.diff(formula, data, sigma = NULL, sigma2 = NULL,
             var.equal = FALSE, alternative = c("two.sided", "less", "greater"),
             conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
             na.omit = FALSE, digits = 2, as.na = NULL, write = NULL,
             append = TRUE, check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.mean.diff_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_y">y</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_mu">mu</code></td>
<td>
<p>a numeric value indicating the population mean under the
null hypothesis. Note that the argument <code>mu</code> is only
used when <code>y = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_sigma">sigma</code></td>
<td>
<p>a numeric vector indicating the population standard deviation(s)
when computing confidence intervals for the difference in
arithmetic means with known standard deviation(s). In case
of independent samples, equal standard deviations are assumed
when specifying one value for the argument <code>sigma</code>; when
specifying two values for the argument <code>sigma</code>, unequal
standard deviations are assumed. Note that either argument
<code>sigma</code> or argument <code>sigma2</code> is specified and it
is only possible to specify one value (i.e., equal variance
assumption) or two values (i.e., unequal variance assumption)
for the argument <code>sigma</code> even though multiple variables
are specified in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_sigma2">sigma2</code></td>
<td>
<p>a numeric vector indicating the population variance(s) when
computing confidence intervals for the difference in arithmetic
means with known variance(s). In case of independent samples,
equal variances are assumed when specifying one value for the
argument <code>sigma2</code>; when specifying two values for the
argument <code>sigma</code>, unequal variances are assumed. Note
that either argument <code>sigma</code> or argument <code>sigma2</code>
is specified and it is only possible to specify one value
(i.e., equal variance assumption) or two values (i.e., unequal
variance assumption) for the argument <code>sigma</code> even though
multiple variables are specified in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_var.equal">var.equal</code></td>
<td>
<p>logical: if <code>TRUE</code>, the population variance in the
independent samples are assumed to be equal.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, confidence interval for the difference
of arithmetic means in paired samples is computed.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_group">group</code></td>
<td>
<p>a numeric vector, character vector or factor as grouping
variable. Note that a grouping variable can only be used
when computing confidence intervals with unknown population
standard deviation and population variance.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_split">split</code></td>
<td>
<p>a numeric vector, character vector or factor as split variable.
Note that a split variable can only be used when computing
confidence intervals with unknown population</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables
when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied
to <code>x</code>, but not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> for one outcome variable
or <code>cbind(y1, y2, y3) ~ group</code> for more than one outcome
variable where <code>y</code> is a numeric variable giving the data
values and <code>group</code> a numeric variable, character variable
or factor with two values or factor levels giving the corresponding
groups.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the formula
<code>formula</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion) when specifying
more than one outcome variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>x</code>, <code>group</code>,
and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>,
<code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# One-sample design

# Example 1a: Two-Sided 95% CI for 'mpg'
# population mean = 20
ci.mean.diff(mtcars$mpg, mu = 20)

# Example 1a: One-Sided 95% CI for 'mpg'
# population mean = 20
ci.mean.diff(mtcars$mpg, mu = 20, alternative = "greater")

#----------------------------------------------------------------------------
# Two-sample design

# Example 2a: Two-Sided 95% CI for 'mpg' by 'vs'
# unknown population variances, unequal variance assumption
ci.mean.diff(mpg ~ vs, data = mtcars)

# Example 2b: Two-Sided 95% CI for 'mpg' by 'vs'
# unknown population variances, equal variance assumption
ci.mean.diff(mpg ~ vs, data = mtcars, var.equal = TRUE)

# Example 2c: Two-Sided 95% CI for 'mpg' by 'vs'
# known population standard deviations, equal standard deviation assumption
ci.mean.diff(mpg ~ vs, data = mtcars, sigma = 4)

# Example 2d: Two-Sided 95% CI for 'mpg' by 'vs'
# known population standard deviations, unequal standard deviation assumption
ci.mean.diff(mpg ~ vs, data = mtcars, sigma = c(4, 5))

# Example 2e: Two-Sided 95% CI for 'mpg', 'cyl', and 'disp' by 'vs'
# unknown population variances, unequal variance assumption
ci.mean.diff(cbind(mpg, cyl, disp) ~ vs, data = mtcars)

# Example 2f: Two-Sided 95% CI for 'mpg', 'cyl', and 'disp' by 'vs'
# unknown population variances, unequal variance assumption,
# analysis by am separately
ci.mean.diff(cbind(mpg, cyl, disp) ~ vs, data = mtcars, group = mtcars$am)

# Example 2g: Two-Sided 95% CI for 'mpg', 'cyl', and 'disp' by 'vs'
# unknown population variances, unequal variance assumption,
# split analysis by am
ci.mean.diff(cbind(mpg, cyl, disp) ~ vs, data = mtcars, split = mtcars$am)

# Example 2h: Two-Sided 95% CI for the mean difference between 'group1' and 'group2'
# unknown population variances, unequal variance assumption
group1 &lt;- c(3, 1, 4, 2, 5, 3, 6, 7)
group2 &lt;- c(5, 2, 4, 3, 1)

ci.mean.diff(group1, group2)

#----------------------------------------------------------------------------
# Paired-sample design

dat.p &lt;- data.frame(pre = c(1, 3, 2, 5, 7, 6), post = c(2, 2, 1, 6, 8, 9),
                    group = c(1, 1, 1, 2, 2, 2))

# Example 3a: Two-Sided 95% CI for the mean difference in 'pre' and 'post'
# unknown poulation variance of difference scores
ci.mean.diff(dat.p$pre, dat.p$post, paired = TRUE)

# Example 21: Two-Sided 95% CI for the mean difference in 'pre' and 'post'
# unknown poulation variance of difference scores
# analysis by group separately
ci.mean.diff(dat.p$pre, dat.p$post, paired = TRUE, group = dat.p$group)

# Example 22: Two-Sided 95% CI for the mean difference in 'pre' and 'post'
# unknown poulation variance of difference scores
# analysis by group separately
ci.mean.diff(dat.p$pre, dat.p$post, paired = TRUE, split = dat.p$group)

# Example 23: Two-Sided 95% CI for the mean difference in 'pre' and 'post'
# known population standard deviation of difference scores
ci.mean.diff(dat.p$pre, dat.p$post, sigma = 2, paired = TRUE)
</code></pre>

<hr>
<h2 id='ci.mean.w'>Within-Subject Confidence Interval for the Arithmetic Mean</h2><span id='topic+ci.mean.w'></span>

<h3>Description</h3>

<p>This function computes difference-adjusted Cousineau-Morey within-subject
confidence interval for the arithmetic mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.mean.w(data, ..., adjust = TRUE,
          alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
          na.omit = TRUE, digits = 2, as.na = NULL, write = NULL, append = TRUE,
          check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.mean.w_+3A_data">data</code></td>
<td>
<p>a data frame with numeric variables representing
the levels of the within-subject factor, i.e., data are
specified in wide-format (i.e., multivariate person level
format).</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>ci.mean.w(dat, time1, time2, time3)</code>. Note that
the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the Cousineau-Morey within-subject confidence intervals
is applied.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), incomplete cases are removed
before conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cousineau within-subject confidence interval (CI, Cousineau, 2005) is an
alternative to the Loftus-Masson within-subject CI (Loftus &amp; Masson, 1994)
that does not assume sphericity or homogeneity of covariances. This approach
removes individual differences by normalizing the raw scores using
participant-mean centering and adding the grand mean back to every score:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ij}^{'} = Y_{ij} - \hat{\mu}_{i} + \hat{\mu}_{grand}</code>
</p>

<p>where <code class="reqn">Y_{ij}^{'}</code> is the score of the <code class="reqn">i</code>th participant in condition
<code class="reqn">j</code> (for <code class="reqn">i = 1</code> to <code class="reqn">n</code>), <code class="reqn">\hat{\mu}_{i}</code> is the mean of
participant <code class="reqn">i</code> across all <code class="reqn">J</code> levels (for <code class="reqn">j = 1</code> to <code class="reqn">J</code>),
and <code class="reqn">\hat{\mu}_{grand}</code> is the grand mean.
</p>
<p>Morey (2008) pointed out that Cousineau's (2005) approach produces intervals
that are consistently too narrow due to inducing a positive covariance
between normalized scores within a condition introducing bias into the
estimate of the sample variances. The degree of bias is proportional to the
number of means and can be removed by rescaling the confidence interval by
a factor of <code class="reqn">\sqrt{J - 1}/J</code>:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu}_j \pm t_{n - 1, 1 - \alpha/2} \sqrt{\frac{J}{J - 1}} \hat{\sigma}^{'}_{{\hat{\mu}}_j}</code>
</p>

<p>where <code class="reqn">\hat{\sigma}^{'}_{{\mu}_j}</code> is the standard error of the mean computed
from the normalized scores of he <code class="reqn">j</code>th factor level.
</p>
<p>Baguley (2012) pointed out that the Cousineau-Morey interval is larger than
that for a difference in means by a factor of <code class="reqn">\sqrt{2}</code> leading to a
misinterpretation of these intervals that overlap of 95% confidence intervals
around individual means is indicates that a 95% confidence interval for the
difference in means would include zero. Hence, following adjustment to the
Cousineau-Morey interval was proposed:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu}_j \pm \frac{\sqrt{2}}{2} (t_{n - 1, 1 - \alpha/2} \sqrt{\frac{J}{J - 1}} \hat{\sigma}^{'}_{{\hat{\mu}}_j})</code>
</p>

<p>The adjusted Cousineau-Morey interval is informative about the pattern of
differences between means and is computed by default (i.e., <code>adjust = TRUE</code>).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Baguley, T. (2012). Calculating and graphing within-subject confidence intervals
for ANOVA. <em>Behavior Research Methods, 44</em>, 158-175.
https://doi.org/10.3758/s13428-011-0123-7
</p>
<p>Cousineau, D. (2005) Confidence intervals in within-subject designs: A simpler
solution to Loftus and Masson’s Method. <em>Tutorials in Quantitative Methods
for Psychology, 1</em>, 42–45.  https://doi.org/10.20982/tqmp.01.1.p042
</p>
<p>Loftus, G. R., and Masson, M. E. J. (1994). Using confidence intervals in
within-subject designs. <em>Psychonomic Bulletin and Review, 1</em>, 476–90.
https://doi.org/10.3758/BF03210951
</p>
<p>Morey, R. D. (2008). Confidence intervals from normalized data: A correction
to Cousineau. <em>Tutorials in Quantitative Methods for Psychology, 4</em>, 61–4.
https://doi.org/10.20982/tqmp.01.1.p042
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+test.t">test.t</a></code>,
<code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,' <code><a href="#topic+ci.median">ci.median</a></code>, <code><a href="#topic+ci.prop">ci.prop</a></code>,
<code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(time1 = c(3, 2, 1, 4, 5, 2, 3, 5, 6, 7),
                  time2 = c(4, 3, 6, 5, 8, 6, 7, 3, 4, 5),
                  time3 = c(1, 2, 2, 3, 6, 5, 1, 2, 4, 6))

# Example 1: Difference-adjusted Cousineau-Morey confidence intervals
ci.mean.w(dat)

# Example 2: Cousineau-Morey confidence intervals
ci.mean.w(dat, adjust = FALSE)

## Not run: 
# Example 3: Write results into a text file
ci.mean.w(dat, write = "WS_Confidence_Interval.txt")
## End(Not run)
</code></pre>

<hr>
<h2 id='ci.prop'>(Bootstrap) Confidence Intervals for Proportions</h2><span id='topic+ci.prop'></span>

<h3>Description</h3>

<p>This function computes and plots confidence intervals for proportions,
optionally by a grouping and/or split variable. The function also
supports three types of bootstrap confidence intervals (e.g., bias-corrected
(BC) percentile bootstrap or bias-corrected and accelerated (BCa) bootstrap
confidence intervals) and plots the bootstrap samples with histograms and
density curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.prop(data, ..., method = c("wald", "wilson"),
        boot = c("none", "perc", "bc", "bca"), R = 1000, seed = NULL,
        alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
        group = NULL, split = NULL, sort.var = FALSE, na.omit = FALSE, digits = 3,
        as.na = NULL, plot = c("none", "ci", "boot"), point.size = 2.5,
        point.shape = 19, errorbar.width = 0.3, dodge.width = 0.5, hist = TRUE,
        binwidth = NULL, bins = NULL, hist.alpha = 0.4, fill = "gray85",
        density = TRUE, density.col = "#0072B2", density.linewidth = 0.5,
        density.linetype = "solid", point = TRUE, point.col = "#CC79A7",
        point.linewidth = 0.6, point.linetype = "solid", ci = TRUE, ci.col = "black",
        ci.linewidth = 0.6, ci.linetype = "dashed",  line = FALSE, intercept = 0.5,
        linetype = "solid", line.col = "gray65",  xlab = NULL, ylab = NULL,
        xlim = NULL, ylim = NULL,  xbreaks = ggplot2::waiver(),
        ybreaks = ggplot2::waiver(),  axis.title.size = 11, axis.text.size = 10,
        strip.text.size = 11, title = NULL, subtitle = NULL, group.col = NULL,
        plot.margin = NA, legend.title = "",
        legend.position = c("right", "top", "left", "bottom", "none"),
        legend.box.margin = c(-10, 0, 0, 0), facet.ncol = NULL, facet.nrow = NULL,
        facet.scales = "free_y", filename = NULL, width = NA, height = NA,
        units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL, append = TRUE,
        check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.prop_+3A_data">data</code></td>
<td>
<p>a numeric vector or data frame with numeric
variables with 0 and 1 values.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>ci.prop(dat, x1, x2, x3)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used
to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_method">method</code></td>
<td>
<p>a character string specifying the method for computing
the confidence interval, must be one of <code>"wald"</code>,
or <code>"wilson"</code> (default).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_boot">boot</code></td>
<td>
<p>a character string specifying the type of bootstrap
confidence intervals (CI), i.e., <code>"none"</code> (default)
for not conducting bootstrapping, <code>"perc"</code>, for
the percentile bootstrap CI <code>"bc"</code> (default) for
the bias-corrected (BC) percentile bootstrap CI (without
acceleration), and <code>"bca"</code> for the bias-corrected
and accelerated (BCa) bootstrap CI, see 'Details' in
the <code><a href="#topic+ci.cor">ci.cor</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_r">R</code></td>
<td>
<p>a numeric value indicating the number of bootstrap
replicates (default is 1000).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying seeds of the pseudo-random
numbers used in the bootstrap algorithm when conducting
bootstrapping.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name
of the grouping variable in <code>data</code>,
or a vector representing the grouping variable.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_split">split</code></td>
<td>
<p>either a character string indicating the variable name
of the split variable in <code>data</code>,
or a vector representing the split variable.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by
variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed
before conducting the analysis (i.e., listwise deletion)
when specifying more than one outcome variable.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal
places to be used.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing
values, i.e. these values are converted to <code>NA</code>
before conducting the analysis. Note that <code>as.na()</code>
function is only applied to <code>data</code>, but not to
<code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_plot">plot</code></td>
<td>
<p>a character string indicating the type of the plot
to display, i.e., <code>"none"</code> (default) for not
displaying any plots, <code>"ci"</code> for displaying
confidence intervals for the proportion, <code>"boot"</code>
for displaying bootstrap samples with histograms and
density curves when the argument <code>"boot"</code> is
other than <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>geom_point</code> function for controlling the
size of points when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_point.shape">point.shape</code></td>
<td>
<p>a numeric value between 0 and 25 or a character string
as plotting symbol indicating the <code>shape</code> argument
in the <code>geom_point</code> function for controlling the
symbols of points when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
in the <code>geom_errorbar</code> function for controlling
the width of the whiskers in the <code>geom_errorbar</code>
function when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_dodge.width">dodge.width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
controlling the width of the <code>geom</code> elements to
be dodged when specifying a grouping variable using
the argument <code>group</code> when plotting confidence
intervals (<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_hist">hist</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), histograms are
drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_binwidth">binwidth</code></td>
<td>
<p>a numeric value or a function for specifying the
<code>binwidth</code> argument in the <code>geom_histogram</code>
function for controlling the width of the bins when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_bins">bins</code></td>
<td>
<p>a numeric value for specifying the <code>bins</code> argument
in the <code>geom_histogram</code> function for controlling
the number of bins when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_hist.alpha">hist.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_histogram</code>
function for controlling the opacity of the bars
when plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_fill">fill</code></td>
<td>
<p>a character string specifying the <code>fill</code> argument
in the <code>geom_histogram</code> function controlling the
fill aesthetic when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_density">density</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), density curves are
drawn when plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_density.col">density.col</code></td>
<td>
<p>a character string specifying the <code>color</code> argument
in the <code>geom_density</code> function controlling the
color of the density curves when plotting bootstrap
samples (<code>plot = "boot"</code>). Note that this argument
applied only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_density.linewidth">density.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewidth</code>
argument in the <code>geom_density</code> function controlling
the line width of the density curves when plotting
bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_density.linetype">density.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_density</code>
function controlling the line type of the density
curves when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vertical lines
representing the point estimate of the proportion
are drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_point.col">point.col</code></td>
<td>
<p>a character string specifying the <code>color</code> argument
in the <code>geom_vline</code> function for controlling the
color of the vertical line displaying the proportion
when plotting bootstrap samples (<code>plot = "boot"</code>).
Note that this argument applied only when no grouping
variable was specified <code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_point.linewidth">point.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewdith</code>
argument in the <code>geom_vline</code> function for
controlling the line width of the vertical line
displaying proportions when plotting bootstrap
samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_point.linetype">point.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_vline</code>
function controlling the line type of the vertical
line displaying proportions when plotting bootstrap
samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vertical lines
representing the bootstrap confidence intervals of
proportions are drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_ci.col">ci.col</code></td>
<td>
<p>character string specifying the <code>color</code> argument
in the <code>geom_vline</code> function for controlling the
color of the vertical line displaying bootstrap
confidence intervals when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_ci.linewidth">ci.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewdith</code> argument
in the <code>geom_vline</code> function for controlling the
line width of the vertical line displaying bootstrap
confidence intervals when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_ci.linetype">ci.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_vline</code>
function controlling the line type of the vertical
line displaying bootstrap confidence intervals when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code>, a horizontal line
is drawn when <code>plot = "ci"</code> or a vertical line
is drawn when <code>plot = "boot"</code></p>
</td></tr>
<tr><td><code id="ci.prop_+3A_intercept">intercept</code></td>
<td>
<p>a numeric value indicating the <code>yintercept</code> or
<code>xintercept</code> argument in the <code>geom_hline</code>
or <code>geom_vline</code> function controlling the position
of the horizontal or vertical line when <code>plot = "ci"</code>
and <code>line = TRUE</code> or when <code>plot = "boot"</code>
and <code>line = TRUE</code>. By default, the horizontal or
vertical line is drawn at 0.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_linetype">linetype</code></td>
<td>
<p>a character string indicating the <code>linetype</code>
argument in the <code>geom_hline</code> or <code>geom_vline</code>
function controlling the line type of the horizontal
or vertical line (default is <code>linetype = "dashed"</code>).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_line.col">line.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
in the <code>geom_hline</code> or <code>geom_vline</code> function
for controlling the color of the horizontal or vertical
line.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_xlab">xlab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
in the <code>scale_x_continuous</code> function for labeling
the x-axis. The default setting is <code>xlab = NULL</code>
when <code>plot = "ci"</code> and <code>xlab = "Proportion"</code>
when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_ylab">ylab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
in the <code>scale_y_continuous</code> function for labeling
the y-axis. The default setting is <code>ylab = "Proportion"</code>
when <code>plot = "ci"</code> and
<code>ylab = "Probability Density, f(x)"</code> when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_xlim">xlim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument in the <code>scale_x_continuous</code>
function for controlling the scale range of the x-axis.
The default setting is <code>xlim = NULL</code>
when <code>plot = "ci"</code> and <code>xlim = c(0, 1)</code>
when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument in the <code>scale_y_continuous</code>
function for controlling the scale range of the y-axis.
The default setting is <code>ylim = c(0, 1)</code> when
<code>plot = "ci"</code> and <code>xlim = NULL</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_xbreaks">xbreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
in the <code>scale_x_continuous</code> function for controlling
the x-axis breaks. The default setting is
<code>xbreaks = NULL</code> when <code>plot = "ci"</code>
and <code>xbreaks = seq(-1, 1, by = 0.25)</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
in the <code>scale_y_continuous</code> function for controlling
the y-axis breaks. The default setting is
<code>ybreaks = seq(-1, 1, by = 0.25)</code> when
<code>plot = "ci"</code> and <code>ybreaks = NULL</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_axis.title.size">axis.title.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the axis title,
i.e., <code>theme(axis.title = element_text(size = axis.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_axis.text.size">axis.text.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the axis text,
i.e., <code>theme(axis.text = element_text(size = axis.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_strip.text.size">strip.text.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the strip text,
i.e., <code>theme(strip.text = element_text(size = strip.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_title">title</code></td>
<td>
<p>a character string indicating the <code>title</code> argument
in the <code>labs</code> function for the subtitle of the plot.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string indicating the <code>subtite</code> argument
in the <code>labs</code> function for the subtitle of the plot.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_group.col">group.col</code></td>
<td>
<p>a character vector indicating the <code>color</code> argument
in the <code>scale_color_manual</code> and <code>scale_fill_manual</code>
functions when specifying a grouping variable using
the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_plot.margin">plot.margin</code></td>
<td>
<p>a numeric vector with four elements indicating the
<code>plot.margin</code> argument in the <code>theme</code> function
controlling the plot margins . The default setting
is <code>c(5.5, 5.5, 5.5, 5.5)</code>, but switches
to <code>c(5.5, 5.5, -2.5, 5.5)</code> when specifying a
grouping variable using the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_legend.title">legend.title</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
in the <code>labs</code> function for specifying the legend
title when specifying a grouping variable using the
argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_legend.position">legend.position</code></td>
<td>
<p>a character string indicating the <code>legend.position</code>
in the <code>theme</code> argument for controlling the
position of the legend  function when specifying a
grouping variable using the argument <code>group</code>.
By default, the legend is placed at the bottom the
plot.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_legend.box.margin">legend.box.margin</code></td>
<td>
<p>a numeric vector with four elements indicating the
<code>legend.box.margin</code> argument in the <code>theme</code>
function for controlling the margins around the full
legend area when specifying a grouping variable using
the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_facet.ncol">facet.ncol</code></td>
<td>
<p>a numeric value indicating the <code>ncol</code> argument
in the <code>facet_wrap</code> function for controlling
the number of columns when specifying a split variable
using the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_facet.nrow">facet.nrow</code></td>
<td>
<p>a numeric value indicating the <code>nrow</code> argument
in the <code>facet_wrap</code> function for controlling the
number of rows when specifying a split variable using
the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_facet.scales">facet.scales</code></td>
<td>
<p>a character string indicating the <code>scales</code> argument
in the <code>facet_wrap</code> function for controlling the
scales shared across facets, i.e., <code>"fixed"</code>,
<code>"free_x"</code>, <code>"free_y"</code>, or <code>"free"</code>
(default) when specifying a split variable using
the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>file</code>
argument. Note that plots can only be saved when
<code>plot = "ci"</code> or <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output
into either a text file with file extension <code>".txt"</code>
(e.g., <code>"Output.txt"</code>) or Excel file with file
extension <code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>).
If the file name does not contain any file extension,
an Excel file will be written.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be
appended to an existing text file with extension
<code>.txt</code> specified in <code>write</code>, if <code>FALSE</code>
existing text file will be overwritten.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on
the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wald confidence interval which is based on the normal approximation to the
binomial distribution are computed by specifying <code>method = "wald"</code>, while
the Wilson (1927) confidence interval (aka Wilson score interval) is requested
by specifying <code>method = "wilson"</code>. By default, Wilson confidence interval
is computed which have been shown to be reliable in small samples of n = 40 or
less, and larger samples of n &gt; 40 (Brown, Cai &amp; DasGupta, 2001), while the
Wald confidence intervals is inadequate in small samples and when <em>p</em> is
near 0 or 1 (Agresti &amp; Coull, 1998).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>...</code>, <code>data</code>, <code>group</code>, and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>data frame with bootstrap replicates of the aproportion when bootstrapping was requested</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results and the data frame used for plotting</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Bootstrap confidence intervals are computed using the R package <code>boot</code>
by Angelo Canty and Brain Ripley (2024).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Agresti, A. &amp; Coull, B.A. (1998). Approximate is better than &quot;exact&quot; for
interval estimation of binomial proportions. <em>American Statistician, 52</em>,
119-126.
</p>
<p>Brown, L. D., Cai, T. T., &amp; DasGupta, A., (2001). Interval estimation for a
binomial proportion. <em>Statistical Science, 16</em>, 101-133.
</p>
<p>Canty, A., &amp; Ripley, B. (2024). <em>boot: Bootstrap R (S-Plus) Functions</em>.
R package version 1.3-31.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Wilson, E. B. (1927). Probable inference, the law of succession, and statistical
inference. <em>Journal of the American Statistical Association, 22</em>, 209-212.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.prop.diff">ci.prop.diff</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>,
<code><a href="#topic+ci.prop.diff">ci.prop.diff</a></code>, <code><a href="#topic+ci.cor">ci.cor</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>,
<code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Confidence Interval (CI) forproportions

# Example 1a: Two-Sided 95% CI
ci.prop(mtcars, vs, am)

# Alternative specification without using the '...' argument
ci.prop(mtcars[, c("vs", "am")])

# Example 1b: One-Sided 95% CI using Wald method
ci.prop(mtcars, vs, am, method = "wald", alternative = "less")

## Not run: 
#----------------------------------------------------------------------------
# Bootstrap Confidence Interval (CI)

# Example 2a: Bias-corrected (BC) percentile bootstrap CI
ci.prop(mtcars, vs, am, boot = "bc")

# Example 2b: Bias-corrected and accelerated (BCa) bootstrap CI,
# 5000 bootstrap replications, set seed of the pseudo-random number generator
ci.prop(mtcars, vs, am, boot = "bca", R = 5000, seed = 123)

#----------------------------------------------------------------------------
# Grouping and Split Variable

# Example 3a: Grouping variable
ci.prop(mtcars, vs, group = "am")

# Alternative specification without using the '...' argument
ci.prop(mtcars$vs, group = mtcars$am)

# Example 3b: Split variable
ci.prop(mtcars, vs, split = "am")

# Alternative specification without using the '...' argument
ci.prop(mtcars$vs, split = mtcars$am)

# Example 3c: Grouping and split variable
ci.prop(mtcars, vs, group = "am", split = "cyl")

# Alternative specification without using the '...' argument
ci.prop(mtcars$vs, group = mtcars$am, split = mtcars$cyl)

#----------------------------------------------------------------------------
# Write Output

# Example 4a: Text file
ci.prop(mtcars, vs, am, write = "CI_Prop_Text.txt")

# Example 4b: Excel file
ci.prop(mtcars, vs, am, write = "CI_Prop_Excel.xlsx")

#----------------------------------------------------------------------------
# Plot Confidence Intervals

# Example 5a: Two-Sided 95
ci.prop(mtcars, vs, am, plot = "ci")

# Example 5b: Grouping variable
ci.prop(mtcars, vs, am, group = "am", plot = "ci")

# Example 5c: Split variable
ci.prop(mtcars, vs, am, split = "am", plot = "ci")

# Example 5d: Save plot as PDF file
ci.prop(mtcars, vs, am, plot = "ci", saveplot = "CI_Prop.pdf",
        width = 9, height = 6)

# Example 5e: Save plot as PNG file
ci.prop(mtcars, vs, am, plot = "ci", saveplot = "CI_Prop.png",
        width = 9, height = 6)

#----------------------------------------------------------------------------
# Plot Bootstrap Samples

# Example 6a: Two-Sided 95
ci.prop(mtcars, vs, am, boot = "bc", plot = "boot")

# Example 6b: Grouping variable
ci.prop(mtcars, vs, am, group = "am", boot = "bc", plot = "boot")

# Example 6c: Split variable
ci.prop(mtcars, vs, am, split = "am", boot = "bc", plot = "boot")

# Example 6d: Save plot as PDF file
ci.prop(mtcars, vs, am, boot = "bc", plot = "boot",
        saveplot = "CI_Prop_Boot.pdf", width = 9, height = 6)

# Example 6e: Save plot as PNG file
ci.prop(mtcars, vs, am, boot = "bc", plot = "boot",
        saveplot = "CI_Prop_Boot.png", width = 9, height = 6)

## End(Not run)
</code></pre>

<hr>
<h2 id='ci.prop.diff'>Confidence Interval for the Difference in Proportions</h2><span id='topic+ci.prop.diff'></span><span id='topic+ci.prop.diff.default'></span><span id='topic+ci.prop.diff.formula'></span>

<h3>Description</h3>

<p>This function computes a confidence interval for the difference in proportions in a two-sample
and paired-sample design for one or more variables, optionally by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.prop.diff(x, ...)

## Default S3 method:
ci.prop.diff(x, y, method = c("wald", "newcombe"), paired = FALSE,
             alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
             group = NULL, split = NULL, sort.var = FALSE, digits = 2,
             as.na = NULL, write = NULL, append = TRUE,
             check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
ci.prop.diff(formula, data, method = c("wald", "newcombe"),
             alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
             group = NULL, split = NULL, sort.var = FALSE, na.omit = FALSE,
             digits = 2, as.na = NULL, write = NULL, append = TRUE,
             check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.prop.diff_+3A_x">x</code></td>
<td>
<p>a numeric vector with 0 and 1 values.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_y">y</code></td>
<td>
<p>a numeric vector with 0 and 1 values.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_method">method</code></td>
<td>
<p>a character string specifying the method for computing the confidence interval,
must be one of <code>"wald"</code>, or <code>"newcombe"</code> (default).</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, confidence interval for the difference of proportions
in paired samples is computed.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of
<code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level of the interval.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_group">group</code></td>
<td>
<p>a numeric vector, character vector or factor as grouping variable. Note that a grouping
variable can only be used when computing confidence intervals with unknown population
standard deviation and population variance.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_split">split</code></td>
<td>
<p>a numeric vector, character vector or factor as split variable. Note that a split
variable can only be used when computing confidence intervals with unknown population
standard deviation and population variance.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting the analysis.
Note that <code>as.na()</code> function is only applied to <code>x</code>, but
not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> for one outcome variable or
<code>cbind(y1, y2, y3) ~ group</code> for more than one outcome variable where
<code>y</code> is a numeric variable with 0 and 1 values and <code>group</code> a numeric
variable, character variable or factor with two values or factor levels giving
the corresponding group.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before conducting the analysis
(i.e., listwise deletion) when specifying more than one outcome variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wald confidence interval which is based on the normal approximation to the binomial distribution are
computed by specifying <code>method = "wald"</code>, while the Newcombe Hybrid Score interval (Newcombe, 1998a;
Newcombe, 1998b) is requested by specifying <code>method = "newcombe"</code>. By default, Newcombe Hybrid Score
interval is computed which have been shown to be reliable in small samples (less than n = 30 in each sample)
as well as moderate to larger samples(n &gt; 30 in each sample) and with proportions close to 0 or 1, while the
Wald confidence intervals does not perform well unless the sample size is large (Fagerland, Lydersen &amp; Laake, 2011).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>x</code>, <code>group</code>,
and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Fagerland, M. W., Lydersen S., &amp; Laake, P. (2011) Recommended confidence intervals for two independent binomial
proportions. <em>Statistical Methods in Medical Research, 24</em>, 224-254.
</p>
<p>Newcombe, R. G. (1998a). Interval estimation for the difference between independent proportions: Comparison of
eleven methods. <em>Statistics in Medicine, 17</em>, 873-890.
</p>
<p>Newcombe, R. G. (1998b). Improved confidence intervals for the difference between binomial proportions based on
paired data. <em>Statistics in Medicine, 17</em>, 2635-2650.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology - Using R and SPSS</em>.
John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.median">ci.median</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>,
<code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Two-sample design

# Example 1a: Two-Sided 95% CI for 'vs' by 'am'
# Newcombes Hybrid Score interval
ci.prop.diff(vs ~ am, data = mtcars)

# Example 1b: Two-Sided 95% CI for 'vs' by 'am'
# Wald CI
ci.prop.diff(vs ~ am, data = mtcars, method = "wald")

# Example 1c: Two-Sided 95% CI for the difference in proportions
# Newcombes Hybrid Score interval
ci.prop.diff(c(0, 1, 1, 0, 0, 1, 0, 1), c(1, 1, 1, 0, 0))

#----------------------------------------------------------------------------
# Paired-sample design

dat.p &lt;- data.frame(pre = c(0, 1, 1, 0, 1), post = c(1, 1, 0, 1, 1))

# Example 2a: Two-Sided 95% CI for the difference in proportions 'pre' and 'post'
# Newcombes Hybrid Score interval
ci.prop.diff(dat.p$pre, dat.p$post, paired = TRUE)

# Example 2b: Two-Sided 95% CI for the difference in proportions 'pre' and 'post'
# Wald CI
ci.prop.diff(dat.p$pre, dat.p$post, method = "wald", paired = TRUE)
</code></pre>

<hr>
<h2 id='ci.var'>(Bootstrap) Confidence Intervals for Variances and Standard Deviations</h2><span id='topic+ci.var'></span><span id='topic+ci.sd'></span>

<h3>Description</h3>

<p>The function <code>ci.var</code> computes and plots confidence intervals for variances,
and the function <code>ci.sd</code> computes confidence intervals for the standard
deviations, optionally by a grouping and/or split variable. These functions
also supports three types of bootstrap confidence intervals (e.g., bias-corrected
(BC) percentile bootstrap or bias-corrected and accelerated (BCa) bootstrap
confidence intervals) and plots the bootstrap samples with histograms and
density curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.var(data, ..., method = c("chisq", "bonett"),
       boot = c("none", "perc", "bc", "bca"), R = 1000, seed = NULL,
       alternative = c("two.sided", "less", "greater"),
       conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
       na.omit = FALSE, digits = 2, as.na = NULL,
       plot = c("none", "ci", "boot"), point.size = 2.5, point.shape = 19,
       errorbar.width = 0.3, dodge.width = 0.5, hist = TRUE,
       binwidth = NULL, bins = NULL, hist.alpha = 0.4, fill = "gray85", density = TRUE,
       density.col = "#0072B2", density.linewidth = 0.5, density.linetype = "solid",
       point = TRUE, point.col = "#CC79A7", point.linewidth = 0.6,
       point.linetype = "solid", ci = TRUE, ci.col = "black",
       ci.linewidth = 0.6, ci.linetype = "dashed", line = FALSE, intercept = 0,
       linetype = "solid", line.col = "gray65", xlab = NULL, ylab = NULL,
       xlim = NULL, ylim = NULL, xbreaks = ggplot2::waiver(), ybreaks = ggplot2::waiver(),
       axis.title.size = 11, axis.text.size = 10, strip.text.size = 11, title = NULL,
       subtitle = NULL, group.col = NULL, plot.margin = NA,  legend.title = "",
       legend.position = c("right", "top", "left", "bottom", "none"),
       legend.box.margin = c(-10, 0, 0, 0), facet.ncol = NULL, facet.nrow = NULL,
       facet.scales = "free", filename = NULL, width = NA, height = NA,
       units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL, append = TRUE,
       check = TRUE, output = TRUE)

ci.sd(data, ..., method = c("chisq", "bonett"),
      boot = c("none", "perc", "bc", "bca"), R = 1000, seed = NULL,
      alternative = c("two.sided", "less", "greater"),
      conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
      na.omit = FALSE, digits = 2, as.na = NULL,
      plot = c("none", "ci", "boot"), point.size = 2.5, point.shape = 19,
      errorbar.width = 0.3, dodge.width = 0.5, hist = TRUE,
      binwidth = NULL, bins = NULL, hist.alpha = 0.4, fill = "gray85", density = TRUE,
      density.col = "#0072B2", density.linewidth = 0.5, density.linetype = "solid",
      point = TRUE, point.col = "#CC79A7", point.linewidth = 0.6,
      point.linetype = "solid", ci = TRUE, ci.col = "black",
      ci.linewidth = 0.6, ci.linetype = "dashed", line = FALSE, intercept = 0,
      linetype = "solid", line.col = "gray65", xlab = NULL, ylab = NULL,
      xlim = NULL, ylim = NULL, xbreaks = ggplot2::waiver(), ybreaks = ggplot2::waiver(),
      axis.title.size = 11, axis.text.size = 10, strip.text.size = 11, title = NULL,
      subtitle = NULL, group.col = NULL, plot.margin = NA,  legend.title = "",
      legend.position = c("right", "top", "left", "bottom", "none"),
      legend.box.margin = c(-10, 0, 0, 0), facet.ncol = NULL, facet.nrow = NULL,
      facet.scales = "free", filename = NULL, width = NA, height = NA,
      units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL,
      append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ci.var_+3A_data">data</code></td>
<td>
<p>a numeric vector or data frame with numeric
variables, i.e., factors and character variables are
excluded from <code>data</code> before conducting the analysis.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>ci.var(dat, x1, x2, x3)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used
to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_method">method</code></td>
<td>
<p>a character string specifying the method for computing
the confidence interval, must be one of <code>"chisq"</code>,
or <code>"bonett"</code> (default).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_boot">boot</code></td>
<td>
<p>a character string specifying the type of bootstrap
confidence intervals (CI), i.e., <code>"none"</code> (default)
for not conducting bootstrapping, <code>"perc"</code>, for
the percentile bootstrap CI <code>"bc"</code> (default) for
the bias-corrected (BC) percentile bootstrap CI (without
acceleration), and <code>"bca"</code> for the bias-corrected
and accelerated (BCa) bootstrap CI, see 'Details' in
the <code><a href="#topic+ci.cor">ci.cor</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_r">R</code></td>
<td>
<p>a numeric value indicating the number of bootstrap
replicates (default is 1000).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying seeds of the pseudo-random
numbers used in the bootstrap algorithm when conducting
bootstrapping.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name
of the grouping variable in <code>data</code>, or a vector representing the grouping
variable.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_split">split</code></td>
<td>
<p>either a character string indicating the variable name
of the split variable in 'data', or a vector representing the split variable.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by
variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed
before conducting the analysis (i.e., listwise deletion)
when specifying more than one outcome variable.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal
places to be used.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.
Note that <code>as.na()</code> function is only applied to
<code>data</code>, but not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_plot">plot</code></td>
<td>
<p>a character string indicating the type of the plot
to display, i.e., <code>"none"</code> (default) for not
displaying any plots, <code>"ci"</code> for displaying
confidence intervals for variances or standard deviations,
<code>"boot"</code> for displaying bootstrap samples with
histograms and density curves when the argument
<code>"boot"</code> is other than <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>geom_point</code> function for controlling the
size of points when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_point.shape">point.shape</code></td>
<td>
<p>a numeric value between 0 and 25 or a character string
as plotting symbol indicating the <code>shape</code> argument
in the <code>geom_point</code> function for controlling the
symbols of points when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
in the <code>geom_errorbar</code> function for controlling
the width of the whiskers in the <code>geom_errorbar</code>
function when plotting confidence intervals
(<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_dodge.width">dodge.width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
controlling the width of the <code>geom</code> elements to
be dodged when specifying a grouping variable using
the argument <code>group</code> and plotting confidence
intervals (<code>plot = "ci"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_hist">hist</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), histograms are
drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_binwidth">binwidth</code></td>
<td>
<p>a numeric value or a function for specifying the
<code>binwidth</code> argument in the <code>geom_histogram</code>
function for controlling the width of the bins when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_bins">bins</code></td>
<td>
<p>a numeric value for specifying the <code>bins</code> argument
in the <code>geom_histogram</code> function for controlling
the number of bins when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_hist.alpha">hist.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_histogram</code>
function for controlling the opacity of the bars
when plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_fill">fill</code></td>
<td>
<p>a character string specifying the <code>fill</code> argument
in the <code>geom_histogram</code> function controlling the
fill aesthetic when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_density">density</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), density curves are
drawn when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_density.col">density.col</code></td>
<td>
<p>a character string specifying the <code>color</code> argument
in the <code>geom_density</code> function controlling the
color of the density curves when plotting bootstrap
samples (<code>plot = "boot"</code>). Note that this argument
applied only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_density.linewidth">density.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewidth</code>
argument in the <code>geom_density</code> function controlling
the line width of the density curves when plotting
bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_density.linetype">density.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_density</code>
function controlling the line type of the density
curves when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vertical lines
representing the point estimate of the variance or
standard deviation are drawn when plotting bootstrap
samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_point.col">point.col</code></td>
<td>
<p>a character string specifying the <code>color</code> argument
in the <code>geom_vline</code> function for controlling the
color of the vertical line displaying the variance
or standard deviation when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument
applied only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_point.linewidth">point.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewdith</code>
argument in the <code>geom_vline</code> function for
controlling the line width of the vertical line
displaying the variance or standard deviation when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_point.linetype">point.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_vline</code>
function controlling the line type of the vertical
line displaying the variance or standard deviation
when plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vertical lines
representing the bootstrap confidence intervals of
the variance or standard deviation are drawn when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_ci.col">ci.col</code></td>
<td>
<p>character string specifying the <code>color</code> argument
in the <code>geom_vline</code> function for controlling the
color of the vertical line displaying bootstrap
confidence intervals when plotting bootstrap samples
(<code>plot = "boot"</code>). Note that this argument applied
only when no grouping variable was specified
<code>group = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_ci.linewidth">ci.linewidth</code></td>
<td>
<p>a numeric value specifying the <code>linewdith</code> argument
in the <code>geom_vline</code> function for controlling the
line width of the vertical line displaying bootstrap
confidence intervals when plotting bootstrap samples
(<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_ci.linetype">ci.linetype</code></td>
<td>
<p>a numeric value or character string specifying the
<code>linetype</code> argument in the <code>geom_vline</code>
function controlling the line type of the vertical
line displaying bootstrap confidence intervals when
plotting bootstrap samples (<code>plot = "boot"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code>, a horizontal line
is drawn when <code>plot = "ci"</code> or a vertical line
is drawn when <code>plot = "boot"</code></p>
</td></tr>
<tr><td><code id="ci.var_+3A_intercept">intercept</code></td>
<td>
<p>a numeric value indicating the <code>yintercept</code> or
<code>xintercept</code> argument in the <code>geom_hline</code>
or <code>geom_vline</code> function controlling the position
of the horizontal or vertical line when <code>plot = "ci"</code>
and <code>line = TRUE</code> or when <code>plot = "boot"</code>
and <code>line = TRUE</code>. By default, the horizontal or
vertical line is drawn at 0.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_linetype">linetype</code></td>
<td>
<p>a character string indicating the <code>linetype</code>
argument in the <code>geom_hline</code> or <code>geom_vline</code>
function controlling the line type of the horizontal
or vertical line (default is <code>linetype = "dashed"</code>).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_line.col">line.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
in the <code>geom_hline</code> or <code>geom_vline</code> function
for controlling the color of the horizontal or vertical
line.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_xlab">xlab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
in the <code>scale_x_continuous</code> function for labeling
the x-axis. The default setting is <code>xlab = NULL</code>
when <code>plot = "ci"</code> and <code>xlab = "Variance"</code>
or <code>xlab = "Standard Deviation"</code> when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_ylab">ylab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
in the <code>scale_y_continuous</code> function for labeling
the y-axis. The default setting is <code>ylab = "Variance"</code>
or <code>ylab = "Standard Deviation"</code> when <code>plot = "ci"</code>
and <code>ylab = "Probability Density, f(x)"</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_xlim">xlim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument in the <code>scale_x_continuous</code>
function for controlling the scale range of the x-axis.
The default setting is <code>xlim = NULL</code>
when <code>plot = "ci"</code> and <code>xlim = c(-1, 1)</code>
when <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument in the <code>scale_y_continuous</code>
function for controlling the scale range of the y-axis.
The default setting is <code>ylim = c(-1, 1)</code> when
<code>plot = "ci"</code> and <code>xlim = NULL</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_xbreaks">xbreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
in the <code>scale_x_continuous</code> function for controlling
the x-axis breaks. The default setting is
<code>xbreaks = NULL</code> when <code>plot = "ci"</code>
and <code>xbreaks = seq(-1, 1, by = 0.25)</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
in the <code>scale_y_continuous</code> function for controlling
the y-axis breaks. The default setting is
<code>ybreaks = seq(-1, 1, by = 0.25)</code> when
<code>plot = "ci"</code> and <code>ybreaks = NULL</code> when
<code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_axis.title.size">axis.title.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the axis title,
i.e., <code>theme(axis.title = element_text(size = axis.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_axis.text.size">axis.text.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the axis text,
i.e., <code>theme(axis.text = element_text(size = axis.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_strip.text.size">strip.text.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> argument
in the <code>element_text</code> function for specifying the
function controlling the font size of the strip text,
i.e., <code>theme(strip.text = element_text(size = strip.text.size))</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_title">title</code></td>
<td>
<p>a character string indicating the <code>title</code> argument
in the <code>labs</code> function for the subtitle of the plot.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string indicating the <code>subtite</code> argument
in the <code>labs</code> function for the subtitle of the plot.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_group.col">group.col</code></td>
<td>
<p>a character vector indicating the <code>color</code> argument
in the <code>scale_color_manual</code> and <code>scale_fill_manual</code>
functions when specifying a grouping variable using
the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_plot.margin">plot.margin</code></td>
<td>
<p>a numeric vector with four elements indicating the
<code>plot.margin</code> argument in the <code>theme</code> function
controlling the plot margins . The default setting
is <code>c(5.5, 5.5, 5.5, 5.5)</code>, but switches
to <code>c(5.5, 5.5, -2.5, 5.5)</code> when specifying a
grouping variable using the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_legend.title">legend.title</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
in the <code>labs</code> function for specifying the legend
title when specifying a grouping variable using the
argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_legend.position">legend.position</code></td>
<td>
<p>a character string indicating the <code>legend.position</code>
in the <code>theme</code> argument for controlling the
position of the legend  function when specifying a
grouping variable using the argument <code>group</code>.
By default, the legend is placed at the bottom the
plot.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_legend.box.margin">legend.box.margin</code></td>
<td>
<p>a numeric vector with four elements indicating the
<code>legend.box.margin</code> argument in the <code>theme</code>
function for controlling the margins around the full
legend area when specifying a grouping variable using
the argument <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_facet.ncol">facet.ncol</code></td>
<td>
<p>a numeric value indicating the <code>ncol</code> argument
in the <code>facet_wrap</code> function for controlling
the number of columns when specifying a split variable
using the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_facet.nrow">facet.nrow</code></td>
<td>
<p>a numeric value indicating the <code>nrow</code> argument
in the <code>facet_wrap</code> function for controlling the
number of rows when specifying a split variable using
the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_facet.scales">facet.scales</code></td>
<td>
<p>a character string indicating the <code>scales</code> argument
in the <code>facet_wrap</code> function for controlling the
scales shared across facets, i.e., <code>"fixed"</code>,
<code>"free_x"</code>, <code>"free_y"</code>, or <code>"free"</code>
(default) when specifying a split variable using
the argument <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>file</code>
argument. Note that plots can only be saved when
<code>plot = "ci"</code> or <code>plot = "boot"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output
into either a text file with file extension <code>".txt"</code>
(e.g., <code>"Output.txt"</code>) or Excel file with file
extension <code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>).
If the file name does not contain any file extension,
an Excel file will be written.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be
appended to an existing text file with extension
<code>.txt</code> specified in <code>write</code>, if <code>FALSE</code>
existing text file will be overwritten.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown
on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence interval based on the chi-square distribution is computed by
specifying <code>method = "chisq"</code>, while the Bonett (2006) confidence interval
is requested by specifying <code>method = "bonett"</code>. By default, the Bonett
confidence interval interval is computed which performs well under moderate
departure from normality, while the confidence interval based on the chi-square
distribution is highly sensitive to minor violations of the normality assumption
and its performance does not improve with increasing sample size. Note that at
least four valid observations are needed to compute the Bonett confidence interval.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>...</code>, <code>data</code>, <code>group</code>, and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>data frame with bootstrap replicates of the variance or standard deviation when bootstrapping was requested</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results and the data frame used for plotting</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Bootstrap confidence intervals are computed using the R package <code>boot</code>
by Angelo Canty and Brain Ripley (2024).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Canty, A., &amp; Ripley, B. (2024). <em>boot: Bootstrap R (S-Plus) Functions</em>.
R package version 1.3-31.
</p>
<p>Bonett, D. G. (2006). Approximate confidence interval for standard deviation
of nonnormal distributions. <em>Computational Statistics and Data Analysis,
50</em>, 775-782. https://doi.org/10.1016/j.csda.2004.10.003
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>,
<code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.prop.diff">ci.prop.diff</a></code>,  <code><a href="#topic+ci.cor">ci.cor</a></code>,
<code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Confidence Interval (CI) for the Variance

# Example 1a: Two-Sided 95% CI
ci.var(mtcars)

# Example 1b: One-Sided 99% CI based on the chi-square distributio
ci.var(mtcars, alternative = "less", method = "chisq")

#----------------------------------------------------------------------------
# Confidence Interval (CI) for the Standard Deviation

# Example 2a: Two-Sided 95% CI
ci.sd(mtcars)

# Example 2b: One-Sided 99% CI based on the chi-square distributio
ci.sd(mtcars, alternative = "less", method = "chisq")

## Not run: 
#----------------------------------------------------------------------------
# Bootstrap Confidence Interval (CI)

# Example 3a: Bias-corrected (BC) percentile bootstrap CI
ci.var(mtcars, boot = "bc")

# Example 3b: Bias-corrected and accelerated (BCa) bootstrap CI,
# 5000 bootstrap replications, set seed of the pseudo-random number generator
ci.var(mtcars, boot = "bca", R = 5000, seed = 123)

#----------------------------------------------------------------------------
# Grouping and Split Variable

# Example 4a: Grouping variable
ci.var(mtcars, mpg, cyl, disp, group = "vs")

# Alternative specification without using the '...' argument
ci.var(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs)

# Example 4b: Split variable
ci.var(mtcars, mpg, cyl, disp, split = "am")

# Alternative specification without using the '...' argument
ci.var(mtcars[, c("mpg", "cyl", "disp")], split = mtcars$am)

# Example 4c: Grouping and split variable
ci.var(mtcars, mpg, cyl, disp, group = "vs", split = "am")

# Alternative specification without using the '...' argument
ci.var(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs, split = mtcars$am)

#----------------------------------------------------------------------------
# Write Output

# Example 5a: Text file
ci.var(mtcars, write = "CI_Var_Text.txt")

# Example 5b: Excel file
ci.var(mtcars, write = "CI_Var_Excel.xlsx")

#----------------------------------------------------------------------------
# Plot Confidence Intervals

# Example 6a: Two-Sided 95
ci.var(mtcars, plot = "ci")

# Example 6b: Grouping variable
ci.var(mtcars, disp, hp, group = "vs", plot = "ci")

# Example 6c: Split variable
ci.var(mtcars, disp, hp, split = "am", plot = "ci")

# Example 6d: Save plot as PDF file
ci.var(mtcars, disp, hp, plot = "ci", saveplot = "CI_Var.pdf",
       width = 9, height = 6)

# Example 6e: Save plot as PNG file
ci.var(mtcars, disp, hp, plot = "ci", saveplot = "CI_Var.png",
       width = 9, height = 6)

#----------------------------------------------------------------------------
# Plot Bootstrap Samples

# Example 7a: Two-Sided 95
ci.var(mtcars, disp, hp, boot = "bc", plot = "boot")

# Example 7b: Grouping variable
ci.var(mtcars, disp, hp, group = "vs", boot = "bc", plot = "boot")

# Example 7c: Split variable
ci.var(mtcars, disp, hp, split = "am", boot = "bc", plot = "boot")

# Example 7d: Save plot as PDF file
ci.var(mtcars, disp, hp, boot = "bc", plot = "boot",
       saveplot = "CI_Var_Boot.pdf", width = 12, height = 7)

# Example 7e: Save plot as PNG file
ci.var(mtcars, disp, hp, boot = "bc", plot = "boot",
       saveplot = "CI_Var_Boot.png", width = 12, height = 7)

## End(Not run)
</code></pre>

<hr>
<h2 id='clear'>Clear Console in RStudio</h2><span id='topic+clear'></span>

<h3>Description</h3>

<p>This function clears the console equivalent to <code>Ctrl + L</code> in RStudio on
Windows, Mac, UNIX, or Linux operating system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clear()
</code></pre>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>See Also</h3>

<p><code><a href="#topic+restart">restart</a></code>, <code><a href="#topic+setsource">setsource</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Clear console
clear()

## End(Not run)
</code></pre>

<hr>
<h2 id='cluster.scores'>Cluster Scores</h2><span id='topic+cluster.scores'></span>

<h3>Description</h3>

<p>This function computes group means by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster.scores(data, ..., cluster,
               fun = c("mean", "sum", "median", "var", "sd", "min", "max"),
               expand = TRUE, append = TRUE, name = ".a", as.na = NULL,
               check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cluster.scores_+3A_data">data</code></td>
<td>
<p>a numeric vector for centering a predictor variable, or a
data frame for centering more than one predictor variable.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code> e.g.,
<code>cluster.scores(dat, x1, x2, cluster = "cluster")</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also
be used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the variable name of
the cluster variable in <code>data</code>, or a vector representing
the nested grouping structure (i.e., group or cluster variable).</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_fun">fun</code></td>
<td>
<p>character string indicating the function used to compute group
scores, default: <code>"mean"</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_expand">expand</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vector of cluster scores is expanded
to match the input vector <code>data</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), cluster scores are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names
of the computed variables. By default, variables are named with the ending
<code>".a"</code> resulting in e.g. <code>"x1.a"</code> and <code>"x2.a"</code>. Variable names
can also be specified using a character vector matching the number
of variables specified in <code>data</code> (e.g.,
<code>name = c("cluster.x1", "cluster.x2")</code>).</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.
these values are converted to <code>NA</code> before conducting the
analysis. Note that <code>as.na()</code> function is only applied to
the argument <code>data</code>, but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector or data frame containing cluster scores with the same
length or same number of rows as <code>data</code> if <code>expand = TRUE</code> or with the
length or number of rows as <code>length(unique(cluster))</code> if <code>expand = FALSE</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel analysis:
Techniques and applications</em> (3rd. ed.). Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An
introduction to basic and advanced multilevel modeling</em> (2nd ed.). Sage
Publishers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.scores">item.scores</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>,
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Example 1: Compute cluster means for 'y1' and expand to match the input 'y1'
cluster.scores(Demo.twolevel, y1, cluster = "cluster", append = FALSE)

# Alternative specification without using the '...' argument
cluster.scores(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

# Example 2: Compute standard deviation for each cluster
# and expand to match the input x
cluster.scores(Demo.twolevel, cluster = "cluster", fun = "sd")

# Example 3: Compute cluster means without expanding the vector
cluster.scores(Demo.twolevel, cluster = "cluster", expand = FALSE)

# Example 4: Compute cluster means for 'y1' and 'y2' and append to 'Demo.twolevel'
cluster.scores(Demo.twolevel, y1, y2, cluster = "cluster")

# Alternative specification without using the '...' argument
cbind(Demo.twolevel,
      cluster.scores(Demo.twolevel[, c("y1", "y2")], cluster = Demo.twolevel$cluster))
</code></pre>

<hr>
<h2 id='coding'>Coding Categorical Variables</h2><span id='topic+coding'></span>

<h3>Description</h3>

<p>This function creates <code class="reqn">k - 1</code> variables for a categorical variable with
<code class="reqn">k</code> distinct levels. The coding system available in this function are
dummy coding, simple coding, unweighted effect coding, weighted effect coding,
repeated coding, forward Helmert coding, reverse Helmert coding, and orthogonal
polynomial coding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coding(data, ...,
       type = c("dummy", "simple", "effect", "weffect", "repeat",
                "fhelm", "rhelm", "poly"), base = NULL,
       name = c("dum.", "sim.", "eff.", "weff.", "rep.", "fhelm.", "rhelm.", "poly."),
       append = TRUE, as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coding_+3A_data">data</code></td>
<td>
<p>a numeric vector with integer values, character vector or factor.</p>
</td></tr>
<tr><td><code id="coding_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable name in <code>data</code>,
e.g., <code>coding(dat, x)</code>. Note that the function can only
deal with one categorical variable.</p>
</td></tr>
<tr><td><code id="coding_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of coding, i.e.,
<code>dummy</code> (default) for dummy coding, <code>simple</code> for
simple coding, <code>effect</code> for unweighted effect coding,
<code>weffect</code> for weighted effect coding, <code>repeat</code>
for repeated coding, <code>fhelm</code> for forward Helmert coding,
<code>rhelm</code> for reverse Helmert coding, and <code>poly</code> for
orthogonal polynomial coding (see 'Details').</p>
</td></tr>
<tr><td><code id="coding_+3A_base">base</code></td>
<td>
<p>a numeric value or character string indicating the baseline
group for dummy and simple coding and the omitted group in
effect coding. By default, the first group or factor level is
selected as baseline or omitted group.</p>
</td></tr>
<tr><td><code id="coding_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names
of the coded variables. By default, variables are named
<code>"dum."</code>, <code>"sim."</code>, <code>"eff."</code>, <code>"weff."</code>,
<code>"rep."</code>, <code>"fhelm."</code>, <code>"rhelm."</code>,or <code>"poly."</code>
depending on the <code>type</code> of coding with the category used
in the comparison (e.g., <code>"dum.2"</code> and <code>"dum.3"</code>).
Variable names can be specified using a character string (e.g.,
<code>name = "dummy_"</code> leads to <code>dummy_2</code> and <code>dummy_3</code>)
or a character vector matching the number of coded variables
(e.g. <code>name = c("x1_2", "x1_3")</code>)  which is the number of
unique categories minus one.</p>
</td></tr>
<tr><td><code id="coding_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), coded variables are appended
to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="coding_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="coding_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Dummy Coding</strong></dt><dd><p>Dummy or treatment coding compares the mean of
each level of the categorical variable to the mean of a baseline group. By
default, the first group or factor level is selected as baseline group. The
intercept in the regression model represents the mean of the baseline group.
For example, dummy coding based on a  categorical variable with four groups
<code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following comparisons:
<code>B vs A</code>, <code>C vs A</code>, and <code>D vs A</code> with <code>A</code> being the
baseline group.</p>
</dd>
<dt><strong>Simple Coding</strong></dt><dd><p>Simple coding compares each level of the
categorical variable to the mean of a baseline level. By default, the first
group or factor level is selected as baseline group. The intercept in the
regression model represents the unweighted grand mean, i.e., mean of group
means. For example, simple coding based on a  categorical variable with four
groups <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following comparisons:
<code>B vs A</code>, <code>C vs A</code>, and <code>D vs A</code> with <code>A</code> being the
baseline group.</p>
</dd>
<dt><strong>Unweighted Effect Coding</strong></dt><dd><p>Unweighted effect or sum coding
compares the mean of a given level to the unweighted grand mean, i.e., mean of
group means. By default, the first group or factor level is selected as
omitted group. For example, effect coding based on a  categorical variable
with four groups <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following
comparisons: <code>B vs (A, B, C, D)</code>, <code>C vs (A, B, C, D)</code>, and
<code>D vs (A, B, C, D)</code> with <code>A</code> being the omitted group.</p>
</dd>
<dt><strong>Weighted Effect Coding</strong></dt><dd><p>Weighted effect or sum coding compares
the mean of a given level to the weighed grand mean, i.e., sample mean. By
default, the first group or factor level is selected as omitted group. For
example, effect coding based on a categorical variable with four groups
<code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following comparisons:
<code>B vs (A, B, C, D)</code>, <code>C vs (A, B, C, D)</code>, and <code>D vs (A, B, C, D)</code>
with <code>A</code> being the omitted group.</p>
</dd>
<dt><strong>Repeated Coding</strong></dt><dd><p>Repeated or difference coding compares the
mean of each level of the categorical variable to the mean of the previous
adjacent level. For example, repeated coding based on a  categorical variable
with four groups <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following
comparisons: <code>B vs A</code>, <code>C vs B</code>, and <code>D vs C</code>.</p>
</dd>
<dt><strong>Foward Helmert Coding</strong></dt><dd><p>Forward Helmert coding compares the
mean of each level of the categorical variable to the unweighted mean of all
subsequent level(s) of the categorical variable. For example, forward Helmert
coding based on a  categorical variable with four groups <code>A</code>, <code>B</code>,
<code>C</code>, <code>D</code> makes following comparisons: <code>(B, C, D) vs A</code>,
<code>(C, D) vs B</code>, and <code>D vs C</code>.</p>
</dd>
<dt><strong>Reverse Helmert Coding</strong></dt><dd><p>Reverse Helmert coding compares the
mean of each level of the categorical variable to the unweighted mean of all
prior level(s) of the categorical variable. For example, reverse Helmert
coding based on a  categorical variable with four groups <code>A</code>, <code>B</code>,
<code>C</code>, <code>D</code> makes following comparisons: <code>B vs A</code>, <code>C vs (A, B)</code>,
and <code>D vs (A, B, C)</code>.</p>
</dd>
<dt><strong>Orthogonal Polynomial Coding</strong></dt><dd><p>Orthogonal polynomial coding is
a form of trend analysis based on polynomials of order <code class="reqn">k - 1</code>, where
<code class="reqn">k</code> is the number of levels of the categorical variable. This coding
scheme assumes an ordered-categorical variable with equally spaced levels.
For example, orthogonal polynomial coding based on a categorical variable with
four groups <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> investigates a linear,
quadratic, and cubic trends in the categorical variable.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a data frame with <code class="reqn">k - 1</code> coded variables or a data frame with the
same length or same number of rows as <code>...</code> containing the coded variables.
</p>


<h3>Note</h3>

<p>This function uses the <code>contr.treatment</code> function from the <span class="pkg">stats</span>
package for dummy coding and simple coding, a modified copy of the
<code>contr.sum</code> function from the <span class="pkg">stats</span> package for effect coding,
a modified copy of the <code>contr.wec</code> function from the <span class="pkg">wec</span> package
for weighted effect coding, a modified copy of the <code>contr.sdif</code>
function from the <span class="pkg">MASS</span> package for repeated coding, a modified copy
of the <code>code_helmert_forward</code> function from the <span class="pkg">codingMatrices</span>
for forward Helmert coding, a modified copy of the <code>contr_code_helmert</code>
function from the <span class="pkg">faux</span> package for reverse Helmert coding, and the
<code>contr.poly</code> function from the <span class="pkg">stats</span> package for orthogonal
polynomial coding.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rec">rec</a></code>, <code><a href="#topic+item.reverse">item.reverse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Dummy coding for 'gear', baseline group = 3
coding(mtcars, gear)

# Alternative specification without using the '...' argument
coding(mtcars$gear)

# Example 2: Dummy coding for 'gear', baseline group = 4
coding(mtcars, gear, base = 4)

# Example 3: Effect coding for 'gear', omitted group = 3
coding(mtcars, gear, type = "effect")

# Example 3: Effect coding for 'gear', omitted group = 4
coding(mtcars, gear, type = "effect", base = 4)

# Example 4a: Dummy-coded variable names with prefix "gear3."
coding(mtcars, gear, name = "gear3.")

# Example 4b: Dummy-coded variables named "gear_4vs3" and "gear_5vs3"
coding(mtcars, gear, name = c("gear_4vs3", "gear_5vs3"))
</code></pre>

<hr>
<h2 id='cohens.d'>Cohen's d</h2><span id='topic+cohens.d'></span><span id='topic+cohens.d.default'></span><span id='topic+cohens.d.formula'></span>

<h3>Description</h3>

<p>This function computes Cohen's d for one-sample, two-sample (i.e., between-subject design),
and paired-sample designs (i.e., within-subject design) for one or more variables, optionally
by a grouping and/or split variable. In a two-sample design, the function computes the
standardized mean difference by dividing the difference between  means of the two groups
of observations by the weighted pooled standard deviation (i.e., Cohen's <code class="reqn">d_s</code>
according to Lakens, 2013) by default. In a paired-sample design, the function computes the
standardized mean difference by dividing the mean of the difference scores by the standard
deviation of the difference scores (i.e., Cohen's <code class="reqn">d_z</code> according to Lakens, 2013) by
default. Note that by default Cohen's d is computed without applying the correction factor
for removing the small sample bias (i.e., Hedges' g).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cohens.d(x, ...)

## Default S3 method:
cohens.d(x, y = NULL, mu = 0, paired = FALSE, weighted = TRUE, cor = TRUE,
         ref = NULL, correct = FALSE, alternative = c("two.sided", "less", "greater"),
         conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
         digits = 2, as.na = NULL, write = NULL, append = TRUE,
         check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
cohens.d(formula, data, weighted = TRUE, cor = TRUE, ref = NULL,
         correct = FALSE, alternative = c("two.sided", "less", "greater"),
         conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
         na.omit = FALSE, digits = 2, as.na = NULL, write = NULL, append = TRUE,
         check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cohens.d_+3A_x">x</code></td>
<td>
<p>a numeric vector or data frame.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_y">y</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_mu">mu</code></td>
<td>
<p>a numeric value indicating the reference mean.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, Cohen's d for a paired-sample design is computed.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the weighted pooled standard deviation is used
to compute the standardized mean difference between two groups of a two-sample
design (i.e., <code>paired = FALSE</code>), while standard deviation of the difference
scores is used to compute the standardized mean difference in a paired-sample
design (i.e., <code>paired = TRUE</code>).</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_cor">cor</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), <code>paired = TRUE</code>, and <code>weighted = FALSE</code>,
Cohen's d for a paired-sample design while controlling for the correlation between
the two sets of measurement is computed. Note that this argument is only used in
a paired-sample design (i.e., <code>paired = TRUE</code>) when specifying <code>weighted = FALSE</code>.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_ref">ref</code></td>
<td>
<p>character string <code>"x"</code> or <code>"y"</code> for specifying the reference reference
group when using the default <code>cohens.d()</code> function or a numeric value or
character string indicating the reference group in a two-sample design when using
the formula <code>cohens.d()</code> function. The standard deviation of the reference variable
or reference group is used to standardized the mean difference.
Note that this argument is only used in a two-sample design (i.e., <code>paired = FALSE</code>).</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor to remove positive bias in small samples is
used.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of
<code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level of the interval.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_group">group</code></td>
<td>
<p>a numeric vector, character vector or factor as grouping variable.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_split">split</code></td>
<td>
<p>a numeric vector, character vector or factor as split variable.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used for
displaying results.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting the analysis.
Note that <code>as.na()</code> function is only applied to <code>y</code> but not to <code>group</code>
in a two-sample design, while <code>as.na()</code> function is applied to <code>pre</code>
and <code>post</code> in a paired-sample design.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> for one outcome variable or
<code>cbind(y1, y2, y3) ~ group</code> for more than one outcome variable where <code>y</code>
is a numeric variable giving the data values and <code>group</code> a numeric variable,
character variable or factor with two values or factor levels giving the
corresponding groups.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before conducting the analysis
(i.e., listwise deletion) when specifying more than one outcome variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cohen (1988, p.67) proposed to compute the standardized mean difference in a two-sample design
by dividing the mean difference by the unweighted pooled standard deviation (i.e.,
<code>weighted = FALSE</code>).
</p>
<p>Glass et al. (1981, p. 29) suggested to use the standard deviation of the control group
(e.g., <code>ref = 0</code> if the control group is coded with 0) to compute the standardized
mean difference in a two-sample design (i.e., Glass's <code class="reqn">\Delta</code>) since the standard deviation of the control group
is unaffected by the treatment and will therefore more closely reflect the population
standard deviation.
</p>
<p>Hedges (1981, p. 110) recommended to weight each group's standard deviation by its sample
size resulting in a weighted and pooled standard deviation (i.e., <code>weighted = TRUE</code>,
default). According to Hedges and Olkin (1985, p. 81), the standardized mean difference
based on the weighted and pooled standard deviation has a positive small sample bias,
i.e., standardized mean difference is overestimated in small samples (i.e., sample size
less than 20 or less than 10 in each group). However, a correction factor can be applied
to remove the small sample bias (i.e., <code>correct = TRUE</code>). Note that the function uses
a gamma function for computing the correction factor, while a approximation method is
used if computation based on the gamma function fails.
</p>
<p>Note that the terminology is inconsistent because the standardized mean difference based
on the weighted and pooled standard deviation is usually called Cohen's d, but sometimes
called Hedges' g. Oftentimes, Cohen's d is called Hedges' d as soon as the small sample
correction factor is applied. Cumming and Calin-Jageman (2017, p.171) recommended to avoid
the term Hedges' g , but to report which standard deviation was used to standardized the
mean difference (e.g., unweighted/weighted pooled standard deviation, or the standard
deviation of the control group) and whether a small sample correction factor was applied.
</p>
<p>As for the terminology according to Lakens (2013), in a two-sample design (i.e.,
<code>paired = FALSE</code>) Cohen's <code class="reqn">d_s</code> is computed when using <code>weighted = TRUE</code> (default)
and Hedges's <code class="reqn">g_s</code> is computed when using <code>correct = TRUE</code> in addition. In a
paired-sample design (i.e., <code>paired = TRUE</code>), Cohen's <code class="reqn">d_z</code> is computed when using
<code>weighted = TRUE, default</code>, while Cohen's <code class="reqn">d_{rm}</code> is computed when using
<code>weighted = FALSE</code> and <code>cor = TRUE, default</code> and Cohen's <code class="reqn">d_{av}</code> is computed when
using <code>weighted = FALSE</code> and <code>cor = FALSE</code>. Corresponding Hedges' <code class="reqn">g_z</code>, <code class="reqn">g_{rm}</code>,
and <code class="reqn">g_{av}</code> are computed when using <code>correct = TRUE</code> in addition.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>type of sample, i.e., one-, two-, or, paired-sample</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.).
Academic Press.
</p>
<p>Cumming, G., &amp; Calin-Jageman, R. (2017). <em>Introduction to the new statistics: Estimation, open science,
&amp; beyond</em>. Routledge.
</p>
<p>Glass. G. V., McGaw, B., &amp; Smith, M. L. (1981). <em>Meta-analysis in social research</em>. Sage Publication.
</p>
<p>Goulet-Pelletier, J.-C., &amp; Cousineau, D. (2018) A review of effect sizes and their confidence intervals,
Part I: The Cohen's d family. <em>The Quantitative Methods for Psychology, 14</em>, 242-265.
https://doi.org/10.20982/tqmp.14.4.p242
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's estimator of effect size and related estimators.
<em>Journal of Educational Statistics, 6</em>(3), 106-128.
</p>
<p>Hedges, L. V. &amp; Olkin, I. (1985). <em>Statistical methods for meta-analysis</em>. Academic Press.
</p>
<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science:
A practical primer for t-tests and ANOVAs. <em>Frontiers in Psychology, 4</em>, 1-12.
https://doi.org/10.3389/fpsyg.2013.00863
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+effsize">effsize</a></code>, <code><a href="#topic+cor.matrix">cor.matrix</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# One-sample design

# Example 1a: Cohen's d.z with two-sided 95% CI
# population mean = 3
cohens.d(mtcars$mpg, mu = 20)

# Example 1b: Cohen's d.z (aka Hedges' g.z) with two-sided 95% CI
# population mean = 3, with small sample correction factor
cohens.d(mtcars$mpg, mu = 20, correct = TRUE)

# Example 1c: Cohen's d.z with two-sided 95% CI
# population mean = 3, by 'vs' separately
cohens.d(mtcars$mpg, mu = 20, group = mtcars$vs)

# Example 1d: Cohen's d.z with two-sided 95% CI
# population mean = 20, split analysis by 'vs'
cohens.d(mtcars$mpg, mu = 20, split = mtcars$vs)

# Example 1e: Cohen's d.z with two-sided 95% CI
# population mean = 3, by 'vs' separately, split by 'am'
cohens.d(mtcars$mpg, mu = 20, group = mtcars$vs, split = mtcars$am)

#----------------------------------------------------------------------------
# Two-sample design

# Example 2a: Cohen's d.s with two-sided 95% CI
# weighted pooled SD
cohens.d(mpg ~ vs, data = mtcars)

# Example 2b: Cohen's d.s with two-sided 99% CI
# weighted pooled SD
cohens.d(mpg ~ vs, data = mtcars, conf.level = 0.99)

# Example 2c: Cohen's d.s with one-sided 99% CI
# weighted pooled SD
cohens.d(mpg ~ vs, data = mtcars, alternative = "greater", conf.level = 0.99)

# Example 2d: Cohen's d.s for more than one variable with two-sided 95% CI
# weighted pooled SD
cohens.d(cbind(mpg, disp, hp) ~ vs, data = mtcars)

# Example 2e: Cohen's d with two-sided 95% CI
# unweighted SD
cohens.d(mpg ~ vs, data = mtcars, weighted = FALSE)

# Example 2f: Cohen's d.s (aka Hedges' g.s) with two-sided 95% CI
# weighted pooled SD, with small sample correction factor
cohens.d(mpg ~ vs, data = mtcars, correct = TRUE)

# Example 2g: Cohen's d (aka Hedges' g) with two-sided 95% CI
# Unweighted SD, with small sample correction factor
cohens.d(mpg ~ vs, data = mtcars, weighted = FALSE, correct = TRUE)

# Example 2h: Cohen's d (aka Glass's delta) with two-sided 95% CI
# SD of reference group 1
cohens.d(mpg ~ vs, data = mtcars, ref = 0)

# Example 2i: Cohen's d.s with two-sided 95% CI
# weighted pooled SD, by 'am' separately
cohens.d(mpg ~ vs, data = mtcars, group = mtcars$am)

# Example 2j: Cohen's d.s with two-sided 95% CI
# weighted pooled SD, split analysis by 'am'
cohens.d(mpg ~ vs, data = mtcars, split = mtcars$am)

#----------------------------------------------------------------------------
# Paired-sample design

# Example 3a: Cohen's d.z with two-sided 95% CI
# SD of the difference scores
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE)

# Example 3b: Cohen's d.z with one-sided 99% CI
# SD of the difference scores
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE, alternative = "greater",
         conf.level = 0.99)

# Example 3c: Cohen's d.rm with two-sided 95% CI
# controlling for the correlation between measures
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE, weighted = FALSE)

# Example 3d: Cohen's d.av with two-sided 95% CI
# without controlling for the correlation between measures
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE, weighted = FALSE, cor = FALSE)

# Example 3e: Cohen's d.z (aka Hedges' g.z) with two-sided 95% CI
# SD of the differnece scores
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE, correct = TRUE)

# Example 3f: Cohen's d.rm (aka Hedges' g.rm) with two-sided 95% CI
# controlling for the correlation between measures
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE, weighted = FALSE, correct = TRUE)

# Example 3g: Cohen's d.av (aka Hedges' g.av) with two-sided 95% CI
# without controlling for the correlation between measures
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE, weighted = FALSE, cor = FALSE,
         correct = TRUE)

# Example 3h: Cohen's d.z with two-sided 95% CI
# SD of the difference scores, by 'vs' separately
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE, group = mtcars$vs)

# Example 3i:  Cohen's d.z with two-sided 95% CI
# SD of the difference scores, split analysis by 'vs'
cohens.d(mtcars$drat, mtcars$wt, paired = TRUE, split = mtcars$vs)
</code></pre>

<hr>
<h2 id='cor.matrix'>Correlation Matrix</h2><span id='topic+cor.matrix'></span>

<h3>Description</h3>

<p>This function computes a correlation matrix based on Pearson product-moment
correlation coefficient, Spearman's rank-order correlation coefficient,
Kendall's Tau-b correlation coefficient, Kendall-Stuart's Tau-c correlation
coefficient, tetrachoric correlation coefficient, or polychoric correlation
coefficient and computes significance values (<em>p</em>-values) for testing the
hypothesis H0: <code class="reqn">\rho</code> = 0 for all pairs of variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.matrix(data, ...,
           method = c("pearson", "spearman", "kendall-b", "kendall-c", "tetra", "poly"),
           na.omit = FALSE, group = NULL, sig = FALSE, alpha = 0.05,
           print = c("all", "cor", "n", "stat", "df", "p"),
           tri = c("both", "lower", "upper"),
           p.adj = c("none", "bonferroni", "holm", "hochberg", "hommel",
                     "BH", "BY", "fdr"), continuity = TRUE,
           digits = 2, p.digits = 3, as.na = NULL,
           write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cor.matrix_+3A_data">data</code></td>
<td>
<p>a data frame with numeric variables, i.e., factors and character
variables are excluded from <code>data</code> before conducting the
analysis.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>cor.matrix(dat, x1, x2, x3)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_method">method</code></td>
<td>
<p>a character vector indicating which correlation coefficient
is to be computed, i.e. <code>"pearson"</code> for Pearson product-moment correlation
coefficient (default), <code>"spearman"</code> for Spearman's rank-order correlation
coefficient, <code>"kendall-b"</code> for Kendall's Tau-b correlation coefficient,
<code>"kendall-c"</code> for Kendall-Stuart's Tau-c correlation coefficient,
<code>"tetra"</code> for tetrachoric correlation coefficient, and <code>"poly"</code> for
polychoric correlation coefficient.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion); if <code>FALSE</code>
(default), pairwise deletion is used.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name of
the grouping variable in <code>data</code>, or a
vector representing the grouping variable. Note that the
grouping variable is limited to two groups.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_sig">sig</code></td>
<td>
<p>logical: if <code>TRUE</code>, statistically significant correlation
coefficients are shown in boldface on the console. Note that
this function does not provide statistical significance
testing for tetrachoric or polychoric correlation coefficients.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the significance
level at which correlation coefficients are printed boldface
when <code>sig = TRUE</code>.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results
to show on the console, i.e. <code>"all"</code> for all results,
<code>"cor"</code> for correlation coefficients, <code>"n"</code> for the
sample sizes, <code>"stat"</code> for the test statistic, <code>"df"</code>
for the degrees of freedom, and <code>"p"</code> for <em>p</em>-values.
Note that the function does not provide <em>p</em>-values for
tetrachoric or polychoric correlation coefficients.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_tri">tri</code></td>
<td>
<p>a character string indicating which triangular of the matrix
to show on the console, i.e., <code>both</code> for upper and lower
triangular, <code>lower</code> (default) for the lower triangular,
and <code>upper</code> for the upper triangular.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_p.adj">p.adj</code></td>
<td>
<p>a character string indicating an adjustment method for multiple
testing based on <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>, i.e., <code>none</code> ,
<code>bonferroni</code>, <code>holm</code> (default), <code>hochberg</code>,
<code>hommel</code>, <code>BH</code>, <code>BY</code>, or <code>fdr</code>.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_continuity">continuity</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), continuity correction is
used for testing Spearman's rank-order correlation coefficient
and Kendall's Tau-b correlation.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying correlation coefficients.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that unlike the <code><a href="stats.html#topic+cor.test">cor.test</a></code> function, this
function does not compute an exact <em>p</em>-value for Spearman's rank-order
correlation coefficient or Kendall's Tau-b correlation coefficient, but uses
the asymptotic <em>t</em> approximation.
</p>
<p>Statistically significant correlation coefficients can be shown in boldface on
the console when specifying <code>sig = TRUE</code>. However, this option is not supported
when using R Markdown, i.e., the argument <code>sig</code> will switch to <code>FALSE</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>cor</code> for the
correlation matrix, <code>n</code> for a matrix with the sample
sizes, <code>stat</code> for a matrix with the test statistics,
<code>df</code> for a matrix with the degrees of freedom, and
<code>p</code>-value for the matrix with the significance values
(<em>p</em>-values)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses the <code>polychoric()</code> function in the <span class="pkg">psych</span>
package by William Revelle to estimate tetrachoric and polychoric correlation
coefficients.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Revelle, W. (2018) <em>psych: Procedures for personality and psychological
research</em>. Northwestern University, Evanston, Illinois, USA,
https://CRAN.R-project.org/package=psych Version = 1.8.12.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+effsize">effsize</a></code>,
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code>, <code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+size.cor">size.cor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Pearson product-moment correlation coefficient between 'Ozone' and 'Solar.R
cor.matrix(airquality, Ozone, Solar.R)

# Alternative specification without using the '...' argument
cor.matrix(airquality[, c("Ozone", "Solar.R")])

# Example 2: Pearson product-moment correlation matrix using pairwise deletion
cor.matrix(airquality, Ozone:Wind)

# Alternative specification without using the '...' argument
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")])

# Example 3: Spearman's rank-order correlation matrix
cor.matrix(airquality, Ozone, Solar.R, Wind, method = "spearman")

# Example 4: Pearson product-moment correlation matrix
# highlight statistically significant result at alpha = 0.05
cor.matrix(airquality, Ozone, Solar.R, Wind, sig = TRUE)

# Example 5: Pearson product-moment correlation matrix
# highlight statistically significant result at alpha = 0.05
cor.matrix(airquality, Ozone, Solar.R, Wind, sig = TRUE, alpha = 0.10)

# Example 6: Pearson product-moment correlation matrix
# print sample size and significance values
cor.matrix(airquality, Ozone, Solar.R, Wind, print = "all")

# Example 7: Pearson product-moment correlation matrix using listwise deletion,
# print sample size and significance values
cor.matrix(airquality, Ozone, Solar.R, Wind, na.omit = TRUE, print = "all")

# Example 8: Pearson product-moment correlation matrix
# print sample size and significance values with Bonferroni correction
cor.matrix(airquality, Ozone, Solar.R, Wind, na.omit = TRUE, print = "all",
           p.adj = "bonferroni")

# Example 9: Pearson product-moment correlation matrix for 'mpg', 'cyl', and 'disp'
# results for group "0" and "1" separately
cor.matrix(mtcars, mpg:disp, group = "vs")

# Alternative specification without using the '...' argument
cor.matrix(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs)

## Not run: 
# Example 10a: Write Results into a text file
cor.matrix(airquality, Ozone, Solar.R, Wind, print = "all", write = "Correlation.txt")

# Example 10b: Write Results into a Excel file
cor.matrix(airquality, Ozone, Solar.R, Wind, print = "all", write = "Correlation.xlsx")
## End(Not run)</code></pre>

<hr>
<h2 id='crosstab'>Cross Tabulation</h2><span id='topic+crosstab'></span>

<h3>Description</h3>

<p>This function creates a two-way and three-way cross tabulation with absolute
frequencies and row-wise, column-wise and total percentages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crosstab(data, ..., print = c("no", "all", "row", "col", "total"),
         freq = TRUE, split = FALSE, na.omit = TRUE, digits = 2, as.na = NULL,
         write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crosstab_+3A_data">data</code></td>
<td>
<p>a data frame with two or three columns.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>, e.g.,
<code>crosstab(dat, x1, x2, x3)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
percentage(s) to be printed on the console, i.e., no percentages
(<code>"no"</code>) (default), all percentages (<code>"all"</code>),
row-wise percentages (<code>"row"</code>), column-wise percentages
(<code>"col"</code>), and total percentages (<code>"total"</code>).</p>
</td></tr>
<tr><td><code id="crosstab_+3A_freq">freq</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), absolute frequencies will be included
in the cross tabulation.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is split in absolute
frequencies and percentage(s).</p>
</td></tr>
<tr><td><code id="crosstab_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), incomplete cases are removed before
conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="crosstab_+3A_digits">digits</code></td>
<td>
<p>an integer indicating the number of decimal places digits
to be used for displaying percentages.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is printed on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>crosstab</code> for the
cross tabulation, <code>freq.a</code> for the absolute frequencies,
<code>perc.r</code> for the row-wise percentages, <code>perc.c</code>
for the column-wise percentages, <code>perc.t</code> for the total
percentages</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>
<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+freq">freq</a></code>, <code><a href="#topic+descript">descript</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>.
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Two-Dimensional Table

# Example 1: Cross Tabulation for 'vs' and 'am'
crosstab(mtcars, vs, am)

# Alternative specification without using the '...' argument
crosstab(mtcars[, c("vs", "am")])

# Example 2: Cross Tabulation, print all percentages
crosstab(mtcars, vs, am, print = "all")

# Example 3: Cross Tabulation, print row-wise percentages
crosstab(mtcars, vs, am, print = "row")

# Example 4: Cross Tabulation, print col-wise percentages
crosstab(mtcars, vs, am, print = "col")

# Example 5: Cross Tabulation, print total percentages
crosstab(mtcars, vs, am, print = "total")

# Example 6: Cross Tabulation, print all percentages, split output table
crosstab(mtcars, vs, am, print = "all", split = TRUE)

#----------------------------------------------------------------------------
# Three-Dimensional Table

# Example 7: Cross Tabulation for 'vs', 'am', ane 'gear'
crosstab(mtcars, vs:gear)

# Alternative specification without using the '...' argument
crosstab(mtcars[, c("vs", "am", "gear")])

# Example 8: Cross Tabulation, print all percentages
crosstab(mtcars, vs:gear, print = "all")

# Example 9: Cross Tabulation, print all percentages, split output table
crosstab(mtcars, vs:gear, print = "all", split = TRUE)

## Not run: 
# Example 10a: Write Results into a text file
crosstab(mtcars, vs:gear, print = "all", write = "Crosstab.txt")

# Example 10b: Write Results into a Excel file
crosstab(mtcars, vs:gear, print = "all", write = "Crosstab.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='descript'>Descriptive Statistics</h2><span id='topic+descript'></span>

<h3>Description</h3>

<p>This function computes summary statistics for one or more than one variable, optionally
by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>descript(data, ...,
         print = c("all", "default", "n", "nNA", "pNA", "m", "se.m", "var", "sd",
                   "min", "p25", "med", "p75", "max", "range", "iqr", "skew", "kurt"),
         group = NULL, split = NULL, sample = FALSE, sort.var = FALSE,
         na.omit = FALSE, digits = 2, as.na = NULL, write = NULL, append = TRUE,
         check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="descript_+3A_data">data</code></td>
<td>
<p>a numeric vector or data frame with numeric variables,
i.e., factors and character variables are excluded from
<code>data</code> before conducting the analysis.</p>
</td></tr>
<tr><td><code id="descript_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>descript(dat, x1, x2, x3)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="descript_+3A_print">print</code></td>
<td>
<p>a character vector indicating which statistical measures to be
printed on the console, i.e. <code>n</code> (number of observations),
<code>nNA</code> (number of missing values), <code>pNA</code> (percentage of
missing values), <code>m</code> (arithmetic mean), <code>se.m</code> (standard
error of the arithmetic mean), <code>var</code> (variance), <code>sd</code>
(standard deviation), <code>med</code> (median),<code>min</code> (minimum),
<code>p25</code> (25th percentile, first quartile), <code>p75</code> (75th
percentile, third quartile), <code>max</code> (maximum),  <code>range</code>
(range), <code>iqr</code> (interquartile range), <code>skew</code> (skewness),
and <code>kurt</code> (excess kurtosis). The default setting is
<code>print = ("n", "nNA", "pNA", "m", "sd", "min", "max", "skew", "kurt")</code>.</p>
</td></tr>
<tr><td><code id="descript_+3A_group">group</code></td>
<td>
<p>a numeric vector, character vector or factor as grouping variable.
Alternatively, a character string indicating the variable name
of the grouping variable in <code>data</code> can be specified.</p>
</td></tr>
<tr><td><code id="descript_+3A_split">split</code></td>
<td>
<p>a numeric vector, character vector or factor as split variable.
Alternatively, a character string indicating the variable name
of the split variable in <code>data</code> can be specified.</p>
</td></tr>
<tr><td><code id="descript_+3A_sample">sample</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the univariate sample skewness
or kurtosis is computed, while the population skewness or kurtosis
is computed when <code>sample = FALSE</code>.</p>
</td></tr>
<tr><td><code id="descript_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when
specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="descript_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="descript_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used.</p>
</td></tr>
<tr><td><code id="descript_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied
to <code>data</code>, but not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="descript_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="descript_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="descript_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="descript_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>data</code>, <code>group</code>, and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>,
<code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.prop.diff">ci.prop.diff</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>,
<code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+freq">freq</a></code>, <code><a href="#topic+crosstab">crosstab</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Descriptive statistics

# Example 1a: Descriptive statistics for 'mpg', 'cyl', and 'hp'
descript(mtcars, mpg, cyl, hp)

# Alternative specification without using the '...' argument
descript(mtcars[, c("mpg", "cyl", "hp")])

# Example 1b: Print all available statistical measures
descript(mtcars, mpg, cyl, hp, print = "all")

# Example 1c: Print default statistical measures plus median
descript(mtcars, mpg, cyl, hp, print = c("default", "med"))

#----------------------------------------------------------------------------
# Grouping and Split Variable

# Example 2a: Grouping variable
descript(mtcars, mpg, cyl, hp, group = "vs")

# Alternative specification without using the '...' argument
descript(mtcars[, c("mpg", "cyl", "hp")], group = mtcars$vs)

# Example 2b: Split variable
descript(mtcars, mpg, cyl, hp, split = "am")

# Alternative specification without using the '...' argument
descript(mtcars[, c("mpg", "cyl", "hp")], split = mtcars$am)

# Example 2c: Grouping and split variable
descript(mtcars, mpg, cyl, hp, group = "vs", split = "am")

# Alternative specification without using the '...' argument
descript(mtcars[, c("mpg", "cyl", "hp")], group = mtcars$vs, split = mtcars$am)

#----------------------------------------------------------------------------
# Write Output

## Not run: 
# Example 3a: Text file
descript(mtcars, write = "Descript_Text.txt")

# Example 3b: Excel file
descript(mtcars, write = "Descript_Excel.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='df.check'>Data Check</h2><span id='topic+df.check'></span>

<h3>Description</h3>

<p>This function is a wrapper around the functions <code>dim</code> for the number of
rows and columns, <code>names</code> for the variable names, <code>df.head</code> for the
first rows, and <code>df.tail</code> for the last rows of a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.check(data, print = c("dim", "names", "head", "tail"), n = 4,
         digits = 3, width = 20, row.names = TRUE, row.names.col = "gray2",
         message = TRUE, message.col = "b.blue", check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.check_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.check_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e., <code>"dim"</code>, for
the number of rows and number of columns, <code>"names"</code>
for the variable names, <code>"head"</code> for the first rows
of the data frame, and <code>"tail"</code> for the last rows
of the data frame.</p>
</td></tr>
<tr><td><code id="df.check_+3A_n">n</code></td>
<td>
<p>a numeric value indicating the number of rows to be
printed on the console.</p>
</td></tr>
<tr><td><code id="df.check_+3A_digits">digits</code></td>
<td>
<p>a numeric value indicating the maximum number of decimal
places to be used.</p>
</td></tr>
<tr><td><code id="df.check_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the maximum width of the
character strings in the vector.</p>
</td></tr>
<tr><td><code id="df.check_+3A_row.names">row.names</code></td>
<td>
<p>logical: if <code>TRUE</code>, row names of the data frame are
printed on the console.</p>
</td></tr>
<tr><td><code id="df.check_+3A_row.names.col">row.names.col</code></td>
<td>
<p>a character string indicating the text color for the row
names, see <code>color</code> argument of the <code><a href="#topic+chr.color">chr.color</a></code>
function.</p>
</td></tr>
<tr><td><code id="df.check_+3A_message">message</code></td>
<td>
<p>logical: if <code>TRUE</code>, number of remaining rows and
columns are printed on the console.</p>
</td></tr>
<tr><td><code id="df.check_+3A_message.col">message.col</code></td>
<td>
<p>a character string indicating the text color for the
number of remaining rows and columns printed on the
console, see <code>color</code> argument of the
<code><a href="#topic+chr.color">chr.color</a></code> function.</p>
</td></tr>
<tr><td><code id="df.check_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="df.check_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this function only provides a basic data check suitable for checking
a data frame after importing data into R and is not designed to offer a thorough
data check (e.g., identifying duplicate IDs or inconsistencies in the data).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.head">df.head</a></code>, <code><a href="#topic+df.head">df.head</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Check data frame mtcars
df.check(mtcars)
</code></pre>

<hr>
<h2 id='df.duplicated'>Extract Duplicated or Unique Rows</h2><span id='topic+df.duplicated'></span><span id='topic+df.unique'></span>

<h3>Description</h3>

<p>The function <code>df.duplicated</code> extracts duplicated rows and the function
<code>df.unique</code> extracts unique rows from a matrix or data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.duplicated(data, ..., first = TRUE, keep.all = TRUE, from.last = FALSE,
              keep.row.names = TRUE, check = TRUE)

df.unique(data, ..., keep.all = TRUE, from.last = FALSE,
          keep.row.names = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.duplicated_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>
used to determine duplicated or unique rows.e.g.,
<code>df.duplicated(x1, x2, data = dat)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select
variables, see Details in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_first">first</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the <code>df.duplicated()</code>
function will return duplicated rows including the first of identical
rows.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_keep.all">keep.all</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the function will return all
variables in <code>data</code> after extracting duplicated or unique rows based
on the variables specified in the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_from.last">from.last</code></td>
<td>
<p>logical: if <code>TRUE</code>, duplication will be considered
from the reversed side, i.e., the last of identical rows
would correspond to <code>duplicated = FALSE</code>.
Note that this argument is only used when <code>first = FALSE</code>.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_keep.row.names">keep.row.names</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the row names from <code>data</code> are kept,
otherwise they are set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>df.unique(x)</code> is equivalent to <code>unique(x)</code>. That is, the
main difference between the <code>df.unique()</code> and the <code>unique()</code> function is
that the <code>df.unique()</code> function provides the <code>...</code> argument to
specify a variable or multiple variables which are used to determine unique rows.
</p>


<h3>Value</h3>

<p>Returns duplicated or unique rows of the data frame in <code>...</code> or <code>data</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(x1 = c(1, 1, 2, 1, 4), x2 = c(1, 1, 2, 1, 6),
                  x3 = c(2, 2, 3, 2, 6), x4 = c(1, 1, 2, 2, 4),
                  x5 = c(1, 1, 4, 4, 3))

#----------------------------------------------------------------------------
# df.duplicated() function

# Example 1: Extract duplicated rows based on all variables
df.duplicated(dat)

# Example 2: Extract duplicated rows based on 'x4'
df.duplicated(dat, x4)

# Example 3: Extract duplicated rows based on 'x2' and 'x3'
df.duplicated(dat, x2, x3)

# Example 4: Extract duplicated rows based on all variables
# exclude first of identical rows
df.duplicated(dat, first = FALSE)

# Example 5: Extract duplicated rows based on 'x2' and 'x3'
# do not return all variables
df.duplicated(dat, x2, x3, keep.all = FALSE)

# Example 6: Extract duplicated rows based on 'x4'
# consider duplication from the reversed side
df.duplicated(dat, x4, first = FALSE, from.last = TRUE)

# Example 7: Extract duplicated rows based on 'x2' and 'x3'
# set row names to NULL
df.duplicated(dat, x2, x3, keep.row.names = FALSE)

#----------------------------------------------------------------------------
# df.unique() function

# Example 8: Extract unique rows based on all variables
df.unique(dat)

# Example 9: Extract unique rows based on 'x4'
df.unique(dat, x4)

# Example 10: Extract unique rows based on 'x1', 'x2', and 'x3'
df.unique(dat, x1, x2, x3)

# Example 11: Extract unique rows based on 'x2' and 'x3'
# do not return all variables
df.unique(dat, x2, x3, keep.all = FALSE)

# Example 12: Extract unique rows based on 'x4'
# consider duplication from the reversed side
df.unique(dat, x4, from.last = TRUE)

# Example 13: Extract unique rows based on 'x2' and 'x3'
# set row names to NULL
df.unique(dat, x2, x3, keep.row.names = FALSE)
</code></pre>

<hr>
<h2 id='df.head'>Print the First and Last Rows of a Data Frame</h2><span id='topic+df.head'></span><span id='topic+df.tail'></span>

<h3>Description</h3>

<p>The function <code>df.head</code> prints the first rows of a data frame and the
function <code>df.tail</code> prints the last rows of a data frame and prints as
many columns as fit on the console supplemented by a summary of the remaining
rows and columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.head(data, n = 6, digits = 3, width = 20, factor.labels = TRUE,
        row.names = TRUE, row.names.col = "gray2", message = TRUE,
        message.col = "b.blue", check = TRUE, output = TRUE)

df.tail(data, n = 6, digits = 3, width = 20, factor.labels = TRUE,
        row.names = TRUE, row.names.col = "gray2", message = TRUE,
        message.col = "b.blue", check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.head_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.head_+3A_n">n</code></td>
<td>
<p>a numeric value indicating the number of rows to be
printed on the console.</p>
</td></tr>
<tr><td><code id="df.head_+3A_digits">digits</code></td>
<td>
<p>a numeric value indicating the maximum number of decimal
places to be used.</p>
</td></tr>
<tr><td><code id="df.head_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the maximum width of the
character strings in the vector.</p>
</td></tr>
<tr><td><code id="df.head_+3A_factor.labels">factor.labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, factor labels will be printed
on the console.</p>
</td></tr>
<tr><td><code id="df.head_+3A_row.names">row.names</code></td>
<td>
<p>logical: if <code>TRUE</code>, row names of the data frame are
printed on the console.</p>
</td></tr>
<tr><td><code id="df.head_+3A_row.names.col">row.names.col</code></td>
<td>
<p>a character string indicating the text color for the row
names, see <code>color</code> argument of the <code><a href="#topic+chr.color">chr.color</a></code>
function.</p>
</td></tr>
<tr><td><code id="df.head_+3A_message">message</code></td>
<td>
<p>logical: if <code>TRUE</code>, number of remaining rows and columns
are printed on the console.</p>
</td></tr>
<tr><td><code id="df.head_+3A_message.col">message.col</code></td>
<td>
<p>a character string indicating the text color for the
number of remaining rows and columns printed on the
console, see <code>color</code> argument of the
<code><a href="#topic+chr.color">chr.color</a></code> function.</p>
</td></tr>
<tr><td><code id="df.head_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="df.head_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with following entries:
</p>
<table role = "presentation">
<tr><td><code>df</code></td>
<td>
<p>data frame specified in <code>data</code> with the first or last <code>n</code>
rows of the data frame with as many columns as fit on the console</p>
</td></tr>
<tr><td><code>row.col</code></td>
<td>
<p>character string indicating the remaining rows and columns</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.check">df.check</a></code>, <code><a href="utils.html#topic+head">head</a></code>, <code><a href="utils.html#topic+tail">tail</a></code>, <code><a href="#topic+freq">freq</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Print first and last six rows
df.head(mtcars)
df.tail(mtcars)

# Example 2: Print first and last six rows without row names
df.head(mtcars, row.names = FALSE)
df.tail(mtcars, row.names = FALSE)

# Example 3: Print first and last three rows with one max. number of decimal places
df.head(mtcars, n = 3, digits = 1)
df.head(mtcars, n = 3, digits = 1)
</code></pre>

<hr>
<h2 id='df.merge'>Merge Multiple Data Frames</h2><span id='topic+df.merge'></span>

<h3>Description</h3>

<p>This function merges data frames by a common column (i.e., matching variable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.merge(..., by, all = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.merge_+3A_...">...</code></td>
<td>
<p>a sequence of matrices or data frames and/or matrices to be merged to one.</p>
</td></tr>
<tr><td><code id="df.merge_+3A_by">by</code></td>
<td>
<p>a character string indicating the column used for merging (i.e., matching variable),
see 'Details'.</p>
</td></tr>
<tr><td><code id="df.merge_+3A_all">all</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), then extra rows with <code>NA</code>s will be added
to the output for each row in a data frame that has no matching row in
another data frame.</p>
</td></tr>
<tr><td><code id="df.merge_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="df.merge_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are following requirements for merging multiple data frames: First, each data frame
has the same matching variable specified in the <code>by</code> argument. Second, matching variable
in the data frames have all the same class. Third, there are no duplicated values in the
matching variable in each data frame. Fourth, there are no missing values in the matching
variables. Last, there are no duplicated variable names across the data frames except for
the matching variable.
</p>
<p>Note that it is possible to specify data frames matrices and/or in the argument <code>...</code>.
However, the function always returns a data frame.
</p>


<h3>Value</h3>

<p>Returns a merged data frame.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>adat &lt;- data.frame(id = c(1, 2, 3),
                   x1 = c(7, 3, 8))

bdat &lt;- data.frame(id = c(1, 2),
                   x2 = c(5, 1))

cdat &lt;- data.frame(id = c(2, 3),
                   y3 = c(7, 9))

ddat &lt;- data.frame(id = 4,
                   y4 = 6)

# Example 1: Merge 'adat', 'bdat', 'cdat', and 'ddat' by the variable 'id'
df.merge(adat, bdat, cdat, ddat, by = "id")

# Example 2: Do not show output on the console
df.merge(adat, bdat, cdat, ddat, by = "id", output = FALSE)

## Not run: 
#-------------------------------------------------------------------------------
# Error messages

adat &lt;- data.frame(id = c(1, 2, 3),
                   x1 = c(7, 3, 8))

bdat &lt;- data.frame(code = c(1, 2, 3),
                   x2 = c(5, 1, 3))

cdat &lt;- data.frame(id = factor(c(1, 2, 3)),
                   x3 = c(5, 1, 3))

ddat &lt;- data.frame(id = c(1, 2, 2),
                   x2 = c(5, 1, 3))

edat &lt;- data.frame(id = c(1, NA, 3),
                   x2 = c(5, 1, 3))

fdat &lt;- data.frame(id = c(1, 2, 3),
                   x1 = c(5, 1, 3))

# Error 1: Data frames do not have the same matching variable specified in 'by'.
df.merge(adat, bdat, by = "id")

# Error 2: Matching variable in the data frames do not all have the same class.
df.merge(adat, cdat, by = "id")

# Error 3: There are duplicated values in the matching variable specified in 'by'.
df.merge(adat, ddat, by = "id")

# Error 4: There are missing values in the matching variable specified in 'by'.
df.merge(adat, edat, by = "id")

# Error 5: There are duplicated variable names across data frames.
df.merge(adat, fdat, by = "id")

## End(Not run)
</code></pre>

<hr>
<h2 id='df.move'>Move Variable(s) in a Data Frame</h2><span id='topic+df.move'></span>

<h3>Description</h3>

<p>This function moves variables to a different position in the data frame, i.e.,
changes the column positions in the data frame. By default, variables specified
in the first argument <code>...</code> are moved to the first position in the data
frame specified in the argument <code>data</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.move(data, ..., before = NULL, after = NULL, first = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.move_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.move_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code> to
move. Note that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also be used to
select variables, see Details in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="df.move_+3A_before">before</code></td>
<td>
<p>a character string indicating a variable in <code>data</code>.
Variable(s) specified in <code>...</code> are moved to the left-hand
side of this variable.</p>
</td></tr>
<tr><td><code id="df.move_+3A_after">after</code></td>
<td>
<p>a character string indicating a variable in <code>data</code>.
Variable(s) specified in <code>...</code> are moved to the right-hand
side of this variable.</p>
</td></tr>
<tr><td><code id="df.move_+3A_first">first</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable(s) specified in
<code>...</code> will be moved to the first position in 'data', if
<code>FALSE</code>, variable(s) specified in <code>...</code> will be moved
to the last position in 'data'.</p>
</td></tr>
<tr><td><code id="df.move_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the data frame in <code>data</code> with columns in a different place.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Move variables 'hp' and 'am' to the first position
df.move(mtcars, hp, am)

# Example 2: Move variables 'hp' and 'am' to the last position
df.move(mtcars, hp, am, first = FALSE)

# Example 3: Move variables 'hp' and 'am' to the left-hand side of 'disp'
df.move(mtcars, hp, am, before = "disp")

# Example 4: Move variables 'hp' and 'am' to the right-hand side of 'disp'
df.move(mtcars, hp, am, after = "disp")
</code></pre>

<hr>
<h2 id='df.rbind'>Combine Data Frames by Rows, Filling in Missing Columns</h2><span id='topic+df.rbind'></span>

<h3>Description</h3>

<p>This function takes a sequence of data frames and combines them by rows, while filling in missing
columns with <code>NA</code>s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.rbind(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.rbind_+3A_...">...</code></td>
<td>
<p>a sequence of data frame to be row bind together. This argument can be a
list of data frames, in which case all other arguments are ignored.
Any <code>NULL</code> inputs are silently dropped. If all inputs are <code>NULL</code>,
the output is also <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an enhancement to <code><a href="base.html#topic+rbind">rbind</a></code> that adds in columns that are not present in all inputs,
accepts a sequence of data frames, and operates substantially faster.
</p>
<p>Column names and types in the output will appear in the order in which they were encountered.
</p>
<p>Unordered factor columns will have their levels unified and character data bound with factors will
be converted to character. POSIXct data will be converted to be in the same time zone.
Array and matrix columns must have identical dimensions after the row count. Aside from these there
are no general checks that each column is of consistent data type.
</p>


<h3>Value</h3>

<p>Returns a single data frame
</p>


<h3>Note</h3>

<p>This function is a copy of the <code>rbind.fill()</code> function in the <span class="pkg">plyr</span>
package by Hadley Wickham.
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham
</p>


<h3>References</h3>

<p>Wickham, H. (2011). The split-apply-combine strategy for data analysis.
<em>Journal of Statistical Software, 40</em>, 1-29. https://doi.org/10.18637/jss.v040.i01
</p>
<p>Wickham, H. (2019). plyr: Tools for Splitting, Applying and Combining Data. R package
version 1.8.5.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>adat &lt;- data.frame(id = c(1, 2, 3), a = c(7, 3, 8), b = c(4, 2, 7))

bdat &lt;- data.frame(id = c(4, 5, 6), a = c(2, 4, 6), c = c(4, 2, 7))

cdat &lt;- data.frame(id = c(7, 8, 9), a = c(1, 4, 6), d = c(9, 5, 4))

# Example 1
df.rbind(adat, bdat, cdat)
</code></pre>

<hr>
<h2 id='df.rename'>Rename Columns in a Matrix or Variables in a Data Frame</h2><span id='topic+df.rename'></span>

<h3>Description</h3>

<p>This function renames columns in a matrix or variables in a data frame by
(1) using <code>old_name = new_name</code>, by using the functions <code>toupper</code>,
<code>tolower</code>, <code>sub</code>, and <code>gsub</code>, or (3) by specifying a character
vector indicating the column(s) or variable(s) to be renamed (argument <code>from</code>)
and a character vector indicating the corresponding replacement values (argument
<code>to</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.rename(data, ..., from, to, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.rename_+3A_data">data</code></td>
<td>
<p>a matrix or data frame.</p>
</td></tr>
<tr><td><code id="df.rename_+3A_...">...</code></td>
<td>
<p><code>old_name = new_name</code> when <code>from = NULL</code> and <code>to = NULL</code>,
or one of the functions <code>toupper</code>, <code>tolower</code>, <code>sub</code>,
and <code>gsub</code>. Note that a tilde (<code>~</code>) needs to be specified
before when using a function, e.g., <code>~toupper</code> or
<code>~gsub("_", ".")</code>.</p>
</td></tr>
<tr><td><code id="df.rename_+3A_from">from</code></td>
<td>
<p>a character string or character vector indicating the column(s) or variable(s) to be renamed.</p>
</td></tr>
<tr><td><code id="df.rename_+3A_to">to</code></td>
<td>
<p>a character string or character vector indicating the corresponding replacement values for
the column(s) or variable(s) specified in the argument <code>name</code>.</p>
</td></tr>
<tr><td><code id="df.rename_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the matrix or data frame <code>data</code> with renamed columns or variables.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Rename using variable names

# Example 1a: Rename 'cyl' in 'mtcars' to 'cylinder' using 'old_name = new_name'
df.rename(mtcars, cyl = cylinder)

# Example 1b: Rename 'cyl' in 'mtcars' to 'cylinder' using 'from' and 'to'
df.rename(mtcars, from = "cyl", to = "cylinder")

# Example 2a: Rename 'cyl' and 'wt' in 'mtcars' to 'cylinder' and 'weight'
# using 'old_name = new_name'
df.rename(mtcars, cyl = cylinder, wt = weight)

# Example 2b: Rename 'cyl' and 'wt' in 'mtcars' to 'cylinder' and 'weight'
# using using 'from' and 'to'
df.rename(mtcars, from = c("cyl", "wt"), to = c("cylinder", "weight"))

#----------------------------------------------------------------------------
# Rename using functions

# Example 3: Convert all variable names to lowercase
df.rename(iris, ~tolower)

# Example 4: Replace all '.' with '_'
# Note, the argument fixed is set to TRUE by default.
df.rename(iris, ~gsub(".", "_"))

# Example 5: Replace all 'S' with 'P'
df.rename(iris, ~gsub("S", "P"))

# Example 6: Replace all 'S' with 'P', ignore case during matching
df.rename(iris, ~gsub("S", "P", ignore.case = TRUE))
</code></pre>

<hr>
<h2 id='df.sort'>Data Frame Sorting</h2><span id='topic+df.sort'></span>

<h3>Description</h3>

<p>This function arranges a data frame in increasing or decreasing order according to one or more variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.sort(data, ..., decreasing = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.sort_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.sort_+3A_...">...</code></td>
<td>
<p>a sorting variable or a sequence of sorting variables which are specified without
quotes <code>''</code> or double quotes <code>""</code>.</p>
</td></tr>
<tr><td><code id="df.sort_+3A_decreasing">decreasing</code></td>
<td>
<p>logical: if <code>TRUE</code>, the sort is decreasing.</p>
</td></tr>
<tr><td><code id="df.sort_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data frame <code>data</code> sorted according to the variables specified in <code>...</code>,
a matrix will be coerced to a data frame.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>Knuth, D. E. (1998) <em>The Art of Computer Programming, Volume 3: Sorting and Searching</em> (2nd ed.). Addison-Wesley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Sort data frame 'mtcars' by 'mpg' in increasing order
df.sort(mtcars, mpg)

# Example 2: Sort data frame 'mtcars' by 'mpg' in decreasing order
df.sort(mtcars, mpg, decreasing = TRUE)

# Example 3: Sort data frame 'mtcars' by 'mpg' and 'cyl' in increasing order
df.sort(mtcars, mpg, cyl)

# Example 4: Sort data frame 'mtcars' by 'mpg' and 'cyl' in decreasing order
df.sort(mtcars, mpg, cyl, decreasing = TRUE)
</code></pre>

<hr>
<h2 id='df.subset'>Subsetting Data Frames</h2><span id='topic+df.subset'></span>

<h3>Description</h3>

<p>This function returns subsets of data frames which meet conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.subset(data, ..., subset = NULL, drop = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df.subset_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.subset_+3A_...">...</code></td>
<td>
<p>an expression indicating variables to select from the data frame
specified in <code>data</code>. See Details for the list of operators
used in this function, i.e., <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code>. Note that all variables
are selected if the argument <code>...</code> is not specified.</p>
</td></tr>
<tr><td><code id="df.subset_+3A_subset">subset</code></td>
<td>
<p>a logical expression indicating rows to keep, e.g., <code>var == 1</code>,
<code>var1 == 1 &amp; var2 == 3</code>, or <code>gender == "female"</code>. By default,
all rows of the data frame specified in <code>data</code> are kept. Note
that logical queries for rows resulting in missing values are
not select.</p>
</td></tr>
<tr><td><code id="df.subset_+3A_drop">drop</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), data frame with a single
column is converted into a vector.</p>
</td></tr>
<tr><td><code id="df.subset_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>...</code> is used to specify an expression indicating the
variables to select from the data frame specified in <code>data</code>, e.g.,
<code>df.subset(dat, x1, x2, x3)</code>. There are seven operators which
can be used in the expression <code>...</code>:
</p>

<dl>
<dt><strong>Dot (<code>.</code>) Operator</strong></dt><dd><p>The dot operator is used to select
all variables from the data frame specified in <code>data</code>. For example,
<code>df.subset(dat, .)</code> selects all variables in <code>dat</code>. Note
that this operator is similar to the function <code>everything()</code> from the
<span class="pkg">tidyselect</span> package.</p>
</dd>
<dt><strong>Plus (<code>+</code>) Operator</strong></dt><dd><p>The plus operator is used to select
variables matching a prefix from the data frame specified in <code>data</code>. For
example, <code>df.subset(dat, +x)</code> selects all variables with the
prefix <code>x</code>. Note that this operator is equivalent to the function
<code>starts_with()</code> from the <span class="pkg">tidyselect</span> package.</p>
</dd>
<dt><strong>Minus (<code>-</code>) Operator</strong></dt><dd><p>The minus operator is used to select
variables matching a suffix from the data frame specified in <code>data</code>. For
example, <code>df.subset(dat, -y)</code> selects all variables with the
suffix <code>y</code>. Note that this operator is equivalent to the function
<code>ends_with()</code> from the <span class="pkg">tidyselect</span> package.</p>
</dd>
<dt><strong>Tilde (<code>~</code>) Operator</strong></dt><dd><p>The tilde operator is used to select
variables containing a word from the data frame specified in <code>data</code>. For
example, <code>df.subset(dat, ~al)</code> selects all variables with the word
<code>al</code>. Note that this operator is equivalent to the function
<code>contains()</code> from the <span class="pkg">tidyselect</span> package.</p>
</dd>
<dt><strong>Colon (<code>:</code>) operator</strong></dt><dd><p>The colon operator is used to select
a range of consecutive variables from the data frame specified in <code>data</code>.
For example, <code>df.subset(dat, x:z)</code> selects all variables from
<code>x</code> to <code>z</code>. Note that this operator is equivalent to the <code>:</code>
operator from the <code>select</code> function in the <span class="pkg">dplyr</span> package.</p>
</dd>
<dt><strong>Double Colon (<code>::</code>) Operator</strong></dt><dd><p>The double colon operator
is used to select numbered variables from the data frame specified in
<code>data</code>. For example, <code>df.subset(dat, x1::x3)</code> selects the
variables <code>x1</code>, <code>x2</code>, and <code>x3</code>. Note that this operator is
similar to the function <code>num_range()</code> from the <span class="pkg">tidyselect</span>
package.</p>
</dd>
<dt><strong>Exclamation Point (<code>!</code>) Operator</strong></dt><dd><p>The exclamation point
operator is used to drop variables from the data frame specified in <code>data</code>
or for taking the complement of a set of variables. For example,
<code>df.subset(dat, ., !x)</code> selects all variables using the dot operator
(<code>.</code>) but <code>x</code> in ' <code>dat</code>., <code>df.subset(dat, ., !~x)</code>
selects all variables but variables with the prefix <code>x</code>, or
<code>df.subset(dat, x:z, !x1:x3)</code> selects all variables from <code>x</code> to <code>z</code>
but excludes all variables from <code>x1</code> to <code>x3</code>. Note that this operator
is equivalent to the <code>!</code> operator from the <code>select</code> function in the
<span class="pkg">dplyr</span> package.</p>
</dd></dl>

<p>Note that operators can be combined within the same function call. For example,
<code>df.subset(dat, +x, -y, !x2:x4, z)</code> selects all variables with the prefix
<code>x</code> and with the suffix <code>y</code> but excludes variables from <code>x2</code> to
<code>x4</code> and select variable <code>z</code>.
</p>


<h3>Value</h3>

<p>Returns a data frame containing the variables and rows selected in the argument
<code>...</code> and rows selected in the argument <code>subset</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#----------------------------------------------------------------------------
# Select single variables

# Example 1: Select 'Sepal.Length' and 'Petal.Width'
df.subset(iris, Sepal.Length, Petal.Width)

#----------------------------------------------------------------------------
# Select all variables using the . operator

# Example 2a: Select all variables, select rows with 'Species' equal 'setosa'
df.subset(iris, subset = Species == "setosa")

# Example 2b: Select all variables, select rows with 'Petal.Length' smaller 1.2
df.subset(iris, subset = Petal.Length &lt; 1.2)

#----------------------------------------------------------------------------
# Select variables matching a prefix using the + operator

# Example 3: Select variables with prefix 'Petal'
df.subset(iris, +Petal)

#----------------------------------------------------------------------------
# Select variables matching a suffix using the - operator

# Example 4: Select variables with suffix 'Width'
df.subset(iris, -Width)

#----------------------------------------------------------------------------
# Select variables containing a word using the ~ operator
#
# Example 5: Select variables containing 'al'
df.subset(iris, ~al)

#----------------------------------------------------------------------------
# Select consecutive variables using the : operator

# Example 6: Select all variables from 'Sepal.Width' to 'Petal.Width'
df.subset(iris, Sepal.Width:Petal.Width)

#----------------------------------------------------------------------------
# Select numbered variables using the :: operator

# Example 7: Select all variables from 'x1' to 'x3' and 'y1' to 'y3'
df.subset(anscombe, x1::x3, y1::y3)
#
#----------------------------------------------------------------------------
# Drop variables using the ! operator

# Example 8a: Select all variables but 'Sepal.Width'
df.subset(iris, !Sepal.Width)

# Example 8b: Select all variables but 'Sepal.Width' to 'Petal.Width'
df.subset(iris, !Sepal.Width:Petal.Width)

#----------------------------------------------------------------------------
# Combine +, -, !, and : operators

# Example 9: Select variables with prefix 'x' and suffix '3', but exclude
# variables from 'x2' to 'x3'
df.subset(anscombe, +x, -3, !x2:x3)

## End(Not run)
</code></pre>

<hr>
<h2 id='dominance'>Dominance Analysis</h2><span id='topic+dominance'></span>

<h3>Description</h3>

<p>This function conducts dominance analysis (Budescu, 1993; Azen &amp; Budescu, 2003)
for linear models estimated by using the <code>lm()</code> function to determine the
relative importance of predictor variables. By default, the function reports
general dominance, but conditional and complete dominance can be requested by
specifying the argument <code>print</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dominance(model, print = c("all", "gen", "cond", "comp"), digits = 3,
          write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dominance_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>lm</code>.</p>
</td></tr>
<tr><td><code id="dominance_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results
to show on the console, i.e. <code>"all"</code> for all results, <code>"gen"</code>
for general dominance, <code>"cond"</code> for conditional dominance,
and <code>"comp"</code> for complete dominance.</p>
</td></tr>
<tr><td><code id="dominance_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying results. Note that the percentage relative
importance of predictors are printed with <code>digits</code> minus 1
decimal places.</p>
</td></tr>
<tr><td><code id="dominance_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="dominance_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="dominance_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="dominance_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Dominance analysis (Budescu, 1993; Azen &amp; Budescu, 2003) is used to determine
the relative importance of predictor variables in a statistical model by examining
the additional contribution of predictors in <em>R</em>-squared relative to each
other in all of the possible <code class="reqn">2^{(p - 2)}</code> subset models with <code class="reqn">p</code> being
the number of predictors. Three levels of dominance can be established through
pairwise comparison of all predictors in a regression model:
</p>

<dl>
<dt><strong>Complete Dominance</strong></dt><dd><p>A predictor completely dominates another
predictor if its additional contribution in <em>R</em>-Squared is higher than that
of the other predictor across all possible subset models that do not include both
predictors. For example, in a regression model with four predictors, <code class="reqn">X_1</code>
completely dominates <code class="reqn">X_2</code> if the additional contribution in <em>R</em>-squared
for <code class="reqn">X_1</code> is higher compared to <code class="reqn">X_2</code> in (1) the null model without any
predictors, (2) the model including <code class="reqn">X_3</code>, (3) the model including
<code class="reqn">X_4</code>, and (4) the model including both <code class="reqn">X_3</code> and <code class="reqn">X_4</code>. Note
that complete dominance cannot be established if one predictor's additional
contribution is greater than the other's for some, but not all of the subset
models. In this case, dominance is undetermined and the result will be <code>NA</code></p>
</dd>
<dt><strong>Conditional Dominance</strong></dt><dd><p>A predictor conditionally dominates another
predictor if its average additional contribution in <em>R</em>-squared is higher
within each model size than that of the other predictor. For example, in a
regression model with four predictors, <code class="reqn">X_1</code> conditionally dominates <code class="reqn">X_2</code>
if the average additional contribution in <em>R</em>-squared is higher compared
to <code class="reqn">X_2</code> in (1) the null model without any predictors, (2) the four models
including one predictor, (3) the six models including two predictors, and (4)
the four models including three predictors.</p>
</dd>
<dt><strong>General Dominance</strong></dt><dd><p>A predictor generally dominates another predictor
if its overall averaged additional contribution in <em>R</em>-squared is higher
than that of the other predictor. For example, in a regression model with four
predictors, <code class="reqn">X_1</code> generally dominates <code class="reqn">X_2</code> if the average across the
four conditional values (i.e., null model, model with one predictor, model with
two predictors, and model with three predictors) is higher than that of <code class="reqn">X_2</code>.
Note that the general dominance measures represent the proportional contribution
that each predictor makes to the <em>R</em>-squared since their sum across all
predictors equals the  <em>R</em>-squared of the full model.</p>
</dd>
</dl>

<p>The three levels of dominance are related to each other in a hierarchical fashion:
Complete dominance implies conditional dominance, which in turn implies general
dominance. However, the converse may not hold for more than three predictors.
That is, general dominance does not imply conditional dominance, and conditional
dominance does not necessarily imply complete dominance.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in <code>model</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with results, i.e., <code>gen</code> for general dominance,
<code>cond</code> for conditional dominance, <code>comp</code> for complete dominance,
and <code>condtsat</code> for the statistics of the conditional dominance</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on the <code>domir</code> function from the <code>domir</code>
package (Luchman, 2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Azen, R., &amp; Budescu, D. V. (2003). The dominance analysis approach for comparing
predictors in multiple regression. <em>Psychological Methods, 8</em>(2), 129–148.
https://doi.org/10.1037/1082-989X.8.2.129
</p>
<p>Budescu, D. V. (1993). Dominance analysis: A new approach to the problem of
relative importance of predictors in multiple regression. <em>Psychological Bulletin, 114</em>(3),
542–551. https://doi.org/10.1037/0033-2909.114.3.542
</p>
<p>Luchman J (2023). <em>domir: Tools to support relative importance analysis</em>. R package
version 1.0.1, https://CRAN.R-project.org/package=domir.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dominance.manual">dominance.manual</a></code>, <code><a href="#topic+std.coef">std.coef</a></code>, <code><a href="#topic+write.result">write.result</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Example 1: Dominance analysis for a linear model

# Example 1
mod &lt;- lm(mpg ~ cyl + disp + hp, data = mtcars)
dominance(mod)

# Print all results
dominance(mod, print = "all")

## Not run: 
#----------------------------------------------------------------------------
# Write results into a Text or Excel file

# Example 2a: Text file
dominance(mod, write = "Dominance.txt", output = FALSE)

# Example 2b: Excel file
dominance(mod, write = "Dominance.xlsx", output = FALSE)
## End(Not run)
</code></pre>

<hr>
<h2 id='dominance.manual'>Dominance Analysis, Manually Inputting a Correlation Matrix</h2><span id='topic+dominance.manual'></span>

<h3>Description</h3>

<p>This function conducts dominance analysis (Budescu, 1993; Azen &amp; Budescu, 2003)
based on a (model-implied) correlation matrix of the manifest or latent variables.
Note that the function only provides general dominance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dominance.manual(x, out = NULL, digits = 3, write = NULL, append = TRUE,
                 check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dominance.manual_+3A_x">x</code></td>
<td>
<p>a matrix or data frame with the (model-implied) correlation matrix
of the manifest or latent variables. Note that column names need
to represent the variables names in <code>x</code>.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_out">out</code></td>
<td>
<p>a character string representing the outcome variable. By default,
the first row and column represents the outcome variable.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying results. Note that the percentage relative
importance of predictors are printed with <code>digits</code> minus 1
decimal places.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>correlation matrix specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>results table for the general dominance</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function implements the function provided in Appendix 1 of Gu (2022) and
copied the function <code>combinations()</code> from the <code>gtools</code> package
(Bolker, Warnes, &amp; Lumley, 2022).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Azen, R., &amp; Budescu, D. V. (2003). The dominance analysis approach for comparing
predictors in multiple regression. <em>Psychological Methods, 8</em>(2), 129–148.
https://doi.org/10.1037/1082-989X.8.2.129
</p>
<p>Bolker, B., Warnes, G., &amp; Lumley, T. (2022). <em>gtools: Various R Programming Tools</em>.
R package version 3.9.4, https://CRAN.R-project.org/package=gtools
</p>
<p>Budescu, D. V. (1993). Dominance analysis: A new approach to the problem of
relative importance of predictors in multiple regression. <em>Psychological Bulletin, 114</em>(3),
542–551. https://doi.org/10.1037/0033-2909.114.3.542
</p>
<p>Gu, X. (2022). Assessing the relative importance of predictors in latent regression
models. <em>Structural Equation Modeling: A Multidisciplinary Journal, 4</em>, 569-583.
https://doi.org/10.1080/10705511.2021.2025377
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dominance">dominance</a></code>, <code><a href="#topic+std.coef">std.coef</a></code>, <code><a href="#topic+write.result">write.result</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Linear model

# Example 1a: Dominance analysis, 'mpg' predicted by 'cyl', 'disp', and 'hp'
dominance.manual(cor(mtcars[, c("mpg", "cyl", "disp", "hp")]))

# Example 1b: Equivalent results using the dominance() function
mod &lt;- lm(mpg ~ cyl + disp + hp, data = mtcars)
dominance(mod)

# Example 1c: Dominance analysis, 'hp' predicted by 'mpg', 'cyl', and 'disp'
dominance.manual(cor(mtcars[, c("mpg", "cyl", "disp", "hp")]), out = "hp")

## Not run: 
# Example 1d: Write results into a text file
dominance.manual(cor(mtcars[, c("mpg", "cyl", "disp", "hp")]),
                 write = "Dominance_Manual.txt")
## End(Not run)

#----------------------------------------------------------------------------
# Example 2: Structural equation modeling

library(lavaan)

#.............
# Latent variables

# Model specification
model &lt;- '# Measurement model
          ind60 =~ x1 + x2 + x3
          dem60 =~ y1 + y2 + y3 + y4
          dem65 =~ y5 + y6 + y7 + y8
          # regressions
          ind60 ~ dem60 + dem65'

# Model estimation
fit &lt;- sem(model, data = PoliticalDemocracy)

# Model-implied correlation matrix of the latent variables
fit.cor &lt;- lavInspect(fit, what = "cor.lv")

# Dominance analysis
dominance.manual(fit.cor)

#.............
# Example 3: Latent and manifest variables

# Model specification, convert manifest to latent variable
model &lt;- '# Measurement model
          ind60 =~ x1 + x2 + x3
          dem60 =~ y1 + y2 + y3 + y4
          # Manifest as latent variable
          ly5 =~ 1*y5
          y5 ~~ 0*y5
          # Regressions
          ind60 ~ dem60 + ly5'

# Model estimation
fit &lt;- sem(model, data = PoliticalDemocracy)

# Model-implied correlation matrix of the latent variables
fit.cor &lt;- lavInspect(fit, what = "cor.lv")

# Dominance analysis
dominance.manual(fit.cor)

#----------------------------------------------------------------------------
# Example 4: Multilevel modeling

# Model specification
model &lt;- 'level: 1
            fw =~ y1 + y2 + y3
            # Manifest as latent variables
            lx1 =~ 1*x1
            lx2 =~ 1*x2
            lx3 =~ 1*x3
            x1 ~~ 0*x1
            x2 ~~ 0*x2
            x3 ~~ 0*x3
            # Regression
            fw ~ lx1 + lx2 + lx3
          level: 2
            fb =~ y1 + y2 + y3
            # Manifest as latent variables
            lw1 =~ 1*w1
            lw2 =~ 1*w2
            # Regression
            fb ~ lw1 + lw2'

# Model estimation
fit &lt;- sem(model, data = Demo.twolevel, cluster = "cluster")

# Model-implied correlation matrix of the latent variables
fit.cor &lt;- lavInspect(fit, what = "cor.lv")

# Dominance analysis Within
dominance.manual(fit.cor$within)

# Dominance analysis Between
dominance.manual(fit.cor$cluster)

## Not run: 
#----------------------------------------------------------------------------
# Example 5: Mplus
#
# In Mplus, the model-implied correlation matrix of the latent variables
# can be requested by OUTPUT: TECH4 and imported into R by using the
# MplusAuomtation package, for example:

library(MplusAutomation)

# Read Mplus output
output &lt;- readModels()

# Extract model-implied correlation matrix of the latent variables
fit.cor &lt;- output$tech4$latCorEst

## End(Not run)
</code></pre>

<hr>
<h2 id='effsize'>Effect Sizes for Categorical Variables</h2><span id='topic+effsize'></span>

<h3>Description</h3>

<p>This function computes effect sizes for one or more than one categorical
variable, i.e., (adjusted) phi coefficient, (bias-corrected) Cramer's <em>V</em>,
(bias-corrected) Tschuprow's <em>T</em>, (adjusted) Pearson's contingency
coefficient, Cohen's <em>w</em>), and <em>Fei</em>. By default, the function
computes <em>Fei</em> based on a chi-square goodness-of-fit test for one
categorical variable, phi coefficient based on a chi-square test of
independence for two dichotomous variables, and Cramer's <em>V</em> based on a
chi-square test of independence for two variables with at least one polytomous
variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>effsize(data, ..., type = c("phi", "cramer", "tschuprow", "cont", "w", "fei"),
        alternative = c("two.sided", "less", "greater"),   conf.level = 0.95,
        adjust = TRUE, indep = TRUE, p = NULL, digits = 3, as.na = NULL,
        write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="effsize_+3A_data">data</code></td>
<td>
<p>a vector, factor or data frame.</p>
</td></tr>
<tr><td><code id="effsize_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>effsize(dat, x1, x2)</code>. When specifying more than
one variable, the first variable is always the focal variable
in the Chi-square test of independence which association
with all other variables is investigated. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="effsize_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of effect size, i.e.,
<code>phi</code> for phi coefficient, <code>cramer</code> for Cramer's
V, <code>tschuprow</code> for Tschuprow’s T, <code>cont</code> for
Pearson's contingency coefficient, <code>w</code> for Cohen's w,
and <code>Fei</code> for Fei.</p>
</td></tr>
<tr><td><code id="effsize_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="effsize_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="effsize_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), phi coefficient and
Pearson's contingency coefficient are adjusted by relating
the coefficient to the possible maximum, or Cramer's <em>V</em>
and Tschuprow’s <em>T</em> are corrected for small-sample bias.</p>
</td></tr>
<tr><td><code id="effsize_+3A_indep">indep</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size computation is based
on a chi-square test of independence (default when specifying
two variable, if <code>FALSE</code> effect size
computation is based on a chi-square goodness-of-fit test
(default when specifying one variable).</p>
</td></tr>
<tr><td><code id="effsize_+3A_p">p</code></td>
<td>
<p>a numeric vector specifying the expected proportions in
each category of the categorical variable when conducting a
chi-square goodness-of-fit test. By default, the expected
proportions in each category are assumed to be equal.</p>
</td></tr>
<tr><td><code id="effsize_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
digits to be used for displaying the results.</p>
</td></tr>
<tr><td><code id="effsize_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="effsize_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output
into either a text file with file extension <code>".txt"</code>
(e.g., <code>"Output.txt"</code>) or Excel file with file
extension <code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If
the file name does not contain any file extension, an Excel
file will be written.</p>
</td></tr>
<tr><td><code id="effsize_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="effsize_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="effsize_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame with variables used in the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on modified copies of the functions <code>chisq_to_phi</code>,
<code>chisq_to_cramers_v</code>, <code>chisq_to_tschuprows_t</code>, <code>chisq_to_pearsons_c</code>,
<code>chisq_to_cohens_w</code>, and <code>chisq_to_fei</code> from the <span class="pkg">effectsize</span>
package (Ben-Shachar, Lüdecke &amp; Makowski, 2020).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Bergsma, W. (2013). A bias correction for Cramer's V and Tschuprow's T.
<em>Journal of the Korean Statistical Society, 42</em>, 323-328.
https://doi.org/10.1016/j.jkss.2012.10.002
</p>
<p>Ben-Shachar M. S., Lüdecke D., Makowski D. (2020). effectsize: Estimation of Effect
Size Indices and Standardized Parameters. <em>Journal of Open Source Software, 5</em>
(56), 2815. https://doi.org/10.21105/joss.02815
</p>
<p>Ben-Shachar, M. S., Patil, I., Theriault, R., Wiernik, B. M., Lüdecke, D. (2023).
Phi, Fei, Fo, Fum: Effect sizes for categorical data that use the chi-squared
statistic. <em>Mathematics, 11</em>, 1982. https://doi.org/10.3390/math11091982
</p>
<p>Cureton, E. E. (1959). Note on Phi/Phi max. <em>Psychometrika, 24</em>, 89-91.
</p>
<p>Davenport, E. C., &amp; El-Sanhurry, N. A. (1991). Phi/Phimax: Review and synthesis.
<em>Educational and Psychological Measurement, 51</em>, 821-828.
https://doi.org/10.1177/001316449105100403
</p>
<p>Sakoda, J.M. (1977). Measures of association for multivariate contingency tables.
<em>Proceedings of the Social Statistics Section of the American Statistical
Association (Part III)</em>, 777-780.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cor.matrix">cor.matrix</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Phi coefficient for 'vs' and 'am'
effsize(mtcars, vs, am)

# Alternative specification without using the '...' argument
effsize(mtcars[, c("vs", "am")])

# Example 2: Bias-corrected Cramer's V for 'gear' and 'carb'
effsize(mtcars, gear, carb)

# Example 3: Cramer's V (without bias-correction) for 'gear' and 'carb'
effsize(mtcars, gear, carb, adjust = FALSE)

# Example 4: Adjusted Pearson's contingency coefficient for 'gear' and 'carb'
effsize(mtcars, gear, carb, type = "cont")

# Example 5: Fei for 'gear'
effsize(mtcars, gear)

# Example 6: Bias-corrected Cramer's V for 'cyl' and 'vs', 'am', 'gear', and 'carb'
effsize(mtcars, cyl, vs:carb)

# Alternative specification without using the '...' argument
effsize(mtcars[, c("cyl", "vs", "am", "gear", "carb")])

## Not run: 
# Example 7a: Write Results into a text file
effsize(mtcars, cyl, vs:carb, write = "Cramer.txt")

# Example 7b: Write Results into a Excel file
effsize(mtcars, cyl, vs:carb, write = "Cramer.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='freq'>Frequency Table</h2><span id='topic+freq'></span>

<h3>Description</h3>

<p>This function computes a frequency table with absolute and percentage frequencies
for one or more than one variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freq(data, ..., print = c("no", "all", "perc", "v.perc"), freq = TRUE,
     split = FALSE, labels = TRUE, val.col = FALSE, round = 3, exclude = 15,
     digits = 2, as.na = NULL, write = NULL, append = TRUE, check = TRUE,
     output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="freq_+3A_data">data</code></td>
<td>
<p>a vector, factor, or data frame.</p>
</td></tr>
<tr><td><code id="freq_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>freq(dat, x1, x2, x3)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="freq_+3A_print">print</code></td>
<td>
<p>a character string indicating which percentage(s) to be
printed on the console, i.e., no percentages (<code>"no"</code>),
all percentages (<code>"all"</code>), percentage frequencies
(<code>"print"</code>), and valid percentage frequencies
(<code>"v.perc"</code>). Default setting when specifying one
variable is <code>print = "all"</code>, while default
setting when specifying more than one variable is <code>print = "no"</code>
unless <code>split = TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq_+3A_freq">freq</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), absolute frequencies will
be shown on the console.</p>
</td></tr>
<tr><td><code id="freq_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is split by variables
when specifying more than one variable in <code>...</code>.</p>
</td></tr>
<tr><td><code id="freq_+3A_labels">labels</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), labels for the factor
levels will be used.</p>
</td></tr>
<tr><td><code id="freq_+3A_val.col">val.col</code></td>
<td>
<p>logical: if <code>TRUE</code>, values are shown in the columns,
variables in the rows.</p>
</td></tr>
<tr><td><code id="freq_+3A_round">round</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for rounding numeric variables.</p>
</td></tr>
<tr><td><code id="freq_+3A_exclude">exclude</code></td>
<td>
<p>an integer value indicating the maximum number of unique
values for variables to be included in the analysis when
specifying more than one variable i.e.,
variables with the number of unique values exceeding
<code>exclude</code> will be excluded from the analysis. It is
also possible to specify <code>exclude = FALSE</code> to include
all variables in the analysis.</p>
</td></tr>
<tr><td><code id="freq_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying percentages.</p>
</td></tr>
<tr><td><code id="freq_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="freq_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="freq_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="freq_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="freq_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, the function displays the absolute and percentage frequencies when
specifying one variable, while the function displays only the absolute frequencies
when more than one variable is specified. The function displays valid percentage
frequencies only in the presence of missing values and excludes variables with
all values missing from the analysis. Note that it is possible to mix numeric
variables, factors, and character variables in the data frame specified in the
argument <code>data</code>. By default, numeric variables are rounded to three digits
before computing the frequency table.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>freq</code> for absolute
frequencies, <code>perc</code> for percentages, and <code>v.perc</code>
for valid percentages</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M., &amp; Wilks, A. R. (1988). <em>The New  S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+crosstab">crosstab</a></code>, <code><a href="#topic+descript">descript</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Frequency table for 'cyl'
freq(mtcars, cyl)

# Alternative specification without using the '...' argument
freq(mtcars$cyl)

# Example 2: Frequency table, values shown in columns
freq(mtcars, cyl, val.col = TRUE)

# Example 3: Frequency table, use 3 digit for displaying percentages
freq(mtcars, cyl, digits = 3)

# Example 4: Frequency table for 'cyl', 'gear', and 'carb'
freq(mtcars, cyl, gear, carb)

# Alternative specification without using the '...' argument
freq(mtcars[, c("cyl", "gear", "carb")])

# Example 5: Frequency table, with percentage frequencies
freq(mtcars, cyl, gear, carb, print = "all")

# Example 6: Frequency table, split output table
freq(mtcars, cyl, gear, carb, split = TRUE)

# Example 7: Frequency table, exclude variables with more than 5 unique values
freq(mtcars, exclude = 5)

## Not run: 
# Example 8a: Write Results into a text file
freq(mtcars, cyl, gear, carb, split = TRUE, write = "Frequencies.txt")

# Example 8b: Write Results into a Excel file
freq(mtcars, cyl, gear, carb, split = TRUE, write = "Frequencies.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='indirect'>Confidence Intervals for the Indirect Effect</h2><span id='topic+indirect'></span>

<h3>Description</h3>

<p>This function computes confidence intervals for the indirect effect based on the
asymptotic normal method, distribution of the product method and the Monte Carlo
method. By default, the function uses the distribution of the product method
for computing the two-sided 95% asymmetric confidence intervals for the indirect
effect product of coefficient estimator <code class="reqn">\hat{a}\hat{b}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indirect(a, b, se.a, se.b, print = c("all", "asymp", "dop", "mc"),
         se = c("sobel", "aroian", "goodman"), nrep = 100000,
         alternative = c("two.sided", "less", "greater"), seed = NULL,
         conf.level = 0.95, digits = 3, write = NULL, append = TRUE,
         check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="indirect_+3A_a">a</code></td>
<td>
<p>a numeric value indicating the coefficient <code class="reqn">a</code>, i.e.,
effect of <code class="reqn">X</code> on <code class="reqn">M</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_b">b</code></td>
<td>
<p>a numeric value indicating the coefficient <code class="reqn">b</code>, i.e.,
effect of <code class="reqn">M</code> on <code class="reqn">Y</code> adjusted for <code class="reqn">X</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_se.a">se.a</code></td>
<td>
<p>a positive numeric value indicating the standard error of
<code class="reqn">a</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_se.b">se.b</code></td>
<td>
<p>a positive numeric value indicating the standard error of
<code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which confidence
intervals (CI) to show on the console, i.e. <code>"all"</code> for all
CIs, <code>"asymp"</code> for the CI based on the asymptotic normal
method, <code>"dop"</code> (default) for the CI based on the distribution
of the product method, and <code>"mc"</code> for the CI based on the Monte
Carlo method.</p>
</td></tr>
<tr><td><code id="indirect_+3A_se">se</code></td>
<td>
<p>a character string indicating which standard error (SE) to compute
for the asymptotic normal method, i.e., <code>"sobel"</code> for the
approximate standard error by Sobel (1982) using the multivariate
delta method based on a first order Taylor series approximation,
<code>"aroian"</code> (default) for the exact standard error by
Aroian (1947) based on a first and second order Taylor series
approximation, and <code>"goodman"</code> for the unbiased standard
error by Goodman (1960).</p>
</td></tr>
<tr><td><code id="indirect_+3A_nrep">nrep</code></td>
<td>
<p>an integer value indicating the number of Monte Carlo repetitions.</p>
</td></tr>
<tr><td><code id="indirect_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be
one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the seed of the random number generator
when using the Monte Carlo method.</p>
</td></tr>
<tr><td><code id="indirect_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level
of the interval.</p>
</td></tr>
<tr><td><code id="indirect_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying</p>
</td></tr>
<tr><td><code id="indirect_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="indirect_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="indirect_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="indirect_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In statistical mediation analysis (MacKinnon &amp; Tofighi, 2013), the indirect effect
refers to the effect of the independent variable <code class="reqn">X</code> on the outcome variable
<code class="reqn">Y</code> transmitted by the mediator variable <code class="reqn">M</code>. The magnitude of the indirect
effect <code class="reqn">ab</code> is quantified by the product of the the coefficient <code class="reqn">a</code>
(i.e., effect of <code class="reqn">X</code> on <code class="reqn">M</code>) and the coefficient <code class="reqn">b</code> (i.e., effect of
<code class="reqn">M</code> on <code class="reqn">Y</code> adjusted for <code class="reqn">X</code>). In practice, researchers are often
interested in confidence limit estimation for the indirect effect. This function
offers three different methods for computing the confidence interval for the
product of coefficient estimator <code class="reqn">\hat{a}\hat{b}</code>:
</p>
<p><strong>(1) Asymptotic normal method</strong>
</p>
<p>In the asymptotic normal method, the standard error for the product of the
coefficient estimator <code class="reqn">\hat{a}\hat{b}</code> is computed which is used to create
a symmetrical confidence interval based on the z-value of the standard normal
(<code class="reqn">z</code>) distribution assuming that the indirect effect is normally distributed.
Note that the function provides three formulas for computing the standard error
by specifying the argument <code>se</code>:
</p>

<dl>
<dt><code>"sobel"</code></dt><dd><p>Approximate standard error by Sobel (1982) using the
multivariate delta method based on a first order Taylor series approximation:
</p>
<p style="text-align: center;"><code class="reqn">\sqrt(a^2 \sigma^2_a + b^2 \sigma^2_b)</code>
</p>
</dd>
<dt><code>"aroian"</code></dt><dd><p>Exact standard error by Aroian (1947) based on a first
and second order Taylor series approximation:
</p>
<p style="text-align: center;"><code class="reqn">\sqrt(a^2 \sigma^2_a + b^2 \sigma^2_b + \sigma^2_a \sigma^2_b)</code>
</p>
</dd>
<dt><code>"goodman"</code></dt><dd><p>Unbiased standard error by Goodman (1960):
</p>
<p style="text-align: center;"><code class="reqn">\sqrt(a^2 \sigma^2_a + b^2 \sigma^2_b - \sigma^2_a \sigma^2_b)</code>
</p>

<p>Note that the unbiased standard error is often negative and is hence
undefined for zero or small effects or small sample sizes.</p>
</dd>
</dl>

<p>The asymptotic normal method is known to have low statistical power because
the distribution of the product <code class="reqn">\hat{a}\hat{b}</code> is not normally distributed.
(Kisbu-Sakarya, MacKinnon, &amp; Miocevic, 2014). In the null case, where both random
variables have mean equal to zero, the distribution is symmetric with kurtosis of
six. When the product of the means of the two random variables is nonzero, the
distribution is skewed (up to a maximum value of <code class="reqn">\pm</code> 1.5) and has a excess
kurtosis (up to a maximum value of 6). However, the product approaches a normal
distribution as one or both of the ratios of the means to standard errors of each
random variable get large in absolute value (MacKinnon, Lockwood &amp; Williams, 2004).
</p>
<p><strong>(2) Distribution of the product method</strong>
</p>
<p>The distribution of the product method (MacKinnon et al., 2002) relies on an
analytical approximation of the distribution of the product of two normally
distributed variables. The method uses the standardized <code class="reqn">a</code> and <code class="reqn">b</code>
coefficients to compute <code class="reqn">ab</code> and then uses the critical values for the
distribution of the product (Meeker, Cornwell, &amp; Aroian, 1981) to create
asymmetric confidence intervals. The distribution of the product approaches
the gamma distribution (Aroian, 1947). The analytical solution for the distribution
of the product is provided by the Bessel function used to the solution of
differential equations and is approximately proportional to the Bessel function
of the second kind with a purely imaginary argument (Craig, 1936).
</p>
<p><strong>(3) Monte Carlo method</strong>
</p>
<p>The Monte Carlo (MC) method (MacKinnon et al., 2004) relies on the assumption
that the parameters <code class="reqn">a</code> and <code class="reqn">b</code> have a joint normal sampling distribution.
Based on the parametric assumption, a sampling distribution of the product
<code class="reqn">a</code><code class="reqn">b</code> using random samples with population values equal to the sample
estimates <code class="reqn">\hat{a}</code>, <code class="reqn">\hat{b}</code>, <code class="reqn">\hat{\sigma}_a</code>, and <code class="reqn">\hat{\sigma}_b</code>
is generated. Percentiles of the sampling distribution are identified to serve as
limits for a <code class="reqn">100(1 - \alpha)</code>% asymmetric confidence interval about the sample
<code class="reqn">\hat{a}\hat{b}</code> (Preacher &amp; Selig, 2012). Note that parametric assumptions
are invoked for <code class="reqn">\hat{a}</code> and <code class="reqn">\hat{b}</code>, but no parametric assumptions
are made about the distribution of <code class="reqn">\hat{a}\hat{b}</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>a</code> <code>b</code>, <code>se.a</code>,
and <code>se.b</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>asymp</code> with CI based
on the asymptotic normal method, <code>dop</code> with CI based
on the distribution of the product method, and <code>mc</code>
for CI based on the Monte Carlo method</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function was adapted from the <code>medci()</code> function in the <span class="pkg">RMediation</span>
package by Davood Tofighi and David P. MacKinnon (2016).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Aroian, L. A. (1947). The probability function of the product of two normally distributed variables.
<em>Annals of Mathematical Statistics, 18</em>, 265-271. https://doi.org/10.1214/aoms/1177730442
</p>
<p>Craig,C.C. (1936). On the frequency function of xy. <em>Annals of Mathematical Statistics, 7</em>, 1–15.
https://doi.org/10.1214/aoms/1177732541
</p>
<p>Goodman, L. A. (1960). On the exact variance of products. <em>Journal of the American Statistical
Association, 55</em>, 708-713. https://doi.org/10.1080/01621459.1960.10483369
</p>
<p>Kisbu-Sakarya, Y., MacKinnon, D. P., &amp; Miocevic M. (2014). The distribution of the product explains
normal theory mediation confidence interval estimation. <em>Multivariate Behavioral Research, 49</em>,
261–268. https://doi.org/10.1080/00273171.2014.903162
</p>
<p>MacKinnon, D. P., Lockwood, C. M., Hoffman, J. M., West, S. G., &amp; Sheets, V. (2002). Comparison of methods
to test mediation and other intervening variable effects. <em>Psychological Methods, 7</em>, 83–104.
https://doi.org/10.1037/1082-989x.7.1.83
</p>
<p>MacKinnon, D. P., Lockwood, C. M., &amp; Williams, J. (2004). Confidence limits for the indirect effect:
Distribution of the product and resampling methods. <em>Multivariate Behavioral Research, 39</em>, 99-128.
https://doi.org/10.1207/s15327906mbr3901_4
</p>
<p>MacKinnon, D. P., &amp; Tofighi, D. (2013). Statistical mediation analysis. In J. A. Schinka, W. F. Velicer,
&amp; I. B. Weiner (Eds.), <em>Handbook of psychology: Research methods in psychology</em> (pp. 717-735).
John Wiley &amp; Sons, Inc..
</p>
<p>Meeker, W. Q., Jr., Cornwell, L. W., &amp; Aroian, L. A. (1981). The product of two normally distributed
random variables. In W. J. Kennedy &amp; R. E. Odeh (Eds.), <em>Selected tables in mathematical statistics</em>
(Vol. 7, pp. 1–256). Providence, RI: American Mathematical Society.
</p>
<p>Preacher, K. J., &amp; Selig, J. P. (2012). Advantages of Monte Carlo confidence intervals for indirect effects.
<em>Communication Methods and Measures, 6</em>, 77–98. http://dx.doi.org/10.1080/19312458.2012.679848
</p>
<p>Sobel, M. E. (1982). Asymptotic confidence intervals for indirect effects in structural equation models.
In S. Leinhardt (Ed.), <em>Sociological methodology 1982</em> (pp. 290-312). Washington, DC: American
Sociological Association.
</p>
<p>Tofighi, D. &amp; MacKinnon, D. P. (2011). RMediation: An R package for mediation analysis
confidence intervals. <em>Behavior Research Methods, 43</em>, 692-700.
https://doi.org/10.3758/s13428-011-0076-x
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.indirect">multilevel.indirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Distribution of the Product Method
indirect(a = 0.35, b = 0.27, se.a = 0.12, se.b = 0.18)

# Example 2: Monte Carlo Method
indirect(a = 0.35, b = 0.27, se.a = 0.12, se.b = 0.18, print = "mc")

# Example 3: Asymptotic Normal Method
indirect(a = 0.35, b = 0.27, se.a = 0.12, se.b = 0.18, print = "asymp")

## Not run: 
# Example 4: Write results into a text file
indirect(a = 0.35, b = 0.27, se.a = 0.12, se.b = 0.18, write = "Indirect.txt")
## End(Not run)
</code></pre>

<hr>
<h2 id='item.alpha'>Coefficient Alpha and Item Statistics</h2><span id='topic+item.alpha'></span>

<h3>Description</h3>

<p>This function computes point estimate and confidence interval for the (ordinal)
coefficient alpha (aka Cronbach's alpha) along with the corrected item-total
correlation and coefficient alpha if item deleted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.alpha(data, ..., exclude = NULL, std = FALSE, ordered = FALSE,
           na.omit = FALSE, print = c("all", "alpha", "item"), digits = 2,
           conf.level = 0.95, as.na = NULL, write = NULL, append = TRUE,
           check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="item.alpha_+3A_data">data</code></td>
<td>
<p>a data frame, variance-covariance or correlation
matrix. Note that raw data is needed to compute ordinal
coefficient alpha, i.e., <code>ordered = TRUE</code>.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>
e.g., <code>item.alpha(dat, x1, x2, x3)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_exclude">exclude</code></td>
<td>
<p>a character vector indicating items to be excluded from the
analysis.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_std">std</code></td>
<td>
<p>logical: if <code>TRUE</code>, the standardized coefficient alpha
is computed.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_ordered">ordered</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables are treated as ordered (ordinal)
variables to compute ordinal coefficient alpha.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion); if
<code>FALSE</code> (default), pairwise deletion is used.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e.
<code>"all"</code> (default), for all results <code>"alpha"</code> for
the coefficient alpha, and <code>"item"</code> for item statistics.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying coefficient alpha and item-total correlations.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level
of the interval.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ordinal coefficient alpha was introduced by Zumbo, Gadermann and Zeisser (2007)
which is obtained by applying the formula for computing coefficient alpha to the
polychoric correlation matrix instead of the variance-covariance or product-moment
correlation matrix. Note that Chalmers (2018) highlighted that the ordinal
coefficient alpha should be interpreted only as a hypothetical estimate of an
alternative reliability, whereby a test's ordinal categorical response options
have be modified to include an infinite number of ordinal response options and
concludes that coefficient alpha should not be reported as a measure of a test's
reliability. However, Zumbo and Kroc (2019) argued that Chalmers' critique of
ordinal coefficient alpha is unfounded and that ordinal coefficient alpha may
be the most appropriate quantifier of reliability when using Likert-type measurement
to study a latent continuous random variable.
Confidence intervals are computed using the procedure by Feldt, Woodruff and Salih
(1987). When computing confidence intervals using pairwise deletion, the average
sample size from all pairwise samples is used. Note that there are at least 10
other procedures for computing the confidence interval (see Kelley and
Pornprasertmanit, 2016), which are implemented in the <code>ci.reliability()</code>
function in the <span class="pkg">MBESSS</span> package by Ken Kelley (2019).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>alpha</code> for a table
with coefficient alpha and <code>itemstat</code> for a table with
item statistics</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P. (2018). On misconceptions and the limited usefulness of ordinal alpha.
<em>Educational and Psychological Measurement, 78</em>, 1056-1071.
https://doi.org/10.1177/0013164417727036
</p>
<p>Cronbach, L.J. (1951). Coefficient alpha and the internal structure of tests.
<em>Psychometrika, 16</em>, 297-334. https://doi.org/10.1007/BF02310555
</p>
<p>Cronbach, L.J. (2004). My current thoughts on coefficient alpha and successor
procedures. <em>Educational and Psychological Measurement, 64</em>, 391-418.
https://doi.org/10.1177/0013164404266386
</p>
<p>Feldt, L. S., Woodruff, D. J., &amp; Salih, F. A. (1987). Statistical inference for
coefficient alpha. <em>Applied Psychological Measurement</em>, 11 93-103.
https://doi.org/10.1177/014662168701100107
</p>
<p>Kelley, K., &amp; Pornprasertmanit, S. (2016). Confidence intervals for population
reliability coefficients: Evaluation of methods, recommendations, and software
for composite measures. <em>Psychological Methods, 21</em>, 69-92.
https://doi.org/10.1037/a0040086.
</p>
<p>Ken Kelley (2019). <em>MBESS: The MBESS R Package</em>. R package version 4.6.0.
https://CRAN.R-project.org/package=MBESS
</p>
<p>Zumbo, B. D., &amp; Kroc, E. (2019). A measurement is a choice and Stevens' scales
of measurement do not help make it: A response to Chalmers. <em>Educational
and Psychological Measurement, 79</em>, 1184-1197.
https://doi.org/10.1177/0013164419844305
</p>
<p>Zumbo, B. D., Gadermann, A. M., &amp; Zeisser, C. (2007). Ordinal versions of coefficients
alpha and theta for Likert rating scales. <em>Journal of Modern Applied Statistical
Methods, 6</em>, 21-29. https://doi.org/10.22237/jmasm/1177992180
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+item.cfa">item.cfa</a></code>, <code><a href="#topic+item.omega">item.omega</a></code>,
<code><a href="#topic+item.reverse">item.reverse</a></code>, <code><a href="#topic+item.scores">item.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(item1 = c(4, 2, 3, 4, 1, 2, 4, 2), item2 = c(4, 3, 3, 3, 2, 2, 4, 1),
                  item3 = c(3, 2, 4, 2, 1, 3, 4, 1), item4 = c(4, 1, 2, 3, 2, 3, 4, 2))

# Example 1: Compute unstandardized coefficient alpha and item statistics
item.alpha(dat)

# Example 2: Compute standardized coefficient alpha and item statistics
item.alpha(dat, std = TRUE)

# Example 3: Compute unstandardized coefficient alpha
item.alpha(dat, print = "alpha")

# Example 4: Compute item statistics
item.alpha(dat, print = "item")

# Example 5: Compute unstandardized coefficient alpha and item statistics while excluding item3
item.alpha(dat, exclude = "item3")

# Example 6: Compute unstandradized coefficient alpha based on the variance-covariance matrix
item.alpha(cov(dat))

# Example 7: Compute standardized coefficient alpha based on the correlation matrix
item.alpha(cor(dat))

# Example 8: Compute ordinal coefficient alpha
item.alpha(dat, ordered = TRUE)

## Not run: 
# Example 9a: Write Results into a text file
result &lt;- item.alpha(dat, write = "Alpha.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='item.cfa'>Confirmatory Factor Analysis</h2><span id='topic+item.cfa'></span>

<h3>Description</h3>

<p>This function is a wrapper function for conducting confirmatory factor analysis
with continuous and/or ordered-categorical indicators by calling the <code>cfa</code>
function in the R package <span class="pkg">lavaan</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.cfa(data, ..., model = NULL, rescov = NULL, hierarch = FALSE,
         meanstructure = TRUE, ident = c("marker", "var", "effect"),
         parameterization = c("delta", "theta"), ordered = NULL, cluster = NULL,
         estimator = c("ML", "MLM", "MLMV", "MLMVS", "MLF", "MLR",
                       "GLS", "WLS", "DWLS", "WLSM", "WLSMV",
                       "ULS", "ULSM", "ULSMV", "DLS", "PML"),
         missing = c("listwise", "pairwise", "fiml",
                     "two.stage", "robust.two.stage", "doubly.robust"),
         print = c("all", "summary", "coverage", "descript", "fit", "est",
                   "modind", "resid"),
         mod.minval = 6.63, resid.minval = 0.1, digits = 3, p.digits = 3,
         as.na = NULL, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="item.cfa_+3A_data">data</code></td>
<td>
<p>a data frame. If <code>model = NULL</code>,
confirmatory factor analysis based on a measurement
model with one factor labeled <code>f</code> comprising all
variables in the data frame is conducted.
Note that the cluster variable is excluded from <code>data</code>
when specifying <code>cluster</code>. If <code>model</code> is
specified, the data frame needs to contain
all variables used in the argument <code>model</code> and
the cluster variable when specifying <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>item.cfa(x1, x2, x3, data = dat)</code>. Note
that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also
be used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_model">model</code></td>
<td>
<p>a character vector specifying a measurement model with
one factor, or a list of character vectors for specifying
a measurement model with more than one factor, e.g.,
<code>model = c("x1", "x2", "x3", "x4")</code> for specifying
a measurement model with one factor labeled <code>f</code>
comprising four indicators, or
<code>model = list(factor1 = c("x1", "x2", "x3", "x4"),
factor2 = c("x5", "x6", "x7", "x8"))</code> for specifying a
measurement model with two latent factors labeled
<code>factor1</code> and <code>factor2</code> each comprising four
indicators. Note that the name of each list element is
used to label factors, i.e., all list elements need to
be named, otherwise factors are labeled with
<code>"f1", "f2", "f3"</code> and so on.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for
specifying residual covariances, e.g.
<code>rescov = c("x1", "x2")</code> for specifying a residual
covariance between items <code>x1</code> and <code>x2</code>, or
<code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code> for
specifying residual covariances between items <code>x1</code>
and <code>x2</code>, and items <code>x3</code> and <code>x4</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_hierarch">hierarch</code></td>
<td>
<p>logical: if <code>TRUE</code>, a second-order factor model
is specified given at least three first-order factors
were specified in <code>model</code>. Note that it is not
possible to specify more than one second-order factor.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_meanstructure">meanstructure</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), intercept/means of
observed variables means of latent variables will be
added to the model. Note that <code>meanstructure = FALSE</code>
is only applicable when the <code>missing</code> is
<code>listwise</code>, <code>pairwise</code>, or <code>doubly-robust</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_ident">ident</code></td>
<td>
<p>a character string indicating the method used for
identifying and scaling latent variables, i.e.,
<code>"marker"</code> for the marker variable method fixing
the first factor loading of each latent variable to 1,
<code>"var"</code> for the fixed variance method fixing the
variance of each latent variable to 1, or <code>"effect"</code>
for the effects-coding method using equality constraints
so that the average of the factor loading for each
latent variable equals 1. By default, fixed variance
method is used when <code>hierarch = FALSE</code>, whereas
marker variable method is used when
<code>hierarch = TRUE</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_parameterization">parameterization</code></td>
<td>
<p>a character string indicating the method used for
identifying and scaling latent variables when indicators
are ordered, i.e., <code>"delta"</code> (default) for delta
parameterization and <code>"theta"</code> for theta
parameterization.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_ordered">ordered</code></td>
<td>
<p>if <code>NULL</code> (default), all indicators of the
measurement model are treated as continuous. If
<code>TRUE</code>, all indicators of the measurement model
are treated as ordered (ordinal). Alternatively, a
character vector indicating which variables to treat
as ordered (ordinal) variables can be specified.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name
of the cluster variable in <code>data</code>,
or a vector representing the nested grouping structure
(i.e., group or cluster variable) for computing
cluster-robust standard errors. Note that cluster-robust
standard errors are not available when treating indicators
of the measurement model as ordered (ordinal).</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used
(see 'Details'). By default, <code>"MLR"</code> is used for
CFA models with continuous indicators (i.e.,
<code>ordered = FALSE</code>) and <code>"WLSMV"</code> is used for
CFA model with ordered-categorical indicators (i.e.,
ordered = TRUE).</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing
data, i.e., <code>"listwise"</code> for listwise deletion,
<code>"pairwise"</code> for pairwise deletion, <code>"fiml"</code>
for full information maximum likelihood method,
<code>two.stage</code> for two-stage maximum likelihood
method, <code>robust.two.stage</code> for robust two-stage
maximum likelihood method, and <code>doubly-robust</code>
for doubly-robust method (see 'Details'). By default,
<code>"fiml"</code> is used for CFA models with continuous
indicators which are estimated by using
<code>estimator = "MLR"</code>, and <code>"pairwise"</code> for
CFA models with ordered-categorical indicators which
are estimated by using <code>estimator = "pairwise"</code>
by default.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e. <code>"all"</code> for
all results, <code>"summary"</code> for a summary of the
specification of the estimation method and missing
data handling in lavaan, <code>"coverage"</code> for the
variance-covariance coverage of the data,
<code>"descript"</code> for descriptive statistics,
<code>"fit"</code> for model fit, <code>"est"</code> for parameter
estimates, <code>"modind"</code> for modification
indices and <code>"resid"</code> for the residual correlation
matrix and standardized residual means By default, a
summary of the specification, model fit, and parameter
estimates are printed.. By default, a summary of the specification,
model fit, and parameter estimates are printed.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_mod.minval">mod.minval</code></td>
<td>
<p>numeric value to filter modification indices and only
show modifications with a modification index value equal
or higher than this minimum value. By default, modification
indices equal or higher 6.63 are printed. Note that a
modification index value of 6.63 is equivalent to a
significance level of <code class="reqn">\alpha = .01</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_resid.minval">resid.minval</code></td>
<td>
<p>numeric value indicating the minimum absolute residual
correlation coefficients and standardized means to
highlight in boldface. By default, absolute residual
correlation coefficients and standardized means equal
or higher 0.1 are highlighted. Note that highlighting
can be disabled by setting the minimum value to 1.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis. Note that <code>as.na()</code>
function is only applied to <code>data</code> but not to
<code>cluster</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Estimator</strong></dt><dd><p>The R package <span class="pkg">lavaan</span> provides seven estimators
that affect the estimation, namely <code>"ML"</code>, <code>"GLS"</code>, <code>"WLS"</code>,
<code>"DWLS"</code>, <code>"ULS"</code>, <code>"DLS"</code>, and <code>"PML"</code>. All other options
for the argument <code>estimator</code> combine these estimators with various standard
error and chi-square test statistic computation. Note that the estimators also
differ in how missing values can be dealt with (e.g., listwise deletion,
pairwise deletion, or full information maximum likelihood, FIML).
</p>

<ul>
<li><p><code>"ML"</code>: Maximum likelihood parameter estimates with conventional standard errors
and conventional test statistic. For both complete and incomplete data
using pairwise deletion or FIML.
</p>
</li>
<li><p><code>"MLM"</code>: Maximum likelihood parameter estimates with conventional
robust standard errors and a Satorra-Bentler scaled test statistic that
are robust to non-normality. For complete data only.
</p>
</li>
<li><p><code>"MLMV"</code>: Maximum likelihood parameter estimates with conventional
robust standard errors and a mean and a variance adjusted test statistic
using a scale-shifted approach that are robust to non-normality. For complete
data only.
</p>
</li>
<li><p><code>"MLMVS"</code>: Maximum likelihood parameter estimates with conventional
robust standard errors and a mean and a variance adjusted test statistic
using the Satterthwaite approach that are robust to non-normality. For complete
data only.
</p>
</li>
<li><p><code>"MLF"</code>: Maximum likelihood parameter estimates with standard
errors approximated by first-order derivatives and conventional test statistic.
For both complete and incomplete data using pairwise deletion or FIML.
</p>
</li>
<li><p><code>"MLR"</code>: Maximum likelihood parameter estimates with Huber-White
robust standard errors a test statistic which is asymptotically equivalent
to the Yuan-Bentler T2* test statistic that are robust to non-normality
and non-independence of observed when specifying a cluster variable using
the argument <code>cluster</code>. For both complete and incomplete data using
pairwise deletion or FIML.
</p>
</li>
<li><p><code>"GLS"</code>: Generalized least squares parameter estimates with
conventional standard errors and conventional test statistic that uses a
normal-theory based weight matrix. For complete data only.
and conventional chi-square test. For both complete and incomplete data.
</p>
</li>
<li><p><code>"WLS"</code>: Weighted least squares parameter estimates (sometimes
called ADF estimation) with conventional standard errors and conventional
test statistic that uses a full weight matrix. For complete data only.
</p>
</li>
<li><p><code>"DWLS"</code>: Diagonally weighted least squares parameter estimates
which uses the diagonal of the weight matrix for estimation with conventional
standard errors and conventional test statistic. For both complete and
incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"WLSM"</code>: Diagonally weighted least squares parameter estimates
which uses the diagonal of the weight matrix for estimation, but uses the
full weight matrix for computing the conventional robust standard errors
and a Satorra-Bentler scaled test statistic. For both complete and incomplete
data using pairwise deletion.
</p>
</li>
<li><p><code>"WLSMV"</code>: Diagonally weighted least squares parameter estimates
which uses the diagonal of the weight matrix for estimation, but uses the
full weight matrix for computing the conventional robust standard errors
and a mean and a variance adjusted test statistic using a scale-shifted
approach. For both complete and incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"ULS"</code>: Unweighted least squares parameter estimates with
conventional standard errors and conventional test statistic. For both
complete and incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"ULSM"</code>: Unweighted least squares parameter estimates with
conventional robust standard errors and a Satorra-Bentler scaled test
statistic. For both complete and incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"ULSMV"</code>: Unweighted least squares parameter estimates with
conventional robust standard errors and a mean and a variance adjusted
test statistic using a scale-shifted approach. For both complete and
incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"DLS"</code>: Distributionally-weighted least squares parameter
estimates with conventional robust standard errors and a Satorra-Bentler
scaled test statistic. For complete data only.
</p>
</li>
<li><p><code>"PML"</code>: Pairwise maximum likelihood parameter estimates
with Huber-White robust standard errors and a mean and a variance adjusted
test statistic using the Satterthwaite approach. For both complete and
incomplete data using pairwise deletion.
</p>
</li></ul>

</dd>
<dt><strong>Missing Data</strong></dt><dd><p>The R package <span class="pkg">lavaan</span> provides six methods
for dealing with missing data:
</p>

<ul>
<li><p><code>"listwise"</code>: Listwise deletion, i.e., all cases with missing
values are removed from the data before conducting the analysis. This is
only valid if the data are missing completely at random (MCAR).
</p>
</li>
<li><p><code>"pairwise"</code>: Pairwise deletion, i.e., each element of a
variance-covariance matrix is computed using cases that have data needed
for estimating that element. This is only valid if the data are missing
completely at random (MCAR).
</p>
</li>
<li><p><code>"fiml"</code>: Full information maximum likelihood (FIML) method,
i.e., likelihood is computed case by case using all available data from
that case. FIML method is only applicable for following estimators:
<code>"ML"</code>, <code>"MLF"</code>, and <code>"MLR"</code>.
</p>
</li>
<li><p><code>"two.stage"</code>: Two-stage maximum likelihood estimation, i.e.,
sample statistics is estimated using EM algorithm in the first step. Then,
these estimated sample statistics are used as input for a regular analysis.
Standard errors and test statistics are adjusted correctly to reflect the
two-step procedure. Two-stage method is only applicable for following
estimators: <code>"ML"</code>, <code>"MLF"</code>, and <code>"MLR"</code>.
</p>
</li>
<li><p><code>"robust.two.stage"</code>: Robust two-stage maximum likelihood
estimation, i.e., two-stage maximum likelihood estimation with standard
errors and a test statistic that are robust against non-normality. Robust
two-stage method is only applicable for following estimators: <code>"ML"</code>,
<code>"MLF"</code>, and <code>"MLR"</code>.
</p>
</li>
<li><p><code>"doubly.robust"</code>: Doubly-robust method only applicable for
pairwise maximum likelihood estimation (i.e., <code>estimator = "PML"</code>.
</p>
</li></ul>

</dd>
<dt><strong>Convergence and model idenfitification checks</strong></dt><dd><p>In line with the
R package <span class="pkg">lavaan</span>, this functions provides several checks for model
convergence and model identification:
</p>

<ul>
<li><p><code>Degrees of freedom</code>: An error message is printed if the number
of degrees of freedom is negative, i.e., the model is not identified.
</p>
</li>
<li><p><code>Model convergence</code>: An error message is printed if the
optimizer has not converged, i.e., results are most likely unreliable.
</p>
</li>
<li><p><code>Standard errors</code>: An error message is printed if the standard
errors could not be computed, i.e., the model might not be identified.
</p>
</li>
<li><p><code>Variance-covariance matrix of the estimated parameters</code>: A
warning message is printed if the variance-covariance matrix of the
estimated parameters is not positive definite, i.e., the smallest eigenvalue
of the matrix is smaller than zero or very close to zero.
</p>
</li>
<li><p><code>Negative variances of observed variables</code>: A warning message
is printed if the estimated variances of the observed variables are
negative.
</p>
</li>
<li><p><code>Variance-covariance matrix of observed variables</code>: A warning
message is printed if the estimated variance-covariance matrix of the
observed variables is not positive definite, i.e., the smallest eigenvalue
of the matrix is smaller than zero or very close to zero.
</p>
</li>
<li><p><code>Negative variances of latent variables</code>: A warning message
is printed if the estimated variances of the latent variables are
negative.
</p>
</li>
<li><p><code>Variance-covariance matrix of latent variables</code>: A warning
message is printed if the estimated variance-covariance matrix of the
latent variables is not positive definite, i.e., the smallest eigenvalue
of the matrix is smaller than zero or very close to zero.
</p>
</li></ul>

<p>Note that unlike the R package <span class="pkg">lavaan</span>, the <code>item.cfa</code> function does
not provide any results when the degrees of freedom is negative, the model
has not converged, or standard errors could not be computed.
</p>
</dd>
<dt><strong>Model Fit</strong></dt><dd><p>The <code>item.cfa</code> function provides the chi-square
test, incremental fit indices (i.e., CFI and TLI), and absolute fit indices
(i.e., RMSEA, and SRMR) to evaluate overall model fit. However, different
versions of the CFI, TLI, and RMSEA are provided depending on the estimator.
Unlike the R package <span class="pkg">lavaan</span>, the different versions are labeled with
<code>Standard</code>, <code>Scaled</code>, and <code>Robust</code> in the output:
</p>

<ul>
<li><p><code>"Standard"</code>: CFI, TLI, and RMSEA without any non-normality
corrections. These fit measures based on the normal theory maximum
likelihood test statistic are sensitive to deviations from multivariate
normality of endogenous variables. Simulation studies by Brosseau-Liard
et al. (2012), and Brosseau-Liard and Savalei (2014) showed that the
uncorrected fit indices are affected by non-normality, especially at small
and medium sample sizes (e.g., n &lt; 500).
</p>
</li>
<li><p><code>"Scaled"</code>: Population-corrected robust CFI, TLI, and RMSEA
with ad hoc non-normality corrections that simply replace the maximum
likelihood test statistic with a robust test statistic (e.g., mean-adjusted
chi-square). These fit indices change the population value being estimated
depending on the degree of non-normality present in the data. Brosseau-Liard
et al. (2012) demonstrated that the ad hoc corrected RMSEA increasingly
accepts poorly fitting models as non-normality in the data increases, while
the effect of the ad hoc correction on the CFI and TLI is less predictable
with non-normality making fit appear worse, better, or nearly unchanged
(Brosseau-Liard &amp; Savalei, 2014).
</p>
</li>
<li><p><code>"Robust"</code>: Sample-corrected robust CFI, TLI, and RMSEA
with non-normality corrections based on formula provided by Li and Bentler
(2006) and Brosseau-Liard and Savalei (2014). These fit indices do not
change the population value being estimated and can be interpreted the
same way as the uncorrected fit indices when the data would have been
normal.
</p>
</li></ul>

<p>In conclusion, the use of sample-corrected fit indices (<code>Robust</code>)
instead of population-corrected fit indices (<code>Scaled</code>) is recommended.
Note that when sample size is very small (e.g., n &lt; 200), non-normality
correction does not appear to adjust fit indices sufficiently to counteract
the effect of non-normality (Brosseau-Liard &amp; Savalei, 2014).
</p>
</dd>
<dt><strong>Modification Indices and Residual Correlation Matrix</strong></dt><dd><p>The <code>item.cfa</code>
function provides modification indices and the residual correlation matrix when
requested by using the <code>print</code> argument. Modification indices (aka score
tests) are univariate Lagrange Multipliers (LM) representing a chi-square
statistic with a single degree of freedom. LM approximates the amount by which
the chi-square test statistic would decrease if a fixed or constrained parameter
is freely estimated (Kline, 2023). However, (standardized) expected parameter
change (EPC) values should also be inspected since modification indices are
sensitive to sample size. EPC values are an estimate of how much the parameter
would be expected to change if it were freely estimated (Brown, 2023). The residual
correlation matrix is computed by separately converting the sample covariance
and model-implied covariance matrices to correlation matrices before calculation
differences between observed and predicted covariances (i.e., <code>type = "cor.bollen"</code>).
As a rule of thumb, absolute correlation residuals greater than .10 indicate
possible evidence for poor local fit, whereas smaller correlation residuals
than 0.05 indicate negligible degree of model misfit (Maydeu-Olivares, 2017).
There is no reliable connection between the size of diagnostic statistics
(i.e., modification indices and residuals) and the type or amount of model
misspecification since (1) diagnostic statistics are themselves affected by
misspecification, (2) misspecification in one part of the model distorts estimates
in other parts of the model (i.e., error propagation), and (3) equivalent models
have identical residuals but contradict the pattern of causal effects (Kline, 2023).
Note that according to Kline' (2023) &quot;any report of the results without information
about the residuals is deficient&quot; (p. 172).</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>specified model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>results of the convergence and model identification check</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
specification of the estimation method and missing data
handling in lavaan, <code>"coverage"</code> for the
variance-covariance coverage of the data, <code>"descript"</code>
for descriptive statistics, <code>itemfreq</code> for absolute
frequencies (<code>freq</code>), percentages (<code>perc</code>),
and  (<code>v.perc</code>) valid percentages, <code>"fit"</code> for
model fit, <code>"param"</code> for parameter estimates, and
<code>"modind"</code> for modification indices.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>cfa</code>, <code>lavInspect</code>, <code>lavTech</code>,
<code>modindices</code>, <code>parameterEstimates</code>, and <code>standardizedsolution</code>
provided in the R package <span class="pkg">lavaan</span> by Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Brosseau-Liard, P. E., Savalei, V., &amp; Li. L. (2012). An investigation of the
sample performance of two nonnormality corrections for RMSEA,
<em>Multivariate Behavioral Research, 47</em>, 904-930.
https://doi.org/10.1080/00273171.2014.933697
</p>
<p>Brosseau-Liard, P. E., &amp; Savalei, V. (2014) Adjusting incremental fit indices
for nonnormality. <em>Multivariate Behavioral Research, 49</em>, 460-470.
https://doi.org/10.1080/00273171.2014.933697
</p>
<p>Brown, T. A. (2023). Confirmatory factor analysis. In R. H. Hoyle (Ed.),
<em>Handbook of structural equation modeling</em> (2nd ed.) (pp. 361–379). The
Guilford Press.
</p>
<p>Kline, R. B. (2023). <em>Principles and practice of structural equation modeling</em> (5th ed.).
Guilford Press.
</p>
<p>Li, L., &amp; Bentler, P. M. (2006). Robust statistical tests for evaluating the
hypothesis of close fit of misspecified mean and covariance structural models.
<em>UCLA Statistics Preprint #506</em>. University of California.
</p>
<p>Maydeu-Olivares, A. (2017). Assessing the size of model misfit in structural
equation models. <em>Psychometrika, 82</em>(3), 533–558. https://doi.org/10.1007/s11336-016-9552-7
</p>
<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.omega">item.omega</a></code>, <code><a href="#topic+item.scores">item.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

#----------------------------------------------------------------------------
# Measurement model with one factor

# Example 1a: Specification using the argument '...'
item.cfa(HolzingerSwineford1939, x1:x3)

# Example 1b: Alternative specification without using the '...' argument
item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")])

# Example 1c: Alternative specification using the argument 'model'
item.cfa(HolzingerSwineford1939, model = c("x1", "x2", "x3"))

# Example 1e: Alternative specification using the argument 'model'
item.cfa(HolzingerSwineford1939, model = list(visual = c("x1", "x2", "x3")))

#----------------------------------------------------------------------------
# Measurement model with three factors

# Example 2: Specification using the argument 'model'
item.cfa(HolzingerSwineford1939,
         model = list(visual = c("x1", "x2", "x3"),
                      textual = c("x4", "x5", "x6"),
                      speed = c("x7", "x8", "x9")))

#----------------------------------------------------------------------------
# Residual covariances

# Example 3a: One residual covariance
item.cfa(HolzingerSwineford1939,
         model = list(visual = c("x1", "x2", "x3"),
                      textual = c("x4", "x5", "x6"),
                      speed = c("x7", "x8", "x9")),
         rescov = c("x1", "x2"))

# Example 3b: Two residual covariances
item.cfa(HolzingerSwineford1939,
         model = list(visual = c("x1", "x2", "x3"),
                      textual = c("x4", "x5", "x6"),
                      speed = c("x7", "x8", "x9")),
         rescov = list(c("x1", "x2"), c("x4", "x5")))

#----------------------------------------------------------------------------
# Second-order factor model based on three first-order factors

# Example 4
item.cfa(HolzingerSwineford1939,
         model = list(visual = c("x1", "x2", "x3"),
                      textual = c("x4", "x5", "x6"),
                      speed = c("x7", "x8", "x9")), hierarch = TRUE)

#----------------------------------------------------------------------------
# Measurement model with ordered-categorical indicators

# Example 5
item.cfa(round(HolzingerSwineford1939[, c("x4", "x5", "x6")]), ordered = TRUE)

#----------------------------------------------------------------------------
# Cluster-robust standard errors

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Example 6a: Specification using the '...' argument
item.cfa(y4:y6, data = Demo.twolevel, cluster = "cluster")

# Example 6b: Alternative specification without using the '...' argument
item.cfa(Demo.twolevel[, c("y4", "y5", "y6")], cluster = Demo.twolevel$cluster)

# Example 6c: Alternative specification without using the '...' argument
item.cfa(Demo.twolevel[, c("y4", "y5", "y6", "cluster")], cluster = "cluster")

#----------------------------------------------------------------------------
# Print argument

# Example 7a: Request all results
item.cfa(HolzingerSwineford1939, x1, x2, x3, print = "all")

# Example 7b: Request modification indices with value equal or higher than 5
item.cfa(HolzingerSwineford1939, x1, x2, x3, x4, print = "modind", mod.minval = 5)

#----------------------------------------------------------------------------
# lavaan summary of the estimated model

# Example 8
mod &lt;- item.cfa(HolzingerSwineford1939, x1, x2, x3, output = FALSE)

lavaan::summary(mod$model.fit, standardized = TRUE, fit.measures = TRUE)

## Not run: 
#----------------------------------------------------------------------------
# Write Results

# Example 9a: Write Results into a text file
item.cfa(HolzingerSwineford1939, x1, x2, x3, write = "CFA.txt")

# Example 9b: Write Results into a Excel file
item.cfa(HolzingerSwineford1939, x1, x2, x3, write = "CFA.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='item.invar'>Between-Group and Longitudinal Measurement Invariance Evaluation</h2><span id='topic+item.invar'></span>

<h3>Description</h3>

<p>This function is a wrapper function for evaluating configural, metric, scalar,
and strict between-group or longitudinal (partial) measurement invariance using
confirmatory  factor analysis with continuous indicators by calling the <code>cfa</code>
function in the R package <span class="pkg">lavaan</span>. By default, the function evaluates
configural, metric, and scalar measurement invariance by providing a table
with model fit information (i.e., chi-square test, fit indices based on a proper
null model, and information criteria) and model comparison (i.e., chi-square
difference test, change in fit indices, and change in information criteria).
Additionally, variance-covariance coverage of the data, descriptive statistics,
parameter estimates, modification indices, and residual correlation matrix can
be requested by specifying the argument <code>print</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.invar(data, ..., model = NULL, rescov = NULL, rescov.long = TRUE,
           group = NULL, long = FALSE, cluster = NULL,
           invar = c("config", "metric", "scalar", "strict"),
           partial = NULL, ident = c("marker", "var", "effect"),
           estimator = c("ML", "MLM", "MLMV", "MLMVS", "MLF", "MLR",
                         "GLS", "WLS", "DWLS", "WLSM", "WLSMV",
                         "ULS", "ULSM", "ULSMV", "DLS", "PML"),
           missing = c("listwise", "pairwise", "fiml", "two.stage",
                       "robust.two.stage", "doubly.robust"), null.model = TRUE,
           print = c("all", "summary", "coverage", "descript", "fit", "est",
                     "modind", "resid"),
           print.fit = c("all", "standard", "scaled", "robust"),
           mod.minval = 6.63, resid.minval = 0.1, digits = 3, p.digits = 3,
           as.na = NULL, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="item.invar_+3A_data">data</code></td>
<td>
<p>a data frame. If <code>model = NULL</code>, confirmatory
factor analysis based on a measurement model with one factor
labeled <code>f</code> comprising all variables in the
data frame specified in <code>x</code> for evaluating between-group
measurement invariance for the grouping variable specified
in the argument <code>group</code> is conducted. Longitudinal
measurement invariance evaluation can only be conducted by
specifying the model using the argument <code>model</code>. Note
that the cluster variable is excluded from <code>x</code> when
specifying <code>cluster</code>. If <code>model</code> is specified,
the data frame needs to contain all variables
used in the argument <code>model</code> and the cluster variable
when specifying the name of the cluster variable in the
argument <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_...">...</code></td>
<td>
<p> an expression indicating the variable names in <code>data</code>,
e.g., <code>item.invar(dat, x1, x2, x2, group = "group")</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also be
used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_model">model</code></td>
<td>
<p>a character vector specifying a measurement model with one
factor, or a list of character vectors for specifying a
measurement model with more than one factor for evaluating
between-group measurement invariance when <code>long = FALSE</code>
or a list of character vectors for specifying a measurement
model with one factor for each time of measurement for
evaluating longitudinal measurement invariance when
specifying <code>long = TRUE</code>. For example,
<code>model = c("x1", "x2", "x3", "x4")</code> for specifying a
measurement model with one factor labeled <code>f</code> comprising
four indicators, or <code>model = list(factor1 = c("x1", "x2", "x3", "x4"),
factor2 = c("x5", "x6", "x7", "x8"))</code> for specifying a
measurement model with two latent factors labeled <code>factor1</code>
and <code>factor2</code> each comprising four indicators for
evaluating between-group measurement invariance, or
<code>model = list(time1 = c("ax1", "ax2", "ax3", "ax4"),
time2 = c("bx1", "bx2", "bx3", "bx4"),
time3 = c("cx1", "cx2", "cx3", "cx4"))</code> for specifying a
longitudinal measurement model with three time points comprising
four indicators at each time point. This function cannot
evaluate longitudinal measurement invariance for a measurement
model with more than one factor. Note that the name of each
list element is used to label factors, i.e., all list elements
need to be named, otherwise factors are labeled with <code>"f1", "f2", "f3"</code>
when <code>long = FALSE</code> and with <code>"t1", "t2", "t3"</code>
when <code>long = TRUE</code> and so on.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances, e.g., <code>rescov = c("x1", "x2")</code>
for specifying a residual covariance between items <code>x1</code>
and <code>x2</code>, or <code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code>
for specifying residual covariances between items <code>x1</code>
and <code>x2</code>, and items <code>x3</code> and <code>x4</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_rescov.long">rescov.long</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), residual covariances between
parallel indicators are estimated across time when evaluating
longitudinal measurement invariance (<code>long = TRUE</code>),
i.e., residual variances of the same indicators that are
measured at different time points are correlated across all
possible time points. Note that residual covariances should
be estimated even if the parameter estimates are statistically
not significant since indicator-specific systematic variance
is likely to correlate with itself over time (Little, 2013,
p. 164).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name of
the grouping variable in the data frame specified
in <code>x</code> or a vector representing the groups
for conducting multiple-group analysis to evaluate between-group
measurement invariance.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_long">long</code></td>
<td>
<p>logical: if <code>TRUE</code>, longitudinal measurement invariance
evaluation is conducted. The longitudinal measurement model
is specified by using the argument <code>model</code>. Note that
this function can only evaluate either between-group or
longitudinal measurement invariance, but not both at the
same time.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name
of the cluster variable in <code>data</code>,
or a vector representing the nested grouping structure
(i.e., group or cluster variable) for computing
cluster-robust standard errors. Note that cluster-robust
standard errors are not available when treating indicators
of the measurement model as ordered (ordinal).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_invar">invar</code></td>
<td>
<p>a character string indicating the level of measurement
invariance to be evaluated, i.e., <code>config</code> to evaluate
configural measurement invariance (i.e., same factor structure
across groups or time), <code>metric</code> to evaluate configural
and metric measurement invariance (i.e., equal factor loadings
across groups or time), <code>scalar</code> (default) to evaluate
configural, metric and scalar measurement invariance (i.e.,
equal intercepts or thresholds across groups or time), and
<code>strict</code> to evaluate configural, metric, scalar, and
strict measurement invariance (i.e., equal residual variances
across groups or time).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_partial">partial</code></td>
<td>
<p>a character string or character vector containing the labels
of the parameters which should be free in all groups or across
time to specify a partial measurement invariance model. Note
that the labels of the parameters need to match the labels
shown in the output, i.e., <code>"L"</code> with a number for factor
loadings, <code>"T"</code> with a number for intercepts, and
<code>"E"</code> with a number for factor residual variances. The
number attached to the <code>"L"</code>, <code>"T"</code>, or <code>"E"</code>
label corresponds to the number of the indicator in the
measurement model (e.g., <code>"T3"</code> for the intercept of
the third indicator). When specifying the model using the
argument <code>model</code>, however, the number for the factor
loading is a combination of the number of the factor and
the number of the indicator (e.g., <code>"L23"</code> is the third
indicator of the second factor). Note that at least two
invariant indicators are needed for a partial measurement
invariance model. Otherwise there might be issues with model
non-identification.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_ident">ident</code></td>
<td>
<p>a character string indicating the method used for identifying
and scaling latent variables, i.e., <code>"marker"</code> for the
marker variable method fixing the first factor loading of
each latent variable to 1, <code>"var"</code> (default) for the
fixed variance method fixing the variance of each latent
variable to 1, or <code>"effect"</code> for the effects-coding
method using equality constraints so that the average of
the factor loading for each latent variable equals 1.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used
(see 'Details' in the help page of the <code>item.cfa()</code>
function). By default, <code>"MLR"</code> is used for CFA models
with continuous indicators.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data,
i.e., <code>"listwise"</code> for listwise deletion, <code>"pairwise"</code>
for pairwise deletion, <code>"fiml"</code> for full information
maximum likelihood method, <code>two.stage</code> for two-stage
maximum likelihood method, <code>robust.two.stage</code> for robust
two-stage maximum likelihood method, and <code>doubly-robust</code>
for doubly-robust method (see 'Details' in the help page
of the<code>item.cfa()</code> function). By default, <code>"fiml"</code>
is used for CFA models with continuous indicators which are
estimated by using <code>estimator = "MLR"</code>. However, argument
<code>missing</code> switches to <code>listwise</code> when the data
set is complete, i.e., it is not possible to use FIML in
complete data. Note that the robust CFI, TLI, and RMSEA
are different in complete data depending on whether FIML or
listwise deletion was specified when estimating the model
in lavaan.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_null.model">null.model</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the proper null model
for computing incremental fit indices (i.e., CFI and TLI)
is used, i.e., means and variances of the indicators are
constrained to be equal across group or time in the null
model (Little, 2013, p. 112).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results
to show on the console, i.e. <code>"all"</code> for all results,
<code>"summary"</code> for a summary of the specification of the
estimation method and missing data handling in lavaan,
<code>"coverage"</code> for the variance-covariance coverage of
the data, <code>"descript"</code> for descriptive statistics,
<code>"fit"</code> for model fit and model comparison, <code>"est"</code>
for parameter estimates, <code>"modind"</code> for modification
indices, and <code>"resid"</code> for the residual correlation
matrix and standardized residual means. By default, a summary
of the specification, model fit, and parameter estimates
are printed. Note that parameter estimates, modification
indices, and residual correlation matrix is only provided
for the model investigating the level of measurement
invariance specified in the argument <code>"invar"</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_print.fit">print.fit</code></td>
<td>
<p>a character string or character vector indicating which
version of the CFI, TLI, and RMSEA to show on the console
when using a robust estimation method involving a scaling
correction factor, i.e., <code>"all"</code> for all versions of
the CFI, TLI, and RMSEA, <code>"standard"</code> (default when
<code>estimator</code> is one of <code>"ML", "MLF", "GLS", "WLS", "DWLS", "ULS", "PML"</code>)
for fit indices without any non-normality correction,
<code>"scaled"</code> for population-corrected robust fit indices
with ad hoc non-normality correction, and <code>robust</code>
(default when <code>estimator</code> is one of <code>"MLM", "MLMV", "MLMVS", "MLR", "WLSM", "WLSMV", "ULSM", "ULSMV", "DLS"</code>)
for sample-corrected robust fit indices based on formula
provided by Li and Bentler (2006) and Brosseau-Liard and
Savalei (2014).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_mod.minval">mod.minval</code></td>
<td>
<p>numeric value to filter modification indices and only show
modifications with a modification index value equal or higher
than this minimum value. By default, modification indices
equal or higher 6.63 are printed. Note that a modification
index value of 6.63 is equivalent to a significance level
of <code class="reqn">\alpha = .01</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_resid.minval">resid.minval</code></td>
<td>
<p>numeric value indicating the minimum absolute residual
correlation coefficients and standardized means to highlight
in boldface. By default, absolute residual correlation
coefficients and standardized means equal or higher 0.1
are highlighted. Note that highlighting can be disabled by
setting the minimum value to 1.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that information
criteria and chi-square test statistic are printed with
<code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying <em>p</em>-values, covariance coverage
(i.e., <code>p.digits - 1</code>), and residual correlation
coefficients.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.,
these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only
applied to <code>x</code> but not to <code>group</code> or <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked
and convergence and model identification checks are conducted
for all estimated models.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame including all variables used in the analysis, i.e.,
indicators for the factor, grouping variable and cluster variable</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>list with specified model for the configural, metric, scalar,
and strict invariance model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>list with fitted lavaan object of the configural, metric,
scalar, and strict invariance model</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>list with the results of the convergence and model identification
check for the configural, metric, scalar, and strict invariance
model</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary of the specification of the estimation method and
missing data handling in lavaan, <code>coverage</code> for the
variance-covariance coverage of the data, <code>descript</code>
for descriptive statistics, <code>fit</code> for a list with
model fit based on standard, scaled, and robust fit indices,
<code>est</code> for a list with parameter estimates for the
configural, metric, scalar, and strict invariance model,
<code>modind</code> for the list with modification indices for
the configural, metric, scalar, and strict invariance model,
<code>score</code> for the list with result of the score tests
for constrained parameters for the configural, metric,
scalar, and strict invariance model, and <code>resid</code> for
the list with residual correlation matrices and standardized
residual means for the configural, metric, scalar, and
strict invariance model</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>cfa</code>, <code>fitmeasures</code> ,<code>lavInspect</code>,
<code>lavTech</code>, <code>lavTestLRT</code>, <code>lavTestScore</code>, <code>modindices</code>,
<code>parameterEstimates</code>, <code>parTable</code>, and <code>standardizedsolution</code>
provided in the R package <span class="pkg">lavaan</span> by Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Brosseau-Liard, P. E., &amp; Savalei, V. (2014) Adjusting incremental fit indices
for nonnormality. <em>Multivariate Behavioral Research, 49</em>, 460-470.
https://doi.org/10.1080/00273171.2014.933697
</p>
<p>Li, L., &amp; Bentler, P. M. (2006). Robust statistical tests for evaluating the
hypothesis of close fit of misspecified mean and covariance structural models.
<em>UCLA Statistics Preprint #506</em>. University of California.
</p>
<p>Little, T. D. (2013). <em>Longitudinal structural equation modeling</em>. Guilford
Press.
</p>
<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.cfa">item.cfa</a></code>, <code><a href="#topic+multilevel.invar">multilevel.invar</a></code>, <code><a href="#topic+write.result">write.result</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

#----------------------------------------------------------------------------
# Between-Group Measurement Invariance Evaluation

#..................
# Measurement model with one factor

# Example 1a: Specification using the argument '...'
item.invar(HolzingerSwineford1939, x1:x4, group = "sex")

# Example 1b: Alternative specification without using the argument '...'
item.invar(HolzingerSwineford1939[, c("x1", "x2", "x3", "x4")],
           group = HolzingerSwineford1939$sex)

# Example 1c: Alternative specification without using the argument '...'
item.invar(HolzingerSwineford1939[, c("x1", "x2", "x3", "x4", "sex")], group = "sex")

# Example 1d: Alternative specification using the argument 'model'
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"), group = "sex")

#..................
# Measurement model with two factors

item.invar(HolzingerSwineford1939,
           model = list(c("x1", "x2", "x3", "x4"), c("x5", "x6", "x7", "x8")),
           group = "sex")

#..................
# Configural, metric, scalar, and strict measurement invariance

# Example 2: Evaluate configural, metric, scalar, and strict measurement invariance
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", invar = "strict")

#..................
# Partial measurement invariance

# Example 3: Free second factor loading (L2) and third intercept (T3)
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", partial = c("L2", "T3"), print = c("fit", "est"))

#..................
# Residual covariances

# Example 4a: One residual covariance
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           rescov = c("x3", "x4"), group = "sex")

# Example 4b: Two residual covariances
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           rescov = list(c("x1", "x4"), c("x3", "x4")), group = "sex")

#..................
# Scaled test statistic and cluster-robust standard errors

# Example 5a: Specify cluster variable using a variable name in 'data'
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", cluster = "agemo")

# Example 5b: Specify vector of the cluster variable in the argument 'cluster'
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", cluster = HolzingerSwineford1939$agemo)

#..................
# Default Null model

# Example 6: Specify default null model for computing incremental fit indices
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", null.model = FALSE)

#..................
# Print argument

# Example 7a: Request all results
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", print = "all")

# Example 7b: Request fit indices with ad hoc non-normality correction
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", print.fit = "scaled")

# Example 7c: Request modification indices with value equal or higher than 10
# and highlight residual correlations equal or higher than 0.3
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", print = c("modind", "resid"),
           mod.minval = 10, resid.minval = 0.3)

#..................
# Model syntax and lavaan summary of the estimated model

# Example 8
mod &lt;- item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
                  group = "sex", output = FALSE)

# lavaan model syntax scalar invariance model
cat(mod$model$scalar)

# lavaan summary of the scalar invariance model
lavaan::summary(mod$model.fit$scalar, standardized = TRUE, fit.measures = TRUE)

#----------------------------------------------------------------------------
# Longitudinal Measurement Invariance Evaluation

# Example 9: Two time points with three indicators at each time point
item.invar(HolzingerSwineford1939,
           model = list(c("x1", "x2", "x3"),
                        c("x5", "x6", "x7")), long = TRUE)

#------------------------------------------------
# Write Results

# Example 10a: Write Results into a text file
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", print = "all", write = "Invariance.txt", output = FALSE)

# Example 10b: Write Results into a Excel file
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", print = "all", write = "Invariance.xlsx", output = FALSE)

result &lt;- item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
                     group = "sex", print = "all", output = FALSE)
write.result(result, "Invariance.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='item.omega'>Coefficient Omega, Hierarchical Omega, and Categorical Omega</h2><span id='topic+item.omega'></span>

<h3>Description</h3>

<p>This function computes point estimate and confidence interval for the coefficient
omega (McDonald, 1978), hierarchical omega (Kelley &amp; Pornprasertmanit, 2016),
and categorical omega (Green &amp; Yang, 2009) along with standardized factor loadings
and omega if item deleted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.omega(data, ..., rescov = NULL, type = c("omega", "hierarch", "categ"),
           exclude = NULL, std = FALSE, na.omit = FALSE,
           print = c("all", "omega", "item"), digits = 2, conf.level = 0.95,
           as.na = NULL, write = NULL, append = TRUE, check = TRUE,
           output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="item.omega_+3A_data">data</code></td>
<td>
<p>a data frame. Note that at least three items are
needed for computing coefficient omega.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>
e.g., <code>item.omega(dat, x1, x2, x3)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances when computing coefficient omega, e.g.
<code>rescov = c("x1", "x2")</code> for specifying a residual
covariance between items <code>x1</code> and <code>x2</code> or
<code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code> for specifying
residual covariances between items <code>x1</code> and <code>x2</code>,
and items <code>x3</code> and <code>x4</code>.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of omega to be computed, i.e.,
<code>omega</code> (default) for coefficient omega, <code>hierarch</code> for
hierarchical omega, and <code>categ</code> for categorical omega.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_exclude">exclude</code></td>
<td>
<p>a character vector indicating items to be excluded from the
analysis.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_std">std</code></td>
<td>
<p>logical: if <code>TRUE</code>, the standardized coefficient omega
is computed.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion); if <code>FALSE</code>,
full information maximum likelihood (FIML) is used for computing
coefficient omega or hierarchical omega, while pairwise deletion
is used for computing categorical omega.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e.
<code>"all"</code> (default), for all results <code>"omega"</code> for omega,
and <code>"item"</code> for item statistics.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying omega and standardized factor loadings.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level
of the interval.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Omega is computed by estimating a confirmatory factor analysis model using the
<code>cfa()</code> function in the <span class="pkg">lavaan</span> package by Yves Rosseel (2019). Maximum
likelihood (<code>"ML"</code>) estimator is used for computing coefficient omega and
hierarchical omega, while diagonally weighted least squares estimator (<code>"DWLS"</code>)
is used for computing categorical omega.
</p>
<p>Approximate confidence intervals are computed using the procedure by Feldt, Woodruff
and Salih (1987). Note that there are at least 10 other procedures for computing
the confidence interval (see Kelley and Pornprasertmanit, 2016), which are implemented
in the <code>ci.reliability()</code> function in the <span class="pkg">MBESSS</span> package by Ken Kelley (2019).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>omega</code> for a table
with coefficient omega and <code>itemstat</code> for a table with
item statistics</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Computation of the hierarchical and categorical omega is based on
the <code>ci.reliability()</code> function in the <span class="pkg">MBESS</span> package by Ken Kelley
(2019).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Feldt, L. S., Woodruff, D. J., &amp; Salih, F. A. (1987). Statistical inference for
coefficient alpha. <em>Applied Psychological Measurement</em>, 11 93-103.
</p>
<p>Green, S. B., &amp; Yang, Y. (2009). Reliability of summed item scores using structural
equation modeling: An alternative to coefficient alpha. <em>Psychometrika, 74</em>,
155-167. https://doi.org/10.1007/s11336-008-9099-3
</p>
<p>Kelley, K., &amp; Pornprasertmanit, S. (2016). Confidence intervals for population
reliability coefficients: Evaluation of methods, recommendations, and software
for composite measures. <em>Psychological Methods, 21</em>, 69-92.
http://dx.doi.org/10.1037/a0040086
</p>
<p>Ken Kelley (2019). <em>MBESS: The MBESS R Package</em>. R package version 4.6.0.
https://CRAN.R-project.org/package=MBESS
</p>
<p>McDonald, R. P. (1978). Generalizability in factorable domains: Domain validity
and generalizability. <em>Educational and Psychological Measurement, 38</em>, 75-79.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.cfa">item.cfa</a></code>,
<code><a href="#topic+item.reverse">item.reverse</a></code>, <code><a href="#topic+item.scores">item.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

dat &lt;- data.frame(item1 = c(5, 2, 3, 4, 1, 2, 4, 2), item2 = c(5, 3, 3, 5, 2, 2, 5, 1),
                  item3 = c(4, 2, 4, 5, 1, 3, 5, 1), item4 = c(5, 1, 2, 5, 2, 3, 4, 2))

# Example 1a: Compute unstandardized coefficient omega and item statistics
item.omega(dat)

# Example 2: Compute unstandardized coefficient omega and item statistics while excluding item3
item.omega(dat, exclude = "item3")

# Example 3: Compute unstandardized coefficient omega with a residual covariance
# and item statistics
item.omega(dat, rescov = c("item1", "item2"))

# Example 4: Compute unstandardized coefficient omega with residual covariances
# and item statistics
item.omega(dat, rescov = list(c("item1", "item2"), c("item1", "item3")))

# Example 5: Compute unstandardized hierarchical omega and item statistics
item.omega(dat, type = "hierarch")

# Example 6: Compute categorical omega and item statistics
item.omega(dat, type = "categ")

# Example 7: Compute standardized coefficient omega and item statistics
item.omega(dat, std = TRUE)

# Example 8: Compute unstandardized coefficient omega
item.omega(dat, print = "omega")

# Example 9: Print only item statistics
item.omega(dat, print = "item")

# Example 10: Summary of the CFA model used to compute coefficient omega
lavaan::summary(item.omega(dat, output = FALSE)$model.fit,
                fit.measures = TRUE, standardized = TRUE)

# Example 11a: Write Results into a text file
item.omega(dat, write = "Omega.txt")

# Example 11b: Write Results into a Excel file
item.omega(dat, write = "Omega.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='item.reverse'>Reverse Code Scale Item</h2><span id='topic+item.reverse'></span>

<h3>Description</h3>

<p>This function reverse codes inverted items, i.e., items that are negatively
worded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.reverse(data, ..., min = NULL, max = NULL, keep = NULL, append = TRUE,
             name = ".r", as.na = NULL, table = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="item.reverse_+3A_data">data</code></td>
<td>
<p>a numeric vector for reverse coding an item or data frame
for reverse coding more than one item.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code> e.g.,
<code>item.reverse(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_min">min</code></td>
<td>
<p>an integer indicating the minimum of the item (i.e., lowest possible
scale value).</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_max">max</code></td>
<td>
<p>an integer indicating the maximum of the item (i.e., highest possible
scale value).</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_keep">keep</code></td>
<td>
<p>a numeric vector indicating values not to be reverse coded.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), recoded variable(s) are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names
of the reverse coded item. By default, variables are named with the ending
<code>".r"</code> resulting in e.g. <code>"x1.r"</code> and <code>"x2.r"</code>. Variable names
can also be specified using a character vector matching the number
of variables (e.g., <code>name = c("reverse.x1", "reverse.x2")</code>).</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e. these
values are converted to <code>NA</code> before conducting the analysis.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_table">table</code></td>
<td>
<p>logical: if <code>TRUE</code>, a cross table item x reverse coded item
is printed on the console if only one variable is specified.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If arguments <code>min</code> and/or <code>max</code> are not specified, empirical minimum
and/or maximum is computed from the data Note, however, that reverse coding
might fail if the lowest or highest possible scale value is not represented in
the data That is, it is always preferable to specify the arguments <code>min</code>
and <code>max</code>.
</p>


<h3>Value</h3>

<p>Returns a numeric vector or data frame with the same length or same number of
rows as <code>data</code> containing the reverse coded scale item(s).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.omega">item.omega</a></code>, <code><a href="#topic+rec">rec</a></code>,
<code><a href="#topic+item.scores">item.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(item1 = c(1, 5, 3, 1, 4, 4, 1, 5),
                  item2 = c(1, 1.3, 1.7, 2, 2.7, 3.3, 4.7, 5),
                  item3 = c(4, 2, 4, 5, 1, 3, 5, -99))

# Example 1: Reverse code 'item1' and append to 'dat'
item.reverse(dat, item1, min = 1, max = 5)

# Alternative specification without using the '...' argument
item.reverse(dat$item1, min = 1, max = 5)

# Example 2: Reverse code 'item3' while keeping the value -99
item.reverse(dat, item3, min = 1, max = 5, keep = -99)

# Example 3: Reverse code 'item3' while keeping the value -99 and check recoding
item.reverse(dat, item3, min = 1, max = 5, keep = -99, table = TRUE)

# Example 4: Reverse code 'item1', 'item2', and 'item3' and attach to 'dat'
item.reverse(item1:item3, data = dat, min = 1, max = 5, keep = -99)

# Alternative specification without using the '...' argument
dat &lt;- cbind(dat,
             item.reverse(dat[, c("item1", "item2", "item3")],
                          min = 1, max = 5, keep = -99))
</code></pre>

<hr>
<h2 id='item.scores'>Scale Scores</h2><span id='topic+item.scores'></span>

<h3>Description</h3>

<p>This function computes (prorated) scale scores by averaging the (available) items
that measure a single construct by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.scores(data, ..., fun = c("mean", "sum", "median", "var", "sd", "min", "max"),
            prorated = TRUE, p.avail = NULL, n.avail = NULL, append = TRUE,
            name = "scores", as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="item.scores_+3A_data">data</code></td>
<td>
<p>a data frame with numeric vectors.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>item.scores(dat, x1, x2, x3)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_fun">fun</code></td>
<td>
<p>a character string indicating the function used to compute
scale scores, default: <code>"mean"</code>.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_prorated">prorated</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), prorated scale scores are
computed (see 'Details'); if <code>FALSE</code>, scale scores of
only complete cases are computed.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_p.avail">p.avail</code></td>
<td>
<p>a numeric value indicating the minimum proportion of available
item responses needed for computing a prorated scale score for
each case, e.g. <code>p.avail = 0.8</code> indicates that scale scores
are only computed for cases with at least 80% of item responses
available. By default prorated scale scores are computed for
all cases with at least one item response. Note that either
argument <code>p.avail</code> or <code>n.avail</code> is used to specify
the proration criterion.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_n.avail">n.avail</code></td>
<td>
<p>an integer indicating the minimum number of available item
responses needed for computing a prorated scale score for each
case, e.g. <code>n.avail = 2</code> indicates that scale scores are
only computed for cases with item responses on at least 2 items.
By default prorated scale scores are computed for all cases
with at least one item response. Note that either argument
<code>p.avail</code> or <code>n.avail</code> is used to specify the proration
criterion.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a variable with scale scores
is appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_name">name</code></td>
<td>
<p>a character string indicating the names of the variable appended
to the data frame specified in the argument <code>data</code> when
<code>append = TRUE</code>. By default, the variable is named <code>scores</code>.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prorated mean scale scores are computed by averaging the available items, e.g.,
if a participant answers 4 out of 8 items, the prorated scale score is the average
of the 4 responses. Averaging the available items is equivalent to substituting
the mean of a participant's own observed items for each of the participant's missing
items, i.e., <em>person mean imputation</em> (Mazza, Enders &amp; Ruehlman, 2015) or
<em>ipsative mean imputation</em> (Schafer &amp; Graham, 2002).
</p>
<p>Proration may be reasonable when (1) a relatively high proportion of the items
(e.g., 0.8) and never fewer than half are used to form the scale score, (2) means
of the items comprising a scale are similar and (3) the item-total correlations
are similar (Enders, 2010; Graham, 2009; Graham, 2012). Results of simulation
studies indicate that proration is prone to substantial bias when either the
item means or the inter-item correlation vary (Lee, Bartholow, McCarthy, Pederson
&amp; Sher, 2014; Mazza et al., 2015).
</p>


<h3>Value</h3>

<p>Returns a numeric vector with the same length as <code>nrow(x)</code> containing (prorated)
scale scores.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. New York, NY: Guilford
Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>Graham, J. W. (2012). Missing data: Analysis and design. New York, NY: Springer
</p>
<p>Lee, M. R., Bartholow, B. D., McCarhy, D. M., Pederson, S. L., &amp; Sher, K. J. (2014).
Two alternative approaches to conventional person-mean imputation scoring of the
self-rating of the effects of alcohol scale (SRE). <em>Psychology of Addictive Behaviors, 29</em>,
231-236. https://doi.org/10.1037/adb0000015
</p>
<p>Mazza, G. L., Enders, C. G., &amp; Ruehlman, L. S. (2015). Addressing item-level missing
data: A comparison of proration and full information maximum likelihood estimation.
<em>Multivariate Behavioral Research, 50</em>, 504-519.
https://doi.org/10.1080/00273171.2015.1068157
</p>
<p>Schafer, J. L., &amp; Graham, J. W. (2002). Missing data: Our view of the state of
the art. <em>Psychological Methods, 7</em>, 147-177.' https://doi.org/10.1037/1082-989X.7.2.147
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cluster.scores">cluster.scores</a></code>, <code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.cfa">item.cfa</a></code>,
<code><a href="#topic+item.omega">item.omega</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(item1 = c(3,  2,  4, 1,  5, 1,  3, NA),
                  item2 = c(2,  2, NA, 2,  4, 2, NA,  1),
                  item3 = c(1,  1,  2, 2,  4, 3, NA, NA),
                  item4 = c(4,  2,  4, 4, NA, 2, NA, NA),
                  item5 = c(3, NA, NA, 2,  4, 3, NA,  3))

# Example 1: Prorated mean scale scores
item.scores(dat)

# Example 2: Prorated standard deviation scale scores
item.scores(dat, fun = "sd")

# Example 3: Sum scale scores without proration
item.scores(dat, fun = "sum", prorated = FALSE)

# Example 4: Prorated mean scale scores,
# minimum proportion of available item responses = 0.8
item.scores(dat, p.avail = 0.8)

# Example 5: Prorated mean scale scores,
# minimum number of available item responses = 3
item.scores(dat, n.avail = 3)
</code></pre>

<hr>
<h2 id='lagged'>Create Lagged Variables</h2><span id='topic+lagged'></span>

<h3>Description</h3>

<p>This function computes lagged values of variables by a specified number of
observations. By default, the function returns lag-1 values of the vector
or data frame specified in the first argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagged(data, ..., id = NULL, obs = NULL, day = NULL, lag = 1, time = NULL,
       units = c("secs", "mins", "hours", "days", "weeks"), append = TRUE,
       name = ".lag", name.td = ".td", as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lagged_+3A_data">data</code></td>
<td>
<p>a numeric vector for computing a lagged values for a variable
or data frame for computing lagged values for more than one
variable. Note that the subject ID variable (<code>id</code>),
observation number variable (<code>obs</code>), day number variable
(<code>day</code>), and the date and time variable (<code>time</code>) are
excluded from <code>data</code> when specifying theses arguments.</p>
</td></tr>
<tr><td><code id="lagged_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used to select
variables, see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="lagged_+3A_id">id</code></td>
<td>
<p>either a character string indicating the variable name of the
subject ID variable or a vector representing the
subject IDs, see 'Details'.</p>
</td></tr>
<tr><td><code id="lagged_+3A_obs">obs</code></td>
<td>
<p>either a character string indicating the variable name of the
observation number variable or a vector representing
the observations. Note that duplicated values within the same
subject ID are not allowed, see 'Details'.</p>
</td></tr>
<tr><td><code id="lagged_+3A_day">day</code></td>
<td>
<p>either a character string indicating the variable name of the
day number variable in or a vector representing the days,
see 'Details'.</p>
</td></tr>
<tr><td><code id="lagged_+3A_lag">lag</code></td>
<td>
<p>a numeric value specifying the lag, e.g. <code>lag = 1</code> (default)
returns lag-1 values.</p>
</td></tr>
<tr><td><code id="lagged_+3A_time">time</code></td>
<td>
<p>a variable of class <code>POSIXct</code> or <code>POSIXlt</code> representing
the date and time of the observation used to compute time
differences between observations.</p>
</td></tr>
<tr><td><code id="lagged_+3A_units">units</code></td>
<td>
<p>a character string indicating the units in which the time
difference is represented, i.e., <code>"secs"</code> for seconds,
<code>"mins"</code> (default) for minutes, <code>"hours"</code> for hours,
<code>"days"</code> for days, and <code>"weeks"</code> for weeks.</p>
</td></tr>
<tr><td><code id="lagged_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), lagged variable(s) are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="lagged_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names of
the lagged variables. By default, lagged variables are named
with the ending <code>".lag"</code> resulting in e.g. <code>"x1.lag"</code>
and <code>"x2.lag"</code> when specifying two variables. Variable
names can also be specified using a character vector matching
the number of variables, e.g.,
<code>name = c("lag.x1", "lag.x2")</code>).</p>
</td></tr>
<tr><td><code id="lagged_+3A_name.td">name.td</code></td>
<td>
<p>a character string or character vector indicating the names of
the time difference variables when specifying a date and time
variables for the argument <code>time</code>. By default, time
difference variables are named with the ending <code>".td"</code>
resulting in e.g. <code>"x1.td"</code> and <code>"x2.td"</code> when
specifying two variables. Variable names can also be specified
using a character vector matching the number of variables
specified, e.g., <code>name = c("td.x1", "td.x2")</code>).</p>
</td></tr>
<tr><td><code id="lagged_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.
these values are converted to <code>NA</code> before conducting the
analysis. Note that <code>as.na()</code> function is only applied to
the argument <code>data</code>, but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="lagged_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<p>The function is used to create lagged version of the variable(s) specified via
the <code>data</code> argument:
</p>
<dl>
<dt><strong>Optional argument <code>id</code></strong></dt><dd><p>If the <code>id</code> argument is not specified
<code>i.e., id = NULL</code>, all observations are assumed to come from the same
subject.  If the dataset includes multiple subjects, then this variable needs
to be specified so that observations are not lagged across subjects</p>
</dd>
<dt><strong>Optional argument <code>day</code></strong></dt><dd><p>If the <code>day</code> argument is not specified
<code>i.e., day = NULL</code>, values of the variable to be lagged are allowed to be
lagged across days in case there are multiple observation days.</p>
</dd>
<dt><strong>Optional argument <code>obs</code></strong></dt><dd><p>If the <code>obs</code> argument is not specified
<code>i.e., obs = NULL</code>, consecutive observations from the same subjects are
assumed to be one lag apart.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a numeric vector or data frame with the same length or same number of
rows as <code>data</code> containing the lagged variable(s).
</p>


<h3>Note</h3>

<p>This function is a based on the <code>lagvar()</code> function in the <span class="pkg">esmpack</span>
package by Wolfgang Viechtbauer and Mihail Constantin (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Viechtbauer W, Constantin M (2023). <em>esmpack: Functions that facilitate
preparation and management of ESM/EMA data</em>. R package version 0.1-20.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+center">center</a></code>, <code><a href="#topic+rec">rec</a></code>, <code><a href="#topic+coding">coding</a></code>, <code><a href="#topic+item.reverse">item.reverse</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(subject = rep(1:2, each = 6),
                   day = rep(1:2, each = 3),
                   obs = rep(1:6, times = 2),
                   time = as.POSIXct(c("2024-01-01 09:01:00", "2024-01-01 12:05:00",
                                       "2024-01-01 15:14:00", "2024-01-02 09:03:00",
                                       "2024-01-02 12:21:00", "2024-01-02 15:03:00",
                                       "2024-01-01 09:02:00", "2024-01-01 12:09:00",
                                       "2024-01-01 15:06:00", "2024-01-02 09:02:00",
                                       "2024-01-02 12:15:00", "2024-01-02 15:06:00")),
                    pos = c(6, 7, 5, 8, NA, 7, 4, NA, 5, 4, 5, 3),
                    neg = c(2, 3, 2, 5, 3, 4, 6, 4, 6, 4, NA, 8))

# Example 1: Lagged variable for 'pos'
lagged(dat$pos, id = dat$subject, day = dat$day)

# Example 1b: Alternative specification without using the '...' argument
lagged(dat[, c("pos", "subject", "day")], id = "subject", day = "day")

# Example 1c: Alternative specification using the 'data' argument
lagged(pos, data = dat, id = "subject", day = "day")

# Example 2a: Lagged variable for 'pos' and 'neg'
lagged(dat[, c("pos", "neg")], id = dat$subject, day = dat$day)

# Example 2b: Alternative specification using the 'data' argument
lagged(pos, neg, data = dat, id = "subject", day = "day")

# Example 3: Lag-2 variables for 'pos' and 'neg'
lagged(pos, neg, data = dat, id = "subject", day = "day", lag = 2)

# Example 4: Lagged variable and time difference variable
lagged(pos, neg, data = dat, id = "subject", day = "day", time = "time")

# Example 5: Lagged variables and time difference variables,
# name variables
lagged(pos, neg, data = dat, id = "subject", day = "day", time = "time",
       name = c("p.lag1", "n.lag1"), name.td = c("p.diff", "n.diff"))

# Example 6: NA observations excluded from the data frame
dat.excl &lt;- dat[!is.na(dat$pos), ]

# Number of observation not taken into account, i.e.,
# - observation 4 used as lagged value for observation 6 for subject 1
# - observation 1 used as lagged value for observation 3 for subject 2
lagged(pos, data = dat.excl, id = "subject", day = "day")

# Number of observation taken into account by specifying the 'ob' argument
lagged(pos, data = dat.excl, id = "subject", day = "day", obs = "obs")
</code></pre>

<hr>
<h2 id='libraries'>Load and Attach Multiple Packages</h2><span id='topic+libraries'></span>

<h3>Description</h3>

<p>This function loads and attaches multiple add-on packages at once.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>libraries(..., install = FALSE, quiet = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="libraries_+3A_...">...</code></td>
<td>
<p>the names of the packages to be loaded, given as names
(e.g., <code>misty, lavaan, lme4</code>), or  literal character
strings (e.g., <code>"misty", "lavaan", "lme4"</code>), or character
vector (e.g., <code>c("misty", "lavaan", "lme4")</code>).</p>
</td></tr>
<tr><td><code id="libraries_+3A_install">install</code></td>
<td>
<p>logical: if <code>TRUE</code>, missing packages and dependencies are
installed.</p>
</td></tr>
<tr><td><code id="libraries_+3A_quiet">quiet</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), startup messages when loading
package are disabled.</p>
</td></tr>
<tr><td><code id="libraries_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, argument specification is checked.</p>
</td></tr>
<tr><td><code id="libraries_+3A_output">output</code></td>
<td>
<p>logical: logical: if <code>TRUE</code>, output is shown on the console.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+library">library</a></code>, <code><a href="base.html#topic+require">require</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Load packages using the names of the packages
misty::libraries(misty, lme4, lmerTest)

# Example 2: Load packages using literal character strings
misty::libraries("misty", "lme4", "lmerTest")

# Example 3: Load packages using a character vector
misty::libraries(c("misty", "lme4", "lmerTest"))

# Example 4: Check packages, i.e., TRUE = all depends/imports/suggests installed
misty::libraries(misty, lme4, lmerTest, output = FALSE)$result$restab

# Example 5: Depends, FALSE = not installed, TRUE = installed
misty::libraries(misty, lme4, lmerTest, output = FALSE)$result$depends

# Example 6: Imports, FALSE = not installed, TRUE = installed
misty::libraries(misty, lme4, lmerTest, output = FALSE)$result$imports

# Example 6: Suggests, FALSE = not installed, TRUE = installed
misty::libraries(misty, lme4, lmerTest, output = FALSE)$result$suggests

## End(Not run)
</code></pre>

<hr>
<h2 id='mplus'>Create, Run, and Print Mplus Models</h2><span id='topic+mplus'></span>

<h3>Description</h3>

<p>This wrapper function creates a Mplus input file, runs the input file by using
the <code>mplus.run()</code> function, and prints the Mplus output file by using the
<code>mplus.print()</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplus(x, file = "Mplus_Input.inp", data = NULL, comment = FALSE,
      replace.inp = TRUE, mplus.run = TRUE, show.out = FALSE,
      replace.out = c("always", "never", "modified"), Mplus = .detect.mplus(),
      print = c("all", "input", "result"),
      input = c("all", "default", "data", "variable", "define", "analysis",
                "model", "montecarlo", "mod.pop", "mod.cov", "mod.miss",
                "message"),
      result = c("all", "default", "summary.analysis.short",
                 "summary.data.short", "random.starts", "summary.fit",
                 "mod.est", "fit", "class.count", "classif", "mod.result",
                 "total.indirect"),
      exclude = NULL, variable = FALSE, not.input = TRUE, not.result = TRUE,
      write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplus_+3A_x">x</code></td>
<td>
<p>a character string containing the Mplus input text.</p>
</td></tr>
<tr><td><code id="mplus_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the Mplus input
file with or without the file extension <code>.inp</code>, e.g.,
<code>"Mplus_Input.inp"</code> or <code>"Mplus_Input"</code>.</p>
</td></tr>
<tr><td><code id="mplus_+3A_data">data</code></td>
<td>
<p>a matrix or data frame from which the variables names for
the subsection <code>NAMES</code> are extracted.</p>
</td></tr>
<tr><td><code id="mplus_+3A_comment">comment</code></td>
<td>
<p>logical: if <code>FALSE</code> (default), comments (i.e., text
after the <code>!</code> symbol) are removed from the input text
specified in the argument <code>x</code>.</p>
</td></tr>
<tr><td><code id="mplus_+3A_replace.inp">replace.inp</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), an existing input
file will be replaced.</p>
</td></tr>
<tr><td><code id="mplus_+3A_mplus.run">mplus.run</code></td>
<td>
<p>logical: if <code>TRUE</code>, the input file specified in the
argument <code>file</code> containing the input text specified
in the argument <code>x</code> is run using the <code>mplus.run()</code>
function.</p>
</td></tr>
<tr><td><code id="mplus_+3A_show.out">show.out</code></td>
<td>
<p>logical: if <code>TRUE</code>, estimation output (<code>TECH8</code>)
is show on the R console. Note that if run within Rgui,
output will display within R, but if run via Rterm, a
separate window will appear during estimation.</p>
</td></tr>
<tr><td><code id="mplus_+3A_replace.out">replace.out</code></td>
<td>
<p>a character string for specifying three settings:
<code>"always"</code> (default), which runs all models, regardless
of whether an output file for the model exists, <code>"never"</code>,
which does not run any model that has an existing output file,
and <code>"modified"</code>, which only runs a model if the
modified date for the input file is more recent than the
output file modified date.</p>
</td></tr>
<tr><td><code id="mplus_+3A_mplus">Mplus</code></td>
<td>
<p>a character string for specifying the name or path of the
Mplus executable to be used for running models. This covers
situations where Mplus is not in the system's path, or where
one wants to test different versions of the Mplus program.
Note that there is no need to specify this argument for most
users since it has intelligent defaults.</p>
</td></tr>
<tr><td><code id="mplus_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e.
<code>"all"</code> (default) for all results <code>"input"</code> for
input command sections, and <code>"result"</code> for result sections.</p>
</td></tr>
<tr><td><code id="mplus_+3A_input">input</code></td>
<td>
<p>a character vector specifying Mplus input command sections
included in the output (see 'Details' in the <code><a href="#topic+mplus.print">mplus.print</a></code>
function).</p>
</td></tr>
<tr><td><code id="mplus_+3A_result">result</code></td>
<td>
<p>a character vector specifying Mplus result sections included
in the output (see 'Details' in the <code><a href="#topic+mplus.print">mplus.print</a></code>
function).</p>
</td></tr>
<tr><td><code id="mplus_+3A_exclude">exclude</code></td>
<td>
<p>a character vector specifying Mplus input command or result
sections excluded from the output (see 'Details' in the
<code><a href="#topic+mplus.print">mplus.print</a></code> function).</p>
</td></tr>
<tr><td><code id="mplus_+3A_variable">variable</code></td>
<td>
<p>logical: if <code>TRUE</code>, names of the variables in the data
set (<code>NAMES ARE</code>) specified in the <code>VARIABLE:</code>
command section are shown. By default, names of the variables
in the data set are excluded from the output unless all variables
are used in the analysis (i.e., no <code>USEVARIABLES</code> option
specified in the Mplus input file).</p>
</td></tr>
<tr><td><code id="mplus_+3A_not.input">not.input</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the input commands not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="mplus_+3A_not.result">not.result</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the result sections not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="mplus_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>).</p>
</td></tr>
<tr><td><code id="mplus_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="mplus_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="mplus_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console by using the function <code>mplus.print()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>The <code>NAMES</code> Option</strong></dt><dd><p>The <code>NAMES</code> option in the <code>VARIABLE</code>
section used to assign names to the variables in the data set can be specified by using the
<code>data</code> argument:
</p>

<ul>
<li><p><code>Write Mplus Data File</code>: In the first step, the Mplus data
file is written by using the <code>write.mplus()</code> function, e.g.
<code>write.mplus(ex3_1, file = "ex3_1.dat")</code>.
</p>
</li>
<li><p><code>Specify Mplus Input</code>: In the second step, the Mplus input
is specified as a character string. The <code>NAMES</code> option is left out
from the Mplus input text, e.g.,
<code>input &lt;- 'DATA:     FILE IS ex3_1.dat;\nMODEL:    y1 ON x1 x3;'</code>.
</p>
</li>
<li><p><code>Run Mplus Input</code>: In the third step, the Mplus input is run
by using the <code>mplus()</code> function. The argument <code>data</code>
needs to be specified given that the <code>NAMES</code> option was left out from
the Mplus input text in the previous step, e.g.,
<code>mplus(input, file = "ex3_1.inp", data = ex3_1)</code>.
</p>
</li></ul>

</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>a character vector containing the Mplus input text</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>input</code></td>
<td>
<p>list with input command sections</p>
</td></tr>
<tr><td><code>write</code></td>
<td>
<p>write command sections</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with input command sections (<code>input</code>) and
result sections (<code>result</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>, <code><a href="#topic+mplus.update">mplus.update</a></code>,
<code><a href="#topic+mplus.print">mplus.print</a></code>, <code><a href="#topic+mplus.plot">mplus.plot</a></code>, <code><a href="#topic+mplus.bayes">mplus.bayes</a></code>,
<code><a href="#topic+mplus.run">mplus.run</a></code>, <code><a href="#topic+mplus.lca">mplus.lca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Example 1: Write data, specify input, and run input

# Write Mplus Data File
write.mplus(ex3_1, file = "ex3_1.dat")

# Specify Mplus input, specify NAMES option
input1 &lt;- '
DATA:     FILE IS ex3_1.dat;
VARIABLE: NAMES ARE y1 x1 x3;
MODEL:    y1 ON x1 x3;
OUTPUT:   SAMPSTAT;
'

# Run Mplus input
mplus(input1, file = "ex3_1.inp")

#----------------------------------------------------------------------------
# Example 2: Alternative specification using the data argument

# Specify Mplus input, leave out the NAMES option
input2 &lt;- '
DATA:     FILE IS ex3_1.dat;
MODEL:    y1 ON x1 x3;
OUTPUT:   SAMPSTAT;
'

# Run Mplus input, specify the data argument
mplus(input2, file = "ex3_1.inp", data = ex3_1)

## End(Not run)
</code></pre>

<hr>
<h2 id='mplus.bayes'>Mplus Summary Measures, Convergence and Efficiency Diagnostics</h2><span id='topic+mplus.bayes'></span>

<h3>Description</h3>

<p>This function uses the <code>h5file</code> function in the <span class="pkg">hdf5r</span> package to
read a Mplus GH5 file that is requested by the command <code>PLOT: TYPE IS PLOT2</code>
in Mplus to compute point estimates (i.e., mean, median, and MAP), measures of dispersion
(i.e., standard deviation and mean absolute deviation), measures of shape (i.e.,
skewness and kurtosis), credible intervals (i.e., equal-tailed intervals and
highest density interval), convergence and efficiency diagnostics (i.e., potential
scale reduction factor R-hat, effective sample size, and Monte Carlo standard error),
probability of direction, and probability of being in the region of practical
equivalence for the posterior distribution for each parameter. By default, the
function computes the maximum of rank-normalized split-R-hat and rank normalized
folded-split-R-hat, Bulk effective sample size
(Bulk-ESS) for rank-normalized values using split chains, tail effective sample
size (Tail-ESS) defined as the minimum of the effective sample size for 0.025 and
0.975 quantiles, the Bulk Monte Carlo standard error (Bulk-MCSE) for the median
and Tail Monte Carlo standard error (Tail-MCSE) defined as the maximum of the MCSE
for 0.025 and 0.975 quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplus.bayes(x,
            print = c("all", "default", "m", "med", "map", "sd", "mad",
                      "skew", "kurt", "eti", "hdi",
                      "rhat", "b.ess", "t.ess", "b.mcse", "t.mcse"),
            param = c("all", "on", "by", "with", "inter", "var", "r2", "new"),
            std = c("all", "none", "stdyx", "stdy", "std"),
            m.bulk = FALSE, split = TRUE, rank = TRUE, fold = TRUE,
            pd = FALSE, null = 0, rope = NULL,
            ess.tail = c(0.025, 0.975), mcse.tail = c(0.025, 0.975),
            alternative = c("two.sided", "less", "greater"),
            conf.level = 0.95, digits = 2, r.digits = 3, ess.digits = 0,
            mcse.digits = 3, p.digits = 3, write = NULL, append = TRUE,
            check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplus.bayes_+3A_x">x</code></td>
<td>
<p>a character string indicating the name of the Mplus GH5 file
(HDF5 format) with or without the file extension <code>.gh5</code>,
e.g., <code>"Mplus_Plot.gh5"</code> or <code>"Mplus_Plot"</code>.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_print">print</code></td>
<td>
<p>a character vector indicating which summary measures,
convergence, and efficiency diagnostics to be printed on
the console, i.e. <code>"all"</code> for all summary measures,
convergence, and efficiency diagnostics, <code>"m"</code> for the
mean, <code>"med"</code> for the median, <code>"MAP"</code> for the
maximum a posteriori probability estimate, <code>"med"</code>
for the standard deviation, <code>"mad"</code> for the mean
absolute deviation, <code>"skew"</code> for the skewness,
<code>"kurt"</code> for the kurtosis, <code>"eti"</code> for the
equal-tailed credible interval, <code>"hdi"</code> for the
highest density credible interval, <code>"rhat"</code> for the
potential scale reduction (PSR) factor R-hat convergence
diagnostic, <code>"b.ess"</code> for the bulk effective sample
size (ESS), <code>"t.ess"</code> for the tail ESS, <code>"b.mcse"</code>
for the bulk Monte Carlo standard error (MCSE), and
<code>"t.mcse"</code> for the tail MCSE. The default setting is
<code>print = c("med", "sd", "skew", "kurt", "eti", "rhat", "b.ess", "t.ess", "b.mcse", "t.mcse")</code>.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_param">param</code></td>
<td>
<p>character vector indicating which parameters to print
for the summary measures, convergence, and efficiency
diagnostics, i.e., <code>"all"</code> for all parameters,
<code>"on"</code> (default), for regression slopes, <code>"by"</code>
for factor loadings, <code>"with"</code> for covariances,
<code>"inter"</code> for intercepts and thresholds, <code>"var"</code>
for (residual) variances, <code>"r2"</code> for r-square, and
<code>"new"</code> for parameters not in the analysis model
specified in the <code>NEW</code> option. The default setting
is <code>"on"</code> if regression slopes are available. Otherwise,
the default setting switches to <code>"by"</code> and to
<code>"with"</code> if factor loadings are not available.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_std">std</code></td>
<td>
<p>a character vector indicating the standardized
parameters to print for the summary measures, convergence,
and efficiency diagnostics, i.e., <code>"all"</code> for all
standardized parameters, <code>"none"</code> (default) for not
printing any standardized parameters, <code>"stdyx"</code> for
StdYX standardized parameters, <code>"stdy"</code> for StdY
standardized parameters, and <code>"std"</code> for StdX
standardized parameters.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_m.bulk">m.bulk</code></td>
<td>
<p>logical: if <code>TRUE</code> the Monte Carlo standard error for the mean
is computed. The default setting is <code>m.bulk = FALSE</code>, i.e., the Monte Carlo
standard error for the median is computed.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), each MCMC chain is split
in half before computing R-hat. Note that the argument
<code>split</code> is always set to <code>FALSE</code> when computing
ESS.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_rank">rank</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), rank-normalization is
applied to the posterior draws before computing R-hat and ESS. Note that
the argument <code>rank</code> is always set to <code>FALSE</code> when computing MCSE.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_fold">fold</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the maximum of
rank-normalized split-R-hat and rank normalized folded-split-R-hat
is computed. Note that the arguments <code>split</code> and
<code>rank</code> are always set to <code>TRUE</code> when specifying
<code>fold = TRUE</code>.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_pd">pd</code></td>
<td>
<p>logical: if <code>TRUE</code>, the probability of direction is
printed on the console.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_null">null</code></td>
<td>
<p>a numeric value considered as a null effect for the probability
of direction (default is <code>0</code>). Note that the value
specified in the argument <code>null</code> applies to all parameters
which might not be sensible for all parameters.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_rope">rope</code></td>
<td>
<p>a numeric vector with two elements indicating the ROPE's
lower and upper bounds. ROPE is also depending on the argument
<code>alternative</code>, e.g., if <code>rope = c(-0.1, 0.1)</code>,
then the actual ROPE is <code>[-0.1, 0.1]</code> given
<code>alternative = "two.sided} (default), \code{[-Inf, 0.1]}
given \code{alternative = "greater</code>, and <code>[-0.1, Inf]</code>
given <code>alternative = "less"</code>. Note that the interval
specified in the argument <code>rope</code> applies to all parameters
which might not be sensible for all parameters.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_ess.tail">ess.tail</code></td>
<td>
<p>a numeric vector with two elements to specify the quantiles
for computing the tail ESS. The default setting is
<code>tail = c(0.025, 0.975)</code>, i.e., tail ESS is the minimum
of effective sample sizes for 5% and 95% quantiles.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_mcse.tail">mcse.tail</code></td>
<td>
<p>a numeric vector with two elements to specify the quantiles
for computing the tail MCSE. The default setting is
<code>tail = c(0.025, 0.975)</code>, i.e., tail MCSE is the maximum
of Monte Carlo standard error for 5% and 95% quantiles.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis
for the credible intervals, must be one of <code>"two.sided"</code>
(default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the credible interval. The default setting is <code>conf.level = 0.95</code>.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying point estimates, measures of
dispersion, and credible intervals.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_r.digits">r.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying R-hat values.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_ess.digits">ess.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying effective sample sizes.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_mcse.digits">mcse.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying Monte Carlo standard errors.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the probability of direction
and the probability of being in the region of practical
equivalence (ROPE).</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="mplus.bayes_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console by using the function <code>mplus.print()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Convergence and Efficiency Diagnostics for Markov Chains</strong></dt><dd><p>Convergence
and efficiency diagnostics for Markov chains is based on following numeric
measures:
</p>

<ul>
<li><p><strong>Potential Scale Reduction (PSR) factor R-hat</strong>: The PSR factor
R-hat compares the between- and within-chain variance for a model
parameter, i.e., R-hat larger than 1 indicates that the between-chain
variance is greater than the within-chain variance and chains have not
mixed well. According to the default setting, the function computes the
improved R-hat as recommended by Vehtari et al. (2020) based on rank-normalizing
(i.e., <code>rank = TRUE</code>) and folding (i.e., <code>fold = TRUE</code>) the
posterior draws after splitting each MCMC chain in half (i.e.,
<code>split = TRUE</code>). The traditional R-hat used in Mplus can be requested
by specifying <code>split = FALSE</code>, <code>rank = FALSE</code>, and
<code>fold = FALSE</code>. Note that the traditional R-hat can catch many
problems of poor convergence, but fails if the chains have different
variances with the same mean parameter or if the chains have infinite
variance with one of the chains having a different location parameter to
the others (Vehtari et al., 2020). According to Gelman et al. (2014) a
R-hat value of 1.1 or smaller for all parameters can be considered evidence
for convergence. The Stan Development Team (2024) recommends running at
least four chains and a convergence criterion of less than 1.05 for the
maximum of rank normalized split-R-hat and rank normalized folded-split-R-hat.
Vehtari et al. (2020), however, recommended to only use the posterior
samples if R-hat is less than 1.01 because the R-hat can fall below 1.1
well before convergence in some scenarios (Brooks &amp; Gelman, 1998; Vats &amp;
Knudon, 2018).
</p>
</li>
<li><p><strong>Effective Sample Size (ESS)</strong>: The ESS is the estimated number
of independent samples from the posterior distribution that would lead
to the same precision as the autocorrelated samples at hand. According
to the default setting, the function computes the ESS based on rank-normalized
split-R-hat and within-chain autocorrelation. The function provides the
estimated Bulk-ESS (<code>B.ESS</code>) and the Tail-ESS (<code>T.ESS</code>). The
Bulk-ESS is a useful measure for sampling efficiency in the bulk of the
distribution (i.e, efficiency of the posterior mean), and the Tail-ESS
is useful measure for sampling efficiency in the tails of the distribution
(e.g., efficiency of tail quantile estimates). Note that by default, the
Tail-ESS is the minimum of the effective sample sizes for 5% and 95%
quantiles (<code>tail = c(0.025, 0.975)</code>). According to Kruschke (2015),
a rank-normalized ESS greater than 400 is usually sufficient to get a
stable estimate of the Monte Carlo standard error. However, a ESS of
at least 1000 is considered optimal (Zitzmann &amp; Hecht, 2019).
</p>
</li>
<li><p><strong>Monte Carlo Standard Error (MCSE)</strong>: The MCSE is defined as
the standard deviation of the chains divided by their effective sample
size and reflects uncertainty due to the stochastic algorithm of the
Markov Chain Monte Carlo method. The function provides the estimated
Bulk-MCSE (<code>B.MCSE</code>) for the margin of error when using the MCMC
samples to estimate the posterior mean and the Tail-ESS (<code>T.MCSE</code>)
for the margin of error when using the MCMC samples for interval
estimation.
</p>
</li></ul>

</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>Mplus GH5 file</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>three-dimensional array parameter x iteration x chain of
the posterior</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table with summary measures, convergence, and
efficiency diagnostics</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is a modified copy of functions provided in the <span class="pkg">rstan</span>
package by Stan Development Team (2024) and <span class="pkg">bayestestR</span> package by
Makowski et al. (2019).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Brooks, S. P. and Gelman, A. (1998). General Methods for Monitoring Convergence
of Iterative Simulations. <em>Journal of Computational and Graphical Statistics, 7</em>(4):
434–455. MR1665662.
</p>
<p>Gelman, A., &amp; Rubin, D.B. (1992). Inference from iterative simulation using
multiple sequences. <em>Statistical Science, 7</em>, 457-472.
https://doi.org/10.1214/ss/1177011136
</p>
<p>Kruschke, J. (2015). <em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em>.
Academic Press.
</p>
<p>Makowski, D., Ben-Shachar, M., &amp; Lüdecke, D. (2019). bayestestR: Describing
effects and their uncertainty, existence and significance within the Bayesian
framework. <em>Journal of Open Source Software, 4</em>(40), 1541.
https://doi.org/10.21105/joss.01541
</p>
<p>Stan Development Team (2024). <em>RStan: the R interface to Stan</em>. R package
version 2.32.6. https://mc-stan.org/.
</p>
<p>Vats, D. and Knudson, C. (2018). Revisiting the Gelman-Rubin Diagnostic.
arXiv:1812.09384.
</p>
<p>Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; Bürkner, P.-C. (2020).
Rank-normalization, folding, and localization: An improved R-hat for assessing
convergence of MCMC. <em>Bayesian analysis, 16</em>(2), 667-718.
https://doi.org/110.1214/20-BA1221
</p>
<p>Zitzmann, S., &amp; Hecht, M. (2019). Going beyond convergence in Bayesian estimation:
Why precision matters too and how to assess it. <em>Structural Equation Modeling:
A Multidisciplinary Journal, 26</em>(4), 646–661. https://doi.org/10.1080/10705511.2018.1545232
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>, <code><a href="#topic+mplus">mplus</a></code>,
<code><a href="#topic+mplus.update">mplus.update</a></code>, <code><a href="#topic+mplus.print">mplus.print</a></code>, <code><a href="#topic+mplus.plot">mplus.plot</a></code>,
<code><a href="#topic+mplus.run">mplus.run</a></code>, <code><a href="#topic+mplus.lca">mplus.lca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Mplus Example 3.18: Moderated Mediation with a Plot of the Indirect Effect

# Example 1: Default setting
mplus.bayes("ex3.18.gh5")

# Example 2: Print all parameters
mplus.bayes("ex3.18.gh5", param = "all")

# Example 3: Print parameters not in the analysis model
mplus.bayes("ex3.18.gh5", param = "new")

# Example 4a: Print all summary measures, convergence, and efficiency diagnostics
mplus.bayes("ex3.18.gh5", print = "all")

# Example 4a: Print default measures plus MAP
mplus.bayes("ex3.18.gh5", print = c("default", "map"))

# Example 5: Print traditional R-hat in line with Mplus
mplus.bayes("ex3.18.gh5", split = FALSE, rank = FALSE, fold = FALSE)

# Example 6: Print probability of direction and the probability of
# being ROPE [-0.1, 0.1]
mplus.bayes("ex3.18.gh5", pd = TRUE, rope = c(-0.1, 0.1))

# Example 7: Write Results into a text file
mplus.bayes("ex3.18.gh5", write = "Bayes_Summary.txt")

# Example 8b: Write Results into a Excel file
mplus.bayes("ex3.18.gh5", write = "Bayes_Summary.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='mplus.lca'>Mplus Model Specification for Latent Class Analysis</h2><span id='topic+mplus.lca'></span>

<h3>Description</h3>

<p>This function writes Mplus input files for conducting latent class analysis (LCA)
for continuous, count, ordered categorical, and unordered categorical variables.
LCA with continuous indicator variables are based on six different
variance-covariance structures, while LCA for all other variable types assume
local independence. By default, the function conducts LCA with continuous
variables and creates folders in the current working directory for each of the
six sets of analysis, writes Mplus input files for conducting LCA with
<em>k</em> = 1 to <em>k</em> = 6 classes into these folders, and writes the matrix
or data frame specified in <code>x</code> into a Mplus data file in the current working
directory. Optionally, all models can be estimated by setting the argument
<code>mplus.run</code> to <code>TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplus.lca(x, ind = NULL,
          type = c("continuous", "count", "categorical", "nominal"), cluster = NULL,
          folder = c("A_Invariant-Theta_Diagonal-Sigma",
                     "B_Varying-Theta_Diagonal-Sigma",
                     "C_Invariant-Theta_Invariant-Unrestrictred-Sigma",
                     "D_Invariant-Theta_Varying-Unrestricted-Sigma",
                     "E_Varying-Theta_Invariant-Unrestricted-Sigma",
                     "F_Varying-Theta_Varying-Unrestricted-Sigma"),
          file = "Data_LCA.dat", write = c("all", "folder", "data", "input"),
          useobservations = NULL, missing = -99, classes = 6, estimator = "MLR",
          starts = c(100, 50), stiterations = 10, lrtbootstrap = 1000,
          lrtstarts = c(0, 0, 100, 50), processors = c(8, 8),
         output = c("all", "SVALUES", "CINTERVAL", "TECH7", "TECH8", "TECH11", "TECH14"),
          replace.inp = FALSE, mplus.run = FALSE, Mplus = "Mplus",
          replace.out = c("always", "never", "modified"), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplus.lca_+3A_x">x</code></td>
<td>
<p>a matrix or data frame. Note that all variable names must
be no longer than 8 character.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_ind">ind</code></td>
<td>
<p>a character vector indicating the variables names of the
latent class indicators in <code>x</code>.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_type">type</code></td>
<td>
<p>a character string indicating the variable type of the
latent class indicators, i.e., <code>"continuous"</code> (default)
for continuous variables, <code>"count"</code> for count variables,
<code>"categorical"</code> for binary or ordered categorical
variables, and <code>"nominal"</code> for unordered categorical
variables. Note that it is not possible to mix different
variable types in the analysis.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the cluster variable in
the matrix or data frame specified in <code>x</code> representing
the nested grouping structure for computing cluster-robust
standard errors. Note that specifying a cluster variables
does not have any effect on the information criteria,
but on the Vuong-Lo-Mendell-Rubin likelihood ratio test
of model fit.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_folder">folder</code></td>
<td>
<p>a character vector with six character strings for specifying
the names of the six folder representing different
variance-covariance structures for conducting LCA with
continuous indicator variables. There is only one folder
for LCA with all other variable types which is called
<code>"LCA_1-x_Classes"</code> with <code>x</code> being the maximum number of classes
specified in the argument <code>classes</code>.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_file">file</code></td>
<td>
<p>a character string naming the Mplus data file with or
without the file extension '.dat', e.g., <code>"Data_LCA.dat"</code>
(default) or <code>"Data_LCA"</code>.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_write">write</code></td>
<td>
<p>a character string or character vector indicating whether
to create the six folders specified in the argument
<code>folder</code> (<code>"folder"</code>), to write the matrix or
data frame specified in <code>x</code> into a Mplus data file
(<code>"data"</code>), and write the Mplus input files into
the six folders specified in the argument <code>folder</code>
(<code>"input"</code>). By default, the function creates the
folders, writes the Mplus data file, and writes the Mplus
input files into the folders.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_useobservations">useobservations</code></td>
<td>
<p>a character string indicating the conditional statement
to select observations.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_missing">missing</code></td>
<td>
<p>a numeric value or character string representing missing
values (<code>NA</code>) in the Mplus data set. This values
or character string will be specified in the Mplus input
file as <code>MISSING IS ALL(missing)</code>. By default,
<code>-99</code> is used to represent missing values.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_classes">classes</code></td>
<td>
<p>an integer value specifying the maximum number of classes
for the latent class analysis. By default, LCA with
a maximum of 6 classes is specified (i.e., <em>k</em> = 1
to <em>k</em> = 6).</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_estimator">estimator</code></td>
<td>
<p>a character string for specifying the <code>ESTIMATOR</code>
option in Mplus. By default, the estimator <code>"MLR"</code>
is used.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_starts">starts</code></td>
<td>
<p>a vector with two integer values for specifying the
<code>STARTS</code> option in Mplus. The first number represents
the number of random sets of starting values to generate
in the initial stage and the second number represents the
optimizations to use in the final stage. By default, 500
random sets of starting values are generated and 100
optimizations are carried out in the final stage.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_stiterations">stiterations</code></td>
<td>
<p>an integer value specifying the <code>STITERATIONS</code> option
in Mplus. The numeric value represents the maximum number
of iterations allowed in the initial stage. By default,
50 iterations are requested.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_lrtbootstrap">lrtbootstrap</code></td>
<td>
<p>an integer value for specifying the <code>LRTBOOTSTRAP</code>
option in Mplus when requesting a parametric bootstrapped
likelihood ratio test (i.e., <code>output = "TECH14"</code>).
The value represents the number of bootstrap draws to
be used in estimating the <em>p</em>-value of the parametric
bootstrapped likelihood ratio test. By default, 1000
bootstrap draws are requested.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_lrtstarts">lrtstarts</code></td>
<td>
<p>a vector with four integer values for specifying the
<code>LRTSTARTS</code> option in Mplus when requesting a
parametric bootstrapped likelihood ratio test (i.e.,
<code>output = "TECH14"</code>). The values specify the number
of starting values to use in the initial stage and the
number of optimizations to use in the final stage for
the <code>k - 1</code> and <code>k</code> classes model when the
data generated by bootstrap draws are analyzed. By default,
0 random sets of starting values in the initial stage
and 0 optimizations in the final stage are used for the
<code>k - 1</code> classes model and 100 random sets of starting
values in the initial stage and 50 optimizations in the
final stage are used for the <code>k</code> class model.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_processors">processors</code></td>
<td>
<p>a vector of one or two integer values for specifying the
<code>PROCESSORS</code> option in Mplus. The values specifies
the number of processors and threads to be used for
parallel computing to increase computational speed. By
default, 8 processors and threads are used for parallel
computing.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_output">output</code></td>
<td>
<p>a character string or character vector specifying the
<code>TECH</code> options in the <code>OUTPUT</code> section in Mplus,
i.e., <code>SVALUES</code> to request input statements that
contain parameter estimates from the analysis, <code>CINTERVAL</code>
to request confidence intervals, <code>TECH7</code> to request
sample statistics for each class using raw data weighted
by the estimated posterior probabilities for each class,
<code>TECH8</code> to request the optimization history in
estimating the model, <code>TECH11</code> to request the
Lo-Mendell-Rubin likelihood ratio test of model fit,
and <code>TECH14</code> to request a parametric bootstrapped
likelihood ratio test. By default, <code>SVALUES</code> and
<code>TECH11</code> are requested. Note that <code>TECH11</code>
is only available for the <code>MLR</code> estimator.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_replace.inp">replace.inp</code></td>
<td>
<p>logical: if <code>TRUE</code>, all existing input files in the
folder specified in the argument <code>folder</code> are replaced.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_mplus.run">mplus.run</code></td>
<td>
<p>logical: if <code>TRUE</code>, all models in the folders specified
in the argument <code>folder</code> are estimated by using the
<code>mplus.run</code> function in the R package <code>misty</code>.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_mplus">Mplus</code></td>
<td>
<p>a character string for specifying the name or path of
the Mplus executable to be used for running models. This
covers situations where Mplus is not in the system's path,
or where one wants to test different versions of the Mplus
program. Note that there is no need to specify this argument
for most users since it has intelligent defaults.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_replace.out">replace.out</code></td>
<td>
<p>a character string for specifying three settings, i.e.,
<code>"always"</code> to run all models regardless of whether
an output file for the model exists, <code>"never"</code>
to not run any model that has an existing output file,
and <code>"modified"</code> (default) to only runs a model if the
modified date for the input file is more recent than
the output file modified date.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Latent class analysis (LCA) is a model-based clustering and classification
method used to identify qualitatively different classes of observations which
are unknown and must be inferred from the data. LCA can accommodate continuous,
count, binary, ordered categorical, and unordered categorical indicators. LCA
with continuous indicator variables are also known as latent profile analysis
(LPA). In LPA, the within-profile variance-covariance structures represent
different assumptions regarding the variance and covariance of the indicator
variables both within and between latent profiles. As the best within-profile
variance-covariance structure is not known a priori, all of the different
structures must be investigated to identify the best model (Masyn, 2013). This
function specifies six different variance-covariance structures labeled A to F
(see Table 1 in Patterer et al, 2023):
</p>

<dl>
<dt><strong>Model A</strong></dt><dd><p>The within-profile variance is constrained to be
profile-invariant and covariances are constrained to be 0 in all profiles
(i.e., equal variances across profiles and no covariances among indicator
variables). This is the default setting in Mplus.</p>
</dd>
<dt><strong>Model B</strong></dt><dd><p>The within-profile variance is profile-varying and
covariances are constrained to be 0 in all profiles (i.e., unequal variances
across profiles and no covariances among indicator variables).</p>
</dd>
<dt><strong>Model C</strong></dt><dd><p>The within-profile variance is constrained to be
profile-invariant and covariances are constrained to be equal in all profiles
(i.e., equal variances and covariances across profiles).</p>
</dd>
<dt><strong>Model D</strong></dt><dd><p>The within-profile variance is constrained to be
profile-invariant and covariances are profile-varying (i.e., equal variances
across profiles and unequal covariances across profiles).</p>
</dd>
<dt><strong>Model E</strong></dt><dd><p>The within-profile variances are profile-varying and
covariances are constrained to be equal in all profiles (i.e., unequal
variances across profiles and equal covariances across profiles).</p>
</dd>
<dt><strong>Model F</strong></dt><dd><p>The within-class variance and covariances are both
profile-varying (i.e., unequal variances and covariances across profiles).</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>matrix or data frame specified in the argument x</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with six entries for each of the variance-covariance
structures and Mplus inputs based on different number
of profiles in case of continuous indicators or list of
Mplus inputs based on different number of classes in case
of count, ordered or unordered categorical indicators.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Masyn, K. E. (2013). Latent class analysis and finite mixture modeling. In T. D.
Little (Ed.), <em>The Oxford handbook of quantitative methods: Statistical analysis</em>
(pp. 551–611). Oxford University Press.
</p>
<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>
<p>Patterer, A. S., Yanagida, T., Kühnel, J., &amp; Korunka, C. (2023). Daily receiving
and providing of social support at work: Identifying support exchange patterns
in hierarchical data. <em>Journal of Work and Organizational Psychology, 32</em>(4),
489-505. https://doi.org/10.1080/1359432X.2023.2177537
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>, <code><a href="#topic+mplus">mplus</a></code>,
<code><a href="#topic+mplus.update">mplus.update</a></code>, <code><a href="#topic+mplus.print">mplus.print</a></code>, <code><a href="#topic+mplus.plot">mplus.plot</a></code>,
<code><a href="#topic+mplus.bayes">mplus.bayes</a></code>, <code><a href="#topic+mplus.run">mplus.run</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

#-------------------------------------------------------------------------------
# Example 1: LCA with k = 1 to k = 8 profiles, continuous indicators
# Input statements that contain parameter estimates
# Vuong-Lo-Mendell-Rubin LRT and bootstrapped LRT
mplus.lca(HolzingerSwineford1939, ind = c("x1", "x2", "x3", "x4"),
          classes = 8, output = c("SVALUES", "TECH11", "TECH14"))

#-------------------------------------------------------------------------------
# Example 22: LCA with k = 1 to k = 6 profiles, ordered categorical indicators
# Select observations with ageyr &lt;= 13
# Estimate all models in Mplus
mplus.lca(round(HolzingerSwineford1939[, -5]), ind = c("x1", "x2", "x3", "x4"),
          type = "categorical", useobservations = "ageyr &lt;= 13",
          mplus.run = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='mplus.plot'>Plot Mplus GH5 File</h2><span id='topic+mplus.plot'></span>

<h3>Description</h3>

<p>This function uses the <code>h5file</code> function in the <span class="pkg">hdf5r</span> package to
read a Mplus GH5 file that is requested by the command <code>PLOT: TYPE IS PLOT2</code>
in Mplus to display trace plots, posterior distribution plots, autocorrelation
plots, posterior predictive check plots based on the &quot;bayesian_data&quot; section, and
the loop plot based on the &quot;loop_data&quot; section of the Mplus GH5 file. By default,
the function displays trace plots if the &quot;bayesian_data&quot; section is available in
the Mplus GH5 File. Otherwise, the function plots the loop plot if the &quot;loop_data&quot;
section is available in the Mplus GH5 file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplus.plot(x, plot = c("none", "trace", "post", "auto", "ppc", "loop"),
           param = c("all", "on", "by", "with", "inter", "var", "r2", "new"),
           std = c("all", "none", "stdyx", "stdy", "std"), burnin = TRUE,
           point = c("all", "none", "m", "med", "map"),
           ci = c("none", "eti", "hdi"), chain = 1, conf.level = 0.95,
           hist = TRUE, density = TRUE, area = TRUE, alpha = 0.4,
           fill = "gray85", facet.nrow = NULL, facet.ncol = NULL,
           facet.scales = c("fixed", "free", "free_x", "free_y"),
           xlab = NULL, ylab = NULL, xlim = NULL, ylim = NULL,
           xbreaks = ggplot2::waiver(), ybreaks = ggplot2::waiver(),
           xexpand = ggplot2::waiver(), yexpand = ggplot2::waiver(),
           palette = "Set 2", binwidth = NULL, bins = NULL,
           density.col = "#0072B2", shape = 21,
           point.col = c("#CC79A7", "#D55E00", "#009E73"),
           linewidth = 0.6, linetype = "dashed", line.col = "black",
           bar.col = "black", bar.width = 0.8, plot.margin = NULL,
           legend.title.size = 10, legend.text.size = 10, legend.box.margin = NULL,
           saveplot = c("all", "none", "trace", "post", "auto", "ppc", "loop"),
           filename = "Mplus_Plot.pdf",
           file.plot = c("_TRACE", "_POST", "_AUTO", "_PPC", "_LOOP"),
           width = NA, height = NA, units = c("in", "cm", "mm", "px"),
           dpi = 600, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplus.plot_+3A_x">x</code></td>
<td>
<p>a character string indicating the name of the Mplus
GH5 file (HDF5 format) with or without the file
extension <code>.gh5</code>, e.g., <code>"Mplus_Plot.gh5"</code>
or <code>"Mplus_Plot"</code>. Alternatively, a <code>misty.object</code>
of type <code>mplus</code> can be specified, i.e., result
object of the <code>mplus.plot()</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_plot">plot</code></td>
<td>
<p>a character string indicating the type of plot to
display, i.e., <code>"none"</code> for not displaying any
plot, <code>"trace"</code> (default) for displaying trace
plots, <code>post</code> for displaying posterior distribution
plots, <code>"auto"</code> for displaying autocorrelation
plots, <code>"ppc"</code> for displaying posterior predictive
check plots, and <code>"loop"</code> for displaying the
loop plot. The default setting is <code>"trace"</code> if
the &quot;bayesian_data&quot; section is available in the Mplus
GH5 file. Otherwise, the default setting switches to
<code>"loop"</code>.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_param">param</code></td>
<td>
<p>character vector indicating which parameters to print
for the trace plots, posterior distribution plots,
and autocorrelation plots, i.e., <code>"all"</code> for all
parameters, <code>"on"</code> (default), for regression
slopes, <code>"by"</code> for factor loadings, <code>"with"</code>
for covariances, <code>"inter"</code> for intercepts and
thresholds, <code>"var"</code> for (residual) variances,
<code>"r2"</code> for r-square, and <code>"new"</code> for
parameters not in the analysis model specified in the
<code>NEW</code> option. The default setting is <code>"on"</code>
if regression slopes are available. Otherwise, the
default setting switches to <code>"by"</code> and to
<code>"with"</code> if factor loadings are not available.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_std">std</code></td>
<td>
<p>a character vector indicating the standardized
parameters to print for the trace plots, posterior
distribution plots, and autocorrelation plots, i.e.,
<code>"all"</code> for all standardized parameters,
<code>"none"</code> (default) for not printing any
standardized parameters, <code>"stdyx"</code> for StdYX
standardized parameters, <code>"stdy"</code> for StdY
standardized parameters, and <code>"std"</code> for StdX
standardized parameters.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_burnin">burnin</code></td>
<td>
<p>logical: if <code>FALSE</code>, the first half of each chain
is discarded as being part of the burnin phase when
displaying trace plots. The default setting for
<code>plot = "trace"</code> is <code>TRUE</code>. Note that the
first half of each chain is always discarded when
displaying posterior distribution plots (<code>plot = "post"</code>) regardless
of the setting of the argument <code>burnin</code>.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_point">point</code></td>
<td>
<p>a character vector indicating the point estimate(s)
to be displayed in the posterior distribution plots,
i.e., <code>"all"</code> for all point estimates, <code>"none"</code>
for not displaying any point estimates, <code>"m"</code>
for the posterior mean estimate, <code>"med"</code> (default)
for the posterior median estimate, and <code>"map"</code>
for the maximum a posteriori estimate.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_ci">ci</code></td>
<td>
<p>a character string indicating the type of credible
interval to be displayed in the posterior distribution
plots, i.e., <code>"none"</code> for not displaying any
credible intervals, <code>"eti"</code> (default) for displaying
the equal-tailed intervals and <code>"hdi"</code> for displaying
the highest density interval.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_chain">chain</code></td>
<td>
<p>a numerical value indicating the chain to be used for
the autocorrelation plots. By default, the first
chain is used.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the
confidence level of the credible interval (default is
<code>0.95</code>).</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_hist">hist</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), histograms are
drawn in the posterior probability plots.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_density">density</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), density curves are
drawn in the posterior probability plots.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_area">area</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), statistical not
significant and statistical significant area is
filled with a different color and vertical lines are
drawn.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for the <code>alpha</code>
argument (default is <code>0.4</code>) for the <code>annotate</code>,
<code>geom_histogram</code>, <code>geom_bar</code>, and
<code>geom_ribbon</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_fill">fill</code></td>
<td>
<p>a character string indicating the color for the
<code>"fill"</code> argument (default is <code>"gray85"</code>)
for the <code>annotate</code>, <code>geom_histogram</code>,
<code>geom_bar</code>, and <code>geom_point</code> functions.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_facet.nrow">facet.nrow</code></td>
<td>
<p>a numeric value indicating the <code>nrow</code> argument
(default is <code>NULL</code>) for the <code>facet_wrap</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_facet.ncol">facet.ncol</code></td>
<td>
<p>a numeric value indicating the <code>ncol</code> argument
(default is <code>2</code>) for the <code>facet_wrap</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_facet.scales">facet.scales</code></td>
<td>
<p>a character string indicating the <code>scales</code> argument
(default is <code>"free"</code>) for the <code>facet_wrap</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_xlab">xlab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
for the <code>scale_x_continuous</code> function. Note that
the default setting depends on the type of plot,
e.g., <code>""</code> for the trace plots and <code>"Lag"</code>
for the autocorrelation plots.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_ylab">ylab</code></td>
<td>
<p>a character string indicating the <code>name</code> argument
for the <code>scale_y_continuous</code> function. Note that
the default setting depends on the type of plot,
e.g., <code>""</code> for the trace plots and <code>"Autocorrelation"</code>
for the autocorrelation plots.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_xlim">xlim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument (default it <code>NULL</code>) for
the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>limits</code> argument (default it <code>NULL</code>) for
the <code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_xbreaks">xbreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
(default is <code>ggplot2::waiver()</code>) for the
<code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector indicating the <code>breaks</code> argument
(default is <code>ggplot2::waiver()</code>) for the
<code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_xexpand">xexpand</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>expand</code> argument (default is <code>(0.02, 0)</code>)
for the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_yexpand">yexpand</code></td>
<td>
<p>a numeric vector with two elements indicating the
<code>expand</code> argument for the <code>scale_y_continuous</code>
function. Note that the default setting depends
on the type of plot, e.g., <code>(0.02, 0)</code> for the
trace plots and <code>expansion(mult = c(0, 0.05))</code>
for the posterior distribution plots.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_palette">palette</code></td>
<td>
<p>a character string indicating the palette name (default
is <code>"Set 2"</code>) for the <code>hcl.colors</code> function.
Note that the character string must be one of
<code>hcl.pals()</code>.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_binwidth">binwidth</code></td>
<td>
<p>a numeric value indicating the <code>binwidth</code> argument
(default is to use the number of bins in <code>bins</code>
argument) for the <code>geom_histogram</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_bins">bins</code></td>
<td>
<p>a numeric value indicating the <code>bins</code> argument
(default is <code>30</code>) for the <code>geom_histogram</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_density.col">density.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
(default is <code>"#0072B2"</code>) for the <code>geom_density</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_shape">shape</code></td>
<td>
<p>a numeric value indicating the <code>shape</code> argument
(default is <code>21</code>) for the <code>geom_point</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_point.col">point.col</code></td>
<td>
<p>a character vector with three elements indicating the
<code>values</code> argument (default is
<code>c("#CC79A7", "#D55E00", "#009E73")</code>) for the
<code>scale_color_manual</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_linewidth">linewidth</code></td>
<td>
<p>a numeric value indicating the <code>linewidth</code> argument
(default is <code>0.6</code>) for the <code>geom_vline</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_linetype">linetype</code></td>
<td>
<p>a numeric value indicating the <code>linetype</code> argument
(default is <code>"dashed"</code>) for the <code>geom_vline</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_line.col">line.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
(default is <code>"black"</code>) for the <code>geom_vline</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_bar.col">bar.col</code></td>
<td>
<p>a character string indicating the <code>color</code> argument
(default is <code>"black"</code>) for the <code>geom_bar</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_bar.width">bar.width</code></td>
<td>
<p>a character string indicating the <code>width</code> argument
(default = <code>0.8</code>)for the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_plot.margin">plot.margin</code></td>
<td>
<p>a numeric vector indicating the <code>plot.margin</code>
argument for the <code>theme</code> function. Note that the
default setting depends on the type of the plot, e.g.,
<code>c(4, 15, -10, 0)</code> for the trace plots, and
<code>c(4, 15, 4, 4)</code> for the autocorrelation plots.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_legend.title.size">legend.title.size</code></td>
<td>
<p>a numeric value indicating the <code>legend.title</code>
argument (default is <code>element_text(size = 10)</code>)
for the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>a numeric value indicating the <code>legend.text</code>
argument (default is <code>element_text(size = 10)</code>)
for the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_legend.box.margin">legend.box.margin</code></td>
<td>
<p>a numeric vector indicating the <code>legend.box.margin</code>
argument for the <code>theme</code> function. Note that the
default setting depends on the type of plot, e.g.,
<code>c(-16, 6, 6, 6)</code> for the trace plots, and
<code>c(-25, 6, 6, 6)</code> for the posterior distribution
plots with displaying point estimates.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_saveplot">saveplot</code></td>
<td>
<p>a character vector indicating the plot to be saved,
i.e., <code>"all"</code> for saving all plots, <code>"none"</code>
(default) for not saving any plots, <code>"trace"</code>
for saving the trace plots, <code>post</code> for the saving
the posterior distribution plots, <code>"auto"</code> for
saving the autocorrelation plots, <code>"ppc"</code> for
saving the posterior predictive check plots, and
<code>"loop"</code> for saving the loop plot.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument (default is <code>"Mplus_Plot.pdf"</code>) including
the file extension for the <code>ggsave</code> function.
Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default), <code>".jpeg"</code>,
<code>".tiff"</code>, <code>".png"</code>, <code>".bmp"</code>,
<code>".svg"</code> or <code>".wmf"</code> needs to be specified
as file extension in the <code>filename</code> argument.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_file.plot">file.plot</code></td>
<td>
<p>a character vector with five elements for distinguishing
different types of plots. By default, the character
string specified in the argument <code>"filename"</code>
(<code>"Mplus_Plot"</code>) is concatenated with <code>"_TRACE"</code>
(<code>"Mplus_Plot_TRACE"</code>) for the trace plots,
<code>"_POST"</code> (<code>"Mplus_Plot_POST"</code>) for
the posterior distribution plots, <code>"_AUTO"</code>
(<code>"Mplus_Plot_AUTO"</code>) for the autocorrelation
plots, <code>"_PPC"</code> (<code>"Mplus_Plot_PPC"</code>) for the
posterior predictive check plots, and <code>"_LOOP"</code>
(<code>"Mplus_Plot_LOOP"</code>) for the loop plot.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code>
argument (default is <code>in</code>) for the <code>ggsave</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="mplus.plot_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument
specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>Mplus GH5 file</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with posterior distribution of each parameter estimate
in wide and long format (<code>post</code>), autocorrelation for
each parameter estimate in wide and long format (<code>auto</code>),
data for the posterior predictive check (<code>ppc</code>),
and data for the loop plot (<code>loop</code>)</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>list with the trace plots (<code>trace</code>, posterior distribution
plots (<code>post</code>), autocorrelation plots (<code>auto</code>),
posterior predictive check plots (<code>ppc</code>), and
loop plot (<code>loop</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>, <code><a href="#topic+mplus">mplus</a></code>,
<code><a href="#topic+mplus.update">mplus.update</a></code>, <code><a href="#topic+mplus.print">mplus.print</a></code>, <code><a href="#topic+mplus.bayes">mplus.bayes</a></code>,
<code><a href="#topic+mplus.run">mplus.run</a></code>, <code><a href="#topic+mplus.lca">mplus.lca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Mplus Example 3.18: Moderated Mediation with a Plot of the Indirect Effect

#..........
# Trace Plots

# Example 1a: Default setting
mplus.plot("ex3.18.gh5")

# Example 1b: Exclude first half of each chain
mplus.plot("ex3.18.gh5", burnin = FALSE)

# Example 1c: Print all parameters
mplus.plot("ex3.18.gh5", param = "all")

# Example 1d: Print user-specified parameters
mplus.plot("ex3.18.gh5", param = "param")

# Example 1e: Arrange panels in three columns
mplus.plot("ex3.18.gh5", ncol = 3)

# Example 1f: Specify "Pastel 1" palette for the hcl.colors function
mplus.plot("ex3.18.gh5", palette = "Pastel 1")

#..........
# Posterior Distribution Plots

# Example 2a: Default setting, i.e., posterior median and equal-tailed interval
mplus.plot("ex3.18.gh5", plot = "post")

# Example 2b: Display posterior mean and maximum a posteriori
mplus.plot("ex3.18.gh5", plot = "post", point = c("m", "map"))

# Example 2c: Display maximum a posteriori and highest density interval
mplus.plot("ex3.18.gh5", plot = "post", point = "map", ci = "hdi")

# Example 2d: Do not display any point estimates and credible interval
mplus.plot("ex3.18.gh5", plot = "post", point = "none", ci = "none")

# Example 2d: Do not display histograms
mplus.plot("ex3.18.gh5", plot = "post", hist = FALSE)

#..........
# Autocorrelation Plots

# Example 3a: Default setting, i.e., first chain
mplus.plot("ex3.18.gh5", plot = "auto")

# Example 3b: Use second chain
mplus.plot("ex3.18.gh5", plot = "auto", chain = 2)

# Example 3b: Modify limits and breaks of the y-axis
mplus.plot("ex3.18.gh5", plot = "auto",
           ylim = c(-0.05, 0.05), ybreaks = seq(-0.1, 0.1, by = 0.025))

#..........
# Posterior Predictive Check Plots

# Example 4a: Default setting, i.e., 95% Interval
mplus.plot("ex3.18.gh5", plot = "ppc")

# Example 4b: Default setting, i.e., 99% Interval
mplus.plot("ex3.18.gh5", plot = "ppc", conf.level = 0.99)

#..........
# Loop Plot

# Example 5a: Default setting
mplus.plot("ex3.18.gh5", plot = "loop")

# Example 5b: Do not fill area and draw vertical lines
mplus.plot("ex3.18.gh5", plot = "loop", area = FALSE)

#..........
# Save Plots

# Example 6a: Save all plots in pdf format
mplus.plot("ex3.18.gh5", saveplot = "all")

# Example 6b: Save all plots in png format with 300 dpi
mplus.plot("ex3.18.gh5", saveplot = "all", filename = "Mplus_Plot.png", dpi = 300)

# Example 6a: Save loop plot, specify width and height of the plot
mplus.plot("ex3.18.gh5", plot = "none", saveplot = "loop",
           width = 7.5, height = 7)

#----------------------------------------------------------------------------
# Plot from misty.object

# Create misty.object
object &lt;- mplus.plot("ex3.18.gh5", plot = "none")

# Trace plot
mplus.plot(object, plot = "trace")

# Posterior distribution plot
mplus.plot(object, plot = "post")

# Autocorrelation plot
mplus.plot(object, plot = "auto")

# Posterior predictive check plot
mplus.plot(object, plot = "ppc")

# Loop plot
mplus.plot(object, plot = "loop")

#----------------------------------------------------------------------------
# Create Plots Manually

# Load ggplot2 package
library(ggplot2)

# Create misty object
object &lt;- mplus.plot("ex3.18.gh5", plot = "none")

#..........
# Example 7: Trace Plots

# Extract data in long format
data.post &lt;- object$data$post$long

# Extract ON parameters
data.trace &lt;- data.post[grep(" ON ", data.post$param), ]

# Plot
ggplot(data.trace, aes(x = iter, y = value, color = chain)) +
  annotate("rect", xmin = 0, xmax = 15000, ymin = -Inf, ymax = Inf,
           alpha = 0.4, fill = "gray85") +
  geom_line() +
  facet_wrap(~ param, ncol = 2, scales = "free") +
  scale_x_continuous(name = "", expand = c(0.02, 0)) +
  scale_y_continuous(name = "", expand = c(0.02, 0)) +
  scale_colour_manual(name = "Chain",
                      values = hcl.colors(n = 2, palette = "Set 2")) +
  theme_bw() +
  guides(color = guide_legend(nrow = 1, byrow = TRUE)) +
  theme(plot.margin = margin(c(4, 15, -10, 0)),
        legend.position = "bottom",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.box.margin = margin(c(-16, 6, 6, 6)),
        legend.background = element_rect(fill = "transparent"))

#..........
# Example 8: Posterior Distribution Plots

# Extract data in long format
data.post &lt;- object$data$post$long

# Extract ON parameters
data.post &lt;- data.post[grep(" ON ", data.post$param), ]

# Discard burn-in iterations
data.post &lt;- data.post[data.post$iter &gt; 15000, ]

# Drop factor levels
data.post$param &lt;- droplevels(data.post$param,
                              exclude = c("[Y]", "[M]", "Y", "M", "INDIRECT", "MOD"))

# Plot
ggplot(data.post, aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), color = "black", alpha = 0.4,
                 fill = "gray85") +
  geom_density(color = "#0072B2") +
  geom_vline(data = data.frame(param = unique(data.post$param),
                               stat = tapply(data.post$value, data.post$param, median)),
             aes(xintercept = stat, color = "Median"), linewidth = 0.6) +
  geom_vline(data = data.frame(param = unique(data.post$param),
                               low = tapply(data.post$value, data.post$param,
                                            function(y) quantile(y, probs = 0.025))),
             aes(xintercept = low), linetype = "dashed", linewidth = 0.6) +
  geom_vline(data = data.frame(param = unique(data.post$param),
                               upp = tapply(data.post$value, data.post$param,
                                            function(y) quantile(y, probs = 0.975))),
             aes(xintercept = upp), linetype = "dashed", linewidth = 0.6) +
  facet_wrap(~ param, ncol = 2, scales = "free") +
  scale_x_continuous(name = "", expand = c(0.02, 0)) +
  scale_y_continuous(name = "Probability Density, f(x)",
                     expand = expansion(mult = c(0L, 0.05))) +
  scale_color_manual(name = "Point Estimate", values = c(Median = "#D55E00")) +
  labs(caption = "95% Equal-Tailed Interval") +
  theme_bw() +
  theme(plot.margin = margin(c(4, 15, -8, 4)),
        plot.caption = element_text(hjust = 0.5, vjust = 7),
        legend.position = "bottom",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.box.margin = margin(c(-30, 6, 6, 6)),
        legend.background = element_rect(fill = "transparent"))

#..........
# Example 9: Autocorrelation Plots

# Extract data in long format
data.auto &lt;- object$data$auto$long

# Select first chain
data.auto &lt;- data.auto[data.auto$chain == 1, ]

# Extract ON parameters
data.auto &lt;- data.auto[grep(" ON ", data.auto$param), ]

# Plot
ggplot(data.auto, aes(x = lag, y = cor)) +
  geom_bar(stat = "identity", alpha = 0.4, color = "black", fill = "gray85",
           width = 0.8) +
  facet_wrap(~ param, ncol = 2) +
  scale_x_continuous(name = "Lag", breaks = seq(1, 30, by = 2), expand = c(0.02, 0)) +
  scale_y_continuous(name = "Autocorrelation", limits = c(-0.1, 0.1),
                     breaks = seq(-0.1, 1., by = 0.05), expand = c(0.02, 0)) +
  theme_bw() +
  theme(plot.margin = margin(c(4, 15, 4, 4)))

#..........
# Example 10: Posterior Predictive Check (PPC) Plots

# Extract data
data.ppc &lt;- object$data$ppc

# Scatter plot
ppc.scatter &lt;- ggplot(data.ppc, aes(x = obs, y = rep)) +
  geom_point(shape = 21, fill = "gray85") +
  geom_abline(slope = 1) +
  scale_x_continuous("Observed", limits = c(0, 45), breaks = seq(0, 45, by = 5),
                     expand = c(0.02, 0)) +
  scale_y_continuous("Recpliated", limits = c(0, 45), breaks = seq(0, 45, by = 5),
                     expand = c(0.02, 0)) +
  theme_bw() +
  theme(plot.margin = margin(c(2, 15, 4, 4)))

# Histogram
ppc.hist &lt;- ggplot(data.ppc, aes(x = diff)) +
  geom_histogram(color = "black", alpha = 0.4, fill = "gray85") +
  geom_vline(xintercept = mean(data.ppc$diff), color = "#CC79A7") +
  geom_vline(xintercept = quantile(data.ppc$diff, probs = 0.025),
             linetype = "dashed", color = "#CC79A7") +
  geom_vline(xintercept = quantile(data.ppc$diff, probs = 0.975),
             linetype = "dashed", color = "#CC79A7") +
  scale_x_continuous("Observed - Replicated", expand = c(0.02, 0)) +
  scale_y_continuous("Count", expand = expansion(mult = c(0L, 0.05))) +
  theme_bw() +
  theme(plot.margin = margin(c(2, 15, 4, 4)))

# Combine plots using the patchwork package
patchwork::wrap_plots(ppc.scatter, ppc.hist)

#..........
# Example 11: Loop Plot

# Extract data
data.loop &lt;- object$data$loop

# Plot
plot.loop &lt;- ggplot(data.loop, aes(x = xval, y = estimate)) +
  geom_line(linewidth = 0.6, show.legend = FALSE) +
  geom_line(aes(xval, low)) +
  geom_line(aes(xval, upp)) +
  scale_x_continuous("MOD", expand = c(0.02, 0)) +
  scale_y_continuous("INDIRECT", expand = c(0.02, 0)) +
  scale_fill_manual("Statistical Significance",
                    values = hcl.colors(n = 2, palette = "Set 2")) +
  theme_bw() +
  theme(plot.margin = margin(c(4, 15, -6, 4)),
        legend.position = "bottom",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        legend.box.margin = margin(-10, 6, 6, 6),
        legend.background = element_rect(fill = "transparent"))

# Significance area
for (i in unique(data.loop$group)) {

  plot.loop &lt;- plot.loop + geom_ribbon(data = data.loop[data.loop$group == i, ],
                                       aes(ymin = low, ymax = upp, fill = sig), alpha = 0.4)

}

# Vertical lines
plot.loop + geom_vline(data = data.loop[data.loop$change == 1, ],
                       aes(xintercept = xval, color = sig), linewidth = 0.6,
                           linetype = "dashed", show.legend = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='mplus.print'>Print Mplus Output</h2><span id='topic+mplus.print'></span>

<h3>Description</h3>

<p>This function prints the input command sections and the result sections of a Mplus
output file (<code>.out</code>) on the R console. By default, the function prints
selected result sections, e.g., short <code>Summary of Analysis</code>, short
<code>Summary of Data</code>, <code>Model Fit Information</code>, and <code>Model Results</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplus.print(x, print = c("all", "input", "result"),
            input = c("all", "default", "data", "variable", "define",
                      "analysis", "model", "montecarlo", "mod.pop", "mod.cov",
                      "mod.miss", "message"),
             result = c("all", "default", "summary.analysis.short",
                        "summary.data.short", "random.starts", "summary.fit",
                        "mod.est", "fit", "class.count", "classif",
                        "mod.result", "total.indirect"),
             exclude = NULL, variable = FALSE, not.input = TRUE, not.result = TRUE,
             write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplus.print_+3A_x">x</code></td>
<td>
<p>a character string indicating the name of the Mplus output
file with or without the file extension <code>.out</code>, e.g.,
<code>"Mplus_Output.out"</code> or <code>"Mplus_Output"</code>.
Alternatively, a <code>misty.object</code> of type <code>mplus</code>
can be specified, i.e., result object of the <code>mplus.print()</code>,
<code>mplus()</code> or <code>mplus.update()</code> function.</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_print">print</code></td>
<td>
<p>a character vector indicating which section to show, i.e.
<code>"all"</code> for input and result sections, <code>"input"</code>
for input command section only, and <code>"result"</code> (default)
for result sections only</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_input">input</code></td>
<td>
<p>a character vector specifying Mplus input command sections</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_result">result</code></td>
<td>
<p>a character vector specifying Mplus result sections included
in the output (see 'Details').</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_exclude">exclude</code></td>
<td>
<p>a character vector specifying Mplus input command or result
sections excluded from the output (see 'Details').</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_variable">variable</code></td>
<td>
<p>logical: if <code>TRUE</code>, names of the variables in the data
set (<code>NAMES</code> option) specified in the <code>VARIABLE:</code>
command section are shown. By default, names of the variables
in the data set are excluded from the output unless all variables
are used in the analysis (i.e., no <code>USEVARIABLES</code> option
specified in the Mplus input file).</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_not.input">not.input</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the input commands not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_not.result">not.result</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the result sections not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>).</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="mplus.print_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Input Command Sections</strong></dt><dd><p>Following input command sections can be
selected by using the <code>input</code> argument or excluded by using the <code>exclude</code>
argument:
</p>

<ul>
<li><p><code>"title"</code> for the <code>TITLE</code> command used to provide a title
for the analysis.
</p>
</li>
<li><p><code>"data"</code> for the <code>DATA</code> command used to provide information
about the data set to be analyzed.
</p>
</li>
<li><p><code>"data.imp"</code> for the <code>DATA IMPUTATION</code> command used to
create a set of imputed data sets using multiple imputation methodology.
</p>
</li>
<li><p><code>"data.wl"</code> for the <code>DATA WIDETOLONG</code> command used to
rearrange data from a multivariate wide format to a univariate long format.
</p>
</li>
<li><p><code>"data.lw"</code> for the <code>DATA LONGTOWIDE</code> command used to
rearrange a univariate long format to a multivariate wide format.
</p>
</li>
<li><p><code>"data.tp"</code> for the <code>DATA TWOPART</code> command used to create
a binary and a continuous variable from a continuous variable with a floor
effect for use in two-part modeling.
</p>
</li>
<li><p><code>"data.miss"</code> for the <code>DATA MISSING</code> command used to
create a set of binary variables that are indicators of missing data or
dropout for another set of variables.
</p>
</li>
<li><p><code>"data.surv"</code> for the <code>DATA SURVIVAL</code> command used to
create variables for discrete-time survival modeling.
</p>
</li>
<li><p><code>"data.coh"</code> for the <code>DATA COHORT</code> command used to
rearrange longitudinal data from a format where time points represent
measurement occasions to a format where time points represent age or
another time-related variable,
</p>
</li>
<li><p><code>"variable"</code> for the <code>VARIABLE</code> command used to provide
information about the variables in the data set to be analyzed.
</p>
</li>
<li><p><code>"define"</code> for the <code>DEFINE</code> command used to transform
existing variables and to create new variables.
</p>
</li>
<li><p><code>"analysis"</code> for the <code>ANALYSIS</code> command used to describe
the technical details for the analysis.
</p>
</li>
<li><p><code>"model"</code> <code>MODEL</code> for the command used to describe the
model to be estimated.
</p>
</li>
<li><p><code>"mod.ind"</code> for the <code>MODEL INDIRECT</code> command used to
request indirect and directed effects and their standard errors.
</p>
</li>
<li><p><code>"mod.test"</code> for the <code>MODEL TEST</code> command used to
test restrictions on the parameters in the <code>MODEL</code> and <code>MODEL CONSTRAINT</code>
commands using the Wald chi-square test.
</p>
</li>
<li><p><code>"mod.prior"</code> for the <code>MODEL PRIORS</code> command used with
<code>ESTIMATOR IS BAYES</code> to specify the prior distribution for each
parameter.
</p>
</li>
<li><p><code>"montecarlo"</code> for the <code>MONTECARLO</code> command used to set
up and carry out a Monte Carlo simulation study.
</p>
</li>
<li><p><code>"mod.pop"</code> for the <code>MODEL POPULATION</code> command used
to provide the population parameter values to be used in data generation
using the options of the <code>MODEL</code> command.
</p>
</li>
<li><p><code>"mod.cov"</code> for the <code>MODEL COVERAGE</code> used to provide
the population parameter values to be used for computing coverage.
</p>
</li>
<li><p><code>"mod.miss"</code>  for the <code>MODEL MISSING</code> command used to
provide information about the population parameter values for the missing
data model to be used in the generation of data.
</p>
</li>
<li><p><code>"output"</code> for the  for the <code>OUTPUT</code> command used to
request additional output beyond that included as the default.
</p>
</li>
<li><p><code>"savedata"</code> for the <code>SAVEDATA</code> command used to save
the analysis data and/or a variety of model results in an ASCII file for
future use.
</p>
</li>
<li><p><code>"plot"</code> for the <code>PLOT</code> command used to requested graphical
displays of observed data and analysis results.
</p>
</li>
<li><p><code>"message"</code> for warning and error messages that have been
generated by the program after the input command sections.
</p>
</li></ul>

<p>Note that all input command sections are requested by specifying <code>input = "all"</code>.
The <code>input</code> argument is also used to select one (e.g., <code>input = "model"</code>)
or more than one input command sections (e.g., <code>input = c("analysis", "model")</code>),
or to request input command sections in addition to the default setting (e.g.,
<code>input = c("default", "output")</code>). The <code>exclude</code> argument is used
to exclude input command sections from the output (e.g., exclude = &quot;variable&quot;).
</p>
</dd>
<dt><strong>Result Sections</strong></dt><dd><p>Following result sections can be selected by
using the <code>result</code> argument or excluded by using the <code>exclude</code>
argument:
</p>

<ul>
<li><p><code>"summary.analysis"</code> for the <code>SUMMARY OF ANALYSIS</code> section..
</p>
</li>
<li><p><code>"summary.analysis.short"</code> for a short <code>SUMMARY OF ANALYSIS</code> section including the number of observations, number of groups, estimator, and optimization algorithm.
</p>
</li>
<li><p><code>"summary.data"</code> for the <code>SUMMARY OF DATA</code> section indicating.
</p>
</li>
<li><p><code>"summary.data.short"</code> for a short <code>SUMMARY OF DATA</code> section including number of clusters, average cluster size, and estimated intraclass correlations.
</p>
</li>
<li><p><code>"prop.count"</code> for the <code>UNIVARIATE PROPORTIONS AND COUNTS FOR CATEGORICAL VARIABLES</code> section.
</p>
</li>
<li><p><code>"summary.censor"</code> for the <code>SUMMARY OF CENSORED LIMITS</code> section.
</p>
</li>
<li><p><code>"prop.zero"</code> for the <code>COUNT PROPORTION OF ZERO, MINIMUM AND MAXIMUM VALUES</code> section.
</p>
</li>
<li><p><code>"crosstab"</code> for the <code>CROSSTABS FOR CATEGORICAL VARIABLES</code> section.
</p>
</li>
<li><p><code>"summary.miss"</code> for the <code>SUMMARY OF MISSING DATA PATTERNS</code> section.
</p>
</li>
<li><p><code>"coverage"</code> for the <code>COVARIANCE COVERAGE OF DATA</code> section.
</p>
</li>
<li><p><code>"basic"</code> for the <code>RESULTS FOR BASIC ANALYSIS</code> section.
</p>
</li>
<li><p><code>"sample.stat"</code> for the <code>SAMPLE STATISTICS</code> section.
</p>
</li>
<li><p><code>"uni.sample.stat"</code> for the <code>UNIVARIATE SAMPLE STATISTICS</code> section.
</p>
</li>
<li><p><code>"random.starts"</code> for the <code>RANDOM STARTS RESULTS</code> section.
</p>
</li>
<li><p><code>"summary.fit"</code> for the <code>SUMMARY OF MODEL FIT INFORMATION</code> section.
</p>
</li>
<li><p><code>"mod.est"</code> for the <code>THE MODEL ESTIMATION TERMINATED NORMALLY</code> message and warning messages from the model estimation.
</p>
</li>
<li><p><code>"fit"</code> for the <code>MODEL FIT INFORMATION</code> section.
</p>
</li>
<li><p><code>"class.count"</code> for the <code>FINAL CLASS COUNTS AND PROPORTIONS FOR THE LATENT CLASSES</code> section.
</p>
</li>
<li><p><code>"ind.means"</code> for the <code>LATENT CLASS INDICATOR MEANS AND PROBABILITIES</code> section.
</p>
</li>
<li><p><code>"trans.prob"</code> for the <code>LATENT TRANSITION PROBABILITIES BASED ON THE ESTIMATED MODEL</code> section.
</p>
</li>
<li><p><code>"classif"</code> for the <code>CLASSIFICATION QUALITY</code> section.
</p>
</li>
<li><p><code>"mod.result"</code> for the <code>MODEL RESULTS</code> and <code>RESULTS FOR EXPLORATORY FACTOR ANALYSIS</code> section.
</p>
</li>
<li><p><code>"odds.ratio"</code> for the <code>LOGISTIC REGRESSION ODDS RATIO RESULTS</code> section.
</p>
</li>
<li><p><code>"prob.scale"</code> for the <code>RESULTS IN PROBABILITY SCALE</code> section.
</p>
</li>
<li><p><code>"ind.odds.ratio"</code> for the <code>LATENT CLASS INDICATOR ODDS RATIOS FOR THE LATENT CLASSES</code> section.
</p>
</li>
<li><p><code>"alt.param"</code> for the <code>ALTERNATIVE PARAMETERIZATIONS FOR THE CATEGORICAL LATENT VARIABLE REGRESSION</code> section.
</p>
</li>
<li><p><code>"irt.param"</code> for the <code>IRT PARAMETERIZATION</code> section.
</p>
</li>
<li><p><code>"brant.wald"</code> for the <code>BRANT WALD TEST FOR PROPORTIONAL ODDS</code> section.
</p>
</li>
<li><p><code>"std.mod.result"</code> for the <code>STANDARDIZED MODEL RESULTS</code> section.
</p>
</li>
<li><p><code>"rsquare"</code> for the <code>R-SQUARE</code> section.
</p>
</li>
<li><p><code>"total.indirect"</code> for the <code>TOTAL, TOTAL INDIRECT, SPECIFIC INDIRECT, AND DIRECT EFFECTS</code> section.
</p>
</li>
<li><p><code>"std.total.indirect"</code> for the <code>STANDARDIZED TOTAL, TOTAL INDIRECT, SPECIFIC INDIRECT, AND DIRECT EFFECTS</code> section.
</p>
</li>
<li><p><code>"std.mod.result.cluster"</code> for the <code>WITHIN-LEVEL STANDARDIZED MODEL RESULTS FOR CLUSTER</code> section.
</p>
</li>
<li><p><code>"fs.comparison"</code> for the <code>BETWEEN-LEVEL FACTOR SCORE COMPARISONS</code> section.
</p>
</li>
<li><p><code>"conf.mod.result"</code> for the <code>CONFIDENCE INTERVALS OF MODEL RESULTS</code> section.
</p>
</li>
<li><p><code>"conf.std.conf"</code> for the <code>CONFIDENCE INTERVALS OF STANDARDIZED MODEL RESULTS</code> section.
</p>
</li>
<li><p><code>"conf.total.indirect"</code> for the <code>CONFIDENCE INTERVALS OF TOTAL, TOTAL INDIRECT, SPECIFIC INDIRECT, AND DIRECT EFFECTS</code> section.
</p>
</li>
<li><p><code>"conf.odds.ratio"</code> for the <code>CONFIDENCE INTERVALS FOR THE LOGISTIC REGRESSION ODDS RATIO RESULTS</code> section.
</p>
</li>
<li><p><code>"modind"</code> for the <code>MODEL MODIFICATION INDICES</code> section.
</p>
</li>
<li><p><code>"resid"</code> for the <code>RESIDUAL OUTPUT</code> section.
</p>
</li>
<li><p><code>"logrank"</code> for the <code>LOGRANK OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech1"</code> for the <code>TECHNICAL 1 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech2"</code> for the <code>TECHNICAL 2 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech3"</code> for the <code>TECHNICAL 3 OUTPUT</code> section.
</p>
</li>
<li><p><code>"h1.tech3"</code> for the <code>H1 TECHNICAL 3 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech4"</code> for the <code>TECHNICAL 4 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech5"</code> for the <code>TECHNICAL 5 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech6"</code> for the <code>TECHNICAL 6 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech7"</code> for the <code>TECHNICAL 7 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech8"</code> for the <code>TECHNICAL 8 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech9"</code> for the <code>TECHNICAL 9 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech10"</code> for the <code>TECHNICAL 10 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech11"</code> for the <code>TECHNICAL 11 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech12"</code> for the <code>TECHNICAL 12 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech13"</code> for the <code>TECHNICAL 13 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech14"</code> for the <code>TECHNICAL 14 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech15"</code> for the <code>TECHNICAL 15 OUTPUT</code> section.
</p>
</li>
<li><p><code>"tech16"</code> for the <code>TECHNICAL 16 OUTPUT</code> section.
</p>
</li>
<li><p><code>"svalues"</code> for the <code>MODEL COMMAND WITH FINAL ESTIMATES USED AS STARTING VALUES</code> section.
</p>
</li>
<li><p><code>"stat.fscores"</code> for the <code>SAMPLE STATISTICS FOR ESTIMATED FACTOR SCORES</code> section.
</p>
</li>
<li><p><code>"summary.fscores"</code> for the <code>SUMMARY OF FACTOR SCORES</code> section.
</p>
</li>
<li><p><code>"pv"</code> for the <code>SUMMARIES OF PLAUSIBLE VALUES</code> section.
</p>
</li>
<li><p><code>"plotinfo"</code> for the <code>PLOT INFORMATION</code> section.
</p>
</li>
<li><p><code>"saveinfo"</code> for the <code>SAVEDATA INFORMATION</code> section.
</p>
</li></ul>

<p>Note that all result sections are requested by specifying <code>result = "all"</code>.
The <code>result</code> argument is also used to select one (e.g., <code>result = "mod.result"</code>)
or more than one result sections (e.g., <code>result = c("mod.result", "std.mod.result")</code>),
or to request result sections in addition to the default setting (e.g.,
<code>result = c("default", "odds.ratio")</code>). The <code>exclude</code> argument is used
to exclude result sections from the output (e.g., <code>exclude = "mod.result"</code>).
</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>character string or misty object</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>print</code></td>
<td>
<p>print objects</p>
</td></tr>
<tr><td><code>notprint</code></td>
<td>
<p>character vectors indicating the input commands and
result sections not requested</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with input command sections (<code>input</code>) and result
sections (<code>input</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>, <code><a href="#topic+mplus">mplus</a></code>,
<code><a href="#topic+mplus.update">mplus.update</a></code>, <code><a href="#topic+mplus.plot">mplus.plot</a></code>, <code><a href="#topic+mplus.bayes">mplus.bayes</a></code>,
<code><a href="#topic+mplus.run">mplus.run</a></code>, <code><a href="#topic+mplus.lca">mplus.lca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Mplus Example 3.1: Linear Regression

# Example 1a: Default setting
mplus.print("ex3.1.out")

# Example 1b:  Print result section only
mplus.print("ex3.1.out", print = "result")

# Example 1c: Print MODEL RESULTS only
mplus.print("ex3.1.out", print = "result", result = "mod.result")

# Example 1d: Print UNIVARIATE SAMPLE STATISTICS in addition to the default setting
mplus.print("ex3.1.out", result = c("default", "uni.sample.stat"))

# Example 1e: Exclude MODEL FIT INFORMATION section
mplus.print("ex3.1.out", exclude = "fit")

# Example 1f: Print all result sections, but exclude MODEL FIT INFORMATION section
mplus.print("ex3.1.out", result = "all", exclude = "fit")

# Example 1g: Print result section in a different order
mplus.print("ex3.1.out", result = c("mod.result", "fit", "summary.analysis"))

#----------------------------------------------------------------------------
# misty.object of type 'mplus.print'

# Example 2
# Create misty.object
object &lt;- mplus.print("ex3.1.out", output = FALSE)

# Print misty.object
mplus.print(object)

#----------------------------------------------------------------------------
# Write Results

# # Example 3: Write Results into a text file
mplus.print("ex3.1.out", write = "Output_3-1.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='mplus.run'>Run Mplus Models</h2><span id='topic+mplus.run'></span>

<h3>Description</h3>

<p>This function runs a group of Mplus models (<code>.inp</code> files) located within
a single directory or nested within subdirectories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplus.run(target = getwd(), recursive = FALSE, filefilter = NULL, show.out = FALSE,
          replace.out = c("always", "never", "modified"), message = TRUE,
          logFile = NULL, Mplus = .detect.mplus(), killOnFail = TRUE,
          local_tmpdir = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplus.run_+3A_target">target</code></td>
<td>
<p>a character string indicating the directory containing
Mplus input files (<code>.inp</code>)
to run or the single <code>.inp</code> file to be run. May be
a full path, relative path, or a filename within the working
directory.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_recursive">recursive</code></td>
<td>
<p>logical: if <code>TRUE</code>, run all models nested in subdirectories
within directory. Not relevant if target is a single file.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_filefilter">filefilter</code></td>
<td>
<p>a Perl regular expression (PCRE-compatible) specifying particular
input files to be run within directory. See regex or
http://www.pcre.org/pcre.txt for details about regular
expression syntax. Not relevant if target is a single file.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_show.out">show.out</code></td>
<td>
<p>logical: if <code>TRUE</code>, estimation output (<code>TECH8</code>)
is show on the R console. Note that if run within Rgui,
output will display within R, but if run via Rterm,
a separate window will appear during estimation.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_replace.out">replace.out</code></td>
<td>
<p>a character string for specifying three settings:
<code>"always"</code> (default), which runs all models, regardless
of whether an output file for the model exists, <code>"never"</code>,
which does not run any model that has an existing output file,
and <code>"modified"</code>, which only runs a model if the
modified date for the input file is more recent than the
output file modified date.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_message">message</code></td>
<td>
<p>logical: if <code>TRUE</code>, message <code>Running model:</code>
and <code>System command:</code> is printed on the console.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_logfile">logFile</code></td>
<td>
<p>a character string specifying a file that records the settings
passed into the function and the models run (or skipped)
during the run.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_mplus">Mplus</code></td>
<td>
<p>a character string for specifying the name or path of the
Mplus executable to be used for running models. This covers
situations where Mplus is not in the system's path, or where
one wants to test different versions of the Mplus program.
Note that there is no need to specify this argument for most
users since it has intelligent defaults.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_killonfail">killOnFail</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), all processes named mplus.exe when
<code>mplus.run()</code> does not terminate normally are killed.
Windows only.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_local_tmpdir">local_tmpdir</code></td>
<td>
<p>logical: if <code>TRUE</code>, the TMPDIR environment variable
is set to the location of the <code>.inp file</code> prior to
execution. This is useful in Monte Carlo studies where many
instances of Mplus may run in parallel and we wish to avoid
collisions in temporary files among processes. Linux/Mac only.</p>
</td></tr>
<tr><td><code id="mplus.run_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification, convergence
and model identification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Note</h3>

<p>This function is a copy of the <code>runModels()</code> function in the
<span class="pkg">MplusAutomation</span> package by Michael Hallquist and Joshua Wiley (2018).
</p>


<h3>Author(s)</h3>

<p>Michael Hallquist and Joshua Wiley
</p>


<h3>References</h3>

<p>Hallquist, M. N. &amp; Wiley, J. F. (2018). MplusAutomation: An R package for facilitating
large-scale latent variable analyses in Mplus. <em>Structural Equation Modeling:
A Multidisciplinary Journal, 25</em>, 621-638. https://doi.org/10.1080/10705511.2017.1402334.
</p>
<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>, <code><a href="#topic+mplus">mplus</a></code>,
<code><a href="#topic+mplus.update">mplus.update</a></code>, <code><a href="#topic+mplus.print">mplus.print</a></code>, <code><a href="#topic+mplus.plot">mplus.plot</a></code>,
<code><a href="#topic+mplus.bayes">mplus.bayes</a></code>, <code><a href="#topic+mplus.lca">mplus.lca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Run Mplus models located within a single directory
mplus.run(Mplus = "C:/Program Files/Mplus/Mplus.exe")

# Example 2: Run Mplus models located nested within subdirectories
mplus.run(recursive = TRUE,
          Mplus = "C:/Program Files/Mplus/Mplus.exe")

## End(Not run)
</code></pre>

<hr>
<h2 id='mplus.update'>Mplus Input Updating</h2><span id='topic+mplus.update'></span>

<h3>Description</h3>

<p>This function updates specific input command sections of a <code>misty.object</code>
of type <code>mplus</code> to create an updated Mplus input file, run the updated
input file by using the <code>mplus.run()</code> function, and print the updated Mplus
output file by using the <code>mplus.print()</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplus.update(x, update, file = "Mplus_Input_Update.inp", comment = FALSE,
             replace.inp = TRUE, mplus.run = TRUE,
             show.out = FALSE, replace.out = c("always", "never", "modified"),
             print = c("all", "input", "result"),
             input = c("all", "default", "data", "variable", "define",
                       "analysis", "model", "montecarlo", "mod.pop", "mod.cov",
                       "mod.miss", "message"),
             result = c("all", "default", "summary.analysis.short",
                        "summary.data.short", "random.starts", "summary.fit",
                        "mod.est", "fit", "class.count", "classif",
                        "mod.result", "total.indirect"),
             exclude = NULL, variable = FALSE, not.input = TRUE, not.result = TRUE,
             write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplus.update_+3A_x">x</code></td>
<td>
<p><code>misty.object</code> object of type <code>mplus</code>.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_update">update</code></td>
<td>
<p>a character string containing the updated input command
sections.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the updated Mplus
input file with or without the file extension <code>.inp</code>,
e.g., <code>"Mplus_Input_Update.inp"</code> or <code>"Mplus_Input_Update"</code>.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_comment">comment</code></td>
<td>
<p>logical: if <code>FALSE</code> (default), comments (i.e., text
after the <code>!</code> symbol) are removed from the input text
specified in the argument <code>x</code>.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_replace.inp">replace.inp</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), an existing input
file will be replaced.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_mplus.run">mplus.run</code></td>
<td>
<p>logical: if <code>TRUE</code>, the input file specified in the
argument <code>file</code> containing the input text specified
in the argument <code>x</code> is run using the <code>mplus.run</code>
function.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_show.out">show.out</code></td>
<td>
<p>logical: if <code>TRUE</code>, estimation output (<code>TECH8</code>)
is show on the R console. Note that if run within Rgui,
output will display within R, but if run via Rterm, a
separate window will appear during estimation.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_replace.out">replace.out</code></td>
<td>
<p>a character string for specifying three settings:
<code>"always"</code> (default), which runs all models, regardless
of whether an output file for the model exists, <code>"never"</code>,
which does not run any model that has an existing output file,
and <code>"modified"</code>, which only runs a model if the
modified date for the input file is more recent than the
output file modified date.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_print">print</code></td>
<td>
<p>a character string indicating which results to show, i.e.
<code>"all"</code> (default) for all results <code>"input"</code> for
input command sections, and <code>"result"</code> for result sections.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_input">input</code></td>
<td>
<p>a character vector specifying Mplus input command sections
included in the output (see 'Details' in the <code><a href="#topic+mplus.print">mplus.print</a></code>
function).</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_result">result</code></td>
<td>
<p>a character vector specifying Mplus result sections included
in the output (see 'Details' in the <code><a href="#topic+mplus.print">mplus.print</a></code>
function).</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_exclude">exclude</code></td>
<td>
<p>a character vector specifying Mplus input command or result
sections excluded from the output (see 'Details' in the
<code><a href="#topic+mplus.print">mplus.print</a></code> function).</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_variable">variable</code></td>
<td>
<p>logical: if <code>TRUE</code>, names of the variables in the data
set (<code>NAMES ARE</code>) specified in the <code>VARIABLE:</code>
command section are shown. By default, names of the variables
in the data set are excluded from the output unless all variables
are used in the analysis (i.e., no <code>USEVARIABLES</code> command
specified in the Mplus input file).</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_not.input">not.input</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the input commands not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_not.result">not.result</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), character vector indicating
the result sections not requested are shown on the console.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>).</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="mplus.update_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the
console by using the function <code>mplus.print</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Mplus Input Sections</strong></dt><dd><p>The function is used to update
following Mplus input sections:
</p>

<ul>
<li><p><code>TITLE</code>
</p>
</li>
<li><p><code>DATA</code>
</p>
</li>
<li><p><code>DATA IMPUTATION</code>
</p>
</li>
<li><p><code>DATA WIDETOLONG</code>
</p>
</li>
<li><p><code>DATA LONGTOWIDE</code>
</p>
</li>
<li><p><code>DATA TWOPARTE</code>
</p>
</li>
<li><p><code>DATA MISSING</code>
</p>
</li>
<li><p><code>DATA SURVIVAL</code>
</p>
</li>
<li><p><code>DATA COHORT</code>
</p>
</li>
<li><p><code>VARIABLE</code>
</p>
</li>
<li><p><code>DEFINE</code>
</p>
</li>
<li><p><code>ANALYSIS</code>
</p>
</li>
<li><p><code>MODEL</code>
</p>
</li>
<li><p><code>MODEL INDIRECT</code>
</p>
</li>
<li><p><code>MODEL CONSTRAINT</code>
</p>
</li>
<li><p><code>MODEL TEST</code>
</p>
</li>
<li><p><code>MODEL PRIORS</code>
</p>
</li>
<li><p><code>MODEL MONTECARLO</code>
</p>
</li>
<li><p><code>MODEL POPULATION</code>
</p>
</li>
<li><p><code>MODEL COVERAGE</code>
</p>
</li>
<li><p><code>MODEL MISSING</code>
</p>
</li>
<li><p><code>OUTPUT</code>
</p>
</li>
<li><p><code>SAVEDATA</code>
</p>
</li>
<li><p><code>PLOT</code>
</p>
</li></ul>

</dd>
<dt><strong>The <code>...;</code> Specification</strong></dt><dd><p>The <code>...;</code> Specification
is used to update specific options in the <code>VARIABLE</code> and <code>ANALYSIS</code>
section, while keeping all other options in the <code>misty.object</code> of type
<code>mplus</code> specified in the argument <code>x</code>. The <code>...;</code> specification
is only available for the <code>VARIABLE</code> and <code>ANALYSIS</code> section. Note
that <code>...;</code> including the semicolon <code>;</code> needs to be specified,
i.e., <code>...</code> without the semicolon <code>;</code> will result in an error message.</p>
</dd>
<dt><strong>The <code>---;</code> Specification</strong></dt><dd><p>The <code>---;</code> specification is
used to remove entire sections (e.g., <code>OUTPUT: ---;</code>) or options within the
<code>VARIABLE:</code> and <code>ANALYSIS:</code> section (e.g., <code>ANALYSIS: ESTIMATOR IS ---;</code>)
from the Mplus input. Note that <code>---;</code> including the semicolon <code>;</code>
needs to be specified, i.e., <code>---</code> without the semicolon <code>;</code> will
result in an error message.</p>
</dd>
<dt><strong>Comments in the Mplus Input</strong></dt><dd><p>Comments in the Mplus Input can cause
problems when following keywords in uppercase, lower case, or mixed upper and lower
case letters are involved in the comments of the <code>VARIABLE</code> and <code>ANALYSIS</code>
section:
</p>

<ul>
<li><p><strong><code>VARIABLE</code> section</strong>: <code>"NAMES", "USEOBSERVATIONS",
     "USEVARIABLES", "MISSING", "CENSORED", "CATEGORICAL", "NOMINAL", "COUNT",
     "DSURVIVAL", "GROUPING", "IDVARIABLE", "FREQWEIGHT", "TSCORES", "AUXILIARY",
     "CONSTRAINT", "PATTERN", "STRATIFICATION", "CLUSTER", "WEIGHT", "WTSCALE",
     "BWEIGHT", "B2WEIGHT", "B3WEIGHT", "BWTSCALE", "REPWEIGHTS", "SUBPOPULATION",
     "FINITE", "CLASSES", "KNOWNCLASS", "TRAINING", "WITHIN", "BETWEEN", "SURVIVAL",
     "TIMECENSORED", "LAGGED"</code>, or <code>"TINTERVAL"</code>.
</p>
</li>
<li><p><strong><code>ANALYSIS</code> section</strong>: <code>"TYPE", "ESTIMATOR", "MODEL",
     "ALIGNMENT", "DISTRIBUTION", "PARAMETERIZATION", "LINK", "ROTATION",
     "ROWSTANDARDIZATION", "PARALLEL", "REPSE", "BASEHAZARD", "CHOLESKY", "ALGORITHM",
     "INTEGRATION", "MCSEED", "ADAPTIVE", "INFORMATION", "BOOTSTRAP", "LRTBOOTSTRAP",
     "STARTS", "STITERATIONS", "STCONVERGENCE", "STSCALE", "STSEED", "OPTSEED",
     "K-1STARTS", "LRTSTARTS", "RSTARTS", "ASTARTS", "H1STARTS", "DIFFTEST",
     "MULTIPLIER", "COVERAGE", "ADDFREQUENCY", "ITERATIONS", "SDITERATIONS",
     "H1ITERATIONS", "MITERATIONS", "MCITERATIONS", "MUITERATIONS", "RITERATIONS",
     "AITERATIONS", "CONVERGENCE", "H1CONVERGENCE", "LOGCRITERION", "RLOGCRITERION",
     "MCONVERGENCE", "MCCONVERGENCE", "MUCONVERGENCE", "RCONVERGENCE", "ACONVERGENCE",
     "MIXC", "MIXU", "LOGHIGH", "LOGLOW", "UCELLSIZE", "VARIANCE", "SIMPLICITY",
     "TOLERANCE", "METRIC", "MATRIX", "POINT", "CHAINS", "BSEED", "STVALUES",
     "PREDICTOR", "ALGORITHM", "BCONVERGENCE", "BITERATIONS", "FBITERATIONS",
     "THIN", "MDITERATIONS", "KOLMOGOROV", "PRIOR", "INTERACTIVE"</code>, or <code>"PROCESSORS"</code>.
</p>
</li></ul>

<p>Note that comments are removed from the input text by default, i.e., <code>comment = FALSE</code>.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p><code>misty.object</code> object of type <code>mplus</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>input</code></td>
<td>
<p>list with input command sections</p>
</td></tr>
<tr><td><code>write</code></td>
<td>
<p>updated write command sections</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with input command sections (<code>input</code>) and
result sections (<code>input</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>, <code><a href="#topic+mplus">mplus</a></code>,
<code><a href="#topic+mplus.print">mplus.print</a></code>, <code><a href="#topic+mplus.plot">mplus.plot</a></code>, <code><a href="#topic+mplus.bayes">mplus.bayes</a></code>,
<code><a href="#topic+mplus.run">mplus.run</a></code>, <code><a href="#topic+mplus.lca">mplus.lca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Example 1: Update VARIABLE and MODEL section

# Write Mplus Data File
write.mplus(ex3_1, file = "ex3_1.dat")

# Specify Mplus input
input &lt;- '
DATA:     FILE IS ex3_1.dat;
VARIABLE: NAMES ARE y1 x1 x3;
MODEL:    y1 ON x1 x3;
OUTPUT:   SAMPSTAT;
'

# Run Mplus input
mod0 &lt;- mplus(input, file = "ex3_1.inp")

# Update VARIABLE and MODEL section
update1 &lt;- '
VARIABLE: ...;
          USEVARIABLES ARE y1 x1;
MODEL:    y1 ON x1;
'

# Run updated Mplus input
mod1 &lt;- mplus.update(mod0, update1, file = "ex3_1_update1.inp")

#----------------------------------------------------------------------------
# Example 2: Update ANALYSIS section

# Update ANALYSIS section
update2 &lt;- '
ANALYSIS: ESTIMATOR IS MLR;
'

# Run updated Mplus input
mod2 &lt;- mplus.update(mod1, update2, file = "ex3_1_update2.inp")

#----------------------------------------------------------------------------
# Example 3: Remove OUTPUT section

# Remove OUTPUT section
update3 &lt;- '
OUTPUT: ---;
'

# Run updated Mplus input
mod3 &lt;- mplus.update(mod2, update3, file = "ex3_1_update3.inp")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.cfa'>Multilevel Confirmatory Factor Analysis</h2><span id='topic+multilevel.cfa'></span>

<h3>Description</h3>

<p>This function is a wrapper function for conducting multilevel confirmatory factor
analysis to investigate four types of constructs, i.e., within-cluster constructs,
shared cluster-level constructs, configural cluster constructs, and simultaneous
shared and configural cluster constructs by calling the <code>cfa</code> function in
the R package <span class="pkg">lavaan</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.cfa(data, ..., cluster, model = NULL, rescov = NULL,
               model.w = NULL, model.b = NULL, rescov.w = NULL, rescov.b = NULL,
               const = c("within", "shared", "config", "shareconf"),
               fix.resid = NULL, ident = c("marker", "var", "effect"),
               ls.fit = FALSE, estimator = c("ML", "MLR"),
               optim.method = c("nlminb", "em"), missing = c("listwise", "fiml"),
               print = c("all", "summary", "coverage", "descript", "fit", "est",
                         "modind", "resid"),
               mod.minval = 6.63, resid.minval = 0.1, digits = 3, p.digits = 3,
               as.na = NULL, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.cfa_+3A_data">data</code></td>
<td>
<p>a data frame. If <code>model</code>, <code>model.w</code>, and <code>model.b</code>
are <code>NULL</code>, multilevel confirmatory factor analysis
based on a measurement model with one factor labeled <code>wf</code>
at the Within level and one factor labeled <code>bf</code> at the
Between level comprising all variables in the data frame
is conducted. Note that the cluster variable specified in
<code>cluster</code> is excluded from <code>data</code> when specifying
the argument <code>cluster</code> using the variable name of the
cluster variable. If <code>model</code> or <code>mode.w</code>
and <code>model.b</code> is specified, the data frame needs to
contain all variables used in the <code>model</code> argument(s).</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also be
used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>data</code> or <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_model">model</code></td>
<td>
<p>a character vector for specifying the same factor structure
with one factor at the Within and Between Level, or a list
of character vectors for specifying the same measurement
model with more than one factor at the Within and Between
Level, e.g.,<code>model = c("x1", "x2", "x3", "x4")</code> for
specifying a measurement model with one factor labeled <code>wf</code>
at the Within level and a measurement model with one factor
labeled <code>bf</code> at the Between level each comprising four
indicators, or <code>model = list(factor1 = c("x1", "x2", "x3", "x4"),
factor2 = c("x5", "x6", "x7", "x8"))</code> for specifying a
measurement model with two latent factors labeled <code>wfactor1</code>
and <code>wfactor2</code> at the Within level and a measurement
model with two latent factors labeled <code>bfactor1</code> and
<code>bfactor2</code> at the Between level each comprising four
indicators. Note that the name of each list element is used
to label factors, where prefixes <code>w</code> and <code>b</code> are
added the labels to distinguish factor labels at the Within
and Between level, i.e., all list elements need to be named,
otherwise factors are labeled with <code>"wf1", "wf2", "wf3"</code>
for labels at the Within level and <code>"bf1", "bf2", "bf3"</code>
for labels at the Between level and so on.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances at the Within level, e.g. <code>rescov = c("x1", "x2")</code>
for specifying a residual covariance between indicators <code>x1</code>
and <code>x2</code> at the Within level or <code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code>
for specifying residual covariances between indicators <code>x1</code>
and <code>x2</code>, and indicators <code>x3</code> and <code>x4</code> at
the Within level. Note that residual covariances at the
Between level can only be specified by using the arguments
<code>model.w</code>, <code>model.b</code>, and <code>model.b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_model.w">model.w</code></td>
<td>
<p>a character vector specifying a measurement model with one
factor at the Within level, or a list of character vectors
for specifying a measurement model with more than one factor
at the Within level.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_model.b">model.b</code></td>
<td>
<p>a character vector specifying a measurement model with one
factor at the Between level, or a list of character vectors
for specifying a measurement model with more than one factor
at the Between level.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_rescov.w">rescov.w</code></td>
<td>
<p>a character vector or a list of character vectors for
specifying residual covariances at the Within level.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_rescov.b">rescov.b</code></td>
<td>
<p>a character vector or a list of character vectors for
specifying residual covariances at the Between level.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_const">const</code></td>
<td>
<p>a character string indicating the type of construct(s), i.e.,
<code>"within"</code> for within-cluster constructs, <code>"shared"</code>
for shared cluster-level constructs, <code>"config"</code> (default)
for configural cluster constructs, and <code>"shareconf"</code>
for simultaneous shared and configural cluster constructs.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_fix.resid">fix.resid</code></td>
<td>
<p>a character vector for specifying residual variances to be
fixed at 0 at the Between level, e.g., <code>fix.resid = c("x1", "x3")</code>
to fix residual variances of indicators <code>x1</code> and <code>x2</code>
at the Between level at 0. Note that it is also possible
to specify <code>fix.resid = "all"</code> which fixes all residual
variances at the Between level at 0 in line with the strong
factorial measurement invariance assumption across cluster.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_ident">ident</code></td>
<td>
<p>a character string indicating the method used for identifying
and scaling latent variables, i.e., <code>"marker"</code> for the
marker variable method fixing the first factor loading of
each latent variable to 1, <code>"var"</code> for the fixed variance
method fixing the variance of each latent variable to 1,
or <code>"effect"</code> for the effects-coding method using equality
constraints so that the average of the factor loading for
each latent variable equals 1.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_ls.fit">ls.fit</code></td>
<td>
<p>logical: if <code>TRUE</code> (default) level-specific fit indices
are computed when specifying a model using the arguments
<code>model.w</code> and <code>model.b</code> given the model does not
contain any cross-level equality constraints.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used:
<code>"ML"</code> for maximum likelihood with conventional standard
errors and <code>"MLR"</code> (default) for maximum likelihood
with Huber-White robust standard errors and a scaled test
statistic that is asymptotically equal to the Yuan-Bentler
test statistic. Note that by default, full information maximum
likelihood (FIML) method is used to deal with missing data
when using <code>"ML"</code> (<code>missing = "fiml"</code>), whereas
incomplete cases are removed listwise (i.e., <code>missing = "listwise"</code>)
when using <code>"MLR"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_optim.method">optim.method</code></td>
<td>
<p>a character string indicating the optimizer, i.e., <code>"nlminb"</code>
(default) for the unconstrained and bounds-constrained
quasi-Newton method optimizer and <code>"em"</code> for the
Expectation Maximization (EM) algorithm.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data,
i.e., <code>"listwise"</code> (default) for listwise deletion or
<code>"fiml"</code> for full information maximum likelihood (FIML)
method. Note that FIML method is only available when <code>estimator = "ML"</code>,
that it takes longer to estimate the model  using FIML, and
that FIML is prone to convergence issues which might be
resolved by switching to listwise deletion.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e. <code>"all"</code> for all
results, <code>"summary"</code> for a summary of the specification
of the estimation method and missing data handling in lavaan,
<code>"coverage"</code> for the variance-covariance coverage of
the data, <code>"descript"</code> for descriptive statistics,
<code>"fit"</code> for model fit,  <code>"est"</code> for parameter
estimates, and <code>"modind"</code> for modification indices.
By default, a summary of the specification, descriptive
statistics, model fit, and parameter estimates are printed.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_mod.minval">mod.minval</code></td>
<td>
<p>numeric value to filter modification indices and only
show modifications with a modification index value equal
or higher than this minimum value. By default, modification
indices equal or higher 6.63 are printed. Note that a
modification index value of 6.63 is equivalent to a
significance level of <code class="reqn">\alpha = .01</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_resid.minval">resid.minval</code></td>
<td>
<p>numeric value indicating the minimum absolute residual
correlation coefficients and standardized means to
highlight in boldface. By default, absolute residual
correlation coefficients and standardized means equal
or higher 0.1 are highlighted. Note that highlighting
can be disabled by setting the minimum value to 1.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that loglikelihood,
information criteria and chi-square test statistic is
printed with <code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only
applied to <code>data</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification, convergence
and model identification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>specified model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>results of the convergence and model identification check</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary of the specification of the estimation method
and missing data handling in lavaan, <code>coverage</code> for
the variance-covariance coverage of the data, <code>descript</code>
for descriptive statistics, <code>fit</code> for model fit,
<code>est</code> for parameter estimates, and <code>modind</code>
for modification indices.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>cfa</code>, <code>lavInspect</code>, <code>lavTech</code>,
<code>modindices</code>, <code>parameterEstimates</code>, and <code>standardizedsolution</code>
provided in the R package <span class="pkg">lavaan</span> by Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.cfa">item.cfa</a></code>, <code><a href="#topic+multilevel.fit">multilevel.fit</a></code>, <code><a href="#topic+multilevel.invar">multilevel.invar</a></code>,
<code><a href="#topic+multilevel.omega">multilevel.omega</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Model specification using 'data' for a one-factor model
# with the same factor structure with one factor at the Within and Between Level

#..........
# Cluster variable specification

# Example 1a: Specification using the argument '...'
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster")

# Example 1b: Alternative specification with cluster variable 'cluster' in 'data'
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4", "cluster")], cluster = "cluster")

# Example 1c: Alternative specification with cluster variable 'cluster' not in 'data'
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster)

#..........
# Type of construct

# Example 2a: Within-cluster constructs
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", const = "within")

# Example 2b: Shared cluster-level construct
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", const = "shared")

# Example 2c: Configural cluster construct (default)
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", const = "config")

# Example 2d: Simultaneous shared and configural cluster construct
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", const = "shareconf")

#..........
# Residual covariances at the Within level

# Example 3a: Residual covariance between 'y1' and 'y3'
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", rescov = c("y1", "y3"))

# Example 3b: Residual covariance between 'y1' and 'y3', and 'y2' and 'y4'
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster",
               rescov = list(c("y1", "y3"), c("y2", "y4")))

#..........
# Residual variances at the Between level fixed at 0

# Example 4a: All residual variances fixed at 0
# i.e., strong factorial invariance across clusters
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", fix.resid = "all")

# Example 4b: Fesidual variances of 'y1', 'y2', and 'y4' fixed at 0
# i.e., partial strong factorial invariance across clusters
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", fix.resid = c("y1", "y2", "y4"))

#..........
# Print all results

# Example 5: Set minimum value for modification indices to 1
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", print = "all",
               mod.minval = 1)

#..........
# Example 6: lavaan model and summary of the estimated model

mod &lt;- multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", output = FALSE)

# lavaan model syntax
cat(mod$model)

# Fitted lavaan object
lavaan::summary(mod$model.fit, standardized = TRUE, fit.measures = TRUE)

#..........
# Write results

# Example 7a: Assign results into an object and write results into an Excel file
mod &lt;- multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", print = "all",
                      write = "Multilevel_CFA.txt", output = FALSE)

# Example 7b: Assign results into an object and write results into an Excel file
mod &lt;- multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", print = "all",
                      output = FALSE)

# Write results into an Excel file
write.result(mod, "Multilevel_CFA.xlsx")

# Estimate model and write results into an Excel file
multilevel.cfa(Demo.twolevel, y1:y4, cluster = "cluster", print = "all",
               write = "Multilevel_CFA.xlsx")

#----------------------------------------------------------------------------
# Model specification using 'model' for one or multiple factor model
# with the same factor structure at the Within and Between Level

# Example 8a: One-factor model
multilevel.cfa(Demo.twolevel, cluster = "cluster", model = c("y1", "y2", "y3", "y4"))

# Example 8b: Two-factor model
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

# Example 8c: Two-factor model with user-specified labels for the factors
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model = list(factor1 = c("y1", "y2", "y3"), factor2 = c("y4", "y5", "y6")))

#..........
# Type of construct

# Example 9a: Within-cluster constructs
multilevel.cfa(Demo.twolevel, cluster = "cluster", const = "within",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

# Example 9b: Shared cluster-level construct
multilevel.cfa(Demo.twolevel, cluster = "cluster", const = "shared",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

# Example 9c: Configural cluster construct (default)
multilevel.cfa(Demo.twolevel, cluster = "cluster", const = "config",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

# Example 9d: Simultaneous shared and configural cluster construct
multilevel.cfa(Demo.twolevel, cluster = "cluster", const = "shareconf",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

#..........
# Residual covariances at the Within level

# Example 10a: Residual covariance between 'y1' and 'y4' at the Within level
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")),
               rescov = c("y1", "y4"))

# Example 10b: Fix all residual variances at 0
# i.e., strong factorial invariance across clusters
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")),
               fix.resid = "all")

#----------------------------------------------------------------------------
# Model specification using 'model.w' and 'model.b' for one or multiple factor model
# with different factor structure at the Within and Between Level

# Example 11a: Two-factor model at the Within level and one-factor model at the Between level
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model.w = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")),
               model.b = c("y1", "y2", "y3", "y4", "y5", "y6"))

# Example 11b: Residual covariance between 'y1' and 'y4' at the Within level
# Residual covariance between 'y5' and 'y6' at the Between level
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model.w = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")),
               model.b = c("y1", "y2", "y3", "y4", "y5", "y6"),
               rescov.w = c("y1", "y4"),
               rescov.b = c("y5", "y6"))

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.cor'>Within-Group and Between-Group Correlation Matrix</h2><span id='topic+multilevel.cor'></span>

<h3>Description</h3>

<p>This function is a wrapper function for computing the within-group and
between-group correlation matrix by calling the <code>sem</code> function in the
R package <span class="pkg">lavaan</span> and provides standard errors, z test statistics, and
significance values (<em>p</em>-values) for testing the hypothesis
H0: <code class="reqn">\rho</code> = 0 for all pairs of variables within and between groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.cor(data, ..., cluster, within = NULL, between = NULL,
               estimator = c("ML", "MLR"), optim.method = c("nlminb", "em"),
               missing = c("listwise", "fiml"), sig = FALSE, alpha = 0.05,
               print = c("all", "cor", "se", "stat", "p"), split = FALSE,
               order = FALSE, tri = c("both", "lower", "upper"), tri.lower = TRUE,
               p.adj = c("none", "bonferroni", "holm", "hochberg", "hommel",
                         "BH", "BY", "fdr"), digits = 2, p.digits = 3,
               as.na = NULL, write = NULL, append = TRUE, check = TRUE,
               output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.cor_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>multilevel.cor(dat, x1, x2, x3)</code>. Note that
the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used to
select variables, see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_within">within</code></td>
<td>
<p>a character vector representing variables that are measured
on the within level and modeled only on the within level.
Variables not mentioned in <code>within</code> or <code>between</code>
are measured on the within level and will be modeled on both
the within and between level.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_between">between</code></td>
<td>
<p>a character vector representing variables that are measured
on the between level and modeled only on the between level.
Variables not mentioned in <code>within</code> or <code>between</code>
are measured on the within level and will be modeled on
both the within and between level.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used:
<code>"ML"</code> (default) for maximum likelihood with
conventional standard errors and <code>"MLR"</code> for maximum
likelihood with Huber-White robust standard errors. Note
that by default, full information maximum likelihood (FIML)
method is used to deal with missing data when using
<code>"ML"</code> (<code>missing = "fiml"</code>), whereas incomplete
cases are removed listwise (i.e., <code>missing = "listwise"</code>)
when using <code>"MLR"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_optim.method">optim.method</code></td>
<td>
<p>a character string indicating the optimizer, i.e., <code>nlminb</code>
(default) for the unconstrained and bounds-constrained
quasi-Newton method optimizer and <code>"em"</code> for the
Expectation Maximization (EM) algorithm.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing
data, i.e., <code>"listwise"</code> for listwise deletion or
<code>"fiml"</code> (default) for full information maximum
likelihood (FIML) method. Note that FIML method is only
available when <code>estimator = "ML"</code>. Note that it takes
longer to estimate the model when using FIML and using FIML
might cause issues in model convergence, these issues might
be resolved by switching to listwise deletion.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_sig">sig</code></td>
<td>
<p>logical: if <code>TRUE</code>, statistically significant
correlation coefficients are shown in boldface on the
console.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the significance
level at which correlation coefficients are printed
boldface when <code>sig = TRUE</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e. <code>"all"</code> for all
results, <code>"cor"</code> for correlation coefficients,
<code>"se"</code> for standard errors, <code>"stat"</code> for z test
statistics, and <code>"p"</code> for <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is split in
within-group and between-group correlation matrix.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_order">order</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables in the output table are
ordered, so that variables specified in the argument
<code>between</code> are shown first.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_tri">tri</code></td>
<td>
<p>a character string indicating which triangular of the
matrix to show on the console when <code>split = TRUE</code>,
i.e., <code>both</code> for upper and <code>upper</code> for the upper
triangular.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_tri.lower">tri.lower</code></td>
<td>
<p>logical: if <code>TRUE</code> (default) and <code>split = FALSE</code>
(default), within-group correlations are shown in the lower
triangular and between-group correlation are shown in the
upper triangular.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_p.adj">p.adj</code></td>
<td>
<p>a character string indicating an adjustment method for
multiple testing based on <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>, i.e.,
<code>none</code> (default), <code>bonferroni</code>, <code>holm</code>,
<code>hochberg</code>, <code>hommel</code>, <code>BH</code>, <code>BY</code>, or
<code>fdr</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying correlation coefficients.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis. Note that <code>as.na()</code> function
is only applied to <code>data</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specification of the within-group and between-group variables is in line
with the syntax in Mplus. That is, the <code>within</code> argument is used to
identify the variables in the data frame specified in <code>data</code> that
are measured on the individual level and modeled only on the within level.
They are specified to have no variance in the between part of the model. The
<code>between</code> argument is used to identify the variables in the
data frame specified in <code>data</code> that are measured on the cluster level and
modeled only on the between level. Variables not mentioned in the arguments
<code>within</code> or <code>between</code> are measured on the individual level and will
be modeled on both the within and between level.
</p>
<p>The function uses maximum likelihood estimation with conventional standard
errors (<code>estimator = "ML"</code>) which are not robust against non-normality
and full information maximum likelihood (FIML) method (<code>missing = "fiml"</code>)
to deal with missing data by default. FIML method cannot be used when
within-group variables have no variance within some clusters. In this cases,
the function
will switch to listwise deletion. Note that the current lavaan version 0.6-11
supports FIML method only for maximum likelihood estimation with conventional
standard errors (<code>estimator = "ML"</code>) in multilevel models. Maximum
likelihood estimation with Huber-White robust standard errors
(<code>estimator = "MLR"</code>) uses listwise deletion to deal with missing data.
When using FIML method there might be issues in model convergence, which might
be resolved by switching to listwise deletion (<code>missing = "listwise"</code>).
</p>
<p>The lavaan package uses a quasi-Newton optimization method (<code>"nlminb"</code>)
by default. If the optimizer does not converge, model estimation will switch
to the Expectation Maximization (EM) algorithm.
</p>
<p>Statistically significant correlation coefficients can be shown in boldface
on the console when specifying <code>sig = TRUE</code>. However, this option is not
supported when using R Markdown, i.e., the argument <code>sig</code> will switch to
<code>FALSE</code>.
</p>
<p>Adjustment method for multiple testing when specifying the argument <code>p.adj</code>
is applied to the within-group and between-group correlation matrix separately.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code> including the group variable
specified in <code>cluster</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
specification of the estimation method and missing data
handling in lavaan, <code>wb.cor</code> for the within- and
between-group correlations, <code>wb.se</code> for the standard
error of the within- and between-group correlations,
<code>wb.stat</code> for the test statistic of within- and between-group
correlations, <code>wb.p</code> for the significance value of
the within- and between-group correlations, <code>with.cor</code>
for the within-group correlations, <code>with.se</code> for the
standard error of the within-group correlations, <code>with.stat</code>
for the test statistic of within-group correlations, <code>with.p</code>
for the significance value of the within-group correlations,
<code>betw.cor</code> for the between-group correlations, <code>betw.se</code>
for the standard error of the between-group correlations,
<code>betw.stat</code> for the test statistic of between-group
correlations, <code>betw.p</code> for the significance value of
the between-group correlations</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>sem</code>, <code>lavInspect</code>,
<code>lavMatrixRepresentation</code>, <code>lavTech</code>, <code>parameterEstimates</code>,
and <code>standardizedsolution</code> provided in the R package <span class="pkg">lavaan</span> by
Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel analysis:
Techniques and applications</em> (3rd. ed.). Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An
introduction to basic and advanced multilevel modeling</em> (2nd ed.). Sage
Publishers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>,
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code>, <code><a href="#topic+cluster.scores">cluster.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Cluster variable specification

# Example 1a: Specification using the argument '...'
multilevel.cor(Demo.twolevel, y1, y2, y3, cluster = "cluster")

# Example 1b: Alternative specification with cluster variable 'cluster' in 'data'
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3", "cluster")], cluster = "cluster")

# Example 1b: Alternative specification with cluster variable 'cluster' not in 'data'
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")], cluster = Demo.twolevel$cluster)

#----------------------------------------------------------------------------
# Example 2: All variables modeled at both the within and between level
# Highlight statistically significant result at alpha = 0.05
multilevel.cor(Demo.twolevel, y1, y2, y3, sig = TRUE, cluster = "cluster")

# Example 3: Split output table in within-group and between-group correlation matrix.
multilevel.cor(Demo.twolevel, y1, y2, y3, cluster = "cluster", split = TRUE)

# Example 4: Print correlation coefficients, standard errors, z test statistics,
# and p-values
multilevel.cor(Demo.twolevel, y1, y2, y3, cluster = "cluster", print = "all")

# Example 5: Print correlation coefficients and p-values
# significance values with Bonferroni correction
multilevel.cor(Demo.twolevel, y1, y2, y3, cluster = "cluster", print = c("cor", "p"),
               p.adj = "bonferroni")

#----------------------------------------------------------------------------
# Example 6: Variables "y1", "y2", and "y2" modeled at both the within and between level
# Variables "w1" and "w2" modeled at the cluster level
multilevel.cor(Demo.twolevel, y1, y2, y3, w1, w2, cluster = "cluster",
               between = c("w1", "w2"))

# Example 7: Show variables specified in the argument 'between' first
multilevel.cor(Demo.twolevel, y1, y2, y3, w1, w2, cluster = "cluster",
               between = c("w1", "w2"), order = TRUE)

#----------------------------------------------------------------------------
# Example 8: Variables "y1", "y2", and "y2" modeled only at the within level
# Variables "w1" and "w2" modeled at the cluster level
multilevel.cor(Demo.twolevel, y1, y2, y3, w1, w2, cluster = "cluster",
               within = c("y1", "y2", "y3"), between = c("w1", "w2"))

#----------------------------------------------------------------------------
# Example 9: lavaan model and summary of the multilevel model used to compute the
# within-group and between-group correlation matrix

mod &lt;- multilevel.cor(Demo.twolevel, y1, y2, y3, cluster = "cluster", output = FALSE)

# lavaan model syntax
mod$model

# Fitted lavaan object
lavaan::summary(mod$model.fit, standardized = TRUE)

#----------------------------------------------------------------------------
# Write Results

# Example 10a: Write Results into a text file
multilevel.cor(Demo.twolevel, y1, y2, y3, cluster = "cluster",
               write = "Multilevel_Correlation.txt")

# Example 10b: Write Results into a Excel file
multilevel.cor(Demo.twolevel, y1, y2, y3, cluster = "cluster",
               write = "Multilevel_Correlation.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.descript'>Multilevel Descriptive Statistics for Two-Level and Three-Level Data</h2><span id='topic+multilevel.descript'></span>

<h3>Description</h3>

<p>This function computes descriptive statistics for two-level and three-level
multilevel data, e.g. average cluster size, variance components, intraclass
correlation coefficient, design effect, and effective sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.descript(data, ..., cluster, type = c("1a", "1b"),
                    method = c("aov", "lme4", "nlme"),
                    print = c("all", "var", "sd"), REML = TRUE, digits = 2,
                    icc.digits = 3, as.na = NULL, write = NULL, append = TRUE,
                    check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.descript_+3A_data">data</code></td>
<td>
<p>a numeric vector or data frame.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also be
used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the name of the cluster
variable in <code>data</code> for two-level data,
a character vector indicating the names of the cluster
variables in <code>data</code> for three-level data, or a vector
or data frame representing the nested grouping structure
(i.e., group or cluster variables). Alternatively, a
character string or character vector indicating the variable
name(s) of the cluster variable(s) in <code>data</code>. Note that
the cluster variable at Level 3 come first in a three-level
model, i.e., <code>cluster = c("level3", "level2")</code>.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of intraclass
correlation coefficient, i.e., <code>type = "1a"</code> (default)
for ICC(1) representing the proportion of variance at Level 2 and Level 3,
<code>type = "1b"</code> representing an estimate of the expected correlation
between two randomly chosen elements in the same group when specifying
a three-level model (i.e., two cluster variables). See 'Details' in the
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code> function for the formula used
in this function.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_method">method</code></td>
<td>
<p>a character string indicating the method used to estimate
intraclass correlation coefficients, i.e., <code>"aov"</code> ICC
estimated using the <code>aov</code> function, <code>"lme4"</code> (default)
ICC estimated using the <code>lmer</code> function in the <span class="pkg">lme4</span>
package, <code>"nlme"</code> ICC estimated using the <code>lme</code> function
in the <span class="pkg">nlme</span> package.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results to
show on the console, i.e. <code>"all"</code> for variances and standard deviations,
<code>"var"</code> (default) for variances, or <code>"sd"</code> for standard deviations
within and between clusters.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_reml">REML</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), restricted maximum likelihood
is used to estimate the null model when using the <code>lmer()</code>
function in the <span class="pkg">lme4</span> package or the <code>lme()</code> function in
the <span class="pkg">nlme</span> package.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_icc.digits">icc.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying intraclass correlation coefficients.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied
to <code>data</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Two-Level Model</strong></dt><dd><p>In a two-level model, the intraclass
correlation coefficients, design effect, and the effective sample size are
computed based on the random intercept-only model:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ij} = \gamma_{00} + u_{0j} + r_{ij}</code>
</p>

<p>where the variance in <code class="reqn">Y</code> is decomposed into two independent components:
<code class="reqn">\sigma^2_{u_{0}}</code>, which represents the variance at Level 2, and
<code class="reqn">\sigma^2_{r}</code>, which represents the variance at Level 1 (Hox et al.,
2018). For the computation of the intraclass correlation coefficients, see
'Details' in the <code><a href="#topic+multilevel.icc">multilevel.icc</a></code> function. The design effect
represents the effect of cluster sampling on the variance of parameter
estimation and is defined by the equation
</p>
<p style="text-align: center;"><code class="reqn">deff = (\frac{SE_{Cluster}}{SE_{Simple}})^2 = 1 + \rho(J - 1)</code>
</p>

<p>where <code class="reqn">SE_{Cluster}</code> is the standard error under cluster sampling,
<code class="reqn">SE_{Simple}</code> is the standard error under simple random sampling,
<code class="reqn">\rho</code> is the intraclass correlation coefficient, ICC(1), and
<code class="reqn">J</code> is the average cluster size. The effective sample size is defined
by the equation:
</p>
<p style="text-align: center;"><code class="reqn">N_{effective} = \frac{N{total}}{deff}</code>
</p>

<p>The effective sample size <code class="reqn">N_{effective}</code> represents the equivalent total
sample size that we should use in estimating the standard error (Snijders &amp;
Bosker, 2012).
</p>
</dd>
<dt><strong>Three-Level Model</strong></dt><dd><p>In a three-level model, the intraclass
correlation coefficients, design effect, and the effective sample size are
computed based on the random intercept-only model:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ijk} = \gamma_{000} + v_{0k} + u_{0jk} + r_{ijk}</code>
</p>

<p>where the variance in <code class="reqn">Y</code> is decomposed into three independent components:
<code class="reqn">\sigma^2_{v_{0}}</code>, which represents the variance at Level 3,
<code class="reqn">\sigma^2_{u_{0}}</code>, which represents the variance at Level 2, and
<code class="reqn">\sigma^2_{r}</code>, which represents the variance at Level 1 (Hox et al., 2018).
For the computation of the intraclass correlation coefficients, see 'Details'
in the <code><a href="#topic+multilevel.icc">multilevel.icc</a></code> function. The design effect
represents the effect of cluster sampling on the variance of parameter
estimation and is defined by the equation
</p>
<p style="text-align: center;"><code class="reqn">deff = (\frac{SE_{Cluster}}{SE_{Simple}})^2 = 1 + \rho_{L2}(J - 1) + \rho_{L3}(JK - 1)</code>
</p>

<p>where <code class="reqn">\rho_{L2}</code> is the ICC(1) at Level 2, <code class="reqn">\rho_{L3}</code> is the ICC(1) at Level 3,
<code class="reqn">J</code> is the average cluster size at Level 2, and <code class="reqn">K</code> is the average
cluster size at Level 3.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code> including the cluster
variable(s) specified in <code>cluster</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e.,
<code>no.obs</code> for the number of observations,
<code>no.no.miss</code> for the number of missing value,
<code>no.cluster.l2</code> and <code>no.cluster.l3</code> for the number of clusters at Level 2 and/or Level 3,
<code>m.cluster.size.l2</code> and <code>m.cluster.size.l3</code> for the average cluster size at Level 2 and/or Level 3,
<code>sd.cluster.size.l2</code> and <code>sd.cluster.size.l3</code> for the standard deviation of the cluster size at Level 2 and/or Level 3,
<code>min.cluster.size.l2</code> <code>min.cluster.size.l3</code> for the minimum cluster size at Level 2 and/or Level 3,
<code>max.cluster.size.l2</code> <code>max.cluster.size.l3</code> for the maximum cluster size at Level 2 and/or Level 3,
<code>mean.x</code> for the intercept of the multilevel model,
<code>var.r</code> for the variance within clusters,
<code>var.u</code> for the variance between Level 2 clusters,
<code>var.b</code> for the variance between Level 3 clusters,
<code>icc1.l2</code> and <code>icc1.l3</code> for ICC(1) at Level 2 and/or Level 3,
<code>icc2.l2</code> and <code>icc2.l3</code> for ICC(2) at Level 2 and/or Level 3,
<code>deff</code> for the design effect,
<code>deff.sqrt</code> for the square root of the design effect,
<code>n.effect</code> for the effective sample size</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel analysis:
Techniques and applications</em> (3rd. ed.). Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An
introduction to basic and advanced multilevel modeling</em> (2nd ed.). Sage Publishers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+multilevel.icc">multilevel.icc</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Two-Level Data

#..........
# Cluster variable specification

# Example 1a: Specification using the argument '...'
multilevel.descript(Demo.twolevel, y1, cluster = "cluster")

# Example 1b: Alternative specification with  cluster variable 'cluster' in 'data'
multilevel.descript(Demo.twolevel[, c("y1", "cluster")], cluster = "cluster")

# Example 1c: Alternative specification with cluster variable 'cluster' not in 'data'
multilevel.descript(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

#---------------------------

# Example 2: Multilevel descriptive statistics for 'y1'
multilevel.descript(Demo.twolevel, y1, cluster = "cluster")

# Example 3: Multilevel descriptive statistics, print variance and standard deviation
multilevel.descript(Demo.twolevel, y1, cluster = "cluster", print = "all")

# Example 4: Multilevel descriptive statistics, print ICC with 5 digits
multilevel.descript(Demo.twolevel, y1, cluster = "cluster", icc.digits = 5)

# Example 5: Multilevel descriptive statistics
# use lme() function in the nlme package to estimate ICC
multilevel.descript(Demo.twolevel, y1, cluster = "cluster", method = "nlme")

# Example 6a: Multilevel descriptive statistics for 'y1', 'y2', 'y3', 'w1', and 'w2'
multilevel.descript(Demo.twolevel, y1, y2, y3, w1, w2, cluster = "cluster")

# Alternative specification without using the '...' argument
multilevel.descript(Demo.twolevel[, c("y1", "y2", "y3", "w1", "w2")],
                    cluster = Demo.twolevel$cluster)

#----------------------------------------------------------------------------
# Three-Level Data

# Create arbitrary three-level data
Demo.threelevel &lt;- data.frame(Demo.twolevel, cluster2 = Demo.twolevel$cluster,
                                             cluster3 = rep(1:10, each = 250))

#..........
# Cluster variable specification

# Example 7a: Specification using the argument '...'
multilevel.descript(Demo.threelevel, y1, cluster = c("cluster3", "cluster2"))

# Example 7b: Alternative specification without using the argument '...'
multilevel.descript(Demo.threelevel[, c("y1", "cluster3", "cluster2")],
                    cluster = c("cluster3", "cluster2"))

# Example 7c: Alternative specification with cluster variables 'cluster' not in 'data'
multilevel.descript(Demo.threelevel$y1,
                    cluster = Demo.threelevel[, c("cluster3", "cluster2")])

#----------------------------------------------------------------------------

# Example 8: Multilevel descriptive statistics for 'y1', 'y2', 'y3', 'w1', and 'w2'
multilevel.descript(Demo.threelevel, y1:y3, w1, w2, cluster = c("cluster3", "cluster2"))

#----------------------------------------------------------------------------
# Write Results

# Example 9a: Write Results into a text file
multilevel.descript(Demo.twolevel, y1, y2, y3, w1, w2, cluster = "cluster",
                    write = "Multilevel_Descript.txt")

# Example 9b: Write Results into a Excel file
multilevel.descript(Demo.twolevel, y1, y2, y3, w1, w2, cluster = "cluster",
                    write = "Multilevel_Descript.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.fit'>Simultaneous and Level-Specific Multilevel Model Fit Information</h2><span id='topic+multilevel.fit'></span>

<h3>Description</h3>

<p>This function provides simultaneous and level-specific model fit information
using the partially saturated model method for multilevel models estimated
with the <span class="pkg">lavaan</span> package. Note that level-specific fit indices cannot
be computed when the fitted model contains cross-level constraints, e.g.,
equal factor loadings across levels in line with the metric cross-level
measurement invariance assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.fit(model, print = c("all", "summary", "fit"), digits = 3, p.digits = 3,
               write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.fit_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lavaan"</code> from the <span class="pkg">lavaan</span>
package.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results
to show on the console, i.e. <code>"all"</code> for all results,
<code>"summary"</code> for a summary of the specification of the
estimation method and missing data handling in lavaan and
<code>"fit"</code> for model fit.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that loglikelihood,
information criteria and chi-square test statistic is
printed with <code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>a fitted model of class <code>"lavaan"</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>specified models, i.e., <code>mod.l1</code> for the model at the
Within level, <code>mod.l1.syntax</code> for the lavaan syntax
for the model at the Between level, <code>mod.l2</code> for the
model at the Within level, <code>mod.l2.syntax</code> for the
lavaan syntax for the model at the Between level,
<code>mod.l12</code> for the model at the Within and Between
level, <code>mod.l12.syntax</code> for the lavaan syntax for
the model at the Within and Between level, <code>l1.mod.base</code>
for the baseline model at the Within level saturated at
the Between level, <code>l1.mod.hypo</code> for the hypothesized
model at the Within level saturated at the Between level,
<code>l2.mod.base</code> for the baseline model at the Between
level saturated at the Within level, <code>l2.mod.hypo</code>
for the hypothesized model at the Between level saturated
at the Within level</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary of the specification of the estimation method
and missing data handling in lavaan and <code>fit</code> for
the model fit information.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>cfa</code>, <code>fitmeasures</code>, <code>lavInspect</code>,
<code>lavTech</code>, and <code>parTable</code> provided in the R package <span class="pkg">lavaan</span> by
Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.invar">multilevel.invar</a></code>,
<code><a href="#topic+multilevel.omega">multilevel.omega</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Model specification
model &lt;- 'level: 1
              fw =~ y1 + y2 + y3
              fw ~ x1 + x2 + x3
           level: 2
              fb =~ y1 + y2 + y3
              fb ~ w1 + w2'

#-------------------------------------------------------------------------------

# Example 1: Model estimation with estimator = "ML"
fit1 &lt;- lavaan::sem(model = model, data = Demo.twolevel, cluster = "cluster",
                    estimator = "ML")

# Simultaneous and level-specific multilevel model fit information
ls.fit1 &lt;- multilevel.fit(fit1)

# Write results into a text file
multilevel.fit(fit1, write = "LS-Fit1.txt")

# Write results into an Excel file
write.result(ls.fit1, "LS-Fit1.xlsx")

# Example 2: Model estimation with estimator = "MLR"
fit2 &lt;- lavaan::sem(model = model, data = Demo.twolevel, cluster = "cluster",
                    estimator = "MLR")

# Simultaneous and level-specific multilevel model fit information
# Write results into an Excel file
multilevel.fit(fit2, write = "LS-Fit2.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.icc'>Intraclass Correlation Coefficient, ICC(1) and ICC(2)</h2><span id='topic+multilevel.icc'></span>

<h3>Description</h3>

<p>This function computes the intraclass correlation coefficient ICC(1), i.e.,
proportion of the total variance explained by the grouping structure, and ICC(2),
i.e., reliability of aggregated variables in a two-level and three-level model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.icc(data, ..., cluster, type = c("1a", "1b", "2"),
               method = c("aov", "lme4", "nlme"), REML = TRUE,
               as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.icc_+3A_data">data</code></td>
<td>
<p>a numeric vector or data frame.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used to select
variables, see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the name of the cluster
variable in <code>data</code> for two-level data,
a character vector indicating the names of the cluster
variables in <code>data</code> for three-level data, or a vector
or data frame representing the nested grouping structure
(i.e., group or cluster variables). Alternatively, a
character string or character vector indicating the variable
name(s) of the cluster variable(s) in <code>data</code>. Note that
the cluster variable at Level 3 come first in a three-level
model, i.e., <code>cluster = c("level3", "level2")</code>.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of intraclass correlation
coefficient, i.e., <code>type = "1a"</code> (default) for ICC(1) and
<code>type = "2"</code> for ICC(2) when specifying a two-level model
(i.e., one cluster variable), and <code>type = "1a"</code> (default)
for ICC(1) representing the proportion of variance at Level 2
and Level 3, <code>type = "1b"</code> representing an estimate
of the expected correlation between two randomly chosen elements
in the same group, and <code>type = "2"</code> for ICC(2) when
specifying a three-level model (i.e., two cluster variables). See 'Details'
for the formula used in this function.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_method">method</code></td>
<td>
<p>a character string indicating the method used to estimate
intraclass correlation coefficients, i.e., <code>method = "aov"</code>
ICC estimated using the <code>aov</code> function, <code>method = "lme4"</code>
(default) ICC estimated using the <code>lmer</code> function in the
<span class="pkg">lme4</span> package, <code>method = "nlme"</code> ICC estimated using
the <code>lme</code> function in the <span class="pkg">nlme</span> package. Note that
if the lme4 or nlme package is needed when estimating ICCs in
a three-level model.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_reml">REML</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), restricted maximum likelihood
is used to estimate the null model when using the <code>lmer</code>
function in the <span class="pkg">lme4</span> package or the <code>lme</code> function
in the <span class="pkg">nlme</span> package.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied
to <code>x</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Two-Level Model</strong></dt><dd><p>In a two-level model, the intraclass
correlation coefficients are computed in the random intercept-only model:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ij} = \gamma_{00} + u_{0j} + r_{ij}</code>
</p>

<p>where the variance in <code class="reqn">Y</code> is decomposed into two independent components:
<code class="reqn">\sigma^2_{u_{0}}</code>, which represents the variance at Level 2, and
<code class="reqn">\sigma^2_{r}</code>, which represents the variance at Level 1 (Hox et al.,
2018). These two variances sum up to the total variance and are referred to
as variance components. The intraclass correlation coefficient, ICC(1)
<code class="reqn">\rho</code> requested by <code>type = "1a"</code> represents the proportion of the
total variance explained by the grouping structure and is defined by the equation
</p>
<p style="text-align: center;"><code class="reqn">\rho = \frac{\sigma^2_{u_{0}}}{\sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>The intraclass correlation coefficient, ICC(2) <code class="reqn">\lambda_j</code> requested by
<code>type = "2"</code> represents the reliability of aggregated variables and is
defined by the equation
</p>
<p style="text-align: center;"><code class="reqn">\lambda_j = \frac{\sigma^2_{u_{0}}}{\sigma^2_{u_{0}} + \frac{\sigma^2_{r}}{n_j}} = \frac{n_j\rho}{1 + (n_j - 1)\rho}</code>
</p>

<p>where <code class="reqn">n_j</code> is the average group size (Snijders &amp; Bosker, 2012).
</p>
</dd>
<dt><strong>Three-Level Model</strong></dt><dd><p>In a three-level model, the intraclass
correlation coefficients are computed in the random intercept-only model:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ijk} = \gamma_{000} + v_{0k} + u_{0jk} + r_{ijk}</code>
</p>

<p>where the variance in <code class="reqn">Y</code> is decomposed into three independent components:
<code class="reqn">\sigma^2_{v_{0}}</code>, which represents the variance at Level 3,
<code class="reqn">\sigma^2_{u_{0}}</code>, which represents the variance at Level 2, and
<code class="reqn">\sigma^2_{r}</code>, which represents the variance at Level 1 (Hox et al.,
2018). There are two ways to compute the intraclass correlation coefficient
in a three-level model. The first method requested by <code>type = "1a"</code>
represents the proportion of variance at Level 2 and Level 3 and should be
used if we are interested in a decomposition of the variance across levels.
The intraclass correlation coefficient, ICC(1) <code class="reqn">\rho_{L2}</code> at Level 2 is
defined as:
</p>
<p style="text-align: center;"><code class="reqn">\rho_{L2} = \frac{\sigma^2_{u_{0}}}{\sigma^2_{v_{0}} + \sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>The ICC(1) <code class="reqn">\rho_{L3}</code> at Level 3 is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\rho_{L3} = \frac{\sigma^2_{v_{0}}}{\sigma^2_{v_{0}} + \sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>The second method requested by <code>type = "1b"</code> represents the expected
correlation between two randomly chosen elements in the same group. The
intraclass correlation coefficient, ICC(1) <code class="reqn">\rho_{L2}</code> at Level 2 is
defined as:
</p>
<p style="text-align: center;"><code class="reqn">\rho_{L2} = \frac{\sigma^2_{v_{0}} + \sigma^2_{u_{0}}}{\sigma^2_{v_{0}} + \sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>The ICC(1) <code class="reqn">\rho_L3</code> at Level 3 is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\rho_{L3} = \frac{\sigma^2_{v_{0}}}{\sigma^2_{v_{0}} + \sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>Note that both formula are correct, but express different aspects of the data,
which happen to coincide when there are only two levels (Hox et al., 2018).
</p>
<p>The intraclass correlation coefficients, ICC(2) requested by <code>type = "2"</code>
represent the reliability of aggregated variables at Level 2 and Level 3.
The ICC(2) <code class="reqn">\lambda_j</code> at Level 2 is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\lambda_j = \frac{\sigma^2_{u_{0}}}{\sigma^2_{u_{0}} + \frac{\sigma^2_{r}}{n_j}}</code>
</p>

<p>The ICC(2) <code class="reqn">\lambda_k</code> at Level 3 is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\lambda_k = \frac{\sigma^2_{v_{0}}}{\frac{{\sigma^2_{v_{0}} + \sigma^2_{u_{0}}}}{n_{j}} + \frac{\sigma^2_{r}}{n_k \cdot n_j}}</code>
</p>

<p>where <code class="reqn">n_j</code> is the average group size at Level 2 and <code class="reqn">n_j</code> is the average group size at Level 3 (Hox et al., 2018).</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a numeric vector or matrix with intraclass correlation coefficient(s).
In a three level model, the label <code>L2</code> is used for ICCs at Level 2 and <code>L3</code> for ICCs at Level 3.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel analysis:
Techniques and applications</em> (3rd. ed.). Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An introduction
to basic and advanced multilevel modeling</em> (2nd ed.). Sage Publishers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Two-Level Data

#..........
# Cluster variable specification

# Example 1a: Specification using the argument '...'
multilevel.icc(Demo.twolevel, y1, cluster = "cluster")

# Example 1b: Alternative specification with cluster variable 'cluster' in 'data'
multilevel.icc(Demo.twolevel[, c("y1", "cluster")], cluster = "cluster")

# Example 1c: Alternative specification with cluster variable 'cluster' not in 'data'
multilevel.icc(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

#..........

# Example 2: ICC(1) for 'y1'
multilevel.icc(Demo.twolevel, y1, cluster = "cluster")

# Example 3: ICC(2)
multilevel.icc(Demo.twolevel, y1, cluster = "cluster", type = "2")

# Example 4: ICC(1)
# use lme() function in the lme4 package to estimate ICC
multilevel.icc(Demo.twolevel, y1, cluster = "cluster", method = "nlme")

# Example 5: ICC(1) for 'y1', 'y2', and 'y3'
multilevel.icc(Demo.twolevel, y1, y2, y3, cluster = "cluster")

# Alternative specification without using the '...' argument
multilevel.icc(Demo.twolevel[, c("y1", "y2", "y3")], cluster = Demo.twolevel$cluster)

#----------------------------------------------------------------------------
# Three-Level Data

# Create arbitrary three-level data
Demo.threelevel &lt;- data.frame(Demo.twolevel, cluster2 = Demo.twolevel$cluster,
                                             cluster3 = rep(1:10, each = 250))

#..........
# Cluster variable specification

# Example 6a: Specification using the argument '...'
multilevel.icc(Demo.threelevel, y1, cluster = c("cluster3", "cluster2"))

# Example 6b: Alternative specification without using the argument '...'
multilevel.icc(Demo.threelevel[, c("y1", "cluster3", "cluster2")],
               cluster = c("cluster3", "cluster2"))

# Example 6c: Alternative specification with cluster variables 'cluster' not in 'data'
multilevel.icc(Demo.threelevel$y1, cluster = Demo.threelevel[, c("cluster3", "cluster2")])

#----------------------------------------------------------------------------

# Example 7a: ICC(1), proportion of variance at Level 2 and Level 3
multilevel.icc(Demo.threelevel, y1, cluster = c("cluster3", "cluster2"))

# Example 7b: ICC(1), expected correlation between two randomly chosen elements
# in the same group
multilevel.icc(Demo.threelevel, y1, cluster = c("cluster3", "cluster2"), type = "1b")

# Example 7c: ICC(2)
multilevel.icc(Demo.threelevel, y1, cluster = c("cluster3", "cluster2"), type = "2")
</code></pre>

<hr>
<h2 id='multilevel.indirect'>Confidence Interval for the Indirect Effect in a 1-1-1 Multilevel Mediation Model</h2><span id='topic+multilevel.indirect'></span>

<h3>Description</h3>

<p>This function computes the confidence interval for the indirect effect in a
1-1-1 multilevel mediation model with random slopes based on the Monte Carlo
method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.indirect(a, b, se.a, se.b, cov.ab = 0, cov.rand, se.cov.rand,
                    nrep = 100000, alternative = c("two.sided", "less", "greater"),
                    seed = NULL, conf.level = 0.95, digits = 3, write = NULL,
                    append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.indirect_+3A_a">a</code></td>
<td>
<p>a numeric value indicating the coefficient <code class="reqn">a</code>, i.e.,
average effect of <code class="reqn">X</code> on <code class="reqn">M</code> on the cluster or
between-group level.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_b">b</code></td>
<td>
<p>a numeric value indicating the coefficient <code class="reqn">b</code>, i.e.,
average effect of <code class="reqn">M</code> on <code class="reqn">Y</code> adjusted for <code class="reqn">X</code>
on the cluster or between-group level.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_se.a">se.a</code></td>
<td>
<p>a positive numeric value indicating the standard error of
<code class="reqn">a</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_se.b">se.b</code></td>
<td>
<p>a positive numeric value indicating the standard error of
<code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_cov.ab">cov.ab</code></td>
<td>
<p>a positive numeric value indicating the covariance between
<code class="reqn">a</code> and <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_cov.rand">cov.rand</code></td>
<td>
<p>a positive numeric value indicating the covariance between
the random slopes for <code class="reqn">a</code> and <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_se.cov.rand">se.cov.rand</code></td>
<td>
<p>a positive numeric value indicating the standard error of the
covariance between the random slopes for <code class="reqn">a</code> and <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_nrep">nrep</code></td>
<td>
<p>an integer value indicating the number of Monte Carlo repetitions.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be
one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the seed of the random number generator
when using the Monte Carlo method.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level
of the interval.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In statistical mediation analysis (MacKinnon &amp; Tofighi, 2013), the indirect effect
refers to the effect of the independent variable <code class="reqn">X</code> on the outcome variable
<code class="reqn">Y</code> transmitted by the mediator variable <code class="reqn">M</code>. The magnitude of the indirect
effect <code class="reqn">ab</code> is quantified by the product of the the coefficient <code class="reqn">a</code>
(i.e., effect of <code class="reqn">X</code> on <code class="reqn">M</code>) and the coefficient <code class="reqn">b</code> (i.e., effect of
<code class="reqn">M</code> on <code class="reqn">Y</code> adjusted for <code class="reqn">X</code>). However, mediation in the context of a
1-1-1 multilevel mediation model where variables <code class="reqn">X</code>, <code class="reqn">M</code>, and <code class="reqn">Y</code>
are measured at level 1, the coefficients <code class="reqn">a</code> and <code class="reqn">b</code> can vary across
level-2 units (i.e., random slope). As a result, <code class="reqn">a</code> and <code class="reqn">b</code> may covary
so that the estimate of the indirect effect is no longer simply the product of
the coefficients <code class="reqn">\hat{a}\hat{b}</code>, but <code class="reqn">\hat{a}\hat{b} + \tau_{a,b}</code>,
where <code class="reqn">\tau_{a,b}</code> (i.e., <code>cov.rand</code>) is the level-2 covariance between
the random slopes <code class="reqn">a</code> and <code class="reqn">b</code>. The covariance term needs to be added to
<code class="reqn">\hat{a}\hat{b}</code> only when random slopes are estimated for both <code class="reqn">a</code> and
<code class="reqn">b</code>. Otherwise, the simple product is sufficient to quantify the indirect
effect, and the <code><a href="#topic+indirect">indirect</a></code> function can be used instead.
</p>
<p>In practice, researchers are often interested in confidence limit estimation
for the indirect effect. There are several methods for computing a confidence
interval for the indirect effect in a single-level mediation models (see
<code><a href="#topic+indirect">indirect</a></code> function). The Monte Carlo (MC) method (MacKinnon et al.,
2004) is a promising method in single-level mediation model which was also adapted
to the multilevel mediation model (Bauer, Preacher &amp; Gil, 2006). This method
requires seven pieces of information available from the results of a multilevel
mediation model:
</p>

<dl>
<dt>a</dt><dd><p>Coefficient <code class="reqn">a</code>, i.e., average effect of <code class="reqn">X</code> on <code class="reqn">M</code>
on the cluster or between-group level. In Mplus, <code>Estimate</code>
of the random slope <code class="reqn">a</code> under <code>Means</code> at the
<code>Between Level</code>.</p>
</dd>
<dt>b</dt><dd><p>Coefficient <code class="reqn">b</code>, i.e., average effect of <code class="reqn">M</code> on <code class="reqn">Y</code>
on the cluster or between-group level. In Mplus, <code>Estimate</code>
of the random slope <code class="reqn">b</code> under <code>Means</code> at the
<code>Between Level</code>.</p>
</dd>
<dt>se.a</dt><dd><p>Standard error of <code>a</code>. In Mplus, <code>S.E.</code>
of the random slope <code class="reqn">a</code> under <code>Means</code> at the
<code>Between Level</code>.</p>
</dd>
<dt>se.b</dt><dd><p>Standard error of <code>b</code>. In Mplus, <code>S.E.</code>
of the random slope <code class="reqn">b</code> under <code>Means</code> at the
<code>Between Level</code>.</p>
</dd>
<dt>cov.ab</dt><dd><p>Covariance between <code class="reqn">a</code> and <code class="reqn">b</code>. In Mplus, the
estimated covariance matrix for the parameter estimates
(i.e., asymptotic covariance matrix) need to be requested
by specifying <code>TECH3</code> along with <code>TECH1</code> in the
<code>OUTPUT</code> section. In the <code>TECHNICAL 1 OUTPUT</code>
under <code>PARAMETER SPECIFICATION FOR BETWEEN</code>, the
numbers of the parameter for the coefficients <code class="reqn">a</code> and
<code class="reqn">b</code> need to be identified under <code>ALPHA</code> to look
up <code>cov.av</code> in the corresponding row and column in
the <code>TECHNICAL 3 OUTPUT</code> under <code>ESTIMATED COVARIANCE
                MATRIX FOR PARAMETER ESTIMATES</code>.</p>
</dd>
<dt>cov.rand</dt><dd><p>Covariance between the random slopes for <code class="reqn">a</code> and
<code class="reqn">b</code>. In Mplus, <code>Estimate</code> of the covariance
<code class="reqn">a</code> <code>WITH</code> <code class="reqn">b</code> at the <code>Between Level</code></p>
</dd></dl>
<p>.
</p>
<dl>
<dt>se.cov.rand</dt><dd><p>Standard error of the covariance between the random
slopes for <code class="reqn">a</code> and <code class="reqn">b</code>. In Mplus, <code>S.E.</code>
of the covariance <code class="reqn">a</code> <code>WITH</code> <code class="reqn">b</code> at the
<code>Between Level</code></p>
</dd></dl>
<p>.

</p>
<p>Note that all pieces of information except <code>cov.ab</code> can be looked up in
the standard output of the multilevel mediation model. In order to specify
<code>cov.ab</code>, the covariance matrix for the parameter estimates (i.e.,
asymptotic covariance matrix) is required. In practice, <code>cov.ab</code> will
oftentimes be very small so that <code>cov.ab</code> may be set to 0 (i.e., default
value) with negligible impact on the results.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>a</code>, <code>b</code>,
<code>se.a</code>, <code>se.b</code>, <code>cov.ab</code>, <code>cov.rand</code>,
and <code>se.cov.rand</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>ab</code> for the simulated
<code>ab</code> values and <code>mc</code> for the estimate of the
indirect effect and the confidence interval</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function was adapted from the interactive web tool by Preacher and
Selig (2010).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Bauer, D. J., Preacher, K. J., &amp; Gil, K. M. (2006). Conceptualizing and testing
random indirect effects and moderated Mediation in multilevel models: New procedures
and recommendations. <em>Psychological Methods, 11</em>, 142-163.
https://doi.org/10.1037/1082-989X.11.2.142
</p>
<p>Kenny, D. A., Korchmaros, J. D., &amp; Bolger, N. (2003). Lower level Mediation in
multilevel models. <em>Psychological Methods, 8</em>, 115-128.
https://doi.org/10.1037/1082-989x.8.2.115
</p>
<p>MacKinnon, D. P., Lockwood, C. M., &amp; Williams, J. (2004). Confidence limits for the indirect effect:
Distribution of the product and resampling methods. <em>Multivariate Behavioral Research, 39</em>, 99-128.
https://doi.org/10.1207/s15327906mbr3901_4
</p>
<p>MacKinnon, D. P., &amp; Tofighi, D. (2013). Statistical mediation analysis. In J. A. Schinka, W. F. Velicer,
&amp; I. B. Weiner (Eds.), <em>Handbook of psychology: Research methods in psychology</em> (pp. 717-735).
John Wiley &amp; Sons, Inc..
</p>
<p>Preacher, K. J., &amp; Selig, J. P. (2010). <em>Monte Carlo method for assessing
multilevel Mediation: An interactive tool for creating confidence intervals for
indirect effects in 1-1-1 multilevel models</em> [Computer software]. Available from
http://quantpsy.org/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+indirect">indirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Confidence Interval for the Indirect Effect
multilevel.indirect(a = 0.25, b = 0.20, se.a = 0.11, se.b = 0.13,
                    cov.ab = 0.01, cov.rand = 0.40, se.cov.rand = 0.02)

# Example 2: Save results of the Monte Carlo method
ab &lt;- multilevel.indirect(a = 0.25, b = 0.20, se.a = 0.11, se.b = 0.13,
                          cov.ab = 0.01, cov.rand = 0.40, se.cov.rand = 0.02,
                          output = FALSE)$result$ab

# Histogram of the distribution of the indirect effect
hist(ab)

## Not run: 
# Example 3: Write results into a text file
multilevel.indirect(a = 0.25, b = 0.20, se.a = 0.11, se.b = 0.13,
                    cov.ab = 0.01, cov.rand = 0.40, se.cov.rand = 0.02,
                    write = "ML-Indirect.txt")
## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.invar'>Cross-Level Measurement Invariance Evaluation</h2><span id='topic+multilevel.invar'></span>

<h3>Description</h3>

<p>This function is a wrapper function for evaluating configural, metric, and
scalar cross-level measurement invariance using multilevel confirmatory factor
analysis with continuous indicators by calling the <code>cfa</code> function in the
R package <span class="pkg">lavaan</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.invar(data, ..., cluster, model = NULL, rescov = NULL,
                 invar = c("config", "metric", "scalar"), fix.resid = NULL,
                 ident = c("marker", "var", "effect"),
                 estimator = c("ML", "MLR"), optim.method = c("nlminb", "em"),
                 missing = c("listwise", "fiml"),
                 print = c("all", "summary", "coverage", "descript", "fit",
                           "est", "modind", "resid"),
                 print.fit = c("all", "standard", "scaled", "robust"),
                 mod.minval = 6.63, resid.minval = 0.1, digits = 3, p.digits = 3,
                 as.na = NULL, write = NULL, append = TRUE, check = TRUE,
                 output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.invar_+3A_data">data</code></td>
<td>
<p>a data frame. If <code>model</code> is <code>NULL</code>,
multilevel confirmatory factor analysis based on a
measurement model with one factor at the Within and Between
level comprising all variables in the data frame
is conducted to evaluate cross-level measurement invariance.
Note that the cluster variable specified in <code>cluster</code>
is excluded from <code>data</code> when specifying the argument
<code>cluster</code> using the variable name of the cluster
variable. If <code>model</code> is specified, the data
frame needs to contain all variables used in the <code>model</code>
argument.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>multilevel.invar(dat, x1, x2, x3, cluster = "cluster")</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used to
select variables, see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_model">model</code></td>
<td>
<p>a character vector specifying the same factor structure
with one factor at the Within and Between Level, or a list
of character vectors for specifying the same measurement
model with more than one factor at the Within and Between
Level, e.g.,<code>model = c("x1", "x2", "x3", "x4")</code> for
specifying a measurement model with one factor labeled
<code>wf</code> at the Within level and a measurement model with
one factor labeled <code>bf</code> at the Between level each
comprising four indicators, or <code>model = list(factor1 = c("x1", "x2", "x3", "x4"),
factor2 = c("x5", "x6", "x7", "x8"))</code> for specifying a
measurement model with two latent factors labeled <code>wfactor1</code>
and <code>wfactor2</code> at the Within level and a measurement
model with two latent factors labeled <code>bfactor1</code> and
<code>bfactor2</code> at the Between level each comprising four
indicators. Note that the name of each list element is used
to label factors, where prefixes <code>w</code> and <code>b</code> are
added the labels to distinguish factor labels at the Within
and Between level, i.e., all list elements need to be named,
otherwise factors are labeled with <code>"wf1", "wf2", "wf3"</code>
for labels at the Within level and <code>"bf1", "bf2", "bf3"</code>
for labels at the Between level and so on.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances at the Within level, e.g. <code>rescov = c("x1", "x2")</code>
for specifying a residual covariance between indicators <code>x1</code>
and <code>x2</code> at the Within level or <code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code>
for specifying residual covariances between indicators <code>x1</code>
and <code>x2</code>, and indicators <code>x3</code> and <code>x4</code> at
the Within level. Note that residual covariances at the
Between level can only be specified by using the arguments
<code>model.w</code>, <code>model.b</code>, and <code>model.b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_invar">invar</code></td>
<td>
<p>a character string indicating the level of measurement invariance
to be evaluated, i.e., <code>config</code> to evaluate configural
measurement invariance (i.e., same factor structure across
levels), <code>metric</code> (default) to evaluate configural and
metric measurement invariance (i.e., equal factor loadings
across level), and <code>scalar</code> to evaluate configural,
metric and scalar measurement invariance (i.e., all residual
variances at the Between level equal zero).</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_fix.resid">fix.resid</code></td>
<td>
<p>a character vector for specifying residual variances to be
fixed at 0 at the Between level for the configural and metric
invariance model, e.g., <code>fix.resid = c("x1", "x3")</code>
to fix residual variances of indicators <code>x1</code> and <code>x2</code>
at the Between level at 0. Note that it is also possible
to specify <code>fix.resid = "all"</code> which fixes all residual
variances at the Between level at 0 in line with the strong
factorial measurement invariance assumption across cluster.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_ident">ident</code></td>
<td>
<p>a character string indicating the method used for identifying
and scaling latent variables, i.e., <code>"marker"</code> for the
marker variable method fixing the first factor loading of
each latent variable to 1, <code>"var"</code> for the fixed variance
method fixing the variance of each latent variable to 1,
or <code>"effect"</code> for the effects-coding method using equality
constraints so that the average of the factor loading for
each latent variable equals 1.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used:
<code>"ML"</code> for maximum likelihood with conventional standard
errors and <code>"MLR"</code> (default) for maximum likelihood
with Huber-White robust standard errors and a scaled test
statistic that is asymptotically equal to the Yuan-Bentler
test statistic. Note that by default, full information maximum
likelihood (FIML) method is used to deal with missing data
when using <code>"ML"</code> (<code>missing = "fiml"</code>), whereas
incomplete cases are removed listwise (i.e., <code>missing = "listwise"</code>)
when using <code>"MLR"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_optim.method">optim.method</code></td>
<td>
<p>a character string indicating the optimizer, i.e., <code>"nlminb"</code>
(default) for the unconstrained and bounds-constrained
quasi-Newton method optimizer and <code>"em"</code> for the
Expectation Maximization (EM) algorithm.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data,
i.e., <code>"listwise"</code> (default) for listwise deletion or
<code>"fiml"</code> for full information maximum likelihood (FIML)
method. Note that FIML method is only available when
<code>estimator = "ML"</code>, that it takes longer to estimate
the model  using FIML, and that FIML is prone to convergence
issues which might be resolved by switching to listwise deletion.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e. <code>"all"</code> for all
results, <code>"summary"</code> for a summary of the specification
of the estimation method and missing data handling in lavaan,
<code>"coverage"</code> for the variance-covariance coverage of
the data, <code>"descript"</code> for descriptive statistics,
<code>"fit"</code> for model fit and  model comparison, <code>"est"</code>
for parameter estimates, and <code>"modind"</code> for modification
indices. By default, a summary of the specification and model fit
and model comparison are printed.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_print.fit">print.fit</code></td>
<td>
<p>a character string or character vector indicating which
version of the CFI, TLI, and RMSEA to show on the console,
i.e., <code>"all"</code> for all versions of the CFI, TLI, and
RMSEA, <code>"standard"</code> (default when <code>estimator = "ML"</code>)
for fit indices without any non-normality correction,
<code>"scaled"</code> for population-corrected robust fit indices
with ad hoc non-normality correction, and <code>robust</code>
(default when <code>estimator = "MLR"</code>) for sample-corrected
robust fit indices based on formula provided by Li and Bentler
(2006) and Brosseau-Liard and Savalei (2014).</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_mod.minval">mod.minval</code></td>
<td>
<p>numeric value to filter modification indices and only
show modifications with a modification index value equal
or higher than this minimum value. By default, modification
indices equal or higher 6.63 are printed. Note that a
modification index value of 6.63 is equivalent to a
significance level of <code class="reqn">\alpha = .01</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_resid.minval">resid.minval</code></td>
<td>
<p>numeric value indicating the minimum absolute residual
correlation coefficients and standardized means to
highlight in boldface. By default, absolute residual
correlation coefficients and standardized means equal
or higher 0.1 are highlighted. Note that highlighting
can be disabled by setting the minimum value to 1.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that information
criteria and chi-square test statistic is printed with
<code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only
applied to <code>data</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification, convergence
and model identification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>list with specified model for the configural, metric, and
scalar invariance model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>list with fitted lavaan object of the configural, metric,
and scalar invariance model</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>list with the results of the convergence and model identification
check for the configural, metric, and scalar invariance model</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary of the specification of the estimation method and
missing data handling in lavaan, <code>coverage</code> for the
variance-covariance coverage of the data, <code>descript</code>
for descriptive statistics, <code>fit</code> for a list with
model fit based on standard, scaled, and robust fit indices,
<code>est</code> for a list with parameter estimates for the
configural, metric, and scalar invariance model, and
<code>modind</code> for the list with modification indices for
the configural, metric, and scalar invariance model</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>lavTestLRT</code> provided in the R package
<span class="pkg">lavaan</span> by Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.fit">multilevel.fit</a></code>, <code><a href="#topic+multilevel.omega">multilevel.omega</a></code>,
<code><a href="#topic+multilevel.cor">multilevel.cor</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Cluster variable specification

# Example 1a: Specification using the argument '...'
multilevel.invar(Demo.twolevel, y1:y4, cluster = "cluster")

# Example 1b: Alternative specification with cluster variable 'cluster' in 'data'
multilevel.invar(Demo.twolevel[, c("y1", "y2", "y3", "y4", "cluster")], cluster = "cluster")

# Example 1b: Alternative specification with cluster variable 'cluster' not in 'data'
multilevel.invar(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster)

#----------------------------------------------------------------------------
# Model specification using 'data' for a one-factor model

#..........
# Level of measurement invariance

# Example 2a: Configural invariance
multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", invar = "config")

# Example 2b: Metric invariance
multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", invar = "metric")

# Example 2c: Scalar invariance
multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", invar = "scalar")

#..........
# Residual covariance at the Within level and residual variance at the Between level

# Example 3a: Residual covariance between "y3" and "y4" at the Within level
multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster",
                 rescov = c("y3", "y4"))

# Example 3b: Residual variances of 'y1' at the Between level fixed at 0
multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", fix.resid = "y1")

#..........
# Example 4: Print all results
multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", print = "all")

#..........
# Example 5: lavaan model and summary of the estimated model
mod &lt;- multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", output = FALSE)

# lavaan syntax of the metric invariance model
mod$model$metric

# Fitted lavaan object of the metric invariance model
lavaan::summary(mod$model.fit$metric, standardized = TRUE, fit.measures = TRUE)

#----------------------------------------------------------------------------
# Model specification using 'model' for one or multiple factor model

# Example 6a: One-factor model
multilevel.invar(Demo.twolevel, cluster = "cluster", model = c("y1", "y2", "y3", "y4"))

# Example 6b:  Two-factor model
multilevel.invar(Demo.twolevel, cluster = "cluster",
                 model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

#----------------------------------------------------------------------------
# Write results

# Example 7a: Write Results into a Excel file
multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", print = "all",
                 write = "Multilevel_Invariance.txt")

# Example 7b:  Write Results into a Excel file
multilevel.invar(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", print = "all",
                 write = "Multilevel_Invariance.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.omega'>Multilevel Composite Reliability</h2><span id='topic+multilevel.omega'></span>

<h3>Description</h3>

<p>This function computes point estimate and Monte Carlo confidence interval for
the multilevel composite reliability defined by Lai (2021) for a within-cluster
construct, shared cluster-level construct, and configural cluster construct by
calling the <code>cfa</code> function in the R package <span class="pkg">lavaan</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.omega(data, ..., cluster, rescov = NULL,
                 const = c("within", "shared", "config"),
                 fix.resid = NULL, optim.method = c("nlminb", "em"),
                 missing = c("listwise", "fiml"), nrep = 100000, seed = NULL,
                 conf.level = 0.95, print = c("all", "omega", "item"),
                 digits = 2, as.na = NULL, write = NULL, append = TRUE,
                 check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.omega_+3A_data">data</code></td>
<td>
<p>a data frame. Multilevel confirmatory factor
analysis based on a measurement model with one factor
at the Within level and one factor at the Between level
comprising all variables in the data frame is
conducted. Note that the cluster variable specified in
<code>cluster</code> is excluded from <code>data</code> when specifying
the argument <code>cluster</code> using the variable name of the
cluster variable.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>multilevel.omega(dat, x1, x2, x3, cluster = "cluster")</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also be
used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances at the Within level, e.g. <code>rescov = c("x1", "x2")</code>
for specifying a residual covariance between indicators <code>x1</code>
and <code>x2</code> at the Within level or <code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code>
for specifying residual covariances between indicators <code>x1</code>
and <code>x2</code>, and indicators <code>x3</code> and <code>x4</code> at
the Within level. Note that residual covariances at the
Between level cannot be  specified using this function.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_const">const</code></td>
<td>
<p>a character string indicating the type of construct(s), i.e.,
<code>"within"</code> for within-cluster constructs, <code>"shared"</code>
for shared cluster-level constructs, and <code>"config"</code>
(default) for configural cluster constructs.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_fix.resid">fix.resid</code></td>
<td>
<p>a character vector for specifying residual variances to be
fixed at 0 at the Between level, e.g., <code>fix.resid = c("x1", "x3")</code>
to fix residual variances of indicators <code>x1</code> and <code>x2</code>
at the Between level at 0. Note that it is also possible
to specify <code>fix.resid = "all"</code> which fixes all residual
variances at the Between level at 0 in line with the strong
factorial measurement invariance assumption across cluster.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_optim.method">optim.method</code></td>
<td>
<p>a character string indicating the optimizer, i.e., <code>"nlminb"</code>
(default) for the unconstrained and bounds-constrained
quasi-Newton method optimizer and <code>"em"</code> for the
Expectation Maximization (EM) algorithm.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data,
i.e., <code>"listwise"</code> for listwise deletion or <code>"fiml"</code>
(default) for full information maximum likelihood (FIML)
method.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_nrep">nrep</code></td>
<td>
<p>an integer value indicating the number of Monte Carlo
repetitions for computing confidence intervals.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the seed of the random number
generator for computing the Monte Carlo confidence interval.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e.
<code>"all"</code> (default), for all results <code>"omega"</code> for
omega, and <code>"item"</code> for item statistics.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that loglikelihood,
information criteria and chi-square test statistic is
printed with <code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only
applied to <code>data</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification, convergence
and model identification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code> including the group variable
specified in <code>cluster</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>specified model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>results of the convergence and model identification check</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>omega</code> for the coefficient
omega including Monte Carlo confidence interval and
<code>itemstat</code> for descriptive statistics</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>lavInspect</code>, <code>lavTech</code>, and <code>lavNames</code>,
provided in the R package <span class="pkg">lavaan</span> by Yves Rosseel (2012). The internal function
<code>.internal.mvrnorm</code> is a copy of the <code>mvrnorm</code> function in the package
<span class="pkg">MASS</span> by Venables and Ripley (2002).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Lai, M. H. C. (2021). Composite reliability of multilevel data: It’s about
observed scores and construct meanings. <em>Psychological Methods, 26</em>(1),
90–102. https://doi.org/10.1037/met0000287
</p>
<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>
<p>Venables, W. N., Ripley, B. D. (2002).<em>Modern Applied Statistics with S</em> (4th ed.).
Springer. https://www.stats.ox.ac.uk/pub/MASS4/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.omega">item.omega</a></code>, <code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.fit">multilevel.fit</a></code>,
<code><a href="#topic+multilevel.invar">multilevel.invar</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Cluster variable specification

# Example 1a: Specification using the argument '...'
multilevel.omega(Demo.twolevel, y1:y4, cluster = "cluster")

# Example 1b: Alternative specification with cluster variable 'cluster' in 'data'
multilevel.omega(Demo.twolevel[, c("y1", "y2", "y3", "y4", "cluster")], cluster = "cluster")

# Example 1b: Alternative specification with cluster variable 'cluster' not in 'data'
multilevel.omega(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster)

#----------------------------------------------------------------------------
# Type of construct

# Example 2a: Within-Cluster Construct
multilevel.omega(Demo.twolevel[, c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, const = "within")

# Example 2b: Shared Cluster-Level Construct
multilevel.omega(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", const = "shared")

# Example 2c: Configural Construct
multilevel.omega(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", const = "config")

#----------------------------------------------------------------------------
# Residual covariance at the Within level and residual variance at the Between level

# Example 3a: Residual covariance between "y4" and "y5" at the Within level
multilevel.omega(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", const = "config",
                 rescov = c("y3", "y4"))

# Example 3b: Residual variances of 'y1' at the Between level fixed at 0
multilevel.omega(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster", const = "config",
                 fix.resid = c("y1", "y2"), digits = 3)

#----------------------------------------------------------------------------
# Write results

# Example 4a: Write results into a text file
multilevel.omega(Demo.twolevel[, c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, write = "Multilevel_Omega.txt")

# Example 4b: Write results into a Excel file
multilevel.omega(Demo.twolevel, y1, y2, y3, y4, cluster = "cluster",
                 write = "Multilevel_Omega.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.r2'>R-Squared Measures for Multilevel and Linear Mixed Effects Models</h2><span id='topic+multilevel.r2'></span>

<h3>Description</h3>

<p>This function computes R-squared measures by Raudenbush and Bryk (2002),
Snijders and Bosker (1994), Nakagawa and Schielzeth (2013) as extended by
Johnson (2014), and Rights and Sterba (2019) for multilevel and linear mixed
effects models estimated by using the <code>lmer()</code> function in the package
<span class="pkg">lme4</span> or <code>lme()</code> function in the package <span class="pkg">nlme</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.r2(model, print = c("all", "RB", "SB", "NS", "RS"), digits = 3,
              plot = FALSE, gray = FALSE, start = 0.15, end = 0.85,
              color = c("#D55E00", "#0072B2", "#CC79A7", "#009E73", "#E69F00"),
              filename = NULL, width = NA, height = NA,
              units = c("in", "cm", "mm", "px"), dpi = 600,
              write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.r2_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lmerMod"</code> from the <span class="pkg">lme4</span>
package or <code>"lme"</code> from the <span class="pkg">nlme</span> package.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_print">print</code></td>
<td>
<p>a character vector indicating which R-squared measures to be
printed on the console, i.e., <code>RB</code> for measures from
Raudenbush and Bryk (2002), <code>SB</code> for measures from Snijders
and Bosker (1994), <code>NS</code> for measures from Nakagawa and
Schielzeth (2013) as extended by Johnson (2014), and <code>RS</code>
for measures from Rights and Sterba (2019). The default setting
is <code>print = "RS"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar chart showing the decomposition of
scaled total, within-cluster, and between-cluster outcome variance
into five (total), three (within-cluster), and two (between-cluster)
proportions is drawn. Note that the <span class="pkg">ggplot2</span> package is required
to draw the bar chart.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_gray">gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, graphical parameter to draw the bar chart
in gray scale.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_start">start</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the low end of the palette.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_end">end</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the high end of the palette.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_color">color</code></td>
<td>
<p>a character vector, graphical parameter indicating the color of
bars in the bar chart in the following order: Fixed slopes (Within),
Fixed slopes (Between), Slope variation (Within), Intercept variation
(Between), and Residual (Within). By default, colors from the
colorblind-friendly palettes are used.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>file</code>
argument. Note that plots can only be saved when
<code>plot = TRUE</code> and <code>print = "RS"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of R-squared measures for multilevel and linear mixed effects models have
been developed in the methodological literature (see Rights &amp; Sterba, 2018).
Based on these measures, following measures were implemented in the current function:
</p>

<dl>
<dt><strong>Raudenbush and Bryk (2002)</strong></dt><dd><p>R-squared measures by Raudenbush
and Bryk (2002) are based on the proportional reduction of unexplained variance
when predictors are added. More specifically, variance estimates from the
baseline/null model (i.e., <code class="reqn">\sigma^2_{e|b}</code> and <code class="reqn">\sigma^2_{u0|b}</code>)
and variance estimates from the model including predictors (i.e., <code class="reqn">\sigma^2_{e|m}</code>
and <code class="reqn">\sigma^2_{u0|m}</code>) are used to compute the proportional reduction in
variance between baseline/null model and the complete model by:
</p>
<p style="text-align: center;"><code class="reqn">R^2_1(RB) = \frac{\sigma^2_{e|b} - \sigma^2_{e|m}}{\sigma^2_{e|b}}</code>
</p>

<p>for the proportional reduction at level-1 (within-cluster) and by:
</p>
<p style="text-align: center;"><code class="reqn">R^2_2(RB) = \frac{\sigma^2_{u0|b} - \sigma^2_{u0|m}}{\sigma^2_{u0|b}}</code>
</p>

<p>for the proportional reduction at level-2 (between-cluster), where <code class="reqn">|b</code>
and <code class="reqn">|m</code> represent the baseline and full models, respectively (Hox et al.,
2018; Roberts et al., 2010).
</p>
<p>A major disadvantage of these measures is that adding predictors can increases
rather than decreases some of the variance components and it is even possible
to obtain negative values for <code class="reqn">R^2</code> with these formulas (Snijders &amp; Bosker,
2012). According to Snijders and Bosker (1994) this can occur because the
between-group variance is a function of both level-1 and level-2 variance:
</p>
<p style="text-align: center;"><code class="reqn">var(\bar{Y}_j) = \sigma^2_{u0} + \frac{\sigma^2_e}{n_j}</code>
</p>

<p>Hence, adding a predictor (e.g., cluster-mean centered predictor) that explains
proportion of the within-group variance will decrease the estimate of <code class="reqn">\sigma^2_e</code>
and increase the estimate <code class="reqn">\sigma^2_{u0}</code> if this predictor does not explain
a proportion of the between-group variance to balance out the decrease in
<code class="reqn">\sigma^2_e</code> (LaHuis et al., 2014). Negative estimates for <code class="reqn">R^2</code> can
also simply occur due to chance fluctuation in sample estimates from the two
models.
</p>
<p>Another disadvantage of these measures is that <code class="reqn">R^2_2(RB)</code> for the explained
variance at level-2 has been shown to perform poorly in simulation studies even
with <code class="reqn">j = 200</code> clusters with group cluster size of <code class="reqn">n_j = 50</code> (LaHuis
et al., 2014; Rights &amp; Sterba, 2019).
</p>
<p>Moreover, when there is missing data in the level-1 predictors, it is possible
that sample sizes for the baseline and complete models differ.
</p>
<p>Finally, it should be noted that R-squared measures by Raudenbush and Bryk (2002)
are appropriate for random intercept models, but not for random intercept and
slope models. For random slope models, Snijders and Bosker (2012) suggested to
re-estimate the model as random intercept models with the same predictors while
omitting the random slopes to compute the R-squared measures. However, the
simulation study by LaHuis (2014) suggested that the R-squared measures showed
an acceptable performance when there was little slope variance, but did not
perform well in the presence of higher levels of slope variance.</p>
</dd>
<dt><strong>Snijders and Bosker (1994)</strong></dt><dd><p>R-squared measures by Snijders and
Bosker (1994) are based on the proportional reduction of mean squared prediction
error and is computed using the formula:
</p>
<p style="text-align: center;"><code class="reqn">R^2_1(SB) = \frac{\hat{\sigma}^2_{e|m} + \hat{\sigma}^2_{u0|m}}{\hat{\sigma}^2_{e|b} + \hat{\sigma}^2_{u0|b}}</code>
</p>

<p>for computing the proportional reduction of error at level-1 representing
the total amount of explained variance and using the formula:
</p>
<p style="text-align: center;"><code class="reqn">R^2_2(SB) = \frac{\hat{\sigma}^2_{e|m} / n_j + \hat{\sigma}^2_{u0|m}}{\hat{\sigma}^2_{e|b} / n_j + \hat{\sigma}^2_{u0|b}}</code>
</p>

<p>for computing the proportional reduction of error at level-2 by dividing the
<code class="reqn">\hat{\sigma}^2_e</code> by the group cluster size <code class="reqn">n_j</code> or by the average
cluster size for unbalanced data (Roberts et al., 2010). Note that the function
uses the harmonic mean of the group sizes as recommended by Snijders and Bosker
(1994). The population values of <code class="reqn">R^2</code> based on these measures cannot be
negative because the interplay of level-1 and level-2 variance components is
considered. However, sample estimates of <code class="reqn">R^2</code> can be negative either due
to chance fluctuation when sample sizes are small or due to model misspecification
(Snijders and Bosker, 2012).
</p>
<p>When there is missing data in the level-1 predictors, it is possible that sample
sizes for the baseline and complete models differ.
</p>
<p>Similar to the R-squared measures by Raudenbush and Bryk (2002), the measures
by Snijders and Bosker (1994) are appropriate for random intercept models, but
not for random intercept and slope models. Accordingly, for random slope models,
Snijders and Bosker (2012) suggested to re-estimate the model as random intercept
models with the same predictors while omitting the random slopes to compute the
R-squared measures. The simulation study by LaHuis et al. (2014) revealed that
the R-squared measures showed an acceptable performance, but it should be noted
that <code class="reqn">R^2_2(SB)</code> the explained variance at level-2 was not investigated in
their study.</p>
</dd>
<dt><strong>Nakagawa and Schielzeth (2013)</strong></dt><dd><p>R-squared measures by Nakagawa
and Schielzeth (2013) are based on partitioning model-implied variance from a
single fitted model and uses the variance of predicted values of <code class="reqn">var(\hat{Y}_{ij})</code>
to form both the outcome variance in the denominator and the explained variance
in the numerator of the formulas:
</p>
<p style="text-align: center;"><code class="reqn">R^2_m(NS) = \frac{var(\hat{Y}_{ij})}{var(\hat{Y}_{ij}) + \sigma^2_{u0} + \sigma^2_{e}}</code>
</p>

<p>for marginal total <code class="reqn">R^2_m(NS)</code> and:
</p>
<p style="text-align: center;"><code class="reqn">R^2_c(NS) = \frac{var(\hat{Y}_{ij}) + \sigma^2_{u0}}{var(\hat{Y}_{ij}) + \sigma^2_{u0} + \sigma^2_{e}}</code>
</p>

<p>for conditional total <code class="reqn">R^2_c(NS)</code>. In the former formula <code class="reqn">R^2</code> predicted
scores are marginalized across random effects to indicate the variance explained
by fixed effects and in the latter formula <code class="reqn">R^2</code> predicted scores are conditioned
on random effects to indicate the variance explained by fixed and random effects
(Rights and Sterba, 2019).
</p>
<p>The advantage of these measures is that they can never become negative and
that they can also be extended to generalized linear mixed effects models (GLMM)
when outcome variables are not continuous (e.g., binary outcome variables).
Note that currently the function does not provide <code class="reqn">R^2</code> measures for GLMMs,
but these measures can be obtained using the <code>r.squaredGLMM()</code> function in
the <span class="pkg">MuMIn</span> package.
</p>
<p>A disadvantage is that these measures do not allow random slopes and are restricted
to the simplest random effect structure (i.e., random intercept model). In other
words, these measures do not fully reflect the structure of the fitted model when
using random intercept and slope models. However, Johnson (2014) extended these
measures to allow random slope by taking into account the contribution of random
slopes, intercept-slope covariances, and the covariance matrix of random slope
to the variance in <code class="reqn">Y_{ij}</code>. As a result, R-squared measures by Nakagawa
and Schielzeth (2013) as extended by Johnson (2014) can be used for both random
intercept, and random intercept and slope models.
</p>
<p>The major criticism of the R-squared measures by Nakagawa and Schielzeth (2013)
as extended by Johnson (2014) is that these measures do not decompose outcome
variance into each of total, within-cluster, and between-cluster variance which
precludes from computing level-specific <code class="reqn">R^2</code> measures. In addition, these
measures do not distinguish variance attributable to level-1 versus level-2
predictors via fixed effects, and they also do not distinguish between random
intercept and random slope variation (Rights and Sterba, 2019).</p>
</dd>
<dt><strong>Rights and Sterba (2019)</strong></dt><dd><p>R-squared measures by Rights and Sterba
(2019) provide an integrative framework of R-squared measures for multilevel
and linear mixed effects models with random intercepts and/or slopes. Their
measures are also based on partitioning model implied variance from a single
fitted model, but they provide a full partitioning of the total outcome variance
to one of five specific sources:
</p>

<ul>
<li><p> variance attributable to level-1 predictors via fixed slopes (shorthand:
variance attributable to <code>f1</code>)
</p>
</li>
<li><p> variance attributable to level-2 predictors via fixed slopes (shorthand:
variance attributable to <code>f2</code>)
</p>
</li>
<li><p> variance attributable to level-1 predictors via random slope variation/
covariation (shorthand: variance attributable to <code>v</code>)
</p>
</li>
<li><p> variance attributable to cluster-specific outcome means via random
intercept variation (shorthand: variance attributable to <code>m</code>)
</p>
</li>
<li><p> variance attributable to level-1 residuals
</p>
</li></ul>

<p><code class="reqn">R^2</code> measures are based on the outcome variance of interest (total,
within-cluster, or between-cluster) in the denominator, and the source contributing
to explained variance in the numerator:
</p>

<dl>
<dt><strong>Total <code class="reqn">R^2</code> measures</strong></dt><dd><p>incorporate both within-cluster
and between cluster variance in the denominator and quantify variance
explained in an omnibus sense:
</p>

<ul>
<li><p><code class="reqn">R^{2(f_1)}_t</code>: Proportion of total outcome variance explained
by level-1 predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(f_2)}_t</code>: Proportion of total outcome variance explained
by level-2 predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(f)}_t</code>: Proportion of total outcome variance explained
by all predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(v)}_t</code>: Proportion of total outcome variance explained
by level-1 predictors via random slope variation/covariation.
</p>
</li>
<li><p><code class="reqn">R^{2(m)}_t</code>: Proportion of total outcome variance explained
by cluster-specific outcome means via random intercept variation.
</p>
</li>
<li><p><code class="reqn">R^{2(fv)}_t</code>: Proportion of total outcome variance explained
by predictors via fixed slopes and random slope variation/covariation.
</p>
</li>
<li><p><code class="reqn">R^{2(fvm)}_t</code>: Proportion of total outcome variance explained
by predictors via fixed slopes and random slope variation/covariation
and by cluster-specific outcome means via random intercept variation.
</p>
</li></ul>

</dd>
<dt><strong>Within-Cluster <code class="reqn">R^2</code> measures</strong></dt><dd><p>incorporate only within-cluster
variance in the denominator and indicate
the degree to which within-cluster variance can be explained by a given model:
</p>

<ul>
<li><p><code class="reqn">R^{2(f_1)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(v)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via random slope variation/covariation.
</p>
</li>
<li><p><code class="reqn">R^{2(f_1v)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via fixed slopes and random slope
variation/covariation.
</p>
</li></ul>

</dd>
<dt><strong>Between-Cluster <code class="reqn">R^2</code> measures</strong></dt><dd><p>incorporate only between-cluster
variance in the denominator and indicate the degree to which between-cluster
variance can be explained by a given model:
</p>

<ul>
<li><p><code class="reqn">R^{2(f_2)}_b</code>: Proportion of between-cluster outcome variance
explained by level-2 predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(m)}_b</code>: Proportion of between-cluster outcome variance
explained by cluster-specific outcome means via random intercept variation.
</p>
</li></ul>

</dd>
</dl>

<p>The decomposition of the total outcome variance can be visualized in a bar
chart by specifying <code>plot = TRUE</code>. The first column of the bar chart
decomposes scaled total variance into five distinct proportions (i.e.,
<code class="reqn">R^{2(f_1)}_t</code>, <code class="reqn">R^{2(f_2)}_t</code>, <code class="reqn">R^{2(f)}_t</code>, <code class="reqn">R^{2(v)}_t</code>,
<code class="reqn">R^{2(m)}_t</code>, <code class="reqn">R^{2(fv)}_t</code>, and <code class="reqn">R^{2(fvm)}_t</code>), the second
column decomposes scaled within-cluster variance into three distinct proportions
(i.e., <code class="reqn">R^{2(f_1)}_w</code>, <code class="reqn">R^{2(v)}_w</code>, and <code class="reqn">R^{2(f_1v)}_w</code>), and
the third column decomposes scaled between-cluster variance into two distinct
proportions (i.e., <code class="reqn">R^{2(f_2)}_b</code>, <code class="reqn">R^{2(m)}_b</code>).
</p>
<p>Note that the function assumes that all level-1 predictors are centered within
cluster (i.e., group-mean or cluster-mean centering) as has been widely recommended
(e.g., Enders &amp; Tofighi, D., 2007; Rights et al., 2019). In fact, it does not
matter whether a lower-level predictor is merely a control variable, or is
quantitative or categorical (Yaremych et al., 2021), cluster-mean centering
should always be used for lower-level predictors to obtain an orthogonal
between-within partitioning of a lower-level predictor's variance that directly
parallels what happens to a level-1 outcome (Hoffman &amp; Walters, 2022). In the
absence of cluster-mean-centering, however, the function provides total <code class="reqn">R^2</code>
measures, but does not provide any within-cluster or between-cluster <code class="reqn">R^2</code>
measures.</p>
</dd>
</dl>

<p>By default, the function only computes R-squared measures by Rights and Sterba
(2019) because the other R-squared measures reflect the same population quantity
provided by Rights and Sterba (2019). That is, R-squared measures <code class="reqn">R^2_1(RB)</code>
and <code class="reqn">R^2_2(RB)</code> by Raudenbush and Bryk (2002) are equivalent to <code class="reqn">R^{2(f_1v)}_w</code>
and <code class="reqn">R^{2(f_2)}_b</code>, R-squared measures <code class="reqn">R^2_1(SB)</code> and <code class="reqn">R^2_2(SB)</code>
are equivalent to <code class="reqn">R^{2(f)}_t</code> and <code class="reqn">R^{2(f_2)}_b</code>, and R-squared measures
<code class="reqn">R^2_m(NS)</code> and <code class="reqn">R^2_c(NS)</code> by Nakagawa and Schielzeth (2013) as extended
by Johnson (2014) are equivalent to <code class="reqn">R^{2(f)}_t</code> and <code class="reqn">R^{2(fvm)}_t</code>
(see Rights and Sterba, Table 3).
</p>
<p>Note that none of these measures provide an <code class="reqn">R^2</code> for the random slope
variance explained by cross-level interactions, a quantity that is frequently
of interest (Hoffman &amp; Walters, 2022).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>rb</code> for the R2 measures
by Raudenbush and Bryk (2002), <code>sb</code> for the R2 measures
by Snijders and Bosker (1994), <code>ns</code> for the R2 measures
by Nakagawa and Schielzeth (2013), and <code>rs</code> for the R2
measures by Rights and Sterba (2019)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on the <code>multilevelR2()</code> function from the <span class="pkg">mitml</span>
package by Simon Grund, Alexander Robitzsch and Oliver Luedtke (2021), and a
copy of the function <code>r2mlm</code> in the <span class="pkg">r2mlm</span> package by Mairead Shaw,
Jason Rights, Sonya Sterba, and Jessica Flake.
</p>


<h3>Author(s)</h3>

<p>Simon Grund, Alexander Robitzsch, Oliver Luedtk, Mairead Shaw, Jason D. Rights,
Sonya K. Sterba, Jessica K. Flake, and Takuya Yanagida
</p>


<h3>References</h3>

<p>Enders, C. K., &amp; Tofighi, D. (2007). Centering predictor variables in
cross-sectional multilevel models: A new look at an old issue.
<em>Psychological Methods, 12</em>, 121-138. https://doi.org/10.1037/1082-989X.12.2.121
</p>
<p>Hoffmann, L., &amp; Walter, W. R. (2022). Catching up on multilevel modeling.
<em>Annual Review of Psychology, 73</em>, 629-658. https://doi.org/10.1146/annurev-psych-020821-103525
</p>
<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel Analysis:
Techniques and Applications</em> (3rd ed.) Routledge.
</p>
<p>Johnson, P. C. D. (2014). Extension of Nakagawa &amp; Schielzeth’s R2 GLMM to random
slopes models. <em>Methods in Ecology and Evolution, 5</em>(9), 944-946.
https://doi.org/10.1111/2041-210X.12225
</p>
<p>LaHuis, D. M., Hartman, M. J., Hakoyama, S., &amp; Clark, P. C. (2014). Explained
variance measures for multilevel models. <em>Organizational Research Methods, 17</em>,
433-451. https://doi.org/10.1177/1094428114541701
</p>
<p>Nakagawa, S., &amp; Schielzeth, H. (2013). A general and simple method for obtaining
R2 from generalized linear mixed-effects models. <em>Methods in Ecology and Evolution, 4</em>(2),
133-142. https://doi.org/10.1111/j.2041-210x.2012.00261.x
</p>
<p>Raudenbush, S. W., &amp; Bryk, A. S., (2002). <em>Hierarchical linear models: Applications
and data analysis methods</em>. Sage.
</p>
<p>Rights, J. D., Preacher, K. J., &amp; Cole, D. A. (2020). The danger of conflating
level-specific effects of control variables when primary interest lies in level-2
effects. <em>British Journal of Mathematical and Statistical Psychology, 73</em>(Suppl 1),
194-211. https://doi.org/10.1111/bmsp.12194
</p>
<p>Rights, J. D., &amp; Sterba, S. K. (2019). Quantifying explained variance in multilevel
models: An integrative framework for defining R-squared measures. <em>Psychological Methods, 24</em>,
309-338. https://doi.org/10.1037/met0000184
</p>
<p>Roberts, K. J., Monaco, J. P., Stovall, H., &amp; Foster, V. (2011). Explained variance
in multilevel models (pp. 219-230). In J. J. Hox &amp; J. K. Roberts (Eds.), <em>Handbook
of Advanced Multilevel Analysis</em>. Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. (1994). Modeled variance in two-level models.
<em>Sociological methods and research, 22</em>, 342-363. https://doi.org/10.1177/0049124194022003004
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An introduction
to basic and advanced multilevel modeling</em> (2nd ed.). Sage.
</p>
<p>Yaremych, H. E., Preacher, K. J., &amp; Hedeker, D. (2021). Centering categorical
predictors in multilevel models: Best practices and interpretation. <em>Psychological
Methods</em>. Advance online publication. https://doi.org/10.1037/met0000434
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.cor">multilevel.cor</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>,
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code>, <code><a href="#topic+multilevel.indirect">multilevel.indirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load misty, lme4, nlme, and ggplot2 package
misty::libraries(misty, lme4, nlme, ggplot2)

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------

# Cluster mean centering, center() from the misty package
Demo.twolevel &lt;- center(Demo.twolevel, x2, type = "CWC", cluster = "cluster")

# Compute group means, cluster.scores() from the misty package
Demo.twolevel &lt;- cluster.scores(Demo.twolevel, x2, cluster = "cluster", name = "x2.b")

# Estimate multilevel model using the lme4 package
mod1a &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1 + x2.c | cluster), data = Demo.twolevel,
              REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

# Estimate multilevel model using the nlme package
mod1b &lt;- lme(y1 ~ x2.c + x2.b + w1, random = ~ 1 + x2.c | cluster, data = Demo.twolevel,
             method = "ML")

#----------------------------------------------------------------------------
# Example 1a: R-squared measures according to Rights and Sterba (2019)
multilevel.r2(mod1a)

# Example 1b: R-squared measures according to Rights and Sterba (2019)
multilevel.r2(mod1b)

# Example 1a: Write Results into a text file
multilevel.r2(mod1a, write = "ML-R2.txt")

#-------------------------------------------------------------------------------
# Example 2: Bar chart showing the decomposition of scaled total, within-cluster,
# and between-cluster outcome variance
multilevel.r2(mod1a, plot = TRUE)

# Bar chart in gray scale
multilevel.r2(mod1a, plot = TRUE, gray = TRUE)

# Save bar chart
multilevel.r2(mod1a, plot = TRUE, filename = "Proportion_of_Variance.png",
              dpi = 600, width = 5.5, height = 5.5)

#-------------------------------------------------------------------------------
# Example 3: Estimate multilevel model without random slopes
# Note. R-squared measures by Raudenbush and Bryk (2002), and  Snijders and
# Bosker (2012) should be computed based on the random intercept model
mod2 &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1 | cluster), data = Demo.twolevel,
             REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

# Print all available R-squared measures
multilevel.r2(mod2, print = "all")

#-------------------------------------------------------------------------------
# Example 4: Draw bar chart manually
mod1a.r2 &lt;- multilevel.r2(mod1a, output = FALSE)

# Prepare data frame for ggplot()
df &lt;- data.frame(var = factor(rep(c("Total", "Within", "Between"), each = 5),
                              level = c("Total", "Within", "Between")),
                 part = factor(c("Fixed Slopes (Within)", "Fixed Slopes (Between)",
                                 "Slope Variation (Within)", "Intercept Variation (Between)",
                                 "Residual (Within)"),
                 level = c("Residual (Within)", "Intercept Variation (Between)",
                           "Slope Variation (Within)", "Fixed Slopes (Between)",
                           "Fixed Slopes (Within)")),
                 y = as.vector(mod1a.r2$result$rs$decomp))

# Draw bar chart in line with the default setting of multilevel.r2()
ggplot(df, aes(x = var, y = y, fill = part)) +
  theme_bw() +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#E69F00", "#009E73", "#CC79A7", "#0072B2", "#D55E00")) +
  scale_y_continuous(name = "Proportion of Variance", breaks = seq(0, 1, by = 0.1)) +
  theme(axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.title = element_blank(),
        legend.position = "bottom",
        legend.box.margin = margin(-10, 6, 6, 6)) +
  guides(fill = guide_legend(nrow = 2, reverse = TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.r2.manual'>R-Squared Measures for Multilevel and Linear Mixed Effects Models by Rights
and Sterba (2019), Manually Inputting Parameter Estimates</h2><span id='topic+multilevel.r2.manual'></span>

<h3>Description</h3>

<p>This function computes R-squared measures by Rights and Sterba (2019) for
multilevel and linear mixed effects models by manually inputting parameter
estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.r2.manual(data, within = NULL, between = NULL, random = NULL,
                     gamma.w = NULL, gamma.b = NULL, tau, sigma2,
                     intercept = TRUE, center = TRUE, digits = 3,
                     plot = FALSE, gray = FALSE, start = 0.15, end = 0.85,
                     color = c("#D55E00", "#0072B2", "#CC79A7", "#009E73", "#E69F00"),
                     filename = NULL, width = NA, height = NA,
                     units = c("in", "cm", "mm", "px"), dpi = 600,
                     write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multilevel.r2.manual_+3A_data">data</code></td>
<td>
<p>a matrix or data frame with the level-1 and level-2 predictors
and outcome variable used in the model.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_within">within</code></td>
<td>
<p>a character vector with the variable names in <code>data</code> or
numeric vector with numbers corresponding to the columns in
<code>data</code> of the level-1 predictors used in the model. If
none used, set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_between">between</code></td>
<td>
<p>a character vector with the variable names in <code>data</code> or
numeric vector with numbers corresponding to the columns in
<code>data</code> of the level-2 predictors used in the model. If
none used, set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_random">random</code></td>
<td>
<p>a character vector with the variable names in <code>data</code> or
numeric vector with numbers corresponding to the columns in
<code>data</code> of the level-1 predictors that have random slopes
in the model. If no random slopes specified, set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_gamma.w">gamma.w</code></td>
<td>
<p>a numeric vector of fixed slope estimates for all level-1
predictors, to be entered in the order of the predictors
listed in the argument <code>within</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_gamma.b">gamma.b</code></td>
<td>
<p>a numeric vector of the intercept and fixed slope estimates
for all level-2predictors, to be entered in the order of the
predictors listed in the argument <code>between</code>. Note that
the first element is the parameter estimate for the intercept
if <code>intercept = TRUE</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_tau">tau</code></td>
<td>
<p>a matrix indicating the random effects covariance matrix, the
first row/column denotes the intercept variance and covariances
(if intercept is fixed, set all to 0) and each subsequent
row/column denotes a given random slope's variance and covariances
(to be entered in the order listed in the argument <code>random</code>).</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_sigma2">sigma2</code></td>
<td>
<p>a numeric value indicating the level-1 residual variance.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_intercept">intercept</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the first element in the
<code>gamma.b</code> is assumed to be the fixed intercept estimate;
if set to <code>FALSE</code>, the first element in the argument
<code>gamma.b</code> is assumed to be the first fixed level-2
predictor slope.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_center">center</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), all level-1 predictors are
assumed to be cluster-mean-centered and the function will
output all decompositions; if set to <code>FALSE</code>, function
will output only the total decomposition.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar chart showing the decomposition
of scaled total, within-cluster, and between-cluster outcome
variance into five (total), three (within-cluster), and two
(between-cluster) proportions is drawn. Note that the <span class="pkg">ggplot2</span>
package is required to draw the bar chart.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_gray">gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, graphical parameter to draw the bar
chart in gray scale.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_start">start</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the low end of the palette.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_end">end</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the high end of the palette.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_color">color</code></td>
<td>
<p>a character vector, graphical parameter indicating the color
of bars in the bar chart in the following order: Fixed slopes
(Within), Fixed slopes (Between), Slope variation (Within),
Intercept variation (Between), and Residual (Within). By default,
colors from the colorblind-friendly palettes are used.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>file</code>
argument. Note that plots can only be saved when
<code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of R-squared measures for multilevel and linear mixed effects models
have been developed in the methodological literature (see Rights &amp; Sterba, 2018).
R-squared measures by Rights and Sterba (2019) provide an integrative framework
of R-squared measures for multilevel and linear mixed effects models with random
intercepts and/or slopes. Their measures are based on partitioning model implied
variance from a single fitted model, but they provide a full partitioning of
the total outcome variance to one of five specific sources. See the help page
of the <code><a href="#topic+multilevel.r2">multilevel.r2</a></code> function for more details.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>decomp</code> for the
decomposition, <code>total</code> for total R2 measures,
<code>within</code> for the within-cluster R2 measures, and
<code>between</code></p>
</td></tr></table>
<p> for the between-cluster R2 measures.
</p>


<h3>Note</h3>

<p>This function is based on a copy of the function <code>r2mlm_manual()</code> in the
<span class="pkg">r2mlm</span> package by Mairead Shaw, Jason Rights, Sonya Sterba, and Jessica
Flake.
</p>


<h3>Author(s)</h3>

<p>Jason D. Rights, Sonya K. Sterba, Jessica K. Flake, and Takuya Yanagida
</p>


<h3>References</h3>

<p>Rights, J. D., &amp; Cole, D. A. (2018). Effect size measures for multilevel models
in clinical child and adolescent research: New r-squared methods and recommendations.
<em>Journal of Clinical Child and Adolescent Psychology, 47</em>, 863-873.
https://doi.org/10.1080/15374416.2018.1528550
</p>
<p>Rights, J. D., &amp; Sterba, S. K. (2019). Quantifying explained variance in multilevel
models: An integrative framework for defining R-squared measures. <em>Psychological Methods, 24</em>,
309-338. https://doi.org/10.1037/met0000184
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.r2">multilevel.r2</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+multilevel.icc">multilevel.icc</a></code>,
<code><a href="#topic+multilevel.indirect">multilevel.indirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load misty and lme4 package
misty::libraries(misty, lme4)

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#-------------------------------------------------------------------------------

Demo.twolevel &lt;- center(Demo.twolevel, x2, type = "CWC", cluster = "cluster")

# Compute group means, cluster.scores() from the misty package
Demo.twolevel &lt;- cluster.scores(Demo.twolevel, x2, cluster = "cluster", name = "x2.b")

# Estimate random intercept model using the lme4 package
mod1 &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1| cluster), data = Demo.twolevel,
             REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

# Estimate random intercept and slope model using the lme4 package
mod2 &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1 + x2.c | cluster), data = Demo.twolevel,
             REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

#-------------------------------------------------------------------------------
# Example 1: Random intercept model

# Fixed slope estimates
fixef(mod1)

# Random effects variance-covariance matrix
as.data.frame(VarCorr(mod1))

# R-squared measures according to Rights and Sterba (2019)
multilevel.r2.manual(data = Demo.twolevel,
                     within = "x2.c", between = c("x2.b", "w1"),
                     gamma.w = 0.41127956,
                     gamma.b = c(0.01123245, -0.08269374, 0.17688507),
                     tau = 0.9297401,
                     sigma2 = 1.813245794)

#-------------------------------------------------------------------------------
# Example 2: Random intercept and slope model

# Fixed slope estimates
fixef(mod2)

# Random effects variance-covariance matrix
as.data.frame(VarCorr(mod2))

# R-squared measures according to Rights and Sterba (2019)
multilevel.r2.manual(data = Demo.twolevel,
                     within = "x2.c", between = c("x2.b", "w1"), random = "x2.c",
                     gamma.w = 0.41127956,
                     gamma.b = c(0.01123245, -0.08269374, 0.17688507),
                     tau = matrix(c(0.931008649, 0.004110479, 0.004110479, 0.017068857), ncol = 2),
                     sigma2 = 1.813245794)

## End(Not run)
</code></pre>

<hr>
<h2 id='na.auxiliary'>Auxiliary Variables Analysis</h2><span id='topic+na.auxiliary'></span>

<h3>Description</h3>

<p>This function computes (1) Pearson product-moment correlation matrix to identify
variables related to the incomplete variable (i.e., correlates of incomplete
variables), (2) Cohen's d matrix comparing cases with and without missing values
to identify variables related to the probability of missingness(i.e., correlates
of missingness), and (3) semi-partial correlations of an outcome variable
conditional on the predictor variables of a substantive model with a set of
candidate auxiliary variables to identify correlates of an incomplete outcome
variable as suggested by Raykov and West (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.auxiliary(data, ..., model = NULL, estimator = c("ML", "MLR"),
             missing = c("fiml", "two.stage", "robust.two.stage", "doubly.robust"),
             tri = c("both", "lower", "upper"), weighted = FALSE, correct = FALSE,
             digits = 2, p.digits = 3, as.na = NULL, write = NULL, append = TRUE,
             check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.auxiliary_+3A_data">data</code></td>
<td>
<p>a data frame with incomplete data, where missing
values are coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>na.auxiliary(dat, x1, x2, x3)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_model">model</code></td>
<td>
<p>a character string specifying the substantive model predicting
an continuous outcome variable using a set of predictor variables
to estimate semi-partial correlations between the outcome
variable and a set of candidate auxiliary variables. The default
setting is <code>model = NULL</code>, i.e., the function computes
Pearson product-moment correlation matrix and Cohen's d matrix.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used
when estimating semi-partial correlation coefficients, i.e.,
<code>"ML"</code> for maximum likelihood parameter estimates with
conventional standard errors or <code>"MLR"</code> (default) maximum
likelihood parameter estimates with Huber-White robust standard
errors.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data
when estimating semi-partial correlation coefficients,
i.e., <code>"fiml"</code> for full information maximum likelihood
method, <code>two.stage</code> for two-stage maximum likelihood
method, <code>robust.two.stage</code> for robust two-stage maximum
likelihood method, and <code>doubly-robust</code> for doubly-robust
method (see 'Details' in the <code><a href="#topic+item.cfa">item.cfa</a></code> function).
The default setting is <code>missing = "fiml"</code>.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_tri">tri</code></td>
<td>
<p>a character string indicating which triangular of the correlation
matrix to show on the console, i.e., <code>both</code> for upper and
lower triangular, <code>lower</code> (default) for the lower triangular,
and <code>upper</code> for the upper triangular.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the weighted pooled standard
deviation is used.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor for Cohen's d to
remove positive bias in small samples is used.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_digits">digits</code></td>
<td>
<p>integer value indicating the number of decimal places digits
to be used for displaying correlation coefficients and Cohen's d
estimates.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that non-numeric variables (i.e., factors, character vectors, and logical
vectors) are excluded from to the analysis.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>lavaan model syntax for estimating the semi-partial correlations</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan model for estimating the semi-partial correlations</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>pecification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>Raykov, T., &amp; West, B. T. (2016). On enhancing plausibility of the missing at
random assumption in incomplete data analyses via evaluation of response-auxiliary
variable correlations. <em>Structural Equation Modeling, 23</em>(1), 45–53.
https://doi.org/10.1080/10705511.2014.937848
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>,
<code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>, <code><a href="#topic+na.pattern">na.pattern</a></code>,
<code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Auxiliary variables
na.auxiliary(airquality)

# Example 2: Semi-partial correlation coefficients
na.auxiliary(airquality, model = "Ozone ~ Solar.R + Wind")

## Not run: 
# Example 3a: Write Results into a text file
na.auxiliary(airquality, write = "NA_Auxiliary.txt")

# Example 3a: Write Results into an Excel file
na.auxiliary(airquality, write = "NA_Auxiliary.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='na.coverage'>Variance-Covariance Coverage</h2><span id='topic+na.coverage'></span>

<h3>Description</h3>

<p>This function computes the proportion of cases that contributes for the calculation
of each variance and covariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.coverage(data, ..., tri = c("both", "lower", "upper"), digits = 2,
            as.na = NULL, write = NULL, append = TRUE, check = TRUE,
            output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.coverage_+3A_data">data</code></td>
<td>
<p>a data frame with incomplete data, where missing
values are coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>, e.g.,
<code>na.coverage(dat, x1, x2, x3)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_tri">tri</code></td>
<td>
<p>a character string or character vector indicating which triangular
of the matrix to show on the console, i.e., <code>both</code> for
upper and lower triangular, <code>lower</code> (default) for the
lower triangular, and <code>upper</code> for the upper triangular.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying proportions.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576. https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Compute variance-covariance coverage
na.coverage(airquality)

## Not run: 
# Example 2a: Write Results into a text file
na.coverage(airquality, write = "Coverage.txt")

# Example 2b: Write Results into a Excel file
na.coverage(airquality, write = "Coverage.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='na.descript'>Descriptive Statistics for Missing Data in Single-Level, Two-Level and Three-Level Data</h2><span id='topic+na.descript'></span>

<h3>Description</h3>

<p>This function computes descriptive statistics for missing data in single-level,
two-level, and three-level data, e.g. number of incomplete cases, number
of missing values, and summary statistics for the number of missing
values across all variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.descript(data, ..., cluster = NULL,  table = FALSE, digits = 2,
            as.na = NULL, write = NULL, append = TRUE, check = TRUE,
            output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.descript_+3A_data">data</code></td>
<td>
<p>a data frame with incomplete data, where missing
values are coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>na.descript(dat, x1, x2, x3)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the name of the cluster
variable in <code>data</code> for two-level data,
a character vector indicating the names of the cluster
variables in <code>data</code> for three-level data, or a vector
or data frame representing the nested grouping structure
(i.e., group or cluster variables). Alternatively, a
character string or character vector indicating the variable
name(s) of the cluster variable(s) in <code>data</code>. Note that
the cluster variable at Level 3 come first in a three-level
model, i.e., <code>cluster = c("level3", "level2")</code>.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_table">table</code></td>
<td>
<p>logical: if <code>TRUE</code>, a frequency table with number of
observed values (<code>"nObs"</code>), percent of observed values
(<code>"pObs"</code>), number of missing values (<code>"nNA"</code>),
and percent of missing values (<code>"pNA"</code>) is printed for
each variable on the console.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying percentages.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with results</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Single-Level Data

# Example 1: Descriptive statistics for missing data
na.descript(airquality)

# Example 2: Descriptive statistics for missing data, print results with 3 digits
na.descript(airquality, digits = 3)

# Example 3: Descriptive statistics for missing data with frequency table
na.descript(airquality, table = TRUE)

#----------------------------------------------------------------------------
# Two-Level Data

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Example 4: Descriptive statistics for missing data
na.descript(Demo.twolevel, cluster = "cluster")

#----------------------------------------------------------------------------
# Three-Level Data

# Create arbitrary three-level data
Demo.threelevel &lt;- data.frame(Demo.twolevel, cluster2 = Demo.twolevel$cluster,
                                             cluster3 = rep(1:10, each = 250))

# Example 5: Descriptive statistics for missing data
na.descript(Demo.threelevel, cluster = c("cluster3", "cluster2"))

## Not run: 
#----------------------------------------------------------------------------
# Write Results

# Example 6a: Write Results into a text file
na.descript(airquality, table = TRUE, write = "NA_Descriptives.txt")

# Example 6b: Write Results into a Excel file
na.descript(airquality, table = TRUE, write = "NA_Descriptives.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='na.indicator'>Missing Data Indicator Matrix</h2><span id='topic+na.indicator'></span>

<h3>Description</h3>

<p>This function creates a missing data indicator matrix <code class="reqn">R</code> that denotes whether
values are observed or missing, i.e., <code class="reqn">r = 0</code> if a value is observed, and
<code class="reqn">r = 1</code> if a value is missing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.indicator(data, ..., na = 1, append = TRUE, name = ".i", as.na = NULL,
             check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.indicator_+3A_data">data</code></td>
<td>
<p>a data frame with incomplete data, where missing
values are coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>, e.g.,
<code>na.indicator(dat, x1, x2, x3)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_na">na</code></td>
<td>
<p>an integer value specifying the value representing missing values,
i.e., either <code>na = 0</code> for <code>0 = missing</code> and
<code>1 = observed</code>, or <code>na = 1</code> (default) for <code>0</code> (observed)
and <code>1 = missing</code>.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), missing data indicator matrix
is appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_name">name</code></td>
<td>
<p>a character string indicating the name suffix of indicator variables
By default, the indicator variables are named with the ending
<code>".i"</code> resulting in e.g. <code>"x1.i"</code> and <code>"x2.i"</code>.
Note that when selecting one single variable, the indicator variable
is named <code>x.i</code> by default or named after the argument <code>name</code>.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix or data frame with <code class="reqn">r = 1</code> if a value is observed, and <code class="reqn">r = 0</code>
if a value is missing.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.). Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>, <code><a href="#topic+na.auxiliary">na.auxiliary</a></code>,
<code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.pattern">na.pattern</a></code>,
<code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Create missing data indicator matrix
na.indicator(airquality)

# Example 2: Do not append missing data indicator matrix to the data frame
na.indicator(airquality, append = FALSE)
</code></pre>

<hr>
<h2 id='na.pattern'>Missing Data Pattern</h2><span id='topic+na.pattern'></span>

<h3>Description</h3>

<p>This function computes a summary of missing data patterns, i.e., number (
cases with a specific missing data pattern and plots the missing data
patterns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.pattern(data, ..., order = FALSE, n.pattern = NULL, digits = 2, as.na = NULL,
           plot = FALSE, square = TRUE, rotate = FALSE,
           color = c("#B61A51B3", "#006CC2B3"), tile.alpha = 0.6,
           plot.margin = c(4, 16, 0, 4), legend.box.margin = c(-8, 6, 6, 6),
           legend.key.size = 12, legend.text.size = 9, filename = NULL,
           width = NA, height = NA, units = c("in", "cm", "mm", "px"),
           dpi = 600, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.pattern_+3A_data">data</code></td>
<td>
<p>a data frame with incomplete data, where
missing values are coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in
<code>data</code> e.g., <code>na.pattern(dat, x1, x2, x3)</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also
be used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_order">order</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables are ordered from left to
right in increasing order of missing values.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_n.pattern">n.pattern</code></td>
<td>
<p>an integer value indicating the minimum number of cases sharing
a missing data pattern to be included in the result table and the plot, e.g., specifying
<code>n.pattern = 5</code> excludes missing data patters with less than <code>5</code> cases.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying percentages.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to NA before conducting the
analysis.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, missing data pattern is plotted.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_square">square</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the plot tiles are squares
to mimic the <code>md.pattern</code> function in the package <span class="pkg">mice</span>.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_rotate">rotate</code></td>
<td>
<p>logical: if <code>TRUE</code>, the variable name labels are rotated 90 degrees.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_color">color</code></td>
<td>
<p>a character string indicating the color for the <code>"fill"</code> argument.
Note that the first color represents missing values and the second color
represent observed values.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_tile.alpha">tile.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for the <code>alpha</code> argument (default is <code>0.1</code>).</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_plot.margin">plot.margin</code></td>
<td>
<p>a numeric vector indicating the <code>plot.margin</code> argument for the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_legend.box.margin">legend.box.margin</code></td>
<td>
<p>a numeric vector indicating the <code>legend.box.margin</code>
argument for the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_legend.key.size">legend.key.size</code></td>
<td>
<p>a numeric value indicating the <code>legend.key</code>
argument (default is <code>unit(12, "pt")</code>) for the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>a numeric value indicating the <code>legend.text</code>
argument (default is <code>element_text(size = 10)</code>) for the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code> argument (default is <code>"NA_Pattern.pdf"</code>) including
the file extension for the <code>ggsave</code> function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default), <code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>, <code>".bmp"</code>,
<code>".svg"</code> or <code>".wmf"</code> needs to be specified as file extension in the <code>file</code> argument.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument (default is the
size of the current graphics device) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame with variables used in the analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>pattern</code></td>
<td>
<p>a numeric vector indicating the missing data pattern for each case</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The code for plotting missing data patterns is based on the <code>plot_pattern</code>
function in the <span class="pkg">ggmice</span> package by Hanne Oberman.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>Oberman, H. (2023). <em>ggmice: Visualizations for 'mice' with 'ggplot2'</em>.
R package version 0.1.0. https://doi.org/10.32614/CRAN.package.ggmice
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>,
<code><a href="#topic+na.indicator">na.indicator</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Compute a summary of missing data patterns
dat.pattern &lt;- na.pattern(airquality)

# Example 2a: Compute and plot a summary of missing data patterns
na.pattern(airquality, plot = TRUE)

# Example 2b: Exclude missing data patterns with less than 3 cases
na.pattern(airquality, plot = TRUE, n.pattern = 3)

# Example 3: Vector of missing data pattern for each case
dat.pattern$pattern

# Data frame without cases with missing data pattern 2 and 4
airquality[!dat.pattern$pattern == 2, ]

## Not run: 
# Example 4a: Write Results into a text file
na.pattern(airquality, write = "NA_Pattern.xlsx")

# Example 4b: Write Results into a Excel file
na.pattern(airquality, write = "NA_Pattern.xlsx")
## End(Not run)
</code></pre>

<hr>
<h2 id='na.prop'>Proportion of Missing Data for Each Case</h2><span id='topic+na.prop'></span>

<h3>Description</h3>

<p>This function computes the proportion of missing data for each case in a
data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.prop(data, ..., digits = 2, append = TRUE, name = "na.prop",
        as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.prop_+3A_data">data</code></td>
<td>
<p>a data frame with incomplete data, where missing
values are coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="na.prop_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>, e.g.,
<code>na.prop(dat, x1, x2, x3)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.prop_+3A_name">name</code></td>
<td>
<p>a character string indicating the name of the variable appended
to the data frame specified in the argument <code>data</code> when
<code>append = TRUE</code>.</p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code id="na.prop_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable with proportion of
missing data is appended to the data frame specified in the
argument <code>data</code></p>
</td></tr>
<tr><td><code id="na.prop_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying proportions.</p>
</td></tr>
<tr><td><code id="na.prop_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.prop_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector with the same length as the number of rows in <code>data</code>
containing the proportion of missing data.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>, <code><a href="#topic+na.auxiliary">na.auxiliary</a></code>,
<code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Compute proportion of missing data for each case in the data frame
na.prop(airquality)

# Example 2: Do not append proportions of missing data to the data frame
na.prop(airquality, append = FALSE)
</code></pre>

<hr>
<h2 id='na.satcor'>Fit a Saturated Correlates Model</h2><span id='topic+na.satcor'></span><span id='topic+cfa.satcor'></span><span id='topic+sem.satcor'></span><span id='topic+growth.satcor'></span><span id='topic+lavaan.satcor'></span>

<h3>Description</h3>

<p>This function estimates a confirmatory factor analysis model (<code>cfa.satcor</code>
function), structural equation model (<code>sem.satcor</code> function), growth curve
model (<code>growth.satcor</code> function), or latent variable model (<code>lavaan.satcor</code>
function) in the R package <span class="pkg">lavaan</span> using full information maximum likelihood
(FIML) method to handle missing data while automatically specifying a saturated
correlates model to incorporate auxiliary variables into a substantive model
without affecting the parameter estimates, the standard errors, or the estimates
of quality of fit (Graham, 2003).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.satcor(model, data, aux, fun = c("cfa", "sem", "growth", "lavaan"),
          check = TRUE, ...)

cfa.satcor(model, data, aux, check = TRUE, ...)

sem.satcor(model, data, aux, check = TRUE, ...)

growth.satcor(model, data, aux, check = TRUE, ...)

lavaan.satcor(model, data, aux, check = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.satcor_+3A_model">model</code></td>
<td>
<p>a character string indicating the lavaan model syntax without the
auxiliary variables specified in <code>aux</code>.</p>
</td></tr>
<tr><td><code id="na.satcor_+3A_data">data</code></td>
<td>
<p>a data frame containing the observed variables used in the lavaan
model syntax specified in <code>model</code> and the auxiliary variables
specified in <code>aux</code>.</p>
</td></tr>
<tr><td><code id="na.satcor_+3A_aux">aux</code></td>
<td>
<p>a character vector indicating the names of the auxiliary variables
in the data frame specified in <code>data</code> that will be added to
the lavaan model syntax specified in <code>model</code>. Note that
this function can only incorporate continuous auxiliary variables,
i.e., the function cannot deal with categorical auxiliary variables.</p>
</td></tr>
<tr><td><code id="na.satcor_+3A_fun">fun</code></td>
<td>
<p>a character string indicating the name of a specific lavaan function
used to fit <code>model</code>, i.e., <code>cfa</code>, <code>sem</code>, <code>growth</code>,
or <code>lavaan</code>. Note that this argument is only required for
the function <code>na.satcor</code>.</p>
</td></tr>
<tr><td><code id="na.satcor_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="na.satcor_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the lavaan function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class lavaan, for which several methods are available in the
R package <span class="pkg">lavaan</span>, including  a summary method.
</p>


<h3>Note</h3>

<p>This function is a modified copy of the <code>auxiliary()</code>, <code>cfa.auxiliary()</code>,
<code>sem.auxiliary()</code>, <code>growth.auxiliary()</code>, and <code>lavaan.auxiliary()</code>
functions in the <span class="pkg">semTools</span> package by Terrence D. Jorgensen et al.
(2022).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Graham, J. W. (2003). Adding missing-data-relevant variables to FIML-based
structural equation models. <em>Structural Equation Modeling, 10</em>(1), 80-100.
https://doi.org/10.1207/S15328007SEM1001_4
</p>
<p>Jorgensen, T. D., Pornprasertmanit, S., Schoemann, A. M., &amp; Rosseel, Y. (2022).
<em>semTools: Useful tools for structural equation modeling</em>. R package version
0.5-6. Retrieved from https://CRAN.R-project.org/package=semTools
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load lavaan package
library(lavaan)

#----------------------------------------------------------------------------
# Example 1: Saturated correlates model for the sem function

# Model specification
model &lt;- 'Ozone ~ Wind'

# Model estimation using the sem.satcor function
mod.fit &lt;- sem.satcor(model, data = airquality, aux = c("Temp", "Month"))

# Model estimation using the na.satcor function
mod.fit &lt;- na.satcor(model, data = airquality, fun = "sem", aux = c("Temp", "Month"),
                     estimator = "MLR")

# Result summary
summary(mod.fit)
</code></pre>

<hr>
<h2 id='na.test'>Missing Completely at Random (MCAR) Test</h2><span id='topic+na.test'></span>

<h3>Description</h3>

<p>This function performs Little's Missing Completely at Random (MCAR) test and
Jamshidian and Jalal's approach for testing the MCAR assumption. By default,
the function performs the Little's MCAR test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.test(data, ..., print = c("all", "little", "jamjal"),
        impdat = NULL, delete = 6, method = c("npar", "normal"),
        m = 20, seed = 123, nrep = 10000, n.min = 30,
        pool = c("m", "med", "min", "max", "random"),
        alpha = 0.05, digits = 2, p.digits = 3, as.na = NULL,
        write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.test_+3A_data">data</code></td>
<td>
<p>a data frame with incomplete data, where missing values are
coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="na.test_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>, e.g.,
<code>na.test(dat, x1, x2, x3)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.test_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to be printed on
the console, i.e. <code>"all"</code> for Little's MCAR test and Jamshidian and
Jalal's approach, <code>"little"</code> (default) for Little's MCAR test, and
<code>"jamjal"</code> for Jamshidian and Jalal's approach.</p>
</td></tr>
<tr><td><code id="na.test_+3A_impdat">impdat</code></td>
<td>
<p>an object of class <code>mids</code> from the <span class="pkg">mice</span> package to
provide a data set multiply imputed in the <span class="pkg">mice</span> package.
The function will not impute the data data set specified in
the argument <code>data</code> when specifying this argument and will
use the imputed data sets provided in the argument <code>impdat</code>
for performing the Jamshidian and Jalal's approach. Note that
the argument <code>data</code> still needs to be specified because
the variables used for the analysis are extracted from the
data frame specified in <code>data</code>.</p>
</td></tr>
<tr><td><code id="na.test_+3A_delete">delete</code></td>
<td>
<p>an integer value indicating missing data patterns consisting
of <code>delete</code> number of cases or less removed from the
Jamshidian and Jalal's approach. The default setting is
<code>delete = 6</code>.</p>
</td></tr>
<tr><td><code id="na.test_+3A_method">method</code></td>
<td>
<p>a character string indicating the imputation method, i.e.,
<code>"npar"</code> for using a non-parametric imputation method
by Sirvastava and Dolatabadi (2009) or <code>"normal"</code> for
imputing missing data assuming that the data come from a
multivariate normal distribution (see Jamshidian &amp; Jalal, 2010).</p>
</td></tr>
<tr><td><code id="na.test_+3A_m">m</code></td>
<td>
<p>an integer value indicating the number of multiple imputations.
The default setting is <code>m = 20</code>.</p>
</td></tr>
<tr><td><code id="na.test_+3A_seed">seed</code></td>
<td>
<p>an integer value that is used as argument by the <code>set.seed</code>
function for offsetting the random number generator before
performing Jamshidian and Jalal's approach. The default
setting is <code>seed = 123</code>. Set the value to <code>NULL</code> to
specify a system selected seed.</p>
</td></tr>
<tr><td><code id="na.test_+3A_nrep">nrep</code></td>
<td>
<p>an integer value indicating the replications used to simulate
the Neyman distribution to determine the cut off value for the
Neyman test. Larger values increase the accuracy of the Neyman
test. The default setting is <code>nrep = 10000</code>.</p>
</td></tr>
<tr><td><code id="na.test_+3A_n.min">n.min</code></td>
<td>
<p>an integer value indicating the minimum number of cases in a
group that triggers the use of asymptotic Chi-square distribution
in place of the empirical distribution in the Neyman test of
uniformity.</p>
</td></tr>
<tr><td><code id="na.test_+3A_pool">pool</code></td>
<td>
<p>a character string indicating the pooling method, i.e.,
<code>"m"</code> for computing the average test statistic and p-values,
<code>"med"</code> for computing the median test statistic and p-values,
<code>"min"</code> for computing the maximum test statistic and minimum p-values,
<code>"max"</code> for computing the minimum test statistic and maximum p-values,
and <code>"random"</code> for randomly choosing a test statistic and
corresponding p-value from repeated complete data analyses.
The default setting is <code>pool = "med"</code>, i.e., median test
statistic and p-values are computed as suggested by
Eekhout, Wiel and Heymans (2017).</p>
</td></tr>
<tr><td><code id="na.test_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the significance
level of the Hawkins test. The default setting is <code>alpha = 0.05</code>,
i.e., the Anderson-Darling non-parametric test is provided
when the p-value of the Hawkins test is less than or equal
<code>0.05</code>.</p>
</td></tr>
<tr><td><code id="na.test_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying results.</p>
</td></tr>
<tr><td><code id="na.test_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="na.test_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.
these values are converted to NA before conducting the analysis.</p>
</td></tr>
<tr><td><code id="na.test_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="na.test_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.test_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.test_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Little's MCAR Test</strong></dt><dd>
<p>Little (1988) proposed a multivariate test of Missing Completely at Random
(MCAR) that tests for mean differences on every variable in the data set
across subgroups that share the same missing data pattern by comparing the
observed variable means for each pattern of missing data with the expected
population means estimated using the expectation-maximization (EM) algorithm
(i.e., EM maximum likelihood estimates). The test statistic is the sum of
the squared standardized differences between the subsample means and the
expected population means weighted by the estimated variance-covariance
matrix and the number of observations within each subgroup (Enders, 2010).
Under the null hypothesis that data are MCAR, the test statistic follows
asymptotically a chi-square distribution with <code class="reqn">\sum k_j - k</code> degrees of
freedom, where <code class="reqn">k_j</code> is the number of complete variables for missing data
pattern <code class="reqn">j</code>, and <code class="reqn">k</code> is the total number of variables. A statistically
significant result provides evidence against MCAR.
</p>
<p>Note that Little's MCAR test has a number of problems (see Enders, 2010).
</p>

<ul>
<li><p><strong>First</strong>, the test does not identify the specific variables
that violates MCAR, i.e., the test does not identify potential correlates
of missingness (i.e., auxiliary variables).
</p>
</li>
<li><p><strong>Second</strong>, the test is based on multivariate normality,
i.e., under departure from the normality assumption the test might be
unreliable unless the sample size is large and is not suitable for
categorical variables.
</p>
</li>
<li><p><strong>Third</strong>, the test investigates mean differences assuming
that the missing data pattern share a common covariance matrix, i.e.,
the test cannot detect covariance-based deviations from MCAR stemming
from a Missing at Random (MAR) or Missing Not at Random (MNAR) mechanism
because MAR and MNAR mechanisms can also produce missing data subgroups
with equal means.
</p>
</li>
<li><p><strong>Fourth</strong>, simulation studies suggest that Little's MCAR
test suffers from low statistical power, particularly when the number
of variables that violate MCAR is small, the relationship between the
data and missingness is weak, or the data are MNAR (Thoemmes &amp; Enders,
2007).
</p>
</li>
<li><p><strong>Fifth</strong>, the test can only reject, but cannot prove the
MCAR assumption, i.e., a statistically not significant result and failing
to reject the null hypothesis of the MCAR test does not prove the null
hypothesis that the data is MCAR.
</p>
</li>
<li><p><strong>Sixth</strong>, under the null hypothesis the data are actually
MCAR or MNAR, while a statistically significant result indicates that
missing data are MAR or MNAR, i.e., MNAR cannot be ruled out regardless
of the result of the test.
</p>
</li></ul>

<p>The function for performing Little's MCAR test is based on the <code>mlest</code>
function from the <span class="pkg">mvnmle</span> package which can handle up to 50 variables.
Note that the <code>mcar_test</code> function in the <span class="pkg">naniar</span> package is based
on the <code>prelim.norm</code> function from the <span class="pkg">norm</span> package. This function
can handle about 30 variables, but with more than 30 variables specified in
the argument <code>data</code>, the <code>prelim.norm</code> function might run into
numerical problems leading to results that are not trustworthy (i.e.,
<code>p.value = 1</code>). In that case, the warning message
<code>In norm::prelim.norm(data) : NAs introduced by coercion to integer range</code>
is printed on the console.</p>
</dd>
<dt><strong>Jamshidian and Jalal's Approach for Testing MCAR</strong></dt><dd><p>Jamshidian
and Jalal (2010) proposed an approach for testing the Missing Completely at
Random (MCAR) assumption based on two tests of multivariate normality and
homogeneity of covariances among groups of cases with identical missing data
patterns:
</p>

<ol>
<li><p><strong>In the first step</strong>, missing data are multiply imputed
(<code>m = 20</code> times by default) using a non-parametric imputation method
(<code>method = "npar"</code> by default) by Sirvastava and Dolatabadi (2009)
or using a parametric imputation method assuming multivariate normality
of data (<code>method = "normal"</code>) for each group of cases sharing a common
missing data pattern.
</p>
</li>
<li><p><strong>In the second step</strong>, a modified Hawkins test for multivariate
normality and homogeneity of covariances applicable to complete data
consisting of groups with a small number of cases is performed. A statistically
not significant result indicates no evidence against multivariate normality
of data or homogeneity of covariances, while a statistically significant
result provides evidence against multivariate normality of data or homogeneity
of covariances (i.e., violation of the MCAR assumption). Note that the
Hawkins test is a test of multivariate normality as well as homogeneity
of covariance. Hence, a statistically significant test is ambiguous unless
the researcher assumes multivariate normality of data.
</p>
</li>
<li><p><strong>In the third step</strong>, if the Hawkins test is statistically
significant, the Anderson-Darling non-parametric test is performed. A
statistically not significant result indicates evidence against multivariate
normality of data but no evidence against homogeneity of covariances, while
a statistically significant result provides evidence against homogeneity
of covariances (i.e., violation of the MCAR assumption). However, no
conclusions can be made about the multivariate normality of data when the
Anderson-Darling non-parametric test is statistically significant.
</p>
</li></ol>

<p>In summary, a statistically significant result of both the Hawkins and the
Anderson-Darling non-parametric test provides evidence against the MCAR assumption.
The test statistic and the significance values of the Hawkins test and the
Anderson-Darling non-parametric based on multiply imputed data sets are pooled
by computing the median test statistic and significance value (<code>pool = "med"</code>
by default) as suggested by Eekhout, Wiel, and Heymans (2017).
</p>
<p>Note that out of the problems listed for the Little's MCAR test the first,
second (i.e., approach is not suitable for categorical variables), fifth,
and sixth problems also apply to the Jamshidian and Jalal's approach for
testing the MCAR assumption.
</p>
</dd>
</dl>
<p>In practice, rejecting or not rejecting the MCAR assumption may not be relevant
as modern missing data handling methods like full information maximum likelihood
(FIML) estimation, Bayesian estimation, or multiple imputation are asymptotically
valid under the missing at random (MAR) assumption (Jamshidian &amp; Yuan, 2014).
It is more important to distinguish MAR from missing not at random (MNAR),
but MAR and MNAR mechanisms cannot be distinguished without auxiliary
information.

</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>little</code> for the
result table of the Little's MCAR test, <code>jamjal</code>
for the list with results of the Jamshidian and Jalal's
approach, <code>hawkins</code> for the result table of the
Hawkins test, and <code>anderson</code> for the result table of
the Anderson-Darling non-parametric test</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The code for Little's MCAR test is a modified copy of the <code>LittleMCAR</code>
function in the <span class="pkg">BaylorEdPsych</span> package by A. Alexander Beaujean. The code
for Jamshidian and Jalal's approach is a modified copy of the <code>TestMCARNormality</code>
function in the <span class="pkg">MissMech</span> package by Mortaza Jamshidian, Siavash Jalal,
Camden Jansen, and Mao Kobayashi (2024).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Beaujean, A. A. (2012). <em>BaylorEdPsych: R Package for Baylor University
Educational Psychology Quantitative Courses</em>. R package version 0.5.
http://cran.nexr.com/web/packages/BaylorEdPsych/index.html
</p>
<p>Eekhout, I., M. A. Wiel, &amp; M. W. Heymans (2017). Methods for significance
testing of categorical covariates in logistic regression models after multiple
imputation: Power and applicability analysis. <em>BMC Medical Research
Methodology</em>, 17:129. https://doi.org/10.1186/s12874-017-0404-7
</p>
<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Little, R. J. A. (1988). A test of Missing Completely at Random for multivariate
data with missing values. <em>Journal of the American Statistical Association,
83</em>, 1198-1202. https://doi.org/10.2307/2290157
</p>
<p>Jamshidian, M., &amp; Jalal, S. (2010). Tests of homoscedasticity, normality, and
missing completely at random for incomplete multivariate data. <em>Psychometrika,
75</em>(4), 649-674. https://doi.org/10.1007/s11336-010-9175-3
</p>
<p>Jamshidian, M., &amp; Yuan, K.H. (2014). Examining missing data mechanisms via
homogeneity of parameters, homogeneity of distributions, and multivariate
normality. <em>WIREs Computational Statistics, 6</em>(1), 56-73.
https://doi.org/10.1002/wics.1287
</p>
<p>Mortaza, J., Siavash, J., Camden, J., &amp; Kobayashi, M. (2024). <em>MissMech:
Testing Homoscedasticity, Multivariate Normality, and Missing Completely at
Random</em>. R package version 1.0.4. https://doi.org/10.32614/CRAN.package.MissMech
</p>
<p>Srivastava, M.S., &amp; Dolatabadi, M. (2009). Multiple imputation and other
resampling scheme for imputing missing observations. <em>Journal of Multivariate
Analysis, 100</em>, 1919-1937. https://doi.org/10.1016/j.jmva.2009.06.003
</p>
<p>Thoemmes, F., &amp; Enders, C. K. (2007, April). <em>A structural equation model for
testing whether data are missing completely at random</em>. Paper presented at the
annual meeting of the American Educational Research Association, Chicago, IL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>, <code><a href="#topic+na.auxiliary">na.auxiliary</a></code>,
<code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Perform Little's MCAR test and Jamshidian and Jalal's approach
na.test(airquality)

# Alternative specification using the 'data' argument,
na.test(., data = airquality)

# Example 2: Perform Jamshidian and Jalal's approach
na.test(airquality, print = "jamjal")

## Not run: 
# Example 3: Write results into a text file
na.test(airquality, write = "NA_Test.txt")
## End(Not run)
</code></pre>

<hr>
<h2 id='plot.misty.object'>Plots misty.object object</h2><span id='topic+plot.misty.object'></span>

<h3>Description</h3>

<p>This function plots an <code>misty.object</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'misty.object'
plot(x, plot = x$args$plot, bar = x$args$bar,
     box = x$args$box, violin = x$args$violin, hist = x$args$hist,
     point = x$args$point, line = x$args$line, ci = x$args$ci,
     conf.level = x$args$conf.level, adjust = x$args$adjust,
     jitter = x$args$jitter, density = x$args$density,
     square = x$args$square, rotate = x$args$rotate,
     binwidth = x$args$binwidth, bins = x$args$bins,
     fill = x$args$fill, hist.alpha = x$args$hist.alpha,
     tile.alpha = x$args$tile.alpha, violin.alpha = x$args$violin.alpha,
     violin.trim = x$args$violin.trim, box.width = x$args$box.width,
     box.alpha = x$args$box.alpha, linetype = x$args$linetype,
     linewidth = x$args$linewidth, line.col = x$args$line.col,
     intercept = x$args$intercept, density.col = x$args$density.col,
     density.linewidth = x$args$density.linewidth,
     density.linetype = x$args$density.linetype,
     point.size = x$args$point.size, point.linewidth = x$args$point.linewidth,
     point.linetype = x$args$point.linetype,
     point.shape = x$args$point.shape, point.col = x$args$point.col,
     ci.col = x$args$ci.col, ci.linewidth = x$args$ci.linewidth,
     ci.linetype = x$args$ci.linetype, errorbar.width = x$args$errorbar.width,
     dodge.width = x$args$dodge.width, jitter.size = x$args$jitter.size,
     jitter.width = x$args$jitter.width, jitter.height = x$args$jitter.height,
     jitter.alpha = x$args$jitter.alpha, gray = x$args$gray,
     start = x$args$start, end = x$args$end, color = x$args$color,
     xlab = x$args$xlab, ylab = x$args$ylab,
     xlim = x$args$xlim, ylim = x$args$ylim,
     xbreaks = x$args$xbreaks, ybreaks = x$args$ybreaks,
     axis.title.size = x$args$axis.title.sizes,
     axis.text.size = x$args$axis.text.size,
     strip.text.size = x$args$strip.text.size, title = x$args$title,
     subtitle = x$args$subtitle, group.col = x$args$group.col,
     plot.margin = x$args$plot.margin, legend.title = x$args$legend.title,
     legend.position = x$args$legend.position,
     legend.box.margin = x$args$legend.box.margin,
     legend.key.size = x$args$legend.key.size,
     legend.text.size = x$args$legend.text.size,
     facet.ncol = x$args$facet.ncol, facet.nrow = x$args$facet.nrow,
     facet.scales = x$args$facet.scales, filename = x$args$filename,
     width = x$args$width, height = x$args$height, units = x$args$units,
     dpi = x$args$dpi, check = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.misty.object_+3A_x">x</code></td>
<td>
<p><code>misty.object</code> object.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_plot">plot</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g.,
<code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_bar">bar</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_box">box</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_violin">violin</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_hist">hist</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_point">point</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>), or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_line">line</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.w">aov.w</a></code>,
<code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>), or <code><a href="#topic+test.t">test.t</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_ci">ci</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_conf.level">conf.level</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_adjust">adjust</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or
<code><a href="#topic+test.welch">test.welch</a></code>,</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_jitter">jitter</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>,  <code><a href="#topic+test.t">test.t</a></code>,
<code><a href="#topic+test.levene">test.levene</a></code>,or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_density">density</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_square">square</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+na.pattern">na.pattern</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_rotate">rotate</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+na.pattern">na.pattern</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_binwidth">binwidth</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_bins">bins</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_fill">fill</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_hist.alpha">hist.alpha</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_tile.alpha">tile.alpha</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+na.pattern">na.pattern</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_violin.alpha">violin.alpha</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_violin.trim">violin.trim</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_box.width">box.width</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_box.alpha">box.alpha</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_linetype">linetype</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>)
or <code><a href="#topic+test.t">test.t</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_linewidth">linewidth</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+test.t">test.t</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_line.col">line.col</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_intercept">intercept</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_density.col">density.col</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_density.linewidth">density.linewidth</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_density.linetype">density.linetype</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_point.size">point.size</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>), <code><a href="#topic+test.t">test.t</a></code>,
or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_point.linewidth">point.linewidth</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_point.linetype">point.linetype</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_point.shape">point.shape</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_point.col">point.col</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_ci.col">ci.col</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_ci.linewidth">ci.linewidth</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_ci.linetype">ci.linetype</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>), <code><a href="#topic+test.t">test.t</a></code>,
or <code><a href="#topic+test.welch">test.welch</a></code>,</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_dodge.width">dodge.width</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_jitter.size">jitter.size</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.levene">test.levene</a></code>,
<code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_jitter.width">jitter.width</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.levene">test.levene</a></code>,
<code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_jitter.height">jitter.height</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or
<code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.levene">test.levene</a></code>,
<code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_gray">gray</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+multilevel.r2">multilevel.r2</a></code>
or <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_start">start</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+multilevel.r2">multilevel.r2</a></code>
or <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_end">end</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+multilevel.r2">multilevel.r2</a></code>
or <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_color">color</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+multilevel.r2">multilevel.r2</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, or <code><a href="#topic+test.levene">test.levene</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_xlab">xlab</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_ylab">ylab</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_xlim">xlim</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or
<code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_ylim">ylim</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_xbreaks">xbreaks</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or
<code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_ybreaks">ybreaks</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_axis.title.size">axis.title.size</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_axis.text.size">axis.text.size</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_strip.text.size">strip.text.size</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_title">title</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_subtitle">subtitle</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_group.col">group.col</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_plot.margin">plot.margin</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_legend.title">legend.title</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_legend.position">legend.position</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_legend.box.margin">legend.box.margin</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>)
or <code><a href="#topic+na.pattern">na.pattern</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_legend.key.size">legend.key.size</code></td>
<td>
<p>see 'Arguments' in the function <code><a href="#topic+na.pattern">na.pattern</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+na.pattern">na.pattern</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_facet.ncol">facet.ncol</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_facet.nrow">facet.nrow</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_facet.scales">facet.scales</code></td>
<td>
<p>see 'Arguments' in the functions <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>).</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_filename">filename</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_width">width</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_height">height</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_units">units</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_dpi">dpi</code></td>
<td>
<p>see 'Arguments' in the functions <code><a href="#topic+aov.b">aov.b</a></code>,
<code><a href="#topic+aov.w">aov.w</a></code>, <code>ci.*</code> (e.g., <code><a href="#topic+ci.cor">ci.cor</a></code>),
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.t">test.t</a></code>, or <code><a href="#topic+test.welch">test.welch</a></code>.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="plot.misty.object_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>

<hr>
<h2 id='print.misty.object'>Print misty.object object</h2><span id='topic+print.misty.object'></span>

<h3>Description</h3>

<p>This function prints an <code>misty.object</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'misty.object'
print(x,
      print = x$args$print, tri = x$args$tri, freq = x$args$freq,
      hypo = x$args$hypo, descript = x$args$descript, epsilon = x$args$epsilon,
      effsize = x$args$effsize, posthoc = x$args$posthoc, split = x$args$split,
      table = x$args$table, digits = x$args$digits, p.digits = x$args$p.digits,
      icc.digits = x$args$icc.digits, r.digits = x$args$r.digits,
      ess.digits = x$args$ess.digits, mcse.digits = x$args$mcse.digits,
      sort.var = x$args$sort.var, order = x$args$order, check = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.misty.object_+3A_x">x</code></td>
<td>
<p><code>misty.object</code> object.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to to be printed on the console.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_tri">tri</code></td>
<td>
<p>a character string or character vector indicating which
triangular of the matrix to show on the console, i.e.,
<code>both</code> for upper and lower triangular, <code>lower</code>
for the lower triangular, and <code>upper</code> for the upper
triangular.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_freq">freq</code></td>
<td>
<p>logical: if <code>TRUE</code>, absolute frequencies will be included
in the cross tabulation (<code>crosstab()</code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code>, null and alternative hypothesis are
shown on the console (<code><a href="#topic+test.t">test.t</a></code>,
<code><a href="#topic+test.welch">test.welch</a></code>, <code><a href="#topic+test.z">test.z</a></code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code>, descriptive statistics are shown on
the console (<code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>,
<code><a href="#topic+test.z">test.z</a></code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_epsilon">epsilon</code></td>
<td>
<p>logical: if <code>TRUE</code>, box indices of sphericity (epsilon)
are shown on the console (<code><a href="#topic+aov.w">aov.w</a></code>).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measure(s) is shown on
the console (<code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>,
<code><a href="#topic+test.z">test.z</a></code> function).
<code><a href="#topic+test.z">test.z</a></code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_posthoc">posthoc</code></td>
<td>
<p>logical: if <code>TRUE</code>,post hoc test for multiple comparison
is shown on the console (<code><a href="#topic+test.welch">test.welch</a></code>).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is split by variables
when specifying more than one variable in <code>x</code>
(<code><a href="#topic+freq">freq</a></code>).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_table">table</code></td>
<td>
<p>logical: if <code>TRUE</code>, a frequency table with number of
observed values (<code>"nObs"</code>), percent of observed values
(<code>"pObs"</code>), number of missing values (<code>"nNA"</code>),
and percent of missing values (<code>"pNA"</code>) is printed for
each variable on the console (<code>na.descript()</code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_icc.digits">icc.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying intraclass correlation coefficients
(<code>multilevel.descript()</code> and <code>multilevel.icc()</code>
function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_r.digits">r.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying R-hat values.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_ess.digits">ess.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying effective sample sizes.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_mcse.digits">mcse.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying monte carlo standard errors.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output is sorted by variables.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_order">order</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables are ordered from left to
right in increasing order
of missing values (<code>na.descript()</code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, argument specification is checked.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>

<hr>
<h2 id='read.data'>Read Data File in Table format, SPSS, Excel, or Stata DTA File</h2><span id='topic+read.data'></span>

<h3>Description</h3>

<p>This function reads a (1) data file in CSV (<code>.csv</code>), DAT (<code>.dat</code>),
or TXT (<code>.txt</code>) format using the <code>fread</code> function from the <span class="pkg">data.table</span>
package, (2) SPSS file (<code>.sav</code>) using the <code>read.sav</code> function, (3)
Excel file (<code>.xlsx</code>) using the <code>read.xlsx</code> function, or a (4) Stata
DTA file (<code>.dta</code>) using the <code>read.dta</code> function in the <span class="pkg">misty</span>
package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.data(file, sheet = NULL, header = TRUE, select = NULL, drop = NULL,
          sep = "auto", dec = "auto", use.value.labels = FALSE,
          use.missings = TRUE, na.strings = c("NA", ""),
          stringsAsFactors = FALSE, formats = FALSE, label = FALSE,
          labels = FALSE, missing = FALSE, widths = FALSE, as.data.frame = TRUE,
          encoding = c("unknown", "UTF-8", "Latin-1"), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.data_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the data file
with the file extension <code>.csv</code>, <code>.dat</code>,
<code>.txt</code>, <code>.sav</code>, <code>.xlsx</code>, or <code>.dta</code>.
Note that the function will select an appropriate
<code>read</code>-function depending on the file extension.</p>
</td></tr>
<tr><td><code id="read.data_+3A_sheet">sheet</code></td>
<td>
<p>a character string indicating the name of a Excel sheet
or a numeric value indicating the position of the Excel
sheet to read. By default the first sheet will be read
when reading an Excel file (<code>.xlsx</code>).</p>
</td></tr>
<tr><td><code id="read.data_+3A_header">header</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the first row is used
as column names when reading an Excel file (<code>.xlsx</code>),
if <code>FALSE</code> default names are used. A character vector
giving a name for each column can also be used.</p>
</td></tr>
<tr><td><code id="read.data_+3A_select">select</code></td>
<td>
<p>a character vector of column names or numeric vector to
keep, drop the rest. See the help page of the
<code>fread</code> function in the <span class="pkg">data.table</span> package.</p>
</td></tr>
<tr><td><code id="read.data_+3A_drop">drop</code></td>
<td>
<p>a character vector of column names or numeric vector
to drop, keep the rest.</p>
</td></tr>
<tr><td><code id="read.data_+3A_sep">sep</code></td>
<td>
<p>a character string indicating the separator between
columns for the <code>fread</code> function when reading data
in CSV (<code>.csv</code>), DAT (<code>.dat</code>), or TXT (<code>.txt</code>)
format.</p>
</td></tr>
<tr><td><code id="read.data_+3A_dec">dec</code></td>
<td>
<p>a character string indicating the decimal separator
for the <code>fread</code> function when reading data in CSV
(<code>.csv</code>), DAT (<code>.dat</code>), or TXT (<code>.txt</code>)
format.</p>
</td></tr>
<tr><td><code id="read.data_+3A_use.value.labels">use.value.labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables with value labels
are converted into factors.</p>
</td></tr>
<tr><td><code id="read.data_+3A_use.missings">use.missings</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), user-defined missing
values are converted into NAs.</p>
</td></tr>
<tr><td><code id="read.data_+3A_na.strings">na.strings</code></td>
<td>
<p>a character vector of strings which are to be interpreted
as NA values.</p>
</td></tr>
<tr><td><code id="read.data_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>logical: if <code>TRUE</code>, character vectors are converted
to factors.</p>
</td></tr>
<tr><td><code id="read.data_+3A_formats">formats</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable formats are shown in
an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.data_+3A_label">label</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable labels are shown in
an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.data_+3A_labels">labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, value labels are shown in an
attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.data_+3A_missing">missing</code></td>
<td>
<p>logical: if <code>TRUE</code>, value labels for user-defined
missings are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.data_+3A_widths">widths</code></td>
<td>
<p>logical: if <code>TRUE</code>, widths are shown in an attribute
for all variables.</p>
</td></tr>
<tr><td><code id="read.data_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), function returns a
regular data frame; if <code>FALSE</code> function returns
a tibble or data.table.</p>
</td></tr>
<tr><td><code id="read.data_+3A_encoding">encoding</code></td>
<td>
<p>a character string indicating the encoding, i.e.,
<code>"unknown"</code>, <code>"UTF-8"</code>, or <code>"Latin-1"</code>
(default).</p>
</td></tr>
<tr><td><code id="read.data_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame, tibble, or data table.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida
</p>


<h3>References</h3>

<p>Barrett, T., Dowle, M., Srinivasan, A., Gorecki, J., Chirico, M., Hocking, T.,
&amp; Schwendinger, B. (2024). data.table: Extension of 'data.frame'. R package
version 1.16.0. <a href="https://CRAN.R-project.org/package=data.table">https://CRAN.R-project.org/package=data.table</a>
</p>
<p>Wickham H, Miller E, Smith D (2023). <em>haven: Import and Export 'SPSS',
'Stata' and 'SAS' Files</em>. R package version 2.5.3.
<a href="https://CRAN.R-project.org/package=haven">https://CRAN.R-project.org/package=haven</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.sav">read.sav</a></code>, <code><a href="#topic+read.xlsx">read.xlsx</a></code>, <code><a href="#topic+read.dta">read.dta</a></code>,
<code><a href="#topic+read.mplus">read.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Read CSV data file
dat &lt;- read.data("CSV_Data.csv")

# Read DAT data file
dat &lt;- read.data("DAT_Data.dat")

# Read TXT data file
dat &lt;- read.data("TXT_Data.txt")

# Read SPSS data file
dat &lt;- read.data("SPSS_Data.sav")

# Read Excel data file
dat &lt;- read.data("Excel_Data.xlsx")

# Read Stata data file
dat &lt;- read.data("Stata_Data.dta")

## End(Not run)
</code></pre>

<hr>
<h2 id='read.dta'>Read Stata DTA File</h2><span id='topic+read.dta'></span>

<h3>Description</h3>

<p>This function calls the <code>read_dta</code> function in the <span class="pkg">haven</span> package
by Hadley Wickham, Evan Miller and Danny Smith (2023) to read a Stata DTA file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.dta(file, use.value.labels = FALSE, formats = FALSE, label = FALSE, labels = FALSE,
         missing = FALSE,   widths = FALSE, as.data.frame = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.dta_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the Stata
data file with or without file extension '.dta', e.g.,
<code>"Stata_Data.dta"</code> or <code>"Stata_Data"</code>.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_use.value.labels">use.value.labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables with value labels
are converted into factors.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_formats">formats</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable formats are
shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_label">label</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable labels are
shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_labels">labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, value labels are
shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_missing">missing</code></td>
<td>
<p>logical: if <code>TRUE</code>, convert tagged missing values
to regular R <code>NA</code>.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_widths">widths</code></td>
<td>
<p>logical: if <code>TRUE</code>, widths are shown in an attribute
for all variables.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), function returns a
regular data frame;
if <code>FALSE</code> function returns a tibble.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame or tibble.
</p>


<h3>Note</h3>

<p>This function is a modified copy of the <code>read_dta()</code> function in the
<span class="pkg">haven</span> package by Hadley Wickham, Evan Miller and Danny Smith (2023).
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham and Evan Miller
</p>


<h3>References</h3>

<p>Wickham H, Miller E, Smith D (2023). <em>haven: Import and Export 'SPSS',
'Stata' and 'SAS' Files</em>. R package version 2.5.3.
<a href="https://CRAN.R-project.org/package=haven">https://CRAN.R-project.org/package=haven</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.sav">read.sav</a></code>, <code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+read.xlsx">read.xlsx</a></code>,
<code><a href="#topic+write.xlsx">write.xlsx</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

read.dta("Stata_Data.dta")
read.dta("Stata_Data")

# Example 2: Read Stata data, convert variables with value labels into factors
read.dta("Stata_Data.dta", use.value.labels = TRUE)

# Example 3: Read Stata data as tibble
read.dta("Stata_Data.dta", as.data.frame = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='read.mplus'>Read Mplus Data File and Variable Names</h2><span id='topic+read.mplus'></span>

<h3>Description</h3>

<p>This function reads a Mplus data file and/or Mplus input/output file to return
a data frame with variable names extracted from the Mplus input/output file. Note
that by default <code>-99</code> in the Mplus data file is replaced with to <code>NA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.mplus(file, sep = "", input = NULL, na = -99, print = FALSE, return.var = FALSE,
           encoding = "UTF-8-BOM", check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.mplus_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the Mplus data
file with or without the file extension <code>.dat</code>, e.g.,
<code>"Mplus_Data.dat"</code> or <code>"Mplus_Data"</code>.
Note that it is not necessary to specify this argument when
<code>return.var = TRUE</code>.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_sep">sep</code></td>
<td>
<p>a character string indicating the field separator (i.e.,
delimiter) used in the data file specified in <code>file</code>.
By default, the separator is 'white space', i.e., one or more
spaces, tabs, newlines or carriage returns.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_input">input</code></td>
<td>
<p>a character string indicating the Mplus input (<code>.inp</code>)
or output file (<code>.out</code>) in which the variable names
are specified in the <code>VARIABLE:</code> section. Note that if
<code>input = NULL</code>, this function is equivalent to <code>read.table(file)</code>.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_na">na</code></td>
<td>
<p>a numeric vector indicating values to replace with <code>NA</code>.
By default, <code>-99</code> is replaced with <code>NA</code>. If
<code>-99</code> is not a missing value change the argument to
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_print">print</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable names are printed on the
console.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_return.var">return.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, the function returns the variable
names extracted from the Mplus input or output file only.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_encoding">encoding</code></td>
<td>
<p>character string declaring the encoding used on <code>file</code>
so the character data can be re-encoded.See the 'Encoding' section of the help
page for the <code>file</code> function, the 'R Data Import/Export Manual' and 'Note'.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing a representation of the data in the file.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>, <code><a href="#topic+read.sav">read.sav</a></code>,
<code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+read.xlsx">read.xlsx</a></code>, <code><a href="#topic+write.xlsx">write.xlsx</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Read Mplus data file and variable names extracted from the Mplus input file
dat &lt;- read.mplus("Mplus_Data.dat", input = "Mplus_Input.inp")

# Example 2: Read Mplus data file and variable names extracted from the Mplus input file,
# print variable names on the console
dat &lt;- read.mplus("Mplus_Data.dat", input = "Mplus_Input.inp", print = TRUE)

# Example 3: Read variable names extracted from the Mplus input file
varnames &lt;- read.mplus(input = "Mplus_Input.inp", return.var = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='read.sav'>Read SPSS File</h2><span id='topic+read.sav'></span>

<h3>Description</h3>

<p>This function calls the <code>read_spss</code> function in the <span class="pkg">haven</span> package
by Hadley Wickham, Evan Miller and Danny Smith (2023) to read an SPSS file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.sav(file, use.value.labels = FALSE, use.missings = TRUE, formats = FALSE,
         label = FALSE, labels = FALSE, missing = FALSE, widths = FALSE,
         as.data.frame = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.sav_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the SPSS data file
with or without file extension '.sav', e.g., <code>"SPSS_Data.sav"</code>
or <code>"SPSS_Data"</code>.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_use.value.labels">use.value.labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables with value labels are converted into factors.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_use.missings">use.missings</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), user-defined missing values are converted into NAs.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_formats">formats</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable formats are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_label">label</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable labels are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_labels">labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, value labels are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_missing">missing</code></td>
<td>
<p>logical: if <code>TRUE</code>, value labels for user-defined missings are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_widths">widths</code></td>
<td>
<p>logical: if <code>TRUE</code>, widths are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), function returns a regular data frame; if <code>FALSE</code> function returns a tibble.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame or tibble.
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham, Evan Miller and Danny Smith
</p>


<h3>References</h3>

<p>Wickham H, Miller E, &amp; Smith D (2023). <em>haven: Import and Export 'SPSS', 'Stata' and 'SAS' Files</em>.
R package version 2.5.3. <a href="https://CRAN.R-project.org/package=haven">https://CRAN.R-project.org/package=haven</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>, <code><a href="#topic+read.xlsx">read.xlsx</a></code>,
<code><a href="#topic+write.xlsx">write.xlsx</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Read SPSS data file
read.sav("SPSS_Data.sav")
read.sav("SPSS_Data")

# Example 2: Read SPSS data file, convert variables with value labels into factors
read.sav("SPSS_Data.sav", use.value.labels = TRUE)

# Example 3: Read SPSS data file, user-defined missing values are not converted into NAs
read.sav("SPSS_Data.sav", use.missing = FALSE)

# Example 4: Read SPSS data file as tibble
read.sav("SPSS_Data.sav", as.data.frame = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='read.xlsx'>Read Excel File</h2><span id='topic+read.xlsx'></span>

<h3>Description</h3>

<p>This function calls the <code>read_xlsx()</code> function in the <span class="pkg">readxl</span> package
by Hadley Wickham and Jennifer Bryan (2019) to read an Excel file (.xlsx).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.xlsx(file, sheet = NULL, header = TRUE, range = NULL,
          coltypes = c("skip", "guess", "logical", "numeric", "date", "text", "list"),
          na = "", trim = TRUE, skip = 0, nmax = Inf, guessmax = min(1000, nmax),
          progress = readxl::readxl_progress(), name.repair = "unique",
          as.data.frame = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.xlsx_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the Excel data
file with or without file extension '.xlsx', e.g., <code>"My_Excel_Data.xlsx"</code>
or <code>"My_Excel_Data"</code>.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_sheet">sheet</code></td>
<td>
<p>a character string indicating the name of a sheet or a numeric
value indicating the position of the sheet to read. By default
the first sheet will be read.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_header">header</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the first row is used
as column names, if <code>FALSE</code> default names are used.
A character vector giving a name for each column can also
be used. If <code>coltypes</code> as a vector is provided,
<code>colnames</code> can have one entry per column, i.e. have
the same length as <code>coltypes</code>, or one entry per unskipped
column.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_range">range</code></td>
<td>
<p>a character string indicating the cell range to read from,
e.g. typical Excel ranges like <code>"B3:D87"</code>, possibly
including the sheet name like <code>"Data!B2:G14"</code>. Interpreted
strictly, even if the range forces the inclusion of leading
or trailing empty rows or columns. Takes precedence over
<code>skip</code>, <code>nmax</code> and <code>sheet</code>.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_coltypes">coltypes</code></td>
<td>
<p>a character vector containing one entry per column from
these options <code>"skip"</code>, <code>"guess"</code>, <code>"logical"</code>,
<code>"numeric"</code>, <code>"date"</code>, <code>"text"</code> or <code>"list"</code>.
If exactly one <code>coltype</code> is specified, it will be recycled.
By default (i.e., <code>coltypes = NULL</code>) coltypes will
be guessed. The content of a cell in a skipped column is
never read and that column will not appear in the data frame
output. A list cell loads a column as a list of length 1
vectors, which are typed using the type guessing logic from
<code>coltypes = NULL</code>, but on a cell-by-cell basis.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_na">na</code></td>
<td>
<p>a character vector indicating strings to interpret as missing
values. By default, blank cells will be treated as missing data.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_trim">trim</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), leading and trailing
whitespace will be trimmed.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_skip">skip</code></td>
<td>
<p>a numeric value indicating the minimum number of rows to
skip before reading anything, be it column names or data.
Leading empty rows are automatically skipped, so this is
a lower bound. Ignored if the argument <code>range</code> is specified.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_nmax">nmax</code></td>
<td>
<p>a numeric value indicating the maximum number of data rows
to read. Trailing empty rows are automatically skipped, so
this is an upper bound on the number of rows in the returned
data frame. Ignored if the argument <code>range</code> is specified.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_guessmax">guessmax</code></td>
<td>
<p>a numeric value indicating the maximum number of data rows
to use for guessing column types.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_progress">progress</code></td>
<td>
<p>display a progress spinner? By default, the spinner appears
only in an interactive session, outside the context of knitting
a document, and when the call is likely to run for several
seconds or more.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_name.repair">name.repair</code></td>
<td>
<p>a character string indicating the handling of column names.
By default, the function ensures column names are not empty
and are unique.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), function returns a regular
data frame; if <code>FALSE</code> function returns a tibble.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame or tibble.
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham and Jennifer Bryan
</p>


<h3>References</h3>

<p>Wickham H, Miller E, Smith D (2023). <em>readxl: Read Excel Files</em>. R package
version 1.4.3. <a href="https://CRAN.R-project.org/package=readxl">https://CRAN.R-project.org/package=readxl</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>, <code><a href="#topic+read.sav">read.sav</a></code>,
<code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Read Excel file (.xlsx)
read.xlsx("data.xlsx")

# Example 1: Read Excel file (.xlsx), use default names as column names
read.xlsx("data.xlsx", header = FALSE)

# Example 2: Read Excel file (.xlsx), interpret -99 as missing values
read.xlsx("data.xlsx", na = "-99")

# Example 3: Read Excel file (.xlsx), use x1, x2, and x3 as column names
read.xlsx("data.xlsx", header = c("x1", "x2", "x3"))

# Example 4: Read Excel file (.xlsx), read cells A1:B5
read.xlsx("data.xlsx", range = "A1:B5")

# Example 5: Read Excel file (.xlsx), skip 2 rows before reading data
read.xlsx("data.xlsx", skip = 2)

# Example 5: Read Excel file (.xlsx), return a tibble
read.xlsx("data.xlsx", as.data.frame = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='rec'>Recode Variable</h2><span id='topic+rec'></span>

<h3>Description</h3>

<p>This function recodes numeric vectors, character vectors, or factors according
to recode specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rec(data, ..., spec, as.factor = FALSE, levels = NULL, append = TRUE,
    name = ".e", as.na = NULL, table = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rec_+3A_data">data</code></td>
<td>
<p>a numeric vector, character vector, factor, or data
frame.</p>
</td></tr>
<tr><td><code id="rec_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>rec(dat, x1, x2, x3, spec = "1 = 0"))</code>. Note that
the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="rec_+3A_spec">spec</code></td>
<td>
<p>a character string of recode specifications (see 'Details').</p>
</td></tr>
<tr><td><code id="rec_+3A_as.factor">as.factor</code></td>
<td>
<p>logical: if <code>TRUE</code>, character vector will be coerced to
a factor.</p>
</td></tr>
<tr><td><code id="rec_+3A_levels">levels</code></td>
<td>
<p>a character vector for specifying the levels in the returned
factor.</p>
</td></tr>
<tr><td><code id="rec_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="rec_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), centered variable(s) are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="rec_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names
of the recoded variables. By default, variables are named with the ending
<code>".r"</code> Resulting in e.g. <code>"x1.r"</code> and <code>"x2.r"</code>. Variable
names can also be specified using a character vector matching
the number of variables specified in <code>data</code> (e.g.,
<code>name = c("recode.x1", "recode.x2")</code>).</p>
</td></tr>
<tr><td><code id="rec_+3A_table">table</code></td>
<td>
<p>logical: if <code>TRUE</code>, a cross table variable x recoded
variable is printed on the console if only one variable is
specified in <code>data</code>.</p>
</td></tr>
<tr><td><code id="rec_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recode specifications appear in a character string, separated by semicolons
(see the examples below), of the form input = output. If an input value satisfies
more than one specification, then the first (from left to right) applies. If
no specification is satisfied, then the input value is carried over to the
result. <code>NA</code> is allowed in input and output. Several recode specifications
are supported:
</p>

<dl>
<dt><strong>Single Value</strong></dt><dd><p>For example, <code>spec = "0 = NA".</code></p>
</dd>
<dt><strong>Vector of Values</strong></dt><dd><p>For example, <code>spec = "c(7, 8, 9) = 'high'"</code>.</p>
</dd>
<dt><strong>Range of Values</strong></dt><dd><p>For example, <code>spec = "7:9 = 'C'"</code>. The
special values <code>lo</code> (lowest value) and <code>hi</code> (highest value) may
appear in a range. For example, <code>spec = "lo:10 = 1"</code>. Note that <code>:</code>
is not the R sequence operator. In addition you may not use <code>:</code> with the
collect operator, e.g., <code>spec = "c(1, 3, 5:7)"</code> will cause an error.</p>
</dd>
<dt><strong>else</strong></dt><dd><p>For example, <code>spec = "0 = 1; else = NA"</code>. Everything
that does not fit a previous specification. Note that <code>else</code> matches all
otherwise unspecified values on input, including <code>NA</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a numeric vector or data frame with the same length or same number of
rows as <code>data</code> containing the recoded coded variable(s).
</p>


<h3>Note</h3>

<p>This function was adapted from the <code>recode()</code> function in the <span class="pkg">car</span>
package by John Fox and Sanford Weisberg (2019).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Fox, J., &amp; Weisberg S. (2019). <em>An R Companion to Applied Regression</em> (3rd ed.).
Thousand Oaks CA: Sage. URL: https://socialsciences.mcmaster.ca/jfox/Books/Companion/
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coding">coding</a></code>, <code><a href="#topic+item.reverse">item.reverse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Example 1: Numeric vector
x.num &lt;- c(1, 2, 4, 5, 6, 8, 12, 15, 19, 20)

# Example 1a: Recode 5 = 50 and 19 = 190
rec(x.num, spec = "5 = 50; 19 = 190")

# Example 1b: Recode 1, 2, and 5 = 100 and 4, 6, and 7 = 200 and else = 300
rec(x.num, spec = "c(1, 2, 5) = 100; c(4, 6, 7) = 200; else = 300")

# Example 1c: Recode lowest value to 10 = 100 and 11 to highest value = 200
rec(x.num, spec = "lo:10 = 100; 11:hi = 200")

# Example 1d: Recode 5 = 50 and 19 = 190 and check recoding
rec(x.num, spec = "5 = 50; 19 = 190", table = TRUE)

#----------------------------------------------------------------------------
# Example 2: Character vector
x.chr &lt;- c("a", "c", "f", "j", "k")

# Example 2a: Recode a to x
rec(x.chr, spec = "'a' = 'X'")

# Example 2b: Recode a and f to x, c and j to y, and else to z
rec(x.chr, spec = "c('a', 'f') = 'x'; c('c', 'j') = 'y'; else = 'z'")

# Example 2c: Recode a to x and coerce to a factor
rec(x.chr, spec = "'a' = 'X'", as.factor = TRUE)

#----------------------------------------------------------------------------
# Example 3: Factor
x.fac &lt;- factor(c("a", "b", "a", "c", "d", "d", "b", "b", "a"))

# Example 3a: Recode a to x, factor levels ordered alphabetically
rec(x.fac, spec = "'a' = 'x'")

# Example 3b: Recode a to x, user-defined factor levels
rec(x.fac, spec = "'a' = 'x'", levels = c("x", "b", "c", "d"))

#----------------------------------------------------------------------------
# Example 4: Multiple variables
dat &lt;- data.frame(x1.num = c(1, 2, 4, 5, 6),
                  x2.num = c(5, 19, 2, 6, 3),
                  x1.chr = c("a", "c", "f", "j", "k"),
                  x2.chr = c("b", "c", "a", "d", "k"),
                  x1.fac = factor(c("a", "b", "a", "c", "d")),
                  x2.fac = factor(c("b", "a", "d", "c", "e")))

# Example 4a: Recode numeric vector and attach to 'dat'
cbind(dat, rec(dat[, c("x1.num", "x2.num")], spec = "5 = 50; 19 = 190"))

# Alternative specification using the 'data' argument,
rec(dat, x1.num, x2.num, spec = "5 = 50; 19 = 190")

# Example 4b: Recode character vector and attach to 'dat'
cbind(dat, rec(dat[, c("x1.chr", "x2.chr")], spec = "'a' = 'X'"))

# Example 4c: Recode factor vector and attach to 'dat'
cbind(dat, rec(dat[, c("x1.fac", "x2.fac")], spec = "'a' = 'X'"))</code></pre>

<hr>
<h2 id='restart'>Restart R Session</h2><span id='topic+restart'></span>

<h3>Description</h3>

<p>This function restarts the RStudio session and is equivalent to using the menu
item <code>Session - Restart R</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>restart()
</code></pre>


<h3>Details</h3>

<p>The function call <code>executeCommand("restartR")</code> in the package <span class="pkg">rstudioapi</span>
is used to restart the R session. Note that the function <code>restartSession()</code>
in the package <span class="pkg">rstudioapi</span> is not equivalent to the menu item
<code>Session - Restart R</code> since it does not unload packages loaded during an
R session.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2022). rstudioapi: Safely
access the RStudio API. R package version 0.14.
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Restart the R Session
restart()

## End(Not run)
</code></pre>

<hr>
<h2 id='result.lca'>Summary Result Table and Grouped Bar Charts for Latent Class Analysis Estimated in Mplus</h2><span id='topic+result.lca'></span>

<h3>Description</h3>

<p>This function reads all Mplus output files from latent class analysis in
subfolders to create a summary result table and bar charts for each latent
class solution separately. By default, the function reads output files in all
subfolders of the current working directory. Optionally, bar charts for each
latent class solution can be requested by setting the argument <code>plot</code>
to <code>TRUE</code>. Note that subfolders with only one Mplus output file are
excluded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>result.lca(folder = getwd(), exclude = NULL, sort.n = TRUE, sort.p = TRUE,
           plot = FALSE, group.ind = TRUE, ci = TRUE, conf.level = 0.95, adjust = TRUE,
           axis.title = 7, axis.text = 7, levels = NULL, labels = NULL,
           ylim = NULL, ylab = "Mean Value", breaks = ggplot2::waiver(),
           errorbar.width = 0.1, legend.title = 7, legend.text = 7, legend.key.size = 0.4,
           gray = FALSE, start = 0.15, end = 0.85, dpi = 600,
           width = "n.ind", height = 4, digits = 1, p.digits = 3,
           write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="result.lca_+3A_folder">folder</code></td>
<td>
<p>a character vector indicating the name of the subfolders
to be excluded from the summary result table.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_exclude">exclude</code></td>
<td>
<p>a character vector indicating the name of the subfolders
excluded from the result tables.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_sort.n">sort.n</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), result table is sorted
according to the number of classes within each folder.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_sort.p">sort.p</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), class proportions are
sorted decreasing.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar charts with
error bars for confidence intervals are saved
in the  folder <code>_Plots</code> within subfolders. Note
that plots are only available for LCA with continuous
or count indicator variables.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_group.ind">group.ind</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), latent class indicators
are represented by separate bars, if <code>FALSE</code> latent classes
are represented by separate bars.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), confidence intervals
are added to the bar charts.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the confidence intervals is applied.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_axis.title">axis.title</code></td>
<td>
<p>a numeric value specifying the size of the axis title.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_axis.text">axis.text</code></td>
<td>
<p>a numeric value specifying the size of the axis text</p>
</td></tr>
<tr><td><code id="result.lca_+3A_levels">levels</code></td>
<td>
<p>a character string specifying the order of the indicator
variables shown on the x-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_labels">labels</code></td>
<td>
<p>a character string specifying the labels of the indicator
variables shown on the x-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
y-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the label of the y-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric vector specifying the width of the error bars.
By default, the width of the error bars is 0.1 plus
number of classes divided by 30.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_legend.title">legend.title</code></td>
<td>
<p>a numeric value specifying the size of the legend title.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_legend.text">legend.text</code></td>
<td>
<p>a numeric value specifying the size of the legend text.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_legend.key.size">legend.key.size</code></td>
<td>
<p>a numeric value specifying the size of the legend keys.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_gray">gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar charts are drawn in gray
scale.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_start">start</code></td>
<td>
<p>a numeric value between 0 and 1 specifying the gray value
at the low end of the palette.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_end">end</code></td>
<td>
<p>a numeric value between 0 and 1 specifying the gray value
at the high end of the palette.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value specifying the plot resolution when saving
the bar chart.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_width">width</code></td>
<td>
<p>a numeric value specifying the width of the plot when
saving the bar chart. By default, the width is number of
indicators plus number of classes divided by 2.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_height">height</code></td>
<td>
<p>a numeric value specifying the height of the plot when
saving the bar chart.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that the scaling
correction factor is displayed  with <code>digits</code> plus 1
decimal places.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying <em>p</em>-values, entropy value,
and class proportions.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The result summary table comprises following entries:
</p>

<ul>
<li><p><code>"Folder"</code>: Subfolder from which the group of Mplus outputs files
were summarized.
</p>
</li>
<li><p><code>"#Class"</code>: Number of classes (i.e., <code>CLASSES ARE c(#Class)</code>).
</p>
</li>
<li><p><code>"Conv"</code>: Model converged, <code>TRUE</code> or <code>FALSE</code> (i.e.,
<code>THE MODEL ESTIMATION TERMINATED NORMALLY</code>.
</p>
</li>
<li><p><code>"#Param"</code>: Number of estimated parameters (i.e.,
<code>Number of Free Parameters</code>).
</p>
</li>
<li><p><code>"logLik"</code>: Log-likelihood of the estimated model (i.e., <code>H0 Value</code>).
</p>
</li>
<li><p><code>"Scale"</code>: Scaling correction factor (i.e.,
<code>H0 Scaling Correction Factor for</code>). Provided
only when <code>ESTIMATOR IS MLR</code>.
</p>
</li>
<li><p><code>"LL Rep"</code>: Best log-likelihood replicated, <code>TRUE</code> or <code>FALSE</code>
(i.e., <code>THE BEST LOGLIKELIHOOD VALUE HAS BEEN REPLICATED</code>).
</p>
</li>
<li><p><code>"AIC"</code>: Akaike information criterion (i.e., <code>Akaike (AIC)</code>).
</p>
</li>
<li><p><code>"CAIC"</code>: Consistent AIC, not reported in the Mplus output, but
simply <code>BIC + #Param</code>.
</p>
</li>
<li><p><code>"BIC"</code>: Bayesian information criterion (i.e., <code>Bayesian (BIC)</code>).
</p>
</li>
<li><p><code>"Chi-Pear"</code>: Pearson chi-square test of model fit (i.e., <code>Pearson Chi-Square</code>),
only available when indicators are count or ordered categorical.
</p>
</li>
<li><p><code>"Chi-LRT"</code>: Likelihood ratio chi-square test of model fit (i.e., <code>Likelihood Ratio Chi-Square</code>),
only available when indicators are count or ordered categorical.
</p>
</li>
<li><p><code>"SABIC"</code>: Sample-size adjusted BIC (i.e., <code>Sample-Size Adjusted BIC</code>).
</p>
</li>
<li><p><code>"LMR-LRT"</code>: Significance value (<em>p</em>-value) of the Vuong-Lo-Mendell-Rubin test
(i.e., <code>VUONG-LO-MENDELL-RUBIN LIKELIHOOD RATIO TEST</code>).
Provided only when <code>OUTPUT: TECH11</code>.
</p>
</li>
<li><p><code>"A-LRT"</code>: Significance value (<em>p</em>-value) of the Adjusted Lo-Mendell-Rubin Test
(i.e., <code>LO-MENDELL-RUBIN ADJUSTED LRT TEST</code>).
Provided only when <code>OUTPUT: TECH11</code>.
</p>
</li>
<li><p><code>"BLRT"</code>: Significance value (<em>p</em>-value) of the bootstrapped
likelihood ratio test. Provided only when <code>OUTPUT: TECH14</code>.
</p>
</li>
<li><p><code>"Entropy"</code>: Sample-size adjusted BIC (i.e., <code>Entropy</code>).
</p>
</li>
<li><p><code>"p1"</code>: Class proportion of the first class based on the estimated
posterior probabilities (i.e., <code>FINAL CLASS COUNTS AND PROPORTIONS</code>).
</p>
</li>
<li><p><code>"p2"</code>: Class proportion of the second class based on the estimated
posterior probabilities (i.e., <code>FINAL CLASS COUNTS AND PROPORTIONS</code>).
</p>
</li></ul>



<h3>Value</h3>

<p>Returns an object, which is a list with following entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>output</code></td>
<td>
<p>list with all Mplus outputs</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary result table, <code>mean_var</code> for the result
table with means and variances for each latent class
separately, <code>mean</code> for the result table with means
for each latent class separately, and <code>var</code> for the
result table with variances for each latent class separately</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Masyn, K. E. (2013). Latent class analysis and finite mixture modeling. In T. D.
Little (Ed.), <em>The Oxford handbook of quantitative methods: Statistical analysis</em>
(pp. 551–611). Oxford University Press.
</p>
<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mplus.lca">mplus.lca</a></code>, <code><a href="#topic+mplus.run">mplus.run</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>,
<code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

# Run LCA with k = 1 to k = 6 classes
mplus.lca(HolzingerSwineford1939, ind = c("x1", "x2", "x3", "x4"),
          mplus.run = TRUE)

# Example 1a: Read Mplus output files, create result table, write table, and save plots
result.lca(write = "LCA.xlsx", plot = TRUE)

# Example 1b: Write results into a text file
result.lca(write = "LCA.txt")

#-------------------------------------------------------------------------------
# Example 2: Draw bar chart manually

library(ggplot2)

# Collect LCA results
lca.result &lt;- result.lca()

# Result table with means
means &lt;- lca.result$result$mean

# Extract results from variance-covariance structure A with 4 latent classes
plotdat &lt;- means[means$folder == "A_Invariant-Theta_Diagonal-Sigma" &amp;  means$nclass == 4, ]

# Draw bar chart
ggplot(plotdat, aes(ind, est, group = class, fill = class)) +
  geom_bar(stat = "identity", position = "dodge", color = "black",
           linewidth = 0.1) +
  geom_errorbar(aes(ymin = low, ymax = upp), width = 0.23,
                linewidth = 0.2, position = position_dodge(0.9)) +
  scale_x_discrete("") +
  scale_y_continuous("Mean Value", limits = c(0, 9),
                     breaks = seq(0, 9, by = 1)) +
  labs(fill = "Latent Class") +
  guides(fill = guide_legend(nrow = 1L)) +
  theme(axis.title = element_text(size = 11),
        axis.text = element_text(size = 11),
        legend.position = "bottom",
        legend.key.size = unit(0.5 , 'cm'),
        legend.title = element_text(size = 11),
        legend.text = element_text(size = 11),
        legend.box.spacing = unit(-9L, "pt"))

# Save bar chart
ggsave("LCA_4-Class.png", dpi = 600, width = 6, height = 4)

## End(Not run)
</code></pre>

<hr>
<h2 id='robust.coef'>Unstandardized Coefficients with Heteroscedasticity-Consistent Standard Errors</h2><span id='topic+robust.coef'></span>

<h3>Description</h3>

<p>This function computes heteroscedasticity-consistent standard errors and
significance values for linear models estimated by using the <code>lm()</code>
function and generalized linear models estimated by using the <code>glm()</code>
function. For linear models the heteroscedasticity-robust F-test is computed
as well. By default, the function uses the HC4 estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robust.coef(model, type = c("HC0", "HC1", "HC2", "HC3", "HC4", "HC4m", "HC5"),
            digits = 3, p.digits = 3, write = NULL, append = TRUE, check = TRUE,
            output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="robust.coef_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>lm</code> or <code>glm</code>.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_type">type</code></td>
<td>
<p>a character string specifying the estimation type, where
<code>"H0"</code> gives White's estimator and <code>"H1"</code> to
<code>"H5"</code> are refinement of this estimator. See help page
of the <code>vcovHC()</code> function in the R package <code>sandwich</code>
for more details.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that information
criteria and chi-square test statistic are printed with
<code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The family of heteroscedasticity-consistent (HC) standard errors estimator for
the model parameters of a regression model is based on an HC covariance matrix
of the parameter estimates and does not require the assumption of homoscedasticity.
HC estimators approach the correct value with increasing sample size, even in
the presence of heteroscedasticity. On the other hand, the OLS standard error
estimator is biased and does not converge to the proper value when the assumption
of homoscedasticity is violated (Darlington &amp; Hayes, 2017).
</p>
<p>White (1980) introduced
the idea of HC covariance matrix to econometricians and derived the asymptotically
justified form of the HC covariance matrix known as HC0 (Long &amp; Ervin, 2000).
Simulation studies have shown that the HC0 estimator tends to underestimate the
true variance in small to moderately large samples (<code class="reqn">N \leq 250</code>) and in
the presence of leverage observations, which leads to an inflated
type I error risk (e.g., Cribari-Neto &amp; Lima, 2014). The alternative estimators
HC1 to HC5 are asymptotically equivalent to HC0 but include finite-sample corrections,
which results in superior small sample properties compared to the HC0 estimator.
Long and Ervin (2000) recommended routinely using the HC3 estimator regardless
of a heteroscedasticity test. However, the HC3 estimator can be unreliable when
the data contains leverage observations. The HC4 estimator, on
the other hand, performs well with small samples, in the presence of high leverage
observations, and when errors are not normally distributed (Cribari-Neto, 2004).
In summary, it appears that the HC4 estimator performs the best in terms of
controlling the type I and type II error risk (Rosopa, 2013). As opposed to the
findings of Cribari-Neto et al. (2007), the HC5 estimator did not show any
substantial advantages over HC4. Both HC5 and HC4 performed similarly across
all the simulation conditions considered in the study (Ng &amp; Wilcox, 2009).
</p>
<p>Note that the <em>F</em>-test of significance on the multiple correlation coefficient
<em>R</em> also assumes homoscedasticity of the errors. Violations of this assumption
can result in a hypothesis test that is either liberal or conservative, depending
on the form and severity of the heteroscedasticity.
</p>
<p>Hayes (2007) argued that using a HC estimator instead of assuming homoscedasticity
provides researchers with more confidence in the validity and statistical power
of inferential tests in regression analysis. Hence, the HC3 or HC4 estimator
should be used routinely when estimating regression models. If a HC estimator
is not used as the default method of standard error estimation, researchers are
advised to at least double-check the results by using an HC estimator to ensure
that conclusions are not compromised by heteroscedasticity. However, the presence
of heteroscedasticity suggests that the data is not adequately explained by
the statistical model of estimated conditional means. Unless heteroscedasticity
is believed to be solely caused by measurement error associated with the predictor
variable(s), it should serve as warning to the researcher regarding the adequacy
of the estimated model.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in <code>model</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with results, i.e., <code>coef</code> for the unstandardized
regression coefficients with heteroscedasticity-consistent standard errors,
<code>F.test</code> for the heteroscedasticity-robust F-Test, and <code>sandwich</code>
for the sandwich covariance matrix</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on the <code>vcovHC</code> function from the <code>sandwich</code>
package (Zeileis, Köll, &amp; Graham, 2020) and the functions <code>coeftest</code> and
<code>waldtest</code> from the <code>lmtest</code> package (Zeileis &amp; Hothorn, 2002).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Darlington, R. B., &amp; Hayes, A. F. (2017). <em>Regression analysis and linear
models: Concepts, applications, and implementation</em>. The Guilford Press.
</p>
<p>Cribari-Neto, F. (2004). Asymptotic inference under heteroskedasticity of unknown
form. <em>Computational Statistics &amp; Data Analysis, 45</em>, 215-233.
https://doi.org/10.1016/S0167-9473(02)00366-3
</p>
<p>Cribari-Neto, F., &amp; Lima, M. G. (2014). New heteroskedasticity-robust standard
errors for the linear regression model. <em>Brazilian Journal of Probability and Statistics, 28</em>,
83-95.
</p>
<p>Cribari-Neto, F., Souza, T., &amp; Vasconcellos, K. L. P. (2007). Inference under
heteroskedasticity and leveraged data. <em>Communications in Statistics - Theory and Methods, 36</em>,
1877-1888. https://doi.org/10.1080/03610920601126589
</p>
<p>Hayes, A.F, &amp; Cai, L. (2007). Using heteroscedasticity-consistent standard error
estimators in OLS regression: An introduction and software implementation.
<em>Behavior Research Methods, 39</em>, 709-722. https://doi.org/10.3758/BF03192961
</p>
<p>Long, J.S., &amp; Ervin, L.H. (2000). Using heteroscedasticity consistent standard
errors in the linear regression model. <em>The American Statistician, 54</em>,
217-224. https://doi.org/10.1080/00031305.2000.10474549
</p>
<p>Ng, M., &amp; Wilcoy, R. R. (2009). Level robust methods based on the least squares
regression estimator. <em>Journal of Modern Applied Statistical Methods, 8</em>,
284-395. https://doi.org/10.22237/jmasm/1257033840
</p>
<p>Rosopa, P. J., Schaffer, M. M., &amp; Schroeder, A. N. (2013). Managing heteroscedasticity
in general linear models. <em>Psychological Methods, 18</em>(3), 335-351.
https://doi.org/10.1037/a0032553
</p>
<p>White, H. (1980). A heteroskedastic-consistent covariance matrix estimator and
a direct test of heteroskedasticity. <em>Econometrica, 48</em>, 817-838.
https://doi.org/10.2307/1912934
</p>
<p>Zeileis, A., &amp; Hothorn, T. (2002). Diagnostic checking in regression relationships.
<em>R News, 2</em>(3), 7–10. http://CRAN.R-project.org/doc/Rnews/
</p>
<p>Zeileis A, Köll S, &amp; Graham N (2020). Various versatile variances: An
object-oriented implementation of clustered covariances in R.
<em>Journal of Statistical Software, 95</em>(1), 1-36.
https://doi.org/10.18637/jss.v095.i01
</p>


<h3>See Also</h3>

<p><code><a href="#topic+std.coef">std.coef</a></code>, <code><a href="#topic+write.result">write.result</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Example 1: Linear model

mod.lm &lt;- lm(mpg ~ cyl + disp, data = mtcars)
robust.coef(mod.lm)

#----------------------------------------------------------------------------
# Example 2: Generalized linear model

mod.glm &lt;- glm(carb ~ cyl + disp, data = mtcars, family = poisson())
robust.coef(mod.glm)

## Not run: 
#----------------------------------------------------------------------------
# Write Results

# Example 3a: Write results into a text file
robust.coef(mod.lm, write = "Robust_Coef.txt", output = FALSE)

# Example 3b: Write results into a Excel file
robust.coef(mod.lm, write = "Robust_Coef.xlsx", output = FALSE)
## End(Not run)
</code></pre>

<hr>
<h2 id='rwg.lindell'>Lindell, Brandt and Whitney (1999) r*wg(j) Within-Group Agreement Index for
Multi-Item Scales</h2><span id='topic+rwg.lindell'></span>

<h3>Description</h3>

<p>This function computes r*wg(j) within-group agreement index for multi-item scales
as described in Lindell, Brandt and Whitney (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rwg.lindell(data, ...,  cluster, A = NULL, ranvar = NULL, z = TRUE,
            expand = TRUE, na.omit = FALSE, append = TRUE, name = "rwg",
            as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rwg.lindell_+3A_data">data</code></td>
<td>
<p>a numeric vector or data frame.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>,
e.g., <code>rwg.lindell(dat, x1, x2, x3)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_a">A</code></td>
<td>
<p>a numeric value indicating the number of discrete response
options of the items from which the random variance is computed
based on <code class="reqn">(A^2 - 1) / 12</code>. Note that either the argument
<code>j</code> or the argument<code>ranvar</code> is specified.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_ranvar">ranvar</code></td>
<td>
<p>a numeric value indicating the random variance to which the
mean of the item variance is divided. Note that either the
argument <code>j</code> or the argument<code>ranvar</code> is specified.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_z">z</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Fisher z-transformation based on the
formula <code class="reqn">z = 0.5*log((1 + r) / (1 - r))</code> is applied to
the vector of r*wg(j) estimates.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_expand">expand</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vector of r*wg(j) estimates is expanded
to match the input vector <code>data</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default),  a variable with the r*wg(j)
within-group agreement index are appended to the data frame
specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_name">name</code></td>
<td>
<p>a character string indicating the name of the variable appended
to the data frame specified in the argument <code>data</code> when
<code>append = TRUE</code>. By default, the variable is named <code>rwg</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied to
<code>data</code>, but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The r*wg(j) index is calculated by dividing the mean of the item variance by
the expected random variance (i.e., null distribution). The default null distribution
in most research is the rectangular or uniform distribution calculated with
<code class="reqn">\sigma^2_eu = (A^2 - 1) / 12</code>, where <code class="reqn">A</code> is the number of discrete response
options of the items. However, what constitutes a reasonable standard for random
variance is highly debated. Note that the r*wg(j) allows that the mean of the
item variances to be larger than the expected random variances, i.e., r*wg(j)
values can be negative.
</p>
<p>Note that the <code>rwg.j.lindell()</code> function in the <span class="pkg">multilevel</span> package
uses listwise deletion by default, while the <code>rwg.lindell()</code> function uses
all available information to compute the r*wg(j) agreement index by default. In
order to obtain equivalent results in the presence of missing values, listwise
deletion (<code>na.omit = TRUE</code>) needs to be applied.
</p>
<p>Examples for the application of r*wg(j) within-group agreement index for multi-item
scales can be found in Bardach, Yanagida, Schober and Lueftenegger (2018),
Bardach, Lueftenegger, Yanagida, Schober and Spiel (2018), and Bardach, Lueftenegger,
Yanagida, Spiel and Schober (2019).
</p>


<h3>Value</h3>

<p>Returns a numeric vector containing r*wg(j) agreement index for multi-item scales
with the same length as <code>group</code> if <code>expand = TRUE</code> or a data frame with
following entries if <code>expand = FALSE</code>:
</p>
<table role = "presentation">
<tr><td><code>cluster</code></td>
<td>
<p>cluster identifier</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>cluster size</p>
</td></tr>
<tr><td><code>rwg.lindell</code></td>
<td>
<p>r*wg(j) estimate for each group</p>
</td></tr>
<tr><td><code>z.rwg.lindell</code></td>
<td>
<p>Fisher z-transformed r*wg(j) estimate for each cluster</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Bardach, L., Lueftenegger, M., Yanagida, T., &amp; Schober, B. (2019). Achievement
or agreement - Which comes first? Clarifying the temporal ordering of achievement
and within-class consensus on classroom goal structures. <em>Learning and Instruction,
61</em>, 72-83. https://doi.org/10.1016/j.learninstruc.2019.01.003
</p>
<p>Bardach, L., Lueftenegger, M., Yanagida, T., Schober, B. &amp; Spiel, C. (2019).
The role of within-class consensus on mastery goal structures in predicting
socio-emotional outcomes. <em>British Journal of Educational Psychology, 89</em>,
239-258. https://doi.org/10.1111/bjep.12237
</p>
<p>Bardach, L., Yanagida, T., Schober, B. &amp; Lueftenegger, M. (2018). Within-class
consensus on classroom goal structures: Relations to achievement and achievement
goals in mathematics and language classes. <em>Learning and Individual Differences,
67</em>, 78-90. https://doi.org/10.1016/j.lindif.2018.07.002
</p>
<p>Lindell, M. K., Brandt, C. J., &amp; Whitney, D. J. (1999). A revised index of interrater
agreement for multi-item ratings of a single target. <em>Applied Psychological
Measurement</em>, <em>23</em>, 127-135. https://doi.org/10.1177/01466219922031257
</p>
<p>O'Neill, T. A. (2017). An overview of interrater agreement on Likert scales for
researchers and practitioners. <em>Frontiers in Psychology</em>, <em>8</em>, Article
777. https://doi.org/10.3389/fpsyg.2017.00777
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cluster.scores">cluster.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(id = c(1, 2, 3, 4, 5, 6, 7, 8, 9),
                  cluster = c(1, 1, 1, 2, 2, 2, 3, 3, 3),
                  x1 = c(2, 3, 2, 1, 1, 2, 4, 3, 5),
                  x2 = c(3, 2, NA, 1, 2, 1, 3, 2, 5),
                  x3 = c(3, 1, 1, 2, 3, 3, 5, 5, 4))

# Example 1: Compute Fisher z-transformed r*wg(j) for a multi-item scale with A = 5 response options
rwg.lindell(dat, x1, x2, x3, cluster = "cluster", A = 5)

# Alternative specification without using the '...' argument
rwg.lindell(dat[, c("x1", "x2", "x3")], cluster = dat$cluster, A = 5)

# Example 2: Compute Fisher z-transformed r*wg(j) for a multi-item scale with a random variance of 2
rwg.lindell(dat, x1, x2, x3, cluster = "cluster", ranvar = 2)

# Example 3: Compute r*wg(j) for a multi-item scale with A = 5 response options
rwg.lindell(dat, x1, x2, x3, cluster = "cluster", A = 5, z = FALSE)

# Example 4: Do not expand Fisher z-transformed r*wg(j)
rwg.lindell(dat, x1, x2, x3, cluster = "cluster", A = 5, expand = FALSE)</code></pre>

<hr>
<h2 id='script.copy'>Save Copy of the Current Script in RStudio</h2><span id='topic+script.copy'></span>

<h3>Description</h3>

<p>This function saves a copy of the current script in RStudio. By default, a
folder called <code>_R_Script_Archive</code> will be created to save the copy of
the current R script with the current date and time into the folder. Note that
the current R script needs to have a file location before the script can be
copied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>script.copy(file = NULL, folder = "_R_Script_Archive", create.folder = TRUE,
            time = TRUE, format = "%Y-%m-%d_%H%M", overwrite = TRUE,
            check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="script.copy_+3A_file">file</code></td>
<td>
<p>a character string naming the file of the copy without
the file extension <code>".R"</code>. By default, the file of
the copy has the same name as the original file.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_folder">folder</code></td>
<td>
<p>a character string naming the folder in which the file
of the copy is saved. If <code>NULL</code>, the file of the
copy is saved in the same folder as the original file.
By default, the file of the copy is saved into a folder
called <code>"_R_Script_Archive"</code>.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_create.folder">create.folder</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), folder(s) specified in
the <code>file</code> argument is created. If <code>FALSE</code> and
the folder does not exist, then a error message is printed
on the console.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_time">time</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the current time is
attached to the name of the file specified in the argument
<code>file</code>.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_format">format</code></td>
<td>
<p>a character string indicating the format if the <code>POSIXct</code>
class resulting from the <code>Sys.time</code> function. The default
setting provides a character string indicating the year, month, day, minutes, and seconds. See the help page of the <code><a href="base.html#topic+format.POSIXct">format.POSIXct</a></code> function.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_overwrite">overwrite</code></td>
<td>
<p>logical: if <code>TRUE</code> (default) an existing destination
file is overwritten.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses the <code>getSourceEditorContext()</code> function in the
<span class="pkg">rstudioapi</span> package by Kevin Ushey, JJ Allaire, Hadley Wickham, and Gary
Ritchie (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2023). <em>rstudioapi: Safely
access the RStudio API</em>. R package version 0.15.0
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>See Also</h3>

<p><code><a href="#topic+script.new">script.new</a></code>, <code><a href="#topic+script.close">script.close</a></code>, <code><a href="#topic+script.open">script.open</a></code>, <code><a href="#topic+script.save">script.save</a></code>, <code><a href="#topic+setsource">setsource</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Save copy current R script into the folder '_R_Script_Archive'
script.copy()

# Exmample 2: Save current R script as 'R_Script.R' into the folder 'Archive'
script.copy("R_Script", folder = "Archive", time = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='script.new'>Open new R Script, R Markdown script, or SQL Script in RStudio</h2><span id='topic+script.new'></span>

<h3>Description</h3>

<p>This function opens a new R script, R markdown script, or SQL script
in RStudio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>script.new(text = "", type = c("r", "rmarkdown", "sql"),
           position = rstudioapi::document_position(0, 0),
           run = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="script.new_+3A_text">text</code></td>
<td>
<p>a character vector indicating what text should be inserted in
the new R script. By default, an empty script is opened.</p>
</td></tr>
<tr><td><code id="script.new_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of document to be
created, i.e., <code>r</code> (default) for an R script, <code>rmakrdown</code>
for an R Markdown file, or <code>sql</code> for an SQL script.</p>
</td></tr>
<tr><td><code id="script.new_+3A_position">position</code></td>
<td>
<p><code>document_position()</code> function in the <span class="pkg">rstudioapi</span>
package indicating the cursor position.</p>
</td></tr>
<tr><td><code id="script.new_+3A_run">run</code></td>
<td>
<p>logical: if <code>TRUE</code>, the code is executed after the document
is created.</p>
</td></tr>
<tr><td><code id="script.new_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses the <code>documentNew()</code> function in the <span class="pkg">rstudioapi</span>
package by Kevin Ushey, JJ Allaire, Hadley Wickham, and Gary Ritchie (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2023). <em>rstudioapi:
Safely access the RStudio API</em>. R package version 0.15.0
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>See Also</h3>

<p><code><a href="#topic+script.close">script.close</a></code>, <code><a href="#topic+script.open">script.open</a></code>,
<code><a href="#topic+script.save">script.save</a></code>, <code><a href="#topic+script.copy">script.copy</a></code>, <code><a href="#topic+setsource">setsource</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Open new R script file
script.new()

# Example 2: Open new R script file and run some code
script.new("#----------------------------
# Example

# Generate 100 random numbers
rnorm(100)")

## End(Not run)
</code></pre>

<hr>
<h2 id='script.open'>Open, Close and Save R Script in RStudio</h2><span id='topic+script.open'></span><span id='topic+script.close'></span><span id='topic+script.save'></span>

<h3>Description</h3>

<p>The function <code>script.open</code> opens an R script, R markdown script, or SQL
script in RStudio, the function <code>script.close</code> closes an R script, and
the function <code>script.save</code> saves an R script. Note that the R script need
to have a file location before the script can be saved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>script.open(path, line = 1, col = 1, cursor = TRUE, run = FALSE,
            echo = TRUE, max.length = 999, spaced = TRUE, check = TRUE)

script.close(save = FALSE, check = TRUE)

script.save(all = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="script.open_+3A_path">path</code></td>
<td>
<p>a character string indicating the path of the script.</p>
</td></tr>
<tr><td><code id="script.open_+3A_line">line</code></td>
<td>
<p>a numeric value indicating the line in the script to navigate
to.</p>
</td></tr>
<tr><td><code id="script.open_+3A_col">col</code></td>
<td>
<p>a numeric value indicating the column in the script to
navigate to.</p>
</td></tr>
<tr><td><code id="script.open_+3A_cursor">cursor</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the cursor moves to the
requested location after opening the document.</p>
</td></tr>
<tr><td><code id="script.open_+3A_run">run</code></td>
<td>
<p>logical: if <code>TRUE</code>, the code is executed after the
document is opened</p>
</td></tr>
<tr><td><code id="script.open_+3A_echo">echo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), each expression is printed after
parsing, before evaluation.</p>
</td></tr>
<tr><td><code id="script.open_+3A_max.length">max.length</code></td>
<td>
<p>a numeric value indicating the maximal number of characters
output for the deparse of a single expression.</p>
</td></tr>
<tr><td><code id="script.open_+3A_spaced">spaced</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), empty line is printed before each
expression.</p>
</td></tr>
<tr><td><code id="script.open_+3A_save">save</code></td>
<td>
<p>logical: if <code>TRUE</code>, the script is saved before closing
when using the function <code>script.close</code>.</p>
</td></tr>
<tr><td><code id="script.open_+3A_all">all</code></td>
<td>
<p>logical: if <code>TRUE</code>, all scripts opened in RStudio are
saved when using the function <code>script.save</code>.</p>
</td></tr>
<tr><td><code id="script.open_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses the <code>documentOpen()</code>, <code>documentPath()</code>,
<code>documentClose()</code>, <code>documentSave()</code>, and <code>documentSaveAll()</code>
functions in the <span class="pkg">rstudioapi</span> package by Kevin Ushey,  JJ Allaire, Hadley
Wickham, and Gary Ritchie (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2023). <em>rstudioapi: Safely
access the RStudio API</em>. R package version 0.15.0
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>See Also</h3>

<p><code><a href="#topic+script.save">script.save</a></code>, <code><a href="#topic+script.copy">script.copy</a></code>, <code><a href="#topic+setsource">setsource</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Open  R script file
script.open("script.R")

# Example 2: Open  R script file and run the code
script.open("script.R", run = TRUE)

# Example 3: Close current R script file
script.close()

# Example 4: Save current R script
script.save()

# Example 5: Save all R scripts
script.save(all = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='setsource'>Set Working Directory to the Source File Location</h2><span id='topic+setsource'></span>

<h3>Description</h3>

<p>This function sets the working directory to the source file location
(i.e., path of the current R script) in RStudio and is equivalent to using the
menu item <code>Session - Set Working Directory - To Source File Location</code>.
Note that the R script needs to have a file location before this function can
be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setsource(path = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setsource_+3A_path">path</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the path of the source file is
shown on the console.</p>
</td></tr>
<tr><td><code id="setsource_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the path of the source file location.
</p>


<h3>Note</h3>

<p>This function uses the <code>documentPath()</code> function in the
<span class="pkg">rstudioapi</span> package by Kevin Ushey, JJ Allaire, Hadley Wickham, and Gary
Ritchie (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2023). <em>rstudioapi: Safely
access the RStudio API</em>. R package version 0.15.0
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>See Also</h3>

<p><code><a href="#topic+script.close">script.close</a></code>, <code><a href="#topic+script.new">script.new</a></code>, <code><a href="#topic+script.open">script.open</a></code>,
<code><a href="#topic+script.save">script.save</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Set working directory to the source file location
setsource()

# Example 2: Set working directory to the source file location
# and assign path to an object
path &lt;- setsource()
path

## End(Not run)
</code></pre>

<hr>
<h2 id='size.mean'>Sample Size Determination</h2><span id='topic+size.mean'></span><span id='topic+size.prop'></span><span id='topic+size.cor'></span>

<h3>Description</h3>

<p>This function performs sample size determination the one-sample and two-sample
t-tests, proportions, and Pearson product-moment correlation coefficients
based on precision requirements (i.e., type-I-risk, type-II-risk and an effect
size).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size.mean(delta, sample = c("two.sample", "one.sample"),
          alternative = c("two.sided", "less", "greater"),
          alpha = 0.05, beta = 0.1, write = NULL, append = TRUE,
          check = TRUE, output = TRUE)

size.prop(pi = 0.5, delta, sample = c("two.sample", "one.sample"),
          alternative = c("two.sided", "less", "greater"),
          alpha = 0.05, beta = 0.1, correct = FALSE, write = NULL,
          append = TRUE, check = TRUE, output = TRUE)

size.cor(rho, delta,
         alternative = c("two.sided", "less", "greater"),
         alpha = 0.05, beta = 0.1, write = NULL, append = TRUE,
         check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="size.mean_+3A_delta">delta</code></td>
<td>
<p>a numeric value indicating the minimum mean difference to
be detected, <code class="reqn">\delta</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_sample">sample</code></td>
<td>
<p>a character string specified in the function <code>size.mean</code>
or <code>size.prop</code> specifying a one- or two-sample t-test
or a proportion test, i.e., <code>"two.sample"</code> (default)
for a two-sample test and <code>"one.sample"</code> for a one-sample
test.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value indicating the type-I-risk, <code class="reqn">\alpha</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_beta">beta</code></td>
<td>
<p>a numeric value indicating the type-II-risk, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_pi">pi</code></td>
<td>
<p>a numeric value specified in the function <code>size.prop</code>
indicating the true value of the probability under the null
hypothesis in the one-sample test <code class="reqn">\pi</code>.0 or a number
indicating the true value of the probability in group 1 in
the two-sample test <code class="reqn">\pi</code>.1.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_rho">rho</code></td>
<td>
<p>a numeric value specified in the function <code>size.cor</code>
indicating the correlation coefficient under the null
hypothesis <code class="reqn">\rho</code>.0.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, continuity correction is applied.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>,
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Rasch, D., Pilz, J., Verdooren, L. R., &amp; Gebhardt, G. (2011).
<em>Optimal experimental design with R</em>.Chapman &amp; Hall/CRC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.t">test.t</a></code>, <code><a href="stats.html#topic+prop.test">prop.test</a></code>, <code><a href="stats.html#topic+cor.test">cor.test</a></code>,
<code><a href="#topic+cor.matrix">cor.matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Example 1: One- and two-sample t-test

# Example 1a: One-sample t-test
# H0: mu = mu.0, H1: mu != mu.0
# alpha = 0.05, beta = 0.2, delta = 0.5
size.mean(delta = 0.5, sample = "one.sample",
          alternative = "two.sided", alpha = 0.05, beta = 0.2)

# Example 1b: One-sided two-sample test
# H0: mu.1 &gt;= mu.2, H1: mu.1 &lt; mu.2
# alpha = 0.01, beta = 0.1, delta = 1
size.mean(delta = 1, sample = "two.sample",
          alternative = "less", alpha = 0.01, beta = 0.1)

#----------------------------------------------------------------------------
# Example 2: One- and two-sample test for proportions

# Example 2a: Two-sided one-sample test
# H0: pi = 0.5, H1: pi != 0.5
# alpha = 0.05, beta = 0.2, delta = 0.2
size.prop(pi = 0.5, delta = 0.2, sample = "one.sample",
          alternative = "two.sided", alpha = 0.05, beta = 0.2)

# Example 2b: One-sided two-sample test
# H0: pi.1 &lt;=  pi.1 = 0.5, H1: pi.1 &gt; pi.2
# alpha = 0.01, beta = 0.1, delta = 0.2
size.prop(pi = 0.5, delta = 0.2, sample = "two.sample",
          alternative = "greater", alpha = 0.01, beta = 0.1)

#----------------------------------------------------------------------------
# Example 3: Testing the Pearson product-moment correlation coefficient

# H0: rho = 0.3, H1: rho != 0.3
# alpha = 0.05, beta = 0.2, delta = 0.2
size.cor(rho = 0.3, delta = 0.2, alpha = 0.05, beta = 0.2)

# H0: rho &lt;= 0.3, H1: rho &gt; 0.3
# alpha = 0.05, beta = 0.2, delta = 0.2
size.cor(rho = 0.3, delta = 0.2,
         alternative = "greater", alpha = 0.05, beta = 0.2)
</code></pre>

<hr>
<h2 id='skewness'>Univariate and Multivariate Skewness and Kurtosis</h2><span id='topic+skewness'></span><span id='topic+kurtosis'></span>

<h3>Description</h3>

<p>The function <code>skewness</code> computes the univariate sample or population
skewness and conduct's Mardia's test for multivariate skewness, while the
function <code>kurtosis</code> computes the univariate sample or population (excess)
kurtosis or the multivariate (excess) kurtosis and conduct's Mardia's test for
multivariate kurtosis. By default, the function computes the sample univariate
skewness or multivariate skewness and the univariate sample excess kurtosis or
multivariate excess kurtosis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewness(data, ..., sample = TRUE, digits = 2, p.digits,
         as.na = NULL, check = TRUE, output = TRUE)

kurtosis(data, ..., sample = TRUE, center = TRUE, digits = 2, p.digits,
         as.na = NULL, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="skewness_+3A_data">data</code></td>
<td>
<p>a numeric vector or data frame.</p>
</td></tr>
<tr><td><code id="skewness_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>, e.g.,
<code>skewness(dat, x1)</code>. Note that the operators <code>.</code>,
<code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code>
can also be used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="skewness_+3A_sample">sample</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the univariate sample skewness
or kurtosis is computed, while the population skewness or kurtosis
is computed when <code>sample = FALSE</code>.</p>
</td></tr>
<tr><td><code id="skewness_+3A_center">center</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the univariate or multivariate
kurtosis is centered, so that the expected kurtosis under
univariate or multivariate normality is 0, while the expected
kurtosis under univariate or multivariate normality is 3 when
<code>center = FALSE</code>.</p>
</td></tr>
<tr><td><code id="skewness_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used. Note that this argument only applied when computing
multivariate skewness and kurtosis.</p>
</td></tr>
<tr><td><code id="skewness_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="skewness_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.,
these values are converted to <code>NA</code> before conducting the analysis.</p>
</td></tr>
<tr><td><code id="skewness_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="skewness_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.
Note that this argument only applied when computing multivariate skewness and kurtosis.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Univariate Skewness and Kurtosis</strong></dt><dd><p>Univariate skewness and kurtosis
are computed based on the same formula as in SAS and SPSS:
</p>

<ul>
<li><p><em>Population Skewness</em>
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{n}\frac{\sum_{i=1}^{n}(X_i - \bar{X})^3}{(\sum_{i=1}^{n}(X_i - \bar{X})^2)^{3/2}}</code>
</p>

</li>
<li><p><em>Sample Skewness</em>
</p>
<p style="text-align: center;"><code class="reqn">\frac{n\sqrt{n - 1}}{n-2}
      \frac{\sum_{i=1}^{n}(X_i - \bar{X})^3}{(\sum_{i=1}^{n}(X_i - \bar{X})^2)^{3/2}}</code>
</p>

</li>
<li><p><em>Population Excess Kurtosis</em>
</p>
<p style="text-align: center;"><code class="reqn">n\frac{\sum_{i=1}^{n}(X_i - \bar{X})^4}{(\sum_{i=1}^{n}(X_i - \bar{X})^2)^2} - 3</code>
</p>

</li>
<li><p><em>Sample Excess Kurtosis</em>
</p>
<p style="text-align: center;"><code class="reqn">(n + 1)\frac{\sum_{i=1}^{n}(X_i - \bar{X})^4}{(\sum_{i=1}^{n}(X_i - \bar{X})^2)^2} - 3 + 6\frac{n - 1}{(n - 2)(n - 3)}</code>
</p>

</li></ul>

<p>Note that missing values (<code>NA</code>) are stripped before the computation and
that at least 3 observations are needed to compute skewness and at least
4 observations are needed to compute kurtosis.</p>
</dd>
<dt><strong>Multivariate Skewness and Kurtosis</strong></dt><dd><p>Mardia's multivariate skewness
and kurtosis compares the joint distribution of several variables against a
multivariate normal distribution. The expected skewness is 0 for a multivariate
normal distribution, while the expected kurtosis is <code class="reqn">p(p + 2)</code> for a
multivariate distribution of <code class="reqn">p</code> variables. However, this function scales
the multivariate kurtosis on <code class="reqn">p(p + 2)</code> according to the default setting
<code>center = TRUE</code> so that the expected kurtosis under multivariate normality
is 0. Multivariate skewness and kurtosis are tested for statistical significance
based on the chi-square distribution for skewness and standard normal distribution
for the kurtosis. If at least one of the tests is statistically significant,
the underlying joint population is inferred to be non-normal. Note that non-significance of
these statistical tests do not imply multivariate normality.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns univariate skewness or kurtosis of <code>data</code> or an object of class
<code>misty.object</code>, which is a list with following entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>a numeric vector or data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Note</h3>

<p>These functions implemented a modified copy of the <code>mardia()</code> function
in the <span class="pkg">psych</span> package by William Revelle (2024).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Cain, M. K., Zhang, Z., &amp; Yuan, KH. (2024). Univariate and multivariate skewness
and kurtosis for measuring nonnormality: Prevalence, influence and estimation.
<em>Behavior Research Methods, 49</em>, 1716–1735. https://doi.org/10.3758/s13428-016-0814-1
</p>
<p>Mardia, K. V. (1970). Measures of multivariate skewness and kurtosis with applications.
<em>Biometrika, 57</em>(3), 519-530. https://doi.org/10.2307/2334770
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>William Revelle (2024). <em>psych: Procedures for Psychological, Psychometric, and
Personality Research</em>. Northwestern University, Evanston, Illinois.
R package version 2.4.6, https://CRAN.R-project.org/package=psych.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Compute univariate sample skewness
skewness(mtcars, mpg)

# Example 1b: Compute univariate sample excess kurtosis
kurtosis(mtcars, mpg)

# Example 2a: Compute multivariate skewness
skewness(mtcars)

# Example 2b: Compute multivariate excess kurtosis
kurtosis(mtcars)
</code></pre>

<hr>
<h2 id='std.coef'>Standardized Coefficients</h2><span id='topic+std.coef'></span>

<h3>Description</h3>

<p>This function computes standardized coefficients for linear models estimated by using the <code>lm()</code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std.coef(model, print = c("all", "stdx", "stdy", "stdyx"), digits = 3, p.digits = 3,
         write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="std.coef_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lm"</code>.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e. <code>"all"</code>, for all results,
<code>"stdx"</code> for standardizing only the predictor, <code>"stdy"</code> for for standardizing only
the criterion, and <code>"stdyx"</code> for for standardizing both the predictor and the criterion.
Note that the default setting is depending on the level of measurement of the predictors,
i.e., if all predictors are continuous, the default setting is <code>print = "stdyx"</code>;
if all predictors are binary, the default setting is <code>print = "stdy"</code>; if predictors
are continuous and binary, the default setting is <code>print = c("stdy", "stdyx")</code>.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used for displaying
results.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used for displaying the
<em>p</em>-value.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extension <code>".xlsx"</code>
(e.g., <code>"Output.xlsx"</code>). If the file name does not contain
any file extension, an Excel file will be written.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The slope <code class="reqn">\beta</code> can be standardized with respect to only <code class="reqn">x</code>, only <code class="reqn">y</code>, or both <code class="reqn">y</code>
and <code class="reqn">x</code>:
</p>
<p style="text-align: center;"><code class="reqn">StdX(\beta_1) = \beta_1 SD(x)</code>
</p>

<p><code class="reqn">StdX(\beta_1)</code> standardizes with respect to <code class="reqn">x</code> only and is interpreted as the change in
<code class="reqn">y</code> when <code class="reqn">x</code> changes one standard deviation referred to as <code class="reqn">SD(x)</code>.
</p>
<p style="text-align: center;"><code class="reqn">StdY(\beta_1) = \frac{\beta_1}{SD(x)}</code>
</p>

<p><code class="reqn">StdY(\beta_1)</code> standardizes with respect to <code class="reqn">y</code> only and is interpreted as the change in
<code class="reqn">y</code> standard deviation units, referred to as <code class="reqn">SD(y)</code>, when <code class="reqn">x</code> changes one unit.
</p>
<p style="text-align: center;"><code class="reqn">StdYX(\beta_1) = \beta_1 \frac{SD(x)}{SD(y)}</code>
</p>

<p><code class="reqn">StdYX(\beta_1)</code> standardizes with respect to both <code class="reqn">y</code> and <code class="reqn">x</code> and is interpreted as the change
in <code class="reqn">y</code> standard deviation units when <code class="reqn">x</code> changes one standard deviation.
</p>
<p>Note that the <code class="reqn">StdYX(\beta_1)</code> and the <code class="reqn">StdY(\beta_1)</code> standardizations are not suitable for the
slope of a binary predictor because a one standard deviation change in a binary variable is generally
not of interest (Muthen, Muthen, &amp; Asparouhov, 2016).
</p>
<p>The standardization of the slope <code class="reqn">\beta_3</code> in a regression model with an interaction term uses the
product of standard deviations <code class="reqn">SD(x_1)SD(x_2)</code> rather than the standard deviation of the product
<code class="reqn">SD(x_1 x_2)</code> for the interaction variable <code class="reqn">x_1</code><code class="reqn">x_2</code> (see Wen, Marsh &amp; Hau, 2010). Likewise,
the standardization of the slope <code class="reqn">\beta_3</code> in a polynomial regression model with a quadratic term
uses the product of standard deviations <code class="reqn">SD(x)SD(x)</code> rather than the standard deviation of the
product <code class="reqn">SD(x x)</code> for the quadratic term <code class="reqn">x^2</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in <code>model</code> </p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>coef</code> for the regression
table including standardized coefficients and <code>sd</code>
for the standard deviation of the outcome and predictor(s)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Muthen, B. O., Muthen, L. K., &amp; Asparouhov, T. (2016). <em>Regression and mediation analysis using Mplus</em>.
Muthen &amp; Muthen.
</p>
<p>Wen, Z., Marsh, H. W., &amp; Hau, K.-T. (2010). Structural equation models of latent interactions:
An appropriate standardized solution and its scale-free properties. <em>Structural Equation Modeling:
A Multidisciplinary Journal, 17</em>, 1-22. https://doi.org/10.1080/10705510903438872
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Linear model

# Example 1: Regression model with continuous predictors
mod.lm1 &lt;- lm(mpg ~ cyl + disp, data = mtcars)
std.coef(mod.lm1)

# Example 2: Print all standardized coefficients
std.coef(mod.lm1, print = "all")

# Example 3: Regression model with dichotomous predictor
mod.lm2 &lt;- lm(mpg ~ vs, data = mtcars)
std.coef(mod.lm2)

# Example 4: Regression model with continuous and dichotomous predictors
mod.lm3 &lt;- lm(mpg ~ disp + vs, data = mtcars)
std.coef(mod.lm3)

# Example 5: Regression model with continuous predictors and an interaction term
mod.lm4 &lt;- lm(mpg ~ cyl*disp, data = mtcars)
std.coef(mod.lm4)

# Example 6: Regression model with a quadratic term
mod.lm5 &lt;- lm(mpg ~ cyl + I(cyl^2), data = mtcars)
std.coef(mod.lm5)

## Not run: 
#----------------------------------------------------------------------------
# Example 7: Write Results into a Text of Excel file

# Example 7a: Text file
std.coef(mod.lm1, write = "Std_Coef.txt", output = FALSE, check = FALSE)

# Example 7b: Excel file
std.coef(mod.lm1, write = "Std_Coef.xlsx", output = FALSE, check = FALSE)
## End(Not run)
</code></pre>

<hr>
<h2 id='test.levene'>Levene's Test for Homogeneity of Variance</h2><span id='topic+test.levene'></span>

<h3>Description</h3>

<p>This function performs Levene's test for homogeneity of variance across two
or more independent groups including a plot showing violins and boxplots
representing the distribution of the outcome variable for each group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.levene(formula, data, method = c("median", "mean"), conf.level = 0.95,
            hypo = TRUE, descript = TRUE, digits = 2, p.digits = 3, as.na = NULL,
            plot = FALSE, violin = TRUE, box = TRUE, jitter = FALSE,
            violin.alpha = 0.3, violin.trim = FALSE, box.alpha = 0.2,
            box.width = 0.2, jitter.size = 1.25, jitter.width = 0.05,
            jitter.height = 0, jitter.alpha = 0.2, gray = FALSE, start = 0.9,
            end = 0.4, color = NULL, xlab = NULL, ylab = NULL, ylim = NULL,
            ybreaks = ggplot2::waiver(), title = "", subtitle = "",
            filename = NULL, width = NA, height = NA,
            units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL,
            append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.levene_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> where <code>y</code> is
a numeric variable giving the data values and <code>group</code>
a numeric variable, character variable or factor with two
or more than two values or factor levels giving the
corresponding groups.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_method">method</code></td>
<td>
<p>a character string specifying the method to compute the
center of each group, i.e. <code>method = "median"</code> (default)
to compute the Levene's test based on the median (aka
Brown-Forsythe test) or <code>method = "mean"</code> to compute
the Levene's test based on the arithmetic mean.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing violins with
boxplots is drawn.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_violin">violin</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), violins are drawn.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_box">box</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), boxplots are drawn.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), jittered data points
are drawn.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_violin.alpha">violin.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_violin</code>
function for controlling the opacity of the violins.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_violin.trim">violin.trim</code></td>
<td>
<p>logical: if <code>TRUE</code>, the tails of the violins to the
range of the data is trimmed.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_box.alpha">box.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_boxplot</code>
function for controlling the opacity of the boxplots.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_box.width">box.width</code></td>
<td>
<p>a numeric value indicating the width of the boxplots.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_jitter</code>
function for controlling the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_gray">gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, the plot is drawn in gray scale.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_start">start</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to
specify the gray value at the low end of the palette.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_end">end</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to
specify the gray value at the high end of the palette.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_color">color</code></td>
<td>
<p>a character vector, indicating the color of the violins
and the boxes. By default, default ggplot2 colors are
used.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle
for the plot.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code> argument (default is <code>"NA_Pattern.pdf"</code>) including
the file extension for the <code>ggsave</code> function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default), <code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>, <code>".bmp"</code>,
<code>".svg"</code> or <code>".wmf"</code> needs to be specified as file extension in the <code>file</code> argument.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument (default is the
size of the current graphics device) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Levene's test is equivalent to a one-way analysis of variance (ANOVA) with the
absolute deviations of observations from the mean of each group as dependent
variable (<code>center = "mean"</code>). Brown and Forsythe (1974) modified the
Levene's test by using the absolute deviations of observations from the median
(<code>center = "median"</code>). By default, the Levene's test uses the absolute
deviations of observations from the median.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>descript</code> for
descriptive statistics and <code>test</code> for the ANOVA
table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Brown, M. B., &amp; Forsythe, A. B. (1974). Robust tests for the equality of
variances. <em>Journal of the American  Statistical Association, 69</em>,
364-367.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Levene's test based on the median
test.levene(mpg ~ gear, data = mtcars)

# Example 2: Levene's test based on the arithmetic mean
test.levene(mpg ~ gear, data = mtcars, method = "mean")

# Example 3: Levene's test based on the median, plot results
test.levene(mpg ~ gear, data = mtcars, plot = TRUE)

## Not run: 
# Example 4: Write results into a text file
test.levene(mpg ~ gear, data = mtcars, write = "Levene.txt")

# Example 5: Levene's test based on the median, save plot
test.levene(mpg ~ gear, data = mtcars, plot = TRUE,
            filename = "Levene-test.png", dpi = 600, width = 6, height = 5)
## End(Not run)
</code></pre>

<hr>
<h2 id='test.t'>t-Test</h2><span id='topic+test.t'></span><span id='topic+test.t.default'></span><span id='topic+test.t.formula'></span>

<h3>Description</h3>

<p>This function performs one-sample, two-sample, and paired-sample t-tests and
provides descriptive statistics, effect size measure, and a plot showing bar
plots with error bars for (difference-adjusted) confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.t(x, ...)

## Default S3 method:
test.t(x, y = NULL, mu = 0, paired = FALSE,
       alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
       hypo = TRUE, descript = TRUE, effsize = FALSE, weighted = FALSE,
       cor = TRUE, ref = NULL, correct = FALSE, digits = 2, p.digits = 3,
       as.na = NULL, plot = FALSE, bar = TRUE, point = FALSE, ci = TRUE,
       line = TRUE, jitter = FALSE, adjust = TRUE, point.size = 4, errorbar.width = 0.1,
       xlab = NULL, ylab = NULL, ylim = NULL, ybreaks = ggplot2::waiver(),
       linetype = 3, linewidth = 0.8, jitter.size = 1.25, jitter.width = 0.05,
       jitter.height = 0, jitter.alpha = 0.1, title = "",
       subtitle = "Confidence Interval", filename = NULL, width = NA, height = NA,
       units = c("in", "cm", "mm", "px"),
       dpi = 600, write = NULL, append = TRUE, check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
test.t(formula, data, alternative = c("two.sided", "less", "greater"),
       conf.level = 0.95, hypo = TRUE, descript = TRUE, effsize = FALSE, weighted = FALSE,
       cor = TRUE, ref = NULL, correct = FALSE, digits = 2, p.digits = 3, as.na = NULL,
       plot = FALSE, bar = TRUE, point = FALSE, ci = TRUE, line = TRUE,
       jitter = FALSE, adjust = TRUE, point.size = 4, errorbar.width = 0.1, xlab = NULL,
       ylab = NULL, ylim = NULL, ybreaks = ggplot2::waiver(), linetype = 3,
       linewidth = 0.8, jitter.size = 1.25, jitter.width = 0.05, jitter.height = 0,
       jitter.alpha = 0.1, title = "", subtitle = "Confidence Interval", filename = NULL,
       width = NA, height = NA, units = c("in", "cm", "mm", "px"), dpi = 600,
       write = NULL, append = TRUE, check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.t_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="test.t_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="test.t_+3A_y">y</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="test.t_+3A_mu">mu</code></td>
<td>
<p>a numeric value indicating the population mean under the
null hypothesis. Note that the argument <code>mu</code> is only
used when computing a one sample t-test.</p>
</td></tr>
<tr><td><code id="test.t_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, paired-samples t-test is computed.</p>
</td></tr>
<tr><td><code id="test.t_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="test.t_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="test.t_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="test.t_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measure Cohen's d is
shown on the console, see <code><a href="#topic+cohens.d">cohens.d</a></code> function.</p>
</td></tr>
<tr><td><code id="test.t_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code>, the weighted pooled standard deviation
is used to compute Cohen's d for a two-sample design (i.e.,
<code>paired = FALSE</code>), while standard deviation of the
difference scores is used to compute Cohen's d for a
paired-sample design (i.e., <code>paired = TRUE</code>).</p>
</td></tr>
<tr><td><code id="test.t_+3A_cor">cor</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), <code>paired = TRUE</code>,
and <code>weighted = FALSE</code>, Cohen's d for a paired-sample
design while controlling for the correlation between the
two sets of measurement is computed. Note that this
argument is only used in
a paired-sample design (i.e., <code>paired = TRUE</code>) when
specifying <code>weighted = FALSE</code>.</p>
</td></tr>
<tr><td><code id="test.t_+3A_ref">ref</code></td>
<td>
<p>character string <code>"x"</code> or <code>"y"</code> for specifying
the reference reference group when using the default
<code>test.t()</code> function or a numeric value or character
string indicating the reference group in a two-sample
design when using the formula <code>test.t()</code> function.
The standard deviation of the reference variable or
reference group is used to standardized the mean difference
to compute Cohen's d. Note that this argument is only used
in a two-sample design (i.e., <code>paired = FALSE</code>).</p>
</td></tr>
<tr><td><code id="test.t_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor to remove
positive bias in small samples is used.</p>
</td></tr>
<tr><td><code id="test.t_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="test.t_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying descriptive statistics and
confidence interval.</p>
</td></tr>
<tr><td><code id="test.t_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="test.t_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing bar plots with
error bars for confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="test.t_+3A_bar">bar</code></td>
<td>
<p>ogical: if <code>TRUE</code> (default), bars representing means
for each groups are drawn.</p>
</td></tr>
<tr><td><code id="test.t_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code>, points representing means for
each groups are drawn.</p>
</td></tr>
<tr><td><code id="test.t_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), error bars representing
confidence intervals are drawn.</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code>, jittered data points are drawn.</p>
</td></tr>
<tr><td><code id="test.t_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a horizontal line
is drawn at <code>mu</code> for the one-sample t-test or at
0 for the paired-sample t-test.</p>
</td></tr>
<tr><td><code id="test.t_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment for the
confidence intervals in a two-sample design is applied.</p>
</td></tr>
<tr><td><code id="test.t_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="test.t_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="test.t_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_linetype">linetype</code></td>
<td>
<p>an integer value or character string specifying the line
type for the line representing the population mean under
the null hypothesis, i.e., 0 = blank, 1 = solid, 2 = dashed,
3 = dotted, 4 = dotdash, 5 = longdash, 6 = twodash.</p>
</td></tr>
<tr><td><code id="test.t_+3A_linewidth">linewidth</code></td>
<td>
<p>a numeric value indicating the <code>linewidth</code> aesthetic
for the line representing the population mean under the
null hypothesis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p> a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_jitter</code>
function for controlling the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="test.t_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="test.t_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle for
the plot.</p>
</td></tr>
<tr><td><code id="test.t_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code> argument (default is <code>"NA_Pattern.pdf"</code>) including
the file extension for the <code>ggsave</code> function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default), <code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>, <code>".bmp"</code>,
<code>".svg"</code> or <code>".wmf"</code> needs to be specified as file extension in the <code>file</code> argument.</p>
</td></tr>
<tr><td><code id="test.t_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument (default is the
size of the current graphics device) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.t_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.t_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.t_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.t_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="test.t_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="test.t_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="test.t_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="test.t_+3A_formula">formula</code></td>
<td>
<p>in case of two sample t-test (i.e., <code>paired = FALSE</code>),
a formula of the form <code>y ~ group</code> where <code>group</code>
is a numeric variable, character variable or factor with
two values or factor levels giving the corresponding
groups.</p>
</td></tr>
<tr><td><code id="test.t_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Effect Size Measure</strong></dt><dd><p>By default, Cohen's d based on the non-weighted
standard deviation (i.e., <code>weighted = FALSE</code>) which does not assume homogeneity
of variance is computed (see Delacre et al., 2021) when requesting an effect size
measure (i.e., <code>effsize = TRUE</code>). Cohen's d based on the pooled standard
deviation assuming equality of variances between groups can be requested by
specifying <code>weighted = TRUE</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>type of sample, i.e., one-, two-, or paired sample</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame with the outcome and grouping variable</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in
psychology - Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Delacre, M., Lakens, D., Ley, C., Liu, L., &amp; Leys, C. (2021). Why Hedges' g*s
based on the non-pooled standard deviation should be reported with Welch's t-test.
https://doi.org/10.31234/osf.io/tu6mp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>, <code><a href="#topic+test.z">test.z</a></code>,
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# One-Sample Design

# Example 1a: Two-sided one-sample t-test, population mean = 20
test.t(mtcars$mpg, mu = 20)

# Example 1b: One-sided one-sample t-test, population mean = 20, print Cohen's d
test.t(mtcars$mpg, mu = 20, alternative = "greater", effsize = TRUE)

# Example 1c: Two-sided one-sample t-test, population mean = 20, plot results
test.t(mtcars$mpg, mu = 20, plot = TRUE)

## Not run: 
# Example 1d: Two-sided one-sample t-test, population mean = 20, save plot
test.t(mtcars$mpg, mu = 20, plot = TRUE, filename = "One-sample_t-test.png",
       width = 4, height = 5)
## End(Not run)

#----------------------------------------------------------------------------
# Two-Sample Design

# Example 2a: Two-sided two-sample t-test
test.t(mpg ~ vs, data = mtcars)

# Example 2b: Two-sided two-sample t-test, alternative specification
test.t(c(3, 1, 4, 2, 5, 3, 6, 7), c(5, 2, 4, 3, 1))

# Example 2c: One-sided two-sample t-test, print Cohen's d with weighted pooled SD
test.t(mpg ~ vs, data = mtcars, alternative = "greater", effsize = TRUE)

# Example 2d: Two-sided two-sample t-test, plot results
test.t(mpg ~ vs, data = mtcars, plot = TRUE)

## Not run: 
# Example 2e: Two-sided two-sample t-test, plot results
test.t(mpg ~ vs, data = mtcars, plot = TRUE, filename = "Two-sample_t-test.png",
       width = 5, height = 6)
## End(Not run)

#----------------------------------------------------------------------------
# Paired-Sample Design

# Example 3a: Two-sided paired-sample t-test
test.t(mtcars$drat, mtcars$wt, paired = TRUE)

# Example 3b: One-sided paired-sample t-test,
# print Cohen's d based on the SD of the difference scores
test.t(mtcars$drat, mtcars$wt, paired = TRUE, alternative = "greater",
       effsize = TRUE)

# Example 3c: Two-sided paired-sample t-test, plot results
test.t(mtcars$drat, mtcars$wt, paired = TRUE, plot = TRUE)

## Not run: 
# Example 3d: Two-sided paired-sample t-test, save plot
test.t(mtcars$drat, mtcars$wt, paired = TRUE, plot = TRUE,
       filename = "Paired-sample_t-test.png", width = 4, height = 5)
## End(Not run)
</code></pre>

<hr>
<h2 id='test.welch'>Welch's Test</h2><span id='topic+test.welch'></span>

<h3>Description</h3>

<p>This function performs Welch's two-sample t-test and Welch's ANOVA including
Games-Howell post hoc test for multiple comparison and provides descriptive
statistics, effect size measures, and a plot showing bars representing means
for each group and error bars for difference-adjusted confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.welch(formula, data, alternative = c("two.sided", "less", "greater"),
           posthoc = FALSE, conf.level = 0.95, hypo = TRUE, descript = TRUE,
           effsize = FALSE, weighted = FALSE, ref = NULL, correct = FALSE,
           digits = 2, p.digits = 3, as.na = NULL, plot = FALSE, bar = TRUE,
           point = FALSE, ci = TRUE, jitter = FALSE, adjust = TRUE,
           point.size = 3, errorbar.width = 0.1, jitter.size = 1.25,
           jitter.width = 0.05, jitter.height = 0, jitter.alpha = 0.1,
           xlab = NULL, ylab = "y", ylim = NULL, ybreaks = ggplot2::waiver(),
           title = NULL, subtitle = "Confidence Interval", filename = NULL,
           width = NA, height = NA, units = c("in", "cm", "mm", "px"),
           dpi = 600, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.welch_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> where <code>y</code> is
a numeric variable giving the data values and <code>group</code>
a numeric variable, character variable or factor with two
or more than two values or factor levels giving the
corresponding groups.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>. Note that this argument is only used when
conducting Welch's two-sample t-test.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_posthoc">posthoc</code></td>
<td>
<p>logical: if <code>TRUE</code>, Games-Howell post hoc test for
multiple comparison is conducted when performing Welch's
ANOVA.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measure Cohen's d for
Welch's two-sample t-test (see <code><a href="#topic+cohens.d">cohens.d</a></code>),
<code class="reqn">\eta^2</code> and <code class="reqn">\omega^2</code> for Welch's ANOVA and
Cohen's d for the post hoc tests are shown on the console.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code>, the weighted pooled standard
deviation is used to compute Cohen's d.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_ref">ref</code></td>
<td>
<p>a numeric value or character string indicating the reference
group. The standard deviation of the reference group is used
to standardized the mean difference to compute Cohen's d.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor to remove positive
bias in small samples is used.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying descriptive statistics and
confidence interval.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing error bars for
confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_bar">bar</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), bars representing means
for each groups are drawn.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code>, points representing means for
each groups are drawn.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), error bars representing
confidence intervals are drawn.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code>, jittered data points are drawn.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the confidence intervals is applied.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p> a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_jitter</code>
function for controlling the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title of
the plot.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle of
the plot.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code>
argument including the file extension in the <code>ggsave</code>
function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default),
<code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>,
<code>".bmp"</code>, <code>".svg"</code> or <code>".wmf"</code> needs
to be specified as file extension in the <code>filename</code>
argument. Note that plots can only be saved when
<code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device)
in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) in the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Effect Size Measure</strong></dt><dd><p>By default, Cohen's d based on the non-weighted
standard deviation (i.e., <code>weighted = FALSE</code>) which does not assume homogeneity
of variance is computed (see Delacre et al., 2021) when requesting an effect size
measure (i.e., <code>effsize = TRUE</code>). Cohen's d based on the pooled standard
deviation assuming equality of variances between groups can be requested by
specifying <code>weighted = TRUE</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>type of sample, i.e., one-, two-, or paired sample</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame with the outcome and grouping variable</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Delacre, M., Lakens, D., Ley, C., Liu, L., &amp; Leys, C. (2021). Why Hedges' g*s
based on the non-pooled standard deviation should be reported with Welch's t-test.
https://doi.org/10.31234/osf.io/tu6mp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+test.levene">test.levene</a></code>,
<code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Two-Sample Design

# Example 1a: Two-sided two-sample Welch-test
test.welch(mpg ~ vs, data = mtcars)

# Example 1b: One-sided two-sample Welch-test
test.welch(mpg ~ vs, data = mtcars, alternative = "greater")

# Example 1c: Two-sided two-sample Welch-test, print Cohen's d
test.welch(mpg ~ vs, data = mtcars, effsize = TRUE)

# Example 1d: Two-sided two-sample Welch-test, plot results
test.welch(mpg ~ vs, data = mtcars, plot = TRUE)

#----------------------------------------------------------------------------
# Multiple-Sample Design

# Example 2a: Welch's ANOVA
test.welch(mpg ~ gear, data = mtcars)

# Example 2b: Welch's ANOVA, Games-Howell post hoc test
test.welch(mpg ~ gear, data = mtcars, posthoc = TRUE)

# Example 2c: Welch's ANOVA, print eta-squared and omega-squared
test.welch(mpg ~ gear, data = mtcars, effsize = TRUE)

# Example 2d: Welch's ANOVA, plot results
test.welch(mpg ~ gear, data = mtcars, plot = TRUE)

## Not run: 
# Example 2e: Welch's ANOVA, save plot
test.welch(mpg ~ gear, data = mtcars, plot = TRUE,
           filename = "Multiple-sample_Welch-test.png", width = 6, height = 5)
## End(Not run)
</code></pre>

<hr>
<h2 id='test.z'>z-Test</h2><span id='topic+test.z'></span><span id='topic+test.z.default'></span><span id='topic+test.z.formula'></span>

<h3>Description</h3>

<p>This function performs one-sample, two-sample, and paired-sample z-tests and
provides descriptive statistics, effect size measure, and a plot showing error
bars for (difference-adjusted) confidence intervals with jittered data points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.z(x, ...)

## Default S3 method:
test.z(x, y = NULL, sigma = NULL, sigma2 = NULL, mu = 0,
       paired = FALSE, alternative = c("two.sided", "less", "greater"),
       conf.level = 0.95, hypo = TRUE, descript = TRUE, effsize = FALSE,
       digits = 2, p.digits = 3, as.na = NULL, plot = FALSE, bar = TRUE,
       point = FALSE, ci = TRUE, line = TRUE, jitter = FALSE, adjust = TRUE,
       point.size = 4, errorbar.width = 0.1, xlab = NULL, ylab = NULL,
       ylim = NULL, ybreaks = ggplot2::waiver(), linetype = 3, linewidth = 0.8,
       jitter.size = 1.25, jitter.width = 0.05, jitter.height = 0,
       jitter.alpha = 0.1, title = "", subtitle = "Confidence Interval",
       filename = NULL, width = NA, height = NA, units = c("in", "cm", "mm", "px"),
       dpi = 600, write = NULL, append = TRUE, check = TRUE,
       output = TRUE, ...)

## S3 method for class 'formula'
test.z(formula, data, sigma = NULL, sigma2 = NULL,
       alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
       hypo = TRUE, descript = TRUE, effsize = FALSE, digits = 2, p.digits = 3,
       as.na = NULL, plot = FALSE, bar = TRUE, point = FALSE, ci = TRUE,
       line = TRUE, jitter = FALSE, adjust = TRUE, point.size = 4, errorbar.width = 0.1,
       xlab = NULL, ylab = NULL, ylim = NULL, ybreaks = ggplot2::waiver(),
       linetype = 3, linewidth = 0.8, jitter.size = 1.25, jitter.width = 0.05,
       jitter.height = 0, jitter.alpha = 0.1, title = "",
       subtitle = "Confidence Interval", filename = NULL, width = NA, height = NA,
       units = c("in", "cm", "mm", "px"), dpi = 600, write = NULL, append = TRUE,
       check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.z_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="test.z_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="test.z_+3A_y">y</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="test.z_+3A_sigma">sigma</code></td>
<td>
<p>a numeric vector indicating the population standard deviation(s).
In case of two-sample z-test, equal standard deviations are
assumed when specifying one value for the argument <code>sigma</code>;
when specifying two values for the argument <code>sigma</code>,
unequal standard deviations are assumed. Note that either
argument <code>sigma</code> or argument <code>sigma2</code> is specified.</p>
</td></tr>
<tr><td><code id="test.z_+3A_sigma2">sigma2</code></td>
<td>
<p>a numeric vector indicating the population variance(s). In
case of two-sample z-test, equal variances are assumed when
specifying one value for the argument <code>sigma2</code>; when
specifying two values for the argument <code>sigma</code>, unequal
variance are assumed. Note that either argument <code>sigma</code>
or argument <code>sigma2</code> is specified.</p>
</td></tr>
<tr><td><code id="test.z_+3A_mu">mu</code></td>
<td>
<p>a numeric value indicating the population mean under the null
hypothesis. Note that the argument <code>mu</code> is only used
when computing a one-sample z-test.</p>
</td></tr>
<tr><td><code id="test.z_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, paired-sample z-test is computed.</p>
</td></tr>
<tr><td><code id="test.z_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="test.z_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis are
shown on the console.</p>
</td></tr>
<tr><td><code id="test.z_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="test.z_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measure Cohen's d is
shown on the console.</p>
</td></tr>
<tr><td><code id="test.z_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="test.z_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying descriptive statistics and confidence
interval.</p>
</td></tr>
<tr><td><code id="test.z_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="test.z_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing bar plots with
error bars for confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="test.z_+3A_bar">bar</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), bars representing means
for each groups are drawn.</p>
</td></tr>
<tr><td><code id="test.z_+3A_point">point</code></td>
<td>
<p>logical: if <code>TRUE</code>, points representing means for
each groups are drawn.</p>
</td></tr>
<tr><td><code id="test.z_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), error bars representing
confidence intervals are drawn.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code>, jittered data points are drawn.</p>
</td></tr>
<tr><td><code id="test.z_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a horizontal line
is drawn at <code>mu</code> for the one-sample z-test or at
0 for the paired-sample z-test.</p>
</td></tr>
<tr><td><code id="test.z_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment for the
confidence intervals in a two-sample design is applied.</p>
</td></tr>
<tr><td><code id="test.z_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="test.z_+3A_errorbar.width">errorbar.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="test.z_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_linetype">linetype</code></td>
<td>
<p>an integer value or character string specifying the line
type for the line representing the population mean under
the null hypothesis, i.e., 0 = blank, 1 = solid, 2 = dashed,
3 = dotted, 4 = dotdash, 5 = longdash, 6 = twodash.</p>
</td></tr>
<tr><td><code id="test.z_+3A_linewidth">linewidth</code></td>
<td>
<p>a numeric value indicating the <code>linewidth</code> aesthetic
for the line representing the population mean under the
null hypothesis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p> a numeric value between 0 and 1 for specifying the
<code>alpha</code> argument in the <code>geom_jitter</code>
function for controlling the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="test.z_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="test.z_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle for
the plot.</p>
</td></tr>
<tr><td><code id="test.z_+3A_filename">filename</code></td>
<td>
<p>a character string indicating the <code>filename</code> argument (default is <code>"NA_Pattern.pdf"</code>) including
the file extension for the <code>ggsave</code> function. Note that one of <code>".eps"</code>, <code>".ps"</code>,
<code>".tex"</code>, <code>".pdf"</code> (default), <code>".jpeg"</code>, <code>".tiff"</code>, <code>".png"</code>, <code>".bmp"</code>,
<code>".svg"</code> or <code>".wmf"</code> needs to be specified as file extension in the <code>file</code> argument.</p>
</td></tr>
<tr><td><code id="test.z_+3A_width">width</code></td>
<td>
<p>a numeric value indicating the <code>width</code> argument (default is the
size of the current graphics device) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.z_+3A_height">height</code></td>
<td>
<p>a numeric value indicating the <code>height</code> argument
(default is the size of the current graphics device) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.z_+3A_units">units</code></td>
<td>
<p>a character string indicating the <code>units</code> argument
(default is <code>in</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.z_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value indicating the <code>dpi</code> argument
(default is <code>600</code>) for the <code>ggsave</code> function.</p>
</td></tr>
<tr><td><code id="test.z_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="test.z_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="test.z_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="test.z_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="test.z_+3A_formula">formula</code></td>
<td>
<p>in case of two sample z-test (i.e., <code>paired = FALSE</code>),
a formula of the form <code>y ~ group</code> where <code>group</code>
is a numeric variable, character variable or factor with
two values or factor levels giving the corresponding
groups.</p>
</td></tr>
<tr><td><code id="test.z_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cohen's d reported when argument <code>effsize = TRUE</code> is based on the population
standard deviation specified in <code>sigma</code> or the square root of the population
variance specified in <code>sigma2</code>. In a one-sample and paired-sample design,
Cohen's d is the mean of the difference scores divided by the population standard
deviation of the difference scores (i.e., equivalent to Cohen's <code class="reqn">d_z</code> according
to Lakens, 2013). In a two-sample design, Cohen's d is the difference between
means of the two groups of observations divided by either the population standard
deviation when assuming and specifying equal standard deviations or the unweighted
pooled population standard deviation when assuming and specifying unequal standard
deviations.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>type of sample, i.e., one-, two-, or paired sample</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame with the outcome and grouping variable</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative
science: A practical primer for t-tests and ANOVAs. <em>Frontiers in Psychology, 4</em>,
1-12. https://doi.org/10.3389/fpsyg.2013.00863
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>,
<code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# One-Sample Design

# Example 1a: Two-sided one-sample z-test, population mean = 20, population SD = 6
test.z(mtcars$mpg, sigma = 6, mu = 20)

# Example 1b: One-sided one-sample z-test, population mean = 20, population SD = 6,
# print Cohen's d
test.z(mtcars$mpg, sigma = 6, mu = 20, alternative = "greater", effsize = TRUE)

# Example 1c: Two-sided one-sample z-test, population mean = 20, population SD = 6,
# plot results
test.z(mtcars$mpg, sigma = 6, mu = 20, plot = TRUE)

## Not run: 
# Example 1d: Two-sided one-sample z-test, save plot
test.z(mtcars$mpg, sigma = 6, mu = 20, plot = TRUE, filename = "One-sample_z-test.png",
       width = 4, height = 5)
## End(Not run)

#----------------------------------------------------------------------------
# Two-Sample Design

# Example 2a: Two-sided two-sample z-test, population SD = 6, equal SD assumption
test.z(mpg ~ vs, data = mtcars, sigma = 6)

# Example 2b: Two-sided two-sample z-test, alternative specification
test.z(c(3, 1, 4, 2, 5, 3, 6, 7), c(5, 2, 4, 3, 1), sigma = 1.2)

# Example 2c: Two-sided two-sample z-test, population SD = 4 and 6, unequal SD assumption
test.z(mpg ~ vs, data = mtcars, sigma = c(4, 6))

# Example 2d: One-sided two-sample z-test, population SD = 4 and 6, unequal SD assumption
# print Cohen's d
test.z(mpg ~ vs, data = mtcars, sigma = c(4, 6), alternative = "greater",
       effsize = TRUE)

# Example 2e: Two-sided two-sample z-test, population SD = 6, equal SD assumption
# plot results
test.z(mpg ~ vs, data = mtcars, sigma = 6, plot = TRUE)

## Not run: 
# Example 2f: Two-sided two-sample z-test, save plot
test.z(mpg ~ vs, data = mtcars, sigma = 6, plot = TRUE, filename = "Two-sample_z-test.png",
       width = 5, height = 6)
## End(Not run)

#----------------------------------------------------------------------------
# Paired-Sample Design

# Example 3a: Two-sided paired-sample z-test, population SD of difference score = 1.2
test.z(mtcars$drat, mtcars$wt, sigma = 1.2, paired = TRUE)

# Example 3b: One-sided paired-sample z-test, population SD of difference score = 1.2,
# print Cohen's d
test.z(mtcars$drat, mtcars$wt, sigma = 1.2, paired = TRUE,
       alternative = "greater", effsize = TRUE)

# Example 3c: Two-sided paired-sample z-test, population SD of difference score = 1.2,
# plot results
test.z(mtcars$drat, mtcars$wt, sigma = 1.2, paired = TRUE, plot = TRUE)

## Not run: 
# Example 3d: Two-sided paired-sample z-test, save plot
test.z(mtcars$drat, mtcars$wt, sigma = 1.2, paired = TRUE, plot = TRUE,
       filename = "Paired-sample_z-test.png", width = 4, height = 5)
## End(Not run)
</code></pre>

<hr>
<h2 id='write.dta'>Write Stata DTA File</h2><span id='topic+write.dta'></span>

<h3>Description</h3>

<p>This function writes a data frame or matrix into a Stata data file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.dta(x, file = "Stata_Data.dta", version = 14, label = NULL,
          str.thres = 2045, adjust.tz = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.dta_+3A_x">x</code></td>
<td>
<p>a matrix or data frame to be written in Stata, vectors are
coerced to a data frame.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without file extension
'.dta', e.g., <code>"Stata_Data.dta"</code> or <code>"Stata_Data"</code>.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_version">version</code></td>
<td>
<p>Stats file version to use. Supports versions 8-15.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_label">label</code></td>
<td>
<p>dataset label to use, or <code>NULL</code>. Defaults to the value
stored in the &quot;label&quot; attribute pf data. Must be &lt;= 80
characters.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_str.thres">str.thres</code></td>
<td>
<p>any character vector with a maximum length greater than
<code>str.thre</code> bytes will be stored as a long string
<code>strL</code> instead of a standard string <code>str</code>
variable if <code>version</code> is greater or equal 13.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_adjust.tz">adjust.tz</code></td>
<td>
<p>this argument controls how the timezone of date-time values
is treated when writing, see 'Details' in the
in the <code>write_dta</code> function in the <code>havan</code>
package.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable attributes
specified in the argument <code>var.attr</code> is checked.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is a modified copy of the <code>read_dta()</code> function in the
<span class="pkg">haven</span> package by Hadley Wickham, Evan Miller and Danny Smith (2023).
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham, Evan Miller and Danny Smith
</p>


<h3>References</h3>

<p>Wickham H, Miller E, Smith D (2023). <em>haven: Import and Export 'SPSS',
'Stata' and 'SAS' Files</em>. R package version 2.5.3.
<a href="https://CRAN.R-project.org/package=haven">https://CRAN.R-project.org/package=haven</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>, <code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>,
<code><a href="#topic+write.xlsx">write.xlsx</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Write data frame 'mtcars' into the State data file 'mtcars.dta'
write.dta(mtcars, "mtcars.dta")

## End(Not run)
</code></pre>

<hr>
<h2 id='write.mplus'>Write Mplus Data File</h2><span id='topic+write.mplus'></span>

<h3>Description</h3>

<p>This function writes a matrix or data frame to a tab-delimited file without variable
names, a Mplus input template, and a text file with variable names. Note that only
numeric variables are allowed, i.e., non-numeric variables will be removed from
the data set. Missing data will be coded as a single numeric value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.mplus(x, file = "Mplus_Data.dat", data = TRUE, input = TRUE,
            var = FALSE, na = -99, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.mplus_+3A_x">x</code></td>
<td>
<p>a matrix or data frame to be written to a tab-delimited file.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without the file extension
'.dat', e.g., <code>"Mplus_Data.dat"</code> or <code>"Mplus_Data"</code>.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_data">data</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Mplus data file is written in a
text file named according to the argument<code>file</code>.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_input">input</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Mplus input template is written
in a text file named according to the argument<code>file</code> with the
extension <code>_INPUT.inp</code>.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_var">var</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable names are written in a text file
named according to the argument<code>file</code> with the extension
<code>_VARNAMES.txt</code>.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_na">na</code></td>
<td>
<p>a numeric value or character string representing missing values
(<code>NA</code>) in the data set.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character string indicating the variable names for the Mplus input file.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+mplus.run">mplus.run</a></code>, <code><a href="#topic+write.sav">write.sav</a></code>,
<code><a href="#topic+write.xlsx">write.xlsx</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Write Mplus Data File and a Mplus input template
write.mplus(mtcars)

# Example 2: Write Mplus Data File "mtcars.dat" and a Mplus input template "mtcars_INPUT.inp",
# missing values coded with -999,
# write variable names in a text file called "mtcars_VARNAMES.inp"
write.mplus(mtcars, file = "mtcars.dat", var = TRUE, na = -999)

## End(Not run)
</code></pre>

<hr>
<h2 id='write.result'>Write Results of a misty Object into an Excel file</h2><span id='topic+write.result'></span>

<h3>Description</h3>

<p>This function writes the results of a <code>misty.object</code>) into an Excel file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.result(x, file = "Results.xlsx", tri = x$args$tri,
             digits = x$args$digits, p.digits = x$args$p.digits,
             icc.digits = x$args$icc.digits, r.digits = x$args$r.digits,
             ess.digits = x$args$ess.digits, mcse.digits = x$args$mcse.digits,
             check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.result_+3A_x">x</code></td>
<td>
<p>misty object (<code>misty.object</code>) resulting from a misty function
supported by the <code>write.result</code> function (see 'Details').</p>
</td></tr>
<tr><td><code id="write.result_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without file extension
'.xlsx', e.g., <code>"Results.xlsx"</code> or <code>"Results"</code>.</p>
</td></tr>
<tr><td><code id="write.result_+3A_tri">tri</code></td>
<td>
<p>a character string or character vector indicating which triangular
of the matrix to show on the console, i.e., <code>both</code> for upper and lower
triangular, <code>lower</code> for the lower triangular, and <code>upper</code> for the upper
triangular.</p>
</td></tr>
<tr><td><code id="write.result_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places digits
to be used for displaying results.</p>
</td></tr>
<tr><td><code id="write.result_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="write.result_+3A_icc.digits">icc.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying intraclass correlation coefficients.</p>
</td></tr>
<tr><td><code id="write.result_+3A_r.digits">r.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying R-hat values.</p>
</td></tr>
<tr><td><code id="write.result_+3A_ess.digits">ess.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying effective sample sizes.</p>
</td></tr>
<tr><td><code id="write.result_+3A_mcse.digits">mcse.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying Monte Carlo standard errors.</p>
</td></tr>
<tr><td><code id="write.result_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently the function supports result objects from the following functions:
<code><a href="#topic+blimp.bayes">blimp.bayes</a></code>, <code><a href="#topic+ci.cor">ci.cor</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>,
<code><a href="#topic+ci.median">ci.median</a></code>, <code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>,
<code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+cor.matrix">cor.matrix</a></code>, <code><a href="#topic+crosstab">crosstab</a></code>,
<code><a href="#topic+descript">descript</a></code>, <code><a href="#topic+dominance.manual">dominance.manual</a></code>, <code><a href="#topic+dominance">dominance</a></code>,
<code><a href="#topic+effsize">effsize</a></code>, <code><a href="#topic+freq">freq</a></code>, <code><a href="#topic+item.alpha">item.alpha</a></code>,
<code><a href="#topic+item.cfa">item.cfa</a></code>, <code><a href="#topic+item.invar">item.invar</a></code>, <code><a href="#topic+item.omega">item.omega</a></code>,
<code><a href="#topic+mplus.bayes">mplus.bayes</a></code>, <code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+multilevel.fit">multilevel.fit</a></code>,
<code><a href="#topic+multilevel.invar">multilevel.invar</a></code>, <code><a href="#topic+multilevel.omega">multilevel.omega</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+result.lca">result.lca</a></code>, <code><a href="#topic+robust.coef">robust.coef</a></code>,
and <code><a href="#topic+std.coef">std.coef</a></code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#----------------------------------------------------------------------------
# Example 1: item.cfa() function

# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

result &lt;- item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")], output = FALSE)
write.result(result, "CFA.xlsx")

#----------------------------------------------------------------------------
# Example 2: multilevel.descript() function

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

result &lt;- multilevel.descript(y1:y3, data = Demo.twolevel, cluster = "cluster",
                              output = FALSE)
write.result(result, "Multilevel_Descript.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='write.sav'>Write SPSS File</h2><span id='topic+write.sav'></span>

<h3>Description</h3>

<p>This function writes a data frame or matrix into a SPSS file by either using the
<code>write_sav()</code> function in the <span class="pkg">haven</span> package by Hadley Wickham and Evan
Miller (2019) or the free software <em>PSPP</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.sav(x, file = "SPSS_Data.sav", var.attr = NULL, pspp.path = NULL,
          digits = 2, write.csv = FALSE, sep = c(";", ","), na = "",
          write.sps = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.sav_+3A_x">x</code></td>
<td>
<p>a matrix or data frame to be written in SPSS, vectors are
coerced to a data frame.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without file extension
'.sav', e.g., <code>"SPSS_Data.sav"</code> or <code>"SPSS_Data"</code>.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_var.attr">var.attr</code></td>
<td>
<p>a matrix or data frame with variable attributes used in the
SPSS file, only 'variable labels' (column name <code>label</code>),
'value labels' column name <code>values</code>, and 'user-missing values'
column name <code>missing</code> are supported (see 'Details').</p>
</td></tr>
<tr><td><code id="write.sav_+3A_pspp.path">pspp.path</code></td>
<td>
<p>a character string indicating the path where the PSPP folder
is located on the computer, e.g.<code>C:/Program Files/PSPP/</code>.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places shown
in the SPSS file for non-integer variables.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_write.csv">write.csv</code></td>
<td>
<p>logical: if <code>TRUE</code>, CSV file is written along with the
SPSS file.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_sep">sep</code></td>
<td>
<p>a character string for specifying the CSV file, either <code>";"</code>
for the separator and <code>"."</code>
for the decimal point (default, i.e. equivalent to <code>write.csv2</code>)
or <code>"."</code> for the decimal point and <code>","</code> for the
separator (i.e. equivalent to <code>write.csv</code>), must be one
of both <code>";"</code> (default) or <code>","</code>.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_na">na</code></td>
<td>
<p>a character string for specifying missing values in the CSV file.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_write.sps">write.sps</code></td>
<td>
<p>logical: if <code>TRUE</code>, SPSS syntax is written along with
the SPSS file when using PSPP.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable attributes specified in the
argument <code>var.attr</code> is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If arguments <code>pspp.path</code> is not specified (i.e., <code>pspp.path = NULL</code>),
<code>write_sav()</code> function in the <span class="pkg">haven</span> is used. Otherwise the object <code>x</code>
is written as CSV file, which is subsequently imported into SPSS using the free
software <em>PSPP</em> by executing a SPSS syntax written in R. Note that <em>PSPP</em>
needs to be installed on your computer when using the <code>pspp.path</code> argument.
</p>
<p>A SPSS file with 'variable labels', 'value labels', and 'user-missing values' is
written by specifying the <code>var.attr</code> argument. Note that the number of rows
in the matrix or data frame specified in <code>var.attr</code> needs to match with the
number of columns in the data frame or matrix specified in <code>x</code>, i.e., each
row in <code>var.attr</code> represents the variable attributes of the corresponding
variable in <code>x</code>. In addition, column names of the matrix or data frame
specified in <code>var.attr</code> needs to be labeled as <code>label</code> for 'variable
labels, <code>values</code> for 'value labels', and <code>missing</code> for 'user-missing
values'.
</p>
<p>Labels for the values are defined in the column <code>values</code> of the matrix or
data frame in <code>var.attr</code> using the equal-sign (e.g., <code>0 = female</code>) and
are separated by a semicolon (e.g., <code>0 = female; 1 = male</code>).
</p>
<p>User-missing values are defined in the column <code>missing</code> of the matrix or
data frame in <code>var.attr</code>, either specifying one user-missing value (e.g.,
<code>-99</code>) or more than one but up to three user-missing values separated
by a semicolon (e.g., <code>-77; -99</code>.
</p>


<h3>Note</h3>

<p>Part of the function using <em>PSPP</em> was adapted from the <code>write.pspp()</code>
function in the <span class="pkg">miceadds</span> package by Alexander Robitzsch, Simon Grund and
Thorsten Henke (2019).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>GNU Project (2018). <em>GNU PSPP for GNU/Linux</em> (Version 1.2.0).
Boston, MA: Free Software Foundation. https://www.gnu.org/software/pspp/
</p>
<p>Wickham H., &amp; Miller, E. (2019). <em>haven: Import and Export 'SPSS', 'Stata'
and 'SAS' Files</em>. R package version 2.2.0.
</p>
<p>Robitzsch, A., Grund, S., &amp; Henke, T. (2019). <em>miceadds: Some additional
multiple imputation functions, especially for mice</em>. R package version 3.4-17.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.sav">read.sav</a></code>, <code><a href="#topic+write.xlsx">write.xlsx</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>,
<code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

dat &lt;- data.frame(id = 1:5,
                  gender = c(NA, 0, 1, 1, 0),
                  age = c(16, 19, 17, NA, 16),
                  status = c(1, 2, 3, 1, 4),
                  score = c(511, 506, 497, 502, 491))

# Example 1: Write SPSS file using the haven package
write.sav(dat, file = "Dataframe_haven.sav")

# Example 2: Write SPSS file using PSPP,
# write CSV file and SPSS syntax along with the SPSS file
write.sav(dat, file = "Dataframe_PSPP.sav", pspp.path = "C:/Program Files/PSPP",
          write.csv = TRUE, write.sps = TRUE)

# Example 3: Specify variable attributes
# Note that it is recommended to manually specify the variables attritbues in a CSV or
# Excel file which is subsequently read into R
attr &lt;- data.frame(# Variable names
                   var = c("id", "gender", "age", "status", "score"),
                   # Variable labels
                   label = c("Identification number", "Gender", "Age in years",
                             "Migration background", "Achievement test score"),
                   # Value labels
                   values = c("", "0 = female; 1 = male", "",
                              "1 = Austria; 2 = former Yugoslavia; 3 = Turkey; 4 = other",
                              ""),
                   # User-missing values
                   missing = c("", "-99", "-99", "-99", "-99"))

# Example 4: Write SPSS file with variable attributes using the haven package
write.sav(dat, file = "Dataframe_haven_Attr.sav", var.attr = attr)

# Example 5: Write SPSS with variable attributes using PSPP
write.sav(dat, file = "Dataframe_PSPP_Attr.sav", var.attr = attr,
          pspp.path = "C:/Program Files/PSPP")

## End(Not run)
</code></pre>

<hr>
<h2 id='write.xlsx'>Write Excel File</h2><span id='topic+write.xlsx'></span>

<h3>Description</h3>

<p>This function calls the <code>write_xlsx()</code> function in the <span class="pkg">writexl</span> package
by Jeroen Ooms to write an Excel file (.xlsx).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.xlsx(x, file = "Excel_Data.xlsx", col.names = TRUE, format = FALSE,
           use.zip64 = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.xlsx_+3A_x">x</code></td>
<td>
<p>a matrix, data frame or (named) list of matrices or data frames
that will be written in the Excel file.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without file extension
'.xlsx', e.g., <code>"My_Excle.xlsx"</code> or <code>"My_Excel"</code>.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_col.names">col.names</code></td>
<td>
<p>logical: if <code>TRUE</code>, column names are written at the top
of the Excel sheet.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_format">format</code></td>
<td>
<p>logical: if <code>TRUE</code>, column names in the Excel file are
centered and bold.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_use.zip64">use.zip64</code></td>
<td>
<p>logical: if <code>TRUE</code>, zip64 to enable support for 4GB+ Excel
files is used.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function supports strings, numbers, booleans, and dates.
</p>


<h3>Note</h3>

<p>The function was adapted from the <code>write_xlsx()</code> function in the <span class="pkg">writexl</span>
package by Jeroen Ooms (2021).
</p>


<h3>Author(s)</h3>

<p>Jeroen Ooms
</p>


<h3>References</h3>

<p>Jeroen O. (2021). <em>writexl: Export Data Frames to Excel 'xlsx' Format</em>.
R package version 1.4.0. https://CRAN.R-project.org/package=writexl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.xlsx">read.xlsx</a></code>, <code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>,
<code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Write Excel file (.xlsx)
write.xlsx(mtcars, file = "mtcars.xlsx")

# Example 2: Write Excel file with multiple sheets (.xlsx)
write.xlsx(list(cars = cars, mtcars = mtcars), file = "Excel_Sheets.xlsx")
## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
