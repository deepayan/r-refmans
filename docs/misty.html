<!DOCTYPE html><html><head><title>Help for package misty</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {misty}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aov.b'><p>Between-Subject Analysis of Variance</p></a></li>
<li><a href='#aov.w'><p>Repeated Measures Analysis of Variance (Within-Subject ANOVA)</p></a></li>
<li><a href='#as.na'><p>Replace User-Specified Values With Missing Values or Missing Values With</p>
User-Specified Values</a></li>
<li><a href='#center'><p>Centering Predictor Variables in Single-Level and Multilevel Data</p></a></li>
<li><a href='#check.collin'><p>Collinearity Diagnostics</p></a></li>
<li><a href='#check.outlier'><p>Statistical Measures for Leverage, Distance, and Influence</p></a></li>
<li><a href='#check.resid'><p>Residual Diagnostics</p></a></li>
<li><a href='#chr.gsub'><p>Multiple Pattern Matching And Replacements</p></a></li>
<li><a href='#chr.omit'><p>Omit Strings</p></a></li>
<li><a href='#chr.trim'><p>Trim Whitespace from String</p></a></li>
<li><a href='#ci.mean'><p>Confidence Interval for the Arithmetic Mean and Median</p></a></li>
<li><a href='#ci.mean.diff'><p>Confidence Interval for the Difference in Arithmetic Means</p></a></li>
<li><a href='#ci.mean.w'><p>Within-Subject Confidence Interval for the Arithmetic Mean</p></a></li>
<li><a href='#ci.prop'><p>Confidence Interval for Proportions</p></a></li>
<li><a href='#ci.prop.diff'><p>Confidence Interval for the Difference in Proportions</p></a></li>
<li><a href='#ci.var'><p>Confidence Interval for the Variance and Standard Deviation</p></a></li>
<li><a href='#cluster.scores'><p>Cluster Scores</p></a></li>
<li><a href='#coding'><p>Coding Categorical Variables</p></a></li>
<li><a href='#cohens.d'><p>Cohen's d</p></a></li>
<li><a href='#cor.matrix'><p>Correlation Matrix</p></a></li>
<li><a href='#crosstab'><p>Cross Tabulation</p></a></li>
<li><a href='#descript'><p>Descriptive Statistics</p></a></li>
<li><a href='#df.duplicated'><p>Extract Duplicated or Unique Rows</p></a></li>
<li><a href='#df.merge'><p>Merge Multiple Data Frames</p></a></li>
<li><a href='#df.move'><p>Move Variable(s) in a Data Frame</p></a></li>
<li><a href='#df.rbind'><p>Combine Data Frames by Rows, Filling in Missing Columns</p></a></li>
<li><a href='#df.rename'><p>Rename Columns in a Matrix or Variables in a Data Frame</p></a></li>
<li><a href='#df.sort'><p>Data Frame Sorting</p></a></li>
<li><a href='#df.subset'><p>Subsetting Data Frames</p></a></li>
<li><a href='#dominance'><p>Dominance Analysis</p></a></li>
<li><a href='#dominance.manual'><p>Dominance Analysis, Manually Inputting a Correlation Matrix</p></a></li>
<li><a href='#effsize'><p>Effect Sizes for Categorical Variables</p></a></li>
<li><a href='#freq'><p>Frequency Table</p></a></li>
<li><a href='#indirect'><p>Confidence Intervals for the Indirect Effect</p></a></li>
<li><a href='#item.alpha'><p>Coefficient Alpha and Item Statistics</p></a></li>
<li><a href='#item.cfa'><p>Confirmatory Factor Analysis</p></a></li>
<li><a href='#item.invar'><p>Between-Group and Longitudinal Measurement Invariance Evaluation</p></a></li>
<li><a href='#item.omega'><p>Coefficient Omega, Hierarchical Omega, and Categorical Omega</p></a></li>
<li><a href='#item.reverse'><p>Reverse Code Scale Item</p></a></li>
<li><a href='#item.scores'><p>Compute Scale Scores</p></a></li>
<li><a href='#lagged'><p>Create Lagged Variables</p></a></li>
<li><a href='#libraries'><p>Load and Attach Multiple Packages</p></a></li>
<li><a href='#mplus.lca'><p>Mplus Model Specification for Latent Class Analysis</p></a></li>
<li><a href='#multilevel.cfa'><p>Multilevel Confirmatory Factor Analysis</p></a></li>
<li><a href='#multilevel.cor'><p>Within-Group and Between-Group Correlation Matrix</p></a></li>
<li><a href='#multilevel.descript'><p>Multilevel Descriptive Statistics for Two-Level and Three-Level Data</p></a></li>
<li><a href='#multilevel.fit'><p>Simultaneous and Level-Specific Multilevel Model Fit Information</p></a></li>
<li><a href='#multilevel.icc'><p>Intraclass Correlation Coefficient, ICC(1) and ICC(2)</p></a></li>
<li><a href='#multilevel.indirect'><p>Confidence Interval for the Indirect Effect in a 1-1-1 Multilevel Mediation Model</p></a></li>
<li><a href='#multilevel.invar'><p>Cross-Level Measurement Invariance Evaluation</p></a></li>
<li><a href='#multilevel.omega'><p>Multilevel Composite Reliability</p></a></li>
<li><a href='#multilevel.r2'><p>R-Squared Measures for Multilevel and Linear Mixed Effects Models</p></a></li>
<li><a href='#multilevel.r2.manual'><p>R-Squared Measures for Multilevel and Linear Mixed Effects Models by Rights</p>
and Sterba (2019), Manually Inputting Parameter Estimates</a></li>
<li><a href='#na.auxiliary'><p>Auxiliary variables analysis</p></a></li>
<li><a href='#na.coverage'><p>Variance-Covariance Coverage</p></a></li>
<li><a href='#na.descript'><p>Descriptive Statistics for Missing Data in Single-Level, Two-Level and Three-Level Data</p></a></li>
<li><a href='#na.indicator'><p>Missing Data Indicator Matrix</p></a></li>
<li><a href='#na.pattern'><p>Missing Data Pattern</p></a></li>
<li><a href='#na.prop'><p>Proportion of Missing Data for Each Case</p></a></li>
<li><a href='#na.test'><p>Little's Missing Completely at Random (MCAR) Test</p></a></li>
<li><a href='#print.misty.object'><p>Print misty.object object</p></a></li>
<li><a href='#read.dta'><p>Read Stata DTA File</p></a></li>
<li><a href='#read.mplus'><p>Read Mplus Data File and Variable Names</p></a></li>
<li><a href='#read.sav'><p>Read SPSS File</p></a></li>
<li><a href='#read.xlsx'><p>Read Excel File</p></a></li>
<li><a href='#rec'><p>Recode Variable</p></a></li>
<li><a href='#restart'><p>Restart R Session</p></a></li>
<li><a href='#result.lca'><p>Summary Result Table and Grouped Bar Charts for Latent Class Analysis Estimated in Mplus</p></a></li>
<li><a href='#robust.coef'><p>Unstandardized Coefficients with Heteroscedasticity-Consistent Standard Errors</p></a></li>
<li><a href='#run.mplus'><p>Run Mplus Models</p></a></li>
<li><a href='#rwg.lindell'><p>Lindell, Brandt and Whitney (1999) r*wg(j) Within-Group Agreement Index for</p>
Multi-Item Scales</a></li>
<li><a href='#script.copy'><p>Save Copy of the Current Script in RStudio</p></a></li>
<li><a href='#script.new'><p>Open new R Script, R Markdown script, or SQL Script in RStudio</p></a></li>
<li><a href='#script.open'><p>Open, Close and Save R Script in RStudio</p></a></li>
<li><a href='#setsource'><p>Set Working Directory to the Source File Location</p></a></li>
<li><a href='#size.cor'><p>Sample Size Determination for Testing Pearson's Correlation Coefficient</p></a></li>
<li><a href='#size.mean'><p>Sample Size Determination for Testing Arithmetic Means</p></a></li>
<li><a href='#size.prop'><p>Sample Size Determination for Testing Proportions</p></a></li>
<li><a href='#skewness'><p>Skewness and Kurtosis</p></a></li>
<li><a href='#std.coef'><p>Standardized Coefficients</p></a></li>
<li><a href='#test.levene'><p>Levene's Test for Homogeneity of Variance</p></a></li>
<li><a href='#test.t'><p>t-Test</p></a></li>
<li><a href='#test.welch'><p>Welch's Test</p></a></li>
<li><a href='#test.z'><p>z-Test</p></a></li>
<li><a href='#write.dta'><p>Write Stata DTA File</p></a></li>
<li><a href='#write.mplus'><p>Write Mplus Data File</p></a></li>
<li><a href='#write.result'><p>Write Results of a misty Object into an Excel file</p></a></li>
<li><a href='#write.sav'><p>Write SPSS File</p></a></li>
<li><a href='#write.xlsx'><p>Write Excel File</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Miscellaneous Functions 'T. Yanagida'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Takuya Yanagida [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Takuya Yanagida &lt;takuya.yanagida@univie.ac.at&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Miscellaneous functions for (1) data management (e.g., grand-mean and group-mean centering, coding variables and reverse coding items, scale and cluster scores, reading and writing Excel and SPSS files), (2) descriptive statistics (e.g., frequency table, cross tabulation, effect size measures), (3) missing data (e.g., descriptive statistics for missing data, missing data pattern, Little's test of Missing Completely at Random, and auxiliary variable analysis), (4) multilevel data (e.g., multilevel descriptive statistics, within-group and between-group correlation matrix, multilevel confirmatory factor analysis, level-specific fit indices, cross-level measurement equivalence evaluation,  multilevel composite reliability, and multilevel R-squared measures), (5) item analysis (e.g., confirmatory factor analysis, coefficient alpha and omega, between-group and longitudinal measurement equivalence evaluation), and (6) statistical analysis (e.g., confidence intervals, collinearity and residual diagnostics, dominance analysis, between- and within-subject analysis of variance, latent class analysis, t-test, z-test, sample size determination).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, haven, lavaan, lme4, nlme, norm, readxl, rstudioapi,
writexl</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Matrix, patchwork, plyr, mnormt</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-05 17:50:48 UTC; takuy</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-05 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aov.b'>Between-Subject Analysis of Variance</h2><span id='topic+aov.b'></span>

<h3>Description</h3>

<p>This function performs an one-way between-subject analysis of variance (ANOVA)
including Tukey HSD post hoc test for multiple comparison and provides descriptive
statistics, effect size measures, and a plot showing error bars for
difference-adjusted confidence intervals with jittered data points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aov.b(formula, data, posthoc = TRUE, conf.level = 0.95, hypo = TRUE,
      descript = TRUE, effsize = FALSE, weighted = FALSE, correct = FALSE,
      plot = FALSE, point.size = 4, adjust = TRUE, error.width = 0.1,
      xlab = NULL, ylab = NULL, ylim = NULL, breaks = ggplot2::waiver(),
      jitter = TRUE, jitter.size = 1.25, jitter.width = 0.05,
      jitter.height = 0, jitter.alpha = 0.1, title = "",
      subtitle = "Confidence Interval", digits = 2, p.digits = 4,
      as.na = NULL, write = NULL, append = TRUE, check = TRUE,
      output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aov.b_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> where <code>y</code> is
a numeric variable giving the data values and <code>group</code>
a numeric variable, character variable or factor with more
than two values or factor levels giving the corresponding
groups.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_posthoc">posthoc</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Tukey HSD post hoc test for
multiple comparison is conducted.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measures <code class="reqn">\eta^2</code>
and <code class="reqn">\omega^2</code> for the ANOVA and Cohen's d for the post
hoc tests are shown on the console.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code>, the weighted pooled standard
deviation is used to compute Cohen's d.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor to remove
positive bias in small samples is used.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing error bars for
confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the confidence intervals is applied.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_error.width">error.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), jittered data points
are drawn.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value indicating the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle for
the plot.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying descriptive statistics and
confidence interval.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="aov.b_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Post Hoc Test</strong></dt><dd><p>Tukey HSD post hoc test reports Cohen's d based
on the non-weighted standard deviation (i.e., <code>weighted = FALSE</code>) when
requesting an effect size measure  (i.e., <code>effsize = TRUE</code>) following the
recommendation by Delacre et al. (2021).
</p>
</dd>
<dt><strong>Confidence Intervals</strong></dt><dd><p>Cumming and Finch (2005) pointed out that
when 95% confidence intervals (CI) for two separately plotted means overlap,
it is still possible that the CI for the difference would not include zero.
Baguley (2012) proposed to adjust the width of the CIs by the factor of
<code class="reqn">\sqrt{2}</code> to reflect the correct width of the CI for a mean difference:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu}_{j} \pm t_{n - 1, 1 - \alpha/2} \frac{\sqrt{2}}{2} \hat{\sigma}_{{\hat{\mu}}_j}</code>
</p>
</dd>
</dl>
<p>These difference-adjusted CIs around the individual means can be interpreted
as if it were a CI for their difference. Note that the width of these intervals
is sensitive to differences in the variance and sample size of each sample,
i.e., unequal population variances and unequal <code class="reqn">n</code> alter the interpretation
of difference-adjusted CIs.

</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame with variables used in the current analysis</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>descript</code> for descriptive
statistics, <code>test</code> for the ANOVA table, <code>posthoc</code>
for post hoc tests, and <code>aov</code> for the return object
of the <code>aov</code> function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Baguley, T. S. (2012a). <em>Serious stats: A guide to advanced statistics for
the behavioral sciences</em>. Palgrave Macmillan.
</p>
<p>Cumming, G., and Finch, S. (2005) Inference by eye: Confidence intervals, and
how to read pictures of data. <em>American Psychologist, 60</em>, 170–80.
</p>
<p>Delacre, M., Lakens, D., Ley, C., Liu, L., &amp; Leys, C. (2021). Why Hedges' g*s
based on the non-pooled standard deviation should be reported with Welch's t-test.
https://doi.org/10.31234/osf.io/tu6mp
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.z">test.z</a></code>,
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>,
<code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(group = c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3),
                  y = c(3, 1, 4, 2, 5, 3, 2, 3, 6, 6, 3, NA))

# Example 1: Between-subject ANOVA
aov.b(y ~ group, data = dat)

# Example 2: Between-subject ANOVA
# print effect size measures
aov.b(y ~ group, data = dat, effsize = TRUE)

# Example 3: Between-subject ANOVA
# do not print hypotheses and descriptive statistics,
aov.b(y ~ group, data = dat, descript = FALSE, hypo = FALSE)

## Not run: 
# Example 4: Write results into a text file
aov.b(y ~ group, data = dat, write = "ANOVA.txt")

# Example 5: Between-subject ANOVA
# plot results
aov.b(y ~ group, data = dat, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Example 6: Save plot, ggsave() from the ggplot2 package
ggsave("Between-Subject_ANOVA.png", dpi = 600, width = 4.5, height = 6)

# Example 7: Between-subject ANOVA
# extract plot
p &lt;- aov.b(y ~ group, data = dat, output = FALSE)$plot
p

# Extract data
plotdat &lt;- aov.b(y ~ group, data = dat, output = FALSE)$data

# Draw plot in line with the default setting of aov.b()
ggplot(plotdat, aes(group, y)) +
  geom_jitter(alpha = 0.1, width = 0.05, height = 0, size = 1.25) +
  geom_point(stat = "summary", fun = "mean", size = 4) +
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.20) +
  scale_x_discrete(name = NULL) +
  labs(subtitle = "Two-Sided 95
  theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5))

## End(Not run)
</code></pre>

<hr>
<h2 id='aov.w'>Repeated Measures Analysis of Variance (Within-Subject ANOVA)</h2><span id='topic+aov.w'></span>

<h3>Description</h3>

<p>This function performs an one-way repeated measures analysis of variance (within
subject ANOVA) including paired-samples t-tests for multiple comparison and
provides descriptive statistics, effect size measures, and a plot showing error
bars for difference-adjusted Cousineau-Morey within-subject confidence intervals
with jittered data points including subject-specific lines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aov.w(formula, data, print = c("all", "none", "LB", "GG", "HF"),
      posthoc = TRUE, conf.level = 0.95,
      p.adj = c("none", "bonferroni", "holm", "hochberg", "hommel", "BH", "BY", "fdr"),
      hypo = TRUE, descript = TRUE, epsilon = TRUE, effsize = FALSE,
      na.omit = TRUE, plot = FALSE, point.size = 4, adjust = TRUE,
      error.width = 0.1, xlab = NULL, ylab = NULL, ylim = NULL,
      breaks = ggplot2::waiver(), jitter = TRUE, line = TRUE,
      jitter.size = 1.25, jitter.width = 0.05, jitter.height = 0,
      jitter.alpha = 0.1, title = "", subtitle = "Confidence Interval",
      digits = 2, p.digits = 4, as.na = NULL, write = NULL, append = TRUE,
      check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aov.w_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>cbind(time1, time2, time3) ~ 1</code>
where <code>time1</code>, <code>time2</code>, and <code>time3</code> are
numeric variables representing the levels of the within-subject
factor, i.e., data are specified in wide-format (i.e.,
multivariate person level format).</p>
</td></tr>
<tr><td><code id="aov.w_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_print">print</code></td>
<td>
<p>a character vector indicating which sphericity correction
to use, i.e., <code>all</code> for all corrections, <code>none</code>
for no correction, <code>LB</code> for lower bound correction,
<code>GG</code> for Greenhouse-Geisser correction, and <code>HF</code>,
for Huynh-Feldt correction.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_posthoc">posthoc</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), paired-samples t-tests for multiple
comparison are conducted.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_p.adj">p.adj</code></td>
<td>
<p>a character string indicating an adjustment method for
multiple testing based on <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>, i.e.,
<code>none</code>, <code>bonferroni</code>, <code>holm</code> (default),
<code>h ochberg</code>, <code>hommel</code>, <code>BH</code>, <code>BY</code>, or
<code>fdr</code>.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_epsilon">epsilon</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), box indices of sphericity (epsilon)
are shown on the console, i.e., lower bound, Greenhouse
and Geiser (GG), Huynh and Feldt (HF) and average of GG
and HF.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measures eta-squared
(<code class="reqn">\eta^2</code>), partial eta-squared (<code class="reqn">\eta^2_p</code>),
omega-squared (<code class="reqn">\omega^2</code>), and partial omega-squared
(<code class="reqn">\omega^2_p</code>) for the repeated measures ANOVA and
Cohen's <em>d</em> for the post hoc tests are shown on
the console.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed
before conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="aov.w_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing error bars for
confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the Cousineau-Morey within-subject confidence
intervals is applied.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_error.width">error.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), jittered data points
are drawn.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), subject-specific lines
are drawn.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value indicating the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle for
the plot.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying descriptive statistics and
confidence interval.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="aov.w_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Sphericity</strong></dt><dd><p>The <em>F</em>-Test of the repeated measures ANOVA
is based on the assumption of sphericity, which is defined as the assumption
that the variance of differences between repeated measures are equal in the
population. The Mauchly's test is commonly used to test this hypothesis.
However, test of assumptions addresses an irrelevant hypothesis because what
matters is the degree of violation rather than its presence (Baguley, 2012a).
Moreover, the test is not recommended because it lacks statistical power (Abdi,
2010). Instead, the Box index of sphericity (<code class="reqn">\varepsilon</code>) should be used to
assess the degree of violation of the sphericity assumption. The <code class="reqn">\varepsilon</code>
parameter indicates the degree to which the population departs from sphericity
with <code class="reqn">\varepsilon = 1</code> indicating that sphericity holds. As the departure
becomes more extreme, <code class="reqn">\varepsilon</code> approaches its lower bound
<code class="reqn">\hat{\varepsilon}_{lb}</code>:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\varepsilon}_{lb} = \frac{1}{J - 1}</code>
</p>

<p>where <code class="reqn">J</code> is the number of levels of the within-subject factor. Box (1954a,
1954b) suggested a measure for sphericity, which applies to a population
covariance matrix. Greenhouse and Geisser (1959) proposed an estimate for
<code class="reqn">\varepsilon</code> known as <code class="reqn">\hat{\varepsilon}_{gg}</code> that can be computed
from the sample covariance matrix, whereas Huynh and Feldt (1976) proposed
an alternative estimate <code class="reqn">\hat{\varepsilon}_{hf}</code>. These estimates can
be used to correct the effect and error <em>df</em> of the <em>F</em>-test.
Simulation studies showed that <code class="reqn">\hat{\varepsilon}_{gg} \leq \hat{\varepsilon}_{hf}</code>
and that <code class="reqn">\hat{\varepsilon}_{gg}</code> tends to be conservative underestimating
<code class="reqn">\varepsilon</code>, whereas <code class="reqn">\hat{\varepsilon}_{hf}</code> tends to be liberal
overestimating <code class="reqn">\varepsilon</code> and occasionally exceeding one. Baguley (2012a)
recommended to compute the average of the conservative estimate <code class="reqn">\hat{\varepsilon}_{gg}</code>
and the liberal estimate <code class="reqn">\hat{\varepsilon}_{hf}</code> to assess the sphericity
assumption.
By default, the function prints results depending on the average
<code class="reqn">\hat{\varepsilon}_{gg}</code> and <code class="reqn">\hat{\varepsilon}_{hf}</code>:
</p>

<ul>
<li><p> If the average is less than 0.75 results of the <em>F</em>-Test based on
Greenhouse-Geiser correction factor (<code class="reqn">\hat{\varepsilon}_{gg}</code>) is printed.
</p>
</li>
<li><p> If the average is less greater or equal 0.75, but less than 0.95
results of the <em>F</em>-Test based on Huynh-Feldt correction factor
(<code class="reqn">\hat{\varepsilon}_{hf}</code>) is printed.
</p>
</li>
<li><p> If the average is greater or equal 0.95 results of the <em>F</em>-Test
without any corrections are printed.
</p>
</li></ul>

</dd>
<dt><strong>Missing Data</strong></dt><dd><p>The function uses listwise deletion by default to
deal with missing data. However, the function also allows to use all available
observations by conducting the repeated measures ANOVA in long data format when
specifying <code>na.omit = FALSE</code>. Note that in the presence of missing data,
the <em>F</em>-Test without any sphericity corrections may be reliable, but it
is not clear whether results based on Greenhouse-Geiser or Huynh-Feldt correction
are trustworthy given that pairwise deletion is used for estimating the
variance-covariance matrix when computing <code class="reqn">\hat{\varepsilon}_{gg}</code> and the total
number of subjects regardless of missing values (i.e., complete and incomplete
cases) are used for computing <code class="reqn">\hat{\varepsilon}_{hf}</code>.
</p>
</dd>
<dt><strong>Within-Subject Confidence Intervals</strong></dt><dd><p>The function provides a
plot showing error bars for difference-adjusted Cousineau-Morey confidence
intervals (Baguley, 2012b). The intervals matches that of a CI for a difference,
i.e., non-overlapping CIs corresponds to an inferences of no statistically
significant difference. The Cousineau-Morey confidence intervals without
adjustment can be used by specifying <code>adjust = FALSE</code>.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the data (<code>data</code>) in wide-format (<code>wide</code>), reshaped data in long-format (<code>long</code>), and within-subject confidence intervals (<code>ci</code>)</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>descript</code> for descriptive
statistics, <code>epsilon</code> for a table with indices of sphericity,
<code>test</code> for the ANOVA table (<code>none</code> for no sphericity
correction, <code>lb</code> for lower bound correction, <code>gg</code>
for Greenhouse and Geiser correction, and <code>hf</code> for
Huynh and Feldt correction), <code>posthoc</code> for post hoc
tests, and <code>aov</code> for the return object of the <code>aov</code>
function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Abdi, H. (2010). The Greenhouse-Geisser correction. In N. J. Salkind (Ed.)
<em>Encyclopedia of Research Design</em> (pp. 630-634), Sage.
https://dx.doi.org/10.4135/9781412961288
</p>
<p>Baguley, T. S. (2012a). <em>Serious stats: A guide to advanced statistics for the
behavioral sciences</em>. Palgrave Macmillan.
</p>
<p>Baguley, T. (2012b). Calculating and graphing within-subject confidence intervals
for ANOVA. <em>Behavior Research Methods, 44</em>, 158-175.
https://doi.org/10.3758/s13428-011-0123-7
</p>
<p>Bakerman, R. (2005). Recommended effect size statistics for repeated measures
designs. <em>Behavior Research Methods</em>, 37, 179-384.
https://doi.org/10.3758/BF03192707
</p>
<p>Box, G. E. P. (1954a) Some Theorems on Quadratic Forms Applied in the Study
of Analysis of Variance Problems, I. Effects of Inequality of Variance in
the One-way Classification. <em>Annals of Mathematical Statistics, 25</em>,
290–302.
</p>
<p>Box, G. E. P. (1954b) Some Theorems on Quadratic Forms Applied in the Study
of Analysis of Variance Problems, II. Effects of Inequality of Variance and
of Correlation between Errors in the Two-way Classification.
<em>Annals of Mathematical Statistics, 25</em>, 484–98.
</p>
<p>Greenhouse, S. W., and Geisser, S. (1959). On methods in the analysis of profile
data.<em>Psychometrika, 24</em>, 95-112. https://doi.org/10.1007/BF02289823
</p>
<p>Huynh, H., and Feldt, L. S. (1976). Estimation of the box correction for degrees
of freedom from sample data in randomized block and splitplot designs.
<em>Journal of Educational Statistics, 1</em>, 69-82.
https://doi.org/10.2307/1164736
</p>
<p>Olejnik, S., &amp; Algina, J. (2000). Measures of effect size for comparative studies:
Applications, interpretations, and limitations. <em>Contemporary Educational
Psychology, 25</em>, 241-286. https://doi.org/10.1006/ceps.2000.1040
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.z">test.z</a></code>,
<code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(time1 = c(3, 2, 1, 4, 5, 2, 3, 5, 6, 7),
                  time2 = c(4, 3, 6, 5, 8, 6, 7, 3, 4, 5),
                  time3 = c(1, 2, 2, 3, 6, 5, 1, 2, 4, 6))

# Example 1: Repeated measures ANOVA
aov.w(cbind(time1, time2, time3) ~ 1, data = dat)

# Example 2: Repeated measures ANOVA
# print results based on all sphericity corrections
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, print = "all")

# Example 3: Repeated measures ANOVA
# print effect size measures
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, effsize = TRUE)

# Example 4: Repeated measures ANOVA
# do not print hypotheses and descriptive statistics,
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, descript = FALSE, hypo = FALSE)

## Not run: 
# Example 5: Write results into a text file
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, write = "RM-ANOVA.txt")

# Example 6: Repeated measures ANOVA
# plot results
aov.w(cbind(time1, time2, time3) ~ 1, data = dat, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("Repeated_measures_ANOVA.png", dpi = 600, width = 4.5, height = 4)

# Example 7: Repeated measures ANOVA
# extract plot
p &lt;- aov.w(cbind(time1, time2, time3) ~ 1, data = dat, output = FALSE)$plot
p

# Extract data
plotdat &lt;- aov.w(cbind(time1, time2, time3) ~ 1, data = dat, output = FALSE)$data

# Draw plot in line with the default setting of aov.w()
ggplot(plotdat$long, aes(time, y, group = 1L)) +
geom_point(aes(time, y, group = id),
          alpha = 0.1, position = position_dodge(0.05)) +
geom_line(aes(time, y, group = id),
         alpha = 0.1, position = position_dodge(0.05)) +
geom_point(data = plotdat$ci, aes(variable, m), stat = "identity", size = 4) +
stat_summary(aes(time, y), fun = mean, geom = "line") +
geom_errorbar(data = plotdat$ci, aes(variable, m, ymin = low, ymax = upp), width = 0.1) +
theme_bw() + xlab(NULL) +
labs(subtitle = "Two-Sided 95
theme(plot.subtitle = element_text(hjust = 0.5),
     plot.title = element_text(hjust = 0.5))

## End(Not run)
</code></pre>

<hr>
<h2 id='as.na'>Replace User-Specified Values With Missing Values or Missing Values With
User-Specified Values</h2><span id='topic+as.na'></span><span id='topic+na.as'></span>

<h3>Description</h3>

<p>The function <code>as.na</code> replaces user-specified values in the argument
<code>na</code> in a vector, factor, matrix, array, list, or data frame with
<code>NA</code>, while the function <code>na.as</code> replaces <code>NA</code> in a vector,
factor, matrix or data frame with user-specified values in the argument
<code>na</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.na(..., data = NULL, na, replace = TRUE, check = TRUE)

na.as(..., data = NULL, na, replace = TRUE, as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.na_+3A_...">...</code></td>
<td>
<p>a vector, factor, matrix, array, data frame, or list.
Alternatively, an expression indicating the variable names in
<code>data</code> e.g., <code>as.na(x1, x2, data = dat)</code>. Note that
the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can be used to select variables, see
'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="as.na_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a vector, factor, matrix, array, data frame,
or list for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="as.na_+3A_na">na</code></td>
<td>
<p>a vector indicating values or characters to replace with
<code>NA</code>, or which <code>NA</code> is replaced.</p>
</td></tr>
<tr><td><code id="as.na_+3A_replace">replace</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable(s) specified in
<code>...</code> are replaced in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="as.na_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
<tr><td><code id="as.na_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector or character vector indicating user-defined
missing values, i.e. these values are converted to <code>NA</code>
before conducting the analysis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector, factor, matrix, array, data frame, or list specified in the
argument <code>...</code> or a data frame specified in <code>data</code> with variables
specified in <code>...</code> replaced.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>,
<code><a href="#topic+na.indicator">na.indicator</a></code>, <code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>,
<code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------------------
# Numeric vector
num &lt;- c(1, 3, 2, 4, 5)

# Example 1: Replace 2 with NA
as.na(num, na = 2)

# Example 2: Replace 2, 3, and 4 with NA
as.na(num, na = c(2, 3, 4))

# Example 3: Replace NA with 2
na.as(c(1, 3, NA, 4, 5), na = 2)

#-------------------------------------------------------------------------------
# Character vector
chr &lt;- c("a", "b", "c", "d", "e")

# Example 4: Replace "b" with NA
as.na(chr, na = "b")

# Example 5: Replace "b", "c", and "d" with NA
as.na(chr, na = c("b", "c", "d"))

# Example 6: Replace NA with "b"
na.as(c("a", NA, "c", "d", "e"), na = "b")

#-------------------------------------------------------------------------------
# Factor
fac &lt;- factor(c("a", "a", "b", "b", "c", "c"))

# Example 7: Replace "b" with NA
as.na(fac, na = "b")

# Example 8: Replace "b" and "c" with NA
as.na(fac, na = c("b", "c"))

# Example 9: Replace NA with "b"
na.as(factor(c("a", "a", NA, NA, "c", "c")), na = "b")

#-------------------------------------------------------------------------------
# Matrix
mat &lt;- matrix(1:20, ncol = 4)

# Example 10: Replace 8 with NA
as.na(mat, na = 8)

# Example 11: Replace 8, 14, and 20 with NA
as.na(mat, na = c(8, 14, 20))

# Example 12: Replace NA with 2
na.as(matrix(c(1, NA, 3, 4, 5, 6), ncol = 2), na = 2)

#-------------------------------------------------------------------------------
# Array

# Example 13: Replace 1 and 10 with NA
as.na(array(1:20, dim = c(2, 3, 2)), na = c(1, 10))

#-------------------------------------------------------------------------------
# List

# Example 14:  Replace 1 with NA
as.na(list(x1 = c(1, 2, 3, 1, 2, 3),
           x2 = c(2, 1, 3, 2, 1),
           x3 = c(3, 1, 2, 3)), na = 1)

#-------------------------------------------------------------------------------
# Data frame
df &lt;- data.frame(x1 = c(1, 2, 3),
                 x2 = c(2, 1, 3),
                 x3 = c(3, 1, 2))

# Example 15a: Replace 1 with NA
as.na(df, na = 1)

# Example 15b: Alternative specification using the 'data' argument
as.na(., data = df, na = 1)

# Example 16: Replace 1 and 3 with NA
as.na(df, na = c(1, 3))

# Example 17a: Replace 1 with NA in 'x2'
as.na(df$x2, na = 1)

# Example 17b: Alternative specification using the 'data' argument
as.na(x2, data = df, na = 1)

# Example 18: Replace 1 with NA in 'x2' and 'x3'
as.na(x2, x3, data = df, na = 1)

# Example 19: Replace 1 with NA in 'x1', 'x2', and 'x3'
as.na(x1:x3, data = df, na = 1)

# Example 20: Replace NA with -99
na.as(data.frame(x1 = c(NA, 2, 3),
                 x2 = c(2, NA, 3),
                 x3 = c(3, NA, 2)), na = -99)

# Example 2: Recode by replacing 30 with NA and then replacing NA with 3
na.as(data.frame(x1 = c(1, 2, 30),
                 x2 = c(2, 1, 30),
                 x3 = c(30, 1, 2)), na = 3, as.na = 30)
</code></pre>

<hr>
<h2 id='center'>Centering Predictor Variables in Single-Level and Multilevel Data</h2><span id='topic+center'></span>

<h3>Description</h3>

<p>This function centers predictor variables in single-level data, two-level
data, and three-level data at the grand mean (CGM, i.e., grand mean centering)
or within cluster (CWC, i.e., group mean centering).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>center(..., data = NULL, cluster = NULL, type = c("CGM", "CWC"),
       cwc.mean = c("L2", "L3"), value = NULL, name = ".c",
       append = TRUE, as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="center_+3A_...">...</code></td>
<td>
<p>a numeric vector for centering a predictor variable, or a
data frame for centering more than one predictor. Alternatively,
an expression indicating the variable names in <code>data</code> e.g.,
<code>center(x1, x2, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="center_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more predictor variables
in the argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector or data frame for the argument
<code>...</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the name of the cluster
variable in <code>...</code> or <code>data</code> for two-level data,
a character vector indicating the names of the cluster
variables in <code>...</code> for three-level data, or a vector
or data frame representing the nested grouping structure
(i.e., group or cluster variables). Alternatively, a
character string or character vector indicating the variable
name(s) of the cluster variable(s) in <code>data</code>. Note that
the cluster variable at Level 3 come first in a three-level
model, i.e., <code>cluster = c("level3", "level2")</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of centering, i.e.,
<code>"CGM"</code> for centering at the grand mean (i.e., grand mean
centering, default when <code>cluster = NULL</code>) or <code>"CWC"</code>
for centering within cluster (i.e., group mean centering, default
when specifying the argument <code>cluster</code>).</p>
</td></tr>
<tr><td><code id="center_+3A_cwc.mean">cwc.mean</code></td>
<td>
<p>a character string indicating the type of centering of a level-1
predictor variable in a three-level model, i.e., <code>L2</code>
(default) for centering the predictor variable at the level-2
cluster means, and  <code>L2</code> for centering the predictor
variable at the level-3 cluster means.</p>
</td></tr>
<tr><td><code id="center_+3A_value">value</code></td>
<td>
<p>a numeric value for centering on a specific user-defined value.
Note that this option is only available when specifying a
single-level predictor variable, i.e., <code>cluster = NULL</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names of
the centered predictor variables. By default, centered predictor
variables are named with the ending <code>".c"</code> resulting in
e.g. <code>"x1.c"</code> and <code>"x2.c"</code>. Variable names can also
be specified by using a character vector matching the number
of variables specified in <code>...</code> (e.g.,
<code>name = c("center.x1", "center.x2")</code>).</p>
</td></tr>
<tr><td><code id="center_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), centered variable(s) are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.
these values are converted to <code>NA</code> before conducting the
analysis. Note that <code>as.na()</code> function is only applied to
<code>...</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="center_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Single-Level Data</strong></dt><dd><p><strong>Predictor variables in single-level
data</strong> can only be centered at the grand mean (CGM) by specifying
<code>type = "CGM"</code>:
</p>
<p style="text-align: center;"><code class="reqn">x_{i} - \bar{x}_{.}</code>
</p>

<p>where <code class="reqn">x_{i}</code> is the predictor value of observation <code class="reqn">i</code> and
<code class="reqn">\bar{x}_{.}</code> is the average <code class="reqn">x</code> score. Note that predictor variables
can be centered on any meaningful value specifying the argument <code>value</code>,
e.g., a predictor variable centered at 5 by applying following formula:
</p>
<p style="text-align: center;"><code class="reqn">x_{i} - \bar{x}_{.} + 5</code>
</p>

<p>resulting in a mean of the centered predictor variable of 5.
</p>
</dd>
<dt><strong>Two-Level Data</strong></dt><dd><p><strong>Level-1 (L1) predictor variables</strong> in
two-level data can be centered at the grand mean (CGM) by specifying
<code>type = "CGM"</code>:
</p>
<p style="text-align: center;"><code class="reqn">x_{ij} - \bar{x}_{..}</code>
</p>

<p>where <code class="reqn">x_{ij}</code> is the predictor value of observation <code class="reqn">i</code> in L2 cluster
<code class="reqn">j</code> and <code class="reqn">\bar{x}_{..}</code> is the average <code class="reqn">x</code> score.
</p>
<p>L1 predictor variables are centered at the group mean (CWC) by specifying
<code>type = "CWC"</code> (Default):
</p>
<p style="text-align: center;"><code class="reqn">x_{ij} - \bar{x}_{.j}</code>
</p>

<p>where <code class="reqn">\bar{x_{.j}}</code> is the average <code class="reqn">x</code> score in cluster <code class="reqn">j</code>.
</p>
<p><strong>Level-2 (L1) predictor variables</strong> in two-level data can only be
centered at the grand mean:
</p>
<p style="text-align: center;"><code class="reqn">x_{.j} - \bar{x}_{..}</code>
</p>

<p>where <code class="reqn">x_{.j}</code> is the predictor value of Level 2 cluster <code class="reqn">j</code> and
<code class="reqn">\bar{x}_{..}</code> is the average Level-2 cluster score. Note that the cluster
membership variable needs to be specified when centering a L2 predictor variable
in two-level data. Otherwise the average <code class="reqn">x_{ij}</code> individual score instead
of the average <code class="reqn">x_{.j}</code> cluster score is used to center the predictor
variable.
</p>
</dd>
<dt><strong>Three-Level Data</strong></dt><dd><p><strong>Level-1 (L1) predictor variables</strong> in
three-level data can be centered at the grand mean (CGM) by specifying
<code>type = "CGM"</code>:
</p>
<p style="text-align: center;"><code class="reqn">x_{ijk} - \bar{x}_{...}</code>
</p>

<p>where <code class="reqn">x_{ijk}</code> is the predictor value of observation <code class="reqn">i</code> in Level-2
cluster <code class="reqn">j</code> within Level-3 cluster <code class="reqn">k</code> and <code class="reqn">\bar{x}_{...}</code> is the average
<code class="reqn">x</code> score.
</p>
<p>L1 predictor variables are centered within cluster (CWC) by specifying
<code>type = "CWC"</code> (Default). However, L1 predictor variables can be either
centered within Level-2 cluster (<code>cwc.mean = "L2"</code>, Default, see Brincks et
al., 2017):
</p>
<p style="text-align: center;"><code class="reqn">x_{ijk} - \bar{x}_{.jk}</code>
</p>

<p>or within Level-3 cluster (<code>cwc.mean = "L3"</code>, see Enders, 2013):
</p>
<p style="text-align: center;"><code class="reqn">x_{ijk} - \bar{x}_{..k}</code>
</p>

<p>where <code class="reqn">\bar{x}_{.jk}</code> is the average <code class="reqn">x</code> score in Level-2 cluster
<code class="reqn">j</code> within Level-3 cluster <code class="reqn">k</code> and <code class="reqn">\bar{x}_{..k}</code> is the average
<code class="reqn">x</code> score in Level-3 cluster <code class="reqn">k</code>.
</p>
<p><strong>Level-2 (L2) predictor variables</strong> in three-level data can be centered
at the grand mean (CGM) by specifying <code>type = "CGM"</code>:
</p>
<p style="text-align: center;"><code class="reqn">x_{.jk} - \bar{x}_{...}</code>
</p>

<p>where <code class="reqn">x_{.jk}</code> is the predictor value of Level-2 cluster <code class="reqn">j</code> within
Level-3 cluster <code class="reqn">k</code> and <code class="reqn">\bar{x}_{...}</code> is the average Level-2 cluster
score.
</p>
<p>L2 predictor variables are centered within cluster (CWC) by specifying
<code>type = "CWC"</code> (Default):
</p>
<p style="text-align: center;"><code class="reqn">x_{.jk} - \bar{x}_{..k}</code>
</p>

<p>where <code class="reqn">\bar{x}_{..k}</code> is the average <code class="reqn">x</code> score in Level-3 cluster
<code class="reqn">k</code>.
</p>
<p><strong>Level-3 (L3) predictor variables</strong> in three-level data can only be
centered at the grand mean:
</p>
<p style="text-align: center;"><code class="reqn">x_{..k} - \bar{x}_{...}</code>
</p>

<p>where <code class="reqn">x_{..k}</code> is the predictor value of Level-3 cluster <code class="reqn">k</code> and
<code class="reqn">\bar{x}_{...}</code> is the average Level-3 cluster score. Note that the cluster
membership variable needs to be specified when centering a L3 predictor variable
in three-level data.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a numeric vector or data frame with the same length or same number of
rows as <code>...</code> containing the centered variable(s).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Brincks, A. M., Enders, C. K., Llabre, M. M., Bulotsky-Shearer, R. J., Prado, G.,
&amp; Feaster, D. J. (2017). Centering predictor variables in three-level contextual
models. <em>Multivariate Behavioral Research, 52</em>(2), 149–163.
https://doi.org/10.1080/00273171.2016.1256753
</p>
<p>Chang, C.-N., &amp; Kwok, O.-M. (2022) Partitioning Variance for a Within-Level
Predictor in Multilevel Models. <em>Structural Equation Modeling: A
Multidisciplinary Journal</em>. Advance online publication.
https://doi.org/10.1080/10705511.2022.2051175
</p>
<p>Enders, C. K. (2013). Centering predictors and contextual effects. In M. A.
Scott, J. S. Simonoff, &amp; B. D. Marx (Eds.), <em>The Sage handbook of
multilevel modeling</em> (pp. 89-109). Sage. https://dx.doi.org/10.4135/9781446247600
</p>
<p>Enders, C. K., &amp; Tofighi, D. (2007). Centering predictor variables in
cross-sectional multilevel models: A new look at an old issue. <em>Psychological
Methods, 12</em>, 121-138. https://doi.org/10.1037/1082-989X.12.2.121
</p>
<p>Rights, J. D., Preacher, K. J., &amp; Cole, D. A. (2020). The danger of conflating
level-specific effects of control variables when primary interest lies in
level-2 effects. <em>British Journal of Mathematical &amp; Statistical Psychology,
73</em>, 194-211. https://doi.org/10.1111/bmsp.12194
</p>
<p>Yaremych, H. E., Preacher, K. J., &amp; Hedeker, D. (2021). Centering categorical
predictors in multilevel models: Best practices and interpretation.
<em>Psychological Methods</em>. Advance online publication.
https://doi.org/10.1037/met0000434
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coding">coding</a></code>, <code><a href="#topic+cluster.scores">cluster.scores</a></code>, <code><a href="#topic+rec">rec</a></code>,
<code><a href="#topic+item.reverse">item.reverse</a></code>, <code><a href="#topic+rwg.lindell">rwg.lindell</a></code>, <code><a href="#topic+item.scores">item.scores</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Predictor Variables in Single-Level Data

# Example 1a: Center predictor 'disp' at the grand mean
center(mtcars$disp)

# Example 1b: Alternative specification using the 'data' argument
center(disp, data = mtcars)

# Example 2a: Center predictors 'disp' and 'hp' at the grabd mean and append to 'mtcars'
cbind(mtcars, center(mtcars[, c("disp", "hp")]))

# Example 2b: Alternative specification using the 'data' argument
center(disp, hp, data = mtcars)

# Example 3: Center predictor 'disp' at the value 3
center(disp, data = mtcars, value = 3)

# Example 4: Center predictors 'disp' and 'hp' and label with the suffix ".v"
center(disp, hp, data = mtcars, name = ".v")

#----------------------------------------------------------------------------
# Predictor Variables in Two-Level Data

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Example 5a: Center L1 predictor 'y1' within cluster
center(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

# Example 5b: Alternative specification using the 'data' argument
center(y1, data = Demo.twolevel, cluster = "cluster")

# Example 6: Center L2 predictor 'w2' at the grand mean
center(w1, data = Demo.twolevel, cluster = "cluster")

# Example 6: Center L1 predictor 'y1' within cluster and L2 predictor 'w1' at the grand mean
center(y1, w1, data = Demo.twolevel, cluster = "cluster")

#----------------------------------------------------------------------------
# Predictor Variables in Three-Level Data

# Create arbitrary three-level data
Demo.threelevel &lt;- data.frame(Demo.twolevel, cluster2 = Demo.twolevel$cluster,
                                             cluster3 = rep(1:10, each = 250))

# Example 7a: Center L1 predictor 'y1' within L2 cluster
center(y1, data = Demo.threelevel, cluster = c("cluster3", "cluster2"))

# Example 7b: Center L1 predictor 'y1' within L3 cluster
center(y1, data = Demo.threelevel, cluster = c("cluster3", "cluster2"), cwc.mean = "L3")

# Example 7b: Center L1 predictor 'y1' within L2 cluster and L2 predictor 'w1' within L3 cluster
center(y1, w1, data = Demo.threelevel, cluster = c("cluster3", "cluster2"))
</code></pre>

<hr>
<h2 id='check.collin'>Collinearity Diagnostics</h2><span id='topic+check.collin'></span>

<h3>Description</h3>

<p>This function computes tolerance, standard error inflation factor, variance inflation
factor, eigenvalues, condition index, and variance proportions for linear, generalized
linear, and mixed-effects models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.collin(model, print = c("all", "vif", "eigen"), digits = 3, p.digits = 3,
             write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.collin_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lm"</code>, <code>"glm"</code>, <code>"lmerMod"</code>,
<code>"lmerModLmerTest"</code>, <code>"glmerMod"</code>, <code>"lme"</code>, or
<code>"glmmTMB"</code>.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e. <code>"all"</code>,
for all results, <code>"vif"</code> for tolerance, std. error inflation
factor, and variance inflation factor, or <code>eigen</code> for eigenvalue,
condition index, and variance proportions.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying results.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="check.collin_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Collinearity diagnostics can be conducted for objects returned from the <code>lm()</code>
and <code>glm()</code> function, but also from objects returned from the <code>lmer()</code>
and <code>glmer()</code> function from the <span class="pkg">lme4</span> package, <code>lme()</code> function
from the <span class="pkg">nlme</span> package, and the <code>glmmTMB()</code> function from the <span class="pkg">glmmTMB</span>
package.
</p>
<p>The generalized variance inflation factor (Fox &amp; Monette, 1992) is computed for
terms with more than 1 df resulting from factors with more than two levels. The
generalized VIF (GVIF) is interpretable as the inflation in size of the confidence
ellipse or ellipsoid for the coefficients of the term in comparison with what would
be obtained for orthogonal data. GVIF is invariant to the coding of the terms in
the model. In order to adjust for the dimension of the confidence ellipsoid,
GVIF<code class="reqn">^\frac{1}{2df}</code> is computed. Note that the adjusted GVIF (aGVIF) is
actually a generalized standard error inflation factor (GSIF). Thus, the aGIF
needs to be squared before applying a common cutoff threshold for the VIF (e.g.,
VIF &gt; 10). Note that the output of <code>check.collin()</code> function reports either
the variance inflation factor or the squared generalized variance inflation factor
in the column <code>VIF</code>, while the standard error inflation factor or the adjusted
generalized variance inflation factor is reported in the column <code>SIF</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in the <code>model</code> argument</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>coef</code> for the regression
table including tolerance, std. error inflation factor and
variance inflation factors, <code>vif</code> for the tolerance,
std. error inflation factor, and variance inflation factor,
and <code>eigen</code> for eigenvalue condition index, and variance
proportion</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The computation of the VIF and the GVIF is based on the <code>vif()</code> function
in the <span class="pkg">car</span> package by John Fox, Sanford Weisberg and Brad Price (2020),
and the computation of eigenvalues, condition index, and variance proportions
is based on the <code>ols_eigen_cindex()</code> function in the <span class="pkg">olsrr</span> package
by Aravind Hebbali (2020).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Fox, J., &amp; Monette, G. (1992). Generalized collinearity diagnostics.
<em>Journal of the American Statistical Association, 87</em>, 178-183.
</p>
<p>Fox, J., Weisberg, S., &amp; Price, B. (2020). <em>car: Companion to Applied
Regression</em>. R package version 3.0-8. https://cran.r-project.org/web/packages/car/
</p>
<p>Hebbali, A. (2020). <em>olsrr: Tools for building OLS regression models</em>.
R package version 0.5.3. https://cran.r-project.org/web/packages/olsrr/
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.outlier">check.outlier</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(group = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4),
                  x1 = c(3, 2, 4, 9, 5, 3, 6, 4, 5, 6, 3, 5),
                  x2 = c(1, 4, 3, 1, 2, 4, 3, 5, 1, 7, 8, 7),
                  x3 = c(7, 3, 4, 2, 5, 6, 4, 2, 3, 5, 2, 8),
                  x4 = c("a", "b", "a", "c", "c", "c", "a", "b", "b", "c", "a", "c"),
                  y1 = c(2, 7, 4, 4, 7, 8, 4, 2, 5, 1, 3, 8),
                  y2 = c(0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1),
                  stringsAsFactors = TRUE)

#-------------------------------------------------------------------------------
# Linear model

# Estimate linear model with continuous predictors
mod.lm1 &lt;- lm(y1 ~ x1 + x2 + x3, data = dat)

# Example 1: Tolerance, std. error, and variance inflation factor
check.collin(mod.lm1)

# Example 2: Tolerance, std. error, and variance inflation factor
# Eigenvalue, Condition index, and variance proportions
check.collin(mod.lm1, print = "all")

# Estimate model with continuous and categorical predictors
mod.lm2 &lt;- lm(y1 ~ x1 + x2 + x3 + x4, data = dat)

# Example 3: Tolerance, generalized std. error, and variance inflation factor
check.collin(mod.lm2)

#-------------------------------------------------------------------------------
# Generalized linear model

# Estimate logistic regression model with continuous predictors
mod.glm &lt;- glm(y2 ~ x1 + x2 + x3, data = dat, family = "binomial")

# Example 4: Tolerance, std. error, and variance inflation factor
check.collin(mod.glm)

## Not run: 
#-------------------------------------------------------------------------------
# Linear mixed-effects model

# Estimate linear mixed-effects model with continuous predictors using lme4 package
mod.lmer &lt;- lme4::lmer(y1 ~ x1 + x2 + x3 + (1|group), data = dat)

# Example 5: Tolerance, std. error, and variance inflation factor
check.collin(mod.lmer)

# Estimate linear mixed-effects model with continuous predictors using nlme package
mod.lme &lt;- nlme::lme(y1 ~ x1 + x2 + x3, random = ~ 1 | group, data = dat)

# Example 6: Tolerance, std. error, and variance inflation factor
check.collin(mod.lme)

# Estimate linear mixed-effects model with continuous predictors using glmmTMB package
mod.glmmTMB1 &lt;- glmmTMB::glmmTMB(y1 ~ x1 + x2 + x3 + (1|group), data = dat)

# Example 7: Tolerance, std. error, and variance inflation factor
check.collin(mod.glmmTMB1)

#-------------------------------------------------------------------------------
# Generalized linear mixed-effects model

# Estimate mixed-effects logistic regression model with continuous predictors using lme4 package
mod.glmer &lt;- lme4::glmer(y2 ~ x1 + x2 + x3 + (1|group), data = dat, family = "binomial")

# Example 8: Tolerance, std. error, and variance inflation factor
check.collin(mod.glmer)

# Estimate mixed-effects logistic regression model with continuous predictors using glmmTMB package
mod.glmmTMB2 &lt;- glmmTMB::glmmTMB(y2 ~ x1 + x2 + x3 + (1|group), data = dat, family = "binomial")

# Example 9: Tolerance, std. error, and variance inflation factor
check.collin(mod.glmmTMB2)

#----------------------------------------------------------------------------
# Write Results

# Example 10: Write results into a text file
check.collin(mod.lm1, write = "Diagnostics.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='check.outlier'>Statistical Measures for Leverage, Distance, and Influence</h2><span id='topic+check.outlier'></span>

<h3>Description</h3>

<p>This function computes statistical measures for leverage, distance, and
influence for linear models estimated by using the <code>lm()</code> function.
Mahalanobis distance and hat values are computed for quantifying
<em>leverage</em>, standardized leverage-corrected residuals and
studentized leverage-corrected residuals are computed for quantifying
<em>distance</em>, and Cook's distance and DfBetas are computed
for quantifying <em>influence</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.outlier(model, check = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.outlier_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lm"</code>.</p>
</td></tr>
<tr><td><code id="check.outlier_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="check.outlier_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In regression analysis, an observation can be extreme in three major ways (see
Darlington &amp; Hayes, p. 484): (1) An observation has high <strong>leverage</strong> if it
has a atypical pattern of values on the predictors, (2) an observation has high
<strong>distance</strong> if its observed outcome value <code class="reqn">Y_i</code> has a large deviation
from the predicted value <code class="reqn">\hat{Y}_i</code>, and (3) an observation has high
<strong>influence</strong> if its inclusion substantially changes the estimates for the
intercept and/or slopes.
</p>


<h3>Value</h3>

<p>Returns a data frame with following entries:
</p>
<table>
<tr><td><code>idout</code></td>
<td>
<p>ID variable</p>
</td></tr>
<tr><td><code>mahal</code></td>
<td>
<p>Mahalanobis distance</p>
</td></tr>
<tr><td><code>hat</code></td>
<td>
<p>hat values</p>
</td></tr>
<tr><td><code>rstand</code></td>
<td>
<p>standardized leverage-corrected residuals</p>
</td></tr>
<tr><td><code>rstud</code></td>
<td>
<p>studentized leverage-corrected residuals</p>
</td></tr>
<tr><td><code>cook</code></td>
<td>
<p>Cook's distance</p>
</td></tr>
<tr><td><code>Intercept.dfb</code></td>
<td>
<p>DFBetas for the intercept</p>
</td></tr>
<tr><td><code>pred1.dfb</code></td>
<td>
<p>DFBetas for the slope of the predictor pred1</p>
</td></tr>
<tr><td><code>....dfb</code></td>
<td>
<p>DFBetas for the slope of the predictor ...</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Darlington, R. B., &amp;, Hayes, A. F. (2017). <em>Regression analysis and linear
models</em>: Concepts, applications, and implementation. The Guilford Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.collin">check.collin</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Regression model and measures for leverage, distance, and influence
mod.lm &lt;- lm(mpg ~ cyl + disp + hp, data = mtcars)
check.outlier(mod.lm)

# Merge result table with the data
dat1 &lt;- cbind(mtcars, check.outlier(mod.lm))
</code></pre>

<hr>
<h2 id='check.resid'>Residual Diagnostics</h2><span id='topic+check.resid'></span>

<h3>Description</h3>

<p>This function performs residual diagnostics for linear models estimated by
using the <code>lm()</code> function for detecting nonlinearity (partial residual or
component-plus-residual plots), nonconstant error variance (predicted values
vs. residuals plot), and non-normality of residuals (Q-Q plot and histogram
with density plot).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.resid(model, type = c("linear", "homo", "normal"),
            resid = c("unstand", "stand", "student"),
            point.shape = 21, point.fill = "gray80", point.size = 1,
            line1 = TRUE, line2 = TRUE,
            line.type1 = "solid", line.type2 = "dashed",
            line.width1 = 1, line.width2 = 1,
            line.color1 = "#0072B2", line.color2 = "#D55E00",
            bar.width = NULL, bar.n = 30, bar.color = "black",
            bar.fill = "gray95", strip.size = 11,
            label.size = 10, axis.size = 10,
            xlimits = NULL, ylimits = NULL,
            xbreaks = ggplot2::waiver(), ybreaks = ggplot2::waiver(),
            check = TRUE, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.resid_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>lm</code>.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_type">type</code></td>
<td>
<p>a character string specifying the type of the plot, i.e.,
<code>"linear"</code> for partial (component-plus-residual) plots,
<code>"homo"</code> (default) for predicted values vs. residuals
plot, and <code>"normal"</code> for Q-Q plot and histogram with
a density plot. Note that partial plots are not available
for models with interaction terms.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_resid">resid</code></td>
<td>
<p>a character string specifying the type of residual used for
the partial (component-plus-residual) plots or Q-Q plot and
histogram, i.e., <code>"unstand"</code> for unstandardized residuals
<code>"stand"</code> for standardized residuals, and <code>"student"</code>
for studentized residual. By default, studentized residuals
are used for predicted values vs. residuals plot and unstandardized
residuals are used for Q-Q plot and histogram.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_point.shape">point.shape</code></td>
<td>
<p>a numeric value for specifying the argument <code>shape</code>
in the <code>geom_point</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_point.fill">point.fill</code></td>
<td>
<p>a numeric value for specifying the argument <code>fill</code>
in the <code>geom_point</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value for specifying the argument <code>size</code>
in the <code>geom_point</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line1">line1</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), regression line is drawn
in the partial (component-plus-residual) plots, horizontal
line is drawn in the predicted values vs. residuals plot,
and t-distribution or normal distribution curve is drawn in
the histogram.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line2">line2</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Loess smooth line is drawn
in the partial (component-plus-residual) plots, loess mooth
lines are drawn in the predicted values vs. residuals plot,
and density curve is drawn in the histogram.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line.type1">line.type1</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>linetype</code> in the <code>geom_smooth</code>, <code>geom_hline</code>,
or <code>stat_function</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line.type2">line.type2</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>linetype</code> in the <code>geom_smooth</code> or <code>geom_density</code>
function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line.width1">line.width1</code></td>
<td>
<p>a numeric value for specifying the argument <code>linewidth</code>
in the <code>geom_smooth</code>, <code>geom_hline</code>, or <code>stat_function</code>
function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line.width2">line.width2</code></td>
<td>
<p>a numeric value for specifying the argument <code>linewidth</code>
in the <code>geom_smooth</code> or <code>geom_density</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line.color1">line.color1</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>color</code> in the <code>geom_smooth</code>, <code>geom_hline</code>,
or <code>stat_function</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_line.color2">line.color2</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>color</code> in the <code>geom_smooth</code> or <code>geom_density</code>
function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_bar.width">bar.width</code></td>
<td>
<p>a numeric value for specifying the argument <code>bins</code> in
the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_bar.n">bar.n</code></td>
<td>
<p>a numeric value for specifying the argument <code>bins</code> in
the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_bar.color">bar.color</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>color</code> in the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_bar.fill">bar.fill</code></td>
<td>
<p>a character string or numeric value for specifying the argument
<code>fill</code> in the <code>geom_bar</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_strip.size">strip.size</code></td>
<td>
<p>a numeric value for specifying the argument <code>size</code> in
the <code>element_text</code> function of the <code>strip.text</code>
argument within the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_label.size">label.size</code></td>
<td>
<p>a numeric value for specifying the argument <code>size</code> in
the <code>element_text</code> function of the <code>axis.title</code>
argument within the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_axis.size">axis.size</code></td>
<td>
<p>a numeric value for specifying the argument <code>size</code> in
the <code>element_text</code> function of the <code>axis.text </code>
argument within the <code>theme</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_xlimits">xlimits</code></td>
<td>
<p>a numeric value for specifying the argument <code>limits</code>
in the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_ylimits">ylimits</code></td>
<td>
<p>a numeric value for specifying the argument <code>limits</code>
in the <code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_xbreaks">xbreaks</code></td>
<td>
<p>a numeric value for specifying the argument <code>breaks </code>
in the <code>scale_x_continuous</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_ybreaks">ybreaks</code></td>
<td>
<p>a numeric value for specifying the argument <code>breaks </code>
in the <code>scale_y_continuous</code> function.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="check.resid_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a plot is drawn.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Nonlinearity</strong></dt><dd><p>The violation of the assumption of linearity
implies that the model cannot accurately capture the systematic pattern of the
relationship between the outcome and predictor variables. In other words, the
specified regression surface does not accurately represent the relationship
between the conditional mean values of <code class="reqn">Y</code> and the <code class="reqn">X</code>s. That means
the average error <code class="reqn">E(\varepsilon)</code> is not 0 at every point on the regression
surface (Fox, 2015).
</p>
<p>In multiple regression, plotting the outcome variable <code class="reqn">Y</code> against each predictor
variable <code class="reqn">X</code> can be misleading because it does not reflect the partial
relationship between <code class="reqn">Y</code> and <code class="reqn">X</code> (i.e., statistically controlling for
the other <code class="reqn">X</code>s), but rather the marginal relationship between <code class="reqn">Y</code> and
<code class="reqn">X</code> (i.e., ignoring the other <code class="reqn">X</code>s). Partial residual plots or
component-plus-residual plots should be used to detect nonlinearity in multiple
regression. The partial residual for the <code class="reqn">j</code>th predictor variable is defined
as
</p>
<p style="text-align: center;"><code class="reqn">e_i^{(j)} = b_jX_{ij} + e_i</code>
</p>

<p>The linear component of the partial relationship between <code class="reqn">Y</code> and <code class="reqn">X_j</code>
is added back to the least-squares residuals, which may include an unmodeled
nonlinear component. Then, the partial residual <code class="reqn">e_i^{(j)}</code> is plotted
against the predictor variable <code class="reqn">X_j</code>. Nonlinearity may become apparent when
a non-parametric regression smoother is applied.
</p>
<p>By default, the function plots
each predictor against the partial residuals, and draws the linear regression
and the loess smooth line to the partial residual plots.</p>
</dd>
<dt><strong>Nonconstant Error Variance</strong></dt><dd><p>The violation of the assumption of
constant error variance, often referred to as heteroscedasticity, implies that
the variance of the outcome variable around the regression surface is not the
same at every point on the regression surface (Fox, 2015).
</p>
<p>Plotting residuals against the outcome variable <code class="reqn">Y</code> instead of the predicted
values <code class="reqn">\hat{Y}</code> is not recommended because <code class="reqn">Y = \hat{Y} + e</code>. Consequently,
the linear correlation between the outcome variable <code class="reqn">Y</code> and the residuals
<code class="reqn">e</code> is <code class="reqn">\sqrt{1 - R^2}</code> where <code class="reqn">R</code> is the multiple correlation coefficient.
In contrast, plotting residuals against the predicted values <code class="reqn">\hat{Y}</code> is
much easier to examine for evidence of nonconstant error variance as the correlation
between <code class="reqn">\hat{Y}</code> and <code class="reqn">e</code> is 0. Note that the least-squares residuals
generally have unequal variance <code class="reqn">Var(e_i) = \sigma^2 / (1 - h_i)</code> where
<code class="reqn">h</code> is the leverage of observation <code class="reqn">i</code>, even if errors have constant
variance <code class="reqn">\sigma^2</code>. The studentized residuals <code class="reqn">e^*_i</code>, however, have
a constant variance under the assumption of the regression model. Residuals
are studentized by dividing them by <code class="reqn">\sigma^2_i(\sqrt{(1 - h_i)}</code> where
<code class="reqn">\sigma^2_i</code> is the estimate of <code class="reqn">\sigma^2</code> obtained after deleting the
<code class="reqn">i</code>th observation, and <code class="reqn">h_i</code> is the leverage of observation <code class="reqn">i</code>
(Meuleman et al, 2015).
</p>
<p>By default, the function plots the predicted values
against the studentized residuals. It also draws a horizontal line at 0, a
loess smooth lines for all residuals as well as separate loess smooth lines
for positive and negative residuals.</p>
</dd>
<dt><strong>Non-normality of Residuals</strong></dt><dd><p>Statistical inference under the
violation of the assumption of normally distributed errors is approximately
valid in all but small samples. However, the efficiency of least squares is
not robust because the least-squares estimator is the most efficient and
unbiased estimator only when the errors are normally distributed. For instance,
when error distributions have heavy tails, the least-squares estimator becomes
much less efficient compared to robust estimators. In addition, error distributions with
heavy-tails result in outliers and compromise the interpretation of conditional
means because the mean is not an accurate measure of central tendency in a highly
skewed distribution. Moreover, a multimodal error distribution suggests the omission
of one or more discrete explanatory variables that naturally divide the data
into groups (Fox, 2016).
</p>
<p>By default, the function plots a Q-Q plot of the unstandardized residuals, and
a histogram of the unstandardized residuals and a density plot. Note that
studentized residuals follow a <code class="reqn">t</code>-distribution with <code class="reqn">n - k - 2</code> degrees
of freedom where <code class="reqn">n</code> is the sample size and <code class="reqn">k</code> is the number of predictors.
However, the normal and <code class="reqn">t</code>-distribution are nearly identical unless the
sample size is small. Moreover, even if the model is correct, the studentized
residuals are not an independent random sample from <code class="reqn">t_{n - k - 2}</code>. Residuals
are correlated with each other depending on the configuration of the predictor
values. The correlation is generally negligible unless the sample size is small.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in <code>model</code></p>
</td></tr>
<tr><td><code>plotdat</code></td>
<td>
<p>data frame used for the plot</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the residuals</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Fox, J. (2016). <em>Applied regression analysis and generalized linear models</em>
(3rd ed.). Sage Publications, Inc.
</p>
<p>Meuleman, B., Loosveldt, G., &amp; Emonds, V. (2015). Regression analysis: Assumptions
and diagnostics. In H. Best &amp; C. Wolf (Eds.), <em>The SAGE handbook of regression analysis and causal inference (pp. 83-110)</em>.
Sage.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check.collin">check.collin</a></code>, <code><a href="#topic+check.outlier">check.outlier</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#-------------------------------------------------------------------------------
# Residual diagnostics for a linear model

mod &lt;- lm(Ozone ~ Solar.R + Wind + Temp, data = airquality)

# Example 1: Partial (component-plus-residual) plots
check.resid(mod, type = "linear")

# Example 2: Predicted values vs. residuals plot
check.resid(mod, type = "homo")

# Example 3: Q-Q plot and histogram with density plot
check.resid(mod, type = "normal")

#-------------------------------------------------------------------------------
# Extract data and ggplot2 object

object &lt;- check.resid(mod, type = "linear", plot = FALSE)

# Data frame
object$plotdat

# ggplot object
object$plot

## End(Not run)
</code></pre>

<hr>
<h2 id='chr.gsub'>Multiple Pattern Matching And Replacements</h2><span id='topic+chr.gsub'></span>

<h3>Description</h3>

<p>This function is a multiple global string replacement wrapper that allows access
to multiple methods of specifying matches and replacements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.gsub(pattern, replacement, x, recycle = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chr.gsub_+3A_pattern">pattern</code></td>
<td>
<p>a character vector with character strings to be matched.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_replacement">replacement</code></td>
<td>
<p>a character vector equal in length to <code>pattern</code> or of
length one which are a replacement for matched patterns.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_x">x</code></td>
<td>
<p>a character vector where matches and replacements are sought.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_recycle">recycle</code></td>
<td>
<p>logical: if <code>TRUE</code>, replacement is recycled if lengths differ.</p>
</td></tr>
<tr><td><code id="chr.gsub_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to the <code>regexpr</code> or <code>sub</code>
function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return a character vector of the same length and with the same attributes as
<code>x</code> (after possible coercion to character).
</p>


<h3>Note</h3>

<p>This function was adapted from the <code>mgsub()</code> function in the <span class="pkg">mgsub</span>
package by Mark Ewing (2019).
</p>


<h3>Author(s)</h3>

<p>Mark Ewing
</p>


<h3>References</h3>

<p>Mark Ewing (2019). <em>mgsub: Safe, Multiple, Simultaneous String Substitution</em>.
R package version 1.7.1. https://CRAN.R-project.org/package=mgsub
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.omit">chr.omit</a></code>, <code><a href="#topic+chr.trim">chr.trim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
string &lt;- c("hey ho, let's go!")
chr.gsub(c("hey", "ho"), c("ho", "hey"), string)

# Example 2
string &lt;- "they don't understand the value of what they seek."
chr.gsub(c("the", "they"), c("a", "we"), string)

# Example 3
string &lt;- c("hey ho, let's go!")
chr.gsub(c("hey", "ho"), "yo", string, recycle = TRUE)

# Example 4
string &lt;- "Dopazamine is not the same as dopachloride or dopastriamine, yet is still fake."
chr.gsub(c("[Dd]opa([^ ]*?mine)","fake"), c("Meta\\1","real"), string)
</code></pre>

<hr>
<h2 id='chr.omit'>Omit Strings</h2><span id='topic+chr.omit'></span>

<h3>Description</h3>

<p>This function omits user-specified values or strings from a numeric vector,
character vector or factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.omit(x, omit = "", na.omit = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chr.omit_+3A_x">x</code></td>
<td>
<p>a numeric vector, character vector or factor.</p>
</td></tr>
<tr><td><code id="chr.omit_+3A_omit">omit</code></td>
<td>
<p>a numeric vector or character vector indicating values or
strings to be omitted
from the vector <code>x</code>, the default setting is the empty
strings <code>""</code>.</p>
</td></tr>
<tr><td><code id="chr.omit_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, missing values (<code>NA</code>) are also
omitted from the vector.</p>
</td></tr>
<tr><td><code id="chr.omit_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector, character vector or factor with values or strings
specified in <code>omit</code> omitted from the vector specified in <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.gsub">chr.gsub</a></code>, <code><a href="#topic+chr.trim">chr.trim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------------------
# Charater vector
x.chr &lt;- c("a", "", "c", NA, "", "d", "e", NA)

# Example 1: Omit character string ""
chr.omit(x.chr)

# Example 2: Omit character string "" and missing values (NA)
chr.omit(x.chr, na.omit = TRUE)

# Example 3: Omit character string "c" and "e"
chr.omit(x.chr, omit = c("c", "e"))

# Example 4: Omit character string "c", "e", and missing values (NA)
chr.omit(x.chr, omit = c("c", "e"), na.omit = TRUE)

#-------------------------------------------------------------------------------
# Numeric vector
x.num &lt;- c(1, 2, NA, 3, 4, 5, NA)

# Example 5: Omit values 2 and 4
chr.omit(x.num, omit = c(2, 4))

# Example 6: Omit values 2, 4, and missing values (NA)
chr.omit(x.num, omit = c(2, 4), na.omit = TRUE)

#-------------------------------------------------------------------------------
# Factor
x.factor &lt;- factor(letters[1:10])

# Example 7: Omit factor levels "a", "c", "e", and "g"
chr.omit(x.factor, omit = c("a", "c", "e", "g"))
</code></pre>

<hr>
<h2 id='chr.trim'>Trim Whitespace from String</h2><span id='topic+chr.trim'></span>

<h3>Description</h3>

<p>This function removes whitespace from start and/or end of a string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chr.trim(x, side = c("both", "left", "right"), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chr.trim_+3A_x">x</code></td>
<td>
<p>a character vector.</p>
</td></tr>
<tr><td><code id="chr.trim_+3A_side">side</code></td>
<td>
<p>a character string indicating the side on which to remove whitespace,
i.e., <code>"both"</code> (default), <code>"left"</code> or <code>"right"</code>.</p>
</td></tr>
<tr><td><code id="chr.trim_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector with whitespaces removed from the vector specified
in <code>x</code>.
</p>


<h3>Note</h3>

<p>This function is based on the <code>str_trim()</code> function from the <span class="pkg">stringr</span>
package by Hadley Wickham.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Wickham, H. (2019). <em>stringr: Simple, consistent wrappers for common string
operations</em>.
R package version 1.4.0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chr.gsub">chr.gsub</a></code>, <code><a href="#topic+chr.omit">chr.omit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- "  string  "

# Example 1: Remove whitespace at both sides
chr.trim(x)

# Example 2: Remove whitespace at the left side
chr.trim(x, side = "left")

# Example 3: Remove whitespace at the right side
chr.trim(x, side = "right")
</code></pre>

<hr>
<h2 id='ci.mean'>Confidence Interval for the Arithmetic Mean and Median</h2><span id='topic+ci.mean'></span><span id='topic+ci.median'></span>

<h3>Description</h3>

<p>The function <code>ci.mean</code> computes a confidence interval for the arithmetic
mean with known or unknown population standard deviation or population variance
and the function <code>ci.median</code> computes the confidence interval for the
median for one or more variables, optionally by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.mean(..., data = NULL, sigma = NULL, sigma2 = NULL, adjust = FALSE,
        alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
        group = NULL, split = NULL, sort.var = FALSE, na.omit = FALSE,
        digits = 2, as.na = NULL, write = NULL, append = TRUE,
        check = TRUE, output = TRUE)

ci.median(..., data = NULL, alternative = c("two.sided", "less", "greater"),
          conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
          na.omit = FALSE, digits = 2, as.na = NULL, write = NULL, append = TRUE,
          check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.mean_+3A_...">...</code></td>
<td>
<p>a numeric vector, matrix or data frame with numeric variables,
i.e., factors and character variables are excluded from <code>x</code>
before conducting the analysis. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>ci.mean(x1, x2, data = dat)</code>. Note that
the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables, see
'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector, matrix or data frame
for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_sigma">sigma</code></td>
<td>
<p>a numeric vector indicating the population standard deviation when computing confidence
intervals for the arithmetic mean with known standard deviation Note that either argument
<code>sigma</code> or argument <code>sigma2</code> is specified and it is only possible to specify one
value for the argument <code>sigma</code> even though multiple variables are specified in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_sigma2">sigma2</code></td>
<td>
<p>a numeric vector indicating the population variance when computing confidence intervals
for the arithmetic mean with known variance. Note that either argument <code>sigma</code>
or argument <code>sigma2</code> is specified and it is only possible to specify one value for the
argument <code>sigma2</code> even though multiple variables are specified in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment for the
confidence intervals for the arithmetic means is applied.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of
<code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level of the interval.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name of
the grouping variable in <code>...</code> or <code>data</code>, or a vector
representing the grouping variable. Note that a grouping
variable can only be used when computing confidence intervals
with unknown population standard deviation and population
variance.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_split">split</code></td>
<td>
<p>either a character string indicating the variable name of
the split variable in <code>...</code> or <code>data</code>, or a vector
representing the split variable. Note that a grouping
variable can only be used when computing confidence intervals
with unknown population standard deviation and population
variance.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before conducting the analysis
(i.e., listwise deletion) when specifying more than one outcome variable.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting the analysis.
Note that <code>as.na()</code> function is only applied to <code>x</code>, but
not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.mean_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A difference-adjusted confidence interval (Baguley, 2012) for the arithmetic
mean can be computed by specifying <code>adjust = TRUE</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>...</code>, <code>data</code>,                           <code>group</code>, and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Baguley, T. S. (2012). <em>Serious stats: A guide to advanced statistics for
the behavioral sciences</em>. Palgrave Macmillan.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>,
<code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Two-Sided 95% Confidence Interval for the Arithmetic Mean for 'mpg'
ci.mean(mtcars$mpg)

# Example 1b: Alternative specification using the 'data' argument
ci.mean(mpg, data = mtcars)

# Example 2: Two-Sided 95% Confidence Interval for the Median
ci.median(mtcars$mpg)

# Example 3: Two-Sided 95% Difference-Adjusted Confidence Interval
ci.mean(mtcars$mpg, adjust = TRUE)

# Example 4: Two-Sided 95% Confidence Interval with known standard deviation
ci.mean(mtcars$mpg, sigma = 1.2)

# Example 5: Two-Sided 95% Confidence Interval with known variance
ci.mean(mtcars$mpg, sigma2 = 2.5)

# Example 6: One-Sided 95% Confidence Interval
ci.mean(mtcars$mpg, alternative = "less")

# Example 7: Two-Sided 99% Confidence Interval
ci.mean(mtcars$mpg, conf.level = 0.99)

# Example 8: Two-Sided 95% Confidence Interval, print results with 3 digits
ci.mean(mtcars$mpg, digits = 3)

# Example 9a: Two-Sided 95% Confidence Interval for 'mpg', 'cyl', and 'disp',
# listwise deletion for missing data
ci.mean(mtcars[, c("mpg", "cyl", "disp")], na.omit = TRUE)
#
# Example 9b: Alternative specification using the 'data' argument
ci.mean(mpg:disp, data = mtcars, na.omit = TRUE)

# Example 10a: Two-Sided 95% Confidence Interval, analysis by 'vs' separately
ci.mean(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs)

# Example 10b: Alternative specification using the 'data' argument
ci.mean(mpg:disp, data = mtcars, group = "vs")

# Example 11: Two-Sided 95% Confidence Interval, analysis by 'vs' separately,
# sort by variables
ci.mean(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs, sort.var = TRUE)

# Example 12: Two-Sided 95% Confidence Interval, split analysis by 'am'
ci.mean(mtcars[, c("mpg", "cyl", "disp")], split = mtcars$am)

# Example 13a: Two-Sided 95% Confidence Interval for 'mpg', 'cyl', and 'disp'
# analysis by 'vs' separately, split analysis by 'am'
ci.mean(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs, split = mtcars$am)

# Example 13b: Alternative specification using the 'data' argument
ci.mean(mpg:disp, data = mtcars, group = "vs", split = "am")

## Not run: 
# Example 14: Write results into a text file
ci.mean(mpg:disp, data = mtcars, group = "vs", split = "am", write = "Means.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='ci.mean.diff'>Confidence Interval for the Difference in Arithmetic Means</h2><span id='topic+ci.mean.diff'></span><span id='topic+ci.mean.diff.default'></span><span id='topic+ci.mean.diff.formula'></span>

<h3>Description</h3>

<p>This function computes a confidence interval for the difference in arithmetic
means in a one-sample, two-sample and paired-sample design with known or unknown
population standard deviation or population variance for one or more variables,
optionally by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.mean.diff(x, ...)

## Default S3 method:
ci.mean.diff(x, y, mu = 0, sigma = NULL, sigma2 = NULL,
             var.equal = FALSE, paired = FALSE,
             alternative = c("two.sided", "less", "greater"),
             conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
             digits = 2, as.na = NULL, write = NULL, append = TRUE,
             check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
ci.mean.diff(formula, data, sigma = NULL, sigma2 = NULL,
             var.equal = FALSE, alternative = c("two.sided", "less", "greater"),
             conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
             na.omit = FALSE, digits = 2, as.na = NULL, write = NULL, append = TRUE,
             check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.mean.diff_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_y">y</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_mu">mu</code></td>
<td>
<p>a numeric value indicating the population mean under the
null hypothesis. Note that the argument <code>mu</code> is only
used when <code>y = NULL</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_sigma">sigma</code></td>
<td>
<p>a numeric vector indicating the population standard deviation(s)
when computing confidence intervals for the difference in
arithmetic means with known standard deviation(s). In case
of independent samples, equal standard deviations are assumed
when specifying one value for the argument <code>sigma</code>; when
specifying two values for the argument <code>sigma</code>, unequal
standard deviations are assumed. Note that either argument
<code>sigma</code> or argument <code>sigma2</code> is specified and it
is only possible to specify one value (i.e., equal variance
assumption) or two values (i.e., unequal variance assumption)
for the argument <code>sigma</code> even though multiple variables
are specified in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_sigma2">sigma2</code></td>
<td>
<p>a numeric vector indicating the population variance(s) when
computing confidence intervals for the difference in arithmetic
means with known variance(s). In case of independent samples,
equal variances are assumed when specifying one value for the
argument <code>sigma2</code>; when specifying two values for the
argument <code>sigma</code>, unequal variances are assumed. Note
that either argument <code>sigma</code> or argument <code>sigma2</code>
is specified and it is only possible to specify one value
(i.e., equal variance assumption) or two values (i.e., unequal
variance assumption) for the argument <code>sigma</code> even though
multiple variables are specified in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_var.equal">var.equal</code></td>
<td>
<p>logical: if <code>TRUE</code>, the population variance in the
independent samples are assumed to be equal.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, confidence interval for the difference
of arithmetic means in paired samples is computed.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_group">group</code></td>
<td>
<p>a numeric vector, character vector or factor as grouping
variable. Note that a grouping variable can only be used
when computing confidence intervals with unknown population
standard deviation and population variance.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_split">split</code></td>
<td>
<p>a numeric vector, character vector or factor as split variable.
Note that a split variable can only be used when computing
confidence intervals with unknown population</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables
when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied
to <code>x</code>, but not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> for one outcome variable
or <code>cbind(y1, y2, y3) ~ group</code> for more than one outcome
variable where <code>y</code> is a numeric variable giving the data
values and <code>group</code> a numeric variable, character variable
or factor with two values or factor levels giving the corresponding
groups.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the formula
<code>formula</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.diff_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion) when specifying
more than one outcome variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>x</code>, <code>group</code>,
and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>,
<code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat1 &lt;- data.frame(group1 = c(1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,
                              1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2),
                   group2 = c(1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2,
                              1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2),
                   group3 = c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
                              1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2),
                   x1 = c(3, 1, 4, 2, 5, 3, 2, 3, 6, 4, 3, NA, 5, 3,
                          3, 2, 6, 3, 1, 4, 3, 5, 6, 7, 4, 3, 6, 4),
                   x2 = c(4, NA, 3, 6, 3, 7, 2, 7, 3, 3, 3, 1, 3, 6,
                          3, 5, 2, 6, 8, 3, 4, 5, 2, 1, 3, 1, 2, NA),
                   x3 = c(7, 8, 5, 6, 4, 2, 8, 3, 6, 1, 2, 5, 8, 6,
                          2, 5, 3, 1, 6, 4, 5, 5, 3, 6, 3, 2, 2, 4))

#-------------------------------------------------------------------------------
# One-sample design

# Example 1: Two-Sided 95% CI for x1
# population mean = 3
ci.mean.diff(dat1$x1, mu = 3)

#-------------------------------------------------------------------------------
# Two-sample design

# Example 2: Two-Sided 95% CI for y1 by group1
# unknown population variances, unequal variance assumption
ci.mean.diff(x1 ~ group1, data = dat1)

# Example 3: Two-Sided 95% CI for y1 by group1
# unknown population variances, equal variance assumption
ci.mean.diff(x1 ~ group1, data = dat1, var.equal = TRUE)

# Example 4: Two-Sided 95% CI with known standard deviations for x1 by group1
# known population standard deviations, equal standard deviation assumption
ci.mean.diff(x1 ~ group1, data = dat1, sigma = 1.2)

# Example 5: Two-Sided 95% CI with known standard deviations for x1 by group1
# known population standard deviations, unequal standard deviation assumption
ci.mean.diff(x1 ~ group1, data = dat1, sigma = c(1.5, 1.2))

# Example 6: Two-Sided 95% CI with known variance for x1 by group1
# known population variances, equal variance assumption
ci.mean.diff(x1 ~ group1, data = dat1, sigma2 = 1.44)

# Example 7: Two-Sided 95% CI with known variance for x1 by group1
# known population variances, unequal variance assumption
ci.mean.diff(x1 ~ group1, data = dat1, sigma2 = c(2.25, 1.44))

# Example 8: One-Sided 95% CI for y1 by group1
# unknown population variances, unequal variance assumption
ci.mean.diff(x1 ~ group1, data = dat1, alternative = "less")

# Example 9: Two-Sided 99% CI for y1 by group1
# unknown population variances, unequal variance assumption
ci.mean.diff(x1 ~ group1, data = dat1, conf.level = 0.99)

# Example 10: Two-Sided 95% CI for y1 by group1
# unknown population variances, unequal variance assumption
# print results with 3 digits
ci.mean.diff(x1 ~ group1, data = dat1, digits = 3)

# Example 11: Two-Sided 95% CI for y1 by group1
# unknown population variances, unequal variance assumption
# convert value 4 to NA
ci.mean.diff(x1 ~ group1, data = dat1, as.na = 4)

# Example 12: Two-Sided 95% CI for y1, y2, and y3 by group1
# unknown population variances, unequal variance assumption
ci.mean.diff(cbind(x1, x2, x3) ~ group1, data = dat1)

# Example 13: Two-Sided 95% CI for y1, y2, and y3 by group1
# unknown population variances, unequal variance assumption,
# listwise deletion for missing data
ci.mean.diff(cbind(x1, x2, x3) ~ group1, data = dat1, na.omit = TRUE)

# Example 14: Two-Sided 95% CI for y1, y2, and y3 by group1
# unknown population variances, unequal variance assumption,
# analysis by group2 separately
ci.mean.diff(cbind(x1, x2, x3) ~ group1, data = dat1, group = dat1$group2)

# Example 15: Two-Sided 95% CI for y1, y2, and y3 by group1
# unknown population variances, unequal variance assumption,
# analysis by group2 separately, sort by variables
ci.mean.diff(cbind(x1, x2, x3) ~ group1, data = dat1, group = dat1$group2,
             sort.var = TRUE)# Check if input 'y' is NULL

# Example 16: Two-Sided 95% CI for y1, y2, and y3 by group1
# unknown population variances, unequal variance assumption,
# split analysis by group2
ci.mean.diff(cbind(x1, x2, x3) ~ group1, data = dat1, split = dat1$group2)

# Example 17: Two-Sided 95% CI for y1, y2, and y3 by group1
# unknown population variances, unequal variance assumption,
# analysis by group2 separately, split analysis by group3
ci.mean.diff(cbind(x1, x2, x3) ~ group1, data = dat1,
             group = dat1$group2, split = dat1$group3)

#-----------------

group1 &lt;- c(3, 1, 4, 2, 5, 3, 6, 7)
group2 &lt;- c(5, 2, 4, 3, 1)

# Example 18: Two-Sided 95% CI for the mean difference between group1 and group2
# unknown population variances, unequal variance assumption
ci.mean.diff(group1, group2)

# Example 19: Two-Sided 95% CI for the mean difference between group1 and group2
# unknown population variances, equal variance assumption
ci.mean.diff(group1, group2, var.equal = TRUE)

#-------------------------------------------------------------------------------
# Paired-sample design

dat2 &lt;- data.frame(pre = c(1, 3, 2, 5, 7, 6),
                   post = c(2, 2, 1, 6, 8, 9),
                   group = c(1, 1, 1, 2, 2, 2), stringsAsFactors = FALSE)

# Example 20: Two-Sided 95% CI for the mean difference in pre and post
# unknown poulation variance of difference scores
ci.mean.diff(dat2$pre, dat2$post, paired = TRUE)

# Example 21: Two-Sided 95% CI for the mean difference in pre and post
# unknown poulation variance of difference scores
# analysis by group separately
ci.mean.diff(dat2$pre, dat2$post, paired = TRUE, group = dat2$group)

# Example 22: Two-Sided 95% CI for the mean difference in pre and post
# unknown poulation variance of difference scores
# analysis by group separately
ci.mean.diff(dat2$pre, dat2$post, paired = TRUE, split = dat2$group)

# Example 23: Two-Sided 95% CI for the mean difference in pre and post
# known population standard deviation of difference scores
ci.mean.diff(dat2$pre, dat2$post, sigma = 2, paired = TRUE)

# Example 24: Two-Sided 95% CI for the mean difference in pre and post
# known population variance of difference scores
ci.mean.diff(dat2$pre, dat2$post, sigma2 = 4, paired = TRUE)

# Example 25: One-Sided 95% CI for the mean difference in pre and post
# unknown poulation variance of difference scores
ci.mean.diff(dat2$pre, dat2$post, alternative = "less", paired = TRUE)

# Example 26: Two-Sided 99% CI for the mean difference in pre and post
# unknown poulation variance of difference scores
ci.mean.diff(dat2$pre, dat2$post, conf.level = 0.99, paired = TRUE)

# Example 27: Two-Sided 95% CI for for the mean difference in pre and post
# unknown poulation variance of difference scores
# print results with 3 digits
ci.mean.diff(dat2$pre, dat2$post, paired = TRUE, digits = 3)

# Example 28: Two-Sided 95% CI for for the mean difference in pre and post
# unknown poulation variance of difference scores
# convert value 1 to NA
ci.mean.diff(dat2$pre, dat2$post, as.na = 1, paired = TRUE)
</code></pre>

<hr>
<h2 id='ci.mean.w'>Within-Subject Confidence Interval for the Arithmetic Mean</h2><span id='topic+ci.mean.w'></span>

<h3>Description</h3>

<p>This function computes difference-adjusted Cousineau-Morey within-subject
confidence interval for the arithmetic mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.mean.w(..., data = NULL, adjust = TRUE,
          alternative = c("two.sided", "less", "greater"),
          conf.level = 0.95, na.omit = TRUE, digits = 2,
          as.na = NULL, write = NULL, append = TRUE, check = TRUE,
          output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.mean.w_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with numeric variables representing
the levels of the within-subject factor, i.e., data are
specified in wide-format (i.e., multivariate person level
format). Alternatively, an expression indicating the variable
names in <code>data</code> e.g., <code>ci.mean.w(x1, x2, x3, data = dat)</code>.
Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame
for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the Cousineau-Morey within-subject confidence intervals
is applied.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), incomplete cases are removed
before conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.mean.w_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cousineau within-subject confidence interval (CI, Cousineau, 2005) is an
alternative to the Loftus-Masson within-subject CI (Loftus &amp; Masson, 1994)
that does not assume sphericity or homogeneity of covariances. This approach
removes individual differences by normalizing the raw scores using
participant-mean centering and adding the grand mean back to every score:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ij}^{'} = Y_{ij} - \hat{\mu}_{i} + \hat{\mu}_{grand}</code>
</p>

<p>where <code class="reqn">Y_{ij}^{'}</code> is the score of the <code class="reqn">i</code>th participant in condition
<code class="reqn">j</code> (for <code class="reqn">i = 1</code> to <code class="reqn">n</code>), <code class="reqn">\hat{\mu}_{i}</code> is the mean of
participant <code class="reqn">i</code> across all <code class="reqn">J</code> levels (for <code class="reqn">j = 1</code> to <code class="reqn">J</code>),
and <code class="reqn">\hat{\mu}_{grand}</code> is the grand mean.
</p>
<p>Morey (2008) pointed out that Cousineau's (2005) approach produces intervals
that are consistently too narrow due to inducing a positive covariance
between normalized scores within a condition introducing bias into the
estimate of the sample variances. The degree of bias is proportional to the
number of means and can be removed by rescaling the confidence interval by
a factor of <code class="reqn">\sqrt{J - 1}/J</code>:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu}_j \pm t_{n - 1, 1 - \alpha/2} \sqrt{\frac{J}{J - 1}} \hat{\sigma}^{'}_{{\hat{\mu}}_j}</code>
</p>

<p>where <code class="reqn">\hat{\sigma}^{'}_{{\mu}_j}</code> is the standard error of the mean computed
from the normalized scores of he <code class="reqn">j</code>th factor level.
</p>
<p>Baguley (2012) pointed out that the Cousineau-Morey interval is larger than
that for a difference in means by a factor of <code class="reqn">\sqrt{2}</code> leading to a
misinterpretation of these intervals that overlap of 95% confidence intervals
around individual means is indicates that a 95% confidence interval for the
difference in means would include zero. Hence, following adjustment to the
Cousineau-Morey interval was proposed:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu}_j \pm \frac{\sqrt{2}}{2} (t_{n - 1, 1 - \alpha/2} \sqrt{\frac{J}{J - 1}} \hat{\sigma}^{'}_{{\hat{\mu}}_j})</code>
</p>

<p>The adjusted Cousineau-Morey interval is informative about the pattern of
differences between means and is computed by default (i.e., <code>adjust = TRUE</code>).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Baguley, T. (2012). Calculating and graphing within-subject confidence intervals
for ANOVA. <em>Behavior Research Methods, 44</em>, 158-175.
https://doi.org/10.3758/s13428-011-0123-7
</p>
<p>Cousineau, D. (2005) Confidence intervals in within-subject designs: A simpler
solution to Loftus and Masson’s Method. <em>Tutorials in Quantitative Methods
for Psychology, 1</em>, 42–45.  https://doi.org/10.20982/tqmp.01.1.p042
</p>
<p>Loftus, G. R., and Masson, M. E. J. (1994). Using confidence intervals in
within-subject designs. <em>Psychonomic Bulletin and Review, 1</em>, 476–90.
https://doi.org/10.3758/BF03210951
</p>
<p>Morey, R. D. (2008). Confidence intervals from normalized data: A correction
to Cousineau. <em>Tutorials in Quantitative Methods for Psychology, 4</em>, 61–4.
https://doi.org/10.20982/tqmp.01.1.p042
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+test.t">test.t</a></code>,
<code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,' <code><a href="#topic+ci.median">ci.median</a></code>, <code><a href="#topic+ci.prop">ci.prop</a></code>,
<code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(time1 = c(3, 2, 1, 4, 5, 2, 3, 5, 6, 7),
                  time2 = c(4, 3, 6, 5, 8, 6, 7, 3, 4, 5),
                  time3 = c(1, 2, 2, 3, 6, 5, 1, 2, 4, 6))

# Example 1: Difference-adjusted Cousineau-Morey confidence intervals
ci.mean.w(dat)

# Example 1: Alternative specification using the 'data' argument
ci.mean.w(., data = dat)

# Example 2: Cousineau-Morey confidence intervals
ci.mean.w(dat, adjust = FALSE)

## Not run: 
# Example 3: Write results into a text file
ci.mean.w(dat, write = "WS_Confidence_Interval.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='ci.prop'>Confidence Interval for Proportions</h2><span id='topic+ci.prop'></span>

<h3>Description</h3>

<p>This function computes a confidence interval for proportions for one or more variables, optionally
by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.prop(..., data = NULL, method = c("wald", "wilson"),
        alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
        group = NULL, split = NULL, sort.var = FALSE, na.omit = FALSE,
        digits = 3, as.na = NULL, write = NULL, append = TRUE, check = TRUE,
        output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.prop_+3A_...">...</code></td>
<td>
<p>a numeric vector, matrix or data frame with numeric variables
with 0 and 1 values, i.e., factors and character variables
are excluded from <code>x</code> before conducting the analysis.
Alternatively, an expression indicating the variable
names in <code>data</code> e.g., <code>ci.prop(x1, x2, x3, data = dat)</code>.
Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector, matrix or data frame
for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_method">method</code></td>
<td>
<p>a character string specifying the method for computing the confidence interval,
must be one of <code>"wald"</code>, or <code>"wilson"</code> (default).</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of
<code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level of the interval.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name of
the grouping variable in <code>...</code> or <code>data</code>, or a vector
representing the grouping variable.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_split">split</code></td>
<td>
<p>either a character string indicating the variable name of
the split variable in <code>...</code> or <code>data</code>, or a vector
representing the split variable.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before conducting the analysis
(i.e., listwise deletion) when specifying more than one outcome variable.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting the analysis.
Note that <code>as.na()</code> function is only applied to <code>x</code>, but
not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.prop_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wald confidence interval which is based on the normal approximation to the binomial distribution are
computed by specifying <code>method = "wald"</code>, while the Wilson (1927) confidence interval (aka Wilson
score interval) is requested by specifying <code>method = "wilson"</code>. By default, Wilson confidence
interval is computed which have been shown to be reliable in small samples of n = 40 or less, and
larger samples of n &gt; 40 (Brown, Cai &amp; DasGupta, 2001), while the Wald confidence intervals is
inadequate in small samples and when <em>p</em> is near 0 or 1 (Agresti &amp; Coull, 1998).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>...</code>, <code>data</code>,                           <code>group</code>, and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Agresti, A. &amp; Coull, B.A. (1998). Approximate is better than &quot;exact&quot; for interval estimation of binomial
proportions. <em>American Statistician, 52</em>, 119-126.
</p>
<p>Brown, L. D., Cai, T. T., &amp; DasGupta, A., (2001). Interval estimation for a binomial proportion.
<em>Statistical Science, 16</em>, 101-133.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology - Using R and SPSS</em>.
John Wiley &amp; Sons.
</p>
<p>Wilson, E. B. (1927). Probable inference, the law of succession, and statistical inference.
<em>Journal of the American Statistical Association, 22</em>, 209-212.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>,
<code><a href="#topic+ci.prop.diff">ci.prop.diff</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>,
<code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Two-Sided 95% CI for 'vs'
ci.prop(mtcars$vs)
#
# Example 1b: Alternative specification using the 'data' argument
ci.prop(vs, data = mtcars)

# Example 2: Two-Sided 95% CI using Wald method
ci.prop(mtcars$vs, method = "wald")

# Example 3: One-Sided 95% CI
ci.prop(mtcars$vs, alternative = "less")

# Example 4: Two-Sided 99% CI
ci.prop(mtcars$vs, conf.level = 0.99)

# Example 5: Two-Sided 95% CI, print results with 4 digits
ci.prop(mtcars$vs, digits = 4)

# Example 6a: Two-Sided 95% CI for 'vs' and 'am',
# listwise deletion for missing data
ci.prop(mtcars[, c("vs", "am")], na.omit = TRUE)

# Example 6b: Alternative specification using the 'data' argument
# listwise deletion for missing data
ci.prop(vs, am, data = mtcars, na.omit = TRUE)

# Example 7a: Two-Sided 95% CI, analysis by 'gear' separately
ci.prop(mtcars[, c("vs", "am")], group = mtcars$gear)

# Example 7b: Alternative specification using the 'data' argument
ci.prop(vs, am, data = mtcars, group = "gear")

# Example 8: Two-Sided 95% CI, analysis by 'gear' separately, sort by variables
ci.prop(mtcars[, c("vs", "am")], group = mtcars$gear, sort.var = TRUE)

# Example 9: Two-Sided 95% CI, split analysis by 'cyl'
ci.prop(mtcars[, c("vs", "am")], split = mtcars$cyl)

# Example 10a: Two-Sided 95% CI, analysis by 'gear' separately, split by 'cyl'
ci.prop(mtcars[, c("vs", "am")], group = mtcars$gear, split = mtcars$cyl)

# Example 10b: Alternative specification using the 'data' argument
ci.prop(vs, am, data = mtcars, group = "gear", split = "cyl")

## Not run: 
# Example 11: Write results into a text file
ci.prop(vs, am, data = mtcars, group = "gear", split = "cyl", write = "Prop.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='ci.prop.diff'>Confidence Interval for the Difference in Proportions</h2><span id='topic+ci.prop.diff'></span><span id='topic+ci.prop.diff.default'></span><span id='topic+ci.prop.diff.formula'></span>

<h3>Description</h3>

<p>This function computes a confidence interval for the difference in proportions in a two-sample
and paired-sample design for one or more variables, optionally by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.prop.diff(x, ...)

## Default S3 method:
ci.prop.diff(x, y, method = c("wald", "newcombe"), paired = FALSE,
             alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
             group = NULL, split = NULL, sort.var = FALSE, digits = 2,
             as.na = NULL, write = NULL, append = TRUE,
             check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
ci.prop.diff(formula, data, method = c("wald", "newcombe"),
             alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
             group = NULL, split = NULL, sort.var = FALSE, na.omit = FALSE,
             digits = 2, as.na = NULL, write = NULL, append = TRUE,
             check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.prop.diff_+3A_x">x</code></td>
<td>
<p>a numeric vector with 0 and 1 values.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_y">y</code></td>
<td>
<p>a numeric vector with 0 and 1 values.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_method">method</code></td>
<td>
<p>a character string specifying the method for computing the confidence interval,
must be one of <code>"wald"</code>, or <code>"newcombe"</code> (default).</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, confidence interval for the difference of proportions
in paired samples is computed.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of
<code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level of the interval.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_group">group</code></td>
<td>
<p>a numeric vector, character vector or factor as grouping variable. Note that a grouping
variable can only be used when computing confidence intervals with unknown population
standard deviation and population variance.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_split">split</code></td>
<td>
<p>a numeric vector, character vector or factor as split variable. Note that a split
variable can only be used when computing confidence intervals with unknown population
standard deviation and population variance.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting the analysis.
Note that <code>as.na()</code> function is only applied to <code>x</code>, but
not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> for one outcome variable or
<code>cbind(y1, y2, y3) ~ group</code> for more than one outcome variable where
<code>y</code> is a numeric variable with 0 and 1 values and <code>group</code> a numeric
variable, character variable or factor with two values or factor levels giving
the corresponding group.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="ci.prop.diff_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before conducting the analysis
(i.e., listwise deletion) when specifying more than one outcome variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wald confidence interval which is based on the normal approximation to the binomial distribution are
computed by specifying <code>method = "wald"</code>, while the Newcombe Hybrid Score interval (Newcombe, 1998a;
Newcombe, 1998b) is requested by specifying <code>method = "newcombe"</code>. By default, Newcombe Hybrid Score
interval is computed which have been shown to be reliable in small samples (less than n = 30 in each sample)
as well as moderate to larger samples(n &gt; 30 in each sample) and with proportions close to 0 or 1, while the
Wald confidence intervals does not perform well unless the sample size is large (Fagerland, Lydersen &amp; Laake, 2011).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>x</code>, <code>group</code>,
and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Fagerland, M. W., Lydersen S., &amp; Laake, P. (2011) Recommended confidence intervals for two independent binomial
proportions. <em>Statistical Methods in Medical Research, 24</em>, 224-254.
</p>
<p>Newcombe, R. G. (1998a). Interval estimation for the difference between independent proportions: Comparison of
eleven methods. <em>Statistics in Medicine, 17</em>, 873-890.
</p>
<p>Newcombe, R. G. (1998b). Improved confidence intervals for the difference between binomial proportions based on
paired data. <em>Statistics in Medicine, 17</em>, 2635-2650.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology - Using R and SPSS</em>.
John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.median">ci.median</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>, <code><a href="#topic+ci.sd">ci.sd</a></code>,
<code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat1 &lt;- data.frame(group1 = c(1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,
                              1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2),
                   group2 = c(1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2,
                              1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2),
                   group3 = c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
                              1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2),
                   x1 = c(0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, NA, 0, 0,
                          1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0),
                   x2 = c(0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,
                          1, 0, 1, 0, 1, 1, 1, NA, 1, 0, 0, 1, 1, 1),
                   x3 = c(1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,
                          1, 0, 1, 1, 0, 1, 1, 1, 0, 1, NA, 1, 0, 1))

#-------------------------------------------------------------------------------
# Two-sample design

# Example 1: Two-Sided 95% CI for x1 by group1
# Newcombes Hybrid Score interval
ci.prop.diff(x1 ~ group1, data = dat1)

# Example 2: Two-Sided 95% CI for x1 by group1
# Wald CI
ci.prop.diff(x1 ~ group1, data = dat1, method = "wald")

# Example 3: One-Sided 95% CI for x1 by group1
# Newcombes Hybrid Score interval
ci.prop.diff(x1 ~ group1, data = dat1, alternative = "less")

# Example 4: Two-Sided 99% CI for x1 by group1
# Newcombes Hybrid Score interval
ci.prop.diff(x1 ~ group1, data = dat1, conf.level = 0.99)

# Example 5: Two-Sided 95% CI for y1 by group1
# Newcombes Hybrid Score interval, print results with 3 digits
ci.prop.diff(x1 ~ group1, data = dat1, digits = 3)

# Example 6: Two-Sided 95% CI for y1 by group1
# Newcombes Hybrid Score interval, convert value 0 to NA
ci.prop.diff(x1 ~ group1, data = dat1, as.na = 0)

# Example 7: Two-Sided 95% CI for y1, y2, and y3 by group1
# Newcombes Hybrid Score interval
ci.prop.diff(cbind(x1, x2, x3) ~ group1, data = dat1)

# Example 8: Two-Sided 95% CI for y1, y2, and y3 by group1
# Newcombes Hybrid Score interval, listwise deletion for missing data
ci.prop.diff(cbind(x1, x2, x3) ~ group1, data = dat1, na.omit = TRUE)

# Example 9: Two-Sided 95% CI for y1, y2, and y3 by group1
# Newcombes Hybrid Score interval, analysis by group2 separately
ci.prop.diff(cbind(x1, x2, x3) ~ group1, data = dat1, group = dat1$group2)

# Example 10: Two-Sided 95% CI for y1, y2, and y3 by group1
# Newcombes Hybrid Score interval, analysis by group2 separately, sort by variables
ci.prop.diff(cbind(x1, x2, x3) ~ group1, data = dat1, group = dat1$group2,
             sort.var = TRUE)

# Example 11: Two-Sided 95% CI for y1, y2, and y3 by group1
# split analysis by group2
ci.prop.diff(cbind(x1, x2, x3) ~ group1, data = dat1, split = dat1$group2)

# Example 12: Two-Sided 95% CI for y1, y2, and y3 by group1
# Newcombes Hybrid Score interval, analysis by group2 separately, split analysis by group3
ci.prop.diff(cbind(x1, x2, x3) ~ group1, data = dat1,
             group = dat1$group2, split = dat1$group3)

#-----------------

group1 &lt;- c(0, 1, 1, 0, 0, 1, 0, 1)
group2 &lt;- c(1, 1, 1, 0, 0)

# Example 13: Two-Sided 95% CI for the mean difference between group1 amd group2
# Newcombes Hybrid Score interval
ci.prop.diff(group1, group2)

#-------------------------------------------------------------------------------
# Paires-sample design

dat2 &lt;- data.frame(pre = c(0, 1, 1, 0, 1),
                   post = c(1, 1, 0, 1, 1))

# Example 14: Two-Sided 95% CI for the mean difference in x1 and x2
# Newcombes Hybrid Score interval
ci.prop.diff(dat2$pre, dat2$post, paired = TRUE)

# Example 15: Two-Sided 95% CI for the mean difference in x1 and x2
# Wald CI
ci.prop.diff(dat2$pre, dat2$post, method = "wald", paired = TRUE)

# Example 16: One-Sided 95% CI for the mean difference in x1 and x2
# Newcombes Hybrid Score interval
ci.prop.diff(dat2$pre, dat2$post, alternative = "less", paired = TRUE)

# Example 17: Two-Sided 99% CI for the mean difference in x1 and x2
# Newcombes Hybrid Score interval
ci.prop.diff(dat2$pre, dat2$post, conf.level = 0.99, paired = TRUE)

# Example 18: Two-Sided 95% CI for for the mean difference in x1 and x2
# Newcombes Hybrid Score interval, print results with 3 digits
ci.prop.diff(dat2$pre, dat2$post, paired = TRUE, digits = 3)
</code></pre>

<hr>
<h2 id='ci.var'>Confidence Interval for the Variance and Standard Deviation</h2><span id='topic+ci.var'></span><span id='topic+ci.sd'></span>

<h3>Description</h3>

<p>The function <code>ci.var</code> computes the confidence interval for the variance,
and the function <code>ci.sd</code> computes the confidence interval for the standard
deviation for one or more variables, optionally by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.var(..., data = NULL, method = c("chisq", "bonett"),
       alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
       group = NULL, split = NULL, sort.var = FALSE, na.omit = FALSE,
       digits = 2, as.na = NULL, write = NULL, append = TRUE,
       check = TRUE, output = TRUE)

ci.sd(..., data = NULL, method = c("chisq", "bonett"),
      alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
      group = NULL, split = NULL, sort.var = FALSE, na.omit = FALSE, digits = 2,
      as.na = NULL, write = NULL, append = TRUE,
      check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.var_+3A_...">...</code></td>
<td>
<p>a numeric vector, matrix or data frame with numeric variables,
i.e., factors and character variables are excluded from <code>x</code>
before conducting the analysis. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>ci.var(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector, matrix or data frame
for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_method">method</code></td>
<td>
<p>a character string specifying the method for computing the confidence interval,
must be one of <code>"chisq"</code>, or <code>"bonett"</code> (default).</p>
</td></tr>
<tr><td><code id="ci.var_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of
<code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level of the interval.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name of
the grouping variable in <code>...</code> or <code>data</code>, or a vector
representing the grouping variable.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_split">split</code></td>
<td>
<p>either a character string indicating the variable name of
the split variable in <code>...</code> or <code>data</code>, or a vector
representing the split variable.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before conducting the analysis
(i.e., listwise deletion) when specifying more than one outcome variable.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting the analysis.
Note that <code>as.na()</code> function is only applied to <code>x</code>, but
not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="ci.var_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence interval based on the chi-square distribution is computed by specifying <code>method = "chisq"</code>,
while the Bonett (2006) confidence interval is requested by specifying <code>method = "bonett"</code>. By default,
the Bonett confidence interval interval is computed which performs well under moderate departure from
normality, while the confidence interval based on the chi-square distribution is highly sensitive to minor
violations of the normality assumption and its performance does not improve with increasing sample size.
Note that at least four valid observations are needed to compute the Bonett confidence interval.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>...</code>, <code>data</code>,                           <code>group</code>, and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology - Using R and SPSS</em>.
John Wiley &amp; Sons.
</p>
<p>Bonett, D. G. (2006). Approximate confidence interval for standard deviation of nonnormal distributions.
<em>Computational Statistics and Data Analysis, 50</em>, 775-782. https://doi.org/10.1016/j.csda.2004.10.003
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>,
<code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.prop.diff">ci.prop.diff</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Two-Sided 95% CI for the variance for 'mpg'
ci.var(mtcars$mpg)

# Example 1b: Alternative specification using the 'data' argument
ci.var(mpg, data = mtcars)

# Example 2a: Two-Sided 95% CI for the standard deviation for 'mpg'
ci.sd(mtcars$mpg)

# Example 2b: Alternative specification using the 'data' argument
ci.sd(mpg, data = mtcars)

# Example 3: Two-Sided 95% CI using chi square distribution
ci.var(mtcars$mpg, method = "chisq")

# Example 4: One-Sided 95% CI
ci.var(mtcars$mpg, alternative = "less")

# Example 5: Two-Sided 99% CI
ci.var(mtcars$mpg, conf.level = 0.99)

# Example 6: Two-Sided 95% CI, print results with 3 digits
ci.var(mtcars$mpg, digits = 3)

# Example 7a: Two-Sided 95% CI for 'mpg', 'disp', and 'hp',
# listwise deletion for missing data
ci.var(mtcars[, c("mpg", "disp", "hp")])

# Example 7b: Alternative specification using the 'data' argument
ci.var(mpg:hp, data = mtcars)

# Example 8a: Two-Sided 95% CI, analysis by 'vs' separately
ci.var(mtcars[, c("mpg", "disp", "hp")], group = mtcars$vs)

# Example 8b: Alternative specification using the 'data' argument
ci.var(mpg:hp, data = mtcars, group = "vs")

# Example 9: Two-Sided 95% CI for, analysis by 'vs' separately, sort by variables
ci.var(mtcars[, c("mpg", "disp", "hp")], group = mtcars$vs, sort.var = TRUE)

# Example 10: Two-Sided 95% CI, split analysis by 'vs'
ci.var(mtcars[, c("mpg", "disp", "hp")], split = mtcars$vs)

# Example 11a: Two-Sided 95% CI, analysis by 'vs' separately, split analysis by 'am'
ci.var(mtcars[, c("mpg", "disp", "hp")], group = mtcars$vs, split = mtcars$am)

# Example 11b: Alternative specification using the 'data' argument
ci.var(mpg:hp, data = mtcars, group = "vs", split = "am")

## Not run: 
# Example 12: Write results into a text file
ci.var(mpg:hp, data = mtcars, group = "vs", split = "am", write = "Variance.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='cluster.scores'>Cluster Scores</h2><span id='topic+cluster.scores'></span>

<h3>Description</h3>

<p>This function computes group means by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster.scores(..., data = NULL, cluster,
              fun = c("mean", "sum", "median", "var", "sd", "min", "max"),
              expand = TRUE, append = TRUE, name = ".a", as.na = NULL,
              check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster.scores_+3A_...">...</code></td>
<td>
<p>a numeric vector for computing cluster scores for a variable,
matrix or data frame for computing cluster scores for more than
one variable. Alternatively, an expression indicating the variable
names in <code>data</code> e.g., <code>ci.mean(x1, x2, data = dat)</code>.
Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector, matrix, or data frame for
the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>...</code> or <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_fun">fun</code></td>
<td>
<p>character string indicating the function used to compute group
scores, default: <code>"mean"</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_expand">expand</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vector of cluster scores is expanded
to match the input vector <code>x</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), cluster scores are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names
of the computed variables. By default, variables are named with the ending
<code>".a"</code> resulting in e.g. <code>"x1.a"</code> and <code>"x2.a"</code>. Variable names
can also be specified using a character vector matching the number
of variables specified in <code>x</code> (e.g.,
<code>name = c("cluster.x1", "cluster.x2")</code>).</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.
these values are converted to <code>NA</code> before conducting the
analysis. Note that <code>as.na()</code> function is only applied to
the argument <code>x</code>, but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="cluster.scores_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector or data frame containing cluster scores with the same
length or same number of rows as <code>x</code> if <code>expand = TRUE</code> or with the
length or number of rows as <code>length(unique(cluster))</code> if <code>expand = FALSE</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel analysis:
Techniques and applications</em> (3rd. ed.). Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An
introduction to basic and advanced multilevel modeling</em> (2nd ed.). Sage
Publishers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.scores">item.scores</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>,
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Example 1a: Compute cluster means for 'y1' and expand to match the input 'y1'
cluster.scores(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

# Example 1b: Alternative specification using the 'data' argument
cluster.scores(y1, data = Demo.twolevel, cluster = "cluster")

# Example 2: Compute standard deviation for each cluster
# and expand to match the input x
cluster.scores(Demo.twolevel$y1, cluster = Demo.twolevel$cluster, fun = "sd")

# Example 3: Compute cluster means without expanding the vector
cluster.scores(Demo.twolevel$y1, cluster = Demo.twolevel$cluster, expand = FALSE)

# Example 4a: Compute cluster means for 'y1' and 'y2' and append to 'Demo.twolevel'
cbind(Demo.twolevel,
      cluster.scores(Demo.twolevel[, c("y1", "y2")], cluster = Demo.twolevel$cluster))

# Example 4b: Alternative specification using the 'data' argument
cluster.scores(y1, y2, data = Demo.twolevel, cluster = "cluster")
</code></pre>

<hr>
<h2 id='coding'>Coding Categorical Variables</h2><span id='topic+coding'></span>

<h3>Description</h3>

<p>This function creates <code class="reqn">k - 1</code> variables for a categorical variable with
<code class="reqn">k</code> distinct levels. The coding system available in this function are
dummy coding, simple coding, unweighted effect coding, weighted effect coding,
repeated coding, forward Helmert coding, reverse Helmert coding, and orthogonal
polynomial coding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coding(..., data = NULL,
       type = c("dummy", "simple", "effect", "weffect", "repeat",
                "fhelm", "rhelm", "poly"), base = NULL,
       name = c("dum.", "sim.", "eff.", "weff.", "rep.", "fhelm.", "rhelm.", "poly."),
       append = TRUE, as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coding_+3A_...">...</code></td>
<td>
<p>a numeric vector with integer values, character vector or factor
Alternatively, an expression indicating the variable name in
<code>data</code>. Note that the function can only deal with one
categorical variable.</p>
</td></tr>
<tr><td><code id="coding_+3A_data">data</code></td>
<td>
<p>a data frame when specifying a variable in the argument <code>...</code>.
Note that the argument is <code>NULL</code> when specifying a numeric
vector with integer values, character vector or factor numeric
vector for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="coding_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of coding, i.e.,
<code>dummy</code> (default) for dummy coding, <code>simple</code> for
simple coding, <code>effect</code> for unweighted effect coding,
<code>weffect</code> for weighted effect coding, <code>repeat</code>
for repeated coding, <code>fhelm</code> for forward Helmert coding,
<code>rhelm</code> for reverse Helmert coding, and <code>poly</code> for
orthogonal polynomial coding (see 'Details').</p>
</td></tr>
<tr><td><code id="coding_+3A_base">base</code></td>
<td>
<p>a numeric value or character string indicating the baseline
group for dummy and simple coding and the omitted group in
effect coding. By default, the first group or factor level is
selected as baseline or omitted group.</p>
</td></tr>
<tr><td><code id="coding_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names
of the coded variables. By default, variables are named
<code>"dum."</code>, <code>"sim."</code>, <code>"eff."</code>, <code>"weff."</code>,
<code>"rep."</code>, <code>"fhelm."</code>, <code>"rhelm."</code>,or <code>"poly."</code>
depending on the <code>type</code> of coding with the category used
in the comparison (e.g., <code>"dum.2"</code> and <code>"dum.3"</code>).
Variable names can be specified using a character string (e.g.,
<code>name = "dummy_"</code> leads to <code>dummy_2</code> and <code>dummy_3</code>)
or a character vector matching the number of coded variables
(e.g. <code>name = c("x1_2", "x1_3")</code>)  which is the number of
unique categories minus one.</p>
</td></tr>
<tr><td><code id="coding_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), coded variables are appended
to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="coding_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="coding_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Dummy Coding</strong></dt><dd><p>Dummy or treatment coding compares the mean of
each level of the categorical variable to the mean of a baseline group. By
default, the first group or factor level is selected as baseline group. The
intercept in the regression model represents the mean of the baseline group.
For example, dummy coding based on a  categorical variable with four groups
<code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following comparisons:
<code>B vs A</code>, <code>C vs A</code>, and <code>D vs A</code> with <code>A</code> being the
baseline group.</p>
</dd>
<dt><strong>Simple Coding</strong></dt><dd><p>Simple coding compares each level of the
categorical variable to the mean of a baseline level. By default, the first
group or factor level is selected as baseline group. The intercept in the
regression model represents the unweighted grand mean, i.e., mean of group
means. For example, simple coding based on a  categorical variable with four
groups <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following comparisons:
<code>B vs A</code>, <code>C vs A</code>, and <code>D vs A</code> with <code>A</code> being the
baseline group.</p>
</dd>
<dt><strong>Unweighted Effect Coding</strong></dt><dd><p>Unweighted effect or sum coding
compares the mean of a given level to the unweighed grand mean, i.e., mean of
group means. By default, the first group or factor level is selected as
omitted group. For example, effect coding based on a  categorical variable
with four groups <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following
comparisons: <code>B vs (A, B, C, D)</code>, <code>C vs (A, B, C, D)</code>, and
<code>D vs (A, B, C, D)</code> with <code>A</code> being the omitted group.</p>
</dd>
<dt><strong>Weighted Effect Coding</strong></dt><dd><p>Weighted effect or sum coding compares
the mean of a given level to the weighed grand mean, i.e., sample mean. By
default, the first group or factor level is selected as omitted group. For
example, effect coding based on a categorical variable with four groups
<code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following comparisons:
<code>B vs (A, B, C, D)</code>, <code>C vs (A, B, C, D)</code>, and <code>D vs (A, B, C, D)</code>
with <code>A</code> being the omitted group.</p>
</dd>
<dt><strong>Repeated Coding</strong></dt><dd><p>Repeated or difference coding compares the
mean of each level of the categorical variable to the mean of the previous
adjacent level. For example, repeated coding based on a  categorical variable
with four groups <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> makes following
comparisons: <code>B vs A</code>, <code>C vs B</code>, and <code>D vs C</code>.</p>
</dd>
<dt><strong>Foward Helmert Coding</strong></dt><dd><p>Forward Helmert coding compares the
mean of each level of the categorical variable to the unweighted mean of all
subsequent level(s) of the categorical variable. For example, forward Helmert
coding based on a  categorical variable with four groups <code>A</code>, <code>B</code>,
<code>C</code>, <code>D</code> makes following comparisons: <code>(B, C, D) vs A</code>,
<code>(C, D) vs B</code>, and <code>D vs C</code>.</p>
</dd>
<dt><strong>Reverse Helmert Coding</strong></dt><dd><p>Reverse Helmert coding compares the
mean of each level of the categorical variable to the unweighted mean of all
prior level(s) of the categorical variable. For example, reverse Helmert
coding based on a  categorical variable with four groups <code>A</code>, <code>B</code>,
<code>C</code>, <code>D</code> makes following comparisons: <code>B vs A</code>, <code>C vs (A, B)</code>,
and <code>D vs (A, B, C)</code>.</p>
</dd>
<dt><strong>Orthogonal Polynomial Coding</strong></dt><dd><p>Orthogonal polynomial coding is
a form of trend analysis based on polynomials of order <code class="reqn">k - 1</code>, where
<code class="reqn">k</code> is the number of levels of the categorical variable. This coding
scheme assumes an ordered-categorical variable with equally spaced levels.
For example, orthogonal polynomial coding based on a categorical variable with
four groups <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code> investigates a linear,
quadratic, and cubic trends in the categorical variable.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a data frame with <code class="reqn">k - 1</code> coded variables or a data frame with the
same length or same number of rows as <code>...</code> containing the coded variables.
</p>


<h3>Note</h3>

<p>This function uses the <code>contr.treatment</code> function from the <span class="pkg">stats</span>
package for dummy coding and simple coding, a modified copy of the
<code>contr.sum</code> function from the <span class="pkg">stats</span> package for effect coding,
a modified copy of the <code>contr.wec</code> function from the <span class="pkg">wec</span> package
for weighted effect coding, a modified copy of the <code>contr.sdif</code>
function from the <span class="pkg">MASS</span> package for repeated coding, a modified copy
of the <code>code_helmert_forward</code> function from the <span class="pkg">codingMatrices</span>
for forward Helmert coding, a modified copy of the <code>contr_code_helmert</code>
function from the <span class="pkg">faux</span> package for reverse Helmert coding, and the
<code>contr.poly</code> function from the <span class="pkg">stats</span> package for orthogonal
polynomial coding.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rec">rec</a></code>, <code><a href="#topic+item.reverse">item.reverse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Dummy coding for 'gear', baseline group = 3
coding(gear, data = mtcars)

# Example 1b: Alterantive specification without using the 'data' argument
coding(mtcars$gear)

# Example 2: Dummy coding for 'gear', baseline group = 4
coding(gear, data = mtcars, base = 4)

# Example 3: Effect coding for 'gear', omitted group = 3
coding(gear, data = mtcars, type = "effect")

# Example 3: Effect coding for 'gear', omitted group = 4
coding(gear, data = mtcars, type = "effect", base = 4)

# Example 4a: Dummy-coded variable names with prefix "gear3."
coding(gear, data = mtcars, name = "gear3.")

# Example 4b: Dummy-coded variables named "gear_4vs3" and "gear_5vs3"
coding(gear, data = mtcars, name = c("gear_4vs3", "gear_5vs3"))
</code></pre>

<hr>
<h2 id='cohens.d'>Cohen's d</h2><span id='topic+cohens.d'></span><span id='topic+cohens.d.default'></span><span id='topic+cohens.d.formula'></span>

<h3>Description</h3>

<p>This function computes Cohen's d for one-sample, two-sample (i.e., between-subject design),
and paired-sample designs (i.e., within-subject design) for one or more variables, optionally
by a grouping and/or split variable. In a two-sample design, the function computes the
standardized mean difference by dividing the difference between  means of the two groups
of observations by the weighted pooled standard deviation (i.e., Cohen's <code class="reqn">d_s</code>
according to Lakens, 2013) by default. In a paired-sample design, the function computes the
standardized mean difference by dividing the mean of the difference scores by the standard
deviation of the difference scores (i.e., Cohen's <code class="reqn">d_z</code> according to Lakens, 2013) by
default. Note that by default Cohen's d is computed without applying the correction factor
for removing the small sample bias (i.e., Hedges' g).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cohens.d(x, ...)

## Default S3 method:
cohens.d(x, y = NULL, mu = 0, paired = FALSE, weighted = TRUE, cor = TRUE,
         ref = NULL, correct = FALSE, alternative = c("two.sided", "less", "greater"),
         conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
         digits = 2, as.na = NULL, write = NULL, append = TRUE,
         check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
cohens.d(formula, data, weighted = TRUE, cor = TRUE, ref = NULL,
         correct = FALSE, alternative = c("two.sided", "less", "greater"),
         conf.level = 0.95, group = NULL, split = NULL, sort.var = FALSE,
         na.omit = FALSE, digits = 2, as.na = NULL, write = NULL, append = TRUE,
         check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cohens.d_+3A_x">x</code></td>
<td>
<p>a numeric vector or data frame.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_y">y</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_mu">mu</code></td>
<td>
<p>a numeric value indicating the reference mean.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, Cohen's d for a paired-sample design is computed.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the weighted pooled standard deviation is used
to compute the standardized mean difference between two groups of a two-sample
design (i.e., <code>paired = FALSE</code>), while standard deviation of the difference
scores is used to compute the standardized mean difference in a paired-sample
design (i.e., <code>paired = TRUE</code>).</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_cor">cor</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), <code>paired = TRUE</code>, and <code>weighted = FALSE</code>,
Cohen's d for a paired-sample design while controlling for the correlation between
the two sets of measurement is computed. Note that this argument is only used in
a paired-sample design (i.e., <code>paired = TRUE</code>) when specifying <code>weighted = FALSE</code>.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_ref">ref</code></td>
<td>
<p>character string <code>"x"</code> or <code>"y"</code> for specifying the reference reference
group when using the default <code>cohens.d()</code> function or a numeric value or
character string indicating the reference group in a two-sample design when using
the formula <code>cohens.d()</code> function. The standard deviation of the reference variable
or reference group is used to standardized the mean difference.
Note that this argument is only used in a two-sample design (i.e., <code>paired = FALSE</code>).</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor to remove positive bias in small samples is
used.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of
<code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level of the interval.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_group">group</code></td>
<td>
<p>a numeric vector, character vector or factor as grouping variable.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_split">split</code></td>
<td>
<p>a numeric vector, character vector or factor as split variable.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used for
displaying results.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting the analysis.
Note that <code>as.na()</code> function is only applied to <code>y</code> but not to <code>group</code>
in a two-sample design, while <code>as.na()</code> function is applied to <code>pre</code>
and <code>post</code> in a paired-sample design.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> for one outcome variable or
<code>cbind(y1, y2, y3) ~ group</code> for more than one outcome variable where <code>y</code>
is a numeric variable giving the data values and <code>group</code> a numeric variable,
character variable or factor with two values or factor levels giving the
corresponding groups.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="cohens.d_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before conducting the analysis
(i.e., listwise deletion) when specifying more than one outcome variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cohen (1988, p.67) proposed to compute the standardized mean difference in a two-sample design
by dividing the mean difference by the unweighted pooled standard deviation (i.e.,
<code>weighted = FALSE</code>).
</p>
<p>Glass et al. (1981, p. 29) suggested to use the standard deviation of the control group
(e.g., <code>ref = 0</code> if the control group is coded with 0) to compute the standardized
mean difference in a two-sample design (i.e., Glass's <code class="reqn">\Delta</code>) since the standard deviation of the control group
is unaffected by the treatment and will therefore more closely reflect the population
standard deviation.
</p>
<p>Hedges (1981, p. 110) recommended to weight each group's standard deviation by its sample
size resulting in a weighted and pooled standard deviation (i.e., <code>weighted = TRUE</code>,
default). According to Hedges and Olkin (1985, p. 81), the standardized mean difference
based on the weighted and pooled standard deviation has a positive small sample bias,
i.e., standardized mean difference is overestimated in small samples (i.e., sample size
less than 20 or less than 10 in each group). However, a correction factor can be applied
to remove the small sample bias (i.e., <code>correct = TRUE</code>). Note that the function uses
a gamma function for computing the correction factor, while a approximation method is
used if computation based on the gamma function fails.
</p>
<p>Note that the terminology is inconsistent because the standardized mean difference based
on the weighted and pooled standard deviation is usually called Cohen's d, but sometimes
called Hedges' g. Oftentimes, Cohen's d is called Hedges' d as soon as the small sample
correction factor is applied. Cumming and Calin-Jageman (2017, p.171) recommended to avoid
the term Hedges' g , but to report which standard deviation was used to standardized the
mean difference (e.g., unweighted/weighted pooled standard deviation, or the standard
deviation of the control group) and whether a small sample correction factor was applied.
</p>
<p>As for the terminology according to Lakens (2013), in a two-sample design (i.e.,
<code>paired = FALSE</code>) Cohen's <code class="reqn">d_s</code> is computed when using <code>weighted = TRUE</code> (default)
and Hedges's <code class="reqn">g_s</code> is computed when using <code>correct = TRUE</code> in addition. In a
paired-sample design (i.e., <code>paired = TRUE</code>), Cohen's <code class="reqn">d_z</code> is computed when using
<code>weighted = TRUE, default</code>, while Cohen's <code class="reqn">d_{rm}</code> is computed when using
<code>weighted = FALSE</code> and <code>cor = TRUE, default</code> and Cohen's <code class="reqn">d_{av}</code> is computed when
using <code>weighted = FALSE</code> and <code>cor = FALSE</code>. Corresponding Hedges' <code class="reqn">g_z</code>, <code class="reqn">g_{rm}</code>,
and <code class="reqn">g_{av}</code> are computed when using <code>correct = TRUE</code> in addition.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>type of sample, i.e., one-, two-, or, paired-sample</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>x</code>, <code>group</code>,
and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.).
Academic Press.
</p>
<p>Cumming, G., &amp; Calin-Jageman, R. (2017). <em>Introduction to the new statistics: Estimation, open science,
&amp; beyond</em>. Routledge.
</p>
<p>Glass. G. V., McGaw, B., &amp; Smith, M. L. (1981). <em>Meta-analysis in social research</em>. Sage Publication.
</p>
<p>Goulet-Pelletier, J.-C., &amp; Cousineau, D. (2018) A review of effect sizes and their confidence intervals,
Part I: The Cohen's d family. <em>The Quantitative Methods for Psychology, 14</em>, 242-265.
https://doi.org/10.20982/tqmp.14.4.p242
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's estimator of effect size and related estimators.
<em>Journal of Educational Statistics, 6</em>(3), 106-128.
</p>
<p>Hedges, L. V. &amp; Olkin, I. (1985). <em>Statistical methods for meta-analysis</em>. Academic Press.
</p>
<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science:
A practical primer for t-tests and ANOVAs. <em>Frontiers in Psychology, 4</em>, 1-12.
https://doi.org/10.3389/fpsyg.2013.00863
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+effsize">effsize</a></code>, <code><a href="#topic+cor.matrix">cor.matrix</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat1 &lt;- data.frame(group1 = c(1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,
                              1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1),
                   group2 = c(1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2,
                              1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2),
                   group3 = c(1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1,
                              1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1),
                   x1 = c(3, 2, 5, 3, 6, 3, 2, 4, 6, 5, 3, 3, 5, 4,
                          4, 3, 5, 3, 2, 3, 3, 6, 6, 7, 5, 6, 6, 4),
                   x2 = c(4, 4, 3, 6, 4, 7, 3, 5, 3, 3, 4, 2, 3, 6,
                          3, 5, 2, 6, 8, 3, 2, 5, 4, 5, 3, 2, 2, 4),
                   x3 = c(7, 6, 5, 6, 4, 2, 8, 3, 6, 1, 2, 5, 8, 6,
                          2, 5, 3, 1, 6, 4, 5, 5, 3, 6, 3, 2, 2, 4))

#-------------------------------------------------------------------------------
# One-sample design

# Example 1: Cohen's d.z with two-sided 95% CI
# population mean = 3
cohens.d(dat1$x1, mu = 3)

# Example 2: Cohen's d.z (aka Hedges' g.z) with two-sided 95% CI
# population mean = 3, with small sample correction factor
cohens.d(dat1$x1, mu = 3, correct = TRUE)

# Example 3: Cohen's d.z for more than one variable with two-sided 95% CI
# population mean = 3
cohens.d(dat1[, c("x1", "x2", "x3")], mu = 3)

# Example 4: Cohen's d.z with two-sided 95% CI
# population mean = 3, by group1 separately
cohens.d(dat1$x1, mu = 3, group = dat1$group1)

# Example 5: Cohen's d.z for more than one variable with two-sided 95% CI
# population mean = 3, by group1 separately
cohens.d(dat1[, c("x1", "x2", "x3")], mu = 3, group = dat1$group1)

# Example 6: Cohen's d.z with two-sided 95% CI
# population mean = 3, split analysis by group1
cohens.d(dat1$x1, mu = 3, split = dat1$group1)

# Example 7: Cohen's d.z for more than one variable with two-sided 95% CI
# population mean = 3, split analysis by group1
cohens.d(dat1[, c("x1", "x2", "x3")], mu = 3, split = dat1$group1)

# Example 8: Cohen's d.z with two-sided 95% CI
# population mean = 3, by group1 separately1, split by group2
cohens.d(dat1$x1, mu = 3, group = dat1$group1, split = dat1$group2)

# Example 9: Cohen's d.z for more than one variable with two-sided 95% CI
# population mean = 3, by group1 separately1, split by group2
cohens.d(dat1[, c("x1", "x2", "x3")], mu = 3, group = dat1$group1,
         split = dat1$group2)

#-------------------------------------------------------------------------------
# Two-sample design

# Example 10: Cohen's d.s with two-sided 95% CI
# weighted pooled SD
cohens.d(x1 ~ group1, data = dat1)

# Example 11: Cohen's d.s with two-sided 99% CI
# weighted pooled SD
cohens.d(x1 ~ group1, data = dat1, conf.level = 0.99)

# Example 12: Cohen's d.s with one-sided 99% CI
# weighted pooled SD
cohens.d(x1 ~ group1, data = dat1, alternative = "greater")

# Example 13: Cohen's d.s with two-sided 99% CI
# weighted pooled SD
cohens.d(x1 ~ group1, data = dat1, conf.level = 0.99)

# Example 14: Cohen's d.s with one-sided 95%% CI
# weighted pooled SD
cohens.d(x1 ~ group1, data = dat1, alternative = "greater")

# Example 15: Cohen's d.s for more than one variable with two-sided 95% CI
# weighted pooled SD
cohens.d(cbind(x1, x2, x3) ~ group1, data = dat1)

# Example 16: Cohen's d with two-sided 95% CI
# unweighted SD
cohens.d(x1 ~ group1, data = dat1, weighted = FALSE)

# Example 17: Cohen's d.s (aka Hedges' g.s) with two-sided 95% CI
# weighted pooled SD, with small sample correction factor
cohens.d(x1 ~ group1, data = dat1, correct = TRUE)

# Example 18: Cohen's d (aka Hedges' g) with two-sided 95% CI
# Unweighted SD, with small sample correction factor
cohens.d(x1 ~ group1, data = dat1, weighted = FALSE, correct = TRUE)

# Example 19: Cohen's d (aka Glass's delta) with two-sided 95% CI
# SD of reference group 1
cohens.d(x1 ~ group1, data = dat1, ref = 1)

# Example 20: Cohen's d.s with two-sided 95% CI
# weighted pooled SD, by group2 separately
cohens.d(x1 ~ group1, data = dat1, group = dat1$group2)

# Example 21: Cohen's d.s for more than one variable with two-sided 95% CI
# weighted pooled SD, by group2 separately
cohens.d(cbind(x1, x2, x3) ~ group1, data = dat1, group = dat1$group2)

# Example 22: Cohen's d.s with two-sided 95% CI
# weighted pooled SD, split analysis by group2
cohens.d(x1 ~ group1, data = dat1, split = dat1$group2)

# Example 23: Cohen's d.s for more than one variable with two-sided 95% CI
# weighted pooled SD, split analysis by group2
cohens.d(cbind(x1, x2, x3) ~ group1, data = dat1, split = dat1$group2)

# Example 24: Cohen's d.s with two-sided 95% CI
# weighted pooled SD, by group2 separately, split analysis by group3
cohens.d(x1 ~ group1, data = dat1,
         group = dat1$group2, split = dat1$group3)

# Example 25: Cohen's d.s for more than one variable with two-sided 95% CI
# weighted pooled SD, by group2 separately, split analysis by group3
cohens.d(cbind(x1, x2, x3) ~ group1, data = dat1,
         group = dat1$group2, split = dat1$group3)

#-------------------------------------------------------------------------------
# Paired-sample design

# Example 26: Cohen's d.z with two-sided 95% CI
# SD of the difference scores
cohens.d(dat1$x1, dat1$x2, paired = TRUE)

# Example 27: Cohen's d.z with two-sided 99% CI
# SD of the difference scores
cohens.d(dat1$x1, dat1$x2, paired = TRUE, conf.level = 0.99)

# Example 28: Cohen's d.z with one-sided 95% CI
# SD of the difference scores
cohens.d(dat1$x1, dat1$x2, paired = TRUE, alternative = "greater")

# Example 29: Cohen's d.rm with two-sided 95% CI
# controlling for the correlation between measures
cohens.d(dat1$x1, dat1$x2, paired = TRUE, weighted = FALSE)

# Example 30: Cohen's d.av with two-sided 95% CI
# without controlling for the correlation between measures
cohens.d(dat1$x1, dat1$x2, paired = TRUE, weighted = FALSE, cor = FALSE)

# Example 31: Cohen's d.z (aka Hedges' g.z) with two-sided 95% CI
# SD of the differnece scores
cohens.d(dat1$x1, dat1$x2, paired = TRUE, correct = TRUE)

# Example 32: Cohen's d.rm (aka Hedges' g.rm) with two-sided 95% CI
# controlling for the correlation between measures
cohens.d(dat1$x1, dat1$x2, paired = TRUE, weighted = FALSE, correct = TRUE)

# Example 33: Cohen's d.av (aka Hedges' g.av) with two-sided 95% CI
# without controlling for the correlation between measures
cohens.d(dat1$x1, dat1$x2, paired = TRUE, weighted = FALSE, cor = FALSE,
         correct = TRUE)

# Example 34: Cohen's d.z with two-sided 95% CI
# SD of the difference scores, by group1 separately
cohens.d(dat1$x1, dat1$x2, paired = TRUE, group = dat1$group1)

# Example 35:  Cohen's d.z with two-sided 95% CI
# SD of the difference scores, split analysis by group1
cohens.d(dat1$x1, dat1$x2, paired = TRUE, split = dat1$group1)

# Example 36: Cohen's d.z with two-sided 95% CI
# SD of the difference scores, by group1 separately, split analysis by group2
cohens.d(dat1$x1, dat1$x2, paired = TRUE,
         group = dat1$group1, split = dat1$group2)
</code></pre>

<hr>
<h2 id='cor.matrix'>Correlation Matrix</h2><span id='topic+cor.matrix'></span>

<h3>Description</h3>

<p>This function computes a correlation matrix based on Pearson product-moment
correlation coefficient, Spearman's rank-order correlation coefficient,
Kendall's Tau-b correlation coefficient, Kendall-Stuart's Tau-c correlation
coefficient, tetrachoric correlation coefficient, or polychoric correlation
coefficient and computes significance values (<em>p</em>-values) for testing the
hypothesis H0: <code class="reqn">\rho</code> = 0 for all pairs of variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.matrix(..., data = NULL,
           method = c("pearson", "spearman", "kendall-b", "kendall-c", "tetra", "poly"),
           na.omit = FALSE, group = NULL, sig = FALSE, alpha = 0.05,
           print = c("all", "cor", "n", "stat", "df", "p"),
           tri = c("both", "lower", "upper"),
           p.adj = c("none", "bonferroni", "holm", "hochberg", "hommel",
                     "BH", "BY", "fdr"), continuity = TRUE,
           digits = 2, p.digits = 3, as.na = NULL,
           write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor.matrix_+3A_...">...</code></td>
<td>
<p>a matrix or data frame. Alternatively, an expression indicating
the variable names in <code>data</code> e.g.,
<code>cor.matrix(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_method">method</code></td>
<td>
<p>a character vector indicating which correlation coefficient
is to be computed, i.e. <code>"pearson"</code> for Pearson product-moment correlation
coefficient (default), <code>"spearman"</code> for Spearman's rank-order correlation
coefficient, <code>"kendall-b"</code> for Kendall's Tau-b correlation coefficient,
<code>"kendall-c"</code> for Kendall-Stuart's Tau-c correlation coefficient,
<code>"tetra"</code> for tetrachoric correlation coefficient, and <code>"poly"</code> for
polychoric correlation coefficient.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion); if <code>FALSE</code>
(default), pairwise deletion is used.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name of
the grouping variable in <code>...</code> or <code>data</code>, or a
vector representing the grouping variable. Note that the
grouping variable is limited to two groups.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_sig">sig</code></td>
<td>
<p>logical: if <code>TRUE</code>, statistically significant correlation
coefficients are shown in boldface on the console. Note that
this function does not provide statistical significance
testing for tetrachoric or polychoric correlation coefficients.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the significance
level at which correlation coefficients are printed boldface
when <code>sig = TRUE</code>.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results
to show on the console, i.e. <code>"all"</code> for all results,
<code>"cor"</code> for correlation coefficients, <code>"n"</code> for the
sample sizes, <code>"stat"</code> for the test statistic, <code>"df"</code>
for the degrees of freedom, and <code>"p"</code> for <em>p</em>-values.
Note that the function does not provide <em>p</em>-values for
tetrachoric or polychoric correlation coefficients.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_tri">tri</code></td>
<td>
<p>a character string indicating which triangular of the matrix
to show on the console, i.e., <code>both</code> for upper and lower
triangular, <code>lower</code> (default) for the lower triangular,
and <code>upper</code> for the upper triangular.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_p.adj">p.adj</code></td>
<td>
<p>a character string indicating an adjustment method for multiple
testing based on <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>, i.e., <code>none</code> ,
<code>bonferroni</code>, <code>holm</code> (default), <code>hochberg</code>,
<code>hommel</code>, <code>BH</code>, <code>BY</code>, or <code>fdr</code>.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_continuity">continuity</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), continuity correction is
used for testing Spearman's rank-order correlation coefficient
and Kendall's Tau-b correlation.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying correlation coefficients.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="cor.matrix_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that unlike the <code><a href="stats.html#topic+cor.test">cor.test</a></code> function, this
function does not compute an exact <em>p</em>-value for Spearman's rank-order
correlation coefficient or Kendall's Tau-b correlation coefficient, but uses
the asymptotic <em>t</em> approximation.
</p>
<p>Statistically significant correlation coefficients can be shown in boldface on
the console when specifying <code>sig = TRUE</code>. However, this option is not supported
when using R Markdown, i.e., the argument <code>sig</code> will switch to <code>FALSE</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>cor</code> for the
correlation matrix, <code>n</code> for a matrix with the sample
sizes, <code>stat</code> for a matrix with the test statistics,
<code>df</code> for a matrix with the degrees of freedom, and
<code>p</code>-value for the matrix with the significance values
(<em>p</em>-values)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses the <code>polychoric()</code> function in the <span class="pkg">psych</span>
package by William Revelle to estimate tetrachoric and polychoric correlation
coefficients.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Revelle, W. (2018) <em>psych: Procedures for personality and psychological
research</em>. Northwestern University, Evanston, Illinois, USA,
https://CRAN.R-project.org/package=psych Version = 1.8.12.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+effsize">effsize</a></code>,
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code>, <code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+size.cor">size.cor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Pearson product-moment correlation coefficient between 'Ozone' and 'Solar.R#
cor.matrix(airquality[, c("Ozone", "Solar.R")])

# Example 1b: Alternative specification using the 'data' argument
cor.matrix(Ozone, Solar.R, data = airquality)

# Example 2a: Pearson product-moment correlation matrix using pairwise deletion
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")])

# Example 2b: Alternative specification using the 'data' argument
cor.matrix(Ozone:Wind, data = airquality)

# Example 3: Spearman's rank-order correlation matrix
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], method = "spearman")

# Example 4: Pearson product-moment correlation matrix
# highlight statistically significant result at alpha = 0.05
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], sig = TRUE)

# Example 5: Pearson product-moment correlation matrix
# highlight statistically significant result at alpha = 0.05
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], sig = TRUE, alpha = 0.10)

# Example 6: Pearson product-moment correlation matrix
# print sample size and significance values
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], print = "all")

# Example 7: Pearson product-moment correlation matrix using listwise deletion,
# print sample size and significance values
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], na.omit = TRUE, print = "all")

# Example 8: Pearson product-moment correlation matrix
# print sample size and significance values with Bonferroni correction
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], na.omit = TRUE,
           print = "all", p.adj = "bonferroni")

# Example 9a: Pearson product-moment correlation matrix for 'mpg', 'cyl', and 'disp'
# results for group "0" and "1" separately
cor.matrix(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs)

# Example 9b: Alternative specification using the 'data' argument
cor.matrix(mpg:disp, data = mtcars, group = "vs")

## Not run: 
# Example 10a: Write results into a text file
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], print = "all", write = "Correlation.txt")

# Example 10b: Write results into an Excel file
cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], print = "all", write = "Correlation.xlsx")

result &lt;- cor.matrix(airquality[, c("Ozone", "Solar.R", "Wind")], print = "all", output = FALSE)
write.result(result, "Correlation.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='crosstab'>Cross Tabulation</h2><span id='topic+crosstab'></span>

<h3>Description</h3>

<p>This function creates a two-way and three-way cross tabulation with absolute
frequencies and row-wise, column-wise and total percentages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crosstab(...,  data = NULL, print = c("no", "all", "row", "col", "total"),
         freq = TRUE, split = FALSE, na.omit = TRUE, digits = 2, as.na = NULL,
         write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crosstab_+3A_...">...</code></td>
<td>
<p> a matrix or data frame with two or three columns. Alternatively,
an expression indicating the variable names in <code>data</code>.
Note, variable names are specified without quotes <code>''</code> or
double quotes <code>""</code>, e.g., <code>crosstab(x1, x2, data = dat)</code>.
Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument
<code>...</code>.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
percentage(s) to be printed on the console, i.e., no percentages
(<code>"no"</code>) (default), all percentages (<code>"all"</code>),
row-wise percentages (<code>"row"</code>), column-wise percentages
(<code>"col"</code>), and total percentages (<code>"total"</code>).</p>
</td></tr>
<tr><td><code id="crosstab_+3A_freq">freq</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), absolute frequencies will be included
in the cross tabulation.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is split in absolute
frequencies and percentage(s).</p>
</td></tr>
<tr><td><code id="crosstab_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), incomplete cases are removed before
conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="crosstab_+3A_digits">digits</code></td>
<td>
<p>an integer indicating the number of decimal places digits
to be used for displaying percentages.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="crosstab_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is printed on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>...</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>crosstab</code> for the
cross tabulation, <code>freq.a</code> for the absolute frequencies,
<code>perc.r</code> for the row-wise percentages, <code>perc.c</code>
for the column-wise percentages, <code>perc.t</code> for the total
percentages</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>
<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+freq">freq</a></code>, <code><a href="#topic+descript">descript</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>.
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Two-Dimensional Table

# Example 1a: Cross Tabulation for 'vs' and 'am'
crosstab(mtcars[, c("vs", "am")])

# Example 1b: Alternative specification using the 'data' argument
crosstab(vs, am, data = mtcars)

# Example 2: Cross Tabulation, print all percentages
crosstab(mtcars[, c("vs", "am")], print = "all")

# Example 3: Cross Tabulation, print row-wise percentages
crosstab(mtcars[, c("vs", "am")], print = "row")

# Example 4: Cross Tabulation, print col-wise percentages
crosstab(mtcars[, c("vs", "am")], print = "col")

# Example 5: Cross Tabulation, print total percentages
crosstab(mtcars[, c("vs", "am")], print = "total")

# Example 6: Cross Tabulation, print all percentages, split output table
crosstab(mtcars[, c("vs", "am")], print = "all", split = TRUE)

#----------------------------------------------------------------------------
# Three-Dimensional Table

# Example 7a: Cross Tabulation for 'vs', 'am', ane 'gear'
crosstab(mtcars[, c("vs", "am", "gear")])

# Example 7b: Alternative specification using the 'data' argument
crosstab(vs:gear, data = mtcars)

# Example 8: Cross Tabulation, print all percentages
crosstab(mtcars[, c("vs", "am", "gear")], print = "all")

# Example 9: Cross Tabulation, print all percentages, split output table
crosstab(mtcars[, c("vs", "am", "gear")], print = "all", split = TRUE)

## Not run: 
# Example 10a: Write results into a text file
crosstab(mtcars[, c("vs", "am")], print = "all", write = "Crosstab.txt")

# Example 10b: Write results into an Excel file
crosstab(mtcars[, c("vs", "am")], print = "all", write = "Crosstab.xlsx")

result &lt;- crosstab(mtcars[, c("vs", "am")], print = "all", output = FALSE)
write.result(result, "Crosstab.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='descript'>Descriptive Statistics</h2><span id='topic+descript'></span>

<h3>Description</h3>

<p>This function computes summary statistics for one or more than one variables, optionally
by a grouping and/or split variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>descript(..., data = NULL,
        print = c("all", "n", "nNA", "pNA", "m", "se.m", "var", "sd", "min",
                  "p25", "med", "p75", "max", "range", "iqr", "skew", "kurt"),
        group = NULL, split = NULL, sort.var = FALSE, na.omit = FALSE, digits = 2,
        as.na = NULL, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="descript_+3A_...">...</code></td>
<td>
<p>a numeric vector, matrix or data frame with numeric variables,
i.e., factors and character variables are excluded from <code>...</code>
before conducting the analysis. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>descript(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="descript_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector, matrix, or data frame for
the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="descript_+3A_print">print</code></td>
<td>
<p>a character vector indicating which statistical measures to be
printed on the console, i.e. <code>n</code> (number of observations),
<code>nNA</code> (number of missing values), <code>pNA</code> (percentage of
missing values), <code>m</code> (arithmetic mean), <code>se.m</code> (standard
error of the arithmetic mean), <code>var</code> (variance), <code>sd</code>
(standard deviation), <code>med</code> (median),<code>min</code> (minimum),
<code>p25</code> (25th percentile, first quartile), <code>p75</code> (75th
percentile, third quartile), <code>max</code> (maximum),  <code>range</code>
(range), <code>iqr</code> (interquartile range), <code>skew</code> (skewness),
and <code>kurt</code> (excess kurtosis). The default setting is
<code>print = ("n", "nNA", "pNA", "m", "sd", "min", "max", "skew", "kurt")</code>.</p>
</td></tr>
<tr><td><code id="descript_+3A_group">group</code></td>
<td>
<p>a numeric vector, character vector or factor as grouping variable.
Alternatively, a character string indicating the variable name
of the grouping variable in <code>data</code> can be specified.</p>
</td></tr>
<tr><td><code id="descript_+3A_split">split</code></td>
<td>
<p>a numeric vector, character vector or factor as split variable.
Alternatively, a character string indicating the variable name
of the split variable in <code>data</code> can be specified.</p>
</td></tr>
<tr><td><code id="descript_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is sorted by variables when
specifying <code>group</code>.</p>
</td></tr>
<tr><td><code id="descript_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="descript_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used.</p>
</td></tr>
<tr><td><code id="descript_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied
to <code>...</code>, but not to <code>group</code> or <code>split</code>.</p>
</td></tr>
<tr><td><code id="descript_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="descript_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="descript_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="descript_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>...</code>, <code>group</code>,
and <code>split</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table(s)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.mean">ci.mean</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.median">ci.median</a></code>,
<code><a href="#topic+ci.prop">ci.prop</a></code>, <code><a href="#topic+ci.prop.diff">ci.prop.diff</a></code>, <code><a href="#topic+ci.var">ci.var</a></code>,
<code><a href="#topic+ci.sd">ci.sd</a></code>, <code><a href="#topic+freq">freq</a></code>, <code><a href="#topic+crosstab">crosstab</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Descriptive statistics for 'mpg'
descript(mtcars$mpg)

# Example 1b: Alternative specification using the 'data' argument
descript(mpg, data = mtcars)

# Example 2: Descriptive statistics, print results with 3 digits
descript(mtcars$mpg, digits = 3)

# Example 3: Descriptive statistics for x1, print all available statistical measures
descript(mtcars$mpg, print = "all")

# Example 4a: Descriptive statistics for 'mpg', 'cyl', and 'disp'
descript(mtcars[, c("mpg", "cyl", "disp")])

# Example 4b: Alternative specification using the 'data' argument
descript(mpg:disp, data = mtcars)

# Example 5a: Descriptive statistics, analysis by 'vs' separately
descript(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs)

# Example 5b: Alternative specification using the 'data' argument
descript(mpg:disp, data = mtcars, group = "vs")

# Example 6: Descriptive statistics, analysis by 'vs' separately, sort by variables
descript(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs, sort.var = TRUE)

# Example 7: Descriptive statistics, split analysis by 'am'
descript(mtcars[, c("mpg", "cyl", "disp")], split = mtcars$am)

# Example 8a: Descriptive statistics,analysis by 'vs' separately, split analysis by 'am'
descript(mtcars[, c("mpg", "cyl", "disp")], group = mtcars$vs, split = mtcars$am)

# Example 8b: Alternative specification using the 'data' argument
descript(mpg:disp, data = mtcars, group = "vs", split = "am")

## Not run: 
# Example 11a: Write results into a text file
descript(mtcars[, c("mpg", "cyl", "disp")], write = "Descript.txt")

# Example 11b: Write results into an Excel file
descript(mtcars[, c("mpg", "cyl", "disp")], write = "Descript.xlsx")

result &lt;- descript(mtcars[, c("mpg", "cyl", "disp")], output = FALSE)
write.result(result, "Descript.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='df.duplicated'>Extract Duplicated or Unique Rows</h2><span id='topic+df.duplicated'></span><span id='topic+df.unique'></span>

<h3>Description</h3>

<p>The function <code>df.duplicated</code> extracts duplicated rows and the function
<code>df.unique</code> extracts unique rows from a matrix or data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.duplicated(..., data, first = TRUE, keep.all = TRUE, from.last = FALSE,
              keep.row.names = TRUE, check = TRUE)

df.unique(..., data, keep.all = TRUE, from.last = FALSE,
          keep.row.names = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df.duplicated_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code>
used to determine duplicated or unique rows.e.g.,
<code>df.duplicated(x1, x2, data = dat)</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select
variables, see Details in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_first">first</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the <code>df.duplicated()</code>
function will return duplicated rows including the first of identical
rows.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_keep.all">keep.all</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the function will return all
variables in <code>x</code> after extracting duplicated or unique rows based
on the variables specified in the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_from.last">from.last</code></td>
<td>
<p>logical: if <code>TRUE</code>, duplication will be considered
from the reversed side, i.e., the last of identical rows
would correspond to <code>duplicated = FALSE</code>.
Note that this argument is only used when <code>first = FALSE</code>.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_keep.row.names">keep.row.names</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the row names from <code>x</code> are kept,
otherwise they are set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="df.duplicated_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>df.unique(x)</code> is equivalent to <code>unique(x)</code>. That is, the
main difference between the <code>df.unique()</code> and the <code>unique()</code> function is
that the <code>df.unique()</code> function provides the <code>...</code> argument to
specify a variable or multiple variables which are used to determine unique rows.
</p>


<h3>Value</h3>

<p>Returns duplicated or unique rows of the data frame in <code>...</code> or <code>data</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(x1 = c(1, 1, 2, 1, 4),
                  x2 = c(1, 1, 2, 1, 6),
                  x3 = c(2, 2, 3, 2, 6),
                  x4 = c(1, 1, 2, 2, 4),
                  x5 = c(1, 1, 4, 4, 3))

#-------------------------------------------------------------------------------
# df.duplicated() function

# Example 1: Extract duplicated rows based on all variables
df.duplicated(., data = dat)

# Example 2: Extract duplicated rows based on x4
df.duplicated(x4, data = dat)

# Example 3: Extract duplicated rows based on x2 and x3
df.duplicated(x2, x3, data = dat)

# Example 4: Extract duplicated rows based on all variables
# exclude first of identical rows
df.duplicated(., data = dat, first = FALSE)

# Example 5: Extract duplicated rows based on x2 and x3
# do not return all variables
df.duplicated(x2, x3, data = dat, keep.all = FALSE)

# Example 6: Extract duplicated rows based on x4
# consider duplication from the reversed side
df.duplicated(x4, data = dat, first = FALSE, from.last = TRUE)

# Example 7: Extract duplicated rows based on x2 and x3
# set row names to NULL
df.duplicated(x2, x3, data = dat, keep.row.names = FALSE)

#-------------------------------------------------------------------------------
# df.unique() function

# Example 8: Extract unique rows based on all variables
df.unique(., data = dat)

# Example 9: Extract unique rows based on x4
df.unique(x4, data = dat)

# Example 10: Extract unique rows based on x1, x2, and x3
df.unique(x1, x2, x3, data = dat)

# Example 11: Extract unique rows based on x2 and x3
# do not return all variables
df.unique(x2, x3, data = dat, keep.all = FALSE)

# Example 12: Extract unique rows based on x4
# consider duplication from the reversed side
df.unique(x4, data = dat, from.last = TRUE)

# Example 13: Extract unique rows based on x2 and x3
# set row names to NULL
df.unique(x2, x3, data = dat, keep.row.names = FALSE)
</code></pre>

<hr>
<h2 id='df.merge'>Merge Multiple Data Frames</h2><span id='topic+df.merge'></span>

<h3>Description</h3>

<p>This function merges data frames by a common column (i.e., matching variable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.merge(..., by, all = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df.merge_+3A_...">...</code></td>
<td>
<p>a sequence of matrices or data frames and/or matrices to be merged to one.</p>
</td></tr>
<tr><td><code id="df.merge_+3A_by">by</code></td>
<td>
<p>a character string indicating the column used for merging (i.e., matching variable),
see 'Details'.</p>
</td></tr>
<tr><td><code id="df.merge_+3A_all">all</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), then extra rows with <code>NA</code>s will be added
to the output for each row in a data frame that has no matching row in
another data frame.</p>
</td></tr>
<tr><td><code id="df.merge_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="df.merge_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are following requirements for merging multiple data frames: First, each data frame
has the same matching variable specified in the <code>by</code> argument. Second, matching variable
in the data frames have all the same class. Third, there are no duplicated values in the
matching variable in each data frame. Fourth, there are no missing values in the matching
variables. Last, there are no duplicated variable names across the data frames except for
the matching variable.
</p>
<p>Note that it is possible to specify data frames matrices and/or in the argument <code>...</code>.
However, the function always returns a data frame.
</p>


<h3>Value</h3>

<p>Returns a merged data frame.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>adat &lt;- data.frame(id = c(1, 2, 3),
                   x1 = c(7, 3, 8))

bdat &lt;- data.frame(id = c(1, 2),
                   x2 = c(5, 1))

cdat &lt;- data.frame(id = c(2, 3),
                   y3 = c(7, 9))

ddat &lt;- data.frame(id = 4,
                   y4 = 6)

# Merge adat, bdat, cdat, and data by the variable id
df.merge(adat, bdat, cdat, ddat, by = "id")

# Do not show output on the console
df.merge(adat, bdat, cdat, ddat, by = "id", output = FALSE)

adat &lt;- data.frame(id = c(1, 2, 3),
                   x1 = c(7, 3, 8))

bdat &lt;- data.frame(id = c(1, 2),
                   x2 = c(5, 1))

cdat &lt;- data.frame(id = c(2, 3),
                   y3 = c(7, 9))

ddat &lt;- data.frame(id = 4,
                   y4 = 6)

# Example 1: Merge adat, bdat, cdat, and data by the variable id
df.merge(adat, bdat, cdat, ddat, by = "id")

# Example 2: Do not show output on the console
df.merge(adat, bdat, cdat, ddat, by = "id", output = FALSE)

## Not run: 
#-------------------------------------------------------------------------------
# Error messages

adat &lt;- data.frame(id = c(1, 2, 3),
                   x1 = c(7, 3, 8))

bdat &lt;- data.frame(code = c(1, 2, 3),
                   x2 = c(5, 1, 3))

cdat &lt;- data.frame(id = factor(c(1, 2, 3)),
                   x3 = c(5, 1, 3))

ddat &lt;- data.frame(id = c(1, 2, 2),
                   x2 = c(5, 1, 3))

edat &lt;- data.frame(id = c(1, NA, 3),
                   x2 = c(5, 1, 3))

fdat &lt;- data.frame(id = c(1, 2, 3),
                   x1 = c(5, 1, 3))

# Error 1: Data frames do not have the same matching variable specified in 'by'.
df.merge(adat, bdat, by = "id")

# Error 2: Matching variable in the data frames do not all have the same class.
df.merge(adat, cdat, by = "id")

# Error 3: There are duplicated values in the matching variable specified in 'by'.
df.merge(adat, ddat, by = "id")

# Error 4: There are missing values in the matching variable specified in 'by'.
df.merge(adat, edat, by = "id")

# Error 5: There are duplicated variable names across data frames.
df.merge(adat, fdat, by = "id")

## End(Not run)
</code></pre>

<hr>
<h2 id='df.move'>Move Variable(s) in a Data Frame</h2><span id='topic+df.move'></span>

<h3>Description</h3>

<p>This function moves variables to a different position in the data frame, i.e.,
changes the column positions in the data frame. By default, variables specified
in the first argument <code>...</code> are moved to the first position in the data
frame specified in the argument <code>data</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.move(..., data = NULL, before = NULL, after = NULL, first = TRUE, check = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df.move_+3A_...">...</code></td>
<td>
<p>an expression indicating the variable names in <code>data</code> to
move. Note that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also be used to
select variables, see Details in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="df.move_+3A_data">data</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.move_+3A_before">before</code></td>
<td>
<p>a character string indicating a variable in <code>data</code>.
Variable(s) specified in <code>...</code> are moved to the left-hand
side of this variable.</p>
</td></tr>
<tr><td><code id="df.move_+3A_after">after</code></td>
<td>
<p>a character string indicating a variable in <code>data</code>.
Variable(s) specified in <code>...</code> are moved to the right-hand
side of this variable.</p>
</td></tr>
<tr><td><code id="df.move_+3A_first">first</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable(s) specified in
<code>...</code> will be moved to the first position in 'data', if
<code>FALSE</code>, variable(s) specified in <code>...</code> will be moved
to the last position in 'data'.</p>
</td></tr>
<tr><td><code id="df.move_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the data frame in <code>data</code> with columns in a different place.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Move variables 'hp' and 'am' to the first position
df.move(hp, am, data = mtcars)

# Example 2: Move variables 'hp' and 'am' to the last position
df.move(hp, am, data = mtcars, first = FALSE)

# Example 3: Move variables 'hp' and 'am' to the left-hand side of 'disp'
df.move(hp, am, data = mtcars, before = "disp")

# Example 4: Move variables 'hp' and 'am' to the right-hand side of 'disp'
df.move(hp, am, data = mtcars, after = "disp")
</code></pre>

<hr>
<h2 id='df.rbind'>Combine Data Frames by Rows, Filling in Missing Columns</h2><span id='topic+df.rbind'></span>

<h3>Description</h3>

<p>This function takes a sequence of data frames and combines them by rows, while filling in missing
columns with <code>NA</code>s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.rbind(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df.rbind_+3A_...">...</code></td>
<td>
<p>a sequence of data frame to be row bind together. This argument can be a
list of data frames, in which case all other arguments are ignored.
Any <code>NULL</code> inputs are silently dropped. If all inputs are <code>NULL</code>,
the output is also <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an enhancement to <code><a href="base.html#topic+rbind">rbind</a></code> that adds in columns that are not present in all inputs,
accepts a sequence of data frames, and operates substantially faster.
</p>
<p>Column names and types in the output will appear in the order in which they were encountered.
</p>
<p>Unordered factor columns will have their levels unified and character data bound with factors will
be converted to character. POSIXct data will be converted to be in the same time zone.
Array and matrix columns must have identical dimensions after the row count. Aside from these there
are no general checks that each column is of consistent data type.
</p>


<h3>Value</h3>

<p>Returns a single data frame
</p>


<h3>Note</h3>

<p>This function is a copy of the <code>rbind.fill()</code> function in the <span class="pkg">plyr</span>
package by Hadley Wickham.
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham
</p>


<h3>References</h3>

<p>Wickham, H. (2011). The split-apply-combine strategy for data analysis.
<em>Journal of Statistical Software, 40</em>, 1-29. https://doi.org/10.18637/jss.v040.i01
</p>
<p>Wickham, H. (2019). plyr: Tools for Splitting, Applying and Combining Data. R package
version 1.8.5.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>adat &lt;- data.frame(id = c(1, 2, 3),
                   a = c(7, 3, 8),
                   b = c(4, 2, 7))

bdat &lt;- data.frame(id = c(4, 5, 6),
                   a = c(2, 4, 6),
                   c = c(4, 2, 7))

cdat &lt;- data.frame(id = c(7, 8, 9),
                   a = c(1, 4, 6),
                   d = c(9, 5, 4))

# Example 1
df.rbind(adat, bdat, cdat)
</code></pre>

<hr>
<h2 id='df.rename'>Rename Columns in a Matrix or Variables in a Data Frame</h2><span id='topic+df.rename'></span>

<h3>Description</h3>

<p>This function renames columns in a matrix or variables in a data frame by specifying a character string or
character vector indicating the columns or variables to be renamed and a character string or character
vector indicating the corresponding replacement values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.rename(x, from, to, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df.rename_+3A_x">x</code></td>
<td>
<p>a matrix or data frame.</p>
</td></tr>
<tr><td><code id="df.rename_+3A_from">from</code></td>
<td>
<p>a character string or character vector indicating the column(s) or variable(s) to be renamed.</p>
</td></tr>
<tr><td><code id="df.rename_+3A_to">to</code></td>
<td>
<p>a character string or character vector indicating the corresponding replacement values for
the column(s) or variable(s) specified in the argument <code>name</code>.</p>
</td></tr>
<tr><td><code id="df.rename_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix or data frame with renamed columns or variables.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.sort">df.sort</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(a = c(3, 1, 6),
                  b = c(4, 2, 5),
                  c = c(7, 3, 1))

# Example 1: Rename variable b in the data frame 'dat' to y
df.rename(dat, from = "b", to = "y")

# Example 2: Rename variable a, b, and c in the data frame 'dat' to x, y, and z
df.rename(dat, from = c("a", "b", "c"), to = c("x", "y", "z"))
</code></pre>

<hr>
<h2 id='df.sort'>Data Frame Sorting</h2><span id='topic+df.sort'></span>

<h3>Description</h3>

<p>This function arranges a data frame in increasing or decreasing order according to one or more variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.sort(x, ..., decreasing = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df.sort_+3A_x">x</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="df.sort_+3A_...">...</code></td>
<td>
<p>a sorting variable or a sequence of sorting variables which are specified without
quotes <code>''</code> or double quotes <code>""</code>.</p>
</td></tr>
<tr><td><code id="df.sort_+3A_decreasing">decreasing</code></td>
<td>
<p>logical: if <code>TRUE</code>, the sort is decreasing.</p>
</td></tr>
<tr><td><code id="df.sort_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data frame <code>x</code> sorted according to the variables specified in <code>...</code>, a matrix will
be coerced to a data frame.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>Knuth, D. E. (1998) <em>The Art of Computer Programming, Volume 3: Sorting and Searching</em> (2nd ed.). Addison-Wesley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>,
<code><a href="#topic+df.subset">df.subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(x = c(5, 2, 5, 5, 7, 2),
                  y = c(1, 6, 2, 3, 2, 3),
                  z = c(2, 1, 6, 3, 7, 4))

# Example 1: Sort data frame 'dat' by "x" in increasing order
df.sort(dat, x)

# Example 2: Sort data frame 'dat' by "x" in decreasing order
df.sort(dat, x, decreasing = TRUE)

# Example 3: Sort data frame 'dat' by "x" and "y" in increasing order
df.sort(dat, x, y)

# Example 4: Sort data frame 'dat' by "x" and "y" in decreasing order
df.sort(dat, x, y, decreasing = TRUE)
</code></pre>

<hr>
<h2 id='df.subset'>Subsetting Data Frames</h2><span id='topic+df.subset'></span>

<h3>Description</h3>

<p>This function returns subsets of data frames which meet conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.subset(..., data, subset = NULL, drop = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df.subset_+3A_...">...</code></td>
<td>
<p>an expression indicating variables to select from the data frame
specified in <code>data</code>. See Details for the list of operators
used in this function, i.e., <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code>.</p>
</td></tr>
<tr><td><code id="df.subset_+3A_data">data</code></td>
<td>
<p>a data frame that contains the variables specified in the
argument <code>...</code>. Note that if <code>data = NULL</code>, only the
variables specified in <code>...</code> are returned.</p>
</td></tr>
<tr><td><code id="df.subset_+3A_subset">subset</code></td>
<td>
<p>character string with a logical expression indicating rows to
keep, e.g., <code>"x == 1"</code>, <code>"x1 == 1 &amp; x2 == 3"</code>, or
<code>"gender == 'female'"</code>. By default, all rows of the data frame specified
in <code>data</code> are kept. Note that logical queries for rows
resulting in missing values are not select.</p>
</td></tr>
<tr><td><code id="df.subset_+3A_drop">drop</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), data frame with a single
column is converted into a vector.</p>
</td></tr>
<tr><td><code id="df.subset_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>...</code> is used to specify an epxression indicating the
variables to select from the data frame specified in <code>data</code>, e.g.,
<code>df.subset(x1, x2, x3, data = dat)</code>. There are seven operators which
can be used in the expression <code>...</code>:
</p>

<dl>
<dt><strong>Dot (<code>.</code>) Operator</strong></dt><dd><p>The dot operator is used to select
all variables from the data frame specified in <code>data</code>. For example,
<code>df.subset(., data = dat)</code> selects all variables in <code>dat</code>. Note
that this operator is similar to the function <code>everything()</code> from the
<span class="pkg">tidyselect</span> package.</p>
</dd>
<dt><strong>Plus (<code>+</code>) Operator</strong></dt><dd><p>The plus operator is used to select
variables matching a prefix from the data frame specified in <code>data</code>. For
example, <code>df.subset(+x, data = dat)</code> selects all variables with the
prefix <code>x</code>. Note that this operator is equivalent to the function
<code>starts_with()</code> from the <span class="pkg">tidyselect</span> package.</p>
</dd>
<dt><strong>Minus (<code>-</code>) Operator</strong></dt><dd><p>The minus operator is used to select
variables matching a suffix from the data frame specified in <code>data</code>. For
example, <code>df.subset(-y, data = dat)</code> selects all variables with the
suffix <code>y</code>. Note that this operator is equivalent to the function
<code>ends_with()</code> from the <span class="pkg">tidyselect</span> package.</p>
</dd>
<dt><strong>Tilde (<code>~</code>) Operator</strong></dt><dd><p>The tilde operator is used to select
variables containg a word from the data frame specified in <code>data</code>. For
example, <code>df.subset(?al, data = dat)</code> selects all variables with the word
<code>al</code>. Note that this operator is equivalent to the function
<code>contains()</code> from the <span class="pkg">tidyselect</span> package.</p>
</dd>
<dt><strong>Colon (<code>:</code>) operator</strong></dt><dd><p>The colon operator is used to select
a range of consecutive variables from the data frame specified in <code>data</code>.
For example, <code>df.subset(x:z, data = dat)</code> selects all variables from
<code>x</code> to <code>z</code>. Note that this operator is equivalent to the <code>:</code>
operator from the <code>select</code> function in the <span class="pkg">dplyr</span> package.</p>
</dd>
<dt><strong>Double Colon (<code>::</code>) Operator</strong></dt><dd><p>The double colon operator
is used to select numbered variables from the data frame specified in
<code>data</code>. For example, <code>df.subset(x1::x3, data = dat)</code> selects the
variables <code>x1</code>, <code>x2</code>, and <code>x3</code>. Note that this operator is
similar to the function <code>num_range()</code> from the <span class="pkg">tidyselect</span>
package.</p>
</dd>
<dt><strong>Exclamation Point (<code>!</code>) Operator</strong></dt><dd><p>The exclamation point
operator is used to drop variables from the data frame specified in <code>data</code>
or for taking the complement of a set of variables. For example,
<code>df.subset(., !x, data = dat)</code> selects all variables but <code>x</code> in
<code>dat</code>., <code>df.subset(., !~x, data = dat)</code> selects all variables but
variables with the prefix <code>x</code>, or <code>df.subset(x:z, !x1:x3, data = dat)</code>
selects all variables from <code>x</code> to <code>z</code> but excludes all variables
from <code>x1</code> to <code>x3</code>. Note that this operator is equivalent to the <code>!</code>
operator from the <code>select</code> function in the <span class="pkg">dplyr</span> package.</p>
</dd></dl>

<p>Note that operators can be combined within the same function call. For example,
<code>df.subset(+x, -y, !x2:x4, z, data = dat)</code> selects all variables with
the prefix <code>x</code> and with the suffix <code>y</code> but excludes variables from
<code>x2</code> to <code>x4</code> and select variable <code>z</code>.
</p>


<h3>Value</h3>

<p>Returns a data frame containing the variables and rows selected in the argument
<code>...</code> and rows selected in the argument <code>subset</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.duplicated">df.duplicated</a></code>, <code><a href="#topic+df.merge">df.merge</a></code>,
<code><a href="#topic+df.move">df.move</a></code>, <code><a href="#topic+df.rbind">df.rbind</a></code>,
<code><a href="#topic+df.rename">df.rename</a></code>, <code><a href="#topic+df.sort">df.sort</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#-------------------------------------------------------------------------------
# Select single variables

# Example 1: Select 'Sepal.Length' and 'Petal.Width'
df.subset(Sepal.Length, Petal.Width, data = iris)

#-------------------------------------------------------------------------------
# Select all variables using the \code{.} operator

# Example 2a: Select all variables, select rows with 'Species' equal 'setosa'
# Note that single quotation marks (\code{''}) are needed to specify 'setosa'
df.subset(., data = iris, subset = "Species == 'setosa'")

# Example 2b: Select all variables, select rows with 'Petal.Length' smaller 1.2
df.subset(., data = iris, subset = "Petal.Length &lt; 1.2")

#-------------------------------------------------------------------------------
# Select variables matching a prefix using the \code{+} operator

# Example 3: Select variables with prefix 'Petal'
df.subset(+Petal, data = iris)

#-------------------------------------------------------------------------------
# Select variables matching a suffix using the \code{-} operator

# Example 4: Select variables with suffix 'Width'
df.subset(-Width, data = iris)

#-------------------------------------------------------------------------------
# Select variables containing a word using the \code{~} operator
# Example 5: Select variables containing 'al'
df.subset(~al, data = iris)

#-------------------------------------------------------------------------------
# Select consecutive variables using the \code{:} operator

# Example 6: Select all variables from 'Sepal.Width' to 'Petal.Width'
df.subset(Sepal.Width:Petal.Width, data = iris)

#-------------------------------------------------------------------------------
# Select numbered variables using the \code{::} operator

# Example 7: Select all variables from 'x1' to 'x3' and 'y1' to 'y3'
df.subset(x1::x3, y1::y3, data = anscombe)

#-------------------------------------------------------------------------------
# Drop variables using the \code{!} operator

# Example 8a: Select all variables but 'Sepal.Width'
df.subset(., !Sepal.Width, data = iris)

# Example 8b: Select all variables but 'Sepal.Width' to 'Petal.Width'
df.subset(., !Sepal.Width:Petal.Width, data = iris)

#----------------------------------------------------------------------------
# Combine \code{+}, \code{-} , \code{!}, and \code{:} operators

# Example 9: Select variables with prefix 'x' and suffix '3', but exclude
# variables from 'x2' to 'x3'
df.subset(+x, -3, !x2:x3, data = anscombe)

## End(Not run)
</code></pre>

<hr>
<h2 id='dominance'>Dominance Analysis</h2><span id='topic+dominance'></span>

<h3>Description</h3>

<p>This function conducts dominance analysis (Budescu, 1993; Azen &amp; Budescu, 2003)
for linear models estimated by using the <code>lm()</code> function to determine the
relative importance of predictor variables. By default, the function reports
general dominance, but conditional and complete dominance can be requested by
specifying the argument <code>print</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dominance(model, print = c("all", "gen", "cond", "comp"), digits = 3,
          write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dominance_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>lm</code>.</p>
</td></tr>
<tr><td><code id="dominance_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results
to show on the console, i.e. <code>"all"</code> for all results, <code>"gen"</code>
for general dominance, <code>"cond"</code> for conditional dominance,
and <code>"comp"</code> for complete dominance.</p>
</td></tr>
<tr><td><code id="dominance_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying results. Note that the percentage relative
importance of predictors are printed with <code>digits</code> minus 1
decimal places.</p>
</td></tr>
<tr><td><code id="dominance_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="dominance_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="dominance_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="dominance_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Dominance analysis (Budescu, 1993; Azen &amp; Budescu, 2003) is used to determine
the relative importance of predictor variables in a statistical model by examining
the additional contribution of predictors in <em>R</em>-squared relative to each
other in all of the possible <code class="reqn">2^{(p - 2)}</code> subset models with <code class="reqn">p</code> being
the number of predictors. Three levels of dominance can be established through
pairwise comparison of all predictors in a regression model:
</p>

<dl>
<dt><strong>Complete Dominance</strong></dt><dd><p>A predictor completely dominates another
predictor if its additional contribution in <em>R</em>-Squared is higher than that
of the other predictor across all possible subset models that do not include both
predictors. For example, in a regression model with four predictors, <code class="reqn">X_1</code>
completely dominates <code class="reqn">X_2</code> if the additional contribution in <em>R</em>-squared
for <code class="reqn">X_1</code> is higher compared to <code class="reqn">X_2</code> in (1) the null model without any
predictors, (2) the model including <code class="reqn">X_3</code>, (3) the model including
<code class="reqn">X_4</code>, and (4) the model including both <code class="reqn">X_3</code> and <code class="reqn">X_4</code>. Note
that complete dominance cannot be established if one predictor's additional
contribution is greater than the other's for some, but not all of the subset
models. In this case, dominance is undetermined and the result will be <code>NA</code></p>
</dd>
<dt><strong>Conditional Dominance</strong></dt><dd><p>A predictor conditionally dominates another
predictor if its average additional contribution in <em>R</em>-squared is higher
within each model size than that of the other predictor. For example, in a
regression model with four predictors, <code class="reqn">X_1</code> conditionally dominates <code class="reqn">X_2</code>
if the average additional contribution in <em>R</em>-squared is higher compared
to <code class="reqn">X_2</code> in (1) the null model without any predictors, (2) the four models
including one predictor, (3) the six models including two predictors, and (4)
the four models including three predictors.</p>
</dd>
<dt><strong>General Dominance</strong></dt><dd><p>A predictor generally dominates another predictor
if its overall averaged additional contribution in <em>R</em>-squared is higher
than that of the other predictor. For example, in a regression model with four
predictors, <code class="reqn">X_1</code> generally dominates <code class="reqn">X_2</code> if the average across the
four conditional values (i.e., null model, model with one predictor, model with
two predictors, and model with three predictors) is higher than that of <code class="reqn">X_2</code>.
Note that the general dominance measures represent the proportional contribution
that each predictor makes to the <em>R</em>-squared since their sum across all
predictors equals the  <em>R</em>-squared of the full model.</p>
</dd>
</dl>

<p>The three levels of dominance are related to each other in a hierarchical fashion:
Complete dominance implies conditional dominance, which in turn implies general
dominance. However, the converse may not hold for more than three predictors.
That is, general dominance does not imply conditional dominance, and conditional
dominance does not necessarily imply complete dominance.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in <code>model</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with results, i.e., <code>gen</code> for general dominance,
<code>cond</code> for conditional dominance, <code>comp</code> for complete dominance,
and <code>condtsat</code> for the statistics of the conditional dominance</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on the <code>domir</code> function from the <code>domir</code>
package (Luchman, 2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Azen, R., &amp; Budescu, D. V. (2003). The dominance analysis approach for comparing
predictors in multiple regression. <em>Psychological Methods, 8</em>(2), 129–148.
https://doi.org/10.1037/1082-989X.8.2.129
</p>
<p>Budescu, D. V. (1993). Dominance analysis: A new approach to the problem of
relative importance of predictors in multiple regression. <em>Psychological Bulletin, 114</em>(3),
542–551. https://doi.org/10.1037/0033-2909.114.3.542
</p>
<p>Luchman J (2023). <em>domir: Tools to support relative importance analysis</em>. R package
version 1.0.1, https://CRAN.R-project.org/package=domir.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dominance.manual">dominance.manual</a></code>, <code><a href="#topic+std.coef">std.coef</a></code>, <code><a href="#topic+write.result">write.result</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Example 1: Dominance analysis for a linear model

mod &lt;- lm(mpg ~ cyl + disp + hp, data = mtcars)
dominance(mod)

# Print all results
dominance(mod, print = "all")

## Not run: 
#----------------------------------------------------------------------------
# Example 2: Write results into a text file

dominance(mod, write = "Dominance.txt", output = FALSE)

#----------------------------------------------------------------------------
# Example 3: Write results into an Excel file

dominance(mod, write = "Dominance.xlsx", output = FALSE)

result &lt;- dominance(mod, print = "all", output = FALSE)
write.result(result, "Dominance.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='dominance.manual'>Dominance Analysis, Manually Inputting a Correlation Matrix</h2><span id='topic+dominance.manual'></span>

<h3>Description</h3>

<p>This function conducts dominance analysis (Budescu, 1993; Azen &amp; Budescu, 2003)
based on a (model-implied) correlation matrix of the manifest or latent variables.
Note that the function only provides general dominance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dominance.manual(x, out = NULL, digits = 3, write = NULL, append = TRUE,
                 check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dominance.manual_+3A_x">x</code></td>
<td>
<p>a matrix or data frame with the (model-implied) correlation matrix
of the manifest or latent variables. Note that column names need
to represent the variables names in <code>x</code>.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_out">out</code></td>
<td>
<p>a character string representing the outcome variable. By default,
the first row and column represents the outcome variable.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying results. Note that the percentage relative
importance of predictors are printed with <code>digits</code> minus 1
decimal places.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="dominance.manual_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>correlation matrix specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>results table for the general dominance</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function implements the function provided in Appendix 1 of Gu (2022) and
copied the function <code>combinations()</code> from the <code>gtools</code> package
(Bolker, Warnes, &amp; Lumley, 2022).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Azen, R., &amp; Budescu, D. V. (2003). The dominance analysis approach for comparing
predictors in multiple regression. <em>Psychological Methods, 8</em>(2), 129–148.
https://doi.org/10.1037/1082-989X.8.2.129
</p>
<p>Bolker, B., Warnes, G., &amp; Lumley, T. (2022). <em>gtools: Various R Programming Tools</em>.
R package version 3.9.4, https://CRAN.R-project.org/package=gtools
</p>
<p>Budescu, D. V. (1993). Dominance analysis: A new approach to the problem of
relative importance of predictors in multiple regression. <em>Psychological Bulletin, 114</em>(3),
542–551. https://doi.org/10.1037/0033-2909.114.3.542
</p>
<p>Gu, X. (2022). Assessing the relative importance of predictors in latent regression
models. <em>Structural Equation Modeling: A Multidisciplinary Journal, 4</em>, 569-583.
https://doi.org/10.1080/10705511.2021.2025377
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dominance">dominance</a></code>, <code><a href="#topic+std.coef">std.coef</a></code>, <code><a href="#topic+write.result">write.result</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#----------------------------------------------------------------------------
# Linear model

# Example 1a: Dominance analysis, 'mpg' predicted by 'cyl', 'disp', and 'hp'
dominance.manual(cor(mtcars[, c("mpg", "cyl", "disp", "hp")]))

# Example 1b: Equivalent results using the dominance() function
mod &lt;- lm(mpg ~ cyl + disp + hp, data = mtcars)
dominance(mod)

# Example 1c: Dominance analysis, 'hp' predicted by 'mpg', 'cyl', and 'disp'
dominance.manual(cor(mtcars[, c("mpg", "cyl", "disp", "hp")]), out = "hp")

# Example 1d: Write results into a text file
dominance.manual(cor(mtcars[, c("mpg", "cyl", "disp", "hp")]),
                 write = "Dominance_Manual.txt")

#----------------------------------------------------------------------------
# Example 2: Structural equation modeling

library(lavaan)

#.............
# Latent variables

# Model specification
model &lt;- '# Measurement model
          ind60 =~ x1 + x2 + x3
          dem60 =~ y1 + y2 + y3 + y4
          dem65 =~ y5 + y6 + y7 + y8
          # regressions
          ind60 ~ dem60 + dem65'

# Model estimation
fit &lt;- sem(model, data = PoliticalDemocracy)

# Model-implied correlation matrix of the latent variables
fit.cor &lt;- lavInspect(fit, what = "cor.lv")

# Dominance analysis
dominance.manual(fit.cor)

#.............
# Example 3: Latent and manifest variables

# Model specification, convert manifest to latent variable
model &lt;- '# Measurement model
          ind60 =~ x1 + x2 + x3
          dem60 =~ y1 + y2 + y3 + y4
          # Manifest as latent variable
          ly5 =~ 1*y5
          y5 ~~ 0*y5
          # Regressions
          ind60 ~ dem60 + ly5'

# Model estimation
fit &lt;- sem(model, data = PoliticalDemocracy)

# Model-implied correlation matrix of the latent variables
fit.cor &lt;- lavInspect(fit, what = "cor.lv")

# Dominance analysis
dominance.manual(fit.cor)

#----------------------------------------------------------------------------
# Example 4: Multilevel modeling

# Model specification
model &lt;- 'level: 1
            fw =~ y1 + y2 + y3
            # Manifest as latent variables
            lx1 =~ 1*x1
            lx2 =~ 1*x2
            lx3 =~ 1*x3
            x1 ~~ 0*x1
            x2 ~~ 0*x2
            x3 ~~ 0*x3
            # Regression
            fw ~ lx1 + lx2 + lx3
          level: 2
            fb =~ y1 + y2 + y3
            # Manifest as latent variables
            lw1 =~ 1*w1
            lw2 =~ 1*w2
            # Regression
            fb ~ lw1 + lw2'

# Model estimation
fit &lt;- sem(model, data = Demo.twolevel, cluster = "cluster")

# Model-implied correlation matrix of the latent variables
fit.cor &lt;- lavInspect(fit, what = "cor.lv")

# Dominance analysis Within
dominance.manual(fit.cor$within)

# Dominance analysis Between
dominance.manual(fit.cor$cluster)

#----------------------------------------------------------------------------
# Example 5: Mplus
#
# In Mplus, the model-impied correlation matrix  of the latent variables
# can be requested by OUTPUT: TECH4 and imported into R by using the
# MplusAuomtation package, for example:

library(MplusAutomation)

# Read Mplus output
output &lt;- readModels()

# Extract model-implied correlation matrix of the latent variables
fit.cor &lt;- output$tech4$latCorEst

## End(Not run)
</code></pre>

<hr>
<h2 id='effsize'>Effect Sizes for Categorical Variables</h2><span id='topic+effsize'></span>

<h3>Description</h3>

<p>This function computes effect sizes for one or more than one categorical
variable, i.e., (adjusted) phi coefficient, (bias-corrected) Cramer's <em>V</em>,
(bias-corrected) Tschuprow's <em>T</em>, (adjusted) Pearson's contingency
coefficient, Cohen's <em>w</em>), and <em>Fei</em>. By default, the function
computes <em>Fei</em> based on a chi-square goodness-of-fit test for one
categorical variable, phi coefficient based on a chi-square test of
independence for two dichotomous variables, and Cramer's <em>V</em> based on a
chi-square test of independence for two variables with at least one polytomous
variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>effsize(..., data = NULL, type = c("phi", "cramer", "tschuprow", "cont", "w", "fei"),
        alternative = c("two.sided", "less", "greater"),   conf.level = 0.95,
        adjust = TRUE, indep = TRUE, p = NULL, digits = 3, as.na = NULL,
        write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="effsize_+3A_...">...</code></td>
<td>
<p>a vector, factor, matrix or data frame. Alternatively, an
expression indicating the variable names in <code>data</code> e.g.,
<code>as.na(x1, x2, data = dat)</code>. When specifying more than
one variable, the first variable is always the focal variable
in the Chi-square test of independence which association with
all other variables is investigated. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see
'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="effsize_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a vector, factor, matrix, array, data frame,
or list for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="effsize_+3A_type">type</code></td>
<td>
<p>a chracter string indicating the type of effect size, i.e.,
<code>phi</code> for phi coefficient, <code>cramer</code> for Cramer's
V, <code>tschuprow</code> for Tschuprow’s T, <code>cont</code> for
Pearson's contingency coefficient, <code>w</code> for Cohen's w,
and <code>Fei</code> for Fei.</p>
</td></tr>
<tr><td><code id="effsize_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="effsize_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="effsize_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), phi coefficient and
Pearson's contingency coefficient are adjusted by relating
the coefficient to the possible maximum, or Cramer's <em>V</em>
and Tschuprow’s <em>T</em> are corrected for small-sample bias.</p>
</td></tr>
<tr><td><code id="effsize_+3A_indep">indep</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size computation is based
on a chi-square test of independence (default when specifying
two variable in <code>...</code>), if <code>FALSE</code> effect size
computation is based on a chi-square goodness-of-fit test
(default when specifying one variable in <code>...</code>).</p>
</td></tr>
<tr><td><code id="effsize_+3A_p">p</code></td>
<td>
<p>a numeric vector specifying the expected proportions in
each category of the categorical variable when conduting a
chi-square goodness-of-fit test. By default, the expected
proportions in each category are assumed to be equal.</p>
</td></tr>
<tr><td><code id="effsize_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
digits to be used for displaying the results.</p>
</td></tr>
<tr><td><code id="effsize_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="effsize_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output
into either a text file with file extension <code>".txt"</code>
(e.g., <code>"Output.txt"</code>) or Excel file with file
extention <code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If
the file name does not contain any file extension, an Excel
file will be written.</p>
</td></tr>
<tr><td><code id="effsize_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="effsize_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="effsize_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on modified copies of the functions <code>chisq_to_phi</code>,
<code>chisq_to_cramers_v</code>, <code>chisq_to_tschuprows_t</code>, <code>chisq_to_pearsons_c</code>,
<code>chisq_to_cohens_w</code>, and <code>chisq_to_fei</code> from the <span class="pkg">effectsize</span>
package (Ben-Shachar, Lüdecke &amp; Makowski, 2020).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Bergsma, W. (2013). A bias correction for Cramer's V and Tschuprow's T.
<em>Journal of the Korean Statistical Society, 42</em>, 323-328.
https://doi.org/10.1016/j.jkss.2012.10.002
</p>
<p>Ben-Shachar M. S., Lüdecke D., Makowski D. (2020). effectsize: Estimation of Effect
Size Indices and Standardized Parameters. <em>Journal of Open Source Software, 5</em>
(56), 2815. https://doi.org/10.21105/joss.02815
</p>
<p>Ben-Shachar, M. S., Patil, I., Theriault, R., Wiernik, B. M., Lüdecke, D. (2023).
Phi, Fei, Fo, Fum: Effect sizes for categorical data that use the chi-squared
statistic. <em>Mathematics, 11</em>, 1982. https://doi.org/10.3390/math11091982
</p>
<p>Cureton, E. E. (1959). Note on Phi/Phi max. <em>Psychometrika, 24</em>, 89-91.
</p>
<p>Davenport, E. C., &amp; El-Sanhurry, N. A. (1991). Phi/Phimax: Review and synthesis.
<em>Educational and Psychological Measurement, 51</em>, 821-828.
https://doi.org/10.1177/001316449105100403
</p>
<p>Sakoda, J.M. (1977). Measures of association for multivariate contingency tables.
<em>Proceedings of the Social Statistics Section of the American Statistical
Association (Part III)</em>, 777-780.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cor.matrix">cor.matrix</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Phi coefficient for 'vs' and 'am'
effsize(mtcars[, c("vs", "am")])

# Example 1a: Alternative specification using the 'data' argument
effsize(vs, am, data = mtcars)

# Example 2: Bias-corrected Cramer's V for 'gear' and 'carb'
effsize(gear, carb, data = mtcars)

# Example 3: Cramer's V (without bias-correction) for 'gear' and 'carb'
effsize(gear, carb, data = mtcars, adjust = FALSE)

# Example 4: Adjusted Pearson's contingency coefficient for 'gear' and 'carb'
effsize(gear, carb, data = mtcars, type = "cont")

# Example 5: Fei for 'gear'
effsize(gear, data = mtcars)

# Example 6a: Bias-corrected Cramer's V for 'cyl' and 'vs', 'am', 'gear', and 'carb'
effsize(mtcars[, c("cyl", "vs", "am", "gear", "carb")])

# Example 6b: Alternative specification using the 'data' argument
effsize(cyl, vs:carb, data = mtcars)

## Not run: 
# Example 7b: Write Results into a text file
effsize(cyl, vs:carb, data = mtcars, write = "Cramer.txt")

# Example 7b: Write Results into a Excel file
effsize(cyl, vs:carb, data = mtcars, write = "Cramer.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='freq'>Frequency Table</h2><span id='topic+freq'></span>

<h3>Description</h3>

<p>This function computes a frequency table with absolute and percentage frequencies
for one or more than one variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freq(..., data = NULL, print = c("no", "all", "perc", "v.perc"), freq = TRUE,
     split = FALSE, labels = TRUE, val.col = FALSE, round = 3, exclude = 15,
     digits = 2, as.na = NULL, write = NULL, append = TRUE, check = TRUE,
     output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freq_+3A_...">...</code></td>
<td>
<p>a vector, factor, matrix or data frame. Alternatively, an
expression indicating the variable names in <code>data</code> e.g.,
<code>freq(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="freq_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a vector, factor, matrix or data frame for
the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="freq_+3A_print">print</code></td>
<td>
<p>a character string indicating which percentage(s) to be
printed on the console, i.e., no percentages (<code>"no"</code>),
all percentages (<code>"all"</code>), percentage frequencies
(<code>"print"</code>), and valid percentage frequencies
(<code>"v.perc"</code>). Default setting when specifying one
variable in <code>...</code> is <code>print = "all"</code>, while default
setting when specifying more than one variable in <code>...</code>
is <code>print = "no"</code> unless <code>split = TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq_+3A_freq">freq</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), absolute frequencies will
be shown on the console.</p>
</td></tr>
<tr><td><code id="freq_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is split by variables
when specifying more than one variable in <code>...</code>.</p>
</td></tr>
<tr><td><code id="freq_+3A_labels">labels</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), labels for the factor
levels will be used.</p>
</td></tr>
<tr><td><code id="freq_+3A_val.col">val.col</code></td>
<td>
<p>logical: if <code>TRUE</code>, values are shown in the columns,
variables in the rows.</p>
</td></tr>
<tr><td><code id="freq_+3A_round">round</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for rounding numeric variables.</p>
</td></tr>
<tr><td><code id="freq_+3A_exclude">exclude</code></td>
<td>
<p>an integer value indicating the maximum number of unique
values for variables to be included in the analysis when
specifying more than one variable in <code>...</code> i.e.,
variables with the number of unique values exceeding
<code>exclude</code> will be excluded from the analysis. It is
also possible to specify <code>exclude = FALSE</code> to include
all variables in the analysis.</p>
</td></tr>
<tr><td><code id="freq_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying percentages.</p>
</td></tr>
<tr><td><code id="freq_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="freq_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="freq_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="freq_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="freq_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, the function displays the absolute and percentage frequencies when
specifying one variable in the argument <code>...</code>, while the function displays
only the absolute frequencies when more than one variable is specified. The
function displays valid percentage frequencies only in the presence of missing
values and excludes variables with all values missing from the analysis. Note
that it is possible to mix numeric variables, factors, and character variables
in the data frame specified in the argument <code>...</code>. By default, numeric
variables are rounded to three digits before computing the frequency table.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>freq</code> for absolute
frequencies, <code>perc</code> for percentages, and <code>v.perc</code>
for valid percentages</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M., &amp; Wilks, A. R. (1988). <em>The New  S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+crosstab">crosstab</a></code>, <code><a href="#topic+descript">descript</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Frequency table for 'cyl'
freq(mtcars$cyl)

# Example 1b: Alternative specification using the 'data' argument
freq(cyl, data = mtcars)

# Example 2: Frequency table, values shown in columns
freq(mtcars$cyl, val.col = TRUE)

# Example 3: Frequency table, use 3 digit for displaying percentages
freq(mtcars$cyl, digits = 3)

# Example 4a: Frequency table for 'cyl', 'gear', and 'carb'
freq(mtcars[, c("cyl", "gear", "carb")])

# Example 4b: Alternative specification using the 'data' argument
freq(cyl, gear, carb, data = mtcars)

# Example 5: Frequency table, with percentage frequencies
freq(mtcars[, c("cyl", "gear", "carb")], print = "all")

# Example 6: Frequency table, split output table
freq(mtcars[, c("cyl", "gear", "carb")], split = TRUE)

# Example 7: Frequency table, exclude variables with more than 5 unique values
freq(mtcars, exclude = 5)

## Not run: 
# Example 8a: Write results into a text file
freq(mtcars[, c("cyl", "gear", "carb")], split = TRUE, write = "Frequencies.txt")

# Example 8b: Write results into an Excel file
freq(mtcars[, c("cyl", "gear", "carb")], split = TRUE, write = "Frequencies.xlsx")

result &lt;- freq(mtcars[, c("cyl", "gear", "carb")], split = TRUE, output = FALSE)
write.result(result, "Frequencies.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='indirect'>Confidence Intervals for the Indirect Effect</h2><span id='topic+indirect'></span>

<h3>Description</h3>

<p>This function computes confidence intervals for the indirect effect based on the
asymptotic normal method, distribution of the product method and the Monte Carlo
method. By default, the function uses the distribution of the product method
for computing the two-sided 95% asymmetric confidence intervals for the indirect
effect product of coefficient estimator <code class="reqn">\hat{a}\hat{b}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indirect(a, b, se.a, se.b, print = c("all", "asymp", "dop", "mc"),
         se = c("sobel", "aroian", "goodman"), nrep = 100000,
         alternative = c("two.sided", "less", "greater"), seed = NULL,
         conf.level = 0.95, digits = 3, write = NULL, append = TRUE,
         check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="indirect_+3A_a">a</code></td>
<td>
<p>a numeric value indicating the coefficient <code class="reqn">a</code>, i.e.,
effect of <code class="reqn">X</code> on <code class="reqn">M</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_b">b</code></td>
<td>
<p>a numeric value indicating the coefficient <code class="reqn">b</code>, i.e.,
effect of <code class="reqn">M</code> on <code class="reqn">Y</code> adjusted for <code class="reqn">X</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_se.a">se.a</code></td>
<td>
<p>a positive numeric value indicating the standard error of
<code class="reqn">a</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_se.b">se.b</code></td>
<td>
<p>a positive numeric value indicating the standard error of
<code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which confidence
intervals (CI) to show on the console, i.e. <code>"all"</code> for all
CIs, <code>"asymp"</code> for the CI based on the asymptotic normal
method, <code>"dop"</code> (default) for the CI based on the distribution
of the product method, and <code>"mc"</code> for the CI based on the Monte
Carlo method.</p>
</td></tr>
<tr><td><code id="indirect_+3A_se">se</code></td>
<td>
<p>a character string indicating which standard error (SE) to compute
for the asymptotic normal method, i.e., <code>"sobel"</code> for the
approximate standard error by Sobel (1982) using the multivariate
delta method based on a first order Taylor series approximation,
<code>"aroian"</code> (default) for the exact standard error by
Aroian (1947) based on a first and second order Taylor series
approximation, and <code>"goodman"</code> for the unbiased standard
error by Goodman (1960).</p>
</td></tr>
<tr><td><code id="indirect_+3A_nrep">nrep</code></td>
<td>
<p>an integer value indicating the number of Monte Carlo repetitions.</p>
</td></tr>
<tr><td><code id="indirect_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be
one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="indirect_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the seed of the random number generator
when using the Monte Carlo method.</p>
</td></tr>
<tr><td><code id="indirect_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level
of the interval.</p>
</td></tr>
<tr><td><code id="indirect_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying</p>
</td></tr>
<tr><td><code id="indirect_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="indirect_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="indirect_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="indirect_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In statistical mediation analysis (MacKinnon &amp; Tofighi, 2013), the indirect effect
refers to the effect of the independent variable <code class="reqn">X</code> on the outcome variable
<code class="reqn">Y</code> transmitted by the mediator variable <code class="reqn">M</code>. The magnitude of the indirect
effect <code class="reqn">ab</code> is quantified by the product of the the coefficient <code class="reqn">a</code>
(i.e., effect of <code class="reqn">X</code> on <code class="reqn">M</code>) and the coefficient <code class="reqn">b</code> (i.e., effect of
<code class="reqn">M</code> on <code class="reqn">Y</code> adjusted for <code class="reqn">X</code>). In practice, researchers are often
interested in confidence limit estimation for the indirect effect. This function
offers three different methods for computing the confidence interval for the
product of coefficient estimator <code class="reqn">\hat{a}\hat{b}</code>:
</p>
<p><strong>(1) Asymptotic normal method</strong>
</p>
<p>In the asymptotic normal method, the standard error for the product of the
coefficient estimator <code class="reqn">\hat{a}\hat{b}</code> is computed which is used to create
a symmetrical confidence interval based on the z-value of the standard normal
(<code class="reqn">z</code>) distribution assuming that the indirect effect is normally distributed.
Note that the function provides three formulas for computing the standard error
by specifying the argument <code>se</code>:
</p>

<dl>
<dt><code>"sobel"</code></dt><dd><p>Approximate standard error by Sobel (1982) using the
multivariate delta method based on a first order Taylor series approximation:
</p>
<p style="text-align: center;"><code class="reqn">\sqrt(a^2 \sigma^2_a + b^2 \sigma^2_b)</code>
</p>
</dd>
<dt><code>"aroian"</code></dt><dd><p>Exact standard error by Aroian (1947) based on a first
and second order Taylor series approximation:
</p>
<p style="text-align: center;"><code class="reqn">\sqrt(a^2 \sigma^2_a + b^2 \sigma^2_b + \sigma^2_a \sigma^2_b)</code>
</p>
</dd>
<dt><code>"goodman"</code></dt><dd><p>Unbiased standard error by Goodman (1960):
</p>
<p style="text-align: center;"><code class="reqn">\sqrt(a^2 \sigma^2_a + b^2 \sigma^2_b - \sigma^2_a \sigma^2_b)</code>
</p>

<p>Note that the unbiased standard error is often negative and is hence
undefined for zero or small effects or small sample sizes.</p>
</dd>
</dl>

<p>The asymptotic normal method is known to have low statistical power because
the distribution of the product <code class="reqn">\hat{a}\hat{b}</code> is not normally distributed.
(Kisbu-Sakarya, MacKinnon, &amp; Miocevic, 2014). In the null case, where both random
variables have mean equal to zero, the distribution is symmetric with kurtosis of
six. When the product of the means of the two random variables is nonzero, the
distribution is skewed (up to a maximum value of <code class="reqn">\pm</code> 1.5) and has a excess
kurtosis (up to a maximum value of 6). However, the product approaches a normal
distribution as one or both of the ratios of the means to standard errors of each
random variable get large in absolute value (MacKinnon, Lockwood &amp; Williams, 2004).
</p>
<p><strong>(2) Distribution of the product method</strong>
</p>
<p>The distribution of the product method (MacKinnon et al., 2002) relies on an
analytical approximation of the distribution of the product of two normally
distributed variables. The method uses the standardized <code class="reqn">a</code> and <code class="reqn">b</code>
coefficients to compute <code class="reqn">ab</code> and then uses the critical values for the
distribution of the product (Meeker, Cornwell, &amp; Aroian, 1981) to create
asymmetric confidence intervals. The distribution of the product approaches
the gamma distribution (Aroian, 1947). The analytical solution for the distribution
of the product is provided by the Bessel function used to the solution of
differential equations and is approximately proportional to the Bessel function
of the second kind with a purely imaginary argument (Craig, 1936).
</p>
<p><strong>(3) Monte Carlo method</strong>
</p>
<p>The Monte Carlo (MC) method (MacKinnon et al., 2004) relies on the assumption
that the parameters <code class="reqn">a</code> and <code class="reqn">b</code> have a joint normal sampling distribution.
Based on the parametric assumption, a sampling distribution of the product
<code class="reqn">a</code><code class="reqn">b</code> using random samples with population values equal to the sample
estimates <code class="reqn">\hat{a}</code>, <code class="reqn">\hat{b}</code>, <code class="reqn">\hat{\sigma}_a</code>, and <code class="reqn">\hat{\sigma}_b</code>
is generated. Percentiles of the sampling distribution are identified to serve as
limits for a <code class="reqn">100(1 - \alpha)</code>% asymmetric confidence interval about the sample
<code class="reqn">\hat{a}\hat{b}</code> (Preacher &amp; Selig, 2012). Note that parametric assumptions
are invoked for <code class="reqn">\hat{a}</code> and <code class="reqn">\hat{b}</code>, but no parametric assumptions
are made about the distribution of <code class="reqn">\hat{a}\hat{b}</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>a</code> <code>b</code>, <code>se.a</code>,
and <code>se.b</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>asymp</code> with CI based
on the asymptotic normal method, <code>dop</code> with CI based
on the distribution of the product method, and <code>mc</code>
for CI based on the Monte Carlo method</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function was adapted from the <code>medci()</code> function in the <span class="pkg">RMediation</span>
package by Davood Tofighi and David P. MacKinnon (2016).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Aroian, L. A. (1947). The probability function of the product of two normally distributed variables.
<em>Annals of Mathematical Statistics, 18</em>, 265-271. https://doi.org/10.1214/aoms/1177730442
</p>
<p>Craig,C.C. (1936). On the frequency function of xy. <em>Annals of Mathematical Statistics, 7</em>, 1–15.
https://doi.org/10.1214/aoms/1177732541
</p>
<p>Goodman, L. A. (1960). On the exact variance of products. <em>Journal of the American Statistical
Association, 55</em>, 708-713. https://doi.org/10.1080/01621459.1960.10483369
</p>
<p>Kisbu-Sakarya, Y., MacKinnon, D. P., &amp; Miocevic M. (2014). The distribution of the product explains
normal theory mediation confidence interval estimation. <em>Multivariate Behavioral Research, 49</em>,
261–268. https://doi.org/10.1080/00273171.2014.903162
</p>
<p>MacKinnon, D. P., Lockwood, C. M., Hoffman, J. M., West, S. G., &amp; Sheets, V. (2002). Comparison of methods
to test mediation and other intervening variable effects. <em>Psychological Methods, 7</em>, 83–104.
https://doi.org/10.1037/1082-989x.7.1.83
</p>
<p>MacKinnon, D. P., Lockwood, C. M., &amp; Williams, J. (2004). Confidence limits for the indirect effect:
Distribution of the product and resampling methods. <em>Multivariate Behavioral Research, 39</em>, 99-128.
https://doi.org/10.1207/s15327906mbr3901_4
</p>
<p>MacKinnon, D. P., &amp; Tofighi, D. (2013). Statistical mediation analysis. In J. A. Schinka, W. F. Velicer,
&amp; I. B. Weiner (Eds.), <em>Handbook of psychology: Research methods in psychology</em> (pp. 717-735).
John Wiley &amp; Sons, Inc..
</p>
<p>Meeker, W. Q., Jr., Cornwell, L. W., &amp; Aroian, L. A. (1981). The product of two normally distributed
random variables. In W. J. Kennedy &amp; R. E. Odeh (Eds.), <em>Selected tables in mathematical statistics</em>
(Vol. 7, pp. 1–256). Providence, RI: American Mathematical Society.
</p>
<p>Preacher, K. J., &amp; Selig, J. P. (2012). Advantages of Monte Carlo confidence intervals for indirect effects.
<em>Communication Methods and Measures, 6</em>, 77–98. http://dx.doi.org/10.1080/19312458.2012.679848
</p>
<p>Sobel, M. E. (1982). Asymptotic confidence intervals for indirect effects in structural equation models.
In S. Leinhardt (Ed.), <em>Sociological methodology 1982</em> (pp. 290-312). Washington, DC: American
Sociological Association.
</p>
<p>Tofighi, D. &amp; MacKinnon, D. P. (2011). RMediation: An R package for mediation analysis
confidence intervals. <em>Behavior Research Methods, 43</em>, 692-700.
https://doi.org/10.3758/s13428-011-0076-x
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.indirect">multilevel.indirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Distribution of the Product Method
indirect(a = 0.35, b = 0.27, se.a = 0.12, se.b = 0.18)

# Example 2: Monte Carlo Method
indirect(a = 0.35, b = 0.27, se.a = 0.12, se.b = 0.18, print = "mc")

# Example 3: Asymptotic Normal Method
indirect(a = 0.35, b = 0.27, se.a = 0.12, se.b = 0.18, print = "asymp")

## Not run: 
# Example 4: Write results into a text file
indirect(a = 0.35, b = 0.27, se.a = 0.12, se.b = 0.18, write = "Indirect.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='item.alpha'>Coefficient Alpha and Item Statistics</h2><span id='topic+item.alpha'></span>

<h3>Description</h3>

<p>This function computes point estimate and confidence interval for the (ordinal)
coefficient alpha (aka Cronbach's alpha) along with the corrected item-total
correlation and coefficient alpha if item deleted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.alpha(..., data = NULL, exclude = NULL, std = FALSE, ordered = FALSE,
           na.omit = FALSE, print = c("all", "alpha", "item"), digits = 2,
           conf.level = 0.95, as.na = NULL, write = NULL, append = TRUE,
           check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item.alpha_+3A_...">...</code></td>
<td>
<p>a matrix, data frame, variance-covariance or correlation
matrix. Note that raw data is needed to compute ordinal
coefficient alpha, i.e., <code>ordered = TRUE</code>. Alternatively,
an expression indicating the variable names in <code>data</code>
e.g., <code>item.alpha(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix, data frame, variance-covariance
or correlation matrix for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_exclude">exclude</code></td>
<td>
<p>a character vector indicating items to be excluded from the
analysis.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_std">std</code></td>
<td>
<p>logical: if <code>TRUE</code>, the standardized coefficient alpha
is computed.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_ordered">ordered</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables are treated as ordered (ordinal)
variables to compute ordinal coefficient alpha.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion); if
<code>FALSE</code> (default), pairwise deletion is used.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e.
<code>"all"</code> (default), for all results <code>"alpha"</code> for
the coefficient alpha, and <code>"item"</code> for item statistics.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying coefficient alpha and item-total correlations.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level
of the interval.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="item.alpha_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ordinal coefficient alpha was introduced by Zumbo, Gadermann and Zeisser (2007)
which is obtained by applying the formula for computing coefficient alpha to the
polychoric correlation matrix instead of the variance-covariance or product-moment
correlation matrix. Note that Chalmers (2018) highlighted that the ordinal
coefficient alpha should be interpreted only as a hypothetical estimate of an
alternative reliability, whereby a test's ordinal categorical response options
have be modified to include an infinite number of ordinal response options and
concludes that coefficient alpha should not be reported as a measure of a test's
reliability. However, Zumbo and Kroc (2019) argued that Chalmers' critique of
ordinal coefficient alpha is unfounded and that ordinal coefficient alpha may
be the most appropriate quantifier of reliability when using Likert-type measurement
to study a latent continuous random variable.
Confidence intervals are computed using the procedure by Feldt, Woodruff and Salih
(1987). When computing confidence intervals using pairwise deletion, the average
sample size from all pairwise samples is used. Note that there are at least 10
other procedures for computing the confidence interval (see Kelley and
Pornprasertmanit, 2016), which are implemented in the <code>ci.reliability()</code>
function in the <span class="pkg">MBESSS</span> package by Ken Kelley (2019).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>alpha</code> for a table
with coefficient alpha and <code>itemstat</code> for a table with
item statistics</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P. (2018). On misconceptions and the limited usefulness of ordinal alpha.
<em>Educational and Psychological Measurement, 78</em>, 1056-1071.
https://doi.org/10.1177/0013164417727036
</p>
<p>Cronbach, L.J. (1951). Coefficient alpha and the internal structure of tests.
<em>Psychometrika, 16</em>, 297-334. https://doi.org/10.1007/BF02310555
</p>
<p>Cronbach, L.J. (2004). My current thoughts on coefficient alpha and successor
procedures. <em>Educational and Psychological Measurement, 64</em>, 391-418.
https://doi.org/10.1177/0013164404266386
</p>
<p>Feldt, L. S., Woodruff, D. J., &amp; Salih, F. A. (1987). Statistical inference for
coefficient alpha. <em>Applied Psychological Measurement</em>, 11 93-103.
https://doi.org/10.1177/014662168701100107
</p>
<p>Kelley, K., &amp; Pornprasertmanit, S. (2016). Confidence intervals for population
reliability coefficients: Evaluation of methods, recommendations, and software
for composite measures. <em>Psychological Methods, 21</em>, 69-92.
https://doi.org/10.1037/a0040086.
</p>
<p>Ken Kelley (2019). <em>MBESS: The MBESS R Package</em>. R package version 4.6.0.
https://CRAN.R-project.org/package=MBESS
</p>
<p>Zumbo, B. D., &amp; Kroc, E. (2019). A measurement is a choice and Stevens' scales
of measurement do not help make it: A response to Chalmers. <em>Educational
and Psychological Measurement, 79</em>, 1184-1197.
https://doi.org/10.1177/0013164419844305
</p>
<p>Zumbo, B. D., Gadermann, A. M., &amp; Zeisser, C. (2007). Ordinal versions of coefficients
alpha and theta for Likert rating scales. <em>Journal of Modern Applied Statistical
Methods, 6</em>, 21-29. https://doi.org/10.22237/jmasm/1177992180
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+item.cfa">item.cfa</a></code>, <code><a href="#topic+item.omega">item.omega</a></code>,
<code><a href="#topic+item.reverse">item.reverse</a></code>, <code><a href="#topic+item.scores">item.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(item1 = c(4, 2, 3, 4, 1, 2, 4, 2),
                  item2 = c(4, 3, 3, 3, 2, 2, 4, 1),
                  item3 = c(3, 2, 4, 2, 1, 3, 4, 1),
                  item4 = c(4, 1, 2, 3, 2, 3, 4, 2))

# Example 1a: Compute unstandardized coefficient alpha and item statistics
item.alpha(dat)

# Example 1b: Alternative specification using the 'data' argument
item.alpha(., data = dat)

# Example 2: Compute standardized coefficient alpha and item statistics
item.alpha(dat, std = TRUE)

# Example 3: Compute unstandardized coefficient alpha
item.alpha(dat, print = "alpha")

# Example 4: Compute item statistics
item.alpha(dat, print = "item")

# Example 5: Compute unstandardized coefficient alpha and item statistics while excluding item3
item.alpha(dat, exclude = "item3")

# Example 6: Compute variance-covariance matrix
dat.cov &lt;- cov(dat)
# Compute unstandardized coefficient alpha based on the variance-covariance matrix
item.alpha(dat.cov)

# Compute correlation matrix
dat.cor &lt;- cor(dat)
# Example 7: Compute standardized coefficient alpha based on the correlation matrix
item.alpha(dat.cor)

# Example 8: Compute ordinal coefficient alpha
item.alpha(dat, ordered = TRUE)

## Not run: 
# Example 9a: Write results into a text file
result &lt;- item.alpha(dat, write = "Alpha.txt")

# Example 9b: Write results into a Excel file
result &lt;- item.alpha(dat, write = "Alpha.xlsx")

result &lt;- item.alpha(dat, output = FALSE)
write.result(result, "Alpha.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='item.cfa'>Confirmatory Factor Analysis</h2><span id='topic+item.cfa'></span>

<h3>Description</h3>

<p>This function is a wrapper function for conducting confirmatory factor analysis
with continuous and/or ordered-categorical indicators by calling the <code>cfa</code>
function in the R package <span class="pkg">lavaan</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.cfa(..., data = NULL, model = NULL, rescov = NULL, hierarch = FALSE,
         meanstructure = TRUE, ident = c("marker", "var", "effect"),
         parameterization = c("delta", "theta"), ordered = NULL, cluster = NULL,
         estimator = c("ML", "MLM", "MLMV", "MLMVS", "MLF", "MLR",
                       "GLS", "WLS", "DWLS", "WLSM", "WLSMV",
                       "ULS", "ULSM", "ULSMV", "DLS", "PML"),
         missing = c("listwise", "pairwise", "fiml",
                     "two.stage", "robust.two.stage", "doubly.robust"),
         print = c("all", "summary", "coverage", "descript", "fit", "est",
                   "modind", "resid"),
         mod.minval = 6.63, resid.minval = 0.1, digits = 3, p.digits = 3,
         as.na = NULL, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item.cfa_+3A_...">...</code></td>
<td>
<p>a matrix or data frame. If <code>model = NULL</code>,
confirmatory factor analysis based on a measurement
model with one factor labeled <code>f</code> comprising all
variables in the matrix or data frame is conducted.
Note that the cluster variable is excluded from <code>x</code>
when specifying <code>cluster</code>. If <code>model</code> is
specified, the matrix or data frame needs to contain
all variables used in the argument <code>model</code> and
the cluster variable when specifying <code>cluster</code>.
Alternatively, an expression indicating the variable names in
<code>data</code> e.g., <code>item.cfa(x1, x2, x3, data = dat)</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a vector, factor, matrix, array, data frame,
or list for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_model">model</code></td>
<td>
<p>a character vector specifying a measurement model with
one factor, or a list of character vectors for specifying
a measurement model with more than one factor, e.g.,
<code>model = c("x1", "x2", "x3", "x4")</code> for specifying
a measurement model with one factor labeled <code>f</code>
comprising four indicators, or
<code>model = list(factor1 = c("x1", "x2", "x3", "x4"),
factor2 = c("x5", "x6", "x7", "x8"))</code> for specifying a
measurement model with two latent factors labeled
<code>factor1</code> and <code>factor2</code> each comprising four
indicators. Note that the name of each list element is
used to label factors, i.e., all list elements need to
be named, otherwise factors are labeled with
<code>"f1", "f2", "f3"</code> and so on.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for
specifying residual covariances, e.g.
<code>rescov = c("x1", "x2")</code> for specifying a residual
covariance between items <code>x1</code> and <code>x2</code>, or
<code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code> for
specifying residual covariances between items <code>x1</code>
and <code>x2</code>, and items <code>x3</code> and <code>x4</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_hierarch">hierarch</code></td>
<td>
<p>logical: if <code>TRUE</code>, a second-order factor model
is specified given at least three first-order factors
were specified in <code>model</code>. Note that it is not
possible to specify more than one second-order factor.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_meanstructure">meanstructure</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), intercept/means of
observed variables means of latent variables will be
added to the model. Note that <code>meanstructure = FALSE</code>
is only applicable when the <code>missing</code> is
<code>listwise</code>, <code>pairwise</code>, or <code>doubly-robust</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_ident">ident</code></td>
<td>
<p>a character string indicating the method used for
identifying and scaling latent variables, i.e.,
<code>"marker"</code> for the marker variable method fixing
the first factor loading of each latent variable to 1,
<code>"var"</code> for the fixed variance method fixing the
variance of each latent variable to 1, or <code>"effect"</code>
for the effects-coding method using equality constraints
so that the average of the factor loading for each
latent variable equals 1. By default, fixed variance
method is used when <code>hierarch = FALSE</code>, whereas
marker variable method is used when
<code>hierarch = TRUE</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_parameterization">parameterization</code></td>
<td>
<p>a character string indicating the method used for
identifying and scaling latent variables when indicators
are ordered, i.e., <code>"delta"</code> (default) for delta
parameterization and <code>"theta"</code> for theta
parameterization.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_ordered">ordered</code></td>
<td>
<p>if <code>NULL</code> (default), all indicators of the
measurement model are treated as continuous. If
<code>TRUE</code>, all indicators of the measurement model
are treated as ordered (ordinal). Alternatively, a
character vector indicating which variables to treat
as ordered (ordinal) variables can be specified.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name
of the cluster variable in <code>...</code> or <code>data</code>,
or a vector representing the nested grouping structure
(i.e., group or cluster variable) for computing
cluster-robust standard errors. Note that cluster-robust
standard errors are not available when treating indicators
of the measurement model as ordered (ordinal).</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used
(see 'Details'). By default, <code>"MLR"</code> is used for
CFA models with continuous indicators (i.e.,
<code>ordered = FALSE</code>) and <code>"WLSMV"</code> is used for
CFA model with ordered-categorical indicators (i.e.,
ordered = TRUE).</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing
data, i.e., <code>"listwise"</code> for listwise deletion,
<code>"pairwise"</code> for pairwise deletion, <code>"fiml"</code>
for full information maximum likelihood method,
<code>two.stage</code> for two-stage maximum likelihood
method, <code>robust.two.stage</code> for robust two-stage
maximum likelihood method, and <code>doubly-robust</code>
for doubly-robust method (see 'Details'). By default,
<code>"fiml"</code> is used for CFA models with continuous
indicators which are estimated by using
<code>estimator = "MLR"</code>, and <code>"pairwise"</code> for
CFA models with ordered-categorical indicators which
are estimated by using <code>estimator = "pairwise"</code>
by default.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e. <code>"all"</code> for
all results, <code>"summary"</code> for a summary of the
specification of the estimation method and missing
data handling in lavaan, <code>"coverage"</code> for the
variance-covariance coverage of the data,
<code>"descript"</code> for descriptive statistics,
<code>"fit"</code> for model fit, <code>"est"</code> for parameter
estimates, <code>"modind"</code> for modification
indices and <code>"resid"</code> for the residual correlation
matrix and standardized residual means By default, a
summary of the specification, model fit, and parameter
estimates are printed.. By default, a summary of the specification,
model fit, and parameter estimates are printed.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_mod.minval">mod.minval</code></td>
<td>
<p>numeric value to filter modification indices and only
show modifications with a modification index value equal
or higher than this minimum value. By default, modification
indices equal or higher 6.63 are printed. Note that a
modification index value of 6.63 is equivalent to a
significance level of <code class="reqn">\alpha = .01</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_resid.minval">resid.minval</code></td>
<td>
<p>numeric value indicating the minimum absolute residual
correlation coefficients and standardized means to
highlight in boldface. By default, absolute residual
correlation coefficients and standardized means equal
or higher 0.1 are highlighted. Note that highlighting
can be disabled by setting the minimum value to 1.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis. Note that <code>as.na()</code>
function is only applied to <code>x</code> but not to
<code>cluster</code>.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="item.cfa_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Estimator</strong></dt><dd><p>The R package <span class="pkg">lavaan</span> provides seven estimators
that affect the estimation, namely <code>"ML"</code>, <code>"GLS"</code>, <code>"WLS"</code>,
<code>"DWLS"</code>, <code>"ULS"</code>, <code>"DLS"</code>, and <code>"PML"</code>. All other options
for the argument <code>estimator</code> combine these estimators with various standard
error and chi-square test statistic computation. Note that the estimators also
differ in how missing values can be dealt with (e.g., listwise deletion,
pairwise deletion, or full information maximum likelihood, FIML).
</p>

<ul>
<li><p><code>"ML"</code>: Maximum likelihood with conventional standard errors
and conventional test statistic. For both complete and incomplete data
using pairwise deletion or FIML.
</p>
</li>
<li><p><code>"MLM"</code>: Maximum likelihood parameter estimates with conventional
robust standard errors and a Satorra-Bentler scaled test statistic that
are robust to non-normality. For complete data only.
</p>
</li>
<li><p><code>"MLMV"</code>: Maximum likelihood parameter estimates with conventional
robust standard errors and a mean and a variance adjusted test statistic
using a scale-shifted approach that are robust to non-normality. For complete
data only.
</p>
</li>
<li><p><code>"MLMVS"</code>: Maximum likelihood parameter estimates with conventional
robust standard errors and a mean and a variance adjusted test statistic
using the Satterthwaite approach that are robust to non-normality. For complete
data only.
</p>
</li>
<li><p><code>"MLF"</code>: Maximum likelihood parameter estimates with standard
errors approximated by first-order derivatives and conventional test statistic.
For both complete and incomplete data using pairwise deletion or FIML.
</p>
</li>
<li><p><code>"MLR"</code>: Maximum likelihood parameter estimates with Huber-White
robust standard errors a test statistic which is asymptotically equivalent
to the Yuan-Bentler T2* test statistic that are robust to non-normality
and non-independence of observed when specifying a cluster variable using
the argument <code>cluster</code>. For both complete and incomplete data using
pairwise deletion or FIML.
</p>
</li>
<li><p><code>"GLS"</code>: Generalized least squares parameter estimates with
conventional standard errors and conventional test statistic that uses a
normal-theory based weight matrix. For complete data only.
and conventional chi-square test. For both complete and incomplete data.
</p>
</li>
<li><p><code>"WLS"</code>: Weighted least squares parameter estimates (sometimes
called ADF estimation) with conventional standard errors and conventional
test statistic that uses a full weight matrix. For complete data only.
</p>
</li>
<li><p><code>"DWLS"</code>: Diagonally weighted least squares parameter estimates
which uses the diagonal of the weight matrix for estimation with conventional
standard errors and conventional test statistic. For both complete and
incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"WLSM"</code>: Diagonally weighted least squares parameter estimates
which uses the diagonal of the weight matrix for estimation, but uses the
full weight matrix for computing the conventional robust standard errors
and a Satorra-Bentler scaled test statistic. For both complete and incomplete
data using pairwise deletion.
</p>
</li>
<li><p><code>"WLSMV"</code>: Diagonally weighted least squares parameter estimates
which uses the diagonal of the weight matrix for estimation, but uses the
full weight matrix for computing the conventional robust standard errors
and a mean and a variance adjusted test statistic using a scale-shifted
approach. For both complete and incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"ULS"</code>: Unweighted least squares parameter estimates with
conventional standard errors and conventional test statistic. For both
complete and incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"ULSM"</code>: Unweighted least squares parameter estimates with
conventional robust standard errors and a Satorra-Bentler scaled test
statistic. For both complete and incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"ULSMV"</code>: Unweighted least squares parameter estimates with
conventional robust standard errors and a mean and a variance adjusted
test statistic using a scale-shifted approach. For both complete and
incomplete data using pairwise deletion.
</p>
</li>
<li><p><code>"DLS"</code>: Distributionally-weighted least squares parameter
estimates with conventional robust standard errors and a Satorra-Bentler
scaled test statistic. For complete data only.
</p>
</li>
<li><p><code>"PML"</code>: Pairwise maximum likelihood parameter estimates
with Huber-White robust standard errors and a mean and a variance adjusted
test statistic using the Satterthwaite approach. For both complete and
incomplete data using pairwise deletion.
</p>
</li></ul>

</dd>
<dt><strong>Missing Data</strong></dt><dd><p>The R package <span class="pkg">lavaan</span> provides six methods
for dealing with missing data:
</p>

<ul>
<li><p><code>"listwise"</code>: Listwise deletion, i.e., all cases with missing
values are removed from the data before conducting the analysis. This is
only valid if the data are missing completely at random (MCAR).
</p>
</li>
<li><p><code>"pairwise"</code>: Pairwise deletion, i.e., each element of a
variance-covariance matrix is computed using cases that have data needed
for estimating that element. This is only valid if the data are missing
completely at random (MCAR).
</p>
</li>
<li><p><code>"fiml"</code>: Full information maximum likelihood (FIML) method,
i.e., likelihood is computed case by case using all available data from
that case. FIML method is only applicable for following estimators:
<code>"ML"</code>, <code>"MLF"</code>, and <code>"MLR"</code>.
</p>
</li>
<li><p><code>"two.stage"</code>: Two-stage maximum likelihood estimation, i.e.,
sample statistics is estimated using EM algorithm in the first step. Then,
these estimated sample statistics are used as input for a regular analysis.
Standard errors and test statistics are adjusted correctly to reflect the
two-step procedure. Two-stage method is only applicable for following
estimators: <code>"ML"</code>, <code>"MLF"</code>, and <code>"MLR"</code>.
</p>
</li>
<li><p><code>"robust.two.stage"</code>: Robust two-stage maximum likelihood
estimation, i.e., two-stage maximum likelihood estimation with standard
errors and a test statistic that are robust against non-normality. Robust
two-stage method is only applicable for following estimators: <code>"ML"</code>,
<code>"MLF"</code>, and <code>"MLR"</code>.
</p>
</li>
<li><p><code>"doubly.robust"</code>: Doubly-robust method only applicable for
pairwise maximum likelihood estimation (i.e., <code>estimator = "PML"</code>.
</p>
</li></ul>

</dd>
<dt><strong>Convergence and model idenfitification checks</strong></dt><dd><p>In line with the
R package <span class="pkg">lavaan</span>, this functions provides several checks for model
convergence and model identification:
</p>

<ul>
<li><p><code>Degrees of freedom</code>: An error message is printed if the number
of degrees of freedom is negative, i.e., the model is not identified.
</p>
</li>
<li><p><code>Model convergence</code>: An error message is printed if the
optimizer has not converged, i.e., results are most likely unreliable.
</p>
</li>
<li><p><code>Standard errors</code>: An error message is printed if the standard
errors could not be computed, i.e., the model might not be identified.
</p>
</li>
<li><p><code>Variance-covariance matrix of the estimated parameters</code>: A
warning message is printed if the variance-covariance matrix of the
estimated parameters is not positive definite, i.e., the smallest eigenvalue
of the matrix is smaller than zero or very close to zero.
</p>
</li>
<li><p><code>Negative variances of observed variables</code>: A warning message
is printed if the estimated variances of the observed variables are
negative.
</p>
</li>
<li><p><code>Variance-covariance matrix of observed variables</code>: A warning
message is printed if the estimated variance-covariance matrix of the
observed variables is not positive definite, i.e., the smallest eigenvalue
of the matrix is smaller than zero or very close to zero.
</p>
</li>
<li><p><code>Negative variances of latent variables</code>: A warning message
is printed if the estimated variances of the latent variables are
negative.
</p>
</li>
<li><p><code>Variance-covariance matrix of latent variables</code>: A warning
message is printed if the estimated variance-covariance matrix of the
latent variables is not positive definite, i.e., the smallest eigenvalue
of the matrix is smaller than zero or very close to zero.
</p>
</li></ul>

<p>Note that unlike the R package <span class="pkg">lavaan</span>, the <code>item.cfa</code> function does
not provide any results when the degrees of freedom is negative, the model
has not converged, or standard errors could not be computed.
</p>
</dd>
<dt><strong>Model Fit</strong></dt><dd><p>The <code>item.cfa</code> function provides the chi-square
test, incremental fit indices (i.e., CFI and TLI), and absolute fit indices
(i.e., RMSEA, and SRMR) to evaluate overall model fit. However, different
versions of the CFI, TLI, and RMSEA are provided depending on the estimator.
Unlike the R package <span class="pkg">lavaan</span>, the different versions are labeled with
<code>Standard</code>, <code>Scaled</code>, and <code>Robust</code> in the output:
</p>

<ul>
<li><p><code>"Standard"</code>: CFI, TLI, and RMSEA without any non-normality
corrections. These fit measures based on the normal theory maximum
likelihood test statistic are sensitive to deviations from multivariate
normality of endogenous variables. Simulation studies by Brosseau-Liard
et al. (2012), and Brosseau-Liard and Savalei (2014) showed that the
uncorrected fit indices are affected by non-normality, especially at small
and medium sample sizes (e.g., n &lt; 500).
</p>
</li>
<li><p><code>"Scaled"</code>: Population-corrected robust CFI, TLI, and RMSEA
with ad hoc non-normality corrections that simply replace the maximum
likelihood test statistic with a robust test statistic (e.g., mean-adjusted
chi-square). These fit indices change the population value being estimated
depending on the degree of non-normality present in the data. Brosseau-Liard
et al. (2012) demonstrated that the ad hoc corrected RMSEA increasingly
accepts poorly fitting models as non-normality in the data increases, while
the effect of the ad hoc correction on the CFI and TLI is less predictable
with non-normality making fit appear worse, better, or nearly unchanged
(Brosseau-Liard &amp; Savalei, 2014).
</p>
</li>
<li><p><code>"Robust"</code>: Sample-corrected robust CFI, TLI, and RMSEA
with non-normality corrections based on formula provided by Li and Bentler
(2006) and Brosseau-Liard and Savalei (2014). These fit indices do not
change the population value being estimated and can be interpreted the
same way as the uncorrected fit indices when the data would have been
normal.
</p>
</li></ul>

<p>In conclusion, the use of sample-corrected fit indices (<code>Robust</code>)
instead of population-corrected fit indices (<code>Scaled</code>) is recommended.
Note that when sample size is very small (e.g., n &lt; 200), non-normality
correction does not appear to adjust fit indices sufficiently to counteract
the effect of non-normality (Brosseau-Liard &amp; Savalei, 2014).
</p>
</dd>
<dt><strong>Modification Indices and Residual Correlation Matrix</strong></dt><dd><p>The <code>item.cfa</code>
function provides modification indices and the residual correlation matrix when
requested by using the <code>print</code> argument. Modification indices (aka score
tests) are univariate Lagrange Multipliers (LM) representing a chi-square
statistic with a single degree of freedom. LM approximates the amount by which
the chi-square test statistic would decrease if a fixed or constrained parameter
is freely estimated (Kline, 2023). However, (standardized) expected parameter
change (EPC) values should also be inspected since modification indices are
sensitive to sample size. EPC values are an estimate of how much the parameter
would be expected to change if it were freely estimated (Brown, 2023). The residual
correlation matrix is computed by separately converting the sample covariance
and model-implied covariance matrices to correlation matrices before calculation
differences between observed and predicted covariances (i.e., <code>type = "cor.bollen"</code>).
As a rule of thumb, absolute correlation residuals greater than .10 indicate
possible evidence for poor local fit, whereas smaller correlation residuals
than 0.05 indicate negligible degree of model misfit (Maydeu-Olivares, 2017).
There is no reliable connection between the size of diagnostic statistics
(i.e., modification indices and residuals) and the type or amount of model
misspecification since (1) diagnostic statistics are themselves affected by
misspecification, (2) misspecification in one part of the model distorts estimates
in other parts of the model (i.e., error propagation), and (3) equivalent models
have identical residuals but contradict the pattern of causal effects (Kline, 2023).
Note that according to Kline' (2023) &quot;any report of the results without information
about the residuals is deficient&quot; (p. 172).</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>specified model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>results of the convergence and model identification check</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
specification of the estimation method and missing data
handling in lavaan, <code>"coverage"</code> for the
variance-covariance coverage of the data, <code>"descript"</code>
for descriptive statistics, <code>itemfreq</code> for absolute
frequencies (<code>freq</code>), percentages (<code>perc</code>),
and  (<code>v.perc</code>) valid percentages, <code>"fit"</code> for
model fit, <code>"param"</code> for parameter estimates, and
<code>"modind"</code> for modification indices.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>cfa</code>, <code>lavInspect</code>, <code>lavTech</code>,
<code>modindices</code>, <code>parameterEstimates</code>, and <code>standardizedsolution</code>
provided in the R package <span class="pkg">lavaan</span> by Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Brosseau-Liard, P. E., Savalei, V., &amp; Li. L. (2012). An investigation of the
sample performance of two nonnormality corrections for RMSEA,
<em>Multivariate Behavioral Research, 47</em>, 904-930.
https://doi.org/10.1080/00273171.2014.933697
</p>
<p>Brosseau-Liard, P. E., &amp; Savalei, V. (2014) Adjusting incremental fit indices
for nonnormality. <em>Multivariate Behavioral Research, 49</em>, 460-470.
https://doi.org/10.1080/00273171.2014.933697
</p>
<p>Brown, T. A. (2023). Confirmatory factor analysis. In R. H. Hoyle (Ed.),
<em>Handbook of structural equation modeling</em> (2nd ed.) (pp. 361–379). The
Guilford Press.
</p>
<p>Kline, R. B. (2023). <em>Principles and practice of structural equation modeling</em> (5th ed.).
Guilford Press.
</p>
<p>Li, L., &amp; Bentler, P. M. (2006). Robust statistical tests for evaluating the
hypothesis of close fit of misspecified mean and covariance structural models.
<em>UCLA Statistics Preprint #506</em>. University of California.
</p>
<p>Maydeu-Olivares, A. (2017). Assessing the size of model misfit in structural
equation models. <em>Psychometrika, 82</em>(3), 533–558. https://doi.org/10.1007/s11336-016-9552-7
</p>
<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.omega">item.omega</a></code>, <code><a href="#topic+item.scores">item.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

#----------------------------------------------------------------------------
# Measurement model with one factor

# Example 1a: Specification using the argument 'x'
item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")])

# Example 1b: Alternative specification using the 'data' argument
item.cfa(x1:x3, data = HolzingerSwineford1939)

# Example 1c: Alternative specification using the argument 'model'
item.cfa(HolzingerSwineford1939, model = c("x1", "x2", "x3"))

# Example 1d: Alternative specification using the 'data' and 'model' argument
item.cfa(., data = HolzingerSwineford1939, model = c("x1", "x2", "x3"))

# Example 1e: Alternative specification using the argument 'model'
item.cfa(HolzingerSwineford1939, model = list(visual = c("x1", "x2", "x3")))

# Example 1f: Alternative specification using the  'data' and 'model' argument
item.cfa(., data = HolzingerSwineford1939, model = list(visual = c("x1", "x2", "x3")))

#----------------------------------------------------------------------------
# Measurement model with three factors

# Example 2: Specification using the argument 'model'
item.cfa(HolzingerSwineford1939,
         model = list(visual = c("x1", "x2", "x3"),
                      textual = c("x4", "x5", "x6"),
                      speed = c("x7", "x8", "x9")))

#----------------------------------------------------------------------------
# Residual covariances

# Example 3a: One residual covariance
item.cfa(HolzingerSwineford1939,
         model = list(visual = c("x1", "x2", "x3"),
                      textual = c("x4", "x5", "x6"),
                      speed = c("x7", "x8", "x9")),
         rescov = c("x1", "x2"))

# Example 3b: Two residual covariances
item.cfa(HolzingerSwineford1939,
         model = list(visual = c("x1", "x2", "x3"),
                      textual = c("x4", "x5", "x6"),
                      speed = c("x7", "x8", "x9")),
         rescov = list(c("x1", "x2"), c("x4", "x5")))

#----------------------------------------------------------------------------
# Second-order factor model based on three first-order factors

# Example 4
item.cfa(HolzingerSwineford1939,
         model = list(visual = c("x1", "x2", "x3"),
                      textual = c("x4", "x5", "x6"),
                      speed = c("x7", "x8", "x9")),
         hierarch = TRUE)

#----------------------------------------------------------------------------
# Measurement model with ordered-categorical indicators

# Example 5
item.cfa(round(HolzingerSwineford1939[, c("x4", "x5", "x6")]), ordered = TRUE)

#----------------------------------------------------------------------------
# Cluster-robust standard errors

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Example 6a: Specification using a variable in 'x'
item.cfa(Demo.twolevel[, c("y4", "y5", "y6", "cluster")], cluster = "cluster")

# Example 6b: Specification of the cluster variable in 'cluster'
item.cfa(Demo.twolevel[, c("y4", "y5", "y6")], cluster = Demo.twolevel$cluster)

# Example 6c: Alternative specification using the 'data' argument
item.cfa(y4:y6, data = Demo.twolevel, cluster = "cluster")

#----------------------------------------------------------------------------
# Print argument

# Example 7a: Request all results
item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")], print = "all")

# Example 7b: Request modification indices with value equal or higher than 5
item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3", "x4")],
         print = "modind", mod.minval = 5)

#----------------------------------------------------------------------------
# lavaan summary of the estimated model

# Example 8
mod &lt;- item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")], output = FALSE)

lavaan::summary(mod$model.fit, standardized = TRUE, fit.measures = TRUE)

#----------------------------------------------------------------------------
# Write Results

# Example 9a: Write results into a text file
item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")], write = "CFA.txt")

# Example 9b: Write results into an Excel file
item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")], write = "CFA.xlsx")

result &lt;- item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")], output = FALSE)
write.result(result, "CFA.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='item.invar'>Between-Group and Longitudinal Measurement Invariance Evaluation</h2><span id='topic+item.invar'></span>

<h3>Description</h3>

<p>This function is a wrapper function for evaluating configural, metric, scalar,
and strict between-group or longitudinal (partial) measurement invariance using
confirmatory  factor analysis with continuous indicators by calling the <code>cfa</code>
function in the R package <span class="pkg">lavaan</span>. By default, the function evaluates
configural, metric, and scalar measurement invariance by providing a table
with model fit information (i.e., chi-square test, fit indices based on a proper
null model, and information criteria) and model comparison (i.e., chi-square
difference test, change in fit indices, and change in information criteria).
Additionally, variance-covariance coverage of the data, descriptive statistics,
parameter estimates, modification indices, and residual correlation matrix can
be requested by specifying the argument <code>print</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.invar(..., data = NULL, model = NULL, rescov = NULL, rescov.long = TRUE,
           group = NULL, long = FALSE, cluster = NULL,
           invar = c("config", "metric", "scalar", "strict"),
           partial = NULL, ident = c("marker", "var", "effect"),
           estimator = c("ML", "MLM", "MLMV", "MLMVS", "MLF", "MLR",
                         "GLS", "WLS", "DWLS", "WLSM", "WLSMV",
                         "ULS", "ULSM", "ULSMV", "DLS", "PML"),
           missing = c("listwise", "pairwise", "fiml", "two.stage",
                       "robust.two.stage", "doubly.robust"), null.model = TRUE,
           print = c("all", "summary", "coverage", "descript", "fit", "est",
                     "modind", "resid"),
           print.fit = c("all", "standard", "scaled", "robust"),
           mod.minval = 6.63, resid.minval = 0.1, digits = 3, p.digits = 3,
           as.na = NULL, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item.invar_+3A_...">...</code></td>
<td>
<p>a matrix or data frame. If <code>model = NULL</code>, confirmatory
factor analysis based on a measurement model with one factor
labeled <code>f</code> comprising all variables in the matrix or
data frame specified in <code>x</code> for evaluating between-group
measurement invariance for the grouping variable specified
in the argument <code>group</code> is conducted. Longitudinal
measurement invariance evaluation can only be conducted by
specifying the model using the argument <code>model</code>. Note
that the cluster variable is excluded from <code>x</code> when
specifying <code>cluster</code>. If <code>model</code> is specified,
the matrix or data frame needs to contain all variables
used in the argument <code>model</code> and the cluster variable
when specifying the name of the cluster variable in the
argument <code>cluster</code>. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>item.invar(x1, x2, x2, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a vector, factor, matrix, array, data frame,
or list for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_model">model</code></td>
<td>
<p>a character vector specifying a measurement model with one
factor, or a list of character vectors for specifying a
measurement model with more than one factor for evaluating
between-group measurement invariance when <code>long = FALSE</code>
or a list of character vectors for specifying a measurement
model with one factor for each time of measurement for
evaluating longitudinal measurement invariance when
specifying <code>long = TRUE</code>. For example,
<code>model = c("x1", "x2", "x3", "x4")</code> for specifying a
measurement model with one factor labeled <code>f</code> comprising
four indicators, or <code>model = list(factor1 = c("x1", "x2", "x3", "x4"),
factor2 = c("x5", "x6", "x7", "x8"))</code> for specifying a
measurement model with two latent factors labeled <code>factor1</code>
and <code>factor2</code> each comprising four indicators for
evaluating between-group measurement invariance, or
<code>model = list(time1 = c("ax1", "ax2", "ax3", "ax4"),
time2 = c("bx1", "bx2", "bx3", "bx4"),
time3 = c("cx1", "cx2", "cx3", "cx4"))</code> for specifying a
longitudinal measurement model with three time points comprising
four indicators at each time point. This function cannot
evaluate longitudinal measurement invariance for a measurement
model with more than one factor. Note that the name of each
list element is used to label factors, i.e., all list elements
need to be named, otherwise factors are labeled with <code>"f1", "f2", "f3"</code>
when <code>long = FALSE</code> and with <code>"t1", "t2", "t3"</code>
when <code>long = TRUE</code> and so on.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances, e.g., <code>rescov = c("x1", "x2")</code>
for specifying a residual covariance between items <code>x1</code>
and <code>x2</code>, or <code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code>
for specifying residual covariances between items <code>x1</code>
and <code>x2</code>, and items <code>x3</code> and <code>x4</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_rescov.long">rescov.long</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), residual covariances between
parallel indicators are estimated across time when evaluating
longitudinal measurement invariance (<code>long = TRUE</code>),
i.e., residual variances of the same indicators that are
measured at different time points are correlated across all
possible time points. Note that residual covariances should
be estimated even if the parameter estimates are statistically
not significant since indicator-specific systematic variance
is likely to correlate with itself over time (Little, 2013,
p. 164).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_group">group</code></td>
<td>
<p>either a character string indicating the variable name of
the grouping variable in the matrix or data frame specified
in <code>x</code> or a vector representing the groups
for conducting multiple-group analysis to evaluate between-group
measurement invariance.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_long">long</code></td>
<td>
<p>logical: if <code>TRUE</code>, longitudinal measurement invariance
evaluation is conducted. The longitudinal measurement model
is specified by using the argument <code>model</code>. Note that
this function can only evaluate either between-group or
longitudinal measurement invariance, but not both at the
same time.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name
of the cluster variable in <code>...</code> or <code>data</code>,
or a vector representing the nested grouping structure
(i.e., group or cluster variable) for computing
cluster-robust standard errors. Note that cluster-robust
standard errors are not available when treating indicators
of the measurement model as ordered (ordinal).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_invar">invar</code></td>
<td>
<p>a character string indicating the level of measurement
invariance to be evaluated, i.e., <code>config</code> to evaluate
configural measurement invariance (i.e., same factor structure
across groups or time), <code>metric</code> to evaluate configural
and metric measurement invariance (i.e., equal factor loadings
across groups or time), <code>scalar</code> (default) to evaluate
configural, metric and scalar measurement invariance (i.e.,
equal intercepts or thresholds across groups or time), and
<code>strict</code> to evaluate configural, metric, scalar, and
strict measurement invariance (i.e., equal residual variances
across groups or time).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_partial">partial</code></td>
<td>
<p>a character string or character vector containing the labels
of the parameters which should be free in all groups or across
time to specify a partial measurement invariance model. Note
that the labels of the parameters need to match the labels
shown in the output, i.e., <code>"L"</code> with a number for factor
loadings, <code>"T"</code> with a number for intercepts, and
<code>"E"</code> with a number for factor residual variances. The
number attached to the <code>"L"</code>, <code>"T"</code>, or <code>"E"</code>
label corresponds to the number of the indicator in the
measurement model (e.g., <code>"T3"</code> for the intercept of
the third indicator). When specifying the model using the
argument <code>model</code>, however, the number for the factor
loading is a combination of the number of the factor and
the number of the indicator (e.g., <code>"L23"</code> is the third
indicator of the second factor). Note that at least two
invariant indicators are needed for a partial measurement
invariance model. Otherwise there might be issues with model
non-identification.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_ident">ident</code></td>
<td>
<p>a character string indicating the method used for identifying
and scaling latent variables, i.e., <code>"marker"</code> for the
marker variable method fixing the first factor loading of
each latent variable to 1, <code>"var"</code> (default) for the
fixed variance method fixing the variance of each latent
variable to 1, or <code>"effect"</code> for the effects-coding
method using equality constraints so that the average of
the factor loading for each latent variable equals 1.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used
(see 'Details' in the help page of the <code>item.cfa()</code>
function). By default, <code>"MLR"</code> is used for CFA models
with continuous indicators.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data,
i.e., <code>"listwise"</code> for listwise deletion, <code>"pairwise"</code>
for pairwise deletion, <code>"fiml"</code> for full information
maximum likelihood method, <code>two.stage</code> for two-stage
maximum likelihood method, <code>robust.two.stage</code> for robust
two-stage maximum likelihood method, and <code>doubly-robust</code>
for doubly-robust method (see 'Details' in the help page
of the<code>item.cfa()</code> function). By default, <code>"fiml"</code>
is used for CFA models with continuous indicators which are
estimated by using <code>estimator = "MLR"</code>. However, argument
<code>missing</code> switches to <code>listwise</code> when the data
set is complete, i.e., it is not possible to use FIML in
complete data. Note that the robust CFI, TLI, and RMSEA
are different in complete data depending on whether FIML or
listwise deletion was specified when estimating the model
in lavaan.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_null.model">null.model</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the proper null model
for computing incremental fit indices (i.e., CFI and TLI)
is used, i.e., means and variances of the indicators are
constrained to be equal across group or time in the null
model (Little, 2013, p. 112).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results
to show on the console, i.e. <code>"all"</code> for all results,
<code>"summary"</code> for a summary of the specification of the
estimation method and missing data handling in lavaan,
<code>"coverage"</code> for the variance-covariance coverage of
the data, <code>"descript"</code> for descriptive statistics,
<code>"fit"</code> for model fit and model comparison, <code>"est"</code>
for parameter estimates, <code>"modind"</code> for modification
indices, and <code>"resid"</code> for the residual correlation
matrix and standardized residual means. By default, a summary
of the specification, model fit, and parameter estimates
are printed. Note that parameter estimates, modification
indices, and residual correlation matrix is only provided
for the model investigating the level of measurement
invariance specified in the argument <code>"invar"</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_print.fit">print.fit</code></td>
<td>
<p>a character string or character vector indicating which
version of the CFI, TLI, and RMSEA to show on the console
when using a robust estimation method involving a scaling
correction factor, i.e., <code>"all"</code> for all versions of
the CFI, TLI, and RMSEA, <code>"standard"</code> (default when
<code>estimator</code> is one of <code>"ML", "MLF", "GLS", "WLS", "DWLS", "ULS", "PML"</code>)
for fit indices without any non-normality correction,
<code>"scaled"</code> for population-corrected robust fit indices
with ad hoc non-normality correction, and <code>robust</code>
(default when <code>estimator</code> is one of <code>"MLM", "MLMV", "MLMVS", "MLR", "WLSM", "WLSMV", "ULSM", "ULSMV", "DLS"</code>)
for sample-corrected robust fit indices based on formula
provided by Li and Bentler (2006) and Brosseau-Liard and
Savalei (2014).</p>
</td></tr>
<tr><td><code id="item.invar_+3A_mod.minval">mod.minval</code></td>
<td>
<p>numeric value to filter modification indices and only show
modifications with a modification index value equal or higher
than this minimum value. By default, modification indices
equal or higher 6.63 are printed. Note that a modification
index value of 6.63 is equivalent to a significance level
of <code class="reqn">\alpha = .01</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_resid.minval">resid.minval</code></td>
<td>
<p>numeric value indicating the minimum absolute residual
correlation coefficients and standardized means to highlight
in boldface. By default, absolute residual correlation
coefficients and standardized means equal or higher 0.1
are highlighted. Note that highlighting can be disabled by
setting the minimum value to 1.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that information
criteria and chi-square test statistic are printed with
<code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying <em>p</em>-values, covariance coverage
(i.e., <code>p.digits - 1</code>), and residual correlation
coefficients.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.,
these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only
applied to <code>x</code> but not to <code>group</code> or <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked
and convergence and model identification checks are conducted
for all estimated models.</p>
</td></tr>
<tr><td><code id="item.invar_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame including all variables used in the analysis, i.e.,
indicators for the factor, grouping variable and cluster variable</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>list with specified model for the configural, metric, scalar,
and strict invariance model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>list with fitted lavaan object of the configural, metric,
scalar, and strict invariance model</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>list with the results of the convergence and model identification
check for the configural, metric, scalar, and strict invariance
model</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary of the specification of the estimation method and
missing data handling in lavaan, <code>coverage</code> for the
variance-covariance coverage of the data, <code>descript</code>
for descriptive statistics, <code>fit</code> for a list with
model fit based on standard, scaled, and robust fit indices,
<code>est</code> for a list with parameter estimates for the
configural, metric, scalar, and strict invariance model,
<code>modind</code> for the list with modification indices for
the configural, metric, scalar, and strict invariance model,
<code>score</code> for the list with result of the score tests
for constrained parameters for the configural, metric,
scalar, and strict invariance model, and <code>resid</code> for
the list with residual correlation matrices and standardized
residual means for the configural, metric, scalar, and
strict invariance model</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>cfa</code>, <code>fitmeasures</code> ,<code>lavInspect</code>,
<code>lavTech</code>, <code>lavTestLRT</code>, <code>lavTestScore</code>, <code>modindices</code>,
<code>parameterEstimates</code>, <code>parTable</code>, and <code>standardizedsolution</code>
provided in the R package <span class="pkg">lavaan</span> by Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Brosseau-Liard, P. E., &amp; Savalei, V. (2014) Adjusting incremental fit indices
for nonnormality. <em>Multivariate Behavioral Research, 49</em>, 460-470.
https://doi.org/10.1080/00273171.2014.933697
</p>
<p>Li, L., &amp; Bentler, P. M. (2006). Robust statistical tests for evaluating the
hypothesis of close fit of misspecified mean and covariance structural models.
<em>UCLA Statistics Preprint #506</em>. University of California.
</p>
<p>Little, T. D. (2013). <em>Longitudinal structural equation modeling</em>. Guilford
Press.
</p>
<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.cfa">item.cfa</a></code>, <code><a href="#topic+multilevel.invar">multilevel.invar</a></code>, <code><a href="#topic+write.result">write.result</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

#-------------------------------------------------------------------------------
# Between-Group Measurement Invariance Evaluation

#..................
# Measurement model with one factor

# Example 1a: Specification of the grouping variable in 'x'
item.invar(HolzingerSwineford1939[, c("x1", "x2", "x3", "x4", "sex")], group = "sex")

# Example 1b: Specification of the grouping variable in 'group'
item.invar(HolzingerSwineford1939[, c("x1", "x2", "x3", "x4")],
           group = HolzingerSwineford1939$sex)

# Example 1c: Alternative specification using the 'data' argument
item.invar(x1:x4, data = HolzingerSwineford1939, group = "sex")

# Example 1d: Alternative specification using the argument 'model'
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"), group = "sex")

# Example 1e: Alternative specification using the 'data' and 'model' argument
item.invar(., data = HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"), group = "sex")

#..................
# Measurement model with two factors

item.invar(HolzingerSwineford1939,
           model = list(c("x1", "x2", "x3", "x4"),
                        c("x5", "x6", "x7", "x8")), group = "sex")

#..................
# Configural, metric, scalar, and strict measurement invariance

# Example 2: Evaluate configural, metric, scalar, and strict measurement invariance
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", invar = "strict")

#..................
# Partial measurement invariance

# Example 3: Free second factor loading (L2) and third intercept (T3)
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", partial = c("L2", "T3"), print = c("fit", "est"))

#..................
# Residual covariances

# Example 4a: One residual covariance
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           rescov = c("x3", "x4"), group = "sex")

# Example 4b: Two residual covariances
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           rescov = list(c("x1", "x2"), c("x3", "x4")), group = "sex")

#..................
# Scaled test statistic and cluster-robust standard errors

# Example 5a: Specify cluster variable using a variable name in 'x'
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", cluster = "agemo")

# Example 5b: Specify vector of the cluster variable in the argument 'cluster'
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", cluster = HolzingerSwineford1939$agemo)

#..................
# Default Null model

# Example 6: Specify default null model for computing incremental fit indices
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", null.model = FALSE)

#..................
# Print argument

# Example 7a: Request all results
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", print = "all")

# Example 7b: Request fit indices with ad hoc non-normality correction
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", print.fit = "scaled")

# Example 7c: Request modification indices with value equal or higher than 10
# and highlight residual correlations equal or higher than 0.3
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
           group = "sex", print = c("modind", "resid"),
           mod.minval = 10, resid.minval = 0.3)

#..................
# Model syntax and lavaan summary of the estimated model

# Example 8
mod &lt;- item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
                  group = "sex", output = FALSE)

# lavaan model syntax scalar invariance model
cat(mod$model$scalar)

# lavaan summary of the scalar invariance model
lavaan::summary(mod$model.fit$scalar, standardized = TRUE, fit.measures = TRUE)

#-------------------------------------------------------------------------------
# Longitudinal Measurement Invariance Evaluation

# Example 9: Two time points with three indicators at each time point
item.invar(HolzingerSwineford1939,
           model = list(c("x1", "x2", "x3"),
                        c("x5", "x6", "x7")), long = TRUE)

#------------------------------------------------
# Write Results

# Example 10a: Write results into a text file
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
            group = "sex", print = "all", write = "Invariance.txt", output = FALSE)

# Example 10b: Write results into an Excel file
item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
            group = "sex", print = "all", write = "Invariance.xlsx", output = FALSE)

result &lt;- item.invar(HolzingerSwineford1939, model = c("x1", "x2", "x3", "x4"),
                     group = "sex", print = "all", output = FALSE)
write.result(result, "Invariance.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='item.omega'>Coefficient Omega, Hierarchical Omega, and Categorical Omega</h2><span id='topic+item.omega'></span>

<h3>Description</h3>

<p>This function computes point estimate and confidence interval for the coefficient
omega (McDonald, 1978), hierarchical omega (Kelley &amp; Pornprasertmanit, 2016),
and categorical omega (Green &amp; Yang, 2009) along with standardized factor loadings
and omega if item deleted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.omega(..., data = NULL, rescov = NULL, type = c("omega", "hierarch", "categ"),
           exclude = NULL, std = FALSE, na.omit = FALSE,
           print = c("all", "omega", "item"), digits = 2, conf.level = 0.95,
           as.na = NULL, write = NULL, append = TRUE, check = TRUE,
           output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item.omega_+3A_...">...</code></td>
<td>
<p>a matrix or data frame. Note that at least three items are
needed for computing omega. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>item.omega(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument
<code>...</code>.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances when computing coefficient omega, e.g.
<code>rescov = c("x1", "x2")</code> for specifying a residual
covariance between items <code>x1</code> and <code>x2</code> or
<code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code> for specifying
residual covariances between items <code>x1</code> and <code>x2</code>,
and items <code>x3</code> and <code>x4</code>.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of omega to be computed, i.e.,
<code>omega</code> (default) for coefficient omega, <code>hierarch</code> for
hierarchical omega, and <code>categ</code> for categorical omega.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_exclude">exclude</code></td>
<td>
<p>a character vector indicating items to be excluded from the
analysis.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_std">std</code></td>
<td>
<p>logical: if <code>TRUE</code>, the standardized coefficient omega
is computed.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion); if <code>FALSE</code>,
full information maximum likelihood (FIML) is used for computing
coefficient omega or hierarchical omega, while pairwise deletion
is used for computing categorical omega.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e.
<code>"all"</code> (default), for all results <code>"omega"</code> for omega,
and <code>"item"</code> for item statistics.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying omega and standardized factor loadings.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level
of the interval.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="item.omega_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Omega is computed by estimating a confirmatory factor analysis model using the
<code>cfa()</code> function in the <span class="pkg">lavaan</span> package by Yves Rosseel (2019). Maximum
likelihood (<code>"ML"</code>) estimator is used for computing coefficient omega and
hierarchical omega, while diagonally weighted least squares estimator (<code>"DWLS"</code>)
is used for computing categorical omega.
</p>
<p>Approximate confidence intervals are computed using the procedure by Feldt, Woodruff
and Salih (1987). Note that there are at least 10 other procedures for computing
the confidence interval (see Kelley and Pornprasertmanit, 2016), which are implemented
in the <code>ci.reliability()</code> function in the <span class="pkg">MBESSS</span> package by Ken Kelley (2019).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>alpha</code> for a table
with coefficient omega and <code>itemstat</code> for a table with
item statistics</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Computation of the hierarchical and categorical omega is based on
the <code>ci.reliability()</code> function in the <span class="pkg">MBESS</span> package by Ken Kelley
(2019).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Feldt, L. S., Woodruff, D. J., &amp; Salih, F. A. (1987). Statistical inference for
coefficient alpha. <em>Applied Psychological Measurement</em>, 11 93-103.
</p>
<p>Green, S. B., &amp; Yang, Y. (2009). Reliability of summed item scores using structural
equation modeling: An alternative to coefficient alpha. <em>Psychometrika, 74</em>,
155-167. https://doi.org/10.1007/s11336-008-9099-3
</p>
<p>Kelley, K., &amp; Pornprasertmanit, S. (2016). Confidence intervals for population
reliability coefficients: Evaluation of methods, recommendations, and software
for composite measures. <em>Psychological Methods, 21</em>, 69-92.
http://dx.doi.org/10.1037/a0040086
</p>
<p>Ken Kelley (2019). <em>MBESS: The MBESS R Package</em>. R package version 4.6.0.
https://CRAN.R-project.org/package=MBESS
</p>
<p>McDonald, R. P. (1978). Generalizability in factorable domains: Domain validity
and generalizability. <em>Educational and Psychological Measurement, 38</em>, 75-79.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.cfa">item.cfa</a></code>,
<code><a href="#topic+item.reverse">item.reverse</a></code>, <code><a href="#topic+item.scores">item.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- data.frame(item1 = c(5, 2, 3, 4, 1, 2, 4, 2),
                  item2 = c(5, 3, 3, 5, 2, 2, 5, 1),
                  item3 = c(4, 2, 4, 5, 1, 3, 5, 1),
                  item4 = c(5, 1, 2, 5, 2, 3, 4, 2))

# Example 1a: Compute unstandardized coefficient omega and item statistics
item.omega(dat)

# Example 1b: Alternative specification using the 'data' argument
item.omega(., data = dat)

# Example 2: Compute unstandardized coefficient omega with a residual covariance
# and item statistics
item.omega(dat, rescov = c("item1", "item2"))

# Example 3: Compute unstandardized coefficient omega with residual covariances
# and item statistics
item.omega(dat, rescov = list(c("item1", "item2"), c("item1", "item3")))

# Example 4: Compute unstandardized hierarchical omega and item statistics
item.omega(dat, type = "hierarch")

# Example 5: Compute categorical omega and item statistics
item.omega(dat, type = "categ")

# Example 6: Compute standardized coefficient omega and item statistics
item.omega(dat, std = TRUE)

# Example 7: Compute unstandardized coefficient omega
item.omega(dat, print = "omega")

# Example 8: Compute item statistics
item.omega(dat, print = "item")

# Example 9: Compute unstandardized coefficient omega and item statistics while excluding item3
item.omega(dat, exclude = "item3")

# Example 10: Summary of the CFA model used to compute coefficient omega
lavaan::summary(item.omega(dat, output = FALSE)$model.fit,
                fit.measures = TRUE, standardized = TRUE)

# Example 11a: Write results into a text file
item.omega(dat, write = "Omega.txt")

# Example 11b: Write results into a Excel file
item.omega(dat, write = "Omega.xlsx")

result &lt;- item.omega(dat, output = FALSE)
write.result(result, "Omega.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='item.reverse'>Reverse Code Scale Item</h2><span id='topic+item.reverse'></span>

<h3>Description</h3>

<p>This function reverse codes inverted items, i.e., items that are negatively
worded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.reverse(..., data = NULL, min = NULL, max = NULL, keep = NULL, append = TRUE,
             name = ".r", as.na = NULL, table = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item.reverse_+3A_...">...</code></td>
<td>
<p>a numeric vector for reverse coding an item, matrix or data frame
for reverse coding more than one item. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>item.reverse(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector or data frame for the argument
<code>...</code>.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_min">min</code></td>
<td>
<p>an integer indicating the minimum of the item (i.e., lowest possible
scale value).</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_max">max</code></td>
<td>
<p>an integer indicating the maximum of the item (i.e., highest possible
scale value).</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_keep">keep</code></td>
<td>
<p>a numeric vector indicating values not to be reverse coded.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), recoded variable(s) are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names
of the reverse coded item. By default, variables are named with the ending
<code>".r"</code> resulting in e.g. <code>"x1.r"</code> and <code>"x2.r"</code>. Variable names
can also be specified using a character vector matching the number
of variables specified in <code>...</code> (e.g.,
<code>name = c("reverse.x1", "reverse.x2")</code>).</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e. these
values are converted to <code>NA</code> before conducting the analysis.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_table">table</code></td>
<td>
<p>logical: if <code>TRUE</code>, a cross table item x reverse coded item
is printed on the console if only one variable is specified in
<code>...</code>.</p>
</td></tr>
<tr><td><code id="item.reverse_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If arguments <code>min</code> and/or <code>max</code> are not specified, empirical minimum
and/or maximum is computed from the data Note, however, that reverse coding
might fail if the lowest or highest possible scale value is not represented in
the data That is, it is always preferable to specify the arguments <code>min</code>
and <code>max</code>.
</p>


<h3>Value</h3>

<p>Returns a numeric vector or data frame with the same length or same number of
rows as <code>...</code> containing the reverse coded scale item(s).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. New York: John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.omega">item.omega</a></code>, <code><a href="#topic+rec">rec</a></code>,
<code><a href="#topic+item.scores">item.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(item1 = c(1, 5, 3, 1, 4, 4, 1, 5),
                  item2 = c(1, 1.3, 1.7, 2, 2.7, 3.3, 4.7, 5),
                  item3 = c(4, 2, 4, 5, 1, 3, 5, -99))

# Example 1a: Reverse code item1 and append to 'dat'
dat$item1r &lt;- item.reverse(dat$item1, min = 1, max = 5)

# Example 1b: Alternative specification using the 'data' argument
item.reverse(item1, data = dat, min = 1, max = 5)

# Example 2: Reverse code item3 while keeping the value -99
dat$item3r &lt;- item.reverse(dat$item3, min = 1, max = 5, keep = -99)

# Example 3: Reverse code item3 while keeping the value -99 and check recoding
dat$item3r &lt;- item.reverse(dat$item3, min = 1, max = 5, keep = -99, table = TRUE)

# Example 4a: Reverse code item1, item2, and item 3 and attach to 'dat'
dat &lt;- cbind(dat,
             item.reverse(dat[, c("item1", "item2", "item3")],
                          min = 1, max = 5, keep = -99))

# Example 4b: Alternative specification using the 'data' argument
item.reverse(item1:item3, data = dat, min = 1, max = 5, keep = -99)
</code></pre>

<hr>
<h2 id='item.scores'>Compute Scale Scores</h2><span id='topic+item.scores'></span>

<h3>Description</h3>

<p>This function computes (prorated) scale scores by averaging the (available) items
that measure a single construct by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.scores(..., data = NULL, fun = c("mean", "sum", "median", "var", "sd", "min", "max"),
            prorated = TRUE, p.avail = NULL, n.avail = NULL, append = TRUE,
            name = "scores", as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item.scores_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with numeric vectors. Alternatively, an
expression indicating the variable names in <code>data</code> e.g.,
<code>item.scores(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument
<code>...</code>.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_fun">fun</code></td>
<td>
<p>a character string indicating the function used to compute
scale scores, default: <code>"mean"</code>.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_prorated">prorated</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), prorated scale scores are
computed (see 'Details'); if <code>FALSE</code>, scale scores of
only complete cases are computed.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_p.avail">p.avail</code></td>
<td>
<p>a numeric value indicating the minimum proportion of available
item responses needed for computing a prorated scale score for
each case, e.g. <code>p.avail = 0.8</code> indicates that scale scores
are only computed for cases with at least 80% of item responses
available. By default prorated scale scores are computed for
all cases with at least one item response. Note that either
argument <code>p.avail</code> or <code>n.avail</code> is used to specify
the proration criterion.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_n.avail">n.avail</code></td>
<td>
<p>an integer indicating the minimum number of available item
responses needed for computing a prorated scale score for each
case, e.g. <code>n.avail = 2</code> indicates that scale scores are
only computed for cases with item responses on at least 2 items.
By default prorated scale scores are computed for all cases
with at least one item response. Note that either argument
<code>p.avail</code> or <code>n.avail</code> is used to specify the proration
criterion.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a variable with scale scores
is appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_name">name</code></td>
<td>
<p>a character string indicating the names of the variable appended
to the data frame specified in the arguement <code>data</code> when
<code>append = TRUE</code>. By default, the variable is named <code>scores</code>.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="item.scores_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prorated mean scale scores are computed by averaging the available items, e.g.,
if a participant answers 4 out of 8 items, the prorated scale score is the average
of the 4 responses. Averaging the available items is equivalent to substituting
the mean of a participant's own observed items for each of the participant's missing
items, i.e., <em>person mean imputation</em> (Mazza, Enders &amp; Ruehlman, 2015) or
<em>ipsative mean imputation</em> (Schafer &amp; Graham, 2002).
</p>
<p>Proration may be reasonable when (1) a relatively high proportion of the items
(e.g., 0.8) and never fewer than half are used to form the scale score, (2) means
of the items comprising a scale are similar and (3) the item-total correlations
are similar (Enders, 2010; Graham, 2009; Graham, 2012). Results of simulation
studies indicate that proration is prone to substantial bias when either the
item means or the inter-item correlation vary (Lee, Bartholow, McCarthy, Pederson
&amp; Sher, 2014; Mazza et al., 2015).
</p>


<h3>Value</h3>

<p>Returns a numeric vector with the same length as <code>nrow(x)</code> containing (prorated)
scale scores.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. New York, NY: Guilford
Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>Graham, J. W. (2012). Missing data: Analysis and design. New York, NY: Springer
</p>
<p>Lee, M. R., Bartholow, B. D., McCarhy, D. M., Pederson, S. L., &amp; Sher, K. J. (2014).
Two alternative approaches to conventional person-mean imputation scoring of the
self-rating of the effects of alcohol scale (SRE). <em>Psychology of Addictive Behaviors, 29</em>,
231-236. https://doi.org/10.1037/adb0000015
</p>
<p>Mazza, G. L., Enders, C. G., &amp; Ruehlman, L. S. (2015). Addressing item-level missing
data: A comparison of proration and full information maximum likelihood estimation.
<em>Multivariate Behavioral Research, 50</em>, 504-519.
https://doi.org/10.1080/00273171.2015.1068157
</p>
<p>Schafer, J. L., &amp; Graham, J. W. (2002). Missing data: Our view of the state of
the art. <em>Psychological Methods, 7</em>, 147-177.' https://doi.org/10.1037/1082-989X.7.2.147
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cluster.scores">cluster.scores</a></code>, <code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.cfa">item.cfa</a></code>,
<code><a href="#topic+item.omega">item.omega</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(item1 = c(3,  2,  4, 1,  5, 1,  3, NA),
                  item2 = c(2,  2, NA, 2,  4, 2, NA,  1),
                  item3 = c(1,  1,  2, 2,  4, 3, NA, NA),
                  item4 = c(4,  2,  4, 4, NA, 2, NA, NA),
                  item5 = c(3, NA, NA, 2,  4, 3, NA,  3))

# Example 1a: Prorated mean scale scores
item.scores(dat)

# Example 1b: Alternative specification using the 'data' argument
item.scores(., data = dat)

# Example 2: Prorated standard deviation scale scores
item.scores(dat, fun = "sd")

# Example 3: Sum scale scores without proration
item.scores(dat, fun = "sum", prorated = FALSE)

# Example 4: Prorated mean scale scores,
# minimum proportion of available item responses = 0.8
item.scores(dat, p.avail = 0.8)

# Example 5: Prorated mean scale scores,
# minimum number of available item responses = 3
item.scores(dat, n.avail = 3)
</code></pre>

<hr>
<h2 id='lagged'>Create Lagged Variables</h2><span id='topic+lagged'></span>

<h3>Description</h3>

<p>This function computes lagged values of variables by a specified number of
observations. By default, the function returns lag-1 values of the vector,
matrix, or data frame specified in the first argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagged(..., data = NULL, id = NULL, obs = NULL, day = NULL, lag = 1, time = NULL,
       units = c("secs", "mins", "hours", "days", "weeks"), append = TRUE,
       name = ".lag", name.td = ".td", as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lagged_+3A_...">...</code></td>
<td>
<p>a vector for computing a lagged values for a variable, matrix
or data frame for computing lagged values for more than one
variable. Note that the subject ID variable (<code>id</code>),
observation number variable (<code>obs</code>), day number variable
(<code>day</code>), and the date and time variable (<code>time</code>) are
excluded from <code>...</code> when specifying the argument the
using the names of the variables. Alternatively, an expression
indicating the variable names in <code>data</code>. Note that the
operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>,
<code>::</code>, and <code>!</code> can also be used to select variables,
see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="lagged_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a vector, matrix, or data frame for the argument
<code>...</code>.</p>
</td></tr>
<tr><td><code id="lagged_+3A_id">id</code></td>
<td>
<p>either a character string indicating the variable name of the
subject ID variable in '...' or a vector representing the
subject IDs, see 'Details'.</p>
</td></tr>
<tr><td><code id="lagged_+3A_obs">obs</code></td>
<td>
<p>either a character string indicating the variable name of the
observation number variable in '...' or a vector representing
the observations. Note that duplicaed values within the same
subject ID are not allowed, see 'Details'.</p>
</td></tr>
<tr><td><code id="lagged_+3A_day">day</code></td>
<td>
<p>either a character string indicating the variable name of the
day number variable in '...' or a vector representing the days,
see 'Details'.</p>
</td></tr>
<tr><td><code id="lagged_+3A_lag">lag</code></td>
<td>
<p>a numeric value specifying the lag, e.g. <code>lag = 1</code> (default)
returns lag-1 values.</p>
</td></tr>
<tr><td><code id="lagged_+3A_time">time</code></td>
<td>
<p>a variable of class <code>POSIXct</code> or <code>POSIXlt</code> representing
the date and time of the observation used to compute time
differences beween observations.</p>
</td></tr>
<tr><td><code id="lagged_+3A_units">units</code></td>
<td>
<p>a character string indicating the units in which the time
difference is represented, i.e., <code>"secs"</code> for seconds,
<code>"mins"</code> (default) for minutes, <code>"hours"</code> for hours,
<code>"days"</code> for days, and <code>"weeks"</code> for weeks.</p>
</td></tr>
<tr><td><code id="lagged_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), lagged variable(s) are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="lagged_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names of
the lagged variables. By default, lagged variables are named
with the ending <code>".lag"</code> resulting in e.g. <code>"x1.lag"</code>
and <code>"x2.lag"</code> when specifying two variables. Variable
names can also be specified using a character vector matching
the number of variables specified in <code>...</code>, e.g.
<code>name = c("lag.x1", "lag.x2")</code>).</p>
</td></tr>
<tr><td><code id="lagged_+3A_name.td">name.td</code></td>
<td>
<p>a character string or character vector indicating the names of
the time difference variables when specifying a date and time
variables for the argument <code>time</code>. By default, time
difference variables are named with the ending <code>".td"</code>
resulting in e.g. <code>"x1.td"</code> and <code>"x2.td"</code> when
specifying two variables. Variable names can also be specified
using a character vector matching the number of variables
specified in <code>...</code>, e.g. <code>name = c("td.x1", "td.x2")</code>).</p>
</td></tr>
<tr><td><code id="lagged_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.
these values are converted to <code>NA</code> before conducting the
analysis. Note that <code>as.na()</code> function is only applied to
the argument <code>x</code>, but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="lagged_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<p>The function is used to create lagged verions of the variable(s) specified via
the <code>...</code> argument:
</p>
<dl>
<dt><strong>Optional argument <code>id</code></strong></dt><dd><p>If the <code>id</code> argument is not specified
<code>i.e., id = NULL</code>, all observations are assumed to come from the same
subject.  If the dataset includes multiple subjects, then this variable needs
to be specified so that observations are not lagged across subjects</p>
</dd>
<dt><strong>Optional argument <code>day</code></strong></dt><dd><p>If the <code>day</code> argument is not specified
<code>i.e., day = NULL</code>, values of the variable to be lagged are allowed to be
lagged across days in case there are multiple observation days.</p>
</dd>
<dt><strong>Optional argument <code>obs</code></strong></dt><dd><p>If the <code>obs</code> argument is not specified
<code>i.e., obs = NULL</code>, consecutive observations from the same subjects are
assumed to be one lag apart.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a numeric vector or data frame with the same length or same number of
rows as <code>...</code> containing the lagged variable(s).
</p>


<h3>Note</h3>

<p>This function is a based on the <code>lagvar()</code> function in the <span class="pkg">esmpack</span>
package by Wolfgang Viechtbauer and Mihail Constantin (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Viechtbauer W, Constantin M (2023). <em>esmpack: Functions that facilitate
preparation and management of ESM/EMA data</em>. R package version 0.1-20.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+center">center</a></code>, <code><a href="#topic+rec">rec</a></code>, <code><a href="#topic+coding">coding</a></code>, <code><a href="#topic+item.reverse">item.reverse</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(subject = rep(1:2, each = 6),
                   day = rep(1:2, each = 3),
                   obs = rep(1:6, times = 2),
                   time = as.POSIXct(c("2024-01-01 09:01:00", "2024-01-01 12:05:00",
                                       "2024-01-01 15:14:00", "2024-01-02 09:03:00",
                                       "2024-01-02 12:21:00", "2024-01-02 15:03:00",
                                       "2024-01-01 09:02:00", "2024-01-01 12:09:00",
                                       "2024-01-01 15:06:00", "2024-01-02 09:02:00",
                                       "2024-01-02 12:15:00", "2024-01-02 15:06:00")),
                    pos = c(6, 7, 5, 8, NA, 7, 4, NA, 5, 4, 5, 3),
                    neg = c(2, 3, 2, 5, 3, 4, 6, 4, 6, 4, NA, 8))

# Example 1a: Lagged variable for 'pos'
lagged(dat$pos, id = dat$subject, day = dat$day)

# Example 1b: Alternative specification
lagged(dat[, c("pos", "subject", "day")], id = "subject", day = "day")

# Example 1c: Alternative specification using the 'data' argument
lagged(pos, data = dat, id = "subject", day = "day")

# Example 2a: Lagged variable for 'pos' and 'neg'
lagged(dat[, c("pos", "neg")], id = dat$subject, day = dat$day)

# Example 2b: Alternative specification using the 'data' argument
lagged(pos, neg, data = dat, id = "subject", day = "day")

# Example 3: Lag-2 variables for 'pos' and 'neg'
lagged(pos, neg, data = dat, id = "subject", day = "day", lag = 2)

# Example 4: Lagged variable and time difference variable
lagged(pos, neg, data = dat, id = "subject", day = "day", time = "time")

# Example 5: Lagged variables and time difference variables,
# name variables
lagged(pos, neg, data = dat, id = "subject", day = "day", time = "time",
       name = c("p.lag1", "n.lag1"), name.td = c("p.diff", "n.diff"))

# Example 6: NA observations excluded from the data frame
dat.excl &lt;- dat[!is.na(dat$pos), ]

# Number of observation not taken into account, i.e.,
# - observation 4 used as lagged value for observation 6 for subject 1
# - observation 1 used as lagged value for observation 3 for subject 2
lagged(pos, data = dat.excl, id = "subject", day = "day")

# Number of observation taken into account by specifying the 'ob' argument
lagged(pos, data = dat.excl, id = "subject", day = "day", obs = "obs")
</code></pre>

<hr>
<h2 id='libraries'>Load and Attach Multiple Packages</h2><span id='topic+libraries'></span>

<h3>Description</h3>

<p>This function loads and attaches multiple add-on packages at once.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>libraries(..., install = FALSE, quiet = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="libraries_+3A_...">...</code></td>
<td>
<p>the names of the packages to be loaded, given as names
(e.g., <code>misty, lavaan, lme4</code>), or  literal character
strings (e.g., <code>"misty", "lavaan", "lme4"</code>), or character
vector (e.g., <code>c("misty", "lavaan", "lme4")</code>).</p>
</td></tr>
<tr><td><code id="libraries_+3A_install">install</code></td>
<td>
<p>logical: if <code>TRUE</code>, missing packages and dependencies are
installed.</p>
</td></tr>
<tr><td><code id="libraries_+3A_quiet">quiet</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), startup messages when loading
package are disabled.</p>
</td></tr>
<tr><td><code id="libraries_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, argument specification is checked.</p>
</td></tr>
<tr><td><code id="libraries_+3A_output">output</code></td>
<td>
<p>logical: logical: if <code>TRUE</code>, output is shown on the console.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+library">library</a></code>, <code><a href="base.html#topic+require">require</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Load packages using the names of the packages
misty::libraries(misty, lme4, lmerTest)

# Example 2: Load packages using literal character strings
misty::libraries("misty", "lme4", "lmerTest")

# Example 3: Load packages using a character vector
misty::libraries(c("misty", "lme4", "lmerTest"))

# Example 4: Check packages, i.e., TRUE = all depends/imports/suggests installed
misty::libraries(misty, lme4, lmerTest, output = FALSE)$result$restab

# Example 5: Depends, FALSE = not installed, TRUE = installed
misty::libraries(misty, lme4, lmerTest, output = FALSE)$result$depends

# Example 6: Imports, FALSE = not installed, TRUE = installed
misty::libraries(misty, lme4, lmerTest, output = FALSE)$result$imports

# Example 6: Suggests, FALSE = not installed, TRUE = installed
misty::libraries(misty, lme4, lmerTest, output = FALSE)$result$suggests

## End(Not run)
</code></pre>

<hr>
<h2 id='mplus.lca'>Mplus Model Specification for Latent Class Analysis</h2><span id='topic+mplus.lca'></span>

<h3>Description</h3>

<p>This function writes Mplus input files for conducting latent class analysis (LCA)
for continuous, count, ordered categorical, and unordered categorical variables.
LCA with continuous indicator variables are based on six different
variance-covariance structures, while LCA for all other variable types assume
local independence. By default, the function conducts LCA with continuous
variables and creates folders in the current working directory for each of the
six sets of analysis, writes Mplus input files for conducting LCA with
<em>k</em> = 1 to <em>k</em> = 6 classes into these folders, and writes the matrix
or data frame specified in <code>x</code> into a Mplus data file in the current working
directory. Optionally, all models can be estimated by setting the argument
<code>run.mplus</code> to <code>TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplus.lca(x, ind = NULL,
          type = c("continuous", "count", "categorical", "nominal"), cluster = NULL,
          folder = c("A_Invariant-Theta_Diagonal-Sigma",
                     "B_Varying-Theta_Diagonal-Sigma",
                     "C_Invariant-Theta_Invariant-Unrestrictred-Sigma",
                     "D_Invariant-Theta_Varying-Unrestricted-Sigma",
                     "E_Varying-Theta_Invariant-Unrestricted-Sigma",
                     "F_Varying-Theta_Varying-Unrestricted-Sigma"),
          file = "Data_LCA.dat", write = c("all", "folder", "data", "input"),
          useobservations = NULL, missing = -99, classes = 6, estimator = "MLR",
          starts = c(100, 50), stiterations = 10, lrtbootstrap = 1000,
          lrtstarts = c(0, 0, 100, 50), processors = 8,
         output = c("all", "SVALUES", "CINTERVAL", "TECH7", "TECH8", "TECH11", "TECH14"),
          replace.inp = FALSE, run.mplus = FALSE, Mplus = "Mplus",
          replace.out = c("always", "never", "modifiedDate"), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mplus.lca_+3A_x">x</code></td>
<td>
<p>a matrix or data frame. Note that all variable names must
be no longer than 8 character.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_ind">ind</code></td>
<td>
<p>a character vector indicating the variables names of the
latent class indicators in <code>x</code>.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_type">type</code></td>
<td>
<p>a character string indicating the variable type of the
latent class indicators, i.e., <code>"continuous"</code> (default)
for continuous variables, <code>"count"</code> for count variables,
<code>"categorical"</code> for binary or ordered categorical
variables, and <code>"nominal"</code> for unordered categorical
variables. Note that it is not possible to mix different
variable types in the analysis.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the cluster variable in
the matrix or data frame specified in <code>x</code> representing
the nested grouping structure for computing cluster-robust
standard errors. Note that specifying a cluster variables
does not have any effect on the information criteria,
but on the Vuong-Lo-Mendell-Rubin likelihood ratio test
of model fit.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_folder">folder</code></td>
<td>
<p>a character vector with six character strings for specifying
the names of the six folder representing different
variance-covariance structures for conducting LCA with
continuous indicator variables. There is only one folder
for LCA with all other variable types which is called
<code>"LCA_1-x_Classes"</code> with <code>x</code> being the maximum number of classes
specified in the argument <code>classes</code>.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_file">file</code></td>
<td>
<p>a character string naming the Mplus data file with or
without the file extension '.dat', e.g., <code>"Data_LCA.dat"</code>
(default) or <code>"Data_LCA"</code>.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_write">write</code></td>
<td>
<p>a character string or character vector indicating whether
to create the six folders specified in the argument
<code>folder</code> (<code>"folder"</code>), to write the matrix or
data frame specified in <code>x</code> into a Mplus data file
(<code>"data"</code>), and write the Mplus input files into
the six folders specified in the argument <code>folder</code>
(<code>"input"</code>). By default, the function creates the
folders, writes the Mplus data file, and writes the Mplus
input files into the folders.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_useobservations">useobservations</code></td>
<td>
<p>a character string indicating the conditional statement
to select observations.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_missing">missing</code></td>
<td>
<p>a numeric value or character string representing missing
values (<code>NA</code>) in the Mplus data set. This values
or character string will be specified in the Mplus input
file as <code>MISSING IS ALL(missing)</code>. By default,
<code>-99</code> is used to represent missing values.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_classes">classes</code></td>
<td>
<p>an integer value specifying the maximum number of classes
for the latent class analysis. By default, LCA with
a maximum of 6 classes isspecified (i.e., <em>k</em> = 1
to <em>k</em> = 6).</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_estimator">estimator</code></td>
<td>
<p>a character string for specifying the <code>ESTIMATOR</code>
option in Mplus. By default, the estimator <code>"MLR"</code>
is used.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_starts">starts</code></td>
<td>
<p>a vector with two integer values for specifying the
<code>STARTS</code> option in Mplus. The first number represents
the number of random sets of starting values to generate
in the initial stage and the second number represents the
optimizations to use in the final stage. By default, 500
random sets of starting values are generated and 100
optimizations are carried out in the final stage.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_stiterations">stiterations</code></td>
<td>
<p>an integer value specifying the <code>STITERATIONS</code> option
in Mplus. The numeric value represents the maximum number
of iterations allowed in the initial stage. By default,
50 iterations are requested.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_lrtbootstrap">lrtbootstrap</code></td>
<td>
<p>an integer value for specifying the <code>LRTBOOTSTRAP</code>
option in Mplus when requesting a parametric bootstrapped
likelihood ratio test (i.e., <code>output = "TECH14"</code>).
The value represents the number of bootstrap draws to
be used in estimating the <em>p</em>-value of the parametric
bootstrapped likelihood ratio test. By default, 1000
bootstrap draws are requested.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_lrtstarts">lrtstarts</code></td>
<td>
<p>a vector with four integer values for specifying the
<code>LRTSTARTS</code> option in Mplus when requesting a
parametric bootstrapped likelihood ratio test (i.e.,
<code>output = "TECH14"</code>). The values specify the number
of starting values to use in the initial stage and the
number of optimizations to use in the final stage for
the <code>k - 1</code> and <code>k</code> classes model when the
data generated by bootstrap draws are analyzed. By default,
0 random sets of starting values in the initial stage
and 0 optimizations in the final stage are used for the
<code>k - 1</code> classes model and 100 random sets of starting
values in the initial stage and 50 optimizations in the
final stage are used for the <code>k</code> class model.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_processors">processors</code></td>
<td>
<p>an integer value for specifying the <code>PROCESSORS</code>
option in Mplus. The value specifies the number of
processors and threads to be used for parallel computing
to increase computational speed. By default, 8 processors
and threads are used for parallel computing.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_output">output</code></td>
<td>
<p>a character string or character vector specifying the
<code>TECH</code> options in the <code>OUTPUT</code> section in Mplus,
i.e., <code>SVALUES</code> to request input statements that
contain parameter estimates from the analysis, <code>CINTERVAL</code>
to request confidence intervals, <code>TECH7</code> to request
sample statistics for each class using raw data weighted
by the estimated posterior probabilities for each class,
<code>TECH8</code> to request the optimization history in
estimating the model, <code>TECH11</code> to request the
Lo-Mendell-Rubin likelihood ratio test of model fit,
and <code>TECH14</code> to request a parametric bootstrapped
likelihood ratio test. By default, <code>SVALUES</code> and
<code>TECH11</code> are requested. Note that <code>TECH11</code>
is only available for the <code>MLR</code> estimator.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_replace.inp">replace.inp</code></td>
<td>
<p>logical: if <code>TRUE</code>, all existing input files in the
folder specified in the argument <code>folder</code> are replaced.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_run.mplus">run.mplus</code></td>
<td>
<p>logical: if <code>TRUE</code>, all models in the folders specified
in the argument <code>folder</code> are estimated by using the
<code>run.mplus</code> function in the R package <code>misty</code>.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_mplus">Mplus</code></td>
<td>
<p>a character string for specifying the name or path of
the Mplus executable to be used for running models. This
covers situations where Mplus is not in the system's path,
or where one wants to test different versions of the Mplus
program. Note that there is no need to specify this argument
for most users since it has intelligent defaults.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_replace.out">replace.out</code></td>
<td>
<p>a character string for specifying three settings, i.e.,
<code>"always"</code> to run all models regardless of whether
an output file for the model exists, <code>"never"</code> (default)
to not run any model that has an existing output file,
and <code>"modifiedDate"</code> to only runs a model if the
modified date for the input file is more recent than
the output file modified date.</p>
</td></tr>
<tr><td><code id="mplus.lca_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Latent class analysis (LCA) is a model-based clustering and classification
method used to identify qualitatively different classes of observations which
are unknown and must be inferred from the data. LCA can accommodate continuous,
count, binary, ordered categorical, and unordered categorical indicators. LCA
with continuous indicator variables are also known as latent profile analysis
(LPA). In LPA, the within-profile variance-covariance structures represent
different assumptions regarding the variance and covariance of the indicator
variables both within and between latent profiles. As the best within-profile
variance-covariance structure is not known a priori, all of the different
structures must be investigated to identify the best model (Masyn, 2013). This
function specifies six different variance-covariance structures labeled A to F
(see Table 1 in Patterer et al, 2023):
</p>

<dl>
<dt><strong>Model A</strong></dt><dd><p>The within-profile variance is constrained to be
profile-invariant and covariances are constrained to be 0 in all profiles
(i.e., equal variances across profiles and no covariances among indicator
variables). This is the default setting in Mplus.</p>
</dd>
<dt><strong>Model B</strong></dt><dd><p>The within-profile variance is profile-varying and
covariances are constrained to be 0 in all profiles (i.e., unequal variances
across profiles and no covariances among indicator variables).</p>
</dd>
<dt><strong>Model C</strong></dt><dd><p>The within-profile variance is constrained to be
profile-invariant and covariances are constrained to be equal in all profiles
(i.e., equal variances and covariances across profiles).</p>
</dd>
<dt><strong>Model D</strong></dt><dd><p>The within-profile variance is constrained to be
profile-invariant and covariances are profile-varying (i.e., equal variances
across profiles and unequal covariances across profiles).</p>
</dd>
<dt><strong>Model E</strong></dt><dd><p>The within-profile variances are profile-varying and
covariances are constrained to be equal in all profiles (i.e., unequal
variances across profiles and equal covariances across profiles).</p>
</dd>
<dt><strong>Model F</strong></dt><dd><p>The within-class variance and covariances are both
profile-varying (i.e., unequal variances and covariances across profiles).</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>matrix or data frame specified in the argument x</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with six entries for each of the variance-covariance
structures and Mplus inputs based on different number
of profiles in case of continuous indicators or list of
Mplus inputs based on different number of classes in case
of count, ordered or unordered categorical indicators.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Masyn, K. E. (2013). Latent class analysis and finite mixture modeling. In T. D.
Little (Ed.), <em>The Oxford handbook of quantitative methods: Statistical analysis</em>
(pp. 551–611). Oxford University Press.
</p>
<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>
<p>Patterer, A. S., Yanagida, T., Kühnel, J., &amp; Korunka, C. (2023). Daily receiving
and providing of social support at work: Identifying support exchange patterns
in hierarchical data. <em>Journal of Work and Organizational Psychology, 32</em>(4),
489-505. https://doi.org/10.1080/1359432X.2023.2177537
</p>


<h3>See Also</h3>

<p><code><a href="#topic+result.lca">result.lca</a></code>, <code><a href="#topic+run.mplus">run.mplus</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>,
<code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

#-------------------------------------------------------------------------------
# Example 1: LCA with k = 1 to k = 8 profiles, continuous indicators
# Input statements that contain parameter estimates
# Vuong-Lo-Mendell-Rubin LRT and bootstrapped LRT
mplus.lca(HolzingerSwineford1939, ind = c("x1", "x2", "x3", "x4"),
          classes = 8, output = c("SVALUES", "TECH11", "TECH14"))

#-------------------------------------------------------------------------------
# Example 22: LCA with k = 1 to k = 6 profiles, ordered categorical indicators
# Select observations with ageyr &lt;= 13
# Estimate all models in Mplus
mplus.lca(round(HolzingerSwineford1939[, -5]), ind = c("x1", "x2", "x3", "x4"),
          type = "categorical", useobservations = "ageyr &lt;= 13",
          run.mplus = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.cfa'>Multilevel Confirmatory Factor Analysis</h2><span id='topic+multilevel.cfa'></span>

<h3>Description</h3>

<p>This function is a wrapper function for conducting multilevel confirmatory factor
analysis to investigate four types of constructs, i.e., within-cluster constructs,
shared cluster-level constructs, configural cluster constructs, and simultaneous
shared and configural cluster constructs by calling the <code>cfa</code> function in
the R package <span class="pkg">lavaan</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.cfa(..., data = NULL, cluster, model = NULL, rescov = NULL,
               model.w = NULL, model.b = NULL, rescov.w = NULL, rescov.b = NULL,
               const = c("within", "shared", "config", "shareconf"),
               fix.resid = NULL, ident = c("marker", "var", "effect"),
               ls.fit = TRUE, estimator = c("ML", "MLR"),
               optim.method = c("nlminb", "em"), missing = c("listwise", "fiml"),
               print = c("all", "summary", "coverage", "descript", "fit", "est",
                         "modind", "resid"),
               mod.minval = 6.63, resid.minval = 0.1, digits = 3, p.digits = 3,
               as.na = NULL, write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.cfa_+3A_...">...</code></td>
<td>
<p>a matrix or data frame. If <code>model</code>, <code>model.w</code>,
and <code>model.b</code> are <code>NULL</code>, multilevel confirmatory
factor analysis based on a measurement model with one factor
labeled <code>wf</code> at the Within level and one factor labeled
<code>bf</code> at the Between level comprising all variables in
the matrix or data frame is conducted. Note that the cluster
variable specified in <code>cluster</code> is excluded from <code>...</code>
when specifying the argument <code>cluster</code> using the variable
name of the cluster variable. If <code>model</code> or <code>mode.w</code>
and <code>model.b</code> is specified, the matrix or data frame
needs to contain all variables used in the <code>model</code>
argument(s). Alternatively, an expression indicating
the variable names in <code>data</code>.
Note that the operators <code>.</code>, <code>+</code>, <code>-</code>,
<code>~</code>, <code>:</code>, <code>::</code>, and <code>!</code> can also be
used to select variables, see 'Details' in the
<code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>...</code> or <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_model">model</code></td>
<td>
<p>a character vector for specifying the same factor structure
with one factor at the Within and Between Level, or a list
of character vectors for specifying the same measurement
model with more than one factor at the Within and Between
Level, e.g.,<code>model = c("x1", "x2", "x3", "x4")</code> for
specifying a measurement model with one factor labeled <code>wf</code>
at the Within level and a measurement model with one factor
labeled <code>bf</code> at the Between level each comprising four
indicators, or <code>model = list(factor1 = c("x1", "x2", "x3", "x4"),
factor2 = c("x5", "x6", "x7", "x8"))</code> for specifying a
measurement model with two latent factors labeled <code>wfactor1</code>
and <code>wfactor2</code> at the Within level and a measurement
model with two latent factors labeled <code>bfactor1</code> and
<code>bfactor2</code> at the Between level each comprising four
indicators. Note that the name of each list element is used
to label factors, where prefixes <code>w</code> and <code>b</code> are
added the labels to distinguish factor labels at the Within
and Between level, i.e., all list elements need to be named,
otherwise factors are labeled with <code>"wf1", "wf2", "wf3"</code>
for labels at the Within level and <code>"bf1", "bf2", "bf3"</code>
for labels at the Between level and so on.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances at the Within level, e.g. <code>rescov = c("x1", "x2")</code>
for specifying a residual covariance between indicators <code>x1</code>
and <code>x2</code> at the Within level or <code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code>
for specifying residual covariances between indicators <code>x1</code>
and <code>x2</code>, and indicators <code>x3</code> and <code>x4</code> at
the Within level. Note that residual covariances at the
Between level can only be specified by using the arguments
<code>model.w</code>, <code>model.b</code>, and <code>model.b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_model.w">model.w</code></td>
<td>
<p>a character vector specifying a measurement model with one
factor at the Within level, or a list of character vectors
for specifying a measurement model with more than one factor
at the Within level.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_model.b">model.b</code></td>
<td>
<p>a character vector specifying a measurement model with one
factor at the Between level, or a list of character vectors
for specifying a measurement model with more than one factor
at the Between level.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_rescov.w">rescov.w</code></td>
<td>
<p>a character vector or a list of character vectors for
specifying residual covariances at the Within level.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_rescov.b">rescov.b</code></td>
<td>
<p>a character vector or a list of character vectors for
specifying residual covariances at the Between level.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_const">const</code></td>
<td>
<p>a character string indicating the type of construct(s), i.e.,
<code>"within"</code> for within-cluster constructs, <code>"shared"</code>
for shared cluster-level constructs, <code>"config"</code> (default)
for configural cluster constructs, and <code>"shareconf"</code>
for simultaneous shared and configural cluster constructs.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_fix.resid">fix.resid</code></td>
<td>
<p>a character vector for specifying residual variances to be
fixed at 0 at the Between level, e.g., <code>fix.resid = c("x1", "x3")</code>
to fix residual variances of indicators <code>x1</code> and <code>x2</code>
at the Between level at 0. Note that it is also possible
to specify <code>fix.resid = "all"</code> which fixes all residual
variances at the Between level at 0 in line with the strong
factorial measurement invariance assumption across cluster.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_ident">ident</code></td>
<td>
<p>a character string indicating the method used for identifying
and scaling latent variables, i.e., <code>"marker"</code> for the
marker variable method fixing the first factor loading of
each latent variable to 1, <code>"var"</code> for the fixed variance
method fixing the variance of each latent variable to 1,
or <code>"effect"</code> for the effects-coding method using equality
constraints so that the average of the factor loading for
each latent variable equals 1.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_ls.fit">ls.fit</code></td>
<td>
<p>logical: if <code>TRUE</code> (default) level-specific fit indices
are computed when specifying a model using the arguments
<code>model.w</code> and <code>model.b</code> given the model does not
contain any cross-level equality constraints.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used:
<code>"ML"</code> for maximum likelihood with conventional standard
errors and <code>"MLR"</code> (default) for maximum likelihood
with Huber-White robust standard errors and a scaled test
statistic that is asymptotically equal to the Yuan-Bentler
test statistic. Note that by default, full information maximum
likelihood (FIML) method is used to deal with missing data
when using <code>"ML"</code> (<code>missing = "fiml"</code>), whereas
incomplete cases are removed listwise (i.e., <code>missing = "listwise"</code>)
when using <code>"MLR"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_optim.method">optim.method</code></td>
<td>
<p>a character string indicating the optimizer, i.e., <code>"nlminb"</code>
(default) for the unconstrained and bounds-constrained
quasi-Newton method optimizer and <code>"em"</code> for the
Expectation Maximization (EM) algorithm.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data,
i.e., <code>"listwise"</code> (default) for listwise deletion or
<code>"fiml"</code> for full information maximum likelihood (FIML)
method. Note that FIML method is only available when <code>estimator = "ML"</code>,
that it takes longer to estimate the model  using FIML, and
that FIML is prone to convergence issues which might be
resolved by switching to listwise deletion.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e. <code>"all"</code> for all
results, <code>"summary"</code> for a summary of the specification
of the estimation method and missing data handling in lavaan,
<code>"coverage"</code> for the variance-covariance coverage of
the data, <code>"descript"</code> for descriptive statistics,
<code>"fit"</code> for model fit,  <code>"est"</code> for parameter
estimates, and <code>"modind"</code> for modification indices.
By default, a summary of the specification, descriptive
statistics, model fit, and parameter estimates are printed.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_mod.minval">mod.minval</code></td>
<td>
<p>numeric value to filter modification indices and only
show modifications with a modification index value equal
or higher than this minimum value. By default, modification
indices equal or higher 6.63 are printed. Note that a
modification index value of 6.63 is equivalent to a
significance level of <code class="reqn">\alpha = .01</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_resid.minval">resid.minval</code></td>
<td>
<p>numeric value indicating the minimum absolute residual
correlation coefficients and standardized means to
highlight in boldface. By default, absolute residual
correlation coefficients and standardized means equal
or higher 0.1 are highlighted. Note that highlighting
can be disabled by setting the minimum value to 1.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that loglikelihood,
information criteria and chi-square test statistic is
printed with <code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only
applied to <code>x</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification, convergence
and model identification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.cfa_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>specified model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>results of the convergence and model identification check</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary of the specification of the estimation method
and missing data handling in lavaan, <code>coverage</code> for
the variance-covariance coverage of the data, <code>descript</code>
for descriptive statistics, <code>fit</code> for model fit,
<code>est</code> for parameter estimates, and <code>modind</code>
for modification indices.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>cfa</code>, <code>lavInspect</code>, <code>lavTech</code>,
<code>modindices</code>, <code>parameterEstimates</code>, and <code>standardizedsolution</code>
provided in the R package <span class="pkg">lavaan</span> by Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.cfa">item.cfa</a></code>, <code><a href="#topic+multilevel.fit">multilevel.fit</a></code>, <code><a href="#topic+multilevel.invar">multilevel.invar</a></code>,
<code><a href="#topic+multilevel.omega">multilevel.omega</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Model specification using 'x' for a one-factor model
# with the same factor structure with one factor at the Within and Between Level

#..........
# Cluster variable specification

# Example 1a: Cluster variable 'cluster' in 'x'
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4", "cluster")], cluster = "cluster")

# Example 1b: Cluster variable 'cluster' not in 'x'
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster)

# Example 1c: Alternative specification using the 'data' argument
multilevel.cfa(y1:y4, data = Demo.twolevel, cluster = "cluster")

#..........
# Type of construct

# Example 2a: Within-cluster constructs
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               const = "within")

# Example 2b: Shared cluster-level construct
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               const = "shared")

# Example 2c: Configural cluster construct (default)
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               const = "config")

# Example 2d: Simultaneous shared and configural cluster construct
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               const = "shareconf")

#..........
# Residual covariances at the Within level

# Example 3a: Residual covariance between 'y1' and 'y3'
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               rescov = c("y1", "y3"))

# Example 3b: Residual covariance between 'y1' and 'y3', and 'y2' and 'y4'
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               rescov = list(c("y1", "y3"), c("y2", "y4")))

#..........
# Residual variances at the Between level fixed at 0

# Example 4a: All residual variances fixed at 0
# i.e., strong factorial invariance across clusters
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               fix.resid = "all")

# Example 4b: Fesidual variances of 'y1', 'y2', and 'y4' fixed at 0
# i.e., partial strong factorial invariance across clusters
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               fix.resid = c("y1", "y2", "y4"))

#..........
# Print all results

# Example 5: Set minimum value for modification indices to 1
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               print = "all", mod.minval = 1)

#..........
# Example 6: lavaan model and summary of the estimated model

mod &lt;- multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
                      output = FALSE)

# lavaan model syntax
cat(mod$model)

# Fitted lavaan object
lavaan::summary(mod$model.fit, standardized = TRUE, fit.measures = TRUE)

#..........
# Write results

# Example 7a: Assign results into an object and write results into an Excel file
mod &lt;- multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
                      print = "all", write = "Multilevel_CFA.txt", output = FALSE)

# Example 7b: Assign results into an object and write results into an Excel file
mod &lt;- multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
                      print = "all", output = FALSE)

# Write results into an Excel file
write.result(mod, "Multilevel_CFA.xlsx")

# Estimate model and write results into an Excel file
multilevel.cfa(Demo.twolevel[, c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster,
               print = "all", write = "Multilevel_CFA.xlsx")

#----------------------------------------------------------------------------
# Model specification using 'model' for one or multiple factor model
# with the same factor structure at the Within and Between Level

# Example 8a: One-factor model
multilevel.cfa(Demo.twolevel, cluster = "cluster", model = c("y1", "y2", "y3", "y4"))

# Example 8b: Two-factor model
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

# Example 8c: Two-factor model with user-specified labels for the factors
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model = list(factor1 = c("y1", "y2", "y3"), factor2 = c("y4", "y5", "y6")))

#..........
# Type of construct

# Example 9a: Within-cluster constructs
multilevel.cfa(Demo.twolevel, cluster = "cluster", const = "within",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

# Example 9b: Shared cluster-level construct
multilevel.cfa(Demo.twolevel, cluster = "cluster", const = "shared",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

# Example 9c: Configural cluster construct (default)
multilevel.cfa(Demo.twolevel, cluster = "cluster", const = "config",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

# Example 9d: Simultaneous shared and configural cluster construct
multilevel.cfa(Demo.twolevel, cluster = "cluster", const = "shareconf",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

#..........
# Residual covariances at the Within level

# Example 10a: Residual covariance between 'y1' and 'y4' at the Within level
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")),
               rescov = c("y1", "y4"))

# Example 10b: Fix all residual variances at 0
# i.e., strong factorial invariance across clusters
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")),
               fix.resid = "all")

#----------------------------------------------------------------------------
# Model specification using 'model.w' and 'model.b' for one or multiple factor model
# with different factor structure at the Within and Between Level

# Example 11a: Two-factor model at the Within level and one-factor model at the Between level
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model.w = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")),
               model.b = c("y1", "y2", "y3", "y4", "y5", "y6"))

# Example 11b: Residual covariance between 'y1' and 'y4' at the Within level
# Residual covariance between 'y5' and 'y6' at the Between level
multilevel.cfa(Demo.twolevel, cluster = "cluster",
               model.w = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")),
               model.b = c("y1", "y2", "y3", "y4", "y5", "y6"),
               rescov.w = c("y1", "y4"),
               rescov.b = c("y5", "y6"))

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.cor'>Within-Group and Between-Group Correlation Matrix</h2><span id='topic+multilevel.cor'></span>

<h3>Description</h3>

<p>This function is a wrapper function for computing the within-group and
between-group correlation matrix by calling the <code>sem</code> function in the
R package <span class="pkg">lavaan</span> and provides standard errors, z test statistics, and
significance values (<em>p</em>-values) for testing the hypothesis
H0: <code class="reqn">\rho</code> = 0 for all pairs of variables within and between groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.cor(..., data = NULL, cluster, within = NULL, between = NULL,
               estimator = c("ML", "MLR"), optim.method = c("nlminb", "em"),
               missing = c("listwise", "fiml"), sig = FALSE, alpha = 0.05,
               print = c("all", "cor", "se", "stat", "p"), split = FALSE,
               order = FALSE, tri = c("both", "lower", "upper"), tri.lower = TRUE,
               p.adj = c("none", "bonferroni", "holm", "hochberg", "hommel",
                         "BH", "BY", "fdr"), digits = 2, p.digits = 3,
               as.na = NULL, write = NULL, append = TRUE, check = TRUE,
               output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.cor_+3A_...">...</code></td>
<td>
<p>a matrix or data frame.  Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>multilevel.cor(x1, x2, x3, data = dat)</code>. Note that
the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used to
select variables, see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>...</code> or <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_within">within</code></td>
<td>
<p>a character vector representing variables that are measured
on the within level and modeled only on the within level.
Variables not mentioned in <code>within</code> or <code>between</code>
are measured on the within level and will be modeled on both
the within and between level.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_between">between</code></td>
<td>
<p>a character vector representing variables that are measured
on the between level and modeled only on the between level.
Variables not mentioned in <code>within</code> or <code>between</code>
are measured on the within level and will be modeled on
both the within and between level.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used:
<code>"ML"</code> (default) for maximum likelihood with
conventional standard errors and <code>"MLR"</code> for maximum
likelihood with Huber-White robust standard errors. Note
that by default, full information maximum likelihood (FIML)
method is used to deal with missing data when using
<code>"ML"</code> (<code>missing = "fiml"</code>), whereas incomplete
cases are removed listwise (i.e., <code>missing = "listwise"</code>)
when using <code>"MLR"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_optim.method">optim.method</code></td>
<td>
<p>a character string indicating the optimizer, i.e., <code>nlminb</code>
(default) for the unconstrained and bounds-constrained
quasi-Newton method optimizer and <code>"em"</code> for the
Expectation Maximization (EM) algorithm.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing
data, i.e., <code>"listwise"</code> for listwise deletion or
<code>"fiml"</code> (default) for full information maximum
likelihood (FIML) method. Note that FIML method is only
available when <code>estimator = "ML"</code>. Note that it takes
longer to estimate the model when using FIML and using FIML
might cause issues in model convergence, these issues might
be resolved by switching to listwise deletion.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_sig">sig</code></td>
<td>
<p>logical: if <code>TRUE</code>, statistically significant
correlation coefficients are shown in boldface on the
console.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the significance
level at which correlation coefficients are printed
boldface when <code>sig = TRUE</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e. <code>"all"</code> for all
results, <code>"cor"</code> for correlation coefficients,
<code>"se"</code> for standard errors, <code>"stat"</code> for z test
statistics, and <code>"p"</code> for <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is split in
within-group and between-group correlation matrix.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_order">order</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables in the output table are
ordered, so that variables specified in the argument
<code>between</code> are shown first.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_tri">tri</code></td>
<td>
<p>a character string indicating which triangular of the
matrix to show on the console when <code>split = TRUE</code>,
i.e., <code>both</code> for upper and <code>upper</code> for the upper
triangular.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_tri.lower">tri.lower</code></td>
<td>
<p>logical: if <code>TRUE</code> (default) and <code>split = FALSE</code>
(default), within-group correlations are shown in the lower
triangular and between-group correlation are shown in the
upper triangular.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_p.adj">p.adj</code></td>
<td>
<p>a character string indicating an adjustment method for
multiple testing based on <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>, i.e.,
<code>none</code> (default), <code>bonferroni</code>, <code>holm</code>,
<code>hochberg</code>, <code>hommel</code>, <code>BH</code>, <code>BY</code>, or
<code>fdr</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying correlation coefficients.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis. Note that <code>as.na()</code> function
is only applied to <code>x</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.cor_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specification of the within-group and between-group variables is in line
with the syntax in Mplus. That is, the <code>within</code> argument is used to
identify the variables in the matrix or data frame specified in <code>x</code> that
are measured on the individual level and modeled only on the within level.
They are specified to have no variance in the between part of the model. The
<code>between</code> argument is used to identify the variables in the matrix or
data frame specified in <code>x</code> that are measured on the cluster level and
modeled only on the between level. Variables not mentioned in the arguments
<code>within</code> or <code>between</code> are measured on the individual level and will
be modeled on both the within and between level.
</p>
<p>The function uses maximum likelihood estimation with conventional standard
errors (<code>estimator = "ML"</code>) which are not robust against non-normality
and full information maximum likelihood (FIML) method (<code>missing = "fiml"</code>)
to deal with missing data by default. FIML method cannot be used when
within-group variables have no variance within some clusters. In this cases,
the function
will switch to listwise deletion. Note that the current lavaan version 0.6-11
supports FIML method only for maximum likelihood estimation with conventional
standard errors (<code>estimator = "ML"</code>) in multilevel models. Maximum
likelihood estimation with Huber-White robust standard errors
(<code>estimator = "MLR"</code>) uses listwise deletion to deal with missing data.
When using FIML method there might be issues in model convergence, which might
be resolved by switching to listwise deletion (<code>missing = "listwise"</code>).
</p>
<p>The lavaan package uses a quasi-Newton optimization method (<code>"nlminb"</code>)
by default. If the optimizer does not converge, model estimation will switch
to the Expectation Maximization (EM) algorithm.
</p>
<p>Statistically significant correlation coefficients can be shown in boldface
on the console when specifying <code>sig = TRUE</code>. However, this option is not
supported when using R Markdown, i.e., the argument <code>sig</code> will switch to
<code>FALSE</code>.
</p>
<p>Adjustment method for multiple testing when specifying the argument <code>p.adj</code>
is applied to the within-group and between-group correlation matrix separately.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>x</code> including the group variable
specified in <code>cluster</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
specification of the estimation method and missing data
handling in lavaan, <code>wb.cor</code> for the within- and
between-group correlations, <code>wb.se</code> for the standard
error of the within- and between-group correlations,
<code>wb.stat</code> for the test statistic of within- and between-group
correlations, <code>wb.p</code> for the significance value of
the within- and between-group correlations, <code>with.cor</code>
for the within-group correlations, <code>with.se</code> for the
standard error of the within-group correlations, <code>with.stat</code>
for the test statistic of within-group correlations, <code>with.p</code>
for the significance value of the within-group correlations,
<code>betw.cor</code> for the between-group correlations, <code>betw.se</code>
for the standard error of the between-group correlations,
<code>betw.stat</code> for the test statistic of between-group
correlations, <code>betw.p</code> for the significance value of
the between-group correlations</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>sem</code>, <code>lavInspect</code>,
<code>lavMatrixRepresentation</code>, <code>lavTech</code>, <code>parameterEstimates</code>,
and <code>standardizedsolution</code> provided in the R package <span class="pkg">lavaan</span> by
Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel analysis:
Techniques and applications</em> (3rd. ed.). Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An
introduction to basic and advanced multilevel modeling</em> (2nd ed.). Sage
Publishers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>,
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code>, <code><a href="#topic+cluster.scores">cluster.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#-------------------------------------------------------------------------------
# Cluster variable specification

# Example 1a: Cluster variable 'cluster' in 'x'
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3", "cluster")], cluster = "cluster")

# Example 1b: Cluster variable 'cluster' not in 'x'
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")], cluster = Demo.twolevel$cluster)

# Example 1c: Alternative specification using the 'data' argument
multilevel.cor(x1:x3, data = Demo.twolevel, cluster = "cluster")

#-------------------------------------------------------------------------------
# Example 2: All variables modeled on both the within and between level
# Highlight statistically significant result at alpha = 0.05
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")], sig = TRUE,
              cluster = Demo.twolevel$cluster)

# Example 3: Split output table in within-group and between-group correlation matrix.
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")],
               cluster = Demo.twolevel$cluster, split = TRUE)

# Example 4: Print correlation coefficients, standard errors, z test statistics,
# and p-values
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")],
               cluster = Demo.twolevel$cluster, print = "all")

# Example 5: Print correlation coefficients and p-values
# significance values with Bonferroni correction
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")],
               cluster = Demo.twolevel$cluster, print = c("cor", "p"),
               p.adj = "bonferroni")

#-------------------------------------------------------------------------------
# Example 6: Variables "y1", "y2", and "y2" modeled on both the within and between level
# Variables "w1" and "w2" modeled on the cluster level
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3", "w1", "w2")],
               cluster = Demo.twolevel$cluster,
               between = c("w1", "w2"))

# Example 7: Show variables specified in the argument 'between' first
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3", "w1", "w2")],
               cluster = Demo.twolevel$cluster,
               between = c("w1", "w2"), order = TRUE)

#-------------------------------------------------------------------------------
# Example 8: Variables "y1", "y2", and "y2" modeled only on the within level
# Variables "w1" and "w2" modeled on the cluster level
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3", "w1", "w2")],
               cluster = Demo.twolevel$cluster,
               within = c("y1", "y2", "y3"), between = c("w1", "w2"))

#-------------------------------------------------------------------------------
# Example 9: lavaan model and summary of the multilevel model used to compute the
# within-group and between-group correlation matrix

mod &lt;- multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")],
                      cluster = Demo.twolevel$cluster, output = FALSE)

# lavaan model syntax
mod$model

# Fitted lavaan object
lavaan::summary(mod$model.fit, standardized = TRUE)

#----------------------------------------------------------------------------
# Write Results

# Example 10a: Write results into a text file
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")],
               cluster = Demo.twolevel$cluster,
               write = "Multilevel_Correlation.txt")

# Example 10b: Write results into an Excel file
multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")],
               cluster = Demo.twolevel$cluster,
               write = "Multilevel_Correlation.xlsx")

result &lt;- multilevel.cor(Demo.twolevel[, c("y1", "y2", "y3")],
                         cluster = Demo.twolevel$cluster, output = FALSE)
write.result(result, "Multilevel_Correlation.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.descript'>Multilevel Descriptive Statistics for Two-Level and Three-Level Data</h2><span id='topic+multilevel.descript'></span>

<h3>Description</h3>

<p>This function computes descriptive statistics for two-level and three-level
multilevel data, e.g. average cluster size, variance components, intraclass
correlation coefficient, design effect, and effective sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.descript(..., data = NULL, cluster, type = c("1a", "1b"),
                    method = c("aov", "lme4", "nlme"),
                    print = c("all", "var", "sd"), REML = TRUE, digits = 2,
                    icc.digits = 3, as.na = NULL, write = NULL, append = TRUE,
                    check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.descript_+3A_...">...</code></td>
<td>
<p>a numeric vector, matrix, or data frame. Alternatively, an
expression indicating the variable names in <code>data</code> e.g.,
<code>multilevel.descript(x1, x2, x3, data = dat, cluster = "cluster")</code>. Note that the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector, matrix, or data frame for
the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the name of the cluster
variable in <code>...</code> or <code>data</code> for two-level data,
a character vector indicating the names of the cluster
variables in <code>...</code> for three-level data, or a vector
or data frame representing the nested grouping structure
(i.e., group or cluster variables). Alternatively, a
character string or character vector indicating the variable
name(s) of the cluster variable(s) in <code>data</code>. Note that
the cluster variable at Level 3 come first in a three-level
model, i.e., <code>cluster = c("level3", "level2")</code>.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of intraclass
correlation coefficient, i.e., <code>type = "1a"</code> (default)
for ICC(1) representing the propotion of variance at Level 2 and Level 3,
<code>type = "1b"</code> representing an estimate of the expected correlation
between two randomly chosen elements in the same group when specifying
a three-level model (i.e., two cluster variables). See 'Details' in the
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code> function for the formula used
in this function.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_method">method</code></td>
<td>
<p>a character string indicating the method used to estimate
intraclass correlation coefficients, i.e., <code>"aov"</code> ICC
estimated using the <code>aov</code> function, <code>"lme4"</code> (default)
ICC estimated using the <code>lmer</code> function in the <span class="pkg">lme4</span>
package, <code>"nlme"</code> ICC estimated using the <code>lme</code> function
in the <span class="pkg">nlme</span> package.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results to
show on the console, i.e. <code>"all"</code> for variances and standard deviations,
<code>"var"</code> (default) for variances, or <code>"sd"</code> for standard deviations
within and between clusters.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_reml">REML</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), restricted maximum likelihood
is used to estimate the null model when using the <code>lmer()</code>
function in the <span class="pkg">lme4</span> package or the <code>lme()</code> function in
the <span class="pkg">nlme</span> package.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_icc.digits">icc.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying intraclass correlation coefficients.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied
to <code>...</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.descript_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Two-Level Model</strong></dt><dd><p>In a two-level model, the intraclass
correlation coefficients, design effect, and the effective sample size are
computed based on the random intercept-only model:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ij} = \gamma_{00} + u_{0j} + r_{ij}</code>
</p>

<p>where the variance in <code class="reqn">Y</code> is decomposed into two independent components:
<code class="reqn">\sigma^2_{u_{0}}</code>, which represents the variance at Level 2, and
<code class="reqn">\sigma^2_{r}</code>, which represents the variance at Level 1 (Hox et al.,
2018). For the computation of the intraclass correlation coefficients, see
'Details' in the <code><a href="#topic+multilevel.icc">multilevel.icc</a></code> function. The design effect
represents the effect of cluster sampling on the variance of parameter
estimation and is defined by the equation
</p>
<p style="text-align: center;"><code class="reqn">deff = (\frac{SE_{Cluster}}{SE_{Simple}})^2 = 1 + \rho(J - 1)</code>
</p>

<p>where <code class="reqn">SE_{Cluster}</code> is the standard error under cluster sampling,
<code class="reqn">SE_{Simple}</code> is the standard error under simple random sampling,
<code class="reqn">\rho</code> is the intraclass correlation coefficient, ICC(1), and
<code class="reqn">J</code> is the average cluster size. The effective sample size is defined
by the equation:
</p>
<p style="text-align: center;"><code class="reqn">N_{effective} = \frac{N{total}}{deff}</code>
</p>

<p>The effective sample size <code class="reqn">N_{effective}</code> represents the equivalent total
sample size that we should use in estimating the standard error (Snijders &amp;
Bosker, 2012).
</p>
</dd>
<dt><strong>Three-Level Model</strong></dt><dd><p>In a three-level model, the intraclass
correlation coefficients, design effect, and the effective sample size are
computed based on the random intercept-only model:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ijk} = \gamma_{000} + v_{0k} + u_{0jk} + r_{ijk}</code>
</p>

<p>where the variance in <code class="reqn">Y</code> is decomposed into three independent components:
<code class="reqn">\sigma^2_{v_{0}}</code>, which represents the variance at Level 3,
<code class="reqn">\sigma^2_{u_{0}}</code>, which represents the variance at Level 2, and
<code class="reqn">\sigma^2_{r}</code>, which represents the variance at Level 1 (Hox et al., 2018).
For the computation of the intraclass correlation coefficients, see 'Details'
in the <code><a href="#topic+multilevel.icc">multilevel.icc</a></code> function. The design effect
represents the effect of cluster sampling on the variance of parameter
estimation and is defined by the equation
</p>
<p style="text-align: center;"><code class="reqn">deff = (\frac{SE_{Cluster}}{SE_{Simple}})^2 = 1 + \rho_{L2}(J - 1) + \rho_{L3}(JK - 1)</code>
</p>

<p>where <code class="reqn">\rho_{L2}</code> is the ICC(1) at Level 2, <code class="reqn">\rho_{L3}</code> is the ICC(1) at Level 3,
<code class="reqn">J</code> is the average cluster size at Level 2, and <code class="reqn">K</code> is the average
cluster size at Level 3.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>...</code> including the cluster
variable(s) specified in <code>cluster</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e.,
<code>no.obs</code> for the number of observations,
<code>no.no.miss</code> for the number of missing value,
<code>no.cluster.l2</code> and <code>no.cluster.l3</code> for the number of clusters at Level 2 and/or Level 3,
<code>m.cluster.size.l2</code> and <code>m.cluster.size.l3</code> for the average cluster size at Level 2 and/or Level 3,
<code>sd.cluster.size.l2</code> and <code>sd.cluster.size.l3</code> for the standard deviation of the cluster size at Level 2 and/or Level 3,
<code>min.cluster.size.l2</code> <code>min.cluster.size.l3</code> for the minimum cluster size at Level 2 and/or Level 3,
<code>max.cluster.size.l2</code> <code>max.cluster.size.l3</code> for the maximum cluster size at Level 2 and/or Level 3,
<code>mean.x</code> for the intercept of the multilevel model,
<code>var.r</code> for the variance within clusters,
<code>var.u</code> for the variance between Level 2 clusters,
<code>var.b</code> for the variance between Level 3 clusters,
<code>icc1.l2</code> and <code>icc1.l3</code> for ICC(1) at Level 2 and/or Level 3,
<code>icc2.l2</code> and <code>icc2.l3</code> for ICC(2) at Level 2 and/or Level 3,
<code>deff</code> for the design effect,
<code>deff.sqrt</code> for the square root of the design effect,
<code>n.effect</code> for the effective sample size</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel analysis:
Techniques and applications</em> (3rd. ed.). Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An
introduction to basic and advanced multilevel modeling</em> (2nd ed.). Sage Publishers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+multilevel.icc">multilevel.icc</a></code>, <code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Two-Level Data

#..........
# Cluster variable specification

# Example 1a: Cluster variable 'cluster'
multilevel.descript(Demo.twolevel[, c("y1", "cluster")], cluster = "cluster")

# Example 1b: Cluster variable 'cluster' not in '...'
multilevel.descript(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

# Example 1c: Alternative specification using the 'data' argument
multilevel.descript(y1, data = Demo.twolevel, cluster = "cluster")

#---------------------------

# Example 2: Multilevel descriptive statistics for 'y1'
multilevel.descript(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

# Example 3: Multilevel descriptive statistics, print variance and standard deviation
multilevel.descript(Demo.twolevel$y1, cluster = Demo.twolevel$cluster, print = "all")

# Example 4: Multilevel descriptive statistics, print ICC with 5 digits
multilevel.descript(Demo.twolevel$y1, cluster = Demo.twolevel$cluster, icc.digits = 5)

# Example 5: Multilevel descriptive statistics
# use lme() function in the nlme package to estimate ICC
multilevel.descript(Demo.twolevel$y1, cluster = Demo.twolevel$cluster, method = "nlme")

# Example 6a: Multilevel descriptive statistics for 'y1', 'y2', 'y3', 'w1', and 'w2'
multilevel.descript(Demo.twolevel[, c("y1", "y2", "y3", "w1", "w2")],
                      cluster = Demo.twolevel$cluster)

# Example 6b: Alternative specification using the 'data' argument
multilevel.descript(y1:y3, w1, w2, data = Demo.twolevel, cluster = "cluster")

#----------------------------------------------------------------------------
# Three-Level Data

# Create arbitrary three-level data
Demo.threelevel &lt;- data.frame(Demo.twolevel, cluster2 = Demo.twolevel$cluster,
                                             cluster3 = rep(1:10, each = 250))

#..........
# Cluster variable specification

# Example 7a: Cluster variables 'cluster' in '...'
multilevel.descript(Demo.threelevel[, c("y1", "cluster3", "cluster2")],
                    cluster = c("cluster3", "cluster2"))

# Example 7b: Cluster variables 'cluster' not in '...'
multilevel.descript(Demo.threelevel$y1, cluster = Demo.threelevel[, c("cluster3", "cluster2")])

# Example 7c: Alternative specification using the 'data' argument
multilevel.descript(y1, data = Demo.threelevel, cluster = c("cluster3", "cluster2"))

#----------------------------------------------------------------------------

# Example 8: Multilevel descriptive statistics for 'y1', 'y2', 'y3', 'w1', and 'w2'
multilevel.descript(y1:y3, w1, w2, data = Demo.threelevel, cluster = c("cluster3", "cluster2"))

#----------------------------------------------------------------------------
# Write Results

# Example 9a: Write results into a Excel file
multilevel.descript(Demo.twolevel[, c("y1", "y2", "y3", "w1", "w2")],
                    cluster = Demo.twolevel$cluster, write = "Multilevel_Descript.txt")

# Example 9b: Write results into a Excel file
multilevel.descript(Demo.twolevel[, c("y1", "y2", "y3", "w1", "w2")],
                    cluster = Demo.twolevel$cluster, write = "Multilevel_Descript.xlsx")

result &lt;- multilevel.descript(Demo.twolevel[, c("y1", "y2", "y3", "w1", "w2")],
                              cluster = Demo.twolevel$cluster, output = FALSE)
write.result(result, "Multilevel_Descript.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.fit'>Simultaneous and Level-Specific Multilevel Model Fit Information</h2><span id='topic+multilevel.fit'></span>

<h3>Description</h3>

<p>This function provides simultaneous and level-specific model fit information
using the partially saturated model method for multilevel models estimated
with the <span class="pkg">lavaan</span> package. Note that level-specific fit indices cannot
be computed when the fitted model contains cross-level constraints, e.g.,
equal factor loadings across levels in line with the metric cross-level
measurement invariance assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.fit(x, print = c("all", "summary", "fit"), digits = 3, p.digits = 3,
               write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.fit_+3A_x">x</code></td>
<td>
<p>a fitted model of class <code>"lavaan"</code> from the <span class="pkg">lavaan</span>
package.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which results
to show on the console, i.e. <code>"all"</code> for all results,
<code>"summary"</code> for a summary of the specification of the
estimation method and missing data handling in lavaan and
<code>"fit"</code> for model fit.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that loglikelihood,
information criteria and chi-square test statistic is
printed with <code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.fit_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>a fitted model of class <code>"lavaan"</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>specified models, i.e., <code>mod.l1</code> for the model at the
Within level, <code>mod.l1.syntax</code> for the lavaan syntax
for the model at the Between level, <code>mod.l2</code> for the
model at the Within level, <code>mod.l2.syntax</code> for the
lavaan syntax for the model at the Between level,
<code>mod.l12</code> for the model at the Within and Between
level, <code>mod.l12.syntax</code> for the lavaan syntax for
the model at the Within and Between level, <code>l1.mod.base</code>
for the baseline model at the Within level saturated at
the Between level, <code>l1.mod.hypo</code> for the hypothesized
model at the Within level saturated at the Between level,
<code>l2.mod.base</code> for the baseline model at the Between
level saturated at the Within level, <code>l2.mod.hypo</code>
for the hypothesized model at the Between level saturated
at the Within level</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary of the specification of the estimation method
and missing data handling in lavaan and <code>fit</code> for
the model fit information.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>cfa</code>, <code>fitmeasures</code>, <code>lavInspect</code>,
<code>lavTech</code>, and <code>parTable</code> provided in the R package <span class="pkg">lavaan</span> by
Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.invar">multilevel.invar</a></code>,
<code><a href="#topic+multilevel.omega">multilevel.omega</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Model specification
model &lt;- 'level: 1
              fw =~ y1 + y2 + y3
              fw ~ x1 + x2 + x3
           level: 2
              fb =~ y1 + y2 + y3
              fb ~ w1 + w2'

#-------------------------------------------------------------------------------

# Example 1: Model estimation with estimator = "ML"
fit1 &lt;- lavaan::sem(model = model, data = Demo.twolevel, cluster = "cluster",
                    estimator = "ML")

# Simultaneous and level-specific multilevel model fit information
ls.fit1 &lt;- multilevel.fit(fit1)

# Write results into a text file
multilevel.fit(fit1, write = "LS-Fit1.txt")

# Write results into an Excel file
write.result(ls.fit1, "LS-Fit1.xlsx")

# Example 2: Model estimation with estimator = "MLR"
fit2 &lt;- lavaan::sem(model = model, data = Demo.twolevel, cluster = "cluster",
                    estimator = "MLR")

# Simultaneous and level-specific multilevel model fit information
# Write results into an Excel file
multilevel.fit(fit2, write = "LS-Fit2.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.icc'>Intraclass Correlation Coefficient, ICC(1) and ICC(2)</h2><span id='topic+multilevel.icc'></span>

<h3>Description</h3>

<p>This function computes the intraclass correlation coefficient ICC(1), i.e.,
proportion of the total variance explained by the grouping structure, and ICC(2),
i.e., reliability of aggregated variables in a two-level and three-level model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.icc(..., data = NULL, cluster, type = c("1a", "1b", "2"),
               method = c("aov", "lme4", "nlme"), REML = TRUE,
               as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.icc_+3A_...">...</code></td>
<td>
<p>a numeric vector, matrix, or data frame. Alternatively, an
expression indicating the variable names in <code>data</code>. Note
that the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used to select
variables, see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector, matrix, or data frame for
the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the name of the cluster
variable in <code>...</code> or <code>data</code> for two-level data,
a character vector indicating the names of the cluster
variables in <code>...</code> for three-level data, or a vector
or data frame representing the nested grouping structure
(i.e., group or cluster variables). Alternatively, a
character string or character vector indicating the variable
name(s) of the cluster variable(s) in <code>data</code>. Note that
the cluster variable at Level 3 come first in a three-level
model, i.e., <code>cluster = c("level3", "level2")</code>.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of intraclass correlation
coefficient, i.e., <code>type = "1a"</code> (default) for ICC(1) and
<code>type = "2"</code> for ICC(2) when specifying a two-level model
(i.e., one cluster variable), and <code>type = "1a"</code> (default)
for ICC(1) representing the propotion of variance at Level 2
and Level 3, <code>type = "1b"</code> representing an estimate
of the expected correlation between two randomly chosen elements
in the same group, and <code>type = "2"</code> for ICC(2) when
specifying a three-level model (i.e., two cluster variables). See 'Details'
for the formula used in this function.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_method">method</code></td>
<td>
<p>a character string indicating the method used to estimate
intraclass correlation coefficients, i.e., <code>method = "aov"</code>
ICC estimated using the <code>aov</code> function, <code>method = "lme4"</code>
(default) ICC estimated using the <code>lmer</code> function in the
<span class="pkg">lme4</span> package, <code>method = "nlme"</code> ICC estimated using
the <code>lme</code> function in the <span class="pkg">nlme</span> package. Note that
if the lme4 or nlme package is needed when estimating ICCs in
a three-level model.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_reml">REML</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), restricted maximum likelihood
is used to estimate the null model when using the <code>lmer</code>
function in the <span class="pkg">lme4</span> package or the <code>lme</code> function
in the <span class="pkg">nlme</span> package.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied
to <code>x</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.icc_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Two-Level Model</strong></dt><dd><p>In a two-level model, the intraclass
correlation coefficients are computed in the random intercept-only model:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ij} = \gamma_{00} + u_{0j} + r_{ij}</code>
</p>

<p>where the variance in <code class="reqn">Y</code> is decomposed into two independent components:
<code class="reqn">\sigma^2_{u_{0}}</code>, which represents the variance at Level 2, and
<code class="reqn">\sigma^2_{r}</code>, which represents the variance at Level 1 (Hox et al.,
2018). These two variances sum up to the total variance and are referred to
as variance components. The intraclass correlation coefficient, ICC(1)
<code class="reqn">\rho</code> requested by <code>type = "1a"</code> represents the proportion of the
total variance explained by the grouping structure and is defined by the equation
</p>
<p style="text-align: center;"><code class="reqn">\rho = \frac{\sigma^2_{u_{0}}}{\sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>The intraclass correlation coefficient, ICC(2) <code class="reqn">\lambda_j</code> requested by
<code>type = "2"</code> represents the reliability of aggregated variables and is
defined by the equation
</p>
<p style="text-align: center;"><code class="reqn">\lambda_j = \frac{\sigma^2_{u_{0}}}{\sigma^2_{u_{0}} + \frac{\sigma^2_{r}}{n_j}} = \frac{n_j\rho}{1 + (n_j - 1)\rho}</code>
</p>

<p>where <code class="reqn">n_j</code> is the average group size (Snijders &amp; Bosker, 2012).
</p>
</dd>
<dt><strong>Three-Level Model</strong></dt><dd><p>In a three-level model, the intraclass
correlation coefficients are computed in the random intercept-only model:
</p>
<p style="text-align: center;"><code class="reqn">Y_{ijk} = \gamma_{000} + v_{0k} + u_{0jk} + r_{ijk}</code>
</p>

<p>where the variance in <code class="reqn">Y</code> is decomposed into three independent components:
<code class="reqn">\sigma^2_{v_{0}}</code>, which represents the variance at Level 3,
<code class="reqn">\sigma^2_{u_{0}}</code>, which represents the variance at Level 2, and
<code class="reqn">\sigma^2_{r}</code>, which represents the variance at Level 1 (Hox et al.,
2018). There are two ways to compute the intraclass correlation coefficient
in a three-level model. The first method requested by <code>type = "1a"</code>
represents the proportion of variance at Level 2 and Level 3 and should be
used if we are interestd in a decomposition of the variance across levels.
The intraclass correlation coefficient, ICC(1) <code class="reqn">\rho_{L2}</code> at Level 2 is
defined as:
</p>
<p style="text-align: center;"><code class="reqn">\rho_{L2} = \frac{\sigma^2_{u_{0}}}{\sigma^2_{v_{0}} + \sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>The ICC(1) <code class="reqn">\rho_{L3}</code> at Level 3 is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\rho_{L3} = \frac{\sigma^2_{v_{0}}}{\sigma^2_{v_{0}} + \sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>The second method requested by <code>type = "1b"</code> represents the expected
correlation between two randomly chosen elements in the same group. The
intraclass correlation coefficient, ICC(1) <code class="reqn">\rho_{L2}</code> at Level 2 is
defined as:
</p>
<p style="text-align: center;"><code class="reqn">\rho_{L2} = \frac{\sigma^2_{v_{0}} + \sigma^2_{u_{0}}}{\sigma^2_{v_{0}} + \sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>The ICC(1) <code class="reqn">\rho_L3</code> at Level 3 is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\rho_{L3} = \frac{\sigma^2_{v_{0}}}{\sigma^2_{v_{0}} + \sigma^2_{u_{0}} + \sigma^2_{r}}</code>
</p>

<p>Note that both formula are correct, but express different aspects of the data,
which happen to coincide when there are only two levels (Hox et al., 2018).
</p>
<p>The intraclass correlation coefficients, ICC(2) requested by <code>type = "2"</code>
represent the reliability of aggregated variables at Level 2 and Level 3.
The ICC(2) <code class="reqn">\lambda_j</code> at Level 2 is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\lambda_j = \frac{\sigma^2_{u_{0}}}{\sigma^2_{u_{0}} + \frac{\sigma^2_{r}}{n_j}}</code>
</p>

<p>The ICC(2) <code class="reqn">\lambda_k</code> at Level 3 is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\lambda_k = \frac{\sigma^2_{v_{0}}}{\frac{{\sigma^2_{v_{0}} + \sigma^2_{u_{0}}}}{n_{j}} + \frac{\sigma^2_{r}}{n_k \cdot n_j}}</code>
</p>

<p>where <code class="reqn">n_j</code> is the average group size at Level 2 and <code class="reqn">n_j</code> is the average group size at Level 3 (Hox et al., 2018).</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a numeric vector or matrix with intraclass correlation coefficient(s).
In a three level model, the label <code>L2</code> is used for ICCs at Level 2 and <code>L3</code> for ICCs at Level 3.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel analysis:
Techniques and applications</em> (3rd. ed.). Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An introduction
to basic and advanced multilevel modeling</em> (2nd ed.). Sage Publishers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Two-Level Models

#..........
# Cluster variable specification

# Example 1a: Cluster variable 'cluster' in '...'
multilevel.icc(Demo.twolevel[, c("y1", "cluster")], cluster = "cluster")

# Example 1b: Cluster variable 'cluster' not in '...'
multilevel.icc(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

# Example 1c: Alternative specification using the 'data' argument
multilevel.icc(y1, data = Demo.twolevel, cluster = "cluster")

#..........

# Example 2: ICC(1) for 'y1'
multilevel.icc(Demo.twolevel$y1, cluster = Demo.twolevel$cluster)

# Example 3: ICC(2)
multilevel.icc(Demo.twolevel$y1, cluster = Demo.twolevel$cluster, type = 2)

# Example 4: ICC(1)
# use lme() function in the lme4 package to estimate ICC
multilevel.icc(Demo.twolevel$y1, cluster = Demo.twolevel$cluster, method = "nlme")

# Example 5a: ICC(1) for 'y1', 'y2', and 'y3'
multilevel.icc(Demo.twolevel[, c("y1", "y2", "y3")], cluster = Demo.twolevel$cluster)

# Example 5b: Alternative specification using the 'data' argument
multilevel.icc(y1:y3, data = Demo.twolevel, cluster = "cluster")

#----------------------------------------------------------------------------
# Three-Level Models

# Create arbitrary three-level data
Demo.threelevel &lt;- data.frame(Demo.twolevel, cluster2 = Demo.twolevel$cluster,
                                             cluster3 = rep(1:10, each = 250))

#..........
# Cluster variable specification

# Example 6a: Cluster variables 'cluster' in '...'
multilevel.icc(Demo.threelevel[, c("y1", "cluster3", "cluster2")],
               cluster = c("cluster3", "cluster2"))

# Example 6b: Cluster variables 'cluster' not in '...'
multilevel.icc(Demo.threelevel$y1, cluster = Demo.threelevel[, c("cluster3", "cluster2")])

# Example 6c: Alternative specification using the 'data' argument
multilevel.icc(y1, data = Demo.threelevel, cluster = c("cluster3", "cluster2"))

#..........

# Example 7a: ICC(1), propotion of variance at Level 2 and Level 3
multilevel.icc(y1, data = Demo.threelevel, cluster = c("cluster3", "cluster2"))

# Example 7b: ICC(1), expected correlation between two randomly chosen elements
# in the same group
multilevel.icc(y1, data = Demo.threelevel, cluster = c("cluster3", "cluster2"),
               type = "1b")

# Example 7c: ICC(2)
multilevel.icc(y1, data = Demo.threelevel, cluster = c("cluster3", "cluster2"),
type = "2")
</code></pre>

<hr>
<h2 id='multilevel.indirect'>Confidence Interval for the Indirect Effect in a 1-1-1 Multilevel Mediation Model</h2><span id='topic+multilevel.indirect'></span>

<h3>Description</h3>

<p>This function computes the confidence interval for the indirect effect in a
1-1-1 multilevel mediation model with random slopes based on the Monte Carlo
method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.indirect(a, b, se.a, se.b, cov.ab = 0, cov.rand, se.cov.rand,
                    nrep = 100000, alternative = c("two.sided", "less", "greater"),
                    seed = NULL, conf.level = 0.95, digits = 3, write = NULL,
                    append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.indirect_+3A_a">a</code></td>
<td>
<p>a numeric value indicating the coefficient <code class="reqn">a</code>, i.e.,
average effect of <code class="reqn">X</code> on <code class="reqn">M</code> on the cluster or
between-group level.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_b">b</code></td>
<td>
<p>a numeric value indicating the coefficient <code class="reqn">b</code>, i.e.,
average effect of <code class="reqn">M</code> on <code class="reqn">Y</code> adjusted for <code class="reqn">X</code>
on the cluster or between-group level.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_se.a">se.a</code></td>
<td>
<p>a positive numeric value indicating the standard error of
<code class="reqn">a</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_se.b">se.b</code></td>
<td>
<p>a positive numeric value indicating the standard error of
<code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_cov.ab">cov.ab</code></td>
<td>
<p>a positive numeric value indicating the covariance between
<code class="reqn">a</code> and <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_cov.rand">cov.rand</code></td>
<td>
<p>a positive numeric value indicating the covariance between
the random slopes for <code class="reqn">a</code> and <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_se.cov.rand">se.cov.rand</code></td>
<td>
<p>a positive numeric value indicating the standard error of the
covariance between the random slopes for <code class="reqn">a</code> and <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_nrep">nrep</code></td>
<td>
<p>an integer value indicating the number of Monte Carlo repetitions.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be
one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the seed of the random number generator
when using the Monte Carlo method.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence level
of the interval.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.indirect_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In statistical mediation analysis (MacKinnon &amp; Tofighi, 2013), the indirect effect
refers to the effect of the independent variable <code class="reqn">X</code> on the outcome variable
<code class="reqn">Y</code> transmitted by the mediator variable <code class="reqn">M</code>. The magnitude of the indirect
effect <code class="reqn">ab</code> is quantified by the product of the the coefficient <code class="reqn">a</code>
(i.e., effect of <code class="reqn">X</code> on <code class="reqn">M</code>) and the coefficient <code class="reqn">b</code> (i.e., effect of
<code class="reqn">M</code> on <code class="reqn">Y</code> adjusted for <code class="reqn">X</code>). However, mediation in the context of a
1-1-1 multilevel mediation model where variables <code class="reqn">X</code>, <code class="reqn">M</code>, and <code class="reqn">Y</code>
are measured at level 1, the coefficients <code class="reqn">a</code> and <code class="reqn">b</code> can vary across
level-2 units (i.e., random slope). As a result, <code class="reqn">a</code> and <code class="reqn">b</code> may covary
so that the estimate of the indirect effect is no longer simply the product of
the coefficients <code class="reqn">\hat{a}\hat{b}</code>, but <code class="reqn">\hat{a}\hat{b} + \tau_{a,b}</code>,
where <code class="reqn">\tau_{a,b}</code> (i.e., <code>cov.rand</code>) is the level-2 covariance between
the random slopes <code class="reqn">a</code> and <code class="reqn">b</code>. The covariance term needs to be added to
<code class="reqn">\hat{a}\hat{b}</code> only when random slopes are estimated for both <code class="reqn">a</code> and
<code class="reqn">b</code>. Otherwise, the simple product is sufficient to quantify the indirect
effect, and the <code><a href="#topic+indirect">indirect</a></code> function can be used instead.
</p>
<p>In practice, researchers are often interested in confidence limit estimation
for the indirect effect. There are several methods for computing a confidence
interval for the indirect effect in a single-level mediation models (see
<code><a href="#topic+indirect">indirect</a></code> function). The Monte Carlo (MC) method (MacKinnon et al.,
2004) is a promising method in single-level mediation model which was also adapted
to the multilevel mediation model (Bauer, Preacher &amp; Gil, 2006). This method
requires seven pieces of information available from the results of a multilevel
mediation model:
</p>

<dl>
<dt>a</dt><dd><p>Coefficient <code class="reqn">a</code>, i.e., average effect of <code class="reqn">X</code> on <code class="reqn">M</code>
on the cluster or between-group level. In Mplus, <code>Estimate</code>
of the random slope <code class="reqn">a</code> under <code>Means</code> at the
<code>Between Level</code>.</p>
</dd>
<dt>b</dt><dd><p>Coefficient <code class="reqn">a</code>, i.e., average effect of <code class="reqn">M</code> on <code class="reqn">Y</code>
on the cluster or between-group level. In Mplus, <code>Estimate</code>
of the random slope <code class="reqn">b</code> under <code>Means</code> at the
<code>Between Level</code>.</p>
</dd>
<dt>se.a</dt><dd><p>Standard error of <code>a</code>. In Mplus, <code>S.E.</code>
of the random slope <code class="reqn">a</code> under <code>Means</code> at the
<code>Between Level</code>.</p>
</dd>
<dt>se.a</dt><dd><p>Standard error of <code>a</code>. In Mplus, <code>S.E.</code>
of the random slope <code class="reqn">a</code> under <code>Means</code> at the
<code>Between Level</code>.</p>
</dd>
<dt>cov.ab</dt><dd><p>Covariance between <code class="reqn">a</code> and <code class="reqn">b</code>. In Mplus, the
estimated covariance matrix for the parameter estimates
(i.e., asymptotic covariance matrix) need to be requested
by specifying <code>TECH3</code> along with <code>TECH1</code> in the
<code>OUTPUT</code> section. In the <code>TECHNICAL 1 OUTPUT</code>
under <code>PARAMETER SPECIFICATION FOR BETWEEN</code>, the
numbers of the parameter for the coefficients <code class="reqn">a</code> and
<code class="reqn">b</code> need to be identified under <code>ALPHA</code> to look
up <code>cov.av</code> in the corresponding row and column in
the <code>TECHNICAL 3 OUTPUT</code> under <code>ESTIMATED COVARIANCE
                MATRIX FOR PARAMETER ESTIMATES</code>.</p>
</dd>
<dt>cov.rand</dt><dd><p>Covariance between the random slopes for <code class="reqn">a</code> and
<code class="reqn">b</code>. In Mplus, <code>Estimate</code> of the covariance
<code class="reqn">a</code> <code>WITH</code> <code class="reqn">b</code> at the <code>Between Level</code></p>
</dd></dl>
<p>.
</p>
<dl>
<dt>se.cov.rand</dt><dd><p>Standard error of the covariance between the random
slopes for <code class="reqn">a</code> and <code class="reqn">b</code>. In Mplus, <code>S.E.</code>
of the covariance <code class="reqn">a</code> <code>WITH</code> <code class="reqn">b</code> at the
<code>Between Level</code></p>
</dd></dl>
<p>.

</p>
<p>Note that all pieces of information except <code>cov.ab</code> can be looked up in
the standard output of the multilevel mediation model. In order to specify
<code>cov.ab</code>, the covariance matrix for the parameter estimates (i.e.,
asymptotic covariance matrix) is required. In practice, <code>cov.ab</code> will
oftentimes be very small so that <code>cov.ab</code> may be set to 0 (i.e., default
value) with negligible impact on the results.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>list with the input specified in <code>a</code>, <code>b</code>,
<code>se.a</code>, <code>se.b</code>, <code>cov.ab</code>, <code>cov.rand</code>,
and <code>se.cov.rand</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>ab</code> for the simulated
<code>ab</code> values and <code>mc</code> for the estimate of the
indirect effect and the confidence interval</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function was adapted from the interactive web tool by Preacher and
Selig (2010).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Bauer, D. J., Preacher, K. J., &amp; Gil, K. M. (2006). Conceptualizing and testing
random indirect effects and moderated Mediation in multilevel models: New procedures
and recommendations. <em>Psychological Methods, 11</em>, 142-163.
https://doi.org/10.1037/1082-989X.11.2.142
</p>
<p>Kenny, D. A., Korchmaros, J. D., &amp; Bolger, N. (2003). Lower level Mediation in
multilevel models. <em>Psychological Methods, 8</em>, 115-128.
https://doi.org/10.1037/1082-989x.8.2.115
</p>
<p>MacKinnon, D. P., Lockwood, C. M., &amp; Williams, J. (2004). Confidence limits for the indirect effect:
Distribution of the product and resampling methods. <em>Multivariate Behavioral Research, 39</em>, 99-128.
https://doi.org/10.1207/s15327906mbr3901_4
</p>
<p>MacKinnon, D. P., &amp; Tofighi, D. (2013). Statistical mediation analysis. In J. A. Schinka, W. F. Velicer,
&amp; I. B. Weiner (Eds.), <em>Handbook of psychology: Research methods in psychology</em> (pp. 717-735).
John Wiley &amp; Sons, Inc..
</p>
<p>Preacher, K. J., &amp; Selig, J. P. (2010). <em>Monte Carlo method for assessing
multilevel Mediation: An interactive tool for creating confidence intervals for
indirect effects in 1-1-1 multilevel models</em> [Computer software]. Available from
http://quantpsy.org/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+indirect">indirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Confidence Interval for the Indirect Effect
multilevel.indirect(a = 0.25, b = 0.20, se.a = 0.11, se.b = 0.13,
                    cov.ab = 0.01, cov.rand = 0.40, se.cov.rand = 0.02)

# Example 2: Save results of the Monte Carlo method
ab &lt;- multilevel.indirect(a = 0.25, b = 0.20, se.a = 0.11, se.b = 0.13,
                          cov.ab = 0.01, cov.rand = 0.40, se.cov.rand = 0.02,
                          output = FALSE)$result$ab

# Histogram of the distribution of the indirect effect
hist(ab)

# Example 3: Write results into a text file
multilevel.indirect(a = 0.25, b = 0.20, se.a = 0.11, se.b = 0.13,
                    cov.ab = 0.01, cov.rand = 0.40, se.cov.rand = 0.02,
                    write = "ML-Indirect.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.invar'>Cross-Level Measurement Invariance Evaluation</h2><span id='topic+multilevel.invar'></span>

<h3>Description</h3>

<p>This function is a wrapper function for evaluating configural, metric, and
scalar cross-level measurement invariance using multilevel confirmatory factor
analysis with continuous indicators by calling the <code>cfa</code> function in the
R package <span class="pkg">lavaan</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.invar(..., data = NULL, cluster, model = NULL, rescov = NULL,
                 invar = c("config", "metric", "scalar"), fix.resid = NULL,
                 ident = c("marker", "var", "effect"),
                 estimator = c("ML", "MLR"), optim.method = c("nlminb", "em"),
                 missing = c("listwise", "fiml"),
                 print = c("all", "summary", "coverage", "descript", "fit",
                           "est", "modind", "resid"),
                 print.fit = c("all", "standard", "scaled", "robust"),
                 mod.minval = 6.63, resid.minval = 0.1, digits = 3, p.digits = 3,
                 as.na = NULL, write = NULL, append = TRUE, check = TRUE,
                 output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.invar_+3A_...">...</code></td>
<td>
<p>a matrix or data frame. If <code>model</code> is <code>NULL</code>,
multilevel confirmatory factor analysis based on a
measurement model with one factor at the Within and Between
level comprising all variables in the matrix or data frame
is conducted to evaluate cross-level measurement invariance.
Note that the cluster variable specified in <code>cluster</code>
is excluded from <code>x</code> when specifying the argument
<code>cluster</code> using the variable name of the cluster
variable. If <code>model</code> is specified, the matrix or data
frame needs to contain all variables used in the <code>model</code>
argument. Alternatively, an expression indicating the
variable names in <code>data</code> e.g.,
<code>multilevel.invar(x1, x2, x3, data = dat)</code>. Note that
the operators <code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>,
<code>:</code>, <code>::</code>, and <code>!</code> can also be used to
select variables, see 'Details' in the <code><a href="#topic+df.subset">df.subset</a></code>
function.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>...</code> or <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_model">model</code></td>
<td>
<p>a character vector specifying the same factor structure
with one factor at the Within and Between Level, or a list
of character vectors for specifying the same measurement
model with more than one factor at the Within and Between
Level, e.g.,<code>model = c("x1", "x2", "x3", "x4")</code> for
specifying a measurement model with one factor labeled
<code>wf</code> at the Within level and a measurement model with
one factor labeled <code>bf</code> at the Between level each
comprising four indicators, or <code>model = list(factor1 = c("x1", "x2", "x3", "x4"),
factor2 = c("x5", "x6", "x7", "x8"))</code> for specifying a
measurement model with two latent factors labeled <code>wfactor1</code>
and <code>wfactor2</code> at the Within level and a measurement
model with two latent factors labeled <code>bfactor1</code> and
<code>bfactor2</code> at the Between level each comprising four
indicators. Note that the name of each list element is used
to label factors, where prefixes <code>w</code> and <code>b</code> are
added the labels to distinguish factor labels at the Within
and Between level, i.e., all list elements need to be named,
otherwise factors are labeled with <code>"wf1", "wf2", "wf3"</code>
for labels at the Within level and <code>"bf1", "bf2", "bf3"</code>
for labels at the Between level and so on.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances at the Within level, e.g. <code>rescov = c("x1", "x2")</code>
for specifying a residual covariance between indicators <code>x1</code>
and <code>x2</code> at the Within level or <code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code>
for specifying residual covariances between indicators <code>x1</code>
and <code>x2</code>, and indicators <code>x3</code> and <code>x4</code> at
the Within level. Note that residual covariances at the
Between level can only be specified by using the arguments
<code>model.w</code>, <code>model.b</code>, and <code>model.b</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_invar">invar</code></td>
<td>
<p>a character string indicating the level of measurement invariance
to be evaluated, i.e., <code>config</code> to evaluate configural
measurement invariance (i.e., same factor structure across
levels), <code>metric</code> (default) to evaluate configural and
metric measurement invariance (i.e., equal factor loadings
across level), and <code>scalar</code> to evaluate configural,
metric and scalar measurement invariance (i.e., all residual
variances at the Between level equal zero).</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_fix.resid">fix.resid</code></td>
<td>
<p>a character vector for specifying residual variances to be
fixed at 0 at the Between level for the configural and metric
invariance model, e.g., <code>fix.resid = c("x1", "x3")</code>
to fix residual variances of indicators <code>x1</code> and <code>x2</code>
at the Between level at 0. Note that it is also possible
to specify <code>fix.resid = "all"</code> which fixes all residual
variances at the Between level at 0 in line with the strong
factorial measurement invariance assumption across cluster.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_ident">ident</code></td>
<td>
<p>a character string indicating the method used for identifying
and scaling latent variables, i.e., <code>"marker"</code> for the
marker variable method fixing the first factor loading of
each latent variable to 1, <code>"var"</code> for the fixed variance
method fixing the variance of each latent variable to 1,
or <code>"effect"</code> for the effects-coding method using equality
constraints so that the average of the factor loading for
each latent variable equals 1.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_estimator">estimator</code></td>
<td>
<p>a character string indicating the estimator to be used:
<code>"ML"</code> for maximum likelihood with conventional standard
errors and <code>"MLR"</code> (default) for maximum likelihood
with Huber-White robust standard errors and a scaled test
statistic that is asymptotically equal to the Yuan-Bentler
test statistic. Note that by default, full information maximum
likelihood (FIML) method is used to deal with missing data
when using <code>"ML"</code> (<code>missing = "fiml"</code>), whereas
incomplete cases are removed listwise (i.e., <code>missing = "listwise"</code>)
when using <code>"MLR"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_optim.method">optim.method</code></td>
<td>
<p>a character string indicating the optimizer, i.e., <code>"nlminb"</code>
(default) for the unconstrained and bounds-constrained
quasi-Newton method optimizer and <code>"em"</code> for the
Expectation Maximization (EM) algorithm.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data,
i.e., <code>"listwise"</code> (default) for listwise deletion or
<code>"fiml"</code> for full information maximum likelihood (FIML)
method. Note that FIML method is only available when
<code>estimator = "ML"</code>, that it takes longer to estimate
the model  using FIML, and that FIML is prone to convergence
issues which might be resolved by switching to listwise deletion.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to show on the console, i.e. <code>"all"</code> for all
results, <code>"summary"</code> for a summary of the specification
of the estimation method and missing data handling in lavaan,
<code>"coverage"</code> for the variance-covariance coverage of
the data, <code>"descript"</code> for descriptive statistics,
<code>"fit"</code> for model fit and  model comparison, <code>"est"</code>
for parameter estimates, and <code>"modind"</code> for modification
indices. By default, a summary of the specification and model fit
and model comparison are printed.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_print.fit">print.fit</code></td>
<td>
<p>a character string or character vector indicating which
version of the CFI, TLI, and RMSEA to show on the console,
i.e., <code>"all"</code> for all versions of the CFI, TLI, and
RMSEA, <code>"standard"</code> (default when <code>estimator = "ML"</code>)
for fit indices without any non-normality correction,
<code>"scaled"</code> for population-corrected robust fit indices
with ad hoc non-normality correction, and <code>robust</code>
(default when <code>estimator = "MLR"</code>) for sample-corrected
robust fit indices based on formula provided by Li and Bentler
(2006) and Brosseau-Liard and Savalei (2014).</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_mod.minval">mod.minval</code></td>
<td>
<p>numeric value to filter modification indices and only
show modifications with a modification index value equal
or higher than this minimum value. By default, modification
indices equal or higher 6.63 are printed. Note that a
modification index value of 6.63 is equivalent to a
significance level of <code class="reqn">\alpha = .01</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_resid.minval">resid.minval</code></td>
<td>
<p>numeric value indicating the minimum absolute residual
correlation coefficients and standardized means to
highlight in boldface. By default, absolute residual
correlation coefficients and standardized means equal
or higher 0.1 are highlighted. Note that highlighting
can be disabled by setting the minimum value to 1.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that information
criteria and chi-square test statistic is printed with
<code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only
applied to <code>x</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification, convergence
and model identification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.invar_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>list with specified model for the configural, metric, and
scalar invariance model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>list with fitted lavaan object of the configural, metric,
and scalar invariance model</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>list with the results of the convergence and model identification
check for the configural, metric, and scalar invariance model</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary of the specification of the estimation method and
missing data handling in lavaan, <code>coverage</code> for the
variance-covariance coverage of the data, <code>descript</code>
for descriptive statistics, <code>fit</code> for a list with
model fit based on standard, scaled, and robust fit indices,
<code>est</code> for a list with parameter estimates for the
configural, metric, and scalar invariance model, and
<code>modind</code> for the list with modification indices for
the configural, metric, and scalar invariance model</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>lavTestLRT</code> provided in the R package
<span class="pkg">lavaan</span> by Yves Rosseel (2012).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.fit">multilevel.fit</a></code>, <code><a href="#topic+multilevel.omega">multilevel.omega</a></code>,
<code><a href="#topic+multilevel.cor">multilevel.cor</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
# Cluster variable specification

# Example 1a: Cluster variable 'cluster' in 'x'
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4", "cluster")], cluster = "cluster")

# Example 1b: Cluster variable 'cluster' not in 'x'
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster)

# Example 1c: Alternative specification using the 'data' argument
multilevel.invar(y1:y4, data = Demo.twolevel, cluster = "cluster")

#----------------------------------------------------------------------------
# Model specification using 'x' for a one-factor model

#..........
# Level of measurement invariance

# Example 2a: Configural invariance
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, invar = "config")

# Example 2b: Metric invariance
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, invar = "metric")

# Example 2c: Scalar invariance
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, invar = "scalar")

#..........
# Residual covariance at the Within level and residual variance at the Between level

# Example 3a: Residual covariance between "y3" and "y4" at the Within level
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, rescov = c("y3", "y4"))

# Example 3b: Residual variances of 'y1' at the Between level fixed at 0
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, fix.resid = "y1")

#..........
# Example 4: Print all results
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, print = "all")

#..........
# Example 5: lavaan model and summary of the estimated model
mod &lt;- multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                        cluster = Demo.twolevel$cluster, output = FALSE)

# lavaan syntax of the metric invariance model
mod$model$metric

# Fitted lavaan object of the metric invariance model
lavaan::summary(mod$model.fit$metric, standardized = TRUE, fit.measures = TRUE)

#----------------------------------------------------------------------------
# Model specification using 'model' for one or multiple factor model

# Example 6a: One-factor model
multilevel.invar(Demo.twolevel, cluster = "cluster", model = c("y1", "y2", "y3", "y4"))

# Example 6b:  Two-factor model
multilevel.invar(Demo.twolevel, cluster = "cluster",
                 model = list(c("y1", "y2", "y3"), c("y4", "y5", "y6")))

#----------------------------------------------------------------------------
# Write results

# Example 7a: Write results into an Excel file
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, print = "all",
                 write = "Multilevel_Invariance.txt")

# Example 7b:  Write results into an Excel file
multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, print = "all",
                 write = "Multilevel_Invariance.xlsx")

# Assign results into an object and write results into an Excel file
mod &lt;- multilevel.invar(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                        cluster = Demo.twolevel$cluster, print = "all",
                        output = FALSE)

# Write results into an Excel file
write.result(mod, "Multilevel_Invariance.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.omega'>Multilevel Composite Reliability</h2><span id='topic+multilevel.omega'></span>

<h3>Description</h3>

<p>This function computes point estimate and Monte Carlo confidence interval for
the multilevel composite reliability defined by Lai (2021) for a within-cluster
construct, shared cluster-level construct, and configural cluster construct by
calling the <code>cfa</code> function in the R package <span class="pkg">lavaan</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.omega(..., data = NULL, cluster, rescov = NULL,
                 const = c("within", "shared", "config"),
                 fix.resid = NULL, optim.method = c("nlminb", "em"),
                 missing = c("listwise", "fiml"), nrep = 100000, seed = NULL,
                 conf.level = 0.95, print = c("all", "omega", "item"),
                 digits = 2, as.na = NULL, write = NULL, append = TRUE,
                 check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.omega_+3A_...">...</code></td>
<td>
<p>a matrix or data frame. Multilevel confirmatory factor
analysis based on a measurement model with one factor
at the Within level and one factor at the Between level
comprising all variables in the matrix or data frame is
conducted. Note that the cluster variable specified in
<code>cluster</code> is excluded from <code>x</code> when specifying
the argument <code>cluster</code> using the variable name of the
cluster variable. Alternatively, an expression indicating
the variable names in <code>data</code> e.g.,
<code>multilevel.omega(x1, x2, x3, data = dat, cluster = "cluster")</code>.
Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument
<code>...</code>.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>...</code> or <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_rescov">rescov</code></td>
<td>
<p>a character vector or a list of character vectors for specifying
residual covariances at the Within level, e.g. <code>rescov = c("x1", "x2")</code>
for specifying a residual covariance between indicators <code>x1</code>
and <code>x2</code> at the Within level or <code>rescov = list(c("x1", "x2"), c("x3", "x4"))</code>
for specifying residual covariances between indicators <code>x1</code>
and <code>x2</code>, and indicators <code>x3</code> and <code>x4</code> at
the Within level. Note that residual covariances at the
Between level cannot be  specified using this function.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_const">const</code></td>
<td>
<p>a character string indicating the type of construct(s), i.e.,
<code>"within"</code> for within-cluster constructs, <code>"shared"</code>
for shared cluster-level constructs, and <code>"config"</code>
(default) for configural cluster constructs.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_fix.resid">fix.resid</code></td>
<td>
<p>a character vector for specifying residual variances to be
fixed at 0 at the Between level, e.g., <code>fix.resid = c("x1", "x3")</code>
to fix residual variances of indicators <code>x1</code> and <code>x2</code>
at the Between level at 0. Note that it is also possible
to specify <code>fix.resid = "all"</code> which fixes all residual
variances at the Between level at 0 in line with the strong
factorial measurement invariance assumption across cluster.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_optim.method">optim.method</code></td>
<td>
<p>a character string indicating the optimizer, i.e., <code>"nlminb"</code>
(default) for the unconstrained and bounds-constrained
quasi-Newton method optimizer and <code>"em"</code> for the
Expectation Maximization (EM) algorithm.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_missing">missing</code></td>
<td>
<p>a character string indicating how to deal with missing data,
i.e., <code>"listwise"</code> for listwise deletion or <code>"fiml"</code>
(default) for full information maximum likelihood (FIML)
method.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_nrep">nrep</code></td>
<td>
<p>an integer value indicating the number of Monte Carlo
repetitions for computing confidence intervals.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the seed of the random number
generator for computing the Monte Carlo confidence interval.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e.
<code>"all"</code> (default), for all results <code>"omega"</code> for
omega, and <code>"item"</code> for item statistics.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that loglikelihood,
information criteria and chi-square test statistic is
printed with <code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only
applied to <code>x</code> but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification, convergence
and model identification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.omega_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>x</code> including the group variable
specified in <code>cluster</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>specified model</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>fitted lavaan object (<code>mod.fit</code>)</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>results of the convergence and model identification check</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>omega</code> for the coefficient
omega including Monte Carlo confidence interval and
<code>itemstat</code> for descriptive statistics</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses the functions <code>lavInspect</code>, <code>lavTech</code>, and <code>lavNames</code>,
provided in the R package <span class="pkg">lavaan</span> by Yves Rosseel (2012). The internal function
<code>.internal.mvrnorm</code> is a copy of the <code>mvrnorm</code> function in the package
<span class="pkg">MASS</span> by Venables and Ripley (2002).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Lai, M. H. C. (2021). Composite reliability of multilevel data: It’s about
observed scores and construct meanings. <em>Psychological Methods, 26</em>(1),
90–102. https://doi.org/10.1037/met0000287
</p>
<p>Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling.
<em>Journal of Statistical Software, 48</em>, 1-36. https://doi.org/10.18637/jss.v048.i02
</p>
<p>Venables, W. N., Ripley, B. D. (2002).<em>Modern Applied Statistics with S</em> (4th ed.).
Springer. https://www.stats.ox.ac.uk/pub/MASS4/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+item.omega">item.omega</a></code>, <code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>, <code><a href="#topic+multilevel.fit">multilevel.fit</a></code>,
<code><a href="#topic+multilevel.invar">multilevel.invar</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#-------------------------------------------------------------------------------
# Cluster variable specification

# Example 1a: Cluster variable 'cluster' in 'x'
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4", "cluster")], cluster = "cluster")

# Example 1b: Cluster variable 'cluster' not in 'x'
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")], cluster = Demo.twolevel$cluster)

# Example 1c: Alternative specification using the 'data' argument
multilevel.omega(y1:y4, data = Demo.twolevel, cluster = "cluster")

#-------------------------------------------------------------------------------
# Type of construct

# Example 2a: Within-Cluster Construct
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, const = "within")

# Example 2b: Shared Cluster-Level Construct
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, const = "shared")

# Example 2c: Configural Construct
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, const = "config")

#-------------------------------------------------------------------------------
# Residual covariance at the Within level and residual variance at the Between level

# Example 3a: Residual covariance between "y4" and "y5" at the Within level
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, const = "config",
                 rescov = c("y3", "y4"))

# Example 3b: Residual variances of 'y1' at the Between level fixed at 0
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, const = "config",
                 fix.resid = c("y1", "y2"), digits = 3)

#----------------------------------------------------------------------------
# Write results

# Example 4a: Write results into a text file
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, write = "Multilevel_Omega.txt")

# Example 4b: Write results into an Excel file
multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                 cluster = Demo.twolevel$cluster, write = "Multilevel_Omega.xlsx")

# Example 4b: Assign results into an object and write results into an Excel file
mod &lt;- multilevel.omega(Demo.twolevel[,c("y1", "y2", "y3", "y4")],
                        cluster = Demo.twolevel$cluster, output = FALSE)

# Write results into an Excel file
write.result(mod, "Multilevel_Omega.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.r2'>R-Squared Measures for Multilevel and Linear Mixed Effects Models</h2><span id='topic+multilevel.r2'></span>

<h3>Description</h3>

<p>This function computes R-squared measures by Raudenbush and Bryk (2002),
Snijders and Bosker (1994), Nakagawa and Schielzeth (2013) as extended by
Johnson (2014), and Rights and Sterba (2019) for multilevel and linear mixed
effects models estimated by using the <code>lmer()</code> function in the package
<span class="pkg">lme4</span> or <code>lme()</code> function in the package <span class="pkg">nlme</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.r2(model, print = c("all", "RB", "SB", "NS", "RS"), digits = 3,
              plot = FALSE, gray = FALSE, start = 0.15, end = 0.85,
              color = c("#D55E00", "#0072B2", "#CC79A7", "#009E73", "#E69F00"),
              write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.r2_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lmerMod"</code> from the <span class="pkg">lme4</span>
package or <code>"lme"</code> from the <span class="pkg">nlme</span> package.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_print">print</code></td>
<td>
<p>a character vector indicating which R-squared measures to be
printed on the console, i.e., <code>RB</code> for measures from
Raudenbush and Bryk (2002), <code>SB</code> for measures from Snijders
and Bosker (1994), <code>NS</code> for measures from Nakagawa and
Schielzeth (2013) as extended by Johnson (2014), and <code>RS</code>
for measures from Rights and Sterba (2019). The default setting
is <code>print = "RS"</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar chart showing the decomposition of
scaled total, within-cluster, and between-cluster outcome variance
into five (total), three (within-cluster), and two (between-cluster)
proportions is drawn. Note that the <span class="pkg">ggplot2</span> package is required
to draw the bar chart.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_gray">gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, graphical parameter to draw the bar chart
in gray scale.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_start">start</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the low end of the palette.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_end">end</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the high end of the palette.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_color">color</code></td>
<td>
<p>a character vector, graphical parameter indicating the color of
bars in the bar chart in the following order: Fixed slopes (Within),
Fixed slopes (Between), Slope variation (Within), Intercept variation
(Between), and Residual (Within). By default, colors from the
colorblind-friendly palettes are used</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.r2_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of R-squared measures for multilevel and linear mixed effects models have
been developed in the methodological literature (see Rights &amp; Sterba, 2018).
Based on these measures, following measures were implemented in the current function:
</p>

<dl>
<dt><strong>Raudenbush and Bryk (2002)</strong></dt><dd><p>R-squared measures by Raudenbush
and Bryk (2002) are based on the proportional reduction of unexplained variance
when predictors are added. More specifically, variance estimates from the
baseline/null model (i.e., <code class="reqn">\sigma^2_{e|b}</code> and <code class="reqn">\sigma^2_{u0|b}</code>)
and variance estimates from the model including predictors (i.e., <code class="reqn">\sigma^2_{e|m}</code>
and <code class="reqn">\sigma^2_{u0|m}</code>) are used to compute the proportional reduction in
variance between baseline/null model and the complete model by:
</p>
<p style="text-align: center;"><code class="reqn">R^2_1(RB) = \frac{\sigma^2_{e|b} - \sigma^2_{e|m}}{\sigma^2_{e|b}}</code>
</p>

<p>for the proportional reduction at level-1 (within-cluster) and by:
</p>
<p style="text-align: center;"><code class="reqn">R^2_2(RB) = \frac{\sigma^2_{u0|b} - \sigma^2_{u0|m}}{\sigma^2_{u0|b}}</code>
</p>

<p>for the proportional reduction at level-2 (between-cluster), where <code class="reqn">|b</code>
and <code class="reqn">|m</code> represent the baseline and full models, respectively (Hox et al.,
2018; Roberts et al., 2010).
</p>
<p>A major disadvantage of these measures is that adding predictors can increases
rather than decreases some of the variance components and it is even possible
to obtain negative values for <code class="reqn">R^2</code> with these formulas (Snijders &amp; Bosker,
2012). According to Snijders and Bosker (1994) this can occur because the
between-group variance is a function of both level-1 and level-2 variance:
</p>
<p style="text-align: center;"><code class="reqn">var(\bar{Y}_j) = \sigma^2_{u0} + \frac{\sigma^2_e}{n_j}</code>
</p>

<p>Hence, adding a predictor (e.g., cluster-mean centered predictor) that explains
proportion of the within-group variance will decrease the estimate of <code class="reqn">\sigma^2_e</code>
and increase the estimate <code class="reqn">\sigma^2_{u0}</code> if this predictor does not explain
a proportion of the between-group variance to balance out the decrease in
<code class="reqn">\sigma^2_e</code> (LaHuis et al., 2014). Negative estimates for <code class="reqn">R^2</code> can
also simply occur due to chance fluctuation in sample estimates from the two
models.
</p>
<p>Another disadvantage of these measures is that <code class="reqn">R^2_2(RB)</code> for the explained
variance at level-2 has been shown to perform poorly in simulation studies even
with <code class="reqn">j = 200</code> clusters with group cluster size of <code class="reqn">n_j = 50</code> (LaHuis
et al., 2014; Rights &amp; Sterba, 2019).
</p>
<p>Moreover, when there is missing data in the level-1 predictors, it is possible
that sample sizes for the baseline and complete models differ.
</p>
<p>Finally, it should be noted that R-squared measures by Raudenbush and Bryk (2002)
are appropriate for random intercept models, but not for random intercept and
slope models. For random slope models, Snijders and Bosker (2012) suggested to
re-estimate the model as random intercept models with the same predictors while
omitting the random slopes to compute the R-squared measures. However, the
simulation study by LaHuis (2014) suggested that the R-squared measures showed
an acceptable performance when there was little slope variance, but did not
perform well in the presence of higher levels of slope variance.</p>
</dd>
<dt><strong>Snijders and Bosker (1994)</strong></dt><dd><p>R-squared measures by Snijders and
Bosker (1994) are based on the proportional reduction of mean squared prediction
error and is computed using the formula:
</p>
<p style="text-align: center;"><code class="reqn">R^2_1(SB) = \frac{\hat{\sigma}^2_{e|m} + \hat{\sigma}^2_{u0|m}}{\hat{\sigma}^2_{e|b} + \hat{\sigma}^2_{u0|b}}</code>
</p>

<p>for computing the proportional reduction of error at level-1 representing
the total amount of explained variance and using the formula:
</p>
<p style="text-align: center;"><code class="reqn">R^2_2(SB) = \frac{\hat{\sigma}^2_{e|m} / n_j + \hat{\sigma}^2_{u0|m}}{\hat{\sigma}^2_{e|b} / n_j + \hat{\sigma}^2_{u0|b}}</code>
</p>

<p>for computing the proportional reduction of error at level-2 by dividing the
<code class="reqn">\hat{\sigma}^2_e</code> by the group cluster size <code class="reqn">n_j</code> or by the average
cluster size for unbalanced data (Roberts et al., 2010). Note that the function
uses the harmonic mean of the group sizes as recommended by Snijders and Bosker
(1994). The population values of <code class="reqn">R^2</code> based on these measures cannot be
negative because the interplay of level-1 and level-2 variance components is
considered. However, sample estimates of <code class="reqn">R^2</code> can be negative either due
to chance fluctuation when sample sizes are small or due to model misspecification
(Snijders and Bosker, 2012).
</p>
<p>When there is missing data in the level-1 predictors, it is possible that sample
sizes for the baseline and complete models differ.
</p>
<p>Similar to the R-squared measures by Raudenbush and Bryk (2002), the measures
by Snijders and Bosker (1994) are appropriate for random intercept models, but
not for random intercept and slope models. Accordingly, for random slope models,
Snijders and Bosker (2012) suggested to re-estimate the model as random intercept
models with the same predictors while omitting the random slopes to compute the
R-squared measures. The simulation study by LaHuis et al. (2014) revealed that
the R-squared measures showed an acceptable performance, but it should be noted
that <code class="reqn">R^2_2(SB)</code> the explained variance at level-2 was not investigated in
their study.</p>
</dd>
<dt><strong>Nakagawa and Schielzeth (2013)</strong></dt><dd><p>R-squared measures by Nakagawa
and Schielzeth (2013) are based on partitioning model-implied variance from a
single fitted model and uses the variance of predicted values of <code class="reqn">var(\hat{Y}_{ij})</code>
to form both the outcome variance in the denominator and the explained variance
in the numerator of the formulas:
</p>
<p style="text-align: center;"><code class="reqn">R^2_m(NS) = \frac{var(\hat{Y}_{ij})}{var(\hat{Y}_{ij}) + \sigma^2_{u0} + \sigma^2_{e}}</code>
</p>

<p>for marginal total <code class="reqn">R^2_m(NS)</code> and:
</p>
<p style="text-align: center;"><code class="reqn">R^2_c(NS) = \frac{var(\hat{Y}_{ij}) + \sigma^2_{u0}}{var(\hat{Y}_{ij}) + \sigma^2_{u0} + \sigma^2_{e}}</code>
</p>

<p>for conditional total <code class="reqn">R^2_c(NS)</code>. In the former formula <code class="reqn">R^2</code> predicted
scores are marginalized across random effects to indicate the variance explained
by fixed effects and in the latter formula <code class="reqn">R^2</code> predicted scores are conditioned
on random effects to indicate the variance explained by fixed and random effects
(Rights and Sterba, 2019).
</p>
<p>The advantage of these measures is that they can never become negative and
that they can also be extended to generalized linear mixed effects models (GLMM)
when outcome variables are not continuous (e.g., binary outcome variables).
Note that currently the function does not provide <code class="reqn">R^2</code> measures for GLMMs,
but these measures can be obtained using the <code>r.squaredGLMM()</code> function in
the <span class="pkg">MuMIn</span> package.
</p>
<p>A disadvantage is that these measures do not allow random slopes and are restricted
to the simplest random effect structure (i.e., random intercept model). In other
words, these measures do not fully reflect the structure of the fitted model when
using random intercept and slope models. However, Johnson (2014) extended these
measures to allow random slope by taking into account the contribution of random
slopes, intercept-slope covariances, and the covariance matrix of random slope
to the variance in <code class="reqn">Y_{ij}</code>. As a result, R-squared measures by Nakagawa
and Schielzeth (2013) as extended by Johnson (2014) can be used for both random
intercept, and random intercept and slope models.
</p>
<p>The major criticism of the R-squared measures by Nakagawa and Schielzeth (2013)
as extended by Johnson (2014) is that these measures do not decompose outcome
variance into each of total, within-cluster, and between-cluster variance which
precludes from computing level-specific <code class="reqn">R^2</code> measures. In addition, these
measures do not distinguish variance attributable to level-1 versus level-2
predictors via fixed effects, and they also do not distinguish between random
intercept and random slope variation (Rights and Sterba, 2019).</p>
</dd>
<dt><strong>Rights and Sterba (2019)</strong></dt><dd><p>R-squared measures by Rights and Sterba
(2019) provide an integrative framework of R-squared measures for multilevel
and linear mixed effects models with random intercepts and/or slopes. Their
measures are also based on partitioning model implied variance from a single
fitted model, but they provide a full partitioning of the total outcome variance
to one of five specific sources:
</p>

<ul>
<li><p> variance attributable to level-1 predictors via fixed slopes (shorthand:
variance attributable to <code>f1</code>)
</p>
</li>
<li><p> variance attributable to level-2 predictors via fixed slopes (shorthand:
variance attributable to <code>f2</code>)
</p>
</li>
<li><p> variance attributable to level-1 predictors via random slope variation/
covariation (shorthand: variance attributable to <code>v</code>)
</p>
</li>
<li><p> variance attributable to cluster-specific outcome means via random
intercept variation (shorthand: variance attributable to <code>m</code>)
</p>
</li>
<li><p> variance attributable to level-1 residuals
</p>
</li></ul>

<p><code class="reqn">R^2</code> measures are based on the outcome variance of interest (total,
within-cluster, or between-cluster) in the denominator, and the source contributing
to explained variance in the numerator:
</p>

<dl>
<dt><strong>Total <code class="reqn">R^2</code> measures</strong></dt><dd><p>incorporate both within-cluster
and between cluster variance in the denominator and quantify variance
explained in an omnibus sense:
</p>

<ul>
<li><p><code class="reqn">R^{2(f_1)}_t</code>: Proportion of total outcome variance explained
by level-1 predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(f_2)}_t</code>: Proportion of total outcome variance explained
by level-2 predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(f)}_t</code>: Proportion of total outcome variance explained
by all predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(v)}_t</code>: Proportion of total outcome variance explained
by level-1 predictors via random slope variation/covariation.
</p>
</li>
<li><p><code class="reqn">R^{2(m)}_t</code>: Proportion of total outcome variance explained
by cluster-specific outcome means via random intercept variation.
</p>
</li>
<li><p><code class="reqn">R^{2(fv)}_t</code>: Proportion of total outcome variance explained
by predictors via fixed slopes and random slope variation/covariation.
</p>
</li>
<li><p><code class="reqn">R^{2(fvm)}_t</code>: Proportion of total outcome variance explained
by predictors via fixed slopes and random slope variation/covariation
and by cluster-specific outcome means via random intercept variation.
</p>
</li></ul>

</dd>
<dt><strong>Within-Cluster <code class="reqn">R^2</code> measures</strong></dt><dd><p>incorporate only within-cluster
variance in the denominator and indicate
the degree to which within-cluster variance can be explained by a given model:
</p>

<ul>
<li><p><code class="reqn">R^{2(f_1)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(v)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via random slope variation/covariation.
</p>
</li>
<li><p><code class="reqn">R^{2(f_1v)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via fixed slopes and random slope
variation/covariation.
</p>
</li></ul>

</dd>
<dt><strong>Between-Cluster <code class="reqn">R^2</code> measures</strong></dt><dd><p>incorporate only between-cluster
variance in the denominator and indicate the degree to which between-cluster
variance can be explained by a given model:
</p>

<ul>
<li><p><code class="reqn">R^{2(f_2)}_b</code>: Proportion of between-cluster outcome variance
explained by level-2 predictors via fixed slopes.
</p>
</li>
<li><p><code class="reqn">R^{2(m)}_b</code>: Proportion of between-cluster outcome variance
explained by cluster-specific outcome means via random intercept variation.
</p>
</li></ul>

</dd>
</dl>

<p>The decomposition of the total outcome variance can be visualized in a bar
chart by specifying <code>plot = TRUE</code>. The first column of the bar chart
decomposes scaled total variance into five distinct proportions (i.e.,
<code class="reqn">R^{2(f_1)}_t</code>, <code class="reqn">R^{2(f_2)}_t</code>, <code class="reqn">R^{2(f)}_t</code>, <code class="reqn">R^{2(v)}_t</code>,
<code class="reqn">R^{2(m)}_t</code>, <code class="reqn">R^{2(fv)}_t</code>, and <code class="reqn">R^{2(fvm)}_t</code>), the second
column decomposes scaled within-cluster variance into three distinct proportions
(i.e., <code class="reqn">R^{2(f_1)}_w</code>, <code class="reqn">R^{2(v)}_w</code>, and <code class="reqn">R^{2(f_1v)}_w</code>), and
the third column decomposes scaled between-cluster variance into two distinct
proportions (i.e., <code class="reqn">R^{2(f_2)}_b</code>, <code class="reqn">R^{2(m)}_b</code>).
</p>
<p>Note that the function assumes that all level-1 predictors are centered within
cluster (i.e., group-mean or cluster-mean centering) as has been widely recommended
(e.g., Enders &amp; Tofighi, D., 2007; Rights et al., 2019). In fact, it does not
matter whether a lower-level predictor is merely a control variable, or is
quantitative or categorical (Yaremych et al., 2021), cluster-mean centering
should always be used for lower-level predictors to obtain an orthogonal
between-within partitioning of a lower-level predictor's variance that directly
parallels what happens to a level-1 outcome (Hoffman &amp; Walters, 2022). In the
absence of cluster-mean-centering, however, the function provides total <code class="reqn">R^2</code>
measures, but does not provide any within-cluster or between-cluster <code class="reqn">R^2</code>
measures.</p>
</dd>
</dl>

<p>By default, the function only computes R-squared measures by Rights and Sterba
(2019) because the other R-squared measures reflect the same population quantity
provided by Rights and Sterba (2019). That is, R-squared measures <code class="reqn">R^2_1(RB)</code>
and <code class="reqn">R^2_2(RB)</code> by Raudenbush and Bryk (2002) are equivalent to <code class="reqn">R^{2(f_1v)}_w</code>
and <code class="reqn">R^{2(f_2)}_b</code>, R-squared measures <code class="reqn">R^2_1(SB)</code> and <code class="reqn">R^2_2(SB)</code>
are equivalent to <code class="reqn">R^{2(f)}_t</code> and <code class="reqn">R^{2(f_2)}_b</code>, and R-squared measures
<code class="reqn">R^2_m(NS)</code> and <code class="reqn">R^2_c(NS)</code> by Nakagawa and Schielzeth (2013) as extended
by Johnson (2014) are equivalent to <code class="reqn">R^{2(f)}_t</code> and <code class="reqn">R^{2(fvm)}_t</code>
(see Rights and Sterba, Table 3).
</p>
<p>Note that none of these measures provide an <code class="reqn">R^2</code> for the random slope
variance explained by cross-level interactions, a quantity that is frequently
of interest (Hoffman &amp; Walters, 2022).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>rb</code> for the R2 measures
by Raudenbush and Bryk (2002), <code>sb</code> for the R2 measures
by Snijders and Bosker (1994), <code>ns</code> for the R2 measures
by Nakagawa and Schielzeth (2013), and <code>rs</code> for the R2
measures by Rights and Sterba (2019)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on the <code>multilevelR2()</code> function from the <span class="pkg">mitml</span>
package by Simon Grund, Alexander Robitzsch and Oliver Luedtke (2021), and a
copy of the function <code>r2mlm</code> in the <span class="pkg">r2mlm</span> package by Mairead Shaw,
Jason Rights, Sonya Sterba, and Jessica Flake.
</p>


<h3>Author(s)</h3>

<p>Simon Grund, Alexander Robitzsch, Oliver Luedtk, Mairead Shaw, Jason D. Rights,
Sonya K. Sterba, Jessica K. Flake, and Takuya Yanagida
</p>


<h3>References</h3>

<p>Enders, C. K., &amp; Tofighi, D. (2007). Centering predictor variables in
cross-sectional multilevel models: A new look at an old issue.
<em>Psychological Methods, 12</em>, 121-138. https://doi.org/10.1037/1082-989X.12.2.121
</p>
<p>Hoffmann, L., &amp; Walter, W. R. (2022). Catching up on multilevel modeling.
<em>Annual Review of Psychology, 73</em>, 629-658. https://doi.org/10.1146/annurev-psych-020821-103525
</p>
<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel Analysis:
Techniques and Applications</em> (3rd ed.) Routledge.
</p>
<p>Johnson, P. C. D. (2014). Extension of Nakagawa &amp; Schielzeth’s R2 GLMM to random
slopes models. <em>Methods in Ecology and Evolution, 5</em>(9), 944-946.
https://doi.org/10.1111/2041-210X.12225
</p>
<p>LaHuis, D. M., Hartman, M. J., Hakoyama, S., &amp; Clark, P. C. (2014). Explained
variance measures for multilevel models. <em>Organizational Research Methods, 17</em>,
433-451. https://doi.org/10.1177/1094428114541701
</p>
<p>Nakagawa, S., &amp; Schielzeth, H. (2013). A general and simple method for obtaining
R2 from generalized linear mixed-effects models. <em>Methods in Ecology and Evolution, 4</em>(2),
133-142. https://doi.org/10.1111/j.2041-210x.2012.00261.x
</p>
<p>Raudenbush, S. W., &amp; Bryk, A. S., (2002). <em>Hierarchical linear models: Applications
and data analysis methods</em>. Sage.
</p>
<p>Rights, J. D., Preacher, K. J., &amp; Cole, D. A. (2020). The danger of conflating
level-specific effects of control variables when primary interest lies in level-2
effects. <em>British Journal of Mathematical and Statistical Psychology, 73</em>(Suppl 1),
194-211. https://doi.org/10.1111/bmsp.12194
</p>
<p>Rights, J. D., &amp; Sterba, S. K. (2019). Quantifying explained variance in multilevel
models: An integrative framework for defining R-squared measures. <em>Psychological Methods, 24</em>,
309-338. https://doi.org/10.1037/met0000184
</p>
<p>Roberts, K. J., Monaco, J. P., Stovall, H., &amp; Foster, V. (2011). Explained variance
in multilevel models (pp. 219-230). In J. J. Hox &amp; J. K. Roberts (Eds.), <em>Handbook
of Advanced Multilevel Analysis</em>. Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. (1994). Modeled variance in two-level models.
<em>Sociological methods and research, 22</em>, 342-363. https://doi.org/10.1177/0049124194022003004
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An introduction
to basic and advanced multilevel modeling</em> (2nd ed.). Sage.
</p>
<p>Yaremych, H. E., Preacher, K. J., &amp; Hedeker, D. (2021). Centering categorical
predictors in multilevel models: Best practices and interpretation. <em>Psychological
Methods</em>. Advance online publication. https://doi.org/10.1037/met0000434
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.cor">multilevel.cor</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>,
<code><a href="#topic+multilevel.icc">multilevel.icc</a></code>, <code><a href="#topic+multilevel.indirect">multilevel.indirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load misty, lme4, nlme, and ggplot2 package
library(misty)
library(lme4)
library(nlme)
library(ggplot2)

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
#'
# Cluster mean centering, center() from the misty package
Demo.twolevel$x2.c &lt;- center(Demo.twolevel$x2, type = "CWC",
                             cluster = Demo.twolevel$cluster)

# Compute group means, cluster.scores() from the misty package
Demo.twolevel$x2.b &lt;- cluster.scores(Demo.twolevel$x2,
                                     cluster = Demo.twolevel$cluster)

# Estimate multilevel model using the lme4 package
mod1a &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1 + x2.c | cluster), data = Demo.twolevel,
              REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

# Estimate multilevel model using the nlme package
mod1b &lt;- lme(y1 ~ x2.c + x2.b + w1, random = ~ 1 + x2.c | cluster, data = Demo.twolevel,
             method = "ML")

#----------------------------------------------------------------------------
#'
# Example 1a: R-squared measures according to Rights and Sterba (2019)
multilevel.r2(mod1a)
#'
# Example 1b: R-squared measures according to Rights and Sterba (2019)
multilevel.r2(mod1b)
#'
# Example 1a: Write Results into a text file
multilevel.r2(mod1a, write = "ML-R2.txt")

#-------------------------------------------------------------------------------

# Example 2: Bar chart showing the decomposition of scaled total, within-cluster,
# and between-cluster outcome variance
multilevel.r2(mod1a, plot = TRUE)

# Bar chart in gray scale
multilevel.r2(mod1a, plot = TRUE, gray = TRUE)

# Save bar chart, ggsave() from the ggplot2 package
ggsave("Proportion_of_Variance.png", dpi = 600, width = 5.5, height = 5.5)

#-------------------------------------------------------------------------------

# Example 3: Estimate multilevel model without random slopes
# Note. R-squared measures by Raudenbush and Bryk (2002), and  Snijders and
# Bosker (2012) should be computed based on the random intercept model
mod2 &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1 | cluster), data = Demo.twolevel,
             REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

# Print all available R-squared measures
multilevel.r2(mod2, print = "all")

#-------------------------------------------------------------------------------

# Example 4: Draw bar chart manually
mod1a.r2 &lt;- multilevel.r2(mod1a, output = FALSE)

# Prepare data frame for ggplot()
df &lt;- data.frame(var = factor(rep(c("Total", "Within", "Between"), each = 5),
                              level = c("Total", "Within", "Between")),
                 part = factor(c("Fixed Slopes (Within)", "Fixed Slopes (Between)",
                                 "Slope Variation (Within)", "Intercept Variation (Between)",
                                 "Residual (Within)"),
                 level = c("Residual (Within)", "Intercept Variation (Between)",
                           "Slope Variation (Within)", "Fixed Slopes (Between)",
                           "Fixed Slopes (Within)")),
                 y = as.vector(mod1a.r2$result$rs$decomp))

# Draw bar chart in line with the default setting of multilevel.r2()
ggplot(df, aes(x = var, y = y, fill = part)) +
  theme_bw() +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#E69F00", "#009E73", "#CC79A7", "#0072B2", "#D55E00")) +
  scale_y_continuous(name = "Proportion of Variance", breaks = seq(0, 1, by = 0.1)) +
  theme(axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.title = element_blank(),
        legend.position = "bottom",
        legend.box.margin = margin(-10, 6, 6, 6)) +
  guides(fill = guide_legend(nrow = 2, reverse = TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='multilevel.r2.manual'>R-Squared Measures for Multilevel and Linear Mixed Effects Models by Rights
and Sterba (2019), Manually Inputting Parameter Estimates</h2><span id='topic+multilevel.r2.manual'></span>

<h3>Description</h3>

<p>This function computes R-squared measures by Rights and Sterba (2019) for
multilevel and linear mixed effects models by manually inputting parameter
estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilevel.r2.manual(data, within = NULL, between = NULL, random = NULL,
                     gamma.w = NULL, gamma.b = NULL, tau, sigma2,
                     intercept = TRUE, center = TRUE, digits = 3,
                     plot = FALSE, gray = FALSE, start = 0.15, end = 0.85,
                     color = c("#D55E00", "#0072B2", "#CC79A7", "#009E73", "#E69F00"),
                     write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilevel.r2.manual_+3A_data">data</code></td>
<td>
<p>a matrix or data frame with the level-1 and level-2 predictors
and outcome variable used in the model.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_within">within</code></td>
<td>
<p>a character vector with the variable names in <code>data</code> or
numeric vector with numbers corresponding to the columns in
<code>data</code> of the level-1 predictors used in the model. If
none used, set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_between">between</code></td>
<td>
<p>a character vector with the variable names in <code>data</code> or
numeric vector with numbers corresponding to the columns in
<code>data</code> of the level-2 predictors used in the model. If
none used, set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_random">random</code></td>
<td>
<p>a character vector with the variable names in <code>data</code> or
numeric vector with numbers corresponding to the columns in
<code>data</code> of the level-1 predictors that have random slopes
in the model. If no random slopes specified, set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_gamma.w">gamma.w</code></td>
<td>
<p>a numeric vector of fixed slope estimates for all level-1
predictors, to be entered in the order of the predictors
listed in the argument <code>within</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_gamma.b">gamma.b</code></td>
<td>
<p>a numeric vector of the intercept and fixed slope estimates
for all level-2predictors, to be entered in the order of the
predictors listed in the argument <code>between</code>. Note that
the first element is the parameter estimate for the intercept
if <code>intercept = TRUE</code>.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_tau">tau</code></td>
<td>
<p>a matrix indicating the random effects covariance matrix, the
first row/column denotes the intercept variance and covariances
(if intercept is fixed, set all to 0) and each subsequent
row/column denotes a given random slope's variance and covariances
(to be entered in the order listed in the argument <code>random</code>).</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_sigma2">sigma2</code></td>
<td>
<p>a numeric value indicating the level-1 residual variance.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_intercept">intercept</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the first element in the
<code>gamma.b</code> is assumed to be the fixed intercept estimate;
if set to <code>FALSE</code>, the first element in the argument
<code>gamma.b</code> is assumed to be the first fixed level-2
predictor slope.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_center">center</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), all level-1 predictors are
assumed to be cluster-mean-centered and the function will
output all decompositions; if set to <code>FALSE</code>, function
will output only the total decomposition.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar chart showing the decomposition
of scaled total, within-cluster, and between-cluster outcome
variance into five (total), three (within-cluster), and two
(between-cluster) proportions is drawn. Note that the <span class="pkg">ggplot2</span>
package is required to draw the bar chart.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_gray">gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, graphical parameter to draw the bar
chart in gray scale.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_start">start</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the low end of the palette.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_end">end</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the high end of the palette.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_color">color</code></td>
<td>
<p>a character vector, graphical parameter indicating the color
of bars in the bar chart in the following order: Fixed slopes
(Within), Fixed slopes (Between), Slope variation (Within),
Intercept variation (Between), and Residual (Within). By default,
colors from the colorblind-friendly palettes are used.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="multilevel.r2.manual_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of R-squared measures for multilevel and linear mixed effects models
have been developed in the methodological literature (see Rights &amp; Sterba, 2018).
R-squared measures by Rights and Sterba (2019) provide an integrative framework
of R-squared measures for multilevel and linear mixed effects models with random
intercepts and/or slopes. Their measures are based on partitioning model implied
variance from a single fitted model, but they provide a full partitioning of
the total outcome variance to one of five specific sources. See the help page
of the <code><a href="#topic+multilevel.r2">multilevel.r2</a></code> function for more details.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>decomp</code> for the
decomposition, <code>total</code> for total R2 measures,
<code>within</code> for the within-cluster R2 measures, and
<code>between</code></p>
</td></tr></table>
<p> for the between-cluster R2 measures.
</p>


<h3>Note</h3>

<p>This function is based on a copy of the function <code>r2mlm_manual()</code> in the
<span class="pkg">r2mlm</span> package by Mairead Shaw, Jason Rights, Sonya Sterba, and Jessica
Flake.
</p>


<h3>Author(s)</h3>

<p>Jason D. Rights, Sonya K. Sterba, Jessica K. Flake, and Takuya Yanagida
</p>


<h3>References</h3>

<p>Rights, J. D., &amp; Cole, D. A. (2018). Effect size measures for multilevel models
in clinical child and adolescent research: New r-squared methods and recommendations.
<em>Journal of Clinical Child and Adolescent Psychology, 47</em>, 863-873.
https://doi.org/10.1080/15374416.2018.1528550
</p>
<p>Rights, J. D., &amp; Sterba, S. K. (2019). Quantifying explained variance in multilevel
models: An integrative framework for defining R-squared measures. <em>Psychological Methods, 24</em>,
309-338. https://doi.org/10.1037/met0000184
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multilevel.r2">multilevel.r2</a></code>, <code><a href="#topic+multilevel.cor">multilevel.cor</a></code>,
<code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+multilevel.icc">multilevel.icc</a></code>,
<code><a href="#topic+multilevel.indirect">multilevel.indirect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load misty, lme4, nlme, and ggplot2 package
library(misty)
library(lme4)

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#-------------------------------------------------------------------------------

# Cluster mean centering, center() from the misty package
Demo.twolevel$x2.c &lt;- center(Demo.twolevel$x2, type = "CWC",
                             cluster = Demo.twolevel$cluster)

# Compute group means, cluster.scores() from the misty package
Demo.twolevel$x2.b &lt;- cluster.scores(Demo.twolevel$x2,
                                     cluster = Demo.twolevel$cluster)

# Estimate random intercept model using the lme4 package
mod1 &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1| cluster), data = Demo.twolevel,
             REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

# Estimate random intercept and slope model using the lme4 package
mod2 &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1 + x2.c | cluster), data = Demo.twolevel,
             REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

#-------------------------------------------------------------------------------
# Example 1: Random intercept model

# Fixed slope estimates
fixef(mod1)

# Random effects variance-covariance matrix
as.data.frame(VarCorr(mod1))

# R-squared measures according to Rights and Sterba (2019)
multilevel.r2.manual(data = Demo.twolevel,
                     within = "x2.c", between = c("x2.b", "w1"),
                     gamma.w = 0.41127956,
                     gamma.b = c(0.01123245, -0.08269374, 0.17688507),
                     tau = 0.9297401,
                     sigma2 = 1.813245794)

#-------------------------------------------------------------------------------
# Example 2: Random intercept and slope model

# Fixed slope estimates
fixef(mod2)

# Random effects variance-covariance matrix
as.data.frame(VarCorr(mod2))

# R-squared measures according to Rights and Sterba (2019)
multilevel.r2.manual(data = Demo.twolevel,
                     within = "x2.c", between = c("x2.b", "w1"), random = "x2.c",
                     gamma.w = 0.41127956,
                     gamma.b = c(0.01123245, -0.08269374, 0.17688507),
                     tau = matrix(c(0.931008649, 0.004110479, 0.004110479, 0.017068857), ncol = 2),
                     sigma2 = 1.813245794)

## End(Not run)
</code></pre>

<hr>
<h2 id='na.auxiliary'>Auxiliary variables analysis</h2><span id='topic+na.auxiliary'></span>

<h3>Description</h3>

<p>This function computes (1) Pearson product-moment correlation matrix to identify
variables related to the incomplete variable and (2) Cohen's d comparing cases
with and without missing values to identify variables related to the probability
of missingness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.auxiliary(..., data = NULL, tri = c("both", "lower", "upper"), weighted = FALSE,
             correct = FALSE, digits = 2, as.na = NULL, write = NULL,
             append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="na.auxiliary_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with incomplete data, where missing
values are coded as <code>NA</code>. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>na.auxiliary(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_tri">tri</code></td>
<td>
<p>a character string indicating which triangular of the correlation
matrix to show on the console, i.e., <code>both</code> for upper and
lower triangular, <code>lower</code> (default) for the lower triangular,
and <code>upper</code> for the upper triangular.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the weighted pooled standard
deviation is used.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor for Cohen's d to
remove positive bias in small samples is used.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_digits">digits</code></td>
<td>
<p>integer value indicating the number of decimal places digits
to be used for displaying correlation coefficients and Cohen's d
estimates.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.auxiliary_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that non-numeric variables (i.e., factors, character vectors, and logical
vectors) are excluded from to the analysis.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>cor.mat</code> for the
correlation matrix and <code>d.mat</code> for Cohen's d</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>,
<code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>, <code><a href="#topic+na.pattern">na.pattern</a></code>,
<code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Auxiliary variables
na.auxiliary(airquality)

# Example 1b: Alternative specification using the 'data' argument
na.auxiliary(., data = airquality)

## Not run: 
# Example 2: Write Results into a text file
na.auxiliary(airquality, write = "NA_Auxiliary.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='na.coverage'>Variance-Covariance Coverage</h2><span id='topic+na.coverage'></span>

<h3>Description</h3>

<p>This function computes the proportion of cases that contributes for the calculation
of each variance and covariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.coverage(..., data = NULL, tri = c("both", "lower", "upper"), digits = 2,
            as.na = NULL, write = NULL, append = TRUE, check = TRUE,
            output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="na.coverage_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with incomplete data, where missing
values are coded as <code>NA</code>. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>na.coverage(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_tri">tri</code></td>
<td>
<p>a character string or character vector indicating which triangular
of the matrix to show on the console, i.e., <code>both</code> for
upper and lower triangular, <code>lower</code> (default) for the
lower triangular, and <code>upper</code> for the upper triangular.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying proportions.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.coverage_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576. https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Compute variance-covariance coverage
na.coverage(airquality)

# Example 1b: Alternative specification using the 'data' argument
na.coverage(., data = airquality)

## Not run: 
# Example 2a: Write Results into a text file
na.coverage(airquality, write = "Coverage.txt")

# Example 2b: Write Results into an Excel file
na.coverage(airquality, write = "Coverage.xlsx")

result &lt;- na.coverage(airquality, output = FALSE)
write.result(result, "Coverage.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='na.descript'>Descriptive Statistics for Missing Data in Single-Level, Two-Level and Three-Level Data</h2><span id='topic+na.descript'></span>

<h3>Description</h3>

<p>This function computes descriptive statistics for missing data in single-level,
two-level, and three-level data, e.g. number of incomplete cases, number
of missing values, and summary statistics for the number of missing
values across all variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.descript(..., data = NULL, cluster = NULL,  table = FALSE, digits = 2,
            as.na = NULL, write = NULL, append = TRUE, check = TRUE,
            output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="na.descript_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with incomplete data, where missing
values are coded as <code>NA</code>. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>na.descript(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_cluster">cluster</code></td>
<td>
<p>a character string indicating the name of the cluster
variable in <code>...</code> or <code>data</code> for two-level data,
a character vector indicating the names of the cluster
variables in <code>...</code> for three-level data, or a vector
or data frame representing the nested grouping structure
(i.e., group or cluster variables). Alternatively, a
character string or character vector indicating the variable
name(s) of the cluster variable(s) in <code>data</code>. Note that
the cluster variable at Level 3 come first in a three-level
model, i.e., <code>cluster = c("level3", "level2")</code>.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_table">table</code></td>
<td>
<p>logical: if <code>TRUE</code>, a frequency table with number of
observed values (<code>"nObs"</code>), percent of observed values
(<code>"pObs"</code>), number of missing values (<code>"nNA"</code>),
and percent of missing values (<code>"pNA"</code>) is printed for
each variable on the console.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying percentages.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.descript_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with results</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Single-Level Data

# Example 1a: Descriptive statistics for missing data
na.descript(airquality)

# Example 1b: Alternative specification using the 'data' argument
na.descript(., data = airquality)

# Example 2: Descriptive statistics for missing data, print results with 3 digits
na.descript(airquality, digits = 3)

# Example 3: Descriptive statistics for missing data with frequency table
na.descript(airquality, table = TRUE)

#----------------------------------------------------------------------------
# Two-Level Data

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

# Example 4: escriptive statistics for missing data
na.descript(Demo.twolevel, cluster = "cluster")

#----------------------------------------------------------------------------
# Three-Level Data

# Create arbitrary three-level data
Demo.threelevel &lt;- data.frame(Demo.twolevel, cluster2 = Demo.twolevel$cluster,
                                             cluster3 = rep(1:10, each = 250))

# Example 5: escriptive statistics for missing data
na.descript(Demo.threelevel, cluster = c("cluster3", "cluster2"))

#----------------------------------------------------------------------------
# Write Results

## Not run: 
# Example 6a: Write Results into a text file
na.descript(airquality, table = TRUE, write = "NA_Descriptives.txt")

# Example 6b: Write Results into a Excel file
na.descript(airquality, table = TRUE, write = "NA_Descriptives.xlsx")

result &lt;- na.descript(airquality, table = TRUE, output = FALSE)
write.result(result, "NA_Descriptives.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='na.indicator'>Missing Data Indicator Matrix</h2><span id='topic+na.indicator'></span>

<h3>Description</h3>

<p>This function creates a missing data indicator matrix <code class="reqn">R</code> that denotes whether
values are observed or missing, i.e., <code class="reqn">r = 1</code> if a value is observed, and
<code class="reqn">r = 0</code> if a value is missing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.indicator(..., data = NULL, as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="na.indicator_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with incomplete data, where missing
values are coded as <code>NA</code>. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>na.indicator(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.indicator_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix or data frame with <code class="reqn">r = 1</code> if a value is observed, and <code class="reqn">r = 0</code>
if a value is missing.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.). Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>, <code><a href="#topic+na.auxiliary">na.auxiliary</a></code>,
<code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.pattern">na.pattern</a></code>,
<code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Create missing data indicator matrix \eqn{R}
na.indicator(airquality)

# Example 1b: Alternative specification using the 'data' argument
na.indicator(., data = airquality)
</code></pre>

<hr>
<h2 id='na.pattern'>Missing Data Pattern</h2><span id='topic+na.pattern'></span>

<h3>Description</h3>

<p>This function computes a summary of missing data patterns, i.e., number (
cases with a specific missing data pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.pattern(..., data = NULL, order = FALSE, digits = 2, as.na = NULL, write = NULL,
           append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="na.pattern_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with incomplete data, where missing
values are coded as <code>NA</code>. a matrix or data frame with incomplete data, where missing
values are coded as <code>NA</code>. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>na.pattern(x1, x2, x3, data = dat)</code>.Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_order">order</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables are ordered from left to
right in increasing order of missing values.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying percentages.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to NA before conducting the
analysis.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.pattern_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame used for the current analysis</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result tables</p>
</td></tr>
<tr><td><code>pattern</code></td>
<td>
<p>group variable of missing data pattern</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.result">write.result</a></code>, <code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>,
<code><a href="#topic+na.auxiliary">na.auxiliary</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>,
<code><a href="#topic+na.indicator">na.indicator</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1a: Compute a summary of missing data patterns
dat.pattern &lt;- na.pattern(airquality)

# Example 1b: Alternative specification using the 'data' argument
dat.pattern &lt;- na.pattern(., data = airquality)

# Example 2: Vector of missing data pattern for each case
dat.pattern$pattern

# Data frame without cases with missing data pattern 2 and 4
airquality[!dat.pattern$pattern 

# Example 3a: Write Results into an text file
result &lt;- na.pattern(airquality, write = "NA_Pattern.txt")

# Example 3b: Write Results into an Excel file
result &lt;- na.pattern(airquality, write = "NA_Pattern.xlsx")

result &lt;- na.pattern(dat, output = FALSE)
write.result(result, "NA_Pattern.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='na.prop'>Proportion of Missing Data for Each Case</h2><span id='topic+na.prop'></span>

<h3>Description</h3>

<p>This function computes the proportion of missing data for each case in a matrix
or data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.prop(..., data = NULL, digits = 2, append = TRUE, name = "na.prop",
        as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="na.prop_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with incomplete data, where missing
values are coded as <code>NA</code>. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>na.prop(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.prop_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="na.prop_+3A_name">name</code></td>
<td>
<p>a character string indicating the name of the variable appended
to the data frame specified in the arguement <code>data</code> when
<code>append = TRUE</code>.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="na.prop_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable with proportion of
missing data is appended to the data frame specified in the
argument <code>data</code></p>
</td></tr>
<tr><td><code id="na.prop_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying proportions.</p>
</td></tr>
<tr><td><code id="na.prop_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="na.prop_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector with the same length as the number of rows in <code>x</code>
containing the proportion of missing data.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Graham, J. W. (2009). Missing data analysis: Making it work in the real world.
<em>Annual Review of Psychology, 60</em>, 549-576.
https://doi.org/10.1146/annurev.psych.58.110405.085530
</p>
<p>van Buuren, S. (2018). <em>Flexible imputation of missing data</em> (2nd ed.).
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>, <code><a href="#topic+na.auxiliary">na.auxiliary</a></code>,
<code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.test">na.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Compute proportion of missing data for each case in the data frame
na.prop(airquality)

# Example 1b: Alternative specification using the 'data' argument,
# append proportions to the data frame 'airquality'
na.prop(., data = airquality)
</code></pre>

<hr>
<h2 id='na.test'>Little's Missing Completely at Random (MCAR) Test</h2><span id='topic+na.test'></span>

<h3>Description</h3>

<p>This function performs Little's Missing Completely at Random (MCAR) test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.test(..., data = NULL, digits = 2, p.digits = 3, as.na = NULL, write = NULL,
        append = TRUE,check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="na.test_+3A_...">...</code></td>
<td>
<p>a matrix or data frame with incomplete data, where missing
values are coded as <code>NA</code>. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>na.test(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="na.test_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="na.test_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying results.</p>
</td></tr>
<tr><td><code id="na.test_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be
used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="na.test_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values, i.e.
these values are converted to NA before conducting the analysis.</p>
</td></tr>
<tr><td><code id="na.test_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="na.test_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="na.test_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="na.test_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Little (1988) proposed a multivariate test of Missing Completely at Random (MCAR)
that tests for mean differences on every variable in the data set across subgroups
that share the same missing data pattern by comparing the observed variable means
for each pattern of missing data with the expected population means estimated using
the expectation-maximization (EM) algorithm (i.e., EM maximum likelihood estimates).
The test statistic is the sum of the squared standardized differences between the
subsample means and the expected population means weighted by the estimated
variance-covariance matrix and the number of observations within each subgroup
(Enders, 2010). Under the null hypothesis that data are MCAR, the test statistic
follows asymptotically a chi-square distribution with <code class="reqn">\sum k_j - k</code> degrees
of freedom, where <code class="reqn">k_j</code> is the number of complete variables for missing data
pattern <code class="reqn">j</code>, and <code class="reqn">k</code> is the total number of variables. A statistically
significant result provides evidence against MCAR.
</p>
<p>Note that Little's MCAR test has a number of problems (see Enders, 2010).
<strong>First</strong>, the test does not identify the specific variables that violates
MCAR, i.e., the test does not identify potential correlates of missingness (i.e.,
auxiliary variables). <strong>Second</strong>, the test is based on multivariate normality,
i.e., under departure from the normality assumption the test might be unreliable
unless the sample size is large and is not suitable for categorical variables.
<strong>Third</strong>, the test investigates mean  differences assuming that the missing
data pattern share a common covariance matrix, i.e., the test cannot detect
covariance-based deviations from MCAR stemming from a Missing at Random (MAR)
or Missing Not at Random (MNAR) mechanism because MAR and MNAR mechanisms can
also produce missing data subgroups with equal means. <strong>Fourth</strong>, simulation
studies suggest that Little's MCAR test suffers from low statistical power,
particularly when the number of variables that violate MCAR is small, the
relationship between the data and missingness is weak, or the data are MNAR
(Thoemmes &amp; Enders, 2007). <strong>Fifth</strong>, the test can only reject, but cannot
prove the MCAR assumption, i.e., a statistically not significant result and failing
to reject the null hypothesis of the MCAR test does not prove the null hypothesis
that the data is MCAR. <strong>Finally</strong>, under the null hypothesis the data are
actually MCAR or MNAR, while a statistically significant result indicates that
missing data are MAR or MNAR, i.e., MNAR cannot be ruled out regardless of the
result of the test.
</p>
<p>This function is based on the <code>prelim.norm</code> function in the <span class="pkg">norm</span>
package which can handle about 30 variables. With more than 30 variables
specified in the argument <code>x</code>, the <code>prelim.norm</code> function might run
into numerical problems leading to results that are not trustworthy. In this
case it is recommended to reduce the number of variables specified in the argument
<code>x</code>. If the number of variables cannot be reduced, it is recommended to
use the <code>LittleMCAR</code> function in the <span class="pkg">BaylorEdPsych</span> package which can
deal with up to 50 variables. However, this package was removed from the CRAN
repository and needs to be obtained from the archive along with the <span class="pkg">mvnmle</span>
which is needed for using the <code>LittleMCAR</code> function. Note that the
<code>mcar_test</code> function in the <span class="pkg">naniar</span> package is also based on the
<code>prelim.norm</code> function which results are not trustworthy whenever the warning
message <code>In norm::prelim.norm(data) : NAs introduced by coercion to integer range</code>
is printed on the console.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Code is adapted from the R function by Eric Stemmler:
tinyurl.com/r-function-for-MCAR-test
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</p>
<p>Thoemmes, F., &amp; Enders, C. K. (2007, April). <em>A structural equation model for
testing whether data are missing completely at random</em>. Paper presented at the
annual meeting of the American Educational Research Association, Chicago, IL.
</p>
<p>Little, R. J. A. (1988). A test of Missing Completely at Random for multivariate
data with missing values. <em>Journal of the American Statistical Association, 83</em>,
1198-1202. https://doi.org/10.2307/2290157
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.na">as.na</a></code>, <code><a href="#topic+na.as">na.as</a></code>, <code><a href="#topic+na.auxiliary">na.auxiliary</a></code>,
<code><a href="#topic+na.coverage">na.coverage</a></code>, <code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.indicator">na.indicator</a></code>,
<code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+na.prop">na.prop</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1a: Conduct Little's MCAR test
na.test(airquality)

# Example b: Alternative specification using the 'data' argument,
na.test(., data = airquality)

## Not run: 
# Example 2: Write results into a text file
na.test(airquality, write = "NA_Test.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='print.misty.object'>Print misty.object object</h2><span id='topic+print.misty.object'></span>

<h3>Description</h3>

<p>This function prints the <code>misty.object</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'misty.object'
print(x,
      print = x$args$print, tri = x$args$tri, freq = x$args$freq,
      hypo = x$args$hypo, descript = x$args$descript, epsilon = x$args$epsilon,
      effsize = x$args$effsize, posthoc = x$args$posthoc, split = x$args$split,
      table = x$args$table, digits = x$args$digits, p.digits = x$args$p.digits,
      icc.digits = x$args$icc.digits, sort.var = x$args$sort.var,
      order = x$args$order, check = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.misty.object_+3A_x">x</code></td>
<td>
<p><code>misty.object</code> object.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_print">print</code></td>
<td>
<p>a character string or character vector indicating which
results to to be printed on the console.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_tri">tri</code></td>
<td>
<p>a character string or character vector indicating which
triangular of the matrix to show on the console, i.e.,
<code>both</code> for upper and lower triangular, <code>lower</code>
for the lower triangular, and <code>upper</code> for the upper
triangular.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_freq">freq</code></td>
<td>
<p>logical: if <code>TRUE</code>, absolute frequencies will be included
in the cross tabulation (<code>crosstab()</code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code>, null and alternative hypothesis are
shown on the console (<code><a href="#topic+test.t">test.t</a></code>,
<code><a href="#topic+test.welch">test.welch</a></code>, <code><a href="#topic+test.z">test.z</a></code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code>, descriptive statistics are shown on
the console (<code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>,
<code><a href="#topic+test.z">test.z</a></code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_epsilon">epsilon</code></td>
<td>
<p>logical: if <code>TRUE</code>, box indices of sphericity (epsilon)
are shown on the console (<code><a href="#topic+aov.w">aov.w</a></code>).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measure(s) is shown on
the console (<code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>,
<code><a href="#topic+test.z">test.z</a></code> function).
<code><a href="#topic+test.z">test.z</a></code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_posthoc">posthoc</code></td>
<td>
<p>logical: if <code>TRUE</code>,post hoc test for multiple comparison
is shown on the console (<code><a href="#topic+test.welch">test.welch</a></code>).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_split">split</code></td>
<td>
<p>logical: if <code>TRUE</code>, output table is split by variables
when specifying more than one variable in <code>x</code>
(<code><a href="#topic+freq">freq</a></code>).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_table">table</code></td>
<td>
<p>logical: if <code>TRUE</code>, a frequency table with number of
observed values (<code>"nObs"</code>), percent of observed values
(<code>"pObs"</code>), number of missing values (<code>"nNA"</code>),
and percent of missing values (<code>"pNA"</code>) is printed for
each variable on the console (<code>na.descript()</code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places digits
to be used for displaying results.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_icc.digits">icc.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying intraclass correlation coefficients
(<code>multilevel.descript()</code> and <code>multilevel.icc()</code>
function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_sort.var">sort.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, output is sorted by variables.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_order">order</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables are ordered from left to
right in increasing order
of missing values (<code>na.descript()</code> function).</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, argument specification is checked.</p>
</td></tr>
<tr><td><code id="print.misty.object_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>

<hr>
<h2 id='read.dta'>Read Stata DTA File</h2><span id='topic+read.dta'></span>

<h3>Description</h3>

<p>This function calls the <code>read_dta</code> function in the <span class="pkg">haven</span> package
by Hadley Wickham, Evan Miller and Danny Smith (2023) to read a Stata DTA file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.dta(file, use.value.labels = FALSE, formats = FALSE, label = FALSE, labels = FALSE,
         missing = FALSE,   widths = FALSE, as.data.frame = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.dta_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the Stata
data file with or without file extension '.dta', e.g.,
<code>"Stata_Data.dta"</code> or <code>"Stata_Data"</code>.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_use.value.labels">use.value.labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables with value labels
are converted into factors.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_formats">formats</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable formats are
shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_label">label</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable labels are
shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_labels">labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, value labels are
shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_missing">missing</code></td>
<td>
<p>logical: if <code>TRUE</code>, convert tagged missing values
to regular R <code>NA</code>.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_widths">widths</code></td>
<td>
<p>logical: if <code>TRUE</code>, widths are shown in an attribute
for all variables.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), function returns a
regular data frame;
if <code>FALSE</code> function returns a tibble.</p>
</td></tr>
<tr><td><code id="read.dta_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification
is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame or tibble.
</p>


<h3>Note</h3>

<p>This function is a modified copy of the <code>read_dta()</code> function in the
<span class="pkg">haven</span> package by Hadley Wickham, Evan Miller and Danny Smith (2023).
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham and Evan Miller
</p>


<h3>References</h3>

<p>Wickham H, Miller E, Smith D (2023). <em>haven: Import and Export 'SPSS',
'Stata' and 'SAS' Files</em>. R package version 2.5.3.
<a href="https://CRAN.R-project.org/package=haven">https://CRAN.R-project.org/package=haven</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.sav">read.sav</a></code>, <code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+read.xlsx">read.xlsx</a></code>,
<code><a href="#topic+write.xlsx">write.xlsx</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

read.dta("Stata_Data.dta")
read.dta("Stata_Data")

# Example 2: Read Stata data, convert variables with value labels into factors
read.dta("Stata_Data.dta", use.value.labels = TRUE)

# Example 3: Read Stata data as tibble
read.dta("Stata_Data.dta", as.data.frame = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='read.mplus'>Read Mplus Data File and Variable Names</h2><span id='topic+read.mplus'></span>

<h3>Description</h3>

<p>This function reads a Mplus data file and/or Mplus input/output file to return
a data frame with variable names extracted from the Mplus input/output file. Note
that by default <code>-99</code> in the Mplus data file is replaced with to <code>NA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.mplus(file, sep = "", input = NULL, na = -99, print = FALSE, return.var = FALSE,
           fileEncoding = "UTF-8-BOM", check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.mplus_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the Mplus data
file with or without the file extension <code>.dat</code>, e.g.,
<code>"Mplus_Data.dat"</code> or <code>"Mplus_Data"</code>.
Note that it is not necessary to specify this argument when
<code>return.var = TRUE</code>.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_sep">sep</code></td>
<td>
<p>a character string indicating the field separator (i.e.,
delimiter) used in the data file specified in <code>file</code>.
By default, the separator is 'white space', i.e., one or more
spaces, tabs, newlines or carriage returns.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_input">input</code></td>
<td>
<p>a character string indicating the Mplus input (<code>.inp</code>)
or output file (<code>.out</code>) in which the variable names
are specified in the <code>VARIABLE:</code> section. Note that if
<code>input = NULL</code>, this function is equivalent to <code>read.table(file)</code>.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_na">na</code></td>
<td>
<p>a numeric vector indicating values to replace with <code>NA</code>.
By default, <code>-99</code> is replaced with <code>NA</code>. If
<code>-99</code> is not a missing value change the argument to
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_print">print</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable names are printed on the
console.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_return.var">return.var</code></td>
<td>
<p>logical: if <code>TRUE</code>, the function returns the variable
names extracted from the Mplus input or output file only.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_fileencoding">fileEncoding</code></td>
<td>
<p>character string declaring the encoding used on <code>file</code>
so the character data can be re-encoded. See <code><a href="#topic+df.sort">df.sort</a></code>.</p>
</td></tr>
<tr><td><code id="read.mplus_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing a representation of the data in the file.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>, <code><a href="#topic+read.sav">read.sav</a></code>,
<code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+read.xlsx">read.xlsx</a></code>, <code><a href="#topic+write.xlsx">write.xlsx</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Read Mplus data file and variable names extracted from the Mplus input file
dat &lt;- read.mplus("Mplus_Data.dat", input = "Mplus_Input.inp")

# Example 2: Read Mplus data file and variable names extracted from the Mplus input file,
# print variable names on the console
dat &lt;- read.mplus("Mplus_Data.dat", input = "Mplus_Input.inp", print = TRUE)

# Example 3: Read variable names extracted from the Mplus input file
varnames &lt;- read.mplus(input = "Mplus_Input.inp", return.var = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='read.sav'>Read SPSS File</h2><span id='topic+read.sav'></span>

<h3>Description</h3>

<p>This function calls the <code>read_spss</code> function in the <span class="pkg">haven</span> package
by Hadley Wickham, Evan Miller and Danny Smith (2023) to read an SPSS file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.sav(file, use.value.labels = FALSE, use.missings = TRUE, formats = FALSE,
         label = FALSE, labels = FALSE, missing = FALSE, widths = FALSE,
         as.data.frame = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.sav_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the SPSS data file
with or without file extension '.sav', e.g., <code>"SPSS_Data.sav"</code>
or <code>"SPSS_Data"</code>.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_use.value.labels">use.value.labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, variables with value labels are converted into factors.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_use.missings">use.missings</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), user-defined missing values are converted into NAs.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_formats">formats</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable formats are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_label">label</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable labels are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_labels">labels</code></td>
<td>
<p>logical: if <code>TRUE</code>, value labels are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_missing">missing</code></td>
<td>
<p>logical: if <code>TRUE</code>, value labels for user-defined missings are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_widths">widths</code></td>
<td>
<p>logical: if <code>TRUE</code>, widths are shown in an attribute for all variables.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), function returns a regular data frame; if <code>FALSE</code> function returns a tibble.</p>
</td></tr>
<tr><td><code id="read.sav_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame or tibble.
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham, Evan Miller and Danny Smith
</p>


<h3>References</h3>

<p>Wickham H, Miller E, Smith D (2023). <em>haven: Import and Export 'SPSS', 'Stata' and 'SAS' Files</em>.
R package version 2.5.3. <a href="https://CRAN.R-project.org/package=haven">https://CRAN.R-project.org/package=haven</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>, <code><a href="#topic+read.xlsx">read.xlsx</a></code>,
<code><a href="#topic+write.xlsx">write.xlsx</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Read SPSS data file
read.sav("SPSS_Data.sav")
read.sav("SPSS_Data")

# Example 2: Read SPSS data file, convert variables with value labels into factors
read.sav("SPSS_Data.sav", use.value.labels = TRUE)

# Example 3: Read SPSS data file, user-defined missing values are not converted into NAs
read.sav("SPSS_Data.sav", use.missing = FALSE)

# Example 4: Read SPSS data file as tibble
read.sav("SPSS_Data.sav", as.data.frame = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='read.xlsx'>Read Excel File</h2><span id='topic+read.xlsx'></span>

<h3>Description</h3>

<p>This function calls the <code>read_xlsx()</code> function in the <span class="pkg">readxl</span> package
by Hadley Wickham and Jennifer Bryan (2019) to read an Excel file (.xlsx).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.xlsx(file, sheet = NULL, header = TRUE, range = NULL,
          coltypes = c("skip", "guess", "logical", "numeric", "date", "text", "list"),
          na = "", trim = TRUE, skip = 0, nmax = Inf, guessmax = min(1000, nmax),
          progress = readxl::readxl_progress(), name.repair = "unique",
          as.data.frame = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.xlsx_+3A_file">file</code></td>
<td>
<p>a character string indicating the name of the Excel data
file with or without file extension '.xlsx', e.g., <code>"My_Excel_Data.xlsx"</code>
or <code>"My_Excel_Data"</code>.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_sheet">sheet</code></td>
<td>
<p>a character string indicating the name of a sheet or a numeric
value indicating the position of the sheet to read. By default
the first sheet will be read.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_header">header</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the first row is used
as column names, if <code>FALSE</code> default names are used.
A character vector giving a name for each column can also
be used. If <code>coltypes</code> as a vector is provided,
<code>colnames</code> can have one entry per column, i.e. have
the same length as <code>coltypes</code>, or one entry per unskipped
column.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_range">range</code></td>
<td>
<p>a character string indicating the cell range to read from,
e.g. typical Excel ranges like <code>"B3:D87"</code>, possibly
including the sheet name like <code>"Data!B2:G14"</code>. Interpreted
strictly, even if the range forces the inclusion of leading
or trailing empty rows or columns. Takes precedence over
<code>skip</code>, <code>nmax</code> and <code>sheet</code>.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_coltypes">coltypes</code></td>
<td>
<p>a character vector containing one entry per column from
these options <code>"skip"</code>, <code>"guess"</code>, <code>"logical"</code>,
<code>"numeric"</code>, <code>"date"</code>, <code>"text"</code> or <code>"list"</code>.
If exactly one <code>coltype</code> is specified, it will be recycled.
By default (i.e., <code>coltypes = NULL</code>) coltypes will
be guessed. The content of a cell in a skipped column is
never read and that column will not appear in the data frame
output. A list cell loads a column as a list of length 1
vectors, which are typed using the type guessing logic from
<code>coltypes = NULL</code>, but on a cell-by-cell basis.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_na">na</code></td>
<td>
<p>a character vector indicating strings to interpret as missing
values. By default, blank cells will be treated as missing data.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_trim">trim</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), leading and trailing
whitespace will be trimmed.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_skip">skip</code></td>
<td>
<p>a numeric value indicating the minimum number of rows to
skip before reading anything, be it column names or data.
Leading empty rows are automatically skipped, so this is
a lower bound. Ignored if the argument <code>range</code> is specified.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_nmax">nmax</code></td>
<td>
<p>a numeric value indicating the maximum number of data rows
to read. Trailing empty rows are automatically skipped, so
this is an upper bound on the number of rows in the returned
data frame. Ignored if the argument <code>range</code> is specified.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_guessmax">guessmax</code></td>
<td>
<p>a numeric value indicating the maximum number of data rows
to use for guessing column types.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_progress">progress</code></td>
<td>
<p>display a progress spinner? By default, the spinner appears
only in an interactive session, outside the context of knitting
a document, and when the call is likely to run for several
seconds or more.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_name.repair">name.repair</code></td>
<td>
<p>a character string indicating the handling of column names.
By default, the function ensures column names are not empty
and are unique.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), function returns a regular
data frame; if <code>FALSE</code> function returns a tibble.</p>
</td></tr>
<tr><td><code id="read.xlsx_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame or tibble.
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham and Jennifer Bryan
</p>


<h3>References</h3>

<p>Wickham H, Miller E, Smith D (2023). <em>readxl: Read Excel Files</em>. R package
version 1.4.3. <a href="https://CRAN.R-project.org/package=readxl">https://CRAN.R-project.org/package=readxl</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>, <code><a href="#topic+read.sav">read.sav</a></code>,
<code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Read Excel file (.xlsx)
read.xlsx("data.xlsx")

# Example 1: Read Excel file (.xlsx), use default names as column names
read.xlsx("data.xlsx", header = FALSE)

# Example 2: Read Excel file (.xlsx), interpret -99 as missing values
read.xlsx("data.xlsx", na = "-99")

# Example 3: Read Excel file (.xlsx), use x1, x2, and x3 as column names
read.xlsx("data.xlsx", header = c("x1", "x2", "x3"))

# Example 4: Read Excel file (.xlsx), read cells A1:B5
read.xlsx("data.xlsx", range = "A1:B5")

# Example 5: Read Excel file (.xlsx), skip 2 rows before reading data
read.xlsx("data.xlsx", skip = 2)

# Example 5: Read Excel file (.xlsx), return a tibble
read.xlsx("data.xlsx", as.data.frame = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='rec'>Recode Variable</h2><span id='topic+rec'></span>

<h3>Description</h3>

<p>This function recodes numeric vectors, character vectors, or factors according
to recode specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rec(..., data = NULL, spec, as.factor = FALSE, levels = NULL, append = TRUE,
    name = ".e", as.na = NULL, table = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rec_+3A_...">...</code></td>
<td>
<p>a numeric vector, character vector, factor, matrix or data
frame. Alternatively, an expression indicating the variable
names in <code>data</code> e.g., <code>rec(x1, x2, x3, data = dat, spec = "1 = 0"))</code>.
Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="rec_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a a numeric vector, character vector, factor,
matrix or data frame for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="rec_+3A_spec">spec</code></td>
<td>
<p>a character string of recode specifications (see 'Details').</p>
</td></tr>
<tr><td><code id="rec_+3A_as.factor">as.factor</code></td>
<td>
<p>logical: if <code>TRUE</code>, character vector will be coerced to
a factor.</p>
</td></tr>
<tr><td><code id="rec_+3A_levels">levels</code></td>
<td>
<p>a character vector for specifying the levels in the returned
factor.</p>
</td></tr>
<tr><td><code id="rec_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="rec_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), centered variable(s) are
appended to the data frame specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="rec_+3A_name">name</code></td>
<td>
<p>a character string or character vector indicating the names
of the recoded variables. By default, variables are named with the ending
<code>".r"</code> Resulting in e.g. <code>"x1.r"</code> and <code>"x2.r"</code>. Variable
names can also be specified using a character vector matching
the number of variables specified in <code>...</code> (e.g.,
<code>name = c("recode.x1", "recode.x2")</code>).</p>
</td></tr>
<tr><td><code id="rec_+3A_table">table</code></td>
<td>
<p>logical: if <code>TRUE</code>, a cross table variable x recoded
variable is printed on the console if only one variable is
specified in <code>...</code>.</p>
</td></tr>
<tr><td><code id="rec_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recode specifications appear in a character string, separated by semicolons
(see the examples below), of the form input = output. If an input value satisfies
more than one specification, then the first (from left to right) applies. If
no specification is satisfied, then the input value is carried over to the
result. <code>NA</code> is allowed in input and output. Several recode specifications
are supported:
</p>

<dl>
<dt><strong>Single Value</strong></dt><dd><p>For example, <code>spec = "0 = NA".</code></p>
</dd>
<dt><strong>Vector of Values</strong></dt><dd><p>For example, <code>spec = "c(7, 8, 9) = 'high'"</code>.</p>
</dd>
<dt><strong>Range of Values</strong></dt><dd><p>For example, <code>spec = "7:9 = 'C'"</code>. The
special values <code>lo</code> (lowest value) and <code>hi</code> (highest value) may
appear in a range. For example, <code>spec = "lo:10 = 1"</code>. Note that <code>:</code>
is not the R sequence operator. In addition you may not use <code>:</code> with the
collect operator, e.g., <code>spec = "c(1, 3, 5:7)"</code> will cause an error.</p>
</dd>
<dt><strong>else</strong></dt><dd><p>For example, <code>spec = "0 = 1; else = NA"</code>. Everything
that does not fit a previous specification. Note that <code>else</code> matches all
otherwise unspecified values on input, including <code>NA</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a numeric vector or data frame with the same length or same number of
rows as <code>...</code> containing the recoded coded variable(s).
</p>


<h3>Note</h3>

<p>This function was adapted from the <code>recode()</code> function in the <span class="pkg">car</span>
package by John Fox and Sanford Weisberg (2019).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Fox, J., &amp; Weisberg S. (2019). <em>An R Companion to Applied Regression</em> (3rd ed.).
Thousand Oaks CA: Sage. URL: https://socialsciences.mcmaster.ca/jfox/Books/Companion/
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coding">coding</a></code>, <code><a href="#topic+item.reverse">item.reverse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#----------------------------------------------------------------------------
# Numeric vector
x.num &lt;- c(1, 2, 4, 5, 6, 8, 12, 15, 19, 20)

# Example 1a: Recode 5 = 50 and 19 = 190
rec(x.num, spec = "5 = 50; 19 = 190")

# Example 1b: Recode 1, 2, and 5 = 100 and 4, 6, and 7 = 200 and else = 300
rec(x.num, spec = "c(1, 2, 5) = 100; c(4, 6, 7) = 200; else = 300")

# Example 1c: Recode lowest value to 10 = 100 and 11 to highest value = 200
rec(x.num, spec = "lo:10 = 100; 11:hi = 200")

# Example 1d: Recode 5 = 50 and 19 = 190 and check recoding
rec(x.num, spec = "5 = 50; 19 = 190", table = TRUE)

#----------------------------------------------------------------------------
# Character vector
x.chr &lt;- c("a", "c", "f", "j", "k")

# Example 2a: Recode a to x
rec(x.chr, spec = "'a' = 'X'")

# Example 2b: Recode a and f to x, c and j to y, and else to z
rec(x.chr, spec = "c('a', 'f') = 'x'; c('c', 'j') = 'y'; else = 'z'")

# Example 2c: Recode a to x and coerce to a factor
rec(x.chr, spec = "'a' = 'X'", as.factor = TRUE)

#----------------------------------------------------------------------------
# Factor
x.fac &lt;- factor(c("a", "b", "a", "c", "d", "d", "b", "b", "a"))

# Example 3a: Recode a to x, factor levels ordered alphabetically
rec(x.fac, spec = "'a' = 'x'")

# Example 3b: Recode a to x, user-defined factor levels
rec(x.fac, spec = "'a' = 'x'", levels = c("x", "b", "c", "d"))

#----------------------------------------------------------------------------
# Multiple variables
dat &lt;- data.frame(x1.num = c(1, 2, 4, 5, 6),
                  x2.num = c(5, 19, 2, 6, 3),
                  x1.chr = c("a", "c", "f", "j", "k"),
                  x2.chr = c("b", "c", "a", "d", "k"),
                  x1.fac = factor(c("a", "b", "a", "c", "d")),
                  x2.fac = factor(c("b", "a", "d", "c", "e")))

# Example 4a: Recode numeric vector and attach to 'dat'
dat &lt;- cbind(dat, rec(dat[, c("x1.num", "x2.num")], spec = "5 = 50; 19 = 190"))

# Example 4b: Alternative specification using the 'data' argument,
rec(x1.num, x2.num, data = dat, spec = "5 = 50; 19 = 190")

# Example 4c: Recode character vector and attach to 'dat'
dat &lt;- cbind(dat, rec(dat[, c("x1.chr", "x2.chr")], spec = "'a' = 'X'"))

# Example 4d: Recode factor vector and attach to 'dat'
dat &lt;- cbind(dat, rec(dat[, c("x1.fac", "x2.fac")], spec = "'a' = 'X'"))
</code></pre>

<hr>
<h2 id='restart'>Restart R Session</h2><span id='topic+restart'></span>

<h3>Description</h3>

<p>This function restarts the RStudio session and is equivalent to using the menu
item <code>Session - Restart R</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>restart()
</code></pre>


<h3>Details</h3>

<p>The function call <code>executeCommand("restartR")</code> in the package <span class="pkg">rstudioapi</span>
is used to restart the R session. Note that the function <code>restartSession()</code>
in the package <span class="pkg">rstudioapi</span> is not equivalent to the menu item
<code>Session - Restart R</code> since it does not unload packages loaded during an
R session.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2022). rstudioapi: Safely
access the RStudio API. R package version 0.14.
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Restart the R Session
restart()

## End(Not run)
</code></pre>

<hr>
<h2 id='result.lca'>Summary Result Table and Grouped Bar Charts for Latent Class Analysis Estimated in Mplus</h2><span id='topic+result.lca'></span>

<h3>Description</h3>

<p>This function reads all Mplus output files from latent class analysis in
subfolders to create a summary result table and bar charts for each latent
class solution separately. By default, the function reads output files in all
subfolders of the current working directory. Optionally, bar charts for each
latent class solution can be requested by setting the argument <code>plot</code>
to <code>TRUE</code>. Note that subfolders with only one Mplus output file are
excluded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>result.lca(folder = getwd(), exclude = NULL, sort.n = TRUE, sort.p = TRUE,
           plot = FALSE, group.ind = TRUE, ci = TRUE, conf.level = 0.95, adjust = TRUE,
           axis.title = 7, axis.text = 7, levels = NULL, labels = NULL,
           ylim = NULL, ylab = "Mean Value", breaks = ggplot2::waiver(),
           error.width = 0.1, legend.title = 7, legend.text = 7, legend.key.size = 0.4,
           gray = FALSE, start = 0.15, end = 0.85, dpi = 600,
           width = "n.ind", height = 4, digits = 1, p.digits = 3,
           write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="result.lca_+3A_folder">folder</code></td>
<td>
<p>a character vector indicating the name of the subfolders
to be excluded from the summary result table.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_exclude">exclude</code></td>
<td>
<p>a character vector indicating the name of the subfolders
excluded from the result tables.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_sort.n">sort.n</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), result table is sorted
according to the number of classes within each folder.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_sort.p">sort.p</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), class proportions are
sorted decreasing.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar charts with
error bars for confidence intervals are saved
in the  folder <code>_Plots</code> within subfolders. Note
that plots are only available for LCA with continuous
or count indicator variables.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_group.ind">group.ind</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), latent class indicators
are represented by separate bars, if <code>FALSE</code> latent classes
are represented by separate bars.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_ci">ci</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), confidence intervals
are added to the bar charts.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment
for the confidence intervals is applied.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_axis.title">axis.title</code></td>
<td>
<p>a numeric value specifying the size of the axis title.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_axis.text">axis.text</code></td>
<td>
<p>a numeric value specifying the size of the axis text</p>
</td></tr>
<tr><td><code id="result.lca_+3A_levels">levels</code></td>
<td>
<p>a character string specifying the order of the indicator
variables shown on the x-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_labels">labels</code></td>
<td>
<p>a character string specifying the labels of the indicator
variables shown on the x-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
y-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the label of the y-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_error.width">error.width</code></td>
<td>
<p>a numeric vector specifying the width of the error bars.
By default, the width of the error bars is 0.1 plus
number of classes divided by 30.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_legend.title">legend.title</code></td>
<td>
<p>a numeric value specifying the size of the legend title.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_legend.text">legend.text</code></td>
<td>
<p>a numeric value specifying the size of the legend text.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_legend.key.size">legend.key.size</code></td>
<td>
<p>a numeric value specifying the size of the legend keys.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_gray">gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar charts are drawn in gray
scale.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_start">start</code></td>
<td>
<p>a numeric value between 0 and 1 specifying the gray value
at the low end of the palette.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_end">end</code></td>
<td>
<p>a numeric value between 0 and 1 specifying the gray value
at the high end of the palette.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_dpi">dpi</code></td>
<td>
<p>a numeric value specifying the plot resolution when saving
the bar chart.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_width">width</code></td>
<td>
<p>a numeric value specifying the width of the plot when
saving the bar chart. By default, the width is number of
indicators plus number of classes divided by 2.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_height">height</code></td>
<td>
<p>a numeric value specifying the height of the plot when
saving the bar chart.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that the scaling
correction factor is displayed  with <code>digits</code> plus 1
decimal places.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying <em>p</em>-values, entropy value,
and class proportions.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="result.lca_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The result summary table comprises following entries:
</p>

<ul>
<li><p><code>"Folder"</code>: Subfolder from which the group of Mplus outputs files
were summarized.
</p>
</li>
<li><p><code>"#Class"</code>: Number of classes (i.e., <code>CLASSES ARE c(#Class)</code>).
</p>
</li>
<li><p><code>"Conv"</code>: Model converged, <code>TRUE</code> or <code>FALSE</code> (i.e.,
<code>THE MODEL ESTIMATION TERMINATED NORMALLY</code>.
</p>
</li>
<li><p><code>"#Param"</code>: Number of estimated parameters (i.e.,
<code>Number of Free Parameters</code>).
</p>
</li>
<li><p><code>"logLik"</code>: Log-likelihood of the estimated model (i.e., <code>H0 Value</code>).
</p>
</li>
<li><p><code>"Scale"</code>: Scaling correction factor (i.e.,
<code>H0 Scaling Correction Factor for</code>). Provided
only when <code>ESTIMATOR IS MLR</code>.
</p>
</li>
<li><p><code>"LL Rep"</code>: Best log-likelihood replicated, <code>TRUE</code> or <code>FALSE</code>
(i.e., <code>THE BEST LOGLIKELIHOOD VALUE HAS BEEN REPLICATED</code>).
</p>
</li>
<li><p><code>"AIC"</code>: Akaike information criterion (i.e., <code>Akaike (AIC)</code>).
</p>
</li>
<li><p><code>"CAIC"</code>: Consistent AIC, not reported in the Mplus output, but
simply <code>BIC + #Param</code>.
</p>
</li>
<li><p><code>"BIC"</code>: Bayesian information criterion (i.e., <code>Bayesian (BIC)</code>).
</p>
</li>
<li><p><code>"Chi-Pear"</code>: Pearson chi-square test of model fit (i.e., <code>Pearson Chi-Square</code>),
only available when indicators are count or ordered categorical.
</p>
</li>
<li><p><code>"Chi-LRT"</code>: Likelihood ratio chi-square test of model fit (i.e., <code>Likelihood Ratio Chi-Square</code>),
only available when indicators are count or ordered catgeorical.
</p>
</li>
<li><p><code>"SABIC"</code>: Sample-size adjusted BIC (i.e., <code>Sample-Size Adjusted BIC</code>).
</p>
</li>
<li><p><code>"LMR-LRT"</code>: Significance value (<em>p</em>-value) of the Vuong-Lo-Mendell-Rubin test
(i.e., <code>VUONG-LO-MENDELL-RUBIN LIKELIHOOD RATIO TEST</code>).
Provided only when <code>OUTPUT: TECH11</code>.
</p>
</li>
<li><p><code>"A-LRT"</code>: Significance value (<em>p</em>-value) of the Adjusted Lo-Mendell-Rubin Test
(i.e., <code>LO-MENDELL-RUBIN ADJUSTED LRT TEST</code>).
Provided only when <code>OUTPUT: TECH11</code>.
</p>
</li>
<li><p><code>"BLRT"</code>: Significance value (<em>p</em>-value) of the bootstrapped
likelihood ratio test. Provided only when <code>OUTPUT: TECH14</code>.
</p>
</li>
<li><p><code>"Entropy"</code>: Sample-size adjusted BIC (i.e., <code>Entropy</code>).
</p>
</li>
<li><p><code>"p1"</code>: Class proportion of the first class based on the estimated
posterior probabilities (i.e., <code>FINAL CLASS COUNTS AND PROPORTIONS</code>).
</p>
</li>
<li><p><code>"p2"</code>: Class proportion of the second class based on the estimated
posterior probabilities (i.e., <code>FINAL CLASS COUNTS AND PROPORTIONS</code>).
</p>
</li></ul>



<h3>Value</h3>

<p>Returns an object, which is a list with following entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>output</code></td>
<td>
<p>list with all Mplus outputs</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>summary</code> for the
summary result table, <code>mean_var</code> for the result
table with means and variances for each latent class
separately, <code>mean</code> for the result table with means
for each latent class separately, and <code>var</code> for the
result table with variances for each latent class separately</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Masyn, K. E. (2013). Latent class analysis and finite mixture modeling. In T. D.
Little (Ed.), <em>The Oxford handbook of quantitative methods: Statistical analysis</em>
(pp. 551–611). Oxford University Press.
</p>
<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mplus.lca">mplus.lca</a></code>, <code><a href="#topic+run.mplus">run.mplus</a></code>, <code><a href="#topic+read.mplus">read.mplus</a></code>,
<code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

# Run LCA with k = 1 to k = 6 classes
mplus.lca(HolzingerSwineford1939, ind = c("x1", "x2", "x3", "x4"),
          run.mplus = TRUE)

# Example 1a: Read Mplus output files, create result table, write table, and save plots
result.lca(write = "LCA.xlsx", plot = TRUE)

# Example 1b: Write results into a text file
result.lca(write = "LCA.txt")

#-------------------------------------------------------------------------------
# Example 2: Draw bar chart manually

library(ggplot2)

# Collect LCA results
lca.result &lt;- result.lca()

# Result table with means
means &lt;- lca.result$result$mean

# Extract results from variance-covariance structure A with 4 latent classes
plotdat &lt;- means[means$folder == "A_Invariant-Theta_Diagonal-Sigma" &amp;  means$nclass == 4, ]

# Draw bar chart
ggplot(plotdat, aes(ind, est, group = class, fill = class)) +
  geom_bar(stat = "identity", position = "dodge", color = "black",
           linewidth = 0.1) +
  geom_errorbar(aes(ymin = low, ymax = upp), width = 0.23,
                linewidth = 0.2, position = position_dodge(0.9)) +
  scale_x_discrete("") +
  scale_y_continuous("Mean Value", limits = c(0, 9),
                     breaks = seq(0, 9, by = 1)) +
  labs(fill = "Latent Class") +
  guides(fill = guide_legend(nrow = 1L)) +
  theme(axis.title = element_text(size = 11),
        axis.text = element_text(size = 11),
        legend.position = "bottom",
        legend.key.size = unit(0.5 , 'cm'),
        legend.title = element_text(size = 11),
        legend.text = element_text(size = 11),
        legend.box.spacing = unit(-9L, "pt"))

# Save bar chart
ggsave("LCA_4-Class.png", dpi = 600, width = 6, height = 4)

## End(Not run)
</code></pre>

<hr>
<h2 id='robust.coef'>Unstandardized Coefficients with Heteroscedasticity-Consistent Standard Errors</h2><span id='topic+robust.coef'></span>

<h3>Description</h3>

<p>This function computes heteroscedasticity-consistent standard errors and
significance values for linear models estimated by using the <code>lm()</code>
function and generalized linear models estimated by using the <code>glm()</code>
function. For linear models the heteroscedasticity-robust F-test is computed
as well. By default the function uses the HC4 estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robust.coef(model, type = c("HC0", "HC1", "HC2", "HC3", "HC4", "HC4m", "HC5"),
            digits = 3, p.digits = 4, write = NULL, append = TRUE, check = TRUE,
            output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="robust.coef_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>lm</code> or <code>glm</code>.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_type">type</code></td>
<td>
<p>a character string specifying the estimation type, where
<code>"H0"</code> gives White's estimator and <code>"H1"</code> to
<code>"H5"</code> are refinement of this estimator. See help page
of the <code>vcovHC()</code> function in the R package <code>sandwich</code>
for more details.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results. Note that information
criteria and chi-square test statistic are printed with
<code>digits</code> minus 1 decimal places.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_write">write</code></td>
<td>
<p>a character string naming a file for writing the output into
either a text file with file extension <code>".txt"</code> (e.g.,
<code>"Output.txt"</code>) or Excel file with file extention
<code>".xlsx"</code>  (e.g., <code>"Output.xlsx"</code>). If the file
name does not contain any file extension, an Excel file will
be written.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="robust.coef_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The family of heteroscedasticity-consistent (HC) standard errors estimator for
the model parameters of a regression model is based on an HC covariance matrix
of the parameter estimates and does not require the assumption of homoscedasticity.
HC estimators approach the correct value with increasing sample size, even in
the presence of heteroscedasticity. On the other hand, the OLS standard error
estimator is biased and does not converge to the proper value when the assumption
of homoscedasticity is violated (Dalington &amp; Hayes, 2017).
</p>
<p>White (1980) introduced
the idea of HC covariance matrix to econometricians and derived the asymptotically
justified form of the HC covariance matrix known as HC0 (Long &amp; Ervin, 2000).
Simulation studies have shown that the HC0 estimator tends to underestimate the
true variance in small to moderately large samples (<code class="reqn">N \leq 250</code>) and in
the presence of leverage observations, which leads to an inflated
type I error risk (e.g., Cribari-Neto &amp; Lima, 2014). The alternative estimators
HC1 to HC5 are asymptotically equivalent to HC0 but include finite-sample corrections,
which results in superior small sample properties compared to the HC0 estimator.
Long and Ervin (2000) recommended routinely using the HC3 estimator regardless
of a heteroscedasticity test. However, the HC3 estimator can be unreliable when
the data contains leverage observations. The HC4 estimator, on
the other hand, performs well with small samples, in the presence of high leverage
observations, and when errors are not normally distributed (Cribari-Neto, 2004).
In summary, it appears that the HC4 estimator performs the best in terms of
controlling the type I and type II error risk (Rosopa, 2013). As opposed to the
findings of Cribari-Neto et al. (2007), the HC5 estimator did not show any
substantial advantages over HC4. Both HC5 and HC4 performed similarly across
all the simulation conditions considered in the study (Ng &amp; Wilcox, 2009).
</p>
<p>Note that the <em>F</em>-test of significance on the multiple correlation coefficient
<em>R</em> also assumes homoscedasticity of the errors. Violations of this assumption
can result in a hypothesis test that is either liberal or conservative, depending
on the form and severity of the heteroscedasticity.
</p>
<p>Hayes (2007) argued that using a HC estimator instead of assuming homoscedasticity
provides researchers with more confidence in the validity and statistical power
of inferential tests in regression analysis. Hence, the HC3 or HC4 estimator
should be used routinely when estimating regression models. If a HC estimator
is not used as the default method of standard error estimation, researchers are
advised to at least double-check the results by using an HC estimator to ensure
that conclusions are not compromised by heteroscedasticity. However, the presence
of heteroscedasticity suggests that the data is not adequately explained by
the statistical model of estimated conditional means. Unless heteroscedasticity
is believed to be solely caused by measurement error associated with the predictor
variable(s), it should serve as warning to the researcher regarding the adequacy
of the estimated model.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in <code>model</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with results, i.e., <code>coef</code> for the unstandardized
regression coefficients with heteroscedasticity-consistent standard errors,
<code>F.test</code> for the heteroscedasticity-robust F-Test, and <code>sandwich</code>
for the sandwich covariance matrix</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is based on the <code>vcovHC</code> function from the <code>sandwich</code>
package (Zeileis, Köll, &amp; Graham, 2020) and the functions <code>coeftest</code> and
<code>waldtest</code> from the <code>lmtest</code> package (Zeileis &amp; Hothorn, 2002).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Darlington, R. B., &amp; Hayes, A. F. (2017). <em>Regression analysis and linear
models: Concepts, applications, and implementation</em>. The Guilford Press.
</p>
<p>Cribari-Neto, F. (2004). Asymptotic inference under heteroskedasticity of unknown
form. <em>Computational Statistics &amp; Data Analysis, 45</em>, 215-233.
https://doi.org/10.1016/S0167-9473(02)00366-3
</p>
<p>Cribari-Neto, F., &amp; Lima, M. G. (2014). New heteroskedasticity-robust standard
errors for the linear regression model. <em>Brazilian Journal of Probability and Statistics, 28</em>,
83-95.
</p>
<p>Cribari-Neto, F., Souza, T., &amp; Vasconcellos, K. L. P. (2007). Inference under
heteroskedasticity and leveraged data. <em>Communications in Statistics - Theory and Methods, 36</em>,
1877-1888. https://doi.org/10.1080/03610920601126589
</p>
<p>Hayes, A.F, &amp; Cai, L. (2007). Using heteroscedasticity-consistent standard error
estimators in OLS regression: An introduction and software implementation.
<em>Behavior Research Methods, 39</em>, 709-722. https://doi.org/10.3758/BF03192961
</p>
<p>Long, J.S., &amp; Ervin, L.H. (2000). Using heteroscedasticity consistent standard
errors in the linear regression model. <em>The American Statistician, 54</em>,
217-224. https://doi.org/10.1080/00031305.2000.10474549
</p>
<p>Ng, M., &amp; Wilcoy, R. R. (2009). Level robust methods based on the least squares
regression estimator. <em>Journal of Modern Applied Statistical Methods, 8</em>,
284-395. https://doi.org/10.22237/jmasm/1257033840
</p>
<p>Rosopa, P. J., Schaffer, M. M., &amp; Schroeder, A. N. (2013). Managing heteroscedasticity
in general linear models. <em>Psychological Methods, 18</em>(3), 335-351.
https://doi.org/10.1037/a0032553
</p>
<p>White, H. (1980). A heteroskedastic-consistent covariance matrix estimator and
a direct test of heteroskedasticity. <em>Econometrica, 48</em>, 817-838.
https://doi.org/10.2307/1912934
</p>
<p>Zeileis, A., &amp; Hothorn, T. (2002). Diagnostic checking in regression relationships.
<em>R News, 2</em>(3), 7–10. http://CRAN.R-project.org/doc/Rnews/
</p>
<p>Zeileis A, Köll S, &amp; Graham N (2020). Various versatile variances: An
object-oriented implementation of clustered covariances in R.
<em>Journal of Statistical Software, 95</em>(1), 1-36.
https://doi.org/10.18637/jss.v095.i01
</p>


<h3>See Also</h3>

<p><code><a href="#topic+std.coef">std.coef</a></code>, <code><a href="#topic+write.result">write.result</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(x1 = c(3, 2, 4, 9, 5, 3, 6, 4, 5, 6, 3, 5),
                  x2 = c(1, 4, 3, 1, 2, 4, 3, 5, 1, 7, 8, 7),
                  x3 = c(0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1),
                  y1 = c(2, 7, 4, 4, 7, 8, 4, 2, 5, 1, 3, 8),
                  y2 = c(0, 1, 0, 2, 0, 1, 0, 0, 1, 2, 1, 0))

#-------------------------------------------------------------------------------
# Example 1: Linear model

mod1 &lt;- lm(y1 ~ x1 + x2 + x3, data = dat)
robust.coef(mod1)

#-------------------------------------------------------------------------------
# Example 2: Generalized linear model

mod2 &lt;- glm(y2 ~ x1 + x2 + x3, data = dat, family = poisson())
robust.coef(mod2)

## Not run: 
#----------------------------------------------------------------------------
# Write Results

# Example 3a: Write Results into a text file
robust.coef(mod1, write = "Robust_Coef.txt", output = FALSE)

# Example 3b: Write Results into an Excel file
robust.coef(mod1, write = "Robust_Coef.xlsx", output = FALSE)

result &lt;- robust.coef(mod1, output = FALSE)
write.result(result, "Robust_Coef.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='run.mplus'>Run Mplus Models</h2><span id='topic+run.mplus'></span>

<h3>Description</h3>

<p>This function runs a group of Mplus models (<code>.inp</code> files) located within
a single directory or nested within subdirectories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run.mplus(target = getwd(), recursive = FALSE, filefilter = NULL, showOutput = FALSE,
          replaceOutfile = c("always", "never", "modifiedDate"), logFile = NULL,
          Mplus = "Mplus", killOnFail = TRUE, local_tmpdir = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="run.mplus_+3A_target">target</code></td>
<td>
<p>a character string indicating the directory containing
Mplus input files (<code>.inp</code>)
to run or the single <code>.inp</code> file to be run. May be
a full path, relative path, or a filename within the working
directory.</p>
</td></tr>
<tr><td><code id="run.mplus_+3A_recursive">recursive</code></td>
<td>
<p>logical: if <code>TRUE</code>, run all models nested in subdirectories
within directory. Not relevant if target is a single file.</p>
</td></tr>
<tr><td><code id="run.mplus_+3A_filefilter">filefilter</code></td>
<td>
<p>a Perl regular expression (PCRE-compatible) specifying particular
input files to be run within directory. See regex or
http://www.pcre.org/pcre.txt for details about regular
expression syntax. Not relevant if target is a single file.</p>
</td></tr>
<tr><td><code id="run.mplus_+3A_showoutput">showOutput</code></td>
<td>
<p>logical: if <code>TRUE</code>, estimation output (<code>TECH8</code>)
is show on the R console. Note that if run within Rgui,
output will display within R, but if run via Rterm,
a separate window will appear during estimation.</p>
</td></tr>
<tr><td><code id="run.mplus_+3A_replaceoutfile">replaceOutfile</code></td>
<td>
<p>a character string for specifying three settings:
<code>"always"</code> (default), which runs all models, regardless
of whether an output file for the model exists, <code>"never"</code>,
which does not run any model that has an existing output file,
and <code>"modifiedDate"</code>, which only runs a model if the
modified date for the input file is more recent than the
output file modified date.</p>
</td></tr>
<tr><td><code id="run.mplus_+3A_logfile">logFile</code></td>
<td>
<p>a character string specifying a file that records the settings
passed into the function and the models run (or skipped)
during the run.</p>
</td></tr>
<tr><td><code id="run.mplus_+3A_mplus">Mplus</code></td>
<td>
<p>a character string for specifying the name or path of the
Mplus executable to be used for running models. This covers
situations where Mplus is not in the system's path, or where
one wants to test different versions of the Mplus program.
Note that there is no need to specify this argument for most
users since it has intelligent defaults.</p>
</td></tr>
<tr><td><code id="run.mplus_+3A_killonfail">killOnFail</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), all processes named mplus.exe when
<code>mplus.run()</code> does not terminate normally are killed.
Windows only.</p>
</td></tr>
<tr><td><code id="run.mplus_+3A_local_tmpdir">local_tmpdir</code></td>
<td>
<p>logical: if <code>TRUE</code>, the TMPDIR environment variable
is set to the location of the <code>.inp file</code> prior to
execution. This is useful in Monte Carlo studies where many
instances of Mplus may run in parallel and we wish to avoid
collisions in temporary files among processes. Linux/Mac only.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Note</h3>

<p>This function is a copy of the <code>runModels()</code> function in the
<span class="pkg">MplusAutomation</span> package by Michael Hallquist and Joshua Wiley (2018).
</p>


<h3>Author(s)</h3>

<p>Michael Hallquist
</p>


<h3>References</h3>

<p>Hallquist, M. N. &amp; Wiley, J. F. (2018). MplusAutomation: An R package for facilitating
large-scale latent variable analyses in Mplus. <em>Structural Equation Modeling:
A Multidisciplinary Journal, 25</em>, 621-638. https://doi.org/10.1080/10705511.2017.1402334.
</p>
<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Run Mplus models located within a single directory
run.mplus(Mplus = "C:/Program Files/Mplus/Mplus.exe")

# Example 2: Run Mplus models located nested within subdirectories
run.mplus(recursive = TRUE,
          Mplus = "C:/Program Files/Mplus/Mplus.exe")

## End(Not run)
</code></pre>

<hr>
<h2 id='rwg.lindell'>Lindell, Brandt and Whitney (1999) r*wg(j) Within-Group Agreement Index for
Multi-Item Scales</h2><span id='topic+rwg.lindell'></span>

<h3>Description</h3>

<p>This function computes r*wg(j) within-group agreement index for multi-item scales
as described in Lindell, Brandt and Whitney (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rwg.lindell(..., data = NULL, cluster, A = NULL, ranvar = NULL, z = TRUE,
            expand = TRUE, na.omit = FALSE, append = TRUE, name = "rwg",
            as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rwg.lindell_+3A_...">...</code></td>
<td>
<p>a numeric vector or data frame. Alternatively, an expression
indicating the variable names in <code>data</code> e.g.,
<code>rwg.lindell(x1, x2, x3, data = dat)</code>. Note that the operators
<code>.</code>, <code>+</code>, <code>-</code>, <code>~</code>, <code>:</code>, <code>::</code>,
and <code>!</code> can also be used to select variables, see 'Details'
in the <code><a href="#topic+df.subset">df.subset</a></code> function.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_data">data</code></td>
<td>
<p>a data frame when specifying one or more variables in the
argument <code>...</code>. Note that the argument is <code>NULL</code>
when specifying a numeric vector or data frame for the argument
<code>...</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_cluster">cluster</code></td>
<td>
<p>either a character string indicating the variable name of
the cluster variable in <code>...</code> or <code>data</code>, or a
vector representing the nested grouping structure (i.e.,
group or cluster variable).</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_a">A</code></td>
<td>
<p>a numeric value indicating the number of discrete response
options of the items from which the random variance is computed
based on <code class="reqn">(A^2 - 1) / 12</code>. Note that either the argument
<code>j</code> or the argument<code>ranvar</code> is specified.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_ranvar">ranvar</code></td>
<td>
<p>a numeric value indicating the random variance to which the
mean of the item variance is divided. Note that either the
argument <code>j</code> or the argument<code>ranvar</code> is specified.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_z">z</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Fisher z-transformation based on the
formula <code class="reqn">z = 0.5*log((1 + r) / (1 - r))</code> is applied to
the vector of r*wg(j) estimates.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_expand">expand</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), vector of r*wg(j) estimates is expanded
to match the input vector <code>x</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_na.omit">na.omit</code></td>
<td>
<p>logical: if <code>TRUE</code>, incomplete cases are removed before
conducting the analysis (i.e., listwise deletion).</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default),  a variable with the r*wg(j)
within-group agreement index are appended to the data frame
specified in the argument <code>data</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_name">name</code></td>
<td>
<p>a character string indicating the name of the variable appended
to the data frame specified in the arguement <code>data</code> when
<code>append = TRUE</code>. By default, the variable is named <code>rwg</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis. Note that <code>as.na()</code> function is only applied to
<code>x</code>, but not to <code>cluster</code>.</p>
</td></tr>
<tr><td><code id="rwg.lindell_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The r*wg(j) index is calculated by dividing the mean of the item variance by
the expected random variance (i.e., null distribution). The default null distribution
in most research is the rectangular or uniform distribution calculated with
<code class="reqn">\sigma^2_eu = (A^2 - 1) / 12</code>, where <code class="reqn">A</code> is the number of discrete response
options of the items. However, what constitutes a reasonable standard for random
variance is highly debated. Note that the r*wg(j) allows that the mean of the
item variances to be larger than the expected random variances, i.e., r*wg(j)
values can be negative.
</p>
<p>Note that the <code>rwg.j.lindell()</code> function in the <span class="pkg">multilevel</span> package
uses listwise deletion by default, while the <code>rwg.lindell()</code> function uses
all available information to compute the r*wg(j) agreement index by default. In
order to obtain equivalent results in the presence of missing values, listwise
deletion (<code>na.omit = TRUE</code>) needs to be applied.
</p>
<p>Examples for the application of r*wg(j) within-group agreement index for multi-item
scales can be found in Bardach, Yanagida, Schober and Lueftenegger (2018),
Bardach, Lueftenegger, Yanagida, Schober and Spiel (2018), and Bardach, Lueftenegger,
Yanagida, Spiel and Schober (2019).
</p>


<h3>Value</h3>

<p>Returns a numeric vector containing r*wg(j) agreement index for multi-item scales
with the same length as <code>group</code> if <code>expand = TRUE</code> or a data frame with
following entries if <code>expand = FALSE</code>:
</p>
<table>
<tr><td><code>cluster</code></td>
<td>
<p>cluster identifier</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>cluster size</p>
</td></tr>
<tr><td><code>rwg.lindell</code></td>
<td>
<p>r*wg(j) estimate for each group</p>
</td></tr>
<tr><td><code>z.rwg.lindell</code></td>
<td>
<p>Fisher z-transformed r*wg(j) estimate for each cluster</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Bardach, L., Lueftenegger, M., Yanagida, T., &amp; Schober, B. (2019). Achievement
or agreement - Which comes first? Clarifying the temporal ordering of achievement
and within-class consensus on classroom goal structures. <em>Learning and Instruction,
61</em>, 72-83. https://doi.org/10.1016/j.learninstruc.2019.01.003
</p>
<p>Bardach, L., Lueftenegger, M., Yanagida, T., Schober, B. &amp; Spiel, C. (2019).
The role of within-class consensus on mastery goal structures in predicting
socio-emotional outcomes. <em>British Journal of Educational Psychology, 89</em>,
239-258. https://doi.org/10.1111/bjep.12237
</p>
<p>Bardach, L., Yanagida, T., Schober, B. &amp; Lueftenegger, M. (2018). Within-class
consensus on classroom goal structures: Relations to achievement and achievement
goals in mathematics and language classes. <em>Learning and Individual Differences,
67</em>, 78-90. https://doi.org/10.1016/j.lindif.2018.07.002
</p>
<p>Lindell, M. K., Brandt, C. J., &amp; Whitney, D. J. (1999). A revised index of interrater
agreement for multi-item ratings of a single target. <em>Applied Psychological
Measurement</em>, <em>23</em>, 127-135. https://doi.org/10.1177/01466219922031257
</p>
<p>O'Neill, T. A. (2017). An overview of interrater agreement on Likert scales for
researchers and practitioners. <em>Frontiers in Psychology</em>, <em>8</em>, Article
777. https://doi.org/10.3389/fpsyg.2017.00777
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cluster.scores">cluster.scores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(id = c(1, 2, 3, 4, 5, 6, 7, 8, 9),
                  cluster = c(1, 1, 1, 2, 2, 2, 3, 3, 3),
                  x1 = c(2, 3, 2, 1, 1, 2, 4, 3, 5),
                  x2 = c(3, 2, 2, 1, 2, 1, 3, 2, 5),
                  x3 = c(3, 1, 1, 2, 3, 3, 5, 5, 4))

# Example 1a: Compute Fisher z-transformed r*wg(j) for a multi-item scale
# with A = 5 response options
rwg.lindell(dat[, c("x1", "x2", "x3")], cluster = dat$cluster, A = 5)

# Example 1b: Alternative specification using the 'data' argument,
rwg.lindell(x1:x3, data = dat, cluster = "cluster", A = 5)
# Example 2: Compute Fisher z-transformed r*wg(j) for a multi-item scale with a random variance of 2
rwg.lindell(dat[, c("x1", "x2", "x3")], cluster = dat$cluster, ranvar = 2)

# Example 3: Compute r*wg(j) for a multi-item scale with A = 5 response options
rwg.lindell(dat[, c("x1", "x2", "x3")], cluster = dat$cluster, A = 5, z = FALSE)

# Example 4: Compute Fisher z-transformed r*wg(j) for a multi-item scale
# with A = 5 response options, do not expand the vector
rwg.lindell(dat[, c("x1", "x2", "x3")], cluster = dat$cluster, A = 5, expand = FALSE)
</code></pre>

<hr>
<h2 id='script.copy'>Save Copy of the Current Script in RStudio</h2><span id='topic+script.copy'></span>

<h3>Description</h3>

<p>This function saves a copy of the current script in RStudio. By default, a
folder callled <code>_R_Script_Archive</code> will be created to save the copy of
the current R script with the current date and time into the folder. Note that
the current R script needs to have a file location before the script can be
copied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>script.copy(file = NULL, folder = "_R_Script_Archive", create.folder = TRUE,
            time = TRUE, format = "%Y-%m-%d_%H%M", overwrite = TRUE,
            check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="script.copy_+3A_file">file</code></td>
<td>
<p>a character string naming the file of the copy without
the file extension <code>".R"</code>. By default, the file of
the copy has the same name as the original file.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_folder">folder</code></td>
<td>
<p>a character string naming the folder in which the file
of the copy is saved. If <code>NULL</code>, the file of the
copy is saved in the same folder as the original file.
By default, the file of the copy is saved into a folder
called <code>"_R_Script_Archive"</code>.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_create.folder">create.folder</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), folder(s) specified in
the <code>file</code> argument is created. If <code>FALSE</code> and
the folder does not exist, then a error message is printed
on the console.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_time">time</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the current time is
attached to the name of the file specified in the argument
<code>file</code>.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_format">format</code></td>
<td>
<p>a character string indicating the format if the <code>POSIXct</code>
class resulting from the <code>Sys.time</code> function. The default
setting provides a character string indicating the year, month, day, minutes, and seconds. See the help page of the <code><a href="base.html#topic+format.POSIXct">format.POSIXct</a></code> function.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_overwrite">overwrite</code></td>
<td>
<p>logical: if <code>TRUE</code> (default) an existing destination
file is overwritten.</p>
</td></tr>
<tr><td><code id="script.copy_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is
checked.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses the <code>getSourceEditorContext()</code> function in the
<span class="pkg">rstudioapi</span> package by Kevin Ushey, JJ Allaire, Hadley Wickham, and Gary
Ritchie (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2023). <em>rstudioapi: Safely
access the RStudio API</em>. R package version 0.15.0
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>See Also</h3>

<p><code><a href="#topic+script.new">script.new</a></code>, <code><a href="#topic+script.close">script.close</a></code>, <code><a href="#topic+script.open">script.open</a></code>, <code><a href="#topic+script.save">script.save</a></code>, <code><a href="#topic+setsource">setsource</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Save copy current R script into the folder '_R_Script_Archive'
script.copy()

# Exmample 2: Save current R script as 'R_Script.R' into the folder 'Archive'
script.copy("R_Script", folder = "Archive", time = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='script.new'>Open new R Script, R Markdown script, or SQL Script in RStudio</h2><span id='topic+script.new'></span>

<h3>Description</h3>

<p>This function opens a new R script, R markdown script, or SQL script
in RStudio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>script.new(text = "", type = c("r", "rmarkdown", "sql"),
           position = rstudioapi::document_position(0, 0),
           run = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="script.new_+3A_text">text</code></td>
<td>
<p>a character vector indicating what text should be inserted in
the new R script. By default, an empty script is opened.</p>
</td></tr>
<tr><td><code id="script.new_+3A_type">type</code></td>
<td>
<p>a character string indicating the type of document to be
created, i.e., <code>r</code> (default) for an R script, <code>rmakrdown</code>
for an R Markdown file, or <code>sql</code> for an SQL script.</p>
</td></tr>
<tr><td><code id="script.new_+3A_position">position</code></td>
<td>
<p><code>document_position()</code> function in the <span class="pkg">rstudioapi</span>
package indicating the cursor position.</p>
</td></tr>
<tr><td><code id="script.new_+3A_run">run</code></td>
<td>
<p>logical: if <code>TRUE</code>, the code is executed after the document
is created.</p>
</td></tr>
<tr><td><code id="script.new_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses the <code>documentNew()</code> function in the <span class="pkg">rstudioapi</span>
package by Kevin Ushey, JJ Allaire, Hadley Wickham, and Gary Ritchie (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2023). <em>rstudioapi:
Safely access the RStudio API</em>. R package version 0.15.0
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>See Also</h3>

<p><code><a href="#topic+script.close">script.close</a></code>, <code><a href="#topic+script.open">script.open</a></code>,
<code><a href="#topic+script.save">script.save</a></code>, <code><a href="#topic+script.copy">script.copy</a></code>, <code><a href="#topic+setsource">setsource</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Open new R script file
script.new()

# Example 2: Open new R script file and run some code
script.new("#----------------------------
# Example

# Generate 100 random numbers
rnorm(100)")

## End(Not run)
</code></pre>

<hr>
<h2 id='script.open'>Open, Close and Save R Script in RStudio</h2><span id='topic+script.open'></span><span id='topic+script.close'></span><span id='topic+script.save'></span>

<h3>Description</h3>

<p>The function <code>script.open</code> opens an R script, R markdown script, or SQL
script in RStudio, the function <code>script.close</code> closes an R script, and
the function <code>script.save</code> saves an R script. Note that the R script need
to have a file location before the script can be saved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>script.open(path, line = 1, col = 1, cursor = TRUE, run = FALSE,
            echo = TRUE, max.length = 999, spaced = TRUE, check = TRUE)

script.close(save = FALSE, check = TRUE)

script.save(all = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="script.open_+3A_path">path</code></td>
<td>
<p>a character string indicating the path of the script.</p>
</td></tr>
<tr><td><code id="script.open_+3A_line">line</code></td>
<td>
<p>a numeric value indicating the line in the script to navigate
to.</p>
</td></tr>
<tr><td><code id="script.open_+3A_col">col</code></td>
<td>
<p>a numeric value indicating the column in the script to
navigate to.</p>
</td></tr>
<tr><td><code id="script.open_+3A_cursor">cursor</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the cursor moves to the
requested location after opening the document.</p>
</td></tr>
<tr><td><code id="script.open_+3A_run">run</code></td>
<td>
<p>logical: if <code>TRUE</code>, the code is executed after the
document is opened</p>
</td></tr>
<tr><td><code id="script.open_+3A_echo">echo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), each expression is printed after
parsing, before evaluation.</p>
</td></tr>
<tr><td><code id="script.open_+3A_max.length">max.length</code></td>
<td>
<p>a numeric value indicating the maximal number of characters
output for the deparse of a single expression.</p>
</td></tr>
<tr><td><code id="script.open_+3A_spaced">spaced</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), empty line is printed before each
expression.</p>
</td></tr>
<tr><td><code id="script.open_+3A_save">save</code></td>
<td>
<p>logical: if <code>TRUE</code>, the script is saved before closing
when using the function <code>script.close</code>.</p>
</td></tr>
<tr><td><code id="script.open_+3A_all">all</code></td>
<td>
<p>logical: if <code>TRUE</code>, all scripts opened in RStudio are
saved when using the function <code>script.save</code>.</p>
</td></tr>
<tr><td><code id="script.open_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses the <code>documentOpen()</code>, <code>documentPath()</code>,
<code>documentClose()</code>, <code>documentSave()</code>, and <code>documentSaveAll()</code>
functions in the <span class="pkg">rstudioapi</span> package by Kevin Ushey,  JJ Allaire, Hadley
Wickham, and Gary Ritchie (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2023). <em>rstudioapi: Safely
access the RStudio API</em>. R package version 0.15.0
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>See Also</h3>

<p><code><a href="#topic+script.save">script.save</a></code>, <code><a href="#topic+script.copy">script.copy</a></code>, <code><a href="#topic+setsource">setsource</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Open  R script file
script.open("script.R")

# Example 2: Open  R script file and run the code
script.open("script.R", run = TRUE)

# Example 3: Close current R script file
script.close()

# Example 4: Save current R script
script.save()

# Example 5: Save all R scripts
script.save(all = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='setsource'>Set Working Directory to the Source File Location</h2><span id='topic+setsource'></span>

<h3>Description</h3>

<p>This function sets the working directory to the source file location
(i.e., path of the current R script) in RStudio and is equivalent to using the
menu item <code>Session - Set Working Directory - To Source File Location</code>.
Note that the R script needs to have a file location before this function can
be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setsource(path = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setsource_+3A_path">path</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), the path of the source file is
shown on the console.</p>
</td></tr>
<tr><td><code id="setsource_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the path of the source file location.
</p>


<h3>Note</h3>

<p>This function uses the <code>documentPath()</code> function in the
<span class="pkg">rstudioapi</span> package by Kevin Ushey, JJ Allaire, Hadley Wickham, and Gary
Ritchie (2023).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Ushey, K., Allaire, J., Wickham, H., &amp; Ritchie, G. (2023). <em>rstudioapi: Safely
access the RStudio API</em>. R package version 0.15.0
https://CRAN.R-project.org/package=rstudioapi
</p>


<h3>See Also</h3>

<p><code><a href="#topic+script.close">script.close</a></code>, <code><a href="#topic+script.new">script.new</a></code>, <code><a href="#topic+script.open">script.open</a></code>,
<code><a href="#topic+script.save">script.save</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Set working directory to the source file location
setsource()

# Example 2: Set working directory to the source file location
# and assign path to an object
path &lt;- setsource()
path

## End(Not run)
</code></pre>

<hr>
<h2 id='size.cor'>Sample Size Determination for Testing Pearson's Correlation Coefficient</h2><span id='topic+size.cor'></span>

<h3>Description</h3>

<p>This function performs sample size computation for testing Pearson's product-moment correlation coefficient
based on precision requirements (i.e., type-I-risk, type-II-risk and an effect size).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size.cor(rho, delta, alternative = c("two.sided", "less", "greater"),
         alpha = 0.05, beta = 0.1, write = NULL, append = TRUE,
         check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="size.cor_+3A_rho">rho</code></td>
<td>
<p>a number indicating the correlation coefficient under the null hypothesis, <code class="reqn">\rho</code>.0.</p>
</td></tr>
<tr><td><code id="size.cor_+3A_delta">delta</code></td>
<td>
<p>a numeric value indicating the minimum difference to be detected, <code class="reqn">\delta</code>.</p>
</td></tr>
<tr><td><code id="size.cor_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="size.cor_+3A_alpha">alpha</code></td>
<td>
<p>type-I-risk, <code class="reqn">\alpha</code>.</p>
</td></tr>
<tr><td><code id="size.cor_+3A_beta">beta</code></td>
<td>
<p>type-II-risk, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="size.cor_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="size.cor_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="size.cor_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="size.cor_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with the result, i.e., optimal sample size</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>,
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology - Using R and SPSS</em>.
New York: John Wiley &amp; Sons.
</p>
<p>Rasch, D., Pilz, J., Verdooren, L. R., &amp; Gebhardt, G. (2011).
<em>Optimal experimental design with R</em>. Boca Raton: Chapman &amp; Hall/CRC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+size.mean">size.mean</a></code>, <code><a href="#topic+size.prop">size.prop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------------------
# Example 1: Two-sided test
# H0: rho = 0.3, H1: rho != 0.3
# alpha = 0.05, beta = 0.2, delta = 0.2

size.cor(rho = 0.3, delta = 0.2, alpha = 0.05, beta = 0.2)

#-------------------------------------------------------------------------------
# Example 2: One-sided test
# H0: rho &lt;= 0.3, H1: rho &gt; 0.3
# alpha = 0.05, beta = 0.2, delta = 0.2

size.cor(rho = 0.3, delta = 0.2, alternative = "greater", alpha = 0.05, beta = 0.2)</code></pre>

<hr>
<h2 id='size.mean'>Sample Size Determination for Testing Arithmetic Means</h2><span id='topic+size.mean'></span>

<h3>Description</h3>

<p>This function performs sample size computation for the one-sample and two-sample t-test
based on precision requirements (i.e., type-I-risk, type-II-risk and an effect size).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size.mean(delta, sample = c("two.sample", "one.sample"),
          alternative = c("two.sided", "less", "greater"),
          alpha = 0.05, beta = 0.1, write = NULL, append = TRUE,
          check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="size.mean_+3A_delta">delta</code></td>
<td>
<p>a numeric value indicating the relative minimum difference
to be detected, <code class="reqn">\delta</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_sample">sample</code></td>
<td>
<p>a character string specifying one- or two-sample t-test,
must be one of <code>"two.sample"</code> (default) or <code>"one.sample"</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_alpha">alpha</code></td>
<td>
<p>type-I-risk, <code class="reqn">\alpha</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_beta">beta</code></td>
<td>
<p>type-II-risk, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="size.mean_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with the result, i.e., optimal sample size</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>,
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology - Using R and SPSS</em>.
New York: John Wiley &amp; Sons.
</p>
<p>Rasch, D., Pilz, J., Verdooren, L. R., &amp; Gebhardt, G. (2011).
<em>Optimal experimental design with R</em>. Boca Raton: Chapman &amp; Hall/CRC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+size.prop">size.prop</a></code>, <code><a href="#topic+size.cor">size.cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------------------
# Example 1: Two-sided one-sample test
# H0: mu = mu.0, H1: mu != mu.0
# alpha = 0.05, beta = 0.2, delta = 0.5

size.mean(delta = 0.5, sample = "one.sample",
          alternative = "two.sided", alpha = 0.05, beta = 0.2)

#-------------------------------------------------------------------------------
# Example 2: One-sided one-sample test
# H0: mu &lt;= mu.0, H1: mu &gt; mu.0
# alpha = 0.05, beta = 0.2, delta = 0.5

size.mean(delta = 0.5, sample = "one.sample",
          alternative = "greater", alpha = 0.05, beta = 0.2)

#-------------------------------------------------------------------------------
# Example 3: Two-sided two-sample test
# H0: mu.1 = mu.2, H1: mu.1 != mu.2
# alpha = 0.01, beta = 0.1, delta = 1

size.mean(delta = 1, sample = "two.sample",
          alternative = "two.sided", alpha = 0.01, beta = 0.1)

#-------------------------------------------------------------------------------
# Example 4: One-sided two-sample test
# H0: mu.1 &lt;= mu.2, H1: mu.1 &gt; mu.2
# alpha = 0.01, beta = 0.1, delta = 1

size.mean(delta = 1, sample = "two.sample",
          alternative = "greater", alpha = 0.01, beta = 0.1)
</code></pre>

<hr>
<h2 id='size.prop'>Sample Size Determination for Testing Proportions</h2><span id='topic+size.prop'></span>

<h3>Description</h3>

<p>This function performs sample size computation for the one-sample and two-sample test for proportions
based on precision requirements (i.e., type-I-risk, type-II-risk and an effect size).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size.prop(pi = 0.5, delta, sample = c("two.sample", "one.sample"),
          alternative = c("two.sided", "less", "greater"),
          alpha = 0.05, beta = 0.1, correct = FALSE,
          write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="size.prop_+3A_pi">pi</code></td>
<td>
<p>a number indicating the true value of the probability under the null hypothesis (one-sample test), <code class="reqn">\pi</code>.0
or a number indicating the true value of the probability in group 1 (two-sample test), <code class="reqn">\pi</code>.1.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_delta">delta</code></td>
<td>
<p>minimum difference to be detected, <code class="reqn">\delta</code>.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_sample">sample</code></td>
<td>
<p>a character string specifying one- or two-sample proportion test,
must be one of <code>"two.sample"</code> (default) or <code>"one.sample"</code>.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"less"</code> or <code>"greater"</code>.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_alpha">alpha</code></td>
<td>
<p>type-I-risk, <code class="reqn">\alpha</code>.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_beta">beta</code></td>
<td>
<p>type-II-risk, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_correct">correct</code></td>
<td>
<p>a logical indicating whether continuity correction should be applied.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="size.prop_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>x</code></p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with the result, i.e., optimal sample size</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>,
</p>


<h3>References</h3>

<p>Fleiss, J. L., Levin, B., &amp; Paik, M. C. (2003). <em>Statistical methods for rates and proportions</em> (3rd ed.).
John Wiley &amp; Sons.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology - Using R and SPSS</em>.
John Wiley &amp; Sons.
</p>
<p>Rasch, D., Pilz, J., Verdooren, L. R., &amp; Gebhardt, G. (2011).
<em>Optimal experimental design with R</em>. Chapman &amp; Hall/CRC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+size.mean">size.mean</a></code>, <code><a href="#topic+size.cor">size.cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------------------
# Example 1: Two-sided one-sample test
# H0: pi = 0.5, H1: pi != 0.5
# alpha = 0.05, beta = 0.2, delta = 0.2

size.prop(pi = 0.5, delta = 0.2, sample = "one.sample",
          alternative = "two.sided", alpha = 0.05, beta = 0.2)

#-------------------------------------------------------------------------------
# Example 2: Two-sided one-sample test
# H0: pi = 0.5, H1: pi != 0.5
# alpha = 0.05, beta = 0.2, delta = 0.2
# with continuity correction

size.prop(pi = 0.5, delta = 0.2, sample = "one.sample",
          alternative = "two.sided", alpha = 0.05, beta = 0.2,
          correct = TRUE)

#-------------------------------------------------------------------------------
# Example 3: One-sided one-sample test
# H0: pi &lt;= 0.5, H1: pi &gt; 0.5
# alpha = 0.05, beta = 0.2, delta = 0.2

size.prop(pi = 0.5, delta = 0.2, sample = "one.sample",
          alternative = "less", alpha = 0.05, beta = 0.2)

#-------------------------------------------------------------------------------
# Example 4: Two-sided two-sample test
# H0: pi.1 = pi.2 = 0.5, H1: pi.1 != pi.2
# alpha = 0.01, beta = 0.1, delta = 0.2

size.prop(pi = 0.5, delta = 0.2, sample = "two.sample",
          alternative = "two.sided", alpha = 0.01, beta = 0.1)

#-------------------------------------------------------------------------------
# Example 5: One-sided two-sample test
# H0: pi.1 &lt;=  pi.1 = 0.5, H1: pi.1 &gt; pi.2
# alpha = 0.01, beta = 0.1, delta = 0.2

size.prop(pi = 0.5, delta = 0.2, sample = "two.sample",
          alternative = "greater", alpha = 0.01, beta = 0.1)
</code></pre>

<hr>
<h2 id='skewness'>Skewness and Kurtosis</h2><span id='topic+skewness'></span><span id='topic+kurtosis'></span>

<h3>Description</h3>

<p>The function <code>skewness</code> computes the skewness, the function <code>kurtosis</code>
computes the kurtosis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewness(..., data = NULL, as.na = NULL, check = TRUE)

kurtosis(..., data = NULL, as.na = NULL, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skewness_+3A_...">...</code></td>
<td>
<p>a numeric vector. Alternatively, an expression indicating the
variable names in <code>data</code> e.g., <code>skewness(x1, data = dat)</code>. </p>
</td></tr>
<tr><td><code id="skewness_+3A_data">data</code></td>
<td>
<p>a data frame when specifying the variable in the argument
<code>...</code>. Note that the argument is <code>NULL</code> when specifying
a numeric vector for the argument <code>...</code>.</p>
</td></tr>
<tr><td><code id="skewness_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="skewness_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The same method for estimating skewness and kurtosis is used in SAS and SPSS.
Missing values (<code>NA</code>) are stripped before the computation. Note that at
least 3 observations are needed to compute skewness and at least 4 observations
are needed to compute excess kurtosis.
</p>


<h3>Value</h3>

<p>Returns the estimated skewness or kurtosis of <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. New York: John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+descript">descript</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Set seed of the random number generation
set.seed(123)
# Generate random numbers according to N(0, 1)
x &lt;- rnorm(100)

# Example 1: Compute skewness
skewness(x)

# Example 2: Compute excess kurtosis
kurtosis(x)
</code></pre>

<hr>
<h2 id='std.coef'>Standardized Coefficients</h2><span id='topic+std.coef'></span>

<h3>Description</h3>

<p>This function computes standardized coefficients for linear models estimated by using the <code>lm()</code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std.coef(model, print = c("all", "stdx", "stdy", "stdyx"), digits = 3, p.digits = 4,
         write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="std.coef_+3A_model">model</code></td>
<td>
<p>a fitted model of class <code>"lm"</code>.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_print">print</code></td>
<td>
<p>a character vector indicating which results to show, i.e. <code>"all"</code>, for all results,
<code>"stdx"</code> for standardizing only the predictor, <code>"stdy"</code> for for standardizing only
the criterion, and <code>"stdyx"</code> for for standardizing both the predictor and the criterion.
Note that the default setting is depending on the level of measurement of the predictors,
i.e., if all predictors are continuous, the default setting is <code>print = "stdyx"</code>;
if all predictors are binary, the default setting is <code>print = "stdy"</code>; if predictors
are continuous and binary, the default setting is <code>print = c("stdy", "stdyx")</code>.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used for displaying
results.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used for displaying the
<em>p</em>-value.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="std.coef_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The slope <code class="reqn">\beta</code> can be standardized with respect to only <code class="reqn">x</code>, only <code class="reqn">y</code>, or both <code class="reqn">y</code>
and <code class="reqn">x</code>:
</p>
<p style="text-align: center;"><code class="reqn">StdX(\beta_1) = \beta_1 SD(x)</code>
</p>

<p><code class="reqn">StdX(\beta_1)</code> standardizes with respect to <code class="reqn">x</code> only and is interpreted as the change in
<code class="reqn">y</code> when <code class="reqn">x</code> changes one standard deviation referred to as <code class="reqn">SD(x)</code>.
</p>
<p style="text-align: center;"><code class="reqn">StdY(\beta_1) = \frac{\beta_1}{SD(x)}</code>
</p>

<p><code class="reqn">StdY(\beta_1)</code> standardizes with respect to <code class="reqn">y</code> only and is interpreted as the change in
<code class="reqn">y</code> standard deviation units, referred to as <code class="reqn">SD(y)</code>, when <code class="reqn">x</code> changes one unit.
</p>
<p style="text-align: center;"><code class="reqn">StdYX(\beta_1) = \beta_1 \frac{SD(x)}{SD(y)}</code>
</p>

<p><code class="reqn">StdYX(\beta_1)</code> standardizes with respect to both <code class="reqn">y</code> and <code class="reqn">x</code> and is interpreted as the change
in <code class="reqn">y</code> standard deviation units when <code class="reqn">x</code> changes one standard deviation.
</p>
<p>Note that the <code class="reqn">StdYX(\beta_1)</code> and the <code class="reqn">StdY(\beta_1)</code> standardizations are not suitable for the
slope of a binary predictor because a one standard deviation change in a binary variable is generally
not of interest (Muthen, Muthen, &amp; Asparouhov, 2016).
</p>
<p>The standardization of the slope <code class="reqn">\beta_3</code> in a regression model with an interaction term uses the
product of standard deviations <code class="reqn">SD(x_1)SD(x_2)</code> rather than the standard deviation of the product
<code class="reqn">SD(x_1 x_2)</code> for the interaction variable <code class="reqn">x_1</code><code class="reqn">x_2</code> (see Wen, Marsh &amp; Hau, 2010). Likewise,
the standardization of the slope <code class="reqn">\beta_3</code> in a polynomial regression model with a quadratic term
uses the product of standard deviations <code class="reqn">SD(x)SD(x)</code> rather than the standard deviation of the
product <code class="reqn">SD(x x)</code> for the quadratic term <code class="reqn">x^2</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>model specified in <code>model</code> </p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>coef</code> for the regression
table including standardized coefficients and <code>sd</code>
for the standard deviation of the outcome and predictor(s)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Muthen, B. O., Muthen, L. K., &amp; Asparouhov, T. (2016). <em>Regression and mediation analysis using Mplus</em>.
Muthen &amp; Muthen.
</p>
<p>Wen, Z., Marsh, H. W., &amp; Hau, K.-T. (2010). Structural equation models of latent interactions:
An appropriate standardized solution and its scale-free properties. <em>Structural Equation Modeling:
A Multidisciplinary Journal, 17</em>, 1-22. https://doi.org/10.1080/10705510903438872
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(x1 = c(3, 2, 4, 9, 5, 3, 6, 4, 5, 6, 3, 5),
                  x2 = c(1, 4, 3, 1, 2, 4, 3, 5, 1, 7, 8, 7),
                  x3 = c(0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1),
                  y = c(2, 7, 4, 4, 7, 8, 4, 2, 5, 1, 3, 8))

#-------------------------------------------------------------------------------
# Linear model

# Example 1: Regression model with continuous predictors
mod.lm1 &lt;- lm(y ~ x1 + x2, data = dat)
std.coef(mod.lm1)

# Example 2: Print all standardized coefficients
std.coef(mod.lm1, print = "all")

# Example 3: Regression model with dichotomous predictor
mod.lm2 &lt;- lm(y ~ x3, data = dat)
std.coef(mod.lm2)

# Example 4: Regression model with continuous and dichotomous predictors
mod.lm3 &lt;- lm(y ~ x1 + x2 + x3, data = dat)
std.coef(mod.lm3)

# Example 5: Regression model with continuous predictors and an interaction term
mod.lm4 &lt;- lm(y ~ x1*x2, data = dat)

# Example 6: Regression model with a quadratic term
mod.lm5 &lt;- lm(y ~ x1 + I(x1^2), data = dat)
std.coef(mod.lm5)

#-------------------------------------------------------------------------------
# Example 7: Write Results into an Excel file

## Not run: 
mod.lm1 &lt;- lm(y ~ x1 + x2, data = dat)

std.coef(mod.lm1, write = "Std_Coef.xlsx", output = FALSE)

result &lt;- std.coef(mod.lm1, output = FALSE)
write.result(result, "Std_Coef.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='test.levene'>Levene's Test for Homogeneity of Variance</h2><span id='topic+test.levene'></span>

<h3>Description</h3>

<p>This function performs Levene's test for homogeneity of variance across two
or more independent groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.levene(formula, data, method = c("median", "mean"), conf.level = 0.95,
            hypo = TRUE, descript = TRUE, plot = FALSE, violin.alpha = 0.3,
            violin.trim = FALSE, box = TRUE, box.alpha = 0.2, box.width = 0.2,
            jitter = TRUE, jitter.size = 1.25, jitter.width = 0.05,
            jitter.height = 0, jitter.alpha = 0.2, gray = FALSE,
            start = 0.9, end = 0.4, color = NULL, xlab = NULL, ylab = NULL,
            ylim = NULL, breaks = ggplot2::waiver(), title = "",
            subtitle = "", digits = 2, p.digits = 3, as.na = NULL,
            write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test.levene_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> where <code>y</code> is
a numeric variable giving the data values and <code>group</code>
a numeric variable, character variable or factor with two
or more than two values or factor levels giving the
corresponding groups.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_method">method</code></td>
<td>
<p>a character string specifying the method to compute the
center of each group, i.e. <code>method = "median"</code> (default)
to compute the Levene's test based on the median (aka
Brown-Forsythe test) or <code>method = "mean"</code> to compute
the Levene's test based on the arithmetic mean.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing violin plots with
boxplots is drawn.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_violin.alpha">violin.alpha</code></td>
<td>
<p>a numeric value indicating the opacity of the violins.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_violin.trim">violin.trim</code></td>
<td>
<p>logical: if <code>TRUE</code>, the tails of the violins to the
range of the data is trimmed.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_box">box</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), boxplots are drawn.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_box.alpha">box.alpha</code></td>
<td>
<p>a numeric value indicating the opacity of the boxplots.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_box.width">box.width</code></td>
<td>
<p>a numeric value indicating the width of the boxplots.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), jittered data points
are drawn.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value indicating the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_gray">gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, the plot is drawn in gray scale.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_start">start</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to
specify the gray value at the low end of the palette.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_end">end</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to
specify the gray value at the high end of the palette.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_color">color</code></td>
<td>
<p>a character vector, indicating the color of the violins
and the boxes. By default, default ggplot2 colors are
used.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle
for the plot.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying results.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="test.levene_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Levene's test is equivalent to a one-way analysis of variance (ANOVA) with the
absolute deviations of observations from the mean of each group as dependent
variable (<code>center = "mean"</code>). Brown and Forsythe (1974) modified the
Levene's test by using the absolute deviations of observations from the median
(<code>center = "median"</code>). By default, the Levene's test uses the absolute
deviations of observations from the median.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>descript</code> for
descriptive statistics and <code>test</code> for the ANOVA
table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Brown, M. B., &amp; Forsythe, A. B. (1974). Robust tests for the equality of
variances. <em>Journal of the American  Statistical Association, 69</em>,
364-367.
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(y = c(2, 3, 4, 5, 5, 7, 8, 4, 5, 2, 4, 3),
                  group = c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3))

# Example 1: Levene's test based on the median with 95% confidence interval
test.levene(y ~ group, data = dat)

# Example 2: Levene's test based on the arithmetic mean  with 95% confidence interval
test.levene(y ~ group, data = dat, method = "mean")

# Example 3: Levene's test based on the median with 99% confidence interval
test.levene(y ~ group, data = dat, conf.level = 0.99)

## Not run: 
# Example 4: Write results into a text file
test.levene(y ~ group, data = dat, write = "Levene.txt")

# Example 5: Levene's test based on the median with 95
# plot results
test.levene(y ~ group, data = dat, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("Levene-test.png", dpi = 600, width = 5, height = 6)

# Levene's test based on the median with 95
# extract plot
p &lt;- test.levene(y ~ group, data = dat, output = FALSE)$plot
p

# Example 6: Extract data
plotdat &lt;- test.levene(y ~ group, data = dat, output = FALSE)$data

# Draw violin and boxplots in line with the default setting of test.levene()
ggplot(plotdat, aes(group, y, fill = group)) +
  geom_violin(alpha = 0.3, trim = FALSE) +
  geom_boxplot(alpha = 0.2, width = 0.2) +
  geom_jitter(alpha = 0.2, width = 0.05, size = 1.25) +
  theme_bw() + guides(fill = "none")

## End(Not run)
</code></pre>

<hr>
<h2 id='test.t'>t-Test</h2><span id='topic+test.t'></span><span id='topic+test.t.default'></span><span id='topic+test.t.formula'></span>

<h3>Description</h3>

<p>This function performs one-sample, two-sample, and paired-sample t-tests and
provides descriptive statistics, effect size measure, and a plot showing error
bars for (difference-adjusted) confidence intervals with jittered data points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.t(x, ...)

## Default S3 method:
test.t(x, y = NULL, mu = 0, paired = FALSE,
       alternative = c("two.sided", "less", "greater"),
       conf.level = 0.95,  hypo = TRUE, descript = TRUE, effsize = FALSE,
       weighted = FALSE, cor = TRUE, ref = NULL, correct = FALSE,
       plot = FALSE, point.size = 4, adjust = TRUE, error.width = 0.1,
       xlab = NULL, ylab = NULL, ylim = NULL, breaks = ggplot2::waiver(),
       line = TRUE, line.type = 3, line.size = 0.8,
       jitter = TRUE, jitter.size = 1.25, jitter.width = 0.05,
       jitter.height = 0, jitter.alpha = 0.1, title = "",
       subtitle = "Confidence Interval", digits = 2, p.digits = 4,
        as.na = NULL, write = NULL, append = TRUE,check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
test.t(formula, data, alternative = c("two.sided", "less", "greater"),
       conf.level = 0.95, hypo = TRUE, descript = TRUE, effsize = FALSE,
       weighted = FALSE, cor = TRUE, ref = NULL, correct = FALSE,
       plot = FALSE, point.size = 4, adjust = TRUE, error.width = 0.1,
       xlab = NULL, ylab = NULL, ylim = NULL, breaks = ggplot2::waiver(),
       jitter = TRUE, jitter.size = 1.25, jitter.width = 0.05,
       jitter.height = 0, jitter.alpha = 0.1, title = "",
       subtitle = "Confidence Interval", digits = 2, p.digits = 4,
       as.na = NULL, write = NULL, append = TRUE, check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test.t_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="test.t_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="test.t_+3A_y">y</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="test.t_+3A_mu">mu</code></td>
<td>
<p>a numeric value indicating the population mean under the
null hypothesis. Note that the argument <code>mu</code> is only
used when computing a one sample t-test.</p>
</td></tr>
<tr><td><code id="test.t_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, paired-samples t-test is computed.</p>
</td></tr>
<tr><td><code id="test.t_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="test.t_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="test.t_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="test.t_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measure Cohen's d is
shown on the console, see <code><a href="#topic+cohens.d">cohens.d</a></code> function.</p>
</td></tr>
<tr><td><code id="test.t_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code>, the weighted pooled standard deviation
is used to compute Cohen's d for a two-sample design (i.e.,
<code>paired = FALSE</code>), while standard deviation of the
difference scores is used to compute Cohen's d for a
paired-sample design (i.e., <code>paired = TRUE</code>).</p>
</td></tr>
<tr><td><code id="test.t_+3A_cor">cor</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), <code>paired = TRUE</code>,
and <code>weighted = FALSE</code>, Cohen's d for a paired-sample
design while controlling for the correlation between the
two sets of measurement is computed. Note that this
argument is only used in
a paired-sample design (i.e., <code>paired = TRUE</code>) when
specifying <code>weighted = FALSE</code>.</p>
</td></tr>
<tr><td><code id="test.t_+3A_ref">ref</code></td>
<td>
<p>character string <code>"x"</code> or <code>"y"</code> for specifying
the reference reference group when using the default
<code>test.t()</code> function or a numeric value or character
string indicating the reference group in a two-sample
design when using the formula <code>test.t()</code> function.
The standard deviation of the reference variable or
reference group is used to standardized the mean difference
to compute Cohen's d. Note that this argument is only used
in a two-sample design (i.e., <code>paired = FALSE</code>).</p>
</td></tr>
<tr><td><code id="test.t_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor to remove
positive bias in small samples is used.</p>
</td></tr>
<tr><td><code id="test.t_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="test.t_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing error bars for
confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="test.t_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="test.t_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment for the
confidence intervals in a two-sample design is applied.</p>
</td></tr>
<tr><td><code id="test.t_+3A_error.width">error.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="test.t_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a horizontal line
is drawn at <code>mu</code> for the one-sample t-test or at
0 for the paired-sample t-test.</p>
</td></tr>
<tr><td><code id="test.t_+3A_line.type">line.type</code></td>
<td>
<p>an integer value or character string specifying the line
type for the line representing the population mean under
the null hypothesis, i.e., 0 = blank, 1 = solid, 2 = dashed,
3 = dotted, 4 = dotdash, 5 = longdash, 6 = twodash.</p>
</td></tr>
<tr><td><code id="test.t_+3A_line.size">line.size</code></td>
<td>
<p>a numeric value indicating the <code>linewidth</code> aesthetic
for the line representing the population mean under the
null hypothesis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), jittered data points
are drawn.</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="test.t_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value indicating the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="test.t_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="test.t_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle for
the plot.</p>
</td></tr>
<tr><td><code id="test.t_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying descriptive statistics and
confidence interval.</p>
</td></tr>
<tr><td><code id="test.t_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="test.t_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before
conducting the analysis.</p>
</td></tr>
<tr><td><code id="test.t_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="test.t_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="test.t_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="test.t_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="test.t_+3A_formula">formula</code></td>
<td>
<p>in case of two sample t-test (i.e., <code>paired = FALSE</code>),
a formula of the form <code>y ~ group</code> where <code>group</code>
is a numeric variable, character variable or factor with
two values or factor levels giving the corresponding
groups.</p>
</td></tr>
<tr><td><code id="test.t_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Effect Size Measure</strong></dt><dd><p>By default, Cohen's d based on the non-weighted
standard deviation (i.e., <code>weighted = FALSE</code>) which does not assume homogeneity
of variance is computed (see Delacre et al., 2021) when requesting an effect size
measure (i.e., <code>effsize = TRUE</code>). Cohen's d based on the pooled standard
deviation assuming equality of variances between groups can be requested by
specifying <code>weighted = TRUE</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>type of sample, i.e., one-, two-, or paired sample</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in
psychology - Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Delacre, M., Lakens, D., Ley, C., Liu, L., &amp; Leys, C. (2021). Why Hedges' g*s
based on the non-pooled standard deviation should be reported with Welch's t-test.
https://doi.org/10.31234/osf.io/tu6mp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>, <code><a href="#topic+test.z">test.z</a></code>,
<code><a href="#topic+test.levene">test.levene</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat1 &lt;- data.frame(group = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2),
                   x = c(3, 1, 4, 2, 5, 3, 2, 3, 6, 6, 3, NA))

#-------------------------------------------------------------------------------
# One-Sample Design

# Example 1a: Two-sided one-sample t-test
# population mean = 3
test.t(dat1$x, mu = 3)

# Example 1b: One-sided one-sample t-test
# population mean = 3, population standard deviation = 1.2
test.t(dat1$x, mu = 3, alternative = "greater")

# Example 1c: Two-sided one-sample t-test
# population mean = 3, convert value 3 to NA
test.t(dat1$x, mu = 3, as.na = 3)

# Example 1d: Two-sided one-sample t-test
# population mean = 3, print Cohen's d
test.t(dat1$x, sigma = 1.2, mu = 3, effsize = TRUE)

# Example 1e: Two-sided one-sample t-test
# population mean = 3, print Cohen's d with small sample correction factor
test.t(dat1$x, sigma = 1.2, mu = 3, effsize = TRUE, correct = TRUE)

# Example 1f: Two-sided one-sample t-test
# population mean = 3,
# do not print hypotheses and descriptive statistics
test.t(dat1$x, sigma = 1.2, mu = 3, hypo = FALSE, descript = FALSE)

# Example 1g: Two-sided one-sample t-test
# print descriptive statistics with 3 digits and p-value with 5 digits
test.t(dat1$x,  mu = 3, digits = 3, p.digits = 5)

## Not run: 
# Example 1h: Two-sided one-sample t-test
# population mean = 3, plot results
test.t(dat1$x, mu = 3, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("One-sample_t-test.png", dpi = 600, width = 3, height = 6)

# Example 1i: Two-sided one-sample t-test
# population mean = 3, extract plot
p &lt;- test.t(dat1$x, mu = 3, output = FALSE)$plot
p

# Extract data
plotdat &lt;- data.frame(x = test.t(dat1$x, mu = 3, output = FALSE)$data[[1]])

# Draw plot in line with the default setting of test.t()
ggplot(plotdat, aes(0, x)) +
   geom_point(stat = "summary", fun = "mean", size = 4) +
   stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.20) +
   scale_x_continuous(name = NULL, limits = c(-2, 2)) +
   scale_y_continuous(name = NULL) +
   geom_hline(yintercept = 3, linetype = 3, linewidth = 0.8) +
   labs(subtitle = "Two-Sided 95
   theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5),
                      axis.text.x = element_blank(),
                      axis.ticks.x = element_blank())

## End(Not run)
#-------------------------------------------------------------------------------
# Two-Sample Design

# Example 2a: Two-sided two-sample t-test
test.t(x ~ group, data = dat1)

# Example 2b: One-sided two-sample t-test
test.t(x ~ group, data = dat1, alternative = "greater")

# Example 2c: Two-sided two-sample t-test
# print Cohen's d with weighted pooled SD
test.t(x ~ group, data = dat1, effsize = TRUE)

# Example 2d: Two-sided two-sample t-test
# print Cohen's d with unweighted pooled SD
test.t(x ~ group, data = dat1, effsize = TRUE, weighted = FALSE)

# Example 2e: Two-sided two-sample t-test
# print Cohen's d with weighted pooled SD and
# small sample correction factor
test.t(x ~ group, data = dat1, effsize = TRUE, correct = TRUE)

# Example 2f: Two-sided two-sample t-test
# print Cohen's d with SD of the reference group 1
test.t(x ~ group, data = dat1, effsize = TRUE,
       ref = 1)

# Example 2f: Two-sided two-sample t-test
# print Cohen's d with weighted pooled SD and
# small sample correction factor
test.t(x ~ group, data = dat1, effsize = TRUE,
       correct = TRUE)

# Example 2h: Two-sided two-sample t-test
# do not print hypotheses and descriptive statistics,
test.t(x ~ group, data = dat1, descript = FALSE, hypo = FALSE)

# Example 2i: Two-sided two-sample t-test
# print descriptive statistics with 3 digits and p-value with 5 digits
test.t(x ~ group, data = dat1, digits = 3, p.digits = 5)

## Not run: 
# Example 2j: Two-sided two-sample t-test
# Plot results
test.t(x ~ group, data = dat1, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("Two-sample_t-test.png", dpi = 600, width = 4, height = 6)

# Example 2k: Two-sided two-sample t-test
# extract plot
p &lt;- test.t(x ~ group, data = dat1, output = FALSE)$plot
p

# Extract data used to plot results
plotdat &lt;- test.t(x ~ group, data = dat1, output = FALSE)$data

# Draw plot in line with the default setting of test.t()
ggplot(plotdat, aes(factor(group), x)) +
   geom_point(stat = "summary", fun = "mean", size = 4) +
   stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.20) +
   scale_x_discrete(name = NULL) + scale_y_continuous(name = "y") +
   labs(title = "", subtitle = "Two-Sided 95
   theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5))

## End(Not run)

#-----------------

group1 &lt;- c(3, 1, 4, 2, 5, 3, 6, 7)
group2 &lt;- c(5, 2, 4, 3, 1)

# Example 2l: Two-sided two-sample t-test
test.t(group1, group2)

#-------------------------------------------------------------------------------
# Paired-Sample Design

dat2 &lt;- data.frame(pre = c(1, 3, 2, 5, 7),
                   post = c(2, 2, 1, 6, 8))

# Example 3a: Two-sided paired-sample t-test
test.t(dat2$pre, dat2$post, paired = TRUE)

# Example 3b: One-sided paired-sample t-test
test.t(dat2$pre, dat2$post, paired = TRUE,
       alternative = "greater")

# Example 3c: Two-sided paired-sample t-test
# convert value 1 to NA
test.t(dat2$pre, dat2$post, as.na = 1, paired = TRUE)

# Example 3d: Two-sided paired-sample t-test
# print Cohen's d based on the standard deviation of the difference scores
test.t(dat2$pre, dat2$post, paired = TRUE, effsize = TRUE)

# Example 3e: Two-sided paired-sample t-test
# print Cohen's d based on the standard deviation of the difference scores
# with small sample correction factor
test.t(dat2$pre, dat2$post, paired = TRUE, effsize = TRUE,
       correct = TRUE)

# Example 3f: Two-sided paired-sample t-test
# print Cohen's d controlling for the correlation between measures
test.t(dat2$pre, dat2$post, paired = TRUE, effsize = TRUE,
       weighted = FALSE)

# Example 3g: Two-sided paired-sample t-test
# print Cohen's d controlling for the correlation between measures
# with small sample correction factor
test.t(dat2$pre, dat2$post, paired = TRUE, effsize = TRUE,
       weighted = FALSE, correct = TRUE)

# Example 3h: Two-sided paired-sample t-test
# print Cohen's d ignoring the correlation between measures
test.t(dat2$pre, dat2$post, paired = TRUE, effsize = TRUE,
       weighted = FALSE, cor = FALSE)

# Example 3i: Two-sided paired-sample t-test
# do not print hypotheses and descriptive statistics
test.t(dat2$pre, dat2$post, paired = TRUE, hypo = FALSE, descript = FALSE)

# Example 3j: Two-sided paired-sample t-test
# population standard deviation of difference score = 1.2
# print descriptive statistics with 3 digits and p-value with 5 digits
test.t(dat2$pre, dat2$post, paired = TRUE, digits = 3,
       p.digits = 5)

## Not run: 
# Example 3k: Two-sided paired-sample t-test
# Plot results
test.t(dat2$pre, dat2$post, paired = TRUE, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("Paired-sample_t-test.png", dpi = 600, width = 3, height = 6)

# Example 3l: Two-sided paired-sample t-test
# Extract plot
p &lt;- test.t(dat2$pre, dat2$post, paired = TRUE, output = FALSE)$plot
p

# Extract data used to plot results
plotdat &lt;- data.frame(test.t(dat2$pre, dat2$post, paired = TRUE, output = FALSE)$data)

# Difference score
plotdat$diff &lt;- plotdat$y - plotdat$x

# Draw plot in line with the default setting of test.t()
ggplot(plotdat, aes(0, diff)) +
   geom_point(stat = "summary", fun = "mean", size = 4) +
   stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.20) +
   scale_x_discrete(name = NULL) + scale_y_continuous(name = NULL) +
   geom_hline(yintercept = 0, linetype = 3, linewidth = 0.8) +
   labs(subtitle = "Two-Sided 95
   theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5),
                      axis.text.x = element_blank(),
                      axis.ticks.x = element_blank())

## End(Not run)
</code></pre>

<hr>
<h2 id='test.welch'>Welch's Test</h2><span id='topic+test.welch'></span>

<h3>Description</h3>

<p>This function performs Welch's two-sample t-test and Welch's ANOVA including
Games-Howell post hoc test for multiple comparison and provides descriptive
statistics, effect size measures, and a plot showing error bars for
difference-adjusted confidence intervals with jittered data points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.welch(formula, data, alternative = c("two.sided", "less", "greater"),
           posthoc = TRUE, conf.level = 0.95, hypo = TRUE, descript = TRUE,
           effsize = FALSE, weighted = FALSE, ref = NULL, correct = FALSE,
           plot = FALSE, point.size = 4, adjust = TRUE, error.width = 0.1,
           xlab = NULL, ylab = NULL, ylim = NULL, breaks = ggplot2::waiver(),
           jitter = TRUE, jitter.size = 1.25, jitter.width = 0.05,
           jitter.height = 0, jitter.alpha = 0.1, title = "",
           subtitle = "Confidence Interval", digits = 2, p.digits = 4,
           as.na = NULL, write = NULL, append = TRUE, check = TRUE,
           output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test.welch_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ group</code> where <code>y</code> is
a numeric variable giving the data values and <code>group</code>
a numeric variable, character variable or factor with two
or more than two values or factor levels giving the
corresponding groups.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the
formula <code>formula</code>.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>. Note that this argument is only used when
conducting Welch's two-sample t-test.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_posthoc">posthoc</code></td>
<td>
<p>logical: if <code>TRUE</code>, Games-Howell post hoc test for
multiple comparison is conducted when performing Welch's
ANOVA.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis
are shown on the console.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measure Cohen's d for
Welch's two-sample t-test (see <code><a href="#topic+cohens.d">cohens.d</a></code>),
<code class="reqn">\eta^2</code> and <code class="reqn">\omega^2</code> for Welch's ANOVA and
Cohen's d for the post hoc tests are shown on the console.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_weighted">weighted</code></td>
<td>
<p>logical: if <code>TRUE</code>, the weighted pooled standard
deviation is used to compute Cohen's d.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_ref">ref</code></td>
<td>
<p>a numeric value or character string indicating the reference
group. The standard deviation of the reference group is used
to standardized the mean difference to compute Cohen's d.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_correct">correct</code></td>
<td>
<p>logical: if <code>TRUE</code>, correction factor to remove positive
bias in small samples is used.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing error bars for
confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment for the
confidence intervals is applied.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_error.width">error.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), jittered data points
are drawn.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value indicating the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying descriptive statistics and
confidence interval.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places
to be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="test.welch_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle for
the plot.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><strong>Effect Size Measure</strong></dt><dd><p>By default, Cohen's d based on the non-weighted
standard deviation (i.e., <code>weighted = FALSE</code>) which does not assume homogeneity
of variance is computed (see Delacre et al., 2021) when requesting an effect size
measure (i.e., <code>effsize = TRUE</code>). Cohen's d based on the pooled standard
deviation assuming equality of variances between groups can be requested by
specifying <code>weighted = TRUE</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>type of sample, i.e., two- or multiple sample</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>
<p>Delacre, M., Lakens, D., Ley, C., Liu, L., &amp; Leys, C. (2021). Why Hedges' g*s
based on the non-pooled standard deviation should be reported with Welch's t-test.
https://doi.org/10.31234/osf.io/tu6mp
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+test.z">test.z</a></code>, <code><a href="#topic+test.levene">test.levene</a></code>,
<code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>,
<code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat1 &lt;- data.frame(group1 = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2),
                   group2 = c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3),
                   y = c(3, 1, 4, 2, 5, 3, 2, 3, 6, 6, 3, NA))

#-------------------------------------------------------------------------------
# Two-Sample Design

# Example 1a: Two-sided two-sample Welch-test
test.welch(y ~ group1, data = dat1)

# Example 1b: One-sided two-sample Welch-test
test.welch(y ~ group1, data = dat1, alternative = "greater")

# Example 1c: Two-sided two-sample Welch-test
# print Cohen's d with weighted pooled SD
test.welch(y ~ group1, data = dat1, effsize = TRUE)

# Example 1d: Two-sided two-sample Welch-test
# print Cohen's d with unweighted pooled SD
test.welch(y ~ group1, data = dat1, effsize = TRUE, weighted = FALSE)

# Example 1e: Two-sided two-sample Welch-test
# print Cohen's d with weighted pooled SD and
# small sample correction factor
test.welch(y ~ group1, data = dat1, effsize = TRUE, correct = TRUE)

# Example 1f: Two-sided two-sample Welch-test
# print Cohen's d with SD of the reference group 1
test.welch(y ~ group1, data = dat1, effsize = TRUE,
           ref = 1)

# Example 1g: Two-sided two-sample Welch-test
# print Cohen's d with weighted pooled SD and
# small sample correction factor
test.welch(y ~ group1, data = dat1, effsize = TRUE,
           correct = TRUE)

# Example 1h: Two-sided two-sample Welch-test
# do not print hypotheses and descriptive statistics,
test.welch(y ~ group1, data = dat1, descript = FALSE, hypo = FALSE)

# Example 1i: Two-sided two-sample Welch-test
# print descriptive statistics with 3 digits and p-value with 5 digits
test.welch(y ~ group1, data = dat1, digits = 3, p.digits = 5)

## Not run: 
# Example 1j: Two-sided two-sample Welch-test
# plot results
test.welch(y ~ group1, data = dat1, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("Two-sample_Welch-test.png", dpi = 600, width = 4, height = 6)

# Example 1k: Two-sided two-sample Welch-test
# extract plot
p &lt;- test.welch(y ~ group1, data = dat1, output = FALSE)$plot
p

# Extract data
plotdat &lt;- test.welch(y ~ group1, data = dat1, output = FALSE)$data

# Draw plot in line with the default setting of test.welch()
ggplot(plotdat, aes(factor(group), y)) +
  geom_point(stat = "summary", fun = "mean", size = 4) +
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.20) +
  scale_x_discrete(name = NULL) +
  labs(subtitle = "Two-Sided 95
  theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5))

## End(Not run)
#-------------------------------------------------------------------------------
# Multiple-Sample Design

# Example 2a: Welch's ANOVA
test.welch(y ~ group2, data = dat1)

# Example 2b: Welch's ANOVA
# print eta-squared and omega-squared
test.welch(y ~ group2, data = dat1, effsize = TRUE)

# Example 2c: Welch's ANOVA
# do not print hypotheses and descriptive statistics,
test.welch(y ~ group2, data = dat1, descript = FALSE, hypo = FALSE)

## Not run: 
# Example 2d: Welch's ANOVA
# plot results
test.welch(y ~ group2, data = dat1, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("Multiple-sample_Welch-test.png", dpi = 600, width = 4.5, height = 6)

# Example 2e: Welch's ANOVA
# extract plot
p &lt;- test.welch(y ~ group2, data = dat1, output = FALSE)$plot
p

# Extract data
plotdat &lt;- test.welch(y ~ group2, data = dat1, output = FALSE)$data

# Draw plot in line with the default setting of test.welch()
ggplot(plotdat, aes(group, y)) +
  geom_point(stat = "summary", fun = "mean", size = 4) +
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.20) +
  scale_x_discrete(name = NULL) +
  labs(subtitle = "Two-Sided 95
  theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5))

## End(Not run)
</code></pre>

<hr>
<h2 id='test.z'>z-Test</h2><span id='topic+test.z'></span><span id='topic+test.z.default'></span><span id='topic+test.z.formula'></span>

<h3>Description</h3>

<p>This function performs one-sample, two-sample, and paired-sample z-tests and
provides descriptive statistics, effect size measure, and a plot showing error
bars for (difference-adjusted) confidence intervals with jittered data points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.z(x, ...)

## Default S3 method:
test.z(x, y = NULL, sigma = NULL, sigma2 = NULL, mu = 0,
       paired = FALSE, alternative = c("two.sided", "less", "greater"),
       conf.level = 0.95, hypo = TRUE, descript = TRUE, effsize = FALSE,
       plot = FALSE, point.size = 4, adjust = TRUE, error.width = 0.1,
       xlab = NULL, ylab = NULL, ylim = NULL, breaks = ggplot2::waiver(),
       line = TRUE, line.type = 3, line.size = 0.8, jitter = TRUE,
       jitter.size = 1.25, jitter.width = 0.05, jitter.height = 0,
       jitter.alpha = 0.1, title = "", subtitle = "Confidence Interval",
       digits = 2, p.digits = 4, as.na = NULL, write = NULL, append = TRUE,
       check = TRUE, output = TRUE, ...)

## S3 method for class 'formula'
test.z(formula, data, sigma = NULL, sigma2 = NULL,
       alternative = c("two.sided", "less", "greater"), conf.level = 0.95,
       hypo = TRUE, descript = TRUE, effsize = FALSE,
       plot = FALSE, point.size = 4, adjust = TRUE, error.width = 0.1,
       xlab = NULL, ylab = NULL, ylim = NULL, breaks = ggplot2::waiver(),
       jitter = TRUE, jitter.size = 1.25, jitter.width = 0.05, jitter.height = 0,
       jitter.alpha = 0.1, title = "",  subtitle = "Confidence Interval",
       digits = 2, p.digits = 4, as.na = NULL, write = NULL, append = TRUE,
       check = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test.z_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="test.z_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="test.z_+3A_y">y</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="test.z_+3A_sigma">sigma</code></td>
<td>
<p>a numeric vector indicating the population standard deviation(s).
In case of two-sample z-test, equal standard deviations are
assumed when specifying one value for the argument <code>sigma</code>;
when specifying two values for the argument <code>sigma</code>,
unequal standard deviations are assumed. Note that either
argument <code>sigma</code> or argument <code>sigma2</code> is specified.</p>
</td></tr>
<tr><td><code id="test.z_+3A_sigma2">sigma2</code></td>
<td>
<p>a numeric vector indicating the population variance(s). In
case of two-sample z-test, equal variances are assumed when
specifying one value for the argument <code>sigma2</code>; when
specifying two values for the argument <code>sigma</code>, unequal
variance are assumed. Note that either argument <code>sigma</code>
or argument <code>sigma2</code> is specified.</p>
</td></tr>
<tr><td><code id="test.z_+3A_mu">mu</code></td>
<td>
<p>a numeric value indicating the population mean under the null
hypothesis. Note that the argument <code>mu</code> is only used
when computing a one-sample z-test.</p>
</td></tr>
<tr><td><code id="test.z_+3A_paired">paired</code></td>
<td>
<p>logical: if <code>TRUE</code>, paired-sample z-test is computed.</p>
</td></tr>
<tr><td><code id="test.z_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="test.z_+3A_hypo">hypo</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), null and alternative hypothesis are
shown on the console.</p>
</td></tr>
<tr><td><code id="test.z_+3A_descript">descript</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), descriptive statistics are shown
on the console.</p>
</td></tr>
<tr><td><code id="test.z_+3A_effsize">effsize</code></td>
<td>
<p>logical: if <code>TRUE</code>, effect size measure Cohen's d is
shown on the console.</p>
</td></tr>
<tr><td><code id="test.z_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between 0 and 1 indicating the confidence
level of the interval.</p>
</td></tr>
<tr><td><code id="test.z_+3A_plot">plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, a plot showing error bars for
confidence intervals is drawn.</p>
</td></tr>
<tr><td><code id="test.z_+3A_point.size">point.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic for
the point representing the mean value.</p>
</td></tr>
<tr><td><code id="test.z_+3A_adjust">adjust</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), difference-adjustment for the
confidence intervals in a two-sample design is applied.</p>
</td></tr>
<tr><td><code id="test.z_+3A_error.width">error.width</code></td>
<td>
<p>a numeric value indicating the horizontal bar width of
the error bar.</p>
</td></tr>
<tr><td><code id="test.z_+3A_xlab">xlab</code></td>
<td>
<p>a character string specifying the labels for the x-axis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_ylab">ylab</code></td>
<td>
<p>a character string specifying the labels for the y-axis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_ylim">ylim</code></td>
<td>
<p>a numeric vector of length two specifying limits of the
limits of the y-axis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector specifying the points at which tick-marks
are drawn at the y-axis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_line">line</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), a horizontal line
is drawn at <code>mu</code> for the one-sample t-test or at
0 for the paired-sample t-test.</p>
</td></tr>
<tr><td><code id="test.z_+3A_line.type">line.type</code></td>
<td>
<p>an integer value or character string specifying the line
type for the line representing the population mean under
the null hypothesis, i.e., 0 = blank, 1 = solid, 2 = dashed,
3 = dotted, 4 = dotdash, 5 = longdash, 6 = twodash.</p>
</td></tr>
<tr><td><code id="test.z_+3A_line.size">line.size</code></td>
<td>
<p>a numeric value indicating the <code>linewidth</code> aesthetic
for the line representing the population mean under the
null hypothesis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter">jitter</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), jittered data points
are drawn.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter.size">jitter.size</code></td>
<td>
<p>a numeric value indicating the <code>size</code> aesthetic
for the jittered data points.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter.width">jitter.width</code></td>
<td>
<p>a numeric value indicating the amount of horizontal jitter.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter.height">jitter.height</code></td>
<td>
<p>a numeric value indicating the amount of vertical jitter.</p>
</td></tr>
<tr><td><code id="test.z_+3A_jitter.alpha">jitter.alpha</code></td>
<td>
<p>a numeric value indicating the opacity of the jittered
data points.</p>
</td></tr>
<tr><td><code id="test.z_+3A_title">title</code></td>
<td>
<p>a character string specifying the text for the title for
the plot.</p>
</td></tr>
<tr><td><code id="test.z_+3A_subtitle">subtitle</code></td>
<td>
<p>a character string specifying the text for the subtitle for
the plot.</p>
</td></tr>
<tr><td><code id="test.z_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying descriptive statistics and confidence
interval.</p>
</td></tr>
<tr><td><code id="test.z_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to
be used for displaying the <em>p</em>-value.</p>
</td></tr>
<tr><td><code id="test.z_+3A_as.na">as.na</code></td>
<td>
<p>a numeric vector indicating user-defined missing values,
i.e. these values are converted to <code>NA</code> before conducting
the analysis.</p>
</td></tr>
<tr><td><code id="test.z_+3A_write">write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td></tr>
<tr><td><code id="test.z_+3A_append">append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td></tr>
<tr><td><code id="test.z_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
<tr><td><code id="test.z_+3A_output">output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td></tr>
<tr><td><code id="test.z_+3A_formula">formula</code></td>
<td>
<p>in case of two sample z-test (i.e., <code>paired = FALSE</code>),
a formula of the form <code>y ~ group</code> where <code>group</code>
is a numeric variable, character variable
or factor with two values or factor levels giving the
corresponding groups.</p>
</td></tr>
<tr><td><code id="test.z_+3A_data">data</code></td>
<td>
<p>a matrix or data frame containing the variables in the formula
<code>formula</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cohen's d reported when argument <code>effsize = TRUE</code> is based on the population
standard deviation specified in <code>sigma</code> or the square root of the population
variance specified in <code>sigma2</code>. In a one-sample and paired-sample design,
Cohen's d is the mean of the difference scores divided by the population standard
deviation of the difference scores (i.e., equivalent to Cohen's <code class="reqn">d_z</code> according
to Lakens, 2013). In a two-sample design, Cohen's d is the difference between
means of the two groups of observations divided by either the population standard
deviation when assuming and specifying equal standard deviations or the unweighted
pooled population standard deviation when assuming and specifying unequal standard
deviations.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>type of analysis</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>type of sample, i.e., one-, two-, or paired sample</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the current analysis</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data frame specified in <code>data</code></p>
</td></tr>
<tr><td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>result table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative
science: A practical primer for t-tests and ANOVAs. <em>Frontiers in Psychology, 4</em>,
1-12. https://doi.org/10.3389/fpsyg.2013.00863
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). <em>Statistics in psychology
- Using R and SPSS</em>. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test.t">test.t</a></code>, <code><a href="#topic+aov.b">aov.b</a></code>, <code><a href="#topic+aov.w">aov.w</a></code>, <code><a href="#topic+test.welch">test.welch</a></code>,
<code><a href="#topic+cohens.d">cohens.d</a></code>, <code><a href="#topic+ci.mean.diff">ci.mean.diff</a></code>, <code><a href="#topic+ci.mean">ci.mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat1 &lt;- data.frame(group = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2),
                   x = c(3, 1, 4, 2, 5, 3, 2, 3, 6, 4, 3, NA))

#-------------------------------------------------------------------------------
# One-Sample Design

# Example 1a: Two-sided one-sample z-test
# population mean = 3, population standard deviation = 1.2
test.z(dat1$x, sigma = 1.2, mu = 3)

# Example 1b: Two-sided one-sample z-test
# population mean = 3, population variance = 1.44
test.z(dat1$x, sigma2 = 1.44, mu = 3)

# Example 1c: One-sided one-sample z-test
# population mean = 3, population standard deviation = 1.2
test.z(dat1$x, sigma = 1.2, mu = 3, alternative = "greater")

# Example 1d: Two-sided one-sample z-test
# population mean = 3, population standard deviation = 1.2
# convert value 3 to NA
test.z(dat1$x, sigma = 1.2, mu = 3, as.na = 3)

# Example 1e: Two-sided one-sample z-test
# population mean = 3, population standard deviation = 1.2
# print Cohen's d
test.z(dat1$x, sigma = 1.2, mu = 3, effsize = TRUE)

# Example 1f: Two-sided one-sample z-test
# population mean = 3, population standard deviation = 1.2
# do not print hypotheses and descriptive statistics
test.z(dat1$x, sigma = 1.2, mu = 3, hypo = FALSE, descript = FALSE)

# Example 1g: Two-sided one-sample z-test
# population mean = 3, population standard deviation = 1.2
# print descriptive statistics with 3 digits and p-value with 5 digits
test.z(dat1$x, sigma = 1.2, mu = 3, digits = 3, p.digits = 5)

## Not run: 
# Example 1h: Two-sided one-sample z-test
# population mean = 3, population standard deviation = 1.2
# plot results
test.z(dat1$x, sigma = 1.2, mu = 3, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("One-sample_z-test.png", dpi = 600, width = 3, height = 6)

# Example 1i: Two-sided one-sample z-test
# population mean = 3, population standard deviation = 1.2
# extract plot
p &lt;- test.z(dat1$x, sigma = 1.2, mu = 3, output = FALSE)$plot
p

# Extract data
plotdat &lt;- data.frame(test.z(dat1$x, sigma = 1.2, mu = 3, output = FALSE)$data[[1]])

# Extract results
result &lt;- test.z(dat1$x, sigma = 1.2, mu = 3, output = FALSE)$result

# Draw plot in line with the default setting of test.z()
ggplot(plotdat, aes(0, x)) +
  geom_point(data = result, aes(x = 0L, m), size = 4) +
  geom_errorbar(data = result, aes(x = 0L, y = m, ymin = m.low, ymax = m.upp),
                width = 0.2) +
  scale_x_continuous(name = NULL, limits = c(-2, 2)) +
  scale_y_continuous(name = NULL) +
  geom_hline(yintercept = 3, linetype = 3, linewidth = 0.8) +
  labs(subtitle = "Two-Sided 95
  theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5),
                     axis.text.x = element_blank(),
                     axis.ticks.x = element_blank())

## End(Not run)

#-------------------------------------------------------------------------------
# Two-Sample Design

# Example 2a: Two-sided two-sample z-test
# population standard deviation (SD) = 1.2, equal SD assumption
test.z(x ~ group, sigma = 1.2, data = dat1)

# Example 2b: Two-sided two-sample z-test
# population standard deviation (SD) = 1.2 and 1.5, unequal SD assumption
test.z(x ~ group, sigma = c(1.2, 1.5), data = dat1)

# Example 2c: Two-sided two-sample z-test
# population variance (Var) = 1.44 and 2.25, unequal Var assumption
test.z(x ~ group, sigma2 = c(1.44, 2.25), data = dat1)

# Example 2d: One-sided two-sample z-test
# population standard deviation (SD) = 1.2, equal SD assumption
test.z(x ~ group, sigma = 1.2, data = dat1, alternative = "greater")

# Example 2e: Two-sided two-sample z-test
# population standard deviation (SD) = 1.2, equal SD assumption
# print Cohen's d
test.z(x ~ group, sigma = 1.2, data = dat1, effsize = TRUE)

# Example 2f: Two-sided two-sample z-test
# population standard deviation (SD) = 1.2, equal SD assumption
# do not print hypotheses and descriptive statistics,
# print Cohen's d
test.z(x ~ group, sigma = 1.2, data = dat1, descript = FALSE, hypo = FALSE)

# Example 2g: Two-sided two-sample z-test
# population mean = 3, population standard deviation = 1.2
# print descriptive statistics with 3 digits and p-value with 5 digits
test.z(x ~ group, sigma = 1.2, data = dat1, digits = 3, p.digits = 5)

## Not run: 
# Example 2h: Two-sided two-sample z-test
# population standard deviation (SD) = 1.2, equal SD assumption
# plot results
test.z(x ~ group, sigma = 1.2, data = dat1, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("Two-sample_z-test.png", dpi = 600, width = 4, height = 6)

# Example 2i: Two-sided two-sample z-test
# population standard deviation (SD) = 1.2, equal SD assumption
# extract plot
p &lt;- test.z(x ~ group, sigma = 1.2, data = dat1, output = FALSE)$plot
p

## End(Not run)

#-----------------

group1 &lt;- c(3, 1, 4, 2, 5, 3, 6, 7)
group2 &lt;- c(5, 2, 4, 3, 1)

# Example 2j: Two-sided two-sample z-test
# population standard deviation (SD) = 1.2, equal SD assumption
test.z(group1, group2, sigma = 1.2)

#-------------------------------------------------------------------------------
# Paired-Sample Design

dat2 &lt;- data.frame(pre = c(1, 3, 2, 5, 7),
                   post = c(2, 2, 1, 6, 8), stringsAsFactors = FALSE)

# Example 3a: Two-sided paired-sample z-test
# population standard deviation of difference score = 1.2
test.z(dat2$pre, dat2$post, sigma = 1.2, paired = TRUE)

# Example 3b: Two-sided paired-sample z-test
# population variance of difference score = 1.44
test.z(dat2$pre, dat2$post, sigma2 = 1.44, paired = TRUE)

# Example 3c: One-sided paired-sample z-test
# population standard deviation of difference score = 1.2
test.z(dat2$pre, dat2$post, sigma = 1.2, paired = TRUE,
       alternative = "greater")

# Example 3d: Two-sided paired-sample z-test
# population standard deviation of difference score = 1.2
# convert value 1 to NA
test.z(dat2$pre, dat2$post, sigma = 1.2, as.na = 1, paired = TRUE)

# Example 3e: Two-sided paired-sample z-test
# population standard deviation of difference score = 1.2
# print Cohen's d
test.z(dat2$pre, dat2$post, sigma = 1.2, paired = TRUE, effsize = TRUE)

# Example 3f: Two-sided paired-sample z-test
# population standard deviation of difference score = 1.2
# do not print hypotheses and descriptive statistics
test.z(dat2$pre, dat2$post, sigma = 1.2, mu = 3, paired = TRUE,
       hypo = FALSE, descript = FALSE)

# Example 3g: Two-sided paired-sample z-test
# population standard deviation of difference score = 1.2
# print descriptive statistics with 3 digits and p-value with 5 digits
test.z(dat2$pre, dat2$post, sigma = 1.2, paired = TRUE,
       digits = 3, p.digits = 5)

## Not run: 
# Example 3h: Two-sided paired-sample z-test
# population standard deviation of difference score = 1.2
# plot results
test.z(dat2$pre, dat2$post, sigma = 1.2, paired = TRUE, plot = TRUE)

# Load ggplot2 package
library(ggplot2)

# Save plot, ggsave() from the ggplot2 package
ggsave("Paired-sample_z-test.png", dpi = 600, width = 3, height = 6)

# Example 3i: Two-sided paired-sample z-test
# population standard deviation of difference score = 1.2
# extract plot
p &lt;- test.z(dat2$pre, dat2$post, sigma = 1.2, paired = TRUE, output = FALSE)$plot
p

# Extract data
plotdat &lt;- data.frame(test.z(dat2$pre, dat2$post, sigma = 1.2, paired = TRUE,
                      output = FALSE)$data)

# Difference score
plotdat$diff &lt;- plotdat$y - plotdat$x

# Extract results
result &lt;- test.z(dat2$pre, dat2$post, sigma = 1.2, paired = TRUE,
                  output = FALSE)$result

# Draw plot in line with the default setting of test.t()
ggplot(plotdat, aes(0, diff)) +
  geom_point(data = result, aes(x = 0, m.diff), size = 4) +
  geom_errorbar(data = result,
                aes(x = 0L, y = m.diff, ymin = m.low, ymax = m.upp), width = 0.2) +
   scale_x_continuous(name = NULL, limits = c(-2, 2)) +
   scale_y_continuous(name = "y") +
   geom_hline(yintercept = 0, linetype = 3, linewidth = 0.8) +
   labs(subtitle = "Two-Sided 95
   theme_bw() + theme(plot.subtitle = element_text(hjust = 0.5),
                      axis.text.x = element_blank(),
                      axis.ticks.x = element_blank())

## End(Not run)
</code></pre>

<hr>
<h2 id='write.dta'>Write Stata DTA File</h2><span id='topic+write.dta'></span>

<h3>Description</h3>

<p>This function writes a data frame or matrix into a Stata data file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.dta(x, file = "Stata_Data.dta", version = 14, label = NULL,
          str.thres = 2045, adjust.tz = TRUE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.dta_+3A_x">x</code></td>
<td>
<p>a matrix or data frame to be written in Stata, vectors are
coerced to a data frame.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without file extension
'.dta', e.g., <code>"Stata_Data.dta"</code> or <code>"Stata_Data"</code>.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_version">version</code></td>
<td>
<p>Stats file version to use. Supports versions 8-15.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_label">label</code></td>
<td>
<p>Sataset label to use, or <code>NULL</code>. Defaults to the value
stored in the &quot;label&quot; attribute pf data. Must be &lt;= 80
characters.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_str.thres">str.thres</code></td>
<td>
<p>any chracter vector with a maximum length greater than
<code>str.thre</code> bytes wil be stored as a long string
<code>strL</code> instead of a standard string <code>str</code>
variable if <code>version</code> is greater or equal 13.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_adjust.tz">adjust.tz</code></td>
<td>
<p>this argument controls how the timezone of date-time values
is treated when writing, see 'Details' in the
in the <code><a href="haven.html#topic+write_dta">write_dta</a></code> function in the <code>havan</code>
package.</p>
</td></tr>
<tr><td><code id="write.dta_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), variable attributes
specified in the argument <code>var.attr</code> is checked.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is a modified copy of the <code>read_dta()</code> function in the
<span class="pkg">haven</span> package by Hadley Wickham, Evan Miller and Danny Smith (2023).
</p>


<h3>Author(s)</h3>

<p>Hadley Wickham, Evan Miller and Danny Smith
</p>


<h3>References</h3>

<p>Wickham H, Miller E, Smith D (2023). <em>haven: Import and Export 'SPSS',
'Stata' and 'SAS' Files</em>. R package version 2.5.3.
<a href="https://CRAN.R-project.org/package=haven">https://CRAN.R-project.org/package=haven</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.dta">read.dta</a></code>, <code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+write.mplus">write.mplus</a></code>,
<code><a href="#topic+write.xlsx">write.xlsx</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Example 1: Write data frame 'mtcars' into the State data file 'mtcars.dta'
write.dta(mtcars, "mtcars.dta")

## End(Not run)
</code></pre>

<hr>
<h2 id='write.mplus'>Write Mplus Data File</h2><span id='topic+write.mplus'></span>

<h3>Description</h3>

<p>This function writes a matrix or data frame to a tab-delimited file without variable
names, a Mplus input template, and a text file with variable names. Note that only
numeric variables are allowed, i.e., non-numeric variables will be removed from
the data set. Missing data will be coded as a single numeric value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.mplus(x, file = "Mplus_Data.dat", input = TRUE, n.var = 8,
            var = FALSE, na = -99, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.mplus_+3A_x">x</code></td>
<td>
<p>a matrix or data frame to be written to a tab-delimited file.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without the file extension
'.dat', e.g., <code>"Mplus_Data.dat"</code> or <code>"Mplus_Data"</code>.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_input">input</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), Mplus input template is written
in a text file named according to the argument<code>file</code> with the
extension <code>_INPUT.inp</code>.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_n.var">n.var</code></td>
<td>
<p>a numeric value indicating the number of variables in each line
under <code>NAMES ARE</code> in the the Mplus input template.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_var">var</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable names are written in a text file
named according to the argument<code>file</code> with the extension
<code>_VARNAMES.txt</code>.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_na">na</code></td>
<td>
<p>a numeric value or character string representing missing values
(<code>NA</code>) in the data set.</p>
</td></tr>
<tr><td><code id="write.mplus_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>Muthen, L. K., &amp; Muthen, B. O. (1998-2017). <em>Mplus User's Guide</em> (8th ed.).
Muthen &amp; Muthen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.mplus">read.mplus</a></code>, <code><a href="#topic+run.mplus">run.mplus</a></code>, <code><a href="#topic+write.sav">write.sav</a></code>,
<code><a href="#topic+write.xlsx">write.xlsx</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Write Mplus Data File and a Mplus input template
write.mplus(mtcars)

# Example 2: Write Mplus Data File "mtcars.dat" and a Mplus input template "mtcars_INPUT.inp",
# missing values coded with -999, 4 variables in each line under "NAMES ARE"
# write variable names in a text file called "mtcars_VARNAMES.inp"
write.mplus(mtcars, file = "mtcars.dat", n.var = 4, var = TRUE, na = -999)

## End(Not run)
</code></pre>

<hr>
<h2 id='write.result'>Write Results of a misty Object into an Excel file</h2><span id='topic+write.result'></span>

<h3>Description</h3>

<p>This function writes the results of a misty object (<code>misty.object</code>)
into a Excel file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.result(x, file = "Results.xlsx", tri = x$args$tri,
             digits = x$args$digits, p.digits = x$args$p.digits,
             icc.digits = x$args$icc.digits, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.result_+3A_x">x</code></td>
<td>
<p>misty object (<code>misty.object</code>) resulting from a misty function
supported by the <code>write.result</code> function (see 'Details').</p>
</td></tr>
<tr><td><code id="write.result_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without file extension
'.xlsx', e.g., <code>"Results.xlsx"</code> or <code>"Results"</code>.</p>
</td></tr>
<tr><td><code id="write.result_+3A_tri">tri</code></td>
<td>
<p>a character string or character vector indicating which triangular
of the matrix to show on the console, i.e., <code>both</code> for upper and lower
triangular, <code>lower</code> for the lower triangular, and <code>upper</code> for the upper
triangular.</p>
</td></tr>
<tr><td><code id="write.result_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places digits
to be used for displaying results.</p>
</td></tr>
<tr><td><code id="write.result_+3A_p.digits">p.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying <em>p</em>-values.</p>
</td></tr>
<tr><td><code id="write.result_+3A_icc.digits">icc.digits</code></td>
<td>
<p>an integer indicating the number of decimal places to be used
for displaying intraclass correlation coefficients.</p>
</td></tr>
<tr><td><code id="write.result_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently the function supports result objects from the function
<code>cor.matrix</code>, <code>crosstab</code>, <code>descript</code>, <code>dominance.manual</code>,
<code>dominance</code>, <code>effsize</code>, <code>freq</code>, <code>item.alpha</code>, <code>item.cfa</code>,
<code>item.invar</code>, <code>item.omega</code>, <code>result.lca</code>, <code>multilevel.cfa</code>,
<code>multilevel.cor</code>, <code>multilevel.descript</code>, <code>multilevel.fit</code>,
<code>multilevel.invar</code>, <code>multilevel.omega</code>, <code>na.coverage</code>,
<code>na.descript</code>, <code>na.pattern</code>, <code>robust.coef</code>, and <code>std.coef</code>.
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cor.matrix">cor.matrix</a></code>, <code><a href="#topic+crosstab">crosstab</a></code>, <code><a href="#topic+descript">descript</a></code>,
<code><a href="#topic+dominance.manual">dominance.manual</a></code>, <code><a href="#topic+dominance">dominance</a></code>, <code><a href="#topic+effsize">effsize</a></code>,
<code><a href="#topic+freq">freq</a></code>, <code><a href="#topic+item.alpha">item.alpha</a></code>, <code><a href="#topic+item.cfa">item.cfa</a></code>, <code><a href="#topic+item.invar">item.invar</a></code>,
<code><a href="#topic+item.omega">item.omega</a></code>, <code><a href="#topic+result.lca">result.lca</a></code>, <code><a href="#topic+multilevel.cfa">multilevel.cfa</a></code>,
<code><a href="#topic+multilevel.cor">multilevel.cor</a></code>, <code><a href="#topic+multilevel.descript">multilevel.descript</a></code>, <code><a href="#topic+multilevel.fit">multilevel.fit</a></code>,
<code><a href="#topic+multilevel.invar">multilevel.invar</a></code>, <code><a href="#topic+multilevel.omega">multilevel.omega</a></code>, <code><a href="#topic+na.coverage">na.coverage</a></code>,
<code><a href="#topic+na.descript">na.descript</a></code>, <code><a href="#topic+na.pattern">na.pattern</a></code>, <code><a href="#topic+robust.coef">robust.coef</a></code>, <code><a href="#topic+std.coef">std.coef</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#----------------------------------------------------------------------------
# Example 1: item.cfa() function

# Load data set "HolzingerSwineford1939" in the lavaan package
data("HolzingerSwineford1939", package = "lavaan")

result &lt;- item.cfa(HolzingerSwineford1939[, c("x1", "x2", "x3")], output = FALSE)
write.result(result, "CFA.xlsx")

#----------------------------------------------------------------------------
# Example 2: multilevel.descript() function

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

result &lt;- multilevel.descript(y1:y3, data = Demo.twolevel, cluster = "cluster",
                              output = FALSE)
write.result(result, "Multilevel_Descript.xlsx")

## End(Not run)
</code></pre>

<hr>
<h2 id='write.sav'>Write SPSS File</h2><span id='topic+write.sav'></span>

<h3>Description</h3>

<p>This function writes a data frame or matrix into a SPSS file by either using the
<code>write_sav()</code> function in the <span class="pkg">haven</span> package by Hadley Wickham and Evan
Miller (2019) or the free software <em>PSPP</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.sav(x, file = "SPSS_Data.sav", var.attr = NULL, pspp.path = NULL,
          digits = 2, write.csv = FALSE, sep = c(";", ","), na = "",
          write.sps = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.sav_+3A_x">x</code></td>
<td>
<p>a matrix or data frame to be written in SPSS, vectors are
coerced to a data frame.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without file extension
'.sav', e.g., <code>"SPSS_Data.sav"</code> or <code>"SPSS_Data"</code>.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_var.attr">var.attr</code></td>
<td>
<p>a matrix or data frame with variable attributes used in the
SPSS file, only 'variable labels' (column name <code>label</code>),
'value labels' column name <code>values</code>, and 'user-missing values'
column name <code>missing</code> are supported (see 'Details').</p>
</td></tr>
<tr><td><code id="write.sav_+3A_pspp.path">pspp.path</code></td>
<td>
<p>a character string indicating the path where the PSPP folder
is located on the computer, e.g.<code>C:/Program Files/PSPP/</code>.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_digits">digits</code></td>
<td>
<p>an integer value indicating the number of decimal places shown
in the SPSS file for non-integer variables.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_write.csv">write.csv</code></td>
<td>
<p>logical: if <code>TRUE</code>, CSV file is written along with the
SPSS file.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_sep">sep</code></td>
<td>
<p>a character string for specifying the CSV file, either <code>";"</code>
for the separator and <code>"."</code>
for the decimal point (default, i.e. equivalent to <code>write.csv2</code>)
or <code>"."</code> for the decimal point and <code>","</code> for the
separator (i.e. equivalent to <code>write.csv</code>), must be one
of both <code>";"</code> (default) or <code>","</code>.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_na">na</code></td>
<td>
<p>a character string for specifying missing values in the CSV file.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_write.sps">write.sps</code></td>
<td>
<p>logical: if <code>TRUE</code>, SPSS syntax is written along with
the SPSS file when using PSPP.</p>
</td></tr>
<tr><td><code id="write.sav_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code>, variable attributes specified in the
argument <code>var.attr</code> is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If arguments <code>pspp.path</code> is not specified (i.e., <code>pspp.path = NULL</code>),
<code>write_sav()</code> function in the <span class="pkg">haven</span> is used. Otherwise the object <code>x</code>
is written as CSV file, which is subsequently imported into SPSS using the free
software <em>PSPP</em> by executing a SPSS syntax written in R. Note that <em>PSPP</em>
needs to be installed on your computer when using the <code>pspp.path</code> argument.
</p>
<p>A SPSS file with 'variable labels', 'value labels', and 'user-missing values' is
written by specifying the <code>var.attr</code> argument. Note that the number of rows
in the matrix or data frame specified in <code>var.attr</code> needs to match with the
number of columns in the data frame or matrix specified in <code>x</code>, i.e., each
row in <code>var.attr</code> represents the variable attributes of the corresponding
variable in <code>x</code>. In addition, column names of the matrix or data frame
specified in <code>var.attr</code> needs to be labeled as <code>label</code> for 'variable
labels, <code>values</code> for 'value labels', and <code>missing</code> for 'user-missing
values'.
</p>
<p>Labels for the values are defined in the column <code>values</code> of the matrix or
data frame in <code>var.attr</code> using the equal-sign (e.g., <code>0 = female</code>) and
are separated by a semicolon (e.g., <code>0 = female; 1 = male</code>).
</p>
<p>User-missing values are defined in the column <code>missing</code> of the matrix or
data frame in <code>var.attr</code>, either specifying one user-missing value (e.g.,
<code>-99</code>) or more than one but up to three user-missing values separated
by a semicolon (e.g., <code>-77; -99</code>.
</p>


<h3>Note</h3>

<p>Part of the function using <em>PSPP</em> was adapted from the <code>write.pspp()</code>
function in the <span class="pkg">miceadds</span> package by Alexander Robitzsch, Simon Grund and
Thorsten Henke (2019).
</p>


<h3>Author(s)</h3>

<p>Takuya Yanagida <a href="mailto:takuya.yanagida@univie.ac.at">takuya.yanagida@univie.ac.at</a>
</p>


<h3>References</h3>

<p>GNU Project (2018). <em>GNU PSPP for GNU/Linux</em> (Version 1.2.0).
Boston, MA: Free Software Foundation. <a href="https://www.gnu.org/software/pspp/">https://www.gnu.org/software/pspp/</a>
</p>
<p>Wickham H., &amp; Miller, E. (2019). <em>haven: Import and Export 'SPSS', 'Stata'
and 'SAS' Files</em>. R package version 2.2.0.
</p>
<p>Robitzsch, A., Grund, S., &amp; Henke, T. (2019). <em>miceadds: Some additional
multiple imputation functions, especially for mice</em>. R package version 3.4-17.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.sav">read.sav</a></code>, <code><a href="#topic+write.xlsx">write.xlsx</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>,
<code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- data.frame(id = 1:5,
                  gender = c(NA, 0, 1, 1, 0),
                  age = c(16, 19, 17, NA, 16),
                  status = c(1, 2, 3, 1, 4),
                  score = c(511, 506, 497, 502, 491))

# Example 1: Write SPSS file using the haven package
write.sav(dat, file = "Dataframe_haven.sav")

# Example 2: Write SPSS file using PSPP,
# write CSV file and SPSS syntax along with the SPSS file
write.sav(dat, file = "Dataframe_PSPP.sav", pspp.path = "C:/Program Files/PSPP",
          write.csv = TRUE, write.sps = TRUE)

# Example 3: Specify variable attributes
# Note that it is recommended to manually specify the variables attritbues in a CSV or
# Excel file which is subsequently read into R
attr &lt;- data.frame(# Variable names
                   var = c("id", "gender", "age", "status", "score"),
                   # Variable labels
                   label = c("Identification number", "Gender", "Age in years",
                             "Migration background", "Achievement test score"),
                   # Value labels
                   values = c("", "0 = female; 1 = male", "",
                              "1 = Austria; 2 = former Yugoslavia; 3 = Turkey; 4 = other",
                              ""),
                   # User-missing values
                   missing = c("", "-99", "-99", "-99", "-99"), stringsAsFactors = FALSE)

# Example 4: Write SPSS file with variable attributes using the haven package
write.sav(dat, file = "Dataframe_haven_Attr.sav", var.attr = attr)

# Example 5: Write SPSS with variable attributes using PSPP
write.sav(dat, file = "Dataframe_PSPP_Attr.sav", var.attr = attr,
          pspp.path = "C:/Program Files/PSPP")

## End(Not run)
</code></pre>

<hr>
<h2 id='write.xlsx'>Write Excel File</h2><span id='topic+write.xlsx'></span>

<h3>Description</h3>

<p>This function calls the <code>write_xlsx()</code> function in the <span class="pkg">writexl</span> package
by Jeroen Ooms to write an Excel file (.xlsx).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.xlsx(x, file = "Excel_Data.xlsx", col.names = TRUE, format = FALSE,
           use.zip64 = FALSE, check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.xlsx_+3A_x">x</code></td>
<td>
<p>a matrix, data frame or (named) list of matrices or data frames
that will be written in the Excel file.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_file">file</code></td>
<td>
<p>a character string naming a file with or without file extension
'.xlsx', e.g., <code>"My_Excle.xlsx"</code> or <code>"My_Excel"</code>.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_col.names">col.names</code></td>
<td>
<p>logical: if <code>TRUE</code>, column names are written at the top
of the Excel sheet.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_format">format</code></td>
<td>
<p>logical: if <code>TRUE</code>, column names in the Excel file are
centered and bold.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_use.zip64">use.zip64</code></td>
<td>
<p>logical: if <code>TRUE</code>, zip64 to enable support for 4GB+ Excel
files is used.</p>
</td></tr>
<tr><td><code id="write.xlsx_+3A_check">check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function supports strings, numbers, booleans, and dates.
</p>


<h3>Note</h3>

<p>The function was adapted from the <code>write_xlsx()</code> function in the <span class="pkg">writexl</span>
package by Jeroen Ooms (2021).
</p>


<h3>Author(s)</h3>

<p>Jeroen Ooms
</p>


<h3>References</h3>

<p>Jeroen O. (2021). <em>writexl: Export Data Frames to Excel 'xlsx' Format</em>.
R package version 1.4.0. https://CRAN.R-project.org/package=writexl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.xlsx">read.xlsx</a></code>, <code><a href="#topic+write.sav">write.sav</a></code>, <code><a href="#topic+write.dta">write.dta</a></code>,
<code><a href="#topic+write.mplus">write.mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Write Excel file (.xlsx)
dat &lt;- data.frame(id = 1:5,
                  gender = c(NA, 0, 1, 1, 0),
                  age = c(16, 19, 17, NA, 16),
                  status = c(1, 2, 3, 1, 4),
                  score = c(511, 506, 497, 502, 491))

write.xlsx(dat, file = "Excel.xlsx")

# Example 2: Write Excel file with multiple sheets (.xlsx)
write.xlsx(list(cars = cars, mtcars = mtcars), file = "Excel_Sheets.xlsx")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
