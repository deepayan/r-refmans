<!DOCTYPE html><html lang="en"><head><title>Help for package SLmetrics</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SLmetrics}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SLmetrics-package'><p>SLmetrics: Machine Learning Performance Evaluation on Steroids</p></a></li>
<li><a href='#accuracy.factor'><p>Accuracy</p></a></li>
<li><a href='#auc.numeric'><p>AUC</p></a></li>
<li><a href='#baccuracy.factor'><p>Balanced Accuracy</p></a></li>
<li><a href='#banknote'><p>Banknote Authentication Dataset</p></a></li>
<li><a href='#ccc.numeric'><p>Concordance Correlation Coefficient</p></a></li>
<li><a href='#ckappa.factor'><p>Cohen's <code class="reqn">\kappa</code>-statistic</p></a></li>
<li><a href='#cmatrix.factor'><p>Confusion Matrix</p></a></li>
<li><a href='#cov.wt.matrix'><p>Weighted Covariance Matrices</p></a></li>
<li><a href='#dor.factor'><p>Diagnostic Odds Ratio</p></a></li>
<li><a href='#entropy.matrix'><p>Entropy</p></a></li>
<li><a href='#fbeta.factor'><p><code class="reqn">F_{\beta}</code>-score</p></a></li>
<li><a href='#fdr.factor'><p>false discovery rate</p></a></li>
<li><a href='#fer.factor'><p>False Omission Rate</p></a></li>
<li><a href='#fmi.factor'><p>Fowlkes-Mallows Index</p></a></li>
<li><a href='#fpr.factor'><p>False Positive Rate</p></a></li>
<li><a href='#huberloss.numeric'><p>Huber Loss</p></a></li>
<li><a href='#jaccard.factor'><p>Jaccard Index</p></a></li>
<li><a href='#logloss.factor'><p>Log Loss</p></a></li>
<li><a href='#mae.numeric'><p>Mean Absolute Error</p></a></li>
<li><a href='#mape.numeric'><p>Mean Absolute Percentage Error</p></a></li>
<li><a href='#mcc.factor'><p>Matthews Correlation Coefficient</p></a></li>
<li><a href='#mpe.numeric'><p>Mean Percentage Error</p></a></li>
<li><a href='#mse.numeric'><p>Mean Squared Error</p></a></li>
<li><a href='#nlr.factor'><p>Negative Likelihood Ratio</p></a></li>
<li><a href='#npv.factor'><p>Negative Predictive Value</p></a></li>
<li><a href='#obesity'><p>Obesity Levels Dataset</p></a></li>
<li><a href='#openmp.on'><p>Use OpenMP</p></a></li>
<li><a href='#pinball.numeric'><p>Pinball Loss</p></a></li>
<li><a href='#plr.factor'><p>Positive Likelihood Ratio</p></a></li>
<li><a href='#pr.auc.matrix'><p>Area under the Precision-Recall Curve</p></a></li>
<li><a href='#precision.factor'><p>Precision</p></a></li>
<li><a href='#preorder'><p>Preorder</p></a></li>
<li><a href='#presort'><p>Presort</p></a></li>
<li><a href='#prROC.factor'><p>Precision-Recall Curve</p></a></li>
<li><a href='#rae.numeric'><p>Relative Absolute Error</p></a></li>
<li><a href='#recall.factor'><p>Recall</p></a></li>
<li><a href='#rmse.numeric'><p>Root Mean Squared Error</p></a></li>
<li><a href='#rmsle.numeric'><p>Root Mean Squared Logarithmic Error</p></a></li>
<li><a href='#roc.auc.matrix'><p>Area under the Receiver Operator Characteristics Curve</p></a></li>
<li><a href='#ROC.factor'><p>Receiver Operator Characteristics</p></a></li>
<li><a href='#rrmse.numeric'><p>Relative Root Mean Squared Error</p></a></li>
<li><a href='#rrse.numeric'><p>Root Relative Squared Error</p></a></li>
<li><a href='#rsq.numeric'><p><code class="reqn">R^2</code></p></a></li>
<li><a href='#smape.numeric'><p>Symmetric Mean Absolutte Percentage Error</p></a></li>
<li><a href='#specificity.factor'><p>Specificity</p></a></li>
<li><a href='#wine_quality'><p>Wine Quality Dataset</p></a></li>
<li><a href='#zerooneloss.factor'><p>Zero-One Loss</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Machine Learning Performance Evaluation on Steroids</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3-3</td>
</tr>
<tr>
<td>Description:</td>
<td>
  Performance evaluation metrics for supervised and unsupervised machine learning, statistical learning and artificial intelligence applications. Core computations are implemented in 'C++' for scalability and efficiency.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, reticulate, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, lattice, Rcpp</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://serkor1.github.io/SLmetrics/">https://serkor1.github.io/SLmetrics/</a>,
<a href="https://github.com/serkor1/SLmetrics">https://github.com/serkor1/SLmetrics</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/serkor1/SLmetrics/issues">https://github.com/serkor1/SLmetrics/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-17 13:41:49 UTC; serkan</td>
</tr>
<tr>
<td>Author:</td>
<td>Serkan Korkmaz <a href="https://orcid.org/0000-0002-5052-0982"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Serkan Korkmaz &lt;serkor1@duck.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-18 15:20:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='SLmetrics-package'>SLmetrics: Machine Learning Performance Evaluation on Steroids</h2><span id='topic+SLmetrics'></span><span id='topic+SLmetrics-package'></span>

<h3>Description</h3>

<p>{SLmetrics} is a lightweight package written in C++ for supervised and unsupervised Machine Learning applications. The package has been
developed with two primary goals in mind: memory management and execution speed. All functions are designed with internal pointers and references,
ensuring that passed objects are not copied into memory, resulting in optimized performance.
</p>


<h3>Handling of Missing Values</h3>

<p>{SLmetrics} does not provide explicit handling for missing values in either regression or classification applications. Users are advised
to ensure that their input data is preprocessed to remove or impute missing values before passing them to any functions.
</p>
<p>Since the package heavily relies on pointers and references for performance, passing data with missing values may lead to undefined behavior,
including potential crashes of the R session.
</p>
<p>For classification metrics that support micro and macro averages, {SLmetrics} does handle invalid values such as divisions by zero,
ensuring robust computation and accurate results.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Serkan Korkmaz <a href="mailto:serkor1@duck.com">serkor1@duck.com</a> (<a href="https://orcid.org/0000-0002-5052-0982">ORCID</a>) [copyright holder]
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://serkor1.github.io/SLmetrics/">https://serkor1.github.io/SLmetrics/</a>
</p>
</li>
<li> <p><a href="https://github.com/serkor1/SLmetrics">https://github.com/serkor1/SLmetrics</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/serkor1/SLmetrics/issues">https://github.com/serkor1/SLmetrics/issues</a>
</p>
</li></ul>


<hr>
<h2 id='accuracy.factor'>Accuracy</h2><span id='topic+accuracy.factor'></span><span id='topic+weighted.accuracy.factor'></span><span id='topic+accuracy.cmatrix'></span><span id='topic+accuracy'></span><span id='topic+weighted.accuracy'></span>

<h3>Description</h3>

<p>A generic function for the (normalized) <a href="https://developers.google.com/machine-learning/glossary#accuracy">accuracy</a> in classification tasks.
Use <code><a href="#topic+weighted.accuracy">weighted.accuracy()</a></code> for the weighted <a href="https://developers.google.com/machine-learning/glossary#accuracy">accuracy</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
accuracy(actual, predicted, ...)

## S3 method for class 'factor'
weighted.accuracy(actual, predicted, w, ...)

## S3 method for class 'cmatrix'
accuracy(x, ...)

## Generic S3 method
accuracy(...)

## Generic S3 method
weighted.accuracy(
...,
w
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="accuracy.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="accuracy.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="accuracy.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="accuracy.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default</p>
</td></tr>
<tr><td><code id="accuracy.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\alpha} \in [0, 1]</code> be the proportion of correctly predicted classes. The <a href="https://developers.google.com/machine-learning/glossary#accuracy">accuracy</a> of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\alpha} = \frac{\#TP + \#TN}{\#TP + \#TN + \#FP + \#FN}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TP</code> is the number of true positives,
</p>
</li>
<li> <p><code class="reqn">\#TN</code> is the number of true negatives,
</p>
</li>
<li> <p><code class="reqn">\#FP</code> is the number of false positives, and
</p>
</li>
<li> <p><code class="reqn">\#FN</code> is the number of false negatives.
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate model
# performance
cat(
  "Accuracy", accuracy(
    actual    = actual,
    predicted = predicted
  ),

  "Accuracy (weigthed)", weighted.accuracy(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length)
  ),
  sep = "\n"
)

</code></pre>

<hr>
<h2 id='auc.numeric'>AUC</h2><span id='topic+auc.numeric'></span><span id='topic+auc'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+auc">auc()</a></code>-function calculates the area under the curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
auc(y, x, method = 0L, presorted = TRUE, ...)

## Generic S3 method
auc(
 y,
 x,
 method = 0,
 presorted = TRUE,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="auc.numeric_+3A_y">y</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="auc.numeric_+3A_x">x</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="auc.numeric_+3A_method">method</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; value (default: <code class="reqn">0</code>). Defines the underlying method of calculating the area under the curve. If <code class="reqn">0</code> it is calculated using the <code>trapezoid</code>-method, if <code class="reqn">1</code> it is calculated using the <code>step</code>-method.</p>
</td></tr>
<tr><td><code id="auc.numeric_+3A_presorted">presorted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value <a href="base.html#topic+length">length</a> 1 (default: <a href="base.html#topic+FALSE">FALSE</a>). If <a href="base.html#topic+TRUE">TRUE</a> the input will not be sorted by threshold.</p>
</td></tr>
<tr><td><code id="auc.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;  vector  of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p><strong>Trapezoidal rule</strong>
</p>
<p>The <strong>trapezoidal rule</strong> approximates the integral of a function <code class="reqn">f(x)</code> between
<code class="reqn">x = a</code> and <code class="reqn">x = b</code> using trapezoids formed between consecutive points. If
we have points <code class="reqn">x_0, x_1, \ldots, x_n</code> (with <code class="reqn">a = x_0 &lt; x_1 &lt; \cdots &lt; x_n = b</code>)
and corresponding function values <code class="reqn">f(x_0), f(x_1), \ldots, f(x_n)</code>, the area under
the curve <code class="reqn">A_T</code> is approximated by:
</p>
<p style="text-align: center;"><code class="reqn">
  A_T \approx \sum_{k=1}^{n} \frac{f(x_{k-1}) + f(x_k)}{2} \bigl[x_k - x_{k-1}\bigr].
</code>
</p>

<p><strong>Step-function method</strong>
</p>
<p>The <strong>step-function (rectangular) method</strong> uses the value of the function at one
endpoint of each subinterval to form rectangles. With the same partition
<code class="reqn">x_0, x_1, \ldots, x_n</code>, the rectangular approximation <code class="reqn">A_S</code> can be written as:
</p>
<p style="text-align: center;"><code class="reqn">
  A_S \approx \sum_{k=1}^{n} f(x_{k-1}) \bigl[x_k - x_{k-1}\bigr].
</code>
</p>



<h3>See Also</h3>

<p>Other Tools: 
<code><a href="#topic+cov.wt.matrix">cov.wt.matrix</a>()</code>,
<code><a href="#topic+preorder">preorder</a>()</code>,
<code><a href="#topic+presort">presort</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1) Ordered x and y pair
x &lt;- seq(0, pi, length.out = 200)
y &lt;- sin(x)

## 1.1) calculate area
ordered_auc &lt;- auc(y = y,  x = x)

## 2) Unordered x and y pair
x &lt;- sample(seq(0, pi, length.out = 200))
y &lt;- sin(x)

## 2.1) calculate area
unordered_auc &lt;- auc(y = y,  x = x)

## 2.2) calculate area with explicit
## ordering
unordered_auc_flag &lt;- auc(
  y = y,
  x = x,
  presorted = FALSE
)

## 3) display result
cat(
  "AUC (ordered x and y pair)", ordered_auc,
  "AUC (unordered x and y pair)", unordered_auc,
  "AUC (unordered x and y pair, with unordered flag)", unordered_auc_flag,
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='baccuracy.factor'>Balanced Accuracy</h2><span id='topic+baccuracy.factor'></span><span id='topic+weighted.baccuracy.factor'></span><span id='topic+baccuracy.cmatrix'></span><span id='topic+baccuracy'></span><span id='topic+weighted.baccuracy'></span>

<h3>Description</h3>

<p>A generic function for the (normalized) balanced <a href="https://arxiv.org/abs/2008.05756">accuracy</a>.
Use <code><a href="#topic+weighted.baccuracy">weighted.baccuracy()</a></code> for the weighted balanced <a href="https://arxiv.org/abs/2008.05756">accuracy</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
baccuracy(actual, predicted, adjust = FALSE, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.baccuracy(actual, predicted, w, adjust = FALSE, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
baccuracy(x, adjust = FALSE, na.rm = TRUE, ...)

## Generic S3 method
baccuracy(
  ...,
  adjust = FALSE,
  na.rm  = TRUE
)

## Generic S3 method
weighted.baccuracy(
  ...,
  w,
  adjust = FALSE,
  na.rm  = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="baccuracy.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="baccuracy.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="baccuracy.factor_+3A_adjust">adjust</code></td>
<td>
<p>A <a href="base.html#topic+logical">logical</a> value (default: <a href="base.html#topic+FALSE">FALSE</a>). If <a href="base.html#topic+TRUE">TRUE</a> the metric is adjusted for random chance <code class="reqn">\frac{1}{k}</code>.</p>
</td></tr>
<tr><td><code id="baccuracy.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A <a href="base.html#topic+logical">logical</a> value (default: <a href="base.html#topic+TRUE">TRUE</a>).  If <a href="base.html#topic+TRUE">TRUE</a> calculation of the metric is based on valid classes.</p>
</td></tr>
<tr><td><code id="baccuracy.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="baccuracy.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default</p>
</td></tr>
<tr><td><code id="baccuracy.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="base.html#topic+numeric">numeric</a>-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\alpha} \in [0, 1]</code> be the proportion of correctly predicted classes. If <code>adjust == false</code>, the balanced <a href="https://arxiv.org/abs/2008.05756">accuracy</a> of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\alpha} = \frac{\text{sensitivity} + \text{specificity}}{2}
</code>
</p>

<p>otherwise,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\alpha} = \frac{\text{sensitivity} + \text{specificity}}{2} \frac{1}{k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">k</code> is the number of classes
</p>
</li>
<li> <p><code class="reqn">\text{sensitivity}</code> is the overall <a href="https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall#recall_or_true_positive_rate">sensitivity</a>, and
</p>
</li>
<li> <p><code class="reqn">\text{specificity}</code> is the overall <a href="https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall#recall_or_true_positive_rate">specificity</a>
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate the
# model
cat(
  "Balanced accuracy", baccuracy(
    actual    = actual,
    predicted = predicted
  ),
  
  "Balanced accuracy (weigthed)", weighted.baccuracy(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='banknote'>Banknote Authentication Dataset</h2><span id='topic+banknote'></span>

<h3>Description</h3>

<p>This dataset contains features extracted from the wavelet transform of banknote
images, which are used to classify banknotes as authentic or inauthentic. The data
originates from the UCI Machine Learning Repository.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(banknote)
</code></pre>


<h3>Format</h3>

<p>A list with two components:
</p>

<dl>
<dt>features</dt><dd><p>A data frame with 4 variables: <code>variance</code>, <code>skewness</code>,
<code>curtosis</code>, and <code>entropy</code>.</p>
</dd>
<dt>target</dt><dd><p>A factor with levels <code>"inauthentic"</code> and <code>"authentic"</code>
representing the banknote's authenticity.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data is provided as a list with two components:
</p>

<dl>
<dt>features</dt><dd><p>A data frame containing the following variables:
</p>

<dl>
<dt>variance</dt><dd><p>Variance of the wavelet transformed image.</p>
</dd>
<dt>skewness</dt><dd><p>Skewness of the wavelet transformed image.</p>
</dd>
<dt>curtosis</dt><dd><p>Curtosis of the wavelet transformed image.</p>
</dd>
<dt>entropy</dt><dd><p>Entropy of the image.</p>
</dd>
</dl>

</dd>
<dt>target</dt><dd><p>A factor indicating the authenticity of the banknote. The factor has
two levels:
</p>

<dl>
<dt>inauthentic</dt><dd><p>Indicates the banknote is not genuine.</p>
</dd>
<dt>authentic</dt><dd><p>Indicates the banknote is genuine.</p>
</dd>
</dl>

</dd>
</dl>



<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/dataset/267/banknote+authentication">https://archive.ics.uci.edu/dataset/267/banknote+authentication</a>
</p>

<hr>
<h2 id='ccc.numeric'>Concordance Correlation Coefficient</h2><span id='topic+ccc.numeric'></span><span id='topic+weighted.ccc.numeric'></span><span id='topic+ccc'></span><span id='topic+weighted.ccc'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/Concordance_correlation_coefficient">concordance correlation coefficient</a>. Use <code><a href="#topic+weighted.ccc">weighted.ccc()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/Concordance_correlation_coefficient">concordance correlation coefficient</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
ccc(actual, predicted, correction = FALSE, ...)

## S3 method for class 'numeric'
weighted.ccc(actual, predicted, w, correction = FALSE, ...)

ccc(
 ...,
 correction = FALSE
)

weighted.ccc(
 ...,
 w,
 correction = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ccc.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="ccc.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="ccc.numeric_+3A_correction">correction</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; vector of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+FALSE">FALSE</a>). If <a href="base.html#topic+TRUE">TRUE</a> the variance and covariance
will be adjusted with <code class="reqn">\frac{1-n}{n}</code></p>
</td></tr>
<tr><td><code id="ccc.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="ccc.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\rho_c \in [0,1]</code> measure the agreement between <code class="reqn">y</code> and <code class="reqn">\upsilon</code>. The classifier agreement is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \rho_c = \frac{2 \rho \sigma_{\upsilon} \sigma_y}{\sigma_{\upsilon}^2 + \sigma_y^2 + (\mu_{\upsilon} - \mu_y)^2}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\rho</code> is the pearson correlation coefficient
</p>
</li>
<li> <p><code class="reqn">\sigma_y</code> is the unbiased standard deviation of <code class="reqn">y</code>
</p>
</li>
<li> <p><code class="reqn">\sigma_{\upsilon}</code> is the unbiased standard deviation of <code class="reqn">\upsilon</code>
</p>
</li>
<li> <p><code class="reqn">\mu_y</code> is the mean of <code class="reqn">y</code>
</p>
</li>
<li> <p><code class="reqn">\mu_{\upsilon}</code> is the mean of <code class="reqn">\upsilon</code>
</p>
</li></ul>

<p>If <code>correction == TRUE</code> each <code class="reqn">\sigma_{i \in [y, \upsilon]}</code> is adjusted by <code class="reqn">\frac{1-n}{n}</code>
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance
cat(
  "Concordance Correlation Coefficient", ccc(
    actual     = actual,
    predicted  = predicted,
    correction = FALSE
  ),
  "Concordance Correlation Coefficient (corrected)", ccc(
    actual     = actual,
    predicted  = predicted,
    correction = TRUE
  ),
  "Concordance Correlation Coefficient (weigthed)", weighted.ccc(
    actual     = actual,
    predicted  = predicted,
    w          = mtcars$mpg/mean(mtcars$mpg),
    correction = FALSE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='ckappa.factor'>Cohen's <code class="reqn">\kappa</code>-statistic</h2><span id='topic+ckappa.factor'></span><span id='topic+weighted.ckappa.factor'></span><span id='topic+ckappa.cmatrix'></span><span id='topic+ckappa'></span><span id='topic+weighted.ckappa'></span>

<h3>Description</h3>

<p>A generic function for <a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">Cohen's <code class="reqn">\kappa</code></a>-statistic. Use <code><a href="#topic+weighted.ckappa">weighted.ckappa()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa"><code class="reqn">\kappa</code></a>-statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
ckappa(actual, predicted, beta = 0, ...)

## S3 method for class 'factor'
weighted.ckappa(actual, predicted, w, beta = 0, ...)

## S3 method for class 'cmatrix'
ckappa(x, beta = 0, ...)

ckappa(
 ...,
 beta = 0
)

weighted.ckappa(
 ...,
 w,
 beta = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ckappa.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="ckappa.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="ckappa.factor_+3A_beta">beta</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; value of <a href="base.html#topic+length">length</a> 1 (default: 0). If <code class="reqn">\beta \neq 0</code> the off-diagonals of the confusion matrix are penalized with a factor of <code class="reqn">(y_{+} - y_{i,-})^\beta</code>.</p>
</td></tr>
<tr><td><code id="ckappa.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="ckappa.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="ckappa.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\kappa \in [0, 1]</code> be the inter-rater (intra-rater) reliability. The inter-rater (intra-rater) reliability is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \kappa = \frac{\rho_p - \rho_e}{1-\rho_e}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\rho_p</code> is the empirical probability of agreement between predicted and actual values
</p>
</li>
<li> <p><code class="reqn">\rho_e</code> is the expected probability of agreement under random chance
</p>
</li></ul>

<p>If <code class="reqn">\beta \neq 0</code> the off-diagonals in the confusion matrix is penalized before <code class="reqn">\rho</code> is calculated. More formally,
</p>
<p style="text-align: center;"><code class="reqn">
 \chi = X \circ Y^{\beta}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">X</code> is the confusion matrix
</p>
</li>
<li> <p><code class="reqn">Y</code> is the penalizing matrix and
</p>
</li>
<li> <p><code class="reqn">\beta</code> is the penalizing factor
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate model performance with
# Cohens Kappa statistic
cat(
  "Kappa", ckappa(
    actual    = actual,
    predicted = predicted
  ),
  "Kappa (penalized)", ckappa(
    actual    = actual,
    predicted = predicted,
    beta      = 2
  ),
  "Kappa (weigthed)", weighted.ckappa(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='cmatrix.factor'>Confusion Matrix</h2><span id='topic+cmatrix.factor'></span><span id='topic+weighted.cmatrix.factor'></span><span id='topic+cmatrix'></span><span id='topic+weighted.cmatrix'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+cmatrix">cmatrix()</a></code>-function uses cross-classifying factors to build
a confusion matrix of the counts at each combination of the <a href="base.html#topic+factor">factor</a> levels.
Each row of the <a href="base.html#topic+matrix">matrix</a> represents the actual <a href="base.html#topic+factor">factor</a> levels, while each
column represents the predicted <a href="base.html#topic+factor">factor</a> levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
cmatrix(actual, predicted, ...)

## S3 method for class 'factor'
weighted.cmatrix(actual, predicted, w, ...)

## Generic S3 method
cmatrix(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.cmatrix(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cmatrix.factor_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+factor">factor</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="cmatrix.factor_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+factor">factor</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="cmatrix.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="cmatrix.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code> (default: <a href="base.html#topic+NULL">NULL</a>) If passed it will return a weighted confusion matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named <code class="reqn">k</code> x <code class="reqn">k</code> &lt;<a href="base.html#topic+matrix">matrix</a>&gt;
</p>


<h3>Dimensions</h3>

<p>There is no robust defensive measure against mis-specifying
the confusion matrix. If the arguments are correctly specified, the resulting
confusion matrix is on the form:</p>

<table>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: center;"> A (Predicted) </td><td style="text-align: right;"> B (Predicted) </td>
</tr>
<tr>
 <td style="text-align: left;">
   A (Actual) </td><td style="text-align: center;"> Value </td><td style="text-align: right;"> Value </td>
</tr>
<tr>
 <td style="text-align: left;">
   B (Actual) </td><td style="text-align: center;"> Value </td><td style="text-align: right;"> Value </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) summarise performance
# in a confusion matrix

# 4.1) unweighted matrix
confusion_matrix &lt;- cmatrix(
  actual    = actual,
  predicted = predicted
)

# 4.1.1) summarise matrix
summary(
  confusion_matrix
)

# 4.1.2) plot confusion
# matrix
plot(
  confusion_matrix
)

# 4.2) weighted matrix
confusion_matrix &lt;- weighted.cmatrix(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 4.2.1) summarise matrix
summary(
  confusion_matrix
)

# 4.2.1) plot confusion
# matrix
plot(
  confusion_matrix
)
</code></pre>

<hr>
<h2 id='cov.wt.matrix'>Weighted Covariance Matrices</h2><span id='topic+cov.wt.matrix'></span><span id='topic+cov.wt.data.frame'></span><span id='topic+cov.wt'></span>

<h3>Description</h3>

<p>Returns a list containing estimates of the weighted covariance matrix
and the mean of the data, and optionally of the (weighted) correlation
matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matrix'
cov.wt(x, wt = NULL, cor = FALSE, center = TRUE, method = "unbiased", ...)

## S3 method for class 'data.frame'
cov.wt(x, wt = NULL, cor = FALSE, center = TRUE, method = "unbiased", ...)

cov.wt(
  x,
  wt = NULL,
  cor = FALSE,
  center = TRUE,
  method = c("unbiased", "ML"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov.wt.matrix_+3A_x">x</code></td>
<td>
<p>a matrix or data frame.  As usual, rows are observations and
columns are variables.</p>
</td></tr>
<tr><td><code id="cov.wt.matrix_+3A_wt">wt</code></td>
<td>
<p>a non-negative and non-zero vector of weights for each
observation.  Its length must equal the number of rows of <code>x</code>.</p>
</td></tr>
<tr><td><code id="cov.wt.matrix_+3A_cor">cor</code></td>
<td>
<p>a logical indicating whether the estimated correlation
weighted matrix will be returned as well.</p>
</td></tr>
<tr><td><code id="cov.wt.matrix_+3A_center">center</code></td>
<td>
<p>either a logical or a numeric vector specifying the
centers to be used when computing covariances.  If <code>TRUE</code>, the
(weighted) mean of each variable is used, if <code>FALSE</code>, zero is
used.  If <code>center</code> is numeric, its length must equal the number
of columns of <code>x</code>.</p>
</td></tr>
<tr><td><code id="cov.wt.matrix_+3A_method">method</code></td>
<td>
<p>string specifying how the result is scaled, see
&lsquo;Details&rsquo; below.  Can be abbreviated.</p>
</td></tr>
<tr><td><code id="cov.wt.matrix_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, <code>method = "unbiased"</code>,
The covariance matrix is divided by one minus the sum of squares of
the weights, so if the weights are the default (<code class="reqn">1/n</code>) the conventional
unbiased estimate of the covariance matrix with divisor <code class="reqn">(n - 1)</code>
is obtained.
</p>


<h3>Value</h3>

<p>A list containing the following named components:
</p>
<table role = "presentation">
<tr><td><code>cov</code></td>
<td>
<p>the estimated (weighted) covariance matrix</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>an estimate for the center (mean) of the data.</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>the number of observations (rows) in <code>x</code>.</p>
</td></tr>
<tr><td><code>wt</code></td>
<td>
<p>the weights used in the estimation.  Only returned if given
as an argument.</p>
</td></tr>
<tr><td><code>cor</code></td>
<td>
<p>the estimated correlation matrix.  Only returned if
<code>cor</code> is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Tools: 
<code><a href="#topic+auc.numeric">auc.numeric</a>()</code>,
<code><a href="#topic+preorder">preorder</a>()</code>,
<code><a href="#topic+presort">presort</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(xy &lt;- cbind(x = 1:10, y = c(1:3, 8:5, 8:10)))
 w1 &lt;- c(0,0,0,1,1,1,1,1,0,0)
 cov.wt(xy, wt = w1) # i.e. method = "unbiased"
 cov.wt(xy, wt = w1, method = "ML", cor = TRUE)
</code></pre>

<hr>
<h2 id='dor.factor'>Diagnostic Odds Ratio</h2><span id='topic+dor.factor'></span><span id='topic+weighted.dor.factor'></span><span id='topic+dor.cmatrix'></span><span id='topic+dor'></span><span id='topic+weighted.dor'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/Diagnostic_odds_ratio">diagnostic odds ratio</a> in classification tasks. Use <code><a href="#topic+weighted.dor">weighted.dor()</a></code> weighted <a href="https://en.wikipedia.org/wiki/Diagnostic_odds_ratio">diagnostic odds ratio</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
dor(actual, predicted, ...)

## S3 method for class 'factor'
weighted.dor(actual, predicted, w, ...)

## S3 method for class 'cmatrix'
dor(x, ...)

## Generic S3 method
dor(...)

## Generic S3 method
weighted.dor(
 ...,
 w
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dor.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="dor.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="dor.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="dor.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="dor.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\alpha} \in [0, \infty]</code> be the effectiveness of the classifier.  The <a href="https://en.wikipedia.org/wiki/Diagnostic_odds_ratio">diagnostic odds ratio</a> of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\alpha} = \frac{\text{\#TP} \text{\#TN}}{\text{\#FP} \text{\#FN}}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\text{\#TP}</code> is the number of true positives
</p>
</li>
<li> <p><code class="reqn">\text{\#TN}</code> is the number of true negatives
</p>
</li>
<li> <p><code class="reqn">\text{\#FP}</code> is the number of false positives
</p>
</li>
<li> <p><code class="reqn">\text{\#FN}</code> is the number of false negatives
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)


# 4) evaluate model performance
# with Diagnostic Odds Ratio
cat("Diagnostic Odds Ratio", sep = "\n")
dor(
  actual    = actual, 
  predicted = predicted
)

cat("Diagnostic Odds Ratio (weighted)", sep = "\n")
weighted.dor(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)
</code></pre>

<hr>
<h2 id='entropy.matrix'>Entropy</h2><span id='topic+entropy.matrix'></span><span id='topic+relative.entropy.matrix'></span><span id='topic+cross.entropy.matrix'></span><span id='topic+entropy'></span><span id='topic+relative.entropy'></span><span id='topic+cross.entropy'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+entropy">entropy()</a></code> function calculates the <strong>Entropy</strong> of given probability distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matrix'
entropy(pk, dim = 0L, base = -1, ...)

## S3 method for class 'matrix'
relative.entropy(pk, qk, dim = 0L, base = -1, ...)

## S3 method for class 'matrix'
cross.entropy(pk, qk, dim = 0L, base = -1, ...)

## Generic S3 method
entropy(
 pk,
 dim  = 0,
 base = -1,
 ...
)

## Generic S3 method
relative.entropy(
 pk,
 qk,
 dim  = 0,
 base = -1,
 ...
)

## Generic S3 method
cross.entropy(
 pk,
 qk,
 dim  = 0,
 base = -1,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="entropy.matrix_+3A_pk">pk</code></td>
<td>
<p>A <code class="reqn">n \times k</code> &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-matrix of observed probabilities.
The <code class="reqn">i</code>-th row should sum to 1 (i.e., a valid probability distribution
over the <code class="reqn">k</code> classes). The first column corresponds to the first factor
level in <code>actual</code>, the second column to the second factor level, and so on.</p>
</td></tr>
<tr><td><code id="entropy.matrix_+3A_dim">dim</code></td>
<td>
<p>An &lt;<a href="base.html#topic+integer">integer</a>&gt; value of <a href="base.html#topic+length">length</a> 1 (Default: 0). Defines the dimension along which to calculate the entropy (0: total, 1: row-wise, 2: column-wise).</p>
</td></tr>
<tr><td><code id="entropy.matrix_+3A_base">base</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; value of <a href="base.html#topic+length">length</a> 1 (Default: -1). The logarithmic base to use. Default value specifies natural logarithms.</p>
</td></tr>
<tr><td><code id="entropy.matrix_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="entropy.matrix_+3A_qk">qk</code></td>
<td>
<p>A <code class="reqn">n \times k</code> &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-matrix of predicted probabilities.
The <code class="reqn">i</code>-th row should sum to 1 (i.e., a valid probability distribution
over the <code class="reqn">k</code> classes). The first column corresponds to the first factor
level in <code>actual</code>, the second column to the second factor level, and so on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; value or vector:
</p>

<ul>
<li><p> A single &lt;<a href="base.html#topic+numeric">numeric</a>&gt; value (length 1) if <code>dim == 0</code>.
</p>
</li>
<li><p> A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector with length equal to the <a href="base.html#topic+length">length</a> of rows if <code>dim == 1</code>.
</p>
</li>
<li><p> A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector with length equal to the <a href="base.html#topic+length">length</a> of columns if <code>dim == 2</code>.
</p>
</li></ul>



<h3>Definition</h3>

<p><strong>Entropy:</strong>
</p>
<p style="text-align: center;"><code class="reqn">H(pk) = -\sum_{i} pk_i \log(pk_i)</code>
</p>

<p><strong>Cross Entropy:</strong>
</p>
<p style="text-align: center;"><code class="reqn">H(pk, qk) = -\sum_{i} pk_i \log(qk_i)</code>
</p>

<p><strong>Relative Entropy</strong>
</p>
<p style="text-align: center;"><code class="reqn">D_{KL}(pk \parallel qk) = \sum_{i} pk_i \log\left(\frac{pk_i}{qk_i}\right)</code>
</p>



<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) Define actual
# and observed probabilities

# 1.1) actual probabilies
pk &lt;- matrix(
  cbind(1/2, 1/2),
  ncol = 2
)

# 1.2) observed (estimated) probabilites
qk &lt;- matrix(
  cbind(9/10, 1/10), 
  ncol = 2
)

# 2) calculate
# Entropy
cat(
  "Entropy", entropy(
    pk
  ),
  "Relative Entropy", relative.entropy(
    pk,
    qk
  ),
  "Cross Entropy", cross.entropy(
    pk,
    qk
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='fbeta.factor'><code class="reqn">F_{\beta}</code>-score</h2><span id='topic+fbeta.factor'></span><span id='topic+weighted.fbeta.factor'></span><span id='topic+fbeta.cmatrix'></span><span id='topic+fbeta'></span><span id='topic+weighted.fbeta'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/F1_score"><code class="reqn">F_{\beta}</code></a>-score. Use <code><a href="#topic+weighted.fbeta">weighted.fbeta()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/F1_score"><code class="reqn">F_{\beta}</code></a>-score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
fbeta(actual, predicted, beta = 1, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.fbeta(actual, predicted, w, beta = 1, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
fbeta(x, beta = 1, micro = NULL, na.rm = TRUE, ...)

## Generic S3 method
fbeta(
 ...,
 beta  = 1,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.fbeta(
 ...,
 w,
 beta = 1,
 micro = NULL,
 na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fbeta.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="fbeta.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="fbeta.factor_+3A_beta">beta</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <code class="reqn">1</code>).</p>
</td></tr>
<tr><td><code id="fbeta.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="fbeta.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="fbeta.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="fbeta.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="fbeta.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{F}_{\beta} \in [0, 1]</code> be the <code class="reqn">F_{\beta}</code> score, which is a weighted harmonic mean of precision and recall. <code class="reqn">F_{\beta}</code> score of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{F}_{\beta} = \left(1 + \beta^2\right) \frac{\text{Precision} \times \text{Recall}}
                                          {\beta^2 \times \text{Precision} + \text{Recall}}
</code>
</p>

<p>Substituting <code class="reqn">\text{Precision} = \frac{\#TP_k}{\#TP_k + \#FP_k}</code> and <code class="reqn">\text{Recall} = \frac{\#TP_k}{\#TP_k + \#FN_k}</code> yields:
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{F}_{\beta} = \left(1 + \beta^2\right)
    \frac{\frac{\#TP_k}{\#TP_k + \#FP_k} \times \frac{\#TP_k}{\#TP_k + \#FN_k}}
         {\beta^2 \times \frac{\#TP_k}{\#TP_k + \#FP_k} + \frac{\#TP_k}{\#TP_k + \#FN_k}}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TP_k</code> is the number of true positives,
</p>
</li>
<li> <p><code class="reqn">\#FP_k</code> is the number of false positives,
</p>
</li>
<li> <p><code class="reqn">\#FN_k</code> is the number of false negatives, and
</p>
</li>
<li> <p><code class="reqn">\beta</code> is a non-negative real number that determines the relative importance of precision vs. recall in the score.
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using F1-score

# 4.1) unweighted F1-score
fbeta(
  actual    = actual,
  predicted = predicted,
  beta      = 1
)

# 4.2) weighted F1-score
weighted.fbeta(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length),
  beta      = 1
)

# 5) evaluate overall performance
# using micro-averaged F1-score
cat(
  "Micro-averaged F1-score", fbeta(
    actual    = actual,
    predicted = predicted,
    beta      = 1,
    micro     = TRUE
  ),
  "Micro-averaged F1-score (weighted)", weighted.fbeta(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    beta      = 1,
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='fdr.factor'>false discovery rate</h2><span id='topic+fdr.factor'></span><span id='topic+weighted.fdr.factor'></span><span id='topic+fdr.cmatrix'></span><span id='topic+fdr'></span><span id='topic+weighted.fdr'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/False_discovery_rate">False Discovery Rate</a>. Use <code><a href="#topic+weighted.fdr">weighted.fdr()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/False_discovery_rate">False Discovery Rate</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
fdr(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.fdr(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
fdr(x, micro = NULL, na.rm = TRUE, ...)

## Generic S3 method
fdr(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.fdr(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdr.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="fdr.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="fdr.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="fdr.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="fdr.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="fdr.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="fdr.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\alpha} \in [0, 1]</code> be the proportion of false positives among the preditced positives. The false discovery rate of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\alpha} = \frac{\#FP_k}{\#TP_k+\#FP_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TP_k</code> is the number of true positives, and
</p>
</li>
<li> <p><code class="reqn">\#FP_k</code> is the number of false positives
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using False Discovery Rate

# 4.1) unweighted False Discovery Rate
fdr(
  actual    = actual,
  predicted = predicted
)

# 4.2) weighted False Discovery Rate
weighted.fdr(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall performance
# using micro-averaged False Discovery Rate
cat(
  "Micro-averaged False Discovery Rate", fdr(
    actual    = actual,
    predicted = predicted,
    micro     = TRUE
  ),
  "Micro-averaged False Discovery Rate (weighted)", weighted.fdr(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)

</code></pre>

<hr>
<h2 id='fer.factor'>False Omission Rate</h2><span id='topic+fer.factor'></span><span id='topic+weighted.fer.factor'></span><span id='topic+fer.cmatrix'></span><span id='topic+fer'></span><span id='topic+weighted.fer'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values#False_omission_rate">false omission rate</a>. Use <code><a href="#topic+weighted.fdr">weighted.fdr()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values#False_omission_rate">false omission rate</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
fer(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.fer(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
fer(x, micro = NULL, na.rm = TRUE, ...)

## Generic S3 method
fer(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.fer(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fer.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="fer.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="fer.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="fer.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="fer.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="fer.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="fer.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\beta} \in [0, 1]</code> be the proportion of false negatives among the predicted negatives. The false omission rate of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\beta} = \frac{\#FN_k}{\#TN_k + \#FN_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TN_k</code> is the number of true negatives, and
</p>
</li>
<li> <p><code class="reqn">\#FN_k</code> is the number of false negatives.
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using False Omission Rate

# 4.1) unweighted False Omission Rate
fer(
  actual    = actual,
  predicted = predicted
)

# 4.2) weighted False Omission Rate
weighted.fer(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall performance
# using micro-averaged False Omission Rate
cat(
  "Micro-averaged False Omission Rate", fer(
    actual    = actual,
    predicted = predicted,
    micro     = TRUE
  ),
  "Micro-averaged False Omission Rate (weighted)", weighted.fer(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='fmi.factor'>Fowlkes-Mallows Index</h2><span id='topic+fmi.factor'></span><span id='topic+fmi.cmatrix'></span><span id='topic+fmi'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+fmi">fmi()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Fowlkes%E2%80%93Mallows_index">Fowlkes-Mallows Index</a> (FMI), a measure of the similarity between two sets of clusterings, between
two vectors of predicted and observed <code><a href="base.html#topic+factor">factor()</a></code> values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
fmi(actual, predicted, ...)

## S3 method for class 'cmatrix'
fmi(x, ...)

## Generic S3 method
fmi(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fmi.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="fmi.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="fmi.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="fmi.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>The metric is calculated for each class <code class="reqn">k</code> as follows,
</p>
<p style="text-align: center;"><code class="reqn">
  \sqrt{\frac{\#TP_k}{\#TP_k + \#FP_k} \times \frac{\#TP_k}{\#TP_k + \#FN_k}}
</code>
</p>

<p>Where <code class="reqn">\#TP_k</code>, <code class="reqn">\#FP_k</code>, and <code class="reqn">\#FN_k</code> represent the number of true positives, false positives, and false negatives for each class <code class="reqn">k</code>, respectively.
</p>


<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate model performance
# using Fowlkes Mallows Index
cat(
  "Fowlkes Mallows Index", fmi(
  actual    = actual,
  predicted = predicted
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='fpr.factor'>False Positive Rate</h2><span id='topic+fpr.factor'></span><span id='topic+weighted.fpr.factor'></span><span id='topic+fpr.cmatrix'></span><span id='topic+fallout.factor'></span><span id='topic+weighted.fallout.factor'></span><span id='topic+fallout.cmatrix'></span><span id='topic+fpr'></span><span id='topic+fallout'></span><span id='topic+weighted.fpr'></span><span id='topic+weighted.fallout'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/False_positive_rate">False Positive Rate</a>. Use <code><a href="#topic+weighted.fpr">weighted.fpr()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/False_positive_rate">False Positive Rate</a>.
</p>


<h4>Other names</h4>

<p>Fallout
</p>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
fpr(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.fpr(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
fpr(x, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
fallout(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.fallout(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
fallout(x, micro = NULL, na.rm = TRUE, ...)

## Generic S3 method
fpr(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
fallout(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.fpr(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.fallout(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fpr.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="fpr.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="fpr.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="fpr.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="fpr.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="fpr.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="fpr.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\gamma} \in [0, 1]</code> be the proportion of false positives among the actual negatives. The false positive rate of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\gamma} = \frac{\#FP_k}{\#TN_k + \#FP_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TN_k</code> is the number of true negatives, and
</p>
</li>
<li> <p><code class="reqn">\#FP_k</code> is the number of false positives.
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using False Positive Rate

# 4.1) unweighted False Positive Rate
fpr(
  actual    = actual,
  predicted = predicted
)

# 4.2) weighted False Positive Rate
weighted.fpr(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall performance
# using micro-averaged False Positive Rate
cat(
  "Micro-averaged False Positive Rate", fpr(
    actual    = actual,
    predicted = predicted,
    micro     = TRUE
  ),
  "Micro-averaged False Positive Rate (weighted)", weighted.fpr(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='huberloss.numeric'>Huber Loss</h2><span id='topic+huberloss.numeric'></span><span id='topic+weighted.huberloss.numeric'></span><span id='topic+huberloss'></span><span id='topic+weighted.huberloss'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+huberloss">huberloss()</a></code>-function computes the simple and weighted <a href="https://en.wikipedia.org/wiki/Huber_loss">huber loss</a> between
the predicted and observed &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.huberloss">weighted.huberloss()</a></code> function computes the weighted Huber Loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
huberloss(actual, predicted, delta = 1, ...)

## S3 method for class 'numeric'
weighted.huberloss(actual, predicted, w, delta = 1, ...)

## Generic S3 method
huberloss(
 actual,
 predicted,
 delta = 1,
 ...
)

## Generic S3 method
weighted.huberloss(
 actual,
 predicted,
 w,
 delta = 1,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="huberloss.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="huberloss.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="huberloss.numeric_+3A_delta">delta</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <code class="reqn">1</code>). The threshold value for switch between functions (see calculation).</p>
</td></tr>
<tr><td><code id="huberloss.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="huberloss.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as follows,
</p>
<p style="text-align: center;"><code class="reqn">
 \frac{1}{2} (y - \upsilon)^2 ~for~ |y - \upsilon| \leq \delta
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
  \delta |y-\upsilon|-\frac{1}{2} \delta^2 ~for~ \text{otherwise}
</code>
</p>

<p>where <code class="reqn">y</code> and <code class="reqn">\upsilon</code> are the <code>actual</code> and <code>predicted</code> values respectively. If <code>w</code> is not <a href="base.html#topic+NULL">NULL</a>, then all values
are aggregated using the weights.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)


# 2) calculate the metric
# with delta 0.5
huberloss(
  actual = actual,
  predicted = predicted,
  delta = 0.5
)

# 3) caclulate weighted
# metric using arbitrary weights
w &lt;- rbeta(
  n = 1e3,
  shape1 = 10,
  shape2 = 2
)

huberloss(
  actual = actual,
  predicted = predicted,
  delta = 0.5,
  w     = w
)
</code></pre>

<hr>
<h2 id='jaccard.factor'>Jaccard Index</h2><span id='topic+jaccard.factor'></span><span id='topic+weighted.jaccard.factor'></span><span id='topic+jaccard.cmatrix'></span><span id='topic+csi.factor'></span><span id='topic+weighted.csi.factor'></span><span id='topic+csi.cmatrix'></span><span id='topic+tscore.factor'></span><span id='topic+weighted.tscore.factor'></span><span id='topic+tscore.cmatrix'></span><span id='topic+jaccard'></span><span id='topic+csi'></span><span id='topic+tscore'></span><span id='topic+weighted.jaccard'></span><span id='topic+weighted.csi'></span><span id='topic+weighted.tscore'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+jaccard">jaccard()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard Index</a>, also known as the Intersection over Union, between
two vectors of predicted and observed <code><a href="base.html#topic+factor">factor()</a></code> values. The <code><a href="#topic+weighted.jaccard">weighted.jaccard()</a></code> function computes the weighted Jaccard Index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
jaccard(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.jaccard(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
jaccard(x, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
csi(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.csi(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
csi(x, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
tscore(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.tscore(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
tscore(x, micro = NULL, na.rm = TRUE, ...)

## Generic S3 method
jaccard(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
csi(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
tscore(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.jaccard(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.csi(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.tscore(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jaccard.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="jaccard.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="jaccard.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="jaccard.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="jaccard.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="jaccard.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="jaccard.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>The metric is calculated for each class <code class="reqn">k</code> as follows,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{\#TP_k}{\#TP_k + \#FP_k + \#FN_k}
</code>
</p>

<p>Where <code class="reqn">\#TP_k</code>, <code class="reqn">\#FP_k</code>, and <code class="reqn">\#FN_k</code> represent the number of true positives, false positives, and false negatives for each class <code class="reqn">k</code>, respectively.
</p>


<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using Jaccard Index

# 4.1) unweighted Jaccard Index
jaccard(
  actual    = actual,
  predicted = predicted
)

# 4.2) weighted Jaccard Index
weighted.jaccard(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall performance
# using micro-averaged Jaccard Index
cat(
  "Micro-averaged Jaccard Index", jaccard(
    actual    = actual,
    predicted = predicted,
    micro     = TRUE
  ),
  "Micro-averaged Jaccard Index (weighted)", weighted.jaccard(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='logloss.factor'>Log Loss</h2><span id='topic+logloss.factor'></span><span id='topic+weighted.logloss.factor'></span><span id='topic+logloss.integer'></span><span id='topic+weighted.logloss.integer'></span><span id='topic+logloss'></span><span id='topic+weighted.logloss'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+logloss">logloss()</a></code> function computes the <strong>Log Loss</strong> between observed classes (as a &lt;<a href="base.html#topic+factor">factor</a>&gt;) and their predicted probability distributions (a &lt;<a href="base.html#topic+numeric">numeric</a>&gt; matrix). The <code><a href="#topic+weighted.logloss">weighted.logloss()</a></code> function is the weighted version, applying observation-specific weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
logloss(actual, response, normalize = TRUE, ...)

## S3 method for class 'factor'
weighted.logloss(actual, response, w, normalize = TRUE, ...)

## S3 method for class 'integer'
logloss(actual, response, normalize = TRUE, ...)

## S3 method for class 'integer'
weighted.logloss(actual, response, w, normalize = TRUE, ...)

## Generic S3 method
logloss(
 actual,
 response,
 normalize = TRUE,
 ...
)

## Generic S3 method
weighted.logloss(
 actual,
 response,
 w,
 normalize = TRUE,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logloss.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="logloss.factor_+3A_response">response</code></td>
<td>
<p>A <code class="reqn">n \times k</code> &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-matrix of predicted probabilities.
The <code class="reqn">i</code>-th row should sum to 1 (i.e., a valid probability distribution
over the <code class="reqn">k</code> classes). The first column corresponds to the first factor
level in <code>actual</code>, the second column to the second factor level, and so on.</p>
</td></tr>
<tr><td><code id="logloss.factor_+3A_normalize">normalize</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>,
the mean cross-entropy across all observations is returned; otherwise, the
sum of cross-entropies is returned.</p>
</td></tr>
<tr><td><code id="logloss.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="logloss.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p style="text-align: center;"><code class="reqn">H(p, response) = -\sum_{i} \sum_{j} y_{ij} \log_2(response_{ij})</code>
</p>

<p>where:
</p>

<ul>
<li> <p><code class="reqn">y_{ij}</code> is the <code>actual</code>-values, where <code class="reqn">y_{ij}</code> = 1 if the <code>i</code>-th sample belongs to class <code>j</code>, and 0 otherwise.
</p>
</li>
<li> <p><code class="reqn">response_{ij}</code> is the estimated probability for the <code>i</code>-th sample belonging to class <code>j</code>.
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) Recode the iris data set to a binary classification problem
#    Here, the positive class ("Virginica") is coded as 1,
#    and the rest ("Others") is coded as 0.
iris$species_num &lt;- as.numeric(iris$Species == "virginica")

# 2) Fit a logistic regression model predicting species_num from Sepal.Length &amp; Sepal.Width
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(link = "logit")
)

# 3) Generate predicted classes: "Virginica" vs. "Others"
predicted &lt;- factor(
  as.numeric(predict(model, type = "response") &gt; 0.5),
  levels = c(1, 0),
  labels = c("Virginica", "Others")
)

# 3.1) Generate actual classes
actual &lt;- factor(
  x      = iris$species_num,
  levels = c(1, 0),
  labels = c("Virginica", "Others")
)

# For Log Loss, we need predicted probabilities for each class.
# Since it's a binary model, we create a 2-column matrix:
#   1st column = P("Virginica")
#   2nd column = P("Others") = 1 - P("Virginica")
predicted_probs &lt;- predict(model, type = "response")
response_matrix &lt;- cbind(predicted_probs, 1 - predicted_probs)

# 4) Evaluate unweighted Log Loss
#    'logloss' takes (actual, response_matrix, normalize=TRUE/FALSE).
#    The factor 'actual' must have the positive class (Virginica) as its first level.
unweighted_LogLoss &lt;- logloss(
  actual    = actual,           # factor
  response  = response_matrix,  # numeric matrix of probabilities
  normalize = TRUE              # normalize = TRUE
)

# 5) Evaluate weighted Log Loss
#    We introduce a weight vector, for example:
weights &lt;- iris$Petal.Length / mean(iris$Petal.Length)
weighted_LogLoss &lt;- weighted.logloss(
  actual    = actual,
  response  = response_matrix,
  w         = weights,
  normalize = TRUE
)

# 6) Print Results
cat(
  "Unweighted Log Loss:", unweighted_LogLoss,
  "Weighted Log Loss:", weighted_LogLoss,
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='mae.numeric'>Mean Absolute Error</h2><span id='topic+mae.numeric'></span><span id='topic+weighted.mae.numeric'></span><span id='topic+mae'></span><span id='topic+weighted.mae'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+mae">mae()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Mean_absolute_error">mean absolute error</a> between
the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.mae">weighted.mae()</a></code> function computes the weighted mean absolute error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
mae(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.mae(actual, predicted, w, ...)

## Generic S3 method
mae(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.mae(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mae.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="mae.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="mae.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="mae.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calulated as follows,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{\sum_i^n |y_i - \upsilon_i|}{n}
</code>
</p>



<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Mean Absolute Error (MAE)
cat(
  "Mean Absolute Error", mae(
    actual    = actual,
    predicted = predicted,
  ),
  "Mean Absolute Error (weighted)", weighted.mae(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='mape.numeric'>Mean Absolute Percentage Error</h2><span id='topic+mape.numeric'></span><span id='topic+weighted.mape.numeric'></span><span id='topic+mape'></span><span id='topic+weighted.mape'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+mape">mape()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error">mean absolute percentage error</a> between
the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.mape">weighted.mape()</a></code> function computes the weighted mean absolute percentage error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
mape(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.mape(actual, predicted, w, ...)

## Generic S3 method
mape(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.mape(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mape.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="mape.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="mape.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="mape.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_i^n \frac{|y_i - \upsilon_i|}{|y_i|}
</code>
</p>



<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Mean Absolute Percentage Error (MAPE)
cat(
  "Mean Absolute Percentage Error", mape(
    actual    = actual,
    predicted = predicted,
  ),
  "Mean Absolute Percentage Error (weighted)", weighted.mape(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='mcc.factor'>Matthews Correlation Coefficient</h2><span id='topic+mcc.factor'></span><span id='topic+weighted.mcc.factor'></span><span id='topic+mcc.cmatrix'></span><span id='topic+phi.factor'></span><span id='topic+weighted.phi.factor'></span><span id='topic+phi.cmatrix'></span><span id='topic+mcc'></span><span id='topic+phi'></span><span id='topic+weighted.mcc'></span><span id='topic+weighted.phi'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+mcc">mcc()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Matthews Correlation Coefficient</a> (MCC), also known as the <code class="reqn">\phi</code>-coefficient, between
two vectors of predicted and observed <code><a href="base.html#topic+factor">factor()</a></code> values. The <code><a href="#topic+weighted.mcc">weighted.mcc()</a></code> function computes the weighted Matthews Correlation Coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
mcc(actual, predicted, ...)

## S3 method for class 'factor'
weighted.mcc(actual, predicted, w, ...)

## S3 method for class 'cmatrix'
mcc(x, ...)

## S3 method for class 'factor'
phi(actual, predicted, ...)

## S3 method for class 'factor'
weighted.phi(actual, predicted, w, ...)

## S3 method for class 'cmatrix'
phi(x, ...)

## Generic S3 method
mcc(...)

## Generic S3 method
weighted.mcc(
 ...,
 w
)

## Generic S3 method
phi(...)

## Generic S3 method
weighted.phi(
 ...,
 w
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcc.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="mcc.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="mcc.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="mcc.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default</p>
</td></tr>
<tr><td><code id="mcc.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>The metric is calculated as follows,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{\#TP \times \#TN - \#FP \times \#FN}{\sqrt{(\#TP + \#FP)(\#TP + \#FN)(\#TN + \#FP)(\#TN + \#FN)}}
</code>
</p>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate performance
# using Matthews Correlation Coefficient
cat(
  "Matthews Correlation Coefficient", mcc(
    actual    = actual,
    predicted = predicted
  ),
  "Matthews Correlation Coefficient (weighted)", weighted.mcc(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length)
  ),
  sep = "\n"
)

</code></pre>

<hr>
<h2 id='mpe.numeric'>Mean Percentage Error</h2><span id='topic+mpe.numeric'></span><span id='topic+weighted.mpe.numeric'></span><span id='topic+mpe'></span><span id='topic+weighted.mpe'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+mpe">mpe()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Mean_percentage_error">mean percentage error</a> between
the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.mpe">weighted.mpe()</a></code> function computes the weighted mean percentage error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
mpe(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.mpe(actual, predicted, w, ...)

## Generic S3 method
mpe(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.mpe(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mpe.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="mpe.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="mpe.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="mpe.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_i^n \frac{y_i - \upsilon_i}{y_i}
</code>
</p>

<p>Where <code class="reqn">y_i</code> and <code class="reqn">\upsilon_i</code> are the <code>actual</code> and <code>predicted</code> values respectively.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Mean Percentage Error (MPE)
cat(
  "Mean Percentage Error", mpe(
    actual    = actual,
    predicted = predicted,
  ),
  "Mean Percentage Error (weighted)", weighted.mpe(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='mse.numeric'>Mean Squared Error</h2><span id='topic+mse.numeric'></span><span id='topic+weighted.mse.numeric'></span><span id='topic+mse'></span><span id='topic+weighted.mse'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+mse">mse()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared error</a> between
the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.mse">weighted.mse()</a></code> function computes the weighted mean squared error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
mse(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.mse(actual, predicted, w, ...)

## Generic S3 method
mse(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.mse(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mse.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="mse.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="mse.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="mse.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_i^n (y_i - \upsilon_i)^2
</code>
</p>

<p>Where <code class="reqn">y_i</code> and <code class="reqn">\upsilon_i</code> are the <code>actual</code> and <code>predicted</code> values respectively.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Mean Squared Error (MSE)
cat(
  "Mean Squared Error", mse(
    actual    = actual,
    predicted = predicted,
  ),
  "Mean Squared Error (weighted)", weighted.mse(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='nlr.factor'>Negative Likelihood Ratio</h2><span id='topic+nlr.factor'></span><span id='topic+weighted.nlr.factor'></span><span id='topic+nlr.cmatrix'></span><span id='topic+nlr'></span><span id='topic+weighted.nlr'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">negative likelihood ratio</a> in classification tasks. Use <code><a href="#topic+weighted.nlr">weighted.nlr()</a></code> weighted <a href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">negative likelihood ratio</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
nlr(actual, predicted, ...)

## S3 method for class 'factor'
weighted.nlr(actual, predicted, w, ...)

## S3 method for class 'cmatrix'
nlr(x, ...)

## Generic S3 method
nlr(...)

## Generic S3 method
weighted.nlr(
 ...,
 w
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nlr.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="nlr.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="nlr.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="nlr.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="nlr.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\alpha} \in [0, \infty]</code> be the likelihood of a negative outcome. The <a href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">negative likelihood ratio</a> of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\alpha} = \frac{1 - \frac{\#TP}{\#TP + \#FN}}{\frac{\#TN}{\#TN + \#FP}}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\frac{\#TP}{\#TP + \#FN}</code> is the sensitivity, or true positive rate
</p>
</li>
<li> <p><code class="reqn">\frac{\#TN}{\#TN + \#FP}</code> is the specificity, or true negative rate
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+plr">plr()</a></code>-function for the Positive Likehood Ratio (LR+)
</p>
<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate model performance
# with class-wise negative likelihood ratios
cat("Negative Likelihood Ratio", sep = "\n")
nlr(
  actual    = actual, 
  predicted = predicted
)

cat("Negative Likelihood Ratio (weighted)", sep = "\n")
weighted.nlr(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)
</code></pre>

<hr>
<h2 id='npv.factor'>Negative Predictive Value</h2><span id='topic+npv.factor'></span><span id='topic+weighted.npv.factor'></span><span id='topic+npv.cmatrix'></span><span id='topic+npv'></span><span id='topic+weighted.npv'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+npv">npv()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values">negative predictive value</a>, also known as the True Negative Predictive Value, between
two vectors of predicted and observed <code><a href="base.html#topic+factor">factor()</a></code> values. The <code><a href="#topic+weighted.npv">weighted.npv()</a></code> function computes the weighted negative predictive value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
npv(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.npv(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
npv(x, micro = NULL, na.rm = TRUE, ...)

npv(...)

weighted.npv(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="npv.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="npv.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="npv.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="npv.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="npv.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="npv.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="npv.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>The metric is calculated for each class <code class="reqn">k</code> as follows,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{\#TN_k}{\#TN_k + \#FN_k}
</code>
</p>

<p>Where <code class="reqn">\#TN_k</code> and <code class="reqn">\#FN_k</code> are the number of true negatives and false negatives, respectively, for each class <code class="reqn">k</code>.
</p>


<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using Negative Predictive Value

# 4.1) unweighted Negative Predictive Value
npv(
  actual    = actual,
  predicted = predicted
)

# 4.2) weighted Negative Predictive Value
weighted.npv(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall performance
# using micro-averaged Negative Predictive Value
cat(
  "Micro-averaged Negative Predictive Value", npv(
    actual    = actual,
    predicted = predicted,
    micro     = TRUE
  ),
  "Micro-averaged Negative Predictive Value (weighted)", weighted.npv(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='obesity'>Obesity Levels Dataset</h2><span id='topic+obesity'></span>

<h3>Description</h3>

<p>This dataset is used to estimate obesity levels based on eating habits and physical
condition. The data originates from the UCI Machine Learning Repository and has been
preprocessed to include both predictors and a target variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(obesity)
</code></pre>


<h3>Format</h3>

<p>A list with two components:
</p>

<dl>
<dt>features</dt><dd><p>A data frame containing various predictors related to eating habits, physical condition, and lifestyle.</p>
</dd>
<dt>target</dt><dd><p>A list with two elements: <code>regression</code> (weight in kilograms) and <code>class</code> (obesity level classification).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The dataset is provided as a list with two components:
</p>

<dl>
<dt>features</dt><dd><p>A data frame containing various predictors related to lifestyle,
eating habits, and physical condition. The variables include:
</p>

<dl>
<dt>age</dt><dd><p>The age of the individual in years.</p>
</dd>
<dt>height</dt><dd><p>The height of the individual in meters.</p>
</dd>
<dt>family_history_with_overweight</dt><dd><p>Binary variable indicating whether the individual has a family history of overweight (1 = yes, 0 = no).</p>
</dd>
<dt>favc</dt><dd><p>Binary variable indicating whether the individual frequently consumes high-calorie foods (1 = yes, 0 = no).</p>
</dd>
<dt>fcvc</dt><dd><p>The frequency of consumption of vegetables in meals.</p>
</dd>
<dt>ncp</dt><dd><p>The number of main meals consumed per day.</p>
</dd>
<dt>caec</dt><dd><p>Categorical variable indicating the frequency of consumption of food between meals.
Typical levels include <code>"no"</code>, <code>"sometimes"</code>, <code>"frequently"</code>, and <code>"always"</code>.</p>
</dd>
<dt>smoke</dt><dd><p>Binary variable indicating whether the individual smokes (1 = yes, 0 = no).</p>
</dd>
<dt>ch2o</dt><dd><p>Daily water consumption (typically in liters).</p>
</dd>
<dt>scc</dt><dd><p>Binary variable indicating whether the individual monitors calorie consumption (1 = yes, 0 = no).</p>
</dd>
<dt>faf</dt><dd><p>The frequency of physical activity.</p>
</dd>
<dt>tue</dt><dd><p>The time spent using electronic devices (e.g., screen time in hours).</p>
</dd>
<dt>calc</dt><dd><p>Categorical variable indicating the frequency of alcohol consumption.
Typical levels include <code>"no"</code>, <code>"sometimes"</code>, <code>"frequently"</code>, and <code>"always"</code>.</p>
</dd>
<dt>male</dt><dd><p>Binary variable indicating the gender of the individual (1 = male, 0 = female).</p>
</dd>
</dl>

</dd>
<dt>target</dt><dd><p>A list containing two elements:
</p>

<dl>
<dt>regression</dt><dd><p>A numeric vector representing the weight of the individual (used as the regression target).</p>
</dd>
<dt>class</dt><dd><p>A factor indicating the obesity level classification. The levels are derived from the original <code>nobeyesdad</code> variable in the dataset.</p>
</dd>
</dl>

</dd>
</dl>



<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition">https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition</a>
</p>

<hr>
<h2 id='openmp.on'>Use OpenMP</h2><span id='topic+openmp.on'></span><span id='topic+openmp.off'></span><span id='topic+openmp.threads'></span>

<h3>Description</h3>

<p>This function allows you to enable or disable the use of OpenMP for parallelizing computations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## enable OpenMP
openmp.on()

## disable OpenMP
openmp.off()

## set number of threads
openmp.threads(threads)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="openmp.on_+3A_threads">threads</code></td>
<td>
<p>A positive &lt;<a href="base.html#topic+integer">integer</a>&gt;-value (Default: None). If <code>threads</code> is missing, the <code>openmp.threads()</code> returns the number of available threads. If <a href="base.html#topic+NULL">NULL</a> all available threads will be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If OpenMP is unavailable, the function returns <a href="base.html#topic+NULL">NULL</a>.
</p>
<p>If OpenMP is unavailable, the function returns <a href="base.html#topic+NULL">NULL</a>.
</p>
<p>If OpenMP is unavailable, the function returns <a href="base.html#topic+NULL">NULL</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  ## enable OpenMP
  SLmetrics::openmp.on()

  ## disable OpenMP
  SLmetrics::openmp.off()

  ## available threads
  SLmetrics::openmp.threads()

  ## set number of threads
  SLmetrics::openmp.threads(2)


## End(Not run)

</code></pre>

<hr>
<h2 id='pinball.numeric'>Pinball Loss</h2><span id='topic+pinball.numeric'></span><span id='topic+weighted.pinball.numeric'></span><span id='topic+pinball'></span><span id='topic+weighted.pinball'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+pinball">pinball()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Quantile_regression">pinball loss</a> between
the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.pinball">weighted.pinball()</a></code> function computes the weighted Pinball Loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
pinball(actual, predicted, alpha = 0.5, deviance = FALSE, ...)

## S3 method for class 'numeric'
weighted.pinball(actual, predicted, w, alpha = 0.5, deviance = FALSE, ...)

## Generic S3 method
pinball(
 actual,
 predicted,
 alpha    = 0.5,
 deviance = FALSE,
 ...
)

## Generic S3 method
weighted.pinball(
 actual,
 predicted,
 w,
 alpha    = 0.5,
 deviance = FALSE,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pinball.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="pinball.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="pinball.numeric_+3A_alpha">alpha</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <code class="reqn">0.5</code>). The slope of the pinball loss function.</p>
</td></tr>
<tr><td><code id="pinball.numeric_+3A_deviance">deviance</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> 1 (default: <a href="base.html#topic+FALSE">FALSE</a>). If <a href="base.html#topic+TRUE">TRUE</a> the function returns the <code class="reqn">D^2</code> loss.</p>
</td></tr>
<tr><td><code id="pinball.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="pinball.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">\text{PinballLoss}_{\text{unweighted}} = \frac{1}{n} \sum_{i=1}^{n} \left[ \alpha \cdot \max(0, y_i - \hat{y}_i) - (1 - \alpha) \cdot \max(0, \hat{y}_i - y_i) \right]</code>
</p>

<p>where <code class="reqn">y_i</code> is the actual value, <code class="reqn">\hat{y}_i</code> is the predicted value and <code class="reqn">\alpha</code> is the quantile level.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Pinball Loss
cat(
  "Pinball Loss", pinball(
    actual    = actual,
    predicted = predicted,
  ),
  "Pinball Loss (weighted)", weighted.pinball(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='plr.factor'>Positive Likelihood Ratio</h2><span id='topic+plr.factor'></span><span id='topic+weighted.plr.factor'></span><span id='topic+plr.cmatrix'></span><span id='topic+plr'></span><span id='topic+weighted.plr'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">positive likelihood ratio</a> in classification tasks. Use <code><a href="#topic+weighted.plr">weighted.plr()</a></code> weighted <a href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">positive likelihood ratio</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
plr(actual, predicted, ...)

## S3 method for class 'factor'
weighted.plr(actual, predicted, w, ...)

## S3 method for class 'cmatrix'
plr(x, ...)

## Generic S3 method
plr(...)

## Generic S3 method
weighted.plr(
 ...,
 w
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plr.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="plr.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="plr.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="plr.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="plr.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\alpha} \in [0, \infty]</code> be the likelihood of a positive outcome. The <a href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">positive likelihood ratio</a> of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\alpha} = \frac{\frac{\#TP}{\#TP + \#FN}}{1 - \frac{\#TN}{\#TN + \#FP}}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\frac{\#TP}{\#TP + \#FN}</code> is the sensitivity, or true positive rate
</p>
</li>
<li> <p><code class="reqn">\frac{\#TN}{\#TN + \#FP}</code> is the specificity, or true negative rate
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+nlr">nlr()</a></code>-function for the Negative Likehood Ratio (LR-)
</p>
<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate model performance
# with class-wise positive likelihood ratios
cat("Positive Likelihood Ratio", sep = "\n")
plr(
  actual    = actual, 
  predicted = predicted
)

cat("Positive Likelihood Ratio (weighted)", sep = "\n")
weighted.plr(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)
</code></pre>

<hr>
<h2 id='pr.auc.matrix'>Area under the Precision-Recall Curve</h2><span id='topic+pr.auc.matrix'></span><span id='topic+weighted.pr.auc.matrix'></span><span id='topic+pr.auc'></span><span id='topic+weighted.pr.auc'></span>

<h3>Description</h3>

<p>A generic function for the area under the Precision-Recall Curve. Use <code><a href="#topic+weighted.pr.auc">weighted.pr.auc()</a></code> for the weighted area under the Precision-Recall Curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matrix'
pr.auc(actual, response, micro = NULL, method = 0L, ...)

## S3 method for class 'matrix'
weighted.pr.auc(actual, response, w, micro = NULL, method = 0L, ...)

## Generic S3 method
pr.auc(
 actual,
 response,
 micro  = NULL,
 method = 0,
 ...
)

## Generic S3 method
weighted.pr.auc(
 actual,
 response,
 w,
 micro  = NULL,
 method = 0,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pr.auc.matrix_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="pr.auc.matrix_+3A_response">response</code></td>
<td>
<p>A <code class="reqn">n \times k</code> &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-<a href="base.html#topic+matrix">matrix</a>. The estimated response probabilities for each class <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="pr.auc.matrix_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="pr.auc.matrix_+3A_method">method</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; value (default: <code class="reqn">0</code>). Defines the underlying method of calculating the area under the curve. If <code class="reqn">0</code> it is calculated using the <code>trapezoid</code>-method, if <code class="reqn">1</code> it is calculated using the <code>step</code>-method.</p>
</td></tr>
<tr><td><code id="pr.auc.matrix_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="pr.auc.matrix_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;  vector  of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p><strong>Trapezoidal rule</strong>
</p>
<p>The <strong>trapezoidal rule</strong> approximates the integral of a function <code class="reqn">f(x)</code> between
<code class="reqn">x = a</code> and <code class="reqn">x = b</code> using trapezoids formed between consecutive points. If
we have points <code class="reqn">x_0, x_1, \ldots, x_n</code> (with <code class="reqn">a = x_0 &lt; x_1 &lt; \cdots &lt; x_n = b</code>)
and corresponding function values <code class="reqn">f(x_0), f(x_1), \ldots, f(x_n)</code>, the area under
the curve <code class="reqn">A_T</code> is approximated by:
</p>
<p style="text-align: center;"><code class="reqn">
  A_T \approx \sum_{k=1}^{n} \frac{f(x_{k-1}) + f(x_k)}{2} \bigl[x_k - x_{k-1}\bigr].
</code>
</p>

<p><strong>Step-function method</strong>
</p>
<p>The <strong>step-function (rectangular) method</strong> uses the value of the function at one
endpoint of each subinterval to form rectangles. With the same partition
<code class="reqn">x_0, x_1, \ldots, x_n</code>, the rectangular approximation <code class="reqn">A_S</code> can be written as:
</p>
<p style="text-align: center;"><code class="reqn">
  A_S \approx \sum_{k=1}^{n} f(x_{k-1}) \bigl[x_k - x_{k-1}\bigr].
</code>
</p>



<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
response &lt;- predict(model, type = "response")

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) generate precision-recall
# data

# 4.1) calculate residual
# probability and store as matrix
response &lt;- matrix(
  data = cbind(response, 1-response),
  nrow = length(actual)
)

# 4.2) calculate class-wise
# area under the curve
pr.auc(
  actual   = actual,
  response = response 
)

# 4.3) calculate class-wise
# weighted area under the curve
weighted.pr.auc(
  actual   = actual,
  response = response,
  w        = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall area under
# the curve
cat(
  "Micro-averaged area under the precision-recall curve", pr.auc(
    actual    = actual,
    response  = response,
    micro     = TRUE
  ),
  "Micro-averaged area under the precision-recall curve (weighted)", weighted.pr.auc(
    actual    = actual,
    response  = response,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='precision.factor'>Precision</h2><span id='topic+precision.factor'></span><span id='topic+weighted.precision.factor'></span><span id='topic+precision.cmatrix'></span><span id='topic+ppv.factor'></span><span id='topic+weighted.ppv.factor'></span><span id='topic+ppv.cmatrix'></span><span id='topic+precision'></span><span id='topic+ppv'></span><span id='topic+weighted.precision'></span><span id='topic+weighted.ppv'></span>

<h3>Description</h3>

<p>A generic funcion for the <a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values">precision</a>. Use <code><a href="#topic+weighted.fdr">weighted.fdr()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values">precision</a>.
</p>


<h4>Other names</h4>

<p>Positive Predictive Value
</p>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
precision(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.precision(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
precision(x, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
ppv(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.ppv(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
ppv(x, micro = NULL, na.rm = TRUE, ...)

## Generic S3 method
precision(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.precision(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
ppv(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.ppv(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="precision.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="precision.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="precision.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="precision.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="precision.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="precision.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="precision.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\pi} \in [0, 1]</code> be the proportion of true positives among the predicted positives. The precision of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\pi} = \frac{\#TP_k}{\#TP_k + \#FP_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TP_k</code> is the number of true positives, and
</p>
</li>
<li> <p><code class="reqn">\#FP_k</code> is the number of false positives.
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using Precision

# 4.1) unweighted Precision
precision(
  actual    = actual,
  predicted = predicted
)

# 4.2) weighted Precision
weighted.precision(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall performance
# using micro-averaged Precision
cat(
  "Micro-averaged Precision", precision(
    actual    = actual,
    predicted = predicted,
    micro     = TRUE
  ),
  "Micro-averaged Precision (weighted)", weighted.precision(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='preorder'>Preorder</h2><span id='topic+preorder'></span>

<h3>Description</h3>

<p>This function does a column-wise ordering permutation of <a href="base.html#topic+numeric">numeric</a> or <a href="base.html#topic+integer">integer</a> matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preorder(
 x,
 decreasing = FALSE,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preorder_+3A_x">x</code></td>
<td>
<p>a <a href="base.html#topic+numeric">numeric</a> or <a href="base.html#topic+integer">integer</a> matrix to be sorted.</p>
</td></tr>
<tr><td><code id="preorder_+3A_decreasing">decreasing</code></td>
<td>
<p>a <a href="base.html#topic+logical">logical</a> value of <a href="base.html#topic+length">length</a> 1 (default: <a href="base.html#topic+FALSE">FALSE</a>). If <a href="base.html#topic+TRUE">TRUE</a> the matrix is returned in descending order.</p>
</td></tr>
<tr><td><code id="preorder_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="base.html#topic+matrix">matrix</a> with indices to the ordered values.
</p>


<h3>See Also</h3>

<p>Other Tools: 
<code><a href="#topic+auc.numeric">auc.numeric</a>()</code>,
<code><a href="#topic+cov.wt.matrix">cov.wt.matrix</a>()</code>,
<code><a href="#topic+presort">presort</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) generate a 4x4 matrix
# with random values to be sorted
set.seed(1903)
X &lt;- matrix(
  data = cbind(sample(16:1)),
  nrow = 4
)

# 2) sort matrix
# in decreasing order
presort(X)

# 3) get indices 
# for sorted matrix
preorder(X)
</code></pre>

<hr>
<h2 id='presort'>Presort</h2><span id='topic+presort'></span>

<h3>Description</h3>

<p>This generic function does a column-wise sorting of a <a href="base.html#topic+numeric">numeric</a> or <a href="base.html#topic+integer">integer</a> matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>presort(
 x,
 decreasing = FALSE,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="presort_+3A_x">x</code></td>
<td>
<p>a <a href="base.html#topic+numeric">numeric</a> or <a href="base.html#topic+integer">integer</a> matrix to be sorted.</p>
</td></tr>
<tr><td><code id="presort_+3A_decreasing">decreasing</code></td>
<td>
<p>a <a href="base.html#topic+logical">logical</a> value of <a href="base.html#topic+length">length</a> 1 (default: <a href="base.html#topic+FALSE">FALSE</a>). If <a href="base.html#topic+TRUE">TRUE</a> the matrix is returned in descending order.</p>
</td></tr>
<tr><td><code id="presort_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="base.html#topic+matrix">matrix</a> with sorted rows.
</p>


<h3>See Also</h3>

<p>Other Tools: 
<code><a href="#topic+auc.numeric">auc.numeric</a>()</code>,
<code><a href="#topic+cov.wt.matrix">cov.wt.matrix</a>()</code>,
<code><a href="#topic+preorder">preorder</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) generate a 4x4 matrix
# with random values to be sorted
set.seed(1903)
X &lt;- matrix(
  data = cbind(sample(16:1)),
  nrow = 4
)

# 2) sort matrix
# in decreasing order
presort(X)

# 3) get indices 
# for sorted matrix
preorder(X)
</code></pre>

<hr>
<h2 id='prROC.factor'>Precision-Recall Curve</h2><span id='topic+prROC.factor'></span><span id='topic+weighted.prROC.factor'></span><span id='topic+prROC'></span><span id='topic+weighted.prROC'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+prROC">prROC()</a></code>-function computes the <code><a href="#topic+precision">precision()</a></code> and <code><a href="#topic+recall">recall()</a></code> at thresholds provided by the <code class="reqn">response</code>- or <code class="reqn">thresholds</code>-vector. The function
constructs a <code><a href="base.html#topic+data.frame">data.frame()</a></code> grouped by <code class="reqn">k</code>-classes where each class is treated as a binary classification problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
prROC(actual, response, thresholds = NULL, presorted = FALSE, ...)

## S3 method for class 'factor'
weighted.prROC(actual, response, w, thresholds = NULL, presorted = FALSE, ...)

## Generic S3 method
prROC(
 actual,
 response,
 thresholds = NULL,
 presorted  = FALSE,
 ...
)

## Generic S3 method
weighted.prROC(
 actual,
 response,
 w,
 thresholds = NULL,
 presorted  = FALSE,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prROC.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="prROC.factor_+3A_response">response</code></td>
<td>
<p>A <code class="reqn">n \times k</code> &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-<a href="base.html#topic+matrix">matrix</a>. The estimated response probabilities for each class <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="prROC.factor_+3A_thresholds">thresholds</code></td>
<td>
<p>An optional &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code> (default: <a href="base.html#topic+NULL">NULL</a>).</p>
</td></tr>
<tr><td><code id="prROC.factor_+3A_presorted">presorted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value <a href="base.html#topic+length">length</a> 1 (default: <a href="base.html#topic+FALSE">FALSE</a>). If <a href="base.html#topic+TRUE">TRUE</a> the input will not be sorted by threshold.</p>
</td></tr>
<tr><td><code id="prROC.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="prROC.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="base.html#topic+data.frame">data.frame</a> on the following form,
</p>
<table role = "presentation">
<tr><td><code>threshold</code></td>
<td>
<p>&lt;<a href="base.html#topic+numeric">numeric</a>&gt; Thresholds used to determine <code><a href="#topic+recall">recall()</a></code> and <code><a href="#topic+precision">precision()</a></code></p>
</td></tr>
<tr><td><code>level</code></td>
<td>
<p>&lt;<a href="base.html#topic+character">character</a>&gt; The level of the actual &lt;<a href="base.html#topic+factor">factor</a>&gt;</p>
</td></tr>
<tr><td><code>label</code></td>
<td>
<p>&lt;<a href="base.html#topic+character">character</a>&gt; The levels of the actual &lt;<a href="base.html#topic+factor">factor</a>&gt;</p>
</td></tr>
<tr><td><code>recall</code></td>
<td>
<p>&lt;<a href="base.html#topic+numeric">numeric</a>&gt; The recall</p>
</td></tr>
<tr><td><code>precision</code></td>
<td>
<p>&lt;<a href="base.html#topic+numeric">numeric</a>&gt; The precision</p>
</td></tr>
</table>


<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\sigma} \in [0, 1]</code> be the proportion of true negatives among the actual negatives. The specificity of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\sigma} = \frac{\#TN_k}{\#TN_k + \#FP_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TN_k</code> is the number of true negatives, and
</p>
</li>
<li> <p><code class="reqn">\#FP_k</code> is the number of false positives.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
response &lt;- predict(model, type = "response")

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) generate precision-recall
# data

# 4.1) calculate residual
# probability and store as matrix
response &lt;- matrix(
  data = cbind(response, 1-response),
  nrow = length(actual)
)

# 4.2) generate precision-recall
# data
roc &lt;- prROC(
  actual   = actual,
  response = response
)

# 5) plot by species
plot(roc)

# 5.1) summarise
summary(roc)

# 6) provide custom
# threholds
roc &lt;- prROC(
  actual     = actual,
  response   = response,
  thresholds = seq(
    1,
    0,
    length.out = 20
  )
)

# 5) plot by species
plot(roc)
</code></pre>

<hr>
<h2 id='rae.numeric'>Relative Absolute Error</h2><span id='topic+rae.numeric'></span><span id='topic+weighted.rae.numeric'></span><span id='topic+rae'></span><span id='topic+weighted.rae'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+rae">rae()</a></code>-function calculates the normalized <a href="https://www.statisticshowto.com/relative-absolute-error/">relative absolute error</a> between
the predicted and observed &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.rae">weighted.rae()</a></code> function computes the weigthed relative absolute error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
rae(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.rae(actual, predicted, w, ...)

## Generic S3 method
rae(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.rae(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rae.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rae.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rae.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="rae.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The Relative Absolute Error (RAE) is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">
  \text{RAE} = \frac{\sum_{i=1}^n |y_i - \upsilon_i|}{\sum_{i=1}^n |y_i - \bar{y}|}
</code>
</p>

<p>Where <code class="reqn">y_i</code> are the <code>actual</code> values, <code class="reqn">\upsilon_i</code> are the <code>predicted</code> values,
and <code class="reqn">\bar{y}</code> is the mean of the <code>actual</code> values.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Relative Absolute Error (RAE)
cat(
  "Relative Absolute Error", rae(
    actual    = actual,
    predicted = predicted,
  ),
  "Relative Absolute Error (weighted)", weighted.rae(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='recall.factor'>Recall</h2><span id='topic+recall.factor'></span><span id='topic+weighted.recall.factor'></span><span id='topic+recall.cmatrix'></span><span id='topic+sensitivity.factor'></span><span id='topic+weighted.sensitivity.factor'></span><span id='topic+sensitivity.cmatrix'></span><span id='topic+tpr.factor'></span><span id='topic+weighted.tpr.factor'></span><span id='topic+tpr.cmatrix'></span><span id='topic+recall'></span><span id='topic+sensitivity'></span><span id='topic+tpr'></span><span id='topic+weighted.recall'></span><span id='topic+weighted.sensitivity'></span><span id='topic+weighted.tpr'></span>

<h3>Description</h3>

<p>A generic funcion for the <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">Recall</a>. Use <code><a href="#topic+weighted.fdr">weighted.fdr()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">Recall</a>.
</p>


<h4>Other names</h4>

<p>Sensitivity, True Positive Rate
</p>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
recall(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.recall(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
recall(x, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
sensitivity(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.sensitivity(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
sensitivity(x, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
tpr(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.tpr(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
tpr(x, micro = NULL, na.rm = TRUE, ...)

## Generic S3 method
recall(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
sensitivity(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
tpr(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.recall(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.sensitivity(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.tpr(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recall.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="recall.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="recall.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="recall.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="recall.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="recall.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="recall.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\rho} \in [0, 1]</code> be the proportion of true positives among the actual positives. The recall of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\rho} = \frac{\#TP_k}{\#TP_k + \#FN_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TP_k</code> is the number of true positives, and
</p>
</li>
<li> <p><code class="reqn">\#FN_k</code> is the number of false negatives.
</p>
</li></ul>



<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using Recall

# 4.1) unweighted Recall
recall(
  actual    = actual,
  predicted = predicted
)

# 4.2) weighted Recall
weighted.recall(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall performance
# using micro-averaged Recall
cat(
  "Micro-averaged Recall", recall(
    actual    = actual,
    predicted = predicted,
    micro     = TRUE
  ),
  "Micro-averaged Recall (weighted)", weighted.recall(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='rmse.numeric'>Root Mean Squared Error</h2><span id='topic+rmse.numeric'></span><span id='topic+weighted.rmse.numeric'></span><span id='topic+rmse'></span><span id='topic+weighted.rmse'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+rmse">rmse()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">root mean squared error</a> between
the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.rmse">weighted.rmse()</a></code> function computes the weighted root mean squared error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
rmse(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.rmse(actual, predicted, w, ...)

## Generic S3 method
rmse(
 actual,
 predicted,
 ...
)

weighted.rmse(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmse.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rmse.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rmse.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="rmse.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \sqrt{\frac{1}{n} \sum_i^n (y_i - \upsilon_i)^2}
</code>
</p>

<p>Where <code class="reqn">y_i</code> and <code class="reqn">\upsilon_i</code> are the <code>actual</code> and <code>predicted</code> values respectively.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Root Mean Squared Error (RMSE)
cat(
  "Root Mean Squared Error", rmse(
    actual    = actual,
    predicted = predicted,
  ),
  "Root Mean Squared Error (weighted)", weighted.rmse(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)

</code></pre>

<hr>
<h2 id='rmsle.numeric'>Root Mean Squared Logarithmic Error</h2><span id='topic+rmsle.numeric'></span><span id='topic+weighted.rmsle.numeric'></span><span id='topic+rmsle'></span><span id='topic+weighted.rmsle'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+rmsle">rmsle()</a></code>-function computes the root mean squared logarithmic error between the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.rmsle">weighted.rmsle()</a></code> function computes the weighted root mean squared logarithmic error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
rmsle(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.rmsle(actual, predicted, w, ...)

## Generic S3 method
rmsle(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.rmsle(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmsle.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rmsle.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rmsle.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="rmsle.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \sqrt{\frac{1}{n} \sum_i^n (\log(1 + y_i) - \log(1 + \upsilon_i))^2}
</code>
</p>

<p>Where <code class="reqn">y_i</code> and <code class="reqn">\upsilon_i</code> are the <code>actual</code> and <code>predicted</code> values respectively.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)


# 2) evaluate in-sample model
# performance using Root Mean Squared Logarithmic Error (RMSLE)
cat(
  "Root Mean Squared Logarithmic Error", rmsle(
    actual    = actual,
    predicted = predicted,
  ),
  "Root Mean Squared Logarithmic Error (weighted)", weighted.rmsle(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='roc.auc.matrix'>Area under the Receiver Operator Characteristics Curve</h2><span id='topic+roc.auc.matrix'></span><span id='topic+weighted.roc.auc.matrix'></span><span id='topic+roc.auc'></span><span id='topic+weighted.roc.auc'></span>

<h3>Description</h3>

<p>A generic function for the area under the Receiver Operator Characteristics Curve. Use <code><a href="#topic+weighted.roc.auc">weighted.roc.auc()</a></code> for the weighted area under the Receiver Operator Characteristics Curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matrix'
roc.auc(actual, response, micro = NULL, method = 0L, ...)

## S3 method for class 'matrix'
weighted.roc.auc(actual, response, w, micro = NULL, method = 0L, ...)

## Generic S3 method
roc.auc(
 actual,
 response,
 micro  = NULL,
 method = 0,
 ...
)

## Generic S3 method
weighted.roc.auc(
 actual,
 response,
 w,
 micro  = NULL,
 method = 0,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="roc.auc.matrix_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="roc.auc.matrix_+3A_response">response</code></td>
<td>
<p>A <code class="reqn">n \times k</code> &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-<a href="base.html#topic+matrix">matrix</a>. The estimated response probabilities for each class <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="roc.auc.matrix_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="roc.auc.matrix_+3A_method">method</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; value (default: <code class="reqn">0</code>). Defines the underlying method of calculating the area under the curve. If <code class="reqn">0</code> it is calculated using the <code>trapezoid</code>-method, if <code class="reqn">1</code> it is calculated using the <code>step</code>-method.</p>
</td></tr>
<tr><td><code id="roc.auc.matrix_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="roc.auc.matrix_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;  vector  of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p><strong>Trapezoidal rule</strong>
</p>
<p>The <strong>trapezoidal rule</strong> approximates the integral of a function <code class="reqn">f(x)</code> between
<code class="reqn">x = a</code> and <code class="reqn">x = b</code> using trapezoids formed between consecutive points. If
we have points <code class="reqn">x_0, x_1, \ldots, x_n</code> (with <code class="reqn">a = x_0 &lt; x_1 &lt; \cdots &lt; x_n = b</code>)
and corresponding function values <code class="reqn">f(x_0), f(x_1), \ldots, f(x_n)</code>, the area under
the curve <code class="reqn">A_T</code> is approximated by:
</p>
<p style="text-align: center;"><code class="reqn">
  A_T \approx \sum_{k=1}^{n} \frac{f(x_{k-1}) + f(x_k)}{2} \bigl[x_k - x_{k-1}\bigr].
</code>
</p>

<p><strong>Step-function method</strong>
</p>
<p>The <strong>step-function (rectangular) method</strong> uses the value of the function at one
endpoint of each subinterval to form rectangles. With the same partition
<code class="reqn">x_0, x_1, \ldots, x_n</code>, the rectangular approximation <code class="reqn">A_S</code> can be written as:
</p>
<p style="text-align: center;"><code class="reqn">
  A_S \approx \sum_{k=1}^{n} f(x_{k-1}) \bigl[x_k - x_{k-1}\bigr].
</code>
</p>



<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
response &lt;- predict(model, type = "response")

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) generate receiver operator characteristics
# data

# 4.1) calculate residual
# probability and store as matrix
response &lt;- matrix(
  data = cbind(response, 1-response),
  nrow = length(actual)
)

# 4.2) calculate class-wise
# area under the curve
roc.auc(
  actual   = actual,
  response = response 
)

# 4.3) calculate class-wise
# weighted area under the curve
weighted.roc.auc(
  actual   = actual,
  response = response,
  w        = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall area under
# the curve
cat(
  "Micro-averaged area under the ROC curve", roc.auc(
    actual    = actual,
    response  = response,
    micro     = TRUE
  ),
  "Micro-averaged area under the ROC curve (weighted)", weighted.roc.auc(
    actual    = actual,
    response  = response,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='ROC.factor'>Receiver Operator Characteristics</h2><span id='topic+ROC.factor'></span><span id='topic+weighted.ROC.factor'></span><span id='topic+ROC'></span><span id='topic+weighted.ROC'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+ROC">ROC()</a></code>-function computes the <code><a href="#topic+tpr">tpr()</a></code> and <code><a href="#topic+fpr">fpr()</a></code> at thresholds provided by the <code class="reqn">response</code>- or <code class="reqn">thresholds</code>-vector. The function
constructs a <code><a href="base.html#topic+data.frame">data.frame()</a></code> grouped by <code class="reqn">k</code>-classes where each class is treated as a binary classification problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
ROC(actual, response, thresholds = NULL, presorted = FALSE, ...)

## S3 method for class 'factor'
weighted.ROC(actual, response, w, thresholds = NULL, presorted = FALSE, ...)

## Generic S3 method
ROC(
 actual,
 response,
 thresholds = NULL,
 presorted  = FALSE,
 ...
)

## Generic S3 method
weighted.ROC(
 actual,
 response,
 w,
 thresholds = NULL,
 presorted  = FALSE,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ROC.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="ROC.factor_+3A_response">response</code></td>
<td>
<p>A <code class="reqn">n \times k</code> &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-<a href="base.html#topic+matrix">matrix</a>. The estimated response probabilities for each class <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="ROC.factor_+3A_thresholds">thresholds</code></td>
<td>
<p>An optional &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code> (default: <a href="base.html#topic+NULL">NULL</a>).</p>
</td></tr>
<tr><td><code id="ROC.factor_+3A_presorted">presorted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value <a href="base.html#topic+length">length</a> 1 (default: <a href="base.html#topic+FALSE">FALSE</a>). If <a href="base.html#topic+TRUE">TRUE</a> the input will not be sorted by threshold.</p>
</td></tr>
<tr><td><code id="ROC.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="ROC.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="base.html#topic+data.frame">data.frame</a> on the following form,
</p>
<table role = "presentation">
<tr><td><code>threshold</code></td>
<td>
<p>&lt;<a href="base.html#topic+numeric">numeric</a>&gt; Thresholds used to determine <code><a href="#topic+tpr">tpr()</a></code> and <code><a href="#topic+fpr">fpr()</a></code></p>
</td></tr>
<tr><td><code>level</code></td>
<td>
<p>&lt;<a href="base.html#topic+character">character</a>&gt; The level of the actual &lt;<a href="base.html#topic+factor">factor</a>&gt;</p>
</td></tr>
<tr><td><code>label</code></td>
<td>
<p>&lt;<a href="base.html#topic+character">character</a>&gt; The levels of the actual &lt;<a href="base.html#topic+factor">factor</a>&gt;</p>
</td></tr>
<tr><td><code>fpr</code></td>
<td>
<p>&lt;<a href="base.html#topic+numeric">numeric</a>&gt; The false positive rate</p>
</td></tr>
<tr><td><code>tpr</code></td>
<td>
<p>&lt;<a href="base.html#topic+numeric">numeric</a>&gt; The true positve rate</p>
</td></tr>
</table>


<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\sigma} \in [0, 1]</code> be the proportion of true negatives among the actual negatives. The specificity of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\sigma} = \frac{\#TN_k}{\#TN_k + \#FP_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TN_k</code> is the number of true negatives, and
</p>
</li>
<li> <p><code class="reqn">\#FP_k</code> is the number of false positives.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
response &lt;- predict(model, type = "response")

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) generate reciever
# operator characteristics

# 4.1) calculate residual
# probability and store as matrix
response &lt;- matrix(
  data = cbind(response, 1-response),
  nrow = length(actual)
)

# 4.2) construct 
# data.frame
roc &lt;- ROC(
  actual   = actual,
  response = response
)

# 5) plot by species
plot(roc)

# 5.1) summarise
summary(roc)

# 6) provide custom
# threholds
roc &lt;- ROC(
  actual     = actual,
  response   = response,
  thresholds = seq(
    1,
    0,
    length.out = 20
  )
)

# 5) plot by species
plot(roc)

</code></pre>

<hr>
<h2 id='rrmse.numeric'>Relative Root Mean Squared Error</h2><span id='topic+rrmse.numeric'></span><span id='topic+weighted.rrmse.numeric'></span><span id='topic+rrmse'></span><span id='topic+weighted.rrmse'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+rrmse">rrmse()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">Relative Root Mean Squared Error</a> between
the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.rrmse">weighted.rrmse()</a></code> function computes the weighted Relative Root Mean Squared Error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
rrmse(actual, predicted, normalization = 1L, ...)

## S3 method for class 'numeric'
weighted.rrmse(actual, predicted, w, normalization = 1L, ...)

## Generic S3 method
rrmse(
 actual,
 predicted,
 normalization = 1,
 ...
)

## Generic S3 method
weighted.rrmse(
 actual,
 predicted,
 w,
 normalization = 1,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rrmse.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rrmse.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rrmse.numeric_+3A_normalization">normalization</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <code class="reqn">1</code>). <code class="reqn">0</code>: <a href="base.html#topic+mean">mean</a>-normalization, <code class="reqn">1</code>: <a href="base.html#topic+range">range</a>-normalization, <code class="reqn">2</code>: <a href="stats.html#topic+IQR">IQR</a>-normalization.</p>
</td></tr>
<tr><td><code id="rrmse.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="rrmse.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{RMSE}{\gamma}
</code>
</p>

<p>Where <code class="reqn">\gamma</code> is the normalization factor.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Relative Root Mean Squared Error (RRMSE)
cat(
  "IQR Relative Root Mean Squared Error", rrmse(
    actual        = actual,
    predicted     = predicted,
    normalization = 2
  ),
  "IQR Relative Root Mean Squared Error (weighted)", weighted.rrmse(
    actual        = actual,
    predicted     = predicted,
    w             = mtcars$mpg/mean(mtcars$mpg),
    normalization = 2
  ),
  sep = "\n"
)

</code></pre>

<hr>
<h2 id='rrse.numeric'>Root Relative Squared Error</h2><span id='topic+rrse.numeric'></span><span id='topic+weighted.rrse.numeric'></span><span id='topic+rrse'></span><span id='topic+weighted.rrse'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+rrse">rrse()</a></code>-function calculates the <a href="https://en.wikipedia.org/wiki/Root_mean_square_deviation">root relative  squared error</a> between
the predicted and observed &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.rrse">weighted.rrse()</a></code> function computes the weighed root relative squared errorr.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
rrse(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.rrse(actual, predicted, w, ...)

## Generic S3 method
rrse(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.rrse(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rrse.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rrse.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rrse.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="rrse.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \text{RRSE} = \sqrt{\frac{\sum_{i=1}^n (y_i - \upsilon_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}}
</code>
</p>

<p>Where <code class="reqn">y_i</code> are the <code>actual</code> values, <code class="reqn">\upsilon_i</code> are the <code>predicted</code> values,
and <code class="reqn">\bar{y}</code> is the mean of the <code>actual</code> values.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Relative Root Squared Errror (RRSE)
cat(
  "Relative Root Squared Errror", rrse(
    actual    = actual,
    predicted = predicted,
  ),
  "Relative Root Squared Errror (weighted)", weighted.rrse(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='rsq.numeric'><code class="reqn">R^2</code></h2><span id='topic+rsq.numeric'></span><span id='topic+weighted.rsq.numeric'></span><span id='topic+rsq'></span><span id='topic+weighted.rsq'></span>

<h3>Description</h3>

<p>A generic function for the <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination"><code class="reqn">R^2</code></a>. The unadjusted <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination"><code class="reqn">R^2</code></a> is returned by default.
Use <code><a href="#topic+weighted.rsq">weighted.rsq()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination"><code class="reqn">R^2</code></a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
rsq(actual, predicted, k = 0, ...)

## S3 method for class 'numeric'
weighted.rsq(actual, predicted, w, k = 0, ...)

## Generic S3 method
rsq(
 ...,
 k = 0
)

## Generic S3 method
weighted.rsq(
 ...,
 w,
 k = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rsq.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rsq.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="rsq.numeric_+3A_k">k</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1 (default: 0). For adjusted <code class="reqn">R^2</code> set <code class="reqn">k = \kappa - 1</code>, where <code class="reqn">\kappa</code> is the number of parameters.</p>
</td></tr>
<tr><td><code id="rsq.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="rsq.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">R^2 \in [-\infty, 1]</code> be the explained variation. The <code class="reqn">R^2</code> is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  R^2 = 1 - \frac{\sum{(y_i - \hat{y}_i)^2}}{\sum{(y_i-\bar{y})^2}} \frac{n-1}{n - (k + 1)}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">n</code> is the number of observations
</p>
</li>
<li> <p><code class="reqn">k</code> is the number of features
</p>
</li>
<li> <p><code class="reqn">y</code> is the actual values
</p>
</li>
<li> <p><code class="reqn">\hat{y}_i</code> is the predicted values
</p>
</li>
<li> <p><code class="reqn">\sum{(y_i - \hat{y}_i)^2}</code> is the sum of squared errors and,
</p>
</li>
<li> <p><code class="reqn">\sum{(y_i-\bar{y})^2}</code> is total sum of squared errors
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure in-sample performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) calculate performance
# using R squared adjusted and
# unadjused for features
cat(
  "Rsq", rsq(
    actual    = actual,
    predicted = fitted(model)
  ),
  "Rsq (Adjusted)", rsq(
    actual    = actual,
    predicted = fitted(model),
    k = ncol(model.matrix(model)) - 1
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='smape.numeric'>Symmetric Mean Absolutte Percentage Error</h2><span id='topic+smape.numeric'></span><span id='topic+weighted.smape.numeric'></span><span id='topic+smape'></span><span id='topic+weighted.smape'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+smape">smape()</a></code>-function computes the  <a href="https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error">symmetric mean absolute percentage error</a> between
the observed and predicted &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vectors. The <code><a href="#topic+weighted.smape">weighted.smape()</a></code> function computes the weighted symmetric mean absolute percentage error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
smape(actual, predicted, ...)

## S3 method for class 'numeric'
weighted.smape(actual, predicted, w, ...)

## Generic S3 method
smape(
 actual,
 predicted,
 ...
)

## Generic S3 method
weighted.smape(
 actual,
 predicted,
 w,
 ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smape.numeric_+3A_actual">actual</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The observed (continuous) response variable.</p>
</td></tr>
<tr><td><code id="smape.numeric_+3A_predicted">predicted</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The estimated (continuous) response variable.</p>
</td></tr>
<tr><td><code id="smape.numeric_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods.</p>
</td></tr>
<tr><td><code id="smape.numeric_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. The weight assigned to each observation in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt; vector of <a href="base.html#topic+length">length</a> 1.
</p>


<h3>Definition</h3>

<p>The metric is calculated as follows,
</p>
<p style="text-align: center;"><code class="reqn">
  \sum_i^n \frac{1}{n} \frac{|y_i - \upsilon_i|}{\frac{|y_i|+|\upsilon_i|}{2}}
</code>
</p>

<p>where <code class="reqn">y_i</code> and <code class="reqn">\upsilon_i</code> is the <code>actual</code> and <code>predicted</code> values respectively.
</p>


<h3>See Also</h3>

<p>Other Regression: 
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) fit a linear
# regression
model &lt;- lm(
  mpg ~ .,
  data = mtcars
)

# 1.1) define actual
# and predicted values
# to measure performance
actual    &lt;- mtcars$mpg
predicted &lt;- fitted(model)

# 2) evaluate in-sample model
# performance using Symmetric Mean Absolute Percentage Error (MAPE)
cat(
  "Symmetric Mean Absolute Percentage Error", mape(
    actual    = actual,
    predicted = predicted,
  ),
  "Symmetric Mean Absolute Percentage Error (weighted)", weighted.mape(
    actual    = actual,
    predicted = predicted,
    w         = mtcars$mpg/mean(mtcars$mpg)
  ),
  sep = "\n"
)
</code></pre>

<hr>
<h2 id='specificity.factor'>Specificity</h2><span id='topic+specificity.factor'></span><span id='topic+weighted.specificity.factor'></span><span id='topic+specificity.cmatrix'></span><span id='topic+tnr.factor'></span><span id='topic+weighted.tnr.factor'></span><span id='topic+tnr.cmatrix'></span><span id='topic+selectivity.factor'></span><span id='topic+weighted.selectivity.factor'></span><span id='topic+selectivity.cmatrix'></span><span id='topic+specificity'></span><span id='topic+tnr'></span><span id='topic+selectivity'></span><span id='topic+weighted.specificity'></span><span id='topic+weighted.tnr'></span><span id='topic+weighted.selectivity'></span>

<h3>Description</h3>

<p>A generic funcion for the <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">Specificity</a>. Use <code><a href="#topic+weighted.specificity">weighted.specificity()</a></code> for the weighted <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">Specificity</a>.
</p>


<h4>Other names</h4>

<p>True Negative Rate, Selectivity
</p>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
specificity(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.specificity(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
specificity(x, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
tnr(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.tnr(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
tnr(x, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
selectivity(actual, predicted, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'factor'
weighted.selectivity(actual, predicted, w, micro = NULL, na.rm = TRUE, ...)

## S3 method for class 'cmatrix'
selectivity(x, micro = NULL, na.rm = TRUE, ...)

## Generic S3 method
specificity(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
tnr(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
selectivity(
 ...,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.specificity(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.tnr(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)

## Generic S3 method
weighted.selectivity(
 ...,
 w,
 micro = NULL,
 na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="specificity.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="specificity.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; values of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels.</p>
</td></tr>
<tr><td><code id="specificity.factor_+3A_micro">micro</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt;-value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+NULL">NULL</a>). If <a href="base.html#topic+TRUE">TRUE</a> it returns the
micro average across all <code class="reqn">k</code> classes, if <a href="base.html#topic+FALSE">FALSE</a> it returns the macro average.</p>
</td></tr>
<tr><td><code id="specificity.factor_+3A_na.rm">na.rm</code></td>
<td>
<p>A &lt;<a href="base.html#topic+logical">logical</a>&gt; value of <a href="base.html#topic+length">length</a> <code class="reqn">1</code> (default: <a href="base.html#topic+TRUE">TRUE</a>). If <a href="base.html#topic+TRUE">TRUE</a>, <a href="base.html#topic+NA">NA</a> values are removed from the computation.
This argument is only relevant when <code>micro != NULL</code>.
When <code>na.rm = TRUE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(na.omit(c(1, 2, NA)))</code>.
When <code>na.rm = FALSE</code>, the computation corresponds to <code>sum(c(1, 2, NA), na.rm = TRUE) / length(c(1, 2, NA))</code>.</p>
</td></tr>
<tr><td><code id="specificity.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="specificity.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default.</p>
</td></tr>
<tr><td><code id="specificity.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>micro</code> is <a href="base.html#topic+NULL">NULL</a> (the default), a named &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> k
</p>
<p>If <code>micro</code> is <a href="base.html#topic+TRUE">TRUE</a> or <a href="base.html#topic+FALSE">FALSE</a>, a &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>Definition</h3>

<p>Let <code class="reqn">\hat{\sigma} \in [0, 1]</code> be the proportion of true negatives among the actual negatives. The specificity of the classifier is calculated as,
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\sigma} = \frac{\#TN_k}{\#TN_k + \#FP_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">\#TN_k</code> is the number of true negatives, and
</p>
</li>
<li> <p><code class="reqn">\#FP_k</code> is the number of false positives.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+zerooneloss.factor">zerooneloss.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate class-wise performance
# using Specificity

# 4.1) unweighted Specificity
specificity(
  actual    = actual,
  predicted = predicted
)

# 4.2) weighted Specificity
weighted.specificity(
  actual    = actual,
  predicted = predicted,
  w         = iris$Petal.Length/mean(iris$Petal.Length)
)

# 5) evaluate overall performance
# using micro-averaged Specificity
cat(
  "Micro-averaged Specificity", specificity(
    actual    = actual,
    predicted = predicted,
    micro     = TRUE
  ),
  "Micro-averaged Specificity (weighted)", weighted.specificity(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length),
    micro     = TRUE
  ),
  sep = "\n"
)

</code></pre>

<hr>
<h2 id='wine_quality'>Wine Quality Dataset</h2><span id='topic+wine_quality'></span>

<h3>Description</h3>

<p>This dataset contains measurements of various chemical properties of white wines
along with their quality ratings and a quality classification. The dataset was
obtained from the UCI Machine Learning Repository.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wine_quality)
</code></pre>


<h3>Format</h3>

<p>A list with two components:
</p>

<dl>
<dt>features</dt><dd><p>A data frame with 11 chemical property variables.</p>
</dd>
<dt>target</dt><dd><p>A list with two elements: <code>regression</code> (wine quality scores) and <code>class</code> (quality classification).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data is provided as a list with two components:
</p>

<dl>
<dt>features</dt><dd><p>A data frame containing the chemical properties of the wines.
The variables include:
</p>

<dl>
<dt>fixed_acidity</dt><dd><p>Fixed acidity (g/L).</p>
</dd>
<dt>volatile_acidity</dt><dd><p>Volatile acidity (g/L), mainly due to acetic acid.</p>
</dd>
<dt>citric_acid</dt><dd><p>Citric acid (g/L).</p>
</dd>
<dt>residual_sugar</dt><dd><p>Residual sugar (g/L).</p>
</dd>
<dt>chlorides</dt><dd><p>Chloride concentration (g/L).</p>
</dd>
<dt>free_sulfur_dioxide</dt><dd><p>Free sulfur dioxide (mg/L).</p>
</dd>
<dt>total_sulfur_dioxide</dt><dd><p>Total sulfur dioxide (mg/L).</p>
</dd>
<dt>density</dt><dd><p>Density of the wine (g/cm<code class="reqn">^3</code>).</p>
</dd>
<dt>pH</dt><dd><p>pH value of the wine.</p>
</dd>
<dt>sulphates</dt><dd><p>Sulphates (g/L).</p>
</dd>
<dt>alcohol</dt><dd><p>Alcohol content (% by volume).</p>
</dd>
</dl>

</dd>
<dt>target</dt><dd><p>A list containing two elements:
</p>

<dl>
<dt>regression</dt><dd><p>A numeric vector representing the wine quality scores (used as the regression target).</p>
</dd>
<dt>class</dt><dd><p>A factor with levels <code>"High Quality"</code>, <code>"Medium Quality"</code>, and <code>"Low Quality"</code>,
where classification is determined as follows:
</p>

<dl>
<dt>High Quality</dt><dd><p>quality <code class="reqn">\geq</code> 7.</p>
</dd>
<dt>Low Quality</dt><dd><p>quality <code class="reqn">\leq</code> 4.</p>
</dd>
<dt>Medium Quality</dt><dd><p>for all other quality scores.</p>
</dd>
</dl>

</dd>
</dl>

</dd>
</dl>



<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/dataset/186/wine+quality">https://archive.ics.uci.edu/dataset/186/wine+quality</a>
</p>

<hr>
<h2 id='zerooneloss.factor'>Zero-One Loss</h2><span id='topic+zerooneloss.factor'></span><span id='topic+weighted.zerooneloss.factor'></span><span id='topic+zerooneloss.cmatrix'></span><span id='topic+zerooneloss'></span><span id='topic+weighted.zerooneloss'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+zerooneloss">zerooneloss()</a></code>-function computes the <a href="https://en.wikipedia.org/wiki/Loss_functions_for_classification">zero-one Loss</a>, a classification loss function that calculates the proportion of misclassified instances between
two vectors of predicted and observed <code><a href="base.html#topic+factor">factor()</a></code> values. The <code><a href="#topic+weighted.zerooneloss">weighted.zerooneloss()</a></code> function computes the weighted zero-one loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
zerooneloss(actual, predicted, ...)

## S3 method for class 'factor'
weighted.zerooneloss(actual, predicted, w, ...)

## S3 method for class 'cmatrix'
zerooneloss(x, ...)

## Generic S3 method
zerooneloss(...)

## Generic S3 method
weighted.zerooneloss(
 ...,
 w
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zerooneloss.factor_+3A_actual">actual</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="zerooneloss.factor_+3A_predicted">predicted</code></td>
<td>
<p>A vector of &lt;<a href="base.html#topic+factor">factor</a>&gt; with <a href="base.html#topic+length">length</a> <code class="reqn">n</code>, and <code class="reqn">k</code> levels</p>
</td></tr>
<tr><td><code id="zerooneloss.factor_+3A_...">...</code></td>
<td>
<p>Arguments passed into other methods</p>
</td></tr>
<tr><td><code id="zerooneloss.factor_+3A_w">w</code></td>
<td>
<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> <code class="reqn">n</code>. <a href="base.html#topic+NULL">NULL</a> by default</p>
</td></tr>
<tr><td><code id="zerooneloss.factor_+3A_x">x</code></td>
<td>
<p>A confusion matrix created <code><a href="#topic+cmatrix">cmatrix()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &lt;<a href="base.html#topic+numeric">numeric</a>&gt;-vector of <a href="base.html#topic+length">length</a> 1
</p>


<h3>Definition</h3>

<p>The metric is calculated as follows,
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{\#FP + \#FN}{\#TP + \#TN + \#FP + \#FN}
</code>
</p>

<p>Where <code class="reqn">\#TP</code>, <code class="reqn">\#TN</code>, <code class="reqn">\#FP</code>, and <code class="reqn">\#FN</code> represent the true positives, true negatives, false positives, and false negatives, respectively.
</p>


<h3>Creating &lt;<a href="base.html#topic+factor">factor</a>&gt;</h3>

<p>Consider a classification problem with three classes: <code>A</code>, <code>B</code>, and <code>C</code>. The actual vector of <code><a href="base.html#topic+factor">factor()</a></code> values is defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] B A B B A C B C C A
#&gt; Levels: A B C
</pre></div>
<p>Here, the values 1, 2, and 3 are mapped to <code>A</code>, <code>B</code>, and <code>C</code>, respectively. Now, suppose your model does not predict any <code>B</code>'s. The predicted vector of <code><a href="base.html#topic+factor">factor()</a></code> values would be defined as follows:
</p>
<div class="sourceCode r"><pre>## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#&gt;  [1] C A C C C C C C A C
#&gt; Levels: A B C
</pre></div>
<p>In both cases, <code class="reqn">k = 3</code>, determined indirectly by the <code>levels</code> argument.
</p>


<h3>See Also</h3>

<p>Other Classification: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fmi.factor">fmi.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>
</p>
<p>Other Supervised Learning: 
<code><a href="#topic+ROC.factor">ROC.factor</a>()</code>,
<code><a href="#topic+accuracy.factor">accuracy.factor</a>()</code>,
<code><a href="#topic+baccuracy.factor">baccuracy.factor</a>()</code>,
<code><a href="#topic+ccc.numeric">ccc.numeric</a>()</code>,
<code><a href="#topic+ckappa.factor">ckappa.factor</a>()</code>,
<code><a href="#topic+cmatrix.factor">cmatrix.factor</a>()</code>,
<code><a href="#topic+dor.factor">dor.factor</a>()</code>,
<code><a href="#topic+entropy.matrix">entropy.matrix</a>()</code>,
<code><a href="#topic+fbeta.factor">fbeta.factor</a>()</code>,
<code><a href="#topic+fdr.factor">fdr.factor</a>()</code>,
<code><a href="#topic+fer.factor">fer.factor</a>()</code>,
<code><a href="#topic+fpr.factor">fpr.factor</a>()</code>,
<code><a href="#topic+huberloss.numeric">huberloss.numeric</a>()</code>,
<code><a href="#topic+jaccard.factor">jaccard.factor</a>()</code>,
<code><a href="#topic+logloss.factor">logloss.factor</a>()</code>,
<code><a href="#topic+mae.numeric">mae.numeric</a>()</code>,
<code><a href="#topic+mape.numeric">mape.numeric</a>()</code>,
<code><a href="#topic+mcc.factor">mcc.factor</a>()</code>,
<code><a href="#topic+mpe.numeric">mpe.numeric</a>()</code>,
<code><a href="#topic+mse.numeric">mse.numeric</a>()</code>,
<code><a href="#topic+nlr.factor">nlr.factor</a>()</code>,
<code><a href="#topic+npv.factor">npv.factor</a>()</code>,
<code><a href="#topic+pinball.numeric">pinball.numeric</a>()</code>,
<code><a href="#topic+plr.factor">plr.factor</a>()</code>,
<code><a href="#topic+pr.auc.matrix">pr.auc.matrix</a>()</code>,
<code><a href="#topic+prROC.factor">prROC.factor</a>()</code>,
<code><a href="#topic+precision.factor">precision.factor</a>()</code>,
<code><a href="#topic+rae.numeric">rae.numeric</a>()</code>,
<code><a href="#topic+recall.factor">recall.factor</a>()</code>,
<code><a href="#topic+rmse.numeric">rmse.numeric</a>()</code>,
<code><a href="#topic+rmsle.numeric">rmsle.numeric</a>()</code>,
<code><a href="#topic+roc.auc.matrix">roc.auc.matrix</a>()</code>,
<code><a href="#topic+rrmse.numeric">rrmse.numeric</a>()</code>,
<code><a href="#topic+rrse.numeric">rrse.numeric</a>()</code>,
<code><a href="#topic+rsq.numeric">rsq.numeric</a>()</code>,
<code><a href="#topic+smape.numeric">smape.numeric</a>()</code>,
<code><a href="#topic+specificity.factor">specificity.factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1) recode Iris
# to binary classification
# problem
iris$species_num &lt;- as.numeric(
  iris$Species == "virginica"
)

# 2) fit the logistic
# regression
model &lt;- glm(
  formula = species_num ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family  = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted &lt;- factor(
  as.numeric(
    predict(model, type = "response") &gt; 0.5
  ),
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 3.1) generate actual
# classes
actual &lt;- factor(
  x = iris$species_num,
  levels = c(1,0),
  labels = c("Virginica", "Others")
)

# 4) evaluate model
# performance using Zero-One Loss
cat(
  "Zero-One Loss", zerooneloss(
    actual    = actual,
    predicted = predicted
  ),
  "Zero-One Loss (weigthed)", weighted.zerooneloss(
    actual    = actual,
    predicted = predicted,
    w         = iris$Petal.Length/mean(iris$Petal.Length)
  ),
  sep = "\n"
)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
