<!DOCTYPE html><html><head><title>Help for package HDTSA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HDTSA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coint'><p>Identifying conintegration rank of given time series</p></a></li>
<li><a href='#factors'><p>Factor modeling: Inference for the number of factors</p></a></li>
<li><a href='#HDSReg'><p>High dimensional stochastic regression with latent factors</p></a></li>
<li><a href='#MartG_test'><p>Testing for martingale difference hypothesis in high dimension</p></a></li>
<li><a href='#PCA4_TS'><p>Principal component analysis for time serise</p></a></li>
<li><a href='#ur.test'><p>Testing for unit roots based on sample autocovariances</p></a></li>
<li><a href='#WN_test'><p>Testing for white noise hypothesis in high dimension</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>High Dimensional Time Series Analysis Tools</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-12-22</td>
</tr>
<tr>
<td>Author:</td>
<td>Chen Lin [aut, cre],
  Jinyuan Chang [aut],
  Qiwei Yao [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Chen Lin &lt;linchen@smail.swufe.edu.cn&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Procedures for high-dimensional time series analysis including factor analysis proposed by Lam and Yao (2012) &lt;<a href="https://doi.org/10.1214%2F12-AOS970">doi:10.1214/12-AOS970</a>&gt; and Chang, Guo and Yao (2015) &lt;<a href="https://doi.org/10.1016%2Fj.jeconom.2015.03.024">doi:10.1016/j.jeconom.2015.03.024</a>&gt;, martingale difference test proposed by Chang, Jiang and Shao (2021) preprint, principal component analysis proposed by Chang, Guo and Yao (2018) &lt;<a href="https://doi.org/10.1214%2F17-AOS1613">doi:10.1214/17-AOS1613</a>&gt;, identifying conintegration proposed by Zhang, Robinson and Yao (2019) &lt;<a href="https://doi.org/10.1080%2F01621459.2018.1458620">doi:10.1080/01621459.2018.1458620</a>&gt;, unit root test proposed by Chang, Cheng and Yao (2021) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasab034">doi:10.1093/biomet/asab034</a>&gt; and white noise test proposed by Chang, Yao and Zhou (2017) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasw066">doi:10.1093/biomet/asw066</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, Rcpp, clime, sandwich, methods</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Linc2021/HDTSA">https://github.com/Linc2021/HDTSA</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Linc2021/HDTSA/issues">https://github.com/Linc2021/HDTSA/issues</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-12-29 09:01:51 UTC; linchen</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-07 13:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='coint'>Identifying conintegration rank of given time series</h2><span id='topic+coint'></span>

<h3>Description</h3>

<p><code>coint</code> seeks for a contemporaneous linear
transformation for a multivariate time series such that we can identifying 
cointegration rank from the transformed series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coint(
  Y,
  lag.k = 5,
  type = c("acf", "pptest", "chang", "all"),
  c0 = 0.3,
  m = 20,
  alpha = 0.01
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coint_+3A_y">Y</code></td>
<td>
<p><code class="reqn">{\bf Y} = \{{\bf y}_1, \dots , {\bf y}_n \}'</code>, a data matrix
with <code class="reqn">n</code> rows and <code class="reqn">p</code> columns, where <code class="reqn">n</code> is the sample size and
<code class="reqn">p</code> is the dimension of <code class="reqn">{\bf y}_t</code>.</p>
</td></tr>
<tr><td><code id="coint_+3A_lag.k">lag.k</code></td>
<td>
<p>Time lag <code class="reqn">k_0</code> used to calculate the nonnegative definte
matrix <code class="reqn">\widehat{{\bf W}}_y</code>: </p>
<p style="text-align: center;"><code class="reqn">\widehat{\mathbf{W}}_y\ =\
\sum_{k=0}^{k_0}\widehat{\mathbf{\Sigma}}_y(k)\widehat{\mathbf{\Sigma}}_y(k)'</code>
</p>

<p>where <code class="reqn">\widehat{\bf \Sigma}_y(k)</code> is the sample autocovariance of
<code class="reqn"> \widehat{{\bf y}_t}</code> at lag <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="coint_+3A_type">type</code></td>
<td>
<p>The method of identifying cointegration rank after segment 
procedure. Option is <code>'acf'</code>, <code>'all'</code>, <code>'chang'</code> or <code>'pptest'</code>
, the latter two methods use the unit-root test method to identify the 
cointegration rank, and the option <code>type = 'all'</code> means use all three
methods to identify the cointegration rank. Default is <code>type = 'acf'</code>.
See Sections 2.3 in Zhang, Robinson and Yao (2019) for more information.</p>
</td></tr>
<tr><td><code id="coint_+3A_c0">c0</code></td>
<td>
<p>The prescribed constant for identifying 
cointegration rank using <code>"acf"</code> method. Default is 0.3.[See (2.3) in
Zhang, Robinson and Yao (2019)].</p>
</td></tr>
<tr><td><code id="coint_+3A_m">m</code></td>
<td>
<p>The prescribed constant for identifying 
cointegration rank using <code>"acf"</code> method. Default is 20. [See (2.3) in
Zhang, Robinson and Yao (2019)].</p>
</td></tr>
<tr><td><code id="coint_+3A_alpha">alpha</code></td>
<td>
<p>The prescribed significance level for identifying 
cointegration rank using <code>"pptest","chang"</code> method. Default is 0.01.
[See (2.3) in Zhang, Robinson and Yao (2019)].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>A <code class="reqn">1 \times 1</code> matrix representing the cointegration rank.
If <code>'type' = 'all'</code>, then return a <code class="reqn">1 \times 3</code> matrix representing
the cointegration rank of all three methods.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, R., Robinson, P. &amp; Yao, Q. (2019).  <em>Identifying 
Cointegration by Eigenanalysis</em>.  Journal of the American Statistical 
Association, Vol. 114, pp. 916&ndash;927
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- 10
n &lt;- 1000
r &lt;- 3
d &lt;- 1
X &lt;- mat.or.vec(p, n)
X[1,] &lt;- arima.sim(n-d, model = list(order=c(0, d, 0)))
for(i in 2:3)X[i,] &lt;- rnorm(n)
for(i in 4:(r+1)) X[i, ] &lt;- arima.sim(model = list(ar = 0.5), n)
for(i in (r+2):p) X[i, ] &lt;- arima.sim(n = (n-d), model = list(order=c(1, d, 1), ar=0.6, ma=0.8))
M1 &lt;- matrix(c(1, 1, 0, 1/2, 0, 1, 0, 1, 0), ncol = 3, byrow = TRUE)
A &lt;- matrix(runif(p*p, -3, 3), ncol = p)
A[1:3,1:3] &lt;- M1
Y &lt;- t(A%*%X)
coint(Y, type = "all")
</code></pre>

<hr>
<h2 id='factors'>Factor modeling: Inference for the number of factors</h2><span id='topic+factors'></span>

<h3>Description</h3>

<p><code>factors()</code> deals with factor modeling for high-dimensional
time series proposed in Lam and Yao (2012):</p>
<p style="text-align: center;"><code class="reqn">{\bf y}_t = {\bf Ax}_t +
{\boldsymbol{\epsilon}}_t, </code>
</p>
<p> where <code class="reqn">{\bf x}_t</code> is an <code class="reqn">r \times 1</code>
latent process with (unknown) <code class="reqn">r \leq p</code>, <code class="reqn">{\bf A}</code> is a <code class="reqn">p
\times r</code> unknown constant matrix, and <code class="reqn"> {\boldsymbol{\epsilon}}_t \sim
\mathrm{WN}({\boldsymbol{\mu}}_{\epsilon}, {\bf \Sigma}_{\epsilon})</code> is a
vector white noise process. The number of factors <code class="reqn">r</code> and the factor
loadings <code class="reqn">{\bf A}</code> can be estimated in terms of an eigenanalysis for a
nonnegative definite matrix, and is therefore applicable when the dimension
of <code class="reqn">{\bf y}_t</code> is on the order of a few thousands. This function aims to
estimate the number of factors <code class="reqn">r</code> and the factor loading matrix
<code class="reqn">{\bf A}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factors(Y, lag.k = 5, twostep = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factors_+3A_y">Y</code></td>
<td>
<p><code class="reqn">{\bf Y} = \{{\bf y}_1, \dots , {\bf y}_n \}'</code>, a data matrix
with <code class="reqn">n</code> rows and <code class="reqn">p</code> columns, where <code class="reqn">n</code> is the sample size and
<code class="reqn">p</code> is the dimension of <code class="reqn">{\bf y}_t</code>.</p>
</td></tr>
<tr><td><code id="factors_+3A_lag.k">lag.k</code></td>
<td>
<p>Time lag <code class="reqn">k_0</code> used to calculate the nonnegative definte
matrix <code class="reqn"> \widehat{\mathbf{M}}</code>: </p>
<p style="text-align: center;"><code class="reqn">\widehat{\mathbf{M}}\ =\
\sum_{k=1}^{k_0}\widehat{\mathbf{\Sigma}}_y(k)\widehat{\mathbf{\Sigma}}_y(k)',
</code>
</p>
<p> where <code class="reqn">\widehat{\bf \Sigma}_y(k)</code> is the sample autocovariance of
<code class="reqn"> {\bf y}_t</code> at lag <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="factors_+3A_twostep">twostep</code></td>
<td>
<p>Logical. If <code>FALSE</code> (the default), then standard
procedures [See Section 2.2 in Lam and Yao (2012)] for estimating <code class="reqn">r</code>
and <code class="reqn">{\bf A}</code> will be implemented. If <code>TRUE</code>, then a two step
estimation procedure [See Section 4 in Lam and Yao (2012)] will be
implemented for estimating <code class="reqn">r</code> and <code class="reqn">{\bf A}</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;factors&quot; is a list containing the following
components: </p>
<table>
<tr><td><code>factor_num</code></td>
<td>
<p>The estimated number of factors
<code class="reqn">\hat{r}</code>.</p>
</td></tr> <tr><td><code>loading.mat</code></td>
<td>
<p>The estimated <code class="reqn">p \times r</code> factor
loading matrix <code class="reqn">\widehat{\bf A}</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Lam, C. &amp; Yao, Q. (2012). <em>Factor modelling for
high-dimensional time series: Inference for the number of factors</em>, The
Annals of Statistics, Vol. 40, pp. 694&ndash;726.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate x_t
p &lt;- 400
n &lt;- 400
r &lt;- 3
X &lt;- mat.or.vec(n, r)
A &lt;- matrix(runif(p*r, -1, 1), ncol=r)
x1 &lt;- arima.sim(model=list(ar=c(0.6)), n=n)
x2 &lt;- arima.sim(model=list(ar=c(-0.5)), n=n)
x3 &lt;- arima.sim(model=list(ar=c(0.3)), n=n)
eps &lt;- matrix(rnorm(n*p), p, n)
X &lt;- t(cbind(x1, x2, x3))
Y &lt;- A %*% X + eps
Y &lt;- t(Y)
fac &lt;- factors(Y,lag.k=2)
r_hat &lt;- fac$factor_num
loading_Mat &lt;- fac$loading.mat
</code></pre>

<hr>
<h2 id='HDSReg'>High dimensional stochastic regression with latent factors</h2><span id='topic+HDSReg'></span>

<h3>Description</h3>

<p><code>HDSReg()</code> considers a multivariate time series model which
represents a high dimensional vector process as a sum of three terms: a
linear regression of some observed regressors, a linear combination of some
latent and serially correlated factors, and a vector white noise:</p>
<p style="text-align: center;"><code class="reqn">{\bf
y}_t = {\bf Dz}_t + {\bf Ax}_t + {\boldsymbol {\epsilon}}_t,</code>
</p>
<p> where <code class="reqn">{\bf
y}_t</code> and <code class="reqn">{\bf z}_t</code> are, respectively, observable <code class="reqn">p\times 1</code> and
<code class="reqn">m \times 1</code> time series, <code class="reqn">{\bf x}_t</code> is an <code class="reqn">r \times 1</code> latent
factor process, <code class="reqn">{\boldsymbol{\epsilon}}_t \sim
\mathrm{WN}({\boldsymbol{0}},{\bf \Sigma}_{\epsilon}) </code> is a white noise with
zero mean and covariance matrix <code class="reqn">{\bf \Sigma}_{\epsilon}</code> and
<code class="reqn">{\boldsymbol{\epsilon}}_t</code> is uncorrelated with <code class="reqn">({\bf z}_t, {\bf
x}_t)</code>, <code class="reqn">{\bf D}</code> is an unknown regression coefficient matrix, and
<code class="reqn">{\bf A}</code> is an unknown factor loading matrix. This procedure proposed in
Chang, Guo and Yao (2015) aims to estimate the unknown regression coefficient
matrix <code class="reqn">{\bf D}</code>, the number of factors <code class="reqn">r</code> and the factor loading
matrix <code class="reqn">{\bf A}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HDSReg(Y, Z, D = NULL, lag.k = 1, twostep = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HDSReg_+3A_y">Y</code></td>
<td>
<p><code class="reqn">{\bf Y} = \{{\bf y}_1, \dots , {\bf y}_n \}'</code>, a data matrix
with <code class="reqn">n</code> rows and <code class="reqn">p</code> columns, where <code class="reqn">n</code> is the sample size and
<code class="reqn">p</code> is the dimension of <code class="reqn">{\bf y}_t</code>.</p>
</td></tr>
<tr><td><code id="HDSReg_+3A_z">Z</code></td>
<td>
<p><code class="reqn">{\bf Z} = \{{\bf z}_1, \dots , {\bf z}_n \}'</code>, a data matrix
representing some observed regressors with <code class="reqn">n</code> rows and <code class="reqn">m</code>
columns, where <code class="reqn">n</code> is the sample size and <code class="reqn">m</code> is the dimension of
<code class="reqn">{\bf z}_t</code>.</p>
</td></tr>
<tr><td><code id="HDSReg_+3A_d">D</code></td>
<td>
<p>A <code class="reqn">p\times m</code> regression coefficient matrix <code class="reqn">\widetilde{\bf
D}</code>. If <code>D = NULL</code> (the default), our procedure will estimate
<code class="reqn">{\bf D}</code> first and let <code class="reqn">\widetilde{\bf D}</code> be the estimate of
<code class="reqn">{\bf D}</code>. If <code>D</code> is given by R users, then
<code class="reqn">\widetilde{\bf D}={\bf D}</code>.</p>
</td></tr>
<tr><td><code id="HDSReg_+3A_lag.k">lag.k</code></td>
<td>
<p>Time lag <code class="reqn">k_0</code> used to calculate the nonnegative definte
matrix <code class="reqn"> \widehat{\mathbf{M}}</code>: </p>
<p style="text-align: center;"><code class="reqn">\widehat{\mathbf{M}}\ =\
\sum_{k=1}^{k_0}\widehat{\mathbf{\Sigma}}_{\eta}(k)\widehat{\mathbf{\Sigma}}_{\eta}(k)',
</code>
</p>
<p> where <code class="reqn">\widehat{\bf \Sigma}_{\eta}(k)</code> is the sample autocovariance
of <code class="reqn"> {\boldsymbol {\eta}}_t = {\bf y}_t - \widetilde{\bf D}{\bf z}_t</code>
at lag <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="HDSReg_+3A_twostep">twostep</code></td>
<td>
<p>Logical. If <code>FALSE</code> (the default), then standard
procedures (see <code><a href="#topic+factors">factors</a></code>) will be implemented to estimate
<code class="reqn">r</code> and <code class="reqn">{\bf A}</code>. If <code>TRUE</code>, then a two step estimation
procedure (see <code><a href="#topic+factors">factors</a></code>) will be implemented to estimate
<code class="reqn">r</code> and <code class="reqn">{\bf A}</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;HDSReg&quot; is a list containing the following
components:
</p>
<table>
<tr><td><code>factor_num</code></td>
<td>
<p>The estimated number of factors <code class="reqn">\hat{r}</code>.</p>
</td></tr>
<tr><td><code>reg.coff.mat</code></td>
<td>
<p>The estimated <code class="reqn">p \times m</code> regression coefficient
matrix <code class="reqn">\widetilde{\bf D}</code> if <code>D</code> is not given.</p>
</td></tr>
<tr><td><code>loading.mat</code></td>
<td>
<p>The estimated <code class="reqn">p \times m</code> factor loading matrix
<code class="reqn">{\bf \widehat{A}}</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chang, J., Guo, B. &amp; Yao, Q. (2015).  <em>High dimensional
stochastic regression with latent factors, endogeneity and nonlinearity</em>,
Journal of Econometrics, Vol. 189, pp. 297–312.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+factors">factors</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 400
p &lt;- 200
m &lt;- 2
r &lt;- 3
X &lt;- mat.or.vec(n,r)
x1 &lt;- arima.sim(model=list(ar=c(0.6)),n=n)
x2 &lt;- arima.sim(model=list(ar=c(-0.5)),n=n)
x3 &lt;- arima.sim(model=list(ar=c(0.3)),n=n)
X &lt;- cbind(x1,x2,x3)
X &lt;- t(X)

Z &lt;- mat.or.vec(m,n)
S1 &lt;- matrix(c(5/8,1/8,1/8,5/8),2,2)
Z[,1] &lt;- c(rnorm(m))
for(i in c(2:n)){
  Z[,i] &lt;- S1%*%Z[, i-1] + c(rnorm(m))
}
D &lt;- matrix(runif(p*m, -2, 2), ncol=m)
A &lt;- matrix(runif(p*r, -2, 2), ncol=r)
eps &lt;- mat.or.vec(n, p)
eps &lt;- matrix(rnorm(n*p), p, n)
Y &lt;- D %*% Z + A %*% X + eps
Y &lt;- t(Y)
Z &lt;- t(Z)
res1 &lt;- HDSReg(Y,Z,D,lag.k=2)
res2 &lt;- HDSReg(Y,Z,lag.k=2)
</code></pre>

<hr>
<h2 id='MartG_test'>Testing for martingale difference hypothesis in high dimension</h2><span id='topic+MartG_test'></span>

<h3>Description</h3>

<p><code>MartG_test()</code> implements a new test proposed in
Chang, Jiang and Shao (2021) for the following hypothesis testing problem: 
</p>
<p style="text-align: center;"><code class="reqn">H_0:\{{\bf x}_t\}_{t=1}^n\mathrm{\ is\ a\ MDS\ \ versus\ \ }H_1:
\{{\bf x}_t\}_{t=1}^n\mathrm{\ is\ not\ a\ MDS,} </code>
</p>
<p> where 
MDS is the abbreviation of &quot;martingale difference sequence&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MartG_test(
  X,
  lag.k = 2,
  B = 1000,
  type = c("Linear", "Quad"),
  alpha = 0.05,
  kernel.type = c("QS", "Par", "Bart")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MartG_test_+3A_x">X</code></td>
<td>
<p><code class="reqn">{\bf X} = \{{\bf x}_1, \dots , {\bf x}_n \}'</code>, an <code class="reqn">n\times
p</code> sample matrix, where <code class="reqn">n</code> is the sample size and <code class="reqn">p</code> is the 
dimension of <code class="reqn">{\bf x}_t</code>.</p>
</td></tr>
<tr><td><code id="MartG_test_+3A_lag.k">lag.k</code></td>
<td>
<p>Time lag <code class="reqn">K</code>, a positive integer, used to calculate the test
statistic. Default is <code>lag.k</code> <code class="reqn">=2</code>.</p>
</td></tr>
<tr><td><code id="MartG_test_+3A_b">B</code></td>
<td>
<p>Bootstrap times for generating multivariate normal distributed 
random vectors in calculating the critical value. 
Default is <code>B</code> <code class="reqn">=2000</code>.</p>
</td></tr>
<tr><td><code id="MartG_test_+3A_type">type</code></td>
<td>
<p>String, a map is chosen by the R users, such as the
default option is <code>'Linear'</code> means linear identity 
map (<code class="reqn">\boldsymbol \phi({\bf x})={\bf x}</code>). Also including another 
option <code>'Quad'</code> (Both linear and quadratic terms 
<code class="reqn">\boldsymbol \phi({\bf x})=\{{\bf x}',({\bf x}^2)'\}'</code>). Also the users
can choose set the map themselves, use for example <code>expression(X, X^2)</code>,
<code>quote(X, X^2)</code>, <code>parse(X, X^2)</code>, <code>substitute(X, X^2)</code> or 
just map without function (such as cbind(X, X^2)) to set their own map. 
See Section 2.1 in Chang, Jiang and Shao (2021) for more information.</p>
</td></tr>
<tr><td><code id="MartG_test_+3A_alpha">alpha</code></td>
<td>
<p>The prescribed significance level. Default is 0.05.</p>
</td></tr>
<tr><td><code id="MartG_test_+3A_kernel.type">kernel.type</code></td>
<td>
<p>String, an option for choosing the symmetric kernel 
used in the estimation of long-run covariance matrix, 
for example, <code>'QS'</code> (Quadratic spectral kernel), 
<code>'Par'</code> (Parzen kernel) and <code>'Bart'</code> 
(Bartlett kernel), see Andrews (1991) for more 
information. Default option is <code>kernel.type = 'QS'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;MartG_test&quot; is a list containing the following
components:
</p>
<table>
<tr><td><code>reject</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, it means rejecting the null
hypothesis, otherwise it means not rejecting the null hypothesis. </p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Numerical value which represents the p-value of the test.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chang, J., Jiang, Q. &amp; Shao, X. (2021). <em>Testing the
martingale difference hypothesis in high dimension</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200
p &lt;- 10
X &lt;- matrix(rnorm(n*p),n,p)
res &lt;- MartG_test(X, type="Linear")
res &lt;- MartG_test(X, type=cbind(X, X^2)) #the same as Linear type
res &lt;- MartG_test(X, type=quote(cbind(X, X^2))) # expr using quote
res &lt;- MartG_test(X, type=substitute(cbind(X, X^2))) # expr using substitute
res &lt;- MartG_test(X, type=expression(cbind(X, X^2))) # expr using expression
res &lt;- MartG_test(X, type=parse(text="cbind(X, X^2)")) # expr using parse
map_fun &lt;- function(X) {X &lt;- cbind(X,X^2); X}
res &lt;- MartG_test(X, type=map_fun)
Pvalue &lt;- res$p.value
rej &lt;- res$reject
</code></pre>

<hr>
<h2 id='PCA4_TS'>Principal component analysis for time serise</h2><span id='topic+PCA4_TS'></span>

<h3>Description</h3>

<p><code>PCA4_TS()</code> seeks for a contemporaneous linear
transformation for a multivariate time series such that the transformed
series is segmented into several lower-dimensional subseries: </p>
<p style="text-align: center;"><code class="reqn">{\bf
  y}_t={\bf Ax}_t,</code>
</p>
<p> where <code class="reqn">{\bf x}_t</code> is an unobservable <code class="reqn">p \times 1</code>
weakly stationary time series consisting of <code class="reqn">q\ (\geq 1)</code> both
contemporaneously and serially uncorrelated subseries. See Chang, Guo and
Yao (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PCA4_TS(
  Y,
  lag.k = 5,
  thresh = FALSE,
  tuning.vec = NULL,
  K = 5,
  prewhiten = TRUE,
  permutation = c("max", "fdr"),
  m = NULL,
  beta,
  just4pre = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PCA4_TS_+3A_y">Y</code></td>
<td>
<p><code class="reqn">{\bf Y} = \{{\bf y}_1, \dots , {\bf y}_n \}'</code>, a data matrix
with <code class="reqn">n</code> rows and <code class="reqn">p</code> columns, where <code class="reqn">n</code> is the sample size and
<code class="reqn">p</code> is the dimension of <code class="reqn">{\bf y}_t</code>. The procedure will first
normalize <code class="reqn">{\bf y}_t</code> as <code class="reqn">\widehat{{\bf V}}^{-1/2}{\bf y}_t</code>, where
<code class="reqn">\widehat{{\bf V}}</code> is an estimator for covariance of <code class="reqn">{\bf y}_t</code>.
See details below for the selection of <code class="reqn">\widehat{{\bf V}}^{-1}</code>.</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_lag.k">lag.k</code></td>
<td>
<p>Time lag <code class="reqn">k_0</code> used to calculate the nonnegative definte
matrix <code class="reqn">\widehat{{\bf W}}_y</code>: </p>
<p style="text-align: center;"><code class="reqn">\widehat{\mathbf{W}}_y\ =\
\sum_{k=0}^{k_0}\widehat{\mathbf{\Sigma}}_y(k)\widehat{\mathbf{\Sigma}}_y(k)'=\mathbf{I}_p+\sum_{k=1}^{k_0}\widehat{\mathbf{\Sigma}}_y(k)\widehat{\mathbf{\Sigma}}_y(k)',
 </code>
</p>
<p> where <code class="reqn">\widehat{\bf \Sigma}_y(k)</code> is the sample autocovariance of
<code class="reqn"> \widehat{{\bf V}}^{-1/2}{\bf y}_t</code> at lag <code class="reqn">k</code>. See (2.5) in
Chang, Guo and Yao (2018).</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_thresh">thresh</code></td>
<td>
<p>Logical. If <code>FALSE</code> (the default), no thresholding will
be applied to estimate <code class="reqn">\widehat{{\bf W}}_y</code>. If <code>TRUE</code>, a
thresholding method will be applied first to estimate <code class="reqn">\widehat{{\bf
W}}_y</code>, see (3.5) in Chang, Guo and Yao (2018).</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_tuning.vec">tuning.vec</code></td>
<td>
<p>The value of the tuning parameter <code class="reqn">\lambda</code> in the
thresholding level <code class="reqn"> u = \lambda \sqrt{n^{-1}\log p}</code>, where default
value is 2. If <code>tuning.vec</code> is a vector, then a cross validation
method proposed in Cai and Liu (2011) will be used to choose the best
tuning parameter <code class="reqn">\lambda</code>.</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_k">K</code></td>
<td>
<p>The number of folders used in the cross validation for the
selection of <code class="reqn">\lambda</code>, the default is 5. It is required when
<code>thresh = TRUE</code>.</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_prewhiten">prewhiten</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), we prewhiten each
transformed component series of <code class="reqn">\hat{\bf z}_t</code> [See Section 2.2.1 in
Chang, Guo and Yao (2018)] by fitting a univariate AR model with the order
between 0 and 5 determined by AIC. If <code>FALSE</code>, then prewhiten
procedure will not be performed to <code class="reqn">\hat{\bf z}_t</code>.</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_permutation">permutation</code></td>
<td>
<p>The method of permutation procedure to assign the
components of <code class="reqn">\hat{\bf z}_t</code> to different groups [See Section 2.2.1 in
Chang, Guo and Yao (2018)]. Option is <code>'max'</code> (Maximum cross
correlation method) or <code>'fdr'</code> (False discovery rate procedure based
on multiple tests), default is <code>permutation = 'max'</code>. See Sections
2.2.2 and 2.2.3 in Chang, Guo and Yao (2018) for more information.</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_m">m</code></td>
<td>
<p>A positive constant used in the permutation procedure [See (2.10) in
Chang, Guo and Yao (2018)]. If <code class="reqn">m</code> is not specified, then default
option is <code>m = </code>10.</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_beta">beta</code></td>
<td>
<p>The error rate used in the permutation procedure when
<code>permutation = 'fdr'</code>.</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_just4pre">just4pre</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the procedure outputs <code class="reqn">\hat{\bf
z}_t</code>, otherwise outputs <code class="reqn">\hat{\bf x}_t</code> (the permutated version of
<code class="reqn">\hat{\bf z}_t</code>).</p>
</td></tr>
<tr><td><code id="PCA4_TS_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the main results of the permutation 
procedure will be output on the console. Otherwise, the result will not be 
output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code class="reqn">p&gt;n^{1/2}</code>, the procedure use package <span class="pkg">clime</span> to
estimate the precision matrix <code class="reqn">\widehat{{\bf V}}^{-1}</code>, otherwise uses
function <code>cov()</code> to estimate <code class="reqn">\widehat{{\bf V}}</code> and calculate its
inverse. When <code class="reqn">p&gt;n^{1/2}</code>, we recommend to use the thresholding method
to calculate <code class="reqn">\widehat{{\bf W}}_y</code>, see more information in Chang, Guo
and Yao (2018).
</p>


<h3>Value</h3>

<p>The output of the segment procedure is a list containing the
following components: </p>
<table>
<tr><td><code>B</code></td>
<td>
<p>The <code class="reqn">p\times p</code> transformation matrix
such that <code class="reqn">\hat{\bf z}_t = \widehat{\bf B}{\bf y}_t</code>, where
<code class="reqn">\widehat{\bf B}=\widehat{\bf \Gamma}_y\widehat{{\bf V}}^{-1/2}</code>.</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p><code class="reqn">\hat{\bf Z}=\{\hat{\bf z}_1,\dots,\hat{\bf z}_n\}'</code>, the
transformed series with <code class="reqn">n</code> rows and <code class="reqn">p</code> columns.</p>
</td></tr>
</table>
<p>The output of the permutation procedure is a list containing the
following components: 
</p>
<table>
<tr><td><code>NoGroups</code></td>
<td>
<p>number of groups with at least two components series.</p>
</td></tr>
<tr><td><code>No_of_Members</code></td>
<td>
<p>The cardinalities of different groups.</p>
</td></tr>
<tr><td><code>Groups</code></td>
<td>
<p>The indices of the components in <code class="reqn">\hat{\bf z}_t</code> that
belongs to a group.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chang, J., Guo, B. &amp; Yao, Q. (2018). <em>Principal component
analysis for second-order stationary vector time series</em>, The Annals of
Statistics, Vol. 46, pp. 2094&ndash;2124.
</p>
<p>Cai, T. &amp; Liu, W. (2011). <em>Adaptive thresholding for sparse covariance
matrix estimation</em>,  Journal of the American Statistical Association, Vol.
106, pp. 672&ndash;684.
</p>
<p>Cai, T., Liu, W., &amp; Luo, X. (2011). <em>A constrained l1 minimization
approach for sparse precision matrix estimation</em>, Journal of the American
Statistical Association, Vol. 106, pp. 594&ndash;607.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1 (Example 5 of Chang Guo and Yao (2018)).
## p=6, x_t consists of 3 independent subseries with 3, 2 and 1 components.

p &lt;- 6;n &lt;- 1500
# Generate x_t
X &lt;- mat.or.vec(p,n)
x &lt;- arima.sim(model=list(ar=c(0.5, 0.3), ma=c(-0.9, 0.3, 1.2,1.3)),
n=n+2,sd=1)
for(i in 1:3) X[i,] &lt;- x[i:(n+i-1)]
x &lt;- arima.sim(model=list(ar=c(0.8,-0.5),ma=c(1,0.8,1.8) ),n=n+1,sd=1)
for(i in 4:5) X[i,] &lt;- x[(i-3):(n+i-4)]
x &lt;- arima.sim(model=list(ar=c(-0.7, -0.5), ma=c(-1, -0.8)),n=n,sd=1)
X[6,] &lt;- x
# Generate y_t
A &lt;- matrix(runif(p*p, -3, 3), ncol=p)
Y &lt;- A%*%X
Y &lt;- t(Y)
res &lt;- PCA4_TS(Y, lag.k=5,permutation = "max")
res1=PCA4_TS(Y, lag.k=5,permutation = "fdr", beta=10^(-10))
# The transformed series z_t
Z &lt;- res$Z
# Plot the cross correlogram of z_t and y_t
Y &lt;- data.frame(Y);Z=data.frame(Z)
names(Y) &lt;- c("Y1","Y2","Y3","Y4","Y5","Y6")
names(Z) &lt;- c("Z1","Z2","Z3","Z4","Z5","Z6")
# The cross correlogram of y_t shows no block pattern
acfY &lt;- acf(Y)
# The cross correlogram of z_t shows 3-2-1 block pattern
acfZ &lt;- acf(Z)

## Example 2 (Example 6 of Chang Guo and Yao (2018)).
## p=20, x_t consists of 5 independent subseries with 6, 5, 4, 3 and 2 components.
p &lt;- 20;n &lt;- 3000
# Generate x_t
X &lt;- mat.or.vec(p,n)
x &lt;- arima.sim(model=list(ar=c(0.5, 0.3), ma=c(-0.9, 0.3, 1.2,1.3)),n.start=500,
n=n+5,sd=1)
for(i in 1:6) X[i,] &lt;- x[i:(n+i-1)]
x &lt;- arima.sim(model=list(ar=c(-0.4,0.5),ma=c(1,0.8,1.5,1.8)),n.start=500,n=n+4,sd=1)
for(i in 7:11) X[i,] &lt;- x[(i-6):(n+i-7)]
x &lt;- arima.sim(model=list(ar=c(0.85,-0.3),ma=c(1,0.5,1.2)), n.start=500,n=n+3,sd=1)
for(i in 12:15) X[i,] &lt;- x[(i-11):(n+i-12)]
x &lt;- arima.sim(model=list(ar=c(0.8,-0.5),ma=c(1,0.8,1.8)),n.start=500,n=n+2,sd=1)
for(i in 16:18) X[i,] &lt;- x[(i-15):(n+i-16)]
x &lt;- arima.sim(model=list(ar=c(-0.7, -0.5), ma=c(-1, -0.8)),n.start=500,n=n+1,sd=1)
for(i in 19:20) X[i,] &lt;- x[(i-18):(n+i-19)]
# Generate y_t
A &lt;- matrix(runif(p*p, -3, 3), ncol=p)
Y &lt;- A%*%X
Y &lt;- t(Y)
res &lt;- PCA4_TS(Y, lag.k=5,permutation = "max")
res1 &lt;- PCA4_TS(Y, lag.k=5,permutation = "fdr",beta=10^(-200))
# The transformed series z_t
Z &lt;- res$Z
# Plot the cross correlogram of x_t and y_t
Y &lt;- data.frame(Y);Z &lt;- data.frame(Z)
namesY=NULL;namesZ=NULL
for(i in 1:p)
{
   namesY &lt;- c(namesY,paste0("Y",i))
   namesZ &lt;- c(namesZ,paste0("Z",i))
}
names(Y) &lt;- namesY;names(Z) &lt;- namesZ
# The cross correlogram of y_t shows no block pattern
acfY &lt;- acf(Y, plot=FALSE)
plot(acfY, max.mfrow=6, xlab='', ylab='',  mar=c(1.8,1.3,1.6,0.5),
     oma=c(1,1.2,1.2,1), mgp=c(0.8,0.4,0),cex.main=1)
# The cross correlogram of z_t shows 6-5-4-3-2 block pattern
acfZ &lt;- acf(Z, plot=FALSE)
plot(acfZ, max.mfrow=6, xlab='', ylab='',  mar=c(1.8,1.3,1.6,0.5),
     oma=c(1,1.2,1.2,1), mgp=c(0.8,0.4,0),cex.main=1)
# Identify the permutation mechanism
permutation &lt;- res
permutation$Groups  
</code></pre>

<hr>
<h2 id='ur.test'>Testing for unit roots based on sample autocovariances</h2><span id='topic+ur.test'></span>

<h3>Description</h3>

<p>The test proposed in Chang, Cheng and Yao (2021) for the following hypothesis
testing problems: </p>
<p style="text-align: center;"><code class="reqn">H_0:Y_t \sim I(0)\ \ \mathrm{versus}\ \ H_1:Y_t \sim
I(d)\ \mathrm{for\ some\ integer\ }d \geq 2.</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>ur.test(Y, lagk.vec = lagk.vec, con_vec = con_vec, alpha = alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ur.test_+3A_y">Y</code></td>
<td>
<p><code class="reqn">Y = \{y_1, \dots , y_n \}</code>, the observations of a univariate
time series used for the test.</p>
</td></tr>
<tr><td><code id="ur.test_+3A_lagk.vec">lagk.vec</code></td>
<td>
<p>Time lag <code class="reqn">K_0</code> used to calculate the test statistic, see
Section 2.1 in Chang, Cheng and Yao (2021). It can be a vector containing
more than one time lag. If it is a vector, the procedure will output all
the test results based on the different <code class="reqn">K_0</code> in the vector
<code>lagk.vec</code>. If <code>lagk.vec</code> is missing, the default value we choose
lagk.vec=c(0,1,2,3,4).</p>
</td></tr>
<tr><td><code id="ur.test_+3A_con_vec">con_vec</code></td>
<td>
<p>Constant <code class="reqn">c_\kappa</code>, see (5) in Chang, Cheng and Yao
(2021). It also can be a vector. If missing, the default value we use 0.55.</p>
</td></tr>
<tr><td><code id="ur.test_+3A_alpha">alpha</code></td>
<td>
<p>The prescribed significance level. Default is 0.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe containing the following components:
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p><code>'1'</code> means we reject the null hypothesis and <code>'0'</code>
means we do not reject the null hypothesis.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chang, J., Cheng, G. &amp; Yao, Q. (2021).  <em>Testing for unit
roots based on sample autocovariances</em>. Available at
<a href="https://arxiv.org/abs/2006.07551">https://arxiv.org/abs/2006.07551</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N=100
Y=arima.sim(list(ar=c(0.9)), n = 2*N, sd=sqrt(1))
con_vec=c(0.45,0.55,0.65)
lagk.vec=c(0,1,2)
ur.test(Y,lagk.vec=lagk.vec, con_vec=con_vec,alpha=0.05)
ur.test(Y,alpha=0.05)
</code></pre>

<hr>
<h2 id='WN_test'>Testing for white noise hypothesis in high dimension</h2><span id='topic+WN_test'></span>

<h3>Description</h3>

<p><code>WN_test()</code> is the test proposed in Chang, Yao and Zhou
(2017) for the following hypothesis testing problems: </p>
<p style="text-align: center;"><code class="reqn">H_0:\{{\bf x}_t
\}_{t=1}^n\mathrm{\ is\ white\ noise\ \ versus\ \ }H_1:\{{\bf x}_t
\}_{t=1}^n\mathrm{\ is\ not\ white\ noise.} </code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>WN_test(
  X,
  lag.k = 2,
  B = 2000,
  kernel.type = c("QS", "Par", "Bart"),
  pre = FALSE,
  alpha = 0.05,
  k0 = 5,
  thresh = FALSE,
  tuning.vec = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WN_test_+3A_x">X</code></td>
<td>
<p><code class="reqn">{\bf X} = \{{\bf x}_1, \dots , {\bf x}_n \}'</code>, an <code class="reqn">n\times
p</code> sample matrix, where <code class="reqn">n</code> is the sample size and <code class="reqn">p</code> is the
dimension of <code class="reqn">{\bf x}_t</code>.</p>
</td></tr>
<tr><td><code id="WN_test_+3A_lag.k">lag.k</code></td>
<td>
<p>Time lag <code class="reqn">K</code>, a positive integer, used to calculate the test
statistic [See (4) in Chang, Yao and Zhou (2017)]. Default is <code>lag.k</code>
<code class="reqn">=2</code>.</p>
</td></tr>
<tr><td><code id="WN_test_+3A_b">B</code></td>
<td>
<p>Bootstrap times for generating multivariate normal distributed
random vectors in calculating the critical value. Default is <code>B</code>
<code class="reqn">=2000</code>.</p>
</td></tr>
<tr><td><code id="WN_test_+3A_kernel.type">kernel.type</code></td>
<td>
<p>String, an option for choosing the symmetric kernel used
in the estimation of long-run covariance matrix, for example, <code>'QS'</code>
(Quadratic spectral kernel), <code>'Par'</code> (Parzen kernel) and <code>'Bart'</code>
(Bartlett kernel), see Andrews (1991) for more information. Default option
is<code>kernel.type = 'QS'</code>.</p>
</td></tr>
<tr><td><code id="WN_test_+3A_pre">pre</code></td>
<td>
<p>Logical value which determines whether to performs preprocessing
procedure on data matrix <code>X</code> or not, see Remark 1 in Chang, Yao and
Zhou (2017) for more information. If <code>TRUE</code>, then the segment
procedure will be performed to data <code>X</code> first. The three additional
options including <code>thresh</code>, <code>tuning.vec</code> and <code>cv.num</code> are
the same as those in <code><a href="#topic+PCA4_TS">PCA4_TS</a></code>.</p>
</td></tr>
<tr><td><code id="WN_test_+3A_alpha">alpha</code></td>
<td>
<p>The prescribed significance level. Default is 0.05.</p>
</td></tr>
<tr><td><code id="WN_test_+3A_k0">k0</code></td>
<td>
<p>A positive integer specified to calculate <code class="reqn">\widehat{{\bf
W}}_y</code>. See parameter <code>lag.k</code> in <code><a href="#topic+PCA4_TS">PCA4_TS</a></code> for more
information.</p>
</td></tr>
<tr><td><code id="WN_test_+3A_thresh">thresh</code></td>
<td>
<p>Logical. It determines whether to perform the threshold method
to estimate <code class="reqn">\widehat{{\bf W}}_y</code> or not. See parameter <code>thresh</code>
in <code><a href="#topic+PCA4_TS">PCA4_TS</a></code> for more information.</p>
</td></tr>
<tr><td><code id="WN_test_+3A_tuning.vec">tuning.vec</code></td>
<td>
<p>The value of thresholding tuning parameter <code class="reqn">\lambda</code>.
See parameter <code>tuning.vec</code> in <code><a href="#topic+PCA4_TS">PCA4_TS</a></code> for more
information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;WN_test&quot; is a list containing the following
components:
</p>
<table>
<tr><td><code>reject</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, it means rejecting the null
hypothesis, otherwise it means not rejecting the null hypothesis.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Numerical value which represents the p-value of the test
based on the observed data <code class="reqn">\{{\bf x}_t\}_{t=1}^n</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chang, J., Yao, Q. &amp; Zhou, W. (2017). <em>Testing for
high-dimensional white noise using maximum cross-correlations</em>, Biometrika,
Vol. 104, pp. 111–127.
</p>
<p>Chang, J., Guo, B. &amp; Yao, Q. (2018). <em>Principal component analysis for
second-order stationary vector time series</em>, The Annals of Statistics, Vol.
46, pp. 2094–2124.
</p>
<p>Cai, T. and Liu, W. (2011). <em>Adaptive thresholding for sparse
covariance matrix estimation</em>,  Journal of the American Statistical
Association, Vol. 106, pp. 672&ndash;684.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PCA4_TS">PCA4_TS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200
p &lt;- 10
X &lt;- matrix(rnorm(n*p),n,p)
res &lt;- WN_test(X)
Pvalue &lt;- res$p.value
rej &lt;- res$reject
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
