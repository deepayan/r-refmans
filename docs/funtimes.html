<!DOCTYPE html><html><head><title>Help for package funtimes</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {funtimes}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ARest'><p>Estimation of Autoregressive (AR) Parameters</p></a></li>
<li><a href='#AuePolyReg_test'><p>Testing for Change Points in Time Series via Polynomial Regression</p></a></li>
<li><a href='#beales'><p>Beale's Estimator and Sample Size</p></a></li>
<li><a href='#BICC'><p>BIC-Based Spatio-Temporal Clustering</p></a></li>
<li><a href='#causality_pred'><p>Out-of-sample Tests of Granger Causality</p></a></li>
<li><a href='#causality_predVAR'><p>Out-of-sample Tests of Granger Causality using (Restricted) Vector Autoregression</p></a></li>
<li><a href='#ccf_boot'><p>Cross-Correlation of Autocorrelated Time Series</p></a></li>
<li><a href='#CSlideCluster'><p>Slide-Level Time Series Clustering</p></a></li>
<li><a href='#cumsumCPA_test'><p>Change Point Detection in Time Series via a Linear Regression with Temporally Correlated</p>
Errors</a></li>
<li><a href='#CWindowCluster'><p>Window-Level Time Series Clustering</p></a></li>
<li><a href='#DR'><p>Downhill Riding (DR) Procedure</p></a></li>
<li><a href='#funtimes-defunct'><p>Defunct functions in package <span class="pkg">funtimes</span>.</p></a></li>
<li><a href='#funtimes-deprecated'><p>Deprecated functions in package <span class="pkg">funtimes</span>.</p></a></li>
<li><a href='#funtimes-package'><p>funtimes: Functions for Time Series Analysis</p></a></li>
<li><a href='#GombayCPA_test'><p>Change Point Detection in Autoregressive Time Series</p></a></li>
<li><a href='#HVK'><p>HVK Estimator</p></a></li>
<li><a href='#i.tails-defunct'><p>Interval-Based Tails Comparison</p></a></li>
<li><a href='#mcusum_test'><p>Change Point Test for Regression</p></a></li>
<li><a href='#mcusum.test-defunct'><p>Change Point Test for Regression</p></a></li>
<li><a href='#notrend_test'><p>Sieve Bootstrap Based Test for the Null Hypothesis of no Trend</p></a></li>
<li><a href='#notrend.test-defunct'><p>Sieve Bootstrap Based Test for the Null Hypothesis of no Trend</p></a></li>
<li><a href='#purity'><p>Clustering Purity</p></a></li>
<li><a href='#q.tails-defunct'><p>Quantile-Based Tails Comparison</p></a></li>
<li><a href='#sync_cluster'><p>Time Series Clustering based on Trend Synchronism</p></a></li>
<li><a href='#sync_test'><p>Time Series Trend Synchronicity Test</p></a></li>
<li><a href='#sync.cluster-defunct'><p>Time Series Clustering based on Trend Synchronism</p></a></li>
<li><a href='#sync.test-defunct'><p>Time Series Trend Synchronism Test</p></a></li>
<li><a href='#tails_i'><p>Interval-Based Tails Comparison</p></a></li>
<li><a href='#tails_q'><p>Quantile-Based Tails Comparison</p></a></li>
<li><a href='#WAVK'><p>WAVK Statistic</p></a></li>
<li><a href='#wavk_test'><p>WAVK Trend Test</p></a></li>
<li><a href='#wavk.test-defunct'><p>WAVK Trend Test</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functions for Time Series Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>9.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-21</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>dbscan, Kendall, lmtest, mlVAR, parallel, Rdpack, sandwich,
vars</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covid19us, Ecdat, ggplot2, gridExtra, knitr, patchwork,
randomcoloR, readxl, reshape2, rmarkdown</td>
</tr>
<tr>
<td>Description:</td>
<td>Nonparametric estimators and tests for time series analysis. The functions use bootstrap techniques and robust nonparametric difference-based estimators to test for the presence of possibly non-monotonic trends and for synchronicity of trends in multiple time series.</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-21 22:53:01 UTC; Slava</td>
</tr>
<tr>
<td>Author:</td>
<td>Vyacheslav Lyubchich
    <a href="https://orcid.org/0000-0001-7936-4285"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Yulia R. Gel [aut],
  Alexander Brenning [ctb],
  Calvin Chu [ctb],
  Xin Huang [ctb],
  Umar Islambekov [ctb],
  Palina Niamkova [ctb],
  Dorcas Ofori-Boateng [ctb],
  Ethan D. Schaeffer [ctb],
  Srishti Vishwakarma [aut],
  Xingyu Wang [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Vyacheslav Lyubchich &lt;lyubchich@umces.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-21 23:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ARest'>Estimation of Autoregressive (AR) Parameters</h2><span id='topic+ARest'></span>

<h3>Description</h3>

<p>Estimate parameters <code class="reqn">\phi</code> of autoregressive time series model
</p>
<p style="text-align: center;"><code class="reqn">X_t = \sum_{i=1}^p\phi_iX_{t-i} + e_t,</code>
</p>

<p>by default using robust difference-based estimator and Bayesian information
criterion (BIC) to select the order <code class="reqn">p</code>. This function is employed
for time series filtering in the functions <code><a href="#topic+notrend_test">notrend_test</a></code>, <code><a href="#topic+sync_test">sync_test</a></code>,
and <code><a href="#topic+wavk_test">wavk_test</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ARest(x, ar.order = NULL, ar.method = "HVK", ic = c("BIC", "AIC", "none"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ARest_+3A_x">x</code></td>
<td>
<p>a vector containing a univariate time series. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="ARest_+3A_ar.order">ar.order</code></td>
<td>
<p>order of the autoregressive model when <code>ic = "none"</code>, or
the maximal order for IC-based filtering. Default is
<code>round(10*log10(length(x)))</code>, where <code>x</code> is the time series.</p>
</td></tr>
<tr><td><code id="ARest_+3A_ar.method">ar.method</code></td>
<td>
<p>method of estimating autoregression coefficients.
Default <code>"HVK"</code> delivers robust difference-based estimates by
Hall and Van Keilegom (2003). Alternatively,
options of <code>ar</code> function can be used, such as <code>"burg"</code>,
<code>"ols"</code>, <code>"mle"</code>, and <code>"yw"</code>.</p>
</td></tr>
<tr><td><code id="ARest_+3A_ic">ic</code></td>
<td>
<p>information criterion used to select the order of autoregressive filter (AIC of BIC),
considering models of orders <code class="reqn">p=</code> 0,1,...,<code>ar.order</code>.
If <code>ic = "none"</code>, the AR(<code class="reqn">p</code>) model with <code class="reqn">p=</code> <code>ar.order</code> is used,
without order selection.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula for information criteria used consistently for all methods:
</p>
<p style="text-align: center;"><code class="reqn">IC=n\ln(\hat{\sigma}^2) + (p + 1)k,</code>
</p>

<p>where <code class="reqn">n</code> = <code>length(x)</code>,
<code class="reqn">p</code> is the autoregressive order (<code class="reqn">p + 1</code> is the number of model parameters),
and <code class="reqn">k</code> is the penalty (<code class="reqn">k = \ln(n)</code> in BIC, and <code class="reqn">k = 2</code> in AIC).
</p>


<h3>Value</h3>

<p>A vector of estimated AR coefficients. Returns <code>numeric(0)</code> if
the final <code class="reqn">p=0</code>.
</p>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Hall P, Van Keilegom I (2003).
&ldquo;Using difference-based methods for inference in nonparametric regression with time series errors.&rdquo;
<em>Journal of the Royal Statistical Society, Series B (Statistical Methodology)</em>, <b>65</b>(2), 443&ndash;456.
<a href="https://doi.org/10.1111/1467-9868.00395">doi:10.1111/1467-9868.00395</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ar">ar</a></code>, <code><a href="#topic+HVK">HVK</a></code>,
<code><a href="#topic+notrend_test">notrend_test</a></code>, <code><a href="#topic+sync_test">sync_test</a></code>, <code><a href="#topic+wavk_test">wavk_test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate a time series Y:
Y &lt;- arima.sim(n = 200, list(order = c(2, 0, 0), ar = c(-0.7, -0.1)))
plot.ts(Y)

# Estimate the coefficients:
ARest(Y) # HVK, by default
ARest(Y, ar.method = "yw") # Yule--Walker
ARest(Y, ar.method = "burg") # Burg

</code></pre>

<hr>
<h2 id='AuePolyReg_test'>Testing for Change Points in Time Series via Polynomial Regression</h2><span id='topic+AuePolyReg_test'></span>

<h3>Description</h3>

<p>The function uses a nonlinear polynomial regression model in which it tests for the null
hypothesis of structural stability in the regression parameters against the alternative of
a break at an unknown time. The method is based on the extreme value distribution of a
maximum-type test statistic which is asymptotically equivalent to the maximally selected
likelihood ratio. The resulting testing approach is easily tractable and delivers accurate
size and power of the test, even in small samples (Aue et al. 2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AuePolyReg_test(
  y,
  a.order,
  alpha = 0.05,
  crit.type = c("asymptotic", "bootstrap"),
  bootstrap.method = c("nonparametric", "parametric"),
  num.bootstrap = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AuePolyReg_test_+3A_y">y</code></td>
<td>
<p>a vector that contains univariate time series observations. Missing values are
not allowed.</p>
</td></tr>
<tr><td><code id="AuePolyReg_test_+3A_a.order">a.order</code></td>
<td>
<p>order of the autoregressive model which must be a non-negative integer number.</p>
</td></tr>
<tr><td><code id="AuePolyReg_test_+3A_alpha">alpha</code></td>
<td>
<p>significance level for testing hypothesis of no change point. Default value
is 0.05.</p>
</td></tr>
<tr><td><code id="AuePolyReg_test_+3A_crit.type">crit.type</code></td>
<td>
<p>method of obtaining critical values: &quot;asymptotic&quot; (default) or &quot;bootstrap&quot;.</p>
</td></tr>
<tr><td><code id="AuePolyReg_test_+3A_bootstrap.method">bootstrap.method</code></td>
<td>
<p>type of bootstrap if <code>crit.type = "bootstrap"</code>: &quot;nonparametric&quot;
(default) or &quot;parametric&quot;.</p>
</td></tr>
<tr><td><code id="AuePolyReg_test_+3A_num.bootstrap">num.bootstrap</code></td>
<td>
<p>number of bootstrap replications if <code>crit.type = "bootstrap"</code>.
Default number is 1000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>index</code></td>
<td>
<p>time point where the change point has occurred.</p>
</td></tr>
<tr><td><code>stat</code></td>
<td>
<p>test statistic.</p>
</td></tr>
<tr><td><code>crit.val</code></td>
<td>
<p>critical region value (CV(alpha, n)).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p><code>p-value</code> of the change point test.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Palina Niamkova, Dorcas Ofori-Boateng, Yulia R. Gel
</p>


<h3>References</h3>

<p>Aue A, Horvath L, Huskova M, Kokoszka P (2008).
&ldquo;Testing for changes in polynomial regression.&rdquo;
<em>Bernoulli</em>, <b>14</b>(3), 637&ndash;660.
<a href="https://doi.org/10.3150/08-BEJ122">doi:10.3150/08-BEJ122</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcusum.test">mcusum.test</a></code> change point test for regression
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Example 1:

#Simulate some time series:
set.seed(23450)
series_1 = rnorm(137, 3, 5)
series_2 = rnorm(213, 0, 1)
series_val = c(series_1, series_2)
AuePolyReg_test(series_1, 1) # no change (asymptotic)
AuePolyReg_test(series_val,1) # one change (asymptotic)

#Example 2:

#Consider a time series with annual number of world terrorism incidents from 1970 till 2016:
c.data = Ecdat::terrorism["incidents"]
incidents.ts &lt;- ts(c.data, start = 1970, end = 2016)

#Run a test for change points:
AuePolyReg_test(incidents.ts, 2) # one change (asymptotic)
AuePolyReg_test(incidents.ts, 2, 0.05,"bootstrap", "parametric", 200) 
# one change (bootstrap)
incidents.ts[44] #number of victims at the value of change point
year &lt;- 197 + 44 - 1  # year when the change point occurred
plot(incidents.ts) # see the visualized data

#The structural change point occurred at the 44th value which corresponds to 2013, 
#with 11,990 identified incidents in that year. These findings can be explained with 
#a recent rise of nationalism and  extremism due to appearance of the social media, 
#Fisher (2019): White Terrorism Shows 'Stunning' Parallels to Islamic State's Rise. 
#The New York Times.

## End(Not run)

</code></pre>

<hr>
<h2 id='beales'>Beale's Estimator and Sample Size</h2><span id='topic+beales'></span>

<h3>Description</h3>

<p>Beale's ratio estimator (Beale 1962)
for estimating population total and
confidence intervals, with an option of calculating sample size for a required
relative error (<code>p</code>) or margin of error (<code>d</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beales(x, y, level = 0.95, N = NULL, p = NULL, d = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beales_+3A_x">x</code></td>
<td>
<p>a numeric vector with quantities of interest, such as river discharge
per month. Missing values (<code>NA</code>) are allowed.</p>
</td></tr>
<tr><td><code id="beales_+3A_y">y</code></td>
<td>
<p>a numeric vector with quantities of interest for which the total shall
be estimated, such as total nutrient loads per month.
Missing values (<code>NA</code>) are allowed.
Lengths of <code>x</code> and <code>y</code> mush be the same.</p>
</td></tr>
<tr><td><code id="beales_+3A_level">level</code></td>
<td>
<p>confidence level, from 0 to 1.
Default is <code>0.95</code>, that is, 95% confidence.</p>
</td></tr>
<tr><td><code id="beales_+3A_n">N</code></td>
<td>
<p>population size for which the estimate of the total <code>y</code> is required.
By default, <code>length(x)</code> is used.</p>
</td></tr>
<tr><td><code id="beales_+3A_p">p</code></td>
<td>
<p>optional argument specifying the required relative error, from 0 to 1,
for computing the corresponding sample size. For example, <code>p = 0.15</code> defines
a 15% relative error.</p>
</td></tr>
<tr><td><code id="beales_+3A_d">d</code></td>
<td>
<p>optional argument specifying the required margin of error
for computing the corresponding sample size. If both <code>p</code> and <code>d</code> are specified,
only <code>p</code> is used.</p>
</td></tr>
<tr><td><code id="beales_+3A_verbose">verbose</code></td>
<td>
<p>logical value defining whether the output should be printed out
in words. Default is set to <code>TRUE</code> to give such output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>Beale's estimate of the population total for the variable <code>y</code>.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>standard error of the estimate.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>a vector of length 2 with a confidence interval (lower and upper value)
for the estimate.</p>
</td></tr>
<tr><td><code>level</code></td>
<td>
<p>confidence level for the interval.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>population size.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the actual sample size.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the relative error used for sample size calculations.
Reported only if <code>p</code> was specified in the input.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>the margin of error used for sample size calculations.
Reported only if <code>d</code> was specified and <code>p</code> was not specified in the input.</p>
</td></tr>
<tr><td><code>nhat</code></td>
<td>
<p>estimated sample size for the given <code>level</code> and error
(<code>p</code> or <code>d</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich, thanks to Dave Lorenz for pointing out an error in version 7 and below of the package
</p>


<h3>References</h3>

<p>Beale EML (1962).
&ldquo;Some uses of computers in operational research.&rdquo;
<em>Industrielle Organisation</em>, <b>31</b>(1), 27&ndash;28.
</p>


<h3>See Also</h3>

<p><code>vignette("beales", package = "funtimes")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Some hypothetical data for monthly river discharge 
#and corresponding nutrient loads:
discharge &lt;- c(NA, 50, 90, 100, 80, 90, 100, 90, 80, 70, NA, NA)
loads &lt;- c(33, 22, 44, 48, NA, 44, 49, NA, NA, 36, NA, NA)

#Example 1:
#Estimate total annual load (12 months), 
#with 90% confidence intervals
beales(discharge, loads, level = 0.9)

#Example 2:
#Calculate sample size required for 90% confidence intervals 
#with a margin of error 30 units
beales(discharge, loads, level = 0.9, d = 30)

</code></pre>

<hr>
<h2 id='BICC'>BIC-Based Spatio-Temporal Clustering</h2><span id='topic+BICC'></span>

<h3>Description</h3>

<p>Apply the algorithm of unsupervised spatio-temporal clustering, TRUST
(Ciampi et al. 2010), with automatic selection of its
tuning parameters <code>Delta</code> and <code>Epsilon</code> based on Bayesian
information criterion, BIC (Schaeffer et al. 2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BICC(X, Alpha = NULL, Beta = NULL, Theta = 0.8, p, w, s)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BICC_+3A_x">X</code></td>
<td>
<p>a matrix of time series observed within a slide (time series in columns).</p>
</td></tr>
<tr><td><code id="BICC_+3A_alpha">Alpha</code></td>
<td>
<p>lower limit of the time-series domain,
passed to <code><a href="#topic+CSlideCluster">CSlideCluster</a></code>.</p>
</td></tr>
<tr><td><code id="BICC_+3A_beta">Beta</code></td>
<td>
<p>upper limit of the time-series domain passed to <code><a href="#topic+CSlideCluster">CSlideCluster</a></code>.</p>
</td></tr>
<tr><td><code id="BICC_+3A_theta">Theta</code></td>
<td>
<p>connectivity parameter passed to <code><a href="#topic+CSlideCluster">CSlideCluster</a></code>.</p>
</td></tr>
<tr><td><code id="BICC_+3A_p">p</code></td>
<td>
<p>number of layers (time-series observations) in each slide.</p>
</td></tr>
<tr><td><code id="BICC_+3A_w">w</code></td>
<td>
<p>number of slides in each window.</p>
</td></tr>
<tr><td><code id="BICC_+3A_s">s</code></td>
<td>
<p>step to shift a window, calculated in the number of slides. The recommended
values are 1 (overlapping windows) or equal to <code>w</code> (non-overlapping windows).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the upper-level function for time series clustering.
It exploits the functions <code><a href="#topic+CWindowCluster">CWindowCluster</a></code> and
<code><a href="#topic+CSlideCluster">CSlideCluster</a></code> to cluster time series based on closeness and
homogeneity measures. Clustering is performed multiple times with a range
of equidistant values for the parameters <code>Delta</code> and <code>Epsilon</code>,
then optimal parameters <code>Delta</code> and <code>Epsilon</code> along with the
corresponding clustering results are shown
(see Schaeffer et al. 2016, for more details).
</p>
<p>The total length of time series (number of levels, i.e., <code>nrow(X)</code>)
should be divisible by <code>p</code>.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>delta.opt</code></td>
<td>
<p>optimal value for the clustering parameter <code>Delta</code>.</p>
</td></tr>
<tr><td><code>epsilon.opt</code></td>
<td>
<p>optimal value for the clustering parameter <code>Epsilon</code>.</p>
</td></tr>
<tr><td><code>clusters</code></td>
<td>
<p>vector of length <code>ncol(X)</code> with cluster labels.</p>
</td></tr>
<tr><td><code>IC</code></td>
<td>
<p>values of the information criterion (BIC) for each considered
combination of <code>Delta</code> (rows) and <code>Epsilon</code> (columns).</p>
</td></tr>
<tr><td><code>delta.all</code></td>
<td>
<p>vector of considered values for <code>Delta</code>.</p>
</td></tr>
<tr><td><code>epsilon.all</code></td>
<td>
<p>vector of considered values for <code>Epsilon</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ethan Schaeffer, Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Ciampi A, Appice A, Malerba D (2010).
&ldquo;Discovering trend-based clusters in spatially distributed data streams.&rdquo;
In <em>International Workshop of Mining Ubiquitous and Social Environments</em>, 107&ndash;122.<br /><br /> Schaeffer ED, Testa JM, Gel YR, Lyubchich V (2016).
&ldquo;On information criteria for dynamic spatio-temporal clustering.&rdquo;
In Banerjee A, Ding W, Dy JG, Lyubchich V, Rhines A (eds.), <em>The 6th International Workshop on Climate Informatics: CI2016</em>, 5&ndash;8.
<a href="https://doi.org/10.5065/D6K072N6">doi:10.5065/D6K072N6</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CSlideCluster">CSlideCluster</a></code>, <code><a href="#topic+CWindowCluster">CWindowCluster</a></code>, <code><a href="#topic+purity">purity</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fix seed for reproducible simulations:
set.seed(1)

##### Example 1
# Similar to Schaeffer et al. (2016), simulate 3 years of monthly data 
#for 10 locations and apply clustering:
# 1.1 Simulation
T &lt;- 36 #total months
N &lt;- 10 #locations
phi &lt;- c(0.5) #parameter of autoregression
burn &lt;- 300 #burn-in period for simulations
X &lt;- sapply(1:N, function(x) 
    arima.sim(n = T + burn, 
              list(order = c(length(phi), 0, 0), ar = phi)))[(burn + 1):(T + burn),]
colnames(X) &lt;- paste("TS", c(1:dim(X)[2]), sep = "")

# 1.2 Clustering
# Assume that information arrives in year-long slides or data chunks
p &lt;- 12 #number of time layers (months) in a slide
# Let the upper level of clustering (window) be the whole period of 3 years, so
w &lt;- 3 #number of slides in a window
s &lt;- w #step to shift a window, but it does not matter much here as we have only one window of data
tmp &lt;- BICC(X, p = p, w = w, s = s)

# 1.3 Evaluate clustering
# In these simulations, it is known that all time series belong to one class,
#since they were all simulated the same way:
classes &lt;- rep(1, 10)
# Use the information on the classes to calculate clustering purity:
purity(classes, tmp$clusters[1,])

##### Example 2
# 2.1 Modify time series and update classes accordingly:
# Add a mean shift to a half of the time series:
X2 &lt;- X
X2[, 1:(N/2)] &lt;- X2[, 1:(N/2)] + 3
classes2 &lt;- rep(c(1, 2), each = N/2)

# 2.2 Re-apply clustering procedure and evaluate clustering purity:
tmp2 &lt;- BICC(X2, p = p, w = w, s = s)
tmp2$clusters
purity(classes2, tmp2$clusters[1,])

</code></pre>

<hr>
<h2 id='causality_pred'>Out-of-sample Tests of Granger Causality</h2><span id='topic+causality_pred'></span>

<h3>Description</h3>

<p>Test for Granger causality using out-of-sample prediction errors from an
autoregression (AR) model, where some of the near-contemporaneous lags can be removed:
</p>
<p style="text-align: center;"><code class="reqn">Y_t = \sum_{i=1}^{p1}\alpha_iY_{t-i} + \sum_{i=lag.restrict+1}^{p2}\beta_iX_{t-i} + e_t,</code>
</p>

<p>where <code class="reqn">Y_t</code> is the dependent variable,
<code class="reqn">X_t</code> is the cause variable,
<code class="reqn">p1</code> and <code class="reqn">p2</code> are the AR orders (if <code>p.free = FALSE</code>, <code class="reqn">p1 = p2</code>),
<code class="reqn">lag.restrict</code> is the number of restricted first lags (see the argument <code>lag.restrict</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causality_pred(
  y,
  cause = NULL,
  p = NULL,
  p.free = FALSE,
  lag.restrict = 0L,
  lag.max = NULL,
  k = 2,
  B = 500L,
  test = 0.3,
  cl = 1L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causality_pred_+3A_y">y</code></td>
<td>
<p>matrix, data frame, or <code>ts</code> object with two columns
(a dependent and an explanatory time-series variable). Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_cause">cause</code></td>
<td>
<p>name of the cause variable. If not specified, the first variable in
<code>y</code> is treated as the dependent variable and the second is treated as the cause.</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_p">p</code></td>
<td>
<p>a vector of one or two positive integers specifying the order <code class="reqn">p</code> of
autoregressive dependence. The input of length one is recycled, then <code>p[1]</code> is used for
the dependent variable and <code>p[2]</code> is used for the cause variable.
The user must specify <code>p</code> or <code>lag.max</code>.
If <code>lag.max</code> is specified, the argument <code>p</code> is ignored.</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_p.free">p.free</code></td>
<td>
<p>logical value indicating whether the autoregressive orders for the
dependent and cause variables should be selected independently.
The default <code>p.free = FALSE</code> means the same autoregressive order is
selected for both variables. Note that if <code>p.free = TRUE</code> and <code>lag.max</code> is specified,
then <code>lag.max[1] * (lag.max[2] - lag.restrict)</code> models are compared,
which might be slow depending on the maximal lags and sample size.</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_lag.restrict">lag.restrict</code></td>
<td>
<p>integer for the number of short-term lags in the cause variable
to remove from consideration (default is zero, meaning no lags are removed).
This setting does not affect the dependent variable lags that are always present.</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_lag.max">lag.max</code></td>
<td>
<p>a vector of one or two positive integers for the highest lag orders to explore.
The input of length one is recycled, then <code>lag.max[1]</code> used for
the dependent variable and <code>lag.max[2]</code> is used for the cause variable.
The order is then selected using the Akaike information criterion (AIC; default),
see the argument <code>k</code> to change the criterion.
<code>lag.max</code> of length 2 automatically sets <code>p.free = TRUE</code>.</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_k">k</code></td>
<td>
<p>numeric scalar specifying the weight of the equivalent degrees of freedom part
in the AIC formula. Default <code>k = 2</code> corresponds to the traditional AIC.
Use <code>k = log(n)</code> to use the Bayesian information criterion instead
(see <code><a href="stats.html#topic+extractAIC">extractAIC</a></code>).</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_b">B</code></td>
<td>
<p>number of bootstrap replications. Default is 500.</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_test">test</code></td>
<td>
<p>a numeric value specifying the size of the testing set. If <code>test</code> &lt; 1,
the value is treated as a proportion of the sample size to be used as the testing set.
Otherwise, <code>test</code> is treated as the number of the most recent values to be used as the testing set.
Default is 0.3, which means that 30% of the sample is used for calculating
out-of-sample errors. The testing set is always at the end of the time series.</p>
</td></tr>
<tr><td><code id="causality_pred_+3A_cl">cl</code></td>
<td>
<p>parameter to specify computer cluster for bootstrapping passed to
the package <code>parallel</code> (default <code>cl = 1</code>, means no cluster is used).
Possible values are:
</p>

<ul>
<li><p> cluster object (list) produced by <a href="parallel.html#topic+makeCluster">makeCluster</a>.
In this case, a new cluster is not started nor stopped;
</p>
</li>
<li> <p><code>NULL</code>. In this case, the function will detect
available cores (see <a href="parallel.html#topic+detectCores">detectCores</a>) and, if there are
multiple cores (<code class="reqn">&gt;1</code>), a cluster will be started with
<a href="parallel.html#topic+makeCluster">makeCluster</a>. If started, the cluster will be stopped
after the computations are finished;
</p>
</li>
<li><p> positive integer defining the number of cores to start a cluster.
If <code>cl = 1</code> (default), no attempt to create a cluster will be made.
If <code>cl</code> &gt; 1, a cluster will be started (using <a href="parallel.html#topic+makeCluster">makeCluster</a>)
and stopped afterward (using <a href="parallel.html#topic+stopCluster">stopCluster</a>).
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The tests include the MSE-t approach (McCracken 2007) and
MSE-correlation test as in Chapter 9.3 of Granger and Newbold (1986).
The bootstrap is used to empirically derive distributions of the statistics.
</p>
<p>In the implemented bootstrapping, residuals of the restricted model under the null hypothesis of no Granger
causality are bootstrapped to generate new data under the null hypothesis. Then, the full and restricted
models are re-estimated on the bootstrapped data to obtain new (bootstrapped) forecast errors.
</p>
<p>In the current implementation, the bootstrapped <code class="reqn">p</code>-value is calculated using Equation 4.10 in
Davison and Hinkley (1997): <code>p.value</code> = (1 + <code class="reqn">n</code>) / (<code>B</code> + 1),
where <code class="reqn">n</code> is the number of bootstrapped statistics smaller or equal to the observed statistic.
</p>
<p>This function tests the Granger causation
of <code class="reqn">X</code> to <code class="reqn">Y</code> or from <code class="reqn">Y</code> to <code class="reqn">X</code>
(to test in both directions, need to run the function twice, with different argument <code>cause</code>).
To use the symmetric vector autoregression (VAR), use the function <code><a href="#topic+causality_predVAR">causality_predVAR</a></code>.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>stat</code></td>
<td>
<p>a table with the observed values of the test statistics and <code class="reqn">p</code>-values.</p>
</td></tr>
<tr><td><code>cause</code></td>
<td>
<p>the cause variable.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the AR orders used for the dependent variable (<code>p[1]</code>) and for the cause variable (<code>p[2]</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Davison AC, Hinkley DV (1997).
<em>Bootstrap Methods and Their Application</em>.
Cambridge University Press, Cambridge.<br /><br /> Granger CWJ, Newbold P (1986).
<em>Forecasting economic time series</em>, 2 edition.
Academic Press.<br /><br /> McCracken MW (2007).
&ldquo;Asymptotics for out of sample tests of Granger causality.&rdquo;
<em>Journal of Econometrics</em>, <b>140</b>(2), 719&ndash;752.
<a href="https://doi.org/10.1016/j.jeconom.2006.07.020">doi:10.1016/j.jeconom.2006.07.020</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+causality_predVAR">causality_predVAR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Canada time series (ts object)
Canada &lt;- vars::Canada
causality_pred(Canada[,1:2], cause = "e", lag.max = 5, p.free = TRUE)
causality_pred(Canada[,1:2], cause = "e", lag.restrict = 3, lag.max = 15, p.free = TRUE)

# Example 2 (run in parallel, initiate the cluster automatically)
# Box &amp; Jenkins time series
# of sales and a leading indicator, see ?BJsales

D &lt;- cbind(BJsales.lead, BJsales)
causality_pred(D, cause = "BJsales.lead", lag.max = 5, B = 1000, cl = NULL)

# Example 3 (run in parallel, initiate the cluster manually)

# Initiate a local cluster
cores &lt;- parallel::detectCores()
cl &lt;- parallel::makeCluster(cores)
parallel::clusterSetRNGStream(cl, 123) # to make parallel computations reproducible

causality_pred(D, cause = "BJsales.lead", lag.max = 5, B = 1000, cl = cl)
causality_pred(D, cause = "BJsales.lead", lag.restrict = 3, p = 5, B = 1000, cl = cl)
parallel::stopCluster(cl)

## End(Not run)

</code></pre>

<hr>
<h2 id='causality_predVAR'>Out-of-sample Tests of Granger Causality using (Restricted) Vector Autoregression</h2><span id='topic+causality_predVAR'></span>

<h3>Description</h3>

<p>Test for Granger causality using out-of-sample prediction errors from a vector
autoregression (VAR), where the original VAR can be restricted (see Details).
The tests include the MSE-t approach (McCracken 2007) and
MSE-correlation test as in Chapter 9.3 of Granger and Newbold (1986).
The bootstrap is used to empirically derive distributions of the statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causality_predVAR(
  y,
  p = NULL,
  cause = NULL,
  B = 500L,
  test = 0.3,
  cl = 1L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causality_predVAR_+3A_y">y</code></td>
<td>
<p>data frame or <code>ts</code> object for estimating VAR(<code class="reqn">p</code>).</p>
</td></tr>
<tr><td><code id="causality_predVAR_+3A_p">p</code></td>
<td>
<p>an integer specifying the order <code class="reqn">p</code> in VAR.
By default (if <code>p</code> is not specified),
<code class="reqn">p</code> is selected based on the information criterion
<code>ic</code> (see <code>...</code> arguments; default <code>ic</code> is AIC).</p>
</td></tr>
<tr><td><code id="causality_predVAR_+3A_cause">cause</code></td>
<td>
<p>name of the cause variable. If not specified, the first variable in
<code>y</code> is treated as the dependent variable and the second is treated as the cause.</p>
</td></tr>
<tr><td><code id="causality_predVAR_+3A_b">B</code></td>
<td>
<p>number of bootstrap replications. Default is 500.</p>
</td></tr>
<tr><td><code id="causality_predVAR_+3A_test">test</code></td>
<td>
<p>a numeric value specifying the size of the testing set. If <code>test</code> &lt; 1,
the value is treated as a proportion of the sample size to be used as the testing set.
Otherwise, <code>test</code> is treated as the number of the most recent values to be used as the testing set.
Default is 0.3, which means that 30% of the sample is used for calculating
out-of-sample errors. The testing set is always at the end of the time series.</p>
</td></tr>
<tr><td><code id="causality_predVAR_+3A_cl">cl</code></td>
<td>
<p>parameter to specify computer cluster for bootstrapping passed to
the package <code>parallel</code> (default <code>cl = 1</code>, means no cluster is used).
Possible values are:
</p>

<ul>
<li><p> cluster object (list) produced by <a href="parallel.html#topic+makeCluster">makeCluster</a>.
In this case, a new cluster is not started nor stopped;
</p>
</li>
<li> <p><code>NULL</code>. In this case, the function will detect
available cores (see <a href="parallel.html#topic+detectCores">detectCores</a>) and, if there are
multiple cores (<code class="reqn">&gt;1</code>), a cluster will be started with
<a href="parallel.html#topic+makeCluster">makeCluster</a>. If started, the cluster will be stopped
after the computations are finished;
</p>
</li>
<li><p> positive integer defining the number of cores to start a cluster.
If <code>cl = 1</code> (default), no attempt to create a cluster will be made.
If <code>cl</code> &gt; 1, a cluster will be started (using <a href="parallel.html#topic+makeCluster">makeCluster</a>)
and stopped afterward (using <a href="parallel.html#topic+stopCluster">stopCluster</a>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="causality_predVAR_+3A_...">...</code></td>
<td>
<p>other arguments passed to the function for VAR estimation.
The arguments include <code>lag.restrict</code> that is used to remove the first lags
in the cause variable from consideration (use restricted VAR to avoid testing for short-term causality);
default <code>lag.restrict = 0L</code>, i.e., no restrictions.
Other possible arguments are as in the <code><a href="vars.html#topic+VAR">VAR</a></code> function.
Also, see Details and Examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments specified in <code>...</code> are passed to the <code><a href="vars.html#topic+VAR">VAR</a></code> function.
Additionally, <code>lag.restrict</code> can be specified to remove short-term lags from
consideration (<code>lag.restrict</code> is not an option in the original package <code>vars</code>).
Note that if <code>p</code> is specified, <code>lag.restrict</code> must be smaller
than <code>p</code> otherwise the default <code>lag.restrict = 0</code> will be used.
If <code>lag.max</code> is specified instead of <code>p</code>, VAR orders
<code>lag.restrict</code> + 1, ..., <code>lag.max</code> will be considered using the training data
and the order <code class="reqn">p</code> will be automatically selected according to the information criterion
(by default, AIC).
</p>
<p>In the current implementation, the bootstrapped <code class="reqn">p</code>-value is calculated using equation 4.10 of
Davison and Hinkley (1997): <code>p.value</code> = (1 + <code class="reqn">n</code>) / (<code>B</code> + 1),
where <code class="reqn">n</code> is the number of bootstrapped statistics smaller or equal to the observed statistic.
In the fast bootstrap, <code class="reqn">n</code> is the number of bootstrapped statistics greater or equal to 0.
</p>
<p>This function uses symmetric VAR with the same orders <code class="reqn">p</code> for modeling both <code class="reqn">Y</code> to <code class="reqn">X</code>.
To select these orders more independently, consider using the function <code><a href="#topic+causality_pred">causality_pred</a></code>.
</p>


<h3>Value</h3>

<p>Two lists (one for the fast bootstrap,
another for the bootstrap under the null hypothesis) each containing the following elements:
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>a table with the observed values of the test statistics and <code class="reqn">p</code>-values.</p>
</td></tr>
<tr><td><code>cause</code></td>
<td>
<p>the cause variable.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the AR order used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Davison AC, Hinkley DV (1997).
<em>Bootstrap Methods and Their Application</em>.
Cambridge University Press, Cambridge.<br /><br /> Granger CWJ, Newbold P (1986).
<em>Forecasting economic time series</em>, 2 edition.
Academic Press.<br /><br /> McCracken MW (2007).
&ldquo;Asymptotics for out of sample tests of Granger causality.&rdquo;
<em>Journal of Econometrics</em>, <b>140</b>(2), 719&ndash;752.
<a href="https://doi.org/10.1016/j.jeconom.2006.07.020">doi:10.1016/j.jeconom.2006.07.020</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+causality_pred">causality_pred</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Canada time series (ts object)
Canada &lt;- vars::Canada
causality_predVAR(Canada[,1:2], cause = "e", lag.max = 5)
causality_predVAR(Canada[,1:2], cause = "e", lag.restrict = 3, lag.max = 15)

# Example 2 (run in parallel, initiate the cluster manually):
# Box &amp; Jenkins time series
# of sales and a leading indicator, see ?BJsales

# Initiate a local cluster
cores &lt;- parallel::detectCores()
cl &lt;- parallel::makeCluster(cores)
parallel::clusterSetRNGStream(cl, 123) # to make parallel computations reproducible

D &lt;- cbind(BJsales.lead, BJsales)
causality_predVAR(D, cause = "BJsales.lead", lag.max = 5, B = 1000, cl = cl)
causality_predVAR(D, cause = "BJsales.lead", lag.restrict = 3, p = 5, B = 1000, cl = cl)
parallel::stopCluster(cl)

## End(Not run)

</code></pre>

<hr>
<h2 id='ccf_boot'>Cross-Correlation of Autocorrelated Time Series</h2><span id='topic+ccf_boot'></span>

<h3>Description</h3>

<p>Account for possible autocorrelation of time series when assessing the statistical significance
of their cross-correlation. A sieve bootstrap approach is used to generate multiple copies
of the time series with the same autoregressive dependence, under the null hypothesis of the
two time series under investigation being uncorrelated. The significance of cross-correlation
coefficients is assessed based on the distribution of their bootstrapped counterparts.
Both Pearson and Spearman types of coefficients are obtained, but a plot is provided for
only one type, with significant correlations shown using filled circles (see Examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ccf_boot(
  x,
  y,
  lag.max = NULL,
  plot = c("Pearson", "Spearman", "none"),
  level = 0.95,
  B = 1000,
  smooth = FALSE,
  cl = 1L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ccf_boot_+3A_x">x</code>, <code id="ccf_boot_+3A_y">y</code></td>
<td>
<p>univariate numeric time-series objects or numeric vectors for which to
compute cross-correlation. Different time attributes in <code>ts</code> objects are
acknowledged, see Example 2 below.</p>
</td></tr>
<tr><td><code id="ccf_boot_+3A_lag.max">lag.max</code></td>
<td>
<p>maximum lag at which to calculate the cross-correlation. Will be
automatically limited as in <code><a href="stats.html#topic+ccf">ccf</a></code>.</p>
</td></tr>
<tr><td><code id="ccf_boot_+3A_plot">plot</code></td>
<td>
<p>choose whether to plot results for Pearson correlation (default, or use
<code>plot = "Pearson"</code>), Spearman correlation (use <code>plot = "Spearman"</code>), or
suppress plotting (use <code>plot = "none"</code>). Both Pearson's and Spearman's results are
given in the output, regardless of the <code>plot</code> setting.</p>
</td></tr>
<tr><td><code id="ccf_boot_+3A_level">level</code></td>
<td>
<p>confidence level, from 0 to 1. Default is 0.95, that is, 95% confidence.</p>
</td></tr>
<tr><td><code id="ccf_boot_+3A_b">B</code></td>
<td>
<p>number of bootstrap simulations to obtain empirical critical values.
Default is 1000.</p>
</td></tr>
<tr><td><code id="ccf_boot_+3A_smooth">smooth</code></td>
<td>
<p>logical value indicating whether the bootstrap confidence bands
should be smoothed across lags.
Default is <code>FALSE</code> meaning no smoothing.</p>
</td></tr>
<tr><td><code id="ccf_boot_+3A_cl">cl</code></td>
<td>
<p>parameter to specify computer cluster for bootstrapping passed to
the package <code>parallel</code> (default <code>cl = 1</code>, means no cluster is used).
Possible values are:
</p>

<ul>
<li><p> cluster object (list) produced by <a href="parallel.html#topic+makeCluster">makeCluster</a>.
In this case, a new cluster is not started nor stopped;
</p>
</li>
<li> <p><code>NULL</code>. In this case, the function will detect
available cores (see <a href="parallel.html#topic+detectCores">detectCores</a>) and, if there are
multiple cores (<code class="reqn">&gt;1</code>), a cluster will be started with
<a href="parallel.html#topic+makeCluster">makeCluster</a>. If started, the cluster will be stopped
after the computations are finished;
</p>
</li>
<li><p> positive integer defining the number of cores to start a cluster.
If <code>cl = 1</code> (default), no attempt to create a cluster will be made.
If <code>cl</code> &gt; 1, a cluster will be started (using <a href="parallel.html#topic+makeCluster">makeCluster</a>)
and stopped afterward (using <a href="parallel.html#topic+stopCluster">stopCluster</a>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="ccf_boot_+3A_...">...</code></td>
<td>
<p>other parameters passed to the function <code><a href="#topic+ARest">ARest</a></code> to control
how autoregressive dependencies are estimated. The same set of parameters is used
separately on <code>x</code> and <code>y</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the smoothing of confidence bands is implemented purely for the look.
This smoothing is different from the
smoothing methods that can be applied to adjust bootstrap performance
(De Angelis and Young 1992).
For correlations close to the significance bounds, the setting of <code>smooth</code> might
affect the decision on the statistical significance.
In this case, it is recommended to keep <code>smooth = FALSE</code> and set a higher <code>B</code>.
</p>


<h3>Value</h3>

<p>A data frame with the following columns:
</p>
<table>
<tr><td><code>Lag</code></td>
<td>
<p>lags for which the following values were obtained.</p>
</td></tr>
<tr><td><code>r_P</code></td>
<td>
<p>observed Pearson correlations.</p>
</td></tr>
<tr><td><code>lower_P</code>, <code>upper_P</code></td>
<td>
<p>lower and upper confidence bounds (for the confidence level set by <code>level</code>) for Pearson correlations.</p>
</td></tr>
<tr><td><code>r_S</code></td>
<td>
<p>observed Spearman correlations.</p>
</td></tr>
<tr><td><code>lower_S</code>, <code>upper_S</code></td>
<td>
<p>lower and upper confidence bounds (for the confidence level set by <code>level</code>) for Spearman correlations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ARest">ARest</a></code>, <code><a href="stats.html#topic+ar">ar</a></code>, <code><a href="stats.html#topic+ccf">ccf</a></code>,
<code><a href="#topic+HVK">HVK</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Fix seed for reproducible simulations:
set.seed(1)

# Example 1
# Simulate independent normal time series of same lengths
x &lt;- rnorm(100)
y &lt;- rnorm(100)
# Default CCF with parametric confidence band
ccf(x, y)
# CCF with bootstrap
tmp &lt;- ccf_boot(x, y)
# One can extract results for both Pearson and Spearman correlations
tmp$rP
tmp$rS

# Example 2
# Simulated ts objects of different lengths and starts (incomplete overlap)
x &lt;- arima.sim(list(order = c(1, 0, 0), ar = 0.5), n = 30)
x &lt;- ts(x, start = 2001)
y &lt;- arima.sim(list(order = c(2, 0, 0), ar = c(0.5, 0.2)), n = 40)
y &lt;- ts(y, start = 2020)
# Show how x and y are aligned
ts.plot(x, y, col = 1:2, lty = 1:2)
# The usual CCF
ccf(x, y)
# CCF with bootstrap confidence intervals
ccf_boot(x, y, plot = "Spearman")
# Notice that only +-7 lags can be calculated in both cases because of the small
# overlap of the time series. If we save these time series as plain vectors, the time
# information would be lost, and the time series will be misaligned.
ccf(as.numeric(x), as.numeric(y))

# Example 3
# Box &amp; Jenkins time series of sales and a leading indicator, see ?BJsales
plot.ts(cbind(BJsales.lead, BJsales))
# Each of the BJ time series looks as having a stochastic linear trend, so apply differences
plot.ts(cbind(diff(BJsales.lead), diff(BJsales)))
# Get cross-correlation of the differenced series
ccf_boot(diff(BJsales.lead), diff(BJsales), plot = "Spearman")
# The leading indicator "stands out" with significant correlations at negative lags,
# showing it can be used to predict the sales 2-3 time steps ahead (that is,
# diff(BJsales.lead) at times t-2 and t-3 is strongly correlated with diff(BJsales) at
# current time t).

## End(Not run)

</code></pre>

<hr>
<h2 id='CSlideCluster'>Slide-Level Time Series Clustering</h2><span id='topic+CSlideCluster'></span>

<h3>Description</h3>

<p>Cluster time series at a slide level,
based on Algorithm 1 of Ciampi et al. (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CSlideCluster(X, Alpha = NULL, Beta = NULL, Delta = NULL, Theta = 0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CSlideCluster_+3A_x">X</code></td>
<td>
<p>a matrix of time series observed within a slide (time series in columns).</p>
</td></tr>
<tr><td><code id="CSlideCluster_+3A_alpha">Alpha</code></td>
<td>
<p>lower limit of the time series domain. Default is
<code>quantile(X)[2] -</code><br /> <code>1.5*(quantile(X)[4] - quantile(X)[2])</code>.</p>
</td></tr>
<tr><td><code id="CSlideCluster_+3A_beta">Beta</code></td>
<td>
<p>upper limit of the time series domain.
Default is <code>quantile(X)[2] +</code><br /> <code>1.5*(quantile(X)[4] - quantile(X)[2])</code>.</p>
</td></tr>
<tr><td><code id="CSlideCluster_+3A_delta">Delta</code></td>
<td>
<p>closeness parameter, a real value in <code class="reqn">[0,1]</code>.
Default is <code>0.1*(Beta - Alpha)</code>.</p>
</td></tr>
<tr><td><code id="CSlideCluster_+3A_theta">Theta</code></td>
<td>
<p>connectivity parameter, a real value in <code class="reqn">[0,1]</code>. Default is 0.8.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>ncol(X)</code> with cluster labels.
</p>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Ciampi A, Appice A, Malerba D (2010).
&ldquo;Discovering trend-based clusters in spatially distributed data streams.&rdquo;
In <em>International Workshop of Mining Ubiquitous and Social Environments</em>, 107&ndash;122.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CSlideCluster">CSlideCluster</a></code>, <code><a href="#topic+CWindowCluster">CWindowCluster</a></code>,
and <code><a href="#topic+BICC">BICC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
X &lt;- matrix(rnorm(50), 10, 5)
CSlideCluster(X)

</code></pre>

<hr>
<h2 id='cumsumCPA_test'>Change Point Detection in Time Series via a Linear Regression with Temporally Correlated
Errors</h2><span id='topic+cumsumCPA_test'></span>

<h3>Description</h3>

<p>The function tests for a change point in parameters of a linear regression model with errors
exhibiting a general weakly dependent structure. The approach extends earlier methods based
on cumulative sums derived under the assumption of independent errors. The approach applies
smoothing when the time series is dominated by high frequencies. To detect multiple changes,
it is recommended to employ a binary or wild segmentation (Gombay 2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cumsumCPA_test(
  y,
  a.order,
  crit.type = c("asymptotic", "bootstrap"),
  bootstrap.method = c("nonparametric", "parametric"),
  num.bootstrap = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cumsumCPA_test_+3A_y">y</code></td>
<td>
<p>a numeric time series vector. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="cumsumCPA_test_+3A_a.order">a.order</code></td>
<td>
<p>order of the autoregressive model which must be a non-negative integer number.</p>
</td></tr>
<tr><td><code id="cumsumCPA_test_+3A_crit.type">crit.type</code></td>
<td>
<p>a string parameter allowing to choose &quot;asymptotic&quot; or &quot;bootstrap&quot; options.</p>
</td></tr>
<tr><td><code id="cumsumCPA_test_+3A_bootstrap.method">bootstrap.method</code></td>
<td>
<p>a string parameter allowing to choose &quot;nonparametric&quot; or
&quot;parametric&quot; method of bootstrapping. &quot;nonparametric&quot; &ndash; resampling of the estimated
residuals (with replacement); &quot;parametric&quot; &ndash; sampling innovations from a normal distribution.</p>
</td></tr>
<tr><td><code id="cumsumCPA_test_+3A_num.bootstrap">num.bootstrap</code></td>
<td>
<p>number of bootstrap replications if <code>crit.type = "bootstrap"</code>.
The default number is 1000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>index</code></td>
<td>
<p>time point where the change has occurred.</p>
</td></tr>
<tr><td><code>stat</code></td>
<td>
<p>test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p><code>p-value</code> of the change point test.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Palina Niamkova, Dorcas Ofori-Boateng, Yulia R. Gel
</p>


<h3>References</h3>

<p>Gombay E (2010).
&ldquo;Change detection in linear regression with time series errors.&rdquo;
<em>Canadian Journal of Statistics</em>, <b>38</b>(1), 65&ndash;79.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcusum.test">mcusum.test</a></code> for change point test for regression
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Example 1:

#Simulate some time series:
series_1 = rnorm(157, 2, 1)
series_2 = rnorm(43, 7, 10)
main_val = c(series_1, series_2)

#Now perform a change point detection:
cumsumCPA_test(series_1, 1) # no change
cumsumCPA_test(main_val, 1) # one change, asymptotic critical region
cumsumCPA_test(main_val, 1, "bootstrap", "parametric") # one change, parametric bootstrap
cumsumCPA_test(main_val, 1, "bootstrap", "nonparametric") # one change, nonparametric 
#bootstrap

#Example 2:

#Consider time series with ratio of real GDP per family to the median income. This is a
#skewness and income inequality measure for the US families from 1947 till 2012. 
e.data = (Ecdat::incomeInequality['mean.median'])
incomeInequality.ts = ts(e.data, start = 1947, end = 2012, frequency = 1)

#Now perform a change point detection:
cumsumCPA_test(incomeInequality.ts, 0)
cumsumCPA_test(incomeInequality.ts, 0, "bootstrap", "parametric")
cumsumCPA_test(incomeInequality.ts, 0, "bootstrap", "nonparametric")
incomeInequality.ts[13] # median income
Ecdat::incomeInequality$Year[13] + 1 # year of change point

#The first change point occurs at the 13th time point, that is 1960, where the ratio of real 
#GDP per family to the median income is 1.940126. This ratio shows that in 1960 the national
#wealth was not distributed equally between all the population and that most people earn 
#almost twice less than the equal share of the all produced goods and services by the nation.

#Note: To look for the other possible change points, run the same function for the 
#segment of time series after value 13.

## End(Not run)

</code></pre>

<hr>
<h2 id='CWindowCluster'>Window-Level Time Series Clustering</h2><span id='topic+CWindowCluster'></span>

<h3>Description</h3>

<p>Cluster time series at a window level,
based on Algorithm 2 of Ciampi et al. (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CWindowCluster(
  X,
  Alpha = NULL,
  Beta = NULL,
  Delta = NULL,
  Theta = 0.8,
  p,
  w,
  s,
  Epsilon = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CWindowCluster_+3A_x">X</code></td>
<td>
<p>a matrix of time series observed within a slide (time series in columns).</p>
</td></tr>
<tr><td><code id="CWindowCluster_+3A_alpha">Alpha</code></td>
<td>
<p>lower limit of the time-series domain,
passed to <code><a href="#topic+CSlideCluster">CSlideCluster</a></code>.</p>
</td></tr>
<tr><td><code id="CWindowCluster_+3A_beta">Beta</code></td>
<td>
<p>upper limit of the time-series domain passed to <code><a href="#topic+CSlideCluster">CSlideCluster</a></code>.</p>
</td></tr>
<tr><td><code id="CWindowCluster_+3A_delta">Delta</code></td>
<td>
<p>closeness parameter passed to <code><a href="#topic+CSlideCluster">CSlideCluster</a></code>.</p>
</td></tr>
<tr><td><code id="CWindowCluster_+3A_theta">Theta</code></td>
<td>
<p>connectivity parameter passed to <code><a href="#topic+CSlideCluster">CSlideCluster</a></code>.</p>
</td></tr>
<tr><td><code id="CWindowCluster_+3A_p">p</code></td>
<td>
<p>number of layers (time-series observations) in each slide.</p>
</td></tr>
<tr><td><code id="CWindowCluster_+3A_w">w</code></td>
<td>
<p>number of slides in each window.</p>
</td></tr>
<tr><td><code id="CWindowCluster_+3A_s">s</code></td>
<td>
<p>step to shift a window, calculated in the number of slides. The recommended
values are 1 (overlapping windows) or equal to <code>w</code> (non-overlapping windows).</p>
</td></tr>
<tr><td><code id="CWindowCluster_+3A_epsilon">Epsilon</code></td>
<td>
<p>a real value in <code class="reqn">[0,1]</code> used to identify each pair of time series
that are clustered together over at least <code>w*Epsilon</code> slides within a window;
see Definition 7 by Ciampi et al. (2010). Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the upper-level function for time series clustering. It exploits
the function <code><a href="#topic+CSlideCluster">CSlideCluster</a></code> to cluster time series within each slide
based on closeness and homogeneity measures. Then, it uses slide-level cluster
assignments to cluster time series within each window.
</p>
<p>The total length of time series (number of levels, i.e., <code>nrow(X)</code>)
should be divisible by <code>p</code>.
</p>


<h3>Value</h3>

<p>A vector (if <code>X</code> contains only one window) or matrix with cluster
labels for each time series (columns) and window (rows).
</p>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Ciampi A, Appice A, Malerba D (2010).
&ldquo;Discovering trend-based clusters in spatially distributed data streams.&rdquo;
In <em>International Workshop of Mining Ubiquitous and Social Environments</em>, 107&ndash;122.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CSlideCluster">CSlideCluster</a></code>, <code><a href="#topic+CWindowCluster">CWindowCluster</a></code>,
and <code><a href="#topic+BICC">BICC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#For example, weekly data come in slides of 4 weeks
p &lt;- 4 #number of layers in each slide (data come in a slide)
    
#We want to analyze the trend clusters within a window of 1 year
w &lt;- 13 #number of slides in each window
s &lt;- w  #step to shift a window

#Simulate 26 autoregressive time series with two years of weekly data (52*2 weeks), 
#with a 'burn-in' period of 300.
N &lt;- 26
T &lt;- 2*p*w
    
set.seed(123) 
phi &lt;- c(0.5) #parameter of autoregression
X &lt;- sapply(1:N, function(x) arima.sim(n = T + 300, 
     list(order = c(length(phi), 0, 0), ar = phi)))[301:(T + 300),]
colnames(X) &lt;- paste("TS", c(1:dim(X)[2]), sep = "")
 
tmp &lt;- CWindowCluster(X, Delta = NULL, Theta = 0.8, p = p, w = w, s = s, Epsilon = 1)

#Time series were simulated with the same parameters, but based on the clustering parameters,
#not all time series join the same cluster. We can plot the main cluster for each window, and 
#time series out of the cluster:
par(mfrow = c(2, 2))
ts.plot(X[c(1:(p*w)), tmp[1,] == 1], ylim = c(-4, 4), 
        main = "Time series cluster 1 in window 1")
ts.plot(X[c(1:(p*w)), tmp[1,] != 1], ylim = c(-4, 4), 
        main = "The rest of the time series in window 1")
ts.plot(X[c(1:(p*w)) + s*p, tmp[2,] == 1], ylim = c(-4, 4), 
        main = "Time series cluster 1 in window 2")
ts.plot(X[c(1:(p*w)) + s*p, tmp[2,] != 1], ylim = c(-4, 4), 
        main = "The rest of the time series in window 2")

</code></pre>

<hr>
<h2 id='DR'>Downhill Riding (DR) Procedure</h2><span id='topic+DR'></span>

<h3>Description</h3>

<p>Downhill riding procedure for selecting optimal tuning parameters in clustering
algorithms, using an (in)stability probe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DR(X, method, minPts = 3, theta = 0.9, B = 500, lb = -30, ub = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DR_+3A_x">X</code></td>
<td>
<p>an <code class="reqn">n\times k</code> matrix where columns are <code class="reqn">k</code> objects to be clustered,
and each object contains n observations (objects could be a set of time series).</p>
</td></tr>
<tr><td><code id="DR_+3A_method">method</code></td>
<td>
<p>the clustering method to be used &ndash; currently either
&ldquo;TRUST&rdquo; (Ciampi et al. 2010)
or &ldquo;DBSCAN&rdquo; (Ester et al. 1996). If the method is <code>DBSCAN</code>,
then set <code>MinPts</code> and optimal <code class="reqn">\epsilon</code> is selected using DR.
If the method is <code>TRUST</code>, then set <code>theta</code>, and optimal <code class="reqn">\delta</code>
is selected using DR.</p>
</td></tr>
<tr><td><code id="DR_+3A_minpts">minPts</code></td>
<td>
<p>the minimum number of samples in an <code class="reqn">\epsilon</code>-neighborhood of
a point to be considered as a core point. The <code>minPts</code> is to be used only
with the <code>DBSCAN</code> method. The default value is 3.</p>
</td></tr>
<tr><td><code id="DR_+3A_theta">theta</code></td>
<td>
<p>connectivity parameter <code class="reqn">\theta \in (0,1)</code>, which is to be used
only with the <code>TRUST</code> method. The default value is 0.9.</p>
</td></tr>
<tr><td><code id="DR_+3A_b">B</code></td>
<td>
<p>number of random splits in calculating the
Average Cluster Deviation (ACD). The default value is 500.</p>
</td></tr>
<tr><td><code id="DR_+3A_lb">lb</code>, <code id="DR_+3A_ub">ub</code></td>
<td>
<p>endpoints for a range of search for the optimal parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameters <code>lb,ub</code> are endpoints for the search for the
optimal parameter. The parameter candidates are calculated in a way such that
<code class="reqn">P:=  1.1^x , x \in {lb,lb+0.5,lb+1.0,...,ub}</code>.
Although the default range of search is sufficiently wide, in some cases
<code>lb,ub</code> can be further extended if a warning message is given.
</p>
<p>For more discussion on properties of the considered clustering algorithms and the
DR procedure see Huang et al. (2016)
and Huang et al. (2018).
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>P_opt</code></td>
<td>
<p>the value of the optimal parameter. If the method is <code>DBSCAN</code>, then
<code>P_opt</code> is optimal <code class="reqn">\epsilon</code>. If the method is <code>TRUST</code>,
then <code>P_opt</code> is optimal <code class="reqn">\delta</code>.</p>
</td></tr>
<tr><td><code>ACD_matrix</code></td>
<td>
<p>a matrix that returns <code>ACD</code> for different values of a
tuning parameter.
If the method is <code>DBSCAN</code>, then the tuning parameter is <code class="reqn">\epsilon</code>.
If the method is <code>TRUST</code>, then the tuning parameter is <code class="reqn">\delta</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Xin Huang, Yulia R. Gel
</p>


<h3>References</h3>

<p>Ciampi A, Appice A, Malerba D (2010).
&ldquo;Discovering trend-based clusters in spatially distributed data streams.&rdquo;
In <em>International Workshop of Mining Ubiquitous and Social Environments</em>, 107&ndash;122.<br /><br /> Ester M, Kriegel H, Sander J, Xu X (1996).
&ldquo;A density-based algorithm for discovering clusters in large spatial databases with noise.&rdquo;
In <em>Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD)</em>, volume 96(34), 226&ndash;231.<br /><br /> Huang X, Iliev IR, Brenning A, Gel YR (2016).
&ldquo;Space-time clustering with stability probe while riding downhill.&rdquo;
In <em>Proceedings of the 2nd SIGKDD Workshop on Mining and Learning from Time Series (MiLeTS)</em>.<br /><br /> Huang X, Iliev IR, Lyubchich V, Gel YR (2018).
&ldquo;Riding down the bay: space-time clustering of ecological trends.&rdquo;
<em>Environmetrics</em>, <b>29</b>(5&ndash;6), e2455.
<a href="https://doi.org/10.1002/env.2455">doi:10.1002/env.2455</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BICC">BICC</a></code>, <code><a href="dbscan.html#topic+dbscan">dbscan</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## example 1
## use iris data to test DR procedure

data(iris)  
require(clue)  # calculate NMI to compare the clustering result with the ground truth
require(scatterplot3d)

Data &lt;- scale(iris[,-5])
ground_truth_label &lt;- iris[,5]

# perform DR procedure to select optimal eps for DBSCAN 
# and save it in variable eps_opt
eps_opt &lt;- DR(t(Data), method="DBSCAN", minPts = 5)$P_opt   

# apply DBSCAN with the optimal eps on iris data 
# and save the clustering result in variable res
res &lt;- dbscan(Data, eps = eps_opt, minPts =5)$cluster  

# calculate NMI to compare the clustering result with the ground truth label
clue::cl_agreement(as.cl_partition(ground_truth_label),
                   as.cl_partition(as.numeric(res)), method = "NMI") 
# visualize the clustering result and compare it with the ground truth result
# 3D visualization of clustering result using variables Sepal.Width, Sepal.Length, 
# and Petal.Length
scatterplot3d(Data[,-4],color = res)
# 3D visualization of ground truth result using variables Sepal.Width, Sepal.Length,
# and Petal.Length
scatterplot3d(Data[,-4],color = as.numeric(ground_truth_label))


## example 2
## use synthetic time series data to test DR procedure

require(funtimes)
require(clue) 
require(zoo)

# simulate 16 time series for 4 clusters, each cluster contains 4 time series
set.seed(114) 
samp_Ind &lt;- sample(12,replace=F)
time_points &lt;- 30
X &lt;- matrix(0,nrow=time_points,ncol = 12)
cluster1 &lt;- sapply(1:4,function(x) arima.sim(list(order = c(1, 0, 0), ar = c(0.2)),
                                             n = time_points, mean = 0, sd = 1))
cluster2 &lt;- sapply(1:4,function(x) arima.sim(list(order = c(2 ,0, 0), ar = c(0.1, -0.2)),
                                             n = time_points, mean = 2, sd = 1))
cluster3 &lt;- sapply(1:4,function(x) arima.sim(list(order = c(1, 0, 1), ar = c(0.3), ma = c(0.1)),
                                             n = time_points, mean = 6, sd = 1))

X[,samp_Ind[1:4]] &lt;- t(round(cluster1, 4))
X[,samp_Ind[5:8]] &lt;- t(round(cluster2, 4))
X[,samp_Ind[9:12]] &lt;- t(round(cluster3, 4))


# create ground truth label of the synthetic data
ground_truth_label = matrix(1, nrow = 12, ncol = 1) 
for(k in 1:3){
    ground_truth_label[samp_Ind[(4*k - 4 + 1):(4*k)]] = k
}

# perform DR procedure to select optimal delta for TRUST
# and save it in variable delta_opt
delta_opt &lt;- DR(X, method = "TRUST")$P_opt 

# apply TRUST with the optimal delta on the synthetic data 
# and save the clustering result in variable res
res &lt;- CSlideCluster(X, Delta = delta_opt, Theta = 0.9)  

# calculate NMI to compare the clustering result with the ground truth label
clue::cl_agreement(as.cl_partition(as.numeric(ground_truth_label)),
                   as.cl_partition(as.numeric(res)), method = "NMI")

# visualize the clustering result and compare it with the ground truth result
# visualization of the clustering result obtained by TRUST
plot.zoo(X, type = "l", plot.type = "single", col = res, xlab = "Time index", ylab = "")
# visualization of the ground truth result 
plot.zoo(X, type = "l", plot.type = "single", col = ground_truth_label,
         xlab = "Time index", ylab = "")

## End(Not run)

</code></pre>

<hr>
<h2 id='funtimes-defunct'>Defunct functions in package <span class="pkg">funtimes</span>.</h2><span id='topic+funtimes-defunct'></span><span id='topic+i.tails'></span><span id='topic+mcusum.test'></span><span id='topic+notrend.test'></span><span id='topic+q.tails'></span><span id='topic+sync.cluster'></span><span id='topic+sync.test'></span><span id='topic+wavk.test'></span>

<h3>Description</h3>

<p>The functions listed below are defunct and no longer available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>i.tails(...)

mcusum.test(...)

notrend.test(...)

q.tails(...)

sync.cluster(...)

sync.test(...)

wavk.test(...)
</code></pre>


<h3><code>i.tails</code></h3>

<p>For <code>i.tails</code>, use <code><a href="#topic+tails_i">tails_i</a></code>.
</p>


<h3><code>mcusum.test</code></h3>

<p>For <code>mcusum.test</code>, use <code><a href="#topic+mcusum_test">mcusum_test</a></code>.
</p>


<h3><code>notrend.test</code></h3>

<p>For <code>notrend.test</code>, use <code><a href="#topic+notrend_test">notrend_test</a></code>.
</p>


<h3><code>q.tails</code></h3>

<p>For <code>q.tails</code>, use <code><a href="#topic+tails_q">tails_q</a></code>.
</p>


<h3><code>sync.cluster</code></h3>

<p>For <code>sync.cluster</code>, use <code><a href="#topic+sync_cluster">sync_cluster</a></code>.
</p>


<h3><code>sync.test</code></h3>

<p>For <code>sync.test</code>, use <code><a href="#topic+sync_test">sync_test</a></code>.
</p>


<h3><code>wavk.test</code></h3>

<p>For <code>wavk.test</code>, use <code><a href="#topic+wavk_test">wavk_test</a></code>.
</p>


<h3>Author(s)</h3>

<p>Calvin Chu, Yulia R. Gel, Vyacheslav Lyubchich
</p>
<p>Vyacheslav Lyubchich
</p>
<p>Vyacheslav Lyubchich, Yulia R. Gel
</p>
<p>Srishti Vishwakarma, Vyacheslav Lyubchich
</p>
<p>Yulia R. Gel, Vyacheslav Lyubchich, Ethan Schaeffer, Xingyu Wang
</p>
<p>Yulia R. Gel, Vyacheslav Lyubchich, Ethan Schaeffer
</p>

<hr>
<h2 id='funtimes-deprecated'>Deprecated functions in package <span class="pkg">funtimes</span>.</h2><span id='topic+funtimes-deprecated'></span>

<h3>Description</h3>

<p>The functions listed below are deprecated and will be defunct in
the near future. When possible, alternative functions with similar
functionality are also mentioned. Help pages for deprecated functions are
available at <code>help("&lt;function&gt;-deprecated")</code>.
</p>

<hr>
<h2 id='funtimes-package'>funtimes: Functions for Time Series Analysis</h2><span id='topic+funtimes'></span><span id='topic+funtimes-package'></span>

<h3>Description</h3>

<p>Advances in multiple aspects of time-series analysis are documented in this package.
See available vignettes using <br />
<code>browseVignettes(package = "funtimes")</code>
</p>
<p>Tests for trends applicable to autocorrelated data, see <br />
<code>vignette("trendtests", package = "funtimes")</code> <br />
include bootstrapped versions of t-test and Mann&ndash;Kendall test (Noguchi et al. 2011)
and bootstrapped version of WAVK test for possibly non-monotonic trends (Lyubchich et al. 2013).
The WAVK test is further applied in testing synchronicity of trends (Lyubchich and Gel 2016);
see an implementation to climate data in Lyubchich (2016).
With iterative testing, the synchronicity test is also applied for identifying clusters of
multiple time series (Ghahari et al. 2017).
</p>
<p>Additional clustering methods are implemented using functions <code>BICC</code> (Schaeffer et al. 2016)
and <code>DR</code> (Huang et al. 2018);
function <code>purity</code> can be used to assess the accuracy of clustering if true classes are known.
</p>
<p>Changepoint detection methods include modified CUSUM-based bootstrapped test (Lyubchich et al. 2020).
</p>
<p>Additional functions include implementation of the Beale's ratio estimator, see <br />
<code>vignette("beales", package = "funtimes")</code> <br />
Nonparametric comparison of tails of distributions is implemented using small bins defined based on
quantiles (Soliman et al. 2015)
or intervals in the units in which the data are recorded (Lyubchich and Gel 2017).
</p>
<p>For a list of currently deprecated functions, use <code>?'funtimes-deprecated'</code>
</p>
<p>For a list of defunct (removed) functions, use <code>?'funtimes-defunct'</code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Vyacheslav Lyubchich <a href="mailto:lyubchich@umces.edu">lyubchich@umces.edu</a> (<a href="https://orcid.org/0000-0001-7936-4285">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Yulia R. Gel
</p>
</li>
<li><p> Srishti Vishwakarma
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Alexander Brenning [contributor]
</p>
</li>
<li><p> Calvin Chu [contributor]
</p>
</li>
<li><p> Xin Huang [contributor]
</p>
</li>
<li><p> Umar Islambekov [contributor]
</p>
</li>
<li><p> Palina Niamkova [contributor]
</p>
</li>
<li><p> Dorcas Ofori-Boateng [contributor]
</p>
</li>
<li><p> Ethan D. Schaeffer [contributor]
</p>
</li>
<li><p> Xingyu Wang [contributor]
</p>
</li></ul>



<h3>References</h3>

<p>Ghahari A, Gel YR, Lyubchich V, Chun Y, Uribe D (2017).
&ldquo;On employing multi-resolution weather data in crop insurance.&rdquo;
In <em>Proceedings of the SIAM International Conference on Data Mining (SDM17) Workshop on Mining Big Data in Climate and Environment (MBDCE 2017)</em>.<br /><br /> Huang X, Iliev IR, Lyubchich V, Gel YR (2018).
&ldquo;Riding down the bay: space-time clustering of ecological trends.&rdquo;
<em>Environmetrics</em>, <b>29</b>(5&ndash;6), e2455.
<a href="https://doi.org/10.1002/env.2455">doi:10.1002/env.2455</a>.<br /><br /> Lyubchich V (2016).
&ldquo;Detecting time series trends and their synchronization in climate data.&rdquo;
<em>Intelligence. Innovations. Investments</em>, <b>12</b>, 132&ndash;137.<br /><br /> Lyubchich V, Gel YR (2016).
&ldquo;A local factor nonparametric test for trend synchronism in multiple time series.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>150</b>, 91&ndash;104.
<a href="https://doi.org/10.1016/j.jmva.2016.05.004">doi:10.1016/j.jmva.2016.05.004</a>.<br /><br /> Lyubchich V, Gel YR (2017).
&ldquo;Can we weather proof our insurance?&rdquo;
<em>Environmetrics</em>, <b>28</b>(2), e2433.
<a href="https://doi.org/10.1002/env.2433">doi:10.1002/env.2433</a>.<br /><br /> Lyubchich V, Gel YR, El-Shaarawi A (2013).
&ldquo;On detecting non-monotonic trends in environmental time series: a fusion of local regression and bootstrap.&rdquo;
<em>Environmetrics</em>, <b>24</b>(4), 209&ndash;226.
<a href="https://doi.org/10.1002/env.2212">doi:10.1002/env.2212</a>.<br /><br /> Lyubchich V, Lebedeva TV, Testa JM (2020).
&ldquo;A data-driven approach to detecting change points in linear regression models.&rdquo;
<em>Environmetrics</em>, <b>31</b>(1), e2591.
<a href="https://doi.org/10.1002/env.2591">doi:10.1002/env.2591</a>.<br /><br /> Noguchi K, Gel YR, Duguay CR (2011).
&ldquo;Bootstrap-based tests for trends in hydrological time series, with application to ice phenology data.&rdquo;
<em>Journal of Hydrology</em>, <b>410</b>(3), 150&ndash;161.
<a href="https://doi.org/10.1016/j.jhydrol.2011.09.008">doi:10.1016/j.jhydrol.2011.09.008</a>.<br /><br /> Schaeffer ED, Testa JM, Gel YR, Lyubchich V (2016).
&ldquo;On information criteria for dynamic spatio-temporal clustering.&rdquo;
In Banerjee A, Ding W, Dy JG, Lyubchich V, Rhines A (eds.), <em>The 6th International Workshop on Climate Informatics: CI2016</em>, 5&ndash;8.
<a href="https://doi.org/10.5065/D6K072N6">doi:10.5065/D6K072N6</a>.<br /><br /> Soliman M, Lyubchich V, Gel YR, Naser D, Esterby S (2015).
&ldquo;Evaluating the impact of climate change on dynamics of house insurance claims.&rdquo;
In Lakshmanan V, Gilleland E, McGovern A, Tingley M (eds.), <em>Machine Learning and Data Mining Approaches to Climate Science</em>, chapter 16, 175&ndash;183.
Springer, Switzerland.
<a href="https://doi.org/10.1007/978-3-319-17220-0_16">doi:10.1007/978-3-319-17220-0_16</a>.
</p>

<hr>
<h2 id='GombayCPA_test'>Change Point Detection in Autoregressive Time Series</h2><span id='topic+GombayCPA_test'></span>

<h3>Description</h3>

<p>The function detects change points in autoregressive (AR) models for time series. Changes
can be detected in any of <code>p + 2</code> (mean, var, phi) autoregressive parameters where <code>p</code>
is the order of the AR model. The test statistic is based on the efficient score vector (Gombay 2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GombayCPA_test(
  y,
  a.order,
  alternatives = c("two-sided", "greater", "lesser", "temporary"),
  crit.type = c("asymptotic", "bootstrap"),
  num.bootstrap = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GombayCPA_test_+3A_y">y</code></td>
<td>
<p>a vector that contains univariate time-series observations. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="GombayCPA_test_+3A_a.order">a.order</code></td>
<td>
<p>order of the autoregressive model which must be a non-negative integer number.</p>
</td></tr>
<tr><td><code id="GombayCPA_test_+3A_alternatives">alternatives</code></td>
<td>
<p>a string parameter that specifies a type of the test (i.e., &quot;two-sided&quot;,
&quot;greater&quot;, &quot;lesser&quot;, and &quot;temporary&quot;).  The option &quot;temporary&quot; examines the temporary change
in one of the parameters (Gombay 2008).</p>
</td></tr>
<tr><td><code id="GombayCPA_test_+3A_crit.type">crit.type</code></td>
<td>
<p>method of obtaining critical values: &quot;asymptotic&quot; (default) or &quot;bootstrap&quot;.</p>
</td></tr>
<tr><td><code id="GombayCPA_test_+3A_num.bootstrap">num.bootstrap</code></td>
<td>
<p>number of bootstrap replications if <code>crit.type = "bootstrap"</code>.
The default number is 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function tests for a temporary change and a change in specific model parameters.
Critical values can be estimated via asymptotic distribution <code>"asymptotic"</code> (i.e., the
default option) or sieve bootstrap <code>"bootstrap"</code>. The function employs internal
function <code>change.point</code> and sieve bootstrap <code>change.point.sieve</code> function.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>index</code></td>
<td>
<p>points of change for each parameter. The value of the <code>"alternatives"</code>
determines the return:
&quot;temporary&quot; &ndash; returns max, min, and abs.max points;
&quot;greater&quot; &ndash; returns max points;
&quot;lesser&quot; &ndash;  returns min points;
&quot;two-sided&quot; &ndash; returns abs.max.</p>
</td></tr>
<tr><td><code>stats</code></td>
<td>
<p>test statistic values for change points in mean, var, phi.</p>
</td></tr>
<tr><td><code>p.values</code></td>
<td>
<p><code>p-value</code> of the change point test.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Palina Niamkova, Dorcas Ofori-Boateng, Yulia R. Gel
</p>


<h3>References</h3>

<p>Gombay E (2008).
&ldquo;Change detection in autoregressive time series.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>99</b>(3), 451&ndash;464.
<a href="https://doi.org/10.1016/j.jmva.2007.01.003">doi:10.1016/j.jmva.2007.01.003</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcusum.test">mcusum.test</a></code>  change point test for regression and
<code><a href="Ecdat.html#topic+terrorism">terrorism</a></code> dataset used in the Example 2
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Example 1:

#Simulate some time series:
series_1 = arima.sim(n = 100, list(order = c(2,0,0), ar = c(-0.7, -0.1)))
series_2 = arima.sim(n = 200, list(order = c(2,0,0), ar = c(0.1, -0.6)))
main_series = c(series_1, series_2)

result11 = GombayCPA_test(series_1, 2, "two-sided")
result11 #== No change point ===#

result12 = GombayCPA_test(main_series, 2, "two-sided")
result12  #=== One change at phi values ===#

result13 = GombayCPA_test(main_series, 2, "two-sided", "bootstrap")
result13  #=== One change at phi values ===#



#Example 2:

#From the package 'Ecdat' consider a time series with annual world number of victims of
#terrorism in the US from 1970 till 2016:
c.data = Ecdat::terrorism['nkill.us']
nkill.us.ts &lt;- ts(c.data, start = 1970, end = 2016)

#Now perform a change point detection with one sided tests:
GombayCPA_test(nkill.us.ts, 0, "lesser")
GombayCPA_test(nkill.us.ts, 0, "greater")
nkill.us.ts[32]
year = 1970 + 31
print(year)
plot(nkill.us.ts)

#In both cases we find that the change point is located at the position 31 or 32. We can
# examine it further by checking the value of this position (using: nkill.us.ts[32]) as well as
# by plotting the graph (using: plot(nkill.us.ts)). The detected change point corresponds to
#the year of 2001, when the 9/11 attack happened.

## End(Not run)

</code></pre>

<hr>
<h2 id='HVK'>HVK Estimator</h2><span id='topic+HVK'></span>

<h3>Description</h3>

<p>Estimate coefficients in nonparametric autoregression using the difference-based
approach by Hall and Van Keilegom (2003).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HVK(X, m1 = NULL, m2 = NULL, ar.order = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HVK_+3A_x">X</code></td>
<td>
<p>univariate time series. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="HVK_+3A_m1">m1</code>, <code id="HVK_+3A_m2">m2</code></td>
<td>
<p>subsidiary smoothing parameters. Default
<code>m1 = round(length(X)^(0.1))</code>, <code>m2 = round(length(X)^(0.5))</code>.</p>
</td></tr>
<tr><td><code id="HVK_+3A_ar.order">ar.order</code></td>
<td>
<p>order of the nonparametric autoregression (specified by user).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, autocovariances are estimated
using formula (2.6) by Hall and Van Keilegom (2003):
</p>
<p style="text-align: center;"><code class="reqn">\hat{\gamma}(0)=\frac{1}{m_2-m_1+1}\sum_{m=m_1}^{m_2}
\frac{1}{2(n-m)}\sum_{i=m+1}^{n}\{(D_mX)_i\}^2,</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\gamma}(j)=\hat{\gamma}(0)-\frac{1}{2(n-j)}\sum_{i=j+1}^n\{(D_jX)_i\}^2,</code>
</p>

<p>where <code class="reqn">n</code> = <code>length(X)</code> is sample size, <code class="reqn">D_j</code> is a difference operator
such that <code class="reqn">(D_jX)_i=X_i-X_{i-j}</code>. Then, Yule&ndash;Walker method is used to
derive autoregression coefficients.
</p>


<h3>Value</h3>

<p>Vector of length <code>ar.order</code> with estimated autoregression coefficients.
</p>


<h3>Author(s)</h3>

<p>Yulia R. Gel, Vyacheslav Lyubchich, Xingyu Wang
</p>


<h3>References</h3>

<p>Hall P, Van Keilegom I (2003).
&ldquo;Using difference-based methods for inference in nonparametric regression with time series errors.&rdquo;
<em>Journal of the Royal Statistical Society, Series B (Statistical Methodology)</em>, <b>65</b>(2), 443&ndash;456.
<a href="https://doi.org/10.1111/1467-9868.00395">doi:10.1111/1467-9868.00395</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ar">ar</a></code>, <code><a href="#topic+ARest">ARest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- arima.sim(n = 300, list(order = c(1, 0, 0), ar = c(0.6)))
HVK(as.vector(X), ar.order = 1)

</code></pre>

<hr>
<h2 id='i.tails-defunct'>Interval-Based Tails Comparison</h2><span id='topic+i.tails-defunct'></span>

<h3>Description</h3>

<p>Interval-Based Tails Comparison
</p>


<h3>See Also</h3>

<p><code><a href="#topic+funtimes-defunct">funtimes-defunct</a></code>
</p>

<hr>
<h2 id='mcusum_test'>Change Point Test for Regression</h2><span id='topic+mcusum_test'></span>

<h3>Description</h3>

<p>Apply change point test by Horvath et al. (2017)
for detecting at-most-<code class="reqn">m</code> changes in regression coefficients, where
test statistic is a modified cumulative sum (CUSUM), and
critical values are obtained with sieve bootstrap (Lyubchich et al. 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcusum_test(
  e,
  k,
  m = length(k),
  B = 1000,
  shortboot = FALSE,
  ksm = FALSE,
  ksm.arg = list(kernel = "gaussian", bw = "sj"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcusum_test_+3A_e">e</code></td>
<td>
<p>vector of regression residuals (a stationary time series).</p>
</td></tr>
<tr><td><code id="mcusum_test_+3A_k">k</code></td>
<td>
<p>an integer vector or scalar with hypothesized change point location(s) to
test.</p>
</td></tr>
<tr><td><code id="mcusum_test_+3A_m">m</code></td>
<td>
<p>an integer specifying the maximum number of change
points being confirmed as statistically significant (from those
specified in <code>k</code>) would be <code class="reqn">\le m</code>. Thus, <code>m</code> must
be in 1,...,<code>k</code>.</p>
</td></tr>
<tr><td><code id="mcusum_test_+3A_b">B</code></td>
<td>
<p>number of bootstrap simulations to obtain empirical critical values.
Default is 1000.</p>
</td></tr>
<tr><td><code id="mcusum_test_+3A_shortboot">shortboot</code></td>
<td>
<p>if <code>TRUE</code>, then a heuristic
is used to perform the test with a reduced number of bootstrap replicates.
Specifically, <code>B/4</code> replicates are used, which may reduce computing time by
up to 75% when the number of retained null hypotheses is large.
A <code class="reqn">p</code>-value of 999 is reported whenever a null hypothesis
is retained as a result of this mechanism.</p>
</td></tr>
<tr><td><code id="mcusum_test_+3A_ksm">ksm</code></td>
<td>
<p>logical value indicating whether a kernel smoothing to innovations in sieve
bootstrap shall be applied (default is <code>FALSE</code>, that is, the original estimated
innovations are bootstrapped, without the smoothing).</p>
</td></tr>
<tr><td><code id="mcusum_test_+3A_ksm.arg">ksm.arg</code></td>
<td>
<p>used only if <code>ksm = TRUE</code>. A list of arguments for kernel smoothing
to be passed to <code><a href="stats.html#topic+density">density</a></code> function. Default settings specify the
use of the Gaussian kernel and the <code>"sj"</code> rule to choose the bandwidth.</p>
</td></tr>
<tr><td><code id="mcusum_test_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="#topic+ARest">ARest</a></code>
(for example, <code>ar.method</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sieve bootstrap is applied by approximating regression residuals <code>e</code>
with an AR(<code class="reqn">p</code>) model using function <code><a href="#topic+ARest">ARest</a></code>,
where the autoregressive coefficients are estimated with <code>ar.method</code>,
and order <code class="reqn">p</code> is selected based on <code>ar.order</code> and <code>BIC</code> settings
(see <code><a href="#topic+ARest">ARest</a></code>). At the next step, <code>B</code> autoregressive processes
are simulated under the null hypothesis of no change points.
The distribution of test statistics <code class="reqn">M_T</code> computed on each of those
bootstrapped series is used to obtain bootstrap-based <code class="reqn">p</code>-values for the test
(Lyubchich et al. 2020).
</p>
<p>In the current implementation, the bootstrapped <code class="reqn">p</code>-value is calculated using equation 4.10 of
Davison and Hinkley (1997): <code>p.value</code> = (1 + <code class="reqn">n</code>) / (<code>B</code> + 1),
where <code class="reqn">n</code> is number of bootstrapped statistics greater or equal to the observed statistic.
</p>
<p>The test statistic corresponds to the maximal value of the modified CUSUM over
up to <code>m</code> combinations of hypothesized change points specified in <code>k</code>. The change
points that correspond to that maximum are reported in <code>estimate$khat</code>,
and their number is reported as the <code>parameter</code>.
</p>


<h3>Value</h3>

<p>A list of class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>name of the method.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>obseved value of the test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p><code>mhat</code> is the final number of change points,
from those specified in the input <code>k</code>,
for which the test statistic is reported.
See the corresponding locations, <code>khat</code>, in the <code>estimate</code>.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>bootstrapped <code class="reqn">p</code>-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>list with elements: <code>AR_order</code> and
<code>AR_coefficients</code> (the autoregressive order and estimated autoregressive
coefficients used in sieve bootstrap procedure), <code>khat</code> (final change points,
from those specified in the input <code>k</code> for which the test statistic is reported),
and <code>B</code> (the number of bootstrap replications).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Davison AC, Hinkley DV (1997).
<em>Bootstrap Methods and Their Application</em>.
Cambridge University Press, Cambridge.<br /><br /> Horvath L, Pouliot W, Wang S (2017).
&ldquo;Detecting at-most-<code class="reqn">m</code> changes in linear regression models.&rdquo;
<em>Journal of Time Series Analysis</em>, <b>38</b>, 552&ndash;590.
<a href="https://doi.org/10.1111/jtsa.12228">doi:10.1111/jtsa.12228</a>.<br /><br /> Lyubchich V, Lebedeva TV, Testa JM (2020).
&ldquo;A data-driven approach to detecting change points in linear regression models.&rdquo;
<em>Environmetrics</em>, <b>31</b>(1), e2591.
<a href="https://doi.org/10.1002/env.2591">doi:10.1002/env.2591</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##### Model 1 with normal errors, by Horvath et al. (2017)
T &lt;- 100 #length of time series
X &lt;- rnorm(T, mean = 1, sd = 1)
E &lt;- rnorm(T, mean = 0, sd = 1)
SizeOfChange &lt;- 1
TimeOfChange &lt;- 50
Y &lt;- c(1 * X[1:TimeOfChange] + E[1:TimeOfChange],
      (1 + SizeOfChange)*X[(TimeOfChange + 1):T] + E[(TimeOfChange + 1):T])
ehat &lt;- lm(Y ~ X)$resid
mcusum_test(ehat, k = c(30, 50, 70))

#Same, but with bootstrapped innovations obtained from a kernel smoothed distribution:
mcusum_test(ehat, k = c(30, 50, 70), ksm = TRUE)

</code></pre>

<hr>
<h2 id='mcusum.test-defunct'>Change Point Test for Regression</h2><span id='topic+mcusum.test-defunct'></span>

<h3>Description</h3>

<p>Change Point Test for Regression
</p>


<h3>See Also</h3>

<p><code><a href="#topic+funtimes-defunct">funtimes-defunct</a></code>
</p>

<hr>
<h2 id='notrend_test'>Sieve Bootstrap Based Test for the Null Hypothesis of no Trend</h2><span id='topic+notrend_test'></span>

<h3>Description</h3>

<p>A combination of time series trend tests for testing the null hypothesis of no trend,
versus the alternative hypothesis of a linear trend (Student's t-test),
or monotonic trend (Mann&ndash;Kendall test), or more general,
possibly non-monotonic trend (WAVK test).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>notrend_test(
  x,
  B = 1000,
  test = c("t", "MK", "WAVK"),
  ar.method = "HVK",
  ar.order = NULL,
  ic = "BIC",
  factor.length = c("user.defined", "adaptive.selection"),
  Window = NULL,
  q = 3/4,
  j = c(8:11)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="notrend_test_+3A_x">x</code></td>
<td>
<p>a vector containing a univariate time series. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_b">B</code></td>
<td>
<p>number of bootstrap simulations to obtain empirical critical values.
Default is 1000.</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_test">test</code></td>
<td>
<p>trend test to implement: Student's t-test (<code>"t"</code>, default),
Mann&ndash;Kendall test (<code>"MK"</code>), or
WAVK test (<code>"WAVK"</code>, see <code><a href="#topic+WAVK">WAVK</a></code>).</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_ar.method">ar.method</code></td>
<td>
<p>method of estimating autoregression coefficients.
Default <code>"HVK"</code> delivers robust difference-based estimates by
Hall and Van Keilegom (2003). Alternatively,
options of <code>ar</code> function can be used, such as <code>"burg"</code>,
<code>"ols"</code>, <code>"mle"</code>, and <code>"yw"</code>.</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_ar.order">ar.order</code></td>
<td>
<p>order of the autoregressive model when <code>ic = "none"</code>, or
the maximal order for IC-based filtering. Default is
<code>round(10*log10(length(x)))</code>, where <code>x</code> is the time series.</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_ic">ic</code></td>
<td>
<p>information criterion used to select the order of autoregressive filter (AIC of BIC),
considering models of orders <code class="reqn">p=</code> 0,1,...,<code>ar.order</code>.
If <code>ic = "none"</code>, the AR(<code class="reqn">p</code>) model with <code class="reqn">p=</code> <code>ar.order</code> is used,
without order selection.</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_factor.length">factor.length</code></td>
<td>
<p>method to define the length of local windows (factors).
Used only if <code>test = "WAVK"</code>. Default option <code>"user.defined"</code> allows
to set only one value of the argument <code>Window</code>. The option
<code>"adaptive.selection"</code> sets <code>method = "boot"</code> and employs
heuristic <code class="reqn">m</code>-out-of-<code class="reqn">n</code> subsampling algorithm
(Bickel and Sakov 2008) to select an optimal window from the set
of possible windows <code>length(x)*q^j</code> whose values are mapped to the largest
previous integer and greater than 2. Vector <code>x</code> is the time series tested.</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_window">Window</code></td>
<td>
<p>length of the local window (factor), default is
<code>round(0.1*length(x))</code>. Used only if <code>test = "WAVK"</code>.
This argument is ignored if<br /> <code>factor.length = "adaptive.selection"</code>.</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_q">q</code></td>
<td>
<p>scalar from 0 to 1 to define the set of possible windows when
<code>factor.length =</code> <code>"adaptive.selection"</code>.
Used only if <code>test = "WAVK"</code>. Default is <code class="reqn">3/4</code>.
This argument is ignored if <code>factor.length =</code> <code>"user.defined"</code>.</p>
</td></tr>
<tr><td><code id="notrend_test_+3A_j">j</code></td>
<td>
<p>numeric vector to define the set of possible windows when
<code>factor.length =</code> <code>"adaptive.selection"</code>.
Used only if <code>test = "WAVK"</code>. Default is <code>c(8:11)</code>.
This argument is ignored if <code>factor.length =</code> <code>"user.defined"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function tests the null hypothesis of no trend
versus different alternatives.
To set some other shape of trend as the null hypothesis, use <code><a href="#topic+wavk_test">wavk_test</a></code>.
Note that <code><a href="#topic+wavk_test">wavk_test</a></code> employs hybrid bootstrap, which is an alternative
to the sieve bootstrap employed by the current function.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>name of the method.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p><code class="reqn">p</code>-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>list with the following elements: employed AR order and estimated
AR coefficients.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>window that was used in WAVK test, included in the output only
if <code>test = "WAVK"</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Bickel PJ, Sakov A (2008).
&ldquo;On the choice of <code class="reqn">m</code> in the <code class="reqn">m</code> out of <code class="reqn">n</code> bootstrap and confidence bounds for extrema.&rdquo;
<em>Statistica Sinica</em>, <b>18</b>(3), 967&ndash;985.<br /><br /> Hall P, Van Keilegom I (2003).
&ldquo;Using difference-based methods for inference in nonparametric regression with time series errors.&rdquo;
<em>Journal of the Royal Statistical Society, Series B (Statistical Methodology)</em>, <b>65</b>(2), 443&ndash;456.
<a href="https://doi.org/10.1111/1467-9868.00395">doi:10.1111/1467-9868.00395</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ar">ar</a></code>, <code><a href="#topic+HVK">HVK</a></code>, <code><a href="#topic+WAVK">WAVK</a></code>,
<code><a href="#topic+wavk_test">wavk_test</a></code>, <code>vignette("trendtests", package = "funtimes")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Fix seed for reproducible simulations:
set.seed(1)

#Simulate autoregressive time series of length n with smooth linear trend:
n &lt;- 200
tsTrend &lt;- 1 + 2*(1:n/n)
tsNoise &lt;- arima.sim(n = n, list(order = c(2, 0, 0), ar = c(0.5, -0.1)))
U &lt;- tsTrend + tsNoise
plot.ts(U)

#Use t-test
notrend_test(U)

#Use Mann--Kendall test and Yule-Walker estimates of the AR parameters
notrend_test(U, test = "MK", ar.method = "yw")

#Use WAVK test for the H0 of no trend, with m-out-of-n selection of the local window:
notrend_test(U, test = "WAVK", factor.length = "adaptive.selection")
# Sample output:
##	Sieve-bootstrap WAVK trend test
##
##data:  U
##WAVK test statistic = 21.654, moving window = 15, p-value &lt; 2.2e-16
##alternative hypothesis: (non-)monotonic trend.
##sample estimates:
##$AR_order
##[1] 1
##
##$AR_coefficients
##    phi_1
##0.4041848

## End(Not run)

</code></pre>

<hr>
<h2 id='notrend.test-defunct'>Sieve Bootstrap Based Test for the Null Hypothesis of no Trend</h2><span id='topic+notrend.test-defunct'></span>

<h3>Description</h3>

<p>Sieve Bootstrap Based Test for the Null Hypothesis of no Trend
</p>


<h3>See Also</h3>

<p><code><a href="#topic+funtimes-defunct">funtimes-defunct</a></code>
</p>

<hr>
<h2 id='purity'>Clustering Purity</h2><span id='topic+purity'></span>

<h3>Description</h3>

<p>Calculate the purity of the clustering results. For example, see
Schaeffer et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>purity(classes, clusters)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="purity_+3A_classes">classes</code></td>
<td>
<p>a vector with labels of true classes.</p>
</td></tr>
<tr><td><code id="purity_+3A_clusters">clusters</code></td>
<td>
<p>a vector with labels of assigned clusters for which purity is to
be tested. Should be of the same length as <code>classes</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following Manning et al. (2008),
each cluster is assigned to the class which is most frequent in the cluster, then
</p>
<p style="text-align: center;"><code class="reqn">Purity(\Omega,C) = \frac{1}{N}\sum_{k}\max_{j}|\omega_k\cap c_j|,</code>
</p>

<p>where  <code class="reqn">\Omega=\{\omega_1,\ldots,\omega_K \}</code> is the set of identified
clusters and <code class="reqn">C=\{c_1,\ldots,c_J\}</code> is the set of classes. That is, within
each class <code class="reqn">j=1,\ldots,J</code> find the size of the most populous cluster from
the <code class="reqn">K-j</code> unassigned clusters. Then, sum together the <code class="reqn">\min(K,J)</code> sizes
found and divide by <code class="reqn">N</code>,
where <code class="reqn">N</code> = <code>length(classes)</code> = <code>length(clusters)</code>.
</p>
<p>If <code class="reqn">\max_{j}|\omega_k\cap c_j|</code> is not unique for some <code class="reqn">j</code>,
it is assigned to the class which the second maximum is the smallest, to
maximize the <code class="reqn">Purity</code> (see &lsquo;Examples&rsquo;).
</p>
<p>The number of unique elements
in <code>classes</code> and <code>clusters</code> may differ.
</p>


<h3>Value</h3>

<p>A list with two elements:
</p>
<table>
<tr><td><code>pur</code></td>
<td>
<p>purity value.</p>
</td></tr>
<tr><td><code>out</code></td>
<td>
<p>table with <code class="reqn">\min(K,J)</code> = <code>min(length(unique(classes)), 
length(unique(clusters)))</code> rows and the following columns:
<code>ClassLabels</code>, <code>ClusterLabels</code>, and <code>ClusterSize</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Manning CD, Raghavan P, Schutze H (2008).
<em>Introduction to Information Retrieval</em>.
Cambridge University Press, New York.<br /><br /> Schaeffer ED, Testa JM, Gel YR, Lyubchich V (2016).
&ldquo;On information criteria for dynamic spatio-temporal clustering.&rdquo;
In Banerjee A, Ding W, Dy JG, Lyubchich V, Rhines A (eds.), <em>The 6th International Workshop on Climate Informatics: CI2016</em>, 5&ndash;8.
<a href="https://doi.org/10.5065/D6K072N6">doi:10.5065/D6K072N6</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fix seed for reproducible simulations:
# RNGkind(sample.kind = "Rounding") #run this line to have same seed across R versions &gt; R 3.6.0
set.seed(1)

##### Example 1
#Create some classes and cluster labels:
classes &lt;- rep(LETTERS[1:3], each = 5)
clusters &lt;- sample(letters[1:5], length(classes), replace = TRUE)

#From the table below:
# - cluster 'b' corresponds to class A;
# - either of the clusters 'd' and 'e' can correspond to class B,
#   however, 'e' should be chosen, because cluster 'd' also highly 
#   intersects with Class C. Thus,
# - cluster 'd' corresponds to class C.
table(classes, clusters)
##       clusters
##classes a b c d e
##      A 0 3 1 0 1
##      B 1 0 0 2 2
##      C 1 2 0 2 0

#The function does this choice automatically:
purity(classes, clusters)

#Sample output:
##$pur
##[1] 0.4666667
##
##$out
##  ClassLabels ClusterLabels ClusterSize
##1           A             b           3
##2           B             e           2
##3           C             d           2


##### Example 2
#The labels can be also numeric:
classes &lt;- rep(1:5, each = 3)
clusters &lt;- sample(1:3, length(classes), replace = TRUE)
purity(classes, clusters)

</code></pre>

<hr>
<h2 id='q.tails-defunct'>Quantile-Based Tails Comparison</h2><span id='topic+q.tails-defunct'></span>

<h3>Description</h3>

<p>Quantile-Based Tails Comparison
</p>


<h3>See Also</h3>

<p><code><a href="#topic+funtimes-defunct">funtimes-defunct</a></code>
</p>

<hr>
<h2 id='sync_cluster'>Time Series Clustering based on Trend Synchronism</h2><span id='topic+sync_cluster'></span>

<h3>Description</h3>

<p>Cluster time series with a common parametric trend using the
<code><a href="#topic+sync_test">sync_test</a></code> function
(Lyubchich and Gel 2016; Ghahari et al. 2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sync_cluster(formula, rate = 1, alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sync_cluster_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;<code><a href="stats.html#topic+formula">formula</a></code>&quot;,
specifying the type of common trend
for clustering the time series in a <code class="reqn">T</code> by <code class="reqn">N</code> matrix of time series
(time series in columns) which is passed to <code><a href="#topic+sync_test">sync_test</a></code>.
Variable <code class="reqn">t</code> should be used to specify the form
of the trend, where <code class="reqn">t</code> is specified within the function automatically as a
regular sequence of length <code class="reqn">T</code> on the interval (0,1]. See <code>Examples</code>.</p>
</td></tr>
<tr><td><code id="sync_cluster_+3A_rate">rate</code></td>
<td>
<p>rate of removal of time series. Default is 1 (i.e., if the hypothesis
of synchronism is rejected one time series is removed at a time to re-test the
remaining time series). Integer values above 1 are treated as the number of time
series to be removed. Values from 0 to 1 are treated as a fraction of the
time series to be removed.</p>
</td></tr>
<tr><td><code id="sync_cluster_+3A_alpha">alpha</code></td>
<td>
<p>significance level for testing the hypothesis of a common trend
(using <code><a href="#topic+sync_test">sync_test</a></code>) of the parametric form specified in the <code>formula</code>.</p>
</td></tr>
<tr><td><code id="sync_cluster_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code><a href="#topic+sync_test">sync_test</a></code>, for example,
number of bootstrap replications (<code>B</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>sync_cluster</code> function recursively clusters time series having
a pre-specified common parametric trend until there is no time series left.
Starting with the given <code class="reqn">N</code> time series, the <code><a href="#topic+sync_test">sync_test</a></code> function
is used to test for a common trend. If the null hypothesis of common trend is not
rejected by <code><a href="#topic+sync_test">sync_test</a></code>, the time series are grouped
(i.e., assigned to a cluster). Otherwise, the time series with the largest
contribution to the test statistics are temporarily removed (the number of time
series to remove depends on the <code>rate</code> of removal), and <code><a href="#topic+sync_test">sync_test</a></code>
is applied again. The contribution to the test statistic is assessed by the
WAVK test statistic calculated for each time series.
</p>


<h3>Value</h3>

<p>A list with the elements:
</p>
<table>
<tr><td><code>cluster</code></td>
<td>
<p>an integer vector indicating the cluster to which each time series is
allocated. A label <code>'0'</code> is assigned to time series which do not have a common trend
with other time series (that is, all time series labeled with <code>'0'</code> are separate
one-element clusters).</p>
</td></tr>
<tr><td><code>elements</code></td>
<td>
<p>a list with names of the time series in each cluster.</p>
</td></tr>
</table>
<p>The further elements combine results of <code><a href="#topic+sync_test">sync_test</a></code> for each cluster with
at least two elements (that is, single-element clusters labeled with
<code>'0'</code> are excluded):
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>a list with common parametric trend estimates obtained by
<code><a href="#topic+sync_test">sync_test</a></code> for each cluster.
The length of this list is <code>max(cluster)</code>.</p>
</td></tr>
<tr><td><code>pval</code></td>
<td>
<p>a list of <code class="reqn">p</code>-values of <code><a href="#topic+sync_test">sync_test</a></code> for each cluster.
The length of this list is <code>max(cluster)</code>.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>a list with values of <code><a href="#topic+sync_test">sync_test</a></code> test statistic for
each cluster. The length of this list is <code>max(cluster)</code>.</p>
</td></tr>
<tr><td><code>ar_order</code></td>
<td>
<p>a list of AR filter orders used in <code><a href="#topic+sync_test">sync_test</a></code> for each
time series. The results are grouped by cluster in the list of length <code>max(cluster)</code>.</p>
</td></tr>
<tr><td><code>window_used</code></td>
<td>
<p>a list of local windows used in <code><a href="#topic+sync_test">sync_test</a></code> for each
time series. The results are grouped by cluster in the list of length <code>max(cluster)</code>.</p>
</td></tr>
<tr><td><code>all_considered_windows</code></td>
<td>
<p>a list of all windows considered in
<code><a href="#topic+sync_test">sync_test</a></code> and corresponding test results, for each cluster.
The length of this list is <code>max(cluster)</code>.</p>
</td></tr>
<tr><td><code>WAVK_obs</code></td>
<td>
<p>a list of WAVK test statistics obtained in <code><a href="#topic+sync_test">sync_test</a></code>
for each time series.
The results are grouped by cluster in the list of length <code>max(cluster)</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Srishti Vishwakarma, Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Ghahari A, Gel YR, Lyubchich V, Chun Y, Uribe D (2017).
&ldquo;On employing multi-resolution weather data in crop insurance.&rdquo;
In <em>Proceedings of the SIAM International Conference on Data Mining (SDM17) Workshop on Mining Big Data in Climate and Environment (MBDCE 2017)</em>.<br /><br /> Lyubchich V, Gel YR (2016).
&ldquo;A local factor nonparametric test for trend synchronism in multiple time series.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>150</b>, 91&ndash;104.
<a href="https://doi.org/10.1016/j.jmva.2016.05.004">doi:10.1016/j.jmva.2016.05.004</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BICC">BICC</a></code>, <code><a href="#topic+DR">DR</a></code>, <code><a href="#topic+sync_test">sync_test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Simulate 4 autoregressive time series, 
## 3 having a linear trend and 1 without a trend:
set.seed(123)
T = 100 #length of time series
N = 4 #number of time series
X = sapply(1:N, function(x) arima.sim(n = T, 
           list(order = c(1, 0, 0), ar = c(0.6))))
X[,1] &lt;- 5 * (1:T)/T + X[,1]
plot.ts(X)

# Finding clusters with common linear trends:
LinTrend &lt;- sync_cluster(X ~ t) 
  
## Sample Output:
##[1] "Cluster labels:"
##[1] 0 1 1 1
##[1] "Number of single-element clusters (labeled with '0'): 1"

## plotting the time series of the cluster obtained
for(i in 1:max(LinTrend$cluster)) {
    plot.ts(X[, LinTrend$cluster == i], 
            main = paste("Cluster", i))
}


## Simulating 7 autoregressive time series, 
## where first 4 time series have a linear trend added 
set.seed(234)
T = 100 #length of time series
a &lt;- sapply(1:4, function(x) -10 + 0.1 * (1:T) + 
            arima.sim(n = T, list(order = c(1, 0, 0), ar = c(0.6))))
b &lt;- sapply(1:3, function(x) arima.sim(n = T, 
            list(order = c(1, 0, 0), ar = c(0.6))))
Y &lt;- cbind(a, b)
plot.ts(Y)

## Clustering based on linear trend with rate of removal = 2 
# and confidence level for the synchronism test 90%
LinTrend7 &lt;- sync_cluster(Y ~ t, rate = 2, alpha = 0.1, B = 99)
   
## Sample output:
##[1] "Cluster labels:"
##[1] 1 1 1 0 2 0 2
##[1] "Number of single-element clusters (labeled with '0'): 2"

## End(Not run)

</code></pre>

<hr>
<h2 id='sync_test'>Time Series Trend Synchronicity Test</h2><span id='topic+sync_test'></span>

<h3>Description</h3>

<p>Nonparametric test for synchronicity of parametric trends in multiple time series
(Lyubchich and Gel 2016).
The method tests whether <code class="reqn">N</code> observed time series exhibit the same trend
of some pre-specified smooth parametric form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sync_test(
  formula,
  B = 1000,
  Window = NULL,
  q = NULL,
  j = NULL,
  ar.order = NULL,
  ar.method = "HVK",
  ic = "BIC"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sync_test_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;<code><a href="stats.html#topic+formula">formula</a></code>&quot;,
specifying the form of the common parametric time trend to be tested
in a <code class="reqn">T</code> by <code class="reqn">N</code> matrix of time series
(time series in columns). Variable <code class="reqn">t</code> should be used to specify the form of
the trend, where <code class="reqn">t</code> is specified within the function as a regular sequence
on the interval (0,1]. See &lsquo;Examples&rsquo;.</p>
</td></tr>
<tr><td><code id="sync_test_+3A_b">B</code></td>
<td>
<p>number of bootstrap simulations to obtain empirical critical values.
Default is 1000.</p>
</td></tr>
<tr><td><code id="sync_test_+3A_window">Window</code></td>
<td>
<p>scalar or <code class="reqn">N</code>-vector with lengths of the local windows (factors).
If only one value is set, the same <code>Window</code> is applied to each time series.
An <code class="reqn">N</code>-vector gives a specific window for each time series.
If <code>Window</code> is not specified, an automatic algorithm for optimal
window selection is applied as a default option (see &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sync_test_+3A_q">q</code></td>
<td>
<p>scalar from 0 to 1 to define the set of possible windows <code>T*q^j</code>
and to automatically select an optimal window for each time series.
Default is <code class="reqn">3/4</code>. This argument is ignored if the <code>Window</code> is set by the user.</p>
</td></tr>
<tr><td><code id="sync_test_+3A_j">j</code></td>
<td>
<p>numeric vector to define the set of possible windows <code>T*q^j</code>
and to automatically select an optimal window for each time series.
Default is <code>c(8:11)</code>. This argument is ignored if the <code>Window</code> is set by the user.</p>
</td></tr>
<tr><td><code id="sync_test_+3A_ar.order">ar.order</code></td>
<td>
<p>order of the autoregressive filter when <code>ic = "none"</code>,
or the maximal order for IC-based filtering. Default is <code>round(10*log10(T))</code>.
The <code>ar.order</code> can be a scalar or <code class="reqn">N</code>-vector. If scalar, the same
<code>ar.order</code> is applied to each time series. An <code class="reqn">N</code>-vector specifies
a separate <code>ar.order</code> for each time series.</p>
</td></tr>
<tr><td><code id="sync_test_+3A_ar.method">ar.method</code></td>
<td>
<p>method of estimating autoregression coefficients.
Default <code>"HVK"</code> delivers robust difference-based estimates by
Hall and Van Keilegom (2003). Alternatively,
options of <code>ar</code> function can be used, such as <code>"burg"</code>,
<code>"ols"</code>, <code>"mle"</code>, and <code>"yw"</code>.</p>
</td></tr>
<tr><td><code id="sync_test_+3A_ic">ic</code></td>
<td>
<p>information criterion used to select the order of autoregressive filter (AIC of BIC),
considering models of orders <code class="reqn">p=</code> 0,1,...,<code>ar.order</code>.
If <code>ic = "none"</code>, the AR(<code class="reqn">p</code>) model with <code class="reqn">p=</code> <code>ar.order</code> is used,
without order selection.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Arguments <code>Window</code>, <code>j</code>, and <code>q</code> are used to set windows
for the local regression. Current version of the function assumes two options:
(1) user specifies one fixed window for each time series using the argument
<code>Window</code> (if <code>Window</code> is set, <code>j</code> and <code>q</code> are ignored),
and (2) user specifies a set of windows by <code>j</code> and <code>q</code> to apply
this set to each time series and to select an optimal window using a heuristic
<code class="reqn">m</code>-out-of-<code class="reqn">n</code> subsampling algorithm (Bickel and Sakov 2008).
The option of selecting windows automatically for some of the time series,
while for other time series the window is fixed, is not available yet.
If none of these three arguments is set, default <code>j</code> and <code>q</code> are used.
Values <code>T*q^j</code> are mapped to the largest previous integer, then only
those greater than 2 are used.
</p>
<p>See more details in Lyubchich and Gel (2016)
and Lyubchich (2016).
</p>


<h3>Value</h3>

<p>A list of class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>name of the method.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p><code class="reqn">p</code>-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>list with elements <code>common_trend_estimates</code>,
<code>ar_order_used</code>, <code>Window_used</code>, <code>wavk_obs</code>, and
<code>all_considered_windows</code>. The latter is a table with bootstrap and
asymptotic test results for all considered windows, that is, without adaptive
selection of the local window.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yulia R. Gel, Vyacheslav Lyubchich, Ethan Schaeffer, Xingyu Wang
</p>


<h3>References</h3>

<p>Bickel PJ, Sakov A (2008).
&ldquo;On the choice of <code class="reqn">m</code> in the <code class="reqn">m</code> out of <code class="reqn">n</code> bootstrap and confidence bounds for extrema.&rdquo;
<em>Statistica Sinica</em>, <b>18</b>(3), 967&ndash;985.<br /><br /> Hall P, Van Keilegom I (2003).
&ldquo;Using difference-based methods for inference in nonparametric regression with time series errors.&rdquo;
<em>Journal of the Royal Statistical Society, Series B (Statistical Methodology)</em>, <b>65</b>(2), 443&ndash;456.
<a href="https://doi.org/10.1111/1467-9868.00395">doi:10.1111/1467-9868.00395</a>.<br /><br /> Lyubchich V (2016).
&ldquo;Detecting time series trends and their synchronization in climate data.&rdquo;
<em>Intelligence. Innovations. Investments</em>, <b>12</b>, 132&ndash;137.<br /><br /> Lyubchich V, Gel YR (2016).
&ldquo;A local factor nonparametric test for trend synchronism in multiple time series.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>150</b>, 91&ndash;104.
<a href="https://doi.org/10.1016/j.jmva.2016.05.004">doi:10.1016/j.jmva.2016.05.004</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ar">ar</a></code>, <code><a href="#topic+HVK">HVK</a></code>, <code><a href="#topic+WAVK">WAVK</a></code>,
<code><a href="#topic+wavk_test">wavk_test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Fix seed for reproducible simulations:
set.seed(1)

# Simulate two autoregressive time series of length n without trend
#(i.e., with zero or constant trend)
# and arrange the series into a matrix:
n &lt;- 200
y1 &lt;- arima.sim(n = n, list(order = c(1, 0, 0), ar = c(0.6)))
y2 &lt;- arima.sim(n = n, list(order = c(1, 0, 0), ar = c(-0.2)))
Y &lt;- cbind(y1, y2)
plot.ts(Y)


#Test H0 of a common linear trend:
## Not run: 
    sync_test(Y ~ t, B = 500)

## End(Not run)
# Sample output:
##	Nonparametric test for synchronism of parametric trends
##
##data:  Y
##Test statistic = -0.0028999, p-value = 0.7
##alternative hypothesis: common trend is not of the form Y ~ t.
##sample estimates:
##$common_trend_estimates
##               Estimate Std. Error    t value  Pr(&gt;|t|)
##(Intercept) -0.02472566  0.1014069 -0.2438261 0.8076179
##t            0.04920529  0.1749859  0.2811958 0.7788539
##
##$ar.order_used
##         y1 y2
##ar.order  1  1
##
##$Window_used
##       y1 y2
##Window 15  8
##
##$all_considered_windows
## Window    Statistic p-value Asympt. p-value
##      8 -0.000384583   0.728       0.9967082
##     11 -0.024994408   0.860       0.7886005
##     15 -0.047030164   0.976       0.6138976
##     20 -0.015078579   0.668       0.8714980
##
##$wavk_obs
##[1]  0.05827148 -0.06117136

# Add a time series y3 with a different linear trend and re-apply the test:
y3 &lt;- 1 + 3*((1:n)/n) + arima.sim(n = n, list(order = c(1, 0, 0), ar = c(-0.2)))
Y2 &lt;- cbind(Y, y3)
plot.ts(Y2)
## Not run: 
    sync_test(Y2 ~ t, B = 500)
## End(Not run)
# Sample output:
##	Nonparametric test for synchronism of parametric trends
##
##data:  Y2
##Test statistic = 0.48579, p-value &lt; 2.2e-16
##alternative hypothesis: common trend is not of the form Y2 ~ t.
##sample estimates:
##$common_trend_estimates
##              Estimate Std. Error  t value     Pr(&gt;|t|)
##(Intercept) -0.3632963 0.07932649 -4.57976 8.219360e-06
##t            0.7229777 0.13688429  5.28167 3.356552e-07
##
##$ar.order_used
##         Y.y1 Y.y2 y3
##ar.order    1    1  0
##
##$Window_used
##       Y.y1 Y.y2 y3
##Window    8   11  8
##
##$all_considered_windows
## Window Statistic p-value Asympt. p-value
##      8 0.4930069       0    1.207378e-05
##     11 0.5637067       0    5.620248e-07
##     15 0.6369703       0    1.566057e-08
##     20 0.7431621       0    4.201484e-11
##
##$wavk_obs
##[1]  0.08941797 -0.07985614  0.34672734

#Other hypothesized trend forms can be specified, for example:
## Not run: 
    sync_test(Y ~ 1) #constant trend
    sync_test(Y ~ poly(t, 2)) #quadratic trend
    sync_test(Y ~ poly(t, 3)) #cubic trend

## End(Not run)

</code></pre>

<hr>
<h2 id='sync.cluster-defunct'>Time Series Clustering based on Trend Synchronism</h2><span id='topic+sync.cluster-defunct'></span>

<h3>Description</h3>

<p>Time Series Clustering based on Trend Synchronism
</p>


<h3>See Also</h3>

<p><code><a href="#topic+funtimes-defunct">funtimes-defunct</a></code>
</p>

<hr>
<h2 id='sync.test-defunct'>Time Series Trend Synchronism Test</h2><span id='topic+sync.test-defunct'></span>

<h3>Description</h3>

<p>Time Series Trend Synchronism Test
</p>


<h3>See Also</h3>

<p><code><a href="#topic+funtimes-defunct">funtimes-defunct</a></code>
</p>

<hr>
<h2 id='tails_i'>Interval-Based Tails Comparison</h2><span id='topic+tails_i'></span>

<h3>Description</h3>

<p>Compare right tails of two sample distributions using
an interval-based approach (IBA);
see Chu et al. (2015)
and Lyubchich and Gel (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tails_i(x0, x1, d = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tails_i_+3A_x0">x0</code>, <code id="tails_i_+3A_x1">x1</code></td>
<td>
<p>vectors of the same length (preferably).
Tail in <code>x1</code> is compared against the tail in <code>x0</code>.</p>
</td></tr>
<tr><td><code id="tails_i_+3A_d">d</code></td>
<td>
<p>a threshold defining the tail. The threshold is the same for both
<code>x0</code> and <code>x1</code>. Default is <code>quantile(x0, probs = 0.99)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sturges' formula is used to calculate the number of intervals
(<code class="reqn">k</code>) for <code>x0</code> <code class="reqn">\ge</code> <code>d</code>, then interval width is derived.
The tails, <code>x0</code> <code class="reqn">\ge</code> <code>d</code> and <code>x1</code> <code class="reqn">\ge</code> <code>d</code>,
are divided into intervals. The number of <code>x1</code>-values within each interval
is compared with the number of <code>x0</code>-values within the same interval
(this difference is reported as <code>Nk</code>).
</p>


<h3>Value</h3>

<p>A list with two elements:
</p>
<table>
<tr><td><code>Nk</code></td>
<td>
<p>vector that tells how many more <code>x1</code>-values compared with
<code>x0</code>-values there are within each interval.</p>
</td></tr>
<tr><td><code>Ck</code></td>
<td>
<p>vector of the intervals' centers.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Calvin Chu, Yulia R. Gel, Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Chu C, Gel YR, Lyubchich V (2015).
&ldquo;Climate change from an insurance perspective: a case study of Norway.&rdquo;
In Dy JG, Emile-Geay J, Lakshmanan V, Liu Y (eds.), <em>The 5th International Workshop on Climate Informatics: CI2015</em>.<br /><br /> Lyubchich V, Gel YR (2017).
&ldquo;Can we weather proof our insurance?&rdquo;
<em>Environmetrics</em>, <b>28</b>(2), e2433.
<a href="https://doi.org/10.1002/env.2433">doi:10.1002/env.2433</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+q.tails">q.tails</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x0 &lt;- rnorm(1000)
x1 &lt;- rt(1000, 5)
tails_i(x0, x1)

</code></pre>

<hr>
<h2 id='tails_q'>Quantile-Based Tails Comparison</h2><span id='topic+tails_q'></span>

<h3>Description</h3>

<p>Compare right tails of two sample distributions using
a quantile-based approach (QBA);
see Soliman et al. (2014),
Soliman et al. (2015),
and Lyubchich and Gel (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tails_q(x0, x1, q = 0.99)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tails_q_+3A_x0">x0</code>, <code id="tails_q_+3A_x1">x1</code></td>
<td>
<p>vectors of the same length (preferably).
Tail in <code>x1</code> is compared against the tail in <code>x0</code>.</p>
</td></tr>
<tr><td><code id="tails_q_+3A_q">q</code></td>
<td>
<p>a quantile defining the right tail for both <code>x0</code> and <code>x1</code>.
Values above the  thresholds <code>quantile(x0, probs = q)</code> and
<code>quantile(x1, probs = q)</code> are considered as the respective right tails.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sturges' formula is used to calculate the number of intervals (<code class="reqn">k</code>)
to split the upper <code class="reqn">100(1 - q)</code>\
(the right tails). Then, each tail is divided into equally-filled intervals
with a quantile step <code class="reqn">d=(1 - q)/k</code>. <code>Pk</code> reports the difference between
corresponding intervals' centers obtained from <code>x0</code> and <code>x1</code>.
</p>


<h3>Value</h3>

<p>A list with two elements:
</p>
<table>
<tr><td><code>d</code></td>
<td>
<p>the step in probabilities for defining the quantiles.</p>
</td></tr>
<tr><td><code>Pk</code></td>
<td>
<p>vector of differences of the intervals' centers.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Vyacheslav Lyubchich, Yulia R. Gel
</p>


<h3>References</h3>

<p>Lyubchich V, Gel YR (2017).
&ldquo;Can we weather proof our insurance?&rdquo;
<em>Environmetrics</em>, <b>28</b>(2), e2433.
<a href="https://doi.org/10.1002/env.2433">doi:10.1002/env.2433</a>.<br /><br /> Soliman M, Lyubchich V, Gel YR, Naser D, Esterby S (2015).
&ldquo;Evaluating the impact of climate change on dynamics of house insurance claims.&rdquo;
In Lakshmanan V, Gilleland E, McGovern A, Tingley M (eds.), <em>Machine Learning and Data Mining Approaches to Climate Science</em>, chapter 16, 175&ndash;183.
Springer, Switzerland.
<a href="https://doi.org/10.1007/978-3-319-17220-0_16">doi:10.1007/978-3-319-17220-0_16</a>.<br /><br /> Soliman M, Naser D, Lyubchich V, Gel YR, Esterby S (2014).
&ldquo;Evaluating the impact of climate change on dynamics of house insurance claims.&rdquo;
In Ebert-Uphoff I (ed.), <em>The 4th International Workshop on Climate Informatics: CI2014</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+i.tails">i.tails</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x0 &lt;- rnorm(1000)
x1 &lt;- rt(1000, 5)
tails_q(x0, x1)

</code></pre>

<hr>
<h2 id='WAVK'>WAVK Statistic</h2><span id='topic+WAVK'></span>

<h3>Description</h3>

<p>Statistic for testing the parametric form of a regression function,
suggested by Wang et al. (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WAVK(z, kn = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WAVK_+3A_z">z</code></td>
<td>
<p>filtered univariate time series
(see formula (2.1) by Wang and Van Keilegom 2007):
</p>
<p style="text-align: center;"><code class="reqn">Z_i=\left(Y_{i+p}-\sum_{j=1}^p{\hat{\phi}_{j,n}Y_{i+p-j}} \right)-
\left( f(\hat{\theta},t_{i+p})-
\sum_{j=1}^p{\hat{\phi}_{j,n}f(\hat{\theta},t_{i+p-j})} \right),</code>
</p>

<p>where <code class="reqn">Y_i</code> is observed time series of length <code class="reqn">n</code>, <code class="reqn">\hat{\theta}</code>
is an estimator of hypothesized parametric trend <code class="reqn">f(\theta, t)</code>,
and <code class="reqn">\hat{\phi}_p=(\hat{\phi}_{1,n}, \ldots, \hat{\phi}_{p,n})'</code>
are estimated coefficients of an autoregressive filter of order <code class="reqn">p</code>.
Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="WAVK_+3A_kn">kn</code></td>
<td>
<p>length of the local window.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with following components:
</p>
<table>
<tr><td><code>Tn</code></td>
<td>
<p>test statistic based on artificial ANOVA and defined
by Wang and Van Keilegom (2007)
as a difference of mean square for treatments (MST) and mean square for errors (MSE):
</p>
<p style="text-align: center;"><code class="reqn">T_n= MST - MSE =\frac{k_{n}}{n-1} \sum_{t=1}^T
\biggl(\overline{V}_{t.}-\overline{V}_{..}\biggr)^2 -
\frac{1}{n(k_{n}-1)} \sum_{t=1}^n \sum_{j=1}^{k_{n}}\biggl(V_{tj}-\overline{V}_{t.}\biggr)^2,</code>
</p>

<p>where <code class="reqn">\{V_{t1}, \ldots, V_{tk_n}\}=\{Z_j: j\in W_{t}\}</code>, <code class="reqn">W_t</code> is a
local window, <code class="reqn">\overline{V}_{t.}</code> and <code class="reqn">\overline{V}_{..}</code> are the mean
of the <code class="reqn">t</code>th group and the grand mean, respectively.</p>
</td></tr>
<tr><td><code>Tns</code></td>
<td>
<p>standardized version of <code>Tn</code> according to
Theorem 3.1 by Wang and Van Keilegom (2007):
</p>
<p style="text-align: center;"><code class="reqn">T_{ns} = \left( \frac{n}{k_n} \right)^{\frac{1}{2}}T_n \bigg/
\left(\frac{4}{3}\right)^{\frac{1}{2}} \sigma^2,</code>
</p>

<p>where <code class="reqn">n</code> is the length and <code class="reqn">\sigma^2</code> is the variance of the time series.
Robust difference-based Rice's estimator (Rice 1984)
is used to estimate <code class="reqn">\sigma^2</code>.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p><code class="reqn">p</code>-value for <code>Tns</code> based on its
asymptotic <code class="reqn">N(0,1)</code> distribution.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yulia R. Gel, Vyacheslav Lyubchich
</p>


<h3>References</h3>

<p>Rice J (1984).
&ldquo;Bandwidth choice for nonparametric regression.&rdquo;
<em>The Annals of Statistics</em>, <b>12</b>(4), 1215&ndash;1230.
<a href="https://doi.org/10.1214/aos/1176346788">doi:10.1214/aos/1176346788</a>.<br /><br /> Wang L, Akritas MG, Van Keilegom I (2008).
&ldquo;An ANOVA-type nonparametric diagnostic test for heteroscedastic regression models.&rdquo;
<em>Journal of Nonparametric Statistics</em>, <b>20</b>(5), 365&ndash;382.<br /><br /> Wang L, Van Keilegom I (2007).
&ldquo;Nonparametric test for the form of parametric regression with time series errors.&rdquo;
<em>Statistica Sinica</em>, <b>17</b>, 369&ndash;386.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wavk_test">wavk_test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z &lt;- rnorm(300)
WAVK(z, kn = 7)

</code></pre>

<hr>
<h2 id='wavk_test'>WAVK Trend Test</h2><span id='topic+wavk_test'></span>

<h3>Description</h3>

<p>Nonparametric test to detect (non-)monotonic parametric trends in time series
(based on Lyubchich et al. 2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wavk_test(
  formula,
  factor.length = c("user.defined", "adaptive.selection"),
  Window = NULL,
  q = 3/4,
  j = c(8:11),
  B = 1000,
  method = c("boot", "asympt"),
  ar.order = NULL,
  ar.method = "HVK",
  ic = "BIC",
  out = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wavk_test_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;<code><a href="stats.html#topic+formula">formula</a></code>&quot;, specifying the
form of the parametric time trend to be tested. Variable <code class="reqn">t</code> should be used
to specify the form, where <code class="reqn">t</code> is specified within the function as a regular
sequence on the interval (0,1]. See <code>Examples</code>.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_factor.length">factor.length</code></td>
<td>
<p>method to define the length of local windows (factors).
Default option<br /> <code>"user.defined"</code> allows setting only one value of the argument
<code>Window</code>. The option <code>"adaptive.selection"</code> sets <code>method = "boot"</code>
and employs heuristic <code class="reqn">m</code>-out-of-<code class="reqn">n</code> subsampling algorithm
(Bickel and Sakov 2008) to select an optimal window from the set
of possible windows <code>length(x)*q^j</code> whose values are mapped to the largest
previous integer and greater than 2. Vector <code>x</code> is the time series tested.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_window">Window</code></td>
<td>
<p>length of the local window (factor), default is
<code>round(0.1*length(x))</code>, where <code>x</code> is the time series tested.
This argument is ignored if<br /> <code>factor.length = "adaptive.selection"</code>.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_q">q</code></td>
<td>
<p>scalar from 0 to 1 to define the set of possible windows when
<code>factor.length =</code> <code>"adaptive.selection"</code>. Default is <code class="reqn">3/4</code>.
This argument is ignored if<br /> <code>factor.length =</code> <code>"user.defined"</code>.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_j">j</code></td>
<td>
<p>numeric vector to define the set of possible windows when
<code>factor.length =</code> <code>"adaptive.selection"</code>. Default is <code>c(8:11)</code>.
This argument is ignored if<br /> <code>factor.length = "user.defined"</code>.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_b">B</code></td>
<td>
<p>number of bootstrap simulations to obtain empirical critical values.
Default is 1000.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_method">method</code></td>
<td>
<p>method of obtaining critical values: from asymptotical (<code>"asympt"</code>)
or bootstrap (<code>"boot"</code>) distribution.
If <code>factor.length =</code> <code>"adaptive.selection"</code> the option <code>"boot"</code> is used.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_ar.order">ar.order</code></td>
<td>
<p>order of the autoregressive model when <code>ic = "none"</code>, or
the maximal order for IC-based filtering. Default is
<code>round(10*log10(length(x)))</code>, where <code>x</code> is the time series.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_ar.method">ar.method</code></td>
<td>
<p>method of estimating autoregression coefficients.
Default <code>"HVK"</code> delivers robust difference-based estimates by
Hall and Van Keilegom (2003). Alternatively,
options of <code>ar</code> function can be used, such as <code>"burg"</code>,
<code>"ols"</code>, <code>"mle"</code>, and <code>"yw"</code>.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_ic">ic</code></td>
<td>
<p>information criterion used to select the order of autoregressive filter (AIC of BIC),
considering models of orders <code class="reqn">p=</code> 0,1,...,<code>ar.order</code>.
If <code>ic = "none"</code>, the AR(<code class="reqn">p</code>) model with <code class="reqn">p=</code> <code>ar.order</code> is used,
without order selection.</p>
</td></tr>
<tr><td><code id="wavk_test_+3A_out">out</code></td>
<td>
<p>logical value indicates whether the full output should be shown.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See more details in Lyubchich and Gel (2016)
and Lyubchich (2016).
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>name of the method.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>name of the data.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p><code class="reqn">p</code>-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>window that was used.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>list with the following elements: estimated trend coefficients;
user-defined or IC-selected AR order; estimated AR coefficients; and,
if <code>factor.length =</code> <code>"adaptive.selection"</code>,
test results for all considered windows.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yulia R. Gel, Vyacheslav Lyubchich, Ethan Schaeffer
</p>


<h3>References</h3>

<p>Bickel PJ, Sakov A (2008).
&ldquo;On the choice of <code class="reqn">m</code> in the <code class="reqn">m</code> out of <code class="reqn">n</code> bootstrap and confidence bounds for extrema.&rdquo;
<em>Statistica Sinica</em>, <b>18</b>(3), 967&ndash;985.<br /><br /> Hall P, Van Keilegom I (2003).
&ldquo;Using difference-based methods for inference in nonparametric regression with time series errors.&rdquo;
<em>Journal of the Royal Statistical Society, Series B (Statistical Methodology)</em>, <b>65</b>(2), 443&ndash;456.
<a href="https://doi.org/10.1111/1467-9868.00395">doi:10.1111/1467-9868.00395</a>.<br /><br /> Lyubchich V (2016).
&ldquo;Detecting time series trends and their synchronization in climate data.&rdquo;
<em>Intelligence. Innovations. Investments</em>, <b>12</b>, 132&ndash;137.<br /><br /> Lyubchich V, Gel YR (2016).
&ldquo;A local factor nonparametric test for trend synchronism in multiple time series.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>150</b>, 91&ndash;104.
<a href="https://doi.org/10.1016/j.jmva.2016.05.004">doi:10.1016/j.jmva.2016.05.004</a>.<br /><br /> Lyubchich V, Gel YR, El-Shaarawi A (2013).
&ldquo;On detecting non-monotonic trends in environmental time series: a fusion of local regression and bootstrap.&rdquo;
<em>Environmetrics</em>, <b>24</b>(4), 209&ndash;226.
<a href="https://doi.org/10.1002/env.2212">doi:10.1002/env.2212</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ar">ar</a></code>, <code><a href="#topic+HVK">HVK</a></code>, <code><a href="#topic+WAVK">WAVK</a></code>,
<code><a href="#topic+sync_test">sync_test</a></code>, <code>vignette("trendtests", package = "funtimes")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fix seed for reproducible simulations:
set.seed(1)

#Simulate autoregressive time series of length n with smooth quadratic trend:
n &lt;- 100
tsTrend &lt;- 1 + 2*(1:n/n) + 4*(1:n/n)^2
tsNoise &lt;- arima.sim(n = n, list(order = c(2, 0, 0), ar = c(-0.7, -0.1)))
U &lt;- tsTrend + tsNoise
plot.ts(U)

#Test H0 of a linear trend, with m-out-of-n selection of the local window:
## Not run: 
    wavk_test(U ~ t, factor.length = "adaptive.selection")
## End(Not run)
# Sample output:
##	Trend test by Wang, Akritas, and Van Keilegom (bootstrap p-values)
##
##data:  U
##WAVK test statistic = 5.3964, adaptively selected window = 4, p-value &lt; 2.2e-16
##alternative hypothesis: trend is not of the form U ~ t.

#Test H0 of a quadratic trend, with m-out-of-n selection of the local window
#and output of all results:
## Not run: 
    wavk_test(U ~ poly(t, 2), factor.length = "adaptive.selection", out = TRUE)
## End(Not run)
# Sample output:
##	Trend test by Wang, Akritas, and Van Keilegom (bootstrap p-values)
##
##data:  U
##WAVK test statistic = 0.40083, adaptively selected window = 4, p-value = 0.576
##alternative hypothesis: trend is not of the form U ~ poly(t, 2).
##sample estimates:
##$trend_coefficients
##(Intercept) poly(t, 2)1 poly(t, 2)2
##   3.408530   17.681422    2.597213
##
##$AR_order
##[1] 1
##
##$AR_coefficients
##         phi_1
##[1] -0.7406163
##
##$all_considered_windows
## Window WAVK-statistic p-value
##      4     0.40083181   0.576
##      5     0.06098625   0.760
##      7    -0.57115451   0.738
##     10    -1.02982929   0.360

# Test H0 of no trend (constant trend) using asymptotic distribution of statistic.
wavk_test(U ~ 1, method = "asympt")
# Sample output:
##	Trend test by Wang, Akritas, and Van Keilegom (asymptotic p-values)
##
##data:  U
##WAVK test statistic = 25.999, user-defined window = 10, p-value &lt; 2.2e-16
##alternative hypothesis: trend is not of the form U ~ 1.

</code></pre>

<hr>
<h2 id='wavk.test-defunct'>WAVK Trend Test</h2><span id='topic+wavk.test-defunct'></span>

<h3>Description</h3>

<p>WAVK Trend Test
</p>


<h3>See Also</h3>

<p><code><a href="#topic+funtimes-defunct">funtimes-defunct</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
