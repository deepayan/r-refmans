<!DOCTYPE html><html><head><title>Help for package tclust</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tclust}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ctlcurves'><p>Classification Trimmed Likelihood Curves</p></a></li>
<li><a href='#DiscrFact'><p>Discriminant Factor analysis for <code>tclust</code> objects</p></a></li>
<li><a href='#geyser2'><p>Old Faithful Geyser Data</p></a></li>
<li><a href='#LG5data'><p>LG5data data</p></a></li>
<li><a href='#M5data'><p>M5data data</p></a></li>
<li><a href='#pine'><p>Pinus nigra dataset</p></a></li>
<li><a href='#plot.ctlcurves'><p>The <code>plot</code> method for objects of class <code>ctlcurves</code></p></a></li>
<li><a href='#plot.DiscrFact'><p>The <code>plot</code> method for objects of class <code>DiscrFact</code></p></a></li>
<li><a href='#plot.rlg'><p>Plot an 'rlg' object</p></a></li>
<li><a href='#plot.tclust'><p>Plot Method for <code>tclust</code> and <code>tkmeans</code> Objects</p></a></li>
<li><a href='#rlg'><p>Robust Linear Grouping</p></a></li>
<li><a href='#simula.rlg'><p>Simulate contaminated data set for applying rlg</p></a></li>
<li><a href='#simula.tclust'><p>Simulate contaminated data set for applying TCLUST</p></a></li>
<li><a href='#summary.DiscrFact'><p>The <code>summary</code> method for objects of class <code>DiscrFact</code></p></a></li>
<li><a href='#swissbank'><p>Swiss banknotes data</p></a></li>
<li><a href='#tclust'><p>TCLUST method for robust clustering</p></a></li>
<li><a href='#tkmeans'><p>TKMEANS method for robust K-means clustering</p></a></li>
<li><a href='#wholesale'><p>Wholesale customers dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Robust Trimmed Clustering</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0-4</td>
</tr>
<tr>
<td>VersionNote:</td>
<td>Released 2.0-3 on 2024-04-17 on CRAN</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Valentin Todorov &lt;valentin.todorov@chello.at&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions for robust trimmed clustering. The methods are 
    described in Garcia-Escudero (2008) &lt;<a href="https://doi.org/10.1214%2F07-AOS515">doi:10.1214/07-AOS515</a>&gt;, 
    Fritz et al. (2012) &lt;<a href="https://doi.org/10.18637%2Fjss.v047.i12">doi:10.18637/jss.v047.i12</a>&gt;, 
    Garcia-Escudero et al. (2011)  &lt;<a href="https://doi.org/10.1007%2Fs11222-010-9194-z">doi:10.1007/s11222-010-9194-z</a>&gt; and others.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.6.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.7), doParallel, parallel, foreach, MASS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mclust, cluster, sn</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/valentint/tclust">https://github.com/valentint/tclust</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/valentint/tclust/issues">https://github.com/valentint/tclust/issues</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Author:</td>
<td>Valentin Todorov <a href="https://orcid.org/0000-0003-4215-0245"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Luis Angel García Escudero [aut],
  Agustín Mayo Iscar [aut],
  Javier Crespo Guerrero [aut],
  Heinrich Fritz [aut]</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-06 16:56:04 UTC; valen</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-09 13:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ctlcurves'>Classification Trimmed Likelihood Curves</h2><span id='topic+ctlcurves'></span><span id='topic+print.ctlcurves'></span>

<h3>Description</h3>

<p>The function applies <code><a href="#topic+tclust">tclust</a></code> several times on a given dataset while parameters 
<code>alpha</code> and <code>k</code> are altered. The resulting object gives an idea of the optimal 
trimming level and number of clusters considering a particular dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctlcurves(
  x,
  k = 1:4,
  alpha = seq(0, 0.2, len = 6),
  restr.fact = 50,
  parallel = FALSE,
  trace = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ctlcurves_+3A_x">x</code></td>
<td>
<p>A matrix or data frame of dimension n x p, containing the observations (row-wise).</p>
</td></tr>
<tr><td><code id="ctlcurves_+3A_k">k</code></td>
<td>
<p>A vector of cluster numbers to be checked. By default cluster numbers from 1 to 5 are examined.</p>
</td></tr>
<tr><td><code id="ctlcurves_+3A_alpha">alpha</code></td>
<td>
<p>A vector containing the alpha levels to be checked. By default <code>alpha</code> 
levels from 0 to 0.2 (continuously increased by 0.01), are checked.</p>
</td></tr>
<tr><td><code id="ctlcurves_+3A_restr.fact">restr.fact</code></td>
<td>
<p>The restriction factor passed to <code><a href="#topic+tclust">tclust</a></code>.</p>
</td></tr>
<tr><td><code id="ctlcurves_+3A_parallel">parallel</code></td>
<td>
<p>A logical value, to be passed further to <code>tclust()</code>.</p>
</td></tr>
<tr><td><code id="ctlcurves_+3A_trace">trace</code></td>
<td>
<p>Defines the tracing level, which is set to <code>1</code> by default. 
Tracing level <code>2</code> gives additional information on the current iteration.</p>
</td></tr>
<tr><td><code id="ctlcurves_+3A_...">...</code></td>
<td>
<p>Further arguments (as e.g. <code>restr</code>), passed to <code><a href="#topic+tclust">tclust</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>These curves show the values of the trimmed classification (log-)likelihoods 
when altering the trimming proportion <code>alpha</code> and the number of clusters <code>k</code>. 
The careful examination of these curves provides valuable information for choosing 
these parameters in a clustering problem. For instance, an appropriate <code>k</code> 
to be chosen is one that we do not observe a clear increase in the trimmed classification 
likelihood curve for k with respect to the k+1 curve for almost all the range 
of alpha values. Moreover, an appropriate choice of parameter alpha may be derived 
by determining where an initial fast increase of the trimmed classification 
likelihood curve stops for the final chosen k. A more detailed explanation can 
be found in García-Escudero et al. (2011).
</p>


<h3>Value</h3>

<p>The function returns an S3 object of type <code>ctlcurves</code> containing the following components:
</p>

<ul>
<li> <p><code>par</code> A list containing all the parameters passed to this function 
</p>
</li>
<li> <p><code>obj</code>  An array containing the objective functions values of each computed cluster-solution 
</p>
</li>
<li> <p><code>min.weights</code> An array containing the minimum cluster weight of each computed cluster-solution 
</p>
</li></ul>



<h3>References</h3>

<p>García-Escudero, L.A.; Gordaliza, A.; Matrán, C. and Mayo-Iscar, A. (2011), 
&quot;Exploring the number of groups in robust model-based clustering.&quot; <em>Statistics and Computing</em>, <b>21</b> 
pp. 585-599, &lt;doi:10.1007/s11222-010-9194-z&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

 #--- EXAMPLE 1 ------------------------------------------

 sig &lt;- diag (2)
 cen &lt;- rep (1, 2)
 x &lt;- rbind(MASS::mvrnorm(108, cen * 0,   sig),
 	       MASS::mvrnorm(162, cen * 5,   sig * 6 - 2),
 	       MASS::mvrnorm(30, cen * 2.5, sig * 50))

 ctl &lt;- ctlcurves(x, k = 1:4)
 ctl

   ##  ctl-curves 
 plot(ctl)  ##  --&gt; selecting k = 2, alpha = 0.08

   ##  the selected model 
 plot(tclust(x, k = 2, alpha = 0.08, restr.fact = 7))

 #--- EXAMPLE 2 ------------------------------------------

 data(geyser2)
 ctl &lt;- ctlcurves(geyser2, k = 1:5)
 ctl
 
   ##  ctl-curves 
 plot(ctl)  ##  --&gt; selecting k = 3, alpha = 0.08

   ##  the selected model
 plot(tclust(geyser2, k = 3, alpha = 0.08, restr.fact = 5))


 #--- EXAMPLE 3 ------------------------------------------
 
 data(swissbank)
 ctl &lt;- ctlcurves(swissbank, k = 1:5, alpha = seq (0, 0.3, by = 0.025))
 ctl
 
   ##  ctl-curves 
 plot(ctl)  ##  --&gt; selecting k = 2, alpha = 0.1
 
   ##  the selected model
 plot(tclust(swissbank, k = 2, alpha = 0.1, restr.fact = 50))
 

## End(Not run)

</code></pre>

<hr>
<h2 id='DiscrFact'>Discriminant Factor analysis for <code>tclust</code> objects</h2><span id='topic+DiscrFact'></span><span id='topic+print.DiscrFact'></span>

<h3>Description</h3>

<p>Analyzes a <code>tclust</code>-object by calculating discriminant factors 
and comparing the quality of the actual cluster assignments to that of the second best 
possible assignment for each observation. Cluster assignments of observations 
with large discriminant factors are considered &quot;doubtful&quot; decisions. Silhouette 
plots give a graphical overview of the discriminant factors distribution 
(see <code><a href="#topic+plot.DiscrFact">plot.DiscrFact</a></code>). More details can be found in García-Escudero et al. (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DiscrFact(x, threshold = 1/10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DiscrFact_+3A_x">x</code></td>
<td>
<p>A <code>tclust</code> object.</p>
</td></tr>
<tr><td><code id="DiscrFact_+3A_threshold">threshold</code></td>
<td>
<p>A cluster assignment or a trimming decision for an observation with a 
discriminant factor larger than <code>log(threshold)</code> is considered a &quot;doubtful&quot; decision.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an S3 object of type <code>DiscrFact</code> containing the following components:
</p>

<ul>
<li> <p><code>x</code> A <code>tclust</code> object. 
</p>
</li>
<li> <p><code>ylimmin</code> A minimum y-limit calculated for plotting purposes. 
</p>
</li>
<li> <p><code>ind</code> The actual cluster assignment. 
</p>
</li>
<li> <p><code>ind2</code> The second most likely cluster assignment for each observation. 
</p>
</li>
<li> <p><code>lik</code> The (weighted) likelihood of the actual cluster assignment of each observation. 
</p>
</li>
<li> <p><code>lik2</code> The (weighted) likelihood of the second best cluster assignment of each observation. 
</p>
</li>
<li> <p><code>assignfact</code> The factor <code>log(disc/disc2)</code>. 
</p>
</li>
<li> <p><code>threshold</code> The threshold used for deciding whether <code>assignfact</code> indicates a &quot;doubtful&quot; assignment. 
</p>
</li>
<li> <p><code>mean.DiscrFact</code> A vector of length <code>k + 1</code> containing the mean discriminant 
factors for each cluster (including the outliers). 
</p>
</li></ul>



<h3>References</h3>

<p>García-Escudero, L.A.; Gordaliza, A.; Matrán, C. and Mayo-Iscar, A. (2011), 
&quot;Exploring the number of groups in robust model-based clustering.&quot; <em>Statistics and Computing</em>, <b>21</b> 
pp. 585-599, &lt;doi:10.1007/s11222-010-9194-z&gt;
</p>

<hr>
<h2 id='geyser2'>Old Faithful Geyser Data</h2><span id='topic+geyser2'></span>

<h3>Description</h3>

<p>A bivariate data set obtained from the Old Faithful Geyser, containing the 
eruption length and the length of the previous eruption for 271 eruptions 
of this geyser in minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(geyser2)
</code></pre>


<h3>Format</h3>

<p>A data frame containing 272 observations in 2 variables. 
The variables are as follows:
</p>

<ul>
<li> <p><code>Eruption length</code> The eruption length in minutes. 
</p>
</li>
<li> <p><code>Previous eruption length</code> The length of the previous eruption in minutes. 
</p>
</li></ul>



<h3>Source</h3>

<p>This particular data structure can be obtained by applying the following code
to the &quot;Old Faithful Geyser&quot; (<code>faithful</code> data set (Härdle 1991) in the 
package <code>datasets</code>):
<br />
<code>f1 &lt;- faithful[,1]</code><br />
<code>geyser2 &lt;- cbind(f1[-length(f1)], f1[-1])</code><br />
<code>colnames(geyser2) &lt;- c("Eruption length",</code><br />
<code>                      "Previous eruption length")</code>
</p>


<h3>References</h3>

<p>García-Escudero, L.A. and Gordaliza, A. (1999). 
Robustness properties of k-means and trimmed k-means. <em>Journal of the American Statistical Assoc.</em>, Vol.94, No.447, 956&ndash;969.
</p>
<p>Härdle, W. (1991). <em>Smoothing Techniques with Implementation in S.</em>, New York: Springer.
</p>

<hr>
<h2 id='LG5data'>LG5data data</h2><span id='topic+LG5data'></span>

<h3>Description</h3>

<p>A data set in dimension 10 with three clusters around affine subspaces
of common intrinsic dimension. A 10% background noise is added uniformly 
distributed in a rectangle containing the three main clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(LG5data)
</code></pre>


<h3>Format</h3>

<p>The first 10 columns are the variables. The last column is the true 
classification vector where symbol &quot;0&quot; stands for the contaminating data points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#--- EXAMPLE 1 ------------------------------------------ 
data (LG5data)
x &lt;- LG5data[, 1:10]
clus &lt;- rlg(x, d = c(2,2,2), alpha=0.1, trace=TRUE)
plot(x, col=clus$cluster+1)
</code></pre>

<hr>
<h2 id='M5data'>M5data data</h2><span id='topic+M5data'></span>

<h3>Description</h3>

<p>A bivariate data set obtained from three normal bivariate distributions with 
different scales and proportions 1:2:2. One of the components is very overlapped 
with another one. A 10% background noise is added uniformly distributed in a rectangle 
containing the three normal components and not very overlapped with the three mixture 
components. A precise description of the M5 data set can be found in 
García-Escudero et al. (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(M5data)
</code></pre>


<h3>Format</h3>

<p>The first two columns are the two variables. The last column is the true 
classification vector where symbol &quot;0&quot; stands for the contaminating data points.
</p>


<h3>Source</h3>

<p>García-Escudero, L.A.; Gordaliza, A.; Matrán, C. and Mayo-Iscar, A. (2008), 
&quot;A General Trimming Approach to Robust Cluster Analysis&quot;. Annals of Statistics, 
Vol.36, pp. 1324-1345.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#--- EXAMPLE 1 ------------------------------------------ 
data (M5data) 
x &lt;- M5data[, 1:2] 
clus &lt;- tclust(x, k=3, alpha=0.1, nstart=200, niter1=3, niter2=17, 
   nkeep=10, opt="HARD", equal.weights=FALSE, restr.fact=50, trace=TRUE) 
plot (x, col=clus$cluster+1)
</code></pre>

<hr>
<h2 id='pine'>Pinus nigra dataset</h2><span id='topic+pine'></span>

<h3>Description</h3>

<p>To study the growth of the wood mass in a cultivated forest of <em>Pinus nigra</em> 
located in the north of Palencia (Spain), a sample of 362 trees was studied. 
The data set is made of measurements of heights (in meters), in variable &quot;HT&quot;, 
and diameters (in millimetres), in variable &quot;Diameter&quot;, of these trees. 
The presence of three linear groups can be guessed apart from a small group 
of trees forming its own cluster with larger heights and diameters one isolated 
tree with the largest diameter but small height. More details on the 
interpretation of this dataset in García-Escudero et al (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pine)
</code></pre>


<h3>Format</h3>

<p>A data frame containing 362 observations in 2 variables. 
The variables are as follows:
</p>

<ul>
<li> <p><code>Diameter</code> Diameter
</p>
</li>
<li> <p><code>HT</code> Height
</p>
</li></ul>



<h3>References</h3>

<p>García-Escudero, L. A., Gordaliza, A., Mayo-Iscar, A., and San Martín, R. (2010). 
Robust clusterwise linear regression through trimming. 
<em>Computational Statistics &amp; Data Analysis</em>, 54(12), 3057&ndash;3069.
</p>

<hr>
<h2 id='plot.ctlcurves'>The <code>plot</code> method for objects of class <code>ctlcurves</code></h2><span id='topic+plot.ctlcurves'></span>

<h3>Description</h3>

<p>The <code>plot</code> method for class <code>ctlcurves</code>: This function implements 
a series of plots, which display characteristic values 
of the each model, computed with different values for <code>k</code> and <code>alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ctlcurves'
plot(
  x,
  what = c("obj", "min.weights", "doubtful"),
  main,
  xlab,
  ylab,
  xlim,
  ylim,
  col,
  lty = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ctlcurves_+3A_x">x</code></td>
<td>
<p>The ctlcurves object to be shown</p>
</td></tr>
<tr><td><code id="plot.ctlcurves_+3A_what">what</code></td>
<td>
<p>A string indicating which type of plot shall be drawn. See the details section for more information.</p>
</td></tr>
<tr><td><code id="plot.ctlcurves_+3A_main">main</code></td>
<td>
<p>A character-string containing the title of the plot.</p>
</td></tr>
<tr><td><code id="plot.ctlcurves_+3A_xlab">xlab</code>, <code id="plot.ctlcurves_+3A_ylab">ylab</code>, <code id="plot.ctlcurves_+3A_xlim">xlim</code>, <code id="plot.ctlcurves_+3A_ylim">ylim</code></td>
<td>
<p>Arguments passed to plot().</p>
</td></tr>
<tr><td><code id="plot.ctlcurves_+3A_col">col</code></td>
<td>
<p>A single value or vector of line colors passed to <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="plot.ctlcurves_+3A_lty">lty</code></td>
<td>
<p>A single value or vector of line colors passed to <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="plot.ctlcurves_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These curves show the values of the trimmed classification (log-)likelihoods 
when altering the trimming proportion <code>alpha</code> and the number of clusters <code>k</code>.
The careful examination of these curves provides valuable information for choosing these 
parameters in a clustering problem. For instance, an appropriate <code>k</code> to be chosen 
is one that we do not observe a clear increase in the trimmed classification likelihood
curve for <code>k</code> with respect to the <code>k+1</code> curve for almost all the range of
<code>alpha</code> values. Moreover, an appropriate choice of parameter <code>alpha</code> may
be derived by determining where an initial fast increase of the trimmed classification 
likelihood curve stops for the final chosen <code>k</code>. A more detailed explanation 
can be found in García-Escudero et al. (2011).
</p>
<p>This function implements a series of plots, which display characteristic values 
of the each model, computed with different values for <code>k</code> and <code>alpha</code>.
</p>

<dl>
<dt><code>"obj"</code></dt><dd><p>Objective function values.</p>
</dd>
<dt><code>"min.weights"</code></dt><dd><p>The minimum cluster weight found for each computed model. 
This plot is intended to spot spurious clusters, which in 
general yield quite small weights.</p>
</dd>
<dt><code>"doubtful"</code></dt><dd><p>The number of &quot;doubtful&quot; decisions identified by <code><a href="#topic+DiscrFact">DiscrFact</a></code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>García-Escudero, L.A.; Gordaliza, A.; Matrán, C. and Mayo-Iscar, A. (2011), 
&quot;Exploring the number of groups in robust model-based clustering.&quot; <em>Statistics and Computing</em>, <b>21</b> 
pp. 585-599, &lt;doi:10.1007/s11222-010-9194-z&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 #--- EXAMPLE 1 ------------------------------------------

 sig &lt;- diag (2)
 cen &lt;- rep (1, 2)
 x &lt;- rbind(MASS::mvrnorm(108, cen * 0,   sig),
 	       MASS::mvrnorm(162, cen * 5,   sig * 6 - 2),
 	       MASS::mvrnorm(30, cen * 2.5, sig * 50))

 (ctl &lt;- ctlcurves(x, k = 1:4))

 plot(ctl)
</code></pre>

<hr>
<h2 id='plot.DiscrFact'>The <code>plot</code> method for objects of class <code>DiscrFact</code></h2><span id='topic+plot.DiscrFact'></span>

<h3>Description</h3>

<p>The <code>plot</code> method for class <code>DiscrFact</code>: Next to a plot of the <code>tclust</code> 
object which has been used for creating the <code>DiscrFact</code> object, a silhouette plot 
indicates the presence of groups with a large amount of doubtfully assigned 
observations. A third plot similar to the standard <code>tclust</code> plot serves 
to highlight the identified doubtful observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DiscrFact'
plot(
  x,
  enum.plots = FALSE,
  xlab = "Discriminant Factor",
  ylab = "Clusters",
  print.DiscrFact = TRUE,
  xlim,
  col.nodoubt = grey(0.8),
  by.cluster = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.DiscrFact_+3A_x">x</code></td>
<td>
<p>An object of class <code>DiscrFact</code> as returned from DiscrFact()</p>
</td></tr>
<tr><td><code id="plot.DiscrFact_+3A_enum.plots">enum.plots</code></td>
<td>
<p>A logical value indicating whether the plots shall be enumerated 
in their title (&quot;(a)&quot;, &quot;(b)&quot;, &quot;(c)&quot;).</p>
</td></tr>
<tr><td><code id="plot.DiscrFact_+3A_xlab">xlab</code>, <code id="plot.DiscrFact_+3A_ylab">ylab</code>, <code id="plot.DiscrFact_+3A_xlim">xlim</code></td>
<td>
<p>Arguments passed to funcion <code>plot.tclust()</code></p>
</td></tr>
<tr><td><code id="plot.DiscrFact_+3A_print.discrfact">print.DiscrFact</code></td>
<td>
<p>A logical value indicating whether each clusters mean discriminant factor shall be plotted</p>
</td></tr>
<tr><td><code id="plot.DiscrFact_+3A_col.nodoubt">col.nodoubt</code></td>
<td>
<p>Color of all observations not considered as to be assigned doubtfully.</p>
</td></tr>
<tr><td><code id="plot.DiscrFact_+3A_by.cluster">by.cluster</code></td>
<td>
<p>Logical value indicating whether optional parameters pch and col 
(if present) refer to observations (FALSE) or clusters (TRUE)</p>
</td></tr>
<tr><td><code id="plot.DiscrFact_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to or from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot_DiscrFact_p2</code> displays a silhouette plot based on the discriminant 
factors of the observations. A solution with many large discriminant factors is 
not reliable. Such clusters can be identified with this silhouette plot. 
Thus <code>plot_DiscrFact_p3</code> displays the dataset, highlighting observations with 
discriminant factors greater than the given threshold. The function <code>plot.DiscrFact()</code> 
combines the standard plot of a <code>tclust</code> object, and the two plots introduced here.
</p>


<h3>References</h3>

<p>García-Escudero, L.A.; Gordaliza, A.; Matrán, C. and Mayo-Iscar, A. (2011), 
&quot;Exploring the number of groups in robust model-based clustering.&quot; <em>Statistics and Computing</em>, <b>21</b> 
pp. 585-599, &lt;doi:10.1007/s11222-010-9194-z&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'> sig &lt;- diag (2)
 cen &lt;- rep (1, 2)
 x &lt;- rbind(MASS::mvrnorm(360, cen * 0,   sig),
 	       MASS::mvrnorm(540, cen * 5,   sig * 6 - 2),
 	       MASS::mvrnorm(100, cen * 2.5, sig * 50))

 clus.1 &lt;- tclust(x, k = 2, alpha=0.1, restr.fact=12)
 clus.2 &lt;- tclust(x, k = 3, alpha=0.1, restr.fact=1)

 dsc.1 &lt;- DiscrFact(clus.1)
 plot(dsc.1)

 dsc.2 &lt;- DiscrFact(clus.2)
 plot(dsc.2)

</code></pre>

<hr>
<h2 id='plot.rlg'>Plot an 'rlg' object</h2><span id='topic+plot.rlg'></span>

<h3>Description</h3>

<p>Different plots for the results of 'rlg' analysis, stored in an 
<code>rlg</code> object, see Details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rlg'
plot(
  x,
  which = c("all", "scores", "loadings", "eigenvalues"),
  sort = TRUE,
  ask = (which == "all" &amp;&amp; dev.interactive(TRUE)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rlg_+3A_x">x</code></td>
<td>
<p>An <code>rlg</code> object to plot.</p>
</td></tr>
<tr><td><code id="plot.rlg_+3A_which">which</code></td>
<td>
<p>Select the required plot.</p>
</td></tr>
<tr><td><code id="plot.rlg_+3A_sort">sort</code></td>
<td>
<p>Whether to sort.</p>
</td></tr>
<tr><td><code id="plot.rlg_+3A_ask">ask</code></td>
<td>
<p>if <code>TRUE</code>, the user is <em>ask</em>ed before each plot, see <code>par(ask=.)</code>. 
Default is <code>ask = which=="all" &amp;&amp; dev.interactive()</code>.</p>
</td></tr>
<tr><td><code id="plot.rlg_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed to the lower level functions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'> data (LG5data)
 x &lt;- LG5data[, 1:10]
 clus &lt;- rlg(x, d = c(2,2,2), alpha=0.1)
 plot(clus, which="eigenvalues") 
 plot(clus, which="scores") 

</code></pre>

<hr>
<h2 id='plot.tclust'>Plot Method for <code>tclust</code> and <code>tkmeans</code> Objects</h2><span id='topic+plot.tclust'></span><span id='topic+plot.tkmeans'></span>

<h3>Description</h3>

<p>One and two dimensional structures are treated separately (e.g. tolerance 
intervals/ellipses are displayed). Higher dimensional structures are displayed 
by plotting the two first Fisher's canonical coordinates (evaluated by 
<code>tclust::discr_coords</code>) and derived from the final cluster assignments 
(trimmed observations are not taken into account). 
<code>plot.tclust.Nd</code> can be called with one or two-dimensional <code>tclust</code>- or <code>tkmeans</code>-objects 
too. The function fails, if <code>store.x = FALSE</code> is specified in the <code>tclust()</code> or <code>tkmeans()</code> call, 
because the original data matrix is required here.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tclust'
plot(x, ...)

## S3 method for class 'tkmeans'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.tclust_+3A_x">x</code></td>
<td>
<p>The <code>tclust</code> or <code>tkmeans</code> object to be displayed</p>
</td></tr>
<tr><td><code id="plot.tclust_+3A_...">...</code></td>
<td>
<p>Further (optional) arguments which specify the details of the 
resulting plot (see section &quot;Further Arguments&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot method for classes <code>tclust</code> and <code>tkmeans</code>.
</p>


<h3>Further Arguments</h3>


<ul>
<li> <p><code>xlab, ylab, xlim, ylim, pch, col</code> Arguments passed to <code>plot()</code>.
</p>
</li>
<li> <p><code>main</code> The title of the plot. Use <code>"/p"</code> for displaying the chosen parameters 
<code>alpha</code> and <code>k</code> or <code>"/r"</code> for plotting the chosen restriction.
</p>
</li>
<li> <p><code>main.pre</code> An optional string which is added to the plot's caption.
</p>
</li>
<li> <p><code>sub</code> A string specifying the subtitle of the plot. Use <code>"/p"</code> (default) for 
displaying the chosen parameters <code>alpha</code> and <code>k</code>, <code>"/r"</code> for plotting 
the chosen restriction and <code>"/pr"</code> for both. 
</p>
</li>
<li> <p><code>sub1</code> A secondary (optional) subtitle.
</p>
</li>
<li> <p><code>labels</code> A string specifying the type of labels to be drawn. Either 
<code>labels="none"</code> (default), <code>labels="cluster"</code> or <code>labels="observation"</code> 
can be specified. If specified, parameter <code>pch</code> is ignored.
</p>
</li>
<li> <p><code>text</code> A vector of length n (the number of observations) containing 
strings which are used as labels for each observation. If specified, 
the parameters <code>labels</code> and <code>pch</code> are ignored.
</p>
</li>
<li> <p><code>by.cluster</code> Logical value indicating whether parameters 
<code>pch</code> and <code>col</code> refer to observations (FALSE) or clusters (TRUE).
</p>
</li>
<li> <p><code>jitter.y</code> Logical value, specifying whether the drawn values shall be 
jittered in y-direction for better visibility of structures in 1 dimensional data.
</p>
</li>
<li> <p><code>tol</code> The tolerance interval. 95% tolerance ellipsoids (assuming normality) 
are plotted by default.
</p>
</li>
<li> <p><code>tol.col, tol.lty, tol.lwd</code> Vectors of length k or 1 containing 
the <code>col</code>, <code>lty</code> and <code>lwd</code> arguments for the tolerance 
ellipses/lines.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'> #--- EXAMPLE 1------------------------------
 sig &lt;- diag (2)
 cen &lt;- rep (1, 2)
 x &lt;- rbind(MASS::mvrnorm(360, cen * 0,   sig),
 	       MASS::mvrnorm(540, cen * 5,   sig * 6 - 2),
 	       MASS::mvrnorm(100, cen * 2.5, sig * 50))
 # Two groups and 10\% trimming level
 a &lt;- tclust(x, k = 2, alpha = 0.1, restr.fact = 12)
 plot (a)
 plot (a, labels = "observation")
 plot (a, labels = "cluster")
 plot (a, by.cluster = TRUE)
 #--- EXAMPLE 2------------------------------
 sig &lt;- diag (2)
 cen &lt;- rep (1, 2)
 x &lt;- rbind(MASS::mvrnorm(360, cen * 0,   sig),
 	       MASS::mvrnorm(540, cen * 5,   sig),
 	       MASS::mvrnorm(100, cen * 2.5, sig))
 # Two groups and 10\% trimming level
 a &lt;- tkmeans(x, k = 2, alpha = 0.1)
 plot (a)
 plot (a, labels = "observation")
 plot (a, labels = "cluster")
 plot (a, by.cluster = TRUE)

</code></pre>

<hr>
<h2 id='rlg'>Robust Linear Grouping</h2><span id='topic+rlg'></span>

<h3>Description</h3>

<p>The function <code>rlg()</code> searches for clusters around affine subspaces of dimensions given by 
vector <code>d</code> (the length of that vector is the number of clusters). For instance <code>d=c(1,2)</code> 
means that we are clustering around a line and a plane. For robustifying the estimation, 
a proportion <code>alpha</code> of observations is trimmed. In particular, the trimmed k-means 
method is represented by the rlg method, if <code>d=c(0,0,..0)</code> (a vector of length 
<code>k</code> with zeroes).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlg(
  x,
  d,
  alpha = 0.05,
  nstart = 500,
  niter1 = 3,
  niter2 = 20,
  nkeep = 5,
  scale = FALSE,
  parallel = FALSE,
  n.cores = -1,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rlg_+3A_x">x</code></td>
<td>
<p>A matrix or data.frame of dimension n x p, containing the observations (rowwise).</p>
</td></tr>
<tr><td><code id="rlg_+3A_d">d</code></td>
<td>
<p>A numeric vector of length equal to the number of clusters to be detected. 
Each component of vector <code>d</code> indicates the intrinsic dimension of the affine subspace 
where observations on that cluster are going to be clustered. All the elements 
of vector <code>d</code> should be smaller than the problem dimension minus 1.</p>
</td></tr>
<tr><td><code id="rlg_+3A_alpha">alpha</code></td>
<td>
<p>The proportion of observations to be trimmed.</p>
</td></tr>
<tr><td><code id="rlg_+3A_nstart">nstart</code></td>
<td>
<p>The number of random initializations to be performed.</p>
</td></tr>
<tr><td><code id="rlg_+3A_niter1">niter1</code></td>
<td>
<p>The number of concentration steps to be performed for the nstart initializations.</p>
</td></tr>
<tr><td><code id="rlg_+3A_niter2">niter2</code></td>
<td>
<p>The maximum number of concentration steps to be performed for 
the nkeep solutions kept for further iteration. The concentration steps 
are stopped, whenever two consecutive steps lead to the same data partition.</p>
</td></tr>
<tr><td><code id="rlg_+3A_nkeep">nkeep</code></td>
<td>
<p>The number of iterated initializations (after niter1 concentration 
steps) with the best values in the target function that are kept for further iterations</p>
</td></tr>
<tr><td><code id="rlg_+3A_scale">scale</code></td>
<td>
<p>A robust centering and scaling (using the median and MAD) is done if TRUE.</p>
</td></tr>
<tr><td><code id="rlg_+3A_parallel">parallel</code></td>
<td>
<p>A logical value, specifying whether the nstart initializations should be done in parallel.</p>
</td></tr>
<tr><td><code id="rlg_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of cores to use when paralellizing, only taken into account if parallel=T.</p>
</td></tr>
<tr><td><code id="rlg_+3A_trace">trace</code></td>
<td>
<p>Defines the tracing level, which is set to 0 by default. Tracing level 1 gives additional information on the stage of the iterative process.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure allows to deal with robust clustering around affine subspaces 
with an alpha proportion of trimming level by minimizing the trimmed sums of squared 
orthogonal residuals. Each component of vector <code>d</code> indicates the intrinsic dimension of 
the affine subspace where observations on that cluster are going to be clustered. 
Therefore a component equal to 0 on that vector implies clustering around centres, 
equal to 1 around lines, equal to 2 around planes and so on. The procedure so 
allows simultaneous clustering and dimensionality reduction. 
</p>
<p>This iterative algorithm performs &quot;concentration steps&quot; to improve the current 
cluster assignments. For approximately obtaining the global optimum, the procedure 
is randomly initialized <code>nstart</code> times and <code>niter1</code> concentration steps are performed 
for them. The <code>nkeep</code> most “promising” iterations, i.e. the <code>nkeep</code> iterated solutions 
with the initial best values for the target function, are then iterated until 
convergence or until <code>niter2</code> concentration steps are done.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>rlg</code> which is basically a list with the following elements:
</p>

<ul>
<li><p> centers - A matrix of size p x k containing the location vectors (column-wise) of each cluster. 
</p>
</li>
<li><p> U - A list with k elements where each element is p x d_j matrix whose d_j columns are unitary and orthogonal vectors generating the affine subspace (after subtracting the corresponding cluster’s location parameter in centers). d_j is the intrinsic dimension of the affine subspace approximation in the j-th cluster, i.e., the elements of vector d.
</p>
</li>
<li><p> cluster - A numerical vector of size n containing the cluster assignment 
for each observation. Cluster names are integer numbers from 1 to k, 
0 indicates trimmed observations.
</p>
</li>
<li><p> obj - The value of the objective function of the best (returned) solution.
</p>
</li>
<li><p> cluster.ini - A matrix with nstart rows and number of columns equal to the number of observations and where each row shows the final clustering assignments (0 for trimmed observations) obtained after the niter1 iteration of the nstart random initializations.
</p>
</li>
<li><p> obj.ini -A numerical vector of length nstart containing the values of the target function obtained after the niter1 iteration of the nstart random initializations.
</p>
</li>
<li><p> x - The input data set. 
</p>
</li>
<li><p> dimensions - The input d vector with the intrinsic dimensions. The number of clusters is the length of that vector. 
</p>
</li>
<li><p> alpha - The input trimming level.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Javier Crespo Guerrero, Jesús Fernández Iglesias, Luis Angel Garcia Escudero, Agustin Mayo Iscar.
</p>


<h3>References</h3>

<p>García‐Escudero, L. A., Gordaliza, A., San Martin, R., Van Aelst, S., &amp; Zamar, R. (2009). 
Robust linear clustering. Journal of the Royal Statistical Society: 
Series B (Statistical Methodology), 71, 301-318.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##--- EXAMPLE 1 ------------------------------------------
data (LG5data)
x &lt;- LG5data[, 1:10]
clus &lt;- rlg(x, d = c(2,2,2), alpha=0.1)
plot(x, col=clus$cluster+1)
plot(clus, which="eigenvalues") 
plot(clus, which="scores") 

##--- EXAMPLE 2 ------------------------------------------
 data (pine) 
 clus &lt;- rlg(pine, d = c(1,1,1), alpha=0.035)
 plot(pine, col=clus$cluster+1)
 
</code></pre>

<hr>
<h2 id='simula.rlg'>Simulate contaminated data set for applying rlg</h2><span id='topic+simula.rlg'></span>

<h3>Description</h3>

<p>Simulate alpha*100% contaminated data set for applying rlg by 
generating a k=3 components with equal size  and            # 
common underlying dimension q_1=q_2=q_3=q
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simula.rlg(q = 2, p = 10, n = 200, var = 0.01, sep.means = 0, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simula.rlg_+3A_q">q</code></td>
<td>
<p>intrinsic dimension</p>
</td></tr>
<tr><td><code id="simula.rlg_+3A_p">p</code></td>
<td>
<p>dimension (<code>p &gt;= 2</code> and <code>p &gt; q</code>)</p>
</td></tr>
<tr><td><code id="simula.rlg_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="simula.rlg_+3A_var">var</code></td>
<td>
<p>The smaller 'var' the smaller the scatter around the lower dimensional space</p>
</td></tr>
<tr><td><code id="simula.rlg_+3A_sep.means">sep.means</code></td>
<td>
<p>Parameter controlling the location vectors separation</p>
</td></tr>
<tr><td><code id="simula.rlg_+3A_alpha">alpha</code></td>
<td>
<p>contamination level</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following items
</p>

<ul>
<li><p> x - The generated dataset
</p>
</li>
<li><p> true - The true classification
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'> res &lt;- simula.rlg(q=5, p=200, n=150, var=0.01, sep.means=0.00)
 plot(res$x,col=res$true+1)

</code></pre>

<hr>
<h2 id='simula.tclust'>Simulate contaminated data set for applying TCLUST</h2><span id='topic+simula.tclust'></span>

<h3>Description</h3>

<p>Simulate 10% contaminated data set for applying TCLUST
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simula.tclust(n, p = 4, k = 3, type = 2, balanced = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simula.tclust_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="simula.tclust_+3A_p">p</code></td>
<td>
<p>dimension (p&gt;=2 and p&gt;q)</p>
</td></tr>
<tr><td><code id="simula.tclust_+3A_k">k</code></td>
<td>
<p>number of clusters (only k=3 and k=6 are allowed!!!)</p>
</td></tr>
<tr><td><code id="simula.tclust_+3A_type">type</code></td>
<td>
<p>1 (spherical for rest.fact=1) or 2 (elliptical for rest.fact=9^2)</p>
</td></tr>
<tr><td><code id="simula.tclust_+3A_balanced">balanced</code></td>
<td>
<p>1 (all clusters equal size) or 2 [proportions (25,30,35)% if k=3 and (12.5,15,17.5,12.5,15,17.5)% if k=6]</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following items
</p>

<ul>
<li><p> x - The generated dataset
</p>
</li>
<li><p> true - The true classification
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- simula.tclust(n=400,k=3,p=8,type=2,balanced=1)
plot(res$x,col=res$true+1)

</code></pre>

<hr>
<h2 id='summary.DiscrFact'>The <code>summary</code> method for objects of class <code>DiscrFact</code></h2><span id='topic+summary.DiscrFact'></span>

<h3>Description</h3>

<p>The summary method for class <code>DiscrFact</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DiscrFact'
summary(object, hide.emtpy = TRUE, show.clust, show.alt, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.DiscrFact_+3A_object">object</code></td>
<td>
<p>An object of class <code>DiscrFact</code> as returned from <code>DiscrFact()</code>.</p>
</td></tr>
<tr><td><code id="summary.DiscrFact_+3A_hide.emtpy">hide.emtpy</code></td>
<td>
<p>A logical value specifying whether clusters without doubtful 
assignment shall be hidden.</p>
</td></tr>
<tr><td><code id="summary.DiscrFact_+3A_show.clust">show.clust</code></td>
<td>
<p>A logical value specifying whether the number of doubtful 
assignments per cluster shall be displayed.</p>
</td></tr>
<tr><td><code id="summary.DiscrFact_+3A_show.alt">show.alt</code></td>
<td>
<p>A logical value specifying whether the alternative cluster 
assignment shall be displayed.</p>
</td></tr>
<tr><td><code id="summary.DiscrFact_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>References</h3>

<p>García-Escudero, L.A.; Gordaliza, A.; Matrán, C. and Mayo-Iscar, A. (2011), 
&quot;Exploring the number of groups in robust model-based clustering.&quot; <em>Statistics and Computing</em>, <b>21</b> 
pp. 585-599, &lt;doi:10.1007/s11222-010-9194-z&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'> sig &lt;- diag (2)
 cen &lt;- rep (1, 2)
 x &lt;- rbind(MASS::mvrnorm(360, cen * 0,   sig),
 	       MASS::mvrnorm(540, cen * 5,   sig * 6 - 2),
 	       MASS::mvrnorm(100, cen * 2.5, sig * 50)
 )

 clus.1 &lt;- tclust(x, k = 2, alpha=0.1, restr.fact=12)
 clus.2 &lt;- tclust(x, k = 3, alpha=0.1, restr.fact=1)

 dsc.1 &lt;- DiscrFact(clus.1)
 summary(dsc.1)

 dsc.2 &lt;- DiscrFact(clus.2)
 summary(dsc.2)

</code></pre>

<hr>
<h2 id='swissbank'>Swiss banknotes data</h2><span id='topic+swissbank'></span>

<h3>Description</h3>

<p>Six variables measured on 100 genuine and 100 counterfeit old Swiss 1000-franc 
bank notes (Flury and Riedwyl, 1988).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(swissbank)
</code></pre>


<h3>Format</h3>

<p>A data frame containing 200 observations in 6 variables. 
The variables are as follows:
</p>

<ul>
<li> <p><code>Length</code> Length of the bank note 
</p>
</li>
<li> <p><code>Ht_Left</code> Height of the bank note, measured on the left 
</p>
</li>
<li> <p><code>Ht_Right</code> Height of the bank note, measured on the right 
</p>
</li>
<li> <p><code>IF_Lower</code> Distance of inner frame to the lower border 
</p>
</li>
<li> <p><code>IF_Upper</code> Distance of inner frame to the upper border 
</p>
</li>
<li> <p><code>Diagonal</code> Length of the diagonal 
</p>
</li></ul>



<h3>Details</h3>

<p>Observations 1&ndash;100 are the genuine bank notes and the other 100 observations are the counterfeit bank notes.
</p>


<h3>Source</h3>

<p>Flury, B. and Riedwyl, H. (1988). <em>Multivariate Statistics, A Practical Approach</em>, Cambridge University Press.
</p>

<hr>
<h2 id='tclust'>TCLUST method for robust clustering</h2><span id='topic+tclust'></span><span id='topic+print.tclust'></span>

<h3>Description</h3>

<p>This function searches for <code>k</code> (or less) clusters with 
different covariance structures in a data matrix <code>x</code>. Relative cluster 
scatter can be restricted when <code>restr="eigen"</code> by constraining the ratio 
between the largest and the smallest of the scatter matrices eigenvalues 
by a constant value <code>restr.fact</code>. Relative cluster scatters can be also 
restricted with <code>restr="deter"</code> by constraining the ratio between the 
largest and the smallest of the scatter matrices' determinants. 
</p>
<p>For robustifying the estimation, a proportion <code>alpha</code> of observations is trimmed. 
In particular, the trimmed k-means method is represented by the <code>tclust()</code> method,
by setting parameters <code>restr.fact=1</code>, <code>opt="HARD"</code> and <code>equal.weights=TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tclust(
  x,
  k,
  alpha = 0.05,
  nstart = 500,
  niter1 = 3,
  niter2 = 20,
  nkeep = 5,
  iter.max,
  equal.weights = FALSE,
  restr = c("eigen", "deter"),
  restr.fact = 12,
  cshape = 1e+10,
  opt = c("HARD", "MIXT"),
  center = FALSE,
  scale = FALSE,
  store_x = TRUE,
  parallel = FALSE,
  n.cores = -1,
  zero_tol = 1e-16,
  drop.empty.clust = TRUE,
  trace = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tclust_+3A_x">x</code></td>
<td>
<p>A matrix or data.frame of dimension n x p, containing the observations (row-wise).</p>
</td></tr>
<tr><td><code id="tclust_+3A_k">k</code></td>
<td>
<p>The number of clusters initially searched for.</p>
</td></tr>
<tr><td><code id="tclust_+3A_alpha">alpha</code></td>
<td>
<p>The proportion of observations to be trimmed.</p>
</td></tr>
<tr><td><code id="tclust_+3A_nstart">nstart</code></td>
<td>
<p>The number of random initializations to be performed.</p>
</td></tr>
<tr><td><code id="tclust_+3A_niter1">niter1</code></td>
<td>
<p>The number of concentration steps to be performed for the nstart initializations.</p>
</td></tr>
<tr><td><code id="tclust_+3A_niter2">niter2</code></td>
<td>
<p>The maximum number of concentration steps to be performed for the 
<code>nkeep</code> solutions kept for further iteration. The concentration steps are 
stopped, whenever two consecutive steps lead to the same data partition.</p>
</td></tr>
<tr><td><code id="tclust_+3A_nkeep">nkeep</code></td>
<td>
<p>The number of iterated initializations (after niter1 concentration 
steps) with the best values in the target function that are kept for further iterations</p>
</td></tr>
<tr><td><code id="tclust_+3A_iter.max">iter.max</code></td>
<td>
<p>(deprecated, use the combination <code>nkeep, niter1 and niter2</code>) 
The maximum number of concentration steps to be performed.
The concentration steps are stopped, whenever two consecutive steps lead
to the same data partition.</p>
</td></tr>
<tr><td><code id="tclust_+3A_equal.weights">equal.weights</code></td>
<td>
<p>A logical value, specifying whether equal cluster weights 
shall be considered in the concentration and assignment steps.</p>
</td></tr>
<tr><td><code id="tclust_+3A_restr">restr</code></td>
<td>
<p>Restriction type to control relative cluster scatters. 
The default value is <code>restr="eigen"</code>, so that the maximal ratio between 
the largest and the smallest of the scatter matrices eigenvalues is constrained 
to be smaller then or equal to <code>restr.fact</code> 
(Garcia-Escudero, Gordaliza, Matran, and Mayo-Iscar, 2008). 
Alternatively, <code>restr="deter"</code> imposes that the maximal ratio between 
the largest and the smallest of the scatter matrices determinants is smaller 
or equal than <code>restr.fact</code> (see Garcia-Escudero, Mayo-Iscar and Riani, 2020)</p>
</td></tr>
<tr><td><code id="tclust_+3A_restr.fact">restr.fact</code></td>
<td>
<p>The constant <code>restr.fact &gt;= 1</code> constrains the allowed 
differences among group scatters in terms of eigenvalues ratio
(if <code>restr="eigen"</code>) or determinant ratios (if <code>restr="deter"</code>). Larger values 
imply larger differences of group scatters, a value of 1 specifies the 
strongest restriction.</p>
</td></tr>
<tr><td><code id="tclust_+3A_cshape">cshape</code></td>
<td>
<p>constraint to apply to the shape matrices, <code>cshape &gt;= 1</code>, 
(see Garcia-Escudero, Mayo-Iscar and Riani, 2020)). 
This options only works if <code>restr=='deter'</code>. In this case the default 
value is <code>cshape=1e10</code> to ensure the procedure is (virtually) affine equivariant. 
On the other hand, <code>cshape</code> values close to 1 would force the clusters to 
be almost spherical (without necessarily the same scatters if <code>restr.fact</code> 
is strictly greater than 1).</p>
</td></tr>
<tr><td><code id="tclust_+3A_opt">opt</code></td>
<td>
<p>Define the target function to be optimized. A classification likelihood 
target function is considered if <code>opt="HARD"</code> and a mixture classification 
likelihood if <code>opt="MIXT"</code>.</p>
</td></tr>
<tr><td><code id="tclust_+3A_center">center</code></td>
<td>
<p>Optional centering of the data: a function or a vector of length p 
which can optionally be specified for centering x before calculation</p>
</td></tr>
<tr><td><code id="tclust_+3A_scale">scale</code></td>
<td>
<p>Optional scaling of the data: a function or a vector of length p 
which can optionally be specified for scaling x before calculation</p>
</td></tr>
<tr><td><code id="tclust_+3A_store_x">store_x</code></td>
<td>
<p>A logical value, specifying whether the data matrix <code>x</code> shall be 
included in the result object. By default this value is set to <code>TRUE</code>, because 
some of the plotting functions depend on this information. However, when big data 
matrices are handled, the result object's size can be decreased noticeably 
when setting this parameter to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="tclust_+3A_parallel">parallel</code></td>
<td>
<p>A logical value, specifying whether the nstart initializations should be done in parallel.</p>
</td></tr>
<tr><td><code id="tclust_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of cores to use when paralellizing, only taken into account if parallel=T.</p>
</td></tr>
<tr><td><code id="tclust_+3A_zero_tol">zero_tol</code></td>
<td>
<p>The zero tolerance used. By default set to 1e-16.</p>
</td></tr>
<tr><td><code id="tclust_+3A_drop.empty.clust">drop.empty.clust</code></td>
<td>
<p>Logical value specifying, whether empty clusters shall be 
omitted in the resulting object. (The result structure does not contain center 
and covariance estimates of empty clusters anymore. Cluster names are reassigned 
such that the first l clusters (l &lt;= k) always have at least one observation.</p>
</td></tr>
<tr><td><code id="tclust_+3A_trace">trace</code></td>
<td>
<p>Defines the tracing level, which is set to 0 by default. Tracing level 1 
gives additional information on the stage of the iterative process.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure allows to deal with robust clustering with an <code>alpha</code>
proportion of trimming level and searching for <code>k</code> clusters. We are considering 
classification trimmed likelihood when using <code>opt=”HARD”</code> so that “hard” or “crisp” 
clustering assignments are done. On the other hand, mixture trimmed likelihood 
are applied when using <code>opt=”MIXT”</code> so providing a kind of clusters “posterior” 
probabilities for the observations. 
Relative cluster scatter can be restricted when <code>restr="eigen"</code> by constraining 
the ratio between the largest and the smallest of the scatter matrices eigenvalues 
by a constant value <code>restr.fact</code>. Setting <code>restr.fact=1</code>, yields the 
strongest restriction, forcing all clusters to be spherical and equally scattered. 
Relative cluster scatters can be also restricted with <code>restr="deter"</code> by 
constraining the ratio between the largest and the smallest of the scatter 
matrices' determinants. 
</p>
<p>This iterative algorithm performs &quot;concentration steps&quot; to improve the current 
cluster assignments. For approximately obtaining the global optimum, the procedure 
is randomly initialized <code>nstart</code> times and <code>niter1</code> concentration steps are performed for 
them. The <code>nkeep</code> most “promising” iterations, i.e. the <code>nkeep</code> iterated solutions with 
the initial best values for the target function, are then iterated until convergence 
or until <code>niter2</code> concentration steps are done. 
</p>
<p>The parameter <code>restr.fact</code> defines the cluster scatter matrices restrictions, 
which are applied on all clusters during each concentration step. It restricts 
the ratio between the maximum and minimum eigenvalue of 
all clusters' covariance structures to that parameter. Setting <code>restr.fact=1</code>, 
yields the strongest restriction, forcing all clusters to be spherical and equally scattered. 
</p>
<p>Cluster components with similar sizes are favoured when considering <code>equal.weights=TRUE</code> 
while <code>equal.weights=FALSE</code> admits possible different prior probabilities for 
the components and it can easily return empty clusters when the number of 
clusters is greater than apparently needed.
</p>


<h3>Value</h3>

<p>The function returns the following values:
</p>

<ul>
<li><p> cluster - A numerical vector of size <code>n</code> containing the cluster assignment 
for each observation. Cluster names are integer numbers from 1 to k, 0 indicates 
trimmed observations. Note that it could be empty clusters with no observations 
when <code>equal.weights=FALSE</code>.
</p>
</li>
<li><p> obj - The value of the objective function of the best (returned) solution.
</p>
</li>
<li><p> size - An integer vector of size k, returning the number of observations contained by each cluster.
</p>
</li>
<li><p> weights - Vector of Cluster weights
</p>
</li>
<li><p> centers - A matrix of size p x k containing the centers (column-wise) of each cluster. 
</p>
</li>
<li><p> cov - 	An array of size p x p x k containing the covariance matrices of each cluster. 
</p>
</li>
<li><p> code - A numerical value indicating if the concentration steps have 
converged for the returned solution (2).
</p>
</li>
<li><p> posterior - A matrix with k columns that contains the posterior 
probabilities of membership of each observation (row-wise) to the <code>k</code> 
clusters. This posterior probabilities are 0-1 values in the 
<code>opt="HARD"</code> case. Trimmed observations have 0 membership probabilities 
to all clusters.
</p>
</li>
<li><p> cluster.ini - A matrix with nstart rows and number of columns equal to 
the number of observations and where each row shows the final clustering 
assignments (0 for trimmed observations) obtained after the <code>niter1</code> 
iteration of the <code>nstart</code> random initializations.
</p>
</li>
<li><p> obj.ini - A numerical vector of length <code>nstart</code> containing the values 
of the target function obtained after the <code>niter1</code> iteration of the 
<code>nstart</code> random initializations.
</p>
</li>
<li><p> x - The input data set.
</p>
</li>
<li><p> k - The input number of clusters.
</p>
</li>
<li><p> alpha - The input trimming level.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Javier Crespo Guerrero, Luis Angel Garcia Escudero, Agustin Mayo Iscar.
</p>


<h3>References</h3>

<p>Fritz, H.; Garcia-Escudero, L.A.; Mayo-Iscar, A. (2012), &quot;tclust: An R Package 
for a Trimming Approach to Cluster Analysis&quot;. Journal of Statistical Software, 
47(12), 1-26. URL http://www.jstatsoft.org/v47/i12/
</p>
<p>Garcia-Escudero, L.A.; Gordaliza, A.; Matran, C. and Mayo-Iscar, A. (2008), 
&quot;A General Trimming Approach to Robust Cluster Analysis&quot;. Annals of Statistics, 
Vol.36, 1324&ndash;1345.  
</p>
<p>García-Escudero, L. A., Gordaliza, A. and Mayo-Íscar, A. (2014). A constrained 
robust proposal for mixture modeling avoiding spurious solutions. 
Advances in Data Analysis and Classification, 27&ndash;43. 
</p>
<p>García-Escudero, L. A., and Mayo-Íscar, A. and Riani, M. (2020). Model-based 
clustering with determinant-and-shape constraint. Statistics and Computing, 
30, 1363&ndash;1380.]
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 
 ##--- EXAMPLE 1 ------------------------------------------
 sig &lt;- diag(2)
 cen &lt;- rep(1,2)
 x &lt;- rbind(MASS::mvrnorm(360, cen * 0,   sig),
            MASS::mvrnorm(540, cen * 5,   sig * 6 - 2),
            MASS::mvrnorm(100, cen * 2.5, sig * 50))
 
 ## Two groups and 10\% trimming level
 clus &lt;- tclust(x, k = 2, alpha = 0.1, restr.fact = 8)
 
 plot(clus)
 plot(clus, labels = "observation")
 plot(clus, labels = "cluster")
 
 ## Three groups (one of them very scattered) and 0\% trimming level
 clus &lt;- tclust(x, k = 3, alpha=0.0, restr.fact = 100)
 
 plot(clus)
 
 ##--- EXAMPLE 2 ------------------------------------------
 data(geyser2)
 (clus &lt;- tclust(geyser2, k = 3, alpha = 0.03))
 
 plot(clus)
 
## Not run: 

 ##--- EXAMPLE 3 ------------------------------------------
 data(M5data)
 x &lt;- M5data[, 1:2]
 
 clus.a &lt;- tclust(x, k = 3, alpha = 0.1, restr.fact =  1,
                   restr = "eigen", equal.weights = TRUE)
 clus.b &lt;- tclust(x, k = 3, alpha = 0.1, restr.fact =  50,
                    restr = "eigen", equal.weights = FALSE)
 clus.c &lt;- tclust(x, k = 3, alpha = 0.1, restr.fact =  1,
                   restr = "deter", equal.weights = TRUE)
 clus.d &lt;- tclust(x, k = 3, alpha = 0.1, restr.fact = 50,
                   restr = "deter", equal.weights = FALSE)
 
 pa &lt;- par(mfrow = c (2, 2))
 plot(clus.a, main = "(a)")
 plot(clus.b, main = "(b)")
 plot(clus.c, main = "(c)")
 plot(clus.d, main = "(d)")
 par(pa)
 
 ##--- EXAMPLE 4 ------------------------------------------

 data (swissbank)
 ## Two clusters and 8\
 (clus &lt;- tclust(swissbank, k = 2, alpha = 0.08, restr.fact = 50))
 
 ## Pairs plot of the clustering solution
 pairs(swissbank, col = clus$cluster + 1)
 ## Two coordinates
 plot(swissbank[, 4], swissbank[, 6], col = clus$cluster + 1,
      xlab = "Distance of the inner frame to lower border",
      ylab = "Length of the diagonal")
 plot(clus)
 
 ## Three clusters and 0\
 clus&lt;- tclust(swissbank, k = 3, alpha = 0.0, restr.fact = 110)
 
 ## Pairs plot of the clustering solution
 pairs(swissbank, col = clus$cluster + 1)
 
 ## Two coordinates
 plot(swissbank[, 4], swissbank[, 6], col = clus$cluster + 1, 
       xlab = "Distance of the inner frame to lower border", 
       ylab = "Length of the diagonal")
 
 plot(clus)
 
 ##--- EXAMPLE 5 ------------------------------------------
  data(M5data)
  x &lt;- M5data[, 1:2]
  
  ## Classification trimmed likelihood approach
  clus.a &lt;- tclust(x, k = 3, alpha = 0.1, restr.fact =  50,
                     opt="HARD", restr = "eigen", equal.weights = FALSE)
 ## Mixture trimmed likelihood approach
  clus.b &lt;- tclust(x, k = 3, alpha = 0.1, restr.fact =  50,
                     opt="MIXT", restr = "eigen", equal.weights = FALSE)
 
 ## Hard 0-1 cluster assignment (all 0 if trimmed unit)
 head(clus.a$posterior)
 
 ## Posterior probabilities cluster assignment for the
 ##  mixture approach (all 0 if trimmed unit)
 head(clus.b$posterior)
 

## End(Not run)

</code></pre>

<hr>
<h2 id='tkmeans'>TKMEANS method for robust K-means clustering</h2><span id='topic+tkmeans'></span><span id='topic+print.tkmeans'></span>

<h3>Description</h3>

<p>This function searches for <code>k</code> (or less) spherical clusters 
in a data matrix <code>x</code>, whereas the <code>ceiling(alpha n)</code> most outlying 
observations are trimmed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tkmeans(
  x,
  k,
  alpha = 0.05,
  nstart = 500,
  niter1 = 3,
  niter2 = 20,
  nkeep = 5,
  iter.max,
  points = NULL,
  center = FALSE,
  scale = FALSE,
  store_x = TRUE,
  parallel = FALSE,
  n.cores = -1,
  zero_tol = 1e-16,
  drop.empty.clust = TRUE,
  trace = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tkmeans_+3A_x">x</code></td>
<td>
<p>A matrix or data.frame of dimension n x p, containing the observations (row-wise).</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_k">k</code></td>
<td>
<p>The number of clusters initially searched for.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_alpha">alpha</code></td>
<td>
<p>The proportion of observations to be trimmed.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_nstart">nstart</code></td>
<td>
<p>The number of random initializations to be performed.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_niter1">niter1</code></td>
<td>
<p>The number of concentration steps to be performed for the nstart initializations.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_niter2">niter2</code></td>
<td>
<p>The maximum number of concentration steps to be performed for the 
<code>nkeep</code> solutions kept for further iteration. The concentration steps are 
stopped, whenever two consecutive steps lead to the same data partition.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_nkeep">nkeep</code></td>
<td>
<p>The number of iterated initializations (after niter1 concentration 
steps) with the best values in the target function that are kept for further iterations</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_iter.max">iter.max</code></td>
<td>
<p>(deprecated, use the combination <code>nkeep, niter1 and niter2</code>) 
The maximum number of concentration steps to be performed.
The concentration steps are stopped, whenever two consecutive steps lead
to the same data partition.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_points">points</code></td>
<td>
<p>Optional initial mean vectors, <code>NULL</code> or a matrix with <code>k</code> 
vectors used as means to initialize the algorithm. If initial mean vectors are 
specified, <code>nstart</code> should be 1 (otherwise the same initial means are 
used for all runs).</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_center">center</code></td>
<td>
<p>Optional centering of the data: a function or a vector of length p 
which can optionally be specified for centering x before calculation</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_scale">scale</code></td>
<td>
<p>Optional scaling of the data: a function or a vector of length p 
which can optionally be specified for scaling x before calculation</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_store_x">store_x</code></td>
<td>
<p>A logical value, specifying whether the data matrix <code>x</code> shall be 
included in the result object. By default this value is set to <code>TRUE</code>, because 
some of the plotting functions depend on this information. However, when big data 
matrices are handled, the result object's size can be decreased noticeably 
when setting this parameter to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_parallel">parallel</code></td>
<td>
<p>A logical value, specifying whether the nstart initializations should be done in parallel.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of cores to use when paralellizing, only taken into account if parallel=TRUE.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_zero_tol">zero_tol</code></td>
<td>
<p>The zero tolerance used. By default set to 1e-16.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_drop.empty.clust">drop.empty.clust</code></td>
<td>
<p>Logical value specifying, whether empty clusters shall be 
omitted in the resulting object. (The result structure does not contain center 
estimates of empty clusters anymore. Cluster names are reassigned 
such that the first l clusters (l &lt;= k) always have at least one observation.</p>
</td></tr>
<tr><td><code id="tkmeans_+3A_trace">trace</code></td>
<td>
<p>Defines the tracing level, which is set to 0 by default. Tracing level 1 
gives additional information on the stage of the iterative process.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the following values:
</p>

<ul>
<li><p> cluster - A numerical vector of size <code>n</code> containing the cluster assignment 
for each observation. Cluster names are integer numbers from 1 to k, 0 indicates 
trimmed observations. Note that it could be empty clusters with no observations 
when <code>equal.weights=FALSE</code>.
</p>
</li>
<li><p> obj - The value of the objective function of the best (returned) solution.
</p>
</li>
<li><p> size - An integer vector of size k, returning the number of observations contained by each cluster.
</p>
</li>
<li><p> centers - A matrix of size p x k containing the centers (column-wise) of each cluster. 
</p>
</li>
<li><p> code - A numerical value indicating if the concentration steps have 
converged for the returned solution (2).
</p>
</li>
<li><p> cluster.ini - A matrix with nstart rows and number of columns equal to 
the number of observations and where each row shows the final clustering 
assignments (0 for trimmed observations) obtained after the <code>niter1</code> 
iteration of the <code>nstart</code> random initializations.
</p>
</li>
<li><p> obj.ini - A numerical vector of length <code>nstart</code> containing the values 
of the target function obtained after the <code>niter1</code> iteration of the 
<code>nstart</code> random initializations.
</p>
</li>
<li><p> x - The input data set.
</p>
</li>
<li><p> k - The input number of clusters.
</p>
</li>
<li><p> alpha - The input trimming level.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Valentin Todorov, Luis Angel Garcia Escudero, Agustin Mayo Iscar.
</p>


<h3>References</h3>

<p>Cuesta-Albertos, J. A.; Gordaliza, A. and Matrán, C. (1997), &quot;Trimmed k-means: 
an attempt to robustify quantizers&quot;. Annals of Statistics, Vol. 25 (2), 553-576.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 
 ##--- EXAMPLE 1 ------------------------------------------
 sig &lt;- diag(2)
 cen &lt;- rep(1,2)
 x &lt;- rbind(MASS::mvrnorm(360, cen * 0,   sig),
            MASS::mvrnorm(540, cen * 5,   sig),
            MASS::mvrnorm(100, cen * 2.5, sig))
 
 ## Two groups and 10\% trimming level
 (clus &lt;- tkmeans(x, k = 2, alpha = 0.1))

 plot(clus)
 plot(clus, labels = "observation")
 plot(clus, labels = "cluster")

 #--- EXAMPLE 2 ------------------------------------------
 data(geyser2)
 (clus &lt;- tkmeans(geyser2, k = 3, alpha = 0.03))
 plot(clus)
 
</code></pre>

<hr>
<h2 id='wholesale'>Wholesale customers dataset</h2><span id='topic+wholesale'></span>

<h3>Description</h3>

<p>The data set refers to clients of a wholesale distributor. It includes the annual 
spending in monetary units  on diverse product categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wholesale)
</code></pre>


<h3>Format</h3>

<p>A data frame containing 440 observations in 8 variables (6 numerical and two categorical). 
The variables are as follows:
</p>

<ul>
<li> <p><code>Region</code> Customers' Region - Lisbon (coded as 1), Porto (coded as 2) or Other (coded as 3)
</p>
</li>
<li> <p><code>Fresh</code> Annual spending on fresh products
</p>
</li>
<li> <p><code>Milk</code> Annual spending on milk products
</p>
</li>
<li> <p><code>Grocery</code> Annual spending on grocery products
</p>
</li>
<li> <p><code>Frozen</code> Annual spending on frozen products
</p>
</li>
<li> <p><code>Detergents</code> Annual spending on detergents and paper products
</p>
</li>
<li> <p><code>Delicatessen</code> Annual spending on and delicatessen products
</p>
</li>
<li> <p><code>Channel</code>  Customers' Channel - Horeca (Hotel/Restaurant/Café) or 
Retail channel. Horeca is coded as 1 and Retail channel is coded as 2
</p>
</li></ul>



<h3>Source</h3>

<p>Abreu, N. (2011). Analise do perfil do cliente Recheio e desenvolvimento de 
um sistema promocional. Mestrado em Marketing, ISCTE-IUL, Lisbon. 
url=https://api.semanticscholar.org/CorpusID:124027622
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#--- EXAMPLE 1 ------------------------------------------ 
data (wholesale) 
x &lt;- wholesale[, -c(1, ncol(wholesale))] 
clus &lt;- tclust(x, k=3, alpha=0.1, nstart=200, niter1=3, niter2=17, 
   nkeep=10, opt="HARD", equal.weights=FALSE, restr.fact=50, trace=TRUE) 
 plot (x, col=clus$cluster+1)
 plot(clus)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
