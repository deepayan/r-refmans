<!DOCTYPE html><html lang="en"><head><title>Help for package tensorTS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tensorTS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#matAR.RR.est'><p>Estimation for Reduced Rank MAR(1) Model</p></a></li>
<li><a href='#matAR.RR.se'><p>Asymptotic Covariance Matrix of One-Term Reduced rank MAR(1) Model</p></a></li>
<li><a href='#mplot'><p>Plot Matrix-Valued Time Series</p></a></li>
<li><a href='#mplot.acf'><p>Plot ACF of Matrix-Valued Time Series</p></a></li>
<li><a href='#predict.tenAR'><p>Predict funcions for Tensor Autoregressive Models</p></a></li>
<li><a href='#taxi.sim.AR'><p>Simulate taxi data by tenAR models</p></a></li>
<li><a href='#taxi.sim.FM'><p>Simulate taxi data by factor models</p></a></li>
<li><a href='#tenAR.est'><p>Estimation for Autoregressive Model of Tensor-Valued Time Series</p></a></li>
<li><a href='#tenAR.sim'><p>Generate TenAR(p) tensor time series</p></a></li>
<li><a href='#tenFM.est'><p>Estimation for Tucker structure Factor Models of Tensor-Valued Time Series</p></a></li>
<li><a href='#tenFM.rank'><p>Rank Determination for Tensor Factor Models with Tucker Structure</p></a></li>
<li><a href='#tenFM.sim'><p>Generate Tensor Time series using given Factor Process and Factor Loading Matrices</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Factor and Autoregressive Models for Tensor Time Series</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Factor and autoregressive models for matrix and tensor valued time series. We provide functions for estimation, simulation and prediction. The models are discussed in 
    Li et al (2021) &lt;<a href="https://doi.org/10.48550%2FarXiv.2110.00928">doi:10.48550/arXiv.2110.00928</a>&gt;, Chen et al (2020) &lt;<a href="https://doi.org/10.1080%2F01621459.2021.1912757">doi:10.1080/01621459.2021.1912757</a>&gt;, 
    Chen et al (2020) &lt;<a href="https://doi.org/10.1016%2Fj.jeconom.2020.07.015">doi:10.1016/j.jeconom.2020.07.015</a>&gt;, and Xiao et al (2020) &lt;<a href="https://doi.org/10.48550%2FarXiv.2006.02611">doi:10.48550/arXiv.2006.02611</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>tensor, rTensor, expm, methods, stats, MASS, abind, Matrix,
pracma, graphics</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/zebang/tensorTS">https://github.com/zebang/tensorTS</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ZeBang/tensorTS/issues">https://github.com/ZeBang/tensorTS/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-27 12:01:12 UTC; zeban</td>
</tr>
<tr>
<td>Author:</td>
<td>Zebang Li [aut, cre],
  Ruofan Yu [aut],
  Rong Chen [aut],
  Yuefeng Han [aut],
  Han Xiao [aut],
  Dan Yang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Zebang Li &lt;zl326@stat.rutgers.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-27 12:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='matAR.RR.est'>Estimation for Reduced Rank MAR(1) Model</h2><span id='topic+matAR.RR.est'></span>

<h3>Description</h3>

<p>Estimation of the reduced rank MAR(1) model, using least squares (RRLSE) or MLE (RRMLE), as determined by the value of <code>method</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matAR.RR.est(xx, method, A1.init=NULL, A2.init=NULL,Sig1.init=NULL,Sig2.init=NULL,
k1=NULL, k2=NULL, niter=200,tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matAR.RR.est_+3A_xx">xx</code></td>
<td>
<p><code class="reqn">T \times d_1 \times d_2</code> matrix-valued time series, <code class="reqn">T</code> is the length of the series.</p>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_method">method</code></td>
<td>
<p>character string, specifying the method of the estimation to be used. </p>

<dl>
<dt><code>"RRLSE",</code></dt><dd><p>Least squares.</p>
</dd>
<dt><code>"RRMLE",</code></dt><dd><p>MLE under a separable cov(vec(<code class="reqn">E_t</code>)).</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_a1.init">A1.init</code></td>
<td>
<p>initial value of <code class="reqn">A_1</code>. The default is the identity matrix.</p>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_a2.init">A2.init</code></td>
<td>
<p>initial value of <code class="reqn">A_2</code>. The default is the identity matrix.</p>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_sig1.init">Sig1.init</code></td>
<td>
<p>only if <code>method=RRMLE</code>, initial value of <code class="reqn">\Sigma_1</code>. The default is the identity matrix.</p>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_sig2.init">Sig2.init</code></td>
<td>
<p>only if <code>method=RRMLE</code>, initial value of <code class="reqn">\Sigma_2</code>. The default is the identity matrix.</p>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_k1">k1</code></td>
<td>
<p>rank of <code class="reqn">A_1</code>, a positive integer.</p>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_k2">k2</code></td>
<td>
<p>rank of <code class="reqn">A_2</code>, a positive integer.</p>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_niter">niter</code></td>
<td>
<p>maximum number of iterations if error stays above <code>tol</code>.</p>
</td></tr>
<tr><td><code id="matAR.RR.est_+3A_tol">tol</code></td>
<td>
<p>relative Frobenius norm error tolerance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reduced rank MAR(1) model takes the form:
</p>
<p style="text-align: center;"><code class="reqn">X_t =  A_1 X_{t-1} A_2^{^\top} + E_t,</code>
</p>

<p>where <code class="reqn">A_i</code> are <code class="reqn">d_i \times d_i</code> coefficient matrices of ranks <code class="reqn">\mathrm{rank}(A_i) = k_i \le d_i</code>, <code class="reqn">i=1,2</code>. For the MLE method we also assume
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Cov}(\mathrm{vec}(E_t))=\Sigma_2 \otimes \Sigma_1</code>
</p>



<h3>Value</h3>

<p>return a list containing the following:</p>

<dl>
<dt><code>A1</code></dt><dd><p>estimator of <code class="reqn">A_1</code>, a <code class="reqn">d_1</code> by <code class="reqn">d_1</code> matrix.</p>
</dd>
<dt><code>A2</code></dt><dd><p>estimator of <code class="reqn">A_2</code>, a <code class="reqn">d_2</code> by <code class="reqn">d_2</code> matrix.</p>
</dd>
<dt><code>loading</code></dt><dd><p>a list of estimated <code class="reqn">U_i</code>, <code class="reqn">V_i</code>, 
where we write <code class="reqn">A_i=U_iD_iV_i</code> as the singular value decomposition (SVD) of <code class="reqn">A_i</code>, <code class="reqn">i = 1,2</code>.</p>
</dd>
<dt><code>Sig1</code></dt><dd><p>only if <code>method=MLE</code>, when <code class="reqn">\mathrm{Cov}(\mathrm{vec}(E_t))=\Sigma_2 \otimes \Sigma_1</code>.</p>
</dd>
<dt><code>Sig2</code></dt><dd><p>only if <code>method=MLE</code>, when <code class="reqn">\mathrm{Cov}(\mathrm{vec}(E_t))=\Sigma_2 \otimes \Sigma_1</code>.</p>
</dd>
<dt><code>res</code></dt><dd><p>residuals.</p>
</dd>
<dt><code>Sig</code></dt><dd><p>sample covariance matrix of the residuals vec(<code class="reqn">\hat E_t</code>).</p>
</dd>
<dt><code>cov</code></dt><dd><p>a list containing </p>

<dl>
<dt><code>Sigma</code></dt><dd><p>asymptotic covariance matrix of (vec( <code class="reqn">\hat A_1</code>),vec(<code class="reqn">\hat A_2^{\top}</code>)).</p>
</dd>
<dt><code>Theta1.u</code>, <code>Theta1.v</code></dt><dd><p>asymptotic covariance matrix of vec(<code class="reqn">\hat U_1</code>), vec(<code class="reqn">\hat V_1</code>).</p>
</dd>
<dt><code>Theta2.u</code>, <code>Theta2.v</code></dt><dd><p>asymptotic covariance matrix of vec(<code class="reqn">\hat U_2</code>), vec(<code class="reqn">\hat V_2</code>).</p>
</dd>
</dl>
</dd>
<dt><code>sd.A1</code></dt><dd><p>element-wise standard errors of <code class="reqn">\hat A_1</code>, aligned with <code>A1</code>.</p>
</dd>
<dt><code>sd.A2</code></dt><dd><p>element-wise standard errors of <code class="reqn">\hat A_2</code>, aligned with <code>A2</code>.</p>
</dd>
<dt><code>niter</code></dt><dd><p>number of iterations.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>value of the extended Bayesian information criterion.</p>
</dd>
</dl>



<h3>References</h3>

<p>Reduced Rank Autoregressive Models for Matrix Time Series, by Han Xiao, Yuefeng Han, Rong Chen and Chengcheng Liu.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(333)
dim &lt;- c(3,3)
xx &lt;- tenAR.sim(t=500, dim, R=2, P=1, rho=0.5, cov='iid')
est &lt;- matAR.RR.est(xx, method="RRLSE", k1=1, k2=1)
</code></pre>

<hr>
<h2 id='matAR.RR.se'>Asymptotic Covariance Matrix of One-Term Reduced rank MAR(1) Model</h2><span id='topic+matAR.RR.se'></span>

<h3>Description</h3>

<p>Asymptotic covariance matrix of the reduced rank MAR(1) model. If <code>Sigma1</code> and <code>Sigma2</code> is provided in input,
we assume a separable covariance matrix, Cov(vec(<code class="reqn">E_t</code>)) = <code class="reqn">\Sigma_2 \otimes \Sigma_1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matAR.RR.se(A1,A2,k1,k2,method,Sigma.e=NULL,Sigma1=NULL,Sigma2=NULL,RU1=diag(k1),
RV1=diag(k1),RU2=diag(k2),RV2=diag(k2),mpower=100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matAR.RR.se_+3A_a1">A1</code></td>
<td>
<p>left coefficient matrix.</p>
</td></tr>
<tr><td><code id="matAR.RR.se_+3A_a2">A2</code></td>
<td>
<p>right coefficient matrix.</p>
</td></tr>
<tr><td><code id="matAR.RR.se_+3A_k1">k1</code></td>
<td>
<p>rank of <code class="reqn">A_1</code>.</p>
</td></tr>
<tr><td><code id="matAR.RR.se_+3A_k2">k2</code></td>
<td>
<p>rank of <code class="reqn">A_2</code>.</p>
</td></tr>
<tr><td><code id="matAR.RR.se_+3A_method">method</code></td>
<td>
<p>character string, specifying the method of the estimation to be used. </p>

<dl>
<dt><code>"RRLSE",</code></dt><dd><p>Least squares.</p>
</dd>
<dt><code>"RRMLE",</code></dt><dd><p>MLE under a separable cov(vec(<code class="reqn">E_t</code>)).</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="matAR.RR.se_+3A_sigma.e">Sigma.e</code></td>
<td>
<p>only if <code>method</code> = &quot;RRLSE&quot;. Cov(vec(<code class="reqn">E_t</code>)) = Sigma.e: covariance matrix of dimension <code class="reqn">(d_1 d_2) \times (d_1 d_2)</code></p>
</td></tr>
<tr><td><code id="matAR.RR.se_+3A_sigma1">Sigma1</code>, <code id="matAR.RR.se_+3A_sigma2">Sigma2</code></td>
<td>
<p>only if <code>method</code> = &quot;RRMLE&quot;. Cov(vec(<code class="reqn">E_t</code>)) = <code class="reqn">\Sigma_2 \otimes \Sigma_1</code>. <code class="reqn">\Sigma_i</code> is <code class="reqn">d_i \times d_i</code>, <code class="reqn">i=1,2</code>.</p>
</td></tr>
<tr><td><code id="matAR.RR.se_+3A_ru1">RU1</code>, <code id="matAR.RR.se_+3A_rv1">RV1</code>, <code id="matAR.RR.se_+3A_ru2">RU2</code>, <code id="matAR.RR.se_+3A_rv2">RV2</code></td>
<td>
<p>orthogonal rotations of <code class="reqn">U_1,V_1,U_2,V_2</code>, e.g., new_U1=U1 <code>RU1</code>.</p>
</td></tr>
<tr><td><code id="matAR.RR.se_+3A_mpower">mpower</code></td>
<td>
<p>truncate the VMA(<code class="reqn">\infty</code>) representation of vec(<code class="reqn">X_t</code>) at <code>mpower</code> for the purpose of calculating the autocovariances. The default is 100.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following:</p>

<dl>
<dt><code>Sigma</code></dt><dd><p>asymptotic covariance matrix of (vec(<code class="reqn">\hat A_1</code>),vec(<code class="reqn">\hat A_2^T</code>)).</p>
</dd>
<dt><code>Theta1.u</code></dt><dd><p>asymptotic covariance matrix of vec(<code class="reqn">\hat U_1</code>).</p>
</dd>
<dt><code>Theta1.v</code></dt><dd><p>asymptotic covariance matrix of vec(<code class="reqn">\hat V_1</code>).</p>
</dd>
<dt><code>Theta2.u</code></dt><dd><p>asymptotic covariance matrix of vec(<code class="reqn">\hat U_2</code>).</p>
</dd>
<dt><code>Theta2.v</code></dt><dd><p>asymptotic covariance matrix of vec(<code class="reqn">\hat V_2</code>).</p>
</dd>
</dl>



<h3>References</h3>

<p>Han Xiao, Yuefeng Han, Rong Chen and Chengcheng Liu, Reduced Rank Autoregressive Models for Matrix Time Series.
</p>

<hr>
<h2 id='mplot'>Plot Matrix-Valued Time Series</h2><span id='topic+mplot'></span>

<h3>Description</h3>

<p>Plot matrix-valued time series, can be also used to plot a given slice of a tensor-valued time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplot(xx)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplot_+3A_xx">xx</code></td>
<td>
<p><code class="reqn">T \times d_1 \times d_2</code> matrix-valued time series. Note that the number of mode is 3, where the first mode is time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a figure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dim &lt;- c(3,3,3)
xx &lt;- tenAR.sim(t=50, dim, R=2, P=1, rho=0.5, cov='iid')
mplot(xx[1:30,,,1])
</code></pre>

<hr>
<h2 id='mplot.acf'>Plot ACF of Matrix-Valued Time Series</h2><span id='topic+mplot.acf'></span>

<h3>Description</h3>

<p>Plot ACF of matrix-valued time series, can be also used to plot ACF of a given slice of a tensor-valued time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mplot.acf(xx)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mplot.acf_+3A_xx">xx</code></td>
<td>
<p><code class="reqn">T \times d_1 \times d_2</code> matrix-valued time series. Note that the number of mode is 3, where the first mode is time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a figure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dim &lt;- c(3,3,3)
xx &lt;- tenAR.sim(t=50, dim, R=2, P=1, rho=0.5, cov='iid')
mplot.acf(xx[1:30,,,1])
</code></pre>

<hr>
<h2 id='predict.tenAR'>Predict funcions for Tensor Autoregressive Models</h2><span id='topic+predict.tenAR'></span>

<h3>Description</h3>

<p>S3 method for the 'tenAR' class using the generic predict function. Prediction based on the tensor autoregressive model or reduced rank MAR(1) model. If <code>rolling = TRUE</code>, returns the rolling forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tenAR'
predict(object, n.ahead = 1, xx = NULL, rolling = FALSE, n0 = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.tenAR_+3A_object">object</code></td>
<td>
<p>a model object returned by <code>tenAR.est()</code>.</p>
</td></tr>
<tr><td><code id="predict.tenAR_+3A_n.ahead">n.ahead</code></td>
<td>
<p>prediction horizon.</p>
</td></tr>
<tr><td><code id="predict.tenAR_+3A_xx">xx</code></td>
<td>
<p><code class="reqn">T^{\prime} \times d_1 \times \cdots \times d_K</code> new tensor time series to be used for prediction. Must have at least <code>n.ahead</code> length.</p>
</td></tr>
<tr><td><code id="predict.tenAR_+3A_rolling">rolling</code></td>
<td>
<p>TRUE or FALSE, rolling forecast, is FALSE by default.</p>
</td></tr>
<tr><td><code id="predict.tenAR_+3A_n0">n0</code></td>
<td>
<p>only if <code>rolling = TRUE</code>, the starting point of rolling forecast.</p>
</td></tr>
<tr><td><code id="predict.tenAR_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tensor time series of length <code>n.ahead</code> if <code>rolling = FALSE</code>;
</p>
<p>a tensor time series of length <code class="reqn">T^{\prime} - n_0 - n.ahead + 1</code> if <code>rolling = TRUE</code>.
</p>


<h3>See Also</h3>

<p>'predict.ar' or 'predict.arima'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(333)
dim &lt;- c(2,2,2)
t = 20
xx &lt;- tenAR.sim(t, dim, R=2, P=1, rho=0.5, cov='iid')
est &lt;- tenAR.est(xx, R=1, P=1, method="LSE")
pred &lt;- predict(est, n.ahead = 1)
# rolling forcast
n0 = t - min(50,t/2)
pred.rolling &lt;- predict(est, n.ahead = 5, xx = xx, rolling=TRUE, n0)

# prediction for reduced rank MAR(1) model
dim &lt;- c(2,2)
t = 20
xx &lt;- tenAR.sim(t, dim, R=1, P=1, rho=0.5, cov='iid')
est &lt;- matAR.RR.est(xx, method="RRLSE", k1=1, k2=1)
pred &lt;- predict(est, n.ahead = 1)
# rolling forcast
n0 = t - min(50,t/2)
pred.rolling &lt;- predict(est, n.ahead = 5, rolling=TRUE, n0=n0)
</code></pre>

<hr>
<h2 id='taxi.sim.AR'>Simulate taxi data by tenAR models</h2><span id='topic+taxi.sim.AR'></span>

<h3>Description</h3>

<p>Simulate tensor time series by autoregressive models, using estimated coefficients by taxi data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>taxi.sim.AR(t, print.tar.coef=FALSE, print.sig=FALSE, seed=123)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="taxi.sim.AR_+3A_t">t</code></td>
<td>
<p>length of output series.</p>
</td></tr>
<tr><td><code id="taxi.sim.AR_+3A_print.tar.coef">print.tar.coef</code></td>
<td>
<p>print coefficients, default FALSE.</p>
</td></tr>
<tr><td><code id="taxi.sim.AR_+3A_print.sig">print.sig</code></td>
<td>
<p>print covariance matrices, default FALSE.</p>
</td></tr>
<tr><td><code id="taxi.sim.AR_+3A_seed">seed</code></td>
<td>
<p>random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor-valued time series of dimension (5,5,7).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+taxi.sim.FM">taxi.sim.FM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xx = taxi.sim.AR(t=753)
</code></pre>

<hr>
<h2 id='taxi.sim.FM'>Simulate taxi data by factor models</h2><span id='topic+taxi.sim.FM'></span>

<h3>Description</h3>

<p>Simulate tensor time series by factor models, using estimated coefficients by taxi data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>taxi.sim.FM(t, print.tar.coef=FALSE, print.loading=FALSE, seed=216)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="taxi.sim.FM_+3A_t">t</code></td>
<td>
<p>length of output series.</p>
</td></tr>
<tr><td><code id="taxi.sim.FM_+3A_print.tar.coef">print.tar.coef</code></td>
<td>
<p>print coefficients used for simulation, default FALSE.</p>
</td></tr>
<tr><td><code id="taxi.sim.FM_+3A_print.loading">print.loading</code></td>
<td>
<p>print loading matrices used for simulation, default FALSE.</p>
</td></tr>
<tr><td><code id="taxi.sim.FM_+3A_seed">seed</code></td>
<td>
<p>random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor-valued time series of dimension (4,4,3).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+taxi.sim.AR">taxi.sim.AR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xx = taxi.sim.FM(t=252)
</code></pre>

<hr>
<h2 id='tenAR.est'>Estimation for Autoregressive Model of Tensor-Valued Time Series</h2><span id='topic+tenAR.est'></span>

<h3>Description</h3>

<p>Estimation function for tensor autoregressive models. Methods include
projection (PROJ), Least Squares (LSE), maximum likelihood estimation (MLE)
and vector autoregressive model (VAR), as determined by the value of <code>method</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tenAR.est(xx,R=1,P=1,method="LSE",init.A=NULL,init.sig=NULL,niter=150,tol=1e-6)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tenAR.est_+3A_xx">xx</code></td>
<td>
<p><code class="reqn">T \times d_1 \times \cdots \times d_K</code> tensor-valued time series, <code class="reqn">T</code> is the length of the series.</p>
</td></tr>
<tr><td><code id="tenAR.est_+3A_r">R</code></td>
<td>
<p>Kronecker rank for each lag, a vector for <code class="reqn">P&gt;1</code>, a positive integer, it assumes same number of terms in each lag.</p>
</td></tr>
<tr><td><code id="tenAR.est_+3A_p">P</code></td>
<td>
<p>Autoregressive order, a positive integer.</p>
</td></tr>
<tr><td><code id="tenAR.est_+3A_method">method</code></td>
<td>
<p>character string, specifying the type of the estimation method to be used. </p>

<dl>
<dt><code>"PROJ",</code></dt><dd><p>Projection method.</p>
</dd>
<dt><code>"LSE",</code></dt><dd><p>Least squares.</p>
</dd>
<dt><code>"MLE",</code></dt><dd><p>MLE under a separable cov(vec(<code class="reqn">E_t</code>)).</p>
</dd>
<dt><code>"VAR",</code></dt><dd><p>VAR(<code class="reqn">P</code>) model for the <code class="reqn">\mathrm{vec}(E_t)</code>.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="tenAR.est_+3A_init.a">init.A</code></td>
<td>
<p>initial values of coefficient matrices <code class="reqn">A_k^{(ir)}</code> in estimation algorithms, which is a multi-layer list such that
the first layer for the lag <code class="reqn">1 \le i \le P</code>, the second the term <code class="reqn">1 \le r \le R</code>, and the third the mode <code class="reqn">1 \le k \le K</code>.
See &quot;Details&quot;. By default, we use PROJ estimators as initial values.</p>
</td></tr>
<tr><td><code id="tenAR.est_+3A_init.sig">init.sig</code></td>
<td>
<p>only if <code>method=MLE</code>, a list of initial values of <code class="reqn">\Sigma_1,\ldots,\Sigma_K</code>. The default are identity matrices.</p>
</td></tr>
<tr><td><code id="tenAR.est_+3A_niter">niter</code></td>
<td>
<p>maximum number of iterations if error stays above <code>tol</code>.</p>
</td></tr>
<tr><td><code id="tenAR.est_+3A_tol">tol</code></td>
<td>
<p>error tolerance in terms of the Frobenius norm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tensor autoregressive model (of autoregressive order one) has the form:
</p>
<p style="text-align: center;"><code class="reqn">X_t = \sum_{r=1}^R X_{t-1} \times_{1}  A_1^{(r)} \times_{2}  \cdots \times_{K} A_K^{(r)} + E_t,</code>
</p>

<p>where <code class="reqn">A_k^{(r)}</code> are <code class="reqn">d_k \times d_k</code> coefficient matrices, <code class="reqn">k=1,\cdots,K</code>, and <code class="reqn">E_t</code> is a tensor white noise. <code class="reqn">R</code> is the Kronecker rank.
The model of autoregressive order <code class="reqn">P</code> takes the form
</p>
<p style="text-align: center;"><code class="reqn">X_t = \sum_{i=1}^{P} \sum_{r=1}^{R_i} X_{t-i} \times_{1} A_{1}^{(ir)} \times_{2}  \cdots \times_{K} A_{K}^{(ir)} + E_t.</code>
</p>

<p>For the &quot;MLE&quot; method, we also assume,
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Cov}(\mathrm{vec}(E_t))= \Sigma_K \otimes \Sigma_{K-1} \otimes \cdots \otimes \Sigma_1,</code>
</p>



<h3>Value</h3>

<p>return a list containing the following:</p>

<dl>
<dt><code>A</code></dt><dd><p>a list of estimated coefficient matrices <code class="reqn">A_k^{(ir)}</code>. It is a multi-layer list,
the first layer for the lag <code class="reqn">1 \le i \le P</code>, the second the term <code class="reqn">1 \le r \le R</code>, and the third the mode <code class="reqn">1 \le k \le K</code>. See &quot;Details&quot;.</p>
</dd>
<dt><code>SIGMA</code></dt><dd><p>only if <code>method=MLE</code>, a list of estimated <code class="reqn">\Sigma_1,\ldots,\Sigma_K</code>.</p>
</dd>
<dt><code>res</code></dt><dd><p>residuals</p>
</dd>
<dt><code>Sig</code></dt><dd><p>sample covariance matrix of the residuals vec(<code class="reqn">\hat E_t</code>).</p>
</dd>
<dt><code>cov</code></dt><dd><p>grand covariance matrix of all estimated entries of <code class="reqn">A_k^{(ir)}</code></p>
</dd>
<dt><code>sd</code></dt><dd><p>standard errors of the coefficient matrices <code class="reqn">A_k^{(ir)}</code>, returned as a list aligned with <code>A</code>.</p>
</dd>
<dt><code>niter</code></dt><dd><p>number of iterations.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>value of extended Bayesian information criterion.</p>
</dd>
</dl>



<h3>References</h3>

<p>Rong Chen, Han Xiao, and Dan Yang. &quot;Autoregressive models for matrix-valued time series&quot;. Journal of Econometrics, 2020.
</p>
<p>Zebang Li, Han Xiao. &quot;Multi-linear tensor autoregressive models&quot;. arxiv preprint arxiv:2110.00928 (2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(333)

# case 1: tensor-valued time series

dim &lt;- c(2,2,2)
xx &lt;- tenAR.sim(t=100, dim, R=2, P=1, rho=0.5, cov='iid')
est &lt;- tenAR.est(xx, R=2, P=1, method="LSE") # two-term tenAR(1) model
A &lt;- est$A # A is a multi-layer list

length(A) == 1 # TRUE, since the order P = 1
length(A[[1]]) == 2 # TRUE, since the number of terms R = 2
length(A[[1]][[1]]) == 3 # TRUE, since the mode K = 3

# est &lt;- tenAR.est(xx, R=c(1,2), P=2, method="LSE") # tenAR(2) model with R1=1, R2=2

# case 2: matrix-valued time series

dim &lt;- c(2,2)
xx &lt;- tenAR.sim(t=100, dim, R=2, P=1, rho=0.5, cov='iid')
est &lt;- tenAR.est(xx, R=2, P=1, method="LSE") # two-term MAR(1) model 
A &lt;- est$A # A is a multi-layer list

length(A) == 1 # TRUE, since the order P = 1
length(A[[1]]) == 2 # TRUE, since the number of terms R = 2
length(A[[1]][[1]]) == 2 # TRUE, since the mode K = 2
</code></pre>

<hr>
<h2 id='tenAR.sim'>Generate TenAR(p) tensor time series</h2><span id='topic+tenAR.sim'></span>

<h3>Description</h3>

<p>Simulate from the TenAR(p) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tenAR.sim(t, dim, R, P, rho, cov, A = NULL, Sig = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tenAR.sim_+3A_t">t</code></td>
<td>
<p>length of output series, a strictly positive integer.</p>
</td></tr>
<tr><td><code id="tenAR.sim_+3A_dim">dim</code></td>
<td>
<p>dimension of the tensor at each time.</p>
</td></tr>
<tr><td><code id="tenAR.sim_+3A_r">R</code></td>
<td>
<p>Kronecker rank for each lag.</p>
</td></tr>
<tr><td><code id="tenAR.sim_+3A_p">P</code></td>
<td>
<p>autoregressive order.</p>
</td></tr>
<tr><td><code id="tenAR.sim_+3A_rho">rho</code></td>
<td>
<p>spectral radius of coefficient matrix <code class="reqn">\Phi</code>.</p>
</td></tr>
<tr><td><code id="tenAR.sim_+3A_cov">cov</code></td>
<td>
<p>covariance matrix of the error term: diagonal (&quot;iid&quot;), separable (&quot;mle&quot;), random (&quot;svd&quot;).</p>
</td></tr>
<tr><td><code id="tenAR.sim_+3A_a">A</code></td>
<td>
<p>coefficient matrices. If not provided, they are randomly generated according to given <code>dim</code>, <code>R</code>, <code>P</code> and <code>rho</code>.
It is a multi-layer list, the first layer for the lag <code class="reqn">1 \le i \le P</code>, the second the term <code class="reqn">1 \le r \le R</code>, and the third the mode <code class="reqn">1 \le k \le K</code>.
See &quot;Details&quot; of <code><a href="#topic+tenAR.est">tenAR.est</a></code>.</p>
</td></tr>
<tr><td><code id="tenAR.sim_+3A_sig">Sig</code></td>
<td>
<p>only if <code>cov=mle</code>, a list of initial values of <code class="reqn">\Sigma_1,\ldots,\Sigma_K</code>. The default are identity matrices.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor-valued time series generated by the TenAR(p) model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tenFM.sim">tenFM.sim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
dim &lt;- c(3,3,3)
xx &lt;- tenAR.sim(t=500, dim, R=2, P=1, rho=0.5, cov='iid')
</code></pre>

<hr>
<h2 id='tenFM.est'>Estimation for Tucker structure Factor Models of Tensor-Valued Time Series</h2><span id='topic+tenFM.est'></span>

<h3>Description</h3>

<p>Estimation function for Tucker structure factor models of tensor-valued time series.
Two unfolding methods of the auto-covariance tensor, Time series Outer-Product Unfolding Procedure (TOPUP), Time series Inner-Product Unfolding Procedure (TIPUP),
are included, as determined by the value of <code>method</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tenFM.est(x,r,h0=1,method='TIPUP',iter=TRUE,tol=1e-4,maxiter=100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tenFM.est_+3A_x">x</code></td>
<td>
<p><code class="reqn">T \times d_1 \times \cdots \times d_K</code> tensor-valued time series.</p>
</td></tr>
<tr><td><code id="tenFM.est_+3A_r">r</code></td>
<td>
<p>input rank of factor tensor.</p>
</td></tr>
<tr><td><code id="tenFM.est_+3A_h0">h0</code></td>
<td>
<p>the number of lags used in auto-covariance tensor. If h0=0, covariance tensor is used.</p>
</td></tr>
<tr><td><code id="tenFM.est_+3A_method">method</code></td>
<td>
<p>character string, specifying the type of the estimation method to be used. </p>

<dl>
<dt><code>"TIPUP",</code></dt><dd><p>TIPUP method.</p>
</dd>
<dt><code>"TOPUP",</code></dt><dd><p>TOPUP method.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="tenFM.est_+3A_iter">iter</code></td>
<td>
<p>boolean, specifying using an iterative approach or an non-iterative approach.</p>
</td></tr>
<tr><td><code id="tenFM.est_+3A_tol">tol</code></td>
<td>
<p>tolerance in terms of the Frobenius norm.</p>
</td></tr>
<tr><td><code id="tenFM.est_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations if error stays above <code>tol</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tensor factor model with Tucker structure has the following form,
</p>
<p style="text-align: center;"><code class="reqn">X_t = F_t \times_{1} A_1 \times_{2} \cdots \times_{K} A_k + E_t,</code>
</p>

<p>where <code class="reqn">A_k</code> is the deterministic loading matrix of size <code class="reqn">d_k \times r_k</code> and <code class="reqn">r_k \ll d_k</code>,
the core tensor <code class="reqn">F_t</code> itself is a latent tensor factor process of dimension <code class="reqn">r_1 \times \cdots \times r_K</code>,
and the idiosyncratic noise tensor <code class="reqn">E_t</code> is uncorrelated (white) across time. Two estimation approaches, named TOPUP and TIPUP, are studied.
Time series Outer-Product Unfolding Procedure (TOPUP) are based on
</p>
<p style="text-align: center;"><code class="reqn"> {\rm{TOPUP}}_{k}(X_{1:T}) = \left(\sum_{t=h+1}^T \frac{{\rm{mat}}_{k}( X_{t-h}) \otimes {\rm{mat}}_k(X_t)} {T-h}, \ h=1,...,h_0 \right),</code>
</p>

<p>where <code class="reqn">h_0</code> is a predetermined positive integer, <code class="reqn">\otimes</code> is tensor product. Note that
<code class="reqn"> {\rm{TOPUP}}_k(\cdot)</code> is a function mapping a tensor time series to an order-5 tensor.
Time series Inner-Product Unfolding Procedure (TIPUP) replaces the tensor product in TOPUP with the inner product:
</p>
<p style="text-align: center;"><code class="reqn"> {\rm{TIPUP}}_k(X_{1:T})={\rm{mat}}_1\left(\sum_{t=h+1}^T \frac{{\rm{mat}}_k(X_{t-h}) {\rm{mat}}_k^\top(X_t)} {T-h}, \ h=1,...,h_0 \right).</code>
</p>



<h3>Value</h3>

<p>returns a list containing the following:</p>

<dl>
<dt><code>Ft</code></dt><dd><p>estimated factor processes of dimension <code class="reqn">T \times r_1 \times r_2 \times \cdots \times r_k</code>.</p>
</dd>
<dt><code>Ft.all</code></dt><dd><p>Summation of factor processes over time, of dimension <code class="reqn">r_1,r_2,\cdots,r_k</code>.</p>
</dd>
<dt><code>Q</code></dt><dd><p>a list of estimated factor loading matrices <code class="reqn">Q_1,Q_2,\cdots,Q_K</code>. </p>
</dd>
<dt><code>x.hat</code></dt><dd><p>fitted signal tensor, of dimension <code class="reqn">T \times d_1 \times d_2 \times \cdots \times d_k</code>.</p>
</dd>
<dt><code>niter</code></dt><dd><p>number of iterations.</p>
</dd>
<dt><code>fnorm.resid</code></dt><dd><p>Frobenius norm of residuals, divide the Frobenius norm of the original tensor.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chen, Rong, Dan Yang, and Cun-Hui Zhang. &quot;Factor models for high-dimensional tensor time series.&quot; Journal of the American Statistical Association (2021): 1-59.
</p>
<p>Han, Yuefeng, Rong Chen, Dan Yang, and Cun-Hui Zhang. &quot;Tensor factor model estimation by iterative projection.&quot; arXiv preprint arXiv:2006.02611 (2020).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(333)
dims &lt;- c(16,18,20) # dimensions of tensor time series
r &lt;- c(3,3,3)  # dimensions of factor series
Ft &lt;- tenAR.sim(t=100, dim=r, R=1, P=1, rho=0.9, cov='iid')
lambda &lt;- sqrt(prod(dims))
x &lt;- tenFM.sim(Ft,dims=dims,lambda=lambda,A=NULL,cov='iid') # generate t*dims tensor time series
result &lt;- tenFM.est(x,r,h0=1,iter=TRUE,method='TIPUP')  # Estimation
Ft &lt;- result$Ft
</code></pre>

<hr>
<h2 id='tenFM.rank'>Rank Determination for Tensor Factor Models with Tucker Structure</h2><span id='topic+tenFM.rank'></span>

<h3>Description</h3>

<p>Function for rank determination of tensor factor models with Tucker Structure.
Two unfolding methods of the auto-covariance tensor, Time series Outer-Product Unfolding Procedure (TOPUP), Time series Inner-Product Unfolding Procedure (TIPUP),
are included, as determined by the value of <code>method</code>.
Different penalty functions for the information criterion (IC) and the eigen ratio criterion (ER) can be used,
which should be specified by the value of <code>rank</code> and <code>penalty</code>. The information criterion resembles BIC in the vector factor model literature.
And the eigen ratio criterion is similar to the eigenvalue ratio based methods in the vector factor model literature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tenFM.rank(x,r=NULL,h0=1,rank='IC',method='TIPUP',inputr=FALSE,iter=TRUE,penalty=1,
delta1=0,tol=1e-4,maxiter=100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tenFM.rank_+3A_x">x</code></td>
<td>
<p><code class="reqn">T \times d_1 \times \cdots \times d_K</code> tensor-valued time series.</p>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_r">r</code></td>
<td>
<p>initial guess of the rank of factor tensor.</p>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_h0">h0</code></td>
<td>
<p>the number of lags used in auto-covariance tensor. If h0=0, covariance tensor is used.</p>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_rank">rank</code></td>
<td>
<p>character string, specifying the type of the rank determination method to be used. </p>

<dl>
<dt><code>"IC",</code></dt><dd><p>information criterion.</p>
</dd>
<dt><code>"ER",</code></dt><dd><p>eigen ratio criterion.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_method">method</code></td>
<td>
<p>character string, specifying the type of the factor estimation method to be used. </p>

<dl>
<dt><code>"TIPUP",</code></dt><dd><p>TIPUP method.</p>
</dd>
<dt><code>"TOPUP",</code></dt><dd><p>TOPUP method.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_inputr">inputr</code></td>
<td>
<p>boolean, if TRUE, always use initial guess rank r in each iteration; if FLASE, the rank will be updated in each iteration.</p>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_iter">iter</code></td>
<td>
<p>boolean, specifying using an iterative approach or a non-iterative approach.</p>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_penalty">penalty</code></td>
<td>
<p>takes value in <code class="reqn">1,2,3,4,5</code>, decides which penalty function to use for each tensor mode <code class="reqn">k</code>. Here <code class="reqn">\nu</code> is a tuning parameter defined in the argument &quot;<code>delta1</code>&quot;, and <code class="reqn">d=\prod_{i=1}^{K} d_k </code>.
</p>

<dl>
<dt>When</dt><dd><p><code>rank</code>= '<code>IC</code>':</p>
</dd>
<dt>if <code>penalty</code>=1,</dt><dd><p><code class="reqn">g_1= \frac{h_0 d^{2-2\nu}}{T}\log(\frac{dT}{d+T})</code>;</p>
</dd>
<dt>if <code>penalty</code>=2,</dt><dd><p><code class="reqn">g_2= h_0 d^{2-2\nu}(\frac{1}{T}+\frac{1}{d})\log(\frac{dT}{d+T})</code>;</p>
</dd>
<dt>if <code>penalty</code>=3,</dt><dd><p><code class="reqn">g_3= \frac{h_0 d^{2-2\nu}}{T} \log(\min{(d,T)})</code>;</p>
</dd>
<dt>if <code>penalty</code>=4,</dt><dd><p><code class="reqn">g_4= h_0 d^{2-2\nu}(\frac{1}{T}+\frac{1}{d})\log(\min{(d,T)})</code>;</p>
</dd>
<dt>if <code>penalty</code>=5,</dt><dd><p><code class="reqn">g_5= h_0 d^{2-2\nu}(\frac{1}{T}+\frac{1}{d})\log(\min{(d_k,T)})</code>.</p>
</dd>
<dt>When</dt><dd><p><code>rank</code>= '<code>ER</code>':</p>
</dd>
<dt>if <code>penalty</code>=1,</dt><dd><p><code class="reqn">h_1= c_0 h_0</code>;</p>
</dd>
<dt>if <code>penalty</code>=2,</dt><dd><p><code class="reqn">h_2= \frac{h_0 d^2}{T^2}</code>;</p>
</dd>
<dt>if <code>penalty</code>=3,</dt><dd><p><code class="reqn">h_3= \frac{h_0 d^2}{T^2 d_k^2}</code>;</p>
</dd>
<dt>if <code>penalty</code>=4,</dt><dd><p><code class="reqn">h_4= \frac{h_0 d^2}{T^2 d_k^2} + \frac{h_0 d_k^2}{T^2}</code>;</p>
</dd>
<dt>if <code>penalty</code>=5,</dt><dd><p><code class="reqn">h_5= \frac{h_0 d^2}{T^2 d_k^2} + \frac{h_0 dd_k^2}{T^2}</code>.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_delta1">delta1</code></td>
<td>
<p>weakest factor strength, a tuning parameter used for IC method only</p>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_tol">tol</code></td>
<td>
<p>tolerance in terms of the Frobenius norm.</p>
</td></tr>
<tr><td><code id="tenFM.rank_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations if error stays above <code>tol</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">W</code> be a <code class="reqn">p\times p</code> symmetric and non-negative definite matrix and <code class="reqn">\widehat{W}</code> be its sample version, <code class="reqn">{\hat\lambda}_j</code> be the eigenvalues of <code class="reqn">\widehat{W}</code>
such that <code class="reqn">{\hat\lambda}_1\geq {\hat\lambda}_2 \geq \cdots \hat{\lambda}_p</code>.
The rank determination methods using the information criterion (&quot;IC&quot;) and the eigen ratio criterion (&quot;ER&quot;) are defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">IC(\widehat{W}) = \mathrm{argmin}_{0\leq m \leq m^{*}} \left\{ \sum_{j=m+1}^{p} {\hat\lambda}_j + mg(\widehat{W}) \right\},</code>
</p>

<p style="text-align: center;"><code class="reqn">ER(\widehat{W}) = \mathrm{argmin}_{0\leq m \leq m^{*}} \left\{ \frac{{\hat\lambda}_{m+1}+h(\widehat{W})}{ {\hat\lambda}_m +h(\widehat{W})} \right\},</code>
</p>

<p>where <code class="reqn">m^{*}</code> is a predefined upper bound, <code class="reqn">g</code> and <code class="reqn">h</code> are some appropriate positive penalty functions. We have provided 5 choices for <code class="reqn">g</code> and <code class="reqn">h</code>;
see more details in the argument &quot;<code>penalty</code>&quot;.
For non-iterative TOPUP and TIPUP methods, <code class="reqn">\widehat{W}</code> is
<code class="reqn"> {\rm mat}_1({\rm{TOPUP}}_{k}(X_{1:T})) {\rm mat}_1({\rm{TOPUP}}_{k}(X_{1:T}))^\top </code> or
<code class="reqn"> ({\rm{TIPUP}}_{k}(X_{1:T})) ({\rm{TIPUP}}_{k}(X_{1:T}))^\top </code>, for each tensor mode <code class="reqn">k</code>, <code class="reqn">1\leq k \leq K</code>,
where <code class="reqn">{\rm{TOPUP}}_{k}(X_{1:T})</code> and <code class="reqn">{\rm{TIPUP}}_{k}(X_{1:T})</code> are defined in the Details section of the function <code><a href="#topic+tenFM.est">tenFM.est</a></code>.
For iterative TOPUP and TIPUP methods, we refer to the literature in the References section for more information.
</p>


<h3>Value</h3>

<p>return a list containing the following:</p>

<dl>
<dt><code>path</code></dt><dd><p>a <code class="reqn">K \times (\rm{niter}+1)</code> matrix of the estimated Tucker rank of the factor process as a path of the maximum number of iteration (<code class="reqn">\rm{niter}</code>) used. The first row is the estimated rank under non-iterative approach, the <code class="reqn">i+1</code>-th row is the estimated rank <code class="reqn">\hat r_1, \hat r_2, \cdots, \hat r_K</code> at <code class="reqn">(i)</code>-th iteration.</p>
</dd>
<dt><code>factor.num</code></dt><dd><p>final solution of the estimated Tucker rank of the factor process <code class="reqn">\hat r_1, \hat r_2, \cdots, \hat r_K</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Han, Yuefeng, Cun-Hui Zhang, and Rong Chen. &quot;Rank Determination in Tensor Factor Model.&quot; Available at SSRN 3730305 (2020).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(333)
dims &lt;- c(16,18,20) # dimensions of tensor time series
r &lt;- c(3,3,3)  # dimensions of factor series
Ft &lt;- tenAR.sim(t=100, dim=r, R=1, P=1, rho=0.9, cov='iid')
lambda &lt;- sqrt(prod(dims))
x &lt;- tenFM.sim(Ft,dims=dims,lambda=lambda,A=NULL,cov='iid') # generate t*dims tensor time series
rank &lt;- tenFM.rank(x,r=c(4,4,4),h0=1,rank='IC',iter=TRUE,method='TIPUP')  # Estimate the rank
</code></pre>

<hr>
<h2 id='tenFM.sim'>Generate Tensor Time series using given Factor Process and Factor Loading Matrices</h2><span id='topic+tenFM.sim'></span>

<h3>Description</h3>

<p>Simulate tensor time series <code class="reqn">X_t</code> using a given factor process <code class="reqn">F_t</code>. The factor process <code class="reqn">F_t</code> can be generated by the function <code><a href="#topic+tenAR.sim">tenAR.sim</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tenFM.sim(Ft,dims=NULL,lambda=1,A=NULL,cov='iid',rho=0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tenFM.sim_+3A_ft">Ft</code></td>
<td>
<p>input of the factor process, of dimension <code class="reqn">T \times r_1 \times r_2 \times \cdots \times r_k</code>. It can be TenAR(p) tensor time series generated by the function <a href="#topic+tenAR.sim">tenAR.sim</a>.</p>
</td></tr>
<tr><td><code id="tenFM.sim_+3A_dims">dims</code></td>
<td>
<p>dimensions of the output tensor at each time,  <code class="reqn">d_1\times d_2\cdots\times d_K</code>.</p>
</td></tr>
<tr><td><code id="tenFM.sim_+3A_lambda">lambda</code></td>
<td>
<p>signal strength parameter of the tensor factor models, see Details section for more information.</p>
</td></tr>
<tr><td><code id="tenFM.sim_+3A_a">A</code></td>
<td>
<p>a list of the factor loading matrices <code class="reqn">A_1, A_2, \cdots, A_K</code>. The default is random orthogonal matrices <code class="reqn">A_k</code> of dimension <code class="reqn">d_k \times r_k</code>.</p>
</td></tr>
<tr><td><code id="tenFM.sim_+3A_cov">cov</code></td>
<td>
<p>covariance matrix of the error tensor: identity (&quot;iid&quot;), separable Kronecker structure (&quot;separable&quot;), random (&quot;random&quot;).</p>
</td></tr>
<tr><td><code id="tenFM.sim_+3A_rho">rho</code></td>
<td>
<p>a parameter only for &quot;separable&quot; covariance matrix of the error tensor. It is the off-diagonal element of the error matrices, with the diagonal being 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulate from the model :
</p>
<p style="text-align: center;"><code class="reqn">X_t = \lambda F_t \times_{1} A_1 \times_{2} \cdots \times_{K} A_k + E_t,</code>
</p>

<p>where <code class="reqn">A_k</code> is the deterministic loading matrix of size <code class="reqn">d_k \times r_k</code> and <code class="reqn">r_k \ll d_k</code>,
the core tensor <code class="reqn">F_t</code> itself is a latent tensor factor process of dimension <code class="reqn">r_1 \times \cdots \times r_K</code>,
<code class="reqn">\lambda</code> is an additional signal strength parameter,
and the idiosyncratic noise tensor <code class="reqn">E_t</code> is uncorrelated (white) across time. In this function, by default <code class="reqn">A_k</code> are orthogonal matrices.
</p>


<h3>Value</h3>

<p>A tensor-valued time series of dimension <code class="reqn">T\times d_1\times d_2\cdots\times d_K</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tenAR.sim">tenAR.sim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(333)
dims &lt;- c(16,18,20) # dimensions of tensor time series
r &lt;- c(3,3,3)  # dimensions of factor series
Ft &lt;- tenAR.sim(t=100, dim=r, R=1, P=1, rho=0.9, cov='iid')
lambda &lt;- sqrt(prod(dims))
# generate t*dims tensor time series with iid error covaraince structure
x &lt;- tenFM.sim(Ft,dims=dims,lambda=lambda,A=NULL,cov='iid')
# generate t*dims tensor time series with separable error covaraince structure
x &lt;- tenFM.sim(Ft,dims=dims,lambda=lambda,A=NULL,cov='separable',rho=0.2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
