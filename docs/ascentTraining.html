<!DOCTYPE html><html lang="en"><head><title>Help for package ascentTraining</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ascentTraining}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ascentTraining-package'><p>Ascent Training Datasets</p></a></li>
<li><a href='#auto_mpg'><p>Auto MPG Data Set</p></a></li>
<li><a href='#bbc_articles'><p>BBC articles data</p></a></li>
<li><a href='#bbc_articles_full'><p>Full BBC Articles data</p></a></li>
<li><a href='#bbc_business_123'><p>BBC Business article data</p></a></li>
<li><a href='#bbc_politics_123'><p>BBC Politics article data</p></a></li>
<li><a href='#body_image'><p>Body image dataset</p></a></li>
<li><a href='#book_sections'><p>Gutenberg Project books dataset</p></a></li>
<li><a href='#boston'><p>Boston housing dataset</p></a></li>
<li><a href='#breast_cancer'><p>Wisconsin Diagnostic Breast Cancer (WDBC)</p></a></li>
<li><a href='#breast_cancer_clean_features'><p>Wisconsin Breast Cancer Database</p></a></li>
<li><a href='#breast_cancer_clean_target'><p>Wisconsin Breast Cancer Database</p></a></li>
<li><a href='#carriers'><p>Carrier data</p></a></li>
<li><a href='#commute'><p>R For Data Science tidytuesday commute dataset</p></a></li>
<li><a href='#demo_data'><p>Demographics data</p></a></li>
<li><a href='#dow_jones_data'><p>Dow Jones Index Data</p></a></li>
<li><a href='#drugs'><p>Repeated Measures Drug data</p></a></li>
<li><a href='#emax_data'><p>Data that can be used to fit or plot Emax models</p></a></li>
<li><a href='#emax_fun'><p>Function to calculate Emax</p></a></li>
<li><a href='#logistic_fun'><p>Function to fit logistic model</p></a></li>
<li><a href='#messy_data'><p>Messy clinical trial data</p></a></li>
<li><a href='#missing_pk'><p>Clinical trial data</p></a></li>
<li><a href='#pk_data'><p>Typical PK data</p></a></li>
<li><a href='#policy_data'><p>Insurance Policy Data</p></a></li>
<li><a href='#qtpk2'><p>Typical PK data</p></a></li>
<li><a href='#run_data'><p>An example of NONMEM run data</p></a></li>
<li><a href='#students'><p>Students simulated data</p></a></li>
<li><a href='#tube_data'><p>London Tube Performance data</p></a></li>
<li><a href='#x_iris'><p>Iris predictors data for Species classification</p></a></li>
<li><a href='#xp_data'><p>Typical NONMEM data</p></a></li>
<li><a href='#y_iris'><p>Iris class data for Species classification</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Ascent Training Datasets</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Datasets to be used primarily in conjunction with Ascent
    training materials but also for the book 'SAMS Teach Yourself R in 24 Hours' (ISBN: 978-0-672-33848-9).
    Version 1.0-7 is largely for use with the book; however, version 1.1 has a much greater focus on use with
    training materials, whilst retaining compatibility with the book.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.ascent.io/">https://www.ascent.io/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/HarryJAlexander/ascentTraining/issues">https://github.com/HarryJAlexander/ascentTraining/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-03-24 18:18:40 UTC; harry.alexander</td>
</tr>
<tr>
<td>Author:</td>
<td>Ascent [aut],
  Harry Alexander [aut, cre, ctb, dtc, rev]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Harry Alexander &lt;harry.alexander@ascent.io&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-27 07:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='ascentTraining-package'>Ascent Training Datasets</h2><span id='topic+ascentTraining-package'></span><span id='topic+ascentTraining'></span>

<h3>Description</h3>

<p>Datasets designed to be used in conjunction with Ascent training materials.
</p>


<h3>Details</h3>

<p>Datasets designed to be used in conjunction with Ascent training materials and 
book, SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9). The data covers a range 
of applications and has been collected together from a number of sources.
The airquality dataset, from the Core R datasets package is also provided in xlsx format
in the extdata directory of this package.
</p>


<h3>Author(s)</h3>

<p>Ascent
</p>
<p>Contact: Ascent <a href="mailto:rin24hours@mango-solutions.com">rin24hours@mango-solutions.com</a>
</p>

<hr>
<h2 id='auto_mpg'>Auto MPG Data Set</h2><span id='topic+auto_mpg'></span>

<h3>Description</h3>

<p>Data concerns city-cycle fuel consumption - revised from CMU StatLib library.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auto_mpg
</code></pre>


<h3>Format</h3>

<p>A matrix containing 398 observations and 10 attributes.
</p>

<dl>
<dt><code>mpg</code></dt><dd><p>Miles per gallon of the engine. Predictor attribute</p>
</dd>
<dt><code>cylinders</code></dt><dd><p>Number of cylinders in the engine</p>
</dd>
<dt><code>displacement</code></dt><dd><p>Engine displacement</p>
</dd>
<dt><code>horsepower</code></dt><dd><p>Horsepower of the car</p>
</dd>
<dt><code>weight</code></dt><dd><p>Weight of the car (lbs)</p>
</dd>
<dt><code>acceleration</code></dt><dd><p>Acceleration of the car (seconds taken for 0-60mph)</p>
</dd>
<dt><code>model_year</code></dt><dd><p>Model year of the car in the 1900s</p>
</dd>
<dt><code>origin</code></dt><dd><p>Car origin</p>
</dd>
<dt><code>make</code></dt><dd><p>Car manufacturer</p>
</dd>
<dt><code>car_name</code></dt><dd><p>Name of the car</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://archive.ics.uci.edu/ml/datasets/Auto+MPG
</p>


<h3>References</h3>

<p>Quinlan,R. (1993). Combining Instance-Based and Model-Based
Learning. In Proceedings on the Tenth International Conference of Machine
Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.
</p>

<hr>
<h2 id='bbc_articles'>BBC articles data</h2><span id='topic+bbc_articles'></span>

<h3>Description</h3>

<p>A collection of BBC news articles from the business or politics sections. There are a total of 927 articles used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbc_articles
</code></pre>


<h3>Format</h3>

<p>A tibble with 201,571 observations, each a word on a document.
</p>

<dl>
<dt><code>word</code></dt><dd><p>A word in an article</p>
</dd>
<dt><code>document</code></dt><dd><p>The document/article ID where the word was taken from</p>
</dd>
</dl>



<h3>Source</h3>

<ul>
<li><p><a href="https://www.bbc.co.uk/news">https://www.bbc.co.uk/news</a></p>
</li></ul>


<hr>
<h2 id='bbc_articles_full'>Full BBC Articles data</h2><span id='topic+bbc_articles_full'></span>

<h3>Description</h3>

<p>Full BBC Articles data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbc_articles_full
</code></pre>


<h3>Format</h3>

<p>A tibble, with 927 observations of separate documents and their contents. This results in two columns.
</p>

<dl>
<dt><code>words</code></dt><dd><p>The words from a given article</p>
</dd>
<dt><code>document</code></dt><dd><p>The 'document' (article) ID</p>
</dd>
</dl>



<h3>Details</h3>

<p>A collection of business and politics BBC news articles. Each row represents each article (document), 
with a document ID and a string of the text content with stop words removed. This is a 'dirty' version of the 
<code>bbc_articles</code> dataset, where we now have a string of text for each observation, as opposed to a single word.
</p>


<h3>Source</h3>

<ul>
<li><p><a href="https://www.bbc.co.uk/news">https://www.bbc.co.uk/news</a></p>
</li></ul>


<hr>
<h2 id='bbc_business_123'>BBC Business article data</h2><span id='topic+bbc_business_123'></span>

<h3>Description</h3>

<p>A single BBC Business article (not included in the full BBC articles dataset), given in tidy, one word per row format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbc_business_123
</code></pre>


<h3>Format</h3>

<p>A tibble with 107 observations, each a word on a document.
</p>

<dl>
<dt><code>word</code></dt><dd><p>A word in an article</p>
</dd>
<dt><code>document</code></dt><dd><p>The document/article ID where the word was taken from. Note: this only has one unique value, 
however the column is kept for comparison with other BBC datasets.</p>
</dd>
</dl>



<h3>Source</h3>

<ul>
<li><p><a href="https://www.bbc.co.uk/news">https://www.bbc.co.uk/news</a></p>
</li></ul>


<hr>
<h2 id='bbc_politics_123'>BBC Politics article data</h2><span id='topic+bbc_politics_123'></span>

<h3>Description</h3>

<p>A single BBC Politics article (not included in the full BBC articles dataset), given in tidy, one word per row format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbc_politics_123
</code></pre>


<h3>Format</h3>

<p>A tibble with 86 observations, each a word on a document.
</p>

<dl>
<dt><code>word</code></dt><dd><p>A word in an article</p>
</dd>
<dt><code>document</code></dt><dd><p>The document/article ID where the word was taken from. Note: this only has one unique value, 
however the column is kept for comparison with other BBC datasets.</p>
</dd>
</dl>



<h3>Source</h3>

<ul>
<li><p><a href="https://www.bbc.co.uk/news">https://www.bbc.co.uk/news</a></p>
</li></ul>


<hr>
<h2 id='body_image'>Body image dataset</h2><span id='topic+body_image'></span>

<h3>Description</h3>

<p>Body image dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>body_image
</code></pre>


<h3>Format</h3>

<p>A tibble of 246 observations on 8 attributes.
</p>

<dl>
<dt><code>ethnicity</code></dt><dd><p>Subject's ethnicity (Asian, Europn, Maori, Pacific)</p>
</dd>
<dt><code>married</code></dt><dd><p>How many times have they been married?</p>
</dd>
<dt><code>bodyim</code></dt><dd><p>Subject's rating of themselves (slight.uw, right, slight.ow, mod.ow, very.ow)</p>
</dd>
<dt><code>sm.ever</code></dt><dd><p>Have they ever smoked?</p>
</dd>
<dt><code>weight</code></dt><dd><p>Weight in kilograms</p>
</dd>
<dt><code>height</code></dt><dd><p>Height in centimetres</p>
</dd>
<dt><code>age</code></dt><dd><p>Age in years</p>
</dd>
<dt><code>stressgp</code></dt><dd><p>What stress group are they in?</p>
</dd>
</dl>



<h3>Details</h3>

<p>A simulated dataset containing data on the self-image of subjects with differing body aesthetics
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='book_sections'>Gutenberg Project books dataset</h2><span id='topic+book_sections'></span>

<h3>Description</h3>

<p>A mixed up collection of words from different book sections of two books.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>book_sections
</code></pre>


<h3>Format</h3>

<p>A tibble with 108,657 observations, each a word on a document. 
This data set is designed to show how LDA can be used to separate a set of 
mixed documents into two distinct &quot;topics&quot; (or books).
</p>

<dl>
<dt><code>word</code></dt><dd><p>Words from a given section within a book.</p>
</dd>
<dt><code>document</code></dt><dd><p>The book section ID that the word came from.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data taken from two books of the Gutenberg Project 
</p>
<ul>
<li><p><a href="https://www.gutenberg.org/">https://www.gutenberg.org/</a></p>
</li></ul>


<hr>
<h2 id='boston'>Boston housing dataset</h2><span id='topic+boston'></span>

<h3>Description</h3>

<p>Dataset containing housing values in the suburbs of Boston.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boston
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns: 
</p>

<dl>
<dt><code>tract</code></dt><dd><p>Census tract</p>
</dd>
<dt><code>medv</code></dt><dd><p>Median value of owner-occupied homes in $1,000s.  </p>
</dd>
<dt><code>crim</code></dt><dd><p>Per capita crime rate by town.</p>
</dd> 
<dt><code>zn</code></dt><dd><p>Proportion of residential land zoned for lots over 25,000 sq.ft.</p>
</dd>
<dt><code>indus</code></dt><dd><p>Proportion of non-retail business acres per town.  </p>
</dd>
<dt><code>chas</code></dt><dd><p>Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).  </p>
</dd> 
<dt><code>nox</code></dt><dd><p>Nitrogen oxides concentration (parts per 10 million).  </p>
</dd> 
<dt><code>rm</code></dt><dd><p>Average number of rooms per dwelling.  </p>
</dd> 
<dt><code>age</code></dt><dd><p>Proportion of owner-occupied units built prior to 1940.  </p>
</dd> 
<dt><code>dis</code></dt><dd><p>Weighted mean of distances to five Boston employment centres.  </p>
</dd> 
<dt><code>rad</code></dt><dd><p>Index of accessibility to radial highways.  </p>
</dd> 
<dt><code>tax</code></dt><dd><p>Full-value property-tax rate per $10,000.  </p>
</dd> 
<dt><code>ptratio</code></dt><dd><p>Pupil-teacher ratio by town.  </p>
</dd>
<dt><code>b</code></dt><dd><p><code class="reqn">1000(Bk - 0.63)^2</code> where <code class="reqn">Bk</code> is the proportion of blacks by town.  </p>
</dd> 
<dt><code>lstat</code></dt><dd><p>Lower status of the population (percent).  </p>
</dd> 
</dl>



<h3>Details</h3>

<p>The <code>boston</code> data frame has 506 rows and 15 columns.
</p>


<h3>Source</h3>

<p>Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the
demand for clean air.  <em>J. Environ. Economics and Management</em> <b>5</b>,
81&ndash;102.
</p>
<p>Belsley D.A., Kuh, E.  and Welsch, R.E. (1980) <em>Regression Diagnostics.
Identifying Influential Data and Sources of Collinearity.</em> New York: Wiley.
</p>

<hr>
<h2 id='breast_cancer'>Wisconsin Diagnostic Breast Cancer (WDBC)</h2><span id='topic+breast_cancer'></span>

<h3>Description</h3>

<p>The data contain measurements on cells in suspicious lumps in a women's
breast. Features are computed from a digitised image of a fine needle
aspirate (FNA) of a breast mass. They describe characteristics of the cell
nuclei present in the image. All samples are classified as either
<em>benign</em> or
<em>malignant</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>breast_cancer
</code></pre>


<h3>Format</h3>

<p><code>breast_cancer</code> is a <code>tibble</code> with 22 columns. The first column
is an ID column. The second indicates whether the sample is classified as benign or malignant.
The remaining columns contain measurements for 20 features. Ten real-valued features are computed
for each cell nucleus. The references listed below contain detailed descriptions of how these features
are computed.  The mean, and &quot;worst&quot; (or largest - mean of the three largest values) of these features were computed
for each image, resulting in 20 features. Below are descriptions of these features where *
should be replaced by either <code>mean</code> or <code>worst</code>.
</p>

<dl>
<dt><code>*_radius</code></dt><dd><p>mean of distances from center to points on the perimeter</p>
</dd>
<dt><code>*_texture</code></dt><dd><p>standard deviation of gray-scale values</p>
</dd>
<dt><code>*_perimeter</code></dt><dd><p>perimeter value</p>
</dd>
<dt><code>*_area</code></dt><dd><p>area value</p>
</dd>
<dt><code>*_smoothness</code></dt><dd><p>local variation in radius lengths</p>
</dd>
<dt><code>*_compactness</code></dt><dd><p>perimeter^2 / area - 1.0</p>
</dd>
<dt><code>*_concavity</code></dt><dd><p>severity of concave portions of the contour</p>
</dd>
<dt><code>*_concave_points</code></dt><dd><p>number of concave portions of the contour</p>
</dd>
<dt><code>*_symmetry</code></dt><dd><p>symmetry value</p>
</dd>
<dt><code>*_fractal_dimension</code></dt><dd><p>&quot;coastline approximation&quot; - 1</p>
</dd>
</dl>



<h3>Note</h3>

<p>This breast cancer database was obtained from the University of
Wisconsin Hospitals, Madison from Dr. William H. Wolberg.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)</a>
<br /> <br /> Bache, K. &amp; Lichman, M. (2013). UCI Machine Learning Repository.
Irvine, CA: University of California, School of Information and Computer
Science.
</p>


<h3>References</h3>

<p>O. L. Mangasarian and W. H. Wolberg: &quot;Cancer diagnosis via
linear programming&quot;,<br /> SIAM News, Volume 23, Number 5, September 1990, pp 1
&amp; 18. William H. Wolberg and O.L. Mangasarian: &quot;Multisurface method of
pattern separation for medical diagnosis applied to breast cytology&quot;, <br />
Proceedings of the National Academy of Sciences, U.S.A., Volume 87, December
1990, pp 9193-9196. K. P. Bennett &amp; O. L. Mangasarian: &quot;Robust linear
programming discrimination of two linearly inseparable sets&quot;,<br />
Optimization Methods and Software 1, 1992, 23-34 (Gordon &amp; Breach Science
Publishers).
</p>

<hr>
<h2 id='breast_cancer_clean_features'>Wisconsin Breast Cancer Database</h2><span id='topic+breast_cancer_clean_features'></span>

<h3>Description</h3>

<p>Wisconsin Breast Cancer Database
</p>


<h3>Usage</h3>

<pre><code class='language-R'>breast_cancer_clean_features
</code></pre>


<h3>Format</h3>

<p>A list containing a training and test dataset. These come from a data frame 
with 699 observations on 11 variables, however the ID and class columns have been removed. 
There is a train to test ratio of 0.8. 
</p>
 
<dl>
<dt><code>Cl.thickness</code></dt><dd><p>Clump Thickness</p>
</dd>
<dt><code>Cell.size</code></dt><dd><p>Uniformity of Cell Size</p>
</dd>
<dt><code>Cell.shape</code></dt><dd><p>Uniformity of Cell Shape</p>
</dd>
<dt><code>Marg.adhesion</code></dt><dd><p>Marginal Adhesion</p>
</dd>
<dt><code>Epith.c.size</code></dt><dd><p>Single Epithelial Cell Size</p>
</dd>
<dt><code>Bare.nuclei</code></dt><dd><p>Bare Nuclei</p>
</dd>
<dt><code>Bl.cromatin</code></dt><dd><p>Bland Chromatin</p>
</dd>
<dt><code>Normal.nucleoli</code></dt><dd><p>Normal Nucleoli</p>
</dd>
<dt><code>Mitoses</code></dt><dd><p>Mitoses</p>
</dd>
</dl>



<h3>Source</h3>

 <ul>
<li><p> Creator: Dr. WIlliam H. Wolberg (physician);
University of Wisconsin Hospital ;Madison; Wisconsin; USA 
</p>
</li>
<li><p> Donor: Olvi
Mangasarian (mangasarian@cs.wisc.edu) 
</p>
</li>
<li><p> Received: David W. Aha
(aha@cs.jhu.edu) </p>
</li></ul>
<p> These data have been taken from the UCI Repository Of
Machine Learning Databases at 
</p>
 <ul>
<li>
<p><a href="http://archive.ics.uci.edu/ml/datasets.php">http://archive.ics.uci.edu/ml/datasets.php</a> 
</p>
</li>
<li>
<p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a> 
</p>
</li></ul>
<p> and were converted
to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

<p>1. Wolberg,W.H., \&amp; Mangasarian,O.L. (1990). Multisurface method
of pattern separation for medical diagnosis applied to breast cytology. In
Proceedings of the National Academy of Sciences, 87, 9193-9196.<br /> - Size of
data set: only 369 instances (at that point in time)<br /> - Collected
classification results: 1 trial only<br /> - Two pairs of parallel hyperplanes
were found to be consistent with 50% of the data<br /> - Accuracy on remaining
50% of dataset: 93.5%<br /> - Three pairs of parallel hyperplanes were found
to be consistent with 67% of data<br /> - Accuracy on remaining 33% of
dataset: 95.9%
</p>
<p>2. Zhang,J. (1992). Selecting typical instances in instance-based learning.
In Proceedings of the Ninth International Machine Learning Conference (pp.
470-479).  Aberdeen, Scotland: Morgan Kaufmann.<br /> - Size of data set: only
369 instances (at that point in time)<br /> - Applied 4 instance-based learning
algorithms<br /> - Collected classification results averaged over 10 trials<br />
- Best accuracy result: <br /> - 1-nearest neighbor: 93.7%<br /> - trained on 200
instances, tested on the other 169<br /> - Also of interest:<br /> - Using only
typical instances: 92.2% (storing only 23.1 instances)<br /> - trained on 200
instances, tested on the other 169
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).  UCI
Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA: University
of California, Department of Information and Computer Science.
</p>

<hr>
<h2 id='breast_cancer_clean_target'>Wisconsin Breast Cancer Database</h2><span id='topic+breast_cancer_clean_target'></span>

<h3>Description</h3>

<p>Wisconsin Breast Cancer Database
</p>


<h3>Usage</h3>

<pre><code class='language-R'>breast_cancer_clean_target
</code></pre>


<h3>Format</h3>

<p>A list containing a training and test dataset. These come from a data frame 
with 699 observations on 11 variables, however only the target classes have been kept. 
There is a train to test ratio of 0.8. 
</p>
 
<dl>
<dt><code>Class.Benign</code></dt><dd><p>Whether the sample was classified as benign</p>
</dd>
<dt><code>Class.malignant</code></dt><dd><p>Whether the sample was classified as malignant</p>
</dd>
</dl>

<p>2. Zhang,J. (1992). Selecting typical instances in instance-based learning.
In Proceedings of the Ninth International Machine Learning Conference (pp.
470-479).  Aberdeen, Scotland: Morgan Kaufmann.<br /> - Size of data set: only
369 instances (at that point in time)<br /> - Applied 4 instance-based learning
algorithms<br /> - Collected classification results averaged over 10 trials<br />
- Best accuracy result: <br /> - 1-nearest neighbor: 93.7%<br /> - trained on 200
instances, tested on the other 169<br /> - Also of interest:<br /> - Using only
typical instances: 92.2% (storing only 23.1 instances)<br /> - trained on 200
instances, tested on the other 169
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).  UCI
Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA: University
of California, Department of Information and Computer Science.
</p>


<h3>Source</h3>

 <ul>
<li><p> Creator: Dr. WIlliam H. Wolberg (physician);
University of Wisconsin Hospital ;Madison; Wisconsin; USA </p>
</li>
<li><p> Donor: Olvi
Mangasarian (mangasarian@cs.wisc.edu) </p>
</li>
<li><p> Received: David W. Aha
(aha@cs.jhu.edu) </p>
</li></ul>
<p> These data have been taken from the UCI Repository Of
Machine Learning Databases at </p>
 <ul>
<li>
<p><a href="http://archive.ics.uci.edu/ml/datasets.php">http://archive.ics.uci.edu/ml/datasets.php</a> </p>
</li>
<li>
<p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a> </p>
</li></ul>
<p> and were converted
to R format by Evgenia Dimitriadou.
</p>

<hr>
<h2 id='carriers'>Carrier data</h2><span id='topic+carriers'></span>

<h3>Description</h3>

<p>This data comes from the RITA/Transtats database
</p>


<h3>Usage</h3>

<pre><code class='language-R'>carriers
</code></pre>


<h3>Format</h3>

<p>A dataframe with 1492 observations and 2 variables
</p>

<dl>
<dt><code>Code</code></dt><dd><p>A character string giving the IATA code for the carrier</p>
</dd>
<dt><code>Description</code></dt><dd><p>Carrier name/description</p>
</dd>
</dl>


<hr>
<h2 id='commute'>R For Data Science tidytuesday commute dataset</h2><span id='topic+commute'></span>

<h3>Description</h3>

<p>Data from the ACS Survey detailing the use of different transport modes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>commute
</code></pre>


<h3>Format</h3>

<p>A tibble containing 3,496 observations of 9 variables
</p>

<dl>
<dt><code>city</code></dt><dd><p>City</p>
</dd>
<dt><code>state</code></dt><dd><p>State</p>
</dd>
<dt><code>city_size</code></dt><dd><p>City Size - </p>
<ul>
<li><p> Small = 20K to 99,999 </p>
</li>
<li><p> Medium = 100K to 199,999 </p>
</li>
<li><p> Large = &gt;= 200K</p>
</li></ul>
</dd>
<dt><code>mode</code></dt><dd><p>Mode of transport, either walk or bike</p>
</dd>
<dt><code>n</code></dt><dd><p>Number of individuals</p>
</dd>
<dt><code>percent</code></dt><dd><p>Percent of total individuals</p>
</dd>
<dt><code>moe</code></dt><dd><p>Margin of Error (percent)</p>
</dd>
<dt><code>state_abb</code></dt><dd><p>Abbreviated state name</p>
</dd>
<dt><code>state_region</code></dt><dd><p>ACS State region</p>
</dd>
</dl>



<h3>Source</h3>

<p>American Community Survey, United States Census Bureau
</p>
<ul>
<li><p>R For Data Science repository: <a href="https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-11-05">https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-11-05</a>
</p>
</li>
<li><p>Article and underlying data can be found at: <a href="https://www.census.gov/library/publications/2014/acs/acs-25.html?#">https://www.census.gov/library/publications/2014/acs/acs-25.html?#</a>
</p>
</li></ul>


<hr>
<h2 id='demo_data'>Demographics data</h2><span id='topic+demo_data'></span><span id='topic+demoData'></span>

<h3>Description</h3>

<p>A simulated dataset containing demographic data about a number of subjects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>demo_data

demoData
</code></pre>


<h3>Format</h3>

<p>A data frame with 33 observations on the following 7 demographic variables. 
This data is designed so that it can be merged with the dataset pk_data. 
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>A numeric vector giving the subject identifier</p>
</dd>
<dt><code>Sex</code></dt><dd><p>A factor with levels <code>F</code> <code>M</code></p>
</dd>
<dt><code>Age</code></dt><dd><p>A numeric vector giving the age of the subject</p>
</dd>
<dt><code>Weight</code></dt><dd><p>A numeric vector giving weight in kg</p>
</dd>
<dt><code>Height</code></dt><dd><p>A numeric vector giving height in cm</p>
</dd>
<dt><code>BMI</code></dt><dd><p>A numeric vector giving the subject body mass index</p>
</dd>
<dt><code>Smokes</code></dt><dd><p>A factor with levels <code>No</code> <code>Yes</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='dow_jones_data'>Dow Jones Index Data</h2><span id='topic+dow_jones_data'></span><span id='topic+dowJonesData'></span>

<h3>Description</h3>

<p>Dataset containing the Dow Jones Index between 2014-01-01 and 2015-01-01, which is a stock market index that measures the stock performance of 30 large 
companies listed on stock exchanges in the United States.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dow_jones_data

dowJonesData
</code></pre>


<h3>Format</h3>

<p>A data frame with 252 observations on the following 7 variables containing data
from  2014-01-01 to 2015-01-01. 
</p>

<dl>
<dt><code>Date</code></dt><dd><p>Date of observation in character string format &quot;%m/%d/%Y&quot; </p>
</dd>
<dt><code>DJI.Open</code></dt><dd><p>Opening value of DJI on the specified date</p>
</dd>
<dt><code>DJI.High</code></dt><dd><p>High value of the DJI on the specified date</p>
</dd>
<dt><code>DJI.Low</code></dt><dd><p>Low value of the DJI on the specified date</p>
</dd>
<dt><code>DJI.Close</code></dt><dd><p>Closing value of the DJI on the specified date</p>
</dd>
<dt><code>DJI.Volume</code></dt><dd><p>the number of shares or contracts traded</p>
</dd>
<dt><code>DJI.Adj.Close</code></dt><dd><p>Close price adjusted for dividends and splits</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>Data obtained using <code>yahooSeries</code> from the <code>fImport</code> package.
</p>

<hr>
<h2 id='drugs'>Repeated Measures Drug data</h2><span id='topic+drugs'></span>

<h3>Description</h3>

<p>Repeated Measures Drug data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drugs
</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 3 variables.
</p>

<dl>
<dt><code>Subj</code></dt><dd><p>A numeric vector, giving the subject ID</p>
</dd>
<dt><code>Drug</code></dt><dd><p>A numeric vector giving the drug ID, numbered 1 to 4</p>
</dd>
<dt><code>Value</code></dt><dd><p>A numeric vector, giving the observation value</p>
</dd>
</dl>



<h3>Source</h3>

<p>Generated from example data used in <a href="https://www.stattutorials.com/SAS/TUTORIAL-PROC-GLM-REPEAT.htm">https://www.stattutorials.com/SAS/TUTORIAL-PROC-GLM-REPEAT.htm</a>
</p>

<hr>
<h2 id='emax_data'>Data that can be used to fit or plot Emax models</h2><span id='topic+emax_data'></span><span id='topic+emaxData'></span>

<h3>Description</h3>

<p>Data that can be used to fit or plot Emax models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emax_data

emaxData
</code></pre>


<h3>Format</h3>

<p>A data frame with 64 observations on the following 6 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a numeric vector giving the unique subject ID</p>
</dd>
<dt><code>Dose</code></dt><dd><p>a numeric vector giving the dose group</p>
</dd>
<dt><code>E</code></dt><dd><p>a numeric vector giving the Emax</p>
</dd>
<dt><code>Gender</code></dt><dd><p>a numeric vector giving the gender</p>
</dd>
<dt><code>Age</code></dt><dd><p>a numeric vector giving the age of the subject</p>
</dd>
<dt><code>Weight</code></dt><dd><p>a numeric vector giving the weight</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='emax_fun'>Function to calculate Emax</h2><span id='topic+emax_fun'></span>

<h3>Description</h3>

<p>Calculation used for Emax in Ascent materials. Note:  This function has be renamed using tidyverse-style snake_case
naming conventions. However the original name of the function has been kept to ensure backwards compatibility with the book SAMS
Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emax_fun(Dose, E0 = 0, ED50 = 50, Emax = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emax_fun_+3A_dose">Dose</code></td>
<td>
<p>User provided dose values</p>
</td></tr>
<tr><td><code id="emax_fun_+3A_e0">E0</code></td>
<td>
<p>Effect at time 0</p>
</td></tr>
<tr><td><code id="emax_fun_+3A_ed50">ED50</code></td>
<td>
<p>50% of maximum effect</p>
</td></tr>
<tr><td><code id="emax_fun_+3A_emax">Emax</code></td>
<td>
<p>Maximum effect</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value/vector representing the response value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>emax_fun(Dose = 100)

</code></pre>

<hr>
<h2 id='logistic_fun'>Function to fit logistic model</h2><span id='topic+logistic_fun'></span>

<h3>Description</h3>

<p>Simple logistic function as used in Ascent training materials. Note:  This function has be renamed using tidyverse-style snake_case
naming conventions. However the original name of the function has been kept to ensure backwards compatibility with the book SAMS
Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic_fun(Dose, E0 = 0, EC50 = 50, Emax = 1, rc = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logistic_fun_+3A_dose">Dose</code></td>
<td>
<p>The dose value to calculate at</p>
</td></tr>
<tr><td><code id="logistic_fun_+3A_e0">E0</code></td>
<td>
<p>Effect at time 0</p>
</td></tr>
<tr><td><code id="logistic_fun_+3A_ec50">EC50</code></td>
<td>
<p>50% of maximum effect</p>
</td></tr>
<tr><td><code id="logistic_fun_+3A_emax">Emax</code></td>
<td>
<p>Maximum effect</p>
</td></tr>
<tr><td><code id="logistic_fun_+3A_rc">rc</code></td>
<td>
<p>rate constant</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value/vector representing the response value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>logistic_fun(Dose = 50)

</code></pre>

<hr>
<h2 id='messy_data'>Messy clinical trial data</h2><span id='topic+messy_data'></span><span id='topic+messyData'></span>

<h3>Description</h3>

<p>Simulated dataset for examples of reshaping data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>messy_data

messyData
</code></pre>


<h3>Format</h3>

<p>A data frame with 33 observations on the following 7 variables. 
This data has been designed to show reshaping/tidying of data.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>A numeric vector giving the subject ID</p>
</dd>
<dt><code>Placebo.1</code></dt><dd><p>A numeric vector giving the subjects observed value on treatment Placebo at time 1</p>
</dd>
<dt><code>Placebo.2</code></dt><dd><p>A numeric vector giving the subjects observed value on treatment Placebo at time 2</p>
</dd>
<dt><code>Drug1.1</code></dt><dd><p>A numeric vector giving the subjects observed value on treatment Drug1 at time 1</p>
</dd>
<dt><code>Drug1.2</code></dt><dd><p>A numeric vector giving the subjects observed value on treatment Drug1 at time 2</p>
</dd>
<dt><code>Drug2.1</code></dt><dd><p>A numeric vector giving the subjects observed value on treatment Drug2 at time 1</p>
</dd>
<dt><code>Drug2.2</code></dt><dd><p>A numeric vector giving the subjects observed value on treatment Drug2 at time 2</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='missing_pk'>Clinical trial data</h2><span id='topic+missing_pk'></span><span id='topic+missingPk'></span>

<h3>Description</h3>

<p>Clinical trial data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missing_pk

missingPk
</code></pre>


<h3>Format</h3>

<p>A data frame with 165 observations on the following 4 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a numeric vector giving the subject identifier</p>
</dd>
<dt><code>Dose</code></dt><dd><p>a numeric vector giving the dose group</p>
</dd>
<dt><code>Time</code></dt><dd><p>a numeric vector giving the observation times</p>
</dd>
<dt><code>Conc</code></dt><dd><p>a numeric vector giving the observed concentration</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>Simulated from 'pk_data'
</p>

<hr>
<h2 id='pk_data'>Typical PK data</h2><span id='topic+pk_data'></span><span id='topic+pkData'></span>

<h3>Description</h3>

<p>Typical PK data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pk_data

pkData
</code></pre>


<h3>Format</h3>

<p>A data frame with 165 observations on the following 4 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a numeric vector giving the subject identifier</p>
</dd>
<dt><code>Dose</code></dt><dd><p>a numeric vector giving the dose group</p>
</dd>
<dt><code>Time</code></dt><dd><p>a numeric vector giving the observation times</p>
</dd>
<dt><code>Conc</code></dt><dd><p>a numeric vector giving the observed concentration</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='policy_data'>Insurance Policy Data</h2><span id='topic+policy_data'></span><span id='topic+policyData'></span>

<h3>Description</h3>

<p>Insurance Policy Data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>policy_data

policyData
</code></pre>


<h3>Format</h3>

<p>A data frame with 926 observations on the following 13 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>The four digit year of the policy</p>
</dd>
<dt><code>PolicyNo</code></dt><dd><p>The policy number</p>
</dd>
<dt><code>TotalPremium</code></dt><dd><p>The total insurance premium</p>
</dd>
<dt><code>BonusMalus</code></dt><dd><p>Discount level</p>
</dd>
<dt><code>WeightClass</code></dt><dd><p>The weight class of the car</p>
</dd>
<dt><code>Region</code></dt><dd><p>Region of the car owner</p>
</dd>
<dt><code>Age</code></dt><dd><p>Age of the main driver</p>
</dd>
<dt><code>Mileage</code></dt><dd><p>Estimated annual mileage</p>
</dd>
<dt><code>Usage</code></dt><dd><p>Car usage</p>
</dd>
<dt><code>PremiumClass</code></dt><dd><p>Class of the car</p>
</dd>
<dt><code>NoClaims</code></dt><dd><p>Number of previous claims</p>
</dd>
<dt><code>GrossIncurred</code></dt><dd><p>Claim cost</p>
</dd>
<dt><code>Exposure</code></dt><dd><p>How long they have been driving</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>Simulated based on details of how to simulate car insurance data in
Modern Actuarial Risk Theory Using R 2nd Edition (Rob Kaas, Marc Goovaerts, Jan Dhaene, Michel Denuit)
</p>

<hr>
<h2 id='qtpk2'>Typical PK data</h2><span id='topic+qtpk2'></span>

<h3>Description</h3>

<p>Typical PK data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qtpk2
</code></pre>


<h3>Format</h3>

<p>A data frame with 2061 observations on the following 8 variables.
</p>

<dl>
<dt><code>subjid</code></dt><dd><p>A numeric vector giving the subject ID</p>
</dd>
<dt><code>treat</code></dt><dd><p>A factor giving the treatment</p>
</dd>
<dt><code>time</code></dt><dd><p>A numeric vector giving the observation times</p>
</dd>
<dt><code>qt</code></dt><dd><p>A numeric vector giving the QT interval value</p>
</dd>
<dt><code>qtcb</code></dt><dd><p>A numeric vector giving corrected QT interval</p>
</dd>
<dt><code>hr</code></dt><dd><p>A numeric vector giving the heart rate</p>
</dd>
<dt><code>rr</code></dt><dd><p>A numeric vector giving the R-R interval</p>
</dd>
<dt><code>sex</code></dt><dd><p>A factor giving the subject sex</p>
</dd>
</dl>



<h3>Source</h3>

<p>A subset of the data qtpk originally provided in the QT package
</p>

<hr>
<h2 id='run_data'>An example of NONMEM run data</h2><span id='topic+run_data'></span><span id='topic+runData'></span>

<h3>Description</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_data

runData
</code></pre>


<h3>Format</h3>

<p>A data frame with 73 observations on the following 10 variables.
</p>

<dl>
<dt><code>ID</code></dt><dd><p>a numeric vector giving the subject ID</p>
</dd>
<dt><code>DAY</code></dt><dd><p>a numeric vector giving the day of the observation</p>
</dd>
<dt><code>CL</code></dt><dd><p>a numeric vector giving the clearance value</p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector giving the volume of distribution</p>
</dd>
<dt><code>WT</code></dt><dd><p>a numeric vector giving the weight</p>
</dd>
<dt><code>DV</code></dt><dd><p>a numeric vector giving the dependent variable</p>
</dd>
<dt><code>IPRE</code></dt><dd><p>a numeric vector giving the individual prediction</p>
</dd>
<dt><code>PRED</code></dt><dd><p>a numeric vector giving the population prediction</p>
</dd>
<dt><code>RES</code></dt><dd><p>a numeric vector giving the residual</p>
</dd>
<dt><code>WRES</code></dt><dd><p>a numeric vector giving the weighted residual</p>
</dd>
</dl>



<h3>Source</h3>

<p>Simulated Data
</p>

<hr>
<h2 id='students'>Students simulated data</h2><span id='topic+students'></span>

<h3>Description</h3>

<p>Students simulated data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>students
</code></pre>


<h3>Format</h3>

<p>A tibble with 146 observations of 15 variables.
</p>

<dl>
<dt><code>Grade</code></dt><dd><p>Final grade (A, B, C, D)</p>
</dd>
<dt><code>Pass</code></dt><dd><p>Did they pass the course? (No, Yes)</p>
</dd>
<dt><code>Exam</code></dt><dd><p>Mark in final exam (out of 100)</p>
</dd>
<dt><code>Degree</code></dt><dd><p>The degree type undertaken by the student</p>
</dd>
<dt><code>Gender</code></dt><dd><p>Gender of the student</p>
</dd>
<dt><code>Attend</code></dt><dd><p>Did they regularly attend class? (No, Yes)</p>
</dd>
<dt><code>Assign</code></dt><dd><p>Score obtained in mid-term assignment (out of 20)</p>
</dd>
<dt><code>Test</code></dt><dd><p>Score obtained in previous term test (out of 20)</p>
</dd>
<dt><code>B</code></dt><dd><p>Mark for short answer section (out of 20)</p>
</dd>
<dt><code>C</code></dt><dd><p>Mark for long answer section (out of 20)</p>
</dd>
<dt><code>MC</code></dt><dd><p>Mark for multiple choice sectionC (out of 30)</p>
</dd>
<dt><code>Colour</code></dt><dd><p>Colour of exam booklet (Blue, Green, Pink, Yellow)</p>
</dd>
<dt><code>Stage1</code></dt><dd><p>Stage one grade (A, B, C)</p>
</dd>
<dt><code>Years.Since</code></dt><dd><p>Number of years since doing Stage 1</p>
</dd>
<dt><code>Repeat</code></dt><dd><p>Where they repeating the paper? (No, Yes)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='tube_data'>London Tube Performance data</h2><span id='topic+tube_data'></span><span id='topic+tubeData'></span>

<h3>Description</h3>

<p>London Tube Performance data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tube_data

tubeData
</code></pre>


<h3>Format</h3>

<p>A data frame with 1050 observations on the following 9 variables.
</p>

<dl>
<dt><code>Line</code></dt><dd><p>A factor with 10 levels, one for each London tube line</p>
</dd>
<dt><code>Month</code></dt><dd><p>A numeric vector indicating the month of the observation</p>
</dd>
<dt><code>Scheduled</code></dt><dd><p>A numeric vector giving the scheduled running time</p>
</dd>
<dt><code>Excess</code></dt><dd><p>A numeric vector giving the excess running time</p>
</dd>
<dt><code>TOTAL</code></dt><dd><p>A numeric vector giving the total running time</p>
</dd>
<dt><code>Opened</code></dt><dd><p>A numeric vector giving the year the line opened</p>
</dd>
<dt><code>Length</code></dt><dd><p>A numeric vector giving the line length</p>
</dd>
<dt><code>Type</code></dt><dd><p>A factor indicating the type of tube line</p>
</dd>
<dt><code>Stations</code></dt><dd><p>A numeric vector giving the number of stations on the line</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>This data was taken from &quot;https://data.london.gov.uk/dataset/tube-network-performance-data-transport-committee-report&quot;
</p>

<hr>
<h2 id='x_iris'>Iris predictors data for Species classification</h2><span id='topic+x_iris'></span>

<h3>Description</h3>

<p>This data was taken from Edgar Anderson's famous iris data set. This gives the measurements (in centimeters)
of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. 
The species are Iris setosa, versicolor, and virginica. However, the species is seen as the target variable, and as such
has been removed from this dataset, whilst being added to the counterpart <code>y_iris</code> dataset. Furthermore, the 4 remaining 
'predictor' variables have been separated into a training and test set with a ratio of 4:1, followed by centering and scaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x_iris
</code></pre>


<h3>Format</h3>

<p>A list of two named matrices, 'train' and 'test', representing the training and test sets for the predictors. These have 4 
columns each, with 120 and 30 rows respectively.
</p>

<dl>
<dt><code>Sepal.Length</code></dt><dd><p>Sepal length</p>
</dd>
<dt><code>Sepal.Width</code></dt><dd><p>Sepal width</p>
</dd>
<dt><code>Petal.Length</code></dt><dd><p>Petal length</p>
</dd>
<dt><code>Petal.Width</code></dt><dd><p>Petal width</p>
</dd>
</dl>



<h3>Source</h3>

<p>Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7, Part II, 179-188. 
The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2-5
</p>
<ul>
<li><p><a href="https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/iris.html">https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/iris.html</a></p>
</li></ul>



<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) The New S Language. Wadsworth &amp; Brooks/Cole.
</p>

<hr>
<h2 id='xp_data'>Typical NONMEM data</h2><span id='topic+xp_data'></span><span id='topic+xpData'></span>

<h3>Description</h3>

<p>Typical NONMEM data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xp_data

xpData
</code></pre>


<h3>Format</h3>

<p>A data frame with 1061 observations on the following 23 variables.
</p>

<dl>
<dt><code>ID</code></dt><dd><p>a numeric vector giving the subject ID</p>
</dd>
<dt><code>SEX</code></dt><dd><p>a numeric vector giving the subject sex</p>
</dd>
<dt><code>RACE</code></dt><dd><p>a numeric vector giving the subject race</p>
</dd>
<dt><code>SMOK</code></dt><dd><p>a numeric vector giving the subject smoking status</p>
</dd>
<dt><code>HCTZ</code></dt><dd><p>a numeric vector giving the treatment status</p>
</dd>
<dt><code>PROP</code></dt><dd><p>a numeric vector giving the treatment status</p>
</dd>
<dt><code>CON</code></dt><dd><p>a numeric vector giving the treatment status</p>
</dd>
<dt><code>DV</code></dt><dd><p>a numeric vector giving the dependent variable</p>
</dd>
<dt><code>PRED</code></dt><dd><p>a numeric vector giving population prediction</p>
</dd>
<dt><code>RES</code></dt><dd><p>a numeric vector giving the residual</p>
</dd>
<dt><code>WRES</code></dt><dd><p>a numeric vector giving the weighted residual</p>
</dd>
<dt><code>AGE</code></dt><dd><p>a numeric vector giving the subject age</p>
</dd>
<dt><code>HT</code></dt><dd><p>a numeric vector giving the subject height</p>
</dd>
<dt><code>WT</code></dt><dd><p>a numeric vector giving the subject weight</p>
</dd>
<dt><code>SECR</code></dt><dd><p>a numeric vector giving the serum creatinine value</p>
</dd>
<dt><code>OCC</code></dt><dd><p>a numeric vector giving the occasion</p>
</dd>
<dt><code>TIME</code></dt><dd><p>a numeric vector giving the time of the observation time</p>
</dd>
<dt><code>IPRE</code></dt><dd><p>a numeric vector giving individual prediction</p>
</dd>
<dt><code>IWRE</code></dt><dd><p>a numeric vector giving the individual weighted residual</p>
</dd>
<dt><code>SID</code></dt><dd><p>a numeric vector giving the site ID</p>
</dd>
<dt><code>CL</code></dt><dd><p>a numeric vector giving the clearance</p>
</dd>
<dt><code>V</code></dt><dd><p>a numeric vector giving the volume of distribution</p>
</dd>
<dt><code>KA</code></dt><dd><p>a numeric vector giving the absorption rate constant</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset has be renamed using tidyverse-style snake_case naming conventions. However the original name of the dataset has been kept to ensure 
backwards compatibility with the book SAMS Teach Yourself R in 24 Hours (ISBN: 978-0-672-33848-9).
</p>


<h3>Source</h3>

<p>Simulated Data
</p>

<hr>
<h2 id='y_iris'>Iris class data for Species classification</h2><span id='topic+y_iris'></span>

<h3>Description</h3>

<p>This data was taken from Edgar Anderson's famous iris data set. This gives the measurements (in centimeters)
of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. 
The species are Iris setosa, versicolor, and virginica. This is the target dataset (as a counterpart to the <code>x_iris</code> dataset) 
and thus only retains the Species information. As with the <code>x_iris</code> dataset, the data has been split into a training and test
set with a ratio of 4:1. Following this the species class has been one-hot encoded to give three columns, one for each species level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>y_iris
</code></pre>


<h3>Format</h3>

<p>A list of two named matrices, 'train' and 'test', representing the training and test sets for the predictors. These have 3 indicator 
columns each, with 120 and 30 rows respectively.
</p>

<dl>
<dt><code>Species.setosa</code></dt><dd><p>Indicator column for the species class setosa</p>
</dd>
<dt><code>Species.versicolor</code></dt><dd><p>Indicator column for the species class versicolor</p>
</dd>
<dt><code>Species.virginica</code></dt><dd><p>Indicator column for the species class virginica</p>
</dd>
</dl>



<h3>Source</h3>

<p>Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7, Part II, 179-188. 
The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2-5
</p>
<ul>
<li><p><a href="https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/iris.html">https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/iris.html</a></p>
</li></ul>



<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) The New S Language. Wadsworth &amp; Brooks/Cole.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
