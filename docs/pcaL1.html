<!DOCTYPE html><html><head><title>Help for package pcaL1</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pcaL1}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#awl1pca'><p>awPCA</p></a></li>
<li><a href='#l1pca'><p>L1-PCA</p></a></li>
<li><a href='#l1pcahp'><p>L1-PCAhp</p></a></li>
<li><a href='#l1pcastar'><p>L1-PCA*</p></a></li>
<li><a href='#l1projection'><p>L1 Projection</p></a></li>
<li><a href='#L2PCA_approx'><p>L2PCA_approx</p></a></li>
<li><a href='#l2projection'><p>L2 Projection</p></a></li>
<li><a href='#pcal1'><p>PCA-L1</p></a></li>
<li><a href='#pcaL1-package'>
<p>pcaL1: L1-Norm PCA Methods</p></a></li>
<li><a href='#pcalp'><p>PCA-Lp</p></a></li>
<li><a href='#plot.awl1pca'><p>Plot an awl1pca Object</p></a></li>
<li><a href='#plot.l1pca'><p>Plot an L1pca Object</p></a></li>
<li><a href='#plot.l1pcahp'><p>Plot an L1PCAhp Object</p></a></li>
<li><a href='#plot.l1pcastar'><p>Plot an L1pcastar Object</p></a></li>
<li><a href='#plot.pcal1'><p>Plot a Pcal1 Object</p></a></li>
<li><a href='#plot.pcalp'><p>Plot a Pcalp Object</p></a></li>
<li><a href='#plot.sharpel1pca'><p>Plot a Sharpel1pca Object</p></a></li>
<li><a href='#plot.sharpel1rs'><p>Plot a Sharpel1rs Object</p></a></li>
<li><a href='#plot.sparsel1pca'><p>Plot a Sparsel1pca Object</p></a></li>
<li><a href='#plot.wl1pca'><p>Plot a Wl1pca Object</p></a></li>
<li><a href='#sharpel1pca'><p>SharpEl1-PCA</p></a></li>
<li><a href='#sharpel1rs'><p>SharpEl1-RS</p></a></li>
<li><a href='#sparsel1pca'><p>SparsEl1-PCA</p></a></li>
<li><a href='#weightedL1Distance'><p>Weighted L1 Distance</p></a></li>
<li><a href='#wl1pca'><p>wPCA</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.5.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-01-16</td>
</tr>
<tr>
<td>Title:</td>
<td>L1-Norm PCA Methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Author:</td>
<td>Sapan Jot &lt;sapan.madaan@gmail.com&gt;, Paul Brooks
        &lt;jpbrooks@vcu.edu&gt;, 
	Andrea Visentin &lt;andrea.visentin@insight-centre.org&gt;,
        Young Woong Park &lt;ywpark@mail.smu.edu&gt;,
        and Yi-Hui Zhou &lt;yihui_zhou@ncsu.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul Brooks &lt;jpbrooks@vcu.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementations of several methods for principal component analysis 
        using the L1 norm.  The package depends on COIN-OR Clp version &gt;= 
        1.17.4.  The methods implemented are 
        PCA-L1 (Kwak 2008) &lt;<a href="https://doi.org/10.1109%2FTPAMI.2008.114">doi:10.1109/TPAMI.2008.114</a>&gt;, 
        L1-PCA (Ke and Kanade 2003, 2005) &lt;<a href="https://doi.org/10.1109%2FCVPR.2005.309">doi:10.1109/CVPR.2005.309</a>&gt;, 
        L1-PCA* (Brooks, Dula, and Boone 2013) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2012.11.007">doi:10.1016/j.csda.2012.11.007</a>&gt;, 
        L1-PCAhp (Visentin, Prestwich and Armagan 2016) 
                 &lt;<a href="https://doi.org/10.1007%2F978-3-319-46227-1_37">doi:10.1007/978-3-319-46227-1_37</a>&gt;, 
        wPCA (Park and Klabjan 2016) &lt;<a href="https://doi.org/10.1109%2FICDM.2016.0054">doi:10.1109/ICDM.2016.0054</a>&gt;,
        awPCA (Park and Klabjan 2016) &lt;<a href="https://doi.org/10.1109%2FICDM.2016.0054">doi:10.1109/ICDM.2016.0054</a>&gt;,
        PCA-Lp (Kwak 2014) &lt;<a href="https://doi.org/10.1109%2FTCYB.2013.2262936">doi:10.1109/TCYB.2013.2262936</a>&gt;, and
        SharpEl1-PCA (Brooks and Dula, submitted).</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>COIN-OR Clp (&gt;= 1.17.4)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-01-18 16:07:36 UTC; jpbrooks</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-18 18:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='awl1pca'>awPCA</h2><span id='topic+awl1pca'></span>

<h3>Description</h3>

<p>Performs a principal component analysis using the algorithm awPCA described by Park and Klabjan (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>awl1pca(X, projDim=1, center=TRUE, projections="l2",
         tolerance=0.001, iterations=200, beta=0.99, gamma=0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="awl1pca_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="awl1pca_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>
<tr><td><code id="awl1pca_+3A_center">center</code></td>
<td>
<p>whether to center the data using the mean, default is TRUE.</p>
</td></tr>
<tr><td><code id="awl1pca_+3A_projections">projections</code></td>
<td>
<p>whether to calculate projections (reconstructions and scores) using the L2 norm (&quot;l2&quot;, default) or the L1 norm (&quot;l1&quot;).</p>
</td></tr>
<tr><td><code id="awl1pca_+3A_tolerance">tolerance</code></td>
<td>
<p>for testing convergence; if the sum of absolute values of loadings vectors is smaller, then the algorithm terminates.</p>
</td></tr> 
<tr><td><code id="awl1pca_+3A_iterations">iterations</code></td>
<td>
<p>maximum number of iterations in optimization routine.</p>
</td></tr>
<tr><td><code id="awl1pca_+3A_beta">beta</code></td>
<td>
<p>algorithm parameter to set up bound for weights.</p>
</td></tr>
<tr><td><code id="awl1pca_+3A_gamma">gamma</code></td>
<td>
<p>algorithm parameter to determine whether to use approximation formula or prcomp function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to the algorithm described by Park and Klabjan (2016).  The method is an  iteratively reweighted least squares algorithm for L1-norm principal component analysis.</p>


<h3>Value</h3>

<p>'awl1pca' returns a list with class &quot;awl1pca&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x projDim.  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of L2-norm projections of points on the fitted subspace in terms of the original coordinates.  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
<tr><td><code>L1error</code></td>
<td>
<p>sum of the L1 norm of reconstruction errors.</p>
</td></tr>
<tr><td><code>nIter</code></td>
<td>
<p>number of iterations.</p>
</td></tr>
<tr><td><code>ElapsedTime</code></td>
<td>
<p>elapsed time.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Park, Y.W. and Klabjan, D. (2016) Iteratively Reweighted Least Squares Algorithms for L1-Norm Principal Component Analysis, <em>IEEE International Conference on Data Mining (ICDM)</em>, 2016. DOI: 10.1109/ICDM.2016.0054
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) +
               matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
myawl1pca &lt;- awl1pca(X)

##projects data into 2 dimensions.
myawl1pca &lt;- awl1pca(X, projDim=2, center=FALSE)

## plot first two scores
plot(myawl1pca$scores)
</code></pre>

<hr>
<h2 id='l1pca'>L1-PCA</h2><span id='topic+l1pca'></span>

<h3>Description</h3>

<p>Performs a principal component analysis using the algorithm L1-PCA given by Ke and Kanade (2005).</p>


<h3>Usage</h3>

<pre><code class='language-R'>   l1pca(X, projDim=1, center=TRUE, projections="l1", 
	 initialize="l2pca", tolerance=0.0001, iterations=10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="l1pca_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="l1pca_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>
<tr><td><code id="l1pca_+3A_center">center</code></td>
<td>
<p>whether to center the data using the median, default is TRUE.</p>
</td></tr>
<tr><td><code id="l1pca_+3A_projections">projections</code></td>
<td>
<p>Whether to calculate reconstructions and scores using the L1 (&quot;l1&quot;, default) or L2 (&quot;l2&quot;) norm.</p>
</td></tr>
<tr><td><code id="l1pca_+3A_initialize">initialize</code></td>
<td>
<p>initial guess for loadings matrix.  Options are: &quot;l2pca&quot; - use traditional PCA/SVD, &quot;random&quot; - use a randomly-generated matrix.  The user can also provide a matrix as an initial guess.</p>
</td></tr>
<tr><td><code id="l1pca_+3A_tolerance">tolerance</code></td>
<td>
<p>sets the convergence tolerance for the algorithm, default is 0.0001.</p>
</td></tr>
<tr><td><code id="l1pca_+3A_iterations">iterations</code></td>
<td>
<p>sets the number of iterations to run before returning the result, default is 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to the linear programming-based algorithm described by Ke and Kanade (2005).  The method is a locally-convergent algorithm for finding the L1-norm best-fit subspace by alternatively optimizing the scores and the loadings matrix at each iteration.  Linear programming instances are solved using Clp (http://www.coin-or.org)
</p>


<h3>Value</h3>

<p>'l1pca' returns a list with class &quot;l1pca&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x projDim.  The columns defined the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>dispExp</code></td>
<td>
<p>the proportion of L1 dispersion explained by the loadings vectors.  Calculated as the L1 dispersion of the score on each component divided by the L1 dispersion in the original data.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates (reconstructions).  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Ke Q. and Kanade T. (2005) Robust L1 norm factorization in the presence of outliers and missing data by alternative convex programming, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>. DOI:10.1109/CVPR.2005.309
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) + 
                 matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
myl1pca &lt;- l1pca(X)

##projects data into 2 dimensions.
myl1pca &lt;- l1pca(X, projDim=2, center=FALSE, 
                 tolerance=0.00001, iterations=20)

## plot first two scores
plot(myl1pca$scores)
</code></pre>

<hr>
<h2 id='l1pcahp'>L1-PCAhp</h2><span id='topic+l1pcahp'></span>

<h3>Description</h3>

<p>Performs a principal component analysis using the algorithm L1-PCAhp described by Visentin, Prestwich and Armagan (2016)</p>


<h3>Usage</h3>

<pre><code class='language-R'>   l1pcahp(X, projDim=1, center=TRUE, projections="none", 
           initialize="l2pca", threshold=0.0001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="l1pcahp_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="l1pcahp_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>
<tr><td><code id="l1pcahp_+3A_center">center</code></td>
<td>
<p>whether to center the data using the median, default is TRUE.</p>
</td></tr>
<tr><td><code id="l1pcahp_+3A_projections">projections</code></td>
<td>
<p>whether to calculate reconstructions and scores using the L1 norm (&quot;l1&quot;) the L2 norm (&quot;l2&quot;) or not at all (&quot;none&quot;, default).</p>
</td></tr>
<tr><td><code id="l1pcahp_+3A_initialize">initialize</code></td>
<td>
<p>method for initial guess for loadings matrix.  Options are: &quot;l2pca&quot; - use traditional PCA/SVD, &quot;random&quot; - use a randomly-generated matrix.</p>
</td></tr>
<tr><td><code id="l1pcahp_+3A_threshold">threshold</code></td>
<td>
<p>sets the convergence threshold for the algorithm, default is 0.001.</p>
</td></tr></table>


<h3>Details</h3>

<p>The calculation is performed according to the algorithm described by Visentin, Prestwich and Armagan (2016).  The algorithm computes components iteratively in reverse, using a new heuristic based on Linear Programming.  Linear programming instances are solved using Clp (http://www.coin-or.org).</p>


<h3>Value</h3>

<p>'l1pcahp' returns a list with class &quot;l1pcahp&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x ncol(X).  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>dispExp</code></td>
<td>
<p>the proportion of L1 dispersion explained by the loadings vectors.  Calculated as the L1 dispersion of the score on each component divided by the L1 dispersion in the original data.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates.  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Visentin A., Prestwich S., and Armagan S. T. (2016) Robust Principal Component Analysis by Reverse Iterative Linear Programming, <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>,  593-605. DOI:10.1007/978-3-319-46227-1_37
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) +
                matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
myl1pcahp &lt;- l1pcahp(X)

##projects data into 2 dimensions.
myl1pcahp &lt;- l1pcahp(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(myl1pcahp$scores)
</code></pre>

<hr>
<h2 id='l1pcastar'>L1-PCA*</h2><span id='topic+l1pcastar'></span>

<h3>Description</h3>

<p>Performs a principal component analysis using the algorithm L1-PCA* described by Brooks, Dula, and Boone (2013)</p>


<h3>Usage</h3>

<pre><code class='language-R'>   l1pcastar(X, projDim=1, center=TRUE, projections="none")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="l1pcastar_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form</p>
</td></tr>
<tr><td><code id="l1pcastar_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1</p>
</td></tr>
<tr><td><code id="l1pcastar_+3A_center">center</code></td>
<td>
<p>whether to center the data using the median, default is TRUE</p>
</td></tr>
<tr><td><code id="l1pcastar_+3A_projections">projections</code></td>
<td>
<p>whether to calculate reconstructions and scores using the L1 norm (&quot;l1&quot;) the L2 norm (&quot;l2&quot;) or not at all (&quot;none&quot;, default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to the algorithm described by Brooks, Dula, and Boone (2013).  The algorithm finds successive directions of minimum dispersion in the data by finding the L1-norm best-fit hyperplane at each iteration.  Linear programming instances are solved using Clp (http://www.coin-or.org)</p>


<h3>Value</h3>

<p>'l1pcastar' returns a list with class &quot;l1pcastar&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x ncol(X).  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>dispExp</code></td>
<td>
<p>the proportion of L1 dispersion explained by the loadings vectors.  Calculated as the L1 dispersion of the score on each component divided by the L1 dispersion in the original data.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates.  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
</table>


<h3>References</h3>


<ol>
<li><p>Brooks J.P., Dula J.H., and Boone E.L. (2013) A Pure L1-Norm Princpal Component Analysis, <em>Computational Statistics &amp; Data Analysis</em>, 61:83-98. DOI:10.1016/j.csda.2012.11.007
</p>
</li>
<li><p>Zhou, Y.-H. and Marron, J.S. (2016) Visualization of Robust L1PCA, <em>Stat</em>, 5:173-184.  DOI:10.1002/sta4.113
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) +
                 matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
myl1pcastar &lt;- l1pcastar(X)

##projects data into 2 dimensions.
myl1pcastar &lt;- l1pcastar(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(myl1pcastar$scores)
</code></pre>

<hr>
<h2 id='l1projection'>L1 Projection</h2><span id='topic+l1projection'></span>

<h3>Description</h3>

<p>Provides the L1-norm projection of points on a subspace, including both scores and reconstructions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>l1projection(X, loadings)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="l1projection_+3A_x">X</code></td>
<td>
<p>data, in <code>matrix</code> or table form</p>
</td></tr>
<tr><td><code id="l1projection_+3A_loadings">loadings</code></td>
<td>
<p>an orthonormal matrix of loadings vectors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The scores and reconstructions are calculated by solving a linear program.</p>


<h3>Value</h3>

<p>'l1projection' returns a list containing the following components:
</p>
<table>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates (reconstructions)</p>
</td></tr>
</table>

<hr>
<h2 id='L2PCA_approx'>L2PCA_approx</h2><span id='topic+L2PCA_approx'></span><span id='topic+l2pcaapprox'></span>

<h3>Description</h3>

<p>Provides an approximation of traditional PCA described by Park and Klabjan (2016) as a subroutine for awl1pca.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L2PCA_approx(ev.prev, pc.prev, projDim, X.diff)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L2PCA_approx_+3A_ev.prev">ev.prev</code></td>
<td>
<p>matrix of principal component loadings from a previous iteration of awl1pca</p>
</td></tr>
<tr><td><code id="L2PCA_approx_+3A_pc.prev">pc.prev</code></td>
<td>
<p>vector of eigenvalues from previous iteration of awl1pca</p>
</td></tr>
<tr><td><code id="L2PCA_approx_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer</p>
</td></tr>
<tr><td><code id="L2PCA_approx_+3A_x.diff">X.diff</code></td>
<td>
<p>The difference between the current weighted matrix estimate and the estimate from the previous iteration</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to equations (11) and (12) in Park and Klabjan (2016).  The method is an approximation for traditional principal component analysis.</p>


<h3>Value</h3>

<p>'L2PCA_approx' returns a list containing the following components:
</p>
<table>
<tr><td><code>eigenvalues</code></td>
<td>
<p>Estimate of eigenvalues of the covariance matrix.</p>
</td></tr> 
<tr><td><code>eigenvectors</code></td>
<td>
<p>Estimate of eigenvectors of the covariance matrix.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Park, Y.W. and Klabjan, D. (2016) Iteratively Reweighted Least Squares Algorithms for L1-Norm Principal Component Analysis, <em>IEEE International Conference on Data Mining (ICDM)</em>, 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+awl1pca">awl1pca</a></code>
</p>

<hr>
<h2 id='l2projection'>L2 Projection</h2><span id='topic+l2projection'></span>

<h3>Description</h3>

<p>Provides the L2-norm projection of points on a subspace, including both scores and reconstructions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>l2projection(X, loadings)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="l2projection_+3A_x">X</code></td>
<td>
<p>data, in <code>matrix</code> or table form</p>
</td></tr>
<tr><td><code id="l2projection_+3A_loadings">loadings</code></td>
<td>
<p>an orthonormal matrix of loadings vectors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The scores and reconstructions are calculated by solving a linear program.</p>


<h3>Value</h3>

<p>'l2projection' returns a list containing the following components:
</p>
<table>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates (reconstructions)</p>
</td></tr>
</table>

<hr>
<h2 id='pcal1'>PCA-L1</h2><span id='topic+pcal1'></span>

<h3>Description</h3>

<p>Performs a principal component analysis using the algorithm PCA-L1 given by Kwak (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcal1(X, projDim=1, center=TRUE, projections="none", initialize="l2pca")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcal1_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="pcal1_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>
<tr><td><code id="pcal1_+3A_center">center</code></td>
<td>
<p>whether to center the data using the median, default is TRUE.</p>
</td></tr>
<tr><td><code id="pcal1_+3A_projections">projections</code></td>
<td>
<p>whether to calculate reconstructions and scores using the L1 norm (&quot;l1&quot;) the L2 norm (&quot;l2&quot;) or not at all (&quot;none&quot;, default).</p>
</td></tr>
<tr><td><code id="pcal1_+3A_initialize">initialize</code></td>
<td>
<p>initial guess for first component.  Options are: &quot;l2pca&quot; - use traditional PCA/SVD, &quot;maxx&quot; - use the point with the largest norm, &quot;random&quot; - use a random vector.  The user can also provide a vector as the initial guess.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to the algorithm described by Kwak (2008).  The method is a locally-convergent algorithm for finding successive directions of maximum L1 dispersion.</p>


<h3>Value</h3>

<p>'pcal1' returns a list with class &quot;pcal1&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x projDim.  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>dispExp</code></td>
<td>
<p>the proportion of L1 dispersion explained by the loadings vectors.  Calculated as the L1 dispersion of the score on each component divided by the L1 dispersion in the original data.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates (reconstructions).  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Kwak N. (2008) Principal component analysis based on L1-norm maximization, <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 30: 1672-1680. DOI:10.1109/TPAMI.2008.114
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) +
                matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mypcal1 &lt;- pcal1(X)

##projects data into 2 dimensions.
mypcal1 &lt;- pcal1(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(mypcal1$scores)
</code></pre>

<hr>
<h2 id='pcaL1-package'>
pcaL1: L1-Norm PCA Methods
</h2><span id='topic+pcaL1-package'></span><span id='topic+pcaL1'></span>

<h3>Description</h3>

<p>This package contains implementations of six principal component analysis methods using the L1 norm.  The package depends on COIN-OR Clp version &gt;= 1.17.4.  The methods implemented are PCA-L1 (Kwak 2008), L1-PCA (Ke and Kanade 2003, 2005), L1-PCA* (Brooks, Dula, and Boone 2013), L1-PCAhp (Visentin, Prestwich and Armagan 2016), wPCA (Park and Klabjan 2016), and awPCA (Park and Klabjan 2016).
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> pcaL1</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.5.7</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-01-16</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=3)</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> http://www.optimization-online.org/DB_HTML/2012/04/3436.html, http://www.coin-or.org</td>
</tr>
<tr>
 <td style="text-align: left;"> SystemRequirements: </td><td style="text-align: left;"> COIN-OR Clp (&gt;= 1.17.4)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Index:
</p>
<pre>
awl1pca                 awPCA 
l1pca                   L1-PCA
l1pcahp                 L1-PCAhp
l1pcastar               L1-PCA*
l1projection            L1-Norm Projection on a Subspace
L2PCA_approx            Subroutine for awl1pca
l2projection            L2-Norm Projection on a Subspace
pcal1                   PCA-L1
pcalp                   PCA-Lp
pcaL1-package           pcaL1: L1-Norm PCA Methods
plot.awl1pca            Plot an awl1pca Object
plot.l1pca              Plot an l1pca Object
plot.l1pcahp            Plot an l1pcahp Object
plot.l1pcastar          Plot an l1pcastar Object
plot.pcal1              Plot a pcal1 Object
plot.pcalp              Plot a pcalp Object
plot.wl1pca             Plot an wl1pca Object
plot.sharpel1pca        Plot a sharpel1pca Object
sharpel1pca             SharpeEL1-PCA
sharpel1rs              SharpEl1-RS
sparsel1pca             SparseEl1-PCA
wl1pca                  wPCA 
</pre>


<h3>Author(s)</h3>

<p>Sapan Jot &lt;sapan.madaan@gmail.com&gt;, Paul Brooks &lt;jpbrooks@vcu.edu&gt;, Andrea Visentin &lt;andrea.visentin@insight-centre.org&gt;,Young Woong Park &lt;ywpark@mail.smu.edu&gt;, and Yi-Hui Zhou &lt;yihui_zhou@ncsu.edu&gt;
</p>
<p>Maintainer: Paul Brooks &lt;jpbrooks@vcu.edu&gt;
</p>


<h3>References</h3>


<ol>
<li><p>Brooks and Dula (2017) Estimating L1-Norm Best-Fit Lines, submitted
</p>
</li>
<li><p>Brooks J.P., Dula J.H., and Boone E.L. (2013) A Pure L1-Norm Princpal Component Analysis, <em>Computational Statistics &amp; Data Analysis</em>, 61:83-98. DOI:10.1016/j.csda.2012.11.007
</p>
</li>
<li><p>Ke Q. and Kanade T. (2005) Robust L1 Norm Factorization in the Presence of Outliers and Missing Data by Alternative Convex Programming, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>. DOI:10.1109/CVPR.2005.309
</p>
</li>
<li><p>Kwak N. (2008) Principal Component Analysis Based on L1-Norm Maximization, <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 30: 1672-1680. DOI:10.1109/TPAMI.2008.114
</p>
</li>
<li><p>Kwak N. (2014) Principal Component Analysis by  Lp-Norm Maximization, <em>IEEE Transactions on Cybernetics</em>, 44:594-609. DOI:10.1109/TCYB.2013.2262936
</p>
</li>
<li><p>Park, Y.W. and Klabjan, D. (2016) Iteratively Reweighted Least Squares Algorithms for L1-Norm Principal Component Analysis, <em>IEEE International Conference on Data Mining (ICDM)</em>. DOI: 10.1109/ICDM.2016.0054
</p>
</li>
<li><p>Visentin A., Prestwich S., and Armagan S. T. (2016) Robust Principal Component Analysis by Reverse Iterative Linear Programming, <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>,  593-605. DOI:10.1007/978-3-319-46227-1_37
</p>
</li>
<li><p>Zhou, Y.-H. and Marron, J.S. (2016) Visualization of Robust L1PCA, <em>Stat</em>, 5:173-184.  DOI:10.1002/sta4.113
</p>
</li></ol>


<hr>
<h2 id='pcalp'>PCA-Lp</h2><span id='topic+pcalp'></span>

<h3>Description</h3>

<p>Performs a principal component analysis using the greedy algorithms PCA-Lp(G) and PCA-Lp(L) given by Kwak (2014). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcalp(X, projDim=1, p = 1.0, center=TRUE, projections="none", 
        initialize="l2pca",solution = "L", 
	epsilon = 0.0000000001, lratio = 0.02)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcalp_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="pcalp_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>  
<tr><td><code id="pcalp_+3A_p">p</code></td>
<td>
<p>p-norm use to measure the distance between points.</p>
</td></tr>
<tr><td><code id="pcalp_+3A_center">center</code></td>
<td>
<p>whether to center the data using the median, default is TRUE.</p>
</td></tr>
<tr><td><code id="pcalp_+3A_projections">projections</code></td>
<td>
<p>whether to calculate reconstructions and scores using the L1 norm (&quot;l1&quot;) the L2 norm (&quot;l2&quot;) or not at all (&quot;none&quot;, default).</p>
</td></tr>
<tr><td><code id="pcalp_+3A_initialize">initialize</code></td>
<td>
<p>method for initial guess for component.  Options are: &quot;l2pca&quot; - use traditional PCA/SVD, &quot;maxx&quot; - use the point with the largest norm, &quot;random&quot; - use a random vector.</p>
</td></tr>  
<tr><td><code id="pcalp_+3A_solution">solution</code></td>
<td>
<p>method projection vector update.  Options are: &quot;G&quot; - PCA-Lp(G) implementation: Gradient search, &quot;L&quot; - PCA-Lp(L) implementation: Lagrangian (default).</p>
</td></tr>
<tr><td><code id="pcalp_+3A_epsilon">epsilon</code></td>
<td>
<p>for checking convergence.</p>
</td></tr>
<tr><td><code id="pcalp_+3A_lratio">lratio</code></td>
<td>
<p>learning ratio, default is 0.02. Suggested value 1/(nr. instances).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to the algorithm described by Kwak (2014), an extension of the original Kwak(2008).  The method is a greedy locally-convergent algorithm for finding successive directions of maximum Lp dispersion.</p>


<h3>Value</h3>

<p>'pcalp' returns a list with class &quot;pcalp&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x projDim.  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>dispExp</code></td>
<td>
<p>the proportion of L1 dispersion explained by the loadings vectors.  Calculated as the L1 dispersion of the score on each component divided by the L1 dispersion in the original data.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates.  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Kwak N. (2008) Principal component analysis based on L1-norm maximization, <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 30: 1672-1680. DOI:10.1109/TPAMI.2008.114
</p>
<p>Kwak N. (2014). Principal component analysis by Lp-norm maximization. <em>IEEE transactions on cybernetics, 44(5)</em>, 594-609. DOI: 10.1109/TCYB.2013.2262936
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  
##for 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mypcalp &lt;- pcalp(X, p = 1.5)

##projects data into 2 dimensions.
mypcalp &lt;- pcalp(X, projDim=2, p = 1.5, center=FALSE, projections="l1")

## plot first two scores
plot(mypcalp$scores)
</code></pre>

<hr>
<h2 id='plot.awl1pca'>Plot an awl1pca Object</h2><span id='topic+plot.awl1pca'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'awl1pca'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.awl1pca_+3A_x">x</code></td>
<td>

<p>an object of class <code>awl1pca</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.awl1pca_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>awl1pca</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+l1pcastar">l1pcastar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
myawl1pca &lt;- awl1pca(X)

##projects data into 2 dimensions.
myawl1pca &lt;- awl1pca(X, projDim=2, center=FALSE)

## plot first two scores
plot(myawl1pca$scores)
</code></pre>

<hr>
<h2 id='plot.l1pca'>Plot an L1pca Object</h2><span id='topic+plot.l1pca'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'l1pca'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.l1pca_+3A_x">x</code></td>
<td>

<p>an object of class <code>l1pca</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.l1pca_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>l1pca</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+l1pca">l1pca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
              + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
myl1pca &lt;- l1pca(X)

##projects data into 2 dimensions.
myl1pca &lt;- l1pca(X, projDim=2, center=FALSE)

## plot first two scores
plot(myl1pca$scores)
</code></pre>

<hr>
<h2 id='plot.l1pcahp'>Plot an L1PCAhp Object</h2><span id='topic+plot.l1pcahp'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'l1pcahp'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.l1pcahp_+3A_x">x</code></td>
<td>

<p>an object of class <code>l1pcahp</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.l1pcahp_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>l1pcahp</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+l1pcastar">l1pcastar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
myl1pcahp &lt;- l1pcahp(X)

##projects data into 2 dimensions.
myl1pcahp &lt;- l1pcahp(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(myl1pcahp$scores)
</code></pre>

<hr>
<h2 id='plot.l1pcastar'>Plot an L1pcastar Object</h2><span id='topic+plot.l1pcastar'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'l1pcastar'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.l1pcastar_+3A_x">x</code></td>
<td>

<p>an object of class <code>l1pcastar</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.l1pcastar_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>l1pcastar</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+l1pcastar">l1pcastar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
myl1pcastar &lt;- l1pcastar(X)

##projects data into 2 dimensions.
myl1pcastar &lt;- l1pcastar(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(myl1pcastar$scores)
</code></pre>

<hr>
<h2 id='plot.pcal1'>Plot a Pcal1 Object</h2><span id='topic+plot.pcal1'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcal1'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pcal1_+3A_x">x</code></td>
<td>

<p>an object of class <code>pcal1</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.pcal1_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>pcal1</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcal1">pcal1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mypcal1 &lt;- pcal1(X)

##projects data into 2 dimensions.
mypcal1 &lt;- pcal1(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(mypcal1$scores)
</code></pre>

<hr>
<h2 id='plot.pcalp'>Plot a Pcalp Object</h2><span id='topic+plot.pcalp'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcalp'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pcalp_+3A_x">x</code></td>
<td>

<p>an object of class <code>pcalp</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.pcalp_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>pcalp</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcalp">pcalp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mypcalp &lt;- pcalp(X)

##projects data into 2 dimensions.
mypcalp &lt;- pcalp(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(mypcalp$scores)
</code></pre>

<hr>
<h2 id='plot.sharpel1pca'>Plot a Sharpel1pca Object</h2><span id='topic+plot.sharpel1pca'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sharpel1pca'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sharpel1pca_+3A_x">x</code></td>
<td>

<p>an object of class <code>sharpel1pca</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.sharpel1pca_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>sharpel1pca</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sharpel1pca">sharpel1pca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mysharpel1pca &lt;- sharpel1pca(X)

##projects data into 2 dimensions.
mysharpel1pca &lt;- sharpel1pca(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(mysharpel1pca$scores)
</code></pre>

<hr>
<h2 id='plot.sharpel1rs'>Plot a Sharpel1rs Object</h2><span id='topic+plot.sharpel1rs'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sharpel1rs'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sharpel1rs_+3A_x">x</code></td>
<td>

<p>an object of class <code>sharpel1rs</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.sharpel1rs_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>sharpel1rs</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sharpel1rs">sharpel1rs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mysharpel1rs &lt;- sharpel1rs(X)

##projects data into 2 dimensions.
mysharpel1rs &lt;- sharpel1rs(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(mysharpel1rs$scores)
</code></pre>

<hr>
<h2 id='plot.sparsel1pca'>Plot a Sparsel1pca Object</h2><span id='topic+plot.sparsel1pca'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sparsel1pca'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sparsel1pca_+3A_x">x</code></td>
<td>

<p>an object of class <code>sparsel1pca</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.sparsel1pca_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>sparsel1pca</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sparsel1pca">sparsel1pca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mysparsel1pca &lt;- sparsel1pca(X)

##projects data into 2 dimensions.
mysparsel1pca &lt;- sparsel1pca(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(mysparsel1pca$scores)
</code></pre>

<hr>
<h2 id='plot.wl1pca'>Plot a Wl1pca Object</h2><span id='topic+plot.wl1pca'></span>

<h3>Description</h3>

<p>Plots the scores on the first two principal components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wl1pca'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.wl1pca_+3A_x">x</code></td>
<td>

<p>an object of class <code>wl1pca</code> with scores for at least the first two dimensions</p>
</td></tr>
<tr><td><code id="plot.wl1pca_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>plot</code>, for objects of class <code>wl1pca</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+l1pcastar">l1pcastar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) 
               + matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mywl1pca &lt;- wl1pca(X)

##projects data into 2 dimensions.
mywl1pca &lt;- wl1pca(X, projDim=2, center=FALSE)

## plot first two scores
plot(mywl1pca$scores)
</code></pre>

<hr>
<h2 id='sharpel1pca'>SharpEl1-PCA</h2><span id='topic+sharpel1pca'></span>

<h3>Description</h3>

<p>Performs a principal component analysis using the algorithm SharpEl1-PCA described by Brooks and Dula (2017, submitted)</p>


<h3>Usage</h3>

<pre><code class='language-R'>   sharpel1pca(X, projDim=1, center=TRUE, projections="none")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sharpel1pca_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="sharpel1pca_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>
<tr><td><code id="sharpel1pca_+3A_center">center</code></td>
<td>
<p>whether to center the data using the median, default is TRUE.</p>
</td></tr>
<tr><td><code id="sharpel1pca_+3A_projections">projections</code></td>
<td>
<p>whether to calculate reconstructions and scores using the L1 norm (&quot;l1&quot;) the L2 norm (&quot;l2&quot;) or not at all (&quot;none&quot;, default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to the algorithm described by Brooks and Dula (2017, submitted).  The algorithm finds successive, orthogonal fitted lines in the data.</p>


<h3>Value</h3>

<p>'sharpel1pca' returns a list with class &quot;sharpel1pca&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x projDim.  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>dispExp</code></td>
<td>
<p>the proportion of L1 dispersion explained by the loadings vectors.  Calculated as the L1 dispersion of the score on each component divided by the L1 dispersion in the original data.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates.  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
<tr><td><code>minobjectives</code></td>
<td>
<p>the L1 distance of points to their projections in the fitted subspace.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Brooks J.P. and Dula J.H. (2017) Estimating L1-Norm Best-Fit Lines, submitted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) +
                matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mysharpel1pca &lt;- sharpel1pca(X)

##projects data into 2 dimensions.
mysharpel1pca &lt;- sharpel1pca(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(mysharpel1pca$scores)
</code></pre>

<hr>
<h2 id='sharpel1rs'>SharpEl1-RS</h2><span id='topic+sharpel1rs'></span>

<h3>Description</h3>

<p>Fits a line in the presence of missing data based on an L1-norm criterion.</p>


<h3>Usage</h3>

<pre><code class='language-R'>   sharpel1rs(X, projDim=1, center=TRUE, projections="none")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sharpel1rs_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="sharpel1rs_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>
<tr><td><code id="sharpel1rs_+3A_center">center</code></td>
<td>
<p>whether to center the data using the median, default is TRUE.</p>
</td></tr>
<tr><td><code id="sharpel1rs_+3A_projections">projections</code></td>
<td>
<p>whether to calculate reconstructions and scores using the L1 norm (&quot;l1&quot;) the L2 norm (&quot;l2&quot;) or not at all (&quot;none&quot;, default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm finds successive, orthogonal fitted lines in the data.</p>


<h3>Value</h3>

<p>'sharpel1rs' returns a list with class &quot;sharpel1rs&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x projDim.  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>dispExp</code></td>
<td>
<p>the proportion of L1 dispersion explained by the loadings vectors.  Calculated as the L1 dispersion of the score on each component divided by the L1 dispersion in the original data.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates.  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
<tr><td><code>minobjectives</code></td>
<td>
<p>the L1 distance of points to their projections in the fitted subspace.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Valizadeh Gamchi, F. and Brooks J.P. (2023), working paper. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) +
                matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mysharpel1rs &lt;- sharpel1rs(X)

##projects data into 2 dimensions.
mysharpel1rs &lt;- sharpel1rs(X, projDim=2, center=FALSE, projections="l1")

## plot first two scores
plot(mysharpel1rs$scores)
</code></pre>

<hr>
<h2 id='sparsel1pca'>SparsEl1-PCA</h2><span id='topic+sparsel1pca'></span>

<h3>Description</h3>

<p>L1-norm line fitting with L1-regularization.</p>


<h3>Usage</h3>

<pre><code class='language-R'>   sparsel1pca(X, projDim=1, center=TRUE, projections="none", lambda=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sparsel1pca_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="sparsel1pca_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>
<tr><td><code id="sparsel1pca_+3A_center">center</code></td>
<td>
<p>whether to center the data using the median, default is TRUE.</p>
</td></tr>
<tr><td><code id="sparsel1pca_+3A_projections">projections</code></td>
<td>
<p>whether to calculate reconstructions and scores using the L1 norm (&quot;l1&quot;) the L2 norm (&quot;l2&quot;) or not at all (&quot;none&quot;, default).</p>
</td></tr>
<tr><td><code id="sparsel1pca_+3A_lambda">lambda</code></td>
<td>
<p>If negative and number of rows is at most 100, calculates all possible breakpoints for the regularization parameter. Otherwise, fits a regularlized line with lambda set to that value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to the algorithm described by Ling and Brooks (2023, working paper).  The algorithm finds successive, orthogonal fitted lines in the data.</p>


<h3>Value</h3>

<p>'sparsel1pca' returns a list with class &quot;sparsel1pca&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x projDim.  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>dispExp</code></td>
<td>
<p>the proportion of L1 dispersion explained by the loadings vectors.  Calculated as the L1 dispersion of the score on each component divided by the L1 dispersion in the original data.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of projected points in terms of the original coordinates.  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
<tr><td><code>minobjectives</code></td>
<td>
<p>the L1 distance of points to their projections in the fitted subspace.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Ling, X. and Brooks J.P. (2023) L1-Norm Regularized L1-Norm Best-Fit Lines, working paper.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for a 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) +
                matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mysparsel1pca &lt;- sparsel1pca(X, lambda=0.5)

##projects data into 2 dimensions.
mysparsel1pca &lt;- sparsel1pca(X, projDim=2, center=FALSE, projections="l1", lambda=0.5)

## plot first two scores
plot(mysparsel1pca$scores)
</code></pre>

<hr>
<h2 id='weightedL1Distance'>Weighted L1 Distance</h2><span id='topic+weightedL1Distance'></span>

<h3>Description</h3>

<p>Provides the (weighted) L1-norm distances and total distance of points to a subspace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedL1Distance(X, loadings, weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedL1Distance_+3A_x">X</code></td>
<td>
<p>data, in <code>matrix</code> or table form</p>
</td></tr>
<tr><td><code id="weightedL1Distance_+3A_loadings">loadings</code></td>
<td>
<p>an orthonormal matrix of loadings vectors</p>
</td></tr>
<tr><td><code id="weightedL1Distance_+3A_weights">weights</code></td>
<td>
<p>a list of weights for loadings vectors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reconstructions are calculated by solving a linear program.  Then the weights are applied to the distances.</p>


<h3>Value</h3>

<p>'weightedL1Distance' returns a list containing the following components:
</p>
<table>
<tr><td><code>wDistances</code></td>
<td>
<p>list of weighted distances</p>
</td></tr>
<tr><td><code>totalDistance</code></td>
<td>
<p>total distance</p>
</td></tr>
</table>

<hr>
<h2 id='wl1pca'>wPCA</h2><span id='topic+wl1pca'></span>

<h3>Description</h3>

<p>Performs a principal component analysis using the algorithm wPCA described by Park and Klabjan (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wl1pca(X, projDim=1, center=TRUE, projections="l2",
         tolerance=0.001, iterations=200, beta=0.99)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wl1pca_+3A_x">X</code></td>
<td>
<p>data, must be in <code>matrix</code> or table form.</p>
</td></tr>
<tr><td><code id="wl1pca_+3A_projdim">projDim</code></td>
<td>
<p>number of dimensions to project data into, must be an integer, default is 1.</p>
</td></tr>
<tr><td><code id="wl1pca_+3A_center">center</code></td>
<td>
<p>whether to center the data using the mean, default is TRUE</p>
</td></tr>
<tr><td><code id="wl1pca_+3A_projections">projections</code></td>
<td>
<p>whether to calculate projections (reconstructions and scores) using the L2 norm (&quot;l2&quot;, default) or the L1 norm (&quot;l1&quot;).</p>
</td></tr>
<tr><td><code id="wl1pca_+3A_tolerance">tolerance</code></td>
<td>
<p>for testing convergence; if the sum of absolute values of loadings vectors is smaller, then the algorithm terminates.</p>
</td></tr> 
<tr><td><code id="wl1pca_+3A_iterations">iterations</code></td>
<td>
<p>maximum number of iterations in optimization routine.</p>
</td></tr>
<tr><td><code id="wl1pca_+3A_beta">beta</code></td>
<td>
<p>algorithm parameter to set up bound for weights.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is performed according to the algorithm described by Park and Klabjan (2016).  The method is an  iteratively reweighted least squares algorithm for L1-norm principal component analysis.</p>


<h3>Value</h3>

<p>'wl1pca' returns a list with class &quot;wl1pca&quot; containing the following components:
</p>
<table>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings.  The matrix has dimension ncol(X) x projDim.  The columns define the projected subspace.</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>the matrix of projected points.  The matrix has dimension nrow(X) x projDim.</p>
</td></tr>
<tr><td><code>projPoints</code></td>
<td>
<p>the matrix of L2 projections points on the fitted subspace in terms of the original coordinates.  The matrix has dimension nrow(X) x ncol(X).</p>
</td></tr>
<tr><td><code>L1error</code></td>
<td>
<p>sum of the L1 norm of reconstruction errors.</p>
</td></tr>
<tr><td><code>nIter</code></td>
<td>
<p>number of iterations.</p>
</td></tr>
<tr><td><code>ElapsedTime</code></td>
<td>
<p>elapsed time.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Park, Y.W. and Klabjan, D. (2016) Iteratively Reweighted Least Squares Algorithms for L1-Norm Principal Component Analysis, <em>IEEE International Conference on Data Mining (ICDM)</em>, 2016. DOI: 10.1109/ICDM.2016.0054
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##for 100x10 data matrix X, 
## lying (mostly) in the subspace defined by the first 2 unit vectors, 
## projects data into 1 dimension.
X &lt;- matrix(c(runif(100*2, -10, 10), rep(0,100*8)),nrow=100) +
               matrix(c(rep(0,100*2),rnorm(100*8,0,0.1)),ncol=10)
mywl1pca &lt;- wl1pca(X)

##projects data into 2 dimensions.
mywl1pca &lt;- wl1pca(X, projDim=2, center=FALSE)

## plot first two scores
plot(mywl1pca$scores)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
