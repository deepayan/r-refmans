<!DOCTYPE html><html><head><title>Help for package TRES</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TRES}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bat'><p>Bat simulated data</p></a></li>
<li><a href='#ECD'><p>ECD algorithm for estimating the envelope subspace</p></a></li>
<li><a href='#EEG'><p>Electroencephalography (EEG) dataset for alcoholism study.</p></a></li>
<li><a href='#FGfun'><p>The Objective function and its gradient</p></a></li>
<li><a href='#kroncov'><p>The covariance estimation of tensor normal distribution</p></a></li>
<li><a href='#manifold1D'><p>Estimate the envelope subspace (<span class="pkg">ManifoldOptim</span> 1D)</p></a></li>
<li><a href='#manifoldFG'><p>Estimate the envelope subspace (<span class="pkg">ManifoldOptim</span> FG)</p></a></li>
<li><a href='#MenvU_sim'><p>Generate matrices <code class="reqn">M</code> and <code class="reqn">U</code></p></a></li>
<li><a href='#oneD_bic'><p>Envelope dimension selection based on 1D-BIC</p></a></li>
<li><a href='#OptM1D'><p>Estimate the envelope subspace (<span class="pkg">OptM</span> 1D)</p></a></li>
<li><a href='#OptMFG'><p>Estimate the envelope subspace (<span class="pkg">OptM</span> FG)</p></a></li>
<li><a href='#OptStiefelGBB'><p>Optimization on Stiefel manifold</p></a></li>
<li><a href='#plot.Tenv'><p>Plot coefficients and p-value for Tenv object.</p></a></li>
<li><a href='#PMSE'><p>Prediction and mean squared error.</p></a></li>
<li><a href='#predict.Tenv'><p>Predict method for Tenv object.</p></a></li>
<li><a href='#simplsMU'><p>SIMPLS-type algorithm for estimating the envelope subspace</p></a></li>
<li><a href='#square'><p>Square simulated data</p></a></li>
<li><a href='#std_err'><p>Elementwise standard error.</p></a></li>
<li><a href='#subspace'><p>The distance between two subspaces.</p></a></li>
<li><a href='#summary.Tenv'><p>Summarize method for Tenv object.</p></a></li>
<li><a href='#Tenv_Pval'><p>The <code class="reqn">p</code>-value and standard error of coefficient in tensor response regression (TRR) model.</p></a></li>
<li><a href='#TPR.fit'><p>Tensor predictor regression</p></a></li>
<li><a href='#TPRdim'><p>Envelope dimension by cross-validation for tensor predictor regression (TPR).</p></a></li>
<li><a href='#TPRsim'><p>Generate simulation data for tensor predictor regression (TPR)</p></a></li>
<li><a href='#TRES-package'><p>Tensor Regression with Envelope Structure</p></a></li>
<li><a href='#TRR.fit'><p>Tensor response regression</p></a></li>
<li><a href='#TRRdim'><p>Envelope dimension selection for tensor response regression (TRR)</p></a></li>
<li><a href='#TRRsim'><p>Generate simulation data for tensor response regression (TRR)</p></a></li>
<li><a href='#ttt'><p>Matrix product of two tensors</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tensor Regression with Envelope Structure</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-10-19</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides three estimators for tensor response regression (TRR) and tensor predictor regression (TPR) models with tensor envelope structure. The three types of estimation approaches are generic and can be applied to any envelope estimation problems. The full Grassmannian (FG) optimization is often associated with likelihood-based estimation but requires heavy computation and good initialization; the one-directional optimization approaches (1D and ECD algorithms) are faster, stable and does not require carefully chosen initial values; the SIMPLS-type is motivated by the partial least squares regression and is computationally the least expensive. For details of TRR, see Li L, Zhang X (2017) &lt;<a href="https://doi.org/10.1080%2F01621459.2016.1193022">doi:10.1080/01621459.2016.1193022</a>&gt;. For details of TPR, see Zhang X, Li L (2017) &lt;<a href="https://doi.org/10.1080%2F00401706.2016.1272495">doi:10.1080/00401706.2016.1272495</a>&gt;. For details of 1D algorithm, see Cook RD, Zhang X (2016) &lt;<a href="https://doi.org/10.1080%2F10618600.2015.1029577">doi:10.1080/10618600.2015.1029577</a>&gt;. For details of ECD algorithm, see Cook RD, Zhang X (2018) &lt;<a href="https://doi.org/10.5705%2Fss.202016.0037">doi:10.5705/ss.202016.0037</a>&gt;. For more details of the package, see Zeng J, Wang W, Zhang X (2021) &lt;<a href="https://doi.org/10.18637%2Fjss.v099.i12">doi:10.18637/jss.v099.i12</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0), ManifoldOptim (&ge; 1.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, methods, pracma (&ge; 2.2.5), rTensor (&ge; 1.4), stats</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/leozeng15/TRES">https://github.com/leozeng15/TRES</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/leozeng15/TRES/issues">https://github.com/leozeng15/TRES/issues</a></td>
</tr>
<tr>
<td>RcppModules:</td>
<td>ManifoldOptim_module</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 2.1.0)</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-10-19 18:22:34 UTC; JingZeng</td>
</tr>
<tr>
<td>Author:</td>
<td>Wenjing Wang [aut],
  Jing Zeng [aut, cre],
  Xin Zhang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jing Zeng &lt;jing.zeng@stat.fsu.edu&gt;</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-10-20 05:20:16 UTC</td>
</tr>
</table>
<hr>
<h2 id='bat'>Bat simulated data</h2><span id='topic+bat'></span>

<h3>Description</h3>

<p>Synthetic data generated from tensor response regression (TRR) model. Each response observation is a two-dimensional image, and each binary predictor observation takes values 0 and 1, representing two groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("bat")
</code></pre>


<h3>Format</h3>

<p>A list consisting of four components:
</p>

<dl>
<dt>x</dt><dd><p>A <code class="reqn">1 \times 20</code> matrix, each entry takes values 0 and 1, representing two groups.</p>
</dd>
<dt>y</dt><dd><p>A <code class="reqn">64\times 64\times 20</code> tensor, each matrix <code>y@data[,,i]</code> represents an image.</p>
</dd>
<dt>coeffiicients</dt><dd><p>A <code class="reqn">64\times 64 \times 1</code> tensor with the bat pattern.</p>
</dd>
<dt>Gamma</dt><dd><p>A list consisting of two <code class="reqn">64 \times 14</code> envelope basis.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The dataset is generated from the tensor response regression (TRR) model:
</p>
<p style="text-align: center;"><code class="reqn">Y_i = B X_i + \epsilon_i,  i = 1,\ldots, n,</code>
</p>

<p>where <code class="reqn">n=20</code> and the regression coefficient <code class="reqn">B \in R^{64\times 64}</code> is a given image with rank 14, representing the mean difference of the response <code class="reqn">Y</code> between two groups. To make the model conform to the envelope structure, we construct the envelope basis <code class="reqn">\Gamma_k</code> and the covariance matrices <code class="reqn">\Sigma_k, k=1,2</code>, of error term as following. With the singular value decomposition of <code class="reqn">B</code>, namely <code class="reqn">B = \Gamma_1 \Lambda \Gamma_2^T</code>, we choose the envelope basis as <code class="reqn">\Gamma_k \in R^{64\times 14}, k=1,2</code>. Then the envelope dimensions are <code class="reqn">u_1 =  u_2 = 14</code>. We generate another two matrices <code class="reqn">\Omega_k \in R^{14\times 14} = A_k A_k^T</code> and  <code class="reqn">\Omega_{0k} \in R^{50\times 50} =  A_{0k}A_{0k}^T</code>, where <code class="reqn">A_k \in R^{14\times 14}</code> and <code class="reqn">A_{0k} \in R^{50\times 50}</code> are randomly generated from Uniform(0,1) elementwise. Then we set the covariance matrices <code class="reqn">\Sigma_k = \Gamma_k\Omega_k \Gamma_k^T + \Gamma_{0k}\Omega_{0k} \Gamma_{0k}^T</code>, followed by normalization with their Frobenius norms. We set the first 10 predictors <code class="reqn">X_i, i=1,\ldots, 10,</code> as 1 and the rest as 0. The error term is then generated from two-way tensor (matrix) normal distribution <code class="reqn">TN( 0; \Sigma_1, \Sigma_2)</code>.
</p>


<h3>References</h3>

<p>Li, L. and Zhang, X., 2017. Parsimonious tensor response regression. Journal of the American Statistical Association, 112(519), pp.1131-1146.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit bat dataset with the tensor response regression model
data("bat")
x &lt;- bat$x
y &lt;- bat$y
# Model fitting with ordinary least square.
fit_std &lt;- TRR.fit(x, y, method="standard")
# Draw the coefficient and p-value plots
plot(fit_std)

</code></pre>

<hr>
<h2 id='ECD'>ECD algorithm for estimating the envelope subspace</h2><span id='topic+ECD'></span>

<h3>Description</h3>

<p>Estimate the envelope subspace with specified dimension based on ECD algorithm proposed by Cook, R. D., &amp; Zhang, X. (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ECD(M, U, u, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ECD_+3A_m">M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive definite matrix <code class="reqn">M</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="ECD_+3A_u">U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive semi-definite matrix <code class="reqn">U</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="ECD_+3A_u">u</code></td>
<td>
<p>An integer between 0 and <code class="reqn">n</code> representing the envelope dimension.</p>
</td></tr>
<tr><td><code id="ECD_+3A_...">...</code></td>
<td>
<p>Additional user-defined arguments:
</p>

<ul>
<li><p><code>maxiter</code>: The maximal number of iterations.
</p>
</li>
<li><p><code>tol</code>: The tolerance used to assess convergence. See the ECD algorithm in Cook, R. D., &amp; Zhang, X. (2018).
</p>
</li></ul>

<p>The default values are: <code>maxiter=500; tol=1e-08</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimate <code>M</code>-envelope of <code>span(U)</code>. The dimension of the envelope is <code>u</code>.
</p>
<p>See <code><a href="#topic+FGfun">FGfun</a></code> for the generic objective function.
</p>
<p>The ECD algorithm is similar to 1D algorithm proposed by Cook, R. D., &amp; Zhang, X. (2016). A fast and stable algorithm is used for solving each individual objective function.
</p>


<h3>Value</h3>

<p>Return the orthogonal basis of the envelope subspace with each column represent the sequential direction. For example, the first column is the most informative direction.
</p>


<h3>References</h3>

<p>Cook, R.D. and Zhang, X., 2018. Fast envelope algorithms. Statistica Sinica, 28(3), pp.1179-1197.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##simulate two matrices M and U with an envelope structure#
data &lt;- MenvU_sim(p = 20, u = 5, wishart = TRUE, n = 200)
M &lt;- data$M
U &lt;- data$U
G &lt;- data$Gamma
Gamma_ECD &lt;- ECD(M, U, u=5)
subspace(Gamma_ECD, G)

</code></pre>

<hr>
<h2 id='EEG'>Electroencephalography (EEG) dataset for alcoholism study.</h2><span id='topic+EEG'></span>

<h3>Description</h3>

<p>EEG images data of subjects in alcoholic and control groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EEG")
</code></pre>


<h3>Format</h3>

<p>A list consisting of two components:
</p>

<dl>
<dt>x</dt><dd><p>A binary vector with length of 61.</p>
</dd>
<dt>y</dt><dd><p>A <code class="reqn">64 \times 64 \times 61</code> tensor, consisting of 61 <em>channels</em> by <em>time</em> EEG images.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The original EEG data contains 77 alcoholic individuals and 45 controls. To reduce the size, we randomly select 61 samples and obtain 39 alcoholic individuals and 22 controls. Each individual was measured with 64 electrodes placed on the scalp sampled at 256 Hz for 1 sec, resulting an EEG image of 64 channels by 256 time points. More information about data collection and some analysis can be found in Zhang et al. (1995) and Li, Kim, and Altman (2010). To facilitate the analysis, the data is downsized along the time domain by averaging every four consecutive time points, yielding a 64 × 64 matrix response.
</p>


<h3>References</h3>

<p>URL: <a href="https://archive.ics.uci.edu/ml/datasets/EEG+Database">https://archive.ics.uci.edu/ml/datasets/EEG+Database</a>.
</p>
<p>Li, L. and Zhang, X., 2017. Parsimonious tensor response regression. Journal of the American Statistical Association, 112(519), pp.1131-1146.
</p>
<p>Zhang, X.L., Begleiter, H., Porjesz, B., Wang, W. and Litke, A., 1995. Event related potentials during object recognition tasks. Brain research bulletin, 38(6), pp.531-538.
</p>
<p>Li, B., Kim, M.K. and Altman, N., 2010. On dimension folding of matrix-or array-valued statistical objects. The Annals of Statistics, 38(2), pp.1094-1121.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("EEG")
x &lt;- EEG$x
y &lt;- EEG$y
## Estimate the envelope dimension, the output should be c(1,1).

u &lt;- TRRdim(x, y)$u
u &lt;- c(1,1)

## Fit the dataset with TRR.fit and draw the coefficient plot and p-value plot
fit_1D &lt;- TRR.fit(x, y, u, method = "1D")
plot(fit_1D, xlab = "Time", ylab = "Channels")

## Uncomment display the plots from different methods.
# fit_ols &lt;- TRR.fit(x, y, method = "standard")
# fit_pls &lt;- TRR.fit(x, y, u, method = "PLS")
# plot(fit_ols, xlab = "Time", ylab = "Channels")
# plot(fit_pls, xlab = "Time", ylab = "Channels")

</code></pre>

<hr>
<h2 id='FGfun'>The Objective function and its gradient</h2><span id='topic+FGfun'></span>

<h3>Description</h3>

<p>Calculates the objective function and its gradient for estimating the <code class="reqn">M</code>-envelope of span(<code class="reqn">U</code>), where <code class="reqn">M</code> is positive definite and <code class="reqn">U</code> is positive semi-definite.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FGfun(Gamma, M, U)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FGfun_+3A_gamma">Gamma</code></td>
<td>
<p><code class="reqn">\Gamma</code> matrix in the envelope objective function. A <code class="reqn">p</code>-by-<code class="reqn">u</code> matrix.</p>
</td></tr>
<tr><td><code id="FGfun_+3A_m">M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive definite matrix <code class="reqn">M</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="FGfun_+3A_u">U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive semi-definite matrix <code class="reqn">U</code> in the envelope objective function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generic objective function <code class="reqn">F(\Gamma)</code> and its gradient <code class="reqn">G(\Gamma)</code> are listed below for estimating <code class="reqn">M</code>-envelope of span(<code class="reqn">U</code>). For the detailed description, see Cook, R. D., &amp; Zhang, X. (2016).
</p>
<p style="text-align: center;"><code class="reqn">F(\Gamma)=\log|\Gamma^T M \Gamma|+\log| \Gamma^T(M+U)^{-1}\Gamma|</code>
</p>

<p style="text-align: center;"><code class="reqn">G(\Gamma) = dF/d \Gamma = 2 M \Gamma (\Gamma^T M \Gamma)^{-1} + 2 (M + U)^{-1} \Gamma (\Gamma^T (M + U)^{-1} \Gamma)^{-1}</code>
</p>



<h3>Value</h3>

<table>
<tr><td><code>F</code></td>
<td>
<p>The value of the objective function at <code>Gamma</code>.</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>The value of the gradient function at <code>Gamma</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cook, R.D. and Zhang, X., 2016. Algorithms for envelope estimation. Journal of Computational and Graphical Statistics, 25(1), pp.284-300.
</p>

<hr>
<h2 id='kroncov'>The covariance estimation of tensor normal distribution</h2><span id='topic+kroncov'></span>

<h3>Description</h3>

<p>This function provides the MLE of the covariance matrix of tensor normal distribution, where the covariance has a separable Kronecker structure, i.e. <code class="reqn">\Sigma=\Sigma_{m}\otimes \ldots \otimes\Sigma_{1}</code>. The algorithm is a generalization of the MLE algorithm in Manceur, A. M., &amp; Dutilleul, P. (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kroncov(Tn, tol = 1e-06, maxiter = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kroncov_+3A_tn">Tn</code></td>
<td>
<p>A <code class="reqn">p_1\times\cdots p_m\times n</code> matrix, array or tensor, where <code class="reqn">n</code> is the sample size.</p>
</td></tr>
<tr><td><code id="kroncov_+3A_tol">tol</code></td>
<td>
<p>The convergence tolerance with default value <code>1e-6</code>. The iteration terminates when <code class="reqn">||\Sigma_i^{(t+1)} - \Sigma_i^{(t)}||_F &lt;</code> <code>tol</code> for some covariance matrix <code class="reqn">\Sigma_i</code>.</p>
</td></tr>
<tr><td><code id="kroncov_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximal number of iterations. The default value is 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The individual component covariance matrices <code class="reqn">\Sigma_i, i=1,\ldots, m</code> are not identifiable. To overcome the identifiability issue, each matrix <code class="reqn">\Sigma_i</code> is normalized at the end of the iteration such that <code class="reqn">||\Sigma_i||_F = 1</code>. And an overall normalizing constant <code class="reqn">\lambda</code> is extracted so that the overall covariance matrix <code class="reqn">\Sigma</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\Sigma = \lambda \Sigma_m \otimes \cdots \otimes \Sigma_1.</code>
</p>

<p>If <code>Tn</code> is a <code class="reqn">p \times n</code> design matrix for a multivariate random variable, then <code>lambda = 1</code> and <code>S</code> is a length-one list containing the sample covariance matrix.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lambda</code></td>
<td>
<p>The normalizing constant.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>A matrix list, consisting of each normalized covariance matrix <code class="reqn">\Sigma_1,\ldots,\Sigma_m</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Manceur, A.M. and Dutilleul, P., 2013. Maximum likelihood estimation for the tensor normal distribution: Algorithm, minimum sample size, and empirical bias and dispersion. Journal of Computational and Applied Mathematics, 239, pp.37-49.
</p>

<hr>
<h2 id='manifold1D'>Estimate the envelope subspace (<span class="pkg">ManifoldOptim</span> 1D)</h2><span id='topic+manifold1D'></span>

<h3>Description</h3>

<p>The 1D algorithm (Cook and Zhang 2016) implemented with Riemannian manifold optimization from R package <span class="pkg">ManifoldOptim</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manifold1D(M, U, u, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="manifold1D_+3A_m">M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive definite matrix <code class="reqn">M</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="manifold1D_+3A_u">U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive semi-definite matrix <code class="reqn">U</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="manifold1D_+3A_u">u</code></td>
<td>
<p>An integer between 0 and <code class="reqn">n</code> representing the envelope dimension.</p>
</td></tr>
<tr><td><code id="manifold1D_+3A_...">...</code></td>
<td>
<p>Additional user-defined arguments:
</p>

<ul>
<li><p><code>maxiter</code>: The maximal number of iterations.
</p>
</li>
<li><p><code>tol</code>: The tolerance used to assess convergence. See Huang et al. (2018) for details on how this is used.
</p>
</li>
<li><p><code>method</code>: The name of optimization method supported by R package <span class="pkg">ManifoldOptim</span>.
</p>

<ul>
<li><p><code>"LRBFGS"</code>: Limited-memory RBFGS
</p>
</li>
<li><p><code>"LRTRSR1"</code>: Limited-memory RTRSR1
</p>
</li>
<li><p><code>"RBFGS"</code>: Riemannian BFGS
</p>
</li>
<li><p><code>"RBroydenFamily"</code>: Riemannian Broyden family
</p>
</li>
<li><p><code>"RCG"</code>: Riemannian conjugate gradients
</p>
</li>
<li><p><code>"RNewton"</code>: Riemannian line-search Newton
</p>
</li>
<li><p><code>"RSD"</code>: Riemannian steepest descent
</p>
</li>
<li><p><code>"RTRNewton"</code>: Riemannian trust-region Newton
</p>
</li>
<li><p><code>"RTRSD"</code>: Riemannian trust-region steepest descent
</p>
</li>
<li><p><code>"RTRSR1"</code>: Riemannian trust-region symmetric rank-one update
</p>
</li>
<li><p><code>"RWRBFGS"</code>: Riemannian BFGS
</p>
</li></ul>


</li>
<li><p><code>check</code>: Logical value. Should internal manifold object check inputs and print summary message before optimization.
</p>
</li></ul>

<p>The default values are: <code>maxiter = 500; tol = 1e-08; method = "RCG"; check = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimate <code>M</code>-envelope of <code>span(U)</code>. The dimension of the envelope is <code>u</code>.
</p>


<h3>Value</h3>

<p>Return the estimated orthogonal basis of the envelope subspace.
</p>


<h3>References</h3>

<p>Cook, R.D. and Zhang, X., 2016. Algorithms for envelope estimation. Journal of Computational and Graphical Statistics, 25(1), pp.284-300.
</p>
<p>Huang, W., Absil, P.A., Gallivan, K.A. and Hand, P., 2018. ROPTLIB: an object-oriented C++ library for optimization on Riemannian manifolds. ACM Transactions on Mathematical Software (TOMS), 44(4), pp.1-21.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MenvU_sim">MenvU_sim</a>, <a href="#topic+subspace">subspace</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate two matrices M and U with an envelope structure
data &lt;- MenvU_sim(p = 20, u = 5, wishart = TRUE, n = 200)
M &lt;- data$M
U &lt;- data$U
G &lt;- data$Gamma
Gamma_1D &lt;- manifold1D(M, U, u = 5)
subspace(Gamma_1D, G)

</code></pre>

<hr>
<h2 id='manifoldFG'>Estimate the envelope subspace (<span class="pkg">ManifoldOptim</span> FG)</h2><span id='topic+manifoldFG'></span>

<h3>Description</h3>

<p>The FG algorithm (Cook and Zhang 2016) implemented with Riemannian manifold optimization from R package <span class="pkg">ManifoldOptim</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manifoldFG(M, U, u, Gamma_init = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="manifoldFG_+3A_m">M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive definite matrix <code class="reqn">M</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="manifoldFG_+3A_u">U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive semi-definite matrix <code class="reqn">U</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="manifoldFG_+3A_u">u</code></td>
<td>
<p>An integer between 0 and <code class="reqn">n</code> representing the envelope dimension. Ignored if <code>Gamma_init</code> is provided.</p>
</td></tr>
<tr><td><code id="manifoldFG_+3A_gamma_init">Gamma_init</code></td>
<td>
<p>Initial envelope subspace basis. The default value is the estimator from <code>manifold1D(M, U, u)</code>.</p>
</td></tr>
<tr><td><code id="manifoldFG_+3A_...">...</code></td>
<td>
<p>Additional user-defined arguments:
</p>

<ul>
<li><p><code>maxiter</code>: The maximal number of iterations.
</p>
</li>
<li><p><code>tol</code>: The tolerance used to assess convergence. See Huang et al. (2018) for details on how this is used.
</p>
</li>
<li><p><code>method</code>: The name of optimization method supported by R package <span class="pkg">ManifoldOptim</span>
</p>

<ul>
<li><p><code>"LRBFGS"</code>: Limited-memory RBFGS
</p>
</li>
<li><p><code>"LRTRSR1"</code>: Limited-memory RTRSR1
</p>
</li>
<li><p><code>"RBFGS"</code>: Riemannian BFGS
</p>
</li>
<li><p><code>"RBroydenFamily"</code>: Riemannian Broyden family
</p>
</li>
<li><p><code>"RCG"</code>: Riemannian conjugate gradients
</p>
</li>
<li><p><code>"RNewton"</code>: Riemannian line-search Newton
</p>
</li>
<li><p><code>"RSD"</code>: Riemannian steepest descent
</p>
</li>
<li><p><code>"RTRNewton"</code>: Riemannian trust-region Newton
</p>
</li>
<li><p><code>"RTRSD"</code>: Riemannian trust-region steepest descent
</p>
</li>
<li><p><code>"RTRSR1"</code>: Riemannian trust-region symmetric rank-one update
</p>
</li>
<li><p><code>"RWRBFGS"</code>: Riemannian BFGS
</p>
</li></ul>

</li>
<li><p><code>check</code>: Logical value. Should internal manifold object check inputs and print summary message before optimization.
</p>
</li></ul>

<p>The default values are: <code>maxiter = 500; tol = 1e-08; method = "RCG"; check = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimate <code>M</code>-envelope of <code>span(U)</code>. The dimension of the envelope is <code>u</code>.
</p>


<h3>Value</h3>

<p>Return the estimated orthogonal basis of the envelope subspace.
</p>


<h3>References</h3>

<p>Cook, R.D. and Zhang, X., 2016. Algorithms for envelope estimation. Journal of Computational and Graphical Statistics, 25(1), pp.284-300.
</p>
<p>Huang, W., Absil, P.A., Gallivan, K.A. and Hand, P., 2018. ROPTLIB: an object-oriented C++ library for optimization on Riemannian manifolds. ACM Transactions on Mathematical Software (TOMS), 44(4), pp.1-21.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##simulate two matrices M and U with an envelope structure
data &lt;- MenvU_sim(p=20, u=5, wishart = TRUE, n = 200)
M &lt;- data$M
U &lt;- data$U
G &lt;- data$Gamma
Gamma_FG &lt;- manifoldFG(M, U, u=5)
subspace(Gamma_FG, G)

</code></pre>

<hr>
<h2 id='MenvU_sim'>Generate matrices <code class="reqn">M</code> and <code class="reqn">U</code></h2><span id='topic+MenvU_sim'></span>

<h3>Description</h3>

<p>This function generates the matrices <code class="reqn">M</code> and <code class="reqn">U</code> with envelope structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MenvU_sim(
  p,
  u,
  Omega = NULL,
  Omega0 = NULL,
  Phi = NULL,
  jitter = FALSE,
  wishart = FALSE,
  n = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MenvU_sim_+3A_p">p</code></td>
<td>
<p>Dimension of <code class="reqn">p</code>-by-<code class="reqn">p</code> matrix <code class="reqn">M</code>.</p>
</td></tr>
<tr><td><code id="MenvU_sim_+3A_u">u</code></td>
<td>
<p>The envelope dimension. An integer between 0 and <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="MenvU_sim_+3A_omega">Omega</code></td>
<td>
<p>The positive definite matrix <code class="reqn">\Omega</code> in <code class="reqn">M=\Gamma\Omega\Gamma^T+\Gamma_0\Omega_0\Gamma_0^T</code>. The default is <code class="reqn">\Omega=AA^T</code> where the elements in <code class="reqn">A</code> are generated from Uniform(0,1) distribution.</p>
</td></tr>
<tr><td><code id="MenvU_sim_+3A_omega0">Omega0</code></td>
<td>
<p>The positive definite matrix <code class="reqn">\Omega_0</code> in <code class="reqn">M=\Gamma\Omega\Gamma^T+\Gamma_0\Omega_0\Gamma_0^T</code>. The default is <code class="reqn">\Omega_0=AA^T</code> where the elements in <code class="reqn">A</code> are generated from Uniform(0,1) distribution.</p>
</td></tr>
<tr><td><code id="MenvU_sim_+3A_phi">Phi</code></td>
<td>
<p>The positive definite matrix <code class="reqn">\Phi</code> in <code class="reqn">U=\Gamma\Phi\Gamma^T</code>. The default is <code class="reqn">\Phi=AA^T</code> where the elements in <code class="reqn">A</code> are generated from Uniform(0,1) distribution.</p>
</td></tr>
<tr><td><code id="MenvU_sim_+3A_jitter">jitter</code></td>
<td>
<p>Logical or numeric. If it is numeric, the diagonal matrix <code>diag(jitter, nrow(M), ncol(M))</code> is added to matrix <code class="reqn">M</code> to ensure the positive definiteness of <code class="reqn">M</code>. If it is <code>TRUE</code>, then it is set as <code>1e-5</code> and the jitter is added. If it is <code>FALSE</code> (default), no jitter is added.</p>
</td></tr>
<tr><td><code id="MenvU_sim_+3A_wishart">wishart</code></td>
<td>
<p>Logical. If it is <code>TRUE</code>, the sample estimator from Wishart distribution <code class="reqn">W_p(M/n, n)</code> and <code class="reqn">W_p(U/n, n)</code> are generated as the output matrices <code>M</code> and <code>U</code>.</p>
</td></tr>
<tr><td><code id="MenvU_sim_+3A_n">n</code></td>
<td>
<p>The sample size. If <code>wishart</code> is <code>FALSE</code>, then <code>n</code> is ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The matrices <code class="reqn">M</code> and <code class="reqn">U</code> are in forms of
</p>
<p style="text-align: center;"><code class="reqn">M = \Gamma \Omega \Gamma^T + \Gamma_0\Omega_0\Gamma_0^T, U = \Gamma \Phi \Gamma^T.</code>
</p>

<p>The envelope basis <code class="reqn">\Gamma</code> is randomly generated from the Uniform (0, 1) distribution elementwise and then transformed to a semi-orthogonal matrix. <code class="reqn">\Gamma_0</code> is the orthogonal completion of <code class="reqn">\Gamma</code>.
</p>
<p>In some cases, to guarantee that <code class="reqn">M</code> is positive definite which is required by the definition of envelope, a <code>jitter</code> should be added to <code class="reqn">M</code>.
</p>
<p>If <code>wishart</code> is <code>TRUE</code>, after the matrices <code class="reqn">M</code> and <code class="reqn">U</code> are generated, the samples from Wishart distribution <code class="reqn">W_p(M/n, n)</code> and <code class="reqn">W_p(U/n, n)</code> are output as matrices <code class="reqn">M</code> and <code class="reqn">U</code>. If so, <code>n</code> is required.
</p>


<h3>Value</h3>

<table>
<tr><td><code>M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> matrix <code>M</code>.</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> matrix <code>U</code>.</p>
</td></tr>
<tr><td><code>Gamma</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">u</code> envelope basis.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cook, R.D. and Zhang, X., 2018. Fast envelope algorithms. Statistica Sinica, 28(3), pp.1179-1197.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data1 &lt;- MenvU_sim(p = 20, u = 5)
M1 &lt;- data1$M
U1 &lt;- data1$U

# Sample version from Wishart distribution
data2 &lt;- MenvU_sim(p = 20, u = 5, wishart = TRUE, n = 200)
M2 &lt;- data2$M
U2 &lt;- data2$U

</code></pre>

<hr>
<h2 id='oneD_bic'>Envelope dimension selection based on 1D-BIC</h2><span id='topic+oneD_bic'></span>

<h3>Description</h3>

<p>This function selects envelope subspace dimension using 1D-BIC proposed by Zhang, X., &amp; Mai, Q. (2018). The constrained optimization in the 1D algorithm is based on the line search algorithm for optimization on manifold. The algorithm is developed by Wen and Yin (2013) and the Matlab version is in the Matlab package <span class="pkg">OptM</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oneD_bic(M, U, n, C = 1, maxdim = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oneD_bic_+3A_m">M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive definite matrix <code class="reqn">M</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="oneD_bic_+3A_u">U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive semi-definite matrix <code class="reqn">U</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="oneD_bic_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code id="oneD_bic_+3A_c">C</code></td>
<td>
<p>The constant defined in 1D-BIC criterion, the default value is 1.</p>
</td></tr>
<tr><td><code id="oneD_bic_+3A_maxdim">maxdim</code></td>
<td>
<p>The maximum dimension to consider, <code>maxdim</code> is smaller than <code class="reqn">p</code>, the default value is 10.</p>
</td></tr>
<tr><td><code id="oneD_bic_+3A_...">...</code></td>
<td>
<p>Additional user-defined arguments for the line search algorithm:
</p>

<ul>
<li> <p><code>maxiter</code>: The maximal number of iterations.
</p>
</li>
<li> <p><code>xtol</code>: The convergence tolerance for the relative changes of the consecutive iterates <code class="reqn">w</code>, e.g., <code class="reqn">||w^{(k)} - w^{(k-1)}||_F/\sqrt{p}</code>
</p>
</li>
<li> <p><code>gtol</code>: The convergence tolerance for the gradient of Lagrangian, e.g., <code class="reqn">||G^{(k)} - w^{(k)} (G^{(t)})^T w^{(t)}||_F</code>
</p>
</li>
<li> <p><code>ftol</code>: The convergence tolerance for relative changes of the consecutive objective function values <code class="reqn">F</code>, e.g., <code class="reqn">|F^{(k)} - F^{(k-1)}|/(1+|F^{(k-1)}|)</code>. Usually, <code>max{xtol, gtol} &gt; ftol</code>
</p>
</li></ul>

<p>The default values are: <code>maxiter=500; xtol=1e-08; gtol=1e-08; ftol=1e-12.</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The objective function <code class="reqn">F(w)</code> and its gradient <code class="reqn">G(w)</code> in line search algorithm are:
</p>
<p style="text-align: center;"><code class="reqn">F(w)=\log|w^T M_k w|+\log|w^T(M_k+U_k)^{-1}w|</code>
</p>

<p style="text-align: center;"><code class="reqn">G(w) = dF/dw = 2 (w^T M_k w)^{-1} M_k w + 2 (w^T (M_k + U_k)^{-1} w)^{-1}(M_k + U_k)^{-1} w</code>
</p>

<p>See Cook, R. D., &amp; Zhang, X. (2016) for more details of the 1D algorithm.
</p>
<p>The 1D-BIC criterion is defined as
</p>
<p style="text-align: center;"><code class="reqn">I(k) = \sum_{j=1}^k \phi_j(\hat{w}_j) + Ck\log(n)/n, \quad k = 0,1, \ldots, p,</code>
</p>

<p>where <code class="reqn">C &gt; 0</code> is a constant, <code class="reqn">\hat{w}</code> is the 1D solver, the function <code class="reqn">\phi_j</code> is the individual objective function solved by 1D algorithm, <code class="reqn">n</code> is the sample size. Then the selected dimension <code class="reqn">u</code> is the one yielding the smallest 1D-BIC <code class="reqn">I(k)</code>. See Zhang, X., &amp; Mai, Q. (2018) for more details.
</p>
<p>As suggested by Zhang, X., &amp; Mai, Q. (2018), the number <code class="reqn">C</code> should be set to its default value <code class="reqn">C = 1</code> when there is no additional model assumption or prior information. However, if additional model assumption or prior information are known, C should be set such that <code class="reqn">Ck</code> best matches the degree-of-freedom or total number of free parameters of the model or estimation procedure. For example, in TRR model where the predictor design matrix is of dimension <code class="reqn">p \times n</code>, <code class="reqn">C</code> should be set as <code class="reqn">p</code>. See Zhang, X., &amp; Mai, Q. (2018) for more details.
</p>


<h3>Value</h3>

<table>
<tr><td><code>bicval</code></td>
<td>
<p>The BIC values for different envelope dimensions.</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>The dimension selected which corresponds to the smallest BIC values.</p>
</td></tr>
<tr><td><code>Gamma</code></td>
<td>
<p>The estimation of envelope subspace basis.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, X. and Mai, Q., 2018. Model-free envelope dimension selection. Electronic Journal of Statistics, 12(2), pp.2193-2216.
</p>
<p>Wen, Z. and Yin, W., 2013. A feasible method for optimization with orthogonality constraints. Mathematical Programming, 142(1-2), pp.397-434.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OptM1D">OptM1D</a>, <a href="#topic+MenvU_sim">MenvU_sim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##simulate two matrices M and U with an envelope structure
data &lt;- MenvU_sim(p = 20, u = 5, wishart = TRUE, n = 200)
M &lt;- data$M
U &lt;- data$U
bic &lt;- oneD_bic(M, U, n = 200)
## visualization
plot(1:10, bic$bicval, type="o", xlab="Envelope Dimension", ylab="BIC values",
main="Envelope Dimension Selection")

</code></pre>

<hr>
<h2 id='OptM1D'>Estimate the envelope subspace (<span class="pkg">OptM</span> 1D)</h2><span id='topic+OptM1D'></span>

<h3>Description</h3>

<p>The 1D algorithm to estimate the envelope subspace based on the line search algorithm for optimization on manifold. The line search algorithm is developed by Wen and Yin (2013) and the Matlab version is implemented in the Matlab package <span class="pkg">OptM</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptM1D(M, U, u, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptM1D_+3A_m">M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive definite matrix <code class="reqn">M</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="OptM1D_+3A_u">U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive semi-definite matrix <code class="reqn">U</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="OptM1D_+3A_u">u</code></td>
<td>
<p>An integer between 0 and <code class="reqn">n</code> representing the envelope dimension.</p>
</td></tr>
<tr><td><code id="OptM1D_+3A_...">...</code></td>
<td>
<p>Additional user-defined arguments for the line search algorithm:
</p>

<ul>
<li> <p><code>maxiter</code>: The maximal number of iterations.
</p>
</li>
<li> <p><code>xtol</code>: The convergence tolerance for the relative changes of the consecutive iterates <code class="reqn">w</code>, e.g., <code class="reqn">||w^{(k)} - w^{(k-1)}||_F/\sqrt{p}</code>
</p>
</li>
<li> <p><code>gtol</code>: The convergence tolerance for the gradient of Lagrangian, e.g., <code class="reqn">||G^{(k)} - w^{(k)} (G^{(t)})^T w^{(t)}||_F</code>
</p>
</li>
<li> <p><code>ftol</code>: The convergence tolerance for relative changes of the consecutive objective function values <code class="reqn">F</code>, e.g., <code class="reqn">|F^{(k)} - F^{(k-1)}|/(1+|F^{(k-1)}|)</code>. Usually, <code>max{xtol, gtol} &gt; ftol</code>
</p>
</li></ul>

<p>The default values are: <code>maxiter=500; xtol=1e-08; gtol=1e-08; ftol=1e-12.</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The objective function <code class="reqn">F(w)</code> and its gradient <code class="reqn">G(w)</code> in line search algorithm are:
</p>
<p style="text-align: center;"><code class="reqn">F(w)=\log|w^T M_k w|+\log|w^T(M_k+U_k)^{-1}w|</code>
</p>

<p style="text-align: center;"><code class="reqn">G(w) = dF/dw = 2 (w^T M_k w)^{-1} M_k w + 2 (w^T (M_k + U_k)^{-1} w)^{-1}(M_k + U_k)^{-1} w</code>
</p>

<p>See Cook, R. D., &amp; Zhang, X. (2016) for more details of the 1D algorithm.
</p>


<h3>Value</h3>

<p>Return the estimated orthogonal basis of the envelope subspace.
</p>


<h3>References</h3>

<p>Cook, R.D. and Zhang, X., 2016. Algorithms for envelope estimation. Journal of Computational and Graphical Statistics, 25(1), pp.284-300.
</p>
<p>Wen, Z. and Yin, W., 2013. A feasible method for optimization with orthogonality constraints. Mathematical Programming, 142(1-2), pp.397-434.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate two matrices M and U with an envelope structure
data &lt;- MenvU_sim(p = 20, u = 5, wishart = TRUE, n = 200)
M &lt;- data$M
U &lt;- data$U
G &lt;- data$Gamma
Gamma_1D &lt;- OptM1D(M, U, u = 5)
subspace(Gamma_1D, G)

</code></pre>

<hr>
<h2 id='OptMFG'>Estimate the envelope subspace (<span class="pkg">OptM</span> FG)</h2><span id='topic+OptMFG'></span>

<h3>Description</h3>

<p>The FG algorithm to estimate the envelope subspace based on the curvilinear search algorithm for optimization on Stiefel manifold. The curvilinear algorithm is developed by Wen and Yin (2013) and the Matlab version is implemented in the Matlab package <span class="pkg">OptM</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptMFG(M, U, u, Gamma_init = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptMFG_+3A_m">M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive definite matrix <code class="reqn">M</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="OptMFG_+3A_u">U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive semi-definite matrix <code class="reqn">U</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="OptMFG_+3A_u">u</code></td>
<td>
<p>An integer between 0 and <code class="reqn">n</code> representing the envelope dimension. Ignored if <code>Gamma_init</code> is provided.</p>
</td></tr>
<tr><td><code id="OptMFG_+3A_gamma_init">Gamma_init</code></td>
<td>
<p>Initial envelope subspace basis. The default value is the estimator from <code>OptM1D(M, U, u)</code>.</p>
</td></tr>
<tr><td><code id="OptMFG_+3A_...">...</code></td>
<td>
<p>Additional user-defined arguments for the curvilinear search algorithm:
</p>

<ul>
<li> <p><code>maxiter</code>: The maximal number of iterations.
</p>
</li>
<li> <p><code>xtol</code>: The convergence tolerance for <code class="reqn">\Gamma</code>, e.g., <code class="reqn">||\Gamma^{(k)} - \Gamma^{(k-1)}||_F/\sqrt{p}</code>
</p>
</li>
<li> <p><code>gtol</code>: The convergence tolerance for the projected gradient, e.g., <code class="reqn">||G^{(k)} - \Gamma^{(k)} (G^{(t)})^T \Gamma^{(t)}||_F</code>
</p>
</li>
<li> <p><code>ftol</code>: The convergence tolerance for objective function <code class="reqn">F</code>, e.g., <code class="reqn">|F^{(k)} - F^{(k-1)}|/(1+|F^{(k-1)}|)</code>. Usually, <code>max{xtol, gtol} &gt; ftol</code>
</p>
</li></ul>

<p>The default values are: <code>maxiter=500; xtol=1e-08; gtol=1e-08; ftol=1e-12.</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>Gamma_init</code> is provided, then the envelope dimension <code>u = ncol(Gamma_init)</code>.
</p>
<p>The function <code>OptMFG</code> calls the function <code><a href="#topic+OptStiefelGBB">OptStiefelGBB</a></code> internally which implements the curvilinear search algorithm.
</p>
<p>The objective function <code class="reqn">F(\Gamma)</code> and its gradient <code class="reqn">G(\Gamma)</code> in curvilinear search algorithm are:
</p>
<p style="text-align: center;"><code class="reqn">F(\Gamma)=\log|\Gamma^T M \Gamma|+\log| \Gamma^T(M+U)^{-1}\Gamma|</code>
</p>

<p style="text-align: center;"><code class="reqn">G(\Gamma) = dF/d \Gamma = 2 M \Gamma (\Gamma^T M \Gamma)^{-1} + 2 (M + U)^{-1} \Gamma (\Gamma^T (M + U)^{-1} \Gamma)^{-1}</code>
</p>



<h3>Value</h3>

<p>Return the estimated orthogonal basis of the envelope subspace.
</p>


<h3>References</h3>

<p>Wen, Z. and Yin, W., 2013. A feasible method for optimization with orthogonality constraints. Mathematical Programming, 142(1-2), pp.397-434.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OptStiefelGBB">OptStiefelGBB</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##simulate two matrices M and U with an envelope structure
data &lt;- MenvU_sim(p=20, u=5, wishart = TRUE, n = 200)
M &lt;- data$M
U &lt;- data$U
G &lt;- data$Gamma
Gamma_FG &lt;- OptMFG(M, U, u=5)
subspace(Gamma_FG, G)
</code></pre>

<hr>
<h2 id='OptStiefelGBB'>Optimization on Stiefel manifold</h2><span id='topic+OptStiefelGBB'></span>

<h3>Description</h3>

<p>Curvilinear search algorithm for optimization on Stiefel manifold developed by Wen and Yin (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptStiefelGBB(X, fun, opts = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptStiefelGBB_+3A_x">X</code></td>
<td>
<p>Initial value to start the optimization. A <code class="reqn">n</code> by <code class="reqn">k</code> orthonormal matrix such that <code class="reqn">X^T X = I_k</code>.</p>
</td></tr>
<tr><td><code id="OptStiefelGBB_+3A_fun">fun</code></td>
<td>
<p>The function that returns the objective function value and its gradient. The syntax for <code>fun</code> is <code>fun(X, data1, data2)</code> where <code>data1, data2</code> are additional data passed to <code>...</code>.</p>
</td></tr>
<tr><td><code id="OptStiefelGBB_+3A_opts">opts</code></td>
<td>
<p>A list specifying additional user-defined arguments for the curvilinear search algorithm. Some important ones are listed in the following:
</p>

<ul>
<li> <p><code>maxiter</code>: The maximal number of iterations.
</p>
</li>
<li> <p><code>xtol</code>: The convergence tolerance for <code class="reqn">X</code>, e.g., <code class="reqn">||X^{(t)} - X^{(t-1)}||_F/\sqrt{k}</code>.
</p>
</li>
<li> <p><code>gtol</code>: The convergence tolerance for the gradient of the Lagrangian function, e.g., <code class="reqn">||G^{(t)} - X^{(t)} (G^{(t)})^T X^{(t)}||_F</code>.
</p>
</li>
<li> <p><code>ftol</code>: The convergence tolerance for objective function <code class="reqn">F</code>, e.g., <code class="reqn">|F^{(t)} - F^{(t-1)}|/(1+|F^{(t-1)}|)</code>. Usually, <code>max{xtol, gtol} &gt; ftol</code>.
</p>
</li></ul>

<p>The default values are: <code>maxiter=500; xtol=1e-08; gtol=1e-08; ftol=1e-12.</code></p>
</td></tr>
<tr><td><code id="OptStiefelGBB_+3A_...">...</code></td>
<td>
<p>Additional input passed to <code>fun</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calling syntax is <code>OptStiefelGBB(X, fun, opts, data1, data2)</code>, where <code>fun(X, data1, data2)</code> returns the objective function value and its gradient.
</p>
<p>For example, for <code class="reqn">n</code> by <code class="reqn">k</code> matrix <code class="reqn">X</code>, the optimization problem is
</p>
<p style="text-align: center;"><code class="reqn">min_{X} -tr(X^T W X), \mbox{ such that } X^T X = I_k.</code>
</p>

<p>The objective function and its gradient are
</p>
<p style="text-align: center;"><code class="reqn">F(X) = -tr(X^T W X), \; G(X) = - 2 W X.</code>
</p>

<p>Then we need to provide the function <code>fun(X, W)</code> which returns <code class="reqn">F(X)</code> and <code class="reqn">G(X)</code>. See <strong>Examples</strong> for details.
</p>
<p>For more details of the termination rules and the tolerances, we refer the interested readers to Section 5.1 of Wen and Yin (2013).
</p>


<h3>Value</h3>

<table>
<tr><td><code>X</code></td>
<td>
<p>The converged solution of the optimization problem.</p>
</td></tr>
<tr><td><code>out</code></td>
<td>
<p>Output information, including estimation error, function value, iteration times etc.
</p>

<ul>
<li><p><code>nfe</code>: The total number of line search attempts.
</p>
</li>
<li><p><code>msg</code>: Message: &quot;convergence&quot; | &quot;exceed max iteration&quot;.
</p>
</li>
<li><p><code>feasi</code>: The feasibility of solution: <code class="reqn">||X^TX - I_k||_F</code>.
</p>
</li>
<li><p><code>nrmG</code>: The convergence criterion based on the projected gradient <code class="reqn">||G - X G^T X||_F</code>.
</p>
</li>
<li><p><code>fval</code>: The objective function value <code class="reqn">F(X)</code> at termination.
</p>
</li>
<li><p><code>iter</code>: The number of iterations.
</p>
</li></ul>
</td></tr>
</table>


<h3>References</h3>

<p>Wen, Z. and Yin, W., 2013. A feasible method for optimization with orthogonality constraints. Mathematical Programming, 142(1-2), pp.397-434.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
k &lt;- 6

# Randomly generated matrix M
W &lt;- matrix(rnorm(n^2), n, n)
W &lt;- t(W) %*% W

# Randomly generated orthonormal initial matrix
X0 &lt;- matrix(rnorm(n*k), n, k)
X0 &lt;- qr.Q(qr(X0))

# The objective function and its gradient
fun &lt;- function(X, W){
  F &lt;- - sum(diag(t(X) %*% W %*% X))
  G &lt;- - 2*(W %*% X)
  return(list(F = F, G = G))
}

# Options list
opts&lt;-list(record = 0, maxiter = 1000, xtol = 1e-5, gtol = 1e-5, ftol = 1e-8)

# Main part
output &lt;- OptStiefelGBB(X0, fun, opts, W)
X &lt;- output$X
out &lt;- output$out

</code></pre>

<hr>
<h2 id='plot.Tenv'>Plot coefficients and p-value for Tenv object.</h2><span id='topic+plot.Tenv'></span>

<h3>Description</h3>

<p>Plot method for object returned from <code>TRR.fit</code> and <code>TPR.fit</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Tenv'
plot(
  x,
  level = 0.05,
  main = paste0("Coefficient plot ", "(", x$method, ")"),
  main_p = paste0("P value plot ", "(", x$method, ")"),
  xlab = "",
  ylab = "",
  axes = TRUE,
  ask = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Tenv_+3A_x">x</code></td>
<td>
<p>An object of class <code>"Tenv"</code>, as the ones returned from <code>TPR.fit</code> or <code>TRR.fit</code>.</p>
</td></tr>
<tr><td><code id="plot.Tenv_+3A_level">level</code></td>
<td>
<p>The significant level of p-value. Default is 0.05.</p>
</td></tr>
<tr><td><code id="plot.Tenv_+3A_main">main</code></td>
<td>
<p>The title of coefficient plot.</p>
</td></tr>
<tr><td><code id="plot.Tenv_+3A_main_p">main_p</code></td>
<td>
<p>The title of <code class="reqn">p</code>-value plot.</p>
</td></tr>
<tr><td><code id="plot.Tenv_+3A_xlab">xlab</code></td>
<td>
<p>The title of x-axis.</p>
</td></tr>
<tr><td><code id="plot.Tenv_+3A_ylab">ylab</code></td>
<td>
<p>The title of y-axis.</p>
</td></tr>
<tr><td><code id="plot.Tenv_+3A_axes">axes</code></td>
<td>
<p>A logical value specifying whether the axes should be drawn.</p>
</td></tr>
<tr><td><code id="plot.Tenv_+3A_ask">ask</code></td>
<td>
<p>A logical value. If it is TRUE (default), user is prompted before the second plot is shown (if exists).</p>
</td></tr>
<tr><td><code id="plot.Tenv_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed to the plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coef(x)</code> must be a two-way tensor or a matrix.
</p>
<p>Since <code class="reqn">p</code>-value depend on <code class="reqn">\widehat{\mathrm{cov}}^{-1}\{\mathrm{vec}(\mathbf{X})\}</code> which is unavailable for the ultra-high dimensional <code class="reqn">\mathrm{vec}(\mathbf{X})</code> in tensor predictor regression (TPR), the <code class="reqn">p</code>-value plot is not provided for the object returned from <code>TPR.fit</code>.
Therefore, for the object return from <code>TPR.fit</code>, only the coefficients plot is displayed. And for the object return from <code>TRR.fit</code>, both the coefficients plot and <code class="reqn">p</code>-value plot are displayed.
</p>
<p><code>main</code> and <code>main_p</code> control the titles of coefficient plot and <code class="reqn">p</code>-value plot separately. Some other arguments used in function <code>graphics::image</code>, e.g., <code>xlim, ylim, zlim, col, xaxs, yaxs, etc.,</code> can be passed to <code>...</code>
</p>
<p><code>ask</code> can be set as <code>FALSE</code> if the pause before the second plot is not preferred. If <code>x</code> is an object from <code>TPR.fit</code>, no pause is enabled.
</p>


<h3>Value</h3>

<p>No return value.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TRR.fit">TRR.fit</a>, <a href="#topic+TPR.fit">TPR.fit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data("bat")
 x &lt;- bat$x
 y &lt;- bat$y
 fit &lt;- TRR.fit(x, y, method="standard")
 plot(fit)

 ## Change the significant level to 0.1
 plot(fit, level = 0.1)
</code></pre>

<hr>
<h2 id='PMSE'>Prediction and mean squared error.</h2><span id='topic+PMSE'></span>

<h3>Description</h3>

<p>Evaluate the tensor response regression (TRR) or tensor predictor regression (TPR) model through the mean squared error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PMSE(x, y, B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PMSE_+3A_x">x</code></td>
<td>
<p>A predictor tensor, array, matrix or vector.</p>
</td></tr>
<tr><td><code id="PMSE_+3A_y">y</code></td>
<td>
<p>A response tensor, array, matrix or vector.</p>
</td></tr>
<tr><td><code id="PMSE_+3A_b">B</code></td>
<td>
<p>An coefficient tensor tensor, array, matrix or vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are three situations:
</p>

<ul>
<li><p> TRR model: If <code>y</code> is an <code class="reqn">m</code>-way tensor (array), <code>x</code> should be matrix or vector and <code>B</code> should be tensor or array.
</p>
</li>
<li><p> TPR model: If <code>x</code> is an <code class="reqn">m</code>-way tensor (array), <code>y</code> should be matrix or vector and <code>B</code> should be tensor or array.
</p>
</li>
<li><p> Other: If <code>x</code> and <code>y</code> are both matrix or vector, <code>B</code> should be matrix. In this case, the prediction is calculated as <code>pred = B*X</code>.
</p>
</li></ul>

<p>In any cases, users are asked to ensure the dimensions of <code>x</code>, <code>y</code> and <code>B</code> match. See <code><a href="#topic+TRRsim">TRRsim</a></code> and <code><a href="#topic+TPRsim">TPRsim</a></code> for more details of the TRR and TPR models.
</p>
<p>Let <code class="reqn">\hat{Y}_i</code> denote each prediction, then the mean squared error is defined as <code class="reqn">1/n\sum_{i=1}^n||Y_i-\hat{Y}_i||_F^2</code>, where <code class="reqn">||\cdot||_F</code> denotes the Frobenius norm.
</p>


<h3>Value</h3>

<table>
<tr><td><code>mse</code></td>
<td>
<p>The mean squared error.</p>
</td></tr>
<tr><td><code>pred</code></td>
<td>
<p>The predictions.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+TRRsim">TRRsim</a>, <a href="#topic+TPRsim">TPRsim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Dataset in TRR model
r &lt;- c(10, 10, 10)
u &lt;- c(2, 2, 2)
p &lt;- 5
n &lt;- 100
dat &lt;- TRRsim(r = r, p = p, u = u, n = n)
x &lt;- dat$x
y &lt;- dat$y

# Fit data with TRR.fit
fit_std &lt;- TRR.fit(x, y, method="standard")
result &lt;- PMSE(x, y, fit_std$coefficients)
## Dataset in TPR model
p &lt;- c(10, 10, 10)
u &lt;- c(1, 1, 1)
r &lt;- 5
n &lt;- 200
dat &lt;- TPRsim(p = p, r = r, u = u, n = n)
x &lt;- dat$x
y &lt;- dat$y

# Fit data with TPR.fit
fit_std &lt;- TPR.fit(x, y, u, method="standard")
result &lt;- PMSE(x, y, fit_std$coefficients)

</code></pre>

<hr>
<h2 id='predict.Tenv'>Predict method for Tenv object.</h2><span id='topic+predict.Tenv'></span>

<h3>Description</h3>

<p>Predict response for the object returned from <code><a href="#topic+TRR.fit">TRR.fit</a></code> and <code><a href="#topic+TPR.fit">TPR.fit</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Tenv'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.Tenv_+3A_object">object</code></td>
<td>
<p>An object of class <code>"Tenv"</code>, as the ones returned from <code><a href="#topic+TPR.fit">TPR.fit</a></code> or <code><a href="#topic+TRR.fit">TRR.fit</a></code>.</p>
</td></tr>
<tr><td><code id="predict.Tenv_+3A_newdata">newdata</code></td>
<td>
<p>The data to be used for prediction. It can be a vector, a matrix or a tensor if <code>object</code> is returned from<code><a href="#topic+TRR.fit">TRR.fit</a></code>, and can be a matrix or a tensor if <code>object</code> is returned from <code><a href="#topic+TPR.fit">TPR.fit</a></code>.</p>
</td></tr>
<tr><td><code id="predict.Tenv_+3A_...">...</code></td>
<td>
<p>Additional arguments. No available arguments exist in this version.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the predicted response.
</p>


<h3>Note</h3>

<p>If <code>newdata</code> is missing, the fitted response from <code>object</code> is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("bat")
x &lt;- bat$x
y &lt;- bat$y
fit &lt;- TRR.fit(x, y, method="standard")
predict(fit, x)
</code></pre>

<hr>
<h2 id='simplsMU'>SIMPLS-type algorithm for estimating the envelope subspace</h2><span id='topic+simplsMU'></span>

<h3>Description</h3>

<p>This algorithm is a generalization of the SIMPLS algorithm in De Jong, S. (1993). See Cook (2018) Section 6.5 for more details of this generalized moment-based envelope algorithm; see Cook, Helland, and Su (2013) for a connection between SIMPLS and the predictor envelope in linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplsMU(M, U, u)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simplsMU_+3A_m">M</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive definite matrix <code class="reqn">M</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="simplsMU_+3A_u">U</code></td>
<td>
<p>The <code class="reqn">p</code>-by-<code class="reqn">p</code> positive semi-definite matrix <code class="reqn">U</code> in the envelope objective function.</p>
</td></tr>
<tr><td><code id="simplsMU_+3A_u">u</code></td>
<td>
<p>An integer between 0 and <code class="reqn">n</code> representing the envelope dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the estimated orthogonal basis of the envelope subspace.
</p>


<h3>References</h3>

<p>De Jong, S., 1993. SIMPLS: an alternative approach to partial least squares regression. Chemometrics and intelligent laboratory systems, 18(3), pp.251-263.
</p>
<p>Cook, R.D., Helland, I.S. and Su, Z., 2013. Envelopes and partial least squares regression. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 75(5), pp.851-877.
</p>
<p>Cook, R.D., 2018. An introduction to envelopes: dimension reduction for efficient estimation in multivariate statistics (Vol. 401). John Wiley &amp; Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##simulate two matrices M and U with an envelope structure#
data &lt;- MenvU_sim(p = 20, u = 5, wishart = TRUE, n = 200)
M &lt;- data$M
U &lt;- data$U
G &lt;- data$Gamma
Gamma_pls &lt;- simplsMU(M, U, u=5)
subspace(Gamma_pls, G)

</code></pre>

<hr>
<h2 id='square'>Square simulated data</h2><span id='topic+square'></span>

<h3>Description</h3>

<p>Synthetic data generated from tensor predictor regression (TPR) model. Each response observation is univariate, and each predictor observation is a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("square")
</code></pre>


<h3>Format</h3>

<p>A list consisting of four components:
</p>

<dl>
<dt>x</dt><dd><p>A <code class="reqn">32 \times 32 \times 200</code> tensor, each matrix <code>x@data[,,i]</code> represents a predictor observation.</p>
</dd>
<dt>y</dt><dd><p>A <code class="reqn">1 \times 200</code> matrix, each entry represents a response observation.</p>
</dd>
<dt>coefficients</dt><dd><p>A <code class="reqn">32\times 32 \times 1</code> tensor with a square pattern.</p>
</dd>
<dt>Gamma</dt><dd><p>A list consisting of two <code class="reqn">32 \times 2</code> envelope basis.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The dataset is generated from the tensor predictor regression (TPR) model:
</p>
<p style="text-align: center;"><code class="reqn">Y_i = B_{(m+1)}vec(X_i) + \epsilon_i, \quad i = 1,\ldots, n,</code>
</p>

<p>where <code class="reqn">n=200</code> and the regression coefficient <code class="reqn">B \in R^{32\times 32}</code> is a given image with rank 2, which has a square pattern. All the elements of the coefficient matrix <code class="reqn">B</code> are either 0.1 or 1. To make the model conform to the envelope structure, we construct the envelope basis <code class="reqn">\Gamma_k</code> and the covariance matrices <code class="reqn">\Sigma_k, k=1,2</code>, of predictor <code class="reqn">X</code> as following. With the singular value decomposition of <code class="reqn">B</code>, namely <code class="reqn">B = \Gamma_1 \Lambda \Gamma_2^T</code>, we choose the envelope basis as <code class="reqn">\Gamma_k \in R^{32 \times 2}, k=1,2</code>. Then the envelope dimensions are <code class="reqn">u_1 =  u_2 = 2</code>. We set matrices <code class="reqn">\Omega_k = I_2</code>  and  <code class="reqn">\Omega_{0k} = 0.01 I_{30}</code>, <code class="reqn">k=1,2</code>. Then we generate the covariance matrices <code class="reqn">\Sigma_k = \Gamma_k \Omega_k \Gamma_k^T + \Gamma_{0k}\Omega_{0k}\Gamma_{0k}^T</code>, followed by normalization with their Frobenius norms. The predictor <code class="reqn">X_i</code> is then generated from two-way tensor (matrix) normal distribution <code class="reqn">TN(0; \Sigma_1, \Sigma_2)</code>. And the error term <code class="reqn">\epsilon_i</code> is generated from standard normal distribution.
</p>


<h3>References</h3>

<p>Zhang, X. and Li, L., 2017. Tensor envelope partial least-squares regression. Technometrics, 59(4), pp.426-436.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit square dataset with the tensor predictor regression model
data("square")
x &lt;- square$x
y &lt;- square$y
# Model fitting with ordinary least square.
fit_std &lt;- TPR.fit(x, y, method="standard")
# Draw the coefficient plot.
plot(fit_std)

</code></pre>

<hr>
<h2 id='std_err'>Elementwise standard error.</h2><span id='topic+std_err'></span>

<h3>Description</h3>

<p>Calculates the elementwise standard error for the object returned from <code>TRR.fit</code>. The standard error for the object returned from <code>TPR.fit</code> is unavailable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std_err(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="std_err_+3A_object">object</code></td>
<td>
<p>an object of class <code>"Tenv"</code>, as the ones returned from <code>TRR.fit</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The standard error tensor is returned.
</p>


<h3>Note</h3>

<p>The function only supports the object returned from <code>TRR.fit</code> since there is no standard error for the object returned from <code>TPR.fit</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("bat")
x &lt;- bat$x
y &lt;- bat$y
fit &lt;- TRR.fit(x, y, method="standard")
std_err(fit)
</code></pre>

<hr>
<h2 id='subspace'>The distance between two subspaces.</h2><span id='topic+subspace'></span>

<h3>Description</h3>

<p>This function calculates the distance between the two subspaces with equal dimensions span<code class="reqn">(A)</code> and span<code class="reqn">(B)</code>, where <code class="reqn">A \in R^{p\times u}</code> and <code class="reqn">B \in R^{p\times u}</code> are the basis matrices of two subspaces. The distance is defined as
</p>
<p style="text-align: center;"><code class="reqn">\|P_{A} - P_{B}\|_F/\sqrt{2d},</code>
</p>

<p>where <code class="reqn">P</code> is the projection matrix onto the given subspace with the standard inner product, and <code class="reqn">d</code> is the common dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subspace(A, B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subspace_+3A_a">A</code></td>
<td>
<p>A <code class="reqn">p</code>-by-<code class="reqn">u</code> full column rank matrix.</p>
</td></tr>
<tr><td><code id="subspace_+3A_b">B</code></td>
<td>
<p>A <code class="reqn">p</code>-by-<code class="reqn">u</code> full column rank matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a distance metric that is between 0 and 1
</p>

<hr>
<h2 id='summary.Tenv'>Summarize method for Tenv object.</h2><span id='topic+summary.Tenv'></span><span id='topic+print.summary.Tenv'></span>

<h3>Description</h3>

<p>Summary method for object returned from <code>TRR.fit</code> and <code>TPR.fit</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Tenv'
summary(object, ...)

## S3 method for class 'summary.Tenv'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.Tenv_+3A_object">object</code></td>
<td>
<p>An object of class <code>"Tenv"</code>, as the ones returned from <code><a href="#topic+TPR.fit">TPR.fit</a></code> or <code><a href="#topic+TRR.fit">TRR.fit</a></code>.</p>
</td></tr>
<tr><td><code id="summary.Tenv_+3A_...">...</code></td>
<td>
<p>Additional arguments. No available arguments exist in this version.</p>
</td></tr>
<tr><td><code id="summary.Tenv_+3A_x">x</code></td>
<td>
<p>An object of class <code>"summary.Tenv"</code>, usually, a result of a call to <code>summary.Tenv</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extract <code>call</code>, <code>method</code>, <code>coefficients</code>, <code>residuals</code>, <code>Gamma</code> from <code>object</code>. And append <code>mse</code>, <code class="reqn">p</code>-value and the standard error of estimated coefficient.
</p>
<p>The mean squared error <code>mse</code> is defined as <code class="reqn">1/n\sum_{i=1}^n||Y_i-\hat{Y}_i||_F^2</code>, where <code class="reqn">\hat{Y}_i</code> is the prediction and <code class="reqn">||\cdot||_F</code> is the Frobenius norm of tensor.
</p>
<p>Since the <code class="reqn">p</code>-value and standard error depend on the estimation of cov<code class="reqn">^{-1}</code>(vec<code class="reqn">(X)</code>) which is unavailable for the ultra-high dimensional <code class="reqn">vec(X)</code> in tensor predictor regression (TPR), the two statistics are only provided for the object returned from <code>TRR.fit</code>.
</p>
<p><code>print.summary.Tenv</code> provides a more readable form of the statistics contained in <code>summary.Tenv</code>. If <code>object</code> is returned from <code><a href="#topic+TRR.fit">TRR.fit</a></code>, then <code>p-val</code> and <code>se</code> are also returned.
</p>


<h3>Value</h3>

<p>Return <code>object</code> with additional components
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The implemented method.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code>xdim</code></td>
<td>
<p>The dimension of predictor.</p>
</td></tr>
<tr><td><code>ydim</code></td>
<td>
<p>The dimension of response.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>The tensor coefficients estimated from <code>TPR.fit</code> or <code>TRR.fit</code>.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>The residuals, which equals to the response minus the fitted values.</p>
</td></tr>
<tr><td><code>Gamma</code></td>
<td>
<p>A list of envelope subspace basis.</p>
</td></tr>
<tr><td><code>mse</code></td>
<td>
<p>The mean squared error. The mean squared Frobenius norm of the difference between each response <code class="reqn">Y_i</code> and fitted value <code class="reqn">\hat{Y}_i</code>.</p>
</td></tr>
<tr><td><code>p_val</code></td>
<td>
<p>The p-value for coefficients. Only for the object returned from <code>TRR.fit</code>.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>The standard error for coefficients. Only for the object returned from <code>TRR.fit</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Fitting functions <code><a href="#topic+TRR.fit">TRR.fit</a></code>, <code><a href="#topic+TPR.fit">TPR.fit</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("bat")
x &lt;- bat$x
y &lt;- bat$y
fit &lt;- TRR.fit(x, y, method="standard")
##print summary
summary(fit)

##Extract the p-value and standard error from summary
summary(fit)$p_val
summary(fit)$se

</code></pre>

<hr>
<h2 id='Tenv_Pval'>The <code class="reqn">p</code>-value and standard error of coefficient in tensor response regression (TRR) model.</h2><span id='topic+Tenv_Pval'></span>

<h3>Description</h3>

<p>Obtain <code class="reqn">p</code>-value of each element in the tensor regression coefficient estimator. Two-sided t-tests are implemented on the coefficient estimator, where asymptotic covariance of the OLS estimator is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tenv_Pval(x, y, Bhat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tenv_Pval_+3A_x">x</code></td>
<td>
<p>The response tensor instance <code class="reqn"> r_1\times r_2\times \cdots \times r_m</code>.</p>
</td></tr>
<tr><td><code id="Tenv_Pval_+3A_y">y</code></td>
<td>
<p>A vector predictor of dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="Tenv_Pval_+3A_bhat">Bhat</code></td>
<td>
<p>The estimator of tensor regression coefficient.
</p>
<p>The <code class="reqn">p</code>-value and the standard error of estimated coefficient are not provided for tensor predictor regression since they depend on <code class="reqn">\widehat{\mathrm{cov}}^{-1}\{\mathrm{vec}(\mathbf{X})\}</code> which is unavailable due to the ultra-high dimension of <code class="reqn">\mathrm{vec}(\mathbf{X})</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>p_ols</code></td>
<td>
<p>The p-value tensor of OLS estimator.</p>
</td></tr>
<tr><td><code>p_val</code></td>
<td>
<p>The p-value tensor of <code>Bhat</code>.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>The standard error tensor of <code>Bhat</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Use dataset bat
data("bat")
x &lt;- bat$x
y &lt;- bat$y
fit_std &lt;- TRR.fit(x, y, method="standard")
Tenv_Pval(x, y, fit_std$coefficients)

</code></pre>

<hr>
<h2 id='TPR.fit'>Tensor predictor regression</h2><span id='topic+TPR.fit'></span><span id='topic+TPR'></span>

<h3>Description</h3>

<p>This function is used for estimation of tensor predictor regression. The available method including standard OLS type estimation, PLS type of estimation as well as envelope estimation with FG, 1D and ECD approaches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TPR.fit(x, y, u, method=c('standard', 'FG', '1D', 'ECD', 'PLS'), Gamma_init = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TPR.fit_+3A_x">x</code></td>
<td>
<p>The predictor tensor instance of dimension <code class="reqn">p_1\times p_2\times\cdots\times p_m \times n</code>, where <code class="reqn">n</code> is the sample size. Array with the same dimensions and matrix with dimension <code class="reqn">p\times n</code> are acceptable. If <code>y</code> is missing, <code>x</code> should be a list or an environment consisting of predictor and response datasets.</p>
</td></tr>
<tr><td><code id="TPR.fit_+3A_y">y</code></td>
<td>
<p>The response matrix of dimension <code class="reqn">r \times n</code>, where <code class="reqn">n</code> is the sample size. Vector of length <code class="reqn">n</code> is acceptable.</p>
</td></tr>
<tr><td><code id="TPR.fit_+3A_u">u</code></td>
<td>
<p>The dimension of envelope subspace. <code class="reqn">u=(u_1,\cdots, u_m)</code>. Used for methods &quot;FG&quot;, &quot;1D&quot;, &quot;ECD&quot; and &quot;PLS&quot;. User can use <code><a href="#topic+TPRdim">TPRdim</a></code> to select dimension.</p>
</td></tr>
<tr><td><code id="TPR.fit_+3A_method">method</code></td>
<td>
<p>The method used for estimation of tensor response regression. There are four possible choices.
</p>

<ul>
<li><p><code>"standard"</code>: The standard OLS type estimation.
</p>
</li>
<li><p><code>"FG"</code>: Envelope estimation with full Grassmannian (FG) algorithm.
</p>
</li>
<li><p><code>"1D"</code>: Envelope estimation with one dimensional optimization approaches by 1D algorithm.
</p>
</li>
<li><p><code>"ECD"</code>: Envelope estimation with one dimensional optimization approaches by ECD algorithm.
</p>
</li>
<li><p><code>"PLS"</code>: The SIMPLS-type estimation without manifold optimization.
</p>
</li></ul>
</td></tr>
<tr><td><code id="TPR.fit_+3A_gamma_init">Gamma_init</code></td>
<td>
<p>A list specifying the initial envelope subspace basis for &quot;FG&quot; method. By default, the estimators given by &quot;1D&quot; algorithm is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please refer to <strong>Details</strong> part of <code><a href="#topic+TPRsim">TPRsim</a></code> for the description of the tensor predictor regression model.
</p>


<h3>Value</h3>

<p><code>TPR.fit</code> returns an object of class &quot;Tenv&quot;.
</p>
<p>The function <code><a href="base.html#topic+summary">summary</a></code> (i.e., <code><a href="#topic+summary.Tenv">summary.Tenv</a></code>) is used to print the summary of the results, including additional information, e.g., the p-value and the standard error for coefficients, and the prediction mean squared error.
</p>
<p>The functions <code>coefficients</code>, <code>fitted.values</code> and <code>residuals</code> can be used to extract different features returned from <code>TPR.fit</code>.
</p>
<p>The function <code><a href="graphics.html#topic+plot">plot</a></code> (i.e., <code><a href="#topic+plot.Tenv">plot.Tenv</a></code>) plots the two-dimensional coefficients and p-value for object of class &quot;Tenv&quot;.
</p>
<p>The function <code><a href="stats.html#topic+predict">predict</a></code> (i.e., <code><a href="#topic+predict.Tenv">predict.Tenv</a></code>) predicts response for the object returned from <code><a href="#topic+TPR.fit">TPR.fit</a></code> function.
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The original predictor dataset.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The original response dataset.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The implemented method.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>The estimation of regression coefficient tensor.</p>
</td></tr>
<tr><td><code>Gamma</code></td>
<td>
<p>The estimation of envelope subspace basis.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>A lists of estimated covariance matrices at each mode for the tensor predictors.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>The fitted response matrix.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>The residuals matrix.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, X. and Li, L., 2017. Tensor envelope partial least-squares regression. Technometrics, 59(4), pp.426-436.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.Tenv">summary.Tenv</a></code> for summaries, calculating mean squared error from the prediction.
</p>
<p><code><a href="#topic+plot.Tenv">plot.Tenv</a></code>(via <code>graphics::image</code>) for drawing the two-dimensional coefficient plot.
</p>
<p><code><a href="#topic+predict.Tenv">predict.Tenv</a></code> for prediction.
</p>
<p>The generic functions <code><a href="stats.html#topic+coef">coef</a>, <a href="stats.html#topic+residuals">residuals</a>, <a href="stats.html#topic+fitted">fitted</a></code>.
</p>
<p><code><a href="#topic+TPRdim">TPRdim</a></code> for selecting the dimension of envelope by cross-validation.
</p>
<p><code><a href="#topic+TPRsim">TPRsim</a></code> for generating the simulated data used in tensor prediction regression.
</p>
<p>The simulated data <code><a href="#topic+square">square</a></code> used in tensor predictor regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The dimension of predictor
p &lt;- c(10, 10, 10)
# The envelope dimensions u.
u &lt;- c(1, 1, 1)
# The dimension of response
r &lt;- 5
# The sample size
n &lt;- 200

# Simulate the data with TPRsim.
dat &lt;- TPRsim(p = p, r = r, u = u, n = n)
x &lt;- dat$x
y &lt;- dat$y
B &lt;- dat$coefficients

fit_std &lt;- TPR.fit(x, y, method="standard")
fit_FG &lt;- TPR.fit(x, y, u, method="FG")
fit_pls &lt;- TPR.fit(x, y, u, method="PLS")

rTensor::fnorm(B-stats::coef(fit_std))
rTensor::fnorm(B-stats::coef(fit_FG))
rTensor::fnorm(B-stats::coef(fit_pls))

## ----------- Pass a list or an environment to x also works ------------- ##
# Pass a list to x
l &lt;- dat[c("x", "y")]
fit_std_l &lt;- TPR.fit(l, method="standard")

# Pass an environment to x
e &lt;- new.env()
e$x &lt;- dat$x
e$y &lt;- dat$y
fit_std_e &lt;- TPR.fit(e, method="standard")

## ----------- Use dataset "square" included in the package ------------- ##
data("square")
x &lt;- square$x
y &lt;- square$y
fit_std &lt;- TPR.fit(x, y, method="standard")

</code></pre>

<hr>
<h2 id='TPRdim'>Envelope dimension by cross-validation for tensor predictor regression (TPR).</h2><span id='topic+TPRdim'></span>

<h3>Description</h3>

<p>Select the envelope dimension by cross-validation for tensor predictor regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TPRdim(x, y, maxdim = 10, nfolds = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TPRdim_+3A_x">x</code></td>
<td>
<p>The predictor tensor instance of dimension <code class="reqn">p_1\times p_2\times\cdots\times p_m \times n</code>, where <code class="reqn">n</code> is the sample size. Array with the same dimensions and matrix with dimension <code class="reqn">p\times n</code> are acceptable.</p>
</td></tr>
<tr><td><code id="TPRdim_+3A_y">y</code></td>
<td>
<p>The response matrix of dimension <code class="reqn">r \times n</code>, where <code class="reqn">n</code> is the sample size. Vector of length <code class="reqn">n</code> is acceptable.</p>
</td></tr>
<tr><td><code id="TPRdim_+3A_maxdim">maxdim</code></td>
<td>
<p>The largest dimension to be considered for selection.</p>
</td></tr>
<tr><td><code id="TPRdim_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for cross-validation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>According to Zhang and Li (2017), the dimensions of envelopes at each mode are assumed to be equal, so the <code>u</code> returned is a single value representing the equal envelope dimension.
</p>
<p>For each dimension <code>u</code> in <code>1:maxdim</code>, we obtain the prediction
</p>
<p style="text-align: center;"><code class="reqn">\hat{Y}_i = \hat{B}_{(m+1)} vec(X_i)</code>
</p>

<p>for each predictor <code class="reqn">X_i</code> in the <code class="reqn">k</code>-th testing dataset, <code class="reqn">k = 1,\ldots,</code><code>nfolds</code>, where <code class="reqn">\hat{B}</code> is the estimated coefficient based on the <code class="reqn">k</code>-th training dataset. And the mean squared error for the <code class="reqn">k</code>-th testing dataset is defined as
</p>
<p style="text-align: center;"><code class="reqn">1/nk \sum_{i=1}^{nk}||Y_i-\hat{Y}_i||_F^2,</code>
</p>

<p>where <code class="reqn">nk</code> is the sample size of the <code class="reqn">k</code>-th testing dataset and <code class="reqn">||\cdot||_F</code> denotes the Frobenius norm. Then, the average of <code>nfolds</code> mean squared error is recorded as cross-validation mean squared error for the dimension <code>u</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>mincv</code></td>
<td>
<p>The minimal cross-validation mean squared error.</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>The envelope subspace dimension selected.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, X. and Li, L., 2017. Tensor envelope partial least-squares regression. Technometrics, 59(4), pp.426-436.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TPRsim">TPRsim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The dimension of predictor
p &lt;- c(10, 10, 10)
# The envelope dimensions u.
u &lt;- c(1, 1, 1)
# The dimension of response
r &lt;- 5
# The sample size
n &lt;- 200
dat &lt;- TPRsim(p = p, r = r, u = u, n = n)
x &lt;- dat$x
y &lt;- dat$y
TPRdim(x, y, maxdim = 5)

## Use dataset square. (time-consuming)

data("square")
x &lt;- square$x
y &lt;- square$y
# check the dimension of x
dim(x)
# use 32 as the maximal envelope dimension
TPRdim(x, y, maxdim=32)

</code></pre>

<hr>
<h2 id='TPRsim'>Generate simulation data for tensor predictor regression (TPR)</h2><span id='topic+TPRsim'></span>

<h3>Description</h3>

<p>This function is used to generate simulation data used in tensor prediction regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TPRsim(p, r, u, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TPRsim_+3A_p">p</code></td>
<td>
<p>The dimension of predictor, a vector in the form of <code class="reqn">(p_1,\cdots, p_m)</code>.</p>
</td></tr>
<tr><td><code id="TPRsim_+3A_r">r</code></td>
<td>
<p>The dimension of response, a scale.</p>
</td></tr>
<tr><td><code id="TPRsim_+3A_u">u</code></td>
<td>
<p>The structural dimension of envelopes at each mode, a vector with the same length as p.</p>
</td></tr>
<tr><td><code id="TPRsim_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tensor predictor regression model is of the form,
</p>
<p style="text-align: center;"><code class="reqn">Y = B_{(m+1)}vec(X) + \epsilon</code>
</p>

<p>where response <code class="reqn">Y \in R^{r}</code>, predictor <code class="reqn">X \in R^{p_1\times \cdots\times p_m}</code>, <code class="reqn">B \in \in R^{p_1 \times\cdots\times p_m \times r}</code> and the error term is multivariate normal distributed. The predictor is tensor normal distributed,
</p>
<p style="text-align: center;"><code class="reqn">X\sim TN(0;\Sigma_1,\dots,\Sigma_m)</code>
</p>

<p>According to the tensor envelope structure, we have
</p>
<p style="text-align: center;"><code class="reqn">B = [\Theta; \Gamma_1,\ldots, \Gamma_m, I_p],</code>
</p>

<p style="text-align: center;"><code class="reqn">\Sigma_k = \Gamma_k \Omega_k \Gamma_k^{T}+ \Gamma_{0k} \Omega_{0k} \Gamma_{0k}^T,</code>
</p>

<p>for some <code class="reqn">\Theta \in R^{u_1 \times\cdots\times u_m \times p}</code>, <code class="reqn">\Omega_k \in R^{u_k \times u_k}</code> and <code class="reqn">\Omega_{0k} \in \in R^{(p_k - u_k) \times (p_k - u_k)}</code>, <code class="reqn">k=1,\ldots,m</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>The predictor of dimension <code class="reqn">p_1\times \cdots\times p_m \times n</code>.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response of dimension <code class="reqn">r\times n</code>.</p>
</td></tr>
<tr><td><code>Gamma</code></td>
<td>
<p>A list of envelope subspace basis of dimension <code class="reqn">p_k \times u_k, \ k=1,\ldots,m</code>.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>The tensor coefficients of dimension <code class="reqn">p_1\times \cdots\times p_m \times r</code>.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>A lists of estimated covariance matrices at each mode for the tensor predictors, i.e., <code class="reqn">\Sigma_1,\dots, \Sigma_m</code>.</p>
</td></tr>
<tr><td><code>p</code>, <code>r</code>, <code>u</code></td>
<td>
<p>The input <code>p,r,u</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The length of <code>p</code> must match that of <code>u</code>, and each element of <code>u</code> must be less than the corresponding element in <code>p</code>.
</p>


<h3>References</h3>

<p>Zhang, X. and Li, L., 2017. Tensor envelope partial least-squares regression. Technometrics, 59(4), pp.426-436.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TPR.fit">TPR.fit</a>, <a href="#topic+TRRsim">TRRsim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- c(10, 10, 10)
u &lt;- c(1, 1, 1)
r &lt;- 5
n &lt;- 200
dat &lt;- TPRsim(p = p, r = r, u = u, n = n)
x &lt;- dat$x
y &lt;- dat$y
fit_std &lt;- TPR.fit(x, y, method="standard")

</code></pre>

<hr>
<h2 id='TRES-package'>Tensor Regression with Envelope Structure</h2><span id='topic+TRES-package'></span><span id='topic+TRES'></span>

<h3>Description</h3>

<p>Provides the ordinary least squares estimator and the three types of tensor envelope structured estimators for tensor response regression (TRR) and tensor predictor regression (TPR) models. The three types of tensor envelope structured approaches are generic and can be applied to any envelope estimation problems. The full Grassmannian (FG) optimization is often associated with likelihood-based estimation but requires heavy computation and good initialization; the one-directional optimization approaches (1D and ECD algorithms) are faster, stable and does not require carefully chosen initial values; the SIMPLS-type is motivated by the partial least squares regression and is computationally the least expensive.
</p>


<h3>Author(s)</h3>

<p>Wenjing Wang, Jing Zeng and Xin Zhang
</p>


<h3>References</h3>

<p>Zeng J., Wang W., Zhang X. (2021) TRES: An R Package for Tensor Regression and Envelope Algorithms. Journal of Statistical Software, 99(12), 1-31. doi:10.18637/jss.v099.i12.
</p>
<p>Cook, R.D. and Zhang, X. (2016). Algorithms for envelope estimation. Journal of Computational and Graphical Statistics, 25(1), pp.284-300.
</p>
<p>Li, L. and Zhang, X. (2017). Parsimonious tensor response regression. Journal of the American Statistical Association, 112(519), pp.1131-1146.
</p>
<p>Zhang, X. and Li, L. (2017). Tensor envelope partial least-squares regression. Technometrics, 59(4), pp.426-436.
</p>
<p>Cook, R.D. and Zhang, X. (2018). Fast envelope algorithms. Statistica Sinica, 28(3), pp.1179-1197.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/leozeng15/TRES">https://github.com/leozeng15/TRES</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/leozeng15/TRES/issues">https://github.com/leozeng15/TRES/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(TRES)
## Load data "bat"
data("bat")
x &lt;- bat$x
y &lt;- bat$y

## 1. Fitting with OLS method.
fit_ols &lt;- TRR.fit(x, y, method="standard")

## Print cofficient
coef(fit_ols)

## Print the summary
summary(fit_ols)

## Extract the mean squared error, p-value and standard error from summary
summary(fit_ols)$mse
summary(fit_ols)$p_val
summary(fit_ols)$se

## Make the prediction on the original dataset
predict(fit_ols, x)

## Draw the plots of two-way coefficient tensor (i.e., matrix) and p-value tensor.
plot(fit_ols)

## 2. Fitting with 1D envelope algorithm. (time-consuming)

fit_1D &lt;- TRR.fit(x, y, u = c(14,14), method="1D") # pass envelope rank (14,14)
coef(fit_1D)
summary(fit_1D)
predict(fit_1D, x)
plot(fit_1D)

</code></pre>

<hr>
<h2 id='TRR.fit'>Tensor response regression</h2><span id='topic+TRR.fit'></span><span id='topic+TRR'></span>

<h3>Description</h3>

<p>This function is used for estimation of tensor response regression. The available method including standard OLS type estimation, PLS type of estimation as well as envelope estimation with FG, 1D and ECD approaches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TRR.fit(x, y, u, method=c('standard', 'FG', '1D', 'ECD', 'PLS'), Gamma_init = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TRR.fit_+3A_x">x</code></td>
<td>
<p>The predictor matrix of dimension <code class="reqn">p \times n</code>. Vector of length <code class="reqn">n</code> is acceptable. If <code>y</code> is missing, <code>x</code> should be a list or an environment consisting of predictor and response datasets.</p>
</td></tr>
<tr><td><code id="TRR.fit_+3A_y">y</code></td>
<td>
<p>The response tensor instance with dimension <code class="reqn">r_1\times r_2\times\cdots\times r_m \times n</code>, where <code class="reqn">n</code> is the sample size. Array with the same dimensions and matrix with dimension <code class="reqn">r\times n</code> are acceptable.</p>
</td></tr>
<tr><td><code id="TRR.fit_+3A_u">u</code></td>
<td>
<p>The dimension of envelope subspace. <code class="reqn">u=(u_1,\cdots, u_m)</code>. Used for methods &quot;FG&quot;, &quot;1D&quot;, &quot;ECD&quot; and &quot;PLS&quot;. User can use <code><a href="#topic+TRRdim">TRRdim</a></code> to select dimension.</p>
</td></tr>
<tr><td><code id="TRR.fit_+3A_method">method</code></td>
<td>
<p>The method used for estimation of tensor response regression. There are four possible choices.
</p>

<ul>
<li><p><code>"standard"</code>: The standard OLS type estimation.
</p>
</li>
<li><p><code>"FG"</code>: Envelope estimation with full Grassmannian (FG) algorithm.
</p>
</li>
<li><p><code>"1D"</code>: Envelope estimation with one dimensional optimization approaches by 1D algorithm.
</p>
</li>
<li><p><code>"ECD"</code>: Envelope estimation with one dimensional optimization approaches by ECD algorithm.
</p>
</li>
<li><p><code>"PLS"</code>: The SIMPLS-type estimation without manifold optimization.
</p>
</li></ul>
</td></tr>
<tr><td><code id="TRR.fit_+3A_gamma_init">Gamma_init</code></td>
<td>
<p>A list specifying the initial envelope subspace basis for &quot;FG&quot; method. By default, the estimators given by &quot;1D&quot; algorithm is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please refer to <strong>Details</strong> part of <code><a href="#topic+TRRsim">TRRsim</a></code> for the description of the tensor response regression model.
</p>
<p>When samples are insufficient, it is possible that the estimation of error covariance matrix <code>Sigma</code> is not available. However, if using ordinary least square method (<code>method = "standard"</code>), as long as sample covariance matrix of predictor <code>x</code> is nonsingular, <code>coefficients</code>, <code>fitted.values</code>, <code>residuals</code> are still returned.
</p>


<h3>Value</h3>

<p><code>TRR.fit</code> returns an object of class &quot;Tenv&quot;.
</p>
<p>The function <code><a href="base.html#topic+summary">summary</a></code> (i.e., <code><a href="#topic+summary.Tenv">summary.Tenv</a></code>) is used to print the summary of the results, including additional information, e.g., the p-value and the standard error for coefficients, and the prediction mean squared error.
</p>
<p>The functions <code>coefficients</code>, <code>fitted.values</code> and <code>residuals</code> can be used to extract different features returned from <code>TRR.fit</code>.
</p>
<p>The function <code><a href="graphics.html#topic+plot">plot</a></code> (i.e., <code><a href="#topic+plot.Tenv">plot.Tenv</a></code>) plots the two-dimensional coefficients and p-value for object of class &quot;Tenv&quot;.
</p>
<p>The function <code><a href="stats.html#topic+predict">predict</a></code> (i.e., <code><a href="#topic+predict.Tenv">predict.Tenv</a></code>) predicts response for the object returned from <code><a href="#topic+TRR.fit">TRR.fit</a></code> function.
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The original predictor dataset.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The original response dataset.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The implemented method.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>The estimation of regression coefficient tensor.</p>
</td></tr>
<tr><td><code>Gamma</code></td>
<td>
<p>The estimation of envelope subspace basis.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>A lists of estimated covariance matrices at each mode for the error term.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>The fitted response tensor.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>The residuals tensor.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Li, L. and Zhang, X., 2017. Parsimonious tensor response regression. Journal of the American Statistical Association, 112(519), pp.1131-1146.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.Tenv">summary.Tenv</a></code> for summaries, calculating mean squared error from the prediction.
</p>
<p><code><a href="#topic+plot.Tenv">plot.Tenv</a></code>(via <code>graphics::image</code>) for drawing the two-dimensional coefficient plot and <code class="reqn">p</code>-value plot.
</p>
<p><code><a href="#topic+predict.Tenv">predict.Tenv</a></code> for prediction.
</p>
<p>The generic functions <code><a href="stats.html#topic+coef">coef</a>, <a href="stats.html#topic+residuals">residuals</a>, <a href="stats.html#topic+fitted">fitted</a></code>.
</p>
<p><code><a href="#topic+TRRdim">TRRdim</a></code> for selecting the dimension of envelope by information criteria.
</p>
<p><code><a href="#topic+TRRsim">TRRsim</a></code> for generating the simulated data used in tensor response regression.
</p>
<p>The simulated data <code><a href="#topic+bat">bat</a></code> used in tensor response regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The dimension of response
r &lt;- c(10, 10, 10)
# The envelope dimensions u.
u &lt;- c(2, 2, 2)
# The dimension of predictor
p &lt;- 5
# The sample size
n &lt;- 100

# Simulate the data with TRRsim.
dat &lt;- TRRsim(r = r, p = p, u = u, n = n)
x &lt;- dat$x
y &lt;- dat$y
B &lt;- dat$coefficients

fit_std &lt;- TRR.fit(x, y, method="standard")
fit_fg &lt;- TRR.fit(x, y, u, method="FG")
fit_1D &lt;- TRR.fit(x, y, u, method="1D")
fit_pls &lt;- TRR.fit(x, y, u, method="PLS")
fit_ECD &lt;- TRR.fit(x, y, u, method="ECD")

rTensor::fnorm(B-stats::coef(fit_std))
rTensor::fnorm(B-stats::coef(fit_fg))
rTensor::fnorm(B-stats::coef(fit_1D))
rTensor::fnorm(B-stats::coef(fit_pls))
rTensor::fnorm(B-stats::coef(fit_ECD))

# Extract the mean squared error, p-value and standard error from summary
summary(fit_std)$mse
summary(fit_std)$p_val
summary(fit_std)$se

## ----------- Pass a list or an environment to x also works ------------- ##
# Pass a list to x
l &lt;- dat[c("x", "y")]
fit_std_l &lt;- TRR.fit(l, method="standard")

# Pass an environment to x
e &lt;- new.env()
e$x &lt;- dat$x
e$y &lt;- dat$y
fit_std_e &lt;- TRR.fit(e, method="standard")

## ----------- Use dataset "bat" included in the package ------------- ##
data("bat")
x &lt;- bat$x
y &lt;- bat$y
fit_std &lt;- TRR.fit(x, y, method="standard")

</code></pre>

<hr>
<h2 id='TRRdim'>Envelope dimension selection for tensor response regression (TRR)</h2><span id='topic+TRRdim'></span>

<h3>Description</h3>

<p>This function uses the 1D-BIC criterion proposed by Zhang, X., &amp; Mai, Q. (2018) to select envelope dimensions in tensor response regression. Refer to <code><a href="#topic+oneD_bic">oneD_bic</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TRRdim(x, y, C = NULL, maxdim = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TRRdim_+3A_x">x</code></td>
<td>
<p>The predictor matrix of dimension <code class="reqn">p \times n</code>. Vector of length <code class="reqn">n</code> is acceptable.</p>
</td></tr>
<tr><td><code id="TRRdim_+3A_y">y</code></td>
<td>
<p>The response tensor instance with dimension <code class="reqn">r_1\times r_2\times\cdots\times r_m \times n</code>, where <code class="reqn">n</code> is the sample size. Array with the same dimensions and matrix with dimension <code class="reqn">r\times n</code> are acceptable.</p>
</td></tr>
<tr><td><code id="TRRdim_+3A_c">C</code></td>
<td>
<p>The parameter passed to <code><a href="#topic+oneD_bic">oneD_bic</a></code>. Default is <code>nrow(x) = p</code>.</p>
</td></tr>
<tr><td><code id="TRRdim_+3A_maxdim">maxdim</code></td>
<td>
<p>The maximum envelope dimension to be considered. Default is 10.</p>
</td></tr>
<tr><td><code id="TRRdim_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+oneD_bic">oneD_bic</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+oneD_bic">oneD_bic</a></code> for more details on the definition of 1D-BIC criterion and on the arguments <code class="reqn">C</code> and the additional arguments.
</p>
<p>Let <code class="reqn">B</code> denote the estimated envelope with the selected dimension <code>u</code>, then the prediction is <code class="reqn">\hat{Y}_i = B \bar{\times}_{(m+1)} X_i</code> for each observation. And the mean squared error is defined as <code class="reqn">1/n\sum_{i=1}^n||Y_i-\hat{Y}_i||_F^2</code>, where <code class="reqn">||\cdot||_F</code> denotes the Frobenius norm.
</p>


<h3>Value</h3>

<table>
<tr><td><code>bicval</code></td>
<td>
<p>The minimal BIC values for each mode.</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>The optimal envelope subspace dimension <code class="reqn">(u_1, u_2,\cdots,u_m).</code></p>
</td></tr>
<tr><td><code>mse</code></td>
<td>
<p>The prediction mean squared error using the selected envelope basis.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Li, L. and Zhang, X., 2017. Parsimonious tensor response regression. Journal of the American Statistical Association, 112(519), pp.1131-1146.
</p>
<p>Zhang, X. and Mai, Q., 2018. Model-free envelope dimension selection. Electronic Journal of Statistics, 12(2), pp.2193-2216.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+oneD_bic">oneD_bic</a></code>, <code><a href="#topic+TRRsim">TRRsim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The dimension of response
r &lt;- c(10, 10, 10)
# The envelope dimensions u.
u &lt;- c(2, 2, 2)
# The dimension of predictor
p &lt;- 5
# The sample size
n &lt;- 100

# Simulate the data with TRRsim.
dat &lt;- TRRsim(r = r, p = p, u = u, n = n)
x &lt;- dat$x
y &lt;- dat$y

TRRdim(x, y) # The estimated envelope dimensions are the same as u.

## Use dataset bat. (time-consuming)

data("bat")
x &lt;- bat$x
y &lt;- bat$y
# check the dimension of y
dim(y)
# use 32 as the maximal envelope dimension
TRRdim(x, y, maxdim=32)


</code></pre>

<hr>
<h2 id='TRRsim'>Generate simulation data for tensor response regression (TRR)</h2><span id='topic+TRRsim'></span>

<h3>Description</h3>

<p>This function is used to generate simulation data used in tensor response regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TRRsim(r, p, u, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TRRsim_+3A_r">r</code></td>
<td>
<p>The dimension of response, a vector with length larger than 2.</p>
</td></tr>
<tr><td><code id="TRRsim_+3A_p">p</code></td>
<td>
<p>The dimension of predictor, a scale.</p>
</td></tr>
<tr><td><code id="TRRsim_+3A_u">u</code></td>
<td>
<p>The structural dimension of envelopes at each mode, a vector with the same length as <code>r</code>.</p>
</td></tr>
<tr><td><code id="TRRsim_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tensor response regression model is of the form,
</p>
<p style="text-align: center;"><code class="reqn">Y = B \bar{\times}_{(m+1)} X + \epsilon</code>
</p>

<p>where predictor <code class="reqn">X \in R^{p}</code>, response <code class="reqn">Y \in R^{r_1\times \cdots\times r_m}</code>, <code class="reqn">B \in R^{r_1\times \cdots\times r_m \times p}</code> and the error term is tensor normal distributed as follows,
</p>
<p style="text-align: center;"><code class="reqn">\epsilon \sim TN(0;\Sigma_1,\dots,\Sigma_m).</code>
</p>

<p>According to the tensor envelope structure, we have
</p>
<p style="text-align: center;"><code class="reqn">B = [\Theta;\Gamma_1,\ldots,\Gamma_m, I_p],</code>
</p>

<p style="text-align: center;"><code class="reqn">\Sigma_k = \Gamma_k \Omega_k \Gamma_k^{T} + \Gamma_{0k} \Omega_{0k} \Gamma_{0k}^T,</code>
</p>

<p>for some <code class="reqn">\Theta \in R^{u_1\times\cdots\times u_m \times p}</code>, <code class="reqn">\Omega_k \in R^{u_k \times u_k}</code> and <code class="reqn">\Omega_{0k} \in \in R^{(p_k - u_k) \times (p_k - u_k)}</code>, <code class="reqn">k=1,\ldots,m</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>The predictor of dimension <code class="reqn">p\times n</code>.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response of dimension <code class="reqn">r_1\times \cdots\times r_m \times n</code>.</p>
</td></tr>
<tr><td><code>Gamma</code></td>
<td>
<p>The envelope subspace basis of dimension <code class="reqn">r_k \times u_k, \ k=1,\ldots,m</code>.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>The tensor coefficients of dimension <code class="reqn">r_1\times \cdots\times r_m \times p</code>.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>A lists of estimated covariance matrices at each mode for the error term, i.e., <code class="reqn">\Sigma_1,\dots,\Sigma_m</code>.</p>
</td></tr>
<tr><td><code>p</code>, <code>r</code>, <code>u</code></td>
<td>
<p>The input <code>p,r,u</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The length of <code>r</code> must match that of <code>u</code>, and each element of <code>u</code> must be less than the corresponding element in <code>r</code>.
</p>


<h3>References</h3>

<p>Li, L. and Zhang, X., 2017. Parsimonious tensor response regression. Journal of the American Statistical Association, 112(519), pp.1131-1146.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TPR.fit">TPR.fit</a>, <a href="#topic+TPRsim">TPRsim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r &lt;- c(10, 10, 10)
u &lt;- c(2, 2, 2)
p &lt;- 5
n &lt;- 100
dat &lt;- TRRsim(r = r, p = p, u = u, n = n)
x &lt;- dat$x
y &lt;- dat$y
fit_std &lt;- TRR.fit(x, y, method="standard")

</code></pre>

<hr>
<h2 id='ttt'>Matrix product of two tensors</h2><span id='topic+ttt'></span>

<h3>Description</h3>

<p>Matrix product of two tensors unfolded on the specified modes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ttt(x, y, ms)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ttt_+3A_x">x</code></td>
<td>
<p>A tensor instance.</p>
</td></tr>
<tr><td><code id="ttt_+3A_y">y</code></td>
<td>
<p>A tensor instance.</p>
</td></tr>
<tr><td><code id="ttt_+3A_ms">ms</code></td>
<td>
<p>The indices of the modes to compute on. A single value or a vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Suppose <code>x</code> is a <code class="reqn">s</code>-way tensor with dimension <code class="reqn">p_1 \times \ldots \times p_s</code> and <code>y</code> is a t-way tensor with dimension <code class="reqn">r_1 \times \ldots \times r_t</code>. <code>ms</code> specifies the indices on which the tensors <code>x</code> and <code>y</code> are unfolded as columns. Thus, <code>ms</code> must be a subset of <code>1:min{s,t}</code>. Meanwhile, the sizes of the dimensions specified by <code>ms</code> must match, e.g., if <code>ms = 1:k</code> where <code>k &lt;= min{s,t}</code>, then <code class="reqn">p_1\times \ldots p_k = s_1\times \ldots s_k</code>. Let <code class="reqn">X_0</code> and <code class="reqn">Y_0</code>  denote the unfolded matrices, the matrix <code class="reqn">X_0 \times Y_0^T</code> is returned. See <strong>Examples</strong> for a better illustration.
</p>


<h3>Value</h3>

<p>Return the matrix product of tensors <code>x</code> and <code>y</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rTensor::as.tensor(array(runif(24), c(3, 4, 2)))
y &lt;- rTensor::as.tensor(array(runif(24), c(3, 4, 2)))
z &lt;- ttt(x, y, 1:2)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
