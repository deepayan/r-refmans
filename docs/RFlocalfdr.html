<!DOCTYPE html><html><head><title>Help for package RFlocalfdr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RFlocalfdr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#count_variables'><p>count the number of times each variable is used in a ranger random forest</p></a></li>
<li><a href='#determine_cutoff'><p>evaluate a measure that can be used to determining a significance level for the Mean Decrease in Impurity measure returned by a Random Forest model</p></a></li>
<li><a href='#determine.C'><p>determine.C</p></a></li>
<li><a href='#f.fit'><p>fit a spline to the histogram of imp</p></a></li>
<li><a href='#fit.to.data.set'><p>fit.to.data.set</p></a></li>
<li><a href='#fit.to.data.set.wrapper'><p>fit.to.data.set.wrapper</p></a></li>
<li><a href='#imp20000'><p>20000 importance values</p></a></li>
<li><a href='#local.fdr'><p>local fdr</p></a></li>
<li><a href='#my_PIMP'><p>my_PIMP</p>
based on the PIMP function from the vita package. ‘PIMP’ implements the test approach of Altmann et al. (2010) for
the permutation variable importance measure ‘VarImp’ returned by the randomForest package (Liaw and Wiener (2002)) for
classification and regression.</a></li>
<li><a href='#my_ranger_PIMP'><p>my_ranger_PIMP</p>
based on the PIMP function from the vita package. ‘PIMP’ implements the test approach of Altmann et al. (2010) for
the permutation variable importance measure ‘VarImp’ returned by the randomForest package (Liaw and Wiener (2002)) for
classification and regression.</a></li>
<li><a href='#my.dsn'><p>my.dsn</p></a></li>
<li><a href='#my.test1fun'><p>my.test1fun</p></a></li>
<li><a href='#plotQ'><p>plotQ</p></a></li>
<li><a href='#propTrueNullByLocalFDR'><p>propTrueNullByLocalFDR</p></a></li>
<li><a href='#run.it.importances'><p>run.it.importances</p></a></li>
<li><a href='#significant.genes'><p>significant.genes</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Significance Level for Random Forest Impurity Importance Scores</td>
</tr>
<tr>
<td>Version:</td>
<td>0.8.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Sets a significance level for  Random Forest MDI (Mean Decrease in Impurity, Gini or
             sum of squares) variable importance scores, using an empirical Bayes approach.
             See Dunne et al. (2022)  &lt;<a href="https://doi.org/10.1101%2F2022.04.06.487300">doi:10.1101/2022.04.06.487300</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>Imports:</td>
<td>minpack.lm, sn, fitdistrplus, grDevices, graphics, stats,
ranger, randomForest, RFlocalfdr.data, vita</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-09 01:38:54 UTC; dun280</td>
</tr>
<tr>
<td>Author:</td>
<td>Robert Dunne <a href="https://orcid.org/0000-0003-1946-7279"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Robert Dunne &lt;rob.dunne@csiro.au&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-09 07:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='count_variables'>count the number of times each variable is used in a ranger random forest</h2><span id='topic+count_variables'></span>

<h3>Description</h3>


<ul>
<li><p> count the number of times each variable is used in a ranger random forest.
</p>
</li>
<li><p> help(treeInfo) warns &quot;splitvarID &ndash; ID of the splitting variable, 0-indexed.
Caution, the variable order changes if the formula interface is used&quot;
However this should be investigated
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>count_variables(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="count_variables_+3A_object">object</code></td>
<td>
<p>a ranger forest object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a table (0-indexed) giving the number of times each variable was used in the random forest
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ranger)
rf1 &lt;- ranger(Species ~ ., data = iris,importance="impurity", seed=123)
count_variables(rf1)
rf2 &lt;- ranger(dependent.variable.name = "Species", data = iris,seed=123)
count_variables(rf2)
rf3&lt;- ranger(y = iris[, 5], x = iris[, -5],seed=123)
count_variables(rf3)

</code></pre>

<hr>
<h2 id='determine_cutoff'>evaluate a measure that can be used to determining a significance level for the Mean Decrease in Impurity measure returned by a Random Forest model</h2><span id='topic+determine_cutoff'></span>

<h3>Description</h3>

<p>evaluate a measure that can be used to determining a significance level for the Mean Decrease in Impurity measure returned by a Random Forest model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>determine_cutoff(
  imp,
  t2,
  cutoff = c(0, 1, 4, 10, 15, 20),
  Q = 0.75,
  plot = NULL,
  verbose = 0,
  try.counter = 3
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="determine_cutoff_+3A_imp">imp</code></td>
<td>
<p>vector of MDI variable importances</p>
</td></tr>
<tr><td><code id="determine_cutoff_+3A_t2">t2</code></td>
<td>
<p>number of times each variable is used in the a ranger forest. Returned by
count_variables for a ranger RF</p>
</td></tr>
<tr><td><code id="determine_cutoff_+3A_cutoff">cutoff</code></td>
<td>
<p>values to evaluate</p>
</td></tr>
<tr><td><code id="determine_cutoff_+3A_q">Q</code></td>
<td>
<p>&ndash; we examine the fit up to the quartile Q</p>
</td></tr>
<tr><td><code id="determine_cutoff_+3A_plot">plot</code></td>
<td>
<p>for 4 selected values of the cutoff. The plot contains
</p>

<ul>
<li><p> The data (black) and  the  fitted density  (red)
</p>
</li>
<li><p> The skew-normal fit (blue)
</p>
</li>
<li><p> The quantile Q (vertical red line)
</p>
</li></ul>
</td></tr>
<tr><td><code id="determine_cutoff_+3A_verbose">verbose</code></td>
<td>
<p>verbose=0, no output to screen
verbose=1, track the cutoff value being used</p>
</td></tr>
<tr><td><code id="determine_cutoff_+3A_try.counter">try.counter</code></td>
<td>
<p>passed to fit.to.data.set.wrapper</p>
</td></tr>
</table>


<h3>Value</h3>

<p>res a matrix if size length(cutoff) by 3.
We model the histogram of imp with a kernel density estimate, y.
Let t1 be  fitted values of the skew normal. Then res contains three columns
</p>

<ul>
<li><p> sum((y-t1)^2)
</p>
</li>
<li><p> sum(abs(y-t1)) and
</p>
</li>
<li><p> max(abs(y-t1)),
evaluated up to the quantile Q
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)
imp &lt;- log(imp20000$importances)
t2&lt;- imp20000$counts
length(imp)
hist(imp,col=6,lwd=2,breaks=100,main="histogram of importances")
res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(0,1,2,3),plot=c(0,1,2,3),Q=0.75,try.counter=1)

plot(c(0,1,2,3),res.temp[,3])
# the minimum is at 1 so
imp&lt;-imp[t2 &gt; 1]

qq &lt;- plotQ(imp,debug.flag = 0)
ppp&lt;-run.it.importances(qq,imp,debug=0)
aa&lt;-significant.genes(ppp,imp,cutoff=0.2,debug.flag=0,do.plot=2, use_95_q=TRUE)
length(aa$probabilities) #11#
names(aa$probabilities)
#[1] "X101"   "X102"   "X103"   "X104"   "X105"   "X2994"  "X9365"  "X10718"
# [9] "X13371" "X15517" "X16460"
# so the observed FDR is 0.54


library(ranger)
library(RFlocalfdr.data)
data(smoking)
y&lt;-smoking$y
smoking_data&lt;-smoking$rma
y.numeric &lt;-ifelse((y=="never-smoked"),0,1)
rf1 &lt;- ranger::ranger(y=y.numeric ,x=smoking_data,importance="impurity",seed=123, num.trees = 10000,     
         classification=TRUE)
t2 &lt;-count_variables(rf1)
imp&lt;-log(rf1$variable.importance)
plot(density((imp)))
# Detemine a cutoff to get a unimodal density.
res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(1,2,3,4),plot=c(1,2,3,4),Q=0.75)
plot(c(1,2,3,4),res.temp[,3])

</code></pre>

<hr>
<h2 id='determine.C'>determine.C</h2><span id='topic+determine.C'></span>

<h3>Description</h3>

<p>by assumption, there is a point q such that to the left of q, f_B sim  f_0 (z). That is, there is a q
such that there are only null values to the left of q. We determine q using a
change point method related to penalized model selection. See
Gauran, Iris Ivy M. and Park, Junyong and Lim, Johan and Park, DoHwan and Zylstra, John and Peterson,
Thomas and Kann, Maricel and Spouge, John L. &quot;Empirical null estimation using zero-inflated discrete
mixture distributions and its application to protein domain data&quot; Biometrics, 2018 74:2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>determine.C(f_fit, df, t1, trace.plot = FALSE, start_at = 30, debug.flag = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="determine.C_+3A_f_fit">f_fit</code></td>
<td>
<p>object returned by f.fit</p>
</td></tr>
<tr><td><code id="determine.C_+3A_df">df</code></td>
<td>
<p>data frame containing x and y</p>
</td></tr>
<tr><td><code id="determine.C_+3A_t1">t1</code></td>
<td>
<p>initial estimates of xi, omega, and  lambda. Generally returned by fit.to.data.set.wrapper</p>
</td></tr>
<tr><td><code id="determine.C_+3A_trace.plot">trace.plot</code></td>
<td>
<p>&ndash; produce a plot of each fit with a 1 second sleep. Can be watched as a movie.</p>
</td></tr>
<tr><td><code id="determine.C_+3A_start_at">start_at</code></td>
<td>
<p>&ndash;  x &lt;- f_fit$midpoints  is of length 119 (quite arbitrary). We use the first start_at
values of x to fit the skew-normal distribution.</p>
</td></tr>
<tr><td><code id="determine.C_+3A_debug.flag">debug.flag</code></td>
<td>
<p>&ndash; debugging level. If debug.flag &gt;0 then some output is printed to the screen.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>&ndash; a vector of numbers of length equal to the rows in df (119 in this case). Say that this is qq.
We determine the minimum value of qq. This is the value &quot;C&quot; such that
&ndash; to the right of C, our data is generated from the NULL distribution
&ndash; to the left of C, we have a mixture of the NULL and non-NULL distribution
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)                                      
imp&lt;-log(imp20000$importances)                               
t2&lt;-imp20000$counts
temp&lt;-imp[t2 &gt; 1]   #see                          
temp&lt;-temp[temp != -Inf]                         
temp &lt;- temp - min(temp) + .Machine$double.eps   
f_fit &lt;- f.fit(temp)                             
y &lt;- f_fit$zh$density                            
x &lt;- f_fit$midpoints                             
df &lt;- data.frame(x, y)                           
initial.estimates &lt;- fit.to.data.set.wrapper(df, temp, try.counter = 3,return.all=FALSE)           
initial.estimates&lt;-  initial.estimates$Estimate

qq&lt;- determine.C(f_fit,df,initial.estimates,start_at=37,trace.plot = FALSE)    
cc&lt;-x[which.min(qq)]                                                                             
plot(x,qq,main="determine cc")                                                                   
abline(v=cc)
# unfortunately the minima does not appear reasonable. In this case it is advisable to use the
# 95th quantile


#needs the  chromosome 22 data in  RFlocalfdr.data. Also has a long runtime.
library(RFlocalfdr.data)
data(ch22)                                                                                    
?ch22                                                                                        
t2 &lt;-ch22$C                                                                                   
imp&lt;-log(ch22$imp)                                                                            
#Detemine a cutoff to get a unimodal density.                                                 
res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(25,30,35,40),plot=c(25,30,35,40),Q=0.75)       
plot(c(25,30,35,40),res.temp[,3])                                                             
imp&lt;-imp[t2 &gt; 30]
debug.flag &lt;- 0
f_fit&lt;- f.fit(imp,debug.flag=debug.flag,temp.dir=temp.dir)
#makes the plot histogram_of_variable_importances.png                              
y&lt;-f_fit$zh$density                                                                                                                           
x&lt;-f_fit$midpoints                                                                                                                                    
plot(density(imp),main="histogram and fitted spline")                                                                                     
lines(x,y,col="red")                                                                                                                      
df&lt;-data.frame(x,y)                                                                                                                           
initial.estimates &lt;- fit.to.data.set.wrapper(df,imp,debug.flag=debug.flag,plot.string="initial",
                                              temp.dir=temp.dir,try.counter=3)    
initial.estimates &lt;- data.frame(summary(initial.estimates)$parameters)$Estimate                                                               
# 1.102303 1.246756 1.799169
qq&lt;- determine.C(f_fit,df,initial.estimates,start_at=37,trace.plot = TRUE)    
cc&lt;-x[which.min(qq)]                                                                             
plot(x,qq,main="determine cc")                                                                   
abline(v=cc)

</code></pre>

<hr>
<h2 id='f.fit'>fit a spline to the histogram of imp</h2><span id='topic+f.fit'></span>

<h3>Description</h3>

<p>fit a spline to the histogram of imp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.fit(imp, df = 10, debug.flag = 0, temp.dir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f.fit_+3A_imp">imp</code></td>
<td>
<p>the variable importances</p>
</td></tr>
<tr><td><code id="f.fit_+3A_df">df</code></td>
<td>
<p>the degrees of freedom for the spline fit</p>
</td></tr>
<tr><td><code id="f.fit_+3A_debug.flag">debug.flag</code></td>
<td>
<p>either 0 (no debugging information), 1 or 2</p>
</td></tr>
<tr><td><code id="f.fit_+3A_temp.dir">temp.dir</code></td>
<td>
<p>if debug flag is &gt;0 then information is written to temp.dir</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following components
</p>

<ul>
<li><p> &quot;x&quot; &ndash; midpoints of the histogram
</p>
</li>
<li><p> &quot;zh&quot; &ndash; a histogram object as returned by &quot;hist&quot;
</p>
</li>
<li><p> &quot;f.spline&quot; &ndash; the spline fit. The fit is given by a glm mode glm(zh$counts ~ splines::ns(x), poisson)
</p>
</li>
<li><p> &quot;counts&quot; the counts from the histogram
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)
imp &lt;- log(imp20000$importances)
res &lt;- f.fit(imp)
plot(res$zh, xlab="importances", main="histogram of importances")
points(res$midpoints,res$counts, col="grey90")
lines(res$zh$breaks[-1],res$f.spline,col="blue", lwd=3)
legend("topleft",c("spline fit"), col="blue", lwd=3)
</code></pre>

<hr>
<h2 id='fit.to.data.set'>fit.to.data.set</h2><span id='topic+fit.to.data.set'></span>

<h3>Description</h3>

<p>This function fit a skew normal to a set of data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.to.data.set(
  df,
  imp,
  debug.flag = 0,
  plot.string = "",
  temp.dir = NULL,
  try.counter = 3,
  return.all = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.to.data.set_+3A_df">df</code></td>
<td>
<p>contains x and y, midpoints and counts from a histogram of imp</p>
</td></tr>
<tr><td><code id="fit.to.data.set_+3A_imp">imp</code></td>
<td>
<p>importances</p>
</td></tr>
<tr><td><code id="fit.to.data.set_+3A_debug.flag">debug.flag</code></td>
<td>
<p>debug flag</p>
</td></tr>
<tr><td><code id="fit.to.data.set_+3A_plot.string">plot.string</code></td>
<td>
<p>file name for a debugging plot</p>
</td></tr>
<tr><td><code id="fit.to.data.set_+3A_temp.dir">temp.dir</code></td>
<td>
<p>directory for debugging output</p>
</td></tr>
<tr><td><code id="fit.to.data.set_+3A_try.counter">try.counter</code></td>
<td>
<p>try.counter=1 my.dsn xi=  1
try.counter=2  xi=  mean(x)
try.counter=3 start xi, omega, lambda from the parameters retuned by fitdistrplus::fitdist</p>
</td></tr>
<tr><td><code id="fit.to.data.set_+3A_return.all">return.all</code></td>
<td>
<p>TRUE, return the full ouput of minpack.lm::nlsLM,
FALSE , return summary of parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the skew-normal fitting routine is succesful, then the matrix of parmaters and standard errors is returned.
&ndash; othewise a &quot;try-error&quot; message is returned
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)                                      
imp&lt;-log(imp20000$importances)                               
t2&lt;-imp20000$counts
temp&lt;-imp[t2 &gt; 1]   #see                          
temp&lt;-temp[temp != -Inf]                         
temp &lt;- temp - min(temp) + .Machine$double.eps   
f_fit &lt;- f.fit(temp)                             
y &lt;- f_fit$zh$density                            
x &lt;- f_fit$midpoints                             
df &lt;- data.frame(x, y)                           
fitted_parameters &lt;- fit.to.data.set(df, temp, try.counter = 3)           
fitted_parameters

hist(temp, breaks = 200, freq = FALSE)
lines(df$x, df$y, type = "l", col = "green", lwd = 2, 
      xlim = c(0, max(df$x) + 0.5))
curve(sn::dsn(x, xi = fitted_parameters$Estimate[1], omega = fitted_parameters$Estimate[2], 
              alpha = fitted_parameters$Estimate[3]), add = TRUE, 
                col = "purple", lwd = 3, xlim = c(0, 16))
curve(my.dsn(x, xi = fitted_parameters$Estimate[1], omega = fitted_parameters$Estimate[2],  
                lambda = fitted_parameters$Estimate[3]), add = TRUE, 
                col = "orange", lwd = 3)


library(RFlocalfdr.data)
data(ch22)                                       
imp&lt;-log(ch22$imp)                               
t2&lt;-ch22$C                                       
temp&lt;-imp[t2 &gt; 30]   #                           
temp&lt;-temp[temp != -Inf]                         
temp &lt;- temp - min(temp) + .Machine$double.eps   
f_fit &lt;- f.fit(temp)                             
y &lt;- f_fit$zh$density                            
x &lt;- f_fit$midpoints                             
df &lt;- data.frame(x, y)                           
mm.df3 &lt;- fit.to.data.set(df, temp)              
mm.df3
##              Estimate Std..Error  t.value     Pr...t..
## xi.xi        1.102303 0.03669284 30.04136 1.485263e-56
## omega.omega  1.246756 0.04716184 26.43569 6.276349e-51
## lambda.alpha 1.799169 0.17343872 10.37351 3.103195e-18

</code></pre>

<hr>
<h2 id='fit.to.data.set.wrapper'>fit.to.data.set.wrapper</h2><span id='topic+fit.to.data.set.wrapper'></span>

<h3>Description</h3>

<p>This function allows you to express your love of cats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.to.data.set.wrapper(
  df,
  imp,
  debug.flag = 0,
  plot.string = "",
  temp.dir = temp.dir,
  return.all = TRUE,
  try.counter = 3
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.to.data.set.wrapper_+3A_df">df</code></td>
<td>
<p>contains x and y, midpoints and counts from a histogram of imp</p>
</td></tr>
<tr><td><code id="fit.to.data.set.wrapper_+3A_imp">imp</code></td>
<td>
<p>importances</p>
</td></tr>
<tr><td><code id="fit.to.data.set.wrapper_+3A_debug.flag">debug.flag</code></td>
<td>
<p>debug flag</p>
</td></tr>
<tr><td><code id="fit.to.data.set.wrapper_+3A_plot.string">plot.string</code></td>
<td>
<p>file name for a debugging plot, passed on to fit.to.data.set</p>
</td></tr>
<tr><td><code id="fit.to.data.set.wrapper_+3A_temp.dir">temp.dir</code></td>
<td>
<p>directory for debugging output, passed on to fit.to.data.set</p>
</td></tr>
<tr><td><code id="fit.to.data.set.wrapper_+3A_return.all">return.all</code></td>
<td>
<p>passed to fit.to.data.set. If TRUE then the full output of minpack.lm::nlsLM is returned. Otherwise
just the matrix of coefficients and t-values is returned.</p>
</td></tr>
<tr><td><code id="fit.to.data.set.wrapper_+3A_try.counter">try.counter</code></td>
<td>
<p>passed on to fit.to.data.set
try.counter=1 my.dsn xi=  1
try.counter=2  xi=  mean(x)
try.counter=3 start xi, omega, lambda from the parameters retuned by fitdistrplus::fitdist</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the skew-normal fitting routine is succesful, then the matrix of parmaters and standard errors is returned.
&ndash; othewise a &quot;try-error&quot; message is returned
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)                                      
imp&lt;-log(imp20000$importances)                               
t2&lt;-imp20000$counts
temp&lt;-imp[t2 &gt; 1]   #see                          
temp&lt;-temp[temp != -Inf]                         
temp &lt;- temp - min(temp) + .Machine$double.eps   
f_fit &lt;- f.fit(temp)                             
y &lt;- f_fit$zh$density                            
x &lt;- f_fit$midpoints                             
df &lt;- data.frame(x, y)                           
fitted_parameters &lt;- fit.to.data.set.wrapper(df, temp, try.counter = 3,return.all=FALSE)           
fitted_parameters

hist(temp, breaks = 200, freq = FALSE)
lines(df$x, df$y, type = "l", col = "green", lwd = 2, 
      xlim = c(0, max(df$x) + 0.5))
curve(sn::dsn(x, xi = fitted_parameters$Estimate[1], omega = fitted_parameters$Estimate[2], 
              alpha = fitted_parameters$Estimate[3]), add = TRUE, 
                col = "purple", lwd = 3, xlim = c(0, 16))
curve(my.dsn(x, xi = fitted_parameters$Estimate[1], omega = fitted_parameters$Estimate[2],  
                lambda = fitted_parameters$Estimate[3]), add = TRUE, 
                col = "orange", lwd = 3)


library(RFlocalfdr.data)
data(ch22)
t2 &lt;-ch22$C
imp&lt;-log(ch22$imp)
imp&lt;-imp[t2 &gt; 30]
imp &lt;- imp[imp != -Inf]
imp &lt;- imp - min(imp) + .Machine$double.eps
f_fit &lt;- f.fit(imp )
y &lt;- f_fit$zh$density
x &lt;- f_fit$midpoints
C &lt;- quantile(imp,probs=0.75)
df2 &lt;- data.frame(x[x &lt; C], y[x &lt; C])
initial.estimates &lt;- fit.to.data.set.wrapper(df2, imp)
#Nonlinear regression model                                            
#  model: y ~ my.dsn(x, xi = xi, omega = omega, lambda = lambda)       
#   data: df                                                           
#       xi.xi  omega.omega lambda.alpha                                
#       1.163        1.193        1.574                                
# residual sum-of-squares: 0.06269                                     
#                                                                      
#Number of iterations to convergence: 23                               
#Achieved convergence tolerance: 1.49e-08

</code></pre>

<hr>
<h2 id='imp20000'>20000 importance values</h2><span id='topic+imp20000'></span>

<h3>Description</h3>

<p>A dataset containing  20000 importance values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imp20000
</code></pre>


<h3>Format</h3>

<p>A vector varaible importances with 20000 values
</p>

<dl>
<dt>imp1</dt><dd><p>importances </p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
require(ranger)
inv.logit &lt;-function (x) {
    plogis(x)}

make_data &lt;- function(nVars, nSamples) {
    as.matrix(sapply(1:nVars, function(t){sample(0:2, nSamples, replace=TRUE)}))
}

make_cont_response &lt;- function(X, w) {
    (X-1) %*% w 
}

make_response &lt;- function(X, w) {
   as.factor(inv.logit((X-1) %*% w * 2 ) &gt; runif(nrow(X)))
} 


nVars &lt;-   20000
nSamples &lt;- 1000

set.seed(19)
X&lt;- make_data(nVars,nSamples)

w &lt;- rep(0, times = nVars)
w[101] &lt;- 1
w[102] &lt;- 1/sqrt(2)
w[103] &lt;- 1/sqrt(4)
w[104] &lt;- 1/sqrt(8)
w[105] &lt;- 1/sqrt(16)
y &lt;- make_response(X, w)


colnames(X) &lt;- c(make.names(1:20000))
set.seed(19)
rf1&lt;-ranger::ranger(y=y,x=X, num.trees = 2000,importance="impurity")
table(y,predict(rf1,data=X)$predictions)
#OOB prediction error:             41.30 % 
table(y,predict(rf1,data=X)$predictions)

t2 &lt;-count_variables(rf1)
head(t2)
dim(t2)

imp&lt;-rf1$variable.importance
imp&lt;-log(imp)
plot(density((imp)))
hist(imp,col=6,lwd=2,breaks=100,main="histogram of importances")

res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(0,1,2,3),plot=c(0,1,2,3),Q=0.75,try.counter=1)
plot(c(0,1,2,3),res.temp[,3])
imp&lt;-imp[t2 &gt; 1]
qq &lt;- plotQ(imp,debug.flag = 0)
ppp&lt;-run.it.importances(qq,imp,debug=0)
aa&lt;-significant.genes(ppp,imp,cutoff=0.2,debug.flag=0,do.plot=2, use_95_q=TRUE)
length(aa$probabilities)
names(aa$probabilities)
#' #[1] "X101"   "X102"   "X103"   "X104"   "X105"   "X2994"  "X9365"  "X10718"
# [9] "X13371" "X15517" "X16460"

counts&lt;-t2
imp20000 &lt;- list(imp,counts)
names(imp20000) &lt;-c("importances","counts")


</code></pre>

<hr>
<h2 id='local.fdr'>local fdr</h2><span id='topic+local.fdr'></span>

<h3>Description</h3>

<p>calculate the local
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local.fdr(
  f,
  x,
  FUN = my.dsn,
  p0 = 1,
  debug.flag = 0,
  plot.string = "",
  temp.dir = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local.fdr_+3A_f">f</code></td>
<td>
<p>object retuned by call to f.fit</p>
</td></tr>
<tr><td><code id="local.fdr_+3A_x">x</code></td>
<td>
<p>f_fit$midpoints</p>
</td></tr>
<tr><td><code id="local.fdr_+3A_fun">FUN</code></td>
<td>
<p>my.dsn</p>
</td></tr>
<tr><td><code id="local.fdr_+3A_p0">p0</code></td>
<td>
<p>estimated proportion of null importances</p>
</td></tr>
<tr><td><code id="local.fdr_+3A_debug.flag">debug.flag</code></td>
<td>
<p>either 0 (no debugging information), 1 or 2</p>
</td></tr>
<tr><td><code id="local.fdr_+3A_plot.string">plot.string</code></td>
<td>
<p>file name for a debugging plot</p>
</td></tr>
<tr><td><code id="local.fdr_+3A_temp.dir">temp.dir</code></td>
<td>
<p>directory for debugging output</p>
</td></tr>
<tr><td><code id="local.fdr_+3A_...">...</code></td>
<td>
<p>arguments passed to FUN</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns an estimate of the local false discovery rate.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)                                      
imp&lt;-log(imp20000$importances)                               
t2&lt;-imp20000$counts
temp&lt;-imp[t2 &gt; 1]   #see                          
temp&lt;-temp[temp != -Inf]                         
temp &lt;- temp - min(temp) + .Machine$double.eps   
f_fit &lt;- f.fit(temp)                             
y &lt;- f_fit$zh$density                            
x &lt;- f_fit$midpoints                             
df &lt;- data.frame(x, y)                           
fitted_parameters &lt;- fit.to.data.set(df, temp, try.counter = 3)           
fitted_parameters

aa &lt;- local.fdr(f_fit, df$x, FUN = my.dsn, xi = fitted_parameters$Estimate[1],
                omega = fitted_parameters$Estimate[2], lambda = fitted_parameters$Estimate[3],
                debug.flag = 0, plot.string = "initial")

plot(x,y,axes=FALSE,type="l",col="blue",main = "local fdr",
      xlab="importances",ylab="")                                                                                       
axis(2, pretty( c(0,max(y)+0.5*max(y)),10))                                                                            
                                                                                                                        
oldpar &lt;- par(new = TRUE)
plot(x, aa, type="l",col="green",main = "",xlab="",ylab="",axes=FALSE)                                                 
abline(h = 0.2)                                                                                                        
axis(4, pretty( aa,10))                                                                                                
                                                                                                                        
axis(1,pretty(x,10))                                                                                                   
box() #- to make it look "as usual                                                                                     
legend("topright",c("density importances","local fdr"),col=c("blue","green"),lty=1)
par(oldpar)


library(RFlocalfdr.data)
data(ch22)                                                                                                             
imp&lt;-log(ch22$imp)
t2&lt;-ch22$C                                                                                                             
imp&lt;-imp[t2 &gt; 30]                                                                                                      
imp &lt;- imp - min(imp) + .Machine$double.eps                                                                            
debug.flag &lt;- 0                                                                                                        
f_fit &lt;- f.fit(imp, debug.flag = debug.flag)                                                                           
y &lt;- f_fit$zh$density                                                                                                  
x &lt;- f_fit$midpoints                                                                                                   
df &lt;- data.frame(x, y)                                                                                                 
initial.estimates &lt;- fit.to.data.set.wrapper(df, imp, debug.flag = debug.flag,
return.all = FALSE)

aa &lt;- local.fdr(f_fit, df$x, FUN = my.dsn, xi = initial.estimates$Estimate[1],
    omega = initial.estimates$Estimate[2], lambda = initial.estimates$Estimate[3],  debug.flag = 0,
                    plot.string = "initial")

plot(x,y,axes=FALSE,type="l",col="blue",main = "local fdr",                                                            
     xlab="importances",ylab="")                                                                                       
axis(2, pretty( c(0,max(y)+0.5*max(y)),10))                                                                            
                                                                                                                       
oldpar &lt;- par(new = TRUE)
plot(x, aa, type="l",col="green",main = "",xlab="",ylab="",axes=FALSE)                                                 
abline(h = 0.2)                                                                                                        
axis(4, pretty( aa,10))                                                                                                
                                                                                                                       
axis(1,pretty(x,10))                                                                                                   
box() #- to make it look "as usual                                                                                     
legend("topright",c("density importances","local fdr"),col=c("blue","green"),lty=1)
par(oldpar)

</code></pre>

<hr>
<h2 id='my_PIMP'>my_PIMP
based on the PIMP function from the vita package. ‘PIMP’ implements the test approach of Altmann et al. (2010) for
the permutation variable importance measure ‘VarImp’ returned by the randomForest package (Liaw and Wiener (2002)) for
classification and regression.</h2><span id='topic+my_PIMP'></span>

<h3>Description</h3>

<p>my_PIMP applies the same method as PIMP but to the MDI (mean decrease in impurity)  variable importance
(mean decrease in Gini index for classification and  mean decrease in MSE for regression).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>my_PIMP(X, y, rForest, S = 100, parallel = FALSE, ncores = 0, seed = 123, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="my_PIMP_+3A_x">X</code></td>
<td>
<p>data matrix of size n by p</p>
</td></tr>
<tr><td><code id="my_PIMP_+3A_y">y</code></td>
<td>
<p>class labels for classification (factor) or real values for regression. Of length n</p>
</td></tr>
<tr><td><code id="my_PIMP_+3A_rforest">rForest</code></td>
<td>
<p>an object of class randomForest, importance must be set to &quot;impurity&quot;.</p>
</td></tr>
<tr><td><code id="my_PIMP_+3A_s">S</code></td>
<td>
<p>The number of permutations for the response vector ‘y’. Default is ‘S=100</p>
</td></tr>
<tr><td><code id="my_PIMP_+3A_parallel">parallel</code></td>
<td>
<p>Should the PIMP-algorithm run parallel?  Default is
<code>parallel=FALSE</code> and the number of cores is set to one. The
parallelized version of the PIMP-algorithm are based on
mclapply and so is not available on Windows</p>
</td></tr>
<tr><td><code id="my_PIMP_+3A_ncores">ncores</code></td>
<td>
<p>The number of cores to use, i.e. at most how many child
processes will be run simultaneously. Must be at least one,
and parallelization requires at least two cores.  If
‘ncores=0’, then the half of CPU cores on the current host
are used.</p>
</td></tr>
<tr><td><code id="my_PIMP_+3A_seed">seed</code></td>
<td>
<p>a single integer value to specify seeds. The &quot;combined
multiple-recursive generator&quot; from L'Ecuyer (1999) is set as
random number generator for the parallelized version of the
PIMP-algorithm.  Default is ‘ seed = 123’.</p>
</td></tr>
<tr><td><code id="my_PIMP_+3A_...">...</code></td>
<td>
<p>additional arguments passed to randomForest</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class PIMP
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(RFlocalfdr.data)
library(ranger)
library(vita) #vita: Variable Importance Testing Approaches
data(smoking)
?smoking 
y&lt;-smoking$y
y&lt;-factor(y)
smoking_data&lt;-smoking$rma

cl.ranger &lt;- ranger::ranger(y=y, x=smoking_data,mtry = 3,num.trees = 1000, importance = 'impurity')
system.time(pimp.varImp.cl&lt;-my_ranger_PIMP(smoking_data,y,cl.ranger,S=10, parallel=TRUE, ncores=2))
#CRAN limits the number of cores available to packages to 2, for performance reasons.
pimp.t.cl &lt;- vita::PimpTest(pimp.varImp.cl,para = FALSE)
aa &lt;- summary(pimp.t.cl,pless = 0.05)
length(which(aa$cmat2[,"p-value"]&lt; 0.05))
hist(aa$cmat2[,"p-value"],breaks=20)

</code></pre>

<hr>
<h2 id='my_ranger_PIMP'>my_ranger_PIMP
based on the PIMP function from the vita package. ‘PIMP’ implements the test approach of Altmann et al. (2010) for
the permutation variable importance measure ‘VarImp’ returned by the randomForest package (Liaw and Wiener (2002)) for
classification and regression.</h2><span id='topic+my_ranger_PIMP'></span>

<h3>Description</h3>

<p>my_PIMP applies the same method as PIMP but to the MDI (mean decrease in impurity)  variable importance
(mean decrease in Gini index for classification and  mean decrease in MSE for regression).
my_ranger_PIMP applies the same method to the ranger RF package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>my_ranger_PIMP(
  X,
  y,
  rForest,
  S = 100,
  parallel = FALSE,
  ncores = 0,
  seed = 123,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="my_ranger_PIMP_+3A_x">X</code></td>
<td>
<p>data matrix of size n by p</p>
</td></tr>
<tr><td><code id="my_ranger_PIMP_+3A_y">y</code></td>
<td>
<p>class labels for classification (factor) or real values for regression. Of length n</p>
</td></tr>
<tr><td><code id="my_ranger_PIMP_+3A_rforest">rForest</code></td>
<td>
<p>an object of class ranger, importance must be set to &quot;impurity&quot;.</p>
</td></tr>
<tr><td><code id="my_ranger_PIMP_+3A_s">S</code></td>
<td>
<p>The number of permutations for the response vector ‘y’. Default is ‘S=100</p>
</td></tr>
<tr><td><code id="my_ranger_PIMP_+3A_parallel">parallel</code></td>
<td>
<p>Should the PIMP-algorithm run parallel?  Default is
‘parallel=FALSE’ and the number of cores is set to one. The
parallelized version of the PIMP-algorithm are based on
mclapply and so is not available on Windows</p>
</td></tr>
<tr><td><code id="my_ranger_PIMP_+3A_ncores">ncores</code></td>
<td>
<p>The number of cores to use, i.e. at most how many child
processes will be run simultaneously. Must be at least one,
and parallelization requires at least two cores.  If
‘ncores=0’, then the half of CPU cores on the current host
are used.</p>
</td></tr>
<tr><td><code id="my_ranger_PIMP_+3A_seed">seed</code></td>
<td>
<p>a single integer value to specify seeds. The &quot;combined
multiple-recursive generator&quot; from L'Ecuyer (1999) is set as
random number generator for the parallelized version of the
PIMP-algorithm.  Default is ‘ seed = 123’.</p>
</td></tr>
<tr><td><code id="my_ranger_PIMP_+3A_...">...</code></td>
<td>
<p>additional arguments passed to ranger</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class PIMP
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
library(RFlocalfdr.data)
library(ranger)
library(vita) #vita: Variable Importance Testing Approaches
data(smoking)
?smoking 
y&lt;-smoking$y
y&lt;-factor(y)
smoking_data&lt;-smoking$rma

cl.ranger &lt;- ranger::ranger(y=y, x=smoking_data,mtry = 3,num.trees = 1000, importance = 'impurity')
system.time(pimp.varImp.cl&lt;-my_ranger_PIMP(smoking_data,y,cl.ranger,S=10, parallel=TRUE, ncores=2))
#CRAN limits the number of cores available to packages to 2, for performance reasons.
pimp.t.cl &lt;- vita::PimpTest(pimp.varImp.cl,para = FALSE)
aa &lt;- summary(pimp.t.cl,pless = 0.05)
length(which(aa$cmat2[,"p-value"]&lt; 0.05))
hist(aa$cmat2[,"p-value"],breaks=20)

</code></pre>

<hr>
<h2 id='my.dsn'>my.dsn</h2><span id='topic+my.dsn'></span><span id='topic+dsn'></span><span id='topic+psn'></span><span id='topic+qsn'></span>

<h3>Description</h3>

<p>density of skew-normal using the appromimation of Ashour, Samir K. and Abdel-hameed, Mahmood A.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>my.dsn(x, xi = 0, omega = 1, lambda = 1)

dsn(x, xi = 0, omega = 1, alpha = 0, tau = 0)

psn(q, xi = -Inf, omega = 1, alpha = 0, tau = 0, ...)

qsn(p, xi = Inf, omega = 1, alpha = 0, tau = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="my.dsn_+3A_x">x</code></td>
<td>
<p>vector of quantiles. Missing values (‘NA’'s) and ‘Inf’'s are   allowed.</p>
</td></tr>
<tr><td><code id="my.dsn_+3A_xi">xi</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
<tr><td><code id="my.dsn_+3A_omega">omega</code></td>
<td>
<p>vector of scale parameters; must be positive</p>
</td></tr>
<tr><td><code id="my.dsn_+3A_lambda">lambda</code></td>
<td>
<p>param</p>
</td></tr>
<tr><td><code id="my.dsn_+3A_alpha">alpha</code></td>
<td>
<p>vector of slant parameter(s)</p>
</td></tr>
<tr><td><code id="my.dsn_+3A_tau">tau</code></td>
<td>
<p>= 0</p>
</td></tr>
<tr><td><code id="my.dsn_+3A_q">q</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="my.dsn_+3A_...">...</code></td>
<td>
<p>arguments passed to sn</p>
</td></tr>
<tr><td><code id="my.dsn_+3A_p">p</code></td>
<td>
<p>vector of probabilities. Missing values (‘NA’'s) are allowed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://en.wikipedia.org/wiki/Skew_normal_distribution">https://en.wikipedia.org/wiki/Skew_normal_distribution</a> for discussion of the skew-normal.
Using the appromimation of Ashour, Samir K. and Abdel-hameed, Mahmood A.
&quot;Approximate Skew Normal Distribution&quot;, Journal of Advanced Research, 2010, 1:4.
It accepts the parameters xi, omega, lambda (Ashour et. al. 2010). Other foumulations may use
different parameterizations. The sn (skew-normal) package incluse the extended skew-normal (ESN) distribution. For the SN the
tau parameter is 0.
</p>
<p>RFlocalfdr also uses wrappers around the functions dsn, qsn and psn from the package &quot;sn&quot;
https://cran.r-project.org/web/packages/sn/.
This is due to the fact that
fitdistrplus::fitdist(imp, &quot;sn&quot;, start = list(xi = mean(imp)...
returns warnings such as
The dsn function should return a zero-length vector when input has length zero and not raise an error
The psn function should have its first argument named: q as in base R
These wrappers ensure conformity with the expectations of fitdistrplus::fitdist
</p>


<h3>Value</h3>

<p>fits the Density function for the skew-normal (SN) distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sn)
curve(sn::dsn(x,xi=0, omega=1, alpha=1, tau=0),xlim=c(-10,10),col="blue")
curve(sn::dsn(x,xi=0, omega=1, alpha=0.1, tau=0),xlim=c(-10,10),col="blue",add=TRUE)
curve(sn::dsn(x,xi=1, omega=2, alpha=2, tau=0),xlim=c(-10,20),col="blue",add=TRUE)
curve(sn::dsn(x,xi=3, omega=4, alpha=4, tau=0),xlim=c(-10,20),col="blue",add=TRUE)

curve(my.dsn(x),xlim=c(-10,10),col="red",add=TRUE)
curve(my.dsn(x,lambda=0.1),xlim=c(-10,10),col="red",add=TRUE)
curve(my.dsn(x,xi=1, omega=2, lambda=2),xlim=c(-10,20),col="red",add=TRUE)
curve(my.dsn(x,xi=3, omega=4, lambda=4),xlim=c(-10,20),col="red",add=TRUE)

#dsn, qsn and psn are wrappers around the provided functions provided by sn. This is done to
# overcome some checking done by fitdistrplus

library(sn)
getAnywhere("dsn")
RFlocalfdr::my.test1fun("sn::dsn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))
RFlocalfdr::my.test1fun("sn::psn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))
RFlocalfdr::my.test1fun("sn::qsn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))
#all return FALSE

detach("package:sn", unload=TRUE)
getAnywhere("dsn")
RFlocalfdr::my.test1fun("dsn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))#TRUE
RFlocalfdr::my.test1fun("psn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))#TRUE
RFlocalfdr::my.test1fun("qsn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))#TRUE

</code></pre>

<hr>
<h2 id='my.test1fun'>my.test1fun</h2><span id='topic+my.test1fun'></span>

<h3>Description</h3>

<p>tests the compliance of skew-normal distribution functions with the expectations
of the package fitdistrplus
</p>


<h3>Usage</h3>

<pre><code class='language-R'>my.test1fun(fn, start.arg, fix.arg, dpqr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="my.test1fun_+3A_fn">fn</code></td>
<td>

<ul>
<li><p> name of the function to be tested &quot;dsn&quot;, &quot;psn&quot; or &quot;qsn&quot;
</p>
</li></ul>
</td></tr>
<tr><td><code id="my.test1fun_+3A_start.arg">start.arg</code></td>
<td>

<ul>
<li><p> the starting arguments for fitting the density
</p>
</li></ul>
</td></tr>
<tr><td><code id="my.test1fun_+3A_fix.arg">fix.arg</code></td>
<td>

<ul>
<li><p> fixed arguments
</p>
</li></ul>
</td></tr>
<tr><td><code id="my.test1fun_+3A_dpqr">dpqr</code></td>
<td>
<p>&ndash; are we testing the &quot;d&quot;, &quot;p&quot; or &quot;q&quot; function? not needed as it can be inferred from the argument &quot;fn&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RFlocalfdr also uses wrappers around the funcions dsn, qsn and psn from the package &quot;sn&quot;
https://cran.r-project.org/web/packages/sn/.
This is due to the fact that
fitdistrplus::fitdist(imp, &quot;sn&quot;, start = list(xi = mean(imp)...
returns warnings such as
The dsn function should return a zero-length vector when input has length zero and not raise an error
The psn function should have its first argument named: q as in base R
These wrappers ensure conformity with the expectations of fitdistrplus::fitdist
</p>


<h3>Value</h3>

<p>fits the Density function for the skew-normal (SN) distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sn)
curve(sn::dsn(x,xi=0, omega=1, alpha=1, tau=0),xlim=c(-10,10),col="blue")
curve(sn::dsn(x,xi=0, omega=1, alpha=0.1, tau=0),xlim=c(-10,10),col="blue",add=TRUE)
curve(sn::dsn(x,xi=1, omega=2, alpha=2, tau=0),xlim=c(-10,20),col="blue",add=TRUE)
curve(sn::dsn(x,xi=3, omega=4, alpha=4, tau=0),xlim=c(-10,20),col="blue",add=TRUE)

curve(my.dsn(x),xlim=c(-10,10),col="red",add=TRUE)
curve(my.dsn(x,lambda=0.1),xlim=c(-10,10),col="red",add=TRUE)
curve(my.dsn(x,xi=1, omega=2, lambda=2),xlim=c(-10,20),col="red",add=TRUE)
curve(my.dsn(x,xi=3, omega=4, lambda=4),xlim=c(-10,20),col="red",add=TRUE)

#dsn, qsn and psn are wrappers around the provided functions provided by sn. This is done to
# overcome some checking done by fitdistrplus

library(sn)
getAnywhere("dsn")
RFlocalfdr::my.test1fun("sn::dsn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))
RFlocalfdr::my.test1fun("sn::psn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))
RFlocalfdr::my.test1fun("sn::qsn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))
#all return FALSE

detach("package:sn", unload=TRUE)
getAnywhere("dsn")
RFlocalfdr::my.test1fun("dsn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))#TRUE
RFlocalfdr::my.test1fun("psn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))#TRUE
RFlocalfdr::my.test1fun("qsn", list(xi = -Inf, omega =1, alpha=0 ), fix.arg = list(tau = 0))#TRUE

</code></pre>

<hr>
<h2 id='plotQ'>plotQ</h2><span id='topic+plotQ'></span>

<h3>Description</h3>

<p>produces a plot showing the q values
</p>

<ul>
<li><p> q_95, the 95th quantile of the data
</p>
</li>
<li><p> q using the penalized selection method of Gauran et.al 2018
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>plotQ(imp, debug.flag = 0, temp.dir = NULL, try.counter = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotQ_+3A_imp">imp</code></td>
<td>
<p>&quot;reduction in impurity&quot; importances from a random forest model</p>
</td></tr>
<tr><td><code id="plotQ_+3A_debug.flag">debug.flag</code></td>
<td>
<p>either 0 (no debugging information), 1 or 2</p>
</td></tr>
<tr><td><code id="plotQ_+3A_temp.dir">temp.dir</code></td>
<td>
<p>if debug flag is &gt;0 then information is written to temp.dir</p>
</td></tr>
<tr><td><code id="plotQ_+3A_try.counter">try.counter</code></td>
<td>
<p>where to explain this?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We estiamte a value &quot;q&quot; such that:
to the left of &quot;q&quot;, the density is composed solely of NULL importance values
to the right of &quot;q&quot; we have  a density that is a mixture of null and non-null  importance values.
The method of Gauran et.al 2018 may not work in cases where the data distribution is not well modelled by a skew-normal.
The q_95 value can be uses as a workaround in these case.
In many cases they will be very similar
</p>


<h3>Value</h3>


<ul>
<li><p> df, contains x and y, midpoints and counts from a histogram of imp
</p>
</li>
<li><p> final.estimates_C_0.95, the output from the fitting routine nlsLM in minpack.lm, where df has been truncated
at the value C_0.95 (the 0.95 quantile of the skew-Normal distribution fitted to the imp histogram
</p>
</li>
<li><p> final.estimates_cc, as for final.estimates_C_0.95 but with cc determined by the procedure of Gauran et.al 2018
</p>
</li>
<li><p> temp.dir,  the directory where debugging information may be written
</p>
</li>
<li><p> C_0.95, the 0.95 quantile of the skew-Normal distribution fitted to the imp histogram
</p>
</li>
<li><p> cc,  determined by the procedure of Gauran et.al 2018
</p>
</li>
<li><p> fileConn, a file connectin for writing debugging information
</p>
</li>
<li><p> f_fit, a spline fit to the histogram
</p>
</li>
<li><p> ww the minimum value of the local fdr
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)
imp &lt;- log(imp20000$importances)
t2 &lt;- imp20000$counts
plot(density((imp)))
hist(imp,col=6,lwd=2,breaks=100,main="histogram of importances")
res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(0,1,2,3),plot=c(0,1,2,3),Q=0.75,try.counter=1)
plot(c(0,1,2,3),res.temp[,3])
imp&lt;-imp[t2 &gt; 1]
qq &lt;- plotQ(imp,debug.flag = 0)                                                          
ppp&lt;-run.it.importances(qq,imp,debug=0)                                                       
aa&lt;-significant.genes(ppp,imp,cutoff=0.2,debug.flag=0,do.plot=2, use_95_q=TRUE)                           
length(aa$probabilities) #11#                                                          
names(aa$probabilities)


library(RFlocalfdr.data)
data(ch22)                                                                                 
?ch22                                                                                     
#document how the data set is created                                                      
plot(density(log(ch22$imp)))                                                               
t2 &lt;-ch22$C                                                                                
imp&lt;-log(ch22$imp)                                                                         
#Detemine a cutoff to get a unimodal density.
# This was calculated previously. See determine_cutoff
imp&lt;-imp[t2 &gt; 30]
qq &lt;- plotQ(imp,debug.flag = 0)

data(smoking)
?smoking 
y&lt;-smoking$y
smoking_data&lt;-smoking$rma
y.numeric &lt;-ifelse((y=="never-smoked"),0,1)

library(ranger)
rf1 &lt;-ranger::ranger(y=y.numeric ,x=smoking_data,importance="impurity",seed=123, num.trees = 10000,
             classification=TRUE)
t2 &lt;-count_variables(rf1)
imp&lt;-log(rf1$variable.importance)
plot(density(imp),xlab="log importances",main="")
cutoffs &lt;- c(2,3,4,5)
res.con&lt;- determine_cutoff(imp,t2,cutoff=cutoffs,plot=c(2,3,4,5))

plot(cutoffs,res.con[,3],pch=15,col="red",cex=1.5,ylab="max(abs(y - t1))")
cutoffs[which.min(res.con[,3])]

temp&lt;-imp[t2 &gt; 3]
temp &lt;- temp - min(temp) + .Machine$double.eps
qq &lt;- plotQ(temp)
ppp&lt;-run.it.importances(qq,temp,debug.flag = 0)
aa&lt;-significant.genes(ppp,temp,cutoff=0.05,debug.flag=0,do.plot=TRUE,use_95_q=TRUE)
length(aa$probabilities) # 17

</code></pre>

<hr>
<h2 id='propTrueNullByLocalFDR'>propTrueNullByLocalFDR</h2><span id='topic+propTrueNullByLocalFDR'></span>

<h3>Description</h3>

<p>Estimate proportion of NULL p-values. Based on  .propTrueNullByLocalFDR in  limma: Linear Models for Microarray Data
written by Belinda Phipson and Gordon Smyth
</p>


<h3>Usage</h3>

<pre><code class='language-R'>propTrueNullByLocalFDR(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="propTrueNullByLocalFDR_+3A_p">p</code></td>
<td>
<p>probabilities</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An estimate of the proportion of null p-values by the local fdr
</p>

<hr>
<h2 id='run.it.importances'>run.it.importances</h2><span id='topic+run.it.importances'></span>

<h3>Description</h3>

<p>run.it.importances
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run.it.importances(qq, imp, debug.flag = 0, temp.dir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="run.it.importances_+3A_qq">qq</code></td>
<td>
<p>object retuned by plotQ</p>
</td></tr>
<tr><td><code id="run.it.importances_+3A_imp">imp</code></td>
<td>
<p>&quot;reduction in impurity&quot; importances from a random forest model</p>
</td></tr>
<tr><td><code id="run.it.importances_+3A_debug.flag">debug.flag</code></td>
<td>
<p>either 0 (no debugging information), 1 or 2</p>
</td></tr>
<tr><td><code id="run.it.importances_+3A_temp.dir">temp.dir</code></td>
<td>
<p>if debug flag is &gt;0 then information is written to temp.dir</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return a list contining
</p>

<ul>
<li><p> &quot;C_0.95&quot; estimate of the cutoff &quot;C&quot; such that there are only null values to the left of C.
Based on the 95th quantile of the density
</p>
</li>
<li><p> &quot;cc&quot;    estimate of the cutoff &quot;C&quot; based on the procedure of Gauran, et al., 2918, Biometrics,
</p>
</li>
<li><p> &quot;estimates_C_0.95&quot; estimate of the parameters of the SN using the data up to the C estimate
</p>
</li>
<li><p> &quot;estimates_cc&quot;     estimate of the parameters of the SN using the data up to the C estimate
</p>
</li>
<li><p> &quot;fdr_0.95&quot;       estimate of the fdr curve using the SN from &quot;estimates_C_0.95&quot;
</p>
</li>
<li><p> &quot;fdr_cc&quot;         estimate of the fdr curve using the SN from &quot;estimates_cc&quot;
</p>
</li>
<li><p> &quot;x&quot;        the x values from plotQ
</p>
</li>
<li><p> &quot;temp.dir&quot; the temp directory for dubuggin
</p>
</li>
<li><p> &quot;p0&quot;     the estmate of the proportion of null values (can be 1)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)
imp &lt;- log(imp20000$importances)
t2 &lt;- imp20000$counts
plot(density((imp)))
hist(imp,col=6,lwd=2,breaks=100,main="histogram of importances")
res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(0,1,2,3),plot=c(0,1,2,3),Q=0.75,try.counter=1)
plot(c(0,1,2,3),res.temp[,3])
imp&lt;-imp[t2 &gt; 1]
qq &lt;- plotQ(imp,debug.flag = 0)                                                          
ppp&lt;-run.it.importances(qq,imp,debug=0)                                                       
aa&lt;-significant.genes(ppp,imp,cutoff=0.2,debug.flag=0,do.plot=2, use_95_q=TRUE)                           
length(aa$probabilities) #11#                                                          
names(aa$probabilities)


library(RFlocalfdr.data)
data(ch22)                                                                                 
? ch22                                                                                     
#document how the data set is created                                                      
plot(density(log(ch22$imp)))                                                               
t2 &lt;-ch22$C                                                                                
imp&lt;-log(ch22$imp)                                                                         
#Detemine a cutoff to get a unimodal density.                                              
res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(1,10,20,30),plot=c(1,10,20,30),Q=0.75)      
plot(c(1,2,3,4),res.temp[,3])                                                              
                                                                                           
res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(25,30,35,40),plot=c(25,30,35,40),Q=0.75)    
plot(c(25,30,35,40),res.temp[,3])                                                          
imp&lt;-imp[t2 &gt; 30]
qq &lt;- plotQ(imp,debug.flag = 0)                                                          
ppp&lt;-run.it.importances(qq,imp,debug=0)                                                       
aa&lt;-significant.genes(ppp,imp,cutoff=0.2,debug.flag=0,do.plot=2)                           
length(aa$probabilities) # 6650                                                            
aa&lt;-significant.genes(ppp,imp,cutoff=0.05,debug.flag=0,do.plot=2)                          
length(aa$probabilities) # 3653

</code></pre>

<hr>
<h2 id='significant.genes'>significant.genes</h2><span id='topic+significant.genes'></span>

<h3>Description</h3>

<p>This function sepects the significant &quot;genes&quot; and makes some plots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>significant.genes(
  object,
  imp,
  cutoff = 0.2,
  use_95_q = TRUE,
  do.plot = TRUE,
  debug.flag = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="significant.genes_+3A_object">object</code></td>
<td>
<p>object retruned by run.it.importance</p>
</td></tr>
<tr><td><code id="significant.genes_+3A_imp">imp</code></td>
<td>
<p>importances</p>
</td></tr>
<tr><td><code id="significant.genes_+3A_cutoff">cutoff</code></td>
<td>
<p>cutoff</p>
</td></tr>
<tr><td><code id="significant.genes_+3A_use_95_q">use_95_q</code></td>
<td>
<p>use the 0.95 q value</p>
</td></tr>
<tr><td><code id="significant.genes_+3A_do.plot">do.plot</code></td>
<td>
<p>do.plot either TRUE or FALSE (no plot)</p>
</td></tr>
<tr><td><code id="significant.genes_+3A_debug.flag">debug.flag</code></td>
<td>
<p>debug.flag  either 0 (no debugging information), 1 or 2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containg
</p>

<ul>
<li><p> probabilities (from the fitted SN distribution) and names of the significant variables
</p>
</li>
<li><p> the estimated FDR
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(imp20000)
imp &lt;- log(imp20000$importances)
t2  &lt;- imp20000$counts
plot(density((imp)))
hist(imp,col=6,lwd=2,breaks=100,main="histogram of importances")
res.temp &lt;- determine_cutoff(imp, t2 ,cutoff=c(0,1,2,3),plot=c(0,1,2,3),Q=0.75,try.counter=1)
plot(c(0,1,2,3),res.temp[,3])
imp&lt;-imp[t2 &gt; 1]
qq &lt;- plotQ(imp,debug.flag = 0)                                                          
ppp&lt;-run.it.importances(qq,imp,debug=0)                                                       
aa&lt;-significant.genes(ppp,imp,cutoff=0.2,debug.flag=0,do.plot=2, use_95_q=TRUE)                           
length(aa$probabilities) #11#                                                          
names(aa$probabilities)


library(RFlocalfdr.data)
data(ch22)                                                                                 
? ch22                                                                                     
plot(density(log(ch22$imp)))                                                               
t2 &lt;-ch22$C                                                                                
imp&lt;-log(ch22$imp)                                                                         
# Detemine a cutoff to get a unimodal density.                                              
# This may take several attempts. The default values of cutoff=c(0,1,4,10,15,20) will not find
# the minimum here.
#which occurs at 30
plot(c(25,30,35,40),res.temp[,3])                                                          
imp&lt;-imp[t2 &gt; 30]
qq &lt;- plotQ(imp,debug.flag = 0)
ppp&lt;-run.it.importances(qq,imp,debug=0)                                                       
aa&lt;-significant.genes(ppp,imp,cutoff=0.2,debug.flag=0,do.plot=2)                           
length(aa$probabilities) # 6650                                                            
aa&lt;-significant.genes(ppp,imp,cutoff=0.05,debug.flag=0,do.plot=2)                          
length(aa$probabilities) # 3653

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
