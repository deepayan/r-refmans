<!DOCTYPE html><html><head><title>Help for package sm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aircraft'><p>These data record six characteristics of aircraft designs which appeared during the twentieth century</p></a></li>
<li><a href='#airpc'><p>These data list the first two principal component scores from the</p>
aircraft data, which record six characteristics of aircraft designs
throughout the twentieth century</a></li>
<li><a href='#binning'>
<p>Construct frequency table from raw data in 1, 2 or 3 dimensions.</p></a></li>
<li><a href='#birth'><p>Low birthweight in babies</p></a></li>
<li><a href='#bissell'><p>Flaws in cloth</p></a></li>
<li><a href='#bonions'><p>Yield-density relationship for Brown Imperial Spanish onions</p></a></li>
<li><a href='#britpts'><p>Coastline of the UK and Ireland</p></a></li>
<li><a href='#citrate'><p>The relationship between plasma citrate and carbohydrate metabolites</p></a></li>
<li><a href='#coalash'><p>Coal ash in mining samples</p></a></li>
<li><a href='#dogs'><p>Coronary sinus potassium in dogs</p></a></li>
<li><a href='#follicle'><p>Ovarian follicle counts</p></a></li>
<li><a href='#geys3d'><p>Duration and the time between eruptions for the Old Faithful Geyser</p></a></li>
<li><a href='#geyser'><p>Old Faithful Geyser Data</p></a></li>
<li><a href='#h.select'>
<p>Selection of the smoothing parameter</p></a></li>
<li><a href='#hcv'>
<p>Cross-validatory choice of smoothing parameter</p></a></li>
<li><a href='#hnorm'>
<p>Normal optimal choice of smoothing parameter in density estimation</p></a></li>
<li><a href='#hsj'>
<p>Sheather-Jones choice of smoothing parameter for density estimation</p></a></li>
<li><a href='#lcancer'><p>Spatial positions of cases of laryngeal cancer</p></a></li>
<li><a href='#mackerel'><p>The abundance of mackerel eggs</p></a></li>
<li><a href='#magrem'><p>Magnetic remanence</p></a></li>
<li><a href='#mildew'><p>Mildew control</p></a></li>
<li><a href='#mosses'><p>Heavy metals in mosses in Galicia.</p></a></li>
<li><a href='#muscle'><p>Rat skeletal muscles</p></a></li>
<li><a href='#nile'><p>Water level of the River Nile</p></a></li>
<li><a href='#nise'><p>Integrated squared error between a density estimate and a Normal density</p></a></li>
<li><a href='#nmise'>
<p>mean integrated squared error for density estimation with normal data</p></a></li>
<li><a href='#nnbr'>
<p>nearest neighbour distances from data in one or two dimensions</p></a></li>
<li><a href='#pause'>
<p>Pause before continuing execution</p></a></li>
<li><a href='#poles'><p>Positions of the south pole</p></a></li>
<li><a href='#provide.data'>
<p>Making data available as data.frame</p></a></li>
<li><a href='#radioc'><p>Radiocarbon in Irish oak</p></a></li>
<li><a href='#sig.trace'>
<p>A significance trace for a hypothesis test</p></a></li>
<li><a href='#sm'>
<p>The sm package: summary information</p></a></li>
<li><a href='#sm-internal'><p>Internal sm functions</p></a></li>
<li><a href='#sm.ancova'>
<p>Nonparametric analysis of covariance</p></a></li>
<li><a href='#sm.autoregression'>
<p>Nonparametric estimation of the autoregression function</p></a></li>
<li><a href='#sm.binomial'>
<p>Nonparametric logistic regression</p></a></li>
<li><a href='#sm.binomial.bootstrap'>
<p>Bootstrap goodness-of-fit test for a logistic regression model.</p></a></li>
<li><a href='#sm.density'>
<p>Nonparametric density estimation in one, two or three dimensions.</p></a></li>
<li><a href='#sm.density.compare'>
<p>Comparison of univariate density estimates</p></a></li>
<li><a href='#sm.discontinuity'><p>The detection of discontinuities in a regression curve or surface.</p></a></li>
<li><a href='#sm.monotonicity'>
<p>A test of monotonicity in a regression curve.</p></a></li>
<li><a href='#sm.options'><p>Set or return options of sm library</p></a></li>
<li><a href='#sm.pca'>
<p>Smooth principal components analysis</p></a></li>
<li><a href='#sm.poisson'>
<p>Nonparametric Poisson regression</p></a></li>
<li><a href='#sm.poisson.bootstrap'>
<p>Bootstrap goodness-of-fit test for a Poisson regression model</p></a></li>
<li><a href='#sm.regression'><p>Nonparametric regression with one or two covariates.</p></a></li>
<li><a href='#sm.regression.autocor'>
<p>Nonparametric regression with autocorrelated errors</p></a></li>
<li><a href='#sm.rm'>
<p>Nonparametric analysis of repeated measurements data</p></a></li>
<li><a href='#sm.script'>
<p>Running a script associated to the sm library</p></a></li>
<li><a href='#sm.sigma'><p>Estimation of the error standard deviation in nonparametric regression.</p></a></li>
<li><a href='#sm.sigma2.compare'><p>Comparison across two groups of the error standard deviation in</p>
nonparametric regression with two covariates.</a></li>
<li><a href='#sm.sphere'>
<p>Nonparametric density estimation for spherical data.</p></a></li>
<li><a href='#sm.surface3d'>
<p>Adding a regression surface to an rgl plot.</p></a></li>
<li><a href='#sm.survival'>
<p>Nonparametric regression with survival data.</p></a></li>
<li><a href='#sm.ts.pdf'>
<p>Nonparametric density estimation of stationary time series data</p></a></li>
<li><a href='#sm.variogram'>
<p>Confidence intervals and tests based on smoothing an empirical variogram.</p></a></li>
<li><a href='#smacker'><p>Mackerel data from a Spanish survey</p></a></li>
<li><a href='#stanford'><p>Survival times from the Stanford Heart Transplant Study</p></a></li>
<li><a href='#tephra'><p>Tephra layer</p></a></li>
<li><a href='#trawl'><p>Trawl data from the Great Barrier Reef</p></a></li>
<li><a href='#trout'><p>Potassium cyanate and trout eggs</p></a></li>
<li><a href='#wonions'><p>Yield-density relationship for White Imperial Spanish onion plants</p></a></li>
<li><a href='#worm'><p>Human parasitic worm infections</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Smoothing Methods for Nonparametric Regression and Density
Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2-6.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Adrian Bowman and Adelchi Azzalini. 
         Ported to R by B. D. Ripley &lt;ripley@stats.ox.ac.uk&gt; up to version 2.0,
	      version 2.1 by Adrian Bowman and Adelchi Azzalini,
	      version 2.2 by Adrian Bowman.	 	 </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adrian Bowman &lt;adrian.bowman@glasgow.ac.uk&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rgl, misc3d, interp, gam, tkrplot, rpanel (&ge; 1.1-4), tcltk</td>
</tr>
<tr>
<td>Description:</td>
<td>This is software linked to the book
  'Applied Smoothing Techniques for Data Analysis -
  The Kernel Approach with S-Plus Illustrations' Oxford University Press.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-17 15:23:19 UTC; adrianbowman</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-17 17:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aircraft'>These data record six characteristics of aircraft designs which appeared during the twentieth century</h2><span id='topic+aircraft'></span>

<h3>Description</h3>

<p>These data record six characteristics of aircraft designs which appeared
during the twentieth century.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Yr</code>     </td><td style="text-align: left;"> year of first manufacture </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Period</code> </td><td style="text-align: left;"> a code to indicate one of three broad time periods </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Power</code>  </td><td style="text-align: left;"> total engine power (kW) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Span</code>   </td><td style="text-align: left;"> wing span (m) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Length</code> </td><td style="text-align: left;"> length (m) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Weight</code> </td><td style="text-align: left;"> maximum take-off weight (kg) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Speed</code>  </td><td style="text-align: left;"> maximum speed (km/h) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Range</code>  </td><td style="text-align: left;"> range (km)
</td>
</tr>

</table>

<p>Source: The data were collected by P. Saviotti and are described in detail
in Saviotti (1996), &quot;Technological Evolution, Variety and Economy&quot;,
Edward Elgar: Cheltenham.
</p>

<hr>
<h2 id='airpc'>These data list the first two principal component scores from the
aircraft data, which record six characteristics of aircraft designs 
throughout the twentieth century</h2><span id='topic+airpc'></span>

<h3>Description</h3>

<p>These data list the first two principal component scores from the
aircraft data, which record six characteristics of aircraft designs 
throughout the twentieth century.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Comp.1:</code> </td><td style="text-align: left;">  first principal component score </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Comp.2:</code> </td><td style="text-align: left;">  second principal component score </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Yr:</code>     </td><td style="text-align: left;">  year of first manufacture </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Period:</code> </td><td style="text-align: left;">  a code to indicate one of three broad time periods
</td>
</tr>

</table>

<p>The data were collected by P. Saviotti and are described in detail
in Saviotti (1996), &quot;Technological Evolution, Variety and Economy&quot;,
Edward Elgar: Cheltenham.
</p>

<hr>
<h2 id='binning'>
Construct frequency table from raw data in 1, 2 or 3 dimensions.
</h2><span id='topic+binning'></span>

<h3>Description</h3>

<p>Given a vector, or a matrix with 1, 2 or 3 columns, this function constructs a frequency table
associated with appropriate intervals covering the range of <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binning(x, y, breaks, nbins)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binning_+3A_x">x</code></td>
<td>

<p>a vector or a matrix with either one, two or three columns, containing the original data. 
</p>
</td></tr>
<tr><td><code id="binning_+3A_y">y</code></td>
<td>

<p>a vector of data, for example response data, associated with the data in <code>x</code>.
</p>
</td></tr>
<tr><td><code id="binning_+3A_breaks">breaks</code></td>
<td>

<p>either a vector or a matrix with two columns (depending on the dimension of <code>x</code>),
assigning the division points of the axis, or the axes in the matrix case.
It must not include <code>Inf</code>,<code>-Inf</code> or <code>NA</code>s, and it must span the whole range of 
the <code>x</code> points.
If <code>breaks</code> is not given, it is computed by dividing the range of <code>x</code>
into <code>nbins</code> intervals for each of the axes.
</p>
</td></tr>
<tr><td><code id="binning_+3A_nbins">nbins</code></td>
<td>

<p>the number of intervals on each axis. If <code>nbins</code> is not supplied, a value is computed as <code>round(log(n)/log(2) + 1)</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is called automatically (under the default settings)
by some of the functions of the <code>sm</code> library when the sample size is
large, to allow handling of datasets of essentially unlimited size.
Specifically, it is used by <code>sm.density</code>, <code>sm.regression</code>, <code>sm.ancova</code>,
<code>sm.binomial</code> and <code>sm.poisson</code>.
</p>


<h3>Value</h3>

<p>In the vector case, a list is returned containing the following elements:
a vector <code>x</code> of the midpoints of the bins excluding those with 0 frequecies, 
its associated matrix <code>x.freq</code> of frequencies, the co-ordinates of the 
<code>midpoints</code>, the division points, and the complete vector of observed 
frequencies <code>freq.table</code> (including the 0 frequencies), and the vector
<code>breaks</code> of division points.
In the matrix case, the returned value is a list with the following 
elements: a two-dimensional matrix <code>x</code> with the coordinates of the
midpoints of the two-dimensional bins excluding those with 0 frequencies, 
its associated matrix <code>x.freq</code> of frequencies, the coordinates of the 
<code>midpoints</code>, the matrix <code>breaks</code> of division points, and the observed 
frequencies <code>freq.table</code> in full tabular form.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis:
the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+sm.density">sm.density</a></code>, <code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.binomial">sm.binomial</a></code>, <code><a href="#topic+sm.poisson">sm.poisson</a></code>, <code><a href="base.html#topic+cut">cut</a></code>, <code><a href="base.html#topic+table">table</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example of 1-d use
x  &lt;- rnorm(1000)
xb &lt;- binning(x)
xb &lt;- binning(x, breaks=seq(-4,4,by=0.5))
# example of 2-d use
x &lt;- rnorm(1000)
y &lt;- 2*x + 0.5*rnorm(1000)
x &lt;- cbind(x, y)
xb&lt;- binning(x, nbins=12)
</code></pre>

<hr>
<h2 id='birth'>Low birthweight in babies</h2><span id='topic+birth'></span>

<h3>Description</h3>

<p>The data refer to a study on low birthweight in babies, defined
as &quot;less than 2500 grams&quot;, and related factors.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Smoke</code> </td><td style="text-align: left;">  indicator of whether the mother is a smoker </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Lwt</code>   </td><td style="text-align: left;">  last menstrual weight of the mother</td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Low</code>   </td><td style="text-align: left;">  indicator variable of low weight
</td>
</tr>

</table>

<p>Hosmer &amp; Lemeshow (1989).  Applied  Logistic Regression. 
Wiley, NY.
The original source contains additional variables; see Appendix 1 of
Hosmer &amp; Lemeshow for a full list of the data, pp.29-30 and p.92 for 
additional information.
</p>

<hr>
<h2 id='bissell'>Flaws in cloth</h2><span id='topic+bissell'></span>

<h3>Description</h3>

<p>These data refer to the length and the observed number of flaws in
rolls of cloth.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Length</code> </td><td style="text-align: left;"> length of each roll (m) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Flaws</code>  </td><td style="text-align: left;">  number of flaws detected
</td>
</tr>

</table>

<p>Source: Bissell (1972). A negative binomial model with varying element sizes.  Biometrika 59, 435-41.
</p>

<hr>
<h2 id='bonions'>Yield-density relationship for Brown Imperial Spanish onions</h2><span id='topic+bonions'></span>

<h3>Description</h3>

<p>These data were collected in a study of the relationship between the
yield of Brown Imperial Spanish onion plants and the density of planting.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Density</code>  </td><td style="text-align: left;"> density of planting (plants/m^2) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Yield</code>    </td><td style="text-align: left;"> yield (g/plant) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Locality</code> </td><td style="text-align: left;"> a code to indicate Mount Gambier (1) or Uraidla (2)
</td>
</tr>

</table>

<p>The data were collected by I.S.Rogers (South Australian Dept. of 
Agriculture &amp; Fisheries).  They are listed in
Ratkowsky (1983), Nonlinear Regression Modeling. Dekker, New York.
</p>

<hr>
<h2 id='britpts'>Coastline of the UK and Ireland</h2><span id='topic+britpts'></span>

<h3>Description</h3>

<p>These data provide the co-ordinates of a set of points lying on the coastlines of the UK and Ireland.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>britlong</code> </td><td style="text-align: left;">  longitude </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>brotlat</code>  </td><td style="text-align: left;">  latitude
</td>
</tr>

</table>


<hr>
<h2 id='citrate'>The relationship between plasma citrate and carbohydrate metabolites</h2><span id='topic+citrate'></span>

<h3>Description</h3>

<p>These data were collected in an experiment to study the 
relationship between possible daily rhythms of plasma citrate and 
daily rhythms of carbohydrate metabolites during feeding with a 
citrate-poor diet.  During the experiment, plasma citrate 
concentrations were determined for each of 10 subjects at 14 
successive time points during the day.  The measurements covered the 
period 8a.m. to 9p.m. at hourly intervals.  Meals were given at 
8a.m., noon and 5p.m.
</p>
<p>The variables are denoted by <code>C08</code>, ..., <code>C21</code> and refer to plasma citrate measurements at the indicated hours.
</p>
<p>Anderson,A.H., Jensen,E.B. &amp; Schou,G.(1981).  Two-way analysis of variance with correlated errors.  Int.Stat.Rev. 49,153-67.
</p>
<p>The data were taken from a report by T.T.Nielsen, N.S.Sorensen and E.B.Jensen.
</p>

<hr>
<h2 id='coalash'>Coal ash in mining samples</h2><span id='topic+coalash'></span>

<h3>Description</h3>

<p>These data record the percentage of coal ash found in mining samples 
originally reported by Gomez and Hazen (1970) and subsequently used
by Cressie (1993).
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>East</code>    </td><td style="text-align: left;">  a code for east-west direction </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>North</code>   </td><td style="text-align: left;">  a code for north-south direction </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Percent</code> </td><td style="text-align: left;">  the percentage of coalash
</td>
</tr>

</table>

<p>Cressie, N. (1993). Statistics for Spatial Data, revised edition. New York: Wiley.
</p>
<p>Gomez, M. and Hazen, K. (1970). Evaluating sulfur and ash distribution in coal seams by statistical response surface regression analysis. Report RI 7377, U.S. Bureau of  Mines, Washington, D. C.
</p>

<hr>
<h2 id='dogs'>Coronary sinus potassium in dogs</h2><span id='topic+dogs'></span>

<h3>Description</h3>

<p>Measurements of coronary sinus potassium (mil equivalent per litre)
were made at (1,3,5,7,9,11,13) minutes after coronary occlusion in a 
number of different dogs.  There are four treatment groups 
(group 1 is the control).  The paper by Grizzle and Allen provides a 
full description of the treatments.  A few subjects develop ventricular 
fibrillation (see paper for details).
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Group</code>                        </td><td style="text-align: left;">  a treatment group indicator </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>P1, P3, P5, P7, P9, P11, P13</code> </td><td style="text-align: left;">  measurements at indicated times 
</td>
</tr>

</table>

<p>J.E.Grizzle &amp; D.M.Allen (1969). Analysis of growth and dose response curves.  Biometrics vol.25, p.357-381
</p>

<hr>
<h2 id='follicle'>Ovarian follicle counts</h2><span id='topic+follicle'></span>

<h3>Description</h3>

<p>These data record the number of ovarian follicles, on a log scale, counted from sectioned ovaries of women of various ages.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Age</code>    </td><td style="text-align: left;">  age of the woman </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Count</code>  </td><td style="text-align: left;">  follicle count </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Source</code> </td><td style="text-align: left;">  an indicator of the source of the data
</td>
</tr>

</table>

<p>The data were reported by Block (1952; 1953), Richardson et al. (1987) and A Gougeon.  They are analysed by Faddy &amp; Gosden (1996) and Faddy &amp; Jones (1997).
</p>

<hr>
<h2 id='geys3d'>Duration and the time between eruptions for the Old Faithful Geyser</h2><span id='topic+geys3d'></span>

<h3>Description</h3>

<p>These data document the duration of eruptions, and the time between
eruptions, for the Old Faithful Geyser in Yellowstone National Park.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Waiting</code>      </td><td style="text-align: left;">  the waiting time before each eruption (minutes) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Next.waiting</code> </td><td style="text-align: left;"> the waiting time following each eruption (minutes) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Duration</code>     </td><td style="text-align: left;">  the length of an eruption ( minutes)
</td>
</tr>

</table>

<p>The data were collected by by the Park Geologist, R.A.Hutchinson.  An earlier set of data is reported in Weisberg (1990), Applied Linear Regression, Wiley, New York.  The later set, used here, was reported by Azzalini &amp; Bowman (1990), &quot;A look at some data on the Old Faithful Geyser&quot;, Applied Statistics 39, 357-65.
</p>

<hr>
<h2 id='geyser'>Old Faithful Geyser Data</h2><span id='topic+geyser'></span>

<h3>Description</h3>

<p>A version of the eruptions data from the &ldquo;Old Faithful&rdquo; geyser in
Yellowstone National  Park,  Wyoming. This version comes from
Azzalini and Bowman (1990) and is of continuous measurement from 
1st August to 15th August 1985. 
</p>
<p>Some nocturnal duration measurements were coded as 2, 3 or 4 minutes,
having originally been described as &lsquo;short&rsquo;, &lsquo;medium&rsquo; or &lsquo;long&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(geyser)</code></pre>


<h3>Format</h3>

<p>A data frame with 299 observations on 2 variables.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>duration</code>  </td><td style="text-align: left;"> numeric  </td><td style="text-align: left;"> Eruption time, in minutes </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>waiting</code>   </td><td style="text-align: left;"> numeric  </td><td style="text-align: left;"> Waiting time before the eruption,
                                         in minutes </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>Note that in versions of the <code>sm</code> package before 2.2-5 the <code>waiting</code> variable was incorrectly described as &lsquo;waiting time to next eruption&rsquo;.
</p>


<h3>References</h3>

<p>Azzalini, A. and Bowman, A. W. (1990) A look at some
data on the Old Faithful geyser.  <em>Applied Statistics</em>
<b>39</b>, 357&ndash;365.
</p>


<h3>See Also</h3>

<p><code><a href="datasets.html#topic+faithful">faithful</a></code></p>

<hr>
<h2 id='h.select'>
Selection of the smoothing parameter
</h2><span id='topic+h.select'></span>

<h3>Description</h3>

<p>This function selects a smoothing parameter for density estimation
in one or two dimensions and for nonparametric regression with one
or two covariates.  Several methods of selection are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> h.select(x, y = NA, weights = NA, group = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h.select_+3A_x">x</code></td>
<td>

<p>a vector, or two-column matrix.
</p>
</td></tr>
<tr><td><code id="h.select_+3A_y">y</code></td>
<td>

<p>a vector of responses, in regression case.
</p>
</td></tr>
<tr><td><code id="h.select_+3A_weights">weights</code></td>
<td>

<p>a vector of integers representing frequencies of individual
observations.  Use of this parameter is incompatible with
<code>binning</code>; hence <code>nbins</code> must then be set to <code>0</code>
or left at its default value <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="h.select_+3A_group">group</code></td>
<td>

<p>a vector of groups indicators (numeric or character values) or
a factor
</p>
</td></tr>
<tr><td><code id="h.select_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function.  There are three which are relevant for this
function, namely <code>method</code>, which specifies the method of
smoothing parameter selection, <code>df</code>, which specifies the
approximate degrees of freedom associated with the selected
smoothing parameter, and <code>structure.2d</code> which determines
the form of the smoothing parameters in the two-dimensional case.
A full description of these arguments are given in the documentation
of <code><a href="#topic+sm.options">sm.options</a></code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see the two references below for discussion of the methods of
smoothing parameter selection.
</p>
<p>If the sample size is large, binning will be employed.  In the 
case of <code>method = "cv"</code> the answer will therefore be
different from that obtained through the function <code>hcv</code>
where binning is not used.
</p>
<p>When the <code>group</code> argument is set, the chosen method of
smoothing parameter selection is applied to each group and the
value returned is the geometric mean of these.  This is intended
for use in <code><a href="#topic+sm.density.compare">sm.density.compare</a></code> and
<code><a href="#topic+sm.ancova">sm.ancova</a></code>, where
the same smoothing parameter is used for all groups so that
the principal bias terms cancel when the estimates are compared.
</p>


<h3>Value</h3>

<p>the value of the selected smoothing parameter.
</p>


<h3>Side Effects</h3>

<p>none
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis:</em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>
<p>Hurvich, C.M., Simonoff, J.S. and Tsai, C.-L. (1998).
Smoothing parameter selection in nonparametric regression
using an improved Akaike information criterion.
<em>J. R. Statistic. Soc., Series B</em>, 60, 271-293.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+sm">sm</a></code>,
<code><a href="#topic+hcv">hcv</a></code>, <code><a href="#topic+hsj">hsj</a></code>, <code><a href="#topic+hnorm">hnorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(50)
h.select(x)
h.select(x, method = "sj")

x &lt;- matrix(rnorm(100), ncol = 2)
h.select(x)
sm.density(x, method = "cv")

x &lt;- rnorm(50)
y &lt;- x^2 + rnorm(50)
h.select(x, y)
sm.regression(x, y, method = "aicc")

x &lt;- matrix(rnorm(100), ncol = 2)
y &lt;- x[,1]^2 + x[,2]^2 + rnorm(50)
h.select(x, y, method = "cv", structure.2d = "common")
sm.regression(x, y, df = 8)
</code></pre>

<hr>
<h2 id='hcv'>
Cross-validatory choice of smoothing parameter
</h2><span id='topic+hcv'></span>

<h3>Description</h3>

<p>This function uses the technique of cross-validation to select a smoothing 
parameter suitable for constructing a density estimate or nonparametric 
regression curve in one or two dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hcv(x, y = NA, hstart = NA, hend = NA, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hcv_+3A_x">x</code></td>
<td>

<p>a vector, or two-column matrix of data.  If <code>y</code> is missing these are 
observations to be used in the construction of a density estimate.  If
<code>y</code> is present, these are the covariate values for a nonparametric regression.
</p>
</td></tr>
<tr><td><code id="hcv_+3A_y">y</code></td>
<td>

<p>a vector of response values for nonparametric regression.
</p>
</td></tr>
<tr><td><code id="hcv_+3A_hstart">hstart</code></td>
<td>

<p>the smallest value of the grid points to be used in an initial grid search 
for the value of the smoothing parameter.
</p>
</td></tr>
<tr><td><code id="hcv_+3A_hend">hend</code></td>
<td>

<p>the largest value of the grid points to be used in an initial grid search 
for the value of the smoothing parameter.
</p>
</td></tr>
<tr><td><code id="hcv_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code> function,
through a mechanism which limits their effect only to this call of the
function. Those specifically relevant for this function are the following:
<code>h.weights</code>, <code>ngrid</code>, <code>display</code>, <code>add</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>See Sections 2.4 and 4.5 of the reference below.
</p>
<p>The two-dimensional case uses a smoothing parameter derived from a single 
value, scaled by the standard deviation of each component.
</p>
<p>This function does not employ a sophisticated algorithm and some
adjustment of the search parameters may be required for different sets
of data.  An initial estimate of the value of h which minimises the
cross-validatory criterion is located from a grid search using values
which are equally spaced on a log scale between <code>hstart</code> and
<code>hend</code>.  A quadratic approximation is then used to refine this
initial estimate.
</p>


<h3>Value</h3>

<p>the value of the smoothing parameter which minimises the cross-validation
criterion over the selected grid.
</p>


<h3>Side Effects</h3>

<p>If the minimising value is located at the end of the grid of search positions,
or if some values of the cross-validatory criterion cannot be evaluated,
then a warning message is printed.  In these circumstances altering the
values of <code>hstart</code> and <code>hend</code> may improve performance.
</p>


<h3>Note</h3>

<p>As from version 2.1 of the package, a similar effect can be
obtained with the new function <code>h.select</code>, via
<code>h.select(x, method="cv")</code>. Users are encouraged to adopt
this route, since <code>hcv</code> might be not accessible directly
in future releases of the package.  When the
sample size is large <code>hcv</code> uses the raw data while
<code>h.select(x, method="cv")</code> uses binning.  The latter is 
likely to produce a more stable choice for <code>h</code>.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997).
<em>Applied Smoothing Techniques for Data Analysis:</em> 
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h.select">h.select</a></code>, <code><a href="#topic+hsj">hsj</a></code>, <code><a href="#topic+hnorm">hnorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  Density estimation

x &lt;- rnorm(50)
par(mfrow=c(1,2))
h.cv &lt;- hcv(x, display="lines", ngrid=32)
sm.density(x, h=hcv(x))
par(mfrow=c(1,1))

#  Nonparametric regression

x &lt;- seq(0, 1, length = 50)
y &lt;- rnorm(50, sin(2 * pi * x), 0.2)
par(mfrow=c(1,2))
h.cv &lt;- hcv(x, y, display="lines", ngrid=32)
sm.regression(x, y, h=hcv(x, y))
par(mfrow=c(1,1))
</code></pre>

<hr>
<h2 id='hnorm'>
Normal optimal choice of smoothing parameter in density estimation
</h2><span id='topic+hnorm'></span>

<h3>Description</h3>

<p>This functions evaluates the smoothing parameter which is asymptotically
optimal for estimating a density function when the underlying distribution
is Normal.  Data in one, two or three dimensions can be handled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hnorm(x, weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hnorm_+3A_x">x</code></td>
<td>

<p>a vector, or matrix with two or three columns, containing the data.
</p>
</td></tr>
<tr><td><code id="hnorm_+3A_weights">weights</code></td>
<td>

<p>an optional vector of integer values
which allows the kernel functions over the observations to take
different weights when they are averaged to produce a density estimate.  This
is useful, in particular, for censored data and to construct an estimate
from binned data. 
</p>
</td></tr></table>


<h3>Details</h3>

<p>See Section 2.4.2 of the reference below.
</p>


<h3>Value</h3>

<p>the value of the asymptotically optimal smoothing parameter for Normal case.
</p>


<h3>Note</h3>

<p>As from version 2.1 of the package, a similar effect can be
obtained with the new function <code>h.select</code>, via <code>h.select(x,
    method="normal", weights=weights)</code> or simply <code>h.select(x)</code>.
Users are encouraged to adopt this route, since <code>hnorm</code> might be
not accessible directly in future releases of the package.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h.select">h.select</a></code>, <code><a href="#topic+hcv">hcv</a></code>, <code><a href="#topic+hsj">hsj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(50)
hnorm(x)
</code></pre>

<hr>
<h2 id='hsj'>
Sheather-Jones choice of smoothing parameter for density estimation
</h2><span id='topic+hsj'></span>

<h3>Description</h3>

<p>This function uses the Sheather-Jones plug-in method of selecting a
smoothing parameter which is suitable for constructing a density estimate
in the one-dimensional case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hsj(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hsj_+3A_x">x</code></td>
<td>

<p>a vector of data.
</p>
</td></tr></table>


<h3>Details</h3>

<p>See Section 2.4.4 of the reference below.
</p>


<h3>Value</h3>

<p>the value of the smoothing parameter located by the Sheather-Jones method.
</p>


<h3>Note</h3>

<p>As from version 2.1 of the package, a similar effect can be
obtained with the new function <code>h.select</code>, via
<code>h.select(x, method="sj")</code>. Users are encouraged to adopt
this route, since <code>hsj</code> might be not accessible directly
in future releases of the package.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). <em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h.select">h.select</a></code>, <code><a href="#topic+hnorm">hnorm</a></code>, <code><a href="#topic+hcv">hcv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(50)
hsj(x)
</code></pre>

<hr>
<h2 id='lcancer'>Spatial positions of cases of laryngeal cancer</h2><span id='topic+lcancer'></span>

<h3>Description</h3>

<p>These data record the spatial positions of cases of laryngeal cancer
in the North-West of England between 1974 and 1983, together with the
positions of a number of lung cancer patients who were used as controls.
The data have been adjusted to preserve anonymity.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Easting</code>  </td><td style="text-align: left;">  a west-east grid reference </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Northing</code> </td><td style="text-align: left;">  a north-south grid reference </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Cancer</code>   </td><td style="text-align: left;">  an indicator of laryngeal (1) or lung (2) cancer
</td>
</tr>

</table>

<p>Source: Bailey &amp; Gatrell (1995).  Interactive Spatial Data Analysis.  Longman Scientific and Technical, Harlow.  A more extensive set of data is analysed in Kelsall &amp; Diggle, kernel estimation of relative risk, Bernoulli 1, 3-16.
</p>

<hr>
<h2 id='mackerel'>The abundance of mackerel eggs</h2><span id='topic+mackerel'></span>

<h3>Description</h3>

<p>These data record the abundance of mackerel eggs off the coast of
north-western Europe, from a multi-country survey in 1992.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Density</code>     </td><td style="text-align: left;">  egg density </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>mack.lat</code>    </td><td style="text-align: left;">  latitude of sampling position </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>mack.long</code>   </td><td style="text-align: left;">  longitude of sampling position </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>mack.depth</code>  </td><td style="text-align: left;">  bottom depth </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Temperature</code> </td><td style="text-align: left;">  surface temperature </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Salinity</code>    </td><td style="text-align: left;">  salinity
</td>
</tr>

</table>

<p>Background to the survey and the data are provided by Watson et al. (1992), Priede and Watson (1993) and Priede et al (1995).  Borchers et al (1997) describe an analysis of the data.
</p>

<hr>
<h2 id='magrem'>Magnetic remanence</h2><span id='topic+magrem'></span>

<h3>Description</h3>

<p>These data record measurements of magnetic remanence in specimens of
Precambrian volcanics.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>maglong</code> </td><td style="text-align: left;">  directional component on a longitude scale </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>maglat</code>  </td><td style="text-align: left;">  directional component on a latitude scale
</td>
</tr>

</table>

<p>Schmidt &amp; Embleton (1985) J.Geophys.Res. 90 (B4), 2967-2984.
</p>
<p>The data are also listed in Fisher, Lewis &amp; Embleton (1987), Statistical Analysis of Spherical Data, Cambridge University Press, Cambridge, dataset B6.
</p>

<hr>
<h2 id='mildew'>Mildew control</h2><span id='topic+mildew'></span>

<h3>Description</h3>

<p>The data refer to study of mildew control sponsored by Bainbridge,
Jenkyn and Dyke at Rothamsted Experimental Station.  There were four
treatments, one of which was a control.  There were 36 adjacent plots,
with an extra plot at each end.  Nine blocks were created by grouping
the plots in fours.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>t1, t2, t3</code>  </td><td style="text-align: left;">  indicators of the four treatment groups </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>p1, ..., p8</code> </td><td style="text-align: left;">  indicators of the nine blocks</td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Yield</code>       </td><td style="text-align: left;">  tons of grain per hectare
</td>
</tr>

</table>

<p>Draper &amp; Guttman (1980).  Incorporating overlap effects from
neighbouring units into response surface models.
Applied Statistics 29, 128-134.
</p>

<hr>
<h2 id='mosses'>Heavy metals in mosses in Galicia.</h2><span id='topic+mosses'></span>

<h3>Description</h3>

<p>Mosses are used as a means of measuring levels of heavy metal concentrations in the atmosphere, since most of the nutrient uptake of the mosses is from the air.  This technique for large-scale monitoring of long-range transport processes has been used in Galicia, in North-West Spain, over the last decade, as described by Fernandez et al. (2005).  In 2006, in both March and September, measurements of different metals were collected at 148 points lying almost in a regular grid over the region with 15 km spacing in north-south and east-west directions.  According to the ecologists' expertise, the period between the two samples, passing from a humid to a dry season, is enough time to guarantee the independence of the observed processes.
</p>
<p>The dataset consists of a list with six components
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>loc.m</code> </td><td style="text-align: left;"> a two-column matrix containing grid locations of the March monitoring sites </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>loc.s</code> </td><td style="text-align: left;"> a two-column matrix containing grid locations of the September monitoring sites </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Co.m</code>  </td><td style="text-align: left;"> cobalt concentration (log scale) in March </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Co.s</code>  </td><td style="text-align: left;"> cobalt concentration (log scale) in September </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Hg.m</code>  </td><td style="text-align: left;"> mercury concentration (log scale) in March </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Hg.s</code>  </td><td style="text-align: left;"> mercury concentration (log scale) in September </td>
</tr>

</table>

<p>Source: The data were kindly made available by the Ecotoxicology and Vegetal Ecophysiology research group in the University of Santiago de Compostela.
</p>


<h3>References</h3>

<p>Fernandez, J., Real, C., Couto, J., Aboal, J., Carballeira, A. (2005).
The effect of sampling design on extensive biomonitoring surveys of air pollution.
Science of the Total Environment, 337, 11-21.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Comparison of Co in March and September
   
with(mosses, {
	
   nbins &lt;- 12
   vgm.m &lt;- sm.variogram(loc.m, Co.m, nbins = nbins, original.scale = TRUE,
                        ylim = c(0, 1.5))
   vgm.s &lt;- sm.variogram(loc.s, Co.s, nbins = nbins, original.scale = TRUE,
                        add = TRUE, col.points = "blue")
                        
   trns &lt;- function(x) (x / 0.977741)^4
   del &lt;- 1000
   plot(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean), type = "b",
         ylim = c(0, 1.5), xlab = "Distance", ylab = "Semi-variogram")
   points(vgm.s$distance.mean - del, trns(vgm.s$sqrtdiff.mean), type = "b",
         col = "blue", pch = 2, lty = 2)

   plot(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean), type = "b",
         ylim = c(0, 1.5), xlab = "Distance", ylab = "Semi-variogram")
   points(vgm.s$distance.mean - del, trns(vgm.s$sqrtdiff.mean), type = "b",
         col = "blue", pch = 2, lty = 2)
   segments(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean - 2 * vgm.m$se),
         vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean + 2 * vgm.m$se))
   segments(vgm.s$distance.mean - del, trns(vgm.s$sqrtdiff.mean - 2 * vgm.s$se),
         vgm.s$distance.mean - del, trns(vgm.s$sqrtdiff.mean + 2 * vgm.s$se),
         col = "blue", lty = 2)

   mn &lt;- (vgm.m$sqrtdiff.mean + vgm.s$sqrtdiff.mean) / 2
   se &lt;- sqrt(vgm.m$se^2 + vgm.s$se^2)
   plot(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean), type = "n",
        ylim = c(0, 1.5), xlab = "Distance", ylab = "Semi-variogram")
   polygon(c(vgm.m$distance.mean, rev(vgm.m$distance.mean)),
        c(trns(mn - se), rev(trns(mn + se))),
        border = NA, col = "lightblue")  
   points(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean))
   points(vgm.s$distance.mean, trns(vgm.s$sqrtdiff.mean), col = "blue", pch = 2)

   vgm1 &lt;- sm.variogram(loc.m, Co.m, nbins = nbins, varmat = TRUE, 
                        display = "none")
   vgm2 &lt;- sm.variogram(loc.s, Co.s, nbins = nbins, varmat = TRUE,
                        display = "none")

   nbin  &lt;- length(vgm1$distance.mean)
   vdiff &lt;- vgm1$sqrtdiff.mean - vgm2$sqrtdiff.mean
   tstat &lt;- c(vdiff %*% solve(vgm1$V + vgm2$V) %*% vdiff)
   pval  &lt;- 1 - pchisq(tstat, nbin)
   print(pval)
})

# Assessing isotropy for Hg in March

with(mosses, {
   sm.variogram(loc.m, Hg.m, model = "isotropic")
})

# Assessing stationarity for Hg in September

with(mosses, {
   vgm.sty &lt;- sm.variogram(loc.s, Hg.s, model = "stationary")
   i &lt;- 1
   image(vgm.sty$eval.points[[1]], vgm.sty$eval.points[[2]], vgm.sty$estimate[ , , i],
         col = topo.colors(20))
   contour(vgm.sty$eval.points[[1]], vgm.sty$eval.points[[2]], vgm.sty$sdiff[ , , i],
         col = "red", add = TRUE)
})


## End(Not run)
</code></pre>

<hr>
<h2 id='muscle'>Rat skeletal muscles</h2><span id='topic+muscle'></span>

<h3>Description</h3>

<p>The data refer to the counts of fibres of different types in 
groups of fibres taken from rat skeletal muscles.  
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>row.labels</code> </td><td style="text-align: left;">  indicators of the four treatment groups </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>TypeI.R</code>    </td><td style="text-align: left;">  indicators of the nine blocks </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>TypeI.P</code>    </td><td style="text-align: left;">  tons of grain per hectare </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>TypeI.B</code>    </td><td style="text-align: left;">  tons of grain per hectare </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>TypeII</code>     </td><td style="text-align: left;">  tons of grain per hectare </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Hand, Daly, Lunn, McConway and Ostrowski (1994).  A handbook of Small Data Sets.  Chapman &amp; Hall: London.  The data were collected by M. Khan and M. Khan.
</p>

<hr>
<h2 id='nile'>Water level of the River Nile</h2><span id='topic+nile'></span>

<h3>Description</h3>

<p>These data record historical data on the water level of the River Nile.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Volume</code> </td><td style="text-align: left;">  Annual volume of the Nile River (discharge at Aswan, 10^8 m^3) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Year</code>   </td><td style="text-align: left;">  1871-1970
</td>
</tr>

</table>

<p>Cobb, G. (1978). The problem of the Nile: conditional solution to a change-point problem.  Biometrika 65, 243-251.
</p>

<hr>
<h2 id='nise'>Integrated squared error between a density estimate and a Normal density</h2><span id='topic+nise'></span>

<h3>Description</h3>

<p>This function evaluates the integrated squared error between a density
estimate constructed from a standardised version of the univariate data
<code>y</code> and a standard normal density function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nise(y, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nise_+3A_y">y</code></td>
<td>
<p>a vector of data.</p>
</td></tr>
<tr><td><code id="nise_+3A_...">...</code></td>
<td>
<p>further arguments which are to be passed to <code>sm.options</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data <code>y</code> are first standardised to have sample mean 0 and sample
variance 1.  The integrated squared error between a density estimate
constructed from these standardised data and a standard normal distribution
is then evaluated.
</p>
<p>See Section 2.5 of the reference below.
</p>


<h3>Value</h3>

<p>the integrated squared error.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). <em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nmise">nmise</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
nise(x)
</code></pre>

<hr>
<h2 id='nmise'>
mean integrated squared error for density estimation with normal data
</h2><span id='topic+nmise'></span>

<h3>Description</h3>

<p>This function evaluates the mean integrated squared error of a density
estimate which is constructed from data which follow a normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmise(sd, n, h)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmise_+3A_sd">sd</code></td>
<td>

<p>the standard deviation of the normal distribution from which the data arise.
</p>
</td></tr>
<tr><td><code id="nmise_+3A_n">n</code></td>
<td>

<p>the sample size of the data.
</p>
</td></tr>
<tr><td><code id="nmise_+3A_h">h</code></td>
<td>

<p>the smoothing parameter used to construct the density estimate.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Section 2.4 of the reference below.
</p>


<h3>Value</h3>

<p>the mean integrated squared error of the density estimate.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). <em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nise">nise</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x  &lt;- rnorm(50)
sd &lt;- sqrt(var(x))
n  &lt;- length(x)
h  &lt;- seq(0.1, 2, length=32)
plot(h, nmise(sd, n, h), type = "l")
</code></pre>

<hr>
<h2 id='nnbr'>
nearest neighbour distances from data in one or two dimensions
</h2><span id='topic+nnbr'></span>

<h3>Description</h3>

<p>This function calculates the <code>k</code> nearest neighbour distance from each
value in <code>x</code> to the remainder of the data.  In two dimensions, Euclidean
distance is used after standardising the data to have unit variance in
each component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nnbr(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nnbr_+3A_x">x</code></td>
<td>

<p>the vector, or two-column matrix, of data.
</p>
</td></tr>
<tr><td><code id="nnbr_+3A_k">k</code></td>
<td>

<p>the required order of nearest neighbour.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Section 1.7.1 of the reference below.
</p>


<h3>Value</h3>

<p>the vector of nearest neighbour distances.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). <em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p>none.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x  &lt;- rnorm(50)
hw &lt;- nnbr(x, 10)
hw &lt;- hw/exp(mean(log(hw)))
sm.density(x, h.weights=hw)
</code></pre>

<hr>
<h2 id='pause'>
Pause before continuing execution  
</h2><span id='topic+pause'></span>

<h3>Description</h3>

<p>If a program produces several plots on the same window, insertion of
<code>pause()</code> between two plots suspends execution until the &lt;Enter&gt;
key is pressed, to allow inspection of the current plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pause()
</code></pre>

<hr>
<h2 id='poles'>Positions of the south pole</h2><span id='topic+poles'></span>

<h3>Description</h3>

<p>These data refer to positions of the south pole determined from the
palaeomagnetic study of New Caledonian laterites.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Latitude</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Longitude</code>
</td>
</tr>

</table>

<p>The data were collected by Falvey and Musgrave.	They are listed in Fisher, Lewis &amp; Embleton (1987), Statistical Analysis of Spherical Data, Cambridge University Press, Cambridge, dataset B1.
</p>

<hr>
<h2 id='provide.data'>
Making data available as data.frame
</h2><span id='topic+provide.data'></span>

<h3>Description</h3>

<p>This function is no longer available in the sm package.  It should be replaced by the use of <code>attach</code>, if necessary.  Each dataset now also has its own help file.
</p>
<p>It was a utility function, widely used in the scripts accompanying
the book described below.  The function provided access to the dataset identified by <code>name</code>.  For flexibility, the datasets were provided in ASCII form, with the name of each variable listed in the first row of the file.  This function reads the files and makes the data available as a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>provide.data(data, path, options = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="provide.data_+3A_data">data</code></td>
<td>

<p>name of the data to be loaded and attached as <code>data.frame</code>
</p>
</td></tr>
<tr><td><code id="provide.data_+3A_path">path</code></td>
<td>

<p>the path where the data and its documentation should be searched for,
The default value is an appropriate sub-directory of the <code>sm</code> package. 
</p>
</td></tr>
<tr><td><code id="provide.data_+3A_options">options</code></td>
<td>

<p>A list of options passed to <code><a href="#topic+sm.options">sm.options</a></code>.  The one used is
<code>describe</code>, a logical flag.  If <code>describe=TRUE</code> (default), a
documentation file of the data is searched and printed, if available.
</p>
</td></tr></table>


<h3>Details</h3>

<p>the data file is assumed to be called <code>data.dat</code> and the documentation
file describing the data (if present) is assumed to be called <code>data.doc</code>.
If the <code>data.frame</code> is already attached, it is re-attached in the second
position of the <code>search</code> list. 
</p>
<p>To set <code>describe=FALSE</code> for the rest of the current session,  use 
<code>sm.options(describe=FALSE)</code>
</p>
<p>The function can easily be adapted to play a similar role for
other packages.
</p>


<h3>Value</h3>

<p>none
</p>


<h3>Side Effects</h3>

<p>messages are printed on the command window, describing  progress of
the operation. If <code>describe=TRUE</code> and a documentation file exists, this
is printed on the command windows or another windows, depending on
the type of platform where the program is executed.
</p>


<h3>Author(s)</h3>

<p>Bowman, A.W. and Azzalini, A.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+data.frame">data.frame</a></code>, <code><a href="base.html#topic+attach">attach</a></code>, <code><a href="#topic+sm">sm</a></code>,
<code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>provide.data(birth)
</code></pre>

<hr>
<h2 id='radioc'>Radiocarbon in Irish oak</h2><span id='topic+radioc'></span>

<h3>Description</h3>

<p>These data record high precision measurements of radiocarbon on Irish oak, used to construct a calibration curve.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Rc.age</code>    </td><td style="text-align: left;">  age predicted from the radiocarbon dating process </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Precision</code> </td><td style="text-align: left;">  a measure of precision of the dating process </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Cal.age</code>   </td><td style="text-align: left;">  true calendar age
</td>
</tr>

</table>

<p>Pearson &amp; Qua (1993).  High precision 14C measurement of Irish oaks to show the natural 14C variations from AD 1840 - 5000 BC: a correction.  Radiocarbon 35, 105-123.
</p>

<hr>
<h2 id='sig.trace'>
A significance trace for a hypothesis test
</h2><span id='topic+sig.trace'></span>

<h3>Description</h3>

<p>This function creates a significance trace for a hypothesis test based
on a nonparametric smoothing procedure.  The p-value of the test is
plotted against a range of smoothing parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sig.trace(expn, hvec, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sig.trace_+3A_expn">expn</code></td>
<td>

<p>an S-Plus expression which should define the hypothesis test to be
performed, with the value of the smoothing parameter <code>h</code> omitted from
the function call.
</p>
</td></tr>
<tr><td><code id="sig.trace_+3A_hvec">hvec</code></td>
<td>

<p>a vector of smoothing parameters for which the test will be performed.
</p>
</td></tr>
<tr><td><code id="sig.trace_+3A_...">...</code></td>
<td>

<p>further arguments which will be passed to <code>sm.options</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Section 5.2 of the reference below.
</p>
<p>Only tests involving a univariate smoothing parameter may be used.
</p>


<h3>Value</h3>

<p>a list containing vectors with the smoothing parameters and p-values.
</p>


<h3>Side Effects</h3>

<p>If the largest p-value is greater than 0.05 then a horizontal line at
0.05 will be superimposed on any plot, for reference.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). <em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p>none.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(50, 0, 1)
y &lt;- 5*x^2 + rnorm(50)
sig.trace(sm.regression(x, y, model = "linear", display="none"), 
        hvec = seq(0.05, 0.3, length = 10))
</code></pre>

<hr>
<h2 id='sm'>
The sm package: summary information
</h2><span id='topic+sm'></span>

<h3>Description</h3>

<p>This package implements nonparametric smoothing methods described
in the book of Bowman &amp; Azzalini (1997)
</p>


<h3>Details</h3>

<p>Missing data are allowed; they are simply removed, together with
the associated variates from the same case, if any.
Datasets of arbitrary size can be handled by the current version of  
<code>sm.density</code>,  <code>sm.regression</code> and <code>sm.ancova</code>, using
binning operations. 
</p>


<h3>Main Features</h3>

<p>The functions in the package use kernel methods to construct
nonparametric estimates of density functions and regression curves in a
variety of settings, and to perform some inferential operations.
</p>
<p>Specifically, density estimates can be constructed for 1-, 2- and
3-dimensional data. Nonparametric regression for continuous data can be
constructed with one or two covariates, and a variety of
tests can be carried out.  Several other data types can be
handled, including survival data, time series, count and binomial
data.
</p>


<h3>Functions</h3>

<p>The main functions are <code>sm.density</code> and <code>sm.regression</code>; other
functions intended for direct access by the user are:
<code>h.select</code>, <code>binning</code>,
<code>sm.ancova</code>, <code>sm.autoregression</code>, <code>sm.binomial</code>,
<code>sm.binomial.bootstrap</code>, <code>sm.poisson</code>, <code>sm.poisson.bootstrap</code>,
<code>sm.options</code>, <code>sm.rm</code>, <code>sm.script</code>, <code>sm.sphere</code>,
<code>sm.survival</code>, <code>sm.ts.pdf</code>, <code>sm.variogram</code>, <code>sm.pca</code>.  There are undocumented functions which are called by these.
</p>


<h3>Scripts</h3>

<p>The function <code>sm.script</code> is used to run a set of examples (called
scripts) presented in the book quoted below. These scripts are
associated with the package but the package can be used independently of
them.  The scripts are generally based on the functions of the package
<code>sm</code>, but a few of them make used of the <code>gam</code> package.
</p>


<h3>Requirements</h3>

<p>R version &gt;= 3.1.0. The <code>gam</code> package is used by
some of the scripts launched via <code>sm.script</code>, but it is not
used by the functions of this package.
</p>


<h3>Version</h3>

<p>This is version 2.2.
The most recent version of the package can be obtained from the CRAN archive.
</p>


<h3>Details</h3>

<p>The book by Bowman and Azzalini (1997) provides more detailed and
background information.  Algorithmic aspects of the software are
discussed by Bowman &amp; Azzalini (2003).  Differences between the first
version of the package, described in the book, and the current one are
summarized in the file <code>history.txt</code> which is distributed with
the package.
</p>


<h3>Acknowledgements</h3>

<p>Important contributions to prototype versions of functions for some
specific techniques included here were made by a succession of students;
these include Stuart Young, Eileen Wright, Peter Foster, Angela Diblasi,
Mitchum Bock and Adrian Hines.  We are grateful for all these
interactions.  These preliminary version have been subsequently
re-written for inclusion in the public release of the package, with the
exception of the functions for three-dimensional density estimation,
written by Stuart Young.  We also thank Luca Scrucca who made useful
comments and who has ported the software to XLispStat.
We are particularly grateful to Brian Ripley for substantial help in
the production of installation files, the creation of MS-Windows
versions, initial porting of the software from S-Plus to R and for
maintaining the package on CRAN for several years.
</p>


<h3>Licence</h3>

<p>This package and its documentation are usable under the terms of the &quot;GNU
General Public License&quot;, a copy of which is distributed with the package.
</p>


<h3>Author(s)</h3>

<p>Adrian Bowman (School of Mathematics and Statistics, University of Glasgow, UK) and
Adelchi Azzalini (Dept Statistical Sciences, University of Padua, Italy).
Please send comments, error reports, etc. to the authors.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997).
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>
<p>Bowman, A.W. and Azzalini, A. (2003).
Computational aspects of nonparametric smoothing
with illustrations from the <code>sm</code> library.
<em>Computational Statistics and Data Analysis</em>, <b>42</b>, 545&ndash;560.
</p>

<hr>
<h2 id='sm-internal'>Internal sm functions</h2><span id='topic+addplot'></span><span id='topic+aicc.crit.reg'></span><span id='topic+britmap'></span><span id='topic+change'></span><span id='topic+circle'></span><span id='topic+cv'></span><span id='topic+cv.crit.dens'></span><span id='topic+cv.crit.reg'></span><span id='topic+df.crit.reg'></span><span id='topic+hidplot'></span><span id='topic+incphi'></span><span id='topic+inctheta'></span><span id='topic+normdens.band'></span><span id='topic+np.contour.plot.3d.'></span><span id='topic+p.quad.moment'></span><span id='topic+plot2'></span><span id='topic+plot2d'></span><span id='topic+replace.na'></span><span id='topic+sj'></span><span id='topic+sm.check.data'></span><span id='topic+sm.density.1d'></span><span id='topic+sm.density.2d'></span><span id='topic+sm.density.3d'></span><span id='topic+sm.density.eval.1d'></span><span id='topic+sm.density.eval.2d'></span><span id='topic+sm.density.positive.1d'></span><span id='topic+sm.density.positive.2d'></span><span id='topic+sm.density.positive.grid'></span><span id='topic+sm.glm'></span><span id='topic+sm.imageplot'></span><span id='topic+sm.persplot'></span><span id='topic+sm.rglplot'></span><span id='topic+sm.regression.1d'></span><span id='topic+sm.regression.2d'></span><span id='topic+sm.regression.eval.1d'></span><span id='topic+sm.regression.eval.2d'></span><span id='topic+sm.regression.test'></span><span id='topic+sm.sigweight'></span><span id='topic+sm.sliceplot'></span><span id='topic+sm.weight'></span><span id='topic+sm.weight2'></span><span id='topic+smplot.density'></span><span id='topic+smplot.regression'></span><span id='topic+wmean'></span><span id='topic+wvar'></span><span id='topic+isInteger'></span><span id='topic+isMatrix'></span>

<h3>Description</h3>

<p>Internal <code>sm</code> functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addplot(d, f, theta, phi)
britmap()
change(th, ph)
circle(r)
cv(x, h, ...)
hidplot(invis, theta, phi)
incphi(ph, inc)
inctheta(th, inc)
isInteger(x)
isMatrix(x)
normdens.band(x, h, weights = rep(1, length(x)), options = list())
p.quad.moment(A, Sigma, tobs, ndevs)
smplot.regression(x, y, design.mat, h, r, model, weights, rawdata = list(),
    options = list(), ...)
plot2(latitude2, longitude2, theta, phi)
plot2d(d, f, theta, phi)
replace.na(List, comp, value)
sj(x, h)
sm.check.data(x, y = NA, weights = NA, group = NA, ...)
sm.density.1d(x, h = hnorm(x, weights), model = "none", weights,
   rawdata = list(x = x), options = list())
sm.density.2d(X, h = hnorm(X, weights), weights = rep(1, length(x)),
   rawdata = list(), options = list())
sm.density.3d(x, h = hnorm(x, weights),  weights = rep(1, length(x)), 
   rawdata = list(), options = list())
sm.density.eval.1d(x, h, weights = rep(1, n), options = list())
sm.density.eval.2d(x, y, h, xnew, ynew, eval.type = "points",
   weights = rep(1, n), options = list())
sm.density.positive.1d(x, h, weights, options = list())
sm.density.positive.2d(X, h = c(hnorm(log(X[, 1] + delta[1]), weights),
   hnorm(log(X[,2] + delta[2]), weights)), eval.type = "points",
   weights = rep(1, nrow(X)), options = list())
sm.density.positive.grid(X, h = c(hnorm(log(X[, 1] + delta[1])),
   hnorm(log(X[, 2] + delta[2]))), weights=NA, options=list())
sm.glm(x, y, family, h, eval.points, start, offset, options=list())
sm.imageplot(x, y, h, weights, rawdata, options = list())
sm.persplot(x, y, h = hnorm(cbind(x, y), weights), weights, rawdata = list(),
    options = list())
sm.regression.1d(x, y, h, design.mat = NA, model = "none",
    weights = rep(1, length(x)), rawdata, options = list())
sm.regression.2d(x, y, h, model = "none", weights = rep(1, length(y)), rawdata,
    options = list())
sm.regression.eval.1d(x, y, design.mat, h, model = "none",
    weights = rep(1, length(x)), rawdata, options = list())
sm.regression.eval.2d (x, y, h, model, eval.points, hull = TRUE,
    weights, options = list())
sm.regression.test(x, y, design.mat = NA, h, model = "no.effect",
    weights = rep(1,length(y)), rawdata, options = list())
sm.sigweight(x, weights)
sm.sliceplot(x, y, h, weights, rawdata = list(), options = list())
sm.weight(x, eval.points, h, cross = FALSE, weights = rep(1, length(x)), options)
sm.weight2(x, eval.points, h, cross = FALSE, weights = rep(1, nrow(x)),
    options = list())
smplot.density(x, h, weights = rep(1, length(x)), rawdata = list(x = x),
    options = list())
wmean(x, w)
wvar(x, w)
</code></pre>


<h3>Details</h3>

<p>These are not to be called by the user.
</p>

<hr>
<h2 id='sm.ancova'>
Nonparametric analysis of covariance
</h2><span id='topic+sm.ancova'></span>

<h3>Description</h3>

<p>This function allows a set of nonparametric regression curves to be
compared, both graphically and formally in a hypothesis test.  A reference
model, used to define the null hypothesis, may be either equality or 
parallelism.  Regression surfaces can also be compared in a test but a
graphical display is not produced.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.ancova(x, y, group, h, model = "none", h.alpha = NA, weights=NA,
                 covar = diag(1/weights), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.ancova_+3A_x">x</code></td>
<td>

<p>a vector or two-column matrix of covariate values.
</p>
</td></tr>
<tr><td><code id="sm.ancova_+3A_y">y</code></td>
<td>

<p>a vector of response values.
</p>
</td></tr>
<tr><td><code id="sm.ancova_+3A_group">group</code></td>
<td>

<p>a vector of group indicators.
</p>
</td></tr>
<tr><td><code id="sm.ancova_+3A_h">h</code></td>
<td>

<p>the smoothing parameter to be used in the construction of each of the
regression curves.  If this is missing the method of smoothing parameter
selection specified by <code>sm.options</code> will be applied.
</p>
</td></tr>
<tr><td><code id="sm.ancova_+3A_model">model</code></td>
<td>

<p>a character variable which defines the reference model.  The values
<code>"none"</code>, <code>"equal"</code> and <code>"parallel"</code> are possible.
</p>
</td></tr>
<tr><td><code id="sm.ancova_+3A_h.alpha">h.alpha</code></td>
<td>

<p>the value of the smoothing parameter used when estimating the vertical
separations of the curves under the parallelism model.  If this is missing,
it is set to 2 * r / n, where r denotes the range of the data and n the
sample size.
</p>
</td></tr>
<tr><td><code id="sm.ancova_+3A_weights">weights</code></td>
<td>

<p>case weights; see the documentation of <code><a href="#topic+sm.regression">sm.regression</a></code>
for a full description.
</p>
</td></tr>
<tr><td><code id="sm.ancova_+3A_covar">covar</code></td>
<td>

<p>the (estimated) covariance matrix of y.  The default value assumes
the data to be independent.  Where appropriate, the covariance structure
of <code>y</code> can be estimated by the user, externally to <code>sm.ancova</code>,
and passed through this argument.  This is used in the hypothesis tests
but not in the construction of the reference band for comparing two groups
(and so graphics are disabled in this case).
</p>
</td></tr>
<tr><td><code id="sm.ancova_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function. Those relevant for this function are the following:
<code>display</code>,
<code>ngrid</code>,
<code>eval.points</code>,
<code>xlab</code>,
<code>ylab</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Sections 6.4 and 6.5 of the book by Bowman &amp; Azzalini, and
the papers by Young &amp; Bowman listed below.
This function is a developed version of code originally written by Stuart Young.
</p>


<h3>Value</h3>

<p>a list containing an estimate of the error standard deviation and, where
appropriate, a p-value and reference model.  If the parallelism model has
been selected then a vector of estimates of the vertical separations of the 
underlying regression curves is also returned.  If a reference band has been
requested, the upper and lower boundaries and their common evaluation points
are also returned.
</p>


<h3>Side Effects</h3>

<p>a plot on the current graphical device is produced, unless <code>display="none"</code>
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>
<p>Young, S.G. and Bowman, A.W. (1995).  
Nonparametric analysis of covariance.  
<em>Biometrics</em>
<b>51</b>, 920&ndash;931.
</p>
<p>Bowman, A.W. and Young, S.G. (1996).  
Graphical comparison of nonparametric curves.  
<em>Applied Statistics</em>
<b>45</b>, 83&ndash;98.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.density.compare">sm.density.compare</a></code>, <code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(50, 0, 1)
y &lt;- 4*sin(6*x) + rnorm(50)
g &lt;- rbinom(50, 1, 0.5)
sm.ancova(x, y, g, h = 0.15, model = "equal")
</code></pre>

<hr>
<h2 id='sm.autoregression'>
Nonparametric estimation of the autoregression function
</h2><span id='topic+sm.autoregression'></span>

<h3>Description</h3>

<p>This function estimates nonparametrically the autoregression function
(conditional mean given the past values) of a time series <code>x</code>,
assumed to be stationary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.autoregression(x, h = hnorm(x), d = 1, maxlag = d, lags,
                  se = FALSE, ask = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.autoregression_+3A_x">x</code></td>
<td>

<p>vector containing the time series values.
</p>
</td></tr>
<tr><td><code id="sm.autoregression_+3A_h">h</code></td>
<td>

<p>the bandwidth used for kernel smoothing.
</p>
</td></tr>
<tr><td><code id="sm.autoregression_+3A_d">d</code></td>
<td>

<p>number of past observations used for conditioning; it must be 1
(default value) or 2.
</p>
</td></tr>
<tr><td><code id="sm.autoregression_+3A_maxlag">maxlag</code></td>
<td>

<p>maximum of the lagged values to be considered (default value is <code>d</code>).
</p>
</td></tr>
<tr><td><code id="sm.autoregression_+3A_lags">lags</code></td>
<td>

<p>if <code>d==1</code>, this is a vector containing the lags considered for conditioning;
if <code>d==2</code>, this is a matrix with two columns, whose rows contains pair of
values considered for conditioning.
</p>
</td></tr>
<tr><td><code id="sm.autoregression_+3A_se">se</code></td>
<td>

<p>if <code>se==T</code>, pointwise confidence bands are computed of approximate level 95%.
</p>
</td></tr>
<tr><td><code id="sm.autoregression_+3A_ask">ask</code></td>
<td>

<p>if <code>ask==TRUE</code>, the program pauses after each plot until &lt;Enter&gt; is pressed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see Section 7.3 of the reference below.
</p>


<h3>Value</h3>

<p>a list with the outcome of the final estimation (corresponding to
the last value or pairs of values of lags), as returned by <code>sm.regression</code>.
</p>


<h3>Side Effects</h3>

<p>graphical output is produced on the current device.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.ts.pdf">sm.ts.pdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sm.autoregression(log(lynx), maxlag=3, se=TRUE)
sm.autoregression(log(lynx), lags=cbind(2:3,4:5))
</code></pre>

<hr>
<h2 id='sm.binomial'>
Nonparametric logistic regression
</h2><span id='topic+sm.binomial'></span>

<h3>Description</h3>

<p>This function estimates the regression curve using the local likelihood
approach for a vector of binomial observations and an associated vector
of covariate values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.binomial(x, y, N = rep(1, length(y)), h, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.binomial_+3A_x">x</code></td>
<td>

<p>vector of the covariate values
</p>
</td></tr>
<tr><td><code id="sm.binomial_+3A_y">y</code></td>
<td>

<p>vector of the response values; they must be
nonnegative integers not larger than those of <code>N</code>.
</p>
</td></tr>
<tr><td><code id="sm.binomial_+3A_h">h</code></td>
<td>

<p>the smoothing parameter; it must be positive.
</p>
</td></tr>
<tr><td><code id="sm.binomial_+3A_n">N</code></td>
<td>

<p>a vector containing the binomial denominators.
If missing, it is assumed to contain all 1's.
</p>
</td></tr>
<tr><td><code id="sm.binomial_+3A_...">...</code></td>
<td>
   
<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function; those relevant for this function are the following:
<code>add</code>, 
<code>col</code>, 
<code>display</code>, 
<code>eval.points</code>, 
<code>nbins</code>, 
<code>ngrid</code>, 
<code>pch</code>, 
<code>xlab</code>, 
<code>ylab</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Sections 3.4 and 5.4 of the reference below.
</p>


<h3>Value</h3>

<p>A list containing vectors with the evaluation points, the corresponding
probability estimates, the linear predictors, the upper and lower points
of the variability bands (on the probability scale) and the standard
errors on the linear predictor scale.
</p>


<h3>Side Effects</h3>

<p>graphical output will be produced, depending on the value of the
<code>display</code> parameter.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis:</em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.binomial.bootstrap">sm.binomial.bootstrap</a></code>, <code><a href="#topic+sm.poisson">sm.poisson</a></code>,
<code><a href="#topic+sm.options">sm.options</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="#topic+binning">binning</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# the next example assumes that all binomial denominators are 1's
sm.binomial(dose, failure, h=0.5)
# in the next example, (some of) the dose levels are replicated 
sm.binomial(dose, failure, n.trials, h=0.5)

## End(Not run)

with(birth, {
   sm.binomial(Lwt[Smoke=="S"], Low[Smoke=="S"], h=20,
           xlab='mother weight[Smoke=="S"]')
   x&lt;- seq(0,1,length=30)
   y&lt;- rbinom(30,10,prob=2*sin(x)/(1+x))
   sm.binomial(x,y,N=rep(10,30), h=0.25)
})
</code></pre>

<hr>
<h2 id='sm.binomial.bootstrap'>
Bootstrap goodness-of-fit test for a logistic regression model. 
</h2><span id='topic+sm.binomial.bootstrap'></span>

<h3>Description</h3>

<p>This function is associated with <code>sm.binomial</code> for the underlying fitting
procedure.  It performs a Pseudo-Likelihood Ratio Test for the
goodness-of-fit of a standard parametric logistic regression of specified
<code>degree</code> in the covariate <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.binomial.bootstrap(x, y, N = rep(1, length(x)), h, degree = 1,
        fixed.disp=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.binomial.bootstrap_+3A_x">x</code></td>
<td>

<p>vector of the covariate values
</p>
</td></tr>
<tr><td><code id="sm.binomial.bootstrap_+3A_y">y</code></td>
<td>

<p>vector of the response values; they must be nonnegative integers.
</p>
</td></tr>
<tr><td><code id="sm.binomial.bootstrap_+3A_h">h</code></td>
<td>

<p>the smoothing parameter; it must be positive.
</p>
</td></tr>
<tr><td><code id="sm.binomial.bootstrap_+3A_n">N</code></td>
<td>

<p>a vector containing the binomial denominators.
If missing, it is assumed to contain all 1's.
</p>
</td></tr>
<tr><td><code id="sm.binomial.bootstrap_+3A_degree">degree</code></td>
<td>

<p>specifies the degree of the fitted polynomial in <code>x</code> on the logit scale
(default=1).</p>
</td></tr>
<tr><td><code id="sm.binomial.bootstrap_+3A_fixed.disp">fixed.disp</code></td>
<td>
<p>if <code>TRUE</code>, the dispersion
parameter is kept at value 1 across the simulated samples, otherwise
the dispersion parameter estimated from the sample is used to generate
samples with that dispersion parameter (default=<code>FALSE</code>).
</p>
</td></tr>
<tr><td><code id="sm.binomial.bootstrap_+3A_...">...</code></td>
<td>

<p>additional parameters passed to <code><a href="#topic+sm.binomial">sm.binomial</a></code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Section 5.4 of the reference below.
</p>


<h3>Value</h3>

<p>a list containing the observed value of the Pseudo-Likelihood Ratio Test
statistic, its observed p-value as estimated via the bootstrap method,
and the vector of estimated dispersion parameters when this value is not 
forced to be 1.
</p>


<h3>Side Effects</h3>

<p>Graphical output representing the bootstrap samples is produced on 
the current graphical device. 
The estimated dispersion parameter, the value of the test statistic
and the observed significance level are printed.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.binomial">sm.binomial</a></code>, <code><a href="#topic+sm.poisson.bootstrap">sm.poisson.bootstrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: sm.binomial.bootstrap(concentration, dead, N, 0.5, nboot=50)
</code></pre>

<hr>
<h2 id='sm.density'>
Nonparametric density estimation in one, two or three dimensions.
</h2><span id='topic+sm.density'></span>

<h3>Description</h3>

<p>This function creates a density estimate from data in one, two or three
dimensions.  In two dimensions a variety of
graphical displays can be selected, and in three dimensions a contour
surface can be plotted.  A number of other features of the construction
of the estimate, and of its display, can be controlled.
</p>
<p>If the <code>rpanel</code> package is available, an interactive panel can be 
activated to control various features of the plot.
</p>
<p>If the <code>rgl</code> package is also available, rotatable plots are
available for the two- and three-dimensional cases.  (For 
three-dimensional data, the <code>misc3d</code> package is also required.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.density(x, h, model = "none", weights = NA, group=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.density_+3A_x">x</code></td>
<td>
<p>a vector, or a matrix with two or three columns, containing the data.
</p>
</td></tr>
<tr><td><code id="sm.density_+3A_h">h</code></td>
<td>
<p>a vector of length one, two or three, defining the smoothing parameter.
A normal kernel function is used and <code>h</code> is its standard deviation.
If this parameter is omitted, a normal optimal smoothing parameter is used.
</p>
</td></tr>
<tr><td><code id="sm.density_+3A_model">model</code></td>
<td>
<p>This argument applies only with one-dimensional data.  Its default value
is <code>"none"</code>.  If it is set to <code>"Normal"</code> (or indeed any value
other than <code>"none"</code>) then a reference band, indicating where a
density estimate is  likely to lie when the data are normally
distributed, will be superimposed  on any plot.
</p>
</td></tr>
<tr><td><code id="sm.density_+3A_weights">weights</code></td>
<td>
<p>a vector of integers representing frequencies of individual observations.
Use of this parameter is incompatible with binning; hence <code>nbins</code> must 
then be set to 0 or left at its default value <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="sm.density_+3A_group">group</code></td>
<td>
<p> a vector of groups indicators (numeric or character values) or
a factor.
</p>
</td></tr>
<tr><td><code id="sm.density_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code> function,
through a mechanism which limits their effect only to this call of the
function. Those specifically relevant for this function are the following:
<code>hmult</code>, 
<code>h.weights</code>, 
<code>band</code>, 
<code>add</code>, 
<code>lty</code>, 
<code>display</code>, 
<code>props</code>, 
<code>xlab</code>, 
<code>ylab</code>, 
<code>zlab</code>, 
<code>xlim</code>, 
<code>ylim</code>, 
<code>yht</code>,        
<code>nbins</code>, 
<code>ngrid</code>, 
<code>eval.points</code>, 
<code>panel</code>, 
<code>positive</code>, 
<code>delta</code>, 
<code>theta</code>, 
<code>phi</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Chapters 1, 2 and 6 of the reference below.
In the three-dimensional case, the contours of the density estimate are
constructed by the <code>contour3d</code> function in the <code>misc3d</code>
package of Feng &amp; Tierney.
</p>


<h3>Value</h3>

<p>a list containing the values of the density estimate at the evaluation points,
the smoothing parameter, the smoothing parameter weights and the kernel 
weights.  For one- and two-dimensional data, the standard error of the estimate
(on the square root scale, where the standard error is approximately constant)
and the upper and lower ends of a variability band are also supplied.  Less 
information is supplied when the smoothing parameter weights
or kernel weights are not all 1, or when <code>positive</code> is set to <code>TRUE</code>.
</p>


<h3>Side Effects</h3>

<p>a plot is produced, unless the option <code>display="none"</code> is set.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h.select">h.select</a></code>, <code><a href="#topic+hnorm">hnorm</a></code>, <code><a href="#topic+hsj">hsj</a></code>, <code><a href="#topic+hcv">hcv</a></code>,
<code><a href="#topic+nise">nise</a></code>, <code><a href="#topic+nmise">nmise</a></code>, <code><a href="#topic+sm">sm</a></code>,
<code><a href="#topic+sm.sphere">sm.sphere</a></code>, <code><a href="#topic+sm.regression">sm.regression</a></code>,
<code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  A one-dimensional example
y &lt;- rnorm(50)
sm.density(y, model = "Normal")
# sm.density(y, panel = TRUE)

#  A two-dimensional example
y &lt;- cbind(rnorm(50), rnorm(50))
sm.density(y, display = "image")
# sm.density(y, panel = TRUE)


#  A three-dimensional example
# y &lt;- cbind(rnorm(50), rnorm(50), rnorm(50))
# sm.density(y)
</code></pre>

<hr>
<h2 id='sm.density.compare'>
Comparison of univariate density estimates
</h2><span id='topic+sm.density.compare'></span>

<h3>Description</h3>

<p>This function allows a set of univariate density estimates to be
compared, both graphically and formally in a permutation test of 
equality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.density.compare(x, group, h, model = "none",  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.density.compare_+3A_x">x</code></td>
<td>

<p>a vector of data.
</p>
</td></tr>
<tr><td><code id="sm.density.compare_+3A_group">group</code></td>
<td>

<p>a vector of group labels.  If this is not already a factor it will be converted to a factor.
</p>
</td></tr>
<tr><td><code id="sm.density.compare_+3A_h">h</code></td>
<td>

<p>the smoothing parameter to be used in the construction of each density
estimate.  Notice that the same smoothing parameter is used for each group.
If this value is omitted, the mean of the normal optimal values for the
different groups is used.
</p>
</td></tr>
<tr><td><code id="sm.density.compare_+3A_model">model</code></td>
<td>

<p>the default value is <code>"none"</code> which restricts comparison to
plotting only. The alternative value <code>"equal"</code> can produce a
bootstrap hypothesis test of equality and the display of an appropriate
reference band.
</p>
</td></tr>
<tr><td><code id="sm.density.compare_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code> function,
through a mechanism which limits their effect only to this call of the
function. Relevant parameters for this function are:
<code>method</code>, <code>df</code>, <code>band</code>, <code>test</code>, <code>nboot</code>,
plus those controlling graphical display (unless <code>display = "none"</code>
is set) such as <code>col</code>, <code>col.band</code>, <code>lty</code> and <code>lwd</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their description.
The parameter <code>nboot</code> controls the number of permutations used in the
permutation test.
</p>
</td></tr></table>


<h3>Details</h3>

<p>For a general description of  the methods involved, see Section 6.2 of the reference below.
</p>
<p>The colours and linetypes of the density estimates are set by <code>col</code> and <code>lty</code> which can be passed as additional arguments.  By default these are set to <code>1 + 1:ngroup</code>, where <code>ngroup</code> is the number of groups represented in the <code>group</code> variable.
</p>


<h3>Value</h3>

<p>A list is returned containing:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>a matrix whose rows contain the estimates for each group.</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>the grid of common evaluation points for the estimates.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>the common smoothing parameter used in the construction of the estimates.</p>
</td></tr>
<tr><td><code>levels</code></td>
<td>
<p>the levels of the group factor.</p>
</td></tr>
<tr><td><code>col</code>, <code>lty</code>, <code>lwd</code></td>
<td>
<p>plotting details which can be useful in constructing a legend for the plot; see the examples below.</p>
</td></tr>
</table>
<p>When <code>"model"</code> is set to <code>"equal"</code>, the output list also contains the p-value (<code>p</code>) of the test.  
</p>
<p>When <code>band = TRUE</code>, and there are only two groups to compare, the output list also contains the upper (<code>upper</code>) and lower (<code>lower</code>) edges of the reference band for equality.
</p>


<h3>Side Effects</h3>

<p>a plot on the current graphical device is produced, unless
<code>display="none"</code>.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). <em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.density">sm.density</a></code>, <code><a href="#topic+sm.ancova">sm.ancova</a></code>, <code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
g &lt;- rep(1:2, rep(50,2))
sm.density.compare(y, g)

comp &lt;- sm.density.compare(y, g, model = "equal")
legend("topleft", comp$levels, col = comp$col, lty = comp$lty, lwd = comp$lwd)
</code></pre>

<hr>
<h2 id='sm.discontinuity'>The detection of discontinuities in a regression curve or surface.
</h2><span id='topic+sm.discontinuity'></span>

<h3>Description</h3>

<p>This function uses a comparison of left and right handed nonparametric 
regression curves to assess the evidence for the presence of one or
more discontinuities in a regression curve or surface.  A hypothesis
test is carried out, under the assumption that the errors in the data 
are approximately normally distributed.  A graphical indication of the 
locations where the evidence for a discontinuity is strongest is also
available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.discontinuity(x, y, h, hd, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.discontinuity_+3A_x">x</code></td>
<td>

<p>a vector or two-column matrix of covariate values.
</p>
</td></tr>
<tr><td><code id="sm.discontinuity_+3A_y">y</code></td>
<td>

<p>a vector of responses observed at the covariate locations.
</p>
</td></tr>
<tr><td><code id="sm.discontinuity_+3A_h">h</code></td>
<td>

<p>a smoothing parameter to be used in the construction of the nonparametric
regression estimates.  A normal kernel
function is used and <code>h</code> is its standard deviation(s).  However, if
this argument is omitted <code>h</code> will be selected by an approximate
degrees of freedom criterion, controlled by the <code>df</code> parameter.
See <code>sm.options</code> for details.
</p>
</td></tr>
<tr><td><code id="sm.discontinuity_+3A_hd">hd</code></td>
<td>

<p>a smoothing parameter to be used in smoothing the differences of the
left and right sided nonparametric regression estimates.  A normal kernel
function is used and <code>hd</code> is its standard deviation(s).  However, if
this argument is omitted <code>hd</code> will be set to <code>h * sqrt(0.25)</code>, and
<code>h</code> reset to <code>h * sqrt(0.75)</code>, when <code>x</code> is a vector
When <code>x</code> is a matrix, <code>hd</code> will be set to <code>h * sqrt(0.5)</code>
and <code>h</code> will be reset to the same value.
</p>
</td></tr>
<tr><td><code id="sm.discontinuity_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function; those relevant for this function are 
<code>add</code>,
<code>eval.points</code>, 
<code>ngrid</code>, 
<code>se</code>, 
<code>band</code>,
<code>xlab</code>, 
<code>ylab</code>, 
<code>xlim</code>, 
<code>ylim</code>, 
<code>lty</code>,
<code>col</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their
description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The reference below describes the statistical methods used in the function.
There are minor differences in some computational details of the implementation.
</p>
<p>Currently duplicated rows of <code>x</code> cause a difficulty in the two covariate case.  Duplicated rows should be removed.
</p>


<h3>Value</h3>

<p>a list containing the following items
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>the p-value for the test of the null hypothesis that no
discontinuities are present.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the estimated standard deviation of the errors.</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>the evaluation points of the nonparametric
regression estimates.  When <code>x</code> is a matrix, 
<code>eval.points</code> is also a matrix whose columns
define the evaluation grid of each margin of the 
evaluation rectangle.</p>
</td></tr>
<tr><td><code>st.diff</code></td>
<td>
<p>a vector or matrix of standardised differences
between the left and right sided estimators at the 
evaluation points.</p>
</td></tr>
<tr><td><code>diffmat</code></td>
<td>
<p>when <code>x</code> is a vector, this contains the
locations and standardised differences where the latter
are greater than 2.5.</p>
</td></tr>
<tr><td><code>angle</code></td>
<td>
<p>when <code>x</code> is a matrix, this contains the estimated 
angles at which the standardised differences were constructed.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>the principal smoothing parameter.</p>
</td></tr>
<tr><td><code>hd</code></td>
<td>
<p>the smoothing parameter used for double-smoothing (see the
reference below).</p>
</td></tr>
</table>


<h3>Side Effects</h3>

<p>a plot on the current graphical device is produced, unless the option 
<code>display="none"</code> is set.  
</p>


<h3>References</h3>

<p>Bowman, A.W., Pope, A. and Ismail, B. (2006).
Detecting discontinuities in nonparametric regression curves and
surfaces.
<em>Statistics &amp; Computing</em>, 16, 377&ndash;390.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>par(mfrow = c(3, 2))

with(nile, {
   sm.discontinuity(Year, Volume, hd = 0)
   sm.discontinuity(Year, Volume)

   ind &lt;- (Year &gt; 1898)
   plot(Year, Volume)
   h &lt;- h.select(Year, Volume)
   sm.regression(Year[!ind], Volume[!ind], h, add = TRUE)
   sm.regression(Year[ ind], Volume[ ind], h, add = TRUE)

   hvec &lt;- 1:15
   p &lt;- numeric(0)
   for (h in hvec) {
      result &lt;- sm.discontinuity(Year, Volume, h,
                          display = "none", verbose = 0)
      p &lt;- c(p, result$p)
   }
   plot(hvec, p, type = "l", ylim = c(0, max(p)), xlab = "h")
   lines(range(hvec), c(0.05, 0.05), lty = 2)
})

with(trawl, {
   Position  &lt;- cbind(Longitude, Latitude)
   ind &lt;- (Longitude &lt; 143.8)
   # Remove a repeated point which causes difficulty with sm.discontinuity
   ind[54] &lt;- FALSE
   sm.regression(Position[ind,], Score1[ind], theta = 35, phi = 30)
   sm.discontinuity(Position[ind,], Score1[ind], col = "blue")
})
par(mfrow = c(1, 1))
	
#  The following example takes longer to run.
#  Alternative values for nside are 32 and 64.
#  Alternative values of yjump are 1 and 0.5.
# nside  &lt;- 16
# yjump  &lt;- 2
# x1     &lt;- seq(0, 1, length = nside)
# x2     &lt;- seq(0, 1, length = nside)
# x      &lt;- expand.grid(x1, x2)
# x      &lt;- cbind(x1 = x[, 1], x2 = x[, 2])
# y      &lt;- rnorm(nside * nside)
# ind    &lt;- (sqrt((x[, 1] - 0.5)^2 + (x[, 2] - 0.5)^2) &lt;= 0.25)
# y[ind] &lt;- y[ind] + yjump
# image(x1, x2, matrix(y, ncol = nside))
# sm.discontinuity(x, y, df = 20, add = TRUE)
</code></pre>

<hr>
<h2 id='sm.monotonicity'>
A test of monotonicity in a regression curve.
</h2><span id='topic+sm.monotonicity'></span>

<h3>Description</h3>

<p>This function uses the idea of a &lsquo;critical bandwidth&rsquo; to assess the 
evidence that a regression curve is non-monotonic.  A hypothesis
test is carried out by bootstrap methods and the empirical p-value
is reported.  Response variables on a continuous scale or with binomial
variation can be handled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.monotonicity(x, y, N = rep(1, length(y)), h, type = "continuous", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.monotonicity_+3A_x">x</code></td>
<td>

<p>a vector of covariate values.
</p>
</td></tr>
<tr><td><code id="sm.monotonicity_+3A_y">y</code></td>
<td>

<p>a vector of responses observed at the covariate locations.
</p>
</td></tr>
<tr><td><code id="sm.monotonicity_+3A_n">N</code></td>
<td>

<p>a vector of sample sizes at the covariate locations, when the
responses have a binomial error structure.
</p>
</td></tr>
<tr><td><code id="sm.monotonicity_+3A_h">h</code></td>
<td>

<p>a smoothing parameter to be used in the construction of the nonparametric
regression estimates.  A normal kernel
function is used and <code>h</code> is its standard deviation(s).  However, if
this argument is omitted <code>h</code> will be selected automatically, using
the <code>method</code> which is currently active.  See <code>sm.options</code> and 
<code>h.select</code> for details.
</p>
</td></tr>
<tr><td><code id="sm.monotonicity_+3A_type">type</code></td>
<td>

<p>an indicator of whether the response variable is on a <code>"continuous"</code>
or <code>"binomial"</code> scale.
</p>
</td></tr>
<tr><td><code id="sm.monotonicity_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function; some of those relevant for this function are 
<code>add</code>,
<code>ngrid</code>, 
<code>xlab</code>, 
<code>ylab</code>, 
<code>xlim</code>, 
<code>ylim</code>, 
<code>lty</code>,
<code>col</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their
description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The first reference below describes the statistical methods used in the function.
The test is an extension of one by Silverman (1986) for density estimation.
</p>


<h3>Value</h3>

<p>a list containing the following items
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>the p-value for the test of the null hypothesis that the
true curve is monotonic.</p>
</td></tr>
<tr><td><code>hcrit</code></td>
<td>
<p>the &lsquo;critical&rsquo; smoothing parameter.  This is the smallest
value which, when applied to the observed data, makes the 
curve monotonic.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>the smoothing parameter used for double-smoothing (see the
reference below).</p>
</td></tr>
</table>


<h3>Side Effects</h3>

<p>a plot of the curves generated by the bootstrap procedure is produced, 
unless the option <code>display="none"</code> is set.  Those curves which
are non-monotonic, and therefore contribute to the empirical p-value,
are drawn in red.
</p>


<h3>References</h3>

<p>Bowman, A.W., Jones, M.C. and Gijbels, I. (1998).
Testing monotonicity of regression.
<em>J.Comp.Graph.Stat.</em> 7, 489-500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
#     Radiocarbon dating data

with(radioc, {
   ind     &lt;- (Cal.age&gt;5000 &amp; Cal.age&lt;6000)
   cal.age &lt;- Cal.age[ind]
   rc.age  &lt;- Rc.age[ind]
   sm.monotonicity(cal.age, rc.age, method = "aicc", nboot = 200)
})

#     Hosmer &amp; Lemeshow birth data

with(birth, {
   sm.monotonicity(Lwt[Smoke == "N"], Low[Smoke == "N"],
          type = "binomial")
})

## End(Not run)</code></pre>

<hr>
<h2 id='sm.options'>Set or return options of sm library</h2><span id='topic+sm.options'></span>

<h3>Description</h3>

<p>This function provides a means to control the behaviour of the <code>sm</code> library such as the colour of the plotted lines, the size of the grid in 2-d estimation, the set of evaluations points, and many others.  A list may be given as the only argument, or any number of arguments may be in the <code>name=value</code> form.  If no arguments are specified then the function returns the current settings of all the arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.options(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.options_+3A_...">...</code></td>
<td>

<p>A list may be given as the only argument, or any number of arguments may be in the <code>name=value</code> form.  The valid names of the arguments are given below.
</p>
</td></tr>
</table>

<dl>
<dt>add</dt><dd>
<p>a logical value which controls whether the estimate is added to
the current plot.  Its default value is <code>FALSE</code>, which creates a new plot.
This argument applies only with one-dimensional data or to contour and <code>rgl</code>
created from two-dimensional data.
</p>
</dd>
<dt>alpha</dt><dd>
<p>a value, or a vector of values, lying between 0 and 1, which controls the transparency of the 
surfaces used to construct an <code>rgl</code> plot, when this form if display is requested.  In the case of regression with two covariates, a single value for <code>alpha</code> is used and the default is <code>0.7</code>.  In the case of density estimation with three variables, <code>alpha</code> should be set to a vector whose length matches the number of contours to be drawn (specified by the <code>props</code> argument).  In this case the default is <code>seq(1, 0.5, length = length(props))</code>.
</p>
</dd>
<dt>alpha.mesh</dt><dd>
<p>a parameter, lying between 0 and 1, which controls the transparency of the 
mesh lines used to construct an <code>rgl</code> plot for regression with two covariates.  
The default value is <code>1</code>.
</p>
</dd>
<dt>band</dt><dd>
<p>a logical value which controls whether the distance between the nonparametric
estimate and a reference model should be indicated as a band (one covariate),
or through colour painting of the regression surface (two covariates).  This
is activated only when a model has been nominated through the <code>model</code> 
parameter.  In the case of two covariates, the setting of the argument 
<code>col</code> has priority over <code>band</code>.  The setting <code>se = TRUE</code> can
also activate this feature.
</p>
</dd>
<dt>col</dt><dd>
<p>the colour used for plotting observed points and estimated curves.
Where groups are used, with one covariate, <code>col</code> may be set to a vector of
colours associated with the groups.  In regression with two covariates
using an <code>rgl</code> display, <code>col</code> may be set to a single colour,
or to the values <code>"height"</code> or <code>"se"</code>.  These latter two setting 
cause the surface to be painted according to its height or to standard 
error information; see the information on the parameters <code>se</code>,
<code>se.breaks</code> and <code>model</code>.
In the case of density estimation with three variables, <code>col</code> can be set to a vector whose length matches the number of contours to be drawn (specified by the <code>props</code> argument).
</p>
</dd>
<dt>col.band</dt><dd>
<p>the colour used for the reference band when a <code>model</code> is specified in regression with one covariate or in density estimation with a single variable.
Default: <code>col.band="cyan"</code>.
</p>
</dd>
<dt>col.mesh</dt><dd>
<p>the colour used for the &lsquo;wire mesh&rsquo; representation plotting observed points 
in an rgl display for regression with two covariates.  This can also be set by the
second component of a vector of length two which is set for <code>col</code>.
Default: <code>col.mesh="black"</code>.
</p>
</dd>
<dt>col.palette</dt><dd>
<p>the colours used for shading an image plot, or for surface painting in an rgl 
display, for regression with two covariates.
Default: <code>col.palette=topo.colors(12)</code>.
</p>
</dd>
<dt>col.points</dt><dd>
<p>the colour used for plotting observed points in a regression with one 
covariate or an <code>rgl</code> display for regression with two covariates.
Default: <code>col.points="black"</code>.
</p>
</dd>
<dt>delta</dt><dd><p>in <code>sm.density</code>,
a value which will be added to the data before they are log transformed in
the procedure to handle positive data.  The value of <code>delta</code> is used
only when <code>positive</code> takes the value <code>TRUE</code>.  The default value
is the smallest value observed in each dimension.  This argument does not
apply with three-dimensional data.
Default: <code>delta=NA</code>
</p>
</dd>
<dt>describe</dt><dd>
<p>logical flag which affects the behaviour of <code>sm.script</code> and
<code>provide.data</code>. 
If <code>describe=TRUE</code> (default), a data documentation file is printed. 
</p>
</dd>
<dt>df</dt><dd><p>approximate degrees-of-freedom of the smoothing parameter used in <code>sm.regression</code>, when a numerical value of <code>h</code> is not specified.  In this case, the equivalent value of <code>h</code> will be computed and included in the list returned on exit from <code>sm.regression</code>.  Default value is 6 if <code>x</code> is a vector and 12 if <code>x</code> is a matrix.
</p>
</dd>
<dt>diff.ord</dt><dd><p>in <code>sm.regression</code>,
an integer defining the degree of differencing to be applied in the
estimation process.
When this argument is set to 1, the method of Rice,
based on the squared differences of pairs of neighbouring observations,
is used.  When the argument is set to 2 (default), the method of Gasser, 
Sroka and Jennen-Steinmetz, based on differences between each observation 
and a linear interpolation from its two neighbours, is used.
</p>
</dd>
<dt>display</dt><dd>
<p>This argument applies only with one- or two-dimensional data.  The
setting <code>"none"</code> will prevent any graphical output from being
produced.  In one dimensions, the default setting <code>"line"</code> will
produce the estimate.  (For compatibility with earlier versions of the
package, the setting <code>"se"</code> will produce a variability band to
show the variability, but not the bias, of the estimate.  This should 
now be controlled by setting the separate parameter <code>se</code>
to <code>TRUE</code>.)  In two dimensions, the default setting
<code>"persp"</code> will produce a perspective plot of the estimate,
while the settings <code>"slice"</code>, <code>"image"</code>  and <code>"rgl"</code>
will produce slice (contour), image or <code>rgl</code> plots.
</p>
</dd>
<dt>eval.grid</dt><dd>
<p>logical flag which controls how the options <code>eval.points</code> are used for two-dimensional data. If <code>eval.grid=TRUE</code> (default), evaluation is performed at points obtained by the cross-product of the two columns of <code>eval.points</code>. If <code>eval.grid=FALSE</code> then evaluation is performed at points with coordinates specified by the coordinates in <code>eval.points</code>.
</p>
</dd>
<dt>eval.points</dt><dd>
<p>the points at which the density or the regression curve or surface estimate 
should be evaluated, for the values returned in the result of the function.  
This should be a vector for one-dimensional data and a two-column matrix 
for two-dimensional data.
This argument does not apply with three-dimensional data.
</p>
</dd>
<dt>h.weights</dt><dd> 
<p>a vector of weights which multiply the smoothing parameter used in the
kernel function at each observation.  This argument does not apply with 
three-dimensional data. Default value: 1.
</p>
</dd>
<dt>hmult</dt><dd>
<p>a factor which can be used to multiply the normal smoothing parameter
before construction of the density estimate. Default value: 1.
</p>
</dd>
<dt>hull</dt><dd>  
<p>a logical value which controls whether the estimate is evaluated and
plotted only on grid points which fall within the convex hull of the
data. When this argument is set to <code>FALSE</code>, evaluation and plotting
take place at all grid points where the contribution from at least one
kernel function is non-negligible.  Both of these settings ensure that
the estimate is not evaluated at points where there are no observations
nearby.  This argument applies only to <code>sm.regression</code> and
<code>sm.discontinuity</code> in the case of two covariates.
</p>
</dd>
<dt>lty</dt><dd>
<p>the line type used to plot the estimate.  This argument applies only
when the estimate is displayed as a curve or a contour.
Default value: 1.
</p>
</dd>
<dt>method</dt><dd>
<p>the method used to select smoothing parameters.  In density estimation
the default is <code>"normal"</code> which uses a value which is asymptotically
optimal for the normal distribution.  Other possibilities are <code>"cv"</code>
for cross-validation and, for one-dimensional data only, <code>"sj"</code> for the Sheather-Jones method.
</p>
<p>In nonparametric regression, the
default is <code>"df"</code> which selects a smoothing parameters associated
with the approximate degrees of freedom given in the <code>df</code> option.
Other possibilities are <code>"cv"</code> for cross-validation and
<code>"aicc"</code> for an AIC-based method proposed by Hurvich, Simonoff and
Tsai.
</p>
</dd>
<dt>nbins</dt><dd>
<p>the number of bins used in one-dimensional binning operations;
in two-dimensional cases, <code>nbins</code> refers to the number of bins 
formed along each axis. Bins with 0 observed frequencies are ignored.
If <code>nbins=0</code>, binning is not performed; if <code>nbins=NA</code> (default),
binning is switched on when the number of observations exceeds
a certain threshold, which depends on the function.
</p>
</dd>
<dt>nboot</dt><dd>
<p>number of samples generated in bootstraps. Default value: 100.
</p>
</dd>
<dt>ngrid</dt><dd>
<p>the number of points in the regular grid used to plot the estimate.
For two- and three-dimensional data, <code>ngrid</code> refers to the
number of points along the axis in each dimension.
The same parameter is also used by a few other functions which perform some
form of search (e.g. <code>hcv</code>).
Default value for <code>sm.regression</code>:
50 and 20 for 1-, 2-dimensional data, respectively.
Default value for <code>sm.density</code>:
100, 50 and 20 for 1-, 2- and 3-dimensional data, respectively.
</p>
</dd>
<dt>panel</dt><dd>
<p>a logical value which, when set to true, creates a panel which allows interactive
control of <code>sm.regression</code> or <code>sm.density</code> plots
for one- or two-dimensional data.  The panel can be used to alter the
value of the smoothing parameter and control a variety of other settings. 
</p>
</dd>
<dt>panel.plot</dt><dd>
<p>a logical value which, when set to true (the default), places the plot
inside the control panel (see the <code>panel</code> argument above),  This creates 
a neater screen arrangement.
</p>
</dd>
<dt>pch</dt><dd>
<p>the standard plotting character identified for data plotting.
Default value: 1.
</p>
</dd>
<dt>period</dt><dd>
<p>a vector of length one or two identifying the period for covariates which
are on a periodic scale.  Periodic smoothing is implemented by local mean
estimation, using a von Mises kernel function.  Non-periodic covariates are
identified by NA.
Default value: NA.
</p>
</dd>
<dt>phi</dt><dd>
<p>the vertical rotation (in degrees) of perspective plots of
estimate in the form of surfaces.  Default value: 40.
</p>
</dd>
<dt>poly.index</dt><dd>
<p>an integer defining local constant (0) or local linear (1) smoothing.
Default value: 1.
</p>
</dd>
<dt>positive</dt><dd>
<p>a logical value which indicates whether the data should be assumed to take
positive values only, in <code>sm.density</code>.
When this argument is set to <code>TRUE</code>, a log transformation
is applied to the data before construction of a density estimate.  The result
is transformed back to the original scale.  This argument does not apply with 
three-dimensional data. Default value: <code>FALSE</code>.
</p>
</dd>
<dt>props</dt><dd>
<p>a vector defining the proportions of the data to be included within each
contour in a slice plot, from two-dimensional data, or a contour surface
plot, from three-dimensional data.  In the three-dimensional case only
the first element of the vector will be used.  This argument does not apply 
to one-dimensional data.  Default value: <code>c(75,50,25)</code>.
</p>
</dd>
<dt>rugplot</dt><dd>
<p>logical flag which regulates whether a rugplot is superimposed to the
density estimate, in the univariate case. Default value: <code>TRUE</code>.
</p>
</dd>
<dt>se</dt><dd>
<p>logical flag which regulates whether a standard error information is
added to the plot produced by <code>sm.regression</code>. If a <code>model</code>
is specified, then these standard errors refer to the difference between
this fitted model and the nonparametric regression estimate.
Default value: <code>TRUE</code>.
</p>
</dd>
<dt>se.breaks</dt><dd>
<p>a numerical vector which defines the cut-points, on a standard error 
scale, for the assignment of colours when painting a regression surface
with standard error information.  Default value: <code>c(-3, -2, 3, 3)</code>.
</p>
</dd>
<dt>show.script</dt><dd>
<p>logical flag which affects the behaviour of <code>sm.script</code> when
this is called with non-empty   argument. If <code>show.script=TRUE</code>
(default) a window is opened to display the source code of the script.
</p>
</dd>
<dt>size</dt><dd>
<p>an integer which defines the size of plotted points in <code>rgl</code>
displays.  The default value is <code>2</code>.
</p>
</dd>
<dt>structure.2d</dt><dd>
<p>the structure of the smoothing parameter in two-dimensional settings.
The default is <code>"scaled"</code>, which uses the structure
(h*sd(x[,1]), h*sd(x[,2])).  Other possibilities are <code>"separate"</code>,
which uses (h1, h2), and <code>"common"</code> which uses (h, h).  The
<code>"common"</code> option may be particularly appropriate when the data
have a spatial origin, where distances in each variable have the same
meaning.  Note that the <code>"separate"</code> option is not available
when <code>"method"</code> is set to <code>"df"</code>.
</p>
</dd>
<dt>test</dt><dd>
<p>a logical flag controlling the production of a formal test, using the 
reference model as the null hypothesis. Default value: <code>TRUE</code>.
</p>
</dd>
<dt>theta</dt><dd>
<p>the horizontal rotation (in degrees) of perspective plots of
estimates in the form of surfaces.  Default value: -30.
</p>
</dd>
<dt>verbose</dt><dd>
<p>regulates the amount of messages and other output printed out.
If <code>verbose=0</code> only errors produce messages; if <code>verbose=1</code>
(default value) warnings  and the more relevant numerical
output are printed ; if <code>verbose=2</code> more messages and more
numerical output are printed.
</p>
</dd>
<dt>xlab</dt><dd>
<p>the label attached to the x-axis.
</p>
</dd>
<dt>xlim</dt><dd>
<p>the range of the horizontal axis of the plot.  This argument does not apply
with three-dimensional data.
</p>
</dd>
<dt>yht</dt><dd>
<p>the upper limit of the vertical axis in a plot of a one-dimensional density
estimate.  The lower limit is always set to 0.  This argument does not apply 
with two- or three-dimensional data.
</p>
</dd>
<dt>ylab</dt><dd>
<p>the label attached to the y-axis. 
</p>
</dd>
<dt>ylim</dt><dd>
<p>the range of the vertical axis of the plot.  This argument does not apply 
with three-dimensional data.
</p>
</dd>
<dt>zlab</dt><dd>
<p>the label attached to the z-axis (three-dimensional plots only).
</p>
</dd>
<dt>zlim</dt><dd>
<p>the range of the vertical axis when estimates are displayed as perspective plots.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Arguments which are set by a function call will remain in effect until the end of the current S-plus session, unless overwritten by a subsequent call.  In addition, they can be added as optional parameters of calls to specific functions of the <code>sm</code> package; in this case, their effect is
limited to that function call.  
</p>
<p>See the documentation of specific functions for the list of options which are recognised by that function.  Notice that some options are relevant only to some functions.
</p>


<h3>Value</h3>

<p>a list with  the updated values of the parameters. If the argument list is not empty, the returned list is invisible.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: sm.options(poly.index = 0)
# subsequent regression estimations will be performed using local means
# instead of local regression
#
sm.options(describe = FALSE)  
# turns off typing documentation files of data loaded by `sm.script'
# (works from command-line)
# 

## End(Not run)</code></pre>

<hr>
<h2 id='sm.pca'>
Smooth principal components analysis
</h2><span id='topic+sm.pca'></span>

<h3>Description</h3>

<p>This function calculates principal components in a manner which changes 
smoothly with a covariate.  The smooth eigenvalues and eigenvector
loadings can be plotted.  A permutation test of equality of the components,
both eigenvalues and eigenvectors, can be carried out.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.pca(x, Y, h, cor = TRUE, nperm = 100, pc = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.pca_+3A_x">x</code></td>
<td>

<p>either a vector of covariate values or a list object which is the output of a previous call to <code>sm.pca</code>.  In the latter case, previously computed information is used to create plots and tests and the arguments <code>Y</code>, <code>h</code>, <code>cor</code> and <code>nperm</code> are not required.
</p>
</td></tr>
<tr><td><code id="sm.pca_+3A_y">Y</code></td>
<td>

<p>a matrix of responses whose rows correspond to the covariate values.
</p>
</td></tr>
<tr><td><code id="sm.pca_+3A_h">h</code></td>
<td>

<p>the smoothing parameter which controls the smoothness of estimation with respect to the covariate <code>x</code>.
</p>
</td></tr>
<tr><td><code id="sm.pca_+3A_cor">cor</code></td>
<td>

<p>a logical value indicating whether the correlation, rather than covariance, matrix should be used.
</p>
</td></tr>
<tr><td><code id="sm.pca_+3A_nperm">nperm</code></td>
<td>

<p>the number of permutations used in the permutation test and graphical reference band.
</p>
</td></tr>
<tr><td><code id="sm.pca_+3A_pc">pc</code></td>
<td>

<p>an integer value indicating the component to be plotted against the covariate.
</p>
</td></tr>
<tr><td><code id="sm.pca_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function. Those relevant for this function are the following:
<code>display</code> (here set to <code>"eigevalues"</code> or <code>"eigenvectors"</code>)
<code>ngrid</code>,
<code>xlab</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their description.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several further arguments may be set and these are passed to <code>sm.options</code>.  Relevant arguments for this function are <code>display</code> (<code>"eigenvalues"</code>, <code>"eigenvectors"</code>), <code>ngrid</code> and <code>df</code>.  See <code>link{sm.options}</code> for further details.
</p>
<p>The smoothing is performed by the local constant kernel method and the smoothing parameter corresponds to the standard deviation of a normal kernel function.  If <code>h</code> is left unspecified then it is selected to correspond to the degrees of freedom set by the parameter <code>df</code>.
</p>
<p>The reference band for a constant eigenvalue is constructed from the upper and lower pointwise 2.5 percentiles of the smooth eigenvalue curves from the data with permuted covariate values.  The p-value compares the observed value of the difference between the smoothed and constant eigenvalues, summed over the covariate grid in <code>eval.points</code>, with the values generated from the permuted data.
</p>
<p>In the eigenvector case, a reference band is computed from the percentiles of the curves from the permuted data, for each of the loadings.  In order to plot all the loadings curves simultaneously, the locations where each curve lies inside its respective reference band are indicated by pale colour.  The p-value compares the observed value of <code>1 - sum(e*e0)^2</code>, where <code>e</code> and <code>e0</code> are the eigenvectors under the smooth and constant scenarios (summed over the covariate grid), with the values generated from the permuted data.  This test statistic differs from the one described in the Miller and Bowman (2012) reference below.  It has been used as it conveniently handles the arbitrary sign of principal components.
</p>
<p>When some components explain similar proportions of variance, the eigenvalues and eigenvectors can easily interchange, causing apparent sharp changes in the eigenvalue and eigenvector curves.  It is difficult to track the components to avoid this.
</p>


<h3>Value</h3>

<p>a list with the following components:
</p>

<dl>
<dt>xgrid</dt><dd><p>a vector of values on the covariate scale at which the smooth estimates are constructed.</p>
</dd>
<dt>evals</dt><dd><p>a matrix whose columns give the smooth eigenvalues for each component at the covariate values.</p>
</dd>
<dt>evecs</dt><dd><p>a three-dimensional array whose third dimension corresponds to the covariate values and whose second dimension indexes the smooth components.</p>
</dd>
<dt>mhat</dt><dd><p>a matrix whose columns give the estimated smooth means for each dimension of <code>Y</code> at the covariate values.</p>
</dd>
<dt>var.explained</dt><dd><p>a matrix whose rows give the proportions of variance explained by each component at each covariate value.</p>
</dd>
<dt>xlab</dt><dd><p>the label attached to the x-axis.</p>
</dd>
<dt>h</dt><dd><p>the smoothing parameter used.</p>
</dd>
<dt>x</dt><dd><p>the covariate values, after removal of missing cases.</p>
</dd>
<dt>Y</dt><dd><p>the matrix of response values, after removal of missing cases.</p>
</dd>
<dt>cor</dt><dd><p>a logical indicator of whether the correlation, rather than covariance, matrix is used in the construction of the eigenvalues and eigenvectors.</p>
</dd>
</dl>

<p>When a test or reference band is computed, the list has the additional components:
</p>

<dl>
<dt>nperm</dt><dd><p>the number of permutations used.</p>
</dd>
<dt>evals.perm</dt><dd><p>the eigenvalues computed from the permuted data.</p>
</dd>
<dt>evecs.perm</dt><dd><p>the eigenvectors computed from the permuted data.</p>
</dd>
</dl>

<p>When display contains <code>"eigenvalues"</code> or <code>"eigenvectors"</code>, the list has the additional components:
</p>

<dl>
<dt>p.values</dt><dd><p>the p-value for a test of constant eigenvalue for the component identified by <code>pc</code>.</p>
</dd>
<dt>p.vectors</dt><dd><p>the p-value for a test of constant eigenvectors for the component identified by <code>pc</code>.</p>
</dd>
</dl>

<p>When display contains <code>"eigenvalues"</code>, the list has the additional component:
</p>

<dl>
<dt>band</dt><dd><p>a matrix whose two columns contain the boundaries of a reference band which indicates where the smooth eigenvalue curve should like if the hypothesis of no change in the eigenvalues with the covariate is correct.</p>
</dd>
</dl>

<p>When display contains <code>"eigenvectors"</code>, the list has the additional components:
</p>

<dl>
<dt>xgrid.plot</dt><dd><p>a vector of values used for plotting the smooth eigenvectors.</p>
</dd>
<dt>evecs.plot</dt><dd><p>a matrix whose rows contain the smooth eigenvectors at each value of <code>xgrid.plot</code>.</p>
</dd>
<dt>evecs.plot</dt><dd><p>a matrix whose columns contain the colours for the line segments in each smooth eigenvector component.</p>
</dd>
</dl>



<h3>Side Effects</h3>

<p>a plot on the current graphical device is produced, unless <code>display="none"</code>
</p>


<h3>References</h3>

<p>Miller, C. and Bowman, A.W. (2012). 
Smooth principal components for investigating changes in covariances over time.
<em>Applied Statistics</em> <b>61</b>, 693&ndash;714.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Y    &lt;- log(as.matrix(aircraft[ , -(1:2)]))
year &lt;- aircraft$Yr
h    &lt;- h.select(year, Y[ , 1], method = "df", df = 4)
spca &lt;- sm.pca(year, Y, h, display = "none")
sm.pca(year, Y, h, display = "eigenvalues")
sm.pca(year, Y, h, display = "eigenvectors", ylim = c(-1, 1))

# The following code shows how the plots can be redrawn from the returned object

spca &lt;- sm.pca(year, Y, h, display = "eigenvalues")
spca &lt;- sm.pca(year, Y, h, display = "eigenvectors", ylim = c(-1, 1))

with(spca, {
   ylim &lt;- range(evals[ , 1], band)
   plot(xgrid, evals[ , 1], type = "n", ylab = "Variance", ylim = ylim)
   polygon(c(xgrid, rev(xgrid)), c(band[ , 1], rev(band[ , 2])),
           col = "lightgreen", border = NA)
   lines(xgrid, evals[ , 1], col = "red")
})

with(spca, {
   pc &lt;- 1
   plot(range(xgrid.plot), range(evecs.plot), type = "n",
        xlab = "x", ylab = "PC loadings")
   for (i in 1:ncol(Y))
      segments(xgrid.plot[-length(xgrid.plot)],
               evecs.plot[-nrow(evecs.plot), i],
               xgrid.plot[-1], evecs.plot[-1, i],
               col = col.plot[ , i], lty = i)
})

## End(Not run)
</code></pre>

<hr>
<h2 id='sm.poisson'>
Nonparametric Poisson regression
</h2><span id='topic+sm.poisson'></span>

<h3>Description</h3>

<p>This function estimates the regression curve using the local likelihood
approach for a vector of Poisson observations and an associated vector
of covariate values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.poisson(x, y, h, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.poisson_+3A_x">x</code></td>
<td>

<p>vector of the covariate values
</p>
</td></tr>
<tr><td><code id="sm.poisson_+3A_y">y</code></td>
<td>

<p>vector of the response values; they must be nonnegative integers.
</p>
</td></tr>
<tr><td><code id="sm.poisson_+3A_h">h</code></td>
<td>

<p>the smoothing parameter; it must be positive.
</p>
</td></tr>
<tr><td><code id="sm.poisson_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code> function,
through a mechanism which limits their effect only to this call of the
function. Those specifically relevant for this function are the following:
<code>add</code>, 
<code>col</code>, 
<code>display</code>, 
<code>eval.points</code>,
<code>nbins</code>, 
<code>ngrid</code>, 
<code>pch</code>, 
<code>xlab</code>, 
<code>ylab</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Sections 3.4 and 5.4 of the reference below.
</p>


<h3>Value</h3>

<p>A list containing vectors with the evaluation points, the corresponding
probability estimates, the linear predictors, the upper and lower points
of the variability bands  and the standard errors on the linear predictor 
scale.
</p>


<h3>Side Effects</h3>

<p>graphical output will be produced, depending on the value of the
<code>display</code> option.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997).
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.binomial">sm.binomial</a></code>, <code><a href="#topic+sm.binomial.bootstrap">sm.binomial.bootstrap</a></code>,
<code><a href="#topic+binning">binning</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(muscle, {
   TypeI &lt;- TypeI.R+ TypeI.P+TypeI.B
   sm.poisson(x=log(TypeI), y=TypeII, h=0.25,display="se")
   sm.poisson(x=log(TypeI), y=TypeII, h=0.75, col=2, add=TRUE)
})
</code></pre>

<hr>
<h2 id='sm.poisson.bootstrap'>
Bootstrap goodness-of-fit test for a Poisson regression model
</h2><span id='topic+sm.poisson.bootstrap'></span>

<h3>Description</h3>

<p>This function is associated with <code>sm.poisson</code> for the underlying
fitting procedure. It performs a Pseudo-Likelihood Ratio Test for the
goodness-of-fit of a standard parametric Poisson regression of specified
<code>degree</code> in the covariate <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.poisson.bootstrap(x, y, h,  degree = 1,
          fixed.disp = FALSE, intercept = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.poisson.bootstrap_+3A_x">x</code></td>
<td>

<p>vector of the covariate values
</p>
</td></tr>
<tr><td><code id="sm.poisson.bootstrap_+3A_y">y</code></td>
<td>

<p>vector of the response values; they must be nonnegative integers.
</p>
</td></tr>
<tr><td><code id="sm.poisson.bootstrap_+3A_h">h</code></td>
<td>

<p>the smoothing parameter; it must be positive.
</p>
</td></tr>
<tr><td><code id="sm.poisson.bootstrap_+3A_degree">degree</code></td>
<td>

<p>specifies the degree of the fitted polynomial in <code>x</code> on the logarithm scale
(default=1).
</p>
</td></tr>
<tr><td><code id="sm.poisson.bootstrap_+3A_fixed.disp">fixed.disp</code></td>
<td>
<p>if <code>TRUE</code>, the dispersion
parameter is kept at value 1 across the simulated samples, otherwise
the dispersion parameter estimated from the sample is used to generate
samples with that dispersion parameter (default=<code>FALSE</code>).
</p>
</td></tr>
<tr><td><code id="sm.poisson.bootstrap_+3A_intercept">intercept</code></td>
<td>
<p><code>TRUE</code> (default) if an intercept is to be included
in the fitted model.</p>
</td></tr>
<tr><td><code id="sm.poisson.bootstrap_+3A_...">...</code></td>
<td>

<p>additional parameters passed to <code><a href="#topic+sm.poisson">sm.poisson</a></code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Section 5.4 of the reference below.
</p>


<h3>Value</h3>

<p>a list containing the observed value of the Pseudo-Likelihood Ratio Test
statistic, its observed p-value as estimated via the bootstrap method,
and the vector of estimated dispersion parameters when this value is not 
forced to be 1.
</p>


<h3>Side Effects</h3>

<p>Graphical output representing the bootstrap samples is produced on 
the current graphical device. 
The estimated dispersion parameter, the value of the test statistic
and the observed significance level are printed.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis:</em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.poisson">sm.poisson</a></code>, <code><a href="#topic+sm.binomial.bootstrap">sm.binomial.bootstrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## takes a while: extend sm.script(muscle)
with(muscle, {
   TypeI &lt;- TypeI.P + TypeI.R + TypeI.B
   sm.poisson.bootstrap(log(TypeI), TypeII, h = 0.5)
})
</code></pre>

<hr>
<h2 id='sm.regression'>Nonparametric regression with one or two covariates.</h2><span id='topic+sm.regression'></span>

<h3>Description</h3>

<p>This function creates a nonparametric regression estimate from data 
consisting of a single response variable and one or two covariates.
In two dimensions a perspective, image (<code>image</code>), contour (<code>slice</code>) 
or <code>rgl</code> plot of the estimated regression surface is produced.  
A number of other features of the construction of the estimate, and of 
its display, can be controlled.
</p>
<p>If the <code>rpanel</code> package is available, an interactive panel can be activated
to control various features of the plot.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'> sm.regression(x, y, h, design.mat = NA, model = "none", weights = NA,
                 group = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.regression_+3A_x">x</code></td>
<td>
<p>a vector, or two-column matrix, of covariate values.</p>
</td></tr>
<tr><td><code id="sm.regression_+3A_y">y</code></td>
<td>
<p>a vector of responses.</p>
</td></tr>
<tr><td><code id="sm.regression_+3A_h">h</code></td>
<td>
<p>a vector of length 1 or 2 giving the smoothing parameter.  A normal kernel
function is used and <code>h</code> is its standard deviation.</p>
</td></tr>
<tr><td><code id="sm.regression_+3A_design.mat">design.mat</code></td>
<td>
<p>the design matrix used to produce <code>y</code> when these are assumed to be the 
residuals from a linear model.</p>
</td></tr>
<tr><td><code id="sm.regression_+3A_model">model</code></td>
<td>
<p>a character variable which defines a reference model.  The settings
<code>"none"</code>, <code>"no effect"</code> and <code>"linear"</code> and all valid.  Note that
when a <code>group</code> argument is used then <code>model</code> should be set to 
<code>"equal"</code> or <code>"parallel"</code>, as befits an analysis of covariance model.</p>
</td></tr>
<tr><td><code id="sm.regression_+3A_weights">weights</code></td>
<td>
<p>a vector  which allows the kernel functions associated with the observations 
to take different weights.  This is useful, in particular, when different
observations have different precisions.
The normal usage of this parameter is to associate observations with
frequencies; if the  <code>weights</code> are not integers, they are converted
to  integers, but in this case the standard errors and tests which are
computed cannot be considered.
This argument applies only to the case of one covariate.
Use of this parameter is incompatible with <code>binning</code>; hence
<code>nbins</code> must then be set to 0 or left at its default value <code>NA</code>.</p>
</td></tr>
<tr><td><code id="sm.regression_+3A_group">group</code></td>
<td>
<p>a vector of groups indicators (numeric or character values) or
a factor.  If this argument is used then the data are passed to the <code>sm.ancova</code>
function.  See the details of the <code>model</code> argument above in that case.</p>
</td></tr>
<tr><td><code id="sm.regression_+3A_...">...</code></td>
<td>
<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function; those relevant for this function are the following:
<code>display</code>,
<code>hmult</code>,
<code>h.weights</code>,
<code>poly.index</code>,
<code>band</code>,
<code>add</code>,
<code>ngrid</code>,
<code>eval.points</code>,
<code>se</code>,
<code>se.breaks</code>,
<code>period</code>,
<code>xlab</code>,
<code>ylab</code>,
<code>zlab</code>,
<code>hull</code>,
<code>panel</code>,
<code>panel.plot</code>,
<code>lty</code>,
<code>col</code>,
<code>col.band</code>,
<code>col.mesh</code>,
<code>col.points</code>,
<code>col.palette</code>;
see the documentation of <code><a href="#topic+sm.options">sm.options</a></code> for their description.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>display</code> is set to <code>"persp"</code> or <code>"rgl"</code>, a number of 
graphical options are available.  By setting the <code>col</code> parameter to
<code>"height"</code> or <code>"se"</code>, the surface will be painted by colours to
reinforce the perception of height or indicate the relative sizes of the
standard errors respectively.  When <code>model</code> is not <code>"none"</code>, 
the colour coding refers to the number of standard errors which separate
the smooth regression surface and the nominated model at each position.
The parameter <code>"se.breaks"</code>, whose default value is <code>c(-3, -2, 3, 3)</code> 
can then be used to set the colour ranges.  In this case, <code>col.palette</code>
must be set to a list of colours whose length is one greater than the length
of the cut-points in <code>"se.breaks"</code>.  If this is not the case, the
default colour palette 
<code>rev(rainbow(length(opt$se.breaks) + 1, start = 0/6, end = 4/6))</code>.
</p>
<p>If the argument <code>col</code> is not set then surface painting will be determined
by the setting of <code>se</code>.  If neither is set then colour painting will be
activated by default if <code>model != "none"</code>. (In this latter case, the
argument <code>band</code>, retained from earlier versions for compatibility, will
also be examined.)
</p>
<p>When <code>display</code> is set to <code>"rgl"</code>, some additional parameters
can be used to control details of the plot.  Transparency can be set by
<code>alpha</code>, which lies between <code>0</code> and <code>1</code>.  When <code>alpha</code>
is set to a vector of length two, the first component refers to the surface
panels and the second to the surface mesh.  Setting a component of <code>alpha</code>
to <code>0</code> will remove the corresponding feature from the plot.  <code>col.mesh</code>,
whose valid values match those of <code>col</code>, controls the colour of the surface
mesh.  The logical parameter <code>lit</code> has the same meaning as in the <code>rgl</code>
package; see <code>material3d</code>.
</p>
<p>When <code>panel</code> is set to <code>"TRUE"</code>, an interactive control panel is
created if the <code>rpanel</code> package is available.
</p>
<p>If a covariate is on a cyclical scale, this can be incorporated by setting
the <code>period</code> argument to a vector (of length 1 or 2) whose components give 
the values of the periods, or NA if the covariate is not periodic.
</p>
<p>See Chapters 3, 4 and 5 of the first reference below for the details of the
construction of the estimate and its standard error.  The second reference
gives further details and examples of surface painting.
</p>


<h3>Value</h3>

<p>a list containing the values of the estimate at the evaluation points,
the smoothing parameter and the smoothing parameter weights.
If a reference model has been specified and <code>test</code> set to
<code>TRUE</code>, then the p-value of the test
is also returned.  When there is only one covariate, the weights associated
with different observations, an estimate of the error standard deviation and 
the standard error of the estimate are also returned.  If a reference model 
has been specified, this standard error refers to the comparison between 
the estimate and the reference model, and the values defining the reference 
model are also returned.
If an <code>rgl</code> display is used, then the indices of the surface and lines
used to create the display are returned.
</p>


<h3>Side Effects</h3>

<p>a plot on the current graphical device is produced, unless the option 
<code>display="none"</code> is set.  
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis:</em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>
<p>Bowman, A.W. (2006).
Comparing nonparametric surfaces.
<em>Statistical Modelling</em>, 6, 279-299.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hcv">hcv</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+sm.ancova">sm.ancova</a></code>,
<code><a href="#topic+sm.binomial">sm.binomial</a></code>, <code><a href="#topic+sm.poisson">sm.poisson</a></code>,
<code><a href="#topic+sm.regression.autocor">sm.regression.autocor</a></code>, <code><a href="#topic+sm.survival">sm.survival</a></code>,
<code><a href="#topic+sm.options">sm.options</a></code>, <code><a href="#topic+sm.surface3d">sm.surface3d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(trawl, {
   Zone92   &lt;- (Year == 0 &amp; Zone == 1)
   Position &lt;- cbind(Longitude - 143, Latitude)
   dimnames(Position)[[2]][1] &lt;- "Longitude - 143"

   par(mfrow = c(2, 2))
   sm.regression(Longitude, Score1, method = "aicc", col = "red",
       model = "linear")
   sm.regression(Position[Zone92, ], Score1[Zone92], display = "image", 
       theta = 120)
   sm.regression(Position[Zone92, ], Score1[Zone92], df = 12, col = "se",
       theta = 120)
   sm.regression(Position[Zone92, ], Score1[Zone92], df = 12, col = "se", 
       model = "linear", theta = 120)
   par(mfrow = c(1, 1))
})

# sm.regression(Position[Zone92, 2:1], Score1[Zone92], display = "rgl", df = 12)
# sm.regression(Position[Zone92, 2:1], Score1[Zone92], display = "rgl", df = 12,
#       alpha = c(0.9, 1), col = "se", model = "linear")

# sm.regression(Position[Zone92, 1], Score1[Zone92], panel = TRUE)
# sm.regression(Position[Zone92,  ], Score1[Zone92], panel = TRUE)
# sm.regression(Position[Zone92,  ], Score1[Zone92], panel = TRUE, display = "rgl")

</code></pre>

<hr>
<h2 id='sm.regression.autocor'>
Nonparametric regression with autocorrelated errors
</h2><span id='topic+sm.regression.autocor'></span>

<h3>Description</h3>

<p>This function estimates nonparametrically the regression function
of <code>y</code> on <code>x</code> when the error terms are serially correlated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.regression.autocor(x = 1:n, y, h.first, minh, maxh, method = "direct", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.regression.autocor_+3A_y">y</code></td>
<td>

<p>vector of the response values
</p>
</td></tr>
<tr><td><code id="sm.regression.autocor_+3A_h.first">h.first</code></td>
<td>

<p>the smoothing parameter used for the initial smoothing stage.
</p>
</td></tr>
<tr><td><code id="sm.regression.autocor_+3A_x">x</code></td>
<td>

<p>vector of the covariate values; if unset, it is assumed to
be <code>1:length(y)</code>.
</p>
</td></tr>
<tr><td><code id="sm.regression.autocor_+3A_minh">minh</code></td>
<td>

<p>the minimum value of the interval where the optimal smoothing parameter
is searched for (default is 0.5).
</p>
</td></tr>
<tr><td><code id="sm.regression.autocor_+3A_maxh">maxh</code></td>
<td>

<p>the maximum value of the interval where the optimal smoothing parameter
is searched for (default is 10).
</p>
</td></tr>
<tr><td><code id="sm.regression.autocor_+3A_method">method</code></td>
<td>

<p>character value which specifies the optimality criterium adopted;
possible values are <code>"no.cor"</code>, <code>"direct"</code> (default),
and <code>"indirect"</code>.
</p>
</td></tr>
<tr><td><code id="sm.regression.autocor_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function. Those relevant for this function are the following:
<code>ngrid</code>,
<code>display</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Section 7.5 of the reference below.
</p>


<h3>Value</h3>

<p>a list as returned from sm.regression called with the new value of
smoothing parameter, with an additional term <code>$aux</code> added which contains
the initial value <code>h.first</code>, the estimated curve using <code>h.first</code>, 
the autocorrelation function of the residuals from the initial fit, 
and the residuals.
</p>


<h3>Side Effects</h3>

<p>a new suggested value for <code>h</code> is printed; also, if the parameter <code>display</code>
is not equal to <code>"none"</code>, graphical output is produced on the current 
graphical device.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.autoregression">sm.autoregression</a></code>
</p>

<hr>
<h2 id='sm.rm'>
Nonparametric analysis of repeated measurements data
</h2><span id='topic+sm.rm'></span>

<h3>Description</h3>

<p>This function estimates nonparametrically the mean profile from a matrix
<code>y</code> which is assumed to contain repeated measurements (i.e. longitudinal
data) from a set of individuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.rm(Time, y, minh = 0.1, maxh = 2, optimize = FALSE,
      rice.display = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.rm_+3A_y">y</code></td>
<td>

<p>matrix containing the values of the response variable, with rows associated 
to individuals and columns associated to observation times.
</p>
</td></tr>
<tr><td><code id="sm.rm_+3A_time">Time</code></td>
<td>

<p>a vector containing the observation times of the response variable, assumed 
to be the same for all individuals of matrix <code>y</code>. 
If <code>Time</code> is not given, this is assumed to be <code>1:ncol(y)</code>.
</p>
</td></tr>
<tr><td><code id="sm.rm_+3A_minh">minh</code></td>
<td>

<p>the minimum value of the interval where the optimal value of the smoothing
parameter is searched according to the modified Rice criterion.
See reference below for details.
</p>
</td></tr>
<tr><td><code id="sm.rm_+3A_maxh">maxh</code></td>
<td>

<p>the maximum value of the above interval.
</p>
</td></tr>
<tr><td><code id="sm.rm_+3A_optimize">optimize</code></td>
<td>

<p>Logical value, default is <code>optimize=FALSE</code>. If
<code>optimize=TRUE</code>, then a full 
optimization is performed after searching the interval <code>(minh,maxh)</code>
using the optimizer <code>optim</code>.
</p>
</td></tr>
<tr><td><code id="sm.rm_+3A_rice.display">rice.display</code></td>
<td>

<p>If this set to <code>TRUE</code> (default is <code>FALSE</code>), a plot is
produced of the curve 
representing the modified Rice criterion for bandwidth selection. 
See reference below for details.
</p>
</td></tr>
<tr><td><code id="sm.rm_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function; those relevant for this function are the following:
</p>

<dl>
<dt>add</dt><dd>
<p>logical value, default is <code>add=FALSE</code>. If <code>add=TRUE</code> and
display is not set to <code>"none"</code>, then graphical output added
to the existing plot, rather than starting a new one.
</p>
</dd>
<dt>display</dt><dd>
<p>character value controlling the amount of graphical output of the estimated 
regression curve. It has the same meaning as in <code>sm.regression</code>. 
Default value is <code>display="lines"</code>.
</p>
</dd>
<dt>ngrid</dt><dd>
<p>the number of divisions of the above interval to be considered. 
Default: <code>ngrid=20</code>.
</p>
</dd>
<dt>poly.index</dt><dd>
<p>overall degree  of  locally-fitted  polynomial, as used by
<code>sm.regression</code>. Default: <code>ngrid=1</code>.
</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>see Section 7.4 of the reference below.
</p>


<h3>Value</h3>

<p>a list containing the returned value produced by <code>sm.regression</code> when 
smoothing the mean response value at each given observation time, 
with an extra component <code>$aux</code> added to the list.
This additional component  is a list itself containing the mean value at each 
observation time, the residual variance of the residuals from the estimated 
regression curve,  the autocorrelation function of the residuals, and 
the value <code>h</code> of the chosen smoothing parameter. 
</p>


<h3>Side Effects</h3>

<p>if the parameter display is not set to <code>"none"</code>, a plot of the estimated 
regression curve is produced; 
other aspects are controlled by the optional parameters (<code>...</code>). 
If <code>rice.display=TRUE</code>, a plot of the modified Rice criterion is shown.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.regression.autocor">sm.regression.autocor</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sm.rm(y=as.matrix(citrate), display.rice=TRUE)
#
with(dogs, {
   Time &lt;- seq(1,13,by=2)
   gr1  &lt;- as.matrix(dogs[dogs$Group==1,2:8])
   plot(c(1,13), c(3,6),xlab="time", ylab="potassium", type="n") 
   sm1  &lt;- sm.rm(Time, gr1, display="se", add=TRUE)
})
</code></pre>

<hr>
<h2 id='sm.script'>
Running a script associated to the sm library
</h2><span id='topic+sm.script'></span>

<h3>Description</h3>

<p>This is a utility function to run scripts, usually those associated 
with the book described below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.script(name, path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.script_+3A_name">name</code></td>
<td>

<p>the name of the file containing the code; a <code>.q</code> suffix will be appended
to the name. If <code>name</code> is missing, a list of the scripts associated to
the <code>sm</code> library will be displayed.
</p>
</td></tr>
<tr><td><code id="sm.script_+3A_path">path</code></td>
<td>

<p>the name of the path where to look for the script. If <code>path</code> is missing,
it is assumed to be the appropriate location for the scripts of the <code>sm</code>
library.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This utility allows the illustrations of the reference below to be reproduced
easily, since each of them has an associated script.  The display of the
script file itself is controlled by the setting of the logical variable
<code>show.script</code> in <code>sm.options</code>.  This is set to <code>TRUE</code> by default.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis: </em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm">sm</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sm.script()
sm.script(speed)
</code></pre>

<hr>
<h2 id='sm.sigma'>Estimation of the error standard deviation in nonparametric regression.</h2><span id='topic+sm.sigma'></span>

<h3>Description</h3>

<p>This function estimates the error standard deviation in nonparametric
regression with one or two covariates.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.sigma(x, y, rawdata = NA, weights = rep(1, length(y)), 
               diff.ord = 2, ci = FALSE, model = "none", h = NA, ...)
       </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.sigma_+3A_x">x</code></td>
<td>
<p>a vector or two-column matrix of covariate values.</p>
</td></tr>
<tr><td><code id="sm.sigma_+3A_y">y</code></td>
<td>
<p>a vector of responses.</p>
</td></tr>
<tr><td><code id="sm.sigma_+3A_rawdata">rawdata</code></td>
<td>
<p>a list containing the output from a binning operation.
This argument is used by <code>sm.regression</code> and it need not be
set for direct calls of the function.</p>
</td></tr>
<tr><td><code id="sm.sigma_+3A_weights">weights</code></td>
<td>
<p>a list of frequencies associated with binned data.
This argument is used by <code>sm.regression</code> and it need not be
set for direct calls of the function.</p>
</td></tr>
<tr><td><code id="sm.sigma_+3A_diff.ord">diff.ord</code></td>
<td>
<p>an integer value which determines first (1) or second (2)
differencing in the estimation of sigma.</p>
</td></tr>
<tr><td><code id="sm.sigma_+3A_ci">ci</code></td>
<td>
<p>a logical value which controls whether a confidence interval is
produced.</p>
</td></tr>
<tr><td><code id="sm.sigma_+3A_model">model</code></td>
<td>
<p>a character variable.  If this is set to <code>"constant"</code>
then a test of constant variance over the covariates is performed
(only in the case of two covariates)</p>
</td></tr>
<tr><td><code id="sm.sigma_+3A_h">h</code></td>
<td>
<p>a vector of length two defining a smoothing parameter to be used
in the test of constant variance.</p>
</td></tr>
<tr><td><code id="sm.sigma_+3A_...">...</code></td>
<td>
<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function; the only one relevant for this function is
<code>nbins</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see the reference below.</p>


<h3>Value</h3>

<p>a list containing the estimate and, in the two covariate case, a 
matrix which can be used by the function <code>sm.sigma2.compare</code>, 
pseudo-residuals and, if appropriate, a confidence interval and 
a p-value for the test of constant variance.</p>


<h3>Side Effects</h3>

<p>none.</p>


<h3>References</h3>

<p>Bock, M., Bowman, A.W. &amp; Ismail, B. (2007).
Estimation and inference for error variance in bivariate 
nonparametric regression.
<em>Statistics &amp; Computing</em>, to appear.</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.sigma2.compare">sm.sigma2.compare</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(airquality, {
   x     &lt;- cbind(Wind, Temp)
   y     &lt;- Ozone^(1/3)
   group &lt;- (Solar.R &lt; 200)
   sig1 &lt;- sm.sigma(x[ group, ], y[ group], ci = TRUE)
   sig2 &lt;- sm.sigma(x[!group, ], y[!group], ci = TRUE)
   print(c(sig1$estimate, sig1$ci))
   print(c(sig2$estimate, sig2$ci))
   print(sm.sigma(x[ group, ], y[ group], model = "constant", h = c(3, 5))$p)
   print(sm.sigma(x[!group, ], y[!group], model = "constant", h = c(3, 5))$p)
   print(sm.sigma2.compare(x[group, ], y[group], x[!group, ], y[!group]))
})

## End(Not run)</code></pre>

<hr>
<h2 id='sm.sigma2.compare'>Comparison across two groups of the error standard deviation in 
nonparametric regression with two covariates.</h2><span id='topic+sm.sigma2.compare'></span>

<h3>Description</h3>

<p>This function compares across two groups, in a hypothesis
test, the error standard deviation in nonparametric regression 
with two covariates.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.sigma2.compare(x1, y1, x2, y2)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.sigma2.compare_+3A_x1">x1</code></td>
<td>
<p>a two-column matrix of covariate values for group 1.</p>
</td></tr>
<tr><td><code id="sm.sigma2.compare_+3A_y1">y1</code></td>
<td>
<p>a vector of responses for group 1.</p>
</td></tr>
<tr><td><code id="sm.sigma2.compare_+3A_x2">x2</code></td>
<td>
<p>a two-column matrix of covariate values for group 2.</p>
</td></tr>
<tr><td><code id="sm.sigma2.compare_+3A_y2">y2</code></td>
<td>
<p>a vector of responses for group 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see the reference below.</p>


<h3>Value</h3>

<p>a p-value for the test of equality of standard deviations.</p>


<h3>Side Effects</h3>

<p>none.</p>


<h3>References</h3>

<p>Bock, M., Bowman, A.W. &amp; Ismail, B. (2007).
Estimation and inference for error variance in bivariate 
nonparametric regression.
<em>Statistics &amp; Computing</em>, to appear.</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.sigma">sm.sigma</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
with(airquality, {
   x     &lt;- cbind(Wind, Temp)
   y     &lt;- Ozone^(1/3)
   group &lt;- (Solar.R &lt; 200)
   sig1 &lt;- sm.sigma(x[ group, ], y[ group], ci = TRUE)
   sig2 &lt;- sm.sigma(x[!group, ], y[!group], ci = TRUE)
   print(c(sig1$estimate, sig1$ci))
   print(c(sig2$estimate, sig2$ci))
   print(sm.sigma(x[ group, ], y[ group], model = "constant", h = c(3, 5))$p)
   print(sm.sigma(x[!group, ], y[!group], model = "constant", h = c(3, 5))$p)
   print(sm.sigma2.compare(x[group, ], y[group], x[!group, ], y[!group]))
})

## End(Not run)</code></pre>

<hr>
<h2 id='sm.sphere'>
Nonparametric density estimation for spherical data.
</h2><span id='topic+sm.sphere'></span>

<h3>Description</h3>

<p>This function creates a density estimate from data which can be viewed
as lying on the surface of a sphere.  Directional data form a principal
example.  The data are displayed in spherical form and a density estimate
may be superimposed.  The angle of view may be altered.  An interactive 
panel is available to control some features of the estimate and the display.
Only modest amounts of data may be used.  The limit will depend on the
memory available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.sphere(lat, long, kappa = 20, hidden = FALSE, sphim = FALSE,
          addpoints = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.sphere_+3A_lat">lat</code></td>
<td>

<p>a vector giving the latitude component of the data in degrees from the 
equator.
</p>
</td></tr>
<tr><td><code id="sm.sphere_+3A_long">long</code></td>
<td>

<p>a vector giving the longitude component of the data in degrees east.
</p>
</td></tr>
<tr><td><code id="sm.sphere_+3A_kappa">kappa</code></td>
<td>

<p>the smoothing parameter used to construct the density estimate.  The kernel
function is a Fisher distribution and <code>kappa</code> is its scale parameter.
Larger values of <code>kappa</code> will produce smaller amounts of smoothing.
</p>
</td></tr>
<tr><td><code id="sm.sphere_+3A_hidden">hidden</code></td>
<td>

<p>a logical value which, when set to <code>TRUE</code>, will display the points which lie
on the rear side of the displayed sphere.  This argument will be ignored
if <code>sphim</code> is set to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="sm.sphere_+3A_sphim">sphim</code></td>
<td>

<p>a logical value which controls whether a density estimate is constructed
and displayed on the sphere in image form.
</p>
</td></tr>
<tr><td><code id="sm.sphere_+3A_addpoints">addpoints</code></td>
<td>

<p>a logical value which controls whether the data points are added to the
plot of the density estimate.
</p>
</td></tr>
<tr><td><code id="sm.sphere_+3A_...">...</code></td>
<td>

<p>arguments for <code><a href="#topic+sm.options">sm.options</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see Section 1.5 of the reference below.
</p>


<h3>Value</h3>

<p>a list containing the value of the smoothing parameter and the rotation 
angles of the displayed plot.
</p>


<h3>Side Effects</h3>

<p>none.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). <em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.density">sm.density</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lat  &lt;- rnorm(50, 10, 15)
long &lt;- c(rnorm(25, 300, 15), rnorm(25, 240, 15))
par(mfrow=c(1,2))
sm.sphere(lat, long)
sm.sphere(lat, long, sphim=TRUE, kappa=15)
par(mfrow=c(1,1))
</code></pre>

<hr>
<h2 id='sm.surface3d'>
Adding a regression surface to an rgl plot.
</h2><span id='topic+sm.surface3d'></span>

<h3>Description</h3>

<p>This function adds a regression surface, defined by a matrix of heights
at a regular grid of values of two covariates, to an <code>rgl</code> plot.
Missing values can be accommodated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> sm.surface3d(eval.points, surf, scaling, 
                    col = "green", col.mesh = "black", 
                    alpha = 0.7, alpha.mesh = 1, lit = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.surface3d_+3A_eval.points">eval.points</code></td>
<td>

<p>if this is a two-column matrix then each column defines the marginal grids of covariate values.  Alternatively, a list with two components can also be used to handle cases where the grids are of different size.
</p>
</td></tr>
<tr><td><code id="sm.surface3d_+3A_surf">surf</code></td>
<td>

<p>a matrix of heights corresponding to the grid of covariate values.
NAs are allowed.
</p>
</td></tr>
<tr><td><code id="sm.surface3d_+3A_scaling">scaling</code></td>
<td>

<p>a function to define the scaling for the <code>rgl</code> plot.  This
function is returned by an initial call to <code>rp.plot3d</code> in the
<code>rpanel</code> package.
</p>
</td></tr>
<tr><td><code id="sm.surface3d_+3A_col">col</code></td>
<td>

<p>the colour of the surface.  If <code>col</code> is set to a single value, this
is replicated across the two components.  However, a matrix of values
corresponding to the entries of <code>surf</code> can also be supplied.
</p>
</td></tr>
<tr><td><code id="sm.surface3d_+3A_col.mesh">col.mesh</code></td>
<td>

<p>the colour of the surface mesh.  If <code>col.mesh</code> is set to a single value, this
is replicated across the two components.  However, a matrix of values
corresponding to the entries of <code>surf</code> can also be supplied.
</p>
</td></tr>
<tr><td><code id="sm.surface3d_+3A_alpha">alpha</code></td>
<td>

<p>the transparency of the filled triangles defining the surface.  Setting 
this to <code>0</code> will remove the filled triangles from the plot.
</p>
</td></tr>
<tr><td><code id="sm.surface3d_+3A_alpha.mesh">alpha.mesh</code></td>
<td>

<p>the transparency of the lines drawn across the regular grid of covariate 
values.  Setting this to <code>0</code> will remove the lines from the plot.
</p>
</td></tr>
<tr><td><code id="sm.surface3d_+3A_lit">lit</code></td>
<td>

<p>a logical variable which controls whether the <code>rgl</code> plot is lit or not.
</p>
</td></tr>
<tr><td><code id="sm.surface3d_+3A_...">...</code></td>
<td>

<p>other optional parameters which are passed to <code>material3d</code> in the 
<code>rgl</code> package.
</p>
</td></tr></table>


<h3>Details</h3>

<p>the principal motivation for this function is that is can handle missing
data in regression surfaces.  In particular, it can be used to plot the
results of applying <code>sm.regression</code>.  In addition, the function can 
be used to build up more complex plots by adding successive surfaces.
</p>


<h3>Value</h3>

<p>a vector of length 2 containing the ids of the filled surface and lines
added to the <code>rgl</code> plot.
</p>


<h3>Side Effects</h3>

<p>a surface is added to the <code>rgl</code> plot.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(trawl, {
   Zone93    &lt;- (Year == 1 &amp; Zone == 1)
   Position  &lt;- cbind(Longitude - 143, Latitude)
   model1 &lt;- sm.regression(Position[Zone93,], Score1[Zone93],
        h= c(0.1, 0.1), display = "rgl", xlab="Longitude - 143")
   model2 &lt;- sm.regression(Position[Zone93,], Score1[Zone93],
        h= c(0.2, 0.2), display = "none")
   sm.surface3d(model2$eval.points, model2$est, model1$scaling, col = "red")
})
</code></pre>

<hr>
<h2 id='sm.survival'>
Nonparametric regression with survival data.
</h2><span id='topic+sm.survival'></span>

<h3>Description</h3>

<p>This function creates a smooth, nonparametric estimate of the quantile
of the distribution of survival data as a function of a single
covariate. A weighted product-limit estimate of the survivor function
is obtained by smoothing across the covariate scale.  A small amount
of smoothing is then also applied across  the survival time scale in
order to achieve a smooth estimate of the quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.survival(x, y, status, h , hv = 0.05, p = 0.5, status.code = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.survival_+3A_x">x</code></td>
<td>

<p>a vector of covariate values.
</p>
</td></tr>
<tr><td><code id="sm.survival_+3A_y">y</code></td>
<td>

<p>a vector of survival times.
</p>
</td></tr>
<tr><td><code id="sm.survival_+3A_status">status</code></td>
<td>

<p>an indicator of a complete survival time or a censored value.  The value of
<code>status.code</code> defines a complete survival time.
</p>
</td></tr>
<tr><td><code id="sm.survival_+3A_h">h</code></td>
<td>

<p>the smoothing parameter applied to the covariate scale.  A normal kernel
function is used and <code>h</code> is its standard deviation.
</p>
</td></tr>
<tr><td><code id="sm.survival_+3A_hv">hv</code></td>
<td>

<p>a smoothing parameter applied to the weighted to the product-limit
estimate derived from the smoothing procedure in the covariate scale.
This ensures that a smooth estimate is obtained.
</p>
</td></tr>
<tr><td><code id="sm.survival_+3A_p">p</code></td>
<td>

<p>the quantile to be estimated at each covariate value.
</p>
</td></tr>
<tr><td><code id="sm.survival_+3A_status.code">status.code</code></td>
<td>

<p>the value of <code>status</code> which defines a complete survival time.
</p>
</td></tr>
<tr><td><code id="sm.survival_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function; those relevant for this function are 
<code>add</code>,
<code>eval.points</code>, 
<code>ngrid</code>, 
<code>display</code>, 
<code>xlab</code>, 
<code>ylab</code>, 
<code>lty</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their
description.
</p>
</td></tr></table>


<h3>Details</h3>

<p>see Section 3.5 of the reference below.
</p>


<h3>Value</h3>

<p>a list containing the values of the estimate at the evaluation points
and the values of the smoothing parameters for the covariate and survival
time scales.
</p>


<h3>Side Effects</h3>

<p>a plot on the current graphical device is produced, unless the option 
<code>display="none"</code> is set.  
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for Data Analysis:</em>
<em>the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(50, 0, 10)
y &lt;- rexp(50, 2)
z &lt;- rexp(50, 1)
status &lt;- rep(1, 50)
status[z&lt;y] &lt;- 0
y &lt;- pmin(z, y)
sm.survival(x, y, status, h=2)
</code></pre>

<hr>
<h2 id='sm.ts.pdf'>
Nonparametric density estimation of stationary time series data
</h2><span id='topic+sm.ts.pdf'></span>

<h3>Description</h3>

<p>This function estimates the density function of a time series <code>x</code>,
assumed to be stationary. The univariate marginal density is estimated
in all cases; bivariate densities of pairs of lagged values are estimated
depending on the parameter <code>lags</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.ts.pdf(x, h = hnorm(x), lags, maxlag = 1, ask = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.ts.pdf_+3A_x">x</code></td>
<td>

<p>a vector containing a time series
</p>
</td></tr>
<tr><td><code id="sm.ts.pdf_+3A_h">h</code></td>
<td>

<p>bandwidth
</p>
</td></tr>
<tr><td><code id="sm.ts.pdf_+3A_lags">lags</code></td>
<td>

<p>for each value, <code>k</code> say, in the vector <code>lags</code> a density
estimate is produced
of the joint distribution of the pair <code>(x(t-k),x(t))</code>.
</p>
</td></tr>
<tr><td><code id="sm.ts.pdf_+3A_maxlag">maxlag</code></td>
<td>

<p>if <code>lags</code> is not given, it is assigned the value <code>1:maxlag</code>
(default=1).
</p>
</td></tr>
<tr><td><code id="sm.ts.pdf_+3A_ask">ask</code></td>
<td>

<p>if <code>ask=TRUE</code>, the program pauses after each plot, until &lt;Enter&gt;
is pressed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see Section 7.2 of the reference below.
</p>


<h3>Value</h3>

<p>a list of two elements, containing the outcome of the estimation of 
the marginal density and the last bivariate density, as produced by 
<code><a href="#topic+sm.density">sm.density</a></code>.
</p>


<h3>Side Effects</h3>

<p>plots are produced on the current graphical device.
</p>


<h3>References</h3>

<p>Bowman, A.W. and Azzalini, A. (1997). <em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with S-Plus Illustrations.</em>
Oxford University Press, Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.density">sm.density</a></code>, <code><a href="#topic+sm.autoregression">sm.autoregression</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(geyser, {
   sm.ts.pdf(geyser$duration, lags=1:2)
})
</code></pre>

<hr>
<h2 id='sm.variogram'>
Confidence intervals and tests based on smoothing an empirical variogram.
</h2><span id='topic+sm.variogram'></span>

<h3>Description</h3>

<p>This function constructs an empirical variogram, using the robust form
of construction based on square-root absolute value differences of the
data.  Flexible regression is used to assess a variety of questions about
the structure of the data used to construct the variogram, including 
independence, isotropy and stationarity.  Confidence bands for the underlying
variogram, and reference bands for the independence, isotropy and stationarity
models, can also be constructed under the assumption that the errors in the 
data are approximately normally distributed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.variogram(x, y, h, df.se = "automatic", max.dist = NA, n.zero.dist = 1,
             original.scale = TRUE, varmat = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.variogram_+3A_x">x</code></td>
<td>

<p>a vector or two-column matrix of spatial location values.
</p>
</td></tr>
<tr><td><code id="sm.variogram_+3A_y">y</code></td>
<td>

<p>a vector of responses observed at the spatial locations.
</p>
</td></tr>
<tr><td><code id="sm.variogram_+3A_h">h</code></td>
<td>

<p>a smoothing parameter to be used on the distance scale.  A normal kernel
function is used and <code>h</code> is its standard deviation.  However, if
this argument is omitted <code>h</code> will be selected by an approximate
degrees of freedom criterion, controlled by the <code>df</code> parameter.
See <code>sm.options</code> for details.
</p>
</td></tr>
<tr><td><code id="sm.variogram_+3A_df.se">df.se</code></td>
<td>

<p>the degrees of freedom used when smoothing the empirical variogram to estimate
standard errors.  The default value of &quot;automatic&quot; selects the degrees of
smoothing described in the Bowman and Crujeiras (2013) reference below.
</p>
</td></tr>
<tr><td><code id="sm.variogram_+3A_max.dist">max.dist</code></td>
<td>

<p>this can be used to constrain the distances used in constructing the variogram.
The default is to use all distances.
</p>
</td></tr>
<tr><td><code id="sm.variogram_+3A_n.zero.dist">n.zero.dist</code></td>
<td>

<p>an integer value which sets the lower limit on the number of pairs of data points with distance zero (in other words the number of pairs whose positions are identical) to trigger a separate variogram bin for zero distance.  Repeat observations at the same location can be informative about the variance of  the underlying process. The default for <code>n.zero.dist</code> is 1, which will create a zero bin for any identical pairs.  However, with small numbers of identical pairs the estimated variance associated with the zero bin may be large, so a higher setting of the <code>n.zero.dist</code> argument can be used to amalgamate the zero distances into the adjacent variogram bin.
</p>
<p>This parameter has no effect when <code>model = "isotropic"</code> or <code>model = "stationary"</code> as the number of bins generated by the multiple dimensions becomes large in these cases, and so zero distances are not allocated a special bin.
</p>
</td></tr>
<tr><td><code id="sm.variogram_+3A_original.scale">original.scale</code></td>
<td>

<p>a logical value which determines whether the plots are constructed on the
original variogram scale (the default) or on the square-root absolute value scale
on which the calculations are performed.
</p>
</td></tr>
<tr><td><code id="sm.variogram_+3A_varmat">varmat</code></td>
<td>

<p>a logical value which determines whether the variance matrix of the estimated
variogram is returned.
</p>
</td></tr>
<tr><td><code id="sm.variogram_+3A_...">...</code></td>
<td>

<p>other optional parameters are passed to the <code>sm.options</code>
function, through a mechanism which limits their effect only to this
call of the function.
</p>
<p>An important parameter here is <code>model</code> which, for
<code>sm.variogram</code>, can be set to <code>"none"</code>, <code>"independent"</code>,
<code>"isotropic"</code> or <code>"stationary"</code>.  The latter two cases are appropriate only for 2-d data.
</p>
<p>Other relevant parameters are 
<code>add</code>,
<code>eval.points</code>, 
<code>ngrid</code>, 
<code>se</code>, 
<code>xlab</code>, 
<code>ylab</code>, 
<code>xlim</code>, 
<code>ylim</code>, 
<code>lty</code>;
see the documentation of  <code><a href="#topic+sm.options">sm.options</a></code> for their
description.  See the details section below for a discussion of
the <code>display</code> and <code>se</code> parameters in this setting.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The reference below describes the statistical methods used in the function.
</p>
<p>Note that, apart from the simple case of the independence model, the calculations
required are extensive and so the function can be slow.
</p>
<p>The <code>display</code> argument has a special meaning for
this function.  Its default value is <code>"binned"</code>, which plots the
binned version of the empirical variogram.  As usual, the value <code>"none"</code>
will suppress the graphical display.  Any other value will lead to a plot 
of the individual differences between all observations.  This will lead
to a very large number of plotted points, unless the dataset is small.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>sqrtdiff</code>, <code>distance</code></td>
<td>
<p>the raw differences and distances</p>
</td></tr>
<tr><td><code>sqrtdiff.mean</code>, <code>distance.mean</code></td>
<td>
<p>the binned differences and distances</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the frequencies of the bins</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the values of the estimate at the evaluation points</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>the evaluation points</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>the value of the smoothing parameter used</p>
</td></tr>
<tr><td><code>ibin</code></td>
<td>
<p>an indicator of the bin in which the distance between
each pair of observations was placed</p>
</td></tr>
<tr><td><code>ipair</code></td>
<td>
<p>the indices of the original observations used to construct each pair</p>
</td></tr>
</table>
<p>When <code>model = "isotropic"</code> or <code>model = "stationary"</code> the following components may also be returned, depending on the arguments passed in ... or the settings in <code>sm.options</code>:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>the p-value of the test</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard errors of the binned values (if the argument <code>se</code> was set to <code>TRUE</code>)</p>
</td></tr>
<tr><td><code>se.band</code></td>
<td>
<p>when an independence model is examined, this gives the standard error of the difference between the smooth estimate and the mean of all the data points, if a reference band has been requested</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>the variance matrix of the binned variogram.  When <code>model</code> is set to <code>"isotropic"</code> or <code>"stationary"</code>, the variance matrix is computed under those assumptions.</p>
</td></tr>
<tr><td><code>sdiff</code></td>
<td>
<p>the standardised difference between the estimate of the variogram and the reference model, evaluated at <code>eval.points</code></p>
</td></tr>
<tr><td><code>levels</code></td>
<td>
<p>the levels of standardised difference at which contours are drawn in the case of <code>model = "isotropy"</code>.</p>
</td></tr>
</table>


<h3>Side Effects</h3>

<p>a plot on the current graphical device is produced, unless the option <code>display = "none"</code> is set.  
</p>


<h3>References</h3>

<p>Diblasi, A. and Bowman, A.W. (2001).
On the use of the variogram for checking independence in a Gaussian spatial process.
<em>Biometrics</em>, 57, 211-218.
</p>
<p>Bowman, A.W. and Crujeiras, R.M. (2013).
Inference for variograms.
<em>Computational Statistics and Data Analysis</em>, 66, 19-31.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.regression">sm.regression</a></code>, <code><a href="#topic+sm.options">sm.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
with(coalash, {
   Position &lt;- cbind(East, North)
   sm.options(list(df = 6, se = TRUE))

   par(mfrow=c(2,2))
   sm.variogram(Position, Percent, original.scale = FALSE, se = FALSE)
   sm.variogram(Position, Percent, original.scale = FALSE)
   sm.variogram(Position, Percent, original.scale = FALSE, model = "independent")
   sm.variogram(East,     Percent, original.scale = FALSE, model = "independent")
   par(mfrow=c(1,1))
})

# Comparison of Co in March and September
   
with(mosses, {
	
   nbins &lt;- 12
   vgm.m &lt;- sm.variogram(loc.m, Co.m, nbins = nbins, original.scale = TRUE,
                        ylim = c(0, 1.5))
   vgm.s &lt;- sm.variogram(loc.s, Co.s, nbins = nbins, original.scale = TRUE,
                        add = TRUE, col.points = "blue")
                        
   trns &lt;- function(x) (x / 0.977741)^4
   del &lt;- 1000
   plot(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean), type = "b",
         ylim = c(0, 1.5), xlab = "Distance", ylab = "Semi-variogram")
   points(vgm.s$distance.mean - del, trns(vgm.s$sqrtdiff.mean), type = "b",
         col = "blue", pch = 2, lty = 2)

   plot(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean), type = "b",
         ylim = c(0, 1.5), xlab = "Distance", ylab = "Semi-variogram")
   points(vgm.s$distance.mean - del, trns(vgm.s$sqrtdiff.mean), type = "b",
         col = "blue", pch = 2, lty = 2)
   segments(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean - 2 * vgm.m$se),
         vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean + 2 * vgm.m$se))
   segments(vgm.s$distance.mean - del, trns(vgm.s$sqrtdiff.mean - 2 * vgm.s$se),
         vgm.s$distance.mean - del, trns(vgm.s$sqrtdiff.mean + 2 * vgm.s$se),
         col = "blue", lty = 2)

   mn &lt;- (vgm.m$sqrtdiff.mean + vgm.s$sqrtdiff.mean) / 2
   se &lt;- sqrt(vgm.m$se^2 + vgm.s$se^2)
   plot(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean), type = "n",
        ylim = c(0, 1.5), xlab = "Distance", ylab = "Semi-variogram")
   polygon(c(vgm.m$distance.mean, rev(vgm.m$distance.mean)),
        c(trns(mn - se), rev(trns(mn + se))),
        border = NA, col = "lightblue")  
   points(vgm.m$distance.mean, trns(vgm.m$sqrtdiff.mean))
   points(vgm.s$distance.mean, trns(vgm.s$sqrtdiff.mean), col = "blue", pch = 2)

   vgm1 &lt;- sm.variogram(loc.m, Co.m, nbins = nbins, varmat = TRUE, 
                        display = "none")
   vgm2 &lt;- sm.variogram(loc.s, Co.s, nbins = nbins, varmat = TRUE,
                        display = "none")

   nbin  &lt;- length(vgm1$distance.mean)
   vdiff &lt;- vgm1$sqrtdiff.mean - vgm2$sqrtdiff.mean
   tstat &lt;- c(vdiff %*% solve(vgm1$V + vgm2$V) %*% vdiff)
   pval  &lt;- 1 - pchisq(tstat, nbin)
   print(pval)
})

# Assessing isotropy for Hg in March

with(mosses, {
   sm.variogram(loc.m, Hg.m, model = "isotropic")
})

# Assessing stationarity for Hg in September

with(mosses, {
   vgm.sty &lt;- sm.variogram(loc.s, Hg.s, model = "stationary")
   i &lt;- 1
   image(vgm.sty$eval.points[[1]], vgm.sty$eval.points[[2]], vgm.sty$estimate[ , , i],
         col = topo.colors(20))
   contour(vgm.sty$eval.points[[1]], vgm.sty$eval.points[[2]], vgm.sty$sdiff[ , , i],
         col = "red", add = TRUE)
})


## End(Not run)
</code></pre>

<hr>
<h2 id='smacker'>Mackerel data from a Spanish survey</h2><span id='topic+smacker'></span>

<h3>Description</h3>

<p>These data were recorded by a Spanish survey, as part of a multi-country 
survey of the abundance of mackerel eggs off the coast of north-western 
Europe, in 1992.  
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Density</code>     </td><td style="text-align: left;">  egg density </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>smack.lat</code>   </td><td style="text-align: left;">  latitude of sampling position </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>smack.long</code>  </td><td style="text-align: left;">  longitude of sampling position </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>smack.depth</code> </td><td style="text-align: left;">  bottom depth </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Temperature</code> </td><td style="text-align: left;">  surface temperature </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>D200</code>        </td><td style="text-align: left;">  distance from the 200m depth contour line
</td>
</tr>

</table>

<p>Background to the survey and the data are provided by Watson et al. (1992), Priede and Watson (1993) and Priede et al (1995).  Borchers et al (1997) describe an analysis of the data.
</p>

<hr>
<h2 id='stanford'>Survival times from the Stanford Heart Transplant Study</h2><span id='topic+stanford'></span>

<h3>Description</h3>

<p>These data refer to the survival times of patients of different ages
from the Stanford Heart Transplant Study.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Log.time</code> </td><td style="text-align: left;">  egg density </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Status</code>   </td><td style="text-align: left;">  latitude of sampling position </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Age</code>      </td><td style="text-align: left;">  longitude of sampling position
</td>
</tr>

</table>

<p>Source: Miller &amp; Halpern (1980).  Regression with censored data.  Biometrika 69, 521-531.
</p>

<hr>
<h2 id='tephra'>Tephra layer</h2><span id='topic+tephra'></span>

<h3>Description</h3>

<p>These data record the percentages of aluminium oxide found in samples
from a tephra layer resulting from a volcanic eruption in Iceland
around 3500 years ago.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Al2O3</code>  </td><td style="text-align: left;">  percentage of aluminium oxide
</td>
</tr>

</table>

<p>The data were collected by A.Dugmore.  The geological background to the data is given by Dugmore et al (1992), Geochemical stability of finegrained silicic tephra in Iceland and Scotland, J.Quatern.Sci. 7, 173-83.
</p>

<hr>
<h2 id='trawl'>Trawl data from the Great Barrier Reef</h2><span id='topic+trawl'></span>

<h3>Description</h3>

<p>These data refer to a survey of the fauna on the sea bed lying
between the coast of northern Queensland and the Great Barrier Reef.
The sampling region covered a zone which was closed to commercial
fishing, as well as neighbouring zones where fishing was permitted.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Zone</code>      </td><td style="text-align: left;">  an indicator for the closed (1) and open (0) zones </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Year</code>      </td><td style="text-align: left;">  an indicator of 1992 (0) or 1993 (1) </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Latitude</code>  </td><td style="text-align: left;">  latitude of the sampling position </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Longitude</code> </td><td style="text-align: left;">  longitude of the sampling position </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Depth</code>     </td><td style="text-align: left;">  bottom depth </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Score1</code>    </td><td style="text-align: left;">  catch score 1 </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Score2</code>    </td><td style="text-align: left;">  catch score 2
</td>
</tr>

</table>

<p>The details of the survey and an analysis of the data are provided by Poiner et al. (1997), The effects of prawn trawling in the far northern section of the Great Barrier Reef, CSIRO Division of Marine Research, Queensland Dept. of Primary Industries.
</p>

<hr>
<h2 id='trout'>Potassium cyanate and trout eggs</h2><span id='topic+trout'></span>

<h3>Description</h3>

<p>These data were collected in a toxocological experiment conducted
at the University of Waterloo.  Different concentrations of
potassium cyanate were applied to vials of trout eggs.  The eggs
in half of the vials were allowed to water-harden before the
toxicant was applied.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Concentr</code> </td><td style="text-align: left;">  toxicant concentration </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Trouts</code>   </td><td style="text-align: left;">  number of trout eggs </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Dead</code>     </td><td style="text-align: left;">  number of eggs which died </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Insert</code>   </td><td style="text-align: left;">  an indicator of whether the eggs were allowed to water-harden
</td>
</tr>

</table>

<p>Source: O'Hara Hines &amp; Carter (1993).  Improved added variable and partial residual plots for the detection of influential observations in generalized linear models.  Applied Statistics 42, 3-20.
</p>
<p>The data are also reported by Hand et al. (1994), A Handbook of Small Data Sets, data set no.418.
</p>

<hr>
<h2 id='wonions'>Yield-density relationship for White Imperial Spanish onion plants</h2><span id='topic+wonions'></span>

<h3>Description</h3>

<p>These data were collected in a study of the relationship between the
yield of White Imperial Spanish onion plants and the density of planting.
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	 <code>Density</code>  </td><td style="text-align: left;">  density of planting (plants/m^2) </td>
</tr>
<tr>
 <td style="text-align: left;">
	 <code>Yield</code>    </td><td style="text-align: left;">  yield (g/plant) </td>
</tr>
<tr>
 <td style="text-align: left;">
	 <code>Locality</code> </td><td style="text-align: left;">  a code to indicate Purnong Landing (1) or Virginia (2)
</td>
</tr>

</table>

<p>The data were collected by I.S.Rogers (South Australian Dept. of Agriculture &amp; Fisheries).  They are listed in Ratkowsky (1983), Nonlinear Regression Modeling. Dekker, New York.
</p>

<hr>
<h2 id='worm'>Human parasitic worm infections</h2><span id='topic+worm'></span>

<h3>Description</h3>

<p>These data record the occurrence of a human parasitic worm infection in residents of a rural community in China. 
</p>
<p>The variables are:
</p>

<table>
<tr>
 <td style="text-align: left;">
	<code>Age</code>       </td><td style="text-align: left;">  age of the resident </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Infection</code> </td><td style="text-align: left;">  presence (1) or absence (0) of infection </td>
</tr>
<tr>
 <td style="text-align: left;">
	<code>Sex</code>       </td><td style="text-align: left;">  male (1) or female (2)
</td>
</tr>

</table>

<p>The background to the data, and an analysis, are described by Weidong et al. (1996), Ascaris, people and pigs in a rural community of Jiangxi province, China, Parasitology 113, 545-57.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
