<!DOCTYPE html><html><head><title>Help for package sna</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sna}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add.isolates'><p> Add Isolates to a Graph</p></a></li>
<li><a href='#bbnam'><p> Butts' (Hierarchical) Bayesian Network Accuracy Model</p></a></li>
<li><a href='#bbnam.bf'><p> Estimate Bayes Factors for the bbnam</p></a></li>
<li><a href='#betweenness'><p> Compute the Betweenness Centrality Scores of Network Positions</p></a></li>
<li><a href='#bicomponent.dist'>
<p>Calculate the Bicomponents of a Graph</p></a></li>
<li><a href='#blockmodel'><p> Generate Blockmodels Based on Partitions of Network Positions</p></a></li>
<li><a href='#blockmodel.expand'><p> Generate a Graph (or Stack) from a Given Blockmodel Using Particular Expansion Rules</p></a></li>
<li><a href='#bn'><p> Fit a Biased Net Model</p></a></li>
<li><a href='#bonpow'><p> Find Bonacich Power Centrality Scores of Network Positions</p></a></li>
<li><a href='#brokerage'><p> Perform a Gould-Fernandez Brokerage Analysis</p></a></li>
<li><a href='#centralgraph'><p> Find the Central Graph of a Labeled Graph Stack</p></a></li>
<li><a href='#centralization'><p> Find the Centralization of a Given Network, for Some Measure of Centrality</p></a></li>
<li><a href='#clique.census'>
<p>Compute Cycle Census Information</p></a></li>
<li><a href='#closeness'><p> Compute the Closeness Centrality Scores of Network Positions</p></a></li>
<li><a href='#coleman'>
<p>Coleman's High School Friendship Data</p></a></li>
<li><a href='#component.dist'><p> Calculate the Component Size Distribution of a Graph</p></a></li>
<li><a href='#component.size.byvertex'>
<p>Get Component Sizes, by Vertex</p></a></li>
<li><a href='#components'><p> Find the Number of (Maximal) Components Within a Given Graph</p></a></li>
<li><a href='#connectedness'><p> Compute Graph Connectedness Scores</p></a></li>
<li><a href='#consensus'><p> Estimate a Consensus Structure from Multiple Observations</p></a></li>
<li><a href='#cug.test'>
<p>Univariate Conditional Uniform Graph Tests</p></a></li>
<li><a href='#cugtest'><p>Perform Conditional Uniform Graph (CUG) Hypothesis Tests for Graph-Level Indices</p></a></li>
<li><a href='#cutpoints'>
<p>Identify the Cutpoints of a Graph or Digraph</p></a></li>
<li><a href='#degree'><p> Compute the Degree Centrality Scores of Network Positions</p></a></li>
<li><a href='#diag.remove'><p> Remove the Diagonals of Adjacency Matrices in a Graph Stack</p></a></li>
<li><a href='#dyad.census'><p> Compute a Holland and Leinhardt MAN Dyad Census</p></a></li>
<li><a href='#efficiency'><p> Compute Graph Efficiency Scores</p></a></li>
<li><a href='#ego.extract'><p> Extract Egocentric Networks from Complete Network Data</p></a></li>
<li><a href='#equiv.clust'><p> Find Clusters of Positions Based on an Equivalence Relation</p></a></li>
<li><a href='#eval.edgeperturbation'><p> Compute the Effects of Single-Edge Perturbations on Structural Indices</p></a></li>
<li><a href='#evcent'><p> Find Eigenvector Centrality Scores of Network Positions</p></a></li>
<li><a href='#event2dichot'><p> Convert an Observed Event Matrix to a Dichotomous matrix</p></a></li>
<li><a href='#flowbet'>
<p>Calculate Flow Betweenness Scores of Network Positions</p></a></li>
<li><a href='#gapply'><p> Apply Functions Over Vertex Neighborhoods</p></a></li>
<li><a href='#gclust.boxstats'><p> Plot Statistics Associated with Graph Clusters</p></a></li>
<li><a href='#gclust.centralgraph'><p> Get Central Graphs Associated with Graph Clusters</p></a></li>
<li><a href='#gcor'>
<p>Find the (Product-Moment) Correlation Between Two or More Labeled Graphs</p></a></li>
<li><a href='#gcov'><p> Find the Covariance(s) Between Two or More Labeled Graphs</p></a></li>
<li><a href='#gden'><p> Find the Density of a Graph</p></a></li>
<li><a href='#gdist.plotdiff'><p> Plot Differences in Graph-level Statistics Against Inter-graph Distances</p></a></li>
<li><a href='#gdist.plotstats'><p> Plot Various Graph Statistics Over a Network MDS</p></a></li>
<li><a href='#geodist'><p> Fund the Numbers and Lengths of Geodesics Among Nodes in a Graph</p></a></li>
<li><a href='#gilschmidt'>
<p>Compute the Gil-Schmidt Power Index</p></a></li>
<li><a href='#gliop'><p> Return a Binary Operation on GLI Values Computed on Two Graphs</p></a></li>
<li><a href='#gplot'><p> Two-Dimensional Visualization of Graphs</p></a></li>
<li><a href='#gplot.arrow'><p> Add Arrows or Segments to a Plot</p></a></li>
<li><a href='#gplot.layout'><p> Vertex Layout Functions for gplot</p></a></li>
<li><a href='#gplot.loop'><p> Add Loops to a Plot</p></a></li>
<li><a href='#gplot.target'><p> Display a Graph in Target Diagram Form</p></a></li>
<li><a href='#gplot.vertex'><p> Add Vertices to a Plot</p></a></li>
<li><a href='#gplot3d'><p> Three-Dimensional Visualization of Graphs</p></a></li>
<li><a href='#gplot3d.arrow'><p> Add Arrows a Three-Dimensional Plot</p></a></li>
<li><a href='#gplot3d.layout'><p> Vertex Layout Functions for gplot3d</p></a></li>
<li><a href='#gplot3d.loop'><p> Add Loops to a Three-Dimensional Plot</p></a></li>
<li><a href='#graphcent'><p> Compute the (Harary) Graph Centrality Scores of Network Positions</p></a></li>
<li><a href='#grecip'><p> Compute the Reciprocity of an Input Graph or Graph Stack</p></a></li>
<li><a href='#gscor'><p> Find the Structural Correlations Between Two or More Graphs</p></a></li>
<li><a href='#gscov'><p> Find the Structural Covariance(s) Between Two or More Graphs</p></a></li>
<li><a href='#gt'>
<p>Transpose an Input Graph</p></a></li>
<li><a href='#gtrans'><p> Compute the Transitivity of an Input Graph or Graph Stack</p></a></li>
<li><a href='#gvectorize'><p> Vectorization of Adjacency Matrices</p></a></li>
<li><a href='#hdist'><p> Find the Hamming Distances Between Two or More Graphs</p></a></li>
<li><a href='#hierarchy'><p> Compute Graph Hierarchy Scores</p></a></li>
<li><a href='#infocent'><p> Find Information Centrality Scores of Network Positions</p></a></li>
<li><a href='#interval.graph'><p> Convert Spell Data to Interval Graphs</p></a></li>
<li><a href='#is.connected'><p> Is a Given Graph Connected?</p></a></li>
<li><a href='#is.isolate'><p> Is Ego an Isolate?</p></a></li>
<li><a href='#isolates'><p> List the Isolates in a Graph or Graph Stack</p></a></li>
<li><a href='#kcores'>
<p>Compute the k-Core Structure of a Graph</p></a></li>
<li><a href='#kpath.census'><p> Compute Path or Cycle Census Information</p></a></li>
<li><a href='#lab.optimize'><p> Optimize a Bivariate Graph Statistic Across a Set of Accessible Permutations</p></a></li>
<li><a href='#lnam'><p> Fit a Linear Network Autocorrelation Model</p></a></li>
<li><a href='#loadcent'>
<p>Compute the Load Centrality Scores of Network Positions</p></a></li>
<li><a href='#lower.tri.remove'><p> Remove the Lower Triangles of Adjacency Matrices in a Graph Stack</p></a></li>
<li><a href='#lubness'><p> Compute Graph LUBness Scores</p></a></li>
<li><a href='#make.stochastic'><p> Make a Graph Stack Row, Column, or Row-column Stochastic</p></a></li>
<li><a href='#maxflow'>
<p>Calculate Maximum Flows Between Vertices</p></a></li>
<li><a href='#mutuality'><p> Find the Mutuality of a Graph</p></a></li>
<li><a href='#nacf'><p> Sample Network Covariance and Correlation Functions</p></a></li>
<li><a href='#neighborhood'><p> Compute Neighborhood Structures of Specified Order</p></a></li>
<li><a href='#netcancor'><p> Canonical Correlation for Labeled Graphs</p></a></li>
<li><a href='#netlm'><p> Linear Regression for Network Data</p></a></li>
<li><a href='#netlogit'><p> Logistic Regression for Network Data</p></a></li>
<li><a href='#npostpred'><p> Take Posterior Predictive Draws for Functions of Networks</p></a></li>
<li><a href='#nties'><p> Find the Number of Possible Ties in a Given Graph or Graph Stack</p></a></li>
<li><a href='#numperm'><p> Get the nth Permutation Vector by Periodic Placement</p></a></li>
<li><a href='#plot.bbnam'><p> Plotting for bbnam Objects</p></a></li>
<li><a href='#plot.blockmodel'><p> Plotting for blockmodel Objects</p></a></li>
<li><a href='#plot.cugtest'><p> Plotting for cugtest Objects</p></a></li>
<li><a href='#plot.equiv.clust'><p> Plot an equiv.clust Object</p></a></li>
<li><a href='#plot.lnam'><p> Plotting for lnam Objects</p></a></li>
<li><a href='#plot.qaptest'><p> Plotting for qaptest Objects</p></a></li>
<li><a href='#plot.sociomatrix'><p> Plot Matrices Using a Color/Intensity Grid</p></a></li>
<li><a href='#potscalered.mcmc'><p> Compute Gelman and Rubin's Potential Scale Reduction Measure for a Markov Chain Monte Carlo Simulation</p></a></li>
<li><a href='#prestige'><p> Calculate the Vertex Prestige Scores</p></a></li>
<li><a href='#print.bayes.factor'><p> Printing for Bayes Factor Objects</p></a></li>
<li><a href='#print.bbnam'><p> Printing for bbnam Objects</p></a></li>
<li><a href='#print.blockmodel'><p> Printing for blockmodel Objects</p></a></li>
<li><a href='#print.cugtest'><p> Printing for cugtest Objects</p></a></li>
<li><a href='#print.lnam'><p> Printing for lnam Objects</p></a></li>
<li><a href='#print.netcancor'><p> Printing for netcancor Objects</p></a></li>
<li><a href='#print.netlm'><p> Printing for netlm Objects</p></a></li>
<li><a href='#print.netlogit'><p> Printing for netlogit Objects</p></a></li>
<li><a href='#print.qaptest'><p> Printing for qaptest Objects</p></a></li>
<li><a href='#print.summary.bayes.factor'><p> Printing for summary.bayes.factor Objects</p></a></li>
<li><a href='#print.summary.bbnam'><p> Printing for summary.bbnam Objects</p></a></li>
<li><a href='#print.summary.blockmodel'><p> Printing for summary.blockmodel Objects</p></a></li>
<li><a href='#print.summary.cugtest'><p> Printing for summary.cugtest Objects</p></a></li>
<li><a href='#print.summary.lnam'><p> Printing for summary.lnam Objects</p></a></li>
<li><a href='#print.summary.netcancor'><p> Printing for summary.netcancor Objects</p></a></li>
<li><a href='#print.summary.netlm'><p> Printing for summary.netlm Objects</p></a></li>
<li><a href='#print.summary.netlogit'><p> Printing for summary.netlogit Objects</p></a></li>
<li><a href='#print.summary.qaptest'><p> Printing for summary.qaptest Objects</p></a></li>
<li><a href='#pstar'><p> Fit a p*/ERG Model Using a Logistic Approximation</p></a></li>
<li><a href='#qaptest'><p> Perform Quadratic Assignment Procedure (QAP) Hypothesis Tests for Graph-Level Statistics</p></a></li>
<li><a href='#reachability'><p> Find the Reachability Matrix of a Graph</p></a></li>
<li><a href='#read.dot'><p> Read Graphviz DOT Files</p></a></li>
<li><a href='#read.nos'><p> Read (N)eo-(O)rg(S)tat Input Files</p></a></li>
<li><a href='#redist'>
<p>Find a Matrix of Distances Between Positions Based on Regular Equivalence</p></a></li>
<li><a href='#rgbn'><p> Draw from a Skvoretz-Fararo Biased Net Process</p></a></li>
<li><a href='#rgnm'><p> Draw Density-Conditioned Random Graphs</p></a></li>
<li><a href='#rgnmix'>
<p>Draw Mixing-Conditioned Random Graphs</p></a></li>
<li><a href='#rgraph'><p> Generate Bernoulli Random Graphs</p></a></li>
<li><a href='#rguman'><p> Draw Dyad Census-Conditioned Random Graphs</p></a></li>
<li><a href='#rgws'><p> Draw From the Watts-Strogatz Rewiring Model</p></a></li>
<li><a href='#rmperm'><p> Randomly Permute the Rows and Columns of an Input Matrix</p></a></li>
<li><a href='#rperm'><p> Draw a Random Permutation Vector with Exchangeability Constraints</p></a></li>
<li><a href='#sdmat'><p> Estimate the Structural Distance Matrix for a Graph Stack</p></a></li>
<li><a href='#sedist'><p> Find a Matrix of Distances Between Positions Based on Structural Equivalence</p></a></li>
<li><a href='#simmelian'><p> Find the Simmelian Tie Structure of a Graph</p></a></li>
<li><a href='#sna'><p>Tools for Social Network Analysis</p></a></li>
<li><a href='#sna-coercion'><p> sna Coercion Functions</p></a></li>
<li><a href='#sna-defunct'><p> Defunct sna Objects</p></a></li>
<li><a href='#sna-deprecated'><p> Deprecated Functions in sna Package</p></a></li>
<li><a href='#sna-internal'><p> Internal sna Functions</p></a></li>
<li><a href='#sna.operators'><p> Graphical Operators</p></a></li>
<li><a href='#sr2css'><p> Convert a Row-wise Self-Report Matrix to a CSS Matrix with Missing Observations</p></a></li>
<li><a href='#stackcount'><p> How Many Graphs are in a Graph Stack?</p></a></li>
<li><a href='#stresscent'><p> Compute the Stress Centrality Scores of Network Positions</p></a></li>
<li><a href='#structdist'><p> Find the Structural Distances Between Two or More Graphs</p></a></li>
<li><a href='#structure.statistics'><p> Compute Network Structure Statistics</p></a></li>
<li><a href='#summary.bayes.factor'><p> Detailed Summaries of Bayes Factor Objects</p></a></li>
<li><a href='#summary.bbnam'><p> Detailed Summaries of bbnam Objects</p></a></li>
<li><a href='#summary.blockmodel'><p> Detailed Summaries of blockmodel Objects</p></a></li>
<li><a href='#summary.cugtest'><p> Detailed Summaries of cugtest Objects</p></a></li>
<li><a href='#summary.lnam'><p> Detailed Summaries of lnam Objects</p></a></li>
<li><a href='#summary.netcancor'><p> Detailed Summaries of netcancor Objects</p></a></li>
<li><a href='#summary.netlm'><p> Detailed Summaries of netlm Objects</p></a></li>
<li><a href='#summary.netlogit'><p> Detailed Summaries of netlogit Objects</p></a></li>
<li><a href='#summary.qaptest'><p> Detailed Summaries of qaptest Objects</p></a></li>
<li><a href='#symmetrize'><p> Symmetrize an Adjacency Matrix</p></a></li>
<li><a href='#triad.census'><p> Compute the Davis and Leinhardt Triad Census</p></a></li>
<li><a href='#triad.classify'><p> Compute the Davis and Leinhardt Classification of a Given Triad</p></a></li>
<li><a href='#upper.tri.remove'><p> Remove the Upper Triangles of Adjacency Matrices in a Graph Stack</p></a></li>
<li><a href='#write.dl'><p> Write Output Graphs in DL Format</p></a></li>
<li><a href='#write.nos'><p> Write Output Graphs in (N)eo-(O)rg(S)tat Format</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.7-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-05</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Social Network Analysis</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.0.0), utils, statnet.common, network</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rgl, numDeriv, SparseM</td>
</tr>
<tr>
<td>Description:</td>
<td>A range of tools for social network analysis, including node and graph-level indices, structural distance and covariance methods, structural equivalence detection, network regression, random graph generation, and 2D/3D network visualization.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://statnet.org">https://statnet.org</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-05 21:42:37 UTC; buttsc</td>
</tr>
<tr>
<td>Author:</td>
<td>Carter T. Butts [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Carter T. Butts &lt;buttsc@uci.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-06 05:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='add.isolates'> Add Isolates to a Graph </h2><span id='topic+add.isolates'></span>

<h3>Description</h3>

<p>Adds <code>n</code> isolates to the graph (or graphs) in <code>dat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add.isolates(dat, n, return.as.edgelist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add.isolates_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="add.isolates_+3A_n">n</code></td>
<td>
<p> the number of isolates to add. </p>
</td></tr>
<tr><td><code id="add.isolates_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; should the input graph be returned as an edgelist (rather than an adjacency matrix)?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>dat</code> contains more than one graph, the <code>n</code> isolates are added to each member of <code>dat</code>.
</p>


<h3>Value</h3>

<p>The updated graph(s).
</p>


<h3>Note</h3>

<p> Isolate addition is particularly useful when computing structural distances between graphs of different orders; see the above reference for details. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Inter-Structural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+isolates">isolates</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
g&lt;-rgraph(10,5)		#Produce some random graphs

dim(g)			#Get the dimensions of g

g&lt;-add.isolates(g,2)	#Add 2 isolates to each graph in g

dim(g)			#Now examine g
g

</code></pre>

<hr>
<h2 id='bbnam'> Butts' (Hierarchical) Bayesian Network Accuracy Model </h2><span id='topic+bbnam'></span><span id='topic+bbnam.actor'></span><span id='topic+bbnam.pooled'></span><span id='topic+bbnam.fixed'></span>

<h3>Description</h3>

<p>Takes posterior draws from Butts' bayesian network accuracy/estimation model for multiple participant/observers (conditional on observed data and priors), using a Gibbs sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbnam(dat, model="actor", ...)
bbnam.fixed(dat, nprior=0.5, em=0.25, ep=0.25, diag=FALSE,
    mode="digraph", draws=1500, outmode="draws", anames=NULL,
    onames=NULL)
bbnam.pooled(dat, nprior=0.5, emprior=c(1,11), epprior=c(1,11),
    diag=FALSE, mode="digraph", reps=5, draws=1500, burntime=500, 
    quiet=TRUE, anames=NULL, onames=NULL, compute.sqrtrhat=TRUE)
bbnam.actor(dat, nprior=0.5, emprior=c(1,11), epprior=c(1,11), 
    diag=FALSE, mode="digraph", reps=5, draws=1500, burntime=500,
    quiet=TRUE, anames=NULL, onames=NULL, compute.sqrtrhat=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bbnam_+3A_dat">dat</code></td>
<td>
<p> Input networks to be analyzed.  This may be supplied in any reasonable form, but must be reducible to an array of dimension <code class="reqn">m \times n \times n</code>, where <code class="reqn">n</code> is <code class="reqn">|V(G)|</code>, the first dimension indexes the observer (or information source), the second indexes the sender of the relation, and the third dimension indexes the recipient of the relation.  (E.g., <code>dat[i,j,k]==1</code> implies that i observed j sending the relation in question to k.)  Note that only dichotomous data is supported at present, and missing values are permitted; the data collection pattern, however, is assumed to be ignorable, and hence the posterior draws are implicitly conditional on the observation pattern. </p>
</td></tr>
<tr><td><code id="bbnam_+3A_model">model</code></td>
<td>
<p> String containing the error model to use; options are <code>"actor"</code>, <code>"pooled"</code>, and <code>"fixed"</code>. </p>
</td></tr>
<tr><td><code id="bbnam_+3A_...">...</code></td>
<td>
<p>Arguments to be passed by <code>bbnam</code> to the particular model method.</p>
</td></tr>
<tr><td><code id="bbnam_+3A_nprior">nprior</code></td>
<td>
<p> Network prior matrix.  This must be a matrix of dimension <code class="reqn">n</code> x <code class="reqn">n</code>, containing the arc/edge priors for the criterion network.  (E.g., <code>nprior[i,j]</code> gives the prior probability of <code>i</code> sending the relation to <code>j</code> in the criterion graph.)  Non-matrix values will be coerced/expanded to matrix form as appropriate.  If no network prior is provided, an uninformative prior on the space of networks will be assumed (i.e., <code class="reqn">\Pr(i\to j)=0.5</code>).  Missing values are not allowed. </p>
</td></tr>
<tr><td><code id="bbnam_+3A_em">em</code></td>
<td>
<p> Probability of a false negative; this may be in the form of a single number, one number per observation slice, one number per (directed) dyad, or one number per dyadic observation (fixed model only). </p>
</td></tr>
<tr><td><code id="bbnam_+3A_ep">ep</code></td>
<td>
<p> Probability of a false positive; this may be in the form of a single number, one number per observation slice, one number per (directed) dyad, or one number per dyadic observation (fixed model only). </p>
</td></tr>
<tr><td><code id="bbnam_+3A_emprior">emprior</code></td>
<td>
<p> Parameters for the (Beta) false negative prior; these should be in the form of an <code class="reqn">(\alpha,\beta)</code> pair for the pooled model, and of an <code class="reqn">n \times 2</code> matrix of <code class="reqn">(\alpha,\beta)</code> pairs for the actor model (or something which can be coerced to this form). If no <code>emprior</code> is given, a weakly informative prior (1,11) will be assumed; note that this may be inappropriate, as described below.  Missing values are not allowed. </p>
</td></tr>
<tr><td><code id="bbnam_+3A_epprior">epprior</code></td>
<td>
<p>  Parameters for the (Beta) false positive prior; these should be in the form of an <code class="reqn">(\alpha,\beta)</code> pair for the pooled model, and of an <code class="reqn">n \times 2</code> matrix of <code class="reqn">(\alpha,\beta)</code> pairs for the actor model (or something which can be coerced to this form). If no <code>epprior</code> is given, a weakly informative prior (1,11) will be assumed; note that this may be inappropriate, as described below.  Missing values are not allowed. </p>
</td></tr>
<tr><td><code id="bbnam_+3A_diag">diag</code></td>
<td>
<p> Boolean indicating whether loops (matrix diagonals) should be counted as data. </p>
</td></tr>
<tr><td><code id="bbnam_+3A_mode">mode</code></td>
<td>
<p> A string indicating whether the data in question forms a <code>"graph"</code> or a <code>"digraph"</code> </p>
</td></tr>
<tr><td><code id="bbnam_+3A_reps">reps</code></td>
<td>
<p> Number of replicate chains for the Gibbs sampler (pooled and actor models only). </p>
</td></tr>
<tr><td><code id="bbnam_+3A_draws">draws</code></td>
<td>
<p> Integer indicating the total number of draws to take from the posterior distribution.  Draws are taken evenly from each replication (thus, the number of draws from a given chain is draws/reps). </p>
</td></tr>
<tr><td><code id="bbnam_+3A_burntime">burntime</code></td>
<td>
<p> Integer indicating the burn-in time for the Markov Chain.  Each replication is iterated burntime times before taking draws (with these initial iterations being discarded); hence, one should realize that each increment to burntime increases execution time by a quantity proportional to reps. (pooled and actor models only) </p>
</td></tr>
<tr><td><code id="bbnam_+3A_quiet">quiet</code></td>
<td>
<p> Boolean indicating whether MCMC diagnostics should be displayed (pooled and actor models only). </p>
</td></tr>
<tr><td><code id="bbnam_+3A_outmode">outmode</code></td>
<td>
 <p><code>posterior</code> indicates that the exact posterior probability matrix for the criterion graph should be returned; otherwise draws from the joint posterior are returned instead (fixed model only). </p>
</td></tr>
<tr><td><code id="bbnam_+3A_anames">anames</code></td>
<td>
<p> A vector of names for the actors (vertices) in the graph. </p>
</td></tr>
<tr><td><code id="bbnam_+3A_onames">onames</code></td>
<td>
<p> A vector of names for the observers (possibly the actors themselves) whose reports are contained in the input data.</p>
</td></tr>
<tr><td><code id="bbnam_+3A_compute.sqrtrhat">compute.sqrtrhat</code></td>
<td>
<p> A boolean indicating whether or not Gelman et al.'s potential scale reduction measure (an MCMC convergence diagnostic) should be computed (pooled and actor models only). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bbnam models a set of network data as reflecting a series of (noisy) observations by a set of participants/observers regarding an uncertain criterion structure.  Each observer is assumed to send false positives (i.e., reporting a tie when none exists in the criterion structure) with probability <code class="reqn">e^+</code>, and false negatives (i.e., reporting that no tie exists when one does in fact exist in the criterion structure) with probability <code class="reqn">e^-</code>.  The criterion network itself is taken to be a Bernoulli (di)graph.  Note that the present model includes three variants:
</p>

<ol>
<li><p> Fixed error probabilities: Each edge is associated with a known pair of false negative/false positive error probabilities (provided by the researcher).  In this case, the posterior for the criterion graph takes the form of a matrix of Bernoulli parameters, with each edge being independent conditional on the parameter matrix.
</p>
</li>
<li><p> Pooled error probabilities: One pair of (uncertain) false negative/false positive error probabilities is assumed to hold for all observations.  Here, we assume that the researcher's prior information regarding these parameters can be expressed as a pair of Beta distributions, with the additional assumption of independence in the prior distribution.  Note that error rates and edge probabilities are <em>not</em> independent in the joint posterior, but the posterior marginals take the form of Beta mixtures and Bernoulli parameters, respectively. 
</p>
</li>
<li><p> Per observer (&ldquo;actor&rdquo;) error probabilities: One pair of (uncertain) false negative/false positive error probabilities is assumed to hold for each observation slice.  Again, we assume that prior knowledge can be expressed in terms of independent Beta distributions (along with the Bernoulli prior for the criterion graph) and the resulting posterior marginals are Beta mixtures and a Bernoulli graph.  (Again, it should be noted that independence in the priors does <em>not</em> imply independence in the joint posterior!)
</p>
</li></ol>

<p>By default, the <code>bbnam</code> routine returns (approximately) independent draws from the joint posterior distribution, each draw yielding one realization of the criterion network and one collection of accuracy parameters (i.e., probabilities of false positives/negatives).  This is accomplished via a Gibbs sampler in the case of the pooled/actor model, and by direct sampling for the fixed probability model. In the special case of the fixed probability model, it is also possible to obtain directly the posterior for the criterion graph (expressed as a matrix of Bernoulli parameters); this can be controlled by the <code>outmode</code> parameter.
</p>
<p>As noted, the taking of posterior draws in the nontrivial case is accomplished via a Markov Chain Monte Carlo method, in particular the Gibbs sampler; the high dimensionality of the problem (<code class="reqn">O(n^2+2n)</code>) tends to preclude more direct approaches.  At present, chain burn-in is determined ex ante on a more or less arbitrary basis by specification of the <code>burntime</code> parameter.  Eventually, a more systematic approach will be utilized.  Note that insufficient burn-in will result in inaccurate posterior sampling, so it's not wise to skimp on burn time where otherwise possible.  Similarly, it is wise to employ more than one Markov Chain (set by <code>reps</code>), since it is possible for trajectories to become &ldquo;trapped&rdquo; in metastable regions of the state space.  Number of draws per chain being equal, more replications are usually better than few; consult Gelman et al. for details.  A useful measure of chain convergence, Gelman and Rubin's potential scale reduction (<code class="reqn">\sqrt{\hat{R}}</code>), can be computed using the <code>compute.sqrtrhat</code> parameter.  The potential scale reduction measure is an ANOVA-like comparison of within-chain versus between-chain variance; it approaches 1 (from above) as the chain converges, and longer burn-in times are strongly recommended for chains with scale reductions in excess of 1.2 or thereabouts.  
</p>
<p>Finally, a cautionary concerning prior distributions: it is important that the specified priors actually reflect the prior knowledge of the researcher; otherwise, the posterior will be inadequately informed.  In particular, note that an uninformative prior on the accuracy probabilities implies that it is a priori equally probable that any given actor's observations will be informative or <em>negatively</em> informative (i.e., that <code class="reqn">i</code> observing <code class="reqn">j</code> sending a tie to <code class="reqn">k</code> <em>reduces</em> <code class="reqn">\Pr(j\to k)</code>).  This is a highly unrealistic assumption, and it will tend to produce posteriors which are bimodal (one mode being related to the &ldquo;informative&rdquo; solution, the other to the &ldquo;negatively informative&rdquo; solution).  Currently, the default error parameter prior is Beta(1,11), which is both diffuse and which renders negatively informative observers extremely improbable (i.e., on the order of 1e-6).  Another plausible but still fairly diffuse prior would be Beta(3,5), which reduces the prior probability of an actor's being negatively informative to 0.16, and the prior probability of any given actor's being more than 50% likely to make a particular error (on average) to around 0.22.  (This prior also puts substantial mass near the 0.5 point, which would seem consonant with the BKS studies.)  For network priors, a reasonable starting point can often be derived by considering the expected mean degree of the criterion graph: if <code class="reqn">d</code> represents the user's prior expectation for the mean degree, then <code class="reqn">d/(N-1)</code> is a natural starting point for the cell values of <code>nprior</code>.  Butts (2003) discusses a number of issues related to choice of priors for the <code>bbnam</code> model, and users should consult this reference if matters are unclear before defaulting to the uninformative solution.
</p>


<h3>Value</h3>

<p>An object of class bbnam, containing the posterior draws.  The components of the output are as follows:
</p>
<table>
<tr><td><code>anames</code></td>
<td>

<p>A vector of actor names.
</p>
</td></tr>
<tr><td><code>draws</code></td>
<td>

<p>An integer containing the number of draws.
</p>
</td></tr>
<tr><td><code>em</code></td>
<td>

<p>A matrix containing the posterior draws for probability of producing false negatives, by actor.
</p>
</td></tr>
<tr><td><code>ep</code></td>
<td>

<p>A matrix containing the posterior draws for probability of producing false positives, by actor.
</p>
</td></tr>
<tr><td><code>nactors</code></td>
<td>

<p>An integer containing the number of actors.
</p>
</td></tr>
<tr><td><code>net</code></td>
<td>

<p>An array containing the posterior draws for the criterion network.
</p>
</td></tr>
<tr><td><code>reps</code></td>
<td>

<p>An integer indicating the number of replicate chains used by the Gibbs sampler.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p> As indicated, the posterior draws are conditional on the observed data, and hence on the data collection mechanism if the collection design is non-ignorable.  Complete data (e.g., a CSS) and random tie samples are examples of ignorable designs; see Gelman et al. for more information concerning ignorability.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Butts, C. T.  (2003).  &ldquo;Network Inference, Error, and Informant (In)Accuracy: A Bayesian Approach.&rdquo;  <em>Social Networks</em>, 25(2), 103-140.
</p>
<p>Gelman, A.; Carlin, J.B.; Stern, H.S.; and Rubin, D.B.  (1995).  <em>Bayesian Data Analysis.</em>  London: Chapman and Hall.
</p>
<p>Gelman, A., and Rubin, D.B.  (1992).  &ldquo;Inference from Iterative Simulation Using Multiple Sequences.&rdquo;  <em>Statistical Science,</em> 7, 457-511.
</p>
<p>Krackhardt, D.  (1987).  &ldquo;Cognitive Social Structures.&rdquo; <em>Social Networks,</em> 9, 109-134.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+npostpred">npostpred</a></code>, <code><a href="#topic+event2dichot">event2dichot</a></code>, <code><a href="#topic+bbnam.bf">bbnam.bf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create some random data
g&lt;-rgraph(5)
g.p&lt;-0.8*g+0.2*(1-g)
dat&lt;-rgraph(5,5,tprob=g.p)

#Define a network prior
pnet&lt;-matrix(ncol=5,nrow=5)
pnet[,]&lt;-0.5
#Define em and ep priors
pem&lt;-matrix(nrow=5,ncol=2)
pem[,1]&lt;-3
pem[,2]&lt;-5
pep&lt;-matrix(nrow=5,ncol=2)
pep[,1]&lt;-3
pep[,2]&lt;-5

#Draw from the posterior
b&lt;-bbnam(dat,model="actor",nprior=pnet,emprior=pem,epprior=pep,
    burntime=100,draws=100)
#Print a summary of the posterior draws
summary(b)
</code></pre>

<hr>
<h2 id='bbnam.bf'> Estimate Bayes Factors for the bbnam </h2><span id='topic+bbnam.bf'></span>

<h3>Description</h3>

<p>This function uses monte carlo integration to estimate the BFs, and tests the fixed probability, pooled, and pooled by actor models. (See <code><a href="#topic+bbnam">bbnam</a></code> for details.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbnam.bf(dat, nprior=0.5, em.fp=0.5, ep.fp=0.5, emprior.pooled=c(1, 11),
    epprior.pooled=c(1, 11), emprior.actor=c(1, 11), epprior.actor=c(1, 11), 
    diag=FALSE, mode="digraph", reps=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bbnam.bf_+3A_dat">dat</code></td>
<td>
<p> Input networks to be analyzed.  This may be supplied in any reasonable form, but must be reducible to an array of dimension <code class="reqn">m \times n \times n</code>, where <code class="reqn">n</code> is <code class="reqn">|V(G)|</code>, the first dimension indexes the observer (or information source), the second indexes the sender of the relation, and the third dimension indexes the recipient of the relation.  (E.g., <code>dat[i,j,k]==1</code> implies that i observed j sending the relation in question to k.)  Note that only dichotomous data is supported at present, and missing values are permitted; the data collection pattern, however, is assumed to be ignorable, and hence the posterior draws are implicitly conditional on the observation pattern.</p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_nprior">nprior</code></td>
<td>
<p> Network prior matrix.  This must be a matrix of dimension <code class="reqn">n</code> x <code class="reqn">n</code>, containing the arc/edge priors for the criterion network.  (E.g., <code>nprior[i,j]</code> gives the prior probability of <code>i</code> sending the relation to <code>j</code> in the criterion graph.)  Non-matrix values will be coerced/expanded to matrix form as appropriate.  If no network prior is provided, an uninformative prior on the space of networks will be assumed (i.e., <code class="reqn">\Pr(i\to j)=0.5</code>).  Missing values are not allowed. </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_em.fp">em.fp</code></td>
<td>
<p> Probability of false negatives for the fixed probability model </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_ep.fp">ep.fp</code></td>
<td>
<p> Probability of false positives for the fixed probability model </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_emprior.pooled">emprior.pooled</code></td>
<td>
 <p><code class="reqn">(\alpha,\beta)</code> pairs for the (beta) false negative prior under the pooled model </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_epprior.pooled">epprior.pooled</code></td>
<td>
 <p><code class="reqn">(\alpha,\beta)</code> pairs for the (beta) false positive prior under the pooled model </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_emprior.actor">emprior.actor</code></td>
<td>
<p> Matrix of per observer <code class="reqn">(\alpha,\beta)</code> pairs for the (beta) false negative prior under the per observer/actor model, or something that can be coerced to this form </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_epprior.actor">epprior.actor</code></td>
<td>
<p> Matrix of per observer (<code class="reqn">(\alpha,\beta)</code> pairs for the (beta) false positive prior under the per observer/actor model, or something that can be coerced to this form </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_diag">diag</code></td>
<td>
<p> Boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the criterion graph can contain loops.  Diag is false by default. </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_mode">mode</code></td>
<td>
<p> String indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  Mode is set to <code>"digraph"</code> by default. </p>
</td></tr>
<tr><td><code id="bbnam.bf_+3A_reps">reps</code></td>
<td>
<p> Number of Monte Carlo draws to take </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bbnam model (detailed in the <code><a href="#topic+bbnam">bbnam</a></code> function help) is a fairly simple model for integrating informant reports regarding social network data.  <code>bbnam.bf</code> computes log Bayes Factors (integrated likelihood ratios) for the three error submodels of the bbnam: fixed error probabilities, pooled error probabilities, and per observer/actor error probabilities.
</p>
<p>By default, <code>bbnam.bf</code> uses weakly informative Beta(1,11) priors for false positive and false negative rates, which may not be appropriate for all cases.  (Likewise, the initial network prior is uniformative.)  Users are advised to consider adjusting the error rate priors when using this function in a practical context; for instance, it is often reasonable to expect higher false negative rates (on average) than false positive rates, and to expect the criterion graph density to be substantially less than 0.5.  See the reference below for a discussion of this issue.
</p>


<h3>Value</h3>

<p>An object of class <code>bayes.factor</code>.
</p>


<h3>Note</h3>

<p> It is important to be aware that the model parameter priors are essential components of the models to be compared; inappropriate parameter priors will result in misleading Bayes Factors. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Butts, C. T.  (2003).  &ldquo;Network Inference, Error, and Informant (In)Accuracy: A Bayesian Approach.&rdquo;  <em>Social Networks</em>, 25(2), 103-140.
</p>
<p>Robert, C.  (1994).  <em>The Bayesian Choice: A Decision-Theoretic Motivation.</em>  Springer. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam">bbnam</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create some random data from the "pooled" model
g&lt;-rgraph(7)
g.p&lt;-0.8*g+0.2*(1-g)
dat&lt;-rgraph(7,7,tprob=g.p)

#Estimate the log Bayes Factors
b&lt;-bbnam.bf(dat,emprior.pooled=c(3,5),epprior.pooled=c(3,5),
    emprior.actor=c(3,5),epprior.actor=c(3,5))
#Print the results
b
</code></pre>

<hr>
<h2 id='betweenness'> Compute the Betweenness Centrality Scores of Network Positions </h2><span id='topic+betweenness'></span><span id='topic+betweenness_R'></span>

<h3>Description</h3>

<p><code>betweenness</code> takes one or more graphs (<code>dat</code>) and returns the betweenness centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  Depending on the specified mode, betweenness on directed or undirected geodesics will be returned; this function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betweenness(dat, g=1, nodes=NULL, gmode="digraph", diag=FALSE,
    tmaxdev=FALSE, cmode="directed", geodist.precomp=NULL, 
    rescale=FALSE, ignore.eval=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betweenness_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="betweenness_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g</code>=1. </p>
</td></tr>
<tr><td><code id="betweenness_+3A_nodes">nodes</code></td>
<td>
<p> vector indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="betweenness_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>gmode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
<tr><td><code id="betweenness_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="betweenness_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev</code>==<code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="betweenness_+3A_cmode">cmode</code></td>
<td>
<p> string indicating the type of betweenness centrality being computed (directed or undirected geodesics, or a variant form &ndash; see below). </p>
</td></tr>
<tr><td><code id="betweenness_+3A_geodist.precomp">geodist.precomp</code></td>
<td>
<p> A <code><a href="#topic+geodist">geodist</a></code> object precomputed for the graph to be analyzed (optional) </p>
</td></tr>
<tr><td><code id="betweenness_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="betweenness_+3A_ignore.eval">ignore.eval</code></td>
<td>
<p> logical; ignore edge values when computing shortest paths?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The shortest-path betweenness of a vertex, <code class="reqn">v</code>, is given by
</p>
<p style="text-align: center;"><code class="reqn">
C_B(v) = \sum_{i,j : i \neq j, i \neq v, j \neq v} \frac{g_{ivj}}{g_{ij}}</code>
</p>

<p>where <code class="reqn">g_{ijk}</code> is the number of geodesics from <code class="reqn">i</code> to <code class="reqn">k</code> through <code class="reqn">j</code>.  Conceptually, high-betweenness vertices lie on a large number of non-redundant shortest paths between other vertices; they can thus be thought of as &ldquo;bridges&rdquo; or &ldquo;boundary spanners.&rdquo;         
</p>
<p>Several variant forms of shortest-path betweenness exist, and can be selected using the <code>cmode</code> argument.  Supported options are as follows:
</p>

<dl>
<dt><code>directed</code></dt><dd><p> Standard betweenness (see above), calculated on directed pairs.  (This is the default option.)</p>
</dd>
<dt><code>undirected</code></dt><dd><p> Standard betweenness (as above), calculated on undirected pairs (undirected graphs only).</p>
</dd>
<dt><code>endpoints</code></dt><dd><p> Standard betweenness, with direct connections counted towards ego's score.  This expresses the intuition that individuals' control over their own direct contacts should be considered in their total score (e.g., when betweenness is interpreted as a measure of information control).</p>
</dd>
<dt><code>proximalsrc</code></dt><dd><p> Borgatti's <em>proximal source betweenness,</em> given by
</p>
<p style="text-align: center;"><code class="reqn">
C_B(v) = \sum_{i,j : i \neq v, i\neq j, j \to v} \frac{g_{ivj}}{g_{ij}}.</code>
</p>

<p>This variant allows betweenness to accumulate only for the last intermediating vertex in each incoming geodesic; this expresses the notion that, by serving as the &ldquo;proximal source&rdquo; for the target, this particular intermediary will in some settings have greater influence or control than other intervening parties. 
</p>
</dd>
<dt><code>proximaltar</code></dt><dd><p> Borgatti's <em>proximal target betweenness,</em> given by
</p>
<p style="text-align: center;"><code class="reqn">
C_B(v) = \sum_{i,j : i \neq v, i\to v, i\neq j} \frac{g_{ivj}}{g_{ij}}.</code>
</p>

<p>This counterpart to proximal source betweenness (above) allows betweenness to accumulate only for the first intermediating vertex in each outgoing geodesic; this expresses the notion that, by serving as the &ldquo;proximal target&rdquo; for the source, this particular intermediary will in some settings have greater influence or control than other intervening parties. </p>
</dd>
<dt><code>proximalsum</code></dt><dd><p>The sum of Borgatti's proximal source and proximal target betweenness scores (above); this may be used when either role is regarded as relevant to the betweenness calculation.</p>
</dd>
<dt><code>lengthscaled</code></dt><dd><p>Borgetti and Everett's <em>length-scaled betweenness</em>, given by
</p>
<p style="text-align: center;"><code class="reqn">
C_B(v) = \sum_{i,j : i \neq j, i \neq v, j \neq v} \frac{1}{d_{ij}}\frac{g_{ivj}}{g_{ij}},</code>
</p>

<p>where <code class="reqn">d_{ij}</code> is the geodesic distance from <code class="reqn">i</code> to <code class="reqn">j</code>.  This measure adjusts the standard betweenness score by downweighting long paths (e.g., as appropriate in circumstances for which such paths are less-often used).
</p>
</dd>
<dt><code>linearscaled</code></dt><dd><p>Geisberger et al.'s <em>linearly-scaled betweenness</em>:
</p>
<p style="text-align: center;"><code class="reqn">
C_B(v) = \sum_{i,j : i \neq j, i \neq v, j \neq v} \frac{1}{d_{ij}}\frac{g_{ivj}}{g_{ij}}.</code>
</p>

<p>This variant modifies the standard betweenness score by giving more weight to intermediaries which are closer to their targets (much like proximal source betweenness, above).  This may be of use when those near the end of a path have greater direct control over the flow of influence or resources than those near its source.
</p>
</dd>
</dl>

<p>See Brandes (2008) for details and additional references.  Geodesics for all of the above can be calculated using valued edges by setting <code>ignore.eval=TRUE</code>.  Edge values are interpreted as distances for this purpose; proximity data should be transformed accordingly before invoking this routine.
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the betweenness scores (depending on the number and size of the input graphs).
</p>


<h3>Warning </h3>

<p>Rescale may cause unexpected results if all actors have zero betweenness.</p>


<h3>Note</h3>

<p> Judicious use of <code>geodist.precomp</code> can save a great deal of time when computing multiple path-based indices on the same network. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Borgatti, S.P. and Everett, M.G.  (2006).  &ldquo;A Graph-Theoretic Perspective on Centrality.&rdquo;  <em>Social Networks</em>, 28, 466-484.
</p>
<p>Brandes, U.  (2008).  &ldquo;On Variants of Shortest-Path Betweenness Centrality and their Generic Computation.&rdquo;  <em>Social Networks</em>, 30, 136&ndash;145.
</p>
<p>Freeman, L.C.  (1979).  &ldquo;Centrality in Social Networks I: Conceptual Clarification.&rdquo; <em>Social Networks</em>, 1, 215-239.
</p>
<p>Geisberger, R., Sanders, P., and Schultes, D.  (2008).  &ldquo;Better Approximation of Betweenness Centrality.&rdquo;  In <em>Proceedings of the 10th Workshop on Algorithm Engineering and Experimentation (ALENEX'08)</em>, 90-100.  SIAM.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+centralization">centralization</a></code>, <code><a href="#topic+stresscent">stresscent</a></code>, <code><a href="#topic+geodist">geodist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(10)     #Draw a random graph with 10 members
betweenness(g)    #Compute betweenness scores
</code></pre>

<hr>
<h2 id='bicomponent.dist'>
Calculate the Bicomponents of a Graph
</h2><span id='topic+bicomponent.dist'></span><span id='topic+bicomponents_R'></span>

<h3>Description</h3>

<p><code>bicomponent.dist</code> returns the bicomponents of an input graph, along with size distribution and membership information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bicomponent.dist(dat, symmetrize = c("strong", "weak"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bicomponent.dist_+3A_dat">dat</code></td>
<td>

<p>a graph or graph stack.
</p>
</td></tr>
<tr><td><code id="bicomponent.dist_+3A_symmetrize">symmetrize</code></td>
<td>

<p>symmetrization rule to apply when pre-processing the input (see <code><a href="#topic+symmetrize">symmetrize</a></code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bicomponents of undirected graph <code>G</code> are its maximal 2-connected vertex sets.  <code>bicomponent.dist</code> calculates the bicomponents of <code class="reqn">G</code>, after first coercing to undirected form using the symmetrization rule in <code>symmetrize</code>.  In addition to bicomponent memberships, various summary statistics regarding the bicomponent distribution are returned; see below.
</p>


<h3>Value</h3>

<p>A list containing
</p>
<table>
<tr><td><code>members</code></td>
<td>
<p>A list, with one entry per bicomponent, containing component members.</p>
</td></tr>
<tr><td><code>memberships</code></td>
<td>
<p>A vector of component memberships, by vertex.  (Note: memberships may not be unique.)  Vertices not belonging to any bicomponent have membership values of <code>NA</code>.</p>
</td></tr>
<tr><td><code>csize</code></td>
<td>
<p>A vector of component sizes, by bicomponent.</p>
</td></tr>
<tr><td><code>cdist</code></td>
<td>
<p>A vector of length <code class="reqn">|V(G)|</code> with the (unnormalized) empirical distribution function of bicomponent sizes.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Remember that bicomponents can intersect; when this occurs, the relevant vertices' entries in the membership vector are assigned to one of the overlapping bicomponents on an arbitrary basis.   The <code>members</code> element of the return list is the safe way to recover membership information.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Brandes, U. and Erlebach, T.  (2005).  <em>Network Analysis: Methodological Foundations.</em>  Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+component.dist">component.dist</a></code>, <code><a href="#topic+cutpoints">cutpoints</a></code>, <code><a href="#topic+symmetrize">symmetrize</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw a moderately sparse graph
g&lt;-rgraph(25,tp=2/24,mode="graph")

#Compute the bicomponents
bicomponent.dist(g)
</code></pre>

<hr>
<h2 id='blockmodel'> Generate Blockmodels Based on Partitions of Network Positions </h2><span id='topic+blockmodel'></span>

<h3>Description</h3>

<p>Given a set of equivalence classes (in the form of an <code><a href="#topic+equiv.clust">equiv.clust</a></code> object, <code><a href="stats.html#topic+hclust">hclust</a></code> object, or membership vector) and one or more graphs, <code>blockmodel</code> will form a blockmodel of the input graph(s) based on the classes in question, using the specified block content type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockmodel(dat, ec, k=NULL, h=NULL, block.content="density", 
    plabels=NULL, glabels=NULL, rlabels=NULL, mode="digraph", 
    diag=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blockmodel_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="blockmodel_+3A_ec">ec</code></td>
<td>
<p> equivalence classes, in the form of an object of class <code>equiv.clust</code> or <code>hclust</code>, or a membership vector. </p>
</td></tr>
<tr><td><code id="blockmodel_+3A_k">k</code></td>
<td>
<p> the number of classes to form (using <code><a href="stats.html#topic+cutree">cutree</a></code>). </p>
</td></tr>
<tr><td><code id="blockmodel_+3A_h">h</code></td>
<td>
<p> the height at which to split classes (using <code><a href="stats.html#topic+cutree">cutree</a></code>). </p>
</td></tr>
<tr><td><code id="blockmodel_+3A_block.content">block.content</code></td>
<td>
<p> string indicating block content type (see below).</p>
</td></tr>
<tr><td><code id="blockmodel_+3A_plabels">plabels</code></td>
<td>
<p> a vector of labels to be applied to the individual nodes.</p>
</td></tr>
<tr><td><code id="blockmodel_+3A_glabels">glabels</code></td>
<td>
<p> a vector of labels to be applied to the graphs being modeled. </p>
</td></tr>
<tr><td><code id="blockmodel_+3A_rlabels">rlabels</code></td>
<td>
<p> a vector of labels to be applied to the (reduced) roles. </p>
</td></tr>
<tr><td><code id="blockmodel_+3A_mode">mode</code></td>
<td>
<p> a string indicating whether we are dealing with graphs or digraphs. </p>
</td></tr>
<tr><td><code id="blockmodel_+3A_diag">diag</code></td>
<td>
<p> a boolean indicating whether loops are permitted. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unless a vector of classes is specified, <code>blockmodel</code> forms its eponymous models by using <code><a href="stats.html#topic+cutree">cutree</a></code> to cut an equivalence clustering in the fashion specified by <code>k</code> and <code>h</code>.  After forming clusters (roles), the input graphs are reordered and blockmodel reduction is applied.  Currently supported reductions are:
</p>

<ol>
<li> <p><code>density</code>: block density, computed as the mean value of the block
</p>
</li>
<li> <p><code>meanrowsum</code>: mean row sums for the block
</p>
</li>
<li> <p><code>meancolsum</code>: mean column sums for the block
</p>
</li>
<li> <p><code>sum</code>: total block sum
</p>
</li>
<li> <p><code>median</code>: median block value
</p>
</li>
<li> <p><code>min</code>: minimum block value
</p>
</li>
<li> <p><code>max</code>: maximum block value
</p>
</li>
<li> <p><code>types</code>: semi-intelligent coding of blocks by &ldquo;type.&rdquo;  Currently recognized types are (in order of precedence) &ldquo;<code>NA</code>&rdquo; (i.e., blocks with no valid data), &ldquo;null&rdquo; (i.e., all values equal to zero), &ldquo;complete&rdquo; (i.e., all values equal to 1), &ldquo;1 covered&rdquo; (i.e., all rows/cols contain a 1), &ldquo;1 row-covered&rdquo; (i.e., all rows contain a 1), &ldquo;1 col-covered&rdquo; (i.e., all cols contain a 1), and &ldquo;other&rdquo; (i.e., none of the above). 
</p>
</li></ol>

<p>Density or median-based reductions are probably the most interpretable for most conventional analyses, though type-based reduction can be useful in examining certain equivalence class hypotheses (e.g., 1 covered and null blocks can be used to infer regular equivalence classes).  Once a given reduction is performed, the model can be analyzed and/or expansion can be used to generate new graphs based on the inferred role structure.
</p>


<h3>Value</h3>

<p>An object of class <code>blockmodel</code>.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Doreian, P.; Batagelj, V.; and Ferligoj, A.  (2005).  <em>Generalized Blockmodeling.</em>  Cambridge: Cambridge University Press.
</p>
<p>White, H.C.; Boorman, S.A.; and Breiger, R.L.  (1976).  &ldquo;Social Structure from Multiple Networks I: Blockmodels of Roles and Positions.&rdquo;  <em>American Journal of Sociology</em>, 81, 730-779.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+equiv.clust">equiv.clust</a></code>, <code><a href="#topic+blockmodel.expand">blockmodel.expand</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a random graph with _some_ edge structure
g.p&lt;-sapply(runif(20,0,1),rep,20)  #Create a matrix of edge 
                                   #probabilities
g&lt;-rgraph(20,tprob=g.p)            #Draw from a Bernoulli graph 
                                   #distribution

#Cluster based on structural equivalence
eq&lt;-equiv.clust(g)

#Form a blockmodel with distance relaxation of 10
b&lt;-blockmodel(g,eq,h=10)
plot(b)                            #Plot it
</code></pre>

<hr>
<h2 id='blockmodel.expand'> Generate a Graph (or Stack) from a Given Blockmodel Using Particular Expansion Rules </h2><span id='topic+blockmodel.expand'></span>

<h3>Description</h3>

<p><code>blockmodel.expand</code> takes a blockmodel and an expansion vector, and expands the former by making copies of the vertices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockmodel.expand(b, ev, mode="digraph", diag=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blockmodel.expand_+3A_b">b</code></td>
<td>
<p> blockmodel object. </p>
</td></tr>
<tr><td><code id="blockmodel.expand_+3A_ev">ev</code></td>
<td>
<p> a vector indicating the number of copies to make of each class (respectively). </p>
</td></tr>
<tr><td><code id="blockmodel.expand_+3A_mode">mode</code></td>
<td>
<p> a string indicating whether the result should be a &ldquo;graph&rdquo; or &ldquo;digraph&rdquo;. </p>
</td></tr>
<tr><td><code id="blockmodel.expand_+3A_diag">diag</code></td>
<td>
<p> a boolean indicating whether or not loops should be permitted. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The primary use of blockmodel expansion is in generating test data from a blockmodeling hypothesis.  Expansion is performed depending on the content type of the blockmodel; at present, only density is supported.  For the density content type, expansion is performed by interpreting the interclass density as an edge probability, and by drawing random graphs from the Bernoulli parameter matrix formed by expanding the density model.  Thus, repeated calls to <code>blockmodel.expand</code> can be used to generate a sample for monte carlo null hypothesis tests under a Bernoulli graph model.
</p>


<h3>Value</h3>

<p>An adjacency matrix, or stack thereof.
</p>


<h3>Note</h3>

<p> Eventually, other content types will be supported. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Doreian, P.; Batagelj, V.; and Ferligoj, A.  (2005).  <em>Generalized Blockmodeling.</em>  Cambridge: Cambridge University Press.
</p>
<p>White, H.C.; Boorman, S.A.; and Breiger, R.L.  (1976).  &ldquo;Social Structure from Multiple Networks I: Blockmodels of Roles and Positions.&rdquo;  <em>American Journal of Sociology</em>, 81, 730-779. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+blockmodel">blockmodel</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a random graph with _some_ edge structure
g.p&lt;-sapply(runif(20,0,1),rep,20)  #Create a matrix of edge 
                                   #probabilities
g&lt;-rgraph(20,tprob=g.p)            #Draw from a Bernoulli graph 
                                   #distribution

#Cluster based on structural equivalence
eq&lt;-equiv.clust(g)

#Form a blockmodel with distance relaxation of 15
b&lt;-blockmodel(g,eq,h=15)

#Draw from an expanded density blockmodel
g.e&lt;-blockmodel.expand(b,rep(2,length(b$rlabels)))  #Two of each class
g.e
</code></pre>

<hr>
<h2 id='bn'> Fit a Biased Net Model </h2><span id='topic+bn'></span><span id='topic+coef.bn'></span><span id='topic+bn.nlpl.dyad'></span><span id='topic+bn.nlpl.edge'></span><span id='topic+bn.nlpl.triad'></span><span id='topic+bn.nltl'></span><span id='topic+plot.bn'></span><span id='topic+print.bn'></span><span id='topic+print.summary.bn'></span><span id='topic+summary.bn'></span><span id='topic+bn_dyadstats_R'></span><span id='topic+bn_lpl_dyad_R'></span><span id='topic+bn_lpl_triad_R'></span><span id='topic+bn_ptriad_R'></span><span id='topic+bn_triadstats_R'></span>

<h3>Description</h3>

<p>Fits a biased net model to an input graph, using moment-based or maximum pseudolikelihood techniques.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bn(dat, method = c("mple.triad", "mple.dyad", "mple.edge", 
    "mtle"), param.seed = NULL, param.fixed = NULL, 
    optim.method = "BFGS", optim.control = list(), 
    epsilon = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bn_+3A_dat">dat</code></td>
<td>
<p> a single input graph. </p>
</td></tr>
<tr><td><code id="bn_+3A_method">method</code></td>
<td>
<p> the fit method to use (see below). </p>
</td></tr>
<tr><td><code id="bn_+3A_param.seed">param.seed</code></td>
<td>
<p> seed values for the parameter estimates. </p>
</td></tr>
<tr><td><code id="bn_+3A_param.fixed">param.fixed</code></td>
<td>
<p> parameter values to fix, if any. </p>
</td></tr>
<tr><td><code id="bn_+3A_optim.method">optim.method</code></td>
<td>
<p> method to be used by <code><a href="stats.html#topic+optim">optim</a></code>. </p>
</td></tr>
<tr><td><code id="bn_+3A_optim.control">optim.control</code></td>
<td>
<p> control parameter for <code><a href="stats.html#topic+optim">optim</a></code>. </p>
</td></tr>
<tr><td><code id="bn_+3A_epsilon">epsilon</code></td>
<td>
<p> tolerance for convergence to extreme parameter values (i.e., 0 or 1). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The biased net model stems from early work by Rapoport, who attempted to model networks via a hypothetical &quot;tracing&quot; process.  This process may be described loosely as follows.  One begins with a small &quot;seed&quot; set of vertices, each member of which is assumed to nominate (generate ties to) other members of the population with some fixed probability.  These members, in turn, may nominate new members of the population, as well as members who have already been reached.  Such nominations may be &quot;biased&quot; in one fashion or another, leading to a non-uniform growth process.  Specifically, let <code class="reqn">e_{ij}</code> be the random event that vertex <code class="reqn">i</code> nominates vertex <code class="reqn">j</code> when reached.  Then the conditional probability of <code class="reqn">e_{ij}</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">
\Pr(e_{ij}|T) = 1-\left(1-\Pr(B_e)\right) \prod_k \left(1-\Pr(B_k|T)\right)
</code>
</p>

<p>where <code class="reqn">T</code> is the current state of the trace, <code class="reqn">B_e</code> is the a Bernoulli event corresponding to the baseline probability of <code class="reqn">e_{ij}</code>, and the <code class="reqn">B_k</code> are &quot;bias events.&quot;  Bias events are taken to be independent Bernoulli trials, given <code class="reqn">T</code>, such that <code class="reqn">e_{ij}</code> is observed with certainty if any bias event occurs.  The specification of a biased net model, then, involves defining the various bias events (which, in turn, influence the structure of the network).
</p>
<p>Although other events have been proposed, the primary bias events employed in current biased net models are the &quot;parent bias&quot; (a tendency to return nominations); the &quot;sibling bias&quot; (a tendency to nominate alters who were nominated by the same third party); and the &quot;double role bias&quot; (a tendency to nominate alters who are both siblings and parents).  These bias events, together with the baseline edge events, are used to form the standard biased net model.  It is standard to assume homogeneity within bias class, leading to the four parameters <code class="reqn">\pi</code> (probability of a parent bias event), <code class="reqn">\sigma</code> (probability of a sibling bias event), <code class="reqn">\rho</code> (probability of a double role bias event), and <code class="reqn">d</code> (probability of a baseline event).  
</p>
<p>Unfortunately, there is no simple expression for the likelihood of a graph given these parameters (and hence, no basis for likelihood based inference).  However, Skvoretz et al. have derived a class of maximum pseudo-likelihood estimators for the the biased net model, based on local approximations to the likelihood at the edge, dyad, or triad level.  These estimators may be employed within <code>bn</code> by selecting the appropriate MPLE for the <em>method</em> argument.  Alternately, it is also possible to derive expected triad census rates for the biased net model, allowing an estimator which maximizes the likelihood of the observed triad census (essentially, a method of moments procedure).  This last may be selected via the argument <code>mode="mtle"</code>.  In addition to estimating model parameters, <code>bn</code> generates predicted edge, dyad, and triad census statistics, as well as structure statistics (using the Fararo-Sunshine recurrence).  These can be used to evaluate goodness-of-fit.  
</p>
<p><code>print</code>, <code>summary</code>, and <code>plot</code> methods are available for <code>bn</code> objects.  See <code><a href="#topic+rgbn">rgbn</a></code> for simulation from biased net models.
</p>


<h3>Value</h3>

<p>An object of class <code>bn</code>.
</p>


<h3>Note</h3>

<p> Asymptotic properties of the MPLE are not known for this model.  Caution is strongly advised. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Fararo, T.J. and Sunshine, M.H. (1964).  &ldquo;A study of a biased friendship net.&rdquo;  Syracuse, NY: Youth Development Center.
</p>
<p>Rapoport, A.  (1957).  &ldquo;A contribution to the theory of random and biased nets.&rdquo;  <em>Bulletin of Mathematical Biophysics,</em> 15, 523-533.
</p>
<p>Skvoretz, J.; Fararo, T.J.; and Agneessens, F.  (2004).  &ldquo;Advances in biased net theory: definitions, derivations, and estimations.&rdquo;  <em>Social Networks,</em> 26, 113-139.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rgbn">rgbn</a></code>, <code><a href="#topic+structure.statistics">structure.statistics</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a random graph
g&lt;-rgraph(25)

#Fit a biased net model, using the triadic MPLE
gbn&lt;-bn(g)

#Examine the results
summary(gbn)
plot(gbn)

#Now, fit a model containing only a density parameter
gbn&lt;-bn(g,param.fixed=list(pi=0,sigma=0,rho=0))
summary(gbn)
plot(gbn)

</code></pre>

<hr>
<h2 id='bonpow'> Find Bonacich Power Centrality Scores of Network Positions </h2><span id='topic+bonpow'></span>

<h3>Description</h3>

<p><code>bonpow</code> takes one or more graphs (<code>dat</code>) and returns the Boncich power centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  The decay rate for power contributions is specified by <code>exponent</code> (1 by default).  This function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bonpow(dat, g=1, nodes=NULL, gmode="digraph", diag=FALSE,
    tmaxdev=FALSE, exponent=1, rescale=FALSE, tol=1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bonpow_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="bonpow_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g</code>=1. </p>
</td></tr>
<tr><td><code id="bonpow_+3A_nodes">nodes</code></td>
<td>
<p> vector indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="bonpow_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  This is currently ignored. </p>
</td></tr>
<tr><td><code id="bonpow_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>Diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="bonpow_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev</code>=<code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="bonpow_+3A_exponent">exponent</code></td>
<td>
<p> exponent (decay rate) for the Bonacich power centrality score; can be negative </p>
</td></tr>
<tr><td><code id="bonpow_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="bonpow_+3A_tol">tol</code></td>
<td>
<p> tolerance for near-singularities during matrix inversion (see <code><a href="Matrix.html#topic+solve">solve</a></code>) </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bonacich's power centrality measure is defined by <code class="reqn">C_{BP}\left(\alpha,\beta\right)=\alpha\left(\mathbf{I}-\beta\mathbf{A}\right)^{-1}\mathbf{A}\mathbf{1}</code>, where <code class="reqn">\beta</code> is an attenuation parameter (set here by <code>exponent</code>) and <code class="reqn">\mathbf{A}</code> is the graph adjacency matrix.  (The coefficient <code class="reqn">\alpha</code> acts as a scaling parameter, and is set here (following Bonacich (1987)) such that the sum of squared scores is equal to the number of vertices.  This allows 1 to be used as a reference value for the &ldquo;middle&rdquo; of the centrality range.)  When <code class="reqn">\beta \rightarrow 1/\lambda_{\mathbf{A}1}</code> (the reciprocal of the largest eigenvalue of <code class="reqn">\mathbf{A}</code>), this is to within a constant multiple of the familiar eigenvector centrality score; for other values of <code class="reqn">\beta</code>, the behavior of the measure is quite different.  In particular, <code class="reqn">\beta</code> gives positive and negative weight to even and odd walks, respectively, as can be seen from the series expansion <code class="reqn">C_{BP}\left(\alpha,\beta\right)=\alpha \sum_{k=0}^\infty \beta^k \mathbf{A}^{k+1} \mathbf{1}</code> which converges so long as <code class="reqn">|\beta| &lt; 1/\lambda_{\mathbf{A}1}</code>.  The magnitude of <code class="reqn">\beta</code> controls the influence of distant actors on ego's centrality score, with larger magnitudes indicating slower rates of decay.  (High rates, hence, imply a greater sensitivity to edge effects.)
</p>
<p>Interpretively, the Bonacich power measure corresponds to the notion that the power of a vertex is recursively defined by the sum of the power of its alters.  The nature of the recursion involved is then controlled by the power exponent: positive values imply that vertices become more powerful as their alters become more powerful (as occurs in cooperative relations), while negative values imply that vertices become more powerful only as their alters become <em>weaker</em> (as occurs in competitive or antagonistic relations).  The magnitude of the exponent indicates the tendency of the effect to decay across long walks; higher magnitudes imply slower decay.  One interesting feature of this measure is its relative instability to changes in exponent magnitude (particularly in the negative case).  If your theory motivates use of this measure, you should be very careful to choose a decay parameter on a non-ad hoc basis.
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the centrality scores (depending on the number and size of the input graphs).
</p>


<h3>Warning </h3>

<p>Singular adjacency matrices cause no end of headaches for this algorithm; thus, the routine may fail in certain cases.  This will be fixed when I get a better algorithm.  <code>bonpow</code> will not symmetrize your data before extracting eigenvectors; don't send this routine asymmetric matrices unless you really mean to do so.</p>


<h3>Note</h3>

<p> The theoretical maximum deviation used here is not obtained with the star network, in general.  For positive exponents, at least, the symmetric maximum occurs for an empty graph with one complete dyad (the asymmetric maximum is generated by the outstar).  UCINET V seems not to adjust for this fact, which can cause some oddities in their centralization scores (thus, don't expect to get the same numbers with both packages).</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>References</h3>

<p> Bonacich, P.  (1972).  &ldquo;Factoring and Weighting Approaches to Status Scores and Clique Identification.&rdquo;  <em>Journal of Mathematical Sociology</em>, 2, 113-120.
</p>
<p>Bonacich, P.  (1987).  &ldquo;Power and Centrality: A Family of Measures.&rdquo; <em>American Journal of Sociology</em>, 92, 1170-1182.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+centralization">centralization</a></code>, <code><a href="#topic+evcent">evcent</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate some test data
dat&lt;-rgraph(10,mode="graph")
#Compute Bonpow scores
bonpow(dat,exponent=1,tol=1e-20)
bonpow(dat,exponent=-1,tol=1e-20)
</code></pre>

<hr>
<h2 id='brokerage'> Perform a Gould-Fernandez Brokerage Analysis </h2><span id='topic+brokerage'></span><span id='topic+summary.brokerage'></span><span id='topic+print.summary.brokerage'></span><span id='topic+brokerage_R'></span>

<h3>Description</h3>

<p>Performs the brokerage analysis of Gould and Fernandez on one or more input graphs, given a class membership vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brokerage(g, cl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brokerage_+3A_g">g</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="brokerage_+3A_cl">cl</code></td>
<td>
<p> a vector of class memberships. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Gould and Fernandez (following Marsden and others) describe <em>brokerage</em> as the role played by a social actor who mediates contact between two alters.  More formally, vertex <code class="reqn">v</code> is a broker for distinct vertices <code class="reqn">a</code> and <code class="reqn">b</code> iff <code class="reqn">a \to v \to b</code> and <code class="reqn">a \not\to b</code>.  Where actors belong to a priori distinct groups, group membership may be used to segment brokerage roles into particular types.  Let <code class="reqn">A \to B \to C</code> denote the two-path associated with a brokerage structure, such that some vertex from group <code class="reqn">B</code> brokers the connection from some vertex from group <code class="reqn">A</code> to a vertex in group <code class="reqn">C</code>.  The types of brokerage roles defined by Gould and Fernandez (and their accompanying two-path structures) are then defined in terms of group membership as follows:
</p>

<ul>
<li> <p><code class="reqn">w_I</code>: Coordinator role; the broker mediates contact between two individuals from his or her own group.  Two-path structure: <code class="reqn">A \to A \to A</code>  
</p>
</li>
<li> <p><code class="reqn">w_O</code>: Itinerant broker role; the broker mediates contact between two individuals from a single group to which he or she does not belong.  Two-path structure: <code class="reqn">A \to B \to A</code>  
</p>
</li>
<li> <p><code class="reqn">b_{OI}</code>: Gatekeeper role; the broker mediates an incoming contact from an out-group member to an in-group member.  Two-path structure: <code class="reqn">A \to B \to B</code>  
</p>
</li>
<li> <p><code class="reqn">b_{IO}</code>: Representative role; the broker mediates an outgoing contact from an in-group member to an out-group member.  Two-path structure: <code class="reqn">A \to A \to B</code>  
</p>
</li>
<li> <p><code class="reqn">b_O</code>: Liaison role; the broker mediates contact between two individuals from different groups, neither of which is the group to which he or she belongs.  Two-path structure: <code class="reqn">A \to B \to C</code>  
</p>
</li>
<li> <p><code class="reqn">t</code>: Total (cumulative) brokerage role occupancy.  (Any of the above two-paths.)   
</p>
</li></ul>

<p>The <em>brokerage score</em> for a given vertex with respect to a given role is the number of ordered pairs having the appropriate group membership(s) brokered by said vertex.  <code>brokerage</code> computes the brokerage scores for each vertex, given an input graph and vector of class memberships.  Aggregate scores are also computed at the graph level, which correspond to the total frequency of each role type within the network structure.  Expectations and variances of the brokerage scores conditional on size and density are computed, along with approximate <code class="reqn">z</code>-tests for incidence of brokerage.  (Note that the accuracy of the normality assumption is not known in the general case; see Gould and Fernandez (1989) for details.  Simulation-based tests may be desirable as an alternative.)
</p>


<h3>Value</h3>

<p>An object of class <code>brokerage</code>, containing the following elements:
</p>
<table>
<tr><td><code>raw.nli</code></td>
<td>
<p>The matrix of observed brokerage scores, by vertex</p>
</td></tr>
<tr><td><code>exp.nli</code></td>
<td>
<p>The matrix of expected brokerage scores, by vertex</p>
</td></tr>
<tr><td><code>sd.nli</code></td>
<td>
<p>The matrix of predicted brokerage score standard deviations, by vertex</p>
</td></tr>
<tr><td><code>z.nli</code></td>
<td>
<p>The matrix of standardized brokerage scores, by vertex</p>
</td></tr>
<tr><td><code>raw.gli</code></td>
<td>
<p>The vector of observed aggregate brokerage scores</p>
</td></tr>
<tr><td><code>exp.gli</code></td>
<td>
<p>The vector of expected aggregate brokerage scores</p>
</td></tr>
<tr><td><code>sd.gli</code></td>
<td>
<p>The vector of predicted aggregate brokerage score standard deviations</p>
</td></tr>
<tr><td><code>z.gli</code></td>
<td>
<p>The vector of standardized aggregate brokerage scores</p>
</td></tr>
<tr><td><code>exp.grp</code></td>
<td>
<p>The matrix of expected brokerage scores, by group</p>
</td></tr>
<tr><td><code>sd.grp</code></td>
<td>
<p>The matrix of predicted brokerage score standard deviations, by group</p>
</td></tr>
<tr><td><code>cl</code></td>
<td>
<p>The vector of class memberships</p>
</td></tr>
<tr><td><code>clid</code></td>
<td>
<p>The original class names</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The input class sizes</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>The order of the input network</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Gould, R.V. and Fernandez, R.M.  1989.  &ldquo;Structures of Mediation: A Formal Approach to Brokerage in Transaction Networks.&rdquo;  <em>Sociological Methodology,</em> 19: 89-126. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+triad.census">triad.census</a></code>, <code><a href="#topic+gtrans">gtrans</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw a random network with 3 groups
g&lt;-rgraph(15)
cl&lt;-rep(1:3,5)

#Compute a brokerage object
b&lt;-brokerage(g,cl)
summary(b)
</code></pre>

<hr>
<h2 id='centralgraph'> Find the Central Graph of a Labeled Graph Stack </h2><span id='topic+centralgraph'></span>

<h3>Description</h3>

<p>Returns the central graph of a set of labeled graphs, i.e. that graph in which i-&gt;j iff i-&gt;j in &gt;=50% of the graphs within the set.  If <code>normalize==TRUE</code>, then the value of the i,jth edge is given as the proportion of graphs in which i-&gt;j.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centralgraph(dat, normalize=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="centralgraph_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="centralgraph_+3A_normalize">normalize</code></td>
<td>
<p> boolean indicating whether the results should be normalized.  The result of this is the &quot;mean matrix&quot;.  By default, <code>normalize==FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The central graph of a set of graphs S is that graph C which minimizes the sum of Hamming distances between C and G in S.  As such, it turns out (for the dichotomous case, at least), to be analogous to both the mean and median for sets of graphs.  The central graph is useful in a variety of contexts; see the references below for more details.
</p>


<h3>Value</h3>

<p>A matrix containing the central graph (or mean matrix)
</p>


<h3>Note</h3>

<p> 0.5 is used as the cutoff value regardless of whether or not the data is dichotomous (as is tacitly assumed).  The routine is unaffected by data type when <code>normalize==TRUE</code>. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Banks, D.L., and Carley, K.M.  (1994).  &ldquo;Metric Inference for Social Networks.&rdquo;  <em>Journal of Classification</em>, 11(1), 121-49. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+hdist">hdist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate some random graphs
dat&lt;-rgraph(10,5)
#Find the central graph
cg&lt;-centralgraph(dat)
#Plot the central graph
gplot(cg)
#Now, look at the mean matrix
cg&lt;-centralgraph(dat,normalize=TRUE)
print(cg)
</code></pre>

<hr>
<h2 id='centralization'> Find the Centralization of a Given Network, for Some Measure of Centrality  </h2><span id='topic+centralization'></span>

<h3>Description</h3>

<p><code>Centralization</code> returns the centralization GLI (graph-level index) for a given graph in <code>dat</code>, given a (node) centrality measure <code>FUN</code>.  <code>Centralization</code> follows Freeman's (1979) generalized definition of network centralization, and can be used with any properly defined centrality measure.  This measure must be implemented separately; see the references below for examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centralization(dat, FUN, g=NULL, mode="digraph", diag=FALSE, 
    normalize=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="centralization_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="centralization_+3A_fun">FUN</code></td>
<td>
<p> Function to return nodal centrality scores.</p>
</td></tr>
<tr><td><code id="centralization_+3A_g">g</code></td>
<td>
<p> Integer indicating the index of the graph for which centralization should be computed.  By default, all graphs are employed. </p>
</td></tr>
<tr><td><code id="centralization_+3A_mode">mode</code></td>
<td>
<p> String indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>mode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
<tr><td><code id="centralization_+3A_diag">diag</code></td>
<td>
<p> Boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="centralization_+3A_normalize">normalize</code></td>
<td>
<p> Boolean indicating whether or not the centralization score should be normalized to the theoretical maximum.  (Note that this function relies on <code>FUN</code> to return this value when called with <code>tmaxdev==TRUE</code>.)  By default, <code>tmaxdev==TRUE</code>. </p>
</td></tr>
<tr><td><code id="centralization_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code>FUN</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The centralization of a graph G for centrality measure <code class="reqn">C(v)</code> is defined (as per Freeman (1979)) to be:
</p>
<p style="text-align: center;"><code class="reqn">C^*(G) = \sum_{i \in V(G)} \left|\max_{v \in V(G)}(C(v))-C(i)\right|</code>
</p>

<p>Or, equivalently, the absolute deviation from the maximum of C on G.  Generally, this value is normalized by the theoretical maximum centralization score, conditional on <code class="reqn">|V(G)|</code>.  (Here, this functionality is activated by <code>normalize</code>.)  <code>Centralization</code> depends on the function specified by <code>FUN</code> to return the vector of nodal centralities when called with <code>dat</code> and <code>g</code>, and to return the theoretical maximum value when called with the above and <code>tmaxdev==TRUE</code>.  For an example of such a centrality routine, see <code><a href="#topic+degree">degree</a></code>.
</p>


<h3>Value</h3>

<p>The centralization of the specified graph.
</p>


<h3>Note</h3>

<p> See <code><a href="#topic+cugtest">cugtest</a></code> for null hypothesis tests involving centralization scores. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Freeman, L.C.  (1979).  &ldquo;Centrality in Social Networks I: Conceptual Clarification.&rdquo; <em>Social Networks</em>, 1, 215-239.
</p>
<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+cugtest">cugtest</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate some random graphs
dat&lt;-rgraph(5,10)
#How centralized is the third one on indegree?
centralization(dat,g=3,degree,cmode="indegree")
#How about on total (Freeman) degree?
centralization(dat,g=3,degree)
</code></pre>

<hr>
<h2 id='clique.census'>
Compute Cycle Census Information
</h2><span id='topic+clique.census'></span><span id='topic+cliques_R'></span>

<h3>Description</h3>

<p><code>clique.census</code> computes clique census statistics on one or more input graphs.  In addition to aggregate counts of maximal cliques, results may be disaggregated by vertex and co-membership information may be computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clique.census(dat, mode = "digraph", tabulate.by.vertex = TRUE,
    clique.comembership = c("none", "sum", "bysize"), enumerate = TRUE,
    na.omit = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clique.census_+3A_dat">dat</code></td>
<td>

<p>one or more input graphs.
</p>
</td></tr>
<tr><td><code id="clique.census_+3A_mode">mode</code></td>
<td>

<p><code>"digraph"</code> for directed graphs, or <code>"graph"</code> for undirected graphs.
</p>
</td></tr>
<tr><td><code id="clique.census_+3A_tabulate.by.vertex">tabulate.by.vertex</code></td>
<td>

<p>logical; should maximal clique counts be tabulated by vertex? 
</p>
</td></tr>
<tr><td><code id="clique.census_+3A_clique.comembership">clique.comembership</code></td>
<td>

<p>the type of clique co-membership information to be tabulated, if any.  <code>"sum"</code> returns a vertex by vertex matrix of clique co-membership counts; these are disaggregated by clique size if <code>"bysize"</code> is used.  If <code>"none"</code> is given, no co-membership information is computed.
</p>
</td></tr>
<tr><td><code id="clique.census_+3A_enumerate">enumerate</code></td>
<td>

<p>logical; should an enumeration of all maximal cliques be returned?
</p>
</td></tr>
<tr><td><code id="clique.census_+3A_na.omit">na.omit</code></td>
<td>

<p>logical; should missing edges be omitted?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A (maximal) <em>clique</em> is a maximal set of mutually adjacenct vertices.  Cliques are important for their role as cohesive subgroups, but show up in many other contexts as well.
</p>
<p>A <em>subgraph census statistic</em> is a function which, for any given graph and subgraph, gives the number of copies of the latter contained in the former.  A collection of subgraph census statistics is referred to as a <em>subgraph census</em>; widely used examples include the dyad and triad censuses, implemented in <code>sna</code> by the <code><a href="#topic+dyad.census">dyad.census</a></code> and <code><a href="#topic+triad.census">triad.census</a></code> functions (respectively).  Likewise, <code>kpath.census</code> and <code>kcycle.census</code> compute a range of census statistics related to <code class="reqn">k</code>-paths and <code class="reqn">k</code>-cycles.   <code>clique.census</code> provides similar functionality for the census of maximal cliques, including:
</p>

<ul>
<li><p> Aggregate counts of maximal cliques by size. 
</p>
</li>
<li><p> Counts of cliques to which each vertex belongs (when <code>tabulate.byvertex==TRUE</code>). 
</p>
</li>
<li><p> Counts of clique co-memberships, potentially disaggregated by size (when the appropriate co-membership argument is set to <code>bylength</code>). 
</p>
</li></ul>

<p>These calculations are intrinsically expensive (clique enumeration is NP hard in the general case), and users should be aware that computing the census can be impractical on large graphs (unless they are very sparse).  On the other hand, the algorithm employed here (a variant of Makino and Uno (2004)) is generally fast enough to suport enumeration for even dense graphs of several hundred vertices on a typical desktop computer.
</p>
<p>Calling this function with <code>mode=="digraph"</code>, forces and initial symmetrization step, which can be avoided with <code>mode=="graph"</code>.  While incorrectly employing the default is harmless (except for the relatively small cost of verifying symmetry), setting <code>mode=="graph"</code> incorrectly may result in problematic behavior.  When in doubt, stick with the default.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>clique.count</code></td>
<td>
<p>If <code>tabulate.byvertex==FALSE</code>, a vector of aggregate counts by clique size.  Otherwise, a matrix whose first column is a vector of aggregate clique counts, and whose succeeding columns contain vectors of clique counts for each vertex.</p>
</td></tr>
<tr><td><code>clique.comemb</code></td>
<td>
<p>If <code>clique.comembership!="none"</code>, a matrix or array containing co-membership in cliques by vertex pairs.  If <code>clique.comembership=="sum"</code>, only a matrix of co-memberships is returned; if <code>bysize</code> is used, however, co-memberships are returned in a <code>maxsize</code> by <code class="reqn">n</code> by <code class="reqn">n</code> array whose <code class="reqn">i,j,k</code>th cell is the number of cliques of size <code class="reqn">i</code> containing <code>j</code> and <code>k</code> (with <code>maxsize</code> being the size of the largest maximal clique).</p>
</td></tr>
<tr><td><code>cliques</code></td>
<td>
<p>If <code>enumerate=TRUE</code>, a list of length equal to the maximum clique size, each element of which is in turn a list of all cliques of corresponding size (given as vectors of vertices).</p>
</td></tr>
</table>


<h3>Warning </h3>

<p> The computational cost of calculating cliques grows very sharply in size and network density.  It is possible that the expected completion time for your calculation may exceed your life expectancy (and those of subsequent generations). </p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Wasserman, S. and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.
</p>
<p>Makino, K. and Uno, T.  (2004.)  &ldquo;New Algorithms for Enumerating All Maximal Cliques.&rdquo;  In T. Hagerup and J. Katajainen (eds.), <em>SWAT 2004</em>, LNCS 3111, 260-272.  Berlin: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dyad.census">dyad.census</a></code>, <code><a href="#topic+triad.census">triad.census</a></code>, <code><a href="#topic+kcycle.census">kcycle.census</a></code>, <code><a href="#topic+kpath.census">kpath.census</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a fairly dense random graph
g&lt;-rgraph(25)

#Obtain cliques by vertex, with co-membership by size
cc&lt;-clique.census(g,clique.comembership="bysize")
cc$clique.count                             #Examine clique counts
cc$clique.comemb[1,,]                       #Isolate co-membership is trivial
cc$clique.comemb[2,,]                       #Co-membership for 2-cliques
cc$clique.comemb[3,,]                       #Co-membership for 3-cliques
cc$cliques                                  #Enumerate the cliques
</code></pre>

<hr>
<h2 id='closeness'> Compute the Closeness Centrality Scores of Network Positions </h2><span id='topic+closeness'></span>

<h3>Description</h3>

<p><code>closeness</code> takes one or more graphs (<code>dat</code>) and returns the closeness centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  Depending on the specified mode, closeness on directed or undirected geodesics will be returned; this function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>closeness(dat, g=1, nodes=NULL, gmode="digraph", diag=FALSE, 
    tmaxdev=FALSE, cmode="directed", geodist.precomp=NULL, 
    rescale=FALSE, ignore.eval=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="closeness_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="closeness_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g</code>=1. </p>
</td></tr>
<tr><td><code id="closeness_+3A_nodes">nodes</code></td>
<td>
<p> list indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="closeness_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>gmode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
<tr><td><code id="closeness_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="closeness_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev==FALSE</code>. </p>
</td></tr>
<tr><td><code id="closeness_+3A_cmode">cmode</code></td>
<td>
<p> string indicating the type of closeness centrality being computed (distances on directed or undirected pairs, or an alternate measure). </p>
</td></tr>
<tr><td><code id="closeness_+3A_geodist.precomp">geodist.precomp</code></td>
<td>
<p> a <code><a href="#topic+geodist">geodist</a></code> object precomputed for the graph to be analyzed (optional) </p>
</td></tr>
<tr><td><code id="closeness_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="closeness_+3A_ignore.eval">ignore.eval</code></td>
<td>
<p> logical; should edge values be ignored when calculating geodesics?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The closeness of a vertex v is defined as
</p>
<p style="text-align: center;"><code class="reqn">C_C(v) = \frac{\left|V\left(G\right)\right|-1}{\sum_{i : i \neq v} d(v,i)}</code>
</p>

<p>where <code class="reqn">d(i,j)</code> is the geodesic distance between i and j (where defined).  Closeness is ill-defined on disconnected graphs; in such cases, this routine substitutes <code>Inf</code>.  It should be understood that this modification is not canonical (though it is common), but can be avoided by not attempting to measure closeness on disconnected graphs in the first place!  Intuitively, closeness provides an index of the extent to which a given vertex has short paths to all other vertices in the graph; this is one reasonable measure of the extent to which a vertex is in the &ldquo;middle&rdquo; of a given structure.
</p>
<p>An alternate form of closeness (apparently due to Gil and Schmidt (1996)) is obtained by taking the sum of the inverse distances to each vertex, i.e.
</p>
<p style="text-align: center;"><code class="reqn">C_C(v) = \frac{\sum_{i : i \neq v} \frac{1}{d(v,i)}}{\left|V\left(G\right)\right|-1}.</code>
</p>
<p>  This measure correlates well with the standard form of closeness where both are well-defined, but lacks the latter's pathological behavior on disconnected graphs.  Computation of alternate closeness may be performed via the argument <code>cmode="suminvdir"</code> (directed case) and <code>cmode="suminvundir"</code> (undirected case).  The corresponding arguments <code>cmode="directed"</code> and <code>cmode="undirected"</code> return the standard closeness scores in the directed or undirected cases (respectively).  Although treated here as a measure of closeness, this index was originally intended to capture power or efficacy; in its original form, the Gil-Schmidt power index is a renormalized version of the above.  Specifically, let <code class="reqn">R(v,G)</code> be the set of vertices reachable by <code class="reqn">v</code> in <code class="reqn">V\setminus v</code>.  Then the Gil-Schmidt power index is defined as
</p>
<p style="text-align: center;"><code class="reqn">C_{GS}(v) = \frac{\sum_{i \in R(v,G)} \frac{1}{d(v,i)}}{|R(v,G)|}.</code>
</p>

<p>with <code class="reqn">C_{GS}</code> defined to be 0 for vertices with no outneighbors.  This may be obtained via the argument <code>cmode="gil-schmidt"</code>.
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the closeness scores (depending on the number and size of the input graphs).
</p>


<h3>Note</h3>

<p> Judicious use of <code>geodist.precomp</code> can save a great deal of time when computing multiple path-based indices on the same network. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts, <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Freeman, L.C.  (1979).  &ldquo;Centrality in Social Networks I: Conceptual Clarification.&rdquo; <em>Social Networks</em>, 1, 215-239. 
</p>
<p>Gil, J. and Schmidt, S.  (1996).  &ldquo;The Origin of the Mexican Network of Power&rdquo;.  Proceedings of the International Social Network Conference, Charleston, SC, 22-25.
</p>
<p>Sinclair, P.A.  (2009).  &ldquo;Network Centralization with the Gil Schmidt Power Centrality Index&rdquo;  <em>Social Networks</em>, 29, 81-92.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+centralization">centralization</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(10)     #Draw a random graph with 10 members
closeness(g)      #Compute closeness scores

</code></pre>

<hr>
<h2 id='coleman'>
Coleman's High School Friendship Data
</h2><span id='topic+coleman'></span>

<h3>Description</h3>

<p>James Coleman (1964) reports research on self-reported friendship ties among 73 boys in a small high school in Illinois over the 1957-1958 academic year.  Networks of reported ties for all 73 informants are provided for two time points (fall and spring). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(coleman)</code></pre>


<h3>Format</h3>

<p>An adjacency array containing two directed, unvalued 73-node networks:
</p>

<table>
<tr>
 <td style="text-align: right;">
    [1,,] </td><td style="text-align: left;"> Fall  </td><td style="text-align: left;"> binary matrix </td><td style="text-align: left;"> Friendship for Fall, 1957</td>
</tr>
<tr>
 <td style="text-align: right;">
    [2,,] </td><td style="text-align: left;"> Spring  </td><td style="text-align: left;"> binary matrix </td><td style="text-align: left;"> Friendship for Spring, 1958</td>
</tr>
<tr>
 <td style="text-align: right;">
   </td>
</tr>

</table>
 


<h3>Details</h3>

<p>Both networks reflect answers to the question, &ldquo;What fellows here in school do you go around with most often?&rdquo; with the presence of an <code class="reqn">(i,j,k)</code> edge indicating that <code class="reqn">j</code> nominated <code class="reqn">k</code> in time period <code class="reqn">i</code>.  The data are unvalued and directed; although the self-reported ties are highly reciprocal, unreciprocated nominations are possible.
</p>
<p>It should be noted that, although this data is usually described as &ldquo;friendship,&rdquo; the sociometric item employed might be more accurately characterized as eliciting &ldquo;frequent elective interaction.&rdquo;  This should be borne in mind when interpreting this data.
</p>


<h3>References</h3>

<p>Coleman, J. S.  (1964).  <em>Introduction to Mathermatical Sociology.</em> New York: Free Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(coleman)

#Plot showing edges by time point
gplot(coleman[1,,]|coleman[2,,],edge.col=2*coleman[1,,]+3*coleman[2,,])
</code></pre>

<hr>
<h2 id='component.dist'> Calculate the Component Size Distribution of a Graph </h2><span id='topic+component.dist'></span><span id='topic+component.largest'></span><span id='topic+undirComponents_R'></span><span id='topic+component_dist_R'></span>

<h3>Description</h3>

<p><code>component.dist</code> returns a list containing a vector of length <code>n</code> such that the <code>i</code>th element contains the number of components of graph <code class="reqn">G</code> having size <code>i</code>, and a vector of length <code>n</code> giving component membership (where <code>n</code> is the graph order).  Component strength is determined by the <code>connected</code> parameter; see below for details.
</p>
<p><code>component.largest</code> identifies the component(s) of maximum order within graph <code>G</code>.  It returns either a <code>logical</code> vector indicating membership in a maximum component or the adjacency matrix of the subgraph of <code class="reqn">G</code> induced by the maximum component(s), as determined by <code>result</code>.  Component strength is determined as per <code>component.dist</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>component.dist(dat, connected=c("strong","weak","unilateral",
     "recursive"))

component.largest(dat, connected=c("strong","weak","unilateral",
     "recursive"), result = c("membership", "graph"), return.as.edgelist =
     FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="component.dist_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="component.dist_+3A_connected">connected</code></td>
<td>
<p> a string selecting strong, weak, unilateral or recursively connected components; by default, <code>"strong"</code> components are used.</p>
</td></tr>
<tr><td><code id="component.dist_+3A_result">result</code></td>
<td>
<p> a string indicating whether a vector of membership indicators or the induced subgraph of the component should be returned. </p>
</td></tr>
<tr><td><code id="component.dist_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; if <code>result=="graph"</code>, should the resulting structure be returned in edgelist form?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Components are maximal sets of mutually connected vertices; depending on the definition of &ldquo;connected&rdquo; one employs, one can arrive at several types of components.  Those supported here are as follows (in increasing order of restrictiveness):
</p>

<ol>
<li> <p><code>weak</code>:  <code class="reqn">v_1</code> is connected to <code class="reqn">v_2</code> iff there exists a semi-path from <code class="reqn">v_1</code> to <code class="reqn">v_2</code> (i.e., a path in the weakly symmetrized graph)
</p>
</li>
<li> <p><code>unilateral</code>:  <code class="reqn">v_1</code> is connected to <code class="reqn">v_2</code> iff there exists a directed path from <code class="reqn">v_1</code> to <code class="reqn">v_2</code> <em>or</em> a directed path from <code class="reqn">v_2</code> to <code class="reqn">v_1</code>
</p>
</li>
<li> <p><code>strong</code>:  <code class="reqn">v_1</code> is connected to <code class="reqn">v_2</code> iff there exists a directed path from <code class="reqn">v_1</code> to <code class="reqn">v_2</code> <em>and</em> a directed path from <code class="reqn">v_2</code> to <code class="reqn">v_1</code>
</p>
</li>
<li> <p><code>recursive</code>:  <code class="reqn">v_1</code> is connected to <code class="reqn">v_2</code> iff there exists a vertex sequence <code class="reqn">v_a,\ldots,v_z</code> such that <code class="reqn">v_1,v_a,\ldots,v_z,v_2</code> and <code class="reqn">v_2,v_z,\ldots,v_a,v_1</code> are directed paths
</p>
</li></ol>

<p>Note that the above definitions are distinct for directed graphs only; if <code>dat</code> is symmetric, then the <code>connected</code> parameter has no effect.  
</p>


<h3>Value</h3>

<p>For <code>component.dist</code>, a list containing:
</p>
<table>
<tr><td><code>membership</code></td>
<td>
<p>A vector of component memberships, by vertex</p>
</td></tr>
<tr><td><code>csize</code></td>
<td>
<p>A vector of component sizes, by component</p>
</td></tr>
<tr><td><code>cdist</code></td>
<td>
<p>A vector of length |V(G)| with the (unnormalized) empirical distribution function of component sizes</p>
</td></tr>
</table>
<p>If multiple input graphs are given, the return value is a list of lists.
</p>
<p>For <code>component.largest</code>, either a <code>logical</code> vector of component membership indicators or the adjacency matrix/edgelist of the subgraph induced by the largest component(s) is returned.  If multiple graphs were given as input, a list of results is returned.
</p>


<h3>Note</h3>

<p>Unilaterally connected component partitions may not be well-defined, since it is possible for a given vertex to be unilaterally connected to two vertices that are not unilaterally connected with one another.  Consider, for instance, the graph <code class="reqn">a \rightarrow b \leftarrow c \rightarrow d</code>.  In this case, the maximal unilateral components are <code class="reqn">ab</code> and <code class="reqn">bcd</code>, with vertex <code class="reqn">b</code> properly belonging to both components.  For such graphs, a unique partition of vertices by component does not exist, and we &ldquo;solve&rdquo; the problem by allocating each &ldquo;problem vertex&rdquo; to one of its components on an essentially arbitrary basis.  (<code>component.dist</code> generates a warning when this occurs.)  It is recommended that the <code>unilateral</code> option be avoided where possible.
</p>
<p>Do not make the mistake of assuming that the subgraphs returned by <code>component.largest</code> are necessarily connected.  This is <em>usually</em> the case, but depends upon the uniqueness of the largest component.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> West, D.B.  (1996).  <em>Introduction to Graph Theory.</em>  Upper Saddle River, N.J.: Prentice Hall.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+components">components</a></code>, <code><a href="#topic+symmetrize">symmetrize</a></code>, <code><a href="#topic+reachability">reachability</a></code> <code><a href="#topic+geodist">geodist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(20,tprob=0.06)   #Generate a sparse random graph

#Find weak components
cd&lt;-component.dist(g,connected="weak")
cd$membership              #Who's in what component?
cd$csize                   #What are the component sizes?
                           #Plot the size distribution
plot(1:length(cd$cdist),cd$cdist/sum(cd$cdist),ylim=c(0,1),type="h")  
lgc&lt;-component.largest(g,connected="weak")  #Get largest component
gplot(g,vertex.col=2+lgc)  #Plot g, with component membership
                           #Plot largest component itself 
gplot(component.largest(g,connected="weak",result="graph"))

#Find strong components
cd&lt;-component.dist(g,connected="strong")
cd$membership              #Who's in what component?
cd$csize                   #What are the component sizes?
                           #Plot the size distribution
plot(1:length(cd$cdist),cd$cdist/sum(cd$cdist),ylim=c(0,1),type="h")
lgc&lt;-component.largest(g,connected="strong")  #Get largest component
gplot(g,vertex.col=2+lgc)  #Plot g, with component membership
                           #Plot largest component itself 
gplot(component.largest(g,connected="strong",result="graph"))
</code></pre>

<hr>
<h2 id='component.size.byvertex'>
Get Component Sizes, by Vertex
</h2><span id='topic+component.size.byvertex'></span><span id='topic+compsizes_R'></span>

<h3>Description</h3>

<p>This function computes the component structure of the input network, and returns a vector whose <code class="reqn">i</code>th entry is the size of the component to which <code class="reqn">i</code> belongs.  This is useful e.g. for studies of diffusion or similar applications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>component.size.byvertex(dat, connected = c("strong", "weak", 
    "unilateral", "recursive"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="component.size.byvertex_+3A_dat">dat</code></td>
<td>

<p>one or more input graphs (for best performance, sna edgelists or network objects are suggested).
</p>
</td></tr>
<tr><td><code id="component.size.byvertex_+3A_connected">connected</code></td>
<td>

<p>a string selecting the connectedness definition to use; by default, <code>"strong"</code> components are used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Component sizes are here computed using <code><a href="#topic+component.dist">component.dist</a></code>; see this function for additional information.
</p>
<p>In an undirected graph, the size of <code class="reqn">v</code>'s component represents the maximum number of nodes that can be reached by a diffusion process along the edges of the graph originating with node <code class="reqn">v</code>; the expectation of component sizes by vertex (rather than the mean component size) is thus one measure of the maximum average diffusion potential of a graph.  Because this quantity is monotone with respect to edge addition, it can be bounded using Bernoulli graphs (see Butts (2011)).  In the directed case, multiple types of components are possible; see <code><a href="#topic+component.dist">component.dist</a></code> for details.
</p>


<h3>Value</h3>

<p>A vector of length equal to the number of vertices in <code>dat</code>, whose <code class="reqn">i</code>th element is the number of vertices in the component to which the <code class="reqn">i</code>th vertex belongs.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>West, D.B.  (1996).  <em>Introduction to Graph Theory.</em> Upper Saddle River, N.J.: Prentice Hall.
</p>
<p>Butts, C.T.  (2011).  &ldquo;Bernoulli Bounds for General Random Graphs.&rdquo;  <em>Sociological Methodology</em>, 41, 299-345.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+component.dist">component.dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a random undirected graph
g&lt;-rgraph(100,tprob=1.5/99,mode="graph",return.as.edgelist=TRUE)

#Get the component sizes for each vertex
cs&lt;-component.size.byvertex(g)
cs
</code></pre>

<hr>
<h2 id='components'> Find the Number of (Maximal) Components Within a Given Graph </h2><span id='topic+components'></span>

<h3>Description</h3>

<p>Returns the number of components within <code>dat</code>, using the connectedness rule given in <code>connected</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>components(dat, connected="strong", comp.dist.precomp=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="components_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="components_+3A_connected">connected</code></td>
<td>
<p> the the component definition to be used by <code><a href="#topic+component.dist">component.dist</a></code> during component extraction. </p>
</td></tr>
<tr><td><code id="components_+3A_comp.dist.precomp">comp.dist.precomp</code></td>
<td>
<p> a component size distribution object from <code><a href="#topic+component.dist">component.dist</a></code> (optional). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>connected</code> parameter corresponds to the <code>rule</code> parameter of <code><a href="#topic+component.dist">component.dist</a></code>.  By default, <code>components</code> returns the number of strong components, but other component types can be returned if so desired.  (See <code><a href="#topic+component.dist">component.dist</a></code> for details.)  For symmetric matrices, this is obviously a moot point.
</p>


<h3>Value</h3>

<p>A vector containing the number of components for each graph in <code>dat</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> West, D.B.  (1996).  <em>Introduction to Graph Theory</em>.  Upper Saddle River, NJ: Prentice Hall. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+component.dist">component.dist</a></code>, <code><a href="#topic+symmetrize">symmetrize</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(20,tprob=0.05)   #Generate a sparse random graph

#Find weak components
components(g,connected="weak")

#Find strong components
components(g,connected="strong")

</code></pre>

<hr>
<h2 id='connectedness'> Compute Graph Connectedness Scores </h2><span id='topic+connectedness'></span><span id='topic+connectedness_R'></span>

<h3>Description</h3>

<p><code>connectedness</code> takes one or more graphs (<code>dat</code>) and returns the Krackhardt connectedness scores for the graphs selected by <code>g</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>connectedness(dat, g=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="connectedness_+3A_dat">dat</code></td>
<td>
<p> one or more graphs. </p>
</td></tr>
<tr><td><code id="connectedness_+3A_g">g</code></td>
<td>
<p> index values for the graphs to be utilized; by default, all graphs are selected. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Krackhardt's connectedness for a digraph <code class="reqn">G</code> is equal to the fraction of all dyads, <code class="reqn">\{i,j\}</code>, such that there exists an undirected path from <code class="reqn">i</code> to <code class="reqn">j</code> in <code class="reqn">G</code>.  (This, in turn, is just the density of the weak <code><a href="#topic+reachability">reachability</a></code> graph of <code class="reqn">G</code>.)  Obviously, the connectedness score ranges from 0 (for the null graph) to 1 (for weakly connected graphs).
</p>
<p>Connectedness is one of four measures (<code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+hierarchy">hierarchy</a></code>, and <code><a href="#topic+lubness">lubness</a></code>) suggested by Krackhardt for summarizing hierarchical structures.  Each corresponds to one of four axioms which are necessary and sufficient for the structure in question to be an outtree; thus, the measures will be equal to 1 for a given graph iff that graph is an outtree.  Deviations from unity can be interpreted in terms of failure to satisfy one or more of the outtree conditions, information which may be useful in classifying its structural properties.
</p>


<h3>Value</h3>

<p>A vector containing the connectedness scores
</p>


<h3>Note</h3>

<p>The four Krackhardt indices are, in general, nondegenerate for a relatively narrow band of size/density combinations (efficiency being the sole exception).  This is primarily due to their dependence on the reachability graph, which tends to become complete rapidly as size/density increase.  See Krackhardt (1994) for a useful simulation study.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Krackhardt, David.  (1994).  &ldquo;Graph Theoretical Dimensions of Informal Organizations.&rdquo; In K. M. Carley and M. J. Prietula (Eds.), <em>Computational Organization Theory</em>, 89-111. Hillsdale, NJ: Lawrence Erlbaum and Associates.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+hierarchy">hierarchy</a></code>, <code><a href="#topic+lubness">lubness</a></code>, <code><a href="#topic+reachability">reachability</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Get connectedness scores for graphs of varying densities
connectedness(rgraph(10,5,tprob=c(0.1,0.25,0.5,0.75,0.9)))
</code></pre>

<hr>
<h2 id='consensus'> Estimate a Consensus Structure from Multiple Observations </h2><span id='topic+consensus'></span>

<h3>Description</h3>

<p><code>consensus</code> estimates a central or consensus structure given multiple observations, using one of several algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensus(dat, mode="digraph", diag=FALSE, method="central.graph", 
    tol=1e-06, maxiter=1e3, verbose=TRUE, no.bias=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="consensus_+3A_dat">dat</code></td>
<td>
<p> a set of input graphs (must have same order). </p>
</td></tr>
<tr><td><code id="consensus_+3A_mode">mode</code></td>
<td>
 <p><code>"digraph"</code> for directed data, else <code>"graph"</code>. </p>
</td></tr>
<tr><td><code id="consensus_+3A_diag">diag</code></td>
<td>
<p> logical; should diagonals (loops) be treated as data? </p>
</td></tr>
<tr><td><code id="consensus_+3A_method">method</code></td>
<td>
<p> one of <code>"central.graph"</code>, <code>"single.reweight"</code>, <code>"iterative.reweight"</code>, <code>"romney.batchelder"</code>, <code>"PCA.reweight"</code>, <code>"LAS.intersection"</code>, <code>"LAS.union"</code>, <code>"OR.row"</code>, or <code>"OR.col"</code>.  </p>
</td></tr>
<tr><td><code id="consensus_+3A_tol">tol</code></td>
<td>
<p> convergence tolerance for the iterative reweighting and B-R algorithms.</p>
</td></tr>
<tr><td><code id="consensus_+3A_maxiter">maxiter</code></td>
<td>
<p> maximum number of iterations to take (regardless of convergence) for the iterative reweighting and B-R algorithms.</p>
</td></tr>
<tr><td><code id="consensus_+3A_verbose">verbose</code></td>
<td>
<p> logical; should bias and competency parameters be reported (where computed)?</p>
</td></tr>
<tr><td><code id="consensus_+3A_no.bias">no.bias</code></td>
<td>
<p> logical; should responses be assumed to be unbiased? </p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The term &ldquo;consensus structure&rdquo; is used by a number of authors to reflect a notion of shared or common perceptions of social structure among a set of observers.  As there are many interpretations of what is meant by &ldquo;consensus&rdquo; (and as to how best to estimate it), several algorithms are employed here:
</p>

<ol>
<li> <p><code>central.graph</code>: Estimate the consensus structure using the central graph.  This corresponds to a &ldquo;median response&rdquo; notion of consensus.
</p>
</li>
<li> <p><code>single.reweight</code>: Estimate the consensus structure using subject responses, reweighted by mean graph correlation.  This corresponds to an &ldquo;expertise-weighted vote&rdquo; notion of consensus.
</p>
</li>
<li> <p><code>iterative.reweight</code>: Similar to <code>single.reweight</code>, but the consensus structure and accuracy parameters are estimated via an iterated proportional fitting scheme.  The implementation employed here uses both bias and competency parameters.
</p>
</li>
<li> <p><code>romney.batchelder</code>: Fits a Romney-Batchelder informant accuracy model using IPF.  This is very similar to <code>iterative.reweight</code>, but can be interpreted as the result of a process in which each informant report is correct with a probability equal to the informant's competency score, and otherwise equal to a Bernoulli trial with parameter equal to the informant's bias score.
</p>
</li>
<li> <p><code>PCA.reweight</code>: Estimate the consensus using the (scores on the) first component of a network PCA.  This corresponds to a &ldquo;shared theme&rdquo; or &ldquo;common element&rdquo; notion of consensus.
</p>
</li>
<li> <p><code>LAS.intersection</code>: Estimate the consensus structure using the locally aggregated structure (intersection rule).  In this model, an i-&gt;j edge exists iff i <em>and</em> j agree that it exists.
</p>
</li>
<li> <p><code>LAS.union</code>: Estimate the consensus structure using the locally aggregated structure (union rule).  In this model, an i-&gt;j edge exists iff i <em>or</em> j agree that it exists.
</p>
</li>
<li> <p><code>OR.row</code>: Estimate the consensus structure using own report.  Here, we take each informant's outgoing tie reports to be correct.
</p>
</li>
<li> <p><code>OR.col</code>: Estimate the consensus structure using own report.  Here, we take each informant's incoming tie reports to be correct.
</p>
</li></ol>

<p>Note that the results returned by the single weighting algorithms are not dichotomized by default; since some algorithms thus return valued graphs, dichotomization may be desirable prior to use.
</p>
<p>It should be noted that a model for estimating an underlying criterion structure from multiple informant reports is provided in <code><a href="#topic+bbnam">bbnam</a></code>; if your goal is to reconstruct an &ldquo;objective&rdquo; network from informant reports, this (or the R-B model) may prove more useful than the ad-hoc solutions.
</p>


<h3>Value</h3>

<p>An adjacency matrix representing the consensus structure
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Banks, D.L., and Carley, K.M.  (1994).  &ldquo;Metric Inference for Social Networks.&rdquo;  <em>Journal of Classification,</em>  11(1), 121-49.
</p>
<p>Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Inter-Structural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University.
</p>
<p>Krackhardt, D.  (1987).  &ldquo;Cognitive Social Structures.&rdquo; <em>Social Networks,</em> 9, 109-134. 
</p>
<p>Romney, A.K.; Weller, S.C.; and Batchelder, W.H.  (1986).  &ldquo;Culture as Consensus: A Theory of Culture and Informant Accuracy.&rdquo;  <em>American Anthropologist,</em> 88(2), 313-38.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam">bbnam</a></code>, <code><a href="#topic+centralgraph">centralgraph</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Generate some test data
g&lt;-rgraph(5)
g.pobs&lt;-g*0.9+(1-g)*0.5
g.obs&lt;-rgraph(5,5,tprob=g.pobs)

#Find some consensus structures
consensus(g.obs)                           #Central graph
consensus(g.obs,method="single.reweight")  #Single reweighting
consensus(g.obs,method="PCA.reweight")     #1st component in network PCA
</code></pre>

<hr>
<h2 id='cug.test'>
Univariate Conditional Uniform Graph Tests
</h2><span id='topic+cug.test'></span><span id='topic+plot.cug.test'></span><span id='topic+print.cug.test'></span>

<h3>Description</h3>

<p><code>cug.test</code> takes an input network and conducts a conditional uniform graph (CUG) test of the statistic in <code>FUN</code>, using the conditioning statistics in <code>cmode</code>.  The resulting test object has custom print and plot methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cug.test(dat, FUN, mode = c("digraph", "graph"), cmode = c("size", 
    "edges", "dyad.census"), diag = FALSE, reps = 1000, 
    ignore.eval = TRUE, FUN.args = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cug.test_+3A_dat">dat</code></td>
<td>

<p>one or more input graphs.
</p>
</td></tr>
<tr><td><code id="cug.test_+3A_fun">FUN</code></td>
<td>

<p>the function generating the test statistic; note that this must take a graph as its first argument, and return a single numerical value.
</p>
</td></tr>
<tr><td><code id="cug.test_+3A_mode">mode</code></td>
<td>

<p><code>graph</code> if <code>dat</code> is an undirected graph, else <code>digraph</code>.
</p>
</td></tr>
<tr><td><code id="cug.test_+3A_cmode">cmode</code></td>
<td>

<p>string indicating the type of conditioning to be applied.
</p>
</td></tr>
<tr><td><code id="cug.test_+3A_diag">diag</code></td>
<td>

<p>logical; should self-ties be treated as valid data?
</p>
</td></tr>
<tr><td><code id="cug.test_+3A_reps">reps</code></td>
<td>

<p>number of Monte Carlo replications to use.
</p>
</td></tr>
<tr><td><code id="cug.test_+3A_ignore.eval">ignore.eval</code></td>
<td>

<p>logical; should edge values be ignored?  (Note: <code>TRUE</code> is usually more efficient.)
</p>
</td></tr>
<tr><td><code id="cug.test_+3A_fun.args">FUN.args</code></td>
<td>

<p>a list containing any additional arguments to <code>FUN</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>cug.test</code> is an improved version of <code>cugtest</code>, for use only with univariate CUG hypotheses.  Depending on <code>cmode</code>, conditioning on the realized size, edge count (or exact edge value distribution), or dyad census (or dyad value distribution) can be selected.  Edges are treated as unvalued unless <code>ignore.eval=FALSE</code>; since the latter setting is less efficient for sparse graphs, it should be used only when necessary.
</p>
<p>A brief summary of the theory and goals of conditional uniform graph testing can be found in the reference below.  See also <code><a href="#topic+cugtest">cugtest</a></code> for a somewhat informal description.
</p>


<h3>Value</h3>

<p>An object of class <code>cug.test</code>.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Butts, Carter T.  (2008).  &ldquo;Social Networks: A Methodological Introduction.&rdquo;  <em>Asian Journal of Social Psychology,</em> 11(1), 13&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cugtest">cugtest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw a highly reciprocal network
g&lt;-rguman(1,15,mut=0.25,asym=0.05,null=0.7)

#Test transitivity against size, density, and the dyad census
cug.test(g,gtrans,cmode="size")
cug.test(g,gtrans,cmode="edges")
cug.test(g,gtrans,cmode="dyad.census")
</code></pre>

<hr>
<h2 id='cugtest'>Perform Conditional Uniform Graph (CUG) Hypothesis Tests for Graph-Level Indices</h2><span id='topic+cugtest'></span>

<h3>Description</h3>

<p><code>cugtest</code> tests an arbitrary GLI (computed on <code>dat</code> by <code>FUN</code>) against a conditional uniform graph null hypothesis, via Monte Carlo simulation.  Some variation in the nature of the conditioning is available; currently, conditioning only on size, conditioning jointly on size and estimated tie probability (via expected density), and conditioning jointly on size and (bootstrapped) edge value distributions are implemented.  Note that fair amount of flexibility is possible regarding CUG tests on functions of GLIs (Anderson et al., 1999).  See below for more details. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cugtest(dat, FUN, reps=1000, gmode="digraph", cmode="density", 
    diag=FALSE, g1=1, g2=2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cugtest_+3A_dat">dat</code></td>
<td>
<p> graph(s) to be analyzed. </p>
</td></tr>
<tr><td><code id="cugtest_+3A_fun">FUN</code></td>
<td>
<p> function to compute GLIs, or functions thereof.  <code>FUN</code> must accept <code>dat</code> and the specified <code>g</code> arguments, and should return a real number. </p>
</td></tr>
<tr><td><code id="cugtest_+3A_reps">reps</code></td>
<td>
<p> integer indicating the number of draws to use for quantile estimation.  Note that, as for all Monte Carlo procedures, convergence is slower for more extreme quantiles.  By default, <code>reps==1000</code>. </p>
</td></tr>
<tr><td><code id="cugtest_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>gmode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
<tr><td><code id="cugtest_+3A_cmode">cmode</code></td>
<td>
<p> string indicating the type of conditioning assumed by the null hypothesis.  If <code>cmode</code> is set to &quot;density&quot;, then the density of the graph in question is used to determine the tie probabilities of the Bernoulli graph draws (which are also conditioned on |V(G)|).  If<code>cmode=="ties"</code>, then draws are bootstrapped from the distribution of edge values within the data matrices.  If <code>cmode="order"</code>, then draws are uniform over all graphs of the same order (size) as the graphs within the input stack.  By default, <code>cmode</code> is set to <code>"density"</code>.</p>
</td></tr>
<tr><td><code id="cugtest_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="cugtest_+3A_g1">g1</code></td>
<td>
<p> integer indicating the index of the first graph input to the GLI.  By default, <code>g1==1</code>. </p>
</td></tr>
<tr><td><code id="cugtest_+3A_g2">g2</code></td>
<td>
<p> integer indicating the index of the second graph input to the GLI.  (<code>FUN</code> can ignore this, if one wishes to test the GLI value of a single graph, but it should recognize the argument.)  By default, <code>g2==2</code>. </p>
</td></tr>
<tr><td><code id="cugtest_+3A_...">...</code></td>
<td>
<p> additional arguments to <code>FUN</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The null hypothesis of the CUG test is that the observed GLI (or function thereof) was drawn from a distribution equivalent to that of said GLI evaluated (uniformly) on the space of all graphs conditional on one or more features.  The most common &ldquo;features&rdquo; used for conditioning purposes are order (size) and density, both of which are known to have strong and nontrivial effects on other GLIs (Anderson et al., 1999) and which are, in many cases, exogenously determined.  (Note that maximum entropy distributions conditional on expected statistics are not in general correctly referred to as &ldquo;conditional uniform graphs&rdquo;, but have been described as such for independent-dyad models; this is indeed the case for this function, although such terminology is not really proper.  See <code><a href="#topic+cug.test">cug.test</a></code> for CUG tests with exact conditioning.)  Since theoretical results regarding functions of arbitrary GLIs on the space of graphs are not available, the standard approach to CUG testing is to approximate the quantiles of the observed statistic associated with the null hypothesis using Monte Carlo methods.  This is the technique utilized by <code>cugtest</code>, which takes appropriately conditioned draws from the set of graphs and computes on them the GLI specified in <code>FUN</code>, thereby accumulating an approximation to the true quantiles.
</p>
<p>The <code>cugtest</code> procedure returns a <code>cugtest</code> object containing the estimated distribution of the test GLI under the null hypothesis, the observed GLI value of the data, and the one-tailed p-values (estimated quantiles) associated with said observation.  As usual, the (upper tail) null hypothesis is rejected for significance level alpha if p&gt;=observation is less than alpha (or p&lt;=observation, for the lower tail).  Standard caveats regarding the use of null hypothesis testing procedures are relevant here: in particular, bear in mind that a significant result does not necessarily imply that the likelihood ratio of the null model and the alternative hypothesis favors the latter.
</p>
<p>Informative and aesthetically pleasing portrayals of <code>cugtest</code> objects are available via the <code><a href="#topic+print.cugtest">print.cugtest</a></code> and <code><a href="#topic+summary.cugtest">summary.cugtest</a></code> methods.  The <code><a href="#topic+plot.cugtest">plot.cugtest</a></code> method displays the estimated distribution, with a reference line signifying the observed value.
</p>


<h3>Value</h3>

<p>An object of class <code>cugtest</code>, containing
</p>
<table>
<tr><td><code>testval</code></td>
<td>

<p>The observed GLI value.
</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>

<p>A vector containing the Monte Carlo draws. 
</p>
</td></tr>
<tr><td><code>pgreq</code></td>
<td>

<p>The proportion of draws which were greater than or equal to the observed GLI value.
</p>
</td></tr>
<tr><td><code>pleeq</code></td>
<td>

<p>The proportion of draws which were less than or equal to the observed GLI value.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function currently conditions only on expected statistics, and is somewhat cumbersome.  <code><a href="#topic+cug.test">cug.test</a></code> is now recommended for univariate CUG tests (and will eventually supplant this function).</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Anderson, B.S.; Butts, C.T.; and Carley, K.M. (1999). &ldquo;The Interaction of Size and Density with Graph-Level Indices.&rdquo; <em>Social Networks</em>, 21(3), 239-267.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+cug.test">cug.test</a></code>, <code><a href="#topic+qaptest">qaptest</a></code>, <code><a href="#topic+gliop">gliop</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw two random graphs, with different tie probabilities
dat&lt;-rgraph(20,2,tprob=c(0.2,0.8))
#Is their correlation higher than would be expected, conditioning 
#only on size?
cug&lt;-cugtest(dat,gcor,cmode="order")
summary(cug)
#Now, let's try conditioning on density as well.
cug&lt;-cugtest(dat,gcor)
summary(cug)
</code></pre>

<hr>
<h2 id='cutpoints'>
Identify the Cutpoints of a Graph or Digraph
</h2><span id='topic+cutpoints'></span><span id='topic+cutpointsDir_R'></span><span id='topic+cutpointsUndir_R'></span>

<h3>Description</h3>

<p><code>cutpoints</code> identifies the cutpoints of an input graph.  Depending on <code>mode</code>, either a directed or undirected notion of &ldquo;cutpoint&rdquo; can be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutpoints(dat, mode = "digraph", connected = c("strong","weak","recursive"),
    return.indicator = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cutpoints_+3A_dat">dat</code></td>
<td>

<p>one or more input graphs.
</p>
</td></tr>
<tr><td><code id="cutpoints_+3A_mode">mode</code></td>
<td>

<p><code>"digraph"</code> for directed graphs, or <code>"graph"</code> for undirected graphs.
</p>
</td></tr>
<tr><td><code id="cutpoints_+3A_connected">connected</code></td>
<td>

<p>string indicating the type of connectedness rule to apply (only relevant where <code>mode=="digraph"</code>).
</p>
</td></tr>
<tr><td><code id="cutpoints_+3A_return.indicator">return.indicator</code></td>
<td>

<p>logical; should the results be returned as a logical (<code>TRUE/FALSE</code>) vector of indicators, rather than as a vector of vertex IDs?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <em>cutpoint</em> (also known as an <em>articulation point</em> or <em>cut-vertex</em>) of an undirected graph, <code class="reqn">G</code> is a vertex whose removal increases the number of components of <code class="reqn">G</code>.  Several generalizations to the directed case exist.  Here, we define a <em>strong cutpoint</em> of directed graph <code class="reqn">G</code> to be a vertex whose removal increases the number of strongly connected components of <code class="reqn">G</code> (see <code><a href="#topic+component.dist">component.dist</a></code>).  Likewise, <em>weak</em> and <em>recursive</em> cutpoints of <em>G</em> are those vertices whose removal increases the number of weak or recursive cutpoints (respectively).  By default, strong cutpoints are used; alternatives may be selected via the <code>connected</code> argument.
</p>
<p>Cutpoints are of particular interest when seeking to identify critical positions in flow networks, since their removal by definition alters the connectivity properties of the graph.  In this context, cutpoint status can be thought of as a primitive form of centrality (with some similarities to <code><a href="#topic+betweenness">betweenness</a></code>).
</p>
<p>Cutpoint computation is significantly faster for the undirected case (and for the weak/recursive cases) than for the strong directed case.  While calling <code>cutpoints</code> with <code>mode="digraph"</code> on an undirected graph will give the same answer as <code>mode="graph"</code>, it is thus to one's advantage to use the latter form.  Do not, however, employ <code>mode="graph"</code> with directed data, unless you enjoy unpredictable behavior.
</p>


<h3>Value</h3>

<p>A vector of cutpoints (if <code>return.indicator==FALSE</code>), or else a logical vector indicating cutpoint status for each vertex.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Berge, Claude.  (1966).  <em>The Theory of Graphs.</em>  New York: John Wiley and Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+component.dist">component.dist</a></code>, <code><a href="#topic+bicomponent.dist">bicomponent.dist</a></code>, <code><a href="#topic+betweenness">betweenness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate some sparse random graph
gd&lt;-rgraph(25,tp=1.5/24)                               #Directed
gu&lt;-rgraph(25,tp=1.5/24,mode="graph")                  #Undirected

#Calculate the cutpoints (as an indicator vector)
cpu&lt;-cutpoints(gu,mode="graph",return.indicator=TRUE)
cpd&lt;-cutpoints(gd,return.indicator=TRUE)

#Plot the result
gplot(gu,gmode="graph",vertex.col=2+cpu)
gplot(gd,vertex.col=2+cpd)

#Repeat with alternate connectivity modes
cpdw&lt;-cutpoints(gd,connected="weak",return.indicator=TRUE)
cpdr&lt;-cutpoints(gd,connected="recursive",return.indicator=TRUE)

#Visualize the difference
gplot(gd,vertex.col=2+cpdw)
gplot(gd,vertex.col=2+cpdr)
</code></pre>

<hr>
<h2 id='degree'> Compute the Degree Centrality Scores of Network Positions </h2><span id='topic+degree'></span><span id='topic+degree_R'></span>

<h3>Description</h3>

<p><code>Degree</code> takes one or more graphs (<code>dat</code>) and returns the degree centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  Depending on the specified mode, indegree, outdegree, or total (Freeman) degree will be returned; this function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>degree(dat, g=1, nodes=NULL, gmode="digraph", diag=FALSE,
    tmaxdev=FALSE, cmode="freeman", rescale=FALSE, ignore.eval=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="degree_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="degree_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g</code>=1. </p>
</td></tr>
<tr><td><code id="degree_+3A_nodes">nodes</code></td>
<td>
<p> vector indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="degree_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>gmode</code> is set to <code>"digraph"</code> by default. </p>
</td></tr>
<tr><td><code id="degree_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="degree_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev==FALSE</code>. </p>
</td></tr>
<tr><td><code id="degree_+3A_cmode">cmode</code></td>
<td>
<p> string indicating the type of degree centrality being computed.  <code>"indegree"</code>, <code>"outdegree"</code>, and <code>"freeman"</code> refer to the indegree, outdegree, and total (Freeman) degree measures, respectively.  The default for <code>cmode</code> is <code>"freeman"</code>. </p>
</td></tr>
<tr><td><code id="degree_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="degree_+3A_ignore.eval">ignore.eval</code></td>
<td>
<p> logical; should edge values be ignored when computing degree scores?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Degree centrality is the social networker's term for various permutations of the graph theoretic notion of vertex degree: for unvalued graphs, indegree of a vertex, <code class="reqn">v</code>, corresponds to the cardinality of the vertex set <code class="reqn">N^+(v)=\{i \in V(G) : (i,v) \in E(G)\}</code>; outdegree corresponds to the cardinality of the vertex set <code class="reqn">N^-(v)=\{i \in V(G) : (v,i) \in E(G)\}</code>; and total (or &ldquo;Freeman&rdquo;) degree corresponds to <code class="reqn">\left|N^+(v)\right| + \left|N^-(v)\right|</code>.  (Note that, for simple graphs, indegree=outdegree=total degree/2.)  Obviously, degree centrality can be interpreted in terms of the sizes of actors' neighborhoods within the larger structure.  See the references below for more details.
</p>
<p>When <code>ignore.eval==FALSE</code>, <code>degree</code> weights edges by their values where supplied.  <code>ignore.eval==TRUE</code> ensures an unweighted degree score (independent of input).  Setting <code>gmode=="graph"</code> forces behavior equivalent to <code>cmode=="indegree"</code> (i.e., each edge is counted only once); to obtain a total degree score for an undirected graph in which both in- and out-neighborhoods are counted separately, simply use <code>gmode=="digraph"</code>.
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the degree scores (depending on the number and size of the input graphs).
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Freeman, L.C.  (1979).  &ldquo;Centrality in Social Networks I: Conceptual Clarification.&rdquo; <em>Social Networks</em>, 1, 215-239. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+centralization">centralization</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a random directed graph
dat&lt;-rgraph(10)
#Find the indegrees, outdegrees, and total degrees
degree(dat,cmode="indegree")
degree(dat,cmode="outdegree")
degree(dat)
</code></pre>

<hr>
<h2 id='diag.remove'> Remove the Diagonals of Adjacency Matrices in a Graph Stack </h2><span id='topic+diag.remove'></span>

<h3>Description</h3>

<p>Returns the input graphs, with the diagonal entries removed/replaced as indicated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diag.remove(dat, remove.val=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diag.remove_+3A_dat">dat</code></td>
<td>
<p> one or more graphs. </p>
</td></tr>
<tr><td><code id="diag.remove_+3A_remove.val">remove.val</code></td>
<td>
<p> the value with which to replace the existing diagonals </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>diag.remove</code> is simply a convenient way to apply <code><a href="base.html#topic+diag">diag</a></code> to an entire collection of adjacency matrices/<code>network</code> objects at once.
</p>


<h3>Value</h3>

<p>The updated graphs.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+diag">diag</a></code>, <code><a href="#topic+upper.tri.remove">upper.tri.remove</a></code>, <code><a href="#topic+lower.tri.remove">lower.tri.remove</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a random graph stack
g&lt;-rgraph(3,5)
#Remove the diagonals
g&lt;-diag.remove(g)
</code></pre>

<hr>
<h2 id='dyad.census'> Compute a Holland and Leinhardt MAN Dyad Census </h2><span id='topic+dyad.census'></span>

<h3>Description</h3>

<p><code>dyad.census</code> computes a Holland and Leinhardt dyad census on the graphs of <code>dat</code> selected by <code>g</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dyad.census(dat, g=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dyad.census_+3A_dat">dat</code></td>
<td>
<p> one or more graphs. </p>
</td></tr>
<tr><td><code id="dyad.census_+3A_g">g</code></td>
<td>
<p> the elements of <code>dat</code> to be included; by default, all graphs are processed. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each dyad in a directed graph may be in one of four states: the null state (<code class="reqn">a \not\leftrightarrow b</code>), the complete or mutual state (<code class="reqn">a \leftrightarrow b</code>), and either of two asymmetric states (<code class="reqn">a \leftarrow b</code> or <code class="reqn">a \rightarrow b</code>).  Holland and Leinhardt's dyad census classifies each dyad into the mutual, asymmetric, or null categories, counting the number of each within the digraph.  These counts can be used as the basis for null hypothesis tests (since their distributions are known under assumptions such as constant edge probability), or for the generation of random graphs (e.g., via the U|MAN distribution, which conditions on the numbers of mutual, asymmetric, and null dyads in each graph).  
</p>


<h3>Value</h3>

<p>A matrix whose three columns contain the counts of mutual, asymmetric, and null dyads (respectively) for each graph
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Holland, P.W. and Leinhardt, S.  (1970).  &ldquo;A Method for Detecting Structure in Sociometric Data.&rdquo;  <em>American Journal of Sociology</em>, 76, 492-513. 
</p>
<p>Wasserman, S., and Faust, K.  (1994).  &ldquo;Social Network Analysis: Methods and Applications.&rdquo;  Cambridge: Cambridge University Press.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+mutuality">mutuality</a></code>, <code><a href="#topic+grecip">grecip</a></code>, <code><a href="#topic+rguman">rguman</a></code> <code><a href="#topic+triad.census">triad.census</a></code>, <code><a href="#topic+kcycle.census">kcycle.census</a></code>, <code><a href="#topic+kpath.census">kpath.census</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a dyad census of random data with varying densities
dyad.census(rgraph(15,5,tprob=c(0.1,0.25,0.5,0.75,0.9)))
</code></pre>

<hr>
<h2 id='efficiency'> Compute Graph Efficiency Scores </h2><span id='topic+efficiency'></span>

<h3>Description</h3>

<p><code>efficiency</code> takes one or more graphs (<code>dat</code>) and returns the Krackhardt efficiency scores for the graphs selected by <code>g</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efficiency(dat, g=NULL, diag=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efficiency_+3A_dat">dat</code></td>
<td>
<p> one or more graphs. </p>
</td></tr>
<tr><td><code id="efficiency_+3A_g">g</code></td>
<td>
<p> index values for the graphs to be utilized; by default, all graphs are selected. </p>
</td></tr>
<tr><td><code id="efficiency_+3A_diag">diag</code></td>
<td>
 <p><code>TRUE</code> if the diagonal contains valid data; by default, <code>diag==FALSE</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">G=\cup_{i=1}^n G_i</code> be a digraph with weak components <code class="reqn">G_1,G_2,\dots,G_n</code>.  For convenience, we denote the cardinalities of these components' vertex sets by <code class="reqn">|V(G)|=N</code> and <code class="reqn">|V(G_i)|=N_i</code>, <code class="reqn">\forall i \in 1,\dots,n</code>.  Then the Krackhardt efficiency of <code class="reqn">G</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">
1-\frac{|E(G)| - \sum_{i=1}^n \left(N_i-1\right)}{\sum_{i=1}^n \left(N_i \left(N_i-1\right)-\left(N_i-1\right)\right)}</code>
</p>

<p>which can be interpreted as 1 minus the proportion of possible &ldquo;extra&rdquo; edges (above those needed to weakly connect the existing components) actually present in the graph.  A graph which an efficiency of 1 has precisely as many edges as are needed to connect its components; as additional edges are added, efficiency gradually falls towards 0.
</p>
<p>Efficiency is one of four measures (<code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+hierarchy">hierarchy</a></code>, and <code><a href="#topic+lubness">lubness</a></code>) suggested by Krackhardt for summarizing hierarchical structures.  Each corresponds to one of four axioms which are necessary and sufficient for the structure in question to be an outtree; thus, the measures will be equal to 1 for a given graph iff that graph is an outtree.  Deviations from unity can be interpreted in terms of failure to satisfy one or more of the outtree conditions, information which may be useful in classifying its structural properties.
</p>


<h3>Value</h3>

<p>A vector of efficiency scores
</p>


<h3>Note</h3>

<p> The four Krackhardt indices are, in general, nondegenerate for a relatively narrow band of size/density combinations (efficiency being the sole exception).  This is primarily due to their dependence on the reachability graph, which tends to become complete rapidly as size/density increase.  See Krackhardt (1994) for a useful simulation study. 
</p>
<p>The violation normalization used before version 0.51 was <code class="reqn">N\left(N-1\right) \sum_{i=1}^n \left(N_i-1\right)</code>, based on a somewhat different interpretation of the definition in Krackhardt (1994).  The former version gave results which more closely matched those of the cited simulation study, but was less consistent with the textual definition.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Krackhardt, David.  (1994).  &ldquo;Graph Theoretical Dimensions of Informal Organizations.&rdquo; In K. M. Carley and M. J. Prietula (Eds.), <em>Computational Organization Theory</em>, 89-111. Hillsdale, NJ: Lawrence Erlbaum and Associates. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+hierarchy">hierarchy</a></code>, <code><a href="#topic+lubness">lubness</a></code>, <code><a href="#topic+gden">gden</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Get efficiency scores for graphs of varying densities
efficiency(rgraph(10,5,tprob=c(0.1,0.25,0.5,0.75,0.9)))
</code></pre>

<hr>
<h2 id='ego.extract'> Extract Egocentric Networks from Complete Network Data </h2><span id='topic+ego.extract'></span>

<h3>Description</h3>

<p><code>ego.extract</code> takes one or more input graphs (<code>dat</code>) and returns a list containing the egocentric networks centered on vertices named in <code>ego</code>, using adjacency rule <em>neighborhood</em> to define inclusion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ego.extract(dat, ego = NULL, neighborhood = c("combined", "in",
    "out"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ego.extract_+3A_dat">dat</code></td>
<td>
<p> one or more graphs. </p>
</td></tr>
<tr><td><code id="ego.extract_+3A_ego">ego</code></td>
<td>
<p> a vector of vertex IDs, or <code>NULL</code> if all are to be selected. </p>
</td></tr>
<tr><td><code id="ego.extract_+3A_neighborhood">neighborhood</code></td>
<td>
<p> the neighborhood to use. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The egocentric network (or &ldquo;ego net&rdquo;) of vertex <code class="reqn">v</code> in graph <code class="reqn">G</code> is defined as <code class="reqn">G[v \cup N(v)]</code> (i.e., the subgraph of <code class="reqn">G</code> induced by <code class="reqn">v</code> and its neighborhood).  The neighborhood employed by <code>ego.extract</code> is selected by the eponymous argument: <code>"in"</code> selects in-neighbors, <code>"out"</code> selects out-neighbors, and <code>"combined"</code> selects all neighbors.  In the event that one of the vertices selected by <code>ego</code> has no qualifying neighbors, <code>ego.extract</code> will return a degenerate (1 by 1) adjacency matrix containing that individual's diagonal entry.
</p>
<p>Vertices within the returned matrices are maintained in their original order, save for ego (who is always listed first).  The ego nets themselves are returned in the order specified in the <code>ego</code> parameter (or their vertex order, if no value was specified).
</p>
<p><code>ego.extract</code> is useful for finding local properties associated with particular vertices.  To compute functions of neighbors' covariates, see <code><a href="#topic+gapply">gapply</a></code>.
</p>


<h3>Value</h3>

<p>A list containing the adjacency matrices for the ego nets of each vertex in <code>ego</code>.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Wasserman, S. and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gapply">gapply</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a sample network
g&lt;-rgraph(10,tp=1.5/9)

#Extract some ego nets
g.in&lt;-ego.extract(g,neighborhood="in")
g.out&lt;-ego.extract(g,neighborhood="out")
g.comb&lt;-ego.extract(g,neighborhood="in")

#View some networks
g.comb

#Compare ego net size with degree
all(sapply(g.in,NROW)==degree(g,cmode="indegree")+1)    #TRUE
all(sapply(g.out,NROW)==degree(g,cmode="outdegree")+1)  #TRUE
all(sapply(g.comb,NROW)==degree(g)/2+1)        #Usually FALSE!

#Calculate egocentric network density
ego.size&lt;-sapply(g.comb,NROW)
if(any(ego.size&gt;2))
  sapply(g.comb[ego.size&gt;2],function(x){gden(x[-1,-1])})
</code></pre>

<hr>
<h2 id='equiv.clust'> Find Clusters of Positions Based on an Equivalence Relation </h2><span id='topic+equiv.clust'></span><span id='topic+print.equiv.clust'></span>

<h3>Description</h3>

<p><code>equiv.clust</code> uses a definition of approximate equivalence (<code>equiv.fun</code>) to form a hierarchical clustering of network positions.  Where <code>dat</code> consists of multiple relations, all specified relations are considered jointly in forming the equivalence clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equiv.clust(dat, g=NULL, equiv.dist=NULL, equiv.fun="sedist",
   method="hamming", mode="digraph", diag=FALSE, 
   cluster.method="complete", glabels=NULL, plabels=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="equiv.clust_+3A_dat">dat</code></td>
<td>
<p> one or more graphs. </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_g">g</code></td>
<td>
<p> the elements of <code>dat</code> to use in clustering the vertices; by default, all structures are used. </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_equiv.dist">equiv.dist</code></td>
<td>
<p> a matrix of distances, by which vertices should be clustered.  (Overrides <code>equiv.fun</code>.) </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_equiv.fun">equiv.fun</code></td>
<td>
<p> the distance function to use in clustering vertices (defaults to <code><a href="#topic+sedist">sedist</a></code>). </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_method">method</code></td>
<td>
 <p><code>method</code> parameter to be passed to <code>equiv.fun</code>. </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_mode">mode</code></td>
<td>
<p> &ldquo;graph&rdquo; or &ldquo;digraph,&rdquo; as appropriate. </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_diag">diag</code></td>
<td>
<p> a boolean indicating whether or not matrix diagonals (loops) should be interpreted as useful data. </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_cluster.method">cluster.method</code></td>
<td>
<p> the hierarchical clustering method to use (see <code><a href="stats.html#topic+hclust">hclust</a></code>). </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_glabels">glabels</code></td>
<td>
<p> labels for the various graphs in <code>dat</code>. </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_plabels">plabels</code></td>
<td>
<p> labels for the vertices of <code>dat</code>. </p>
</td></tr>
<tr><td><code id="equiv.clust_+3A_...">...</code></td>
<td>
<p> additional arguments to <code>equiv.dist</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This routine is essentially a joint front-end to <code><a href="stats.html#topic+hclust">hclust</a></code> and various positional distance functions, though it defaults to structural equivalence in particular.  Taking the specified graphs as input, <code>equiv.clust</code> computes the distances between all pairs of positions using <code>equiv.fun</code> (unless distances are supplied in <code>equiv.dist</code>), and then performs a cluster analysis of the result.  The return value is an object of class <code>equiv.clust</code>, for which various secondary analysis methods exist.
</p>


<h3>Value</h3>

<p>An object of class <code>equiv.clust</code>
</p>


<h3>Note</h3>

<p> See <code><a href="#topic+sedist">sedist</a></code> for an example of a distance function compatible with <code>equiv.clust</code>. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Breiger, R.L.; Boorman, S.A.; and Arabie, P.  (1975).  &ldquo;An Algorithm for Clustering Relational Data with Applications to Social Network Analysis and Comparison with Multidimensional Scaling.&rdquo;  <em>Journal of Mathematical Psychology</em>, 12, 328-383.
</p>
<p>Burt, R.S.  (1976).  &ldquo;Positions in Networks.&rdquo;  <em>Social Forces</em>, 55, 93-122.
</p>
<p>Wasserman, S., and Faust, K.  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+sedist">sedist</a></code>, <code><a href="#topic+blockmodel">blockmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Create a random graph with _some_ edge structure
g.p&lt;-sapply(runif(20,0,1),rep,20)  #Create a matrix of edge 
                                   #probabilities
g&lt;-rgraph(20,tprob=g.p)            #Draw from a Bernoulli graph 
                                   #distribution

#Cluster based on structural equivalence
eq&lt;-equiv.clust(g)
plot(eq)
</code></pre>

<hr>
<h2 id='eval.edgeperturbation'> Compute the Effects of Single-Edge Perturbations on Structural Indices </h2><span id='topic+eval.edgeperturbation'></span>

<h3>Description</h3>

<p>Evaluates a given function on an input graph with and without a specified edge, returning the difference between the results in each case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval.edgeperturbation(dat, i, j, FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval.edgeperturbation_+3A_dat">dat</code></td>
<td>
<p> A single adjacency matrix </p>
</td></tr>
<tr><td><code id="eval.edgeperturbation_+3A_i">i</code></td>
<td>
<p> The row(s) of the edge(s) to be perturbed </p>
</td></tr>
<tr><td><code id="eval.edgeperturbation_+3A_j">j</code></td>
<td>
<p> The column(s) of the edge(s) to be perturbed </p>
</td></tr>
<tr><td><code id="eval.edgeperturbation_+3A_fun">FUN</code></td>
<td>
<p> The function to be computed </p>
</td></tr>
<tr><td><code id="eval.edgeperturbation_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code>FUN</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Although primarily a back-end utility for <code><a href="#topic+pstar">pstar</a></code>, <code>eval.edgeperturbation</code> may be useful in any circumstance in which one wishes to assess the stability of a given structural index with respect to single edge perturbations. The function to be evaluated is calculated first on the input graph with all marked edges set to present, and then on the same graph with said edges absent.  (Obviously, this is sensible only for dichotomous data.)  The difference is then returned.  
</p>
<p>In <code><a href="#topic+pstar">pstar</a></code>, calls to <code>eval.edgeperturbation</code> are used to construct a perturbation effect matrix for the GLM. 
</p>


<h3>Value</h3>

<p>The difference in the values of <code>FUN</code> as computed on the perturbed graphs.
</p>


<h3>Note</h3>

 <p><code>length(i)</code> and <code>length(j)</code> must be equal; where multiple edges are specified, the row and column listings are interpreted as pairs. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Anderson, C.; Wasserman, S.; and Crouch, B. (1999).  &ldquo;A p* Primer:  Logit Models for Social Networks.  <em>Social Networks,</em> 21,37-66. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+pstar">pstar</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Create a random graph
g&lt;-rgraph(5)

#How much does a one-edge change affect reciprocity?
eval.edgeperturbation(g,1,2,grecip)
</code></pre>

<hr>
<h2 id='evcent'> Find Eigenvector Centrality Scores of Network Positions </h2><span id='topic+evcent'></span><span id='topic+evcent_R'></span>

<h3>Description</h3>

<p><code>evcent</code> takes one or more graphs (<code>dat</code>) and returns the eigenvector centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  This function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evcent(dat, g=1, nodes=NULL, gmode="digraph", diag=FALSE,
    tmaxdev=FALSE, rescale=FALSE, ignore.eval=FALSE, tol=1e-10,
    maxiter=1e5, use.eigen=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evcent_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="evcent_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g</code>=1. </p>
</td></tr>
<tr><td><code id="evcent_+3A_nodes">nodes</code></td>
<td>
<p> vector indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="evcent_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  This is currently ignored. </p>
</td></tr>
<tr><td><code id="evcent_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="evcent_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev==FALSE</code>. </p>
</td></tr>
<tr><td><code id="evcent_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="evcent_+3A_ignore.eval">ignore.eval</code></td>
<td>
<p> logical; should edge values be ignored?</p>
</td></tr>
<tr><td><code id="evcent_+3A_tol">tol</code></td>
<td>
<p> convergence tolerance for the eigenvector computation.</p>
</td></tr>
<tr><td><code id="evcent_+3A_maxiter">maxiter</code></td>
<td>
<p> maximum iterations for eigenvector calculation.</p>
</td></tr>
<tr><td><code id="evcent_+3A_use.eigen">use.eigen</code></td>
<td>
<p> logical; should we use R's <code><a href="base.html#topic+eigen">eigen</a></code> routine instead of the (faster but less robust) internal method?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Eigenvector centrality scores correspond to the values of the first eigenvector of the graph adjacency matrix; these scores may, in turn, be interpreted as arising from a reciprocal process in which the centrality of each actor is proportional to the sum of the centralities of those actors to whom he or she is connected.  In general, vertices with high eigenvector centralities are those which are connected to many other vertices which are, in turn, connected to many others (and so on).  (The perceptive may realize that this implies that the largest values will be obtained by individuals in large cliques (or high-density substructures).  This is also intelligible from an algebraic point of view, with the first eigenvector being closely related to the best rank-1 approximation of the adjacency matrix (a relationship which is easy to see in the special case of a diagonalizable symmetric real matrix via the <code class="reqn">S \Lambda S^{-1}</code> decomposition).) 
</p>
<p>By default, a sparse-graph power method is used to obtain the principal eigenvector.  This procedure scales well, but may not converge in some cases.  In the event that the convergence objective set by <code>tol</code> is not obtained, <code>evcent</code> will return a warning message.  Correctives in this case include increasing <code>maxiter</code>, or setting <code>use.eigen</code> to <code>TRUE</code>.  The latter will cause <code>evcent</code> to use R's standard <code><a href="base.html#topic+eigen">eigen</a></code> method to calculate the principal eigenvector; this is far slower for sparse graphs, but is also more robust.
</p>
<p>The simple eigenvector centrality is generalized by the Bonacich power centrality measure; see <code><a href="#topic+bonpow">bonpow</a></code> for more details.
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the centrality scores (depending on the number and size of the input graphs).
</p>


<h3>WARNING </h3>

<p><code>evcent</code> will not symmetrize your data before extracting eigenvectors; don't send this routine asymmetric matrices unless you really mean to do so.</p>


<h3>Note</h3>

<p> The theoretical maximum deviation used here is not obtained with the star network, in general.  For symmetric data, the maximum occurs for an empty graph with one complete dyad; the maximum deviation for asymmetric data is generated by the outstar.  UCINET V seems not to adjust for this fact, which can cause some oddities in their centralization scores (and results in a discrepancy in centralizations between the two packages). </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Bonacich, P.  (1987).  &ldquo;Power and Centrality: A Family of Measures.&rdquo; <em>American Journal of Sociology</em>, 92, 1170-1182.
</p>
<p>Katz, L.  (1953).  &ldquo;A New Status Index Derived from Sociometric Analysis.&rdquo;  <em>Psychometrika</em>, 18, 39-43.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+centralization">centralization</a></code>, <code><a href="#topic+bonpow">bonpow</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Generate some test data
dat&lt;-rgraph(10,mode="graph")
#Compute eigenvector centrality scores
evcent(dat)
</code></pre>

<hr>
<h2 id='event2dichot'> Convert an Observed Event Matrix to a Dichotomous matrix </h2><span id='topic+event2dichot'></span>

<h3>Description</h3>

<p>Given one or more valued adjacency matrices (possibly derived from observed interaction &ldquo;events&rdquo;), <code>event2dichot</code> returns dichotomized equivalents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>event2dichot(m, method="quantile", thresh=0.5, leq=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="event2dichot_+3A_m">m</code></td>
<td>
<p> one or more (valued) input graphs. </p>
</td></tr>
<tr><td><code id="event2dichot_+3A_method">method</code></td>
<td>
<p> one of &ldquo;quantile,&rdquo; &ldquo;rquantile,&rdquo; &ldquo;cquantile,&rdquo; &ldquo;mean,&rdquo; &ldquo;rmean,&rdquo; &ldquo;cmean,&rdquo; &ldquo;absolute,&rdquo; &ldquo;rank,&rdquo; &ldquo;rrank,&rdquo; or &ldquo;crank&rdquo;.  </p>
</td></tr>
<tr><td><code id="event2dichot_+3A_thresh">thresh</code></td>
<td>
<p> dichotomization thresholds for ranks or quantiles. </p>
</td></tr>
<tr><td><code id="event2dichot_+3A_leq">leq</code></td>
<td>
<p> boolean indicating whether values less than or equal to the threshold should be taken as existing edges; the alternative is to use values strictly greater than the threshold. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods used for choosing dichotomization thresholds are as follows:
</p>

<ol>
<li><p> quantile: specified quantile over the distribution of all edge values
</p>
</li>
<li><p> rquantile: specified quantile by row
</p>
</li>
<li><p> cquantile: specified quantile by column
</p>
</li>
<li><p> mean: grand mean
</p>
</li>
<li><p> rmean: row mean
</p>
</li>
<li><p> cmean: column mean
</p>
</li>
<li><p> absolute: the value of <code>thresh</code> itself
</p>
</li>
<li><p> rank: specified rank over the distribution of all edge values
</p>
</li>
<li><p> rrank: specified rank by row
</p>
</li>
<li><p> crank: specified rank by column
</p>
</li></ol>

<p>Note that when a quantile, rank, or value is said to be &ldquo;specified,&rdquo; this refers to the value of <code>thresh</code>.  
</p>


<h3>Value</h3>

<p>The dichotomized data matrix (or matrices)
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Wasserman, S. and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw a matrix of normal values
n&lt;-matrix(rnorm(25),nrow=5,ncol=5)

#Dichotomize by the mean value
event2dichot(n,"mean")

#Dichotomize by the 0.95 quantile
event2dichot(n,"quantile",0.95)

</code></pre>

<hr>
<h2 id='flowbet'>
Calculate Flow Betweenness Scores of Network Positions
</h2><span id='topic+flowbet'></span>

<h3>Description</h3>

<p><code>flowbet</code> takes one or more graphs (<code>dat</code>) and returns the flow betweenness scores of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  Depending on the specified mode, flow betweenness on directed or undirected geodesics will be returned; this function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flowbet(dat, g = 1, nodes = NULL, gmode = "digraph", diag = FALSE,
    tmaxdev = FALSE, cmode = "rawflow", rescale = FALSE, 
    ignore.eval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flowbet_+3A_dat">dat</code></td>
<td>

<p>one or more input graphs.
</p>
</td></tr>
<tr><td><code id="flowbet_+3A_g">g</code></td>
<td>

<p>integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g</code>=1.
</p>
</td></tr>
<tr><td><code id="flowbet_+3A_nodes">nodes</code></td>
<td>

<p>vector indicating which nodes are to be included in the calculation.  By default, all nodes are included.
</p>
</td></tr>
<tr><td><code id="flowbet_+3A_gmode">gmode</code></td>
<td>

<p>string indicating the type of graph being evaluated.  <code>digraph</code> indicates that edges should be interpreted as directed (with flows summed over directed dyads); <code>graph</code> indicates that edges are undirected (with only undirected pairs considered).  <code>gmode</code> is set to <code>digraph</code> by default. 
</p>
</td></tr>
<tr><td><code id="flowbet_+3A_diag">diag</code></td>
<td>

<p>boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default.
</p>
</td></tr>
<tr><td><code id="flowbet_+3A_tmaxdev">tmaxdev</code></td>
<td>

<p>boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev</code>==<code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="flowbet_+3A_cmode">cmode</code></td>
<td>

<p>one of <code>rawflow</code>, <code>normflow</code>, or <code>fracflow</code> (see below).
</p>
</td></tr>
<tr><td><code id="flowbet_+3A_rescale">rescale</code></td>
<td>

<p>if true, centrality scores are rescaled such that they sum to 1.
</p>
</td></tr>
<tr><td><code id="flowbet_+3A_ignore.eval">ignore.eval</code></td>
<td>

<p>logical; ignore edge values when computing maximum flow (alternately, edge values will be assumed to carry capacity information)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The (&ldquo;raw,&rdquo; or unnormalized) flow betweenness of a vertex, <code class="reqn">v \in V(G)</code>, is defined by Freeman et al. (1991) as
</p>
<p style="text-align: center;"><code class="reqn">
C_F(v) = \sum_{i,j : i \neq j, i \neq v, j \neq v} \left(f(i,j,G) - f(i,j,G\setminus v)\right),</code>
</p>

<p>where <code class="reqn">f(i,j,G)</code> is the maximum flow from <code class="reqn">i</code> to <code class="reqn">j</code> within <code class="reqn">G</code> (under the assumption of infinite vertex capacities, finite edge capacities, and non-simultaneity of pairwise flows).  Intuitively, unnormalized flow betweenness is simply the total maximum flow (aggregated across all pairs of third parties) mediated by <code class="reqn">v</code>.
</p>
<p>The above flow betweenness measure is computed by <code>flowbet</code> when <code>cmode=="rawflow"</code>.  In some cases, it may be desirable to normalize the raw flow betweenness by the total maximum flow among third parties (including <code class="reqn">v</code>); this leads to the following normalized flow betweenness measure:
</p>
<p style="text-align: center;"><code class="reqn">
C'_F(v) = \frac{\sum_{i,j : i \neq j, i \neq v, j \neq v} \left(f(i,j,G) - f(i,j,G\setminus v)\right)}{\sum_{i,j : i \neq j, i \neq v, j \neq v} f(i,j,G)}.</code>
</p>

<p>This variant can be selected by setting <code>cmode=="normflow"</code>.
</p>
<p>Finally, it may be noted that the above normalization (from Freeman et al. (1991)) is rather different from that used in the definition of shortest-path betweenness, which normalizes within (rather than across) third-party dyads.  A third flow betweenness variant has been suggested by Koschutzki et al. (2005) based on a normalization of this type:
</p>
<p style="text-align: center;"><code class="reqn">
C''_F(v) = \sum_{i,j : i \neq j, i \neq v, j \neq v} \frac{ \left(f(i,j,G) - f(i,j,G\setminus v)\right)}{f(i,j,G)}</code>
</p>

<p>where 0/0 flow ratios are treated as 0 (as in shortest-path betweenness).  Setting <code>cmode=="fracflow"</code> selects this variant.
</p>


<h3>Value</h3>

<p>A vector of centrality scores.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Freeman, L.C.; Borgatti, S.P.; and White, D.R.  (1991).  &ldquo;Centrality in Valued Graphs: A Measure of Betweenness Based on Network Flow.&rdquo;  <em>Social Networks</em>, 13(2), 141-154.
</p>
<p>Koschutzki, D.; Lehmann, K.A.; Peeters, L.; Richter, S.; Tenfelde-Podehl, D.; Zlotowski, O.  (2005).  &ldquo;Centrality Indices.&rdquo;  In U. Brandes and T. Erlebach (eds.), <em>Network Analysis: Methodological Foundations.</em>  Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betweenness">betweenness</a></code>, <code><a href="#topic+maxflow">maxflow</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(10)                                     #Draw a random graph
flowbet(g)                                        #Raw flow betweenness
flowbet(g,cmode="normflow")                       #Normalized flow betweenness

g&lt;-g*matrix(rpois(100,4),10,10)                   #Add capacity constraints
flowbet(g)                                        #Note the difference!
</code></pre>

<hr>
<h2 id='gapply'> Apply Functions Over Vertex Neighborhoods </h2><span id='topic+gapply'></span>

<h3>Description</h3>

<p>Returns a vector or array or list of values obtained by applying a function to vertex neighborhoods of a given order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gapply(X, MARGIN, STATS, FUN, ..., mode = "digraph", diag = FALSE, 
    distance = 1, thresh = 0, simplify = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gapply_+3A_x">X</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="gapply_+3A_margin">MARGIN</code></td>
<td>
<p> a vector giving the &ldquo;margin&rdquo; of <code>X</code> to be used in calculating neighborhoods.  1 indicates rows (out-neighbors), 2 indicates columns (in-neighbors), and c(1,2) indicates rows and columns (total neighborhood). </p>
</td></tr>
<tr><td><code id="gapply_+3A_stats">STATS</code></td>
<td>
<p> the vector or matrix of vertex statistics to be used. </p>
</td></tr>
<tr><td><code id="gapply_+3A_fun">FUN</code></td>
<td>
<p> the function to be applied.  In the case of operators, the function name must be quoted. </p>
</td></tr>
<tr><td><code id="gapply_+3A_...">...</code></td>
<td>
<p> additional arguments to <code>FUN</code>. </p>
</td></tr>
<tr><td><code id="gapply_+3A_mode">mode</code></td>
<td>
 <p><code>"graph"</code> if <code>X</code> is a simple graph, else <code>"digraph"</code>. </p>
</td></tr>
<tr><td><code id="gapply_+3A_diag">diag</code></td>
<td>
<p> boolean; are the diagonals of <code>X</code> meaningful? </p>
</td></tr>
<tr><td><code id="gapply_+3A_distance">distance</code></td>
<td>
<p> the maximum geodesic distance at which neighborhoods are to be taken.  1 signifies first-order neighborhoods, 2 signifies second-order neighborhoods, etc. </p>
</td></tr>
<tr><td><code id="gapply_+3A_thresh">thresh</code></td>
<td>
<p> the threshold to be used in dichotomizing <code>X</code>. </p>
</td></tr>
<tr><td><code id="gapply_+3A_simplify">simplify</code></td>
<td>
<p> boolean; should we attempt to coerce output to a vector if possible? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each vertex in <code>X</code>, <code>gapply</code> first identifies all members of the relevant neighborhood (as determined by <code>MARGIN</code> and <code>distance</code>) and pulls the rows of <code>STATS</code> associated with each.  <code>FUN</code> is then applied to this collection of values.  This provides a very quick and easy way to answer questions like:
</p>

<ul>
<li><p> How many persons are in each ego's 3rd-order neighborhood?
</p>
</li>
<li><p> What fraction of each ego's alters are female?
</p>
</li>
<li><p> What is the mean income for each ego's trading partners?
</p>
</li>
<li><p> etc.
</p>
</li></ul>

<p>With clever use of <code>FUN</code> and <code>STATS</code>, a wide range of functionality can be obtained.
</p>


<h3>Value</h3>

<p>The result of the iterated application of <code>FUN</code> to each vertex neighborhood's <code>STATS</code>.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+apply">apply</a></code>, <code><a href="base.html#topic+sapply">sapply</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a random graph
g&lt;-rgraph(6)

#Calculate the degree of g using gapply
all(gapply(g,1,rep(1,6),sum)==degree(g,cmode="outdegree"))
all(gapply(g,2,rep(1,6),sum)==degree(g,cmode="indegree"))
all(gapply(g,c(1,2),rep(1,6),sum)==degree(symmetrize(g),cmode="freeman")/2)

#Find first and second order neighborhood means on some variable
gapply(g,c(1,2),1:6,mean)
gapply(g,c(1,2),1:6,mean,distance=2)

</code></pre>

<hr>
<h2 id='gclust.boxstats'> Plot Statistics Associated with Graph Clusters </h2><span id='topic+gclust.boxstats'></span>

<h3>Description</h3>

<p><code>gclust.boxstats</code> creates side-by-side boxplots of graph statistics based on a hierarchical clustering of networks (cut into <code>k</code> sets).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gclust.boxstats(h, k, meas, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gclust.boxstats_+3A_h">h</code></td>
<td>
<p> an <code><a href="stats.html#topic+hclust">hclust</a></code> object, presumably formed by clustering a set of structural distances. </p>
</td></tr>
<tr><td><code id="gclust.boxstats_+3A_k">k</code></td>
<td>
<p> the number of groups to evaluate. </p>
</td></tr>
<tr><td><code id="gclust.boxstats_+3A_meas">meas</code></td>
<td>
<p> a vector of length equal to the number of graphs in <code>h</code>, containing a GLI to be evaluated. </p>
</td></tr>
<tr><td><code id="gclust.boxstats_+3A_...">...</code></td>
<td>
<p> additional parameters to <code><a href="graphics.html#topic+boxplot">boxplot</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gclust.boxstats</code> simply takes the <code><a href="stats.html#topic+hclust">hclust</a></code> object in <code>h</code>, applies <code><a href="stats.html#topic+cutree">cutree</a></code> to form <code>k</code> groups, and then uses <code><a href="graphics.html#topic+boxplot">boxplot</a></code> on the distribution of <code>meas</code> by group.  This can be quite handy for assessing graph clusters.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Note</h3>

<p> Actually, this function will work with any <code><a href="stats.html#topic+hclust">hclust</a></code> object and measure matrix; the data need not originate with social networks.  For this reason, the clever may also employ this function in conjunction with <code><a href="#topic+sedist">sedist</a></code> or <code><a href="#topic+equiv.clust">equiv.clust</a></code> to plot NLIs against clusters of positions within a graph.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS working paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gclust.centralgraph">gclust.centralgraph</a></code>, <code><a href="#topic+gdist.plotdiff">gdist.plotdiff</a></code>, <code><a href="#topic+gdist.plotstats">gdist.plotstats</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create some random graphs
g&lt;-rgraph(10,20,tprob=c(rbeta(10,15,2),rbeta(10,2,15)))

#Find the Hamming distances between them
g.h&lt;-hdist(g)

#Cluster the graphs via their Hamming distances
g.c&lt;-hclust(as.dist(g.h))

#Now display boxplots of density by cluster for a two cluster solution
gclust.boxstats(g.c,2,gden(g))
</code></pre>

<hr>
<h2 id='gclust.centralgraph'> Get Central Graphs Associated with Graph Clusters </h2><span id='topic+gclust.centralgraph'></span>

<h3>Description</h3>

<p>Calculates central graphs associated with particular graph clusters (as indicated by the <code>k</code> partition of <code>h</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gclust.centralgraph(h, k, dat, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gclust.centralgraph_+3A_h">h</code></td>
<td>
<p> an <code><a href="stats.html#topic+hclust">hclust</a></code> object, based on a graph stack in <code>dat</code>. </p>
</td></tr>
<tr><td><code id="gclust.centralgraph_+3A_k">k</code></td>
<td>
<p> the number of groups to evaluate. </p>
</td></tr>
<tr><td><code id="gclust.centralgraph_+3A_dat">dat</code></td>
<td>
<p> one or more graphs (on which the clustering was performed). </p>
</td></tr>
<tr><td><code id="gclust.centralgraph_+3A_...">...</code></td>
<td>
<p> additional arguments to <code><a href="#topic+centralgraph">centralgraph</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gclust.centralgraph</code> uses <code><a href="stats.html#topic+cutree">cutree</a></code> to cut the hierarchical clustering in <code>h</code> into <code>k</code> groups.  <code><a href="#topic+centralgraph">centralgraph</a></code> is then called on each cluster, and the results are returned as a graph stack.  This is a useful tool for interpreting clusters of (labeled) graphs, with the resulting central graphs being subsequently analyzed using standard SNA methods.
</p>


<h3>Value</h3>

<p>An array containing the stack of central graph adjacency matrices
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS working paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="#topic+centralgraph">centralgraph</a></code>, <code><a href="#topic+gclust.boxstats">gclust.boxstats</a></code>, <code><a href="#topic+gdist.plotdiff">gdist.plotdiff</a></code>, <code><a href="#topic+gdist.plotstats">gdist.plotstats</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create some random graphs
g&lt;-rgraph(10,20,tprob=c(rbeta(10,15,2),rbeta(10,2,15)))

#Find the Hamming distances between them
g.h&lt;-hdist(g)

#Cluster the graphs via their Hamming distances
g.c&lt;-hclust(as.dist(g.h))

#Now find central graphs by cluster for a two cluster solution
g.cg&lt;-gclust.centralgraph(g.c,2,g)

#Plot the central graphs
gplot(g.cg[1,,])
gplot(g.cg[2,,])
</code></pre>

<hr>
<h2 id='gcor'> 
Find the (Product-Moment) Correlation Between Two or More Labeled Graphs </h2><span id='topic+gcor'></span>

<h3>Description</h3>

<p><code>gcor</code> finds the product-moment correlation between the adjacency matrices of graphs indicated by <code>g1</code> and <code>g2</code> in stack <code>dat</code> (or possibly <code>dat2</code>).  Missing values are permitted. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcor(dat, dat2=NULL, g1=NULL, g2=NULL, diag=FALSE, mode="digraph")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcor_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="gcor_+3A_dat2">dat2</code></td>
<td>
<p> optionally, a second stack of graphs. </p>
</td></tr>
<tr><td><code id="gcor_+3A_g1">g1</code></td>
<td>
<p> the indices of <code>dat</code> reflecting the first set of graphs to be compared; by default, all members of <code>dat</code> are included. </p>
</td></tr>
<tr><td><code id="gcor_+3A_g2">g2</code></td>
<td>
<p> the indices or <code>dat</code> (or <code>dat2</code>, if applicable) reflecting the second set of graphs to be compared; by default, all members of <code>dat</code> are included. </p>
</td></tr>
<tr><td><code id="gcor_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="gcor_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;Digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>mode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The (product moment) graph correlation between labeled graphs G and H is given by 
</p>
<p style="text-align: center;"><code class="reqn">cor(G,H) = \frac{cov(G,H)}{\sqrt{cov(G,G) cov(H,H)}} </code>
</p>

<p>where the graph covariance is defined as
</p>
<p style="text-align: center;"><code class="reqn">cov(G,H) = \frac{1}{{|V| \choose 2}} \sum_{\{i,j\}} \left(A^G_{ij}-\mu_G\right)\left(A^H_{ij}-\mu_H\right)</code>
</p>

<p>(with <code class="reqn">A^G</code> being the adjacency matrix of G).  The graph correlation/covariance is at the center of a number of graph comparison methods, including network variants of regression analysis, PCA, CCA, and the like.
</p>
<p>Note that <code>gcor</code> computes only the correlation between <em>uniquely labeled</em> graphs.  For the more general case, <code><a href="#topic+gscor">gscor</a></code> is recommended.
</p>


<h3>Value</h3>

<p>A graph correlation matrix
</p>


<h3>Note</h3>

<p>  The <code>gcor</code> routine is really just a front-end to the standard <code><a href="stats.html#topic+cor">cor</a></code> method; the primary value-added is the transparent vectorization of the input graphs (with intelligent handling of simple versus directed graphs, diagonals, etc.).  As noted, the correlation coefficient returned is a standard Pearson's product-moment coefficient, and output should be interpreted accordingly.  Classical null hypothesis testing procedures are not recommended for use with graph correlations; for nonparametric null hypothesis testing regarding graph correlations, see <code><a href="#topic+cugtest">cugtest</a></code> and <code><a href="#topic+qaptest">qaptest</a></code>.  For multivariate correlations among graph sets, try <code><a href="#topic+netcancor">netcancor</a></code>. 
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University.
</p>
<p>Krackhardt, D.  (1987).  &ldquo;QAP Partialling as a Test of Spuriousness.&rdquo;  <em>Social Networks</em>, 9, 171-86
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gscor">gscor</a></code>, <code><a href="#topic+gcov">gcov</a></code>, <code><a href="#topic+gscov">gscov</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate two random graphs each of low, medium, and high density
g&lt;-rgraph(10,6,tprob=c(0.2,0.2,0.5,0.5,0.8,0.8))

#Examine the correlation matrix
gcor(g)
</code></pre>

<hr>
<h2 id='gcov'> Find the Covariance(s) Between Two or More Labeled Graphs</h2><span id='topic+gcov'></span>

<h3>Description</h3>

<p><code>gcov</code> finds the covariances between the adjacency matrices of graphs indicated by <code>g1</code> and <code>g2</code> in stack <code>dat</code> (or possibly <code>dat2</code>).  Missing values are permitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcov(dat, dat2=NULL, g1=NULL, g2=NULL, diag=FALSE, mode="digraph")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcov_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="gcov_+3A_dat2">dat2</code></td>
<td>
<p> optionally, a second graph stack. </p>
</td></tr>
<tr><td><code id="gcov_+3A_g1">g1</code></td>
<td>
<p> the indices of <code>dat</code> reflecting the first set of graphs to be compared; by default, all members of <code>dat</code> are included. </p>
</td></tr>
<tr><td><code id="gcov_+3A_g2">g2</code></td>
<td>
<p> the indices or <code>dat</code> (or <code>dat2</code>, if applicable) reflecting the second set of graphs to be compared; by default, all members of <code>dat</code> are included. </p>
</td></tr>
<tr><td><code id="gcov_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="gcov_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>mode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The graph covariance between two labeled graphs is defined as
</p>
<p style="text-align: center;"><code class="reqn">cov(G,H) = \frac{1}{{|V| \choose 2}} \sum_{\{i,j\}} \left(A^G_{ij}-\mu_G\right)\left(A^H_{ij}-\mu_H\right)</code>
</p>

<p>(with <code class="reqn">A^G</code> being the adjacency matrix of G).  The graph correlation/covariance is at the center of a number of graph comparison methods, including network variants of regression analysis, PCA, CCA, and the like.
</p>
<p>Note that <code>gcov</code> computes only the covariance between <em>uniquely labeled</em> graphs.  For the more general case, <code><a href="#topic+gscov">gscov</a></code> is recommended.
</p>


<h3>Value</h3>

<p>A graph covariance matrix
</p>


<h3>Note</h3>

<p> The <code>gcov</code> routine is really just a front-end to the standard <code><a href="stats.html#topic+cov">cov</a></code> method; the primary value-added is the transparent vectorization of the input graphs (with intelligent handling of simple versus directed graphs, diagonals, etc.).  Classical null hypothesis testing procedures are not recommended for use with graph covariance; for nonparametric null hypothesis testing regarding graph covariance, see <code><a href="#topic+cugtest">cugtest</a></code> and <code><a href="#topic+qaptest">qaptest</a></code>.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gscov">gscov</a></code>, <code><a href="#topic+gcor">gcor</a></code>, <code><a href="#topic+gscor">gscor</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate two random graphs each of low, medium, and high density
g&lt;-rgraph(10,6,tprob=c(0.2,0.2,0.5,0.5,0.8,0.8))

#Examine the covariance matrix
gcov(g)
</code></pre>

<hr>
<h2 id='gden'> Find the Density of a Graph </h2><span id='topic+gden'></span>

<h3>Description</h3>

<p><code>gden</code> computes the density of the graphs indicated by <code>g</code> in collection <code>dat</code>, adjusting for the type of graph in question.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gden(dat, g=NULL, diag=FALSE, mode="digraph", ignore.eval=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gden_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="gden_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graphs for which the density is to be calculated (or a vector thereof).  If <code>g==NULL</code> (the default), density is calculated for all graphs in <code>dat</code>. </p>
</td></tr>
<tr><td><code id="gden_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="gden_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>mode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
<tr><td><code id="gden_+3A_ignore.eval">ignore.eval</code></td>
<td>
<p> logical; should edge values be ignored when calculating density?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density of a graph is here taken to be the sum of tie values divided by the number of possible ties (i.e., an unbiased estimator of the graph mean); hence, the result is interpretable for valued graphs as the mean tie value when <code>ignore.eval==FALSE</code>.  The number of possible ties is determined by the graph type (and by <code>diag</code>) in the usual fashion.
</p>
<p>Where missing data is present, it is removed prior to calculation.  The density/graph mean is thus taken relative to the observed portion of the graph.
</p>


<h3>Value</h3>

<p>The graph density
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press. </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw three random graphs
dat&lt;-rgraph(10,3)
#Find their densities
gden(dat)
</code></pre>

<hr>
<h2 id='gdist.plotdiff'> Plot Differences in Graph-level Statistics Against Inter-graph Distances</h2><span id='topic+gdist.plotdiff'></span>

<h3>Description</h3>

<p>For a given graph set, <code>gdist.plotdiff</code> plots the distances between graphs against their distances (or differences) on a set of graph-level measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gdist.plotdiff(d, meas, method="manhattan", jitter=TRUE, 
    xlab="Inter-Graph Distance", ylab="Measure Distance", 
    lm.line=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gdist.plotdiff_+3A_d">d</code></td>
<td>
<p> A matrix containing the inter-graph distances </p>
</td></tr>
<tr><td><code id="gdist.plotdiff_+3A_meas">meas</code></td>
<td>
<p> An n x m matrix containing the graph-level indices; rows of this matrix must correspond to graphs, and columns to indices </p>
</td></tr>
<tr><td><code id="gdist.plotdiff_+3A_method">method</code></td>
<td>
<p> The distance method used by <code><a href="stats.html#topic+dist">dist</a></code> to establish differences/distances between graph GLI values.  By default, absolute (&quot;manhattan&quot;) differences are used. </p>
</td></tr>
<tr><td><code id="gdist.plotdiff_+3A_jitter">jitter</code></td>
<td>
<p> Should values be jittered prior to display? </p>
</td></tr>
<tr><td><code id="gdist.plotdiff_+3A_xlab">xlab</code></td>
<td>
<p> A label for the X axis </p>
</td></tr>
<tr><td><code id="gdist.plotdiff_+3A_ylab">ylab</code></td>
<td>
<p> A label for the Y axis </p>
</td></tr>
<tr><td><code id="gdist.plotdiff_+3A_lm.line">lm.line</code></td>
<td>
<p> Include a least-squares line? </p>
</td></tr>
<tr><td><code id="gdist.plotdiff_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code><a href="graphics.html#topic+plot">plot</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gdist.plotdiff</code> works by taking the distances between all graphs on <code>meas</code> and then plotting these distances against <code>d</code> for all pairs of graphs (with, optionally, an added least-squares line for reference value).  This can be a useful exploratory tool for relating inter-graph distances (e.g., Hamming distances) to differences on other attributes.  
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Note</h3>

<p> This function is actually quite generic, and can be used with node-level &ndash; or even non-network &ndash; data as well. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS working paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gdist.plotstats">gdist.plotstats</a></code>, <code><a href="#topic+gclust.boxstats">gclust.boxstats</a></code>, <code><a href="#topic+gclust.centralgraph">gclust.centralgraph</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate some random graphs with varying densities
g&lt;-rgraph(10,20,tprob=runif(20,0,1))

#Find the Hamming distances between graphs
g.h&lt;-hdist(g)

#Plot the relationship between distance and differences in density
gdist.plotdiff(g.h,gden(g),lm.line=TRUE)
</code></pre>

<hr>
<h2 id='gdist.plotstats'> Plot Various Graph Statistics Over a Network MDS </h2><span id='topic+gdist.plotstats'></span>

<h3>Description</h3>

<p>Plots a two-dimensional metric MDS of <code>d</code>, with the corresponding values of <code>meas</code> indicated at each point.  Various options are available for controlling how <code>meas</code> is to be displayed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gdist.plotstats(d, meas, siz.lim=c(0, 0.15), rescale="quantile", 
    display.scale="radius", display.type="circleray", cex=0.5, pch=1,
    labels=NULL, pos=1, labels.cex=1, legend=NULL, legend.xy=NULL, 
    legend.cex=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gdist.plotstats_+3A_d">d</code></td>
<td>
<p> A matrix containing the inter-graph distances </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_meas">meas</code></td>
<td>
<p> An nxm matrix containing the graph-level measures; each row must correspond to a graph, and each column must correspond to an index </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_siz.lim">siz.lim</code></td>
<td>
<p> The minimum and maximum sizes (respectively) of the plotted symbols, given as fractions of the total plotting range </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_rescale">rescale</code></td>
<td>
<p> One of &ldquo;quantile&rdquo; for ordinal scaling, &ldquo;affine&rdquo; for max-min scaling, and &ldquo;normalize&rdquo; for rescaling by maximum value; these determine the scaling rule to be used in sizing the plotting symbols </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_display.scale">display.scale</code></td>
<td>
<p> One of &ldquo;area&rdquo; or &ldquo;radius&rdquo;; this controls the attribute of the plotting symbol which is rescaled by the value of <code>meas</code></p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_display.type">display.type</code></td>
<td>
<p> One of &ldquo;circle&rdquo;, &ldquo;ray&rdquo;, &ldquo;circleray&rdquo;, &ldquo;poly&rdquo;, or &ldquo;polyray&rdquo;; this determines the type of plotting symbol used (circles, rays, polygons, or come combination of these) </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_cex">cex</code></td>
<td>
<p> Character expansion coefficient </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_pch">pch</code></td>
<td>
<p> Point types for the base plotting symbol (not the expanded symbols which are used to indicate <code>meas</code> values) </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_labels">labels</code></td>
<td>
<p> Point labels, if desired </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_pos">pos</code></td>
<td>
<p> Relative position of labels (see <code><a href="graphics.html#topic+par">par</a></code>) </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_labels.cex">labels.cex</code></td>
<td>
<p> Character expansion factor for labels </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_legend">legend</code></td>
<td>
<p> Add a legend? </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_legend.xy">legend.xy</code></td>
<td>
<p> x,y coordinates for legend </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_legend.cex">legend.cex</code></td>
<td>
<p> Character expansion factor for legend </p>
</td></tr>
<tr><td><code id="gdist.plotstats_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code><a href="graphics.html#topic+plot">plot</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gdist.plotstats</code> works by performing an MDS (using <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>) on <code>d</code>, and then using the values in <code>meas</code> to determine the shape of the points at each MDS coordinate.  Typically, these shapes involve rays of varying color and length indicating <code>meas</code> magnitude, with circles and polygons of the appropriate radius and/or error being options as well.  Various options are available (described above) to govern the details of the data display; some tinkering may be needed in order to produce an aesthetically pleasing visualization.
</p>
<p>The primary use of <code>gdist.plotstats</code> is to explore broad relationships between graph properties and inter-graph distances.  This routine complements others in the <code>gdist</code> and <code>gclust</code> family of interstructural visualization tools.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Note</h3>

<p> This routine does not actually depend on the data's being graphic in origin, and can be used with any distance matrix/measure matrix combination. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo; CASOS working paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gdist.plotdiff">gdist.plotdiff</a></code>, <code><a href="#topic+gclust.boxstats">gclust.boxstats</a></code>, <code><a href="#topic+gclust.centralgraph">gclust.centralgraph</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate random graphs with varying density
g&lt;-rgraph(10,20,tprob=runif(20,0,1))

#Get Hamming distances between graphs
g.h&lt;-hdist(g)

#Plot the association of distance, density, and reciprocity
gdist.plotstats(g.h,cbind(gden(g),grecip(g)))
</code></pre>

<hr>
<h2 id='geodist'> Fund the Numbers and Lengths of Geodesics Among Nodes in a Graph </h2><span id='topic+geodist'></span><span id='topic+geodist_R'></span><span id='topic+geodist_adj_R'></span><span id='topic+geodist_val_R'></span>

<h3>Description</h3>

<p><code>geodist</code> uses a BFS to find the number and lengths of geodesics between all nodes of <code>dat</code>.  Where geodesics do not exist, the value in <code>inf.replace</code> is substituted for the distance in question.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geodist(dat, inf.replace=Inf, count.paths=TRUE, predecessors=FALSE,
    ignore.eval=TRUE, na.omit=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geodist_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="geodist_+3A_inf.replace">inf.replace</code></td>
<td>
<p> the value to use for geodesic distances between disconnected nodes; by default, this is equal <code>Inf</code>. </p>
</td></tr>
<tr><td><code id="geodist_+3A_count.paths">count.paths</code></td>
<td>
<p> logical; should a count of geodesics be included in the returned object?</p>
</td></tr>
<tr><td><code id="geodist_+3A_predecessors">predecessors</code></td>
<td>
<p> logical; should a predecessor list be included in the returned object?</p>
</td></tr>
<tr><td><code id="geodist_+3A_ignore.eval">ignore.eval</code></td>
<td>
<p> logical; should edge values be ignored when computing geodesics?</p>
</td></tr>
<tr><td><code id="geodist_+3A_na.omit">na.omit</code></td>
<td>
<p> logical; should <code>NA</code>-valued edges be removed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This routine is used by a variety of other functions; many of these will allow the user to provide manually precomputed <code>geodist</code> output so as to prevent expensive recomputation.  Note that the choice of infinite path length for disconnected vertex pairs is non-canonical (albeit common), and some may prefer to simply treat these as missing values.  <code>geodist</code> (without loss of generality) treats all paths as directed, a fact which should be kept in mind when interpreting <code>geodist</code> output.
</p>
<p>By default, <code>geodist</code> ignores edge values (except for <code>NA</code>ed edges, which are dropped when <code>na.omit==TRUE</code>).  Setting <code>ignore.eval=FALSE</code> will change this behavior, with edge values being interpreted as distances; where edge values reflect proximity or tie strength, transformation may be necessary.  Edge values should also be non-negative.  Because the valued-case algorithm is significantly slower than the unvalued-case algorithm, <code>ignore.eval</code> should be set to <code>TRUE</code> wherever possible.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr><td><code>counts</code></td>
<td>
<p>If <code>count.paths==TRUE</code>, a matrix containing the number of geodesics between each pair of vertices</p>
</td></tr>
<tr><td><code>gdist</code></td>
<td>
<p>A matrix containing the geodesic distances between each pair of vertices</p>
</td></tr>
<tr><td><code>predecessors</code></td>
<td>
<p>If <code>predecessors</code>, a list whose ith element is a list of vectors, the jth of which contains the intervening vertices on all shortest paths from i to j</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Brandes, U.  (2000).  &ldquo;Faster Evaluation of Shortest-Path Based Centrality Indices.&rdquo; <em>Konstanzer Schriften in Mathematik und Informatik</em>, 120.
</p>
<p>West, D.B.  (1996).  <em>Introduction to Graph Theory.</em>  Upper Saddle River, N.J.: Prentice Hall. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+component.dist">component.dist</a></code>, <code><a href="#topic+components">components</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Find geodesics on a random graph
gd&lt;-geodist(rgraph(15))

#Examine the number of geodesics
gd$counts

#Examine the geodesic distances
gd$gdist
</code></pre>

<hr>
<h2 id='gilschmidt'>
Compute the Gil-Schmidt Power Index
</h2><span id='topic+gilschmidt'></span><span id='topic+gilschmidt_R'></span>

<h3>Description</h3>

<p><code>gilschmidt</code> computes the Gil-Schmidt Power Index for all nodes in <code>dat</code>, with or without normalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gilschmidt(dat, g = 1, nodes = NULL, gmode = "digraph", diag = FALSE, 
    tmaxdev = FALSE, normalize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gilschmidt_+3A_dat">dat</code></td>
<td>

<p>one or more input graphs (for best performance, sna edgelists or network objects are suggested).
</p>
</td></tr>
<tr><td><code id="gilschmidt_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g</code>=1. </p>
</td></tr>
<tr><td><code id="gilschmidt_+3A_nodes">nodes</code></td>
<td>
<p> list indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="gilschmidt_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>gmode</code> is set to <code>"digraph"</code> by default. </p>
</td></tr>
<tr><td><code id="gilschmidt_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  (This has no effect on this index, but is included for compatibility with <code><a href="#topic+centralization">centralization</a></code>. </p>
</td></tr>
<tr><td><code id="gilschmidt_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev==FALSE</code>. </p>
</td></tr>
<tr><td><code id="gilschmidt_+3A_normalize">normalize</code></td>
<td>

<p>logical; should the index scores be normalized?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For graph <code class="reqn">G=(V,E)</code>, let <code class="reqn">R(v,G)</code> be the set of vertices reachable by <code class="reqn">v</code> in <code class="reqn">V\setminus v</code>.  Then the Gil-Schmidt power index is defined as
</p>
<p style="text-align: center;"><code class="reqn">C_{GS}(v) = \frac{\sum_{i \in R(v,G)} \frac{1}{d(v,i)}}{|R(v,G)|}.</code>
</p>

<p>where <code class="reqn">d(v,i)</code> is the geodesic distance from <code class="reqn">v</code> to <code class="reqn">i</code> in <code class="reqn">G</code>; the index is taken to be 0 for isolates.  The measure takes a value of 1 when <code class="reqn">v</code> is adjacent to all reachable vertices, and approaches 0 as the distance from <code class="reqn">v</code> to each vertex approaches infinity.  (For finite <code class="reqn">N=|V|</code>, the minimum value is 0 if <code class="reqn">v</code> is an isolate, and otherwise <code class="reqn">1/(N-1)</code>.)
</p>
<p>If <code>normalize=FALSE</code> is selected, then normalization by <code class="reqn">|R(v,G)|</code> is not performed.  This measure has been proposed as a better-behaved alternative to closeness (to which it is closely related).
</p>
<p>The <code><a href="#topic+closeness">closeness</a></code> function in the sna library can also be used to compute this index.
</p>


<h3>Value</h3>

<p>A vector of centrality scores.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts, <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Gil, J. and Schmidt, S.  (1996).  &ldquo;The Origin of the Mexican Network of Power&rdquo;.  Proceedings of the International Social Network Conference, Charleston, SC, 22-25.
</p>
<p>Sinclair, P.A.  (2009).  &ldquo;Network Centralization with the Gil Schmidt Power Centrality Index&rdquo;  <em>Social Networks</em>, 29, 81-92.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+closeness">closeness</a>, <a href="#topic+centralization">centralization</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(coleman)  #Load Coleman friendship network
gs&lt;-gilschmidt(coleman,g=1:2)  #Compute the Gil-Schmidt index

#Plot G-S values in the fall, versus spring
plot(gs,xlab="Fall",ylab="Spring",main="G-S Index")
abline(0,1)
</code></pre>

<hr>
<h2 id='gliop'> Return a Binary Operation on GLI Values Computed on Two Graphs </h2><span id='topic+gliop'></span>

<h3>Description</h3>

<p><code>gliop</code> is a wrapper which allows for an arbitrary binary operation on GLIs to be treated as a single call.  This is particularly useful for test routines such as <code><a href="#topic+cugtest">cugtest</a></code> and <code><a href="#topic+qaptest">qaptest</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gliop(dat, GFUN, OP="-", g1=1, g2=2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gliop_+3A_dat">dat</code></td>
<td>
<p> a collection of graphs. </p>
</td></tr>
<tr><td><code id="gliop_+3A_gfun">GFUN</code></td>
<td>
<p> a function taking single graphs as input. </p>
</td></tr>
<tr><td><code id="gliop_+3A_op">OP</code></td>
<td>
<p> the operator to use on the output of <code>GFUN</code>. </p>
</td></tr>
<tr><td><code id="gliop_+3A_g1">g1</code></td>
<td>
<p> the index of the first input graph. </p>
</td></tr>
<tr><td><code id="gliop_+3A_g2">g2</code></td>
<td>
<p> the index of the second input graph. </p>
</td></tr>
<tr><td><code id="gliop_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code>GFUN</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gliop</code> operates by evaluating <code>GFUN</code> on the graphs indexed by <code>g1</code> and <code>g2</code> and returning the result of <code>OP</code> as applied to the <code>GFUN</code> output.
</p>


<h3>Value</h3>

<p><code>OP(GFUN(dat[g1, , ],...),GFUN(dat[g2, , ],...))</code>
</p>


<h3>Note</h3>

<p> If the output of <code>GFUN</code> is not sufficiently well-behaved, undefined behavior may occur.  Common sense is advised. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Anderson, B.S.; Butts, C.T.; and Carley, K.M. (1999). &ldquo;The Interaction of Size and Density with Graph-Level Indices.&rdquo; <em>Social Networks</em>, 21(3), 239-267. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+cugtest">cugtest</a></code>, <code><a href="#topic+qaptest">qaptest</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw two random graphs
g&lt;-rgraph(10,2,tprob=c(0.2,0.5))

#What is their difference in density?
gliop(g,gden,"-",1,2)
</code></pre>

<hr>
<h2 id='gplot'> Two-Dimensional Visualization of Graphs </h2><span id='topic+gplot'></span>

<h3>Description</h3>

<p><code>gplot</code> produces a two-dimensional plot of graph <code>g</code> in collection <code>dat</code>.  A variety of options are available to control vertex placement, display details, color, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot(dat, g = 1, gmode = "digraph", diag = FALSE, 
    label = NULL, coord = NULL, jitter = TRUE, thresh = 0, 
    thresh.absval=TRUE, usearrows = TRUE, mode = "fruchtermanreingold", 
    displayisolates = TRUE, interactive = FALSE, interact.bycomp = FALSE,
    xlab = NULL, ylab = NULL, xlim = NULL, ylim = NULL, pad = 0.2, 
    label.pad = 0.5, displaylabels = !is.null(label), boxed.labels = FALSE, 
    label.pos = 0, label.bg = "white", vertex.enclose = FALSE, 
    vertex.sides = NULL, vertex.rot = 0, arrowhead.cex = 1, label.cex = 1, 
    loop.cex = 1, vertex.cex = 1, edge.col = 1, label.col = 1, 
    vertex.col = NULL, label.border = 1, vertex.border = 1, edge.lty = NULL,
    edge.lty.neg=2, label.lty = NULL, vertex.lty = 1, edge.lwd = 0, 
    label.lwd = par("lwd"), edge.len = 0.5, edge.curve = 0.1, 
    edge.steps = 50, loop.steps = 20, object.scale = 0.01, uselen = FALSE, 
    usecurve = FALSE, suppress.axes = TRUE, vertices.last = TRUE, 
    new = TRUE, layout.par = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot_+3A_dat">dat</code></td>
<td>
<p> a graph or set thereof.  This data may be valued. </p>
</td></tr>
<tr><td><code id="gplot_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph which is to be plotted.  By default, <code>g==1</code>. </p>
</td></tr>
<tr><td><code id="gplot_+3A_gmode">gmode</code></td>
<td>
<p> String indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected; <code>"twomode"</code> indicates that data should be interpreted as two-mode (i.e., rows and columns are distinct vertex sets).  <code>gmode</code> is set to <code>"digraph"</code> by default. </p>
</td></tr>
<tr><td><code id="gplot_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="gplot_+3A_label">label</code></td>
<td>
<p> a vector of vertex labels, if desired; defaults to the vertex index number. </p>
</td></tr>
<tr><td><code id="gplot_+3A_coord">coord</code></td>
<td>
<p> user-specified vertex coordinates, in an NCOL(dat)x2 matrix.  Where this is specified, it will override the <code>mode</code> setting. </p>
</td></tr>
<tr><td><code id="gplot_+3A_jitter">jitter</code></td>
<td>
<p> boolean; should the output be jittered? </p>
</td></tr>
<tr><td><code id="gplot_+3A_thresh">thresh</code></td>
<td>
<p> real number indicating the lower threshold for tie values.  Only ties of value &gt;<code>thresh</code> (by default in absolute value - see <code>thresh.absval</code>)are displayed.  By default, <code>thresh</code>=0.</p>
</td></tr>
<tr><td><code id="gplot_+3A_thresh.absval">thresh.absval</code></td>
<td>
<p> boolean; should the absolute value of edge weights be used when thresholding?  (Defaults to TRUE; setting to FALSE leads to thresholding by signed weights.)</p>
</td></tr>
<tr><td><code id="gplot_+3A_usearrows">usearrows</code></td>
<td>
<p> boolean; should arrows (rather than line segments) be used to indicate edges? </p>
</td></tr>
<tr><td><code id="gplot_+3A_mode">mode</code></td>
<td>
<p> the vertex placement algorithm; this must correspond to a <code><a href="#topic+gplot.layout">gplot.layout</a></code> function. </p>
</td></tr>
<tr><td><code id="gplot_+3A_displayisolates">displayisolates</code></td>
<td>
<p> boolean; should isolates be displayed? </p>
</td></tr>
<tr><td><code id="gplot_+3A_interactive">interactive</code></td>
<td>
<p> boolean; should interactive adjustment of vertex placement be attempted? </p>
</td></tr>
<tr><td><code id="gplot_+3A_interact.bycomp">interact.bycomp</code></td>
<td>
<p> boolean; if <code>interactive==TRUE</code>, should all vertices in the component be moved? </p>
</td></tr>
<tr><td><code id="gplot_+3A_xlab">xlab</code></td>
<td>
<p> x axis label. </p>
</td></tr>
<tr><td><code id="gplot_+3A_ylab">ylab</code></td>
<td>
<p> y axis label. </p>
</td></tr>
<tr><td><code id="gplot_+3A_xlim">xlim</code></td>
<td>
<p> the x limits (min, max) of the plot. </p>
</td></tr>
<tr><td><code id="gplot_+3A_ylim">ylim</code></td>
<td>
<p> the y limits of the plot. </p>
</td></tr> 
<tr><td><code id="gplot_+3A_pad">pad</code></td>
<td>
<p> amount to pad the plotting range; useful if labels are being clipped. </p>
</td></tr>
<tr><td><code id="gplot_+3A_label.pad">label.pad</code></td>
<td>
<p> amount to pad label boxes (if <code>boxed.labels==TRUE</code>), in character size units. </p>
</td></tr>
<tr><td><code id="gplot_+3A_displaylabels">displaylabels</code></td>
<td>
<p> boolean; should vertex labels be displayed? </p>
</td></tr>
<tr><td><code id="gplot_+3A_boxed.labels">boxed.labels</code></td>
<td>
<p> boolean; place vertex labels within boxes? </p>
</td></tr>
<tr><td><code id="gplot_+3A_label.pos">label.pos</code></td>
<td>
<p> position at which labels should be placed, relative to vertices.  <code>0</code> results in labels which are placed away from the center of the plotting region; <code>1</code>, <code>2</code>, <code>3</code>, and <code>4</code> result in labels being placed below, to the left of, above, and to the right of vertices (respectively); and <code>label.pos&gt;=5</code> results in labels which are plotted with no offset (i.e., at the vertex positions). </p>
</td></tr>
<tr><td><code id="gplot_+3A_label.bg">label.bg</code></td>
<td>
<p> background color for label boxes (if <code>boxed.labels==TRUE</code>); may be a vector, if boxes are to be of different colors.</p>
</td></tr>
<tr><td><code id="gplot_+3A_vertex.enclose">vertex.enclose</code></td>
<td>
<p> boolean; should vertices be enclosed within circles?  (Can increase legibility for polygonal vertices.)</p>
</td></tr>
<tr><td><code id="gplot_+3A_vertex.sides">vertex.sides</code></td>
<td>
<p> number of polygon sides for vertices; may be given as a vector, if vertices are to be of different types.  By default, 50 sides are used (or 50 and 4, for two-mode data).</p>
</td></tr>
<tr><td><code id="gplot_+3A_vertex.rot">vertex.rot</code></td>
<td>
<p> angle of rotation for vertices (in degrees); may be given as a vector, if vertices are to be rotated differently. </p>
</td></tr>
<tr><td><code id="gplot_+3A_arrowhead.cex">arrowhead.cex</code></td>
<td>
<p> expansion factor for edge arrowheads.</p>
</td></tr>
<tr><td><code id="gplot_+3A_label.cex">label.cex</code></td>
<td>
<p> character expansion factor for label text. </p>
</td></tr>
<tr><td><code id="gplot_+3A_loop.cex">loop.cex</code></td>
<td>
<p> expansion factor for loops; may be given as a vector, if loops are to be of different sizes. </p>
</td></tr>
<tr><td><code id="gplot_+3A_vertex.cex">vertex.cex</code></td>
<td>
<p> expansion factor for vertices; may be given as a vector, if vertices are to be of different sizes. </p>
</td></tr>
<tr><td><code id="gplot_+3A_edge.col">edge.col</code></td>
<td>
<p> color for edges; may be given as a vector or adjacency matrix, if edges are to be of different colors. </p>
</td></tr>
<tr><td><code id="gplot_+3A_label.col">label.col</code></td>
<td>
<p> color for vertex labels; may be given as a vector, if labels are to be of different colors. </p>
</td></tr>
<tr><td><code id="gplot_+3A_vertex.col">vertex.col</code></td>
<td>
<p> color for vertices; may be given as a vector, if vertices are to be of different colors.  By default, red is used (or red and blue, for two-mode data).</p>
</td></tr>
<tr><td><code id="gplot_+3A_label.border">label.border</code></td>
<td>
<p> label border colors (if <code>boxed.labels==TRUE</code>); may be given as a vector, if label boxes are to have different colors. </p>
</td></tr>
<tr><td><code id="gplot_+3A_vertex.border">vertex.border</code></td>
<td>
<p> border color for vertices; may be given as a vector, if vertex borders are to be of different colors. </p>
</td></tr>
<tr><td><code id="gplot_+3A_edge.lty">edge.lty</code></td>
<td>
<p> line type for (positive weight) edges; may be given as a vector or adjacency matrix, if edges are to have different line types. </p>
</td></tr>
<tr><td><code id="gplot_+3A_edge.lty.neg">edge.lty.neg</code></td>
<td>
<p> line type for negative weight edges, if any; may be given as per <code>edge.lty</code>.</p>
</td></tr> 
<tr><td><code id="gplot_+3A_label.lty">label.lty</code></td>
<td>
<p> line type for label boxes (if <code>boxed.labels==TRUE</code>); may be given as a vector, if label boxes are to have different line types. </p>
</td></tr>
<tr><td><code id="gplot_+3A_vertex.lty">vertex.lty</code></td>
<td>
<p> line type for vertex borders; may be given as a vector or adjacency matrix, if vertex borders are to have different line types. </p>
</td></tr>
<tr><td><code id="gplot_+3A_edge.lwd">edge.lwd</code></td>
<td>
<p> line width scale for edges; if set greater than 0, edge widths are scaled by <code>edge.lwd*dat</code>.  May be given as a vector or adjacency matrix, if edges are to have different line widths. </p>
</td></tr>
<tr><td><code id="gplot_+3A_label.lwd">label.lwd</code></td>
<td>
<p> line width for label boxes (if <code>boxed.labels==TRUE</code>); may be given as a vector, if label boxes are to have different line widths. </p>
</td></tr>
<tr><td><code id="gplot_+3A_edge.len">edge.len</code></td>
<td>
<p> if <code>uselen==TRUE</code>, curved edge lengths are scaled by <code>edge.len</code>. </p>
</td></tr>
<tr><td><code id="gplot_+3A_edge.curve">edge.curve</code></td>
<td>
<p> if <code>usecurve==TRUE</code>, the extent of edge curvature is controlled by <code>edge.curv</code>.  May be given as a fixed value, vector, or adjacency matrix, if edges are to have different levels of curvature.  </p>
</td></tr>
<tr><td><code id="gplot_+3A_edge.steps">edge.steps</code></td>
<td>
<p> for curved edges (excluding loops), the number of line segments to use for the curve approximation. </p>
</td></tr>
<tr><td><code id="gplot_+3A_loop.steps">loop.steps</code></td>
<td>
<p> for loops, the number of line segments to use for the curve approximation. </p>
</td></tr>
<tr><td><code id="gplot_+3A_object.scale">object.scale</code></td>
<td>
<p> base length for plotting objects, as a fraction of the linear scale of the plotting region. Defaults to 0.01.</p>
</td></tr>
<tr><td><code id="gplot_+3A_uselen">uselen</code></td>
<td>
<p> boolean; should we use <code>edge.len</code> to rescale edge lengths? </p>
</td></tr>
<tr><td><code id="gplot_+3A_usecurve">usecurve</code></td>
<td>
<p> boolean; should we use <code>edge.curve</code>? </p>
</td></tr>
<tr><td><code id="gplot_+3A_suppress.axes">suppress.axes</code></td>
<td>
<p> boolean; suppress plotting of axes? </p>
</td></tr>
<tr><td><code id="gplot_+3A_vertices.last">vertices.last</code></td>
<td>
<p> boolean; plot vertices after plotting edges? </p>
</td></tr>
<tr><td><code id="gplot_+3A_new">new</code></td>
<td>
<p> boolean; create a new plot?  If <code>new==FALSE</code>, vertices and edges will be added to the existing plot. </p>
</td></tr>
<tr><td><code id="gplot_+3A_layout.par">layout.par</code></td>
<td>
<p> parameters to the <code><a href="#topic+gplot.layout">gplot.layout</a></code> function specified in <code>mode</code>. </p>
</td></tr>
<tr><td><code id="gplot_+3A_...">...</code></td>
<td>
<p> additional arguments to <code><a href="graphics.html#topic+plot">plot</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gplot</code> is the standard network visualization tool within the <code>sna</code> library.  By means of clever selection of display parameters, a fair amount of display flexibility can be obtained.  Graph layout &ndash; if not specified directly using <code>coord</code> &ndash; is determined via one of the various available algorithms.  These should be specified via the <code>mode</code> argument; see <code><a href="#topic+gplot.layout">gplot.layout</a></code> for a full list.  User-supplied layout functions are also possible &ndash; see the aforementioned man page for details.
</p>
<p>Note that where <code>gmode=="twomode"</code>, the supplied two-mode network is converted to bipartite form prior to computing coordinates (if not in that form already).  <code>vertex.col</code> or other settings may be used to differentiate row and column vertices &ndash; by default, row vertices are drawn as red circles, and column vertices are rendered as blue squares.  If <code>interactive==TRUE</code>, then the user may modify the initial graph layout by selecting an individual vertex and then clicking on the location to which this vertex is to be moved; this process may be repeated until the layout is satisfactory.  If <code>interact.bycomp==TRUE</code> as well, the vertex and all other vertices in the same component as that vertex are moved together.
</p>


<h3>Value</h3>

<p>A two-column matrix containing the vertex positions as x,y coordinates.  
</p>


<h3>Author(s)</h3>

 
<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> 
</p>
<p>Alex Montgomery <a href="mailto:ahm@reed.edu">ahm@reed.edu</a>
</p>


<h3>References</h3>

<p> Wasserman, S. and Faust, K.  (1994)  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press. </p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="#topic+gplot.layout">gplot.layout</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>gplot(rgraph(5))               #Plot a random graph
gplot(rgraph(5),usecurv=TRUE)  #This time, use curved edges
gplot(rgraph(5),mode="mds")    #Try an alternative layout scheme

#A colorful demonstration...
gplot(rgraph(5,diag=TRUE),diag=TRUE,vertex.cex=1:5,vertex.sides=3:8,
    vertex.col=1:5,vertex.border=2:6,vertex.rot=(0:4)*72,
    displaylabels=TRUE,label.bg="gray90")
    
</code></pre>

<hr>
<h2 id='gplot.arrow'> Add Arrows or Segments to a Plot </h2><span id='topic+gplot.arrow'></span>

<h3>Description</h3>

<p><code>gplot.arrow</code> draws a segment or arrow between two pairs of points; unlike <code><a href="graphics.html#topic+arrows">arrows</a></code> or <code><a href="graphics.html#topic+segments">segments</a></code>, the new plot element is drawn as a polygon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot.arrow(x0, y0, x1, y1, length = 0.1, angle = 20, width = 0.01,
    col = 1, border = 1, lty = 1, offset.head = 0, offset.tail = 0,
    arrowhead = TRUE, curve = 0, edge.steps = 50, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot.arrow_+3A_x0">x0</code></td>
<td>
<p> A vector of x coordinates for points of origin </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_y0">y0</code></td>
<td>
<p> A vector of y coordinates for points of origin </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_x1">x1</code></td>
<td>
<p> A vector of x coordinates for destination points </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_y1">y1</code></td>
<td>
<p> A vector of y coordinates for destination points </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_length">length</code></td>
<td>
<p> Arrowhead length, in current plotting units </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_angle">angle</code></td>
<td>
<p> Arrowhead angle (in degrees) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_width">width</code></td>
<td>
<p> Width for arrow body, in current plotting units (can be a vector) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_col">col</code></td>
<td>
<p> Arrow body color (can be a vector) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_border">border</code></td>
<td>
<p> Arrow border color (can be a vector) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_lty">lty</code></td>
<td>
<p> Arrow border line type (can be a vector) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_offset.head">offset.head</code></td>
<td>
<p> Offset for destination point (can be a vector) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_offset.tail">offset.tail</code></td>
<td>
<p> Offset for origin point (can be a vector) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_arrowhead">arrowhead</code></td>
<td>
<p> Boolean; should arrowheads be used?  (Can be a vector)) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_curve">curve</code></td>
<td>
<p> Degree of edge curvature (if any), in current plotting units (can be a vector) </p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_edge.steps">edge.steps</code></td>
<td>
<p> For curved edges, the number of steps to use in approximating the curve (can be a vector)</p>
</td></tr>
<tr><td><code id="gplot.arrow_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code><a href="graphics.html#topic+polygon">polygon</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gplot.arrow</code> provides a useful extension of <code><a href="graphics.html#topic+segments">segments</a></code> and <code><a href="graphics.html#topic+arrows">arrows</a></code> when fine control is needed over the resulting display.  (The results also look better.)  Note that edge curvature is quadratic, with <code>curve</code> providing the maximum horizontal deviation of the edge (left-handed).  Head/tail offsets are used to adjust the end/start points of an edge, relative to the baseline coordinates; these are useful for functions like <code><a href="#topic+gplot">gplot</a></code>, which need to draw edges incident to vertices of varying radii.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot">gplot</a></code>, <code><a href="#topic+gplot.loop">gplot.loop</a></code>, <code><a href="graphics.html#topic+polygon">polygon</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  #Plot two points
  plot(1:2,1:2)
  
  #Add an edge
  gplot.arrow(1,1,2,2,width=0.01,col="red",border="black")
</code></pre>

<hr>
<h2 id='gplot.layout'> Vertex Layout Functions for gplot </h2><span id='topic+gplot.layout'></span><span id='topic+gplot.layout.adj'></span><span id='topic+gplot.layout.circle'></span><span id='topic+gplot.layout.circrand'></span><span id='topic+gplot.layout.eigen'></span><span id='topic+gplot.layout.fruchtermanreingold'></span><span id='topic+gplot.layout.geodist'></span><span id='topic+gplot.layout.hall'></span><span id='topic+gplot.layout.kamadakawai'></span><span id='topic+gplot.layout.mds'></span><span id='topic+gplot.layout.princoord'></span><span id='topic+gplot.layout.random'></span><span id='topic+gplot.layout.rmds'></span><span id='topic+gplot.layout.segeo'></span><span id='topic+gplot.layout.seham'></span><span id='topic+gplot.layout.spring'></span><span id='topic+gplot.layout.springrepulse'></span><span id='topic+gplot.layout.target'></span><span id='topic+gplot_layout_fruchtermanreingold_R'></span><span id='topic+gplot_layout_fruchtermanreingold_old_R'></span><span id='topic+gplot_layout_kamadakawai_R'></span>

<h3>Description</h3>

<p>Various functions which generate vertex layouts for the <code><a href="#topic+gplot">gplot</a></code> visualization routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot.layout.adj(d, layout.par)
gplot.layout.circle(d, layout.par)
gplot.layout.circrand(d, layout.par)
gplot.layout.eigen(d, layout.par)
gplot.layout.fruchtermanreingold(d, layout.par)
gplot.layout.geodist(d, layout.par)
gplot.layout.hall(d, layout.par)
gplot.layout.kamadakawai(d, layout.par)
gplot.layout.mds(d, layout.par)
gplot.layout.princoord(d, layout.par)
gplot.layout.random(d, layout.par)
gplot.layout.rmds(d, layout.par)
gplot.layout.segeo(d, layout.par)
gplot.layout.seham(d, layout.par)
gplot.layout.spring(d, layout.par)
gplot.layout.springrepulse(d, layout.par)
gplot.layout.target(d, layout.par)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot.layout_+3A_d">d</code></td>
<td>
<p> an adjacency matrix, as passed by <code><a href="#topic+gplot">gplot</a></code>. </p>
</td></tr>
<tr><td><code id="gplot.layout_+3A_layout.par">layout.par</code></td>
<td>
<p> a list of parameters. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Vertex layouts for network visualization pose a difficult problem &ndash; there is no single, &ldquo;good&rdquo; layout algorithm, and many different approaches may be valuable under different circumstances.  With this in mind, <code><a href="#topic+gplot">gplot</a></code> allows for the use of arbitrary vertex layout algorithms via the <code>gplot.layout.*</code> family of routines.  When called, <code><a href="#topic+gplot">gplot</a></code> searches for a <code>gplot.layout</code> function whose third name matches its <code>mode</code> argument (see <code><a href="#topic+gplot">gplot</a></code> help for more information); this function is then used to generate the layout for the resulting plot.  In addition to the routines documented here, users may add their own layout functions as needed.  The requirements for a <code>gplot.layout</code> function are as follows:
</p>

<ol>
<li><p> the first argument, <code>d</code>, must be the (dichotomous) graph adjacency matrix;
</p>
</li>
<li><p> the second argument, <code>layout.par</code>, must be a list of parameters (or <code>NULL</code>, if no parameters are specified); and
</p>
</li>
<li><p> the return value must be a real matrix of dimension <code>c(2,NROW(d))</code>, whose rows contain the vertex coordinates.
</p>
</li></ol>

<p>Other than this, anything goes.  (In particular, note that <code>layout.par</code> could be used to pass additional matrices, if needed.)  
</p>
<p>The <code>graph.layout</code> functions currently supplied by default are as follows:
</p>

<dl>
<dt>circle</dt><dd><p> This function places vertices uniformly in a circle; it takes no arguments.</p>
</dd>
<dt>eigen</dt><dd><p> This function places vertices based on the eigenstructure of the adjacency matrix.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$var</code></dt><dd><p> This argument controls the matrix to be used for the eigenanalysis.  <code>"symupper"</code>, <code>"symlower"</code>, <code>"symstrong"</code>, <code>"symweak"</code> invoke <code><a href="#topic+symmetrize">symmetrize</a></code> on <code>d</code> with the respective symmetrizing rule.  <code>"user"</code> indicates a user-supplied matrix (see below), while <code>"raw"</code> indicates that <code>d</code> should be used as-is.  (Defaults to <code>"raw"</code>.)</p>
</dd>
<dt><code>layout.par$evsel</code></dt><dd><p> If <code>"first"</code>, the first two eigenvectors are used; if <code>"size"</code>, the two eigenvectors whose eigenvalues have the largest magnitude are used instead. Note that only the real portion of the associated eigenvectors is used.  (Defaults to <code>"first"</code>.)</p>
</dd>
<dt><code>layout.par$mat</code></dt><dd><p>  If <code>layout.par$var=="user"</code>, this matrix is used for the eigenanalysis. (No default.)</p>
</dd>
</dl>

</dd>
<dt>fruchtermanreingold</dt><dd><p> This function generates a layout using a variant of Fruchterman and Reingold's force-directed placement algorithm.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$niter</code></dt><dd><p> This argument controls the number of iterations to be employed.  Larger values take longer, but will provide a more refined layout.  (Defaults to 500.) </p>
</dd>
<dt><code>layout.par$max.delta</code></dt><dd><p> Sets the maximum change in position for any given iteration.   (Defaults to <code>n</code>.)</p>
</dd>
<dt><code>layout.par$area</code></dt><dd><p>  Sets the &ldquo;area&rdquo; parameter for the F-R algorithm. (Defaults to <code>n^2</code>.)</p>
</dd>
<dt><code>layout.par$cool.exp</code></dt><dd><p>  Sets the cooling exponent for the annealer. (Defaults to 3.)</p>
</dd>
<dt><code>layout.par$repulse.rad</code></dt><dd><p>  Determines the radius at which vertex-vertex repulsion cancels out attraction of adjacent vertices.  (Defaults to <code>area*log(n)</code>.)</p>
</dd>
<dt><code>layout.par$ncell</code></dt><dd><p>  To speed calculations on large graphs, the plot region is divided at each iteration into <code>ncell</code> by <code>ncell</code> &ldquo;cells&rdquo;, which are used to define neighborhoods for force calculation.  Moderate numbers of cells result in fastest performance; too few cells (down to 1, which produces &ldquo;pure&rdquo; F-R results) can yield odd layouts, while too many will result in long layout times.  (Defaults to <code>n^0.5</code>.)</p>
</dd>
<dt><code>layout.par$cell.jitter</code></dt><dd><p>  Jitter factor (in units of cell width) used in assigning vertices to cells.  Small values may generate &ldquo;grid-like&rdquo; anomalies for graphs with many isolates.  (Defaults to <code>0.5</code>.)</p>
</dd>
<dt><code>layout.par$cell.pointpointrad</code></dt><dd><p>  Squared &ldquo;radius&rdquo; (in units of cells) such that exact point interaction calculations are used for all vertices belonging to any two cells less than or equal to this distance apart.  Higher values approximate the true F-R solution, but increase computational cost.  (Defaults to <code>0</code>.)</p>
</dd>
<dt><code>layout.par$cell.pointcellrad</code></dt><dd><p>  Squared &ldquo;radius&rdquo; (in units of cells) such that approximate point/cell interaction calculations are used for all vertices belonging to any two cells less than or equal to this distance apart (and not within the point/point radius).  Higher values provide somewhat better approximations to the true F-R solution at slightly increased computational cost.  (Defaults to <code>18</code>.)</p>
</dd>
<dt><code>layout.par$cell.cellcellrad</code></dt><dd><p>  Squared &ldquo;radius&rdquo; (in units of cells) such that approximate cell/cell interaction calculations are used for all vertices belonging to any two cells less than or equal to this distance apart (and not within the point/point or point/cell radii).  Higher values provide somewhat better approximations to the true F-R solution at slightly increased computational cost.  Note that cells beyond this radius (if any) do not interact, save through edge attraction. (Defaults to <code>ncell^2</code>.)</p>
</dd>
<dt><code>layout.par$seed.coord</code></dt><dd><p> A two-column matrix of initial vertex coordinates.  (Defaults to a random circular layout.) </p>
</dd>  
</dl>

</dd>
<dt>hall</dt><dd><p> This function places vertices based on the last two eigenvectors of the Laplacian of the input matrix (Hall's algorithm).  It takes no arguments.</p>
</dd>
<dt>kamadakawai</dt><dd><p> This function generates a vertex layout using a version of the Kamada-Kawai force-directed placement algorithm.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$niter</code></dt><dd><p> This argument controls the number of iterations to be employed.  (Defaults to 1000.) </p>
</dd>
<dt><code>layout.par$sigma</code></dt><dd><p> Sets the base standard deviation of position change proposals.   (Defaults to <code>NROW(d)/4</code>.)</p>
</dd>
<dt><code>layout.par$initemp</code></dt><dd><p>  Sets the initial &quot;temperature&quot; for the annealing algorithm. (Defaults to 10.)</p>
</dd>
<dt><code>layout.par$cool.exp</code></dt><dd><p>  Sets the cooling exponent for the annealer. (Defaults to 0.99.)</p>
</dd>
<dt><code>layout.par$kkconst</code></dt><dd><p>  Sets the Kamada-Kawai vertex attraction constant.  (Defaults to <code>NROW(d)^2</code>.)</p>
</dd>
<dt><code>layout.par$elen</code></dt><dd><p>  Provides the matrix of interpoint distances to be approximated.  (Defaults to the geodesic distances of <code>d</code> after symmetrizing, capped at <code>sqrt(NROW(d))</code>.)</p>
</dd>
<dt><code>layout.par$seed.coord</code></dt><dd><p> A two-column matrix of initial vertex coordinates.  (Defaults to a gaussian layout.) </p>
</dd>  
</dl>

</dd>
<dt>mds</dt><dd><p> This function places vertices based on a metric multidimensional scaling of a specified distance matrix.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$var</code></dt><dd><p> This argument controls the raw variable matrix to be used for the subsequent distance calculation and scaling.  <code>"rowcol"</code>, <code>"row"</code>, and <code>"col"</code> indicate that the rows and columns (concatenated), rows, or columns (respectively) of <code>d</code> should be used.  <code>"rcsum"</code> and <code>"rcdiff"</code> result in the sum or difference of <code>d</code> and its transpose being employed.  <code>"invadj"</code> indicates that <code>max{d}-d</code> should be used, while <code>"geodist"</code> uses <code><a href="#topic+geodist">geodist</a></code> to generate a matrix of geodesic distances from <code>d</code>. Alternately, an arbitrary matrix can be provided using <code>"user"</code>.  (Defaults to <code>"rowcol"</code>.)</p>
</dd>
<dt><code>layout.par$dist</code></dt><dd><p> The distance function to be calculated on the rows of the variable matrix.  This must be one of the <code>method</code> parameters to <code><a href="stats.html#topic+dist">dist</a></code> (<code>"euclidean"</code>, <code>"maximum"</code>, <code>"manhattan"</code>, or <code>"canberra"</code>), or else <code>"none"</code>.  In the latter case, no distance function is calculated, and the matrix in question must be square (with dimension <code>dim(d)</code>) for the routine to work properly.  (Defaults to <code>"euclidean"</code>.)</p>
</dd>
<dt><code>layout.par$exp</code></dt><dd><p> The power to which distances should be raised prior to scaling.  (Defaults to 2.)</p>
</dd>
<dt><code>layout.par$vm</code></dt><dd><p> If <code>layout.par$var=="user"</code>, this matrix is used for the distance calculation. (No default.)</p>
</dd>
</dl>

<p>Note: the following layout functions are based on <code>mds</code>:
</p>

<dl>
<dt>adj</dt><dd><p> scaling of the raw adjacency matrix, treated as similarities (using <code>"invadj"</code>).</p>
</dd>
<dt>geodist</dt><dd><p> scaling of the matrix of geodesic distances.</p>
</dd>
<dt>rmds</dt><dd><p> euclidean scaling of the rows of <code>d</code>.</p>
</dd>
<dt>segeo</dt><dd><p> scaling of the squared euclidean distances between row-wise geodesic distances (i.e., approximate structural equivalence).</p>
</dd>
<dt>seham</dt><dd><p> scaling of the Hamming distance between rows/columns of <code>d</code> (i.e., another approximate structural equivalence scaling).</p>
</dd>
</dl>

</dd>
<dt>princoord</dt><dd><p> This function places vertices based on the eigenstructure of a given correlation/covariance matrix. It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$var</code></dt><dd><p> The matrix of variables to be used for the correlation/covariance calculation.  <code>"rowcol"</code>, <code>"col"</code>, and <code>"row"</code> indicate that the rows/cols, columns, or rows (respectively) of <code>d</code> should be employed.  <code>"rcsum"</code> <code>"rcdiff"</code> result in the sum or difference of <code>d</code> and <code>t(d)</code> being used.  <code>"user"</code> allows for an arbitrary variable matrix to be supplied.  (Defaults to <code>"rowcol"</code>.)</p>
</dd>
<dt><code>layout.par$cor</code></dt><dd><p> Should the correlation matrix (rather than the covariance matrix) be used?  (Defaults to <code>TRUE</code>.)</p>
</dd>
<dt><code>layout.par$vm</code></dt><dd><p> If <code>layout.par$var=="user"</code>, this matrix is used for the correlation/covariance calculation. (No default.)</p>
</dd>
</dl>

</dd>
<dt>random</dt><dd><p> This function places vertices randomly.  It takes the following argument:
</p>

<dl>
<dt><code>layout.par$dist</code></dt><dd><p> The distribution to be used for vertex placement.  Currently, the options are <code>"unif"</code> (for uniform distribution on the square), <code>"uniang"</code> (for a &ldquo;gaussian donut&rdquo; configuration), and <code>"normal"</code> (for a straight Gaussian distribution).  (Defaults to <code>"unif"</code>.)</p>
</dd>
</dl>

<p>Note: <code>circrand</code>, which is a frontend to the <code>"uniang"</code> option, is based on this function.
</p>
</dd>
<dt>spring</dt><dd><p> This function places vertices using a spring embedder.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$mass</code></dt><dd><p> The vertex mass (in &ldquo;quasi-kilograms&rdquo;).  (Defaults to <code>0.1</code>.)</p>
</dd>
<dt><code>layout.par$equil</code></dt><dd><p> The equilibrium spring extension (in &ldquo;quasi-meters&rdquo;). (Defaults to <code>1</code>.)</p>
</dd>
<dt><code>layout.par$k</code></dt><dd><p> The spring coefficient (in &ldquo;quasi-Newtons per quasi-meter&rdquo;). (Defaults to <code>0.001</code>.)</p>
</dd>
<dt><code>layout.par$repeqdis</code></dt><dd><p> The point at which repulsion (if employed) balances out the spring extension force (in &ldquo;quasi-meters&rdquo;). (Defaults to <code>0.1</code>.)</p>
</dd>
<dt><code>layout.par$kfr</code></dt><dd><p> The base coefficient of kinetic friction (in &ldquo;quasi-Newton quasi-kilograms&rdquo;). (Defaults to <code>0.01</code>.)</p>
</dd>
<dt><code>layout.par$repulse</code></dt><dd><p> Should repulsion be used?  (Defaults to <code>FALSE</code>.)</p>
</dd>
</dl>

<p>Note: <code>springrepulse</code> is a frontend to <code>spring</code>, with repulsion turned on.
</p>
</dd>
<dt>target</dt><dd><p> This function produces a &quot;target diagram&quot; or &quot;bullseye&quot; layout, using a Brandes et al.'s force-directed placement algorithm.  (See also <code><a href="#topic+gplot.target">gplot.target</a></code>.)  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$niter</code></dt><dd><p> This argument controls the number of iterations to be employed.  (Defaults to 1000.) </p>
</dd>
<dt><code>layout.par$radii</code></dt><dd><p> This argument should be a vector of length <code>NROW(d)</code> containing vertex radii.  Ideally, these should lie in the [0,1] interval (and odd behavior may otherwise result).  (Defaults to the affine-transformed Freeman <code><a href="#topic+degree">degree</a></code> centrality scores of <code>d</code>.) </p>
</dd>
<dt><code>layout.par$minlen</code></dt><dd><p> Sets the minimum edge length, below which edge lengths are to be adjusted upwards.  (Defaults to 0.05.) </p>
</dd>
<dt><code>layout.par$area</code></dt><dd><p>  Sets the initial &quot;temperature&quot; for the annealing algorithm. (Defaults to 10.)</p>
</dd>
<dt><code>layout.par$cool.exp</code></dt><dd><p>  Sets the cooling exponent for the annealer. (Defaults to 0.99.)</p>
</dd>
<dt><code>layout.par$maxdelta</code></dt><dd><p>  Sets the maximum angular distance for vertex moves.  (Defaults to <code>pi</code>.)</p>
</dd>
<dt><code>layout.par$periph.outside</code></dt><dd><p>  Boolean; should &quot;peripheral&quot; vertices (in the Brandes et al. sense) be placed together outside the main target area?  (Defaults to <code>FALSE</code>.)</p>
</dd>
<dt><code>layout.par$periph.outside.offset</code></dt><dd><p>  Radius at which to place &quot;peripheral&quot; vertices if <code>periph.outside==TRUE</code>.  (Defaults to 1.2.)</p>
</dd>
<dt><code>layout.par$disconst</code></dt><dd><p>  Multiplier for the Kamada-Kawai-style distance potential.  (Defaults to 1.)</p>
</dd>
<dt><code>layout.par$crossconst</code></dt><dd><p>  Multiplier for the edge crossing potential.  (Defaults to 1.)</p>
</dd>
<dt><code>layout.par$repconst</code></dt><dd><p>  Multiplier for the vertex-edge repulsion potential.  (Defaults to 1.)</p>
</dd>
<dt><code>layout.par$minpdis</code></dt><dd><p>  Sets the &quot;minimum distance&quot; parameter for vertex repulsion.   (Defaults to 0.05.)</p>
</dd>
</dl>

</dd>
</dl>



<h3>Value</h3>

<p>A matrix whose rows contain the x,y coordinates of the vertices of <code>d</code>.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Brandes, U.; Kenis, P.; and Wagner, D.  (2003).  &ldquo;Communicating Centrality in Policy Network Drawings.&rdquo; <em>IEEE Transactions on Visualization and Computer Graphics,</em> 9(2):241-253.
</p>
<p>Fruchterman, T.M.J. and Reingold, E.M.  (1991).  &ldquo;Graph Drawing by Force-directed Placement.&rdquo; <em>Software - Practice and Experience,</em> 21(11):1129-1164.
</p>
<p>Kamada, T. and Kawai, S.  (1989).  &ldquo;An Algorithm for Drawing General Undirected Graphs.&rdquo; <em>Information Processing Letters,</em> 31(1):7-15.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot">gplot</a></code>, <code><a href="#topic+gplot.target">gplot.target</a></code>, <code><a href="#topic+gplot3d.layout">gplot3d.layout</a></code>, <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>, <code><a href="base.html#topic+eigen">eigen</a></code> </p>

<hr>
<h2 id='gplot.loop'> Add Loops to a Plot </h2><span id='topic+gplot.loop'></span>

<h3>Description</h3>

<p><code>gplot.loop</code> draws a &quot;loop&quot; at a specified location; this is used to designate self-ties in <code><a href="#topic+gplot">gplot</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot.loop(x0, y0, length = 0.1, angle = 10, width = 0.01, col = 1,
    border = 1, lty = 1, offset = 0, edge.steps = 10, radius = 1, 
    arrowhead = TRUE, xctr=0, yctr=0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot.loop_+3A_x0">x0</code></td>
<td>
<p> a vector of x coordinates for points of origin. </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_y0">y0</code></td>
<td>
<p> a vector of y coordinates for points of origin. </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_length">length</code></td>
<td>
<p> arrowhead length, in current plotting units. </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_angle">angle</code></td>
<td>
<p> arrowhead angle (in degrees). </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_width">width</code></td>
<td>
<p> width for loop body, in current plotting units (can be a vector). </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_col">col</code></td>
<td>
<p> loop body color (can be a vector). </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_border">border</code></td>
<td>
<p> loop border color (can be a vector). </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_lty">lty</code></td>
<td>
<p> loop border line type (can be a vector). </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_offset">offset</code></td>
<td>
<p> offset for origin point (can be a vector). </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_edge.steps">edge.steps</code></td>
<td>
<p> number of steps to use in approximating curves. </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_radius">radius</code></td>
<td>
<p> loop radius (can be a vector). </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_arrowhead">arrowhead</code></td>
<td>
<p> boolean; should arrowheads be used?  (Can be a vector.) </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_xctr">xctr</code></td>
<td>
<p> x coordinate for the central location away from which loops should be oriented. </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_yctr">yctr</code></td>
<td>
<p> y coordinate for the central location away from which loops should be oriented. </p>
</td></tr>
<tr><td><code id="gplot.loop_+3A_...">...</code></td>
<td>
<p> additional arguments to <code><a href="graphics.html#topic+polygon">polygon</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gplot.loop</code> is the companion to <code><a href="#topic+gplot.arrow">gplot.arrow</a></code>; like the latter, plot elements produced by <code>gplot.loop</code> are drawn using <code><a href="graphics.html#topic+polygon">polygon</a></code>, and as such are scaled based on the current plotting device.  By default, loops are drawn so as to encompass a circular region of radius <code>radius</code>, whose center is <code>offset</code> units from <code>x0,y0</code> and at maximum distance from <code>xctr,yctr</code>.  This is useful for functions like <code><a href="#topic+gplot">gplot</a></code>, which need to draw loops incident to vertices of varying radii.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot.arrow">gplot.arrow</a></code>, <code><a href="#topic+gplot">gplot</a></code>, <code><a href="graphics.html#topic+polygon">polygon</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Plot a few polygons with loops
plot(0,0,type="n",xlim=c(-2,2),ylim=c(-2,2),asp=1)
gplot.loop(c(0,0),c(1,-1),col=c(3,2),width=0.05,length=0.4,
  offset=sqrt(2)/4,angle=20,radius=0.5,edge.steps=50,arrowhead=TRUE)
polygon(c(0.25,-0.25,-0.25,0.25,NA,0.25,-0.25,-0.25,0.25), 
    c(1.25,1.25,0.75,0.75,NA,-1.25,-1.25,-0.75,-0.75),col=c(2,3))

</code></pre>

<hr>
<h2 id='gplot.target'> Display a Graph in Target Diagram Form </h2><span id='topic+gplot.target'></span><span id='topic+gplot_layout_target_R'></span>

<h3>Description</h3>

<p>Displays an input graph (and associated vector) as a &quot;target diagram,&quot; with vertices restricted to lie at fixed radii from the origin.  Such displays are useful ways of representing vertex characteristics and/or local structural properties for graphs of small to medium size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot.target(dat, x, circ.rad = (1:10)/10, circ.col = "blue", 
    circ.lwd = 1, circ.lty = 3, circ.lab = TRUE, circ.lab.cex = 0.75,
    circ.lab.theta = pi, circ.lab.col = 1, circ.lab.digits = 1,
    circ.lab.offset = 0.025, periph.outside = FALSE,
    periph.outside.offset = 1.2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot.target_+3A_dat">dat</code></td>
<td>
<p> an input graph. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_x">x</code></td>
<td>
<p> a vector of vertex properties to be plotted (must match the dimensions of <code>dat</code>). </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.rad">circ.rad</code></td>
<td>
<p> radii at which to draw reference circles. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.col">circ.col</code></td>
<td>
<p> reference circle color. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.lwd">circ.lwd</code></td>
<td>
<p> reference circle line width. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.lty">circ.lty</code></td>
<td>
<p> reference circle line type. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.lab">circ.lab</code></td>
<td>
<p> boolean; should circle labels be displayed? </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.lab.cex">circ.lab.cex</code></td>
<td>
<p> expansion factor for circle labels. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.lab.theta">circ.lab.theta</code></td>
<td>
<p> angle at which to draw circle labels. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.lab.col">circ.lab.col</code></td>
<td>
<p> color for circle labels. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.lab.digits">circ.lab.digits</code></td>
<td>
<p> digits to display for circle labels. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_circ.lab.offset">circ.lab.offset</code></td>
<td>
<p> offset for circle labels. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_periph.outside">periph.outside</code></td>
<td>
<p> boolean; should &quot;peripheral&quot; vertices be drawn together beyond the normal vertex radius? </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_periph.outside.offset">periph.outside.offset</code></td>
<td>
<p> radius at which &quot;peripheral&quot; vertices should be drawn if <code>periph.outside==TRUE</code>. </p>
</td></tr>
<tr><td><code id="gplot.target_+3A_...">...</code></td>
<td>
<p> additional arguments to <code><a href="#topic+gplot">gplot</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+gplot.target">gplot.target</a></code> is a front-end to <code><a href="#topic+gplot">gplot</a></code> which implements the target diagram layout of Brandes et al. (2003).  This layout seeks to optimize various aesthetic criteria, given the constraint that all vertices lie at fixed radii from the origin (set by <code>x</code>).  One important feature of this algorithm is that vertices which belong to mutual dyads (described by Brandes et al. as &ldquo;core&rdquo; vertices) are treated differently from vertices which do not (&ldquo;peripheral&rdquo; vertices).  Layout is optimized for core vertices prior to placing peripheral vertices; thus, the result may be misleading if mutuality is not a salient characteristic of the data.
</p>
<p>The layout for <code>gplot.target</code> is handled by <code><a href="#topic+gplot.layout.target">gplot.layout.target</a></code>; additional parameters are specied on the associated manual page.  Standard arguments may be passed to <code><a href="#topic+gplot">gplot</a></code>, as well.
</p>


<h3>Value</h3>

<p>A two-column matrix of vertex positions (generated by <code><a href="#topic+gplot.layout.target">gplot.layout.target</a></code>)
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>References</h3>

 
<p>Brandes, U.; Kenis, P.; and Wagner, D.  (2003).  &ldquo;Communicating Centrality in Policy Network Drawings.&rdquo; <em>IEEE Transactions on Visualization and Computer Graphics,</em> 9(2):241-253.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot.layout.target">gplot.layout.target</a></code>, <code><a href="#topic+gplot">gplot</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Generate a random graph
g&lt;-rgraph(15)

#Produce a target diagram, centering by betweenness
gplot.target(g,betweenness(g))
</code></pre>

<hr>
<h2 id='gplot.vertex'> Add Vertices to a Plot </h2><span id='topic+gplot.vertex'></span>

<h3>Description</h3>

<p><code>gplot.vertex</code> adds one or more vertices (drawn using <code><a href="graphics.html#topic+polygon">polygon</a></code>) to a plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot.vertex(x, y, radius = 1, sides = 4, border = 1, col = 2, 
    lty = NULL, rot = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot.vertex_+3A_x">x</code></td>
<td>
<p> a vector of x coordinates. </p>
</td></tr>
<tr><td><code id="gplot.vertex_+3A_y">y</code></td>
<td>
<p> a vector of y coordinates. </p>
</td></tr>
<tr><td><code id="gplot.vertex_+3A_radius">radius</code></td>
<td>
<p> a vector of vertex radii. </p>
</td></tr>
<tr><td><code id="gplot.vertex_+3A_sides">sides</code></td>
<td>
<p> a vector containing the number of sides to draw for each vertex. </p>
</td></tr>
<tr><td><code id="gplot.vertex_+3A_border">border</code></td>
<td>
<p> a vector of vertex border colors. </p>
</td></tr>
<tr><td><code id="gplot.vertex_+3A_col">col</code></td>
<td>
<p> a vector of vertex interior colors. </p>
</td></tr>
<tr><td><code id="gplot.vertex_+3A_lty">lty</code></td>
<td>
<p> a vector of vertex border line types. </p>
</td></tr>
<tr><td><code id="gplot.vertex_+3A_rot">rot</code></td>
<td>
<p> a vector of vertex rotation angles (in degrees). </p>
</td></tr>
<tr><td><code id="gplot.vertex_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code><a href="graphics.html#topic+polygon">polygon</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gplot.vertex</code> draws regular polygons of specified radius and number of sides, at the given coordinates.  This is useful for routines such as <code><a href="#topic+gplot">gplot</a></code>, which use such shapes to depict vertices.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot">gplot</a></code>, <code><a href="graphics.html#topic+polygon">polygon</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Open a plot window, and place some vertices
plot(0,0,type="n",xlim=c(-1.5,1.5),ylim=c(-1.5,1.5),asp=1)
gplot.vertex(cos((1:10)/10*2*pi),sin((1:10)/10*2*pi),col=1:10,
    sides=3:12,radius=0.1)

</code></pre>

<hr>
<h2 id='gplot3d'> Three-Dimensional Visualization of Graphs </h2><span id='topic+gplot3d'></span>

<h3>Description</h3>

<p><code>gplot3d</code> produces a three-dimensional plot of graph <code>g</code> in set <code>dat</code>.  A variety of options are available to control vertex placement, display details, color, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot3d(dat, g = 1, gmode = "digraph", diag = FALSE, 
    label = NULL, coord = NULL, jitter = TRUE, thresh = 0,
    mode = "fruchtermanreingold", displayisolates = TRUE, 
    displaylabels = !missing(label), xlab = NULL, ylab = NULL, 
    zlab = NULL, vertex.radius = NULL, absolute.radius = FALSE, 
    label.col = "gray50", edge.col = "black", vertex.col = NULL, 
    edge.alpha = 1, vertex.alpha = 1, edge.lwd = NULL, suppress.axes = TRUE,
    new = TRUE, bg.col = "white", layout.par = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot3d_+3A_dat">dat</code></td>
<td>
<p> a graph or set thereof.  This data may be valued. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph (from <code>dat</code>) which is to be displayed. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated. <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected;<code>"twomode"</code> indicates that data should be interpreted as two-mode (i.e., rows and columns are distinct vertex sets). </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_label">label</code></td>
<td>
<p> a vector of vertex labels; setting this to a zero-length string (e.g., <code>""</code>) omits </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_coord">coord</code></td>
<td>
<p> user-specified vertex coordinates, in an <code>NCOL(dat)</code>x3 matrix.  Where this is specified, it will override the <code>mode</code> setting. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_jitter">jitter</code></td>
<td>
<p> boolean; should vertex positions be jittered? </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_thresh">thresh</code></td>
<td>
<p> real number indicating the lower threshold for tie values.  Only ties of value &gt;<code>thresh</code> are displayed.  </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_mode">mode</code></td>
<td>
<p> the vertex placement algorithm; this must correspond to a <code>gplot3d.layout</code> function. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_displayisolates">displayisolates</code></td>
<td>
<p> boolean; should isolates be displayed? </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_displaylabels">displaylabels</code></td>
<td>
<p> boolean; should vertex labels be displayed? </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_xlab">xlab</code></td>
<td>
<p> X axis label. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_ylab">ylab</code></td>
<td>
<p> Y axis label. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_zlab">zlab</code></td>
<td>
<p> Z axis label. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_vertex.radius">vertex.radius</code></td>
<td>
<p> vertex radius, relative to the baseline (which is set based on layout features); may be given as a vector, if radii vary across vertices. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_absolute.radius">absolute.radius</code></td>
<td>
<p> vertex radius, specified in absolute terms; this may be given as a vector. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_label.col">label.col</code></td>
<td>
<p> color for vertex labels; may be given as a vector, if labels are to be of different colors. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_edge.col">edge.col</code></td>
<td>
<p> color for edges; may be given as a vector or adjacency matrix, if edges are to be of different colors. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_vertex.col">vertex.col</code></td>
<td>
<p> color for vertices; may be given as a vector, if vertices are to be of different colors.   By default, red is used (or red and blue, if <code>gmode=="twomode"</code>).</p>
</td></tr>
<tr><td><code id="gplot3d_+3A_edge.alpha">edge.alpha</code></td>
<td>
<p> alpha (transparency) values for edges; may be given as a vector or adjacency matrix, if edge transparency is to vary. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_vertex.alpha">vertex.alpha</code></td>
<td>
<p> alpha (transparency) values for vertices; may be given as a vector, if vertex transparency is to vary. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_edge.lwd">edge.lwd</code></td>
<td>
<p> line width scale for edges; if set greater than 0, edge widths are rescaled by <code>edge.lwd*dat</code>.  May be given as a vector or adjacency matrix, if edges are to have different line widths. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_suppress.axes">suppress.axes</code></td>
<td>
<p> boolean; suppress plotting of axes? </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_new">new</code></td>
<td>
<p> boolean; create a new plot?  If <code>new==FALSE</code>, the RGL device will not be cleared prior to adding vertices and edges. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_bg.col">bg.col</code></td>
<td>
<p> background color for display. </p>
</td></tr>
<tr><td><code id="gplot3d_+3A_layout.par">layout.par</code></td>
<td>
<p> list of parameters to the <code><a href="#topic+gplot.layout">gplot.layout</a></code> function specified in <code>mode</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gplot3d</code> is the three-dimensional companion to <code>gplot</code>.  As with the latter, clever manipulation of parameters can allow for a great deal of flexibility in the resulting display.  (Displays produced by <code>gplot3d</code> are also interactive, to the extent supported by <code><a href="rgl.html#topic+rgl-package">rgl</a></code>.)  If vertex positions are not specified directly using <code>coord</code>, vertex layout is determined via one of the various available algorithms.  These should be specified via the <code>mode</code> argument; see <code><a href="#topic+gplot3d.layout">gplot3d.layout</a></code> for a full list.  User-supplied layout functions are also possible - see the aforementioned man page for details.
</p>
<p>Note that where <code>gmode=="twomode"</code>, the supplied two-mode graph is converted to bipartite form prior to computing coordinates (assuming it is not in this form already).  It may be desirable to use parameters such as <code>vertex.col</code> to differentiate row and column vertices; by default, row vertices are colored red, and column vertices blue.
</p>


<h3>Value</h3>

<p>A three-column matrix containing vertex coordinates
</p>


<h3>Requires </h3>

<p><code><a href="rgl.html#topic+rgl-package">rgl</a></code></p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>References</h3>

 
<p>Wasserman, S. and Faust, K.  (1994)  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot">gplot</a></code>, <code><a href="#topic+gplot3d.layout">gplot3d.layout</a></code>, <code><a href="rgl.html#topic+rgl-package">rgl</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#A three-dimensional grid...
gplot3d(rgws(1,5,3,1,0))

#...rewired...
gplot3d(rgws(1,5,3,1,0.05))

#...some more!
gplot3d(rgws(1,5,3,1,0.2))

## End(Not run)
</code></pre>

<hr>
<h2 id='gplot3d.arrow'> Add Arrows a Three-Dimensional Plot </h2><span id='topic+gplot3d.arrow'></span>

<h3>Description</h3>

<p><code>gplot3d.arrow</code> draws an arrow between two pairs of points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot3d.arrow(a, b, radius, color = "white", alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot3d.arrow_+3A_a">a</code></td>
<td>
<p> a vector or three-column matrix containing origin X,Y,Z coordinates. </p>
</td></tr>
<tr><td><code id="gplot3d.arrow_+3A_b">b</code></td>
<td>
<p> a vector or three-column matrix containing origin X,Y,Z coordinates. </p>
</td></tr>
<tr><td><code id="gplot3d.arrow_+3A_radius">radius</code></td>
<td>
<p> the arrow radius, in current plotting units. May be a vector, if multiple arrows are to be drawn. </p>
</td></tr>
<tr><td><code id="gplot3d.arrow_+3A_color">color</code></td>
<td>
<p> the arrow color.  May be a vector, if multiple arrows are being drawn. </p>
</td></tr>
<tr><td><code id="gplot3d.arrow_+3A_alpha">alpha</code></td>
<td>
<p> alpha (transparency) value(s) for arrows.  (May be a vector.) </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gplot3d.arrow</code> draws one or more three-dimensional &ldquo;arrows&rdquo; from the points given in <code>a</code> to those given in <code>b</code>.  Note that the &ldquo;arrows&rdquo; are really cones, narrowing in the direction of the destination point.  
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot3d">gplot3d</a></code>, <code><a href="#topic+gplot3d.loop">gplot3d.loop</a></code> </p>

<hr>
<h2 id='gplot3d.layout'> Vertex Layout Functions for gplot3d </h2><span id='topic+gplot3d.layout'></span><span id='topic+gplot3d.layout.adj'></span><span id='topic+gplot3d.layout.eigen'></span><span id='topic+gplot3d.layout.fruchtermanreingold'></span><span id='topic+gplot3d.layout.geodist'></span><span id='topic+gplot3d.layout.hall'></span><span id='topic+gplot3d.layout.kamadakawai'></span><span id='topic+gplot3d.layout.mds'></span><span id='topic+gplot3d.layout.princoord'></span><span id='topic+gplot3d.layout.random'></span><span id='topic+gplot3d.layout.rmds'></span><span id='topic+gplot3d.layout.segeo'></span><span id='topic+gplot3d.layout.seham'></span><span id='topic+gplot3d_layout_fruchtermanreingold_R'></span><span id='topic+gplot3d_layout_kamadakawai_R'></span>

<h3>Description</h3>

<p>Various functions which generate vertex layouts for the <code><a href="#topic+gplot3d">gplot3d</a></code> visualization routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot3d.layout.adj(d, layout.par)
gplot3d.layout.eigen(d, layout.par)
gplot3d.layout.fruchtermanreingold(d, layout.par)
gplot3d.layout.geodist(d, layout.par)
gplot3d.layout.hall(d, layout.par)
gplot3d.layout.kamadakawai(d, layout.par)
gplot3d.layout.mds(d, layout.par)
gplot3d.layout.princoord(d, layout.par)
gplot3d.layout.random(d, layout.par)
gplot3d.layout.rmds(d, layout.par)
gplot3d.layout.segeo(d, layout.par)
gplot3d.layout.seham(d, layout.par)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot3d.layout_+3A_d">d</code></td>
<td>
<p> an adjacency matrix, as passed by <code><a href="#topic+gplot3d">gplot3d</a></code>. </p>
</td></tr>
<tr><td><code id="gplot3d.layout_+3A_layout.par">layout.par</code></td>
<td>
<p> a list of parameters. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Like <code><a href="#topic+gplot">gplot</a></code>, <code><a href="#topic+gplot3d">gplot3d</a></code> allows for the use of arbitrary vertex layout algorithms via the <code>gplot3d.layout.*</code> family of routines.  When called, <code><a href="#topic+gplot3d">gplot3d</a></code> searches for a <code>gplot3d.layout</code> function whose third name matches its <code>mode</code> argument (see <code><a href="#topic+gplot3d">gplot3d</a></code> help for more information); this function is then used to generate the layout for the resulting plot.  In addition to the routines documented here, users may add their own layout functions as needed.  The requirements for a <code>gplot3d.layout</code> function are as follows:
</p>

<ol>
<li><p> the first argument, <code>d</code>, must be the (dichotomous) graph adjacency matrix;
</p>
</li>
<li><p> the second argument, <code>layout.par</code>, must be a list of parameters (or <code>NULL</code>, if no parameters are specified); and
</p>
</li>
<li><p> the return value must be a real matrix of dimension <code>c(3,NROW(d))</code>, whose rows contain the vertex coordinates.
</p>
</li></ol>

<p>Other than this, anything goes.  (In particular, note that <code>layout.par</code> could be used to pass additional matrices, if needed.)  
</p>
<p>The <code>gplot3d.layout</code> functions currently supplied by default are as follows:
</p>

<dl>
<dt>eigen</dt><dd><p> This function places vertices based on the eigenstructure of the adjacency matrix.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$var</code></dt><dd><p> This argument controls the matrix to be used for the eigenanalysis.  <code>"symupper"</code>, <code>"symlower"</code>, <code>"symstrong"</code>, <code>"symweak"</code> invoke <code><a href="#topic+symmetrize">symmetrize</a></code> on <code>d</code> with the respective symmetrizing rule.  <code>"user"</code> indicates a user-supplied matrix (see below), while <code>"raw"</code> indicates that <code>d</code> should be used as-is.  (Defaults to <code>"raw"</code>.)</p>
</dd>
<dt><code>layout.par$evsel</code></dt><dd><p> If <code>"first"</code>, the first three eigenvectors are used; if <code>"size"</code>, the three eigenvectors whose eigenvalues have the largest magnitude are used instead. Note that only the real portion of the associated eigenvectors is used.  (Defaults to <code>"first"</code>.)</p>
</dd>
<dt><code>layout.par$mat</code></dt><dd><p>  If <code>layout.par$var=="user"</code>, this matrix is used for the eigenanalysis. (No default.)</p>
</dd>
</dl>

</dd>
<dt>fruchtermanreingold</dt><dd><p> This function generates a layout using a variant of Fruchterman and Reingold's force-directed placement algorithm.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$niter</code></dt><dd><p> This argument controls the number of iterations to be employed.  (Defaults to 300.) </p>
</dd>
<dt><code>layout.par$max.delta</code></dt><dd><p> Sets the maximum change in position for any given iteration.   (Defaults to <code>NROW(d)</code>.)</p>
</dd>
<dt><code>layout.par$volume</code></dt><dd><p>  Sets the &quot;volume&quot; parameter for the F-R algorithm. (Defaults to <code>NROW(d)^3</code>.)</p>
</dd>
<dt><code>layout.par$cool.exp</code></dt><dd><p>  Sets the cooling exponent for the annealer. (Defaults to 3.)</p>
</dd>
<dt><code>layout.par$repulse.rad</code></dt><dd><p>  Determines the radius at which vertex-vertex repulsion cancels out attraction of adjacent vertices.  (Defaults to <code>volume*NROW(d)</code>.)</p>
</dd>
<dt><code>layout.par$seed.coord</code></dt><dd><p> A three-column matrix of initial vertex coordinates.  (Defaults to a random spherical layout.) </p>
</dd>  
</dl>

</dd>
<dt>hall</dt><dd><p> This function places vertices based on the last three eigenvectors of the Laplacian of the input matrix (Hall's algorithm).  It takes no arguments.</p>
</dd>
<dt>kamadakawai</dt><dd><p> This function generates a vertex layout using a version of the Kamada-Kawai force-directed placement algorithm.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$niter</code></dt><dd><p> This argument controls the number of iterations to be employed.  (Defaults to 1000.) </p>
</dd>
<dt><code>layout.par$sigma</code></dt><dd><p> Sets the base standard deviation of position change proposals.   (Defaults to <code>NROW(d)/4</code>.)</p>
</dd>
<dt><code>layout.par$initemp</code></dt><dd><p>  Sets the initial &quot;temperature&quot; for the annealing algorithm. (Defaults to 10.)</p>
</dd>
<dt><code>layout.par$cool.exp</code></dt><dd><p>  Sets the cooling exponent for the annealer. (Defaults to 0.99.)</p>
</dd>
<dt><code>layout.par$kkconst</code></dt><dd><p>  Sets the Kamada-Kawai vertex attraction constant.  (Defaults to <code>NROW(d)^3</code>.)</p>
</dd>
<dt><code>layout.par$elen</code></dt><dd><p>  Provides the matrix of interpoint distances to be approximated.  (Defaults to the geodesic distances of <code>d</code> after symmetrizing, capped at <code>sqrt(NROW(d))</code>.)</p>
</dd>
<dt><code>layout.par$seed.coord</code></dt><dd><p> A three-column matrix of initial vertex coordinates.  (Defaults to a gaussian layout.) </p>
</dd>  
</dl>

</dd>
<dt>mds</dt><dd><p> This function places vertices based on a metric multidimensional scaling of a specified distance matrix.  It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$var</code></dt><dd><p> This argument controls the raw variable matrix to be used for the subsequent distance calculation and scaling.  <code>"rowcol"</code>, <code>"row"</code>, and <code>"col"</code> indicate that the rows and columns (concatenated), rows, or columns (respectively) of <code>d</code> should be used.  <code>"rcsum"</code> and <code>"rcdiff"</code> result in the sum or difference of <code>d</code> and its transpose being employed.  <code>"invadj"</code> indicates that <code>max{d}-d</code> should be used, while <code>"geodist"</code> uses <code><a href="#topic+geodist">geodist</a></code> to generate a matrix of geodesic distances from <code>d</code>. Alternately, an arbitrary matrix can be provided using <code>"user"</code>.  (Defaults to <code>"rowcol"</code>.)</p>
</dd>
<dt><code>layout.par$dist</code></dt><dd><p> The distance function to be calculated on the rows of the variable matrix.  This must be one of the <code>method</code> parameters to <code><a href="stats.html#topic+dist">dist</a></code> (<code>"euclidean"</code>, <code>"maximum"</code>, <code>"manhattan"</code>, or <code>"canberra"</code>), or else <code>"none"</code>.  In the latter case, no distance function is calculated, and the matrix in question must be square (with dimension <code>dim(d)</code>) for the routine to work properly.  (Defaults to <code>"euclidean"</code>.)</p>
</dd>
<dt><code>layout.par$exp</code></dt><dd><p> The power to which distances should be raised prior to scaling.  (Defaults to 2.)</p>
</dd>
<dt><code>layout.par$vm</code></dt><dd><p> If <code>layout.par$var=="user"</code>, this matrix is used for the distance calculation. (No default.)</p>
</dd>
</dl>

<p>Note: the following layout functions are based on <code>mds</code>:
</p>

<dl>
<dt>adj</dt><dd><p> scaling of the raw adjacency matrix, treated as similarities (using <code>"invadj"</code>).</p>
</dd>
<dt>geodist</dt><dd><p> scaling of the matrix of geodesic distances.</p>
</dd>
<dt>rmds</dt><dd><p> euclidean scaling of the rows of <code>d</code>.</p>
</dd>
<dt>segeo</dt><dd><p> scaling of the squared euclidean distances between row-wise geodesic distances (i.e., approximate structural equivalence).</p>
</dd>
<dt>seham</dt><dd><p> scaling of the Hamming distance between rows/columns of <code>d</code> (i.e., another approximate structural equivalence scaling).</p>
</dd>
</dl>

</dd>
<dt>princoord</dt><dd><p> This function places vertices based on the eigenstructure of a given correlation/covariance matrix. It takes the following arguments:
</p>

<dl>
<dt><code>layout.par$var</code></dt><dd><p> The matrix of variables to be used for the correlation/covariance calculation.  <code>"rowcol"</code>, <code>"col"</code>, and <code>"row"</code> indicate that the rows/cols, columns, or rows (respectively) of <code>d</code> should be employed.  <code>"rcsum"</code> <code>"rcdiff"</code> result in the sum or difference of <code>d</code> and <code>t(d)</code> being used.  <code>"user"</code> allows for an arbitrary variable matrix to be supplied.  (Defaults to <code>"rowcol"</code>.)</p>
</dd>
<dt><code>layout.par$cor</code></dt><dd><p> Should the correlation matrix (rather than the covariance matrix) be used?  (Defaults to <code>TRUE</code>.)</p>
</dd>
<dt><code>layout.par$vm</code></dt><dd><p> If <code>layout.par$var=="user"</code>, this matrix is used for the correlation/covariance calculation. (No default.)</p>
</dd>
</dl>

</dd>
<dt>random</dt><dd><p> This function places vertices randomly.  It takes the following argument:
</p>

<dl>
<dt><code>layout.par$dist</code></dt><dd><p> The distribution to be used for vertex placement.  Currently, the options are <code>"unif"</code> (for uniform distribution on the unit cube), <code>"uniang"</code> (for a &ldquo;gaussian sphere&rdquo; configuration), and <code>"normal"</code> (for a straight Gaussian distribution).  (Defaults to <code>"unif"</code>.)</p>
</dd>
</dl>

</dd>
</dl>



<h3>Value</h3>

<p>A matrix whose rows contain the x,y,z coordinates of the vertices of <code>d</code>.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Fruchterman, T.M.J. and Reingold, E.M.  (1991).  &ldquo;Graph Drawing by Force-directed Placement.&rdquo; <em>Software - Practice and Experience,</em> 21(11):1129-1164.
</p>
<p>Kamada, T. and Kawai, S.  (1989).  &ldquo;An Algorithm for Drawing General Undirected Graphs.&rdquo; <em>Information Processing Letters,</em> 31(1):7-15.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot3d">gplot3d</a></code>, <code><a href="#topic+gplot">gplot</a></code>, <code><a href="#topic+gplot.layout">gplot.layout</a></code>, <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>, <code><a href="base.html#topic+eigen">eigen</a></code> </p>

<hr>
<h2 id='gplot3d.loop'> Add Loops to a Three-Dimensional Plot </h2><span id='topic+gplot3d.loop'></span>

<h3>Description</h3>

<p><code>gplot3d.loop</code> draws a &quot;loop&quot; at a specified location; this is used to designate self-ties in <code><a href="#topic+gplot3d">gplot3d</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gplot3d.loop(a, radius, color = "white", alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gplot3d.loop_+3A_a">a</code></td>
<td>
<p> a vector or three-column matrix containing origin X,Y,Z coordinates. </p>
</td></tr>
<tr><td><code id="gplot3d.loop_+3A_radius">radius</code></td>
<td>
<p> the loop radius, in current plotting units. May be a vector, if multiple loops are to be drawn. </p>
</td></tr>
<tr><td><code id="gplot3d.loop_+3A_color">color</code></td>
<td>
<p> the loop color.  May be a vector, if multiple loops are being drawn. </p>
</td></tr>
<tr><td><code id="gplot3d.loop_+3A_alpha">alpha</code></td>
<td>
<p> alpha (transparency) value(s) for loops.  (May be a vector.) </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gplot3d.loop</code> is the companion to <code><a href="#topic+gplot3d.arrow">gplot3d.arrow</a></code>.  The &quot;loops&quot; produced by this routine currently look less like loops than like &quot;hats&quot; &ndash; they are noticable as spike-like structures which protrude from vertices.  Eventually, something more attractice will be produced by this routine.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gplot3d.arrow">gplot3d.arrow</a></code>, <code><a href="#topic+gplot3d">gplot3d</a></code>, <code><a href="rgl.html#topic+rgl-package">rgl-package</a></code> </p>

<hr>
<h2 id='graphcent'> Compute the (Harary) Graph Centrality Scores of Network Positions </h2><span id='topic+graphcent'></span>

<h3>Description</h3>

<p><code>graphcent</code> takes one or more graphs (<code>dat</code>) and returns the Harary graph centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  Depending on the specified mode, graph centrality on directed or undirected geodesics will be returned; this function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graphcent(dat, g=1, nodes=NULL, gmode="digraph", diag=FALSE, 
    tmaxdev=FALSE, cmode="directed", geodist.precomp=NULL, 
    rescale=FALSE, ignore.eval)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graphcent_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="graphcent_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g==1</code>. </p>
</td></tr>
<tr><td><code id="graphcent_+3A_nodes">nodes</code></td>
<td>
<p> list indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="graphcent_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>gmode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
<tr><td><code id="graphcent_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="graphcent_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev==FALSE</code>. </p>
</td></tr>
<tr><td><code id="graphcent_+3A_cmode">cmode</code></td>
<td>
<p> string indicating the type of graph centrality being computed (directed or undirected geodesics). </p>
</td></tr>
<tr><td><code id="graphcent_+3A_geodist.precomp">geodist.precomp</code></td>
<td>
<p> a <code><a href="#topic+geodist">geodist</a></code> object precomputed for the graph to be analyzed (optional) </p>
</td></tr>
<tr><td><code id="graphcent_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="graphcent_+3A_ignore.eval">ignore.eval</code></td>
<td>
<p> logical; should edge values be ignored when calculating geodesics?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Harary graph centrality of a vertex v is equal to <code class="reqn">\frac{1}{\max_u d(v,u)}</code>, where <code class="reqn">d(v,u)</code> is the geodesic distance from v to u.  Vertices with low graph centrality scores are likely to be near the &ldquo;edge&rdquo; of a graph, while those with high scores are likely to be near the &ldquo;middle.&rdquo;  Compare this with <code><a href="#topic+closeness">closeness</a></code>, which is based on the reciprocal of the sum of distances to all other vertices (rather than simply the maximum).
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the centrality scores (depending on the number and size of the input graphs).
</p>


<h3>Note</h3>

<p> Judicious use of <code>geodist.precomp</code> can save a great deal of time when computing multiple path-based indices on the same network. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Hage, P. and Harary, F.  (1995).  &ldquo;Eccentricity and Centrality in Networks.&rdquo;  <em>Social Networks</em>, 17:57-63. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+centralization">centralization</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(10)     #Draw a random graph with 10 members
graphcent(g)    #Compute centrality scores
</code></pre>

<hr>
<h2 id='grecip'> Compute the Reciprocity of an Input Graph or Graph Stack </h2><span id='topic+grecip'></span>

<h3>Description</h3>

<p><code>grecip</code> calculates the dyadic reciprocity of the elements of <code>dat</code> selected by <code>g</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grecip(dat, g = NULL, measure = c("dyadic", "dyadic.nonnull",
    "edgewise", "edgewise.lrr", "correlation"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grecip_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="grecip_+3A_g">g</code></td>
<td>
<p> a vector indicating which graphs to evaluate (optional). </p>
</td></tr>
<tr><td><code id="grecip_+3A_measure">measure</code></td>
<td>
<p> one of <code>"dyadic"</code> (default), <code>"dyadic.nonnull"</code>, <code>"edgewise"</code>, <code>"edgewise.lrr"</code>, or <code>"correlation"</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dyadic reciprocity of a graph is the proportion of dyads which are symmetric; this is computed and returned by <code>grecip</code> for the graphs indicated.  (<code>dyadic.nonnull</code> returns the ratio of mutuals to non-null dyads.)  Note that the dyadic reciprocity is distinct from the <em>edgewise</em> or <em>tie reciprocity</em>, which is the proportion of <em>edges</em> which are reciprocated.  This latter form may be obtained by setting <code>measure="edgewise"</code>.  Setting <code>measure="edgewise.lrr"</code> returns the log of the ratio of the edgewise reciprocity to the density; this is measure (called <code class="reqn">r_4</code> by Butts (2008)) can be interpreted as the relative log-odds of an edge given a reciprocation, versus the baseline probability of an edge.  Finally, <code>measure="correlation"</code> returns the correlation between within-dyad edge values, where this is defined by
</p>
<p style="text-align: center;"><code class="reqn">\frac{2\sum_{\{i,j\}} (Y_{ij}-\mu_G)(Y_{ji}-\mu_G)}{(2N_d-1) \sigma^2_G}</code>
</p>

<p>with <code class="reqn">Y</code> being the graph adjacency matrix, <code class="reqn">\mu_G</code> being the mean non-loop edge value, <code class="reqn">\sigma^2_G</code> being the variance of non-loop edge values, and <code class="reqn">N_d</code> being the number of dyads.  (Note that this quantity is unaffected by dyad orientation.)  The correlation measure may be interpreted as the net tendency for edges of similar relative value (with respect to the mean edge value) to occur within the same dyads.  For dichotomous data, adjacencies are interpreted as having values of 0 (no edge present) or 1 (edge present), but edge values are used where supplied.  In cases where all edge values are identical (e.g., the complete or empty graph), the correlation reciprocity is taken to be 1 by definition.
</p>
<p>Note that <code>grecip</code> calculates values based on non-missing data; dyads containing missing data are removed from consideration when calculating reciprocity scores (except for the correlation measure, which uses non-missing edges within missing dyads when calculating the graph mean and variance).
</p>


<h3>Value</h3>

<p>The graph reciprocity value(s)
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press. 
</p>
<p>Butts, C.T.  (2008).  &ldquo;Social Networks: A Methodological Introduction.&rdquo; <em>Asian Journal of Social Psychology,</em> 11(1), 13-41. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+mutuality">mutuality</a></code>, <code><a href="#topic+symmetrize">symmetrize</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Calculate the dyadic reciprocity scores for some random graphs
grecip(rgraph(10,5))
</code></pre>

<hr>
<h2 id='gscor'> Find the Structural Correlations Between Two or More Graphs </h2><span id='topic+gscor'></span>

<h3>Description</h3>

<p><code>gscor</code> finds the product-moment structural correlation between the adjacency matrices of graphs indicated by <code>g1</code> and <code>g2</code> in stack <code>dat</code> (or possibly <code>dat2</code>) given exchangeability list <code>exchange.list</code>.  Missing values are permitted. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gscor(dat, dat2=NULL, g1=NULL, g2=NULL,  diag=FALSE, 
    mode="digraph", method="anneal", reps=1000, prob.init=0.9,
    prob.decay=0.85, freeze.time=25, full.neighborhood=TRUE, 
    exchange.list=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gscor_+3A_dat">dat</code></td>
<td>
<p> a stack of input graphs. </p>
</td></tr>
<tr><td><code id="gscor_+3A_dat2">dat2</code></td>
<td>
<p> optionally, a second graph stack. </p>
</td></tr>
<tr><td><code id="gscor_+3A_g1">g1</code></td>
<td>
<p> the indices of <code>dat</code> reflecting the first set of graphs to be compared; by default, all members of <code>dat</code> are included. </p>
</td></tr>
<tr><td><code id="gscor_+3A_g2">g2</code></td>
<td>
<p> the indices or <code>dat</code> (or <code>dat2</code>, if applicable) reflecting the second set of graphs to be compared; by default, all members of <code>dat</code> are included. </p>
</td></tr>
<tr><td><code id="gscor_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="gscor_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>mode</code> is set to <code>"digraph"</code> by default. </p>
</td></tr>
<tr><td><code id="gscor_+3A_method">method</code></td>
<td>
<p> method to be used to search the space of accessible permutations; must be one of <code>"none"</code>, <code>"exhaustive"</code>, <code>"anneal"</code>, <code>"hillclimb"</code>, or <code>"mc"</code>.  </p>
</td></tr>
<tr><td><code id="gscor_+3A_reps">reps</code></td>
<td>
<p> number of iterations for Monte Carlo method. </p>
</td></tr>
<tr><td><code id="gscor_+3A_prob.init">prob.init</code></td>
<td>
<p> initial acceptance probability for the annealing routine. </p>
</td></tr>
<tr><td><code id="gscor_+3A_prob.decay">prob.decay</code></td>
<td>
<p> cooling multiplier for the annealing routine. </p>
</td></tr>
<tr><td><code id="gscor_+3A_freeze.time">freeze.time</code></td>
<td>
<p> freeze time for the annealing routine. </p>
</td></tr>
<tr><td><code id="gscor_+3A_full.neighborhood">full.neighborhood</code></td>
<td>
<p> should the annealer evaluate the full neighborhood of pair exchanges at each iteration? </p>
</td></tr>
<tr><td><code id="gscor_+3A_exchange.list">exchange.list</code></td>
<td>
<p> information on which vertices are exchangeable (see below); this must be a single number, a vector of length n, or a nx2 matrix. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structural correlation coefficient between two graphs G and H is defined as
</p>
<p style="text-align: center;"><code class="reqn">scor\left(G,H \left| L_G,L_H\right.\right) = \max_{L_G,L_H} cor(\ell(G),\ell(H))</code>
</p>

<p>where <code class="reqn">L_G</code> is the set of accessible permutations/labelings of G, <code class="reqn">\ell(G)</code> is a permutation/relabeling of G, and <code class="reqn">\ell(G) \in L_G</code>.  The set of accessible permutations on a given graph is determined by the <em>theoretical exchangeability</em> of its vertices; in a  nutshell, two vertices are considered to be theoretically exchangeable for a given problem if all predictions under the conditioning theory are invariant to a relabeling of the vertices in question (see Butts and Carley (2001) for a more formal exposition).  Where no vertices are exchangeable, the structural correlation becomes the simple graph correlation.  Where <em>all</em> vertices are exchangeable, the structural correlation reflects the correlation between unlabeled graphs; other cases correspond to correlation under partial labeling.  
</p>
<p>The accessible permutation set is determined by the <code>exchange.list</code> argument, which is dealt with in the following manner. First, <code>exchange.list</code> is expanded to fill an nx2 matrix.  If <code>exchange.list</code> is a single number, this is trivially accomplished by replication; if <code>exchange.list</code> is a vector of length n, the matrix is formed by cbinding two copies together.  If <code>exchange.list</code> is already an nx2 matrix, it is left as-is.  Once the nx2 exchangeability matrix has been formed, it is interpreted as follows: columns refer to graphs 1 and 2, respectively; rows refer to their corresponding vertices in the original adjacency matrices; and vertices are taken to be theoretically exchangeable iff their corresponding exchangeability matrix values are identical.  To obtain an unlabeled graph correlation (the default), then, one could simply let <code>exchange.list</code> equal any single number.  To obtain the standard graph correlation, one would use the vector <code>1:n</code>.
</p>
<p>Because the set of accessible permutations is, in general, very large (<code class="reqn">o(n!)</code>), searching the set for the maximum correlation is a non-trivial affair.  Currently supported methods for estimating the structural correlation are hill climbing, simulated annealing, blind monte carlo search, or exhaustive search (it is also possible to turn off searching entirely).  Exhaustive search is not recommended for graphs larger than size 8 or so, and even this may take days; still, this is a valid alternative for small graphs.  Blind monte carlo search and hill climbing tend to be suboptimal for this problem and are not, in general recommended, but they are available if desired.  The preferred (and default) option for permutation search is simulated annealing, which seems to work well on this problem (though some tinkering with the annealing parameters may be needed in order to get optimal performance).  See the help for <code><a href="#topic+lab.optimize">lab.optimize</a></code> for more information regarding these options.
</p>
<p>Structural correlation matrices are p.s.d., and are p.d. so long as no graph within the set is a linear combination of any other under any accessible permutation.  Their eigendecompositions are meaningful and they may be used in linear subspace analyses, so long as the researcher is careful to interpret the results in terms of the appropriate set of accessible labelings.  Classical null hypothesis tests should not be employed with structural correlations, and QAP tests are almost never appropriate (save in the uniquely labeled case).  See <code><a href="#topic+cugtest">cugtest</a></code> for a more reasonable alternative.
</p>


<h3>Value</h3>

<p>An estimate of the structural correlation matrix
</p>


<h3>Warning </h3>

<p>The search process can be <em>very slow</em>, particularly for large graphs.  In particular, the <em>exhaustive</em> method is order factorial, and will take approximately forever for unlabeled graphs of size greater than about 7-9.</p>


<h3>Note</h3>

<p> Consult Butts and Carley (2001) for advice and examples on theoretical exchangeability. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gscov">gscov</a></code>, <code><a href="#topic+gcor">gcor</a></code>, <code><a href="#topic+gcov">gcov</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate two random graphs
g.1&lt;-rgraph(5)
g.2&lt;-rgraph(5)

#Copy one of the graphs and permute it
perm&lt;-sample(1:5)
g.3&lt;-g.2[perm,perm]

#What are the structural correlations between the labeled graphs?
gscor(g.1,g.2,exchange.list=1:5)
gscor(g.1,g.3,exchange.list=1:5)
gscor(g.2,g.3,exchange.list=1:5)

#What are the structural correlations between the underlying 
#unlabeled graphs?
gscor(g.1,g.2)
gscor(g.1,g.3)
gscor(g.2,g.3)
</code></pre>

<hr>
<h2 id='gscov'> Find the Structural Covariance(s) Between Two or More Graphs </h2><span id='topic+gscov'></span>

<h3>Description</h3>

<p><code>gscov</code> finds the structural covariance between the adjacency matrices of graphs indicated by <code>g1</code> and <code>g2</code> in stack <code>dat</code> (or possibly <code>dat2</code>) given exchangeability list <code>exchange.list</code>.  Missing values are permitted. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gscov(dat, dat2=NULL, g1=NULL, g2=NULL, diag=FALSE, mode="digraph",
    method="anneal", reps=1000, prob.init=0.9, prob.decay=0.85,
    freeze.time=25, full.neighborhood=TRUE, exchange.list=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gscov_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="gscov_+3A_dat2">dat2</code></td>
<td>
<p> optionally, a second graph stack. </p>
</td></tr>
<tr><td><code id="gscov_+3A_g1">g1</code></td>
<td>
<p> the indices of <code>dat</code> reflecting the first set of graphs to be compared; by default, all members of <code>dat</code> are included. </p>
</td></tr>
<tr><td><code id="gscov_+3A_g2">g2</code></td>
<td>
<p> the indices or <code>dat</code> (or <code>dat2</code>, if applicable) reflecting the second set of graphs to be compared; by default, all members of <code>dat</code> are included. </p>
</td></tr>
<tr><td><code id="gscov_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="gscov_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>mode</code> is set to <code>"digraph"</code> by default.</p>
</td></tr>
<tr><td><code id="gscov_+3A_method">method</code></td>
<td>
<p> method to be used to search the space of accessible permutations; must be one of <code>"none"</code>, <code>"exhaustive"</code>, <code>"anneal"</code>, <code>"hillclimb"</code>, or <code>"mc"</code>. </p>
</td></tr>
<tr><td><code id="gscov_+3A_reps">reps</code></td>
<td>
<p> number of iterations for Monte Carlo method. </p>
</td></tr>
<tr><td><code id="gscov_+3A_prob.init">prob.init</code></td>
<td>
<p> initial acceptance probability for the annealing routine. </p>
</td></tr>
<tr><td><code id="gscov_+3A_prob.decay">prob.decay</code></td>
<td>
<p> cooling multiplier for the annealing routine. </p>
</td></tr>
<tr><td><code id="gscov_+3A_freeze.time">freeze.time</code></td>
<td>
<p> freeze time for the annealing routine. </p>
</td></tr>
<tr><td><code id="gscov_+3A_full.neighborhood">full.neighborhood</code></td>
<td>
<p> dhould the annealer evaluate the full neighborhood of pair exchanges at each iteration? </p>
</td></tr>
<tr><td><code id="gscov_+3A_exchange.list">exchange.list</code></td>
<td>
<p> information on which vertices are exchangeable (see below); this must be a single number, a vector of length n, or a nx2 matrix. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structural covariance between two graphs G and H is defined as
</p>
<p style="text-align: center;"><code class="reqn">scov\left(G,H \left| L_G,L_H\right.\right) = \max_{L_G,L_H} cov(\ell(G),\ell(H))</code>
</p>

<p>where <code class="reqn">L_G</code> is the set of accessible permutations/labelings of G, <code class="reqn">\ell(G)</code> is a permutation/labeling of G, and <code class="reqn">\ell(G) \in L_G</code>.  The set of accessible permutations on a given graph is determined by the <em>theoretical exchangeability</em> of its vertices; in a  nutshell, two vertices are considered to be theoretically exchangeable for a given problem if all predictions under the conditioning theory are invariant to a relabeling of the vertices in question (see Butts and Carley (2001) for a more formal exposition).  Where no vertices are exchangeable, the structural covariance becomes the simple graph covariance.  Where <em>all</em> vertices are exchangeable, the structural covariance reflects the covariance between unlabeled graphs; other cases correspond to covariance under partial labeling.  
</p>
<p>The accessible permutation set is determined by the <code>exchange.list</code> argument, which is dealt with in the following manner. First, <code>exchange.list</code> is expanded to fill an nx2 matrix.  If <code>exchange.list</code> is a single number, this is trivially accomplished by replication; if <code>exchange.list</code> is a vector of length n, the matrix is formed by cbinding two copies together.  If <code>exchange.list</code> is already an nx2 matrix, it is left as-is.  Once the nx2 exchangeabiliy matrix has been formed, it is interpreted as follows: columns refer to graphs 1 and 2, respectively; rows refer to their corresponding vertices in the original adjacency matrices; and vertices are taken to be theoretically exchangeable iff their corresponding exchangeability matrix values are identical.  To obtain an unlabeled graph covariance (the default), then, one could simply let <code>exchange.list</code> equal any single number.  To obtain the standard graph covariance, one would use the vector <code>1:n</code>.
</p>
<p>Because the set of accessible permutations is, in general, very large (<code class="reqn">o(n!)</code>), searching the set for the maximum covariance is a non-trivial affair.  Currently supported methods for estimating the structural covariance are hill climbing, simulated annealing, blind monte carlo search, or exhaustive search (it is also possible to turn off searching entirely).  Exhaustive search is not recommended for graphs larger than size 8 or so, and even this may take days; still, this is a valid alternative for small graphs.  Blind monte carlo search and hill climbing tend to be suboptimal for this problem and are not, in general recommended, but they are available if desired.  The preferred (and default) option for permutation search is simulated annealing, which seems to work well on this problem (though some tinkering with the annealing parameters may be needed in order to get optimal performance).  See the help for <code><a href="#topic+lab.optimize">lab.optimize</a></code> for more information regarding these options.
</p>
<p>Structural covariance matrices are p.s.d., and are p.d. so long as no graph within the set is a linear combination of any other under any accessible permutation.  Their eigendecompositions are meaningful and they may be used in linear subspace analyses, so long as the researcher is careful to interpret the results in terms of the appropriate set of accessible labelings.  Classical null hypothesis tests should not be employed with structural covariances, and QAP tests are almost never appropriate (save in the uniquely labeled case).  See <code><a href="#topic+cugtest">cugtest</a></code> for a more reasonable alternative.
</p>


<h3>Value</h3>

<p>An estimate of the structural covariance matrix
</p>


<h3>Warning </h3>

<p>The search process can be <em>very slow</em>, particularly for large graphs.  In particular, the <em>exhaustive</em> method is order factorial, and will take approximately forever for unlabeled graphs of size greater than about 7-9.</p>


<h3>Note</h3>

<p> Consult Butts and Carley (2001) for advice and examples on theoretical exchangeability. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gscor">gscor</a></code>, <code><a href="#topic+gcov">gcov</a></code>, <code><a href="#topic+gcor">gcor</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate two random graphs
g.1&lt;-rgraph(5)
g.2&lt;-rgraph(5)

#Copy one of the graphs and permute it
perm&lt;-sample(1:5)
g.3&lt;-g.2[perm,perm]

#What are the structural covariances between the labeled graphs?
gscov(g.1,g.2,exchange.list=1:5)
gscov(g.1,g.3,exchange.list=1:5)
gscov(g.2,g.3,exchange.list=1:5)

#What are the structural covariances between the underlying 
#unlabeled graphs?
gscov(g.1,g.2)
gscov(g.1,g.3)
gscov(g.2,g.3)
</code></pre>

<hr>
<h2 id='gt'>
Transpose an Input Graph
</h2><span id='topic+gt'></span>

<h3>Description</h3>

<p><code>gt</code> returns the graph transpose of its input.  For an adjacency matrix, this is the same as using <code><a href="base.html#topic+t">t</a></code>; however, this function is also applicable to sna edgelists (which cannot be transposed in the usual fashion).  Code written using <code>gt</code> instead of <code>t</code> is thus guaranteed to be safe for either form of input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gt(x, return.as.edgelist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gt_+3A_x">x</code></td>
<td>

<p>one or more graphs.
</p>
</td></tr>
<tr><td><code id="gt_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>

<p>logical; should the result be returned in sna edgelist form?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The transpose of a (di)graph, <code class="reqn">G=(V,E)</code>, is the graph <code class="reqn">G=(V,E')</code> where <code class="reqn">E'=\{(j,i): (i,j) \in E\}</code>.  This is simply the graph formed by reversing the sense of the edges.
</p>


<h3>Value</h3>

<p>The transposed graph(s).
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+symmetrize">symmetrize</a></code>, <code><a href="base.html#topic+t">t</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a graph....
g&lt;-rgraph(5)
g

#Transpose it
gt(g)
gt(g)==t(g)                  #For adjacency matrices, same as t(g)

#Now, see both versions in edgelist form
as.edgelist.sna(g)
gt(g,return.as.edgelist=TRUE)
</code></pre>

<hr>
<h2 id='gtrans'> Compute the Transitivity of an Input Graph or Graph Stack </h2><span id='topic+gtrans'></span><span id='topic+transitivity_R'></span>

<h3>Description</h3>

<p><code>gtrans</code> returns the transitivity of the elements of <code>dat</code> selected by <code>g</code>, using the definition of <code>measure</code>.  Triads involving missing values are omitted from the analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gtrans(dat, g=NULL, diag=FALSE, mode="digraph", measure = c("weak", 
    "strong", "weakcensus", "strongcensus", "rank", "correlation"), 
    use.adjacency = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gtrans_+3A_dat">dat</code></td>
<td>
<p> a collection of input graphs. </p>
</td></tr>
<tr><td><code id="gtrans_+3A_g">g</code></td>
<td>
<p> a vector indicating the graphs which are to be analyzed; by default, all graphs are analyzed. </p>
</td></tr>
<tr><td><code id="gtrans_+3A_diag">diag</code></td>
<td>
<p> a boolean indicating whether or not diagonal entries (loops) are to be taken as valid data. </p>
</td></tr>
<tr><td><code id="gtrans_+3A_mode">mode</code></td>
<td>
 <p><code>"digraph"</code> if directed triads are sought, or else <code>"graph"</code>. </p>
</td></tr>
<tr><td><code id="gtrans_+3A_measure">measure</code></td>
<td>
<p> one of <code>"weak"</code> (default), <code>"strong"</code>, <code>"weakcensus"</code>, <code>"strongcensus"</code>, <code>"rank"</code>, or <code>"correlation"</code>. </p>
</td></tr>
<tr><td><code id="gtrans_+3A_use.adjacency">use.adjacency</code></td>
<td>
<p> logical; should adjacency matrices (versus sparse graph methods) be used in the transitivity computation?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Transitivity is a triadic, algebraic structural constraint.  In its weak form, the transitive constraint corresponds to <code class="reqn">a \rightarrow b \rightarrow c \Rightarrow a \rightarrow c</code>.  In the corresponding strong form, the constraint is <code class="reqn">a \rightarrow b \rightarrow c \Leftrightarrow a \rightarrow c</code>.  (Note that the weak form is that most commonly employed.)  Where <code>measure=="weak"</code>, the fraction of potentially intransitive triads obeying the weak condition is returned.  With the <code>measure=="weakcensus"</code> setting, by contrast, the total <em>number</em> of transitive triads is computed.  The <code>strong</code> versions of the measures are similar to the above, save in that the set of all triads is considered (since all are &ldquo;at risk&rdquo; for intransitivity).  
</p>
<p>Note that where missing values prevent the assessment of whether a triple is transitive, that triple is omitted.
</p>
<p>Generalizations of transitivity to valued graphs are numerous.  The above strong and weak forms ignore edge values, treating any non-zero edge as present.  Two additional notions of transitivity are also supported valued data.  The <code>"rank"</code> condition treads an <code class="reqn">(i, j, k)</code> triple as transitive if the value of the <code class="reqn">(i,k)</code> directed dyad is greater than or equal to the minimum of the values of the <code class="reqn">(i,j)</code> and <code class="reqn">(j,k)</code> dyads.  The <code>"correlation"</code> option implements the correlation transitivity of David Dekker, which is defined as the matrix correlation of the valued adjacency matrix <code class="reqn">A</code> with its second power (i.e., <code class="reqn">A^2</code>), omitting diagonal entries where inapplicable.
</p>
<p>Note that the base forms of transitivity can be calculated using either matrix multiplication or sparse graph methods.  For very large, sparse graphs, the sparse graph method (which can be forced by <code>use.adjacency=FALSE</code>) may be preferred.  The latter provides much better scaling, but is significantly slower for networks of typical size due to the overhead involved (and R's highly optimized matrix operations).  Where <code>use.adjacency</code> is set to <code>TRUE</code>, <code>gtrans</code> will attempt some simple heuristics to determine if the edgelist method should be used instead (and will do so if indicated).  These heuristics depend on recognition of the input data type, and hence may behave slightly differently depending on the form in which <code>dat</code> is given.  Note that the rank measure can at present be calculated only via sparse graph methods, and the correlation measure only by adjacency matrices.  For these measures, the <code>use.adjacency</code> argument is ignored.
</p>


<h3>Value</h3>

<p>A vector of transitivity scores
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Holland, P.W., and Leinhardt, S.  (1972).  &ldquo;Some Evidence on the Transitivity of Positive Interpersonal Sentiment.&rdquo; <em>American Journal of Sociology,</em> 72, 1205-1209.
</p>
<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications</em>.  Cambridge: Cambridge University Press. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+triad.classify">triad.classify</a></code>, <code><a href="#topic+cugtest">cugtest</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw some random graphs
g&lt;-rgraph(5,10)

#Find transitivity scores
gtrans(g)
</code></pre>

<hr>
<h2 id='gvectorize'> Vectorization of Adjacency Matrices</h2><span id='topic+gvectorize'></span>

<h3>Description</h3>

<p><code>gvectorize</code> takes an input graph set and converts it into a corresponding number of vectors by row concatenation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gvectorize(mats, mode="digraph", diag=FALSE, censor.as.na=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gvectorize_+3A_mats">mats</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="gvectorize_+3A_mode">mode</code></td>
<td>
<p> &ldquo;digraph&rdquo; if data is taken to be directed, else &ldquo;graph&rdquo;. </p>
</td></tr>
<tr><td><code id="gvectorize_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether diagonal entries (loops) are taken to contain meaningful data. </p>
</td></tr>
<tr><td><code id="gvectorize_+3A_censor.as.na">censor.as.na</code></td>
<td>
<p> if <code>TRUE</code>, code unused parts of the adjacency matrix as <code>NA</code>s prior to vectorizing; otherwise, unused parts are simply removed. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output of <code>gvectorize</code> is a matrix in which each column corresponds to an input graph, and each row corresponds to an edge.  The columns of the output matrix are formed by simple row-concatenation of the original adjacency matrices, possibly after removing cells which are not meaningful (if <code>censor.as.na==FALSE</code>).  This is useful when preprocessing edge sets for use with <code>glm</code> or the like.
</p>


<h3>Value</h3>

<p>An nxk matrix, where n is the number of arcs and k is the number of graphs; if <code>censor.as.na==FALSE</code>, n will be reflect the relevant number of uncensored arcs.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw two random graphs
g&lt;-rgraph(10,2)

#Examine the vectorized form of the adjacency structure
gvectorize(g)
</code></pre>

<hr>
<h2 id='hdist'> Find the Hamming Distances Between Two or More Graphs </h2><span id='topic+hdist'></span>

<h3>Description</h3>

<p><code>hdist</code> returns the Hamming distance between the labeled graphs <code>g1</code> and <code>g2</code> in set <code>dat</code> for dichotomous data, or else the absolute (manhattan) distance.  If <code>normalize</code> is true, this distance is divided by its dichotomous theoretical maximum (conditional on |V(G)|).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdist(dat, dat2=NULL, g1=NULL, g2=NULL, normalize=FALSE, 
    diag=FALSE, mode="digraph")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hdist_+3A_dat">dat</code></td>
<td>
<p> a stack of input graphs. </p>
</td></tr>
<tr><td><code id="hdist_+3A_dat2">dat2</code></td>
<td>
<p> a second graph stack (optional). </p>
</td></tr>
<tr><td><code id="hdist_+3A_g1">g1</code></td>
<td>
<p> a vector indicating which graphs to compare (by default, all elements of <code>dat</code>). </p>
</td></tr>
<tr><td><code id="hdist_+3A_g2">g2</code></td>
<td>
<p> a vector indicating against which the graphs of <code>g1</code> should be compared (by default, all graphs). </p>
</td></tr>
<tr><td><code id="hdist_+3A_normalize">normalize</code></td>
<td>
<p> divide by the number of available dyads? </p>
</td></tr>
<tr><td><code id="hdist_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="hdist_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>mode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Hamming distance between two labeled graphs <code class="reqn">G_1</code> and <code class="reqn">G_2</code> is equal to <code class="reqn">|\{e : (e \in E(G_1), e \not\in E(G_2)) \wedge (e \not\in E(G_1), e \in E(G_2))\}|</code>.  In more prosaic terms, this may be thought of as the number of addition/deletion operations required to turn the edge set of <code class="reqn">G_1</code> into that of <code class="reqn">G_2</code>.  The Hamming distance is a highly general measure of structural similarity, and forms a metric on the space of graphs (simple or directed).  Users should be reminded, however, that the Hamming distance is extremely sensitive to nodal labeling, and should not be employed directly when nodes are interchangeable.  The structural distance (Butts and Carley (2001)), implemented in <code><a href="#topic+structdist">structdist</a></code>, provides a natural generalization of the Hamming distance to the more general case of unlabeled graphs.
</p>
<p>Null hypothesis testing for Hamming distances is available via <code><a href="#topic+cugtest">cugtest</a></code>, and <code><a href="#topic+qaptest">qaptest</a></code>; graphs which minimize the Hamming distances to all members of a graph set can be found by <code><a href="#topic+centralgraph">centralgraph</a></code>.  For an alternative means of comparing the similarity of graphs, consider <code><a href="#topic+gcor">gcor</a></code>.
</p>


<h3>Value</h3>

<p>A matrix of Hamming distances
</p>


<h3>Note</h3>

<p> For non-dichotomous data, the distance which is returned is simply the sum of the absolute edge-wise differences. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Banks, D., and Carley, K.M.  (1994).  &ldquo;Metric Inference for Social Networks.&rdquo;  <em>Journal of Classification</em>, 11(1), 121-49.
</p>
<p>Butts, C.T. and Carley, K.M.  (2005).  &ldquo;Some Simple Algorithms for Structural Comparison.&rdquo;  <em>Computational and Mathematical Organization Theory,</em> 11(4), 291-305.
</p>
<p>Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University. 
</p>
<p>Hamming, R.W. (1950). &ldquo;Error Detecting and Error Correcting Codes.&rdquo; <em>Bell System Technical Journal,</em> 29, 147-160.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+sdmat">sdmat</a></code>, <code><a href="#topic+structdist">structdist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Get some random graphs
g&lt;-rgraph(5,5,tprob=runif(5,0,1))

#Find the Hamming distances
hdist(g)
</code></pre>

<hr>
<h2 id='hierarchy'> Compute Graph Hierarchy Scores </h2><span id='topic+hierarchy'></span>

<h3>Description</h3>

<p><code>hierarchy</code> takes a graph set (<code>dat</code>) and returns reciprocity or Krackhardt hierarchy scores for the graphs selected by <code>g</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierarchy(dat, g=NULL, measure=c("reciprocity", "krackhardt"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hierarchy_+3A_dat">dat</code></td>
<td>
<p>a stack of input graphs. </p>
</td></tr>
<tr><td><code id="hierarchy_+3A_g">g</code></td>
<td>
<p> index values for the graphs to be utilized; by default, all graphs are selected. </p>
</td></tr>
<tr><td><code id="hierarchy_+3A_measure">measure</code></td>
<td>
<p> one of <code>"reciprocity"</code> or <code>"krackhardt"</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hierarchy measures quantify the extent of asymmetry in a structure; the greater the extent of asymmetry, the more hierarchical the structure is said to be.  (This should not be confused with how <em>centralized</em> the structure is, i.e., the extent to which centralities of vertex positions are highly concentrated.)  <code>hierarchy</code> provides two measures (selected by the <code>measure</code> argument) as follows:
</p>

<ol>
<li> <p><code>reciprocity</code>: This setting returns one minus the dyadic reciprocity for each input graph (see <code><a href="#topic+grecip">grecip</a></code>)
</p>
</li>
<li> <p><code>krackhardt</code>: This setting returns the Krackhardt hierarchy score for each input graph.  The Krackhardt hierarchy is defined as the fraction of non-null dyads in the <code><a href="#topic+reachability">reachability</a></code> graph which are asymmetric.  Thus, when no directed paths are reciprocated (e.g., in an in/outtree), Krackhardt hierarchy is equal to 1; when all such paths are reciprocated, by contrast (e.g., in a cycle or clique), the measure falls to 0. 
</p>
<p>Hierarchy is one of four measures (<code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+hierarchy">hierarchy</a></code>, and <code><a href="#topic+lubness">lubness</a></code>) suggested by Krackhardt for summarizing hierarchical structures.  Each corresponds to one of four axioms which are necessary and sufficient for the structure in question to be an outtree; thus, the measures will be equal to 1 for a given graph iff that graph is an outtree.  Deviations from unity can be interpreted in terms of failure to satisfy one or more of the outtree conditions, information which may be useful in classifying its structural properties.
</p>
</li></ol>

<p>Note that hierarchy is inherently density-constrained: as densities climb above 0.5, the proportion of mutual dyads must (by the pigeonhole principle) increase rapidly, thereby reducing possibilities for asymmetry.  Thus, the interpretation of hierarchy scores should take density into account, particularly if density is artifactual (e.g., due to a particular dichotomization procedure).  
</p>


<h3>Value</h3>

<p>A vector of hierarchy scores
</p>


<h3>Note</h3>

<p> The four Krackhardt indices are, in general, nondegenerate for a relatively narrow band of size/density combinations (efficiency being the sole exception).  This is primarily due to their dependence on the reachability graph, which tends to become complete rapidly as size/density increase.  See Krackhardt (1994) for a useful simulation study. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Krackhardt, David.  (1994).  &ldquo;Graph Theoretical Dimensions of Informal Organizations.&rdquo; In K. M. Carley and M. J. Prietula (Eds.), <em>Computational Organization Theory</em>, 89-111. Hillsdale, NJ: Lawrence Erlbaum and Associates. 
</p>
<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+hierarchy">hierarchy</a></code>, <code><a href="#topic+lubness">lubness</a></code>, <code><a href="#topic+grecip">grecip</a></code>, <code><a href="#topic+mutuality">mutuality</a></code>, <code><a href="#topic+dyad.census">dyad.census</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Get hierarchy scores for graphs of varying densities
hierarchy(rgraph(10,5,tprob=c(0.1,0.25,0.5,0.75,0.9)),
    measure="reciprocity")
hierarchy(rgraph(10,5,tprob=c(0.1,0.25,0.5,0.75,0.9)),
    measure="krackhardt")
</code></pre>

<hr>
<h2 id='infocent'> Find Information Centrality Scores of Network Positions </h2><span id='topic+infocent'></span>

<h3>Description</h3>

<p><code>infocent</code> takes one or more graphs (<code>dat</code>) and returns the information centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  This function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infocent(dat, g=1, nodes=NULL, gmode="digraph", diag=FALSE, 
    cmode="weak", tmaxdev=FALSE, rescale=FALSE,tol=1e-20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infocent_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="infocent_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g==1</code>. </p>
</td></tr>
<tr><td><code id="infocent_+3A_nodes">nodes</code></td>
<td>
<p> list indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="infocent_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  This is currently ignored. </p>
</td></tr>
<tr><td><code id="infocent_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="infocent_+3A_cmode">cmode</code></td>
<td>
<p> the rule to be used by <code><a href="#topic+symmetrize">symmetrize</a></code> when symmetrizing dichotomous data; must be one of <code>"weak"</code> (for an <code>OR</code> rule), <code>"strong"</code> for an <code>AND</code> rule), <code>"upper"</code> (for a <code>max</code> rule), or <code>"lower"</code> (for a <code>min</code> rule).  Set to <code>"weak"</code> by default, this parameter obviously has no effect on symmetric data. </p>
</td></tr>
<tr><td><code id="infocent_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev==FALSE</code>. </p>
</td></tr>
<tr><td><code id="infocent_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="infocent_+3A_tol">tol</code></td>
<td>
<p> tolerance for near-singularities during matrix inversion (see <code><a href="Matrix.html#topic+solve">solve</a></code>). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Actor information centrality is a hybrid measure which relates to both path-length indices (e.g., closeness, graph centrality) and to walk-based eigenmeasures (e.g., eigenvector centrality, Bonacich power).  In particular, the information centrality of a given actor can be understood to be the harmonic average of the &ldquo;bandwidth&rdquo; for all paths originating with said individual (where the bandwidth is taken to be inversely related to path length).  Formally, the index is constructed as follows.  First, we take <code class="reqn">G</code> to be an undirected (but possibly valued) graph &ndash; symmetrizing if necessary &ndash; with (possibly valued) adjacency matrix <code class="reqn">\mathbf{A}</code>.  From this, we remove all isolates (whose information centralities are zero in any event) and proceed to create the weighted connection matrix
</p>
<p style="text-align: center;"><code class="reqn">
\mathbf{C} = \mathbf{B}^{-1}</code>
</p>

<p>where <code class="reqn">\mathbf{B}</code> is a pseudo-adjacency matrix formed by replacing the diagonal of <code class="reqn">1-\mathbf{A}</code> with one plus each actor's degree.  Given the above, let <code class="reqn">T</code> be the trace of <code class="reqn">\mathbf{C}</code> with sum <code class="reqn">S_T</code>, and let <code class="reqn">S_R</code> be an arbitrary row sum (all rows of <code class="reqn">\mathbf{C}</code> have the same sum).  The information centrality scores are then equal to
</p>
<p style="text-align: center;"><code class="reqn">
C_I = \frac{1}{T + \frac{S_T-2S_R}{|V(G)|}}</code>
</p>

<p>(recalling that the scores for any omitted vertices are 0).
</p>
<p>In general, actors with higher information centrality are predicted to have greater control over the flow of information within a network; highly information-central individuals tend to have a large number of short paths to many others within the social structure.  Because the raw centrality values can be difficult to interpret directly, rescaled values are sometimes preferred (see the <code>rescale</code> option).  Though the use of path weights suggest information centrality as a possible replacement for closeness, the problem of inverting the <code class="reqn">\mathbf{B}</code> matrix poses problems of its own; as with all such measures, caution is advised on disconnected or degenerate structures. 
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the centrality scores (depending on the number and size of the input graphs).
</p>


<h3>Note</h3>

<p> The theoretical maximum deviation used here is not obtained with the star network; rather, the maximum occurs for an empty graph with one complete dyad, which is the model used here. </p>


<h3>Author(s)</h3>

<p> David Barron <a href="mailto:david.barron@jesus.ox.ac.uk">david.barron@jesus.ox.ac.uk</a>
</p>
<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Stephenson, K., and Zelen, M. (1989).  &ldquo;Rethinking Centrality: Methods and Applications.&rdquo;  <em>Social Networks</em>, 11, 1-37.
</p>
<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+evcent">evcent</a></code>, <code><a href="#topic+bonpow">bonpow</a></code>, <code><a href="#topic+closeness">closeness</a></code>, <code><a href="#topic+graphcent">graphcent</a></code>, <code><a href="#topic+centralization">centralization</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate some test data
dat&lt;-rgraph(10,mode="graph")
#Compute information centrality scores
infocent(dat)
</code></pre>

<hr>
<h2 id='interval.graph'> Convert Spell Data to Interval Graphs </h2><span id='topic+interval.graph'></span>

<h3>Description</h3>

<p>Constructs one or more interval graphs (and exchangeability vectors) from a set of spells.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interval.graph(slist, type="simple", diag=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interval.graph_+3A_slist">slist</code></td>
<td>
<p> A spell list.  This must consist of an nxmx3 array, with n being the number of actors, m being the maximum number of spells (one per row) and with the three columns of the last dimension containing a (categorical) spell type code, the time of spell onset (any units), and the time of spell termination (same units), respectively. </p>
</td></tr>
<tr><td><code id="interval.graph_+3A_type">type</code></td>
<td>
<p> One of &ldquo;simple&rdquo;, &ldquo;overlap&rdquo;, &ldquo;fracxy&rdquo;, &ldquo;fracyx&rdquo;, or &ldquo;jntfrac&rdquo;. </p>
</td></tr>
<tr><td><code id="interval.graph_+3A_diag">diag</code></td>
<td>
<p> Include the dyadic entries? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given some ordering dimension T (usually time), a &ldquo;spell&rdquo; is defined as the interval between a specified onset and a specified termination (with onset preceding the termination).  An interval graph, then, on spell set V, is <code class="reqn">G=\{V,E\}</code>, where <code class="reqn">\{i,j\} \in E</code> iff there exists some point <code class="reqn">t \in T</code> such that <code class="reqn">t \in i</code> and <code class="reqn">t \in j</code>.  In more prosaic terms, an interval graph on a given spell set has each spell as a vertex, with vertices adjacent iff they overlap.  Such structures are useful for quantifying life history data (where spells might represent marriages, periods of child custody/co-residence, periods of employment, etc.), organizational history data (where spells might reflect periods of strategic alliances, participation in a particular product market, etc.), task scheduling (with spells representing the dedication of a particular resource to a given task), etc.  By giving complex historical data a graphic representation, it is possible to easily perform a range of analyses which would otherwise be difficult and/or impossible (see Butts and Pixley (2004) for examples).
</p>
<p>In addition to the simple interval graph (described above), <code>interval.graph</code> can also generate valued interval graphs using a number of different edge definitions.  This is controlled by the <code>type</code> argument, with edge values as follows:
</p>

<ol>
<li><p> simple: dichotomous coding based on simple overlap (i.e., (x,y)=1 iff x overlaps y)
</p>
</li>
<li><p> overlap: edge value equals the total magnitude of the overlap between spells
</p>
</li>
<li><p> fracxy: the (x,y) edge value equals the fraction of the duration of y which is covered by x
</p>
</li>
<li><p> fracyx: the (x,y) edge value equals the fraction of the duration of x which is covered by y
</p>
</li>
<li><p> jntfrac: edge value equals the total magnitude of the overlap between spells divided by the mean of the spells' lengths
</p>
</li></ol>

<p>Note that &ldquo;simple,&rdquo; &ldquo;overlap,&rdquo; and &ldquo;jntfrac&rdquo; are symmetric relations, while &ldquo;fracxy&rdquo; and &ldquo;fracyx&rdquo; are directed.  As always, the specific edge type used should reflect the application to which the interval graph is being put.
</p>


<h3>Value</h3>

<p>A data frame containing:
</p>
<table>
<tr><td><code>graph</code></td>
<td>
<p>A graph stack containing the interval graphs</p>
</td></tr>
<tr><td><code>exchange.list</code></td>
<td>
<p>Matrix containing the vector of spell types associated with each interval graph</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>References</h3>

 
<p>Butts, C.T. and Pixley, J.E.  (2004).  &ldquo;A Structural Approach to the Representation of Life History Data.&rdquo;  <em>Journal of Mathematical Sociology</em>, 28(2), 81-124.
</p>
<p>West, D.B.  (1996).  <em>Introduction to Graph Theory</em>.  Upper Saddle River, NJ: Prentice Hall. </p>

<hr>
<h2 id='is.connected'> Is a Given Graph Connected? </h2><span id='topic+is.connected'></span>

<h3>Description</h3>

<p>Returns <code>TRUE</code> iff the specified graphs are connected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.connected(g, connected = "strong", comp.dist.precomp = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.connected_+3A_g">g</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="is.connected_+3A_connected">connected</code></td>
<td>
<p> definition of connectedness to use; must be one of <code>"strong"</code>, <code>"weak"</code>, <code>"unilateral"</code>, or <code>"recursive"</code>. </p>
</td></tr>
<tr><td><code id="is.connected_+3A_comp.dist.precomp">comp.dist.precomp</code></td>
<td>
<p> a <code><a href="#topic+component.dist">component.dist</a></code> object precomputed for the graph to be analyzed (optional). </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>is.connected</code> determines whether the elements of <code>g</code> are connected under the definition specified in <code>connected</code>.  (See <code><a href="#topic+component.dist">component.dist</a></code> for details.)  Since <code>is.connected</code> is really just a wrapper for <code><a href="#topic+component.dist">component.dist</a></code>, an object created with the latter can be supplied (via <code>comp.dist.precomp</code>) to speed computation.
</p>


<h3>Value</h3>

<p><code>TRUE</code> iff <code>g</code> is connected, otherwise <code>FALSE</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>West, D.B.  (1996).  <em>Introduction to Graph Theory.</em>  Upper Saddle River, N.J.: Prentice Hall.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+component.dist">component.dist</a></code>, <code><a href="#topic+components">components</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate two graphs:
g1&lt;-rgraph(10,tp=0.1)
g2&lt;-rgraph(10)

#Check for connectedness
is.connected(g1)  #Probably not
is.connected(g2)  #Probably so
</code></pre>

<hr>
<h2 id='is.isolate'> Is Ego an Isolate? </h2><span id='topic+is.isolate'></span>

<h3>Description</h3>

<p>Returns TRUE iff ego is an isolate in graph <code>g</code> of <code>dat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.isolate(dat, ego, g=1, diag=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.isolate_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="is.isolate_+3A_ego">ego</code></td>
<td>
<p> index of the vertex (or a vector of vertices) to check. </p>
</td></tr>
<tr><td><code id="is.isolate_+3A_g">g</code></td>
<td>
<p> which graph(s) should be examined? </p>
</td></tr>
<tr><td><code id="is.isolate_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether adjacency matrix diagonals (i.e., loops) contain meaningful data. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the valued case, any non-zero edge value is taken as sufficient to establish a tie.
</p>


<h3>Value</h3>

<p>A boolean value (or vector thereof) indicating isolate status
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.
</p>
<p>West, D.B.  (1996).  <em>Introduction to Graph Theory</em>.  Upper Saddle River, NJ: Prentice Hall. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+isolates">isolates</a></code>, <code><a href="#topic+add.isolates">add.isolates</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a test graph
g&lt;-rgraph(20)
g[,4]&lt;-0          #Create an isolate
g[4,]&lt;-0

#Check for isolates
is.isolate(g,2)  #2 is almost surely not an isolate
is.isolate(g,4)  #4 is, by construction
</code></pre>

<hr>
<h2 id='isolates'> List the Isolates in a Graph or Graph Stack </h2><span id='topic+isolates'></span>

<h3>Description</h3>

<p>Returns a list of the isolates in the graph or graph set given by <code>dat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isolates(dat, diag=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isolates_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="isolates_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether adjacency matrix diagonals (i.e., loops) contain meaningful data. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the isolates, or a list of vectors if more than one graph was specified
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.
</p>
<p>West, D.B.  (1996).  <em>Introduction to Graph Theory</em>.  Upper Saddle River, NJ: Prentice Hall.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+is.isolate">is.isolate</a></code>, <code><a href="#topic+add.isolates">add.isolates</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a test graph
g&lt;-rgraph(20)
g[,4]&lt;-0          #Create an isolate
g[4,]&lt;-0

#List the isolates
isolates(g)
</code></pre>

<hr>
<h2 id='kcores'>
Compute the k-Core Structure of a Graph
</h2><span id='topic+kcores'></span><span id='topic+kcores_R'></span>

<h3>Description</h3>

<p><code>kcores</code> calculates the k-core structure of the input network, using the centrality measure indicated in <code>cmode</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kcores(dat, mode = "digraph", diag = FALSE, cmode = "freeman",
    ignore.eval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kcores_+3A_dat">dat</code></td>
<td>

<p>one or more (possibly valued) graphs.
</p>
</td></tr>
<tr><td><code id="kcores_+3A_mode">mode</code></td>
<td>

<p><code>"digraph"</code> for directed data, otherwise <code>"graph"</code>.
</p>
</td></tr>
<tr><td><code id="kcores_+3A_diag">diag</code></td>
<td>

<p>logical; should self-ties be included in the degree calculations?
</p>
</td></tr>
<tr><td><code id="kcores_+3A_cmode">cmode</code></td>
<td>

<p>the <code><a href="#topic+degree">degree</a></code> centrality mode to use when constructing the cores.
</p>
</td></tr>
<tr><td><code id="kcores_+3A_ignore.eval">ignore.eval</code></td>
<td>

<p>logical; should edge values be ignored when computing degree?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">G=(V,E)</code> be a graph, and let <code class="reqn">f(v,S,G)</code> for <code class="reqn">v \in V, S\subseteq V</code> be a real-valued <em>vertex property function</em> (in the language of Batagelj and Zaversnik).  Then some set <code class="reqn">H \subseteq V</code> is a <em>generalized k-core</em> for <code class="reqn">f</code> if <code class="reqn">H</code> is a maximal set such that <code class="reqn">f(v,H,G)\ge k</code> for all <code class="reqn">v \in H</code>.  Typically, <code class="reqn">f</code> is chosen to be a degree measure with respect to <code class="reqn">S</code> (e.g., the number of ties to vertices in <code class="reqn">S</code>).  In this case, the resulting k-cores have the intuitive property of being maximal sets such that every set member is tied (in the appropriate manner) to at least k others within the set.
</p>
<p>Degree-based k-cores are a simple tool for identifying well-connected structures within large graphs.  Let the <em>core number</em> of vertex <code class="reqn">v</code> be the value of the highest-value core containing <code class="reqn">v</code>.  Then, intuitively, vertices with high core numbers belong to relatively well-connected sets (in the sense of sets with high minimum internal degree).  It is important to note that, while a given k-core need not be connected, it is composed of subsets which are themselves well-connected; thus, the k-cores can be thought of as unions of relatively cohesive subgroups.  As k-cores are nested, it is also natural to think of each k-core as representing a &ldquo;slice&rdquo; through a hypothetical &ldquo;cohesion surface&rdquo; on <code class="reqn">G</code>.  (Indeed, k-cores are often visualized in exactly this manner.)
</p>
<p>The <code>kcores</code> function produces degree-based k-cores, for various degree measures (with or without edge values).  The return value is the vector of core numbers for <code class="reqn">V</code>, based on the selected degree measure.  Missing (i.e., <code>NA</code>) edge are removed for purposes of the degree calculation.
</p>


<h3>Value</h3>

<p>A vector containing the maximum core membership for each vertex.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Batagelj, V. and Zaversnik, M.  (2002).  &ldquo;An <code class="reqn">O(m)</code> Algorithm for Cores Decomposition of Networks.&rdquo;  arXiv:cs/0310049v1
</p>
<p>Batagelj, V. and Zaversnik, M.  (2002).  &ldquo;Generalized Cores.&rdquo; 	arXiv:cs/0202039v1
</p>
<p>Wasserman, S. and Faust,K.  (1994).  <em>Social Network Analysis: Methods and Applications</em>.  Cambridge: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+degree">degree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a graph with core-periphery structure
cv&lt;-runif(30)
g&lt;-rgraph(30,tp=cv%o%cv)

#Compute the k-cores based on total degree
kc&lt;-kcores(g)
kc

#Plot the result
gplot(g,vertex.col=kc)
</code></pre>

<hr>
<h2 id='kpath.census'> Compute Path or Cycle Census Information </h2><span id='topic+kpath.census'></span><span id='topic+kcycle.census'></span><span id='topic+cycleCensus_R'></span><span id='topic+pathCensus_R'></span>

<h3>Description</h3>

<p><code>kpath.census</code> and <code>kcycle.census</code> compute <code class="reqn">k</code>-path or <code class="reqn">k</code>-cycle census statistics (respectively) on one or more input graphs.  In addition to aggregate counts of paths or cycles, results may be disaggregated by vertex and co-membership information may be computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kcycle.census(dat, maxlen = 3, mode = "digraph", 
    tabulate.by.vertex = TRUE, cycle.comembership = c("none", "sum",
    "bylength"))

kpath.census(dat, maxlen = 3, mode = "digraph", 
    tabulate.by.vertex = TRUE, path.comembership = c("none", "sum",
    "bylength"), dyadic.tabulation = c("none", "sum", "bylength"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kpath.census_+3A_cycle.comembership">cycle.comembership</code></td>
<td>
<p> the type of cycle co-membership information to be tabulated, if any.  <code>"sum"</code> returns a vertex by vertex matrix of cycle co-membership counts; these are disaggregated by cycle length if <code>"bylength"</code> is used.  If <code>"none"</code> is given, no co-membership information is computed.</p>
</td></tr>
<tr><td><code id="kpath.census_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="kpath.census_+3A_maxlen">maxlen</code></td>
<td>
<p> the maximum path/cycle length to evaluate. </p>
</td></tr>
<tr><td><code id="kpath.census_+3A_mode">mode</code></td>
<td>
 <p><code>"digraph"</code> for directed graphs, or <code>"graph"</code> for undirected graphs.</p>
</td></tr>
<tr><td><code id="kpath.census_+3A_tabulate.by.vertex">tabulate.by.vertex</code></td>
<td>
<p> logical; should path or cycle incidence counts be tabulated by vertex? </p>
</td></tr>
<tr><td><code id="kpath.census_+3A_path.comembership">path.comembership</code></td>
<td>
<p> as per <code>cycle.comembership</code>, for paths rather than cycles.  </p>
</td></tr>
<tr><td><code id="kpath.census_+3A_dyadic.tabulation">dyadic.tabulation</code></td>
<td>
<p> the type of dyadic path count information to be tabulated, if any.  <code>"sum"</code> returns a vertex by vertex matrix of source/destination path counts, while <code>"bylength"</code> disaggregates these counts by path length.  Selecting <code>"none"</code> disables this computation. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are several equivalent characterizations of paths and cycles, of which the following is one example.  For an arbitrary graph <code class="reqn">G</code>, a <em>path</em> is a sequence of distinct vertices <code class="reqn">v_1, v_2, \ldots, v_n</code> and included edges such that <code class="reqn">v_i</code> is adjacent to <code class="reqn">v_{i+1}</code> for all <code class="reqn">i \in 1, 2, \ldots, n-1</code> via the pair's included edge. (Contrast this with a <em>walk</em>, in which edges and/or vertices may be repeated.)  A <em>cycle</em> is the union of a path and an edge making <code class="reqn">v_n</code> adjacent to <code class="reqn">v_i</code>.  <code class="reqn">k</code>-paths and <code class="reqn">k</code>-cycles are respective paths and cycles having <code class="reqn">k</code> edges (in the former case) or <code class="reqn">k</code> vertices (in the latter).  The above definitions may be applied in both directed and undirected contexts, by substituting the appropriate notion of adjacency.  (Note that authors do not always employ the same terminology for these concepts, especially in older texts &ndash; it is wise to verify the definitions being used in any particular context.)
</p>
<p>A <em>subgraph census statistic</em> is a function which, for any given graph and subgraph, gives the number of copies of the latter contained in the former.  A collection of subgraph census statistics is referred to as a <em>subgraph census</em>; widely used examples include the dyad and triad censuses, implemented in <code>sna</code> by the <code><a href="#topic+dyad.census">dyad.census</a></code> and <code><a href="#topic+triad.census">triad.census</a></code> functions (respectively).  <code>kpath.census</code> and <code>kcycle.census</code> compute a range of census statistics related to <code class="reqn">k</code>-paths and <code class="reqn">k</code>-cycles, including:
</p>

<ul>
<li><p> Aggregate counts of paths/cycles by length (i.e., <code class="reqn">k</code>). 
</p>
</li>
<li><p> Counts of paths/cycles to which each vertex belongs (when <code>tabulate.byvertex==TRUE</code>). 
</p>
</li>
<li><p> Counts of path/cycle co-memberships, potentially disaggregated by length (when the appropriate co-membership argument is set to <code>bylength</code>). 
</p>
</li>
<li><p> For <code>path.census</code>, counts of the total number of paths from each vertex to each other vertex, possibly disaggregated by length (if <code>dyadic.tabulation=="bylength"</code>).
</p>
</li></ul>

<p>The length of the maximum-length path/cycle to compute is given by <code>maxlen</code>.  These calculations are intrinsically expensive (path/cycle computation is NP complete in the general case), and users should hence be wary when increasing <code>maxlen</code>.  On the other hand, it may be possible to enumerate even long paths or cycles on a very sparse graph; scaling is approximately <code class="reqn">c^k</code>, where <code class="reqn">k</code> is given by <code>maxlen</code> and <code class="reqn">c</code> is the size of the largest dense cluster.  
</p>
<p>The paths or cycles computed by this function are directed if <code>mode=="digraph"</code>, or undirected if <code>mode=="graph"</code>.  Failing to set <code>mode</code> correctly may result in problematic behavior.
</p>


<h3>Value</h3>

<p>For <code>kpath.census</code>, a list with the following elements:
</p>
<table>
<tr><td><code>path.count</code></td>
<td>
<p>If <code>tabulate.byvertex==FALSE</code>, a vector of aggregate counts by path length.  Otherwise, a matrix whose first column is a vector of aggregate path counts, and whose succeeding columns contain vectors of path counts for each vertex.</p>
</td></tr>
<tr><td><code>path.comemb</code></td>
<td>
<p>If <code>path.comembership!="none"</code>, a matrix or array containing co-membership in paths by vertex pairs.  If <code>path.comembership=="sum"</code>, only a matrix of co-memberships is returned; if <code>bylength</code> is used, however, co-memberships are returned in a <code>maxlen</code> by <code class="reqn">n</code> by <code class="reqn">n</code> array whose <code class="reqn">i,j,k</code>th cell is the number of paths of length <code class="reqn">i</code> containing <code>j</code> and <code>k</code>.</p>
</td></tr>
<tr><td><code>paths.bydyad</code></td>
<td>
<p>If <code>dyadic.tabulation!="none"</code>, a matrix or array containing the number of paths originating at a particular vertex and terminating.  If <code>bylength</code> is used, dyadic path counts are supplied via a <code>maxlen</code> by <code class="reqn">n</code> by <code class="reqn">n</code> array whose <code class="reqn">i,j,k</code>th cell is the number of paths of length <code class="reqn">i</code> starting at <code>j</code> and ending with <code>k</code>.  If <code>sum</code> is used instead, only a matrix whose <code class="reqn">i,j</code> cell contains the total number of paths from <code class="reqn">i</code> to <code class="reqn">j</code> is returned.</p>
</td></tr>
</table>
<p>For <code>kcycle.census</code>, a similar list:
</p>
<table>
<tr><td><code>cycle.count</code></td>
<td>
<p>If <code>tabulate.byvertex==FALSE</code>, a vector of aggregate counts by cycle length.  Otherwise, a matrix whose first column is a vector of aggregate cycle counts, and whose succeeding columns contain vectors of cycle counts for each vertex.</p>
</td></tr>
<tr><td><code>cycle.comemb</code></td>
<td>
<p>If <code>cycle.comembership!="none"</code>, a matrix or array containing co-membership in cycles by vertex pairs.  If <code>cycle.comembership=="sum"</code>, only a matrix of co-memberships is returned; if <code>bylength</code> is used, however, co-memberships are returned in a <code>maxlen</code> by <code class="reqn">n</code> by <code class="reqn">n</code> array whose <code class="reqn">i,j,k</code>th cell is the number of cycles of length <code class="reqn">i</code> containing <code>j</code> and <code>k</code>.</p>
</td></tr>
</table>


<h3>Warning </h3>

<p> The computational cost of calculating paths and cycles grows very sharply in both <code>maxlen</code> and network density.  Be wary of setting <code>maxlen</code> greater than 5-6, unless you know what you are doing.  Otherwise, the expected completion time for your calculation may exceed your life expectancy (and those of subsequent generations). </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Butts, C.T.  (2006).  &ldquo;Cycle Census Statistics for Exponential Random Graph Models.&rdquo;  IMBS Technical Report MBS 06-05, University of California, Irvine.
</p>
<p>West, D.B.  (1996).  <em>Introduction to Graph Theory.</em>  Upper Saddle River, N.J.: Prentice Hall.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+dyad.census">dyad.census</a></code>, <code><a href="#topic+triad.census">triad.census</a></code>, <code><a href="#topic+clique.census">clique.census</a></code>, <code><a href="#topic+geodist">geodist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(20,tp=1.5/19)

#Obtain paths by vertex, with dyadic path counts
pc&lt;-kpath.census(g,maxlen=5,dyadic.tabulation="sum")
pc$path.count                                 #Examine path counts
pc$paths.bydyad                               #Examine dyadic paths

#Obtain aggregate cycle counts, with co-membership by length
cc&lt;-kcycle.census(g,maxlen=5,tabulate.by.vertex=FALSE,
    cycle.comembership="bylength")
cc$cycle.count                             #Examine cycle counts
cc$cycle.comemb[1,,]                       #Co-membership for 2-cycles
cc$cycle.comemb[2,,]                       #Co-membership for 3-cycles
cc$cycle.comemb[3,,]                       #Co-membership for 4-cycles
</code></pre>

<hr>
<h2 id='lab.optimize'> Optimize a Bivariate Graph Statistic Across a Set of Accessible Permutations</h2><span id='topic+lab.optimize'></span><span id='topic+lab.optimize.anneal'></span><span id='topic+lab.optimize.exhaustive'></span><span id='topic+lab.optimize.gumbel'></span><span id='topic+lab.optimize.hillclimb'></span><span id='topic+lab.optimize.mc'></span>

<h3>Description</h3>

<p><code>lab.optimize</code> is the front-end to a series of heuristic optimization routines (see below), all of which seek to maximize/minimize some bivariate graph statistic (e.g., graph correlation) across a set of vertex relabelings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lab.optimize(d1, d2, FUN, exchange.list=0, seek="min", 
    opt.method=c("anneal", "exhaustive", "mc", "hillclimb", 
    "gumbel"), ...)
lab.optimize.anneal(d1, d2, FUN, exchange.list=0, seek="min", 
    prob.init=1, prob.decay=0.99, freeze.time=1000, 
    full.neighborhood=TRUE, ...)
lab.optimize.exhaustive(d1, d2, FUN, exchange.list=0, seek="min", ...)
lab.optimize.gumbel(d1, d2, FUN, exchange.list=0, seek="min", 
    draws=500, tol=1e-5, estimator="median", ...)
lab.optimize.hillclimb(d1, d2, FUN, exchange.list=0, seek="min", ...)
lab.optimize.mc(d1, d2, FUN, exchange.list=0, seek="min", 
    draws=1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lab.optimize_+3A_d1">d1</code></td>
<td>
<p> a single graph. </p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_d2">d2</code></td>
<td>
<p> another single graph. </p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_fun">FUN</code></td>
<td>
<p> a function taking two graphs as its first two arguments, and returning a numeric value. </p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_exchange.list">exchange.list</code></td>
<td>
<p> information on which vertices are exchangeable (see below); this must be a single number, a vector of length n, or a nx2 matrix. </p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_seek">seek</code></td>
<td>
<p> &quot;min&quot; if the optimizer should seek a minimum, or &quot;max&quot; if a maximum should be sought. </p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_opt.method">opt.method</code></td>
<td>
<p> the particular optimization method to use. </p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_prob.init">prob.init</code></td>
<td>
<p>initial acceptance probability for a downhill move (<code>lab.optimize.anneal</code> only).</p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_prob.decay">prob.decay</code></td>
<td>
<p>the decay (cooling) multiplier for the probability of accepting a downhill move (<code>lab.optimize.anneal</code> only).</p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_freeze.time">freeze.time</code></td>
<td>
<p>number of iterations at which the annealer should be frozen (<code>lab.optimize.anneal</code> only).</p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_full.neighborhood">full.neighborhood</code></td>
<td>
<p>should all moves in the binary-exchange neighborhood be evaluated at each iteration? (<code>lab.optimize.anneal</code> only).</p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_tol">tol</code></td>
<td>
<p>tolerance for estimation of gumbel distribution parameters (<code>lab.optimize.gumbel</code> only).</p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_estimator">estimator</code></td>
<td>
<p>Gumbel distribution statistic to use as optimal value prediction; must be one of &ldquo;mean&rdquo;, &ldquo;median&rdquo;, or &ldquo;mode&rdquo; (<code>lab.optimize.gumbel</code> only).</p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_draws">draws</code></td>
<td>
<p>number of draws to take for gumbel and mc methods. </p>
</td></tr>
<tr><td><code id="lab.optimize_+3A_...">...</code></td>
<td>
<p> additional arguments to <code>FUN</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lab.optimize</code> is the front-end to a family of routines for optimizing a bivariate graph statistic over a set of permissible relabelings (or equivalently, permutations).  The accessible permutation set is determined by the <code>exchange.list</code> argument, which is dealt with in the following manner. First, <code>exchange.list</code> is expanded to fill an nx2 matrix.  If <code>exchange.list</code> is a single number, this is trivially accomplished by replication; if <code>exchange.list</code> is a vector of length n, the matrix is formed by cbinding two copies together.  If <code>exchange.list</code> is already an nx2 matrix, it is left as-is.  Once the nx2 exchangeabiliy matrix has been formed, it is interpreted as follows: columns refer to graphs 1 and 2, respectively; rows refer to their corresponding vertices in the original adjacency matrices; and vertices are taken to be theoretically exchangeable iff their corresponding exchangeability matrix values are identical.  To obtain an unlabeled graph statistic (the default), then, one could simply let <code>exchange.list</code> equal any single number.  To obtain the labeled statistic, one would use the vector <code>1:n</code>.
</p>
<p>Assuming a non-degenerate set of accessible permutations/relabelings, optimization proceeds via the algorithm specified in <code>opt.method</code>. The optimization routines which are currently implemented use a variety of different techniques, each with certain advantages and disadvantages.  A brief summary of each is as follows:
</p>

<ol>
<li><p> exhaustive search (&ldquo;exhaustive&rdquo;): Under exhaustive search, the entire space of accessible permutations is combed for the global optimum.  This guarantees a correct answer, but at a very high price: the set of all permutations grows with the factorial of the number of vertices, and even substantial exchangeability constraints are unlikely to keep the number of permutations from growing out of control.  While exhaustive search <em>is</em> possible for small graphs, unlabeled structures of size approximately 10 or greater cannot be treated using this algorithm within a reasonable time frame.  
</p>
<p>Approximate complexity: on the order of <code class="reqn">\prod_{i \in L}|V_i|!</code>, where L is the set of exchangeability classes.
</p>
</li>
<li><p> hill climbing (&ldquo;hillclimb&rdquo;): The hill climbing algorithm employed here searches, at each iteration, the set of all permissible binary exchanges of vertices.  If one or more exchanges are found which are superior to the current permutation, the best alternative is taken.  If no superior alternative is found, then the algorithm terminates.  As one would expect, this algorithm is guaranteed to terminate on a local optimum; unfortunately, however, it is quite prone to becoming &ldquo;stuck&rdquo; in suboptimal solutions.  In general, hill climbing is not recommended for permutation search, but the method may prove useful in certain circumstances.  
</p>
<p>Approximate complexity: on the order of <code class="reqn">|V(G)|^2</code> per iteration, total complexity dependent on the number of iterations.
</p>
</li>
<li><p> simulated annealing (&ldquo;anneal&rdquo;): The (fairly simple) annealing procedure here employed proceeds as follows.  At each iteration, the set of all permissible binary exchanges (if <code>full.neighborhood==TRUE</code>) or a random selection from this set is evaluated.  If a superior option is identified, the best of these is chosen.  If no superior options are found, then the algorithm chooses randomly from the set of alternatives with probability equal to the current temperature, otherwise retaining its prior solution.  After each iteration, the current temperature is reduced by a factor equal to <code>prob.decay</code>; the initial temperature is set by <code>prob.init</code>.  When a number of iterations equal to <code>freeze.time</code> have been completed, the algorithm &ldquo;freezes.&rdquo;  Once &ldquo;frozen,&rdquo; the annealer hillclimbs from its present location until no improvement is found, and terminates.  At termination, the best permutation identified so far is utilized; this need not be the most recent position (though it sometimes is).  
</p>
<p>Simulated annealing is sometimes called &ldquo;noisy hill climbing&rdquo; because it uses the introduction of random variation to a hill climbing routine to avoid convergence to local optima; it works well on reasonably correlated search spaces with well-defined solution neighborhoods, and is far more robust than hill climbing algorithms.  As a general rule, simulated annealing is recommended here for most graphs up to size approximately 50.  At this point, computational complexity begins to become a serious barrier, and alternative methods may be more practical.  
</p>
<p>Approximate complexity: on the order of <code class="reqn">|V(G)|^2</code>*<code>freeze.time</code> if <code>full.neighborhood==TRUE</code>, otherwise complexity scales approximately linearly with <code>freeze.time</code>.  This can be misleading, however, since failing to search the full neighborhood generally requires that <code>freeze.time</code> be greatly increased.)
</p>
</li>
<li><p> blind monte carlo search (&ldquo;mc&rdquo;): Blind monte carlo search, as the name implies, consists of randomly drawing a sample of permutations from the accessible permutation set and selecting the best.  Although this not such a bad option when A) a large fraction of points are optimal or nearly optimal and B) the search space is largely uncorrelated, these conditions do not seem to characterize most permutation search problems.  Blind monte carlo search is not generally recommended, but it is provided as an option should it be desired (e.g., when it is absolutely necessary to control the number of permutations examined).  
</p>
<p>Approximate complexity: linear in <code>draws</code>.
</p>
</li>
<li><p> extreme value estimation (&ldquo;gumbel&rdquo;): Extreme value estimation attempts to estimate a global optimum via stochastic modeling of the distribution of the graph statistic over the space of accessible permutations.  The algorithm currently proceeds as follows.  First, a random sample is taken from the accessible permutation set (as with monte carlo search, above).  Next, this sample is used to fit an extreme value (gumbel) model; the gumbel distribution is the limiting distribution of the extreme values from samples under a continuous, unbounded distribution, and we use it here as an approximation.  Having fit the model, an associated statistic (the mean, median, or mode as determined by <code>estimator</code>) is then used as an estimator of the global optimum.
</p>
<p>Obviously, this approach has certain drawbacks.  First of all, our use of the gumbel model in particular assumes an unbounded, continuous underlying distribution, which may or may not be approximately true for any given problem.  Secondly, the inherent non-robustness of extremal problems makes the fact that our prediction rests on a string of approximations rather worrisome: our idea of the shape of the underlying distribution could be distorted by a bad sample, our parameter estimation could be somewhat off, etc., any of which could have serious consequences for our extremal prediction.  Finally, the prediction which is made by the extreme value model is <em>nonconstructive</em>, in the sense that <em>no permutation need have been found by the algorithm which induces the predicted value</em>.  On the bright side, this <em>could</em> allow one to estimate the optimum without having to find it directly; on the dark side, this means that the reported optimum could be a numerical chimera.
</p>
<p>At this time, extreme value estimation should be considered <em>experimental</em>, and <em>is not recommended for use on substantive problems.</em>  <code>lab.optimize.gumbel</code> is not guaranteed to work properly, or to produce intelligible results; this may eventually change in future revisions, or the routine may be scrapped altogether.
</p>
<p>Approximate complexity: linear in <code>draws</code>.
</p>
</li></ol>

<p>This list of algorithms is itself somewhat unstable: some additional techniques (canonical labeling and genetic algorithms, for instance) may be added, and some existing methods (e.g., extreme value estimation) may be modified or removed.  Every attempt will be made to keep the command format as stable as possible for other routines (e.g., <code><a href="#topic+gscov">gscov</a></code>, <code><a href="#topic+structdist">structdist</a></code>) which depend on <code>lab.optimize</code> to do their heavy-lifting.  In general, it is not expected that the end-user will call <code>lab.optimize</code> directly; instead, most end-user interaction with these routines will be via the structural distance/covariance functions which used them.
</p>


<h3>Value</h3>

<p>The estimated global optimum of <code>FUN</code> over the set of relabelings permitted by <code>exchange.list</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>  </p>


<h3>References</h3>

 
<p>Butts, C.T. and Carley, K.M.  (2005).  &ldquo;Some Simple Algorithms for Structural Comparison.&rdquo;  <em>Computational and Mathematical Organization Theory,</em> 11(4), 291-305.
</p>
<p>Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gscov">gscov</a></code>, <code><a href="#topic+gscor">gscor</a></code>, <code><a href="#topic+structdist">structdist</a></code>, <code><a href="#topic+sdmat">sdmat</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a random graph and copy it
g&lt;-rgraph(10)
g2&lt;-rmperm(g)  #Permute the copy randomly

#Seek the maximum correlation
lab.optimize(g,g2,gcor,seek="max",opt.method="anneal",freeze.time=50,
    prob.decay=0.9)

#These two don't do so well...
lab.optimize(g,g2,gcor,seek="max",opt.method="hillclimb")     
lab.optimize(g,g2,gcor,seek="max",opt.method="mc",draws=1000)

</code></pre>

<hr>
<h2 id='lnam'> Fit a Linear Network Autocorrelation Model </h2><span id='topic+lnam'></span><span id='topic+coef.lnam'></span><span id='topic+se.lnam'></span>

<h3>Description</h3>

<p><code>lnam</code> is used to fit linear network autocorrelation models.  These include standard OLS as a special case, although <code><a href="stats.html#topic+lm">lm</a></code> is to be preferred for such analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lnam(y, x = NULL, W1 = NULL, W2 = NULL, theta.seed = NULL, 
    null.model = c("meanstd", "mean", "std", "none"), method = "BFGS", 
    control = list(), tol=1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lnam_+3A_y">y</code></td>
<td>
<p> a vector of responses. </p>
</td></tr>
<tr><td><code id="lnam_+3A_x">x</code></td>
<td>
<p> a vector or matrix of covariates; if the latter, each column should contain a single covariate. </p>
</td></tr>
<tr><td><code id="lnam_+3A_w1">W1</code></td>
<td>
<p> one or more (possibly valued) graphs on the elements of <code>y</code>. </p>
</td></tr>
<tr><td><code id="lnam_+3A_w2">W2</code></td>
<td>
<p> one or more (possibly valued) graphs on the elements of <code>y</code>. </p>
</td></tr>
<tr><td><code id="lnam_+3A_theta.seed">theta.seed</code></td>
<td>
<p> an optional seed value for the parameter vector estimation process. </p>
</td></tr>
<tr><td><code id="lnam_+3A_null.model">null.model</code></td>
<td>
<p> the null model to be fit; must be one of <code>"meanstd"</code>, <code>"mean"</code>, <code>"std"</code>, or <code>"none"</code>. </p>
</td></tr>
<tr><td><code id="lnam_+3A_method">method</code></td>
<td>
<p> method to be used with <code><a href="stats.html#topic+optim">optim</a></code>. </p>
</td></tr>
<tr><td><code id="lnam_+3A_control">control</code></td>
<td>
<p> optional control parameters for <code><a href="stats.html#topic+optim">optim</a></code>. </p>
</td></tr>
<tr><td><code id="lnam_+3A_tol">tol</code></td>
<td>
<p> convergence tolerance for the MLE (expressed as change in deviance).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lnam</code> fits the linear network autocorrelation model given by
</p>
<p style="text-align: center;"><code class="reqn">y = W_1 y + X \beta + e, \quad e = W_2 e + \nu</code>
</p>

<p>where <code class="reqn">y</code> is a vector of responses, <code class="reqn">X</code> is a covariate matrix, <code class="reqn">\nu \sim N(0,\sigma^2)</code>,  
</p>
<p style="text-align: center;"><code class="reqn">W_1 = \sum_{i=1}^p \rho_{1i} W_{1i}, \quad W_2 = \sum_{i=1}^q \rho_{2i} W_{2i},</code>
</p>

<p>and <code class="reqn">W_{1i}</code>, <code class="reqn">W_{2i}</code> are (possibly valued) adjacency matrices.
</p>
<p>Intuitively, <code class="reqn">\rho_1</code> is a vector of &ldquo;AR&rdquo;-like parameters (parameterizing the autoregression of each <code class="reqn">y</code> value on its neighbors in the graphs of <code class="reqn">W_1</code>) while <code class="reqn">\rho_2</code> is a vector of &ldquo;MA&rdquo;-like parameters (parameterizing the autocorrelation of each <em>disturbance</em> in <code class="reqn">y</code> on its neighbors in the graphs of <code class="reqn">W_2</code>).  In general, the two models are distinct, and either or both effects may be selected by including the appropriate matrix arguments.
</p>
<p>Model parameters are estimated by maximum likelihood, and asymptotic standard errors are provided as well; all of the above (and more) can be obtained by means of the appropriate <code>print</code> and <code>summary</code> methods.  A plotting method is also provided, which supplies fit basic diagnostics for the estimated model.  For purposes of comparison, fits may be evaluated against one of four null models:
</p>

<ol>
<li> <p><code>meanstd</code>: mean and standard deviation estimated (default).
</p>
</li>
<li> <p><code>mean</code>: mean estimated; standard deviation assumed equal to 1.
</p>
</li>
<li> <p><code>std</code>: standard deviation estimated; mean assumed equal to 0.
</p>
</li>
<li> <p><code>none</code>: no parameters estimated; data assumed to be drawn from a standard normal density.
</p>
</li></ol>

<p>The default setting should be appropriate for the vast majority of cases, although the others may have use when fitting &ldquo;pure&rdquo; autoregressive models (e.g., without covariates).  Although a major use of the <code>lnam</code> is in controlling for network autocorrelation within a regression context, the model is subtle and has a variety of uses.  (See the references below for suggestions.)
</p>


<h3>Value</h3>

<p>An object of class <code>"lnam"</code> containing the following elements:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>the response vector used.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>if supplied, the coefficient matrix.</p>
</td></tr>
<tr><td><code>W1</code></td>
<td>
<p>if supplied, the W1 array.</p>
</td></tr>
<tr><td><code>W2</code></td>
<td>
<p>if supplied, the W2 array.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>a code indicating the model terms fit.</p>
</td></tr>
<tr><td><code>infomat</code></td>
<td>
<p>the estimated Fisher information matrix for the fitted model.</p>
</td></tr>
<tr><td><code>acvm</code></td>
<td>
<p>the estimated asymptotic covariance matrix for the model parameters.</p>
</td></tr>
<tr><td><code>null.model</code></td>
<td>
<p>a string indicating the null model fit.</p>
</td></tr>
<tr><td><code>lnlik.null</code></td>
<td>
<p>the log-likelihood of y under the null model.</p>
</td></tr>
<tr><td><code>df.null.resid</code></td>
<td>
<p>the residual degrees of freedom under the null model.</p>
</td></tr>
<tr><td><code>df.null</code></td>
<td>
<p>the model degrees of freedom under the null model.</p>
</td></tr>
<tr><td><code>null.param</code></td>
<td>
<p>parameter estimates for the null model.</p>
</td></tr>
<tr><td><code>lnlik.model</code></td>
<td>
<p>the log-likelihood of y under the fitted model.</p>
</td></tr>
<tr><td><code>df.model</code></td>
<td>
<p>the model degrees of freedom.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>df.total</code></td>
<td>
<p>the total degrees of freedom.</p>
</td></tr>
<tr><td><code>rho1</code></td>
<td>
<p>if applicable, the MLE for rho1.</p>
</td></tr>
<tr><td><code>rho1.se</code></td>
<td>
<p>if applicable, the asymptotic standard error for rho1.</p>
</td></tr>
<tr><td><code>rho2</code></td>
<td>
<p>if applicable, the MLE for rho2.</p>
</td></tr>
<tr><td><code>rho2.se</code></td>
<td>
<p>if applicable, the asymptotic standard error for rho2.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the MLE for sigma.</p>
</td></tr>
<tr><td><code>sigma.se</code></td>
<td>
<p>the standard error for sigma</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>if applicable, the MLE for beta.</p>
</td></tr>
<tr><td><code>beta.se</code></td>
<td>
<p>if applicable, the asymptotic standard errors for beta.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted mean values.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals (response minus fitted); note that these correspond to <code class="reqn">\hat{e}</code> in the model equation, not <code class="reqn">\hat{\nu}</code>.</p>
</td></tr>
<tr><td><code>disturbances</code></td>
<td>
<p>the estimated disturbances, i.e., <code class="reqn">\hat{\nu}</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> Actual optimization is performed by calls to <code><a href="stats.html#topic+optim">optim</a></code>.  Information on algorithms and control parameters can be found via the appropriate man pages. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Leenders, T.Th.A.J.  (2002)  &ldquo;Modeling Social Influence Through Network Autocorrelation: Constructing the Weight Matrix&rdquo;  <em>Social Networks</em>, 24(1), 21-47. 
</p>
<p>Anselin, L.  (1988)  <em>Spatial Econometrics: Methods and Models.</em>  Norwell, MA: Kluwer.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+optim">optim</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Construct a simple, random example:
w1&lt;-rgraph(100)               #Draw the AR matrix
w2&lt;-rgraph(100)               #Draw the MA matrix
x&lt;-matrix(rnorm(100*5),100,5) #Draw some covariates
r1&lt;-0.2                       #Set the model parameters
r2&lt;-0.1
sigma&lt;-0.1
beta&lt;-rnorm(5)
#Assemble y from its components:
nu&lt;-rnorm(100,0,sigma)          #Draw the disturbances
e&lt;-qr.solve(diag(100)-r2*w2,nu) #Draw the effective errors
y&lt;-qr.solve(diag(100)-r1*w1,x%*%beta+e)  #Compute y

#Now, fit the autocorrelation model:
fit&lt;-lnam(y,x,w1,w2)
summary(fit)
plot(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='loadcent'>
Compute the Load Centrality Scores of Network Positions
</h2><span id='topic+loadcent'></span>

<h3>Description</h3>

<p><code>loadcent</code> takes one or more graphs (<code>dat</code>) and returns the load centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  Depending on the specified mode, load on directed or undirected geodesics will be returned; this function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadcent(dat, g = 1, nodes = NULL, gmode = "digraph", diag = FALSE, 
    tmaxdev = FALSE, cmode = "directed", geodist.precomp = NULL, 
    rescale = FALSE, ignore.eval = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadcent_+3A_dat">dat</code></td>
<td>

<p>one or more input graphs. 
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_g">g</code></td>
<td>

<p>integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g</code>=1.
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_nodes">nodes</code></td>
<td>

<p>vector indicating which nodes are to be included in the calculation.  By default, all nodes are included.
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_gmode">gmode</code></td>
<td>

<p>string indicating the type of graph being evaluated.  <code>digraph</code> indicates that edges should be interpreted as directed; <code>graph</code> indicates that edges are undirected.  <code>gmode</code> is set to <code>digraph</code> by default.
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_diag">diag</code></td>
<td>

<p>logical; should self-ties be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default.
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_tmaxdev">tmaxdev</code></td>
<td>

<p>logical; return the theoretical maximum absolute deviation from the maximum nodal centrality (instead of the observed centrality scores)?  By default, <code>tmaxdev</code>==<code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_cmode">cmode</code></td>
<td>

<p>string indicating the type of load centrality being computed (directed or undirected). 
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_geodist.precomp">geodist.precomp</code></td>
<td>

<p>a <code><a href="#topic+geodist">geodist</a></code> object precomputed for the graph to be analyzed (optional).
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_rescale">rescale</code></td>
<td>

<p>logical; if true, centrality scores are rescaled such that they sum to 1.
</p>
</td></tr>
<tr><td><code id="loadcent_+3A_ignore.eval">ignore.eval</code></td>
<td>

<p>logical; ignore edge values when computing shortest paths?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Goh et al.'s <em>load centrality</em> (as reformulated by Brandes (2008)) is a betweenness-like measure defined through a hypothetical flow process.  Specifically, it is assumed that each vertex sends a unit of some commodity to each other vertex to which it is connected (without edge or vertex capacity constraints), with routing based on a priority system: given an input of flow <code class="reqn">x</code> arriving at vertex <code class="reqn">v</code> with destination <code class="reqn">v'</code>, <code class="reqn">v</code> divides <code class="reqn">x</code> equally among all neigbors of minumum geodesic distance to the target.  The total flow passing through a given <code class="reqn">v</code> via this process is defined as <code class="reqn">v</code>'s <em>load</em>.  Load is a potential alternative to betweenness for the analysis of flow structures operating well below their capacity constraints.
</p>


<h3>Value</h3>

<p>A vector of centrality scores.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Brandes, U.  (2008).  &ldquo;On Variants of Shortest-Path Betweenness Centrality and their Generic Computation.&rdquo;  <em>Social Networks</em>, 30, 136-145.
</p>
<p>Goh, K.-I.; Kahng, B.; and Kim, D.  (2001).  &ldquo;Universal Behavior of Load Distribution in Scale-free Networks.&rdquo;  <em>Physical Review Letters</em>, 87(27), 1-4.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betweenness">betweenness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(10)     #Draw a random graph with 10 members
loadcent(g)       #Compute load scores
</code></pre>

<hr>
<h2 id='lower.tri.remove'> Remove the Lower Triangles of Adjacency Matrices in a Graph Stack </h2><span id='topic+lower.tri.remove'></span>

<h3>Description</h3>

<p>Returns the input graph set, with the lower triangle entries removed/replaced as indicated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lower.tri.remove(dat, remove.val=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lower.tri.remove_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="lower.tri.remove_+3A_remove.val">remove.val</code></td>
<td>
<p> the value with which to replace the existing lower triangles. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lower.tri.remove</code> is simply a convenient way to apply <code>g[lower.tri(g)]&lt;-remove.val</code> to an entire stack of adjacency matrices at once.
</p>


<h3>Value</h3>

<p>The updated graph set.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+lower.tri">lower.tri</a></code>, <code><a href="#topic+upper.tri.remove">upper.tri.remove</a></code>, <code><a href="#topic+diag.remove">diag.remove</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a random graph stack
g&lt;-rgraph(3,5)
#Remove the lower triangles
g&lt;-lower.tri.remove(g)

</code></pre>

<hr>
<h2 id='lubness'> Compute Graph LUBness Scores </h2><span id='topic+lubness'></span><span id='topic+lubness_con_R'></span>

<h3>Description</h3>

<p><code>lubness</code> takes a graph set (<code>dat</code>) and returns the Krackhardt LUBness scores for the graphs selected by <code>g</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lubness(dat, g=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lubness_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="lubness_+3A_g">g</code></td>
<td>
<p> index values for the graphs to be utilized; by default, all graphs are selected. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the context of a directed graph <code class="reqn">G</code>, two actors <code class="reqn">i</code> and <code class="reqn">j</code> may be said to have an <em>upper bound</em> iff there exists some actor <code class="reqn">k</code> such that directed <code class="reqn">ki</code> and <code class="reqn">kj</code> paths belong to <code class="reqn">G</code>.  An upper bound <code class="reqn">\ell</code> is known as a <em>least upper bound</em> for <code class="reqn">i</code> and <code class="reqn">j</code> iff it belongs to at least one <code class="reqn">ki</code> and <code class="reqn">kj</code> path (respectively) for all <code class="reqn">i,j</code> upper bounds <code class="reqn">k</code>; let <code class="reqn">L(i,j)</code> be an indicator which returns 1 iff such an <code class="reqn">\ell</code> exists, otherwise returning 0.  Now, let <code class="reqn">G_1,G_2,\dots,G_n</code> represent the weak components of <code class="reqn">G</code>.  For convenience, we denote the cardinalities of these graphs' vertex sets by <code class="reqn">|V(G)|=N</code> and <code class="reqn">|V(G_i)|=N_i</code>, <code class="reqn">\forall i \in 1,\dots,n</code>.  Given this, the Krackhardt LUBness of <code class="reqn">G</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">
1-\frac{\sum_{i=1}^n \sum_{v_j,v_k \in V(G_i)} \Bigl(1-L(v_j,v_k)\Bigr)}{\sum_{i=1}^n \frac{1}{2}(N_i-1)(N_i-2)}</code>
</p>

<p>Where all vertex pairs possess a least upper bound, Krackhardt's LUBness is equal to 1; in general, it approaches 0 as this condition is broached.  (This convergence is problematic in certain cases due to the requirement that we sum violations across components; where a graph contains no components of size three or greater, Krackhardt's LUBness is not well-defined.  <code>lubness</code> returns a <code>NaN</code> in these cases.)  
</p>
<p>LUBness is one of four measures (<code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+hierarchy">hierarchy</a></code>, and <code><a href="#topic+lubness">lubness</a></code>) suggested by Krackhardt for summarizing hierarchical structures.  Each corresponds to one of four axioms which are necessary and sufficient for the structure in question to be an outtree; thus, the measures will be equal to 1 for a given graph iff that graph is an outtree.  Deviations from unity can be interpreted in terms of failure to satisfy one or more of the outtree conditions, information which may be useful in classifying its structural properties.
</p>


<h3>Value</h3>

<p>A vector of LUBness scores
</p>


<h3>Note</h3>

<p> The four Krackhardt indices are, in general, nondegenerate for a relatively narrow band of size/density combinations (efficiency being the sole exception).  This is primarily due to their dependence on the reachability graph, which tends to become complete rapidly as size/density increase.  See Krackhardt (1994) for a useful simulation study. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Krackhardt, David.  (1994).  &ldquo;Graph Theoretical Dimensions of Informal Organizations.&rdquo; In K. M. Carley and M. J. Prietula (Eds.), <em>Computational Organization Theory</em>, 89-111. Hillsdale, NJ: Lawrence Erlbaum and Associates. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+hierarchy">hierarchy</a></code>, <code><a href="#topic+lubness">lubness</a></code>, <code><a href="#topic+reachability">reachability</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Get LUBness scores for graphs of varying densities
lubness(rgraph(10,5,tprob=c(0.1,0.25,0.5,0.75,0.9)))

</code></pre>

<hr>
<h2 id='make.stochastic'> Make a Graph Stack Row, Column, or Row-column Stochastic </h2><span id='topic+make.stochastic'></span>

<h3>Description</h3>

<p>Returns a graph stack in which each adjacency matrix in <code>dat</code> has been normalized to row stochastic, column stochastic, or row-column stochastic form, as specified by <code>mode</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.stochastic(dat, mode="rowcol", tol=0.005, 
    maxiter=prod(dim(dat)) * 100, anneal.decay=0.01, errpow=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.stochastic_+3A_dat">dat</code></td>
<td>
<p> a collection of input graphs. </p>
</td></tr>
<tr><td><code id="make.stochastic_+3A_mode">mode</code></td>
<td>
<p> one of &ldquo;row,&rdquo; &ldquo;col,&rdquo; or &ldquo;rowcol&rdquo;. </p>
</td></tr>
<tr><td><code id="make.stochastic_+3A_tol">tol</code></td>
<td>
<p> tolerance parameter for the row-column normalization algorithm. </p>
</td></tr>
<tr><td><code id="make.stochastic_+3A_maxiter">maxiter</code></td>
<td>
<p> maximum iterations for the rwo-column normalization algorithm. </p>
</td></tr>
<tr><td><code id="make.stochastic_+3A_anneal.decay">anneal.decay</code></td>
<td>
<p> probability decay factor for the row-column annealer. </p>
</td></tr>
<tr><td><code id="make.stochastic_+3A_errpow">errpow</code></td>
<td>
<p> power to which absolute row-column normalization errors should be raised for the annealer (i.e., the penalty function). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Row and column stochastic matrices are those whose rows and columns sum to 1 (respectively).  These are quite straightforwardly produced here by dividing each row (or column) by its sum.  Row-column stochastic matrices, by contrast, are those in which each row <em>and</em> each column sums to 1.  Here, we try to produce row-column stochastic matrices whose values are as close in proportion to the original data as possible by means of an annealing algorithm.  This is probably not optimal in the long term, but the results seem to be consistent where row-column stochasticization of the original data is possible (which it is not in all cases).
</p>


<h3>Value</h3>

<p>The stochasticized adjacency matrices
</p>


<h3>Warning </h3>

<p>Rows or columns which sum to 0 in the original data will generate undefined results.  This can happen if, for instance, your input graphs contain in- or out-isolates.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a test matrix
g&lt;-rgraph(15)

#Make it row stochastic
make.stochastic(g,mode="row")

#Make it column stochastic
make.stochastic(g,mode="col")

#(Try to) make it row-column stochastic
make.stochastic(g,mode="rowcol")
</code></pre>

<hr>
<h2 id='maxflow'>
Calculate Maximum Flows Between Vertices
</h2><span id='topic+maxflow'></span><span id='topic+maxflow_EK_R'></span>

<h3>Description</h3>

<p><code>maxflow</code> calculates a matrix of maximum pairwise flows within a (possibly valued) input network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxflow(dat, src = NULL, sink = NULL, ignore.eval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maxflow_+3A_dat">dat</code></td>
<td>

<p>one or more input graphs.
</p>
</td></tr>
<tr><td><code id="maxflow_+3A_src">src</code></td>
<td>

<p>optionally, a vector of source vertices; by default, all vertices are selected.
</p>
</td></tr>
<tr><td><code id="maxflow_+3A_sink">sink</code></td>
<td>

<p>optionally, a vector of sink (or target) vertices; by default, all vertices are selected.
</p>
</td></tr>
<tr><td><code id="maxflow_+3A_ignore.eval">ignore.eval</code></td>
<td>

<p>logical; ignore edge values (i.e., assume unit capacities) when computing flow?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>maxflow</code> computes the maximum flow from each source vertex to each sink vertex, assuming infinite vertex capacities and limited edge capacities.  If <code>ignore.eval==FALSE</code>, supplied edge values are assumed to contain capacity information; otherwise, all non-zero edges are assumed to have unit capacity.
</p>
<p>Note that all flows computed here are pairwise &ndash; i.e., when computing the flow from <code class="reqn">v</code> to <code class="reqn">v'</code>, we ignore any other flows which could also be taking place within the network.  As a result, it should not be assumed that these flows can be realized <em>simultaneously</em>.  (For the latter purpose, the values returned by <code>maxflow</code> can be treated as upper bounds.)
</p>


<h3>Value</h3>

<p>A matrix of pairwise maximum flows (if multiple sources/sinks selected), or a single maximum flow value (otherwise).
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Edmonds, J. and Karp, R.M. (1972). &ldquo;Theoretical Improvements in Algorithmic Efficiency for Network Flow Problems.&rdquo;  <em>Journal of the ACM,</em> 19(2), 248-264.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flowbet">flowbet</a></code>, <code><a href="#topic+geodist">geodist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(10,tp=2/9)                     #Generate a sparse random graph
maxflow(g)                               #Compute all-pairs max flow
</code></pre>

<hr>
<h2 id='mutuality'> Find the Mutuality of a Graph </h2><span id='topic+mutuality'></span>

<h3>Description</h3>

<p>Returns the mutuality scores of the graphs indicated by <code>g</code> in <code>dat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mutuality(dat, g=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mutuality_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="mutuality_+3A_g">g</code></td>
<td>
<p> a vector indicating which elements of <code>dat</code> should be analyzed; by default, all graphs are included. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mutuality of a digraph G is defined as the number of complete dyads (i.e., i&lt;-&gt;j) within G.  (Compare this to dyadic reciprocity, the fraction of dyads within G which are symmetric.)  Mutuality is commonly employed as a measure of reciprocal tendency within the p* literature; although mutuality can be very hard to interpret in practice, it is much better behaved than many alternative measures.
</p>


<h3>Value</h3>

<p>One or more mutuality scores
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Moreno, J.L., and Jennings, H.H.  (1938).  &ldquo;Statistics of Social Configurations.&rdquo;  <em>Sociometry</em>, 1, 342-374. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+grecip">grecip</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create some random graphs
g&lt;-rgraph(15,3)

#Get mutuality and reciprocity scores
mutuality(g)
grecip(g)         #Compare with mutuality
</code></pre>

<hr>
<h2 id='nacf'> Sample Network Covariance and Correlation Functions </h2><span id='topic+nacf'></span>

<h3>Description</h3>

<p><code>nacf</code> computes the sample network covariance/correlation function for a specified variable on a given input network.  Moran's <code class="reqn">I</code> and Geary's <code class="reqn">C</code> statistics at multiple orders may be computed as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nacf(net, y, lag.max = NULL, type = c("correlation", "covariance",
    "moran", "geary"), neighborhood.type = c("in", "out", "total"),
    partial.neighborhood = TRUE, mode = "digraph", diag = FALSE,
    thresh = 0, demean = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nacf_+3A_net">net</code></td>
<td>
<p> one or more graphs. </p>
</td></tr>
<tr><td><code id="nacf_+3A_y">y</code></td>
<td>
<p> a numerical vector, of length equal to the order of <code>net</code>. </p>
</td></tr>
<tr><td><code id="nacf_+3A_lag.max">lag.max</code></td>
<td>
<p> optionally, the maximum geodesic lag at which to compute dependence (defaults to order <code>net</code>-1). </p>
</td></tr>
<tr><td><code id="nacf_+3A_type">type</code></td>
<td>
<p> the type of dependence statistic to be computed. </p>
</td></tr>
<tr><td><code id="nacf_+3A_neighborhood.type">neighborhood.type</code></td>
<td>
<p> the type of neighborhood to be employed when assessing dependence (as per <code><a href="#topic+neighborhood">neighborhood</a></code>). </p>
</td></tr>
<tr><td><code id="nacf_+3A_partial.neighborhood">partial.neighborhood</code></td>
<td>
<p> logical; should partial (rather than cumulative) neighborhoods be employed at higher orders? </p>
</td></tr>
<tr><td><code id="nacf_+3A_mode">mode</code></td>
<td>
 <p><code>"digraph"</code> for directed graphs, or <code>"graph"</code> if <code>net</code> is undirected. </p>
</td></tr>
<tr><td><code id="nacf_+3A_diag">diag</code></td>
<td>
<p> logical; does the diagonal of <code>net</code> contain valid data?</p>
</td></tr>
<tr><td><code id="nacf_+3A_thresh">thresh</code></td>
<td>
<p> threshold at which to dichotomize <code>net</code>. </p>
</td></tr>
<tr><td><code id="nacf_+3A_demean">demean</code></td>
<td>
<p> logical; demean <code>y</code> prior to analysis? </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nacf</code> computes dependence statistics for the vector <code>y</code> on network <code>net</code>, for neighborhoods of various orders.  Specifically, let <code class="reqn">\mathbf{A}_i</code> be the <code class="reqn">i</code>th order adjacency matrix of <code>net</code>.  The sample network autocovariance of <code class="reqn">\mathbf{y}</code> on <code class="reqn">\mathbf{A}_i</code> is then given by
</p>
<p style="text-align: center;"><code class="reqn">
    \sigma_i = \frac{\mathbf{y}^T \mathbf{A}_i \mathbf{y}}{E},
  </code>
</p>

<p>where <code class="reqn">E=\sum_{(j,k)}A_{ijk}</code>.  Similarly, the sample network autocorrelation in the above case is <code class="reqn">\rho_i=\sigma_i/\sigma_0</code>, where <code class="reqn">\sigma_0</code> is the variance of <code class="reqn">y</code>.  Moran's <code class="reqn">I</code> and Geary's <code class="reqn">C</code> statistics are defined in the usual fashion as
</p>
<p style="text-align: center;"><code class="reqn">
  I_i = \frac{N \sum_{j=1}^N \sum_{k=1}^N (y_j-\bar{y}) (y_k-\bar{y}) A_{ijk}}{E \sum_{j=1}^N y_j^2},
  </code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
  C_i = \frac{(N-1) \sum_{j=1}^N \sum_{k=1}^N (y_j-y_k)^2 A_{ijk}}{2 E \sum_{j=1}^N (y-\bar{y})^2}
  </code>
</p>

<p>respectively, where <code class="reqn">N</code> is the order of <code class="reqn">\mathbf{A}_i</code> and <code class="reqn">\bar{y}</code> is the mean of <code class="reqn">\mathbf{y}</code>.
</p>
<p>The adjacency matrix associated with the <code class="reqn">i</code>th order neighborhood is defined as the identity matrix for order 0, and otherwise depends on the type of neighborhood involved.  For input graph <code class="reqn">G=(V,E)</code>, let the <em>base relation</em>, <code class="reqn">R</code>, be given by the underlying graph of <code class="reqn">G</code> (i.e., <code class="reqn">G \cup G^T</code>) if total neighborhoods are sought, the transpose of <code class="reqn">G</code> if incoming neighborhoods are sought, or <code class="reqn">G</code> otherwise.  The partial neighborhood structure of order <code class="reqn">i&gt;0</code> on <code class="reqn">R</code> is then defined to be the digraph on <code class="reqn">V</code> whose edge set consists of the ordered pairs <code class="reqn">(j,k)</code> having geodesic distance <code class="reqn">i</code> in <code class="reqn">R</code>.  The corresponding cumulative neighborhood is formed by the ordered pairs having geodesic distance less than or equal to <code class="reqn">i</code> in <code class="reqn">R</code>.  For purposes of <code>nacf</code>, these neighborhoods are calculated using <code><a href="#topic+neighborhood">neighborhood</a></code>, with the specified parameters (including dichotomization at <code>thresh</code>).
</p>
<p>The return value for <code>nacf</code> is the selected dependence statistic, calculated for each neighborhood structure from order 0 (the identity) through order <code>lag.max</code> (or <code class="reqn">N-1</code>, if <code>lag.max==NULL</code>).  This vector can be used much like the conventional autocorrelation function, to identify dependencies at various lags.  This may, in turn, suggest a starting point for modeling via routines such as <code><a href="#topic+lnam">lnam</a></code>.
</p>


<h3>Value</h3>

<p>A vector containing the dependence statistics (ascending from order 0).
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Geary, R.C. (1954). &ldquo;The Contiguity Ratio and Statistical Mapping.&rdquo; <em>The Incorporated Statistician,</em> 5: 115-145.
</p>
<p>Moran, P.A.P.  (1950).  &ldquo;Notes on Continuous Stochastic Phenomena.&rdquo;  <em>Biometrika,</em> 37: 17-23.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+geodist">geodist</a></code>, <code><a href="#topic+gapply">gapply</a></code>, <code><a href="#topic+neighborhood">neighborhood</a></code>, <code><a href="#topic+lnam">lnam</a></code>, <code><a href="stats.html#topic+acf">acf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a random graph, and an autocorrelated variable
g&lt;-rgraph(50,tp=4/49)
y&lt;-qr.solve(diag(50)-0.8*g,rnorm(50,0,0.05))

#Examine the network autocorrelation function
nacf(g,y)                             #Partial neighborhoods
nacf(g,y,partial.neighborhood=FALSE)  #Cumulative neighborhoods

#Repeat, using Moran's I on the underlying graph
nacf(g,y,type="moran") 
nacf(g,y,partial.neighborhood=FALSE,type="moran")

</code></pre>

<hr>
<h2 id='neighborhood'> Compute Neighborhood Structures of Specified Order </h2><span id='topic+neighborhood'></span>

<h3>Description</h3>

<p>For a given graph, returns the specified neighborhood structure at the selected order(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neighborhood(dat, order, neighborhood.type = c("in", "out", "total"),
    mode = "digraph", diag = FALSE, thresh = 0, return.all = FALSE,
    partial = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neighborhood_+3A_dat">dat</code></td>
<td>
<p> one or more graphs. </p>
</td></tr>
<tr><td><code id="neighborhood_+3A_order">order</code></td>
<td>
<p> order of the neighborhood to extract. </p>
</td></tr>
<tr><td><code id="neighborhood_+3A_neighborhood.type">neighborhood.type</code></td>
<td>
<p> neighborhood type to employ. </p>
</td></tr>
<tr><td><code id="neighborhood_+3A_mode">mode</code></td>
<td>
 <p><code>"digraph"</code> if <code>dat</code> is directed, otherwise <code>"graph"</code>. </p>
</td></tr>
<tr><td><code id="neighborhood_+3A_diag">diag</code></td>
<td>
<p> logical; do the diagonal entries of <code>dat</code> contain valid data? </p>
</td></tr>
<tr><td><code id="neighborhood_+3A_thresh">thresh</code></td>
<td>
<p> dichotomization threshold to use for <code>dat</code>; edges whose values are greater than <code>thresh</code> are treated as present. </p>
</td></tr>
<tr><td><code id="neighborhood_+3A_return.all">return.all</code></td>
<td>
<p> logical; return neighborhoods for all orders up to <code>order</code>? </p>
</td></tr>
<tr><td><code id="neighborhood_+3A_partial">partial</code></td>
<td>
<p> logical; return partial (rather than cumulative) neighborhoods? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The adjacency matrix associated with the <code class="reqn">i</code>th order neighborhood is defined as the identity matrix for order 0, and otherwise depends on the type of neighborhood involved.  For input graph <code class="reqn">G=(V,E)</code>, let the <em>base relation</em>, <code class="reqn">R</code>, be given by the underlying graph of <code class="reqn">G</code> (i.e., <code class="reqn">G \cup G^T</code>) if total neighborhoods are sought, the transpose of <code class="reqn">G</code> if incoming neighborhoods are sought, or <code class="reqn">G</code> otherwise.  The partial neighborhood structure of order <code class="reqn">i&gt;0</code> on <code class="reqn">R</code> is then defined to be the digraph on <code class="reqn">V</code> whose edge set consists of the ordered pairs <code class="reqn">(j,k)</code> having geodesic distance <code class="reqn">i</code> in <code class="reqn">R</code>.  The corresponding cumulative neighborhood is formed by the ordered pairs having geodesic distance less than or equal to <code class="reqn">i</code> in <code class="reqn">R</code>.
</p>
<p>Neighborhood structures are commonly used to parameterize various types of network autocorrelation models.  They may also be used in the calculation of certain types of local structural indices; <code><a href="#topic+gapply">gapply</a></code> provides an alternative function which can be used for this purpose.
</p>


<h3>Value</h3>

<p>An array or adjacency matrix containing the neighborhood structures (if <code>dat</code> is a single graph); if <code>dat</code> contains multiple graphs, then a list of such structures is returned.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gapply">gapply</a></code>, <code><a href="#topic+nacf">nacf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw a random graph
g&lt;-rgraph(10,tp=2/9)

#Show the total partial out-neighborhoods
neigh&lt;-neighborhood(g,9,neighborhood.type="out",return.all=TRUE)
par(mfrow=c(3,3))
for(i in 1:9)
  gplot(neigh[i,,],main=paste("Partial Neighborhood of Order",i))

#Show the total cumulative out-neighborhoods
neigh&lt;-neighborhood(g,9,neighborhood.type="out",return.all=TRUE,
    partial=FALSE)
par(mfrow=c(3,3))
for(i in 1:9)
  gplot(neigh[i,,],main=paste("Cumulative Neighborhood of Order",i))

</code></pre>

<hr>
<h2 id='netcancor'> Canonical Correlation for Labeled Graphs </h2><span id='topic+netcancor'></span>

<h3>Description</h3>

<p><code>netcancor</code> finds the canonical correlation(s) between the graph sets <code>x</code> and <code>y</code>, testing the result using either conditional uniform graph (CUG) or quadratic assignment procedure (QAP) null hypotheses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>netcancor(y, x, mode="digraph", diag=FALSE, nullhyp="cugtie", 
    reps=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="netcancor_+3A_y">y</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="netcancor_+3A_x">x</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="netcancor_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>mode</code> is set to &quot;digraph&quot; by default. </p>
</td></tr>
<tr><td><code id="netcancor_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="netcancor_+3A_nullhyp">nullhyp</code></td>
<td>
<p> string indicating the particular null hypothesis against which to test the observed estimands.  A value of &quot;cug&quot; implies a conditional uniform graph test (see <code><a href="#topic+cugtest">cugtest</a></code>) controlling for order <em>only</em>; &quot;cugden&quot; controls for both order and tie probability; &quot;cugtie&quot; controls for order and tie distribution (via bootstrap); and &quot;qap&quot; implies that the QAP null hypothesis (see <code><a href="#topic+qaptest">qaptest</a></code>) should be used. </p>
</td></tr>
<tr><td><code id="netcancor_+3A_reps">reps</code></td>
<td>
<p>integer indicating the number of draws to use for quantile estimation.  (Relevant to the null hypothesis test only - the analysis itself is unaffected by this parameter.)  Note that, as for all Monte Carlo procedures, convergence is slower for more extreme quantiles. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>netcancor</code> routine is actually a front-end to the <code><a href="stats.html#topic+cancor">cancor</a></code> routine for computing canonical correlations between sets of vectors.  <code>netcancor</code> itself vectorizes the network variables (as per its graph type) and manages the appropriate null hypothesis tests; the actual canonical correlation is handled by <code><a href="stats.html#topic+cancor">cancor</a></code>.  
</p>
<p>Canonical correlation itself is a multivariate generalization of the product-moment correlation.  Specifically, the analysis seeks linear combinations of the variables in <code>y</code> which are well-explained by linear combinations of the variables in <code>x</code>.  The network version of this technique is performed elementwise on the adjacency matrices of the graphs in question; as usual, the result should be interpreted with an eye to the relationship between the type of data used and the assumptions of the underlying model.
</p>
<p>Intelligent printing and summarizing of netcancor objects is provided by <code><a href="#topic+print.netcancor">print.netcancor</a></code> and <code><a href="#topic+summary.netcancor">summary.netcancor</a></code>.  
</p>


<h3>Value</h3>

<p>An object of class <code>netcancor</code> with the following properties:
</p>
<table>
<tr><td><code>xdist</code></td>
<td>

<p>Array containing the distribution of the X coefficients under the null hypothesis test.
</p>
</td></tr>
<tr><td><code>ydist</code></td>
<td>

<p>Array containing the distribution of the Y coefficients under the null hypothesis test.
</p>
</td></tr>
<tr><td><code>cdist</code></td>
<td>

<p>Array containing the distribution of the canonical correlation coefficients under the null hypothesis test.
</p>
</td></tr>
<tr><td><code>cor</code></td>
<td>

<p>Vector containing the observed canonical correlation coefficients.
</p>
</td></tr>
<tr><td><code>xcoef</code></td>
<td>

<p>Vector containing the observed X coefficients.
</p>
</td></tr>
<tr><td><code>ycoef</code></td>
<td>

<p>Vector containing the observed Y coefficients.
</p>
</td></tr>
<tr><td><code>cpgreq</code></td>
<td>

<p>Vector containing the estimated upper tail quantiles (p&gt;=obs) for the observed canonical correlation coefficients under the null hypothesis.
</p>
</td></tr>
<tr><td><code>cpleeq</code></td>
<td>

<p>Vector containing the estimated lower tail quantiles (p&lt;=obs) for the observed canonical correlation coefficients under the null hypothesis.
</p>
</td></tr>
<tr><td><code>xpgreq</code></td>
<td>

<p>Matrix containing the estimated upper tail quantiles (p&gt;=obs) for the observed X coefficients under the null hypothesis.
</p>
</td></tr>
<tr><td><code>xpleeq</code></td>
<td>

<p>Matrix containing the estimated lower tail quantiles (p&lt;=obs) for the observed X coefficients under the null hypothesis.
</p>
</td></tr>
<tr><td><code>ypgreq</code></td>
<td>

<p>Matrix containing the estimated upper tail quantiles (p&gt;=obs) for the observed Y coefficients under the null hypothesis.
</p>
</td></tr>
<tr><td><code>ypleeq</code></td>
<td>

<p>Matrix containing the estimated lower tail quantiles (p&lt;=obs) for the observed Y coefficients under the null hypothesis.
</p>
</td></tr>
<tr><td><code>cnames</code></td>
<td>

<p>Vector containing names for the canonical correlation coefficients.
</p>
</td></tr>
<tr><td><code>xnames</code></td>
<td>

<p>Vector containing names for the X vars.
</p>
</td></tr>
<tr><td><code>ynames</code></td>
<td>

<p>Vector containing names for the Y vars.
</p>
</td></tr>
<tr><td><code>xcenter</code></td>
<td>

<p>Values used to adjust the X variables.
</p>
</td></tr>
<tr><td><code>xcenter</code></td>
<td>

<p>Values used to adjust the Y variables.
</p>
</td></tr>
<tr><td><code>nullhyp</code></td>
<td>

<p>String indicating the null hypothesis employed.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p> This will eventually be replaced with a superior cancor procedure with more interpretable output; the new version will handle arbitrary labeling as well. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS working paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+gcor">gcor</a></code>, <code><a href="#topic+cugtest">cugtest</a></code>, <code><a href="#topic+qaptest">qaptest</a></code>, <code><a href="stats.html#topic+cancor">cancor</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a valued seed structure
cv&lt;-matrix(rnorm(100),nrow=10,ncol=10)
#Produce two sets of valued graphs
x&lt;-array(dim=c(3,10,10))
x[1,,]&lt;-3*cv+matrix(rnorm(100,0,0.1),nrow=10,ncol=10)
x[2,,]&lt;--1*cv+matrix(rnorm(100,0,0.1),nrow=10,ncol=10)
x[3,,]&lt;-x[1,,]+2*x[2,,]+5*cv+matrix(rnorm(100,0,0.1),nrow=10,ncol=10)
y&lt;-array(dim=c(2,10,10))
y[1,,]&lt;--5*cv+matrix(rnorm(100,0,0.1),nrow=10,ncol=10)
y[2,,]&lt;--2*cv+matrix(rnorm(100,0,0.1),nrow=10,ncol=10)
#Perform a canonical correlation analysis
nc&lt;-netcancor(y,x,reps=100)
summary(nc)
</code></pre>

<hr>
<h2 id='netlm'> Linear Regression for Network Data </h2><span id='topic+netlm'></span>

<h3>Description</h3>

<p><code>netlm</code> regresses the network variable in <code>y</code> on the network variables in stack <code>x</code> using ordinary least squares.  The resulting fits (and coefficients) are then tested against the indicated null hypothesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>netlm(y, x, intercept=TRUE, mode="digraph", diag=FALSE,
    nullhyp=c("qap", "qapspp", "qapy", "qapx", "qapallx", 
    "cugtie", "cugden", "cuguman", "classical"), 
    test.statistic = c("t-value", "beta"), tol=1e-7,
    reps=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="netlm_+3A_y">y</code></td>
<td>
<p> dependent network variable.  This should be a matrix, for obvious reasons; NAs are allowed, but dichotomous data is strongly discouraged due to the assumptions of the analysis. </p>
</td></tr>
<tr><td><code id="netlm_+3A_x">x</code></td>
<td>
<p> stack of independent network variables.  Note that NAs are permitted, as is dichotomous data. </p>
</td></tr>
<tr><td><code id="netlm_+3A_intercept">intercept</code></td>
<td>
<p> logical; should an intercept term be added? </p>
</td></tr>
<tr><td><code id="netlm_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>mode</code> is set to <code>"digraph"</code> by default. </p>
</td></tr>
<tr><td><code id="netlm_+3A_diag">diag</code></td>
<td>
<p> logical; should the diagonal be treated as valid data?  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="netlm_+3A_nullhyp">nullhyp</code></td>
<td>
<p> string indicating the particular null hypothesis against which to test the observed estimands. </p>
</td></tr>
<tr><td><code id="netlm_+3A_test.statistic">test.statistic</code></td>
<td>
<p> string indicating the test statistic to be used for the Monte Carlo procedures.</p>
</td></tr>
<tr><td><code id="netlm_+3A_tol">tol</code></td>
<td>
<p> tolerance parameter for <code><a href="base.html#topic+qr.solve">qr.solve</a></code>. </p>
</td></tr>
<tr><td><code id="netlm_+3A_reps">reps</code></td>
<td>
<p> integer indicating the number of draws to use for quantile estimation.  (Relevant to the null hypothesis test only - the analysis itself is unaffected by this parameter.)  Note that, as for all Monte Carlo procedures, convergence is slower for more extreme quantiles.  By default, <code>reps</code>=1000. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>netlm</code> performs an OLS linear network regression of the graph <code>y</code> on the graphs in <code>x</code>.  Network regression using OLS is directly analogous to standard OLS regression elementwise on the appropriately vectorized adjacency matrices of the networks involved.  In particular, the network regression attempts to fit the model:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{A_y} = b_0 \mathbf{A_1} + b_1 \mathbf{A_{x_1}} + b_2 \mathbf{A_{x_2}} + \dots + \mathbf{Z}</code>
</p>

<p>where <code class="reqn">\mathbf{A_y}</code> is the dependent adjacency matrix, <code class="reqn">\mathbf{A_{x_i}}</code> is the ith independent adjacency matrix, <code class="reqn">\mathbf{A_1}</code> is an n x n matrix of 1's, and <code class="reqn">\mathbf{Z}</code> is an n x n matrix of independent normal random variables with mean 0 and variance <code class="reqn">\sigma^2</code>.  Clearly, this model is nonoptimal when <code class="reqn">\mathbf{A_y}</code> is dichotomous (or, for that matter, categorical in general); an alternative such as <code>netlogit</code> should be employed in such cases.  (Note that <code>netlm</code> will still attempt to fit such data...the user should consider him or herself to have been warned.)
</p>
<p>Because of the frequent presence of row/column/block autocorrelation in network data, classical hull hypothesis tests (and associated standard errors) are generally suspect.  Further, it is sometimes of interest to compare fitted parameter values to those arising from various baseline models (e.g., uniform random graphs conditional on certain observed statistics).  The tests supported by <code>netlm</code> are as follows:
</p>

<dl>
<dt><code>classical</code></dt><dd><p> tests based on classical asymptotics. </p>
</dd>
<dt><code>cug</code></dt><dd><p>conditional uniform graph test (see <code><a href="#topic+cugtest">cugtest</a></code>) controlling for order.</p>
</dd>
<dt><code>cugden</code></dt><dd><p>conditional uniform graph test, controlling for order and density.</p>
</dd>
<dt><code>cugtie</code></dt><dd><p>conditional uniform graph test, controlling for order and tie distribution.</p>
</dd>
<dt><code>qap</code></dt><dd><p>QAP permutation test (see <code><a href="#topic+qaptest">qaptest</a></code>); currently identical to <code>qapspp</code>. </p>
</dd>
<dt><code>qapallx</code></dt><dd><p>QAP permutation test, using independent x-permutations.</p>
</dd>
<dt><code>qapspp</code></dt><dd><p>QAP permutation test, using Dekker's &quot;semi-partialling plus&quot; procedure. </p>
</dd>
<dt><code>qapx</code></dt><dd><p>QAP permutation test, using (single) x-permutations.</p>
</dd>
<dt><code>qapy</code></dt><dd><p>QAP permutation test, using y-permutations.</p>
</dd>
</dl>

<p>The statistic to be employed in the above tests may be selected via <code>test.statistic</code>.  By default, the <code class="reqn">t</code>-statistic (rather than estimated coefficient) is used, as this is more approximately pivotal; coefficient-based tests are not recommended for QAP null hypotheses, although they are provided here for legacy purposes.
</p>
<p>Note that interpretation of quantiles for single coefficients can be complex in the presence of multicollinearity or third variable effects.  <code>qapspp</code>  is generally recommended for most multivariable analyses, as it is known to be fairly robust to these conditions.  Reasonable printing and summarizing of <code>netlm</code> objects is provided by <code><a href="#topic+print.netlm">print.netlm</a></code> and <code><a href="#topic+summary.netlm">summary.netlm</a></code>, respectively.  No plot methods exist at this time, alas. 
</p>


<h3>Value</h3>

<p>An object of class <code>netlm</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Dekker, D.; Krackhardt, D.; Snijders, T.A.B.  (2007).  &ldquo;Sensitivity of MRQAP Tests to Collinearity and Autocorrelation Conditions.&rdquo;  <em>Psychometrika</em>, 72(4), 563-581.
</p>
<p>Dekker, D.; Krackhardt, D.; Snijders, T.A.B.  (2003).  &ldquo;Mulicollinearity Robust QAP for Multiple Regression.&rdquo;  CASOS Working Paper, Carnegie Mellon University.
</p>
<p>Krackhardt, D.  (1987).  &ldquo;QAP Partialling as a Test of Spuriousness.&rdquo; <em>Social Networks</em>, 9 171-186.
</p>
<p>Krackhardt, D.  (1988).  &ldquo;Predicting With Networks: Nonparametric Multiple Regression Analyses of Dyadic Data.&rdquo;  <em>Social Networks</em>, 10, 359-382.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+netlogit">netlogit</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create some input graphs
x&lt;-rgraph(20,4)

#Create a response structure
y&lt;-x[1,,]+4*x[2,,]+2*x[3,,]   #Note that the fourth graph is unrelated

#Fit a netlm model
nl&lt;-netlm(y,x,reps=100)

#Examine the results
summary(nl)
</code></pre>

<hr>
<h2 id='netlogit'> Logistic Regression for Network Data </h2><span id='topic+netlogit'></span>

<h3>Description</h3>

<p><code>netlogit</code> performs a logistic regression of the network variable in <code>y</code> on the network variables in set <code>x</code>.  The resulting fits (and coefficients) are then tested against the indicated null hypothesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>netlogit(y, x, intercept=TRUE, mode="digraph", diag=FALSE,
    nullhyp=c("qap", "qapspp", "qapy", "qapx", "qapallx", 
    "cugtie", "cugden", "cuguman", "classical"), test.statistic = 
    c("z-value","beta"), tol=1e-7, reps=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="netlogit_+3A_y">y</code></td>
<td>
<p> dependent network variable.  <code>NA</code>s are allowed, and the data should be dichotomous. </p>
</td></tr>
<tr><td><code id="netlogit_+3A_x">x</code></td>
<td>
<p> the stack of independent network variables.  Note that <code>NA</code>s are permitted, as is dichotomous data. </p>
</td></tr>
<tr><td><code id="netlogit_+3A_intercept">intercept</code></td>
<td>
<p>logical; should an intercept term be fitted?</p>
</td></tr>
<tr><td><code id="netlogit_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>mode</code> is set to <code>"digraph"</code> by default. </p>
</td></tr>
<tr><td><code id="netlogit_+3A_diag">diag</code></td>
<td>
<p>  boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="netlogit_+3A_nullhyp">nullhyp</code></td>
<td>
<p> string indicating the particular null hypothesis against which to test the observed estimands. </p>
</td></tr>
<tr><td><code id="netlogit_+3A_test.statistic">test.statistic</code></td>
<td>
<p>string indicating the test statistic to be used for the Monte Carlo procedures.</p>
</td></tr>
<tr><td><code id="netlogit_+3A_tol">tol</code></td>
<td>
<p> tolerance parameter for <code>qr.solve</code>. </p>
</td></tr>
<tr><td><code id="netlogit_+3A_reps">reps</code></td>
<td>
<p> integer indicating the number of draws to use for quantile estimation.  (Relevant to the null hypothesis test only &ndash; the analysis itself is unaffected by this parameter.)  Note that, as for all Monte Carlo procedures, convergence is slower for more extreme quantiles.  By default, <code>reps</code>=1000. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>netlogit</code> is primarily a front-end to the built-in <code><a href="stats.html#topic+glm.fit">glm.fit</a></code> routine.  <code>netlogit</code> handles vectorization, sets up <code><a href="stats.html#topic+glm">glm</a></code> options, and deals with null hypothesis testing; the actual fitting is taken care of by <code><a href="stats.html#topic+glm.fit">glm.fit</a></code>.  
</p>
<p>Logistic network regression using is directly analogous to standard logistic regression elementwise on the appropriately vectorized adjacency matrices of the networks involved.  As such, it is often a more appropriate model for fitting dichotomous response networks than is linear network regression.  
</p>
<p>Because of the frequent presence of row/column/block autocorrelation in network data, classical hull hypothesis tests (and associated standard errors) are generally suspect.  Further, it is sometimes of interest to compare fitted parameter values to those arising from various baseline models (e.g., uniform random graphs conditional on certain observed statistics).  The tests supported by <code>netlogit</code> are as follows:
</p>

<dl>
<dt><code>classical</code></dt><dd><p> tests based on classical asymptotics. </p>
</dd>
<dt><code>cug</code></dt><dd><p>conditional uniform graph test (see <code><a href="#topic+cugtest">cugtest</a></code>) controlling for order.</p>
</dd>
<dt><code>cugden</code></dt><dd><p>conditional uniform graph test, controlling for order and density.</p>
</dd>
<dt><code>cugtie</code></dt><dd><p>conditional uniform graph test, controlling for order and tie distribution.</p>
</dd>
<dt><code>qap</code></dt><dd><p>QAP permutation test (see <code><a href="#topic+qaptest">qaptest</a></code>); currently identical to <code>qapspp</code>. </p>
</dd>
<dt><code>qapallx</code></dt><dd><p>QAP permutation test, using independent x-permutations.</p>
</dd>
<dt><code>qapspp</code></dt><dd><p>QAP permutation test, using Dekker's &ldquo;semi-partialling plus&rdquo; procedure. </p>
</dd>
<dt><code>qapx</code></dt><dd><p>QAP permutation test, using (single) x-permutations.</p>
</dd>
<dt><code>qapy</code></dt><dd><p>QAP permutation test, using y-permutations.</p>
</dd>
</dl>

<p>Note that interpretation of quantiles for single coefficients can be complex in the presence of multicollinearity or third variable effects.  Although <code>qapspp</code> is known to be robust to these conditions in the OLS case, there are no equivalent results for logistic regression.  Caution is thus advised.  
</p>
<p>The statistic to be employed in the above tests may be selected via <code>test.statistic</code>.  By default, the z-statistic (rather than estimated coefficient) is used, as this is more approximately pivotal; coefficient-based tests are not recommended for QAP null hypotheses, although they are provided here for legacy purposes.
</p>
<p>Reasonable printing and summarizing of <code>netlogit</code> objects is provided by <code><a href="#topic+print.netlogit">print.netlogit</a></code> and <code><a href="#topic+summary.netlogit">summary.netlogit</a></code>, respectively.  No plot methods exist at this time.
</p>


<h3>Value</h3>

<p>An object of class <code>netlogit</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS working paper, Carnegie Mellon University.</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="#topic+netlm">netlm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Create some input graphs
x&lt;-rgraph(20,4)

#Create a response structure
y.l&lt;-x[1,,]+4*x[2,,]+2*x[3,,]   #Note that the fourth graph is 
                                #unrelated
y.p&lt;-apply(y.l,c(1,2),function(a){1/(1+exp(-a))})
y&lt;-rgraph(20,tprob=y.p)

#Fit a netlogit model
nl&lt;-netlogit(y,x,reps=100)

#Examine the results
summary(nl)

## End(Not run)
</code></pre>

<hr>
<h2 id='npostpred'> Take Posterior Predictive Draws for Functions of Networks </h2><span id='topic+npostpred'></span>

<h3>Description</h3>

<p><code>npostpred</code> takes a list or data frame, <code>b</code>, and applies the function <code>FUN</code> to each element of <code>b</code>'s <code>net</code> member.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npostpred(b, FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npostpred_+3A_b">b</code></td>
<td>
<p> A list or data frame containing posterior network draws; these draws must take the form of a graph stack, and must be the member of <code>b</code> referenced by &quot;<code>net</code>&quot; </p>
</td></tr>
<tr><td><code id="npostpred_+3A_fun">FUN</code></td>
<td>
<p> Function for which posterior predictive is to be estimated </p>
</td></tr>
<tr><td><code id="npostpred_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code>FUN</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Although created to work with <code><a href="#topic+bbnam">bbnam</a></code>, <code>npostpred</code> is quite generic.  The form of the posterior draws will vary with the output of <code>FUN</code>; since invocation is handled by <code><a href="base.html#topic+apply">apply</a></code>, check there if unsure.
</p>


<h3>Value</h3>

<p>A series of posterior predictive draws
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Gelman, A.; Carlin, J.B.; Stern, H.S.; and Rubin, D.B.  (1995).  <em>Bayesian Data Analysis.</em>  London: Chapman and Hall. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam">bbnam</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create some random data
g&lt;-rgraph(5)
g.p&lt;-0.8*g+0.2*(1-g)
dat&lt;-rgraph(5,5,tprob=g.p)

#Define a network prior
pnet&lt;-matrix(ncol=5,nrow=5)
pnet[,]&lt;-0.5
#Define em and ep priors
pem&lt;-matrix(nrow=5,ncol=2)
pem[,1]&lt;-3
pem[,2]&lt;-5
pep&lt;-matrix(nrow=5,ncol=2)
pep[,1]&lt;-3
pep[,2]&lt;-5

#Draw from the posterior
b&lt;-bbnam(dat,model="actor",nprior=pnet,emprior=pem,epprior=pep,
    burntime=100,draws=100)
#Plot a summary of the posterior predictive of reciprocity
hist(npostpred(b,grecip))
</code></pre>

<hr>
<h2 id='nties'> Find the Number of Possible Ties in a Given Graph or Graph Stack </h2><span id='topic+nties'></span>

<h3>Description</h3>

<p><code>nties</code> returns the number of possible edges in each element of <code>dat</code>, given <code>mode</code> and <code>diag</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nties(dat, mode="digraph", diag=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nties_+3A_dat">dat</code></td>
<td>
<p> a graph or set thereof. </p>
</td></tr>
<tr><td><code id="nties_+3A_mode">mode</code></td>
<td>
<p> one of &ldquo;digraph&rdquo;, &ldquo;graph&rdquo;, and &ldquo;hgraph&rdquo;. </p>
</td></tr>
<tr><td><code id="nties_+3A_diag">diag</code></td>
<td>
<p> a boolean indicating whether or not diagonal entries (loops) should be treated as valid data; ignored for hypergraphic (&ldquo;hgraph&rdquo;) data. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nties</code> is used primarily to automate maximum edge counts for use with normalization routines.
</p>


<h3>Value</h3>

<p>The number of possible edges, or a vector of the same
</p>


<h3>Note</h3>

<p> For two-mode (hypergraphic) data, the value returned isn't technically the number of edges per se, but rather the number of edge memberships. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#How many possible edges in a loopless digraph of order 15?
nties(rgraph(15),diag=FALSE)
</code></pre>

<hr>
<h2 id='numperm'> Get the nth Permutation Vector by Periodic Placement </h2><span id='topic+numperm'></span>

<h3>Description</h3>

<p><code>numperm</code> implicitly numbers all permutations of length <code>olength</code>, returning the <code>permnum</code>th of these.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numperm(olength, permnum)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numperm_+3A_olength">olength</code></td>
<td>
<p> The number of items to permute </p>
</td></tr>
<tr><td><code id="numperm_+3A_permnum">permnum</code></td>
<td>
<p> The number of the permutation to use (in <code>1:olength!</code>) </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The n! permutations on n items can be deterministically ordered via a factorization process in which there are n slots for the first element, n-1 for the second, and n-i for the ith.  This fact is quite handy if you want to visit each permutation in turn, or if you wish to sample without replacement from the set of permutations on some number of elements: one just enumerates or samples from the integers on [1,n!], and then find the associated permutation.  <code>numperm</code> performs exactly this last operation, returning the <code>permnum</code>th permutation on <code>olength</code> items.
</p>


<h3>Value</h3>

<p>A permutation vector
</p>


<h3>Note</h3>

<p> Permutation search is central to the estimation of structural distances, correlations, and covariances on partially labeled graphs.  <code>numperm</code> is hence used by <code><a href="#topic+structdist">structdist</a></code>, <code><a href="#topic+gscor">gscor</a></code>, <code><a href="#topic+gscov">gscov</a></code>, etc. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+rperm">rperm</a></code>, <code><a href="#topic+rmperm">rmperm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw a graph
g&lt;-rgraph(5)

#Permute the rows and columns
p.1&lt;-numperm(5,1)
p.2&lt;-numperm(5,2)
p.3&lt;-numperm(5,3)
g[p.1,p.1]
g[p.2,p.2]
g[p.3,p.3]
</code></pre>

<hr>
<h2 id='plot.bbnam'> Plotting for bbnam Objects</h2><span id='topic+plot.bbnam'></span><span id='topic+plot.bbnam.fixed'></span><span id='topic+plot.bbnam.pooled'></span><span id='topic+plot.bbnam.actor'></span>

<h3>Description</h3>

<p>Generates various plots of posterior draws from the <code><a href="#topic+bbnam">bbnam</a></code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bbnam'
plot(x, mode="density", intlines=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.bbnam_+3A_x">x</code></td>
<td>
<p> A <code>bbnam</code> object </p>
</td></tr>
<tr><td><code id="plot.bbnam_+3A_mode">mode</code></td>
<td>
<p> &ldquo;density&rdquo; for kernel density estimators of posterior marginals; otherwise, histograms are used </p>
</td></tr>
<tr><td><code id="plot.bbnam_+3A_intlines">intlines</code></td>
<td>
<p> Plot lines for the 0.9 central posterior probability intervals? </p>
</td></tr>
<tr><td><code id="plot.bbnam_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code><a href="graphics.html#topic+plot">plot</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.bbnam</code> provides plots of the estimated posterior marginals for the criterion graph and error parameters (as appropriate).  Plotting may run into difficulties when dealing with large graphs, due to the problem of getting all of the various plots on the page; the routine handles these issues reasonably intelligently, but there is doubtless room for improvement.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Butts, C.T. (1999). &ldquo;Informant (In)Accuracy and Network Estimation: A Bayesian Approach.&rdquo; CASOS Working Paper, Carnegie Mellon University. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam">bbnam</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create some random data
g&lt;-rgraph(5)
g.p&lt;-0.8*g+0.2*(1-g)
dat&lt;-rgraph(5,5,tprob=g.p)

#Define a network prior
pnet&lt;-matrix(ncol=5,nrow=5)
pnet[,]&lt;-0.5
#Define em and ep priors
pem&lt;-matrix(nrow=5,ncol=2)
pem[,1]&lt;-3
pem[,2]&lt;-5
pep&lt;-matrix(nrow=5,ncol=2)
pep[,1]&lt;-3
pep[,2]&lt;-5

#Draw from the posterior
b&lt;-bbnam(dat,model="actor",nprior=pnet,emprior=pem,epprior=pep,
    burntime=100,draws=100)
#Print a summary of the posterior draws
summary(b)
#Plot the result
plot(b)
</code></pre>

<hr>
<h2 id='plot.blockmodel'> Plotting for blockmodel Objects </h2><span id='topic+plot.blockmodel'></span>

<h3>Description</h3>

<p>Displays a plot of the blocked data matrix, given a blockmodel object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blockmodel'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.blockmodel_+3A_x">x</code></td>
<td>
<p> An object of class <code>blockmodel</code> </p>
</td></tr>
<tr><td><code id="plot.blockmodel_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots of the blocked data matrix (i.e., the data matrix with rows and columns permuted to match block membership) can be useful in assessing the strength of the block solution (particularly for clique detection and/or regular equivalence).
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> White, H.C.; Boorman, S.A.; and Breiger, R.L.  (1976).  &ldquo;Social Structure from Multiple Networks I: Blockmodels of Roles and Positions.&rdquo;  <em>American Journal of Sociology</em>, 81, 730-779.
</p>
<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+blockmodel">blockmodel</a></code>, <code><a href="#topic+plot.sociomatrix">plot.sociomatrix</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a random graph with _some_ edge structure
g.p&lt;-sapply(runif(20,0,1),rep,20)  #Create a matrix of edge 
                                   #probabilities
g&lt;-rgraph(20,tprob=g.p)            #Draw from a Bernoulli graph 
                                   #distribution

#Cluster based on structural equivalence
eq&lt;-equiv.clust(g)

#Form a blockmodel with distance relaxation of 10
b&lt;-blockmodel(g,eq,h=10)
plot(b)                            #Plot it
</code></pre>

<hr>
<h2 id='plot.cugtest'> Plotting for cugtest Objects </h2><span id='topic+plot.cugtest'></span>

<h3>Description</h3>

<p>Plots the distribution of a CUG test statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cugtest'
plot(x, mode="density", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cugtest_+3A_x">x</code></td>
<td>
<p> A <code><a href="#topic+cugtest">cugtest</a></code> object </p>
</td></tr>
<tr><td><code id="plot.cugtest_+3A_mode">mode</code></td>
<td>
<p> &ldquo;density&rdquo; for kernel density estimation, &ldquo;hist&rdquo; for histogram </p>
</td></tr>
<tr><td><code id="plot.cugtest_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code><a href="graphics.html#topic+plot">plot</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In addition to the quantiles associated with a CUG test, it is often useful to examine the form of the distribution of the test statistic.  <code>plot.cugtest</code> facilitates this.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Anderson, B.S.; Butts, C.T.; and Carley, K.M. (1999). &ldquo;The Interaction of Size and Density with Graph-Level Indices.&rdquo; <em>Social Networks</em>, 21(3), 239-267. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+cugtest">cugtest</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw two random graphs, with different tie probabilities
dat&lt;-rgraph(20,2,tprob=c(0.2,0.8))

#Is their correlation higher than would be expected, conditioning 
#only on size?
cug&lt;-cugtest(dat,gcor,cmode="order")
summary(cug)
plot(cug)

#Now, let's try conditioning on density as well.
cug&lt;-cugtest(dat,gcor)
plot(cug)
</code></pre>

<hr>
<h2 id='plot.equiv.clust'> Plot an equiv.clust Object </h2><span id='topic+plot.equiv.clust'></span>

<h3>Description</h3>

<p>Plots a hierarchical clustering of node positions as generated by <code><a href="#topic+equiv.clust">equiv.clust</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'equiv.clust'
plot(x, labels=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.equiv.clust_+3A_x">x</code></td>
<td>
<p> An <code><a href="#topic+equiv.clust">equiv.clust</a></code> object </p>
</td></tr>
<tr><td><code id="plot.equiv.clust_+3A_labels">labels</code></td>
<td>
<p> A vector of vertex labels </p>
</td></tr>
<tr><td><code id="plot.equiv.clust_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code><a href="stats.html#topic+plot.hclust">plot.hclust</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.equiv.clust</code> is actually a front-end to <code><a href="stats.html#topic+plot.hclust">plot.hclust</a></code>; see the latter for more additional documentation.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Breiger, R.L.; Boorman, S.A.; and Arabie, P.  (1975).  &ldquo;An Algorithm for Clustering Relational Data with Applications to Social Network Analysis and Comparison with Multidimensional Scaling.&rdquo;  <em>Journal of Mathematical Psychology</em>, 12, 328-383.
</p>
<p>Burt, R.S.  (1976).  &ldquo;Positions in Networks.&rdquo;  <em>Social Forces</em>, 55, 93-122.
</p>
<p>Wasserman, S., and Faust, K.  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+equiv.clust">equiv.clust</a></code>, <code><a href="stats.html#topic+plot.hclust">plot.hclust</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a random graph with _some_ edge structure
g.p&lt;-sapply(runif(20,0,1),rep,20)  #Create a matrix of edge 
                                   #probabilities
g&lt;-rgraph(20,tprob=g.p)            #Draw from a Bernoulli graph 
                                   #distribution

#Cluster based on structural equivalence
eq&lt;-equiv.clust(g)
plot(eq)
</code></pre>

<hr>
<h2 id='plot.lnam'> Plotting for lnam Objects </h2><span id='topic+plot.lnam'></span>

<h3>Description</h3>

<p>Generates various diagnostic plots for <code><a href="#topic+lnam">lnam</a> objects.</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lnam'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lnam_+3A_x">x</code></td>
<td>
<p> an object of class <code>lnam</code>. </p>
</td></tr>
<tr><td><code id="plot.lnam_+3A_...">...</code></td>
<td>
<p> additional arguments to <code><a href="graphics.html#topic+plot">plot</a></code>. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+lnam">lnam</a></code> </p>

<hr>
<h2 id='plot.qaptest'> Plotting for qaptest Objects </h2><span id='topic+plot.qaptest'></span>

<h3>Description</h3>

<p>Plots the Distribution of a QAP Test Statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qaptest'
plot(x, mode="density", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.qaptest_+3A_x">x</code></td>
<td>
<p> A <code><a href="#topic+qaptest">qaptest</a></code> object </p>
</td></tr>
<tr><td><code id="plot.qaptest_+3A_mode">mode</code></td>
<td>
<p> &ldquo;density&rdquo; for kernel density estimation, &ldquo;hist&rdquo; for histogram </p>
</td></tr>
<tr><td><code id="plot.qaptest_+3A_...">...</code></td>
<td>
<p> Additional arguments to <code><a href="graphics.html#topic+plot">plot</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In addition to the quantiles associated with a QAP test, it is often useful to examine the form of the distribution of the test statistic.  <code>plot.qaptest</code> facilitates this.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Hubert, L.J., and Arabie, P.  (1989).  &ldquo;Combinatorial Data Analysis: Confirmatory Comparisons Between Sets of Matrices.&rdquo;  <em>Applied Stochastic Models and Data Analysis</em>, 5, 273-325.
</p>
<p>Krackhardt, D.  (1987).  &ldquo;QAP Partialling as a Test of Spuriousness.&rdquo; <em>Social Networks</em>, 9 171-186.
</p>
<p>Krackhardt, D.  (1988).  &ldquo;Predicting With Networks: Nonparametric Multiple Regression Analyses of Dyadic Data.&rdquo;  <em>Social Networks</em>, 10, 359-382.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+qaptest">qaptest</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Generate three graphs
g&lt;-array(dim=c(3,10,10))
g[1,,]&lt;-rgraph(10)
g[2,,]&lt;-rgraph(10,tprob=g[1,,]*0.8)
g[3,,]&lt;-1; g[3,1,2]&lt;-0              #This is nearly a clique

#Perform qap tests of graph correlation
q.12&lt;-qaptest(g,gcor,g1=1,g2=2)
q.13&lt;-qaptest(g,gcor,g1=1,g2=3)

#Examine the results
summary(q.12)
plot(q.12)
summary(q.13)
plot(q.13)
</code></pre>

<hr>
<h2 id='plot.sociomatrix'> Plot Matrices Using a Color/Intensity Grid </h2><span id='topic+plot.sociomatrix'></span><span id='topic+sociomatrixplot'></span>

<h3>Description</h3>

<p>Plots a matrix, <code>m</code>, associating the magnitude of the i,jth cell of <code>m</code> with the color of the i,jth cell of an <code>nrow(m)</code> by <code>ncol(m)</code> grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sociomatrix'
plot(x, labels=NULL, drawlab=TRUE, diaglab=TRUE, 
    drawlines=TRUE, xlab=NULL, ylab=NULL, cex.lab=1, font.lab=1, col.lab=1,
    scale.values=TRUE, cell.col=gray, ...)

sociomatrixplot(x, labels=NULL, drawlab=TRUE, diaglab=TRUE, 
    drawlines=TRUE, xlab=NULL, ylab=NULL, cex.lab=1, font.lab=1, col.lab=1,
    scale.values=TRUE, cell.col=gray, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sociomatrix_+3A_x">x</code></td>
<td>
<p> an input graph. </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_labels">labels</code></td>
<td>
<p> a list containing the vectors of row and column labels (respectively); defaults to the row/column labels of <code>x</code> (if specified), or otherwise sequential numerical labels. </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_drawlab">drawlab</code></td>
<td>
<p> logical; add row/column labels to the plot? </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_diaglab">diaglab</code></td>
<td>
<p> logical; label the diagonal? </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_drawlines">drawlines</code></td>
<td>
<p> logical; draw lines to mark cell boundaries? </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_xlab">xlab</code></td>
<td>
<p> x axis label. </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_ylab">ylab</code></td>
<td>
<p> y axis label. </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_cex.lab">cex.lab</code></td>
<td>
<p> optional expansion factor for labels. </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_font.lab">font.lab</code></td>
<td>
<p> optional font specification for labels. </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_col.lab">col.lab</code></td>
<td>
<p> optional color specification for labels. </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_scale.values">scale.values</code></td>
<td>
<p> logical; should cell values be affinely scaled to the [0,1] interval?  (Defaults to <code>TRUE</code>.) </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_cell.col">cell.col</code></td>
<td>
<p> function taking a vector of cell values as an argument and returning a corresponding vector of colors; defaults to <code><a href="grDevices.html#topic+gray">gray</a></code>. </p>
</td></tr>
<tr><td><code id="plot.sociomatrix_+3A_...">...</code></td>
<td>
<p> additional arguments to <code><a href="graphics.html#topic+plot">plot</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.sociomatrix</code> is particularly valuable for examining large adjacency matrices, whose structure can be non-obvious otherwise.  <code>sociomatrixplot</code> is an alias to <code>plot.sociomatrix</code>, and may eventually supersede it.
</p>
<p>The <code>cell.col</code> argument can be any function that takes input cell values and returns legal colors; while <code><a href="grDevices.html#topic+gray">gray</a></code> will produce an error for cell values outside the [0,1] interval, user-specified functions can be employed to get other effects (see examples below).  Note that, by default, all input cell values are affinely scaled to the [0,1] interval before colors are computed, so <code>scale.values</code> must be set to <code>FALSE</code> to allow access to the raw inputs.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.blockmodel">plot.blockmodel</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Plot a small adjacency matrix
plot.sociomatrix(rgraph(5))

#Plot a much larger one
plot.sociomatrix(rgraph(100), drawlab=FALSE, diaglab=FALSE)

#Example involving a signed, valued graph and custom colors
mycolfun &lt;- function(z){   #Custom color function
    ifelse(z&lt;0, rgb(1,0,0,alpha=1-1/(1-z)), ifelse(z&gt;0, 
        rgb(0,0,1,alpha=1-1/(1+z)), rgb(0,0,0,alpha=0)))
}
sg &lt;- rgraph(25) * matrix(rnorm(25^2),25,25)
plot.sociomatrix(sg, scale.values=FALSE, cell.col=mycolfun)  #Blue pos/red neg
</code></pre>

<hr>
<h2 id='potscalered.mcmc'> Compute Gelman and Rubin's Potential Scale Reduction Measure for a Markov Chain Monte Carlo Simulation</h2><span id='topic+potscalered.mcmc'></span>

<h3>Description</h3>

<p>Computes Gelman and Rubin's (simplified) measure of scale reduction for draws of a single scalar estimand from parallel MCMC chains. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>potscalered.mcmc(psi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="potscalered.mcmc_+3A_psi">psi</code></td>
<td>
<p> An nxm matrix, with columns corresponding to chains and rows corresponding to iterations. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gelman and Rubin potential scale reduction (<code class="reqn">\sqrt{\hat{R}}</code>) provides an ANOVA-like comparison of the between-chain to within-chain variance on a given scalar estimand; the disparity between these gives an indication of the extent to which the scale of the simulated distribution can be reduced via further sampling.  As the parallel chains converge <code class="reqn">\sqrt{\hat{R}}</code> approaches 1 (from above), and it is generally recommended that values of 1.2 or less be obtained before a series of draws can be considered well-mixed.  (Even so, one should ideally examine other indicators of chain mixing, and verify that the properties of the draws are as they should be.  There is currently no fool-proof way to verify burn-in of an MCMC, but using multiple indicators should help one avoid falling prey to the idiosyncrasies of any one index.)
</p>
<p>Note that the particular estimators used in the <code class="reqn">\sqrt{\hat{R}}</code> formulation are based on normal-theory results, and as such have been criticized vis a vis their behavior on other distributions.  Where simulating distributions whose properties differ greatly from the normal, an alternative form of the measure using robust measures of scale (e.g., the IQR) may be preferable.
</p>


<h3>Value</h3>

<p>The potential scale reduction measure
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Gelman, A.; Carlin, J.B.; Stern, H.S.; and Rubin, D.B.  (1995).  <em>Bayesian Data Analysis.</em>  London: Chapman and Hall.
</p>
<p>Gelman, A., and Rubin, D.B.  (1992).  &ldquo;Inference from Iterative Simulation Using Multiple Sequences.&rdquo;  <em>Statistical Science,</em> 7, 457-511. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam">bbnam</a></code></p>

<hr>
<h2 id='prestige'> Calculate the Vertex Prestige Scores </h2><span id='topic+prestige'></span>

<h3>Description</h3>

<p><code>prestige</code> takes one or more graphs (<code>dat</code>) and returns the prestige scores of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  Depending on the specified mode, prestige based on any one of a number of different definitions will be returned. This function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prestige(dat, g=1, nodes=NULL, gmode="digraph", diag=FALSE, 
    cmode="indegree", tmaxdev=FALSE, rescale=FALSE, tol=1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prestige_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="prestige_+3A_g">g</code></td>
<td>
<p> integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g==1</code>. </p>
</td></tr>
<tr><td><code id="prestige_+3A_nodes">nodes</code></td>
<td>
<p> vector indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="prestige_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  &quot;digraph&quot; indicates that edges should be interpreted as directed; &quot;graph&quot; indicates that edges are undirected.  <code>gmode</code> is set to &quot;digraph&quot; by default.</p>
</td></tr>
<tr><td><code id="prestige_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="prestige_+3A_cmode">cmode</code></td>
<td>
<p> one of &quot;indegree&quot;, &quot;indegree.rownorm&quot;, &quot;indegree.rowcolnorm&quot;, &quot;eigenvector&quot;, &quot;eigenvector.rownorm&quot;, &quot;eigenvector.colnorm&quot;, &quot;eigenvector.rowcolnorm&quot;, &quot;domain&quot;, or &quot;domain.proximity&quot;. </p>
</td></tr>
<tr><td><code id="prestige_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev==FALSE</code>. </p>
</td></tr>
<tr><td><code id="prestige_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="prestige_+3A_tol">tol</code></td>
<td>
<p> Currently ignored </p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Prestige&quot; is the name collectively given to a range of centrality scores which focus on the extent to which one is nominated by others.  The definitions supported here are as follows:
</p>

<ol>
<li><p> indegree: indegree centrality
</p>
</li>
<li><p> indegree.rownorm: indegree within the row-normalized graph
</p>
</li>
<li><p> indegree.rowcolnorm: indegree within the row-column normalized graph
</p>
</li>
<li><p> eigenvector: eigenvector centrality within the transposed graph (i.e., incoming ties recursively determine prestige)
</p>
</li>
<li><p> eigenvector.rownorm: eigenvector centrality within the transposed row-normalized graph
</p>
</li>
<li><p> eigenvector.colnorm: eigenvector centrality within the transposed column-normalized graph
</p>
</li>
<li><p> eigenvector.rowcolnorm: eigenvector centrality within the transposed row/column-normalized graph
</p>
</li>
<li><p> domain: indegree within the reachability graph (Lin's unweighted measure)
</p>
</li>
<li><p> domain.proximity: Lin's proximity-weighted domain prestige
</p>
</li></ol>

<p>Note that the centralization of prestige is simply the extent to which one actor has substantially greater prestige than others; the underlying definition is the same.
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the prestige scores (depending on the number and size of the input graphs).
</p>


<h3>Warning </h3>

<p>Making adjacency matrices doubly stochastic (row-column normalization) is not guaranteed to work.  In general, be wary of attempting to try normalizations on graphs with degenerate rows and columns.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Lin, N.  (1976).  <em>Foundations of Social Research</em>.  New York: McGraw Hill.
</p>
<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+centralization">centralization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(10)                 #Draw a random graph with 10 members
prestige(g,cmode="domain")    #Compute domain prestige scores
</code></pre>

<hr>
<h2 id='print.bayes.factor'> Printing for Bayes Factor Objects </h2><span id='topic+print.bayes.factor'></span>

<h3>Description</h3>

<p>Prints a quick summary of a Bayes Factor object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes.factor'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bayes.factor_+3A_x">x</code></td>
<td>
<p> An object of class <code>bayes.factor</code> </p>
</td></tr>
<tr><td><code id="print.bayes.factor_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam.bf">bbnam.bf</a></code></p>

<hr>
<h2 id='print.bbnam'> Printing for bbnam Objects </h2><span id='topic+print.bbnam'></span><span id='topic+print.bbnam.fixed'></span><span id='topic+print.bbnam.pooled'></span><span id='topic+print.bbnam.actor'></span>

<h3>Description</h3>

<p>Prints a quick summary of posterior draws from <code><a href="#topic+bbnam">bbnam</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bbnam'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bbnam_+3A_x">x</code></td>
<td>
<p> A <code><a href="#topic+bbnam">bbnam</a></code> object </p>
</td></tr>
<tr><td><code id="print.bbnam_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam">bbnam</a></code> </p>

<hr>
<h2 id='print.blockmodel'> Printing for blockmodel Objects </h2><span id='topic+print.blockmodel'></span>

<h3>Description</h3>

<p>Prints a quick summary of a <code><a href="#topic+blockmodel">blockmodel</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blockmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.blockmodel_+3A_x">x</code></td>
<td>
<p> An object of class <code>blockmodel</code> </p>
</td></tr>
<tr><td><code id="print.blockmodel_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+blockmodel">blockmodel</a></code> </p>

<hr>
<h2 id='print.cugtest'> Printing for cugtest Objects</h2><span id='topic+print.cugtest'></span>

<h3>Description</h3>

<p>Prints a quick summary of objects produced by <code><a href="#topic+cugtest">cugtest</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cugtest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cugtest_+3A_x">x</code></td>
<td>
<p> An object of class <code>cugtest</code> </p>
</td></tr>
<tr><td><code id="print.cugtest_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+cugtest">cugtest</a></code> </p>

<hr>
<h2 id='print.lnam'> Printing for lnam Objects </h2><span id='topic+print.lnam'></span>

<h3>Description</h3>

<p>Prints an objsect of class <code>lnam</code> 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lnam'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.lnam_+3A_x">x</code></td>
<td>
<p> an object of class <code>lnam</code>. </p>
</td></tr>
<tr><td><code id="print.lnam_+3A_digits">digits</code></td>
<td>
<p> number of digits to display. </p>
</td></tr>
<tr><td><code id="print.lnam_+3A_...">...</code></td>
<td>
<p> additional arguments. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+lnam">lnam</a></code> </p>

<hr>
<h2 id='print.netcancor'> Printing for netcancor Objects </h2><span id='topic+print.netcancor'></span>

<h3>Description</h3>

<p>Prints a quick summary of objects produced by <code><a href="#topic+netcancor">netcancor</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'netcancor'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.netcancor_+3A_x">x</code></td>
<td>
<p> An object of class <code>netcancor</code></p>
</td></tr>
<tr><td><code id="print.netcancor_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+netcancor">netcancor</a></code> </p>

<hr>
<h2 id='print.netlm'> Printing for netlm Objects </h2><span id='topic+print.netlm'></span>

<h3>Description</h3>

<p>Prints a quick summary of objects produced by <code><a href="#topic+netlm">netlm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'netlm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.netlm_+3A_x">x</code></td>
<td>
<p> An object of class <code>netlm</code></p>
</td></tr>
<tr><td><code id="print.netlm_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+netlm">netlm</a></code></p>

<hr>
<h2 id='print.netlogit'> Printing for netlogit Objects </h2><span id='topic+print.netlogit'></span>

<h3>Description</h3>

<p>Prints a quick summary of objects produced by <code><a href="#topic+netlogit">netlogit</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'netlogit'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.netlogit_+3A_x">x</code></td>
<td>
<p> An object of class <code>netlogit</code> </p>
</td></tr>
<tr><td><code id="print.netlogit_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+netlogit">netlogit</a></code> </p>

<hr>
<h2 id='print.qaptest'> Printing for qaptest Objects </h2><span id='topic+print.qaptest'></span>

<h3>Description</h3>

<p>Prints a quick summary of objects produced by <code><a href="#topic+qaptest">qaptest</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qaptest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.qaptest_+3A_x">x</code></td>
<td>
<p> An object of class <code>qaptest</code> </p>
</td></tr>
<tr><td><code id="print.qaptest_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+qaptest">qaptest</a></code></p>

<hr>
<h2 id='print.summary.bayes.factor'> Printing for summary.bayes.factor Objects </h2><span id='topic+print.summary.bayes.factor'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.bayes.factor</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.bayes.factor'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.bayes.factor_+3A_x">x</code></td>
<td>
<p> An object of class <code>summary.bayes.factor</code> </p>
</td></tr>
<tr><td><code id="print.summary.bayes.factor_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+summary.bayes.factor">summary.bayes.factor</a></code> </p>

<hr>
<h2 id='print.summary.bbnam'> Printing for summary.bbnam Objects </h2><span id='topic+print.summary.bbnam'></span><span id='topic+print.summary.bbnam.fixed'></span><span id='topic+print.summary.bbnam.pooled'></span><span id='topic+print.summary.bbnam.actor'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.bbnam</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.bbnam'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.bbnam_+3A_x">x</code></td>
<td>
<p> An object of class <code>summary.bbnam</code> </p>
</td></tr>
<tr><td><code id="print.summary.bbnam_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam">bbnam</a></code> </p>

<hr>
<h2 id='print.summary.blockmodel'> Printing for summary.blockmodel Objects </h2><span id='topic+print.summary.blockmodel'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.blockmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.blockmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.blockmodel_+3A_x">x</code></td>
<td>
<p> An object of class <code>summary.blockmodel</code> </p>
</td></tr>
<tr><td><code id="print.summary.blockmodel_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+summary.blockmodel">summary.blockmodel</a></code></p>

<hr>
<h2 id='print.summary.cugtest'> Printing for summary.cugtest Objects </h2><span id='topic+print.summary.cugtest'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.cugtest</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.cugtest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.cugtest_+3A_x">x</code></td>
<td>
<p> An object of class <code>summary.cugtest</code> </p>
</td></tr>
<tr><td><code id="print.summary.cugtest_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+summary.cugtest">summary.cugtest</a></code> </p>

<hr>
<h2 id='print.summary.lnam'> Printing for summary.lnam Objects </h2><span id='topic+print.summary.lnam'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.lnam</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.lnam'
print(x, digits = max(3, getOption("digits") - 3), 
    signif.stars = getOption("show.signif.stars"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.lnam_+3A_x">x</code></td>
<td>
<p> an object of class <code>summary.lnam</code>. </p>
</td></tr>
<tr><td><code id="print.summary.lnam_+3A_digits">digits</code></td>
<td>
<p> number of digits to display. </p>
</td></tr>
<tr><td><code id="print.summary.lnam_+3A_signif.stars">signif.stars</code></td>
<td>
<p> show significance stars? </p>
</td></tr>
<tr><td><code id="print.summary.lnam_+3A_...">...</code></td>
<td>
<p> additional arguments. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+summary.lnam">summary.lnam</a></code>, <code><a href="#topic+lnam">lnam</a></code> </p>

<hr>
<h2 id='print.summary.netcancor'> Printing for summary.netcancor Objects </h2><span id='topic+print.summary.netcancor'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.netcancor</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.netcancor'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.netcancor_+3A_x">x</code></td>
<td>
<p> An object of class <code>summary.netcancor</code></p>
</td></tr>
<tr><td><code id="print.summary.netcancor_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+summary.netcancor">summary.netcancor</a></code> </p>

<hr>
<h2 id='print.summary.netlm'> Printing for summary.netlm Objects </h2><span id='topic+print.summary.netlm'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.netlm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.netlm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.netlm_+3A_x">x</code></td>
<td>
<p> An object of class <code>summary.netlm</code> </p>
</td></tr>
<tr><td><code id="print.summary.netlm_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+summary.netlm">summary.netlm</a></code> </p>

<hr>
<h2 id='print.summary.netlogit'> Printing for summary.netlogit Objects </h2><span id='topic+print.summary.netlogit'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.netlogit</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.netlogit'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.netlogit_+3A_x">x</code></td>
<td>
<p> An object of class <code>summary.netlogit</code>~ </p>
</td></tr>
<tr><td><code id="print.summary.netlogit_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+summary.netlogit">summary.netlogit</a></code> </p>

<hr>
<h2 id='print.summary.qaptest'> Printing for summary.qaptest Objects  </h2><span id='topic+print.summary.qaptest'></span>

<h3>Description</h3>

<p>Prints an object of class <code>summary.qaptest</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.qaptest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.qaptest_+3A_x">x</code></td>
<td>
<p> An object of class <code>summary.qaptest</code> </p>
</td></tr>
<tr><td><code id="print.summary.qaptest_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+summary.qaptest">summary.qaptest</a></code> </p>

<hr>
<h2 id='pstar'> Fit a p*/ERG Model Using a Logistic Approximation </h2><span id='topic+pstar'></span>

<h3>Description</h3>

<p>Fits a p*/ERG model to the graph in <code>dat</code> containing the effects listed in <code>effects</code>.  The result is returned as a <code><a href="stats.html#topic+glm">glm</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pstar(dat, effects=c("choice", "mutuality", "density", "reciprocity",
    "stransitivity", "wtransitivity", "stranstri",  "wtranstri", 
    "outdegree", "indegree", "betweenness", "closeness", 
    "degcentralization", "betcentralization", "clocentralization",
    "connectedness", "hierarchy", "lubness", "efficiency"), 
    attr=NULL, memb=NULL, diag=FALSE, mode="digraph")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pstar_+3A_dat">dat</code></td>
<td>
<p> a single graph </p>
</td></tr>
<tr><td><code id="pstar_+3A_effects">effects</code></td>
<td>
<p> a vector of strings indicating which effects should be fit. </p>
</td></tr>
<tr><td><code id="pstar_+3A_attr">attr</code></td>
<td>
<p> a matrix whose columns contain individual attributes (one row per vertex) whose differences should be used as supplemental predictors. </p>
</td></tr>
<tr><td><code id="pstar_+3A_memb">memb</code></td>
<td>
<p> a matrix whose columns contain group memberships whose categorical similarities (same group/not same group) should be used as supplemental predictors.</p>
</td></tr>
<tr><td><code id="pstar_+3A_diag">diag</code></td>
<td>
<p> a boolean indicating whether or not diagonal entries (loops) should be counted as meaningful data. </p>
</td></tr>
<tr><td><code id="pstar_+3A_mode">mode</code></td>
<td>
 <p><code>"digraph"</code> if <code>dat</code> is directed, else <code>"graph"</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Exponential Family-Random Graph Model (ERGM) family, referred to as &ldquo;p*&rdquo; in older literature, is an exponential family specification for network data.  In this specification, it is assumed that 
</p>
<p style="text-align: center;"><code class="reqn">p(G=g) \propto \exp(\beta_0 \gamma_0(g) + \beta_1 \gamma_1(g) + \dots)</code>
</p>

<p>for all g, where the betas represent real coefficients and the gammas represent functions of g.  Unfortunately, the unknown normalizing factor in the above expression makes evaluation difficult in the general case.  One solution to this problem is to operate instead on the edgewise log odds; in this case, the ERGM/p* MLE can be approximated by a logistic regression of each edge on the <em>differences</em> in the gamma scores induced by the presence and absence of said edge in the graph (conditional on all other edges).  It is this approximation (known as autologistic regression, or maximum pseudo-likelihood estimation) that is employed here.  
</p>
<p>Note that ERGM modeling is considerably more advanced than it was when this function was created, and estimation by MPLE is now used only in special cases.  Guidelines for model specification and assessment have also evolved.  The <code>ergm</code> package within the <code>statnet</code> library reflects the current state of the art, and use of the <code>ergm()</code> function in said library is highly recommended.  This function is retained primarily as a legacy tool, for users who are nostalgic for 2000-vintage ERGM (&ldquo;p*&rdquo;) modeling experience.  Caveat emptor.
</p>
<p>Using the <code>effects</code> argument, a range of different potential parameters can be estimated.  The network measure associated with each is, in turn, the edge-perturbed difference in:
</p>

<ol>
<li> <p><code>choice</code>: the number of edges in the graph (acts as a constant)
</p>
</li>
<li> <p><code>mutuality</code>: the number of reciprocated dyads in the graph
</p>
</li>
<li> <p><code>density</code>: the density of the graph
</p>
</li>
<li> <p><code>reciprocity</code>: the edgewise reciprocity of the graph
</p>
</li>
<li> <p><code>stransitivity</code>: the strong transitivity of the graph
</p>
</li>
<li> <p><code>wtransitivity</code>: the weak transitivity of the graph
</p>
</li>
<li> <p><code>stranstri</code>: the number of strongly transitive triads in the graph
</p>
</li>
<li> <p><code>wtranstri</code>: the number of weakly transitive triads in the graph
</p>
</li>
<li> <p><code>outdegree</code>: the outdegree of each actor (|V| parameters)
</p>
</li>
<li> <p><code>indegree</code>: the indegree of each actor (|V| parameters)
</p>
</li>
<li> <p><code>betweenness</code>: the betweenness of each actor (|V| parameters)
</p>
</li>
<li> <p><code>closeness</code>: the closeness of each actor (|V| parameters)
</p>
</li>
<li> <p><code>degcentralization</code>: the Freeman degree centralization of the graph
</p>
</li>
<li> <p><code>betcentralization</code>: the betweenness centralization of the graph
</p>
</li>
<li> <p><code>clocentralization</code>: the closeness centralization of the graph
</p>
</li>
<li> <p><code>connectedness</code>: the Krackhardt connectedness of the graph
</p>
</li>
<li> <p><code>hierarchy</code>: the Krackhardt hierarchy of the graph
</p>
</li>
<li> <p><code>efficiency</code>: the Krackhardt efficiency of the graph
</p>
</li>
<li> <p><code>lubness</code>: the Krackhardt LUBness of the graph
</p>
</li></ol>

<p>(Note that some of these do differ somewhat from the common specifications employed in the older p* literature, e.g. quantities such as density and reciprocity are computed as per the <code><a href="#topic+gden">gden</a></code> and <code><a href="#topic+grecip">grecip</a></code> functions rather than via the unnormalized &quot;choice&quot; and &quot;mutual&quot; quantities that were generally used.)  <em>Please do not attempt to use all effects simultaneously!!!</em>  In addition to the above, the user may specify a matrix of individual attributes whose absolute dyadic differences are to be used as predictors, as well as a matrix of individual memberships whose dyadic categorical similarities (same/different) are used in the same manner.
</p>
<p>Although the ERGM framework is quite versatile in its ability to accommodate a range of structural predictors, it should be noted that the <em>substantial</em> collinearity of many of the terms provided here can lead to very unstable model fits.  Measurement and specification errors compound this problem, as does the use of the MPLE; thus, it is somewhat risky to use <code>pstar</code> in an exploratory capacity (i.e., when there is little prior knowledge to constrain choice of parameters).  While raw instability due to multicollinearity should decline with graph size, improper specification will still result in biased coefficient estimates so long as an omitted predictor correlates with an included predictor.  Moreover, many models created using these effects are at risk of degeneracy, which is difficult to assess without simulation-based model assessment.  Caution is advised - or, better, use of the <code>ergm</code> package.
</p>


<h3>Value</h3>

<p>A <code><a href="stats.html#topic+glm">glm</a></code> object
</p>


<h3>WARNING </h3>

<p>Estimation of p* models by maximum pseudo-likelihood is now known to be a dangerous practice.  Use at your own risk.</p>


<h3>Note</h3>

<p> This is a legacy function - use of the <code>ergm</code> package is now strongly advised.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Anderson, C.; Wasserman, S.; and Crouch, B. (1999).  &ldquo;A p* Primer:  Logit Models for Social Networks.  <em>Social Networks,</em> 21,37-66.
</p>
<p>Holland, P.W., and Leinhardt, S. (1981).  &ldquo;An Exponential Family of Probability Distributions for Directed Graphs.&rdquo; <em>Journal of the American statistical Association</em>, 81, 51-67.
</p>
<p>Wasserman, S., and Pattison, P. (1996).  &ldquo;Logit Models and Logistic Regressions for Social Networks:  I.  An introduction to Markov Graphs and p*.&rdquo;  <em>Psychometrika,</em> 60, 401-426.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+eval.edgeperturbation">eval.edgeperturbation</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Create a graph with expansiveness and popularity effects
in.str&lt;-rnorm(20,0,3)
out.str&lt;-rnorm(20,0,3)
tie.str&lt;-outer(out.str,in.str,"+")
tie.p&lt;-apply(tie.str,c(1,2),function(a){1/(1+exp(-a))})
g&lt;-rgraph(20,tprob=tie.p)

#Fit a model with expansiveness only
p1&lt;-pstar(g,effects="outdegree")
#Fit a model with expansiveness and popularity
p2&lt;-pstar(g,effects=c("outdegree","indegree"))
#Fit a model with expansiveness, popularity, and mutuality
p3&lt;-pstar(g,effects=c("outdegree","indegree","mutuality"))

#Compare the model AICs -- use ONLY as heuristics!!!
extractAIC(p1)
extractAIC(p2)
extractAIC(p3)

## End(Not run)
</code></pre>

<hr>
<h2 id='qaptest'> Perform Quadratic Assignment Procedure (QAP) Hypothesis Tests for Graph-Level Statistics </h2><span id='topic+qaptest'></span>

<h3>Description</h3>

<p><code>qaptest</code> tests an arbitrary graph-level statistic (computed on <code>dat</code> by <code>FUN</code>) against a QAP null hypothesis, via Monte Carlo simulation of likelihood quantiles.  Note that fair amount of flexibility is possible regarding QAP tests on functions of such statistics (see an equivalent discussion with respect to CUG null hypothesis tests in Anderson et al. (1999)).  See below for more details. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qaptest(dat, FUN, reps=1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qaptest_+3A_dat">dat</code></td>
<td>
<p> graphs to be analyzed.  Though one could in principle use a single graph, this is rarely if ever sensible in a QAP-test context.</p>
</td></tr>
<tr><td><code id="qaptest_+3A_fun">FUN</code></td>
<td>
<p> function to generate the test statistic.  <code>FUN</code> must accept <code>dat</code> and the specified <code>g</code> arguments, and should return a real number. </p>
</td></tr>
<tr><td><code id="qaptest_+3A_reps">reps</code></td>
<td>
<p> integer indicating the number of draws to use for quantile estimation.  Note that, as for all Monte Carlo procedures, convergence is slower for more extreme quantiles.  By default, <code>reps</code>=1000. </p>
</td></tr>
<tr><td><code id="qaptest_+3A_...">...</code></td>
<td>
<p> additional arguments to <code>FUN</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The null hypothesis of the QAP test is that the observed graph-level statistic on graphs <code class="reqn">G_1,G_2,\dots</code> was drawn from the distribution of said statistic evaluated (uniformly) on the set of all relabelings of <code class="reqn">G_1,G_2,\dots</code>.  Pragmatically, this test is performed by repeatedly (randomly) relabeling the input graphs, recalculating the test statistic, and then evaluating the fraction of draws greater than or equal to (and less than or equal to) the observed value.  This accumulated fraction approximates the integral of the distribution of the test statistic over the set of unlabeled input graphs.
</p>
<p>The <code>qaptest</code> procedure returns a <code>qaptest</code> object containing the estimated likelihood (distribution of the test statistic under the null hypothesis), the observed value of the test statistic on the input data, and the one-tailed p-values (estimated quantiles) associated with said observation.  As usual, the (upper tail) null hypothesis is rejected for significance level alpha if p&gt;=observation is less than alpha (or p&lt;=observation, for the lower tail); if the hypothesis is undirected, then one rejects if either p&lt;=observation or p&gt;=observation is less then alpha/2.  Standard caveats regarding the use of null hypothesis testing procedures are relevant here: in particular, bear in mind that a significant result does not necessarily imply that the likelihood ratio of the null model and the alternative hypothesis favors the latter.
</p>
<p>In interpreting a QAP test, it is important to bear in mind the nature of the QAP null hypothesis.  The QAP test should <em>not</em> be interpreted as evaluating underlying structural differences; indeed, QAP is more accurately understood as testing differences induced by a particular vertex labeling <em>controlling for</em> underlying structure.  Where there is substantial automorphism in the underling structures, QAP will tend to given non-significant results.  (In fact, it is <em>impossible</em> to obtain a one-tailed significance level in excess of <code class="reqn">\max_{g \in \{G,H\}} \frac{|Aut(g)|}{|Perm(g)|}</code> when using a QAP test on a bivariate graph statistic <code class="reqn">f(G,H)</code>, where Aut(g) and Perm(g) are the automorphism and permutation groups on g, respectively.  This follows from the fact that all members of Aut(g) will induce the same values of <code class="reqn">f()</code>.)  By turns, significance under QAP does not necessarily imply that the observed structural relationship is unusual relative to what one would expect from typical structures with (for instance) the sizes and densities of the graphs in question.  In contexts in which one's research question implies a particular labeling of vertices (e.g., &quot;within this group of individuals, do friends also tend to give advice to one another&quot;), QAP can be a very useful way of ruling out spurious structural influences (e.g., some respondents tend to indiscriminately nominate many people (without regard to whom), resulting in a structural similarity which has nothing to do with the identities of those involved).  Where one's question does not imply a labeled relationship (e.g., is the <em>shape</em> of this group's friendship network similar to that of its advice network), the QAP null hypothesis is inappropriate.
</p>


<h3>Value</h3>

<p>An object of class <code>qaptest</code>, containing
</p>
<table>
<tr><td><code>testval</code></td>
<td>

<p>The observed value of the test statistic.
</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>

<p>A vector containing the Monte Carlo draws. 
</p>
</td></tr>
<tr><td><code>pgreq</code></td>
<td>

<p>The proportion of draws which were greater than or equal to the observed value.
</p>
</td></tr>
<tr><td><code>pleeq</code></td>
<td>

<p>The proportion of draws which were less than or equal to the observed value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Anderson, B.S.; Butts, C.T.; and Carley, K.M. (1999). &ldquo;The Interaction of Size and Density with Graph-Level Indices.&rdquo; <em>Social Networks</em>, 21(3), 239-267.
</p>
<p>Hubert, L.J., and Arabie, P.  (1989).  &ldquo;Combinatorial Data Analysis: Confirmatory Comparisons Between Sets of Matrices.&rdquo;  <em>Applied Stochastic Models and Data Analysis</em>, 5, 273-325.
</p>
<p>Krackhardt, D.  (1987).  &ldquo;QAP Partialling as a Test of Spuriousness.&rdquo; <em>Social Networks</em>, 9 171-186.
</p>
<p>Krackhardt, D.  (1988).  &ldquo;Predicting With Networks: Nonparametric Multiple Regression Analyses of Dyadic Data.&rdquo;  <em>Social Networks</em>, 10, 359-382. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+cugtest">cugtest</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Generate three graphs
g&lt;-array(dim=c(3,10,10))
g[1,,]&lt;-rgraph(10)
g[2,,]&lt;-rgraph(10,tprob=g[1,,]*0.8)
g[3,,]&lt;-1; g[3,1,2]&lt;-0              #This is nearly a clique

#Perform qap tests of graph correlation
q.12&lt;-qaptest(g,gcor,g1=1,g2=2)
q.13&lt;-qaptest(g,gcor,g1=1,g2=3)

#Examine the results
summary(q.12)
plot(q.12)
summary(q.13)
plot(q.13)
</code></pre>

<hr>
<h2 id='reachability'> Find the Reachability Matrix of a Graph </h2><span id='topic+reachability'></span><span id='topic+reachability_R'></span>

<h3>Description</h3>

<p><code>reachability</code> takes one or more (possibly directed) graphs as input, producing the associated reachability matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reachability(dat, geodist.precomp=NULL, return.as.edgelist=FALSE, na.omit=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reachability_+3A_dat">dat</code></td>
<td>
<p> one or more graphs (directed or otherwise). </p>
</td></tr>
<tr><td><code id="reachability_+3A_geodist.precomp">geodist.precomp</code></td>
<td>
<p> optionally, a precomputed <code><a href="#topic+geodist">geodist</a></code> object. </p>
</td></tr>
<tr><td><code id="reachability_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; return the result as an sna edgelist? </p>
</td></tr>
<tr><td><code id="reachability_+3A_na.omit">na.omit</code></td>
<td>
<p> logical; omit missing edges when computing reach? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a digraph <code class="reqn">G=(V,E)</code> with vertices <code class="reqn">i</code> and <code class="reqn">j</code>, let <code class="reqn">P_{ij}</code> represent a directed <code class="reqn">ij</code> path.  Then the (di)graph
</p>
<p style="text-align: center;"><code class="reqn">
R = \left(V\left(G\right),\left\{\left(i,j\right):i,j \in V\left(G\right), P_{ij} \in G\right\}\right)</code>
</p>

<p>is said to be the <em>reachability graph</em> of <code class="reqn">G</code>, and the adjacency matrix of <code class="reqn">R</code> is said to be <code class="reqn">G</code>'s <em>reachability matrix</em>.  (Note that when <code class="reqn">G</code> is undirected, we simply take each undirected edge to be bidirectional.)  Vertices which are adjacent in the reachability graph are connected by one or more directed paths in the original graph; thus, structural equivalence classes in the reachability graph are synonymous with strongly connected components in the original structure.
</p>
<p>Bear in mind that &ndash; as with all matters involving connectedness &ndash; reachability is strongly related to size and density.  Since, for any given density, almost all structures of sufficiently large size are connected, reachability graphs associated with large structures will generally be complete.  Measures based on the reachability graph, then, will tend to become degenerate in the large <code class="reqn">|V(G)|</code> limit (assuming constant positive density).
</p>
<p>By default, <code>reachability</code> will try to build the reachability graph using an internal sparse graph approximation; this is no help on fully connected graphs (but not a lot worse than using an adjacency matrix), but will result in considerable savings for large graphs that are heavily fragmented.  (The intended design tradeoff is thus that one pays a small cost on the usually cheap cases, in exchange for much greater efficiency on the cases that would otherwise be prohibitively expensive.)  If <code>geodist.precomp</code> is given, however, the <code class="reqn">O(N^2)</code> cost of an adjacency matrix representation has already been paid, and we simply employ what we are given &ndash; so, if you want to force the internal use of adjacency matrices, just pass a <code><a href="#topic+geodist">geodist</a></code> object.  Because the internal representation used is otherwise list based, using <code>return.as.edgelist=TRUE</code> will save resources; if you are using <code>reachability</code> as part of a more complex series of calls, it is thus recommended that you both pass and return sna edgelists unless you have a good reason not to do so.
</p>
<p>When set, <code>na.omit</code> results in missing edges (i.e., edges with <code>NA</code> values) being removed prior to computation.  Since paths are not recomputed when <code>geodist.precomp</code> is passed, this option is only active when <code>geodist.precomp==NULL</code>; if this behavior is desired and precomputed distances are being used, such edges should be removed prior to the <code><a href="#topic+geodist">geodist</a></code> call.
</p>


<h3>Value</h3>

<p>A reachability matrix, or the equivalent edgelist representation
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+geodist">geodist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Find the reachability matrix for a sparse random graph
g&lt;-rgraph(10,tprob=0.15)
rg&lt;-reachability(g)
g  #Compare the two structures
rg

#Compare to the output of geodist
all(rg==(geodist(g)$counts&gt;0))
</code></pre>

<hr>
<h2 id='read.dot'> Read Graphviz DOT Files </h2><span id='topic+read.dot'></span>

<h3>Description</h3>

<p>Reads network information in Graphviz's DOT format, returning an adjacency matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.dot(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.dot_+3A_...">...</code></td>
<td>
<p> The name of the file whence to import the data, or else a connection object (suitable for processing by <code><a href="base.html#topic+readLines">readLines</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Graphviz project's DOT language is a simple but flexible tool for describing graphs.  See the included reference for details.
</p>


<h3>Value</h3>

<p>The imported graph, in adjacency matrix form.
</p>


<h3>Author(s)</h3>

<p> Matthijs den Besten <a href="mailto:matthijs.denbesten@gmail.com">matthijs.denbesten@gmail.com</a> </p>


<h3>References</h3>

<p> Graphviz Project.  &quot;The DOT Language.&quot;  http://www.graphviz.org/doc/info/lang.html </p>


<h3>See Also</h3>

 <p><code><a href="#topic+read.nos">read.nos</a></code>, <code><a href="#topic+write.nos">write.nos</a></code>, <code><a href="#topic+write.dl">write.dl</a></code> </p>

<hr>
<h2 id='read.nos'> Read (N)eo-(O)rg(S)tat Input Files</h2><span id='topic+read.nos'></span>

<h3>Description</h3>

<p>Reads an input file in NOS format, returning the result as a graph set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.nos(file, return.as.edgelist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.nos_+3A_file">file</code></td>
<td>
<p> the file to be imported </p>
</td></tr>
<tr><td><code id="read.nos_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; should the resulting graphs be returned in sna edgelist format?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>NOS format consists of three header lines, followed by a whitespace delimited stack of raw adjacency matrices; the format is not particularly elegant, but turns up in certain legacy applications (mostly at CMU).  <code>read.nos</code> provides a quick and dirty way of reading in these files, without the headache of messing with <code><a href="utils.html#topic+read.table">read.table</a></code> settings.
</p>
<p>The content of the NOS format is as follows:
</p>
<p>&lt;m&gt;
</p>
<p>&lt;n&gt; &lt;o&gt;
</p>
<p>&lt;kr1&gt; &lt;kr2&gt; ... &lt;krn&gt; &lt;kc1&gt; &lt;kc2&gt; ... &lt;kcn&gt;
</p>
<p>&lt;a111&gt; &lt;a112&gt; ... &lt;a11o&gt;
</p>
<p>&lt;a121&gt; &lt;a122&gt; ... &lt;a12o&gt;
</p>
<p>...
</p>
<p>&lt;a1n1&gt; &lt;a1n2&gt; ... &lt;a1no&gt;
</p>
<p>&lt;a211&gt; &lt;a212&gt; ... &lt;a21o&gt;
</p>
<p>...
</p>
<p>&lt;a2n1&gt; &lt;a2n2&gt; ... &lt;a2no&gt;
</p>
<p>...
</p>
<p>&lt;amn1&gt; &lt;amn2&gt; ... &lt;amno&gt;
</p>
<p>where &lt;abcd&gt; is understood to be the value of the c-&gt;d edge in the bth graph of the file.  (As one might expect, m, n, and o are the numbers of graphs (matrices), rows, and columns for the data, respectively.)  The &quot;k&quot; line contains a list of row and column &quot;colors&quot;, categorical variables associated with each row and column, respectively.  Although originally intended to communicate exchangability information, these can be used for other purposes (though there are easier ways to deal with attribute data these days).
</p>


<h3>Value</h3>

<p>The imported graph set (in adjacency array or edgelist form).
</p>


<h3>Note</h3>

 <p><code>read.nos</code> currently ignores the coloring information. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+write.nos">write.nos</a></code>, <code><a href="base.html#topic+scan">scan</a></code>, <code><a href="utils.html#topic+read.table">read.table</a></code> </p>

<hr>
<h2 id='redist'>
Find a Matrix of Distances Between Positions Based on Regular Equivalence
</h2><span id='topic+redist'></span>

<h3>Description</h3>

<p><code>redist</code> uses the graphs indicated by <code>g</code> in <code>dat</code> to assess the extent to which each vertex is regularly equivalent; <code>method</code> determines the measure of approximate equivalence which is used (currently, only CATREGE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>redist(dat, g = NULL, method = c("catrege"), mode = "digraph", 
    diag = FALSE, seed.partition = NULL, code.diss = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="redist_+3A_dat">dat</code></td>
<td>

<p>a graph or set thereof.
</p>
</td></tr>
<tr><td><code id="redist_+3A_g">g</code></td>
<td>

<p>a vector indicating which elements of <code>dat</code> should be examined (by default, all are used).
</p>
</td></tr>
<tr><td><code id="redist_+3A_method">method</code></td>
<td>

<p>method to use when assessing regular equivalence (currently, only <code>"catrege"</code>).
</p>
</td></tr>
<tr><td><code id="redist_+3A_mode">mode</code></td>
<td>

<p><code>"digraph"</code> for directed data, otherwise <code>"graph"</code>. 
</p>
</td></tr>
<tr><td><code id="redist_+3A_diag">diag</code></td>
<td>

<p>logical; should diagonal entries (loops) should be treated as meaningful data?
</p>
</td></tr>
<tr><td><code id="redist_+3A_seed.partition">seed.partition</code></td>
<td>

<p>optionally, an initial equivalence partition to &ldquo;seed&rdquo; the CATREGE algorithm.
</p>
</td></tr>
<tr><td><code id="redist_+3A_code.diss">code.diss</code></td>
<td>

<p>logical; return as dissimilarities (rather than similarities)?
</p>
</td></tr>
<tr><td><code id="redist_+3A_...">...</code></td>
<td>

<p>additional parameters (currently ignored).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>redist</code> provides a basic tool for assessing the (approximate) regular equivalence of actors.  Two vertices <code class="reqn">i</code> and <code class="reqn">j</code> are said to be regularly equivalent with respect to role assignment <code>r</code> if <code class="reqn">\{r(u): u\in N^+(i)\}=\{r(u): u\in N^+(j)\}</code> and <code class="reqn">\{r(u): u\in N^-(i)\}=\{r(u): u\in N^-(j)\}</code>, where <code class="reqn">N^+</code> and <code class="reqn">N^-</code> denote out- and in-neighborhoods (respectively).  RE similarity/difference scores are computed by <code>method</code>, currently Borgatti and Everett's CATREGE algorithm (which is based on the multiplex maximal regular equivalence on <code class="reqn">G</code> and its transpose).  The &ldquo;distance&rdquo; between positions in this case is the inverse of the number of iterative refinements of the initial equivalence (i.e., role) structure required to allocate the positions to regularly equivalent roles (with 0 indicating positions which ultimately belong in the same role).  By default, the initial equivalence structure is one in which all vertices are treated as occupying the same role; the <code>seed.partition</code> option can be used to impose alternative constraints.  From this initial structure, vertices within the same role having non-identical mixes of neighbor types are re-allocated to different roles (where &ldquo;neighbor type&rdquo; is initially due to the pattern of (possibly valued) in- and out-ties, cross-classified by current alter type).  This procedure is then iterated until no further division of roles is necessary to satisfy the regularity condition.
</p>
<p>Once the similarities/differences are calculated, the results can be used with a clustering routine (such as <code><a href="#topic+equiv.clust">equiv.clust</a></code>) or an MDS (such as <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>) to identify the underlying role structure.
</p>


<h3>Value</h3>

<p>A matrix of similarity/difference scores.
</p>


<h3>Note</h3>

<p>The maximal regular equivalence is often very uninteresting (i.e., degenerate) for unvalued, undirected graphs.  An exogenous constraint (e.g., via the <code>seed.partition</code>) may be required to uncover a more useful refinement of the unconstrained maximal equivalence.
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Borgatti, S.P. and Everett, M.G.  (1993).  &ldquo;Two Algorithms for Computing Regular Equivalence.&rdquo;  <em>Social Networks</em>, 15, 361-376.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sedist">sedist</a></code>, <code><a href="#topic+equiv.clust">equiv.clust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a random graph with _some_ edge structure
g.p&lt;-sapply(runif(20,0,1),rep,20)  #Create a matrix of edge 
                                   #probabilities
g&lt;-rgraph(20,tprob=g.p)            #Draw from a Bernoulli graph 
                                   #distribution

#Get RE distances
g.re&lt;-redist(g)

#Plot a metric MDS of vertex positions in two dimensions
plot(cmdscale(as.dist(g.re)))

#What if there were already something known to be different about
#the first five vertices?
sp&lt;-rep(1:2,times=c(5,15))            #Create "seed" partition
g.spre&lt;-redist(g,seed.partition=sp)   #Get new RE distances
g.spre
plot.sociomatrix(g.spre)              #Note the blocking! 
</code></pre>

<hr>
<h2 id='rgbn'> Draw from a Skvoretz-Fararo Biased Net Process </h2><span id='topic+rgbn'></span><span id='topic+bn_cftp_R'></span><span id='topic+bn_mcmc_R'></span>

<h3>Description</h3>

<p>Produces a series of draws from a Skvoretz-Fararo biased net process using a (pseudo) Gibbs sampler or exact sampling procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgbn(n, nv, param = list(pi=0, sigma=0, rho=0, d=0.5, delta=0),
    burn = nv*nv*5*100, thin = nv*nv*5, maxiter = 1e7,
    method = c("mcmc","cftp"), dichotomize.sib.effects = FALSE,
    return.as.edgelist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rgbn_+3A_n">n</code></td>
<td>
<p> number of draws to take. </p>
</td></tr>
<tr><td><code id="rgbn_+3A_nv">nv</code></td>
<td>
<p> number of vertices in the graph to be simulated. </p>
</td></tr>
<tr><td><code id="rgbn_+3A_param">param</code></td>
<td>
<p> a list containing the biased net parameters (as described below); <code class="reqn">d</code> may be given as a scalar or as an <code>nv x nv</code> matrix of edgewise baseline edge probabilities.</p>
</td></tr>
<tr><td><code id="rgbn_+3A_burn">burn</code></td>
<td>
<p> for the Gibbs sampler, the number of burn-in draws to take (and discard). </p>
</td></tr>
<tr><td><code id="rgbn_+3A_thin">thin</code></td>
<td>
<p> the thinning parameter for the Gibbs sampler. </p>
</td></tr>
<tr><td><code id="rgbn_+3A_maxiter">maxiter</code></td>
<td>
<p> for the CFTP method, the number of iterations to try before giving up.</p>
</td></tr>
<tr><td><code id="rgbn_+3A_method">method</code></td>
<td>
 <p><code>"mcmc"</code> for the Gibbs sampler, or <code>"cftp"</code> for the exact sampling procedure.</p>
</td></tr>
<tr><td><code id="rgbn_+3A_dichotomize.sib.effects">dichotomize.sib.effects</code></td>
<td>
<p> logical; should sibling and double role effects be dichotomized?</p>
</td></tr> 
<tr><td><code id="rgbn_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; should the simulated draws be returned in edgelist format?</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The biased net model stems from early work by Rapoport, who attempted to model networks via a hypothetical &ldquo;tracing&rdquo; process.  This process may be described loosely as follows.  One begins with a small &ldquo;seed&rdquo; set of vertices, each member of which is assumed to nominate (generate ties to) other members of the population with some fixed probability.  These members, in turn, may nominate new members of the population, as well as members who have already been reached.  Such nominations may be &ldquo;biased&rdquo; in one fashion or another, leading to a non-uniform growth process. 
</p>
<p>While the original biased net model depends upon the tracing process, a local interpretation has been put forward by Skvoretz and colleagues in recent years.  Using the standard four-parameter process, the conditional probability of an <code class="reqn">(i,j)</code> edge given all other edges in a random graph <code class="reqn">G</code> can be approximated as
</p>
<p style="text-align: center;"><code class="reqn">
\Pr(i \to j|G_{-ij}) \approx 1 - (1-\rho)^z (1-\sigma)^y (1-\pi)^x (1-d_{ij})
</code>
</p>

<p>where <code class="reqn">x=1</code> iff <code class="reqn">j \to i</code> (and 0 otherwise), <code class="reqn">y</code> is the number of vertices <code class="reqn">k \neq i,j</code> such that <code class="reqn">k \to i, k \to j</code>, and <code class="reqn">z=1</code> iff <code class="reqn">x=1</code> and <code class="reqn">y&gt;0</code> (and 0 otherwise).  Thus, <code class="reqn">x</code> is the number of potential <em>parent bias</em> events, <code class="reqn">y</code> is the number of potential <em>sibling bias</em> events, and <code class="reqn">z</code> is the number of potential <em>double role bias</em> events.  <code class="reqn">d_{ij}</code> is the probability of the baseline edge event; note that an edge arises if the baseline event or any bias event occurs, and all events are assumed conditionally independent.  Written in this way, it is clear that the edges of <code class="reqn">G</code> are conditionally independent if they share no endpoint.  Thus, a  model with the above structure should be a subfamily of the Markov graphs.
</p>
<p>One potential problem with the above structure is that the hypothetical probabilities implied by the model are not guaranteed to be consistent - that is, the conditions under which there exists a joint pmf with the implied full conditionals are currently unknown (and may be restrictive).  The interpretation of the above as exact conditional probabilities is thus potentially problematic.  However, a well-defined process can be constructed by interpreting the above as transition probabilities for a Markov chain that evolves by updating a randomly selected edge variable at each time point; this is a Gibbs sampler for the implied joint pmf where it exists, and otherwise an irreducible and aperiodic Markov chain with a well-defined equilibrium distribution.
</p>
<p>In the above process, all events act to promote the formation of edges; it is also possible to define events that inhibit them.  For instance, consider a <em>satiation</em> event that, if it occurs, forbids the creation of an <code class="reqn">i \to j</code> edge; we assume that a potential satiation event occurs every time <code class="reqn">i</code> emits an edge to some other vertex.  The associated approximate conditional (i.e., transition probability) is
</p>
<p style="text-align: center;"><code class="reqn">
\Pr(i \to j|G_{-ij}) \approx (1-\delta)^w\left(1 - (1-\rho)^z (1-\sigma)^y (1-\pi)^x (1-d_{ij})\right)
</code>
</p>

<p>where <code class="reqn">w</code> is the outdegree of <code class="reqn">i</code> in <code class="reqn">G_{-ij}</code> and <code class="reqn">\delta</code> is the probability of the satiation event.  The net effect of satiation is to suppress edge formation (in roughly geometric fashion) on high degree nodes.  This may be useful in preventing degeneracy when using sigma and rho effects.  Degeneracy can also be reduced by employing the <code>dichotomize.sib.effects</code> argument, which counts only the first shared partner's contribution towards sibling and double role effects.
</p>
<p>It should be noted that the above process is not entirely consistent with the tracing-based model, which is itself not uniformly well-specified in the literature.  For this reason, the local model is referred to here as a Skvoretz-Fararo graph process.  One significant advantage of this process is that it is well-defined, and easily simulated: the above equation can be used to form the basis of a (pseudo-) Gibbs sampler, which is used by <code class="reqn">rgbn</code> to take draws from the (local) biased net model.  Burn-in and thinning are controlled by the corresponding arguments; since degeneracy is common with models of this type, it is advisable to check for adequate mixing.  An alternative simulation strategy is the exact sampling procedure of Butts (2018), which employs a form of coupling from the past (CFTP).  The CFTP method generates exact, independent draws from the equilibrium distribution of the biased net process (up to numerical limits), but can be slow to attain coalescence (and does not currently support satiation events).  Setting <code>maxiter</code> to smaller values limits the search depth employed, at the possible cost of biasing the resulting sample.
</p>


<h3>Value</h3>

<p>An adjacency array containing the simulated graphs.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a></p>


<h3>References</h3>

 
<p>Butts, C.T.  (2018).  &ldquo;A Perfect Sampling Method for Exponential Family Random Graph Models.&rdquo; <em>Journal of Mathematical Sociology</em>, 42(1), 17-36.
</p>
<p>Rapoport, A.  (1957).  &ldquo;A Contribution to the Theory of Random and Biased Nets.&rdquo;  <em>Bulletin of Mathematical Biophysics,</em> 15, 523-533.
</p>
<p>Skvoretz, J.; Fararo, T.J.; and Agneessens, F.  (2004).  &ldquo;Advances in Biased Net Theory: Definitions, Derivations, and Estimations.&rdquo;  <em>Social Networks,</em> 26, 113-139.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+bn">bn</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate draws with low density and no biases
g1&lt;-rgbn(50,10,param=list(pi=0, sigma=0, rho=0, d=0.17))
apply(dyad.census(g1),2,mean) #Examine the dyad census

#Add a reciprocity bias
g2&lt;-rgbn(50,10,param=list(pi=0.5, sigma=0, rho=0, d=0.17))
apply(dyad.census(g2),2,mean) #Compare with g1

#Alternately, add a sibling bias
g3&lt;-rgbn(50,10,param=list(pi=0.0, sigma=0.3, rho=0, d=0.17))
mean(gtrans(g3))              #Compare transitivity scores
mean(gtrans(g1))

</code></pre>

<hr>
<h2 id='rgnm'> Draw Density-Conditioned Random Graphs </h2><span id='topic+rgnm'></span>

<h3>Description</h3>

<p><code>rgnm</code> generates random draws from a density-conditioned uniform random graph distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgnm(n, nv, m, mode = "digraph", diag = FALSE, 
    return.as.edgelist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rgnm_+3A_n">n</code></td>
<td>
<p> the number of graphs to generate. </p>
</td></tr>
<tr><td><code id="rgnm_+3A_nv">nv</code></td>
<td>
<p> the size of the vertex set (<code class="reqn">|V(G)|</code>) for the random graphs. </p>
</td></tr>
<tr><td><code id="rgnm_+3A_m">m</code></td>
<td>
<p> the number of edges on which to condition. </p>
</td></tr>
<tr><td><code id="rgnm_+3A_mode">mode</code></td>
<td>
 <p><code>"digraph"</code> for directed graphs, or <code>"graph"</code> for undirected graphs. </p>
</td></tr>
<tr><td><code id="rgnm_+3A_diag">diag</code></td>
<td>
<p> logical; should loops be allowed? </p>
</td></tr>
<tr><td><code id="rgnm_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; should the resulting graphs be returned in edgelist form?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rgnm</code> returns draws from the density-conditioned uniform random graph first popularized by the famous work of Erdos and Renyi (the <code class="reqn">G(N,M)</code> process).  In particular, the pmf of a <code class="reqn">G(N,M)</code> process is given by
</p>
<p style="text-align: center;"><code class="reqn">
p(G=g|N,M) = \left( {E_m \atop M} \right)^{-1}
</code>
</p>

<p>where <code class="reqn">E_m</code> is the maximum number of edges in the graph.  (<code class="reqn">E_m</code> is equal to <code>nv*(nv-diag)/(1+(mode=="graph"))</code>.)
</p>
<p>The <code class="reqn">G(N,M)</code> process is one of several process which are used as baseline models of social structure.  Other well-known baseline models include the Bernoulli graph (the <code class="reqn">G(N,p)</code> model of Erdos and Renyi) and the U|MAN model of dyadic independence.  These are implemented within <code>sna</code> as <code><a href="#topic+rgraph">rgraph</a></code> and <code><a href="#topic+rgnm">rgnm</a></code>, respectively.
</p>


<h3>Value</h3>

<p>A matrix or array containing the drawn adjacency matrices
</p>


<h3>Note</h3>

<p> The famous mathematicians referenced in this man page now have misspelled names, due to R's difficulty with accent marks.   </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Erdos, P. and Renyi, A.  (1960).  &ldquo;On the Evolution of Random Graphs.&rdquo;  <em>Public Mathematical Institute of Hungary Academy of Sciences,</em> 5:17-61. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rgraph">rgraph</a></code>, <code><a href="#topic+rguman">rguman</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw 5 random graphs of order 10 
all(gden(rgnm(5,10,9,mode="graph"))==0.2) #Density 0.2
all(gden(rgnm(5,10,9))==0.1)              #Density 0.1

#Plot a random graph
gplot(rgnm(1,10,20))
</code></pre>

<hr>
<h2 id='rgnmix'>
Draw Mixing-Conditioned Random Graphs
</h2><span id='topic+rgnmix'></span>

<h3>Description</h3>

<p><code>rgnmix</code> generates random draws from a mixing-conditioned uniform random graph distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgnmix(n, tv, mix, mode = "digraph", diag = FALSE, 
    method = c("probability", "exact"), return.as.edgelist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rgnmix_+3A_n">n</code></td>
<td>

<p>the number of graphs to generate.
</p>
</td></tr>
<tr><td><code id="rgnmix_+3A_tv">tv</code></td>
<td>

<p>a vector of types or classes (one entry per vertex), corresponding to the rows and columns of <code>mix</code>.  (Note that the total number of vertices generated will be <code>length(tv)</code>.)
</p>
</td></tr>
<tr><td><code id="rgnmix_+3A_mix">mix</code></td>
<td>

<p>a class-by-class mixing matrix, containing either mixing rates (for <code>method=="probability"</code>) or edge counts (for <code>method=="exact"</code>).
</p>
</td></tr>
<tr><td><code id="rgnmix_+3A_mode">mode</code></td>
<td>

<p><code>"digraph"</code> for directed graphs, or <code>"graph"</code> for undirected graphs.
</p>
</td></tr>
<tr><td><code id="rgnmix_+3A_diag">diag</code></td>
<td>

<p>logical; should loops be allowed?
</p>
</td></tr>
<tr><td><code id="rgnmix_+3A_method">method</code></td>
<td>

<p>the generation method to use.  <code>"probability"</code> results in a Bernoulli edge distribution (conditional on the underlying rates), while <code>"exact"</code> results in a uniform draw conditional on the exact per-block edge distribution.
</p>
</td></tr>
<tr><td><code id="rgnmix_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>

<p>logical; should the resulting graphs be returned in sna edgelist form?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generated graphs (in either adjacency or edgelist form).
</p>


<h3>Value</h3>

<p><code>rgnmix</code> draws from a simple generalization of the Erdos-Renyi N,M family (and the related N,p family), generating graphs with fixed expected or realized mixing rates.  Mixing is determined by the <code>mix</code> argument, which must contain a class-by-class matrix of mixing rates (either edge probabilities or number of realized edges).  The class for each vertex is specified in <code>tv</code>, whose entries must correspond to the rows and columns of <code>mix</code>.  The resulting functionality is much like <code><a href="#topic+blockmodel.expand">blockmodel.expand</a></code>, although more general (and in some cases more efficient).
</p>


<h3>Author(s)</h3>

<p>Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>References</h3>

<p>Wasserman, S. and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rguman">rguman</a></code>, <code><a href="#topic+rgnm">rgnm</a></code>, <code><a href="#topic+blockmodel.expand">blockmodel.expand</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Draw a random mixing matrix
mix&lt;-matrix(runif(9),3,3)

#Generate a graph with 4 members per class
g&lt;-rgnmix(1,rep(1:3,each=4),mix)
plot.sociomatrix(g)                                 #Visualize the result

#Repeat the exercise, using the exact method
mix2&lt;-round(mix*8)                                  #Draw an exact matrix
g&lt;-rgnmix(1,rep(1:3,each=4),mix2,method="exact")
plot.sociomatrix(g)
</code></pre>

<hr>
<h2 id='rgraph'> Generate Bernoulli Random Graphs </h2><span id='topic+rgraph'></span><span id='topic+rgbern_R'></span>

<h3>Description</h3>

<p><code>rgraph</code> generates random draws from a Bernoulli graph distribution, with various parameters for controlling the nature of the data so generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgraph(n, m=1, tprob=0.5, mode="digraph", diag=FALSE, replace=FALSE,
    tielist=NULL, return.as.edgelist=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rgraph_+3A_n">n</code></td>
<td>
<p> The size of the vertex set (|V(G)|) for the random graphs </p>
</td></tr>
<tr><td><code id="rgraph_+3A_m">m</code></td>
<td>
<p> The number of graphs to generate </p>
</td></tr>
<tr><td><code id="rgraph_+3A_tprob">tprob</code></td>
<td>
<p> Information regarding tie (edge) probabilities; see below </p>
</td></tr>
<tr><td><code id="rgraph_+3A_mode">mode</code></td>
<td>
<p> &ldquo;digraph&rdquo; for directed data, &ldquo;graph&rdquo; for undirected data </p>
</td></tr>
<tr><td><code id="rgraph_+3A_diag">diag</code></td>
<td>
<p> Should the diagonal entries (loops) be set to zero? </p>
</td></tr>
<tr><td><code id="rgraph_+3A_replace">replace</code></td>
<td>
<p> Sample with or without replacement from a tie list (ignored if <code>tielist==NULL</code> </p>
</td></tr>
<tr><td><code id="rgraph_+3A_tielist">tielist</code></td>
<td>
<p> A vector of edge values, from which the new graphs should be bootstrapped </p>
</td></tr>
<tr><td><code id="rgraph_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; should the resulting graphs be returned in edgelist form?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rgraph</code> is a reasonably versatile routine for generating random network data.  The graphs so generated are either Bernoulli graphs (graphs in which each edge is a Bernoulli trial, independent conditional on the Bernoulli parameters), or are bootstrapped from a user-provided edge distribution (very handy for CUG tests).  In the latter case, edge data should be provided using the <code>tielist</code> argument; the exact form taken by the data is irrelevant, so long as it can be coerced to a vector.  In the former case, Bernoulli graph probabilities are set by the <code>tprob</code> argument as follows:
</p>

<ol>
<li><p> If <code>tprob</code> contains a single number, this number is used as the probability of all edges.
</p>
</li>
<li><p> If <code>tprob</code> contains a vector, each entry is assumed to correspond to a separate graph (in order).  Thus, each entry is used as the probability of all edges within its corresponding graph.
</p>
</li>
<li><p> If <code>tprob</code> contains a matrix, then each entry is assumed to correspond to a separate edge.  Thus, each entry is used as the probability of its associated edge in each graph which is generated.
</p>
</li>
<li><p> Finally, if <code>tprob</code> contains a three-dimensional array, then each entry is assumed to correspond to a particular edge in a particular graph, and is used as the associated probability parameter.
</p>
</li></ol>

<p>Finally, note that <code>rgraph</code> will symmetrize all generated networks if <code>mode</code> is set to &ldquo;graph&rdquo; by copying down the upper triangle.  The lower half of <code>tprob</code>, where applicable, must still be specified, however.
</p>


<h3>Value</h3>

<p>A graph stack
</p>


<h3>Note</h3>

<p> The famous mathematicians referenced in this man page now have misspelled names, due to R's difficulty with accent marks.  </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Erdos, P. and Renyi, A.  (1960).  &ldquo;On the Evolution of Random Graphs.&rdquo;  <em>Public Mathematical Institute of Hungary Academy of Sciences,</em> 5:17-61.
</p>
<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications</em>.  Cambridge: Cambridge University Press. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rmperm">rmperm</a></code>, <code><a href="#topic+rgnm">rgnm</a></code>, <code><a href="#topic+rguman">rguman</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Generate three graphs with different densities
g&lt;-rgraph(10,3,tprob=c(0.1,0.9,0.5))

#Generate from a matrix of Bernoulli parameters
g.p&lt;-matrix(runif(25,0,1),nrow=5)
g&lt;-rgraph(5,2,tprob=g.p)
</code></pre>

<hr>
<h2 id='rguman'> Draw Dyad Census-Conditioned Random Graphs </h2><span id='topic+rguman'></span>

<h3>Description</h3>

<p><code>rguman</code> generates random draws from a dyad census-conditioned uniform random graph distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rguman(n, nv, mut = 0.25, asym = 0.5, null = 0.25, 
    method = c("probability", "exact"), return.as.edgelist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rguman_+3A_n">n</code></td>
<td>
<p> the number of graphs to generate. </p>
</td></tr>
<tr><td><code id="rguman_+3A_nv">nv</code></td>
<td>
<p> the size of the vertex set (<code class="reqn">|V(G)|</code>) for the random graphs. </p>
</td></tr>
<tr><td><code id="rguman_+3A_mut">mut</code></td>
<td>
<p> if <code>method=="probability"</code>, the probability of obtaining a mutual dyad; otherwise, the number of mutual dyads. </p>
</td></tr>
<tr><td><code id="rguman_+3A_asym">asym</code></td>
<td>
<p> if <code>method=="probability"</code>, the probability of obtaining an asymmetric dyad; otherwise, the number of asymmetric dyads. </p>
</td></tr>
<tr><td><code id="rguman_+3A_null">null</code></td>
<td>
<p> if <code>method=="probability"</code>, the probability of obtaining a null dyad; otherwise, the number of null dyads. </p>
</td></tr>
<tr><td><code id="rguman_+3A_method">method</code></td>
<td>
<p> the generation method to use.  <code>"probability"</code> results in a multinomial dyad distribution (conditional on the underlying rates), while <code>"exact"</code> results in a uniform draw conditional on the exact dyad distribution. </p>
</td></tr>
<tr><td><code id="rguman_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; should the resulting graphs be returned in edgelist form?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple generalization of the Erdos-Renyi family, the U|MAN distributions are uniform on the set of graphs, conditional on order (size) and the dyad census.  As with the E-R case, there are two U|MAN variants.  The first (corresponding to <code>method=="probability"</code>) takes dyad states as independent multinomials with parameters <code class="reqn">m</code> (for mutuals), <code class="reqn">a</code> (for asymmetrics), and <code class="reqn">n</code> (for nulls).  The resulting pmf is then
</p>
<p style="text-align: center;"><code class="reqn">
p(G=g|m,a,n) = \frac{(M+A+N)!}{M!A!N!} m^M a^A n^N,
</code>
</p>

<p>where <code class="reqn">M</code>, <code class="reqn">A</code>, and <code class="reqn">N</code> are realized counts of mutual, asymmetric, and null dyads, respectively.  (See <code><a href="#topic+dyad.census">dyad.census</a></code> for an explication of dyad types.) 
</p>
<p>The second U|MAN variant is selected by <code>method=="exact"</code>, and places equal mass on all graphs having the specified (exact) dyad census.  The corresponding pmf is
</p>
<p style="text-align: center;"><code class="reqn">
p(G=g|M,A,N) = \frac{M!A!N!}{(M+A+N)!}.
</code>
</p>

<p>U|MAN graphs provide a natural baseline model for networks which are constrained by size, density, and reciprocity.  In this way, they provide a bridge between edgewise models (e.g., the E-R family) and models with higher order dependence (e.g., the Markov graphs).
</p>


<h3>Value</h3>

<p>A matrix or array containing the drawn adjacency matrices
</p>


<h3>Note</h3>

<p> The famous mathematicians referenced in this man page now have misspelled names, due to R's difficulty with accent marks.  </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Holland, P.W. and Leinhardt, S.  (1976).  &ldquo;Local Structure in Social Networks.&rdquo;  In D. Heise (Ed.), <em>Sociological Methodology</em>, pp 1-45.  San Francisco: Jossey-Bass.
</p>
<p>Wasserman, S. and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rgraph">rgraph</a></code>, <code><a href="#topic+rgnm">rgnm</a></code>, <code><a href="#topic+dyad.census">dyad.census</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Show some examples of extreme U|MAN graphs
gplot(rguman(1,10,mut=45,asym=0,null=0,method="exact")) #Clique
gplot(rguman(1,10,mut=0,asym=45,null=0,method="exact")) #Tournament
gplot(rguman(1,10,mut=0,asym=0,null=45,method="exact")) #Empty

#Draw a sample of multinomial U|MAN graphs
g&lt;-rguman(5,10,mut=0.15,asym=0.05,null=0.8)

#Examine the dyad census
dyad.census(g)
</code></pre>

<hr>
<h2 id='rgws'> Draw From the Watts-Strogatz Rewiring Model </h2><span id='topic+rgws'></span><span id='topic+rewire.ws'></span><span id='topic+rewire.ud'></span><span id='topic+udrewire_R'></span><span id='topic+wsrewire_R'></span>

<h3>Description</h3>

<p><code>rgws</code> generates draws from the Watts-Strogatz rewired lattice model.  Given a set of input graphs, <code>rewire.ws</code> performs a (dyadic) rewiring of those graphs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgws(n, nv, d, z, p, return.as.edgelist = FALSE)
rewire.ud(g, p, return.as.edgelist = FALSE)
rewire.ws(g, p, return.as.edgelist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rgws_+3A_n">n</code></td>
<td>
<p> the number of draws to take. </p>
</td></tr>
<tr><td><code id="rgws_+3A_nv">nv</code></td>
<td>
<p> the number of vertices per lattice dimension. </p>
</td></tr>
<tr><td><code id="rgws_+3A_d">d</code></td>
<td>
<p> the dimensionality of the underlying lattice. </p>
</td></tr>
<tr><td><code id="rgws_+3A_z">z</code></td>
<td>
<p> the nearest-neighbor threshold for local ties. </p>
</td></tr>
<tr><td><code id="rgws_+3A_p">p</code></td>
<td>
<p> the dyadic rewiring probability. </p>
</td></tr>
<tr><td><code id="rgws_+3A_g">g</code></td>
<td>
<p> a graph or graph stack. </p>
</td></tr>
<tr><td><code id="rgws_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; should the resulting graphs be returned in edgelist form?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Watts-Strogatz graph process generates a random graph via the following procedure.  First, a <code>d</code>-dimensional uniform lattice is generated, here with <code>nv</code> vertices per dimension (i.e., <code>nv^d</code> vertices total).  Next, all <code>z</code> neighbors are connected, based on geodesics of the underlying lattice.  Finally, each non-null dyad in the resulting augmented lattice is &quot;rewired&quot; with probability <code>p</code>, where the rewiring operation exchanges the initial dyad state with the state of a uniformly selected null dyad sharing exactly one endpoint with the original dyad.  (In the standard case, this is equivalent to choosing an endpoint of the dyad at random, and then transferring the dyadic edges to/from that endpoint to another randomly chosen vertex.  Hence the &quot;rewiring&quot; metaphor.)  For <code>p==0</code>, the W-S process generates (deterministic) uniform lattices, approximating a uniform G(N,M) process as <code>p</code> approaches 1.  Thus, <code>p</code> can be used to tune overall entropy of the process.  A well-known property of the W-S process is that (for large <code>nv^d</code> and small <code>p</code>) it generates draws with short expected mean geodesic distances (approaching those found in uniform graphs) while maintaining high levels of local &quot;clustering&quot; (i.e., transitivity).  It has thus been proposed as one potential mechanism for obtaining &quot;small world&quot; structures.
</p>
<p><code>rgws</code> produces independent draws from the above process, returning them as an adjacency matrix (if <code>n==1</code>) or array (otherwise).  <code>rewire.ws</code>, on the other hand, applies the rewiring phase of the W-S process to one or more input graphs.  This can be used to explore local perturbations of the original graphs, conditioning on the dyad census.  <code>rewire.ud</code> is similar to <code>rewire.ws</code>, save in that all dyads are eligible for rewiring (not just non-null dyads), and exchanges with non-null dyads are permitted.  This process may be easier to work with than standard W-S rewiring in some cases.
</p>


<h3>Value</h3>

<p>A graph or graph stack containing draws from the appropriate W-S process.
</p>


<h3>Warning </h3>

<p>Remember that the total number of vertices in the graph is <code>nv^d</code>.  This can get out of hand <em>very</em> quickly.</p>


<h3>Note</h3>

 <p><code>rgws</code> generates non-toroidal lattices; some published work in this area utilizes underlying toroids, so users should check for this prior to comparing simulations against published results. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Watts, D. and Strogatz, S. (1998).  &ldquo;Collective Dynamics of Small-world Networks.&rdquo;  <em>Nature,</em> 393:440-442.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rgnm">rgnm</a></code>, <code><a href="#topic+rgraph">rgraph</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Generate Watts-Strogatz graphs, w/increasing levels of rewiring
gplot(rgws(1,100,1,2,0))     #No rewiring
gplot(rgws(1,100,1,2,0.01))  #1% rewiring
gplot(rgws(1,100,1,2,0.05))  #5% rewiring
gplot(rgws(1,100,1,2,0.1))   #10% rewiring
gplot(rgws(1,100,1,2,1))     #100% rewiring 

#Start with a simple graph, then rewire it
g&lt;-matrix(0,50,50)
g[1,]&lt;-1; g[,1]&lt;-1    #Create a star
gplot(g)
gplot(rewire.ws(g,0.05))  #5% rewiring

</code></pre>

<hr>
<h2 id='rmperm'> Randomly Permute the Rows and Columns of an Input Matrix </h2><span id='topic+rmperm'></span>

<h3>Description</h3>

<p>Given an input matrix (or stack thereof), <code>rmperm</code> performs a (random) simultaneous row/column permutation of the input data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmperm(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmperm_+3A_m">m</code></td>
<td>
<p> a matrix, or stack thereof (or a graph set, for that matter). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Random matrix permutations are the essence of the QAP test; see <code><a href="#topic+qaptest">qaptest</a></code> for details.
</p>


<h3>Value</h3>

<p>The permuted matrix (or matrices)
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+rperm">rperm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate an input matrix
g&lt;-rgraph(5)
g             #Examine it

#Examine a random permutation
rmperm(g)
</code></pre>

<hr>
<h2 id='rperm'> Draw a Random Permutation Vector with Exchangeability Constraints </h2><span id='topic+rperm'></span>

<h3>Description</h3>

<p>Draws a random permutation on <code>1:length(exchange.list)</code> such that no two elements whose corresponding <code>exchange.list</code> values are different are interchanged.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rperm(exchange.list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rperm_+3A_exchange.list">exchange.list</code></td>
<td>
<p> A vector such that the permutation vector may exchange the ith and jth positions iff <code>exchange.list[i]==exchange.list[j]</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rperm</code> draws random permutation vectors given the constraints of exchangeability described above.  Thus, <code>rperm(c(0,0,0,0))</code> returns a random permutation of four elements in which all exchanges are allowed, while <code>rperm(c(1,1,"a","a")</code> (or similar) returns a random permutation of four elements in which only the first/second and third/fourth elements may be exchanged.  This turns out to be quite useful for searching permutation spaces with exchangeability constraints (e.g., for structural distance estimation).
</p>


<h3>Value</h3>

<p>A random permutation vector satisfying the given constraints
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+rmperm">rmperm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>rperm(c(0,0,0,0))  #All elements may be exchanged
rperm(c(0,0,0,1))  #Fix the fourth element
rperm(c(0,0,1,1))  #Allow {1,2} and {3,4} to be swapped
rperm(c("a",4,"x",2))  #Fix all elements (the identity permutation)
</code></pre>

<hr>
<h2 id='sdmat'> Estimate the Structural Distance Matrix for a Graph Stack</h2><span id='topic+sdmat'></span>

<h3>Description</h3>

<p>Estimates the structural distances among all elements of <code>dat</code> using the method specified in <code>method</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sdmat(dat, normalize=FALSE, diag=FALSE, mode="digraph", 
    output="matrix", method="mc", exchange.list=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sdmat_+3A_dat">dat</code></td>
<td>
<p> graph set to be analyzed.  </p>
</td></tr>
<tr><td><code id="sdmat_+3A_normalize">normalize</code></td>
<td>
<p> divide by the number of available dyads? </p>
</td></tr>
<tr><td><code id="sdmat_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="sdmat_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>mode</code> is set to <code>"digraph"</code> by default. </p>
</td></tr>
<tr><td><code id="sdmat_+3A_output">output</code></td>
<td>
 <p><code>"matrix"</code> for matrix output, <code>"dist"</code> for a <code><a href="stats.html#topic+dist">dist</a></code> object. </p>
</td></tr>
<tr><td><code id="sdmat_+3A_method">method</code></td>
<td>
<p> method to be used to search the space of accessible permutations; must be one of <code>"none"</code>, <code>"exhaustive"</code>, <code>"anneal"</code>, <code>"hillclimb"</code>, or <code>"mc"</code>. </p>
</td></tr>
<tr><td><code id="sdmat_+3A_exchange.list">exchange.list</code></td>
<td>
<p> information on which vertices are exchangeable (see below); this must be a single number, a vector of length n, or a nx2 matrix. </p>
</td></tr>
<tr><td><code id="sdmat_+3A_...">...</code></td>
<td>
<p> additional arguments to <code><a href="#topic+lab.optimize">lab.optimize</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structural distance between two graphs G and H is defined as
</p>
<p style="text-align: center;"><code class="reqn">d_S\left(G,H \left| L_G,L_H\right.\right) = \min_{L_G,L_H} d\left(\ell\left(G\right),\ell\left(H\right)\right)</code>
</p>

<p>where <code class="reqn">L_G</code> is the set of accessible permutations/labelings of G, and <code class="reqn">\ell(G)</code> is a permuation/relabeling of the vertices of G (<code class="reqn">\ell(G) \in L_G</code>).  The set of accessible permutations on a given graph is determined by the <em>theoretical exchangeability</em> of its vertices; in a  nutshell, two vertices are considered to be theoretically exchangeable for a given problem if all predictions under the conditioning theory are invariant to a relabeling of the vertices in question (see Butts and Carley (2001) for a more formal exposition).  Where no vertices are exchangeable, the structural distance becomes the its labeled counterpart (here, the Hamming distance).  Where <em>all</em> vertices are exchangeable, the structural distance reflects the distance between unlabeled graphs; other cases correspond to distance under partial labeling.  
</p>
<p>The accessible permutation set is determined by the <code>exchange.list</code> argument, which is dealt with in the following manner. First, <code>exchange.list</code> is expanded to fill an nx2 matrix.  If <code>exchange.list</code> is a single number, this is trivially accomplished by replication; if <code>exchange.list</code> is a vector of length n, the matrix is formed by cbinding two copies together.  If <code>exchange.list</code> is already an nx2 matrix, it is left as-is.  Once the nx2 exchangeabiliy matrix has been formed, it is interpreted as follows: columns refer to graphs 1 and 2, respectively; rows refer to their corresponding vertices in the original adjacency matrices; and vertices are taken to be theoretically exchangeable iff their corresponding exchangeability matrix values are identical.  To obtain an unlabeled distance (the default), then, one could simply let <code>exchange.list</code> equal any single number.  To obtain the Hamming distance, one would use the vector <code>1:n</code>.
</p>
<p>Because the set of accessible permutations is, in general, very large (<code class="reqn">o(n!)</code>), searching the set for the minimum distance is a non-trivial affair.  Currently supported methods for estimating the structural distance are hill climbing, simulated annealing, blind monte carlo search, or exhaustive search (it is also possible to turn off searching entirely).  Exhaustive search is not recommended for graphs larger than size 8 or so, and even this may take days; still, this is a valid alternative for small graphs.  Blind monte carlo search and hill climbing tend to be suboptimal for this problem and are not, in general recommended, but they are available if desired.  The preferred (and default) option for permutation search is simulated annealing, which seems to work well on this problem (though some tinkering with the annealing parameters may be needed in order to get optimal performance).  See the help for <code><a href="#topic+lab.optimize">lab.optimize</a></code> for more information regarding these options.
</p>
<p>Structural distance matrices may be used in the same manner as any other distance matrices (e.g., with multidimensional scaling, cluster analysis, etc.)  Classical null hypothesis tests should not be employed with structural distances, and QAP tests are almost never appropriate (save in the uniquely labeled case).  See <code><a href="#topic+cugtest">cugtest</a></code> for a more reasonable alternative.
</p>


<h3>Value</h3>

<p>A matrix of distances (or an object of class <code>dist</code>)
</p>


<h3>Warning </h3>

<p>The search process can be <em>very slow</em>, particularly for large graphs.  In particular, the <em>exhaustive</em> method is order factorial, and will take approximately forever for unlabeled graphs of size greater than about 7-9.</p>


<h3>Note</h3>

<p> For most applications, <code>sdmat</code> is dominated by <code><a href="#topic+structdist">structdist</a></code>; the former is retained largely for reasons of compatibility.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Butts, C.T. and Carley, K.M.  (2005).  &ldquo;Some Simple Algorithms for Structural Comparison.&rdquo;  <em>Computational and Mathematical Organization Theory,</em> 11(4), 291-305.
</p>
<p>Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+hdist">hdist</a></code>, <code><a href="#topic+structdist">structdist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate two random graphs
g&lt;-array(dim=c(3,5,5))
g[1,,]&lt;-rgraph(5)
g[2,,]&lt;-rgraph(5)

#Copy one of the graphs and permute it
g[3,,]&lt;-rmperm(g[2,,])

#What are the structural distances between the labeled graphs?
sdmat(g,exchange.list=1:5)

#What are the structural distances between the underlying unlabeled 
#graphs?
sdmat(g,method="anneal", prob.init=0.9, prob.decay=0.85, 
    freeze.time=50, full.neighborhood=TRUE)
</code></pre>

<hr>
<h2 id='sedist'> Find a Matrix of Distances Between Positions Based on Structural Equivalence </h2><span id='topic+sedist'></span>

<h3>Description</h3>

<p><code>sedist</code> uses the graphs indicated by <code>g</code> in <code>dat</code> to assess the extent to which each vertex is structurally equivalent; <code>joint.analysis</code> determines whether this analysis is simultaneous, and <code>method</code> determines the measure of approximate equivalence which is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedist(dat, g=c(1:dim(dat)[1]), method="hamming", 
    joint.analysis=FALSE, mode="digraph", diag=FALSE, code.diss=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedist_+3A_dat">dat</code></td>
<td>
<p> a graph or set thereof. </p>
</td></tr>
<tr><td><code id="sedist_+3A_g">g</code></td>
<td>
<p> a vector indicating which elements of <code>dat</code> should be examined. </p>
</td></tr>
<tr><td><code id="sedist_+3A_method">method</code></td>
<td>
<p> one of <code>"correlation"</code>, <code>"euclidean"</code>, <code>"hamming"</code>, or <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="sedist_+3A_joint.analysis">joint.analysis</code></td>
<td>
<p> should equivalence be assessed across all networks jointly (<code>TRUE</code>), or individually within each (<code>FALSE</code>)? </p>
</td></tr>
<tr><td><code id="sedist_+3A_mode">mode</code></td>
<td>
 <p><code>"digraph"</code> for directed data, otherwise <code>"graph"</code>. </p>
</td></tr>
<tr><td><code id="sedist_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether diagonal entries (loops) should be treated as meaningful data. </p>
</td></tr>
<tr><td><code id="sedist_+3A_code.diss">code.diss</code></td>
<td>
<p> reverse-code the raw comparison values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sedist</code> provides a basic tool for assessing the (approximate) structural equivalence of actors.  (Two vertices i and j are said to be structurally equivalent if i-&gt;k iff j-&gt;k for all k.)  SE similarity/difference scores are computed by comparing vertex rows and columns using the measure indicated by <code>method</code>:
</p>

<ol>
<li><p> correlation: the product-moment correlation
</p>
</li>
<li><p> euclidean: the euclidean distance
</p>
</li>
<li><p> hamming: the Hamming distance
</p>
</li>
<li><p> gamma: the gamma correlation
</p>
</li></ol>

<p>Once these similarities/differences are calculated, the results can be used with a clustering routine (such as <code><a href="#topic+equiv.clust">equiv.clust</a></code>) or an MDS (such as <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>).
</p>


<h3>Value</h3>

<p>A matrix of similarity/difference scores
</p>


<h3>Note</h3>

<p> Be careful to verify that you have computed what you meant to compute, with respect to similarities/differences. Also, note that (despite its popularity) the product-moment correlation can give rather strange results in some cases.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Breiger, R.L.; Boorman, S.A.; and Arabie, P.  (1975).  &ldquo;An Algorithm for Clustering Relational Data with Applications to Social Network Analysis and Comparison with Multidimensional Scaling.&rdquo;  <em>Journal of Mathematical Psychology</em>, 12, 328-383.
</p>
<p>Burt, R.S.  (1976).  &ldquo;Positions in Networks.&rdquo;  <em>Social Forces</em>, 55, 93-122.
</p>
<p>Wasserman, S., and Faust, K.  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.   </p>


<h3>See Also</h3>

 <p><code><a href="#topic+equiv.clust">equiv.clust</a></code>, <code><a href="#topic+blockmodel">blockmodel</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a random graph with _some_ edge structure
g.p&lt;-sapply(runif(20,0,1),rep,20)  #Create a matrix of edge 
                                   #probabilities
g&lt;-rgraph(20,tprob=g.p)            #Draw from a Bernoulli graph 
                                   #distribution

#Get SE distances
g.se&lt;-sedist(g)

#Plot a metric MDS of vertex positions in two dimensions
plot(cmdscale(as.dist(g.se)))
</code></pre>

<hr>
<h2 id='simmelian'> Find the Simmelian Tie Structure of a Graph </h2><span id='topic+simmelian'></span>

<h3>Description</h3>

<p><code>simmelian</code> takes one or more (possibly directed) graphs as input, producing the associated Simmelian tie structures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simmelian(dat, dichotomize=TRUE, return.as.edgelist=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simmelian_+3A_dat">dat</code></td>
<td>
<p> one or more graphs (directed or otherwise). </p>
</td></tr>
<tr><td><code id="simmelian_+3A_dichotomize">dichotomize</code></td>
<td>
<p> logical; should the presence or absence of Simmelian edges be returned?  If <code>FALSE</code>, returned edges are valued by the number of 3-clique co-memberships for each dyad. </p>
</td></tr>
<tr><td><code id="simmelian_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; return the result as an sna edgelist? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a digraph <code class="reqn">G=(V,E)</code> with vertices <code class="reqn">i</code> and <code class="reqn">j</code>, then <code class="reqn">i</code> and <code class="reqn">j</code> are said to have a <em>Simmelian tie</em> iff <code class="reqn">i</code> and <code class="reqn">j</code> belong to a 3-clique of <code class="reqn">G</code>.  (Note that, in the undirected case, we simply treat <code class="reqn">G</code> as a fully mutual digraph.)  Because they have both a mutual dyad and mutual ties to/from at least one third party, vertex pairs with Simmelian ties in interpersonal networks are often expected to have strong relationships; Simmelian ties may also be more stable than other relationships, due to reinforcement from the mutual shared partner.  In other settings, the derived network of Simmelian ties (which is simply the co-membership network of non-trivial cliques) may be useful for identifying cohesively connected elements in a larger graph, or for finding &ldquo;backbone&rdquo; structures in networks with large numbers of unreciprocated and/or bridging ties.
</p>
<p>Currently, Simmelian tie calculation is performed using <code><a href="#topic+kcycle.census">kcycle.census</a></code>.  While the bulk of the calculations and data handling are performed using edgelists, <code><a href="#topic+kcycle.census">kcycle.census</a></code> currently returns co-memberships in adjacency form.  The implication for the end user is that performance for <code>simmelian</code> will begin to degrade for networks on the order of ten thousand vertices or so (due to the cost of allocating the adjacency structure), irrespective of the content of the network or other settings.  This bottleneck will likely be removed in future versions.
</p>


<h3>Value</h3>

<p>An adjacency matrix containing the Simmelian ties, or the equivalent edgelist representation
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Krackhardt, David.  (1999).  &ldquo;The Ties That Torture: Simmelian Tie Analysis in Organizations.&rdquo;  <em>Research in the Sociology of Organizations</em>, 16:183-210.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+kcycle.census">kcycle.census</a></code>, <code><a href="#topic+clique.census">clique.census</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Contrast the Simmelian ties in the Coleman friendship network with the "raw" ties
data(coleman)
fall&lt;-coleman[1,,]                   #Fall ties
spring&lt;-coleman[2,,]                 #Spring ties
sim.fall&lt;-simmelian(coleman[1,,])    #Fall Simmelian ties
sim.spring&lt;-simmelian(coleman[2,,])  #Spring Simmelian ties

par(mfrow=c(2,2))
gplot(fall,main="Nominations in Fall")
gplot(spring,main="Nominations in Spring")
gplot(sim.fall,main="Simmelian Ties in Fall")
gplot(sim.spring,main="Simmelian Ties in Spring")

#Which ties shall survive?
table(fall=gvectorize(fall),spring=gvectorize(spring))   #Fall vs. spring
table(sim.fall=gvectorize(sim.fall),spring=gvectorize(spring))
sum(fall&amp;spring)/sum(fall)                #About 58% of ties survive, overall...
sum(sim.fall&amp;spring)/sum(sim.fall)        #...but 74% of Simmelian ties survive!
sum(sim.fall&amp;sim.spring)/sum(sim.fall)    #(About 44% stay Simmelian.)
sum(sim.fall&amp;sim.spring)/sum(sim.spring)  #39% of spring Simmelian ties were so in fall
sum(fall&amp;sim.spring)/sum(sim.spring)      #and 67% had at least some tie in fall
</code></pre>

<hr>
<h2 id='sna'>Tools for Social Network Analysis</h2><span id='topic+sna'></span>

<h3>Description</h3>

<p><code>sna</code> is a package containing a range of tools for social network analysis.  Supported functionality includes node and graph-level indices, structural distance and covariance methods, structural equivalence detection, p* modeling, random graph generation, and 2D/3D network visualization (among other things).  
</p>


<h3>Details</h3>

<p>Network data for <code>sna</code> routines can (except as noted otherwise) appear in any of the following forms:
</p>

<ul>
<li><p> adjacency matrices (dimension N x N);
</p>
</li>
<li><p> arrays of adjacency matrices, aka &ldquo;graph stacks&rdquo; (dimension m x N x N);
</p>
</li>
<li><p> sna edge lists (see below);
</p>
</li>
<li><p> sparse matrix objects (from the SparseM package);
</p>
</li>
<li> <p><code>network</code> objects (from the <a href="network.html#topic+network">network</a> package); or
</p>
</li>
<li><p> lists of adjacency matrices/arrays, sparse matrices, and/or <code>network</code> objects.
</p>
</li></ul>

<p>Within the package documentation, the term &ldquo;graph&rdquo; is used generically to refer to any or all of the above (with multiple graphs being referred to as a &ldquo;graph stack&rdquo;).  Note that usage of sparse matrix objects requires that the SparseM package be installed.  (No additional packages are required for use of adjacency matrices/arrays or lists thereof, though the network package, on which sna depends as of 2.4, is used for network objects.)  In general, <code>sna</code> routines attempt to make intelligent decisions regarding the processing of multiple graphs, but common sense is always advised; certain functions, in particular, have more specific data requirements.  Calling <code>sna</code> functions with inappropriate input data can produce &ldquo;interesting&rdquo; results.
</p>
<p>One special data type supported by the sna package (as of version 2.0) is the <em>sna edgelist</em>.  This is a simple data format that is well-suited to representing large, sparse graphs.  (As of version 2.0, many - now most - package routines also process data in this form natively, so using it can produce significant savings of time and/or memory.  Prior to 2.0, all package functions coerced input data to adjacency matrix form.)  An sna edgelist is a three-column matrix, containing (respectively) senders, receivers, and values for each edge in the graph.  (Unvalued edges should have a value of 1.)  Note that this form is invariant to the number of edges in the graph: if there are no edges, then the edgelist is a degenerate matrix of dimension 0 by 3.  Edgelists for undirected graphs should be coded as fully mutual digraphs (as would be the case with an adjacency matrix), with two edges per dyad (one (i,j) edge, and one (j,i) edge).  Graph size for an sna edgelist matrix is indicated by a mandatory numeric attribute, named <code>"n"</code>.  Vertex names may be optionally specified by a vector-valued attribute named <code>"vnames"</code>.  In the case of two-mode data (i.e., data with an enforced bipartition), it is possible to indicate this status via the optional <code>"bipartite"</code> attribute.  Vertices in a two-mode edgelist should be grouped in mode order, with <code>"n"</code> equal to the total number of vertices (across both modes) and <code>"bipartite"</code> equal to the number of vertices in the first mode.
</p>
<p>Direct creation of sna edgelists can be performed by creating a three-column matrix and using the <code><a href="base.html#topic+attr">attr</a></code> function to create the required <code>"n"</code> attribute.  Alternately, the function <code><a href="#topic+as.edgelist.sna">as.edgelist.sna</a></code> can be used to coerce data in any of the above forms to an sna edgelist.  By turns, the function <code><a href="#topic+as.sociomatrix.sna">as.sociomatrix.sna</a></code> can be used to convert any of these data types to adjacency matrix form.
</p>
<p>To get started with <code>sna</code>, try obtaining viewing the list of available functions.  This can be accomplished via the command <code>library(help=sna)</code>.
</p>


<h3>Note</h3>

<p>If you use this package and/or software manual in your work, a citation would be appreciated.  The <code>link{citation}</code> function has helpful information in this regard.  See also the following paper, which explores the package in some detail:
</p>
<p>Butts, Carter T.  (2008).  &ldquo;Social Network Analysis with sna.&rdquo;  <em>Journal of Statistical Software</em>, 24(6).
</p>
<p>If utilizing a contributed routine, please also consider recognizing the author(s) of that specific function.  Contributing authors, if any, are listed on the relevant manual pages.  Your support helps to encourage the growth of the <code>sna</code> package, and is greatly valued!
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>

<hr>
<h2 id='sna-coercion'> sna Coercion Functions </h2><span id='topic+as.edgelist.sna'></span><span id='topic+as.sociomatrix.sna'></span><span id='topic+is.edgelist.sna'></span>

<h3>Description</h3>

<p>Functions to coerce network data into one form or another; these are generally internal, but may in some cases be helpful to the end user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.sociomatrix.sna(x, attrname=NULL, simplify=TRUE, force.bipartite=FALSE)
## S3 method for class 'sna'
as.edgelist(x, attrname = NULL, as.digraph = TRUE, 
    suppress.diag = FALSE, force.bipartite = FALSE, ...)
is.edgelist.sna(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sna-coercion_+3A_x">x</code></td>
<td>
<p>network data in any of several acceptable forms (see below).</p>
</td></tr>
<tr><td><code id="sna-coercion_+3A_attrname">attrname</code></td>
<td>
<p>if <code>x</code> is a <code><a href="network.html#topic+network">network</a></code> object, the (optional) edge attribute to be used to obtain edge values.</p>
</td></tr>
<tr><td><code id="sna-coercion_+3A_simplify">simplify</code></td>
<td>
<p>logical; should output be simplified by collapsing adjacency matrices of identical dimension into adjacency arrays?</p>
</td></tr>
<tr><td><code id="sna-coercion_+3A_force.bipartite">force.bipartite</code></td>
<td>
<p>logical; should the data be interpreted as bipartite (with rows and columns representing different data modes)?</p>
</td></tr>
<tr><td><code id="sna-coercion_+3A_as.digraph">as.digraph</code></td>
<td>
<p>logical; should <code><a href="network.html#topic+network">network</a></code> objects be coded as digraphs, regardless of object properties?  (Recommended)</p>
</td></tr>
<tr><td><code id="sna-coercion_+3A_suppress.diag">suppress.diag</code></td>
<td>
<p>logical; should loops be suppressed?</p>
</td></tr>
<tr><td><code id="sna-coercion_+3A_...">...</code></td>
<td>
<p> additional arguments to <code>sna.edgelist</code> (currently ignored). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+sna">sna</a></code> coercion functions are normally called internally within user-level <code><a href="#topic+sna">sna</a></code> functions to convert network data from various supported forms into a format usable by the function in question.  With few (if any) exceptions, formats acceptable by these functions should be usable with any user-level function in the <code><a href="#topic+sna">sna</a></code> library.
</p>
<p><code>as.sociomatrix.sna</code> takes one or more input graphs, and returns them in adjacency matrix (and/or array) form.  If <code>simplify==TRUE</code>, consolidation of matrices having the same dimensions into adjacency arrays is attempted; otherwise, elements are returned as lists of matrices/arrays.
</p>
<p><code>as.edgelist.sna</code> takes one or more input graphs, and returns them in <code>sna</code> edgelist form &ndash; i.e., a three-column matrix whose rows represent edges, and whose columns contain (respectively) the sender, receiver, and value of each edge.  (Undirected graphs are generally assumed to be coded as fully mutual digraphs; edges may be listed in any order.)  <code>sna</code> edgelists must also carry an attribute named <code>n</code> indicating the number of vertices in the graph, and may optionally contain the attributes <code>vnames</code> (carrying a vector of vertex names, in order) and/or <code>bipartite</code> (optionally, containing the number of row vertices in a two-mode network).  If the bipartite attribute is present and non-false, vertices whose numbers are less than or equal to the attribute value are taken to belong to the first mode (i.e., row vertices), and those of value greater than the attribute are taken to belong to the second mode (i.e., column vertices).  Note that the <code>bipartite</code> attribute is not strictly necessary to represent two-mode data, and may not be utilized by all <code><a href="#topic+sna">sna</a></code> functions.
</p>
<p><code>is.edgelist.sna</code> returns <code>TRUE</code> if its argument is a <code>sna</code> edgelist, or <code>FALSE</code> otherwise; if called with a list, this check is performed (recursively) on the list elements.
</p>
<p>Data for <code>sna</code> coercion routines may currently consist of any combination of standard or sparse (via <code>SparseM</code>) adjacency matrices or arrays, <code><a href="network.html#topic+network">network</a></code> objects, or <code>sna</code> edgelists.  If multiple items are given, they must be contained within a <code><a href="base.html#topic+list">list</a></code>.  Where adjacency arrays are specified, they must be in three-dimensional form, with dimensions given in graph/sender/receiver order.  Matrices or arrays having different numbers of rows and columns are taken to be two-mode adjacency structures, and are treated accordingly; setting <code>force.bipartite</code> will cause square matrices to be treated in similar fashion.  In the case of <code><a href="network.html#topic+network">network</a></code> or <code>sna</code> edgelist matrices, bipartition information is normally read from the object's internal properties.
</p>


<h3>Value</h3>

<p>An adjacency or edgelist structure, or a list thereof.
</p>


<h3>Note</h3>

<p>For large, sparse graphs, edgelists can be dramatically more efficient than adjacency matrices.  Where such savings can be realized, <code><a href="#topic+sna">sna</a></code> package functions usually employ <code>sna</code> edgelists as their &ldquo;native&rdquo; format (coercing input data with <code>as.edgelist.sna</code> as needed).  For this reason, users of large graphs can often obtain considerable savings by storing data in edgelist form, and passing edgelists (rather than adjacency matrices) to <code><a href="#topic+sna">sna</a></code> functions.
</p>
<p>The maximum size of adjacency matrices and edgelists depends upon <code>R</code>'s vector allocation limits.  On a 64-bit platform, these limits are currently around 4.6e4 vertices (adjacency case) or 7.1e8 edges (edgelist case).  The number of vertices in the edgelist case is effectively unlimited (and can technically be infinite), although not all functions will handle such objects gracefully.  (Use of vertex names will limit the number of edgelist vertices to around 2e9.)
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sna">sna</a></code>, <code><a href="network.html#topic+network">network</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Produce some random data, and transform it
g&lt;-rgraph(5)
g
all(g==as.sociomatrix.sna(g))     #TRUE
as.edgelist.sna(g)                #View in edgelist form
as.edgelist.sna(list(g,g))        #Double the fun
g2&lt;-as.sociomatrix.sna(list(g,g)) #Will simplify to an array
dim(g2)
g3&lt;-as.sociomatrix.sna(list(g,g),simplify=FALSE)  #Do not simplify
g3                                                #Now a list

#We can also build edgelists from scratch...
n&lt;-6
edges&lt;-rbind(
c(1,2,1),
c(2,1,2),
c(1,3,1),
c(1,5,2),
c(4,5,1),
c(5,4,1)
)
attr(edges,"n")&lt;-n
attr(edges,"vnames")&lt;-letters[1:n]
gplot(edges,displaylabels=TRUE)               #Plot the graph
as.sociomatrix.sna(edges)                     #Show in matrix form

#Two-mode data works similarly
n&lt;-6
edges&lt;-rbind(
c(1,4,1),
c(1,5,2),
c(4,1,1),
c(5,1,2),
c(2,5,1),
c(5,2,1),
c(3,5,1),
c(3,6,2),
c(6,3,2)
)
attr(edges,"n")&lt;-n
attr(edges,"vnames")&lt;-c(letters[1:3],LETTERS[4:6])
attr(edges,"bipartite")&lt;-3
edges
gplot(edges,displaylabels=TRUE,gmode="twomode")  #Plot
as.sociomatrix.sna(edges)                        #Convert to matrix

</code></pre>

<hr>
<h2 id='sna-defunct'> Defunct sna Objects </h2><span id='topic+addisolates'></span><span id='topic+addisolates-defunct'></span>

<h3>Description</h3>

<p>These objects have been removed from <code>sna</code>, and should no longer be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addisolates(dat, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sna-defunct_+3A_dat">dat</code></td>
<td>
<p> One or more adjacency matrices </p>
</td></tr>
<tr><td><code id="sna-defunct_+3A_n">n</code></td>
<td>
<p> The number of isolates to add </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>

<hr>
<h2 id='sna-deprecated'> Deprecated Functions in sna Package</h2><span id='topic+sna-deprecated'></span>

<h3>Description</h3>

<p>These functions are provided for compatibility with older versions of <code>sna</code> only, and may be defunct as soon as the next release.
</p>


<h3>Details</h3>

<p>The following <code>sna</code> functions are currently deprecated:
</p>
<p>None at this time.
</p>



<p>The original help pages for these functions can be found at <code>help("oldName-deprecated")</code>.  Please avoid using them, since they will disappear....
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+Deprecated">Deprecated</a></code> </p>

<hr>
<h2 id='sna-internal'> Internal sna Functions </h2><span id='topic+sna-internal'></span><span id='topic+bbnam.jntlik'></span><span id='topic+bbnam.jntlik.slice'></span><span id='topic+bbnam.probtie'></span><span id='topic+logSum'></span><span id='topic+logMean'></span><span id='topic+logSub'></span><span id='topic+aggarray3d_R'></span><span id='topic+dyadcode_R'></span><span id='topic+logadd_R'></span><span id='topic+logsub_R'></span>

<h3>Description</h3>

<p>Internal <code>sna</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbnam.jntlik(dat, log=FALSE, ...)
bbnam.jntlik.slice(s, dat, a, em, ep, log=FALSE)
bbnam.probtie(dat, i, j, npriorij, em, ep)
logMean(x)
logSub(x, y)
logSum(x)
</code></pre>


<h3>Details</h3>

<p>These are not to be called by the end user.
</p>

<hr>
<h2 id='sna.operators'> Graphical Operators </h2><span id='topic+sna.operators'></span><span id='topic++25c+25.matrix'></span>

<h3>Description</h3>

<p>These operators allow for algebraic manupulation of graph adjacency matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matrix'
e1 %c% e2
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sna.operators_+3A_e1">e1</code></td>
<td>
<p> an (unvalued) adjacency matrix. </p>
</td></tr>
<tr><td><code id="sna.operators_+3A_e2">e2</code></td>
<td>
<p> another (unvalued) adjacency matrix. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, only one operator is supported.  <code>x %c% y</code> returns the adjacency matrix of the composition of graphs with adjacency matrices <code>x</code> and <code>y</code> (respectively).  (Note that this may contain loops.)
</p>


<h3>Value</h3>

<p>The resulting adjacency matrix.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Wasserman, S. and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: University of Cambridge Press. </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create an in-star
g&lt;-matrix(0,6,6)
g[2:6,1]&lt;-1
gplot(g)

#Compose g with its transpose
gcgt&lt;-g%c%t(g)
gplot(gcgt,diag=TRUE)
gcgt
</code></pre>

<hr>
<h2 id='sr2css'> Convert a Row-wise Self-Report Matrix to a CSS Matrix with Missing Observations </h2><span id='topic+sr2css'></span>

<h3>Description</h3>

<p>Given a matrix in which the ith row corresponds to i's reported relations, <code>sr2css</code> creates a graph stack in which each element represents a CSS slice with missing observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sr2css(net)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sr2css_+3A_net">net</code></td>
<td>
<p> an adjacency matrix. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>A cognitive social structure (CSS) is an nxnxn array in which the ith matrix corresponds to the ith actor's perception of the entire network.  Here, we take a conventional self-report data structure and put it in CSS format for routines (such as <code><a href="#topic+bbnam">bbnam</a></code>) which require this.
</p>


<h3>Value</h3>

<p>An array (graph stack) containing the CSS
</p>


<h3>Note</h3>

<p> A row-wise self-report matrix doesn't contain a great deal of data, and the data in question is certainly not an ignorable sample of the individual's CSS for most purposes.  The provision of this routine should not be perceived as license to substitute SR for CSS data at will. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Krackhardt, D.  (1987).  <em>Cognitive Social Structures</em>, 9, 109-134.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Start with some random reports
g&lt;-rgraph(10)

#Transform to CSS format
c&lt;-sr2css(g)
</code></pre>

<hr>
<h2 id='stackcount'> How Many Graphs are in a Graph Stack? </h2><span id='topic+stackcount'></span>

<h3>Description</h3>

<p>Returns the number of graphs in the stack provided by <code>d</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stackcount(d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stackcount_+3A_d">d</code></td>
<td>
<p> a graph or graph stack. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>The number of graphs in <code>d</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+nties">nties</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>stackcount(rgraph(4,8))==8
</code></pre>

<hr>
<h2 id='stresscent'> Compute the Stress Centrality Scores of Network Positions </h2><span id='topic+stresscent'></span><span id='topic+stresscent_R'></span>

<h3>Description</h3>

<p><code>stresscent</code> takes one or more graphs (<code>dat</code>) and returns the stress centralities of positions (selected by <code>nodes</code>) within the graphs indicated by <code>g</code>.  Depending on the specified mode, stress on directed or undirected geodesics will be returned; this function is compatible with <code><a href="#topic+centralization">centralization</a></code>, and will return the theoretical maximum absolute deviation (from maximum) conditional on size (which is used by <code><a href="#topic+centralization">centralization</a></code> to normalize the observed centralization score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stresscent(dat, g=1, nodes=NULL, gmode="digraph", 
    diag=FALSE, tmaxdev=FALSE, cmode="directed", 
    geodist.precomp=NULL, rescale=FALSE, ignore.eval=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stresscent_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="stresscent_+3A_g">g</code></td>
<td>
<p> Integer indicating the index of the graph for which centralities are to be calculated (or a vector thereof).  By default, <code>g==1</code>. </p>
</td></tr>
<tr><td><code id="stresscent_+3A_nodes">nodes</code></td>
<td>
<p> list indicating which nodes are to be included in the calculation.  By default, all nodes are included. </p>
</td></tr>
<tr><td><code id="stresscent_+3A_gmode">gmode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>gmode</code> is set to <code>"digraph"</code> by default.</p>
</td></tr>
<tr><td><code id="stresscent_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="stresscent_+3A_tmaxdev">tmaxdev</code></td>
<td>
<p> boolean indicating whether or not the theoretical maximum absolute deviation from the maximum nodal centrality should be returned.  By default, <code>tmaxdev==FALSE</code>. </p>
</td></tr>
<tr><td><code id="stresscent_+3A_cmode">cmode</code></td>
<td>
<p> string indicating the type of betweenness centrality being computed (directed or undirected geodesics). </p>
</td></tr>
<tr><td><code id="stresscent_+3A_geodist.precomp">geodist.precomp</code></td>
<td>
<p>a <code><a href="#topic+geodist">geodist</a></code> object precomputed for the graph to be analyzed (optional).  </p>
</td></tr>
<tr><td><code id="stresscent_+3A_rescale">rescale</code></td>
<td>
<p> if true, centrality scores are rescaled such that they sum to 1. </p>
</td></tr>
<tr><td><code id="stresscent_+3A_ignore.eval">ignore.eval</code></td>
<td>
<p> logical; should edge values be ignored when calculating density?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The stress of a vertex, v, is given by
</p>
<p style="text-align: center;"><code class="reqn">C_S(v) = \sum_{i,j : i \neq j,i \neq v,j \neq v} g_{ivj}</code>
</p>

<p>where <code class="reqn">g_{ijk}</code> is the number of geodesics from i to k through j.  Conceptually, high-stress vertices lie on a large number of shortest paths between other vertices; they can thus be thought of as &ldquo;bridges&rdquo; or &ldquo;boundary spanners.&rdquo;  Compare this with <code><a href="#topic+betweenness">betweenness</a></code>, which weights shortest paths by the inverse of their redundancy.
</p>


<h3>Value</h3>

<p>A vector, matrix, or list containing the centrality scores (depending on the number and size of the input graphs).
</p>


<h3>Note</h3>

<p> Judicious use of <code>geodist.precomp</code> can save a great deal of time when computing multiple path-based indices on the same network. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Shimbel, A.  (1953).  &ldquo;Structural Parameters of Communication Networks.&rdquo;  <em>Bulletin of Mathematical Biophysics,</em> 15:501-507. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+centralization">centralization</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>g&lt;-rgraph(10)     #Draw a random graph with 10 members
stresscent(g)     #Compute stress scores
</code></pre>

<hr>
<h2 id='structdist'> Find the Structural Distances Between Two or More Graphs </h2><span id='topic+structdist'></span>

<h3>Description</h3>

<p><code>structdist</code> returns the structural distance between the labeled graphs <code>g1</code> and <code>g2</code> in stack <code>dat</code> based on Hamming distance for dichotomous data, or else the absolute (manhattan) distance.  If <code>normalize</code> is true, this distance is divided by its dichotomous theoretical maximum (conditional on |V(G)|).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>structdist(dat, g1=NULL, g2=NULL, normalize=FALSE, diag=FALSE,
    mode="digraph", method="anneal",  reps=1000, prob.init=0.9,
    prob.decay=0.85, freeze.time=25, full.neighborhood=TRUE,
    mut=0.05, pop=20, trials=5, exchange.list=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="structdist_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="structdist_+3A_g1">g1</code></td>
<td>
<p> a vector indicating which graphs to compare (by default, all elements of <code>dat</code>).  </p>
</td></tr>
<tr><td><code id="structdist_+3A_g2">g2</code></td>
<td>
<p> a vector indicating against which the graphs of <code>g1</code> should be compared (by default, all graphs). </p>
</td></tr>
<tr><td><code id="structdist_+3A_normalize">normalize</code></td>
<td>
<p> divide by the number of available dyads? </p>
</td></tr>
<tr><td><code id="structdist_+3A_diag">diag</code></td>
<td>
<p> boolean indicating whether or not the diagonal should be treated as valid data.  Set this true if and only if the data can contain loops.  <code>diag</code> is <code>FALSE</code> by default. </p>
</td></tr>
<tr><td><code id="structdist_+3A_mode">mode</code></td>
<td>
<p> string indicating the type of graph being evaluated.  <code>"digraph"</code> indicates that edges should be interpreted as directed; <code>"graph"</code> indicates that edges are undirected.  <code>mode</code> is set to <code>"digraph"</code> by default.</p>
</td></tr>
<tr><td><code id="structdist_+3A_method">method</code></td>
<td>
<p> method to be used to search the space of accessible permutations; must be one of <code>"none"</code>, <code>"exhaustive"</code>, <code>"anneal"</code>, <code>"hillclimb"</code>, or <code>"mc"</code>. </p>
</td></tr>
<tr><td><code id="structdist_+3A_reps">reps</code></td>
<td>
<p> number of iterations for Monte Carlo method.</p>
</td></tr>
<tr><td><code id="structdist_+3A_prob.init">prob.init</code></td>
<td>
<p> initial acceptance probability for the annealing routine. </p>
</td></tr>
<tr><td><code id="structdist_+3A_prob.decay">prob.decay</code></td>
<td>
<p> cooling multiplier for the annealing routine. </p>
</td></tr>
<tr><td><code id="structdist_+3A_freeze.time">freeze.time</code></td>
<td>
<p> freeze time for the annealing routine. </p>
</td></tr>
<tr><td><code id="structdist_+3A_full.neighborhood">full.neighborhood</code></td>
<td>
<p> should the annealer evaluate the full neighborhood of pair exchanges at each iteration? </p>
</td></tr>
<tr><td><code id="structdist_+3A_mut">mut</code></td>
<td>
<p> GA Mutation rate (currently ignored). </p>
</td></tr>
<tr><td><code id="structdist_+3A_pop">pop</code></td>
<td>
<p> GA population (currently ignored). </p>
</td></tr>
<tr><td><code id="structdist_+3A_trials">trials</code></td>
<td>
<p> number of GA populations (currently ignored). </p>
</td></tr>
<tr><td><code id="structdist_+3A_exchange.list">exchange.list</code></td>
<td>
<p> information on which vertices are exchangeable (see below); this must be a single number, a vector of length n, or a nx2 matrix. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structural distance between two graphs G and H is defined as
</p>
<p style="text-align: center;"><code class="reqn">d_S\left(G,H \left| L_G,L_H\right.\right) = \min_{L_G,L_H} d\left(\ell\left(G\right),\ell\left(H\right)\right)</code>
</p>

<p>where <code class="reqn">L_G</code> is the set of accessible permutations/labelings of G, and <code class="reqn">\ell(G)</code> is a permuation/relabeling of the vertices of G (<code class="reqn">\ell(G) \in L_G</code>).  The set of accessible permutations on a given graph is determined by the <em>theoretical exchangeability</em> of its vertices; in a  nutshell, two vertices are considered to be theoretically exchangeable for a given problem if all predictions under the conditioning theory are invariant to a relabeling of the vertices in question (see Butts and Carley (2001) for a more formal exposition).  Where no vertices are exchangeable, the structural distance becomes the its labeled counterpart (here, the Hamming distance).  Where <em>all</em> vertices are exchangeable, the structural distance reflects the distance between unlabeled graphs; other cases correspond to distance under partial labeling.  
</p>
<p>The accessible permutation set is determined by the <code>exchange.list</code> argument, which is dealt with in the following manner. First, <code>exchange.list</code> is expanded to fill an nx2 matrix.  If <code>exchange.list</code> is a single number, this is trivially accomplished by replication; if <code>exchange.list</code> is a vector of length n, the matrix is formed by <code>cbind</code>ing two copies together.  If <code>exchange.list</code> is already an nx2 matrix, it is left as-is.  Once the nx2 exchangeabiliy matrix has been formed, it is interpreted as follows: columns refer to graphs 1 and 2, respectively; rows refer to their corresponding vertices in the original adjacency matrices; and vertices are taken to be theoretically exchangeable iff their corresponding exchangeability matrix values are identical.  To obtain an unlabeled distance (the default), then, one could simply let <code>exchange.list</code> equal any single number.  To obtain the Hamming distance, one would use the vector <code>1:n</code>.
</p>
<p>Because the set of accessible permutations is, in general, very large (<code class="reqn">o(n!)</code>), searching the set for the minimum distance is a non-trivial affair.  Currently supported methods for estimating the structural distance are hill climbing, simulated annealing, blind monte carlo search, or exhaustive search (it is also possible to turn off searching entirely).  Exhaustive search is not recommended for graphs larger than size 8 or so, and even this may take days; still, this is a valid alternative for small graphs.  Blind monte carlo search and hill climbing tend to be suboptimal for this problem and are not, in general recommended, but they are available if desired.  The preferred (and default) option for permutation search is simulated annealing, which seems to work well on this problem (though some tinkering with the annealing parameters may be needed in order to get optimal performance).  See the help for <code><a href="#topic+lab.optimize">lab.optimize</a></code> for more information regarding these options.
</p>
<p>Structural distance matrices may be used in the same manner as any other distance matrices (e.g., with multidimensional scaling, cluster analysis, etc.)  Classical null hypothesis tests should not be employed with structural distances, and QAP tests are almost never appropriate (save in the uniquely labeled case).  See <code><a href="#topic+cugtest">cugtest</a></code> for a more reasonable alternative.
</p>


<h3>Value</h3>

<p>A structural distance matrix
</p>


<h3>Warning </h3>

<p>The search process can be <em>very slow</em>, particularly for large graphs.  In particular, the <em>exhaustive</em> method is order factorial, and will take approximately forever for unlabeled graphs of size greater than about 7-9.</p>


<h3>Note</h3>

<p> Consult Butts and Carley (2001) for advice and examples on theoretical exchangeability. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p>Butts, C.T. and Carley, K.M.  (2005).  &ldquo;Some Simple Algorithms for Structural Comparison.&rdquo;  <em>Computational and Mathematical Organization Theory,</em> 11(4), 291-305.
</p>
<p>Butts, C.T., and Carley, K.M.  (2001).  &ldquo;Multivariate Methods for Interstructural Analysis.&rdquo;  CASOS Working Paper, Carnegie Mellon University. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+hdist">hdist</a></code>, <code><a href="#topic+sdmat">sdmat</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate two random graphs
g&lt;-array(dim=c(3,5,5))
g[1,,]&lt;-rgraph(5)
g[2,,]&lt;-rgraph(5)

#Copy one of the graphs and permute it
g[3,,]&lt;-rmperm(g[2,,])

#What are the structural distances between the labeled graphs?
structdist(g,exchange.list=1:5)

#What are the structural distances between the underlying unlabeled 
#graphs?
structdist(g,method="anneal", prob.init=0.9, prob.decay=0.85, 
    freeze.time=50, full.neighborhood=TRUE)
</code></pre>

<hr>
<h2 id='structure.statistics'> Compute Network Structure Statistics </h2><span id='topic+structure.statistics'></span>

<h3>Description</h3>

<p>Computes the structure statistics for the graph(s) in <code>dat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>structure.statistics(dat, geodist.precomp = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="structure.statistics_+3A_dat">dat</code></td>
<td>
<p> one or more input graphs. </p>
</td></tr>
<tr><td><code id="structure.statistics_+3A_geodist.precomp">geodist.precomp</code></td>
<td>
<p> a <code><a href="#topic+geodist">geodist</a></code> object (optional). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">G=(V,E)</code> be a graph of order <code class="reqn">N</code>, and let <code class="reqn">d(i,j)</code> be the geodesic distance from vertex <code class="reqn">i</code> to vertex <code class="reqn">j</code> in <code class="reqn">G</code>.  The &quot;structure statistics&quot; of <code class="reqn">G</code> are then given by the series <code class="reqn">s_0,\ldots,s_{N-1}</code>, where <code class="reqn">s_i = \frac{1}{N^2} \sum_{j \in V} \sum_{k \in V} I\left(d(j,k) \le i\right) </code> and <code class="reqn">I</code> is the standard indicator function.  Intuitively, <code class="reqn">s_i</code> is the expected fraction of <code class="reqn">G</code> which lies within distance <code>i</code> of a randomly chosen vertex.  As such, the structure statistics provide an index of global connectivity.
</p>
<p>Structure statistics have been of particular importance to biased net theorists, because of the link with Rapoport's original tracing model.  They may also be used along with component distributions or connectedness scores as descriptive indices of connectivity at the graph-level.
</p>


<h3>Value</h3>

<p>A vector, matrix, or list (depending on <code>dat</code>) containing the structure statistics.
</p>


<h3>Note</h3>

<p> The term &quot;structure statistics&quot; has been used somewhat loosely in the literature, a trend which seems to be accelerating.  Users should carefully check references before comparing results generated by this routine with those appearing in published work. </p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

 
<p>Fararo, T.J. (1981).  &ldquo;Biased networks and social structure theorems. Part I.&rdquo; <em>Social Networks,</em> 3, 137-159.
</p>
<p>Fararo, T.J. (1984).  &ldquo;Biased networks and social structure theorems. Part II.&rdquo;  <em>Social Networks,</em> 6, 223-258.
</p>
<p>Fararo, T.J. and Sunshine, M.H. (1964).  &ldquo;A study of a biased friendship net.&rdquo;  Syracuse, NY: Youth Development Center.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+geodist">geodist</a></code>, <code><a href="#topic+component.dist">component.dist</a></code>, <code><a href="#topic+connectedness">connectedness</a></code>, <code><a href="#topic+bn">bn</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a moderately sparse Bernoulli graph
g&lt;-rgraph(100,tp=1.5/99)

#Compute the structure statistics for g
ss&lt;-structure.statistics(g)
plot(0:99,ss,xlab="Mean Coverage",ylab="Distance")

</code></pre>

<hr>
<h2 id='summary.bayes.factor'> Detailed Summaries of Bayes Factor Objects </h2><span id='topic+summary.bayes.factor'></span>

<h3>Description</h3>

<p>Returns a <code>bayes.factor</code> summary object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayes.factor'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.bayes.factor_+3A_object">object</code></td>
<td>
<p> An object of class <code>bayes.factor</code> </p>
</td></tr>
<tr><td><code id="summary.bayes.factor_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.bayes.factor</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam.bf">bbnam.bf</a></code> </p>

<hr>
<h2 id='summary.bbnam'> Detailed Summaries of bbnam Objects </h2><span id='topic+summary.bbnam'></span><span id='topic+summary.bbnam.fixed'></span><span id='topic+summary.bbnam.pooled'></span><span id='topic+summary.bbnam.actor'></span>

<h3>Description</h3>

<p>Returns a <code>bbnam</code> summary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bbnam'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.bbnam_+3A_object">object</code></td>
<td>
<p> An object of class <code>bbnam</code> </p>
</td></tr>
<tr><td><code id="summary.bbnam_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.bbnam</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+bbnam">bbnam</a></code> </p>

<hr>
<h2 id='summary.blockmodel'> Detailed Summaries of blockmodel Objects </h2><span id='topic+summary.blockmodel'></span>

<h3>Description</h3>

<p>Returns a <code>blockmodel</code> summary object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blockmodel'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.blockmodel_+3A_object">object</code></td>
<td>
<p> An object of class <code>blockmodel</code> </p>
</td></tr>
<tr><td><code id="summary.blockmodel_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.blockmodel</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+blockmodel">blockmodel</a></code> </p>

<hr>
<h2 id='summary.cugtest'> Detailed Summaries of cugtest Objects </h2><span id='topic+summary.cugtest'></span>

<h3>Description</h3>

<p>Returns a <code>cugtest</code> summary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cugtest'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.cugtest_+3A_object">object</code></td>
<td>
<p> An object of class <code>cugtest</code> </p>
</td></tr>
<tr><td><code id="summary.cugtest_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.cugtest</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+cugtest">cugtest</a></code> </p>

<hr>
<h2 id='summary.lnam'> Detailed Summaries of lnam Objects </h2><span id='topic+summary.lnam'></span>

<h3>Description</h3>

<p>Returns a <code>lnam</code> summary object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lnam'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.lnam_+3A_object">object</code></td>
<td>
<p> an object of class <code>lnam</code>. </p>
</td></tr>
<tr><td><code id="summary.lnam_+3A_...">...</code></td>
<td>
<p> additional arguments. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.lnam</code>.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+lnam">lnam</a></code> </p>

<hr>
<h2 id='summary.netcancor'> Detailed Summaries of netcancor Objects </h2><span id='topic+summary.netcancor'></span>

<h3>Description</h3>

<p>Returns a <code>netcancor</code> summary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'netcancor'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.netcancor_+3A_object">object</code></td>
<td>
<p> An object of class <code>netcancor</code> </p>
</td></tr>
<tr><td><code id="summary.netcancor_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.netcancor</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a>~ </p>


<h3>See Also</h3>

 <p><code><a href="#topic+netcancor">netcancor</a></code> </p>

<hr>
<h2 id='summary.netlm'> Detailed Summaries of netlm Objects </h2><span id='topic+summary.netlm'></span>

<h3>Description</h3>

<p>Returns a <code>netlm</code> summary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'netlm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.netlm_+3A_object">object</code></td>
<td>
<p> An object of class <code>netlm</code> </p>
</td></tr>
<tr><td><code id="summary.netlm_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.netlm</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+netlm">netlm</a></code> </p>

<hr>
<h2 id='summary.netlogit'> Detailed Summaries of netlogit Objects  </h2><span id='topic+summary.netlogit'></span>

<h3>Description</h3>

<p>Returns a <code>netlogit</code> summary object~
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'netlogit'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.netlogit_+3A_object">object</code></td>
<td>
<p>  An object of class <code>netlogit</code>  </p>
</td></tr>
<tr><td><code id="summary.netlogit_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.netlogit</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

<p><code><a href="#topic+netlogit">netlogit</a></code> </p>

<hr>
<h2 id='summary.qaptest'> Detailed Summaries of qaptest Objects </h2><span id='topic+summary.qaptest'></span>

<h3>Description</h3>

<p>Returns a <code>qaptest</code> summary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qaptest'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.qaptest_+3A_object">object</code></td>
<td>
<p> An object of class <code>qaptest</code> </p>
</td></tr>
<tr><td><code id="summary.qaptest_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.qaptest</code>
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+qaptest">qaptest</a></code> </p>

<hr>
<h2 id='symmetrize'> Symmetrize an Adjacency Matrix </h2><span id='topic+symmetrize'></span>

<h3>Description</h3>

<p>Symmetrizes the elements of <code>mats</code> according to the rule in <code>rule</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>symmetrize(mats, rule="weak", return.as.edgelist=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symmetrize_+3A_mats">mats</code></td>
<td>
<p> a graph or graph stack.</p>
</td></tr>
<tr><td><code id="symmetrize_+3A_rule">rule</code></td>
<td>
<p> one of &ldquo;upper&rdquo;, &ldquo;lower&rdquo;, &ldquo;strong&rdquo; or &ldquo;weak&rdquo;. </p>
</td></tr>
<tr><td><code id="symmetrize_+3A_return.as.edgelist">return.as.edgelist</code></td>
<td>
<p> logical; should the symmetrized graphs be returned in edgelist form?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rules used by <code>symmetrize</code> are as follows:
</p>

<ol>
<li><p> upper: Copy the upper triangle over the lower triangle
</p>
</li>
<li><p> lower: Copy the lower triangle over the upper triangle
</p>
</li>
<li><p> strong: i&lt;-&gt;j iff i-&gt;j and i&lt;-j  (AND rule)
</p>
</li>
<li><p> weak: i&lt;-&gt;j iff i-&gt;j or i&lt;-j  (OR rule)
</p>
</li></ol>



<h3>Value</h3>

<p>The symmetrized graph stack
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications</em>.  Cambridge: Cambridge University Press. </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a graph
g&lt;-rgraph(5)

#Weak symmetrization
symmetrize(g)

#Strong symmetrization
symmetrize(g,rule="strong")
</code></pre>

<hr>
<h2 id='triad.census'> Compute the Davis and Leinhardt Triad Census </h2><span id='topic+triad.census'></span><span id='topic+triad_census_R'></span>

<h3>Description</h3>

<p><code>triad.census</code> returns the Davis and Leinhardt triad census of the elements of <code>dat</code> indicated by <code>g</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triad.census(dat, g=NULL, mode = c("digraph", "graph"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="triad.census_+3A_dat">dat</code></td>
<td>
<p> a graph or graph stack. </p>
</td></tr>
<tr><td><code id="triad.census_+3A_g">g</code></td>
<td>
<p> the elements of <code>dat</code> to process. </p>
</td></tr>
<tr><td><code id="triad.census_+3A_mode">mode</code></td>
<td>
<p>string indicating the directedness of edges; <code>"digraph"</code> implies a directed structure, whereas <code>"graph"</code> implies an undirected structure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Davis and Leinhardt triad census consists of a classification of all directed triads into one of 16 different categories; the resulting distribution can be compared against various null models to test for the presence of configural biases (e.g., transitivity bias).  <code>triad.census</code> is a front end for the <code><a href="#topic+triad.classify">triad.classify</a></code> routine, performing the classification for all triads within the selected graphs.  The results are placed in the order indicated by the column names; this is the same order as presented in the <code><a href="#topic+triad.classify">triad.classify</a></code> documentation, to which the reader is referred for additional details.
</p>
<p>In the undirected case, the triad census reduces to four states (based on the number of edges in each triad.  Where <code>mode=="graph"</code>, this is returned instead.
</p>
<p>Compare <code><a href="#topic+triad.census">triad.census</a></code> to <code><a href="#topic+dyad.census">dyad.census</a></code>, the dyadic equivalent.
</p>


<h3>Value</h3>

<p>A matrix whose 16 columns contain the counts of triads by class for each graph, in the directed case.  In the undirected case, only 4 columns are used.
</p>


<h3>Warning </h3>

<p>Valued data may cause strange behavior with this routine.  Dichotomize the data first.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Davis, J.A. and Leinhardt, S.  (1972).  &ldquo;The Structure of Positive Interpersonal Relations in Small Groups.&rdquo;  In J. Berger (Ed.), <em>Sociological Theories in Progress, Volume 2</em>, 218-251.  Boston: Houghton Mifflin.
</p>
<p>Wasserman, S., and Faust, K.  (1994).  &ldquo;Social Network Analysis: Methods and Applications.&rdquo;  Cambridge: Cambridge University Press. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+triad.classify">triad.classify</a></code>, <code><a href="#topic+dyad.census">dyad.census</a></code>, <code><a href="#topic+kcycle.census">kcycle.census</a></code>, <code><a href="#topic+kpath.census">kpath.census</a></code>, <code><a href="#topic+gtrans">gtrans</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a triad census of random data with varying densities
triad.census(rgraph(15,5,tprob=c(0.1,0.25,0.5,0.75,0.9)))
</code></pre>

<hr>
<h2 id='triad.classify'> Compute the Davis and Leinhardt Classification of a Given Triad </h2><span id='topic+triad.classify'></span><span id='topic+triad_classify_R'></span>

<h3>Description</h3>

<p><code>triad.classify</code> returns the Davis and Leinhardt classification of the triad indicated by <code>tri</code> in the <code>g</code>th graph of stack <code>dat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triad.classify(dat, g=1, tri=c(1, 2, 3), mode=c("digraph", 
    "graph"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="triad.classify_+3A_dat">dat</code></td>
<td>
<p> a graph or graph stack. </p>
</td></tr>
<tr><td><code id="triad.classify_+3A_g">g</code></td>
<td>
<p> the index of the graph to be analyzed. </p>
</td></tr>
<tr><td><code id="triad.classify_+3A_tri">tri</code></td>
<td>
<p> a triple containing the indices of the triad to be classified.</p>
</td></tr>
<tr><td><code id="triad.classify_+3A_mode">mode</code></td>
<td>
<p>string indicating the directedness of edges; <code>"digraph"</code> implies a directed structure, whereas <code>"graph"</code> implies an undirected structure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Every unoriented directed triad may occupy one of 16 distinct states.  These states were used by Davis and Leinhardt as a basis for classifying triads within a larger structure; the distribution of triads within a graph (see <code><a href="#topic+triad.census">triad.census</a></code>), for instance, is linked to a range of substantive hypotheses (e.g., concerning structural balance).  The Davis and Leinhardt classification scheme describes each triad by a string of four elements: the number of mutual (complete) dyads within the triad; the number of asymmetric dyads within the triad; the number of null (empty) dyads within the triad; and a configuration code for the triads which are not uniquely distinguished by the first three distinctions.  The complete list of classes is as follows.
</p>

<dl>
<dt><code>003</code></dt><dd> <p><code class="reqn">a \not\leftrightarrow b \not\leftrightarrow c, a \not\leftrightarrow c</code></p>
</dd>
<dt><code>012</code></dt><dd> <p><code class="reqn">a \rightarrow b \not\leftrightarrow c, a \not\leftrightarrow c</code></p>
</dd>
<dt><code>102</code></dt><dd> <p><code class="reqn">a \leftrightarrow b \not\leftrightarrow c, a \not\leftrightarrow c</code></p>
</dd>
<dt><code>021D</code></dt><dd> <p><code class="reqn">a \leftarrow b \rightarrow c, a \not\leftrightarrow c</code></p>
</dd>
<dt><code>021U</code></dt><dd> <p><code class="reqn">a \rightarrow b \leftarrow c, a \not\leftrightarrow c</code></p>
</dd>
<dt><code>021C</code></dt><dd> <p><code class="reqn">a \rightarrow b \rightarrow c, a \not\leftrightarrow c</code></p>
</dd>
<dt><code>111D</code></dt><dd> <p><code class="reqn">a \not\leftrightarrow b \rightarrow c, a \leftrightarrow c</code></p>
</dd>
<dt><code>111U</code></dt><dd> <p><code class="reqn">a \not\leftrightarrow b \leftarrow c, a \leftrightarrow c</code></p>
</dd>
<dt><code>030T</code></dt><dd> <p><code class="reqn">a \rightarrow b \leftarrow c, a \rightarrow c</code></p>
</dd>
<dt><code>030C</code></dt><dd> <p><code class="reqn">a \leftarrow b \leftarrow c, a \rightarrow c</code></p>
</dd>
<dt><code>201</code></dt><dd> <p><code class="reqn">a \leftrightarrow b \not\leftrightarrow c, a \leftrightarrow c</code></p>
</dd>
<dt><code>120D</code></dt><dd> <p><code class="reqn">a \leftarrow b \rightarrow c, a \leftrightarrow c</code></p>
</dd>
<dt><code>120U</code></dt><dd> <p><code class="reqn">a \rightarrow b \leftarrow c, a \leftrightarrow c</code></p>
</dd>
<dt><code>120C</code></dt><dd> <p><code class="reqn">a \rightarrow b \rightarrow c, a \leftrightarrow c</code></p>
</dd>
<dt><code>210</code></dt><dd> <p><code class="reqn">a \rightarrow b \leftrightarrow c, a \leftrightarrow c</code></p>
</dd>
<dt><code>300</code></dt><dd> <p><code class="reqn">a \leftrightarrow b \leftrightarrow c, a \leftrightarrow c</code></p>
</dd>
</dl>

<p>These codes are returned by <code>triad.classify</code> as strings.  In the undirected case, only four triad states are possible (corresponding to the number of edges in the triad).  These are evaluated for <code>mode=="graph"</code>, with the return value being the number of edges.
</p>


<h3>Value</h3>

<p>A string containing the triad classification, or <code>NA</code> if one or more edges were missing
</p>


<h3>Warning </h3>

<p>Valued data and/or loops may cause strange behavior with this routine.  Dichotomize/remove loops first.</p>


<h3>Author(s)</h3>

<p> Carter T. Butts  <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>References</h3>

<p> Davis, J.A. and Leinhardt, S.  (1972).  &ldquo;The Structure of Positive Interpersonal Relations in Small Groups.&rdquo;  In J. Berger (Ed.), <em>Sociological Theories in Progress, Volume 2</em>, 218-251.  Boston: Houghton Mifflin.
</p>
<p>Wasserman, S., and Faust, K.  (1994).  <em>Social Network Analysis: Methods and Applications.</em>  Cambridge: Cambridge University Press.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+triad.census">triad.census</a></code>, <code><a href="#topic+gtrans">gtrans</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a random graph
g&lt;-rgraph(10)

#Classify the triads (1,2,3) and (2,3,4)
triad.classify(g,tri=c(1,2,3))
triad.classify(g,tri=c(1,2,3))

#Plot the triads in question
gplot(g[1:3,1:3])
gplot(g[2:4,2:4])
</code></pre>

<hr>
<h2 id='upper.tri.remove'> Remove the Upper Triangles of Adjacency Matrices in a Graph Stack </h2><span id='topic+upper.tri.remove'></span>

<h3>Description</h3>

<p>Returns the input graph stack, with the upper triangle entries removed/replaced as indicated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>upper.tri.remove(dat, remove.val=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="upper.tri.remove_+3A_dat">dat</code></td>
<td>
<p> a graph or graph stack. </p>
</td></tr>
<tr><td><code id="upper.tri.remove_+3A_remove.val">remove.val</code></td>
<td>
<p> the value with which to replace the existing upper triangles. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>upper.tri.remove</code> is simply a convenient way to apply <code>g[upper.tri(g)]&lt;-remove.val</code> to an entire stack of adjacency matrices at once.
</p>


<h3>Value</h3>

<p>The updated graph stack.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+upper.tri">upper.tri</a></code>, <code><a href="#topic+lower.tri.remove">lower.tri.remove</a></code>, <code><a href="#topic+diag.remove">diag.remove</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate a random graph stack
g&lt;-rgraph(3,5)
#Remove the upper triangles
g&lt;-upper.tri.remove(g)
</code></pre>

<hr>
<h2 id='write.dl'> Write Output Graphs in DL Format </h2><span id='topic+write.dl'></span>

<h3>Description</h3>

<p>Writes a graph stack to an output file in DL format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.dl(x, file, vertex.lab = NULL, matrix.lab = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.dl_+3A_x">x</code></td>
<td>
<p> a graph or graph stack, of common order. </p>
</td></tr>
<tr><td><code id="write.dl_+3A_file">file</code></td>
<td>
<p> a string containing the filename to which the data should be written. </p>
</td></tr>
<tr><td><code id="write.dl_+3A_vertex.lab">vertex.lab</code></td>
<td>
<p> an optional vector of vertex labels. </p>
</td></tr>
<tr><td><code id="write.dl_+3A_matrix.lab">matrix.lab</code></td>
<td>
<p> an optional vector of matrix labels. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>DL format is used by a number of software packages (including UCINET and Pajek) to store network data.  <code>write.dl</code> saves one or more (possibly valued) graphs in DL edgelist format, along with vertex and graph labels (if desired).  These files can, in turn, be used to import data into other software packages.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+write.nos">write.nos</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Generate a random graph stack
g&lt;-rgraph(5,10)

#This would save the graphs in DL format
write.dl(g,file="testfile.dl")

## End(Not run)
</code></pre>

<hr>
<h2 id='write.nos'> Write Output Graphs in (N)eo-(O)rg(S)tat Format </h2><span id='topic+write.nos'></span>

<h3>Description</h3>

<p>Writes a graph stack to an output file in NOS format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.nos(x, file, row.col = NULL, col.col = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.nos_+3A_x">x</code></td>
<td>
<p> a graph or graph stack (all graphs must be of common order). </p>
</td></tr>
<tr><td><code id="write.nos_+3A_file">file</code></td>
<td>
<p> string containing the output file name. </p>
</td></tr>
<tr><td><code id="write.nos_+3A_row.col">row.col</code></td>
<td>
<p> vector of row labels (or &quot;row colors&quot;). </p>
</td></tr>
<tr><td><code id="write.nos_+3A_col.col">col.col</code></td>
<td>
<p> vector of column labels (&quot;column colors&quot;). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>NOS format consists of three header lines, followed by a whitespace delimited stack of raw adjacency matrices; the format is not particularly elegant, but turns up in certain legacy applications (mostly at CMU).  <code>write.nos</code> provides a quick and dirty way of writing files NOS, which can later be retrieved using <code><a href="#topic+read.nos">read.nos</a></code>.
</p>
<p>The content of the NOS format is as follows:
</p>
<p>&lt;m&gt;
</p>
<p>&lt;n&gt; &lt;o&gt;
</p>
<p>&lt;kr1&gt; &lt;kr2&gt; ... &lt;krn&gt; &lt;kc1&gt; &lt;kc2&gt; ... &lt;kcn&gt;
</p>
<p>&lt;a111&gt; &lt;a112&gt; ... &lt;a11o&gt;
</p>
<p>&lt;a121&gt; &lt;a122&gt; ... &lt;a12o&gt;
</p>
<p>...
</p>
<p>&lt;a1n1&gt; &lt;a1n2&gt; ... &lt;a1no&gt;
</p>
<p>&lt;a211&gt; &lt;a212&gt; ... &lt;a21o&gt;
</p>
<p>...
</p>
<p>&lt;a2n1&gt; &lt;a2n2&gt; ... &lt;a2no&gt;
</p>
<p>...
</p>
<p>&lt;amn1&gt; &lt;amn2&gt; ... &lt;amno&gt;
</p>
<p>where &lt;abcd&gt; is understood to be the value of the c-&gt;d edge in the bth graph of the file.  (As one might expect, m, n, and o are the numbers of graphs (matrices), rows, and columns for the data, respectively.)  The &quot;k&quot; line contains a list of row and column &quot;colors&quot;, categorical variables associated with each row and column, respectively.  Although originally intended to communicate exchangability information, these can be used for other purposes (though there are easier ways to deal with attribute data these days).
</p>
<p>Note that NOS format only supports graph stacks of common order; graphs of different sizes cannot be stored within the same file.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Carter T. Butts <a href="mailto:buttsc@uci.edu">buttsc@uci.edu</a> </p>


<h3>See Also</h3>

 <p><code><a href="#topic+read.nos">read.nos</a></code>, <code><a href="#topic+write.dl">write.dl</a></code>, <code><a href="utils.html#topic+write.table">write.table</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Generate a random graph stack
g&lt;-rgraph(5,10)

#This would save the graphs in NOS format
write.nos(g,file="testfile.nos")

#We can also read them back, like so:
g2&lt;-read.nos("testfile.nos")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
