<!DOCTYPE html><html><head><title>Help for package ncvreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ncvreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AUC.cv.ncvsurv'><p>AUC for cv.ncvsurv objects</p></a></li>
<li><a href='#cv.ncvreg'><p>Cross-validation for ncvreg/ncvsurv</p></a></li>
<li><a href='#Heart'><p>Risk factors associated with heart disease</p></a></li>
<li><a href='#local_mfdr'><p>Estimate local mFDR for all features</p></a></li>
<li><a href='#logLik.ncvreg'><p>Extract Log-Likelihood</p></a></li>
<li><a href='#Lung'><p>VA lung cancer data set</p></a></li>
<li><a href='#mfdr'><p>Marginal false discovery rates</p></a></li>
<li><a href='#ncvfit'><p>Direct interface for nonconvex penalized regression (non-pathwise)</p></a></li>
<li><a href='#ncvreg'><p>Fit an MCP- or SCAD-penalized regression path</p></a></li>
<li><a href='#ncvreg-package'><p>ncvreg: Regularization Paths for SCAD and MCP Penalized Regression Models</p></a></li>
<li><a href='#ncvsurv'><p>Fit an MCP- or SCAD-penalized survival model</p></a></li>
<li><a href='#perm.ncvreg'><p>Permutation fitting for ncvreg</p></a></li>
<li><a href='#permres'><p>Permute residuals for a fitted ncvreg model</p></a></li>
<li><a href='#plot.cv.ncvreg'><p>Plots the cross-validation curve from a cv.ncvreg object</p></a></li>
<li><a href='#plot.mfdr'><p>Plot marginal false discovery rate curves</p></a></li>
<li><a href='#plot.ncvreg'><p>Plot coefficients from a ncvreg object</p></a></li>
<li><a href='#plot.ncvsurv.func'><p>Plot survival curve for ncvsurv model</p></a></li>
<li><a href='#predict.cv.ncvreg'><p>Model predictions based on a fitted ncvreg object.</p></a></li>
<li><a href='#predict.ncvsurv'><p>Model predictions based on a fitted &quot;ncvsurv&quot; object.</p></a></li>
<li><a href='#Prostate'><p>Factors associated with prostate specific antigen</p></a></li>
<li><a href='#residuals.ncvreg'><p>Extract residuals from a ncvreg or ncvsurv fit</p></a></li>
<li><a href='#std'><p>Standardizes a design matrix</p></a></li>
<li><a href='#summary.cv.ncvreg'><p>Summarizing cross-validation-based inference</p></a></li>
<li><a href='#summary.ncvreg'><p>Summary method for ncvreg objects</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Regularization Paths for SCAD and MCP Penalized Regression
Models</td>
</tr>
<tr>
<td>Version:</td>
<td>3.14.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-03</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ashr, knitr, parallel, rmarkdown, survival, tinytest</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits regularization paths for linear regression, GLM, and Cox
  regression models using lasso or nonconvex penalties, in particular the
  minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD)
  penalty, with options for additional L2 penalties (the "elastic net" idea).
  Utilities for carrying out cross-validation as well as post-fitting
  visualization, summarization, inference, and prediction are also provided.
  For more information, see Breheny and Huang (2011) &lt;<a href="https://doi.org/10.1214%2F10-AOAS388">doi:10.1214/10-AOAS388</a>&gt;
  or visit the ncvreg homepage <a href="https://pbreheny.github.io/ncvreg/">https://pbreheny.github.io/ncvreg/</a>.</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/pbreheny/ncvreg/issues">https://github.com/pbreheny/ncvreg/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://pbreheny.github.io/ncvreg/">https://pbreheny.github.io/ncvreg/</a>,
<a href="https://github.com/pbreheny/ncvreg">https://github.com/pbreheny/ncvreg</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-03 23:13:12 UTC; pbreheny</td>
</tr>
<tr>
<td>Author:</td>
<td>Patrick Breheny <a href="https://orcid.org/0000-0002-0650-1119"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Patrick Breheny &lt;patrick-breheny@uiowa.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-25 09:40:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='AUC.cv.ncvsurv'>AUC for cv.ncvsurv objects</h2><span id='topic+AUC.cv.ncvsurv'></span><span id='topic+AUC'></span>

<h3>Description</h3>

<p>Calculates the cross-validated AUC (concordance) from a <code>cv.ncvsurv</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.ncvsurv'
AUC(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC.cv.ncvsurv_+3A_obj">obj</code></td>
<td>
<p>A <code>cv.ncvsurv</code> object. You must run <code>cv.ncvsurv()</code> with the
option <code>returnY=TRUE</code> in order for <code>AUC()</code> to work</p>
</td></tr>
<tr><td><code id="AUC.cv.ncvsurv_+3A_...">...</code></td>
<td>
<p>For S3 method compatibility; not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The area under the curve (AUC), or equivalently, the concordance statistic
(C), is calculated according to the procedure described in van Houwelingen
and Putter (2011). The function calls <code>survival::concordancefit()</code>, except
except cross-validated linear predictors are used to guard against
overfitting.  Thus, the values returned by <code>AUC.cv.ncvsurv()</code> will be lower
than those you would obtain with <code>concordancefit()</code> if you fit the full
(unpenalized) model.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny, Brandon Butcher, and Lawrence Hunsicker
</p>


<h3>References</h3>

<p>van Houwelingen H, Putter H (2011). Dynamic Prediction in
Clinical Survival Analysis.  CRC Press.
</p>


<h3>See Also</h3>

<p><code>cv.ncvsurv()</code>, <code>survival::concordancefit()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y

cvfit &lt;- cv.ncvsurv(X, y, returnY=TRUE)
head(AUC(cvfit))
lam &lt;- cvfit$lambda
plot(lam, AUC(cvfit), xlim=rev(range(lam)), lwd=3, type='l',
     las=1, xlab=expression(lambda), ylab='AUC')
</code></pre>

<hr>
<h2 id='cv.ncvreg'>Cross-validation for ncvreg/ncvsurv</h2><span id='topic+cv.ncvreg'></span><span id='topic+cv.ncvsurv'></span>

<h3>Description</h3>

<p>Performs k-fold cross validation for MCP- or SCAD-penalized regression
models over a grid of values for the regularization parameter lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.ncvreg(
  X,
  y,
  ...,
  cluster,
  nfolds = 10,
  seed,
  fold,
  returnY = FALSE,
  trace = FALSE
)

cv.ncvsurv(
  X,
  y,
  ...,
  cluster,
  nfolds = 10,
  seed,
  fold,
  se = c("quick", "bootstrap"),
  returnY = FALSE,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.ncvreg_+3A_x">X</code></td>
<td>
<p>The design matrix, without an intercept, as in
<code>ncvreg</code>/<code>ncvsurv</code>.</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_y">y</code></td>
<td>
<p>The response vector, as in <code>ncvreg</code>/<code>ncvsurv</code>.</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code>ncvreg</code>/<code>ncvsurv</code>.</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_cluster">cluster</code></td>
<td>
<p><code>cv.ncvreg</code> and <code>cv.ncvsurv</code> can be run in parallel
across a cluster using the <code>parallel</code> package.  The cluster must be set
up in advance using the <code>makeCluster</code> function from that pacakge.  The
cluster must then be passed to <code>cv.ncvreg</code>/<code>cv.ncvsurv</code> (see
example).</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of cross-validation folds.  Default is 10.</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_seed">seed</code></td>
<td>
<p>You may set the seed of the random number generator in order to
obtain reproducible results.</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_fold">fold</code></td>
<td>
<p>Which fold each observation belongs to.  By default the
observations are randomly assigned.</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_returny">returnY</code></td>
<td>
<p>Should <code>cv.ncvreg</code>/<code>cv.ncvsurv</code> return the linear
predictors from the cross-validation folds?  Default is FALSE; if TRUE, this
will return a matrix in which the element for row i, column j is the fitted
value for observation i from the fold in which observation i was excluded
from the fit, at the jth value of lambda.  NOTE: For <code>cv.ncvsurv</code>, the
rows of <code>Y</code> are ordered by time on study, and therefore will not
correspond to the original order of observations pased to <code>cv.ncvsurv</code>.</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_trace">trace</code></td>
<td>
<p>If set to TRUE, inform the user of progress by announcing the
beginning of each CV fold.  Default is FALSE.</p>
</td></tr>
<tr><td><code id="cv.ncvreg_+3A_se">se</code></td>
<td>
<p>For <code>cv.ncvsurv</code>, the method by which the cross-valiation
standard error (CVSE) is calculated.  The 'quick' approach is based on a
rough approximation, but can be calculated more or less instantly.  The
'bootstrap' approach is more accurate, but requires additional computing
time.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calls <code>ncvreg</code>/<code>ncvsurv</code> <code>nfolds</code> times, each
time leaving out 1/<code>nfolds</code> of the data.  The cross-validation error is
based on the deviance;
<a href="https://pbreheny.github.io/ncvreg/articles/web/models.html">see here for more details</a>.
</p>
<p>For <code>family="binomial"</code> models, the cross-validation fold assignments
are balanced across the 0/1 outcomes, so that each fold has the same
proportion of 0/1 outcomes (or as close to the same proportion as it is
possible to achieve if cases do not divide evenly).
</p>
<p>For Cox models, <code>cv.ncvsurv</code> uses the approach of calculating the full
Cox partial likelihood using the cross-validated set of linear predictors.
Other approaches to cross-validation for the Cox regression model have been
proposed in the literature; the strengths and weaknesses of the various
methods for penalized regression in the Cox model are the subject of current
research.  A simple approximation to the standard error is provided,
although an option to bootstrap the standard error (<code>se='bootstrap'</code>)
is also available.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>cv.ncvreg</code>/<code>cv.ncvsurv</code>
containing: </p>
 <dl>
<dt>cve</dt><dd><p>The error for each value of <code>lambda</code>,
averaged across the cross-validation folds.</p>
</dd> <dt>cvse</dt><dd><p>The estimated
standard error associated with each value of for <code>cve</code>.</p>
</dd>
<dt>fold</dt><dd><p>The fold assignments for cross-validation for each observation;
note that for <code>cv.ncvsurv</code>, these are in terms of the ordered
observations, not the original observations.</p>
</dd> <dt>lambda</dt><dd><p>The sequence of
regularization parameter values along which the cross-validation error was
calculated.</p>
</dd> <dt>fit</dt><dd><p>The fitted <code>ncvreg</code>/<code>ncvsurv</code> object for
the whole data.</p>
</dd> <dt>min</dt><dd><p>The index of <code>lambda</code> corresponding to
<code>lambda.min</code>.</p>
</dd> <dt>lambda.min</dt><dd><p>The value of <code>lambda</code> with the
minimum cross-validation error.</p>
</dd> <dt>null.dev</dt><dd><p>The deviance for the
intercept-only model. If you have supplied your own <code>lambda</code> sequence,
this quantity may not be meaningful.</p>
</dd> <dt>Bias</dt><dd><p>The estimated bias of the
minimum cross-validation error, as in Tibshirani RJ and Tibshirani R (2009),
&quot;A Bias Correction for the Minimum Error Rate in Cross-Validation&quot;, Ann.
Appl. Stat. 3:822-829.</p>
</dd> <dt>pe</dt><dd><p>If <code>family="binomial"</code>, the
cross-validation prediction error for each value of <code>lambda</code>.</p>
</dd>
<dt>Y</dt><dd><p>If <code>returnY=TRUE</code>, the matrix of cross-validated fitted values
(see above).</p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Patrick Breheny; Grant Brown helped with the parallelization support
</p>


<h3>References</h3>

<p>Breheny P and Huang J. (2011) Coordinate descentalgorithms for
nonconvex penalized regression, with applications to biological feature
selection.  <em>Annals of Applied Statistics</em>, <strong>5</strong>: 232-253.
c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.1214/10-AOAS388&quot;)\ifelse{text}{doi:10.1214/10-AOAS388 &lt;https://doi.org/10.1214/10-AOAS388&gt;}{\ifelse{latex}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214\out{\slash{}}10\out{\-}AOAS388}}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214/10-AOAS388}}}
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg</a></code>, <code><a href="#topic+plot.cv.ncvreg">plot.cv.ncvreg</a></code>,
<code><a href="#topic+summary.cv.ncvreg">summary.cv.ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Prostate)

cvfit &lt;- cv.ncvreg(Prostate$X, Prostate$y)
plot(cvfit)
summary(cvfit)

fit &lt;- cvfit$fit
plot(fit)
beta &lt;- fit$beta[,cvfit$min]

## requires loading the parallel package
## Not run: 
library(parallel)
X &lt;- Prostate$X
y &lt;- Prostate$y
cl &lt;- makeCluster(4)
cvfit &lt;- cv.ncvreg(X, y, cluster=cl, nfolds=length(y))
## End(Not run)

# Survival
data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y

cvfit &lt;- cv.ncvsurv(X, y)
summary(cvfit)
plot(cvfit)
plot(cvfit, type="rsq")

</code></pre>

<hr>
<h2 id='Heart'>Risk factors associated with heart disease</h2><span id='topic+Heart'></span>

<h3>Description</h3>

<p>Data from a subset of the Coronary Risk-Factor Study baseline survey,
carried out in rural South Africa.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Heart
</code></pre>


<h3>Format</h3>

<p>A list of two objects: <code>y</code> and <code>X</code>
</p>

<dl>
<dt>y</dt><dd><p>Coronary heart disease at baseline; 1=Yes 0=No</p>
</dd>
<dt>X</dt><dd><p>A matrix with 462 observations (rows) and 9 predictor variables
(columns). The remainder of this list describes the columns of <code>X</code></p>
</dd>
<dt>sbp</dt><dd><p>Systolic blood pressure</p>
</dd>
<dt>tobacco</dt><dd><p>Cumulative tobacco consumption, in kg</p>
</dd>
<dt>ldl</dt><dd><p>Low-density lipoprotein cholesterol</p>
</dd>
<dt>adiposity</dt><dd><p>Adipose tissue concentration</p>
</dd>
<dt>famhist</dt><dd><p>Family history of heart disease (1=Present, 0=Absent)</p>
</dd>
<dt>typea</dt><dd><p>Score on test designed to measure type-A behavior</p>
</dd>
<dt>obesity</dt><dd><p>Obesity</p>
</dd>
<dt>alcohol</dt><dd><p>Current consumption of alcohol</p>
</dd>
<dt>age</dt><dd><p>Age of subject</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">https://web.stanford.edu/~hastie/ElemStatLearn/</a>
</p>


<h3>References</h3>


<ul>
<li><p> Hastie T, Tibshirani R, and Friedman J. (2001). <em>The Elements of
Statistical Learning</em>.  Springer.
</p>
</li>
<li><p> Rousseauw J, et al. (1983). Coronary risk factor screening in three
rural communities. <em>South African Medical Journal</em>, <strong>64</strong>: 430-436.
</p>
</li></ul>


<hr>
<h2 id='local_mfdr'>Estimate local mFDR for all features</h2><span id='topic+local_mfdr'></span>

<h3>Description</h3>

<p><code>local_mfdr()</code> is called by <code>summary.ncvreg()</code>, which typically offers a more convenient interface to users.
If, however, you are working with local mfdrs programmatically rather than interactively, you probably want to
use <code>local_mfdr()</code>, which skips the sorting, filtering, and print formatting of <code>summary.ncvreg()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local_mfdr(
  fit,
  lambda,
  X = NULL,
  y = NULL,
  method = c("ashr", "kernel"),
  sigma,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local_mfdr_+3A_fit">fit</code></td>
<td>
<p>A fitted <code>ncvreg</code> or <code>ncvsurv</code> object.</p>
</td></tr>
<tr><td><code id="local_mfdr_+3A_lambda">lambda</code></td>
<td>
<p>The value of lambda at which inference should be carried out.</p>
</td></tr>
<tr><td><code id="local_mfdr_+3A_x">X</code>, <code id="local_mfdr_+3A_y">y</code></td>
<td>
<p>The design matrix and response used to fit the model; in most cases, it is not necessary to provide
<code>X</code> and <code>y</code> as they are returned by <code>ncvreg</code>, but see the <code>returnX</code> argument in <code><a href="#topic+ncvreg">ncvreg()</a></code>.</p>
</td></tr>
<tr><td><code id="local_mfdr_+3A_method">method</code></td>
<td>
<p>What method should be used to calculate the local fdr?  Options are <code>ashr</code> (which tends to be more
accurate) and <code>kernel</code> (which requires no additional packages).  The default is to use <code>ashr</code> if the package is
installed.</p>
</td></tr>
<tr><td><code id="local_mfdr_+3A_sigma">sigma</code></td>
<td>
<p>For linear regression models, users can supply an estimate of the residual standard deviation.
The default is to use RSS / DF, where degrees of freedom are approximated using the number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="local_mfdr_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code>ash()</code> if using <code>method='ashr'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If all features are penalized, then the object returns a data frame with one row per feature and four columns:
</p>

<ul>
<li> <p><code>Estimate</code>: The coefficient estimate from the penalized regression fit
</p>
</li>
<li> <p><code>z</code>: A test statistic that approximately follows a standard normal distribution under the null hypothesis that the
feature is marginally independent of the outcome
</p>
</li>
<li> <p><code>mfdr</code>: The estimated marginal local false discovery rate
</p>
</li>
<li> <p><code>Selected</code>: Features with nonzero coefficient estimates are given an asterisk
</p>
</li></ul>

<p>If some features are penalized and others are not, then a list is returned with two elements: <code>pen.vars</code>, which consists
of the data frame described above, and <code>unpen.vars</code>, a data frame with four columns: <code>Estimate</code>, <code>SE</code>, <code>Statistic</code>, and
<code>p.value</code>.  The standard errors and p-values are based on a classical <code>lm</code>/<code>glm</code>/<code>coxph</code> model using the effect of the
penalized features as an offset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.ncvreg">summary.ncvreg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Linear regression
data(Prostate)
fit &lt;- ncvreg(Prostate$X, Prostate$y)
local_mfdr(fit, 0.1)

fit &lt;- ncvreg(Prostate$X, Prostate$y, penalty.factor=rep(0:1, each=4))
local_mfdr(fit, 0.1)

# Logistic regression
data(Heart)
X &lt;- Heart$X
y &lt;- Heart$y
fit &lt;- ncvreg(X, y, family='binomial')
local_mfdr(fit, 0.1)

# Cox regression
data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y
fit &lt;- ncvsurv(X, y)
local_mfdr(fit, 0.1)
</code></pre>

<hr>
<h2 id='logLik.ncvreg'>Extract Log-Likelihood</h2><span id='topic+logLik.ncvreg'></span><span id='topic+logLik.ncvsurv'></span>

<h3>Description</h3>

<p>Extract the log-likelihood of an <code>ncvreg</code> or <code>ncvsurv</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncvreg'
logLik(object, REML = FALSE, ...)

## S3 method for class 'ncvsurv'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.ncvreg_+3A_object">object</code></td>
<td>
<p>An <code>ncvreg</code> or <code>ncvsurv</code> object, as obtained from <code>ncvreg()</code> or <code>ncvsurv()</code></p>
</td></tr>
<tr><td><code id="logLik.ncvreg_+3A_reml">REML</code></td>
<td>
<p>As in <code>logLik.lm()</code></p>
</td></tr>
<tr><td><code id="logLik.ncvreg_+3A_...">...</code></td>
<td>
<p>For S3 compatibility</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>logLik()</code>
</p>

<hr>
<h2 id='Lung'>VA lung cancer data set</h2><span id='topic+Lung'></span>

<h3>Description</h3>

<p>Data from a randomised trial of two treatment regimens for lung cancer. This
is a standard survival analysis data set from the classic textbook by
Kalbfleisch and Prentice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lung
</code></pre>


<h3>Format</h3>

<p>A list of two objects: <code>y</code> and <code>X</code>
</p>

<dl>
<dt>y</dt><dd><p>A two column matrix (<code>Surv</code> object) containing the follow-up
time (in days) and an indicator variable for whether the patient died
while on the study or not.</p>
</dd>
<dt>X</dt><dd><p>A matrix with 137 observations (rows) and 9 predictor variables
(columns). The remainder of this list describes the columns of <code>X</code></p>
</dd>
<dt>trt</dt><dd><p>Treatment indicator (1=control group, 2=treatment group)</p>
</dd>
<dt>karno</dt><dd><p>Karnofsky performance score (0=bad, 100=good)</p>
</dd>
<dt>diagtime</dt><dd><p>Time from diagnosis to randomization (months)</p>
</dd>
<dt>age</dt><dd><p>Age (years, at baseline)</p>
</dd>
<dt>prior</dt><dd><p>Prior therapy (0=no, 1=yes)</p>
</dd>
<dt>squamous</dt><dd><p>Indicator for whether the cancer type is squamous cell
carcinoma (0=no, 1=yes)</p>
</dd>
<dt>small</dt><dd><p>Indicator for whether the cancer type is small cell lung
cancer (0=no, 1=yes)</p>
</dd>
<dt>adeno</dt><dd><p>Indicator for whether the cancer type is adenocarcinoma
(0=no, 1=yes)</p>
</dd>
<dt>large</dt><dd><p>Indicator for whether the cancer type is large cell carcinoma
(0=no, 1=yes)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://cran.r-project.org/package=survival">https://cran.r-project.org/package=survival</a>
</p>


<h3>References</h3>


<ul>
<li><p> Kalbfleisch D and Prentice RL (1980), <em>The Statistical Analysis of
Failure Time Data</em>. Wiley, New York.
</p>
</li></ul>



<h3>See Also</h3>

<p><code>ncvsurv()</code>
</p>

<hr>
<h2 id='mfdr'>Marginal false discovery rates</h2><span id='topic+mfdr'></span>

<h3>Description</h3>

<p>Estimates the marginal false discovery rate (mFDR) of a penalized regression
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mfdr(fit, X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mfdr_+3A_fit">fit</code></td>
<td>
<p>An <code>ncvreg</code> or <code>ncvsurv</code> object.</p>
</td></tr>
<tr><td><code id="mfdr_+3A_x">X</code></td>
<td>
<p>The model matrix corresponding to <code>fit</code>.  This is not
necessary for linear regression, but in logistic and Cox regression, the
mFDR depends on X.  It is not necessary to supply <code>X</code> if it is already
contained in <code>fit</code>; i.e., if <code>ncvreg</code>/<code>ncvsurv</code> was run with
<code>returnX=TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function estimates the marginal false discovery rate (mFDR) for a
penalized regression model.  The estimate tends to be accurate in most
settings, but will be slightly conservative if predictors are highly
correlated.  For an alternative way of estimating the mFDR, typically more
accurate in highly correlated cases, see <code><a href="#topic+perm.ncvreg">perm.ncvreg</a></code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>mfdr</code> inheriting from
<code>data.frame</code> and containing: </p>
<table>
<tr><td><code>EF</code></td>
<td>
<p>The number of variables selected
at each value of <code>lambda</code>, averaged over the permutation fits.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>The actual number of selected variables for the non-permuted data.</p>
</td></tr>
<tr><td><code>mFDR</code></td>
<td>
<p>The estimated marginal false discovery rate (<code>EF/S</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny and Ryan Miller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg</a></code>, <code><a href="#topic+ncvsurv">ncvsurv</a></code>,
<code><a href="#topic+plot.mfdr">plot.mfdr</a></code>, <code><a href="#topic+perm.ncvreg">perm.ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Linear regression --------------------------------
data(Prostate)
fit &lt;- ncvreg(Prostate$X, Prostate$y)

obj &lt;- mfdr(fit)
obj[1:10,]

# Comparison with perm.ncvreg
op &lt;- par(mfrow=c(2,2))
plot(obj)
plot(obj, type="EF")
pmfit &lt;- perm.ncvreg(Prostate$X, Prostate$y)
plot(pmfit)
plot(pmfit, type="EF")
par(op)

# Logistic regression ------------------------------
data(Heart)
fit &lt;- ncvreg(Heart$X, Heart$y, family="binomial")
obj &lt;- mfdr(fit)
head(obj)
op &lt;- par(mfrow=c(1,2))
plot(obj)
plot(obj, type="EF")
par(op)

# Cox regression -----------------------------------
data(Lung)
fit &lt;- ncvsurv(Lung$X, Lung$y)
obj &lt;- mfdr(fit)
head(obj)
op &lt;- par(mfrow=c(1,2))
plot(obj)
plot(obj, type="EF")
par(op)

</code></pre>

<hr>
<h2 id='ncvfit'>Direct interface for nonconvex penalized regression (non-pathwise)</h2><span id='topic+ncvfit'></span>

<h3>Description</h3>

<p>This function is intended for users who know exactly what they're doing and want complete
control over the fitting process:
no standardization is applied, no intercept is included, no path is fit.
All of these things are best practices for data analysis, so if you are choosing not to do
them, you are on your own &ndash; there is no guarantee that your results will be meaningful.
Some things in particular that you should pay attention to:
</p>

<ul>
<li><p> If your model has an intercept, it is up to you to (un)penalize it properly, typically
by settings its corresponding element of <code>penalty.factor</code> to zero.
</p>
</li>
<li><p> You should provide initial values for the coefficients; in nonconvex optimization,
initial values are very important in determining which local solution an algorithm
converges to.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ncvfit(
  X,
  y,
  init = rep(0, ncol(X)),
  r,
  xtx,
  penalty = c("MCP", "SCAD", "lasso"),
  gamma = switch(penalty, SCAD = 3.7, 3),
  alpha = 1,
  lambda,
  eps = 1e-05,
  max.iter = 1000,
  penalty.factor = rep(1, ncol(X)),
  warn = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ncvfit_+3A_x">X</code></td>
<td>
<p>Design matrix; no intercept will be added, no standardization
will occur (n x p matrix)</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_y">y</code></td>
<td>
<p>Response vector (length n vector)</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_init">init</code></td>
<td>
<p>Initial values for beta.  Default: zero (length p vector)</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_r">r</code></td>
<td>
<p>Residuals corresponding to <code>init</code>; these will be calculated if not
supplied, but if they have already been calculated elsewhere, it is
more efficient to pass them as an argument. WARNING: If you supply
an incorrect value of <code>r</code>, the solution will be incorrect. (length
n vector)</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_xtx">xtx</code></td>
<td>
<p>X scales: the jth element should equal <code>crossprod(X[,j])/n</code>. These
will be calculated if not supplied, but if they have already been
calculated elsewhere, it is more efficient to pass them as an
argument.  In particular, if X is standardized, one should pass
<code>xtx = rep(1, p)</code>.  WARNING: If you supply an incorrect value of
<code>xtx</code>, the solution will be incorrect. (length p vector)</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_penalty">penalty</code></td>
<td>
<p>Penalty function to be applied, either &quot;MCP&quot; (default), &quot;SCAD&quot;, or
&quot;lasso&quot;)</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_gamma">gamma</code></td>
<td>
<p>Tuning parameter of the MCP/SCAD penalty, as in <code>ncvreg()</code>; default
is 3 for MCP and 3.7 for SCAD.</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_alpha">alpha</code></td>
<td>
<p>Tuning paramter controlling the ridge component of penalty, as in
<code>ncvreg()</code>; default is 1 (meaning no ridge penalty)</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_lambda">lambda</code></td>
<td>
<p>Regularization parameter value at which to estimate beta; must be
scalar &ndash; for pathwise optimization, see <code>ncvreg()</code></p>
</td></tr>
<tr><td><code id="ncvfit_+3A_eps">eps</code></td>
<td>
<p>Convergence threshhold. The algorithm iterates until the RMSD for
the change in linear predictors for each coefficient is less than
eps. Default is 1e-4.</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of allowed iterations; if this number is reached,
algorithm will terminate prior to convergence.  Default: 1000.</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Multiplicative factor for the penalty applied to each coefficient,
as in <code>ncvreg()</code>.  In particular, note that if you include an
intercept, you probably want to set its entry to zero here.</p>
</td></tr>
<tr><td><code id="ncvfit_+3A_warn">warn</code></td>
<td>
<p>Return warning messages for failures to converge and model
saturation? Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>At the moment, this function only works for least-squares loss functions.  Additional
functionality for other loss functions (logistic, Cox) is in development.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>beta</code>: The estimated regression coefficients
</p>
</li>
<li> <p><code>iter</code>: The number of iterations required to solve for 'beta
</p>
</li>
<li> <p><code>loss</code>: The loss (residual sum of squares) at convergence
</p>
</li>
<li> <p><code>resid</code>: The residuals at convergence
</p>
</li>
<li> <p><code>lambda</code>: See above
</p>
</li>
<li> <p><code>penalty</code>: See above
</p>
</li>
<li> <p><code>gamma</code>: See above
</p>
</li>
<li> <p><code>alpha</code>: See above
</p>
</li>
<li> <p><code>penalty.factor</code>: See above
</p>
</li>
<li> <p><code>n</code>: Sample size
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(Prostate)
X &lt;- cbind(1, Prostate$X)
y &lt;- Prostate$y
fit &lt;- ncvfit(X, y, lambda=0.1, penalty.factor=c(0, rep(1, ncol(X)-1)))
fit$beta
# Compare with:
coef(ncvreg(X, y), 0.1)
# The unstandardized version makes little sense here, as it fails to account
# for differences in the scales of the predictors.
</code></pre>

<hr>
<h2 id='ncvreg'>Fit an MCP- or SCAD-penalized regression path</h2><span id='topic+ncvreg'></span>

<h3>Description</h3>

<p>Fit coefficients paths for MCP- or SCAD-penalized regression models over a
grid of values for the regularization parameter lambda.  Fits linear and
logistic regression models, with option for an additional L2 penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ncvreg(
  X,
  y,
  family = c("gaussian", "binomial", "poisson"),
  penalty = c("MCP", "SCAD", "lasso"),
  gamma = switch(penalty, SCAD = 3.7, 3),
  alpha = 1,
  lambda.min = ifelse(n &gt; p, 0.001, 0.05),
  nlambda = 100,
  lambda,
  eps = 1e-04,
  max.iter = 10000,
  convex = TRUE,
  dfmax = p + 1,
  penalty.factor = rep(1, ncol(X)),
  warn = TRUE,
  returnX,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ncvreg_+3A_x">X</code></td>
<td>
<p>The design matrix, without an intercept.  <code>ncvreg</code>
standardizes the data and includes an intercept by default.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_y">y</code></td>
<td>
<p>The response vector.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_family">family</code></td>
<td>
<p>Either &quot;gaussian&quot;, &quot;binomial&quot;, or &quot;poisson&quot;, depending on the
response.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_penalty">penalty</code></td>
<td>
<p>The penalty to be applied to the model.  Either &quot;MCP&quot; (the
default), &quot;SCAD&quot;, or &quot;lasso&quot;.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_gamma">gamma</code></td>
<td>
<p>The tuning parameter of the MCP/SCAD penalty (see details).
Default is 3 for MCP and 3.7 for SCAD.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter for the Mnet estimator which controls the
relative contributions from the MCP/SCAD penalty and the ridge, or L2
penalty.  <code>alpha=1</code> is equivalent to MCP/SCAD penalty, while
<code>alpha=0</code> would be equivalent to ridge regression.  However,
<code>alpha=0</code> is not supported; <code>alpha</code> may be arbitrarily small, but
not exactly 0.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_lambda.min">lambda.min</code></td>
<td>
<p>The smallest value for lambda, as a fraction of
lambda.max.  Default is .001 if the number of observations is larger than
the number of covariates and .05 otherwise.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values.  Default is 100.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_lambda">lambda</code></td>
<td>
<p>A user-specified sequence of lambda values.  By default, a
sequence of values of length <code>nlambda</code> is computed, equally spaced on
the log scale.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_eps">eps</code></td>
<td>
<p>Convergence threshhold.  The algorithm iterates until the RMSD
for the change in linear predictors for each coefficient is less than
<code>eps</code>.  Default is <code>1e-4</code>.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations (total across entire path).
Default is 10000.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_convex">convex</code></td>
<td>
<p>Calculate index for which objective function ceases to be
locally convex?  Default is TRUE.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_dfmax">dfmax</code></td>
<td>
<p>Upper bound for the number of nonzero coefficients.  Default is
no upper bound.  However, for large data sets, computational burden may be
heavy for models with a large number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>A multiplicative factor for the penalty applied to
each coefficient.  If supplied, <code>penalty.factor</code> must be a numeric
vector of length equal to the number of columns of <code>X</code>.  The purpose of
<code>penalty.factor</code> is to apply differential penalization if some
coefficients are thought to be more likely than others to be in the model.
In particular, <code>penalty.factor</code> can be 0, in which case the coefficient
is always in the model without shrinkage.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_warn">warn</code></td>
<td>
<p>Return warning messages for failures to converge and model
saturation?  Default is TRUE.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_returnx">returnX</code></td>
<td>
<p>Return the standardized design matrix along with the fit?  By
default, this option is turned on if X is under 100 MB, but turned off for
larger matrices to preserve memory.  Note that certain methods, such as
<code><a href="#topic+summary.ncvreg">summary.ncvreg</a></code> require access to the design matrix and may not
be able to run if <code>returnX=FALSE</code>.</p>
</td></tr>
<tr><td><code id="ncvreg_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by the regularization parameter <code>lambda</code>
is fit using a coordinate descent algorithm.  For logistic regression
models, some care is taken to avoid model saturation; the algorithm may exit
early in this setting.  The objective function is defined to be
</p>
<p style="text-align: center;"><code class="reqn">Q(\beta|X, y) = \frac{1}{n} L(\beta|X, y) + </code>
</p>
<p style="text-align: center;"><code class="reqn"> P_\lambda(\beta)</code>
</p>
<p> where the loss function L is
the deviance (-2 times the log likelihood) for the specified outcome
distribution (gaussian/binomial/poisson). See
<a href="https://pbreheny.github.io/ncvreg/articles/web/models.html">here</a> for more
details.
</p>
<p>This algorithm is stable, very efficient, and generally converges quite
rapidly to the solution.  For GLMs,
<a href="https://myweb.uiowa.edu/pbreheny/pdf/Breheny2011.pdf">adaptive rescaling</a>
is used.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"ncvreg"</code> containing: </p>

<dl>
<dt>beta</dt><dd><p>The fitted matrix of coefficients.  The number of rows is equal
to the number of coefficients, and the number of columns is equal to
<code>nlambda</code>.</p>
</dd> <dt>iter</dt><dd><p>A vector of length <code>nlambda</code> containing
the number of iterations until convergence at each value of <code>lambda</code>.</p>
</dd>
<dt>lambda</dt><dd><p>The sequence of regularization parameter values in the path.</p>
</dd>
<dt>penalty</dt><dd><p>Same as above.</p>
</dd> <dt>family</dt><dd><p>Same as above.</p>
</dd>
<dt>gamma</dt><dd><p>Same as above.</p>
</dd> <dt>alpha</dt><dd><p>Same as above.</p>
</dd>
<dt>convex.min</dt><dd><p>The last index for which the objective function is locally
convex.  The smallest value of lambda for which the objective function is
convex is therefore <code>lambda[convex.min]</code>, with corresponding
coefficients <code>beta[,convex.min]</code>.</p>
</dd> <dt>loss</dt><dd><p>A vector containing the
deviance (i.e., the loss) at each value of <code>lambda</code>.  Note that for
<code>gaussian</code> models, the loss is simply the residual sum of squares.</p>
</dd>
<dt>penalty.factor</dt><dd><p>Same as above.</p>
</dd> <dt>n</dt><dd><p>Sample size.</p>
</dd> </dl>

<p>Additionally, if <code>returnX=TRUE</code>, the object will also contain
</p>
 <dl>
<dt>X</dt><dd><p>The standardized design matrix.</p>
</dd> <dt>y</dt><dd><p>The response,
centered if <code>family='gaussian'</code>.</p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>

<p>Breheny P and Huang J. (2011) Coordinate descentalgorithms for
nonconvex penalized regression, with applications to biological feature
selection.  <em>Annals of Applied Statistics</em>, <strong>5</strong>: 232-253.
c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.1214/10-AOAS388&quot;)\ifelse{text}{doi:10.1214/10-AOAS388 &lt;https://doi.org/10.1214/10-AOAS388&gt;}{\ifelse{latex}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214\out{\slash{}}10\out{\-}AOAS388}}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214/10-AOAS388}}}
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.ncvreg">plot.ncvreg</a></code>, <code><a href="#topic+cv.ncvreg">cv.ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Linear regression --------------------------------------------------
data(Prostate)
X &lt;- Prostate$X
y &lt;- Prostate$y

op &lt;- par(mfrow=c(2,2))
fit &lt;- ncvreg(X, y)
plot(fit, main=expression(paste(gamma,"=",3)))
fit &lt;- ncvreg(X, y, gamma=10)
plot(fit, main=expression(paste(gamma,"=",10)))
fit &lt;- ncvreg(X, y, gamma=1.5)
plot(fit, main=expression(paste(gamma,"=",1.5)))
fit &lt;- ncvreg(X, y, penalty="SCAD")
plot(fit, main=expression(paste("SCAD, ",gamma,"=",3)))
par(op)

op &lt;- par(mfrow=c(2,2))
fit &lt;- ncvreg(X, y)
plot(fit, main=expression(paste(alpha,"=",1)))
fit &lt;- ncvreg(X, y, alpha=0.9)
plot(fit, main=expression(paste(alpha,"=",0.9)))
fit &lt;- ncvreg(X, y, alpha=0.5)
plot(fit, main=expression(paste(alpha,"=",0.5)))
fit &lt;- ncvreg(X, y, alpha=0.1)
plot(fit, main=expression(paste(alpha,"=",0.1)))
par(op)

op &lt;- par(mfrow=c(2,2))
fit &lt;- ncvreg(X, y)
plot(mfdr(fit))             # Independence approximation
plot(mfdr(fit), type="EF")  # Independence approximation
perm.fit &lt;- perm.ncvreg(X, y)
plot(perm.fit)
plot(perm.fit, type="EF")
par(op)

# Logistic regression ------------------------------------------------
data(Heart)
X &lt;- Heart$X
y &lt;- Heart$y

op &lt;- par(mfrow=c(2,2))
fit &lt;- ncvreg(X, y, family="binomial")
plot(fit, main=expression(paste(gamma,"=",3)))
fit &lt;- ncvreg(X, y, family="binomial", gamma=10)
plot(fit, main=expression(paste(gamma,"=",10)))
fit &lt;- ncvreg(X, y, family="binomial", gamma=1.5)
plot(fit, main=expression(paste(gamma,"=",1.5)))
fit &lt;- ncvreg(X, y, family="binomial", penalty="SCAD")
plot(fit, main=expression(paste("SCAD, ",gamma,"=",3)))
par(op)

op &lt;- par(mfrow=c(2,2))
fit &lt;- ncvreg(X, y, family="binomial")
plot(fit, main=expression(paste(alpha,"=",1)))
fit &lt;- ncvreg(X, y, family="binomial", alpha=0.9)
plot(fit, main=expression(paste(alpha,"=",0.9)))
fit &lt;- ncvreg(X, y, family="binomial", alpha=0.5)
plot(fit, main=expression(paste(alpha,"=",0.5)))
fit &lt;- ncvreg(X, y, family="binomial", alpha=0.1)
plot(fit, main=expression(paste(alpha,"=",0.1)))
par(op)

</code></pre>

<hr>
<h2 id='ncvreg-package'>ncvreg: Regularization Paths for SCAD and MCP Penalized Regression Models</h2><span id='topic+ncvreg-package'></span>

<h3>Description</h3>

<p>Fits regularization paths for linear regression, GLM, and Cox regression models using lasso or nonconvex penalties, in particular the minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD) penalty, with options for additional L2 penalties (the &quot;elastic net&quot; idea). Utilities for carrying out cross-validation as well as post-fitting visualization, summarization, inference, and prediction are also provided. For more information, see Breheny and Huang (2011) <a href="https://doi.org/10.1214/10-AOAS388">doi:10.1214/10-AOAS388</a> or visit the ncvreg homepage <a href="https://pbreheny.github.io/ncvreg/">https://pbreheny.github.io/ncvreg/</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Patrick Breheny <a href="mailto:patrick-breheny@uiowa.edu">patrick-breheny@uiowa.edu</a> (<a href="https://orcid.org/0000-0002-0650-1119">ORCID</a>)
</p>


<h3>References</h3>

<p>Breheny P and Huang J. (2011) Coordinate descent algorithms for
nonconvex penalized regression, with applications to biological feature
selection. <em>Annals of Applied Statistics</em>, <strong>5</strong>: 232-253.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://pbreheny.github.io/ncvreg/">https://pbreheny.github.io/ncvreg/</a>
</p>
</li>
<li> <p><a href="https://github.com/pbreheny/ncvreg">https://github.com/pbreheny/ncvreg</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/pbreheny/ncvreg/issues">https://github.com/pbreheny/ncvreg/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>vignette("getting-started", package="ncvreg")
</code></pre>

<hr>
<h2 id='ncvsurv'>Fit an MCP- or SCAD-penalized survival model</h2><span id='topic+ncvsurv'></span>

<h3>Description</h3>

<p>Fit coefficients paths for MCP- or SCAD-penalized Cox regression models over
a grid of values for the regularization parameter lambda, with option for an
additional L2 penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ncvsurv(
  X,
  y,
  penalty = c("MCP", "SCAD", "lasso"),
  gamma = switch(penalty, SCAD = 3.7, 3),
  alpha = 1,
  lambda.min = ifelse(n &gt; p, 0.001, 0.05),
  nlambda = 100,
  lambda,
  eps = 1e-04,
  max.iter = 10000,
  convex = TRUE,
  dfmax = p,
  penalty.factor = rep(1, ncol(X)),
  warn = TRUE,
  returnX,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ncvsurv_+3A_x">X</code></td>
<td>
<p>The design matrix of predictor values.  <code>ncvsurv</code> standardizes
the data prior to fitting.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_y">y</code></td>
<td>
<p>The time-to-event outcome, as a two-column matrix or
<code><a href="survival.html#topic+Surv">Surv</a></code> object.  The first column should be time on
study (follow up time); the second column should be a binary variable with 1
indicating that the event has occurred and 0 indicating (right) censoring.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_penalty">penalty</code></td>
<td>
<p>The penalty to be applied to the model.  Either &quot;MCP&quot; (the
default), &quot;SCAD&quot;, or &quot;lasso&quot;.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_gamma">gamma</code></td>
<td>
<p>The tuning parameter of the MCP/SCAD penalty (see details).
Default is 3 for MCP and 3.7 for SCAD.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter for the Mnet estimator which controls the
relative contributions from the MCP/SCAD penalty and the ridge, or L2
penalty.  <code>alpha=1</code> is equivalent to MCP/SCAD penalty, while
<code>alpha=0</code> would be equivalent to ridge regression.  However,
<code>alpha=0</code> is not supported; <code>alpha</code> may be arbitrarily small, but
not exactly 0.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_lambda.min">lambda.min</code></td>
<td>
<p>The smallest value for lambda, as a fraction of
lambda.max.  Default is .001 if the number of observations is larger than
the number of covariates and .05 otherwise.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values.  Default is 100.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_lambda">lambda</code></td>
<td>
<p>A user-specified sequence of lambda values.  By default, a
sequence of values of length <code>nlambda</code> is computed, equally spaced on
the log scale.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_eps">eps</code></td>
<td>
<p>Convergence threshhold.  The algorithm iterates until the RMSD
for the change in linear predictors for any coefficient is less than
<code>eps</code>.  Default is <code>1e-4</code>.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations (total across entire path).
Default is 1000.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_convex">convex</code></td>
<td>
<p>Calculate index for which objective function ceases to be
locally convex?  Default is TRUE.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_dfmax">dfmax</code></td>
<td>
<p>Upper bound for the number of nonzero coefficients.  Default is
no upper bound.  However, for large data sets, computational burden may be
heavy for models with a large number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>A multiplicative factor for the penalty applied to
each coefficient.  If supplied, <code>penalty.factor</code> must be a numeric
vector of length equal to the number of columns of <code>X</code>.  The purpose of
<code>penalty.factor</code> is to apply differential penalization if some
coefficients are thought to be more likely than others to be in the model.
In particular, <code>penalty.factor</code> can be 0, in which case the coefficient
is always in the model without any penalization/shrinkage.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_warn">warn</code></td>
<td>
<p>Return warning messages for failures to converge and model
saturation?  Default is TRUE.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_returnx">returnX</code></td>
<td>
<p>Return the standardized design matrix along with the fit?  By
default, this option is turned on if X is under 100 MB, but turned off for
larger matrices to preserve memory.  Note that certain methods, such as
<code><a href="#topic+summary.ncvreg">summary.ncvreg</a></code> require access to the design matrix and may not
be able to run if <code>returnX=FALSE</code>.</p>
</td></tr>
<tr><td><code id="ncvsurv_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by the regularization parameter <code>lambda</code>
is fit using a coordinate descent algorithm.  In order to accomplish this,
the second derivative (Hessian) of the Cox partial log-likelihood is
diagonalized (see references for details).  The objective function is
defined to be </p>
<p style="text-align: center;"><code class="reqn">Q(\beta|X, y) = \frac{1}{n} L(\beta|X, y) + </code>
</p>
<p style="text-align: center;"><code class="reqn">
P_\lambda(\beta)</code>
</p>

<p>where the loss function L is the deviance (-2 times the partial
log-likelihood) from the Cox regression mode. See
<a href="https://pbreheny.github.io/ncvreg/articles/web/models.html">here</a> for more
details.
</p>
<p>Presently, ties are not handled by <code>ncvsurv</code> in a particularly
sophisticated manner.  This will be improved upon in a future release of
<code>ncvreg</code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"ncvsurv"</code> containing: </p>

<dl>
<dt>beta</dt><dd><p>The fitted matrix of coefficients.  The number of rows is equal
to the number of coefficients, and the number of columns is equal to
<code>nlambda</code>.</p>
</dd> <dt>iter</dt><dd><p>A vector of length <code>nlambda</code> containing
the number of iterations until convergence at each value of <code>lambda</code>.</p>
</dd>
<dt>lambda</dt><dd><p>The sequence of regularization parameter values in the path.</p>
</dd>
<dt>penalty</dt><dd><p>Same as above.</p>
</dd> <dt>model</dt><dd><p>Same as above.</p>
</dd>
<dt>gamma</dt><dd><p>Same as above.</p>
</dd> <dt>alpha</dt><dd><p>Same as above.</p>
</dd>
<dt>convex.min</dt><dd><p>The last index for which the objective function is locally
convex.  The smallest value of lambda for which the objective function is
convex is therefore <code>lambda[convex.min]</code>, with corresponding
coefficients <code>beta[,convex.min]</code>.</p>
</dd> <dt>loss</dt><dd><p>The deviance of the
fitted model at each value of <code>lambda</code>.</p>
</dd> <dt>penalty.factor</dt><dd><p>Same as
above.</p>
</dd> <dt>n</dt><dd><p>The number of observations.</p>
</dd> </dl>

<p>For Cox models, the following objects are also returned (and are necessary
to estimate baseline survival conditonal on the estimated regression
coefficients), all of which are ordered by time on study.  I.e., the ith row
of <code>W</code> does not correspond to the ith row of <code>X</code>):
</p>
 <dl>
<dt>W</dt><dd><p>Matrix of <code>exp(beta)</code> values for each subject over
all <code>lambda</code> values.</p>
</dd> <dt>time</dt><dd><p>Times on study.</p>
</dd> <dt>fail</dt><dd><p>Failure
event indicator.</p>
</dd> </dl>

<p>Additionally, if <code>returnX=TRUE</code>, the object will also contain
</p>
 <dl>
<dt>X</dt><dd><p>The standardized design matrix.</p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>

 <ul>
<li><p> Breheny P and Huang J. (2011) Coordinate
descentalgorithms for nonconvex penalized regression, with applications to
biological feature selection.  <em>Annals of Applied Statistics</em>,
<strong>5</strong>: 232-253.  c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.1214/10-AOAS388&quot;)\ifelse{text}{doi:10.1214/10-AOAS388 &lt;https://doi.org/10.1214/10-AOAS388&gt;}{\ifelse{latex}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214\out{\slash{}}10\out{\-}AOAS388}}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214/10-AOAS388}}}
</p>
</li>
<li><p> Simon N, Friedman JH, Hastie T, and Tibshirani R. (2011)
Regularization Paths for Cox's Proportional Hazards Model via Coordinate
Descent.  <em>Journal of Statistical Software</em>, <strong>39</strong>: 1-13.
c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.18637/jss.v039.i05&quot;)\ifelse{text}{doi:10.18637/jss.v039.i05 &lt;https://doi.org/10.18637/jss.v039.i05&gt;}{\ifelse{latex}{\href{https://doi.org/10.18637/jss.v039.i05}{doi:10.18637\out{\slash{}}jss.v039.i05}}{\href{https://doi.org/10.18637/jss.v039.i05}{doi:10.18637/jss.v039.i05}}}
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.ncvreg">plot.ncvreg</a></code>, <code><a href="#topic+cv.ncvsurv">cv.ncvsurv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y

op &lt;- par(mfrow=c(2,2))
fit &lt;- ncvsurv(X, y)
plot(fit, main=expression(paste(gamma,"=",3)))
fit &lt;- ncvsurv(X, y, gamma=10)
plot(fit, main=expression(paste(gamma,"=",10)))
fit &lt;- ncvsurv(X, y, gamma=1.5)
plot(fit, main=expression(paste(gamma,"=",1.5)))
fit &lt;- ncvsurv(X, y, penalty="SCAD")
plot(fit, main=expression(paste("SCAD, ",gamma,"=",3)))
par(op)

fit &lt;- ncvsurv(X,y)
ll &lt;- log(fit$lambda)
op &lt;- par(mfrow=c(2,1))
plot(ll, BIC(fit), type="l", xlim=rev(range(ll)))
lam &lt;- fit$lambda[which.min(BIC(fit))]
b &lt;- coef(fit, lambda=lam)
b[b!=0]
plot(fit)
abline(v=lam)
par(op)

S &lt;- predict(fit, X, type='survival', lambda=lam)
plot(S, xlim=c(0,200))

</code></pre>

<hr>
<h2 id='perm.ncvreg'>Permutation fitting for ncvreg</h2><span id='topic+perm.ncvreg'></span>

<h3>Description</h3>

<p>Fits multiple penalized regression models in which the outcome is randomly
permuted, thereby allowing estimation of the marginal false discovery rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perm.ncvreg(
  X,
  y,
  ...,
  permute = c("outcome", "residuals"),
  N = 10,
  seed,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perm.ncvreg_+3A_x">X</code></td>
<td>
<p>The design matrix, without an intercept, as in <code>ncvreg</code>.</p>
</td></tr>
<tr><td><code id="perm.ncvreg_+3A_y">y</code></td>
<td>
<p>The response vector, as in <code>ncvreg</code>.</p>
</td></tr>
<tr><td><code id="perm.ncvreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code>ncvreg</code>.</p>
</td></tr>
<tr><td><code id="perm.ncvreg_+3A_permute">permute</code></td>
<td>
<p>What to permute.  If <code>'outcome'</code>, the response vector,
<code>y</code>, is permuted.  If <code>'residuals'</code>, the residuals are permuted.
This is only available for linear regression (i.e., for
<code>family='gaussian'</code>).  Note that permuting the residuals may take a
long time, as the residuals differ for each value of <code>lambda</code>, so
separate permutations are required at every value of <code>lambda</code>.  See
also <code><a href="#topic+permres">permres</a></code>.</p>
</td></tr>
<tr><td><code id="perm.ncvreg_+3A_n">N</code></td>
<td>
<p>The number of permutation replications.  Default is 10.</p>
</td></tr>
<tr><td><code id="perm.ncvreg_+3A_seed">seed</code></td>
<td>
<p>You may set the seed of the random number generator in order to
obtain reproducible results.</p>
</td></tr>
<tr><td><code id="perm.ncvreg_+3A_trace">trace</code></td>
<td>
<p>If set to TRUE, perm.ncvreg will inform the user of its
progress by announcing the beginning of each permutation fit. Default is
FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function fits a penalized regression model to the actual data, then
repeats the process <code>N</code> times with a permuted version of the response
vector.  This allows estimation of the expected number of variables included
by chance for each value of <code>lambda</code>.  The ratio of this expected
quantity to the number of selected variables using the actual (non-permuted)
response is called the marginal false discovery rate (mFDR).
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"perm.ncvreg"</code> containing:
</p>
<table>
<tr><td><code>EF</code></td>
<td>
<p>The number of variables selected at each value of <code>lambda</code>,
averaged over the permutation fits.</p>
</td></tr> <tr><td><code>S</code></td>
<td>
<p>The actual number of selected
variables for the non-permuted data.</p>
</td></tr> <tr><td><code>mFDR</code></td>
<td>
<p>The estimated marginal
false discovery rate (<code>EF/S</code>).</p>
</td></tr> <tr><td><code>fit</code></td>
<td>
<p>The fitted <code>ncvreg</code>
object for the original (non-permuted) data.</p>
</td></tr> <tr><td><code>loss</code></td>
<td>
<p>The loss/deviance
for each value of <code>lambda</code>, averaged over the permutation fits.  This
is an estimate of the explanatory power of the model under null conditions,
and can be used to adjust the loss of the fitted model in a manner akin to
the idea of an adjusted R-squared in classical regression.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny <a href="mailto:patrick-breheny@uiowa.edu">patrick-breheny@uiowa.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg</a></code>, <code><a href="#topic+plot.mfdr">plot.mfdr</a></code>, <code><a href="#topic+mfdr">mfdr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Linear regression --------------------------------------------------
data(Prostate)
pmfit &lt;- perm.ncvreg(Prostate$X, Prostate$y)

op &lt;- par(mfcol=c(2,2))
plot(pmfit)
plot(pmfit, type="EF")
plot(pmfit$fit)
lam &lt;- pmfit$fit$lambda

pmfit.r &lt;- perm.ncvreg(Prostate$X, Prostate$y, permute='residuals')
plot(pmfit.r, col="red")              # Permuting residuals is
lines(lam, pmfit$mFDR, col="gray60")  # less conservative
par(op)

# Logistic regression ------------------------------------------------
data(Heart)
pmfit &lt;- perm.ncvreg(Heart$X, Heart$y, family="binomial")

op &lt;- par(mfcol=c(2,2))
plot(pmfit)
plot(pmfit, type="EF")
plot(pmfit$fit)
par(op)

</code></pre>

<hr>
<h2 id='permres'>Permute residuals for a fitted ncvreg model</h2><span id='topic+permres'></span><span id='topic+permres.ncvreg'></span>

<h3>Description</h3>

<p>Fits multiple penalized regression models in which the residuals are
randomly permuted, thereby allowing estimation of the marginal false
discovery rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permres(fit, ...)

## S3 method for class 'ncvreg'
permres(fit, lambda, N = 10, seed, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permres_+3A_fit">fit</code></td>
<td>
<p>A fitted ncvreg model, as produced by <code><a href="#topic+ncvreg">ncvreg</a>()</code>. To
use with <code>permres</code>, the model must be fit using the <code>returnX=TRUE</code>
option.</p>
</td></tr>
<tr><td><code id="permres_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="permres_+3A_lambda">lambda</code></td>
<td>
<p>The regularization parameter to use for estimating residuals.
Unlike <code><a href="#topic+perm.ncvreg">perm.ncvreg</a></code>, <code>permres</code> calculates EF and mFDR for
a specific <code>lambda</code> value, not an entire path.  As a result, it runs
much faster.</p>
</td></tr>
<tr><td><code id="permres_+3A_n">N</code></td>
<td>
<p>The number of permutation replications.  Default is 10.</p>
</td></tr>
<tr><td><code id="permres_+3A_seed">seed</code></td>
<td>
<p>You may set the seed of the random number generator in order to
obtain reproducible results.</p>
</td></tr>
<tr><td><code id="permres_+3A_trace">trace</code></td>
<td>
<p>If set to TRUE, perm.ncvreg will inform the user of its
progress by announcing the beginning of each permutation fit. Default is
FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function fits a penalized regression model to the actual data, then
repeats the process <code>N</code> times with a permuted version of the response
vector.  This allows estimation of the expected number of variables included
by chance for each value of <code>lambda</code>.  The ratio of this expected
quantity to the number of selected variables using the actual (non-permuted)
response is called the marginal false discovery rate (mFDR).
</p>


<h3>Value</h3>

<p>A list with the following components: </p>
<table>
<tr><td><code>EF</code></td>
<td>
<p>The number of
variables selected at each value of <code>lambda</code>, averaged over the
permutation fits.</p>
</td></tr> <tr><td><code>S</code></td>
<td>
<p>The actual number of selected variables for the
non-permuted data.</p>
</td></tr> <tr><td><code>mFDR</code></td>
<td>
<p>The estimated marginal false discovery rate
(<code>EF/S</code>).</p>
</td></tr> <tr><td><code>loss</code></td>
<td>
<p>The loss/deviance, averaged over the permutation
fits.  This is an estimate of the explanatory power of the model under null
conditions, and can be used to adjust the loss of the fitted model in a
manner akin to the idea of an adjusted R-squared in classical regression.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny <a href="mailto:patrick-breheny@uiowa.edu">patrick-breheny@uiowa.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg</a></code>, <code><a href="#topic+mfdr">mfdr</a></code>, <code><a href="#topic+perm.ncvreg">perm.ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Prostate)
fit &lt;- ncvreg(Prostate$X, Prostate$y, N=50)
permres(fit, lambda=0.15)

</code></pre>

<hr>
<h2 id='plot.cv.ncvreg'>Plots the cross-validation curve from a cv.ncvreg object</h2><span id='topic+plot.cv.ncvreg'></span>

<h3>Description</h3>

<p>Plots the cross-validation curve from a <code>cv.ncvreg</code> or
<code>cv.ncvsurv</code> object, along with standard error bars.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.ncvreg'
plot(
  x,
  log.l = TRUE,
  type = c("cve", "rsq", "scale", "snr", "pred", "all"),
  selected = TRUE,
  vertical.line = TRUE,
  col = "red",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.ncvreg_+3A_x">x</code></td>
<td>
<p>A <code>cv.ncvreg</code> or <code>cv.ncvsurv</code> object.</p>
</td></tr>
<tr><td><code id="plot.cv.ncvreg_+3A_log.l">log.l</code></td>
<td>
<p>Should horizontal axis be on the log scale?  Default is TRUE.</p>
</td></tr>
<tr><td><code id="plot.cv.ncvreg_+3A_type">type</code></td>
<td>
<p>What to plot on the vertical axis.  <code>cve</code> plots the
cross-validation error (deviance); <code>rsq</code> plots an estimate of the
fraction of the deviance explained by the model (R-squared); <code>snr</code>
plots an estimate of the signal-to-noise ratio; <code>scale</code> plots, for
<code>family="gaussian"</code>, an estimate of the scale parameter (standard
deviation); <code>pred</code> plots, for <code>family="binomial"</code>, the estimated
prediction error; <code>all</code> produces all of the above.</p>
</td></tr>
<tr><td><code id="plot.cv.ncvreg_+3A_selected">selected</code></td>
<td>
<p>If <code>TRUE</code> (the default), places an axis on top of the
plot denoting the number of variables in the model (i.e., that have a
nonzero regression coefficient) at that value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="plot.cv.ncvreg_+3A_vertical.line">vertical.line</code></td>
<td>
<p>If <code>TRUE</code> (the default), draws a vertical line at
the value where cross-validaton error is minimized.</p>
</td></tr>
<tr><td><code id="plot.cv.ncvreg_+3A_col">col</code></td>
<td>
<p>Controls the color of the dots (CV estimates).</p>
</td></tr>
<tr><td><code id="plot.cv.ncvreg_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Error bars representing approximate 68\
along with the estimates at value of <code>lambda</code>.  For <code>rsq</code> and
<code>snr</code> applied to models other than linear regression, the Cox-Snell
R-squared is used.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>

<p>Breheny P and Huang J. (2011) Coordinate descentalgorithms for
nonconvex penalized regression, with applications to biological feature
selection.  <em>Annals of Applied Statistics</em>, <strong>5</strong>: 232-253.
c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.1214/10-AOAS388&quot;)\ifelse{text}{doi:10.1214/10-AOAS388 &lt;https://doi.org/10.1214/10-AOAS388&gt;}{\ifelse{latex}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214\out{\slash{}}10\out{\-}AOAS388}}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214/10-AOAS388}}}
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg</a></code>, <code><a href="#topic+cv.ncvreg">cv.ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Linear regression --------------------------------------------------
data(Prostate)
cvfit &lt;- cv.ncvreg(Prostate$X, Prostate$y)
plot(cvfit)
op &lt;- par(mfrow=c(2,2))
plot(cvfit, type="all")
par(op)

# Logistic regression ------------------------------------------------
data(Heart)
cvfit &lt;- cv.ncvreg(Heart$X, Heart$y, family="binomial")
plot(cvfit)
op &lt;- par(mfrow=c(2,2))
plot(cvfit, type="all")
par(op)

# Cox regression -----------------------------------------------------
data(Lung)
cvfit &lt;- cv.ncvsurv(Lung$X, Lung$y)
op &lt;- par(mfrow=c(1,2))
plot(cvfit)
plot(cvfit, type="rsq")
par(op)
</code></pre>

<hr>
<h2 id='plot.mfdr'>Plot marginal false discovery rate curves</h2><span id='topic+plot.mfdr'></span>

<h3>Description</h3>

<p>Plot marginal false discovery rate curves from an <code>"mfdr"</code> or
<code>"perm.ncvreg"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mfdr'
plot(
  x,
  type = c("mFDR", "EF"),
  log.l = FALSE,
  selected = TRUE,
  legend = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mfdr_+3A_x">x</code></td>
<td>
<p>A <code>"perm.ncvreg"</code> or <code>"mfdr"</code> object.</p>
</td></tr>
<tr><td><code id="plot.mfdr_+3A_type">type</code></td>
<td>
<p>What to plot on the vertical axis.  <code>mFDR</code> plots the
marginal false discovery rate; <code>EF</code> plots the expected number of false
discoveries along with the actual number of variables included in the model.</p>
</td></tr>
<tr><td><code id="plot.mfdr_+3A_log.l">log.l</code></td>
<td>
<p>Should horizontal axis be on the log scale?  Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.mfdr_+3A_selected">selected</code></td>
<td>
<p>If <code>TRUE</code> (the default), places an axis on top of the
plot denoting the number of variables in the model (i.e., that have a
nonzero regression coefficient) at that value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="plot.mfdr_+3A_legend">legend</code></td>
<td>
<p>For <code>type="EF"</code> plots, draw a legend to indicate which
line is for the actual selections and which line is for the expected number
of false discoveries?  Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.mfdr_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to pass to <code>plot</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>

<p>Breheny P (2019). Marginal false discovery rates for penalized
regression models. Biostatistics, 20: 299-314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mfdr">mfdr</a></code>, <code><a href="#topic+perm.ncvreg">perm.ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Prostate)
fit &lt;- ncvreg(Prostate$X, Prostate$y)

obj &lt;- mfdr(fit)
obj[1:10,]

# Some plotting options
plot(obj)
plot(obj, type="EF")
plot(obj, log=TRUE)


# Comparison with perm.ncvreg
op &lt;- par(mfrow=c(2,2))
plot(obj)
plot(obj, type="EF")
pmfit &lt;- perm.ncvreg(Prostate$X, Prostate$y)
plot(pmfit)
plot(pmfit, type="EF")
par(op)
</code></pre>

<hr>
<h2 id='plot.ncvreg'>Plot coefficients from a ncvreg object</h2><span id='topic+plot.ncvreg'></span>

<h3>Description</h3>

<p>Produces a plot of the coefficient paths for a fitted <code>ncvreg</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncvreg'
plot(x, alpha = 1, log.l = FALSE, shade = TRUE, col, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ncvreg_+3A_x">x</code></td>
<td>
<p>Fitted <code>"ncvreg"</code> model.</p>
</td></tr>
<tr><td><code id="plot.ncvreg_+3A_alpha">alpha</code></td>
<td>
<p>Controls alpha-blending, helpful when the number of covariates
is large.  Default is alpha=1.</p>
</td></tr>
<tr><td><code id="plot.ncvreg_+3A_log.l">log.l</code></td>
<td>
<p>Should horizontal axis be on the log scale?  Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.ncvreg_+3A_shade">shade</code></td>
<td>
<p>Should nonconvex region be shaded?  Default is TRUE.</p>
</td></tr>
<tr><td><code id="plot.ncvreg_+3A_col">col</code></td>
<td>
<p>Vector of colors for coefficient lines.  By default, evenly
spaced colors are selected automatically.</p>
</td></tr>
<tr><td><code id="plot.ncvreg_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>

<p>Breheny P and Huang J. (2011) Coordinate descentalgorithms for
nonconvex penalized regression, with applications to biological feature
selection.  <em>Annals of Applied Statistics</em>, <strong>5</strong>: 232-253.
c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.1214/10-AOAS388&quot;)\ifelse{text}{doi:10.1214/10-AOAS388 &lt;https://doi.org/10.1214/10-AOAS388&gt;}{\ifelse{latex}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214\out{\slash{}}10\out{\-}AOAS388}}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214/10-AOAS388}}}
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Prostate)
fit &lt;- ncvreg(Prostate$X, Prostate$y)
plot(fit)
plot(fit, col="black")
plot(fit, log=TRUE)
fit &lt;- ncvreg(Prostate$X, Prostate$y, penalty.factor=rep(c(1, 1, 1, Inf), 2))
plot(fit, col=c('red', 'black', 'green'))  # Recycled among nonzero paths
</code></pre>

<hr>
<h2 id='plot.ncvsurv.func'>Plot survival curve for ncvsurv model</h2><span id='topic+plot.ncvsurv.func'></span>

<h3>Description</h3>

<p>Plot survival curve for a model that has been fit using <code>ncvsurv</code>
followed by a prediction of the survival function using
<code>predict.ncvsurv</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncvsurv.func'
plot(x, alpha = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ncvsurv.func_+3A_x">x</code></td>
<td>
<p>A <code>'ncvsurv.func'</code> object, which is returned by
<code>predict.ncvsurv</code> if <code>type='survival'</code> is specified.  See
examples.</p>
</td></tr>
<tr><td><code id="plot.ncvsurv.func_+3A_alpha">alpha</code></td>
<td>
<p>Controls alpha-blending (i.e., transparency).  Useful if many
overlapping lines are present.</p>
</td></tr>
<tr><td><code id="plot.ncvsurv.func_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to pass to <code>plot</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvsurv">ncvsurv</a></code>, <code><a href="#topic+predict.ncvsurv">predict.ncvsurv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y

fit &lt;- ncvsurv(X, y)

# A single survival curve
S &lt;- predict(fit, X[1,], type='survival', lambda=.15)
plot(S, xlim=c(0,200))

# Lots of survival curves
S &lt;- predict(fit, X, type='survival', lambda=.08)
plot(S, xlim=c(0,200), alpha=0.3)
</code></pre>

<hr>
<h2 id='predict.cv.ncvreg'>Model predictions based on a fitted ncvreg object.</h2><span id='topic+predict.cv.ncvreg'></span><span id='topic+coef.cv.ncvreg'></span><span id='topic+predict.cv.ncvsurv'></span><span id='topic+predict.ncvreg'></span><span id='topic+coef.ncvreg'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this function returns predictions from a
fitted <code>ncvreg</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.ncvreg'
predict(
  object,
  X,
  type = c("link", "response", "class", "coefficients", "vars", "nvars"),
  which = object$min,
  ...
)

## S3 method for class 'cv.ncvreg'
coef(object, which = object$min, ...)

## S3 method for class 'cv.ncvsurv'
predict(
  object,
  X,
  type = c("link", "response", "survival", "median", "coefficients", "vars", "nvars"),
  which = object$min,
  ...
)

## S3 method for class 'ncvreg'
predict(
  object,
  X,
  type = c("link", "response", "class", "coefficients", "vars", "nvars"),
  lambda,
  which = 1:length(object$lambda),
  ...
)

## S3 method for class 'ncvreg'
coef(object, lambda, which = 1:length(object$lambda), drop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.ncvreg_+3A_object">object</code></td>
<td>
<p>Fitted <code>ncvreg</code> model object.</p>
</td></tr>
<tr><td><code id="predict.cv.ncvreg_+3A_x">X</code></td>
<td>
<p>Matrix of values at which predictions are to be made.  Not used for
<code>type="coefficients"</code> or for some of the <code>type</code> settings in
<code>predict</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.ncvreg_+3A_type">type</code></td>
<td>
<p>Type of prediction: <code>"link"</code> returns the linear predictors;
<code>"response"</code> gives the fitted values; <code>"class"</code> returns the
binomial outcome with the highest probability; <code>"coefficients"</code> returns
the coefficients; <code>"vars"</code> returns a list containing the indices and
names of the nonzero variables at each value of <code>lambda</code>;
<code>"nvars"</code> returns the number of nonzero coefficients at each value of
<code>lambda</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.ncvreg_+3A_which">which</code></td>
<td>
<p>Indices of the penalty parameter <code>lambda</code> at which
predictions are required.  By default, all indices are returned.  If
<code>lambda</code> is specified, this will override <code>which</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.ncvreg_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="predict.cv.ncvreg_+3A_lambda">lambda</code></td>
<td>
<p>Values of the regularization parameter <code>lambda</code> at which
predictions are requested.  For values of <code>lambda</code> not in the sequence
of fitted models, linear interpolation is used.</p>
</td></tr>
<tr><td><code id="predict.cv.ncvreg_+3A_drop">drop</code></td>
<td>
<p>If coefficients for a single value of <code>lambda</code> are to be
returned, reduce dimensions to a vector?  Setting <code>drop=FALSE</code> returns
a 1-column matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>

<p>Breheny P and Huang J. (2011) Coordinate descentalgorithms for
nonconvex penalized regression, with applications to biological feature
selection.  <em>Annals of Applied Statistics</em>, <strong>5</strong>: 232-253.
c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.1214/10-AOAS388&quot;)\ifelse{text}{doi:10.1214/10-AOAS388 &lt;https://doi.org/10.1214/10-AOAS388&gt;}{\ifelse{latex}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214\out{\slash{}}10\out{\-}AOAS388}}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214/10-AOAS388}}}
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Heart)

fit &lt;- ncvreg(Heart$X, Heart$y, family="binomial")
coef(fit, lambda=0.05)
head(predict(fit, Heart$X, type="link", lambda=0.05))
head(predict(fit, Heart$X, type="response", lambda=0.05))
head(predict(fit, Heart$X, type="class", lambda=0.05))
predict(fit, type="vars", lambda=c(0.05, 0.01))
predict(fit, type="nvars", lambda=c(0.05, 0.01))
</code></pre>

<hr>
<h2 id='predict.ncvsurv'>Model predictions based on a fitted &quot;ncvsurv&quot; object.</h2><span id='topic+predict.ncvsurv'></span><span id='topic+coef.ncvsurv'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this function returns predictions from a
fitted <code>"ncvsurv"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncvsurv'
predict(
  object,
  X,
  type = c("link", "response", "survival", "hazard", "median", "coefficients", "vars",
    "nvars"),
  lambda,
  which = 1:length(object$lambda),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ncvsurv_+3A_object">object</code></td>
<td>
<p>Fitted <code>"ncvsurv"</code> model object.</p>
</td></tr>
<tr><td><code id="predict.ncvsurv_+3A_x">X</code></td>
<td>
<p>Matrix of values at which predictions are to be made.  Not used for
<code>type="coefficients"</code> or for some of the <code>type</code> settings in
<code>predict</code>.</p>
</td></tr>
<tr><td><code id="predict.ncvsurv_+3A_type">type</code></td>
<td>
<p>Type of prediction: <code>"link"</code> returns the linear predictors;
<code>"response"</code> gives the risk (i.e., exp(link)); <code>"survival"</code>
returns the estimated survival function; <code>"median"</code> estimates median
survival times.  The other options are all identical to their <code>ncvreg</code>
counterparts: <code>"coefficients"</code> returns the coefficients; <code>"vars"</code>
returns a list containing the indices and names of the nonzero variables at
each value of <code>lambda</code>; <code>"nvars"</code> returns the number of nonzero
coefficients at each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="predict.ncvsurv_+3A_lambda">lambda</code></td>
<td>
<p>Values of the regularization parameter <code>lambda</code> at which
predictions are requested.  For values of <code>lambda</code> not in the sequence
of fitted models, linear interpolation is used.</p>
</td></tr>
<tr><td><code id="predict.ncvsurv_+3A_which">which</code></td>
<td>
<p>Indices of the penalty parameter <code>lambda</code> at which
predictions are required.  By default, all indices are returned.  If
<code>lambda</code> is specified, this will override <code>which</code>.</p>
</td></tr>
<tr><td><code id="predict.ncvsurv_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimation of baseline survival function conditional on the estimated values
of <code>beta</code> is carried out according to the method described in Chapter
4.3 of Kalbfleish and Prentice.  In particular, it agrees exactly the
results returned by <code>survfit.coxph(..., type='kalbfleisch-prentice')</code>
in the <code>survival</code> package.
</p>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny <a href="mailto:patrick-breheny@uiowa.edu">patrick-breheny@uiowa.edu</a>
</p>


<h3>References</h3>

 <ul>
<li><p> Breheny P and Huang J. (2011) Coordinate
descentalgorithms for nonconvex penalized regression, with applications to
biological feature selection.  <em>Annals of Applied Statistics</em>,
<strong>5</strong>: 232-253.  c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.1214/10-AOAS388&quot;)\ifelse{text}{doi:10.1214/10-AOAS388 &lt;https://doi.org/10.1214/10-AOAS388&gt;}{\ifelse{latex}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214\out{\slash{}}10\out{\-}AOAS388}}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214/10-AOAS388}}}
</p>
</li>
<li><p> Kalbfleish JD and Prentice RL (2002). <em>The Statistical Analysis
of Failure Time Data</em>, 2nd edition. Wiley.  </p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ncvsurv">ncvsurv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y

fit &lt;- ncvsurv(X,y)
coef(fit, lambda=0.05)
head(predict(fit, X, type="link", lambda=0.05))
head(predict(fit, X, type="response", lambda=0.05))

# Survival function
S &lt;- predict(fit, X[1,], type="survival", lambda=0.05)
S(100)
S &lt;- predict(fit, X, type="survival", lambda=0.05)
plot(S, xlim=c(0,200))

# Medians
predict(fit, X[1,], type="median", lambda=0.05)
M &lt;- predict(fit, X, type="median")
M[1:10, 1:10]

# Nonzero coefficients
predict(fit, type="vars", lambda=c(0.1, 0.01))
predict(fit, type="nvars", lambda=c(0.1, 0.01))
</code></pre>

<hr>
<h2 id='Prostate'>Factors associated with prostate specific antigen</h2><span id='topic+Prostate'></span><span id='topic+prostate'></span>

<h3>Description</h3>

<p>Data from a study by by Stamey et al. (1989) to examine the association
between prostate specific antigen (PSA) and several clinical measures that
are potentially associated with PSA in men who were about to receive a
radical prostatectomy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Prostate
</code></pre>


<h3>Format</h3>

<p>A list of two objects: <code>y</code> and <code>X</code>
</p>

<dl>
<dt>y</dt><dd><p>Log PSA</p>
</dd>
<dt>X</dt><dd><p>A matrix with 97 instances (rows) and 8 predictor variables
(columns). The remainder of this list describes the columns of <code>X</code></p>
</dd>
<dt>lcavol</dt><dd><p>Log cancer volume</p>
</dd>
<dt>lweight</dt><dd><p>Log prostate weight</p>
</dd>
<dt>age</dt><dd><p>The man's age (years)</p>
</dd>
<dt>lbph</dt><dd><p>Log of the amount of benign hyperplasia</p>
</dd>
<dt>svi</dt><dd><p>Seminal vesicle invasion (1=Yes, 0=No)</p>
</dd>
<dt>lcp</dt><dd><p>Log of capsular penetration</p>
</dd>
<dt>gleason</dt><dd><p>Gleason score</p>
</dd>
<dt>pgg45</dt><dd><p>Percent of Gleason scores 4 or 5</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">https://web.stanford.edu/~hastie/ElemStatLearn/</a>
</p>


<h3>References</h3>


<ul>
<li><p> Hastie T, Tibshirani R, and Friedman J. (2001). <em>The Elements of
Statistical Learning</em>.  Springer.
</p>
</li>
<li><p> Stamey T, et al. (1989). Prostate specific antigen in the diagnosis
and treatment of adenocarcinoma of the prostate. II. Radical prostatectomy
treated patients. <em>Journal of Urology</em>, <strong>16</strong>: 1076-1083.
</p>
</li></ul>


<hr>
<h2 id='residuals.ncvreg'>Extract residuals from a ncvreg or ncvsurv fit</h2><span id='topic+residuals.ncvreg'></span>

<h3>Description</h3>

<p>Currently, only deviance residuals are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncvreg'
residuals(object, lambda, which = 1:length(object$lambda), drop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.ncvreg_+3A_object">object</code></td>
<td>
<p>Object of class <code>ncvreg</code> or <code>ncvsurv</code>.</p>
</td></tr>
<tr><td><code id="residuals.ncvreg_+3A_lambda">lambda</code></td>
<td>
<p>Values of the regularization parameter at which residuals are requested (numeric vector). For values of lambda not in the sequence of fitted models, linear interpolation is used.</p>
</td></tr>
<tr><td><code id="residuals.ncvreg_+3A_which">which</code></td>
<td>
<p>Index of the penalty parameter at which residuals are requested (default = all indices). If <code>lambda</code> is specified, this take precedence over <code>which</code>.</p>
</td></tr>
<tr><td><code id="residuals.ncvreg_+3A_drop">drop</code></td>
<td>
<p>By default, if a single value of lambda is supplied, a vector of residuals is returned (logical; default=<code>TRUE</code>). Set <code>drop=FALSE</code> if you wish to have the function always return a matrix (see <code><a href="base.html#topic+drop">drop()</a></code>).</p>
</td></tr>
<tr><td><code id="residuals.ncvreg_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(Prostate)
X &lt;- Prostate$X
y &lt;- Prostate$y
fit &lt;- ncvreg(X, y)
residuals(fit)[1:5, 1:5]
head(residuals(fit, lambda=0.1))
</code></pre>

<hr>
<h2 id='std'>Standardizes a design matrix</h2><span id='topic+std'></span>

<h3>Description</h3>

<p>The function <code>std</code> accepts a design matrix and returns a standardized version of that matrix (i.e., each column will have mean 0 and mean sum of squares equal to 1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std(X, Xnew)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="std_+3A_x">X</code></td>
<td>
<p>A matrix (or object that can be coerced to a matrix, such as a data frame or numeric vector).</p>
</td></tr>
<tr><td><code id="std_+3A_xnew">Xnew</code></td>
<td>
<p>Optional. If supplied, <code>X</code> must be the output of <code>std()</code> and <code>Xnew</code> is to be standardized in the same way. See examples for why this might be useful.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function centers and scales each column of <code>X</code> so that
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^n x_{ij}=0</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">n^{-1} \sum_{i=1}^n x_{ij}^2 = 1</code>
</p>

<p>for all j.  This is usually not necessary to call directly, as <code>ncvreg</code> internally standardizes the design matrix, but inspection of the standardized design matrix can sometimes be useful.  This differs from the base R function <code><a href="base.html#topic+scale">scale</a></code> in two ways:
</p>

<ol>
<li> <p><code>scale</code> uses the sample standard deviation <code>sqrt(sum(x^2)/(n-1))</code>, while <code>std</code> uses the root-mean-square (population) standard deviation <code>sqrt(mean(sum(x^2)))</code>
</p>
</li>
<li> <p><code>std</code> is faster.
</p>
</li></ol>



<h3>Value</h3>

<p>The standardized design matrix, with the following attribues:
</p>

<ul>
<li> <p><code>center</code>, <code>scale</code>: mean and standard deviation used to scale the columns
</p>
</li>
<li> <p><code>nonsingular</code>: A vector indicating which columns of the original design matrix were able to be standardized (constant columns cannot be standardized to have a standard deviation of 1)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(Prostate)
S &lt;- std(Prostate$X)
apply(S, 2, sum)
apply(S, 2, function(x) mean(x^2))

# Standardizing new observations
X1 &lt;- Prostate$X[1:90,]
X2 &lt;- Prostate$X[91:97,]
S &lt;- std(X1)
head(std(S, X2))
# Useful if you fit to a standardized X, but then get new obs:
y &lt;- Prostate$y[1:90]
fit &lt;- ncvreg(S, y)
predict(fit, std(S, X2), lambda=0.1)
# Same as
predict(ncvreg(X1, y), X2, lambda=0.1)
</code></pre>

<hr>
<h2 id='summary.cv.ncvreg'>Summarizing cross-validation-based inference</h2><span id='topic+summary.cv.ncvreg'></span><span id='topic+print.summary.cv.ncvreg'></span>

<h3>Description</h3>

<p>Summary method for <code>cv.ncvreg</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.ncvreg'
summary(object, ...)

## S3 method for class 'summary.cv.ncvreg'
print(x, digits, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.cv.ncvreg_+3A_object">object</code></td>
<td>
<p>A <code>"cv.ncvreg"</code> or <code>"cv.ncvsurv"</code> object.</p>
</td></tr>
<tr><td><code id="summary.cv.ncvreg_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.cv.ncvreg_+3A_x">x</code></td>
<td>
<p>A <code>"summary.cv.ncvreg"</code> object.</p>
</td></tr>
<tr><td><code id="summary.cv.ncvreg_+3A_digits">digits</code></td>
<td>
<p>Number of digits past the decimal point to print out.  Can be
a vector specifying different display digits for each of the five
non-integer printed values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.cv.ncvreg</code> produces an object with S3 class
<code>"summary.cv.ncvreg"</code>.  The class has its own print method and contains
the following list elements: </p>
 <dl>
<dt>penalty</dt><dd><p>The penalty used by
<code>ncvreg</code>.</p>
</dd> <dt>model</dt><dd><p>Either <code>"linear"</code> or <code>"logistic"</code>,
depending on the <code>family</code> option in <code>ncvreg</code>.</p>
</dd> <dt>n</dt><dd><p>Number of
observations</p>
</dd> <dt>p</dt><dd><p>Number of regression coefficients (not including the
intercept).</p>
</dd> <dt>min</dt><dd><p>The index of <code>lambda</code> with the smallest
cross-validation error.</p>
</dd> <dt>lambda</dt><dd><p>The sequence of <code>lambda</code> values
used by <code>cv.ncvreg</code>.</p>
</dd> <dt>cve</dt><dd><p>Cross-validation error (deviance).</p>
</dd>
<dt>r.squared</dt><dd><p>Proportion of variance explained by the model, as estimated
by cross-validation.  For models outside of linear regression, the Cox-Snell
approach to defining R-squared is used.</p>
</dd> <dt>snr</dt><dd><p>Signal to noise ratio,
as estimated by cross-validation.</p>
</dd> <dt>sigma</dt><dd><p>For linear regression
models, the scale parameter estimate.</p>
</dd> <dt>pe</dt><dd><p>For logistic regression
models, the prediction error (misclassification error).</p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>

<p>Breheny P and Huang J. (2011) Coordinate descentalgorithms for
nonconvex penalized regression, with applications to biological feature
selection.  <em>Annals of Applied Statistics</em>, <strong>5</strong>: 232-253.
c(&quot;\Sexpr[results=rd]tools:::Rd_expr_doi(\&quot;#1\&quot;)&quot;,
&quot;10.1214/10-AOAS388&quot;)\ifelse{text}{doi:10.1214/10-AOAS388 &lt;https://doi.org/10.1214/10-AOAS388&gt;}{\ifelse{latex}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214\out{\slash{}}10\out{\-}AOAS388}}{\href{https://doi.org/10.1214/10-AOAS388}{doi:10.1214/10-AOAS388}}}
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg</a></code>, <code><a href="#topic+cv.ncvreg">cv.ncvreg</a></code>,
<code><a href="#topic+plot.cv.ncvreg">plot.cv.ncvreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Linear regression --------------------------------------------------
data(Prostate)
cvfit &lt;- cv.ncvreg(Prostate$X, Prostate$y)
summary(cvfit)

# Logistic regression ------------------------------------------------
data(Heart)
cvfit &lt;- cv.ncvreg(Heart$X, Heart$y, family="binomial")
summary(cvfit)

# Cox regression -----------------------------------------------------
data(Lung)
cvfit &lt;- cv.ncvsurv(Lung$X, Lung$y)
summary(cvfit)
</code></pre>

<hr>
<h2 id='summary.ncvreg'>Summary method for ncvreg objects</h2><span id='topic+summary.ncvreg'></span><span id='topic+print.summary.ncvreg'></span>

<h3>Description</h3>

<p>Inferential summaries for <code>ncvreg</code> and <code>ncvsurv</code> objects based on local marginal false discovery rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncvreg'
summary(object, lambda, which, number, cutoff, sort = TRUE, sigma, ...)

## S3 method for class 'summary.ncvreg'
print(x, digits, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ncvreg_+3A_object">object</code></td>
<td>
<p>An <code>ncvreg</code> or <code>ncvsurv</code> object.</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_lambda">lambda</code></td>
<td>
<p>The regularization parameter value at which inference should be reported.</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_which">which</code></td>
<td>
<p>Alternatively, <code>lambda</code> may be specified by index; <code>which=10</code> means: report inference for the 10th value of
<code>lambda</code> along the regularization path.  If both <code>lambda</code> and <code>which</code> are specified, <code>lambda</code> takes precedence.</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_number">number</code></td>
<td>
<p>By default, <code>summary</code> will provide an inferential summary for each variable that has been selected (i.e.,  each
variable with a nonzero coefficient).  Specifying <code>number=5</code>, for example, means that the summary table will include the 5
features with the lowest mfdr values, regardless of whether they were selected.  To see all features, <code>number=Inf</code>.</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_cutoff">cutoff</code></td>
<td>
<p>Alternatively, specifying for example <code>cutoff=0.3</code> will report inference for all features with mfdr under 30%.
If both <code>number</code> and <code>cutoff</code> are specified, the intersection between both sets of features is reported.</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_sort">sort</code></td>
<td>
<p>Should the results be sorted by <code>mfdr</code>? (default: TRUE)</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_sigma">sigma</code></td>
<td>
<p>For linear regression models, users can supply an estimate of the residual standard deviation.
The default is to use RSS / DF, where degrees of freedom are approximated using the number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_...">...</code></td>
<td>
<p>Further arguments; in particular, if you have set <code>returnX=FALSE</code>, you will need to supply <code>X</code> and <code>y</code> in order to calculate local mFDRs.</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_x">x</code></td>
<td>
<p>A <code>summary.ncvreg</code> object.</p>
</td></tr>
<tr><td><code id="summary.ncvreg_+3A_digits">digits</code></td>
<td>
<p>Number of digits past the decimal point to print out. Can be a vector specifying different display digits for
each of the five non-integer printed values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Whether passed an <code>ncvreg</code> or <code>ncvsurv</code> object, the return value is an object with S3 class <code>summary.ncvreg</code>. The class has its own print method and contains the following list elements:
</p>

<ul>
<li> <p><code>penalty</code>: The penalty used by <code>ncvreg</code> or <code>ncvsurv</code>.
</p>
</li>
<li> <p><code>model</code>: Either <code>"linear"</code>, <code>"logistic"</code>, or <code>"Cox"</code>.
</p>
</li>
<li> <p><code>n</code>: Number of instances.
</p>
</li>
<li> <p><code>p</code>: Number of regression coefficients (not including the intercept).
</p>
</li>
<li> <p><code>lambda</code>: The <code>lambda</code> value at which inference is being reported.
</p>
</li>
<li> <p><code>nvars</code>: The number of nonzero coefficients (again, not including the intercept) at that value of <code>lambda</code>.
</p>
</li>
<li> <p><code>table</code>: A table containing estimates, normalized test statistics (z), and an estimate of the local mfdr for each coefficient.
The mfdr may be loosely interpreted, in an empirical Bayes sense, as the probability that the given feature is null.
</p>
</li>
<li> <p><code>unpen.table</code>: If there are any unpenalized coefficients, a separate inferential summary is given for them.  Currently, this is
based on <code>lm</code>/<code>glm</code>/<code>coxph</code> using the penalized coefficients to provide an offset.  This is useful and more or less
accurate, but not ideal; we hope to improve the inferential methods for unpenalized variables in the future.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Patrick Breheny <a href="mailto:patrick-breheny@uiowa.edu">patrick-breheny@uiowa.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncvreg">ncvreg()</a></code>, <code><a href="#topic+cv.ncvreg">cv.ncvreg()</a></code>, <code><a href="#topic+plot.cv.ncvreg">plot.cv.ncvreg()</a></code>, <code><a href="#topic+local_mfdr">local_mfdr()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Linear regression --------------------------------------------------
data(Prostate)
fit &lt;- ncvreg(Prostate$X, Prostate$y)
summary(fit, lambda=0.08)

# Logistic regression ------------------------------------------------
data(Heart)
fit &lt;- ncvreg(Heart$X, Heart$y, family="binomial")
summary(fit, lambda=0.05)

# Cox regression -----------------------------------------------------
data(Lung)
fit &lt;- ncvsurv(Lung$X, Lung$y)
summary(fit, lambda=0.1)

# Options ------------------------------------------------------------
fit &lt;- ncvreg(Heart$X, Heart$y, family="binomial")
summary(fit, lambda=0.08, number=3)
summary(fit, lambda=0.08, number=Inf)
summary(fit, lambda=0.08, cutoff=0.5)
summary(fit, lambda=0.08, number=3, cutoff=0.5)
summary(fit, lambda=0.08, number=5, cutoff=0.1)
summary(fit, lambda=0.08, number=Inf, sort=FALSE)
summary(fit, lambda=0.08, number=3, cutoff=0.5, sort=FALSE)

# If X and y are not returned with the fit, they must be supplied
fit &lt;- ncvreg(Heart$X, Heart$y, family="binomial", returnX=FALSE)
summary(fit, X=Heart$X, y=Heart$y, lambda=0.08)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
