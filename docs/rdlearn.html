<!DOCTYPE html><html lang="en"><head><title>Help for package rdlearn</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rdlearn}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#package_rdlearn'><p>Safe Policy Learning for Regression Discontinuity Designs</p></a></li>
<li><a href='#acces'><p>ACCES Program</p></a></li>
<li><a href='#plot'><p>Plot Cutoff Changes for rdlearn Objects</p></a></li>
<li><a href='#rdestimate'><p>RD Estimate Function</p></a></li>
<li><a href='#rdlearn'><p>Safe Policy Learning for Regression Discontinuity Design with Multiple</p>
Cutoffs</a></li>
<li><a href='#sens'><p>Sensitivity Analysis for rdlearn Objects</p></a></li>
<li><a href='#simdata_A'><p>Simulation Data A</p></a></li>
<li><a href='#simdata_B'><p>Simulation Data B</p></a></li>
<li><a href='#summary'><p>Summary function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Safe Policy Learning under Regression Discontinuity Design with
Multiple Cutoffs</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements safe policy learning under regression discontinuity designs
    with multiple cutoffs, based on Zhang et al. (2022) &lt;<a href="https://doi.org/10.48550%2FarXiv.2208.13323">doi:10.48550/arXiv.2208.13323</a>&gt;.
    The learned cutoffs are guaranteed  to perform no worse than the existing
    cutoffs in terms of overall outcomes. The 'rdlearn' package also includes
    features for visualizing the learned cutoffs relative to the baseline and
    conducting sensitivity analyses.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kkawato/rdlearn">https://github.com/kkawato/rdlearn</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kkawato/rdlearn/issues">https://github.com/kkawato/rdlearn/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>nprobust, nnet, rdrobust, ggplot2, dplyr, glue, cli</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-26 04:18:09 UTC; kawatokentaryuu</td>
</tr>
<tr>
<td>Author:</td>
<td>Kentaro Kawato [cre, cph],
  Yi Zhang [aut],
  Soichiro Yamauchi [aut],
  Eli Ben-Michael [aut],
  Kosuke Imai [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kentaro Kawato &lt;kentaro1358nohe@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-29 18:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='package_rdlearn'>Safe Policy Learning for Regression Discontinuity Designs</h2><span id='topic+rdlearn-package'></span><span id='topic+package_rdlearn'></span>

<h3>Description</h3>

<p>The <code>rdlearn</code> package provides tools for safe policy
learning under regression discontinuity designs with multiple cutoffs.
</p>


<h3>Package Functions</h3>

<p>The <code>rdlearn</code> package offers the following
main functions:
</p>
<p><b>Policy Learning</b>
</p>

<ul>
<li> <p><code><a href="#topic+rdlearn">rdlearn</a></code>: Learn new treatment assignment cutoffs
</p>
</li></ul>

<p><b>Visualization</b>
</p>

<ul>
<li> <p><code><a href="#topic+plot">plot</a></code>: Visualize the learned cutoffs
</p>
</li></ul>

<p><b>Sensitivity Analysis</b>
</p>

<ul>
<li> <p><code><a href="#topic+sens">sens</a></code>: Perform sensitivity analysis
</p>
</li></ul>

<p><b>RD Estimate</b>
</p>

<ul>
<li> <p><code><a href="#topic+rdestimate">rdestimate</a></code>: Estimate RD treatment effects
</p>
</li></ul>

<p><b>Summary</b>
</p>

<ul>
<li> <p><code><a href="#topic+summary">summary</a></code>: Summarize the result of <code><a href="#topic+rdlearn">rdlearn</a></code> and <code><a href="#topic+rdestimate">rdestimate</a></code>
</p>
</li></ul>

<p>This package also contains the ACCES Program data <code><a href="#topic+acces">acces</a></code> for
replication of Section 6 of Zhang et al. (2022). We thank Tatiana Velasco
and her coauthors for sharing the dataset (Melguizo et al. (2016)).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Kentaro Kawato <a href="mailto:kentaro1358nohe@gmail.com">kentaro1358nohe@gmail.com</a> [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Yi Zhang
</p>
</li>
<li><p> Soichiro Yamauchi
</p>
</li>
<li><p> Eli Ben-Michael
</p>
</li>
<li><p> Kosuke Imai
</p>
</li></ul>



<h3>References</h3>

<p>Zhang, Y., Ben-Michael, E. and Imai, K. (2022) 'Safe Policy
Learning under Regression Discontinuity Designs with Multiple Cutoffs',
arXiv [stat.ME]. Available at: <a href="http://arxiv.org/abs/2208.13323">http://arxiv.org/abs/2208.13323</a>.
</p>
<p>Melguizo, F., Sanchez, F., and Velasco, T. (2016) 'Credit for Low Income
Students and Access to and Academic Performance in Higher Education in
Colombia: A Regression Discontinuity Approach', World Development, 80(1):
61-77.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/kkawato/rdlearn">https://github.com/kkawato/rdlearn</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/kkawato/rdlearn/issues">https://github.com/kkawato/rdlearn/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Simulation Data B from Appendix D of Zhang et al. (2022)
set.seed(1)
n &lt;- 300
X &lt;- runif(n, -1000, -1)
G &lt;- 2 * as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &gt; 0)
) +
as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &lt;= 0)
)
c1 &lt;- -850
c0 &lt;- -571
C &lt;- ifelse(G == 1, c1, c0)
D &lt;- as.numeric(X &gt;= C)
coef0 &lt;- c(-1.992230e+00, -1.004582e-02, -1.203897e-05, -4.587072e-09)
coef1 &lt;- c(9.584361e-01, 5.308251e-04, 1.103375e-06, 1.146033e-09)
Px &lt;- poly(X, degree = 3, raw = TRUE)
# Px = poly(X-735.4334-c1,degree=3,raw=TRUE) for Simulation A
Px &lt;- cbind(rep(1, nrow(Px)), Px)
EY0 &lt;- Px %*% coef0
EY1 &lt;- Px %*% coef1
d &lt;- 0.2 + exp(0.01 * X) * (1 - G) + 0.3 * (1 - D)
Y &lt;- EY0 * (1 - D) + EY1 * D - d * as.numeric(I(G == 1)) + rnorm(n, sd = 0.3)

simdata_B_demo &lt;- data.frame(Y,X,C)

# Learn new treatment assignment cutoffs
rdlearn_result &lt;- rdlearn(
  y = "Y", x = "X", c = "C", data = simdata_B_demo,
  fold = 2, M = 0, cost = 0
)

# Summarise the learned policies
summary(rdlearn_result)

# Visualize the learned policies
plot(rdlearn_result, opt = "dif")
# The learned cutoff for Group 1 is the same as the baseline cutoff, because
# the baseline cutoff is set to equal to oracle cutoff in this simulation.

# Implement sensitivity analysis
sens_result &lt;- sens(rdlearn_result, M = 1, cost = 0)
plot(sens_result, opt = "dif")
</code></pre>

<hr>
<h2 id='acces'>ACCES Program</h2><span id='topic+acces'></span>

<h3>Description</h3>

<p>A dataset comprising 8245 applicants to the ACCES Program across 23 different
departments in Colombia, including eligibility for the ACCES Program,
position score of the SABER 11, cutoff of each department, and the name of
each department.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acces
</code></pre>


<h3>Format</h3>

<p>A data frame with 8245 rows and 4 columns: </p>

<dl>
<dt>elig</dt><dd><p>eligibility for the ACCES Program.
1: eligible; 0: not eligible</p>
</dd>
<dt>saber11</dt><dd><p>position scores of the SABER 11.
We multiply the position score by -1 so that the values of the running variable
above a cutoff lead to the program eligibility.</p>
</dd>
<dt>cutoff</dt><dd><p>cutoffs of each department.</p>
</dd>
<dt>department</dt><dd><p>the names of each department.</p>
</dd></dl>



<h3>References</h3>

<p>Melguizo, T., F. Sanchez, and T. Velasco (2016). Credit for
low-income students and access to and academic performance in higher
education in colombia: A regression discontinuity approach. World
development 80, 61-77.
</p>

<hr>
<h2 id='plot'>Plot Cutoff Changes for rdlearn Objects</h2><span id='topic+plot'></span>

<h3>Description</h3>

<p>This function plots the changes in cutoff values relative to the baseline cutoffs
for each group, under different combinations of the smoothness
multiplier (M) and the cost of treatment (C).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot(x, opt, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>An object of class <code>rdlearn</code> returned by the
<code><a href="#topic+rdlearn">rdlearn</a></code> function.</p>
</td></tr>
<tr><td><code id="plot_+3A_opt">opt</code></td>
<td>
<p>When set to &quot;safe&quot;, it displays the derived safe cutoffs and the
original cutoffs. When set to &quot;dif&quot;, it displays the change in cutoffs.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot2</code> plot which also contains the distance measure between original cutoffs and safe cutoffs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulation Data B from Appendix D of Zhang et al. (2022)
set.seed(1)
n &lt;- 300
X &lt;- runif(n, -1000, -1)
G &lt;- 2 * as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &gt; 0)
) +
as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &lt;= 0)
)
c1 &lt;- -850
c0 &lt;- -571
C &lt;- ifelse(G == 1, c1, c0)
D &lt;- as.numeric(X &gt;= C)
coef0 &lt;- c(-1.992230e+00, -1.004582e-02, -1.203897e-05, -4.587072e-09)
coef1 &lt;- c(9.584361e-01, 5.308251e-04, 1.103375e-06, 1.146033e-09)
Px &lt;- poly(X, degree = 3, raw = TRUE)
# Px = poly(X-735.4334-c1,degree=3,raw=TRUE) for Simulation A
Px &lt;- cbind(rep(1, nrow(Px)), Px)
EY0 &lt;- Px %*% coef0
EY1 &lt;- Px %*% coef1
d &lt;- 0.2 + exp(0.01 * X) * (1 - G) + 0.3 * (1 - D)
Y &lt;- EY0 * (1 - D) + EY1 * D - d * as.numeric(I(G == 1)) + rnorm(n, sd = 0.3)

simdata_B_demo &lt;- data.frame(Y,X,C)

# Learn new treatment assignment cutoffs
rdlearn_result &lt;- rdlearn(
  y = "Y", x = "X", c = "C", data = simdata_B_demo,
  fold = 2, M = 0, cost = 0
)

# Summarise the learned policies
summary(rdlearn_result)

# Visualize the learned policies
plot(rdlearn_result, opt = "dif")
# The learned cutoff for Group 1 is the same as the baseline cutoff, because
# the baseline cutoff is set to equal to oracle cutoff in this simulation.

# Implement sensitivity analysis
sens_result &lt;- sens(rdlearn_result, M = 1, cost = 0)
plot(sens_result, opt = "dif")
</code></pre>

<hr>
<h2 id='rdestimate'>RD Estimate Function</h2><span id='topic+rdestimate'></span>

<h3>Description</h3>

<p>This function estimates local causal effect of treatment under standard
regression discontinuity (RD) setting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdestimate(y, x, c, group_name = NULL, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rdestimate_+3A_y">y</code></td>
<td>
<p>A character string specifying the name of column containing the
outcome variable.</p>
</td></tr>
<tr><td><code id="rdestimate_+3A_x">x</code></td>
<td>
<p>A character string specifying the name of column containing the
running variable.</p>
</td></tr>
<tr><td><code id="rdestimate_+3A_c">c</code></td>
<td>
<p>A character string specifying the name of column containing the
cutoff variable.</p>
</td></tr>
<tr><td><code id="rdestimate_+3A_group_name">group_name</code></td>
<td>
<p>A character ctring specifying the name of the column
containing group names (e.g., department names) for each cutoff. If not
provided, the groups are assigned names &quot;Group 1&quot;, &quot;Group 2&quot;, ... in
ascending order of cutoff values.</p>
</td></tr>
<tr><td><code id="rdestimate_+3A_data">data</code></td>
<td>
<p>A data frame containing all required variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the RD estimates for each group, including the
sample size of each group, baseline cutoff, RD estimate, standard error,
and p-value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rdestimate_result &lt;- rdestimate(
  y = "elig", x = "saber11", c = "cutoff",
  group_name = "department", data = acces
)
print(rdestimate_result)
</code></pre>

<hr>
<h2 id='rdlearn'>Safe Policy Learning for Regression Discontinuity Design with Multiple
Cutoffs</h2><span id='topic+rdlearn'></span>

<h3>Description</h3>

<p>The <code>rdlearn</code> function implements safe policy learning under a
regression discontinuity design with multiple cutoffs. The resulting new
treatment assignment rules (cutoffs) are guaranteed to yield no worse overall
outcomes than the existing cutoffs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdlearn(
  y,
  x,
  c,
  group_name = NULL,
  data,
  fold = 10,
  M = 1,
  cost = 0,
  trace = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rdlearn_+3A_y">y</code></td>
<td>
<p>A character string specifying the name of column containing the outcome variable.</p>
</td></tr>
<tr><td><code id="rdlearn_+3A_x">x</code></td>
<td>
<p>A character string specifying the name of column containing the running variable.</p>
</td></tr>
<tr><td><code id="rdlearn_+3A_c">c</code></td>
<td>
<p>A character string specifying the name of column containing the cutoff variable.</p>
</td></tr>
<tr><td><code id="rdlearn_+3A_group_name">group_name</code></td>
<td>
<p>A character string specifying the name of the column
containing group names (e.g., department names) for each cutoff. If not
provided, the groups are assigned names &quot;Group 1&quot;, &quot;Group 2&quot;, ... in
ascending order of cutoff values.</p>
</td></tr>
<tr><td><code id="rdlearn_+3A_data">data</code></td>
<td>
<p>A data frame containing all required variables.</p>
</td></tr>
<tr><td><code id="rdlearn_+3A_fold">fold</code></td>
<td>
<p>The number of folds for cross-fitting. Default is 10.</p>
</td></tr>
<tr><td><code id="rdlearn_+3A_m">M</code></td>
<td>
<p>A numeric value or vector specifying the multiplicative smoothness
factor(s) for sensitivity analysis. Default is 1.</p>
</td></tr>
<tr><td><code id="rdlearn_+3A_cost">cost</code></td>
<td>
<p>A numeric value or vector specifying the cost of treatment for
calculating regret. This cost should be scaled by the range of the outcome
variable Y. Default is 0.</p>
</td></tr>
<tr><td><code id="rdlearn_+3A_trace">trace</code></td>
<td>
<p>A logical value that controls whether to display the progress.
If set to TRUE, the progress will be printed. The default value is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Regarding the detail of the algorithm, please refer to Zhang et al. (2022) &quot;4 Empirical policy
learning&quot; and &quot;A.2 A double robust estimator for heterogeneous cross-group
differences&quot;.
</p>


<h3>Value</h3>

<p>An object of class <code>rdlearn</code>, which is a list containing the
following components:
</p>

<dl>
<dt>call</dt><dd><p>The original function call.</p>
</dd>
<dt>var_names</dt><dd><p>A list of variable names for the outcome, running variable, and cutoff.</p>
</dd>
<dt>org_cut</dt><dd><p>A vector of original cutoff values.</p>
</dd>
<dt>safe_cut</dt><dd><p>A data frame containing the obtained new treatment assignment cutoffs.</p>
</dd>
<dt>sample</dt><dd><p>The total sample size.</p>
</dd>
<dt>num_group</dt><dd><p>The number of groups.</p>
</dd>
<dt>group_name</dt><dd><p>A vector of group names.</p>
</dd>
<dt>cross_fit_output</dt><dd><p>The intermediate output of the cross-fitting procedure.</p>
</dd>
<dt>dif_lip_output</dt><dd><p>The intermediate output of the cross-group differences and the smoothness parameters</p>
</dd>
<dt>distance</dt><dd><p>A numeric vector containing the measures of difference between safe cutoffs and original cutoffs</p>
</dd>
<dt>rdestimates</dt><dd><p>A data frame containing the result of <code>rdesimate</code> such as causal effect estimates.</p>
</dd>
<dt>temp_reg_df</dt><dd><p>A data frame containing the regrets of every alternative cutoff.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># Simulation Data B from Appendix D of Zhang et al. (2022)
set.seed(1)
n &lt;- 300
X &lt;- runif(n, -1000, -1)
G &lt;- 2 * as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &gt; 0)
) +
as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &lt;= 0)
)
c1 &lt;- -850
c0 &lt;- -571
C &lt;- ifelse(G == 1, c1, c0)
D &lt;- as.numeric(X &gt;= C)
coef0 &lt;- c(-1.992230e+00, -1.004582e-02, -1.203897e-05, -4.587072e-09)
coef1 &lt;- c(9.584361e-01, 5.308251e-04, 1.103375e-06, 1.146033e-09)
Px &lt;- poly(X, degree = 3, raw = TRUE)
# Px = poly(X-735.4334-c1,degree=3,raw=TRUE) for Simulation A
Px &lt;- cbind(rep(1, nrow(Px)), Px)
EY0 &lt;- Px %*% coef0
EY1 &lt;- Px %*% coef1
d &lt;- 0.2 + exp(0.01 * X) * (1 - G) + 0.3 * (1 - D)
Y &lt;- EY0 * (1 - D) + EY1 * D - d * as.numeric(I(G == 1)) + rnorm(n, sd = 0.3)

simdata_B_demo &lt;- data.frame(Y,X,C)

# Learn new treatment assignment cutoffs
rdlearn_result &lt;- rdlearn(
  y = "Y", x = "X", c = "C", data = simdata_B_demo,
  fold = 2, M = 0, cost = 0
)

# Summarise the learned policies
summary(rdlearn_result)

# Visualize the learned policies
plot(rdlearn_result, opt = "dif")
# The learned cutoff for Group 1 is the same as the baseline cutoff, because
# the baseline cutoff is set to equal to oracle cutoff in this simulation.

# Implement sensitivity analysis
sens_result &lt;- sens(rdlearn_result, M = 1, cost = 0)
plot(sens_result, opt = "dif")
</code></pre>

<hr>
<h2 id='sens'>Sensitivity Analysis for rdlearn Objects</h2><span id='topic+sens'></span>

<h3>Description</h3>

<p>This function performs sensitivity analysis for the <code>rdlearn</code> object
under different smoothness multiplier (M) and the cost of treatment (cost).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sens(object, M = NULL, cost = NULL, trace = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sens_+3A_object">object</code></td>
<td>
<p>An object of class <code>rdlearn</code> returned by the
<code><a href="#topic+rdlearn">rdlearn</a></code> function.</p>
</td></tr>
<tr><td><code id="sens_+3A_m">M</code></td>
<td>
<p>A numeric value or vector specifying the multiplicative smoothness
factor(s) for sensitivity analysis.</p>
</td></tr>
<tr><td><code id="sens_+3A_cost">cost</code></td>
<td>
<p>A numeric value or vector specifying the cost of treatment for
calculating regret.</p>
</td></tr>
<tr><td><code id="sens_+3A_trace">trace</code></td>
<td>
<p>A logical value that controls whether to display the progress of
cross-fitting and regret calculation. If set to TRUE, the progress will be
printed. The default value is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated <code>rdlearn</code> object with the new cutoffs based on the
provided values of M and cost.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulation Data B from Appendix D of Zhang et al. (2022)
set.seed(1)
n &lt;- 300
X &lt;- runif(n, -1000, -1)
G &lt;- 2 * as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &gt; 0)
) +
as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &lt;= 0)
)
c1 &lt;- -850
c0 &lt;- -571
C &lt;- ifelse(G == 1, c1, c0)
D &lt;- as.numeric(X &gt;= C)
coef0 &lt;- c(-1.992230e+00, -1.004582e-02, -1.203897e-05, -4.587072e-09)
coef1 &lt;- c(9.584361e-01, 5.308251e-04, 1.103375e-06, 1.146033e-09)
Px &lt;- poly(X, degree = 3, raw = TRUE)
# Px = poly(X-735.4334-c1,degree=3,raw=TRUE) for Simulation A
Px &lt;- cbind(rep(1, nrow(Px)), Px)
EY0 &lt;- Px %*% coef0
EY1 &lt;- Px %*% coef1
d &lt;- 0.2 + exp(0.01 * X) * (1 - G) + 0.3 * (1 - D)
Y &lt;- EY0 * (1 - D) + EY1 * D - d * as.numeric(I(G == 1)) + rnorm(n, sd = 0.3)

simdata_B_demo &lt;- data.frame(Y,X,C)

# Learn new treatment assignment cutoffs
rdlearn_result &lt;- rdlearn(
  y = "Y", x = "X", c = "C", data = simdata_B_demo,
  fold = 2, M = 0, cost = 0
)

# Summarise the learned policies
summary(rdlearn_result)

# Visualize the learned policies
plot(rdlearn_result, opt = "dif")
# The learned cutoff for Group 1 is the same as the baseline cutoff, because
# the baseline cutoff is set to equal to oracle cutoff in this simulation.

# Implement sensitivity analysis
sens_result &lt;- sens(rdlearn_result, M = 1, cost = 0)
plot(sens_result, opt = "dif")
</code></pre>

<hr>
<h2 id='simdata_A'>Simulation Data A</h2><span id='topic+simdata_A'></span>

<h3>Description</h3>

<p>This dataset is based on the ACCES Program and generated according to
scenario A described in Appendix D of Zhang et al. (2022). In this scenario,
the baseline policy (cutoff) is set equal to the oracle policy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simdata_A
</code></pre>


<h3>Format</h3>

<p>A data frame with 2000 rows and 3 columns:
</p>

<dl>
<dt>Y</dt><dd><p>outcome variable</p>
</dd>
<dt>X</dt><dd><p>running variable</p>
</dd>
<dt>C</dt><dd><p>cutoff value</p>
</dd>
</dl>



<h3>References</h3>

<p>Zhang, Y., Ben-Michael, E. and Imai, K. (2022) 'Safe Policy
Learning under Regression Discontinuity Designs with Multiple Cutoffs',
arXiv [stat.ME]. Available at: <a href="http://arxiv.org/abs/2208.13323">http://arxiv.org/abs/2208.13323</a>.
</p>

<hr>
<h2 id='simdata_B'>Simulation Data B</h2><span id='topic+simdata_B'></span>

<h3>Description</h3>

<p>This dataset is based on the ACCES Program and generated according to
scenario B described in Appendix D of Zhang et al. (2022). In this scenario,
the baseline policy (cutoff) differs from the oracle policy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simdata_B
</code></pre>


<h3>Format</h3>

<p>A data frame with 2000 rows and 3 columns:
</p>

<dl>
<dt>Y</dt><dd><p>outcome variable</p>
</dd>
<dt>X</dt><dd><p>running variable</p>
</dd>
<dt>C</dt><dd><p>cutoff value</p>
</dd>
</dl>



<h3>References</h3>

<p>Zhang, Y., Ben-Michael, E. and Imai, K. (2022) 'Safe Policy
Learning under Regression Discontinuity Designs with Multiple Cutoffs',
arXiv [stat.ME]. Available at: <a href="http://arxiv.org/abs/2208.13323">http://arxiv.org/abs/2208.13323</a>.
</p>

<hr>
<h2 id='summary'>Summary function</h2><span id='topic+summary'></span>

<h3>Description</h3>

<p>This function summarizes the key results returned by <code>rdlearn</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>An object of class <code>rdlearn</code> returned by the
<code><a href="#topic+rdlearn">rdlearn</a></code> function.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Displays key outputs from the <code><a href="#topic+rdlearn">rdlearn</a></code> function. It
provides basic information and RD causal effect estimates from
<code><a href="#topic+rdestimate">rdestimate</a></code>, as well as the safe cutoffs derived by
<code><a href="#topic+rdlearn">rdlearn</a></code> and the difference between them and the original
cutoffs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulation Data B from Appendix D of Zhang et al. (2022)
set.seed(1)
n &lt;- 300
X &lt;- runif(n, -1000, -1)
G &lt;- 2 * as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &gt; 0)
) +
as.numeric(
I(0.01 * X + 5 + rnorm(n, sd = 10) &lt;= 0)
)
c1 &lt;- -850
c0 &lt;- -571
C &lt;- ifelse(G == 1, c1, c0)
D &lt;- as.numeric(X &gt;= C)
coef0 &lt;- c(-1.992230e+00, -1.004582e-02, -1.203897e-05, -4.587072e-09)
coef1 &lt;- c(9.584361e-01, 5.308251e-04, 1.103375e-06, 1.146033e-09)
Px &lt;- poly(X, degree = 3, raw = TRUE)
# Px = poly(X-735.4334-c1,degree=3,raw=TRUE) for Simulation A
Px &lt;- cbind(rep(1, nrow(Px)), Px)
EY0 &lt;- Px %*% coef0
EY1 &lt;- Px %*% coef1
d &lt;- 0.2 + exp(0.01 * X) * (1 - G) + 0.3 * (1 - D)
Y &lt;- EY0 * (1 - D) + EY1 * D - d * as.numeric(I(G == 1)) + rnorm(n, sd = 0.3)

simdata_B_demo &lt;- data.frame(Y,X,C)

# Learn new treatment assignment cutoffs
rdlearn_result &lt;- rdlearn(
  y = "Y", x = "X", c = "C", data = simdata_B_demo,
  fold = 2, M = 0, cost = 0
)

# Summarise the learned policies
summary(rdlearn_result)

# Visualize the learned policies
plot(rdlearn_result, opt = "dif")
# The learned cutoff for Group 1 is the same as the baseline cutoff, because
# the baseline cutoff is set to equal to oracle cutoff in this simulation.

# Implement sensitivity analysis
sens_result &lt;- sens(rdlearn_result, M = 1, cost = 0)
plot(sens_result, opt = "dif")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
