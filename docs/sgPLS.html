<!DOCTYPE html><html lang="en"><head><title>Help for package sgPLS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sgPLS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#sgPLS-package'>
<p>Group and Sparse Group Partial Least Square Model</p></a></li>
<li><a href='#gPLS'><p>Group Partial Least Squares (gPLS)</p></a></li>
<li><a href='#gPLSda'><p>Group Sparse Partial Least Squares Discriminant Analysis (sPLS-DA)</p></a></li>
<li><a href='#per.variance'><p>Percentage of variance of the <code class="reqn">Y</code> matrix explained by the score-vectors obtained by PLS approaches</p></a></li>
<li><a href='#perf'><p>Compute evaluation criteria for PLS, sPLS, PLS-DA and sPLS-DA</p></a></li>
<li><a href='#plotcim'><p>Plots a cluster image mapping of correlations between</p>
outcomes and all predictors</a></li>
<li><a href='#predict'><p>Predict Method for sPLS, gPLS, sgPLS, sPLDda, gPLSda, sgPLSda</p></a></li>
<li><a href='#select.sgpls'><p>Output of selected variables from a gPLS model or a sgPLS model</p></a></li>
<li><a href='#select.spls'><p>Output of selected variables from a sPLS model</p></a></li>
<li><a href='#sgPLS'><p>Sparse Group Partial Least Squares (sgPLS)</p></a></li>
<li><a href='#sgPLS-internal'><p>Internal Functions</p></a></li>
<li><a href='#sgPLSda'><p>Sparse Group Sparse Partial Least Squares Discriminant Analysis (sPLS-DA)</p></a></li>
<li><a href='#simuData'><p>Simulated Data for group PLS-DA model</p></a></li>
<li><a href='#sPLS'><p>Sparse Partial Least Squares (sPLS)</p></a></li>
<li><a href='#sPLSda'><p>Sparse Partial Least Squares Discriminant Analysis (sPLS-DA)</p></a></li>
<li><a href='#tuning.gPLS.X'><p>Choice of the tuning parameter (number of groups) related to  predictor matrix for gPLS model (regression mode)</p></a></li>
<li><a href='#tuning.sgPLS.X'><p>Choice of the tuning parameters (number of groups and mixing parameter) related to  predictor matrix for sgPLS model (regression mode)</p></a></li>
<li><a href='#tuning.sPLS.X'><p>Choice of the tuning parameter (number of variables) related to  predictor matrix for sPLS model (regression mode)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sparse Group Partial Least Square Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>1.8</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-04</td>
</tr>
<tr>
<td>Author:</td>
<td>Benoit Liquet and Pierre Lafaye de Micheaux and Camilo Broc</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Benoit Liquet &lt;b.liquet@uq.edu.au&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>mixOmics, mvtnorm</td>
</tr>
<tr>
<td>Description:</td>
<td>Regularized version of partial least square approaches providing sparse, group, and sparse group versions of partial least square regression models (Liquet, B., Lafaye de Micheaux, P., Hejblum B., Thiebaut, R. (2016) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtv535">doi:10.1093/bioinformatics/btv535</a>&gt;). Version of PLS Discriminant analysis is also provided.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-05 04:08:00 UTC; liquet</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-05 05:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='sgPLS-package'>
Group and Sparse Group Partial Least Square Model
</h2><span id='topic+sgPLS-package'></span>

<h3>Description</h3>

<p>The sgPLS package provides sparse, group and sparse group
version for PLS approaches. 
The main functions are:  <code><a href="#topic+sPLS">sPLS</a></code> for sparse PLS, <code><a href="#topic+gPLS">gPLS</a></code> for group PLS and <code><a href="#topic+sgPLS">sgPLS</a></code> for sparse group PLS.
</p>


<h3>Author(s)</h3>

<p>Benoit Liquet &lt;b.liquet@uq.edu.au&gt;, Pierre Lafaye de Micheaux</p>


<h3>References</h3>

<p>Liquet Benoit, Lafaye de Micheaux Pierre, Hejblum Boris, Thiebaut Rodolphe. A group and Sparse Group Partial Least Square approach applied in Genomics context. <em>Submitted</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sgPLS">sgPLS</a></code>, <code><a href="#topic+gPLS">gPLS</a></code>
</p>

<hr>
<h2 id='gPLS'>Group Partial Least Squares (gPLS)</h2><span id='topic+gPLS'></span>

<h3>Description</h3>

<p>Function to perform group Partial Least Squares (gPLS) in
the context of two datasets which are both divided into groups of
variables. The gPLS approach aims to select only a few groups of
variables from one dataset which are linearly related to a few groups of variables of the second dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gPLS(X, Y, ncomp, mode = "regression",
     max.iter = 500, tol = 1e-06, keepX, 
     keepY = NULL, ind.block.x, ind.block.y = NULL,scale=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gPLS_+3A_x">X</code></td>
<td>
<p>numeric matrix of predictors.</p>
</td></tr>
<tr><td><code id="gPLS_+3A_y">Y</code></td>
<td>
<p>numeric vector or matrix of responses (for multi-response models).</p>
</td></tr>
<tr><td><code id="gPLS_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to include in the model (see Details).</p>
</td></tr>
<tr><td><code id="gPLS_+3A_mode">mode</code></td>
<td>
<p>character string. What type of algorithm to use, (partially) matching 
one of <code>"regression"</code> or <code>"canonical"</code>. See Details.</p>
</td></tr>
<tr><td><code id="gPLS_+3A_max.iter">max.iter</code></td>
<td>
<p>integer, the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="gPLS_+3A_tol">tol</code></td>
<td>
<p>a positive real, the tolerance used in the iterative algorithm.</p>
</td></tr>
<tr><td><code id="gPLS_+3A_keepx">keepX</code></td>
<td>
<p>numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">X</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="gPLS_+3A_keepy">keepY</code></td>
<td>
<p>numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">Y</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="gPLS_+3A_ind.block.x">ind.block.x</code></td>
<td>
<p>a vector of integers describing the grouping of the <code class="reqn">X</code>-variables. (see an example in Details section)</p>
</td></tr>
<tr><td><code id="gPLS_+3A_ind.block.y">ind.block.y</code></td>
<td>
<p>a vector of consecutive integers describing the grouping of the <code class="reqn">Y</code>-variables (see an example in Details section)</p>
</td></tr>
<tr><td><code id="gPLS_+3A_scale">scale</code></td>
<td>
<p>a logical indicating if the orignal data set need to be scaled. By default <code>scale</code>=TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gPLS</code> function fits gPLS models with <code class="reqn">1, \ldots ,</code><code>ncomp</code> components. 
Multi-response models are fully supported. 
</p>
<p>The type of algorithm to use is specified with the <code>mode</code> argument. Two gPLS 
algorithms are available: gPLS regression <code>("regression")</code> and gPLS canonical analysis 
<code>("canonical")</code> (see References). 
</p>
<p><code>ind.block.x &lt;- c(3,10,15)</code> means that <code class="reqn">X</code> is structured into 4 groups: X1 to X3; X4 to X10, X11 to X15 and X16 to X<code class="reqn">p</code> where <code class="reqn">p</code> is the number of variables in the <code class="reqn">X</code> matrix.</p>


<h3>Value</h3>

<p><code>gPLS</code> returns an object of class <code>"gPLS"</code>, a list 
that contains the following components:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>the centered and standardized original predictor matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the centered and standardized original response vector or matrix.</p>
</td></tr>
<tr><td><code>ncomp</code></td>
<td>
<p>the number of components included in the model.</p>
</td></tr>
<tr><td><code>mode</code></td>
<td>
<p>the algorithm used to fit the model.</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>number of <code class="reqn">X</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>keepY</code></td>
<td>
<p>number of <code class="reqn">Y</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>mat.c</code></td>
<td>
<p>matrix of coefficients to be used internally by <code>predict</code>.</p>
</td></tr>
<tr><td><code>variates</code></td>
<td>
<p>list containing the variates.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>list containing the estimated loadings for the <code class="reqn">X</code> and 
<code class="reqn">Y</code> variates.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>list containing the names to be used for individuals and variables.</p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>the tolerance used in the iterative algorithm, used for subsequent S3 methods.</p>
</td></tr>
<tr><td><code>max.iter</code></td>
<td>
<p>the maximum number of iterations, used for subsequent S3 methods.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>vector containing the number of iterations for convergence in each component.</p>
</td></tr> 
<tr><td><code>ind.block.x</code></td>
<td>
<p>a vector of integers describing the grouping of the X variables.</p>
</td></tr>
<tr><td><code>ind.block.y</code></td>
<td>
<p>a vector of consecutive integers describing the grouping of the Y variables. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux.</p>


<h3>References</h3>

<p>Liquet Benoit, Lafaye de Micheaux Pierre , Hejblum Boris, Thiebaut Rodolphe. A group and Sparse Group Partial Least Square approach applied in Genomics context. <em>Submitted</em>.
</p>
<p>Le Cao, K.-A., Martin, P.G.P., Robert-Grani\'e, C. and Besse, P. (2009). Sparse canonical methods for biological data integration: application to a cross-platform study. <em>BMC Bioinformatics</em> <b>10</b>:34.
</p>
<p>Le Cao, K.-A., Rossouw, D., Robert-Grani\'e, C. and Besse, P. (2008). A sparse PLS for variable 
selection when integrating Omics data. <em>Statistical Applications in Genetics and Molecular 
Biology</em> <b>7</b>, article 35.
</p>
<p>Shen, H. and Huang, J. Z. (2008). Sparse principal component analysis via regularized 
low rank matrix approximation. <em>Journal of Multivariate Analysis</em> <b>99</b>, 1015-1034.    
</p>
<p>Tenenhaus, M. (1998). <em>La r\'egression PLS: th\'eorie et pratique</em>. Paris: Editions Technic.
</p>
<p>Wold H. (1966). Estimation of principal components and related models by iterative least squares. 
In: Krishnaiah, P. R. (editors), <em>Multivariate Analysis</em>. Academic Press, N.Y., 391-420.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sPLS">sPLS</a></code>, <code><a href="#topic+sgPLS">sgPLS</a></code>, <code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="#topic+perf">perf</a></code>, <code>cim</code> and functions from <code>mixOmics</code> package: <code>summary</code>, <code>plotIndiv</code>, <code>plotVar</code>, <code>plot3dIndiv</code>, <code>plot3dVar</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>	
## Simulation of datasets X and Y with group variables
n &lt;- 100
sigma.gamma &lt;- 1
sigma.e &lt;- 1.5
p &lt;- 400
q &lt;- 500
theta.x1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5,15), 
              rep(0, 5), rep(-1.5, 15), rep(0, 325))
theta.x2 &lt;- c(rep(0, 320), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
              rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5))

theta.y1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5, 15),
              rep(0, 5), rep(-1.5, 15), rep(0, 425))
theta.y2 &lt;- c(rep(0, 420), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
              rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5))                            


Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0,nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

set.seed(125)

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.y1, theta.y2), 
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, q), sigma =
     Sigmay, method = "svd")


ind.block.x &lt;- seq(20, 380, 20)
ind.block.y &lt;- seq(20, 480, 20)
##


#### gPLS model
model.gPLS &lt;- gPLS(X, Y, ncomp = 2, mode = "regression", keepX = c(4, 4), 
     keepY = c(4, 4), ind.block.x = ind.block.x , ind.block.y = ind.block.y)

result.gPLS &lt;- select.sgpls(model.gPLS)
result.gPLS$group.size.X
result.gPLS$group.size.Y
</code></pre>

<hr>
<h2 id='gPLSda'>Group Sparse Partial Least Squares Discriminant Analysis (sPLS-DA)</h2><span id='topic+gPLSda'></span>

<h3>Description</h3>

<p>Function to perform group Partial Least Squares to classify samples (supervised analysis) and select variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gPLSda(X, Y, ncomp = 2, keepX = rep(ncol(X), ncomp),
       max.iter = 500, tol = 1e-06, ind.block.x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gPLSda_+3A_x">X</code></td>
<td>
<p>numeric matrix of predictors. <code>NA</code>s are allowed.</p>
</td></tr>
<tr><td><code id="gPLSda_+3A_y">Y</code></td>
<td>
<p>a factor or a class vector for the discrete outcome.</p>
</td></tr>
<tr><td><code id="gPLSda_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to include in the model (see Details).</p>
</td></tr>
<tr><td><code id="gPLSda_+3A_keepx">keepX</code></td>
<td>
<p>numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">X</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="gPLSda_+3A_max.iter">max.iter</code></td>
<td>
<p>integer, the maximum number of iterations.</p>
</td></tr>   
<tr><td><code id="gPLSda_+3A_tol">tol</code></td>
<td>
<p>a positive real, the tolerance used in the iterative algorithm.</p>
</td></tr> 
<tr><td><code id="gPLSda_+3A_ind.block.x">ind.block.x</code></td>
<td>
<p>a vector of integers describing the grouping of the <code class="reqn">X</code>-variables. (see an example in Details section)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gPLSda</code> function fit gPLS models with <code class="reqn">1, \ldots ,</code><code>ncomp</code> components
to the factor or class vector <code>Y</code>. The appropriate indicator (dummy)
matrix is created.
</p>
<p><code>ind.block.x &lt;- c(3,10,15)</code> means that <code class="reqn">X</code> is structured into 4 groups: X1 to X3; X4 to X10, X11 to X15 and X16 to X<code class="reqn">p</code> where <code class="reqn">p</code> is the number of variables in the <code class="reqn">X</code> matrix.</p>


<h3>Value</h3>

<p><code>sPLSda</code> returns an object of class <code>"sPLSda"</code>, a list 
that contains the following components:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>the centered and standardized original predictor matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the centered and standardized indicator response vector or matrix.</p>
</td></tr>
<tr><td><code>ind.mat</code></td>
<td>
<p>the indicator matrix.</p>
</td></tr>
<tr><td><code>ncomp</code></td>
<td>
<p>the number of components included in the model.</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>number of <code class="reqn">X</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>mat.c</code></td>
<td>
<p>matrix of coefficients to be used internally by <code>predict</code>.</p>
</td></tr>
<tr><td><code>variates</code></td>
<td>
<p>list containing the variates.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>list containing the estimated loadings for the <code>X</code> and 
<code>Y</code> variates.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>list containing the names to be used for individuals and variables.</p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>the tolerance used in the iterative algorithm, used for subsequent S3 methods</p>
</td></tr>
<tr><td><code>max.iter</code></td>
<td>
<p>the maximum number of iterations, used for subsequent S3 methods</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations of the algorthm for each component</p>
</td></tr>
<tr><td><code>ind.block.x</code></td>
<td>
<p>a vector of integers describing the grouping of the X variables.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet  and Pierre Lafaye de Micheaux.</p>


<h3>References</h3>

<p>Liquet Benoit, Lafaye de Micheaux Pierre , Hejblum Boris, Thiebaut Rodolphe (2016). A group and Sparse Group Partial Least Square approach applied in Genomics context. <em>Bioinformatics</em>.	
</p>
<p>On sPLS-DA:
Le Cao, K.-A., Boitard, S. and Besse, P. (2011). Sparse PLS Discriminant Analysis: biologically relevant feature selection and graphical displays for multiclass problems. <em>BMC Bioinformatics</em> <b>12</b>:253.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sPLS">sPLS</a></code>, <code><a href="base.html#topic+summary">summary</a></code>, 
<code>plotIndiv</code>, <code>plotVar</code>, 
<code>cim</code>, <code>network</code>, <code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="#topic+perf">perf</a></code> and http://www.mixOmics.org for more details.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(simuData)
X &lt;- simuData$X
Y &lt;- simuData$Y
ind.block.x &lt;- seq(100, 900, 100)
model &lt;- gPLSda(X, Y, ncomp = 3,ind.block.x=ind.block.x, keepX = c(2, 2, 2))
result.gPLSda &lt;- select.sgpls(model)
result.gPLSda$group.size.X

# perf(model,criterion="all",validation="loo") -&gt; res
# res$error.rate
		
</code></pre>

<hr>
<h2 id='per.variance'>Percentage of variance of the <code class="reqn">Y</code> matrix explained by the score-vectors obtained by PLS approaches</h2><span id='topic+per.variance'></span>

<h3>Description</h3>

<p>The <code>per.variance</code> function computes the percentage of variance of the <code class="reqn">Y</code> matrix explained by the score-vectors obtained by PLS approaches (sPLS, gPLS or sgPLS) in a regression mode.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  per.variance(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="per.variance_+3A_object">object</code></td>
<td>
<p>object of class inheriting from <code>"sPLS"</code>, <code>"gPLS"</code>, 
or <code>"sgPLS"</code>. The function will retrieve some key parameters stored in that object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>per.variance</code> produces a list with the following components: 
</p>
<table role = "presentation">
<tr><td><code>perX</code></td>
<td>
<p>Percentage of variance of the <code class="reqn">Y</code> matrix explained by each score-vectors.</p>
</td></tr>
<tr><td><code>cum.perX</code></td>
<td>
<p>The cumulative of the percentage of variance of the <code class="reqn">Y</code> matrix explained by the score-vectors.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet, <a href="mailto:b.liquet@uq.edu.au">b.liquet@uq.edu.au</a>, <br /> Pierre Lafaye de Micheaux <a href="mailto:lafaye@dms.umontreal.ca">lafaye@dms.umontreal.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 	
## Simulation of datasets X and Y with group variables
n &lt;- 100
sigma.gamma &lt;- 1
sigma.e &lt;- 1.5
p &lt;- 400
q &lt;- 500
theta.x1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5, 15),
              rep(0, 5), rep(-1.5, 15), rep(0, 325))
theta.x2 &lt;- c(rep(0, 320), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
              rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5))

theta.y1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5, 15),
              rep(0, 5), rep(-1.5, 15), rep(0, 425))
theta.y2 &lt;- c(rep(0, 420), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
              rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5))

Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

set.seed(125)

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.y1, theta.y2), 
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, q), sigma =
     Sigmay, method = "svd")

ind.block.x &lt;- seq(20, 380, 20)
ind.block.y &lt;- seq(20, 480, 20)

#### gPLS model
model.sgPLS &lt;- sgPLS(X, Y, ncomp = 2, mode = "regression", keepX = c(4, 4), 
                   keepY = c(4, 4), ind.block.x = ind.block.x,
                   ind.block.y = ind.block.y,
                   alpha.x = c(0.5, 0.5), alpha.y = c(0.5, 0.5))

result.sgPLS &lt;- select.sgpls(model.sgPLS)
result.sgPLS$group.size.X
result.sgPLS$group.size.Y

#### gPLS model
model.gPLS &lt;- gPLS(X, Y, ncomp = 2, mode = "regression", keepX = c(4, 4), 
     keepY = c(4, 4), ind.block.x = ind.block.x ,ind.block.y = ind.block.y)

result.gPLS &lt;- select.sgpls(model.gPLS)
result.gPLS$group.size.X
result.gPLS$group.size.Y

per.variance(model.gPLS)
per.variance(model.sgPLS)


## End(Not run)
</code></pre>

<hr>
<h2 id='perf'>Compute evaluation criteria for PLS, sPLS, PLS-DA and sPLS-DA</h2><span id='topic+perf'></span><span id='topic+perf.sPLS'></span><span id='topic+perf.gPLS'></span><span id='topic+perf.sgPLS'></span><span id='topic+perf.sPLSda'></span><span id='topic+perf.gPLSda'></span><span id='topic+perf.sgPLSda'></span>

<h3>Description</h3>

<p>Function to evaluate the performance of the fitted sparse PLS, group PLS, sparse group PLS, sparse PLS-DA, group PLS-DA and sparse group PLS-DA models using various criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>           

## S3 method for class 'sPLS'
perf(object, 
          criterion = c("all", "MSEP", "R2", "Q2"), 
          validation = c("Mfold", "loo"), 
          folds = 10, progressBar = TRUE, setseed = 1,...)
          
## S3 method for class 'gPLS'
perf(object, 
          criterion = c("all", "MSEP", "R2", "Q2"), 
          validation = c("Mfold", "loo"), 
          folds = 10, progressBar = TRUE, setseed = 1, ...)
          
## S3 method for class 'sgPLS'
perf(object, 
          criterion = c("all", "MSEP", "R2", "Q2"), 
          validation = c("Mfold", "loo"), 
          folds = 10, progressBar = TRUE,setseed = 1, ...)
          
          
## S3 method for class 'sPLSda'
perf(object,
          method.predict = c("all", "max.dist", "centroids.dist", "mahalanobis.dist"),
          validation = c("Mfold", "loo"), 
          folds = 10, progressBar = TRUE, ...)	

## S3 method for class 'gPLSda'
perf(object,
          method.predict = c("all", "max.dist", "centroids.dist", "mahalanobis.dist"),
          validation = c("Mfold", "loo"), 
          folds = 10, progressBar = TRUE, ...)
          
## S3 method for class 'sgPLSda'
perf(object,
          method.predict = c("all", "max.dist", "centroids.dist", "mahalanobis.dist"),
          validation = c("Mfold", "loo"), 
          folds = 10, progressBar = TRUE, ...)                  
          
          
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="perf_+3A_object">object</code></td>
<td>
<p>Object of class inheriting from <code>"sPLS"</code>, <code>"gPLS"</code>, <code>"sgPLS"</code>, <code>"sPLSda"</code>, <code>"gPLSda"</code> or <code>"sgPLSda"</code>. The function will retrieve some key parameters stored in that object.</p>
</td></tr>
<tr><td><code id="perf_+3A_criterion">criterion</code></td>
<td>
<p>The criteria measures to be calculated (see Details). Can be set to either <code>"all"</code>, <code>"MSEP"</code>, <code>"R2"</code>, <code>"Q2"</code>. By default set to <code>"all"</code>. Only applies to an object inheriting from <code>"sPLS"</code>, <code>"gPLS"</code> or <code>"sgPLS"</code></p>
</td></tr>
<tr><td><code id="perf_+3A_method.predict">method.predict</code></td>
<td>
<p>only applies to an object inheriting from <code>"PLSda"</code>, <code>"gPLSda"</code> or <code>"sgPLSda"</code> to evaluate the classification performance of the model. Should be a subset of <code>"max.dist"</code>, <code>"centroids.dist"</code>, <code>"mahalanobis.dist"</code>. Default is <code>"all"</code>. See <code><a href="stats.html#topic+predict">predict</a></code>.</p>
</td></tr>
<tr><td><code id="perf_+3A_validation">validation</code></td>
<td>
<p>Character.  What kind of (internal) validation to use, matching one of <code>"Mfold"</code> or 
<code>"loo"</code> (see below). Default is <code>"Mfold"</code>.</p>
</td></tr>
<tr><td><code id="perf_+3A_folds">folds</code></td>
<td>
<p>The folds in the Mfold cross-validation. See Details.</p>
</td></tr>
<tr><td><code id="perf_+3A_progressbar">progressBar</code></td>
<td>
<p>By default set to <code>TRUE</code> to output the progress bar of the computation.</p>
</td></tr>
<tr><td><code id="perf_+3A_setseed">setseed</code></td>
<td>
<p>Integer value to specify the random generator state.</p>
</td></tr>
<tr><td><code id="perf_+3A_...">...</code></td>
<td>
<p>Not used at the moment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method <code>perf</code> has been created by Sebastien Dejean, Ignacio Gonzalez, Amrit Singh and Kim-Anh Le Cao for pls and spls models performed by <code>mixOmics</code> package. Similar code has been adapted for sPLS, gPLS and sgPLS in the package <code>sgPLS</code>. 	
</p>
<p><code>perf</code> estimates the 
mean squared error of prediction (MSEP), <code class="reqn">R^2</code>, and <code class="reqn">Q^2</code> to assess the predictive 
performance of the model using M-fold or leave-one-out cross-validation. Note that only the <code>classic</code>, <code>regression</code> and  <code>invariant</code> modes can be applied.
</p>
<p>If <code>validation = "Mfold"</code>, M-fold cross-validation is performed. 
How many folds to generate is selected by specifying the number of folds in <code>folds</code>.
The folds also can be supplied as a list of vectors containing the indexes defining each 
fold as produced by <code>split</code>.
If <code>validation = "loo"</code>, leave-one-out cross-validation is performed.
</p>
<p>For fitted sPLS-DA, gPLS-DA and sgPLS-DA models, <code>perf</code> estimates the classification error rate 
using cross-validation. 
</p>
<p>Note that the <code>perf</code> function will retrieve the <code>keepX</code> and <code>keepY</code> inputs from the previously run object. The sPLS, gPLS, sgPLS, sPLSda, gPLSda or sgPLSda functions will be run again on several and different subsets of data (the cross-folds) and certainly on different subset of selected features. For sPLS, the MSEP, <code class="reqn">R^2</code>, and <code class="reqn">Q^2</code> criteria are averaged across all folds. A feature stability measure is output for the user to assess how often the variables are selected across all folds. For sPLS-DA, the classification erro rate is averaged across all folds.
</p>


<h3>Value</h3>

<p><code>perf</code> produces a list with the following components: 
</p>
<table role = "presentation">
<tr><td><code>MSEP</code></td>
<td>
<p>Mean Square Error Prediction for each <code class="reqn">Y</code> variable, only applies to object inherited from <code>"sPLS"</code>, <code>"gPLS"</code> and <code>"sgPLS"</code>.</p>
</td></tr>
<tr><td><code>R2</code></td>
<td>
<p>a matrix of <code class="reqn">R^2</code> values of the <code class="reqn">Y</code>-variables for models 
with <code class="reqn">1, \ldots ,</code><code>ncomp</code> components, only applies to object inherited from <code>"sPLS"</code>, <code>"gPLS"</code> and <code>"sgPLS"</code>.</p>
</td></tr>
<tr><td><code>Q2</code></td>
<td>
<p>if <code class="reqn">Y</code> contains one variable, a vector of <code class="reqn">Q^2</code> values else a list with 
a matrix of <code class="reqn">Q^2</code> values for each <code class="reqn">Y</code>-variable. Note that in the specific case of an sPLS model, it is better to have a look at the Q2.total criterion, only applies to object inherited from from <code>"sPLS"</code>, <code>"gPLS"</code> and <code>"sgPLS"</code>.</p>
</td></tr>
<tr><td><code>Q2.total</code></td>
<td>
<p>a vector of <code class="reqn">Q^2</code>-total values for models with <code class="reqn">1, \ldots ,</code><code>ncomp</code> components, only applies to object inherited from from <code>"sPLS"</code>, <code>"gPLS"</code> and <code>"sgPLS"</code>.</p>
</td></tr>
<tr><td><code>features</code></td>
<td>
<p>a list of features selected across the folds (<code>$stable.X</code> and <code>$stable.Y</code>) or on the whole data set (<code>$final</code>) for the <code>keepX</code> and <code>keepY</code> parameters from the input object.</p>
</td></tr>
<tr><td><code>error.rate</code></td>
<td>

<p>For sPLS-DA, gPLS-DA and sgPLS-DA models, <code>perf</code> produces a matrix of classification error rate estimation. 
The dimensions correspond to the components in the model and to the prediction method used, respectively. Note that error rates reported in any component include the performance of the model in earlier components for the specified <code>keepX</code> parameters (e.g. error rate reported for component 3 for <code>keepX = 20</code> already includes the fitted model on components 1 and 2 for  <code>keepX = 20</code>). For more advanced usage of the <code>perf</code> function, see mixOmics package and consider using the <code>predict</code> function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux</p>


<h3>References</h3>

	
<p>Tenenhaus, M. (1998). <em>La r\'egression PLS: th\'eorie et pratique</em>. Paris: Editions Technic. 
</p>
<p>Le Cao, K.-A., Rossouw, D., Robert-Grani\'e, C. and Besse, P. (2008). A sparse PLS for variable 
selection when integrating Omics data. <em>Statistical Applications in Genetics and Molecular 
Biology</em> <b>7</b>, article 35.
</p>
<p>Mevik, B.-H., Cederkvist, H. R. (2004). Mean Squared Error of Prediction (MSEP) Estimates for Principal Component 
Regression (PCR) and Partial Least Squares Regression (PLSR). <em>Journal of Chemometrics</em> <b>18</b>(9), 422-429.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+predict">predict</a></code>, <code>plot.perf</code> (from package <code>mixOmics</code>)</p>


<h3>Examples</h3>

<pre><code class='language-R'>## validation for objects of class 'sPLS' (regression)
## Example from mixOmics package 
# ----------------------------------------
## Not run: 
data(liver.toxicity)
X &lt;- liver.toxicity$gene
Y &lt;- liver.toxicity$clinic


## validation for objects of class 'spls' (regression)
# ----------------------------------------
ncomp &lt;- 7
# first, learn the model on the whole data set
model.spls &lt;- sPLS(X, Y, ncomp = ncomp, mode = 'regression',
	 keepX = c(rep(5, ncomp)), keepY = c(rep(2, ncomp)))


# with leave-one-out cross validation
set.seed(45)
model.spls.loo.val &lt;- perf(model.spls, validation = "loo")

#Q2 total
model.spls.loo.val$Q2.total

# R2:we can see how the performance degrades when ncomp increases
# results are similar to 5-fold
model.spls.loo.val$R2


## End(Not run)

</code></pre>

<hr>
<h2 id='plotcim'>Plots a cluster image mapping of correlations between
outcomes and all predictors</h2><span id='topic+plotcim'></span>

<h3>Description</h3>

<p>The <code>plotcim</code> function plots a cluster image
mapping of correlations between outcomes and all the predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotcim(matX, matY, cexCol = 0.5, cexRow = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotcim_+3A_matx">matX</code></td>
<td>
<p>data frame corresponding to the predictors.</p>
</td></tr>
<tr><td><code id="plotcim_+3A_maty">matY</code></td>
<td>
<p>data frame corresponding to the outcomes.</p>
</td></tr>
<tr><td><code id="plotcim_+3A_cexrow">cexRow</code>, <code id="plotcim_+3A_cexcol">cexCol</code></td>
<td>
<p>positive numbers, used as <code>cex.axis</code> in for the row or column 
axis labeling. The defaults currently only use number of rows or columns, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To be used with a small number of predictors (&lt;1,000).
</p>


<h3>Author(s)</h3>

<p>Benoit Liquet, <a href="mailto:b.liquet@uq.edu.au">b.liquet@uq.edu.au</a>, <br /> Pierre Lafaye de Micheaux <a href="mailto:lafaye@dms.umontreal.ca">lafaye@dms.umontreal.ca</a>
</p>

<hr>
<h2 id='predict'>Predict Method for sPLS, gPLS, sgPLS, sPLDda, gPLSda, sgPLSda</h2><span id='topic+predict.sgPLS'></span><span id='topic+predict.gPLS'></span><span id='topic+predict.sPLS'></span><span id='topic+predict.sgPLSda'></span><span id='topic+predict.gPLSda'></span><span id='topic+predict.sPLSda'></span>

<h3>Description</h3>

<p>Predicted values based on sparse PLS, group PLS, sparse group PLS, sparse PLSda, group PLSda, sparse group PLSda models. New responses and 
variates are predicted using a fitted model and a new matrix of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'sPLS'
predict(object, newdata, ...)

## S3 method for class 'gPLS'
predict(object, newdata, ...)

## S3 method for class 'sgPLS'
predict(object, newdata, ...)

## S3 method for class 'sPLSda'
predict(object, newdata, method = c("all", "max.dist", 
        "centroids.dist", "mahalanobis.dist"), ...)

## S3 method for class 'gPLSda'
predict(object, newdata, method = c("all", "max.dist", 
        "centroids.dist", "mahalanobis.dist"), ...)

## S3 method for class 'sgPLSda'
predict(object, newdata, method = c("all", "max.dist", 
        "centroids.dist", "mahalanobis.dist"), ...)




</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>object of class inheriting from <code>"sPLS"</code>, <code>"gPLS"</code>, <code>"sgPLS"</code>,  <code>"sPLSda"</code>, <code>"gPLSda"</code> or  <code>"sgPLSda"</code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_newdata">newdata</code></td>
<td>
<p>data matrix in which to look for for explanatory variables to be used for prediction.</p>
</td></tr>
<tr><td><code id="predict_+3A_method">method</code></td>
<td>
<p>method to be applied for <code>sPLSda</code>, <code>gPLSda</code> or <code>sgPLSda</code> to predict the class of new data, 
should be a subset of <code>"centroids.dist"</code>, <code>"mahalanobis.dist"</code> or <code>"max.dist"</code> (see Details). 
Defaults to <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>
<p>not used currently.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>predict</code> function for pls and spls object has been created by Sebastien Dejean, Ignacio Gonzalez, Amrit Singh and Kim-Anh Le Cao for <code>mixOmics</code> package. Similar code is used for sPLS, gPLS, sgPLS, sPLSda, gPLSda, sgPLSda models performed by <code>sgPLS</code> package. 	
</p>
<p><code>predict</code> function produces predicted values, obtained by evaluating the sparse PLS, group PLS or sparse group PLS  
model returned by <code>sPLS</code>, <code>gPLS</code> or <code>sgPLS</code> in the frame <code>newdata</code>. 
Variates for <code>newdata</code> are also returned. The prediction values are calculated based on the regression coefficients of <code>object$Y</code> onto <code>object$variates$X</code>.
</p>
<p>Different class prediction methods are proposed for <code>sPLSda</code>, <code>gPLSda</code> or <code>sgPLSda</code>: <code>"max.dist"</code> 
is the naive method to predict the class. It is based on the predicted matrix (<code>object$predict</code>) 
which can be seen as a probability matrix to assign each test data to a class. The class with the largest 
class value is the predicted class. <code>"centroids.dist"</code> allocates the individual <code class="reqn">x</code> to the class of 
<code class="reqn">Y</code> minimizing <code class="reqn">dist(\code{x-variate}, G_l)</code>, where <code class="reqn">G_l</code>, <code class="reqn">l = 1,...,L</code> are the centroids of 
the classes calculated on the <code class="reqn">X</code>-variates of the model. <code>"mahalanobis.dist"</code> allocates the individual 
<code class="reqn">x</code> to the class of <code class="reqn">Y</code> as in <code>"centroids.dist"</code> but by using the Mahalanobis metric 
in the calculation of the distance.
</p>


<h3>Value</h3>

<p><code>predict</code> produces a list with the following components: 
</p>
<table role = "presentation">
<tr><td><code>predict</code></td>
<td>
<p>A three dimensional array of predicted response values. The dimensions 
correspond to the observations, the response variables and the model dimension, respectively.</p>
</td></tr>
<tr><td><code>variates</code></td>
<td>
<p>Matrix of predicted variates.</p>
</td></tr>
<tr><td><code>B.hat</code></td>
<td>
<p>Matrix of regression coefficients (without the intercept).</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>vector or matrix of predicted class by using <code class="reqn">1,...,</code><code>ncomp</code> 
(sparse)PLS-DA components.</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p>matrix of coordinates for centroids.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux</p>


<h3>References</h3>

<p>Tenenhaus, M. (1998). <em>La r\'egression PLS: th\'eorie et pratique</em>. Paris: Editions Technic.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sPLS">sPLS</a></code>, <code><a href="#topic+gPLS">gPLS</a></code>, <code><a href="#topic+sgPLS">sgPLS</a></code>, <code><a href="#topic+sPLSda">sPLSda</a></code>, <code><a href="#topic+gPLSda">gPLSda</a></code>, <code><a href="#topic+sgPLSda">sgPLSda</a></code>.</p>

<hr>
<h2 id='select.sgpls'>Output of selected variables from a gPLS model or a sgPLS model</h2><span id='topic+select.sgpls'></span>

<h3>Description</h3>

<p>This function outputs the selected variables on each component for the group and sparse group PLS. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  select.sgpls(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select.sgpls_+3A_model">model</code></td>
<td>
<p>object of class inheriting from  <code>"gPLS"</code> or<code>"sgPLS"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>select.sgpls</code> produces a list with the following components: 
</p>
<table role = "presentation">
<tr><td><code>group.size.X</code></td>
<td>
<p>A matrix containing in the first column the size of the groups in the <code class="reqn">X</code> dataset. Then, the next columns indicate the size of the groups selected for each component.</p>
</td></tr>
<tr><td><code>select.group.X</code></td>
<td>
<p>A list containing for each element (corresponding to each group of the <code class="reqn">X</code> dataset) the indices of the variables selected.</p>
</td></tr>
<tr><td><code>group.size.Y</code></td>
<td>
<p>A matrix containing in the first column the size of the groups in the <code class="reqn">Y</code> dataset. Then the next columns indicate the size of the groups selected for each component.</p>
</td></tr>
<tr><td><code>select.group.Y</code></td>
<td>
<p>A list containing for each element (corresponding to each group of the <code class="reqn">Y</code> dataset) the indices of the variables selected.</p>
</td></tr>
<tr><td><code>select.X</code></td>
<td>
<p>A list containing for each element (corresponding to each component of the gPLS or sgPLS model) the names of the selected variables in the <code class="reqn">X</code> dataset.</p>
</td></tr>
<tr><td><code>select.Y</code></td>
<td>
<p>A list containing for each element (corresponding to each component of the gPLS or sgPLS model) the names of the selected variables in the <code class="reqn">Y</code> dataset.</p>
</td></tr>
<tr><td><code>select.X.total</code></td>
<td>
<p>The names of the variables selected from the gPLS or sgPLS model regarding the <code class="reqn">X</code> matrix.</p>
</td></tr>
<tr><td><code>select.Y.total</code></td>
<td>
<p>The names of the variables selected from the gPLS or sgPLS model regarding the <code class="reqn">Y</code> matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet, <a href="mailto:b.liquet@uq.edu.au">b.liquet@uq.edu.au</a>, <br /> Pierre Lafaye de Micheaux <a href="mailto:lafaye@dms.umontreal.ca">lafaye@dms.umontreal.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 	
## Simulation of datasets X and Y with group variables
n &lt;- 100
sigma.gamma &lt;- 1
sigma.e &lt;- 1.5
p &lt;- 400
q &lt;- 500
theta.x1 &lt;- c(rep(1,15),rep(0,5),rep(-1,15),rep(0,5),rep(1.5,15)
			,rep(0,5),rep(-1.5,15),rep(0,325))
theta.x2 &lt;- c(rep(0,320),rep(1,15),rep(0,5),rep(-1,15),rep(0,5),
			rep(1.5,15),rep(0,5),rep(-1.5,15),rep(0,5))

theta.y1 &lt;- c(rep(1,15),rep(0,5),rep(-1,15),rep(0,5),rep(1.5,15)
			,rep(0,5),rep(-1.5,15),rep(0,425))
theta.y2 &lt;- c(rep(0,420),rep(1,15),rep(0,5),rep(-1,15),rep(0,5),
			rep(1.5,15),rep(0,5),rep(-1.5,15),rep(0,5))                            


Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

set.seed(125)

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.y1, theta.y2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, q), sigma =
     Sigmay, method = "svd")

ind.block.x &lt;- seq(20, 380, 20)
ind.block.y &lt;- seq(20, 480, 20)

#### gPLS model
model.sgPLS &lt;- sgPLS(X, Y, ncomp = 2, mode = "regression", keepX = c(4, 4), 
                   keepY = c(4, 4), ind.block.x = ind.block.x,
                   ind.block.y = ind.block.y,
                   alpha.x = c(0.5, 0.5), alpha.y = c(0.5, 0.5))

result.sgPLS &lt;- select.sgpls(model.sgPLS)
result.sgPLS$group.size.X
result.sgPLS$group.size.Y

#### gPLS model
model.gPLS &lt;- gPLS(X, Y, ncomp = 2, mode = "regression", keepX = c(4, 4), 
     keepY = c(4,4), ind.block.x = ind.block.x ,ind.block.y = ind.block.y)

result.gPLS &lt;- select.sgpls(model.gPLS)
result.gPLS$group.size.X
result.gPLS$group.size.Y




## End(Not run)
</code></pre>

<hr>
<h2 id='select.spls'>Output of selected variables from a sPLS model</h2><span id='topic+select.spls'></span>

<h3>Description</h3>

<p>This function outputs the selected variables on each component for the sPLS. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  select.spls(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select.spls_+3A_model">model</code></td>
<td>
<p>object of class inheriting from <code>"sPLS"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>select.spls</code> produces a list with the following components: 
</p>
<table role = "presentation">
<tr><td><code>select.X</code></td>
<td>
<p>A list containing for each element (corresponding to each component of the sPLS model) the names of the selected variables in the <code class="reqn">X</code> dataset.</p>
</td></tr>
<tr><td><code>select.Y</code></td>
<td>
<p>A list containing for each element (corresponding to each component of the sPLS model) the names of the selected variables in the <code class="reqn">Y</code> dataset.</p>
</td></tr>
<tr><td><code>select.X.total</code></td>
<td>
<p>The names of the variables selected from the sPLS model regarding the <code class="reqn">X</code> matrix.</p>
</td></tr>
<tr><td><code>select.Y.total</code></td>
<td>
<p>The names of the variables selected from the sPLS model regarding the <code class="reqn">Y</code> matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet, <a href="mailto:b.liquet@uq.edu.au">b.liquet@uq.edu.au</a>, <br /> Pierre Lafaye de Micheaux <a href="mailto:lafaye@dms.umontreal.ca">lafaye@dms.umontreal.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 	
## Simulation of datasets X and Y with group variables
n &lt;- 100
sigma.gamma &lt;- 1
sigma.e &lt;- 1.5
p &lt;- 400
q &lt;- 500
theta.x1 &lt;- c(rep(1,15),rep(0,5),rep(-1,15),rep(0,5),rep(1.5,15)
             ,rep(0,5),rep(-1.5,15),rep(0,325))
theta.x2 &lt;- c(rep(0,320),rep(1,15),rep(0,5),rep(-1,15),rep(0,5)
             ,rep(1.5,15),rep(0,5),rep(-1.5,15),rep(0,5))

theta.y1 &lt;- c(rep(1,15),rep(0,5),rep(-1,15),rep(0,5),rep(1.5,15)
             ,rep(0,5),rep(-1.5,15),rep(0,425))
theta.y2 &lt;- c(rep(0,420),rep(1,15),rep(0,5),rep(-1,15),rep(0,5),
             rep(1.5,15),rep(0,5),rep(-1.5,15),rep(0,5))                             

temp &lt;-  matrix(c(theta.y1, theta.y2), nrow = 2, byrow = TRUE)

Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

set.seed(125)

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.y1, theta.y2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, q), sigma =
     Sigmay, method = "svd")

ind.block.x &lt;- seq(20, 380, 20)
ind.block.y &lt;- seq(20, 480, 20)

#### sPLS model
model.sPLS &lt;- sPLS(X, Y, ncomp = 2, mode = "regression", keepX = c(60, 60), 
                     keepY = c(60, 60))
result.sPLS &lt;- select.spls(model.sPLS)
result.sPLS$select.X
result.sPLS$select.Y




## End(Not run)
</code></pre>

<hr>
<h2 id='sgPLS'>Sparse Group Partial Least Squares (sgPLS)</h2><span id='topic+sgPLS'></span>

<h3>Description</h3>

<p>Function to perform  sparse group Partial Least Squares (sgPLS) in the conext of datasets are divided into groups of variables. The sgPLS approach enables selection at both groups and single feature levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sgPLS(X, Y, ncomp, mode = "regression",
     max.iter = 500, tol = 1e-06, keepX, 
     keepY = NULL,ind.block.x, ind.block.y = NULL, alpha.x, alpha.y = NULL,
     upper.lambda = 10 ^ 5,scale=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sgPLS_+3A_x">X</code></td>
<td>
<p>Numeric matrix of predictors.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_y">Y</code></td>
<td>
<p>Numeric vector or matrix of responses (for multi-response models). </p>
</td></tr>
<tr><td><code id="sgPLS_+3A_ncomp">ncomp</code></td>
<td>
<p>The number of components to include in the model (see Details). </p>
</td></tr>
<tr><td><code id="sgPLS_+3A_mode">mode</code></td>
<td>
<p>character string. What type of algorithm to use, (partially) matching 
one of <code>"regression"</code> or <code>"canonical"</code>. See Details.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_max.iter">max.iter</code></td>
<td>
<p>Integer, the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_tol">tol</code></td>
<td>
<p>A positive real, the tolerance used in the iterative algorithm.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_keepx">keepX</code></td>
<td>
<p>Numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">X</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_keepy">keepY</code></td>
<td>
<p>Numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">Y</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_ind.block.x">ind.block.x</code></td>
<td>
<p>A vector of integers describing the grouping of the <code class="reqn">X</code> variables. (see an example in Details section).</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_ind.block.y">ind.block.y</code></td>
<td>
<p>A vector of integers describing the grouping of the <code class="reqn">Y</code> variables (see example in Details section).</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_alpha.x">alpha.x</code></td>
<td>
<p>The mixing parameter (value between 0 and 1) related to the sparsity within group for the <code class="reqn">X</code> dataset.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_alpha.y">alpha.y</code></td>
<td>
<p>The mixing parameter (value between 0 and 1) related to the sparsity within group for the <code class="reqn">Y</code> dataset.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_upper.lambda">upper.lambda</code></td>
<td>
<p>By default <code>upper.lambda=10 ^ 5</code>. A large value specifying the upper bound of the intervall of lambda values for searching the value of the tuning parameter (lambda) corresponding to a non-zero group of variables.</p>
</td></tr>
<tr><td><code id="sgPLS_+3A_scale">scale</code></td>
<td>
<p>a logical indicating if the orignal data set need to be scaled. By default <code>scale</code>=TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sgPLS</code> function fit gPLS models with <code class="reqn">1, \ldots ,</code><code>ncomp</code> components. 
Multi-response models are fully supported. 
</p>
<p>The type of algorithm to use is specified with the <code>mode</code> argument. Two gPLS 
algorithms are available: gPLS regression <code>("regression")</code> and gPLS canonical analysis 
<code>("canonical")</code> (see References). 
</p>
<p><code>ind.block.x &lt;- c(3, 10, 15)</code> means that <code class="reqn">X</code> is structured into 4 groups: X1 to X3; X4 to X10, X11 to X15 and X16 to X<code class="reqn">p</code> where <code class="reqn">p</code> is the number of variables in the <code class="reqn">X</code> matrix.</p>


<h3>Value</h3>

<p><code>sgPLS</code> returns an object of class <code>"sgPLS"</code>, a list 
that contains the following components:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>The centered and standardized original predictor matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>The centered and standardized original response vector or matrix.</p>
</td></tr>
<tr><td><code>ncomp</code></td>
<td>
<p>The number of components included in the model.</p>
</td></tr>
<tr><td><code>mode</code></td>
<td>
<p>The algorithm used to fit the model.</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>Number of <code class="reqn">X</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>keepY</code></td>
<td>
<p>Number of <code class="reqn">Y</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>mat.c</code></td>
<td>
<p>Matrix of coefficients to be used internally by <code>predict</code>.</p>
</td></tr>
<tr><td><code>variates</code></td>
<td>
<p>List containing the variates.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>List containing the estimated loadings for the <code class="reqn">X</code> and 
<code class="reqn">Y</code> variates.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>List containing the names to be used for individuals and variables.</p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>The tolerance used in the iterative algorithm, used for subsequent S3 methods.</p>
</td></tr>
<tr><td><code>max.iter</code></td>
<td>
<p>The maximum number of iterations, used for subsequent S3 methods.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Vector containing the number of iterations for convergence in each component.</p>
</td></tr> 
<tr><td><code>ind.block.x</code></td>
<td>
<p>A vector of integers describing the grouping of the <code class="reqn">X</code> variables.</p>
</td></tr>
<tr><td><code>ind.block.y</code></td>
<td>
<p>A vector of consecutive integers describing the grouping of the <code class="reqn">Y</code> variables.</p>
</td></tr>
<tr><td><code>alpha.x</code></td>
<td>
<p>The mixing parameter related to the sparsity within group for the <code class="reqn">X</code> dataset.</p>
</td></tr>
<tr><td><code>alpha.y</code></td>
<td>
<p>The mixing parameter related to the sparsity within group for the <code class="reqn">Y</code> dataset.</p>
</td></tr>
<tr><td><code>upper.lambda</code></td>
<td>
<p>The upper bound of the intervall of lambda values for searching the value of the tuning parameter (lambda) corresponding to a non-zero group of variables.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux.</p>


<h3>References</h3>

<p>Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). A group and Sparse Group Partial Least Square approach applied in Genomics context. <em>Bioinformatics</em>.
</p>
<p>Le Cao, K.-A., Martin, P.G.P., Robert-Grani\'e, C. and Besse, P. (2009). Sparse canonical methods for biological data integration: application to a cross-platform study. <em>BMC Bioinformatics</em> <b>10</b>:34.
</p>
<p>Le Cao, K.-A., Rossouw, D., Robert-Grani\'e, C. and Besse, P. (2008). A sparse PLS for variable 
selection when integrating Omics data. <em>Statistical Applications in Genetics and Molecular 
Biology</em> <b>7</b>, article 35.
</p>
<p>Shen, H. and Huang, J. Z. (2008). Sparse principal component analysis via regularized 
low rank matrix approximation. <em>Journal of Multivariate Analysis</em> <b>99</b>, 1015-1034.    
</p>
<p>Tenenhaus, M. (1998). <em>La r\'egression PLS: th\'eorie et pratique</em>. Paris: Editions Technic.
</p>
<p>Wold H. (1966). Estimation of principal components and related models by iterative least squares. 
In: Krishnaiah, P. R. (editors), <em>Multivariate Analysis</em>. Academic Press, N.Y., 391-420.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sPLS">sPLS</a></code>, <code><a href="#topic+sgPLS">sgPLS</a></code>, <code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="#topic+perf">perf</a></code> and functions from <code>mixOmics</code> package: <code>summary</code>, <code>plotIndiv</code>, <code>plotVar</code>, <code>plot3dIndiv</code>, <code>plot3dVar</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>	
## Simulation of datasets X and Y with group variables
n &lt;- 100
sigma.gamma &lt;- 1
sigma.e &lt;- 1.5
p &lt;- 400
q &lt;- 500
theta.x1 &lt;- c(rep(1,15),rep(0,5),rep(-1,15),rep(0,5),rep(1.5,15)
             ,rep(0,5),rep(-1.5,15),rep(0,325))
theta.x2 &lt;- c(rep(0,320),rep(1,15),rep(0,5),rep(-1,15),rep(0,5)
             ,rep(1.5,15),rep(0,5),rep(-1.5,15),rep(0,5))

theta.y1 &lt;- c(rep(1,15),rep(0,5),rep(-1,15),rep(0,5),rep(1.5,15)
             ,rep(0,5),rep(-1.5,15),rep(0,425))
theta.y2 &lt;- c(rep(0,420),rep(1,15),rep(0,5),rep(-1,15),rep(0,5),
			rep(1.5,15),rep(0,5),rep(-1.5,15),rep(0,5))                             


Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

set.seed(125)

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.y1, theta.y2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, q), sigma =
     Sigmay, method = "svd")


ind.block.x &lt;- seq(20, 380, 20)
ind.block.y &lt;- seq(20, 480, 20)
##


model.sgPLS &lt;- sgPLS(X, Y, ncomp = 2, mode = "regression", keepX = c(4, 4), 
                   keepY = c(4, 4), ind.block.x = ind.block.x
                   ,ind.block.y = ind.block.y,
                   alpha.x = c(0.95, 0.95), alpha.y = c(0.95, 0.95))

result.sgPLS &lt;- select.sgpls(model.sgPLS)
result.sgPLS$group.size.X
result.sgPLS$group.size.Y
</code></pre>

<hr>
<h2 id='sgPLS-internal'>Internal Functions</h2><span id='topic+normv'></span><span id='topic+soft.thresholding'></span><span id='topic+soft.thresholding.group'></span><span id='topic+soft.thresholding.sparse.group'></span><span id='topic+lambda.quadra'></span><span id='topic+step1.spls.sparsity'></span><span id='topic+step1.sparse.group.spls.sparsity'></span><span id='topic+step1.group.spls.sparsity'></span><span id='topic+step2.spls'></span>

<h3>Description</h3>

<p>Internal functions not to be used by the user.
</p>

<hr>
<h2 id='sgPLSda'>Sparse Group Sparse Partial Least Squares Discriminant Analysis (sPLS-DA)</h2><span id='topic+sgPLSda'></span>

<h3>Description</h3>

<p>Function to perform sparse group Partial Least Squares to classify samples (supervised analysis) and select variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sgPLSda(X, Y, ncomp = 2, keepX = rep(ncol(X), ncomp),
       max.iter = 500, tol = 1e-06, ind.block.x,
     alpha.x, upper.lambda = 10 ^ 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sgPLSda_+3A_x">X</code></td>
<td>
<p>numeric matrix of predictors. <code>NA</code>s are allowed.</p>
</td></tr>
<tr><td><code id="sgPLSda_+3A_y">Y</code></td>
<td>
<p>a factor or a class vector for the discrete outcome.</p>
</td></tr>
<tr><td><code id="sgPLSda_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to include in the model (see Details).</p>
</td></tr>
<tr><td><code id="sgPLSda_+3A_keepx">keepX</code></td>
<td>
<p>numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">X</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="sgPLSda_+3A_max.iter">max.iter</code></td>
<td>
<p>integer, the maximum number of iterations.</p>
</td></tr>   
<tr><td><code id="sgPLSda_+3A_tol">tol</code></td>
<td>
<p>a positive real, the tolerance used in the iterative algorithm.</p>
</td></tr> 
<tr><td><code id="sgPLSda_+3A_ind.block.x">ind.block.x</code></td>
<td>
<p>a vector of integers describing the grouping of the <code class="reqn">X</code>-variables. (see an example in Details section)</p>
</td></tr>
<tr><td><code id="sgPLSda_+3A_alpha.x">alpha.x</code></td>
<td>
<p>The mixing parameter (value between 0 and 1) related to the sparsity within group for the <code class="reqn">X</code> dataset.</p>
</td></tr>
<tr><td><code id="sgPLSda_+3A_upper.lambda">upper.lambda</code></td>
<td>
<p>By default <code>upper.lambda=10 ^ 5</code>. A large value specifying the upper bound of the intervall of lambda values for searching the value of the tuning parameter (lambda) corresponding to a non-zero group of variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sgPLSda</code> function fit sgPLS models with <code class="reqn">1, \ldots ,</code><code>ncomp</code> components
to the factor or class vector <code>Y</code>. The appropriate indicator (dummy)
matrix is created.
</p>
<p><code>ind.block.x &lt;- c(3,10,15)</code> means that <code class="reqn">X</code> is structured into 4 groups: X1 to X3; X4 to X10, X11 to X15 and X16 to X<code class="reqn">p</code> where <code class="reqn">p</code> is the number of variables in the <code class="reqn">X</code> matrix.</p>


<h3>Value</h3>

<p><code>sPLSda</code> returns an object of class <code>"sPLSda"</code>, a list 
that contains the following components:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>the centered and standardized original predictor matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the centered and standardized indicator response vector or matrix.</p>
</td></tr>
<tr><td><code>ind.mat</code></td>
<td>
<p>the indicator matrix.</p>
</td></tr>
<tr><td><code>ncomp</code></td>
<td>
<p>the number of components included in the model.</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>number of <code class="reqn">X</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>mat.c</code></td>
<td>
<p>matrix of coefficients to be used internally by <code>predict</code>.</p>
</td></tr>
<tr><td><code>variates</code></td>
<td>
<p>list containing the variates.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>list containing the estimated loadings for the <code>X</code> and 
<code>Y</code> variates.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>list containing the names to be used for individuals and variables.</p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>the tolerance used in the iterative algorithm, used for subsequent S3 methods</p>
</td></tr>
<tr><td><code>max.iter</code></td>
<td>
<p>the maximum number of iterations, used for subsequent S3 methods</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations of the algorthm for each component</p>
</td></tr>
<tr><td><code>ind.block.x</code></td>
<td>
<p>a vector of integers describing the grouping of the X variables.</p>
</td></tr>
<tr><td><code>alpha.x</code></td>
<td>
<p>The mixing parameter related to the sparsity within group for the <code class="reqn">X</code> dataset.</p>
</td></tr>
<tr><td><code>upper.lambda</code></td>
<td>
<p>The upper bound of the intervall of lambda values for searching the value of the tuning parameter (lambda) corresponding to a non-zero group of variables.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux.</p>


<h3>References</h3>

<p>Liquet Benoit, Lafaye de Micheaux Pierre , Hejblum Boris, Thiebaut Rodolphe (2016). A group and Sparse Group Partial Least Square approach applied in Genomics context. <em>Bioinformatics</em>.	
</p>
<p>On sPLS-DA:
Le Cao, K.-A., Boitard, S. and Besse, P. (2011). Sparse PLS Discriminant Analysis: biologically relevant feature selection and graphical displays for multiclass problems. <em>BMC Bioinformatics</em> <b>12</b>:253.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sPLS">sPLS</a></code>, <code><a href="base.html#topic+summary">summary</a></code>, 
<code>plotIndiv</code>, <code>plotVar</code>, 
<code>cim</code>, <code>network</code>, <code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="#topic+perf">perf</a></code> and http://www.mixOmics.org for more details.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(simuData)
X &lt;- simuData$X
Y &lt;- simuData$Y
ind.block.x &lt;- seq(100, 900, 100)
ind.block.x[2] &lt;- 250
#To add some noise in the second group
model &lt;- sgPLSda(X, Y, ncomp = 3,ind.block.x=ind.block.x, keepX = c(2, 2, 2)
, alpha.x = c(0.5,0.5,0.99))
result.sgPLSda &lt;- select.sgpls(model)
result.sgPLSda$group.size.X
##perf(model,criterion="all",validation="loo") -&gt; res
##res$error.rate	
</code></pre>

<hr>
<h2 id='simuData'>Simulated Data for group PLS-DA model</h2><span id='topic+simuData'></span>

<h3>Description</h3>

<p>This simulated data set contains the expression of 1000 genes for 4 clusters from 48 different individuals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(simuData)</code></pre>


<h3>Format</h3>

<p>A list containing the following components:
</p>

<dl>
<dt><code>X</code></dt><dd><p>data matrix with 48 rows and 1000 columns. Each row represents 
an experimental sample, and each column a single gene.</p>
</dd>
<dt><code>Y</code></dt><dd><p>a factor variable indicating the cluster of each subject</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data have been simulated such that only 6 groups of 100 genes are linked to the 4 clusters. The others 4 groups of 100 genes has been added to represent some noise. The relevant groups are the group 1,2,4,6,7 and 9. The groups 3,5,8, and 10 are noise groups.
</p>

<hr>
<h2 id='sPLS'>Sparse Partial Least Squares (sPLS)</h2><span id='topic+sPLS'></span>

<h3>Description</h3>

<p>Function to perform sparse Partial Least Squares (sPLS). The sPLS approach
combines both integration and variable selection simultaneously on two data sets
in a one-step strategy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sPLS(X, Y, ncomp, mode = "regression",
     max.iter = 500, tol = 1e-06, keepX = rep(ncol(X), ncomp), 
     keepY = rep(ncol(Y), ncomp),scale=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sPLS_+3A_x">X</code></td>
<td>
<p>Numeric matrix of predictors.</p>
</td></tr>
<tr><td><code id="sPLS_+3A_y">Y</code></td>
<td>
<p>Numeric vector or matrix of responses (for multi-response models).</p>
</td></tr>
<tr><td><code id="sPLS_+3A_ncomp">ncomp</code></td>
<td>
<p>The number of components to include in the model (see Details).</p>
</td></tr>
<tr><td><code id="sPLS_+3A_mode">mode</code></td>
<td>
<p>Character string. What type of algorithm to use, (partially) matching 
one of <code>"regression"</code> or <code>"canonical"</code>. See Details.</p>
</td></tr>
<tr><td><code id="sPLS_+3A_max.iter">max.iter</code></td>
<td>
<p>Integer, the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="sPLS_+3A_tol">tol</code></td>
<td>
<p>A positive real, the tolerance used in the iterative algorithm.</p>
</td></tr>
<tr><td><code id="sPLS_+3A_keepx">keepX</code></td>
<td>
<p>Numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">X</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="sPLS_+3A_keepy">keepY</code></td>
<td>
<p>Numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">Y</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="sPLS_+3A_scale">scale</code></td>
<td>
<p>a logical indicating if the orignal data set need to be scaled. By default <code>scale</code>=TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sPLS</code> function fit sPLS models with <code class="reqn">1, \ldots ,</code><code>ncomp</code> components. 
Multi-response models are fully supported.
</p>
<p>The type of algorithm to use is specified with the <code>mode</code> argument. Two sPLS 
algorithms are available: sPLS regression <code>("regression")</code> and sPLS canonical analysis 
<code>("canonical")</code> (see References). 
</p>


<h3>Value</h3>

<p><code>sPLS</code> returns an object of class <code>"sPLS"</code>, a list 
that contains the following components:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>The centered and standardized original predictor matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>The centered and standardized original response vector or matrix.</p>
</td></tr>
<tr><td><code>ncomp</code></td>
<td>
<p>The number of components included in the model.</p>
</td></tr>
<tr><td><code>mode</code></td>
<td>
<p>The algorithm used to fit the model.</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>Number of <code class="reqn">X</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>keepY</code></td>
<td>
<p>Number of <code class="reqn">Y</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>mat.c</code></td>
<td>
<p>Matrix of coefficients to be used internally by <code>predict</code>.</p>
</td></tr>
<tr><td><code>variates</code></td>
<td>
<p>List containing the variates.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>List containing the estimated loadings for the <code class="reqn">X</code> and 
<code class="reqn">Y</code> variates.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>List containing the names to be used for individuals and variables.</p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>The tolerance used in the iterative algorithm, used for subsequent S3 methods</p>
</td></tr>
<tr><td><code>max.iter</code></td>
<td>
<p>The maximum number of iterations, used for subsequent S3 methods</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux.</p>


<h3>References</h3>

<p>Liquet Benoit, Lafaye de Micheaux Pierre, Hejblum Boris, Thiebaut Rodolphe. A group and Sparse Group Partial Least Square approach applied in Genomics context. <em>Submitted</em>.
</p>
<p>Le Cao, K.-A., Martin, P.G.P., Robert-Grani\', C. and Besse, P. (2009). Sparse canonical methods for biological data integration: application to a cross-platform study. <em>BMC Bioinformatics</em> <b>10</b>:34.
</p>
<p>Le Cao, K.-A., Rossouw, D., Robert-Grani\'e, C. and Besse, P. (2008). A sparse PLS for variable 
selection when integrating Omics data. <em>Statistical Applications in Genetics and Molecular 
Biology</em> <b>7</b>, article 35.
</p>
<p>Shen, H. and Huang, J. Z. (2008). Sparse principal component analysis via regularized 
low rank matrix approximation. <em>Journal of Multivariate Analysis</em> <b>99</b>, 1015-1034.    
</p>
<p>Tenenhaus, M. (1998). <em>La r\'egression PLS: th\'eorie et pratique</em>. Paris: Editions Technic.
</p>
<p>Wold H. (1966). Estimation of principal components and related models by iterative least squares. 
In: Krishnaiah, P. R. (editors), <em>Multivariate Analysis</em>. Academic Press, N.Y., 391-420.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gPLS">gPLS</a></code>, <code><a href="#topic+sgPLS">sgPLS</a></code>, <code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="#topic+perf">perf</a></code> and functions from <code>mixOmics</code> package: <code>summary</code>, <code>plotIndiv</code>, <code>plotVar</code>, <code>plot3dIndiv</code>, <code>plot3dVar</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simulation of datasets X and Y with group variables
n &lt;- 100
sigma.gamma &lt;- 1
sigma.e &lt;- 1.5
p &lt;- 400
q &lt;- 500
theta.x1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
			rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 325))
theta.x2 &lt;- c(rep(0, 320), rep(1, 15), rep(0, 5), rep(-1, 15),
			rep(0, 5), rep(1.5, 15), rep(0, 5), rep(-1.5, 15),
			rep(0, 5))

theta.y1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), 
			rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 425))
theta.y2 &lt;- c(rep(0, 420), rep(1, 15), rep(0, 5), rep(-1, 15)
			,rep(0, 5), rep(1.5, 15), rep(0, 5), rep(-1.5, 15)
			, rep(0, 5))                            


Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

set.seed(125)

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.y1, theta.y2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, q), sigma =
     Sigmay, method = "svd")


ind.block.x &lt;- seq(20, 380, 20)
ind.block.y &lt;- seq(20, 480, 20)


#### sPLS model
model.sPLS &lt;- sPLS(X, Y, ncomp = 2, mode = "regression", keepX = c(60, 60), 
                     keepY = c(60, 60))
result.sPLS &lt;- select.spls(model.sPLS)
result.sPLS$select.X
result.sPLS$select.Y

</code></pre>

<hr>
<h2 id='sPLSda'>Sparse Partial Least Squares Discriminant Analysis (sPLS-DA)</h2><span id='topic+sPLSda'></span>

<h3>Description</h3>

<p>Function to perform sparse Partial Least Squares to classify samples (supervised analysis) and select variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sPLSda(X, Y, ncomp = 2, keepX = rep(ncol(X), ncomp),
       max.iter = 500, tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sPLSda_+3A_x">X</code></td>
<td>
<p>numeric matrix of predictors. <code>NA</code>s are allowed.</p>
</td></tr>
<tr><td><code id="sPLSda_+3A_y">Y</code></td>
<td>
<p>a factor or a class vector for the discrete outcome.</p>
</td></tr>
<tr><td><code id="sPLSda_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to include in the model (see Details).</p>
</td></tr>
<tr><td><code id="sPLSda_+3A_keepx">keepX</code></td>
<td>
<p>numeric vector of length <code>ncomp</code>, the number of variables
to keep in <code class="reqn">X</code>-loadings. By default all variables are kept in the model.</p>
</td></tr>
<tr><td><code id="sPLSda_+3A_max.iter">max.iter</code></td>
<td>
<p>integer, the maximum number of iterations.</p>
</td></tr>   
<tr><td><code id="sPLSda_+3A_tol">tol</code></td>
<td>
<p>a positive real, the tolerance used in the iterative algorithm.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p><code>sPLSda</code> function fit sPLS models with <code class="reqn">1, \ldots ,</code><code>ncomp</code> components
to the factor or class vector <code>Y</code>. The appropriate indicator (dummy)
matrix is created.
</p>


<h3>Value</h3>

<p><code>sPLSda</code> returns an object of class <code>"sPLSda"</code>, a list 
that contains the following components:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>the centered and standardized original predictor matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the centered and standardized indicator response vector or matrix.</p>
</td></tr>
<tr><td><code>ind.mat</code></td>
<td>
<p>the indicator matrix.</p>
</td></tr>
<tr><td><code>ncomp</code></td>
<td>
<p>the number of components included in the model.</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>number of <code class="reqn">X</code> variables kept in the model on each component.</p>
</td></tr>
<tr><td><code>mat.c</code></td>
<td>
<p>matrix of coefficients to be used internally by <code>predict</code>.</p>
</td></tr>
<tr><td><code>variates</code></td>
<td>
<p>list containing the variates.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>list containing the estimated loadings for the <code>X</code> and 
<code>Y</code> variates.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>list containing the names to be used for individuals and variables.</p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>the tolerance used in the iterative algorithm, used for subsequent S3 methods</p>
</td></tr>
<tr><td><code>max.iter</code></td>
<td>
<p>the maximum number of iterations, used for subsequent S3 methods</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations of the algorthm for each component</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux.</p>


<h3>References</h3>

<p>On sPLS-DA:
Le Cao, K.-A., Boitard, S. and Besse, P. (2011). Sparse PLS Discriminant Analysis: biologically relevant feature selection and graphical displays for multiclass problems. <em>BMC Bioinformatics</em> <b>12</b>:253.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sPLS">sPLS</a></code>, <code><a href="base.html#topic+summary">summary</a></code>, 
<code>plotIndiv</code>, <code>plotVar</code>, 
<code>cim</code>, <code>network</code>, <code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="#topic+perf">perf</a></code> and http://www.mixOmics.org for more details.</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Examples from mixOmics packages	


data(liver.toxicity)
X &lt;- as.matrix(liver.toxicity$gene)
# Y will be transformed as a factor in the function,
# but we set it as a factor to set up the colors.
Y &lt;- as.factor(liver.toxicity$treatment[, 4])

model &lt;- sPLSda(X, Y, ncomp = 2, keepX = c(20, 20))


</code></pre>

<hr>
<h2 id='tuning.gPLS.X'>Choice of the tuning parameter (number of groups) related to  predictor matrix for gPLS model (regression mode)</h2><span id='topic+tuning.gPLS.X'></span>

<h3>Description</h3>

<p>For a grid of tuning parameter, this function computes by leave-one-out or M-fold cross-validation the MSEP (Mean Square Error of Prediction) of a gPLS model. </p>


<h3>Usage</h3>

<pre><code class='language-R'>tuning.gPLS.X(X,Y,folds=10,validation=c("Mfold","loo"),
		ncomp,keepX=NULL,grid.X,setseed,progressBar=FALSE,
		ind.block.x=ind.block.x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tuning.gPLS.X_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times p)</code>, the observations on the <code class="reqn">X</code> variables.</p>
</td></tr>
<tr><td><code id="tuning.gPLS.X_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times q)</code>, the observations on the <code class="reqn">Y</code> variables.</p>
</td></tr>
<tr><td><code id="tuning.gPLS.X_+3A_folds">folds</code></td>
<td>
<p>Positive integer. Number of folds to use if <code>validation="Mfold"</code>. Defaults to <code>folds=10</code>.</p>
</td></tr>
<tr><td><code id="tuning.gPLS.X_+3A_validation">validation</code></td>
<td>
<p>Character string. What kind of (internal) cross-validation method to use, (partially) matching one of <code>"Mfolds"</code> (M-folds) or <code>"loo"</code> (leave-one-out).</p>
</td></tr>
<tr><td><code id="tuning.gPLS.X_+3A_ncomp">ncomp</code></td>
<td>
<p>Number of component for investigating the choice of the tuning parameter.</p>
</td></tr>
<tr><td><code id="tuning.gPLS.X_+3A_keepx">keepX</code></td>
<td>
<p>Vector of integer indicating the number of group of variables to keep in each component. See details for more information.</p>
</td></tr>
<tr><td><code id="tuning.gPLS.X_+3A_grid.x">grid.X</code></td>
<td>
<p>Vector of integers defining the values of the tuning parameter (corresponding to the number of group of variables to select) at which cross-validation score should be computed. </p>
</td></tr>
<tr><td><code id="tuning.gPLS.X_+3A_setseed">setseed</code></td>
<td>
<p>Integer indicating the random number generation state.</p>
</td></tr>	
<tr><td><code id="tuning.gPLS.X_+3A_progressbar">progressBar</code></td>
<td>
<p>By default set to <code>FALSE</code> to output the progress bar of the computation.</p>
</td></tr>
<tr><td><code id="tuning.gPLS.X_+3A_ind.block.x">ind.block.x</code></td>
<td>
<p>A vector of integers describing the grouping of the X variables. (see an example in details section)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>validation="Mfolds"</code>, M-fold cross-validation is performed by calling 
<code>Mfold</code>. The folds are generated. The number of cross-validation 
folds is specified with the argument <code>folds</code>. 
</p>
<p>If <code>validation="loo"</code>, 
leave-one-out cross-validation is performed by calling the 
<code>loo</code> function. In this case the arguments <code>folds</code> are ignored.
</p>
<p>if <code>keepX</code> is specified (by default is NULL), each element of <code>keepX</code> indicates the value of the tuning parameter for the corresponding component. Only the choice of the tuning parameters corresponding to the remaining components are investigating by evaluating the cross-validation score at different values defining by <code>grid.X</code>.
</p>


<h3>Value</h3>

<p>The returned value is a list with components: 
</p>
<table role = "presentation">
<tr><td><code>MSEP</code></td>
<td>
<p>Matrix containing the cross-validation score computed on the grid.</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>Value of the tuning parameter (lambda) on which
the cross-validation method reached it minimum.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 	
## Simulation of Datasets X (with group variables) and Y a multivariate response variable 
n &lt;- 200
sigma.e &lt;- 0.5
p &lt;- 400
q &lt;- 10
theta.x1 &lt;- c(rep(1,15),rep(0,5),rep(-1,15),rep(0,5),rep(1.5,15),
			rep(0,5),rep(-1.5,15),rep(0,325))
theta.x2 &lt;- c(rep(0,320),rep(1,15),rep(0,5),rep(-1,15),rep(0,5),
			rep(1.5,15),rep(0,5),rep(-1.5,15),rep(0,5))

set.seed(125)
theta.y1 &lt;- runif(10,0.5,2)
theta.y2 &lt;- runif(10,0.5,2)
  
temp &lt;-  matrix(c(theta.y1,theta.y2),nrow=2,byrow=TRUE)

Sigmax &lt;- matrix(0,nrow=p,ncol=p)
diag(Sigmax) &lt;- sigma.e^2
Sigmay &lt;- matrix(0,nrow=q,ncol=q)
diag(Sigmay) &lt;- sigma.e^2

gam1 &lt;- rnorm(n,0,1)
gam2 &lt;- rnorm(n,0,1)

X &lt;- matrix(c(gam1,gam2),ncol=2,byrow=FALSE)%*%matrix(c(theta.x1,theta.x2),nrow=2,byrow=TRUE)
+rmvnorm(n,mean=rep(0,p),sigma=Sigmax,method="svd")
Y &lt;- matrix(c(gam1,gam2),ncol=2,byrow=FALSE)%*%t(svd(temp)$v)
+rmvnorm(n,mean=rep(0,q),sigma=Sigmay,method="svd")

ind.block.x &lt;- seq(20,380,20)

grid.X &lt;- 1:16

## Strategy with same value for both components
tun.gPLS &lt;- tuning.gPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
		ncomp=2,keepX = NULL, grid.X=grid.X, setseed=1, progressBar = FALSE, 
		ind.block.x = ind.block.x) 

tun.gPLS$keepX # for each component

##For a sequential strategy
tun.gPLS.1 &lt;- tuning.gPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"),
			 ncomp=1, keepX = NULL, grid.X=grid.X, setseed=1,
                             ind.block.x = ind.block.x) 
tun.gPLS.1$keepX # for the first component

tun.gPLS.2 &lt;- tuning.gPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), ncomp=2, 
                            keepX = tun.gPLS.1$keepX , grid.X=grid.X, setseed=1, 
                            ind.block.x = ind.block.x) 

tun.gPLS.2$keepX # for the second component

## End(Not run)
</code></pre>

<hr>
<h2 id='tuning.sgPLS.X'>Choice of the tuning parameters (number of groups and mixing parameter) related to  predictor matrix for sgPLS model (regression mode)</h2><span id='topic+tuning.sgPLS.X'></span>

<h3>Description</h3>

<p>For a grid in two dimension of tuning parameters, this function computes by leave-one-out or M-fold cross-validation the MSEP (Mean Square Error of Prediction) of a sgPLS model. </p>


<h3>Usage</h3>

<pre><code class='language-R'>tuning.sgPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), ncomp,
				keepX = NULL, alpha.x = NULL, grid.gX, grid.alpha.X,
				setseed, progressBar = FALSE, ind.block.x = ind.block.x,
				upper.lambda = 10 ^ 9)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tuning.sgPLS.X_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times p)</code>, the observations on the <code class="reqn">X</code> variables.</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times q)</code>, the observations on the <code class="reqn">Y</code> variables.</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_folds">folds</code></td>
<td>
<p>Positive integer. Number of folds to use if <code>validation="Mfold"</code>. Defaults to
<code>folds=10</code>.</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_validation">validation</code></td>
<td>
<p>Character string. What kind of (internal) cross-validation method to use, 
(partially) matching one of <code>"Mfolds"</code> (M-folds) or <code>"loo"</code> (leave-one-out).</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_ncomp">ncomp</code></td>
<td>
<p>Number of component for investigating the choice of the tuning parameter.</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_keepx">keepX</code></td>
<td>
<p>Vector of integer indicating the number of group of variables to keep in each component. See Details for more information.</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_alpha.x">alpha.x</code></td>
<td>
<p>Numeric vector indicating the number of group of variables to keep in each component. See Details for more information.</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_grid.gx">grid.gX</code>, <code id="tuning.sgPLS.X_+3A_grid.alpha.x">grid.alpha.X</code></td>
<td>
<p>Vector numeric defining the values of
tuning parameter lambda (number of groups to select) and tuning
parameter alpha (mixing paramter values between 0 and 1) at which cross-validation score should be computed</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_setseed">setseed</code></td>
<td>
<p>Integer indicating the random number generation state.</p>
</td></tr>	
<tr><td><code id="tuning.sgPLS.X_+3A_progressbar">progressBar</code></td>
<td>
<p>By default set to <code>FALSE</code> to output the progress bar of the computation.</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_ind.block.x">ind.block.x</code></td>
<td>
<p>A vector of integers describing the grouping of the X variables. (see an example in Details section).</p>
</td></tr>
<tr><td><code id="tuning.sgPLS.X_+3A_upper.lambda">upper.lambda</code></td>
<td>
<p>By default <code>upper.lambda=10 ^ 9</code>. A large value specifying the upper bound of the intervall of lambda values for searching the value of the tuning parameter (lambda) corresponding to a non-zero group of variables.</p>
</td></tr>	
</table>


<h3>Details</h3>

<p>If <code>validation = "Mfolds"</code>, M-fold cross-validation is performed by calling 
<code>Mfold</code>. The folds are generated. The number of cross-validation 
folds is specified with the argument <code>folds</code>. 
</p>
<p>If <code>validation = "loo"</code>, 
leave-one-out cross-validation is performed by calling the 
<code>loo</code> function. In this case the arguments <code>folds</code> are ignored.
</p>
<p>if <code>keepX</code> is specified (by default is NULL), each element of <code>keepX</code> indicates the value of the tuning parameter for the corresponding component. Only the choice of the tuning parameters corresponding to the remaining components are investigating by evaluating the cross-validation score at different values defining by <code>grid.X</code>.
</p>
<p>if <code>alpha.x</code> is specified (by default is NULL), each element of <code>alpha.x</code> indicates the value of the tuning parameter (alpha) for the corresponding component. Only the choice of the tuning parameters corresponding to the remaining components are investigating by evaluating the cross-vlidation score at different values defining by <code>grid.alpha.X</code>.
</p>


<h3>Value</h3>

<p>The returned value is a list with components: 
</p>
<table role = "presentation">
<tr><td><code>MSEP</code></td>
<td>
<p>vector containing the cross-validation score computed on the grid</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>value of the tuning parameter on which
the cross-validation method reached it minimum.</p>
</td></tr>
<tr><td><code>alphaX</code></td>
<td>
<p>value of the tuning parameter (alpha) on which
the cross-validation method reached it minimum.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 	
## Simulation of datasets X (with group variables) and Y a multivariate response variable 
n &lt;- 200
sigma.e &lt;- 0.5
p &lt;- 400
q &lt;- 10
theta.x1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5, 15),
			rep(0, 5), rep(-1.5, 15), rep(0, 325))
theta.x2 &lt;- c(rep(0, 320), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
			rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5))

set.seed(125)
theta.y1 &lt;- runif(10, 0.5, 2)
theta.y2 &lt;- runif(10, 0.5, 2)
  
temp &lt;-  matrix(c(theta.y1, theta.y2), nrow = 2, byrow = TRUE)

Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% t(svd(temp)$v) 
     + rmvnorm(n, mean = rep(0, q), sigma = Sigmay, method = "svd")

ind.block.x &lt;- seq(20, 380, 20)

grid.X &lt;- 2:16
grid.alpha.X &lt;- c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 0.95)
## Strategy with same value of each tuning parameter for both components
tun.sgPLS &lt;- tuning.sgPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
				ncomp = 2,keepX = NULL, alpha.x = NULL,grid.gX = grid.X, 
				grid.alpha.X = grid.alpha.X, setseed = 1, progressBar = FALSE, 
				ind.block.x = ind.block.x) 

tun.sgPLS$keepX # for each component
tun.sgPLS$alphaX # for each component
##For a sequential strategy
tun.sgPLS.1 &lt;- tuning.sgPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"),
			         ncomp = 1, keepX = NULL,  alpha.x = NULL, grid.gX = grid.X,
				 grid.alpha.X = grid.alpha.X, setseed = 1, 
				 ind.block.x = ind.block.x) 
					 
tun.sgPLS.1$keepX # for the first component
tun.sgPLS.1$alphaX # for the first component

tun.sgPLS.2 &lt;- tuning.sgPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
					ncomp = 2, keepX = tun.sgPLS.1$keepX,
					alpha.x = tun.sgPLS.1$alphaX,
					grid.gX = grid.X,
					grid.alpha.X = grid.alpha.X,
					setseed = 1,
					ind.block.x = ind.block.x) 

tun.sgPLS.2$keepX # for the second component
tun.sgPLS.2$alphaX # for the second component

## End(Not run)
</code></pre>

<hr>
<h2 id='tuning.sPLS.X'>Choice of the tuning parameter (number of variables) related to  predictor matrix for sPLS model (regression mode)</h2><span id='topic+tuning.sPLS.X'></span>

<h3>Description</h3>

<p>For a grid of tuning parameter, this function computes by leave-one-out or M-fold cross-validation the MSEP (Mean Square Error of Prediction) of a sPLS model. </p>


<h3>Usage</h3>

<pre><code class='language-R'>tuning.sPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), ncomp,
		keepX = NULL, grid.X, setseed, progressBar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tuning.sPLS.X_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times p)</code>, the observations on the <code class="reqn">X</code> variables.</p>
</td></tr>
<tr><td><code id="tuning.sPLS.X_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times q)</code>, the observations on the <code class="reqn">Y</code> variables.</p>
</td></tr>
<tr><td><code id="tuning.sPLS.X_+3A_folds">folds</code></td>
<td>
<p>Positive integer. Number of folds to use if <code>validation="Mfold"</code>. Defaults to
<code>folds=10</code>.</p>
</td></tr>
<tr><td><code id="tuning.sPLS.X_+3A_validation">validation</code></td>
<td>
<p>Character string. What kind of (internal) cross-validation method to use, (partially) matching one of <code>"Mfolds"</code> (M-folds) or <code>"loo"</code> (leave-one-out).</p>
</td></tr>
<tr><td><code id="tuning.sPLS.X_+3A_ncomp">ncomp</code></td>
<td>
<p>Number of component for investigating the choice of the tuning parameter.</p>
</td></tr>
<tr><td><code id="tuning.sPLS.X_+3A_keepx">keepX</code></td>
<td>
<p>Vector of integer indicating the number of variables to keep in each component. See Details for more information.</p>
</td></tr>
<tr><td><code id="tuning.sPLS.X_+3A_grid.x">grid.X</code></td>
<td>
<p>Vector of integers defining the values of the tuning parameter (corresponding to the number of variables to select) at which cross-validation score should be computed. </p>
</td></tr>
<tr><td><code id="tuning.sPLS.X_+3A_setseed">setseed</code></td>
<td>
<p>Integer indicating the random number generation state.</p>
</td></tr>	
<tr><td><code id="tuning.sPLS.X_+3A_progressbar">progressBar</code></td>
<td>
<p>By default set to <code>FALSE</code> to output the progress bar of the computation.</p>
</td></tr>	
</table>


<h3>Details</h3>

<p>If <code>validation="Mfolds"</code>, M-fold cross-validation is performed by calling 
<code>Mfold</code>. The folds are generated. The number of cross-validation 
folds is specified with the argument <code>folds</code>. 
</p>
<p>If <code>validation="loo"</code>, 
leave-one-out cross-validation is performed by calling the 
<code>loo</code> function. In this case the arguments <code>folds</code> are ignored.
</p>
<p>if <code>keepX</code> is specified (by default is NULL), each element of <code>keepX</code> indicates the value of the tuning parameter for the corresponding component. Only the choice of the tuning parameters corresponding to the remaining components are investigating by evaluating the cross-validation score at different values defining by <code>grid.X</code>.
</p>


<h3>Value</h3>

<p>The returned value is a list with components: 
</p>
<table role = "presentation">
<tr><td><code>MSEP</code></td>
<td>
<p>Vector containing the cross-validation score computed on the grid</p>
</td></tr>
<tr><td><code>keepX</code></td>
<td>
<p>Value of the tuning parameter on which
the cross-validation method reached it minimum.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 	
## Simulation of Datasets X (with group variables) and Y a multivariate response variable 
n &lt;- 200
sigma.e &lt;- 0.5
p &lt;- 400
q &lt;- 10
theta.x1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5, 15),
			rep(0, 5), rep(-1.5, 15), rep(0, 325))
theta.x2 &lt;- c(rep(0, 320), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
			rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5))

set.seed(125)
theta.y1 &lt;- runif(10, 0.5, 2)
theta.y2 &lt;- runif(10, 0.5, 2)
  
temp &lt;-  matrix(c(theta.y1, theta.y2), nrow = 2, byrow = TRUE)

Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% t(svd(temp)$v)
     + rmvnorm(n, mean = rep(0, q), sigma = Sigmay, method = "svd")


grid.X &lt;- c(20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 200, 250, 300)

## Strategy with same value for both components
tun.sPLS &lt;- tuning.sPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
		ncomp = 2, keepX = NULL, grid.X = grid.X, setseed = 1)
tun.sPLS$keepX # for each component

##For a sequential strategy
tun.sPLS.1 &lt;- tuning.sPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
		ncomp = 1, keepX = NULL, grid.X = grid.X, setseed = 1)

tun.sPLS.1$keepX # for the first component

tun.sPLS.2 &lt;- tuning.sPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"),
		 ncomp = 2, keepX = tun.sPLS.1$keepX , grid.X = grid.X, setseed = 1)
tun.sPLS.2$keepX # for the second component


## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
