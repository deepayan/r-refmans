<!DOCTYPE html><html lang="en"><head><title>Help for package fence</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fence}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adaptivefence'><p>Adaptive Fence model selection</p></a></li>
<li><a href='#adaptivefence.fh'><p>Adaptive Fence model selection (Small Area Estmation)</p></a></li>
<li><a href='#fence.lmer'><p>Fence model selection (Linear Mixed Model)</p></a></li>
<li><a href='#fence.NF'><p>Fence model selection (Nonparametric Model)</p></a></li>
<li><a href='#fence.sae'><p>Fence model selection (Small Area Estmation)</p></a></li>
<li><a href='#IF.lm'><p>Invisible Fence model selection (Linear Model)</p></a></li>
<li><a href='#IF.lmer'><p>Invisible Fence model selection (Linear Mixed Model)</p></a></li>
<li><a href='#invisiblefence'><p>Invisible Fence model selection</p></a></li>
<li><a href='#kidney'><p>kidney</p></a></li>
<li><a href='#nonadaptivefence'><p>Nonadaptive Fence model selection</p></a></li>
<li><a href='#plot.AF'><p>Plot Adaptive Fence model selection</p></a></li>
<li><a href='#plot.NF'><p>Plot Nonparametric Fence model selection</p></a></li>
<li><a href='#RF'><p>Adaptive Fence model selection (Restricted Fence)</p></a></li>
<li><a href='#summary.AF'><p>Summary Adaptive Fence model selection</p></a></li>
<li><a href='#summary.NF'><p>Summary Nonparametric Fence model selection</p></a></li>
<li><a href='#X.lmer'><p>X.lmer</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Using Fence Methods for Model Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-05-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Jiming Jiang, Jianyang Zhao, J. Sunil Rao, Thuan Nguyen</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thuan Nguyen &lt;nguythua@ohsu.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>This method is a new class of model selection strategies, 
    for mixed model selection, which includes linear and generalized linear 
    mixed models. The idea involves a procedure to isolate a subgroup of what 
    are known as correct models (of which the optimal model is a member). This is 
    accomplished by constructing a statistical fence, or barrier, to carefully 
    eliminate incorrect models. Once the fence is constructed, the optimal model is 
    selected from among those within the fence according to a criterion which can 
    be made flexible.
    References: 
    1. Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. 
    The Annals of Statistics, 36(4): 1669-1692.  
    &lt;<a href="https://doi.org/10.1214%2F07-AOS517">doi:10.1214/07-AOS517</a>&gt; <a href="https://projecteuclid.org/euclid.aos/1216237296">https://projecteuclid.org/euclid.aos/1216237296</a>.
    2. Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. 
    Statistics and Probability Letters, 79, 625-629.  
    &lt;<a href="https://doi.org/10.1016%2Fj.spl.2008.10.014">doi:10.1016/j.spl.2008.10.014</a>&gt; <a href="https://www.researchgate.net/publication/23991417_A_simplified_adaptive_fence_procedure">https://www.researchgate.net/publication/23991417_A_simplified_adaptive_fence_procedure</a>
    3. Jiang J., Nguyen T., Rao J.S. (2010), Fence Method for Nonparametric Small Area Estimation. 
    Survey Methodology, 36(1), 3-11.  
    <a href="http://publications.gc.ca/collections/collection_2010/statcan/12-001-X/12-001-x2010001-eng.pdf">http://publications.gc.ca/collections/collection_2010/statcan/12-001-X/12-001-x2010001-eng.pdf</a>.
    4. Jiming Jiang, Thuan Nguyen and J. Sunil Rao (2011), Invisible fence methods and the identification of differentially expressed gene sets. 
    Statistics and Its Interface, Volume 4, 403-415.
    <a href="http://www.intlpress.com/site/pub/files/_fulltext/journals/sii/2011/0004/0003/SII-2011-0004-0003-a014.pdf">http://www.intlpress.com/site/pub/files/_fulltext/journals/sii/2011/0004/0003/SII-2011-0004-0003-a014.pdf</a>.
    5. Thuan Nguyen &amp; Jiming Jiang (2012), Restricted fence method for covariate selection in longitudinal data analysis. 
    Biostatistics, 13(2), 303-314.  
    &lt;<a href="https://doi.org/10.1093%2Fbiostatistics%2Fkxr046">doi:10.1093/biostatistics/kxr046</a>&gt; <a href="https://academic.oup.com/biostatistics/article/13/2/303/263903/Restricted-fence-method-for-covariate-selection-in">https://academic.oup.com/biostatistics/article/13/2/303/263903/Restricted-fence-method-for-covariate-selection-in</a>.
    6. Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  
    Statistical Computation and Simulation, 84(3), 644-662.  
    &lt;<a href="https://doi.org/10.1080%2F00949655.2012.721885">doi:10.1080/00949655.2012.721885</a>&gt; <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3891925/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3891925/</a>.
    7. Jiang, J. (2014), The fence methods, in Advances in Statistics, Hindawi Publishing Corp., Cairo.  
    &lt;<a href="https://doi.org/10.1155%2F2014%2F830821">doi:10.1155/2014/830821</a>&gt;.
    8. Jiming Jiang and Thuan Nguyen (2015), The Fence Methods, World Scientific, Singapore.  
    <a href="https://www.abebooks.com/9789814596060/Fence-Methods-Jiming-Jiang-981459606X/plp">https://www.abebooks.com/9789814596060/Fence-Methods-Jiming-Jiang-981459606X/plp</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-2-Clause">BSD_2_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, stats, lme4, ggplot2, compiler, sae, fields, grDevices,
snowfall, snow</td>
</tr>
<tr>
<td>Suggests:</td>
<td>pscl</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-06-30 19:11:50 UTC; Tyler</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-07-01 08:02:18 UTC</td>
</tr>
</table>
<hr>
<h2 id='adaptivefence'>Adaptive Fence model selection</h2><span id='topic+adaptivefence'></span>

<h3>Description</h3>

<p>Adaptive Fence model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaptivefence(mf, f, ms, d, lf, pf, bs, grid = 101, bandwidth)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adaptivefence_+3A_mf">mf</code></td>
<td>
<p>function for fitting the model</p>
</td></tr>
<tr><td><code id="adaptivefence_+3A_f">f</code></td>
<td>
<p>formula of full model</p>
</td></tr>
<tr><td><code id="adaptivefence_+3A_ms">ms</code></td>
<td>
<p>list of formula of candidates models</p>
</td></tr>
<tr><td><code id="adaptivefence_+3A_d">d</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="adaptivefence_+3A_lf">lf</code></td>
<td>
<p>measure lack of fit (to minimize)</p>
</td></tr>
<tr><td><code id="adaptivefence_+3A_pf">pf</code></td>
<td>
<p>model selection criteria, e.g., model dimension</p>
</td></tr>
<tr><td><code id="adaptivefence_+3A_bs">bs</code></td>
<td>
<p>bootstrap samples</p>
</td></tr>
<tr><td><code id="adaptivefence_+3A_grid">grid</code></td>
<td>
<p>grid for c</p>
</td></tr>
<tr><td><code id="adaptivefence_+3A_bandwidth">bandwidth</code></td>
<td>
<p>bandwidth for kernel smooth function</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>models</code></td>
<td>
<p>list all model candidates in the model space</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>list the number of bootstrap samples that have been used</p>
</td></tr>
<tr><td><code>lack_of_fit_matrix</code></td>
<td>
<p>list a matrix of Qs for all model candidates (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>Qd_matrix</code></td>
<td>
<p>list a matrix of QM - QM.tilde for all model candidates. Each row is for each bootrap sample</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>list the value of bandwidth</p>
</td></tr>
<tr><td><code>model_mat</code></td>
<td>
<p>list a matrix of selected models at each c values in grid (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>freq_mat</code></td>
<td>
<p>list a matrix of coverage probabilities (frequency/smooth_frequency) of each selected models for a given c value (index)</p>
</td></tr>
<tr><td><code>c</code></td>
<td>
<p>list the adaptive choice of c value from which the parsimonious model is selected</p>
</td></tr>
<tr><td><code>sel_model</code></td>
<td>
<p>list the selected (parsimonious) model given the adaptive c value</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jiming Jiang  Jianyang Zhao  J. Sunil Rao  Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. Statistics and Probability Letters, 79, 625-629
</p>
</li>
<li><p>Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  Statistical Computation and Simulation, 84(3), 644-662
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(fence)

#### Example 1 #####
data(iris)
full = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width + (1|Species)
test_af = fence.lmer(full, iris)
plot(test_af)
test_af$sel_model

#### Example 2 #####
r =1234; set.seed(r)  
p=8; n=150; rho = 0.6
id = rep(1:50,each=3)
R = diag(p)
for(i in 1:p){
  for(j in 1:p){
     R[i,j] = rho^(abs(i-j))
  }
} 
R = 1*R
x=mvrnorm(n, rep(0, p), R)  # all x's are time-varying dependence #
colnames(x)=paste('x',1:p, sep='')
tbetas = c(0,0.5,1,0,0.5,1,0,0.5)  # non-zero beta 2,3,5,6,8
epsilon = rnorm(150)
y = x%*%tbetas + epsilon
colnames(y) = 'y'
data = data.frame(cbind(x,y,id))
full = y ~ x1+x2+x3+x4+x5+x6+x7+x8+(1|id)
#X = paste('x',1:p, sep='', collapse='+')
#full = as.formula(paste('y~',X,'+(1|id)', sep=""))  #same as previous one
fence_obj = fence.lmer(full,data)   # it takes 3-5 min #
plot(fence_obj)
fence_obj$sel_model

## End(Not run)
</code></pre>

<hr>
<h2 id='adaptivefence.fh'>Adaptive Fence model selection (Small Area Estmation)</h2><span id='topic+adaptivefence.fh'></span>

<h3>Description</h3>

<p>Adaptive Fence model selection (Small Area Estmation)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaptivefence.fh(mf, f, ms, d, lf, pf, bs, grid = 101, bandwidth, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adaptivefence.fh_+3A_mf">mf</code></td>
<td>
<p>Call function, for example: default calls: function(m, b) eblupFH(formula = m, vardir = D, data = b, method = &quot;FH&quot;)</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_f">f</code></td>
<td>
<p>Full Model</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_ms">ms</code></td>
<td>
<p>find candidate model, findsubmodel.fh(full)</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_d">d</code></td>
<td>
<p>Dimension number</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_lf">lf</code></td>
<td>
<p>Measures lack of fit using function(res) -res$fit$goodness[1]</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_pf">pf</code></td>
<td>
<p>Dimensions of model</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_bs">bs</code></td>
<td>
<p>Bootstrap</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_grid">grid</code></td>
<td>
<p>grid for c</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_bandwidth">bandwidth</code></td>
<td>
<p>bandwidth for kernel smooth function</p>
</td></tr>
<tr><td><code id="adaptivefence.fh_+3A_method">method</code></td>
<td>
<p>Method to be used. Fay-Herriot method is the default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Jiang et. al (2008), the adaptive c value is chosen from the highest peak in the p* vs. c plot.  
In Jiang et. al (2009), 95% CI is taken into account while choosing such an adaptive choice of c.
In Thuan Nguyen et. al (2014), the adaptive c value is chosen from the first peak. This approach works better in the 
moderate sample size or weak signal situations.  Empirically, the first peak becomes highest peak when sample size 
increases or signals become stronger
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>models</code></td>
<td>
<p>list all model candidates in the model space</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>list the number of bootstrap samples that have been used</p>
</td></tr>
<tr><td><code>lack_of_fit_matrix</code></td>
<td>
<p>list a matrix of Qs for all model candidates (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>Qd_matrix</code></td>
<td>
<p>list a matrix of QM - QM.tilde for all model candidates. Each row is for each bootrap sample</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>list the value of bandwidth</p>
</td></tr>
<tr><td><code>model_mat</code></td>
<td>
<p>list a matrix of selected models at each c values in grid (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>freq_mat</code></td>
<td>
<p>list a matrix of coverage probabilities (frequency/smooth_frequency) of each selected models for a given c value (index)</p>
</td></tr>
<tr><td><code>c</code></td>
<td>
<p>list the adaptive choice of c value from which the parsimonious model is selected</p>
</td></tr>
<tr><td><code>sel_model</code></td>
<td>
<p>list the selected (parsimonious) model given the adaptive c value</p>
</td></tr>
</table>


<h3>Note</h3>


<ul>
<li><p>The current Fence package focuses on variable selection. 
However, Fence methods can be used to select other parameters of interest, e.g., tunning parameter, variance-covariance structure, etc.
</p>
</li>
<li><p>The number of bootstrap samples is suggested to be increased, e.g., B=1000 when the sample size is small, or signals are weak
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Jiming Jiang  Jianyang Zhao  J. Sunil Rao  Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. Statistics and Probability Letters, 79, 625-629
</p>
</li>
<li><p>Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  Statistical Computation and Simulation, 84(3), 644-662
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(fence)
### example 1 ####
data("kidney")
data = kidney[-which.max(kidney$x),]     # Delete a suspicious data point #
data$x2 = data$x^2
data$x3 = data$x^3
data$x4 = data$x^4
data$D = data$sqrt.D.^2
plot(data$y ~ data$x)
full = y~x+x2+x3+x4
testfh = fence.sae(full, data, B=1000, fence="adaptive", method="F-H", D = D)
testfh$sel_model
testfh$c

## End(Not run)
</code></pre>

<hr>
<h2 id='fence.lmer'>Fence model selection (Linear Mixed Model)</h2><span id='topic+fence.lmer'></span>

<h3>Description</h3>

<p>Fence model selection (Linear Mixed Model)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fence.lmer(full, data, B = 100, grid = 101, fence = c("adaptive",
  "nonadaptive"), cn = NA, REML = TRUE, bandwidth = NA,
  cpus = parallel::detectCores())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fence.lmer_+3A_full">full</code></td>
<td>
<p>formula of full model</p>
</td></tr>
<tr><td><code id="fence.lmer_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="fence.lmer_+3A_b">B</code></td>
<td>
<p>number of bootstrap samples, parametric bootstrap is used</p>
</td></tr>
<tr><td><code id="fence.lmer_+3A_grid">grid</code></td>
<td>
<p>grid for c</p>
</td></tr>
<tr><td><code id="fence.lmer_+3A_fence">fence</code></td>
<td>
<p>a procedure of the fence method to be used.
It's suggested to choose nonadaptive procedure if c is known; otherwise nonadaptive must be chosen</p>
</td></tr>
<tr><td><code id="fence.lmer_+3A_cn">cn</code></td>
<td>
<p>cn value for nonadaptive</p>
</td></tr>
<tr><td><code id="fence.lmer_+3A_reml">REML</code></td>
<td>
<p>Restricted Maximum Likelihood approach</p>
</td></tr>
<tr><td><code id="fence.lmer_+3A_bandwidth">bandwidth</code></td>
<td>
<p>bandwidth for kernel smooth function</p>
</td></tr>
<tr><td><code id="fence.lmer_+3A_cpus">cpus</code></td>
<td>
<p>Number of parallel computers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Jiang et. al (2008), the adaptive c value is chosen from the highest peak in the p* vs. c plot.  
In Jiang et. al (2009), 95% CI is taken into account while choosing such an adaptive choice of c.
In Thuan Nguyen et. al (2014), the adaptive c value is chosen from the first peak. This approach works better in the 
moderate sample size or weak signal situations.  Empirically, the first peak becomes highest peak when sample size 
increases or signals become stronger
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>models</code></td>
<td>
<p>list all model candidates in the model space</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>list the number of bootstrap samples that have been used</p>
</td></tr>
<tr><td><code>lack_of_fit_matrix</code></td>
<td>
<p>list a matrix of Qs for all model candidates (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>Qd_matrix</code></td>
<td>
<p>list a matrix of QM - QM.tilde for all model candidates. Each row is for each bootrap sample</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>list the value of bandwidth</p>
</td></tr>
<tr><td><code>model_mat</code></td>
<td>
<p>list a matrix of selected models at each c values in grid (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>freq_mat</code></td>
<td>
<p>list a matrix of coverage probabilities (frequency/smooth_frequency) of each selected models for a given c value (index)</p>
</td></tr>
<tr><td><code>c</code></td>
<td>
<p>list the adaptive choice of c value from which the parsimonious model is selected</p>
</td></tr>
<tr><td><code>sel_model</code></td>
<td>
<p>list the selected (parsimonious) model given the adaptive c value</p>
</td></tr>
</table>
<p>@note The current Fence package focuses on variable selection. 
However, Fence methods can be used to select other parameters of interest, e.g., tunning parameter, variance-covariance structure, etc.
</p>


<h3>Author(s)</h3>

<p>Jiming Jiang  Jianyang Zhao  J. Sunil Rao  Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. Statistics and Probability Letters, 79, 625-629
</p>
</li>
<li><p>Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  Statistical Computation and Simulation, 84(3), 644-662
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>require(fence)
library(snow)

#### Example 1 #####
data(iris)
full = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width + (1|Species)
# Takes greater than 5 seconds to run
# test_af = fence.lmer(full, iris)
# test_af$c
# test_naf = fence.lmer(full, iris, fence = "nonadaptive", cn = 12)
# plot(test_af)
# test_af$sel_model
# test_naf$sel_model
</code></pre>

<hr>
<h2 id='fence.NF'>Fence model selection (Nonparametric Model)</h2><span id='topic+fence.NF'></span>

<h3>Description</h3>

<p>Fence model selection (Noparametric Model)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fence.NF(full, data, spline, ps = 1:3, qs = NA, B = 100, grid = 101,
  bandwidth = NA, lambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fence.NF_+3A_full">full</code></td>
<td>
<p>formula of full model</p>
</td></tr>
<tr><td><code id="fence.NF_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="fence.NF_+3A_spline">spline</code></td>
<td>
<p>variable needed for spline terms</p>
</td></tr>
<tr><td><code id="fence.NF_+3A_ps">ps</code></td>
<td>
<p>order of power</p>
</td></tr>
<tr><td><code id="fence.NF_+3A_qs">qs</code></td>
<td>
<p>number of knots</p>
</td></tr>
<tr><td><code id="fence.NF_+3A_b">B</code></td>
<td>
<p>number of bootstrap sample, parametric for lmer</p>
</td></tr>
<tr><td><code id="fence.NF_+3A_grid">grid</code></td>
<td>
<p>grid for c</p>
</td></tr>
<tr><td><code id="fence.NF_+3A_bandwidth">bandwidth</code></td>
<td>
<p>bandwidth for kernel smooth function</p>
</td></tr>
<tr><td><code id="fence.NF_+3A_lambda">lambda</code></td>
<td>
<p>A grid of lambda values</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>models</code></td>
<td>
<p>list all model candidates with p polynomial degrees and q knots in the model space</p>
</td></tr>
<tr><td><code>Qd_matrix</code></td>
<td>
<p>list a matrix of QM - QM.tilde for all model candidates. Each row is for each bootrap sample</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>list the value of bandwidth</p>
</td></tr>
<tr><td><code>model_mat</code></td>
<td>
<p>list a matrix of selected models at each c values in grid (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>freq_mat</code></td>
<td>
<p>list a matrix of coverage probabilities (frequency/smooth_frequency) of each selected models for a given c value (index)</p>
</td></tr>
<tr><td><code>c</code></td>
<td>
<p>list the adaptive choice of c value from which the parsimonious model is selected</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>penalty (or smoothing) parameter estimate given selected p and q</p>
</td></tr>
<tr><td><code>sel_model</code></td>
<td>
<p>list the selected (parsimonious) model given the adaptive c value</p>
</td></tr>
<tr><td><code>beta.est.u</code></td>
<td>
<p>A list of coefficient estimates given a lambda value</p>
</td></tr>
<tr><td><code>f.x.hat</code></td>
<td>
<p>A vector of fitted values obtained from a given lambda value and beta.est.u</p>
</td></tr>
</table>
<p>@note The current Fence method in Nonparametric model focuses on one spline variable. 
This method can be extended to a general case with more than one spline variables, and includes non-spline variables.
</p>


<h3>Author(s)</h3>

<p>Jiming Jiang Jianyang Zhao J. Sunil Rao Bao-Qui Tran Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. Statistics and Probability Letters, 79, 625-629
</p>
</li>
<li><p>Jiang J., Nguyen T., Rao J.S. (2010), Fence Method for Nonparametric Small Area Estimation. Survey Methodology, 36, 1, 3-11
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(fence)
n = 100
set.seed(1234)
x=runif(n,0,3)
y = 1-x+x^2- 2*(x-1)^2*(x&gt;1) + 2*(x-2)^2*(x&gt;2) + rnorm(n,sd=.2)
lambda=exp((c(1:60)-30)/3)
data=data.frame(cbind(x,y))   
test_NF = fence.NF(full=y~x, data=data, spline='x', ps=c(1:3), qs=c(2,5), B=1000, lambda=lambda)
plot(test_NF)
summary &lt;- summary(test_NF) 
model_sel &lt;- summary[[1]]
model_sel
lambda_sel &lt;- summary[[2]]
lambda_sel

## End(Not run)
</code></pre>

<hr>
<h2 id='fence.sae'>Fence model selection (Small Area Estmation)</h2><span id='topic+fence.sae'></span>

<h3>Description</h3>

<p>Fence model selection (Small Area Estmation)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fence.sae(full, data, B = 100, grid = 101, fence = c("adaptive",
  "nonadaptive"), cn = NA, method = c("F-H", "NER"), D = NA,
  REML = FALSE, bandwidth = NA, cpus = parallel::detectCores())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fence.sae_+3A_full">full</code></td>
<td>
<p>formular of full model</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_b">B</code></td>
<td>
<p>number of bootstrap sample, parametric for lmer</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_grid">grid</code></td>
<td>
<p>grid for c</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_fence">fence</code></td>
<td>
<p>fence method to be used, e.g., adaptive, or nonadaptive.
It's suggested to choose nonadaptive procedure if c is known; otherwise nonadaptive must be chosen</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_cn">cn</code></td>
<td>
<p>cn for nonadaptive</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_method">method</code></td>
<td>
<p>Select method to use</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_d">D</code></td>
<td>
<p>vector containing the D sampling variances of direct estimators for each domain. The values must be sorted as the variables in formula. Only used in FH model</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_reml">REML</code></td>
<td>
<p>Restricted Maximum Likelihood approach</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_bandwidth">bandwidth</code></td>
<td>
<p>bandwidth for kernel smooth function</p>
</td></tr>
<tr><td><code id="fence.sae_+3A_cpus">cpus</code></td>
<td>
<p>Number of parallel computers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Jiang et. al (2008), the adaptive c value is chosen from the highest peak in the p* vs. c plot.  
In Jiang et. al (2009), 95% CI is taken into account while choosing such an adaptive choice of c.
In Thuan Nguyen et. al (2014), the adaptive c value is chosen from the first peak. This approach works better in the 
moderate sample size or weak signal situations.  Empirically, the first peak becomes highest peak when sample size 
increases or signals become stronger
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>models</code></td>
<td>
<p>list all model candidates in the model space</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>list the number of bootstrap samples that have been used</p>
</td></tr>
<tr><td><code>lack_of_fit_matrix</code></td>
<td>
<p>list a matrix of Qs for all model candidates (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>Qd_matrix</code></td>
<td>
<p>list a matrix of QM - QM.tilde for all model candidates. Each row is for each bootrap sample</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>list the value of bandwidth</p>
</td></tr>
<tr><td><code>model_mat</code></td>
<td>
<p>list a matrix of selected models at each c values in grid (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>freq_mat</code></td>
<td>
<p>list a matrix of coverage probabilities (frequency/smooth_frequency) of each selected models for a given c value (index)</p>
</td></tr>
<tr><td><code>c</code></td>
<td>
<p>list the adaptive choice of c value from which the parsimonious model is selected</p>
</td></tr>
<tr><td><code>sel_model</code></td>
<td>
<p>list the selected (parsimonious) model given the adaptive c value</p>
</td></tr>
</table>


<h3>Note</h3>


<ul>
<li><p>The current Fence package focuses on variable selection. 
However, Fence methods can be used to select other parameters of interest, e.g., tunning parameter, variance-covariance structure, etc.
</p>
</li>
<li><p>The number of bootstrap samples is suggested to be increased, e.g., B=1000 when the sample size is small, or signals are weak
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Jiming Jiang  Jianyang Zhao  J. Sunil Rao  Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. Statistics and Probability Letters, 79, 625-629
</p>
</li>
<li><p>Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  Statistical Computation and Simulation, 84(3), 644-662
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>require(fence)
library(snow)
### example 1 ####
data("kidney")
data = kidney[-which.max(kidney$x),]     # Delete a suspicious data point #
data$x2 = data$x^2
data$x3 = data$x^3
data$x4 = data$x^4
data$D = data$sqrt.D.^2
plot(data$y ~ data$x)
full = y~x+x2+x3+x4
# Takes more than 5 seconds to run
# testfh = fence.sae(full, data, B=100, fence="adaptive", method="F-H", D = D)
# testfh$sel_model
# testfh$c
</code></pre>

<hr>
<h2 id='IF.lm'>Invisible Fence model selection (Linear Model)</h2><span id='topic+IF.lm'></span>

<h3>Description</h3>

<p>Invisible Fence model selection (Linear Model)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IF.lm(full, data, B = 100, cpus = 2, lftype = c("abscoef", "pvalue"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IF.lm_+3A_full">full</code></td>
<td>
<p>formula of full model</p>
</td></tr>
<tr><td><code id="IF.lm_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="IF.lm_+3A_b">B</code></td>
<td>
<p>number of bootstrap sample, parametric for lm</p>
</td></tr>
<tr><td><code id="IF.lm_+3A_cpus">cpus</code></td>
<td>
<p>number of parallel computers</p>
</td></tr>
<tr><td><code id="IF.lm_+3A_lftype">lftype</code></td>
<td>
<p>subtractive measure type, e.g., absolute value of coefficients, p-value, t-value, etc.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method (Jiang et. al, 2011) is motivated by computational expensive in complex and high dimensional problem.
The idea of the method&ndash;there is the best model in each dimension (in model space).  The boostrapping determines the coverage
probability of the selected model in each dimensions. The parsimonious model is the selected model with the highest coverage probabily
(except the one for the full model, always probability of 1.)
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>full</code></td>
<td>
<p>list the full model</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>list the number of bootstrap samples that have been used</p>
</td></tr>
<tr><td><code>freq</code></td>
<td>
<p>list the coverage probabilities of the selected model for each dimension</p>
</td></tr>
<tr><td><code>size</code></td>
<td>
<p>list the number of variables in the parsimonious model</p>
</td></tr>
<tr><td><code>term</code></td>
<td>
<p>list variables included in the full model</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>list the variables selected in-the-order in the parsimonious model</p>
</td></tr>
</table>
<p>@note The current Invisible Fence focuses on variable selection. The current routine is applicable to the case in which
the subtractive measure is the absolute value of the coefficients, p-value, t-value.
However, the method can be extended to other subtractive measures.  See Jiang et. al (2011) for more details.
</p>


<h3>Author(s)</h3>

<p>Jiming Jiang  Jianyang Zhao  J. Sunil Rao  Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiming Jiang, Thuan Nguyen and J. Sunil Rao (2011), Invisible fence methods and the identification of differentially expressed gene sets. Statistics and Its Interface, Volume 4, 403-415.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(fence)
library(MASS)
library(snow)
r =1234; set.seed(r)
p=10; n=300; rho = 0.6
R = diag(p)
for(i in 1:p){
  for(j in 1:p){
     R[i,j] = rho^(abs(i-j))
  }
}
R = 1*R
x=mvrnorm(n, rep(0, p), R)
colnames(x)=paste('x',1:p, sep='')
X = cbind(rep(1,n),x)
tbetas = c(1,1,1,0,1,1,0,1,0,0,0)  # non-zero beta 1,2,4,5,7
epsilon = rnorm(n)
y = as.matrix(X)%*%tbetas + epsilon
colnames(y) = 'y'
data = data.frame(cbind(X,y))
full = y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10
# Takes greater than 5 seconds (~`17 seconds) to run
# obj1 = IF.lm(full = full, data = data, B = 100, lftype = "abscoef")
# sort((names(obj1$model$coef)[-1]))  
# obj2 = IF.lm(full = full, data = data, B = 100, lftype = "pvalue")
# sort(setdiff(names(data[c(-1,-12)]), names(obj2$model$coef)))

</code></pre>

<hr>
<h2 id='IF.lmer'>Invisible Fence model selection (Linear Mixed Model)</h2><span id='topic+IF.lmer'></span>

<h3>Description</h3>

<p>Invisible Fence model selection (Linear Mixed Model)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IF.lmer(full, data, B = 100, REML = TRUE, method = c("marginal",
  "conditional"), cpus = parallel::detectCores(), lftype = c("abscoef",
  "tvalue"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IF.lmer_+3A_full">full</code></td>
<td>
<p>formula of full model</p>
</td></tr>
<tr><td><code id="IF.lmer_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="IF.lmer_+3A_b">B</code></td>
<td>
<p>number of bootstrap sample, parametric for lmer</p>
</td></tr>
<tr><td><code id="IF.lmer_+3A_reml">REML</code></td>
<td>
<p>Restricted maximum likelihood estimation</p>
</td></tr>
<tr><td><code id="IF.lmer_+3A_method">method</code></td>
<td>
<p>choose either marginal (e.g., GEE) or conditional model</p>
</td></tr>
<tr><td><code id="IF.lmer_+3A_cpus">cpus</code></td>
<td>
<p>Number of parallel computers</p>
</td></tr>
<tr><td><code id="IF.lmer_+3A_lftype">lftype</code></td>
<td>
<p>subtractive measure type, e.g., absolute value of coefficients, p-value, t-value, etc.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method (Jiang et. al, 2011) is motivated by computational expensive in complex and high dimensional problem.
The idea of the method&ndash;there is the best model in each dimension (in model space).  The boostrapping determines the coverage
probability of the selected model in each dimensions. The parsimonious model is the selected model with the highest coverage probabily
(except the one for the full model, always probability of 1.)
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>full</code></td>
<td>
<p>list the full model</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>list the number of bootstrap samples that have been used</p>
</td></tr>
<tr><td><code>freq</code></td>
<td>
<p>list the coverage probabilities of the selected model for each dimension</p>
</td></tr>
<tr><td><code>size</code></td>
<td>
<p>list the number of variables in the parsimonious model</p>
</td></tr>
<tr><td><code>term</code></td>
<td>
<p>list variables included in the full model</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>list the variables selected in-the-order in the parsimonious model</p>
</td></tr>
</table>
<p>@note The current Invisible Fence focuses on variable selection. The current routine is applicable to the case in which
the subtractive measure is the absolute value of the coefficients, p-value, t-value.
However, the method can be extended to other subtractive measures.  See Jiang et. al (2011) for more details.
</p>


<h3>Author(s)</h3>

<p>Jiming Jiang  Jianyang Zhao  J. Sunil Rao  Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiming Jiang, Thuan Nguyen and J. Sunil Rao (2011), Invisible fence methods and the identification of differentially expressed gene sets. Statistics and Its Interface, Volume 4, 403-415.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>require(fence)
library(snow)
library(MASS)
data("X.lmer")
data = data.frame(X.lmer)
# non-zero beta I.col.2, I.col.3a, I.col.3b, V5, V7, V8, V9
beta = matrix(c(0, 1, 1, 1, 1, 0, 0.1, 0.05, 0.25, 0), ncol = 1)
set.seed(1234)
alpha = rep(rnorm(100), each = 3)
mu = alpha + as.matrix(data[,-1]) %*% beta
data$id = as.factor(data$id)
data$y = mu + rnorm(300)
raw = "y ~ (1|id)+I.col.2+I.col.3a+I.col.3b"
for (i in 5:10) {
    raw = paste0(raw, "+V", i)
}
full = as.formula(raw)
# The following output takes more than 5 seconds (~70 seconds) to run. 

# obj1.lmer = IF.lmer(full = full, data = data, B = 100, method="conditional",lftype = "abscoef")
# sort(obj1.lmer$model) 

# obj2.lmer = IF.lmer(full = full, data = data, B = 100, method="conditional",lftype = "tvalue")
# sort(obj2.lmer$model)

# Similarly, the following scenarios can be run

# obj2.lmer = IF.lmer(full = full, data = data, B = 100, method="conditional",lftype = "tvalue")
# sort(obj2.lmer$model)
# obj1.lm = IF.lmer(full = full, data = data, B = 100, method="marginal", lftype = "abscoef")
# sort(names(obj1.lm$model$coefficients[-1]))
# obj2.lm = IF.lmer(full = full, data = data, B = 100, method="marginal", lftype = "tvalue")
# sort(names(obj2.lm$model$coefficients[-1]))

</code></pre>

<hr>
<h2 id='invisiblefence'>Invisible Fence model selection</h2><span id='topic+invisiblefence'></span>

<h3>Description</h3>

<p>Invisible Fence model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invisiblefence(mf, f, d, lf, bs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="invisiblefence_+3A_mf">mf</code></td>
<td>
<p>Call function, for example: default calls: function(m, b) eblupFH(formula = m, vardir = D, data = b, method = &quot;FH&quot;)</p>
</td></tr>
<tr><td><code id="invisiblefence_+3A_f">f</code></td>
<td>
<p>Full model</p>
</td></tr>
<tr><td><code id="invisiblefence_+3A_d">d</code></td>
<td>
<p>Dimension number</p>
</td></tr>
<tr><td><code id="invisiblefence_+3A_lf">lf</code></td>
<td>
<p>Measures lack of fit using function(res) -res$fit$goodness[1]</p>
</td></tr>
<tr><td><code id="invisiblefence_+3A_bs">bs</code></td>
<td>
<p>Bootstrap</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method (Jiang et. al, 2011) is motivated by computational expensive in complex and high dimensional problem.
The idea of the method&ndash;there is the best model in each dimension (in model space).  The boostrapping determines the coverage
probability of the selected model in each dimensions. The parsimonious model is the selected model with the highest coverage probabily
(except the one for the full model, always probability of 1.)
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>full</code></td>
<td>
<p>list the full model</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>list the number of bootstrap samples that have been used</p>
</td></tr>
<tr><td><code>freq</code></td>
<td>
<p>list the coverage probabilities of the selected model for each dimension</p>
</td></tr>
<tr><td><code>size</code></td>
<td>
<p>list the number of variables in the parsimonious model</p>
</td></tr>
<tr><td><code>term</code></td>
<td>
<p>list variables included in the full model</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>list the variables selected in-the-order in the parsimonious model</p>
</td></tr>
</table>
<p>@note The current Invisible Fence focuses on variable selection. The current routine is applicable to the case in which
the subtractive measure is the absolute value of the coefficients, p-value, t-value.
However, the method can be extended to other subtractive measures.  See Jiang et. al (2011) for more details.
</p>


<h3>Author(s)</h3>

<p>Jiming Jiang  Jianyang Zhao  J. Sunil Rao  Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiming Jiang, Thuan Nguyen and J. Sunil Rao (2011), Invisible fence methods and the identification of differentially expressed gene sets. Statistics and Its Interface, Volume 4, 403-415.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("X.lmer")
data = data.frame(X.lmer)
beta = matrix(c(0, 1, 1, 1, 1, 0, 0.1, 0.05, 0.25, 0), ncol = 1)
set.seed(1234)
alpha = rep(rnorm(100), each = 3)
mu = alpha + as.matrix(data[,-1]) %*% beta
data$id = as.factor(data$id)
data$y = mu + rnorm(300)
raw = "y ~ (1|id)+I.col.2+I.col.3a+I.col.3b"
for (i in 5:10) {
    raw = paste0(raw, "+V", i)
}
full = as.formula(raw)
obj1.lmer = IF.lmer(full = full, data = data, B = 100, method="conditional",lftype = "abscoef")
obj1.lmer$model$coefficients
obj2.lmer = IF.lmer(full = full, data = data, B = 100, method="conditional",lftype = "tvalue")
obj2.lmer$model$coefficients
obj1.lm = IF.lmer(full = full, data = data, B = 100, method="marginal", lftype = "abscoef")
obj1.lm$model$coefficients
obj2.lm = IF.lmer(full = full, data = data, B = 100, method="marginal", lftype = "tvalue")
obj2.lm$model$coefficients

## End(Not run)
</code></pre>

<hr>
<h2 id='kidney'>kidney</h2><span id='topic+kidney'></span>

<h3>Description</h3>

<p>Data used for kidney example
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kidney
</code></pre>


<h3>Format</h3>

<p>A data frame with 4 variables</p>

<hr>
<h2 id='nonadaptivefence'>Nonadaptive Fence model selection</h2><span id='topic+nonadaptivefence'></span>

<h3>Description</h3>

<p>Nonadaptive Fence model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nonadaptivefence(mf, f, ms, d, lf, pf, cn)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nonadaptivefence_+3A_mf">mf</code></td>
<td>
<p>function for fitting the model</p>
</td></tr>
<tr><td><code id="nonadaptivefence_+3A_f">f</code></td>
<td>
<p>formula of full model</p>
</td></tr>
<tr><td><code id="nonadaptivefence_+3A_ms">ms</code></td>
<td>
<p>list of formula of candidates models</p>
</td></tr>
<tr><td><code id="nonadaptivefence_+3A_d">d</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="nonadaptivefence_+3A_lf">lf</code></td>
<td>
<p>measure lack of fit (to minimize)</p>
</td></tr>
<tr><td><code id="nonadaptivefence_+3A_pf">pf</code></td>
<td>
<p>model selection criteria, e.g., model dimension</p>
</td></tr>
<tr><td><code id="nonadaptivefence_+3A_cn">cn</code></td>
<td>
<p>given a specific c value</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>models</code></td>
<td>
<p>list all model candidates in the model space</p>
</td></tr>
<tr><td><code>lack_of_fit</code></td>
<td>
<p>list a vector of Qs for all model candidates</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>list the model of the selected parsimonious model</p>
</td></tr>
<tr><td><code>sel_model</code></td>
<td>
<p>list the selected (parsimonious) model given the adaptive c value</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jiming Jiang  Jianyang Zhao  J. Sunil Rao  Thuan Nguyen
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. Statistics and Probability Letters, 79, 625-629
</p>
</li>
<li><p>Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  Statistical Computation and Simulation, 84(3), 644-662
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(fence)

#### Example 1 #####
data(iris)
full = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width + (1|Species)
test_naf = fence.lmer(full, iris, fence = "nonadaptive", cn = 12)
test_naf$sel_model

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.AF'>Plot Adaptive Fence model selection</h2><span id='topic+plot.AF'></span>

<h3>Description</h3>

<p>Plot Adaptive Fence model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'AF'
plot(x = res, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.AF_+3A_x">x</code></td>
<td>
<p>Object to be plotted</p>
</td></tr>
<tr><td><code id="plot.AF_+3A_...">...</code></td>
<td>
<p>Additional arguments. CNot currently used.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.NF'>Plot Nonparametric Fence model selection</h2><span id='topic+plot.NF'></span>

<h3>Description</h3>

<p>Plot Nonparametric Fence model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'NF'
plot(x = res, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.NF_+3A_x">x</code></td>
<td>
<p>Object to be plotted</p>
</td></tr>
<tr><td><code id="plot.NF_+3A_...">...</code></td>
<td>
<p>Additional arguments. CNot currently used.</p>
</td></tr>
</table>

<hr>
<h2 id='RF'>Adaptive Fence model selection (Restricted Fence)</h2><span id='topic+RF'></span>

<h3>Description</h3>

<p>Adaptive Fence model selection (Restricted Fence)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RF(full, data, groups, B = 100, grid = 101, bandwidth = NA,
  plot = FALSE, method = c("marginal", "conditional"), id = "id",
  cpus = parallel::detectCores())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RF_+3A_full">full</code></td>
<td>
<p>formula of full model</p>
</td></tr>
<tr><td><code id="RF_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="RF_+3A_groups">groups</code></td>
<td>
<p>A list of formulas of (full) model in each bins (groups) of variables</p>
</td></tr>
<tr><td><code id="RF_+3A_b">B</code></td>
<td>
<p>number of bootstrap sample, parametric for lmer</p>
</td></tr>
<tr><td><code id="RF_+3A_grid">grid</code></td>
<td>
<p>grid for c</p>
</td></tr>
<tr><td><code id="RF_+3A_bandwidth">bandwidth</code></td>
<td>
<p>bandwidth for kernel smooth function</p>
</td></tr>
<tr><td><code id="RF_+3A_plot">plot</code></td>
<td>
<p>Plot object</p>
</td></tr>
<tr><td><code id="RF_+3A_method">method</code></td>
<td>
<p>either marginal (GEE) or conditional approach is selected</p>
</td></tr>
<tr><td><code id="RF_+3A_id">id</code></td>
<td>
<p>Subject or cluster id variable</p>
</td></tr>
<tr><td><code id="RF_+3A_cpus">cpus</code></td>
<td>
<p>Number of parallel computers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Jiang et. al (2008), the adaptive c value is chosen from the highest peak in the p* vs. c plot.  
In Jiang et. al (2009), 95% CI is taken into account while choosing such an adaptive choice of c.
In Thuan Nguyen et. al (2014), the adaptive c value is chosen from the first peak. This approach works better in the 
moderate sample size or weak signal situations.  Empirically, the first peak becomes highest peak when sample size 
increases or signals become stronger
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>models</code></td>
<td>
<p>list all model candidates in the model space</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>list the number of bootstrap samples that have been used</p>
</td></tr>
<tr><td><code>lack_of_fit_matrix</code></td>
<td>
<p>list a matrix of Qs for all model candidates (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>Qd_matrix</code></td>
<td>
<p>list a matrix of QM - QM.tilde for all model candidates. Each row is for each bootrap sample</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>list the value of bandwidth</p>
</td></tr>
<tr><td><code>model_mat</code></td>
<td>
<p>list a matrix of selected models at each c values in grid (in columns). Each row is for each bootstrap sample</p>
</td></tr>
<tr><td><code>freq_mat</code></td>
<td>
<p>list a matrix of coverage probabilities (frequency/smooth_frequency) of each selected models for a given c value (index)</p>
</td></tr>
<tr><td><code>c</code></td>
<td>
<p>list the adaptive choice of c value from which the parsimonious model is selected</p>
</td></tr>
<tr><td><code>sel_model</code></td>
<td>
<p>list the selected (parsimonious) model given the adaptive c value</p>
</td></tr>
</table>


<h3>Note</h3>

<p>bandwidth = (cs[2] - cs[1]) * 3. So it's chosen as 3 times grid between two c values.
</p>


<h3>References</h3>


<ul>
<li><p>Jiang J., Rao J.S., Gu Z., Nguyen T. (2008),  Fence Methods for Mixed Model Selection. The Annals of Statistics, 36(4): 1669-1692
</p>
</li>
<li><p>Jiang J., Nguyen T., Rao J.S. (2009), A Simplified Adaptive Fence Procedure. Statistics and Probability Letters, 79, 625-629
</p>
</li>
<li><p>Thuan Nguyen, Jiming Jiang (2012), Restricted fence method for covariate selection in longitudinal data analysis. Biostatistics, 13(2), 303-314
</p>
</li>
<li><p>Thuan Nguyen, Jie Peng, Jiming Jiang (2014), Fence Methods for Backcross Experiments.  Statistical Computation and Simulation, 84(3), 644-662
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
r =1234; set.seed(r)
n = 100; p=15; rho = 0.6
beta = c(1,1,1,0,1,1,0,1,0,0,1,0,0,0,0)  # non-zero beta 1,2,3,V6,V7,V9,V12
id = rep(1:n,each=3)
V.1 = rep(1,n*3)
I.1 = rep(c(1,-1),each=150)
I.2a = rep(c(0,1,-1),n)
I.2b = rep(c(0,-1,1),n)
x = matrix(rnorm(n*3*11), nrow=n*3, ncol=11)
x = cbind(id,V.1,I.1,I.2a,I.2b,x)
R = diag(3)
for(i in 1:3){
 for(j in 1:3){
   R[i,j] = rho^(abs(i-j))
 }
} 
e=as.vector(t(mvrnorm(n, rep(0, 3), R)))  
y = as.vector(x[,-1]%*%beta) + e
data = data.frame(x,y)
raw = "y ~ V.1 + I.1 + I.2a +I.2b"
for (i in 6:16) { raw = paste0(raw, "+V", i)}; full = as.formula(raw)
bin1="y ~ V.1 + I.1 + I.2a +I.2b"
for (i in 6:8) { bin1 = paste0(bin1, "+V", i)}; bin1 = as.formula(bin1)
bin2="y ~ V9"
for (i in 10:16){ bin2 = paste0(bin2, "+V", i)}; bin2 = as.formula(bin2)
# May take longer than 30 min since there are two stages in this RF procedure
obj1.RF = RF(full = full, data = data, groups = list(bin1,bin2), method="conditional")
obj1.RF$sel_model
obj2.RF = RF(full = full, data = data, groups = list(bin1,bin2), B=100, method="marginal")
obj2.RF$sel_model

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.AF'>Summary Adaptive Fence model selection</h2><span id='topic+summary.AF'></span>

<h3>Description</h3>

<p>Summary Adaptive Fence model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'AF'
summary(object = res, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.AF_+3A_object">object</code></td>
<td>
<p>Object to be summarized</p>
</td></tr>
<tr><td><code id="summary.AF_+3A_...">...</code></td>
<td>
<p>addition arguments. Not currently used</p>
</td></tr>
</table>

<hr>
<h2 id='summary.NF'>Summary Nonparametric Fence model selection</h2><span id='topic+summary.NF'></span>

<h3>Description</h3>

<p>Summary Nonparametric Fence model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'NF'
summary(object = res, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.NF_+3A_object">object</code></td>
<td>
<p>Object to be summarized</p>
</td></tr>
<tr><td><code id="summary.NF_+3A_...">...</code></td>
<td>
<p>addition arguments. Not currently used</p>
</td></tr>
</table>

<hr>
<h2 id='X.lmer'>X.lmer</h2><span id='topic+X.lmer'></span>

<h3>Description</h3>

<p>Data used in the example for X.lmer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(X.lmer)
</code></pre>


<h3>Format</h3>

<p>A data frame with 10 variables:</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
