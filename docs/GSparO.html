<!DOCTYPE html><html><head><title>Help for package GSparO</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GSparO}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#demon'><p>The example for GSparO</p></a></li>
<li><a href='#GSparO'><p>Group sparse optimization</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Group Sparse Optimization</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Approaches a group sparse solution of an underdetermined linear system. It implements the proximal gradient algorithm to solve a lower regularization model of group sparse learning. For details, please refer to the paper "Y. Hu, C. Li, K. Meng, J. Qin and X. Yang. Group sparse optimization via l_{p,q} regularization. Journal of Machine Learning Research, to appear, 2017".</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.1)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats,ThreeWay,ggplot2</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-02-20 04:02:36 UTC; Administrator</td>
</tr>
<tr>
<td>Author:</td>
<td>Yaohua Hu [aut, cre, cph],
  Xinlin Hu [trl]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yaohua Hu &lt;mayhhu@szu.edu.cn&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-02-20 08:11:11</td>
</tr>
</table>
<hr>
<h2 id='demon'>The example for GSparO</h2><span id='topic+demon'></span>

<h3>Description</h3>

<p>demon is a function that implements GSparO for an example of least squares regression with A and b being Gaussian ensembles. A figure plotting the true signal and estimation by GSparO is illustrated in Plots, and the errors of least squares regression and obtained solution are printed. Two packages ThreeWay and ggplot2 should be installed for implementing demon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>demon()
</code></pre>


<h3>Details</h3>

<p>Copyright by Dr. Yaohua Hu, College of Mathematics and Statistics, Shenzhen University.
Email: mayhhu@szu.edu.cn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>demon()
</code></pre>

<hr>
<h2 id='GSparO'>Group sparse optimization</h2><span id='topic+GSparO'></span>

<h3>Description</h3>

<p>Group sparse optimization (GSparO) for least squares regression by using the proximal gradient algorithm to solve the L_2,1/2 regularization model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GSparO(A, b, Initial, group, MaxIter, sparsity)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GSparO_+3A_a">A</code></td>
<td>
<p>decoding matrix (matrix of predictors)</p>
</td></tr>
<tr><td><code id="GSparO_+3A_b">b</code></td>
<td>
<p>noised signal (response)</p>
</td></tr>
<tr><td><code id="GSparO_+3A_initial">Initial</code></td>
<td>
<p>an initial point of iteration, recommend to set as a column vector of zeros</p>
</td></tr>
<tr><td><code id="GSparO_+3A_group">group</code></td>
<td>
<p>group information, a column vector consisting of the length of each group</p>
</td></tr>
<tr><td><code id="GSparO_+3A_maxiter">MaxIter</code></td>
<td>
<p>the maximum number of iterations (a stopping criterion), recommend to set as 200</p>
</td></tr>
<tr><td><code id="GSparO_+3A_sparsity">sparsity</code></td>
<td>
<p>a guess of the group sparsity level (the number of nonzero groups)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GSparO is group sparse optimization for least squares regression described in [Hu et al(2017)], in which the proximal gradient algorithm is implemented to solve the L_2,1/2 regularization model. GSparO is an iterative algorithm consisting of a gradient step for the least squares regression and a proximal steps for the L_2,1/2 penalty, which is analytically formulated in this function. Also, GSparO can solve sparse variable selection problem in absence of group structure. In particular, setting group in GSparO be a vector of ones, GSparO is reduced to the iterative half thresholding algorithm introduced in [Xu et al (2012)].
Copyright by Dr. Yaohua Hu, College of Mathematics and Statistics, Shenzhen University.
Email: mayhhu@szu.edu.cn
</p>


<h3>Author(s)</h3>

<p>Yaohua Hu</p>


<h3>References</h3>

<p>Y. Hu, C. Li, K. Meng, J. Qin, and X. Yang (2017). Group sparse optimization via L_p,q regularization. Journal of Machine Learning Research, to appear.
</p>
<p>Z. Xu, X. Chang, F. Xu, and H. Zhang (2012). L_1/2 regularization: A thresholding representation theory and a fast solver. IEEE Transactions on Neural Networks and Learning Systems.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- 256
n &lt;- 1024
sparsity &lt;- 6
gLen &lt;- 16
MaxIter &lt;- 200
gNo &lt;- 1024/gLen
group &lt;- gLen*matrix(1,gNo,1)
A &lt;- matrix(rnorm(m*n,0,1),m,n)
library(ThreeWay)
A &lt;- orth(t(A))
A &lt;- t(A)
gNo1 &lt;- 1:gNo
ActInd &lt;- sample(gNo1,gNo)
Bs &lt;- matrix(0,n,1)
c &lt;- matrix(rnorm(n,0,1),n,1)
for (i in 1:sparsity){
 Bs[((ActInd[i]-1)*gLen+1):(ActInd[i]*gLen)] &lt;- matrix(1,gLen,1)}
c &lt;- Bs*c
sigma &lt;- 1e-3
b &lt;- A%*%c + sigma*matrix(runif(m,min=0,max=1),m,1)
Initial &lt;- matrix(0,n,1)
GSparO(A,b,Initial,group,MaxIter,sparsity)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
