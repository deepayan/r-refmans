<!DOCTYPE html><html><head><title>Help for package WebAnalytics</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {WebAnalytics}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calculatePercentiles'><p>calculate quantile values from a column.</p></a></li>
<li><a href='#configFilesDirectoryNameGet'><p>get the path of the temporary directory used for storing work files</p></a></li>
<li><a href='#configVariablesLoad'><p>Read a configuration file and store the variables</p></a></li>
<li><a href='#laTeXEscapeString'><p>Escapes a string to enable it to be embedded in a LaTeX document</p></a></li>
<li><a href='#laTexFilePercentileComparisonsWrite'><p>Write percentile count comparison table</p></a></li>
<li><a href='#laTeXParagraphWrite'><p>Writes a LaTex paragraph on stdout</p></a></li>
<li><a href='#logFileFieldsGetIIS'><p>Get field names from an IIS log file</p></a></li>
<li><a href='#logFileListRead'><p>Given a list of file names, read them as log files</p></a></li>
<li><a href='#logFileNamesGet'><p>Base function for retrieval of file names from a base directory and a list of data directories</p></a></li>
<li><a href='#logFileNamesGetAll'><p>Get the list of file names matching a regex (default picks .log files) from a list of log directories</p></a></li>
<li><a href='#logFileNamesGetLast'><p>Get lexically last file names from a list of log directories.</p></a></li>
<li><a href='#logFileNamesGetLastMatching'><p>Get lexically last file names from a list of log directories, checking that the file names are the same in all directories.</p></a></li>
<li><a href='#logFileRead'><p>Given a list of file names, read them as log files</p></a></li>
<li><a href='#pdfGenerate'><p>Generate a PDF using the R API for TinyTeX</p></a></li>
<li><a href='#percentileBaselinePrint'><p>Print a LaTeX table comparing current and baseline values and return a bar graph of the same data</p></a></li>
<li><a href='#plotByRate'><p>Generates a plot that compares how percentile values in a metric of interest vary as an underlying rate metric changes.</p></a></li>
<li><a href='#plotDataRateImpactOnResponse'><p>Get list of latest files from log directories</p></a></li>
<li><a href='#plotDataRateImpactOnStaticResponse'><p>Plot static object response time against aggregate data rate</p></a></li>
<li><a href='#plotErrorRateByHour'><p>Plots rates of HTTP response code groups by hour</p></a></li>
<li><a href='#plotFrequencyHistogram'><p>Plot histogram of response times for a transaction dataframe</p></a></li>
<li><a href='#plotFrequencyHistogramOutlierCutoff'><p>Plot frequencies of elapsed times up to a percentile cutoff</p></a></li>
<li><a href='#plotParallelismRateImpactOnResponse'><p>Plot response time against degree of parallelism</p></a></li>
<li><a href='#plotResponseTimeScatter'><p>Generates a scatter plot of response times</p></a></li>
<li><a href='#plotSave'><p>Save a plot to a file with a generated name</p></a></li>
<li><a href='#plotTransactionRateImpactOnDynamicContentResponse'><p>Generate a plot of mean transaction rate by interval against dynamic content response</p></a></li>
<li><a href='#plotWriteFilenameToLaTexFile'><p>Write an includegraphic element to the generated LaTeX file</p></a></li>
<li><a href='#printPercentiles'><p>calculate quantile values from a column and print as an xtable vertically</p></a></li>
<li><a href='#summaryTxDataFrameCreate'><p>Creates a dataframe containing summary URL performance metrics</p></a></li>
<li><a href='#summaryTxTablePrint'><p>Prints a transaction summary table generated by summaryTxDataFrameCreate</p></a></li>
<li><a href='#WebAnalytics-package'>
<p>Tools for web server log performance reporting</p></a></li>
<li><a href='#workingDirectoryPopulate'><p>Create  files in the working directory to be used for report generation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Web Server Log Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.12</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-04</td>
</tr>
<tr>
<td>Author:</td>
<td>Greg Hunt [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Greg Hunt &lt;greg@firmansyah.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides Apache and IIS log analytics for transaction performance, client populations and workload definitions.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0), utils, ggplot2 (&ge; 3.3.5), xtable (&ge; 1.8.4),
data.table(&ge; 1.14.2), scales (&ge; 1.1.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>brew (&ge; 1.0-6), fs (&ge; 1.5.2), reshape2 (&ge; 1.4.4), digest
(&ge; 0.6.29), tinytex (&ge; 0.37), uaparserjs (&ge; 0.3.5)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>whoami (&ge; 1.3.0), testthat (&ge; 3.1)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/gregfrog/WebAnalytics">https://github.com/gregfrog/WebAnalytics</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-04 11:19:09 UTC; greg</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-04 12:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='calculatePercentiles'>calculate quantile values from a column.  
</h2><span id='topic+calculatePercentiles'></span>

<h3>Description</h3>

<p>Calculate quantile values for a supplied numeric list.  This is a wrapper around the R quantile function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculatePercentiles(column, 
  percentileList=c(0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 1)) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculatePercentiles_+3A_column">column</code></td>
<td>

<p>a vector of numeric values.  The values will be rounded to two decimal places before calculation.  
</p>
</td></tr>
<tr><td><code id="calculatePercentiles_+3A_percentilelist">percentileList</code></td>
<td>

<p>a list of the quantile values that are to be calculated (as decimal values in the range 0 to 1)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of the quantile calculated by quantile.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataValues = c(1,1,1,2,3,4,5,6,7,8,9,10,10,10,10)
calculatePercentiles(dataValues, percentileList=c(0.5))
calculatePercentiles(dataValues)
</code></pre>

<hr>
<h2 id='configFilesDirectoryNameGet'>get the path of the temporary directory used for storing work files </h2><span id='topic+configFilesDirectoryNameGet'></span>

<h3>Description</h3>

<p>This directory may be an absolute or relative path and ends with a / character
</p>


<h3>Usage</h3>

<pre><code class='language-R'>configFilesDirectoryNameGet()
</code></pre>


<h3>Value</h3>

<p>Returns a string that is the path of the work directory 
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>configFilesDirectoryNameGet()
</code></pre>

<hr>
<h2 id='configVariablesLoad'>Read a configuration file and store the variables
</h2><span id='topic+configVariablesLoad'></span><span id='topic+configVariableGet'></span><span id='topic+configVariableIs'></span><span id='topic+configVariablesAll'></span><span id='topic+configVariableSet'></span><span id='topic+sample.config'></span>

<h3>Description</h3>

<p>These are functions to read, validate and execute a report configuration file placing its output as a series of variables in a hidden scope; they also access and check existence of the variables.  Variables whose names begin 'config.' will be printed at load time along with their values.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>configVariablesLoad(fileName="report.config")
configVariableGet(name)
configVariableIs(name)
configVariablesAll()
configVariableSet(name, value)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="configVariablesLoad_+3A_filename">fileName</code></td>
<td>

<p>The name of the configuration file
</p>
</td></tr>
<tr><td><code id="configVariablesLoad_+3A_name">name</code></td>
<td>

<p>The name of a variable from the config file. 
</p>
</td></tr>
<tr><td><code id="configVariablesLoad_+3A_value">value</code></td>
<td>

<p>The value to be assigned to the config variable name.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The configuration file is an R script that is intended to be used to define the variables and helper functions that control the supplied sample report script.  The config file may be executed more than once as part of validating its content.  
</p>
<p>String values in the config file should be quoted using double quote characters. Lists of values are written using the R <code>c()</code> function, for example <code>c("a","b")</code> 
</p>
<p>Switches controlling behaviour 
</p>

<dl>
<dt><code>config.projectName</code></dt><dd>
<p>The Project name for the cover page of the document.  This is also printed on the internal page headers.
</p>
 
<ul>
<li><p> Required
</p>
</li>
<li><p> No Default Value
</p>
</li></ul>

</dd>
<dt><code>config.documentName</code></dt><dd>
<p>The name to be printed on the document cover page.
</p>
 
<ul>
<li><p> Required
</p>
</li>
<li><p> No Default value
</p>
</li></ul>

</dd>
<dt><code>config.current.dataDir</code></dt><dd>
<p>Data is assumed to be stored in a directory hierarchy, with a root directory and a series of child directories corresponding with the individual web servers, this variable specifies the root directory of that hierarchy.  For example a directory structure might be a series of server specific logs under <code>/var/logs/apache</code>, with the individual servers' logs being located in <code>/var/logs/apache/server1</code>, <code>/var/logs/apache/server2</code> and <code>/var/logs/apache/server3</code>.  the data dir in this case is <code>/var/logs/apache</code> with the <code>config.current.dirNames</code> being specified as <code>c("server1", "server2", "server3")</code>.
</p>
 
<ul>
<li><p> Required
</p>
</li>
<li><p> No Default Value
</p>
</li></ul>

</dd>
<dt><code>config.current.dirNames</code></dt><dd>
<p>This is the list of child directory paths, often corresponding with a list of server names, it must be a concatenation of strings, for example <code>c("PRODMAW1","PRODMAW2")</code>.  
Multiple directory names can be coded here: <code>c("PRODMAW1/app1","PRODMAW2/app1")</code>.
</p>
 
<ul>
<li><p> Required
</p>
</li>
<li><p> No Default Value
</p>
</li></ul>

</dd>
<dt><code>config.current.columnList</code></dt><dd>
<p>The list of column names in the log file, for example 
</p>
<p><code>c("Apache", "elapsedus", "jsessionid")</code>.  
</p>
<p>See <code><a href="#topic+logFileRead">logFileRead</a></code> for the list of valid column names.  The name <code>Apache</code> is an abbreviation for the Apache common log format: 
</p>
<p><code>c("userip", "ignored column 1", "username", "ApacheTimestamp", "url", "httpcode", "responsebytes")</code>
</p>

<ul>
<li><p> Required 
</p>
</li>
<li><p> No Default Value
</p>
</li></ul>

</dd>
<dt><code>config.readBaseline</code></dt><dd> 
<p>Read a baseline log to be compared with current behaviour. Valid values are either <code>TRUE</code> or <code>FALSE</code>. 
</p>

<ul>
<li><p> Optional 
</p>
</li>
<li><p> Default value: <code>FALSE</code>
</p>
</li></ul>

</dd>
<dt><code>config.baseline.dataDir</code></dt><dd>
<p>The root directory for the baseline data files 
</p>

<ul>
<li><p> Must be supplied if <code>config.readBaseline=TRUE</code> 
</p>
</li>
<li><p> No Default Value
</p>
</li></ul>

</dd>
<dt><code>config.baseline.dirNames</code></dt><dd> 
<p>The list of baseline log server-specific directories, usually a list of server names, it must be a concatenation of strings, for example <code>c("PRODMAW1","PRODMAW2")</code> 
</p>

<ul>
<li><p> Must be specified if <code>config.readBaseline=TRUE</code> 
</p>
</li>
<li><p> No Default Value, 
</p>
</li></ul>

</dd>
<dt><code>config.baseline.columnList</code></dt><dd>
<p>The list of columns to be read.  It is the baseline version of 
</p>
<p><code>config.current.columnList</code> 
</p>

<ul>
<li><p> Must be specified if <code>config.readBaseline=TRUE</code>
</p>
</li>
<li><p> No Default Value
</p>
</li></ul>

</dd>
<dt><code>config.generateGraphForTimeOver</code></dt><dd>
<p>Response time graphs and histograms are generated for URLs whose maximum elapsed time exceeds this number of milliseconds 
</p>

<ul>
<li><p> Optional 
</p>
</li>
<li><p> Default Value: 10000
</p>
</li></ul>

</dd>
<dt><code>config.generateServerSessionStats</code></dt><dd>
<p>Generate histograms and counts of requests by server.  These are only generated if <code>jsessionid</code> is also one of the column names in the current data 
</p>

<ul>
<li><p> Optional 
</p>
</li>
<li><p> Default Value: <code>TRUE</code>
</p>
</li></ul>

</dd>
<dt><code>config.generatePercentileRankings</code></dt><dd>
<p>Generate tables that compare frequencies and total elapsed times of URLs in the baseline and current data.  Intended to be used for calibrating performance test workloads 
</p>

<ul>
<li><p> Optional 
</p>
</li>
<li><p> Default Value: <code>FALSE</code>
</p>
</li></ul>

</dd>
<dt><code>config.fix.data</code></dt><dd>
<p>An R function definition that is used to adjust the data read from the log files.  This is provided in the sample report configuration file.  The function must categorise records using the literals <code>"Static Content Requests"</code> and <code>"Monitoring"</code>.  The function supplied in the sample.config file created by <code><a href="#topic+workingDirectoryPopulate">workingDirectoryPopulate</a></code> is a good starting point and can be used to subset or correct the log data as it is read to focus on a smaller subset of records.   
</p>

<ul>
<li><p> Optional 
</p>
</li>
<li><p> No Default Value 
</p>
</li></ul>

</dd>
<dt><code>config.fix.current.data</code></dt><dd>
<p>The function to be used to adjust baseline data if different cleaning functions are to be applied to current and baseline data 
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> No Default Value
</p>
</li></ul>

</dd>
<dt><code>config.fix.baseline.data</code></dt><dd>
<p>The function to use if different functions are to be applied to current and baseline data
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default value: <code>config.fix.current.data</code>
</p>
</li></ul>

</dd>
<dt><code>config.tempdir</code></dt><dd>
<p>The name of the temp dir to be used for storage of generated graphics.
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default Value: ./txdata/
</p>
</li></ul>

</dd>
<dt><code>config.useragent.generateFrequencies</code></dt><dd>
<p>Generate the User Agent Frequency Section of the report.  Setting this to FALSE suppresses the report, which in any case is only produced if the current dataset contains user agent strings.   
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default Value: TRUE
</p>
</li></ul>

</dd>
<dt><code>config.useragent.minimumPercentage</code></dt><dd>
<p>The minimum percentage that a User Agent family or version must represent to be considered.   
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default Value: 2
</p>
</li></ul>

</dd>
<dt><code>config.useragent.maximumPercentile</code></dt><dd>
<p>The maximum cumulative percentile to report.  The last few percent is made up of very low frequency of occurrence 
User agents that are not feasible (or in many cases possible) to test.  
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default Value: 96
</p>
</li></ul>

</dd>
<dt><code>config.useragent.discardOther</code></dt><dd>
<p>Discard browser family &quot;Other&quot; records.  These are typically monitoring or heartbeat sources whose frequencies distort 
the percentile calculations.  
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default Value: TRUE
</p>
</li></ul>

</dd>
<dt><code>config.author</code></dt><dd>
<p>Name of the author of the report.  Displayed on the default first page and in the page footer.   
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default Value: Author
</p>
</li></ul>

</dd>
<dt><code>config.securityClass</code></dt><dd>
<p>The security classification of the document.  Displayed on the default first page and in the page footer.
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default Value: Commercial-In-Confidence
</p>
</li></ul>

</dd>
<dt><code>config.longurls.threshold</code></dt><dd>
<p>The length in characters of a URL above which the URL text is replaced by a placeholder and the URL content is logged. Increasing this number will allow processing of longer URL text, but can lead to problems in LaTeX's processing the file. 
</p>

<ul>
<li><p> Optional
</p>
</li>
<li><p> Default Value: 1000
</p>
</li></ul>

</dd>
</dl>



<h3>Value</h3>

<p>configVariableIs returns a boolean to indicate existence of a named variable
configVariableGet returns the value of the variable
configVariableAll returns a list of all variables
configVariableSet does not return a value
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+workingDirectoryPopulate">workingDirectoryPopulate</a></code>
<code><a href="#topic+logFileRead">logFileRead</a></code>
<code><a href="#topic+logFileListRead">logFileListRead</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
configVariablesLoad(fileName=paste0(tempdir(),"/xx/sample.config"))
if(configVariableIs("config.documentName"))
{
  print(configVariableGet("config.documentName"))
}
allvars = configVariablesAll()

</code></pre>

<hr>
<h2 id='laTeXEscapeString'>Escapes a string to enable it to be embedded in a LaTeX document
</h2><span id='topic+laTeXEscapeString'></span>

<h3>Description</h3>

<p>The string parameter is an R string that will have a regex applied to it so backslashes will need to be escaped before calling this.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>laTeXEscapeString(nameString)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="laTeXEscapeString_+3A_namestring">nameString</code></td>
<td>

<p>The string to have escapes applied.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the escaped string
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>laTeXEscapeString("a$b")
</code></pre>

<hr>
<h2 id='laTexFilePercentileComparisonsWrite'>Write percentile count comparison table  
</h2><span id='topic+laTexFilePercentileComparisonsWrite'></span>

<h3>Description</h3>

<p>Writes a LaTeX table listing URLs in decreasing order of request count for a baseline workload compared with a current workload on stdout for incorporation in a LaTeX report
</p>


<h3>Usage</h3>

<pre><code class='language-R'>laTexFilePercentileComparisonsWrite(latest, 
          baseline, 
          headingLaTeX="\\section{Transaction Count Percentile Ranking}")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="laTexFilePercentileComparisonsWrite_+3A_latest">latest</code></td>
<td>

<p>data frame of log records for the latest (test) workload
</p>
</td></tr>
<tr><td><code id="laTexFilePercentileComparisonsWrite_+3A_baseline">baseline</code></td>
<td>

<p>data frame of log records for the baseline workload
</p>
</td></tr>
<tr><td><code id="laTexFilePercentileComparisonsWrite_+3A_headinglatex">headingLaTeX</code></td>
<td>

<p>LaTeX section heading for this table
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Does not return a value.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

laTexFilePercentileComparisonsWrite(logdf, 
                logdf)
</code></pre>

<hr>
<h2 id='laTeXParagraphWrite'>Writes a LaTex paragraph on stdout
</h2><span id='topic+laTeXParagraphWrite'></span>

<h3>Description</h3>

<p>A convenience function to write a paragraph (with optional text) on stdout.  This is useful in code blocks in Brew files, for example between 
graphics.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>laTeXParagraphWrite(string="")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="laTeXParagraphWrite_+3A_string">string</code></td>
<td>

<p>Text to be inserted into the paragraph
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Does not return any value
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>laTeXParagraphWrite()
laTeXParagraphWrite("blah blah")
</code></pre>

<hr>
<h2 id='logFileFieldsGetIIS'>Get field names from an IIS log file</h2><span id='topic+logFileFieldsGetIIS'></span>

<h3>Description</h3>

<p>Retrieves and validates the log fields from an IIS Log file.  An IIS log file contains one or more comments records (leading hash) that identify the software that produced the log and the fields that were written.  There may be multiple fields records, the code does not attempt to handle the case where different fields are written in different parts of the log.  The MS names are mapped to the names used by this package. 
</p>
<p>Fields that the package does not use have names which begin with 'ignored: ' and these are dropped when the file is read.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logFileFieldsGetIIS(fileName)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logFileFieldsGetIIS_+3A_filename">fileName</code></td>
<td>

<p>name of the file to be examined
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of field names mapped to the   
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>logFileFieldsGetIIS(system.file("extdata", "compressed.log", package = "WebAnalytics"))
</code></pre>

<hr>
<h2 id='logFileListRead'>Given a list of file names, read them as log files
</h2><span id='topic+logFileListRead'></span>

<h3>Description</h3>

<p>This function calls logFileRead to read the individual log files.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logFileListRead(fileNameList, readFunction=logFileRead, columnList=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logFileListRead_+3A_filenamelist">fileNameList</code></td>
<td>

<p>A list of character file names 
</p>
</td></tr>
<tr><td><code id="logFileListRead_+3A_readfunction">readFunction</code></td>
<td>

<p>This function is called to read the file name.  
</p>
</td></tr>
<tr><td><code id="logFileListRead_+3A_columnlist">columnList</code></td>
<td>

<p>The columnList is a list of predefined column names.  See <code><a href="#topic+logFileRead">logFileRead</a></code> for the list of valid values. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe that is the concatenation (rbind) of the read log files.  
If the default read function is used the data frame will contain the standard column set required by the other functions in this package.
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

fileNameList = logFileNamesGetAll(dataDirectory=datd)

logdf = logFileListRead(fileNameList, 
          readFunction=logFileRead, 
          columnList=logFileFieldsGetIIS(fileNameList[[1]]))
</code></pre>

<hr>
<h2 id='logFileNamesGet'>Base function for retrieval of file names from a base directory and a list of data directories
</h2><span id='topic+logFileNamesGet'></span>

<h3>Description</h3>

<p>The function searches in a list of log file directories for log file names and returns a list of names found.  A typical 
directory topology for log access is to have a number of per-server directories mounted or mapped under some common root
and this function's parameters reflect that.  
</p>
<p>Switches are provided to return all or only the lexically last file names in each directory.  Returning the lexically last file name works where a report is scheduled to be run late in a day so it will pick up the current day's file - this works for IIS logs and for typical Apache log rotation schemes. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logFileNamesGet(dataDirectory = getwd(), 
            directoryNames=c("."), 
            fileNamePattern=".*[.]log", 
            allNamesMustMatch = TRUE,
            getLastFileName = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logFileNamesGet_+3A_datadirectory">dataDirectory</code></td>
<td>

<p>a string containing the root directory under which the log file directories are found
</p>
</td></tr>
<tr><td><code id="logFileNamesGet_+3A_directorynames">directoryNames</code></td>
<td>

<p>a list of directory names that is concatenated with the data directory name.  
This is intended to support the structure where logs are collected into a series of per-server log directories.  
</p>
</td></tr>
<tr><td><code id="logFileNamesGet_+3A_filenamepattern">fileNamePattern</code></td>
<td>

<p>a string containing a regular expression for the log file names that are to be processed
</p>
</td></tr>
<tr><td><code id="logFileNamesGet_+3A_allnamesmustmatch">allNamesMustMatch</code></td>
<td>

<p>when processing files named for the period that they contain (for example a date in a typical IIS log file name) this ensures that 
the same log data period is processed from each log file directory. This does not guarantee that the content of the log files are complete, it just ensures that 
the log was written for the period. This check is only applicable when getLastFileName is true.  If there are a number of files returned,
there could be gaps in logging on one or more servers or servers may have failed over, so it does not make sense to check that the sets of
logs from each directory are the same.  
</p>
</td></tr>
<tr><td><code id="logFileNamesGet_+3A_getlastfilename">getLastFileName</code></td>
<td>

<p>Returns the lexically last file name from each data directory.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of character string file names.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>datd = dirname(system.file("extdata", "compressed.log", package = "WebAnalytics"))
logFileNamesGet(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log", allNamesMustMatch=FALSE)
</code></pre>

<hr>
<h2 id='logFileNamesGetAll'>Get the list of file names matching a regex (default picks .log files) from a list of log directories
</h2><span id='topic+logFileNamesGetAll'></span>

<h3>Description</h3>

<p>The function returns a list of names found in a list of directories.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logFileNamesGetAll(dataDirectory = getwd(), 
  directoryNames=c("."), 
  fileNamePattern=".*[.]log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logFileNamesGetAll_+3A_datadirectory">dataDirectory</code></td>
<td>

<p>a string containing the root directory under which the log file directories are found
</p>
</td></tr>
<tr><td><code id="logFileNamesGetAll_+3A_directorynames">directoryNames</code></td>
<td>

<p>a list of directory names that is concatenated with the data directory name.  
This is intended to support the structure where logs are collected into a series of per-server log directories.  
</p>
</td></tr>
<tr><td><code id="logFileNamesGetAll_+3A_filenamepattern">fileNamePattern</code></td>
<td>

<p>a string containing a regular expression for the log file names that are to be processed
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of character string file names.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>datd = dirname(system.file("extdata", "compressed.log", package = "WebAnalytics"))
logFileNamesGetAll(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")
</code></pre>

<hr>
<h2 id='logFileNamesGetLast'>Get lexically last file names from a list of log directories.  
</h2><span id='topic+logFileNamesGetLast'></span>

<h3>Description</h3>

<p>The function searches in a list of log file directories for log file names and returns a list of names found (the last name in each directory). 
This function does not check that the found file names are all the same from each directory.
This is intended to be used to locate the most recent day's log file for reporting.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logFileNamesGetLast(dataDirectory = getwd(), 
  directoryNames=c("."), 
  fileNamePattern=".*[.]log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logFileNamesGetLast_+3A_datadirectory">dataDirectory</code></td>
<td>

<p>a string containing the root directory under which the log file directories are found
</p>
</td></tr>
<tr><td><code id="logFileNamesGetLast_+3A_directorynames">directoryNames</code></td>
<td>

<p>a list of directory names that is concatenated with the data directory name.  
This is intended to support the structure where logs are collected into a series of per-server log directories.  
</p>
</td></tr>
<tr><td><code id="logFileNamesGetLast_+3A_filenamepattern">fileNamePattern</code></td>
<td>

<p>a string containing a regular expression for the log file names that are to be processed
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of character string file names.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>datd = dirname(system.file("extdata", "compressed.log", package = "WebAnalytics"))
logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")
</code></pre>

<hr>
<h2 id='logFileNamesGetLastMatching'>Get lexically last file names from a list of log directories, checking that the file names are the same in all directories.
</h2><span id='topic+logFileNamesGetLastMatching'></span>

<h3>Description</h3>

<p>The function searches in a list of log file directories for log file names and returns a list of names found (the last name in each directory).  
This is intended to be used to locate the most recent day's log file for reporting.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logFileNamesGetLastMatching(dataDirectory = getwd(), 
  directoryNames=c("."), 
  fileNamePattern=".*[.]log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logFileNamesGetLastMatching_+3A_datadirectory">dataDirectory</code></td>
<td>

<p>a string containing the root directory under which the log file directories are found
</p>
</td></tr>
<tr><td><code id="logFileNamesGetLastMatching_+3A_directorynames">directoryNames</code></td>
<td>

<p>a list of directory names that is concatenated with the data directory name.  
This is intended to support the structure where logs are collected into a series of per-server log directories.  
</p>
</td></tr>
<tr><td><code id="logFileNamesGetLastMatching_+3A_filenamepattern">fileNamePattern</code></td>
<td>

<p>a string containing a regular expression for the log file names that are to be processed
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of character string file names.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>datd = dirname(system.file("extdata", "compressed.log", package = "WebAnalytics"))
logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")
</code></pre>

<hr>
<h2 id='logFileRead'>Given a list of file names, read them as log files
</h2><span id='topic+logFileRead'></span>

<h3>Description</h3>

<p>This function reads a file, parsing it for the fields specified, and normalises the values that have been read.    
</p>
<p>The log file is assumed to be space delimited, which is the case for Apache and IIS.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logFileRead(fileName, 
  columnList=c("MSTimestamp", "clientip", "url", "httpcode", "elapsed"), 
  logTimeZone = "", 
  timeFormat = "") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logFileRead_+3A_filename">fileName</code></td>
<td>

<p>The name, including path, of the file to read
</p>
</td></tr>
<tr><td><code id="logFileRead_+3A_columnlist">columnList</code></td>
<td>

<p>The columns in the file, in order.  Columns are:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>ApacheTimestamp</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Apache log format timestamp </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>MSTimestamp</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> IIS log format timestamp </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>servername</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Name of the web server </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>serverip</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> IP of the server </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>httpop</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> HTTP verb </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>url</code> </td><td style="text-align: left;"> Required </td><td style="text-align: left;"> Path part of the request </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>parms</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Query string </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>port</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> TCP/IP port that the request arrived on </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>username</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> User name logged by the web server </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>userip</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> IP that the request was seen to originate from. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>useragent</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> User agent string in the request </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>httpcode</code> </td><td style="text-align: left;"> Required </td><td style="text-align: left;"> HTTP response code </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>windowscode</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Windows return code recorded by IIS </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>windowssubcode</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Windows sub code recorded by IIS </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>responsebytes</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Number of bytes in the HTTP response </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>requestbytes</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Number of bytes in the HTTP request </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>elapsedms</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Request elapsed time in milliseconds </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>elapsedus</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Request elapsed time in microseconds (will be rounded to milliseconds)</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>elapseds</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Request elapsed time in seconds (not recommended, will be expanded to milliseconds) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>jsessionid</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> User session identifier </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ignore*</code> </td><td style="text-align: left;"> Optional </td><td style="text-align: left;"> Columns with names starting with 'ignore' are dropped  
</td>
</tr>

</table>

<p>One timestamp and one elapsed time column name must be specified.  
</p>
<p>The Apache URL is handled partly in the fix data procedure in the config file because it wraps the operation and URL path in one field.  The IIS URL does not need this additional parsing. 
</p>
</td></tr>
<tr><td><code id="logFileRead_+3A_logtimezone">logTimeZone</code></td>
<td>

<p>The timezone to use to adjust the timestamps in the log.  This is used primarily for IIS logs where the log may be either UTC or local time.  
</p>
</td></tr>
<tr><td><code id="logFileRead_+3A_timeformat">timeFormat</code></td>
<td>

<p>If the timestamp in the log is not in the default for IIS or Apache this can be used to override the timestamp parsing.  The format is the r strptime format.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe that contains the contents of the file.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")
</code></pre>

<hr>
<h2 id='pdfGenerate'>Generate a PDF using the R API for TinyTeX  
</h2><span id='topic+pdfGenerate'></span>

<h3>Description</h3>

<p>This function calls <a href="https://CRAN.R-project.org/package=brew"><span class="pkg">brew</span></a> to generate a TeX document and then calls the TinyTeX API to generate a PDF from the LaTeX document in the specified work directory.  
</p>
<p>The function does not attempt to install TinyTex itself, this must be done by the user calling the <code>tinytex::install_tinytex()</code> function. The first time that this function is called to generate a report, provided that TinyTeX is has been installed with default settings, it will install the required LaTeX packages for the report.  This may take some time.
</p>
<p>Tinytex has been observed to run glacially slowly on Windows.  For some users it may be preferable (and far quicker) to install some version of xelatex and run it with it set to automatically download packages.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfGenerate(configFile, templateFile="sampleRfile.R", workDir=".") 
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="pdfGenerate_+3A_configfile">configFile</code></td>
<td>

<p>The name of the config file to use.  If this parameter is omitted, the work directory is searched for a file whose name ends, case insensitively, in <code>.config</code>.  If there is only one file with the extnsion <code>.config</code> it is used.  If there is no config file or multiple config files an error is signalled.  The leading part of the config file name, before <code>.config</code>, is used as the prefix for the gemerated PDF name</p>
</td></tr>
<tr><td><code id="pdfGenerate_+3A_templatefile">templateFile</code></td>
<td>

<p>This defaults to <code>sampleRfile.R</code> which is the default name of the template.
</p>
</td></tr>
<tr><td><code id="pdfGenerate_+3A_workdir">workDir</code></td>
<td>

<p>The directory to use for document generation.  This directory must contain the template and any associated support files, such as the LaTeX document class. <code><a href="#topic+workingDirectoryPopulate">workingDirectoryPopulate</a></code> will populate this directory correctly and create a temporary files directory under it.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the name of the generated PDF.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
filesDir =  paste0(tempdir(),"/ex")
wkDir = paste0(tempdir(),"/ey")
configVariableSet("config.workdir", filesDir)
# setup the work directory 
workingDirectoryPopulate(wkDir)

pdfGenerate(workDir=wkDir) 


## End(Not run)


</code></pre>

<hr>
<h2 id='percentileBaselinePrint'>Print a LaTeX table comparing current and baseline values and return a bar graph of the same data 
</h2><span id='topic+percentileBaselinePrint'></span>

<h3>Description</h3>

<p>Calculate quantile values for a supplied numeric list.  This is a wrapper around the R quantile function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentileBaselinePrint(column, 
        baselineColumn, 
        columnNames = c("Delta", "Current", "Baseline", "Percentile")) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="percentileBaselinePrint_+3A_column">column</code></td>
<td>

<p>a vector of numeric values from the current dataset  The values will be rounded to two decimal places before calculation.  
</p>
</td></tr>
<tr><td><code id="percentileBaselinePrint_+3A_baselinecolumn">baselineColumn</code></td>
<td>

<p>a vector of numeric values from the baseline data.  The values will be rounded to two decimal places before calculation.  
</p>
</td></tr>
<tr><td><code id="percentileBaselinePrint_+3A_columnnames">columnNames</code></td>
<td>

<p>names of the columns in the table that is printed by this function.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot graph of the data.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

fileNameList = logFileNamesGetAll(dataDirectory=datd)

logdf = logFileListRead(fileNameList, 
          readFunction=logFileRead, 
          columnList=logFileFieldsGetIIS(fileNameList[[1]]))

logbasedf = logFileListRead(fileNameList, 
          readFunction=logFileRead, 
          columnList=logFileFieldsGetIIS(fileNameList[[1]]))
plotWriteFilenameToLaTexFile(
  plotSaveGG(
    percentileBaselinePrint(logdf$elapsed, 
              logbasedf$elapsed, 
              columnNames = c("Delta", "Current", "Baseline", "Percentile"))
    , "xxx")
    )


</code></pre>

<hr>
<h2 id='plotByRate'>Generates a plot that compares how percentile values in a metric of interest vary as an underlying rate metric changes.  </h2><span id='topic+plotByRate'></span>

<h3>Description</h3>

<p>Data is supplied as separate columns for time, data, base rate, 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotByRate(timecol, 
      datacol, 
      baseratecol, 
      percentile, 
      breaksString, 
      baseratetimes = timecol, 
      xlab = "Rate", 
      ylab="Variation from overall 95th percentile", 
      title="", 
      baseTimeCol = NULL, 
      baseDataCol=NULL, 
      baseBaseRateCol = NULL, 
      outlierPercentile=NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotByRate_+3A_timecol">timecol</code></td>
<td>

<p>the timestamps for the data column 
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_datacol">datacol</code></td>
<td>

<p>the data to be compared with the rate column (y axis)
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_baseratecol">baseratecol</code></td>
<td>

<p>the underlying rate (x axis on the plot), as a list of counts (setting a dataframe column to 1 works for a web server log dataframe).  The rate is calculated over the <code>breaksString</code> interval, meaning that if you want to aggregate over a ten minute interval and report an indicative per-second rate the counts in this column must be scaled by dividing them by 600, the number of seconds in ten minutes.  
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_percentile">percentile</code></td>
<td>

<p>the percentile value that the values are calculated at, the percentiles are calculated for each <code>breaksString</code> interval and converted to differences from the value of the percentile calculated over the whole period.   
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_breaksstring">breaksString</code></td>
<td>

<p>the time interval used for calculation of percentile values, it is supplied to the <code><a href="base.html#topic+cut">cut</a></code> function to group the data values.
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_baseratetimes">baseratetimes</code></td>
<td>

<p>the timestamps for the base data if they are not the same as the timestamps for the data column (defaults to the data column timestamps).  The two sets of timestamps must correspond in some way and the extent to which they do not align must be accounted for in the breaks interval, for example a few seconds or minutes difference would not be an issue for an aggregation interval of an hour, but would be a problem if aggregation is being done by minute or second
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_xlab">xlab</code></td>
<td>

<p>label for the rate metric
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_ylab">ylab</code></td>
<td>

<p>label for the data metric
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_title">title</code></td>
<td>

<p>the plot title	
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_basetimecol">baseTimeCol</code></td>
<td>

<p>Use this parameteter and the associated <code>baseDataCol</code> as an alternative time base and data to summarise the data.
</p>
</td></tr> 
<tr><td><code id="plotByRate_+3A_basedatacol">baseDataCol</code></td>
<td>

<p>Data values associated with the rate column above.  
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_basebaseratecol">baseBaseRateCol</code></td>
<td>

<p>Rate column for the prevoious two columns.   
</p>
</td></tr>
<tr><td><code id="plotByRate_+3A_outlierpercentile">outlierPercentile</code></td>
<td>

<p>discard data above this percentile
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an R base graphics plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSave">plotSave</a></code>
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cut">cut</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")
           
logdf$numrequestsinthisrecord = 1

plotByRate(logdf$ts, 
      logdf$elapsed, 
      logdf$numrequestsinthisrecord, 
      0.95, 
      "10 mins", 
      xlab="request rate (10 minutes)",
      ylab="variance from overall 95th percentile response time (milliseconds)")

</code></pre>

<hr>
<h2 id='plotDataRateImpactOnResponse'>Get list of latest files from log directories
</h2><span id='topic+plotDataRateImpactOnResponse'></span>

<h3>Description</h3>

<p>Generates a plot of 95th percentile response time for a specified combination of transaction and response status against 
aggregate data rate, for ten minute intervals in the dataframe provided.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDataRateImpactOnResponse(dataFrame, filterURL, status) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDataRateImpactOnResponse_+3A_dataframe">dataFrame</code></td>
<td>

<p>a transaction data frame  
</p>
</td></tr>
<tr><td><code id="plotDataRateImpactOnResponse_+3A_filterurl">filterURL</code></td>
<td>

<p>the URL to be examined
</p>
</td></tr>
<tr><td><code id="plotDataRateImpactOnResponse_+3A_status">status</code></td>
<td>

<p>the status of the request: 'Success', 'Redirect', 'Client Error' or 'Server Error'
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an R base graphics plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSave">plotSave</a></code>
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")
plotDataRateImpactOnResponse(logdf, "/QWERTYTest/XRMServices/2011/Organization.svc", "Success") 

</code></pre>

<hr>
<h2 id='plotDataRateImpactOnStaticResponse'>Plot static object response time against aggregate data rate
</h2><span id='topic+plotDataRateImpactOnStaticResponse'></span>

<h3>Description</h3>

<p>Generates a plot of 95th percentile response time for static objects against 
aggregate data rate, for ten minute intervals in the dataframe provided.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDataRateImpactOnStaticResponse(dataFrame) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDataRateImpactOnStaticResponse_+3A_dataframe">dataFrame</code></td>
<td>

<p>a transaction data frame  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a base graphics plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSave">plotSave</a></code>
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

plotDataRateImpactOnStaticResponse(logdf) 
</code></pre>

<hr>
<h2 id='plotErrorRateByHour'>Plots rates of HTTP response code groups by hour  
</h2><span id='topic+plotErrorRateByHour'></span>

<h3>Description</h3>

<p>Generates a stacked bar plot of http response code types (2xx Success, 3xx Redirect, 4xx User Error and 5xx System Error) by hour.
</p>
<p>The x-axis is hours and the plot is limited to 24 axis labels (optimally this is one day) regardless of how many days are being reported. 
This ensures that the labels are readable.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotErrorRateByHour(dataFrame) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotErrorRateByHour_+3A_dataframe">dataFrame</code></td>
<td>

<p>a transaction data frame created by <code><a href="#topic+logFileRead">logFileRead</a></code> or <code><a href="#topic+logFileListRead">logFileListRead</a></code> 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot2 plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSaveGG">plotSaveGG</a></code>
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logFileRead">logFileRead</a></code>
<code><a href="#topic+logFileListRead">logFileListRead</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

plotErrorRateByHour(logdf) 
</code></pre>

<hr>
<h2 id='plotFrequencyHistogram'>Plot histogram of response times for a transaction dataframe 
</h2><span id='topic+plotFrequencyHistogram'></span>

<h3>Description</h3>

<p>Generates a plot of response time frequencies.  
</p>
<p>Times are expressed in seconds.  
</p>
<p>The histogram bin width is a minimum of 0.1 seconds, or 1/200 of the maximum elapsed time.  The graph tries to show a minimum of 20 bins (2 seconds), 
for data with very small elapsed times this can lead to graphs with significant empty space on the right.  
</p>
<p>If the maximum elapsed is greater than 99 seconds, the x axis labels are rotated so that they do not overlap.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotFrequencyHistogram(theDf) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotFrequencyHistogram_+3A_thedf">theDf</code></td>
<td>

<p>a transaction data frame  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot2 plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSaveGG">plotSaveGG</a></code>
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

plotFrequencyHistogram(logdf) 
</code></pre>

<hr>
<h2 id='plotFrequencyHistogramOutlierCutoff'>Plot frequencies of elapsed times up to a percentile cutoff</h2><span id='topic+plotFrequencyHistogramOutlierCutoff'></span>

<h3>Description</h3>

<p>Given a column of values or a data frame created by readFileList or readFile, generate a ggplot of a frequency histogram excluding values above a specified percentile</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotFrequencyHistogramOutlierCutoff(theDf, outlierCutoff) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotFrequencyHistogramOutlierCutoff_+3A_thedf">theDf</code></td>
<td>

<p>Either a data frame created by readFile or readFileList or a vector of numeric values (assumed to be elapsed times).
</p>
</td></tr>
<tr><td><code id="plotFrequencyHistogramOutlierCutoff_+3A_outliercutoff">outlierCutoff</code></td>
<td>

<p>A value between 0 and 1 which specifies the percentile above which values are excluded.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is used to produce histogram plots of elapsed times with outliers excluded.  
It can accept either a list (which is converted to a data frame with the column named 'elapsed' or a data frame from a log file.  
</p>


<h3>Value</h3>

<p>Returns a ggplot2 plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSaveGG">plotSaveGG</a></code>
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logFileRead">logFileRead</a></code>
<code><a href="#topic+logFileListRead">logFileListRead</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

plotFrequencyHistogramOutlierCutoff(logdf, 0.95) 
</code></pre>

<hr>
<h2 id='plotParallelismRateImpactOnResponse'>Plot response time against degree of parallelism</h2><span id='topic+plotParallelismRateImpactOnResponse'></span>

<h3>Description</h3>

<p>Generates a plot of the effect of overall parallelism on response time possibly limited to a single URL in the overall background, the URL whose time is calculated, and by http response type and status.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotParallelismRateImpactOnResponse(b, 
      intervalLength = 600, 
			excludeURLOverall="", 
			includeURLOverall="",
			excludeResponse="",
			includeResponse="", 
			excludeStatus="",
			includeStatus="",
			percentileCutoff = 1,
			title="Degree of Parallelism and Response Time", 
			subtitle="")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_b">b</code></td>
<td>

<p>a transaction data frame  
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_intervallength">intervalLength</code></td>
<td>

<p>length of the intervals (in seconds) that parallelism is calculated over
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_excludeurloverall">excludeURLOverall</code></td>
<td>

<p>a URL to be deleted from the dataset
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_includeurloverall">includeURLOverall</code></td>
<td>

<p>the URL to be included from the dataset
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_excluderesponse">excludeResponse</code></td>
<td>

<p>a URL to be excluded from the response time calculation
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_includeresponse">includeResponse</code></td>
<td>

<p>the URL to be used for the response time calculation
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_excludestatus">excludeStatus</code></td>
<td>

<p>a status to be excluded from the response time calculation, for example success statuses could be excluded.  Possible status values are: 'Success', 'Redirect', 'Client Error' or 'Server Error'
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_includestatus">includeStatus</code></td>
<td>

<p>a status to filter URLs by, for example, only include success responses in the response time calculation 
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_percentilecutoff">percentileCutoff</code></td>
<td>

<p>exclude values above the specified quantile, intended for use in excluding outlier events that would distort the elapsed time calculation 
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_title">title</code></td>
<td>

<p>the plot title
</p>
</td></tr>
<tr><td><code id="plotParallelismRateImpactOnResponse_+3A_subtitle">subtitle</code></td>
<td>

<p>the plot subtitle
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an R base graphics plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSave">plotSave</a></code>
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")
plotParallelismRateImpactOnResponse(logdf,
            includeStatus="Success",
            excludeResponse="Static Content Requests",
            percentileCutoff=0.95)
</code></pre>

<hr>
<h2 id='plotResponseTimeScatter'>Generates a scatter plot of response times  
</h2><span id='topic+plotResponseTimeScatter'></span><span id='topic+plotLogResponseTimeScatter'></span>

<h3>Description</h3>

<p>Scatter plot (base graphics object) of response times from a data.  The log form uses a log10 y axis.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotLogResponseTimeScatter(times, elapsed,timeDivisor = 1000, ylabText = "Time (log sec)") 
plotResponseTimeScatter(times, elapsed,timeDivisor = 1000, ylabText = "Time (sec)") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotResponseTimeScatter_+3A_times">times</code></td>
<td>

<p>POSIXct timestamps
</p>
</td></tr>
<tr><td><code id="plotResponseTimeScatter_+3A_elapsed">elapsed</code></td>
<td>

<p>elapsed milliseconds 
</p>
</td></tr>
<tr><td><code id="plotResponseTimeScatter_+3A_timedivisor">timeDivisor</code></td>
<td>

<p>divisor to adjust times to seconds (the default value of 1000) or some other interval
</p>
</td></tr>
<tr><td><code id="plotResponseTimeScatter_+3A_ylabtext">ylabText</code></td>
<td>

<p>divisor to adjust times to seconds (the default value of 1000) or some other interval
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generates a base graphics plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSave">plotSave</a></code>
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="grDevices.html#topic+savePlot">savePlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]] # only want one

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

plotResponseTimeScatter(logdf$ts, logdf$elapsed) 
plotLogResponseTimeScatter(logdf$ts, logdf$elapsed) 
</code></pre>

<hr>
<h2 id='plotSave'>Save a plot to a file with a generated name</h2><span id='topic+plotSave'></span><span id='topic+plotSaveGG'></span>

<h3>Description</h3>

<p>These two functions save a base graphics plot function call or a ggplot object to a file with a generated name in the format (eps or jpg) specified and return the generated file name.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSaveGG(thePlot, fileID, fileType = "jpg") 
plotSave(thePlot,
      fileID, 
      fileType = "jpg", 
      imageQuality=90, 
      imageDefaultWidth=600, 
      imageDefaultHeight=400) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotSave_+3A_theplot">thePlot</code></td>
<td>

<p>Either a base graphics plot function call or a ggplot plot object.  The base graphics function call is valuated within the function, not at the time of the call (A peculiarity of the R language)
</p>
</td></tr>
<tr><td><code id="plotSave_+3A_fileid">fileID</code></td>
<td>

<p>A unique ID for the file.  This ID is used to generate a hash which is used as the file name.  The ID may contain any characters and can, for example be a URL which would not otherwise be a valid filename.  
</p>
</td></tr>
<tr><td><code id="plotSave_+3A_filetype">fileType</code></td>
<td>

<p>Either eps or jpg depending on the file format required.  EPS files grow significantly as the number of data points grows.  For very large data sets jpg is preferable.    
</p>
</td></tr>
<tr><td><code id="plotSave_+3A_imagequality">imageQuality</code></td>
<td>

<p>The percent quality for JPG file construction.  EPS files are metafiles and do not have a percent quality.  
</p>
</td></tr>
<tr><td><code id="plotSave_+3A_imagedefaultwidth">imageDefaultWidth</code></td>
<td>

<p>The width in pixels of the image 
</p>
</td></tr>
<tr><td><code id="plotSave_+3A_imagedefaultheight">imageDefaultHeight</code></td>
<td>

<p>The height in pixels of the image 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the generated file name after creating the file.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

plotSaveGG(plotErrorRateByHour(logdf),"xxx", "eps")
plotSave(plotResponseTimeScatter(logdf$ts, logdf$elapsed), "yyy", "jpg")

</code></pre>

<hr>
<h2 id='plotTransactionRateImpactOnDynamicContentResponse'>Generate a plot of mean transaction rate by interval against dynamic content response</h2><span id='topic+plotTransactionRateImpactOnDynamicContentResponse'></span>

<h3>Description</h3>

<p>Calls <code><a href="#topic+plotByRate">plotByRate</a></code> internally to generate a rate plot.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotTransactionRateImpactOnDynamicContentResponse(b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotTransactionRateImpactOnDynamicContentResponse_+3A_b">b</code></td>
<td>

<p>a transaction data frame created by <code><a href="#topic+logFileRead">logFileRead</a></code> or <code><a href="#topic+logFileListRead">logFileListRead</a></code> 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an R base graphics plot.  This function is intended to be wrapped in a call to <code><a href="#topic+plotSave">plotSave</a></code> 
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotByRate">plotByRate</a></code>
<code><a href="grDevices.html#topic+savePlot">savePlot</a></code>
<code><a href="#topic+logFileRead">logFileRead</a></code>
<code><a href="#topic+logFileListRead">logFileListRead</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

plotTransactionRateImpactOnDynamicContentResponse(logdf)

</code></pre>

<hr>
<h2 id='plotWriteFilenameToLaTexFile'>Write an includegraphic element to the generated LaTeX file</h2><span id='topic+plotWriteFilenameToLaTexFile'></span>

<h3>Description</h3>

<p>Writes an includegraphic element to the brew-generated LaTeX file.  Written to be used in a series of nested calls as shown in the example. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotWriteFilenameToLaTexFile(graphicFileName) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotWriteFilenameToLaTexFile_+3A_graphicfilename">graphicFileName</code></td>
<td>

<p>The name of the file to be included in the LaTeX
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Does not return a value
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

plotWriteFilenameToLaTexFile(plotSaveGG(plotErrorRateByHour(logdf),"xxx", "eps"))

</code></pre>

<hr>
<h2 id='printPercentiles'>calculate quantile values from a column and print as an xtable vertically  
</h2><span id='topic+printPercentiles'></span>

<h3>Description</h3>

<p>Calculate quantile values for a supplied numeric list.  .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>printPercentiles(column, 
      dataName, 
      percentileList=c(0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 1)) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="printPercentiles_+3A_column">column</code></td>
<td>

<p>a vector of numeric values.  The values will be rounded to two decimal places before calculation.  
</p>
</td></tr>
<tr><td><code id="printPercentiles_+3A_dataname">dataName</code></td>
<td>

<p>the literal value to be used as the data name in the table  
</p>
</td></tr>
<tr><td><code id="printPercentiles_+3A_percentilelist">percentileList</code></td>
<td>

<p>a list of the quantile values that are to be calculated (as decimal values in the range 0 to 1)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Does not return a value.  It prints the xtable.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataValues = c(1,1,1,2,3,4,5,6,7,8,9,10,10,10,10)
printPercentiles(dataValues, "Random Data", percentileList=c(0.5, 0.75, 0.9))
</code></pre>

<hr>
<h2 id='summaryTxDataFrameCreate'>Creates a dataframe containing summary URL performance metrics
</h2><span id='topic+summaryTxDataFrameCreate'></span>

<h3>Description</h3>

<p>From a dataframe containing log data, calculate 95th percentile response, total wait and error counts, embed TeX hyperlinks referencing the URL.  
Return these in a dataframe intended for printing in a report.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryTxDataFrameCreate(logDataframe) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summaryTxDataFrameCreate_+3A_logdataframe">logDataframe</code></td>
<td>

<p>a dataframe created by the functions that read log files.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe containing columns
</p>

<dl>
<dt>Response (sec, 95th pctl)</dt><dd><p>95th Percentile response time for the URL</p>
</dd>
<dt>Transaction</dt><dd><p>The URL</p>
</dd>
<dt>Count</dt><dd><p>Number of requests for that URL</p>
</dd>
<dt>Total Wait (sec)</dt><dd><p>Total wait time for the URL in seconds</p>
</dd>
<dt>Server Errors</dt><dd><p>Number of HTTP 5xx  errors</p>
</dd>
<dt>Client Error</dt><dd><p>Number of HTTP 4xx errors</p>
</dd>
<dt>Redirect</dt><dd><p>Number of HTTP 3xx responses</p>
</dd>
<dt>Success</dt><dd><p>Number of HTTP 200 responses</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

summarydf = summaryTxDataFrameCreate(logdf)
</code></pre>

<hr>
<h2 id='summaryTxTablePrint'>Prints a transaction summary table generated by summaryTxDataFrameCreate 
</h2><span id='topic+summaryTxTablePrint'></span>

<h3>Description</h3>

<p>Formats and prints the LaTeX for a transaction summary table as generated by <code><a href="#topic+summaryTxDataFrameCreate">summaryTxDataFrameCreate</a></code>.
</p>
<p>The first column in the table is assumed to be a URL and is 0.6 times the width of the text page, subsequent column are formatted left or right aligned as appropriate for numeric or character variables.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryTxTablePrint(dataFrame, formatFunctions=NULL) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summaryTxTablePrint_+3A_dataframe">dataFrame</code></td>
<td>

<p>transaction summary data frame generated by <code><a href="#topic+summaryTxDataFrameCreate">summaryTxDataFrameCreate</a></code>
</p>
</td></tr>
<tr><td><code id="summaryTxTablePrint_+3A_formatfunctions">formatFunctions</code></td>
<td>

<p>a list of formatting functions that accept a value and return a formatted value.  The sample report includes functions f0, f2 that format numbers with 0 or 2 respectively decimal places.   
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Does not return a value.  It prints the xtable.  
</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
f0&lt;-function(n)
{
	return(format(n,digits=1,nsmall=0,big.mark=","))
}
f2&lt;-function(n)
{
	return(format(n,digits=2,nsmall=2,big.mark=","))
}
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

cols = logFileFieldsGetIIS(logFileName)

logdf = logFileRead(logFileName, columnList=cols, 
            logTimeZone = "", timeFormat = "")

summarydf = summaryTxDataFrameCreate(logdf)

summaryTxTablePrint(summarydf[1:40,c(2,1,4,3)],list(format, f2, f2, f0))

</code></pre>

<hr>
<h2 id='WebAnalytics-package'>
Tools for web server log performance reporting
</h2><span id='topic+WebAnalytics-package'></span><span id='topic+WebAnalytics'></span>

<h3>Description</h3>

<p>The WebAnalytics package is a simple, low-impact way of getting detailed insights into the performance of a web application and of identifying opportunities for remediation.  It generates detailed analytical reports on application response time from web server logs.  
</p>
<p>The objective of the package is to extract the maximum value from web server log data and to use that information to identify problems and potential areas for remediation.  It enables you to easily read web server log files; generate histograms, scatter plots and tabular reports of response times, overall and per URL; to generate some diagnostic plots; and to generate a LaTeX document that can then be formatted as a PDF.  The package supplies scripts and templates to do that document generation.  
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> WebAnalytics</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-10-04</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL 3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>This code was used for many years in a performance consulting/toubleshooting context, dealing with systems 
that were not set up with comprehensive monitoring infrastructure, and sometimes with systems that did have monitoring infrastructure but which did not generate useful measures (percentiles are difficult to calculate on stream data, sometimes too little data is retained for longitudinal analysis), or which rolled up performance metrics to mean values over long 
intervals, destroying the short term information in the logs.  For some systems the diagnostic plots were interesting by themselves.  
</p>
<p>It is not a debugging tool, it indicates where problems are and where there are behaviours that are unexpected: the tables and histograms identifying multiple code paths that developers may not be aware of, the diagnostic plots indicating contention, the scatter plots indicating short term variations in response time that are indicative of some kind of problem.  All these enable potential fixes to be worked on, and once those fixes are developed, enabling direct measurement of the impact using the baselining graphs and tables.
</p>
<p>A sample PDF report can be generated in the current directory, with work files saved in under the R tempdir using the following code fragment:
</p>
<pre>
library(WebAnalytics)
filesDir = paste0(tempdir(),"/ex")
configVariableSet("config.workdir", filesDir)
workingDirectoryPopulate(".")
pdfGenerate()
</pre>
<p>The generated report provides the following:
</p>
<p><b>Response Time Overview</b>
</p>

<ul>
<li><p> Detailed Response Time Percentiles
</p>
</li>
<li><p> Response Time Change over baseline workload (if a baseline log is supplied and the baseline is read)
</p>
</li>
<li><p> Request/Response Size Percentile Breakdown 
</p>
</li>
<li><p> Response Times by Time - Scatter Plot 
</p>
</li>
<li><p> Response Time Histogram 
</p>
</li>
<li><p> Request Status by Hour 
</p>
</li>
<li><p> Top Transactions by 95th percentile response time 
</p>
</li>
<li><p> Top Transactions by aggregate response time 
</p>
</li>
<li><p> Top Transactions by error rate
</p>
</li></ul>

<p>This section addresses questions such as
</p>

<ul>
<li><p> How many static, dynamic and monitoring requests are there in the logs?
</p>
</li>
<li><p> How much of total system processing time is accounted for by static, dynamic and monitoring requests?
</p>
</li>
<li><p> How much static, dynamic and monitoring data transfer is there?
</p>
</li>
<li><p> How many requests per hour are made and in what hours?
</p>
</li>
<li><p> What are the transactions with the highest 95th percentile response times?
</p>
</li>
<li><p> What are the transactions that account for the most aggregate wait time in the system?
</p>
</li></ul>

<p>The 95th percentile and aggregate wait time tables are useful to identify those tramnsactions that could repay some
performance optimisation.  Anything high in both lists is worth investigating.  
</p>
<p><b>Transaction Data for each URL</b>
</p>

<ul>
<li><p> response time percentiles
</p>
</li>
<li><p> response time scatter plot by time of day
</p>
</li>
<li><p> response time histogram
</p>
</li>
<li><p> error rate by hour
</p>
</li>
<li><p> and variances over a baseline dataset (useful for comparing before and after release performance)
</p>
</li></ul>

<p>This addresses questions such as
</p>

<ul>
<li><p> What is the clock time distribution of requests and response times for a URL?
</p>
</li>
<li><p> How many distinct groups of response times are there for a URL? 
</p>
</li>
<li><p> How have these metrics changed relative to a baseline set of log data?
</p>
</li></ul>

<p><b>Browser Mix Percentages</b> 
</p>

<ul>
<li><p> Browser family percentiles
</p>
</li>
<li><p> Browser family and version percentiles
</p>
</li></ul>

<p>These percentages are useful for identifying which browsers and versions need to be tested.  
</p>
<p><b>Diagnostic Charts</b>
</p>

<ul>
<li><p> 95th percentile response time by request rate
</p>
</li>
<li><p> Dynamic Content Response time by degree of request concurrency
</p>
</li>
<li><p> Static Content Redirect time by degree of request concurrency 
</p>
</li>
<li><p> Static Content (successful requests) time by request concurrency 
</p>
</li>
<li><p> Static Content (successful requests) time by outbound data rate
</p>
</li></ul>
 
<p>These plots mostly adddress the scalability of the system.  
</p>
<p><b>Percentile Comparison of transaction mix with baseline reporting period</b>
</p>

<ul>
<li><p> Input Data stats
</p>
</li>
<li><p> Transaction Counts and percentages by URL 
</p>
</li>
<li><p> Transaction Waits and percentages by URL 
</p>
</li></ul>

<p>These are primarily used for callibrating test workloads to ensure that the transaction mix is similar to the production workload, or the planned workload.  
</p>
<p><b>Server and Session Analysis</b>
</p>

<ul>
<li><p> Server Request Counts 
</p>
</li>
<li><p> Session Request Counts
</p>
</li>
<li><p> Unique Sessions by Hour
</p>
</li></ul>

<p>A function <code><a href="#topic+workingDirectoryPopulate">workingDirectoryPopulate</a></code> is provided to populate a working directory with all needed supporting files and a sample <span class="rlang"><b>R</b></span> report file which can be edited as needed.  The working directory contains:
</p>

<ul>
<li> <p><code>sampleRfile.R</code> - sample report template
</p>
</li>
<li> <p><code><a href="#topic+sample.config">sample.config</a></code> - configuration file for the report
</p>
</li>
<li> <p><code>logo.eps</code> - a 2cm by 2cm logo graphic (a placeholder) in EPS format
</p>
</li>
<li> <p><code>makerpt.ps1</code> - PowerShell script to run the report and process the output with <code>xelatex</code>
</p>
</li>
<li> <p><code>makerpt.sh</code> - bash script to run the report and process the output with <code>xelatex</code> 
</p>
</li>
<li> <p><code>WebAnalytics.cls</code> - the report LaTeX class
</p>
</li></ul>

<p>An R function, <code><a href="#topic+workingDirectoryPopulate">workingDirectoryPopulate</a></code> will place copies of all necessary files in a directory, already configured to generate a sample PDF report from test data supplied with the package.
</p>
<p>The supplied
configuration file <code><a href="#topic+sample.config">sample.config</a></code> read by the report script provides enough flexibility for most purposes.  Switches are provided to turn on or off different sections of the report.  Edit the config file, <code><a href="#topic+sample.config">sample.config</a></code> to update the list of column names and data types (documented in <code><a href="#topic+logFileRead">logFileRead</a></code> or use the IIS log utility function <code><a href="#topic+logFileFieldsGetIIS">logFileFieldsGetIIS</a></code>.  The directory structure that it assumes is that there is a data directory identified in <code>config.current.dataDir</code> with multiple log directories under it (<code>config.current.dirNames</code>).  This applies to both current data and the baseline log.  The default behaviour of the script is to read the lexically last file name with a <code>.log</code> extension from each log directory and it checks that the log names are the same in each directory.  This is consistent with a structure in which logs are regularly copied into a log directory for processing or where some pre-processing is required, for example where the log is being written with a varying number of fields as a result of sme other configuration by network or admin teams.  Additional functions are provided to select all or some files: <code><a href="#topic+logFileNamesGet">logFileNamesGet</a></code>, <code><a href="#topic+logFileNamesGetAll">logFileNamesGetAll</a></code>, <code><a href="#topic+logFileNamesGetLast">logFileNamesGetLast</a></code>,  and <code><a href="#topic+logFileNamesGetLastMatching">logFileNamesGetLastMatching</a></code> and these can be substituted in the report template as needed.  
</p>
<p>There are multiple ways to run <code>xelatex</code> on the generated template. A bash script and a Powershell script are provided to do that if you have LaTeX already installed.  Run the sample script and config file that are created in that directory using the command <code>. ./makerpt.sh sample</code> or  <code>powershell -f makerpt.ps1 sample</code> to generate a sample PDF from the test data supplied as part of the package.  If you do not have a LaTeX installation, The R package <a href="https://CRAN.R-project.org/package=tinytex"><span class="pkg">tinytex</span></a> can be used to install LaTeX and a function <code><a href="#topic+pdfGenerate">pdfGenerate</a></code> is provided in this package to do the PDF generation from within R.
</p>
<p>The package uses the CRAN package <a href="https://CRAN.R-project.org/package=brew"><span class="pkg">brew</span></a> to produce the LaTeX source from a Brew template and comes with its own LaTeX document class and a blank logo graphic, both of which can be tailored as needed.  
</p>
<p>The generated LaTeX document has been tested with <code>xelatex</code> and is known not to work with plain LaTeX because of font issues.  
</p>
<p>The package requires Apache or IIS log files to contain elapsed times in addition to timestamps, HTTP verbs, HTTP response codes and URLs. In Apache the elapsed time is provided by the <code>%d</code> or <code>%D</code> format specifier in a log format specification  string.  In IIS the <code>time-taken</code> field must be added to the log format.  If supplied, the request and response sizes are also used by the report.  For WebSphere applications, adding the JSESSIONID cookie to the log enables server-level session statistics (the server ID is parsed out of the WebSphere JSESSIONID cookie value, if the JSESSIONID cookie is not of the format <code>serverID:sessionID</code> the server distribution will be represented by a single server. To get session-level information without the cookie being present, it might be possible to use the client IP (depending on the structure of the network), in which case, adding
</p>
<pre>b$jsessionid = b$userip
b$serverid = 1
</pre>
<p>to the <code>config.fix.data</code> function, in the sample configuration file, will provide some useful information.  
</p>
<p>The <code>config.fix.data</code> function is used to classify URLS as dynamic (the URL is retained), static or monitoring.  The script depends on the literals that are used and the function must use those literals to identify Static and monitoring requests.  
</p>


<h3>Author(s)</h3>

<p>Maintainer: Greg Hunt <a href="mailto:greg@firmansyah.com">greg@firmansyah.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# find the *.log files in the directory 
logFileName = logFileNamesGetLast(dataDirectory=datd, 
  directoryNames=c(".", "."), 
  fileNamePattern="*[.]log")[[1]]

# get the columns from an IIS log
cols = logFileFieldsGetIIS(logFileName)

# read the log file as the current data 
logdf = logFileListRead(logFileName, 
          readFunction=logFileRead, 
          columnList=cols)
          
# read a baseline data set 
logbasedf = logFileListRead(logFileName, 
          readFunction=logFileRead, 
          columnList=cols)
  
# compare percentage counts and delays between 
#   baseline and current, useful for load test callibration 
plotWriteFilenameToLaTexFile(
  plotSaveGG(
    # convert elapsed time to seconds
    percentileBaselinePrint(logdf$elapsed/1000, 
              logbasedf$elapsed/1000,    
              columnNames = c("Delta", "Current", "Baseline", "Percentile"))
    , "xxx")
    )

## End(Not run)

</code></pre>

<hr>
<h2 id='workingDirectoryPopulate'>Create  files in the working directory to be used for report generation
</h2><span id='topic+workingDirectoryPopulate'></span>

<h3>Description</h3>

<p>The function creates the specified directory (if it does not already exist) and creates the configured file directory (by default the name is 'txdata') if that does not exist.  If the files directory has an absolute path it is created, if it is a relative path it is appended to the work directory path and created.  The work directory contains the report template and scripts, the files directory holds the images that are generated by the report template.  
It creates the following files:
</p>

<dl>
<dt>makerpt.ps1</dt><dd><p>PowerShell script to generate the report.  The script is run by specifying its name followed by the stem part of the R file that contains the script <code>.\makerpt.ps1 reportname</code></p>
</dd>
<dt>makerpt.sh</dt><dd><p>bash script to generate the report.  The script is run by specifying its name followed by the stem part of the R file that contains the script <code>./makerpt.sh reportname</code></p>
</dd>
<dt>size10.clo</dt><dd><p>A file used by LaTex that specifies the page layout</p>
</dd>
<dt>webanalyticsreport.cls</dt><dd><p>A latex document class that the report uses</p>
</dd>
<dt>logo.eps</dt><dd><p>A 2cm square eps logo placed in the top right corner of each report page</p>
</dd>
<dt>sampleRfile.R</dt><dd><p>An outline R report file</p>
</dd>
</dl>

<p>If a file exists and has different content to the new file it will be renamed (a timestamp suffix added to the name) before the new file is created.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>workingDirectoryPopulate(directoryName = ".")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="workingDirectoryPopulate_+3A_directoryname">directoryName</code></td>
<td>

<p>A character string that specifies the name of the directory to be created and populated
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function does not return a value</p>


<h3>Author(s)</h3>

<p>Greg Hunt &lt;greg@firmansyah.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># in the current directory run it as 
# workingDirectoryPopulate()


workingDir = paste0(tempdir(),"/wk")

workingDirectoryPopulate(workingDir)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
