<!DOCTYPE html><html><head><title>Help for package dgof</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dgof}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cvm.test'><p>Discrete Cramer-von Mises Goodness-of-Fit Tests</p></a></li>
<li><a href='#ks.test'><p>Kolmogorov-Smirnov Tests</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-07-16</td>
</tr>
<tr>
<td>Title:</td>
<td>Discrete Goodness-of-Fit Tests</td>
</tr>
<tr>
<td>Author:</td>
<td>Taylor B. Arnold, John W. Emerson, R Core Team and contributors
        worldwide</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Taylor B. Arnold &lt;taylor.b.arnold@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A revision to the stats::ks.test() function and the associated
        ks.test.Rd help page. With one minor exception, it does not change the
        existing behavior of ks.test(), and it adds features necessary
        for doing one-sample tests with hypothesized discrete
        distributions. The package also contains cvm.test(), for doing
        one-sample Cramer-von Mises goodness-of-fit tests.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-16 16:06:55 UTC; taylor</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-16 16:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cvm.test'>Discrete Cramer-von Mises Goodness-of-Fit Tests</h2><span id='topic+cvm.test'></span>

<h3>Description</h3>

<p>Computes the test statistics for doing one-sample Cramer-von Mises goodness-of-fit tests
and calculates asymptotic p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvm.test(x, y, type = c("W2", "U2", "A2"),
         simulate.p.value=FALSE, B=2000, tol=1e-8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvm.test_+3A_x">x</code></td>
<td>
<p>a numerical vector of data values.</p>
</td></tr>
<tr><td><code id="cvm.test_+3A_y">y</code></td>
<td>
<p>an <code><a href="stats.html#topic+ecdf">ecdf</a></code> or step-function (<code><a href="stats.html#topic+stepfun">stepfun</a></code>) for specifying the hypothesized model.</p>
</td></tr>
<tr><td><code id="cvm.test_+3A_type">type</code></td>
<td>
<p>the variant of the Cramer-von Mises test; <code>"W2"</code> is the default and most common method, <code>"U2"</code> is for cyclical data, and <code>"A2"</code> is the Anderson-Darling alternative. For details see references.</p>
</td></tr>
<tr><td><code id="cvm.test_+3A_simulate.p.value">simulate.p.value</code></td>
<td>
<p>a logical indicating whether to compute
p-values by Monte Carlo simulation.</p>
</td></tr>
<tr><td><code id="cvm.test_+3A_b">B</code></td>
<td>
<p>an integer specifying the number of replicates used in the
Monte Carlo test (for discrete goodness-of-fit tests only).</p>
</td></tr>
<tr><td><code id="cvm.test_+3A_tol">tol</code></td>
<td>
<p>used as an upper bound for possible rounding error in values
(say, <code>a</code> and <code>b</code>) when needing to check for equality
(<code>a==b</code>) (for discrete goodness-of-fit tests only).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>While the Kolmogorov-Smirnov test may be the most
popular of the nonparametric goodness-of-fit tests,
Cramer-von Mises tests have been shown to be more
powerful against a large class of alternatives hypotheses. 
The original test was developed by Harald
Cramer and Richard von Mises (Cramer, 1928; von
Mises, 1928) and further adapted by Anderson and
Darling (1952), and Watson (1961).
</p>


<h3>Value</h3>

<p>An object of class <code>htest</code>.
</p>


<h3>Note</h3>

<p>Additional notes?
</p>


<h3>Author(s)</h3>

<p>Taylor B. Arnold and John W. Emerson
</p>
<p>Maintainer: Taylor B. Arnold &lt;taylor.arnold@yale.edu&gt;
</p>


<h3>References</h3>

<p>T. W. Anderson and D. A. Darling (1952). <em>Asymptotic
theory of certain &quot;goodness of fit&quot; criteria based on stochastic
processes.</em> Annals of Mathematical Statistics, 23:193-212.
</p>
<p>V. Choulakian, R. A. Lockhart, and M. A. Stephens (1994).
<em>Cramer-von Mises statistics for discrete distributions</em>.
The Canadian Journal of Statistics, 22(1): 125-137.
</p>
<p>H. Cramer (1928).
<em>On the composition of elementary errors.</em>
Skand. Akt., 11:141-180.
</p>
<p>M. A. Stephens (1974).
<em>Edf statistics for goodness of fit and some comparisons</em>.
Journal of the American Statistical Association, 69(347): 730-737.
</p>
<p>R. E. von Mises (1928).
<em>Wahrscheinlichkeit, Statistik und Wahrheit.</em>
Julius Springer, Vienna, Austria.
</p>
<p>G. S. Watson (1961).  <em>Goodness of fit tests on the circle.</em>
Biometrika, 48:109-114.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ks.test">ks.test</a></code>, <code><a href="stats.html#topic+ecdf">ecdf</a></code>, <code><a href="stats.html#topic+stepfun">stepfun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(dgof)

x3 &lt;- sample(1:10, 25, replace=TRUE)

# Using ecdf() to specify a discrete distribution:
ks.test(x3, ecdf(1:10))
cvm.test(x3, ecdf(1:10))

# Using step() to specify the same discrete distribution:
myfun &lt;- stepfun(1:10, cumsum(c(0, rep(0.1, 10))))
ks.test(x3, myfun)
cvm.test(x3, myfun)

# Usage of U2 for cyclical distributions (note U2 unchanged, but W2 not)

set.seed(1)
y &lt;- sample(1:4, 20, replace=TRUE)
cvm.test(y, ecdf(1:4), type='W2')
cvm.test(y, ecdf(1:4), type='U2')
z &lt;- y
cvm.test(z, ecdf(1:4), type='W2')
cvm.test(z, ecdf(1:4), type = 'U2')

# Compare analytic results to simulation results
set.seed(1)
y &lt;- sample(1:3, 10, replace=TRUE)
cvm.test(y, ecdf(1:6), simulate.p.value=FALSE)
cvm.test(y, ecdf(1:6), simulate.p.value=TRUE)

</code></pre>

<hr>
<h2 id='ks.test'>Kolmogorov-Smirnov Tests</h2><span id='topic+ks.test'></span>

<h3>Description</h3>

<p>Performs one or two sample Kolmogorov-Smirnov tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>

ks.test(x, y, ...,
        alternative = c("two.sided", "less", "greater"),
        exact = NULL, tol=1e-8, simulate.p.value=FALSE, B=2000)


</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ks.test_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>


<tr><td><code id="ks.test_+3A_y">y</code></td>
<td>
<p>a numeric vector of data values, or a character string
naming a cumulative distribution function or an actual cumulative
distribution function such as <code>pnorm</code>. Alternatively, <code>y</code>
can be an <code><a href="stats.html#topic+ecdf">ecdf</a></code> function (or an object of class
<code><a href="stats.html#topic+stepfun">stepfun</a></code>) for specifying a discrete distribution.</p>
</td></tr>


<tr><td><code id="ks.test_+3A_...">...</code></td>
<td>
<p>parameters of the distribution specified (as a character
string) by <code>y</code>.</p>
</td></tr>
<tr><td><code id="ks.test_+3A_alternative">alternative</code></td>
<td>
<p>indicates the alternative hypothesis and must be
one of <code>"two.sided"</code> (default), <code>"less"</code>, or
<code>"greater"</code>.  You can specify just the initial letter of the
value, but the argument name must be give in full.
See &lsquo;Details&rsquo; for the meanings of the possible values.</p>
</td></tr>
<tr><td><code id="ks.test_+3A_exact">exact</code></td>
<td>
<p><code>NULL</code> or a logical indicating whether an exact
p-value should be computed.  See &lsquo;Details&rsquo; for the meaning of
<code>NULL</code>.  Not used for the one-sided two-sample case.</p>
</td></tr>


<tr><td><code id="ks.test_+3A_tol">tol</code></td>
<td>
<p>used as an upper bound for possible rounding error in values
(say, <code>a</code> and <code>b</code>) when needing to check for equality
(<code>a==b</code>); value of <code>NA</code> or <code>0</code> does exact comparisons
but risks making errors due to numerical imprecisions.</p>
</td></tr>
<tr><td><code id="ks.test_+3A_simulate.p.value">simulate.p.value</code></td>
<td>
<p>a logical indicating whether to compute
p-values by Monte Carlo simulation, for discrete goodness-of-fit
tests only.</p>
</td></tr>
<tr><td><code id="ks.test_+3A_b">B</code></td>
<td>
<p>an integer specifying the number of replicates used in the
Monte Carlo test (for discrete goodness-of-fit tests only).</p>
</td></tr>


</table>


<h3>Details</h3>

<p>If <code>y</code> is numeric, a two-sample test of the null hypothesis
that <code>x</code> and <code>y</code> were drawn from the same <em>continuous</em>
distribution is performed.
</p>


<p>Alternatively, <code>y</code> can be a character string naming a continuous
(cumulative) distribution function (or such a function),
or an <code><a href="stats.html#topic+ecdf">ecdf</a></code> function
(or object of class <code>stepfun</code>) giving a discrete distribution.  In
these cases, a one-sample test is carried  out of the null that the
distribution function which generated <code>x</code> is distribution <code>y</code>
with parameters specified by <code>...</code>.
</p>
<p>The presence of ties generates a warning unless <code>y</code> describes a discrete
distribution (see above), since continuous distributions do not generate them.


</p>
<p>The possible values <code>"two.sided"</code>, <code>"less"</code> and
<code>"greater"</code> of <code>alternative</code> specify the null hypothesis
that the true distribution function of <code>x</code> is equal to, not less
than or not greater than the hypothesized distribution function
(one-sample case) or the distribution function of <code>y</code> (two-sample
case), respectively.  This is a comparison of cumulative distribution
functions, and the test statistic is the maximum difference in value,
with the statistic in the <code>"greater"</code> alternative being
<code class="reqn">D^+ = \max_u [ F_x(u) - F_y(u) ]</code>.
Thus in the two-sample case
<code>alternative="greater"</code> includes distributions for which <code>x</code>
is stochastically <em>smaller</em> than <code>y</code> (the CDF of <code>x</code> lies
above and hence to the left of that for <code>y</code>), in contrast to
<code><a href="stats.html#topic+t.test">t.test</a></code> or <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>.
</p>


<p>Exact p-values are not available for the one-sided two-sample case,
or in the case of ties if <code>y</code> is continuous.  If <code>exact = NULL</code>
(the default), an exact p-value is computed if the sample size is less
than 100 in the one-sample case with <code>y</code> continuous or if the sample
size is less than or equal to 30 with <code>y</code>
discrete; or if the product of the
sample sizes is less than 10000 in the two-sample case for continuous
<code>y</code>.  Otherwise,
asymptotic distributions are used whose approximations may be inaccurate
in small samples.  With <code>y</code> continuous,
the one-sample two-sided case, exact p-values are
obtained as described in Marsaglia, Tsang &amp; Wang (2003); the formula of
Birnbaum &amp; Tingey (1951) is used for the one-sample one-sided case.
</p>
<p>In the one-sample case with <code>y</code> discrete, the methods presented in
Conover (1972) and Gleser (1985) are used when <code>exact=TRUE</code> (or when
<code>exact=NULL</code>) and <code>length(x)&lt;=30</code> as described above.
When <code>exact=FALSE</code> or <code>exact=NULL</code> with
<code>length(x)&gt;30</code>, the test is not exact and the resulting p-values
are known to be conservative.  Usage of <code>exact=TRUE</code> with
sample sizes greater than 30 is not advised due to numerical instabilities;
in such cases, simulated p-values may be desirable.
</p>
<p>If a single-sample test is used with <code>y</code> continuous,
the parameters specified in
<code>...</code> must be pre-specified and not estimated from the data.
There is some more refined distribution theory for the KS test with
estimated parameters (see Durbin, 1973), but that is not implemented
in <code>ks.test</code>.


</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of test was
performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Modified by Taylor B. Arnold and John W. Emerson to include
one-sample testing with a discrete distribution (as presented
in Conover's 1972 paper &ndash; see references).
</p>


<h3>References</h3>

<p>Z. W. Birnbaum and Fred H. Tingey (1951),
One-sided confidence contours for probability distribution functions.
<em>The Annals of Mathematical Statistics</em>, <b>22</b>/4, 592&ndash;596.
</p>
<p>William J. Conover (1971),
<em>Practical Nonparametric Statistics</em>.
New York: John Wiley &amp; Sons.
Pages 295&ndash;301 (one-sample Kolmogorov test),
309&ndash;314 (two-sample Smirnov test).
</p>


<p>William J. Conover (1972),
A Kolmogorov Goodness-of-Fit Test for Discontinuous Distributions.
<em>Journal of American Statistical Association</em>, Vol. 67, No. 339, 591&ndash;596.
</p>
<p>Leon Jay Gleser (1985),
Exact Power of Goodness-of-Fit Tests of Kolmogorov Type for Discontinuous
Distributions.
<em>Journal of American Statistical Association</em>, Vol. 80, No. 392,  954&ndash;958.


</p>
<p>Durbin, J. (1973)
<em>Distribution theory for tests based on the sample distribution
function</em>.  SIAM.
</p>
<p>George Marsaglia, Wai Wan Tsang and Jingbo Wang (2003),
Evaluating Kolmogorov's distribution.
<em>Journal of Statistical Software</em>, <b>8</b>/18.
<a href="https://www.jstatsoft.org/v08/i18/">https://www.jstatsoft.org/v08/i18/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> which performs the Shapiro-Wilk test for
normality; <code><a href="#topic+cvm.test">cvm.test</a></code> for Cramer-von Mises type tests.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)
require(dgof)

set.seed(1)

x &lt;- rnorm(50)
y &lt;- runif(30)
# Do x and y come from the same distribution?
ks.test(x, y)
# Does x come from a shifted gamma distribution with shape 3 and rate 2?
ks.test(x+2, "pgamma", 3, 2) # two-sided, exact
ks.test(x+2, "pgamma", 3, 2, exact = FALSE)
ks.test(x+2, "pgamma", 3, 2, alternative = "gr")

# test if x is stochastically larger than x2
x2 &lt;- rnorm(50, -1)
plot(ecdf(x), xlim=range(c(x, x2)))
plot(ecdf(x2), add=TRUE, lty="dashed")
t.test(x, x2, alternative="g")
wilcox.test(x, x2, alternative="g")
ks.test(x, x2, alternative="l")

#########################################################
# TBA, JWE new examples added for discrete distributions:

x3 &lt;- sample(1:10, 25, replace=TRUE)

# Using ecdf() to specify a discrete distribution:
ks.test(x3, ecdf(1:10))

# Using step() to specify the same discrete distribution:
myfun &lt;- stepfun(1:10, cumsum(c(0, rep(0.1, 10))))
ks.test(x3, myfun)

# The previous R ks.test() does not correctly calculate the
# test statistic for discrete distributions (gives warning):
# stats::ks.test(c(0, 1), ecdf(c(0, 1)))
# ks.test(c(0, 1), ecdf(c(0, 1)))

# Even when the correct test statistic is given, the
# previous R ks.test() gives conservative p-values:
stats::ks.test(rep(1, 3), ecdf(1:3))
ks.test(rep(1, 3), ecdf(1:3))
ks.test(rep(1, 3), ecdf(1:3), simulate=TRUE, B=10000)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
