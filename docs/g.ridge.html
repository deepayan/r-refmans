<!DOCTYPE html><html lang="en"><head><title>Help for package g.ridge</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {g.ridge}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#g.ridge'><p>g.ridge (generalized ridge regression)</p></a></li>
<li><a href='#GCV'><p>GCV (generalized cross-validation)</p></a></li>
<li><a href='#X.mat'><p>X.mat (generating a design matrix)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Generalized Ridge Regression for Linear Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Ridge regression due to Hoerl and Kennard (1970)&lt;<a href="https://doi.org/10.1080%2F00401706.1970.10488634">doi:10.1080/00401706.1970.10488634</a>&gt; and generalized ridge regression due to Yang and Emura (2017)&lt;<a href="https://doi.org/10.1080%2F03610918.2016.1193195">doi:10.1080/03610918.2016.1193195</a>&gt; with optimized tuning parameters.
 These ridge regression estimators (the HK estimator and the YE estimator) are computed by minimizing the cross-validated mean squared errors.
 Both the ridge and generalized ridge estimators are applicable for high-dimensional regressors (p&gt;n), where p is the number of regressors, and n is the sample size.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-07 05:29:27 UTC; takes</td>
</tr>
<tr>
<td>Author:</td>
<td>Takeshi Emura [aut, cre],
  Szu-Peng Yang [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Takeshi Emura &lt;takeshiemura@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-07 11:50:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='g.ridge'>g.ridge (generalized ridge regression)</h2><span id='topic+g.ridge'></span>

<h3>Description</h3>

<p>Generalized ridge regression with the optimal shrinkage parameter.
Ridge regression (Hoerl and Kennard, 1970) and
generalized ridge regression (Yang and Emura 2017) are implemented.
Tuning parameters are optimized by minimizing the CGV function (by the function CGV(.)):
See Golub et al. (1979), and Sections 2.3 and 3.3 of Yang and Emura (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g.ridge(X, Y, method = "HK", kmax = 500)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="g.ridge_+3A_x">X</code></td>
<td>
<p>design matrix of explanatory variables (regressors)</p>
</td></tr>
<tr><td><code id="g.ridge_+3A_y">Y</code></td>
<td>
<p>vector of response variables</p>
</td></tr>
<tr><td><code id="g.ridge_+3A_method">method</code></td>
<td>
<p>&quot;HK&quot; or &quot;YE&quot; for Hoerl and Kennard (1970) or Yang and Emura (2017)</p>
</td></tr>
<tr><td><code id="g.ridge_+3A_kmax">kmax</code></td>
<td>
<p>maximum possible value for the shrinkage parameter (the &quot;lambda&quot; parameter),
where the parameter is optimized in the interval (0, kmax).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>lambda: optimized shrinkage parameter
</p>
<p>delta: the optimized thresholding parameter
</p>
<p>estimate: regression coefficients (beta)
</p>
<p>SE: Standard Error
</p>
<p>Z: Z-value for testing beta=0
</p>
<p>SE: P-value for testing beta=0
</p>
<p>Sigma: variance estimate of the error distribution
(the square of the standard deviation)
</p>
<p>delta: thresholding parameter
</p>


<h3>References</h3>

<p>Yang SP, Emura T (2017) A Bayesian approach with generalized ridge estimation
for high-dimensional regression and testing, Commun Stat-Simul 46(8): 6083-105.
</p>
<p>Hoerl AE, Kennard RW (1970) Ridge regression: Biased estimation for
nonorthogonal problems. Technometrics 12:55–67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=100 # no. of observations
p=100 # no. of dimensions
q=r=10 # no. of nonzero coefficients
beta=c(rep(0.5,q),rep(0.5,r),rep(0,p-q-r))
X=X.mat(n,p,q,r)
Y=X%*%beta+rnorm(n,0,1)
g.ridge(X,Y-mean(Y),method="HK",kmax=200)
g.ridge(X,Y-mean(Y),method="YE",kmax=200)
</code></pre>

<hr>
<h2 id='GCV'>GCV (generalized cross-validation)</h2><span id='topic+GCV'></span>

<h3>Description</h3>

<p>The CGV function gives the sum of cross-validated squared errors
that can be used to optimize tuning parameters in ridge regression and
generalized ridge regression.
See Golub et al. (1979), and Sections 2.3 and 3.3 of Yang and Emura (2017) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GCV(X, Y, k, W = diag(ncol(X)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GCV_+3A_x">X</code></td>
<td>
<p>matrix of explanatory variables (design matrix)</p>
</td></tr>
<tr><td><code id="GCV_+3A_y">Y</code></td>
<td>
<p>vector of response variables</p>
</td></tr>
<tr><td><code id="GCV_+3A_k">k</code></td>
<td>
<p>shrinkage parameter (&gt;0); it is the &quot;lambda&quot; parameter</p>
</td></tr>
<tr><td><code id="GCV_+3A_w">W</code></td>
<td>
<p>matrix of weights (default is the identity matrix)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of GCV
</p>


<h3>References</h3>

<p>Yang SP, Emura T (2017) A Bayesian approach with generalized ridge estimation
for high-dimensional regression and testing, Commun Stat-Simul 46(8): 6083-105.
</p>
<p>Golub GH, Heath M, Wahba G (1979) Generalized cross-validation as
a method for choosing a good ridge parameter. Technometrics 21:215–223.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=100 # no. of observations
p=100 # no. of dimensions
q=r=10 # no. of nonzero coefficients
beta=c(rep(0.5,q),rep(0.5,r),rep(0,p-q-r))
X=X.mat(n,p,q,r)
Y=X%*%beta+rnorm(n,0,1)
GCV(X,Y,k=1)
</code></pre>

<hr>
<h2 id='X.mat'>X.mat (generating a design matrix)</h2><span id='topic+X.mat'></span>

<h3>Description</h3>

<p>A design matrix (X; nrow(X)=n, ncol(X)=p) is generated
by random numbers as previously used in our simulation studies
(Section 5 of Yang and Emura (2017); p.6093).
The design matrix has two blocks of correlated regressors
(Pearson correlation=0.5): the first q regressors and the second r regressors.
Other p-q-r regressors are independent.
If regressors are gene expressions, the correlated blocks may be regarded as
&quot;gene pathways&quot; (Emura et al. 2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.mat(n, p, q, r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="X.mat_+3A_n">n</code></td>
<td>
<p>the number of rows (samples)</p>
</td></tr>
<tr><td><code id="X.mat_+3A_p">p</code></td>
<td>
<p>the number of columns (regressors)</p>
</td></tr>
<tr><td><code id="X.mat_+3A_q">q</code></td>
<td>
<p>the number of correlated regressors in the first block (1&lt;=q&lt;p, q+r&lt;p)</p>
</td></tr>
<tr><td><code id="X.mat_+3A_r">r</code></td>
<td>
<p>the number of correlated regressors in the second block (1&lt;=r&lt;p, q+r&lt;p)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix X (nrow(X)=n, ncol(X)=p)
</p>


<h3>References</h3>

<p>Yang SP, Emura T (2017) A Bayesian approach with generalized ridge estimation
for high-dimensional regression and testing, Commun Stat-Simul 46(8): 6083-105
</p>
<p>Emura T, Chen YH, Chen HY (2012) Survival prediction based on compound covariate method
under Cox proportional hazard models PLoS ONE 7(10) doi:10.1371/journal.pone.0047627
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X.mat(n=10,p=5,q=2,r=2)
X.mat(n=100,p=50,q=10,r=10) # Case I in Section 5 of Yang and Emura (2017)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
